@&#MAIN-TITLE@&#
Global optimization of signomial geometric programming problems

@&#HIGHLIGHTS@&#
Global optimization of signomial geometric programming (SGP) problems.SGP problems are difficult, NP-hard problems to solve for global optimality.Nonconvex SGP are solved very efficiently by a series of geometric programmings.Compared with other methods, our approach rapidly and successfully solves a SGP.

@&#KEYPHRASES@&#
Geometric programming,Signomial geometric programming,Global optimization,Convexification,

@&#ABSTRACT@&#
This paper presents a global optimization approach for solving signomial geometric programming problems. In most cases nonconvex optimization problems with signomial parts are difficult, NP-hard problems to solve for global optimality. But some transformation and convexification strategies can be used to convert the original signomial geometric programming problem into a series of standard geometric programming problems that can be solved to reach a global solution. The tractability and effectiveness of the proposed successive convexification framework is demonstrated by seven numerical experiments. Some considerations are also presented to investigate the convergence properties of the algorithm and to give a performance comparison of our proposed approach and the current methods in terms of both computational efficiency and solution quality.

@&#INTRODUCTION@&#
Optimization problems that contain signomial expressions in the objective and constraint functions are usually called Signomial Geometric Programming (SGP) problems. This kind of optimization problems have a wide range of applications in engineering, science, management, etc. Examples of application of SGP are engineering design (Avriel & Barrett, 1978; Dembo & Avriel, 1978; Maranas & Floudas, 1997; Marín-Sanguino, Voit, González-Alcón, & Torres, 2007; Xu, 2013), inventory control (Jung & Klein, 2005; Kim & Lee, 1998; Mandal, Roy, & Maiti, 2006), project management (Scott & Jefferson, 1995), power control (Chiang, Tan, Palomar, O’Neill, & Julian, 2007), etc. Some comprehensive surveys of these applications can be found in Maranas and Floudas (1997), Floudas (2000), Biegler and Grossmann (2004), Chiang (2005), Boyd, Kim, Vandenberghe, and Hassibi (2007), Floudas and Gounaris (2009), Lin, Tsai, and Yu (2012).Since the SGP problems belong to a truly nonconvex class of problems that is an intrinsically intractable NP-hard problem, these problems are difficult to solve for global optimality. In the last decades, some research has been directed toward the development of global optimization strategies for SGP problems (Chiang et al., 2007; Floudas, 2000; Lange & Zhou, in press; Li & Lu, 2009; Lin & Tsai, 2012; Lundell & Westerlund, 2009a, 2009b; Lundell, Westerlund, & Westerlund, 2009; Maranas & Floudas, 1997; Pörn, Björk, & Westerlund, 2008; Qu, Zhang, & Ji, 2007; Shen, 2005; Toscano & Amouri, 2012; Tsai & Lin, 2008, 2011; Tsai, Lin, & Hu, 2007; Wang, Zhang, & Gao, 2004; Westerlund, 2007). For example, Maranas and Floudas (1997), Floudas (2000) proposed a branch-and-bound based global optimization method for the solution of SGP problems by using the exponential variable transformation and convex underestimation. Shen (2005) globally solved SGP problems through a series of linear programming problems. Chiang et al. (2007) presented a heuristic strategy that can compute truly nonconvex power control problems by solving a sequence of geometric programming (GP) problems through the method of successive convex approximations. In the practical implementation of this approach, however, more iterations are possibly required to find the approximately global optimum of a SGP problem (see Section 3.2, Example 6). Li and Lu (2009) developed a method to deal with SGP problems with mixed free-sign variables using some linearization and convexification techniques. Lundell et al. (2009) presented some power transformation and piecewise linear approximation strategies to reach a global optimal solution of optimization problems including signomial terms. Toscano and Amouri (2012) introduced some simple approaches for easily solving a kind of nonconvex problems, called quasi geometric programming problems. Lange and Zhou (in press) applied the geometric arithmetic mean inequality and a supporting hyperplane inequality to derive an MM algorithm for SGP problems. Tsai and Lin (2011) proposed an approach for solving a posynomial geometric programming with separable functions by utilizing superior piecewise linear functions and efficient variable transformations. This method requires much time to reach an approximate global solution of SGP problems (Lin & Tsai, 2012). To handle this difficulty of computational burden, Lin and Tsai (2012) improved the Tsai and Lin (2011) approach by using the range reduction strategies to decrease the CPU time in treating the SGP problems. Two possible outcomes produce when this modified version is used to solve a SGP problem. One is that the Lin and Tsai (2012) method requires much time to reach the globally optimal solutions of some SGP problems (see Examples 2–4 in Lin & Tsai (2012)). The other is that the solution obtained by the Lin and Tsai (2012) method is not a global optimum but a local one of CSTR sequence design problem in Lin and Tsai (2012) (see also Section 3.2, Example 5).In this paper, we present an iterative method to efficiently find the globally optimal solution of an SGP problem. The approach proposed relies on posing the nonconvex SGP problem as a standard GP problem by using simple transformation and condense techniques. The resulting optimization problem can be solved very efficiently by a sequence of standard GPs. We demonstrate the capabilities of the proposed algorithm through seven numerical examples, comparing our results with those produced by other methods. Numerical experiments show that the proposed algorithm requires much less CPU time to obtain the global optimum of a SGP problem with lower errors in objective and constraint functions than the current approaches do.The rest of this paper is organized as follows. Section 2 describes the SGP problems and presents the global optimization method for solving SGP problems. Then seven numerical examples taken from the literature are presented to illustrate the tractability and effectiveness of the proposed approach in computational efficiency and solution quality. Finally, brief conclusions are given in Section 4.Let us consider a signomial geometric programming (SGP) in the following form:(1)minf0(x)=∑j=1m0c0j∏i=1nxia0ijsubject to satisfying:(2)fk(x)=∑j=1mkckj∏i=1nxiakij⩽1,k=1,2,…,p(3)fk(x)=∑j=1mkckj∏i=1nxiakij=1,k=p+1,p+2,…,q(4)xi>0,i=1,2,…,nwhere x=(x1,x2,…,xn)T∈Rn, ckj∈R, akij∈R, mk(k=0,1,…,q) represents the number of product terms of the objective function and of the constraints, and∏1nxiakijand fk(k=0, 1,…,q) are monomial and signomial functions respectively.The SGP problem as shown in Eqs. (1)–(4) is a highly nonlinear, nonconvex optimization problem and difficult to solve for global optimality.This paper proposes a global optimization approach for solving SGP problems. Some transformation and convexification strategies are applied to convert the original SGP problem into a sequence of standard geometric programming (GP) problems that can be solved to reach a global solution.We first denote all functions fk(k=0,1,…,q) in Eqs. (1)–(3) as(5)fk=fk+(x)-fk-(x),k=0,1,…,qwherefk+(x)andfk-(x)have the following posynomial formulations:fk+(x)=∑j∈Jk+ckj∏i=1nxiakij,k=0,1,…,qfk-(x)=∑j∈Jk-(-ckj)∏i=1nxiakij,k=0,1,…,qwhereJk+={j|j∈Jk,ckj>0}andJk-={j|j∈Jk,ckj<0}with Jk={1,2,…,mk}.Then optimization problem (1)–(4) can be written as the following equivalent formulation:(6)minf0+(x)-f0-(x)+Msubject to satisfying:(7)fk+(x)-fk-(x)⩽1,k=1,2,…,p(8)fk+(x)-fk-(x)=1,k=p+1,p+2,…,q(9)xi>0,i=1,2,…,nwhere M>0 is a sufficiently large constant. The reason for usingf0+(x)-f0-(x)+Minstead off0+(x)-f0-(x)to be the objective function is that a sufficiently large M value will forcef0+(x)-f0-(x)+M>0.Next we introduce an additional variable x0 to create a linear objective function and rearrange the constraints into quotient form to obtain the following equivalent optimization problem:(10)minx0subject to satisfying:(11)f0+(x)+Mf0-(x)+x0⩽1(12)fk+(x)fk-(x)+1⩽1,k=1,2,…,p(13)fk+(x)fk-(x)+1=1,k=p+1,p+2,…,q(14)xi>0,i=0,1,…,nIn this representation, constraints (11)–(13) involve a special structure in the form of a ratio between two posynomials. This kind of optimization problems as shown in Eqs. (10)–(14) belong to a truly nonconvex class of problems known as complementary geometric programming (CGP) (Chiang, 2005; Chiang et al., 2007) that is an intrinsically intractable NP-hard problem.Now we introduce auxiliary variables tkand rewrite optimization problem (10)–(14) as(15)minx0+∑k∈K22∪K23∪K24wktksubject to satisfying:(16)f0+(x)+Mf0-(x)+x0⩽1(17)fk+(x)fk-(x)+1⩽1,k∈K11(18)fk+(x)fk-(x)+1⩽1,k∈K12(19)fk+(x)fk-(x)+1=1,k∈K21(20)fk+(x)fk-(x)+1⩽1,k∈K22(21)fk+(x)fk-(x)+1⩾1-tk,k∈K22(22)fk-(x)+1fk+(x)⩽1,k∈K23(23)fk-(x)+1fk+(x)⩾1-tk,k∈K23(24)fk+(x)fk-(x)+1⩽1,k∈K24(25)fk+(x)fk-(x)+1⩾1-tk,k∈K24(26)xi>0,i=0,1,…,n(27)0⩽tk⩽1,k∈K22∪K23∪K24by relaxing equality constraints (13) with constraints (19)–(25). Here wk>0 are the weighting coefficients with sufficiently large values, and index sets K11, K12, K21, K22, K23 and K24 are defined respectively as:K11={k|k∈K1,fk-(x)+1are monomials}K12={k|k∈K1,k∉K11}K21=k|k∈K2,fk+(x)andfk-(x)+1are monomialsK22=k|k∈K2,fk+(x)are posynomials andfk-(x)+1are monomialsK23=k|k∈K2,fk-(x)+1are posynomials andfk+(x)are monomialsK24={k|k∈K2,k∉K21∪K22∪K23}with K1={1,2,…,p} and K2={p+1,p+2,…,q}. It can be seen that when tk=0, problem (15)–(27) is equivalent to the original SGP problem (1)–(4). The purpose of the second term in the objective function (15) is to guarantee that the optimum solution will have tk=0.As in any GP, there is an implicit constraint that the optimization variables are positive (Boyd et al., 2007). But the variables tkin problem (15)–(27) do not meet this requirement. To deal with this issue, we propose the following transformation strategy to transform the variables tkinto other positive ones:(28)sk=11-tk,k∈K22∪K23∪K24where sk⩾1. Then we have the following equivalent representation of problem (15)–(27):(29)minx0+∑k∈K22∪K23∪K24wksksubject to satisfying:(30)f0+(x)+Mf0-(x)+x0⩽1(31)fk+(x)fk-(x)+1⩽1,k∈K11(32)fk+(x)fk-(x)+1⩽1,k∈K12(33)fk+(x)fk-(x)+1=1,k∈K21(34)fk+(x)fk-(x)+1⩽1,k∈K22(35)sk-1fk-(x)+1fk+(x)⩽1,k∈K22(36)fk-(x)+1fk+(x)⩽1,k∈K23(37)sk-1fk+(x)fk-(x)+1⩽1,k∈K23(38)fk+(x)fk-(x)+1⩽1,k∈K24(39)sk-1(fk-(x)+1)fk+(x)⩽1,k∈K24(40)xi>0,i=0,1,…,n(41)sk⩾1,k∈K22∪K23∪K24In this problem the objective (29) is a posynomial function, constraint (33) is a monomial equality, constraints (31), (34) and (36) are posynomial inequalities, and constraints (40) and (41) are monomial inequalities. They are all allowable expressions required in standard GP. However, all other constraints in problem (29)–(41) are not allowable in standard GP. To deal with this difficulty, we propose to approximate every denominator of constrains (30), (32), (35), (37), (38) and (39) with monomial functions, but leave their numerators as posynomial functions. The required monomial approximation can be computed using the following arithmetic–geometric mean approximation.Consider a posynomial functiong(x)=∑vuv(x)with uv(x) being the monomial terms. Then we have the following expression by the arithmetic–geometric mean inequality:(42)g(x)⩾gˆ(x)=∏vuv(x)αv(y)αv(y)where the parameters αv(y) can be obtained by computing(43)αv(y)=uv(y)g(y),∀vwhere y is a fixed point with y>0. It can be easily verified thatgˆ(y)is the best local monomial approximation of g(x) near y (Boyd et al., 2007). Then an inequality constraint on a ratio of two posynomials h(x)/g(x)⩽1 can be approximated withh(x)/gˆ(x)⩽1andh(x)/g(x)⩽h(x)/gˆ(x)⩽1holds. Applying the presented monomial approximation method to each denominator of constrains (30), (32), (35), (37), (38) and (39), we get the following optimization problem:(44)minx0+∑k∈K22∪K23∪K24wksksubject to satisfying:(45)f0+(x)+Mfˆ0-(x,x0)⩽1(46)fk+(x)fk-(x)+1⩽1,k∈K11(47)fk+(x)fˆ12k-(x)⩽1,k∈K12(48)fk+(x)fk-(x)+1=1,k∈K21(49)fk+(x)fk-(x)+1⩽1,k∈K22(50)sk-1fk-(x)+1fˆ22k+(x)⩽1,k∈K22(51)fk-(x)+1fk+(x)⩽1,k∈K23(52)sk-1fk+(x)fˆ23k-(x)⩽1,k∈K23(53)fk+(x)fˆ24k-(x)⩽1,k∈K24(54)sk-1fk-(x)+1fˆ24k+(x)⩽1,k∈K24(55)xi>0,i=0,1,…,n(56)sk⩾1,k∈K22∪K23∪K24wherefˆ0-(x,x0),fˆ12k-(x),fˆ22k+(x),fˆ23k-(x),fˆ24k-(x)andfˆ24k+(x)are the corresponding monomial functions approximated by using (42). Optimization problem (44)–(56) is a standard GP that can be turned into a nonlinear convex problem and so can be solved efficiently (Boyd et al., 2007; Boyd & Vandenberghe, 2004).We now summarize the proposed approach for global optimization of SGP problems in this work and construct an iterative algorithm. The basic steps of the algorithm are given below.Step 0Choose initial feasible values for the variables x and x0, x(0) andx0(0)respectively. Give initial weightswk(0)and solution accuracy ε>0. Set iteration counter r=0.At the r-th iteration evaluate the monomial terms in the denominator posynomials of constraints (30), (32), (35), (37), (38) and (39) with the given x(r−1) andx0(r-1). Compute their corresponding parametersαvx(r-1),x0(r-1)by using Eq. (43).Perform the condensation on the denominator posynomials of constraints (30), (32), (35), (37), (38) and (39) using Eq. (42) with parametersαvx(r-1),x0(r-1).Solve the standard GP (44)–(56) to attainx(r),x0(r)andsk(r)with weighting coefficientswk(r-1).If ∥x(r)−x(r−1)∥⩽ε, then stop. Else go to Step 5.Update the weighting coefficientswk(r)with(57)wk(r)=Wwk(r-1),k∈K22∪K23∪K24The proposed algorithm requires fewer iterations and less CPU time to obtain the global optimum of a SGP problem with lower errors in objective and constraint functions than the approach used in Xu (2013) does. See Example 6 of Section 3.2.Let us briefly take into account the convergence properties of the proposed iterative algorithm. On the one hand, for problems (29)–(41) and (44)–(56), we can easily prove that the following conditions hold by using Eq. (42):(1)f0+(x)+Mf0-(x)+x0⩽f0+(x)+Mfˆ0-(x,x0)fk+(x)fk-(x)+1⩽fk+(x)fˆ12k-(x),k∈K12sk-1fk-(x)+1fk+(x)⩽sk-1fk-(x)+1fˆ22k+(x),k∈K22sk-1fk+(x)fk-(x)+1⩽sk-1fk+(x)fˆ23k-(x),k∈K23fk+(x)fk-(x)+1⩽fk+(x)fˆ24k-(x),k∈K24sk-1fk-(x)+1fk+(x)⩽sk-1fk-(x)+1fˆ24k+(x),k∈K24f0+(x(r))+Mf0-(x(r))+x0(r)=f0+(x(r))+Mfˆ0-(x(r),x0(r))fk+(x(r))fk-(x(r))+1=fk+(x(r))fˆ12k-(x(r)),k∈K12(sk(r))-1(fk-(x(r))+1)fk+(x(r))=(sk(r))-1(fk-(x(r))+1)fˆ22k+(x(r)),k∈K22(sk(r))-1fk+(x(r))fk-(x(r))+1=(sk(r))-1fk+(x(r))fˆ23k-(x(r)),k∈K23fk+(x(r))fk-(x(r))+1=fk+(x(r))fˆ24k-(x(r)),k∈K24(sk(r))-1fk-(x(r))+1fk+(x(r))=(sk(r))-1fk-(x(r))+1fˆ24k+(x(r)),k∈K24∇f0+(x(r))+Mf0-(x(r))+x0(r)=∇f0+(x(r))+Mfˆ0-x(r),x0(r)∇fk+(x(r))fk-(x(r))+1=∇fk+(x(r))fˆ12k-(x(r)),k∈K12∇sk(r)-1fk-(x(r))+1fk+(x(r))=∇sk(r)-1fk-(x(r))+1fˆ22k+(x(r)),k∈K22∇(sk(r))-1fk+(x(r))fk-(x(r))+1=∇(sk(r))-1fk+(x(r))fˆ23k-(x(r)),k∈K23∇fk+(x(r))fk-(x(r))+1=∇fk+(x(r))fˆ24k-(x(r)),k∈K24∇sk(r)-1fk-(x(r))+1fk+(x(r))=∇sk(r)-1fk-(x(r))+1fˆ24k+(x(r)),k∈K24In the practical implementation of the algorithm, one can choose any feasible points as the values of initial variables x(0) andx0(0). In fact, we can find that the proposed algorithm with an infeasible initial point can quickly produces a feasible point of SGP problem. This suggests that we can select an infeasible initial point in the implementation of the proposed algorithm if it is difficult to find a feasible point of some large-scale SGP problem as shown in Example 7. See Examples 4 and 7 of Section 3.We borrow from the theory and practice of penalty function methods to select a weighting coefficientwk(r). We can choose a small initial weightwk(0), such aswk(0)=1or other small positive numbers. The reason for using Eq. (57) to update the weighting coefficientswk(r)is that as the proposed algorithm moves toward the final convergence point, the increasing penalty will force the auxiliary variables sktoward the value 1. In the practical implementation of the algorithm, one can choose a monotonically increasing function to update the weighting coefficientswk(r), such aswk(r)=1+r,wk(r)=βwk(r-1)(β>1), andwk(r)=wk(r-1).When all auxiliary variables skreach their lower bounds, the feasible region of relaxed problem (29)–(41) is the one of original SGP problem.Letx∗,x0∗,sk∗be the final optimum solution obtained by the proposed algorithm. To evaluate the errors in objective and constraint functions produced by monomial approximation (42), we first compute(58)εf=f0+(x∗)-f0-(x∗)+M-x0∗(59)ε1=f0+(x∗)+M-f0-(x∗)-x0∗-f0+(x∗)+M-fˆ0-x∗,x0∗=f0-(x∗)+x0∗-fˆ0-x∗,x0∗(60)ε2k=fk+(x∗)-fk-(x∗)+1-fk+(x∗)-fˆ12k-(x∗)=fk-(x∗)+1-fˆ12k-(x∗),k∈K12(61)ε3k=fk-(x∗)+1-sk∗fk+(x∗)-fk-(x∗)+1-sk∗fˆ22k+(x∗)=sk∗fk+(x∗)-sk∗fˆ22k+(x∗),k∈K22(62)ε4k=fk+(x∗)-sk∗(fk-(x∗)+1)-fk+(x∗)-sk∗fˆ23k-(x∗)=sk∗fk-(x∗)+1-sk∗fˆ23k-(x∗),k∈K23(63)ε5k=fk+(x∗)-fk-(x∗)+1-fk+(x∗)-fˆ24k-(x∗)=fk-(x∗)+1-fˆ24k-(x∗),k∈K24(64)ε6k=fk-(x∗)+1-sk∗fk+(x∗)-fk-(x∗)+1-sk∗fˆ24k+(x∗)=sk∗fk+(x∗)-sk∗fˆ24k+(x∗),k∈K24(65)εg=max(ε1,ε2k,ε3k,ε4k,ε5k,ε6k)Then we use εfand εgto evaluate the approximation error in objective and the approximation error in constraint functions respectively. The approximation errors εfand εgat the final optimum solutionx∗,x0∗,sk∗are very small. See Tables 1 and 3of Section 3.In this section, seven examples are given to illustrate the proposed algorithm in computational efficiency and solution quality. These problems were optimized using the MATLAB based solver GGPLAB (Mutapcic, Koh, Kim, & Boyd, 2006) on a PC with AMD Athlon (tm) II X4 610e Processor 2.40GHz CPU.In this subsection, we consider three SGP problems without equality constraints.Example 1This example is taken from Rijckaert and Martens (1978) and Floudas et al. (1999).min0.5x1x2-1-x1-5x2-1subject to satisfying:0.01x2x3-1+0.01x1+0.0005x1x3⩽11⩽x1,x2,x3⩽100The objective function0.5x1x2-1-x1-5x2-1was first transformed as0.5x1x2-1-x1-5x2-1+M. Then Example 1 can be reformulated as the following form:minx0subject to satisfying:0.5x1x2-1+Mx1+5x2-1+x0⩽10.01x2x3-1+0.01x1+0.0005x1x3⩽11⩽x1,x2,x3⩽100x0>0At the rth iteration, we have the following approximation of this problem by using Eqs. (42) and (43) in Section 2:minx0subject to satisfying:0.5x1x2-1+Mfˆ0-(x,x0)⩽10.01x2x3-1+0.01x1+0.0005x1x3⩽11⩽x1,x2,x3⩽100x0>0wherefˆ0-(x,x0)is the corresponding monomial approximation of posynomial functionx1+5x2-1+x0. It has the following formulation by using Eq. (42):fˆ0-(x,x0)=x1α11α115x2-1α12α12x0α13α13where α11, α12 and α13 can be computed by using Eq. (43) as follows:α11=x1(r)x1(r)+5(x2(r))-1+x0(r)α12=5(x2(r))-1x1(r)+5(x2(r))-1+x0(r)α13=x0(r)x1(r)+5(x2(r))-1+x0(r)The simulation experiments of Example 1 using the proposed approach were performed. The following algorithm parameters were assumed in the method:x1(0)=1,x2(0)=1,x3(0)=1,x0(0)=94.5,M=100,ε=10-6. After 13 iterations we can obtain an optimal solution (x1,x2,x3)=(88.355909,7.672653,1.317862) and an objective value −83.249728 with about 1.17s CPU time. The attained results are within the optimality tolerance 10−8 and the feasibility tolerance 10−13. Table 1 presents the comparison between the proposed approach and the reported methods (Lin & Tsai, 2012; Tsai & Lin, 2011) for Examples 1–3. In this table it can be seen that our proposed approach requires much less CPU time to find the global optimum of Example 1 with a lower error than the Tsai and Lin (2011) and Lin and Tsai (2012) methods do.Example 2This example is taken from Dembo (1976) and Floudas et al. (1999) and it deals with the optimal design of a reactor.min0.4x10.67x7-0.67+0.4x20.67x8-0.67+10-x1-x2subject to satisfying:0.0588x5x7+0.1x1⩽10.0588x6x8+0.1x1+0.1x2⩽14x3x5-1+2x3-0.71x5-1+0.0588x3-1.3x7⩽14x4x6-1+2x4-0.71x6-1+0.0588x4-1.3x8⩽10.1⩽xi⩽10,i=1,2,…,8The following algorithm parameters were set in the implementation of the proposed method:x1(0)=1,x2(0)=1,x3(0)=1,x4(0)=1,x5(0)=10,x6(0)=10,x7(0)=1,x8(0)=1,x0(0)=8.8,ε=10-6. The proposed algorithm uses about 12s CPU time to perform 96 iterations and find an optimal solution (x1,x2,x3,x4,x5,x6,x7,x8)=(6.465110,2.232712,0.667398,0.595756,5.932676,5.527235,1.013323,0.400668) and an objective value 3.951163 with the optimality tolerance 5.094263×10−10 and the feasibility tolerance 1.056932×10−13. Table 1 provides us with a comparison of these results and those obtained by other reported methods (Lin & Tsai, 2012; Tsai & Lin, 2011). As can be seen in this table, the proposed approach in this paper spends much less CPU time to attain the global optimum of Example 2 with lower errors in objective and constraint functions than the Tsai and Lin (2011) and Lin and Tsai (2012) methods do.Example 3This example is drawn from Floudas et al. (1999). The problem was first proposed to deal with the optimal design of a heat exchanger network by Avriel and Williams (1971).minx1+x2+x3subject to satisfying:833.33252x1-1x4x6-1+100.0x6-1-83333.333x1-1x6-1⩽11250.0x2-1x5x7-1+1.0x4x7-1-1250.0x2-1x4x7-1⩽11250000.0x3-1x8-1+1.0x5x8-1-2500.0x3-1x5x8-1⩽10.0025x4+0.0025x6⩽1-0.0025x4+0.0025x5+0.0025x7⩽10.01x8-0.01x5⩽1100⩽x1⩽10,0001000⩽xi⩽10,000,i=2,310⩽xi⩽1000,i=4,5,…,8The following algorithm parameters were selected in the simulation experiments of Example 3 by using the proposed method:x1(0)=1000,x2(0)=1000,x3(0)=7500,x4(0)=200,x5(0)=200,x6(0)=200,x7(0)=400,x8(0)=300,ε=10-6. The proposed algorithm spends about 5s CPU time to perform 40 iterations and reach an optimal solution (x1,x2,x3,x4,x5,x6,x7,x8)=(579.306682,1359.970674,5109.970674,182.017699,295.601173,217.982301,286.416526,395.601173) and an objective value 7049.248030 with the optimality tolerance 0 and the feasibility tolerance 2.328306×10−9. Table 1 shows the comparison between the proposed approach and the reported methods (Tsai & Lin, 2011;Lin & Tsai, 2012) for Example 3. As can be seen in Table 1, the Tsai and Lin (2011) method uses over 8h CPU time to attain an inferior solution with a higher error in constraint functions. But our proposed approach requires much less CPU time to find the global optimum of Example 3 with a lower error than the Lin and Tsai (2012) method does.Next we provide a comparison of global solutions reported by Floudas et al. (1999) and the proposed approach for Examples 1–3. This is shown in Table 2. It can be seen that the proposed algorithm obtains the real global optimum of each example with low errors in objective and constraint functions than the Floudas et al. (1999) does.In this subsection, we consider four SGP problems with equality constraints.Example 4The following example is taken from Rountree and Rigler (1982).minx12+x22+5-4x1-2x2subject to satisfying:0.25x12+x22⩽12x2-x1=1xi>0,i=1,2The real global solution of this problem is (x1,x2)=((70.5−1)/2,(70.5+1)/4)≈(0.822876,0.911438). According to Eqs. (29)–(41) in Section 2, Example 4 can be transformed into the following form:minx0+w2s2subject to satisfying:x12+x22+54x1+2x2+x0⩽10.25x12+x22⩽1x1+12x2⩽12x2s2-1x1+1⩽1xi>0,i=0,1,2s2⩾1At the rth iteration, we have the following approximation of this problem by using Eqs. (42) and (43) in Section 2:minx0+w2s2subject to satisfying:x12+x22+5fˆ0-(x,x0)⩽10.25x12+x22⩽1x1+12x2⩽12x2s2-1fˆ222+(x)⩽1xi>0,i=0,1,2s2⩾1wherefˆ0-(x,x0)andfˆ222+(x)are the corresponding monomial approximations of posynomial functions 4x1+2x2+x0 and x1+1 respectively. They have the following formulations by using Eq. (42):fˆ0-(x,x0)=4x1α11α112x2α12α12x0α13α13fˆ222+(x)=x1α21α211α22α22where α11, α12, α13, α21 and α22 can be computed by using Eq. (43) as follows:α11=4x1(r)4x1(r)+2x2(r)+x0(r)α12=2x2(r)4x1(r)+2x2(r)+x0(r)α13=x0(r)4x1(r)+2x2(r)+x0(r)α21=x1(r)x1(r)+1α22=1x1(r)+1The following algorithm parameters were chosen in the proposed method:x1(0)=0.6,x2(0)=0.8,x0(0)=2,w2(0)=1,w2(r)=1+r(r⩾1),ε=10-6. After 5 iterations we can obtain an optimal solution (x1,x2,x0,s2)=(0.822876,0.911438,1.393465,1) and an objective value 1.393465 with about 0.7s CPU time. The attained results are within the optimality tolerance 3.154166×10−9 and the feasibility tolerance 2.220446×10−16. Table 3shows the results obtained by the proposed approach for Examples 4–7. Table 4presents the comparison between the proposed approach and the reported methods (Rountree & Rigler, 1982; Burns, 1987) for Example 4. In this table it can be observed that our proposed algorithm can find a better global solution of Example 4 than the Rountree and Rigler (1982) and Burns (1987) methods do in the same solution accuracy ε=0.001.To investigate the influence of initial weightw2(0)on the performance of our proposed algorithm, ten numerical experiments with different initial weights were performed with the following algorithm parameters:x1(0)=0.6,x2(0)=0.8,x0(0)=2,w2(r)=1+r(r⩾1),ε=10-6. Table 5compares the influence of different initial weights on the performance of our proposed algorithm. In this table it can be seen that as the value of initial weightw2(0)increases from 0.001 to 1000 the proposed algorithm obtains the real global optimum of Example 4 with low errors in objective and constraint functions. We can also observe that the proposed approach requires 5 iterations to reach the global optimum of Example 4 when initial weightw2(0)belongs to the interval [0.001,10], but it needs 6 iterations to achieve this optimization task when initial weightw2(0)belongs to the interval [10,1000]. These results not only show that our proposed approach is highly robust to various initial weights, but also suggest that we should choose a smallerwk(0)value to promote the evolution rate of the proposed algorithm.Next we illustrate the influence of weighting coefficientw2(r)(r⩾1)on the performance of our proposed algorithm. Twelve computational experiments with different weighting coefficientsw2(r)(r⩾1)were performed with the following algorithm parameters:x1(0)=0.6,x2(0)=0.8,x0(0)=2,w2(0)=1,ε=10-6. Table 6compares the influence of different weighting coefficientsw2(r)(r⩾1)on the performance of the proposed approach. It can be observed that the proposed algorithm with 12 different weighting coefficients runs 5 iterations to attain the real global optimum of Example 4 with low errors in objective and constraint functions, but it yields a slightly large error in objective function when we select a large weighting coefficient such as 100, 100+r, 8r, 2r2 and r3. This suggests that we should not choose a too largewk(r)(r⩾1)value in the implementation of the proposed algorithm.Now we illustrate the influence of initial points x(0) andx0(0)on the performance of the proposed approach. Ten numerical experiments of Example 4 with different initial points were performed. The following algorithm parameters were set in our presented algorithm:w2(r)=1+r(r⩾0), ε=10−6. Table 7gives 10 groups of initial points used in the computational experiments of Example 4. In this table points A–D are feasible, while points E–J are infeasible. Table 8compares the influence of various initial points on the performance of the proposed approach. As can be seen in this table, ten runs of the proposed algorithm with feasible and infeasible initial points can all rapidly obtains the global solution of Example 4 with low errors in objective and constraint functions. We can also find that the proposed algorithm with an infeasible initial point only runs one iteration to reach a feasible point of Example 4 (see Table 9). These conclusions suggest that we can choose an infeasible initial point in the implementation of the proposed algorithm if it is difficult to find a feasible point of some large-scale SGP problem as shown in Example 7.Example 5This example is taken from Floudas et al. (1999). The problem was originally presented in Manousiouthakis and Sourlas (1992) to address the optimal design of a sequence of two CSTR reactors.min-x4subject to satisfying:x1+k1x1x5=1x2-x1+k2x2x6=0x3+x1+k3x3x5=1x4-x3+x2-x1+k4x4x6=0x50.5+x60.5⩽4k1=0.09755988k2=0.99k1k3=0.0391908k4=0.9k3(0,0,0,0,10-5,10-5)⩽(x1,x2,x3,x4,x5,x6)⩽(1,1,1,1,16,16)This problem has a global and two local minima and is shown to have caused difficulties for many global optimization methods (Floudas et al., 1999).It can be easily verified that xi>0 (i=1,2,3,4) hold in Example 5. Then according to Eqs. (29)–(41) in Section 2, Example 5 can be rewritten as the following form:minx0+∑k=25wksksubject to satisfying:Mx4+x0⩽1x1+k1x1x5⩽1s2-1x1+k1x1x5⩽1x2+k2x2x6x1⩽1s3-1x1x2+k2x2x6⩽1x3+x1+k3x3x5⩽1s4-1x3+x1+k3x3x5⩽1x4+x2+k4x4x6x1+x3⩽1s5-1(x1+x3)x4+x2+k4x4x6⩽1x50.5+x60.5⩽4k1=0.09755988k2=0.99k1k3=0.0391908k4=0.9k3(10-8,10-8,10-8,10-8,10-5,10-5)⩽(x1,x2,x3,x4,x5,x6)⩽(1,1,1,1,16,16)x0>0sk⩾1,k=2,3,4,5The following algorithm parameters were assumed in the computational experiments of Example 5 by using the proposed method:x1(0)=0.836736,x2(0)=0.701272,x3(0)=0.151397,x4(0)=0.267958,x5(0)=2,x6(0)=2,x0(0)=1.2-x4(0),M=1.2,wk(r)=1(k=2,3,4,5),ε=10-6. The proposed algorithm requires about 85s CPU time to run 507 iterations and reach an optimal solution (x1,x2,x3,x4,x5,x6,x0,s2,s3,s4,s5)=(0.771518,0.516992,0.204191,0.3888114,3.035535,5.097305,0.811189,1,1,1,1) and an objective value −0.3888114 with the optimality tolerance 5.484115×10−10 and the feasibility tolerance 3.996803×10−15. The results obtained by the proposed approach for Example 5 are given in Table 3. Fig. 1presents the trajectory generated by the proposed algorithm. As can be seen in this figure, the proposed approach in this paper shows a rapid convergence behavior. Table 10presents a comparison of these results and those attained by other reported methods (Floudas et al., 1999; Lin & Tsai, 2012). It can be observed that the solution found by the proposed approach in this paper has lower errors in objective and constraint functions than the one in Floudas et al. (1999). We can also conclude that the solution obtained by the Lin and Tsai (2012) method is not a global optimum but a local one (Floudas et al., 1999) of Example 5.Example 6This example is taken from Marín-Sanguino et al. (2007). The problem was modified from Floudas (2000) and has been studied by Xu (2013).minx1subject to satisfying:14x1+12x2-116x12-116x22-1=0114x12+114x22+1-37x1-37x2=01⩽x1⩽5.51⩽x2⩽5.5This problem has a fragmented feasible region that contains only two points: (1.177124,2.177124) and (3.822876,4.822876). Clearly the first point is the global solution of Example 6.Example 6 can be represented as the following form by Eqs. (29)–(41) in Section 2:minx1+∑k=12wksksubject to satisfying:14x1+12x2116x12+116x22+1⩽1s1-1116x12+116x22+114x1+12x2⩽1114x12+114x22+137x1+37x2⩽1s2-137x1+37x2114x12+114x22+1⩽11⩽xi⩽5.5,i=1,2sk⩾1,k=1,2The following algorithm parameters were chosen in the simulation experiments of Example 6 by using the proposed method:x1(0)=3.822876,x2(0)=4.822876,w1(0)=w2(0)=1,wk(r)=1+r(r⩾1),ε=10-6. The proposed algorithm spends about 1.44s CPU time to perform 11 iterations and reach an optimal solution (x1,x2,s1,s2)=(1.177124,2.177124,1,1) and an objective value 1.177124 with the optimality tolerance 0 and the feasibility tolerance 4.440892×10−16. The results obtained by the proposed approach for Example 6 are presented in Table 3. Fig. 2illustrates the corresponding variation of optimization index during the proposed approach starting from the given initial point. Table 11shows the comparison between the proposed approach and the reported method in Xu (2013) for Example 6. From Table 11, we see that both the proposed in this paper and Xu (2013) approaches can find the global optimum of Example 6. However, our proposed approach in this work requires much less CPU time and more fewer iterations to reach the global solution of Example 6 with a lower error in constraint functions than the Xu (2013) method does.Example 7This example is drawn from Rountree and Rigler (1982). The problem was first presented in Avriel and Barrett (1978) to address the optimal design of a pitched laminated wood beam.min720Hc+43,200ϕ+14,400ϕ3+5760ϕ5+R2ϕ3+0.4R2ϕ5-7198.2subject to satisfying:252.154H-2+4500R-2⩽10.0125H+0.00833Rϕ+0.0000694Rϕ5-0.001389Rϕ3⩽12238.432Hc-3+53720.208Hc-4ϕ+17906.736Hc-4ϕ3+7162.694Hc-4ϕ5+19.995Hc-1-8951.297Hc-4-120Hc-1ϕ-40Hc-1ϕ3-16Hc-1ϕ5⩽130.52132Hc-1-120Hc-1ϕ-40Hc-1ϕ3-16Hc-1ϕ5⩽1252.1543Ht-2+0.005837Ht-2R2ϕ4+4500R-2-0.0175Ht-2R2ϕ2-0.000778Ht-2R2ϕ6⩽167.73085H-1.8RM0.2ϕ0.2+146.53487H-0.8RM-0.8ϕ0.2+393.09732H0.2RM-1.8ϕ0.2⩽1HHt-1+0.5Ht-1Rϕ2+0.02777Ht-1Rϕ3-0.0416667Ht-1Rϕ4-0.16663Ht-1Rϕ-0.001389Ht-1Rϕ5=12HR-1ϕ-2-2HcR-1ϕ-2-0.41667ϕ2-0.16944ϕ4=1R-1RM-0.5HR-1=1The following algorithm parameters were set in the proposed method:wk(0)=5(k=7,8,9),wk(r)=5(1+r)(r⩾1),ε=10-6. Table 12gives the initial data set corresponding to Example 7 from Avriel and Barrett (1978), Rountree and Rigler (1982). It can be easily verified that the initial point given in Table 12 is infeasible. After 16 iterations we can obtain an optimal solution (x0,H,Hc,Ht,R,RM,ϕ)=(9422.778916,17.749004,15,15.176066,330,338.874512,0.12863) and an objective value 9422.778915 with about 5.46s CPU time. The attained results are within the optimality tolerance 1.447443×10−7 and the feasibility tolerance 1.776357×10−15. Table 3 presents the results obtained by the proposed approach for Example 7. Fig. 3illustrates the corresponding variation of objective value during the proposed approach starting from the input data given in Table 12. As can be seen in this figure, the proposed approach in this paper shows a rapid convergence behavior. Table 13shows the comparison between the proposed approach and the reported methods (Avriel & Barrett, 1978; Rountree & Rigler, 1982) for Example 7. As can be seen for the objective value, the proposed approach in this paper can find a better global solution of Example 7 than the other two approaches applied in Avriel and Barrett (1978) and Rountree and Rigler (1982), with an improvement in about 8%. These conclusions clearly show the tractability and effectiveness of the presented algorithm in handling global optimization of Example 7.

@&#CONCLUSIONS@&#
In this work, we have presented a method for global optimization of signomial geometric programming problems. The considered nonconvex optimization problem is easily transformed into a series of standard geometric programming problems that can be solved to reach a global solution through simple equivalence transformation and convexification strategies. The proposed approach has been applied to several examples in the literature. Compared with other current methods, our iterative approach rapidly and successfully obtain the globally optimal solution of a signomial geometric programming. These conclusions show the tractability and effectiveness of the proposed convex approximation method in handling global optimization of signomial geometric programming.