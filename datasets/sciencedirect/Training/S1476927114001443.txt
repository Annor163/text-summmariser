@&#MAIN-TITLE@&#
Predicting protein–RNA interaction amino acids using random forest based on submodularity subset selection

@&#HIGHLIGHTS@&#
We proposed a computational method for protein–RNA binding sites prediction by combining local features and global features from protein sequence based on submodularity subset selection.It achieved better performance than other state-of-the-art methods.It indicated that extracted global features have very strong discriminate ability for identifying interaction sites.

@&#KEYPHRASES@&#
Protein–RNA interaction site,Sample imbalance,Evolution information,Submodularity subset selection,Random forest,

@&#ABSTRACT@&#
Protein–RNA interaction plays a very crucial role in many biological processes, such as protein synthesis, transcription and post-transcription of gene expression and pathogenesis of disease. Especially RNAs always function through binding to proteins. Identification of binding interface region is especially useful for cellular pathways analysis and drug design. In this study, we proposed a novel approach for binding sites identification in proteins, which not only integrates local features and global features from protein sequence directly, but also constructed a balanced training dataset using sub-sampling based on submodularity subset selection. Firstly we extracted local features and global features from protein sequence, such as evolution information and molecule weight. Secondly, the number of non-interaction sites is much more than interaction sites, which leads to a sample imbalance problem, and hence biased machine learning model with preference to non-interaction sites. To better resolve this problem, instead of previous randomly sub-sampling over-represented non-interaction sites, a novel sampling approach based on submodularity subset selection was employed, which can select more representative data subset. Finally random forest were trained on optimally selected training subsets to predict interaction sites. Our result showed that our proposed method is very promising for predicting protein–RNA interaction residues, it achieved an accuracy of 0.863, which is better than other state-of-the-art methods. Furthermore, it also indicated the extracted global features have very strong discriminate ability for identifying interaction residues from random forest feature importance analysis.

@&#INTRODUCTION@&#
Protein–RNA interaction plays a key role in many biological cellular processes, such as regulation and post-transcription of gene expression (Bartel, 2009; Tuschl, 2003). And most RNAs function through interacting with proteins (Lunde et al., 2007), which bind together to form RNA-binding proteins (RBPs) complex. For example, Argonaute (AGO) family of RBPs, crucial components of the RNA-induced silencing complex (RISC), which incorporates microRNAs (miRNAs) to bind to their target genes, thereby negatively regulate gene expression. So identifying the key interaction residues involved in RNA binding can broaden our understanding of mechanism of those processes, and therefore guide for the mutant design and drug design.With the recent rapid advances in high-throughput technologies for identifying protein–RNA interaction sites, such as cross-linking and immunoprecipitation protocols (CLIP) (Ule et al., 2005; Kishore et al., 2011) and electrophoretic mobility shift assay (EMSA) (Hellman and Fried, 2007), RNA–protein binding residues data are increasingly collected from experiments, such as PRIDB (Lewis et al., 2011). However, high-throughput experiments to identify RNA–protein interaction sites are very time-consuming and lab investment, especially in the post-genomic era. And there are a lot of studies (Hormoz, 2013; Ray et al., 2009; Kim et al., 2006) indicating that the compositions in RBPs are closely related to interaction residues. Hence, to complement experimental methods, a reliable computational method from sequences is considered as one of the most important and efficient methods to predict protein–RNA interacting interface based on accumulated experimentally verified protein–RNA binding sites.Currently there are a lot of excellent work developed to predict RNA–protein interaction residues, in general it can be categorized into two subgroups based on its source of data: one is protein sequence and structure based approaches, the other is CLIP-seq based approaches. For the first group, one is features extracted from sequences directly, which is inputted to machine learning algorithms, such as physiochemical properties, amino acid compositions, position specific scoring matrix (PSSM) and sequence based predicted features(predicted protein structure or relative solvent accessibilities). RNABindR (Terribilini et al., 2007) predicted amino acid sites from simple sequence composition features using Naive Bayes classifier and Wang et al. (2013) applied an extended Naive Bayes classifier after feature selection. BindN+ (Wang et al., 2010) designed SVM based method to discriminate interaction sites using PSSM information. Based on BindN, RNAProB Cheng et al. (2008) incorporated context information from nearby residues and smoothed PSSM to improve prediction performance. Liu et al. (2010) presented Random Forest to classify binding sites combining different features with interaction propensities (defined as mutual interaction propensity between nucleotide and residue triplet) from sequences, which achieved very promising performance. The other one is information extracted from protein structure. For example, Chen and Lim (2008) firstly inferred surface geometry from structure information, then classified as interface sites if they have higher relative solvent accessibilities. OPRA (Pérez-Cano and Fernández-Recio, 2010) predicted interface residues with higher local patch energy scores and residue's atom distance from any RNA atom smaller than 10Å. For the second subgroup, information is extracted from high-throughput CLIP-seq data to identify binding sites. PARalyzer (Skalsky et al., 2011) proposed kernel density estimate classifier to map the high resolution binding sites from PAR-CLIP. CapR (Fukunaga et al., 2014) calculated the probability of binding position within each secondary structural context from CLIP-seq. Recently MiClip (Wang et al., 2014) was proposed to identify highly reliable protein–RNA binding sites from CLIP-seq using two-stage HMM algorithm, which outperformed state-of-the-art method by 17–300%.In this study, we focused on prediction from sequences and proposed a novel method based on submodularity sample subset selection to predict the interaction sites, which integrates global and local features, due to the following reasons: (1) different proteins have different percent of interaction sites and interaction patterns, as shown in Fig. 1, which is taken into consideration during model training via introducing global features, such as molecular weight, protein length; (2) number of non-interaction sites dominate the training and testing data, which leads to a sample imbalance problem, and hence bias model with preference to overwhelmed non-interaction sites. Meanwhile, as indicated in (Wei and Dunbrack, 2013), classifiers achieves the best performance on balanced training sets. To this end, here we proposed a novel sampling strategy based on submodularity subset selection to select more informative and representative data subset, which is like batch active learning (Guo et al., 2013), instead of randomly undersampling the majority class or oversampling minority class. To the best of our knowledge, our method is the first work that incorporates submodularity optimization for selecting good training subset from unbalanced data, which can be extended to other studies with imbalanced data problem. Our experiment achieved better performance with accuracy of 0.863, precision of 0.847, sensitivity of 0.885, specificity of 0.840 and Matthews correlation coefficient of 0.726, which outperformed other state-of-the-art methods by 2% respectively.The benchmark dataset was taken from Liu et al. (2010), whose protein–RNA complexes were downloaded from RsiteDB (Shulman-Peleg et al., 2008). which contains 205 non-redundant protein–RNA chains in 164 complexes with structure resolution smaller than 3Å, none of protein and RNA chains in the whole datasets has above 25% and 60% sequence identity respectively. We extracted the interaction sites between protein and RNA chains defined by ENTANGLE (Allers and Shamoo, 2001). In total 53,315 residues from protein chains, 5261 (9.87%) were interaction residues, and the rest 48,054 (90.13%) were non-binding protein residues, the number of non-interaction residues is about 9 times more than interaction residues.Different proteins have different percent of interaction sites, as shown in Fig. 1, the minimum is only 0.003, while the maximum is 0.848, they vary very differently. So global features were extracted to take it into consideration in this study. Firstly we used secondary structure prediction tool PSIPRED (Jones, 1999) to obtain structure information from protein sequence, it can be represented by a matrix of 3*L given protein with L amino acids, then we got the global secondary structure through calculating the summation of every column and normalize them, so we can get a 3-dimension feature. It was also found that protein molecular weight is closely correlated with protein–RNA interaction (Rhode et al., 2003), which is calculated from protein sequence using Compute pI/Mw tool (Gasteiger et al., 2005). Other extracted global features are surface accessibility, which is calculated using DSSP Kabsch and Sander (1983), protein length, and amino acid composition of Lysine, Arginine, Aspartic and Glutamic.Considering the effect of nearby amino acids, a sequence segment of windows size M with centring on residue i was used to extract local features. For making a trade-off between accuracy and computational efficiency, here window size M=5 was applied in this study like Liu et al. (2010). First of all, the local secondary structure information within windows was extracted, which got a 3*5=15 features. Secondly, the PSSM, which shows the evolutionary information of proteins, was used. The L×20 PSSM scores were generated by using PSI-BLAST (Altschul et al., 1997) to search sequence against the Swissprot database (Bairoch and Apweiler, 2000) through three iterations with 0.001 as the E-value cut-off for multiple sequence alignment, whose diagonal value is extracted as conservation feature. Finally previous study (Liu et al., 2010) also has shown physiochemical property, hydrophobicity, relative accessible surface area, side-chain environment pKa and statistical interaction propensity have high correlations with binding residues, they also were extracted in our study.In total, we got 85 feature components, i.e. 10 global features and 15*5=75 local features based on window size 5.Sample imbalance is very ubiquitous in many practical classification problems, i.e., at least one of the classes overwhelms other classes. In this study, the number of non-interaction residues is about 9 times more than interaction residues on whole dataset. The sample imbalance also exists in other binding sites problem, such as protein–ATP binding sites (Zhang et al., 2012). The unbalanced training data has very huge impact on final model performance, it is the reason that classification algorithms, such as support vector machine (Vapnik, 1995) and random forest (Breiman, 2001), usually focus on minimizing the overall error rate, which cannot obtain good model generalization for imbalanced data. To achieve better model, currently most methods used random subsampling of over-represented class to create more balanced training data, while it cannot select a more representative data for model training.It is well known that how to select a representative subset is very important in constructing machine learning model from redundant data, here we presented a novel method based on submodularity framework to address this problem. Submodularity (Krause et al., 2008) has an intuitive diminishing returns feature, adding an element to an input set rewards more than adding it to another set. Submodularity has been used in data subset selection problem in speech recognition and natural language processing (Lin and Bilmes, 2009; Moore and Lewis, 2010), which encourages small vocabulary subsets and large acoustic spans.We want to sample a good data subset S that maximizes some objective function with size K from original data V, as shown in Eq. (1):(1)maxS⊆V{f(S):|S|≤K}This optimization is NP-hard, so we approximately achieve near-optimal solution using a simple greedy algorithm starting with S=∅, and iteratively adds the element that maximize the objective function until obtain desirable data subset.Assume we have a graphG=(V,E,w), V is the nodes (amino acid), and E is the edge between nodes, an edge e=(i, j) connects two nodes i and j,wdenotes pairwise similarity between nodes. Our goal is to select most representative subset S from the whole negative set V via optimizing the following objectives:(2)maxk∑i∈V∖Sw(i,k)−∑j∈S∪{k}w(j,k)The above objective can be optimized nearoptimally using greedy algorithm, for more details and proof, please refer to Lin and Bilmes (2009). Here we firstly select the desired data subset from whole dataset based on the above objective, after obtaining the same number of majority class with minority class, the selected balanced dataset is applied in following model training. In this study, we use submodularity subset selection to select the balanced data subset with the same number of non-interaction (majority class) and interaction sites (minority class), it also works for data set that the proteins have large interfaces.Random forest (RF) (Breiman, 2001) is an ensemble of multiple unpruned decision trees grown from separate bootstrap samples of the training data, and a feature subset sampled independently from the original feature space. Compared to other algorithms, such as support vector machine (Vapnik, 1995), it has very few parameters to tune. In our experiment, Scikit-learn (Pedregosa et al., 2011) is used to construct RF model, we only set parameter number of trees as 500, and all other parameters are default values. It can be used for classification and regression with high prediction accuracy, robustness to noise, and high-dimensional big data. Recently it has been widely used in many areas, such as computer vision (Shotton et al., 2011), bioinformatics (Pan et al., 2010; Song et al., 2012).Random forest also can be used to evaluate the importance of input features. During the RF training process, bootstrap process keeps about 1/3 training data as the out-of-bag data points, whose averaged error is calculated over the forest. Then the out-of-bag error is calculated again after the values of the each feature are exchanged among the 2/3 training data points. The importance score for each feature is the mean value of difference of out-of-bag error before and after the permutation over forest.In this study, we train machine learning model to predict whether amino acids in protein are RNA binding residues or not. In order to compare with previous proposed methods, 5-fold cross-validation testing was used to evaluate model performance. We follow their evaluation measure by means of the classification accuracy, precision, sensitivity, specificity and the Matthews correlation coefficient (MCC) as defined respectively by:(3)Accuracy=TP+TNTP+TN+FP+FN(4)Sensitivity=TPTP+FN(5)Specificity=TNTN+FP(6)Precision=TPTP+FP(7)MCC=TP×TN−FP×FN(TP+FP)(TP+FN)(TN+FP)(TN+FN)where TP, TN, FP, and FN represents true positive, true negative, false positive, and false negative, respectively. We also exploit Receiver Operating Characteristic (ROC) curve and calculated the area under the ROC curve (AUC).

@&#CONCLUSIONS@&#
