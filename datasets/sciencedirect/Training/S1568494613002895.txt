@&#MAIN-TITLE@&#
Cost-sensitive decision tree ensembles for effective imbalanced classification

@&#HIGHLIGHTS@&#
A novel cost-sensitive ensemble, based on decision trees, for imbalanced classification.An evolutionary-based simultaneous classifier selection and fusion boost the recognition rate of the minority class.An analysis of the influence of the cost matrix parameters and data imbalance ratio on the performance of the ensemble.A ROC-based tuning method of the ensemble parameters.

@&#KEYPHRASES@&#
Machine learning,Multiple classifier system,Ensemble classifier,Imbalanced classification,Cost-sensitive classification,Decision tree,Classifier selection,Evolutionary algorithms,Classifier fusion,

@&#ABSTRACT@&#
Real-life datasets are often imbalanced, that is, there are significantly more training samples available for some classes than for others, and consequently the conventional aim of reducing overall classification accuracy is not appropriate when dealing with such problems. Various approaches have been introduced in the literature to deal with imbalanced datasets, and are typically based on oversampling, undersampling or cost-sensitive classification. In this paper, we introduce an effective ensemble of cost-sensitive decision trees for imbalanced classification. Base classifiers are constructed according to a given cost matrix, but are trained on random feature subspaces to ensure sufficient diversity of the ensemble members. We employ an evolutionary algorithm for simultaneous classifier selection and assignment of committee member weights for the fusion process. Our proposed algorithm is evaluated on a variety of benchmark datasets, and is confirmed to lead to improved recognition of the minority class, to be capable of outperforming other state-of-the-art algorithms, and hence to represent a useful and effective approach for dealing with imbalanced datasets.

@&#INTRODUCTION@&#
Numerous approaches have been introduced in the literature aiming to provide effective and efficient classification systems [19]. However, it is also well known that according to the no free lunch theory there is no universal classifier that performs best for all decision problems [41].Canonical machine learning methods are based on the idea of selecting the single best classifier from a set of available models. However, making a decision based on solely a single classifier also discards the possibility that other models may also offer a valuable contribution. Methods that are trying to exploit the strengths of several models are known as multiple classifier systems (MCSs) or classifier ensembles [29], and are one of the most promising research directions in the current field of machine learning and pattern recognition.There are typically two main challenges when constructing MCSs: how to select classifiers to form an ensemble, and how to fuse the individual decisions of the base classifiers into a single decision. Poor selection may undermine the whole process of designing MCSs, while a good strategy for building an ensemble should guarantee an improvement in its diversity. This can be achieved by using different partitions of the dataset or by generating a number of datasets through data splitting, a cross-validated committee, bagging, or boosting [29], so that the generated base classifiers, since trained on different inputs, would be complementary. Among the employed approaches, constructing random subspaces [17] is one of the most generic ones, and typically works well with various types of classifiers.Classifier fusion methods can be categorised into approaches that are based on classifier labels and those that utilise discriminant analysis. The former includes various voting algorithms [4,46]. While (majority) voting schemes are among the most popular fusion methods, often better results are obtained by approaches that consider the importance of decisions coming from particular committee members [39,28].For methods based on discriminant analysis, the main form of discriminants is a posterior probability, although outputs of neural networks or other functions whose values are used to establish the decision of the classifier (so called support functions) can also be considered. While simple aggregation methods (like minimum, maximum, product, mean) can be used, they are typically subject to rather restrictive conditions [12] which limit their practical use. Better results can be achieved by designing fusion models based on a training procedure to arrive at so-called trained fusers [44].The underlying class distribution can play a crucial role in the derivation of effective classifiers. In many cases the distribution is roughly equal among all the classes but this does not hold for every application. When one of the classes (referred to as the majority class) significantly outnumbers the remaining (minority) class(es), we deal with a problem known as imbalanced classification [16] which occurs in a variety of domains including anomaly detection [20], fault diagnosis [47], medical data analysis [23], drug design [22], SPAM detection [48] and face recognition [32]. While the performance of classification algorithms is typically evaluated using predictive accuracy, clearly this is not appropriate when the data is imbalanced as it would favour the correct identification of majority class samples.In this paper, we propose, based on our earlier work [25,27], a classifier ensemble design algorithm which is built on the basis of a cost matrix for improved minority class prediction. As base classifiers we utilise cost-sensitive decision trees due to their susceptibility to improvement via the ensemble approach, while we employ an evolutionary algorithm to simultaneously perform classifier selection and fusion.Instead of using a fixed cost matrix we derive its parameters via ROC analysis. To gain a deeper insight into the influence of cost matrices on the minority class recognition, we investigate several imbalanced datasets with different levels of imbalance to identify a useful pattern for setting the cost matrix.The main contributions of this paper are as follows:•A new ensemble pruning method based on the combination of decision trees trained on different sets of features.Use of an evolutionary algorithm for simultaneous classifier selection and fusion to promote the best base classifiers and boost the recognition rate of the minority class.In-depth analysis of the influence of the cost matrix parameters and data imbalance ratio on the performance of the proposed ensemble based on ROC analysis.The remainder of the paper is organised as follows. In Section 2 we present the pattern recognition background that our approach is based on, while Section 3 discusses the problem of imbalanced classification. Our new algorithm is introduced in detail in Section 4. Experimental results are reported and discussed in Section 5, while Section 6 concludes the paper.The aim of pattern recognition is to assign a given sample to one of a number of pre-defined categories. A pattern recognition algorithm Ψ thus maps the feature space X to the set of class labelsM(1)Ψ:X→M.This mapping is typically established on the basis of examples from a training set which contains learning examples, i.e. observations of features together with their correct classifications. Although it is important for the performance of a classifier, we do not focus on feature selection in this paper, but assume that the set of features is given by an expert or chosen by an appropriate feature selection method [11].Let's assume that we have n classifiers Ψ(1), …, Ψ(2), …, Ψ(n). For a given object x, each of them makes a decision regarding class i∈M={1, …, M}. The combined classifierΨ¯then makes a decision according to a weighted voting rule(2)Ψ¯(Ψ(1)(x),Ψ(2)(x),…,Ψ(n)(x))=argmaxj∈M∑l=1nδ(j,Ψ(l)(x))w(l),where(3)δ(j,i)=0ifi≠j1ifi=j,andw(l)is the weight assigned to the lth classifier. The weights used in Eq. (2) play a key-role in establishing the quality ofΨ¯[42]. In this paper, we construct an ensemble with decision tree classifiers as base classifiers. Therefore, it is not possible to use support functions [45] and we consequently revert to a weighted voting approach which has been shown to behave better than canonical voting methods [43].The performance and quality of machine learning algorithms is conventionally evaluated using predictive accuracy. However, this is not appropriate when the data under consideration is strongly imbalanced, since the decision boundary may be strongly biased towards the majority class, leading to poor recognition of the minority class as illustrated in Fig. 1.Class imbalance not only makes the learning task more complex [38], it is usually accompanied also by other difficulties such as:•Small sample size: In many cases the number of minority class samples is insufficient to properly train a classifier, hence resulting in poor generalisation and possibly leading to overfitting. Even though it has been shown, that when the number of minority samples is sufficient the uneven class distribution itself does not cause a significant drop in recognition rate [10], often this is not possible for real-life classification problems.Small disjuncts: This problem is connected to the previous one, as it may happen that the minority class is represented by a number of subconcepts, meaning that its objects form several spread “chunks” of data [34]. This leads to difficulties due to the lack of uniform structure in the minority class and low sample count in each of the subconcepts.Class overlapping: When discriminative rules are constructed in such a way as to minimise the number of misclassified instances, this may lead to poor performance for objects in the overlap area to the minority class [14].Techniques that address the problems associated with imbalanced datasets can in general be divided into three groups [33]:•Data level approaches work, in a pre-processing stage, directly on the data space, and attempt to re-balance the class distributions. They are independent of the actual classification stage, and hence can be employed flexibly. The most popular approaches employ an oversampling strategy that introduces artificial objects into the data space. The best known technique here is SMOTE [7], although more recently, improved alternatives such as ADASYN [15] (which also considers which objects are the most difficult to learn) or RAMO [9] (which uses a probabilistically directed approach) have been proposed. Oversampling methods however may also lead to other problems, such as class distribution shift when running too many iterations (since new artificial objects are being created on the basis of previously introduced samples).Classifier level approaches try to adapt existing algorithms to the problem of imbalanced datasets and bias them towards favouring the minority class. Here, some more in-depth knowledge about the nature of the used predictors and factors that cause its failure in minority class recognition is required. One possibility is to perform one-class classification, which can learn the concepts of the minority class by treating majority objects as outliers [26].Cost-sensitive approaches can use both data modifications (by adding a specified cost to the misclassification) and modifications of the learning algorithms (to adapt them to the possibility of misclassification). A higher misclassification cost is assigned for minority class objects and classification performed so as to reduce the overall learning cost. Costs are often specified in form of cost matrices such as the one presented in Table 1. The main disadvantage of cost-sensitive methods is the lack of knowledge on how to set the actual values in the cost matrix, since in most cases this is not known from the data nor given by an expert.MCSs have also been adapted to account for possible class imbalances [40], and typically combine an MCS algorithm with one of the above techniques. Examples of a combination of oversampling and classifier ensembles are SMOTEBagging [40] and SMOTEBoost [8] which introduce new objects into each of the bags/boosting iterations separately. IIvotes [5] is another interesting approach which fuses a rule-based ensemble with a SPIDER pre-processing scheme so as to be more robust with respect to atypical data distributions in minority classes and to automatically find an optimal number of bags. A fusion of MCSs and one-class classifiers constructed with respect to maintaining their diversity has been shown to be effective for imbalanced classification [21]. Cost-sensitive MCSs are mostly based on adjusting the object weights in a boosting schema [37], although schemes based on cost-sensitive decision trees have also been exploited [24]. EasyEnsemble [31] uses bagging as the main concept, but since for each of the bags AdaBoost is used as the base model, it can be viewed as an ensemble of ensembles.The problem we are addressing in this paper is how to select and combine individual classifiers of an ensemble with respect to misclassification cost. Our aim is to create an ensemble with minimal classification error P within the cost bounds of a cost matrix C. For this purpose, we require a pool of base classifiers at our disposal. For this, we propose a method to create a start-up pool of classifiers for further evaluation using an evolutionary approach.As base classifier we have chosen a cost-sensitive classification tree, that has its roots in the idea of the EG2 algorithm [35] whose decision tree induction is based on the misclassification cost rate proposed in [6]. A local sequential search at each node is performed [30]. This way, we can boost the recognition rate of the majority class by assigning a greater cost to a situation when a minority object is misclassified. An example of the differences in outputs of canonical and cost-sensitive decision trees for an imbalanced problem is illustrated in Fig. 2.To create a representative pool of classifiers, we use a random subspace approach [17], which randomly divides the feature space into several subspaces and trains individual classifiers in each of them. This ensures that the pool is diverse and contains heterogeneous rather than homogenous classifiers.In order to select individual classifiers for the ensemble, we employ an evolutionary algorithm (EA). An individual in the EA population represents a classifier ensemble(4)Ch=[W],where component W represents the weights assigned to each of the base classifiers(5)W=[W1,W2,…,WL],and is a real-valued vector with values in [0;1]. When a classifier is not selected in a particular individual its weight is automatically set to 0. In earlier work [27], we have used a maximal size of the ensemble, which required the number of ensemble members as a parameter. Our proposed algorithm lifts this restriction. The chromosome always have size equal to L, but when the weight assigned to the lth classifier drops to 0, the classifier takes no part in the final decision (hence by this we apply the classifier selection procedure). Therefore, the algorithm automatically adjusts the size of the committee.Our proposed algorithm is given, in pseudo-code form, in Algorithm 1.Algorithm 1Evolutionary ensemble algorithm.Input:U → set of classifiersOutput:Q → ensemble after pruningW → set of weights assigned to classifiersP=1.0B= emptyCreate initial populationSelect individuals for evaluationfor all selected individuals doif fitness(W) <PthenReplace the overall ensemble error with the lower oneReplace the best solution with the current oneend ifend forwhile termination conditions not satisfied doSelect pairs for crossover from best-ranked individualsApply crossover operatorApply mutation operatorSelect new individualsfor all selected individuals doif fitness(W) <PthenReplace the overall ensemble error with the lower oneReplace the best solution with the current oneend ifend forCreate new populationend whileThe control parameters of the EA are as follows:•Nc– the upper limit of algorithm cycles,Np– the population quantity,β – the mutation probability,γ – the crossover probability,Δm– the mutation range factor,V – the upper limit of algorithm iterations without quality improvement.In the following, we detail each of the steps of the algorithm:Population generation: We generate a set of members in such a way that all constraints and implications resulting from the model's logic and the input parameter values are preserved.Population assessment: At the beginning, for each member of the population, the value of the fitness function is calculated according to Eq. (2).Choosing elite members: Members with the highest fitness values are taken from the population and carried over to the descendant population without mutation, crossover or selection.Mutation: The mutation operator changes a selected (one at a time) member of the population by applying some random changes to its chromosome. The chromosome is altered with a probability that is changed during the optimisation progress. In the early phase of the optimisation, a special emphasis is put on searching for possibly best areas of the weights values, while later on attention is shifted to exploring the most promising area for optimal settings. Mutation involves adding a vector of numbers randomly generated according to a normal density distribution (with mean of 0 and standard deviation of Δm).Crossover: The crossover operator generates one offspring member from two parents. Offsprings are obtained according to the two-point rule.Selection of new population: A selection of individuals from the population is formed by merging the descendant population and a set of individuals created by mutation and crossover. The probability of selection Psof a particular individual is proportional to the value of its fitness. A tournament selection scheme is employed [3].The weighted voting rule is used to combine the base classifiers following Eq. (2). The ensemble classification error, calculated on the training set, serves as fitness function. Termination conditions can be adjusted; we use the number of iterations without result improvement. The number of classifiers in the committee after the pruning procedure is automatically adjusted by the EA.In this section, we present a thorough experimental investigation to examine the behaviour of our proposed cost-sensitive ensemble. Besides a comparison between our new algorithm and several state-of-the-art methods, we also examine the influence of the cost matrix setting on the overall classification accuracy. For this purpose, we apply ROC analysis [13] where as the cut-off points we use the parameter assigned as misclassification cost of the minority class, denoted as Cminority. This way we may search for correlations between the cost parameter and the overall classification accuracy. The employed cost matrix is given in Table 2. We investigate the performance of our algorithm with three different imbalance ratios to see if there is any correlation between the object distribution disproportion and the optimal value of Cminorityin Table 2.For our experiments, we have selected six benchmark binary imbalanced datasets taken from the KEEL Repository [1]. Details of the employed datasets are given in Table 3.A total of 50 cost-sensitive decision trees classifiers were trained using the random subspace approach, consisting of 40% of the original feature space.As the ensemble pruning procedure is based on an EA, the employed parameters may have a crucial impact on its quality. Therefore, to establish the values of optimisation parameters we ran a grid search procedure [36] over the following intervals of parameters values:•Nc∈[100, 2000], with step-size 100;Np∈[10, 200], with step-size 5;β∈[0.1, 0.9] with step-size 0.1;γ∈[0.1, 0.9] with step-size 0.1;Δm∈[0.1, 0.9] with step-size 0.1;V∈[10, 100] with step-size 10.The intervals for the examined parameter values were dictated by our previous experience with evolutionary-based ensembles [18,24,27]. The values, which returned the best final results for the weights optimisation, were as follows: Nc=1000, Np=50, β=0.7, γ=0.3, Δm=0.2, and V=20.We compared our method to SMOTEBagging, SMOTEBoost, IIvotes and EasyEnsemble. In addition, we implemented a single cost-sensitive tree, and the cost-sensitive ensemble from our previous work [27], in which the classifiers weights were set according to their individual accuracies and with a maximum ensemble size of 5. Both of these used the same cost matrices as derived for the proposed committee.A combined 5x2 CV F test [2] was carried out to assess the statistical significance of the obtained results with classifier sensitivity as the tested value.Since we would like to examine the behaviour of our proposed method at different levels of imbalance, we derived three new datasets using a random undersampling method so that each of the six datasets were examined at levels of imbalance ratios of 1:10, 1:25, and 1:50.

@&#CONCLUSIONS@&#
Imbalanced classification constitutes a major challenge in machine learning. In this paper, we have introduced a novel ensemble dedicated to imbalanced classification problems. Combining cost-sensitive decision trees with random subspace based feature space partitioning results in the creation of a pool of individual classifiers capable of improved recognition of the minority class. From the classifier pool, complementary classifiers are selected with the aid of an evolutionary algorithm while at the same time, the assignment of classifier weights, used in the fusion step, is treated as an optimisation problem and also embedded into the evolutionary approach. Consequently, simultaneous selection and weighted fusion is performed to exploit the individual strengths of classifiers available at hand.One of the major issues in cost-sensitive classification is the derivation of cost-matrices. In our approach, we addressed this based on ROC analysis, and showed that there exists a direct correlation between the dataset imbalance ratio and the optimal cost matrix settings.We evaluated our method on six binary imbalanced benchmarks and with three different levels of data imbalance. Our results conclusively show that our proposed method provides an effective tool for the classification of imbalanced datasets, often outperforming other state-of-the-art ensembles.