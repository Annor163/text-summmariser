@&#MAIN-TITLE@&#
Machine Learnable Fold Space Representation based on Residue Cluster Classes

@&#HIGHLIGHTS@&#
We implemented a vectorial representation of residues contactsWe implemented an efficient statistical test for machine-learnable dataOur vectorial model reproduces protein packingA predictor is trained to effectively reproduce CATH and SCOP classificationsOur predictor automatically identified inconsistent classification in CATH and SCOP

@&#KEYPHRASES@&#


@&#ABSTRACT@&#
MotivationProtein fold space is a conceptual framework where all possible protein folds exist and ideas about protein structure, function and evolution may be analyzed. Classification of protein folds in this space is commonly achieved by using similarity indexes and/or machine learning approaches, each with different limitations.ResultsWe propose a method for constructing a compact vector space model of protein fold space by representing each protein structure by its residues local contacts. We developed an efficient method to statistically test for the separability of points in a space and showed that our protein fold space representation is learnable by any machine-learning algorithm.AvailabilityAn API is freely available at https://code.google.com/p/pyrcc/.

@&#INTRODUCTION@&#
All possible protein folds are assumed to occupy an abstract space referred to as fold space. This fold space has become a conceptual framework to unify ideas about protein structures with protein function and protein evolution (Cheng and Brooks, 2013). For instance, it is debated whether this space is discrete or continuous (Kolodny et al., 2006; Skolnick et al., 2009; Sadreyev et al., 2009). Relevant to our study is the common use of protein similarity measures (e.g., root mean square deviation or RMSD) aimed to infer their proximities in this space (Minary and Levitt, 2008). In this case, the inference derived from such measurements assumes that the proximity of protein folds is the only relevant property to explain protein fold evolution and function.Instead of focusing only on the proximity of protein folds, vector space models have been used to expand the protein fold space representation. In this space, each protein structure is represented in a fixed dimension space (e.g., euclidean space) by a point (position vector); adjusting the positions of these vectors by approximating their relative distances to protein similarity measures may derive these position vectors. For example, using sequential structure alignment program scores between each pair of structures as a protein similarity measure (Orengo and Taylor, 1996), followed by multi dimensional scaling allowed the assignment of positions vectors representing each protein structure (Michie et al., 1996).Using DALI as similarity measure, Holm (Holm and Sander, 1998) showed two-dimensional projections to explore protein neighbors in fold space. DALI has also been used as similarity measure to visualize class distribution and fold usages between two bacterial species (Hou et al., 2003) and to explore protein function assignment based on position on this fold space representation (Hou et al., 2005).Fold space constructions based on protein structure similarities have two important limitations. First, the time needed to run a structural comparison for each pair of structures is restrictive: 25000 central processing unit hours were needed for calculating similarities between 1898 protein structures (Hou et al., 2005). Second, the position of each point depends heavily on the set of structures being analyzed, and in such case the inclusion of a single new structure can displace all previously assigned positions; thus, there are as many fold space representations as different protein structures data sets, even adopting a unique similarity score.An alternative fold space representation may be built by assigning the position of the vector considering only the structural features of the protein it represents. In this way, a new structure can find its location in this fold space without altering the existing ones. One implementation of a vector space model is FragBag (Budowski-Tal et al., 2010), which represents protein structures in 400 dimensions; here, each component in the vector representing a protein fold corresponds to the number of occurrences of a particular contiguous protein sequence fragment. Another approach uses knot invariants as values in each component for vector points in 30 dimensions (Rogen and Fain, 2003). In these cases, it is assumed that proximal protein structures should belong to the same structural class, assumption that is not necessarily correct as we will argue below.Once a protein fold space construction is chosen, a metric distance induced by the space can be used as a measure of similarity and it is expected to be in agreement with direct structural measures (such as RMSD, GDT, TMscore, etc), but overcoming the problems noted above about these scores not being a metric (Sippl, 2008).In such space, a given set of protein structures that are considered to have the same fold may be close in this space representation. Yet, it may occur that some proteins with different folds may be closer than proteins with the same fold (see Figure 1). Thus, confusion may be induced at distinguishing class membership in this fold space when only similarity measures are considered.To address this problem, the boundaries between proteins with different folds may be obtained using empirical data and machine learning algorithms, which naturally segregate protein structures sharing common features. In these models it is also possible to evaluate the separability of this space independently of any machine-learning algorithm using a statistical test (Zighed et al., 2002). Therefore, it is possible to generate a protein fold space representation independent on the protein similarity measure used and to test for the separability of this space independently of any particular classification algorithm. This protein fold space may then be used to analyze protein structure-function relation and protein evolution without the limitations previously noted of current protein fold space construction approaches.In this work, we propose a compact (low dimensional) fold space representation based on Residue Cluster Classes (RCCs), a Sperner family that includes all sets of residues in simultaneous contact. We also present an efficient computational method useful to test for the separability of this fold space representation. As a proof of principle, we analyzed the CATH classification and automatically detected conflicts in CATH. Furthermore, we show that our method improves state of the art protein structure neighbor retrieval methods. To facilitate the construction of protein folds represented by RCCs, we present an API available at https://code.google.com/p/pyrcc/.CATHALL1 set includes all domains in CATH release v3.5 that were parsable with our API and consists of 168964 domains. CATHALL2 set includes all domains in CATH release v4.0 and contains 235858 domains. CATCHOP was obtained from a random sample of CATHALL1 considering only six domains per topology; topologies with less than six members were excluded rendering a total of 5220 domains (see supplemental Table S1 for a complete list).The SCOP30 dataset was provided by the authors of ContactLib (Xuefeng Cui et al., 2014) and contains 3295 SCOP domains. SCOP30 contains 2639, 3232 and 3290 neighbours at SAS levels 20,35 and 50. Yet, only 2049, 2620 and 2722 domains have at least one neighbor in SAS 20, 35 and 50, respectively. The SCOPtrain1 is a random sample of 136300 SCOP 1.75B. SCOPtrain2 contains all 203025 domains from SCOP release v2.5. The SCOPtrainAUC includes 109310 SCOPtrain domains absent in SAS50 group, and only belonging to a class in SCOP30. If a class (at any level) contains more than 2000 domains, 2000 domains were chosen randomly to represent that class.Residue Neighbourhood (Nϵ(r)). Let P be a protein with residues R=r1, r2, ..., rn. The system τprimis defined as:τprim={{ri,rj}:thereexistsabondbetweenriandrj}Given a metric d:R×R→[0, ∞) and a cut-off distance ϵ, the neighbourhood Nϵ(r) of a residue r is given by:Nϵ(r)={x∈R:∃a∈A(x),b∈A(r);d(a,b)≤ϵ}Where A(r) is the set of non-hydrogen atoms of residue r. Thus, Nϵ(r) is the set of all residues near r, i.e., they are at no more than a distance ϵ from r.Residue Cluster (RC). A residue cluster on P is a subset A⊆2Rsuch that A⊆Nϵ(a) for all a∈A. IfA=k, then A is a k-Residue Cluster,kRCResidue Cluster Class (RCC). A class over a RC is defined by the primary structure on τprim. A pair of residues ri, rjare contiguous if {ri, rj}∈τprimand a setsL¯of L residues form a segment in τprimif it contains (L−1) contiguous residues. By convention,s1¯={r}for any r∈R.Let be γ the family of all segments in τprim. C is a set cover of a k-Residue ClusterkRC ifC={sLα¯:α∈A,sLα¯∈γ}such thatkRC=⋃α∈AsLα¯andci∩cj=∅,∀ci,cj∈CTherefore,C=sL1¯,sL2¯,...,sLA¯is a covering if∑i=1ALi=kand can be uniquely identified by the vector classC→=(L1,L2,...,LA)with Li≤Ljfor any i, j such that i≤j.Lets define the k-Residue Cluster ClasskRCC→as the set of allkRC of classC→. The residue cluster class systemRis a Sperner family (Lubell, 1996). It is defined as the set of all residue clusters for all k,C→such that none is subset of some other, that is:R={W∈R:∃X∈kRCc→,X⊆W}LetM(ci→)be the number of occurrences of a residue cluster classci→in a systemR.The vector pointR→ofRis defined byR→=∑i∈IM(ci→)viwithvi∈B, whereB={v1,v2,...,v|I|}is the standard orthonormal basis forℝ|I|and I is an index set over the set of cluster classes considered.Thus, an RCC construction is illustrated in Figure 2where different classes are assigned to akRCC→according to sequence contiguity.Clusters were computed using graph theoretical algorithms. First, a graph G is constructed with a V(G) vertex set that represents the residues set for a given protein, and E(G) edges set is the set of all residue clusters of size two. This graph is equivalent to a residue contact map and is constructed with the same program used in (Cusack et al., 2007): any two residues are paired if they share at least one atom pair at 5Å or less in the three dimensional representation of a folded protein. As any clique in G (i.e. a complete subgraph) is consistent with our cluster definition, all maximal cliques (cliques that are not a subgraph of any other clique) are considered as clusters, and classes are assigned directly from sequence contiguity. Maximal cliques were obtained using the algorithm previously described (Tomita et al., 2006) as implemented in NetworkX (Hagberg et al., 2008).Thus, for any given protein there are 3 3RCC ([1,1,1], [1,2], [3]; see Figure 2 for the nomenclature used to refer to these RCCs), 5 4RCC ([1,1,1,1], [1,1,2], [2,2], [1,3], [4]), 7 5RCC ([1,1,1,1,1], [1,1,1,2], [1,2,2], [1,1,3], [2,3], [1,4], [5]) and 11 6RCC ([1,1,1,1,1,1], [1,1,1,1,2], [1,1,2,2], [2,2,2], [1,1,1,3], [1,2,3], [3,3], [1,1,4], [2,4], [1,5], [6]); thus, there are 26 RCCs for any given protein. To represent these in a vector, we used the frequency of occurrence of eachkRCC as the value for each dimension of this vector. Figure 3illustrates an example of the construction of a vector using a self-avoiding walk over a lattice grid. An API was made for cluster calculations from protein structures and can be accessed via https://code.google.com/p/pyrcc/.The Cut Edge Weight statistic (Zighed et al., 2002) was used to test the hypothesis that a given class distribution of vector points (i.e., protein domains in CATH) is random. The construction of the statistic is limited by the construction of the relative neighbourhood graph (RNG) of the points. A naive algorithm takes O(n3) and lower bounds have been reported only for particular cases in low dimensions. Here we include a demonstration that a RNG is always a subgraph of the Half-Space Proximal (HSP) graph (see below).To obtain the RNG, the HSP graph H of the set of 26-dimension vectors was obtained (see below for HSP construction procedure). Then, for each edge (a, b) in H we remove the edge if the following condition was satisfied:max{d(a,c),d(b,c)<d(a,b)}where d(i, j) is the euclidean distance between points i and j.This condition was applied for any c in H. After this procedure, the resulting graph was the RNG used for statistics computation as described in Zighed et al. (2002).A detailed description of HSP and a proof for containing RNG is described below. The source code to compute this statistical test can be obtained from the authors upon request.The Half Space Proximal (HSP) is a local test for building a geometric spanner of bounded dilation over a set of points in the space, it was introduced in Chavez et al. (2006). Assume there is a set V of points loaded with a metric. To fix ideas think in the plane and the euclidean distance between points, in our case the set of points are 26 dimensional vectors representing protein structures, although these could be any set of objects in an abstract metric space. All the construction will be based on the distance metric. For each point u in V we compute its HSP neighbours as follows.For a point u in V take its nearest elementvand add an edge from u tov; remove all the elements that are closer tovthan to u. The region of points closer tovthan to u is called the forbidden region from the point u with respect tov. From the remaining points, those points not in the forbidden region, take the nearest point to u and repeat until all points in V belong to some forbidden region. In the end, we will have a directed graph with vertex set V and the edges found with the above procedure. In this paper we are interested in the HSP as a super graph of the Relative Neighbourhood Graph (RNG), faster to build, as described below.For the same set V two points u,vwill share an edge in the RNG if there is not a point z∈V such that z is in the intersection of the circles centered in u,v, respectively, with radiusuv. Then, RNG and the HSP are related and we will show that RNG ⊆ HSP.Lemma 1If there is not an edge from the point u tov, then there exist a point z such that it connects to u and z is in the intersection of the two circles centered at u andvwith radiusuv.ProofIf there is not an edge from the point u tov, then,vis in a forbidden region of u and some point z. The point z connects to u and is closer to u than fromv, so, z is in the circle centered at u with radiusuv. Asvis in the forbidden region of u with respect to z, thenvis closer to z than to u, so, z is in the circle centered atvwith radiusuv.One way to characterize the RNG is by observing that two points p and q will share an edge whenever there is not a third point r that is closer to both p and q than they are to each other.Lemma 2If an edge is in the RNG then, it is in the HSP.ProofLets suppose that two points p and q are not connected by the HSP, then, there exist a point z that is in the intersection of the two circles centered at p and q with radiuspq, then the two point p, q are not connected in the RNG.A brute force approach to build the RNG built over a set of n points require checking O(n2) pairs to see if they share and edge; furthermore, each pair requires O(n) points to be tested for inclusion in the intersection. This yields a total complexity of O(n3) operations. On the other hand, all the HSP neighbours of a point u can be computed in an amortized O(n) operations. The total complexity of building the HSP is then O(n2). The total number of HSP neighbours of any point u is bounded, and depends only on the dimension of the space, and it is independent of the size of the point set. This implies that the number of edges in the HSP is only linear on n.Using the above observations to test if an edge is in the RNG graph, we only need to test the linear number of edges of the HSP. Each test cost O(n) operations, and consist in checking if the intersection is empty. Even with brute force, the total time for building the RNG would be O(n2) instead of O(n3) using other construction algorithms.Figure 4illustrates the inclusion of the RNG in the HSP. Dotted edges in the figure are those to be removed from the HSP. To exemplify the improvement on computing time by our approach, Figure 5 shows execution times to calculate RNG, HSP and RNG from HSP for two randomly generated datasets.A learner including an ensemble of 250 extremely randomized trees (ERT) was trained for cross-validation tests, predicting the Class, Architecture and Topology in CATH classification, and Class, Topology and Superfamily in SCOP. Bootstrap samples were not used for building the trees, and a minimum of 3 nodes where required to remain after each split. In each tree, Gini index was used for deciding attributes for splitting.Same setup but with 300 trees was used for AUROC analysis. These classifiers were implemented using sklearn (Pedregosa et al., 2011).To learn the structural classification from CATH, we used the CATHALL1 and CATHAll2 sets; for SCOP, we used the SCOPtrain1 and SCOPTtrain2 sets.

@&#CONCLUSIONS@&#
