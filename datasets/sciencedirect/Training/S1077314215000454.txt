@&#MAIN-TITLE@&#
Selection of optimized features and weights on face-iris fusion using distance images

@&#HIGHLIGHTS@&#
A novel system for face-iris fusion on distance images is proposed.Optimal features, feature extractors and weights are selected.Backtracking Search Algorithm and Particle Swarm Optimization are used.The proposed system outperforms state-of-the-art face-iris recognition systems.The proposed system is robust against spoofing attacks.

@&#KEYPHRASES@&#
Multimodal biometrics,Particle Swarm Optimization,Backtracking Search Algorithm,Information fusion,Spoof attacks,

@&#ABSTRACT@&#
The focus of this paper is on proposing new schemes based on score level and feature level fusion to fuse face and iris modalities by employing several global and local feature extraction methods in order to effectively code face and iris modalities. The proposed schemes are examined using different techniques at matching score level and feature level fusion on CASIA Iris Distance database, Print Attack face database, Replay Attack face database and IIIT-Delhi Contact Lens iris database. The proposed schemes involve the consideration of Particle Swarm Optimization (PSO) and Backtracking Search Algorithm (BSA) in order to select optimized features and weights to achieve robust recognition system by reducing the number of features in feature level fusion of the multimodal biometric system and optimizing the weights assigned to the face-iris multimodal biometric system scores in score level fusion step. Additionally, in order to improve face and iris recognition systems and subsequently the recognition of multimodal face-iris biometric system, the proposed methods attempt to correct and align the location of both eyes by measuring the iris rotation angle. Demonstration of the results based on both identification and verification rates clarifies that the proposed fusion schemes obtain a significant improvement over unimodal and other multimodal methods implemented in this study. Furthermore, the robustness of the proposed multimodal schemes is demonstrated against spoof attacks on several face and iris spoofing datasets.

@&#INTRODUCTION@&#
Currently, the identification and verification of human beings based on physical or behavioral characteristics is a trend in places with high security needs. In general, most biometric systems in the real time applications use a single biometric characteristic; unimodal biometric is suffered due to different factors such as lack of uniqueness, non-universality and noisy data [1]. For instance, variations in terms of illumination, pose and expression lead to degradation of face recognition performance [1]. Performance of iris recognition can be degraded in non-cooperative situations [2]. In order to solve the problem raised by the single trait, multimodality that is extracting information from multiple biometric traits can be applied as a remedy and ultimately causes to improve the performance of biometric systems.In this study, face and iris biometrics are used to fuse the information because of many similar characteristics of these two modalities. Information fusion for multimodal biometric systems can be performed at four different levels: sensor level, feature level, matching score level and decision level fusion [1]. Due to the ease in accessing and combining the scores, matching score fusion level is more popular among all fusion levels and involves three different categories. The first category is Transformation-based score fusion where normalization of matching scores into a common domain is needed prior to combining due to incompatibility of different modalities feature set. Classifier-based score fusion is the second category that concatenates the scores from different systems. In fact, the scores from different classifiers are treated as a feature vector where each matching score is considered as an element of feature vector. Finally, the third category is Density-based score fusion that requires an explicit estimation of genuine and impostor matching score densities leading to an increase in implementation complexity [3]. Current researchers’ studies [3,4] can be used as an evidence to state that employing score fusion techniques such as Sum Rule and Weighted-Sum Rule with a proper score normalization method leads to an unprecedented improvement on unimodal biometric systems performance. On the other hand, feature level fusion [43,44] considers the original feature sets of different modalities and therefore contains richer information about the raw biometric data compared to matching score level fusion and may lead to performance improvement. However, concatenating the feature sets may cause high dimensionality problem and produces noisy or redundant data; consequently affecting the performance [5]. In this respect, feature selection can be considered as a solution to enhance the performance of biometric systems by selecting an optimized subset of features from the original feature set based on a certain objective function.In this study, effect of several techniques in different fusion levels is investigated on the proposed schemes using face and iris modalities. Local and global feature extraction methods namely subpattern-based PCA (spPCA) [6], modular PCA (mPCA) [7], Local Binary Patterns (LBP) [8], Principal Component Analysis (PCA) [9] and subspace Linear Discriminant Analysis (LDA) [10] are employed on face images in this study. For iris recognition, a publicly available library implemented by Masek and Kovesi [11] is applied to extract iris features. In order to evaluate the proposed schemes, CASIA Iris Distance[12] database, Print Attack face database [38], Replay Attack face database [39] and IIIT-Delhi Contact Lens iris database [40] are used. CASIA-Iris-Distance images were captured by a high resolution camera, so both dual-eye iris and face patterns are included in the image region with detailed facial features for multimodal biometric information fusion [12]. The Print-Attack Replay Database consists of 200 video clips of printed-photo attack attempts to 50 clients, under different lighting conditions and 200 real-access attempt videos from the same clients [38]. On the other hand, Replay-Attack Database consists of 1300 video clips of photo and video attack attempts to 50 clients, under different lighting conditions [39]. IIIT-Delhi Contact Lens iris database consists of 6570 iris images pertaining to 101 subjects. Both left and right iris images of each subject are available in this database. Iris images are captured using two iris sensors namely; Cogent dual iris sensor and VistaFA2E single iris sensor [40]. In this study, as a unimodal system, all five local and global methods are applied on face images of the database and both left and right irises of the corresponding face image are considered to extract iris features by using Masek & Kovesi iris recognition system. As a multimodal biometric system, the proposed scheme involves consideration of all face and both left and right iris scores along with Particle Swarm Optimization (PSO) [13] and Backtracking Search Algorithm [41] to select the optimized subset of features and weights. In order to enhance the accuracy of face and iris unimodal and multimodal systems, face images are detected and aligned based on the center position of both left and right eyes. Indeed, by using the center positions, angle of head roll and iris rotation can be measured to align the face images and rotate back the iris patterns. Prior to fusion, tanh normalization [14,15] is applied on the face and iris scores to transfer the scores into a common domain and range. The fusion of the two modalities, face and iris, is then tested with a well known combination method namely Weighted Sum Rule [5]. The proposed schemes are also tested on several spoofing attacks to show the robustness of the multimodal fusion schemes. In general, spoofing attacks [45–47] include cheating on biometric traits in order to have unauthorized access to the biometric system. Since it is not needed to have any specific knowledge on the system for spoofing, such as the feature extraction or matching algorithm used, the chance of having a spoofing attack on the biometric system is high. Therefore, constructing a robust multimodal system against spoof attacks is very important for the security of biometric systems. There are several ways to spoof face images such as: (i) face spoofing through photograph, (ii) face spoofing through video or (iii) 3D face model or mask of a genuine user. The most common, the cheapest and the easiest way to spoof face images is face spoofing through photograph or video. Spoofing attacks through photograph, known as ‘photo-attacks’ consist of submitting a photograph of a legitimate user to the face recognition system displayed in hard copy or on the screen of a portable computer or smart phone [45–47]. On the other hand, there are different methods to spoof iris images also. Some of the ways for iris spoofing can be stated as (i) iris spoofing through pupil dilation, (ii) iris spoofing through textured contact lenses and (iii) iris spoofing through print attack [48].The proposed face-iris multimodal scheme is presented and compared with the existing unimodal and multimodal biometric systems in this study using Receiver Operator Characteristics (ROC) curves and Genuine Acceptance Rate (GAR). GAR at false acceptance rate (FAR 0.01%) is used to demonstrate the verification performance and recognition rate is also used to show the identification performance.The contribution of our work is to use left and right iris patterns with optimized features of local and global based facial feature extraction methods using PSO and BSA to remove redundant data for the fusion of face-iris multimodal system with tanh score normalization and Weighted Sum Rule fusion method where the weights are also optimized using PSO and BSA. The proposed scheme can be used practically in person identification and verification systems using facial images. The iris information from left and right eye can be extracted from the face image of the same individual and the fusion of face-iris multimodal system can be performed to improve the performance of the individual face and iris recognition systems. In fact, recognition is performed on fusion of face and both of the eyes’ iris patterns and therefore the verification becomes undisputable.The organization of the paper is as follows. Section 2 describes unimodal biometric systems. Section 3 has an overview on the fusion of face and iris biometrics at feature level and score level fusion. The proposed schemes are explained in Section 4 while Section 5 is devoted to the database details, experiments and results. Finally, Section 6 draws some conclusions.Face and iris biometrics are considered in this study to construct the structure of the unimodal and consequently multimodal system. Generally, face recognition and iris recognition are considered as one of the most attractive areas for biometric schemes in the past few years [30–36]. These biometrics are briefly described in the following subsections.The common processing steps for unimodal face system are image preprocessing, training, testing and matching. The illumination effects of face images are reduced by applying histogram equalization (HE) and mean-and-variance normalization (MVN) [16] on facial images in preprocessing step. The facial features are then extracted in the training and testing stages to be examined by different techniques in matching score level fusion, feature level and/or combination of both fusion levels. Finally in the last step, in order to compute the matching score between train and test feature vectors, Manhattan distance measurement is applied.The face databases used in different experiments of this study include several variations in images. Pose variations, illumination variations, facial expressions, distance images and occlusions due to glasses, mustache and beard are the variations that appear in the facial images. The availability of these variations on the facial databases used in this study is demonstrated in Table 1.In addition, identification accuracies of the state-of-the-art methods used in this study such as PCA, LDA, spPCA, mPCA and LBP are shown in that comparative table on the facial databases used in this study. Identification accuracies of the state-of-the-art methods are also presented in Table 1 using FERET, BANCA and CASIA-Iris-Distance datasets of facial images. The accuracies are reported using 50 individuals with 2 train and 2 test images on FERET, BANCA datasets and 90 individuals with 5 train and 5 test images on CASIA-Iris-Distance dataset. ORL database includes 40 individuals which are all used in these experiments with 2 train and 2 test images for each individual. The same parameter settings related to the state-of-the-art feature extraction methods are used as in [20]. The results demonstrate that LBP achieves better recognition accuracy compared to the other state-of-the-art feature extractors on all datasets. The highest accuracies are obtained on ORL dataset and the lowest accuracies are reported on CASIA-Iris-Distance dataset due to the distance factor that exist in these images.In this work, in order to improve the recognition performance of face images, AAM toolbox (Active Appearance Modeling) [17,37] is used to detect face images based on the center position of left and right irises. The toolbox aims to model and annotate human face images and obtain a precise location of facial features such as mouth, nose, eyes, and eyebrows. The precise center position of both irises is achieved by the toolbox and therefore we are able to measure the angle of head roll that may happen during acquisition of a face image. In fact, using the center positions and the measured angle, both eyes can be aligned in the face image.In this study, in order to extract iris features, Libor Masek’s iris recognition system [11] is applied. The typical processing steps for an iris recognition system are segmentation, normalization, feature encoding, and feature matching [11,23,29]. The automatic segmentation system of Libor Masek’s iris recognition system is based on the Hough transform to localize the circular iris and pupil region, occluding eyelids and eyelashes, and reflections. The extracted iris region is then normalized into a fixed rectangular block. In feature encoding step, 1D Log-Gabor filters are employed to extract the phase information of iris to encode the unique pattern of the iris into a bit-wise biometric template. Finally, the Hamming distance measurement is employed for classification of iris templates [11].Iris images include several variations such as illumination changes, occlusions due to eyelashes, eyelids and glasses, distance images, different noise factors such as reflections, contrast, luminosity, off angle, rotation, blurring and focus problems. These variations are summarized in Table 2 using the iris databases involved in the experiments of this study. The identification accuracies of the iris recognition system used in this study are also shown in Table 2 on three iris datasets namely CASIA-Iris-Distance-Left, CASIA-Iris-Distance-Right and UBIRIS. In the experiments, 50 individuals from each database with 2 train and 2 test images are used. The recognition accuracy achieved on UBIRIS dataset is better than the accuracies obtained on CASIA-Iris-Distance datasets because of the distance factor available in these images. Additionally, the iris images on CASIA-Iris-Distance datasets are extracted from the face images which decrease the quality of the iris images and consequently, the identification accuracy using these extracted iris images decreases.On the other hand, the performance of iris recognition system is needed to be improved by using rotation of the iris patterns. In other words, during acquisition of a face image, the iris patterns may rotate frequently because of the user head roll to left or right shoulder that may lead to degrade iris recognition performance [18]. The rotation of face images and consequently iris images causes circular shifting of the iris features and therefore if the rotation angles of the irises are different, the extracted feature codes can be misaligned which affects the recognition accuracy [18]. In this respect, plenty of researches are conducted to solve this problem based on shifting the iris feature codes to perform matching. The authors in [18] proposed a new method by measuring the angle of head roll to shift the iris feature codes. In this study, we apply a similar algorithm as in [18] to improve the iris recognition accuracy.Development of face-iris multimodal biometric system is one of the most significant steps in this study. This section describes the details of fusion techniques for face and iris modalities in different levels. Generally, fusing different modalities denotes an advantage to enhance the strength of the system especially in the case when one biometric trait of a person becomes defective. In the proposed scheme, feature level fusion and matching score level fusion is considered to authenticate the reality of a person.In feature level fusion, concatenation of the original feature sets of face and iris modalities is considered and therefore this level of fusion contains richer information about the raw biometric data. In this study, involving five different local and global feature extractor methods to extract the original facial feature sets may lead high dimension vectors resulting to decrease the system performance. Therefore designing a scheme to retain the appropriate information from the fused features of the five algorithms, namely Face Feature Vector Fusion (Face-FVF), with the ability of solving the dimensionality problem has to be considered. In order to overcome the dimensionality problem, we applied two optimization methods separately in 2 different levels as depicted in Fig. 1to select the optimized subsets of methods and features by removing the redundant and irrelevant data [1,13]. In the first proposed method, the well-known optimization technique named PSO [13] is used and then a more recent optimization technique named BSA [41] is applied in order to improve the system accuracy.PSO that was introduced by Kennedy and Eberhart in 1995 [13] aims to find an optimized solution in a search space. It is initialized with a population of random solutions called particles to be evaluated using a fitness function. Each particle is treated as a point in an n-dimensional feature space. The ith particle is represented as xi=(xi1,xi2,…,xin). The ability of PSO to memorize the best previous positions at each iteration causes to update each particle by two best values pbest and gbest. Pbest is the position giving the best fitness value of any particle which can be recorded and represented as pi=(pi1,pi2,…,pin), where P is the size of the population. The index of the best particle among all the particles in the population is called gbest and represented as pg. The velocity for ith particle is represented as vi=(vi1,vi2,…,vin). A particle’s new velocity is calculated according to its previous velocity and the distances of its current position from its own best position and from the group’s best experience. The particles are updated as follows [1,4,13]:(3.1)vi=wvi+c1×rand1(0.25em0ex)(pi−xi)+c2×rand2(0.25em0ex)(pg−xi)(3.2)xi=xi+vi(3.3)xi={1if0.35em0ex11+e−vi>rand3(0.25em0ex)0otherwisewhere w is the inertia weight, c1 and c2 are acceleration constants and rand1(), rand2(), rand3() are separate random numbers.Generally, selecting a proper inertia weight provides a balance between global and local explorations and consequently results in finding sufficient optimal solution faster. The acceleration constants c1 and c2 are used to pull particle toward pbest and gbest. Indeed, employing an appropriate fitness function to optimize the problem in feature selection techniques such as PSO is an important issue. Due to measuring verification and identification performance of biometric systems in this study, the consideration of two different fitness functions in implementing PSO is needed. The fitness function corresponding to identification aims to maximize the recognition rate by computing the distance of a test sample against all the training samples to find the match scores and selecting the lowest distance value to check if it belongs to the same person or not. On the other hand, the verification fitness function considers the distance between training and testing samples to obtain match scores and then computes FAR and its corresponding GAR to maximize them by setting a threshold.In this study, we set the inertia weight to 1, and the acceleration constants c1 and c2 both to 2 as in the original PSO [13]. Selection of features is based on a bit string of length M, where M is the number of feature extraction methods applied on face unimodal system in level 1 and number of features in level 2 that are taken from the selected feature extraction methods of level 1. In other words, every bit here represents one feature extraction method or one feature in the sense that; value ‘1’ means all features of corresponding feature extraction method are selected and ‘0’ means that they are not selected for level 1 PSO. In level 2 PSO, value ‘1’ means the feature of the corresponding feature extraction method taken from level 1 is selected and ‘0’ means that it is not selected. In our work for level 1 PSO, we assigned the size of the population and iteration as 6. In level 2 PSO, population and iteration size are set to 20 and 30 respectively.On the other hand, Backtracking Search Algorithm (BSA) is a recent optimization algorithm applied on many numerical optimization benchmark problems. BSA is compared with six widely used algorithms including PSO and it is reported that BSA is more successful than these comparison algorithms [41]. BSA was introduced by Civicioglu in 2013 [41] as a new Evolutionary Algorithm for solving real-valued numerical optimization problems. The algorithm reduces the effects of problems encountered in Evolutionary Algorithms such as excessive sensitivity to control parameters, premature convergence and slow computation. BSA has a single parameter, a simple structure that is effective, fast and capable of solving multimodal problems and it can be adapted to different numerical optimization problems. It includes two new crossover and mutation operators for generating a trial population. BSA has memory that allows it to use experiences from previous generations for generating trial populations.Backtracking Search Algorithm is a population-based iterative Evolutionary Algorithm and it has five processes namely initialization, selection-I, mutation, crossover and selection-II. The general structure of BSA algorithm is shown in Algorithm 1.Algorithm 1. General Structure of Backtracking Search Algorithm [41].1. Initializationrepeat2. Selection-IGeneration of Trial-Population3. Mutation4. Crossoverend5. Selection-IIUntil stopping conditions are metIn this study, instead of using minimization which is the main goal of BSA, we modified the algorithm to perform maximization. Scaling factor F is set to 1, mix_rate is set to 1, population and iteration size for level 1 BSA is set to 6. In level 2 BSA, population and iteration size are set to 20 and 30 respectively. The stopping condition for level 2 BSA is set to maximum number of iteration, or obtaining the highest recognition rate or failing to update the last best solution after 200 evaluations. If one of these three conditions are satisfied, the algorithm stops. The size of the swarm for weight selection using BSA is set to 20 with maximum iteration of 100. The stopping condition is set to maximum number of iteration, or obtaining the lowest possible EER or failing to update the last best solution after 400 evaluations.Matching score fusion level provides a rule to combine different scores. In this fusion method, different matchers may produce different scores such as distances or similarity measures with different probability distributions or accuracies [3]. Matching score level fusion can be considered as the classification of the scores into one of two classes, Accept/Reject, or combination of the scores to provide an individual scalar score [19]. Match score level fusion involves several simple or complicated algorithms to combine the scores such as Sum Rule, Weighted Sum Rule, Product Rule, classification using SVM and estimation of scores density. Similar and equivalent performance from the aforementioned combination methods are reported in the recent studies [3,5,20,21]. Involving match score level fusion for this work is arranged to combine the left and right irises of a certain person, facial scores achieved by individual feature extractors, facial scores obtained in the feature level fusion step using PSO in two different levels and finally it is used to combine fused face and iris scores.In order to normalize the face and iris matching scores produced from Manhattan distance and Hamming distance, tanh normalization technique [14] is applied on the produced matching scores from face and iris images to transfer them into a common domain and range. Tanh normalization is a robust and efficient method that was introduced by Hampel et al. [15] and works very well for noisy training scores. Tanh normalization is represented as(3.4)sk′={tanh(0.01(sk−μGHσGH))+1}where μGHis the mean and σGHis the standard deviation of the genuine score distribution [14].In this study we employ Sum Rule and Weighted Sum Rule techniques to combine the face and iris scores. Finding efficient weights to perform the experiments in both verification and identification modes is an important issue that can be effective for performance enhancement. Generally, Weighted Sum Rule is a method that can be used to compute combined matching scores of the individual matchers. Jain and Ross [22] have proposed to compute the weighted sum of scores from different modalities using user-specific weights. Usually, weights are computed using Equal Error Rate (EER), distribution of scores, quality of the individual biometrics or empirical schemes [4]. Weighted Sum Rule (ws) of different score matchers can be written as(3.5)ws=w1×s1+w2×s2+⋯+wn×snwhere w1,w2, …,wnare the assigned weights for different modalities and s1,s2, …,snare the scores obtained using individual biometric systems.In this study, we consider the idea of using continuous PSO to select the optimized weights to have a better evaluation on the multimodal system. Generally, assigning the proper weights to the scores obtained using individual biometric systems may produce sufficient output to guarantee the improved performance in both verification and identification modes. Each particle, i, representing the weighting vector wi=(wi1,wi2, …,win), is randomly initialized between 0 and 1 and then normalized with the constraint∑i=1kwi=1, where k is the number of weights. The particle positions are updated using velocity and position functions according to continuous PSO technique. Fitness function is computed as a combination of EER’s of involved scores in the proposed scheme with the weights represented by the particle as in the following equation to be considered as an optimization problem for minimization.(3.6)F(∑i=1kwiEERi)where w1,w2,…,wnare the optimized weights for different modalities and EER1,EER2,…,EERk(EERi) are the Equal Error Rates obtained using the corresponding scores in the proposed scheme. A reference database is used to test the proposed optimal weight selection part in order to choose the optimized weights and then the optimum weights are applied on our multimodal system. The size of the swarm in this study is set as 20 with maximum iteration of 100, inertia weight is 1, and the acceleration constants c1 and c2 are both set to 2.The structure of the proposed schemes is based on a face-iris multimodal biometric system using score-level fusion and feature level fusion. In fact, availability of sufficient information content and the ease in accessing and combining matching scores encouraged us to propose new schemes using matching score fusion techniques along with feature level fusion.The fusion of face and iris can be done with only one of the irises (left or right) or combination of both irises. This leads to improve the multimodal biometric system performance especially whenever the fusion is done using face and information obtained from combined scores of both irises. Since combining the information of both left and right irises can improve the authentication accuracy even with the images with low quality [24], in the proposed schemes we consider the combination of two irises as demonstrated in Fig. 2. The score fusion of left and right irises is done using Weighted Sum Rule.On the other hand, we performed feature concatenation on original face feature sets that may result dimensionality and redundancy problems and performance degradation. These kinds of problems can be alleviated using optimization algorithms such as PSO and BSA by selecting an optimized subset of features from original feature sets and removing the redundant and irrelevant data based on a certain objective function. Therefore, we applied two optimization algorithms separately in two different levels. In the first proposed scheme, the well-known PSO algorithm is used for optimization as in [4,42] on face and iris biometrics. Then, a new optimization technique named Backtracking Search Algorithm (BSA) [41] is used in the second proposed method to improve the accuracy of the first proposed method. In the first proposed method, we apply PSO in two different levels to select proper and optimized feature extractors and features. In addition, in order to combine face and iris in each PSO level, several fusion techniques are employed with left iris, right iris and combination of left and right irises as shown in Fig. 3.Fusion of face and iris explained in the above schemes in Fig. 3 may help to enhance the performance of the overall multimodal biometric system although the need to improve the performance of the system motivated us to find a new design to fuse face and iris information. The proposed scheme considers the combination of facial feature level fusion scores in both levels along with all the facial scores achieved using the five aforementioned feature extractors of an individual to be fused with the combined scores of left and right iris of the same individual. It is needed to state that the combination of all facial scores obtained using the five local and global feature extractors (PCA, LDA, spPCA, mPCA, LBP) is done with Weighted Sum Rule. On the other hand, Weighted Sum Rule fusion is applied on the normalized face and iris scores that guided us to a better performance compared to unimodal and other existing multimodal systems in this study.The proposed scheme considers the implementation of optimized weights using PSO with the fact that the proper weights are able to reflect the relative difference in unimodal systems performance compared to other fusion techniques [4]. The main idea of the proposed scheme is to fuse scores of all implemented algorithms and techniques on face and iris modalities to take the advantages of each technique on a specific modality for increasing the ability of the multimodal system. The block diagram of the proposed method is presented in Fig. 4. Four different weights are needed to fuse the face and iris scores using Weighted Sum Rule as shown in the block diagram of the proposed method in Fig. 4.The steps involved in proposed scheme I are used in proposed scheme II, however, instead of using the well-known PSO technique, BSA is used which is a more recent optimization technique. The block diagram of the second proposed method is demonstrated in Fig. 5.This section covers the detailed explanations about the database, experimental works and results on the unimodal and multimodal systems in order to show the robustness and strength of our proposed system compared to other existing techniques in this study.The face system used in this study employs five local and global feature extraction methods namely subpattern-based PCA (spPCA), modular PCA (mPCA), Local Binary Patterns (LBP), Principal Component Analysis (PCA) and subspace Linear Discriminant Analysis (LDA) to examine the performance. Implementation of all feature extractors is done using MATLAB. The facial images in subpattern-based PCA and modular PCA are initially partitioned into N2 subimages. Eigenvectors corresponding to 97% of eigenvalues with N=81, where N is the number of partitions, are considered for both spPCA and mPCA. Each facial image before partitioning is resized in order to have equal size for each subimage. PCA algorithm is implemented as described in [9] based on the selection of maximum number of nonzero eigenvectors. In subspace LDA, in order to have dimensionality reduction, PCA is applied on facial images initially and then extracted principal components by PCA are used as inputs to LDA. The numbers of eigenvectors selected in the first and second stages of LDA method are selected as the maximum number of nonzero eigenvectors. For Local Binary Patterns (LBP), the number of partitions used is N=81 as in spPCA and mPCA and (8,2) circular neighborhood is used.In order to evaluate the performance of our multimodal system, a publicly available database named CASIA-Iris-Distance is used. CASIA-Iris-Distance images were captured by a high resolution camera, so both dual-eye iris and face patterns are included in the image region with detailed facial features for multimodal biometric information fusion [12]. The full database includes 142 subjects and a total number of 2567 images. Face images were acquired at-a-distance of ∼3m from camera [12]. In this study we consider 90 subjects to construct our multimodal face and iris biometric system. The chosen subjects cover the proper information needed for building the multimodal system including the whole face images and clear dual-eye iris patterns. Those images that are not selected do not include some parts of face components such as mouth, forehead or eyebrows. Randomly 10 samples for each subject or individual are selected, 5 samples for training and the rest 5 for testing. Additionally, in order to decide on the four optimized weights applied in the first proposed scheme using PSO technique, three different face and iris subsets are used. These include FERET [25] +UBIRIS [26] dataset with 50 individuals and 4 samples from each database, ORL [27] +UBIRIS dataset with 40 individuals and 4 samples from each database and BANCA [28] +UBIRIS dataset with 50 individuals and 4 samples from each database. These subsets are only employed for weight selection. The averaged optimized selected weights with PSO are as w1=0.10, w2=0.31, w3=0.24 and w4=0.35 where the number of particles is 20 and the dimension of the search space is 400. Similarly, whenever BSA is employed in the second proposed scheme, the average optimized weights become as w1=0.21, w2=0.26, w3=0.22 and w4=0.31. In general, preliminary results comparing state-of-the-art methods used in Section 2 of this study are obtained using all the databases mentioned above and the corresponding results were shown in Tables 1 and 2. The evaluation of the proposed fusion schemes (proposed scheme I and proposed scheme II) and the corresponding comparisons with the state-of-the-art methods are all performed on CASIA-Iris-Distance images and the results are demonstrated in Tables 3–10. Parameter tuning for PSO and BSA optimization techniques are performed on three datasets namely FERET+UBIRIS, ORL+UBIRIS and BANCA+UBIRIS datasets.

@&#CONCLUSIONS@&#
