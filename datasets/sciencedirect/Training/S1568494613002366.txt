@&#MAIN-TITLE@&#
Subcellular localization using fluorescence imagery: Utilizing ensemble classification with diverse feature extraction strategies and data balancing

@&#HIGHLIGHTS@&#
Random Forest and Rotation Forest classifiers are used for subcellular localization.Various feature extraction strategies are utilized.SMOTE is employed as a data balancing technique.SMOTE has improved prediction performance in classifying protein images.A web server is available online at http://111.68.99.218/RF-SubLoc.

@&#KEYPHRASES@&#
Ensemble classification,Random forest,Rotation forest,Data balancing,SMOTE,Subcellular localization,

@&#ABSTRACT@&#
Protein subcellular localization plays a vital role in understanding proteins’ behavior under different circumstances. The effectiveness of various drugs can be assessed by the successful prediction of protein locations. Therefore, it is important to develop a prediction system that is sufficiently reliable and accurate in making decisions regarding the protein localization. However, main problem in developing a reliable and high throughput prediction system is the presence of imbalanced data, which greatly affects the performance of a prediction system. In order to remedy this problem, we utilized the notion of oversampling through Synthetic Minority Oversampling TEchnique (SMOTE). Further, different feature extraction strategies and ensemble classification techniques are assessed for their contribution toward the solution of the challenging problem of subcellular localization. After applying SMOTE data balancing technique, a remarkable improvement is observed in the performance of random forest and rotation forest ensemble classifiers for CHOM, CHOA and VeroA datasets. It is anticipated that our proposed model might be helpful for the research community in the field of functional and structural proteomics as well as in drug discovery.

@&#INTRODUCTION@&#
Protein is a fundamental component of cells in living organisms. Currently, comprehension of all the functions of proteins is an important goal in the field of biological sciences. This provides valuable information about the working of proteins both interior and exterior to cell [1]. Among various characteristics of proteins, subcellular localization is considered the most valuable one. This conveys substantial information about the behavioral and functional aspects of different proteins [2]. Various protein functions could be comprehended by specifying the subcellular localization of a particular protein [3]. For example, comprehension of subcellular location of proteins can help in understanding the cell behavior in different situations. Further, knowledge about the accurate localization of proteins could be helpful in examining the usefulness of drugs [4–6]. Early diagnosis of diseases might be expected successfully by accurately finding the protein locations within cells [7].Advancements in the medical imaging techniques allow the researchers to have large collections of medical images for research purposes [1]. In the domain of biological sciences, fluorescence microscopy is a widely used technique to acquire images of protein locations within cells. Analysis of these images, for classification purpose, is usually performed in traditional ways. However, conventional techniques are error prone, expensive, and time consuming [1,8]. Inaccurate and vague conclusions could be drawn about the subcellular localization of proteins. Automated classification systems, on the other hand, can outperform visual inspection [9]. Therefore, in order to predict protein localization with high precision, automated classification approaches are needed to be developed [7].Due to the development of computational resources, various researchers have developed efficient computational models that are capable of determining the subcellular localization of proteins from microscopy images [5,8,10,11]. Srinivasa et al. have developed an adaptive multiresolution technique for protein subcellular localization. They have utilized Haralick textures and morphological based feature extraction strategies at the sub-band levels. They have, then, combined decisions by employing the weighted k-means algorithm [7]. Lin et al. have proposed a variant of the AdaBoost algorithm using AdaBoost with Error-correcting Repeating Codes to predict the protein locations from fluorescence microscopy images. Using these images, they have extracted Strong Subcellular Location Features (SSLF) and Weak Subcellular Location Features (WSLF) [5]. In another approach, linear and radial basis functions for Support Vector Machine (SVM) models were developed by employing different Local Binary Patterns (LBP) for medical image classification [1]. Similarly, Huang and Murphy have utilized Directed Acyclic Graph (DAG) Gaussian kernel and max-win Gaussian kernel for SVM based prediction models using morphological features, Haralick texture features and their combination to classify multi-cell version of 2D HeLa images [12]. Further, they have employed stepwise discriminant analysis for selecting discriminative subsets of the extracted features. Zhang and Pham have used Subcellular Location Features (SLF), Local Binary Patterns (LBP), Gabor, and gray level co-occurrence matrix (GLCM) based features to develop two-staged hybrid classifier ensemble [13]. The first stage of their ensemble system consists of binary SVM models. Rejections of the first stage are given as input to the second stage where Random Forest, Multi-layer Perceptron, and SVM are developed. The combined decision is made using the majority voting scheme. In another approach, Zhang et al. have utilized curvelet transforms to develop a Random Subspace Ensemble (RSE) using Multi-layer Perceptron as base classifier. Then, simple majority voting scheme is utilized to combine the subspace predictions and make the final decision [14].Though, researchers have proposed various computational models to classify protein subcellular localization images, efforts are still going on to improve the accuracy of prediction systems by exploring the performance of different classifiers with various feature extraction strategies. Our aim is to develop an improved performance prediction system for subcellular location of fluorescence images. For this purpose, we have investigated the effectiveness of Random Forest and Rotation Forest based ensemble approaches. In our previous work, we have proposed SVM-SubLoc [4] prediction system for the classification of protein images from 2D HeLa and LOCATE datasets. Various spatial and transform domain features have been extracted from these images, which were exploited by different SVM models. The predictions of these SVMs are combined through the majority voting ensemble technique. In the current study, we have focused on developing such a prediction model that is capable of classifying unbalanced nature of data efficiently without biasing toward the majority class. Moreover, we have used spatial domain features only, which make it simpler than our previous work as far as feature extraction complexity is concerned. The feature extraction strategies, in the current study, include Haralick texture, Local Binary Patterns (LBP), edge, image, hull, histogram of oriented gradients and morphological based features. Various hybrid feature sets are constructed for the proposed prediction models by concatenating the individual features. These features have showed significant performance in extracting image based features from the input images. Three different datasets CHOM, CHOA, and VeroA are utilized to evaluate the performance of the proposed models. CHOA and VeroA datasets are highly unbalanced whereas CHOM dataset is possessing slight unbalance classes. Data imbalance is always considered a problem in developing efficient and reliable prediction systems. Due to unbalanced data, the prediction of classifier is biased toward the majority class [15,16]. Therefore, the performance related to the minority class is decreased. In this scenario, we have attempted to employ the Synthetic Minority Oversampling TEchnique (SMOTE) [17], which can minimize the effect of biased decision. SMOTE creates synthetic samples in the feature space to increase the number of minority class samples. This leads to the increase in classifier bias toward the minority class examples. Our proposed system has shown significant improvement using balanced data through SMOTE compared to using unbalanced data.The rest of the paper is organized as follows. Section 2 presents the datasets, discusses the oversampling technique, portrays the proposed system, describes the feature extraction strategies, and briefly introduces the classification algorithms. Section 3 then illustrates the experimental work carried out along with the analysis. Comparative analysis and conclusion are finally drawn at the end.In this section, we will provide the details about the datasets, SMOTE oversampling technique, various feature extraction strategies, and classification algorithms as follows.The performance of the proposed scheme is reported using three diverse types of datasets, which are obtained from two different labs. The dataset CHOM is obtained from Murphy's lab whereas datasets CHOA and VeroA are acquired from the Artificial Intelligence for Investigating Anti-cancer solutions (AIIA) lab in Taiwan.CHOM is a fluorescence microscopy image dataset consisting of Chinese Hamster Ovary cells [18]. It contains 327 images distributed in five distinct classes. Similarly, CHOA and VeroA contain 668 and 1472 images, respectively, distributed in eight distinct classes each [5]. Some sample images from each dataset are given in Figs. 1–3.We have adopted SMOTE to increase the minority class samples of all three datasets [17]. The number of samples before and after applying SMOTE technique has been demonstrated in Tables 1–3for all the datasets.SMOTE increases the amount of minority class samples by introducing synthetic examples in the feature space. It takes sample of the minority class and creates new synthetic samples along the line segments connecting some or all of the k nearest neighbors of that class. SMOTE first finds the difference between sample under consideration and its nearest neighbor. The output is then multiplied by a random number ranges from 0 to 1 and finally added to the sample under consideration. The produced synthetic sample is guaranteed to be along the line segment between two particular features. The generalization capability of classifier might be increased due to the synthetic samples.In this study, we propose Random Forest and Rotation Forest based ensemble system by employing various feature extraction strategies for CHOM, CHOA, and VeroA datasets. Fig. 4demonstrates the proposed prediction system developed for protein subcellular locations. After the computation of individual and hybrid features, SMOTE is applied in feature space. The output feature vectors are then delivered to the classifier. For comparison purpose, we have also obtained results without SMOTE technique. The detail of each part of the proposed system is presented as follows.We have employed Haralick textures, LBPs, image, edge, hull, and histogram of oriented gradients based feature extraction strategies. Further, we have constructed different hybrid models of these individual features. Table 4shows the complete name, short name, and dimension of each feature extraction technique. We have denoted uniform rotation invariant LBPs as LBP8, LBP16, and LBP24. The number with the feature name represents the neighborhood of operation.Haralick features [19] are computed along four directions horizontal, vertical, diagonal, and off diagonal. For Haralick texture features, first a Spatial Gray Level Dependence Matrix (SGLD) of an image with N gray levels is obtained. At certain angle θ, the size of resultant SGLD matrix is N×N. Each element in SGLD matrix shows the total number of pairs of gray levels co-occurred along the direction θ at some distance d, where distance d is measured in terms of the pixel distance. An example of 8-gray level image segment and its respective SGLD matrix are given in Fig. 5.Thirteen different statistical features have been computed from the SGLD matrix. These features include energy, correlation, inertia, entropy, inverse difference moment, sum average, sum variance, sum entropy, difference average, difference variance, difference entropy, and two information measures of correlation. These features are measured along four directions, θ=0°, 45°, 90° and 135°, yielding 52 features. In this effort, we combined the features along horizontal and vertical directions by computing the mean value. Similarly, features along diagonal and off-diagonal directions are averaged together. Therefore, 26 features for each input image are obtained for d=1.Local Binary Pattern (LBP) [1] is a texture based feature extraction strategy, which has low computational cost, low sensitivity to changes in illumination and rotation invariance that make it attractive for researchers. For a 3×3 mask, the procedure of computing the LBP code is explained as: First, value of the central pixel gcis subtracted from the value of each pixel gpin the neighborhood. Then, a threshold is applied to obtain the LBP textured image. Finally, each value of the neighborhood is converted to the decimal number system and summed to get the LBP code. In this way, we obtained LBP codes for the entire image.(1)LBPP,R=∑p=0P−1s(gp−gc)2pwhere P represents the number of neighborhood pixels and R indicates the radius around the central pixel. We have employed uniform rotation invariant LBPs with parameters (P=8, R=1), (P=16, R=2) and (P=24, R=3). LBP code generated with parameters (P=8, R=1) is illustrated in Fig. 6.The computation of image features is based on the Otsu global threshold [20]. This technique converts the image into binary form before feature computation. All 8-connected components of the binary image are then found. Image features of the segmented objects include number of objects in the image, Euler number of the image (the number of objects in the region -minus- the number of holes in those objects), average and variance of the non-zero pixels per object, ratio of the largest object to the smallest object, average and variance of the object distances from the center of fluorescence (COF), and ratio of the distance of the furthest object from the COF to the distance of the closest object to the COF.The computation of edge related features is based on the image's Prewitt gradient [21]. This gradient based technique is used to detect horizontal and vertical edges in an image. Edge features may include mean, median, variance, and 8-bin histogram of the magnitude and the direction components. Additionally, total number of edge pixels, and direction homogeneity computed by the part of edge pixels present in the first two bins of the direction histogram are computed as edge features. The difference of the direction histogram bin at angle θ and θ+π is also computed that results in the difference of edge direction. This difference is obtained from the subtraction of the sum of bins 1 through 4 from the sum of bins 5 through 8. The differences along both directions are added for normalization.In this paper, we have employed the following five edge features:•Edge pixels areaDirection homogeneityDifference of the direction histogram binsRatio of the maximum to minimum intensities present in the 8-bin histogramRatio of the maximum to the next maximum intensities present in the 8-bin histogramHull features are computed using the binary convex hull of the input image [6]. These features include the fraction of the convex hull area occupied by protein fluorescence, the shape of the convex hull, and the convex hull eccentricity.Histogram of Oriented Gradients (HOG) is an effective feature extraction technique for object detection [22]. HOG descriptor is computationally efficient and robust to object variation such as scale, rotation, and translation. HOG descriptor is computed by dividing the whole image into cells, and then occurrences of edge orientations for each cell are counted in the form of a 1D histogram. The final feature space is constructed by combining these histogram entries. The complete theoretical and implementation details can be found in [22,23].An individual feature extraction technique may not extract all the essential information from an image required by a classifier to predict its class. In such cases, we combine different individual features to get hybrid features [24] that might enhance the prediction capability of a classifier. The performance of the proposed system is also reported using these hybrid features. Table 4 demonstrates the names, short names, and dimensions of hybrid feature models.In classiﬁcation tasks, on the basis of attribute values, instances are mapped onto various classes. In the field of computer vision, computational material, bioinformatics, and pattern recognition [25–27], numerous individual and ensemble machine learning algorithms have been developed for classification [1,4,13,25,28–30]. However, in this work, we utilized Random Forest and Rotation Forest based ensemble classifiers. The performance of these classifiers is to be investigated in the presence of unbalanced and large datasets. Both of these issues are addressed in this paper. First, we classified the unbalanced datasets using these two classifiers and then we assessed their performance on the oversampled balanced datasets. In addition, Random Forest and Rotation Forest classifiers made their final decisions on majority voting basis, which have enhanced the prediction accuracies of the system. Now, we provide brief details about these two classifiers as follows.Random Forest ensemble (RF) uses decision trees as base classifiers [24,25,31], which are developed from bootstrap samples of the dataset. Final decision is drawn by combining decisions of the individual trees through the majority voting scheme. The learning in RF ensemble is based on tree structure; therefore, it will be robust in the presence of erroneous features. RF ensemble classifier has been frequently used in the field of machine learning and bioinformatics [24,25]. Data balancing through the use of SMOTE technique results in larger size of datasets, which can be handled efficiently by RF ensemble.Rotation Forest (RotF) is an ensemble classifier generation technique [32], which uses decision tree as base learner. It utilizes Principal Component Analysis (PCA) based linear feature extraction strategy to rotate the training data around the feature axis. The attribute set is arbitrarily divided into K subsets and then PCA is applied to each of these K subsets. The order of all the principal components is preserved to ensure the availability of variability information in the data. In order to construct new attributes for the base classifier, K axis rotations must take place. This rotation will improve the diversity in the RotF ensemble since features are extracted for each base classifier. The accuracy is enhanced by preserving all the principal components. In addition, each base classifier is trained using the whole data to endorse high system performance.

@&#CONCLUSIONS@&#
