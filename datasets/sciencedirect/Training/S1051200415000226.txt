@&#MAIN-TITLE@&#
Camera model identification based on DCT coefficient statistics

@&#HIGHLIGHTS@&#
Camera model identification is addressed using hypothesis testing theory.The statistical performance of the proposed test is analytically established.The model of DCT coefficients is exploited in the proposed test.A novel camera fingerprint in the DCT domain is proposed.

@&#KEYPHRASES@&#
Digital forensics,Camera model identification,Hypothesis testing,Natural image model,Discrete cosine transform,

@&#ABSTRACT@&#
The goal of this paper is to design a statistical test for the camera model identification problem from JPEG images. The approach focuses on extracting information in Discrete Cosine Transform (DCT) domain. The main motivation is that the statistics of DCT coefficients change with different sensor noises combining with various in-camera processing algorithms. To accurately capture this information, this paper relies on the state-of-the-art model of DCT coefficients proposed in our previous work. The DCT coefficient model is characterized by two parameters(α,β). The parameters(c,d)that characterize the simplified relation between these parameters are exploited as camera fingerprint for camera model identification. The camera model identification problem is cast in the framework of hypothesis testing theory. In an ideal context where all model parameters are perfectly known, the Likelihood Ratio Test is presented and its performances are theoretically established. For a practical use, two Generalized Likelihood Ratio Tests are designed to deal with unknown model parameters such that they can meet a prescribed false alarm probability while ensuring a high detection performance. Numerical results on simulated and real JPEG images highlight the relevance of the proposed approach.

@&#INTRODUCTION@&#
The evolution of digital imaging technology and information technologies in the past decades has raised a number of information security challenges. Digital images can be easily edited, altered or falsified because of a large availability of low-cost image editing tools. Consequently, the credibility and trustworthiness of digital images have been eroded. Digital image forensics has emerged in response to the increasing need to verify the trustworthiness of digital images, see [1] and references therein for detailed introductions.One of the key problems of digital image forensics is identification of image origin, which aims to verify whether a given image was acquired by a specific camera and to determine camera models/brands as well as types of imaging mechanism (e.g. scanners, cell-phone cameras, or computer graphics). Basically, when an image is captured by a camera, it is stored with the metadata headers in the memory storage device, e.g. Exchangeable Image File (EXIF) and JPEG headers. Therefore, the simplest way to determine the source of the image is to read out directly from the metadata. However, such metadata headers are not always available in practice if the image is resaved in a different format or recompressed. Another problem is that the metadata headers are not reliable as they can be easily removed or modified using low-cost editing tools. Therefore, it is desirable for law enforcement agencies to build a set of reliable forensic tools for image origin identification.In general, there are two approaches to address the problem of image origin identification. Active forensics involves generating security measures such as digital watermarks [2] and digital signatures [3], referred to as extrinsic fingerprints, and adding to the image file. However, active forensics is of limited extent due to many strict constraints in its protocols. In order to solve the problem of image origin identification in its entirety, passive forensics evolved. In contrast to active forensics, passive forensics do not impose any constraint, nor require any prior information. Forensic analysts have only the suspect image at their disposal and must explore useful information from that image to gather forensic evidence and trace the acquisition device. The common philosophy in passive approach is to rely on inherent intrinsic fingerprints that the digital camera leaves in a given image. Passive forensics can be widely applied to millions of images that circulate daily on communication networks.This paper mainly addresses the identification origin of images acquired by digital cameras based on the passive approach. Technically, any method proposed for image origin identification must respond to the following questions:1.Which fingerprints are utilized for identification?How to extract these fingerprints accurately from a given image?Under which frameworks is the method designed to exploit the discriminability of fingerprints extracted from images captured by different sources22The term source refers to an individual camera instance, a camera model, or a camera brand.and to calculate the similarity of fingerprints extracted from images captured by the same source?In image origin identification problem, it is important to distinguish the problem of camera instance identification and the problem of camera model/brand identification. More specifically, fingerprints used for camera instance identification should capture individuality, especially cameras coming from the same brand and model. For camera model/brand identification, it is necessary to exploit fingerprints that are shared between cameras of the same model/brand but discriminative for different camera models/brands. Passive forensic methods proposed for those problems can be divided into two fundamental categories.Several fingerprints have been proposed in the literature. Sensor Pattern Noise (SPN), which is caused by imperfections during the manufacturing process and non-uniformity of photo-electronic conversion due to inhomogeneity of silicon wafers, is used in [4] for camera instance identification. Two main components of the SPN are the Fixed Pattern Noise (FPN) and the Photo-Response Non-Uniformity (PRNU) noise. The FPN is also used for camera instance identification in [5]. However it can be compensated by subtracting a dark frame from the output image, thus it is not a robust fingerprint and no longer used in recent works. The PRNU is directly exploited in [6–8]. Moreover, PRNU can be also used for camera model identification as proposed in [9] based on the assumption that the fingerprint obtained from images in the TIFF or JPEG format contains traces of post-acquisition processes (e.g. demosaicing) that carry information about the camera model. Other fingerprints include lens aberration [10], Color Filter Array (CFA) pattern and interpolation algorithms [11–14], JPEG compression [15], or collection of features [16–18], which are proposed for camera model/brand identification.In general, the image origin identification problem can be formulated into two frameworks: supervised classification [19] and hypothesis testing [20]. Compared with hypothesis testing framework, supervised classification framework is utilized by most existing methods in the literature to identify camera brands/models. Based on the above fingerprint, a forensic feature set is designed and employed in a machine learning algorithm, e.g. Support Vector Machines (SVM) [21]. Supervised classification framework involves three main drawbacks. To achieve high accuracy, this framework requires an expensive training stage that comprises many images with different characteristics (e.g. image content or camera settings) from various sources to represent a real-world situation, which might be unrealistic in practice. Another drawback is the choice of an appropriate forensic feature, which affects the detection performance of the classifier. Besides, the analytic establishment of statistical performances still remains an open problem in supervised classification framework [22].Even though these methods perform efficiently, they have been designed with a very limited exploitation of hypothesis testing theory and statistical image models. Therefore, their performance cannot be analytically established and is only evaluated based on a large image database. Moreover, in the operational context, it is crucial to warrant a prescribed false alarm probability. Our previous work [23] proposed the design of a statistical test within hypothesis testing framework based on the heteroscedastic noise model for camera model identification from RAW images. Recently, this work has been extended in [24] for camera model identification from JPEG images based on the generalized noise model [25]. The proposed tests can guarantee a false alarm probability while ensuring a high detection performance on a large database.The present paper addresses the problem of camera model identification from JPEG images. More specifically, this paper is based on the hypothesis testing theory, which is the same methodology proposed in our previous research papers [23,24,26]. The main difference between the approaches proposed in this paper and in our previous research papers [23,24] is that the previous research papers focus on noise statistics in the spatial domain while the present paper extracts this information in the Discrete Cosine Transform (DCT) domain. More specifically, the approach proposed in [23] relies on the heteroscedastic noise model (1) for camera model identification from RAW images. However, the RAW format is not always available in practice. Since most cameras nowadays export images in JPEG format, it is desirable to identify camera models from JPEG images. Another approach proposed in [24] is based on the generalized noise model (2) provided in [25]. By contrast, the present paper works in the DCT domain. The main motivation is that the statistics of DCT coefficients change with different sensor noises combining with various in-camera processing algorithms. Therefore, this paper exploits a state-of-the-art model of DCT coefficients [29] to accurately extract information at different frequencies and proposes a new fingerprint for camera model identification.The main contributions are the following:•This paper is based on the state-of-the-art statistical model of DCT coefficients [27–29] for fingerprint extraction. The parameters(c,d)that characterize the simplified linear relation between two parameters α andβ−1, which are specified in the proposed model of DCT coefficients, are exploited as camera fingerprint for camera model identification.Stating the camera model identification problem in hypothesis testing framework, the paper studies the optimal detector given by the Likelihood Ratio Test (LRT) in an ideal context where all model parameters are known. This optimal detector serves as an upper-boundary of any statistical test for the camera model identification problem.In the practical context, the model parameters are unknown. The paper proposes two Generalized Likelihood Ratio Tests (GLRTs) to deal with the difficulty of unknown parameters. The statistical performance of the GLRTs is analytically established. Moreover, the proposed GLRTs enable us to guarantee a prescribed false-alarm rate and the setting of decision threshold independently of the image content, which is crucial in an operational context. Numerical experiments also show that the loss of power of GLRTs compared with the LRT is negligible.The present paper is an extended version of our conference submission [26]. The conference version presents the LRT in the theoretical context and the first GLRT in the practical context dealing with unknown image parameters (i.e. unknown parameter α). This journal version provides more demonstrations such that the linear relation between α andβ−1(see Appendix A) and the methodology for estimation of camera fingerprint(c,d)in the practical context (see Section 3). Moreover, the journal version studies a more general scenario where the image parameters and camera parameters are unknown and fully develops the second GLRT for this scenario. More numerical experiments and case of studies are included in the present paper to highlight the relevance of the proposed approach.The paper is organized as follows. Section 2 presents the camera fingerprint that is further exploited for camera model identification. Section 3 designs an algorithm for camera fingerprint extraction in the DCT domain. Section 4 states the camera model identification problem in the framework of hypothesis testing theory and studies the LRT assuming that all model parameters are known in advance. Section 5 designs two GLRTs to address the difficulty of unknown parameters. Section 6 presents numerical results of two proposed GLRTs on simulated and real JPEG images. Finally, Section 7 concludes the paper.To design a camera fingerprint, it is vital to fully understand image characteristics during various stages of image processing pipeline and study image statistics. Image processing pipeline involves several steps from light capturing to image storage performed in a digital camera, see details about image processing pipeline in [30,27,29]. After measuring light intensity at each pixel, the RAW image is recorded by the image sensor. Then it goes through some typical post-acquisition processes, e.g. demosaicing, white-balancing and gamma correction, to render a full-color high-quality output image, referred to as TIFF image. JPEG compression can be also performed for ease of storage and transmission.The study of noise statistics in a natural image from RAW format to TIFF format was carried out in our previous work [25]. Firstly, the study starts from the heteroscedastic noise model proposed in [23], which is established by modeling various noise sources during RAW image acquisition [31]. The heteroscedastic noise model characterizes the RAW image more accurately than the Additive White Gaussian Noise (AWGN) model widely used in image processing since it takes into account the contribution of Poisson noise in the acquisition process. The heteroscedastic noise model is given as(1)xi∼N(μxi,aμxi+b),wherexidenotes a RAW pixel andμXdenotes the expectation of a random variable X. The parameters(a,b)was proposed in our previous work [23] as fingerprint for camera model identification from RAW images.Then, assuming the operations of demosaicing and white-balancing are linear, it is proposed to take into account the non-linear effect of gamma correction to develop a so-called generalized noise model, given as(2)σzi2=1γ2μzi2−2γ(a˜μziγ+b˜),wherezidenotes an output pixel,σX2denotes the variance of a random variable X, γ is the correction factor, and(a˜,b˜)differ from the parameters(a,b)due to the operations of demosaicing and white balancing. It is also shown in [25] that the generalized noise model is relevant to characterize JPEG images with moderate-to-high quality factors (QF≥70). More details of the generalized noise model are given in [25]. Similarly, the parameters(a˜,b˜,γ)are proposed in [24] as fingerprint to identify camera models from JPEG images.The next step in image processing pipeline is JPEG compression that involves transforming the TIFF image into the DCT domain. To capture statistics of DCT coefficients accurately, it is necessary to study the model of DCT coefficients. Based on the assumption that the pixels are identically distributed within8×8block, our previous work [27–29] has recently proposed a novel model of DCT coefficients, given by(3)fI(u)=2π(|u|β2)α−12βαΓ(α)Kα−12(|u|2β),wherefXdenotes the probability density function (pdf) with respect to a random variable X, α is a positive shape parameter, β is a positive scale parameter,Γ(⋅)denotes the gamma function andKν(x)denotes the modified Bessel function [32, chap. 5.5]. The proposed model of DCT coefficients outperforms the Laplacian, Generalized Gaussian, and Generalized Gamma models, see more details in [29]. The parameters(α,β)can be estimated following the Maximum Likelihood (ML) approach as proposed in [29].Since the parameters(a˜,b˜,γ)also contain information about camera model, after transforming into DCT domain, this information is expanded over different frequencies. Therefore, it is proposed to establish the relation between the parameters(a˜,b˜,γ)and(α,β)to capture such information in the DCT domain. For the sake of simplification, this relation is given by(4)β−1=cα+d,where the parameters(c,d)depend on(a˜,b˜,γ)(see more details in Appendix A). To illustrate the linear relation (4), we conduct an experiment on uniform synthetic images. These images are randomly generated using an original image and the generalized noise model (2) with parametersa˜=0.1,b˜=2,γ=2.2. The original image is created such that the intensities in each8×8block is identical, which aims to ensure the assumption used for the statistical study of DCT coefficients in [29]. Then, those simulated images are transformed into DCT domain. The parameters(α,β)at each frequency are estimated. Relation (4) on those simulated images is illustrated in Fig. 1. It should be noted that in such uniform images the energy is located equally at different frequencies. Therefore, the parameters(α,β)are identical among different frequencies.Relation (4) suggests that the parameters(c,d)can also be used for camera model identification. It can be noted that while relations (1) and (2) characterize the non-stationarity of noise in the spatial domain, relation (4) characterizes this property in the DCT domain. The relation (4) can capture the difference of noise statistics in natural images taken by different camera models. Moreover, the linearity in relation (4) can facilitate the estimation of the parameters(c,d). Therefore, this paper proposes the exploitation of the parameters(c,d)as new fingerprint for camera model identification.An important requirement when using parameters(c,d)as camera fingerprint is that they should be invariant to image content. Furthermore, to guarantee the above mathematical framework, it is necessary to work on homogeneous blocks. These considerations are addressed in this section.Because of heterogeneity and noise non-stationarity in a natural image, the energy tends to be more located in lower frequencies. Consequently, DCT coefficients at different frequencies do not share the same parameters(α,β)and(c,d). Therefore, the estimation of parameters(α,β)and(c,d)should be performed on each frequency separately. In this paper it is proposed to arrange DCT coefficients into 64 vectors of coefficients according to the zig-zag order. LetIk=(Ik,1,…,Ik,N)withk∈{1,…,64}, be the vector of length N that contains coefficients at the frequency k. The coefficients(I1,i,…,I64,i)are in the same block. Analogously, let denote the parameters(αk,βk)and(ck,dk)with respect to the AC coefficientsIk.The proposed algorithm for estimation of parameters(ck,dk)consists of three fundamental steps: image denoising, homogeneous block detection, and Least-Squares (LS) estimation [33]. Image denoising step aims to attenuate the impact of image content. The detection of homogeneous blocks is performed subsequently to provide appropriate sample data for parameter estimation. The LS approach is applied straightforwardly as the relation (4) is linear.Let Z be a two-dimensional matrix representing a natural image. To remove the image content, a denoising filterDis employed so that the residual image W is given by(5)W=Z−D(Z).If Z is a color image, the denoising filterDis performed on each color component, then three residual components are combined into one residual image using the usual conversion from RGB to grayscale(6)W=0.2989Wr+0.587Wg+0.114Wb,whereWr,Wg, andWbare respectively residuals of red, green, and blue component. The residual image W is then transformed into the DCT domain(7)I=DCT(W),where I is the image of DCT coefficients of the residual image W.For homogeneous block detection, this paper proposes the calculation of the standard deviation of each block and compare it with a threshold λ. The median of absolute deviations (MAD), which is considered as a robust estimator of standard deviation [34], is utilized to calculate the standard deviation of each block. Instead of calculating the standard deviation in the spatial domain where the pixels are correlated, it is proposed in this paper to calculate it in the DCT domain because of the decorrelation property of a DCT operation [35]. Moreover, since DCT is an orthogonal transformation, in an ideal case where the block is homogeneous and the pixels are statistically independent, the standard deviation in the spatial domain should be the same as the one in the DCT domain. The standard deviation of block i in the DCT domain is calculated as(8)sˆi=1.4826⋅MAD(I2,i,…,I64,i).In a homogeneous block, the values of AC coefficients should be closed to each other. Therefore, only AC coefficients are used in the calculation of standard deviationsˆi. The DC coefficientI1,iis excluded since it represents a weighted sum of pixel values. Block i is selected if the standard deviationsˆiis smaller than the threshold λ. The number of selected homogeneous blocks is denoted asNb.Suppose that L couples(αˆk,l,βˆk,l),l∈{1,…,L}are available, the LS estimates of the parameters(ck,dk)are given by(9)(cˆkdˆk)=(HkTHk)−1HkTυkwithHk=(αˆk,11⋮⋮αˆk,L1)andυk=(βˆk,1−1⋮βˆk,L−1),whereHkTandHk−1denote respectively the transpose and inverse of the matrixHk. The LS estimates(cˆk,dˆk)are unbiased and asymptotically equivalent to ML estimates in large samples [33].As shown above, the LS approach requires several couples(αk,βk)for estimation of parameters(ck,dk). One can collect L images and estimate a couple(αk,l,βk,l)from all homogeneous blocks of each image following the ML approach [29]. However, from the practical point of view, it is necessary to estimate the parameters(ck,dk)from a single image. This is accomplished by randomly extracting a subset ofnbhomogeneous blocks fromNbblocks, then performing the ML estimation of parameters(αk,l,βk,l)on this subset.When the image content is removed perfectly, the parameters(ck,dk)remain identical for images with different image contents. However, in practice, due to the fact that the perfect denoising filterDis difficult to obtain, the DCT coefficients at low frequencies are still affected by image content. Meanwhile, the coefficients at high frequencies contain mostly noises because of the energy compaction property of the DCT operation. Thus they are more relevant to exploit for camera model identification. Fig. 2shows the linear relation (4) at frequency(8,8)of natural JPEG images taken by Canon Ixus 70 and Nikon D200 camera models. It should be noted that each point(α,β)in Fig. 2 corresponds to one image. Fig. 2 involves the JPEG images with different imaged scenes, different camera settings, different devices per model, and different environmental conditions. This indicates that the parameters(ck,dk)remain similar under those conditions.Moreover, for the camera model identification problem, it is necessary to verify the discriminability of parameters(ck,dk)for different camera models and their similarity between different devices of the same camera model. Fig. 3shows the parameters(ck,dk)estimated from JPEG images at frequency(8,8)for different camera models. Furthermore, Fig. 4shows the parameters(ck,dk)estimated from JPEG images at frequency(8,8)for different devices of two Canon Ixus 70 and Nikon D200 models. Therefore, the parameters(ck,dk)can be exploited as camera fingerprint to identify camera models.Let us analyze two camera modelsS0andS1. Each camera modelSj,j∈{0,1}, is characterized by the parameters(ck,j,dk,j),k∈{1,…,K}, where K is the number of usable frequencies for camera model identification. For obvious reasons, it is assumed that(ck,0,dk,0)≠(ck,1,dk,1). In a binary hypothesis testing, the inspected image Z is either acquired by camera modelS0or camera modelS1. The goal of the test is to decide between two hypotheses defined by∀k∈{1,…,K},∀i∈{1,…,Nb}(10){H0={Ik,i∼Pθk,0,βk,0−1=ck,0αk+dk,0}H1={Ik,i∼Pθk,1,βk,1−1=ck,1αk+dk,1},wherePθk,j,θk,j=(αk,ck,j,dk,j), denotes the probability distribution of DCT coefficientsIk,iunder hypothesisHj. As previously explained, this paper focuses on designing a test guarantees of a prescribed false-alarm probability. Hence, letKα0={δ:supθ0⁡PH0[δ(Z)=H1]≤α0}be the class of tests where the false alarm probability is upper-bounded by the prescribed rateα0. Hereθ0=(θ1,0,…,θK,0)is the vector containing all parameters,PHj[E]stands for the probability of event E under hypothesisHj,j∈{0,1}, and the supremum overθhas to be understood as whatever the model parameters might be. Among all the tests in the classKα0, it is aimed at finding a test δ which maximizes the power function, defined by the correct detection probability:βδ=PH1[δ(Z)=H1].The problem (10) highlights three fundamental difficulties of the camera model identification. First, even when all model parameters(αk,ck,j,dk,j)are known, the most powerful test, namely the LRT, has never been studied in the literature. The second difficulty concerns unknown parametersαkin practice. Finally, the camera parameters(ck,j,dk,j)are also unknown, thus the hypothesisHjbecomes composite.Suppose that the camera modelS0is available, thus forensic analysts can have access to its characteristics, or its fingerprints, i.e. its camera parameters(ck,0,dk,0)can be known. Therefore, they can make a decision by checking whether the image under investigation Z contains the fingerprint(ck,0,dk,0). It is proposed to solve the problem (10) when the alternative hypothesisH1is composite, i.e. the camera parameters(ck,1,dk,1)are unknown. It can be noted that a test that maximizes the correct detection probability whatever(ck,1,dk,1)is might scarcely exist [20]. The main goal of this paper is to study the LRT and to design the GLRTs to address the second and third difficulties.When all model parameters are known, by virtue of the Neyman-Pearson lemma [20, Theorem 3.2.1], the most powerful testδ⁎solving the problem (10) is the LRT given by the following decision rule(11)δ⁎(Z)={H0ifΛ(Z)=∑k=1K∑i=1NbΛ(Ik,i)<τ⁎H1ifΛ(Z)=∑k=1K∑i=1NbΛ(Ik,i)≥τ⁎where the decision thresholdτ⁎is the solution of the equation(12)PH0[Λ(Z)≥τ⁎]=α0to ensure that the LRT is in the classKα0and the LRΛ(Ik,i)is defined as(13)Λ(Ik,i)=log⁡Pθk,1[Ik,i]Pθk,0[Ik,i],assuming that the DCT coefficients are statistically independent. From (3), it can be noted that the expression of the LRΛ(Ik,i)is difficult to exploit for subsequent stages, e.g. the design of the GLRT and analytic establishment of its statistical performance. Therefore it is proposed to simplify the LRΛ(Ik,i)to facilitate the study in a manner that does not cause any loss of optimality.Using the Laplace's approximation [36,37] (see more details in Appendix B), the functionfI(u)can be approximated as(14)fI(u)≈|u|α−1(2β)α2Γ(α)exp⁡(−|u|2β).Consequently, the LRΛ(Ik,i)can be simplified as(15)Λ(Ik,i)=log⁡|Ik,i|αk−1(2βk,1)αk2Γ(αk)exp⁡(−|Ik,i|2βk,1)|Ik,i|αk−1(2βk,0)αk2Γ(αk)exp⁡(−|Ik,i|2βk,0)=αk2log⁡βk,1−1βk,0−1−2|Ik,i|(βk,1−1−βk,0−1).It should be noted that other polynomial expansions for the modified Bessel functionKν(x)are provided in [32], so a polynomial approximation offI(u)can be derived. However, those approximations are not considered in this paper. The main advantage of the Laplace's approximation (14) is to provide an approximation of the form of exponential family function, which allows us to simplify the expression of the LRΛ(Ik,i). The approximating function (14) is used only for simplification of the LR. The estimation of parameters(αk,βk)is always based on the exact function (3).In order to analytically establish the statistical performance of the LRT, it is necessary to characterize the statistical distribution of the LRΛ(Z)under each hypothesisHj. To this end, it is proposed to rely on the Lindeberg Central Limit Theorem (CLT) [20, Theorem 11.2.5] that requires the calculation of the expectation and variance ofΛ(Ik,i).Proposition 1Under hypothesisHj, the first two moments of the LRΛ(Ik,i)are given by(16)mk,j≜EHj[Λ(Ik,i)]=αk2log⁡βk,1−1βk,0−1−2πβk,j12Γ(αk+12)Γ(αk)(βk,1−1−βk,0−1)(17)vk,j≜VarHj[Λ(Ik,i)]=2(βk,1−1−βk,0−1)2(αkβk,j−2βk,jπΓ2(αk+12)Γ2(αk)),whereEHj[⋅]andVarHj[⋅]respectively denote the mathematical expectation and variance under hypothesisHj.ProofProof of Proposition 1 is given in Appendix C.  □By virtue of Lindeberg CLT, the statistical distribution of the LRΛ(Z)under hypothesisHjis derived as(18)Λ(Z)→dN(mj,vj),where the notation→ddenotes the convergence in distribution and the expectationmjand variancevjare given by(19)mj=∑k=1K∑i=1NbEHj[Λ(Ik,i)]=∑k=1KNbmk,j(20)vj=∑k=1K∑i=1NbVarHj[Λ(Ik,i)]=∑k=1KNbvk,j.Since a natural image is heterogeneous, it is proposed to normalize the LRΛ(Z)in order to set the decision threshold independently of the camera parameters. The normalized LR is defined byΛ⋆(Z)=Λ(Z)−m0v0. Accordingly, the corresponding LRTδ⋆is rewritten as follows(21)δ⋆(Z)={H0ifΛ⋆(Z)<τ⋆H1ifΛ⋆(Z)≥τ⋆where the decision thresholdτ⋆is the solution of the equationPH0[Λ⋆(Z)≥τ⋆]=α0. The decision thresholdτ⋆and the powerβδ⋆are given in the following theorem.Theorem 1In an ideal context where all the model parameters(αk,ck,j,dk,j)are known precisely, the decision threshold and the power function of the LRTδ⋆are given by(22)τ⋆=Φ−1(1−α0)(23)βδ⋆=1−Φ(m0−m1+τ⋆v0v1),whereΦ(⋅)andΦ−1(⋅)denotes respectively the cumulative distribution function of the standard Gaussian random variable and its inverse.The test powerβδ⋆serves as an upper-boundary of any statistical test for the camera model identification problem. The testδ⋆enables a warranty of a prescribed false alarm rate and maximizes the detection probability. Since its statistical performance is analytically established, it can provide an analytically predictable result for any false alarm probabilityα0.The scenario studied in the LRT may not be realistic because the parameters(αk,ck,1,dk,1)are unknown in practice. This section designs two GLRTs to deal with unknown parameters. It is proposed to replace unknown parameters by their ML estimates in the LRΛ(Ik,i)(15).In this subsection it is assumed that the camera parameters(ck,j,dk,j)are known and we only deal with unknown nuisance parametersαk. By replacing unknown parameterαkby its ML estimateαˆkin the LRΛ(Ik,i)(15) (see more details about ML estimation of parameters(αk,βk)in [29]), the Generalized Likelihood Ratio (GLR)Λˆ1(Ik,i)can be given by(24)Λˆ1(Ik,i)=αˆk2log⁡ck,1αˆk+dk,1ck,0αˆk+dk,0−2|Ik,i|(ck,1αˆk+dk,1−ck,0αˆk+dk,0).The ML estimateαˆkis asymptotically consistent [20], i.e. it asymptotically converges in probability to its true value:αˆk→pαk. Therefore, from the Slutsky's theorem [20, Theorem 11.2.11], the statistical distribution of the GLRΛˆ1(Z)=∑k=1K∑i=1NbΛˆ1(Ik,i)under each hypothesisHjcan be approximated as(25)Λˆ1(Z)→dN(mj,vj),where the expectationmjand variancevjare given in (19) and (20), respectively.Similarly, the normalized GLRΛˆ1⋆(Z)is defined byΛˆ1⋆(Z)=Λˆ1(Z)−m0v0. However, the expectationm0and variancev0cannot be defined in practice since the parametersαkare unknown. Therefore, this paper proposes the replacement ofαkbyαˆkin (19) and (20) to obtain the estimates ofm0andv0, denotedmˆ0andvˆ0. The normalized GLRΛˆ1⋆(Z)can be given in practice asΛˆ1⋆(Z)=Λˆ1(Z)−mˆ0vˆ0. Since the estimatesmˆ0andvˆ0are consistent, it also follows from Slutsky's theorem that(26){Λˆ1⋆(Z)→dN(0,1)underH0,Λˆ1⋆(Z)→dN(m1−m0v0,v1v0)underH1.Finally, the GLRTδˆ1⋆based on the normalized GLRΛˆ1⋆(Z)is given by(27)δˆ1⋆(Z)={H0ifΛˆ1⋆(Z)<τˆ1⋆H1ifΛˆ1⋆(Z)≥τˆ1⋆where the decision thresholdτˆ1⋆is the solution of the equationPH0[Λˆ1⋆(Z)≥τˆ1⋆]=α0. From (26), the decision threshold and the power of the GLRTδˆ1⋆can be accordingly defined as in Theorem 1.Before designing the GLRT, the LS estimation of camera parameters(ck,1,dk,1)is performed on the inspected image Z; see Section 3. The LS estimates(cˆk,1,dˆk,1)are asymptotically equivalent to ML estimates in large samples [33]. Moreover, they are unbiased and follow the asymptotic bivariate Gaussian distribution(28)(cˆk,1dˆk,1)∼N((ck,1dk,1),(σck,12σck,1dk,1σck,1dk,1σdk,12)),whereσck,12,σdk,12,σck,1dk,1denote the variance ofcˆk,1, variance ofdˆk,1, and covariance betweencˆk,1anddˆk,1, respectively (see also discussions in Section 6.1 for this covariance matrix). The parameters(ck,1,dk,1)would characterize an unknown camera model. It is required to take into account the variability of LS estimates(cˆk,1,dˆk,1)in the analytic establishment of performance of the GLRT.By replacing unknown parameters(αk,ck,1,dk,1)by(αˆk,cˆk,1,dˆk,1)in the LRΛ(Ik,i)(15), the GLRΛˆ2(Ik,i)is given by(29)Λˆ2(Ik,i)=αˆk2log⁡cˆk,1αˆk+dˆk,1ck,0αˆk+dk,0−2|Ik,i|(cˆk,1αˆk+dˆk,1−ck,0αˆk+dk,0).Proposition 2Under hypothesisHj, from the Delta method[20, Theorem 11.2.14], the first two moments of the GLRΛˆ2(Ik,i)can be approximated as(30)EHj[Λˆ2(Ik,i)]=mk,j(31)VarHj[Λˆ2(Ik,i)]=vk,j+βk,12αk(αk+2)4(αk2σck,12+σdk,12+2αkσck,1dk,1).ProofProof of Proposition 2 is given in Appendix D.  □For brevity, let us denotev˜k,j=VarHj[Λˆ2(Ik,i)]. It can be noted that the second term in (31) aims to take into account the variability of LS estimates(cˆk,1,dˆk,1). By virtue of Lindeberg CLT, the GLRΛˆ2(Z)=∑k=1K∑i=1NbΛˆ2(Ik,i)follows the Gaussian distribution under each hypothesisHj(32)Λˆ2(Z)→dN(mj,v˜j),where the expectationmjis given in (19) and the variancev˜jis defined as(33)v˜j=∑k=1KNbv˜k,j.Finally, the GLRTδˆ2⋆based on the normalized GLRΛˆ2⋆(Z)=Λˆ2(Z)−mˆ0v˜ˆ0is written as(34)δˆ2⋆(Z)={H0ifΛˆ2⋆(Z)<τˆ2⋆H1ifΛˆ2⋆(Z)≥τˆ2⋆where the decision thresholdτˆ2⋆is the solution of the equationPH0[Λˆ2⋆(Z)≥τˆ2⋆]=α0andmˆ0andv˜ˆ0are estimates ofm0andv˜0by replacing unknown parameters(αk,ck,1,dk,1)by(αˆk,cˆk,1,dˆk,1)in (19) and (33), respectively. From Slutsky's theorem [20, Theorem 11.2.11], the decision threshold and the power of the GLRTδˆ2⋆are given in the following theorem.Theorem 2When the imageZis tested against the known camera modelS0characterized by the parameters(ck,0,dk,0), the decision threshold and the power of the GLRTδˆ2⋆are given by(35)τˆ2⋆=Φ−1(1−α0)(36)βδˆ2⋆=1−Φ(m0−m1+τˆ2⋆v˜0v˜1).The statistical performance of the proposed GLRTsδˆ1⋆andδˆ2⋆is analytically provided. Moreover, they allow us to warrant a prescribed false alarm rate and set the decision threshold independently of camera parameters (see (22) and (35)). It is worth noting that the GLRT dealing with unknown parametersαkwhile the camera parameters(ck,j,dk,j)are known can be interpreted as a closed hypothesis testing since the decision is made only between two known camera modelsS0andS1. Meanwhile, the GLRT dealing with unknown camera parameters(ck,1,dk,1)becomes an open hypothesis testing showing whether the given image is acquired by camera modelS0or not. The given image can be acquired by an unknown camera model. Therefore, two proposed tests can be straightforwardly applied, depending on the requirements of the operational context.In this paper, the wavelet-based denoising filter proposed in [38,4] is employed to suppress image content because of its relative accuracy and computational efficiency. Besides, the selection of homogeneous blocks requires an appropriate threshold λ. This threshold should be fixed independently of image content. The threshold λ is set atλ=0.5.The implementation of the GLRTδˆ2⋆requires knowing the covariance matrix of LS estimates(cˆk,1,dˆk,1). However, the ML estimates(αˆk,βˆk)are solved numerically, which causes a difficulty of defining their statistical properties. Thus it seems impossible to establish the covariance matrix of(cˆk,dˆk)analytically. To overcome this difficulty, it is proposed to estimate the parameters(ck,dk)on each image from 50 images taken by the camera modelS0since this camera model is assumed to be available. Then the empirical covariance matrix can be calculated from previous couples(cˆk,dˆk). Strictly speaking, this is the covariance matrix characterizing the variability of the camera parameters(ck,0,dk,0). By doing so, it is expected that the parameters(cˆk,1,dˆk,1)will fall into the neighborhood of(ck,0,dk,0), namely that the inspected image Z is acquired by the camera modelS0. This leads us to exploit this covariance matrix in the implementation of the GLRTδˆ2⋆. This step is also performed in the test with real images.The detection performance of proposed tests is first theoretically studied on a simulated database. Suppose that the camera modelsS0andS1are characterized by the parameters(c0,d0)=(11.8,−3.5)and(c1,d1)=(13.5,−4.5), respectively. These parameters correspond to frequency(8,8)of JPEG images taken by Canon Ixus 70 and Nikon D200 camera models in the Dresden image database [39], respectively (see Fig. 2). They are used to randomly generate 5000 vectors of 1024 and 4096 coefficients underH0andH1. Because this paper proposes the simplification of the LRΛ(Ik,i)to facilitate the study, it is desirable to compare the detection performance of the LRT based on the approximated LR with the one based on the exact LR. The expectation and variance of the exact LR are calculated numerically. Moreover, it is necessary to compare the detection performance of the proposed GLRTs with the LRT since the GLRTs utilize ML estimates of unknown parameters, which may cause a loss of power. Fig. 5and Fig. 6show the detection performance of all proposed tests for 1024 and 4096 coefficients, respectively. For clarity, only regions of interest are illustrated in the figures. It is worth noting that the loss of power between the theoretical LRT and approximating LRT is negligible. Besides, a small loss of power is revealed between the GLRTs and LRT due to the estimation of unknown parameters. Nevertheless this loss of power decreases when the number of coefficients increases. It can also be noted that the loss of power between two GLRTsδˆ1⋆andδˆ2⋆is negligible, i.e. the variability of estimates(cˆk,1,dˆk,1)are accurately taken into account in GLRTδˆ2⋆. It should be noted that the test power rises with the increment of the number of coefficients. From 214 coefficients, the power function of all proposed tests in this experiment is perfect (i.e.βδ=1) for any false alarm rateα0.Moreover, it is desirable to study the detection performance of the proposed tests on simulated images that follow the image processing pipeline as described in Section 2. To this end, suppose the camera modelsS0andS1are characterized by the parameters(a˜0,b˜0,γ0)=(0.1,2,2.2)and(a˜1,b˜1,γ1)=(0.2,2,2.2). These parameters are used together with the reference image lena to generate randomly 5000 images underH0andH1. The simulated images are then compressed with quality factor of 90 and 75. The detection performance of the proposed GLRTs for 1024 coefficients at frequency(8,8)extracted randomly from those simulated images is shown in Fig. 7. As expected, a small loss of power is revealed with the decline of the quality factor.It is important to remember that the proposed GLRTs are designed in the framework of hypothesis testing theory where the reference camera parameters(ck,0,dk,0)under hypothesisH0are assumed to be known in advance. Therefore, those parameters need to be defined accurately in practice. To this end, the parameters(ck,dk)are estimated on 50 images of the camera modelS0and the reference parameter(ck,0,dk,0)is calculated as the average of previous estimates(cˆk,dˆk). Evidently, using more images will get a better estimate but it is also less realistic. The number of 50 is a good trade-off.To highlight the relevance of the proposed GLRTs, two Canon Ixus 70 and Nikon D200 camera models of the Dresden image database [39] are chosen to conduct experiments. The Canon Ixus 70 and Nikon D200 cameras are respectively set atH0andH1. All available JPEG images of each camera model are used in this experiment. The reference camera parameters are estimated as discussed above. The Fig. 8shows the detection performance of the GLRTsδˆ1⋆andδˆ2⋆for 1024 and 4096 coefficients extracted randomly at frequency(8,8)of natural JPEG images taken by Canon Ixus 70 and Nikon D200 camera models. We can note a similar behavior to the detection performance on simulated database. Besides, there is a small loss of power between the two GLRTs because different estimates(cˆk,1,dˆk,1)used in the design of the GLRTδˆ2⋆are still influenced by image content. Nevertheless, this loss of power also decreases when the number of coefficients increases. Besides, Fig. 9illustrates detection performance of the GLRTδˆ2⋆for 4096 coefficients randomly extracted at different frequencies. It can be noted that the detection performance decreases with the reverse zig-zag order.Meanwhile, Fig. 10shows the comparison between the theoretical and empirical false alarm probability, which are plotted as a function of decision threshold τ. The two proposed GLRTsδˆ1⋆andδˆ2⋆show an ability to guarantee a prescribed false alarm rate, even though there is a slight difference in some cases (typicallyα0≤10−3) due to the influence of image content and the inaccuracy of the CLT for modeling tails.Experiments are then conducted on a large database to verify the efficiency of the proposed approach. The public Dresden image database [39] is chosen in our experiments. Technical specifications of the cameras are shown in Table 1, see more details in [39]. The database covers different devices per camera model, different imaged scenes, different camera settings and different environmental conditions. All images are acquired with the highest available JPEG quality setting and maximum available resolution. For each camera model, the set contains 50 images per camera model for estimation of reference camera parameters and 100 images per device for testing, which are randomly selected from the Dresden database.Firstly, GLRTδˆ2⋆is used to verify whether a given image is acquired by the camera model of interest. The decision thresholdτˆ2⋆is given by the Theorem 2 corresponding to the false alarm rateα0=10−5. If the normalized GLRΛˆ2⋆(Z)is smaller than the decision thresholdτˆ2⋆, the hypothesisH0is accepted, i.e. the given image is taken from the camera model of interest. On the contrary, hypothesisH1is accepted. It is proposed to use the last 21 high frequencies for the test. The detection performance of the testδˆ2⋆is shown in Table 2. In this table, each camera model is considered as hypothesisH0(row) and all images (column) are tested againstH0. The values in the table indicate the percentage of images that are detected taken by the camera modelH0. The table in this paper is not used in the same way as in the classification in which the sum for each class yields 100%. The inspected image is brought into the binary testing of the known camera modelH0against the others, thus the sum of a class may not yield 100%. It could lead to a scenario that an image is declared taken by at least two camera models. It can be noted from Table 2 that the incorrect detection in some groups of camera models, such as (C,N1,Pe), (F,Ro), and (K,N3), is important. This may be justified due to a similarity in JPEG compression scheme used in the camera. To deal with this scenario, the first GLRTδˆ1⋆could be performed on the camera models of conflict to better classify the inspected images.This paper also presents the SVM-based detector for comparison, which has been already performed in [39] on the Dresden database using 46 different features to capture characteristics of different camera components of a digital camera. The feature set includes three main groups: color features describing the color reproduction of a camera model, wavelet statistics quantifying sensor noise and image quality metrics measuring sharpness and noise. The reader is referred to [40] for more details of this feature set. The detection performance of this SVM-based detector is shown in Table 3. The proposed detectorδˆ2⋆is almost equivalent to the SVM-based detector in terms of average correct detection performance but the misclassification of the former is more severe. The PRNU-based detector [7] is also performed in this experiment. This PRNU-based detector is only conducted on one device per model. Its detection performance is shown in Table 4. Overall, the two proposed detectors provide an equivalent detection performance compared with the other ones in the literature, but the latter cannot guarantee a prescribed false alarm probability like the proposed detectors.Remark 1The present paper proposes exploiting the state-of-the-ar model of DCT coefficients provided in [29]. This model is not only more accurate than prior-art models in the literature, but also is the only one that is mathematically justified based on a statistical analysis of images' properties according to the image processing pipeline, as provided in [29]. Therefore, relying on the proposed model allows us to accurately capture statistics of DCT coefficients as well as to analyze camera fingerprint that can be exploited for camera model identification.

@&#CONCLUSIONS@&#
