@&#MAIN-TITLE@&#
Sense-level subjectivity in a multilingual setting

@&#HIGHLIGHTS@&#
A manual annotation study shows that approximately 90% of the senses retain their subjectivity across languages.Subjectivity labeling discrepancy is caused by differences between languages in sense usage and lexicon granularity.Subjectivity information from multiple languages can be employed jointly to label new senses in a given language.Bootstrapping multilingual sense level subjectivity labeling outperforms monolingual learning.

@&#KEYPHRASES@&#
Sentiment and text classification,Multilingual subjectivity analysis,Sense level subjectivity,

@&#ABSTRACT@&#
Recent research on English word sense subjectivity has shown that the subjective aspect of an entity is a characteristic that is better delineated at the sense level, instead of the traditional word level. In this paper, we seek to explore whether senses aligned across languages exhibit this trait consistently, and if this is the case, we investigate how this property can be leveraged in an automatic fashion. We first conduct a manual annotation study to gauge whether the subjectivity trait of a sense can be robustly transferred across language boundaries. An automatic framework is then introduced that is able to predict subjectivity labeling for unseen senses using either cross-lingual or multilingual training enhanced with bootstrapping. We show that the multilingual model consistently outperforms the cross-lingual one, with an accuracy of over 73% across all iterations.

@&#INTRODUCTION@&#
Sentiment and subjectivity analysis seeks to automatically identify opinions, beliefs, speculations, emotions, sentiments and other private states in natural text (Wiebe et al., 2005). Quirk et al. (1985) define a private state as a state that does not lend itself to an objective external validation, or in other words “a person may be observed to assert that God exists, but not to believe that God exists. Belief is in this sense private.” (p. 1181). In the field of natural language processing, researchers have used the term subjectivity analysis to denote identifying private states in text, namely separating objective from subjective instances, while sentiment or polarity analysis further refines the subjective text into positive, negative or neutral.Sentiment and subjectivity analysis has stemmed into a prolific area of research, mainly due to the fact that numerous text processing applications stand to gain from incorporating sentiment dimensions into their models, including automatic expressive text-to-speech synthesis (Alm et al., 1990), tracking sentiment timelines in on-line forums and news (Balog et al., 2006; Lloyd et al., 2005), and mining opinions from product reviews (Hu and Liu, 2004). In many natural language processing tasks, subjectivity and sentiment classification has been used as a first phase filtering to generate more viable data. Research that benefited from this additional layering ranges from question answering (Yu and Hatzivassiloglou, 2003), to conversation summarization (Carenini et al., 2008), text semantic analysis (Wiebe and Mihalcea, 2006; Esuli and Sebastiani, 2006) and lexical substitution (Su and Markert, 2010).In experiments carried out on English, Wiebe and Mihalcea (2006) have shown that the most robust subjectivity delineation occurs at sense and not at word level. Following this more fine-grained perspective, Esuli and Sebastiani (2006) and Andreevskaia and Bergler (2006) have proposed methods to embed sense-level automatic sentiment annotations (objective/neutral, negative and positive) over the English WordNet structure (Miller, 1995), using its relationships (synonymy, antonymy, meronymy, etc.). On the other hand, noticing the scarcity of hand crafted sense-level subjectivity/polarity lexica, Markert and Su (2008) have explored ways to infer them from data annotated at either the word or sentence level.Sense-level subjectivity and cross-lingual subjectivity and sentiment analysis have received considerable attentions in recent years, yet our paper explores the area that lies at the intersection of these two topics. To our knowledge, this area has not been formally investigated, and while the techniques may be similar to those applied in sentiment and subjectivity analysis at the sentence or the review level, our work explores the more difficult task of sense-level subjectivity, which also involves deep semantic aspects of the language. The manual annotation study we performed for this task (cross-lingual sense-level subjectivity annotations), as well as the methods we proposed (cross-lingual and multilingual learning using dictionaries in multiple languages) are novel to our knowledge.This work seeks to answer the following questions. First, for word senses aligned across languages, is their subjectivity content consistent, or in other words, does a subjective sense in language A map to a subjective sense in language B (and similarly for an objective sense)? Second, can we employ a multilingual framework that can automatically discover new subjective/objective senses starting with a limited amount of annotated data? We seek to answer the first question by conducting a manual annotation study in Section 2. For the second question, we propose two models (see Section 3), one cross-lingual and one multilingual, which are able to simultaneously use information extracted from several languages when making subjectivity sense-level predictions.To answer the first question, we conduct a case study in subjectivity sense transfer across languages, focusing on English and Romanian.We consider a sense-level aligned multilingual resource such as WordNet. WordNet (Miller, 1995) was first developed for English, and is a lexical resource that maintains semantic relationships between basic units of meaning, or synsets. A synset groups together senses of different words that share a very similar meaning. Due to its particular usefulness for NLP tasks, numerous independent non-commercial projects11http://www.globalwordnet.org/gwa/wordnet_table.htm.have replicated its structure in over 50 languages, while maintaining alignment with the original WordNet and allowing for sense-level mapping across languages.In our experiments we use the English (Miller, 1995) and the Romanian (Tufis et al., 2006) versions of WordNet, which contain 117,65922http://wordnet.princeton.edu/wordnet/man/wnstats.7WN.html.and 58,72533http://www.racai.ro/wnbrowser/Help.aspx.synsets, respectively. Many of these are aligned at the synset level.In order to infuse subjectivity information into the model, we use sense-level manually annotated subjectivity data from (Wiebe and Mihalcea, 2006) and (Akkaya et al., 2009), as well as a list of 48 additional words, for a total of 128 words accounting for 580 English senses (with an average polysemy of 4.6). Their equivalent into Romanian is also obtained by traversing the WordNet structure. A native speaker of Romanian (who participated in previous subjectivity annotations studies) was asked to annotate the Romanian data, by being presented with the gloss (definition) and the synset of each given sense from the Romanian WordNet. The annotator agreement between the English and the Romanian subjectivity labels ranged from 84% (for the Akkaya et al. (2009) dataset) to 90% (for the Wiebe and Mihalcea (2006) dataset). When excluding senses that had both subjective and objective uses in either of the languages, the annotator agreement becomes 87%, with Cohen's κ=0.74 for the first dataset, and 94.7% with κ=0.88 for the second one, indicating good to very good agreement. These findings support the hypothesis that the subjectivity of a sense maintains itself across language boundaries. Furthermore, they indicate that senses aligned across languages may represent vessels of subjectivity transfer into other languages, thus providing an anchor to generating subjectivity annotated lexica in a target language. Since not all senses have the same subjectivity label across languages, we describe below in more detail the various scenarios we encountered.In the remainder of this article, English is abbreviated as En and Romanian as Ro.There were several examples where the subjectivity label changed between languages. For instance, the fourth sense of the noun argument, as listed in Table 1, is marked in the English data as subjective, since it represents an essay where “you take a position on a debatable topic and attempt to change readers’ minds about it. The more persuasive your argumentative essay, the more likely readers will be to concede your points and grant your conclusion.”44Writing literary arguments –http://academic.cengage.com/resource_uploads/downloads/1413022812_59427.pdf.Instead, the Romanian gloss and synset for this word denote a “direct summary,” which by definition disallows the expression of any subjective perspective. Therefore, in Romanian this sense is objective.A similar scenario is posed by the fourth sense of the verb decide (also listed in Table 1). While the English sense is labeled as objective, as its meaning denotes causality, the Romanian sense directly implies a subjective decision, and therefore acquires a subjective label.In several cases, the same sense in WordNet may have both subjective and objective meanings. To exemplify, let us consider the first sense of the adjective free, as shown in Table 1. While the English sense can have both subjective and objective uses, the Romanian sense is subjective, as it further enforces the constraint that the context of the word should refer to people.From these examples, we notice that a perfect sense to sense mapping among languages is impossible, as a particular sense may denote additional meanings and uses in one language compared to another. However, in our annotation study about 90% of the senses maintained their subjective meaning across languages, implying that this information can be leveraged in an automatic fashion to provide additional clues for the subjectivity labeling of unseen senses.In our previous work exploring the ability of multilingual models to better capture subjectivity at the sentence level (Banea et al., 2010), which was conducted on six languages, namely English, Arabic, German, Romanian, Spanish and French, we noticed that simultaneously considering features originating from multiple languages results in error rate reductions ranging from 5% for English to 15% for Arabic, as compared to the monolingual model baselines. The experiments also showed that the maximum improvement is achieved when the multilingual model is built over the expanded feature space comprising the vocabulary of all six languages. This observation became the catalyst for the work presented here, as it seeks to explore whether the task of sense level subjectivity classification can also benefit from being modeled with a multilingual perspective in mind, and compare it to a monolingual baseline.Thus, in this section we explore ways to use a multilingual learning mechanism to automatically predict the subjectivity of a word sense. We experiment with two methods. The first one is based on cross-lingual training using monolingual feature spaces. This method uses the output of individually trained monolingual classifiers paired with a set of constraints to reach an overall decision. The second method introduces a learner that is trained on a multilingual feature space, and whose decision is automatically inferred. Ultimately, we seek to understand whether, under this scenario, a classifier is able to make a better decision by having access to the entire feature set.We start by considering the intersection of the Romanian and English WordNets, so that we can have equivalent senses (including their definitions and synsets) in both languages. We were thus able to obtain 19,124 unique synsets. We then generate vectorial representations for two monolingual models (one in English and one in Romanian), and one multilingual model (comprising both Romanian and English features). These are composed of uni-grams extracted from a synset and its gloss, appended with a binary weight. The synset is stripped of any sense identifying features55We only keep the lemma for the words in the synset when we add them to the vectorial representation of a given sense; we do not include any information on the part-of-speech or sense number.in order not to favor the classifier. To exemplify, we provide below the sparse vector representation of the fourth sense of the noun argument (see Table 1 for its original gloss and synset in English and Romanian):English vector: <aen1, summary 1, of 1, the 1, subject 1, or 1, plot 1, literary 1, work 1, play 1, movie 1, editor 1, added 1, argument 1, to 1, poem 1>Romanian vector: <redare 1, prezentare 1, pe 1, scurt 1, scrisa 1, orala 1, aro1, ideilor 1, unei 1, lucrari 1, ale 1, expuneri 1, etc 1, rezumat 1>Multilingual vector: <aen1, summary 1, of 1, the 1, subject 1, or 1, plot 1, literary 1, work 1, play 1, movie 1, editor 1, added 1, argument 1, to 1, poem 1, redare 1, prezentare 1, pe 1, scurt 1, scrisa 1, orala 1, aro1, ideilor 1, unei 1, lucrari 1, ale 1, expuneri 1, etc 1, rezumat 1>Traditionally, the subjectivity content of an entity, be it word, sentence, or document, is regarded as a binary decision (either subjective or objective). In this paper, we mimic its occurrence in natural language, and we represent it on a continuum, where 0 is at one end of the spectrum and represents full objectivity, while 1 is at the other end, and denotes full subjectivity. We establish a zone of 0.4 from the left and right of our spectrum, and we consider the synsets whose scores fall in these ranges as objective (if below 0.4) or subjective (if above 0.6). This allows us to have a buffer zone of 0.2 (above 0.4 and below 0.6), which contains samples that may be considered too vague to be clearly labeled for subjectivity. Because a typical classification approach does not lend itself to being employed under a gradient subjectivity content paradigm (unless mapping the numeric scores to nominal buckets), in order to run the experiments we use a linear regression algorithm,66Included with the Weka machine learning distribution (Hall et al., 2009).which extrapolates from the data and infers a subjectivity score for every synset.The first method focuses on cross-lingual learning (CL). Based on the co-training algorithm proposed by Wan (2008), we consider the manually annotated training data in each of the languages individually, and we learn two monolingual regression algorithms (see Fig. 1, (1)77The numbers or symbols between parentheses refer to the indices included in the figures.). For every sample in the unlabeled data (2), we allow the machine learners to individually predict a score (3), and at every iteration maintain two sets with the top n most confident objective and subjective examples, respectively. These sets are ordered based on the average of the predictions coming from the English and Romanian learners, which must also fall within the same range (i.e. both below 0.4 or both above 0.6), thus signaling that both learners agree. As long as the sets are not empty (4), at the next iteration the monolingual English vectors and the aligned Romanian vectors are added to their respective training set (+) appended with their adjusted subjectivity score, and removed from their respective test set (−); otherwise the bootstrapping terminates.Although the method differs from the original co-training mechanism proposed by Blum and Mitchell (1998), since it enforces that both predictions fall in the same range before adding the samples to the next train set, we believe this was a necessary modification given the extremely short contexts available, and the low accuracy attained by the English and Romanian classifiers by themselves (67.66% and 70.28%, respectively). Through this additional agreement constraint, we ensure that only samples that have a high probability of being labeled correctly are added, therefore reducing noise propagation across iterations. At the same time, we are able to learn new information from the features co-occurring with those that participated in the previous classification step.The second method employs multilingual learning (ML) (see Fig. 2). We create a multilingual feature space based on the model proposed in Banea et al. (2010). As mentioned earlier, in that work, instead of using the monolingual feature vectors to represent the sentences, we used a multilingual space combinining features drawn from up to six languages. Similarly, here, instead of using the monolingual vectors described above, we enrich the feature space by merging together two aligned vector space representations (see the multilingual vector example above), thus allowing the system to simultaneously use both Romanian and English features in order to decide the subjectivity of a given sense. We train the multilingual learner (1) and for every sample in the testing set (2), we predict a subjectivity score (3). As we did for the cross-lingual learning setup, at every iteration we select the most confident n objective and n subjective samples (4), and add them to the training set (+), while discarding them from the test set for the next iteration (−).For both methods, the score of the new samples that are added to the train set during each iteration is mapped to either 0 (objective) or 1 (subjective), the determination being made based on the range in which the original score fell (i.e. if an instance initially received a score of 0.3, since it falls in the objective range its adjusted score will be 0, and the instance will be added to the next iteration training set with this score). This allows all the training samples to equally participate in the decision process at every iteration, instead of their novel features being penalized due to being absent from the initial training step. For our experiments, we conducted 20 iterations for both methods and added 50 subjective and 50 objective samples at each iteration. Additional iterations would have been possible, but we decided to stop given the drop in performance of the Romanian learner embedded in the cross-lingual model.We use the manually annotated data described in Section 2, from which we remove 20 examples that were labeled as both objective and subjective in either English or Romanian, since they could confuse the classifiers and prevent them from making strong predictions.88We did not remove those synsets that had conflicting labels across languages.We then split the labeled data into three subsets to enable three-fold cross validation. As these subsets are biased towards the objective class in a ratio of 2:1, we randomly discard about half of the objective samples to be included in the fold for each training set in order to obtain balanced training folds, thus allowing our experiments to not be skewed towards any of the classes. Note that we did not balance the test sets. Also, throughout every iteration the class balance is maintained as an equal number of subjective and objective samples are added to the next train set. Each fold comprises an initial train set of 328 samples and a test set of 164 samples, on which the evaluations for the respective fold are carried out. In order to generate a running test set for each fold, we append the remaining unlabeled WordNet senses to each test fold (see Figs. 1 and 2, (2)). These running test sets are used to provide the learners with novel samples (and features) throughout the bootstrapping process. We only used 328 training examples because there is a very limited amount of subjectivity data manually annotated at the sense level in English, which moreover, needs to be mirrored in the Romanian WordNet, which has far less coverage (and thus lower overlap) vis-à-vis the English WordNet. A similar issue will be encountered by most (if not all) of the WordNets developed for languages other than English. From the 580 manually annotated English senses, approximately 500 had an equivalent in the Romanian WordNet. For this reason, in our experiments we used all the training examples we could have for both our methods as well as the baseline, that would also allow for the existence of a small test set so that we can evaluate our results.

@&#CONCLUSIONS@&#
