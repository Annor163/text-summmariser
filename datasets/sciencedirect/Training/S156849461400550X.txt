@&#MAIN-TITLE@&#
Opposition versus randomness in binary spaces

@&#HIGHLIGHTS@&#
We introduce the concept of opposition-based learning in binary spaces.It is proven that utilizing random numbers and their opposite is beneficial in evolutionary algorithms.Opposite numbers are applied to accelerate the convergence rate of Binary Gravitational Search Algorithm (BGSA).The results show that OBGSA possesses superior performance in accuracy as compared to the BGSA.

@&#KEYPHRASES@&#
Opposition-based learning,Binary spaces,Randomness,Binary gravitational search algorithm,

@&#ABSTRACT@&#
Evolutionary algorithms start with an initial population vector, which is randomly generated when no preliminary knowledge about the solution is available. Recently, it has been claimed that in solving continuous domain optimization problems, the simultaneous consideration of randomness and opposition is more effective than pure randomness. In this paper it is mathematically proven that this scheme, called opposition-based learning, also does well in binary spaces. The proposed binary opposition-based scheme can be embedded inside many binary population-based algorithms. We applied it to accelerate the convergence rate of binary gravitational search algorithm (BGSA) as an application. The experimental results and mathematical proofs confirm each other.

@&#INTRODUCTION@&#
Many real-world problems such as feature selection and dimensionality reduction, data mining, unit commitment, and cell formation, are formulated as optimization problems with binary variables. In addition, problems defined in the real space may be considered in the binary space since binary coding provides some of the algorithms with a lot of flexibility by decomposing each real value and allowing the implicit parallelism to take advantage of this. In the past decades, different kinds of nature-inspired evolutionary optimization algorithms have been designed and applied to solve binary-encoded optimization problems, e.g., binary differential evolution [1], binary particle swarm optimization [2], binary ant colony optimization [3], genetic algorithm [4], and binary gravitational search algorithm [5]. This algorithms start with an initial population vector, which is randomly generated when no preliminary knowledge about the solution space is available. The computation time is directly related to the distance of initial guesses from the optimal solution.We can improve our chance to start with a closer (fitter) solution by checking the opposite solution simultaneously [6]. The concept of opposition-based learning (OBL) was originally introduced by Tizhoosh [6]. It has been utilized in a wide range of learning and optimization fields. OBL was first proposed as a machine intelligence scheme for reinforcement learning [6–8]. Afterward, it has been employed to enhance soft computing methods such as fuzzy systems [9,10] and artificial neural networks [11–14]. OBL has proven to be an effective method for solving optimization problems by combining it with differential evolution [15–17], particle swarm optimization [18–21], ant colony optimization [22,23], simulated annealing [24], and gravitational search algorithm [25] in a wide range of fields from image processing [10,26,27] to system identification [28,29]. It has been also applied to assist evolutionary algorithms in solving discrete and combinatorial optimization problems [30]. It has been shown that in terms of convergence speed, utilizing random numbers and their opposite is more beneficial than using the pure randomness to generate initial estimates in absence of a prior knowledge about the solution of a continuous domain optimization problem [31]. In this paper, it will be mathematically proven that this fact can be extended to binary optimization problems. It is noticeable that the proofs in [31] are not suitable for binary spaces.Binary gravitational search algorithm, introduced by Rashedi et al., is a stochastic search algorithm based on the law of gravity and mass interactions [5]. In BGSA, the search agents are a collection of masses which interact with each other based on the Newtonian theory that postulates every particle in the universe attracts every other particle with a force that is directly proportional to the product of their masses and inversely proportional to the square of the distance between them. BGSA is able to optimize both real and binary optimization problems. The effectiveness of this algorithm in solving a set of nonlinear benchmark functions has been proven [5].This paper is organized as follows. In Section 2 the concept of opposition-based learning in continuous and binary spaces are introduced. It also covers the theorems and proofs corresponding to opposition in binary domains. Section 3 provides a brief review of binary gravitational search algorithm. The outline of opposition-based binary gravitational search algorithm is presented in Section 4. Then, an experimental study is given in Section 5, where OBL is applied to accelerate the convergence rate of BGSA as an application and the performance of the new algorithm will be evaluated on nonlinear benchmark functions. Finally, a conclusion is given in Section 6.In this section, first, the concept of opposition-based learning in the continuous space is reviewed. Afterward, it will be defined in binary domains and its corresponding theorems will be proven.Definition 1Let x∈[a, b] be a real number. The opposite number, denoted byx⌣, is defined byx⌣=a+b−x.This definition can be extended to higher dimensions [6].Definition 2Let X(x1, x2, …, xd) be a point in d-dimensional space, where x1, x2, …, xdare real numbers and xi∈[ai, bi], i=1, 2, …, d. The opposite point of X is denoted byX⌣(x⌣1,x⌣2,…,x⌣d)wherex⌣i=ai+bi−xi,i=1,2,…,d.Although, opposition-based learning was created for accelerating a continuous search space, it can be applied alongside binary space. In this section we prove that a binary opposite point is more likely to be closer to the solution than a random one. To follow this purpose, first we modify the previous definitions as follows.Definition 3Let x∈{0, 1}. The opposite number, denoted byx⌣, is defined byx⌣=1−x.Similarly, this definition can be extended to higher dimensions.Definition 4Let X(x1, x2, …, xd) be a point in d-dimensional binary space S={0, 1}dwhere xi∈{0, 1}, i=1, 2, …, d. The opposite point of X is denoted byX⌣(x⌣1,x⌣2,…,x⌣d)wherex⌣i=1−xi,i=1,2,…,d.In this paper, the distance between two points is computed based on the Hamming distance which is defined as follows.Definition 5The Hamming distance between two binary vectors x, y∈{0, 1}dis defined byNow, we are going to prove our theorems.Theorem 1Every point X(x1, x2, …, xd) in the d-dimensional binary space with xi∈{0, 1}, i=1, 2, …, d, has a unique opposite pointX⌣(x⌣1,x⌣2,…,x⌣d)defined byx⌣i=1−xi,i=1,2,…,d.Let bothX⌣(x⌣1,x⌣2,…,x⌣d)andX′(x′1,x′2,…,x′d)be the opposite points of X(x1, x2, …, xd). According to the definition of opposite point, for each i, 1≤i≤d, we havex⌣i=1−xiandx′i=1−xiand sox⌣i=x′i.This means thatX⌣=X′.□Let X(x1, x2, …, xd) be a point in d-dimensional binary space, where xi∈{0, 1}, i=1, 2, …, d, andX⌣(x⌣1,x⌣2,…,x⌣d)is its opposite point. Then, for each Y∈{0, 1}dwe haveHD(X,Y)=d−HD(X⌣,Y).where HD denotes the Hamming distance.It is clear that for each x∈{0, 1}, x2=x. So,HD(X,Y)=∑i=1dx(i)⊕y(i)=∑i=1dxi−yi=∑i=1d1−x⌣i−yi=∑i=1d(1−x⌣i−yi)2=∑i=1d(x⌣i2−2x⌣i+yi2−2yi+2x⌣iyi+1).Sincex⌣i=x⌣i2andyi=yi2, we have∑i=1d(x⌣i2−2x⌣i+yi2−2yi+2x⌣iyi+1)=∑i=1d(−x⌣i2−yi2+2x⌣iyi+1)=∑i=1d(1−(x⌣i−yi)2)=d−∑i=1dx⌣i−yi=d−HD(X⌣,Y).Hence,HD(X,Y)=d−HD(X⌣,Y). □Let X(x1, x2, …xd) be a candidate solution for a binary optimization problem. Assume f(X) is a fitness function which is used to measure candidates optimality. According to opposite point definition,X⌣(x⌣1,x⌣2,…,x⌣d)is the opposite point of X(x1, x2, …, xd). Now, iff(X⌣)≥f(X),then point X can be replaced withX⌣.Otherwise, we continue with X Hence, the point and its opposite are evaluated simultaneously to continue with the fitter one.When evaluating a solution X to a given problem, simultaneously computing its opposite solution will provide another chance for finding a candidate solution closer to the global optimum. The following theorem answers this significant question: why is an opposite number more effective than an independent random number.Theorem 3Assume y=f(X) is an arbitrary function with at least one solution atXs(xs1,xs2,…,xsd),xsi∈{0,1},i=1,2,…,d. Suppose X(x1, x2, …, xd) andXr(xr1,xr2,…,xrd)are the first and second random guesses in the solution space respectively. Then(2)(i)Pr(X⌣,Xs≤min{X,Xs,Xr,Xs})>Pr(Xr,Xs≤min{X,Xs,X⌣,Xs),where d≠1. In other words, The probability that the distance betweenX⌣and Xsbe less than or equal to the distance between {X, Xr} and Xsis more than the probability that the distance between Xrand Xsbe less than or equal to the distance between{X,X⌣}and Xs. In fact,X⌣is more probable than Xrto be the closest to Xsamong{X,X⌣,Xr}. Equality holds in Eq. (2) when d=1.(3)(ii)Pr(min{X,Xs,X⌣,Xs}≤min{X,Xs,Xr,Xs})>Pr(min{X,Xs,Xr,Xs}≤min{X,Xs,X⌣,Xs}),i.e., applying random numbers and their opposites is more useful than using pure randomness. In other words,{X,X⌣}is more probable than {X, Xr} to be closer to Xs..denotes the Hamming distance.It is clear that the number of all possible situations for each ofX,X⌣,Xrand Xs is equal to 2d. Thus, the number of all possible events that they form in relation with each other is 23dNotice that the place ofX⌣depends on X's position. First, suppose that d is even and d≥2. LetNxrandNx⌣be the number of events in which XrandX⌣are the closest to the solution Xsamong{X,X⌣,Xr}respectively. They can be computed as follows:(4)Nxr=∑i=0d/2∑j=id−i2ddidj,(5)Nx⌣=∑i=0d/2∑j=id2ddidj.In Eq. (4), 2dis equal to the number of positions that Xsis likely to meet; In fact2ddidjaccounts for the number of events in whichXr,Xs=i,X,Xs=jandX⌣,Xs=d−j.From Theorem 2, we can say that the distance of either X orX⌣from Xsis always less than or equal to d/2. So, Xrcannot be the closest to XsunlessXr,Xs≤d/2. Therefore,i≤d/2.SinceNxris the number of events in whichXr,Xs≤X,XsandXr,Xs≤X⌣,Xs, we must have i≤j and i≤d−j and so i≤j≤d−i.In Eq. (5),diis the number of positions where the distance of X andX⌣from Xsare equal to d−i and i respectively, anddjdepicts the number of all possible situations for Xrin which Xris in a distance of j from Xs. The range of i assures thatX⌣,Xs≤X,Xs. Since in this case,X⌣,Xs≤Xr,Xs,j changes between i and d.Now we show thatNx⌣>Nxr. Based on the fact that∑j=id2ddidjand∑j=id−i2ddidjare equal for i=0, we haveNx⌣−Nxr=∑i=0d/2∑j=id2ddidj−∑i=0d/2∑j=id−i2ddidj=∑i=1d/2∑j=d−i+1d2ddidj>0.This obviously means thatNx⌣>Nxr.In order to complete our proof, suppose thatPxrandPx⌣are the probability of XrandX⌣being the closest to the solution Xsamong{X,X⌣,Xr}respectively, i.e.,Pxr=Pr(Xr,Xs≤min{X,Xs,X⌣,Xs),andPx⌣=Pr(X⌣,Xs≤min{X,Xs,Xr,Xs}).We havePxr=Nxr/23d,andPx⌣=Nx⌣/23d. SinceNx⌣>Nxr, we conclude thatPx⌣>Pxr.In other words, we havePr(X⌣,Xs≤min{X,Xs,Xr,Xs})>Pr(Xr,Xs≤min{X,Xs,X⌣,Xs).which proves (i) when d is even.Now suppose that d is odd. In this case, we have(6)Nxr=∑i=0(d−1)/2∑j=id−i2ddidj,(7)Nx⌣=∑i=0(d−1)/2∑j=id2ddidj.The only difference between (4) and (6) and also (5) and (7) is in the range of i. According to Theorem 2, the distance of either X orX⌣from Xsis always less than or equal to (d−1)/2; so Xrcannot be the closest to XsunlessXr,Xs≤(d−1)/2. Likewise, it is possible forX⌣to be the closest to Xsonly whenX⌣,Xs≤(d−1)/2. Hence, in Eqs. (6) and (7) we have 0≤i≤(d−1)/2.For d=1, it is clear thatNxr=Nx⌣and soPx⌣=Pxr. When d≠1, we haveNx⌣−Nxr=∑i=0(d−1)/2∑j=id2ddidj−∑i=0(d−1)/2∑j=id−i2ddidj=∑i=1(d−1)/2∑j=d−i+1ddj>0.Therefore, in this case,Nx⌣>Nxrand soPx⌣>Pxr. In other words,Pr(X⌣,Xs≤min{X,Xs,Xr,Xs})>(Xr,Xs≤min{X,Xs,X⌣,Xs),This completes the proof of (i).To proof (ii), first, suppose that d is even. LetNxr∩xbe the number of events in which both Xrand X are the closest to Xs,Nx⌣∩xbe the number of events in which bothX⌣and X are the closest to XsandPxr∩xandPx⌣∩xbe the probability of these events respectively. We have(8)Nxr∩x=∑i=0d/22ddi2,(9)Nx⌣∩x=∑i=d/2d2ddd/2di.In Eq. (8),2ddi2accounts for the number of events in whichXr,Xs=X,Xs=i,X⌣,Xs=d−i,and Xrand X are the nearest ones to Xsamong{X,X⌣,Xr}. In fact,0≤i≤d/2guarantees that i≤d−i and soXr,Xs≤X⌣,XsandX,Xs≤X⌣,Xs.In Eq. (9),2ddd/2diis equal to the number of events in whichX,Xs=X⌣,Xs=d/2, andXr,Xs=iwhere d/2≤i≤d. According to Theorem 2,X,XsandX⌣,Xsare equal to each other if and only if both of them are equal to d/2.Now, we can compute the probability of{X,X⌣}and also {X, Xr} to be the closest to Xsas follows. Notice that Px, which is the probability of X to be the best of all among{X,X⌣,Xr}, is computed the same asPx⌣andPx=Px⌣.(10)Pr(min{X,Xs,X⌣,Xs}≤min{X,Xs,Xr,Xs})=Px+Px⌣−Px⌣∩x=(1/23d)2∑i=0d/2∑j=id2ddidj−∑i=d/2d2ddd/2di.Similarly we have(11)Pr(min{X,Xs,Xr,Xs}≤min{X,Xs,X⌣,Xs})=Px+Pxr−Pxr∩x=(1/23d)∑i=0d/2∑j=id2ddidj+∑i=0d/2∑j=id−i2ddidj−∑i=0d/22ddi2.Subtracting the relation (11) from (10), we obtainPr(min{X,Xs,X⌣,Xs}≤min{X,Xs,Xr,Xs})−Pr(min{X,Xs,Xr,Xs}≤min{X,Xs,X⌣,Xs})=(1/23d)2∑i=0d/2∑j=id2ddidj−∑i=d/2d2ddd/2di−(1/23d)∑i=0d/2∑j=id2ddidj+∑i=0d/2∑j=id−i2ddidj−∑i=0d/22ddi2=(1/22d)∑i=0d/2∑j=iddidj−∑i=d/2ddd/2di−∑i=0d/2∑j=id−ididj+∑i=0d/2di2=(1/22d)∑i=1d/2∑j=d−i+1ddidj+∑i=0d/2di2−∑i=0d/2dd/2di=(1/22d)∑i=1d/2∑j=0i−1didj+∑i=0d/2di2−∑i=0d/2dd/2di=(1/22d)∑i=0(d/2)−1∑j=0ididj>0,this means thatPr(min{X,Xs,X⌣,Xs}≤min{X,Xs,Xr,Xs})>Pr(min{X,Xs,Xr,Xs}≤min{X,Xs,X⌣,Xs}).Now suppose that d is odd. In this case we haveNxr∩x=∑i=0(d−1)/22ddi2.Based on Theorem 2, we haveX,Xs≠X⌣,Xsif d is odd. HenceNx⌣∩x=0; soPr(min{X,Xs,X⌣,Xs}≤min{X,Xs,Xr,Xs})=Px+Px⌣−Px⌣∩x=(1/23d)2∑i=0(d−1)/2∑j=id2ddidj.andPr(min{X,Xs,Xr,Xs}≤min{X,Xs,X⌣,Xs})=Px+Pxr−Pxr∩x=(1/23d)∑i=0(d−1)/2∑j=id2ddidj+∑i=0(d−1)/2∑j=id−i2ddidj−∑i=0(d−1)/22ddi2,so, we havePr(min{X,Xs,X⌣,Xs}≤min{X,Xs,Xr,Xs})−Pr(min{X,Xs,Xr,Xs}≤min{X,Xs,X⌣,Xs})=(1/23d)2∑i=0(d−1)/2∑j=id2ddidj−∑i=0(d−1)/2∑j=id2ddidj−∑i=0(d−1)/2∑j=id−i2ddidj+∑i=0(d−1)/22ddi2=(1/22d)∑i=0(d−1)/2∑j=0ididj>0.HencePr(min{X,Xs,X⌣,Xs}≤min{X,Xs,Xr,Xs})>Pr(min{X,Xs,Xr,Xs}≤min{X,Xs,X⌣,Xs}).□BGSA is one of the newest heuristic algorithms that has been inspired by the law of motion [5]. In BGSA, Newtonian laws of gravity are applied to find the optimum solution by a set of agents. Agents are considered as objects and their performance is measured by their masses. All these objects attract each other by the gravity force, and this force causes a movement of all objects toward the objects with heavier masses. In fact, BGSA could be considered as an isolated system of masses.Many optimization problems are set in binary space. BGSA was introduced in Ref. [5] for binary encoded optimization problems. In BGSA, every dimension can take only 0 or 1 and Moving through a dimension means that the corresponding variable value changes from 0 to 1 or vice versa. The results obtained in Ref. [5] confirm that BGSA is a suitable tool for optimization problems.To describe the BGSA, consider a system with N agents (masses) in which the position of the ith mass is defined as follows:Xi=(xi1,…,xik,…,xid),i=1,2,…,N.wherexikis the position of ith agent in the kth dimension, and d is the dimension of the search space. It is noted that the positions of masses correspond to the solutions of the problem.Based on [32], the mass of each agent is calculated after computing current population's fitness as follows:Mi(t)=(fiti(t)−worst(t))∑j=1N(fitj(t)−worst(t)),where Mi(t) and fiti(t) represent the mass and the fitness value of the agent i at iteration t, and, worst(t) is defined as follows (for a minimization problem):worst(t)=maxj∈{1,…,N}fitj(t).To compute the acceleration of an agent, total forces from a set of heavier masses that apply on an agent should be considered based on the law of gravity (Eq. (12)), which is followed by calculation of agent acceleration using the law of motion (Eq. (13)).(12)Fik(t)=∑j∈kbest,j≠irandjG(t)Mj(t)Mi(t)Rij(t)+ε(xjk(t)−xik(t)),(13)aik(t)=Fik(t)Mi(t)=∑j∈kbest,j≠irandjG(t)Mj(t)Rij(t)+ε(xjk−xik),where randiand randjare two uniformly distributed random numbers in the interval [0,1], ɛ is a small value, Rij(t) is the Euclidean distance between two agents i and j, defined asRij(t)=Xi(t),Xj(t)2and kbest is the set of first B agents with the best fitness value and biggest mass, which is a function of time, initialized to B0 and decreased over time. The gravitational constant, G, is a decreasing function of time where it is set to G0 at the beginning and is decreased towards zero with lapse of time.Afterwards, velocity is updated according to Eq. (14):(14)vi(k(t+1)=randi×vik(t)+aik(t).The modified version of Eq. (14) is as follows [33]:(15)vi(k(t+1)=randi×vik(t)+aik(t)+c×rand×(gbest−xik(t)),where gbest is all particles’ best position in their history and c is weighting factor.BGSA considers the new position to be 1 or 0 with a probability. The probability of changing the value ofxikfrom 0 to 1 or vice versa depends onvik. In Ref. [5], functionS(vik)is defined as a transfer function to map the velocity to the probability of position updating (Eq. (16)).(16)S(vik(t))=tanh(vik(t)).OnceS(vid(t))is calculated, the agents will move according to Eq. (17).(17)ifrand<S(vik(t+1))xik(t+1)=complement(xik(t))elsexik(t+1)=xik(t).To achieve a good converge rate,vikmust be limited into a good bound,vik(t)<vmax.vmax was set to 6 in Ref. [5].In this section, opposition-based learning is utilized to enhance the performance of binary gravitational search algorithm. Our proposed algorithm, which is called OBGSA, uses opposite numbers during population initialization and also for generating new populations during the evolutionary process to accelerate the convergence rate of the BGSA. The outline of OBGSA is described as follows:Step 1(Random initialization) Generate a random population with N masses (P0).(Opposition based population initialization) Calculate the opposite of initial population (OP0). Then, evaluate the fitness of each agent and its opposite and select N fittest individuals from the set {P0,OP0}.Update G(t), best(t), worst(t)and Mi(t) for i=1,…,N.Calculate the total forces in different directions.Calculate accelerations and velocities according to Eqs. (13) and (15).Update agents’ position according to Eq. (17) and generate new population P.Calculate Opposite Population (OP), evaluate the fitness of each agent in {P,OP} and select N fittest ones.Repeat steps 2–7 until the stopping criterion is met.To evaluate the performance of OBGSA, it is applied to 22 minimization and 2 maximization benchmark functions and the results are compared with those of BGSA. Tables 1–4list these functions and the ranges of their search space [34]. In these tables, m is the dimension of the function and Sis a subset of Rm. In the case of an m dimensional search space, each individual consists of m variables with each variable encoded as a bit string. In the case of continuous valued variables, variable should be mapped to a d-dimensional bit vector φ:R→{0, 1}d. The range of each continuous variable needs to be restricted to a finite range. Using standard binary decoding, each continuous variable is encoded using a fixed length bit string. For example, if x∈[xmin, xmax] needs to be converted to a 30-bit representation, the following conversion can be used:(2030−1)(x−xmin)/(xmax−xmin).The minimum value of the functions of Tables 1 and 2 are zero, except for F13 which has a minimum value of −418.9829×m. A detailed description of the functions of Table 3 is given in Appendix. Functions in Table 4, Max-Ones and Royal-Road, are maximization binary problems. These functions are described only in binary space. The maximum values of these functions are m and m/8 respectively.For both algorithms, the population size is set to 50 (N=50) in all cases. For functions of Tables 1 and 2, dimension is 5 (m=5). 15 bits have been used to represent each continuous variable. Therefore, for each continuous function the dimension of each agent is m×15. Number of generations is 500 for the functions of Tables 1–4. The results are averaged over 25 independent runs and the average, median and standard deviations of the best solutions are reported in Tables 5–8.OBL has an apparent effect on accelerating the convergence rate of GSA. Obviously, after converging to the optimal solution, the efficiency of the opposite solutions may decrease. Hence, we compute the number of the times the opposite solutions are used instead of candidate solutions for the first one hundred iterations. These numbers are also averaged over 25 independent runs. The minimum, the first quartile, the median, the third quartile, and the maximum average number of applying opposite numbers in iterations are presented in Table 9.In both algorithms in iteration t, G is set as followsG(t)=G0e−α(t/T),where G0 and α are set to 100 and 20 respectively and T is the total number of iterations.Furthermore, B0 is set to N (total number of agents) and is decreased linearly to 1.Results of applying BGSA and OBGSA to the benchmark functions are represented in Tables 5–8. From these results we can observe that OBGSA achieves better results on almost all cases and especially significantly improves the results on function 1, 3, 6, 15, 20 and 23. Also, the good convergence rate of OBGSA could be concluded from Figs. 1–4. They show the progress of the average best-so-far solution over 25 independent runs. According to these figures, OBGSA tends to find the global optimum faster than BGSA and hence OBGSA has more potential than BGSA to search space. Finally, the results of Table 9 confirm the usefulness of applying opposite numbers during evolutionary process.

@&#CONCLUSIONS@&#
