@&#MAIN-TITLE@&#
Special Genetic Identification Algorithm with smoothing in the frequency domain

@&#HIGHLIGHTS@&#
We extended our identification with a smoothing technique in frequency domain.We identify nominal parameters of a PT1-system and a real robot for test purpose.We compare the computation cost, accuracy and precision with a standard algorithm.Smoothing in frequency domain decreases the computational cost.Smoothing in frequency domain increases the accuracy and precision.

@&#KEYPHRASES@&#
Genetic algorithm,Identification,Frequency domain,Multibody simulation,Smoothing technique,Tripod robot,

@&#ABSTRACT@&#
Due to the increase in speed and lightweight construction, modern robots vibrate significantly during motion. Thus, accurate mechanical modeling and detailed controller behavior is essential for accurate path planning and control design of robots. For the suppression of undesired vibrations detailed models are used to develop robust controllers. Least square identification methods require deep insight in the analytical equations and thus are not very suitable for identification of different highly nonlinear robot models. Recently, we presented our genetic parameter identification in Brussels, Ludwig and Gerstmayr (2011). It minimizes the error of measured and simulated quantities. Highly efficient models in the multibody system tool HOTINT lead to short computational times for various simulations with different parameters. The simulation models can easily be assembled by engineers without a detailed knowledge of the underlying multibody system. As drawback of genetic optimization, many sub-minima were detected. Many simulations were required for the determination of the global minimum. Our current approach was to extend our previous algorithm. Measured and simulated quantities are transformed into the frequency domain. In contrast to previous work, Ludwig and Gerstmayr (2013), amplitude spectra of measured and simulated quantities are smoothed prior to the L2-norm computation. The presented method is tested using small scale test problems as well as real robots. Smoothing in the frequency domain leads to a smaller number of simulations needed for obtaining higher accuracy. It turns out that the presented algorithm is more accurate and precise than a standard algorithm and reduces the computational cost.

@&#INTRODUCTION@&#
The investigation of undesirable oscillations which occur during the complex motions of industrial robots using only measurement data is a difficult task. Some of the possible reasons for derivations of planned trajectories are the limitations of drive torque, motor current or voltage. Some other reasons are excitations of the Eigenfrequencies during the motion of the robot (as a result of the physical parameters of the mechanical components as well as the electrical parts e.g. the controller circuit). Mathematical models of the coupled electrical and mechanical system are required to get a deep insight into the physics and the source of the oscillations as well as derivations with respect to the planned path. At this point, it must be emphasised that only the use of the original robot controller software and the correct physical parameters lead to accurate models. An overview of a real robot controller system including the path planning Motion Control Unit (MCU) is depicted in Fig. 1. In order to fully understand the physical effects on the robot, we built our own robot simulator. It was programmed within the object oriented multibody code HOTINT, see Gerstmayr and Stangl [5]. The simulated mechanical links of robots with serial kinematics were assembled using the constraint equations, see Ludwig et al. [10]. The generalized force vector of the motor torque was projected into the Newton–Euler equations using the principle of virtual work. The MCU uses four-dimensional matrix transformations to define the position and the orientation of the robot joints – according to Denavit and Hartenberg [3]. In order to define bodies according to the definitions in HOTINT, the transformations are converted into redundant Euler Parameters. To identify the arbitrary uncertain parameters of the robot a novel algorithm was developed. To apply our algorithm to non-linear differential equations (e.g. from the friction models or non-linear drive stiffness), the zero order is selected for the algorithm. Unlike the first and the second order algorithms, the zero order algorithm does not require any gradient information or Hesse matrix from the cost function, see e.g. Bestle [2] or Farkas et al. [4]. The unknown parameters of the simulation are generated by our novel algorithm Ludwig and Gerstmayr [11] for the automatic parameter identification (shortly an identification) using the time domain. The algorithm is based on the theory of genetic optimization – a theory which is well suited for searching optimal solutions for the real world problems, see Begambre and Laier [1] and Hemmatian et al. [6]. The cost function – minimized by the identification – is the sum of the L2-norms of the difference between the measured and the simulated outputs in the time domain. Many multiple minima appeared in the distribution of the cost function and lead to a number of optimization steps. Parseval’s Theorem guarantees that the L2-norm of the cost function in the time domain and the frequency domain is equal. In order to benefit from this fact, the Discrete Fourier Transform (DFT) was implemented into our identification. Compared to the time domain, the weight functions in the frequency domain lead to lower values of local minima of the cost function. This technique was successfully applied to identify several parameters of a test example with well-known nominal parameters as well as to a real robot, see Ludwig and Gerstmayr [12]. The disadvantage of this technique is that the weight functions in the frequency domain must be selected very carefully.The main point of this paper is the following: instead of employing the user defined weight factors for the identification, compare Ludwig and Gerstmayr [12], a smoothing operation is applied before the evaluation of the L2-norm. First, we test the effect on the distribution of the cost function on a simple example of a PT2-system with well-known parameters. Afterwards we identify several parameters of a robot using the smoothing technique in the frequency domain. One limitation of our method is that the zero order identification does not use derivatives of the cost function with respect to the parameters. This fact might lead to higher computational efforts in the case of simple problems with no discontinuities and non-linearities (compared to the methods using gradients or the Hesse matrix). On the other hand, our zero order identification is well suited for the real problems where these effects should not be neglected. Another complication of the higher order algorithms is a strong dependency of the derivative on a small differentiation parameter which is used for the computation of the differential quotient. If the magnitude of the selected differentiation parameter is not sufficiently small, the gradient information might be incorrect. In some special cases, the numerically computed gradient has an opposite direction to the real gradient, see Zielkinsky and Neumann [13]. The higher computational effort in our zero order identification is therefore compensated by a more robust behavior. Due to the fact that the identification is based on the theory of genetic optimization, the user has to choose a sufficient number of initial parameter values, surviving parameters, children and realistic limits for the parameter space – in which the optimal parameters are searched Ludwig and Gerstmayr [11]. The distribution of the DFT depends on the length of the time window which is defined by the duration of the simulation or a time window and the sample frequency. If the time values of the simulation have no equidistant time interval, the values are interpolated in order to get a constant sample frequency. The ratio of the sample frequency and the number of samples within the time window define the frequency step of DFT.The new approach discussed in our paper should lead to a simplification of the identification and to a higher accuracy of the identified parameters in comparison to the methods using only the L2-norm of the cost function in the time domain. The presented paper extends the existing literature in the field of robotics which employs genetic algorithms to the best of the author’s knowledge. In contrast to Lei et al. [8], Kaoru et al. [9] and Hong et al. [7], where optimal paths of robots are investigated, we identify unknown physical parameters of robots to obtain a realistic behavior of the robot simulation. It is well-known, that the kinematic equations for Tripod – robots lead to very ill-conditioned problems. After applying our Special Genetic Algorithm we were able to successfully identify simulation parameters of a Tripod. In comparison to the Particle Swarm Optimization algorithm, our Special Genetic Algorithm lead to higher accuracy and precision of the cost function residual and as well a lower computation effort and a lower number of cost function evaluations, see Section 4.The trajectory planning is called Motion Control Unit (MCU). It is suitable for various applications – e.g. high speed pick-and-place motions, painting and sealing operations. Furthermore, experience with complicated tasks such as accurate compliance of limits concerning torque or acceleration, tracing of moving objects and use of model-based torque by means of feed-forward control, reduce path deviations. The MCU is available in a virtual version as well. Our robot simulator and the virtual MCU were coupled in a co-simulation via TCP/IP. An oscilloscope service is also a part of the real and virtual controller software. It is used for the visualization of the drive and the controller signals, compare Fig. 1.The interface of the coupled simulation fulfills three main tasks: the initialization of the simulation, the transfer of the reference signals and the synchronization of the MCU as well as our robot simulator. After the start of our robot simulator and the MCU, the initial reference values are transferred to the robot simulator and the dynamic model is initialized with these values. The numerical simulation is then started and the reference signals are transferred to our simulator – they represent the input of our control circuits in the robot simulator. The reference values are updated at a certain point in the time – dedicated to the update time step – and interpolated in the intervals between the points in time. An extended DLL of the oscilloscope service was included in our robot simulator – it is necessary for retaining a consistent connection to the data server of the MCU.This section contains the description of the extended form of our genetic algorithm for the parameter identification, see also Ludwig and Gerstmayr [11,12], shortly denoted as an identification. The identification minimizes the L2-norm – in other words the cost function – of the residual measurement and simulation. The cost function is available in the time domain and the frequency domain of our algorithm. We extended our identification by smoothing the amplitude spectra of the measured and the simulated quantities prior to the computation of the cost function.The identification searches for the vector of the optimal model parametersθopt. Its algorithm has zero order and it is well suited for the problems where multiple (local) minima appear in the distribution of the cost function with respect to the parameters. The identification does not need to compute the gradients numerically as it is required by the Newton’s method. The Newton’s method often finds only the local minimum near the initial parameter values in the complex distributions of the cost function. The identification needs only a few option values to obtain an algorithm which makes it user friendly. The option values contain the names of the optimized parameters in the simulation model. Their maximal and minimal values represent the boundaries of the parameter spaceP. Additionally, the number of the uniformly distributed trial parameters of the first generationg=1and the normally distributed parameters of the further generations are defined by the user.The cost functionegc– shortly denoted as e – is obtained by computing the mean quadratic error of the residual measurement and simulation. The simulation is repeated with every parameter vectorθgc. The child index c is dedicated to the child parameter vectors of thegth generation of the parameters. The first generation(1)c=(1,2,…,Ni),hasNiinitial parameter vectors with the uniformly distributed components. The child index of the following generationsg>1is(2)c=(1,2,…,NcNs).Nsis the number of the surviving parameters from the previous generationg-1– with low cost function – andNcis the number of children of each surviving parameter of the generationg. The child parameter set of the generation(3)g=(1,2,…,Ng),contains the child parameter vectors(4)Cg=(θg1,θg2,…,θgNsNc).Ngdenotes the user defined number of generations.The surviving parameter vectorsθgsare selected by means of a comparison of magnitude of the corresponding cost functions of child parameters, see Section 2.2.4. They are contained within the surviving parameter set(5)Sg=(θg1,θg2,…,θgNs),with(6)s=(1,2,…,Ns).The principle of the mutation is applied to the surviving parameter vectors(7)θgs→θ(g+1)c.The next generation contains the child parameter vectorsθ(g+1)c. The distance between each surviving parameter vector and its child parameters is normally distributed, see Section 2.2.5. It decreases with an increasing generation indexgin order to find the optimal parameter vector with a higher precision.The identification is able to compute the cost function in the time or alternatively in the frequency domain, see Section 2.2.1. We are especially interested in the modifications of the spectra of the residual measurement and simulation by smoothing in the frequency domain. The algorithm is terminated when the number of generations defined by the user is reached. Afterwards, the optimal model parameter vectorθoptwhich leads to the lowest cost function is returned as a result.The measured and simulated output vectorsymes(tj)andysim(θgc,tj)are M-dimensional. They contain the measured and simulated data at the equidistant discrete points in the timetj,j=(1,2,…,Nt). The simulated output vector depends on the child parameter vectorθgcof a specific simulation. In order to compare the accuracy of different simulations with different parameters, a cost function is defined in the following way. First, the error vectore(θgc,tj)is defined as a difference between the measured and the simulated output vector,(8)e(θgc,tj)=ymes(tj)-ysim(θgc,tj),at each point in timetj. We apply the L2-norm to each component ofe(θgc,tj)in order to compute the cost function(9)egc=∑k=1M1/Nt∑j=0Nt-1[ek(θgc,tj)]2.During the selection process, the cost function values are compared. Our identification minimizes the cost function and it searches for the optimal parameter vectorθopt, see Fig. 2. The dimension N of the parameter spaceP⊂RNis equal to the number of the parameters which are optimized. The limits of the parameter spaceRN– in which the optimal parameter vector is searched – are defined by the user.The components of child parameter vectorsθgcare limited to(10)θigc=[θi,min,θi,max],compare Fig. 3.The Discrete Fourier Transform (DFT) enables an improvement of the spectra of the components ofe(θgc,tj)in the frequency domain – e.g. by the application of weights or smoothing approach to the spectra prior to the evaluation of the cost function. The DFT(11)X^=(X^0,X^1,…,X^N-1),of a vector(12)x=(x0,x1,…,xN-1),consists of the components(13)X^l=DFT(x,l)=∑j=0N-1xjexp(-i2πjl/Nt),i=-1,l=(0,1,…,N-1).Applying Parseval’s Theorem and the symmetric characteristic of the complex conjugate values of the DFT of real valued time signals to Eq. (9) leads to the cost function in the frequency domain,(14)egc=12∑k=1M∑l=0⌊Nt/2⌋|E^lk|2,(15)E^lk=DFT(ek(θgc),l).For the norm of the value corresponding to zero frequency in Eq. (14) we use the factor1/Nt,(16)|E^0k|=signE^0kE^0k/Nt.For the norm of the DFT-values belonging to positive frequencies we use the factor2/Nt,(17)|E^lk|=2/NtR{E^lk(θgc)}2+I{E^lk(θgc)}2,∀l=(1,2,…,⌊Nt/2⌋).In our paper, we are mainly focusing on the improvements due to an application of the smoothing function,(18)Ψ(x,n)=∑j=max(j)-n,0)min(j+n,N-1)xj/(min(j+n,N-1)-max(j-n,0)+1),(19)x=(x0,x1,…,xN-1).The smoothed amplitude spectrum can be obtained by using the transformation(20)E^sk=Ψ(|E^k|,N‾),|E^sk|=(E^s,0k,E^s,1k,…,E^s,⌊Nt/2⌋k).By inserting Eq. (20) into Eq. (14) we evaluate the cost function of the spectrum with a smoothed amplitude,(21)egc=1/2∑k=1M∑l=0⌊Nt/2⌋(E^s,lk)2.Our experience has shown that the influence of constant time delays between measured and simulated signals can be suppressed by a small modification during the evaluation of the cost function. First, the spectra of the simulated and measured signals are evaluated separately in the frequency domain. Afterwards, the difference of the spectra and its cost function is computed. In this paper, we want to identify the time delay (see Section 3.2), therefore we do not use this modified evaluation of the cost function.Before the start of the identification, the user defines some options for the identification, see Fig. 4. The cardinality of the set of the uniformly distributed parameters is called initial population size. In case it is set to a high value, more parameters are tested in the first generation of parameters and the probability of finding the global minimum increases. However, the optimization time of our identification increases as well.The values of the cost function are computed after each simulation by means of comparing the norm of the (modified) measured and simulated residual signals in the time domain Eq. (9) or frequency domain, Eqs. (14)–(20). The best parameter vectors are called the surviving parameters. They correspond to the lowest values of the cost functionegcof all the computed generations and are the elements of the set of the surviving parametersSg. The user defines a majority|Sg|with a parameter called the surviving population size, see Fig. 4.Naturally/logically the parameters of the first generation have no predecessor. For this reason the initial parametersθi1care uniformly distributed within the parameter space(22)θigc=θi,min+(θi,max-θi,min)rigc,rigc∈[0,1],g=1,using the different random values ofrigcfor eachθigc. The function(23)s(x)=0ifx=0.5sgn(x-0.5)-log(2|x-0.5|)if0⩽x<0.5or0.5<x⩽xis used to define the distance between each component of a child parameter vector and its corresponding surviving parameter of the previous generation. In order to decrease these distances, a user defined range reduction factorξ∈]0,1]is established and used during the principle of mutation(24)θi(g+1)c=θigs+(θi,max-θi,min)s(rigc)ξ(g-1).According to the Eq. (10), in case that the result of Eq. (24) exceeds the corresponding interval, the componentsθi(g+1)cwill be limited toθi,minorθi,max.In this section, the identification is applied to a search of certain parameters of a simple PT2-system and a Tripod robot depicted in Fig. 5. In order to compute the accuracy of the identified parameters, the measurement dataymes(tj)is generated from simulations with well-known nominal parameters. The identification is tested with different nominal parameters, as well as different random valuesrof the genetic algorithm. In the following section we compare the identification behavior in the time domain with the behavior in the frequency domain (with and without smoothing) – we want to demonstrate the result improvements due to the application of smoothing in the frequency domain with respect to improved convergence due to lower number of minima, as well as the lower residual of the cost function and the lower number of simulations for a certain accuracy, compared to identifications with disabled smoothing.As a simple application of our identification we consider a PT2-system depending on the parameters mass m, stiffness k and damping d. The position is denoted asx=x(t)and the external force isF=F(t),(25)mx¨+dẋ+kx=F,x(t=0)=0,ẋ(t=0)=0.The dynamic equations Eq. (25) can be rewritten as(26)x¨+2ζ/ωẋ+ω02x=F/m,x(t=0)=0,ẋ(t=0)=0,with the Eigenfrequencyω0=k/mand the relative dampingζ=0.5d/km. In the following we evaluate the time history of the positionx(t)with nominal parameters after using a step for the forceF(t)=x(t→∞)σ(t)k withx(t→∞)=0.001m. In order to investigate the influence of smoothing in the frequency domain Eq. (20), the identification is started multiple times with different smoothing parametersN‾, see Eq. (20) and Table 1. The time signals are considered until the end time202π/ω0: during the identification. The sample time was set to4ms. The nominal parameters taken from Table 2. In order to show that the dependency of the identification with smoothing with respect to the random value is low, the further identifications are done twice with initial random value 0.1 and 0.5, see Eqs. (22) and (24). With each parameter of Table 2, one simulation with nominal parameters is done in order to treat the positionx(t)as ideal measurement data for testing the identification. After every simulation with nominal parameters, the identification process is started to compare the accuracy of the result of the identification – the optimal model parameter vectorθopt– with the well-known nominal parameter vector.The distribution of the cost function e in the frequency domain can be improved by using the smoothing technique in the frequency domain, see Figs. 6c, 7c and 8c. In the following it is demonstrated that the L2-norm in the time domain (Figs. 6a, 7a and 8a) and not smoothed frequency domain (Figs. 6b, 7b and 8b) lead to equivalent cost function distributions according to Parseval’s Theorem.The identification of the parametersk,mand d was done with every smoothing parameterN‾=(1,2,…,8). Table 1 summarily shows that in the majority of the test cases the identification result is more accurate when smoothing is activated. Hence, for the identification of real (unknown) parameters it is recommended to repeat the identification with different smoothing parametersN‾until the accuracy of the optimal model parametersθoptis satisfying. The extended identification with enabled smoothing leads in a majority of test cases to lower cost function residuals compared with the identification results with switched off smoothing – especially when the smoothing parameterN‾>3, see Table 3.The original and smoothed amplitude spectra, used for the identification of the PT2-system, are depicted in Fig. 9. The original (N‾=0) and the smoothed (N‾=4) amplitude spectrum of measured data are plotted with solid lines. The dashed line is the spectrum of a simulation with child parametersθgcnear a local minimum of the cost function. The cost functionsegcare computed according to Eq. (18) after the evaluation of the smoothed spectra.In Fig. 10, the mean parameter error of the parametersk,mandζis shown with respect to the smoothing parameterN‾. The figure summarizes the identification results with different identification options (cmp. Table 1) and and with different nominal parameter values ofk,mandζ(cmp. Table 2).The next step is an investigation of the dependency of the mean parameter error,(27)e¯θ=∑k=1N(θopt[k]-θnom[k])/θnom[k],with respect to the smoothing parameterN‾– the nominal parameter vector is denoted asθnom. Therefore, our identification is applied to a search of well-known (nominal) parameters of a Tripod model, see Fig. 5, which is also described in Ludwig and Gerstmayr [11,12]. The advantage of our zero-order identification is the ability to search mechanical variables like mass, stiffness, but also delay time and other parameters – for example of a nonlinear behavior like friction. The simulated motor torque is very sensitive to the drive parameters. This signal is defined as outputymes(tj)for our test of the identification, see Eq. (8). During the identification, we simulate with different parameter vectorsθgc. The output of each simulation is the motor torqueysim(θgc,tj).We identify the nominal parameters in Table 4. In contrast to previous work (see Ludwig and Gerstmayr [11,12]), we set the drive inertia constant toJD=80×10-6kgm2in order to identify only one parameter dedicated to the effect of inertia – the tool massmt. We use large search intervals for the components of the optimal model parameter vectorθopt. During the simulation a time delayΔTwith nominal parameters is considered. The nominal drive torque signal is delayed for a short time span. In real drive torque this behavior is caused by the transfer time from measuring until transferring the data into a data storage.The drive torque is output of the simulated cascade controller, which uses signals of the Motion Control Unit, see Fig. 1. The simulation also considers static friction and viscous damping which is subtracted from the drive torque. The drive torque is multiplied with the gear factor and applied to the rail mass. The rail massmrail, which is well-known from the data sheet, is coupled with the tool mass by a constraint equation which keeps the distance constant – so the rods of the Tripod are assumed to be massless. Furthermore, the gravity force is applied to the rail. A multiplication of the drive inertia by the square of the gear factor leads to an equivalent massmeof the moment of inertia of the motor. The drive inertia and the mass of the rail are assumed to be known from data sheets. The connection of an equivalent massmeand a rail mass is a spring damper element with stiffnesscGand gear damping(28)dG=2ζGmemrailcG/(me+mrail),representing effects of elasticity and damping. The use of a relative gear dampingζGallows better physical understanding.Following settings are used for the identifications of nominal Tripod parameters, see Table 4. Instead of using the value twenty for the number of initial, surviving and children parameters as in previous work Ludwig and Gerstmayr [12], we use only twelve. The frequenciesf=[0,50]Hzare shown in the amplitude spectra of our fast pick and place motion. We use the computation of the cost function in the frequency domain for the identification of nominal Tripod parameters and investigate the effect of the smoothing parameter, see Table 5, on the mean parameter error, see Eq. (27). The identification without smoothing,N‾=0leads to a mean parameter error of16.1%. The median of the mean parameter error of the identifications with enabled smoothing parameterN‾=(1,2,…,20)is 3.2 times lower than the residual without smoothing, see Fig. 11. The next step is the investigation of the convergence of the identified parameters by means of comparing the values of the mean parameter errore¯θ. For this the values of Table 5 are used with the condition that the number of initial parameter values, surviving parameters and children are set to the same value –n=(10,12,15). Furthermore, the identifications were repeated with different smoothing factorsN‾=(1,2,3). Fig. 12visualizes the result of the convergence study – the mean parameter error is depicted with respect to the number of simulations. The mean parameter error decreases with increasing number of simulations for the identification. The mean parameter error is lower if the smoothing of the parameters is enabledN‾>0.The aim of this section is the comparison of our Special Genetic Identification Algorithm (SGA) with the well-known Particle Swarm Optimization (PSO). Therefore we use following functions as cost function e: (1)e1=θ12+1.5θ22, (2)e2=∑k=12θk2⋯ DeJong (Sphere) function, (3)e3=∑k=12θk2/4000-∏l=12(cos(θl/l))+1⋯ the Griewank function, (4)e4=20+∑k=12((θk2)-10cos(2πθk))⋯ the Rastrigrin function and (5)e5=100(θ2-θ12)2+(1-θ1)2⋯ the Rosenbrock function. The DeJong, Griewank, Rastrigrin and Rosenbrock functions are standard test examples of the Particle Swarm Optimization. The algorithms use the random value generator. Following results of accuracy, computational cost and precision are obtained by a thousand computations with different initial random values. The cost function is minimized with the absolute tolerance10-4. The swarm size of the PSO was set to 10. The other PSO settings are default values. The settings of the SGA are similar to Table 1 – the difference is that the initial population size was decreased to the value 20 and different random values were used for the performance assessment and comparison with the PSO.The mean computation cost from 1000 computations of the SGA is lower than from the PSO, see Table 6. The mean number of cost function evaluations of the SGA is lower than the mean number of cost function evaluations of the PSO, see Table 7.The accuracy is obtained by averaging the cost function residuals from 1000 computations. The SGA minimizes the cost functions with higher accuracy than the PSO, see Table 8. In order to compare the precision of the SGA and the PSO, the maximal cost function residuals of the 1000 computations with different initial random values are summarized in Tables 9and 10. Our SGA showed higher precision than the PSO.In Ludwig and Gerstmayr [11], a powerful identification algorithm, based on the theory of genetic optimization, with a low number of user defined options was developed. With this first approach useing a cost function in the time domain, the parameters of a nominal test example and of a real robot were identified successfully – although multiple (local) minima appeared in the distribution of the cost function with respect to the parameters.Further work in Ludwig and Gerstmayr [12] focussed on the reduction of the (local) minima due to the use of DFT – techniques, especially with the use of weights of the amplitude spectra before the cost function is evaluated. The use of carefully chosen weigths in the frequency domain leads to a successful reduction of the multiple local minima.This paper deals with a more robust method in the frequency domain without carefully chosen user defined weigths. This extended identification depends on only one more user defined variableN‾, which influences the smoothing of the amplitude 4.06 spectra, see Eq. (18). For testing the extended identification was applied to a simple PT2-system and a Tripod robot. The use of this technique leads to higher accuracy of the identified parameters, which can be seen depicted in Figs. 6c, 7c, 8c, 11 and 12. Fig. 12 shows that compared to the identification method without smoothing in Ludwig and Gerstmayr [11], the extended identification leads to a lower number of simulations for a certain residual of the mean parameter error. The extended identification with smoothing method in the frequency domain proved to be very useful for an accurate identification of system parameters. Our Special Genetic Algorithm was compared with a standard Particle Swarm Optimization and showed higher accuracy and precision as well as lower computation cost.

@&#CONCLUSIONS@&#
Our identification algorithm, based on the theory of genetic optimization, was extended by a special cost function. The idea is that the use of a cost function smoothes the amplitude spectra in the frequency domain before the L2-norm is evaluated. This extended identification algorithm was applied to a simple PT2-system. The well-known nominal parameters were obtained in high accuracy by the identification. The extended identification leads to lower cost function residuals – compared to the identification results with switched-off smoothing. As a second test example for the extended identification, the parameters of a robot model were identified multiple times, using different identification options. The enabled smoothing leads to a lower mean parameter error than with disabled smoothing – even when the number of simulations is constant. Furthermore, the influence of the number of simulations was investigated in a manifold of different identifications. A lower mean parameter error of the identified robot parameters could be obtained with the extended algorithm – compared with identification without smoothing and higher number of simulations during the identification process. We want to emphasize that compared with the use of weights in the frequency domain for the cost function, the extended identification algorithm needs less insight into the system’s behavior. Additionally, the accuracy of the estimated parameters is higher in many cases compared to the identified parameters with cost function in the time domain. A final comparison of our algorithm against a standard Particle Swarm Optimization showed higher accuracy and precision in most of the tested cost functions as well as lower computation times and a lower number of optimization steps in all test cases.