@&#MAIN-TITLE@&#
Three-way decisions based on decision-theoretic rough sets under linguistic assessment with the aid of group decision making

@&#HIGHLIGHTS@&#
We provide a method of the determination of the two types of parameters used in the DTRS.The application of DTRS is extended to the scenarios of qualitative evaluation.An algorithm is designed to improve the inconsistency of multi-attribute group decision making under linguistic assessment.

@&#KEYPHRASES@&#
Linguistic terms,Group decision making,Loss function,Decision-theoretic rough sets,Three-way decisions,

@&#ABSTRACT@&#
Based on decision-theoretic rough set model of three-way decisions, we augment the existing model by introducing linguistic terms. Considering the two types of parameters being used in the three-way decisions with linguistic assessment, a certain type of novel three-way decisions based on the Bayesian decision procedure is constructed. In this way, three-way decisions with decision-theoretic rough sets are extended to the qualitative environment. With the aid of multi-attribute group decision making, the values of these parameters are determined. An adaptive algorithm supporting consistency improvement of multi-attribute group decision making is designed. Then, we optimize the scales of the linguistic terms with the use of particle swarm optimization. The values of these parameters of three-way decisions are aggregated when proceeding with group decision making. Finally, the proposed model of three-way decisions with linguistic assessment is applied to the selection process of new product ideas.

@&#INTRODUCTION@&#
Three-way decisions, consisting of acceptance, non-commitment (or further investigation) and rejection, are commonly encountered in problem solving strategies occurring in many decision process [56]. This way of decision-making has been applied to many domains, such as environmental precaution [8], text classification [15], information filtering [16], risk decision [17], cluster [20,57], investment decision [21], government decision [24], shadowed sets [32], email filtering [63], etc. Pawlak's rough sets [29,55] provide a certain convenient theoretical interpretation of the three-way decisions. The lower approximation and the upper approximation of rough sets [29,50] divide the universe of discourse (space) into the three pairwise disjoint regions: positive region, boundary region and negative region. The notion of three-way decisions based on the three pairwise disjoint regions was proposed by Yao [51,53,54]. The three-way decisions comprise positive rules, boundary rules and negative rules. The positive rules associated with the positive region produce acceptance decisions. The negative rules coming with the negative region give rise to rejection decisions, while the boundary rules (coming with the boundary region) result in decisions of non-commitment.Original rough sets [29] require exact results of classification and do not involve the tolerance for errors. Probabilistic rough sets arise a generalized model for original rough sets, which hinge on two components, i.e. a conditional probability and a pair of thresholds (α, β). The tolerance of errors is characterized by the thresholds of probabilistic rough sets. A series of models of probabilistic rough sets [10,50] was proposed, such as 0.5-probabilistic rough sets [30], decision-theoretic rough sets (DTRS) [48,49], variable precision rough sets (VPRS) [64], Bayesian rough sets [35], parameterized rough sets [9], etc. With respect to probabilistic rough set models, we need to compare the conditional probability with the thresholds in order to make a decision (see Fig. 1).Following studies reported in [55], the researches on three-way decisions with probabilistic rough sets can be summarized as shown in Fig. 1.•The determination of threshold values used in probabilistic rough set models. The determination of a pair of thresholds for the probabilistic rough sets constitutes a challenge [22]. The pair of thresholds presented in most probabilistic rough set models comes with subjectively assigned values and lacks of semantics [51,53,54]. In recent years, the determinations of thresholds are discussed in the framework of DTRS, which was first proposed by Yao et al. [48,49] using the Bayesian decision procedure. The pair of thresholds used in the DTRS model can be automatically calculated by loss functions with the minimum expected overall risk. In some cases, the loss function can be expressed in the form of money, energy or time [22]. Yao [51] adopted the relative value of loss function to express the thresholds. Herbert and Yao [11] introduced game theory to determinate the threshold values of probabilistic rough sets. Li and Zhou [17] discussed the value of loss function for a multi-view DTRS decision model based on different attitudes of decision makers. Liang et al. [18] generalized a concept of the precise value of loss function to triangular fuzzy decision-theoretic rough sets. Considering different criteria adopted by different agents, Yang and Yao [47] discussed some aggregation methods of loss functions and proposed a multi-agent DTRS model.The determination of the conditional probability used in probabilistic rough set models. Yao and Zhou [52] proposed a naive Bayesian decision-theoretic rough set model, where the conditional probability is estimated by using the Bayes theorem with naive probabilistic independence assumption. Liu et al. [23] employed binary logistic regression to compute the conditional probability of DTRS model.Evidently, the conditional probability and the thresholds are two important components of three-way decisions. DTRS is a representative model of probabilistic rough sets [48–50]. It not only considers the decision semantics, e.g. cost, risk, but also explains the thresholds of probabilistic rough set models [22,50]. The values of the thresholds used in the probabilistic rough set models are implied by the loss functions and associated with decision makers. Note that the loss functions and the conditional probability presented in the existing studies are mainly numerics. However, in the realistic decision process, some influencing factors result in decision makers not to assign specific numerics, e.g. cost, time and complexity [18]. Under these circumstances, the assessment of the description in terms of quantitative expressions is not suitable, see [39,46]. Other than the results reported in [18], we can resort ourselves to the assessment realized with the aid of linguistic terms. Linguistic terms have been witnessed in numerous situations [2,3,12,25,28,33,37–39,41,42,44,45,58–60]. For example, when evaluating a performance of a smartphone, linguistic terms like good, fair, poor can be considered. When we grade a student, linguistic terms like good, medium, poor can be used. In this case, the linguistic information can be directly used to compute and the linguistic terms need not been transformed into numerical counterparts [7,31,39,41,42,44,45]. Considering the conditional probability and the loss functions of the DTRS model with linguistic terms, we construct a certain type of novel three-way decisions. In light of the results presented in [18], these parameters of three-way decisions are evaluated by decision makers. In order to realize linguistic assessment of both the conditional probability and the loss functions, group decision making [1,4,26,33,37,38,43,61,62] is adopted. Group decision making can aggregate the wisdom of the different domain experts and effectively copes with the risk decision problem. More importantly, it provides a semantic interpretation for the relevant parameters of three-way decisions. Reaching consensus in group decision making becomes an essential step. For the consensus problem of group decision making, Pedrycz and Song [33] developed a novel approach. The approach used a particle swarm optimization (PSO) algorithm to optimize the scale over which linguistic terms were expressed. PSO is a population-based optimization method, which uses a swarm of particles to determine an optimal solution in a search space [6]. The conditional probability and the loss functions comprise the set of multi-attributes. Based on the approach reported in [33], this study further discusses the determination for the values of its parameters (i.e. conditional probability and loss functions) with the aid of multiple-attribute group decision making. The main contribution of our study can be identified as follows: (a) We provide a method of the determination of the two types of parameters used in the DTRS; (b) The application of DTRS is extended to the scenarios of qualitative evaluation; (c) An algorithm is designed to improve the inconsistency of multi-attribute group decision making under linguistic assessment (see Algorithm 1).The remainder of this paper is organized as follows: Section 2 provides some underlying concepts of probabilistic rough sets, Bayesian decision procedure, DTRS, linguistic terms and related operational laws. In Section 3, a certain type of novel three-way decisions is constructed. With the aid of multi-attribute group decision making with the linguistic assessment, Section 4 designs an adaptive algorithm for consistency improvement and investigates the determination of the values of both the conditional probability and the loss functions. An example is presented to illustrate the application of the novel three-way decisions in Section 5. Section 6 concludes this study and elaborates on future studies.In this section, basic concepts of probabilistic rough sets, Bayesian decision procedure, linguistic terms and operational laws are briefly reviewed.Let U be a finite and nonempty set and R an equivalence relation on U. The pair apr=(U, R) is called an approximation space, The equivalence relation R induces a partition of U. For a subset C⊆U, the probabilistic lower and upper approximations are defined by [50,51]:(1)apr_(C)={x∈U∣Pr(C|[x])≥α};(2)apr¯(C)={x∈U∣Pr(C|[x])>β}.where [x] is the equivalence class containing x under R. The thresholds α and β satisfy the condition: 0≤β<α≤1. Pr(C|[x]) is the conditional probability expressed as(3)Pr(C|[x])=|[x]⋂C||[x]|.When α=1 and β=0, (1) and (2) are degenerated into the original rough set model [29].Based on the rough set approximations of a subset C⊆U, one can divide the universe U into three pair-wise disjoint regions: the positive region, the boundary region and the negative region [50,51]. They give rise to three-way decisions. According to the probabilistic lower and upper approximations (i.e., (1) and (2)), the probabilistic positive, boundary and negative regions can be defined as follows.(4)POS(C)={x∈U∣Pr(C|[x])≥α},(5)BND(C)={x∈U∣β<Pr(C|[x])<α},(6)NEG(C)={x∈U∣Pr(C|[x])≤β}.The rules derived by the positive region POS(C) make decisions of acceptance. The rules derived by the negative region NEG(C) imply rejection decisions, while the rules derived by the boundary region BND(C) deal with decisions of non-commitment.In particular, if α=β, we set γ=α=β, (4)–(6) can be degenerated as:(7)POS(C)={x∈U∣Pr(C|[x])≥γ},(8)NEG(C)={x∈U∣Pr(C|[x])<γ}.Eqs. (7) and (8) compose two-way decisions, which is a special case of three-way decisions. In most of probabilistic rough sets, the interpretation of the thresholds α and β is not fully transparent. To overcome these weaknesses, the semantic explanation presented in DTRS model is given by bringing a Bayesian decision procedure to probabilistic rough sets [48,49]. In what follows, we briefly elaborate on the Bayesian decision theory.Based on observed evidence, the Bayesian decision procedure produces a decision with the minimum risk. In this section, we present a brief description of the procedure, see [5]. The set of states given byΩ={w1,w2,…,wm}is a finite set of m states andA={a1,a2,…,an}is a finite set of n possible actions.Pr(wi|x)is the conditional probability of an object x being in statewigiven that the object is described by x. Letλ(aj|wi)denote the loss or cost for taking action ajin the statewi. For an object x, suppose the action ajis taken. SincePr(wi|x)is the probability of which true state iswiby given x, the expected cost associated with taking action ajis given in the form:(9)R(aj|x)=∑i=1mλ(aj|wi)Pr(wi|x).For a given object x, a decision rule can be conceived as a function τ(x) that specifies which action to take. Hence, the overall risk R associated with every object with a corresponding decision rule is calculated by:(10)R=∑x∈UR(τ(x)|x)Pr(x).where the summation is taken over the set of all possible descriptions of objects. For every object x, we compute the conditional risk R(τ(x)|x) for every action by (9) and select the action for which the conditional risk is minimum. Thus, if τ(x) is chosen so that R(τ(x)|x) is as small as possible for every x, the overall risk R becomes minimized.For the DTRS model based on the Bayesian decision theory [48,49], the loss functions regarding the risk or cost of actions in different states are given in Table 1.From Table 1, the DTRS model is composed of 2 states and 3 actions. The set of states is given by Ω={C, ¬C} indicating that an object is in C and not in C, respectively. The set of actions is given byA={aP,aB,aN}, where aP, aB, and aNrepresent three actions when classifying object x, namely, deciding x∈POS(C), deciding x should be further investigated x∈BND(C), and deciding x∈NEG(C), respectively. λPP, λBPand λNPdenote the losses incurred for taking actions of aP, aBand aN, respectively, when an object belongs to C. Similarly, λPN, λBNand λNNdenote the losses incurred for taking the same actions when the object belongs to ¬C. Pr(C|[x]) is the conditional probability of an object x belonging to C given that the object is described by its equivalence class [x].For an object x, the expected loss R(ai|[x]) associated by taking the individual action can be expressed as:(11)R(aP|[x])=λPPPr(C|[x])+λPNPr(¬C|[x]),(12)R(aB|[x])=λBPPr(C|[x])+λBNPr(¬C|[x]),(13)R(aN|[x])=λNPPr(C|[x])+λNNPr(¬C|[x]).The Bayesian decision procedure suggests the following minimum-cost decision rules:(P0)IfR(aP|[x])≤R(aB|[x])andR(aP|[x])≤R(aN|[x]),decidex∈POS(C);(B0)IfR(aB|[x])≤R(aP|[x])andR(aB|[x])≤R(aN|[x]),decidex∈BND(C);(N0)IfR(aN|[x])≤R(aP|[x])andR(aN|[x])≤R(aB|[x]),decidex∈NEG(C).Since Pr(C|[x])+Pr(¬C|[x])=1, we simplify the rules based only on the probability Pr(C|[x]) and the loss function. By considering a reasonable kind of loss functions with the conditons(14)λPP≤λBP<λNP,(15)λNN≤λBN<λPN.The decision rules (P0)-(N0) can be expressed concisely as follows:(P0′)IfPr(C|[x])≥αandPr(C|[x])≥γ,decidex∈POS(C);(B0′)IfPr(C|[x])≤αandPr(C|[x])≥β,decidex∈BND(C);(N0′)IfPr(C|[x])≤βandPr(C|[x])≤γ,decidex∈NEG(C).The thresholds values α, β, γ are given:(16)α=(λPN−λBN)(λPN−λBN)+(λBP−λPP),(17)β=(λBN−λNN)(λBN−λNN)+(λNP−λBP),(18)γ=(λPN−λNN)(λPN−λNN)+(λNP−λPP).Where the thresholds (α, β, γ) are calculated by losses. In this case, the values of the thresholds (4)–(8) used in the probabilistic rough set models can be explained by (16)–(18). Furthermore, the probabilistic rough set models can be derived from DTRS under some specific conditions of loss functions [50,53–55].Linguistic terms have been used in AHP [2,33], risk analysis [3,25,44], group decision making [12,28,37–39,41,42,45], and alike. The set of linguistic terms can be denoted by S={sl|l=0, a, …, t}, where slrepresents a certain linguistic term [12]. For example, S={s0=Absolute low, s1=Very low, s2=Low, s3=Fairly low, s4=Medium, s5=Fairly high, s6=High, s7=Very high, s8=Absolute high} refers to Fig. 2.From Fig. 2, the subscript shown in the linguistic term included in the discrete term set is a non-negative integer. More specifically, s0 and stare the lower limit and the upper limit of S, respectively. t denotes the largest index of the subscript shown in the linguistic term, which is an even number. The set of linguistic terms S satisfies the following four requirements [12]:(a)The set is ordered: si≥sjif i≥j;There is the negation operator: neg(si)=sjsuch that j=t−i;Max operator: max(si, sj)=siif si≥sj;Min operator: min(si, sj)=siif si≤sj.In order to avoid loss of decision information and facilitate computations, the discrete term set S can be extended to a continuous term setS¯={sl|s0≤sl≤sq}whose elements also meet all the characteristics identified above while q is a sufficiently large positive numeric. If sl∈S, we call slthe original term and l the original term index; otherwise, we call slthe virtual term and l the virtual term index [39].Definition 1LetS¯={sl|s0≤sl≤sq}be a set of extended continuous linguistic terms, wheresl∈S¯is a linguistic term. The corresponding term index l can be expressed with the aid of the function I (I:S¯→[0,q]) as discussed in [28,38]:(19)I(sl)=l,sl∈S¯.Considering any two linguistic terms si,sj∈S¯and some constant μ∈[0, 1], we define the operational laws as follows [25,39,42]:(a)si⊕sj=sj⊕si=si+j;μsi=sμi;μ(si⊕sj)=μsi⊕μsj;si⊗sj=sj⊗si=sij.In what follows, we consider an example to illustrate Definitions 1 and the operational laws.Example 1Suppose that the set of linguistic terms is S={sl|l=0, 1, …, 8}. In light of the result present in [39], the corresponding continuous term setS¯={sl|s0≤sl≤sq}in which q is a sufficiently large positive numeric. Let two linguistic terms denote as s1, s2∈S and the constant be μ=0.5. For the operational law of μ(s1⊕s2), we have: μ(s1⊕s2)=0.5s1⊕0.5s2=s0.5⊕s1. In this case, s1 is an original term in S, while s0.5 is a virtual term. However, s0.5,s1∈S¯. Hence, we also can use the operational laws, i.e. μ(s1⊕s2)=s1.5.Corollary 1If the conditional probability of DTRS is a linguistic term denoted byPr(C|[x])˜, thenI(Pr(C|[x])˜)+I(Pr(¬C|[x])˜)=twith the set of linguistic terms S={sl|l=0, 1, …, t}.The conditional probability and the loss functions are two types of parameters of the three-way decisions with DTRS. For the loss functions, they are evaluated by decision makers. The numeric and non-numeric results have appeared in the evaluation process realized by a decision maker [12,22,28,37–39,41,42,45,52]. Hence, the values of the loss functions may embrace numeric or non-numeric results. For the conditional probability, the probability is normally computed according to rough membership implied by nature of information systems or based on available historical data [23,52], which are reflective of the experiences of experts. Using (3), the value of the conditional probability is numeric. However, the value of the conditional probability could be non-numeric. For example, we might not have any historical data at our disposal meaning that a granular characterization of the data is quite legitimate. In [44], the probability is assessed considering questionnaire data provided by experts based on Likert scale with linguistic terms [19]. Those terms are described as Very low, Low, Moderate, High and Very high. This provides a new way to acquire the value of the conditional probability (experts’ experiences) and is widely used in the areas of marketing and management. Generally speaking, the conditional probability could come with numeric and non-numeric outcomes. By introducing the linguistic assessment into DTRS, the combination of different kinds of the values of both the conditional probability and the loss functions are shown in Table 2.According to the combination of the numeric and linguistic terms present in the conditional probability and the loss function, there are four different situations as outlined in Table 2: (a) the values of both the conditional probability and the loss functions are numeric; (b) the value of the conditional probability is a linguistic term and the values of the loss functions are expressed numerically; (c) the values of the loss functions are linguistic terms while the value of the conditional probability is numeric; (d) the values of the loss functions and the conditional probability are linguistic terms. Under condition (a), its corresponding model is DTRS, which has been discussed in the existing literatures [48–50]. Under the conditions (b)–(d), the corresponding models formed here are referred to as Model 1, Model 2 and Model 3. In this section, we focus on constructing three novel models of three-way decisions under (b)–(d), namely, Model 1, Model 2 and Model 3. In what follows, we assume the set of linguistic terms is S={sl|l=0, 1, …, t} and t denotes the largest index of the subscript shown in the linguistic terms.In this section, we construct Model 1, where the value of the conditional probability in the three-way decisions with DTRS is a linguistic term and the loss functions in Table 1 are numeric. In this case, the conditional probability is denoted asPr(C|[x])˜. In light of Corollary 1,Pr(¬C|[x])˜is the negative probability ofPr(C|[x])˜. For example, the set of linguistic terms is S={s0=Very low, s1=Low, s2=Moderate, s3=High, s4=Very high} andPr(C|[x])˜is a linguistic term Very low. Thus,Pr(¬C|[x])˜is Very high.SinceI(Pr(C|[x])˜)+I(Pr(¬C|[x])˜)=t, we simplify the rules (P0)-(N0) based on the probabilityPr(C|[x])˜, linguistic operational laws, and (14) and (15). The decision rules (P0)-(N0) can be expressed concisely as:(P1)IfI(Pr(C|[x])˜)≥α1andI(Pr(C|[x])˜)≥γ1,decidex∈POS(C);(B1)IfI(Pr(C|[x])˜)≤α1andI(Pr(C|[x])˜)≥β1,decidex∈BND(C);(N1)IfI(Pr(C|[x])˜)≤β1andI(Pr(C|[x])˜)≤γ1,decidex∈NEG(C).The thresholds values α1, β1, γ1 are given by:(20)α1=t(λPN−λBN)(λPN−λBN)+(λBP−λPP),(21)β1=t(λBN−λNN)(λBN−λNN)+(λNP−λBP),(22)γ1=t(λPN−λNN)(λPN−λNN)+(λNP−λPP).Where 0≤α1≤t, 0≤β1≤t and 0≤γ1≤t. Following the discussion presented by Yao [50,53–55], as a well-defined boundary region, the conditions of rule (B1) suggest that α1>β1, that is,(23)(λBP−λPP)(λPN−λBN)<(λNP−λBP)(λBN−λNN).It implies that 0≤β1<γ1<α1≤t. In this case, after tie-breaking, the following simplified rules are obtained:(P1′)IfI(Pr(C|[x])˜)≥α1,decidex∈POS(C);(B1′)Ifβ1<I(Pr(C|[x])˜)<α1,decidex∈BND(C);(N1′)IfI(Pr(C|[x])˜)≤β1,decidex∈NEG(C).Besides (23), we can also obtain another condition α1≤β1, that is,(24)(λBP−λPP)(λPN−λBN)≥(λNP−λBP)(λBN−λNN).It implies that 0≤α1≤γ1≤β1≤t. In this case, the decision rules(P1′)-(N1′)can be rewritten as:(P1″)IfI(Pr(C|[x])˜)≥γ1,decidex∈POS(C);(N1″)IfI(Pr(C|[x])˜)<γ1,decidex∈NEG(C).where the three-way decision rules(P1′)-(N1′)change to the two-way decisions(P1″)-(N1″).In this subsection, we discuss Model 2 in which the values of the loss functions of the three-way decisions with DTRS are linguistic terms, while the conditional probability is quantified numerically. The loss functions are shown in Table 3.Since Pr(C|[x])+Pr(¬C|[x])=1, we simplify the rules based on the probability Pr(C|[x]), linguistic operational laws and the loss functions. By considering a sound form of loss functions with(25)I(λPP˜)≤I(λBP˜)<I(λNP˜),(26)I(λNN˜)≤I(λBN˜)<I(λPN˜).The decision rules (P0)-(N0) can be expressed as:(P2)IfPr(C|[x])≥α2andPr(C|[x])≥γ2,decidex∈POS(C);(B2)IfPr(C|[x])≤α2andPr(C|[x])≥β2,decidex∈BND(C);(N2)IfPr(C|[x])≤β2andPr(C|[x])≤γ2,decidex∈NEG(C).The thresholds values α2, β2, γ2 are given by:(27)α2=(I(λPN˜)−I(λBN˜))(I(λPN˜)−I(λBN˜))+(I(λBP˜)−I(λPP˜)),(28)β2=(I(λBN˜)−I(λNN˜))(I(λBN˜)−I(λNN˜))+(I(λNP˜)−I(λBP˜)),(29)γ2=(I(λPN˜)−I(λNN˜))(I(λPN˜)−I(λNN˜))+(I(λNP˜)−I(λPP˜)).Following the results reported in [50,53–55], as a well-defined boundary region, the conditions of rule (B2) suggest that α2>β2, that is,(30)(I(λBP˜)−I(λPP˜))(I(λPN˜)−I(λBN˜))<(I(λNP˜)−I(λBP˜))(I(λBN˜)−I(λNN˜)).It implies that 0≤β2<γ2<α2≤1. In this case, after tie-breaking, the following simplified rules are obtained:(P2′)IfPr(C|[x])≥α2,decidex∈POS(C);(B2′)Ifβ2<Pr(C|[x])<α2,decidex∈BND(C);(N2′)IfPr(C|[x])≤β2,decidex∈NEG(C).Besides (30), we also can obtain another condition α2≤β2, that is,(31)(I(λBP˜)−I(λPP˜))(I(λPN˜)−I(λBN˜))≥(I(λNP˜)−I(λBP˜))(I(λBN˜)−I(λNN˜)).It implies that 0≤α2≤γ2≤β2≤1. In this case, the decision rules(P2′)-(N2′)can be rewritten in the following manner:(P2″)IfPr(C|[x])≥γ2,decidex∈POS(C);(N2″)IfPr(C|[x])<γ2,decidex∈NEG(C).where the three-way decision rules(P2′)-(N2′)change to the two-way decisions counterpart(P2″)-(N2″).Model 3 is discussed in this subsection, where the values of the loss functions and the conditional probability of three-way decisions with DTRS are linguistic. SinceI(Pr(C|[x])˜)+I(Pr(¬C|[x])˜)=t, we simplify the rules based on the probabilityPr(C|[x])˜, linguistic operational laws and (25) and (26). The decision rules (P0)-(N0) can be expressed concisely in the following format:(P3)IfI(Pr(C|[x])˜)≥α3andI(Pr(C|[x])˜)≥γ3,decidex∈POS(C);(B3)IfI(Pr(C|[x])˜)≤α3andI(Pr(C|[x])˜)≥β3,decidex∈BND(C);(N3)IfI(Pr(C|[x])˜)≤β3andI(Pr(C|[x])˜)≤γ3,decidex∈NEG(C).The thresholds values (α3, β3, γ3) are given by:(32)α3=t(I(λPN˜)−I(λBN˜))(I(λPN˜)−I(λBN˜))+(I(λBP˜)−I(λPP˜)),(33)β3=t(I(λBN˜)−I(λNN˜))(I(λBN˜)−I(λNN˜))+(I(λNP˜)−I(λBP˜)),(34)γ3=t(I(λPN˜)−I(λNN˜))(I(λPN˜)−I(λNN˜))+(I(λNP˜)−I(λPP˜)).Considering the condition (30), this implies that 0≤β3<γ3<α3≤t. The following simplified rules are formed:(P3′)IfI(Pr(C|[x])˜)≥α3,decidex∈POS(C);(B3′)Ifβ3<I(Pr(C|[x])˜)<α3,decidex∈BND(C);(N3′)IfI(Pr(C|[x])˜)≤β3,decidex∈NEG(C).Considering the condition (31), we have 0≤α3≤γ3≤β3≤t and the decision rules(P3′)-(N3′)can be rewritten as follows:(P3″)IfI(Pr(C|[x])˜)≥γ3,decidex∈POS(C);(N3″)IfI(Pr(C|[x])˜)<γ3,decidex∈NEG(C).The three-way decision rules(P3′)-(N3′)change to(P3″)-(N3″).In Section 3, we have constructed three novel models of three-way decisions with linguistic assessment. They extend the applications of three-way decisions to the linguistic (qualitative) environment. When using these models to form decision rules, we need determine the values of both the conditional probability and the loss functions in advance. Take Model 3 as an example, we investigate a method to determine the values of two kinds of parameters with linguistic terms in this section. For Model 3, the conditional probability and the loss functions are the critical factors of three-way decisions. For example, the loss functions containing six types (aspects) of losses impact the three-way decisions. In light of the likert scale [19] and questionnaire survey [25,44], the values of both the conditional probability and the loss functions with linguistic terms can be acquired from experts. Group decision making can aggregate the wisdom of the different domain experts and effectively copes with the risk decision problem. More importantly, it provides a semantic interpretation for the relevant parameters of three-way decisions. In fact, the decision rules (P3)-(N3) of three-way decisions including the aggregated functions imply the rank strategies of alternatives, which the conditional probability and the loss functions constitute the set of multi-attributes. With the above analysis, multi-attribute group decision making emerges as a suitable method to determine the values of two kinds of parameters used in the novel three-way decisions.Let A={a1, a2, …, a7} be the set of attributes, which corresponds to{Pr(C|[x])˜,λPP˜,λBP˜,λNP˜,λPN˜,λBN˜,λNN˜}, respectively. Let P={p1, p2, …, pm} be a discrete set of alternatives. For alternative pi(1≤i≤m), experts evaluate it with its equivalence class by considering some prior information. Let linguistic terms are denoted as S={s0, s1, …, st}. E={e1, e2, …, en} is the set of experts andW={w1,w2,…,wn}Tis the weight vector of experts, where∑k=1nwk=1andwk≥0. The decision matrix of expert ekis denoted asDk=(Mijk˜)m×7, where k is the mark of expert,Mijk˜is a linguistic assessment given by the expert ekfor the alternative piwith respect to the attribute ajwhere 1≤k≤n, 1≤i≤m and 1≤j≤7. The corresponding group decision matrix is denoted asG=(Mij˜)m×7, where(35)Mij˜=∑k=1nwkMijk˜.Following [38,40,43], the deviate degree of individual to group decision is defined as follows:(36)d(ek,G)=17m∑i=1m∑j=17d(Mijk˜,Mij˜).where d(ek, G) is the distance between ekand G,d(Mijk˜,Mij˜)is the distance between linguistic termMijk˜andMij˜:(37)d(Mijk˜,Mij˜)=|I(Mijk˜)−I(Mij˜)|t.The smaller of d(ek, G) is, the better the consistency between ekand G.In the multi-attribute group decision making problem, the consensus among experts reflects their consistency opinions. Before aggregating individual decision, we need to evaluate the effectiveness of the group decision result by completing a comparison between the consensus degree and a given threshold [26]. If the consensus degree is lower than this threshold, it indicates that there are a number of different opinions among experts. On the contrary, when the consensus degree is higher than the threshold, it shows that most of experts have the same or similar opinion. With respect to reaching consensus, some adaptive approaches [1,4,26,33,38,43,61,62] have been proposed. The consensus is reached by modifying the evaluation outcomes. Pedrycz and Song [33] proposed a new approach to consistency improvement, where the improvement is achieved by adjusting the scale of linguistic terms. As a simple example, consider two decision makers one of which comes with an evaluation “Medium” while the second one arrives at the assessment “Very high”, i.e. S4 and S7 in Fig. 2. In this case, we usually ask the experts to re-evaluate and change their evaluation results until the consistency level is enough high. Their final evaluations may be inclined to a point via negotiation. The approach proposed in [33] evolves the negotiation process of experts and produces higher values of consistency. Inspired by [33], we bring this idea into the multi-attribute group decision making with linguistic assessment. The scale of linguistic terms is usually uniform as encountered in the existing literatures [13], see Fig. 2. With the aid of the PSO algorithm, the consistency level is elevated by making the scale non-uniform. In what follows, we briefly recall the PSO optimization framework [6,34]. In the method, one simulates a swarm behavior in birds flocking and fish schooling to guide the particles to search for globally optimum (minimum or maximum) of a given objective function. The objective function determines the quality of the solution represented by each particle's position. Each particle adjusts its movement and position according to its own flying experience and its companions’ flying experience. Each particle is treated as a point in a D dimensional space. The gth particle is represented as xg=(xg1, xg2, …, xgD) and its velocity vector is given asvg=(vg1,vg2,…,vgD). At any time step f, the gth particle has an associated position vector xg(f)=(xg1(f), xg2(f), …, xgD(f)), and the velocity vectorvg(f)=(vg1(f),vg2(f),…,vgD(f)). A vector pbg(f)=(pbg1(f), pbg2(f), …, pbgD(f)) stores the best position that the particle has ever visited. The best position among all the particles in the population is represented by a vector pg(f)=(pg1(f), pg2(f), …, pgD(f)). The PSO algorithm iteratively updates the velocity and the position of each particle until a stopping criterion has been met. For the gth particle, its basic update rules of the velocity and the position in the dth (d=1, 2, …, D) dimensional space at the time step f are:(38)vgd(f+1)=η(f)×vgd(f)+c1×rand()×(pbgd(f)−xgd(f))+c2×Rand()×(pgd(f)−xgd(f));(39)xgd(f+1)=xgd(f)+vgd(f+1).where c1 and c2 are two constants acceleration coefficients being typically set to 2, rand() and Rand() are random functions in the rang [0, 1]. η(f) is the time-dependent inertia weight and brings in a significant improvement to the PSO performance [34]. The inertia weight can be defined as [33]:(40)η(f)=0.9−(0.9−0.4)×fTmax.where Tmaxis the total number of generations. The velocities have some limits, e.g., the maximum and the minimum. Their values are related to the scope of the search spaces and prevent velocities changing too much.Inspired by the result reported in [33], we use the deviate degree to measure the inconsistency of the individual decision in the group decision making. It is the reverse of consistency degree. The inconsistency of group decision making as the objective function of PSO is:(41)Q=∑k=1nd(ek,G).For the PSO algorithm, the objective function Q is the whole inconsistency of group decision making, which is the sum of inconsistency of individual decision to group decision making and is used to measure the effectiveness of group decision making. (41) is minimized until it is lower than a given threshold of inconsistency δ, i.e. Q≤δ. If Q>δ, we need continue to search the lower objective function value in the hyperspace. The threshold parameter δ represents the necessary level of the overall inconsistency for a solution to be accepted by the group [26], and has been discussed in [4,26,38,40,42,43]. It is often determined by the experts in advance [26,38,40,42,43]. According to the result reported in [43], we also accept the condition δ≤0.5n, where n is the number of the experts. Additionally, we consider that the objective function may not converge to δ. In order to avoid this situation, we set the total number of generations [26].Therefore, based on the predetermined uniform distribution of linguistic terms on the evaluation scale, an adaptive algorithm for consistency improvement of multi-attribute group decision making under linguistic assessment is described as follows.Step 1: Determine the parameters of multiple-attribute group decision making: the number of experts E={e1, e2, …, en} and their weightsW={w1,w2,…,wn}T. Select reasonable linguistic terms with their uniform scales S={sl|l=0, 1, …, t}. In light of the set of alternatives P={p1, p2, …, pm} with respect to the set of attributes A={a1, a2, …, a7}, obtain the evaluation results and construct the corresponding decision matrix for every expertDk=(Mijk˜)m×7. Meanwhile, set the threshold value of the whole inconsistency used in the group decision making to δ.Step 2: Initialize the parameters of the PSO algorithm: the objective function is Q in (41), learning factors are c1, c2 and c1=c2=2. The population of particles sets Num, the total number of generations is Tmax. Each particle is treated as a point in a t dimensional space. The position of the particle is xg(f)=(xg1(f), xg2(f), …, xgt(f)) and its corresponding velocity isvg(f)=(vg1(f),vg2(f),…,vgt(f))(g=1, b, …, Num;f=1, 2, …, Tmax).Step 3: Determine the optimal scale of linguistic terms S′ with the aid of the PSO algorithm, which is described in Algorithm 1.Algorithm 1The adaptive algorithm for consistency improvement of multi-attribute group decision making under linguistic assessmentInput: (1) The linguistic terms and their uniform scale S={sl|l=0, 1, …, t};(2) The set of experts E={e1, e2, …, en} and the weight vector of expertsW={w1,w2,…,wn}T;(3) The decision matrixesDk=(Mijk˜)m×7and the threshold value of whole inconsistency in group decision making δ;(4) The parameters of PSO: the population of particles Num, learning factors c1, c2 and the total number of generations is Tmax.Output: The optimal scale of linguistic terms S′.1begin% The objective function Q in (24) is the inconsistency of group decision making.2Calculate the objective function value under the uniform scale of linguistic terms S, denoted as Q;3% The dimensionality of every particle is t, which respects the number of the interval of S.4forg=1 to Numdo% initialize5textbffor d=1 to tdo6xgd(1)=1t;% initial position, denoted as the proportion of t.7vgd(1)=2*rand−1;% initial velocity8end9end10forg=1 to Numdo11p(g)=Q;% initial the best objective function value of every particle12ford=1 to tdo13pbgd(1)=xgd(1);% initial the best position of every particle14end15end16pbest=Q;% initial the best objective function value of all particles17ford=1 to tdo% initialize18pgd(1)=1t.% initial the best position of all particles, corresponding to pbest19end20f=1;21While (f≤Tmax) & & (pbest>δ) do% Tmaxand δ as generation stopping criterions22η(f)=0.9−(0.9−0.4)*f/Tmax;% the inertia weight23forg=1 to Numdo24ford=1 to tdo25vgd(f+1)=η(f)*vgd(f)+c1*rand()*(pbgd(f)−xgd(f))+c2*Rand()*(pgd(f)−xgd(f));% update the velocity26Adjust velocity whenvgd(f+1)>1orvgd(f+1)<−1;27xgd(f+1)=xgd(f)+vgd(f+1);% update the position28Adjust position and velocity when xgd(f+1)<=0 or xgd(f+1)>1;29end30Determinate the new scale of linguistic terms S′ based on the normalization of xgd(f+1)(d=1, 2, …, t) and t;31Calculate the objective function value Q according to S′ and the decision matrixes;32ifQ<p(g) then33p(g)=Q;34Assign xgd(f+1) to pbgd(f+1)(d=1, 2, …, t);35end36ifp(g)<pbestthen37pbest=p(g);38Assign pbgd(f+1) to pgd(f+1)(d=1, 2, …, t);39end40end41f=f+1;42end43Output the optimal scale of linguistic terms S′ based on the normalization of pgd(f)(d=1, 2, …, t) and t;44endThe overall procedure of the above adaptive algorithm for consistency improvement of multi-attribute group decision making under linguistic assessment is described in Fig. 3.Continuing with the optimal scale of linguistic terms S′ presented in Section 4.2, the values of the conditional probability and the loss functions of each alternative can be determined by aggregating the evaluations of all experts. For an alternative pi(i=1, 2, …, m), the values of its conditional probabilityPr(C|[pi])˜and loss functionsλ••i˜based on (35) are computed as:(42)Pr(C|[pi])˜=w1SI(Mi11˜)′⊕w2SI(Mi12˜)′⊕⋯⊕wnSI(Mi1n˜)′;(43)λPPi˜=w1SI(Mi21˜)′⊕w2SI(Mi22˜)′⊕⋯⊕wnSI(Mi2n˜)′;(44)λBPi˜=w1SI(Mi31˜)′⊕w2SI(Mi32˜)′⊕⋯⊕wnSI(Mi3n˜)′;(45)λNPi˜=w1SI(Mi41˜)′⊕w2SI(Mi42˜)′⊕⋯⊕wnSI(Mi4n˜)′;(46)λPNi˜=w1SI(Mi51˜)′⊕w2SI(Mi52˜)′⊕⋯⊕wnSI(Mi5n˜)′;(47)λBNi˜=w1SI(Mi61˜)′⊕w2SI(Mi62˜)′⊕⋯⊕wnSI(Mi6n˜)′;(48)λNNi˜=w1SI(Mi71˜)′⊕w2SI(Mi72˜)′⊕⋯⊕wnSI(Mi7n˜)′.With respect to (43)–(48), we calculate the thresholds values (α3, β3, γ3) of every alternative using (32)–(34). Comparing with the thresholds values, the three-ways decision rules are generated on the conditions (30) and (31). Furthermore, the concrete decision can be made in accordance with (42).To succeed in a competitive and rapid variable market environment, new product development (NPD) is indeed very important for a company [14,27,36]. NPD can improve its core competitiveness and increase the value of the company, e.g. its market share and profits [36]. The primary task of NPD is to satisfy the customers’ demands. The customers’ demands change quickly and directly impact the development of the company. NPD not only satisfies the customers’ demand, but also belongs to the company's requirement. The new product idea is a pivotal component of the NPD. With an overwhelming number of new product ideas, the manager in a company has to allocate scarce resources to potential new products. Normally, the company is faced with limited resources. The procedure of the NPD also exists some risky and uncertain factors. Ozer [27] summarized four categories factors which influence decision making in the NPD: task-related factors, decision maker-related factors, elicitation-related factors and aggregation-related factors. Kengpol and O’Brien [14] constructed a hierarchy of common criteria and sub-criteria. In order to reduce the risks and allocate resources in the NPD, the manager need to evaluate the new product ideas and select the potential ones to develop. For the sake of the evaluation more confidently and accurately, the manager has to aggregate the multiple experts’ opinions, such as salesmen, designers, managers and others. Ozer [27] pointed at the two types of erroneous selection decisions in the NPD. One is they might decide to pursue a potential unsuccessful new product idea. The other is that they might decide not to develop a potential and successful new product. The two types of errors may cause enormous losses to the company. The former leads to investment loses while the latter leads to missed investment opportunities [27]. Except the selection and non-selection strategies of the new product idea, the deferred action is the third strategy. In particular, the manager hard make a choice as to the new product ideas, while he or she does not want to lose some development chances. The manager need collect more information to make this choice. Hence, the selection decisions of the new product idea are consistent with three-way decisions. In this section, we use the three-way decisions with linguistic assessment to support the selection decisions of the new product idea and illustrate the decision process of the novel three-way decisions. The procedure of the selection decisions of the new product idea is shown in Fig. 4.In what follows, we elaborate on details of the steps described in Fig. 4. For the selection decisions of the new product idea, we have two states Ω={C, ¬C} indicating that the new product idea is a good one or the bad one, respectively. The set of actions for the new product idea x is given byA={aP,aB,aN}, where aP, aB, and aNrepresent selection, need for further investigation and not to make a selection, respectively. The actions aP, aB, and aNcorrespond with(P3′)-(N3′)or(P3″)-(N3″). For the novel three-way decisions of Model 3, there are seven attributes. The conditional probabilityPr(C|[pi])˜denotes the probability of a product idea pibeing a good idea, which piis described by its equivalence class pi(i=1, 2, ⋯, m).λPP˜,λBP˜andλNP˜are the losses incurred for taking actions of selection, need further investigation and do not make selection respectively, when the new product idea belongs to a good idea. Similarly,λPN˜,λBN˜andλNN˜are the losses incurred for taking actions of selection, need further investigated and do not selection when the new product idea is a bad one. With respect to some risky and uncertain factors [14,27], the seven parameters of each new product idea are imprecisely evaluated in NPD. A Likert scale [19] is a technique for measurement of decision makers’ attitude and collecting their experiences. This approach is widely used to scale responses in survey researches [25,44]. Inspired from the results, we adopt linguistic term to assess seven parameters of the new product ideas. For the threshold value δ of the whole inconsistency used in the group decision making, Xu [40] suggested that each individual inconsistency was set to 0.15. Wu and Xu [38] set a more rigorous value of 0.1 to each individual inconsistency. Other authors gave some different threshold values depending upon the problem at hand [4,26,42,43]. Here, we set the threshold value of overall inconsistency to be δ=0.28.Suppose that there are nine new product ideas for the company, i.e., p1, p2, ⋯, p9 and m=9. For making reasonable selection decisions, a salesman, a designer and a manger treated as experts participate in the evaluation, which is denoted as (e1, e2, e3). We assume that they have the same weight, i.e.,W={w1,w2,w3}T={1/3,1/3,1/3}T. The corresponding group decision matrix isG=(Mij˜)9×7(1≤i≤9, 1≤j≤7). The decision matrix of expert ekis denoted asDk=(Mijk˜)9×7, where 1≤k≤3, 1≤i≤9 and 1≤j≤7. The set of linguistic terms is denoted by S={sl|l=0, 1, ⋯, 8}, where S={s0=Absolute low, s1=Very low, s2=Low, s3=Fairly low, s4=Medium, s5=Fairly high, s6=High, s7=Very high, s8=Absolute high} is shown in Fig. 2. According to the proposed three-way decisions model and the set of linguistic terms, the decision matrices of the three experts are given in Tables 4–6, i.e., D1, D2 and D3.In Tables 4–6, the three decision matrices collect the evaluation outcomes of each decision maker. Based on the results of D1-D3, we elaborate the decision process of the novel three-way decisions. Xu [40] discussed the deviation measures of linguistic preference relations in group decision making. According to (36), we compute the deviate degrees of individual to group decision under the original of linguistic terms, namely, d(e1, G)=0.1138, d(e2, G)=0.1025 and d(e3, G)=0.1224. Under the original situation of linguistic terms, the inconsistency of group decision making Q based on (41) is 0.3386 by using the method presented in [40]. Q is used to measure the effectiveness of group decision making. In this case, Q>δ=0.28. Hence, we need to determinate the values of seven attributes for the new product ideas based on Algorithm 1 and group decision making. In allusion to the method presented in [40], Algorithm 1 is a novel method for the improvement of the inconsistency of group decision making with the aid of PSO.According to the results reported in [33], the values of the learning factors are set as c1=c2=2, the population of particles is equal to Num=100 and the total number of generations is fixed as Tmax=500. The objective function is Q standing in (41), which is the inconsistency of group decision making. First, we reach the consensus of group decision making by optimizing the scale of linguistic terms and obtain the optimal scales. The progression of Algorithm 1 is shown in Fig. 5.From Fig. 5, we observe that the value of the objective function is less than δ=0.28 and this occurs after 37th generation of the algorithm. On the basis of the linguistic terms shown in Fig. 2, PSO produces the optimal cutoff points of 2.87, 2.92, 3.92, 4.03, 4.29, 4.62 and 5.13. The optimized scale of linguistic terms S′ is visualized in Fig. 6.Remark 1In Fig. 6, the optimal cutoff points between 0 and 8 are 2.87, 2.92, 3.92, 4.03, 4.29, 4.62 and 5.13 along the horizontal ordinate successively. To reach consensus of group decision making, the optimal cutoff points of linguistic terms become distributed unevenly and this reduces the inconsistency of group decision making.In light of (36), we also calculate the deviate degrees of individual to group decision under the optimal situation of linguistic terms. Under the original and the optimal situations of linguistic terms, we compare the deviate degrees of individual to group decision, respectively. Their results are shown in Fig. 7.In Fig. 7, the horizontal axis denotes the notation of individual decision matrix, which has D1, D2 and D3. The vertical axis is the deviate degrees of individual to group decision. For the original situations of linguistic terms, the deviate degrees of individual to group decision are calculated by Xu [40]. For the optimal situations of linguistic terms, the deviate degrees of individual to group decision based on Xu [40] have been optimized by Algorithm 1. In this situation, the optimized results are d(e1, G)=0.0860, d(e2, G)=0.0950 and d(e3, G)=0.0920. From Fig. 7, it is apparent the deviate degrees of individual to group decision have been reduced under the optimal situation of linguistic terms. The optimal result is lower than a given threshold of inconsistency δ and achieves the requirement of consistency of group decision making.With regards to the improvement of the inconsistency of group decision making, Xu [43] developed an automatic approach, which can automatically modify the diverging individual opinions so as to reach consensus amongst all the experts’ opinions. The main modified formula ofDk=(Mijk˜)9×7is shown as follows:(49)Mijk˜=θMijk˜)⊕(1−θ)Mij˜.where θ is a constant andMij˜is an element of G. According to the method presented in Xu [43], we continue to modify the decision matrices by utilizing (49) until the inconsistency of group decision making Q is lower than δ. Suppose l is the number of iterations. Considering the different values of θ, we calculate their numbers of iterations. The results are listed in Table 7.From Table 7, θ can impact the number of iterations. Compared with the method presented in Xu [43], the number of iterations of Algorithm 1 is less than the results of Table 7. Then, the group decision matrix is constructed based on the optimal results of PSO and (42)–(48). The values of the seven parameters for the new product ideas are determined in the group decision matrix G, see Table 8.Finally, the three threshold values of each new product idea are calculated by using (32)–(34), i.e., (α3, β3, γ3). The conditional probability of every new product is transferred a corresponding linguistic term index. For the clarity, the values of the conditional probability and the thresholds for every new product idea are illustrated in Table 9.From the results shown in Table 9, we compare the three thresholds (α3, β3, γ3) of each new product idea. In Table 9, we find that the thresholds of p1, p2, p3, p4, p7, p8 and p9 exhibit the following relationship: 0≤β3<γ3<α3≤8. The selection decisions of these new product ideas are made in light of(P3′)–(N3′). The thresholds of p5 and p6 come with the relationship: 0≤α3≤γ3≤β3≤8. The selection decisions of these new product ideas are made in light of(P3″)–(N3″). For the nine new product ideas, the experts believe that p1, p4 and p5 need to be selected to develop immediately, while p3, p6 and p8 should not be selected to develop. In addition, they also think p2, p7 and p9 need be further investigated. The selection decisions of the new product ideas are summarized in Table 10.In the above illustrative example, the results of Tables 4–6 are source data, which are used to elaborate the decision process of the novel three-way decisions. We summarize the advantages of our proposed method by comparing with the existing model presented in [48–50] as follows: First, the proposed method extends the existing model of DTRS to a qualitative decision environment. In this example, Model 3 accommodates the linguistic assessment scenario. Second, group decision making provides a semantic interpretation for the relevant parameters of three-way decisions. Under the consistent situation of group decision making, we finally determine the conditional probability and the losses for each new product idea. Third, the proposed method further improves the inconsistency problem of group decision making. The solution is designed by Algorithm 1, which focuses on optimizing the original method reported in [40]. The optimized result has been shown in Fig. 7. In general, the novel three-way decisions can availably guild us to make a decision with linguistic assessment.

@&#CONCLUSIONS@&#
Based on the DTRS model, our study takes the conditional probability and the thresholds with linguistic terms into consideration and proposes one type of novel three-way decisions, i.e. Models 1–3. In the context of multi-attribute group decision making, the values of both the conditional probability and the loss functions of Model 3 are determined by Algorithm 1 and group decision making, in which Algorithm 1 improves the inconsistency of multi-attribute group decision making under linguistic assessment. Besides Model 3, the algorithm is also suitable to other models of three-way decisions. This study provides a method for the determination of the parameters of DTRS and extends its range of applications. Future researches may focus on designing some mechanisms to enhance the performance of Algorithm 1 and draw general conclusions, such as high inconsistency, robustness, etc.