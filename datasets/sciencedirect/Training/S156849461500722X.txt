@&#MAIN-TITLE@&#
Optimal design of a 3D-printed scaffold using intelligent evolutionary algorithms

@&#HIGHLIGHTS@&#
The aggregated artificial neural network was used to investigate the simultaneous effects of printing parameters on the compressive strength and porosity of scaffolds.Particle swarm optimization algorithm was implemented to obtain the optimum topology of the AANN. Pareto front optimization was used to determine the optimal setting parameters.The presented results and discussion can give informative information to practitioners who want to design a porous structure, and need to know the impact of influential design parameters.

@&#KEYPHRASES@&#
Scaffolds,3D printer,Aggregated artificial neural network (AANN),Particle swarm optimization (PSO),Porous structure,Mechanical strength,

@&#ABSTRACT@&#
Fabrication of three-dimensional structures has gained increasing importance in the bone tissue engineering (BTE) field. Mechanical properties and permeability are two important requirement for BTE scaffolds. The mechanical properties of the scaffolds are highly dependent on the processing parameters. Layer thickness, delay time between spreading each powder layer, and printing orientation are the major factors that determine the porosity and compression strength of the 3D printed scaffold.In this study, the aggregated artificial neural network (AANN) was used to investigate the simultaneous effects of layer thickness, delay time between spreading each layer, and print orientation of porous structures on the compressive strength and porosity of scaffolds. Two optimization methods were applied to obtain the optimal 3D parameter settings for printing tiny porous structures as a real BTE problem. First, particle swarm optimization algorithm was implemented to obtain the optimum topology of the AANN. Then, Pareto front optimization was used to determine the optimal setting parameters for the fabrication of the scaffolds with required compressive strength and porosity. The results indicate the acceptable potential of the evolutionary strategies for the controlling and optimization of the 3DP process as a complicated engineering problem.

@&#INTRODUCTION@&#
Additive manufacturing (AM) is a layer-over-layer manufacturing technique. In most cases, enables complex components to be manufactured that are difficult to fabricate or cannot be made using conventional methods. Among AM practices, powder-based three-dimensional printing (3DP) is the most capable technique for bone tissue engineering (BTE) applications [1–6].Seeding and cultivating scaffolds with bone cells is the standard method in BTE. Scaffolds are highly porous 3D structures that aim to imitate the natural extracellular matrix (ECM) of bone on a temporary basis. From a technical point of view, scaffold engineering sets high demands on design and materials. In addition to chemistry, interconnected porosity, permeability, and mechanical strength are critical parameters that define the performance of a scaffold. These factors cannot be controlled precisely through conventional fabrication processes [7–9].The immense potential for fabrication of scaffolds due to its maximum control over porosity and its ability to reproduce the customized anatomical design with great fidelity to the 3D medical pictures are the main advantages of the powder-based 3DP [10–12].Fig. 1shows a schematic illustration of the 3DP process. First, the chosen physical object is modeled on a computer-aided design (CAD) system. Then, the CAD model is converted to the stereolithography (STL) file format. A software program analyzes the STL file and mathematically slices the model into cross sections based on the selected layer thickness. The cross sections are recreated using the reaction of the powder and the binder. This process is repeated layer by layer until a 3D object similar to the design is formed. During the fabrication process, the printer head jets a liquid into thin layers of powder according to the object profile created by the software. Subsequently, a build chamber (build-bed) containing the powder bed is lowered to enable the spreading of the next powder layer. Following the consecutive application of layers, the unbound powder is removed, and the 3D part is produced [13–17]. Setting the 3DP process parameters is a complex and time-consuming task, as there are many variables that influence the printed part quality for particular applications. In many cases, these variables conflict with each other. In recent years, many reports have been made on the 3DP fabrication of BTE scaffolds, and its critical process factors and parameters [18–22]. Many studies have focused on improving the dimensional accuracy (DA) and mechanical properties of 3D-printed objects and have shown sensitive process parameters that can be tuned to improve the desired attributes. These characteristics are related to the process parameters and can be improved with proper adjustment [4,19,20,23–25].Although a number of successful production experiments have been conducted, the quality assessment of fabricated parts remains to be one of the main challenges. Factors influencing quality have been studied through diverse indicators. However, a significant amount of work has not focused on mechanical properties and porosity together for the fabrication of tiny pores on scaffolds in the application of BTE. The cost of the end products of the process is high. Therefore, from a technological and economic point of view, selecting the process parameters for the optimization of manufactured parts is highly essential. In the context of the 3DP process optimization for improving the performance of the prototype, the soft computing method is a promising approach to monitor and model the process based on physical understanding and experimental data [26].Achieving the optimal process parameters for fabricating 3D parts using the experimental tests is a time-consuming and costly approach. Numerical models of the process can be effective tools in finding the appropriate process parameters according to the demanded characteristics. From the physical modeling point of view, the 3DP process is complex. Many physical phenomena (e.g., powder and binder reaction and removing unbound powder) affect product quality. Based on the author's experiments and analysis, it has been observed that the relation between the porosity and compression strength of the porous structures and the influential parameters are nonlinear and uncertain. On the other hand, it is a very formidable task to provide an authentic and exact physics-based mathematical formulation, which can effectively represent the effect of layer thickness, delay time between spreading of each powder layer and printing orientation on the porosity and compression strength of the porous structures. Solving all the related governing equations using the analytical or numerical methods to obtain a mathematical model of the 3DP process is not only difficult but may also be impossible. To overcome this problem, the best way is to use a soft method to obtain a data-driven mapping system to approximately analyze the destined properties of the porous structures. Many researchers prefer to use semi-experimental models instead of numerical models to model the physical process, such as the 3DP process. Artificial neural network (ANN) [27–30], fuzzy system [31,32], Hammerstein–Wiener [33,34], time series [34], and Kalman filter are some of the well-known methods for establishing an experimental model of a system based on the available experimental data. To select a soft method which can be reliably used for this case study, the authors considered several techniques and conducted a primitive study such as neural networks, polynomials, splines, and etc. Published papers on ANNs suggest that this modeling methodology is a promising alternative tool for process modeling [35–40]. This method can overcome conventional modeling difficulties as it has the advantages of ease of implementation and capability of constructing a complex nonlinear map between inputs and outputs of a system. A few studies have been conducted on ANN modeling of the 3DP process. This research aims at developing an experimental based predictive model for the 3D printing process using the aggregated artificial neural network (AANN) method. The AANN algorithm is one of the well-known variants of the neural networks models which has been used in many engineering applications [41–45]. Aggregating multiple neural for improving the generalization of neural networks, is its main contribution. Many researchers have shown that a more accurate predictive model can be obtained in comparison with a single neural network with the same number of neurons by aggregating several neural networks [46,47]. Finding a single neural network that can model a highly uncertain complex engineering phenomenon is often difficult. The major drawbacks of these artificial machines often result from over fitting and high computational complexity. Combining a set of independent networks as cooperative learnable agents appear to be a promising strategy in enhancing the robustness and generalization of these artificial machines. Another promising aspect in designing a modeling machine is to find a system that can handle more than one task simultaneously. To the knowledge of the authors, ensemble artificial machines are best suited in this case, as a single network may concentrate on modeling a specific task while neglecting others. The predominance of AANN for modeling multi-output phenomena is reported in many studies [46]. In the recent study of Furtuna et al. [47], they developed a stacked neural network (SNN) and an evolutionary hyper-heuristic method for the optimum modeling of a complex chemical process. Their results imply the obvious advantages of AANNs for modeling complex engineering application. Selecting the best topology is the main drawback of AANN. For training an AANN it is needed to select the number of neural networks, number of neurons and hidden layers in each neural network. However, no convenient approach exists for the optimal design of these systems. Many researchers have proposed different methods for grasping an optimal topology for AANNs. Zhou et al. [46] applied a simple genetic algorithm (named GASEN) and showed that GASEN could generate an aggregated neural network with a far smaller size and stronger generalization ability compared with other common techniques. In another study, they developed a non-dominated sorting genetic algorithm as a high-level heuristic algorithm and a well-known back propagation method called quasi Newton training as a low-level heuristic algorithm for optimizing the structure of AANN [47]. They reported the effectiveness of their method, but it had some limitations, such as high computational time and complexity.In this study, meta-heuristic algorithms are used as supervised algorithms for finding the stage of the optimum topology of the AANN. Meta-heuristic algorithms are population-based artificial methods that are widely used to handle real-life and hard nonlinear engineering problems [48,49]. These algorithms that initiate the natural evolutionary mechanisms have many advantages compared with the conventional methods. The particle swarm optimization (PSO) algorithm is the selected algorithm for constructing the optimal topology of the AANN. To select PSO, the authors considered some potential training methods, such as PSO, GA, ABC, and FA. It was observed that PSO has a very high computational speed and does not result in a computational stagnation. This is not the case when using GA and ABC which have relatively complicated algorithmic structures, and should activate so many exploration/exploitation operators at each iteration. Given the fact that training AANN is a time-consuming task, and PSO can effectively balance the exploration and exploitation over the searching period, it was selected as the fit algorithm for evolving the architecture of AANN. Furthermore, the authors’ experiments revealed that, at-least for the current case study, PSO could afford the best results as it is just related to inertia weight and can converge to an acceptable solution in a logical period of time. This was not the case when we used GA and ABC. For AG, several parameters, e.g. number of elite chromosomes, mutation probability and crossover probability and etc., would be taken into account, which result in a complex optimization algorithm. The same observation was valid for ABC in which there was a need for fine-tuning of several parameters, such as number of employed and onlooker bees and number of limits for abounding, a cite. Moreover, the simulations clearly demonstrated that PSO can show a faster and much robust exploration/exploitation over the procedure, and also can guarantee the convergence to a near optimum structure for AANN, which was not the case when using the other methods. Such observations have brought the authors to the conclusion that, in spite of its simplicity, PSO is the most logical choice for evolving the architecture of AANN.The main objective of the present study is to develop the best AANN model to analyze the nonlinear effect of 3D printer machine parameters on the compressive strength and porosity of printed porous structures, which is one of the more widely challenging aspects of printing scaffolds. To the best knowledge of the authors, using an aggregated structure has not been proposed before for the considered case study. This is when it is highly necessary to make sure the developed soft sensor possesses an acceptable generalization, as the number of data points is often limited for such applications and there is a possibility for over fitting or under fitting, which makes the soft-sensor unreliable for unseen data (testing phase). In this way, the experiments of the current study take a stride toward indicating that the aggregated structures are best suited for applications the same of Scaffold modeling in which it is not easy to gather a rich database, and it takes a long time (even years) to come up with an exhaustive database which can be fed to simple soft models, such as NN and ANFIS. The rest of the paper is organized as follows. In Section 2, the structure of the 3D printing and its parameters are presented brieﬂy. The aggregated artificial neural network and its structure are introduced in Section 2.4. In Section 2.5, the authors provide the stepwise explanations of the particle swarm optimization algorithm. The experimental and numerical results are given in Section 3. Finally, the paper is concluded in Section 4.Previous studies show that among the various process parameters, the printing direction (axial direction aligned with the x, y, and z directions of the printing build-bed) of a part seems to have the greatest impact [25,50]. The adequate pore size for BTE is generally reported to be in range 100–800μm for cell attachment and vascularization [51]. The ability of a 3D printer to fabricate a minimum geometrical size is restricted by the powder particle size, which determines the thinnest layer thickness. In 3DP processes, layer thickness refers to the height of the powder bed that is spread along the z-axis during the procedure. The typical layer thickness is generally at least twice the powder particle size dimension, which is approximately 100μm [3,52]. Therefore, one of the important factors for building the tiny pore size of engineered scaffolds is layer thickness [18,19]. Furthermore, spraying the binder drops causes shear forces that are applied to the top layer of the powder bed. As a result, the thin printed structures may be displaced, possibly affecting the integrity and accuracy of the printed object. Mechanical features may also be affected, and thus another important factor is stability of the pre-deposit powder layer during the reaction between powder and binder [53,54]. Therefore, adequate time between spreading one layer and jetting the binder to start spreading the next one to relax and desensitize the powder and the binder is another important factor. We refer to this delay as the delay time. Increasing the powder delay time, particularly in pores and channels, results in further densification. Added time can also affect layer-to-layer bonding, which will consequently affect the mechanical and dimensional features of the specimens. Therefore, finding adequate time for the fabrication of small-scale parts is challenging.In this study, a scaffold was considered as a cylindrical structure shaped by an extruding cut by small cubicle elements that determine the pore and strut size. Scaffold prototypes with 12mm height, 6mm diameter, 0.8mm pore size, and 0.6mm strut size were designed using the 3D design software SolidWorks®2012 and exported as an STL file. The height and the diameter circumscribed the number of pores, so the porosity of CAD model was 45.04%. The geometry of the scaffolds was chosen as it represents the typical feature sizes found in the BTE scaffolds. Fig. 2presents the CAD model of the scaffolds.The 3D-printing machine Zprinter®450 (Z-Corporation, Burlington, USA) was used to produce the prototypes. A high-performance composite material (Zp150) and a water-based binder (Zb63) were also supplied by Z Corporation [50,55]. After printing, all the samples were dried for 90min in the machine at the ambient temperature. Then, the printed porous bodies were de-powdered with compressed air to remove any trapped and unbound powder. In this study, the authors avoided any further post hardening or infiltration.The 3DP process parameters examined in this study were layer thickness, delay time in spreading a new layer, and build orientation. All other machine setting parameters were the same as the default, and the binder saturation core and shell for all runs were considered 100%.An experiment plan based on a full factorial design of experiments (DOE) was used to print the scaffold prototypes. Layer thickness was selected from four possible values of 89, 102, 114, and 127μm. The chosen delay times were 50, 100, 300, and 500ms, and X, Y, and Z were considered as part orientations.A porous scaffold is required in BTE to act as an ECM and guide for cell proliferation, differentiation, and eventual tissue growth. Fluid flow through a bone scaffold (permeability) is an important factor because of its ability to build living tissue. Successful BTE depends on the scaffold's ability to enable nutrient diffusion and waste removal from the regeneration site, as well as to provide an appropriate mechanical environment. In other words, maximum permeability is needed as far as the mechanical properties are not compromised. Therefore, a trade-off exists between these two requirements [56].Note that only open and interconnected pores contribute to permeability and cell in-growth, whereas closed pores only reduce the strength. In conclusion, we need to minimize the closed porosity and maximize the open porosity in a way that the mechanical properties (strength and modulus) are not compromised.For the reconstruction of complex bone defects such as osteoporotic fractures, patient-specific BTE implants with a proper internal structure and mechanical properties are needed. Therefore, from the fabrication point of view, maximum compressive strength, maximum fidelity with the CAD design (DA), and maximum permeability are needed to print such a scaffold. These features were used to evaluate the quality of the printed scaffolds for all DOE test samples.The diameter and the height of the fabricated samples were measured using a Mitutoyo digital caliper at the smallest measurement of 0.01mm. In this study, we considered the degree of anisotropy as another factor for evaluating the DA. Here, a DA of 0 corresponded to fully isotropic samples and tended toward 1 as the samples became increasingly anisotropic. The DA values were reported by CT-analyzer software. The scanner used in the experiments was a high-resolution, compact desktop unit (SkyScan In Vivo X-ray 1076, Belgium). As the CAD design was symmetrical, a printed scaffold with a lower DA would possess a greater DA than a sample with a larger DA.Uniaxial compressive testing was conducted using an Intron 5848 Micro Tester (USA) instrument with a 10 KN load-cell and crosshead-loading rate 0.5mm/min−1. Nine specimens of each DOE test run were tested.The porosity was reported by SkyScan micro-CT's 3D analysis software (SkyScan In Vivo X-ray 1076, Belgium). The resolution of the scanner was set to 18μm, and aluminum (0.5mm) was set as a filter. The region of interest was considered at 6×6. Almost 700 scan slices were taken for each specimen.This section discusses the structure of the proposed model. As previously mentioned, the AANN model was used as the structure for predicting the model, and the experimental data were used for training it.The standard topology of AANN is shown in Fig. 3. It is composed of several single feed-forward neural networks, the outputs of which are added together with some weighting coefficients.An important factor in designing the AANN is to find the fittest weighting coefficients in a manner that AANN has the best performance (minimum of prediction error) and the lowest complexity (minimum size) simultaneously. The generalized performance of a neural network is expressed as the following formula:(1)Error=MSEtrain+MSEtest,where MSEtrain and MSEtest are the mean squared errors in the training and testing steps. Zero is the ideal performance. However, in many practical applications, obtaining exactly zero error is impossible, and the authors expect an acceptable generalization from a network with error closer to zero. The mean squared error is defined as(2)MSE=1Nt⋅No⋅∑j=0No∑i=0Nt(dij−yij)2,where No is the number of AANN outputs, and Nt is the number of training or testing data. Parameters Y and d represent the actual output of AANN and the desired AANN output (target), respectively. Each individual neural network estimates the compressive strength and open porosity independently, and the actual outputs of AANN are derived from a linear superposition of these independent outputs. These independent outputs are accumulated mathematically to form the actual outputs as(3)yj=∑k=0NNnowjk⋅yjk,where yjis the jth the output of the stacked neural network, NNno is the number of independent networks, and wjkand yjkare the jth weight and output of the kth independent neural network, respectively.Computational complexity is one of the objective values in designing an AANN. Reducing the computational complexity is equivalent to designing a network with the lowest number of neurons in the hidden layers. Therefore, the following criterion is defined as a metric of complexity:(4)Complexity=∑k=0NNnoHnk,where Hnkis the number of neurons in the cat independent neural network.To obtain a model with the lowest prediction error and computational complexity, the authors define the following total objective function:(5)minF1:f(NNno,wjk,Hn)=γ(MSEtrain+MSEtest)+(1−γ)∑k=0NNnoHnk,where γ is the scaling factor between [0,1] which represents the degree of importance of each objective function. The lowest value of γ means that complexity is more important than the prediction error. In this paper, since a limited amount of actual data is available, so complexity is as important as efficiency. It is noteworthy, as the complexity increases there are more possibilities for over fitting. Thus constant value for γ=0.5 is considered.The correlation between the actual and the desired output data is another important factor in designing an AANN. The training procedure should be done in such a way that the highest correlation value occurs between the actual and the desired data. For this purpose, a minimum acceptable value of correlation is imposed on the training phase as a constraint. The mathematical expression of the correlation is as follows:(6)r=1No⋅∑j=0No∑i=0Nt(yij−y¯j)(dij−đj)∑i=0Nt(yij−y¯j)2∑i=0Nt(dij−đj)2(7)0.9<r<1where r is the correlation,y¯jis the average of the actual values obtained in the processing element j of the neural network output, and đjis the average of the desired values for the processing element j of the neural network output.Before entering the training phase, these experimental data were normalized according to the following equation:(8)ui=2upi−lbiui−12(lbi+ubi),i=1,2,3where upi, ui, lb and ubiare actual input, normalized input, lower bound, and upper bound of the ith input, respectively. It is worth noting that the upper bound and lower bound values are the maximum and minimum values of actual input data. Using the above equation, the acceptable range of the inputs is between [−1,1]. The same preprocessing procedure is conducted for the outputs.The PSO algorithm is a population-based soft computing technique that has attracted the attention of many researchers in solving applied engineering optimization problems. This algorithm, which is based on the behavior of a swarm of ants, a flock of birds, or a school of fish, mimics their social behavior in finding food or their actions in encountering danger. This social behavior can be used in developing modern optimization algorithms. Kennedy and Eberhart [57] originally proposed the PSO algorithm in 1995.In this algorithm, each solution of the optimization algorithm is considered a particle, and a swarm of particles located randomly in the feasible searching domain is initially selected. These particles (i.e., candidate solutions) are updated using an evolutionary mechanism to obtain a better solution. The proposed evolutionary mechanisms are similar to what happens in nature. In nature, each particle tends to act similar to its best experience in life and moves to the best successful experience of its neighbors. These two behaviors, which are called exploration and exploitation, respectively, can be computationally implemented as follows.In the PSO algorithm, for an optimization problem min f(x), each particle is presented by its position vector as(9)xij(t)=[xij]=[xi1,xi2,…,xi(n−1),xin],i=1,2,…,N,j=1,2,…,nwhere t is the generation time, xijis the jth variable of ith particles, N is the swarm size, and n is the searching space dimension.xi(t) is the solution of the optimization problem, and the swarm is a set of swarm={x1,x2, …,xN}.To formulate the evolutionary mechanism, a velocity vector is assigned to each particle as follows:(10)vi(t)=[v1i,v2i,…,v(n−1)i,vni],i=1,2,…,N,wherevi(t) is the velocity of the ith particle. This velocity specifies the updating direction and updating rates of each particle position. The particles are assumed to move iteratively within the search space.The best experience of each particle up to time t is stored in a variable called best position and is expressed aspi(i)=[p1i, p2i, …, p(n−1)i, pni]. The set {p1,p2, …,pN} is a memory set that shows the best positions of the swarm explored by each particle. Evidently, the best position with the lowest fitness function value of this set becomes the global best solution of the minimization problem. This global minimal position is represented byPg(t) and is computed as(11)pg(t)=argmin(f(pi)).iIn a classic variant of the PSO, the updating rule is mathematically expressed as follows:(12)vi(t+1)=w⋅vi(t)+c1⋅R1⋅(pi(t)−xi(t))+c2⋅R2⋅(pg(t)−xi(t)),where w is the weighting coefficient, c1 and c2 are the cognitive and the social acceleration coefficients, respectively, and R1 and R2 are the two random numbers uniformly distributed within [0,1].According to the relation (12), the weighting coefficient w gives the inertia behavior to the motion of the particle. Higher values of w result in more exploration behavior, whereas a lower value increases the exploitation performance. This parameter should be controlled during the generation time. After updating the velocity of the particle, each particle adjusts its current position using the following relation:(13)xi(t+1)=xi(t)+vi(t+1),i=1,…,N.In this paper, PSO with constant inertia weight has been used and the AANN structural parameters considered as particle parameters in swarm. In fact, each particle create AANN network and return network error (Eq. (5)) as PSO min function.(14)minF1:f(NNno,wjk,Hn)=γ(MSEtrain+MSEtest)+(1−γ)∑n=0NNnoHnnγ=0.5xi(t)=[NNno,Wm_,Hnn_]i,i=1,2,…,N,m=1,2,…,2×NNno,n=1,2,…,NNnowhere NNno is the number of single neural networks,Wm_is the number of weighting coefficients and Hnnis the number of hidden layers for each single neural network. Topology of AANN, coefficients and the hidden layers are depicted at Fig. 3. More details are given in next Section.

@&#CONCLUSIONS@&#
