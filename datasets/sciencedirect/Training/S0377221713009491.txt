@&#MAIN-TITLE@&#
Dynamic programming algorithms for the bi-objective integer knapsack problem

@&#HIGHLIGHTS@&#
A property of the traditional dynamic programming algorithm is identified.The first algorithm is developed by directly using the property.The second algorithm is developed by using the property in conjunction with the bound sets.Insufficiency of linear relaxation solutions to estimate an upper bound set is identified.An extended upper set is proposed on the basis of the set of the linear relaxation solutions.

@&#KEYPHRASES@&#
Multi-objective optimization,Integer knapsack problems,Dynamic programming,Bound sets,

@&#ABSTRACT@&#
This paper presents two new dynamic programming (DP) algorithms to find the exact Pareto frontier for the bi-objective integer knapsack problem. First, a property of the traditional DP algorithm for the multi-objective integer knapsack problem is identified. The first algorithm is developed by directly using the property. The second algorithm is a hybrid DP approach using the concept of the bound sets. The property is used in conjunction with the bound sets. Next, the numerical experiments showed that a promising partial solution can be sometimes discarded if the solutions of the linear relaxation for the subproblem associated with the partial solution are directly used to estimate an upper bound set. It means that the upper bound set is underestimated. Then, an extended upper bound set is proposed on the basis of the set of linear relaxation solutions. The efficiency of the hybrid algorithm is improved by tightening the proposed upper bound set. The numerical results obtained from different types of bi-objective instances show the effectiveness of the proposed approach.

@&#INTRODUCTION@&#
The multi-objective integer knapsack problem (MOIKP) is one of the most widely studied multi-objective combinatorial optimization problems where every solution is evaluated according to two or more objectives (Ehrgott, 2005). Most real-life decision problems have to deal with several conflicting criteria which must be optimized simultaneously. MOIKPs can be encountered in a wide range of applications such as capital budgeting (Klamroth & Wiecek, 2000; Kwak, Shi, Lee, & Lee, 1996; Rosenblatt & Sinuany-Stern, 1989), selection of different investment projects (Alanne, 2004; Bas, 2011; Teng & Tzeng, 1996), or relocation issues arising in nature conservation (Kostreva, Ogryczak, & Tonkyn, 1999), or pollution issues for remediation planning (Jenkins, 2002).A MOIKP can be defined as follows. Consider a knapsack capacity, W, and a set of n items where each itemj(j=1,…,n)is associated with a weightwjand r profit values,cjk, one per objectivek(k=1,…,r); each item j has a number of copies (only bounded by⌊W/wj⌋) available. The problem consists of determining the number of copies for each item such that the overall weight does not exceed W and the total profits are maximized in a Pareto sense. The MOIKP can also be stated as a multi-objective integer linear programming model as follows:(MOIKP)vmax∑j=1ncj1xj,…,∑j=1ncjrxjs.t.∑j=1nwjxj⩽W,xj⩾0,integer,j=1,…,n,wherexjare decision variables indicating the number of copies for thejthitem placed in the knapsack. It is assumed thatW,wj(⩽W)andcjk(j=1,…,n,k=1,…,r)are positive integers.Letfk(x)=∑j=1ncjkxj,k=1,…,r. Solving the MOIKP is interpreted here as generating its efficient setXEin the decision spaceX⊆Rnand the corresponding imageYN=f(XE)in the objective spaceRr, called the non-dominated set or the Pareto frontier (PF).The dominance relations are defined based on the componentwise ordering ofRr. Fory1,y2∈Rr,y1⩾y2⇔yk1⩾yk2,k=1,…,ry1⩾y2⇔yk1⩾yk2,k=1,…,randy1≠y2y1>y2⇔yk1>yk2,k=1,…,r.The relations≦,⩽and<are defined accordingly.f(x¯)∈Rris dominated byf(x)∈Rriff(x)⩾f(x¯).XE={x∈X:thereexistsnox¯∈Xwithf(x¯)⩾f(x)}In a multi-objective combinatorial optimization context, the computational effort for identifying the PF is large because the problem of determining whether a given objective vector (outcome) is dominated or not isNP-hard (Serafini, 1986) even though the underlying single objective optimization problem can be solved in pseudo-polynomial time. For a given number of objectives, a multi-objective optimization with 0-1 decision variables is much easier to handle than the problem with general integer variables because the problem structure of the former is simpler and combinations of the decision variables for the former are fewer. Therefore, algorithms for solving the 0-1 multi-objective knapsack problem (MOKP) are relatively abundant when compared with algorithms especially designed for the MOIKP.The 0-1 MOKP as well as the MOIKP fall into the category of multi-objective integer problems. Thus, the resolution of the MOIKP can benefit from the algorithmic developments of both the 0-1 MOKP and the multi-objective integer problem. The literature in the field includes exact and approximate approaches. The former are targeted to find the exact PF while the latter aim at approximating the PF. Exact approaches include dynamic programming (DP) algorithms (Bazgan, Hugot, & Vanderpooten, 2009a; Captivo, Clímaco, Figueira, Martins, & Santos, 2003; Delort & Spanjaard, 2010; Figueira, Tavares, & Wiecek, 2010; Figueira, Paquete, Simões, & Vanderpooten, 2013; Rong & Figueira, 2013; Rong, Figueira, & Pato, 2011; Villarreal & Karwan, 1981), branch-and-bound (BB) algorithms (Florios, Mavrotas, & Diakoulaki, 2010; Mavrotas & Diakoulaki, 2005; Mavrotos, Figueira, & Antoniadis, 2011; Ponte, Paquete, & Figueira, 2012; Visée, Teghem, Pirlot, & Ulungu, 1998), and other exact methods as for example the following ones: exact algorithms that exploit the development for multi-objective linear programs (Jolai, Rezaee, Rabbani, Razmi, & Fattahi, 2007), greedy optimal algorithms (Gorski, Paquete, & Pedrosa, 2012) for a special class of multi-dimensional knapsack problems with binary weights, exact algorithms based on a partition of the search space (Dhaenens, Lemestre, & Talbi, 2010) and algorithms (Laumanns, Thiele, & Zitzler, 2006; Mavrotas & Florios, 2013; Özlen & Azizoğlu, 2009; Przybylski, Gandibleux, & Ehrgott, 2010; Sylva & Crema, 2004, 2007; Zhang & Reimann, 2014) resorting to the scalarization techniques (Ehrgott, 2005) such as weighted-sum method andε-constraint method as well as a general approach for preserving the lexicographic order of efficient solutions in the decision space (Schweigert & Neumayer, 1997). Approximate approaches include polynomial approximation schemes (Bazgan, Hugot, & Vanderpooten, 2009b), tailored heuristics (Zhang & Ong, 2004; Mavrotas, Figueira, & Florios, 2009; Köksalan & Lokman, 2009), and metaheuristics (Alves & Almeida, 2007; Aytgˇ & Sayin, 2009; Ben Abdelaziz, Kirchem, & Chaouadi, 1999; Gandibleux & Fréville, 2000; Gomes da Silva, Clímaco, & Figueira, 2006, 2004; Gomes da Silva, R Figueira, & Clímaco, 2007; Jaszkiewicz, 2004). The interested readers can also be referred to several comprehensive surveys (Ehrgott & Gandibleux, 2000; Jones, Mirrazav, & Tamiz, 2002; Ulungu & Teghem, 1994) for both exact and approximate approaches.Research on multi-objective integer problems dates back to more than three decades ago when Villarreal and Karwan (1981) proposed both basic and hybrid DP approaches. These authors also proposed for the first time the concept of bound sets for the hybrid approach. A bound set consists of a set of bounds, which helps in discarding dominated outcomes in multi-objective combinatorial optimization problems. Very recently, an operational way to compute bound sets has been devised based on the convex hull of the image of solutions in the objective space (Ehrgott & Gandibleux, 2007; Sourd & Spanjaard, 2008). For the 0-1 bi-objective knapsack problem, Delort and Spanjaard (2010) and Ponte et al. (2012) applied the concept of bound sets to develop a DP algorithm and a BB algorithm respectively. Similarly, Figueira et al. (2013) applied the concept of bound sets to improve the solution efficiency for DP algorithms.However, for the MOIKPthe upper bound set was only defined conceptually in Villarreal and Karwan (1981) and there was no efficient operational way to compute the upper bound set. Overall, the algorithm development for the MOIKP advances much more slowly when compared with the 0-1 MOKP. In Klamroth and Wiecek (2000), conceptually DP network approaches for different variants of MOIKP were proposed. In Figueira et al. (2010), an implementation of the generic labeling algorithm for the MOIKP and several network models were considered. Very recently, several reduction techniques were introduced in Rong and Figueira (2013) for improving the solution efficiency for the bi-objective integer knapsack problem.The current research aims at generating the exact PF for the bi-objective integer knapsack problem (BOIKP) using bound sets in the DP algorithm context. Different from Delort and Spanjaard (2010), the bound sets are applied with the multi-objective DP algorithm for solving the original BOIKP directly instead of using the single-objective DP algorithm for solving a sequence of weighted-sum problems in a two-phase framework. In addition, the way of designing bound sets is different. Delort and Spanjaard (2010) did not directly use the set of feasible solutions (the solution of the problem refers to the outcome in the objective space throughout the paper) as a lower bound set considering the non-convexity of the PF. The authors extended the set of feasible solutions to increase the threshold of discarding partial solutions so that promising partial solutions can be kept. The current study directly uses the set of feasible solutions as a lower bound set and guarantees that the promising partial solutions can be kept by extending the set of linear relaxations (upper bound set).The contributions of the paper can be summarized as follows. First, the numerical experiments showed that for a given partial solution associated with a non-dominated outcome of the problem (promising partial solution), the bound set estimated by the set of linear relaxation solutions of the subproblem cannot always provide a proper upper bound set to guarantee that it is kept during the solution process. Then an extended upper bound set is proposed on the basis of the set of linear relaxation solutions. Second, a property of the traditional DP algorithm for the MOIKP is newly identified in the current research. The first new DP algorithm is developed by directly using the property. The main difference between the new and the traditional DP algorithms (the best algorithm in Figueira et al. (2010)) is that the new algorithm can reduce significantly the number of nodes to aggregate at the last time-consuming aggregating stage. Usually, for the multi-objective DP algorithm, the complete non-dominated set for the problem cannot be obtained at a single node. In stead, it needs to be obtained by a union operation of the outcomes for the nodes at the last stage of the DP process (Figueira et al., 2010). The second hybrid algorithm is developed by using the property in conjunction with bound sets. The property is used to reduce the number of the recorded nodes during the DP process and the above proposed bound set is tightened by controlling the extent to which the linear relaxation solutions are extended.The paper is organized as follows. Section 2 introduces a property of the DP algorithm for the MOIKP. Section 3 discusses the bound sets for the BOIKP. Section 4 describes the DP algorithm using the bound sets. Section 5 reports the numerical results for the bi-objective instances. A comparison with different benchmark algorithms is provided.DP (Bellman, 1957) is an optimization approach that decomposes a complex problem into a sequence of simpler subproblems. It can be considered as a recursive process, which interprets an optimization problem as a multi-stage decision process. Associated with each stage of the optimization problem are the states of the process. The state is a way to describe a solution of the subproblem, which contains enough information to make future decisions without the need for checking how the process reached the current state. Finally, a recursion optimization procedure is set up to describe the transition from state to state so that the solution of the problem can be obtained by solving multi-stage subproblems sequentially. There are different representations of the states as well as the transitions between the states for the MOIKP, see Klamroth and Wiecek (2000) and Figueira et al. (2010). Below the basic sequential DP (BDP) network is discussed, which is in essence the same as the network model IV in Figueira et al. (2010) without considering the source node ‘s’. In later sections, the hybrid DP algorithm using the bound set is developed on the basis of the BDP procedure.LetG=(N,A,c)be a directed connected network, whereNis the set of nodes andA⊆N×Nis the set of arcs; the arc from node i to node j is denoted by (i,j) and the values associated with the arc (i,j) are represented by an r dimensional vectorc(i,j)=(c1(i,j),…,cr(i,j)). A state corresponds to a node, the transition from state to state at different stages corresponds to a directed arc. The following bi-objective example is used to illustrate the BDP network.vmax(5x1+4x2+8x3,15x1+11x2+3x3)s.t.5x1+4x2+2x3⩽10,xj⩾0,integer,j∈{1,2,3}.The BDP procedure consists of n stages, namely,α=1,…,n. Each stageαcorresponds to a single variable whose value is determined. The set of node positions at stageα, denoted asNαis determined byNα-1andwαwith|Nα-1|⩽|Nα|⩽(W+1),α=2,…,n. Letαtdenote the node at thetthposition at stageα(α=1,…,n,0⩽t⩽W). In the BDP procedure, t (node weight) represents the sum of the weight of items placed in the knapsack. The transitions between the nodes can be described as follows. Any node(α-1)tis connected to nodeαt, which in turn is connected to nodeαt+wαift+wα⩽W. i.e., nodeαtis connected to both node(α-1)tand nodeαt-wαift-wα∈Nα. It means that all the nodes (αtandαt+wα,0⩽t⩽W-wα) at the same stageαare connected to each other in sequence like a chain. The arc values related to the r profit objectives are given by (cα1,…,cαr) between the nodes at the same stageαand by (0,…,0) between the nodes at two consecutive stagesα-1andα. There is an aggregate stage with one node ‘A’ after stage n, which collects the non-dominated outcomes of stage n. LetS(αt)denote the set of non-dominated outcomes at nodeαtandmα=⌊W/wα⌋, then the recursive equations in the DP procedure can be represented as follows.At the first stageα=1, the initial values of the nodes are assigned.(1)S(1t)={(tc11,…,tc1r)},t=0,…,m1.For the subsequent stageα=2,…,n, there are three cases for determining the non-dominated set of node.(2)S(αt)=S((α-1)t),0⩽t⩽W,t∈Nα-1,t∈Nα,t-wα∉Nα.(3)S(αt)=(cα1,…,cαr)⊕S(αt-wα),wα⩽t⩽W,t∉Nα-1,t∈Nα,t-wα∈Nα.(4)S(αt)=NDS((α-1)t)∪{(cα1,…,cαr)⊕S(αt-wα)},wα⩽t⩽W,t∈Nα-1,t∈Nα,t-wα∈Nα.For the aggregate stage,(5)S(A)=ND⋃t∈NnS(nt)In formulas (3) and (4), the operator ‘⊕’ means the addition operation is applied over all the elements ofS(αt-wα), i.e.,(cα1,…,cαr)should be added to each element of the set. In formulas (4) and (5), the operator ‘ND’ takes the non-dominated outcomes of the operating set.Theorem 1For the BDP network, ifmα=⌊W/wα⌋⩾1,α=1,…,n, then any element inS(αt′)with0⩽t′⩽W-wαis dominated by at least one element inS(αt)withW⩾t>W-wα, wheret-t′=swα,s>0and integer.At stage 1, only one node1m1witht>W-w1, the elements at all the nodes1t′with0⩽t′⩽W-w1are dominated by the element at node1m1according to formula (1).For the subsequent stageα=2,…,n, according to the BDP procedure in Section 3.1,∀t′∈Nα,0⩽t′⩽W-wα, the related node is connected to a node with positiont′+wα, which is eventually connected to a node with positionW⩾t>W-wα. Thus, it is sufficient to show that(6)S(αt)=NDS(αt-wα)∪S(αt),wα⩽t⩽W.IfS(αt)is determined by formula (3), formula (6) trivially holds because any element inS(αt-wα)is dominated by at least one element in{(cα1,…,cαr)⊕S(αt-wα)}.IfS(αt)is determined by formula (4), two cases need to be considered. In the first case, if all the elements in{(cα1,…,cαr)⊕S(αt-wα)}are inS(αt), then formula (6) trivially holds because any element inS(αt-wα)is dominated by at least one element in{(cα1,…,cαr)⊕S(αt-wα)}no matter how many elements inS((α-1)t)remain inS(αt). In the second case, if some or all elements in{(cα1,…,cαr)⊕S(αt-wα)}are excluded fromS(αt), it means that the excluded elements are dominated by at least one element inS((α-1)t), which for sure dominates at least one element inS(αt-wα). Then formula (6) holds because any element inS(αt-wα)is either dominated by an element inS((α-1)t)or an element in(cα1,…,cαr)⊕S(αt-wα).IfS(αt)is determined by formula (2) thenS(αt)will evolve according to either formulas (3) or (4) later whent⩽W-wαwhileS(αt)remains unchanged whent>W-wα. These two categories of nodes are independent of each other. For any node witht⩽W-wα, there should exist some other nodes witht>W-wα, whose elements dominate the elements of the nodes with0⩽t′⩽W-wα,t-t′=swα,s>0and integer. □At the aggregate stage of the BDP algorithm, only the nodes with positionsW⩾t>W-wnneed to be considered to obtain the complete non-dominated set of the MOIKP.An improved BDP procedure can be obtained by aggregating the results of the nodes with positions larger thanW-wnat stage n. At mostwnnodes need to be considered. For the BDP procedure, the computational effort of the aggregate stage accounts for a large portion of solution time. Thus, applying Corollary 2 can improve the solution time efficiency of the traditional BDP algorithm significantly without increasing the memory requirements, especially when the items are ranked according to a non-increasing order of item weight.Fig. 1illustrates the BDP network, where the nodes in grey at each stage are dominated nodes. However, these nodes have to be generated in sequence because the non-dominated outcomes of the stage are derived on the basis of these nodes. At the aggregate stage, only the last two nodes at stage 3 with positions larger thanW-w3=10-2=8need to be considered for the improved BDP procedure. In addition to improving the solution time efficiency of the BDP procedure, Theorem 1 can help to reduce the number of nodes stored in hybrid DP algorithm using the bound set (refer to the later discussion).The concept of bound sets for the multi-objective combinatorial optimization can be viewed as an extension of the concept of upper and lower bounds for the single objective optimization. Bound sets consists of a set of bounds, which help to prune partial solutions that cannot lead to a new non-dominated outcome of the multi-objective combinatorial optimization problem (unpromising partial solutions).In this paper, the vmax combinatorial optimization problem is considered. The operator vmax means vector maximization. The vmax problems arise when more than one objective function is to be maximized over a given feasibility region (Geoffrion, 1968). In this context, the lower bound set is relatively easy to obtain because the feasible solutions of the problem can be used to form a lower bound set. However, it is not easy to compute an effective upper bound set considering the non-convexity of the PF. Ehrgott and Gandibleux (2007) and Sourd and Spanjaard (2008) proposed the idea of using linear relaxation of the problem to compute an upper bound set.Though the set of linear relaxation solutions for the original problem allows to define an upper bound set for the non-dominated set, numerical experiments with the BOIKP instances showed that a promising partial solution can be discarded sometimes during the solution process if the linear relaxation solutions of the subproblem associated with the partial solution are directly used to estimate an upper bound set. It means that the upper bound set is underestimated or not properly estimated. A properly estimated (or proper) upper bound set should guarantee that all the promising partial solutions are kept while unpromising partial solutions are discarded as many as possible. Nevertheless, a majority of non-dominated outcomes can be generated using such an upper bound set. Therefore, the set of linear relaxation solutions remains a basis for estimating a good upper bound set for the BOIKP if it is extended properly.In the following, the definitions of the bound sets are first reviewed. Then an illustrative example is provided. Next, the example is used to illustrate the process of computing a bound set according to the linear relaxation solutions of the subproblem as well as the insufficiency of the bound set (Section 3.2.2) as a proper upper bound set. Then a scheme (Section 3.2.3) is presented to obtain an effective upper bound set by extending the set of linear relaxation solutions. Finally, an algorithm for computing bound sets of the subproblem is given.Here a simple definition of bound sets is given by summarizing the results in Villarreal and Karwan (1981), Ehrgott and Gandibleux (2007) and Sourd and Spanjaard (2008).Definition 3(Upper bound set). A setUBis an upper bound set ofYNif for eachy∈YN, there exists at least oneu∈UBsuch thatu⩾qy.(Lower bound set). A setLBis a lower bound set ofYNif for eachy∈YN, there exists at least onel∈LBsuch thatl≦y.According to the above definitions,YNitself can serve both as an upper bound set and as a lower bound set forYN. Note that an upper bound set allows to include the elements dominated by those inYNaccording to Definition 3 while a lower bound set allows to include the elements dominating those inYNaccording to Definition 4. Fig. 2illustrates the relations of the upper (c) and lower (b) bound sets with respect to the non-dominated set (a) of the BOIKP. Points ‘×’ (A, B, C, D, E and F) are partial non-dominated outcomes of the BOIKP. For the sake of simplicity, no additional notation is introduced for the vertex of the right angle between two consecutive non-dominated outcomes. It is possible to have some new non-dominated outcomes within the right triangle derived from the two consecutive non-dominated outcomes. The staircase curve (thick lines) in the sub-figures (b) and (c) are called polyline(ABCDEF)★for short. In principle, all the points on and below the polyline(ABCDEF)★(e.g., points ‘•’) are in setLBwhile all the points on and above the polyline(ABCDEF)★(e.g., points ‘∘’) are in setUB. For practical purposes, the elements in bound sets should be close to those inYN.In addition, the bound sets should be defined in coordination, e.g., for the vmax combinatorial problem, if the lower bound set does include the elements dominating those inYN, then it is not possible to have effective bounding principles to prune unpromising partial solutions. Accordingly, bound sets for the vmin combinatorial problem should be defined in a similar manner. In practice, lower and upper sets should be estimated properly to prune unpromising nodes consistently without losing any non-dominated outcome. The bounding principles for the vmax optimization problem, which will be presented formally and rigorously in formula (MBP) in Section 4.1, are briefly stated as follows. A partial solution will be discarded if all the elements in the upper bound set are dominated by the elements in the lower bound set while it should be kept if there exists at least one element in the upper bound set, which is not dominated by the elements in the the lower bound set.For the algorithm using bound sets in the current study, motivated by the concept that the non-dominated set itself can serve as a lower bound set, the lower bound set is designed to be the feasible solutions of problem, which is used to approximate the non-dominated set of the problem, instead of using the polyline(ABCDEF)★in Fig. 2 as done in Delort and Spanjaard (2010) and Figueira et al. (2013). The upper bound set is computed according to the linear relaxation of the subproblem associated with the partial solution.The following bi-objective instance withn=20is used to illustrate the process of computing bound sets throughout the section.vmax294x1+199x2+292x3+463x4+603x5+89x6+631x7+862x8+554x9+373x10+604x11+603x12+118x13+840x14+611x15+611x16+575x17+243x18+403x19+694x20,659x1+814x2+608x3+543x4+414x5+817x6+343x7+220x8+513x9+551x10+460x11+340x12+791x13+174x14+297x15+464x16+395x17+734x18+600x19+398x20subject to882x1+826x2+862x3+887x4+898x5+928x6+943x7+962x8+986x9+1003x10+1043x11+1048x12+1058x13+1076x14+1078x15+1088x16+1113x17+1120x18+1159x19+1237x20⩽10069,xj⩾0,integer,j∈{1,…,20}.The linear relaxation solutions can be obtained by solving a sequence of weighted-sum functions using either a general algorithm as in Ehrgott and Gandibleux (2007) or a special algorithm as in Gomes da Silva, Clímaco, and Figueira (2008). For a given weighted-sum function, the linear relaxation solution is determined by the two items with the largest profit-to-weight efficiencies, called efficient pair. It means that the item with the second largest efficiency is always the break item for the problem regardless of the capacity of the knapsack. The algorithm presented in Gomes da Silva et al. (2008) can be used to generate all the efficient pairs according to the break item.During the DP process, usually the upper and lower bound sets of the problem are estimated according to the residual problem of the nodes. For a given nodeαt(α=2,…,n,0⩽t⩽W),S(αt)represents the set of non-dominated solutions consisting of the firstα-1items and some copies of itemαwith node weight t, i.e., the elements inS(αt)are partial solutions. The residual problem ofαtis formulated as follows.vmax∑j=αncj1xj,…,∑j=αncjrxjs.t.∑j=αnwjxj⩽W-t,(Rtα)xj⩾0,integer,j=α,…,n.The residual problem in each stage of the DP process contains the same items but have different residual capacitiesW-taccording to different node weights t. It means that the efficient pairs only need to be computed once in each stage. For a given residual capacity, the linear relaxation solutions are obtained by placing as many (integer) copies of the first item in each efficient pair as possible with the remaining capacity (if any) occupied by the second item.Therefore, if several efficient pairs have the same first item (e.g., two efficient pairs(8,14)and(8,5)for the illustrative example wherew8=962) and the residual capacity (e.g., 9620) happens to be a multiple of the weight for the first item, then linear relaxation solutions contain zero copies of the second item. In this case, several linear relaxation solutions coincide and the number of relaxation solutions for the residual problem is smaller than the number of efficient pairs. Generally speaking, the linear relaxation solutions are less sensitive to the residual capacity when compared with the non-dominated set of the BOIKP.In the DP process, to estimate the upper bound set for the problem, linear relaxation solutions need to be computed only for stagesα=2,…,n-1. For the last stage n, only one item n is left and the upper bound set can be trivially computed (refer to Steps 7 and 8 of Algorithm 1).LetUBW-tαandLBW-tαdenote the upper bound set and lower bound set, respectively for the residual problem of nodeαtfor the items inNα={α,…,n}. The number of efficient pairsKαcan be different according toNα. However,Kαis not a monotonic increasing function of|Nα|, i.e., a large|Nα|does not mean a largeKα.|N1|=20>15=|N6|, butK6=7>6=K1for the illustrative example.Let{(P1k,P2k),k=1,…,Kα}denote the set of efficient pairs corresponding toNα,{(f1k(x),f2k(x)),k=1,…,Kαt}be the set of distinct linear relaxation solutions corresponding to{(P1k,P2k),k=1,…,Kα}for a given residual capacityW-tand{(g1k(x),g2k(x)),k=1,…,Kαt}be the set of feasible solutions corresponding to{(f1k(x),f2k(x)),k=1,…,Kαt},The elements inLBW-tα(α=2,…,n)are used to update the lower bound set for the original problem if a partial solution at nodeαtpasses the bound checking. It is better to compute all(g1k(x),g2k(x))together with(f1k(x),f2k(x))before the bound checking starts.The illustrative example at the end of Section 3.1 is used to illustrate the results of(f1k(x),f2k(x))and(g1k(x),g2k(x))according to efficient pairs{(P1k,P2k),k=1,…,Kα}for a given node64259, i.e.,α=6,t=4259,andW-t=10069-4259=5810.K6=7efficient pairs can be obtained according toN6={6,…,20}using the algorithm in Gomes da Silva et al. (2008).{(P1k,P2k),k=1,…,7}={(8,14),(8,7),(8,9),(9,8),(9,6),(6,9),(6,13)}(7){(f1k(x),f2k(x)),k=1,…,7}={(5201,1326),(5197,1333),(5193,1339),(3558,2766),(2854,3339),(669,5027),(577,5082)}{(g1k(x),g2k(x)),k=1,…,7}={(5172,1320),(5172,1320),(5172,1320),(2770,2565),(2770,2565),(534,4902),(534,4902)}If the efficient pairs are generated according toN1={1,…,n}, then the linear relaxation solutions and the feasible solutions of the original problem can be obtained. The efficiency of an item is simply determined according to the efficient pairs of the original problem. An item is classified as efficient if it appears in one of the efficient pairs for the original problem. As for our example, there are 6 efficient pairs for the original problem, i.e.,{(P1k,P2k),k=1,…,6}={(8,14),(8,5),(8,2),(2,8),(2,1),(2,6)}. It means that items1,2,5,6,8and 14 are efficient items. For the original problem (capacity W),(8){(f1k(x),f2k(x)),k=1,…,6}={(8970,2272),(8921,2407),(8728,2642),(2528,9803),(2444,9893),(2403,9906)}{(g1k(x),g2k(x)),k=1,…,6}={(8620,2220),(8620,2220),(8620,2220),(2388,9768),(2388,9768),(2388,9768)}The initial lower bound set of the problem can be formed by taking the distinct elements from{(g1k(x),g2k(x)),k=1,…,6}, i.e.,{(8620,2220),(2388,9768)}.Both(8620,2220)and(2388,9768)are non-dominated outcomes. It can be seen that the set of linear relaxation solutions for the original problem (formula (8)) does provide a proper upper set for the problem according to Definition 3. However, it does not offer much help in pruning unpromising partial solutions. In the DP process, an estimated upper bound set according to the residual problem of a partial solution should play a role in helping to generate the non-dominated outcomes effectively and efficiently by discarding unpromising partial solutions properly.In the following, let us check whether an estimated bound set according to linear relaxation solutions of the residual problem for node64259work properly or not.There is a partial solution(1758,3244)at node64259, which is associated with a non-dominated outcome(6622,4857). The(6622,4857)is obtained by placing one copy of item 9 and five copies of item 8 above the(1758,3244). The set of feasible solutions up to the time of computing node64259is shown in Table 1. The third element in an objective vector of the table is an indicator used to indicate whether the corresponding feasible solution (first two elements) is an accomplished (‘1’) solution or a predicted (‘0’) solution. The reason for distinguishing between the accomplished and predicted feasible solutions is explained in the later Section 4.1. The estimated bound set is computed according to formula (7) and(1758,3244), i.e.,{(1758,3244)}⊕{(5201,1326),(5197,1333),(5193,1339),(3558,2766),(2854,3339),(669,5027),(577,5082)}(9)={(6959,4570),(6955,4577),(6951,4583),(5316,6010),(4612,6583),(2427,8271),(2335,8326)}Now the results of formula (9), some representative feasible solutions in Table 1 and the non-dominated solution(6622,4857)are used to illustrate the relations between the estimated upper bound set of a partial solution associated with a non-dominated solution and set of feasible solutions in Fig. 3. In the figure, points ‘∘’ (A, B, C, D, E, F and G) correspond to the elements in formula (9). Note that the first three elements in the formula are close to each other. It is difficult to distinguish between them according to the scale of the figure and three points become one point C(A, B). Points ‘∗’ are few representative feasible solutions from Table 1, corresponding to(6975,4590),(5369,6030),(4706,6630)and(2483,9613). Point ‘+’ represents(6622,4857).Now, assume that the estimated bound set given by formula (9) is a proper upper bound set. Then, the partial solution(1758,3244)should be discarded without losing any non-dominated outcome according to the bounding principles mentioned in Section 3.1 because all the elements in formula (9) (points ‘∘’) are dominated by the elements (points ‘∗’) in the lower bound set given in Table 1 as illustrated in Fig. 3. However, it is known that the non-dominated outcome(6622,4857)(point ‘+’ in Fig. 3) has to be generated on the basis of the partial solution(1758,3244). This contradicts the assumption. To guarantee that(1758,3244)is not discarded, there should exist at least one element in the estimated upper bound set, which cannot be dominated by the elements in the lower bound set according to the bounding principles. It means that the set of linear relaxations need to be extended.The idea of full-range extension is similar to the idea of calculating the lower bound set of the bi-objective 0-1 knapsack problem presented in Delort and Spanjaard (2010) and Figueira et al. (2013). If a subset of the non-dominated outcomes is known, then the lower bound set can be estimated as the staircase curve illustrated in sub-figures (b) of Fig. 2. The lower bound set is justified because it is possible to have new non-dominated outcomes within the right triangles derived from the two known consecutive non-dominated outcomes. Similarly, if it is known that some non-dominated outcomes are lost according to the upper bound set calculated directly based on linear relaxation solutions of the residual problems and a subset of lower bounds (possible non-dominated outcomes of the problem) is known (e.g., points ’∗’ in Fig. 3), then the lost non-dominated outcomes should be located within some right triangles derived from the two consecutive outcomes according to linear relaxation solutions as illustrated in Fig. 4(e.g., within triangle CJD). Then the upper bound set with full-range extension is estimated as the staircase curve AHBICJDKELFMG in Fig. 4. Points H and I are not shown in the figure and they are the vertices of the right angles for the triangles derived from points A and B as well points B and C, respectively. N is the point for the controlled extension as discussed later.For randomly generated instances considered in the experiments of the current study, the following results were obtained if the set of the linear relaxation solutions for the residual problem was used to estimate the upper bound set of the original problem.100%uncorrelated unconflicting (weight and profit objectives are not correlated and two profit objectives are positively correlated) instances can be solved correctly while10%of the remaining uncorrelated (two profit objectives can be either uncorrelated or negatively correlated) and more than70%of correlated conflicting instances (two profit objectives are negatively correlated and weight and profit objectives are positively correlated) will lose some non-dominated outcomes.It seems that the above results are related to ratio|YN|/n. The larger the ratio, the larger probability the instances will lose non-dominated outcomes. The|YN|/ndepends on n and correlation relations between weight and profit objectives as well as between the profit objectives. It means that the degree of the extension for linear relaxation solutions should be related to the correlation relations among the items. For a given instance, the correlation relations among the items can be determined by a statistic measure called correlation coefficient as discussed by Rong, Figueira, and Klamroth (2012). Therefore, it is not difficult to single out correlated conflicting and uncorrelated unconflicting instances before the solution process starts.Note that the extension of the upper bound set is equivalent to the extension for the set of linear relaxation solutions. Fig. 4 can be used to illustrate the profile of linear relaxation solutions for the residual problem if the partial solution(1758,3244)is treated as origin(0,0).Assume that the set of the linear relaxation solutions{(f1k(x),f2k(x)),k=1,…,Kαt}are arranged according to the decreasing order of the first criteria, i.e.,f11(x)>,…,>f1Kαt(x). This arrangement means thatf21(x)<,…,<f2Kαt(x). The full-range extension scheme is given below.For any two consecutive linear relaxations(f1k(x),f2k(x))and(f1k+1(x),f2k+1(x)),k=1,…,Kαt-1, a new objective vector(f1k(x),f2k+1(x))is generated. The new objective vectors together with the linear relaxation solutions form a full-range extended upper bound set as illustrated in Fig. 4. In most cases, the above full-range extended upper bound set is too large to eliminate the unpromising partial solutions effectively. Thus, it is necessary to tighten the upper bound set. Then the controlled extension scheme is given below.The first element remains unchanged as just mentioned, i.e.,f1k(x), and the second element is modified asf2k(x)+βk(f2k+1(x)-f2k(x)),0⩽βk⩽1. Ifβk=0(k=1,…,Kαt-1), then the upper bound set coincides the set of linear relaxation solutions. Ifβk=1(k=1,…,Kαt-1), then the upper bound set coincides the full-range extended upper bound set. For tightening purpose,βk=0for some k, and0<βk⩽1for the other k.Whether a new objective vector is needed or not (what valueβktakes) depends on the distribution of the non-dominated outcomes of the BOIKP. For the example in Fig. 4a new point ‘N’ is needed only between points C and D andβk=0.5. Consequently, a tighter upper bound set consists of points A, B, C, N, D, E, F and G. Numerical experiments showed that the distribution of the non-dominated outcomes depends on correlation relations among items as described in SubSection 3.2.3. It is much easier to determine the value ofβkfor uncorrelated instances than for correlated conflicting instances.Note that in the DP process, only upper bound set for the stagesα=2,…,n-1needs to be extended if linear relaxation solutions of the residual problem are used to do estimation. In some special cases (e.g., the cases described in Section 4.3 and last stage n), much tighter upper bound set can be given accurately with no need to be extended.Algorithm 1Procedure for generating an upper and a lower bound set at stageαInput:w,W,ck(k=1,2),{(P1k,P2k),k=1,…,Kα}, node weight t, types of instances IOutput:{UBW-tα,LBW-tα}1: if (α<n) then2: Compute{(f1k(x),f2k(x)),k=1,…,Kαt}and corresponding{(g1k(x),g2k(x)),k=1,…,Kαt}according to{(P1k,P2k),k=1,…,Kα}andW-t.3: Compute(f1k(x),f2k(x)+βk(f2k+1(x)-f2k(x)))according to I using either condition (10) or conditions (a) to (e).4:UBW-tα≔{(f1k(x),f2k(x)),(f1k(x),f2k(x)+βk(f2(x)k+1-f2k(x))),(f1k+1(x),f2k+1(x)),k=1,…,Kαt-1,0⩽βk⩽1}.5:LBW-tα≔{(g1k(x),g2k(x)),k=1,…,Kαt}.6: else7: Compute{(g11(x),g21(x))}according toP11=n.8:LBW-tn≔{(g11(x),g21(x))},UBW-tn≔LBW-tn.9: end ifFor uncorrelated instances where two profit objectives are either negatively correlated or uncorrelated, a new objective vector is needed between linear relaxation solutions k andk+1if(10)P1k≠P1k+1,K1⩾3,P1kandP1k+1areefficient.Ifn⩽10,βk=0(k=1,…,Kαt)while theβkincreases as n increases ifn>10.For correlated conflicting instances, a new objective vector is needed if one of the following conditions is satisfied.(a)P1k≠P1k+1,K1⩾3,P1korP1k+1areefficient;(b)P1k≠P1k+1,K1⩾3,P1k=αorP1k+1=α,P1kandP1k+1arenotefficient;(c)P1k≠P1k+1,K1⩾3,f2k+1(x)⩾γ1f1k(x),f1k(x)⩾γ2f1k+1(x)andδ1(f1k(x)-f1k+1(x))⩽f2k+1(x)-f2k(x)⩽δ2(f1k(x)-f1k+1(x));(d)P1k=P1k+1andefficient,K1⩾3,P2korP2k+1areefficient;(e)P1k=P1k+1,K1⩾3,P2k=αorP2k+1=α,P1k,P2kandP2k+1arenotefficient.As described in Section 2, in the sequential DP process, the items are processed stage by stage, one item in each stage. Conditions (b) and (d) mean that the currently processed itemαis one of the items in the efficient pair. Condition (c) describes the situation when at least one of the criteria coordinate of two consecutive relaxation solutions has a big jump while the magnitude of the jump is kept within a certain range, e.g.,min(γ1,γ2)⩾1.5andmax(γ1,γ2)⩾2.5,δ1⩾0.75andδ2⩽1.8.When compared with uncorrelated instances, theβkincreases much faster with n. Ifn⩽10,βk=0(k=1,…,Kαt). When10<n⩽30,βk=0.5if either condition (a) or (b) holds and whenn>30,βk=1if one of the above (a)–(e) conditions holds. Algorithm 1 gives the procedure for computing the upper and lower bound sets for the residual problem of a given nodeαtat stageα(α=1,…,n). Note that no feasible solutions correspond to the new objective vectors inserted between two linear relaxation solutions.Finally,UBW-tαfor the residual problem of node64259is computed according to Algorithm 1 on the basis of formula (7). The illustrative example is a correlated conflicting instance. Forn=20, conditions (a) and (b) need to be checked. Condition (a) holds for pairs(8,9)and(9,8)as well as for pairs(9,6)and(6,9)because items 8 and 6 are efficient as mentioned in Section 3.2.1.βk=0.5withn=20. A new objective vector(5193,1339+0.5(2766-1339))=(5193,2052)is inserted between(5193,1339)and(3558,2766). Another new objective vector(2854,3339+0.5(5027-3339))=(2854,4183)is inserted between(2854,3339)and(669,5027).(11)UBW-tα={(5201,1326),(5197,1333),(5193,1339),(5139,2052),(3558,2766),(2854,3339),(2854,4183),(669,5027),(577,5082)}An upper bound(1758,3244)+(5193,2052)=(6951,5296)(point ‘N’ in Fig. 4) estimated by the element(5193,2052)can guarantee that the partial solution(1758,3244)is kept and the non-dominated solution(6622,4857)will be generated. The same is also true for the upper bound estimated by(2584,4183)and the corresponding point should be in the middle of line EL in Fig. 4.Fathoming criteria (bounding principles) are fundamental to apply the bound sets for developing the algorithm for the multi-objective combinatorial optimization problem. Unlike single objective case, a set of upper and lower bounds are used to provide the bounds for the non-dominated set of the problem instead of a single upper and lower bound. Some aspects of bounding principles have been discussed and applied in Section 3 for the illustrative purpose. In this section, bounding principles are presented formally to facilitate algorithm description and algorithm implementation.Algorithm 2Procedure for generating nodes using the bound sets at stageαInput:flag,Nα-1,S((α-1)t)(t∈Nα-1),LBα-1,LBα-1,0,LBα-1,1Output:{flag,Nα,S(αt)(t∈Nα),LBα,LBα,0,LBα,1}1:SetW∼≔W-wα,Nα≔{α,…,n},Nα≔∅,U≔∅.2:SetLBα≔LBα-1,LBα,0≔LBα-1,0,LBα,1≔LBα-1,1.3:DetermineJα-11.4:Compute{(P1k,P2k),k=1,…,Kα}according toNα.5:i≔1,f1≔1.6:while (i<Jα-11andf1=1) do7:t≔Nα-1(i).8:{UBW-tα,LBW-tα}≔Algorithm1(w,W,ck(k=1,2),{(P1k,P2k),k=1,…,Kα},t,I).9:S(αt)≔BP(S((α-1)t)).10:if (S(αt)≠∅) then11:f1≔0,Nα≔Nα∪{t}, and possibly updateLBα,0.12:if (t+wα⩽W∼) then13:U≔U∪{t}.14:end if15:end if16:i≔i+1.17:end while18:if (f1=0) then19:while (i<Jα-11orU≠∅) do20:while (i<Jα-11andU≠∅) do21:t1≔Nα-1(i),t2≔U(1).22:if (t1<t2+wα) then23:t≔t1.24:Repeat Steps 8 to 16 without considering the assignment off1.25:else if (t1=t2+wα) then26:t≔t1,U≔U-U(1).27:{UBW-tα,LBW-tα}≔Algorithm1(w,W,ck(k=1,2),{(P1k,P2k),k=1,…,Kα},t,I).28:S(αt)≔BP(ND(S((α-1)t)∪{(cα1,cα2)⊕S(αt-wα)})).29:Repeat Steps 12 to 16 without considering the assignment off1.30:else31:t≔t2+wα,U≔U-U(1).32:{UBW-tα,LBW-tα}≔Algorithm1(w,W,ck(k=1,2),{(P1k,P2k),k=1,…,Kα},t,I).33:S(αt)≔BP((cα1,cα2)⊕S(αt-wα))34:Repeat Steps 12 to 15 without considering the assignment off1.35:end if36:end while37:while (i<Jα-11andU=∅) do38:Repeat Steps 7 to 16 without considering the assignment off1.39:end while40:while (U≠∅) do41:t2≔U(1).42:Repeat Steps 31 to 34.43:end while44:end while45:DetermineJα2.46:for (i=Jα2to|Nα|) do47:t≔Nα(i),LBα,1≔ND(LBα,1∪{(cα1,cα2)⊕S(αt)}).48:end for49:LBα,0≔LBα-LBα,1.50:else51:flag≔0.52:end ifProcedure for the DP algorithm using the bound setsInput:w,W,n,ck(k=1,2)andtypesofinstancesIOutput:YN1:Setα≔1,N1={1,…,n},m1≔⌊W/w1⌋,N1≔{0,…,m1},S(1t)={(tc11,tc12),t∈N1}.2:Generate{(P1k,P2k),k=1,…,K1}according toN1.3:Sett≔0.4:{UBW-t1,LBW-t1}≔Algorithm1(w,W,ck(k=1,2),{(P1k,P2k),k=1,…,K1},t,I).5:LB1≔ND(LBW-t1∪S(1m1)).6:if(S(1m1)⊆LB1)then7:LB1,1≔S(1m1).8:else9:LB1,1≔∅.10:end if11:LB1,0≔LB1-LB1,1.12:α≔α+1,flag≔1.13:while (flag=1andα⩽n) do14:{flag,Nα,S(αt)(t∈Nα),LBα,LBα,0,LBα,1}=Algorithm 2(flag,Nα-1,S((α-1)t)(t∈Nα-1),LBα-1,LBα-1,0,LBα-1,1).15:α≔α+1.16:end while17:YN≔LBα-1.Here the bound sets are applied on the basis of the BDP algorithm described in Section 2 to prune the unpromising nodes in the DP process.TheUBW-tαand theLBW-tαfor the residual problemRtαcan be computed according to Algorithm 1. LetLBα=LBα,0∪LBα,1denote the set of the best lower bounds known so far when itemαis considered to place in the knapsack, whereLBα,0is the set of non-dominated outcomes of the subproblem consisting of the firstα-1items andLBα,1is the set of estimated feasible solutions considering all of items according to the current partial solutionS(αt)and the solution of the residual problemRtα. The feasible solutions inLBα,0andLBα,1can be interpreted as accomplished and unaccomplished (predicted) solutions respectively. In the solution process,LBα,0andLBα,1can be differentiated by an indicator as shown in Table 1.As discussed later, the solution process may not go through all n stages. The lower bound set is the non-dominated set whenever the calculation process ends. The reason whyLBαare divided into two partsLBα,0andLBα,1can be seen in the following formula (MBP) for the bounding principle. If the left-hand side of formula (MBP) is equal to an accomplished lower bound, then the corresponding partial solution is discard. If the left-hand side is equal to a predicted lower bound, then the corresponding partial solution should be kept.(MBP)dα+u≦ll∈LBα,1dα+u⩽ll∈LBα,0For a given partial solutiondα∈S(αt), for eachu∈UBW-tα, at least onel∈LBαsuch that the formula (MBP) holds, thendαis discarded. Otherwise, for eachl∈LBα, at least oneu∈UBW-tαsuch that the formula (MBP) does not holds, thendαis kept andLBα,0is updated if u is associated with a feasible solution inLBW-tα. Let BP(S(αt)) denote the non-dominated set of nodeαtafter formula (MBP) is applied. IfBP(S(αt))=∅, then the corresponding nodeαtis not generated.As mentioned in Section 4.1,LBαis designed to store all the non-dominated outcomes of the firstα-1stages plus some predicted lower bounds so far. Based on Theorem 1, for stageα(α=2,…,n), the non-dominated outcomes are kept at the nodesαt(t>W-wα). Therefore, for the DP procedure applying the bound sets, in each stageα, the results of these nodes can be kept inLBαand only the nodesαt(0⩽t⩽W-wα)are kept in the DP network. This can reduce the memory requirements of the algorithm, which is mainly determined by2max(|Nα|×|S(αt)|,0⩽t⩽W-wα,α=1,…,n). This would be less than2max(|Nα|×|S(αt)|,0⩽t⩽W,α=1,…,n)for the traditional BDP procedure keeping all the nodes in the DP network. On the one hand|Nα|is reduced. On the other hand|S(αt)|is also reduced because it has tendency to increase as t increases. Moreover, if the bound sets are applied,|S(αt)|should not be larger than the case when the bound sets are not applied.The algorithm presented here is designed for the BOIKP because the bound sets are explored for the bi-objective case. Algorithm 2 gives the procedure for computing the nodes at stageα=2,…,n, using the bound sets and Algorithm 3 gives the DP procedure using the bound sets. In the algorithm, the items are arranged in a non-decreasing order of weight. There are two advantages for such arrangement. First, for randomly generated instances, there are more efficient items with smaller weight. The algorithm may terminate earlier before stage n and a ‘flag’ used to control the termination of the algorithm (Steps 13 to 16 of Algorithm 3). Second, tighter upper bounds can be obtained when the node positiont>W-2wαbecause at most one item inNα={α,…,n}can be placed in the knapsack, i.e., the elements of the upper bound set are from{(cβ1,cβ2),β∈Nα}.The node positions inNαare arranged in an increasing order. The operator ‘(i)’ after a set notation takes theithelement in the set. LetJα-11be the index of the first element inNα-1larger thanW-wαandJα2be index of the first element inNαlarger thanW-2wα. The node calculation for the BDP procedure has to be processed from the lowest to the highest positions.To start the algorithm, the first node at stageαneeds to be computed by checking the positiont∈Nα-1sequentially (Steps 6 to 17 of Algorithm 2). If the first node does not exist, then it means that the remaining items inNαcannot lead to a new non-dominated outcome. In this case, the algorithm needs to be terminated (Set flag≔0 at Step 51 of Algorithm 2). If the first node exists, then the node calculation fort⩽W-wαis performed (Steps 19 to 44 of Algorithm 2) and andLBαis updated according to the results of nodes witht>W-wα(Steps 45 to 49 of Algorithm 2). In the algorithmLBα,0andLBα,1can be simply differentiated by an indicator as shown in Table 1. Thus, updatingLBα,0in Step 11 and updatingLBα,1in Step 47 of Algorithm 2 means thatLBαis also updated.To test the effectiveness of the new improved BDP procedure (BDPn) presented at the end of Section 2 as well as the hybrid DP procedure using the bound sets (DPB), two benchmark algorithms are used to solve two variants of problems including the original (o) and the reduction (r) variants. The reduction problem is obtained by a preprocessing procedure to eliminate the dominated items (Rong & Figueira, 2013). On the average, the processing time of the preprocessing procedure is much smaller than the solution time of the reduction problem. Therefore, the processing time of the preprocessing procedure is neglected. One benchmark is theε-constraint method wherea general solver (e.g., CPLEX) is used to solve a sequence ofε-constraint subproblems. The other is the old traditional BDP algorithm (BDPo) in Figueira et al. (2010). The overall performance of theBDPoalgorithm was among the best of DP algorithms based on labeling techniques (Figueira et al., 2010). A comparison is made between new DP algorithms and benchmarks as well as between two new algorithms (DPB andBDPn) and between two benchmarks (ε-constraint andBDPo).All the DP algorithms (BDPo,BDPn, DPB) were implemented in C++ in the Microsoft visual studio 2003 environment. All the experiments were carried out on a 2.49GHz Pentium PC with 2.9GB RAM under Windows XP operating systems. In this study, only randomly generated bi-objective instances were considered.The numerical experiments were associated with the following four types of instances, similar to those for the 0-1 bi-objective knapsack instances (Bazgan et al., 2009a; Rong et al., 2011).(A)Completely uncorrelated instances:cj1∈R[1,U],cj2∈R[1,U],wj∈R[1,U],j=1,…,n;Uncorrelated unconflicting instances, where two profit objectives are positively correlated but weight coefficients and profit objectives are not correlated:cj1∈R[1+0.1U,U],cj2∈R[cj1-0.1U,cj1+0.1U],wj∈R[1,U],j=1,…,n;Uncorrelated conflicting instances, where two profit objectives are negatively correlated but weight coefficients and profit objectives are not correlated:cj1∈R[1,U],cj2∈R[max(1,0.9U-cj1),min(U,1.1U-cj1)],wj∈R[1,U],j=1,…,n;Correlated conflicting instances, where two profit objectives are negatively correlated and weight coefficients are positively correlated with profit objectives:cj1∈R[1,U],cj2∈R[max(1,0.9U-cj1),min(U,1.1U-cj1)],wj∈R[max(1,cj1+cj2-0.2U),cj1+cj2+0.2U],j=1,…,n.Hereu∈R[v1,v2], is a uniform random number in[v1,v2]. SetU=1000, andW=12∑j=1nwjfor all the instances. Types A, B and C are called uncorrected instances for simplicity. 30 instances were considered for each problem size n (the number of items in the knapsack) and each instance type. Average results were obtained on the 30 instances.The following notation is used in the tables.•n: number of items in the knapsack (the problem size of the original problem);W‾: average knapsack capacity on the 30 instances;n¯r,nˆr: average and maximum number of items for 30 instances for the reduction problem;ND‾: averageND(|YN|)on the 30 instances;ND^: maximumND(|YN|)on the 30 instances;N/A: the results are not available because some of instances cannot be solved due to memory restriction;o, r: the original and the reduction problem.In the experiments, the items were arranged according to a non-decreasing order of weight for the DPB and to a non-increasing order of weight for theBDPoand theBDPn. The efficiency of theBDPois not sensitive to the order of items while the efficiency of the DPB and theBDPnis sensitive to the order of items. The chosen orders can obtain the best average solution time on the average. The solution time of the DP algorithm is the CPU time for running the algorithm without involvement of I/O operations. The solution time for theε-constraint method should approximate the CPU time because default settings of CPLEX parameters are used except that the relative gap parameter is set according to the maximum quantity order of the objective value. For example, the relative gap is set to10-6if the maximum objective quantity is in the order of105, which can guarantee that all of the non-dominated outcomes (integer) are generated. For a given instance, if the recorded solution time of the algorithm is zero, then the instance is solved repeatedly a sufficient number of times (e.g., 1000) and total (non-zero) time is recorded. Then the solution time of the instances is the recorded time divided by the number of repetitions. However, if the size of the reduction problem is 1, the solution time is zero and no repetitions are done. In this situation, the processing time of the preprocessing procedure should be larger than the solution time of the reduction problem. However, the former has been neglected as mentioned in the beginning of the section. For evaluating the relative performance (memory requirements and solution time) between different algorithms, GAP(%)=100(Ts-Tb)/Tbis used, whereTsandTbare the performance measures of two different algorithms. The negative value means the former (Algorithm s) performs better than the latter (Algorithm b).Table 2gives the memory requirements in mega bytes (Mb) for the BDP and the DPB algorithms as well as the GAP measure between the DPB and the BDP algorithms. The memory requirements of theBDPoand theBDPnare the same and the memory requirements of theε-constraint method are not provided because it is difficult to estimate the memory requirements for solving a sequence of integer programming problems using CPLEX. The memory requirements for the DP algorithms are those for storing two stages of objective vectors in the solution process. In the table, the average and the maximum size of the reduction problem (n¯randnˆr) are also given. It can be seen that the preprocessing procedure can result in a more significant size reduction for uncorrelated (types A, B and C) instances than for correlated conflicting instances (type D). Overall, the size reduction can improve the performance for all the algorithms (see Table 2for memory requirements and Table 3for solution time) though different algorithms respond differently to the reduction. In the current study, the performance improvement of the new algorithm is focused instead of reduction. For the original problem, the average memory improvement (in percentage) of the DPB over the BDP is87,89,88and 66 for instances of types A, B, C and D. For the reduction problem, the average memory improvement (in percentage) is88,93,90and 65 for instances of types A, B, C and D.Table 3 gives the solution time for different algorithms. The GAP measures for solution time between different algorithms are not shown explicitly in the table considering the fact that differences between different algorithms are obvious as well as the limitation of the space. On the average the DPB is the best algorithm for uncorrelated instances and theBDPnis the best algorithm for correlated conflicting instances.When theBDPnand theBDPoare compared, the former shows consistent significant time improvement over the later for different types of problems due to applying the property discussed in Section 2. For the original problem, it seems the improvement for instances of type B is relatively small as compared with the other types of instances due to the smallerND‾(refer to columnND‾of Table 2) for instances of type B. For the reduction problem, the situation has improved for instances of type B due to the significant size reduction (see columnn¯randnˆrof Table 2).When the DPB and theBDPnare compared, on the average the DPB performs better than theBDPnfor uncorrected instances and worse for correlated conflicting instances for both the original and the reduction problem. This is mainly due to the fact that the upper bound set is easy to tighten for uncorrected instances but difficult for correlated conflicting instances as discussed in Section 3. Another factor is that the DPB algorithm (refer to Algorithm 3 in Section 4) can terminate earlier for uncorrelated instances.Another phenomenon is that the relative performance of the DPB over theBDPnhas tendency to degrade as n increases for instances of types A and D for the reduction variant. This is due to the fact that the problem reduction causes two changes. On the one hand the performance of theBDPnis improved because of the reduced size. On the other hand the room for applying the bound sets to achieve further reduction is decreased because some dominated items are removed beforehand.When the DP algorithms (BDPo,BDPnand DPB) and theε-constraint method are compared, it seems that the DP algorithms is more sensitive to problem size and size reduction. This may be due to the fact the CPLEX is designed for solving the large scale problem. Table 4gives the solution time of theε-constraint method for solving larger size instances.When Table 4 and Table 2 are compared, it can be seen that the sizes (n¯randnˆr) of reduction variants (r) remain almost the same for both small and large size instances for uncorrelated instances (types A, B and C) while proportional to the sizes of the original problem for correlated conflicting instances (type D). Consequently, reduction gains more remarkable improvement over solution time for uncorrelated instances than for correlated conflicting instances. Avg and Max time in the table refers to the average and the maximal solution time on the 30 instances.Based on the above analysis, theBDPnalgorithm is the best algorithm for dealing with correlated conflicting (type D) instances for at least two reasons. First, it is difficult to tighten the upper bound set for correlated conflicting instances in the DPB as discussed in Section 3.2.3. Second, the solution time degradation of the DPB over theBDPnis lager than the memory improvement of the DPB over theBDPnas n increases. The DPB is the best algorithm for uncorrelated (types A, B and C) instances. If there is a preprocessing procedure for reducing the problem size beforehand, theBDPngains advantages for instances of type A as n increases.

@&#CONCLUSIONS@&#
This paper presented two improved DP algorithms for the bi-objective integer knapsack problem according to two techniques. One is a property of the traditional DP algorithm for the multi-objective integer knapsack problem newly identified in the current research. The other is the concept of the bound sets. The first algorithm was developed by directly using the property and the second algorithm was a hybrid DP algorithm by using the property in conjunction with the bound sets.The main challenge of the hybrid algorithm is to construct a proper upper bound set considering the non-convexity of the PF. Numerical experiments showed that a promising partial solution can be sometimes discarded if the solutions of linear relaxation of the subproblem associated with it are directly used to estimate an upper bound set. It means that the upper bound set is underestimated. However, a majority of non-dominated outcomes can be generated using such a bound set. Therefore, an extended upper bound set with the mechanism of controlling the extent of the extension was proposed on the basis of the set of linear relaxation solutions. The way of designing bound sets can be viewed as a dual approach to that used by Delort and Spanjaard (2010) in the sense that (Delort & Spanjaard, 2010) extended the set of feasible solutions (lower bound set) while the current study extended the set of linear relaxation solutions (upper bound set).The numerical results obtained with different types of bi-objective instances showed the effectiveness of two new DP algorithms. The first algorithm is suitable for dealing with correlated conflicting instances (weight coefficients and profit objectives are positively correlated and two profit objectives are negatively correlated) while the hybrid algorithm is suitable for dealing with uncorrelated instances (weight coefficients and profit objectives are not correlated and the relations between two profit objectives can be either uncorrelated or correlated).The hybrid DP algorithm for the current study can be viewed as the bi-objective version of the hybrid DP algorithm (Marsten & Morin, 1978) using bounding techniques. As commented by Dyer, Riha, and Walker (1995), the algorithm in Marsten and Morin (1978) can be viewed as a specialized breadth-first Branch and Bound (BB) tree search which uses fathoming by dominance as well as by bound. The comparisons of the current hybrid DP algorithm with this variant of BB algorithm for the bi-objective case are left for the future work.