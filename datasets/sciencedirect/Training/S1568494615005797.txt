@&#MAIN-TITLE@&#
A new ensemble learning methodology based on hybridization of classifier ensemble selection approaches

@&#HIGHLIGHTS@&#
Proposing a new hybrid approach for ensemble learning systems that exploits the abilities of static ensemble selection (SES) and dynamic ensemble selection (DES) strategies.Presenting an SES approach based on NSGAII multi-objective genetic algorithm.Improving one of the DES approaches by utilizing the SES proposed method.Justifying the performance of the proposed methods by UCI repository and LKC datasets.

@&#KEYPHRASES@&#
Ensemble learning system,Static ensemble selection,Dynamic ensemble selection,Classifier combination,Classifier diversity,Multi-objective optimization,

@&#ABSTRACT@&#
Ensemble learning is a system that improves the performance and robustness of the classification problems. How to combine the outputs of base classifiers is one of the fundamental challenges in ensemble learning systems. In this paper, an optimized Static Ensemble Selection (SES) approach is first proposed on the basis of NSGA-II multi-objective genetic algorithm (called SES-NSGAII), which selects the best classifiers along with their combiner, by simultaneous optimization of error and diversity objectives. In the second phase, the Dynamic Ensemble Selection-Performance (DES-P) is improved by utilizing the first proposed method. The second proposed method is a hybrid methodology that exploits the abilities of both SES and DES approaches and is named Improved DES-P (IDES-P). Accordingly, combining static and dynamic ensemble strategies as well as utilizing NSGA-II are the main contributions of this research. Findings of the present study confirm that the proposed methods outperform the other ensemble approaches over 14 datasets in terms of classification accuracy. Furthermore, the experimental results are described from the view point of Pareto front with the aim of illustrating the relationship between diversity and the over-fitting problem.

@&#INTRODUCTION@&#
In machine learning, Ensemble Learning Systems (ELSs) are inspired from an innate behavior of humans; hence, the opinions of several experts are being collected for making a decision and then, based on these opinions, the final decision is made, especially if these decisions lead to financial, social, and medical consequences [1]. Today, ELSs are important on a broad spectrum of real-world applications such as biomedical [2], financial [3], political [4], and medicine [5]. This learning method is useful in several cases, including online learning [6], incremental learning [7], fusion data [8], feature selection [9], and confidence estimation [10]. Ensemble learning is composed of three different main parts: sample selection, training the base classifiers to compose the Base Classifier Pool (BCP), and combining the BCP [11]; moreover, as ensemble learning decreases the risk of selecting a single classifier with a weak performance [1], it improves the classification accuracy in comparison with single classifier. Numerous ensemble-based algorithms have been proposed, that the most common of them are bagging, boosting, AdaBoost, and random forest. A complete description of these algorithms can be found in [12].How to effectively combine the classifiers outputs is a key issue in ELSs. In the literature, there exist a number of combination approaches which are generally divided into two different categories: Static Classifier Ensemble (SCE) and Dynamic Classifier Ensemble (DCE). SCE determines a unified ensemble scheme for all test samples during the training phase. In general, there are three kinds of SCE strategies: Classifier Fusion (CF), Static Classifier Selection (SCS) [13,14], and Static Ensemble Selection (SES) [15]. While DCE selects one or more classifiers from the BCP on the basis of validation set for each test sample. Presently, DCE is divided into two strategies: Dynamic Classifier Selection (DCS) [16–18] and Dynamic Ensemble Selection (DES) [19–24].In the CF strategy, there may exist inaccurate and redundant classifiers which have the potential to reduce the diversity and performance of ELSs (that will, by themselves, reduce the simplicity of system) [25]. To address this problem, the selection approaches (i.e. SCS, SES, DCS, and DES) have been recently received increasing attention to improve the classification performance. In these approaches, the diversity and accuracy are important criteria for selection of classifiers [20,26]. For designing the classifier ensemble selection, it is also important to obtain a trade-off between error and diversity of the classifiers. Hence, evolutionary multi-objective algorithms are deserved for finding the optimal trade-off between these objectives [27]. So far, a number of multi-objective ensemble learning approaches have been proposed that are briefly presented in Section 3. However, after careful analysis we can find that none of these approaches have taken into consideration the effect of the NSGA-II algorithm along with a large set of structurally different classifiers (i.e. heterogeneous classifiers), that a subset of them together with a combiner is encoded in a chromosome.In the present study, the authors propose a new hybrid approach for ELSs that utilizes the benefits of SES and DES strategies. The approach consists of two main stages that in the first stage, NSGA-II is employed for optimizing SES learning system (named as SES-NSGAII). The aim in the first step is to select the optimal set of classifiers and their combiner for all test samples, by simultaneous optimization of error and diversity objectives. In the second stage, DES-Performance (DES-P) [20] is improved using SES-NSGAII, named as Improved DES-P (IDES-P). IDES-P selects an appropriate classifier subset for a test sample based a competence measure. The key problem for IDES-P is how to classify the test sample if no classifier is selected. To tackle this problem, we utilize the proposed technique in DES-Knora-Eliminate (DES-KE) [19], with the aim of increasing generalization ability of IDES-P. Moreover, the research tries to answer the following questions:1.Is there one suitable combiner for all datasets, or there should be a special type of combiner for each dataset?What kinds of classifiers are needed for each dataset?What is the relation between the diversity of classifiers on training data and the over-fitting problem?The major contributions of this paper are listed as follows. First, inspired by the idea of SES, a new method (SES-NSGAII) is developed using NSGA-II. Besides, according to the results achieved by the developed method, we discuss the relationship between diversity and over-fitting problem from the view point of Pareto optimal front. Second, based on SES-NSGAII, DES-KE and DES-P, a new hybrid method is developed to classify a test sample by the selected classifiers and their combiner. Third, we use the heterogeneous ensemble and different combiners to design the ensemble. Also, the two proposed methods (i.e. SES-NSGAII and IDES-P) are compared with other ensemble approaches over 14 UCI Machine Learning Repository [28] and Ludmila Kuncheva Collection (LKC) [29] datasets. The obtained results show the superiority of our proposed methods in comparison with other ones. Finally, we answer the above research questions on the basis of theses experimental results.The rest of this paper is organized as follows: in Section 2, the related works are briefly introduced on the ELSs. Section 3 gives the background knowledge about multi-objective ensemble learning and describes NSGA-II algorithm. In Section 4, the methods of creating diversity in ensemble classifiers as well as diversity measures are explained, respectively. Section 5 describes the proposed hybrid ELS in detail. The experimental setup, experimental results, and discussion are presented in Section 6. Finally, Section 7 includes the concluding remarks.

@&#CONCLUSIONS@&#
In order to improve the performance of ELSs, this paper proposed a novel hybrid approach for the selection of classifier ensemble that combined the strength of SES and DES strategies. Thus, the approach was composed of two steps: optimization (i.e. SES-NSGAII) and dynamic selection (i.e. IDES-P).SES-NSGAII (i.e. the first proposed method) was developed on the basis of NSGA-II. The method was utilized to select optimal base classifiers and their combiner for all test samples by simultaneously optimizing the error and diversity objectives. Meanwhile, the Q-statistic measure was applied for calculating the diversity among the classifiers. Finally, the best base classifiers and their combiner were selected from the Second solution of the Pareto front and were found efficient in terms of classification performance. However, one can easily select the other final solutions in the Pareto-optimal set.In our second proposed approach (i.e. IDE-P), the DES-P approach was improved using the SES-NSGAII approach. To classify each test sample, this approach used the selected classifiers and their combiner from the Second place of Pareto front. The results of the non-parametric statistical analyses showed that the two proposed methods were the best approaches compared to the other ensemble approaches over 14 UCI and LKC datasets which have used heterogeneous classifiers. Finding of this study revealed that selecting the best classifiers and their combiner by the SES-NSGAII will lead to improve the performance of DES-P. Thus, IDES-P was superior to both SES-NSGAII and DES-P because as mentioned before, the selection phase in the IDES-P was divided into two levels. Therefore, these two levels could improve the classification accuracy. Consequently, the proposed hybrid approach can be applied for a wide range of classification problems.