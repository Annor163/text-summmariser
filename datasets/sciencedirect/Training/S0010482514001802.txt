@&#MAIN-TITLE@&#
Automated diagnosis of Age-related Macular Degeneration using greyscale features from digital fundus images

@&#HIGHLIGHTS@&#
We have developed automated Age-Related Macular Degeneration diagnosis system.Entropies, HOS, FD and Gabor wavelet features are extracted from fundus images.Various feature ranking methods are used to identify optimum features.The proposed system was evaluated using private, ARIA and STARE datasets.It yielded the highest average classification accuracies of 90.19%, 95.07% and 95%.

@&#KEYPHRASES@&#
Age-related Macular Degeneration,Entropy,Texture,Higher order spectra,Gabor wavelet,Computer aided diagnosis,

@&#ABSTRACT@&#
Age-related Macular Degeneration (AMD) is one of the major causes of vision loss and blindness in ageing population. Currently, there is no cure for AMD, however early detection and subsequent treatment may prevent the severe vision loss or slow the progression of the disease. AMD can be classified into two types: dry and wet AMDs. The people with macular degeneration are mostly affected by dry AMD. Early symptoms of AMD are formation of drusen and yellow pigmentation. These lesions are identified by manual inspection of fundus images by the ophthalmologists. It is a time consuming, tiresome process, and hence an automated diagnosis of AMD screening tool can aid clinicians in their diagnosis significantly. This study proposes an automated dry AMD detection system using various entropies (Shannon, Kapur, Renyi and Yager), Higher Order Spectra (HOS) bispectra features, Fractional Dimension (FD), and Gabor wavelet features extracted from greyscale fundus images. The features are ranked using t-test, Kullback–Lieber Divergence (KLD), Chernoff Bound and Bhattacharyya Distance (CBBD), Receiver Operating Characteristics (ROC) curve-based and Wilcoxon ranking methods in order to select optimum features and classified into normal and AMD classes using Naive Bayes (NB), k-Nearest Neighbour (k-NN), Probabilistic Neural Network (PNN), Decision Tree (DT) and Support Vector Machine (SVM) classifiers. The performance of the proposed system is evaluated using private (Kasturba Medical Hospital, Manipal, India), Automated Retinal Image Analysis (ARIA) and STructured Analysis of the Retina (STARE) datasets. The proposed system yielded the highest average classification accuracies of 90.19%, 95.07% and 95% with 42, 54 and 38 optimal ranked features using SVM classifier for private, ARIA and STARE datasets respectively. This automated AMD detection system can be used for mass fundus image screening and aid clinicians by making better use of their expertise on selected images that require further examination.

@&#INTRODUCTION@&#
AMD is a chronic irreversible medical condition characterized by drusen or hyper- or hypopigmentations [1]. It is caused due to cell damage in the macula region resulting in central vision loss. AMD is a multi-factorial disease and has various risk factors, viz. age, ocular risk factors namely drusen, retinal pigmentation, choroidal neovascularization and systemic risk factors namely family history, hypertension and smoking [2–5]. AMD is one of the leading sight-threatening diseases among people above 50years [1,6]. About 20–25 million people are affected globally and it may increase three times in the next 30–40 years with the increase in ageing population [2,7,8]. World Health Organization reported that 8 million people have already been affected with severe blindness due to AMD [2,7,8]. AMD is mainly classified into two types wet and dry [1,9]. They are briefly explained below:(i)Wet macular degeneration affects the retina due to filling of fluid under the retina [1]. It leads to bleeding (see Fig. 1b) and scarring causing loss of vision. It progresses rapidly and may respond to laser treatment in the early stage [1,10]. Approximately 10% of all people with macular degeneration have the ‘wet’ type [1,10,11].Dry macular degeneration is caused by the lack of functioning of visual cells [1]. Initial symptoms of dry AMD are the presence of fatty deposits, called drusen (see Fig. 1c), on the retina [12]. There is no treatment for ‘dry’ type [13]. Most of the people with macular degeneration are affected by the ‘dry’ type [1,10].The Wisconsin AMD grading system categorizes drusen based on size and visibility of the boundary, and is adopted in this study. Drusen can be classified as hard or soft. Further, soft drusen is classified as distinguishable or indistinguishable. Retinal pigmentary lesions are grouped into hypo- and hyper-pigmentation [10,2,14]. The presence of clinical features such as drusen, retinal pigmentation and Geographic Atrophy (GA), dry AMD is categorized into three stages, early, intermediate, and advance[6,10,2], which are briefly described in Table 1.The drusen can be identified by the manual evaluation of retinal fundus images by trained clinicians [6]. Several authors have developed automated drusen segmentation methods, which are the initial step in AMD classification. Automated drusen segmentation methods are briefly described in Table 2.The important challenge in the above-mentioned methods is the identification of drusen and also differentiating drusen from the background noise and other lesions. Moreover, the variation in the shape and size of drusen varies from image to image causing inaccurate detection of drusen. Hence, traditional image segmentation techniques are not very effective in isolating drusen within the retinal photographs [6].In this paper we are proposing to classify normal and dry AMD classes without segmentation of drusen. The fundus images are preprocessed using adaptive histogram equalization. Further, various non-linear features (FD, HOS entropies, and Gabor wavelet) are extracted from the preprocessed images and ranked using t-test, KLD, CBBD, ROC-based and Wilcoxon ranking techniques. Finally, the ranked features are fed to the set of supervised classifiers to identify the best performing classifier. The black diagram of the automated AMD diagnosis system is shown in Fig. 3.This paper is organized as follows: Image acquisition, preprocessing, feature extraction, ranking and selection are presented in Section 2. Classifiers used for AMD classification are briefly described in Section 3. The results of feature ranking method and various classifiers are explained in Section 4. The obtained results are discussed in Section 5 and a conclusion is provided in Section 6.Private dataset: The normal and dry AMD fundus images were acquired using TOPCON non-mydriatic retinal camera (TRC-NW200) from Department of Ophthalmology, Kasturba Medical College, Manipal, India. The images were photographed and labelled by the group of ophthalmologist. The hospital ethics committee has approved the image data for research. The five hundred and forty 24-bit Red Green Blue (RGB) colour images (Normal-270 and dry AMD-270) were stored in lossless JPEG format with an image size of 480×364pixels. The stored AMD images were reviewed by an experienced ophthalmologist and graded into early, intermediate and advance (see Fig. 2) dry AMD images according to Age-Related Eye Disease Study (AREDS) [27] classification.Public dataset: Two publicly available datasets, viz. ARIA (http://www.eyecharity.com/aria_online) and STARE (http://www.ces.clemson.edu/~ahoover/stare), were also used to test the performance of the proposed AMD detection system. The ARIA dataset consists of 101 normal and 60 AMD images acquired using Carl Zeiss Meditec fundus camera with 50° field of view and a resolution of 768×576pixels. The STARE dataset consists of 36 normal and 47 AMD images acquired using TOPCON fundus camera with 35° field of view and a resolution of 700×605pixels.The green band of the RGB colour fundus images was subjected to contrast enhancement using Contrast Limited Adaptive Histogram Equalization (CLAHE). This technique divides the images into blocks and performs adaptive histogram equalization on the divided blocks by considering the pixels in the adjacent area. Hence, each pixel in the image is mapped to a new intensity value which is proportional to its rank in its context region [28], causing anatomical structures such as Optic Disc (OD), macula drusen, and Choroidal neovascularization (CNV) to appear more visible.This section describes the different techniques used to extract features from each green band AMD fundus image. In this work, we have extracted FD, Gabor wavelet, entropies and HOS features from the preprocessed fundus images. They are briefly explained below.Fractal dimension is used to model the natural objects reflecting roughness and self-similarity [29]. Let us consider A is a bounded set in n dimensional Euclidean space and its fractal dimension (D) can be computed using the following equation:(1)1=NrrD(2)D=logNrlog(1r)The differential box counting method [30] considers an image having M×M size which is reduced to a grid size of s×s where2≤s≤12M. Further, the scale factor r can be estimated asr=s/M. Each grid is considered as a set ofs×s×s′sized boxes, which are stacked one by one, wheres′=[s×G/M]and satisfies the relation[M/s]=[G/s′], with G being the total grey levels. The grey level difference of the image in kth and lth box is computed asnr(i,j)=k−l+1, which is the contribution of Nrin (i, j)th grid [30]. The Nris computed by adding all grids contributions which is denoted as follows:(3)Nr=∑i,j=nr(i,j)Nris calculated by changing the values of r. Further, linear least square estimation oflog(Nr)againstlog(1/r)[30] is used to compute D. In this work, sequential modified differential box counting algorithm [31,32] is implemented to compute the D of normal and AMD fundus images. This algorithm considers the grid sizes ass=2i, where i is an integer (here i=2). Moreover, the grid size is doubled untilmax(R,C)<2, where R the rows and C the columns of the image. The Nris computed from the grid boxes by considering minimum and maximum intensity values using Eq. (3). Similarly, D is estimated using Eq. (2).The Gabor wavelet based features provide a proven feature set for texture quantification [33]. The Fourier transform (G(m,n)) of 2D Gabor function (g(x,y)) is computed as follows:(4)g(x,y)=(12πσxσy)exp[−12(x2σx2+y2σy2)+2πjωx](5)Gl,k(m,n)=12πσmσnexp(−12(m2σm2+n2σn2)+2πjωm)where ω is the frequency of sinusoid,σm=1/2πσxandσn=1/2πσyis the standard deviation of the Gaussian envelopes [34]. Two dimensional Gabor wavelets are obtained using dilation and rotation of the mother waveletG(m,n)and it is given below:(6)Gl,k(m,n)=a−lG[a−l(mcosθ+nsinθ),a−l(−msinθ+ncosθ)],a>1wherea−lis the scale factor; l and k are the integers;θ=nπ/Kis the orientation and K is the total number of orientations [34]. The σmand σnare the filter parameters, which are calculated as follows:(7)a=(UhUl)1/(S−1),σm=(a−1)Uh(a+1)2ln2,σn=tan(π2k)[Uh−2ln(2σm2Uh)][2ln2−(2ln2)2σm2Uh2]−1/2where Uhand Ulare respectively the lower and the upper frequency of the sinusoid, S is the number of scales [34].Let us considerI(m,n)is a given fundus image. Its Gabor wavelet transform can be computed using the following equation:(8)gl,k(m,n)=I(m,n)⁎Gl,k(m,n)forl=1,2,…,Sandk=1,2,…,Kwhere ⁎ denotes the convolution operator. The mean (μlk) and the standard deviation (σlk) of the magnitude of the transform coefficients are used as feature vector [34] which are extracted using the following equation:(9)μl,k(m,n)=1M2∑m=1M∑n=1N|gl,k(m,n)|andσl,k(m,n)=(1M2∑m=1M∑n=1N(|gl,k(m,n)|−μl,k)2)1/2we use K=6 orientations and S=4 scales, provide total 48 features (Gabor-1 to Gabor-48), which are denoted as(10)f=(μ1,σ1,…,μ48,σ48).Entropy is mainly used to capture the uncertainty in the image pixels [35–37]. The entropy measures such as Shannon, Kapur, Renyi and Yager are used to quantify the randomness in the intensity distribution of the normal and dry AMD fundus images. ConsideringI(x,y)is either normal or AMD image havingNi(i=0,1,2,3,4,…,L−1)intensity values. Hence, the normalized intensity histogram (Hi) can be computed for the given image (I(x,y)) having size of M×N is given below [35–37]:(11)Hi=NiM×Nwhere M and N are rows and columns of the given image respectively.The Shannon entropy is a measure of average information content [35–37] present in the image and is computed as follows:(12)Shannon’sentropy:S=−∑i=0L−1Hilog2(Hi)where L represents number of grey levels present in the given image.Likewise Renyi, Kapur and Yager entropies are calculated. The Renyi entropy is a generalized entropy [38,39] which is defined as(13)Renyi’sentropy:R=11−αlog∑i=0L−1Hiα,forα≠1,α>0where α is diversity index. Hereα=3.The Kapur entropy is a further generalized version of Renyi entropy [38,39] and it can be defined as(14)Kapur’sentropy:K(α,β)=11−αln∑i=0L−1Hiα∑i=0L−1Hiβ,Forα≠1,β>0,α+β−1>0where α and β are diversity indices. Hereα=0.5andβ=0.7.Yager׳s entropy measure is generally used to capture the visible information present in the image [40] and can be computed as follows:(15)Yager’smeasure:Y=1−∑i=0L−1|2Hi−1||M×N|where M and N are rows and columns of the given image respectively, Hiis the probability distribution of normalized intensity histogram.The radon transform (RT) provides many useful features which may not give any physical meaning as per human perception, however it has mathematical properties which can discriminate the objects [41]. This technique is generally used to reconstruct the image from scattering data in computed tomography. RT transforms the images pixels into line parameters in the Radon domain for a given set of angles [41]. RT [42] can be computed using the following equation:(16)R(ρ,θ)=∫∫−∞∞g(x,y)δ(ρ−xcosθ−ysinθ)dxdywhere θ is the angle at which the line parameters are computed,g(x,y)is the given image andδ(r)is the Dirac function [42,43].Whereδ(xcosθ+ysinθ)is the line integration function ofg(x,y)[42,43] defined using(17)ρ−xcosθ−ysinθ=0In this work, we have used the step sizeθ=10°to compute RT of all images. The HOS bispectrum is performed on these Radon projections.Higher order spectra, or polyspectra, are Fourier spectral representations of third and higher order cumulants of ergodic random processes. They have been extended to apply to deterministic signals and images. In this work, we have the third order HOS or the bispectrum to extract features [44–46]. The bispectrum [47–49] of a deterministic signal x(t) can be estimated as(18)B(f1,f2)=E[X(f1)X(f2)X⁎(f1+f2)]where X(f) is the discrete-time Fourier transform and estimated using Fast Fourier Transform (FFT), f1 andf2are the frequency components that lie between 0 and 1 which are normalized with the Nyquist frequency. The bispectrum of a signal can be denoted with the triangle0≤f2≤f1≤f1+≤f2≤1, considering no bispectral aliasing. Features are extracted by integrating along the slope (a) passing through the bifrequency space [46,50].Different features can be extracted from the bispectrum. Here, bispectral phase entropy (Ph), entropy 1 (P1), entropy 2 (P2) and entropy 3 (P3) are extracted for each radon-transformed (θ−0°,45°,90°,135°) normal and AMD fundus images. The phase entropy can be computed as follows:(19)Ph=∑〈n〉p(Ψn)log(p(Ψn))(20)p(Ψn)=1L∑〈Ω〉l(Φ(B(f1f2))∈Ψn)(21)Ψn={Φ|−π+2πn/N≤Φ<−π+2π(n+1)/N}withn=0,1,…,N−1where B is the bispectrum of the signal, L is the number of points in Ω region, Φ is the phase angle, andl(·)is an indicator function and Ψnis the bin, as depicted in Eq. (20). We have chosen each bin as 45° (with N=4) and the histogram is computed. Further, the Shannon entropy [39] is used to compute three bispectrum entropies which are computed as follows:Normalized bispectral entropy (P1) can be defined as(22)P1=−∑〈k〉pklog(pk)wherepk=|B(f1,f2)|/∑〈Ω〉|B(f1,f2)|, with pkbeing the probability density function and Ω being the bifrequency space [46,50].Normalized bispectral squared entropy (P2) can be defined as(23)P2=−∑〈i〉pilog(pi)wherepi=|B(f1,f2)|2/∑〈Ω〉|B(f1,f2)|2, with pibeing the probability density function and Ω being the bifrequency space [46,50].Normalized bispectral cubed entropy (P3) can be defined as(24)P3=−∑〈n〉pnlog(pn)wherepn=|B(f1,f2)|3/∑〈Ω〉|B(f1,f2)|3, with pnbeing the probability density function and Ω being the bifrequency space [46,50].Feature selection removes the redundant features and retains features which contributes to the classifier performance. It avoids “curse of dimensionality” to enhance the classifier performance [51]. In this work we have evaluated five feature ranking methods namely t-test, KLD, CBBD, ROC-based and Wilcoxon ranking methods. t-test compares the population means of the two groups to identify the correlation among the features [52]. KLD ranks the features based on divergence measure between normal and dry AMD classes [53]. Chernoff bound provides exponential decay on tail distributions using independent variables. Hence it is used with the Bhattacharyya distance for feature ranking [54]. ROC-based feature ranking selects the features using area between ROC and random classifier slope [54]. The Wilcoxon method is a non-parametric test, which does not assume normal distribution.Efficient classification systems can help reduce the screening time and can be used provided they do not trade off accuracy more than desirable. In this work we have used SVM, DT, PNN, k-NN and NB classifiers. They are briefly described below.SVM uses data from normal and dry AMD groups to construct a hyperplane, which separates the two classes. It can be used for non-linearly separable data using kernel functions [55,54,56]. In this work, different kernel functions namely linear, polynomial of orders 2, 3 and radial basis function (RBF) are used. Moreover, we have selected the RBF sigma (σ=2) value to tune the classifier performance. The DT classifier performs the classification task based on set of rules derived from the input features of the training data [54] (normal and AMD). PNN is a feed forward neural network based on Parzens׳ results on probability density estimators. It has three layers such as input, pattern and summation. The compete transfer function in the summation layer used the distance vector probabilities to make the decision during testing [57]. The summation layer spread value (σ) of 0.1 is chosen to obtain maximum accuracy. k-NN is a non-parametric lazy learning algorithm using nearest neighbour principle and makes decision by computing distance between the nearest neighbours [54,58]. In this work we have used k-NN classifier and found that K=1 gave the best performance. NB classifier is derived using the Bayes theorem. It assumes that the data is obtained from normal distribution and also independent. The maximum likelihood algorithm is used to compute the class prior probability and the feature probability. This model is then used along with a maximum a posteriori decision rule to determine the class label of unknown data [54].

@&#CONCLUSIONS@&#
