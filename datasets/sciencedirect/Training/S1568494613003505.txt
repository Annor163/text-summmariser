@&#MAIN-TITLE@&#
Software reliability prediction model based on support vector regression with improved estimation of distribution algorithms

@&#HIGHLIGHTS@&#
To maintain the diversity of the population can improve the performance of the software reliability prediction model, which confirms the improved EDA is effective.In this paper, a method to optimize the SVR parameters is proposed. This method can avoid the blindness of the SVR parameter selection and provide a technical means for the better use of SVR.Software reliability prediction is very important for software engineering. In this paper, an intelligent approach is adopted in order to achieve software reliability prediction and obtain good performance.

@&#KEYPHRASES@&#
Support vector regression,Improved estimation of distribution algorithms,Software reliability prediction,Parameters optimization,

@&#ABSTRACT@&#
Software reliability prediction plays a very important role in the analysis of software quality and balance of software cost. The data during software lifecycle is used to analyze and predict software reliability. However, predicting the variability of software reliability with time is very difficult. Recently, support vector regression (SVR) has been widely applied to solve nonlinear predicting problems in many fields and has obtained good performance in many situations; however it is still difficult to optimize SVR's parameters. Previously, some optimization algorithms have been used to find better parameters of SVR, but these existing algorithms usually are not fully satisfactory. In this paper, we first improve estimation of distribution algorithms (EDA) in order to maintain the diversity of the population, and then a hybrid improved estimation of distribution algorithms (IEDA) and SVR model, called IEDA-SVR model, is proposed. IEDA is used to optimize parameters of SVR, and IEDA-SVR model is used to predict software reliability. We compare IEDA-SVR model with other software reliability models using real software failure datasets. The experimental results show that the IEDA-SVR model has better prediction performance than the other models.

@&#INTRODUCTION@&#
Reliability is the ability of software system to perform its required functions under stated conditions for a specified period of time, and it is an important characteristic inherent in the concept of software quality. It is intimately connected with defects and faults. As more and more faults are encountered, the software reliability will decrease. Software reliability generally changes with time, and these changes can be treated as a time series process.Artificial neural networks (ANN) have general nonlinear mapping capabilities, and have increasingly attracted attention in the field of time series predicting [1–3]. In [4], the reliability of the systems can be predicted by feed-forward multi-layer ANN and radial basis function ANN respectively. The ANN technology has better prediction performance than the autoregressive integrated moving average (ARIMA) approach. In [5], ANN has contributed significantly to software reliability prediction, and which achieved better prediction performance than traditional statistical models. In [6], the counter-propagation and back-propagation ANN models were used to estimate parameters of a reliability distribution with only a small dataset. The experimental results show that the proposed approach improves the accuracy of reliability predicting. In [7], the system reliability may be predicted by a hybrid learning neural fuzzy system. Numerical results demonstrate that the proposed model achieved more accurate predicting results than ARIMA and generalized regression ANN model (GRNN). However, the ANN suffers from a number of weaknesses, e.g., it is based on gradient descent, and it is easy to local minima.Recently, support vector machines (SVMs) [8–11] have been widely applied to solve nonlinear predicting problems in many fields. With the introduction of ɛ-insensitive loss function, it has been also extended to solve nonlinear regression estimation problems, such as new techniques known as support vector regression (SVR) [12]. In [13], the SVM was used to solve financial time series problems. The experimental results demonstrate that SVM forecasts better than back propagation (BP) algorithm. In [14], a two-step kernel learning method based on SVR was proposed for predicting financial time series. The results confirm the advantage of SVR. However, although SVR has very good learning performance and generalization ability, there is no structured way to determine the parameters of SVR.Estimation of distribution algorithms (EDA) [15], sometimes called probabilistic model-building genetic algorithm (GA) [16], have emerged as a generalization of GA, for overcoming the two main problems: poor performance in certain deceptive problems and the difficulty of mathematically modeling a huge number of algorithm variants [17]. In GA, a population of candidate solutions to a problem is maintained as part of the search for an optimum solution. This population is typically represented explicitly as an array of objects. Depending on the specifics of the GA, the objects might be bit strings, vectors of real numbers or some custom representation. In EDA, this explicit representation of the population is replaced with a probability distribution over the choices available at each position in the vector that represents a population member. Moreover, in GA, new candidate solutions are often generated by combining and modifying existing solutions in a stochastic way. The underlying probability distribution of new solutions over the space of possible solutions is usually not explicitly specified. In EDA, a population may be approximated with a probability distribution and new candidate solutions can be obtained by sampling this distribution. Compared with traditional GA, EDA can solve nonlinear variable coupling problems for complex optimization.Software reliability predictions are used for various purposes, such as software planning, reliability assessment, detecting faults in manufacturing processes, and evaluating risks. As reliability prediction plays an increasingly important role in assessing the performance of software systems, intensive studies have been carried out to ensure software reliability. The rest of this paper is organized as follows. Section 2 describes SVR model, expressing it as a combinatorial optimization problem with constraints. Section 3 explains the improved EDA (IEDA) and gives a model of optimizing SVR parameters based on IEDA. In Section 4, we give some assessing methods of the software reliability. Section 5 describes the numerical experiments and the results. Finally, Section 6 shows the conclusions from the experiment results.The performance of SVR depends on the rational optimization of parameters, and the optimization of these parameters is important to predict accurately. The traditional methods of optimizing parameters are: experience selection method (ESM), gradient descent method (GDM), and Bayesian method (BM). However, these methods have their own disadvantages. For example, ESM requires a large amount of experience and domain knowledge in order to obtain the appropriate parameters, and otherwise it is difficult to obtain the appropriate parameters. GDM is very sensitive to the initial point. In addition, GDM is a linear search method, and it is easy to fall into local minimum. Disadvantage of BM is to need some priori knowledge of parameter space for optimizing parameters, and it also needs more computation and computational complexity. In addition, this technique does not guarantee the outcome of better parameters. In fact, some researches have studied how to apply intelligence method to optimize parameters of SVR [18–20].Suppose{(x1,d1),(x2,d2),…,(xn,dn)}⊂Rm×Ris training set, where Rmis the space of the input features xi, and diis the phenomenon under investigation, i.e., the actual value. In ɛ-SVR [19], the goal is to find a function f(x) whose deviation from each target diis at most ɛ for all training data, and at the same time, is as “flat” as possible. For the sake of clarity, we consider the following objective function in the linear case, i.e., F: Rm→R, such that(1)y=f(x)=wϕi(x)+bwhereϕi(x)is the input features, and w and b are coefficients. The coefficients (w and b) are estimated by minimizing the following regularized risk function:(2)RSVR(C)=Remp+12w2=C1n∑i=1nLε(di,yi)+12w2(3)Lε(d,y)=d−y−ε,ifd−y≥ε0,otherwisewhereRSVRandRemprepresent the regression and empirical risk, respectively, C and ɛ are two parameters. In Eq. (2),Lε(d,y)is called the ɛ-insensitive loss function.w2/2is used as a measure of the flatness of the function.Two positive slack variablesξandξ*, which represent the distance from actual values to the corresponding boundary values of ɛ-tube, are introduced. Then, Eq. (2) is transformed into the following convex optimization problem:(4)MinRSVR(w,ξ,ξ*)=C∑i=1n(ξi+ξi∗)+12w2(5)s.t.wϕ(xi)+bi−di≤ε+ξi∗,di−wϕ(xi)−bi≤ε+ξi,ξi,ξi∗≥0.i=1,2,…,nBy introducing Lagrange multipliers and exploiting the optimality constraints, the decision function given by Eq. (1) has the following explicit form [21](6)f(x,αi,αi*)=∑i=1n(αi−αi*)K(x,xi)+bwhereK(xi,xj)is called the kernel function,αiandαi*are the so-called Lagrange multipliers. In Eq. (6), they satisfy the equalityαi∗αi*=0.αiandαi*are calculated by maximizing the dual function of Eq. (4), and the maximal dual function in Eq. (4), which has the following form:(7)MaxR(αi,αi*)=∑i=1ndi(αi−αi*)−ε∑i=1n(αi+αi*)−12∑i=1n∑j=1n(αi−αi*)(αj−αj*)K(xi,xj)under the constraints,∑i=1n(αi−αi*)=0;0≤αi≤C,i=1,2,…,n;0≤αi*≤C,i=1,2,…,n.The value of the kernel is the inner product of the two vectors xiand xjin the feature spaceϕ(xi)andϕ(xj), soK(xi,xj)=ϕ(xi)∗ϕ(xj).Any function that satisfies Mercer condition [21] can be used as the kernel function. Generally, the Gaussian function will yield better prediction performance [15]. Thus, in this work, the Gaussian function,exp(−xi−xj2/2σ2), is used in the SVR. Where, σ2 represents the bandwidth of Gaussian kernel.So, to build a SVR model efficiently, we need to select three positive parameters ɛ, σ and C.Although performance of the EDA is better than GA's, the EDA still has drawbacks. For example, in EDA evolutionary process, the individuals in the population are easy to trend to the same solution and the population diversity declines rapidly. These drawbacks affect the performance of the EDA. In order to maintain population diversity, we improve EDA, and obtain the IEDA, and then the IEDA is used to optimize parameters of the SVR.The chaotic sequence has the characteristics of ergodicity, randomness, initial sensitivity and regularity, and the chaotic mutation operation is an important way to maintain population diversity [22,23]. In this paper, the chaotic mutation was introduced into the traditional EDA. IEDA is described in detail as follows.Algorithm IEDAIEDA evolutionary processStep 1. Generate m initial values x1, x2, …, xmrandomly in the interval (0, 1). LetX0=(x1,x2,…,xm)be an initial point of logistic map, and m is the number of parameters to be optimized.Step 1.1 Many researchers have demonstrated [24,25] that, for logistic map(8)Xt+1=λ⋅Xt(1−Xt)when the parameterλsatisfying3.5699≤λ≤4, after n times iteration, the generated n individualsX1,X2,…,Xnby Eq. (8) is a chaotic sequence. LetX={X1,X2,…,Xn}be a matrix with n rows and m columns, representing the initial population:X=X1X2⋮Xn=x11x12…x1mx21x22…x2m…………xn1xn2…xnmStep 1.2 The initial populationXis extended to the range of the solution space, and the ith variable of the jth individual can be expressed as follows:xji=low+(high−low)xjiwhere low and high are the lower and upper limits of the solution space, respectively.Step 2. Calculate fitness value for each individual of the current population. For individual Xj, its fitness value is calculated as follows(9)F(Xj)=1n∑jn∑im(dji−yji)2where,djiis the ith actual output value of the jth individual,yjiis the ith predict output value of the jth individual. For Eq. (9),F(⋅)is as small as possible.Step 3. Select individuals according to the mutation probability pm<1 to realize chaotic mutation. We calculate the mutation radius of selected individual. The mutation radius of ith variablexjiof the individualXjis calculated according to the following equationRji=v(i)(1−F(Xj))max1≤s≤nF(Xs)wherev(i)=(2(maxx∗i−minx∗i)/n). And, ith variable of the individualXjafter mutation can be expressed asx′ji=xji+2Rji(1−xji). After mutating each selected individual, we calculate the fitness value F of each new individual. If the fitness value F of new individual is less than F value of old individual, then new individuals replace old individuals, and we can obtain the new population, go to Step 4. Otherwise maintain the population not to change, go to Step 5.Step 4. Determine whether to meet the stop criterion of the algorithm, if met, the output current the best individual, otherwise go to Step 5.Step 5. Generate next population.Step 5.1 Select the first0.5nindividuals from the current population. After statistical analysis of selected individuals, build a Gaussian model for each variable of the individual.Step 5.2 Sample1.5nnew individuals accordance to the Gaussian model.Step 5.3 Calculate F values of these1.5nnew individuals, and compare their F values, then choose n better individuals as the next generation population.Step 6. Determine whether to meet the stop criterion of the algorithm, if met, the output current the best individual, otherwise go to Step 3.IEDA is illustrated in Fig. 1.Through the IEDA evolutionary process, we can acquire three optimization parameters, which construct optimized SVR model for predicting software reliability.The prediction procedure based on IEDA-SVR is illustrated in Fig. 2.Hamming distance (HD) is used in this paper since it can describe the difference between individuals. When HD is larger, it means that the difference between individuals is larger, whereas the difference between individuals is smaller. Differences between individuals are calculated asHam=∑Xi,Xj∈XSgn(Xi−Xj).In this study, we represent an individual using bit strings. Assuming the three parameters ɛ, σ and C are represented by the three bit strings with equal to lengths. For example, If ɛ, σ and C are l1=100 … 010 … 001, l2=000 … 110 … 100, l3=011 … 010 … 010 respectively, then the individual is coded into l1l2l3.Letpijkbe the difference value of the individuals Xiand Xjfor the kth bit, i.e.,pijk=1,fxik≠xjk0,other. Therefore, the diversity of population X in the kth bit ispk=∑i=1n∑j=1lpijk. So, the diversity measure of population X is calculated as followsDiv(X)=∑k=1lpkn(n−1)lwhere l is the bit number of the bit string l1l2l3.We use x-fold cross-validation method (CVM) to train the SVR model on the training set. In fact, this is a fitting process which optimizes the parameters of model to make the model fit the training data as well as possible. In x-fold CVM, the original training data is randomly partitioned into x subsets. Of the x subsets, a single subset is retained as the test data for testing the SVR model, and the remaining x−1 subsets are used as training data. The CVM is then repeated x times (the folds), with each of the x subsets used exactly once as the test data. The x results from the folds then can be averaged to produce a single estimation. The advantage of CVM over repeated random sub-sampling is that all observations are used for both training and test, and each observation is used for testing exactly once [26,27].In this paper, training process of SVR is built with a given set of parameters {ɛ, σ, C}, using x−1 subsets as training data. The fitting evaluation of SVR with optimized parameters is calculated by the sum of square error (SSE) or normalized root mean square error (NRMSE) on the test data. This procedure is repeated x times, and each subset is used once for testing. To measure the goodness of fit of IEDA-SVR, we use the correlation coefficient (R). Suppose q is the number of elements in a training data, SSE, and NRMSE, and R represent as follows:SSE=∑i=1q(di−yi)2,NRMSE=∑i=1q(di−yi)2∑i=1qdi2,R=Cov(d,y)σd⋅σy.For simplicity, where diis the actual value,yiis the predict value, andCov(d,y)=1q∑i=1q(di−μd)(di−μy).Stopping condition of training SVR is either the training error is less than 10−4 or not obtaining an individual with a better estimate value after a certain number L of generations.In this paper, two numerical examples are used to demonstrate the predicting performance of IEDA-SVR for predicting software reliability. The software inter-failure times taken from a telemetry network system by AT&T Bell Laboratories [28] are used as the first numerical example. Original data is listed in Table 1. The value Tiis the actual inter-failure time and i is the number of the failure.In the second example, the software failure data obtained from [29] are applied to investigate the prediction performance of IEDA-SVR. Original data is listed in Table 2. The data contains 101 observations of the time series (t, Yt) pertaining to software failure. Here Ytrepresents the failure space time of the software after the tth modification has been made.For predicting a univariate time series, the inputs used in SVR are the past, lagged observations of the time series, while the outputs are the future values. Fig. 3illustrates the basic architecture of IEDA-SVR.In Fig. 3, p denotes the number of lagged variables, which t–p represents the total number of training samples. Following successful training, the SVR can predict future outcomes yt+kat different time steps k. If k=1, the prediction is a one-step-ahead predict, while when k>1 the prediction is a multi-step predict. Since the accumulation of errors, the performance of multi-step predicting is usually poor [4]. In practice, one-step-ahead predicting results are more useful since they provide timely information for preventive and corrective maintenance plans. Therefore, we consider one-step-ahead predictions in this study.After large number of experiments, the parameters of the IEDA-SVR are listed in Table 3. Of course, they were chosen arbitrarily.

@&#CONCLUSIONS@&#
In this paper, we proposed a hybrid IEDA-SVR. In order to maintain the population diversity, the chaos mutation was introduced into traditional EDA. IEDA is used to optimize parameters of SVR, and IEDA-SVR is used to predict software reliability. We used two real software failure datasets in the experiments. We compare prediction performance of proposed model with other various models. The experimental results demonstrate that it is very effective of utilizing IEDA-SVR to predict software reliability, and IEDA-SVR has better prediction performance than the other compared models and a fairly accurate prediction capability. The experimental results also show that to maintain the population diversity can improve the performance of the prediction model. In addition, IEDA-SVR does not require priori knowledge of parameters and as such can give useful results.The contribution of this paper is as follows:(1)To maintain the population diversity can improve the performance of EAD, which confirms the software reliability prediction model based on IEAD is effective.In this paper, a method to optimize the SVR parameters is proposed. The proposed method can avoid the blindness of the SVR parameter selection and provide a technical means for the better use of SVR.Software reliability prediction is very important for software engineering. In this paper, an intelligent approach is adopted in order to achieve software reliability prediction and obtain good performance.We note that the sensitivity of predefined parameters is an important issue. Our future work is to analyze the impact of these parameters for performance of software reliability predict model.