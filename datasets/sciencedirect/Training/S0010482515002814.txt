@&#MAIN-TITLE@&#
Mid-level image representations for real-time heart view plane classification of echocardiograms

@&#HIGHLIGHTS@&#
Proposal of new mid-level representations for real-time heart view plane classification of 2D echocardiograms.Approach relies on bags of visual words with image sampling using large regions.Extensive set of experiments comparing the proposed method with existing descriptors.Evaluation considering real-time constraints, noise filtering, and different machine learning classifiers.Proposed approach is very fast to compute and consistently achieves accuracy above 90%.

@&#KEYPHRASES@&#
Echocardiography,Feature extraction,Real-time systems,Image classification,Pattern analysis,

@&#ABSTRACT@&#
In this paper, we explore mid-level image representations for real-time heart view plane classification of 2D echocardiogram ultrasound images. The proposed representations rely on bags of visual words, successfully used by the computer vision community in visual recognition problems. An important element of the proposed representations is the image sampling with large regions, drastically reducing the execution time of the image characterization procedure. Throughout an extensive set of experiments, we evaluate the proposed approach against different image descriptors for classifying four heart view planes. The results show that our approach is effective and efficient for the target problem, making it suitable for use in real-time setups. The proposed representations are also robust to different image transformations, e.g., downsampling, noise filtering, and different machine learning classifiers, keeping classification accuracy above 90%. Feature extraction can be performed in 30fps or 60fps in some cases. This paper also includes an in-depth review of the literature in the area of automatic echocardiogram view classification giving the reader a through comprehension of this field of study.

@&#INTRODUCTION@&#
Echocardiography plays an important role aiding cardiologists in heart analysis. It relies on the use of ultrasonic techniques that can capture information about the heart of a patient. The heart ultrasound images provide information about different anatomical aspects of the heart structures such as the position, size, and shape of the atrium and ventricles, and how they move. In an echocardiogram examination, the operator of an ultrasound device uses a probe to capture the heart images of a patient. Ultrasound devices capture “slices” of the heart, which are commonly named heart views. Those views depend on the position of the probe in the patient and the most common views are the parasternal long axis, parasternal short axis, and apical views. In each view, different heart structures can be observed and analyzed.Automatic classification of echocardiogram ultrasound images has been studied recently in several aspects [1–10]. The most common task is the automatic classification of echo videos into the different heart views. The automatic classification has several applications. During an ongoing examination, automatically classifying the heart views under analysis makes it possible to label the images/videos as they are recorded, providing a facility for organization and management of echocardiogram videos. It can also help the operator for better probe positioning and even for training of new specialists. Knowing the heart view plane, even after the examination, can make it possible the retrieval and analysis of examinations according to the heart view [11,12]. Other possible use is when taking heart measures [13], like blood volume and size of cavities, which usually requires a previous manual indication of the heart view. Therefore, there are two main scenarios where the automatic recognition of heart views can be used: the first includes the categorization of pre-stored echo videos while the second aims at the real-time view classification, whereby the view categorization is performed during an examination. Efficiency constraints are not as important for the former as they are for the latter.The main approaches used for automatic view plane classification of echocardiograms are based on extracting features from heart images (echo video frames) and using a machine learning scheme for learning and then predicting the view of a test echo video or image [1,3,4,6–9]. For feature extraction, some works point out that the direct use of traditional image descriptors usually employed for object and scene recognition may fail in the ultrasound scenario [6]. However, in the literature review that we present in the paper, we could notice a trend for using generic features for heart view classification, like GIST [8] and HOG [7]. In the current work, we show that despite the noise and contrast issues of ultrasound images, some traditional image representation approaches can be effectively used. Our proposed approach is based on the use of bags of visual words (mid-level features), which are widely used in the computer vision community for visual recognition [14–16].We show experimentally on a dataset of more than 7500 frames (in 52 echo videos, captured by a device used in multiple configurations) how different descriptors perform. Considering the real-time requirement, we also evaluate the descriptors in resized versions of the dataset. An additional evaluation is also performed considering the use of noise filtering procedures. On top of that, we also show how the proposed mid-level representations perform with different machine learning classifiers (Support Vector Machines and Random Forests). We show that the proposed approach is robust to any of those transformations and to the different classifiers, being suitable for use under several different conditions.The main contribution of this paper is the proposal of an efficient and effective approach for heart view classification that can be used both for pre-stored echo videos and for real-time applications. Another differential aspects of the paper are an evaluation of several image representation schemes for automatic classification of echocardiogram images/videos and an in-depth review of the literature detailing the main advances in the heart view classification task and contrasting the pros and cons of each approach.Section 2 discusses approaches employed in the literature for automatic heart view classification, as well as existing image descriptors and the machine learning classifiers used in this paper. Section 3 introduces our proposed approach while Section 4 shows the experiments and the obtained results. Finally, Section 5 concludes the paper and delineates possible future work.

@&#CONCLUSIONS@&#
This paper presents mid-level representations for real-time heart view classification of echocardiograms. The paper also presents a thorough experimental evaluation of different image descriptors and an in-depth literature review of the existing solutions to this problem.In the in-depth literature review presented, we could note that the existing solutions usually present constraints, such as being evaluated only with the end diastolic frame, requiring the training of specific detectors or regions of interest and, in some cases, requiring manual intervention. On top of that, we could also note a trend in more recent works of using generic feature descriptors for heart view classification.Our real-time solution to this problem is based on the use of a bag-of-visual-words (BoVW) methodology, following the trend observed in the literature. The main novelty herein relies on low dense sampling for image characterization, i.e., large and representative image regions are used (instead of a very dense grid) resulting in few (<20) highly discriminative regions per image. The small number of regions drastically reduces the extraction time, making our approach suitable for real-time systems. Another effect of using large regions is that those regions may sometimes correspond to whole heart structures. Hence, the final BoVW descriptor can roughly correspond to an activation vector of heart structures. The proposed approach does not depend on performing any pre- or post-processing in the images or in the detected regions.We compared the proposed approach with several existing image descriptors, both global and based on visual codebooks. Our approach is the only one to present, at the same time, high accuracy and fast feature extraction. We have also evaluated the methods in transformed versions of the image dataset (downsampling and noise/speckle filtering) and the proposed approach was robust to the transformations. Experiments comparing two different classifiers (linear SVMs and Random Forests) also show the quality and robustness of the proposed mid-level representations. In terms of effectiveness, our results were consistently above 90% of average accuracy. Specifically after noise filtering with the median filter, the proposed descriptors achieved very high accuracy (∼98%). In terms of efficiency, in some cases, we could process 30fps or 60fps videos in real-time. Therefore, we can rely on the proposed classification system regardless of the image resolution and acquisition conditions (e.g., presence or absence of noise).As future work, we mention the possibility of creating a supervised codebook, aiming at selecting image regions containing whole heart structures. This would open the opportunity to create a bag of heart structures. Also, as most of the image descriptors herein explore different properties for image characterization, it is likely that some of them encompass complementary information which can be an opportunity for feature and classifier fusion.We also would like to evaluate the method with more diseased hearts. Adding training examples of this kind, we could evaluate the generalization power of the approach. We also envision the applicability of the proposed characterization to other problems outside the realm of echocardiography.Another important evaluation for real-time systems would be in the use of open-set classifiers, for correctly discarding videos/frames of unknown views. While searching for the correct probe position in the patient, the ultrasound device shows images that are not related to any view of interest. A real-time classification system should be able to ignore such images instead of classifying them as one of the existing views.None declared.