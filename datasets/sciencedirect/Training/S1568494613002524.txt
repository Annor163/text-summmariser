@&#MAIN-TITLE@&#
Intelligent controllers for bi-objective dynamic scheduling on a single machine with sequence-dependent setups

@&#HIGHLIGHTS@&#
Development of Reinforcement Learning-based controller for multi-objective sequencing of jobs on a manufacturing facility.Development of evolutionary-tuned fuzzy controller for dynamic sequencing of jobs on a manufacturing facility.Comparison of the developed controllers to fifteen existing dispatching heuristics including recently proposed ones.The proposed controllers produced considerably more Pareto optimal solutions than the examined dispatching rules.Most of the solutions produced by the examined dispatching rules were dominated by the solutions of the proposed controllers.

@&#KEYPHRASES@&#
Scheduling,Dispatching rules,Reinforcement Learning,Fuzzy Logic,Multi-objective evolutionary optimization,

@&#ABSTRACT@&#
This article addresses the problem of dynamic job scheduling on a single machine with Poisson arrivals, stochastic processing times and due dates, in the presence of sequence-dependent setups. The objectives of minimizing mean earliness and mean tardiness are considered. Two approaches for dynamic scheduling are proposed, a Reinforcement Learning-based and one based on Fuzzy Logic and multi-objective evolutionary optimization. The performance of the two scheduling approaches is tested against the performance of 15 dispatching rules in four simulation scenarios with different workload and due date pressure conditions. The scheduling methods are compared in terms of Pareto optimal-oriented metrics, as well as in terms of minimizing mean earliness and mean tardiness independently. The experimental results demonstrate the merits of the proposed methods.

@&#INTRODUCTION@&#
Real-world manufacturing environments are highly dynamic systems where unforeseen events that alter the state of the system in an unpredictable way occur continuously. In this setting, scheduling is an infinite horizon, reactive process where existing schedules which have been rendered obsolete due to unexpected disruptions are constantly subjected to revision. The gap between real-life problems and static, deterministic problems addressed in classical scheduling theory has given rise to an increasing number of publications on dynamic scheduling over the last years [1]. Moreover, realistic scheduling decisions need to take into consideration multiple and possibly conflicting objectives [2]. The preferences regarding scheduling criteria may not be explicitly stated and they may also vary with time.Such an environment is modeled, at a certain level of abstraction, by the manufacturing system investigated in this paper. The manufacturing system consists of a single machine that processes multiple types of jobs and an input buffer. Jobs with stochastic processing times and due dates arrive dynamically to the system at random time intervals. A setup is required when switching from one job type to another. The system operates under a completely reactive rescheduling policy, meaning that the queueing jobs are rescheduled whenever specific events occur. The single machine case is not restrictive for a number of reasons. First, single-machine problems form the building blocks of solutions for systems of higher complexity. Second, in practice, it is common to aggregate several manufacturing functions in a single operation, and third, the performance of complex manufacturing systems often depends heavily on a single bottleneck machine.Dispatching rules are frequently used in completely reactive scheduling. Their main advantage is that they are easy to implement and can provide solutions of good quality with low computational cost. However, no rule is optimal for all objective functions, types and parameters of manufacturing systems. The performance of various dispatching rules has been examined in numerous simulation studies; some indicative examples can be found in the works of Vinodand Sridharan [3], Ang et al. [4] and Thiagarajan and Rajendran [5].The properties of the dispatching rules have led to their wide-spread adoption in industrial practice and, in turn, to their extensive study in scientific literature. Dispatching rules which adapt to the current situation have been added to the set of traditional, static rules. Nonetheless, there is a growing trend, which is fueled by the limitations of dispatching heuristics, to develop more sophisticated scheduling schemes by using techniques from Artificial Intelligence and Machine Learning.The purpose of this paper is to propose methods for building adaptive controllers for dynamic dispatching rule selection with limited human expert interference in the design phase. Two distinct approaches are proposed, a Reinforcement Learning-based and one based on Fuzzy Logic and multi-objective evolutionary optimization. The two approaches will be hereafter referred to as RLS and FS for short. Both controllers/schedulers receive the same representation of the system state as input. The RLS learns a mapping from states to actions by interacting with its environment. It uses an average reward Reinforcement Learning algorithm to update a table of Q-values, the elements of which correspond to the values of selecting specific dispatching rules to certain states [6,7]. The FS stores its knowledge in a set of fuzzy IF-THEN rules where the antecedent terms describe the current state and the consequent terms represent dispatching rules. In each decision-making epoch, the active fuzzy rules and their strengths are identified and the queueing jobs are scheduled according to an adaptive, composite rule. The SPEA2 multi-objective evolutionary algorithm is used to design the consequent terms of the FS [8].The focal points of this research are discussed hereafter. To the best of the authorsâ€™ knowledge, this is the first time that Reinforcement Learning-based and evolutionary-tuned fuzzy controllers are developed for the manufacturing system investigated in this paper. An extensive set of fifteen dispatching rules is examined, including recently proposed setup-oriented rules by Vinod and Sridharan [9] which are not well-studied. The performance of the dynamic scheduling approaches is monitored in multiple simulation scenarios, where the output of the simulation experiments is subjected to rigorous statistical analysis. Unlike most Reinforcement Learning applications for dynamic dispatching rule selection which consider a single objective measure, here emphasis is given in the multi-objective aspect of the dynamic scheduling problem. Mean earliness and mean tardiness are considered both simultaneously and independently, but the proposed methods can be applied for any objective criterion/criteria. Their effectiveness is highlighted by their ability(a)to produce considerably more Pareto optimal solutions than the examined dispatching rules,to generate solutions that dominate the majority of locally non-inferior solutions associated to the examined dispatching rules and,to outperform the examined dispatching rules when the objectives are considered independently in several cases.The practical implication of this research is that the proposed methods can be used to build libraries of control policies that can be easily implemented in real-life industrial environments. When changes in preferences of the scheduling objectives occur, the practitioner can refer to the library of control policies and select the most suitable policy.The remainder of this paper is organized as follows. A brief overview of the related literature is provided in Section 2. In Section 3, the formal description, of the manufacturing system investigated in this paper, is presented. The dispatching rules considered in this study are discussed in Section 4. In Section 5 and the sub-sections therein, we give the detailed description of the proposed controllers. The experimental results are presented and analyzed in Section 6. The paper concludes with a synopsis and some directions for future research in Section 7.

@&#CONCLUSIONS@&#
