@&#MAIN-TITLE@&#
Higher order maximum persistency and comparison theorems

@&#HIGHLIGHTS@&#
A method to find a part of an optimal solution in discrete optimization problems.Applicable to multilabel and higher order graphical models.Based on a simple sufficient condition associated with a given polyhedral relaxation.Generalizes many existing methods originating from different areas of research.Provably determines same or larger part of an optimal solution in a number of cases.

@&#KEYPHRASES@&#
Persistency,Partial optimality,LP relaxation,Discrete optimization,WCSP,Graphical models,

@&#ABSTRACT@&#
We address combinatorial problems that can be formulated as minimization of a partially separable function of discrete variables (energy minimization in graphical models, weighted constraint satisfaction, pseudo-Boolean optimization, 0–1 polynomial programming). For polyhedral relaxations of such problems it is generally not true that variables integer in the relaxed solution will retain the same values in the optimal discrete solution. Those which do are called persistent. Such persistent variables define a part of a globally optimal solution. Once identified, they can be excluded from the problem, reducing its size.To any polyhedral relaxation we associate a sufficient condition proving persistency of a subset of variables. We set up a specially constructed linear program which determines the set of persistent variables maximal with respect to the relaxation. The condition improves as the relaxation is tightened and possesses all its invariances. The proposed framework explains a variety of existing methods originating from different areas of research and based on different principles. A theoretical comparison is established that relates these methods to the standard linear relaxation and proves that the proposed technique identifies same or larger set of persistent variables.

@&#INTRODUCTION@&#
Optimization models in the general form of minimizing a partially separable function of discrete variables, known as energy minimization, weighted/valued constraint satisfaction or max-sum labeling, proved useful in many areas. The function has the formEf(x)=∑c∈Efc(xc). In computer vision and machine learning such models are largely motivated by maximum a posteriori inference in graphical models [71] used to model a variety of structured statistical recognition problems. In case variables take only two values 0 or 1, the problem is known as pseudo-Boolean optimization or 0–1 polynomial programming. Problems where terms (summands) involve at most two 0–1 variables at a time are called quadratic. We consider the general case, where terms may couple more than two variables at a time (higher order) and variables can take more than two values (multilabel).One major trend for performing inference in graphical models is represented by graph cut methods. The basic capability is essentially to solve a binary pairwise submodular problem, e.g., image segmentation [18], by reduction to a minimum cut/maximum flow problem. For the latter, many efficient algorithms exist and their running time is experimentally near linear for typical vision problems [9]. This basic method was extended to submodular multilabel problems [21,51], to general multilabel problems by solving for an optimized crossover between two candidate solutions at a time [10], to higher-order 0–1 models reducible to a graph cut [16,34] and to combinations of higher order and multilabel [13,41].Another technique that can be considered nowadays as a basic graph cut method is the roof dual relaxation [6] known in computer vision as quadratic pseudo-Boolean optimization (QPBO) [32]. It allows to find a partial optimal solution to a non-submodular binary problem and reduces to finding a minimum cut in a specially constructed network [7]. It can be interpreted [28] as solving a submodular relaxation of the initial problem. This basic method is again extended to multilabel problems by solving crossover problems [42] and to general higher order 0–1 problems by reduction (quadratization) techniques expressing the function as a quadratic function with auxiliary variables [5,15,22].Another direction of extending graph cuts to higher order models relies on minimization of more general submodular functions. Several efficient max-flow based algorithms have been proposed [4,29] for minimization of a sum of submodular functions (SoS). A natural extension of QPBO is represented by submodular and bisubmodular relaxations [24,28].Arguably, linear programming (LP) is a much more costly tool than computing a minimum cut. Yet, it provides theoretical insight to many methods [36,37] and there has been solvers developed that can address (sometimes approximately) large scale problems. Dual decomposition methods [35,53] or dual block-descent methods, in particular TRW-S [26], are competitive with graph cut based methods in terms of speed and quality. There are extensions of these specialized LP methods to higher order models [31,33]. Smoothing [49] and proximal [47] methods are scalable and offer a theoretically guaranteed convergence speed. Cutting plane approaches [60,73] are used to tighten the relaxation adaptively to the problem.One drawback of relaxation based methods is that the final discrete solution is obtained by so-called rounding schemes and often appears inferior to solutions by graph cut methods as they stay feasible to the discrete space. Even in the case when many of the relaxed variables take integer values in the optimal relaxed solution, a fundamental problem remains that they may not take the same integer values in the optimal discrete solution. Therefore, unless the relaxation is tight, a local rounding technique cannot provide any guarantees for general models. The situation is dramatically different when we consider quadratic pseudo-Boolean functions. There, all variables that are integer in the relaxation correspond to at least one globally optimal discrete solution [20,44]. This property of the relaxation is called persistency. For general 0–1 polynomial problems persistency was studied by [2,43]. In their terminology persistency is associated with relaxations and is a property of the relaxed solution as a whole. In this work we call any partial assignment of a subset of discrete variables persistent if it can be provably extended to a globally optimal solution based on the properties of the relaxation or any other sufficient condition. Success of relaxation based exact methods such as [50] on computer vision and machine learning problems suggests that often a large part of the relaxed solution is integral. In this case we are interested in determining the largest subset of such variables that is persistent.

@&#CONCLUSIONS@&#
Techniques for partial optimality avoid the NP-hardness of the energy minimization problem by exploiting different sufficient conditions by which a part of optimal solution can be found. We proposed a new sufficient condition corresponding to a given polyhedral relaxation and verifiable in polynomial time. The condition generalizes the mechanism of improving mapping which is present in many works (although often in a hidden form) and allows to explain them from this perspective. We can explain variety of methods originating in different fields and relate these methods to linear relaxations. In particular, it follows that all covered methods cannot be used to tighten FLP relaxation. Applying them as a preprocessing in solving the FLP relaxation may only speed it up but cannot change the set of optimal relaxed solutions. We formally posed and studied the problem of determining the largest set of persistent variables subject to the general sufficient condition. It appeared that there are reasonably large classes of this problem (restricted by the set of allowed mappings) which can be solved in polynomial time. While the proposed solution might not be the most efficient, its generality allows to subsume multiple problem reformulations, reductions, equivalent transformations and choices that other existing techniques depend on. In bisubmodular relaxations, this is the choice of a bisubmodular lower bound function, in method [40] the choice of the order of labels and the test labeling, in methods [15,22] choice of the sequence of the reductions and flips. While optimizing these methods w.r.t. to all such choices does not seem tractable, it is tractable to find a persistent assignment (by the proposed method) which is at least as good as if these choices were optimized over.In the experimental evaluation we verified that our theoretical comparisons hold true, i.e. that all evaluated methods (except DEE2 for which we do not claim anything) have output FLP-improving maps in all test cases. Our linear program (L1) had always integer optimal solution33With exception of few cases when CPLEX experienced a numerical error.ζ. The persistent assignment found by our method with FLP-relaxation was larger per instance and significantly larger on average.