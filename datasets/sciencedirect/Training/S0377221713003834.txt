@&#MAIN-TITLE@&#
Dynamic decision making for graphical models applied to oil exploration

@&#HIGHLIGHTS@&#
We consider a sequential DP problem for oil and gas exploration.Prospects are correlated through graphical models (BN or MRF).We develop approximated strategies for solving large problems.We use heuristic strategies as benchmark for results comparison.We show the benefits in terms of expected revenues and discuss the results.

@&#KEYPHRASES@&#
Bayesian Networks,Dynamic programming,Graphical model,Heuristics,Petroleum exploration,

@&#ABSTRACT@&#
We present a framework for sequential decision making in problems described by graphical models. The setting is given by dependent discrete random variables with associated costs or revenues. In our examples, the dependent variables are the potential outcomes (oil, gas or dry) when drilling a petroleum well. The goal is to develop an optimal selection strategy of wells that incorporates a chosen utility function within an approximated dynamic programming scheme. We propose and compare different approximations, from naive and myopic heuristics to more complex look-ahead schemes, and we discuss their computational properties. We apply these strategies to oil exploration over multiple prospects modeled by a directed acyclic graph, and to a reservoir drilling decision problem modeled by a Markov random field. The results show that the suggested strategies clearly improve the naive or myopic constructions used in petroleum industry today. This is useful for decision makers planning petroleum exploration policies.

@&#INTRODUCTION@&#
This paper considers the problem of sequential decision making, where the outcome of one decision will influence the others. Our motivation and main applications are from oil and gas exploration, where a petroleum company must evaluate a set of potential drilling prospects. For each prospect, we may either drill or not. There is a cost of drilling, but revenues if the well discovers oil or gas. The prospects are statistically dependent, and drilling at one prospect gives information that is used to update the probability of success at other prospects. The goal is to find an optimal drilling sequence, including when to stop drilling and abandon the remaining prospects.The optimization of the expected utility function is a trade-off between two factors: the direct reward from the exploitation, and the indirect gain of learning, or exploration, that helps us make informed future decisions. The balance between the two is controlled by a discounting factor. With no discounting, the problem becomes a maximization of the value of information, whereas a high discounting factor leads to a greedy search where only immediate gain counts.In the oil industry prospects are typically evaluated one-by-one. The implicit working assumption is then independence between prospects, and a greedy search is optimal. As petroleum companies are now forced to look for smaller volumes, gains can be achieved by joint modeling of prospects. Recent work by VanWees et al. (2008) and Martinelli et al. (2011) use Bayesian Networks (BNs) to capture the geological dependencies between prospects, while Bhattacharjya et al. (2010) study the effect of various data acquisition schemes for reservoir units modeled by a Markov random field (MRF). Dependence means that we can update the probability model after exploring the most lucrative prospect. We can next go for the second best prospect, conditional on the outcome of the first, and so on. This line of thinking leads to a myopic (conditional greedy) approach, which uses the dependence in the model for forward learning about the prospects. As is common in sequential decision making, this forward selection approach can be improved by taking the expected value over all possible future drilling scenarios into account, which leads to the optimal solution given by a dynamic program (DP).Our goal with the current paper is to compare various dynamic strategies for the large BN model in Martinelli et al. (2011) and on the MRF in Bhattacharjya et al. (2010). This challenge of constructing drilling strategies for dependent prospects has not been studied much, except certain special cases: Kokolis et al. (1999) describe a similar problem with a focus towards decision making under uncertainty and the technical risks connected to a project. Smith and Thompson (2008) analyze the consequences of dependent versus independent prospects, and give drilling guidelines that are optimal in special situations. In Bickel and Smith (2006) and Bickel et al. (2008) DP is used to compute the optimal sequences and profits from six dependent prospects. The big challenge which we address here is that related to the combinatorial increase in the number of scenarios. DP is not tractable when the number of prospects gets large.A possible solution to large problems is offered by approximate DP methods, see Bertsekas and Tsitsiklis (1996) and Powell (2008). The optimization function is then replaced with a statistical model that captures the impact of decisions now on the future. For our graphical representation of dependent prospects it is not obvious how to find a statistical model that approximates the future value function. Instead we study look-ahead policies, where a DP is used for a finite future horizon and heuristics approximate the continuation value (CV). We also apply pruning of the decision tree, i.e. we ignore unlikely branches to reduce the combinatorial problem. The sequential decisions are thus made according to a rolling-horizon algorithm, where we pick one prospects at a time, update the probabilities, look-ahead using DP and select again. Similar strategies are discussed in Chapter 8 of Powell (2007). An application of such strategies to wind energy is presented in Zhou et al. (2012). Our methods are different because of the statistical modeling based on a BN and MRF. The operations research community have been interested in research ideas at this interface (Meisel and Mattfeld, 2010) in diverse applications, see e.g. Falzon (2006) for military operations. Moreover, the field of learning within BNs is quite active, see e.g. Dearden et al. (1999), Heckerman (1999) or Sucar et al. (2012), but there has been little focus on the sequential selection of nodes, which is our focus for the petroleum prospect selection problem.Note that when considering a set of independent prospects, the optimal sequential decisions are offered by Gittins indeces (Gittins, 1979), used for a petroleum example by Benkherouf and Bather (1988). In our model the correlation is much more complex, and the actions influence the model probabilities in a complicated manner. Branch and bound methods are non-heuristic in the sense that they produce lower and upper bounds for the values (Goel et al., 1979). In practice the gap between bounds can be wide, and in our context we will typically lack monotonicity when computing the best (discounted) sequence. See Brown and Smith (submitted for publication) for promising work in this direction, using the BN that we consider here as an example. See also Ryzhov et al. (2012) for continuous examples in this context, with statistical dependence.We have no theoretical restrictions on the underlying statistical model for dependence. There is a practical requirement that conditional distributions can be computed fast, since many of these conditionals will be evaluated when designing a strategy. For comparing strategies, it is advantageous if we can easily simulate from the models. The BNs and MRFs we consider here are fast to update and easy to simulate from.The paper develops as follows: In Section 2 we motivate by introducing the notation and statistical model for the oil and gas exploration examples. In Section 3 we present the DP algorithm for our problem. In Sections 4 and 5 we propose the various heuristic strategies, and the algorithms used to evaluate the properties of the sequential exploration strategies. In Section 6 we provide results for a small BN model and the BN case study of 25 prospects in the North Sea. In Section 7 we analyze a MRF for a oil reservoir represented on a 5×20 lattice.We consider a set of N prospects. These N prospect nodes are a subset of the total M nodes in a graph. The remaining M−N auxiliary nodes impose the specified dependency structure in the model, but are not observable. For every node i=1,…, M we have a discrete random variable xi∈{1,…, ki}. In the examples below we use ki=k, and k=3. The random vector of all variables is x=(x1,…, xM), where the N first components correspond to the prospect variables. We model the probability distribution of x by a BN or a MRF. We will next motivate our problem description via our main case study.The BN in our main example is defined via a directed graph, which means the joint probability model p(x) is the product of conditional distributionspxi|xipa, for all nodes i=1,…, M, andxipadenotes the set of outcomes at parent nodes of i. Fig. 1shows the directed graph connecting parent nodes to nodes via edges. The graph contains N=25 prospect nodes, while there are M=42 nodes in total.The graph in Fig. 1 is built from the causal large scale geological processes required to make sufficient amounts of oil and gas, see Martinelli et al. (2011). The model intends to translate geological prior knowledge into an expert system; this step is common in other fields, such as biology or reliability (see Lacave and Diez (2002) for a review), but is new in the hydrocarbon (HC) exploration context. The network reflects the geology behind the HC formation and migration in a sector of the Norwegian part of the North Sea. In the geological literature this process goes under the name of charge or source formation, and is one of the relevant factors for the HC accumulation. Other key-factors are the presence of a reservoir, i.e. a porous rock that can hold the HC, and the presence of a trap structure, that presents the HC from leaking out. These three main elements are generally regarded as independent (Gluyas and Swarbrick, 2003) by the industry, and their risk is assessed separately. In this geographical part of the North Sea, the risk connected to trap and reservoir is small, and we will therefore focus our attention on the source part.Fig. 1 contains three different kinds of nodes: we can see four K-nodes that represent kitchens, i.e. areas where the hydrocarbon (HC) generation has been or still is in place, and where the migration of HC started. The P-nodes represent geological macro-regions able to store HC. Finally, the bottom numbered nodes, 1,…, 25 are prospect nodes where the oil and gas company considers drilling wells. The node outcomes are discrete with three possibilities (k=3), correspondent to dry, oil or gas. The edge structure, which were defined by geologists with much experience on the particular basin and petroleum system, are likely migration paths for the HC through geological time. In this form, the edge structure seems to be rather well known. The conditional probability tables (CPT) were specified in a collaborative effort between the geologist and ourselves. The CPT encode the migration arrows into quantitative assessments of the probability of success at a child node given the parents. The realistic parameterization is based on geological and geophysical rules, and attempts to keep the number of tuning parameters low. Each migration path is characterized by just two parameters, one representing the probability of HC flow between the two nodes, and one representing the probability of a gas flow, given that a HC flow is in place. This split is due to a working assumption of abundant gas being able to squeeze out the oil, since its density is lower than that of oil. Further background for this network is provided in Martinelli et al. (2011). Noteably, Martinelli et al. (2011) did not consider the interesting operational research problem of sequential exploration of the dependent prospects, which is our focus here.Examples of evidence propagation are shown in Fig. 2. Here we display the difference between the marginal probability of the oil and the conditional probability of oil after at observation (or evidence) in prospect 14 (top) or 10 (bottom). On the left we show the effect of dry evidence, on the right the effect of oil evidence. We note that oil probabilities in the prospects close to evidence nodes are either boosted (right) or lowered (left). We further note that the differences are higher for unlikely evidence: For example, the effect of a dry evidence in prospect 14 (left, top) is bigger than the effect of oil evidence (right, top), since this latter event has 45% probability of occurrence, while the former has just the 10% probability (see Table 4).The motivation for our current paper is the ability to construct dynamic exploration strategies for the 25-node BN. But, note that the particular type of dependency structure is not critical. However, for our purposes of sequential design we require many updates of the probability model, based on evidence such as that demonstrated in Fig. 2. Fast updating of the conditional probabilities becomes important for computational reasons. BNs are fast to update using for instance the junction tree algorithm, see e.g. Lauritzen and Spiegelhalter (1988) and Cowell et al. (2007). This was used to construct the results of Fig. 2. To demonstrate a larger span of probability models, we use a MRF example in Section 7. This application is for a lattice of cells in a specific reservoir in the North Sea. The MRF model is defined over neighborhoods on the lattice, where p(xi∣x−i)=p(xi∣xj; j∈Ni), and x−iis the vector of all variables except xi, while Niis the neighborhood of node i. Again we need fast updating, and moderate size MRFs can be computed recursively by forward–backward algorithms (Reeves and Pettitt, 2004). Moreover, we will use Monte Carlo samples to generate realistic future scenarios. It is easy to draw samples x=(x1,…, xM)∼p(x) from the BNs and MRFs we consider.Given a probabilistic model with a certain dependence structure, we want to develop a drilling strategy, i.e. a dynamic road map that leads us through the exploration phase of the prospects. Since the prospects are dependent, the outcome of one changes the probability of success in the others (see Fig. 2). The strategy of continued drilling thus entails a sequential updating of the probability model. When building such strategies, we make certain assumptions about the way decisions are made. First, we assume that the decision maker selects one node at a time. Without this assumption, the problem would grow to allow all orders of two-tuples, three-tuples, etc. Second, we assume that there are fixed revenues and costs associated with each prospect. If we choose to explore a prospect, we have to pay a drilling cost, but for certain outcomes of the node variable, we receive a revenue. For instance, if the outcome is oil, we get the fixed revenues associated with this outcome. These revenues and costs typically change from prospect to prospect. Finally, we assume the utility function contains separate parts for each prospect, without any shared costs between them. Various extensions of these assumptions are possible, but makes the presentation much harder. We discuss useful practical extensions in the context of the application in Section 6.3.To describe this sequential decision problem mathematically we follow the notation of Bickel and Smith (2006) which seems to be the useful here. We let ωibe the observable in node i=1,…, N. If node i is not yet observed, we set ωi=− for the empty set. If we choose to observe node i, ωiis the actual outcome of the random variable xiat this node. For instance, in Fig. 2 (top) we observe prospect 14, and set ω14=1 (left) for dry evidence and ω14=3 (right) for oil evidence. Initially, before acquiring any observables, we haveω=(−,…, −). The conditional probabilities of a node i given evidence are p(xi=j∣ω), j=1,…, k, where the empty elements (−) ofωare unobserved and marginalized out. Fig. 2 shows the difference between marginal probabilities (with no evidence) and the conditional probabilities for all nodes i given evidence vectorωempty except entries 14 (top) and 10 (bottom).The CV associated with the state vectorωis denoted v(ω). This is the expected future value of all currently unobserved states, given the observed non-empty states inω. One objective is to find the initial value before any nodes have been explored, i.e. v(ω0) whereω0={−, −,…, −}. This initial value is in theory given exactly by DP, which is explained in Section 3. As an integral part of the DP algorithm one must evaluate the values v(·) of all possible combinations of evidence. This becomes impossible when we have many nodes in the graph. We have N=25 prospects for the BN shown in Fig. 1, which is too large for exact DP evaluation. We instead construct forward selection strategies approximating v(·) to different accuracies. These proposed strategies are presented in Section 5, using building blocks from Section 4 for the CV.In our context DP recursively explores backwards all the possible sequences that may occur, and it uses these evaluations to select the best dynamic decisions. See e.g. Bickel and Smith (2006) for a similar application of DP. By the word sequence we mean each of the possible situations that may arise. Sequences are indexed by adding one element ωi∈{1,…, k} at a time to the evidence vectorω=(ω1,…, ωN). With N=4 prospects, the stateω={−,1,−, 2} means that the node 1 has not yet been explored, node 2 has been observed to be in state 1, node 3 has not yet been explored, and node 4 has been observed to be in state 2. Two different scenarios may correspond to this sequence: (i) when node 2 is explored before node 4 and (ii) when node 4 is explored before 2. This order is of course relevant when we have only explored node 2, and consider observing node 4, or vice versa, but once both node 2 and 4 have been explored, the evidence vectorωis identical, and we no longer distinguish between these two scenarios (except for discounting purposes).The decision tree in Fig. 3visualizes the sequential strategy for six nodes. It works in the following way:1.First, decide which node, if any, to observe first.Then, depending on the outcome xi∈{1,…, k}, which node to observe next, if any, and so on.Note that the sequential selections typically depend on the outcome of the previously selected nodes. This occurs because the conditioningωlargely influences the conditional probabilities for models with statistical dependence. DP solves the tree by working backwards:1.First, decide whether to drill the last prospect, conditional on the first N−1 observables.Then, decide which prospect to drill if there are two nodes left, and so on, until the initial empty set.In order to pursue this strategy, we have to maximize a certain utility function. We use maximum profit here, and the CV v(ω) represents the expected revenues of future cash flows given that we are in stateω. Initially, the vector of observables is empty:ω0={−,−,…,−}. The maximization is among all possible free states:(1)v(ω0)=maxi∈N∑j=1kp(xi=j)rij+δmaxs∈N-1∑l=1kp(xs=l|xi=j)rsl+…,0,0,where the second and the subsequent maximizations are over all nodes not yet considered. Here, δ is a discounting factor that depends on the specific case and on the inclination of the decision maker. Therijare revenues or costs of node i with outcome j. When all the sites have been drilled, the CV is v(·,·,…, ·)=0, and we can proceed backwards, one step at a time, to extract the DP solution. Eq. (1) can be rewritten (Bickel and Smith, 2006), and it can be seen as a maximization over all free nodes and 0 (not exploring any further). This means that v(ω)=maxi{0, vi(ω)}, where:(2)vi(ω)=∑j=1kp(xi=j|ω)rij+δ·vωij.Hereωij={ω-i,ωi=j}means adding one element to the evidence vector, andvωijis the CV of the stateωij, i.e.vωij=maxl≠i0,vlωij.The main problem with the optimal DP solution is the exponential growth of the number of scenarios that have to be considered. Bickel and Smith (2006) derives the computational cost for a non-recombining tree, i.e. a tree ignoring the order of the observed nodes. Then,Numberofpossiblescenariosinanon-recombiningtree:∑i=0NNiki(N-i+1).This entails an order of 104 scenarios for six nodes (Bickel and Smith, 2006), and 1015 when N=25 nodes. The computational cost (proportional to the number of scenarios) is therefore in the order ofN2!kN/2. Bickel and Smith (2006) suggest to save the local results of the computations in order to reduce the number of configurations to consider. Say, for the purposes of the CV, it does not matter whether we drilled first one well or another, given that we observe their outcomes. Nonetheless, the exact procedure remains unfeasible when N increases. Furthermore, the discounting factor δ makes the use of classical non-recombining algorithms impossible.Because of the rapid growth in scenarios, one must look for approximate solutions. The problem shares some features with that of a chess game. The player has to choose among all the possible moves she can carry out, and at the same time must consider all the possible replies of her opponent, and the consequential replies of herself, and so on. What is done in practical chess algorithms is to limit the search to a reasonable amount of moves forward, and to evaluate the best move in that “restricted match”, see Shannon (1950) and Feldmann et al. (1994).Similarly, we push the search through a certain number of steps, figuring out some rules to approximate the CV of the scenarios. The resulting strategies are so-called look-ahead type, where we use DP to look at a small horizon of the future. This is explained in detail in Section 5. Our approximations of the CV are based on naive heuristics or myopic heuristics that are further described in Section 4. These heuristics are not using any of the future information. Chapter 8 of Powell (2007) discuss such policies for approximate DP. We apply them to our problem of sequential exploration of prospects. Since we restrict attention to exploring one prospect at the time, we apply so-called rolling horizon strategies combined with look-ahead to select one prospect at a time (Section 5).We now present heuristic strategies that have shown useful on their own, but for our purposes will play a part in the approximation for the CV at various stages of the DP equations. For sake of presentation we apply these heuristics to the initial problem in this section, i.e. we have no evidence andω=ω0 is the empty vector. In Section 5 the heuristics are used to approximate the CV, we then condition on the current evidenceωwith non-empty entries corresponding to the observed nodes.The naive strategy ignores the dependence among nodes. Therefore, the selection strategy is pre-determined based on a priori knowledge, and does not depend on the sequential outcomes. The expected marginal profits or intrinsic valuesIVi=∑j=1krijp(xi=j)can be ranked from largest to smallest, and the prospects are chosen according to:(3)i(1)=argmaxi{IVi,0},i(2)=argmaxi⧹i(1){IVi,0}….This means we select the prospect with highest a priori intrinsic value first, then the second highest a priori value, etc. We stop when no more intrinsic values are positive.The value is then estimated as a discounted sum of a priori intrinsic values:(4)vN(ω)=∑l=1Nδl-1max{IVi(l),0},where subscript N is used to indicate Naive. This approach, though being very simple (the computational cost is linear in N), still captures a large part of the value if the correlation between nodes is small. The main problem is that disregarding correlation effects can lead to focused attention on nodes that are a priori appealing but may no longer be valuable given the evidence of the previous steps. Disregarding correlations means that the algorithm does not react to new data, so it is neither sequential nor looking ahead.A second natural approach is represented by the myopic strategy (Bollapragada and Morton, 1999). According to this strategy, the best sequence is computed step-by-step in a forward selection scheme. The conditional probabilities in the different nodes are now updated, given the previous outcomes. This represents an intuitive sequential strategy, but it only exploits the dependence in the graph through the past, without considering what the future might bring.The strategy for finding the first best prospect coincides with the naive approach:(5)i(1)=argmaxi∑j=1krijp(xi=j),0.Given an outcomexi(1)at this first selected node i(1), the second myopic node is then chosen as:(6)i(2j1)|xi(1)=j1=argmaxi⧹i(1)∑j=1krijp(xi=j|xi(1)=j1),0,j1=1,…,k.Now, the second best choice, therefore, involves k different maximizations, depending on the outcome ofxi(1). For the third selection, we condition on the outcome of node i(1) and i(1), which means k2 possible condition sets. Thus, using a myopic strategy leads to a decision tree with∑i=0Nkiscenarios.The myopic approach approximates the value byv1=max∑j=1krijp(xi(1)=j),0,v2=∑j=1kmax∑l=1krxi(2j)lp(xi(2j)=l|xi(1)=j),0p(xi(1)=j),vM(ω)=∑i=1Nδi-1vi,where subscript M is used to indicate Myopic. The complexity of designing an entire strategy with this myopic approach is of order kN. This remains considerably high, keeping in mind that we are just using a small part of the information. One way of evaluating the myopic strategy is by Monte Carlo sampling x1, …, xB∼p(x). For each of the B samples the decision is given by the past outcomes, sayxi(1)b=j,xi(2j)b=l,…, and different samples would follow different branches of the decision tree. One could also imagine truncating the myopic evaluation and using the (conditional) naive approach from a certain branch on. We will discuss such approaches in more depth in the next section, when we study more refined forward selection strategies applying the heuristics for the CV at every stage. The myopic algorithm can be seen as a sequential version of the naive algorithm. Correlations with earlier observations are used to update the probabilities, but it does not look ahead. For a given set of probabilities, the myopic and the naive approach will always choose the same first node, but then the myopic diverges as it updates with new information.We next propose look-ahead strategies that apply a depth n forward search combining DP with approximations of the CV. The depth n can be chosen by the user. It will depend on the desired accuracy and on the available time and computation power. The methods considered in the previous section have the common goal of providing an approximation to the CV at each stage.In our oil and gas prospect application, there is typically no need to push the forward–backward selection procedure until the very last node. The oil and gas company is most interested in deciding the first few prospects to drill. In this way the depth n approach seems reasonable. On the other hand, the approximations we consider apply heuristics for the CV, and the resulting sequences are not necessarily optimal.Consider the n first branches of a decision tree, and assume we approximate the CVs at each leaf node of this depth-n tree. In our approach the CV is approximated by a naive or myopic strategy. The approximate CVs are required when we run a restricted n-steps DP. We thus propose to assign a large contribution to the first n<N decisions, and a smaller contribution to the remaining N−n. This entails that we solve the depth-n decision tree with approximate leaf-node values. As outputs we get to select the best node for this strategy, i.e. the one with highest expected value when the CVs are approximated after n branches. The complexity of the algorithm depends on the size n chosen in the approximation, and it is of ordern2!kn/2(N-n)when approximating the CV with the naive heuristic. The strategy is the following:•Starting point: no nodes have been observed yet:ω={−,−,…,−}.The n first branches of the decision tree are evaluated with DP, i.e. v(ω)=max{v1(ω),…, vN(ω)}, over all nodes N. At each step vi(ω) is computed according to Eq. (2), with an approximate CV for each of the depth-n branches.The decision vector has n observed components and N−n still empty (not observed). We define the decision vector at this stageω∗. For instance, if N=6 and n=2, with observations x2=2 and x6=1, thenω∗={−,2,−,−,−,1}.For each leaf-node in the depth-n tree the CV v(ω∗) is approximated using the naive approach introduced in Section 4. Now conditional onω∗:vN(ω∗)=∑i=1N-nmax∑j=1krijp(xi=j|ω∗),0,We can also fix an order for the N−n prospects, based of their intrinsic values, in order to discount the values in a particular way. One may also pursue other approaches in this last step, such as a myopic approximation of the CV, but this is much more time-consuming.vN(ω∗) represents the approximated CV after n steps, and it is finally used for computing the original vi(ω).This algorithm is both sequential, since the next decision depends on previous observations, and it looks ahead, so that correlations influence the next choice. However, in the truncated depth n version, it stops looking ahead after some steps, and use heuristics to approximate the CV.We next combine different look-ahead searches and forward selection strategies. We suggest the idea depicted in Fig. 4, where one first runs a look-ahead search of depth n. Next, the best node is selected. Given the outcome of this node, a second search of depth n is performed, and so on. We call these strategies Depth n (in the following Dpt n) rolling horizon look-ahead (RHLA) strategies (see Le and Day (1982) and Alden and Smith (1992)). It is interesting to note that a Dpt 0 strategy coincides with a full naive or myopic approach (depending on the approximation chosen for the CV), while a Dpt N−1 strategy coincides with a full evaluation of the decision tree, and therefore with the DP presented in Eq. (1).This RHLA strategy is a forward selection, but it partially accounts for future scenarios in its look-ahead length-n DP procedure. In the RHLA strategy we explore the tree up to a certain fixed depth n, but we draw conclusions just about the first best site. Since at every step we rerun the strategy, we can incorporate at this step the outcome of the sample, instead of exploring all the possible combinations of evidence. This algorithm is thus both sequential and looking ahead for all decisions.The resulting algorithm has the same computational complexity as the myopic strategy, with an additional factor due to the complexity of the look-ahead strategy itself. In total we have a complexity ofn2!kn/2(N-n)·kN. Note that this strategy can always be computed in a forward selection manner. It is however much harder to evaluate the strategy, for instance to compute the associated value, or the variability in the computed sequences over different outcomes. For a small number of nodes N, one can compute the values probabilistically for different depths n RHLA strategies. For larger dimensions we suggest to use Monte Carlo sampling to evaluate the different strategies. We then draw samples from the graphical model with joint distribution p(x). We run the RHLA depth n procedure to select nodes, and for each step in the forward selection we plug in the outcomes according to the relevant sample at that node. This approach mimics what would happen in hypothetical scenarios, and we can say that we are playing the game.Algorithm 1Evaluating a rolling horizon look-ahead strategy of depth nω=[−,−,…,−]# Dynamic programming outcome vectory=0# Rolling horizon counterval=0# Value counterseq=[]# Best sequence vectorSample s∼p(x)# Current samplewhile#[ωi={−}]>0 do[v,j]=f(ω,1)ifv>0 then# CV positivity conditionωj=sj# Set sampled outcome sjat selected node jval+=δy·rjsj# Discounting of revenuesseqy+1=j# Selected node is jelsebreakend ify ++end whilereturnvalreturnseqfunction [v,j]=f(ω,d)# Input: Current state, current depthif #[ωi={−}]==0 then# Last iteration condition, stopj=0v=0else ifd⩽n# “Depth n” condition, continue DPfori: ωi={−} doforl=1:kdo[v,j]=f(ωil,d+1)# DP iteration at next depth levelvil=ril+δ·vend forvi=∑l=1k{p(xi=l|ω)·vil}end forv=maxi{vi,0}j=arg max{vi}else# Reached depth n, compute naive CVj=0v(ω)=∑i:ωi={-}max∑l=1kril·p(xi=l|ω),0end ifend functionGiven one realization from the graphical model, the pseudo-algorithm is presented in Algorithm 1. The algorithm presents two parts: The first constitutes the core of the algorithm from where we call the recursion. The second one presents the recursive function itself. In the core we find a while loop that is necessary to terminate the algorithm when all the nodes have been explored and an if condition that breaks the process if none of the nodes presents a positive CV. In the recursive function we have an if condition that ensures that the correct depth is achieved, and a for loop that goes through all the not-yet-explored nodes. When running a RHLA strategy on small examples (cfr. Section 6.1) there is the possibility to run a RHLA for every possible evidence, spanning the whole sample space. By averaging the revenues and costs collected through the strategy, we get a value that coincides (exact and myopic case) or approximates (RHLA case) the estimated final value. In large examples (cfr. Section 6.2) this is not possible and we estimate the final values through a Monte Carlo sampling procedure.Recall that this Monte Carlo evaluation was also suggested for myopic strategies, following exactly the same principle, but getting every time the new best choice using a myopic strategy and not a look-ahead one. In this way we can get a fair comparison between a complex sequential strategy (RHLA), a simpler yet sequential strategy (rolling horizon myopic), and a simple non-sequential strategy (naive).The look-ahead strategies share the idea of choosing a priori the depth n of the search tree. This choice must be done before running an approximation. In practice, we choose n based on the available computation time.The problem is that we often explore branches of the decision tree that are useless for designing an optimal strategy, and we do not privilege enough branches that can give a stronger contribution to the value. We next design adaptive strategies based on tree-pruning, accounting for the value of the different branches. These idea is inspired by similar ideas applied in contiguous fields, like the chess computer-based algorithms.We prune the branches of the tree that are very unlikely. In this way we do not have to explore all the combinations, and we reduce the complexity of the algorithm. We define threshold parameter ε such thatifPωij<εthenvωij≈vωi∗,and we use one of the methods described in Section 4 in order to approximate the CV.A more refined approach is to decide which branches to explore based on the value of the nodes. This reduces the number of nodes to explore. The method can either be based on the intrinsic value of the individual node under consideration or a look-ahead evaluation of depth 1.The pseudo-algorithm is the following:•ω0={−,−,…,−}for i=1: N+ we order the segments on the basis on an approximate CV, that can be either of the following:–Intrinsic value:v(ωi)=∑j=1krikp(xi=j)Look-ahead Dpt 1 value:v(ωi)=∑j=1kp(xi=j)rij+∑s=2Nmax∑l=1kδsr(s)lp(x(s)=l|xi=j),0Keep only the N−Nprun maximum nodes with the highest values and move to the second level of depth in a RHLA framework. For the Nprun nodes with minimum values, use the approximated values already computed (Intrinsic or Look-ahead Dpt 1).In practice, Nprun cannot be too small (too many paths to explore), nor too large (we risk to abandon paths that may result being interesting). We will use the pruning strategies to speed up the computations on large graphs.

@&#CONCLUSIONS@&#
