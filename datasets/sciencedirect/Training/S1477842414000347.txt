@&#MAIN-TITLE@&#
Bounded memory protocols

@&#HIGHLIGHTS@&#
A new class of security protocols is introduced called Bounded Memory ProtocolsThe secrecy problem is undecidable even when we bound the memory of the honest agents.The Standard Dolev–Yao adversary cannot be approximated by Bounded Memory ones.

@&#KEYPHRASES@&#
Protocol security,Dolev–Yao adversary,Secrecy problem,Complexity,Undecidability,

@&#ABSTRACT@&#
It is well-known that the Dolev–Yao adversary is a powerful adversary. Besides acting as the network, intercepting, decomposing, composing and sending messages, he can remember as much information as he needs. That is, his memory is unbounded. We recently proposed a weaker Dolev–Yao like adversary, which also acts as the network, but whose memory is bounded. We showed that this Bounded Memory Dolev–Yao adversary, when given enough memory, can carry out many existing protocol anomalies. In particular, the known anomalies arise for bounded memory protocols, where although the total number of sessions is unbounded, there are only a bounded number of concurrent sessions and the honest participants of the protocol cannot remember an unbounded number of facts or an unbounded number of nonces at a time. This led us to the question of whether it is possible to infer an upper-bound on the memory required by the Dolev–Yao adversary to carry out an anomaly from the memory restrictions of the bounded protocol. This paper answers this question negatively (Theorem 8).

@&#INTRODUCTION@&#
In the symbolic verification of protocol security, one considers a powerful adversary model now usually referred to as the Dolev–Yao adversary, which arose from positions taken by Needham and Schroeder [21] and a model presented by Dolev and Yao [12]. Not only can the Dolev–Yao adversary act as the network, intercepting, decomposing, composing and sending messages, but he can also remember as much information as he needs. The goal in protocol verification is to demonstrate that such a powerful adversary cannot discover some secret information, when using some protocol(s). Clearly, if it is shown that such a powerful adversary cannot discover the secret symbolically, then weaker adversaries will also not be able to discover the secret.In [16], we proposed a Bounded Memory Dolev–Yao adversary, which is similar to the Dolev–Yao adversary. He also acts as the network, intercepting, sending and composing messages, but differently from the Dolev–Yao adversary, he can remember only a bounded number of facts at a given time. So, in order for him to learn some new information, such as a nonce, he might have to forget some information he previously learned, such as an old nonce. Clearly, our Bounded Memory Dolev–Yao adversary is weaker than the Dolev–Yao adversary, the former׳s memory is bounded, while the latter׳s is not.However, despite being weaker, we demonstrated in our previous work [16] that many known anomalies can also be carried out by our Bounded Memory Dolev–Yao adversary. We also noticed that the protocols for which we could replay the anomaly with our bounded memory adversary were all bounded memory protocols, where one considers that the memory of the system is bounded. That is, in concurrent runs the honest participants of the protocol also cannot remember an unbounded number of facts or an unbounded number of nonces at a time. This led us to the question of whether it is possible to infer an upper bound on the memory of the Dolev–Yao adversary with respect to the memory restrictions of bounded memory protocols, that is, with respect to the memory used by the participants. Such an upper bound would mean that an attack using the Standard Dolev–Yao adversary exists if and only if an attack using the Bounded Memory adversary exists.This paper answers this question negatively. That is, it is not possible to determine an upper bound on the memory of the Dolev–Yao adversary even if the memory of the protocol is bounded. From our main result (Theorem 8), we can infer that the Standard Dolev–Yao adversary cannot be constructively approximated by an infinite sequence of increasing memory Bounded Memory adversaries. We show this negative result by proposing a novel undecidability proof for the secrecy problem with the Dolev–Yao adversary. Our undecidability result strengthens the one given in [6,11], confirming the hardness of protocol verification. In particular, we show that the secrecy problem is “very undecidable:” the secrecy problem is undecidable even for bounded memory protocols and thus a bound on the memory of the Dolev–Yao adversary is not computable from a bound on the memory used by a protocol. This is accomplished by a novel encoding of Turing machines by means of memory bounded protocols.After Section 2 where we introduce the preliminary concepts used in this paper, including Balanced Actions, we proceed as follows:•Section 3 reviews the specification of bounded memory protocols, the Dolev–Yao Adversary, and of Bounded Memory adversaries. It also reviews some of the complexity results for the secrecy problem.Section 4 contains the secrecy undecidability proof with memory bounded protocols. This is a novel, stronger undecidability proof, which allows us to infer that it is not possible to determine an upper bound on the memory of the Dolev–Yao adversary from the memory bound of the protocol.Section 5 revisits the undecidability proof given in [6,11] and shows that a similar proof can be obtained by using bounded memory protocols.Finally in Sections 6 and 7 we comment on related work and conclude by pointing out to future work.This is an extended and improved material on bounded memory protocols from the conference paper [17]. Besides containing most of the proofs and more detailed explanation, the material in Section 5 is novel.We formalize bounded memory protocol theories and adversary theories by means of multiset rewrite rules, similarly as in [6,11]. A set of rewrite rules, or a theory, was proposed in [6,11] for modeling protocols and the standard Dolev–Yao adversary with unbounded memory. In order to carefully compare our complexity results, we closely follow this approach and adapt the theories from [6,11] to formalize bounded memory protocols and Bounded Memory adversaries.Assume fixed a sorted first-order alphabet consisting of constant symbols,c1,c2,…, function symbols,f1,f2,…, and predicate symbols,P1,P2,…, all with specific sorts (or types). The multi-sorted terms over the signature are expressions formed by applying functions to arguments of the correct sort. A fact is a ground, atomic formula over multi-sorted terms. Facts have the formP(t1,…,tn)where P is an n-ary predicate symbol, wheret1,…,tnare terms, each with its own sort.The size of a fact is the total number of terms and predicate symbols it contains. We count one for each predicate, function, constant, and variable symbols. We use|F|to denote the size of a fact F. For example,|P(x,c)|=3, and|P(f(z,x,n),z)|=6. We will assume in the remainder of this paper an upper bound on the size of facts, as in [6,11,19]. As we argue later in this section, the combination of a bound on the size of facts and the use of balanced actions imposes a bound on the memory of the system. This will be key for the decidability of the problems that we deal with in this paper.A state or configuration of the system is a finite multiset of grounded facts, i.e., facts that do not contain variables. Intuitively configurations specify the state of the world. They are modified by actions, which are in general multiset rewrite rules of the following form:(1)X1,…,Xn⟶∃x→.Y1,…,Ymwhere Xis and Yjs are the facts. The collectionX1,…,Xnis called the pre-condition of the rule, whileY1,…,Ymis called its post-condition. We assume that all free variables are universally quantified at the head of the rule. By applying the rule for a ground substitution (σ), the pre-condition(X1σ,…,Xnσ)to which this substitution has been applied is replaced with the post-condition(Y1σ,…,Ymσ)to which the same substitution has been applied. In this process, the existentially quantified variables(x→)appearing in the post-condition are replaced by fresh constants, also called nonces in protocol security literature. The rest of the configuration remains untouched. Thus, we can apply the ruleP(x),Q(y)→∃z.R(x,z),Q(y)to the global configurationV,P(t),Q(s)to get the global configurationV,R(t,c),Q(s), where the constant c is new.Given a multiset rewrite system R, one is often interested in the reachability problem: Is there a sequence of (0 or more) rules from R which transforms configuration W into Z? If this is the case then we say that Z is reachable from W using R, and we call any such sequence of actions a plan.An important condition for formalizing bounded protocols is that of balanced actions, introduced in the context of collaborative systems [19]. We classify an action as balanced if the number of facts in its pre-condition is the same as the number of facts in its post-condition. That is, n=m in Eq. (1). If we restrict all actions in a system to be balanced, then the number of facts in each configuration in a run is the same as in the initial configuration. This is because when a balanced action is applied to a configuration, the same number of facts that are removed from the configuration is also inserted into it.The main motivation of using balanced actions is to bound the storage capacity of agents. Since the number of facts of all configurations in a plan is the same as the number of facts in the initial configuration, denoted by the symbol m, the number of facts that are known to agents at any time is bounded. However, even with the use of balanced actions, it does not mean that there is a bound on the number of symbols (or terms) present in any configuration. One also needs a bound on the size of facts denoted by the symbol k. Otherwise, an agent would be able to store as many symbols as he wants by using for instance a pairing rule:M(t1),M(t2)→M(〈t1,t2〉),M(t2)Notice that this action is balanced, but the number of symbols that appear in the post-condition is greater than the number of symbols that appear in the pre-condition. Without bounding the size of facts, one would be able to store an unbounded number of symbols in the term level. In this way it would be possible for the system, represented by a configuration, to contain as much information as needed. On the other hand, bounding the size of facts implies that the pairing rule would not be allowed if the size of the factM(〈t1,t2〉)is greater than the upper-bound. Thus, the number of symbols in a configuration is always bounded by the value mk, where m is the number of facts in the initial configuration and k the upper-bound on the size of facts.These two conditions, namely the use of balanced actions and of an upper-bound on the size of facts, are crucial for our decidability results:•Kanovich, Rowe and Scedrov showed [18] that for unbalanced systems the reachability problem is undecidable even if we bound the size of facts.It was also shown [11] by encoding the Post correspondence problem that if one does not bound the size of facts, then the reachability problem is undecidable even if the system is balanced.As an illustration, consider the following unbalanced rule:→∃n.M(n)This rule specifies that the system may create a fact with a fresh nonce increasing the number of facts in a configuration. Such a rule is not balanced. To support the creation of new facts in balanced systems, we use empty facts, writtenP(⁎). Intuitively, empty facts denote available memory slots that could be filled with some new information. Here ⁎ is not a constant, but just used for illustrative purposes. By using empty facts, one can transform unbalanced systems into balanced systems simply by adding enough empty facts to the pre-condition or the post-condition of each rule so that it becomes balanced. For instance, a balanced version of the above rule, called GEN, is shown below:GEN:P(⁎)→∃n.M(n)The system can then create a new nonce provided the given configuration has at least one empty fact. It is also assumed that the system may forget some information, by replacing a fact by an empty fact, as illustrated by the following rule, called DELM:DELM:M(x)→P(⁎)This is a simple solution for bounding the storage capacity of agents. The agents in the system may need to be careful on how they use the system׳s memory limitation.Finally, the above rules also illustrate two important aspects of using nonces. The first unbalanced rule specifies that one can create a nonce, while the two balanced rules, GEN and DELM, specify that agents in a balanced system do not create nonces, but rather update an existing symbol with a fresh nonce. That is, they replace an existing symbol, possibly an existing nonce, with a fresh one. Hence, differently from the unbalanced systems, agents do not remember all the nonces created. This distinction between nonce creation and nonce update will play an important role in our undecidability proof for the secrecy problem (defined formally in the next section), when compared with the proof given by Durgin et al. [11]. The honest participants in our Turing machine encoding (Section 4) will rely only on nonce updates, while the honest participants in the proof given by Durgin et al. [11] use nonce creation.This section reviews the definition of bounded memory protocols introduced in our previous work [16] illustrating the difference to well-founded protocols used in [11]. We also discuss the differences between the Standard Dolev–Yao adversary and the Bounded Memory adversary in Section 3.2 and finally we review the complexity results for the secrecy problem in Section 3.3, namely the undecidability result given by Durgin et al. [11] in the presence of the Standard Dolev–Yao adversary and our PSPACE-completeness [16] in the presence of the Bounded Memory adversary.A bounded memory protocol, formally defined below, only contains balanced actions [16]. This means that the number of facts known by the participants at a given time is bounded. Bounding the memory available for protocol sessions also intuitively bounds the number of concurrent protocol sessions. This is because for each protocol session, one needs some free memory slots to remember, for instance, the internal states of the agents involved in the session. However, this does not mean that there may not be an unbounded number of protocol sessions in a trace. Once a protocol session is completed, the memory slots it required can be re-used to initiate a new protocol session.This is different from the well-founded protocol theories [6,11] proposed in the literature. The rules in well-founded protocol theories are not necessarily balanced. All protocol sessions are created at the beginning of the trace before any protocol session starts executing. Therefore, in well-founded protocol theories, an unbounded number of protocol sessions can run concurrently and therefore participants are allowed to remember an unbounded number of facts.Definition 1Balanced role theoryA theoryAis a balanced role theory if there is a finite list of predicate names called the role statesS0,S1,…,Smfor some m, such that every ruleL→∃t→.RinAis balanced and there is exactly one occurrence of a state predicate in L, say Si, and exactly one occurrence of a state predicate in R, say Sj, such thati<j. We call the first role state, S0, initial role state, and the last role state, Sm, final role state. Only rules with final role states can have an empty fact in the post-condition.Defining roles in this way ensures that each application of a rule inAadvances the state forward. Each instance of a role can only result in a finite number of steps in a trace. The request on empty facts formalizes the fact that one of the participants, either the initiator or the responder, sends the “last” protocol message. In [16], one can find several examples of protocols specified as balanced role theories.In order to allow for an unbounded number of protocol sessions in a trace, we allow protocol roles to be created at any time with the cost of consuming empty factsP(⁎). At the same time, we allow protocol sessions that have been completed to be forgotten. Once a final role state has been reached, it can be deleted, creating new empty factsP(⁎)in the process. These empty facts can then be used to create new protocol roles starting hence a new protocol session. Such theories are called role regeneration theories.Definition 2Role regeneration theoryIfA1,…,Akare balanced role theories, a role regeneration theory is a set of rules that either have the formQ1(x→1)⋯Qn(x→n)P(⁎)→Q1(x→1)⋯Qn(x→n)S0(x→),whereQ1(x→1)⋯Qn(x→n)is a finite list of facts not involving any role states, and S0 is the initial role state for one of theoriesA1,…,Ak, or have the formSm→P(⁎),where Smis the final state for one of theoriesA1,…,Ak.This definition is a central difference to well-founded protocol theories [6,11]: In well-founded protocol theories [6,11] one assumes that all protocol sessions are initialized at the beginning of the trace, that is, all protocol sessions run concurrently. This means that there is no bound on the memory of the (honest) participants since they need to remember that they participate in a possibly unbounded number of protocol sessions. Under the definition above, on the other hand, this is no longer the case as the explicit use of balanced actions in role theories and role regeneration theories allows us to bound the memory of the participants, including the number of concurrent protocols in the system, without bounding the total number of sessions in a trace.Definition 3Bounded memory protocol theoryA pair(P,H)is a bounded memory protocol theory ifHis a finite set of facts (called initial set), andP=R⊎A1⊎⋯⊎Anis a protocol theory whereRis a role regeneration theory involving only facts fromHand the initial and final roles states ofA1,…,An, andA1,…,Anare balanced role theories. For role theoriesAiandAj, withi≠j, no role state predicate that occurs inAican occur inAj.Intuitively, a bounded memory protocol theory specifies a particular scenario to be model-checked involving some given protocol(s). Besides empty facts,P(⁎), the finite initial set of facts(H)contains all the facts with the information necessary to start protocol sessions, for instance, shared and private keys, the names of the participants, as well as any compromised keys. Here, for simplicity, we assume only symmetric keys, although other types of keys can also be formalized following the lines described in [6,11].The powerful adversary proposed by Dolev and Yao [12] acts as the network, where all messages communicated are sent through the adversary. He hears everything and learns messages modulo encryption. More precisely, he is capable of intercepting any message sent by a protocol participant and can then store the received information, decompose it and decrypt with the keys he possesses. He cannot, however, decrypt messages for which he does not have the correct key. Moreover, he can also create fresh values, encrypt, compose messages from the information he has learned and send messages. One of his major strengths is that he can remember as much information as he wants, i.e., his memory is unbounded.Fig. 1a depicts the rules of such an adversary. The I/O rules specify the fact that the adversary acts as the network receiving all messages sent (NS) and sending all messages that are to be received (NR). The remaining rules are straightforward, specifying when the adversary may decompose and compose messages. The termEK(t)denotes the message obtained by encrypting the term t with the key K. Notice that contrary to the formalization of the bounded memory protocols, the actions specifying the Dolev–Yao adversary are not all balanced. In particular, the adversary may always learn new facts, such as in the actions DECS and GEN, where the adversary learns the contents of an encrypted message and creates a nonce respectively.In [16], we proposed a Bounded Memory Dolev–Yao adversary, which has many capabilities of the Dolev–Yao adversary. He can intercept, send and compose messages, create nonces, etc. But differently from the Dolev–Yao adversary, he can remember only a bounded number of facts of a bounded size, at any given time. This is formally imposed by the balanced adversary theory presented in Fig. 1b and by assuming a bound on the size of all facts. Such a bound disables the intruder to form terms of unbounded size and uses them for storing unbounded amount of data inside facts.In order for intruder to store some new information, such as a nonce, he might have to forget some information he previously learned. This is technically accomplished by using empty factsP(⁎). For instance, the DCMP rule specifies that the bounded memory adversary can decompose a pair he learned(M(〈t1,t2〉))only if he has an empty fact left. So in order to carry out an anomaly, the adversary may need to manage his memory, by forgetting some data he previously learned. This is specified by the additional memory maintenance rule (DELM). Notice that by using the memory maintenance rule adversary is able to replace any M-fact, i.e., he may choose to forget any data from his memory. For example he can forget some message from an earlier session, parts of messages, nonces, etc. On the other hand, if in some interaction with a protocol, adversary has enough free memory to perform his actions, it is not necessary for him to use these rules, i.e., he is not forced to forget any data.In an interaction of malicious adversaries with honest participants, one is interested in the secrecy problem, namely, in determining whether the adversary can discover a secret s. Formally it is an instance of the reachability problem: Is it the case that a configuration containing M(s) can be reached from an initial configuration, where s is a secret originally owned by a honest participant?Undecidability of the secrecy problem: It has been known for some time that the secrecy problem is undecidable in general [6,11]. The undecidability proof in [6,11] proceeds by encoding the existential Horn problem, which is also proved to be undecidable. However, that encoding used well-founded protocol theories, where the memory of the protocol was unbounded. For instance, in well-founded protocol theories, it is allowed for an unbounded number of concurrent protocol sessions to run at the same time. In fact, all the protocol sessions in a trace are initialized at the beginning before any session starts. This implies that the participants of the system may remember an unbounded number of facts, namely, the facts containing the information of the protocol sessions in which they are participating.In Section 4, we strengthen the result in [6,11], by showing that the secrecy problem is undecidable even if the memory of the protocol is bounded. This is accomplished by a novel encoding of Turing machines by means of memory bounded protocols. In Section 5, we revisit the undecidability proof given in [11] and show that it is also possible to encode the existential Horn problem by using bounded protocol theories.We now detail the sound and faithful encoding of Turing machines using bounded memory protocols. We show that an attack on the given protocol by an unbounded, standard Dolev–Yao adversary is possible if and only if the encoded Turing machine terminates. From that we infer the undecidability of a Dolev–Yao attack even for bounded memory protocols. Notice that our result works even if we assume a (large enough) bound on the size of facts, e.g., a bound around 30.Without loss of generality, letMbe a Turing machine such that(i)Mhas only one tape, which is one-way unbounded to the right. The leftmost cell (numbered by 0) contains the marker $ unerased;The initial 3-cell configuration is of the following form, where B stands for the blank symbol:(2)We write〈q,ξ〉to denote that the corresponding cell contains the symbol ξ and is scanned byMin its state q.We assume that all instructions ofMare “move” instructions, i.e., of the formqξ→q′ηRorqξ→q′ηL, denoting: “if in state q looking at symbol ξ, replace it by η, move the tape head one cell to the right, respectively to the left, and go into stateq′”.The head ofMcannot move to the leftmost cell marked with $.Finally,Mhas only one accepting state, q0.Encoding of the tape. In our encoding, we need two honest participants only, Alice and Bob. Assume that they share a symmetric key K, not known to any other participant and that only Alice knows a secret s. We will encode the tape cells separately as follows:(a)An unscanned cell that contains symbol ξ0 is encoded by a term encrypted with the key KEK(〈t0,ξ0,e0,t1〉),where t0 and t1 are nonces, ande0=1if the cell is the last cell in a configuration ande0=0otherwise.The cell that contains symbol ξ and is scanned byMin state q is also encoded by a term encrypted with the key KEK(〈t1,〈q,ξ〉,0,t2〉)where t1 and t2 are nonces. In the above encoding of the scanned cell, the symbol 1 is never used in the place of symbol 0, since the head never visits the last cell of the tape. As will be shown below, as soon as the head visits the penultimate cell the tape is extended.Adjacent cells share nonces as follows. The encoding of the cell immediately to the right of the cell encoded byEK(〈t,α,0,t′〉)isEK(〈t′,β,e0,t″〉).Motivation: The nonces t0 and t1 in the termsEK(〈t0,α,e0,t1〉)encoding the tape cells are used for two purposes:(i)Firstly, t0 and t1 serve as “timestamps” of a visit made byMin the cell. WheneverMre-visits this cell, the previous term is updated with fresh nonces indicating a new visit.Secondly, as t0 and t1 are unique, they are used to uniquely link cells that are adjacent to each other.For example, the initial configuration, Eq. (2), with three cells is encoded by using the sequence of nonces t0, t1, t2, t3 as shown below:〈EK(〈t0,$,0,t1〉),EK(〈t1,〈q1,B〉,0,t2〉),EK(〈t2,B,1,t3〉)〉Notice the role of the nonces t0, t1, t2, t3. In particular, the nonces t1 and t2 are used to correctly encode the fact that the cell〈q1,B〉is to the right of the cell with the mark $ and to the left of the cell with the blank symbol.Given a Turing machineMand the encoding of the tape discussed above, we encode its actions by means of bounded memory protocol calledPM, which is depicted in detail in Fig. 2.Alice starts the computation by sending the message encoding the initial 3-cell configuration ofMto Bob. Bob simulates the computation ofMby transforming the message encoding that in state q the symbol ξ is being read into the new message encoding that the state changed toq′, ξ was replaced by η, and that the head moved to the right (resp. left), provided thatqξ→q′ηR(resp.qξ→q′ηL) is an instruction ofM. In one session Bob simulates one instruction of the machine, or, when necessary, models extending of the tape. Alice also checks whether the accepting state has been reached. In the modeling of the Turing machine computation, intruder plays an essential part by intercepting, storing and sending messages encoding the machine configuration. While the memory of the system used by the protocolPMis bounded, intruder׳s memory is unbounded enabling him to store the entire Turing machine tape and computation.We now describe the role of Alice (initiator) and Bob (responder) in detail. Both Alice and Bob can input and output only messages of the form〈EK(〈t0,α0,0,t1〉),EK(〈t1,α1,0,t2〉),EK(〈t2,α2,e2,t3〉),EK(〈t4,B,1,t5〉)〉where the first three components represent the chain of three cells, and the fourth component is an auxiliary component that serves for extending the tape. This will be modeled through Bob. Namely, when Bob receives the message encoding the last three cells of the tape, he replies with the encoding denoting a new blank cell being added to the right.Alice׳s role: Assume that Alice is the initiator and her initial state contains the encoding of the initial 3-cell configuration:I=〈EK(〈t0,$,0,t1〉),EK(〈t1,〈q,B〉,0,t2〉),EK(〈t2,B,1,t3〉),EK(〈t4,B,1,t5〉)〉Because of the initial configuration of the machine (2) the first component represents the beginning of the tape and the third component represents the last cell, denoted by the symbol 1. Notice that the last term does not share nonces with the first three. It will be used for extending the tape.The protocol starts by Alice updating all nonces titoti′, and sending the following message to Bob, action UPDA in Fig. 2:X′=〈EK(〈t0′,$,0,t1′〉),EK(〈t1′,〈q,B〉,0,t2′〉),EK(〈t2′,B,1,t3′〉),EK(〈t4′,B,1,t5′〉)〉At this point, she does not need to remember the previous terms containing the nonces ti. That is, she erases her memory and is ready to store new facts containing the noncesti′. In particular, she is waiting for a message from Bob of the form:〈EK(〈t0,α0,0,t1〉),EK(〈t˜1,α1,0,t˜2〉),EK(〈t2,α2,e2,t3〉),EK(〈t4,B,1,t5〉)〉By verifying its integrity with(t1=t˜1)and(t˜2=t2), Alice assumes that there is no intrusion in the channel. If some αiis of the form〈q0,ξ〉containing the final state q0, then Alice openly sends the secret s to Bob, formalized by actions RESA0, RESA1 and RESA2 in Fig. 2. Otherwise, Alice sends a neutral message, see action RESA3 in Fig. 2. Notice that in Ys in Fig. 2 related to these rules it is the case thatξ≠$since, by assumption onM, the head cannot move to the cell marking the beginning of the tape.Notice that Alice׳s role is given only for the encoding of the initial 3-cell configuration. Alice only checks whether the nonces from the received message match. She does not compare any data received with what she had sent. During the attack, described further below, Bob׳s replies will be intercepted and stored by the adversary.Bob׳s role. The role of Bob is to transform the message received with the help of an instruction from the given Turing machineM. Bob is expecting to receive a message (presumably from Alice) of the form:〈EK(〈t0,ξ0,0,t1〉),EK(〈t˜1,〈q,ξ〉,0,t˜2〉),EK(〈t2,ξ2,e2,t3〉),EK(〈t4,B,1,t5〉)〉Bob verifies its integrity by(t1=t˜1)and(t˜2=t2), and follows one of three cases:(1)(Extending the tape, action UPDB in Fig. 2) Fore2=1, i.e., for the encoding of the last three cells of the tape, Bob replaces nonces t1 through t5 with the new ones, and sends the following updated message to Alice〈EK(〈t0,ξ0,0,t1′〉),EK(〈t1′,〈q,ξ〉,0,t2′〉),EK(〈t2′,ξ2,0,t3′〉),EK(〈t3′,B,1,t4′〉)〉which provides a new last cell in the chain of four cells. Notice that the fourth component in the above reply refers to the new last cell in the configuration. In particular, notice the noncest1′,t2′andt3′linking the adjacent cells.(Moving the Head of the Machine to the Right, actionMOVEBϱin Fig. 2) For an instruction ϱ ofMof the formqξ→q′ηR, denoting: “if in state q looking at symbol ξ, replace it by η, move the tape head one cell to the right, and go into stateq′”, Bob replaces nonces t1 and t2 with fresh noncest1′andt2′respectively, to mark the event of the head moving to the right and making a new visit to the right cell. and he sends the following updated message〈EK(〈t0,ξ0,0,t1′〉),EK(〈t1′,η,0,t2′〉),EK(〈t2′,〈q′,ξ2〉,0,t3〉),EK(〈t4,B,1,t5〉)〉to Alice encoding the new 3-cell configuration.(Moving the Head of the Machine to the Left, actionMOVEBϱin Fig. 2) For anM׳s instruction ϱ of the formqξ→q′ηL, denoting: “if in state q looking at symbol ξ, replace it by η, move the tape head one cell to the left, and go into stateq′”, Bob replaces nonces t1 and t2 with the new onces, and sends the following updated message to Alice〈EK(〈t0,〈q′,ξ0〉,0,t1′〉),EK(〈t1′,η,0,t2′〉),EK(〈t2′,ξ2,0,t3〉),EK(〈t4,B,1,t5〉)〉The above protocol is balanced. It can be formalized by a bounded memory protocol, see Fig. 2. In particular, only terms of height fixed in advance are used. Also, a fixed number of facts are used by the protocol participants. No new memory is created in the system. Freshly created values are used to only update the facts in the system configuration, that is, the old nonces are replaced by new ones.The protocol formalization with bounded memory theories for the participants A and B is given in Fig. 2. The initial set of facts contains the factsGuy(A,K),Guy(B,K),denoting agents Alice and Bob, and specifying that they share the uncompromised key K, the fact Secret(s) denoting the secret s, the fact Failure(f) representing the neutral message f (this will be used by Alice to mark that the accepting state has not yet been reached). Finally,M׳s initial configuration is encoded in fact Init. In specifications of the role theories, for convenience we use various X and Y abbreviations and ξ and η variables for tape symbols. Both theories for A and for B have the corresponding role generation rules ROLA and ROLB, which create new sessions, as well as rules ERASEA and ERASEB, which delete role state predicates of completed sessions. As previously discussed, this allows traces to have an unbounded number of protocol sessions.The machine computation is initiated by Alice׳s role which relates to the initial tape configuration, and is then simulated instruction per instruction through series of Bobs roles. In each session Bob either simulates one of the machine instructions ϱ throughMOVEBϱrule, or extends the tape when necessary using the UPDB rule. Bob outputs messages encoding the updated machine configuration. These messages are intercepted by intruder who, by storing and decomposing the components, is then able to produce the message for Bob׳s next session, i.e., for the simulation of the nextM׳s instruction. At the same time, each of the Bob׳s output messages is forwarded to Alice so that she can check whether the configuration if the accepting one, that is whether the computation ends.Since there is aMOVEBϱrule for each instruction ϱ ofM, the reduction is polynomial on the number of instructions inM.Finally notice that the initial set of facts, besides the names of the agents and the encoding of initial tape, also contains three empty facts. One is used to create a protocol role for Alice another for Bob and finally the third for running the protocol.We now describe how a standard Dolev–Yao adversary can carry out an attack on the protocol described above. Recall that the Dolev–Yao adversary acts as the network, that is, all the messages are sent through the adversary and that his memory is unbounded.Notice that, because of the form of messages that Alice and Bob exchange and because of the encryption under the secret key K, by active eavesdropping Mallory can accumulate terms of the form(3)EK(〈t1,α1,e1,t2〉)if and only if they are components of outputs generated by Alice or by Bob. We now discuss the following attack on the above protocol:(1)In the first session, Mallory intercepts the initial message from Alice, stores it, and resends it to Bob. While Bob responds, Mallory intercepts the message from Bob, stores it, and resends it to Alice.For each of the next sessions, Mallory first intercepts the initial message from Alice. Taking non-deterministically terms of the form (3) from his memory, Mallory then composes a message of the form:〈EK(〈t0,α0,0,t1〉),EK(〈t˜1,α1,0,t˜2〉),EK(〈t2,α2,e2,t3〉),EK(〈t4,B,1,t5〉)〉and sends it to Bob. If Bob accepts this message and responds with a transformed one as described by the protocol, then Mallory intercepts this new message from Bob, stores it, and resends it to Alice.Recall that Alice releases the secret s after receiving the encoding of the final state of the machineM. Since the machine configuration encoding involves fresh values and is encrypted under the secret key K, only Bob is able to update the machine configuration. Hence, Mallory will learn the secret s only if Bob outputs the encoding of the accepting state of the machineMi.e., ifMterminates on the empty input.Also recall that Alice׳s role always relates to the initial tape configuration. Bob simulates the machine computation, one instruction per session, extending the tape as necessary. Bob׳s replies encode the current, updated, machine configuration. Only in the first session of the anomaly Mallory forwards to Bob the encoding of the initial machine configuration. Instead, in the subsequent sessions Mallory sends to Bob the message encoding the current machine configuration. This enables the simulation of the machine computation, instruction per instruction through series of Bob׳s roles. In each of the sessions Mallory is able to reproduce the encoding of the updated machine configuration. Namely, if in the previous session Bob simulated a move of the machine head, Mallory resends his last message back to Bob. Otherwise, in case in the last session Bob extended the tape, Mallory uses three EK-terms from Bob׳s last message and for the fourth EK-term Mallory can use some old term from her memory, e.g., a termEK(〈t4″,B,1,t5″〉)from one of Alice׳s messages. Although Alice and Bob erase their memory forgetting what they learned from exchanged messages, Mallory intercepts and stores all messages. Her memory is unbounded.Fig. 3illustrates the knowledge that the adversary accumulates during a successful run of the protocol. Notice that although the adversary only learns the encrypted messages containing the new contents of the tape, he has all the contents of the resulting tape. This is because the noncesti+1andti+4are not modified by Bob. This intuition is formalized by the lemma below.Lemma 5Suppose that a term of the formEK(〈t,〈q,ξ〉,0,t′〉)appears in the adversary memory by active eavesdropping. Then there is a unique sequence of noncest0,t1,…,tn+2and a chain of terms from the adversary׳s memoryEK(〈t0,$,0,t1〉),EK(〈t1,x1,0,t2〉),….EK(〈tj−1,xj−1,0,tj〉),EK(〈tj,〈q,xj〉,0,tj+1〉),EK(〈tj+1,xj+1,0,tj+2〉),…,EK(〈tn,xn,0,tn+1〉),EK(〈tn+1,B,1,tn+2〉)such that(a)tj=t,xj=ξ, andtj+1=t′,Mleads from the empty initial configuration to the configuration where the stringx1x2…xj…xn, is written in cells1,2,…,j,…,non the tapeand the j-th cell is scanned byMin state q.By induction on the number of actions performed by Bob to output a message one of the components of which isEK(〈t,〈q,ξ〉,0,t′〉). Notice that any term of the formEK(〈t,〈q,ξ〉,0,t′〉)in Mallory׳s memory comes from an intercepted message since it is encrypted with the key K not known to Mallory. Also notice that Mallory learns this term by decomposing protocol messages. As per protocol specification this term is always accompanied by other three terms from the encoding.For the base case, when the number of Bob׳s actions is 0, a term of the formEK(〈t,〈q,ξ〉,0,t′〉)must have been sent by Alice as a part of an encoding of the initial machine configuration, i.e., as a part of a message of the form:〈EK(〈t0″,$,0,t1″〉),EK(〈t1″,〈q,B〉,0,t2″〉),EK(〈t2″,B,1,t3″〉),EK(〈t4″,B,1,t5″〉)〉The first three terms in this message contain a sequence of noncest0″,t1″,t2″,t3″and from the desired chain of terms in Mallory׳s memory corresponding to the empty computation.Assume that Bob has performed k actions encoding machine instructions or tape extension and that there is a term of the formEK(〈t,〈q,ξ〉,0,t′〉)in Mallory׳s memory. If this term comes form one of Alice׳s messages, then the claim stands for the encoding of an empty computation, just like in the base case. In case the term is a part of a message sent by Bob in some session, but not in the last one, then the claim follows by inductive assumption. In the remaining case the term of the formEK(〈t,〈q,ξ〉,0,t′〉)has been sent by Bob in the last session. Let us assume that in the last session Bob performed the action corresponding to machine head moving to the right,q′ξ′→qξR. The remaining cases are proven similarly. In the last session Bob sent the message of the form:〈EK(〈t0,ξ0,0,t1〉),EK(〈t1,ξ1,0,t〉),EK(〈t,〈q,ξ〉,0,t′〉),EK(〈t4,B,1,t5〉)〉This was necessarily a reply to a message of the form:〈EK(〈t0,ξ0,0,t2〉),EK(〈t2,〈q′,ξ′〉,0,t3〉),EK(〈t3,ξ,e2,t′〉),EK(〈t4,B,1,t5〉)〉encoding the tape cells from the previous machine configuration. Such message must have been sent by Bob in the previous session. Since Mallory controls the network, she had intercepted and stored this message, and was able to decompose it so that the termEK(〈t2,〈q′,ξ′〉,0,t3〉)appears in her memory. Here we assume that Mallory is actively eavesdropping, decomposing whatever she can. Applying the induction hypothesis toEK(〈t2,〈q′,ξ′〉,0,t3〉)corresponds a sequence of noncest0′,t1′,…,tn+2′and the following chain of terms from Mallory׳s memoryEK(〈t0′,$,0,t1′〉),EK(〈t1′,x1′,0,t2′〉),….EK(〈tj−1′,xj−1′,0,tj′〉),EK(〈tj′,〈q′,xj′〉,0,tj+1′〉),EK(〈tj+1′,xj+1′,0,tj+2′〉),…,EK(〈tn′,xn′,0,tn+1′〉),EK(〈tn+1′,B,1,tn+2′〉)wheretj−1′=t0,xj′1′=ξ0,tj′=t2,xj′=ξ′,tj+1′=t3,xj+1′=ξ, andtj+2′=t′, such thatMleads from the empty initial configuration to the configuration where the stringx1′x2′…xj′…xn′is written in cells1,2,…,j,…,non the tape and the j-th cell is scanned byMin stateq′. Then the following sequence of noncest0′,…,tj−1′,t1,t,tj+2′,…,tn+2′and the following chain of terms from Mallory׳s memory:EK(〈t0′,$,0,t1′〉),EK(〈t1′,x1′,0,t2′〉),….EK(〈tj−2′,xj−2′,0,t0〉),EK(〈t0,ξ0,0,t1〉),EK(〈t1,ξ1,0,t〉),EK(〈t,〈q,ξ〉,0,t′〉),〉EK(〈t′,xj+2′,0,tj+3′〉),…,EK(〈tn′,xn′,0,tn+1′〉),EK(〈tn+1′,B,1,tn+2′〉)represent the computations ofMwhich leads from the empty initial configuration to the configuration where the stringx1′x2′…xj−1′ξ1,ξ,xj+2…xn′, is written in cells 1, 2,…,n on the tape and the(j+1)-st cell is scanned byMin state q. □There is a Dolev–Yao attack on the above protocol if and only if the machineMterminates on the empty input.We prove both directions.(a)The direction from a terminating computation to an attack is straightforward by induction on the length of the computation. The key of the encoding is the use of nonces and the encryption under the secret key K which is not known to the adversary. Only Bob is able to update the encoding of the machine configuration. To each machine action corresponds a session of Bob׳s role, with additional roles for tape extension as necessary. When the machine terminates, i.e., reaches the final state q0, Alice sends the secret s unencrypted. Therefore, Mallory is able to obtain the secret.The inverse direction relies on Lemma 5. Mallory will learn the secret s only if Alice receives the encoding of the accepting state of the machineMwhich must contain a term of the formEK(〈t˜1,〈q0,ξ〉,0,t˜2〉). Since adversary controls the network, in the case of a successful attack, a term of the formEK(〈t˜1,〈q0,ξ〉,0,t˜2〉),must appear in the adversary׳s memory. Then by Lemma 5, if a term of the formEK(〈t˜1,〈q0,ξ〉,0,t˜2〉)appears in the adversary׳s memory, thenMleads from the empty initial configuration to a final configuration where a cell is scanned in state q0. That is, machineMterminates on the empty input.□Notice that in the above attacks the adversary in fact does not need to create/update fresh values, but simply actively eavesdrop, that is intercept, decompose, compose and copy messages.Corollary 7The existence of a Dolev–Yao attack is undecidable even for bounded memory protocols,PM, where Alice and Bob are finite automata whom are allowed to update nonces only, all actions by Alice and Bob are balanced, and only terms of height fixed in advance are used by Alice, Bob, and the adversary (even if the actions of the adversary are limited to decompose, compose, and copy).Given a non-recursive recursively enumerable set S, and a sequence of Turing machinesMnsuch thatMnterminates on the empty input iffn∈S, it suffices to consider the corresponding bounded memory protocolsPMn.□Thus an upper bound on the memory of the Dolev–Yao adversary is not computable from a bound on the memory used by a protocol. Moreover, based on peculiarities of our encoding described in Section 4.2, we can express such a phenomenon in quantitative terms.Theorem 8Whatever total recursive function h we take, we can construct a recursive sequence of bounded memory protocolsQnso that(a)For any n, there is a Dolev–Yao attack on the bounded memory protocolQn.However, for any n starting from some n0, any Dolev–Yao adversary whose memory is bounded by h(n) is not capable of detecting an attack on the bounded memory protocolQn.Given a total recursive function f, implemented asQnwe take the bounded memory protocolPMndescribed in Section 4.2, where Mnis a Turing machine terminating on the empty input with the value f(n).We assume that h is large enough to be an upper bound for all memories in question.Given an n, the size of each of the current states of the intruder׳s memory is supposed to be bounded by h(n), which results in that the number of all different states of his memory times the number of all different states of the memories of the other participants is bounded by2O(h(n)). Therefore, interacting with the participants within the protocolsPMn, the bounded memory adversary can only perform at most2O(h(n))steps.It suffices, therefore, to take a function f such that its time complexity is greater than2O(h(n)), for instance,Ω(22h(n)). Thus, the Dolev–Yao adversary will be able to find an attack, as it can take any number of steps, while the Bounded Memory adversary cannot find an attack.□The above theorem implies that the Standard Dolev–Yao adversary cannot be constructively approximated by an infinite sequence of increasing memory Bounded Memory adversaries: for any amount of memory we give to the bounded memory adversary, it is always possible to construct a bounded memory protocol that implements a function that requires more memory.In this section we confirm that the secrecy problem is undecidable even if the memory of the protocol is bounded in an alternative approach. We revisit the undecidability proof given in [11] and show that similar encoding can be obtained by using bounded memory protocol theories. This is not obvious since in well-founded protocol theories used in their encoding there is no bound on the memory of the (honest) participants. Namely, an unbounded number of protocol sessions can run concurrently and therefore participants are allowed to remember an unbounded number of facts denoting their participation in protocol sessions and containing the information of the protocol sessions in which they are participating. More formally, while our the rules of our bounded memory protocol theories are all balanced, well-founded protocol theories contain unbalanced rules, which are the source of undecidability of the reachability problem in multiset rewriting systems.Investigating whether one can adapt the encoding given in [6,11] to use bounded memory protocols, instead of well-founded ones was left as future work in our conference paper [17].Durgin et al. [11] present an undecidability proof for protocol theories based on the encoding of the existential Horn problem. It is know that the existential Horn problem with no function symbols is undecidable [8,11]. We now encode the existential Horn problem using bounded memory protocols instead of the well-founded ones used in [11].In order to use memory bounded protocols we modify the theories from [11]. In particular we add role regeneration rules for each of the roles. Protocol theories in [11] were specified by rules that contained exactly two facts in the pre- and post-condition. Although these rules were balanced, the initialization theory and the role generation theory were unbalanced enabling an unbounded number of protocol sessions. In principle, this allows any number of sessions to run concurrently, which is not possible in bounded memory theories. Nevertheless, there is a run simulating the derivation in the Horn theory in which only one session runs at any given time. In this run the standard Dolev–Yao adversary with unbounded memory is the initiator of each session. He acts as the network intercepting each message and storing all the intercepted data, while participants only share a secret key and do not need to remember the data from previous sessions.An existential Horn clause is a formula of the form:∀x1⋯∀xm.[α1∧⋯∧αn⇒∃y1⋯∃yk.β1∧⋯∧βj].whereα1,…∧αn,β1,…βjare first-order atomic formulas. The existential Horn problem is the problem of determining whether a formula is a consequence of an existential Horn clause theory, i.e., a setHof existential Horn clauses. Here we are interested in formulas that are conjunctions of atomic first-order logic formulas. For the inference of such a formula ϕ fromH, it suffices to check whether ϕ can be obtained by a derivationH⊢ϕ, which is a sequence of formulasϕ1,…,ϕnsuch thatϕn=ϕ, and ϕiis either(a)ϕi∈Hϕi≡β1∧⋯∧βlfor someϕj≡α1∧⋯∧αs,j<iand∀x→[α1∧⋯∧αs⇒∃y→.β1∧⋯∧βl]∈Hϕi≡αkfor someϕj≡α1∧⋯∧αk∧⋯∧αs,j<iϕi≡α1∧⋯∧αl∧⋯∧αm∧⋯∧αs, forj1,…,jk<iϕj1≡α1∧⋯∧αl⋮ϕjk≡αm∧⋯∧αswhere∀x1⋯∀xm.[α1∧⋯∧αs⇒∃y→.β1∧⋯∧βj]∈HGiven a set of existential Horn clausesH, we construct a bounded memory protocol theory and define representations of formulas as encodings of formulas given by (4) below. For such protocol theory, when combined with the standard Dolev–Yao adversary theory given in Fig. 1a, the adversary may learn the representation of a formula if and only if that formula is a consequence of the given Horn theoryH.To each Horn clause X from the given theoryHwe associate a number of protocol roles,P(H). Namely, to the clauseX≡∀x→[α1∧⋯∧αm⇒∃y→.β1∧⋯∧βi∧⋯∧βl]correspond the role theoriesR(X),Di(X)fori=1,…,l,C(X)and the role regeneration theoryG(X), defined below. Role theoryR(X)corresponds to the application of Horn clause X. Each role theoryDi(X)corresponds to the conjunction elimination rule, needed to extract atomic formulas from the conjunctions. Role theoryC(X)corresponds to conjunction introduction, allowing the set of atomic formulas to be combined to produce the conjunction needed to apply another Horn clause. Formally, we define these role theories for X as follows:R(X):A0X(k)NR(⌈α1∧⋯∧αm⌉)→∃y→.A1X(k)NS(⌈β1∧⋯∧βl⌉)Di(X):B0X,i(k)NR(⌈β1∧⋯∧βi∧⋯∧βl⌉)→B1X,i(k)NS(⌈βi⌉),i=1,…,lC(X):C0X(k)NR(⌈α1⌉)→C1X(k,⌈α1⌉)NS(⊤)C1X(k,⌈α1⌉)NR(⌈α2⌉)→C2X(k,⌈α1∧α2⌉)NS(⊤)⋮Ci−1X(k,⌈α1∧⋯∧αi−1⌉)NR(⌈αi⌉)→C2X(k,⌈α1∧⋯∧αi⌉)NS(⊤)⋮Cm−1X(k,⌈α1∧⋯∧αm−1⌉)NR(⌈αk⌉)→CmX(k)NS(⌈α1∧⋯∧αm⌉)G(X):Guy(g,k)P(⁎)→Guy(g,k)A0X(k)A1X(k)→P(⁎)Guy(k)P(⁎)→Guy(k)B0X,i(k)B1X,i(k)→P(⁎),i=1,…,lGuy(g,k)P(⁎)→Guy(g,k)C0X(k)CmX(k)→P(⁎)where the term ⊤ that represents “true”, i.e.the empty conjunction, and⌈ϕ⌉denotes the encoding of a formula ϕ of the formP1(t1,1,…,t1,i1)∧⋯∧Pj(tj,1,…,tj,ij)into a term of type message as specified below:(4)⌈ϕ⌉=Ek(〈P1.P2.….Pj,t1,1,…,t1,i1,…,tj,1,…,tj,ij〉).Here we assume that for each sequence of predicatesP1,…,Pjthat occurs on either side of the given Horn clauses inHthere is a constant symbolP1.P2.….Pjin the signature. In the above representation, encryption under the secret key k not known to the adversary is needed for a faithful encoding of the theory. Otherwise the adversary would be able to interfere with the atomic formulas.However, intruder needs to extract atomic formulas from conjunctions. That is, consequents of Horn clauses must be decomposed into their constituent atomic formulas, so that they can then be combined into antecedents of the next Horn clause in the derivation. We therefore add toP(H)role theoryR(Xmi), and the role regeneration theoryG(Xmi)for each of the following clauses:Xmi≡∀x→[α1∧⋯∧αi∧⋯∧αm⇒αi],i=1,…,mwherem=2,…,band b is the maximal number of atomic formulas in a consequent of a clause inH. This way we obtain the following theories:R(Xmi):A0Xmi(k)NR(⌈α1∧⋯∧αm⌉)→A1Xmi(k)NS(⌈αi⌉)andG(Xmi):Guy(g,k)P(⁎)→Guy(g,k)A0Xmi(k)A1Xmi(k)→P(⁎)We will now show that there is a connection between intruder knowledge of representations of formulas and derivations of these formulas in the Horn theory. As usual, terms in M-facts represent the knowledge of the adversary. In particular, factM(⌈ϕ⌉)will denote that adversary has learnt the representation of formulaϕ, that is,⌈ϕ⌉is stored in his memory.Let the initial configuration contain the following facts:Guy(A,K),Guy(B,K),M(⊤),P(⁎),P(⁎)FactsGuy(A,K)andGuy(B,K)denote that Alice and Bob share the uncompromised key K. FactM(⊤)is used by the adversary to send empty conjunctions when needed. One empty factP(⁎)serves for the network, i.e., for running the protocol. The second empty factP(⁎)will be used by the role regeneration theory for the role states of the single running session. It will be replaced by an empty fact when the session terminates. Notice that all the role theories are responder roles and that the session runs between an honest participant and the adversary who is the initiator of all sessions.Theorem 9LetP(H)be the encoding of the Horn TheoryHinto the bounded memory protocols as described above. The standard Dolev–Yao adversary can learn the representation of a formula ϕ from a run of protocolsP(H)with the initial configurationGuy(A,K),Guy(B,K),M(⊤),P(⁎),P(⁎)if and only if ϕ is derivable fromH.We modify the proof from [11] to accommodate bounded memory protocols.We first show that ifH⊢ϕthenM(⌈ϕ⌉)appears in adversary׳s memory. The proof is by induction on the length of derivations. For the base case we consider a formulaϕ∈H, that is the clauseX≡true⇒ϕfromH, the corresponding protocol roleR(X):A0X(k)NR(⊤)→A1X(k)NS(⌈ϕ⌉)and the role regeneration theoryG(X). The adversary can obtain the factM(⌈ϕ⌉)from the following run with either Alice or Bob:(5)Guy(g,k)P(⁎)→Guy(g,k)A0X(k)M(⊤)→NR(⊤)A0X(k)NR(⊤)→A1X(k)NS(⌈ϕ⌉)NS(⌈ϕ⌉)→M(⌈ϕ⌉)For the induction step, we look at the derivationH⊢ϕof length n where the last formulaϕn≡ϕ. We consider the possible cases, as per derivation definition. Ifϕ∈H, adversary can obtain the factM(⌈ϕ⌉)as in the base case above.Let ϕ be the result of applying the Horn clauseX≡α1∧⋯∧αs⇒∃z→.ϕ(z→)to a formulaϕj≡α1∧⋯∧αs, wherej<i. From the inductive hypothesis applied to the derivationH⊢ϕjof lower length j, the adversary knows the representation of ϕj, i.e.,M(⌈α1∧⋯∧αs⌉)appears in adversary׳s memory. From the following consecutive run of rolesR(Xs1),…,R(Xss), adversary learns representations of atomic formulas of ϕj:Guy(g,k)P(⁎)→Guy(g,k)A0Xs1(k)M(⌈α1∧⋯∧αs⌉)→NR(⌈α1∧⋯∧αs⌉)A0Xs1(k)NR(⌈α1∧⋯∧αs⌉)→A1Xs1(k)NS(⌈α1⌉)NS(⌈α1⌉)→M(⌈α1⌉)A1Xs1(k)→P(⁎)Guy(g,k)P(⁎)→Guy(g,k)A0Xs2(k)M(⌈α1∧⋯∧αs⌉)→NR(⌈α1∧⋯∧αs⌉)A0Xs2(k)NR(⌈α1∧⋯∧αs⌉)→A1Xs2(k)NS(⌈α2⌉)NS(⌈α2⌉)→M(⌈α2⌉)A1Xs2(k)→P(⁎)⋮Guy(g,k)P(⁎)→Guy(g,k)A0Xss(k)M(⌈α1∧⋯∧αs⌉)→NR(⌈α1∧⋯∧αs⌉)A0Xss(k)NR(⌈α1∧⋯∧αs⌉)→A1Xss(k)NS(⌈αs⌉)NS(⌈αs⌉)→M(⌈αs⌉)Hence, factsM(⌈α1⌉),…,M(⌈αs⌉)appear in adversary׳s memory.Now, from the below run, the adversary is able to learnM(⌈ϕ⌉):Guy(g,k)P(⁎)→Guy(g,k)C0X(k)M(⌈α1⌉)→NR(⌈α1⌉)C0X(k)NR(⌈α1⌉)→C1X(k,⌈α1⌉)NS(⊤)NS(⊤)→M(⊤)M(⌈α2⌉)→NR(⌈α2⌉)C1F(k,⌈α1⌉)NR(⌈α2⌉)→C2F(k,⌈α1∧α2⌉)NS(⊤)NS(⊤)→M(⊤)M(⌈α3⌉)→NR(⌈α3⌉)⋮M(⌈αs⌉)→NR(⌈αs⌉)Cs−1X(k,⌈α1∧⋯∧αs−1⌉)NR(⌈αs⌉)→CsX(k)NS(⌈α1∧⋯∧αs⌉)CsX(k)→P(⁎)Guy(g,k)P(⁎)→Guy(g,k)A0X(k)NS(⌈α1∧⋯∧αs⌉)→M(⌈α1∧⋯∧αs⌉)M(⌈α1∧⋯∧αs⌉)→NR(⌈α1∧⋯∧αs⌉)A0X(k)NR(⌈α1∧⋯∧αs⌉)→A1X(k)NS(⌈ϕ⌉)NS(⌈ϕ⌉)→M(⌈ϕ⌉)The above run contains the rolesR(X),C(X)and the role regeneration theoryG(X)corresponding to clause X.Notice that there is enough memory in the system so that all the above rules are applicable. More precisely, one empty fact is used for the network and the other for role state predicates. Since only one role is active at a time that is enough memory for the whole run.The case when ϕ is obtained by the conjunction elimination rule,ϕ=αi, reduces to the above case for the clause Xmi.For the remaining case of the application of conjunction introduction rule to obtain ϕ, it follows that ϕ is the antecedent of some clauseX∈H. Adversary can therefore learn the representation of ϕ by initiating a roleC(X)corresponding to that clause.Next we show that if from a run of protocol theoriesP(H)the adversary learnsM(⌈ϕ⌉)thenH⊢ϕ. The proof is by induction on the length of the run, i.e., the number of roles. Since we assume that the key K is uncompromised, initially no factsM(⌈ϕ⌉)appear in adversary׳s memory. The adversary can only learnM(⌈ϕ⌉)from some message sent by the rules inP(H). The shortest such run is similar to the sequence of rules (5) and corresponds to the clausetrue⇒ϕfromH. Trivially it is the case thatH⊢ϕ.We then consider the run of n protocol roles fromP(H)in which the adversary learnsM(⌈ϕ⌉). Since the system׳s memory is bounded, only one role can run at a time. Role state predicates of previous session have been forgotten by the role regeneration rules and the last role in the run,Rn, has started executing. We assume that after the firstn−1roles the adversary knows{M(⌈ϕ1⌉),…,M(⌈ϕk⌉)}. By the induction hypothesis we haveH⊢{ϕ1,…,ϕk}. As per the construction of protocol theoriesP(H)from the Horn theoryH, roleRnis eitherR(X),Di(X),C(X)orG(X)for some clauseX∈H, orX≡Xmi, forXmi≡∀x→[α1∧⋯∧αi∧⋯∧αm⇒αi]. If the roleRnis aR(X)role, then X is the clauseϕi⇒∃y→ϕfor somei∈{1,…,k}and because ofH⊢ϕiwe haveH⊢ϕ.RolesDi(X)andR(Xmi)correspond to the logical axiomA1∧⋯∧Ai∧⋯∧Aj⇒Ai.This role represents the application of above axiom to a formula from{ϕ1,…,ϕk}which results in ϕ. FromH⊢{ϕ1,…,ϕk}and the above axiom it follows thatH⊢ϕ.If the roleRnis aC(X)role and all its rules have been used in the run, then F is the logical axiomA1∧⋯∧Ai⇒(A1∧⋯∧Ai)for somei∈{1,…,k}, where a number of formulas imply their conjunction. In case the roleC(X)has not finished, i.e., the last rule of the role has not been used in the run, and similarly in the case of roleRnbeingG(X)for some X, no new representations of formulas are exchanged. ConsequentlyM(⌈ϕ⌉)∈{M(⌈ϕ1⌉),…,M(⌈ϕk⌉)}and henceH⊢{ϕ}.□Notice that in the above interaction with the protocol run the adversary does not need to create fresh values. He only needs to intercept and send messages.The next lemma shows that the encoding of the given Horn theory into protocol theories is polynomial, and that the size of the facts in the obtained protocol theories is linearly bounded.Lemma 10The construction of protocol theoriesP(H)from the Horn theoryHis computable in polynomial time. Furthermore, if the formulas inHhave the maximum term size bounded by s, then the size of facts appearing in the run ofP(H)from which the adversary can learn the representation of a formulaϕ∈His bounded by f(s) where f is a linear function of s.LetH={F1,…,Fn}be a Horn theory and let m be the bound on the number of atomic formulas in a conjunction in any of the clauses fromH. To each clause inHcorrespond oneR(F), oneC(F), oneG(F)theories, and up to mDi(F)theories. Each theoryR(F)andDi(F)has a single rule, each theoryC(F)has up to m rules while each theoryG(F)has a maximum of 2m+4 rules. Therefore the construction of protocol theoriesP(H)is polynomial in n and m.Consider a run ofP(H)from which the adversary learns the representation of a formulaϕ∈H. Let s be the maximum term size appearing in the Horn theoryH, where we count one for each predicate symbol, each term symbol and each conjunction. Recall that the size of a fact is the total number of terms and predicate symbols it contains. As per the construction ofP(H)and the run in which the adversary learns⌈ϕ⌉(see the proof of Theorem 9), facts of the largest size have the form of a predicate over the representation of a formula fromH, e.g.,Ck−1F(⌈ϕ1∧⋯∧ϕk⌉),NS(⌈ϕ1∧⋯∧ϕk⌉)orM(⌈ϕ1∧⋯∧ϕk⌉). By Definition 4 the number of predicate and term symbols in a representation of a formula fromHis at most s+2, when counting the key and the encryption. Therefore the size of facts appearing in the run is bounded by s+3, i.e., it is linearly bounded with respect to s.□Durgin et al. [11] show that the existential Horn problem is undecidable even when no function symbols are allowed. The following result is a direct consequence of this fact and of Theorem 9.Corollary 11The existence of a Dolev–Yao attack is undecidable even for bounded memory protocols, where only terms of height fixed in advance are used by participants and the adversary (even if the actions of the adversary are limited to intercept messages, copy and send).

@&#CONCLUSIONS@&#
This paper shows that the memory of the adversary cannot be inferred from the memory bounds of the participants (Theorem 8). This is accomplished by proposing a novel undecidability proof by encoding Turing machines by means of bounded memory protocols. This result confirms the hardness of protocol security. It answers negatively an open problem left in [16]. We further confirm the undecidability of the secrecy problem for bounded memory protocols and the standard Dolev–Yao adversary by revisiting the encoding the existential Horn implication problem shown in [6,11] and demonstrating that this problem can also be encoded by means of bounded memory protocols.Together with Carolyn Talcott, we are investigating the use of the computational tool Maude [5] for the specification and model-checking of regulated processes, such as administrative processes [15].Another direction that we are currently investigating is the extension of our model with continuous time. In particular, systems that can create fresh values and mention continuous time are of great interest to protocol security. For instance, many distance authentication protocols [20,4] rely on timing measures. Thus extending our model with continuous time and determining decidable fragments, e.g., balanced systems, is of great interest for the verification of such protocols.