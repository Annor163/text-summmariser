@&#MAIN-TITLE@&#
Big data and ergonomics methods: A new paradigm for tackling strategic transport safety risks

@&#HIGHLIGHTS@&#
Data from on-train data recorders is underused.Can be used as an input to existing ergonomics methods.300 methods were reviewed and nine leading indicators of human factors risks extracted.The proofs-of-concept can all be automated in a full application.

@&#KEYPHRASES@&#
Big data,Leading indicators,Human performance,Methods,

@&#ABSTRACT@&#
Big data collected from On-Train Data Recorders (OTDR) has the potential to address the most important strategic risks currently faced by rail operators and authorities worldwide. These risk issues are increasingly orientated around human performance and have proven resistant to existing approaches. This paper presents a number of proof of concept demonstrations to show that long standing ergonomics methods can be driven from big data, and succeed in providing insight into human performance in a novel way. Over 300 ergonomics methods were reviewed and a smaller sub-set selected for proof-of-concept development using real on-train recorder data. From this are derived nine candidate Human Factors Leading Indicators which map on to all of the psychological precursors of the identified risks. This approach has the potential to make use of a significantly underused source of data, and enable rail industry stakeholders to intervene sooner to address human performance issues that, via the methods presented in this paper, are clearly manifest in on-train data recordings. The intersection of psychological knowledge, ergonomics methods and big data creates an important new framework for driving new insights.

@&#INTRODUCTION@&#
Data recording is the act of automatically logging information on system parameters over time. Data recording has become increasingly ubiquitous in rail transport operations and easily qualifies as a big data problem (e.g. Wu and Liu, 2014; Geisler et al., 2012). Big data is a rather broad term first used by NASA scientists to describe particularly thorny computer graphics problems which taxed the ability of computer hardware like memory and storage: “We call this the problem of big data. When data sets do not fit in main memory (in core), or when they do not fit even on local disk, the most common solution is to acquire more resources.” (Cox, 1997, p. 235). In the absence of universal agreement on a definition (e.g. Press, 2014) it is possible to turn to Google™, where it is described more broadly as: “extremely large data sets that may be analysed computationally to reveal patterns, trends, and associations, especially relating to human behaviour and interactions.” For this reason, big data looms large over the Ergonomics discipline and represents a potentially paradigm shifting trend going forward (see Drury, 2015). An example of the issues at stake can be found in the rail industry. Entire national train fleets are now required to carry On Train Data Recorders (OTDRs), or so called ‘Black Boxes’, for the purposes of post-accident investigation. Although the data is only accessed periodically (often rarely) the devices themselves are continuously recording how individual trains are being driven, at increasing rates, and across an increasing range of parameters. The outflow of data is therefore extensive and growing in terms of volume (the amount of data), velocity (the speed at which it is growing) and variety (the number of things being measured; Laney, 2001; Drury, 2015). Perhaps because of this, and the practical challenges involved in storing and mining such large quantities of data, it currently represents a significantly underused resource (Hart, 2003). The question, then, is what could it be used for? In this paper we aim to demonstrate that it has the potential to be coupled to existing ergonomics methods, and used to tackle the most important strategic risk issues currently faced by rail operators and authorities worldwide.The intersection of big data and the rail transport context embodies three paradoxes:Improving safety trends are a very welcome outcome of improved safety practices, but because so few major rail accidents occur there are now relatively few opportunities to use OTDRs for their original purpose. With so few accidents there is also no longer enough data to construct reliable forward looking estimates in a way that might have been possible for certain historic engineering (e.g. metal fatigue) or human performance issues (e.g. fatigue risk; Evans, 2011).Safety data is levelling off, with a persistent class of human/system accident now elevated to the status of a key risk (RSSB, 2009; Stanton and Walker, 2011). When safety performance data reaches the level of that achieved in the rail sector it instead starts to become characterised by periodicities, cycles or discrete events. This is becoming evident in EU rail safety data, with a large scale rail accident occurring on average every six years (EU, 2003). This class of accident includes Signals Passed At Danger (SPADs) or overspeed events such as the Santiago de Compostela rail accident in Spain. Here it is possible to demonstrate numerous engineering and procedural safeguards, full compliance with necessary regulatory requirements, well trained individuals and a modern train fleet, yet a largely unforeseen accident still occurred.The third and final paradox is that the opportunities to use On-Train Data Recorders (OTDRs) for their original purpose (i.e. post-accident analysis) are diminishing at the same time as the technical capabilities of data recorders are increasing (Geisler et al., 2012; Morcom, 1970). What this means is that Exabyte's of non-accident data are being collected day in and day out, but not currently used. This is a significant irony given the “widespread concern within the industry that the background indicators – rather than the headline grabbing ones – have remained worryingly stable” (Wolmar, 2012).The opportunity embedded in these paradoxes is to use big data from transport recordings to detect accident precursors, specifically those accidents which have proven resistant to current approaches and which are responsible for the current plateauing of accident trends.Leading indicators are measurable precursors to major events such as an accident. The indication of a precursor leads, or comes before, the actual event itself. Lagging indicators are the opposite. These are so called loss metrics that can only become apparent after an event (Rogers et al., 2009). Leading indicators are said to be proactive because they enable steps to be taken to avoid seriously adverse consequences. Lagging indicators are said to be reactive in that a seriously adverse event needs to occur before it can be learnt from. For this reason, leading indicators are also sometimes referred to as positive performance indicators and lagging indicators as negative performance indicators. The concept of leading and lagging indicators originally derives from the field of economics and the need to understand when one phase of a cyclical economic process this will change to another (Mitchell and Burns, 1938). The terms have been appropriated more recently by the safety and risk field, particularly in view of developments in Safety Management Systems (SMS) since the 1990s. The notion of leading indicators is also beginning to emerge from the ergonomics literature in the form of research on behavioural markers (e.g. Nixon et al., 2015), the use of novel human performance proxy measures (e.g. McIntire et al., 2014), and a more long standing interest in the modelling and prediction of human performance (Hamilton and Clarke, 2005). Leading indicators, in a safety management and ergonomics context, can be defined as “something that provides information that helps the [the organisation] respond to changing circumstances and take actions to achieve desired outcomes or avoid unwanted outcomes” (Step Change, 2003, p. 3). That ‘something’ can be defined according to the risk factors underlying the troublesome class of operational accident (or near accident) that is the focus of this paper.The reason for the emphasis on human performance can be seen in the ‘broad causes’ attributed to recent rail accidents. Out of seven broad causes attributable to European rail accident data (Evans, 2011), four out of seven, including the top three, involve a prominent human performance dimension. Expressed in descriptive terms, these broad causes involve a task in which a combination of the following happens: ‘getting out of sequence’, ‘losing situational awareness’, ‘allocating attention incorrectly and/or ‘allowing prior experience to override the correct action’, or combinations of all four. Table 1summarises a comprehensive review of the literature (reported elsewhere, Walker and Strathie, 2012) linking these descriptive terms to a set of specific risk factors. If we are able to detect when these risk factors are present, using big data as the input, then we should also be able to make progress on these key strategic risks.The basic research problem can be stated thus: despite considerable improvements in safety performance in the rail sector, a persistent class of accident/near accident continues to occur. These incidents reside at the interface of people and systems. What is required is a means to detect the presence or emergence of such problems before they manifest themselves as a serious operational incident. This paper describes how big data from OTDRs can be used to ‘drive’ established ergonomics methods to provide leading indicators of specific risk factors. Four proof-of-concept demonstrators are presented to show how these approaches work, selected on the basis of their potential scalability when used with big data.

@&#CONCLUSIONS@&#
Exabytes of data are routinely and continuously collected from normal journeys by On-Train Data Recorders (OTDR), but are currently not used in a systematic fashion. At the same time, not only are the opportunities to use OTDR data after accidents diminishing because of improving safety trends but we are increasingly left with a class of ergonomics problem that is difficult to predict based on previous occurrences. Human performance issues are a strategic risk and innovative new ways to work at this interface are required. The research reported in this paper advances this agenda. Table 9summarises the nine leading indicator candidates that arise from coupling big data to ergonomics methods and how they map to key risk types (Table 10).The advantage of this approach is that ergonomics methods are able to bring with them a substantial and robust form of construct validity. They have already been shown to provide access to the behavioural issues that are of interest in detecting key risks, and as such provide a novel framework for interrogating big data from OTDR devices. Importantly, the process of review and proof of concept testing establishes the scalability of the methods. They ‘can’ be driven from this new type of data, and furthermore, are amenable to software-based implementation in future. This finding hints at considerable reductions in the analytical overhead required to perform these analyses, indeed, with more automation Human Factors Leading Indicators of the sort tested in this paper could become continuous key performance indicators, relying more on real-time data streams rather than post-hoc analysis. The possibilities are tantalising, but having proved the concept a number of important future research tasks are required. Ergonomics methods are able to demonstrate good construct validity and reliability (based on their substantial legacy of prior use and development) but another source of big data on actual accident and risk outcomes needs to be combined with these candidate leading indicators. This is currently underway. This critical step is required in order to answer questions about whether identified risks around vigilance decrements, clusters of behaviour or decision bias find themselves implicated in actual incidents such as SPADs, overspeeding, wrong-side door releases and station over-runs. The main task is to establish the sensitivity of the leading indicators, along with their predictive validity in terms of actual risk outcomes. If this loop can be closed then we have a powerful and potentially paradigm changing approach that is not restricted to the rail sector. The same insights apply equally to existing Flight Data Monitoring/Flight Operations Quality Assurance practices, wherein problematic Human Factors issues have also become key strategic risks. The authors have also begun to apply this approach in the truck/logistics sector where big data from vehicle telematics is widespread, as is the business need to make better use of an underused resource to solve issues around safety, fatigue risk management, fuel use and eco-driving. Indeed, there are numerous commercial and industrial sectors who collect various forms of system telemetry, and for which Human Factors Leading Indicators would represent a valuable source of insight. The wider implications for the HF/E discipline are perhaps more profound. Instead of applying our methods to samples of a population we can instead work with the entire population. Instead of taking a time isolated slice through a system we can start to look at it continuously. Instead of narrow insights derived from laboratory studies of subjects removed from their context, we can adopt a naturalistic ‘whole-systems’ approach. This paper has tried to show the power of big data in revealing new and previously hidden insights using ergonomics methods. The big data haystack may not be any smaller than it was previously, but the proof of concept demonstrators show that the number of useful needles to be found has been increased and made easier to find.