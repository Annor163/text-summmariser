@&#MAIN-TITLE@&#
Scene shape estimation from multiple partly cloudy days

@&#HIGHLIGHTS@&#
Cloud shadows provide geometric constraints on the shape of an outdoor scene.Video from several partly cloudy days is sufficient to estimate scene geometry.We estimate metric world-point locations for pixels in a calibrated camera.We estimate metric world-point locations for pixels in a calibrated camera network.We can estimate relative 2D world-point locations without any camera calibration.

@&#KEYPHRASES@&#
Shape estimation,Outdoor cameras,Distributed smart cameras,Correspondence estimation,

@&#ABSTRACT@&#
Clouds are a cue for estimating weak correspondences in outdoor cameras. These correspondences encode the uncertain spatio-temporal relationships between pixels both within individual cameras and across networks of cameras. Using this generalized notion of correspondence, we present methods for estimating the geometry of an outdoor scene from: (1) a single calibrated camera, (2) a network of calibrated cameras, and (3) a collection of arbitrary, uncalibrated cameras. Our methods do not require camera motion nor overlapping fields of view, and use simple geometric constraints based on appearance changes caused by cloud shadows. We define these geometric constraints, describe new algorithms for estimating shape given videos from multiple partly cloud days, and evaluate these algorithms on real and synthetic scenes.

@&#INTRODUCTION@&#
Knowledge of the 3D geometry of a scene can be useful for many applications in outdoor camera networks, including video surveillance [1–3], weather estimation [4–6], and environmental monitoring [7,8]. However, standard approaches to estimating scene geometry that rely on camera motion [9] or controlled lighting [10] are not possible for images obtained from static outdoor cameras. In this domain, most approaches consider photometric cues from changes in the sun position [11,12] to provide estimates of surface orientation or geometric cues based on cloud motion [13] to give direct constraints on scene shape. In this work, which extends our previous work [14], we focus on the cloud cue and generalize the problem setting to incorporate constraints provided by multiple days (with independent cloud motion directions) and multiple cameras. This eliminates the ambiguity inherent in only having a single cloud motion direction, enables partial shape estimation with unknown camera calibration, and the recovery of the relative scene layout in an uncalibrated camera network.We assume that the dominant appearance variation in the scene is due to the shadows cast by moving clouds. Since the cameras are static, each pixel has an intensity time series that reflects the pattern of clouds that passed between the sun and the imaged scene point. As clouds translate due to cloud motion, nearby world locations that are inline with the wind will have a related, but temporally offset, intensity time series. We use signal processing methods to estimate this temporal delay and use the set of temporal delays between all pixels in the scene, or across a network of cameras, as the only image measurements input to our shape estimation algorithms. We define a geometric relationship between the scene shape, these temporal delays and the known cloud motion. Fig. 1provides an overview of our approach.We focus on three problem settings for estimating scene geometry: a fully calibrated camera, a fully calibrated camera network, and an uncalibrated and general imaging model, which is suitable for uncalibrated cameras or networks of uncalibrated cameras. In all cases, we take as input video from a static camera (or set of cameras) observing a fixed-geometry scene. In the first two problem settings, we derive linear least-squares formulations that allow us to quickly solve for a full 3D scene model, with known metric scale. In the third setting, only a 2D scene layout reconstruction is possible, due to the ambiguity introduced by the orthographic lighting of the sun.

@&#CONCLUSIONS@&#
