@&#MAIN-TITLE@&#
A comparative appraisal of two equivalence tests for multiple standardized effects

@&#HIGHLIGHTS@&#
This article explicates and evaluates the features of the ANOVA F test and the studentized range test for determining the equivalence of multiple standardized effects.The primary emphasis is to reveal the underlying properties of the two methods with regard to power behavior and sample size requirement across a variety of design configurations.To enhance the practical usefulness, complete sets of SAS and R computer algorithms for calculating the critical values, p-values, power levels, and sample sizes are also developed.

@&#KEYPHRASES@&#
Effect size,Power,Sample size,Standardized mean difference,

@&#ABSTRACT@&#
Equivalence testing is recommended as a better alternative to the traditional difference-based methods for demonstrating the comparability of two or more treatment effects. Although equivalent tests of two groups are widely discussed, the natural extensions for assessing equivalence between several groups have not been well examined. This article provides a detailed and schematic comparison of the ANOVA F and the studentized range tests for evaluating the comparability of several standardized effects. Power and sample size appraisals of the two grossly distinct approaches are conducted in terms of a constraint on the range of the standardized means when the standard deviation of the standardized means is fixed. Although neither method is uniformly more powerful, the studentized range test has a clear advantage in sample size requirements necessary to achieve a given power when the underlying effect configurations are close to the priori minimum difference for determining equivalence. For actual application of equivalence tests and advance planning of equivalence studies, both SAS and R computer codes are available as supplementary files to implement the calculations of critical values, p-values, power levels, and sample sizes.

@&#INTRODUCTION@&#
Many studies are designed explicitly to show that two treatments are functionally equivalent or that a new method is as effective as a well-established method under the same condition. The methodology for establishing statistical equivalence has been typically developed for appraising the bioequivalence between two drug formulations in biopharmaceutical studies. A comprehensive review of the different types of equivalence tests can be found in Meyners [1]. Accordingly, the two one-sided tests procedure proposed by Schuirmann [2] and Westlake [3] is the most common method for equivalence assessment. It is essential to emphasize that power analyses and sample size calculations are often critical for investigators to credibly address designated hypotheses and support research questions. Considerable attention has been devoted to the power and sample size issues of the two one-sided tests procedure in the literature, such as Bristol [4], Chow, Shao, and Wang [5], Chow and Wang [6], Diletti, Hauschke, and Steinijans [7], Liu and Chow [8], Phillips [9], Schuirmann [10], and Wang and Chow [11].Despite the equivalent tests of two groups are widely discussed, the natural extensions for assessing equivalence between several groups have received relatively little attention in the literature. Two different effect size measures have been proposed to represent the degree of disparity among several treatment groups (Cohen [12,13]). One index relies on the standard deviation of the standardized means and the second index is the range of the standardized means. Consequently, these two distinct measures of disparity among standardized means give rise to two different multiple-sample procedures: the ANOVA F test and the studentized range test. However, the research for the two methods has mainly focused on the test of the traditional null hypothesis of no difference in treatment means. In fact, the two approaches can be readily modified as viable equivalence tests. Specifically, Wellek [14] proposed an adjustment of the ANOVA F test based on the variance of the standardized means. On the other hand, the studentized range test was considered in Giani and Finner [15] for the range of the standardized means. Related discussions are presented in Cribbie, Arpin-Cribbie, and Gruman [16], Chen, Wen, and Wang [17], and the references therein.The prescribed results in Wellek [14], Giani and Finner [15], Cribbie, Arpin-Cribbie, and Gruman [16], and Chen, Wen, and Wang [17] of the ANOVA F test and the studentized range test offer fundamental guidance for the equivalence problem of several treatments. Then a natural question of great interest is which of the two methods should be used because they are markedly different in theoretical principles and demand varying computational efforts. It was noted in Wellek [14] that power comparisons between the two approaches are futile because the associated distribution and hypothesis formulation are apparently distinct. Accordingly, no research to date has compared these two approaches regarding which method is more appropriate under what circumstances for determining whether treatment means are sufficiently near each other to be considered equivalent. Although the range of the standardized means is not a function of the standard deviation of the standardized means, there exists an intrinsic property for the lower and upper bounds of the range of the standardized means when the standard deviation of the standardized means is fixed (Pearson and Hartley [18]). Therefore, it provides a unified and meaningful viewpoint to evaluate the power behavior of the two grossly diverse techniques. More importantly, the explications presented later reveal that without a detailed appraisal, one may unknowingly employ an equivalence test procedure with lesser efficiency and inevitably confront the consequence of inadequate power performance and unsatisfactory research outcome.In addition, the notion of least favorable configurations of treatment means emphasized in Giani and Finner [15] and Chen, Wen, and Wang [17] is vital to determine the critical values for conducting equivalence tests of unimportant differences. Tables of such critical values are generally not available to applied researchers and it is impossible to implement the test procedures without an efficient software package. Moreover, in order to enhance the usefulness of a test procedure, the corresponding power and sample size calculations must also be considered to extend its applicability in planning research studies. Due to the complexity of both the studentized range and the ANOVA F test procedures, Chen, Wen, and Wang [17] and Wellek [14] also addressed the corresponding computational issues under different computing systems. However, the presented algorithms do not provide all the desired features for data analysis and design planning. Arguably, the lack of efficient and convenient computer software impedes the practical use of equivalence tests and the theoretical development of equivalence research. Therefore, it is prudent to develop a full account of computer programs for implementing the necessary calculations in equivalence studies.In view of the inadequate results in the literature, the present article aims to contribute to the analysis and design of equivalence studies in two ways. First, within the context of equivalence framework, the fundamental properties of the standard F test and the studentized range test are reviewed to document the importance of the problem and the characteristics of available methods. Moreover, extensive numerical assessments are performed to reveal the power performance and sample size requirement of the ANOVA F test and the studentized range test under a wide range of model configurations. The appraisals discern not only which method is most suitable under what circumstances but also the actual differences between the contending test procedures. Second, to facilitate the application of the examined approaches, the corresponding SAS and R computer codes are developed to compute the critical values, observed significance levels, attained power levels, and required sample sizes. Note that the implementation of both methods involves specialized programs not currently available in prevailing statistical packages. The constructed software programs provide a unified set of algorithms for design planning and data analysis of equivalence investigations.Consider the one-way fixed-effects ANOVA model(1)Yij=μi+εijwhere Yijis the value of the response variable in the jth trial for the ith factor level, μiare treatment means, ɛijare independent N(0, σ2) errors with i=1, …, G (≥2) and j=1, …, N. To characterize the degree of departure from no treatment effect, two distinctive measures for the balanced design were proposed in Cohen [12,13]. The first index is the standard deviation of the standardized means(2)f=σμσwhere σ=(σ2)1/2,σμ=(σμ2)1/2,σμ2=∑i=1G(μi−μ¯)2/Gis the average dispersion between the treatment means, andμ¯=∑i=1Gμi/Gis the mean of the treatment effects. The second index is based on the range of the standardized means(3)δR=μmax−μminσ,where μmax and μmin are the maximum and the minimum of the G treatment means, respectively. In general, the two effect sizes f and δRhave no direct functional relationship except for G=2 that f=δR/2=|δ|/2, where δ=(μ1−μ2)/σ is the well-known standardized mean difference. Notably, the corresponding inferential procedures are also substantially different. The general guidance of Cohen [12,13] suggests that the small, medium, and large effects in terms of f and δ could be defined as f=0.10, 0.25, and 0.40, and δ=0.2, 0.5, and 0.8, respectively. However, it should be noted that the particular research question within a concentrated research field determines whether a specific effect size is practically or scientifically important.The ANOVA F* is the most widely used test statistic for the null hypothesis that all treatment means are equal:(4)F*=SSTR/(G−1)SSE/(NT−G),whereSSTR=N∑i=1G(Y¯i−Y¯)2is the treatment sum of squares,SSE=∑i=1G∑j=1N(Yij−Y¯i)2is the error sum of squares, NT=GN,Y¯i=∑j=1N(Yij/N), andY¯=∑i=1G∑j=1N(Yij/NT). However, Wellek [14] suggested that the equivalence of several mean effects can be evaluated by(5)H0:f≥f0versusH1:f<f0where f0 (>0) is a specified value and denotes a minimal significant difference for declaring equivalence of the treatment means. It follows from the model formulation in Eq. (1) that(6)F*∼F(G−1,NT−G,Λ),where F(G−1, NT−G, Λ) is the noncentral F distribution with (G−1) and (NT−g) degrees of freedom, and noncentrality parameter Λ=NTf2 andf2=σμ2/σ2is the signal to noise ratio (Fleishman [19]). The strength of association η2 that reflects the proportion of total variance that is attributable to treatment effects is related to f2 as η2=f2/(1+f2).It follows from the monotone property of a noncentral F distribution that P{F(G−1, NT−G, Λ0)<c}>P{F(G−1,NT−G, Λ)<c} for Λ>Λ0≥0 and c>0 (Ghosh [20]). Thus, the least favorable configuration ofμ=(μ1, …, μG) isμ0=(μ10, …, μG0) with the standard deviation of the standardized means f=f0. Under the null hypothesis H0: f≥f0, the statistic F is assumed to follow the distribution(7)F*∼F(G−1,NT−G,Λ0)whereΛ0=NTf02. Hence, H0 is rejected at the significance level α if F*<F1−α(G−1, NT−G, Λ0), where F1−α(G−1, NT−G, Λ0) is the (100×α)th percentile of the noncentral F distribution F(G−1, NT−G, Λ0). Then the corresponding power function of the F* test is of the form(8)πF*(Λ)=P{F(G−1,NT−G,Λ)<F1−α(G−1,NT−G,Λ0)},where Λ<Λ0.On the other hand, the comparability of several treatment means may be assessed with the studentized range test in terms of the range of the standardized means as considered in Chen, Wen, and Wang [17]:(9)H0:δR≥δR0versusH1:δR<δR0where δR0 (>0) is a designated constant that indicates a minimal significant difference for determining equivalence. The studentized range statistic is defined as(10)Q*=N1/2(Y¯max-Y¯min)S,whereY¯maxandY¯minare the maximum and minimum of the G sample means, respectively, S=(S2)1/2, and S2=SSE/(NT−G) is the sample variance. It is important to note that the distribution of the studentized range statistic Q* depends on all pairwise mean differences μi−μl, not just a function of the maximum mean difference μmax−μmin. Following the model formulation in Eq. (1), the distribution of Q* does not have a closed-form expression and a convenient unified notation. For ease of illustration, it is denoted here by(11)Q*∼Q(G,N,τ),where τ=(μ1, …, μG)/σ. However, the cumulative distribution function Θ(q) of Q* can be expressed as follows:(12)Θ(q)=P{Q*≤q}=EK∑i=1GEZi∏l=1l≠iG(Φ{Zi+N1/2δil}Φ{Zi+N1/2δil−q[K/(NT−G)]1/2})where K∼χ2(NT−G) is a chi-square random variable with degrees of freedom NT−G, Φ(·) is the cumulative distribution function of a standard normal distribution, Zi∼N(0, 1) are independent standard normal random variables, and EK{·} and EZi{·} are taken with respect to the distribution of K and Zi, respectively. The particular expression in Eq. (12) is similar to those presented in Giani and Finner [15] and Chen, Wen, and Wang [17]. However, it is analytically transparent and has the ease of numerical computation. Under the assumption that all treatment means are equal (μ1=…=μGand δR=0), the property of Q* has been discussed in many statistics textbooks, and the cumulative probability and quantile can be readily computed with popular software systems. However, the general distribution of Q* is relatively more complex and a special purpose algorithm is required to perform the associated calculations.It is noteworthy that the distribution of Q* is not a simple function of δRalone. Thus, the critical value cannot be determined for arbitrary treatment means satisfying δR=δR0. It follows from Giani and Finner [15] that the least favorable configuration of μ=(μ1, …, μG) with δR=δR0 is μ0=(μ10, …, μG0)=(−σδR0/2, 0, …, 0, σδR0/2). Thus, P{Q(G, N, τ0)<c}>P{Q(G, N, τ)<c} for τ0=μ0/σ and any τ that has the range of the standardized means δR0 and c>0. The null hypothesis H0: δR≥δR0 is rejected at the significance level α if Q*<Q1−α(G, N, τ0), where Q1−α(G, N, τ0) is the (100×α)th percentile of the distribution of Q* when the treatment means have the least favorable configuration μ=μ0 and τ0=μ0/σ. Also, the power function of the Q* test is obtained as(13)πQ*(τ)=P{Q(G,N,τ)<Q1−α(G,N,τ0)}for all sets of standardized treatment means τ satisfying δR<δR0.It is essential to note that δRis not a function of f, however, there exists an intrinsic property for the lower and upper bounds of the range of the standardized means δRwhen the standard deviation of the standardized means f is fixed (Pearson and Hartley [18]). Specifically, for all sets of standardized treatment means τ with a fixed value f, the maximum range is δRmax=(2G)1/2f for τ=τmax where τmax={−(G/2)1/2f, 0, …, 0, (G/2)1/2f}. In contrast, when G is even, the minimum range is δRmin=2f for τ=τEmin where τEmin={τ1, …, τG}, τi=−f, i=1, …, G/2; and τi=f, i=G/2+1, …, G. On the other hand, when G is odd, the minimum range is δRmin=2Gf/(G2−1)1/2 for τ=τOmin where τOmin={τ1, …, τG}, τi=−Gf/(G2−1)1/2, i=1, …, (G−1)/2; and τi=Gf/(G2−1)1/2, i=(G−1)/2+1, …, G. For example, consider an equivalence study with G=4 and a fixed value f=0.5. Then the maximum range is δRmax=21/2 associated with the standardized mean structure τmax={−2−1/2, 0, 0, 2−1/2}. On the other hand, the minimum range is δRmin=1 for the standardized mean pattern τEmin={−0.5, −0.5, 0.5, 0.5}. This functional constraint provides a constructive approach to assess the power behavior of the ANOVA F* and the studentized range Q* test procedures.Accordingly, in order to provide a systematic investigation, the effect sizes f0 and f1 under the null and alternative hypotheses are chosen a priori to facilitate meaningful comparisons of the power discrepancy between the F* and Q* techniques. Note that the designated value f0 uniquely defines the minimal significant range δR0=(2G)1/2f0 and the least favorable configuration(14)τ0=τmax={−(G/2)1/2f0,0,…0,(G/2)1/2f0}for determining the critical value of the Q* test of equivalence. On the other hand, the selected alternative f1 will lead to the maximum range δRmax=(2G)1/2f1, and the minimum range δRmin=2f1 when G is even, or δRmin=2Gf1/(G2−1)1/2 when G is odd. The corresponding configurations τEmin and τOmin are readily obtained by replacing f with f1 in the abovementioned expressions. Therefore, πQ*min and πQ*max represent the power of the studentized range test evaluated at two different configurations τmin and τmax with δRmin and δRmax, respectively. In general, δRmin≤δRmax and the equality holds only when f1=0. More importantly, when f1=f0, the least favorable configuration is equivalent to the structure τmax so that πQ*max=α. In contrast, under the same setting of f1=f0, the structure τmin does not match the least favorable configuration, and hence, πQ*min>α. The related features of the studentized range test can be found in David, Lachenbruch, and Brandis [21] and Hayter and Hurn [22].To delineate the underlying features of the two test procedures under different model characteristics, the subsequent empirical investigation consists of two studies. The first appraisal involved power computations for the two competing methods across several model configurations with fixed total sample sizes. In the second study, numerical calculations were performed to provide insights into the required sample sizes to achieve the designated power levels of the two contending approaches under the design characteristics specified in the first study. It should be emphasized that the power functions πF* and πQ* are functions of the following factors: (1) Type I error, (2) number of groups, (3) group sample size, (4) treatment mean structure, (5) error variance, and (6) minimal significant difference. It is evident that the influence of each of these components on the power behavior not only differs but also depends on the concurrent impact of other factors. To provide an informative explication of the nonlinear properties of πF* and πQ*, the numerical assessments are conducted by fixing all but one of these factors and varying that single factor in the evaluation.First, the power assessments were conducted for two minimal effects f0=0.25 and 0.5 with the total sample sizes NT=144 and 48, respectively. In each scenario, three different numbers of groups G=3, 4, and 6 are considered and result in the six combined configurations: {G, N}={3, 48}, {4, 36}, {6, 24}, {3, 16}, {4, 12}, and {6, 8}. Throughout this empirical study, the significance level is set as α=0.05. Under the designated hypotheses H0: f≥f0 versus H1: f<f0, the power πF* of the F* test are computed for the alternative effect size f=f1 with f1={0, 0.05, 0.10, 0.15, 0.20, 0.25} and {0, 0.1, 0.2, 0.3, 0.4, 0.5} for f0=0.25 and 0.5, respectively. Accordingly, for the selected f0 and f1, the power πQ* of the Q* test for H0: δR≥δR0 versus H1: δR<δR0 are also calculated for the two standardized mean extremums {τmax, τOmin} and {τmax, τEmin} when G is odd and even, respectively. For ease of illustration, the attained powers πQ* of the Q* test evaluated at the two extremums are denoted by πQ*min and πQ*max. The designated effect sizes {f1, δRmin, δRmax} and resulting powers {πF*, πQ*min, πQ*max} are summarized in Tables 1 and 2for the two effect settings f0=0.25 and 0.5, respectively.The numerical results in Tables 1 and 2 reveal a clear phenomenon that the achieved powers of πF*, πQ*min, and πQ*max are decreasing in the number of groups G and the value of f1 when all other factors remain constant including the total sample size. Thus, the two equivalence tests require more total sample size to achieve the designated power for larger number of groups or greater magnitude of f1 when all other configurations are fixed. On the other hand, the discrepancy between the computed powers {πF*, πQ*min, πQ*max} is rather small for most of the cases examined here in Tables 1 and 2. Although the differences are not substantial, the studentized range Q* test is more powerful than the ANOVA F* test (πQ*min>πQ*max>πF*) when f1 is close to f0. However, it appears that πF* can be slightly larger than πQ*min and πQ*max when f1 nears 0. For example, when f0=0.5 and f1=0.4, the attained powers in Table 2 are {πQ*min, πQ*max, πF*}={0.1725, 0.1553, 0.1539} and {0.1722, 0.1468, 0.1435} for G=4 and 6, respectively. In contrast, when G=2, the attained powers for f1=0.0 and 0.1 in Table 2 are {πF*, πQ*min, πQ*max}={0.8489, 0.8485, 0.8485} and {0.7838, 0.7837, 0.7837}, respectively. To further justify the power properties of the two tests, additional numerical assessments were conducted to evaluate their power performance for the model configurations in Table 1 with larger total sample size NT=480. In this case, the results revealed a consistent pattern that πQ*min≥πQ*max≥πF*. Also, the differences among the three computed powers can be substantial in some cases. For example, when f1=0.15, the computed powers are {πQ*min, πQ*max, πF*}={0.7368, 0.6984, 0.6899}, {0.8050, 0.6953, 0.6784}, and {0.8404, 0.6895, 0.6562} for G=3, 4 and 6, respectively. Because most of the power levels in Tables 1 and 2 are considerably smaller than the common level of 0.80 in planning research designs, it is prudent to perform further sample size comparisons under the designated power 0.80 as demonstrated in the succeeding study.In the second study, instead of fixing the total sample size, the sample sizes required to achieve the nominal power 0.80 are calculated for the selected group structures and effect settings. The computed sample sizes are presented in Tables 3 and 4and they are denoted by NF*, NQ*min, and NQ*max for the power functions πF*, πQ*min, and πQ*max, respectively. To enhance the illustration, the computed sample sizes NF*, NQ*min, and NQ*max associated with the cases of G=3 and 4 in Table 4 are plotted in Figs. 1 and 2, respectively. As expected, the necessary sample sizes increase with decreasing difference between f1 and f0 for all six combined settings of f0 and G. More importantly, the estimated sample sizes demonstrate a general tendency that NF*≥NQ*max≥NQ*min. Also, the differences between the three sample sizes {NF*, NQ*max, NQ*min} markedly increased as f1 approaches f0, particularly for larger number of groups. Specifically, the sample sizes {NF*, NQ*max, NQ*min}={430, 422, 112} and {115, 113, 30} for G=6 with {f0, f1}={0.25, 0.20} and {0.50, 0.40} are presented in Tables 3 and 4, respectively. Hence, the studentized range Q* test outperforms the ANOVA F* test when the standardized mean structures are close to the extreme pattern of τmin. Although the studentized range Q* procedure is more computationally intensive than the ANOVA F* approach, it is of little consequence if a computer software is available.To demonstrate the embedded features of the ANOVA F* and the studentized range Q* statistics, the numerical demonstration of evaluating four antihypertensive treatments in Wellek [14, p. 223] and Chen, Wen, and Wang [17] is reconsidered here. The emphasis is on the potential discrepancy between the two approaches under varied effect size considerations, especially the comparability of the equivalence thresholds.In this comparative clinical trial, the primary endpoint for evaluating efficacy of treatment is the average of diastolic blood pressure recorded continuously over 24h for each enrolled patient. The sample means and sample standard deviations of the four treatment groups are {99.8120, 99.2903, 100.0024, 98.6407} and {7.5640, 5.9968, 10.4808, 4.5309}, respectively. For illustration, the trial is assumed to have a balanced design with group size N=10. The resulting pooled sample variance is S2=55.8880. The calculations showed that the ANOVA F and the studentized range statistics are F*=0.0666 and Q*=0.5760, respectively. At the significance level α=0.05 and the magnitude f0=0.5, the critical value of the minimal effect F test is 1.2044 and the corresponding p-value is 0.0002. For the studentized range test with a specific effect size δR0=1 and the least favorable configuration τ0={−0.5, 0, 0, 0.5}, the computed critical value and p-value are 1.5633 and 0.0021, respectively. Accordingly, the null hypotheses of two equivalence tests in terms of H0: f≥0.5 and H0: δR≥1 are rejected and the four antihypertensive treatments are essentially equivalent. Note that the SAS/IML (SAS Institute [23]) and R (R Development Core Team [24]) programs employed to perform the exact calculations of critical value and p-value of both tests are presented in supplementary files. Researcher can easily modify the input values to perform the designated equivalence tests with their own specifications.In practice, a research study requires adequate statistical power and sufficient sample size to detect scientifically credible effects. It is sensible that the corresponding power calculations and sample size determinations must be considered in the planning stage of a study. Due to the prospective nature of advance research planning, the general guidelines suggest that typical sources like published finding or expert opinion can offer plausible and reasonable planning values for the vital characteristics of mean effects and variance components. Thus, the sample statistics of the antihypertensive study are employed to provide planning values of the model parameters and effect sizes for future equivalence study. These configurations of μ={99.8120, 99.2903, 100.0024, 98.6407} and σ2=55.8880 are incorporated in the user specifications of the SAS/IML and R programs presented in the supplemental files. The numerical computations showed that the resulting powers for the two tests are πF*=0.6495 and πQ*=0.2900, respectively, for N=10, f0=0.5, δR0=1, and α=0.05. The attained powers are less than the fairly common and somehow minimal level of 0.80, especially for the studentized range Q* test. The results suggest that the designated sample size may not warrant a decent chance of revealing the equivalence property of antihypertensive treatments.With the prescribed power formulas and computer algorithms, the sample size N needed to attain the nominal power (1−β) can be found by a simple iterative search for the chosen significance level α and parameter settings. Detailed computations show that the sample sizes of 14 and 17 are needed for the ANOVA F test (f1=0.0707) to achieve the target power of 0.80 and 0.90, respectively. Alternatively, the studentized range test (δR1=0.1821) necessitates a balanced group size of 27 and 35 for the two power levels 0.80 and 0.90, respectively. It is clear that the studentized range test requires nearly twice the number of sample sizes of the ANOVA F test to obtain the same power performance. These findings raise the important question: Is the ANOVA F test more powerful than the studentized test, or do they simply reflect a lack of comparability between the specifications of f0=0.5 and δR0=1? It appears that this issue was not addressed in Wellek [14, p. 223] and Chen, Wen, and Wang [17]. Consequently, it is of theoretical importance and practical interest to evaluate the relative performance between the F* and Q* test procedures under comparable design configurations.From the technical discussions in the preceding section, the equivalence evaluations of the four antihypertensive treatments with f0=0.5 of the ANOVA F test and δR0=1 of the studentized range test are not compatible. For the threshold f0=0.5 and the number of groups G=4, it follows from Eq. (14) that the matching minimal significant range δR0=21/2=1.4142 and the least favorable configuration τ0={−2−1/2, 0, 0, 2−1/2}. Accordingly, for N=10 and the test of H0: δR≥21/2 versus H1: δR<21/2, the achieved power of the Q* test is πQ*=0.6489. To achieve the target power of 0.80 and 0.90, the computed sample sizes are identical to the results of the ANOVA F test with 14 and 17, respectively. Hence, the presented theoretical features and numerical computations showed that the two tests actually yield almost the same powers under the designated configurations of μ={99.8120, 99.2903, 100.0024, 98.6407} and σ2=55.8880.To further exemplify the vital discrepancy between the two tests and the potential usefulness of the computer codes, the prescribed mean configurations are modified as μ={97.1936, 97.1936, 101.6791, 101.6791} with f1=0.3 and δR1=0.6. In this case, the resulting power for the ANOVA F test of H0: f≥0.5 versus H1: f<0.5 is πF*=0.7705 which is substantially smaller than the attained power πQ*=0.9056 for the studentized test of H0: δR≥21/2 versus H1: δR<21/2. On the other hand, sample size calculations showed the group sizes of 44 and 31 are needed for the F* and Q* tests, respectively, to achieve the target power of 0.80. Therefore, the studentized range test can be more advantageous than the ANOVA F* test when f1 changes from 0.0707 to 0.3 and becomes near f0=0.5. The corresponding minimal significant differences are δR1=0.1821 and 0.6 and the latter is much closer to the null value δR0=21/2. Hence, it is advisable that researchers conduct appropriate power analysis and sample size calculations based on the best knowledge of the mean effect configurations and other vital model characteristics.

@&#CONCLUSIONS@&#
