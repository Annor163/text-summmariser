@&#MAIN-TITLE@&#
Boosting paraphrase detection through textual similarity metrics with abductive networks

@&#HIGHLIGHTS@&#
Analyze a set of weak text reuse similarity metrics for paraphrase detection.Boost the performance of individual metrics using the abductive learning paradigm.Use decision-level fusion to build a committee of models of individual metrics.Use feature-level fusion to get a paraphrase detector using optimal set of metrics.Validate merits of the approach over individual metrics and other learning methods.

@&#KEYPHRASES@&#
Plagiarism,Text reuse detection,Paraphrase detection,Textual similarity metrics,Score fusion,Abductive networks,

@&#ABSTRACT@&#
A number of metrics have been proposed in the literature to measure text re-use between pairs of sentences or short passages. These individual metrics fail to reliably detect paraphrasing or semantic equivalence between sentences, due to the subjectivity and complexity of the task, even for human beings. This paper analyzes a set of five simple but weak lexical metrics for measuring textual similarity and presents a novel paraphrase detector with improved accuracy based on abductive machine learning. The objective here is 2-fold. First, the performance of each individual metric is boosted through the abductive learning paradigm. Second, we investigate the use of decision-level and feature-level information fusion via abductive networks to obtain a more reliable composite metric for additional performance enhancement. Several experiments were conducted using two benchmark corpora and the optimal abductive models were compared with other approaches. Results demonstrate that applying abductive learning has significantly improved the results of individual metrics and further improvement was achieved through fusion. Moreover, building simple models of polynomial functional elements that identify and integrate the smallest subset of relevant metrics yielded better results than those obtained from the support vector machine classifiers utilizing the same datasets and considered metrics. The results were also comparable to the best result reported in the literature even with larger number of more powerful features and/or using more computationally intensive techniques.

@&#INTRODUCTION@&#
The vast amount of information available through electronic media and over the Internet has motivated several research works in natural language processing, machine translation and information retrieval. One interesting related problem is paraphrase or semantic equivalence detection. This problem can have applications in plagiarism detection and authorship authentication, machine translation, text summarization, social network content analysis, information flow in news web sites, etc. For instance, plagiarism has become an alarming problem especially in research and academia [1]. This authorship misconduct is defined as partially or completely copying someone's work or idea and presenting it as another person's work without an appropriate acknowledgment or citation. To maintain academic integrity, plagiarism should be avoided, discouraged, detected and prevented.Effective paraphrase detection is a complex problem due to the subjective nature of the task and the many forms it can take, which poses various levels of challenges for the detection process. For example, Osman et al. [2] classified plagiarism techniques into six groups: character-based, structural-based, cluster-based, syntax-based, cross language-based and semantic-based. They also presented a method by comparing text based on semantic allocation for each term inside sentences. Another extended taxonomy is described by Alzahrani et al. [3] based on linguistic patterns and text features. This taxonomy has two main categories: literal and intelligent. Literal forms can include exact, near or modified copying from the original text. While exact copying is verbatim or word-for-word copying of the whole or part of the document, near copying involves some minimal changes such as deletion, insertion, or substitution of a few words. It may also involve splitting long sentences or joining short ones. Modified copying requires a bit more work to change the original text, e.g., it may reorder phrases or involve syntactical restructuring of the sentence. On the other hand, intelligent changes can obfuscate the appearance of the original text, but retains its semantics.Several approaches have been used for paraphrase detection, including linguistic analysis of reference corpora, and unsupervised and supervised machine learning [4–8]. Basic lexical similarity measures have been used, e.g., Levenshtein edit distance, longest common subsequence (LCS), and several word n-gram (i.e., sequence of n contiguous words) overlap functions. Since individual measures of text similarity have their own strengths and limitations, it is expected that better results can be attained by combining multiple measures into one score which is then used to detect text similarity or reuse.In this paper, we investigate a novel approach for paraphrase detection. The aim is to consider a set of weak textual similarity metrics that are not much better than random guess and boost their performance as individual metrics and through integration using the abductive learning paradigm. Our work is divided into three levels: boosting performance of individual metrics, decision-level fusion of a committee of networks, and feature-level fusion of the most relevant metrics. For evaluation purpose, two benchmark paraphrase corpora have been utilized and several performance measures are evaluated and compared.The rest of the paper is organized as follows. Section2 describes the research problem and contributions of this paper. Section3 briefly reviews related work. Section4 presents the details of the proposed method. Section5 discusses the experimental work on two benchmark corpora. Finally, conclusions and future work are reported in Section6.The problem addressed in this paper can be described as follows. Given a large collection of M annotated sentence pairs or short passage pairs (ai, bi) for i=1 to M, where aimay be a paraphrased version of bi. Paraphrasing indicate semantic equivalence and can occur at various levels ranging from simple copy–paste or changes of few words to more intelligent changes in the structure, content, or style. This collection can be gathered from online news web sites, social network applications such as twitter, student homework submissions, submitted research papers and proposals. The annotation, ci, indicates whether the ith pair is paraphrased or not. This annotation is obtained through a number of human judgments to reduce subjectivity. All annotations are summarized in the binary form where 1 indicates paraphrased and 0 indicates not paraphrased. One example of such collection is the Microsoft Research Paraphrase Corpus (MSRPC) [9]. The research goal is to devise metrics that can reliably detect whether a given un-annotated pair of sentences is paraphrased or not. Although several metrics have been proposed in the literature for measuring the degree of text re-use, they fail to provide reliable results for paraphrase detection due to the complexity of the problem. Motivated by the success of abductive learning and its capability to identify the most relevant subset of features and build optimal models of simple polynomial functional elements, the main contributions in this paper are summarized as follows:•Boost the performance of a set of simple but weak similarity metrics through the abductive learning paradigm, this gives stronger metrics that can have better results when applied individually.Fuse the decisions made by a committee of optimal abductive models to obtain additional performance enhancement by integrating the set of enhanced metrics. This was achieved in three ways: majority vote, simple averaging, and use of a dedicated combination network.Propose and evaluate a feature-level fusion based on abductive networks to identify a smaller subset of available metrics and construct an optimal integration model for paraphrase detection.

@&#CONCLUSIONS@&#
In this paper, a novel approach for paraphrase detection from weak textual metrics has been proposed based on the use of the abductive learning paradigm. Two benchmark corpora have been utilized for extracting five similarity metrics and evaluating the approach. Contributions were made at three levels in this paper. First, abductive learning was used to boost the performance of weak textual similarity metrics that were not much better than random guess when used individually. Moreover, integration of various metrics was investigated at the decision level and feature level. Fusing multiple decisions of simple networks through majority voting, averaging or using a second level combination network method has lead to additional improvements. However, feature-level fusion has yielded superior results while using simpler models. It could also benefit from the inherent capability of abductive learning to automatically select a smaller subset of metrics that is more relevant to modeling paraphrase detection. For instance, for MSRPC benchmark corpus, abductive learning identified only three lexical measures to be most relevant and constructed an optimal abductive network model. Results showed that the proposed method gave superior or comparable performance to other learning approaches, whether those evaluated in this paper using the same feature set or the ones reported in the literature. The results also confirm the critiques reported in the literature on the MSRPC corpus. As future work, we intend to explore the possibility of improving the detection accuracy further through including other semantic and contextual features and through fusing multiple classifiers based on different types of feature sets at the decision level. Another potential research problem for tackling large-scale repositories is to consider the parallelization of the presented approach.