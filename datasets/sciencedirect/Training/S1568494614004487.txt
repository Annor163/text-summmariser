@&#MAIN-TITLE@&#
Comprehensive learning particle swarm optimization based memetic algorithm for model selection in short-term load forecasting using support vector regression

@&#HIGHLIGHTS@&#
Feature selection and parameter tuning are conducted as a unifying model selection.CLPSO-based memetic algorithm is proposed to solve the model selection problem.Providing significant improvement compared with other model selection methods.Improving accuracy and outperform some counterparts in literature.

@&#KEYPHRASES@&#
Support vector regression,Short-term load forecasting,Model selection,Memetic algorithms,Particle swarm optimization,

@&#ABSTRACT@&#
BackgroundShort-term load forecasting is an important issue that has been widely explored and examined with respect to the operation of power systems and commercial transactions in electricity markets. Of the existing forecasting models, support vector regression (SVR) has attracted much attention. While model selection, including feature selection and parameter optimization, plays an important role in short-term load forecasting using SVR, most previous studies have considered feature selection and parameter optimization as two separate tasks, which is detrimental to prediction performance.ObjectiveBy evolving feature selection and parameter optimization simultaneously, the main aims of this study are to make practitioners aware of the benefits of applying unified model selection in STLF using SVR and to provide one solution for model selection in the framework of memetic algorithm (MA).MethodsThis study proposes a comprehensive learning particle swarm optimization (CLPSO)-based memetic algorithm (CLPSO-MA) that evolves feature selection and parameter optimization simultaneously. In the proposed CLPSO-MA algorithm, CLPSO is applied to explore the solution space, while a problem-specific local search is proposed for conducting individual learning, thereby enhancing the exploitation of CLPSO.ResultsCompared with other well-established counterparts, benefits of the proposed unified model selection problem and the proposed CLPSO-MA for model selection are verified using two real-world electricity load datasets, which indicates the SVR equipped with CLPSO-MA can be a promising alternative for short-term load forecasting.

@&#INTRODUCTION@&#
Short-term load forecasting (STLF) aims to predict electricity loads over a short time period. Traditionally, it has been considered a very important issue since not only is it critical for automatic generation control, reliable operation, and resource dispatch, but it also contains fundamental information used for energy transactions in competitive electricity markets [1,2]. However, the electricity load is inevitably affected by various factors, such as climate, social activities, and seasonal factors, and the prediction performance is also highly dependent on the modeling configuration, such as parameter tuning for a specific model. Therefore, it is very difficult to forecast the electricity load accurately when faced with challenges arising from the vast selection of candidate input variables and model configuration parameters.During the past few decades, many approaches for load forecasting have been proposed, such as the autoregressive moving average model [3], regression models [4,5], expert systems [6], fuzzy logic [7], semi-parametric additive model [8], functional time-series predictor [9], neural networks (NN) [2,10–12], and support vector machines (SVMs) [13–20]. Among these, support vector regression (SVR, a regression form of SVMs) is a powerful machine learning technique with strong theoretical foundation [21,22] and has been obtained appealing performance in the field of load forecasting, for example [13–19]. As [23] advocated, the electrical load forecasting has been one of the most widely studied applications for SVR and its variations (i.e., least squares SVMs). Aimed at improving modeling quality, previous research efforts have mainly focused on selecting the influencing input variables (feature selection) and tuning the appropriate parameter settings of the SVR model.Many factors, such as historical load, meteorological factors, and calendar information, have been examined in previous studies [1,11,15,18,24–26]. Of these influencing factors, some could be redundant or even irrelevant to a specific STLF problem; yet there is no general rule about which influencing factors and especially how many time lags of the factors should be included in the case of a time series forecasting system. This is a strong motivation for a feature selection technique in the field of STLF problem [18,27]. Feature selection techniques used in past studies can be divided into two types: filter methods and wrapper methods. A filter method chooses the feature subset based on an evaluation criterion such as mutual information (MI) [28–31], Bayesian ‘automatic relevance determination’ [32], or correlation and linear independency [33,34], maximum-relevance minimum-redundancy criterion (MRMR) and ReliefF [18]. The filter method is characterized by its independence of the learning algorithm and mainly focuses on the invention of measures depicting the relationship between each subset of input variables and the output. As opposed to a filter method, wrapper methods use the performance of the forecasting model as an evaluation criterion to identify the correct input subset. Various wrapper methods have been investigated, and the implementation of some metaheuristics such as the simulated rebounding algorithm [24], simulated annealing [27], genetic algorithms and ant colony optimization [35] are regarded as common practice.Parameter optimization is concerned with the optimal setting of parameters in SVR, such as the penalty coefficient, the kernel parameters, and the width of the loss function. The selection of these parameters is crucial to obtain good performance in handling the electricity load forecasting task using SVR. By involving metaheuristics, such as GAs [36,37], chaotic particle swarm optimization [38], and artificial bee colony algorithms [39], particle swarm pattern search method [18], simulated annealing [27], various studies have focused particularly on parameter optimization in an SVR forecasting model for electricity loads.However, the main disadvantage of the above studies with regard to feature selection and parameter optimization is that they address these two subtasks in an almost disjoint way. To understand this consideration, we must bear in mind that although parameter optimization and feature selection are two separate issues in model selection, the feature subset choice influences the appropriate parameters, and vice versa [40]. On the contrary, this study investigates model selection with a lens on the development of a unifying modeling framework. Obviously, a unifying implementation of these two subtasks implies increased complexity in the problem. As a powerful algorithmic paradigm for evolutionary computing in a wide variety of areas [41–48], MAs are especially attractive for model selection because of their powerful search ability, both in exploration and exploitation. Therefore, this study proposed a solution to the proposed model selection problem in the framework of MAs. Specifically, considering the successful performance in existing applications [49–53], comprehensive learning particle swarm optimization (CLPSO) is applied as global searcher in the proposed MA for exploration of the search space and detection of regions that can potentially yield an optimum solution. Besides, a problem-specific local search is proposed to effectively exploit the potential regions identified by CLPSO in the proposed CLPSO-based MA (CLPSO-MA). The performance of the proposed CLPSO-MA based model selection in SVR is compared using real-world electricity loads with certain selected established counterparts.The main aims of this study are to make practitioners aware of the benefits of applying model selection in STLF using SVR and to provide one solution for model selection using the proposed CLPSO-MA algorithm. The contributions of this work can be summarized as follows. (a) This study first considers feature selection and parameter optimization as a unified model selection process in STLF using SVR. Although many studies have paid special attention on the feature selection and parameters optimization in the SVR-based load forecasting modeling, few, if any, studies related to unified model selection for load forecasting using SVR have been reported in the literature. (b) A novel memetic algorithm is proposed to solve the model selection task; this could be considered to be the first application of an MA for model selection in the case of STLF. (c) In the proposed MA, CLPSO is applied to explore the search space and detect the regions that can potentially yield an optimum solution. A special local search is also proposed to address the local search of the unified model selection problem which is essentially a continuous-binary optimization problem. (d) Compared with other well-established counterparts, benefits of the proposed unified model selection problem and the proposed CLPSO-MA for model selection are verified using two real-world electricity load datasets, which indicates the SVR equipped with CLPSO-MA can be a promising alternative for short-term load forecasting.The remainder of this paper is organized as follows. Section 2 discusses the basic concept and technical concerns of SVR modeling in STLF. Section 3 elaborates on the proposed CLPSO-MA based model selection for SVR forecasting model. Section 4 shows the details of experimental setup. The results together with a discussion thereof are reported in Section 5. Finally, we conclude the paper in Section 6.The essence of STLF is a type of regression procedure. Consider the pretreated sample set{(xi,yi)}i=1n, where xi∈Rmis the i-th vector containing m input features, yiis the corresponding desired load, and n denotes the number of data items in the sample set. Based on Vapnik's statistical learning theory [22], SVR generates a mapping function using the optimization problem:(1)MinimizeR=C∑i=1n(ξi+ξi*)+12∥w∥2Subject toyi−<w,ϕ(xi)>−b≤ε+ξi<w,ϕ(xi)>+b−yi≤ε+ξi*ξi,ξi*≥0,i=1,2,…,nwhere C is a penalty parameter. Here ξiandξi*are non-negative slack variables, and ϕ(x) is the high-dimensional feature space, which is non-linearly mapped from the input space x.According to Wolfe's Dual Theorem and the saddle-point condition, the dual optimization problem of the above problem is obtained as follows:(2)maxα,α*−12∑i,j=1l(αi−αi*)(αj−αj*)<ϕ(xi),ϕ(xj)>−ε∑i,j=1l(αi+αi*)+∑i,j=1lyi(αi−αi*)s.t.∑i,j=1l(αi−αi*)=0andαi,αi*∈[0,C]with(3)w=∑i=1n(αi−αi*)ϕ(xi)whereαi,αi*are nonnegative Lagrange multipliers obtained by solving the convex quadratic programming problem given above.Finally, based on Eq. (3) and applying the kernel function trick, the decision function has the following explicit form:(4)f(x)=∑i=1n(αi−αi*)K(xi,xj)+bHere K(xi, xj) is defined as the kernel function.During forecasting for a short-term load using SVR, one important step is to determine the input features xi. Although previous studies have incorporated many factors to improve load forecasting [1,11,15,24,25,31], some factors may be redundant or even irrelevant to the specific STLF. The use of redundant or even irrelevant factors can decrease the accuracy of the forecasting model and increase its complexity and computational overhead. Feature selection that can identify a powerful predictive subset of variables by eliminating noisy, irrelevant and redundant inputs without degrading the performance of the model, is thus needed.In the optimization problem given in Eq. (1), the first term∑i=1n(ξi+ξi*)is the empirical risk, which is often measured by the ɛ-insensitive tube, where ɛ is called the tube size. The second term,1/2∥w∥2, is the regularization term, which is used as a measure of the flatness or complexity of the function. Hence, C is referred to as the penalty parameter, which specifies the trade-off between the empirical risk and regularization term. Both C and ɛ are user-determined parameters.Moreover, the elegance of using a kernel function is that one can address feature spaces with arbitrary dimensionality without having to compute map ϕ(x) explicitly. The radial basis function (RBF) in Eq. (5), a kernel function strongly recommended and widely used for its superior performance with lower complexity [54], is applied in this study.(5)K(xi,xj)=exp−∥xi−xj∥22δ2where δ is the kernel parameter. The kernel parameter in Eq. (5) should be carefully chosen because it implicitly defines the structure of the high-dimensional feature space ϕ(x) and thus controls the complexity of the model.Overall, three parameters (the penalty parameter C, the RBF kernel parameter δ, and the width ɛ of the loss function) play an important role in the success of SVR [55]. Thus, during STLF using SVR with the RBF kernel, these should be tuned carefully to ensure accurate forecasting.MAs, which were first coined by Moscato [56], constitute a recent core research growth area in computational intelligence. Inspired by Darwinian principles of natural evolution and Dawkins’ notion of a meme, an MA is generally viewed as the union of population-based global evolutionary algorithms and a local learning procedure capable of local search refinements. Designed by hybridization, MAs are expected to achieve a balance between exploration and exploitation of the search space by combining the advantages of population-based methods and local-based methods. Currently, MAs have shown their ability to achieve high performance and superior robustness across a wide range of problem domains (see [41,42] for a recent survey). Nevertheless, hybridization can be more complex and is thus, expensive to implement. Particle swarm optimization (PSO) [57], a population-based stochastic optimization technique, has attracted much interest mainly owing to its high efficiency search without involving any evolution operators (i.e., crossover and mutation). Improved by a comprehensive learning strategy, CLPSO has demonstrated its state-of-the-art global search ability on many complex problems [49–53]. Taking all these factors into consideration, we propose a CLPSO-based memetic algorithm (CLPSO-MA) to address the model selection problem for electricity load forecasting using SVR.In the following subsections, we describe in detail the implementation of the proposed CLPSO-MA for model selection.The concept of CLPSO-MA and CLPSO-MA based model selection are firstly illustrated in Fig. 1. In Fig. 1, the Part.1 shows the proposed CLPSO-based memetic algorithm (CLPSO-MA). In the proposed CLPSO-MA, CLPSO is used to perform exploration owing to its good global search ability, which will be illustrated in Sections 3.2 and 3.3. To enhance the exploitation ability in CLPSO, a problem-specific local search, which is labeled in dotted frame and will be illustrated in Section 3.4, is proposed to perform exploitation with individual learning in local spaces. In addition, it is important to balance exploration and exploitation given the limited computational budget in an MA [58,59]. Hence, in the proposed CLPSO-based MA, each particle undergoes local refinement with a specified probability pl(xk), which is also labeled in dotted frame in Part.1 of Fig. 1. The selection probability is defined by a roulette wheel section scheme with linear scaling [60]:(6)pl(xk)=fmax(P)−f(xk)∑y∈P(fmax(P)−f(y))where f is a fitness function (mean absolute percentage error (MAPE) is used in this study), and fmax(P) is the maximum fitness value in the current population P. With this selection probability, a particle with a better (smaller) fitness value has more chance of being selected for exploitation.In Fig. 1, the Part.2 shows the flowchart of how to evaluate a particle with electricity load forecasting using SVR. As shown in Part.2 in Fig. 1, for a given particle where both parameters and features are encoded (see Section 3.2 for details), the training set is applied to evaluate the parameters and features included in a particle. When the termination condition is satisfied, the best particle in the CLPSO-MA is applied to retrain SVR-based forecasting model on the training set, and then, the testing set is applied to evaluate the proposed CLPSO-MA based model selection for the SVR load forecasting model. The forecasting accuracy obtained on the testing set is used to compare with other accuracies of other forecasting models.Because both exploration and exploitation are emphasized and balanced, the CLPSO-based memetic algorithm is expected to address the model selection problem of load forecasting using SVR optimally. A detailed description of particle encoding, the fitness function, CLPSO-based global search, and a well-designed problem-specific local search are provided in the following subsections.In this study, both the SVR parameters and the input features are determined using our proposed CLPSO-based memetic algorithm. Therefore, a particle (or individual) comprises two parts: three SVR parameters, which are real-valued variables, and the feature masks, which are essentially binary variables denoting the presence or absence of features. For convenience, a binary coding scheme is applied to represent the particles. Fig. 2shows the binary particle representation of our design, wherepC1∼pCnC,pδ1∼pδnδ, andpε1∼pεnεrepresent the binary coding of parameters C, δ, and ɛ, respectively.pf1∼pfnfrepresents the feature masks and the value of 1 or 0 for each feature mask denotes the corresponding feature is selected or excluded, respectively. Here nC, nδ, and nɛare the numbers of bits representing parameters C, δ, ɛ, respectively, and nfis the number of bits representing the number of feature candidates. Note that nC, nδ, and nɛare selected according to the calculation precision required for each parameter, while nfis equal to the number of feature candidates. A set of particles is called a swarm or population. The initial population of the algorithm is generated randomly.Because the ultimate goal of the forecasting model is to forecast future electricity loads with high accuracy (called the generalization ability), it is important to choose a fitness function that can estimate the generalization ability when determining the model's input features and parameters in SVR using the CLPSO-MA. In this study (as shown in Part.2 in Fig. 1), 5-fold cross-validation on the training set was applied to generate and evaluate the input features and parameter set. The mean squared percentage error (MPAE in Table 1), which is a scale-free measure, was selected as the fitness function. The smaller the fitness value is, the better is the particle.In the proposed CLPSO-MA, CLPSO-based operators are used to explore the search space. As one of the most successful variants of PSO, CLPSO has been successful in several applications [49–53,61]. It employs a comprehensive learning strategy in which other particles’ previous best positions (pbest) are used to update the velocity of each particle. CLPSO ensures that the diversity of the swarm is preserved to discourage premature convergence thereby improving the global search ability of the algorithm. In CLPSO, each particle, representing the SVR parameters and the input features of the STLF model in this study, adjusts its flight velocity using the following update equation:(7)vid=w×vid+c×rid×(pbestfi(d)d−xid)wherevidandxiddenote the velocity and position of the ith particle in the dth dimension, respectively,c∈ℝis the acceleration coefficient, w is the inertia weight to balance the exploration and exploitation in the search space,ridis a random number in the range [0,1], andpbestfi(d)drepresents the dth dimension of the exemplar particle's pbest. The exemplar, indicated by fi(d), defines which particles’ pbest should be followed; it can be any particle including its own one.Following [49], fi(d) is chosen based on a predefined probability Pci, referred to as the learning probability that the ith particle will learn from the other particles’ pbest values. This is empirically defined as follows:(8)Pci=0.05+0.45×exp((10(i−1))/(ps−1))−1exp(10)−1where ps denotes population size.Specifically, the index fi(d) of the exemplar particle is determined as follows. (1) For each dimension of particle i, we generate a random number in the range [0,1]. If this random number is greater than probability Pci, the corresponding dimension will learn from its own pbest, that is, fi(d)=i; otherwise, it will learn from another particle's pbest. To select another particle, tournament selection is applied. First, two particles are randomly chosen from the population, which excludes the particle whose velocity is being updated. Then, by comparing the fitness values of these two particles’ pbest values, the particle with the smaller fitness value is selected as the exemplar. If all exemplars of a particle are its own pbest, a randomly selected dimension is forced to learn from the corresponding dimension of another particle's pbest. (2) Once the exemplars for all dimensions of a particle have been selected, the particle keeps learning from these exemplars until a stagnation of m (called the refreshing gap) generations is detected.In this study, the position of any particle is expressed as a binary bit vector composed of 0s and 1s. Following [62], the velocity of the particle is no longer a change ratio of its position, but a change probability of its position. The equation for the final flight trajectory is given in Eq. (9).(9)xid=1ifrand<S(vid),0otherwisewithS(vid)=11+exp(−vid)where rand is a random number generator that is uniformly distributed in [0,1] and S(·) is a sigmoid transfer function.In the proposed CLPSO-MA, the local search is very important for exploitation. For an optimization problem with binary variables, the bit-flip operation is a general local search exploiting the neighbors of a binary-encoded individual. The bit-flip operation always carries out logical negation on a single bit or each of several bits. However, the individual in this study is actually a mixed binary-encoded string of three real-valued variables (C, δ, and ɛ) and several binary variables (feature masks). Although the bit-flip operation is suitable for these binary feature masks for which the bits of the string are completely independent, it can cause the binary code of real-valued variables to degenerate because the bit-flip operation can result in large movement from the current position to another position. To address the problem of mixed types of decision variables in this study, a problem-specific local search is proposed. As shown in Fig. 3, the proposed problem-specific local search handles the real-valued parameters and binary feature masks with two different operations. The feature mask is exploited by using the bit-flip operation, and then, the binary operation is applied to exploit the neighbors of the three real-valued parameters.The complexity of the proposed CLPSO-based MA depends on the complexity of CLPSO and the proposed local search. Their worst-case complexities are as follows:•The complexity of CLPSO is: O(S×I), where S is the population size of the swarm, I is the maximum iteration of the CLPSO.The complexity of local search (LS) is: O(3×i), where i is the maximum iteration of local search.At each iteration of CLPSO, each particle undergoes the local search with the probability pl(xk) (shown in Eq. (6)), thus, the complexity of CLPSO-MA is: O(CLPSO)×pl×O(LS)=O(S×I×pl×3×i). And the worst-case of complexity of CLPSO-MA is O(S×I×3×i) when pl=1 for all particles. Obviously, compared with CLPSO, the CLPSO-MA has the bigger complexity. However, it should be noted that the pl(xk) in Eq. (6) depends on the individual's fitness and the maximum fitness, and∑k=1Spl(xk)=1. That is, for each particle, the probability of undergoing local search is relatively small. So it will no longer obtain the worst-case complexity for proposed CLPSO-MA.

@&#CONCLUSIONS@&#
