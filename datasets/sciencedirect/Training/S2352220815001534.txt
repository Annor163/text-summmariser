@&#MAIN-TITLE@&#
Declarative event based models of concurrency and refinement in psi-calculi

@&#HIGHLIGHTS@&#
Represents prime event structures as a psi-calculi instance, respecting concurrency diamonds and action refinement.Represents Dynamic Condition Response (DCR) Graphs as another psi-calculi instance, respecting the semantics.Syntactic restrictions are identified that make both encodings complete.The logic part of psi-calculi are enough for capturing event structures, whereas communication is needed for DCR graphs.

@&#KEYPHRASES@&#
Psi-calculi,Prime event structures,DCR graphs,Action refinement,Declarative models,Concurrency,

@&#ABSTRACT@&#
Psi-calculi constitute a parametric framework for nominal process calculi, where constraint based process calculi and process calculi for mobility can be defined as instances. We apply here the framework of psi-calculi to provide a foundation for the exploration of declarative event-based process calculi with support for run-time refinement. We first provide a representation of the model of finite prime event structures as an instance of psi-calculi and prove that the representation respects the semantics up to concurrency diamonds and action refinement. We then proceed to give a psi-calculi representation of Dynamic Condition Response Graphs, which conservatively extends prime event structures to allow finite representations of (omega) regular finite (and infinite) behaviours and have been shown to support run-time adaptation and refinement. We end by outlining the final aim of this research, which is to explore nominal calculi for declarative, run-time adaptable mobile processes with shared resources.

@&#INTRODUCTION@&#
Software is increasingly controlling and supporting critical functions and processes in our society; from energy and transportation to finance, military and governmental processes. This makes the development of techniques for guaranteeing correctness of software systems increasingly important. At the same time, there is a growing need for the support of incremental development and adaptation of information systems, for the systems to be able to keep up with the changes in the physical and regulative context. This need is addressed in practice with the introduction of agile and continuous delivery software development methods and in theory by research in adaptable software systems and technology. Agility and adaptability, however, makes the non-trivial task of ensuring correctness of software systems even more difficult.The present work is part of a more ambitious research goal pursued in the CompArt project.33Computational Artefacts (CompArt), http://www.compart.ku.dk.The final aim is to provide a foundation for the description and formal reasoning of adaptable, distributed and mobile computational artefacts under regulative control.A number of proposals have been made for concrete formal models and reasoning techniques for distributed and mobile systems supporting different kinds of adaptability (e.g. [1–5]). The plethora of models indicates that our understanding of the needs for such agile and adaptable computational artefacts is still developing. For this reason, we aim for a foundation that facilitates experimentation with different formal process calculi. Our focus on mobility, shared resources, regulative control and adaptability leads us to consider the formal meta process calculus of psi-calculi [6]. Psi-calculi provides a general setting for the definition of process calculi for distributed and mobile processes, that generalises the seminal pi-calculus [7] in two dimensions: (i) generalisation of channel names to nominal data structures [8], i.e. general terms with a notion of local names; and (ii) a general logic for expressing constraints guarding actions. Examples of calculi encoded as psi-calculi include the spi- and applied-pi calculi [9,10] and the CC-pi [11,12].While the general nominal data structures and channel communication provide a foundation for expression of shared mobile resources, the constraint logic provides a foundation for declarative expression of control and regulations. Concretely, we show how two declarative, event-based process models for concurrency, i.e., the seminal prime event structures [13,14] and the Dynamic Condition Response (DCR) Graphs [15], can be represented as psi-calculi. We consider declarative event-based concurrent models for two reasons: Firstly, declarative models more naturally describe regulations, that is, rules governing processes. Secondly, they are well-behaved with respect to action refinement [16,17], which we see as a fundamental step towards supporting agile development and adaptation. Simply put, action refinement is the method of developing a system by starting with an abstract specification, and gradually refining its components (or actions) by providing more details. Thus an action can be changed from being instantaneous to having structure, or duration. This should not be confused with the notion of refinement often found in process algebras where an implementation refines a specification by reducing the set of execution traces.Fig. 1gives an overview of the main results from this paper. After providing the necessary background on psi-calculi in Section 2, we give a representation of model of finite prime event structures [13,14] as an instance of psi-calculi in Section 3. The encoding function espsi, illustrated by the middle horizontal arrow in Fig. 1 exploits the logic of psi-calculi to represent the causality, independence and conflict relation of event structures. This allows us to prove that the representation respects the semantics up to concurrency diamonds and action refinement [17]. Concretely, we define action refinementrefΨon theeventPsi-processes, and prove in Sec. 3.3 that also action refinement is preserved by our translation, making the upper square diagram of Fig. 1 commute.We also identify the syntactic shape of psi-processes that correspond to finite prime event structures. This last result can be seen as a characterisation of the psi-processes for which the middle arrow in Fig. 1 is one part of an equivalence.Event structures are a denotational model and cannot provide finite representations of infinite behaviours. To accommodate finite representations of infinite behaviours, we proceed in Section 4 to consider Dynamic Condition Response graphs (abbreviated DCR graphs or just DCRs) [15]. DCR graphs are an event-based model of concurrency strictly generalising event structures by permitting the events to happen more than once (as opposed to in event structures, where events happen at most once) and by refining the relations of dependency and conflict between events. This generalises event structures in two ways: Firstly, DCR graphs are a so-called system model allowing finite representations of infinite behaviours. Secondly, DCR graphs allow representation of acceptance criteria for computations, making it possible to express both safety and liveness properties. We will not consider acceptance criteria in the present paper. DCRs have been shown to support run-time adaptation [5] and have been successfully used in industry to model and support flexible and adaptable business processes for knowledge workers [18,19].As for event structures, we provide an encoding dcrpsi of DCR graphs into the psi-instancedcrPsi, shown in Fig. 1 as the lower arrow. Again we identify the syntactic shape of thosedcrPsi-processes which corresponds exactly to DCR graphs, i.e. characterises thedcrPsi-processes for which the mapping is part of an equivalence, and prove a bisimulation relation between the DCR graphs semantics and their encoding for a naturally defined event-labelled transition system semantics of the encoding.We end the section by showing that the encoding of DCR graphs indcrPsiis a conservative generalisation of the encoding of finite event structures by showing that the lower square diagram in Fig. 1 commutes, for the standard embedding dcr of event structures into DCR graphs and a suitably defined, semantics preserving embedding emb ofeventPsi-processes (corresponding to event structures) intodcrPsi-processes (corresponding to DCR graphs).We end in Section 5 by concluding and outlining the path towards the final aim of this research, which is to explore nominal calculi for declarative, run-time adaptable mobile processes with shared resources, subject to both safety and liveness regulations.This paper extends [20] by including new results, more examples, motivation and background. In particular, the background section on psi-calculi has been considerably enlarged, including more definitions, examples and intuitions. The same was done for the backgrounds on DCR graphs and event structures and refinement. The results have more detailed proofs and include new results that complete the diagram of Fig. 1 with the embedding ofeventPsiintodcrPsi, as well as the syntactic restrictions fordcrPsi-processes that make the lower arrow part of an equivalence.Psi-calculi[6] have been developed as a framework for defining nominal process calculi, like the many variants of the pi-calculus [7]. Instances of psi-calculi have been made for applied-pi calculus [10] and for CC-pi [11,12] which can in turn capture probabilistic models. Typed psi-calculi exist [21] as well as the related instance [22] for distributed pi-calculus [23,24].The psi-calculi framework is based on nominal datatypes. We assume an infinite set of atomic namesNranged over bya,b,…. Intuitively, names are symbols that can be statically scoped, as well as be subjected to substitution (which we define later). A nominal datatype is then constructed from a nominal set [8], which is a set equipped with name swapping functions, written(ab), satisfying certain natural axioms such as(ab)((ab)t)=t. Intuitively, applying the name swapping(ab)changes a term t by replacing a with b and b with a. One main point is that even without having any particular syntax for constructing t we can define what it means for a name to “occur” in a term, i.e., when the term can be affected by a swapping that involves that name. The names occurring in this way in a term t constitute the support of t, writtenn(t). In usual datatypes, without binders, we will havea∉n(t)if a does not occur syntactically in t. Whereas in the lambda calculus the support corresponds to the free names, since terms are identified up to alpha-equivalence. A function f is equivariant if(ab)f(t)=f((ab)t)holds for all t. We can then define a nominal datatype formally as follows.Definition 2.1Nominal datatypes and substitutionsA nominal datatype is a nominal set together with a set of equivariant functions on it. Psi-calculi consider substitution functions that substitute terms for names. If t is a term of a datatype,a˜is a sequence of names without duplicates, andT˜is an equally long sequence of terms of possibly different datatypes, the substitutiont[a˜:=T˜]is a term of the same datatype as t. The only formal requirements for substitutions are that a substitution is an equivariant function that satisfies two substitution laws:1.ifa˜⊆n(t)andb∈n(T˜)thenb∈n(t[a˜:=T˜])ifb˜∉n(t)andb˜∉n(a˜), thent[a˜:=T˜]=((b˜a˜)t)[b˜:=T˜].Law 1 says that a substitution does not lose names: any name b in the termsT˜that substitute the namesa˜occurring in t must also appear in the resulting term after the substitutiont[a˜:=T˜]. Law 2 is a form of alpha-conversion for substitutions, wherea˜andb˜have the same length, and(b˜a˜)swaps each name ofa˜with the corresponding name ofb˜.Definition 2.2ParametersThe psi-calculi framework is parametric; instantiating the parameters accordingly, one obtains an instance of psi-calculi, like the pi-calculus, or the cryptographic spi-calculus. These parameters are:Tterms (data/channels)CconditionsAassertionswhich are nominal datatypes not necessarily disjoint; together with the following equivariant operators:↔⋅:T×T→Cchannel equality⊗:A×A→Acomposition of assertions1∈Aminimal assertion⊢⊆A×Centailment relationThe operators are usually written infix, i.e.:M↔⋅N,Ψ⊗Ψ′,Ψ⊢φ.Intuitively, terms can be seen as generated from a signature, as in term algebras [25]. We can think of the conditions and assertions like in first-order logic: the minimal assertion being top/true, entailment the one from first-order logic, and composition taken as conjunction. It is helpful to think of assertions and conditions as logical formulas, and the entailment relation as an entailment in logic; but allow the intuition to think of logics abstractly, not just propositional logic, so that assertions and conditions are used to express any logical statements, where the entailment defines when assertions entail conditions (do not restrict to only thinking of truth tables; e.g., in our encodings we will use an extended logic for sets, with membership, pairs, etc.). The intuition of entailment is thatΨ⊢φmeans that given the information in Ψ, it is possible to infer φ. Two assertions are equivalent if they entail the same conditions.Definition 2.3Assertion equivalenceTwo assertions are equivalent, writtenΨ≃Ψ′, iff for all φ we have thatΨ⊢φ⇔Ψ′⊢φ.The above operators need to obey some natural requirements, when instantiated.Definition 2.4Requisites on valid psi-calculus parametersThe following properties must be satisfied by any psi-instance.Channel Symmetry:Ψ⊢M↔⋅N⟹Ψ⊢N↔⋅MChannel Transitivity:Ψ⊢M↔⋅N∧Ψ⊢N↔⋅L⟹Ψ⊢M↔⋅LCompositionality:Ψ≃Ψ′⟹Ψ⊗Ψ″≃Ψ′⊗Ψ″Identity:Ψ⊗1≃ΨAssociativity:(Ψ⊗Ψ′)⊗Ψ″≃Ψ⊗(Ψ′⊗Ψ″)Commutativity:Ψ⊗Ψ′≃Ψ′⊗ΨChannel equality is a partial equivalence which means that there can be terms that are not equivalent with anything (not even themselves). This does not allow them to be used as channels (but only as data). The composition of assertions (wrt. assertion equivalence) must be associative, commutative, and have 1 as unit; moreover, composition must preserve equivalence of assertions.44Note that idempotence (Ψ⊗Ψ≃Ψ) is not required from the composition operation, meaning that logics to represent resources, like linear logic, can be captured through the assertions language.,55Note also that weakening (Ψ⊢φ⇒Ψ⊗Ψ′⊢φ) is not required, meaning that non-monotonic logics could be captured as well.The intuition is that assertions will be used to capture assumptions about the environment of the processes. Conditions will be used as guards for guarded (non-deterministic) choices, and are to be tested against the assertion of the environment for entailment. Terms are used to represent complex data communicated through channels, but will also be used to define the channels themselves, which can thus be more than just mere names, as is the in pi-calculus. The composition of assertions should capture the notion of combining assumptions from several components of the environment.Definition 2.5SyntaxThe syntax for building psi-processes is the following (psi-processes are denoted byP,Q,…; terms from T byM,N,…):0Empty/trivial processM‾〈N〉.POutputM_〈(λx˜)N〉.PInputcaseφ1:P1,…,φn:PnConditional (non-deterministic) choice(νa)PRestriction of nameainside processesPP∥QParallel composition!PReplication⦇Ψ⦈Assertion processeswherex˜is a sequence of variable names bound in the object term N,φi∈Care conditions, a is a name possibly appearing in P, andΨ∈Ais an assertion.The input and output processes are as in pi-calculus except that the channel objects M can be arbitrary terms. In the input process the object(λx˜)Nis a pattern with the variablesx˜bound in N as well as in the continuation process P.66Note the use of λ as a syntactic binder denoting patterns of terms, and the use of the standard π-calculus restriction operation on names ν. The use of λ is only in the input terms.Intuitively, any term message received on M must match the pattern N for some substitution of the variablesx˜. The same substitution is used to substitute these variables in P after a successful match. The traditional pi-calculus inputa(x).Pwould be modelled in psi-calculi asa_〈(λx)x〉.P, where the names are the only terms allowed. Restriction, parallel composition, and replication are the standard constructs of pi-calculus.The case process behaves like one of thePifor which the conditionφiis entailed by the current environment assumption, as defined by the notion of frame which we present later. Frames are familiar from the applied pi-calculus [10], where were introduced with the purpose of capturing static information about the environment (or seen in reverse, the frame is the static information that the current process exposes to the environment). Particular examples of using the case construct are:1.caseφ:Pwhich can be read asifφthenP;case⊤:P1,⊤:P2, where ⊤ would be any condition that is entailed by all assertions (likea↔⋅ain pi-calculus); this use is mimicking the pi-calculus non-deterministic choiceP1+P2.Remark 2.6Psi-calculi work with finite terms and processes. Therefore, we restrict our further investigations to finite event structures and DCRs. To handle event structure over an infinite set of events one needs to investigate extensions of psi-calculi with three forms of infinity:1.Infinite summation, which is sometimes found in process algebras, e.g., in Milner's SCCS [26]. In the case of psi-calculi an infinite case construct can be written ascaseφi˜:Pi˜where infinite lists are used to represent the respective condition/process pairs. No significant changes to the semantics would be needed.Infinite parallel composition could use the same semantic rule as for the finite case, but care needs to be taken with the required notions of frame and entailment. Often the replication is the preferred way to obtain infinite parallel components.Infinite nominal data structures, where works into infinite terms would be a starting point.Assertion processes⦇Ψ⦈can float freely in a process (i.e., through parallel compositions) thus describing assumptions about the environment. Otherwise, assertions can appear at the end of a sequence of input/output actions, i.e., these are the guarantees that a process provides after it makes an action (on the same lines as in assume/guarantee reasoning about programs). Assertion processes are somehow similar to the active substitutions of the applied pi-calculus, except that assertions do not have computational behaviour, but only restrict the behaviour of the other constructs by providing their assumptions about the environment.Example 2.7Pi-calculus as an instanceTo obtain pi-calculus [7] as an instance of psi-calculi use the following, built over a single set of namesN:T=▵NC=▵{a=b|a,b∈T}A=▵{1}↔⋅=▵=⊢=▵{(1,a=a)|a∈T}with the trivial definition for the composition operation. The only terms are the channel namesa∈N, and there is no other assertion than the unit. The conditions are equality tests for channel names, where the only successful tests are those where the names are equal. Hence, channel comparison is defined as just name equality.Example 2.8From the instance created in Example 2.7 one can obtain the polyadic pi-calculus [27] by adding tupling symbolstnfor tuples of arity n to T, i.e.T=N∪{tn(M1,…,Mn):M1,…Mn∈T}.The polyadic output is to simply output the corresponding tuple of object names, and the polyadic inputa(b1,…,bn).Pis represented by a pattern matchinga_(λb1,…bn)tn(b1,…,bn).P.Strictly speaking this allows nested tuples as well as tuples in the subject position of inputs and outputs. But these do not give rise to transitions because the definition of channel equality only applies to channel names, thusM↔⋅Mcan be entailed by an assertion only when M is a name.Psi-calculi are given an operational semantics in [6] using labelled transition systems, where the states are the process terms and the transitions represent one reduction step, labelled with the action that the process executes. The actions, generally denoted byα,β, represent respectively the input and output constructions, as well as τ the internal synchronisation/communication action:M‾〈(νa˜)N〉|M_〈N〉|τThe restriction operator ν binds the namesa˜in N. We will denote bybn(α)the set of bound names in a communication term; i.e.,bn(M‾〈(νa˜)N〉)=a˜.Transitions are done in a context, which is represented as an assertion Ψ, capturing assumptions about the environment:Ψ▷P→αP′Intuitively, the above transition could be read as: The process P can perform an action α in an environment respecting the assumptions in Ψ, after which it would behave like the processP′.The environment assertion is obtained using the notion of frame which essentially collects (using the composition operation) the outer-most assertions of a process. A frame also keeps the information about the restrictions under which the assertion processes are found.Definition 2.9FrameA frame is of the form(νb˜)Ψwhereb˜is a sequence of names that bind into the assertion Ψ. We write just Ψ for(νϵ)Ψwhen there is no risk of confusing a frame with an assertion. We identify alpha variants of frames. In consequence, composition of frames is defined by(νb1˜)Ψ1⊗(νb2˜)Ψ2=(νb1˜b2˜)Ψ1⊗Ψ2whereb1˜∉n(b2˜,Ψ2)and vice versa. The frame of a processF(P)is defined inductively on the structure of the process as:F(⦇Ψ⦈)=ΨF(P∥Q)=F(P)⊗F(Q)F((νa)P)=(νa)F(P)F(!P)=F(caseφ˜:P˜)=F(M‾〈N〉.P)=F(M_〈(λx˜)N〉.P)=1Any assertion that occurs under an action prefix or a condition is not visible in the frame.Example 2.10Calculating the frame of the following process, whena∉n(Ψ1), is:F(⦇Ψ1⦈∥(νa)(⦇Ψ2⦈∥M‾〈N〉.⦇Ψ3⦈))=Ψ1⊗(νa)Ψ2=(νa)(Ψ1⊗Ψ2).HereΨ3occurs under a prefix and is therefore not included in the frame. An agent where all assertions are guarded thus has a frame equivalent to 1. Because frames are considered equivalent up to alpha-conversion, proper renaming allows to move restriction operators(νa), as exemplified here.Definition 2.11SemanticsThe transition rules for psi-calculi are the following, where the symmetric rules for (par) and (com) are elided.In the (com) rule the assertionsΨPandΨQcome from the frames ofF(P)=(νb˜P)ΨPrespectivelyF(Q)=(νb˜Q)ΨQand it is assumed thatb˜Pis fresh for all ofΨ,b˜Q,Q,Mand P, and respectively forb˜Q.There is no transition rule for the assertion process; this is only used in constructing frames. Once an assertion process is reached, the computation stops, and this assertion remains floating among the other parallel processes and will be composed part of the frames, when necessary, like in the case of the communication rule. The empty process has the same behaviour as, and thus can be modelled by, the trivial assertion process⦇1⦈.The (in) rule makes transitions labelled with any channel term K equivalent to the input channel M, and for any substitution replacing the variablesy˜by term valuesL˜in the (pattern) term N. The input rule is open to any possible matching outputs, where the (com) rule will pair any of the exact matchings. The (out) rule just outputs the term N on some equivalent channel term K.In (open) the expressiona˜∪{b}means the sequencea˜with b inserted anywhere.The communication rule (com) shows how the environment processes executing in parallel contribute their top-most assertions to make the new context assertion for the input/output action of the other parallel process. The (com) rule requires that for a synchronisation to happen the channels in the transition labels for the input and output processes must be equivalent.The (case) rule shows how the conditions are tested against the context assertions. From all the entailed conditions one is non-deterministically chosen as the continuation branch.The (par) rule allows a component P in a parallel process to do an α transition toP′as long as the bound names of the transition label are not captured by the environment process Q, i.e., when the bound names of α are fresh in Q (bn(α)∩n(Q)=∅). Moreover, for the frameF(Q)=(νb˜Q)ΨQit is assumed thatb˜Qis fresh forΨ,Pand α.The (scope) rule can be applied only when b is fresh in both α and the assertion that the process is executed with.The (rep) rule is standard from pi-calculi.Example 2.12For a simple example of a transition, suppose for an assertion Ψ and a condition φ thatΨ⊢φ. Also assume that∀Ψ′.Ψ′▷Q→αQ′i.e., Q has an action α regardless of the environment. Then by the (case) rule we getΨ▷caseφ:Q→αQ′i.e.,caseφ:Qhas the same transition if the environment is Ψ. SinceF(⦇Ψ⦈)=ΨandΨ⊗1we get by (par) that1▷⦇Ψ⦈∥caseφ:Q→α⦇Ψ⦈∥Q′.A more detailed introduction to nominal sets used in psi-calculi can be found in [6, Sec. 2.1] and the recent book [8] contains a thorough treatment of both the theory behind nominal sets as well as various applications, e.g., see [8, Ch. 8] for nominal algebraic datatypes. For our presentation here we expect only some familiarity with notions of algebraic datatypes and term algebras. In the following we briefly present the notion of terms that we will be using in our encodings in the rest of the paper.Definition 2.13Terms, cf. [25, Chap. 3.1]In universal algebra, terms are constructed from a signatureFof function names of some arity, and a set of variablesX, and are denotedt∈T(F,X). Function symbols of arity 0 are called constants. Function symbols are sometimes denoted asf(_)orf(_,_)to emphasise their arity (i.e., number of arguments, respectively one and two in this example). Terms without variables are called ground, their set being denoted byT(F), whereas terms containing variables are sometimes called open, to emphasise this aspect (in consequence, some works call ground terms closed). Every variable is also a term, i.e., an open term.One could see an intuitive association between variables and names, since in nominal datatypes names can be subject to substitutions, the same as variables in open terms. Though names have other properties, as we have seen, like bindings or alpha conversion.Example 2.14Natural numbers as ground termsThe set of natural numbers can be seen as terms denoted byNand defined asT({s(_),0}), i.e., only ground terms, built from the single constant term 0 using the unary successor function. An example of the term representing number 3 iss(s(s(0))).Definition 2.15Multi-sorted terms, cf. [28]A multi-sorted algebraic structure is obtained if we add a notion of sorts to the Definition 2.13. Consider a set of sortss∈Swith a partial order on them, e.g.,s1<s2means that any term of sorts1is also of sorts2. Assign to each function symbolf∈Fa sort for each parameter and a sort for output; e.g.,f:s1,…,sn→stakes n arguments of the respective sorts. In particular, each constant symbol is of some sort. One function can now be applied only to terms of the appropriate sort, to produce a term of the respective result sort. The set of variables is now partitioned into sorted variables, i.e., each variable is of a certain sort. We sometimes mention the set of sorts asT(F,X,S)when we want to be specific; but most of the time we rely on the context for disambiguation.Definition 2.16Equality of termsEquations can be defined between terms,tl=tr, to express which terms should be viewed as equal. Equations are usually defined between open terms and are closed under substitutions, meaning that any two terms obtained by applying the same substitution to both t andt′would also be considered equal. For some set of equations, we infer the equality of two terms by applying the inference rules of equational logic, i.e., identity, symmetry, transitivity, closure under function application and under substitutions.Example 2.17Multi-sets as ground multi-sorted termsOne representation of sets can be given as terms built over two sortsS={el,set}using constant symbolseiof sort el and constant symbol ∅ of sort set, and using a multi-sorted concatenation operation_el:_setwhich takes the first argument of sort el and the second argument of sort set. An example ise1:(e2:(e3:∅)). Because elements can appear several times in a concatenation, we have just modelled multi-sets. All multi-sets over someei∈Eare denoted byNE. With standard equations one could treat the multi-set terms with duplicate elements as equal to terms with a single copy of the element so that, e.g.,e1:(e1:∅)would be equal toe1:∅. Examples of equations of relevance to this case are: commutativity in multi-sets could bee1:(e2:x)=e2:(e1:x), whereas an annihilation equation would bee1:(e1:x)=e1:x. We denote all the terms capturing sets over some E of constant symbols by2E.77Note that to model infinite sets we would need infinite terms in the above term encoding.Example 2.18Natural numbers with operationsWhen interested in operations on natural numbers we could build a term algebraNopfromNof Example 2.14 by adding operators and equations related to the operators, as well as variables. Consider two sortsS={g,op}and have all ground terms from Example 2.14 to be of sort g, i.e., put the constant 0 and the successor function to be of sort g. Take the orderg<op, saying that any ground number g is also a number term with operations. Now define any operations, like_+_or_−_, to be of sort op, i.e., taking as input op terms and returning op terms. Put the standard definition of such an operator into equations, e.g.:s(0)+x=s(x). One can also put as equations the standard properties of such operators, like commutativity. So in our exampleNop=({s,0,+,−},X,S). The sorts have been used just to make the representation nicer, i.e., having the natural numbers as building blocks on which the operations work. But in the presence of equations we can safely do without sorts; we will just have the successor function possibly applied to an operation likes(s(0)+s(s(0))).With such a definition of natural numbers with operations as terms, we can then work with them as usual in mathematical proofs, but also as terms when the psi-calculi rigour requires it. In particular, when using a proof assistant, as is customarily done when making meta-proofs for psi-calculi, we would need to select an appropriate package to work with natural numbers, and with sets and multi-sets. These packages would be using encodings on the lines described above, to every detail. For this paper we stick to the well-known intuitive notations for natural numbers and multi-sets.Example 2.19Multi-sets with operationsTake the sets and multi-sets of Example 2.17 and add functional symbols for standard operations like:_∪_,_∖_,_+_(the last one standing for summation of multi-sets). Consider the definitions of these operations in the equations; for examplee1:e2:∅∪e3:∅=e1:e2:e3:∅. VariablesXare included as well. We could also add sorts for ground sets and sets with operators, as we did in the previous example. We denote such sets and multi-sets with operators and variables over some E by2opE=({:,∅,∪,∖},X)andNopE=({:,∅,+,−},X).Many times data structures used in computer science are multi-sorted, and thinking in terms of sorts makes our results easier to follow. Therefore, we give a few definitions for sorts in the case when names are present. Complete treatment can be found in references like [8,29–31].Definition 2.20Multi-sorted nominal datatypes, cf. [8, ch. 8] or [29]Consider a set of name sortsSNdisjoint from the set of sorts used for the datastructures, which we will call data sorts and denoteSD. Each name is assigned a name sort, the same as we were doing for variables. Name swapping is now sort-respecting in the sense that the two names being swapped must have the same name sort. In consequence, freshness and name abstraction are also sort-respecting (see [8, ch. 4.7]). Nominal datastructures are built over sorts described using the following grammar:S::=SN|SD|1|SN:S|(S,S)This basically describes binding sorts and pairs (and thus tuples) sorts. Functions are defined asf:S→SDalways returning a data sort. Terms are built respecting the sorting, including information about name binding.Our use of sorts in psi-calculi is rather simplistic, mainly to make sure that the right kind of terms are being used in the right place; e.g., when receiving data on a channel. We prefer to minimise mentioning sorting aspects, as for our results these details would mean too much cluttering without gained insights or correctness concerns. Nevertheless, when strictness is necessary, like when working with a proof assistant, then all details of the sorting should be in place, and the methods described in [30,31] should be followed. We give here a brief definition of some main aspects of sorted psi-calculi.Definition 2.21Sorted psi-calculi, [30, sec. 2.4]Multi-sorted psi-calculi use two main notions on top of multi-sorted nominal datatypes:sorts for channelsspecify for each sort (designating terms that can be the subject of a channel) the sort of terms (objects) that can be send/received on that channel;need to know which sorts (of terms) can substitute which sorts of names; i.e., a relation<sub⊆SN×S. The relation on sorts from Definition 2.15 is respected in the sense that ifa<subs2ands1<s2thena<subs1.In our work we rely on sorts to give some discipline in building psi-terms without cluttering unnecessarily the notation. Sorts are intuitive and we will abuse the notation and rely on the context and intuition to disambiguate. Here are a few examples of our simple way of using sorts in the psi-instances that we will define.Example 2.22Simple use of sorts in psi-instancesOften a function like pairing is multi-sorted,(_,_):s1×s2→s3. The left parameter may be of sort natural numbers whereas the right parameter may be a multiset; everything could be considered of sort pairs. We would like to allow names to be used as parameters, and these names could be replaced upon a psi-communication. In this case we just say that the names must be of sort natural number and multiset. In consequence, the substitutions to respect the sorts should replace the name on the left only with natural number terms and the name on the right only with multisets.In this section we provide a psi-calculus representation of finite prime event structures (recalled in Definition 3.1).It is fairly easy to represent the interleaving, transition semantics for a finite event structure as a psi-calculus term. However, in contrast to most process calculi, event structures and more expressive event-based models of concurrency [32–39] come with a non-interleaving semantics. A non-interleaving semantics makes it possible to distinguish between interleaving and independence (sometimes called “true” concurrency) and are well behaved wrt. action refinement [17]. A simple example is given by two concurrent processes executing each a different instance of the same action a. An interleaving transition system based model would represent such a process by an “interleaving” diamond with all four sides labelled by the same action, which semantically typically would be equal to the sequential compositiona.aof the two actions. Refining the action a intoa1.a2in the semantical model, would thus result in the single sequencea1.a2.a1.a2as the possible behaviour. However, when refining the parallel composition of two concurrent processes that both executes a, one would expect all possible interleavings, that is, the two different behaviours{a1.a2.a1.a2,a1.a1.a2.a2}.The encoding of finite prime event structures into the instance of psi-calculi, which we calleventPsi, not only preserves the behaviour of event structures up to interleaving diamonds, but it also preserves the causal structure by exploiting the assertions and conditions of psi-calculi, and as a consequence is also compatible with action refinement.We show in the subsequent section that this idea can be generalised to DCR graphs, and we believe that also other generalised versions of event structures [14,36] can be represented as psi-calculi following a similar approach as presented here.We follow the standard notation and terminology from [40, sec. 8].Definition 3.1Prime event structuresA labelled prime event structure over alphabet Act is a tupleE=(E,≤,♯,l)where E is a possibly infinite set of events,≤⊆E×Eis a partial order (the causality relation) satisfying1.the principle of finite causes, i.e.:∀e∈E:{d∈E|d≤e}is finite,the principle of conflict heredity, i.e.,∀d,e,f∈E:d≤e∧d♯f⇒e♯fIntuitively, a prime event structure models a concurrent system by takingd≤eto mean that event d is a prerequisite of event e, i.e., event e cannot happen before event d has been done. A conflictd♯esays that events d and e cannot both happen in the same run. Compared to other models of concurrency like process algebras, event structures model systems by looking only at their events, and how these events relate to each other. The two basic relations considered by event structures are the dependency and the conflict relations. The conflict relation can be used to capture choices made by the system, since the execution of one event discards all other events in conflict with itself for the rest of the computation.Labels can be understood as actions, with a wide and general meaning. Events are instances of actions, and an action can happen several times, thus as different events. The same action can also happen in different components running in parallel, giving rise to autoconcurrency, as exemplified in the beginning of this section. Actions are important for observational equivalence, but not only them (see Example 3.5).Example 3.2In Fig. 2we pictured four simple examples of finite event structures (taken from [41, Fig. 4]). We illustrate events as boxes containing their labels, the dependency relation by arrows, and the conflict relation by dashed lines with a ♯ sign. In the left-most event structure we have three events, where the events labelled b and c depend on the event labelled a and are in conflict with each other. This is a standard branching point which could be specified in a simple CCS notation asa;(b+c). In the second event structure we have two (conflicting) events, both labelled with a, and two events labelled b and c which depend on the first and the second a-labelled event respectively. Because of the principle of conflict hereditary, b is in conflict with the lower a-labelled event and similarly, c is in conflict with the upper a-labelled event (but the conflict relations are in this case usually not explicitly illustrated). In CCS notation this could bea;b+a;c. In the third event structure we have just two events without any explicit or inherited relation, which means that they are concurrent (e.g.,a‖b), as made precise below. The last event structure is similar to the second, except that it offers two conflicting paths with the label a followed by b or b followed by a respectively.Definition 3.3ConcurrencyCausal independence (concurrency) between events is defined in terms of the above two relations asd‖e=▵¬(d≤e∨e≤d∨d♯e).This definition captures the intuition that two events are concurrent when there is no causal dependence between the two and, moreover, they are not in conflict.From the definition it follows that only the two events in the third event structure in Fig. 2 are concurrent.The behaviour of an event structure is described by subsets of events that happened in some (partial) run of the system being modelled. This is called a configuration of the event structure, and steps can be defined between configurations.Definition 3.4ConfigurationsDefine a configuration of an event structureE=(E,≤,♯)to be a finite subset of eventsC⊆Ethat respects:1.conflict-freeness:∀e,e′∈C:¬(e♯e′)and,downwards-closure:∀e,e′∈E:e′≤e∧e∈C⇒e′∈C.Conflict-freeness is saying that no two conflicting events can happen in one run. This also says that once an event is discarded it can never be executed on the current run. This is similar to how the semantics of the choice operator in process algebras is defined (see rule (case) in Section 2) where all other branches of the choice are discarded once a step is taken. The downwards-closure says that all the dependencies of an executed event (i.e., which is part of a configuration) must have been executed also (on this same run).Note in particular that ∅ is a configuration (i.e., the root configuration) and that any set⌈e⌉=▵{e′∈E|e′≤e}is also a configuration determined by the single event e. Events determine steps between configurations in the sense thatC→eC′wheneverC,C′are configurations,e∉C, andC′=C∪{e}.Example 3.5For the examples from Fig. 2 we get the configurations and steps depicted in Fig. 3.One may note that if only the paths of labels are observed, the two first event structures are indistinguishable, but if the branching structure is observed, i.e. by a bisimulation equivalence, they are distinguishable. One may also note that if the paths of labels are observed and even if branching time is observed, the two latter event structures are indistinguishable, but if concurrency is observed, i.e. by a history-preserving bisimulation equivalence [42,17], they are distinguishable.Remark 3.6It is known (see e.g., [40, Prop. 18]) that prime event structures are fully determined by their sets of configurations, i.e., the relations of causality, conflict, and concurrency can be recovered only from the set of configurationsCEas follows:1.e≤e′iff∀C∈CE:e′∈C⇒e∈C;e♯e′iff∀C∈CE:¬(e∈C∧e′∈C);e‖e′iff∃C,C′∈CE:e∈C∧e′∉C∧e′∈C′∧e∉C′∧C∪C′∈CE.It is also known (see e.g., [40, Sec. 8] for prime event structures or [17, Sec. 4] for the more general event structures of [14]) that there is no loss of expressiveness when working with finite, instead of infinite configurations. An infinite configuration can be obtained from infinite union of finite configurations coming from an infinite run.For some event e we denote by≤e={e′∈E|e′≤e}the set of all events which are conditions of e (which is the same as the notation⌈e⌉from [40], but we prefer to use the above so to be more consistent with similar notations we use in the rest of this paper for similar sets defined for DCRs too), and♯e={e′∈E|e′♯e}those events in conflict with e. We denote by<e=≤e∖{e}the non-trivial conditions of e, i.e., excluding itself.In this section we provide an encoding of finite prime event structures into an instance of psi-calculi which we calleventPsi. We consider finite event structures only, since it is not the goal of our work to represent denotational models. Moreover, the direct encoding we are aiming for of event structures with infinite sets of events would require a treatment in psi-calculi of infinite parallel composition, infinite terms, frame definition, and careful look at the SOS rules which use entailment among infinite assertion and condition terms. Such a treatment is beyond the scope of the paper. We will instead see in the next section how to encode an event-based model generalising event structures to allow finite representations of infinite behaviour.The intuition of the encoding is to represent event structure configurations as assertions and the causality and conflict relations as conditions. We do this by taking assertions A to be sets of events representing the history of executed events, i.e. a configuration, and composition just set union. Conditions C are taken to be pairs(p,c)of sets of events and entailment relation is then defined such that p represents the preconditions of an event, i.e. ≤e, and c represents the conflict set, i.e. ♯e. That is, an assertion (history of executed events) Ψ entails a condition(p,c)if and only ifp⊆Ψ(the preconditions have been executed) andc∩Ψ=∅(none of the conflicting events have been executed). Finally, we take the set of terms T to be simply a set of constants representing the events. To keep the exposition simple, we will ignore event labels until Section 3.3, where we treat action refinement. But labels could easily be added by redefining the terms to be pairs of an event and its label, for some given labelling function; e.g.,(e,l(e)).Definition 3.7Event psi-calculus over EWe define a psi-calculus instance, calledeventPsi, parametrised by a set E of constant symbols, to be understood as events, by providing the following definitions of the key elements of a psi-calculus instance:T=defEC=def(2E×2E)∪{e↔⋅f|e,f∈T}A=def2E⊗=def∪1=def∅⊢=def{Ψ⊢(D,C)iff(D⊆Ψ)∧(C∩Ψ=∅)Ψ⊢e↔⋅fiffe=fwhere T, C, and A are algebraic data types built over the constants in E.It is easy to see that our definitions respect the restrictions of making a psi-calculus instance. In particular, channel equivalence is symmetric and transitive since equality is. The ⊗ is compositional, associative and commutative, as ∪ is; and moreover∅∪S=S, for any set S, i.e., 1 is the identity for ⊗.Remark 3.8We are not using the nominal aspects of psi-calculi. Throughout the rest of this section we do not work with names, and therefore the support of all terms will be empty. Names will make their appearance in the encoding of DCRs in Section 4.We are now ready to provide the encoding espsi which maps a finite prime event structure and a configuration to aneventPsi-process. TheeventPsi-process is defined as a parallel composition of atomic “event processes”. These come in two forms: The first, defined simply as an assertion process, corresponds to events in the configuration of the translated event structure (i.e., those that already happened). The latter corresponds to events that have not happened yet and are defined using the case construct with a conditionφe=(p,c)wherep=<e, i.e. the preconditions of the event e, andc=♯eis the set of events that e is in conflict with. The definition of entailment then ensures that the case process can execute if and only if the event is enabled, and if it executes, the event is asserted, thereby updating the configuration. To easily observe which event happened, we also communicate the event e on the channel e.Definition 3.9Event structures toeventPsiForE=(E,≤,♯)an event structure and a configuration C ofE, defineespsi(E,C)asespsi(E,C)=∥e∈EPewithPe={⦇{e}⦈ife∈Ccaseφe:e‾〈e〉.⦇{e}⦈otherwisewhereφe=(<e,♯e). If the configuration is empty we will allow writingespsi(E)forespsi(E,∅).We often use the product notation in situations as above, i.e.,∏e∈EPeto mean the parallel composition of thePeprocesses.We have seen that theeventPsi-processes that we obtain from event structures in Definition 3.9 have a specific syntactic form. But theeventPsiinstance allows any process term to be constructed over the three nominal data-types that we gave in Definition 3.7. Below we give the syntactic restrictions oneventPsi-process terms corresponding to event structures, via the mapping defined by Theorem 3.19.Definition 3.10Syntactic restrictions foreventPsiWe define aneventPsi-process to be syntactically correct if it is constructed using the grammar:PES:=⦇{e}⦈|caseφ:e‾〈e〉.⦇{e}⦈|PES∥PESand moreover, it respects the following constraints, for anyφe,φe′fromcaseφe:e‾〈e〉.⦇{e}⦈respectivelycaseφe′:e′‾〈e′〉.⦇{e′}⦈:1.conflict: (i)e∉πR(φe)and (ii)e′∈πR(φe)⇔e∈πR(φe′);causality: (i)e∉πL(φe)and (ii)e∈πL(φe′)⇒(e′∉πL(φe)∧πL(φe)⊂πL(φe′));executed events: for any e,PESwill have at most one of⦇{e}⦈orcaseφ:e‾〈e〉.⦇{e}⦈.To justify for the last restriction assume having⦇{e}⦈∥caseφe:e‾〈e〉.⦇{e}⦈part ofPES. This would say that e has already happened and at the same time e can happen in future when the case condition holds. This cannot be in event structures, and thus needs to be ruled out.Definition 3.11Event transitionsWe define transitions between syntactically correcteventPsiprocesses P andP′to beP⇝eP′iff1▷P→e‾eP′.Remark 3.12ArbitraryeventPsi-processes can have different kinds of labelled transitions, but for syntactically correct processes the restrictions guarantee that only event transitions exist.Lemma 3.13For a syntactically correcteventPsiprocess P and a transitionP⇝eP′thenP′is also syntactically correct.ProofHavingP⇝eP′, we know from the transition rules of psi-calculi, and the syntactic restrictions of Definition 3.10 thatP=caseφ:e‾〈e〉.⦇{e}⦈∥Qwhere Q is syntactically correct and does not contain another (case or assertion process)Pe′, i.e., indexed by the same e. Recall that ∅ is the unit assertion 1, and that the minimal process 0 is equivalent with the⦇∅⦈, which can be in place of Q so that the parallel composition ends. The transition thus iscaseφ:e‾〈e〉.⦇{e}⦈∥Q⇝e⦇{e}⦈∥Q=P′.As we know that Q is syntactically correct and it does not contain anotherPe′then⦇{e}⦈∥Q=P′is also syntactically correct.  □Lemma 3.14Correspondence configuration—frameFor any event structureEand configuration C, the frame of theeventPsi-processespsi(E,C)is the same as the configuration C.ProofDenoteespsi(E,C)=PECdefined as in Definition 3.9. The frame ofPECis the composition with ⊗ of the frames ofPefore∈E. AsPeis either⦇{e}⦈ife∈Corcaseφe:e‾〈e〉.⦇{e}⦈then the frame ofPewould be eitherF(⦇{e}⦈)={e}orF(caseφe:e‾〈e〉.⦇{e}⦈)=1=∅. Thus the frame ofPEis the union of ∅ and all events in C.  □Lemma 3.15Transitions are preservedFor any event structureEand any of its configurations C, any transition from this configurationC→eC′is matched by a transitionespsi(E,C)⇝eespsi(E,C′)in the correspondingeventPsi-process.ProofBy Lemma 3.14 the frame ofespsi(E,C)is the same as C. The assumption of the lemma, i.e., the existence of the step between configurations, implies that e is enabled by the configuration C. This means thate∉C, which implies by Definition 3.9 thatespsi(E,C)=caseφe:e‾〈e〉.⦇{e}⦈∥Q. This implies thatF(espsi(E,C))=1⊗F(Q)=C, withe∉C, meaning thatF(Q)=C. Moreover, since C enables e it means that all <e are in C and no ♯e is in C, which is the definition of entailment relation ineventPsi, i.e.,F(espsi(E,C))⊢φe, which enables the step fromespsi(E,C)that the lemma expects. Afterespsi(E,C)⇝eP′we haveP′=⦇{e}⦈∥QandF(P′)=F(⦇{e}⦈)⊗F(Q)={e}∪C=C′. From the definition of the translation function espsi it is easy to see thatespsi(E,C′)=⦇{e}⦈∥Q.  □Lemma 3.16Transitions are reflectedFor an event structureEand a configuration C, any transitionespsi(E,C)⇝eP′is matched by a stepC→eC′, withP′=espsi(E,C′).ProofWe know that forespsi(E,C)to have a transition labelled with e it must be of the formespsi(E,C)=Pe∥QwherePe=caseφe:e‾〈e〉.⦇{e}⦈, withφe=(<e,♯e). We know from Lemma 3.14 that the frame ofespsi(E,C)is the assertion corresponding to C, which isF(Pe∥Q)=1⊗ΨQ=ΨQ. For the transition e to be enabled we also know from Definition 3.7 that<e⊆ΨQand♯e∩ΨQ=∅. From howφeis created in the Definition 3.9 we know that e must be enabled in(E,C). Therefore, we have the transition(E,C)→e(E,C′), whereC′={e}∪C.After a transitionPe∥Q⇝e⦇{e}⦈∥Qwe have that the new frame of the process is{e}∪ΨQ. From Definition 3.9 we see thatespsi(E,C′)would create aneventPsi-process where all but the sub-process for e will be the same as forespsi(E,C), and the sub-processPewill be⦇{e}⦈instead ofcaseφe:e‾〈e〉.⦇{e}⦈. This is the same process that we got after the transition ineventPsi.  □Theorem 3.17Preserving interleaving diamondsFor an event structureE=(E,≤,♯)with two concurrent eventse‖e′, then in the translationespsi(E,∅)we find the behaviour forming the interleaving diamond, i.e., there exists a C s.t.espsi(E,C)⇝eP1⇝e′P2andespsi(E,C)⇝e′P3⇝eP2.ProofIn a prime event structure if two eventse,e′are concurrent then there exists a configuration C reachable from the root which contains the conditions of both events, i.e.,<e⊆Cand<e′⊆C, and does not contain any of the two events, i.e.,e,e′∉C. This can be seen from Remark 3.6(3) which ensures the existence of some configurationsC1,C2, andC1∪C2, which contains bothe,e′. Removing from this last configuration bothe,e′we still obtain a configuration. Take this configuration as the one C sought in the theorem. Therefore we have the following steps in the event structure:C→eC∪{e},C→e′C∪{e′},C∪{e}→e′C∪{e,e′}, andC∪{e′}→eC∪{e,e′}.Since C is reachable from the root then by Lemma 3.15 all the steps are preserved in the behaviour of theeventPsi-processespsi(E,∅), meaning thatespsi(E,C)is reachable from (i.e., part of the behaviour of)espsi(E,∅).Sincee,e′∉Cwe have thatespsi(E,C)is in the formP0=Pe∥Pe′∥QwithPeandPe′processes of kind case. From Lemma 3.14 we know that the frame ofespsi(E,C)is the assertion corresponding to C, which isF(Pe∥Pe′∥Q)=∅∪∅∪ΨQ=ΨQ.From Lemma 3.15 we see the transitions between theeventPsi-processes:espsi(E,C)⇝eP1⇝e′P2withP2=⦇{e}⦈∥⦇{e′}⦈∥Qas well asespsi(E,C)⇝e′P3⇝eP4withP4=⦇{e}⦈∥⦇{e′}⦈∥Q. We thus have the expected interleaving diamond.As an aside, remark thatF(P1)=F(P0)⊗{e}andF(P3)=F(P0)⊗{e′}thusF(P1)⊗F(P3)=F(P0)⊗{e}⊗{e′}=F(P4), which says thate∈F(P1)∧e′∉F(P1)∧e′∈F(P3)∧e∉F(P3)∧F(P1)⊗F(P3)=F(P4). Using Lemma 3.14 these can be correlated with configurations and thus we can see the definition of concurrency from configurations as in Remark 3.6(3).  □Intuitively the next result says that any two events that in the behaviour of theeventPsi-process make up the interleaving diamond are concurrent in the corresponding event structure.Theorem 3.18Reflecting interleaving diamondsFor any event structureE, in the correspondingeventPsi-processespsi(E,∅), for any interleaving diamondespsi(E,C)⇝eP1⇝e′P2andespsi(E,C)⇝e′P3⇝eP2for some configurationC∈CE, we have that the eventse‖e′are concurrent inE.ProofSinceespsi(E,C)has two outgoing transitions labelled with the events e ande′it means thatespsi(E,C)is in the formP0=Pe∥Pe′∥QwithPeandPe′processes of kind case. From Lemma 3.14 we know that the frame ofespsi(E,C)is the assertion corresponding to C, which isF(Pe∥Pe′∥Q)=∅∪∅∪F(Q)=ΨQ.We thus have thate,e′∉ΨQandP0⇝eP1andP0⇝e′P3. This means that for these two transitions to be possible it must be that the precondition for e ande′respectively must be met. Sincee,e′∉ΨQit must be thate′∉πL(φe)ande∉πL(φe′). SinceπL(φe)is the same as the set <e andπL(φe′)the set<e′we have the two parts of the Definition 3.3 that concern ≤ for the causal independence (concurrency) of the eventse,e′, i.e.,¬(e′≤e∨e≤e′). After the two transitions are taken we have thatP1=⦇{e}⦈∥Pe′∥QandP3=Pe∥⦇{e′}⦈∥Q. We thus have thate∈F(P1)ande′∈F(P3). For the transitionP1⇝e′P2to happen we must have thate∉πR(φe′)and forP3⇝eP4we must havee′∉πR(φe). This is the same ase′∉♯eande∉♯e′which makes the last part of Definition 3.3 concerning the conflict relation, i.e.,¬(e′♯e). This completes the proof, showinge‖e′.  □Theorem 3.19Syntactic restrictionsFor any syntactically correcteventPsi-processPESthere exists an event structureEand a configurationC∈CEs.t.espsi(E,C)=PES.ProofFrom aneventPsi-processPESdefined according to the syntactic restrictions of Definition 3.10, we show how to construct an event structureE=(E,≤,♯)and a configuration C. We have thatPESis built up of assertion processes and case guarded outputs, i.e.,PES=(∏e∈Ec⦇{e}⦈)∥(∏f∈Ercaseφf:f‾〈f〉.⦇{f}⦈).Because of the third restriction onPES(i.e., from Definition 3.10(3)) we know thatEcandErare sets, sincePEScannot have in parallel two assertion processes with the same assertion, nor two case processes with the same channel. Moreover, these two sets are disjoint.We take C to be the frame ofF(PES)=Ec. We take the set of events to beE=Ec∪Er. We construct the causality and conflict relations from the processes in the second part ofPESas follows:<:=∪e∈Er{(e′,e)|e′∈πL(φe)}and♯:=∪e∈Er{(e′,e)|e′∈πR(φe)}. We prove that the causality relation is a partial order. For irreflexivity just use the first part of the second restriction onPES. For antisymmetry assume thate≤e′∧e′≤e∧e≠e′which is the same as havinge∈πL(φe′)∧e′∈πL(φe). This contradicts the first part of the second restriction onPES. Transitivity is easy to obtain from the second part of the second restriction which says that whene≤e′then all the conditions of e are a subset of the conditions ofe′. We prove that the conflict relation is irreflexive and symmetric. The irreflexivity follows from the first part of the first restriction onPES, whereas the symmetry is given by the second part.It is easy to see that for the constructed event structure and the configuration chosen above, we haveespsi(E,C)=PESC. The encoding function espsi takes all events from C to the left part of thePES, whereas the remaining events, i.e., fromErare taken from case processes where for each eventf∈Erthe corresponding conditionφfcontains the causing events respectively the conflicting events. But these correspond to how we built the two relations above.  □Notation. For a syntactically correct process P (i.e., restricted according to Definition 3.10) we will use the notationEPfor the events associated to the process P as defined in the above proof, i.e.,EP=Ec∪Er.Below we show how to refineeventPsiprocesses corresponding to action refinement for labelled event structures [17] as recalled below. The intuition of action refinement is to be able to give actions (which are thought of as possible abstractions) more structure, by replacing every event labelled by a particular action with a finite, conflict free event structure (with events possibly labelled by other actions). For example one action can be refined into a sequence of actions, or in general any deterministic finite concurrent process.Since action refinement is defined using the action labels, we assume oureventPsiinstances have labelled events of the form(e,l(e))for some labelling functionl:E→Act, and as usual writeeafor an event(e,a).A refinement functionref:Act→Eis then a function from the set of actions of event structures (denoted by Act) to conflict-free event structures (i.e., the conflict relation is empty) denoted byE. The function ref is considered as a given function to be used in the refinement operation denoted by ref.Definition 3.20Refinement for prime event structuresFor an event structureEwith events labelled byl:E→Acta functionref:Act→Eis called a refinement function (for prime event structures) iff∀a∈Act:ref(a)is a non-empty, finite and conflict-free labelled prime event structure.ForE∈Eand ref a refinement function, letref(E)∈Ebe the prime event structure defined by:•Eref(E):={(e,e′)|e∈EE,e′∈Eref(lE(e))}, whereEref(lE(e))denotes the set of events of the event structureref(lE(e)),(d,d′)≤ref(E)(e,e′)iffd≤Eeor(d=e∧d′≤ref(lE(d))e′),(d,d′)♯ref(E)(e,e′)iffd♯Ee,lref(E)(e,e′):=lref(lE(e))(e′).Example 3.21Fig. 4(a) provides an illustrative example (taken from [17]) of action refinement applied to a process which receives and sends data. We may think of giving more details to the sending event by refining it with a sequential process which first prepares the data and then carries out the actual sending. This refined process is shown in Fig. 4(b). In turn, Fig. 4(c) shows a further refinement, where the preparation of data is refined by a process which in parallel formats the data and asks permission to send.Remark 3.22Action refinement as presented here was introduced by Wirth [16] under the name of stepwise refinement and is quite different than the more recent notion of refinement in process algebras where the refined process is seen as an implementation of the abstract one. In these settings usually refinement is seen as an inclusion-like relation of the behaviours, such as trace inclusion or simulation.We can define a refinement functionrefψ:Act→PeventPsiforeventPsi-processes from a given refinement function ref for event structures as follows:refψ(a)=espsi(ref(a)). For syntactically correcteventPsi-processes these two functions are one-to-one inter-definable in the sense that foreventPsi-processes that represent finite conflict-free event structures (i.e., that have the right elements of the conditions always empty) we can define ref fromrefψby an analogous definition as before, going through Theorem 3.19. In the rest of this section, we prefer to work with the simpler notation provided by ref.We define an action refinement operation foreventPsi-process terms.Definition 3.23Given a refinement function ref for event structures over events E, we define an operationrefΨthat refines aneventPsi-process over events E to a new one over the termsTΨ={(e,e′)|e∈T,e′∈Eref(l(e))}.A syntactically correcteventPsi-process P, built according to Definition 3.10, with frameF(P)=ΨP, is refined into a processrefΨ(P)=∏(e,e′)∈TΨP(e,e′),andP(e,e′)={⦇{(e,e′)}⦈ife∈ΨPcaseφ(e,e′):(e,e′)‾〈(e,e′)〉.⦇{(e,e′)}⦈otherwisewith the conditions beingφ(e,e′)=(<(e,e′),♯(e,e′)),where<(e,e′)={(d,d′)|d∈πL(φe)∨(d=e∧d′<ref(l(d))e′)}and♯(e,e′)={(d,d′)|d∈πR(φe)}.The set of events (which constitute the terms) is the set of pairs of an event from the original process and one of the events from the refinement processes. Note that the above definition is still part of theeventPsiinstance because we can mapTΨonto T. Take any total order < on E and define from it a total order(e,e′)<(d,d′)iffe<d∨(e=d∧e′<d′)on the pairs; map any pair to an event from E while preserving the order, thus makingTΨthe same as the T ofeventPsi.We make new conditions for each event(e1,e2), where<(e1,e2)contains all pairs of events(e1′,e2′)s.t. eithere1′<e1, ore1′=e1∧e2′<e2. We define conflicts by♯(e1,e2)={(e1′,e2′)|e1#e1′}(recalling that the refinement process is conflict-free). The refinement generates for each new pair one process which is either an assertion or a case process, depending on whether the first part of the event pair was in the frame of the old P respectively not.Theorem 3.24Refinement ineventPsicorresponds to that in ESFor any prime event structureEwe have that:espsi(ref(E),∅)=refΨ(espsi(E,∅)).ProofAsT=EandTΨis built from T in Definition 3.23 with rules analogous to thoseErefis built from E in Definition 3.20, we have thatTΨ=Eref. Since the processes we work with are parallel compositions of assertion and case processes, it means we have to show that any assertion processes on the left is also found on the right of the equality (and vice versa), and the same for the case processes. Since we work with the empty initial configuration, then there are no assertion processes on either sides.The case processes on the left side of the equality are those generated by espsi from the pairs of events returned by the ref from the event structureE, i.e.,P(e,e′)=caseφ(e,e′):(e,e′)‾〈(e,e′)〉.⦇{(e,e′)}⦈with the conditionφ(e,e′)=(<(e,e′),♯(e,e′))which is build according to Definition 3.20 from♯Ee,<Ee, and<ref(l(d))e′. On the right side we have case processes for the original process before the refinement, with their respective conditions. But therefΨreplaces each one of thesePewith several case processes, one for each new pair(e,e′)that involves e. Therefore, according to Definition 3.23 we will haveP(e,e′)=caseφ(e,e′):(e,e′)‾〈(e,e′)〉.⦇{(e,e′)}⦈with its condition being built fromπR(φe),πL(φe), and<ref(l(d))e′. These are respectively the same as the ones used on the left side. Checking that any case process from the right side is found in the left side is done similarly.  □In this section we gave a representation of an encoding of the prime event structures into an instance of psi-calculi which preserves the causality relation and thereby also the notion of action refinement. To do this, we made special use of the logic of psi-calculi, i.e., of the assertions and conditions and the entailment between these, as well as the assertion processes. It is noteworthy that we have not used neither names nor the communication mechanism of psi-calculi, which is known to increase expressiveness.88In π-calculus communication of channel names allows to reach Turing completeness [43], in contrast to CCS with only synchronisation and replication (calledCCS!) where the expressiveness is weaker [44].Dynamic Condition Response graphs (DCR graphs) [15,45] is a model of concurrency which generalises event structures in two dimensions: Firstly, it allows finite models of (regular) infinite behaviour, while retaining the possibility of infinite models. The finite models are regular in the automata-theoretic sense, i.e. they (if concurrency is ignored) capture exactly the languages that are the union of a regular and an omega-regular language [46]. Finite DCR graphs have found applications in practice for the description, implementation and automated verification of flexible workflow systems [47,18]. Infinite DCR graphs allow for representation of non-regular behaviour and denotational semantics. Secondly, the DCR graphs model provides an event-based notion of acceptance criteria for both finite and infinite computations in terms of scheduled responses. In the present paper we focus on the first dimension, leaving the interesting question of representing event-based acceptance criteria for infinite computations to future work. We follow the notations for DCR graphs from [15,45].Definition 4.1DCR graphsWe define a Dynamic Condition Response Graph to be a tupleD=(E,M,,,,,,L,l)where1.E is a set of events,M∈2E×2E×2Eis the initial marking,,,,,⊆E×Eare respectively called the condition, response, milestone, include, and exclude relations,l:E→Lis a labelling function mapping events to labels taken from L.For any relation→∈{,,,,}, we use the notation e→ for the set{e′∈E|e→e′}and →e for the set{e′∈E|e′→e}.A markingM=(Ex,Re,In)represents a state of the DCR graph. One should understand Ex as the set of executed events, Re the set of scheduled response events99Similar to the notion of restless events in [48, ch. 6.4.].that must happen sometime in the future or become excluded for the run to be accepting (see Definition 4.4), and In the set of currently included events. The five relations impose constraints on the events and dictate the dynamic inclusion and exclusion of events.Intuitively, the condition relationee′requires the event e to have happened (at least once) or currently be excluded in order fore′to happen. The response relationee′means that if the event e happens, then the evente′becomes scheduled as a response. The milestone relationee′imposes the constraint thate′cannot happen as long as e is a scheduled response and included. Finally, the exclusion and inclusion relations generalise the conflict relation from event structures. An event e that excludes another evente′can be thought as being in (one-sided) conflict; but another event may includee′again, thus making the previous conflict only transient.An event is thus enabled if it is included, all its included preconditions have been executed, and none of the included events that are milestones for it are scheduled responses. In particular, an event can happen an arbitrary number of times as long as it is enabled. We express the enabling condition formally as follows.Definition 4.2Enabling eventsFor a DCR graphD=(E,M,,,,,)with an initial markingM=(Ex,Re,In), we say that an evente∈Eis enabled in M, writtenM⊢e, iffe∈In∧(In∩e)⊆Ex∧(In∩e)⊆(E∖Re).Having defined when events are enabled, we can define an event labelled transition semantics for DCR graphs. Since the execution of an event only changes the marking, we define the transition relation between the markings of a given DCR graph and regard the marking M given in the DCR graph as the initial marking.Definition 4.3TransitionsThe behaviour of a DCR graph is given through transitions between markings done by executing enabled events. The result of the execution in a DCR graphD=(E,M0,,,,,)from markingM=(Ex,Re,In)of an enabled eventM⊢eresults in the new markingM′=def(Ex∪{e},(Re∖{e})∪e,(In∖e)∪e)and is written as the e-labelled transitionM→eM′. The (interleaving) semantics of the DCR graph is then defined as the event-labelled transition system with markings as states andM0the initial state.We can now define (possibly infinite) runs of DCR graphs and the acceptance criteria formally. As stated above, every event scheduled as response must either happen or be excluded in the future, in order for the run to be accepting. An event is no longer scheduled as a response after it has happened, unless it is related to itself by a response relation.Definition 4.4Accepting runs [15]A run of a DCR graph with initial markingM0is a (possibly infinite) sequence of transitionsMi→eiMi+1, with0≤i<k,k∈N∪{ω}, andMi=(Exi,Rei,Ini). A run of a DCR graph is accepting (or completed) if it holds that∀i≥0,e∈Rei.∃j≥i:(e=ej∨e∉Inj)In words, a run of a DCR graph is accepting if no event scheduled as an response is included and pending forever without happening, i.e. it must either eventually happen on the run or become excluded.Since in psi-calculi we do not have readily available a notion of accepting run, we will ignore this aspect for the rest of this paper. However, since our encoding captures the response and milestone relations of DCR graphs, it is prepared for adding a notion of accepting runs via scheduled responses to psi-calculi.It is worth noting that the labelling function on events adds the possibility of non-determinism by taking the language of a DCR graph to be the sequences of labels of events (abstracting from the events) of accepting runs. This extra level of labelling increases the expressive power of finite DCR graphs, which have been shown to capture exactly the languages that are the union of a regular and an omega-regular language [46]. In contrast, by following an encoding along the lines of [49] unlabelled, finite DCR graphs can be represented by Linear-time Temporal Logic (LTL), which is known to be strictly less expressible than omega-regular languages.As given by the mapping in Definition 4.5 below, prime event structure can be seen as a special case of a DCR graph (see [15, Prop. 1&3] for details) where the exclusion relation (capturing the conflict relation) is reflexive and symmetric, the condition relation (capturing the causality relation) is irreflexive and transitive, and the include, response, and milestone relations are empty. The initial marking has no executed events, no scheduled responses and all events are included. Hereto comes of course the two conditions on the causality and conflict relation of event structures, i.e. finite causes and hereditary conflict. The reflexivity of the exclusion relation and emptiness of the inclusion relation imply that events can be executed at most once.Definition 4.5Prime event structures as DCR graphs [15]Define a mapping dcr which takes an event structureE=(E,≤,♯,l)and returns its presentation as a DCR graph(E,M,<,∅,∅,∅,♯∪{(e,e)|e∈E})with the markingM=(∅,∅,E).Example 4.6Consider the small DCR graphDshown in Fig. 5, corresponding to the event structure of Fig. 4(a) which was representing a process of first reading data (r) and then sending data (s). The DCR graph is formalised asD1=({r,s},(∅,∅,{r,s}),{(r,s)},∅,∅,∅,{(r,r),(s,s)}).Here we can see that each event removes itself from the included set when it happens, and that for s to happen its prerequisite r must happen. This corresponds to the causality relation in the event structure in Fig. 4(a).In DCR graphs is possible to demand that if we read some data we will eventually send this data. This is modelled in the DCR graph of Fig. 6formalised asD2=({r,s},(∅,∅,{r,s}),{(r,s)},{(r,s)},∅,∅,{(r,r),(s,s)}),where we added a response relation from r to s. This means that a run is only accepting if any r is eventually followed by an s, e.g., the empty run and the runr.sare accepting, while the run consisting of the single event r is not.The examples above only allow each event to happen once. However, as exemplified below, in DCR graphs the set of events needed for an event to be enabled can change during the run, as events are included or excluded. Moreover, the conflict in DCR graphs is not permanent as is the case with event structures. Conflict in DCR graphs is transient since an event can be included and later excluded during a run. So, already at the conflict and causality relations, the DCR graphs depart from event structures in a non-trivial manner.Example 4.7A message forwarding machine, where the events can happen several times, but alternating, can be represented by the DCR graph in Fig. 7formalised asD3=({r,s},(∅,∅,{r,s}),{(r,s)},{(r,s)},∅,{(r,s),(s,r)},{(r,r),(s,s)}).Each time one of the two events happens it excludes itself but includes the other event, modelling the alternation between reading and sending. We still have that if r happens, eventually s must happen for the run to be accepting, but we make no requirements on how many times the events can happen, so the unique infinite execution and every finite execution of even length will be accepting.Below we provide an encoding of finite DCR graphs as a psi-calculi instance. As was done with configurations of event structures, markings are kept in the frame of the process. Also, similarly to the event structure representation, for each event of the DCR graph we use a case process, and conditions and entailment relation to capture the information needed to decide when events of a DCR graph are enabled in a marking.However, in contrast to the encoding of event structures, it appears that we need the communication constructs on processes to keep track of the current marking of a DCR graph. The expressiveness of DCR graphs seems not to allow for a simple way of updating the marking, as was the case for event structures where union with the newly executed event was enough. But once we use the communication we get a nice natural encoding for DCR graphs in a psi-calculus instance. The idea is to internally communicate a term representing the current marking, and incorporate a generation (or age) of an assertion and then keep the assertion with the latest generation when composing assertions. Generations are inspired by [50], where they are used in a similar way to represent the changing topology of a mobile communication network.Since a step is now an internal communication, we can no longer observe the event that happened by just looking at the communication channel. Instead, we record all executed events in a multi-set part of the assertion. The underlying set of this multi-set corresponds to the set of executed events in the marking of the DCR graph. By recording also the multiplicity of each event one can identify, by multi-set subtraction, which event happened in a transition, as expressed formally below.Notation 4.8For a multi-set S we will denote its underlying set by⌊S⌋and write|S|for the number of elements of S, summing multiplicities.Definition 4.9dcrPsiinstanceGiven a set of constants E (denoting events), we define thedcrPsiinstance over a set of namesNas:T=defN∪A∪NopE∪2opE∪NopA=def(NopE×2opE×2opE×Nop)∪11=def⊥C=def(2opE×2opE×E)∪Nop∪{M↔⋅N|M,N∈T}.whereNopEare the multi-sets over E with the operators of Example 2.19 and possibly containing names fromN,Nopis the data structure capturing natural numbers from Example 2.18, and ⊥ is a special constant term assertion. (We will refer to assertions containing only ground terms as ground assertions, and assertions containing names as open assertions.) For ground assertions, i.e., whenEx,Re,In,gdenote ground terms, define(Ex,Re,In,g)⊗(Ex′,Re′,In′,g′)=def{(Ex,Re,In,g)ifg>g′,(Ex′,Re′,In′,g′)ifg<g′,(∅,∅,∅,g)ifg=g′,where the comparisong<g′is done using sub-term relation, e.g.,s(g)>g(we usually denote generations byg,k∈N). For the other cases defineΨa⊗Ψb=def{ΨawhenΨbis open or1,andΨais ground,ΨbwhenΨaisopen or1,andΨbis ground,1otherwise.Entailment ⊢ is defined as:(Ex,Re,In,g)⊢(Co,Mi,e)iffe∈In∧(In∩Co)⊆Ex∧((In∩Mi)∩Re)=∅(Ex,Re,In,k)⊢g∈Niffk=g(Ex,Re,In,g)⊢a↔⋅biffa,b∈Nanda=b.For any other assertions (e.g. the open ones) or conditions the entailment is undefined.Notation 4.10We denote ground assertions, and the respective four ground terms, by(Ex,Re,In,g). In the few cases where we need to talk about open terms we will use capital lettersXE,XR,XI,XGpossibly indexed to indicate the respective component in the tuple, to stand for a name. We do not always mention explicitly if the assertions or terms are ground when this is clear from the context or the notation.Terms can be either a name or assertions (and their components) which will be the data communicated. Assertions are four-tuples of one multi-set and two sets containing events, whereas the fourth element is a number which we intend to hold the generation of the assertion.1010For all these terms we allow operators to be present, but for simplicity we work with their mathematical presentation, and assume that when evaluated the equations of the respective operators would produce the ground final form, like numbers, sets, multi-sets.The multi-sets capture which events have been executed, and also count how many times each event has been executed. This will allow, in Definition 4.23, to infer from the change in the frame, which event happened in an execution step. The second set holds those events that are pending responses, and the third set those events that are included. The multi-set and set operations in the terms allow us to construct terms for updating the sets when an event is executed. The underlying set of the multi-set represents the first set of a marking from DCRs, whereas the two other sets of an assertion represent the second and third set of a marking of a DCR graph. The generation number helps to get the properties of the assertion composition, which are somewhat symmetric, but still have the composition return only the latest marking/assertion (i.e., somewhat asymmetric).The composition of two assertions keeps the assertion with highest generation if both are tuples of ground terms. For technical reasons, when we compose two ground assertions with the same generation we obtain an assertion where the first three elements are emptysets, and the generation number remains unchanged. Intuitively, we do not want two assertions with the same generation number to exist because this can be thought as an error in the process computation (i.e., assertion generations are supposed to constantly increase). But in our encodings and results this never happens, which can be easily checked. Moreover, technically it is a nice solution to make any two assertions with the same generation disappear.When any of the assertions contain names (i.e., either one of the tuple elements is a name or a term contains a name) then the composition returns the ground assertion when it exists or the identity assertion, when both assertions contain names. In other words, we are interested only in the ground assertions, those containing the actual data, without undefined parts. This makes the composition operation associative, commutative, compositional wrt. assertion equivalence,1111Recalling from Section 2, compositionality refers to:Ψ≃Ψ′⇒Ψ″⊗Ψ≃Ψ″⊗Ψ′.and with identity being the special constant term ⊥.The conditions are tuples of two sets of events and a single event as the third tuple component. The first set is intended to capture the set of events that are conditions for the single event. The second set is intended to capture the set of events that are milestones for the single event.As in [50], we added the set of natural numbers as conditions for technical reasons, so that assertion equivalence will be compositional. Without this we would have(Ex,Re,In,0)≃(Ex,Re,In,2), but when composed with another assertion(Ex′,Re′,In′,1), whereIn∩In′=∅, we would get(Ex,Re,In,0)⊗(Ex′,Re′,In′,1)≄(Ex,Re,In,2)⊗(Ex′,Re′,In′,1)which contradicts compositionality: On the left side we would keep the assertion with highest generation 1 whereas on the right side we would keep the one with 2. As the sets of included events are different we have that they cannot entail the same conditions. With the natural numbers as conditions we can distinguish between the two assertions(Ex,Re,In,0)≄(Ex,Re,In,2)since we have that(Ex,Re,In,0)⊬2but(Ex,Re,In,2)⊢2.Remark 4.11On sortingWe rely on sorting to properly define indcrPsithe terms, substitutions, matching, etc. We rarely mention sorting aspects, only when necessary for clarifications, and rely on the intuition in most cases. For instance, in Definition 4.9 we silently use sorts for several aspects: to distinguish the different kinds of terms (like a sort for natural numbers, another sort for multi-sets); several corresponding name sorts; the assertion tuple operand is multi-sorted; the substitution takes care that names on the respective place in a tuple are replaced by terms of respective sort. We thus make careful use of notation to be in accordance with the sorting aspects; e.g., the notation(a,a,a,b)is unacceptable, opposed to(a,c,c,b)which allows both second and third elements of a tuple to be the same term.Lemma 4.12For two assertionsΨ=(Ex,Re,In,g),Ψ′=(Ex′,Re′,In′,g′)we have thatΨ≃Ψ′⇒g=g′.ProofSinceΨ≃Ψ′andΨ⊢gthen alsoΨ′⊢gwhich means thatg′=g.  □Lemma 4.13Correctness ofdcrPsiThedcrPsiinstance fulfils the requirements of being a psi-calculi instance, cf.Definitions 2.2 and 2.4.ProofWe have to show that the channel equivalence and the composition of assertions conform with the requirements from Definition 2.4. We also need to show that the operators and nominal datatypes of Definition 2.2 are well defined.For the channel equivalence it is easy to see that symmetry and transitivity are respected since in Definition 4.9 (last line) channel equivalence is defined in terms of name equality.For assertion composition we have to look at three different scenarios, one where all the assertions are open or 1, one where we have a mix of open or 1 and ground assertions, and last where we have only ground assertions.We first point out that all open assertions are assertion equivalent through the fact that they cannot entail any conditions (i.e., entailment in Definition 4.9 is undefined for open assertions). The same goes for 1 which also does not entail any conditions, and thus assertion equivalent with all open assertions. Whenever we compose two open assertions we obtain 1, i.e., composition of open assertions results in the identity assertion that is assertion equivalent with all open assertions. (From here on we will refer to 1 as an open assertion for the sake of simplicity because we only care about assertion equivalence for the correctness proofs). Since the four requirements from Definition 4.9 on assertion composition are defined in terms of assertion equivalence, then they are trivially satisfied when only open assertions are involved.1212For example the identity is satisfied sinceΨ⊗1=def1and1≃Ψwhen Ψ is open.For the case where we have a mix of open and ground assertions, the composition returns the ground assertion (i.e., open assertions are absorbed by any ground ones). It is easy to check the four requirements from Definition 4.9. Also note that it is not possible for any ground assertion to be equivalent with any open assertion since the ground assertion will at least entail the condition g when is its generation.When we have only ground assertions the composition will maintain the one with the highest generation, when composing assertions with different generations; otherwise, if we have two ground assertions with the same generation g we obtain the assertion(∅,∅,∅,g).For commutativity it is easy to see that when the generations are the same we will always get the same assertion, independent of the order we compose them. When the assertions have different generations, keeping the one with the highest generation is independent of its place in the composition.For compositionality we know, by Lemma 4.12, that if two assertionsΨ,Ψ′are equivalent then they have the same generation g. Therefore, when composed with another assertionΨ″with generationg″we must treat three cases. Ifg<g″then for bothΨ⊗Ψ″andΨ′⊗Ψ″we obtainΨ″. Ifg=g″then on both sides we obtain the assertion(∅,∅,∅,g). Wheng>g″we have thatΨ⊗Ψ″=ΨandΨ′⊗Ψ″=Ψ′which are equivalent by assumption.For associativity, when all the generations are different we remain with the assertion that has the highest generation (i.e., by virtue of the associativity of the max function on natural numbers). When two or more assertions have the same generation g the result depends on whether this is the largest generation or not. When g is the largest we obtain the assertion(∅,∅,∅,g). Otherwise, the assertion with highest generation will be returned, on both sides.To make sure that the nominal datatypes and operators of the instance are well defined consider the following observations. Assertion composition always returns a correct assertion term, whereas channel equality operation always returns a condition by virtue of the definition including all termsM↔⋅N.It is not difficult to see thatT,Aand C are nominal datatypes when the correct sorting is used. In particular, assertions are four-tuple terms that can take a name of sort multiset, two names of sort set, and one of sort natural numbers; each of which can be substituted with terms of corresponding data sorts. All these terms have finite support since they are finite. Terms can be either names, assertion tuples, or the individual terms that can be used by the substitution functions. There are then closed under name swapping, as well as under substitutions that respect the sorting discipline.  □As stated in the lemma below, the entailment mimics the definition in DCR graphs for when an event (i.e., the third component of the conditions) is enabled in a marking (i.e., the first three components of the assertions).Lemma 4.14Correlation between entailment in DCRs anddcrPsiFor any DCR graphDwe have that(Hi,Re,In,g)⊢(e,e,e)iff(⌊Hi⌋,Re,In)⊢e.ProofFollows directly from Definition 4.2 and Definition 4.9  □We are now ready to provide the mapping of DCR graphs todcrPsi. To facilitate proving the semantical correspondence we provide a slightly more general mapping that takes a DCR graph and a multi-set history of executed events.Definition 4.15DCR-graphs todcrPsiWe define a functiondcrpsi(D,Hi)which takes a DCRD=(E,M,,,,,L,l), with initial markingM=(Ex,Re,In), and a multi-set Hi representing the history of events that have happened, with underlying set⌊Hi⌋=Ex, and returns adcrPsiprocessPdcr=(νm)(Pk∥PE)wherePk=⦇(Hi,Re,In,|Hi|)⦈∥m‾〈(Hi,Re,In,|Hi|)〉.0andPE=∏e∈EPewithPe=!(caseφe:m_〈(XE,XR,XI,XG)〉.!((m‾〈(XE+{e},(XR∖{e})∪e,(XI∖e)∪e,s(XG))〉.0∥!((⦇(XE+{e},(XR∖{e})∪e,(XI∖e)∪e,s(XG))⦈))whereφe=(e,e,e)andXE,XR,XI,XGare names.The processPdcrresulting from dcrpsi contains the processPkthat models the initial marking of the encoded DCR graph as an assertion process, and also communicates this assertion on the channel name m. We give this assertion the generation|Hi|. The rest of the process, i.e.,PE, captures the events and relations of the DCR graph as a parallel composition of processesPefor each of the events of the encoded DCR graph. We will writedcrpsi(D)fordcrpsi(D,Hi), whenHi=Ex.Each event is encoded, following the ideas for event structures, using the case construct with a single guardφe. The guard contains the information for the event e that needs to be checked against the current marking (i.e., the assertion) to decide if the event is enabled: The set of events that are prerequisites for e (i.e.,e) and must either be executed or excluded, the set of milestones related to e (i.e.,e) that must either be excluded or not be scheduled as responses, and the event e itself, that must be included. The events in a DCR graph can happen multiple times, hence the use of the replication operation as the outermost operator.As for event structures, there may be several events enabled by a marking, hence several of the parallel case processes may have their guards entailed by the current assertion. Only one of these input actions will communicate with the single output action on m, and will receive in the four variables the current marking. After the communication, the input process will leave behind an assertion process containing an updated marking, and also a process ready to output on m this updated marking. In fact, after a communication, what is left behind is something looking like aPkprocess, but with an updated marking and an increased generation number. The updating of the marking follows the same definition from the DCR graphs. We also guard the channel name m so that no other input or output transitions can happen on this channel, except the internal communications.Notation 4.16In the context of Definition 4.15, i.e., when encoding a DCR through the dcrpsi, we will use the following shorthand notation to stand for the often and similar way of updating a marking:Ue(XE,XR,XI,XG)=def(XE+{e},(XR∖{e})∪e,(XI∖e)∪e,s(XG)).The updating notation is parametrised by an event e which is enough to extract the sets of events that are used in the denoted term. The four names can be substituted as in any term, thus a substitutionUe(XE,XR,XI,XG)[XE:=Ex,XR:=Re,XI:=In,XG:=g]would produce the term(Ex+{e},(Re∖{e})∪e,(In∖e)∪e,s(g)),and we usually just writeUe(Ex,Re,In,g).Example 4.17Taking the DCR graphD1from Fig. 5, we can create adcrPsi-processP=dcrpsi(D1,∅), with initial generation|∅|=0, as followsP=(νm)(⦇(∅,∅,{r,s},0)⦈∥m‾〈(∅,∅,{r,s},0)〉.0∥!(case(∅,∅,r):m_〈(XE,XR,XI,XG)〉.(⦇Ur(XE,XR,XI,XG)⦈∥m‾〈Ur(XE,XR,XI,XG)〉.0))∥!(case({r},∅,s):m_〈(XE,XR,XI,XG)〉.(⦇Us(XE,XR,XI,XG)⦈∥m‾〈Us(XE,XR,XI,XG)〉.0))).From the entailment we can see that this process may only have a synchronisation between the outputm‾〈(∅,∅,{r,s},0)〉.0and the input guarded by thecase(∅,∅,r), making a transitionP→τP′withP′=(νm)(⦇(∅,∅,{r,s},0)⦈∥0∥⦇({r},{s},{s},1)⦈∥m‾〈({r},{s},{s},1)〉.0∥!(case(∅,∅,r):m_〈(XE,XR,XI,XG)〉.(⦇Ur(XE,XR,XI,XG)⦈∥m‾〈Ur(XE,XR,XI,XG)〉.0))∥!(case({r},∅,s):m_〈(XE,XR,XI,XG)〉.(⦇Us(XE,XR,XI,XG)⦈∥m‾〈Us(XE,XR,XI,XG)〉.0))).The other input was blocked from synchronisation with the output by the entailment relation.Definition 4.18Syntactic restrictions fordcrPsiWe define adcrPsi-process P to be syntactically correct for a set of events E if it is of the following form, up to structural congruence:P=(νm)((∏0≤k≤g≤k′⦇Ψg⦈)∥m‾〈(Exk′,Rek′,Ink′,k′)〉.0∥(∏e∈EPe))withk∈NandΨg:=⦇(Exg,Reg,Ing,g)⦈where|Exg|=g,Pe:=!(caseφe:m_〈(XE,XR,XI,XG)〉.(m‾〈Ue(XE,XR,Xi,XG)〉.0∥⦇Ue(XE,XR,Xi,XG)⦈)),withφe=(e,e,e), where the indexed Ex are multi-sets of events, and the indexedRe,In, as well ase,eare sets of events.The lemma below states some easy observations that we will use in the following.Lemma 4.19In a syntactically correctdcrPsi-process P we have that:1.Different assertion processes have different generations, not necessarily starting at 0, and less or equal to the assertion in the unique output at the top level.EachPesub-process corresponds to a unique event.There is a unique sub-processm‾〈(Ex,Re,In,g)〉.0at top level, and moreover,F(P)=(Ex,Re,In,g).The process P needs only five names{m,XE,XR,XI,XG}since in eachPethe names{XE,XR,XI,XG}are bound by the input construct.In the following when we refer to adcrPsi-process we will assume that it is a syntactically correct process, over some finite set E of event constants. In Theorem 4.28 we prove that for any syntactically correct P there exists a DCR graph which is bisimilar to P. Before that we need a few preparatory results.Lemma 4.20For anyDand Hi, thedcrPsi-processdcrpsi(D,Hi), if defined, is syntactically correct.ProofFollows directly from Definition 4.15 of dcrpsi.  □Lemma 4.21Frame-marking correspondenceFor anyDand Hi, then the following statements are equivalent•the frame ofdcrpsi(D,Hi)is(Hi,Re,In,|Hi|)the marking ofDis(⌊Hi⌋,Re,In).ProofThedcrpsi(D,Hi)returns adcrPsiprocess with only one assertion(Hi,Re,In,|Hi|)which forms the frame. This assertion is made directly from the marking(Ex,Re,In)ofD, together with the given generation|Hi|, and we know that⌊Hi⌋=Ex.  □Lemma 4.22Transitions preserve syntactic correctnessFor any syntactically correctdcrPsi-processP0≡(νm)((∏k≤g≤g0⦇Ψg⦈)∥m‾〈(Ex0,Re0,In0,g0)〉.0∥(∏e∈EPe))if1▷P0→αP1andF(Pi)=(Exi,Rei,Ini,gi), fori∈{0,1}, then1.α=τP1≡(νm)((∏k≤g≤g0+1⦇Ψg⦈)∥m‾〈(Ex1,Re1,In1,g1)〉.0∥(∏e∈EPe))∃e∈Esuch that:Ex1=Ex0+{e},Re1=(Re0∖{e})∪e,In1=(In0∖e)∪e,g1=s(g0).In particular, it follows that transitions of syntactically correctdcrPsi-processes preserve syntactic correctness.Proof1.In psi-calculi there are three different types of transitions: input, output, and τ transitions. Syntactically correctdcrPsi-processes communicate over only one channel name m which is guarded, and therefore there cannot exist input nor output transitions. Thus the only possibility is τ-transitions.To see thatP1is syntactically correct note that any transition inP0is between the unique top level outputm‾〈(Ex0,Re0,In0,g0)〉.0and a case -guarded inputcaseφe:m_〈(XE,XR,XI,XG)〉.(m‾〈Ue(XE,XR,Xi,XG)〉.0∥⦇Ue(XE,XR,Xi,XG)⦈)coming from the replication of somePe. After the transition and substitution updating the marking, the output becomes 0, whereas the case process becomesm‾〈(Ex1,Re1,In1,g1)〉.0∥⦇(Ex1,Re1,In1,g1)⦈whereEx1,Re1,In1,g1are as in the statement, cf. Definition 4.15 and Notation 4.16. SinceEx1=Ex0+{e}we can find the event e responsible for the current τ-transition throughEx1∖Ex0={e}. In consequence:(a)The single output ofP0has been reduced inP1to 0 and we obtained exactly one new output of the correct form, as required.Since no assertions fromP0were removed, we can write the assertions inP1as∏k≤g≤g0⦇Ψg⦈∥⦇(Ex1,Re1,In1,s(g0))⦈, which can be written as∏k≤g≤s(g0)⦇Ψg⦈.The application of rule (rep) reducesPeto itself in parallel with the case-process that participated in the communication above. Therefore, the product ofPeprocesses remains the same, whereas the case process becomes the new output and a new assertion process.Follows directly from the Notation 4.16 forUeafter substitutions. □Based on Lemma 4.22 we can define transitions labelled by event constants between twodcrPsi-processes as follows.Definition 4.23Event transitionsDefineP⇝eP′iff1▷P→τP′andEx′∖Ex={e}fromF(P)=(Ex,Re,In,g)andF(P′)=(Ex′,Re′,In′,g′). Define event-labelled transition systems, denotedLTS, to have as states alldcrPsi-processes and transitions between states defined by the above event-labelled transitions. For somedcrPsi-process P, we call the event-labelled transition system of P, denotedLTS(P), only the part ofLTSreachable from P.We are now ready to show that thedcrPsi-mapping preserves the behaviour.Proposition 4.24Preserving behaviourForP≡(∏k≤g<|Hi|⦇Ψg⦈)∥dcrpsi(D,Hi)thenP⇝eP′⇔D→eD′s.t.P′≡(∏k≤g<|Hi|⦇Ψg⦈)∥⦇F(dcrpsi(D,Hi))⦈∥dcrpsi(D′,Hi+{e}).ProofFirst it is easy to see thatF(P)=F(dcrpsi(D,Hi))from Definitions 4.15 and 4.18.From Definitions 4.2, 4.9 and 4.15, and Lemma 4.21, we can see that an event is enabled in P iff it is enabled inD. Therefore, whenever a transition exists on one side of the double implication, it exists on the other side as well.It is easy to see from Definitions 4.3 and 4.15, that after a transitionP⇝eP′, the updates to the frameF(P)=(Ex,Re,In,g)that we see in the frame ofF(P′)are the same as when updating the marking toM′=(Ex′,Re′,In′)in the transitionD→eD′, with the exception of Ex being a multi-set and the generation g. In particular,Ex′=Ex+{e}, which in a marking it means that e is added to Ex if it was not already there, whereas in the assertion the multiplicity of e is increased.Therefore,P′is the same as P with the addition of the above new assertion process⦇Ψ|Hi+{e}|⦈left behind by the communication, and that the output has been changed to match the new state. Since this has highest generation, it becomes the frame ofP′. Moreover, this assertion together withdcrpsi(D,Hi)are the same asdcrpsi(D′,Hi+{e}).  □Definition 4.25Event bisimulationWe define event bisimulation∼•betweendcrPsi-processesP∼•Q, to be the standard bisimulation between their corresponding event-labelled transition systemsLTS(P)∼LTS(Q). This particularly means that there exists a relationR⊆LTS(P)×LTS(Q)between the states of the two transition systems such that(P,Q)∈Rand for any e1.ifP⇝eP′then∃Q′∈s.t.Q⇝eQ′and(P′,Q′)∈R;ifQ⇝eQ′then∃P′∈s.t.P⇝eP′and(P′,Q′)∈R.The same notion of event bisimulation can be defined for DCR graphs over their event-labelled transition systems.Theorem 4.26For a DCR graphDwith markingM=(Ex,Re,In)thenLTS(D)∼•LTS(dcrpsi(D,Ex)).ProofWe denote byE→a sequence of events, and by→E→a sequence of transitions labelled by the respective evens in the sequenceE→. Indexes are used to refer to elements in such sequences.We show that the following set is a bisimulation:{(Dk,Pk)|D→E→Dk,dcrpsi(D,Ex)⇝E→Pk}.This is equivalent to the single steps coinductive statement of Definition 4.25. The initial pair, for the empty sequence, is(D,dcrpsi(D,Ex)).Proving that all pairs respect the requirements of Definition 4.25 is easy by induction over the length k. The induction has as basis the above initial pair. The Proposition 4.24 ensures that whenever a transition exists from one element of the pair, then the same transition exists from the other element. By the above construction, this new pair is in our bisimulation relation, thus respecting Definition 4.25.  □Proposition 4.27Determinism indcrPsiSyntactically correctdcrPsi-processes are deterministic; i.e., in the execution graph, at any point P ifP⇝eP′thenP′is unique.ProofFor any syntactically correctdcrPsi-processes we know that there is only one output process, cf. Lemma 4.19(3), and all input processes have a unique event e, cf. Lemma 4.19(2). Since event-labelled transitions are communications between one input and the single output, cf. Definition 4.23, then there can be at most one transition labelled by e. Lemma 4.22 ensures that any point in the execution graph is a syntactically correct process, thus finishing the proof.  □Theorem 4.28Syntactic restrictionsFor any syntactically correctdcrPsi-processPDCR, i.e., built according to the syntactic restrictions inDefinition 4.18, there exists a DCR graphDs.t.LTS((D))∼•LTS()(PDCR).ProofWe take the set of events of the DCR graph to be the set of event constants of thedcrPsiinstance. We know from Definition 4.18 thatPDCRis built asP=(νm)((∏k≤g≤k′⦇Ψg⦈)∥m‾〈(Exk′,Rek′,Ink′,k′)〉.0∥(∏e∈EPe))wherePeis of the form!(caseφ:m_〈(XE,XR,XI,XG)〉.(m‾〈Ue(XE,XR,XI,XG)〉.0∥⦇Ue(XE,XR,XI,XG)⦈))withφ=(e,e,e)andUe(XE,XR,XI,XG)=(XE∪{e},(XR∖{e})∪e,(XI∖e)∪e,s(XG))fore,e,e,e,esome subsets of E. We define the relations of the DCR graphDfrom these subsets, i.e. fore,e′∈Edefinee′eife′∈e, and similarly for the other relations.Finally, define the marking M ofDby taking the frame of the processPDCR.The bisimulation follows easily from Theorem 4.26.  □An interesting problem is to look more closely at the encoding of event structures through the espsi and the encoding through dcrpsi when seen as a special case of DCR graphs; a question on these lines could be:areespsi(E)anddcrpsi(dcr(E))similar in any way? Answering this question is not immediate. First of all, espsi translates into theeventPsiinstance, whereas dcrpsi into thedcrPsiinstance, and these two instances work with different terms and operator definitions. Even more, the encoding of event structures exhibits behaviour through labelled transitions, whereas for the encoding of DCRs we need to look into the frames of the processes before and after a transition to find the event that made this transition (cf. Lemma 4.22). Therefore, to find the correspondence that we are looking for we need to work in the same psi-instance, or establish correlations between the instances.Let us first see how thedcrpsi(dcr(E))process looks like, and then we will see a correlation between this and aneventPsi-process for the sameE.Lemma 4.29For an event structureEthedcrPsi-processdcrpsi(dcr(E))has:1.all conditions of the form(Co,∅,e)(for arbitrary Co and e) andthe initial assertion(∅,∅,E,0).ProofFrom Definition 4.5 we know that the DCR graphdcr(E)has=∅, which implies that the encoding function dcrpsi produces conditions(Co,∅,e)with the second element always empty. The initial assertion is made directly from the initial marking in the start processP|Hi|in Definition 4.15, which in the case ofdcr(E)is(∅,∅,E), cf. Definition 4.5.  □Lemma 4.30Ifdcrpsi(dcr(E),Ex)⇝⁎P⇝eP′and frameF(P)=(Ex,∅,In,g), then the new frame isF(P′)=(Ex+{e},∅,In∖(♯e∪{e}),s(g)).ProofThe fact that the generation increases tos(g)is easy to see from how the assertions are created on transitions. The proof of Lemma 4.22 shows that the first element of the updated frame will beEx′=Ex+{e}. From Definition 4.5 ofdcr(E)we have=♯∪{(e,e)|e∈E}which implies thate=(♯e∪{e}). Since=∅, we have that the update of the third element of an assertion, when event e happens, isIn′=(In∖e)∪e=(In∖(♯e∪{e}))∪∅=In∖(♯e∪{e}). From Definition 4.5 we also have=∅, which implies that the second element of the new frame isRe′=(∅∖{e})∪∅=∅.  □Lemma 4.31For adcrPsi-processdcrpsi(dcr(E),Ex)⇝⁎P, ifF(P)=(Ex,Re,In,g)then1.Re=∅,Ex∩In=∅,In=E∖(∪e∈Ex(♯e∪{e})).ProofFor each of the three points of the statement we use an inductive argument. For 1 the base case is given by Lemma 4.29(2) which shows that in the execution of the process initially we haveRe=∅. For the inductive case we use Lemma 4.30.For 2 the base case is given by Lemma 4.29 which says that initiallyEx∩Inis the same as∅∩E=∅. For the inductive case assume that the frame isF(P)=(Ex,∅,In,g), withEx∩In=∅from the induction hypothesis. Consider a transitionP⇝eP′and we show that the second claim holds forP′. Having the transition implies that the event e is enabled in the frame of P; i.e., Definition 4.23 implies a communication with a case processPefor which theφeis enabled byF(P), which by Definition 4.9 implies thate∈In. From Lemma 4.30 we know thatF(P′)=(Ex′=Ex+{e},Re′=∅,In′=In∖(♯e∪{e}),s(g))which only adds{e}toEx′compared to Ex. Sincee∈Init means thatEx′∩In={e}. But forIn′we remove e from In, thus we have thatEx′∩In′=∅.For 3 the base case is given by Lemma 4.29 which says that initiallyIn=EandEx=∅, thus allowing for the equalityIn=E∖(∪e∈∅)(♯e∪{e}). For the induction case we assume that we have a process P with frame(Ex,∅,In,g)whereIn=E∖(∪e∈Ex(♯e∪{e})). Consider a transitionP⇝fP′, implying by definition thatf∈In, and the new frameF(P′)=(Ex′=Ex+{f},∅,In′,s(g))which hasIn′=In∖(♯f∪{f})by Lemma 4.30. Using the induction hypothesis, this is equal toE∖(∪e∈Ex(♯e∪{e}))∖(♯f∪{f})=E∖(∪e∈Ex′(♯e∪{e})).  □From the lemmas above we can define an embeddingembg, parametrised by some natural numberg∈N, from the assertions ineventPsito the assertions indcrPsias follows.Definition 4.32Correlations between assertionsForΨCan assertion ofeventPsiandg∈Na natural number defineembg(ΨC)=(ΨC,∅,(E∖ΨC)∖(∪e∈ΨC♯e),g).We used the notationΨCto remind that the assertion ineventPsiis a set of events corresponding to a configuration C in the event structure, cf. Lemma 3.14. The above definition of embedding is motivated by Lemma 4.31, in particular, having the second element of the assertion being ∅ comes from Lemma 4.31(2) and the shape of the third element is because of Lemma 4.31(3).The opposite direction of the embedding from Definition 4.32 is obvious the projection on the first element of thedcrPsiassertion, keeping only the support set of the multi-set; denote this projection byprj(Ψ).From Lemma 4.29 we can define a similar embedding of conditions, which we will also denote byembe. We use these embeddings in the proofs and definitions later on.Definition 4.33Correlations between conditionsFor some event constant e and condition(S<,S♯)ofeventPsidefineembe((S<,S♯))=(S<,∅,e).We can also define an opposite embeddingemb←S, parametrised by a set of events S, taking a condition(Co,∅,e)ofdcrPsiand returning a condition ineventPsias follows:emb←S((Co,∅,e))=(Co,S).Lemma 4.34Correlation between entailment relationsFor an event structureEand its encodingespsi(E), and one of its conditionsφe=(<e,♯e)entailed by some assertion Ψ, thenΨ⊢φe⇒embg(Ψ)⊢embe(φe)indcrPsi, under the assumption thate∉Ψ, and for some arbitraryg∈N.ProofWe need to prove thatembg(Ψ)=(Ψ,∅,(E∖Ψ)∖(∪e′∈Ψ♯e′),g)⊢(<e,∅,e)=embe(φe)under the assumptions that<e⊆Ψand♯e∩Ψ=∅, coming from the definition of entailment foreventPsi. For proving the above, the definition of entailment fordcrPsirequires that we prove three points (see Definition 4.9)1.e∈In=(E∖Ψ)∖(∪e′∈Ψ♯e′);In∩<e⊆Ψ;(In∩∅)∩∅=∅;For the first point, the assumption thate∉Ψimplies thate∈E∖Ψ. To finish the proof it means we are left with proving the facte∉∪e′∈Ψ{e″∈E∖ΨC|e′∈♯e″}, thus implying thate∈In. We do this proof by reductio ad absurdum and assume the contrary, i.e.,∃e′∈Ψ:e∈♯e′. We know from the fact that in event structures the conflict relation is symmetric, that ife∈♯e′then alsoe′∈♯e. This, together with the fact thate′∈Ψ, implies that♯e∩Ψ≠∅, which is a contradiction, thus making our assumption false and finishing the proof.  □In adcrPsi-processes generated by the encoding function dcrpsi any event (i.e., the associated case processesPe) may happen (i.e., participate in a communication) infinitely many times, as long as it is enabled. On the other hand, in an event structure an event can happen at most once.Lemma 4.35No event in a processdcrpsi(dcr(E))can happen more than once.ProofFor an event to be enabled the corresponding condition must be enabled by the assertion and the frame of the process, which from the definition implies thate∈In. We also know that initially there are no events that have happened andEx=∅. From Lemma 4.30 we know that after a transition the respective event is added to the new Ex and from Lemma 4.31 we know that any events in Ex cannot simultaneously be in In. Since Ex does not decrease we thus have that if an event e has happened it will never be enabled again.  □We are now ready to define an embedding ofeventPsiprocesses in the context of Theorem 3.19, i.e., generated by espsi, intodcrPsi-processes. Assertions ineventPsiare sets and in the next definition we use the number of elements of the set Ψ as the g parameter that theembgrequires when applied over assertions.Definition 4.36EmbeddingeventPsiintodcrPsiWe define an embedding function emb which takes aneventPsi-processesespsi(E)generated from an event structureE, which according to Definition 3.9 isespsi(E)=∥e∈EPewithPe={⦇{e}⦈ife∈Ccaseφe:e‾〈e〉.⦇{e}⦈otherwisewhereφe=(<e,♯e); and returns thedcrPsi-processemb(espsi(E))as follows:emb(espsi(E)):=(νm)(emb(∥e∈C⦇{e}⦈)∥m‾〈emb(⦇⊗e∈C{e}⦈)〉.0∥∥Peemb(Pe))whereemb(⦇Ψ⦈):=⦇embg(Ψ)⦈, withg=|Ψ|, andPeranges over all the case processes fromespsi(E)withemb(Pe)being defined as:emb(Pe):=!(caseembe(φe):m_〈(XE,XR,XI,XG)〉.(m‾〈Ue(XE,XR,XI,XG)〉.0∥⦇Ue(XE,XR,XI,XG)⦈))withUe(XE,XR,XI,XG)=(XE∪{e},(XR∖{e})∪∅,(XI∖({e}∪♯e)∪∅,s(XG)). WhenC=∅, the empty composition becomes the minimal assertion 1.Theorem 4.37For an event structureEand an initial empty configurationC=∅, we have:emb(espsi(E))=dcrpsi(dcr(E),∅).ProofOn the left side of the equality the processespsi(E)looks like∥e∈Ecaseφe:e‾〈e〉.⦇{e}⦈, without any assertion process because the initial configuration isC=∅. This process is embedded intodcrPsi, using Definition 4.36, as:(νm)(emb0(1)∥m‾〈emb0(1)〉.0∥e∈Eemb(Pe)).Since the assertion1=(∅,∅,∅,0)thenemb0(1)∥m‾〈emb0(1)〉.0becomes⦇∅,∅,E,0⦈∥m‾〈(∅,∅,E,0)〉.0. Each of thePeare translated as in Definition 4.36.On the right side of the equality, the Definition 4.5 for dcr says that the DCRdcr(E)=(E,M,<,∅,∅,∅,♯∪{(e,e)|e∈E})has the initial markingM=(∅,∅,E). This means that thePk,k=0, generated bydcrpsi(dcr(E),0)is the same as what we had on the left side above, i.e.,⦇∅,∅,E,0⦈∥m‾〈(∅,∅,E,0)〉.0.It remains to check that the processesPethat Definition 4.15 of dcrpsi generates are the same asemb(Pe), when considering the empty sets that dcr generates. Recall that thePegenerated by dcrpsi, on the right of the equality, are:!(caseφe:m_〈(XE,XR,XI,XG)〉.(m‾〈Ue(XE,XR,XI,XG)〉.0∥⦇Ue(XE,XR,XI,XG)⦈)),withφe=(e,e,e)andUe(XE,XR,XI,XG)=(XE∪{e},(XR∖{e})∪e,(XI∖e)∪e,s(XG)).Since the response, milestone, and include relations are empty, then the above hasφe=(e,∅,e)andUe(XE,XR,XI,XG)=(XE∪{e},(XR∖{e})∪∅,(XI∖e)∪∅,s(XG))whereeis the same as{e}∪♯e. This shows it is equal withemb(Pe)sinceembe(φe)is, by Definition 4.33, the same as(<e,∅,e), and=<in our case.  □We must make sure that the embedding from Definition 4.36 is correct in the sense that it preserves behaviour, as expressed below.Proposition 4.38Embedding preserves behaviourFor an event structureE, thenespsi(E)andemb(espsi(E))have the same behaviour, i.e.:LTS(espsi(E))∼•LTS(emb(espsi(E))).ProofIn short, the proof follows from Lemma 4.34 that correlates the entailment relations, thus showing that whenever an event is enabled in theeventPsi-process then it is also enabled in its embedding.Construct the bisimulation relation∼•between the states of the two event-labelled transition systems as follows; and then show that this respects the requirements of being a bisimulation. We takeespsi(E)∼•emb(espsi(E))to be the initial points. We continue the construction procedure exactly as in the proof of Theorem 4.26. Therefore, for anyE′reachable fromespsi(E)by some event e, take the processP′reachable fromemb(espsi(E))by the same e, if one such exists, and putE′∼•P′. TheE′andP′are necessarily unique. In the proof all we are interested in is the structure of building this relation, which is given by the above procedure.We are left with proving that for any pairE,Pin the bisimulation, we have the following two statements1.ifE⇝eE′then there exists the transitionP⇝eP′ifP⇝eP′then there exists the transitionE⇝eE′These are enough since the determinism and uniqueness of the construction of the relation∼•ensure that the reachable statesE′andP′are bisimilar (for both statements), thus completing the requirements of Definition 4.25.For the first statement we use Lemma 4.34.For the second statement we need to proveembg(Ψ)⊢embe(φe)⟹Ψ⊢φe. This is the same as provingprj(embg(Ψ))=Ψandemb←♯e(embe(φe))=φe. These are both easy to see from the definition of the embedding functions, and we have the second statement.  □We have presented encodings of the declarative event-based models for concurrency of finite prime event structures and finite DCR graphs, a generalisation of event structures allowing finite representations of infinite computations, into corresponding instances of psi-calculi. We proved that computation in the event structures and DCR graph models corresponds to reduction steps in the corresponding psi-processes. Moreover, for both encodings we made use of the expressive logic that psi-calculus provides to capture the causality and conflict relations of the prime event structures and DCR graphs. This made it possible to prove that action refinement is respected by the encoding of event structures.For the encoding of DCR graphs we made use of the communication mechanism of psi-calculi, whereas for prime event structures this was not needed.For both encodings we gave the syntactic restrictions that capture the psi-processes that correspond precisely to prime event structures respectively DCR graphs.Finally, we proved that the encoding of DCR graphs conservatively generalises the encoding of event structures. For this we showed that the two psi-processes obtained by (i) mapping an event structure first to DCR graphs and then to thedcrPsi-calculus, respectively (ii) mapping the same event structure first to theeventPsi-calculi and then embed this in thedcrPsi-calculus, are event-labelled bisimilar.The purpose of our investigations was to provide psi-calculi models of event based, non-interleaving (or causal) concurrency models as a first step towards a study of adaptable, distributed and mobile computational artefacts. We believe that we succeeded showing that the psi-calculi is indeed well suited for representing causal, non-interleaving models for concurrency.Nevertheless, the encodings leave open issues. Firstly, a discrepancy remains between the interleaving semantics based on SOS rules of psi-calculi, and the non-interleaving nature of the two models we considered. Further investigations would look for a non-interleaving concurrency semantics for psi-calculi (with initial results presented as [51]). Secondly, it is not completely satisfactory that the behaviour of thedcrPsi-processes is observed by a somewhat intentionally constructed event-labelled transition semantics. An improvement could be to consider a more compositional definition of event structures and DCR graphs as considered in [46]. Thirdly, it would be interesting to look into adding responses to psi-calculi as introduced in DCR graphs, allowing to represent liveness/progress properties, continuing along the lines of the work in [52] for Transition Systems with Responses.The next steps towards studying adaptable, distributed and mobile computational artefacts will be to consider cases of workflows identified in field studies within the CompArt project and the notion of run-time refinement and adaptation supported by DCR graphs as presented in [46]. By embedding DCR graphs in the richer framework of psi-calculi we anticipate being able to experiment with richer process models, e.g. representing locations, mobility and resources used by actors in workflows.Remark 5.1On infinite set of eventsIf one would want to apply our encoding to infinite event structures then the set E may be infinite, hence the process and individual elements of A and C may be infinite terms (i.e., infinite sets). In the encoding produced by espsi, the conditionsπL(φe)would be finite, because of the principle of finite causes of Definition 3.1 that event structures respects. Still, theπR(φe)may be infinite, because there is no restriction on the conflict relation in event structures, and thus an event can be in conflict with infinitely many events.A simple example where this would appear is pictured in Fig. 8, where we have a labelled transition system on the left and its unfolding as a labelled event structure on the right. The loop is unfolded into infinitely many sequential events, and for every second event we have a branch with a new c-labelled event which is in conflict with the rest of the infinitea,blabelled sequence. Executing one of these c-labelled events would mean cancelling all the infinitely many events that encode this branch. That is to say, the single event is in conflict with all the events on the looping branch, which are infinitely many.Assertion terms from A, produced by espsi, are always finite because they encode, cf. Lemma 3.14, configurations, which are finite sets. Still, it is problematic to have the infinite right part of the conditions, since it is used in deciding the entailment relation where one needs to decide if the intersection of an infinite and finite set is empty.Besides this, the encoding espsi would result in infinitely many parallel processes if the set of events is infinite, since a process is created for eache∈E. For practical use, infinite terms are not desirable, but for a theoretical encoding they could be fine, just like e.g. infinite summation in Milner's work on SCCS, infinite case construct for psi-calculi, or infinite conjunctions in some logics.When building infinite nominal terms and infinite psi-processes one has to take care of not using infinitely many different free names, i.e., not to have infinite support for the nominal terms. Otherwise essential properties like alpha-renaming fail to work [53].

@&#CONCLUSIONS@&#
