@&#MAIN-TITLE@&#
Image segmentation scheme based on SOM–PCNN in frequency domain

@&#HIGHLIGHTS@&#
We have proposed a scheme for segmenting image in SIST domain.Use texture features to get efficient segmented image.We use MRI images and satellite images to evaluate our scheme.We evaluate our scheme via quality measures.

@&#KEYPHRASES@&#
Image segmentation,SIST,Feature vector,SOM,Modified-PCNN,BSR,

@&#ABSTRACT@&#
A hybrid scheme for the image segmentation of high-resolution images is proposed in this study. Our methodology is based on combining both supervised and unsupervised segmentation. The entire process is performed in the frequency domain, rather than the spatial domain, using the Shift Invariant Shearlet Transform (SIST). Initially, the input image is filtered using an anisotropic filter to enhance the texture features. Then, it is separated into low and high sub-band frequencies using SIST. Subsequently, we built a feature vector from coarser coefficients complemented with texture information extracted from high-frequency coefficients of the input image. SOM is used for the preliminary classification of the input image coefficients, and the network training process is performed using the previously built feature vector. Lastly, the modified PCNN is used to augment the SOM results to reduce the over-segmentation artefacts. We used the Berkeley Segmentation Database (BSR) and Quick-Bird Satellite images to validate the results. It was found that the proposed scheme is superior to the Fuzzy-C-Means-based, SOM-based, and PCNN-based segmentation algorithms in terms of quantitative criteria and visual interpretation.

@&#INTRODUCTION@&#
Image segmentation is the process of partitioning an image into multiple regions such that each region consists of a group of pixels that possess the same or nearly the same spatial and/or spectral characteristics, such as intensity or texture. The output of the image segmentation process is a segmented “classified” image containing multiple classes, where each class has its own attribute.Numerous techniques have been developed for image segmentation. The watershed algorithm [1] is a well-known segmentation tool in the image process community, but it suffers from two serious drawbacks, namely, over-segmentation and incomplete segmentation. In the former, there will be many regions with trivial area, and the latter involves inadequate segmentation [2] for areas near grey matter. To overcome these issues, further image processing procedures are needed, such as morphological operations and edge detection.Many authors have used clustering techniques for image segmentation. Cluster techniques group homogeneous pixels using a predefined statistical population. The improved Fuzzy C-Mean (FCM) [3] approach is an excellent example of this type of segmentation procedure. This method not only introduces a compromise for the usage of a fuzzy factor and a kernel metric, but it also uses more information of the input image in the segmentation process, leading to high segmentation accuracy.Li [4] suggested a segmentation energy function with two distribution descriptors to model the background and the target. Mohamed Ben Salah et al. proposed a convex-relaxed kernel mapping formulation of image segmentation under various partition constraints [5].Dwarikanath [6] suggested a segmentation approach based on random forest (RF) classifiers that improves image segmentation by learning discriminative features.Classification based on segmentation can be created according to brightness similarity; the k-nearest neighbour [7] and support vector machine [8] are examples of classification-based segmentation methods. They require training, and the performance of classification-based segmentation depends on the training parameters and classifier inputs.Fu JC [9] proposed a segmentation model that integrates the expectation maximization (EM) model and the PCNN for brain magnetic resonance image (MRI) segmentation.Recently, neural networks have been introduced as a tool for image segmentation due to their capability of approximating non-linear functions of an input space. Back propagation, Hopfield, and Pulse-coupled neural networks and self-organizing maps (SOMs) [9,10] are considered to be traditional methods of neural networks. Depending upon the learning algorithms utilized, there are different models for developing a neural network; SOM belongs to a model that uses a “competitive learning rule,” which mainly differs from other networks in that it uses a neighbouring region to reserve the topological properties of the input space.Furthermore, these methods have some disadvantages as segmentation methods. The first shortcoming is that increasing the number of neurons in this network does not result in enhanced segmentation performance, and the second is that they require a high-dimensional input space with empirical features for optimal performance [11].Tucci [12] enhanced the neuron building structure of SOM to achieve a preservation of topology maps. The idea is based on introducing a successive formulation of network processing units (neurons), where each neuron acts as a “finite impulse response.” During the learning process, the coefficients of the filters are estimated. PCNN is another type of neural network that is used for image segmentation. Karina used PCNN in the image classification of remotely sensed data. The main drawback of PCNN is the several parameters that affect the performance of the network. GU proposed a model to decrease the number of parameters in the network [13].Moreover, PCNN has been considered as a generic system because changing the network parameters leads to the ability to handle different type of data [14]. An excellent review of using a pulse coupled neural network can be found in [14]. Waldemark et al. used PCNN to differentiate land from water in FORT_E satellite images, the algorithm being able to “approximate areas hidden by stationary artifacts” [15]. They concluded that PCNN has great potential in autonomous pre-processing systems. An algorithm for image segmentation based on unit linking PCNN introduced by Gu et al. [16] came with the fact that “the PCNN is automatically and efficiently segment different type of digital images”. Karvonen et al. [17] used pulse-coupled neural networks for the segmentation of synthetic aperture radar (SAR) images to classify Baltic Sea ice. PCNN based on parallelized firing neurons for SAR image segmentation was presented by Peng et al. They proposed a network structure that consists of two levels. The first level seeks the cluster centres and the other uses a unit-linking PCNN to identify similar neurons [18]. On the other hand, several authors have reported that PCNN has excellent performance for image segmentation but suffers from the ambiguity of parameter selection, which has direct effects on the segmentation process [19,20]. Na and Chen [19] proposed an adaptive algorithm for parameter selection based on the integration of neural structure and image intensity.The basic idea of image transformation presented in this study is that the transformed image is eventually divided into a set of sub-images. Wavelets, Contourlets and the Shift Invariant Shearlet Transform (SIST) [21] are examples of such transformation models. SIST overcomes the others in terms of directional selectivity. The coefficients of SIST are constructed in two stages: multiscale and directional decomposition. The coefficients depend on their neighbours at different scales and orientations. The use of SIST is recommended for images with high texture variation. Because SIST comes with the advantages of directional sensitivity at various scales [22], it offers an excellent way to identify the singularity point in terms of position and orientation. Shichong Zhou et al. [23] evaluated the use of shearlet-based texture in the classification of breast tumours. They compared their results with the contourlet, curvelet, wavelet and grey level co-occurrence matrix. The results showed the superiority of shearlet-based texture feature descriptors with respect to classification accuracy, sensitivity, specificity, positive and negative predictive value.Many objects have similar reflectance values, but indeed they belong to different object categories. SIST coefficients that represent only reflectance value alone are inadequate for image segmentation; moreover, we added texture information to accurately segment the entire image. Therefore, SIST coefficients are used for splitting the textured information into various frequencies. Accomplishing reliable image segmentation depends on using the best selection features as system inputs.SOM belongs to a model that uses a “competitive learning rule,” which mainly differs from other networks in that it preserves the topological properties of the input space, while PCNN is considered as a generic system for changing the network parameters information, leading to the ability to handle different types of data problems [16]. Using only SOM as a classifier will lead to mis-classification and over-segmentation results, as shown in the results section [17]; adding PCNN to the system will reduce this type of error.This study introduces a single-scheme segmenting high-resolution image using both supervised and unsupervised paradigms in the frequency domain. It would allow for perfectly dividing the image space into proper segments based on both intensity and texture information. The use of both supervised and unsupervised classification is added to current classification methods in a dynamic way to reduce false and mis-classification results. Alternately, performing the entire classification process in the frequency domain permits the full use of transformation properties, such as directionality and shift invariance. Moreover, the findings provide evidence that a proposed scheme yields better classification results than the use of intensity or texture individually.The remainder of the paper has the following organization: A brief introduction to SIST, SOM, and modified Pulse-Coupled Neural Networks are provided in Section 2. Section 3 presents a detailed description of the proposed segmentation scheme. Quantitative metrics used to evaluate the segmentation algorithms are listed in Section 4. The experimental results and evaluations are discussed in Section 5, followed by concluding remarks in Section 6.This section consists of three subsections, which briefly explain SIST, SOM, and Modified-PCNN.SIST is a 2D multiscale image decomposition (MSD), and it is multi-directional, which is introduced to overcome the wavelet's drawback in capturing directional information; as a result, SIST, as shown in Fig. 1, can provide a better representation of the features of source images and give a representation of transforming coefficients in horizontal and vertical cones. SIST comprises two stages: directional localization followed by multi-scale partitioning. In the multi-scale partitioning, the shift invariance can be achieved by using the non-subsampled pyramid filter scheme [24], in which the Gibbs phenomenon is largely suppressed. In the directional localization, the frequency area is decomposed into a low-frequency sub-band and several high-frequency sub-bands using the shift-invariant shearing filters. Any input image can be decomposed into coarser coefficients, which provide an approximation of the original image, and finer coefficients, which provide the detailed information of the features, such as the edges and corners.A SOM is a feed-forward neural network that uses a competitive learning algorithm and maps high-dimensional inputs to a 2D pattern of neurons. It classifies input data into several patterns according to a similarity factor, such as Euclidean distance or minimum distance.A simple SOM consists of two layers: the input layer, which accepts the external input signals, and the output layer, which is arranged in a 2D structure. Every input neuron is connected to every output neuron, and each connection has a weighting value attached to it, as in [25], and works as follows:(i)Initialize the weight by taking random values as wi=[μi1, μi2, ……., μin] and set the learning iteration number t=0. SOM consists of a set of neurons that build a feature map, and each neuron i has a weight vector wi.Find the winning neuron j that has the closest distance Dmin(t) to the input pattern x(t) via:(1)Dmin(t)=mini∑j(xj(t)−wij(t))2The adjustment weight vector entries for the winning output neuron (win) are:(2)wi(t+1)=wi(t)+μ(t)*(x−wi(t))foralli∈Nj(3)wi(t+1)=wi(t)Otherwisewhere μ(t) is the learning rate function, wiis the weight of the winning node and t is the iteration number. We define a neighbourhood order function DH(t) as follows:(4)α(t)=α0exp−t2T(5)dh(t)=α0exp−t2TSet t=t+1; if t<T, go to Step 3, and otherwise stop.PCNN attempts to simulate a biological neuron; specifically, it simulates the visual cortex of the human brain. The visual cortex of humans is an essential part of the brain that is responsible for handling visual information. A PCNN consists of many neurons arranged in a 2D structure [26]; each neuron in the network represents information from a single pixel of the input image. Recently, PCNN has experienced noticeable growth in image processing applications, especially image enhancement, segmentation and information fusion. Many researchers have proven [14] that PCNN is not much affected by the presence of input or the variation of input patterns. A PCNN neuron consists of three parts: the “input part, linking modulation, and pulse generator.”However, PCNN suffers from the drawbacks of having many parameters that need to be tuned and the pseudo-Gibbs phenomena. The Gibbs Phenomenon is the manner in which the transformed image behaves at a jump discontinuity, that is, the frequency that comes with large oscillations near the singularity points (edges). To reduce this effect, we use the spatial frequency [27,28] as a balance to motivate the neurons via Eq. (2). SF is a way to measure the coefficients gradient in the row and column directions; it is usually calculated using a moving window. In our scheme, SF is calculated for each sub-band and used as an input to the PCNN.In the following, we consider the simplified model for modified PCNN, where Iijthe coefficient used to calculate the spatial frequency Sijlocated at i, j in the image. Uij, F1ijand θijdenote the internal activity of a neuron, the symmetrical feed channel and the dynamic threshold, respectively.(6)Sij=∑i=1M∑j=1N(Iij−Ii−1,j)2+(Iij−Ii,j−1)2(7)Fij(n)=normalizedSFSij(8)Lij(n)=VL∑abWij,abYab(n−1)(9)Uij=MaxFij(n)[1+βijLij(n)](10)θij(n)=exp(−αθ)θij(n−1)+VθYij(n−1)(11)Yij(n)=1Uij(n)>θij(n)0otherwiseEach neuron receives the inputs from two different sources, namely, its own information (intensity) and the neighbouring pixel's information (Sij), in binary form. The linking input Lij(n) mixes both inputs using the linking coefficients βijand accumulates information for both through iterative cycles until a certain threshold θijis exceeded. Yijis the output of a neuron that comprises information for further image segmentation processing.• Procedures with PCNN parameters and training informationFor each pixel in the image, {The network external stimulus receives different pixel information.The neighbourhood pixels transmit its information to the network internal stimulus.The linking and modulation part of the network do {Mix and accumulate both types of received stimuliCompare the stimulus accumulated value with a predefined thresholdDecrease the threshold value gradually through different iterationsf the accumulated value is greater than the thresholdFire the neuron};The threshold increases simultaneouslyThe output of the neuron is then iteratively fed back to the element with a delay of one iterationOur proposed segmentation scheme depends mainly on combining the SOM neural network and the modified-PCNN, where SOM is used to divide the input image into different classes, while PCNN augments the segmentation results. First, we apply an anisotropic filtering [29] to the input image. This is a way to improve the quality of textures via an input image.Low (coarser) and high (finer) sub-band coefficients of the de-noised image are extracted through SIST. Texture information (entropy and skewness) is calculated from coarser coefficients.Entropy and skewness constitute the feature vector. The SOM network uses this vector, which is accompanied by coarser coefficients of the input image, to segment the input coefficients through unsupervised processes. The inverse SIST represents a preliminary classification of the input image.Modified-PCNN is used to enhance the classification results by eliminating over-segmentation, which is defined as “the process by which the objects being segmented from the background are themselves into subcomponents”. In the following subsections, a detailed description of the proposed scheme is introduced.(i)The presence of noise in the images leads to an incorrect image segmentation result. In our scheme, we use anisotropic diffusion [30] as a pre-processing step. It thins unnecessary edges and preserves edge sharpness.Decompose the denoised output image using SIST into coarser coefficients that provide an approximation of the original image and finer coefficients that provide the detailed information about the features.Extract the features of the images by using a sliding window along the average finer SIST coefficients of the image.Using only SIST coefficients in the segmentation process leads to imprecise results because these inputs only characterize the intensity values of the input image. Consequently, we used texture information (entropy and skewness) in our scheme to better describe the input image, and this information is used as ancillary information in the segmentation process. The procedure of extracting texture features is described in Fig. 2.(i)Entropy [30] is a measure of randomness in an image; it has a larger value for more random inputs, while consistent values of image intensity lead to a low value of entropy. The entropy is defined as:(12)Entropyi=∑x=1M∑y=1NIi(x,y)(−lnIi(x,y))M×Nwhere x and y represent the pixel location in an image with a size of N×M.Skewness measures the asymmetry of the image distribution about its mean [30], and its value can be positive, negative, or even undefined.(13)Skewness=∑x=1M∑y=1NIi(x,y)−μ3M×N×σ2where x and y represent the pixel location in an image with a size of N×M. μ and σ denote the mean and standard deviation, respectively. We define a Feature Vector as {FV={Coarsercoeff(xn, ym)Entropy;Skewness}, which can contain texture features and coarser image coefficients (Fig. 3).(a)The Feature Vector (FV) is input into the SOM network to segment the coarser coefficients of the input image. The output value of each output class is assigned to the mean value (from the original RGB image) of the pixels that belong to this class. The preliminary segmented image is obtained by taking the inverse-SISTBecause the SOM drawback occurs when increasing the number of neurons in the network, it does not usually result in better segmentation performance and has a high-dimensional input space with empirical features for optimal performance. Therefore, SOM networks cannot efficiently segment images with heavy noise. Thus, we apply Modified-PCNN to the segmented output image of SOM to overcome the over-segmentation, which might be caused by the presence of noise and enhance the segmented output image. We have presented the steps of the proposed Modified-PCNN segmentation model as follows:(i)Initialize the networkEach pixel of the input image is considered to be a neuron. The pixel grey value is the external input of the neurons, that is, Fij(n)=normalized SF Sij, as in Section 2.3, where a normalized SF Sijis the pixel value after normalization. Set Y as 0 and θ such that all values of its elements are the grey level of the pixel that has the highest value and initialize F as S.Initialize the parameters of the PCNN model. Set αθas follows:(14)αθ=Cμwhere C is a constant, μ is the mean grey level, and αθis the threshold decay time constant.Calculate Lij(n), Uij, θij(n), and Yij(n) and run the network(15)Tij(n)=Tij(n−1)+Yij(n)If the process has been running a given number of times, then go to the next step; otherwise, go to the previous step. Suppose G[i] of the i-th iteration has the highest value; then, R[i] is selected as the segmentation result. Thus, we obtain a final segmented output image. We summarize the proposed scheme as pseudocode snippet, which is shown in Table 1.Several quantitative measures are used to evaluate the results. Supervised evaluation methods are used by comparing the segmented image with ground truth reference samples. The unsupervised evaluation methods do not use a reference image; instead, they depend on a set of statistical properties of segmented images, described as follows:(i)Liu and Yang proposed a factor F(I) to measure the intensity error of the sub-regions [31]; F(I) is calculated as follows:(16)F(I)=11000×ARR∑i=1Rei2Aiwhere ‘I’ represents the output-segmented image with size ‘AR.’ The segmented image consists of ‘R’ sub-regions. Assuming that Aiis the average error of the ith region in the segmented image, the error is calculated with respect to colour information. Let eirepresent the summation of Euclidean distances between pixel intensities in the input and segmented images. Lower values of F(I) indicate better segmentation results, and vice versa.Borsotti extended F(I) by eliminating sub-regions of the same small size [32].(17)F′(I)=11000×SI∑a=1mareaN(a)1+1/a∑j=1Nei2SjIn this, the input image (I) is segmented into N(a) sub-regions in a pre-defined area (S), and the maximum area of the output-segmented image is represented by “Marea.”Q(I) is the modified version F′(I) proposed by Borsotti [32],(18)Q(I)=11000×SIN∑j=1Nej21+logSj+N(Sj)Sj2N(Sj) depicts the number of segmented regions contained in a predefined area (Sj).Error Rate (ER) was proposed by Francisco [33](19)ER=(Nf+Nm)Nt×100%ER represents the ratio between false and mis-segmented image pixels (Nfand Nmrespectively) and the total number of image pixels (Nt).Jaccard [34] measures use the in situ measurements to evaluate the segmentation results.(20)J=Area(A∩B)Area(A∪B)where A and B demonstrate the ground truth information and segmentation results, respectively.The dice similarity metric [34,35] measures a set agreement between segmented and ground truth information. Its formula is:(21)D=2A∩BA+Bwhere A and B demonstrate the ground truth information and segmentation results, respectively.In this section, we present a set of results to validate our proposed scheme. We first begin with a description of the image databases that were used in our experiment. Afterward, we evaluate the efficiency of our scheme via both qualitative and quantitative measures. We also discuss the parameter selection criteria. Finally, our proposed scheme is compared with state-of-the-art methods.For the purpose of assessment and comparison with other image segmentation techniques, we used a different type of digital image: the Berkeley dataset [36] and Quick-Bird satellite images. From the Berkeley dataset, we picked two different examples demonstrating medical and photographic images; the ground truth information was taken from the “Berkeley Segmentation Database” (BSD). Quick-Bird images are 360×360 pixels in size and have a 5-m spatial resolution. They represent a part of Hurghada City, Egypt.The following discussion presents a comparison between the proposed scheme and other segmentation methods. The competence is introduced first by using visual assessment followed by quantitative evaluation in the subsequent sections. Input images and the corresponding outputs are shown in Figs. 4–6. To facilitate the comparison task, the output images of all of the segmentation algorithms are divided into five categories and assigned a unique colour: green for vegetation, yellow for buildings, blue for bodies of water, black for shadows, and others representing different types of land-use (Fig. 7).In Fig. 4, we show a satellite Quick-Bird test image with a size of 360×360 pixels (see Fig. 4(a)). The image represents an area of Hurghada in Egypt. Our output segmentation result is shown in Fig. 4(b), the FCM-Clustering segmentation result is shown in Fig. 4(c), and the SOM segmentation result is presented in Fig. 4(d).The Quick-Bird satellite image is a good example of an image with high variation; it contains many objects with different texture, for example, the sea surface contains smooth water and shallow and deep water. In the same direction, the shadow of the building and the water show the same pixel value but have significantly different textures, buildings, etc.In Fig. 5, we see that the proposed scheme efficiently separates the brain from the background due to the use of texture features and the combination of SOM and PCNN in the frequency domain rather than traditional methods, such as the SOM method alone or the PCNN method alone and the Convex-Relaxed Kernel [5]. Fig. 6 shows medical test images.Figs. 4–7 show comparisons of our segmentation results using PCNN, SOM, the Convex-Relaxed Kernel method and the proposed scheme for medical, satellite and natural input images. The output images reveal the fact that our scheme achieved the best performance. We used 10 images and the corresponding ground truth from the database, but we formed the ground truth in the proposed scheme from the Berkeley Segmentation Database (BSD), as in Fig. 7.In Fig. 7, we see the star natural image, the corresponding ground truth from the BSD database, and a better-segmented output image.To conclude, we propose a methodology for image segmentation that is capable of introducing enhanced segmentation results. Compared with other techniques, such as FCM-Clustering [3], SOM, the Convex-Relaxed Kernel [5], and PCNN, our scheme not only introduces regular segmentation classes but also reserves a small feature from mis-classification.Tables 2a and 2blist the calculated values of F(I), F′(I), Q(I) and ST (Standard Deviation) for the tested images for the Quick-Bird satellite image and medical image, respectively; it can be observed that the proposed scheme has the finest (smallest) value.We observed that Q(I) of the proposed scheme is the finest value and that these results lead to the fact that the proposed scheme introduces the least intensity errors for segmented regions, allowing them to be more precise with less deformation, while other techniques provide a mis-classification error.These results lead to the conclusion that the proposed scheme qualitatively outperforms the PCNN, SOM, Convex Relaxed Kernel, and FCM-Clustering techniques.Alternately, the Jaccard measures show a slight improvement over other techniques, as shown in Table 3. SOM yields the best results, followed by PCNN and FCM. This is due to the Jaccard method accumulating the error from one class to the next.Table 4presents a quantitative evaluation (ER), which is the direct measure of mis- and false-segmented images. FCM-Clustering yields the worst accuracy, and SOM, Convex-Relaxed Kernel, and PCNN have almost the same segmentation error. The proposed method attained a noticeable improvement in error rate.Furthermore, to assess the different algorithms regardless of the presence of noise, different levels of noise were added to the input images, followed by the application of segmentation procedures. Table 5lists the quantitative comparison for dice similarity with respect to the presence of noise. All of the methods show almost consistent values with noise levels of up to 10%, with a slight improvement of the proposed method.The accuracy of the simple segmentation process is much affected by the presence of noise because the segmentation process depends mainly on its grey level intensity [37]; to overcome the noise and obtain precise segmentation results, we should take into consideration the neighbourhood information of each pixel. Yao et al., firstly estimated the noise level in the image, followed by a competitive neural network (SOM) as a segmentation tool [37].This illustrates that the proposed scheme is capable of producing excellent segmentation results with a noise presence of up to 20%. This is due to the use of the modified-PCNN to reduce the oversegmentation caused by the presence of noise.The design issues of the proposed scheme include two types of parameters that need to be selected and adjusted, namely, the SOM and PCNN parameters. The following discussion gives a brief introduction to the required parameters.Various parameters directly affect the construction of SOM: the organization of the training sets, number of neurons in each layer, weight initialization, the updating of the connections between different layers, the value of the learning rate and the activation function. Table 6lists the parameters used in this study. Training sets represented by feature vectors are firstly normalized and then arranged in sequential form.PCNN has many tuneable parameters that directly affect the network performance. The question of which value is suitable in general remains open, and the choice mainly depends on the application. In the modified PCNN, the parameters are adjusted through successive iterations. The parameter values have been selected from different image samples. Table 7lists the set of parameters used for image segmentation.The proposed scheme was coded in MATLAB Version R2014a and run on an Intel R Core i7 4800M CPU, running at 2.9GHz, with 6 Gigabytes of RAM under the 64-bit Windows operating system. The number of feature vectors and the CPU time of different numbers of training pixels were based on different local homogeneity thresholds. It can be seen that although the number of feature vectors, the training time, and the segmenting time are changed by varying degrees as the number of training pixels increases, the classification accuracy is only slightly changed. The computational complexity of the SOM is k2, where K is the number of map units: each learning step requires O(k) computations. The computational time of PCNN is O(nk2) Finally, the total complexity is O(nk2).Table 8displays the computational time required to process a Quick-Bird satellite image. The fastest method is the proposed scheme, followed by the PCNN method, FCM method and SOM method.Generally, the proposed image segmentation scheme attained competitive results, as it gives relatively good results in terms of various segmentation indices for satellite and medical images and the best subjective segmentation quality for most images compared to state-of-the-art segmentation algorithms, including the Fuzzy C-Means clustering algorithm [3], SOM algorithm [9], Convex-Relaxed Kernel Mapping [5] and PCNN algorithm methods [10]. Fig. 8shows the comparison of different algorithms with the proposed scheme. The results of these algorithms used for comparison are all from their corresponding references. One can see that the proposed scheme almost outperforms the other methods at different noise levels. The performance of our scheme increases with the reduction of noise intensity. When there is a low noise level of 1% or 3%, the dice coefficients of our proposed scheme are higher than 95% for both the SOM and FCM-Clustering segmentation results. The performance of correct classification of the test data sets was 94%. These results prove that the performance of classification was suitable. It is hard to attain perfect classification rates using neural networks based on certain selected features.

@&#CONCLUSIONS@&#
The segmentation of images into proper classes is a difficult process, especially for high-resolution images. Mis-classification is a dominant problem in all segmentation algorithms. In this paper, the integration of SOM and modified PCNN is used for image segmentation to create an optimal utilization of them. SOM provides a method to classify the input image space into segments based on unsupervised competitive learning, while modified PCNN uses a supervised approach to reduce the over-segmentation close to segment boundaries. The entire segmentation process is conducted in a transformed domain using SIST; this provides a multi-resolution and better directional representation of the input images. Additionally, the texture feature of an input image is used as extra information to make the classification results more precise. The experimental results based on the SOM, PCNN, Convex Relaxed Kernel, and Fuzzy-C-Means algorithms demonstrate that the proposed scheme succeeds in dividing the image into proper classes with minor mis-classification. A closer look shows that the evidence is overwhelming: the aggregation of supervised and unsupervised classification decreases the classification error rate by 25%, and providing the texture information in the segmentation process increases the classification accuracy by 30%. Another significant finding is the robustness of the proposed scheme in the presence of noise. This is due to use of the modified PCNN as a second classifier stage to improve the over-segmentation caused by either false classification of the first stage or the presence of noise.Summarize a full function description of PCNN parameters used through the learning process, that affect directly on the quality of the output.ParametersDescriptionsFeed channelsijThe feeding channel decay by amount of αF, a higher value indicates rapid decayVFRepresents the intervention between candidate pixels and its neighbored. Increasing this value will lead to more influence from the neighbored pixels.WIt is defined as the size of area consists of the neighbouring pixels. It signifies the synaptic weight strengthLink channelLijThe feeding channel decay by amount of αL, a lower value leads to gentle decayVLRepresents the amount of interference between neighbored pixel and candidate neuron.WRefers to the size of area consists of the neighbouring pixels of the corresponding pixel in the input image. It determines the synaptic weight strengthPulse GeneratorTConsidered a weighting factor of linking channel in linking and modulation activity.θijDetermine at what time the neuron should fire, it represents the rate of decay of the threshold in a different iteration.