@&#MAIN-TITLE@&#
Structure constrained semi-nonnegative matrix factorization for EEG-based motor imagery classification

@&#HIGHLIGHTS@&#
Structure constrained semi-NMF method for motor imagery classification.The mean envelopes of ERP are extracted as structural constraints.Enables the analysis of temporal patterns of general EEG time series by semi-NMF.The temporal patterns extracted by SCS-NMF can be combined with other features.

@&#KEYPHRASES@&#
EEG,Brain computer interface,Motor imagery classification,Event-related potential,Structure constraint,Semi-nonnegative matrix factorization,

@&#ABSTRACT@&#
BackgroundElectroencephalogram (EEG) provides a non-invasive approach to measure the electrical activities of brain neurons and has long been employed for the development of brain-computer interface (BCI). For this purpose, various patterns/features of EEG data need to be extracted and associated with specific events like cue-paced motor imagery. However, this is a challenging task since EEG data are usually non-stationary time series with a low signal-to-noise ratio.New methodIn this study, we propose a novel method, called structure constrained semi-nonnegative matrix factorization (SCS-NMF), to extract the key patterns of EEG data in time domain by imposing the mean envelopes of event-related potentials (ERPs) as constraints on the semi-NMF procedure. The proposed method is applicable to general EEG time series, and the extracted temporal features by SCS-NMF can also be combined with other features in frequency domain to improve the performance of motor imagery classification.ResultsReal data experiments have been performed using the SCS-NMF approach for motor imagery classification, and the results clearly suggest the superiority of the proposed method.Comparison with existing methodsComparison experiments have also been conducted. The compared methods include ICA, PCA, Semi-NMF, Wavelets, EMD and CSP, which further verified the effectivity of SCS-NMF.ConclusionsThe SCS-NMF method could obtain better or competitive performance over the state of the art methods, which provides a novel solution for brain pattern analysis from the perspective of structure constraint.

@&#INTRODUCTION@&#
Brain-computer interface (BCI) aims at establishing an efficient communication channel between human brain and manipulatable device, and therefore has a broad range of real-life applications such as assisting humans with severe disabilities [1]. Existing BCI systems can measure and interpret brain activities evoked by either exogenous or endogenous stimuli, and motor imagery is a representative endogenous event that one can initiate by imaging certain limb or other motions. Electroencephalogram (EEG) is a non-invasive measurement approach that records the electrical activities of brain neurons along the scalp, and it has long been considered as an effective method providing important information for motor imagery analysis and classification [2].Since the focus of this study is to develop a decomposition-based method for identifying EEG patterns in time domain, here we only review the related work on pattern extraction; for classification algorithms like support vector machine used in EEG-based BCIs, the reader is referred to Lotte et al. [3]. EEG data are frequent measurements of electrical signals, it is therefore natural to investigate their frequency domain features such as event-related synchronization (ERS) and event-related desynchronization (ERD) [4,5] after fast Fourier transform (FFT), wavelet transform or Hilbert–Huang transform (HHT) [6]. EEG data are also high-dimensional non-stationary time series with a poor signal-to-noise (SNR) ratio [3,7], it is thus more challenging to identify the useful temporal patterns in time domain. Nevertheless, the concept of event-related potential (ERP), defined as the time-locked average of EEG signals in response to a repeated event, has been introduced into EEG data analysis to improve the SNR [8]. The key temporal patterns embedded in ERPs can then be extracted using decomposition methods such as principle component analysis (PCA) [9] and independent component analysis (ICA) [10]. In particular, the nonnegative matrix factorization (NMF) methods [11–13] have received increasing attention due to its capability of decomposing data into physically meaningful parts. More importantly, unlike the orthogonality assumption in PCA and the independency assumption in ICA, the NMF methods do not make such assumptions on data and are thus applicable to a broader range of problems.In the past decade, many NMF variants have been proposed by incorporating different penalties into the original NMF objective function. Ding et al. [12] proposed the semi-NMF and convex NMF methods; the semi-NMF method relaxes the non-negativity constraint and thus allow negative entries in the results, and the convex NMF forces the basis vectors to be a convex combination of input data and introduces sparsity into the results implicitly. Li et al. [14] proposed a local nonnegative matrix factorization (LNMF) method by introducing sparsity and redundancy restrictions to obtain a minimum number of basis vectors to achieve better locality. The sparseness constraint in Hoyer’s work [15] has a form similar to that of the LNMF. Cai et al. [16] developed the graph regularized nonnegative matrix factorization (GNMF) method, which introduces the inter-sample geometric similarity as an extra proximity constraint on sample representation. A constrained nonnegative matrix factorization (CNMF) was developed by Liu et al. [17] with the label information imposed as a hard constraint.In the methods mentioned above, the PCA and ICA methods make the orthogonality and the independence assumption, respectively, which may not be valid to brain signals. In addition, note that EEG time series can take positive or negative values, which makes the conventional NMF methods inapplicable. Therefore, among all the NMF variants described above, we select the semi-NMF method proposed by Ding et al. [12] and extend it to address the temporal pattern extraction problem for EEG data. This idea is different from those of several previous studies, which applied the NMF method to brain signals (after wavelet transform or short-time FFT) in the frequency domain [18–21]. The SCS-NMF method developed in this paper extracts the temporal EEG patterns, which are physically meaningful, and thus enables the time-domain analysis of brain signals in a pure additive manner. We thus believe that SCS-NMF provides a useful alternative for temporal EEG pattern analysis.A key question that has not been sufficiently addressed in previous studies is what temporal patterns embedded in ERPs in response to the same cue- or self-paced event should be extracted and used for motor imagery classification. In this study, we consider a data-driven approach, which directly learns the temporal patterns from data without feeding it on any prior knowledge. More specifically, we borrow the idea from the empirical mode decomposition (EMD) step in HHT, which extracts the upper and lower envelopes of non-stationary time series via cubic spline interpolation [6]. We thus calculate the mean envelopes of ERPs by averaging the upper and lower envelopes, and hypothesize that these mean envelopes are the common patterns useful to motor imagery classification, based on the fact that the post-stimulus responses of brain to the same event are highly replicable [8]. We impose the mean envelopes of ERPs as structure constraints on the semi-NMF procedure such that the time series from each single trial can be decomposed into a linear combination of the basis temporal patterns. Finally, based on the coefficients of those linear combinations obtained via SCS-NMF, a linear support vector machine (SVM) is trained to classify the brain responses to the imagined motions. To the best knowledge of authors, this is the first time that semi-NMF is extended and introduced into BCI-related problems, which enables the pattern analysis of brain signals in time domain.The rest of the paper is organized as follows: the SCS-NMF method is described and theoretically justified in Section 2, the real data experiment results are shown in Section 3, and the conclusions are presented in Section 4.

@&#CONCLUSIONS@&#
