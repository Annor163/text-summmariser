@&#MAIN-TITLE@&#
Restricted risk measures and robust optimization

@&#HIGHLIGHTS@&#
We study uncertainty sets associated to coherent and distortion risk measures.By focusing on linear and affine random variables we justify the use of new uncertainty sets.These new sets are expansions of classical sets and are related to the expectation correction of a risk measure.These new sets can be used to mitigate estimation errors of the Conditional Value at Risk.

@&#KEYPHRASES@&#
Risk management,Stochastic programming,Uncertainty modeling,

@&#ABSTRACT@&#
In this paper we consider characterizations of the robust uncertainty sets associated with coherent and distortion risk measures. In this context we show that if we are willing to enforce the coherent or distortion axioms only on random variables that are affine or linear functions of the vector of random parameters, we may consider some new variants of the uncertainty sets determined by the classical characterizations. We also show that in the finite probability case these variants are simple transformations of the classical sets. Finally we present results of computational experiments that suggest that the risk measures associated with these new uncertainty sets can help mitigate estimation errors of the Conditional Value-at-Risk.

@&#INTRODUCTION@&#
Coherent risk measures and their relation to robust optimization have received significant attention in the literature (Artzner et al., 1999; Bertsimas and Brown, 2009; Natarajan et al., 2009; Shapiro et al., 2009; Ben-Tal et al., 2009; Wächter and Mazzoni, 2013). It is known that every coherent risk measure is associated with a precisely determined convex uncertainty set with properties that are strongly tied to the axioms characterizing coherent risk measures (e.g. Bertsimas and Brown (2009); Natarajan et al. (2009)). Similar results have also been given for a special class of coherent risk measures known as distortion risk measures, which include the widely used Conditional Value-at-Risk (Bertsimas and Brown, 2009; Pichler and Shapiro, 2013; Shapiro, 2013). All these characterizations are based on the restrictions imposed by the coherence or distortion axioms on the actions of the coherent risk measure over all possible random variables. However, in many settings, the random variables considered are either an affine or linear function of a, potentially correlated, vector of random parameters. A classical example is portfolio optimization (see for example Markowitz (1952); Konno and Yamazaki (1991); Black and Litterman (1992); Cvitanić and Karatzas (1992); Krokhmal et al. (2002); Zymler et al. (2011); Lim et al. (2011); Kawas and Thiele (2011); Fertis et al. (2012); Kolm et al. (2014)) where the random return of a portfolio is usually modeled as a weighted linear combination of the random returns of individual assets (with weights equal to the fraction invested in a given asset) plus a possibly null constant representing investment in a riskless asset. In this paper we show that imposing the coherence and distortion axioms only on random variables that are a linear, or affine linear function of a vector of random variables allows the inclusion of uncertainty sets that are deemed invalid by the classical characterizations. In particular, we show that in the finite probability case these additional sets at least include certain expansions of the classical sets. We also show that such expansions are in turn related to the common practice of taking the convex combination of a risk measure with the expected value. More specifically, we show that risk measures associated to these expansions are affine combinations of a risk measure with the expected value.Finally we present computational experiments that suggest that the risk measures associated with these uncertainty sets can help mitigate estimation errors of the Conditional Value-at-Risk.The rest of this paper is organized as follows. In Section 2 we give some notation and background on risk measures and robust optimization. In Section 3 we show the existence of uncertainty sets that do not fall in the classical characterizations, but do yield distortion risk measures on the subspace of random variables that are either affine or linear functions of a fixed random vector. In Section 4 we show that the risk measures associated to these uncertainty sets are affine combinations of a risk measure with the expected value. Then, in Section 5 we present some results of computational experiments showing that these uncertainty sets could be useful to mitigate estimation errors. Finally, in Section 6 we present some final remarks.Throughout the paper we will use bold letters to denote column vectors, and we will use an apostrophe to denote the transposition operation. Thus,x∈Rdis a column vector andx′ its transpose. We also noteeas the vector with a 1 in every component andeN:=1Ne. For a given setS⊆Rnwe denote byaff(S),conv(S)anderror(S)its affine, convex and closed convex hull respectively. We also letlin(S)be the linear space spanned by S andri(S)the relative interior of S. For a given convex set C we denote byext(C)the set of its extreme points. To denote index sets, we use [m] ≔ {1, …, m}.Let(Ω,F,P)be a probability space andL1(Ω,F,P)be the set of integrable random variables that are an outcome of the uncertain parameter in Ω. We use a tilde to identify random variables as ing˜∈L1(Ω,F,P).Definition 2.1A functionρ:L1(Ω,F,P)→Ris a coherent risk measure if it satisfies the following properties.(C1)Convexity:ρ(tg˜1+(1−t)g˜2)≤tρ(g˜1)+(1−t)ρ(g˜2)for allg˜1,g˜2∈L1(Ω,F,P)and t ∈ [0, 1].Positive homogeneity:ρ(tg˜)=tρ(g˜)for allg˜∈L1(Ω,F,P)and t > 0.Translation equivariance:ρ(t+g˜)=t+ρ(g˜)for allg˜∈L1(Ω,F,P)andt∈R.Monotonicity:ρ(g˜1)≤ρ(g˜2)for allg˜1,g˜2∈L1(Ω,F,P)such thatg˜1≤g˜2a.s.The following theorem gives another characterization of coherent risk measures (Shapiro et al., 2009, Theorem 6.4).Theorem 2.2Let(1a)Δ:={f∈L∞(Ω,F,P):∫Ωf(ω)dP(ω)=1}and(1b)Δ+:={f∈L∞(Ω,F,P):∫Ωf(ω)dP(ω)=1,f(ω)≥0a.s.}.Then a functionρ:L1(Ω,F,P)→Rsatisfies (C1)–(C3) if and only if there existsJ⊆Δsuch that(2)ρ(g˜)=supf∈J∫Ωg˜(ω)f(ω)dP(ω).The function additionally satisfies (C4) if and only ifJ⊆Δ+. Finally, if ρ satisfies (C1)–(C3), then it is additionally continuous. In that case, we have thatJis convex and weakly* compact.A relation between risk measures and robust uncertainty sets emerges when we focus on random variables that are affine or linear functions of a fixed d-dimensional random vectoru˜∈L1d(Ω,F,P)(i.e.u˜i∈L1(Ω,F,P)for each i ∈ [d]). For instanceu˜could be the random returns on d assets and we may be interested in analyzing random portfolio returns of the formg˜x(u˜(ω)):=∑i=1dxiu˜i(ω)wherex∈Rdindicates the fractions invested in each asset (i.e.x∈ [0, 1]dand∑i=1dxi=1). In general, this corresponds to restricting attention to the subspaces ofL1(Ω,F,P)given byV(u˜):={g˜∈L1(Ω,F,P):∃(x,x0)∈Rd×Rsuchthatg˜(ω)=g˜x,x0(ω):=x′u˜(ω)+x0}andV0(u˜):={g˜∈L1(Ω,F,P):∃x∈Rdsuchthatg˜(ω)=g˜x(ω):=x′u˜(ω)}.From now on we assume that the random vectoru˜∈L1d(Ω,F,P)is fixed and we simplify the notation toVandV0,to which we colloquially refer to as the spaces of affine and linear random variables.An advantage of restricting our attention toVor toVois that the effect of a coherent risk measure on such random variables can be interpreted using the language of robust optimization as follows. Let ρ be a risk measure satisfying (C1)–(C3) and letJ⊆Δbe a convex and weakly* compact set satisfying (2). Then, for anyg˜x,x0∈Vwe have(3)ρ(g˜x,x0)=supf∈J∫Ω(x′u˜(ω)+x0)f(ω)dP(ω)=x0+supu∈U(ρ)x′u,whereU(ρ):={∫Ωu˜(ω)f(ω)dP(ω):f∈J}⊆Rd.We have thatU(ρ)is the image of convex and weakly* compact setJunderM:L∞(Ω,F,P)→Rdgiven byMi(f):=∫Ωu˜i(ω)f(ω)dP(ω). Becauseu˜i∈L1(Ω,F,P)we have that M is linear and weakly* continuous and henceU(ρ)is a compact and convex set satisfyingU(ρ)⊆aff(supp(u˜)),wheresupp(u˜)is the support ofu˜. If ρ additionally satisfies (C4) thenJ⊆Δ+,and we have thatU(ρ)⊆error(supp(u˜)). In the robust optimization literature this setU(ρ)is usually denoted the robust uncertainty set and the following well known theorem (e.g. Theorem 4 of Natarajan et al. (2009)) states that its existence essentially characterizes coherent risk measures overV.Theorem 2.3ρ:V→Rsatisfies properties (C1)–(C3) of Definition 2.1 overVif and only if there exists a closed convex setU⊆aff(supp(u˜))such that(4)ρ(g˜x,x0)=x0+supu∈Ux′ufor everyg˜x,x0∈V. In such case we have that the setUsatisfying (4) is unique and equal to(5)U(ρ):={u∈Rd:x′u≤ρ(g˜x)∀x∈Rn}.Furthermore, ρ additionally satisfies property (C4) if and only ifU(ρ)⊆error(supp(u˜)).For the forward implication of the first equivalence note that because ρ is a real valued function that is convex and positive homogeneous overV0⊆V,we have thatρ(x′u˜)is a continuous sub-linear function ofx. Thenρ(x′u˜)=supu∈U(ρ)x′ufor the closed convex setU(ρ)defined in (5) (Theorem C-3.1.1 of Hiriart-Urruty and Lemaréchal (2001)). Now, letu0∈RdandL⊆Rdbe a linear subspace such thataff(supp(u˜))=L+u0. If x ∈ L⊥ thenx′u˜=x′u0a.s.and henceρ(x′u˜)=x′u0. Then, by (5) we have thatU(ρ)⊆{u∈Rd:x′u≤x′u0∀x∈L⊥}={u∈Rd:x′u=x′u0∀x∈L⊥}=L+u0=aff(supp(u˜)).The implication then follows from the translation equivariance property. The reverse implication is straightforward.For the forward implication of the second equivalence note thatU(ρ)⊆error(supp(u˜))is equivalent tosupu∈U(ρ)x′u≤supu∈supp(P)x′ufor allx. Ifsupu∈supp(u˜)x′u=∞this last inequality holds automatically. If not, by translation equivariance and positive homogeneity of ρ we haveρ(supu∈supp(u˜)x′u)=supu∈supp(u˜)x′u. Then, because ofx′u˜≤supu∈supp(u˜)x′uand monotonicity of ρ we havesupu∈U(ρ)x′u=ρ(x′u˜)≤ρ(supu∈supp(u˜)x′u)=supu∈supp(u˜)x′u.For the reverse implication note that ifU(ρ)⊆error(supp(u˜))andx′u˜(ω)+x0≤0a.s.thenρ(x′u˜+x0)=x0+supu∈U(ρ)x′u≤x0+supu∈supp(u˜)x′u≤0. Together with sub-additivity of ρ this implies that ifg˜x,x0≤g˜y,y0thenρ(g˜x,x0)≤ρ(g˜x−y,x0−y0)+ρ(g˜y,y0)≤ρ(g˜y,y0).□Note that in the proof of Theorem 2.3 necessity ofU(ρ)⊆error(supp(u˜))was because of dominance between a constant (supu∈supp(u˜)x′u) and a linear (x′u˜) random variable. In Section 4 we will see that this condition can sometimes be eliminated when we only consider linear random variables (i.e. if we restrict ourselves toV0).Remark 2.1It is also interesting to note the difference between the characterization of coherent risk measures overL1(Ω,F,P)given by Theorem 2.2 and the characterization of coherent risk measures over subspaceVofL1(Ω,F,P)given by Theorem 2.3. While any closed convex setJ⊆Δ+induces a convex uncertainty setU(J):={∫Ωu˜(ω)f(ω)dP(ω):f∈J}⊆error(supp(u˜)),the converse does not always hold. For instance, if we letu˜be uniformly distributed on a compact convex set C andu0 be an extreme point of C, we have thatU={u0}is a convex uncertainty set that will induce a coherent risk measure overVthrough (4). However, there is no f ∈ Δ+ such that∫Ωu˜(ω)f(ω)dP(ω)=ω0and hence by Theorem 2.2 and (3) there cannot be a coherent risk measure overL1(Ω,F,P)that coincides with this measure inV. Therefore the set of coherent risk measures overVis larger than those overL1(Ω,F,P). Note that, if we restrict ourselves to finite probability distributions, it is not too hard to prove that this difference vanishes. However, in Section 3, we show that this difference no longer vanishes for the so-called distortion risk measures.Definition 2.4A coherent risk measureρ:L1(Ω,F,P)→Ris a distortion or spectral risk measure if it satisfies the following additional properties.(D1)Comonotonicity:ρ(g˜1+g˜2)=ρ(g˜1)+ρ(g˜2)for allg˜1,g˜2such that(g˜1(ω1)−g˜1(ω2))(g˜2(ω1)−g˜2(ω2))≥0,∀ω1,ω2∈Ω.Law invariance:ρ(g˜1)=ρ(g˜2)for allg˜1,g˜2that have the same distribution.One of the most well known distortion risk measures is the Conditional Value-at-Risk which is given byCVaRδ(g˜):=inft∈R{t+1δE[(g˜−t)+]}.While some characterizations of distortion risk measures are given for more general probability distributions (e.g. see Shapiro 2013 and Pichler and Shapiro, 2013), we now concentrate on the uniform probability distribution with finite support. Results in this section can be found in, or are direct corollaries of results in Bertsimas and Brown (2009).For uniform discrete distributions we letsupp(P)={ωi:i∈[N]}⊆Ωfor whichP({ωi})=1Nfor all i ∈ [N]. In this setting we assume Ω = {ωi: i ∈ [N]} and thatFis the σ-algebra of all subsets of Ω. Furthermore, under these assumptions sets Δ and Δ+ defined in (1) becomeΔN:={q∈RN:∑i=1Nqi=1}andΔ+N:={q∈RN:∑i=1Nqi=1,qi≥0∀i∈[N]}.With this notation, every random variableg˜∈L1(Ω,F,P)is representable by means of a vectorg∈RNwheregi:=g˜(ωi)for all i ∈ [N]. Indeed, for finite probability spaces it is somewhat meaningless to considerL1(Ω,F,P)as allLp(Ω,F,P)are trivially equal to space of functions from Ω toR. However, we continue using this notation to have a consistent way of distinguishing risk measures that are defined over arbitrary functions of Ω from those that are only defined overVorVo.Theorem 2.5IfPis a finite uniform distribution over Ω = {ωi: i ∈ [N]}, ρ satisfies (C1)–(C3), (D1)–(D2) overL1(Ω,F,P)if and only if there existsq∈ ΔNsuch that(6)ρ(g˜)=maxσ∈SN∑i=1Nqσ(i)gi,where SNis the group of permutations of N elements. Furthermore, in this representation we can additionally chooseq∈Δ^N:={q∈ΔN:q1≥…≥qN}. Finally, ρ further satisfies (C4) overL1(Ω,F,P)if and only ifqadditionally belongs toΔ+NorΔ^+N:={q∈Δ^N:qN≥0}. In both cases we have that(7)U(ρ)=Πq(u˜):=conv({∑i=1Nqσ(i)ui:σ∈SN})whereui=u˜(ωi)for each i ∈ [N].For notational convenience we again drop the dependence of Πqonu˜.Example 2.2Let δ ∈ [0, 1] be such thatδN∈Z+. ThenU(CVaRδ)=Πhδ(Ω)where(8)hjδ:={1δNj≤δN0otherwise.In this section we will prove that, even in the case ofPbeing a finite uniform distribution, there exists distortion risk measuresρ:V→Rthat are not induced by any distortion risk measureρ′:L1(Ω,F,P)→R. For this, we will need some previous technical lemmas.Lemma 3.1If0∈ri(conv(supp(u˜)))then for anyv˜∈Vo,v˜≥0a.s.impliesv˜=0a.s.Sincev˜∈Vo,then∃x∈Rdsuch thatv˜(ω)=x′u˜(ω),∀ω∈Ω. From this,v˜≥0a.s.implies thatx′u˜(ω)≥0,∀ω∈supp(u˜). Ifx= 0 the result is direct. By contradiction, assume that there existsuo∈supp(u˜)such thatx′uo> 0. Now, since0∈ri(conv(supp(u˜))),there exists U a relatively open neighborhood of 0 withinconv(supp(u˜)). However, becauseuo∈aff(conv(supp(u˜))),there exists ɛ > 0 such thatɛuo,−ɛuo∈U⊆conv(supp(u˜)). Then, there must existsu1∈supp(u˜)such thatx′u1 has the same sign asx′( − ɛuo) < 0 which contradictsv˜≥0a.s..□Lemma 3.1 implies that if0∈ri(conv(supp(u˜))),then, condition (C4) is moot forVo.We then get the following refinement of Theorems 2.3 and 2.5 for linear random variables.Corollary 3.2If0∈ri(conv(supp(u˜))),then1.ρ:V0→Rsatisfies (C1)–(C4) overV0if and only ifU(ρ)⊆aff(supp(u˜))andρ(g˜x)=supu∈U(ρ)x′u.IfU(ρ)=Πqforq∈Δ^Nandρ(g˜x)=supu∈U(ρ)x′u,then ρ satisfies (C1)–(C4), (D1)–(D2) overVo.For 1 note that the first part of the proof of Theorem 2.3 shows thatρ:V→Rsatisfies properties (C1)–(C3) overV0if and only ifU(ρ)⊆aff(supp(u˜))andρ(g˜x)=supu∈U(ρ)x′u. To obtain the first equivalence it only remains to show that ifU(ρ)⊆aff(supp(u˜)),then ρ satisfies property (C4) overV0. For this letg˜i:=xi′u˜(ω)for i ∈ {1, 2} be such thatg˜1(ω)≤g˜2(ω)a.s. Then(x2−x1)′u˜(ω)≥0a.s.and hence by Lemma 3.1 we have(x2−x1)′u˜(ω)=0a.s.Henceg˜1(ω)=g˜2(ω)a.swhich impliesρ(g˜1)=ρ(g˜2)and condition (C4) holds.Statement 2 follows similarly from Theorem 2.5 and Lemma 3.1.□Using this corollary we can characterize inclusion relations between family of sets inducing coherent, or distortion risk measures for the case0∈ri(conv(supp(u˜))). For this, we introduce the following definitions:Definition 3.3LetW,V,Vothe set of coherent risk measures defined overL1(Ω,F,P),V,Vorespectively; and letW*,V*,Vo*the set of distortion risk measures defined overL1(Ω,F,P),V,Vorespectively. We will denoteU(·)as the family of sets that induce all risk measures in a given set.Note that, form the definitions above, we always have thatU(H*)⊆U(H)for anyH∈{W,V,Vo}. With these definitions, we can write the following result:Corollary 3.4If0∈ri(conv(supp(u˜))),then1.U(Vo)={U⊆aff(supp(u˜)):Uisclosedandconvex}andU(W)⊆U(V)={U∈U(Vo):U⊆error(supp(u˜))}.Hence,U(V)andU(W)can be strictly contained inU(Vo).IfPis a finite uniform distribution then{Πq:q∈Δ^N}⊆U(Vo*)andU(W*)={Πq:q∈Δ^+N}⊆U(V*)⊆U(V).Hence,U(V*)andU(W*)can be strictly contained inU(Vo*).The characterizations are direct from Corollary 3.2 and Theorems 2.2, 2.3 and 2.5. In particular, the potential lack of equality betweenU(W)andU(V)comes from Remark 2.1. For the first potential strict containment it suffices to find a closed convex setU⊆aff(supp(u˜))such thatU⊈error(supp(u˜)). For the second it suffices to findq∈Δ^Nsuch thatΠq⊈error(supp(u˜)).□Corollary 3.4 shows that, when0∈ri(conv(supp(u˜))),there are somewhat reasonable uncertainty sets for random variables inVothat are not induced by coherent and distortion risk measures overL1(Ω,F,P)orV. However, those sets include points outsideerror(supp(u˜)). Remembering that the risk measure withU(ρ)=error(supp(u˜))corresponds to the worst case over all possible realizations of the random variable, we conclude that a risk measure with ρ′ witherror(supp(u˜))⊊U(ρ)would be clearly over-conservative. Considering an uncertainty set that neither contains nor is contained inerror(supp(u˜))is a bit more reasonable, but it still somewhat strange to include points outsideerror(supp(u˜))in the risk evaluation. To avoid this philosophical issue we now concentrate on the following result, which holds irrespective of the assumption0∈ri(conv(supp(u˜))).Corollary 3.5LetPbe a finite uniform distribution for which 0 is not necessarily contained inri(conv(supp(u˜))). Then(9)U(W*)={Πq:q∈Δ^+N}⊆{Πq:q∈Δ^N,Πq⊆error(supp(u˜))}⊆U(Vo*),U(V*)Direct from Theorems 2.3 and 2.5.□From this corollary, the existence of an actually reasonable uncertainty set for random variables inVoandV(i.e. one that is contained inerror(supp(u˜))and induces measures that satisfy (C1)–(C4), (D1)–(D2)) that is not induced by coherent and distortion risk measures overL1(Ω,F,P),reduces to the possibility of a strict containment in (9). We now show that the first containment can indeed be strict.To show this strict containment we need to findq∈Δ^Nsuch thatΠq⊆error(supp(u˜))and for which there is nor∈Δ^+Nsuch that Πq= Πr. For this, note that, for anyr, by definition, we have thatΠr=conv({∑i=1Nrσ(i)ui:σ∈SN}); but each term∑i=1Nrσ(i)uican be re-written as M · Pσ·r; where M = (u1|…|uN) and Pσis a permutation matrix (i.e.e′Pσ=e′ and Pσe=e) that depends on σ. Also, note that if we know all vertices {vk}k ∈ [m] of Πq, then, for Πqto be equal to Πrfor somer, we need at least that eachvkis the image of some permutation matrix Pσ, i.e. ∃Pkpermutation matrix such thatvk= M · Pk·r. Proposition 3.6 expresses this idea as an optimization problem.Proposition 3.6For a givenq, let {vk}k ∈ [m] be the set of extreme points of Πq. If there existsr∈Δ^+Nsuch that Πq= Πr, then, the following optimization problem has optimal value zero.(10a)min∑k∈[m]∥sk∥1(10b)s.t.vk=M·Pk·r+sk∀k∈[m](10c)e′Pk=e′∀k∈[m](10d)Pke=e∀k∈[m](10e)ri≥ri+1∀i∈[N](10f)e′r=1(10g)Pk∈{0,1}N×N∀k∈[m](10h)sk∈Rd∀k∈[m](10i)r∈R+NProblem (10) has as variables the vectorssk,rand binary matrices Pkfor k ∈ [m]. Conditions (10c), (10d) and (10g), ensure that Pkis a permutation matrix; conditions (10e), (10f) and (10i) ensure thatr∈Δ^+N,while condition (10b) just says that eachvk= M · Pk·r+sk. To finish, just note that the objective function (10a) can only be zero when allskare zero, and thus ensuring that eachvkcorresponds to one of the points generating the set Πr.□Note that in the previous result, (10) having optimal value 0 is not a sufficient condition for Πq= Πr, since it only ensures that Πq⊆Πr. However, we show that for a particularq, problem (10) has non-zero optimal value.Lemma 3.7There existq∈Δ^Nsuch thatΠq⊆error(Ω)andΠq≠Πq′for allq∈Δ^+N.Let d = 2, N = 5,supp(u˜)={(8600,5000),(5700, 8100), (1300, 9900), ( − 9600, 3000), (8500, −5200)} andq= (27/100, 27/100,27/100,27/100,−2/25)∈Δ^N. Using a symbolic computation software it is checked thatext(Πq)={(905,3866),(1920, 2781), (3460, 2151), (7275, 4566), (940, 7436)} andΠq⊆error(Ω). Furthermore, using the exact MIP solvers developed in Espinoza (2006); Cook et al. (2011), we were able to computationally prove that the optimal objective value of (10), for this data, is greater than or equal to 1000.Note that the exact MIP solvers from  Espinoza (2006); Cook et al. (2011) can only solve linear MIP problems and problem (10) is a nonlinear MIP problem. However, (10) can easily be transformed into a linear MIP as follows. The first step is to linearize the products between Pkandrin (10b) using a standard technique (e.g. Adams and Sherali (1986)). For this we introduce matrix variablesGk∈ [0, 1]N × Nfor all k ∈ [m]. This matrix will be such thatGi,jk=Pi,jk·rjfor all i, j and k,rj∈ [0, 1] andPi,jk∈{0,1}. To achieve this we add the set of linear inequalities given byGk≤Pk∀k∈[m]Gi,jk≤rj∀i,j∈[N],k∈[m]Pi,jk+rj≤Gi,jk+1∀i,j∈[N],k∈[m].We then simply replacePk·rin (10b) withGke. Finally, to linearize the objective function we introduce variablesspk,smk∈R+dfor all k ∈ [m], replaceskin (10b) withspk−smkand replace the objective function with ∑k ∈ [m]spk+smk.□Corollary 3.5 and Lemma 3.7 show that there are indeed reasonable uncertainty sets (distortion risk measures) for random variables inVandVothat are not induced by coherent and distortion risk measures overL1(Ω,F,P). However, while theoretically interesting, the conditions for constructing or detecting these sets can be highly intractable. For this reason, in the next section we present a more practical representation of the uncertainty sets Πqforq∈Δ^N.From Lemma 3.7 we know that there exists risk measures represented byq∈Δ^Nwhose uncertainty sets do not coincide with any risk measure inΔ^+N. However, it is possible to give a different characterization of these uncertainty sets, providing a natural geometrical interpretation of these measures.Consider for example the finite uniform probability over the N = 5 points insupp(u˜)={ui}i=1n={(8600,5000),(5700, 8100), (1300, 9900), ( − 9600, 3000), (8500, −5200)} andq=(27/100,27/100,27/100,27/100,−2/25)∈Δ^Nused in Lemma 3.7. We can check thatq= ɛq′ + (1 − ɛ)eNforq′=(1/4,1/4,1/4,1/4,0)∈Δ^+Nand ɛ = 7/5. Note that it is not a convex combination but an affine combination, because ɛ > 1. Fig. 1shows Πqin solid blue,Πq′in dashed red anderror(supp(u˜))in dotted green. The figure also showssupp(u˜)as asterisks andu¯:=1N∑i=1nuias a plus sign. We can see from the figure that Πqis an expansion ofΠq′around the meanu¯that is still contained inerror(supp(u˜)). In this section we show that this figure is representative of allq∈Δ^Nin that for such vectors Πqis always an expansion ofΠq′for someq′∈Δ^+N. This implies that the risk measures associated with elements inΔ^Nare always an affine combination of a distortion risk measure overL1(Ω,F,P)and the expected value. When ɛ ∈ [0, 1], this convex combination is a well known modification of a risk measure (e.g. see Lagos et al. (2011) and Eq. (6.68) in Shapiro et al. (2009)), note however that in this case, ɛ is not restricted to be within [0, 1], as it can take values above 1. Hence the associated measure is an affine combination of a distortion risk measure overL1(Ω,F,P)and the expected value. Because the uncertainty sets associated to these measures are scalings of the traditional sets, we denote these new measures as epsilon scalings.Definition 4.1For a given risk measureρ:L1(Ω,F,P)→Rand ɛ ≥ 0 let the epsilon scaling of the measure beρ^APTARAVAREPSILONε(v˜):=ɛρ(v˜)+(1−ɛ)E[v˜].It is straightforward to show that if ρ is a distortion risk measure overS⊆L1(Ω,F,P)then, for any ɛ ∈ [0, 1],ρ^APTARAVAREPSILONεis also a distortion risk measure overS. It is also easy to see that for ɛ ≥ 0 the only property thatρ^APTARAVAREPSILONεmay fail to inherit is monotonicity. Fortunately, forS=VorS=Vowe can give simple conditions forρ^APTARAVAREPSILONεto be a distortion risk measure. To give these conditions note that the uncertainty set associated withρ^APTARAVAREPSILONεisU(ρ^APTARAVAREPSILONε)=u¯+ɛ(U(ρ)−u¯)whereu¯:=E[u˜].Proposition 4.2Let ɛ ≥ 0, ρ be a distortion risk measure overVandPbe an arbitrary distribution.1.Ifu¯+ɛ(U(ρ)−u¯)⊆error(supp(u˜)),thenρ^APTARAVAREPSILONεis a distortion risk measure overVandVo.If0∈ri(conv(supp(u˜))),thenρ^APTARAVAREPSILONεis a distortion risk measure overVoeven ifu¯+ɛ(U(ρ)−u¯)⊈error(supp(u˜)).Direct from Lemma 3.1, Theorem 2.3 and the preservation of (D1) and (D2) under linear combinations.□If we restrict to finite uniform distributions we can show that epsilon scalings precisely correspond to the uncertainty sets associated with elements inΔ^N.Proposition 4.3IfPis a finite uniform distributions, then{Πq:q∈Δ^N}={U(ρ^APTARAVAREPSILONε):ɛ≥0andρ∈W*}.Forq∈Δ^N∖Δ^+Nlet ɛ ≔ 1 − NqN> 0 andq′:=1ɛ(q+(ɛ−1)eN). Thenq= ɛq′ + (1 − ɛ)eN, ɛ ≥ 0 andq′∈Δ^+N. The result then follows from Corollary 3.4.□In this section we present a computational example that shows that epsilon scalings seem to be less susceptible to estimation errors when approximated using samples. The need for such estimations is common in applications (e.g. Lagos et al. (2011); Vielma et al. (2009)) and, unfortunately, risk measures such as the Conditional Value-at-Risk (CVaR) measure have been shown to be highly susceptible to estimation errors in this setting (Lim et al., 2011). For this reason we study how using the epsilon scaling of CVaR could help alleviate these estimation errors. Following an approach similar to that in Lim et al. (2011) we consider a simple portfolio optimization problem, in which we have d possible assets we want to invest over a single time period, and we have to decide what proportion of our capital we will invest in each of the assets. Every asset i has a return ri∈ [ − 1, ∞), such that if we initially invested Cion i then at the end of the period we will have Ci(1 + ri). When the vectorr≔ (r1, …, rd)′ of returns is known this problem is formulated as max {x′r:x′e= 1,x≥ 0}. Naturally the vector of returnsris subject to uncertainty, hence it is necessary to adopt some decision scheme that considers the risk inherent to the problem. Let(Ω,F,P)be a probability space and letr˜∈L1d(Ω,F,P)be the random vector of returns. Interpreting−x′r˜as the random losses of the portfolio, a classic and well studied approach to this problem is to minimize the Conditional Value-at-Risk of the losses:(11)zδ*:=minx{CVaRδ(−x′r˜):x′e=1,x≥0},whereCVaRδ(v˜):=mint{t+1δE[(v˜−t)+]}. If the distribution ofr˜is known, then (11) is a well defined convex optimization problem which can be solved in theory. However, evaluating CVaR requires multidimensional integration and hence solving (11) is, in general, intractable. Furthermore, more often than not, the distribution ofr˜can only be accessed through a finite number of samples. A common data-driven approach for this issue is to use this finite number of samples to approximate the integrals in the definition of CVaR with the sample mean. This approximation technique is known as Sample Average Approximation (SAA) for stochastic programming and its convergence is assured under very broad settings, see e.g. Shapiro et al. (2009, Section 5.1.1). Assume then that we have a finite i.i.d. sampler1,…,rN∈Rdof the vector of returnsr˜(e.g. from past observed returns or simulations). The SAA version of (11) is given by(12)zδ,N*({ri}i=1N):=minx{CVaRδN(−x′r˜,{ri}i=1N):x′e=1,x≥0},whereCVaRδN(−x′r˜,{ri}i=1N):=mint{t+1δN∑i=1N[−x′ri−t]+}is CVaRδfor the case in whichr˜is uniformly distributed in{ri}i=1N. For notational convenience we drop the dependence ofzδ,N*,CVaRδNand related values, on{ri}i=1N,while noting that any value or solution derived from (12) is dependent on the N samples ofr˜and hence is random unless the sample is fixed. With this in mind, it is well known that, under mild conditions,zδ,N*converges tozδ*w.p. 1 as N grows to infinity and that, under slightly stronger conditions, the optimal set of (12) also converges w.p. 1 to the optimal set of (11) (e.g. Shapiro et al. (2009, Section 5.1)). Furthermore, from Rockafellar and Uryasev (2002); 2000) we have that (12) is equivalent to(13)minx,t{t+1δN∑i=1N[−x′ri−t]+:t∈R,x′e=1,x≥0}.Note that this problem can be formulated as linear programming problem, which can be easily solved. Unfortunately, as noted in Lim et al. (2011), for moderate values of N and small values of δ, the optimal solutions of (12)/(13) can have a significant difference between their sampledCVaRδNand their real CVaRδ. Furthermore, the real CVaRδof these solutions can be far fromzδ*. More specifically, ifxN*is an optimal solution to (12)/(13) it is common to haveCVaRδN(xN*)≪zδ*≪CVaRδ(xN*). We aim to useCVaR^γ,ɛ(i.e., an epsilon scaling of CVaRγwith γ not necessarily equal to δ) to construct a variant of (12)/(13) with optimal solutions that reduce both these gaps. Our motivation for this construction can be best illustrated if we consider elliptical distributions, which have the following convenient characterization ofU(ρ)that we prove in Appendices  A and  B. The use of this characterization will come from the equivalence between approximating CVaRδwithCVaRδNand approximatingU(CVaRδ)withU(CVaRδN)Lemma 5.1Letμ∈Rd,B∈Rd×dbe a non-singular matrix and letr˜∈L1d(Ω,F,P)be such thatu˜x:=x′B−1(r˜−μ)has the same continuous probability distribution for everyx∈Sd−1:={x∈Rd:∥x∥2=1}(e.g.r˜is the uniformly distribution over the ellipsoid{r∈Rd:∥B(r−μ)∥2≤1}orr∼N(μ,BB′)). Then, for any distortion risk measure ρ we have(14)U(ρ)={r∈Rd:∥B−1(r−μ)∥2≤ρ(u˜x0)}wherex0 is an arbitrary element of Sd − 1.Ifr˜is distributed as in Lemma 5.1 with B = I and μ = 0, thenU(CVaRδ)is an Euclidean ball for any δ. In turn, the characterization from Example 2.2 shows that, ifδN∈Z+,thenU(CVaRδN)is the convex hull of the(NδN)points inΩ^hδ:={∑i=1Nhσ(i)δri:σ∈SN}forhδdefined in (8) (Ω^hδcorresponds to all averages of δN points from{ri}i=1N). Now, it is well known that to obtain a good approximations of the Euclidean ball by a set of the formconv(Ω^hδ)we need the number of extreme points of this set to be quite large (see Ball (1997)). While it is hard to predict the number of extreme points ofconv(Ω^hδ),it is likely to be a non-decreasing function of|Ω^hδ|=(NδN). Hence, we would then expect the approximation ofU(CVaR0.5)byU(CVaR0.5N)to be much better that the approximation ofU(CVaRδ)byU(CVaRδN)for small δ. This aligns with the SAA approximation issues of CVaRδbeing worse for small δ. Unfortunately, small values of δ are precisely the ones needed to incorporate appropriate levels of risk aversion and it is unlikely thatU(CVaR0.5N)will provide a good approximation ofU(CVaRδ)for δ ≪ 0.5. However, by noting that bothU(CVaR0.5)andU(CVaRδ)are Euclidean balls (just with different radii), we have thatU(CVaR0.5N)is indeed a good approximation of a scaling ofU(CVaRδ)for δ ≪ 0.5. Conversely, for any δ an appropriate scaling ofU(CVaR0.5N)will be a good approximation ofU(CVaRδ). More precisely, if r0.5 is the radius ofU(CVaR0.5)and rδis the radius ofU(CVaRδ),thenU(CVaRδ)=(rδ/r0.5)U(CVaR0.5)and hence we expect(rδ/r0.5)U(CVaR0.5N)to be a better approximation ofU(CVaRδ)thanU(CVaRδN)(at least for small δ). The potential advantage of usingCVaR^γ,ɛemerges by noting that scalings ofU(CVaR0.5N)are precisely the uncertainty setsU(CVaR^0.5,ɛN)ofCVaR^0.5,ɛfor an appropriately chosen ɛ. We formalize this in the following corollary that shows how to calculate the appropriate ɛ for elliptical distributions and all values of δ. Note that the proposition can be directly extended toCVaR^γ,ɛfor values of γ other than 0.5.Corollary 5.2Letμ∈Rd,B∈Rd×dbe a non-singular matrix and letr˜∈L1d(Ω,F,P)be such thatu˜x:=x′B−1(r˜−μ)has the same continuous probability distribution for everyx∈Sd−1:={x∈Rd:∥x∥2=1}. Then,U(CVaRδ)=U(CVaR^0.5,ɛ)forɛ=CVaRδ(u˜x0)CVaR0.5(u˜x0),wherex0 is an arbitrary element of Sd − 1.Note thatCVaR^0.5,ɛ(u˜x0)=ɛCVaR0.5(u˜x0)+(1−ɛ)E(u˜x0)=ɛCVaR0.5(u˜x0)=CVaRδ(u˜x0).□The following example provides a graphical illustration of the advantage of usingU(CVaR^0.5,ɛN)overU(CVaRδN)to approximateU(CVaRδ).Example 5.1The uncertainty set associated with CVaR1/8 for a three-dimensional standard normal distributedr˜corresponds to a sphere of radius 1.6468 centered at the origin. Fig. 2shows the uncertainty sets associated withCVaR1/8N(left) andCVaR^0.5,ɛN(right) for a sample of N = 8 random points (with ɛ selected as in Corollary 5.2). The uncertainty set associated withCVaR1/8Nhas six vertices and eight faces. In contrast, the uncertainty set associated withCVaR^0.5,ɛNhas 30 vertices and 56 faces and seems to give a closer approximation of the ball.Corollary 5.2 shows that(15)z0.5,ɛ*:=min{CVaR^0.5,ɛ(−x′r˜):x′e=1,x≥0}is equivalent to (11) ifr˜is elliptically distributed and ɛ is chosen as in the corollary (in particularz0.5,ɛ*=zδ*). Furthermore, Example 5.1 illustrates how the SAA version (12)/(13) of (11) is not equivalent to the SAA version of (15) given by(16)z0.5,ɛ,N*:=minx{CVaR^0.5,ɛN(−x′r˜):x′e=1,x≥0},whereCVaR^0.5,ɛN(−x′r˜):=ɛmint{t+10.5N∑i=1N[−x′ri−t]+}−(1−ɛ)1N∑i=1Nx′ri. However, Example 5.1 also suggests that (16) is likely to provide a better approximation of (11) than (12)/(13). While the equivalence between (11) and (15) no longer holds for general distributions, (16) might still provide a better approximation than (12)/(13). In particular, it is still reasonable to expect thatU(CVaR^0.5,ɛN)has a richer structure thanU(CVaRδN)as the former is constructed by taking a larger number of partial averages of the sample points. This could have a smoothing effect similar to the one depicted in Fig. 2, which could provide more stability for small sample sizes. Still, as N grows, we can only guarantee thatCVaR^0.5,ɛNconverges toCVaR^0.5,ɛ,and this last risk measure may not be equivalent to CVaRδfor any δ. However, Corollary 3.4 shows thatCVaR^0.5,ɛis a valid risk measure on its own right, which validates the use ofCVaR^0.5,ɛNindependent of its potential approximation of CVaRδ. Nonetheless, in the next two subsections we test quality of this potential approximation on both elliptical and non-elliptical distributions. We end this section with two observations. The first one concerns the calculation of the scaling factor ɛ for non-elliptical distributions. While Corollary 5.2 no longer provides a precise formula we could still follow its general idea and choose(17)ɛ≈CVaRδ(−x′r˜)−E[−x′r˜]CVaR0.5(−x′r˜)−E[−x′r˜]for some fixedx∈ Sd − 1. Our approach will be to select a SAA approximation of this ratio.Our final observation is that, similar to (13), (16) is also equivalent to the convenient problem given by(18)min{ɛ(t+10.5N∑i=1N[−x′ri−t]+)−(1−ɛ)x′r¯:t∈R,x′e=1,x≥0}wherer¯:=1N∑i=1Nri,which can be also easily formulated as a linear programming problem.We begin our experiments with a Gaussian distribution as it satisfies the conditions of Corollary 5.2 and it also allows for the exact solution of (11). To generate the data for our experiments we utilize the same historical data for 200 stocks listed in SP-500 used in Vielma et al. (2008) to estimate the mean vector μ and covariance matrix Σ of these assets. We then assume that the real distribution of the assets is Gaussian with this mean and covariance. Hence, by Lemma 5.1, we have that (11) is equivalent to the second-order conic problem given by(19)zδ*=minx,t{CVaRδ(ν˜)·t−x′r¯:x′e=1,∥Σ1/2x∥2≤t,x,t≥0}whereν˜∼N(0,1).Our objective is to compare the approximation effectiveness ofCVaRδNandCVaR^0.5,ɛNfor this problem, with a particular emphasis on the quality of the obtained feasible portfolios. For this we proceed as follows for each δ ∈ {0.01, 0.1}.1.Generate N i.i.d. samples from our real distributionN(μ,Σ).Solve the sampled CVaR problem (13) and save the optimal solutionxCVaRδN*.Computeɛ(δ)=CVaRδ(ν˜)CVaR0.5(ν˜)forν˜∼N(0,1).Solve the sampledCVaR^0.5,ɛ(δ)Nproblem (18) and save the optimal solutionxCVaR^0.5,ɛ(δ)N*.PlotCVaRδ(−x′r˜)versusCVaRδN(−x′r˜)forx∈{xCVaRδN*,xCVaR^0.5,ɛ(δ)N*}.Repeat steps 1–5 100 times.Fig. 3shows the results for this experiment. Blue xs correspond toxCVaRδN*and green circles correspond toxCVaR^0.5,ɛ(δ)N*. The vertical magenta line shows the exactzδ*as computed by (19), and the diagonal blue line corresponds to equal values for the real and sampled CVaR. As expected (e.g. Shapiro et al. (2009, Proposition 5.6)), the sampled CVaR consistently underestimates the real CVaR and this effect is more significant for δ = 0.01. However, the epsilon scaling tends to reduce this downward bias. More importantly, the epsilon scaling reduces variability of both the sampled and real CVaR of the optimal solutions and tends to provide better solutions to the original problem.The increased concentration along the real CVaR axis of the epsilon scalings solutions can be particularly advantageous when considering hard-to-solve optimization problems. Estimating the real CVaR of a particular solution can be significantly easier than approximating the whole CVaR function. Hence, if we can generate a relatively large number**Large enough to have variety, but still significantly smaller than all feasible solutions.of potentially good solutions, it is reasonable to estimate the real CVaR and pick the best one. For instance, if we look at the best among the traditional solutions (the blue x further to the left) we can see that it is a relatively good solution. However, generating enough solutions to guarantee we find such best solution may not always be computationally feasible. For example, if we consider portfolio optimization problems with limited diversification or cardinality constraints problem (11) becomes a mixed integer problem that can be very hard to solve (Vielma et al., 2008). Hence, in some cases, a more realistic comparison may be to simulate the effect of solving a single instance of the appropriate optimization problem by randomly selecting one of the traditional solutions (blue x’s) and one of the epsilon scaling solutions (green circles). We explore this evaluation in Table 1where we also study the effect on the results of the number of samples and the number stocks.Table 1 shows results for portfolio sized of 20 and 200 stocks, δ ∈ {0.1, 0.01} and sample sizes of N = 100, 500 and 10, 000. Column Best Solution shows the smallest value ofCVaRδ(−x′r˜)over the 100 repetitions for eachx∈{xCVaRδN*,xCVaR^0.5,ɛ(δ)N*}. This is intended to illustrate the case in which the optimization problem is easy to use and we can generate several candidate solutions, evaluate them and select the best. In contrast, column Average Solution shows the average value ofCVaRδ(−x′r˜)over the 100 repetitions. This is intended to illustrate the case in which the optimization problem is hard to solve and only one or very few solutions can be generated (i.e. we expect this average to be representative of a typical single solution). Finally, columnzδ*shows the exact optimal value obtained through (19). We can see that the epsilon scaling yields better solutions for all parameters and metrics. This advantage is particularly strong for the metric of average solution and small number of samples and δ. In Appendix  B we show how this advantage is increased further when we allow short-selling in the portfolio problem (i.e. when we remove the non-negativity constraint on x variables).To study a case in which the conditions of Corollary 5.2 do not hold we repeat the previous experiment assuming that returns follow a uniform and a normal-inverse gaussian distribution. In the first case, each stock has a returnri=μi+η˜i,whereη˜iare independent random variables uniformly distributed in [ − 1, 1]. Note that in this caseU(CVaRδ)for different δs are not scalings of one another. In the second case, we assume that rifollows a multivariate normal-inverse Gaussian distribution, which is a heavy-tailed distribution commonly used on finance. In this latter case, we assume that stocks have a returnr=μ+τυ(Aas et al., 2006) whereυ∼N(0,Σ)and τ follows a generalized inverse Gaussian distribution of parameters λ = −0.5, χ = 1 and ψ = 1 (following the notation of Prause (1999)).On both cases, even evaluating CVaRδrequires multidimensional integration. For this reason we compute the scaling factor ɛ in step 3 as the sampled estimation of (17), given byɛ=CVaRδM(−x′r˜)+1M∑i=1Mx′riCVaR0.5M(−x′r˜)+1M∑i=1Mx′riwherexis the solution obtained in step 2, and M = 100, 000.As explained in Shapiro et al. (2009, Section 5.6.1), it is possible to estimate a lower bound ofzδ*using the law of large numbers computing the average and the variance ofCVaRδN(xCVaRδN*)over the 100 repetitions. We use this bound in Figs. 4 and 5to replace the exact value calculated with (19), which is not applicable here. We now use a vertical dashed magenta line to emphasize that it is only a lower bound that holds with high probability and not the exact value ofzδ*. Similarly, this bound in Tables 2 and 3is labeled asz̲δ*.We again see that the epsilon scaling provides an advantage, particularly for small number of samples and δ. Furthermore, while the gap between the traditional CVaR and the epsilon scaling is virtually eliminated for very large number of samples (N = 10, 000), the epsilon scaling still provides better solutions in both metrics. Again, results for problems where we allow short-selling are included in Figs. B.1–B.3of Appendix  B.

@&#CONCLUSIONS@&#
We have shown that, at least for finite uniform distributions, the family of uncertainty sets associated with distortion risk measures over affine or linear random variables is strictly larger that those associated with distortion risk measures over arbitrary random variables. In particular, we have shown that certain expansions of uncertainty sets associated with distortion risk measures also yield distortion risk measures over affine or linear random variables. This effectively expands the family of uncertainty sets with favorable theoretical properties. To study the potential advantage of these additional uncertainty sets we have included some preliminary experiments that suggest that these expansions could be useful to mitigate estimation errors.We finally note that the additional uncertainty sets we have considered still do not give a precise characterization of the family of uncertainty sets associated with distortion risk measures over affine or linear random variables. In particular, it is easy to find examples where the law invariance property is also moot for linear random variables. For example, consider Ω = { − 1, 0, 2} with the uniform probability. In this space a linear random variable is represented by a scalar x and its realizations are given by { − x, 0, 2x}. It is easy to see that the random variables associated with x and y have the same distribution only if − x = 2y and − y = 2x. The only solution to this system is x = y = 0 and hence there are no non-trivial linear random variables with the same distribution. More general settings might not completely eliminate the possibility of non-trivial linear random variables with the same distribution. However, a significant limitation of such random variables could validate the use of additional uncertainty sets. Still, it is likely that any characterization of these yet additional sets will be highly dependent on the specific structure of Ω.