@&#MAIN-TITLE@&#
Impact of Word Error Rate on theme identification task of highly imperfect human–human conversations

@&#HIGHLIGHTS@&#
Review of the impact of dialogue representations and classification methods.We discuss the impact of discriminative words in terms of transcription accuracy.Original study evaluating the impact of the WER in the LDA topic space.

@&#KEYPHRASES@&#
Speech analytics,Human–human dialogue,Latent Dirichlet allocation,Topic representation,Principal component analysis,Classification performance study,

@&#ABSTRACT@&#
A review is proposed of the impact of word representations and classification methods in the task of theme identification of telephone conversation services having highly imperfect automatic transcriptions. We firstly compare two word-based representations using the classical Term Frequency-Inverse Document Frequency with Gini purity criteria (TF-IDF-Gini) method and the latent Dirichlet allocation (LDA) approach. We then introduce a classification method that takes advantage of the LDA topic space representation, highlighted as the best word representation. To do so, two assumptions about topic representation led us to choose a Gaussian Process (GP) based method. Its performance is compared with a classical Support Vector Machine (SVM) classification method. Experiments showed that the GP approach is a better solution to deal with the multiple theme complexity of a dialogue, no matter the conditions studied (manual or automatic transcriptions) (Morchid et al., 2014). In order to better understand results obtained using different word representation methods and classification approaches, we then discuss the impact of discriminative and non-discriminative words extracted by both word representations methods in terms of transcription accuracy (Morchid et al., 2014). Finally, we propose a novel study that evaluates the impact of the Word Error Rate (WER) in the LDA topic space learning process as well as during the theme identification task. This original qualitative study points out that selecting a small subset of words having the lowest WER (instead of using all the words) allows the system to better classify automatic transcriptions with an absolute gain of 0.9 point, in comparison to the best performance achieved on this dialogue classification task (precision of 83.3%).

@&#INTRODUCTION@&#
Automatic Speech Recognition (ASR) systems frequently fail on noisy conditions and high Word Error Rates (WER) make difficult the analysis of the automatic transcriptions. Speech analytics suffer from these transcription issues that may be overcome by improving the ASR robustness and/or the tolerance of speech analytic systems to ASR errors. This paper proposes a global study to improve the robustness of speech analytics by first comparing word representations as well as classification methods and the impact of WER in topic space learning process, on the theme identification task (Bechet et al., 2012) in the application framework of the RATP call centre (Paris Public Transportation Authority).Telephone conversation is a particular case of human–human interaction whose automatic processing encounters many difficulties, especially due to the speech recognition step required to obtain the transcription of the speech contents. First, the speaker behavior may be unexpected and the training/test mismatch may be very large. Second, speech signal may be strongly impacted by various sources of variability: environment and channel noises, acquisition devices, etc.Themes are related to the reason why the customer called. Various classes corresponding to the main customer requests are considered (lost and founds, traffic state, timelines, etc). In addition to classical problems in such adverse conditions, the topic-identification system should face issues to classes proximity. For example, a lost and found request is related to itinerary (where was the object lost?) or timeline (when?), that could appear in most of the classes. In fact, these conversations involve a relatively small set of basic concepts related to transportation issues. Fig. 1shows an example of a dialogue manually labeled by the agent as an issue related to an infraction. However, words in bold suggest that this conversation could also be related to a transportation card issue.Agents then annotate a conversation with what they consider the major theme of the customer request: as a result, a single theme is associated for each conversation.In the context of Information Retrieval (IR) tasks, the main feature used is the term frequency that allows to obtain a subset of discriminative11The term “discriminative” is associated to a word if it permits to discern a class from the others.words for a considered class. This set of discriminative words should permit to compose a vector representation of conversation themes in the semantic space. Its application to automatic transcriptions is more difficult since transcription errors would lead to an incorrect word representation. Thereby, we assume that dialogues have to be considered in an intermediate thematic representation to fully perform this multiple themes’ complexity. For this reason, the projection of the automatically transcribed words in a more abstracted space could increase the robustness to the Automatic Speech Recognition (ASR) errors.Thus, we propose to first explore a term frequency representation, with the TF-IDF-Gini method, and a topic space representation, with a latent Dirichlet allocation (LDA) approach (Blei et al., 2003), coupled with a classification method to automatically identify themes from highly imperfect automatic transcriptions. The other main issue is the choice of the best classification method that does not modify the dialogue topic representation.In the second part of this paper, the classical SVM method (Yuan et al., 2012), that modifies the word representation with a kernel function, is compared with a Naive Bayesian classifier, that does not modify it. We assume that this study will highlight the fact that these two assumptions are relevant: the Gaussianity of the theme classes and the equality of the class covariances.The task is in the context of automatic transcriptions from an Automatic Speech Recognition (ASR) system. Thus, the impact of the transcription performance has to be evaluated. This article then discusses about the impact of the Word Error Rate (WER) for discriminative and non-discriminative words chosen by both methods in terms of transcription accuracy (Morchid et al., 2014). This part leads to consider the WER during the theme identification task itself. For this reason, an original study of the impact of the WER during the learning process of the LDA topic space as well as during the theme identification task is proposed.This paper resumes the work carried out on a classification task using highly imperfect transcriptions. First of all, results obtained comparing two word representation methods with the same classification algorithm are described in (Morchid et al., 2014). Secondly, a comparison of performance between two classification methods is performed as reported in (Morchid et al., 2014). Finally, contribution of this paper is an original qualitative study that aims at highlighting the link between word transcription quality and dialogue classification performance. We propose to evaluate the impact of selecting a small subset of words having the lowest WER, instead of using all the words, for the topic-based representation allows the system to better classify automatic transcriptions.The paper is organized as follows. Section 2 presents the related work. The dialogue representation approaches and the classification methods are described in Sections 3 and 4. Sections 5 and 6 report experimental results and a classification performance analysis, before concluding in Section 7.

@&#CONCLUSIONS@&#
In this paper, we first resumed an architecture to identify conversation themes using two different word representations and two different classification methods. We showed that the proposed topic-based representation using a LDA-based method outperforms the classification results obtained by the classical TF-IDF-Gini approach. The classification accuracy reaches 86.6% on manual transcriptions and 81.4% on automatic transcriptions with a respective gain of 6.8 and 7.9 points.The second part of the work focused on choosing the best classification method. We highlighted that the intuitions about the Gaussianity of the theme classes and the equality of the class covariances discussed in this paper are effective. Thus, the topic representation using a Gaussian classifier method outperforms the classification results obtained by the classical SVM approach. The accuracy reaches 87.4% on manual transcriptions and 83.3% on highly imperfect automatic transcriptions with a first respective gain of 0.8 and 1.9 points.We also discussed the possible link between classification performance and transcription accuracy. The proposed analysis showed that the best classification results are obtained on configurations which extract the discriminative words having a lower Word Error Rate (WER). Overall, the Section 6.2 points out that the WER is inextricably related to the topic model quality and therefore, to the theme identification accuracies. The analyse in Section 6.2.3 demonstrates that a trade-off between WER and number of words has to be found. These two remarks are underlined in Fig. 13 where a choice of a vocabulary of words with a WER≤50% is a good trade-off between enough vocabulary size to describe each theme and a set of robust (to automatic transcriptions) set of words. We therefore observe a better accuracy in the theme identification task (84.2) with a significant gain of 0.9 points (see Table 2) when a subset of words with low WER are selected to compose the vocabulary.A perspective would be to propose a solution to estimate the classification performance depending on the transcription accuracy. In the context of evaluation metrics, it would also be interesting to find another way to estimate the accuracy of automatic transcriptions in the context of a specific task since the classical WER is not a good indicator of transcription quality in an applicative context.