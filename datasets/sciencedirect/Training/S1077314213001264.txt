@&#MAIN-TITLE@&#
A LSS-based registration of stereo thermal–visible videos of multiple people using belief propagation

@&#HIGHLIGHTS@&#
A stereo dense correspondence algorithm is proposed for visual–thermal close-range video surveillance.Proposed stereo model is an energy function that is minimized using efficient belief propagation.Local self-similarity is used as similarity metric and motion and color segmentation used as prior.Our method assigns accurate disparities for occluded people that are merged in a ROI.Our method outperforms MI-based local stereo dense correspondence approaches.

@&#KEYPHRASES@&#
IR camera,Visible camera,Dense stereo matching,Belief propagation,Local self-similarity,Multimodal video registration,

@&#ABSTRACT@&#
In this paper, we propose a novel stereo method for registering foreground objects in a pair of thermal and visible videos of close-range scenes. In our stereo matching, we use Local Self-Similarity (LSS) as similarity metric between thermal and visible images. In order to accurately assign disparities to depth discontinuities and occluded Region Of Interest (ROI), we have integrated color and motion cues as soft constraints in an energy minimization framework. The optimal disparity map is approximated for image ROIs using a Belief Propagation (BP) algorithm. We tested our registration method on several challenging close-range indoor video frames of multiple people at different depths, with different clothing, and different poses. We show that our global optimization algorithm significantly outperforms the existing state-of-the art method, especially for disparity assignment of occluded people at different depth in close-range surveillance scenes and for relatively large camera baseline.

@&#INTRODUCTION@&#
In the recent years, by reduction in the price of infrared sensors, there has been a growing interest in visual surveillance using thermal–visible imaging system for civilian applications. The advantages of jointly using a thermal camera with a visible camera have been discussed comprehensively in [1–4]. Combining visible and infrared information allows to better handling shadow, reflection, noise, misdetection, and missing information. The combined data enables better detection and tracking of people. Moreover, for human activity analysis, the joint use of thermal and visible data enables us to better detect and segment the regions related to the object that people may carry based on their temperature differences compared to the human body.A fundamental issue associated to data fusion of close-range thermal–visible imaging is accurately registering corresponding information and features of images with dramatic visual differences. For a close-range scene, matching corresponding features in a pair of visible and thermal videos is much more difficult than for a long-range scene. People might be in very different sizes due to their distances to the camera, in different poses, and at different levels of occlusion. They might have colorful/textured clothes that are visible in color images, but not in thermal images. On the other hand, there might be some textures observable in thermal images caused by the amount of emitted energy from different parts of the human body that are not visible in a color image. Due to the high differences between thermal and visible image characteristics, finding correspondence for entire scene is very challenging. Instead registration is focused on the foreground ROIs.The dense two-frame stereo correspondence is the only viable approach for registering possibly occluded objects at mutiple depths in the scene. Stereo matching is a well-studied subject for unimodal imaging system. An extensive taxonomy of two-frame stereo correspondence algorithms is described in [5]. However, this subject is new for multimodal visual surveillance applications. We summarize the problems associated to multimodal dense stereo as follows:•Dissimilar patterns. This problem is specific to multimodal dense stereo. It is caused by the different types of image modalities. The corresponding regions in two images might be differently textured or one textured while the corresponding one is homogenous.Depth discontinuities. This difficulty is caused by segmentation results that contain two or more merged objects at different depths in the scene. In this case, correct disparities might be significantly different between neighboring pixels located on the depth boundaries.Occlusions. Some pixels in one view might be occluded in the other view. Therefore they should not be matched with pixels in the other view.The main motivation of our proposed algorithm is the limitation of current approaches for registering occluded people ROIs. In this paper we present a global optimization algorithm for partial image ROI registration. we formulate a multimodal stereo matching in a Markov Random Fields (MRFs) framework using color and motion information as smoothness assumptions in order to elegantly handle depth discontinuities, occlusions, and non-informative pixels caused by dissimilar patterns (corresponding pixels that do not contain similar visual information). Applying global optimization to multimodal stereo problem is challenging since most similarity measures, which are used for color images, are not viable for multimodal images. We integrate LSS as similarity measure in our global optimization algorithm.The rest of the paper is organized as follows: The overview of the current multimodal registration approaches that gives insight about the limitations of exisiting methods is presented in Section 2. In Section 3, we describe the strengths of LSS as a viable image feature for matching thermal and visible images. In Section 4, the overview of our registration system is presented, and, in Section 5 each step of our algorithm is described in details. Our experiment is presented in Section 6 and demonstrate that our method is efficient for video surveillance applications and outperforms the current state-of-the-art method. Finally, in Section 7, we conclude this paper by describing the advantages and limitations of our algorithms.

@&#CONCLUSIONS@&#
In this paper, we proposed a stereo model for thermal–visible partial ROI registration using an efficient belief propagation algorithm that outperforms previous state-of-the-art stereo registration designed for close range video surveillance applications. We have tested our methods on two indoor videos, and presented registration results over 4900 frames. Our results demonstrate that our method assigns more accurate disparity to pixels related to depth discontinuity regions and that it is more stable for large disparity range compared to previous works [6,10,4].For video surveillance applications, processing time is an important factor. The processing time of our algorithm for each frame is approximately 2–6s using a 3.40GHz multi-core desktop processor, while for DV method, it is between 1 and 3s. For both methods, the processing time varies based on the number and size of foreground ROIs in the images and as more people are in the field of view of the cameras. Moreover, in our method, the number of iterations of belief propagation algorithm varies for different ROIs depending on the rate of for converging to the minimum energy (when between two consecutive iterations the energy over MRF nodes has not decreased). In our implementation we used lookup tables and parallel processing programming (openMP) in C++ to speed up the processing time significantly.The registered thermal and visible images obtained using our algorithm can be used for further data analysis including tracking, behaviour pattern analysis, and object categorization based on the complementary information provided by data fusion.