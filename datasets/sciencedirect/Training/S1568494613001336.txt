@&#MAIN-TITLE@&#
Modeling a shape memory alloy actuator using an evolvable recursive black-box and hybrid heuristic algorithms inspired based on the annual migration of salmons in nature

@&#HIGHLIGHTS@&#
Applying the evolving computation concept to train a dynamic black box capable of modeling shape memory alloy actuators.Proposing two novel hybrid systems based on cellular automated and self-organizing maps theory.Examining the potential of a recent spotlighted metaheuristic called “The Great Salmon Run” for real world applications.Elaborating on the performance of proposed method in dynamic environment.Analyzing the behavior of proposed shape memory actuator by using the MSE error at each step.

@&#KEYPHRASES@&#
Evolving computing (EC),Shape memory alloys (SMAs),Cellular automated (CA) meta-modeling,Self-organizing (Kohonen) maps (SOMs),The Great Salmon Run (TGSR) optimization algorithm,System identification,Incremental learning,

@&#ABSTRACT@&#
The purpose of current investigation is to engage two efficient evolvable neuro-evolutionary machines to identify a nonlinear dynamic model for a shape memory alloy (SMA) actuator. SMA materials are kind of smart materials capable of compensating any undergo plastic deformations and return to their memorized shape. This fascinating trait gives them versatility to be applied on different engineering applications such as smart actuators and sensors. As a result, modeling and analyzing of their response is an essential task to researchers. Nevertheless, these materials have intricate behaviors that incorporate the modeling with major dilemma and obstacles. In this research, two novel evolvable machines comprised recurrent neural network (RNN) and two novel hybrid heuristic methods nominally cellular automate and Kohonen map assisted versions of The Great Salmon Run (CTGSR and KTGSR respectively) optimization algorithm are developed to find a robust, representative and reliable recursive identification framework capable of modeling the proposed SMA actuator. To elaborate on the acceptable performance of proposed systems, several experimental tests are carried out. Obtained results reveal the promising potential of the evolvable frameworks for modeling the behavior of SMA as a complex real world engineering system. Furthermore, by executing some comparative tests, the authors indicate that both of their proposed hybrid heuristic algorithms outperform the sole version of TGSR as well as some other well-known evolutionary algorithms.

@&#INTRODUCTION@&#
Shape memory alloys (SMAs) are a class of smart materials that can compensate the induced plastic deformations and return to their original shape by different stimulus such as: thermal energy, electrical forces, magnetic forces, ultraviolet light, pH, and chemical energy. Having this behavior which is called shape memory effect (SME) enables these materials to contribute in many applications such as micro-actuation [1], aerospace [2], medical industry [3], vibration damping [4], robotics [5] and automotive [6]. Specifically, the SMA actuators can produce relatively large displacements and have a high force/weight ratio with respect to traditional actuators. Moreover, they offer the following advantages: simple design, smooth motion, easy miniaturization, bio-compatibility, noiseless operation, simplicity of actuation and low power consumption [7]. Accompanying these unique characteristics, its industrial applications are limited due to slow response speed and their inherent nonlinear behavior that makes them difficult to be controlled. However, the nuisances produced by these intrinsic weaknesses can be kept to a minimum using a precise model of the actuator and a robust and reliable controller. The efficiency of an SMA actuator depends on the performance of its controller, which in turn depends on the mathematical model of the SMA.Over the past couple of decades, a vast amount of researches have been carried out on modeling SMA actuators, particularly in capturing their hysteresis properties. Arai et al. [8] developed a nonlinear differential equation to detect the behavior of SMA actuators by fitting the proposed model to experimental data. Since the proposed model was not based on the actual physical governing equations, its performance cannot be guaranteed over the entire operating region. Liang and Rogers [9] proposed a nonlinear constitutive model that includes the hysteretic behavior. The proposed model includes many parameters that should be determined experimentally. Recently, Elahinia and Ahmadian [10,11] presented improved models of previous works supported by experimental studies. The Preisach model has also been used to model the hysteresis of the SMA [10]. Although this model explains the hysteresis characteristic and the minor loops, the formulation is based on experimental data and not on the actual process. This model is also not convenient for developing control strategies. All the proposed models include many parameters with a wide range for their values. These parameters are not constant and vary for different materials and working conditions. Therefore it is unavoidable to identify their values for each applications and usages using the related experimental data.Due to the complexity of the actuator behavior and the hard nonlinearity of the model structure, the identification algorithm is very important. Hence, adaptive identification and control of hysteresis in smart materials, including SMA, is an ongoing research. Soft computing is an interdisciplinary concept which comes to the aid of engineers in variety of applications such as complex system management [12], control [13], intelligent manufacturing [14], robotics [15,16], bio-mechanics [17], pattern recognition [18] and engineering optimization [19]. In recent years, regarding to these versatility and immense number of promising reports in literatures, researchers have switched to the application of soft and intelligent computational methods to model both nonlinear and hysteric behaviors of engineering systems instead of implementing tedious mathematical models. The main provocations for this eagerness can be regarded in two main aspects. Firstly, the appeal of designing a self-imposed dynamic model (black box identifier) unrelated to the knowledge of any expert user. Secondly, the appeal of developing a robust identification model with acceptable generalization capability. Although the dynamic black box identification systems have several advantages, their performance and accuracy strictly relate to the training strategy. Devising an efficient training methodology is the most important step in designing a nonlinear artificial identification system. Up to now, several deterministic and stochastic algorithmic methods have been proposed to provide an efficient training approach that guarantees the maximum generalization of dynamic identification models. Luitel and Venayagamoorthy [20] proposed a quantum inspired particle swarm optimization (PSO-QI) for training a multi input multi output (MIMO) recurrent neural network (RNN). They observed that RNN can effectively learn MIMO systems when trained using PSO-QI. Xu et al. [21] investigated the performance of particle swarm optimization (PSO), differential evolutionary (DE) and hybrid of DE and PSO (DEPSO) to train RNNs for modeling the nonlinear dynamics of genetic networks. Cai et al. [22] proposed a hybrid swarm/evolutionary metaheuristic to train the RNN for predicting the chaotic time series. Juang and Chang [23] developed an elite-guided continuous ant colony optimization (ECACO) for designing a recurrent TSK fuzzy model.In the case of SMA modeling, Tai and Ahn [24] fused the PSO algorithm with a hysteric functional link artificial neural network (HFLANN) for both identification and model predictive control of SMA actuator. They indicated that their method can provide a powerful controller capable of compensating the SMA hysteresis phenomenon. Ma et al. [25] developed a neural network to control the position of shape memory alloy actuators with internal electricity resistance. Song et al. [26] utilized a sliding mode robust controller and neural network for dynamic position tracking control of shape memory alloys. They developed an inverse neuro model to compensate the SMA hysteric phenomena. Pirge et al. [27] utilized a hybrid neuro genetic strategy as an inverse identification system to find the composition of any NiMnGa alloy. In their work, genetic algorithm (GA) was just used to find the optimum synaptic weights of neural network. Asua et al. [28] developed a neural network controller capable of positioning a SMA actuator. Ahn and Kha [29] proposed an internal model control for shape memory alloy actuators using extreme input history and a fuzzy based Preisach model.In spite of the widespread researches for modeling the dynamic behavior of SMAs, there exist rare reports addressing the use of incremental/inductive learning approaches and evolving computation (EC) based strategies for modeling SMA's hysteric behavior. It has been proved that EC can highly ascend the generalization and interpretability of any identification model [30–32,72,73]. In the light of such superiorities, scientific communication engaged the concept of EC to tackle several theoretical and practical obstacles [74], e.g. the effect of multi-level adaption in EC, potential of EC for handling non-stationary environments, application of EC for tuning the self-organizing maps (SOMs), EC in real-time robot control, EC for training neuro-fuzzy systems and etc. Along with the application of EC to neuro computing tasks, it has also proved its aptitude in the field of fuzzy computing. A seminal work by Lughofer endorses on the authenticity of different EC based algorithms and methodologies for adapting the characteristics of the fuzzy systems [75]. The realm of applications of EC has also been expanded to evolving a wide spectrum of intelligent systems. In [76], a rationale is provided which address some useful EC methodologies for different informatics and engineering applications. EC has proved its eligibility for learning in dynamic environments as well. This issue is fully discussed in a seminal book by Sayed-Mouchaweh and Lughofer [77]. Application of EC in online learning of expert systems is a relatively recent spotlighted concern which attracts the attention of numerous researchers [78]. The motivation behind the current investigation emanates in the pursuit of addressing the efficacy of EC in online adaption of intelligent systems. The main concepts behind designing any evolving identifier can be focused from four different angles that are mentioned in below:(1)Incrementality of the learning methods to devise any real time identifier.Online adjusting of both architecture and constructive parameters of identifier systems.By using an evolvable dynamic identification system, the computational complexity decreases significantly since it is not needed to re-train the black box identifier after each data updating process.An efficient evolvable framework provides some useful information about the optimum topology and accuracy of identification system.The main contribution of the current research can be divided into two parts. Firstly, given all abovementioned remarks, authors intend to examine the potential of EC for modeling the hysteric behavior of SMA actuator in a real time manner. Secondly, they engage the EC concept to design an intelligent tool (evolving black box identifier) capable of modeling the hysteric behavior of SMAs without having any information about the governing equations and physical conditions. The developed intelligent tool comprised RNN (a common recursive black box) and two hybrid natural inspired supervisors called CTGSR and KTGSR (heuristic methods which evolve both topology and parameters of the black box). Experiments prove that by embedding both cellular automate (CA) concept and Kohonen map (SOM) within the structure of TGSR [33], the computational complexity does not vary significantly while both speed and accuracy of evolving process rise significantly.The rest of the paper is organized as follows. Section 2 describes the structure of the SMA actuator. The identification black box (RNN) is discussed in Section 3. Section 4 is devoted to the details of both CTGSR and KTGSR evolving techniques. Moreover, some well-known dynamic benchmark problems are used to test the performance of proposed methods. The experimental setup for obtaining the necessary identification data is presented in Section 5. Results and discussion are presented in Section 6. Finally, the paper is concluded in Section 7.Most of the proposed SMA actuators have been made of shape memory wires. In these actuators, the wires are in tension mode and the axial elongation is used to make a movement. This linear movement can be transformed into a rotary movement or can be magnified using a mechanism. In the present research, the authors develop a shape memory alloy actuator that works based on bending a rod instead of stretching a wire. The proposed structure has a higher force/weight ratio and can exert a higher force in comparison to the wire types. For example, a shape memory alloy rod with 1.5mm diameter exerts a 20[N] when subjected to a thermal gradient. Fig. 1shows a schematic illustration of the proposed active actuator that can be used in robotic as an active driving joint. This actuator is very light and can be actuated easily. Therefore the robot inertial is reduced more in comparison to the motorized joints. Moreover, this actuator can be easily energized by electric current passing through the SMA rod. As a result of electric resistance, the heat generates and the rod warms up.During the heating process, phase transformation occurs within the rod and the SMA phase changes from martensit phase to austenite phase. When the material is in martensit phase, it is soft and can be deformed into any shape. But the austenite is a high strength phase and the material tends to transform to its memorized form which is an un-deformed state. So, by increasing the rod temperature, the bent rod transforms to its straight shape and the joint angle is increased. In reverse mode, the electrical current is turned off and the SMA rod gets cooled under the heat transformation with the ambient, so the spiral spring gets back the shape memory rod to its bent shape. The role of the spring is of high important, so that if the stiffness of the spring is high, the speed of the actuator is so high in the cooling mode, while it is slow in the heating and forward movement. Hence, it is so important to design an optimal spring to achieve the equal speed in both forward and backward movement. Having a model that simulates the relation between the electric current and the actuator angle is so important. In the next sections, the authors discuss the steps required to implement the intelligent predictive tool.In this study, the authors adopt a well-known simultaneous recursive neural network to identify the nonlinearity of the developed SMA actuator. Simultaneous RNNs (SRNNs) are class of neural network architectures in which the recurrence is instantaneous [20]. These networks are best suit for approximating complex nonlinear systems with fewer neurons since they are capable of identifying the response of dynamic nonlinear system even with fixed synaptic weights. The mathematical formulation of the feedback from the hidden layer output to the context layer inputs is represented as:(1)H(k,n)=f(WIH×I(k))+WCH×H(k,n−1)+b(2)O(k)=g(WHO×H(k,R)+b′)n=1,2,…,Rwhere I is the set of inputs, H is the set of neuron outputs from the hidden layer and O is the set of outputs from the output layer. WIHis the set of weights from the input layer to the hidden layer, WCHis the set of weights from the context layer to the hidden layer, WHOis the set of weights from the hidden layer to the output layer, n is the index of internal recurrence, k is the index of input sample, R is the number of internal recurrences, b and b′ are the biases, and f and g represent the neuron activation functions in the hidden and output layers respectively. Fig. 2illustrates the architecture of SRNN. This architecture defines the important properties of SRNN such as the nature of feedback connection, the number of time lags and the synaptic weights.In general, SRNN with appropriate topology can easily identify any dynamic system, and such a trait makes it appropriate for our case study. One of the most common strategies for developing a neural network is to choose the architecture randomly or based on the experience of the user. There also exist some gradient based algorithms for network parameter learning assuming a fixed structure [34]. Several drawbacks pertaining to the use of such techniques have been reported in literatures. The most common deficiencies are presented in below:(1)The presence of feedback connections makes the training much more intricate and computationally complex as compared with stationary neural networks.To use gradient and deterministic algorithms, the user should test a large number of structures and then learn the parameters for each of the selected architectures. This is obviously a tedious trial and error procedure and also requires significant user expertise.In dynamic environment, the deterministic/gradient learning techniques are unable to learn long term temporal dependencies as the errors flowing back in time either in descending or ascending styles [35].All these drawbacks force the researchers to seek for an alternative approach which relaxes the network from re-training. EC proved to be a very good technology for adjusting the topology of dynamic black-boxes in an incremental manner [30,36]. As mentioned before, stochastic/heuristic optimization algorithms are competent learning specimens which can simultaneously evolve both structure and parameters of neural networks. In the next section, the authors describe the details of the proposed hybrid natural inspired evolving algorithms more closely.Natural-inspiration is a branch of artificial intelligence that studies the principles and functions found in biological systems and nature that have been developed through evolution. Natural inspired algorithms mimic the biological and physical processes such as immune systems mechanisms, learnable bio systems, molecular interactions, improvisation and harmony in music, Newtonian law and the intelligence of swarms. When using a natural inspired metaheuristic algorithm, especially in dynamic complex areas, several pivotal parameters such as computational speed, trajectory tracking, convergence analysis, exploration robustness and exploitation accuracy should be taken into account. On the other hand, it has been proved that there is no natural-inspired metaheuristic that can outperform other one in all aspects [37]. Hence, several natural inspired techniques and modified meta-models have been proposed to provide an efficient exploration framework capable of handling large scale complex problems.The rest of the section is divided into eight subparts. At the first step, authors make a concise review of some well-known natural inspired methods and relevant modifications. At the second step, the authors state the description of TGSR optimization algorithm precisely. The third and fourth sections devoted to the description of cellular and Kohonen assisted versions of TGSR algorithm which are suited for a fast exploration in dynamic areas (in our case, real-time evolving of SRNN identifier). In sub-sections fifth to seventh, the performance, time complexity and convergence analysis are conducted. In the last sub-section, the results of analytic experiments are presented.Natural inspired metaheuristic algorithms can be divided into three main categories: (1) methods that are based on the theory of Darwin; (2) methods which try to mimic the intelligent of swarms and (3) methods which are based on the natural and physical phenomena. The main idea behind all abovementioned techniques is the same; nevertheless, there is a remarkable difference between their exploration and exploitation strategies. Among the first category, genetic algorithm (GA) proposed by Holland [38] and differential evolutionary algorithm (DEA) introduced by Storn and Price [39] proved their capability to be applied on complex nonlinear numerical and engineering problems. Particle swarm optimization (PSO) [40], artificial bee colony (ABC) [41], cuckoo optimization algorithm (COA) [42] and bat algorithm [43] are some well-known swarm based methods which are based on the intelligence of swarms in society (flocking of birds and schooling of fishes), interactions in bee colony, cuckoo's circumstance and ecological behavior of bats. Here, the interactive behavior between individuals with one another or with their environment contributes to the collective intelligence of the society and often leads to convergence of global behavior. In swarm based algorithms, each member executes a set of predefined operations and shares its information with others. These interactions provide an optimization tool that is able to solve complex problems without using the knowledge of expert user or any central controller. The third group of metaheuristics is simulated based on some adaptive phenomena in nature. Intelligent water drop (IWD) [44] is a powerful metaheuristic algorithm which was inspired based on some physical processes occur between water drops of a river and the soil of the river bed. Gravitation search algorithm (GSA) [45] is another algorithm that simulates the Newton's law of gravity. TGSR by Mozaffari et al. [33] is a recent spotlighted natural inspired algorithm that simulates the annual migration of salmon in nature and the common menaces through their pathways.In spite of the acceptable performance of all abovementioned approaches, they possess some shortcomings when applied to real world engineering problems. Some of these deficiencies are listed below:(1)They often show premature convergence when applied to multi-modal engineering problems [45].Due to their stochastic exploration intrinsic, in the case of large scale optimization, it is observed that they often lose the proper trajectory which leads to global extreme point [46].In some cases where a large amount of operating parameters involves, their computational speed reduces significantly [47].Reports confirm that in the case of constraint optimization, a reliable computation cannot be guaranteed unless some further modified operators or meta-models devise to the structure of metaheuristics [48].For tackling all abovementioned defects and also promoting the heuristic exploration quality, several reports exist in literatures which entail some modified strategies and conceptual improvements (e.g. population division [49], cooperative techniques [50] and hybrid systems [51]).Shi et al. [52] proposed a cellular PSO (CPSO), hybridizing cellular automata (CA) and PSO, for function optimization. In CPSO, CA is used in velocity update to modify the trajectories of each particle. Their experiments revealed that CPSO is capable to avoid being trapped in local optimum. Sun et al. [53] proposed a cooperative PSO with a statistical variable interdependence learning mechanism. They observed that their proposed method is best suit for large scale optimization. Mozaffari et al. [54] proposed a modified artificial bee colony called mutable smart bee algorithm (MSBA) that utilized mutable smart bee instead of conventional bees. Mutable smart bees are capable to maintain their historical memory for the location and quality of food sources and also a little chance of mutation is considered for them. The results unveil the high potential of MSBA for constrain optimization. Michalski's [55] integrated machine learning techniques and evolutionary algorithm to generate new population. These types of algorithms are simply called learnable evolutionary models (LEMs). Following this lead, Mozaffari et al. [14] test the potential of Kohonen map and a Pareto based evolutionary algorithm to find a complete optimal non-dominated Pareto front for laser solid freeform fabrication (LSFF) system. Zhu and Kwong [56] developed a Gbest-guided ABC (G-ABC) algorithm to tackle the exploring deficiencies of classic ABC. Their method takes the advantage of the information of the global best solution to guide the search of candidate solutions. Their experiments indicate that this modification improve the exploitation of the classic ABC. Yang and Deb [57] proposed a hybrid two stage search method called Eagle Strategy (ES) based on the foraging behavior of Aquila Chrysaetos eagles for stochastic optimization. It should be noted that all abovementioned techniques are suited for a peculiar environment. In our case, in which retaining a reliable trajectory is crucial during the evolving procedure; authors examine the potential of integrated CA and SOM hyper models and their novel natural inspired metaheuristic as a supervisor for evolving the RNN black-box.TGSR is a recent spotlighted metaheuristic in which the optimization carry out through two independent operators [33]. Each of these two operators deputes an independent salmon's migration pathway. The first one belongs to the salmons that move through forested regions and mountain's canyons. The other one belongs to the salmons which are passing through oceans, lakes and ponds. As it was mentioned in the former section, salmons choose their passage based on their instinct and without a meaningful inference. Each of these ways is incorporated with their own natural menaces. Commercial fishers concentrate on the ponds and ocean pathways while Grizzly bears hunt the salmons that pass through mountain's canyons and forested regions. Each of these two main hunters utilizes different techniques for hunting salmons with higher qualities. TGSR utilized all above steps to handle an optimization problem. Along with its high ability for unimodal, multimodal and constraint numerical problems [33], it shows promising results in the case of real life engineering systems. In [58], authors prove that TGSR successfully evolved the architecture of a monotonic ensemble artificial neural network (MEANN) for modeling the LSFF process [59]. In the other work, they proposed a hybrid self-organized Pareto based algorithm called (SOPEA) for handling the same problem [14]. Consequent results indicate that while TGSR possesses a lower computational complexity compared to SOPEA, it can identify the LSFF system as well. This encourages the authors to engage the TGSR for a more demanding optimization task i.e. evolving the structure of RNN black box. In the rest of this section, steps required for implementing the TGSR algorithm are given in details. The flowchart of TGSR is given in Fig. 3.a.Initialization: In TGSR algorithm, each potential solution delegates the salmon intensity in a region (amount of salmons in a sub group). In other words, region with higher salmon intensity yields a solution with higher fitness. The solutions are initialized stochastically spanning to the passage dominance (between lower bound and upper bounds). Eq. (3) represents a procedure which is used to initialize random solutions with respect to the solution space.(3)Initialsolution=lb+rand×(ub−lb)where lb and ub are the lower and upper bounds, respectively and rand is a random number spanning to 0 and 1 with a uniform distribution.After initializing the solutions, optimization procedure is started. At the beginning of the optimization process, all of these initialized solutions (salmons sub groups) are prepared for their migration (iterative movements). It is obvious that each iteration cycle is equivalent to a natural migration phenomenon.Choosing pathways for migration: Before migration, salmons choose their pathway based on their instinct. This suggests a stochastic shuffling control parameter for thrusting the salmon groups (initial solutions) in both pathways (evolutionary operators). Eq. (4) formulates a mathematical form of this process.(4)Solution’ssharing:NP1=[μ×Ps]NP2=Ps−NP1whereNP1is the number of salmon groups passing through ocean and ponds,NP2is the number of salmon group passing through forested regions and mountain canyons, Psis the number of all salmon groups which participate in the migration and μ is a sharing factor that represents the salmon's instinct. As seen, the proposed formulation is a strategy for shuffling the solutions stochastically. The results confirm the effectiveness of this shuffling in the diversification of the solutions.After sharing process, these subgroups are entered in their pathways. They face different dangers while crossing these pathways. In the following, the details of the passage traversing are given.Crossing lakes and ponds: In the first operator, the human hunting is simulated. Humans hire scout ships and commercial fishers to investigate the passage dominance (solution space).The scout ships apply some arithmetic graphical search (an intelligent diversification methodology) to explore the passage as best as they can. This exploration has been mathematically modeled in Eq. (5).(5)XN=XF+δ(t,(ub−XF))orXN=XF+δ(t,(XF−lb))where t represents the current iteration number, XNrepresents a new detected region (new solution) and XFshows the former region of the scout ship (former solution). δ(x, y) is calculated using Eq. (6).(6)δ(x,y)=y×rand×1−xTbwhere T is the number of the maximum iteration, b is a random number larger than 1 and rand is a random number spanning to 0 and 1 with a uniform distribution.The remaining ships (known as commercial fishers) communicate with both scout ships and other active commercial fishers to find better areas (with higher salmon intensity) for hunting salmons. Then they congregate in the areas with higher intensity of salmons. Fisher groups often consist of two main hunter ships and one recruited ship. First, the main hunters find regions with an acceptable salmon intensity (solution fitness). After that, they inform the recruited agent to exploit nearby regions to find more intense areas (solution with higher fitness). This exploitation has been mathematically modeled in Eq. (7).(7)XR=β×(XM1−XM2)+XM1where β is a random number spanning to 0 and 1 with uniform distribution, XRrepresents the new detected solution by the recruited agent, XM1 is the solution obtained by the first main hunter and XM2 is the solution obtained by the second one.Fig. 4exposes the graphical representation of evolutionary steps that occur in this phase. The pseudo code of the human hunting strategy is given in Fig. 5.Crossing Mountain Canyons and forested regions: The second operator simulates the Grizzly bears hunting methodology. Similar to other animals, Grizzly bears communicate with each other to find a region with higher salmon intensity. Their hunting method is really simple. They always inform each other if they find an acceptable region. Then, the entire Grizzly bear groups approach the best region and search nearby areas. If they find an area with higher salmon intensity, they inform other bears. Otherwise, they leave the region and continue the local search. One of the main disadvantages of the bears hunting procedure is the lack of an independent diverse exploration. Bears hunting methodology is mathematically expressed in Eq. (8).(8)XB=cos(φ)×(BR−LR)+LRwhere XBrepresents a new detected region, BRis the best reported region by the hunting team, LRis the current region in which the bears have decided to perform a local exploitation and φ is an arbitrary angle spanning to 0 and 360°. cos(φ) directs the bears to their destination. It is obvious that these animals perform an exploitation search with different radii and angle of attacks.Fig. 6exposes the graphical representation of evolutionary steps that occur in forested region phase (bears hunting strategy). The pseudo code of the bears hunting strategy is given in Fig. 7.Regrouping for spawning: At the end of the migration, the survived salmons (current solution vectors) congregate in their destination for spawning. In TGSR, this natural event is simulated through a collection container. After salmons pass through their pathways (two evolutionary operators), the salmon subgroups (solutions) are collected in a unique container. In other words, the solutions are extracted from both operators and make a unique population. At this state, the algorithm has reached the end of the iteration.The change in climate and urge for spawning are two main motivations which force the remaining salmons to begin another migration. Continuity of these permanent migrations turns the TGSR to a powerful iterative optimization algorithm. The pseudo code of TGSR algorithm is given in Fig. 8.CA is relatively a new concept in the field of unconventional computing [60] which studies the potential of small-world cellular automaton networks in simulating long-range interactions of complex physical, biological, social and computational systems. The application of CA in evolutionary computing is a recent topic of interest which was mainly extended by Giacobini et al. [61]. The main idea behind the concept is to provide the population within a connected graph based grid in which each node (vortex) deligates an individual who interacts with its predefined topological neighbors. Both topology and the neighborhood communication may vary with regard to the type of exploration/exploitation or the physic of objective function. Fig. 9visualizes some possible sketches for neighborhood interconnection (in planar space for better visualization). The main provocations behind implementing cellular metaheuristics are listed in below:(1)CA networks are simple in concept and easy to implement [60].The physic of cellular network which is based on synchronous deterministic interconnection of automated cells turn these large arrays of not very powerful elements to a robust tool suited for modeling any complex system [61].CA possess a parallel intrinsic which increases the speed of computation [62].Reports confirm that by devising a logical integration of network topology and neighborhood communication strategy, cellular optimizer can easily outperform other optimization algorithms [61].It has been proved that cellular heuristic can retain a desire exploration trajectory during the optimization of multimodal objective functions [63].Along with abovementioned traits, Shi et al. [63] experiments show some intuitive similarities between the behavior of CA and metaheuristic algorithms. The main similarities are (1) the interaction of individuals in both of these concepts to transmit certain information, (2) in heuristic approaches and CA networks; the state of an individual (smart cell in CA and stochastic agents in heuristics) is updated based on its current state and corresponding neighbors’ states, (3) both methods engage a transition rule to promote the states of their agents (both are evolutionary methods). All these advantages and similarities persuaded Shi et al. [63] to design a cellular heuristic (cellular PSO in their case) algorithm for numerical optimization. To elaborate on their proffer, they setup a solid experimental environment including several optimization algorithms and rival non-cellular algorithms. Their experiments obviously demonstrate the advantages of cellular heuristics over the un-cellular versions. To implement a hybrid CA heuristic algorithm, 6 criteria should be considered. These are: (1) automated cells, (2) cell space, (3) cell state, (4) neighborhood, (5) transition rule and (6) discrete time step. Here, the automated cells are candidate solutions derived from initialization at the very beginning of TGSR algorithm, cell space is the number of all cells, neighborhood is a topology based on lattice structure containing candidate solutions and discrete time interval is equal to iteration in TGSR (i.e. one natural salmon run process).For embedding the CA into the TGSR metaheuristic, first we presume that the whole solution space is the cell space. So, each potential solution in the solution domain deligates a cell in the solution space (it is expected that the cell space is divided by infinite number of cells and the solution space cannot be divided into more cells). After random initialization of solutions in the cells’ domain, we have two groups of cells i.e. those contain heuristic agents (population of TGSR) and null cells. According to a definition by Shi et al. [63], we define a “smart-cell” as a cell which includes a heuristic agent. Consequently, cells (potential solutions) that did not experience heuristic agents are not smart. After discriminating the cells, the next step is to select a neighborhood function. This function is given as below [63]:(9)N(i)=Xit+bestfitnessfitness(Xit)R∘ψfitness(Xit)≠0,bestfitness≥0Xit+fitness(Xit)bestfitnessR∘ψfitness(Xit)≠0,bestfitness<0Xit+ebestfitnessefitness(Xit)2R∘ψfitness(Xit)≠0,bestfitness≥0Xit+ebestfitnessefitness(Xit)2R∘ψfitness(Xit)≠0,bestfitness<0where R3 is a 1×d matrix contains d arrays with random numbers spanning to [−1,1], and “o” represents the Hadamard operator. For the jth dimension (j=1, 2, …, d) ofXit, N(i) generates random points with radius(bestfitness/fitness(Xit))Rjψj,(fitness(Xit)/bestfitness)Rjψjor(ebestfitness/efitness(Xit))2Rjψjaway fromXit. As it is obvious, different numbers of R (i.e. Rδm) yield m different neighbors. Fig. 10visualizes the neighborhoods of the jth and kth dimensions. It should be noted that in TGSR, ψjhave three different definitions regarding to the operating phase i.e. grizzly phase and human phase.The formulations for these states are given in below:(10)ψ=δ(t,(XF−lb))forscoutshipsβ×(XM1−XM2)forcommercialfisherscos(φ)×(BR−LR)forgrizzlybearsThe transition rule of CA in CTGSR is as following [63]:(11)f(ϕ)=min(fitness(N(i)),fitness(N(i+δ)),…,fitness(N(i+δm)))(12)ϕ=iiff(φ)=fitness(N(i)),i+δmiff(φ)=fitness(N(i+δm)),(13)Sit+1=SϕtThe transition equation implies that after evaluating the amounts of neighbor cells, the cell with best fitness is chosen to replace the position of TGSR's heuristic agent. It seems that by implementing a cellular topology, heuristic agents conduct a better exploitation in solution domain while retaining their acceptable rate of convergence. This fact was previously demonstrated by a rigor mathematical convergence analysis [61–64]. The flowchart and pseudo code of CTGSR are given Figs. 11 and 12respectively.In this section, the authors expose the details of second hybrid heuristic algorithm. Here, the authors focus on the potential of a self-organized (Kohonen assisted) version of TGSR. The main idea behind the proposition of this hybrid method is to enhance the exploitation of TGSR through the use of synaptic weights of SOM's neuron. As has been mentioned before, applications of hybrid evolutionary-learning algorithm began by Michalski's researches [55] who hired machine learning technique and evolutionary algorithm to generate new population during the optimization process. These types of algorithms are simply called learnable evolutionary models (LEMs). After its proposition, several researchers have followed the Michalski's lead and developed new models and improvements. Ammor and Rettinger [65] utilized the SOM network to improve the diversity and avoid the fast convergence during the optimization procedure. In their method, SOM approximated the probability of density of input data distribution. Kobuta et al. [66] developed SOM for the reproduction of new seeds in GA. In this paper, an adaptive SOM with conscience mechanism was combined to Pareto based EA to detect the features of obtained non-dominated solutions in current optimal Pareto front as on-line input data. Mozaffari et al. [12] proposed a synchronous parallel self-organized Pareto based evolutionary algorithm for optimizing the operating parameters of Damavand power plant. Rahmani et al. [17] proposed a multiobjective self learning evolutionary algorithm to optimize the porous PMMA scaffold fabricated by laser drilling process. The main privileges of LEMs are listed in below:(1)Experiments stress that LEMs possess much more robustness as compare with sole heuristic algorithms [14,47].In spite of the high computational complexity of LEMs, they are highly capable to cope with complex engineering systems. This gives them versatility to be applied on different engineering cases [12,17].In both single and multiobjective cases, SOM networks can thoroughly improve the convergence, quality and reliability of heuristic algorithms [14,47].Here, the authors engage a time adaptive version of SOM grid with a conscience mechanism [67] to extend the local exploitation of TGSR optimization algorithm. Generally, a SOM network with conscience mechanism uses the following learning rule:(14)Wjn+1(t)=Wjn(t)+yj(t)⋅hj(n)⋅(Rin(t)−Wjn(t)),,t=1,2,…,Twhere t is epoch number in SOM network and n represents the TGSR iteration number. yj(t) is a control parameter that leads weight vectors to the global solution which was transferred from TGSR short-time memory to the network as an on-line input. In other words, if the input's fitness value fR, which is the current global solution, is lower thanfWj(t)then yj(t)=1 and neuron center moves toward the non-dominated solution (networks input) otherwise yj(t)=0 and neuron center does not approach to the solution. This can mathematically expressed as:(15)yj(t)=1ifdominateWj(t)0otherwiseWjn+1(t)refers to updated weight vector and Wj(t) is the old weight vector.Rin−Wjnrepresents the distance between input vectors whereRinis the ith non-dominate solution in nth generation. The learning rate which is a descending function is defined as following:(16)hj(t+1)=hj(t)+αf1sf⋅sl(t)Rin−WjnThe learning rate parameter hj(0) should be initialized with a value close to unity. α obtains any arbitrary value between 0 and 1. sfis a descending constant and should be set based on characteristics of problem. In this paper, we set sf=1000. Function f(·) should be designed in a manner that the following criteria are satisfied appropriately:f(0)=0,0≤f(z)≤1anddf(z)dz≥0for positive values ofz.Here, f(z) is set to be:(17)f(z)=1−11+zScaling value sl for an n dimensional input is adjusted using the following equations:(18)sl(t+1)=∑i=1nEki(t+1)n−i(−1)i+1+,k=1(19)Eki(t+1)=Eki(t)+μi(Rki(t)−Eki(t))where i represents the number of variable in each solution.Eki(0)is initialized with some small random values. Fig. 13(a) depicts the scheme of neurons updating in SOM grid.Conscience mechanism is applied in order to revive the dead units (weights) in neuron center. The schematic illustration of this procedure is visualized in Fig. 13(b). Dead unit is a term that refers to weights with a trivial chance of learning and adaption during the progress. The policy of repairing these units is often called conscience mechanism. Here, a simple well-known mechanism is utilized which tunes the bias of node (neuron) by following formula:(20)bi(t+1)=0.8bi(t)orbi(t)−0.3Here, in each of iterations, the TGSR carries out an optimization process and after that an obtained global solution is introduced to SOM grid. SOM neurons (nodes) follow the abovementioned rules to learn the characteristics of the global solution and approach to its vicinity. The experiments reveal that this procedure results in a reliable exploitation. Fig. 14depicts the schematic illustration of the proposed procedure. The pseudo-code of KTGSR is given Fig. 15.In this section, the authors implement a standard performance evaluation framework (comprised three dynamic test functions) to elaborate on the acceptable capability of the proposed TGSR variants. These functions resemble the incremental environment required to evolve the structure of SRNN for modeling the SMA actuator. In our real-life problem, after a predefined interval (something like t′ in following test functions), sensors yield some new experimental data regarding to the displacement of SMA actuator. So, the proposed methods should be able to evolve the structure of SRNN before the next data updating procedure.The test functions are ADLS, AbVP and APhL[68]. All of these functions are minimization problems. Concise definitions of these test problems are given in Appendix A. Before starting the numerical experiments, it should be noted that TGSR, PSO and TMPSO [69] are considered as rival optimization methods. The dynamic changes in each of the functions occur in a real-time fashion and the variable t′ in all of the test problems is an integer number. The performance metrics are:(21)EOV=meant′=0N(ROV(t′)−BFOV(t′))(22)EOP(j)=meant′=0N(ROP(t′,j)−BFOP(t′,j))where N is the final time, ROV(t′) is the real optimal value of the cost function and BFOV(t′) is the best value of the cost function attained by the optimization algorithm. As it can be seen, in Eq. (21), the mean difference between ROV(t′) and BFOV(t′) is equal to error of value. ROP(t′, j) and BFOP(t′, j) are the real time optimal position and the algorithm's best position in the corresponding time. Just like the prior metric, we define the mean distance between ROP(t′, j) and BFOP(t′, j) as error of position EOP(j) (see Eq. (22)). To gain much more reliable statistical results, for all benchmarks and optimization methods, the test is carried out in 30 independent runs with random initial seeds. Table 1exposes the mean and standard deviation of both metrics for all algorithms in each test case. It can be observed that both CTGSR and KTGSR yield promising results as compared with other metaheuristics. To demonstrate the results better, in Figs. 16 and 17, the authors visualize the performance of both KTGSR and CTGSR for ADLS test function. As it can be seen, optimization is carried out for 1000 iterations. In each 0.1s (that is relatively equal to 20 iterations), a dynamic shock is exerted to spur the landscape of the objective function. It is explicitly obvious that both of TGSR variants are completely successful to incrementally be adapted to new environment. Such a feature gives them versatility to be applied on real word incremental learning cases. In rest of the paper, the authors utilize the proposed algorithms to evolve the topology of SRNN black box in a real-time manner.When proposing either a modified or a novel metaheuristic approach, it is crucial to elaborate on the resulted algorithmic functioning procedure. Complexity analysis is a major task that provides theoretical estimates for resources required by any algorithm to solve a given computational problem. Based on the analysis results, one can decide whether an algorithm is useful for a peculiar optimization task. Until now, a number of methods have been proposed in literatures addressing the complexity analysis of metaheuristic algorithms. Time complexity analysis and big O notation are two of the most popular analytic approaches used by many researchers. Here, the authors adopt the time complexity analysis to verify the effect of operating parameters over optimization procedure. A salient asset of using time complexity approach lies on the fact that it is not required to be worried about the structure of the proposed metaheuristics. Rather, such a complexity analysis just deals with the number of function evaluation. The mathematical formulation required for the analyzing is given in below:(23)Time_Complexity=τˆ2−τ1τ0where τ0 is the code execution time, τ1 is the required time for 100,000 function evaluation andτˆ2is the mean of 30 execution time [70].Table 2listed the obtained results for all rival methods and benchmark problems. As it was expected, the proposed hybrid techniques have a higher computational complexity as compares with the rival methods. This is directly because they have a much more complex algorithmic functioning. However, it can be seen that, the final time complexity is not very high. One interesting thing observed after the experiments refers to the robustness of KTGSR. Although the method has a high computational complexity, it does not affected by changing the benchmark problem. By taking a peek at the obtained results, one can observe that other metaheuristics are much more sensitive. This is because of the fact that the most of the computational load in KTGSR is consumed through the algorithmic functioning instead of function evaluation. Generally, it can be inferred that the use of hybrid methods are really promising. Because while the computational loads of both hybrid techniques are very close to those obtained by rival methods, they show a very promising performance (based on the results obtained in prior section).Here, the authors aim at evaluating the convergence properties of the proposed method. This let the authors to reach some remarkable conclusions regarding the exploration/exploitation of the method during the optimization process. This metric is also really advantageous from the view of random process evaluation. In other word, through the convergence analysis, one can find out the interactions of heuristic agents over the optimization. As we are aware, a good metaheuristic is the one which has a proper and fast convergence. Here the convergence rates of all rival methods are evaluated through the optimization procedure. However, it should be noted that since the current study deals with dynamic environments, we need to devise a proper test bed to measure the convergence before a significant change in the environment of the problem at hand. Since, the characteristics of all benchmark problems are updated about 0.1s (i.e. 20 iteration), the authors check the convergence rate in a predefined interval of 20 iterations (simply the first static interval is selected). A simple mathematical formulation is adopted from a prior work by the authors [71] to evaluate the convergence rate of the rival methods:(24)MeanCost=∑i=1popsizecost(i)popsize(25)BestCost=Min(Cost)(26)ConvergenceRate=BestCostMeanCostTable 3shows the convergence rate of the rival algorithm obtained after 5 iterations in the considered interval. According to the obtained results, it can be inferred that PSO and TMPSO have more attitude toward converging the heuristic agents. This refers to the methodology of swarm based approaches. However, a different scenario is valid for TGSR. Although TGSR is a swarm-based approach, it does not intend to converge all of the solutions in a specific region. This refers to the population sharing of the TGSR, which deter the agents to converge easily. As it can be seen, TGSR and the proposed hybrid techniques hold the level of convergence at a stagnant level over the optimization process. By checking the performances of these algorithms, one can easily find out that such a characteristic is very advantageous. Because, by keeping the heuristic agents at a relatively moderate convergence rate, TGSR fosters the diversified exploration which in turn results a wider search within the solution domain. For example, the incremental convergence rate occurred in PSO does not result in a superior exploration, while both KTGSR and CTGSR show a very promising performance for the benchmark problems (see Table 1).Based on the conducted numerical experiments, following outcomes can be concluded:(1)Bases on the experiments, it has been observed that the proposed hybrid techniques show comparative results as compared with the state-of-the art techniques. For most of the experiments, it is observed that both CTGSR and KTGSR can easily be reconciled to the dynamic behavior of the benchmark problems.According to the results of complexity analysis, it is observed that the both proposed techniques need much more algorithmic functioning as compared to the PSO variants. However, based on the obtained results, it is observed that the difference of the computational time does not have a significant difference, and therefore it can be applied on real-life optimization problems.By performing the convergence analysis, it is observed that both KTGSR and CTGSR foster a stagnant level of diversification through the optimization process. This is different from the behavior of the PSO based techniques which show an incremental convergence rate over the optimization. By taking the results of optimization into account, it is observed that such a behavior can be beneficial specially when handling a complex real-life problem. A constant rate of diversification provides the hybrid algorithms with the opportunity of exploring over a wide landscape within the solution domain.From the algorithmic point of view, it is observed that the hybrid methods consume a higher computational load, and therefore are much more complex to be implemented. However, they can be beneficial if the expert user can adapt the characteristics of the hybrid methods in a suit fashion.One important trait of the KTGSR is its algorithmic robustness. The results of computational complexity reveal that KTGSR is not affected by the characteristics of the optimization problem. However, the other methods show a remarkable algorithmic reaction to the characteristics of the optimization problem.In this section, the model identification of the real SMA actuator is studied. To prepare the identification data, an experimental setup has been designed and implemented. The experimental setup includes a SMA actuator, LVDT sensor, DAQ card, power supply and a computer. The LVDT sensor measures the actuator displacement and the measured displacement is transmitted to the computer using a DAQ card. Also the DAQ card is used to command the power supply to adjust the electric current. Fig. 18shows the experimental setup.DAQ card is a USB 8 Channel 49kHz 12-bit A/D made by EAGLE Technology (MicroDAQ-lite-usb model). The power supply is a programmable switching DC made by Good Will Instrument Co. This power supply communicates with the computer using the RS232 port. The LVDT sensor model is DLH-A-5mm made by DACell Company with ±0.001mm accuracy.A schematic illustration of the fabricated actuator is shown in Fig. 19. According to the figure, the SMA material is a high temperature shape memory Nitinol alloy bent in an arc shape with a 25mm radius. A linear bearing with two joints is also used. Each joint supports one end of the shape memory wire. One joint is fixed while the other one can slide on the linear bearing. The linear bearing friction is ignorable. To bring back the SMA wire to its original deformed shape, a compression spiral spring is utilized. The spring outer diameter is 20mm and its wire diameter is 2mm.

@&#CONCLUSIONS@&#
In the current investigation, the authors have tested the EC concept to model the behavior of SMA actuator as a non-linear dynamic engineering phenomenon. To this end, they have designed two improved version of TGSR optimization algorithm i.e. cellular and Kohonen assisted TGSRs. In CTGSR, the exploration domain of heuristic algorithm was transited into a cellular space. This let the CTGSR to take the advantage of automated cells to conduct a wise exploration. The second developed model (KTGSR) used a self-organizing map for systematic exploitation in vicinity of the global solution. Firstly, they have proved the reliability of their proposed methods through a set of standard benchmark problems. Their tests show that both proposed model can successfully cope with dynamic environments. At the second step, they have engaged the proposed methods for incremental learning of a SRNN black box model for the SMA actuator. The primary experimental tests revealed that the behavior of proposed actuator is dynamic with hard nonlinearities including delay and hysteresis. The modeling results illustrate that both CTGSR and KTGSR have successfully evolved the structure of the recurrent black box in a short period of time. Furthermore, despite of the ascending complexity associate with incremental learning, both algorithms have retained a perpetuate level of prediction error during the evolving process.a.ADLS function: This test problem is a variable dimension version of Rosenbrock test problem. The mathematical formulation is given in below:(A.1)J=∑j=1T[100(x(j)2−x(j+1))2+(x(j)−1)2]where x(j)∈[−5,10] and the parameter T is a linear time function that starts from 1 and increased after each 0.1s.AbVP function: This test function is a dynamic version of Morrison function. The mathematical formulation of this problem is given as:(A.2)J=∑j=1T[−hjT(t′)+ri((x(1)−pi,1)2+(x(2)−pi,2)2)]where x(j)∈[−100,100] and j=1, 2. Here, the variation is simulated as a periodic function of time i.e. T(t′)=cos(t′).H=[hi]T=[2+T(t′)3+T(t′)5+T(t′)7+T(t′)9+T(t′)],R=[ri]=[1357+T(t′)9]PT=[pi,j]T=6518465184APhL function: This benchmark is based on the static Martin-Gady function and is mathematically defined as:(A.3)J=((x(1)−T(t′))−(x(2)−T(t′)))2+(x(1)−T(t′))−(x(2)−T(t′))−1032where x(j)∈[−100,100] and j=1, 2. Here, the variation is simulated as a periodic function of time i.e. T(t′)=t′.The objective functions required for evolving the structure of SRNN are mean square error (MSE) error and networks complexity. Both of these objectives are used as a fitness functions for TGSR's heuristic agents. The MSE error can be formulated as:(B.1)MSE=1T∑t′=1T(Y(t′)−Yˆ(t′))where Y(t′) is the actual experimental data (displacement) at time t’ received by data acquisition tool andYˆ(t′)is the predicted value at time t′.The second objective function aims to minimize both number of nodes in hidden layers (increase the interpretability of network) and required lags (number of hidden layers). This objective function is given in below:(B.2)NumberofNodes=∑k=1NHLHnkwhere NHL controls the number of hidden layers (required lags) in the SRNN network and Hnrepresents the number of hidden nodes in each layer.The total objective function can be written as below:(B.3)J=(MSEtest+MSEtrain)+1(NHL)(λ)(Hnmax)∑k=1NHLHnkwhere λ is equal to 100 and Hnmax that shows the maximum number of permissible nodes in each layer is equal to 20. The experiments reveal that these values help the optimization algorithms to avoid any discrimination between two objective functions.