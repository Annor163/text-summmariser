@&#MAIN-TITLE@&#
Determination of an optimal control strategy for drug administration in tumor treatment using multi-objective optimization differential evolution

@&#HIGHLIGHTS@&#
To formulate and to solve a multi-objective optimal control problem applied to treatment of tumors.To minimize the cancerous cells concentration and the drug concentration.The results demonstrated that an optimal protocol can be obtained considering both objectives.

@&#KEYPHRASES@&#
Mathematical modeling of tumors,Differential evolution algorithm,Optimal control problem,Multi-objective optimization,

@&#ABSTRACT@&#
The mathematical modeling of physical and biologic systems represents an interesting alternative to study the behavior of these phenomena. In this context, the development of mathematical models to simulate the dynamic behavior of tumors is configured as an important theme in the current days. Among the advantages resulting from using these models is their application to optimization and inverse problem approaches. Traditionally, the formulated Optimal Control Problem (OCP) has the objective of minimizing the size of tumor cells by the end of the treatment. In this case an important aspect is not considered, namely, the optimal concentrations of drugs may affect the patients' health significantly. In this sense, the present work has the objective of obtaining an optimal protocol for drug administration to patients with cancer, through the minimization of both the cancerous cells concentration and the prescribed drug concentration. The resolution of this multi-objective problem is obtained through the Multi-objective Optimization Differential Evolution (MODE) algorithm. The Pareto's Curve obtained supplies a set of optimal protocols from which an optimal strategy for drug administration can be chosen, according to a given criterion.

@&#INTRODUCTION@&#
In the last decades, despite of numerous efforts dedicated to the development of new technologies for tumors diagnosis and treatment, the incidence of cancer has increased significantly. The ideal treatment for this disease has not yet been found: to destroy tumor cells without affecting normal cells, and inhibit its aggressive manifestation [1]. As mentioned by Pillis and Radunskaya [2], a tumor's response depends on many factors, including the severity of the disease, the efficiency of the treatment, and the strength of patient's own immune response, to cite only a few. In this context, the development of mathematical models to represent the tumor growth is configured as an interesting research area. The objective is to find the best protocol for drug administration, although the growth of a cancerous tumor is a very complicated process involving complex interactions [2–4]. In the literature, various mathematical models for cancer treatment have been proposed due to better modeling capabilities and due to the refinement of the techniques that can be used to estimate the necessary control parameters. Besides, various contributions are focused on analyzing the problems including chemotherapy treatment as a means to deplete cancer cells, immunotherapy as a way to boost the immune system, as well as a combination of the previous mentioned treatments [2–16].The determination of optimal protocol for drug administration characterizes an Optimal Control Problem (OCP). In the literature, the OCP is solved by using the Optimal Control Theory, with applications in different fields of science and engineering, such as aerospace, process control, robotics, bioengineering, economics, finance, and management science [17–22]. The OCP consists in the determination of the control variable profiles that minimize (maximize) a given performance index as characterized by a differential index, i.e., the number of times required to differentiate the Differential Algebraic-Equation system (DAE) to obtain a system of Ordinary Differential Equations (ODE) [17,22]. For this problem, when the differential index fluctuation occurs as due to the activation and deactivation of inequality constraints or when the control variable behaves linearly in the Hamiltonian function, this is called Singular Optimal Control Problem (SOCP) [17–22].Several numerical methods have been proposed to solve SOCP [17–19], which are classified according to three broad categories: direct optimization methods, Pontryagin's Maximum Principle (PMP) based methods and HJB based (Hamilton–Jacob–Bellman) methods. Among these methods, the direct approach has been preferentially used in the last several years. This approach uses control parameterization or state and control parameterizations, transforming the original problem into a finite dimensional optimization problem. Recently, algorithms based on heuristic approaches have been used to solve the SOCP due to their success observed in solving general optimization problems. In this context, the Differential Evolution Algorithm (DE), proposed by Storn and Price [23,24], has been applied successfully. Kapadi and Gudi [25] determined the substrate concentration profiles in a feed-batch reactor with singular arc. Lobato et al. [26] presented a new algorithm for dealing with control optimization problems. The proposed methodology consists in the extension of the DE to problems with multiple objectives, through the incorporation of special mechanisms such as rank ordering and neighborhood potential solution-candidates exploration. This algorithm is applied to determine the switching times (events) and operation time of the lysine fermentation process. Wang and Chiou [27] proposed an algorithm based on DE to determine the optimal control and optimal time location problems of differential-algebraic systems. Chowdhury et al. [28] presented a hybrid evolutionary direct search technique based on DE to solve optimal control problems. Lobato et al. [29] proposed a strategy for the dynamic updating of the population size to reduce the number of objective function evaluations. This strategy is based on the definition of convergence rate to evaluate the homogeneity of the population in the evolutionary process. It has been applied to the solution of singular optimal control problems in chemical and mechanical engineering.Traditionally, the main objective considered in the determination of optimal protocol for drug administration is the minimization of the size of tumor cells at the end of the treatment [2–4]. In this case, the high drug concentrations in the organism, which affects significantly the patient's health, is not taken into account. In this contribution, the main goal is to introduce a systematic methodology to minimize simultaneously the cancerous cells concentration and the drug concentration during the treatment by using the Multi-objective Optimization Differential Evolution (MODE) algorithm [30]. The work is organized as follows. Section 2 presents the mathematical model of tumor growth. In Section 3, the general aspects regarding the formulation and solution of SOCP are presented. A definition of the Multi-objective Optimization Problem (MOP) is presented in Section 4. A review about DE and its extension to deal with multi-criteria optimization are presented in Sections 5 and 6, respectively. In Section 7, the proposed methodology is discussed. The results obtained from the application of the methodology conveyed as based on two test-cases are presented in Section 9. Finally, the conclusions are outlined in Section 9.In this work, the mathematical model proposed by Pillis and Radunskaya [2] is adopted. This model has the following characteristics:•Immune Response: includes immune cells whose growth may be stimulated by the presence of the tumor and that can destroy tumor cells through a kinetic process;Competition Terms: normal cells and tumor cells compete for available resources, while immune cells and tumor cells compete in a predator-prey fashion;Optimal Control Theory for Chemotherapy: a set of optimal drug therapies is calculated through the minimization of cancerous cells concentration during the treatment while keeping the normal cells in a condition above a required level;Logistic Growth Law.In the model proposed by Pillis and Radunskaya [2], I denotes the number of immune cells at time t, T represents the number of tumor cells at time t, N stands for the number of normal (host) cells at time t, and u is the control strategy. The source of the immune cells is considered to be outside the system, so that it's reasonable to assume a constant influx rate s (steady source rate for immune cells in the absence of a tumor, 0 ≤ s ≤ 0.5). In the absence of any tumor, the cells will die off at a per capita rate dl, resulting in a long-term population size of s/d1 cells. The presence of tumor cells stimulates the immune response as represented by the positive nonlinear growth term for the immune cells.ρITα+Twhere ρ and α are positive constants. The tumor cells as well as the normal cells are modeled by a logistic growth law, with parameters ri(r1 may be bigger or smaller than r2, depending on the type of cancer or stage of growth) and bi(b1−1≤b2−1=1) representing the per capita growth rates and reciprocal carrying capacities of the two types of cells (i = 1, 2 and 3 identifies those associated with the cells tumor, normal tissue and immune, respectively). Mathematically, this model is described by the following system of differential equation:(1)N˙=r2N(1−b2N)−c4TN−a3uN(0)=No(2)T˙=r1T(1−b1T)−c2IT−c3TN−a2uT(0)=To(3)I˙=s+ρITα+T−c1IT−d1I−a1uI(0)=Iowhere the parameters aiare the cell death rates (0 ≤ ai≤ 0.5, with a3 ≤ a1 ≤ a2), ciare the competition rates (ciare considered positive), d1 is the mortality rate, α is related with inverse declivity of immune response (0 ≤ α ≤ 0.5) and ρ is the immune response rate (0 ≤ ρ ≤ 1). In this model, the term T N represents the probability of finding tumor and normal cells, and the term IT describes the probability of finding T and I[2].It is important to emphasize that, since the model used is qualitative and does not focus on a particular tumor type, it's not immediately apparent how to measure which growth law is preferable in this context. However, as mentioned by the authors, the choice of growth law does not significantly affect the qualitative behavior of the model.To better understand the dynamics of the phenomenon, Pillis and Radunskaya [2] analyzed the system without and with drug input. For the first case, the authors demonstrated that depending on the values of the parameters, there could be zero, one, two or three equilibria states. In this analysis, tumor-free equilibrium, dead equilibria and coexisting equilibria were considered. More details about the corresponding stability analysis can be found in Pilis and Radunskaya [2].Mathematically, the SOCP can be formulated as follows [17–19]:(4)minu(t),tfJ=Ψ(z(tt),tf)+∫t0tfL(z,u,t)dtwhere z is the vector of state variables and u is the vector of control variables. Ψ and L are the first and second terms of the performance index, respectively. The objective is subject to the implicit Differential-Algebraic Equations (DAE) system as given by:(5)f(z˙,z,u,t)=0(6)g(z,u,t)≤0(7)p(u,t)≤0(8)q(z,u,t)|t=tf=0with consistent initial conditions given by:(9)φ(z˙(t0),z(t0),u(t0),t0)=0where J(.), L(.),Ψ(.)→ℝ; f (.),φ(.)→ℝmz;z∈ℝmz;u∈ℝmu;g∈ℝmg;p∈ℝmpandq∈ℝmq.According to the Optimal Control Theory [17,18], the solution of the SOCP, defined by Eq.(4) to Eq.(9), is satisfied by the co-state equations and the stationary condition given, respectively, by:(10)λ˙T≡−∂H∂zλ(tf)=∂Ψ∂z|t=tf(11)∂H∂u=0where H is the Hamiltonian function defined by:(12)H≡L+λTfThe system formed by Eq.(10) to Eq.(12) is known as the Euler–Lagrange equations, which are characterized as Boundary Value Problems (BVPs). According to Bryson and Ho [17] and Feehery [18], the main difficulties associated with the SOCP solution are the following: the existence of end-point conditions (or region constraints) implies multipliers and associated complementary conditions that significantly increase the difficulty of solving the BVP by the indirect method; the existence of constraints involving the state variables and the application of slack variables method may originate DAE of higher index, regardless of the constraint activation status, even in problems where the number of inequality constraints is equal to the number of control variables; the Lagrange multipliers can be very sensitive to the initial conditions.The solution of SOCP presents special challenges since it demands the knowledge of the sequence and the number of constraint activations and deactivations (events) along the trajectory. When the amount of constraints is reduced, it is usually possible to determine this sequence by examining the solution of the problem without constraints. However, the presence of a large number of restrictions brings a problem of combinatorial nature [18].In the events, due to discontinuities in the state and/or the co-state variables, changes in the functional form of the DAE and/or in the trajectories of the control variable in each phase may occur. As a consequence, the differential index of the system can change throughout the solution trajectory, increasing when the inequality becomes active. The existence of sections of fluctuating index leads to different errors in these sections, demanding the application of adjusted numerical strategies for each section. Therefore, it is necessary to know previously the moments of activation and deactivation of the restrictions in order to solve the problem adequately. Another difficulty is the presence of singular arcs, where the second derivative matrix of the Hamiltonian with respect to the control is only positive semi-definite [17,18].A particular case of great interest is the one that appears when the control variable behaves linearly in the Hamiltonian function. In general, no minimum optimal solution will exist for such problems unless inequality constraints in the state and/or control are specified. If the inequality constraints are linear with respect to the control variable, it is reasonable to expect that the minimum solution, if it exists, will always impose that the control variables are located at a point belonging to the border of the viable region of control [17,19,22].Consider the following system of equations:(13)z˙=F1(z)+F2(z)uz(to)=zowith the control variable given by:(14)umin≤u≤umaxThe Hamiltonian function is defined as:(15)H=λT(F1(z)+F2(z)u)For this class of control we have:(16)u={umaxλTF2<0ℑλTF2=0uminλTF2>0whereis the Switching Function [18,19].Next section presents the basic concepts about multi-objective optimization, as well general aspects about DE and its extension to the multi-objective context.The Multi-objective Optimization Problem (MOP) is very common in different areas such as mathematics, engineering and sciences in general. This problem is different from that of a single-objective optimization since MOP usually has not only one but a set of non-inferior optimal solutions, known as Pareto's solutions (that form the so-called Pareto's curve). Besides, the optimality concept for this kind of problem is different from the one used in single optimization problems since in multi-objective optimization is not possible to find a single optimal solution that satisfies all the goals simultaneously [31].The notion of optimality for MOP is different from the one used for single optimization problems. The most common idea about multi-objective optimization found in the literature was originally proposed by Edgeworth [32] and later generalized by Pareto [33]. This idea can be described as follows [33]: “a solution is optimal if its dominated by no other feasible solution, which means that there exists no other solution that is superior at least in case of one objective function value, and equal or superior with respect to the other values of the objective functions”. This definition leads to finding a set of solutions that is called the Pareto optimal set, whose corresponding elements are called nondominated or non-inferior solutions.In the literature, there are several methods available in the literature for solving MOPs [31,34]. These methods follow a preference-based approach, in which a relative preference vector is used to scalarize multiple objectives. As classical optimization methods use a point to point approach, in which a solution found for a given iteration is modified to obtain a new solution, the outcome of using a classical optimization method is a single optimized solution. On the other hand, the evolutionary algorithms can find multiple optimal solutions in one single simulation run due to their population-based search approach, being this way well adapted for multi-objective optimization problems. More details regarding the corresponding methodologies can be found in the literature [31,34].Mathematically, the MOP is defined as [31]:(17)min[f1(x)f2(x)…fk(x)]subject to m inequality and l equality constraints(18)gi(x)≤0,i=1,..,m(19)hj(x)=0,j=1,..,land design space defined according to the decision (or design) variables(20)xnU≤xn≤xnL​,n=1,…,N.where k is the number of objective functions fi:ℝN→ℝ.In the last decades, several algorithms based on evolutionary mechanisms have been proposed to find approximations to the Pareto optimal solutions. As reported in the literature, the first Multi-objective Evolutionary Algorithm (MEA) was the Vector Evaluated Genetic Algorithm [35]. On one hand there is a first group known as the first-generation, which includes all the early MEAs: Vector Evaluated Genetic Algorithm [35], Non-dominated Pareto Genetic Algorithm [36], Non-dominated Sorting Genetic Algorithm [37]. On the other hand, there is a second group named the second-generation MEAs, which comprises very efficient optimizers like Strength Pareto Evolutionary Algorithm [38], Non-dominated Sorting Genetic Algorithm II [39], and Multi-objective Optimization Differential Evolution [30], among others. Basically, the main features that distinguish the second-generation MEAs from the first-generation group is the mechanism of adaptation assignment in terms of dominance and the incorporation of elitism [31,39].Differential Evolution (DE) is an optimization technique that belongs to the family of evolutionary computation, which differs from other evolutionary algorithms in the mutation and recombination schemes [23,24,30]. DE executes its mutation operation by adding a weighted difference vector between two individuals to a third individual. Then, the mutated individuals will perform discrete crossover and greedy selection with the corresponding individuals from the last generation to produce the offspring.A classical DE algorithm is presented next [24].NP is the population size, P is the population of the current generation, and P‘ is the population to be formed for the next generation, C[i] is the candidate solution with population index i, C[i][j] is the j-th entry in the solution vector of C[i], r is a random number between 0 and 1, CR is the crossover constant, and F is the weight applied to the random differential (scaling factor).Storn and coworkers [24] have given some simple rules for choosing the key parameters of DE for general applications. Normally, NP should be about 5 to 10 times the dimension (number of parameters in a vector) of the problem. As for F, it lies in the range 0.4 to 1.0. Initially F = 0.5 can be tried, then F and/or NP is increased if the population converges prematurely. These authors proposed various mutation schemes for the generation of new vectors (candidate solutions) by combining the vectors that are randomly chosen from the current population as shown:•rand/1:x=xκ1+F(xκ2−xκ3)rand/2:x=xκ1+F(xκ2−xκ3+xκ4−xκ5)best/1:x=xbest+F(xκ2−xκ3)best/2:x=xbest+F(xκ2−xκ3+xκ4−xκ5)rand/best/1:x=xκ1+F(xbest−xκ1+xκ1−xκ2)rand/best/2:x=xκ1+F(xbest−xκ1)+F(xκ1−xκ2+xκ3−xκ4)In this section, the Multi-objective Optimization Differential Evolution (MODE) algorithm proposed by Lobato and Steffen Jr [30] to solve multi-objective optimization problems is presented. This evolutionary strategy differs from other algorithms by the incorporation of two operators to the original DE algorithm, namely the mechanisms of rank ordering [31,38] and exploration of the neighborhood potential solution candidates [40]. The general structure of the proposed algorithm for MOOP using DE is briefly described in the following [30]. An initial population of size NP is randomly generated. All dominated solutions are removed from the population through the operator Fast Non-Dominated Sorting [31]. This procedure is repeated until each vector is a member of a front. Three parents are selected at random in the population. A child is generated from the three parents (this process continues until NP children are generated). Starting from population P1 of size 2NP, neighbors are generated to each one of the individuals of the population in the following way [40]:(21)χ(x)=[x−Dk(g)/2,x+Dk(g)/2]where(22)Dk(g)=kR[U−L]Dk(g) is a vector inℝnand a function of the generation counter g. R is the number of pseudo fronts defined by the user and the initial maximum neighborhood size in a population is Dk(0) = [U − L], where L and U represent the lower and upper bounds of the variables. The predefined number of individuals in each pseudo front is given by [40]:(23)nk=rnk−1k=2,…,Rwhere nkis the number of individuals in the k-th front and r (<1) is the reduction rate. For a given population with N individuals, nk can be calculated as:(24)nk=N1−r1−rRrk−1According to Hu and coworkers [40], if r< 1, the number of individuals in the first pseudo front is the highest, and each pseudo front has an exponentially reducing number of solutions, this emphasizing a local search. On the contrary, a greater value for r results in more solutions in the last pseudo front and hence emphasizes the global search.In this way, the neighbors generated are classified according to the dominance criterion and only the nondominated neighbors (P2) will be put together with P1 to form P3. The population P3 is then classified according to the dominance criterion. If the number of individuals of the population P3 is larger than a number defined by the user, its truncated according to the criterion of the Crowding Distance [31]. The crowding distance describes the density of solutions surrounding a vector. To compute the crowding distance for a set of population members, the vectors are sorted according to their objective function values for each objective function. To the vectors with the smallest or largest values, an infinite crowding distance (or an arbitrarily large number for practical purposes) is assigned. For all other vectors, the crowding distance is calculated according to:(25)distxi=∑j=0m−1fj,i+1−fj,i−1|fj,max−fj,min|where fjcorresponds to the j-th objective function and m equals the number of objective functions.

@&#CONCLUSIONS@&#
In this contribution, a new multi-objective optimization problem considering both the minimization of the cancerous cells concentration and the prescribed drug concentration to determine an optimal protocol for drug administration in the treatment of tumors was proposed. To solve this problem, the Multi-objective Optimization Differential Evolution (MODE) algorithm [30] was used. In addition, the results obtained from the application of MODE for three test-cases are compared with those obtained by the Non-dominated Sorting Genetic Algorithm (NSGA II) demonstrating that an optimal protocol can be obtained for the drug administration that satisfactorily fulfills both the objectives. It is important to mention that the results obtained are valid for the parameters used in the differential model, i.e., this work is purely theoretical, however, a proof of the concept was demonstrated. Consequently, the use of a mathematical model associated with optimization tools may contribute in the future to the development of optimal protocols to be used in real patients. As mentioned by Pillis and Radunskaya [2], these solutions are not guaranteed to be globally optimal protocols and it may be possible to find other protocols that are just as effective but use less total drug administration. The authors are aware of the difficulties of transferring the numerical results to real world conditions. However, it is important to recognize the potential of the present study for the development of new protocols for cancer treatment. It is worth mentioning that the problem formulated in this work is not normally considered in the specialized literature (only the minimization of the cancerous cells concentration is normally proposed). In this context, the formulation of the multi-objective optimization problem and its solution by using the MODE algorithm represents the main contribution of this research effort. As a sequence of this work, we intend to evaluate other models of carcinomas and compare the obtained optimal protocols with medical protocols used in traditional treatments.