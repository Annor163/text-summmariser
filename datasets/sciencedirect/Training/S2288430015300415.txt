@&#MAIN-TITLE@&#
Depth edge detection by image-based smoothing and morphological operations

@&#HIGHLIGHTS@&#
A method is proposed that can detect edges from depth images more profoundly.We modified the Canny edge detection method using morphological operations.The proposed method works in multi-frames.

@&#KEYPHRASES@&#
Edge,Depth Image,Smoothing,Morphology,

@&#ABSTRACT@&#
Since 3D measurement technologies have been widely used in manufacturing industries edge detection in a depth image plays an important role in computer vision applications. In this paper, we have proposed an edge detection process in a depth image based on the image based smoothing and morphological operations. In this method we have used the principle of Median filtering, which has a renowned feature for edge preservation properties. The edge detection was done based on Canny Edge detection principle and was improvised with morphological operations, which are represented as combinations of erosion and dilation. Later, we compared our results with some existing methods and exhibited that this method produced better results. However, this method works in multiframe applications with effective framerates. Thus this technique will aid to detect edges robustly from depth images and contribute to promote applications in depth images such as object detection, object segmentation, etc.

@&#INTRODUCTION@&#
As depth edges represent object contours [1,2], proper edge detection offers a significant role in various computer vision problems. Edge maps contain part of geometric information of natural scenes; especially in the case of depth images, depth discontinuities separate foreground objects from the background and can be used for various image processing tasks such as segmentation or denoising [3]. Even though there have been some rapid progresses in the field of image patch classification [4–6] object detection is still an active research topic.The 3D measurement technology is generally based on calculating depth information of objects in a scene. There has been some work in 3D measurement technologies, where researchers tried to acquire the depth information of objects in a scene by using stereo cameras [7–9]. However, this approach is limited because stereo cameras are able to work in the scenes containing plentiful textures. Some people used three dimensional laser range finders [10,11]. They were successful to produce accurate depth data. But they cannot use this device to real-time applications due to their expensive apparatus. Even some pattern-based methods [12–15] were used to produce a depth map but those methods also have some limitations with respect to the cameras and object positions. Since the rapid growth of the availability of inexpensive RGB-D sensors such as Apple Prime Sense, Microsoft Kinect, Intel Real Sense, etc., a lot of breakthroughs have been achieved for several tasks such as 3D modeling [16], segmentation [17] and body pose estimation [18,19]. Though these sensors helped us to achieve depth maps but very few methods have been applied to analyze such maps in terms of edge detection.Accurate edge detection from a depth image is essential for some object detection processes [20], which are dependent on a model of particular shape. A proper edge detection process can be used for various Human action analysis [21] problems in a real environment such as walking, spotting and sitting. Existing edge detection processes in depth images, however, cannot be applied in these types of situations due to some limitations. Some methods of edge detection in depth images [22] failed to deliver noise-free depth images; thus proper edge detection cannot be achieved. Some other methods [22,23] work in edge detection in depth images. However, they only work for a single frame. When they are applied to problems requiring processing multi-frames, these methods may fail as they cannot deal with newly generated noises in each frame, such as flickering problems.In this paper, we proposed a method that can detect edges from depth images more profoundly. This method can detect continuous edges, which are very important when we try to detect a large object from an image such as a human body. To detect continuous edges, we modified the Canny edge detection method by incorporating morphological operation. The morphological operation generally deals with shape of features in an image. It has been used to remove imperfections from various types of shape such as object boundaries, skeletons, etc. This operation generally consists of two operators; erosion and dilation. The first operation, denoted as opening, smooths the contour object, breaks narrow strips and eliminates thin protrusions. The second operation, called closing, also smooths contours but in contrast with opening; it fuses thin discontinuities, eradicate trivial holes and fills gaps in the contour. This method also works in multi-frames, whereas the previous methods detect edges in a single frame.This paper is structured as follows: Section 2 explains the overall framework of the proposed system. It also presents the way by which a depth image is acquired. In Section 3, we present a process for smoothing the depth image. Section 4 represents an edge detection process in the depth image. In Section 5 we show our experimental results for different scenes and compare our results with an existing method. Finally Section 6 concludes this paper along with some directions for possible future work.InFig. 1 we have illustrated the overall framework of the proposed system. Here, a depth image has been acquired by using Microsoft Kinect. The data captured from Kinect has to be processed in a certain way. After proper processing of the Kinect data we smooth the depth image for reducing the level of noises using the principle of Median filtering. Later, we move on to the edge detection process with the smoothed depth image. Here, we use the principle of Canny Edge Detection and modified it with Morphological operations for gaining better performance. The morphological operations are opening and closing operations. In this section we discuss the technical approaches for gaining the depth image from Kinect and process it for additional applications. Microsoft provides some built-in libraries which have been used in this work for acquiring the depth image. However, there are some preprocessing task for using Microsoft Kinect. NuiGetSensorCount function has been used to make sure the numbers of sensors ready for use. NuiImageResolutionToSize function has been used to make sure the numbers of sensors ready for use. NuiImageResolutionToSize function has been used to acquire the width and height of the depth frame and INuiSensor::NuiImageStreamOpen function has used to initialize the sensor to stream out the depth data. Once we have started to get the depth stream we had started to capture the data from the next frames by using INuiSensor:NuiImageStreamGetNextFrame and by using INuiSensor:NuiImageStreamReleaseFrame each frame has been released after saving it.Once we capture the depth data frame by frame it is essential to converse with Kinect to get the depth data, particularly one frame at a time. In this situation, we have used an abstract base class called KinectHelper which holds the functions for this type of communication. Here, we have used KinectHelper:UpdateDepthFrame method to update the frame of depth data and later by using KinectHelper:GetDepthImageAsArgb we acquired the Kinect data formatted as ARGB. Once we found this data we would be able to progress our later algorithms as per our later obligations.In this section we will explain the principle that we have used to reduce the level of noises in our acquired depth image. Here we have used the Median filtering principle [24].There are several filters for removing noises from images. However, the median filter is different from most of the existing ones. The most important feature of Median filter is that it preserves edges while removing noises. Basically, Median filter analyzes through every image pixel and replaces every image pixel by pixel by the median of the pixels in the corresponding filter region R. This process can be expressed according to the following equation:(1)I’(u,v)→median{I(u+i,v+j)|(i,j)ϵR}Here, (u,v) is the position of the image pixel and (i,j) is the neighborhood size of the image region and these are specified as a two element numeric vector of positive integers. By using median filtering, each output pixel contains the median value in the i-by-j neighborhood around the corresponding pixel in the input image.Now, as this filter replaces the pixel values with median values the median of 2K+1 pixel values pican be defined as(2)Median(p0,p1,p2,…,pk,…,p2k)ƛ=pkIn Eq. (2) the center value will be pkif the sequence (p0,…,p2k) is sorted by(pi.ℂ.pi+1); sorted according to their numerical values. As the median filter does not generate any new valued pixels that are not in the image before Eq. (2) defines the median of an odd sized set of values. In the situation where the side length of the rectangular filters are odd, then the number of elements in the filter region becomes odd as well. For the other case where the number of elements is even (2K for some K>0), then the median of the sorted sequence (p0,…,pk−1) will be defined as the following equation:(3)Median(p0,...,pk−1,pk,…,p2k−1)=(pk−1+pk)/2In this equation, the arithmetic mean of the two middle values, pk−1 and pkhas been considered as the median of the sequence. As this interpolation creates a new pixel value the region for the median filter is considered to be of even size.InFig. 2 we have shown the effects of the 3×3 pixel median filter region in a certain two dimensional image structure. Here, all the nine values extracted from this image region are sorted as a vector. The center value in the vector is considered as the median and eventually replaces the center value of the prescribed pixel region.In our algorithm, however, we have used the same principle except that we have used a 5×5 pixel median filter in our depth image structure. In the example section we have illustrated the effect of this median filtering technique.This section illustrates the edge detection process of our system. Here, we have used the principle of Canny edge detection process. For achieving better performance we have modified it with some Morphological operations [27].There are several edge detection operators in the image processing field and Canny edge detector [25] is one of the most effective detectors. It is able to perceive an extensive range of edges in an image. As it meets accurately the general criteria’s for edge detection and the implementation process is quite simple it has achieved well-earned recognition for edge detection. In the following sections we explain the process of Canny Edge detection algorithm [26]:The process of Canny Edge detection algorithm can be categorized into five different steps:1.Smoothing: To remove noise from the image, smoothing or blurring operation are performed.Finding gradients: After having the gradients of the image, edges should be marked only in those areas where large magnitudes are obtained.Non-maximum suppression: Only local maxima should be considered as edges.Double thresholding: Prospective edges are determined by double thresholding.Edge tracking by hysteresis: After suppressing all the edges that are not connected to a very certain or strong edges, those will be considered as the final edges.In our work, we do not use all of these steps as we have already applied the smoothing operation by using Median filtering. So we skipped the first step and the other steps had been done for our method. Later on, by introducing Morphological operation we have modified this edge detection process and in terms of depth image this process is completely new.Though Canny Edge detector has been able to detect the edges in a certain manner, to achieve more accurate edge detection from a depth image we have modified this edge detection process using morphological operations. These operations are generally a collection of nonlinear operations carried out comparatively on the ordering of pixels without affecting their numerical values. The key operators for morphological operations are erosion and dilation. In the following we explain the morphological operations [27] used in our method. Based on the shape or morphology of features in an image morphological image processing continues to do some collection of nonlinear operations. These operations depend on the relative ordering of pixel values rather than the numerical values and consequently are especially appropriate for processing binary images. However, morphological operations can be used in other types of images as well, such as grey-scale images. In grey scale images the light transfer functions are unknown and thus their absolute pixel values are of no or minor concern. Usually, Morphological techniques investigate an image by using a small shape or template, which is called the structuring element. This structuring element is usually placed at all probable locations in the image and then compared with the corresponding neighborhood pixels. During this operation, this technique tests whether the element “fits” within the neighborhood or whether the element “hits” or intersects the element.Fig. 3 shows how these operations are carried out over image pixels. In case of binary images, if the test is successful at a particular location then this operation creates a new binary image in which the pixel contains a non-zero value at that particular location of the input image.The structuring element used in this morphological operation is a small binary image, a small matrix of pixels where each of the pixels contains with the value of zero or one. The key explanation can be written as follows:•The matrix dimensions specify the size of the structuring element.The pattern of ones and zeros specifies the shape of the structuring element.An origin of the structuring element is usually one of its pixels, although generally the origin can be outside the structuring element.In our research, we have used a morphological operation that is represented as a combination of erosion and dilation. The first operation is called opening and the other is called closing. Opening is a morphological filter where erosion is followed by dilation. And, closing is a morphological filter where dilation is followed by erosion.These morphological operations can be explained in terms of set-theoretic operations such as the complement of a binary image:fc(a,b)=1iff(a,b)=0,andfc(a,b)=0iff(a,b)=1Here, the complement, fcis the set of elements that are not contained in image f.Now, the intersection I=f ∩ g of two binary images f and g can be explained as the following equations:I(a,b)=1iff(a,b)=1andg(a,b)=1,andI(a,b)=0otherwiseThe union U=f ∪ g of two binary images f and g can be explained as the following equations:U(a,b)=1iff(a,b)=1org(a,b)=1,andU(a,b)=0otherwiseIn the following we explain the opening and closing operations [27], respectively.The opening of an image f by a structuring element s (denoted by f∘s) is an erosion (denoted by ?) followed by a dilation (denoted by⊕):f∘s=(f⊖s)⊕sThe reason for calling this operation opening is because it can open up a gap between objects connected by a thin bridge of pixels. As part of this operation, the regions which may have survived the erosion operation will be restored to their original size by dilation. The benefit of opening with a disc structuring element is that it smoothens corners from the inside. And, by doing the entire operation it removes further noise, round corners from inside and abridges the image.The closing of an image f by a structuring element s (denoted by f • s) is a dilation (denoted by ⊕) followed by erosion (denoted by ?):f•s=(f⊕s)⊖sIn morphological operations, closing is originated because it is able to fill holes in the regions while keeping the initial region sizes unchanged.This closing operation with a disc structuring element is kind of opposite to the opening operation as smoothens corners from the outside. The main objective of this operation is to smoothen the contour and maintains the shape and size of object.As combination of both of these operations we are able to get better results for detection edges in depth image.In this section we have illustrated the result of our research. We have organized the results inFig. 4 as follows: the first pictures of each row represent the RGB image of the scene (Fig. 4a, e, and i) and the following ones denote the raw depth image of that particular scene (Fig. 4b, f, and j). Later, we have shown the outcome we have achieved by applying the median filter (Fig. 4c, g, and k). The fourth and final pictures of each row show our final results obtained by the proposed method (Fig. 4d, h, and l). In this paper we have illustrated our results for four different scenes.For comparing our results with existing methods we have implemented a framework developed by Lejeune et al. [22] and compared our results with theirs. In the following we have shown the result of an edge detection process in similar scenes. In the figures ofFig. 5(i), (iii) and (v), we have presented the edge detection method developed by Lejeune et al. [22] and in the other figures of Fig. 5(ii), (iv) and (vi) we have shown the results of our edge detection method for the same scene sequences.It is clearly shown that by using our technique the level of noise has been reduced significantly. And, in the figures (Fig. 5(i), (iii) and (v)) from the reference method it is also found that some of the edges were not preserved, which were preserved by our technique. To understand these areas clearly we have highlighted those areas with red circles where this type of continuous edge detection was failed on the reference method. Besides this the contours of the various shape have also been improved by using our method.We have also measured the computation time for both of these approaches; the Ref. [22] one and our proposed one inTable 1. We have shown that in terms of computation time our method works faster than the reference one. Both of the methods were tested using the same system with an Intel Core i5 CPU, 8 GByte RAM and Intel(R) HD Graphics 4000.

@&#CONCLUSIONS@&#
