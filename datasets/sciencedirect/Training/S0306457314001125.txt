@&#MAIN-TITLE@&#
Learning combination weights in data fusion using Genetic Algorithms

@&#HIGHLIGHTS@&#
Genetic Algorithm is an effective scheme in determining data fusion weights.Tuning Genetic Algorithm increases time efficiency.Weight learning from only top ranked documents is useful.Redundant runs can be removed based on correlation between scores.

@&#KEYPHRASES@&#
Information retrieval,Data fusion,Linear combination,Genetic Algorithms,

@&#ABSTRACT@&#
Researchers have shown that a weighted linear combination in data fusion can produce better results than an unweighted combination. Many techniques have been used to determine the linear combination weights. In this work, we have used the Genetic Algorithm (GA) for the same purpose. The GA is not new and it has been used earlier in several other applications. But, to the best of our knowledge, the GA has not been used for fusion of runs in information retrieval. First, we use GA to learn the optimum fusion weights using the entire set of relevance assessment. Next, we learn the weights from the relevance assessments of the top retrieved documents only. Finally, we also learn the weights by a twofold training and testing on the queries. We test our method on the runs submitted in TREC. We see that our weight learning scheme, using both full and partial sets of relevance assessment, produces significant improvements over the best candidate run, CombSUM, CombMNZ, Z-Score, linear combination method with performance level, performance level square weighting scheme, multiple linear regression-based weight learning scheme, mixture model result merging scheme, LambdaMerge, ClustFuseCombSUM and ClustFuseCombMNZ. Furthermore, we study how the correlation among the scores in the runs can be used to eliminate redundant runs in a set of runs to be fused. We observe that similar runs have similar contributions in fusion. So, eliminating the redundant runs in a group of similar runs does not hurt fusion performance in any significant way.

@&#INTRODUCTION@&#
Data fusion has been used as an effective tool for improving information retrieval performance. Several IR researchers have proposed several methods of combining two or more retrieved lists to produce a single list that contains the useful documents from all the lists at higher ranks. Given a set of retrieved lists (or runs, as they are popularly referred to) and given a fusion algorithm, it is vital to choose the combination weights which will result in improvement in performance. Previous results show that weighted fusions have scored over unweighted fusions when appropriate weights are assigned to the fused runs (Wu et al., 2009). Much research has been done on learning or optimizing the fusion weights. Vogt and Cottrell (1998) have tried to predict the fusion performance of run pairs using multiple linear regression based on several features. Wu et al. (2009) stated that power functions can be useful in finding good weights for fusion. Bartell et al. (1994) also tried to maximize fusion performance. In the last two papers, Conjugate Gradient method (Press et al., 1995) on Guttman’s Point Alienation function (Guttman, 1978) was used. Vogt and Cottrell used golden search method (Press et al., 1995) for optimization.The Genetic Algorithm (GA) has been used in finding useful solutions to optimization and search problems. GAs generate solutions to optimization problems by using techniques inspired by natural evolution. GAs can thus be used in learning the optimum fusion weights for a weighted linear combination of retrieval scores of different runs.Next, we study how the use of the top ranked documents on linear combination of scores can be used to get an optimal retrieval performance. We consider runs at a given depth k per query and run the optimization algorithm on them. The optimum weights thus learned are tested on the runs. The idea of using the top k documents is modeled on Multi-armed Bandits problem (Auer et al., 1995) where the gambler has no initial knowledge about the levers and tries to maximize the gain based on existing knowledge of each lever. Here we attempt to use partial knowledge about the IR performance of each run to learn the optimal fusion weights. Pal et al. (2011) found that reducing pool size per topic does not have much effect on evaluation. We draw our motivation from this observation also.We also study how the correlation between the scores of runs can help in removing the redundant runs in data fusion. We calculate the correlation values among the run pairs. First we choose the run pair with the highest correlation between them and drop the run which has the inferior retrieval performance. We fuse the remaining runs and see if there is any significant drop in fusion performance. If not, we consider the pair with the next highest correlation. We repeat the procedure until there is a significant drop in performance. This study is aimed at exploring if highly correlated runs in terms of retrieval scores have similar contribution in fusion performance.Our contributions made in the present paper are summarized below:1.Given a set of runs, a GA based approach to finding the optimal weights for an efficient fusion of these runs on the basis of their retrieval scores, is proposed.It is shown that if the learning of the fusion weights by the GA is based only on the top-ranked documents, there is not much loss in efficiency of the resulting fusion. In other words, if only lower depths in the ranked pool of documents are used by the GA to learn the fusion weights, the performance of the resulting fusion is not hurt much.A new approach to determination of the runs that make insignificant contributions in fusion, and hence to determination of the smallest subset of the runs to be fused, without much loss in efficiency, is proposed. It is based on the fusion weights learnt by the GA and the correlation coefficients between pairs of runs obtained on the basis their retrieval scores.The rest of the paper is organized as follows:We provide a discussion on the related works in Section 2. In Section 3, we describe the GA and discuss how this algorithm can be used in the present fusion problem. The experimental setup is described in Section 4. We present our experimental results and a comparative study in Section 5 and conclude in Section 6.Suppose f is a real-valued function defined on a bounded setA=[a1,b1]×[a2,b2]×⋯×[ap,bp]where[ai,bi]is an interval on the real line. The goal of the GA is to find a pointx0=(x10,x20,⋯,xp0)in A such thatf(x0)=maxx∈Af(x). For actual implementation of the GA, a grid is super-imposed on the set A and let S be the set of the grid points. S represents A in a discretised manner and the representation becomes more accurate with a higher resolution of the grid. What the GA actually finds is a pointy0=(y10,y20,⋯,yp0)in S such thatf(y0)=maxy∈Sf(y). A higher resolution of the grid will takey0closer tox0. Every grid pointyin S corresponds to a binary string of length, say, L where a larger L indicates a higher resolution of the grid.For example, let us consider a function f defined onA=[0,10]×[0,10](Fig. 1) asf(x1,x2)=exp{-(x1-5)2-(x2-5)2}. Note that the maximum value of f occurs atx0=(5,5). Now, let the interval corresponding to eachxibe discretised on the basis of binary strings of length 3 where the binary strings 000 and 111 represent the values 0 and 10 respectively. In general, supposeM=(b1b2b3,b4b5b6)is a grid point in S where the binary stringsb1b2b3andb4b5b6represent the discretised values ofx1andx2respectively (Fig. 2). Then the corresponding point inA=[0,10]×[0,10]is computed as follows. Letz1andz2be the two decimal values corresponding to the binary numbersb1b2b3andb4b5b6respectively. Clearly,zibelongs to{0,1,⋯,7}. Then(y1,y2)=(10z1/7,10z2/7)is the point in A corresponding to the grid point M in S. Thus, the value of f at the grid pointM=(b1b2b3,b4b5b6)is in fact the value of f at(y1,y2)in A. The task of the GA is to find the grid point at which the value of f is maximum. Note that here the number of grid points is only 64 and the maximum f value attainable at these grid points (i.e.,f(y0)) will be much less thanf(x0). However, if the length of the binary string is increased for discretisingx1andx2, the value off(y0)will be closer tof(x0)due to higher resolution of the grid. For example, if the length of the binary string is increased from 6 to 8, the number of grid points will increase from 64 to 256 resulting in an enhanced value off(y0). The GA in fact operates on the binary strings representing the grid points of S. However, it converts such a string into a pointxin A whenever needed. The details are provided in the sub-sections below.An optimization approach is based either on exploration or on exploitation or on both. The GA is based on both these aspects and hence is capable of avoiding getting stuck at a local optimum. Mutation and crossover operations described below contribute to exploration and exploitation respectively. Moreover, the GA is applicable even if the function to be optimized is not differentiable or not even continuous or not even having a closed form. The convergence properties of the GA are discussed later in this section.The basic steps of the GA are:A initial populationP1={y1,y2,⋯ym}of m grid points (or members) selected at random from S is formed where m (called the population size) is an even integer. One way of making such a random selection is to select 0 or 1 each with probability 0.5 for all the positions in the binary string corresponding to each of the m members inP1. This population undergoes changes through several iterations (each such iteration is called a generation in the GA parlance). One generation consists of selection, crossover, mutation and elitism operations that are described below. The value of m is taken as 30 in our experiments.The fitness value of a memberyiof the populationP1is defined asf(yi). LetF=∑i=1mf(yi). Now, a random selection of one member fromP1is made in such a way that the probability ofyibeing selected isf(yi)/F. Note that a member having a higher fitness value is more likely to be selected. This process is repeated m times so that a new setP2of m members is generated fromP1. The two setsP1andP2are not necessarily the same. A member having a smaller fitness value inP1is more likely to disappear fromP2. On the other hand, a member having a higher fitness value inP1is more likely to appear more than once inP2.A random pairing of the m members ofP2is done. Each such pair creates a pair of offspring through crossover operation. A site (in the binary string) is first selected at random with equal probability (here there areL-1sites). On the basis of this site, the two members are split into heads and tails as (head1,tail1) and (head2,tail2). Then the two offspring are defined as (head1,tail2) and (head2,tail1). Each pair of members undergoes the crossover operation with probabilitypc. If a pair is selected for crossover operation, the question of site selection arises. Otherwise, this does not arise and the members become their offspring (that is, the two corresponding binary strings remain unchanged). LetP3denote the population obtained after crossover. In our experiments, the value ofpcis taken as 0.7. In Table 1, a crossover example is shown whereL=15and the selected site is 5.In mutation operation, one of the L positions in a binary string is randomly selected with equal probability and the binary value in the selected position is swapped (that is, “0” is changed to “1” and “1” is changed to “0”). Each offspring after crossover operation undergoes the mutation operation with probabilitypm. The value ofpmis taken as 0.2 in our experiments. If an offspring is not selected for mutation operation, its corresponding binary string stays unchanged. In Table 2, offspring 1 and 2 are mutated at positions 4 and 7 respectively. LetP4denote the population obtained after mutation operation. We reduce the mutation probability over time initially starting atpm=0.2. Mutation operation takes care of the exploration aspect of the GA search algorithm. A larger value ofpmleads to more exploration. This value is normally kept fixed at a value around 0.01. However, in our implementation, we start with a high value and keep reducing it through generations. Initially starting atpm=0.2, we reduce it by a factor of 0.9 after every 25 generations. The idea here is that as the algorithm progresses, the need for exploration gets reduced. In that case, a lower value ofpmsuffices. On the other hand, if the value is large compared to the progress that the algorithm has made, unnecessary time is spent on exploration. In other words, we deliberately reduce the search space while making sure that the reduced search space contains the globally maximum value.In elitism operation, the member having the highest fitness value in the population in one generation is carried over to the population in the next generation replacing the member having the lowest fitness value. Thus, in any generation, the population contains the member having the highest fitness value across all the past generations. Note that this fittest member takes part in selection, crossover and mutation operations and is more likely to produce members with high fitness values. LetP5be the population obtained after elitism operation.The role of mutation in GA has been that of restoring lost or unexplored genetic material into the population to prevent the premature convergence of the GA to suboptimal solutions (Srinivas and Patnaik, 1994). Large values of mutation probability transform the GA into a purely random search algorithm, while some mutation is required to prevent the premature convergence of the GA. Rudolph (Rudolph, 1994) has described the GA as a Markov chain, and has proved that an elitist GA converges to the global maximum of the fitness value irrespective of the initial population.We will now illustrate how the above operations in the GA described above, are actually implemented. For this, we consider the exponential function described in the beginning of this section. Let m, the population size, be 4. Thus, in the initialization stage, 4 grid points are randomly selected from the 64 grid points shown in Fig. 2 to form the initial populationP1of size 4. Let us assume that these 4 randomly selected grid points representing populationP1, are what is shown in the first column of Table 3. Now the functional values of these 4 grid points are computed the way it is described in the beginning of this section. These functional values are shown in the second column of Table 3. The probabilities of the 4 members of the population are computed as described in Section 3.1.2. These probabilities are shown in the third column of Table 3. Now a member from the first column is selected at random using the probabilities in the third column. Let it be “101011”. This is the first entry in the fourth column representing populationP2. This random selection is repeated another three times and the outcomes are shown in the last three entries of the fourth column. Note that the member (i.e., “101011”) in populationP1having the highest probability is selected twice in populationP2. Also, the member (i.e., “000001”) in populationP1having the lowest probability is not selected in populationP2. Here stronger members (i.e., having higher f values) are more likely to survive in the selection process.Now, the members in the fourth column are paired at random. An example of such pairing is shown in the fifth column. A pair is now selected for crossover with probabilitypc=0.7. Suppose both the pairs in the fifth column are selected for crossover. For crossover, we have L−1=5 possible sites here. For each crossover, a site is selected with probability 1/5 (see Section 3.1.3). Suppose the two sites for the two pairs are 4 and 2 respectively. The populationP3thus created after crossover is shown in the sixth column. On the basis of the mutation operation as described in Section 3.1.4, suppose the fifth and sixth bits of the last two entries in the sixth column are selected for mutation. The resulting populationP4after mutation is shown in the seventh column. Now, note that the highest fitness value in the populationP1corresponds to “101011” while the member having the lowest fitness value in the populationP4is “100111”. So, in the elitism operation, “101011” replaces “100111” inP4. Thus, the final population of the current iteration isP5that is shown in the eighth column. The functional values of the members ofP5are shown in the last column.Thus, in one generation, the old populationP1(first column) is changed through the GA operations to a new populationP5(eighth column). In the next generation, the new populationP5takes the position (first column) of the old population and the whole process is repeated.Now we will discuss how the GA is implemented for our fusion data task. The value of L depends on the number of runs to be fused. In our experiments, we use 16 bits for the weight of each run. Asymptotically, the GA converges in the sense that the strongest member in the population converges to the optimal pointy0=(y10,y20,⋯,yp0)in S (Rudolph, 1994). However, we run the algorithm for a finitely many generations and the output of the algorithm is the member of the population for which the value f is the maximum. The number of generations needed for convergence of the GA depends largely on the number of runs to be fused. In our experiments, the number of generations varies from 25 to 1000.Letr1,r2,⋯,rNbe N runs on a query set Q with scoress1,s2,⋯,sNrespectively, for a given document and a query. Our aim here is to find a linear combination (in fact, a weighted average) ofs1,s2,⋯,sNthat produces maximum MAP value over all possible combinations. In other words, we would like to determine the weightsw1,w2,⋯,wN(0⩽wi⩽1and∑i=1Nwi=1) such that the new scores=w1s1+w2s2+⋯+wNsNleads to the highest MAP. We will use the GA described above to find these optimal weightswi. However, for the GA, the search space needs to be unconstrained while the search space A of(w1,w2,⋯,wN)here is constrained in the N-dimensional space. To overcome this, we will convert the constrained search space A in N dimensions to an unconstrained search space B in(N-1)dimensions such that there is one-to-one and onto mapping between A and B. It is clear that A corresponds to the surface of the positive quadrant of the unit N-dimensional hyper-sphere. B that we intend to map A to, is a rectangle in the(N-1)dimensional space. Just as an example, consider the surface of the positive quadrant of the unit sphere and the 2-dimensional rectangle[0,π/2]×[0,π/2]. One can see that there is one-to-one and onto mapping between them. Formally, B and the corresponding mapping are defined as follows:B=[0,π/2]×[0,π/2]×⋯×[0,π/2]((N-1)times), and(1)w1=sin2θ1w2=cos2θ1sin2θ2w3=cos2θ1cos2θ2sin2θ3w4=cos2θ1cos2θ2cos2θ3sin2θ4⋮wN-1=cos2θ1…cos2θN-2sin2θN-1wN=cos2θ1…cos2θN-2cos2θN-1whereθi∈[0,π/2]for all i.Let(θ1,θ2,⋯,θN-1)be a point in B and let(w1,w2,⋯,wN)be the corresponding point in A. Supposeg=w1s1+w2s2+⋯+wNsNdenotes the score of the run r produced by the linear combination (fusion) of the runsr1,r2,⋯,rNwith respective weights asw1,w2,⋯,wN. Note that g is a function of(θ1,θ2,⋯,θN-1). Let the number of relevant documents for an information needqj∈Qbemj. Suppose, for the fused runr,Rj,k={d1,d2,⋯,dk}is the set of k top ranked retrieved results. Now let a functionf(θ1,θ2,⋯,θN-1)be defined as:MAP(g,Q)=1|Q|∑j=1|Q|1mj∑k=1mjPrecision(Rjk) which is the mean average precision of run r on Q. Precision(Rjk) is the proportion of retrieved documents that are relevant forqjat the point in the ranked list when we get to the documentdk. Now our task is to determine the values ofθ1,θ2,⋯,θN-1(equivalently, the values ofw1,w2,⋯,wN) for which f is maximum.We use the GA described above to maximize the functionf(θ1,θ2,⋯,θN-1)over the unconstrained space B. Once the values ofθ1,θ2,⋯,θN-1maximizing f are obtained, the values of the optimal weightsw1,w2,⋯,wNare obtained from the Eqs. (1) above. These optimal weights define the best linear combination of the runsr1,r2,⋯,rNproviding the highest MAP.Pal et al. (2011) found that if pooling is done by choosing lower depths for each query, the quality of evaluation is not hurt. So, the top documents can be a good representative of the quality of the run. This is likely to be more prominent when top heavy measures like Mean Average Precision are used for evaluation. In this paper, we study how the documents at lower depths can be used in learning the fusion weights by the GA.Table 4shows the correlation coefficients between the MAPs of the fused runs at depth 1000 and the MAPs of the same runs at lower depths, viz., 100, 50 and 25. The MAPs even at lower depths show high correlation with the MAP values at depth 1000. This led us to believe that using only the documents at shallower depths may be sufficient in achieving good fusion runs by the GA.Letr1,r2,⋯,rNbe N runs which we want to fuse with optimum weights. For the GA, the objective function is the MAP of the fused run. That is, we want to maximize the MAP of the fused run. For each queryqj, we select the top d documents of each run. Let these new runs ber1d,r2d,⋯,rNd. Fig. 3gives a pictorial view of the situation. It shows, for a given query, N runs with documents at ranks 1 to 1000.dk_lis the document of run k at rank l. For example,d1_1,d1_2,⋯,d1_1000are the documents of run 1 at ranks1,2,⋯,1000respectively. Now if we consider topd=25documents of run 1, then the corresponding variant of run 1, sayr125, will contain the documentsd1_1,d1_2,⋯,d1_25and the documents at lower ranks will not be considered. We fuse these new runs with some weightsw1d,w2d,⋯,wNdto get a fused run, say,fd. This can be visualized in Fig. 4. In this figure K is the total number of documents in the fused run. Since each of the N runs contributes d documents in the fused run, so the fused run will contain ⩽N*dunique documents. Note that the inequality is because of the fact that some documents may appear in more than one run. If, for a given query, each of the N runs has d documents, then the fused run will contain a ranked union of all the documents in the runs participating in fusion. This fused runfdis nothing but a ranked pool of the top d documents (per query) inr1,r2,⋯,rN. Let the optimal weights (for which MAP offdis maximized) learned by the GA bew1d_opt,w2d_opt,⋯,wNd_opt. These optimal weights are then tested on the runsr1,r2,⋯,rNat depth 1000 (note that training was done using depth d which is much less than 1000). We will see if these learned weights yield good retrieval performance.Letr1,r2,⋯,rNbe N runs on a query q. Suppose, for the sake of simplicity, d is a document that appears in each of the N runs. Lets1,s2,⋯,sNrespectively be the similarity scores of d with q in the N runs. A run is the retrieval result of a search system which follows a certain retrieval algorithm. This retrieval algorithm varies largely over the runs and it is likely that different ranges of score are assigned to the retrieved documents in different runs. For example, in runr1the similarity scores may range from 43.085 to 447.169 whereas in runr2the range can be −0.99 to −0.56. Clearly, these values cannot be combined unless they are mapped to a common range, say, [0,1]. So, we use the following normalization scheme proposed by Lee (1997):normalized_score=score-min_scoremax_score-min_score.So, a scores1, for a document d and runr1, is normalized to, says1norm, using the above scheme, wheremin_scoreandmax_scoreare the minimum and maximum scores respectively among all the documents in the run for the given query q. Note that this normalization scheme maps all the scores in a run, for a given query, to the range [0,1]. That is, the maximum score is mapped to 1 and the minimum score is mapped to 0. The intermediate values are adjusted accordingly. We do this normalization for each run and get a set of normalized scores for document d (for query q):s1norm,s2norm,⋯,sNnorm. Then we perform a weighted combination (say, g) of the scores asg=w1s1norm+w2s2norm+⋯+wNsNnorm. So, g is the score of d in the fused run for a given query q. Now, we determine the weightsw1,w2,⋯,wNusing the GA such that for all the documents in all the N runs we get g scores that lead to optimum performance of the fused run. For the documents that appear in less than N runs for a given query, their scores in the runs where they do not appear, are set to zero.Letr1andr2be two runs andQ=q1,q2,⋯,qMbe a query set. LetD=d1,d2,⋯,dnbe the set of documents appearing in at least one of the two runs for at least one query. Let us now consider a query q from Q. Then for each documentdi, we have an ordered pair of scores (s1i,s2i), wheres1iis the score ofdifor run 1 ands2iis the score ofdifor run 2. We assign a zero score to the document in the run where it does not appear. For example, if document d appears in runr1with score s and is absent in runr2, then the pair of scores for the document d will be (s,0). Thus, for each query, we have n pairs of scores(s1i,s2i). For all the queries in Q, we have Mn such pairs. We remove(0,0)pairs, i.e., pairs where both the scores are zero. On the basis of the rest of the pairs, we compute the correlation coefficient between the scores obtained byr1andr2.

@&#CONCLUSIONS@&#
