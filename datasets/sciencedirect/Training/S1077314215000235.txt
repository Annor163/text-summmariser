@&#MAIN-TITLE@&#
Background modeling for generative image models

@&#HIGHLIGHTS@&#
Discussion of the implicit but unavoidable background model in generative image models.Analysis of common practical strategies to deal with the problem and their drawbacks.Explicit background models are proposed as a fundamental solution.The background model is introduced through an efficient likelihood ratio correction.The background correction clearly improves on face pose estimation and recognition.

@&#KEYPHRASES@&#
Generative models,Face model,Face analysis,Morphable Model,Bayesian model,Implicit background models,

@&#ABSTRACT@&#
Face image interpretation with generative models is done by reconstructing the input image as well as possible. A comparison between the target and the model-generated image is complicated by the fact that faces are surrounded by background. The standard likelihood formulation only compares within the modeled face region. Through this restriction an unwanted but unavoidable background model appears in the likelihood. This implicitly present model is inappropriate for most backgrounds and leads to artifacts in the reconstruction, ranging from pose misalignment to shrinking of the face. We discuss the problem in detail for a probabilistic 3D Morphable Model and propose to use explicit image-based background models as a simple but fundamental solution. We also discuss common practical strategies which deal with the problem but suffer from a limited applicability which inhibits the fully automatic adaption of such models. We integrate the explicit background model through a likelihood ratio correction of the face model and thereby remove the need to evaluate the complete image. The background models are generic and do not need to model background specifics. The corrected 3D Morphable Model directly leads to more accurate pose estimation and image interpretations at large yaw angles with strong self-occlusion.

@&#INTRODUCTION@&#
A human face in a typical image is surrounded by arbitrary background. In Analysis-by-Synthesis settings, generative, parametric face models such as Active Shape Models, Active Appearance Models or Morphable Models, serve to reconstruct the input face as well as possible [5,4,2]. Depending on its parameter values, the model produces a synthetic image which is then compared to the input image through its likelihood under the model for a given set of parameter values. Since the face only occupies a part of the input image and it can appear in front of any background, one avoids to include background into the model likelihood. Consequently, the likelihood considers only the visible parts and ignores the rest of the image. But as we show in this article, even though background is ignored, it is still present in the model likelihood in the form of an implicit and usually wrong background model.The wrong background model leads to a strong preference for background over the face. Wherever possible, the optimization algorithm will try to reduce the support of the face. This leads to unnatural optimal solutions which range from a strong shrinking effect to pose misalignment in non-frontal situations with self-occlusion (Fig. 1).The issues with the implicit background model become evident as soon as the visibility of model parts can change with respect to the model parameters. So far, most model fitting methods kept the visibility constant, either by model restriction or determining it in advance. For a fully automatic model adaption in unconstrained situations, the full flexibility of the face is needed and the visibility cannot be fixed in advance.Due to the unavoidable use of an implicit background model, we simply propose to use an explicitly controlled, image-based background model to resolve the problems. For practical implementations, we show how it is sufficient to correct the model likelihood for this background assumption without actually evaluating the whole background of the image. These minimal background models work by replacing the model likelihood by a likelihood ratio of model and background. The change in model likelihood is a fundamental change within the model likelihood and can be used to improve any fitting algorithm. It renders the desired interpretation more stable and leads to a likelihood maximum which is more consistent with the expectations of a face interpretation.We focus the discussion of the problem mainly on the 3D Morphable Model (3DMM) [2] but in principle, our results apply to different generative models. We present an analysis of the problem within the probabilistic interpretation of the 3DMM fitting problem from Sch√∂nborn [15] which reveals a variable domain of evaluation as the underlying problem.Model fitting at larger yaw angles is especially susceptible to effects of varying support size due to a large amount of self-occlusion and thus a changing visibility. We evaluate different background models with respect to their performance for pose estimation with the 3DMM. The empirical background model, based on a histogram of the image performs best in the evaluation. But all controlled background models lead to better results than the parasitic model arising from ignoring the effect.Standard fitting algorithms for generative face models evaluate the image difference in the model domain. They project the target image back into the normalized model view and compare within the model, termed model-based evaluation. On the other side, the likelihood can also be evaluated directly within the target image, called image-based evaluation. Image-based evaluation leads to higher quality reconstructions and more accurate pose estimations. Contrary to model-based evaluation, it is even more susceptible to effects of varying visibility since the support of the face in the image changes strongly in accordance with the parameters.We will first discuss the research background and theoretical setup followed by our analysis of the problem. The proposed solution using explicit background models is then discussed together with different choices of possible background models. In the evaluation part, we compare different models with respect to their performance solving a pose estimation problem, a face recognition problem and additionally, we qualitatively compare their performance on real-world images.

@&#CONCLUSIONS@&#
