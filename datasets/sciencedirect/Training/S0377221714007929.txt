@&#MAIN-TITLE@&#
Complexity results for flow shop problems with synchronous movement

@&#HIGHLIGHTS@&#
A corrected NP-hardness proof for the three machine synchronous flow shop.Investigation of machine dominance for synchronous flow shops.NP-hardness proofs and polynomial algorithms for special cases.A concise summary of known complexity results for synchronous flow shops.

@&#KEYPHRASES@&#
Flow shop,Synchronous movement,Complexity,Dominating machines,

@&#ABSTRACT@&#
In this paper we present complexity results for flow shop problems with synchronous movement which are a variant of a non-preemptive permutation flow shop. Jobs have to be moved from one machine to the next by an unpaced synchronous transportation system, which implies that the processing is organized in synchronized cycles. This means that in each cycle the current jobs start at the same time on the corresponding machines and after processing have to wait until the last job is finished. Afterwards, all jobs are moved to the next machine simultaneously. Besides the general situation we also investigate special cases involving machine dominance which means that the processing times of all jobs on a dominating machine are at least as large as the processing times of all jobs on the other machines. Especially, we study flow shops with synchronous movement for a small number of dominating machines (one or two) and different objective functions.

@&#INTRODUCTION@&#
A flow shop with synchronous movement is a variant of a non-preemptive permutation flow shop where transfers of jobs from one machine to the next take place at the same time. Processing of a job on the next machine may only start after the current jobs on all machines are finished, i.e. after the maximal processing time of the jobs that are currently processed. If the processing time of a job on a certain machine is smaller than this maximum, the corresponding machine is idle until the job may be transferred to the next machine. In contrast, in a classical flow shop the transfer of jobs is asynchronous: Jobs may be transferred to the next machine as soon as their processing on the current machine is completed and processing on the next machine immediately starts as soon as this machine is available.Complexity of production systems with synchronous movements was first discussed by Karabati and Sayin (2003). In their work the authors consider a cyclic production environment minimizing the completion time of one production cycle and prove that the problem isNP-hard for an arbitrary number of machines. Soylu et al. (2007) present a branch-and-bound approach to minimize the makespan in flow shops with synchronous transfers. Additionally, it is claimed that the three-machine flow shop problem with synchronous movement isNP-hard, but the proof seems to be flawed. We will present a correctNP-hardness proof for the three-machine case in this work. In Huang and Hung (2010) as well as Huang (2011), rotating production units with synchronous movement and a loading/unloading (L/U) station are considered. In this framework, a job enters the production unit at the L/U station and is then processed on all machines before returning to the L/U station where it is unloaded. A practical application of a synchronous flow shop was studied in Waldherr and Knust (2014). There, in the production process of shelf-boards at a kitchen manufacturer circular production units with eight machines incorporating synchronous movement are used.In this work we study the complexity of flow shops with synchronous movement which we will also call “synchronous flow shops” for short. Motivated by practical applications (e.g. Waldherr and Knust (2014)) and previous work concerning classical flow shop scheduling problems, we also investigate special cases involving machine dominance. A machine is called dominating if the processing times of all jobs on this machine are at least as large as the processing times of all jobs on the other machines. In other words, this implies that the dominating machines dictate the pace of the flow shop with synchronous movement. For example, in the practical application in Waldherr and Knust (2014) among the eight machines two dominating ones exist. Classical flow shop problems with dominating machines are well studied in literature. For example, efficiently solvable cases can be found in Monma and Rinnooy Kan (1983),Ho and Gupta (1995), and Xiang et al. (2000). In Wang and Xia (2005) dominating machines in no-wait flow shops are investigated.The remainder of this paper is organized as follows. After giving a formal description of the considered problems in Section 2, we study general synchronous flow shop problems in Section 3. Especially, we consider different objective functions for the two-machine case and show that the three-machine synchronous flow shop minimizing the makespan isNP-hard. In Section 4 we consider synchronous flow shop problems with dominating machines in general. Afterwards, we present complexity results for the situations of one and two dominating machines in Sections 5 and 6, respectively. Finally, in Section 7 a summary of all results and some concluding remarks can be found.In this section we describe the studied problems more formally and introduce the used notations. We consider a permutation flow shop with m machines M1, …, Mmand n jobs where job j consists of m operations O1j→ O2j→ … → Omj. Operation Oijhas to be processed without preemption on machine Mifor pijtime units. In a feasible schedule each machine processes at most one operation at any time, each job is processed on at most one machine at any time, and the jobs are processed in the predefined order. Furthermore, the jobs are processed in the same order on all machines.The processing is organized in synchronized so-called cycles (rounds) since jobs have to be moved from one machine to the next by an unpaced synchronous transportation system. This means that in a cycle all current jobs start at the same time on the corresponding machines. Then all jobs are processed and have to wait until the last one is finished. Afterwards, all jobs are moved to the next machine simultaneously. The job processed on the last machine Mmleaves the system, a new job (if available) is put on the first machine M1. As a consequence, the processing time of a cycle is determined by the maximum processing time of the operations contained in it. Furthermore, only permutation schedules are feasible, i.e. the jobs have to be processed in the same order on all machines.The time at which a job j has been processed on all machines and leaves the system is called its completion time Cj. Depending on the actual environment, for synchronous flow shops two possible definitions of completion times Cjmay be considered. In the first version, a job can immediately be removed from the last machine after it is completed. In the second version, a job can only be accessed after the whole cycle has been completed, i.e. the job may have to wait until all jobs on the other machines in the corresponding cycle are finished. A flow shop of the first type can easily be transformed into an equivalent flow shop of the second type by adding another machine with processing times 0 for all jobs after the last machine. Conversely, the reverse is not necessarily true. In general, a flow shop of the second type cannot be transformed into an equivalent flow shop of the first type. In this work we always consider the second type.The goal is to find a sequence (permutation) of the jobs such that a given objective function (e.g. the makespan Cmax  = max Cjor the maximum lateness Lmax  involving due dates) is minimized. With each sequence a corresponding (left-shifted) schedule is associated in which each operation starts as early as possible.We consider a small example with three machines, five jobs and the following processing times:j12345p1j31253p2j13211p3j11551Fig. 1shows two feasible synchronous flow shop schedules. The vertical lines indicate the cycles and show when the jobs are transferred to the next machine. In the left part of the figure the schedule corresponding to the job sequence (1, 2, 3, 4, 5) with makespan 23 is shown. Here, we can observe a long waiting period (idle time) on machine M3 between processing jobs 2 and 3: Although job 3 has already finished processing on machine M2 and job 2 has already been processed on machine M3, job 3 may not be transferred to machine M3 because it has to wait until job 4 is finished on machine M1. In the right part of the figure the schedule corresponding to the job sequence (3, 1, 4, 2, 5) with makespan 18 is shown. It is optimal for this instance.In general, a schedule consists of n + m − 1 cycles, which are divided into a starting phase (m − 1 cycles, until jobs are present on each machine), a standard phase (n − m + 1 cycles, as described above), and a final phase (m − 1 cycles, where no more jobs are available for M1).Extending the α|β|γ scheduling classification scheme from Graham et al. (1979), in Huang (2011) the notation “synmv” was added to the β-field in order to indicate synchronous movements. Hence, the notation F|synmv|f refers to a synchronous flow shop with objective function f. If the number of machines m is fixed (i.e. not part of the input), we will write Fm|synmv|f.In this section we consider general synchronous flow shops. Since a flow shop with m = 1 is equivalent to a classical single-machine problem, it is not of special interest. Thus, in the following we will consider synchronous flow shops with m = 2 or m = 3 machines and show that the results may be generalized for m > 3 machines.As already observed in Soylu et al. (2007), the two-machine synchronous flow shop problem is closely related to the corresponding two-machine flow shop problem with no-wait or blocking constraints. It is easy to see that a feasible schedule for a synchronous flow shop also satisfies the blocking constraint and vice versa. Furthermore, a feasible no-wait schedule can be obtained from such a schedule by shifting the operations on the first machine to the right in each cycle (this does not change the completion times of the operations on the second machine). Hence, the makespan is equal in all three situations and thus an optimal schedule for either of the problems F2|no-wait|Cmax , F2|blocking|Cmax  or F2|synmv|Cmax  defines an optimal solution for the other two problems as well. All problems are equivalent to a special case of the traveling salesman problem, which can be solved inO(nlogn)by the algorithm of Gilmore and Gomory (1964).On the other hand, because we defined the completion time of a job within the synchronous flow shop as the completion time of the corresponding cycle, the individual completion times of the jobs in a synchronous flow shop are not the same compared to the no-wait or the blocking situation. Hence, for other objective functions, in general we get different objective values for the three variants. Röck (1984) proved that F2|no-wait|∑Cjand F2|no-wait|Lmax  are stronglyNP-hard. Within his proof schedules without idle times on machines M1 and M2 are generated. If no idle times exist on the second machine, the completion times of the jobs are the same for the no-wait and the synchronous case. Thus, the results of Röck (1984) can be used to show that F2|synmv|∑Cjand F2|synmv|Lmax  are stronglyNP-hard as well.Note that for m ≥ 3 the described equivalence between the three concepts no-wait, blocking, and synchronous movement is no longer valid. For F3|no-wait|Cmax  and F3|blocking|Cmax  it is known that these problems are stronglyNP-hard. Soylu et al. (2007) claimed that also problem F3|synmv|Cmax  isNP-hard by using theNP-hardness of F3|blocking|Cmax . It is shown that the flow shop problem with synchronous movement is a special case of the problem with blocking and then deduced that the flow shop problem with synchronous movement isNP-hard as well. However, this implication seems to be flawed since a special case of anNP-hard problem does not need to beNP-hard as well. In the following theorem we give a correctNP-hardness proof for the synchronous flow shop problem with three machines.Theorem 1Problem F3|synmv|Cmaxis stronglyNP-hard.We prove this via a pseudo-polynomial reduction from the stronglyNP-hard problem 3-PARTITION (cf. Garey and Johnson (1979)). Let (3P) be an instance of 3-PARTITION with 3m integers a1, …, a3msatisfyingmB=∑i=13maiand B/4 < ai< B/2 for i = 1, …, 3m. W.l.o.g. we assume ai≥ 2 for all i which does not change the hardness of 3-PARTITION. The goal is to find a partition into disjoint subsets A0, …, Am − 1 (each containing three elements from {1, …, 3m}) with∑i∈Aλai=Bfor λ = 0, …, m − 1.We construct the following instance (SF) of the synchronous flow shop problem with a setJconsisting of 2mB + 1 jobs. LetS>∑i=13mi(ai−1)andω>Sbe two large constants. We create the following jobs:•One dummy job D0 with processing times (0, S, ω + 1).One dummy job DmBwith processing times (ω + mB, S, 0).For i = 1, …, mB − 1 dummy jobs Diwith processing times (ω + i, Si, ω + i + 1) whereSi={S,ifimodB=00,otherwise.For i = 1, …, 3m•one jobj1iwith processing times (S, ω, i)for l = 2, …, ai− 1 jobsjliwith processing times (i, ω, i)one jobjaiiwith processing times (i, ω, S).This results in aijobs for each element i. As an abbreviation we will call the setJi={jli∣l=1,…,ai}the “job family” of element i. Because we assume ai≥ 2 for all i, at least two jobsj1iandjaiiare created for each element i.We show that there exists a partition of (3P) into m sets with sum value B each iff the synchronous flow shop (SF) has a schedule with makespanCmax≤mBω+mB(mB+1)2+(3m+1)S+∑i=13mi(ai−1).“⇒:” Let A0, …, Am − 1 be a partition into m sets of sum value B each and assume that Aλ= {λ1, λ2, λ3} for λ = 0, …, m − 1. Then we construct a sequence σ = (σ0, …, σ2mB) in the following way: For positions i ∈ {0, …, 2mB} withimod2=0set σi= Di/2 (cf. Fig. 2).Afterwards, for λ = 0, …, m − 1 insert the jobs corresponding to the set Aλ= {λ1, λ2, λ3} withaλ1+aλ2+aλ3=Bat the positions 2λB + 2μ + 1 for μ = 0, …, B − 1 such that job familyJλ1is processed in the firstaλ1,job familyJλ2in the nextaλ2and job familyJλ3in the lastaλ3of these slots (cf. Fig. 3).In the schedule corresponding to sequence σ there are no idle times on machine M1, and the cycle time ctof cycle t = 0, …, 2mB + 2 isct={0,t=0ω+t2,t=2i,i=1,…,mBS,t=2λB+1,λ=0,…,m−1λ1,t=2(λB+l)+1;λ=0,…,m−1;l=1,…,aλ1−1S,t=2(λB+aλ1)+1,λ=0,…,m−1λ2,t=2(λB+aλ1+l)+1;λ=0,…,m−1;l=1,…,aλ2−1S,t=2(λB+aλ1+aλ2)+1,λ=0,…,m−1λ3,t=2(λB+aλ1+aλ2+l)+1;λ=0,…,m−1;l=1,…,aλ3−1S,t=2mB+10,t=2mB+2.The cycle times of the cycles depicted in Fig. 3 can be obtained from this formula by setting λ = 0 for cycles 0, …, 2B and λ = 1 for cycle 2B + 1, respectively.Since the cycle times sum up to∑t=02mB+2ct=∑j∈Jp1j+S=mBω+mB(mB+1)2+(3m+1)S+∑i=13mi(ai−1),a schedule with the required makespan is found.“⇐:” Let conversely σ = (σ0, …, σ2mB) be a sequence with makespanC*≤mBω+mB(mB+1)2+(3m+1)S+∑i=13mi(ai−1).We will show that the corresponding schedule is of the same structure as the one in the first part of the proof. The processing times of jobs Dion machine M1 sum up tomBω+mB(mB+1)2,the processing times of all other jobs on machine M1 sum up to3mS+∑i=13mi(ai−1). Thus, there can be no idle time on machine M1 as any idle time would result in a schedule with makespan larger than C*.At first we show that the dummy jobs Difor i = 0, …, mB have to be scheduled in positions 2i in σ. If the jobs are not scheduled in these positions, there is at least one slot in the schedule where a job of type Diwith i < mB is processed on machine M3 and no other job Dhwith h ≠ i is processed on machine M1 at the same time. As the processing time of any other job is at most S on machine M1 in this cycle, this leads to an idle time of at least ω − S > 0 time units on M1 and hence to a schedule with makespan Cmax  > C*. Thus, these jobs have to be scheduled in positions 2i. Because job D0 is the only one with zero processing time on machine M1, it has to be scheduled in the first position of σ as otherwise an idle time of at least ω would occur on machines M2 and M3 in the first cycle. Likewise, job DmBhas to be scheduled in the last position of σ, since otherwise this would lead to an idle time of at least ω on machines M1 and M2 in the last cycle. Thus, all jobs Dihave to be scheduled in the way described in the first part of the proof in ascending order Difor i = 0, …, mB in positions 2i.Further, as this leads to processing times of length S on machine M2 in positions 2iB + 1 for i = 0, …, m, to avoid idle times on machine M1 there has to be a job of typej1kfor some k scheduled in positions i for(i−1)mod2B=0. This can be seen in Fig. 3: Job D0 is scheduled in cycle 0, leading to a processing time of S on machine M2 in cycle 1. Therefore, to avoid an idle time on machine M1, jobj1λ1is scheduled in position 1, leading to a processing time of S on machine M1 in cycle 1. Likewise, a job of typejaλ3λ3is scheduled in position 2B − 1, so the processing times on machines M1 and M2 are the same in cycle 2B + 1. Then, to avoid idle times on machines M1 and M3, starting with a job of typej1kin position i the whole job family Jkhas to be scheduled in positions i + 2l for l = 0, …, ai− 1, as only in this case the processing time on machine M1 is the same as the processing time on M3 in the following cycles. Since this ends with a processing time of S on machine M3 (and processing times on machine M2 are at most S), another job family has to follow, as only the first job of a job family has a processing time of S on machine M1. In Fig. 3 this is depicted in cycles2aλ1+1,2(aλ1+aλ2)+1and 2B + 1, respectively. Moreover, because of a processing time of length S on machine M2 in positions 2iB + 1 for i = 0, …, m, the last job of a job family (i.e. a job of typejakk), has to be scheduled in position i for(i+1)mod2B=0. Only then, the processing times on machines M2 and M3 are the same and there are no idle times. In Fig. 3 this occurs in cycle 2B − 1.Due to the placement of all other jobs in the sequence and because the cardinality of each job family satisfies B/4 < |Ji| < B/2, for each λ = 0, …, m − 1 the subsequence σ2λB + 2μ + 1 for μ = 0, …, B − 1 has to consist of exactly three job families whose cardinalities sum up to B. This partition of job families leads to a solution of (3P). In Fig. 3, we show the schedule for one set Aλ= {λ1, λ2, λ3} withaλ1+aλ2+aλ3=B. Here, the jobs of the three job familiesJλ1,Jλ2andJλ3are scheduled in positions σ2μ + 1 for μ = 0, …, B − 1.The above reduction is a pseudo-polynomial one since the number of jobs depends on the values aiof the integers used in the 3-PARTITION problem. However, since 3-PARTITION is stronglyNP-hard, according to Garey and Johnson (1979) (page 101, Lemma 4.1) this is sufficient to show that the synchronous flow shop problem is also stronglyNP-hard.□As in the classical flow shop, adding a further machine in a synchronous flow shop does not decrease the difficulty of the problem:Theorem 2For eachm∈Nand any objective function f problemFm|synmv|f reduces polynomially to F(m + 1)|synmv|f.Given an instance (I) of Fm|synmv|f with jobs j = 1, …, n construct an instance (I′) of F(m + 1)|synmv|f: For each job j create a job j′ with processing timesp1j′′=0andpij′′=pi−1,jfor i = 2, …, m + 1. Obviously, this is a polynomial-time reduction and both instances have the same objective value.□This implies that problem Fm|synmv|Cmax  is stronglyNP-hard for each fixed m ≥ 3. Furthermore, Fm|synmv|∑Cjand Fm|synmv|Lmax  are stronglyNP-hard for each fixed m ≥ 2.As we showed in the preceding section, minimizing the makespan of a synchronous flow shop isNP-hard for three or more machines. Therefore, unlessP=NPthere exists no polynomial time algorithm and the problem becomes computationally intractable for larger instances. In the following sections we will discuss special cases of the synchronous flow shop based on machine dominance and will show that some cases are polynomially solvable. We restrict ourselves to cases with one and two dominating machines because cases with three dominating machines can be seen as generalizations of the synchronous flow shop with three machines without machine dominance. Thus, synchronous flow shops problems with three dominating machines are stronglyNP-hard as well.In the situation of dominating machines, the processing times of the cycles are only determined by a subset of dominating machines, i.e. the processing times on the other machines are always at most as large as those on the dominating machines. We say that a machine Mkdominates Mlwheneverminj=1,…,npkj≥maxj=1,…,nplj,i.e. the smallest processing time of any job on machine Mkis at least as large as the largest processing time of any job on machine Ml. Within this work, we broaden the notion of machine dominance. We call a set{Mi∣i∈I}of machines dominating, ifmini∈Iminj=1,…,npij≥maxh∉Imaxj=1,…,nphj,i.e. there is a set of machines which dominate all other machines. If the set{Mi∣i∈I}describes a set of dominating machines, we use the notation “dom(I)” in the β-field of the classification scheme. Fig. 4shows a schedule for a synchronous flow shop where the two machines M1 and M3 are dominating.Machine dominance leads to a simplification of the problem: As soon as the first job is being processed on the first dominating machine, the processing times on all non-dominating machines become irrelevant and we only have to consider the dominating machines. This holds until the last job is transferred from the last dominating machine. In Fig. 5a schedule for a synchronous flow shop with only one dominating machine Mkand the sequence (1, 2, …, n) is shown. For the first k − 1 cycles (before job 1 is processed on Mk) and the last m − k cycles (after job n is processed on Mk), no job is processed on the dominating machine. Thus, for these cycles no further machine dominance occurs and the situation is the same as for a general synchronous flow shop without machine dominance.There are two possibilities for the processing times on non-dominating machines:•The processing times on the non-dominating machines are arbitrary values,the processing times on the non-dominating machines are job-independent, i.e. pij= pifor all j and alli∉I.The assumption of job-independent processing times in the second case may be reasonable in practice if non-dominating machines resemble work processes like insertion or removal of work pieces that have the same processing time regardless of the actual job. Alternatively, the difference between individual processing times might be negligible in practice and assuming a constant time may simplify the problem. In this case, the time required in cycles where no job is processed on a dominating machine is constant independent of the job sequence. Thus, we can simply ignore the cycles in which there is no job being processed on a dominating machine and add a corresponding constant to all completion times. Then, the complexity of a synchronous flow shop with one or two dominating machines does not increase when adding more non-dominating machines. As the constant to be added does not depend on the sequence of the jobs and the value of the constant does not affect an optimal sequence, in this situation we may even assume that all processing times on the non-dominating machines are the same and equal to zero. To denote this special situation, we add “pijndom=0” to the β-field.In the case of arbitrary processing times on the non-dominating machines, the complexity of synchronous flow shop problems increases when adding a non-dominating machine. If the first dominating machine has index k1 and the last dominating machine has index k2, we can iterate over all possible sequences of the first k1 − 1 and the last m − k2 jobs. For all jobs in between the processing times on the non-dominating machines are not relevant as in each cycle these jobs are being processed, a job is processed on at least one dominating machine. Therefore, after fixing the first k1 − 1 and last m − k2 jobs, a reduced scheduling problem for the remaining jobs can be solved assuming zero processing times on the non-dominating machines as explained above. Afterwards, the fixed jobs are added to the front and the end of an optimal sequence of the reduced problem. Finally, the completion times of the jobs and the objective value can be calculated from the obtained sequence.If the number of machines m is fixed, there areO(nm−k2+k1−1)possibilities to fix the job sequences in the first k1 − 1 and the last m − k2 cycles. Thus, if a polynomial algorithm exists to solve the reduced problem with zero processing times on the non-dominating machines, the problem with arbitrary processing times and fixed m can also be solved in polynomial time by trying all possible subsequences for the first and last cycles.In this section we consider synchronous flow shop problems with a single dominating machine Mk. At first we show that if the number of machines is not fixed and the processing times on non-dominating machines are arbitrary, the synchronous flow shop problem with one dominating machine isNP-hard for the objective functions Cmax  and ∑Cj.Theorem 3ProblemF|synmv,dom(I)|Cmaxis stronglyNP-hard for|I|=1if the processing times on non-dominating machines are arbitrary.We prove this via a reduction from F3|synmv|Cmax  which we showed to be stronglyNP-hard in Theorem 1. Let (SF3) be an instance of F3|synmv|Cmax  with n jobs and processing times pij. We construct the following instance (SF1) of a synchronous flow shop problem with a single dominating machine. Letω>∑i=1m∑j=1npij+1be a large constant and set the number of machines to n + 3 in (SF1). For each job j = 1, …, n of (SF3) construct a job j′ for (SF1) with processing times•p1j′′=ω,pij′′=0for  i = 2, …, n,pij′′=pi−n,jfor  i = n + 1, n + 2, n + 3.As can be easily seen, the first machine is dominating since the processing times for any job on machines M2, …, Mn + 3 are smaller than the processing timesp1j′′for any j′. We show that for each threshold value C* the synchronous flow shop (SF3) has a schedule with makespan Cmax  ≤ C* iff the synchronous flow shop (SF1) has a schedule with makespanCmax′≤nω+C*.“⇒”: Let σ be a job sequence for (SF3) with makespan Cmax  ≤ C*. Define a sequence σ′ for (SF1) by settingσλ′=j′if σλ= j. Since the first machine is dominating, the cycle times of the first n cycles sum up to nω. After cycle n there is no further job being processed on the first machine. Thus, the remaining cycle times are determined by the (arbitrary) processing times on the non-dominating machines. Due to the construction of the jobs, the cycle time of cycle n + i in (SF1) is the same as the cycle time of cycle i in (SF3). Thus, the remaining cycle times add up to at most C* and the schedule has the desired makespan. For illustration, Fig. 6shows a schedule for (SF1) with makespan nω + C* based on the sequence σ = (1, …, n) for (SF3) with makespan C*.“⇐”: For a sequence σ′ of (SF1) a corresponding schedule for (SF3) can be constructed in the same way as above.□ProblemF|synmv,dom(I)|∑Cjis stronglyNP-hard for|I|=1if the processing times on the non-dominating machines are arbitrary.The proof is similar to the proof of Theorem 3 and we just sketch it here. Let (SF2) be an instance of the stronglyNP-hard problem F2|synmv|∑Cjwith n jobs. Construct an instance (SF1) of a synchronous flow shop problem with a single dominating machine and objective function ∑Cjin a similar way as in Theorem 3, using n + 2 machines. Then, the synchronous flow shop (SF2) has a schedule with ∑Cj≤ C* iff the synchronous flow shop (SF1) has a schedule with∑Cj′′≤n2ω+C*.□In the following, we study the situation of job-independent processing times on the non-dominating machines, i.e. we assume pij= pifor alli∉I. As described above, in this situation w.l.o.g. we may assume pij= 0 for alli∉I. Then, with the observation from above we have two simple implications: If a problem is alreadyNP-hard in this situation, the problem is alsoNP-hard in the general situation. On the other hand, if a problem is polynomially solvable for job-independent processing times on the non-dominating machines, it is also polynomially solvable for arbitrary processing times on the non-dominating machines and a fixed number m (the running time increases by the factorO(nm−1)).For any objective function f the problemF|synmv,dom(k),pijndom=0|fwith dominating machine Mkis closely related to the single-machine problem 1||f. Any instance of the single-machine problem with jobs j = 1, …, n and processing times pjcan be transformed into a synchronous flow shop problem instance with one dominating machine and the same jobs by setting their processing times on Mkto pjand on all other machines to zero. Obviously, the makespan of a single-machine sequence is equal to the makespan of the same sequence within the synchronous flow shop and does not depend on the sequence itself (it is equal to the sum of all processing times). Therefore, problemF|synmv,dom(k),pijndom=0|Cmaxis trivial for each index k and its optimal objective value can be calculated inO(n). Furthermore, as explained above, this implies that problem Fm|synmv, dom(k)|Cmax  can be solved inO(nm)for each k.Moreover, if we assume that the last machine Mmis dominating andpijndom=0,all completion times of the jobs in a synchronous flow shop schedule are the same as in a single-machine schedule. Therefore, problems with dominating machine Mmare equivalent to the corresponding single-machine problem. Since the problems 1||∑Tjand 1||∑wjUjareNP-hard (cf. Du and Leung (1990),Lawler and Moore (1969)), the synchronous flow shop problemsF2|synmv,dom(2),pijndom=0|∑TjandF2|synmv,dom(2),pijndom=0|∑wjUjareNP-hard as well.However, if the dominating machine is not the last machine, determining the completiontimes of individual jobs becomes more difficult. If the dominating machine has index k < m, the completion time of each job depends on the sequence of the next m − k jobs.In this subsection we study the problem of minimizing the total completion time ∑Cjfor one dominating machine. Let k be the index of the dominating machine and let pj≔ pkjfor simplicity. ProblemF|synmv,dom(k),pijndom=0|∑Cjcan be solved by scheduling the jobs according to non-increasing processing times on the dominating machine. This rule is known as the shortest processing time (SPT) rule, which solves the single-machine problem 1||∑Cjto optimality. As in the single machine case, optimality can be proved by exchange arguments.Theorem 5ProblemF|synmv,dom(k),pijndom=0|∑Cjcan be solved inO(nlogn)by scheduling the jobs according to the SPT rule for the dominating machine Mk.Let σ be an optimal sequence with completion times Cjand assume that σ does not satisfy the SPT rule for Mk. Then there are two jobs σλ, σλ + 1 scheduled at consecutive positions λ, λ + 1 withpσλ>pσλ+1. Consider the sequence σ′ where the jobs σλ, σλ + 1 are interchanged. For σ′ we haveCσλ′=Cσλ+1andCσλ+1′=Cσλ.Additionally, if λ > m − k holds, the completion time of job σλ − (m − k) is changed toCσλ−(m−k)′=Cσλ−(m−k)+pσλ+1−pσλ<Cσλ−(m−k).Since all other completion times remain the same, we have∑Cj′≤∑Cj. Thus, by iteratively exchanging such jobs we obtain an optimal sequence satisfying the SPT rule.□As discussed above, for the more general situation with arbitrary processing times on the non-dominating machines we getCorollary 6Problem Fm|synmv, dom(k)|∑Cjcan be solved inO(nmlogn)time.When considering the weighted sum of completion times, the single-machine problem 1||∑wjCjcan also be solved in polynomial time, using Smith’s rule Smith (1956) that schedules the jobs in order of non-increasing ratios wj/pj. Unfortunately, this rule is not optimal for synchronous flow shops and the resulting schedules can even be arbitrarily bad. This can be seen in the following example for problemF2|synmv,dom(1),pijndom=0|∑wjCjwhere ω is a large constant:j123p1j1ω1p2j000wjω10Fig. 7shows the schedule according to Smith’s rule and the optimal solution, respectively. As can be seen, Smith’s rule (scheduling the jobs according to their ratios wj/pj) sequences job 2 directly after job 1, which leads to a completion time of ω + 1 for the first job and thus a weighted completion time of ω(ω + 1). If job 3 is sequenced after job 1 instead, this results in a weighted completion time of 2ω. Therefore, the relative error of Smith’s rule for this instance isω(ω+1)+(ω+2)−(2ω+ω+2)(2ω+ω+2)=ω2−ω3ω+2which can be arbitrarily large.Although we cannot use a similar rule to find an optimal schedule, we can show the following dominance rule: If for two jobs i, j the inequalities pi≤ pjand wi≥ wjhold, then there exists an optimal schedule in which job i is scheduled prior to job j. This result may reduce the solution space of permutations. The dominance rule can once again be proven by an exchange argument similar to the unweighted case. However, the complexity status of problemF2|synmv,dom(1),pijndom=0|∑wjCjremains open.In this subsection we study the problem of minimizing the maximum lateness Lmax  for one dominating machine. Let again k be the index of the dominating machine and let pj≔ pkjfor simplicity. At first we consider problemF|synmv,dom(k),pijndom=0|Lmax,i.e. the situation that the processing times on the non-dominating machines are zero.For the single-machine problem 1||Lmax  Jackson’s earliest due date (EDD) rule is a polynomial algorithm to minimize the maximum lateness. This rule states that all jobs are scheduled in non-decreasing order of their due dates. As with the WSPT rule for minimizing the sum of weighted completion times, the EDD rule is not optimal and can lead to arbitrarily bad schedules for problemF2|synmv,dom(1),pijndom=0|Lmax.In the following, at first we consider the decision variant ofF|synmv,dom(k),pijndom=0|Lmaxasking whether a feasible schedule with Lmax  ≤ L for a given threshold value L exists. For this problem, Algorithm 1determines a job sequence from the last to the first position. If there exists a feasible schedule, then also a feasible schedule without any idle times on Mkexists. Hence, from the sum of all processing times pjwe know the length of such a schedule, as it is sequence independent. Thus, we can calculate the completion time of the last job in the sequence and can determine which jobs can be scheduled last in the sequence such that their lateness is not larger than the specified maximum lateness L. If more than one job is feasible to be scheduled in the current position of the sequence in iteration λ, we choose a feasible job with largest processing time. The completion time of the job added in the next iteration λ + 1 is calculated in line 11. Because we assume zero processing times on the non-dominating machines, in any schedule the last m − k + 1 jobs all have completion time T. Therefore, nothing is subtracted from T in line 11 in the first m − k iterations of the algorithm. For λ > m − k, the processing time of the job scheduled in position n − λ + 1 + m − k, which is the job scheduled m − k + 1 positions after the job to be scheduled in iteration λ + 1, is subtracted. As the job scheduled in position n − λ + 1 + m − k was one with largest processing time of all feasible jobs, the completion time of the job to be scheduled in iteration λ + 1 is as small as possible.Theorem 7For problemF|synmv,dom(k),pijndom=0|Lmaxand a threshold valueL∈Z,Algorithm 1returns a feasible job sequence with Lmax  ≤ L inO(nlogn)if such a sequence exists.If L ≠ 0, we can transform each instance into an equivalent instance by setting all due dates todj′=dj−Land considering the threshold 0. Thus, w.l.o.g. we assume L = 0. Assume there exists a sequence of the jobsσ˜=(σ˜1,…,σ˜n)such that no job is completed after its due date. We show that in each iteration λ = 1, …, n of the algorithm, there is at least one feasible job to be scheduled, i.e. line 6 is never reached.Let l ≔ m − k + 1 andT:=∑j=1npjbe the sum of processing times on the dominating machine. Because we assume zero processing times on the non-dominating machines, in any schedule the last l jobs all have completion time T. If during the first l steps of the algorithm there is no more feasible job, then less than l jobs have a due date of at least T, contradicting that there exists a feasible schedule of the jobs such that no job is completed after its due date.Consider iteration λ > l of Algorithm 1 and assume that there is no feasible job. The completion time of the job to be scheduled in iteration λ is given bytλ=T−∑μ=1λ−lpσn−μ+1wherepσn−μ+1is the processing time of the job scheduled in iteration μ (i.e. the job scheduled in position n − μ + 1). Consider the jobσ˜n−λ+1which is scheduled in this position in the feasible sequenceσ˜with completion timet˜λ. Because this job is not feasible in iteration λ of the algorithm, this is either because the job has already been scheduled in a prior iteration of the algorithm or becausedσ˜n−λ+1<tλholds. Because Algorithm 1 always inserts a feasible job with largest processing time, tλis as small as possible and thustλ≤t˜λ,which contradictst˜λ≤dσ˜n−λ+1<tλ. If, on the other hand, jobσ˜n−λ+1has already been scheduled in Algorithm 1, then one of the jobs succeeding this one inσ˜has not been scheduled by the algorithm. Because this job is infeasible in iteration λ, its due date must be greater than tλ. However, this contradicts the assumption that the maximum lateness ofσ˜is at most zero.Algorithm 1 can be implemented such that it runs inO(nlogn). Initially, we sort the jobs according to decreasing due dates. Furthermore, we maintain a heap containing all feasible unscheduled jobs j with T − dj≤ L of the current iteration. As key values in the heap we use the processing times pjof the jobs. Then, in each iteration a feasible job with largest processing time can be determined inO(1). Afterwards, the heap has to be updated which can be done inO(logn). Additionally, new jobs may have to be inserted into the heap for the new value T. This can efficiently be done by going through the initial list where the jobs are sorted according to decreasing due dates. Since in total we have n iterations, each job is inserted into the heap exactly once, and in each iteration at most n jobs are in the heap, all heap updates can be performed inO(nlogn).□Using Algorithm 1 we can also solve the optimization problemF|synmv,dom(k),pijndom=0|Lmaxand find the minimum maximum lateness for any instance by applying the algorithm for different values of L. One possibility is to use a binary search approach, starting with a lower bound of − maxjdjand an upper bound of ∑jpj− minjdj. However, then the number of times Algorithm 1 has to be executed depends on the numerical values of pjand djand hence this approach does not yield a strongly polynomial algorithm. However, we can use Algorithm 1 in the strongly polynomial-time Algorithm 2to find the minimum maximum lateness of any instance. Algorithm 2 starts with an upper bound on the maximum lateness and uses Algorithm 1 to construct a feasible schedule σ. In each iteration of the algorithm a new threshold value for the maximum lateness is calculated and tested by Algorithm 1 until Algorithm 1 no longer returns a feasible schedule.Theorem 8For problemF|synmv,dom(k),pijndom=0|LmaxAlgorithm 2finds a sequence of jobs minimizing the maximum lateness LmaxinO(n3logn).First we show that the algorithm is correct. In the first iteration, Algorithm 1 is executed with a value of L = ∑jpj− minjdj. As this is an upper bound for the maximum lateness of each instance and Algorithm 1 is correct (Theorem 7), we get a schedule with lateness Lmax  ≤ L and reach line 11 in Algorithm 2. There the minimum deviation d of the lateness of the returned schedule from the current threshold L is calculated. The consequence is that this schedule yields a maximum lateness of Lmax= L − d and therefore a schedule with maximum lateness Lmax  = L − d exists. In the next step of Algorithm 2 we thus try to find a schedule with maximum lateness Lmax  = L − d − 1. We iteratively go on until no such schedule can be found for values L and d. Then, as a schedule with maximum lateness Lmax  = L − d exists, but a schedule with Lmax  = L − d − 1 does not, we have found the minimum maximum lateness.Next we show that the algorithm runs inO(n3logn). Let σ be the feasible schedule for threshold value L returned by Algorithm 1 in line 5. Consider the job j with largest completion time Cjsatisfying (dj+ L) − Cj= d, which we will call the “critical job”. Let μ be the position of j in σ. Consider the execution of Algorithm 1 for a lateness value of L − d − 1 in the next iteration of Algorithm 2. Then, as job j has to be planned such that its completion time is Cj≤ dj+ L − d − 1, the schedule σ is no longer feasible and has to be changed. Algorithm 1 constructs the new scheduleσ˜in the following way: For all iterations λ < n − μ + 1, the set of feasible jobs constructed in line 4 is a subset of the set of feasible jobs in the prior execution: Each job that was feasible to be scheduled in position n − λ in σ is still feasible as the job is non-critical in σ. Also, in each iteration λ < n − μ + 1 job σn − λ + 1 is chosen in line 9, as there is no job with larger processing time in the set of feasible jobs. Thus,σl˜=σlfor l > μ holds. In iteration n − μ + 1 the critical job j cannot appear in the set of feasible jobs in line 4. Further, no job with processing time larger than pjis in the set of feasible jobs, because otherwise it would have been scheduled in position μ in schedule σ already. Thus, either the set of feasible jobs is empty and no schedule with lateness L − d − 1 can be found, or a feasible job with processing time smaller than pjhas to be scheduled in position μ. Therefore, for each job being critical, the schedule can be improved at mostO(n)times resulting in at mostO(n2)iterations of Algorithm 2. Since Algorithm 1 runs inO(nlogn),the total running time isO(n3logn).□As discussed above, for the more general situation with arbitrary processing times on the non-dominating machines we getCorollary 9Problem Fm|synmv, dom(k)|Lmax  can be solved inO(nm+2logn)time.To achieve this, we have to iterate over allO(nm−1)possibilities to fix the job sequences in the first k − 1 and last m − k cycles. Then, for all these possibilities, Algorithm 2 has to be employed, using slight modifications of Algorithm 1 in each case: The completion times of the last m − k + 1 job have to be calculated individually based on the fixed jobs’ processing times on the non-dominating machines. If the fixed jobs do not already lead to a lateness greater than the threshold, the non-fixed jobs once again can be scheduled iteratively, in each iteration choosing a feasible job with largest processing time. We only considered the case with zero processing times on non-dominating machines in the algorithms and proofs above to improve the readability. Nonetheless, the correctness of the algorithm and the time complexity for the case with arbitrary processing times on non-dominating machines can be proven in an analogous manner.Another polynomially solvable single-machine problem involving due dates is the problem 1||∑Uj, which can be solved by Moore’s algorithm Moore (1968). Unfortunately this algorithm does not work for synchronous flow shops with one dominating machine. Since we also did not find another polynomial-time algorithm, the complexity status of problemF2|synmv,dom(1),pijndom=0|∑Ujremains open.In this section we consider synchronous flow shop problems with two dominating machines. In the case of an arbitrary number of machines where only two are dominating and the two dominating machines directly succeed each other, the makespan of the flow shop with synchronous movement is once more closely related to the makespan of the two-machine flow shop with either no-wait or blocking constraints. Ignoring sequence independent constants, job sequences for the two-machine no-wait flow shop and the synchronous flow shop have the same makespan. Hence, for each 1 ≤ k < m problemF|synmv,dom(k,k+1),pijndom=0|Cmaxis equivalent to problem F2|no-wait|Cmax  and can be solved inO(nlogn). However, the individual completion times Cjfor the jobs again depend on the succeeding jobs in the sequence and can thus not be calculated easily, similar to the case with only one dominating machine.If the two dominating machines do not directly succeed each other, an interesting effect occurs. Let 1 ≤ k1 < k2 ≤ m be the indices of the dominating machines and σ = (σ1, …, σn) be a sequence of jobs. Because the length of one cycle in the synchronous flow shop is determined by the maximum of the processing times on those two dominating machines, the sequence splits into k2 − k1 independent subsequences σλfor λ = 1, …, k2 − k1 withσλ=σλ+μ(k2−k1)forμ=0,…,⌊n−λk2−k1⌋that affect the lengths of disjoint cycles of the schedule. For example, for the synchronous flow shop F3|synmv, dom(1, 3)|f in Figure 4 we have two subsequences (1, 3, 5) and (2, 4, 6). The idle times on the dominating machines M1 and M3 are for each job only caused by the preceding (or succeeding) jobs of the same subsequence.An interesting question is whether it makes a difference if the two dominating machines directly succeed each other or there are non-dominating machines in between (e.g. in the case of F3|synmv, dom(1, 2)|f where M1, M2 are dominating and F3|synmv, dom(1, 3)|f where M1, M3 are dominating). While problem F2|synmv, dom(1, 2)|Cmax  is equivalent to F2|synmv|Cmax  and hence polynomially solvable as described in Section 3, it is not clear whether problem F3|synmv, dom(1, 3)|Cmax  can also be solved in polynomial time. Intuition guides one into thinking that a problem where a non-dominating machine lies between two dominating machines is at least as difficult as a problem in which the two dominating machines are directly succeeding each other. More formally, one would assume that for m ≥ 3 and two indices k1 < k2 < m problem Fm|synmv, dom(k1, k2 + 1)|f is at least as difficult as problem Fm|synmv, dom(k1, k2)|f for any objective function f. Unfortunately we were not able to prove this intuitive result in the general case. However, it can be proven for the objective function of minimizing the makespan. For the makespan objective function and job-independent processing times on non-dominating machines we can ignore all machines before the first dominating machine and after the second dominating machine. Further, for arbitrary processing times on the non-dominating machines we can once more fix the first and last jobs in the sequence. Thus, w.l.o.g. we can assume that the first and last machines are the dominating ones and it is sufficient to consider the relationship between problems Fm|synmv, dom(1, m)|Cmax  and F(m + 1)|synmv, dom(1, m + 1)|Cmax . For them we haveTheorem 10For eachm∈Nwith m ≥ 2 problem Fm|synmv, dom(1, m)|Cmaxreduces polynomially to F(m + 1)|synmv, dom(1, m + 1)|Cmax .Let (I) be an instance of Fm|synmv, dom(1, m)|Cmax  with jobs j = 1, …, n, machines M1, …, Mm, n ≥ m + 1, and processing times pij. Construct an instance (I′) of problem F(m + 1)|synmv, dom(1, m + 1)|Cmax  with machinesM1′,…,Mm+1′and processing timespij′in the following way:•For each job j create a job j′ with processing timespij′′=pijfor i = 1, …, m − 1,pmj′′=0,andpm+1,j′′=pmj.LetP:=∑j=1n(p1j+p2j)+1. Createk:=⌈nm−1⌉auxiliary jobs a1, …, ak. For the first auxiliary job a1 setp1,a1′=0andpm+1,a1′=P. For the last auxiliary job aksetp1,ak′=Pandpm+1,ak′=0,and for all auxiliary jobs alfor l = 2, …, k − 1 setp1,al′=pm+1,al′=P. Additionally, setpi,al′=0for i = 2, …, m and l = 1, …, k.Obviously, if machines M1 and Mmare dominating for (I), then machinesM1′andMm+1′are dominating for (I′). Let C ≤ P − 1. We will show that the instance (I) has a solution with makespan Cmax  ≤ C iff the instance (I′) has a solution with makespanCmax′≤C+(k−1)P.“⇒”: Let σ = (σ1, σ2, …, σn) be a sequence of jobs for (I) with makespanCσn≤C. Construct a sequence σ′ for the instance (I′) byσi′={a⌈im⌉ifimodm=1σi−⌈im⌉otherwisefor i = 1, …, n + k, i.e. inserting the dummy jobs as every mth job (see Fig. 8for an example with m = 2 machines). The auxiliary jobs are scheduled in such a way that auxiliary job alis processed on machineMm+1′when auxiliary job al + 1 is processed on machineM1′. The auxiliary jobs contribute a total of (k − 1)P to the makespanCmax′. The remaining jobs are scheduled in between the auxiliary jobs such that job σiis processed on machineMm+1′when σi + mis processed on machineM1′. Thus, the non-auxiliary jobs addCσnto the makespan of (I′), which leads to the desired makespan ofCmax′≤C+(k−1)P.“⇐”: Letσ′=(σ1′,σ2′,…,σn+k′)be a sequence of jobs for (I′) with makespanCσn+k′≤C+(k−1)P. Note that each auxiliary job has processing time P on at least one machine. Due to C ≤ P this means that the auxiliary jobs have to be scheduled in such a way that for each l1 = 1, …, k − 1, auxiliary jobal1is processed on machineMm+1′when another auxiliary jobal2for some l2 ∈ {2, …, k} is processed on machineM1′. Further, auxiliary job a1 has to be scheduled as the first of the auxiliary jobs in the first m positions of the schedule and job akhas to be scheduled as the last auxiliary job to allow for a processing time of (k − 1)P for the auxiliary jobs. For all jobsσi′,the job is processed on the dominating machineMm+1′when jobσi+m′is processed on machineM1′. Let λ be the position of the first auxiliary job a1 and let w.l.o.g. albe scheduled in position λ + m(l − 1) for l = 2, …, k. Construct a sequence σ byσμ={σμ+⌈μ−λ+1m⌉′forμ≥λσμ′otherwise,for μ = 1, …, n, i.e. removing all auxiliary jobs. Then this sequence results in a makespan ofCσn≤Cfor instance (I) with the same arguments as above.□Theorem 10 shows that adding a non-dominating machine between two dominating machines does not decrease the difficulty of the problem. Thus, if we could showNP-hardness for F3|synmv, dom(1, 3)|Cmax , this would implyNP-hardness forFm|synmv,dom(k1,k2),pijndom=0|Cmaxfor all 1 ≤ k1 < k2 − 1 < m, i.e. for all situations where the two dominating machines are not directly succeeding. While the problem is open for a fixed number of machines, we can prove that problems with two dominating machines areNPhard if the number of machines and the positions of the dominating machines are parts of the input:Theorem 11ProblemF|synmv,dom(I),pijndom=0|Cmaxis stronglyNP-hard for|I|=2.This can be proven via a pseudo-polynomial reduction from 3-PARTITION in a similar way as in Theorem 1. We construct the following instance (SF) of the synchronous flow shop problem with m + 1 machines and mB jobs. For each i = 1, …, 3m introduce the following jobs:•one jobj1iwith processing timesp1,j1i=0andpm+1,j1i=i,for l = 2, …, ai− 1 jobsjliwith processing timesp1,jli=pm+1,jli=i,one jobjaiiwith processing timesp1,jaii=iandpm+1,jaii=0.All other processing times are set to zero, i.e. the machines M1 and Mm + 1 are dominating. This results in aijobs for each element i. As in the proof of Theorem 1 we will call the setJi={jli∣l=1,…,ai}the “job family” of element i. Because we again assume ai≥ 2 for all i = 1, …, 3m, at least two jobsj1iandjaiiare created for each element i. We show that there exists a partition of (3P) into m sets with sum value B each, iff the synchronous flow shop (SF) has a schedule with makespanCmax≤∑i=13mi(ai−1).“⇒:” Let A0, …, Am − 1 be a partition into m sets of sum value B each and assume that Aλ= {λ1, λ2, λ3}. Then we construct a sequence σ = (σ0, …, σmB − 1) in the following way: for λ = 0, …, m − 1 insert the jobs corresponding to the set Aλ= {λ1, λ2, λ3} withaλ1+aλ2+aλ3=Bat the positions λ + μm for μ = 0, …, B − 1 such that job familyJλ1is processed in the firstaλ1,job familyJλ2in the nextaλ2and job familyJλ3in the lastaλ3of these slots. In this sequence there are no idle times on machines M1 and Mm + 1 and the cycle times sum up to∑i=13mi(ai−1).Thus, a schedule with the required makespan is found.“⇐:” Let conversely σ be a sequence with makespanC*≤∑i=13mi(ai−1).We will show that the schedule is of the same structure as the one in the first part of the proof. Because the processing times of all jobs on machines M1 and Mm + 1 sum up to∑i=13mi(ai−1),there may be no idle time on those machines as any idle time would result in a schedule with makespan larger than C*. Thus, the first m jobs have to be of typej1kfor some k and the last m jobs have to be of typejakk. To avoid idle times on machine M1 starting with a job of typej1kin position λ the whole job family Jkhas to be scheduled in positions λ + μm for μ = 0, …, ak− 1. Additionally, if λ + (ak− 1)m < n − m, another job family has to follow as the last job of the family has a processing time of 0 on machine Mm + 1.Because the cardinality of each job family satisfies B/4 < |Ji| < B/2, for each λ = 0, …, m − 1 the subsequence σλ + μmfor μ = 0, …, B − 1 has to consist of exactly three job families whose cardinalities sum up to B. This partition of job families leads to a solution of (3P).□As discussed in Section 3, for the problem of minimizing the maximum lateness or the total completion time, the results of Röck (1984) can already be used to proveNP-hardness for two-machine synchronous flow shops. The proof for minimizing the maximum lateness can be easily adapted to showNP-hardness for any position of two dominating machines:Theorem 12ProblemFm|synmv,dom(I),pijndom=0|Lmaxis stronglyNP-hard for each fixed m ≥ 2 and each setIwith|I|=2.For minimizing the total completion time, the proof of Röck (1984) can only be transferred to synchronous flow shop problems with two succeeding dominating machines. However, it would be a big surprise if the problem would in fact become easy (i.e. solvable in polynomial time) if non-dominating machines are introduced in between.For three dominating machines and the makespan objective, the introduction of non-dominating machines between dominating ones does not decrease the difficulty of the problem. This can be shown similar to the proof of Theorem 10. Thus, for each fixed m and each setIwith|I|≥3problemFm|synmv,dom(I),pijndom=0|Cmaxis stronglyNP-hard because the three-machine problemF3|synmv,dom(1,2,3),pijndom=0|Cmaxis already stronglyNP-hard as proven in Theorem 1.

@&#CONCLUSIONS@&#
