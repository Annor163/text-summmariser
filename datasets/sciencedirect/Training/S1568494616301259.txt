@&#MAIN-TITLE@&#
Spatio-temporal analysis for obstacle detection in agricultural videos

@&#HIGHLIGHTS@&#
We propose a method to detect objects/obstacles from agricultural videos for autonomous navigation.A spatio-temporal analysis is performed to discriminate among static and non-static obstacles.Motion analysis is especially valuable in order to ensure the safety and care of people/animals on the field.Performance analysis is carried out against existing strategies.

@&#KEYPHRASES@&#
Precision agriculture,Autonomous vehicles,Natural images,Spatiotemporal analysis,Obstacle detection,

@&#ABSTRACT@&#
Autonomous mobile vehicles are becoming commoner in outdoor scenarios for agricultural applications. They must be equipped with a robot navigation system for sensing, mapping, localization, path planning, and obstacle avoidance. In autonomous vehicles, safety becomes a major challenge where unexpected obstacles in the working area must be conveniently addressed. Of particular interest are, people or animals crossing in front of the vehicle or fixed/moving uncatalogued elements in specific positions. Detection of unexpected obstacles or elements on video sequences acquired with a machine vision system on-board a tractor moving in cornfields makes the main contribution to this research. We propose a new strategy for automatic video analysis to detect static/dynamic obstacles in agricultural environments via spatial-temporal analysis. At a first stage obstacles are detected by using spatial information based on spectral colour analysis and texture data. At a second stage temporal information is used to detect moving objects/obstacles at the scene, which is of particular interest in camouflaged elements within the environment. A main feature of our method is that it does not require any training process. Another feature of our approach consists in the spatial analysis to obtain an initial segmentation of interesting objects; afterwards, temporal information is used for discriminating between moving and static objects. To the best of our knowledge in the field of agricultural image analysis, classical approaches make use of either spatial or temporal information, but not both at the same time, making an important contribution. Our method shows favourable results when tested in different outdoor scenarios in agricultural environments, which are really complex, mainly due to the high variability in the illumination conditions, causing undesired effects such as shadows and alternating lighted and dark areas. Dynamic background, camera vibrations and static and dynamic objects are also factors complicating the situation. The results are comparable to those obtained with other state-of-art techniques reported in literature.

@&#INTRODUCTION@&#
The concept of fully autonomous vehicles includes a navigation system capable of solving problems such as: mapping, localization, path following, and obstacle avoidance. In recent years, agricultural vehicles (tractors, combines, sprayers, spreaders) have been introduced in agricultural environments to accomplish different tasks including planting, spraying, fertilizing, cultivating, harvesting, thinning, weeding, or inspection. In order to be useful, such vehicles should be equipped with vision-based sensors, which provide the required information to develop these tasks with a good performance.As mentioned above, autonomous agricultural vehicles need a means of detecting obstructions in their path to avoid collisions. If the system detects people, animals, other vehicles, or any obstruction, inside the haulage area during autonomous operation, the truck must stop immediately for security reasons. It is therefore important to emphasise that in agricultural applications few systems include an object detection procedure to guarantee safe vehicle navigation. Here comes our initial motivation; we propose an alternative method to detect objects/obstacles from agricultural videos in order to ensure the safety and care of people/animals in the field, but especially those, which are on the tractor trajectory. In addition, not only obstacle detection is of our interest; also, we study obstacles, which are moving in the crop area. Motion analysis is especially valuable for those elements, which can suddenly appear in front of the vehicle.The videos, used as input data, come from a cornfield during the period of weed removal. They were captured with a unique CCD-based high-resolution camera operating in the visible RGB spectral range. The camera is mounted on board a tractor, which is part of the fleet in the RHEA project [1]; its position is on top of the tractor at a height of 2.20m and with a pitch angle of 25° with respect to the vertical, Fig. 1a. This arrangement and also the camera calibration are conveniently addressed based on the camera model, and system geometry with the help of landmarks in the cornfield, as described in [2]. Fig. 1b displays six consecutive frames captured with this system. For motion obstacles, four scenarios are identified in our video sequences, they are described in Table 1.Images from agricultural videos, containing several elements including plants, trees, weeds, soil, objects, and shadows coming from these elements, are complex from the image processing point of view. The complexity increases by the great variability of vehicle and environmental conditions, such as: changing seasons or weather conditions (sunny or cloudy days), time of day, dust or movements produced by the vehicle in movement along the field, and also because of vibrations caused by the tractor engine. As a consequence of these combined effects, a robust obstacle detection system is very demanding.This paper specifically proposes a particular algorithm to detect dynamic and static elements. To achieve our goal, we have devised an approach based on spatio-temporal analysis. Given an input video, two consecutive video frames are considered for both spatial and temporal analysis. Obstacle segmentation is made by analysing spatial information in the current frame while motion is computed from the first-order spatio-temporal derivatives of two consecutive frames. The spatial and temporal information conveniently combined allows determining objects location and their associated movement if any. One of the major advantages of this representation is that by analysing temporal information, not only obstacle segmentation is improved; it is also possible to identify moving obstacles in front of the tractor trajectory. Motion detection is useful to anticipate and to prevent collisions between autonomous vehicles; this topic is widely discussed in [3]. When the spatial and temporal information is combined, the complexity of motion detection is significantly reduced. Instead of detecting motion with a relatively large number of previous frames, where the scene could change dramatically, we estimate motion based on the first-order temporal difference, but compared against the obstacle segmentation results to determine which of the elements on the scene are really in movement with respect to the tractor motion.Unlike other reported methods where object detection is exclusively based either on static segmentation or differential methods, such as those based on optical flow computation, we propose a static and dynamic combined approach (SDC) that allows exploiting the advantages of both, making an important contribution in the context of object detection in agricultural environments. The spatial differentiation in optical flow-based methods is assumed by the temporal differentiation, which determines image changes [4]. This combination and the simultaneous separation of spatial and temporal analysis is the main contribution of this proposed approach, which is conveniently compared against existing static and dynamic strategies.The remainder of the paper is structured as follows. A review of the state-of-the-art is provided in Section 2. Our methodology is extensively explained in Section 3 where the segmentation process is given in Section 3.1, followed by the moving detection in Section 3.2. Performance evaluation of our proposal is presented in Section 4; finally, we conclude the paper in Section 5 where also future trends are provided.

@&#CONCLUSIONS@&#
