@&#MAIN-TITLE@&#
A Markov modulated Poisson model for software reliability

@&#HIGHLIGHTS@&#
A new model for software reliability is proposed.Proposed model enables us to infer performance of the debugging process.Bayesian inference is developed.An approach is introduced to assess dimension of the Markov process.

@&#KEYPHRASES@&#
Software reliability,Hidden Markov model,Bayesian inference,

@&#ABSTRACT@&#
In this paper, we consider a latent Markov process governing the intensity rate of a Poisson process model for software failures. The latent process enables us to infer performance of the debugging operations over time and allows us to deal with the imperfect debugging scenario. We develop the Bayesian inference for the model and also introduce a method to infer the unknown dimension of the Markov process. We illustrate the implementation of our model and the Bayesian approach by using actual software failure data.

@&#INTRODUCTION@&#
Poisson process and its extensions are widely used in software reliability modeling; see for example, Pham and Zhang (2003). These Poisson process models are generated by the interfailure times of the software. One of the original Poisson process models is the time-dependent error detection model of Goel and Okumoto (1980). Most other Poisson process models are extensions of the Goel-Okumoto model. Such extensions and Kuo and Yang’s (1996) unification of the Poisson process models via general order and record value statistics are discussed in the recent review by Soyer (2011).A Markov-modulated Poisson process (MMPP) is a Poisson process whose intensity depends on the current state of an independently evolving continuous-time Markov process. Özekici and Soyer (2006) discuss probabilistic and statistical issues related to these processes in a rather general setting. These processes are used in a variety of applications in queueing, inventory, and reliability. Use of modulating processes in these applications have gained a lot of attention because they make the models more realistic. The customer arrival process in queueing and inventory models are often affected by an external environmental process that represents economic, financial, social or other factors in which the system operates. The arrival rate of customers depend on the state of the environment as well as other stochastic or deterministic parameters. Prabhu and Zhu (1989) discuss Markov modulated queues, and Arifog̃lu and Özekici (2010) analyze an inventory model operating in a partially observable random environment.First consideration of MMPPs in software reliability applications is due to Özekici and Soyer (2003) who assume that the failures of the software depend on its operational profile. Musa (1993) defines the operational profile as the set of all operations that a software system is designed to perform and their occurrence probabilities. The modulating process represents how the software is used and, thus, the failure process depends on it. Özekici and Soyer (2003) consider a setting where there is perfect debugging during the testing of software and the state of the environmental process is observed. In this paper, we relax both of these assumptions. More specifically, in our setup we consider software that goes through a debugging process, but we do not assume that debugging is perfect [see Aktekin and Caglar (2013) for a similar treatment]. Instead, we assume that the failure rate of the software is nonhomogeneous and modulated by the environmental process and this enables us to consider both improvements and deteriorations in the software as a result of the debugging.Unlike Özekici and Soyer (2003), in our setup the environmental process is latent and it represents the state of the debugging process as well as the operations that the software goes through during the process. Our objective is to provide a computationally tractable Bayesian procedure to make inference on the software failure rates and the parameters of the modulating Markov process based on observed data. In our setting, since the state of the modulating process is latent or hidden, we only have information on the failure times. An interesting problem then is to make statistical inferences on the hidden process based on failure data. Our model extends the discrete time hidden Markov model considered by Durand and Gaudoin (2005) to continuous time and develops its Bayesian analysis. Applications of our model in reliability also include hardware reliability where a device performs a stochastic mission and its failure rate depends on the stage of the mission. Çekyay and Özekici (2010) discuss issues related to mean time to failure and availability when the mission or environmental process is semi-Markovian.The details of our model will be presented in Section 2 where the stochastic structures of the modulating and failure processes are described. In Section 3 we will assume that the number of states of the hidden process is known, and show how we can estimate the software failure rates as well as the transition rates of the Markov process. Then, in Section 4 we will assume that we do not know the number of states of the hidden Markov process, and will present an approach to obtain the marginal likelihood based on Chib (1995) that will enable us to infer the unknown number of states. Finally, our results will be demonstrated using actual software failure data in Section 5. Conclusions follow in Section 6.Let N={Nt; t⩾0} be a modulated Poisson process such that Ntdepicts the total number of software failures until time t. There is an environmental process that modulates the software failure rates. In other words, the software failure rate is random at any time depending on the state of this environmental process. In software reliability, the environmental process can have several different interpretations. In Özekici and Soyer (2003), for example, it is used to represent the operational profile or process which depicts the operations that the software performs randomly after it is released. It may also be used to represent the state of the software during testing and debugging with respect to its failure properties. At any time, the software can be classified to be in “excellent”, “good”, or “bad” state depending on the number of faults or other failure properties. Although our analysis applies to both of these cases, we motivate it by the latter so that the environmental process represents the state of the software during testing and debugging. This state is not necessarily observed and the software failure rate depends on the unobserved state.The environmental process is Y={Yt; t⩾0} where Ytrepresents the state of the software during testing and debugging at time t. Since the effect of the changes made to the software during the debugging process is not necessarily observable, Y is a latent or hidden process. We assume that Y={Yt; t⩾0} is a continuous-time Markov process with a finite state space E={1, 2, …, K} where K is the number of states. We further assume that when the state of the software is i∈E, failures occur according to an ordinary Poisson process with rate λi. Therefore, the rate of failures at time t isλYt. To be more precise,(1)P[Nt=k|Y]=e-AtAtkk!where(2)At=∫0tλ(Ys)dsfor all k=0, 1, … and t⩾0.It follows from the above that, given Y, N is a nonstationary Poisson process with mean value function E[Nt∣Y]=At. Letting T={Tn; n=0, 1, 2, …} denote the software failure process so that Tnis the time of the nth failure, we have the conditional distribution(3)P[Tn+1-Tn>t|Y,Tn]=e-(ATn+t-ATn)The modulated process reduces to the ordinary Poisson process with rate λ if the failure rate vector is λi=λ independent of the state of Y. In this case, At=λt deterministically.The failure process N can be studied via the additive functional A of Y. In particular, (1) and (3) directly yield(4)P[Nt=k]=Ee-AtAtkk!and(5)P[Tn+1-Tn>t|Tn]=E[e-(ATn+t-ATn)]Therefore, the probability law of A, thus that of the environmental process Y, plays an important role in our analysis of N and T.Let Xnbe the nth state of the environmental process and Undenote the time when the process enters the nth state so that Yt=Xnwhenever Un⩽t<Un+1. Since Y is a Markov process, it is well-known that the sequence of states X={Xn; n=0, 1, 2, …} is a Markov chain with state space E and some transition matrix Pij=P[Xn+1=j∣Xn=i] with Pii=0 for all i,j∈E. Moreover, the duration of any state is exponentially distributed so thatP[Un+1-Un>t|Xn=i]=e-ρitwhere ρiis the holding rate for state i. The transition rate matrix or generator of the Markov process Y is(6)Gij=-ρi,ifj=iρiPij,ifj≠ior Gij=ρi(Pij−Iij) where I is the identity matrix.Following Özekici and Soyer (2006), we define another process Yλsuch that(7)Ytλ=Yt,ift<T1Δ,ift⩾T1where T1 is the time of the first failure. While the process is in state i, the time to failure has the exponential distribution with rate λi. It is clear that Yλis also a Markov process on the extended state space EΔ=E∪{Δ} and it is obtained by “stopping” the Markov process Y as soon as a failure occurs. Here, Δ is an absorbing state where the process is dumped to as soon as it is stopped. The transition matrix of the embedded Markov chain is now extended as(8)Pijλ=ρiρi+λiPij,ifi,j∈Eλiρi+λi,ifi∈E,j=Δ1,ifi,j=Δand the transition rate vector is(9)ρiλ=ρi+λi,ifi∈E0,ifi=ΔIf we let the matrixGijλ=ρiλPijλ-Iijdenote the generator of Yλ, then it is well known that the transition functionPijλ(t)=PYtλ=j|Y0λ=ifor all i,j∈EΔis given by the matrix-exponential solution(10)Pλ(t)=exp(Gλt)=∑n=0+∞tnn!(Gλ)nA further simplification is obtained by noting that(11)Gijλ=Gij-Λijfor all i,j∈E where Λ is a diagonal matrix defined as(12)Λij=λi,ifj=i0,ifj≠iSinceGΔjλ=0andGiΔλ=λifor all i∈E and j∈EΔ, we can rewrite (10) as(13)Pijλ(t)=exp(Gλt)ij=exp((G-Λ)t)ijfor all i,j∈E.Now, note that our construction of Yλimplies(14)T1=inft⩾0;Ytλ=Δand T1 is the first-passage-time to the absorbing state Δ. So, it has a phase-type distribution and, in particular,(15)P[T1>t|Y0=i]=P[Ytλ∈E|Y0=i]=∑j∈EPijλ(t)=∑j∈Eexp((G-Λ)t)ijNote that in reliability applications where failures occur exponentially with a rate that depends on the randomly changing environmental process, (15) gives the survival function. In this case, the mean time to failure is another quantity of interest. Using the Markov property, it can be computed by solving the system of linear equations(16)E[T1|Y0=i]=1ρiλ+∑j∈EPijλE[T1|Y0=j]for i∈E so that the explicit solution is(17)E[T1|Y0=i]=∑j∈E[I-Pλ]ij-11ρjλFollowing Özekici and Soyer (2006) an ergodic analysis can also be developed. Suppose that both X and Y are ergodic processes with limiting distributions νj=limn→+∞P[Xn=j] and πj=limt→+∞P[Yt=j]. This implies that ν is the unique solution of ν=νP with the normalizing condition∑i∈Eνi=1. It can be shown that(18)πi=νj/ρj∑k∈E(νk/ρk)Using Theorem 1 of Özekici and Soyer (2006), we can obtain(19)limt→+∞E[Nt-λˆt|Y0=i]=∑j∈Eπjλˆ-λjρjwhere(20)limt→+∞E[Nt|Y0=i]t=λˆ=∑j∈Eπjλjis the average failure rate. It follows from Fischer and Meier-Hellstern (1992) that the expected number of arrivals until time t is(21)E[Nt|Y0=i]=λˆt+∑j∈E([exp(Gt)-I][G+Π]-1)ijλjwhere the matrix Πij=πjhas identical entries in each column.Our primary objective is to develop statistical inference for the MMPP model using a Bayesian framework. It is important to note that in our model the Y process is latent and therefore in addition to the unknown parameters we also need to make inference about the latent states.In this section, we will illustrate how we can estimate all the parameters as well as the latent states in the MMPP model. The approach is based on the Markov Chain Monte Carlo (MCMC) method given in Fearnhead and Sherlock (2006). This method is based on a Gibbs sampler and requires a three-stage process. We first introduce some notation that will be used in describing the three stages. We define the software failure rates as λ={λi; i∈E}, holding rates of the Y process as ρ={ρi; i∈E}, and transition probabilities as P={Pij; i,j∈E}. Since there are K states in E and Pii=0 the total number of parameters to be estimated is K2. For example, when K=3, the transition matrix for the three-state Markov chain is(22)P=0p12p13p210p23p31p320where the sum of the probabilities in each row is one. Therefore, we only need to estimate one probability in each row, say p12, p21 and p31, when estimating P. We assume that the system is observed until some time tobsand n failures are observed at times t1, t2, …, tnduring the observation interval [0, tobs].In Stage 1, we will simulate the state of the hidden Markov process at each of the failure times given by our data setD={t1,t2,…,tn}. Thus, all the results are conditional on the parameters λ, ρ and P. In Stage 2, we will simulate the entire hidden Markov process, and in Stage 3 we will simulate a new set of parameter values using the Gibbs sampler. In what follows, we will outline what each of the three stage involves.Stage 1Since Y is a Markov process, the states{Sk=Ytk}at times 0=t0⩽t1⩽t2⩽⋯⩽tn⩽tn+1=tobs form a Markov chain with transition probabilities(23)Tsk-1,sk(k)=P[Sk=sk|Sk-1=sk-1]during the kth interval with duration tk−tk−1. It is well-known that T(k) is the matrix exponential(24)T(k)=exp[(G-Λ)(tk-tk-1)]We recursively define the matrices(25)A(n+1)=T(n+1)A(k)=T(k)ΛA(k+1)for k=n, n−1, …, 1 giving us the likelihoods(26)Ask-1,sn+1(k)=P[{tk,tk+1,…,tn},Sn+1=sn+1|Sk-1=sk-1]We first calculate {T(k)} using (24), and then we calculate {A(k)} using (25), starting with A(n+1), and going backwards until we have(27)As0,sn+1(1)=P[D,Sn+1=sn+1|S0=s0]We will assume that we know S0=s0 and Sn+1=sn+1, the states of the Markov process at times 0 and tobs, respectively. If they are unknown then we can adjust this algorithm slightly by putting a prior distribution on the state of the process at these times, but in our example we will assume that these states are known. Then, the state Skof the Markov chain at time tkcan be simulated using the conditional distributions(28)P[Sk=s|D,Sk-1=sk-1,Sn+1=sn+1]=Tsk-1,s(k)λsAs,sn+1(k+1)Ask-1,sn+1(k)recursively by proceeding forwards through the observation times t1, t2, …, tn.Stage 2After completing Stage 1, we will have our simulated states of the hidden Markov process {Sk} at each of our observation times {tk}. We will now use these to simulate the entire hidden Markov process Y. In so doing, we first simulate the process over the interval (t0, t1), then over (t1, t2) and so on until (tn, tn+1). The simulation over each interval is done using the uniformization of the Markov process Y supposing that ρ=maxi∈Eρiis finite. It is well-known (see, for example, Ross (1996)) that the Markov process Y can be represented as a Markov chainX^subordinated to a Poisson processN^with arrival rate ρ so thatYt=X^N^tand(29)P[Yt=st|Y0=s0]=P[X^N^t=st|X^N^0=s0]=∑n=0+∞P[N^t=n]×P[X^n=st|X^0=s0]=∑n=0+∞e-ρt(ρt)nn!Ms0,stnwhere(30)M=1ρG+Iis the transition matrix corresponding to the Markov chainX^. Over any interval (tk−1, tk), we already obtained the simulated statesYtk-1=sk-1andYttk=skin Stage 1. Therefore, the conditional distribution of the number failures ofN^during (tk−1, tk) is(31)P[N^tk-N^tk-1=n|Ytk-1=sk-1,Yttk=sk]=e-ρ(tk-tk-1)ρ(tk-tk-1)nn!Msk-1,sknexp[G(tk-tk-1)]sk-1,sksince(32)P[Ytk=sk|Ytk-1=sk-1]=exp[G(tk-tk-1)]sk-1,skTherefore, the number of failuresN^tk-N^tk-1can be simulated using (31). If simulation yieldsN^tk-N^tk-1=r, then the r arrival timestˆ1,tˆ2,…,tˆrofN^over the interval (tk−1, tk) are simulated by generating r uniform variates over (tk−1, tk) and ordering them. Now, we know thatYtk-1=sk-1andYtk=skand the states of hidden Markov process attˆ1⩽tˆ2⩽⋯⩽tˆrare simulated recursively by using the conditional distributions(33)P[Ytˆj=s|Ytˆj-1=sˆj-1,Ytk=sk]=Msˆj-1,sMs,skr-jMsˆj-1,skr-j+1for j=1, 2, …, r. For j=1, one should settˆj-1=tˆ0=tk-1andsˆj-1=sˆ0=sk-1. It also follows from the conditional distribution (33) thatYtˆr=Ytk=skat the last time point when j=r since M0 is the identity matrix.Stage 3Having completed Stages 1 and 2, we should now have the entire simulated hidden Markov process, as well as our data, the observed times of the failures. LetF={Yt;0⩽t⩽tn+1}denote the environmental process generated using the procedure in Stage 2. Thus, we can write the conditional likelihood function of the parameters and then obtain the full conditionals to generate a new set of values for our parameters at each step of the Gibbs sampler. Let τibe the total time that the hidden Markov process spends in state i, let nibe the total number of failures that occur while the process is in state i, and let rijbe the number of times the process makes a transition from state i to state j. It is clear that τi, ni, and rijare inFfor all i,j∈E. Given dataDand the entire historyFof the Markov process, the conditional likelihood function of the parameters ρi’s, λi’s and Pij’s is given by(34)L(ρ,λ,P;F,D)∝∏i∈Eρi∑j∈Erijexp(-ρiτi)λiniexp(-λiτi)∏j∈EPijrijAssuming conjugate independent priors for the unknown parameters the full conditional distributions can be easily obtained. More specifically, for a given state i=1, …, K, we assume independent gamma priors for ρi’s and λi’s, denoted asρi∼Gaiρ,biρ, andλi∼Gaiλ,biλ, respectively. For the i-th row of the transition matrix P, we assume a Dirichlet prior, independent of the other rows, asPi∼Dir(αi1,…,αiK)where Pi=(Pi1, …, PiK). Note that in Piwe have Pii=0 and the corresponding parameter αii=0. Using standard Bayesian results we can show that given the full history of the hidden Markov process, the full conditional distributions of the parameters can be obtained as(35)ρi|ρi-i∼Gaiρ+∑j∈Erij,biρ+τiandλi|λi-i∼Gaiλ+ni,biλ+τi(36)Pi|Pi-i∼Dir(αi1+ri1,…,αiK+riK)where αii=rii=0.We then generate new values for these parameters from their posterior distributions and then repeat the whole process again, starting with Stage 1.Our analysis in Section 3 assumed that the number of states K in the hidden Markov process was known. However, in general, the actual number of states may be unknown. Thus, it is important to be able to determine the number of states. The problem of determining K can be considered as a model selection problem in the Bayesian approach where the model choice is made using Bayes factors; see Kass and Raftery (1995) for a review. The computation of the Bayes factors requires the evaluation of marginal likelihood for a given model, that is, for given value of K in our case. More specifically, if we letD={t1,…,tn}denote our observed data, we want to obtain the marginal likelihoodp(D|K). The model with the highest value ofp(D|K)is the one most supported by the data and this can be used as the criterion for determining the value of K. Alternatively, assuming a support for K and specifying prior probabilities P[K=k] for different models such that∑kP[K=k]=1we can obtain posterior model probabilitiesP[K=k|D]using the marginal likelihood.Evaluation of the marginal likelihoodp(D|K)analytically is not possible in many problems since it requires integrating out the unknown parameters. Since draws from prior distributions of the parameters result in unstable estimation, it is more desirable to use Monte Carlo samples from the posterior distributions to evaluatep(D|K). Although this is not straightforward in many cases, when the full posterior conditional distributions are known forms, the marginal likelihood terms can be approximated using the approach proposed by Chib (1995). Since the Bayesian analysis of the MMPP in Section 3 is based on known full conditionals, we can adopt Chib’s procedure to our problem as will be discussed in the sequel.In our case, the marginal likelihood for a specific model with dimension K is given by(37)p(D)=p(D|ρ,λ,P,F)p(ρ,λ,P,F)p(ρ,λ,P,F|D)where ρ and λ are K-dimensional vectors of ρi’s and λi’s and P is the transition probability matrix of dimension K with zeros on the diagonal. We can rewrite (37) as(38)p(D)=p(D|ρ,λ,P,F)p(F|ρ,P)p(ρ,λ)p(P)p(ρ,λ,P|F,D)p(F|D)Eq. (38) holds for any values of(ρ,λ,P,F)such as(ρ∗,λ∗,P∗,F∗)which is typically chosen as the mean or mode values of the posterior distributions. We note that all the terms in the numerator are available to us analytically and therefore can be evaluated at(ρ∗,λ∗,P∗,F∗). The tricky part to evaluate is the denominator term(39)p(F∗|D)=∫p(F∗|D,λ,ρ,P)p(λ,ρ,P|D)d(λ,ρ,P)which can be evaluated using G samples from the posterior distributionp(λ,ρ,P|D)via(40)p(F∗|D)=1G∑gp(F∗|ρ(g),λ(g),P(g),D)The first termp(ρ∗,λ∗,P∗|F∗,D)can easily be written down as(41)p(ρ∗,λ∗,P∗|F∗,D)=p(ρ∗|F∗,D)p(λ∗|F∗,D)p(P∗|F∗,D)wherep(ρ∗|F∗,D)andp(λ∗|F∗,D)are obtained as the product of gamma densities given by (35) andp(P∗|F∗,D)is the product of the Dirichlet densities in (36). Thus, for each value of K, we can approximate (38) and determine the model with the highest support of the data. As previously mentioned, using the marginal likelihood we can also compute posterior model probabilitiesP[K=k|D]to infer the value of K.In this section we consider Musa’s System I data (see for example, Singpurwalla and Soyer (1992)) to illustrate our model and to discuss what type of additional insights can be obtained from the MMPP model. The data was observed over a period of tobs=90,000 units, and n=136 failures were observed during this time. A plot of the time between failures is shown in Fig. 1below.The failure times will be labeled t1, …, t136. All the numbers from Musa’s System I data have been divided by 1000. We also set t0=0 and tn+1=t137=tobs=90. So the data we are using is t0=0, t1=0.003, …, t136=88.682, t137=90. In our analysis, we will use the standard homogeneous Poisson process model as a benchmark to assess the performance of the MMPP model. Note that the marginal likelihood for the homogeneous Poisson process can be easily obtained as a negative binomial model by using the conjugate gamma prior for failure rate λ.In our development we will present results from the analysis of the two-state MMPP. Note that in this case the transition matrix for the embedded Markov chain of the environmental process is given by(42)P=0110and therefore we only need inference on parameters ρ1, ρ2, λ1, and λ2, as well as on latent states s1, …, sn. In our analysis we use diffused but proper priors for these parameters by settingaiλ=biλ=0.01for i=1, 2. Similarly, we useaiρ=biρ=0.01for the priors of ρ1 and ρ2. After a small burn-in sample, we collected 1000 simulations to obtain the posterior distributions for our four parameters. We have not witnessed any convergence problems in running the Gibbs sampler. Trace plots for posterior samples from the distributions of λ1, and λ2 are shown in Figs. 2 and 3.The posterior distributions of λ1 and λ2 that are shown in Figs. 4 and 5imply that the failure rate in state 1 is higher than the failure rate in state 2. The posterior distribution of the holding rate ρ1 in state 1 is given in Fig. 6. The posterior mean of ρ1 is 0.0532 implying that the expected holding time in state 1 is about 18.795 time units. Our analysis has shown that state 2 is acting like an absorbing state, that is, expected holding time is infinite. Similarly, when we look at the posterior distributions of the long-run probabilities π1 and π2 of (18), we can see that the posterior expected values for π1 and π2 are 0.997 and 0.003, respectively. We can also infer this behavior by looking at the posterior distributions of the states at the failure times ti’s of the software.Table 1shows the posterior mean values of the states at each failure time. These values seem to suggest that the hidden Markov process remains in state 1 approximately until between t78 and t79. Looking at the data, we can see that t78=18.728 and t79=19.556. Comparing this to the posterior distribution of ρ1, the mean of this distribution is 0.0532, which means that the expected holding time in state 1 before changing to state 2 is 1/0.0532=18.795, which also seems to suggest that, on average, the hidden Markov process remains in state 1 until between the 78th and 79th failure. Our simulated posterior density of ρ2 is of no use to us at all. It basically just looks like a point mass at some number very close to zero. Thus, once the environmental process enters state 2 it stays there forever. This implies that during the debugging process the reliability improvement in the software is initially limited as reflected by shorter failure times and the higher failure rate λ1. As the debugging process continues to later periods, failure rate decreases and the time between failures get larger. Thus, based on this we can conclude that as a result of the debugging process reliability of the software has improved. Fig. 7shows both the data and the posterior means of the states of the hidden Markov process on the same graph.Furhermore, using the posterior samples of parameters (ρ, λ) we can obtain the posterior predictive reliability using (15). We note that (15) is a function of (ρ, λ) and therefore we need to evaluate the integral(43)P[T1>t|Y0=i,D]=∫P[T1>t|Y0=i,ρ,λ]p(ρ,λ|D)=∫∑j∈Eexp((G-Λ)t)ijp(ρ,λ|D)dρdλThe above can be approximated by the Monte Carlo average(44)P[T1>t|Y0=i,D]≈1S∑s∑j∈Eexp((Gs-Λs)t)ijusing posterior samples{ρ,λ}s=1Sfromp(ρ,λ|D). In Figs. 8 and 9we present the posterior predictive reliability functions for Y0=1 and Y0=2, respectively. Since environmental state 1 has a higher failure rate, if testing starts in state 1, then the posterior predictive reliability goes to 0 around t=2000 time units. On the other hand, if the initial state is state 2, the reliability reaches to 0 around 6000 time units.We can reach the same conclusion by computing the posterior expected time to failure (17). Again we note that (17) is a function of unknown parameters and it can be approximated as a Monte Carlo average given by(45)E[T1|Y0=i,D]≈1S∑s∑j∈E[I-Pλ]ij-11ρjλsusing posterior samples{ρ,λ}s=1Sfromp(ρ,λ|D). Note that Pλis given by (8) which also depends on P and therefore in general one needs to use the posterior samples of P to evaluate (45). But since P is known for the two dimensional case, we do not need it in our calculations. It can be shown that the posterior expected time to failure can be obtained asE[T1|Y0=1,D]=0.83andE[T1|Y0=2,D]=4.15when testing starts at states 1 and 2, respectively.We have repeated a similar analysis for the MMPP with K=3 states. Finally, we computed the marginal likelihoods using the approach introduced in Section 4. The comparison of the marginal likelihoods indicate that the model with K=2 is preferred over the others.In this paper we introduced a Markov modulated Poisson process to describe the failure of a software that goes through a debugging process. The model can capture imperfect debugging and allows us to make inferences about the performance of the debugging process at each stage of testing. We presented a Bayesian analysis of the model and illustrated how Bayesian inferences can be made about reliability of the software. Furthermore, we introduced an approach to assess the dimension of the hidden Markov process of the model by using the marginal likelihood. In doing so, we showed how the marginal likelihood can be computed using the approach proposed by Chib (1995). We illustrated the implementation of our approach using actual software failure data and discussed the additional insights that can be obtained from our model.

@&#CONCLUSIONS@&#
