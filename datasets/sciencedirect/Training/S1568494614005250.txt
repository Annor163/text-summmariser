@&#MAIN-TITLE@&#
A self-adaptive PSO for joint lot sizing and job shop scheduling with compressible process times

@&#HIGHLIGHTS@&#
This paper seeks the optimal value of the following decision variables:Sequence of processes on different item types over every machine.Sequence of processes of a given item type over the corresponding machines according to predefined precedence relations.Batch size of different item types over planning periods.Working speed/mode of each machine for processing on different item types.

@&#KEYPHRASES@&#
Lot sizing,Scheduling,Process compressibility,Job shop,Particle swarm optimization (PSO),Self-adaptivity,

@&#ABSTRACT@&#
This paper presents mathematical modeling of joint lot sizing and scheduling problem in a job shop environment under a set of realistic working conditions. One main realistic assumption of the current study is dealing with flexible machines able to change their working speeds, known as process compressibility. The production schedules should be subject to limited available time in every planning period. Also, the model assumes that periodical sequences should be determined in a way that they obey from a fixed global sequence. Another complicating aspect of the problem is about consideration of precedence relationships for the needed processes of an item type over the corresponding machines. As the problem is proved to be strongly NP-hard, it is solved by a particle swarm optimization (PSO) algorithm. The proposed algorithm is self-controller about its working parameters, time to stop the search process, search diversification/intensification, and totally about its behavior. Performance of the algorithm is verified in terms of optimality gap using Lingo 11.0 on a set of randomly generated test data.

@&#INTRODUCTION@&#
A production manager should decide about lot size and process routing of some items in each planning period to minimize total cost of the plant. He/she can take either a dynamic or a fixed process sequence for the items. These decisions (i.e. lot sizes and machine sequences) were traditionally made in a sequential manner, resulting in a number of recursive corrective actions. In more details, a similar procedure such as that shown in Fig. 1were generally used in traditional (i.e. MRP-based) production management with some minor variations (Fallah and Shayan [4], Koh et al. [12], Waters [20], Pochet and Wolsey [17]).The decisions are usually updated via a rolling horizon framework with the hope of cost reduction by means of special-purpose packages or heuristics (Karimi et al. [8]). There have been many critiques on the non-optimality of them due to non-simultaneousness of decision makings (Franck et al. [5]). So, if we decide about lot sizes and process sequences simultaneously while considering shop constraints, then we can be sure about the efficiency and/or optimality of the whole production schedule (i.e. lot sizes and machine sequences in periods). However, this may lead to mixed integer programming (MIP) formulations that are hard to solve in reasonable CPU time for sizes close to real world (Pochet and Wolsey [17]). This paper fills in the gap by providing a problem formulation along with an efficient solution algorithm. Now, a brief review of the literature is reported. Previous researchers have provided different contributions to the main problem in terms of concepts, model, and solution methods.Afentakis [1] proposed some crude ideas about combining lot sizing and sequencing decisions in a job shop environment. He proposed extending previous famous models for this aim, but did not provide any formulation. Later, Schwindt and Trautmann [23] dealt with batch scheduling in process industries for when using multi-purpose machines. They have used methods of resource-constrained project scheduling for handling the problem. Other similar contributions are proposed in literature by integrating ideas from other problems. For example, Wong et al. [21] combined ideas in capacitated lot sizing and scheduling problem (CLSP) with resource-constrained project scheduling problem (RCPSP). Both of them assumed that routing of activities among machines is known a priori. On the other hand, different lot streaming and/or lot sizing policies are proposed in the literature that lead in different properties for optimal solutions. Among others, Chan et al. [3] and Wong et al. [21] have considered such policies in details. In contrast, this paper develops a dynamic capacitated lot sizing and scheduling problem, where lot sizes and schedules are determined periodically but periodical schedules obey from a global schedule in all periods. In this respect, to our best knowledge, a similar contribution is not proposed in the literature (Potts and van Wassenhove [18], Zhu and Wilhelm [22], Maravelias and Sung [13]).The most favorite area of research in the literature is dedicated to providing different formulations for the problem according to various working conditions that can arise in real case observations. It should be noted that most of the formulations are based on some famous problems such as CLSP, RCPSP, PLSP (proportional lot sizing and scheduling problem), GLSP (generalized lot sizing and scheduling problem), DLSP (discrete lot sizing and scheduling problem), CSLP (continuous setup lot sizing and scheduling problem), etc. Ierapetritou and Floudas [6] and Ierapetritou et al. [7] proposed formulations for production scheduling in chemical industries. They considered intermediate storages of finite capacities for both work-in-processes and raw materials. They also, considered the precedence relations between different processes on each product in their formulation. Ozturk and Orneck [24] developed a MIP model for multi-period production scheduling with allowable backordering and production capacity constraint along with linked lots. Their model is an extension of capacitated lot sizing and scheduling problem (CLSP) for job shop environment.The main problem is solved with different solution methods in the literature that are mainly exact (for small sizes or simple problems), (meta-)heuristic or hybrid (for complicated problems or large sizes). As an example, Kim and Kim [10] and Wong et al. [21] solved the problem by simulated annealing and genetic algorithm. Chan et al. [3] used genetic algorithm (GA) for determining lot sizes, and simple dispatching rules for determining sequence of lots in a hybrid framework. Ouenniche and Bertrand [16] proposed a model based on basic cycle approach. They decomposed the main problem into an assignment subproblem, a sequencing subproblem, and a lot sizing and scheduling subproblem. Then, assignment subproblem is solved by a heuristic, sequencing subproblem is solved by either of simulated annealing or tabu search, but lot sizing and scheduling is solved by mathematical programming to optimality. Nozick et al. [15] proposed a simple model for processing items in a job shop environment with the help of project scheduling concepts. They solved the model by a heuristic based on generalized Benders’ decomposition (GBD).This paper tries to determine the optimal value of following decision variables simultaneously in an integrated manner:-sequence of processes on different item types over every machine,sequence of processes of a given item type over the corresponding machines according to predefined precedence relations,batch size of different item types over planning periods,working speed/mode of each machine for processing on different item types.To our best knowledge and according to the reviewed literature (see for example Zhu and Wilhelm [22]), this problem is not broadly addressed till now by researchers while it seeks answers to some critical questions of production managers. Rest of the current paper is organized as follows: Section 2 provides problem formulation, Section 3 describes the solution algorithm, Section 4 presents numerical example, and Section 5 concludes the papers and proposes some guides for future research.This section formulates the problem based on the following working conditions:-there are a set of items that each has to pass different processes according to a predefined precedence between the processes (i.e. the machines are in a job shop environment),there are a finite number of planning periods with known dynamic available times,there are a set of single-purpose (i.e. each machine is able to perform a unique process) non-duplicate machines,each machine is a dedicated resource that can only process one item at a time,setup include two parts:(a)sequence-dependent setups which are separable such that it is done before processing on a batch of an item type. In other words, each machine should be setup by changing its current tool/settings whenever it finishes processing an item type, andcleaning time which is independent of the item type and the process such that it is done after processing on a batch of an item type (i.e. cleaning is for brushing, lubricating, etc.),shortage of the items are allowed in term of backorders not lost sales. In this way, shortage is allowed in all periods except the last one,the manager desires to minimize total costs, including setup, production, inventory holding and shortage of the items,holding work-in-process is not allowed for any item types at the end of each planning period. In words, production process of an item should be completed within the same period it started,there are intermediate buffers with large enough capacities to hold work-in-processes before machines,pre-emption/disruption is not allowed,machines are reliable and they do not fail in the horizon. In other words, it is assumed that no emergency maintenance is needed during available time ATtin period t, 1≤t≤T.all input parameters are deterministic,each machine can operate in different discrete speed levels (or modes) such that the set of modes for each machine is known (see Fig. 2for example). Also, the working mode of each machine should be adjusted before starting any processings and the mode cannot be changed over periods according to managerial requirements.Now, the problem can be formulated with the help of the following notations:Sets and indexesjindex of machines (j=1, …, m)kindex of items (k=1, …, K)tindex of periods (t=1, …, T)Skset of machines that item type k needs to be processed on themParametersRj,w,k1if process on machinejis predecessor for process on machinewof itemk0elseATtavailable time in period tMa very large positive numberDk,tdemand of item k in period thkinventory holding cost of item k per periodπkshortage cost of item k per periodpjmaxmaximum/normal duration of processing an item on machine jpjminminimum/crash duration of processing an item on machine jpj,iunit process time of machine j when working at its ith mode (speed level)cj,iunit process cost of machine j when working at its ith mode (speed level)cjmaxmaximum unit cost of processing an item on machine jcjminminimum unit cost of processing an item on machine jljfinishing/cleaning time of machine jθjnumber of modes (=speed levels) that machine j can process items(θj≤pjmax−pjmin−1)Ωj,k1if a process of itemkis performed on machinej0elsestj,k,hsetup time of machine j for process on item k after performing process on item hscj,k,hsetup cost of machine j for process on item k after performing process on item hVariablesSk,tshortage of item k in period tIk,tinventory of item k in period tyk,tproduction volume of item k in period txj,k,tstart time of process of item k on machine j in period tpjduration of processing an item on machine j disregarding the item typeSeqj,k,h1if process of itemkis performed after process of itemhon machinej0elseBk,h,j,t1if item typekis processed immediately before item typehon machinejin periodt0elseλk,t1if itemkis produced in periodt(i.e. ifyk,t≥1)0elseΔj,i1if machinejworks at itsith speed level(for1≤i≤pjmax−pjmin−1)0elsecwj,i,k,tprocess cost of machinejworking at its mode i on a batch of item type k in period tzj,w,k1if itemkis processed on machinewbefore than machinej0elsewj,k,tduration of processing yk,tunits of item type k in period t on machine j (wj,k,t=pjyk,t)Now, the problem formulation is constructed below.(1)minTC=∑t=1T∑k=1K∑j=1m∑h=1KBk,h,j,tscj,k,h+∑t=1T∑k=1K∑j=1m∑i=1θjΩj,kcwj,i,k,t+∑t=1T∑k=1KhkIk,t+∑t=1T∑k=1KπkSk,ts.t.(2)∑i=1θjΔj,i=1∀j(3)wj,k,t≤yk,tpj,i+M(1−Δj,i)∀k,j∈Sk,t,i=1,...,θj(4)yk,t≤λk,t∑q=1TDk,q∀k,t(5)∑t=1Tyk,t≥∑t=1TDk,t∀k(6)Seqj,k,h+Seqj,h,k=1∀k≠h,j∈{Sk∩Sh}(7)∑hΩj,hBk,h,j,t=λk,t∀k,j∈Sk,t(8)cwj,i,k,t≥yk,tcj,i−M(1−Δj,i)∀k,j∈Sk,t,i=1,...,θj(9)∑kBk,k,j,tΩj,k≤1∀t,j(10)Bk,h,j,t+Bh,k,j,t≤λk,t+λh,t2∀k≠h,j∈{Sk∩Sh};t(11)Bk,h,j,t≤1−Seqj,k,h∀k≠h,j∈{Sk∩Sh};t(12)Ik,t−Sk,t=Ik,t−1+yk,t−Sk,t−1−Dk,t∀k,t(13)xj,k,t+wj,k,t≤ATt∀k,t,j∈Sk(14)xj,k,t≥stj,k,k∀k,j∈Sk(15)zj,w,k(1−Rj,w,k)+zw,j,k(1−Rw,j,k)=1∀k,{j≠w}∈Sk(16)xw,k,t≥stj,k,kBk,k,j,t+xj,k,t+wj,k,t−M(1−zw,j,k)∀k,{j≠w}∈Sk(17)xj,k,t≥stj,k,h+xj,h,t+wj,h,t+lj−M(1−Seqj,k,h)∀k,{j≠w}∈Sk(18)wj,k,t,Sk,t,Ik,t,yk,t∈Z+∪{0}(19)Bk,h,j,t,Seqj,k,h,λk,t,Δi,j,zj,w,k∈{0,1}As the manager aims to minimize the total costs, the objective function (1) minimizes total setup costs, production costs, inventory and shortage costs. Also, process compressibility is reflected in production costs. According to the problem assumptions, each process can be done in a time interval over the related machine. This is shown with constraint (2). Also, constraint (2) seems solely sufficient to reflect a true value for pj(note thatpj=∑i=1θjΔj,ipj,i). Constraint (3) measures wj,k,t, where wj,k,t=pj·yk,t. Constraint (4) states that if there is a positive production volume of item type k in period t (i.e. yk,t>0 or λk,t=1), then yk,tis bound by above to total needs of item type k over planning periods. Also, by using constraint (4), we are able to find the need of setup when λk,t=1 (note that according to assumptions, the manager wants to minimize the total costs and this prevents unnecessary λk,t=1 when yk,t=0). On the other hand, constraint (5) states that the total production volume of item type k should not be less than of its total needs over planning periods. Another indirect meaning of constraint (5) is that shortages can only occur in the form of partial backorders not lost sales. In other words, there can be shortages in all periods other than t=T. However, constraint (5) certainly holds in equal form in an optimal solution, but this form helps in finding initial solutions in shorter CPU times by solvers such as Lingo 11.0. As the manager wants to obtain a unique sequence for processing items in all periods, then, according to the definition of Seqj,k,hvariables, constraint (6) holds for this aim. Also, this constraint is only true if further than one item types needs being processed over machine j. However, if there is a case that a machine should just be used by an item type, constraint (6) it is clearly not necessary to consider. Constraint (6) obtains a globally consistent sequencing of different item types over machine j, disregarding whether a/some of the items k is/are produced in a period t or not. Constraint (7) constructs constraints for obtaining periodical sequences but consistent to the global sequence obtained by relation (6) by regarding whether item type k is produced in period t (i.e. λk,t=1) or not (i.e. λk,t=0). Constraint (8) measures process cost of machine j working at its mode i on a batch of item type k in period t.Constraint (9) states that at most one item type k should be at the first position of machine j in period t. Constraint (10) states that two arbitrary item types k and h can be immediately positioned in a sequence for processing on machine j in period t when both of the item types are produced in period t (i.e. λk,t=λh,t=1).Constraint (11) states the relation between Seqj,k,hand Bh,k,j,tin order to building periodical sequences (obtained by Bh,k,j,t) consistent to the global sequence (obtained by Seqj,k,h). Constraint (12) holds for measuring inventory/shortage of item type k at the end of period t.Also, the right hand side of constraint (13) measures the completion time of processing on item type k in period t, and checks if all processes of item type k in period t are completed before the end of available time in period t. In other words, constraint (13) dictates that there should be not semi-finished items between production stages at the end of a period. Then, we know that if item type k is processed at the first priority order of machine j in period t (i.e. Bk,k,j,t=1), then the start of that process is assumed to be greater than or equal to the needed setup time stj,k,k. Constraint (14) states the same sense but in algebraic format. Note that in this way we can model the working condition of separable setups in the whole formulation, where setups can be done before release of an item type to the text process stage.Constraint (15) determines the process sequence on item k over such machines j and w. Constraint (16) is proposed to ensure us about satisfying precedence relations. In more details, constraint (16) relates the process start times of item type k on two machine j and w while considering separability of setups without using zj,w,kvariables for the cases that machine j is explicitly predecessor of machine w. But, as there are cases neither machine j nor machine w are predecessor of the other one. And, as the process sequence on item k over such machines j and w are determined by constraint (15), then constraint (16) correctly relates the start of process on machine w and finish of process on machine j for the same item type k in period t. And, constraint (17) relates the global sequence of item types k and h when both of them are processed on the same machine j in period t. Note that if either of item type k or h is not produced in period t (i.e. λk,t·λh,t=0), then constraint (17) is true but redundant. Also, as it is better not to use big-M in the formulations, and the fact that xj,k,tis bounded from above by ATtaccording to constraint (13), the big-M in constraint (17) can be replaced by ATtwithout any problem.According to the constraints above, when the process of yh,tnumber of item type h is started in period t on machine j, machine j releases this lot at the moment of xj,h,t+pjyh,t. But, start of processing on another lot corresponding to item type k on the same machine j requires that firstly the machine be cleaned and lubricated in ljtime, and the needed setup is performed in stj,k,htime. Finally, relations (18) and (19) state the type of decision variables.As the model is a mixed integer linear program (ILP for short), it is inefficient to solve with commercial solvers such as Lingo 11.0. Furthermore, as the problem can be proved to be NP-hard, the new model is not expected to be solved in polynomial times. Hence, the next section develops an intelligent algorithm for solving it, specially in large sizes close to real world instances.This section explains internal mechanisms of the self-adaptive PSO algorithm. Algorithms are classified in three main groups based on their authority in decision making about their working strategies and/or parameters (Nearchou [14], Kramer [11]):(i)simple algorithms; which should do exactly what we want from them in a predefined way by getting working parameters before their start,adaptive algorithms; which are allowed to have some partial authorities about one of their working parameters/mechanisms, andself-adaptive (or self-controller) algorithms; which have the authority to decide about their behavior type and/or parameters according to the current condition when solving a given instance.The behavior of an algorithm can be observed in some ways/indexes, including (Kramer [11], Pochet and Wolsey [17]):-convergence rate,ability to escape from local optima,ability to diagnose true global optima in the search procedure,run time,ability to decrease the probability of meeting previously visited solutions (i.e. degeneracy).When considering the above performance indices, self-adaptive algorithms are expected to be more intelligent/efficient than the others (Al-Anzi and Allahverdi [2], Wang and Tang [19]). In this section, a self-adaptive PSO is developed for solving the problem. The following notations are used in the algorithm:NOPnumber of particlesnindex of particle (n=1, 2, …, NOP)Iterminminimum number of algorithm internal iterationsiindex of algorithm iterationc1the cognition learning factor (c1∈[0,2])c2the social learning factor (c2∈[0,2])r1, r2random parameterswweight of inertia termyk,tproduction volume of item k in period tpjunit process time of machine jschkprocess routing of item kXn,i(yk,t)partial position of particle n at iteration i depending on yk,tXn,i(pj)partial position of particle n at iteration i depending on pjXn,i(schk)partial position of particle n at iteration i depending on schkVn,i(yk,t)partial velocity of particle n at iteration i depending on yk,tVn,i(pj)partial velocity of particle n at iteration i depending on pjVn,i(schk)partial velocity of particle n at iteration i depending on schkpbestn,i(yk,t)the best partial position of particle n at iteration i depending on yk,tpbestn,i(pj)the best partial position of particle n at iteration i depending on pjpbestn,i(schk)the best partial position of particle n at iteration i depending on schkgbesti(yk,t)the best partial position of population till iteration i depending on yk,tgbesti(pj)the best partial position of population till iteration i depending on pjgbesti(schk)the best partial position of population till iteration i depending on schkincumbentthe best solution vector till the current iteration of the algorithmfbestThe best fitness value obtained till the current iteration of the algorithmfaverageaverage of fitness values obtained till the current iteration of the algorithm{λ; ɛ; β; γ; ψ1; ψ2; ψ3}:a set of working parameters of the proposed algorithmNow, the general schema of the proposed self-adaptive PSO algorithm is given. The algorithm calls some decision making modules for different purposes. Fig. 3illustrates the flowchart of the proposed self-adaptive PSO algorithm. Further explanations about these modules and their internal mechanisms are given in the following sections.Self-adaptive PSO algorithmcall initial swarm modulewhile stopping criteria ≠ true docall particles’ move modulecall fitness evaluation moduleupdate incumbentupdate fitness (incumbent)call self-adapting modulecall stopping criteria moduleend whilereturn {incumbent; fitness (incumbent)}Number of particles of the PSO algorithm is found NOP=70 by try and error on the test data. In other words, we have tested some values for NOP and have run the algorithm with each value on the test data. Then, the algorithm showed almost the best performance for NOP=70.In this paper, the vectors of initial swarms are produced pseudo-randomly within their domain sets. Also, there are a few feasibility seeking heuristics, but for special characteristics of the problem and the speed of random value generation, it is preferred to utilize this method instead of time consuming heuristics. However, infeasible solutions are involved in a large penalty in their fitness values. Now, we explain in more details about generating an initial solution. Furthermore, as X(yk,t), X(pj), and X(schk) are the only independent variables, and V(yk,t), V(pj), and V(schk) can be calculated subsequently, we ignore showing the related cells for V(yk,t), V(pj), and V(schk). For example, for the test data K=4, m=3 and T=3 we have:a.first, yk,tare randomly generated such that constraint (5) be satisfied in equal from. This can be simply achieved by some built-in codes in MATLAB (See Fig. 4),then, pjvalues are randomly generated within their relative sets (See Fig. 5),finally, for each cell in X(schk), a random pair of (item index, machine index) is selected to provide a global sequencing. In this way, when a pair (kr1, Mj1) precedes (kr2, Mj2), one can concludes that process of item type kr1 on machine Mj1 is actually sequenced before the process of item type kr2 on machine Mj2. Thus, we can easily implement precedence relationships for the processes of each item type on the needed machines (See Fig. 6).For example, in the obtained solution we see that process of item type k1 on machine M1 is sequenced before the process of item type k1 on machine M2 and so forth.d.Note that each part of the solution vector is feasible solely. Then, what remains to check is constraint (13). In more details, if the process completion time of each item type at every period is less than the corresponding available times, then constraint (13) is satisfied. Otherwise, we can decrease the unit process time of the machines till reaching feasibility. Above all, if infeasibility persists, we contribute fitness of such a solution with a large penalty. Consequently, after some iterations, the percent of infeasible solutions decreases monotonically. However, one can devastate complex rules for feasibility of such solutions, but our attempts resulted in increase of CPU time and decrease in convergence rate.Each particle is characterized by two vectors for its position and its velocity. According to the decision variables of the constructed model, the position vector consists of three sections as (vp,t, pj, schk) at iteration i. Similarly, the velocity vector consists of three sections as (Vn,i(vp,t), Vn,i(pj), Vn,i(schk)) at iteration i.particles’ move moduleget {w; c1; c2}for n=1 to NOPr1=random (0,1)r2=random (0,1)for k=1 to Kfor t=1 to T(20)Vn,i+1(yk,t)=r1⋅c1⋅(pbestn,i(yk,t)−yk,t)+r2⋅c2⋅(gbesti(yk,t)−yk,t)+w⋅Vn,i(yk,t)(21)Vn,i+1(pj)=r1⋅c1⋅(pbestn,i(pj)−pj)+r2⋅c2⋅(gbesti(pj)−pj)+w⋅Vn,i(pj)(22)Vn,i+1(schk)=r1⋅c1⋅(pbestn,i(schk)−schk)+r2⋅c2⋅(gbesti(schk)−schk)+w⋅Vn,i(schk)(23)Xn,i+1(yk,t)=r1⋅c1⋅(pbestn,i(yk,t)−yk,t)+r2⋅c2⋅(gbesti(yk,t)−yk,t)+w⋅Xn,i(yk,t)(24)Xn,i+1(pj)=r1⋅c1⋅(pbestn,i(pj)−pj)+r2⋅c2⋅(gbesti(pj)−pj)+w⋅Xn,i(pj)(25)Xn,i+1(schk)=r1⋅c1⋅(pbestn,i(schk)−schk)+r2⋅c2⋅(gbesti(schk)−schk)+w⋅Xn,i(schk)return{Xn,i+1(yk,t),Xn,i+1(pj),Xn,i+1(schk),Vn,i+1(yk,t),Vn,i+1(pj),Vn,i+1(schk)}As velocity elements are not confined to be discrete, there is no problem in relations (20)–(22). But, the output of relations (23)–(25) for Xn,i+1(yk,t), Xn,i+1(pj) and Xn,i+1(schk) should be rounded to the nearest integer in order to obtain a feasible solution vector. Also, one can call, without loss of generality, a checking procedure to assure the feasibility after rounding such continuous values. The procedure is illustrated via a numerical example. According to the solution structure described in response to the next comment along with the response to previous comment, the claim is on hand. Also, note that X(schk) refers to the cell number corresponding to the order of processing a pair (kr,Mj). For example, consider the following part of a solution corresponding to X(schk):In the current example, X(k1,M1)=1, X(k2,M1)=2, X(k1,M2)=3, X(k4,M1)=4, X(k3,M1)=5, X(k4,M3)=6, X(k3,M2)=7, X(k1,M3)=8, X(k3,M3)=9, and X(k2,M3)=10 (See Fig. 7). Then, assume that after using relation (25) for obtaining new values for the elements in X(schk) are as below:X(k1,M1)=1.25, X(k2,M1)=1.85, X(k1,M2)=3.59, X(k4,M1)=3.05, X(k3,M1)=6.18, X(k4,M3)=4.73, X(k3,M2)=7.33, X(k1,M3)=8.02, X(k3,M3)=8.09, and X(k2,M3)=10.Now, we should round the X(schk) values to the nearest integers:X(k1,M1)=1, X(k2,M1)=2, X(k4,M1)=3, X(k1,M2)=4, X(k4,M3)=5, X(k3,M1)=6, X(k3,M2)=7, X(k1,M3)=8, X(k3,M3)=8, and X(k2,M3)=10.However, there are two elements with the same order number (i.e. X(k1,M3)=8, X(k3,M3)=8) and simultaneously there is a missing order number in the solution (i.e. there is no X(schk)=9). Now, one can change one of X(k1,M3)=8, or X(k3,M3) to 9 by a simple checking of the precedence relations of the problem (See Fig. 8).Similarly, X(yk,t) and X(pj) can be updated via relations (23) and (24).The fitness function is considered as 1/(1+|TC|) to evaluate each particle at different iterations. On the other hand, different fitness functions such as exp(−|TC|) could be used. However, the final results of both functions do not have meaningful difference for the current problem. In the fitness evaluation module, the current value of fitness function for each particle is calculated and also the parameters of pbestnand gbestnare updated with respect to the amount of fitness improvement for particle nth. Furthermore, the best fitness value for the current particles’ settings is calculated and returned by fbest. In the same way, the average fitness value for the current particles’ settings is returned by faverage.fitness evaluation modulefor n=1 to NOPget {Xn,i+1(yk,t), Xn,i+1(pj), Xn,i+1(schk), Vn,i+1(yk,t), Vn,i+1(pj), Vn,i+1(schk)}calculate total costif the current particle s is infeasible thenadd a big penalty to total cost of particle scalculate fbestand faveragefor the current position of particlesreturn {fbest; faverage}for n=1 to NOPupdate pbestnupdate gbestnreturn {pbestn; gbestn}To obtain an intelligent PSO algorithm which could tune its current parameters in every iteration, some proposals are suggested in this section. Also, this feature makes sure that the search procedure is carried out more efficiently. We could embed mechanisms for changing different input parameters, but for the current problem only a mechanism is proposed for changing w, c1 and c2. The algorithm starts with an initial value set of w, c1 and c2. Then, if no meaningful improvement is reported in a series of sequential solutions, the current value of w should be changed to a lower value. This process should be repeated till a predefined value greater than zero is achieved. Also, if the same process is hired for changing c1 and/or c2 in the iterations, then the PSO algorithm becomes more intelligent and also freer to search the solution space. In this way, the search time of the algorithm is more efficiently used for diversification. The following pseudo-codes illustrate these parts of the self-adaptive PSO, labeled as self-adapting module:self-adapting moduleget {number of sequential degenerations}get {average of best fitness functions; variance of best fitness functions}get {iteration number; λ; ɛ; β; w; c1; c2; γ; ψ1; ψ2; ψ3}if variance of best fitness functions ≤ λ thenif w−ɛ≥γ thenw=w−ɛelse if variance of best fitness functions ≥ β thenif∑n=1NOP|fitness(pbestn)−fitness(gbestn)|≤ψ1thenif c1−ɛ≥γ thenc1=c1−ɛelse if∑n=1NOP|fitness(gbestn)−fitness(incumbent)|≤ψ2thenif c2−ɛ≥γ thenc2=c2−ɛelse if∑n=1NOP|fitness(pbestn)−fitness(gbestn)|+∑n=1NOP|fitness(gbestn)−fitness(incumbent)|≤ψ3thenif c1−ɛ≥γ and c2−ɛ≥γ thenc1=c1−ɛc2=c2−ɛnumber of sequential degenerations=0elsenumber of sequential degenerations= number of sequential degenerations+1return {number of sequential degenerations; w; c1; c2}The role of the inertia weight, w, is considered critical for the PSO algorithm's convergence behavior. Kennedy et al. [9] investigated the effect of w values in the range of [0,1.4], as well as varying w over time. From the investigations, it was observed that choosing w∈[0.8,1.2] results in faster convergence, but when it exceeds 1.2, the algorithm fails to converge consistently.Note that there is no problem for the algorithm when λ<variance of best fitness functions<β. In such a situation, the algorithm simply postpones updating the working parameters of the PSO (including w, c1, and c2) to another forthcoming iteration. Also, there is no obligation for the algorithm to have variance of best fitness function larger than λ and larger than or equal to β. In more details, the module just checks the progress trend in the solution space. Evidently, there can be cases that the variance of best fitness function is neither larger than λ or larger than or equal to β. However, the algorithm can be modified to have other behavior in similar cases in future research.Terminating PSO, after a predetermined number of iterations (Itermin), results in a simple and non-intelligent algorithmic design. On the other hand, a good population-based optimization algorithm should terminate only when it is sure of its convergence to the global optimum. One of the sufficient (but not necessary) conditions for convergence to the global optimum is when the difference between the best fitness and the average fitness of the population becomes below a threshold (ɛ) at a series of sequential iterations. A good value of ɛ could be determined by try and error or by using statistical tests.(26)ε≤α⋅(fitnessmax−fitnessmin)where α is a value between 0 and 0.05. But, this criterion might be satisfied in an early run of the algorithm while trapping in a local optimum. In this situation, it is better to let the algorithm have a minimum number of iterations to explore the solution space sufficiently and then the previous condition is checked. For these reasons, the rules of stopping criteria module are designated in the algorithm as the stopping condition:stopping criteria moduleui=Iterminwhile iter≤Itermindoif |faverage−fbest|≤ɛ thenstopreturn {stopping criteria=true}elseItermin=Itermin+uii=i+1end whileIn this section, we compare the performance of the proposed PSO algorithm with Lingo 11.0 on a numerical example. The data are taken from a current study in a company working in household appliance industry in Iran. All of computations are handled via codes in MATLAB 7 on a Pentium IV PC, 2.4GHz of CPU, and 256 MB of RAM. Tables 1–5provide input data of the smallest test data with K=4, m=3 and T=3. Tables 1–3 provide setup time and cost of parts (stj,k,h, scj,k,h) on machines j=1, 2, and 3, for test data K=4, m=3 and T=3. Fig. 9shows the precedence diagrams of the four item types of this test data.Without loss of generality, in this example, we have run the algorithm for when there is an approximate linear relationship between unit process time and unit process cost on machine j such as fcj−csj×pj, wherepjmin≤pj≤pjmax. In this way, Table 4 provides the needed data for test data K=4, m=3 and T=3.Table 6and Figs. 10–12demonstrate the best solution obtained by PSO for test data K=4, m=3 and T=3. One can see in Figs. 10–12 that periodical sequences are the same, but the schedules and production volumes are different. Also, as Table 8 confirms, this solution is the same as the global optimal solution obtained by Lingo 11.0.For further performance analysis of the proposed PSO, a number of random test data are generated in different values of K, m and T according to Table 7.Then, Table 8reports the optimality gap (in percent) and CPU time of the PSO for each test data after ruing PSO for 5 times on each test data. Obviously, Table 8 shows that the proposed PSO has an acceptable performance in solving different sizes with low worst case optimality gap but in very shorter CPU times than Lingo 11.0. In more details, CPU time of both PSO and Lingo grows larger as the problem size increases, but PSO does it in a steady manner and Lingo in exponential order of magnitudes. Also, the worst case optimality gap of the proposed PSO is below 5.01% for the largest test data. One important point in working with most solvers such as Lingo is their ability to accelerate search speed while getting a good initial solution as input data. In this way, for some of large size instances we used the best obtained solution of PSO as initial solution to Lingo 11.0. Although, the CPU time of Lingo is greater than 100h for such cases, Lingo will not terminate in a bounded time if we do not feed an initial solution. For greater sizes we were unable to obtain true global optimum solution from the solver in order to measure the performance of the proposed algorithm. In other words, larger sizes need very much further CPU time than 100h by the solver. Also, we just wanted to show the performance of the algorithm for the similar large sizes in the current literature (see e.g. Pochet and Wolsey [17], Zhu and Wilhelm [22]). In the largest size, we have considered 6 item types, 5 machines, and 18 planning periods. However, many believes that lot sizing and scheduling decisions should updated every 6–12 periods, which is less than our 18 period problem.This paper formulated a realistic production scheduling problem and also provided an efficient algorithm for solving it. The model is more comprehensive than previous texts in the fields for considering different aspects of a frequent problem in everyday of a production manager. For example, the followings were simultaneously identified as decision variables in an integrated manner in the model:-sequence of processes on different item types over every machine,sequence of processes of a given item type over the corresponding machines according to predefined precedence relations,batch size of different item types over planning periods,working speed/mode of each machine for processing on different item types.However, solving the model with commercial solvers is not so beneficial for exponentially growing CPU times. This motivated us to propose an efficient algorithm. The proposed algorithm is self-adaptive and has the ability to decide about itself. In other words, the algorithm is able to check the progress trend in the solution space in order to update its working parameters. This feature provided a stable and efficient algorithm with the least need to change in its initial working parameters by the change in problem data. As the problem is proved to be NP-hard, other heuristics can be developed for obtaining much better solutions. Furthermore, the problem can be solved by decomposition methods by determining process times and solving the remaining integer linear programming model by solvers easily. Hence, we believe that efficient decomposition techniques can be developed. The current study can be extended to consider other types of production environments such as parallel machines, flow shops, and open shops. Also, it seems interesting to try linearizing the model in order to solve large-size instances of the problem directly with the aid of mathematical formulation.

@&#CONCLUSIONS@&#
