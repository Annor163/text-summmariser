@&#MAIN-TITLE@&#
Ambiguity in risk preferences in robust stochastic optimization

@&#HIGHLIGHTS@&#
Uncertainty in risk preferences and the underlying probability distribution is modeled.A duality theory is derived where random utility functions appear as the Lagrange multipliers.The optimal solution is computed exactly with convex optimization in a special case.In the general case, tractable convex relaxations of our model are obtained.Numerical experiments are conducted for the newsvendor and portfolio optimization problem to analyze the implications of our model.

@&#KEYPHRASES@&#
Stochastic dominance,Robust optimization,Expected utility maximization,

@&#ABSTRACT@&#
We consider robust stochastic optimization problems for risk-averse decision makers, where there is ambiguity about both the decision maker’s risk preferences and the underlying probability distribution. We propose and analyze a robust optimization problem that accounts for both types of ambiguity. First, we derive a duality theory for this problem class and identify random utility functions as the Lagrange multipliers. Second, we turn to the computational aspects of this problem. We show how to evaluate our robust optimization problem exactly in some special cases, and then we consider some tractable relaxations for the general case. Finally, we apply our model to both the newsvendor and portfolio optimization problems and discuss its implications.

@&#INTRODUCTION@&#
We face two sources of ambiguity in real-world stochastic optimization problems. First, there is ambiguity about the risk preferences of the decision maker. A risk-averse decision maker can express his risk preferences by specifying an increasing and concave utility function. However, it is extremely difficult to specify an optimal utility function in practice. We thus consider the utility function in play to be part of the overall model ambiguity. Second, there is ambiguity about the true underlying probability distribution. This distribution is typically only partially known through historical data or the beliefs of the decision maker. In this paper we combine these two sources of ambiguity to focus on risk-aversion in robust stochastic optimization.Our present paper lies at the intersection between two major streams of research: (i) ambiguity in risk preferences and (ii) robust stochastic optimization. The issue of ambiguity in risk preferences has been thoroughly explored in the stochastic dominance literature. In parallel, there is a large body of work on stochastic optimization with statistical ambiguity. We mention minimax stochastic programming as considered in (Dupačová, 2011; Žáčková, 1966) as a representative example.In practical expected utility maximization, there is considerable ambiguity in the choice of the utility function. There is no obvious choice for the “best” utility function for a single decision maker, and the situation is even more confusing for a group of decision makers trying to agree on a utility function. This concept is closely related to the ideas of stochastic dominance and integral stochastic orders (see Muller & Stoyan, 2002; Shaked & Shanthikumar, 2007) which model behavior through a continuum of utility functions. For instance, the increasing concave stochastic order is defined in terms of all increasing concave functions and corresponds to the class of risk-averse decision makers. This stochastic order is used to define dominance constraints in optimization in (Dentcheva & Ruszczyński, 2003; 2004) for the univariate case. Extensions to the multivariate case are developed in (Dentcheva & Ruszczyński, 2008; 2009; Haskell, Shen, & Shanthikumar, 2013; Hu, Homem-de Mello, & Mehrotra, 2012; Homem-de Mello & Mehrotra, 2009). As an alternative to stochastic dominance constraints, various minimax expected utility formulations have been devised by Armbruster and Delage (2011); Hu and Mehrotra (2012), and Hu and Mehortra (2012). The formulation in Armbruster and Delage (2011) leads to linear programming problems for finite probability spaces when the relaxation of increasing concave stochastic dominance is appropriately chosen.Robust stochastic optimization was originally developed for decision makers facing statistical ambiguity. Conic programming is used to efficiently solve a worst-case value-at-risk portfolio optimization problem in (Ghaoui, Oks, & Oustry, 2003). We also mention robust chance constraints (Calafiore & Ghaoui, 2006) and (Branda & Dupačová, 2012). Two-stage stochastic linear programming with risk aversion and uncertainty about the underlying probability model is developed in (Bertsimas, Doan, Natarajan, & Teo, 2010). A new notion of robust stochastic optimization is presented in (Ben-Tal, Bertsimas, & Brown, 2010) which allows the decision maker to vary the protection level over the uncertainty set. This approach is shown to be closely connected to convex risk measures. We refer to (Chen, Sim, Sun, & Teo, 2010), (Natarajan, Sim, & Uichanco, 2010), (Chen, He, & Zhang, 2011), (Li & Kwon, 2012), (Dupačová & Kopa, 2012), (Calafiore, 2007), (See & Sim, 2010), and (Natarajan, Pachamanova, & Sim, 2009) for more on robust stochastic optimization with known explicit risk preferences. Robust risk measures are developed in (Fertis, Baes, & Lüthi, 2012) which consider the worst-case risk over a family of probability distributions. Models and algorithms for robust multi-objective optimization are developed in (Ehrgott, Ide, & Schöbel, 2014; Matos, 2007), and Fliege and Werner (2014). For more information, a recent survey on robust optimization can be found in (Gabrel, Murat, & Thiele, 2014).We see that there has been significant work on both ambiguity in risk preferences and robust stochastic optimization, but so far these two problems have been treated separately. We want to combine these two developments into a single robust optimization problem. In addition to handling statistical uncertainty, we would like to express ambiguity about our risk-preferences. Dentcheva and Ruszczyński (2010) is the most closely related paper to our present objective. In (Dentcheva & Ruszczyński, 2010), robust stochastic dominance constraints are proposed and analyzed. Arguably, the optimization problem in (Dentcheva & Ruszczyński, 2010) accounts for both ambiguity in the probability model and utility function in play: it requires stochastic dominance to hold over a range of probability distributions, and stochastic dominance itself is a comparison over a range of utility functions. However, the model in (Dentcheva & Ruszczyński, 2010) is a constrained optimization problem. It is difficult to ensure that an instance of this class of problems will be feasible even in the univariate case, no solution algorithm is provided, and no applications are developed.We make three main contributions with this paper. First, we propose an attractive class of robust optimization problems to simultaneously address these two major types of ambiguity in stochastic optimization. This problem class is convex and cleanly accounts for both types of model ambiguity. Second, to address practical considerations, we build tractable convex approximations for our notion of regret. In a special case, we show how to solve our model exactly. Finally, we develop newsvendor and portfolio optimization applications and discuss their managerial implications. In particular, we show that our model is a good balance between the conservatism of purely robust optimization and the optimism of risk-neutral decision making.The paper is organized as follows. In Section 2 we develop our methodological framework for the problem of ambiguity in both risk preferences and the underlying probability distribution. We review preliminary material on comparing two random variables under uncertainty. Then, we present our main optimization problem which accounts for model ambiguity in both the underlying probability distribution and the decision maker’s risk preferences. We conclude this section be deriving the dual problem and showing that random utility functions come into play. In Section 3 we turn to the practical aspects of this problem and develop a computational recipe, including tractable approximations. Then, in Section 4 we apply our methodology to the newsvendor and portfolio optimization problems. The paper concludes in Section 5 with a discussion of impact and future research directions.This section first introduces our model for ambiguity and then develops the corresponding robust optimization problem. Let(Ω,A)be a measure space where Ω is a sample space andAis aσ−algebra on Ω. We letLbe the linear space of allA−measurable mappingsX:Ω→Rnfor n ≥ 1, and we letL⊂Lbe a particular admissible space of mappings. LetYbe the space of signed finite measures on(Ω,A),in the total variation norm:∥ν∥M(Ω)≜∫Ωd|ν|.Also letP≜{ν∈Y:∥ν∥M(Ω)=1,ν≥0}⊂Ybe the set of probability distributions on Ω, where ν ≥ 0 is understood to mean ν(A) ≥ 0 for allA∈A. Corresponding toL,we define the dual spaceY⊂Ysuch that ∫Ω|X|(ω)|ν|(dω) for allX∈L. Eachν∈Ydefines a linear functional onLgiven by:〈ν,X〉=∫ΩX(ω)ν(dω),∀X∈L.Whenμ∈P,then ⟨ν, X⟩ is an expectation.The structural uncertainty set reflects ambiguity about the risk preferences of the decision maker. We can only imperfectly elicit the decision maker’s risk preferences. Throughout, we focus on reward maximization so larger values of X are always preferred. Suppose that we have two mappingsX,Y∈Lthat we wish to compare. For simplicity we assume that X(ω), Y(ω) ∈ W for all ω ∈ Ω for some compact set W. For a fixed probability distributionν∈P,X and Y become random variables on the probability space(Ω,A,ν). LetC(W)be the space of continuous functions from W toRin the supremum norm, and letU≜{u∈C(W):uisincreasingandconcave}⊂C(W)be the set of all continuous, increasing, and concave functions on W. A risk-aware decision maker draws his utility function fromU. For a fixed probability distributionν∈Pand a fixed utility functionu∈U,we write expectation of u(X) with respect to aP∈PasEν[u(X)]=〈ν,u(X)〉≡∫Ωu([X](ω))ν(dω).We letU⊂Udenote the structural uncertainty set that contains a range of utility functions that describe the decision maker’s risk preferences. To continue, we become more specific about the uncertainty setUfor the remainder of this paper. We base our choice ofUon (Armbruster & Delage, 2011), the characteristics ofu∈Uare summarized as follows:•u(0)=0. We can translateUby a positive constant sinceE[u(G(z))−u(Y)]=E[(u+a)(G(z))−(u+a)(Y)]for anya∈R.E[u(X0)−u(Y0)]=1for random variables X0 and Y0. The equality constraintE[u(X0)−u(Y0)]=1prevents u with arbitrarily large magnitude from appearing inU,and it also excludes the zero function.E[u(Xi)]≥E[u(Yi)]for pairs of random variables (Xi, Yi) indexed by i ∈ I. One can imagine presenting the decision maker with a series of pairs of random variables {(Xi, Yi)}i ∈ I, and the decision maker selects one from each pair over the other. For clarity, we do not construct X0, Y0 and Xi, Yifor all i ∈ I on Ω, rather, we assume they are constructed directly onR,and that their distributions are known.The statistical ambiguity consists of a setQ⊂Pthat contains the true underlying probability distribution. We haveQbecause the true underlying distribution is only imperfectly known through historical data and statistical estimation.We now present the ingredients for our optimization problem. For a set of admissible decisionsZ⊂Rm,we define the mappingG:Z→Lwhere n ≥ 1. Notice that we allow G(z) to be vector-valued, our development in this paper applies to the univariaten=1and multivariate n ≥ 2 settings simultaneously without any special consideration. We let G(z, ω) denote the realization of G(z) on event ω ∈ Ω. The following assumptions about problem data hold throughout the paper.A1Z⊂Rmis convex and closed.A2G is continuous inL,and G(z, ω) is concave in z ∈ Z for all ω ∈ Ω (in the vector-valued sense).We also make a boundedness assumption on G for technical convenience.A3 There is a compact setW⊂Rnsuch that G(z, ω) ∈ W for all (z, ω) ∈ Z × Ω.The classical robust problem is(1)maxz∈Zinf(u,ν)∈U×QEν[u(G(z))],which maximizes the worst-case expected utility over all models inUandQ. However, Problem (1) is overly pessimistic.We now propose a more flexible model to remedy the pessimism of Problem (1). First, we fix a benchmark random variableY∈Lwhich reflects a desirable performance level. Then, we consider(2)maxz∈Zψ(G(z))≜inf(u,ν)∈U×QEν[u(G(z))−u(Y)],which maximizes the worst-case shortfall in expected utility relative to Y. WhenQ={ν}is a singleton, then Problem (2) considers ambiguity in u only. This formulation has appeared in the stochastic dominance literature in (Armbruster & Delage, 2011). WhenU={u}is a singleton then Problem (2) considers ambiguity in ν only. This formulation is the classical robust optimization formulation. WhenUandQare both finite and small, then Problem (2) can be solved directly with standard convex optimization techniques without any special consideration. Cut generation for Problem (2) is captured by(3)inf(u,ν)∈U×QEν[u(G(z))−u(Y)].We see that Problem (3) is a nonconvex optimization problem because of its objective even whenUandQare both convex. The following properties are immediate.Proposition 2.1(i)ψ is monotonic.ψ is concave.Fix z ∈ Z. The objective of Problem(3),(u,ν)→Eν[u(G(z))−u(Y)],is bilinear in (u, ν).(i)EachX→EP[u(X)]is monotonic, and the infimum of monotonic functions is monotonic.Choose z1, z2 ∈ Z and 0 ≤ λ ≤ 1, thenψ(G(λz1+(1−λ)z2))≤inf(u,ν)∈U×QEν[u(λG(z1)+(1−λ)G(z2))−u(Y)]≤inf(u,ν)∈U×QEν[λu(G(z1))+(1−λ)u(G(z2))−u(Y)]≤λinf(u,ν)∈U×QEν[u(G(z1))−u(Y)]+(1−λ)inf(u,ν)∈U×PEν[u(G(z2))−u(Y)].Notice that(u,ν)→Eν[u(G(z))−u(Y)]is bilinear. For fixedν∈P,u1,u2∈U,andα1,α2∈R,we haveEν[[α1u1+α2u2](G(z))−[α1u1+α2u2](Y)]=α1Eν[u1(G(z))−u1(Y)]+α2Eν[u2(G(z))−u2(Y)],by linearity of the integral. Similarly, for fixedu∈U,ν1,ν2∈P,andα1,α2∈R,we haveE[α1ν1+α2ν2][u(G(z))−u(Y)]=α1Eν1[u(G(z))−u(Y)]+α2Eν2[u(G(z))−u(Y)],by linearity of measures inM(Ω).□To complement Problem (2), we define the new benchmarkϑ(u,ν)≜maxz∈ZEν[u(G(z))],∀(u,ν)∈U×Q,and introduce the regret minimization problem(4)maxz∈Zρ(z)≜inf(u,ν)∈U×Q{Eν[u(G(z))]−ϑ(u,ν)}.Problem (4) does not require a user-defined benchmark Y, rather, it uses the problem data directly. We similarly see that Problem (4) is a convex optimization problem.We briefly comment on some alternative robust formulations that fall within our framework. SupposeEν[u(Y)]≥κ>0for all(u,ν)∈U×Qso that the following objective is well-defined. The problem(5)maxz∈Zinf(u,ν)∈U×QEν[u(G(z))]/Eν[u(Y)]maximizes the worst-case relative shortfall in expected utility relative to Y. We can rewrite Problem (5) asmaxz∈Z,s∈R{s:Eν[u(G(z))]≥Eν[u(Y)]s,∀(u,ν)∈U×Q}to reveal that it is a convex optimization problem. Similarly, we can define(6)maxz∈Zinf(u,ν)∈U×QEν[u(G(z))]/ϑ(u,ν),which maximizes the worst-case relative regret.For a concave objective functionf:Z→R,we can propose the constrained problem(7)supz∈Z{f(z):ψ(G(z))≥0}.Problem (7) is a convex optimization problem under our standing assumptions. This concept is closely related to the notion of robust stochastic dominance:(8)Eν[u(G(z))]≥Eν[u(Y)],∀(u,ν)∈U×Q,developed in (Dentcheva & Ruszczyński, 2010) for the univariate case. Robust stochastic dominance combines the usual notion of stochastic dominance with robustness against ambiguity in the underlying probability distribution. WhenQis a singleton then condition (8) is equivalent to the usual notion of stochastic dominance.We develop a duality theory for Problem (2) in this subsection. In previous work on stochastic dominance constrained optimization (Dentcheva & Ruszczyński, 2003; 2004; Haskell et al., 2013), utility functions emerged as the Lagrange multipliers of stochastic dominance constraints. We will see that utility functions play a role in duality for our Problem (2) as well, though the presence of the statistical uncertainty set Q introduces novelty.We assume thatU={uξ∈U:ξ∈Ξ}is parametrized throughout this subsection. We introduce some additional assumptions for the remainder of this paper.A4Ξ is compact.A5uξ(w) is continuous in ξ for all w ∈ W.A6Ω is finite.For example, in (Dentcheva & Ruszczyński, 2010), where G(z) is a univariate random variable,Uis the collection{min{x−η,0}:η∈[a,b]}of piecewise linear functions parametrized by η. This choice is based on the fact that the preceding family is a “generator” of the increasing concave stochastic order (see Muller & Stoyan, 2002). From now on, we also assume that Ω is finite. We will write ν({ω}) as a lower case pωfor all ω ∈ Ω to emphasize that the probability measure is finite-dimensional. We letPdenote the corresponding set of statistical ambiguity which corresponds to a set inR|Ω|.In this setting, Problem (2) becomes(9)maxz∈Zmin(ξ,p)∈Ξ×P{∑ω∈Ωpω(uξ(G(z,ω))−uξ(Y(ω)))},where we see that the inner minimization problem now has finitely many variables and a bilinear objective. Problem (9) continues to be a convex optimization problem.To proceed with a duality theory, we first rewrite Problem (2) as the constrained optimization problem(10)maxz∈Z,s∈R{s:∑ω∈Ωpωuξ(G(z,ω))−∑ω∈Ωpωuξ(Y(ω))≥s,∀(ξ,p)∈Ξ×P}by introducing an auxiliary variables∈R. Problem (10) is equivalent to Problem (9) in the sense that both problems have the same optimal value and an optimal solution of one can be recovered from the other.The constraints in Problem (10) cause Lagrange multipliers to appear. To identify the correct space for the Lagrange multipliers, define the mapping on the parameters[h(z)](ξ,p)=∑ω∈Ωpωuξ(G(z,ω))−∑ω∈Ωpωuξ(Y(ω)),∀(ξ,p)∈Ξ×P.We establish continuity of this mapping in the next lemma. LetC(Ξ×P)be the space of continuous functions onΞ×Pin the supremum norm, and letC+(Ξ×P)be the cone of nonnegative functions inC(Ξ×P).Lemma 2.2h:Z→C(Ξ×P).Fix z ∈ Z, then we see that [h(z)](ξ, p) is continuous in (ξ, p) since it is the sum of the continuous functions ∑ω ∈ Ωpωuξ(G(z, ω)) and ∑ω ∈ Ωpωuξ(Y(ω)).□Based on continuity of h, the constraint in Problem (10) is equivalent to the conic constrainth(z)∈C+(Ξ×P).Both Ξ andPare compact Euclidean sets by assumption, so we identifyM(Ξ×P),the space of finite signed measures onΞ×P,as the dual space toC(Ξ×P). We also defineM+(Ξ×P)to be the space of nonnegative measures onΞ×P. The Lagrangian for Problem (10) isL(z,s,Λ)=s+∫Ξ×P([h(z)](ξ,p)−s)Λ(d(ξ,p))whereΛ∈M(Ξ×P). The next theorem computes the dual to Problem (10). The feasible region in the upcoming dual problem will have a special interpretation.Theorem 2.3(i)The dual to Problem(10)is(11)min{d(Λ)≜maxz∈Z∫Ξ×P[h(z)](ξ,p)Λ(d(ξ,p)):Λ(Ξ×P)=1,Λ≥0}.Strong duality holds between Problem(10)and Problem(11), i.e. they have the same optimal value.(i)Problem (10) is equivalent tomaxz∈Z,s∈RminΛ∈M+(Ξ×P)L(z,s,Λ),and interchanging max and min gives the dual problemminΛ∈M+(Ξ×P)maxz∈Z,s∈RL(z,s,Λ).The inner maximization above is explicitlymaxz∈Z,s∈R{s+∫Ξ×P([h(z)](ξ,p)−s)Λ(d(ξ,p))}=maxz∈Z{∫Ξ×P[h(z)](ξ,p)Λ(d(ξ,p))}+maxs∈R{s(1−∫Ξ×PΛ(d(ξ,p)))},and the second term is equal to infinity unless∫Ξ×PΛ(d(ξ,p))=1.It is automatic that Problem (10) satisfies the Slater constraint qualification sinces∈Ris unrestricted. In particular, for anyz^∈Z,we can simply chooses^<ψ(G(z^))to get a Slater point.□The preceding theorem reveals that the dual variables in Problem (11) are probability distributions overΞ×P. In the next theorem, we show how to interpret the dual variables for Problem (11) as random utility functions.Theorem 2.4SupposeΛ∈M+(Ξ×P)with∫Ξ×PΛ(d(ξ,p))=1,then:(i)There exists a probability distributionΛ^∈M+(P)with∫PΛ^(dp)=1and a stochastic kernel ϕ( · | p) fromPto Ξ such that∫Ξ×P[h(z)](ξ,p)Λ(d(ξ,p))=∫P∫Ξ[h(z)](ξ,p)ϕ(dξ|p)Λ^(dp).Forp∈P,∫Ξ[h(z)](ξ,p)ϕ(dξ|p)=[h(z)](ξ*,p)=Eν[u^p(G(z))−u^p(Y)],whereν({ω})=pωfor all ω ∈ Ω andu^p(w)=∫Ξuξ(w)ϕ(dξ|p).It follows that∫Ξ×P[h(z)](ξ,p)Λ(d(ξ,p))=∫PEP[u^p(G(z))−u^p(Y)]Λ^(dp).(i)For any such fixed Λ, we view(Ξ×P,B(Ξ×P),Λ)as a probability space, and[h(z)](ξ,p):Ξ×P→Ras a random variable on this probability space. We can then disintegrate the measure Λ into the marginalΛ^onPdefined byΛ^(B)=∫I{u∈B}Λ(d(ξ,p)),∀B∈B(P),and the stochastic kernel ϕ(· | p) which depends on p (see (Pollard, 2002, Appendix F, Theorem 1)).For fixedp∈P,we have∫Ξ[h(z)](ξ,p)ϕ(dv|p)=∫Ξ∑ω∈Ωpω[uξ(G(z,ω))−uξ(Y(ω))]ϕ(dξ|p)=∑ω∈Ωpω∫Ξ[uξ(G(z,ω))−uξ(Y(ω))]ϕ(dξ|p),by interchanging the order of integration and summation. We recover the concave functionw → ∫Ξuξ(w)ϕ(dξ | p) citing the fact that ϕ is a transition kernel, and the nonnegative sum of increasing and concave functions is increasing and concave.Follows by substituting part (ii) into part (i).□We can now see that the expression∫Ξ×P[h(z)](ξ,p)Λ(d(ξ,p))is an expectation over expected utilities via∫PEp[u^p(G(z))−u^p(Y)]Λ^(dp),where the inner utility function depends onp∈P. This result parallels (Dentcheva & Ruszczyński, 2003; 2004; Haskell et al., 2013) where utility functions are shown to be the dual variables for stochastic dominance constraints.We turn to computational considerations in this section. In general, the cut generation for Problem (2) is a bilinear programming problem. However, we show how to solve Problem (2) directly in a special case. Then, we consider some tractable approximations for Problem (2) in the general case.We continue to use the parametrized setsUandPto discuss the issue of computation. The standard cut generation algorithm is as follows. For a finite set{(ξi,pi)}i∈I⊂Ξ×P,we solvemaxz∈Zmin{(ξi,pi)}i∈I{∑ω∈Ωpω[uξ(G(z,ω))−uξ(Y(ω))]}to obtain a candidate solution z* ∈ Z. Problem (3) can now be written cleanly (for fixed z ∈ Z) as(12)min(ξ,p)∈Ξ×P{∑ω∈Ωpω(uξ(G(z,ω))−uξ(Y(ω)))}.Then, we check ifmin{(ξi,pi)}i∈I{∑ω∈Ωpω[uξ(G(z,ω))−uξ(Y(ω))]}≤ψ(G(z*))by exactly evaluating the optimization problem corresponding to ψ(G(z*)). If the preceding inequality is violated, then we add the optimal solution(ξ*,p*)∈Ξ×Pof Problem (12) to {(ξi, pi)}i ∈ Iand repeat the procedure. Otherwise, we have an optimal solution of Problem (9). It is known that procedures of this type converge for semi-infinite programming problems, see (Hettich and Kortanek, 1993, Theorem 7.2)for example. The bottleneck here is the need for repeated calls to a bilinear programming problem which is generally difficult to solve. We offer later offer two tractable relaxations of Problem (9) that address this difficulty.We use Pr(·) to denote the distribution of Y and{Xi,Yi}i=0r. We can now further character the structural uncertainty setUasU={u∈U,∑θ∈ΘPr{X0=θ}u(θ)−∑θ∈ΘPr{Y0=θ}u(θ)=1,∑θ∈ΘPr{Xi=θ}u(θ)≤∑θ∈ΘPr{Yi=θ}u(θ),∀i∈I}.We defineΘ=supp(Y)∪{⋃i=0r{supp(Xi)∪supp(Yi)}}⊂Wto be the union of the support of the benchmark Y and the random variables {Xi, Yi}i ∈ Iused in the definition ofU. We make a key assumption about Θ.A7Θ is finite.This assumption is not unreasonable since the preceding random variables are all user input. At first glance this representation does not offer any computational advantages. However, for the purposes of solving Problem (3), we can characterize the relevant functions inUwith finitely many parameters using the method from (Boyd and Vandenberghe, 2009; Armbruster and Delage, 2011; Haskell et al., 2013, Section 6.5.5) which specifies convex functions in terms of their subgradients.In abstract notation, we can specify the parametrizationU={uξ:ξ∈Ξ}and write Problem (9) as:maxz∈Zinf(ξ,p)∈Ξ×P{〈p,G(z)ξ〉:Aξ=b,ξ≥0},whereG(z)is an appropriate matrix-valued mapping, p represents the statistical uncertainty, and x represents the structural uncertainty. Takeξ=(α,β,δ,γ,u)and set〈p,G(z)ξ〉=∑ω∈Ωpω[〈αω,G(z,ω)〉+βω−u(Y(ω))],which is linear in x for fixed z ∈ Z andp∈P. The linear system{Aξ=b,ξ≥0}for the structural uncertainty can then be written as:(13)〈αω,θ〉+βω≥u(θ),∀ω∈Ω,θ∈Θ,(14)〈δθ,θ′〉+γθ≥u(θ),∀θ,θ′∈Θ,(15)〈δθ,θ〉+γθ=u(θ),∀θ∈Θ,(16)u(0)=0,(17)∑θ∈Θ[Pr({X0=θ})−Pr({Y0=θ})]u(θ)=1,(18)∑θ∈Θ[Pr({Xi=θ})−Pr({Yi=θ})]u(θ)≥0,∀i∈I,(19)α,δ≥0.To explain, we are specifying the value of a utility function at all θ ∈ Θ, {u(θ)}θ ∈ Θ, and we are specifying two sets of linear functions determined by (α, β) and (δ, γ) in slope intercept form. Condition (13) simply defines the value of the linear function at θ, conditions (14) and (15) are necessary and sufficient conditions for u(θ) to be the values of a concave function (i.e. the subgradient characterization), conditions (17) and (18) restate the refined preference information, and condition (19) requires all linear functions here to be increasing. In particular, we see that constraints (13)–(19) can be written compactly as a linear system Aξ ≥ b.The next theorem identifies a special case where it is possible to solve Problem (9) with a single convex optimization problem. In particular, whenPcan be characterized in terms of its extreme points we can solve Problem (9) in one step.Theorem 3.1SupposeP=conv{νj}j∈J.(i)For fixed z ∈ Z,inf(ξ,p)∈Ξ×PEν[uξ(G(z))−uξ(Y)]=infj∈Jinfu∈UEνj[uξ(G(z))−uξ(Y)].Problem(2)is equivalent to(20)maxs(21)s.t.〈b,wj〉≥s,∀j∈J,(22)pjTG(z)≥wjTA,∀j∈J.(i)First observeinf(ξ,p)∈Ξ×PEν[uξ(G(z))−uξ(Y)]=infξ∈Ξinfp∈PEν[uξ(G(z))−uξ(Y)].The functionEν[u(G(z))−u(Y)]is linear in ν for fixedu∈U,andν→infu∈UEν[u(G(z))−u(Y)]is concave in ν as the infimum of linear functions. By (Rockafellar, 1970, Corollary 32.3.4),infp∈Pinfξ∈ΞEνi[uξ(G(z))−uξ(Y)]=infi∈Iinfξ∈ΞEνi[uξ(G(z))−uξ(Y)],since a concave minimization problem over a polyhedron attains its optimum at one the extreme points, and {νj}j ∈ Jare the extreme points ofP.By part (i), Problem (9) is equivalent tomaxz∈Zinfi∈Iinfξ∈Ξ∑ω∈Ωpω[〈αω,G(z,ω)〉+βω−u(Y(ω))],which can be rewritten asmaxz∈Z{s:s≤infξ∈Ξ∑ω∈Ωpj(ω)[〈αω,G(z,ω)〉+βω−u(Y(ω))],∀j∈J}.As shown in Haskell et al. (2014), for each j ∈ J the probleminfu∈UEPi[u(G(z))−u(Y)]is equal to the optimal value of the following linear programming problem. For anyp∈P,we haveinfξ∈Rn{〈p,G(z)ξ〉:Aξ=b,ξ≥0}=supw∈Rq{〈b,w〉:wTA≤pTG(z)}by linear programming duality. We use this observation to get the desired result.□We see that Problem (20)–(22) is a convex optimization problem in z ∈ Z, since the constraintspjTG(z)≥wjTAare all convex by concavity of G and nonnegativity of p. Problem (20)–(22) can be solved directly with standard convex optimization algorithms.The scale of Problem (20)–(22) grows quickly as the number of extreme points ofPgrows, and we cannot claim that this method is practical for arbitraryP. In full generality we have to treat the inner problem as a bilinear programming problem and use a cut generation algorithm to solve Problem (9).In the last subsection we saw that Problem (2) can be solved with convex optimization in a special case, but that this approach is not scalable when the statistical uncertainty setPis complicated. The main difficulty lies with the inner minimization of Problem (2), which is a nonconvex optimization problem. In this subsection we revise this inner minimization problem to make it convex and obtain a more tractable variant of Problem (2). The resulting approximations give us lower bounds for Problem (2).The difficulty lies with the bilinear terms in∑ω∈Ωpω[〈αω,G(z,ω)〉+βω−u(Y(ω))]so we must replace the vectors pωαω, the terms pωβω, and pωu(Y(ω)), for all ω ∈ Ω. There are two main approximation schemes for such constraints in the literature: the reformulation-linearization technique (RLT) and the semidefinite programming (SDP) relaxation, see Anstreicher (2009). We consider each of these techniques and show how they lead to tractable reformulations of our original Problem (2).We begin with the RLT reformulation and the following problem(23)maxz∈Zυ(G(z))≜inf(v,p)∈V×P{〈p,GRLT(z)v〉:Cv=d,v≥0},whereGRLT(z)is an appropriately defined matrix-valued mapping. We can compute the dual of the inner minimization problem to obtain a single maximization problem. The resulting maximization problem turns out to be a convex optimization problem.Theorem 3.2(i)ψlon(G(z)) ≤ ψ(G(z)) for all z ∈ Z.Problem(23)can be written asmaxz∈Z,y{〈d,y〉:yTC≥GRLT(z)},which is a convex optimization problem.The SDP relaxation looks like(24)maxz∈Zϕ(G(z))≜inf(w,p)∈W×P×{tr(GSDP(z)X):tr(AiX)=bi,∀i∈I,X⪰0},whereGSDP(z)is an appropriately defined matrix-valued mapping. We also use abstract notation in the following theorem to avoid cumbersome details.Theorem 3.31.ϕ(G(z)) ≤ ψ(G(z)) for all z ∈ Z.Problem(24)is equivalent to:supz∈Z,λ{∑i∈Iλibi:GSDP(z)⪰∑i∈IλiAi},which is a convex optimization problem whenz→GSDP(z)is concave with respect to the semidefinite ordering.The Lagrangian of the problem corresponding to ϕ(G(z)) isL(X,λ)=tr(GSDP(z)X)+∑i∈Iλi(bi−tr(AiX))=∑i∈Iλibi+tr((GSDP(z)−∑i∈IλiAi)X),and the dual functional isd(λ)={∑i∈IλibiGSDP(z)⪰∑i∈IλiAi,−∞otherwise.The corresponding dual problem is thenϕ(G(z))=supλ{∑i∈Iλibi:GSDP(z)⪰∑i∈IλiAi}.□We develop detailed examples of our method for the classic newsvendor and portfolio optimization problems in this section.We first consider the classical newsvendor. We report numerical experiments that demonstrate the importance of simultaneously considering ambiguity in risk preferences and ambiguity in the underlying probability distribution. Risk-aware variants of the newsvendor have been extensively studied. A risk-averse expected utility maximizing newsvendor is developed in (Keren & Pliskin, 2006) for uniformly distributed demand, and a closed form optimal solution is computed. Alternatively, Ahmed, Çakmak, and Shapiro (2007) considers a coherent risk measure for the classical newsvendor. The conditional value-at-risk minimizing newsvendor is studied in detail in Gotoh and Takano (2007) and solved with linear programming. In Zhang, Xu, and Wu (2009), a variant of the classical newsvendor with risk constraints is proposed and analyzed. The variations of multiplicative risk and random capacity are studied in (Sévi, 2010) and (Wu, Zhu, & Teunter, 2013), respectively.The newsvendor chooses an order quantity q ≥ 0 before seeing the random demandD:Ω→Rfor a single good. Let r be the unit revenue and c be the unit order cost, then the random profit isG(q,D)=rmin{q,D}−cq.Now letu^andν^be the exact newsvendor’s utility function and distribution of demand. Even though the newsvendor cannot observeu^andν^,he has uncertainty setsUandQsuch thatu^∈U,ν^∈Q. For our experiments, we consider the regret minimization problem(25)maxq≥0min(u,ν)∈U×QEP[u(G(q,D))]−ϑ(u,ν),which we compare with the pure robust problem(26)maxq≥0min(u,ν)∈U×QEν[u(G(q,D))],and the classical risk-neutral model(27)maxq≥0Eν[G(q,D)].We will compare the expectationEP[G(q,D)]and the variancevar(G(q,D))≜EP[(G(q,D)−EP[G(q,D)])2]across their different optimal solutions q when ν is taken to be the true model.For simplicity in our first experiment, we setΩ={ω1,ω2}andQ={P1,P2}. Detailed parameter settings are as follows:•There are two demand scenarios,dL=D(ω1)=5“low demand” anddH=D(ω2)=10“high demand”;U={u1,u2}andQ={P1,P2}. We chooseu1(x)=3x1/3,u2(x)=−2e−x/10+1(parameters for u2 are chosen in order to make it comparable to u1),P1(ω1)=0.1,andP2(ω1)=0.7;P^=P1is the true model.The results of this first experiment are reported in Fig. 1. Fig. 1a shows how the expected profit changes as the price/cost ratio increases. The variance and the optimal order quantity for each method are also shown as functions of the price/cost ratio in 1 b and 1 c respectively.We now try a more general experiment with the following parameters:•U={u1,u2}whereu1(x)=3x1/3andu2(x)=−2e−x/10+1;Ω={ω1,ω2,…,ω10},Q={P1,P2,…,P5},andP^=P1;D(ωi)=10*i,i=1,2,…,10.Detailed distributional information is given in Table 1, and the results appear in Fig. 2.From Figs. 1 and 2, we can see that our regret minimization problem (25) finds a solution that balances expected profit against variance. The classical expectation maximization problem (27) achieves the best performance in terms of maximizing expectation by being overly optimistic in its order quantity, as shown in Figs. 1c and 3c, but it also gives the highest variance. In actuality, the performance of the expectation maximization problem (27) will be worse because we have assumed it has access to the true distributionP^to run these experiments. On the other hand, the robust optimization problem (26) makes conservative decisions by ordering the least amount, achieving the smallest variance but also the lowest expected profit.As the price/cost ratio increases, the difference between Problem (27) and Problem (26) becomes more pronounced. Since Problem (26) optimizes against the worst-case scenario, the order quantity and the variance do not change much, while the expected profit increases. For Problem (27), the order quantity is very sensitive to the price/cost ratio. Both the expectation and the variance increase dramatically as this ratio increases. Our regret minimizing model (25) behaves similarly to (27), but with a smaller decrease in expected profit and a significant improvement in terms of the variance.We also note that our regret minimizing model provides a smooth transition for the order quantity as the price/cost ratio increases. Due to our assumption of finite Ω, the optimal order quantity for Problem (27) is piecewise constant. Intuitively, as the price/cost ratio increases, the order quantity will jump to a higher level since the marginal profit is increasing. On the other hand, these results imply that the order quantity for Problem (26) will first increase as the price/cost ratio increases and then will become relatively stable regardless of the price/cost ratio. In contrast, the order quantity for our model Problem (25) provides a smooth increase as the price/cost ratio increases.These experimental results imply that our model Problem (25) is appropriate for decision makers who are between the risk averse decision makers of (26) and the risk neutral decision makers of (27). Our model is useful especially when the difference between Problem (27) and Problem (26) is large (as shown in Fig. 2c)) since it provides a reasonable way to achieve relatively better profit and relatively lower risk.For a final experiment, we use the infinite uncertainty sets:U={u∈U:E[u(X0)−u(Y0)]=1},andQ={p∈R|Ω|:∑ω∈Ωpω=1,p≥0},and we take the following parameter settings:•choose two demand scenarios,dL=D(ω1)=5“low” anddH=D(ω2)=10“high”;letGmin(c,r)=r*D(ω1)−c*D(ω2),which is a lower bound for G(q, D) given unit revenue r and unit cost c. Then, we takeX0=Gmin(c,r)−1andY0=Gmin(c,r)−2,which are constants given r and c;take the “true” demand distribution to beP^(ω1)=0.3andP^(ω2)=0.7.We evaluate the inner minimization in Problems (25) and (26) for any call by using a general nonconvex quadratic programming solver. We solve Problems (25) and (26) themselves using the bisection method. Fig. 3 records the results of this experiment. Compared to the results shown in Fig. 1, our regret minimization model provides a smoother function for the optimal order quantity as the price-cost ratio increases. We hypothesize that this smoothness is due to the choice of the infinite uncertainty sets. In summary, we see that our method gives a good balance between expected profit and variance with respect to the true distribution.We consider the portfolio optimization problem in this subsection. The issue of risk is naturally quite important in this problem and has been carefully studied. In (Dentcheva & Ruszczyński, 2006), the stochastic dominance constrained portfolio optimization is studied which emphasizes ambiguity in risk preferences. A robust portfolio optimization problem is formulated in (Huang, Zhu, Fabozzi, & Fukushima, 2010) which defines regret in terms of conditional value-at-risk. The papers (Lim, Shanthikumar, & Vahn, 2012; Lim, Shanthikumar, & Watewai, 2011) develop an expected utility regret model for portfolio optimization under statistical ambiguity. Several variations on the classical robust portfolio optimization problem are developed in (Zymler, Rustem, & Kuhn, 2011) (insurance guarantees), (Gregory, Darby-Dowman, & Mitra, 2011) (cost of robustness), and (Goh, Lim, Sim, & Zhang, 2012) (asymmetric returns).We study a simple portfolio optimization problem with two assets: one risky asset with random return rate R and one riskless asset with constant return rate α ≥ 1. Letz∈Z≜{z∈R:0≤z≤1}be the proportion of total wealth invested in the risk asset, then for z ∈ Z the random return isRz+α(1−z). We set the parameters for these experiments as follows:•Random return rate R can take two values 1 and 2;Q={P1,P2},P1(R=1)=0.1,andP2(R=1)=0.7;U={u1,u2},u1(x)=3x1/3,u2(x)=−2e−x/10+1(parameters for u2 are chosen in order to make it comparable to u1);P^=P1is the true model.We vary the fixed return rate α between 1 and 2. Fig. 4reports the expectation, variance, and the optimal investment decision as a function of α for the three different models. Just like for the newsvendor problem, these experimental results show that our regret minimizing model provides a good balance between the expectation maximization approach and the robust optimization approach. It is appropriate for decision makers who fall between pure risk-aversion and risk-neutrality.

@&#CONCLUSIONS@&#
