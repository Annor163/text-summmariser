@&#MAIN-TITLE@&#
Multiscale variational decomposition and its application for image hierarchical restoration

@&#HIGHLIGHTS@&#
We propose a multiscale variational decomposition model.We apply the proposed model for hierarchical image restoration and reconstruction.We prove the nontrivial property and the convergence of our model.Experimental results verify the correctness of the theoretical analysis.

@&#KEYPHRASES@&#
Image decomposition,Image restoration,Multiscale,Variation,Primal–dual algorithm,Gradient descent,

@&#ABSTRACT@&#
Variational decomposition has been widely used in image denoising, however, it can’t distinguish texture from noise well. Replacing the fixed parameter in the (BV, G) decomposition with a monotone increasing sequence, and iteratively taking the residual of the previous step as the input to decompose, we propose a multiscale variational decomposition model in this paper. Unlike the fixed-scale decomposition, the new model can decompose the input image into a sum of a series of features with different scales. So, texture can be distinguished from noise. In addition, we prove the nontrivial property and the convergence of this multiscale decomposition, and introduce a hybrid iteration algorithm that combines the first-order primal–dual algorithm with the gradient decent method to numerically solve the multiscale decomposition model. Numerical results validate the effectiveness of the proposed model. Furthermore, we apply this multiscale decomposition for image hierarchical restoration. Compared with the classical hierarchical (BV, L2) decomposition, hierarchical wavelet decomposition and fixed-scale (BV, G) decomposition, our model has better performance for both synthetic and real images in terms of PSNR and MSSIM.

@&#INTRODUCTION@&#
Restoration of the true image from an observation is an important task in image processing, where the observed image is usually a noisy version of the true image. Given an image functionf(x,y):Ω→R, image restoration is to extract true image u from the observation f. This is actually a decomposition off,f=u+v, where u represents cartoon or structure component formed by piecewise smooth regions with sharp boundaries, and v represents oscillatory component consisting of scale repeated details. In order to achieve the decomposition in denoising case, one of the most well known techniques is by regularization and functional minimization, i.e., variational methods; see for example [1–9].Total variation (TV) minimization model proposed by Rudin, Osher and Fatemi (ROF) [5] is a celebrated variational decomposition, in which an image f ∈ L2(Ω) is split into the sum of u ∈ BV(Ω) and v ∈ L2(Ω):(1.1)(u,v)=arginf{|u|BV(Ω)+μ∥v∥L2(Ω),f=u+v};therefore it is also called (BV, L2) decomposition. Here |u|BV(Ω) (also called TV of u) is a regularizing term to remove the noise. Model (1.1) is convex and easy to solve in practice. In addition, the function u ∈ BV(Ω) allows for discontinuities along curves, therefore edges and contours can be preserved in the restoration u.However model (1.1) has some limitations. For instance, the model does not represent well oscillatory details such as textures since the oscillatory functions don’t have small L2-norm [7], and BV pieces are often sent to component v for any μ[10,11]. Meyer [7] first suggested using weaker norms for the oscillatory component instead of L2-norm. One of his choices is the use of the dual norm of BV(Ω) for the oscillatory component. However, there is no known integral representation of continuous linear functional on BV(Ω). To address this problem, Meyer used another slightly larger spaceG(Ω)=W−1,∞(Ω)to approximate the dual of BV(Ω), and introduced the following (BV, G) variational decomposition model,(1.2)infu∈BV(Ω),v∈G(Ω){|u|BV(Ω)+μ∥v∥G(Ω),f=u+v}.In theory, this decomposition model can effectively extract oscillatory components from the observation. However, it cannot be directly solved in practice because there is no standard calculation of the associated Euler–Lagrange equation for energy in (1.2)[1,10–13].Vese and Osher [10,11] first overcame this difficulty by replacing the space G(Ω) withGp(Ω)=W−1,p(Ω)(1≤p<+∞). Later on, in [14], these two authors together with Sole proposed an alternative approximation for the case ofp=2in Gp(Ω), which coincides with the functional spaceH−1(Ω)(the dual of the Hilbert spaceH01(Ω)). Aujol, Aubert, Blanc-Feraud and Chambolle (AABC) [12,15] proposed another approach in the dual framework to solve the Meyer’s original (BV, G) model. Fig. 1shows the result of (BV, G) decomposition for a synthetic image using AABC model. One can clearly see that G functional space can model well repeated pattern. Almost all textures are absorbed by oscillatory component v, but very few cartoon pieces are absorbed.The (BV, G) model and it’s approximations mentioned above are fixed-scale decomposition, since the tuning parameters in these models are fixed. It has been proved that a human visualizing a scene is in multiple scales [16], and image restoration from a noisy observation is actually a simulation of the human visual perception (HVP), i.e., extracting large-scale objects and contours from noisy observation, and simultaneously removing small-scale details. So, in order to identify meaningful features (e.g., contours and textures) and meaningless features (e.g., noise) under different scales, multiscale approaches simulating HVP are appropriate for image restoration and reconstruction. In addition, all these fixed-scale decomposition models split image features on a single-scale. so they cannot distinguish well textures and noises which have different scales. Beside that, searching the optimal parameters in these variational models is still a difficult task.With the work of Tadmor, Nezzar and Vese in [17,18], in this paper we propose a multiscale (BV, G) decomposition model by replacing the fixed parameter in the original (BV, G) decomposition with a monotone increasing sequence, and iteratively taking the residual of the previous step decomposition as the input to decompose. New model can decompose the input image into a series of features with different scales. It the following applications and advantages:•Our model can provide a multiscale representation of the input image in the framework of variation.We use the multiscale (BV, G) decomposition to restore the true image hierarchically, which can distinguish texture from noise more subtly than the corresponding fixed-scale decomposition.As a by-product, our multiscale (BV, G) decomposition can accurately extract texture under different scales, which is actually an active area of image processing [6,16,19,20].Using the proposed multiscale (BV, G) decomposition in denoising application, we do not need complex optimal parameter determination.We perform extensive experiments on the proposed multiscale (BV, G) decomposition model and it’s application for image hierarchical restoration. In addition, We compare their results with the classical hierarchical (BV, L2) decomposition [17,18], hierarchical wavelet decomposition [21,22] and fixed-scale (BV, G) decomposition[12,15]. Results show that our proposed model performs better than these models in terms of PSNR and MSSIM. Our main contributions are summarized as follows.•A multiscale (BV, G) decomposition is proposed that can distinguish texture from noise more subtly than the corresponding fixed-scale decomposition.The nontrivial property and the convergence of our multiscale decomposition are proved.The proposed multiscale (BV, G) decomposition is applied for image hierarchical restoration.Numerical examples verify the theoretical results and illustrate the efficiency of the proposed model.Comparison of experimental results demonstrates superiority of the proposed model over some existing models.The rest of this paper is organized as follows. In Section 2, we present the multiscale (BV, G) decomposition, and then show its nontrivial property. In addition, the convergence of this multiscale decomposition is proved in this section. In Section 3, we introduce a numerical method for the proposed multiscale decomposition. The numerical results showing the performance of the proposed model are given in Section 4. This paper is summarized in Section 5.We first modify the original (BV, G) decomposition by introducing a fidelity term in the energy of (1.2), and then formulate it as a single-parameter pattern. The new energy is defined as(2.1)infu∈BV,v∈G{|u|BV+λ∥f−u−v∥L22+∥v∥G},where λ > 0 is a tuning parameter. By solving (2.1), the image f is discomposed into three components,f=u+v+rsuch thatu∈BV,v∈Gand r ∈ L2, which represent structure, texture and residual (i.e., noise) component of f, respectively.To accomplish hierarchical restoration of the true image from an observation, we propose a multiscale decomposition based on (2.1). Replacing the fixed scale parameter λ in (2.1) with a varying sequence, we can effectively extract structure and texture under different scales.For a given scale λ, the solution of (2.1) can be interpreted as a decomposition,f=uλ+vλ+rλsuch that uλcaptures structure in the scale of1λ, and vλcaptures texture in the scale of 4λγ. In this case, the scale of structure below1λand texture above 4λγ remain unresolved in the residual rλ. The residual rλstill consists of significant edges under a smaller scale than1λ, and oscillations under a larger scale than 4λγ; for example, for12λand 8λγ, respectively, we have(2.2)rλ=u2λ+v2λ+r2λwith(u2λ,v2λ)=arginf{|u|BV+2λ∥rλ−u−v∥L22+∥v∥G}.Similarly, u2λcaptures structure in the scale12λand v2λcaptures texture in 8λγ, while the structure below12λand texture above 8λγ remain unresolved in r2λ. The process of (2.2) can be continued to capture the missing smaller scale structure and larger scale texture.The proposed multiscale (BV, G) decomposition is stated as follows: Starting with an initial scaleλ=λ0,f=u0+v0+r0,where(u0,v0)=arginf{|u|BV+λ0∥f−u−v∥L22+∥v∥G}.Proceeding with successive applications of the dyadic refinement step (2.2), we have(2.3)ri=ui+1+vi+1+ri+1,i=0,1,⋯,where(ui+1,vi+1)=arginf{|u|BV+λ02i+1∥ri−u−v∥L22+∥v∥G}.From (2.3), after k such steps, we obtain the multiscale decomposition of f as follows:(2.4)f=u0+v0+r0=u0+u1+v0+v1+r1=⋯=u0+u1+⋯+uk+v0+v1+⋯+vk+rk.Fig. 2demonstrates the multiscale (BV, G) decomposition. The partial sum∑i=0kuilies in the intermediate scale spaces between BV and L2, which provides a multiscale representation of the structure of the input image f. And∑i=0kvilies in the intermediate scale spaces between G and L2, which represents multiscale texture. The sum of structure and texture∑i=0k(ui+vi)is a multiscale representation of the input image. In denoising application, it provides a hierarchical restoration from the noisy version f.We recall that the multiscale (BV, G) decomposition (2.4) is obtained by solving successively the following variational problem:(2.5)infu,v{|u|BV+λ02i+1∥ri−u−v∥L22+∥v∥G},i=−1,0,1,⋯,wherer−1is interpreted as f, i.e.,r−1=f.If the solution of (2.5) satisfiesui+1¬≡0orvi+1¬≡0for anyi∈{−1,0,1,⋯}, then we call the multiscale decomposition given in (2.4) the nontrivial multiscale decomposition. If the minimization problem (2.5) has only zero solution, i.e.(ui+1,vi+1)≡(0,0), then the decompositionri=ui+1+vi+1+ri+1is trivial, which makes no sense for image decomposition. In what follows, we discuss the existence of the nontrivial multiscale decomposition in (2.4).In the beginning, we define a new quantity || · ||* to measure the L2-function, which will play key role in our following study.Definition 2.1Letω∈L2,∥u∥X=|u|BV,∥v∥Y=∥v∥Gand the interpolation norm∥h∥X+Y=inf{∥u∥X+∥v∥Y:h=u+v,u∈X,v∈Y}.Then || · ||* is given by∥ω∥*=suph<ω,h>∥h∥X+Y=sup∥h∥X+Y≤1<ω,h>where<·,·>denote L2 inner product.Actually, || · ||* is the dual (or polar) norm of∥·∥X+Y. By the definition of || · ||*, we have the following result.Proposition 2.1Let ω ∈ L2. If∫Ωω≠0, then∥ω∥*=+∞.By the definition of ||ω||*, we have∥ω∥*=sup∥h∥X+Y≤1<ω,h>=sups+t≤1sup∥h∥X≤s,∥g∥Y≤t<ω,u+v>=sups+t≤1{s∥ω∥X*+t∥ω∥Y*}=max{∥ω∥X*,∥ω∥Y*}=max{∥ω∥G,∥∇ω∥L1}.From the Proposition 2.2 of [1], we have that if∫Ωω≠0, then∥ω∥G=+∞. It follows that∥ω∥*=+∞if∫Ωω≠0. □Next, we introduce a dual form of the minimization problem (2.5).Lemma 2.1Let(ui+1,vi+1)be a solution of(2.5). Thenri+1=ri−ui+1−vi+1is a solution of the following constrained minimization problem:infr∥ri−r∥L22subjectto∥r∥*≤1λ02i+2.With notations as before, the minimization problem (2.5) can be rewritten as(2.6)infh{∥h∥X+Y+λ02i+1∥ri−h∥L22}.DenotingF(h)=∥h∥X+Y, then (2.6) can be rewritten as(2.7)infh{F(h)+λ02i+1∥ri−h∥L22}.hi+1=ui+1+vi+1is a solution of (2.7) if and only if0∈∂F(hi+1)+λ02i+2(hi+1−ri),i.e.,(2.8)λ02i+2(ri−hi+1)∈∂F(hi+1),where∂F(hi+1)is the sub-differential of F at pointhi+1. Eq. (2.8) is equivalent to(2.9)hi+1∈∂F*(λ02i+2(ri−hi+1)),where F* is the Legendre–Fenchel transform of F, which is the indicator function of the closed convex setK={ω:∥ω∥*≤1}, i.e.,(2.10)F*(ω)=χK(ω)={0ifω∈K+∞otherwiseEq. (2.9) can be rewritten as0∈ri−hi+1−ri+∂F*(λ02i+2(ri−hi+1))which implies thatri+1=ri−ui+1−vi+1=ri−hi+1is a solution ofinfr{12∥ri−r∥L22+1λ02i+2F*(λ02i+2r)}.By the definition of F* given in (2.10), thenri+1is a solution of the following constrained minimization problem:(2.11)infr∥ri−r∥L22subjectto∥r∥*≤1λ02i+2.We thus obtain the desired result.□The constrained minimization problem (2.11) is a dual form of the problem (2.5) with r being the dual variable, whose solution can be written asri+1=ProjKλ(ri)which is just the orthogonal projection of rion the closed setKλ={ω:∥ω∥*≤1λ02i+2}.From Lemma 2.1, we have the following results which give us the theoretical properties of the solution of (2.5).Lemma 2.2Let ri∈ L2and(ui+1,vi+1)be a solution of the minimization problem(2.5). We have that if(ui+1,vi+1)≡(0,0), then∥ri∥*≤1λ02i+2.Since(ui+1,vi+1)≡(0,0)is a solution of (2.5), we have(2.12)ri+1=ri−ui+1−vi+1=ri.From Remark 2.1, we haveri+1=ProjKλ(ri), by combining with (2.12), which impliesri=ProjKλ(ri). Then, we can deduce that ri∈ Kλ, i.e.,∥ri∥*≤1λ02i+2.□Let ri∈ L2and(ui+1,vi+1)be a solution of the minimization problem(2.5). Then we have the following:(1)If∥ri∥*>1λ02i+2, thenui+1¬≡0orvi+1¬≡0.Furthermore, the residualri+1=ri−ui+1−vi+1satisfies∥ri+1∥*=1λ02i+2.The first assertion can be proved directly by Lemma 2.2.For the second assertion, because ofri+1=PKλ(ri)by Remark 2.1 and∥ri∥*>1λ02i+2(i.e.,ri∉Kλ), on the basis of convex optimization theory, we have∥ri+1∥*=1λ02i+2. □As a consequence of Lemma 2.3 we have the following theorem which shows the nontrivial property of our multiscale decomposition given in (2.4).Theorem 2.1Let f ∈ L2with∫Ωf≠0. Then, for any initial scale λ0 > 0, the multiscale decomposition of f, given in(2.4), is nontrivial.For the first step decomposition, because of∫Ωf≠0, we have∥r−1∥*=∥f∥*>12λ0by Proposition 2.1, which means that the first step decompositionf=r−1=u0+v0+r0is nontrivial by Lemma 2.3. In addition, again by Lemma 2.3, the residual r0 of present step satisfies∥r0∥*=12λ0>14λ0which means that the next step decomposition is also nontrivial.Similarly, for the(i+1)th step decomposition, the residualri−1of the previous step satisfies∥ri−1∥*=1λ02i>1λ02i+1which implies that the(i+1)th step decompositionri−1=ui+vi+riis nontrivial by Lemma 2.3.□From Theorem 2.1, we can conclude that if the initial image f satisfies∫Ωf≠0, then the multiscale decomposition given in (2.4) is nontrivial. Further, if the first step decomposition is nontrivial, then the successive multiscale decomposition is also nontrivial.For the multiscale decomposition given in (2.4), we have the following convergence result in the || · ||* topology.Theorem 2.2Let f ∈ L2. Then the residual of the multiscale decomposition of f, given in(2.4), satisfies∥rk∥*→0ask→+∞.From Lemmas 2.2 and 2.3, we have that in each case,∥rk∥*≤1λ02k+1.Lettingk→+∞, we obtain the desired result.□Under the same condition asTheorem 2.2, we have||f−∑i=0k(ui+vi)||*→0ask→+∞Sincerk=f−∑i=0k(ui+vi),we obtain the desired result by Theorem 2.2.□In this section, we present a hybrid iteration algorithm that combines the first-order primal–dual algorithm and the gradient decent for our multiscale decomposition:(3.1)infu,v{|u|BV+λ02k+1∥rk−u−v∥L22+∥v∥G},k=−1,0,1,⋯.We note here that in order not to cause the confusion of subscripts in what follows, the parameter i in (2.1) is replaced by k in (3.1). Computing the solution of the minimization problem (3.1) amounts to successively solve the following coupled problems:•Fixed v, find the solutionuk+1of(3.2)infu{|u|BV+λ02k+1∥rk−u−v∥L22}.Fixed u, find the solutionvk+1of(3.3)infv{λ02k+1∥rk−u−v∥L22+∥v∥G}.We here adopt the first-order primal–dual algorithm proposed by Chambolle and Pock [3] to solve the minimization problem (3.2). The algorithm is stated as follows:•Initialization:u¯0=u0=rk−vandξ0=0.Iterations: updateξn,unandu¯nas followsξi,jn+1=ProjP(ξn+τ∇u¯n)i,j=ξi,jn+τ(∇u¯n)i,jmax{1,|ξi,jn+τ(∇u¯n)i,j|}ui,jn+1=ui,jn+τ(div(ξn+1))i,j+τλ02k+2(rk−v)i,j1+τλ02k+2u¯i,jn+1=ui,jn+1+θ(ui,jn+1−ui,jn)where θ ∈ [0, 1] is the relaxation parameter, τ is the step parameter.Next, we state the method to solve the minimization problem (3.3). Duo to the nature of G-norm, (3.3) cannot be solved directly. We solve this problem by replacing ||v||Gwith∥v∥H−1, which is proposed by Vese, Osher and Sole in [14]. The minimization problem (3.3) is approximated by the following:(3.4)infv{λ02k+1∥rk−u−v∥L22+∥∇(Δ−1v)∥L22}.Using gradient descent method and semi-implicit finite difference scheme, we obtain the following iteration to solve v in (3.4):v0=0,vi,jn+1=vi,jn+τ(λ02k+1(Δ(u+vn−rk))i,j)1+τ.In practice, we always use the most recent values to compute the values of function at each point during iteration process. The principal steps of the hybrid iteration algorithm for (3.1) can be formulated as follows:1.Initialization:u0=u¯0=rk,v0=0andn=0.Computeξn+1:(1)Initializeξ0=0andn=0,Computeξn+1byξi,jn+1=ξi,jn+τ(∇u¯n)i,jmax{1,|ξi,jn+τ(∇u¯n)i,j|}.Check whether|div(ξi,jn+1)−div(ξi,jn)|≤ɛholds. If not, setn=n+1and go back to step (2).Computeun+1byui,jn+1=ui,jn+τdiv(ξn+1)i,j+τλ02k+2(rk−vn)i,j1+τλ02k+2.Computeu¯n+1byu¯i,jn+1=ui,jn+1+θ(ui,jn+1−ui,jn).Computevn+1byvi,jn+1=vi,jn+τ(λ02k+1(Δ(u¯n+1+vn−rk))i,j)1+τ.Check whethermax{|un+1−un|,|vn+1−vn|}≤ɛholds. If not, setn=n+1and go back to step 2.This states the algorithm that solves (3.1) at a fixed k. Let(uk+1,vk+1)=limn→∞(un,vn). Then(uk+1,vk+1)is the solution of (3.1) with fixed k. At last, in order to convert this scheme into the multiscale decomposition, starting with the initial assignmentk=−1withr−1=f, we reiterate the above process, each time updating the value of k ask+1.In this section, we present some numerical examples to demonstrate the efficiency of our model. All programs are coded in MATLAB, and run on a PC with Intel Core i5 2.5G CPU and 4.00G RAM. In all experiments, we takeτ=0.05,θ=1and the initial scaleλ0=0.005. We use peak signal to noise ratio (PSNR) and mean structural similarity (MSSIM) index [23] as the means of judging the performance.In our first experiment, we validate the proposed multiscale (BV, G) decomposition model. According to Section 2.1, the multiscale decomposition of f can be represented asf=∑i=0kui+∑i=0kvi+rk,where k is the number of decomposition levels;∑i=0kuiis multiscale structure;∑i=0kviis multiscale texture and rkrepresents residual.Fig. 3shows the results of the multiscale (BV, G) decomposition applied to a synthetic textured image. The first column shows the structure components of the input image under different scales. Clearly, from top to bottom, the missed structures absorbed by residual components of the previous steps are gradually resolved in terms of the decreased scaling for structure.The second column shows the ‘texture+100’ (plus a constant for better visuals) components of the input image under different scales, which provides a multiscale texture representation of the input image. We can clearly see that an additional amount of blurred textures is resolved in terms of the increased scaling for texture.The last column shows the ‘residual+100’ of each step decomposition. We can clearly see that firstly a very large amount of structures and textures are swept into residual components when the scale parameterλ02i+1is small. And then, with increasing the value of the scale parameter, these structures and textures are swept out from residual components and absorbed by uiand vi, respectively.Fig. 4plots the L2 energy versus the decomposition levels for the multiscale structure∑i=0kui, multiscale texture∑i=0kviand residual rkshown in Fig. 3. We can see that the energy of the multiscale structure and texture is monotone increase, which verifies the nontrivial property of the proposed model (see Section 2.2). The energy of the residual is first fast monotone decrease, then gently and to tend zero. This verifies the convergence of our multiscale decomposition (see Section 2.3).From this experiment, we see that the proposed model can effectively decompose the input image into a sum of a series of structures and textures with different scales. If we use this multiscale decomposition to restore the true image from a noisy observation, the structures and textures can be hierarchically reconstructed in the restoration. The advantage of this implementation is that the image details and noises can be separated subtly.In our second experiment, we evaluate the performance of the hierarchical restoration using multiscale (BV, G) decomposition. Test images are shown in Fig. 5. The first row shows the original clean images with size of256×256; and second row shows the corresponding noisy versions obtained by adding Gaussian noise with standard deviationσ=20to the clean ones. The PSNR and MSSIM for these noisy images are listed in Table 1.Fig. 6shows the hierarchical restorations using the proposed multiscale (BV, G) decomposition for noisy Barbara. The first and second columns show the structure and texture components under different scales, respectively. Clearly, from top to bottom, an additional amount of blurred image details are resolved.The third column shows∑i=0k(ui+vi)s which can be seen as the restorations of noisy Barbara under different scales. Clearly, when the value of k is small, such ask=0,1, there are few textures and noises in the restored images, most of them are swept into residual components. Whenk=2,3, some textures are gradually recovered on the headscarf of Barbara while the noises are removed from the entire image. The PSNR and MSSIM of restorations, listed in the second and third column of Table 2, respectively, keep increasing and simultaneously achieve a maximum whenk=4(the maximums of PSNR and MSSIM are marked in bold). If we continue the decomposition, the noises will reappear in the∑i=0k(ui+vi)components and decrease PSNR and MSSIM of the restorations. This is because that the coarser scales reach the same scales of the noise itself.The last column shows the residual components of each step decomposition. We can clearly see that firstly some edges, textures and all noises are swept into these components when the scale parameterλ02i+1is smaller. And then, with increasing the value of the scale parameter, edges and textures are swept out from residual and absorbed by uiand vi, respectively.Furthermore, we compare our model to the classical hierarchical (BV, L2) decomposition [17,18] and hierarchical wavelet decomposition [21,22] in denoising application.The reason why we choose hierarchical (BV, L2) decomposition to compare is that it is the first one in image multiscale representation under the variational framework, and our present work is a direct extension of this classical method. In order to perform the comparison under the same condition, in hierarchical (BV, L2) decompositionui+1=arginf{|u|BV+λ02i+1∥ri−u∥L22},the initial scale is also choose asλ0=0.005. Fig. 7 shows the results of hierarchical restoration for noisy Barbara using hierarchical (BV, L2) decomposition, where∑i=0kuirepresents denoised image obtained after k-levels decomposition, and rkrepresents corresponding residual component.Fig. 8shows the results of hierarchical restoration for noisy Barbara using hierarchical wavelet decomposition, where ukrepresents denoised image using global soft-thresholding method to the high frequency coefficients obtained after k-levels wavelet decomposition, and rkrepresents corresponding residual component. The reason why we choose wavelet to compare is that it is a good tool for image multiscale representation in frequency domain. In this experiment, we use the classical wavelet thresholdσ2log(N×M)[1,2], whereN×Mrepresents the image size, and σ is the noise variance.From the results shown in Figs. 7 and 8, we see that these two models both can successfully reconstruct image information hierarchically. Hierarchical (BV, L2) decomposition hierarchically reconstructs image structures and textures from the residual component. Conversely, hierarchical wavelet decomposition restores the true image by gradually sweeping out the noise from the original observation. Visually, these two models perform noise removing well but the quantitative comparison (see Table 2) shows that our model has slightly higher PSNR and MSSIM values. The reason is that our model use two suitable function spaces, G and L2, to model the texture and noise, separately. In addition, our hierarchical restoration scheme allows finer distinction between noise and texture.From the above denoising results of Barbara, we see that our model performs best in PSNR and MSSIM among these three models, but our model costs more CPU time: for single-step decomposition, hierarchical (BV, L2) decomposition needs about 1.37s, hierarchical wavelet decomposition needs about 0.98s, while our model takes about 1.64s.Finally, to further show the effectiveness and adaptability of the proposed model, we apply it to denoise some images with different types. Test images are shown in Fig. 5. One is a simple synthetic image that has neat edges and regular textures. The others are two real images: one is a panda image that contains large white areas and black areas; and the other is a butterfly in front of a blurry background. Compared to the panda image, this image is more complex, which contains a large amount of details, textures and features of low contrast. Again, we compare our model to the hierarchical (BV, L2) decomposition and the hierarchical wavelet decomposition. In addition, the original (BV, G) decomposition (i.e. fixed-scale (BV, G) decomposition) [12,15] is to be compared to show the advantage of our hierarchical restoration scheme.Figs. 9–11show the restoration results. The first rows in these figures are denoised images, and the second rows are corresponding residual components. We here only show the restorations with the highest PSNR. One can clearly see that all models can successfully remove noises and simultaneously preserve edges. But our residual components contain the least image information, which in turn indicate that our model possesses the best ability of preserving image structures in restorations. Table 3shows that our model has the highest PSNR and MSSIM values, which further demonstrates that our model has the best performance in these four models.

@&#CONCLUSIONS@&#
To distinguish textures and noises effectively, a multiscale image decomposition model in the framework of variation has been proposed in this paper. The new model is obtained by replacing the fixed parameter in the (BV, G) decomposition with a varying sequence, and iteratively taking the residual of the previous step decomposition as the input to decompose. The theoretical results show the convergence and nontrivial properties of the multiscale decomposition. Furthermore, a hybrid iteration algorithm that combines the first-order primal–dual algorithm with the gradient decent method is introduced to solve it. The experimental results show that the proposed model is effective to decompose the input image into a sum of a series of structures and textures with different scale. In addition, the multiscale (BV, G) decomposition is applied for image hierarchical restoration. Compared with the classical hierarchical (BV, L2) decomposition, hierarchical wavelet decomposition and fixed-scale (BV, G) decomposition, our model has a better performance for both synthetic and real images in terms of PSNR and MSSIM.It should be point out that our model still has some limitations: (1) in numerical implementation, we use the spaceH−1to approximate the original G space. Such an approximation will lead to numerical error inevitably; (2) compared to some classical multiscale decomposition models, our model costs more CUP time. Our successive research will focus on overcoming these problems.