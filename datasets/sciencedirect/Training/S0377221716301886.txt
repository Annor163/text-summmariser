@&#MAIN-TITLE@&#
KKT optimality conditions in interval valued multiobjective programming with generalized differentiable functions

@&#HIGHLIGHTS@&#
We introduce LU and LS relations due to generalized Hukuhara derivative.We propose KKT optimality theorems with generalized Hukuhara differentiability.We analyze LU and LS Pareto minimum points by examples with figures and tables.We show some advantages of our results by comparing with Wu (2007).

@&#KEYPHRASES@&#
Interval valued functions,gH-differentiability,LU,LS-convex functions,Pareto optimal solutions,KKT optimality conditions,

@&#ABSTRACT@&#
We devote this paper to study a class of interval valued multiobjective programming problems. For this we consider two order relations LU and LS on the set of all closed intervals and propose many concepts of Pareto optimal solutions. Based on convexity concepts (viz. LU and LS-convexity) and generalized differentiability (viz. gH-differentiability) of interval valued functions, the KKT optimality conditions for aforesaid problems are obtained. In addition, we compare our results with the results given in Wu (2009) and we show some advantages of our results. The theoretical development is illustrated by suitable examples.

@&#INTRODUCTION@&#
Theory and mathematical modeling (programming) are important components of optimization problems. In practice, it is usually difficult to determine the coefficients of objective function as a real number, since a number of real world problems often involve uncertain or imprecise data due to measurement errors or some unexpected factors. There are two deterministic optimization models to deal with uncertain data viz. robust optimization (Ben-Tal, Ghaoui, & Nemirovski, 2009) and interval valued optimization (Ben-Israel & Robers, 1970). Many approaches have been developed to deal with these problems. Birg and Luoveaux (1997), Vajda (1972), Stancu-Minasian (1984), Prekopa (1995) have provided various techniques for solving stochastic optimization problems. The collection of papers on fuzzy optimization edited by Slowinski (1998) and Delgado, Kacprzyk, Verdegay, and Vila (1994) gave the main stream to the topic. Lai and Hwang (1992,1994) also gave useful survey. Inuiguchi and Ramik (2000) gave a review of fuzzy optimization and a comparison with stochastic optimization in portfolio selection problems. Slowinski and Teghem (1990) have provided comparison between two types of the optimization problems for multiobjective programming problems. Stancu-Minasian and Tigan (1990) obtained solutions for interval valued optimization problems.The interval valued optimization problems are closely related with the inexact linear programming problems. Charnes, Granot, and Phillips (1977) considered the linear programming problems in which the right-hand sides of linear inequality constraints were taken as closed intervals. Steuer (1981) proposed three algorithms called the F-cone algorithm, E-cone algorithm and all emanating algorithm to solve the linear programming problems with interval objective functions. Ishibuchi and Tanaka (1990) proposed the ordering relation between two closed intervals by considering the maximization and minimization problems separately. Mraz (1998) proved algorithms to compute the exact upper bound and lower bound for linear programming problems with interval coefficients. Chanas and Kuchta (1996) presented an approach to unify the solution methods proposed in Ishibuchi and Tanaka (1990) and Rommelfanger, Hanuscheck, and Wolf (1989). Oliveria and Antunes (2007) provided an overview of multiobjective linear programming problems with interval coefficients by illustrating many numerical examples. Lai and Hwang (1992) proposed an interval parameter fuzzy nonlinear optimization model for stream water quality management under uncertainty.The Karush–Kuhn–Tucker optimality conditions play an important role in area of optimization theory and have been studied for over a century. Wu (2007,2008,2009) have studied KKT optimality conditions for interval valued optimization problems. Singh, Dar, and Goyal (2014) have derived KKT optimality conditions for optimization problem in which both objective and constraints are assumed to be interval valued functions. Also Chalco-Cano, Lodwick, and Rufian-Lizana (2013) have studied the KKT optimality conditions of interval valued optimization problem via generalized derivative. Moreover Zhang, Liu, Li, and Feng (2012) derived the KKT optimal conditions for non-convex programming problems with interval valued objective functions. However optimality conditions for invex interval valued nonlinear programming problems via gH-derivative are discussed in Ahmad, Singh, and Ahmad (2014). Also Ahmad, Jayswal, and Banerjee, (2013); Jayswal, Stancu-Minasian, and Ahmad, (2011); Jayswal, Stancu-Minasian, Banerjee, and Stancu, (2015); Zhang, (2013) extended the concept of duality to interval valued optimization problems, involving non-convex functions.This paper develops a theoretical and practical solution method for multiobjective programming problems with interval valued objective functions considering order relationship between two closed intervals inR. In particular we consider order relations following from Wu (2007) and Chalco-Cano et al. (2013). For this problem we obtain KKT conditions by using gH-derivative of interval valued functions. The theoretical concepts are illustrated with adequate number of examples.LetKcdenote the class of all closed and bounded intervals inR. i.e.,Kc={[a,b]:a,b∈Randa≤b},andb−ais the width of the interval[a,b]∈Kc.LetA∈Kc. Then we adopt the notationA=[aL,aU],where aLand aUare the lower and upper bounds respectively. Assume thatA=[aL,aU],B=[bL,bU]∈Kcandλ∈R,then by definition we have,A+B={a+b:a∈Aandb∈B}=[aL+bL,aU+bU],λA=λ[aL,aU]={[λaL,λaU],ifλ≥0,[λaU,λaL],ifλ<0.Therefore−A=−[aL,aU]=[−aU,−aL]andA−B=A+(−B)=[aL−bU,aU−bL].Now ifA=B+C,then the Hukuhara difference (H-difference) or geometrical or pontryagin of A and B (denoted byA−HB) is equal to C. IfA=[aL,aU],B=[bL,bU],A−HB=C=[cL,cU]exist thenaL−bL≤aU−bU,wherecL=aL−bLandcU=aU−bUWu (2007).Further let A,B∈Kc. The generalized Hukuhara difference (gH-difference) is defined asA⊖gB=C⟺{(i)A=B+C,or(ii)B=A+(−1)C.For any two intervalsA=[a,b]andB=[c,d],A⊖gBalways exists and equals toA⊖gB=[min{a−c,b−d},max{a−c,b−d}](Stefanini & Bede, 2009).Let X be a nonempty subset ofRn. A functionf:X→Kcis called an interval-valued function. In this casef(x)=[fL(x),fU(x)],withfL,fU:X→R,fL(x)≤fU(x),∀x∈X.A straight forward concept of differentiability of interval valued functions was introduced in Wu (2007) and is defined as follows.Definition 2.1(Wu, 2007) Let f be an interval valued function defined onX⊂Rn. We say that f is weakly continuously differentiable at x* ∈ X if the real valued functions fLand fUare continuously differentiable at x* (i.e., all partial derivatives of fLand fUexist in some neighborhood of x* and are continuous at x*).Next the Hukuhara differentiability (H-differentiability in short) for interval valued functions, introduced initially by Hukuhara (1967), is based on H-difference of intervals. Later Wu (2007, 2009) used this differentiability to study KKT conditions of programming problems with interval valued objective functions. However this definition of differentiability is restrictive e.g., consider a simple interval valued functionf(x)=(α−x3−βx5)[−α,β],where0<α,β∈R. The H-derivative of f does not exist as H-differencef(0+h)−Hf(0)does not exist ash→0+. In general iff(x)=Ag(x),where A is an interval and g(x) is a real valued function with g′(x) < 0, then f is not differentiable atx=x*(Bede & Gal, 2005).On the basis of gH-difference of intervals the generalization of H-differentiability was introduced in Stefanini and Bede (2009) called gH-differentiability and is given below. For our on-going discussion we define the class of intervalsT=(x1,x2)by T.Definition 2.2(Stefanini & Bede, 2009) The gH-derivative of an interval valued functionf:T→Kcis defined asf′(x*)=limh→0f(x*+h)⊖gf(x*)h.If f′(x*) exists, we say that f is generalized Hukuhara differentiable (gH-differentiable) at x*. Also we say that f is gH-differentiable on T if f is gH-differentiable at each x* ∈ T. Where the limits are taken in the metric space(Kc,H)and H is defined byH(A,B)=max[maxa∈Ad(a,B),maxb∈Bd(A,b)],whered(a,b)=minb∈B∥a−b∥.(Chalco-Cano, Roman-Flores, & Jimenez-Gamero, 2011) Letf:T→Kcbe an interval valued function. If fL and fU are differentiable at x* ∈ T then f is gH-differentiable at x*andf′(x*)=[min{(fL)′(x*),(fU)′(x*)},max{(fL)′(x*),(fU)′(x*)}].The converse of above theorem is not true (see, Chalco-Cano et al., 2011). However we have the following result.Theorem 2.2(Chalco-Cano et al., 2011) Letf:T→Kcbe an interval valued function. Then f is gH-differentiable at x* ∈ T if and only if one of the following cases holds.(i)fL and fU are differentiable at x*.The derivatives(fL)−′(x*),(fL)+′(x*),(fU)−′(x*)and(fU)+′(x*)exist and satisfy(fL)−′(x*)=(fU)+′(x*)and(fL)+′(x*)=(fU)−′(x*).(Chalco-Cano et al., 2013) Letf:T→Kcbe gH-differentiable at x* ∈ T, thenfL+fUis a differentiable function at x*.(Chalco-Cano et al., 2013) Let f be an interval valued function defined onX⊆Rnand letx*=(x1*,...,xn*)be fixed in X.(i)We consider the interval valued functionHi(xi)=f(x1*,…,xi−1*,xi*,xi+1*,…,xn*). IfHiis gH-differentiable atxi*,then we say that f has the ith partial gH-derivative atx*(denotedby(∂f∂xi)g(x*))and(∂f∂xi)g(x*)=(Hi)′(xi*).We say that f is continuously gH-differentiable at x* if all the partial gH-derivatives(∂f∂xi)(x*),i=1,…,nexist on some neighborhood of x* and are continuous at x* (in the sense of interval valued function).(Chalco-Cano et al., 2013) Let f be an interval valued function defined onX⊆Rn. If f is continuously gH-differentiable atx*, thenfL+fUis continuously differentiable atx*.Next, we consider the (interval) multivalued functionF(x)=(f1(x),…,fr(x)) defined onX⊆Rn,wherefk(x)=[fkL(x),fkU(x)],k=1,…,rand study some properties.Now we define the following.Definition 2.6Let F be an (interval) multivalued function. We say that F is(i)(weakly) continuously differentiable at x* ∈ X iffk,k=1,…,rare weakly continuously differentiable at x*.continuously gH-differentiable at x* ∈ X iffk,k=1,…,rare continuously gH-differentiable at x*.It is clear from Definition 2.1 that the weakly continuously differentiability of f is established with relation to the differentiability of the lower and upper (end point) functions. Therefore we do not know about the derivative of f. e.g., consider a simple interval valued functionf(x)=[−|x|,|x|],x∈R. Then f is not weakly continuously differentiable atx=0. However f is continuously gH-differentiable atx=0andf′(x)=[−1,1],for allx∈R.Proposition 2.7Let F be an (interval) multivalued function. Then(i)F is (weakly) continuously differentiable atx*iffkL,fkU,k=1,…,rare differentiable atx*.If F is continuously gH-differentiable atx* ∈ X, thenfkL+fkU,k=1,…,rare continuously differentiable atx*.(i) follows immediately from Definitions 2.1 and 2.6 (i). (ii) follows from Definition 2.6 (ii) and Proposition 2.5.□Consider the following (interval) multiobjective programming problem. (MIP1)minF(x)=(f1(x),…,fr(x)),subjecttox=(x1,…,xn)∈X⊆Rn,wherefk(x)=[fkL(x),fkU(x)],k=1,…,rare interval valued functions and the feasible set X is assumed to be a convex subset ofRn. Since each fkis a closed interval inR,we follow the similar solution concept as it was proposed in Wu (2007). In Wu (2007) a partial ordering “⪯LU” was invoked between two closed intervals as follows.LetA,B∈Kc,then we write A⪯LUB if and only if aL≤ bLand aU≤ bU. We also write A≺LUB if and only if A⪯LUB and A ≠ B or equivalently A≺LUB if and only if(1){aL<bLaU≤bU,or{aL≤bLaU<bU,or{aL<bLaU<bU.A vectorA=(A1,…,Ar)is said to be an interval valued vector ifAk∈Kc,k=1,…,r. Also for any two interval valued vectorsA=(A1,…,Ar)andB=(B1,…,Br)we write A⪯LUB if and only if Ak⪯LUBkfor eachk=1,…,r. We also write A≺LUB if and only if Ak⪯LUBkfor eachk=1,…,rand Ah≺LUBhfor at least one index h (Wu, 2009).Definition 3.1(Wu, 2009) Let x* be a feasible solution of (MIP1). We say that x* is(i)LU-Pareto optimal solution of (MIP1) if there exists nox¯∈X,s.t.,F(x¯)≺LUF(x*).Strongly LU-Pareto optimal solution of (MIP1) if there exists nox¯∈X. s.t.,F(x¯)⪯LUF(x*).Weakly LU-Pareto optimal solution of (MIP1) if there exists nox¯∈X. s.t.,fk(x¯)≺LUfk(x*)fork=1,…,r.(Wu, 2009) Let us denote byXWPLU,XPLU,XSPLUthe set of weakly LU-Pareto optimal solutions, LU-Pareto optimal solutions, and strongly LU-Pareto optimal solutions respectively. ThenXSPLU⊆XPLU⊆XWPLU.Consider the following multiobjective programming problem.(P1)minF(x)subjecttox−2≤0−x−2≤0.ConsiderF(x)=(f11(x),f12(x)). Wheref11(x)={[0,x22],ifx≥0,[−x22,0],ifx≤0andf12(x)={[0,x(x+1)2],ifx≥0,[x2,0],ifx≤0.Clearly there exists no−2≤x11*≤2,such thatf11(x11*)⪯LUf11(x*=−2)andf12(x11*)⪯LUf12(x*=−2)(see, Figs. 1 and 2). Therefore by Definition 3.1 (ii) and Remark 3.2, we see that−2∈XSPLU∩XPLU∩XWPLUfor (P1).Further, if we considerF(x)=(f11(x),f12(x),f13(x)). Wheref13(x)=[sinx2+cosx2,sinx2+cosx+1].Then there existsx31*=2,such thatf13(x31*)=f13(x*=−2)(see, Fig. 2). Therefore−2∈XPLU∩XWPLUbut−2∉XSPLUfor (P1).Next, assume thatF(x)=(f13(x),f14(x),f15(x)). Wheref14(x)=[32sinx3,12(sinx3+1)]andf15(x)=[3sin(x−1)3−1,sin(x−1)3].Then there exist−2≤x41*≈−1.1633,x42*≈1.6776≤2(see, Fig. 3), such thatf14(x41*)=f14(x42*)=f14(x*≈−2)and−2≤x51*≈−1.7346,x52*≈−1.4246,x53*≈−0.9913,x54*≈−0.1575≤2,such thatf15(x51*)=f15(x52*)=f15(x53*)=f15(x54*)=f15(x*≈−2)(see, Fig. 4). Therefore−2∈XWPLUbut−2∉XPLU,XSPLUfor (P1).From the above discussion we summarize the LU-optimal points in Table 1.Note that the values may vary in decimal positions subject to the ‘ × zoom’ applied at the time of calculating values.For another solution concept, we denote byw(A)=aS=aU−aLthe width (spread) ofA=[aL,aU]. In this paper we shall consider only the minimization problem without loss of generality. In this sense, forA,B∈Kcwe write A⪯LSB if and only if aL≤ bLand aS≤ bS. We also write A≺LSB if and only if A⪯LSB and A ≠ B, i.e., A≺LSB if and only if(2){aL<bLaS≤bS,or{aL≤bLaS<bS,or{aL<bLaS<bS.For details one is referred to Chalco-Cano et al. (2013).Let A and B be interval valued vectors, then we write A⪯LSB if and only ifAk⪯LSBk,k=1,…,r. We also write A≺LSB if and only if Ak⪯LSBkfork=1,…,rand Ah≺LSBhfor at least one index h.Definition 3.4Let x* be feasible solution of (MIP1). We say that x* is(i)LS-Pareto optimal solution of (MIP1) if there exists nox¯∈X,s.t.,F(x¯)≺LSF(x*).Strongly LS-Pareto optimal solution of (MIP1) if these exists nox¯∈X. s.t.,F(x¯)⪯LSF(x*).Weakly LS-Pareto optimal solution of (MIP1) if these exists nox¯∈X. s.t.,fk(x¯)≺LSfk(x*),k=1,…,r.Let us denote byXWPLS,XPLS,XSPLSthe set of weakly LS-Pareto optimal solutions, LS-Pareto optimal solutions, and strongly LS-Pareto optimal solutions respectively, thenXSPLS⊆XPLS⊆XWPLU.ConsiderF(x)=(f11(x),f12(x),f16(x)). Wheref16(x)={[min(−x2,2sinx),0]ifx≤0,[0,max(x2,2sinx)]ifx≥0.Then there exists no−2≤x11*≤2,such thatf11(x11*)⪯LSf11(x*=0),f12(x11*)⪯LSf12(x*=0)andf16(x11*)⪯LSf16(x*=0)(see,Figs. 1 and 5). Therefore by Definition 3.4 (ii) and Remark 3.5, we see that0∈XSPLS∩XPLS∩XWPLSfor (P1).Now, assume thatF(x)=(f12(x),f16(x),f17(x)). Wheref17(x)=[12(cosx3−1),53cosx3].Then there existx71*≈1.8475,x72*≈−1.8475andx7q*∈(0−δ1,0+δ1),δ1≈0.3169>0such thatf17(x71*)=f17(x72*)=f17(x7q*)=f17(x*=0)(see, Fig. 6). Therefore0∈XPLS∩XWPLSbut0∉XSPLSfor (P1).Further, assume thatF(x)=(f17(x),f18(x),f19(x)). Wheref18(x)=[13(cosx4−1),32(cosx4−12)]andf19(x)=[14(cosx5−1),32(cosx5−1)].Then there existx81*≈1.8828,x82*≈−1.8828,x83*≈1.5789,x84*≈−1.5789andx8q*∈(0−δ2,0+δ2),δ2≈0.5060>0,such thatf18(x81*)=f18(x82*)=f18(x83*)=f18(x84*)=f18(x8q*)=f18(x*=0)(see,Figs. 7 and 8). Also there existx91*≈1.99275,x92*≈−1.99275,x93*≈1.9056,x94*≈−1.9056,x95*≈1.79965,x96*≈−1.79965,x97*≈1.65898,x98*≈−1.65898andx9q*∈(0−δ3,0+δ3),δ3≈0.5547,such thatf19(x91*)=f19(x92*)=f19(x93*)=f19(x94*)=f19(x95*)=f19(x96*)=f19(x97*)=f19(x98*)=f19(x9q*)=f19(x*=0)(see, Figs. 9 and 10). Therefore0∈XWPLSbut0∉XPLS,XSPLSfor (P1).From the above discussion we summarize the LS-optimal points in Table 2.Let A, B be two closed intervals inKc.(i)If A⪯LSB then A⪯LUB.Chalco-Cano et al. (2013).If A≺LSB then A≺LUB.To prove (ii), assume that A≺LSB, then we haveCase I. aL< bL, aS≤ bS, implyaL<bL,aU−aL≤bU−bL.NowaU<aU+(bL−aL)≤bL+(bU−bL)=bU.Therefore we have A≺LUB.Case II. aL≤ bL, aS< bSand Case III. aL< bL, aS< bSfollow similarly.□Note that the converse of Proposition 3.7 is not valid.Proposition 3.8LetA=(A1,…,Ar)andB=(B1,…,Br)be interval valued vectors.(i)IfA⪯LSBthenA⪯LUB.IfA≺LSBthenA≺LUB.(i)Since A and B are interval valued vectors and A⪯LSB, thenAk⪯LSBk,k=1,…,r.i.e.,akL≤bkLandakS≤bkS,k=1,…,r.It implies thatakL≤bkLandakU−akL≤bkU−bkL,k=1,…,r.Thus we haveakU≤akU+(bkL−akL)=bkL+(akU−akL)≤bkL+(bkU−bkL)=bkU.Therefore we have A⪯LUB.follows immediately from above and from (ii) of Proposition 3.7.□Note that the converse of Proposition 3.8 is not valid, for example letA=(A1=[−1,0],A2=[−1,0])andB=(B1=[−12,0],B2=[−12,0]),then A≺LUB but A⊀LSB.Theorem 3.1Let X be a feasible set of (MIP1). Then(i)XSPLU⊆XSPLS,XPLU⊆XPLS,XWPLU⊆XWPLS.Let x be the feasible solution of (MIP1). i.e., x ∈ X.(i) Assume that(3)x∈XSPLU.Welet contrary thatx∉XSPLS,then by Definition 3.4 there existsx^∈X,s.t.,F(x^)⪯LSF(x). From Proposition 3.8 (i), we see thatF(x^)⪯LUF(x*)which contradicts (3). Hence we see thatXSPLU⊆XSPLS.(ii) follows similarly.For (iii), considerx∈XWPLU. On contrary assume thatx∉XWPLS,then by Definition 3.4 there existsx¯∈Xs.t,fk(x¯)≺LSfk(x),k=1,…,r. From Proposition 3.8 (ii),fk(x¯)≺LUfk(x),k=1,…,rwhich contradicts to the fact thatx∈XWPLU. HenceXWPLU⊆XWPLS.□The converse of above theorem is not valid as we show in the following example.Example 3.9For problem(4)minF(x)=([−x,0],[−xa,0])subjecttox∈R+,where a > 0. We claim that0∈XSPLS. On contrary assume that0∉XSPLS. Then by Definition 3.4, there exists x ≠ 0 inR+s.t,. F(x)⪯LSF(0). i.e.,([−x,0],[−xa,0])⪯LS([0,0],[0,0]).i.e.,f1S(x)=x≤0=f1S(0)andf2S(x)=xa≤0=f2S(0),which is a contradiction because x, a > 0. Hence0∈XSPLS. However0∉XSPLU,since there exists1∈R+s.t., F(1)≺LUF(0). Further from Remark 3.5, we have0∈XPLSand hence (ii) follows similarly. Again from Remark 3.5, we have0∈XWPLSbut0∉XWPLU,since there exists1∈R+,s.t., f1(1)≺LUf1(0) and f2(1)≺LUf2(0).Consider the following optimization problem(P)minf(x)=f(x1,…,xn),subjecttogi(x)≤0,i=1,…,m,where f, gi,i=1,…,mare real valued functions. LetX={x∈Rn:gi(x)≤0,i=1,…,m}be convex feasible set of (P).Definition 4.1(Wu, 2007) We say that the constraint functionsgi,i=1,…,msatisfy KKT assumptions at x* if giare convex onRnand are continuously differentiable at x*.In the rest of this paper, we shall assume that the feasible set X of the problem (MIP2) is a convex subset ofRnand the real valued constraint functionsgi,i=1,…,msatisfy KKT assumptions at x*.The well-known KKT conditions for (P) are as follows (Bazarra, Sherali, & Shetty, 1993).Theorem 4.1LetX={x∈Rn:gi(x)≤0,i=1,…,m}be a feasible set andx* ∈ X. Assume that the objective functionf:Rn→Ris convex and continuously differentiable atx*. If there exist (Lagrange) multipliers0≤μi∈R,i=1,…,m,such that the following KKT conditions hold.(i)∇f(x*)+∑i=1mμi∇gi(x*)=0;μigi(x*)=0,i=1,…,m.Thenx*is an optimal solution of problem (P).Next in this section we shall obtain KKT type optimality conditions for the optimization problem (MIP1) by using gH-differentiability of interval valued function. For this, consider the problem (MIP1) with the feasible setX={x∈Rn,gi(x)≤0,i=1,…,m},wheregi,i=1,…,mare real valued functions. i.e., (MIP2)minF(x)=(f1(x),…,fr(x)),subjecttogi(x)≤0,i=1,…,m.Definition 4.2Let f be an interval valued function defined on convex setX⊆Rn. Then(i)f is said to be LU-convex at x* ∈ X iff(λx*+(1−λ)x)⪯LUλf(x*)+(1−λ)f(x),λ∈(0,1)and x ∈ X. (Wu, 2007).f is said to be LS-convex at x* ∈ X iff(λx*+(1−λ)x)⪯LSλf(x*)+(1−λ)f(x),λ∈(0,1)and x ∈ X. (Chalco-Cano et al., 2013).Let f be an interval valued function defined on convex setX⊆Rn. Letx* ∈ X then the following statements hold true.(i)f is LU-convex if and only if fL and fU are convex atx*. (Wu, 2007).f is LS-convex atx*if and only if fL and fS are convex atx*. (Chalco-Cano et al., 2013).If f is LS-convex atx*then f is LU-convex atx*. (Chalco-Cano et al., 2013).Now we define the following.Definition 4.4Let F be an (interval) multivalued function defined on convex setX⊆Rnand let x* ∈ X. We say that(i)F is LU-convex at x* if each fkis LU-convex atx*,k=1,…,r.F is LS-convex at x* if each fkis LS-convex atx*,k=1,…,r.Let F be an (interval) multivalued function defined on convex setX⊆Rnand letx* ∈ X. Then we have the following properties.(i)F is LU-convex atx*if and only iffkLandfkUare convex atx*,k=1,…,r.F is LS-convex atx*if and only iffkLandfkSare convex atx*,k=1,…,r.F is LS-convex atx*then F is LU-convex atx*.(i) and (ii) follow immediately from Definition 4.4 and Proposition 4.3 and (iii) is the consequence of Proposition 3.8.□Assume that the (interval) multiobjective function F is continuously gH-differentiablex*andfkL,fkU,k=1,…,rare convex functions. If there exist (Lagrange) multipliers0<λk∈R,k=1,…,rand0≤μi∈R,i=1,…,msuch that the following KKT conditions hold.(i)∑k=1rλk∇(fkL+fkU)(x*)+∑i=1mμi∇gi(x*)=0,μigi(x*)=0,i=1,…,m.Thenx*∈XPLUandx*∈XPLSfor (MIP2)Since F is continuously gH-differentiable at x*, we see from Proposition 2.7 that the functionfkL+fkUis continuously differentiable at x* fork=1,…,r. We define a real valued function(5)f¯(x)=∑k=1rλk(fkL+fkU)(x)SincefkLandfkU,k=1,…,rare real valued convex functions, thereforef¯is convex and continuously differentiable function at x*, we have(6)∇f¯(x*)=∑k=1rλk∇(fkL+fkU)(x)Therefore from condition (i) and (ii), we arrive at(iii)∇f¯(x*)+∑i=1mμi∇gi(x*)=0;μigi(x*)=0,i=1,…,m.From Theorem 4.1, we see that x* is an optimal solution of real valued objective functionf¯subjected to the same constraints of (MIP2). i.e.,(7)f¯(x*)≤f¯(x)foreveryx∈X.Letx*∉XPLU. Then by Definition 3.1 there exist x ∈ X and 1 ≤ h ≤ r, such that fh(x)≺LUfh(x*). Therefore from (1) and (5) we see thatf¯(x)<f¯(x*)(sinceλk>0,k=1,…,r), which is a contradiction to (7). This shows thatx*∈XPLU. Hence from Theorem 3.1 we see thatx*∈XPLS. This completes the proof.□Assume that the (interval) multiobjective function F is continuously gH-differentiable and LU-convex atx*. If there exist (Lagrange) multipliers0<λk∈R,k=1,…,rand0≤μi∈R,i=1,…,msuch that the following KKT conditions hold.(i)∑k=1rλk∇(fkL+fkU)(x*)+∑i=1mμi∇gi(x*)=0,μigi(x*)=0,i=1,…,m.Thenx*∈XPLUandx*∈XPLSfor (MIP2).Since F is LU-convex at x* then by Proposition 4.5,fkL,fkU,k=1,…,rare convex at x*. Also since F is continuously gH-differentiable at x*, then from Proposition 2.7, we see that the functionsfkL+fkU,k=1,…,rare continuously differentiable at x*. This implies thatf¯is convex and continuously differentiable at x*. Then from Theorem 4.2 the result follows.□The following example shows the advantages of Theorem 4.2 over to Theorem 4.2 of Wu (2009).Example 4.7We consider the following optimization problem(8)minF(x)=(f1=[−|x|,|x|],f2=[−|x2|,|x2|]),subjecttox−1≤0,−x−1≤0.Since F is continuously gH-differentiable and the conditions of Theorem 4.2 are satisfied at 0. Therefore0∈XPLUfor problem (8) (Fig. 11). But F is not weakly continuously differentiable at 0, therefore Theorem 4.2 of Wu (2009) cannot be used.Utilizing the idea of LS-convexity (Definition 4.2) we prove the following result.Theorem 4.3Assume that the (interval) multiobjective function F is LS-convex atx*and (weakly) continuously differentiable atx*. If there exist (Lagrange) multipliers0<λkL,λkS∈R,k=1,…,rand0≤μi∈R,i=1,…,msuch that the following KKT conditions hold.(i)∑k=1rλkL∇fkL(x*)+∑k=1rλkS∇fkS(x*)+∑i=1mμi∇gi(x*)=0;μigi(x*)=0,i=1,…,m.Thenx*∈XPLSfor (MIP2).Consider the real valued function(9)f¯(x)=∑k=1rλkLfkL(x)+∑k=1rλkSfkS(x)Since F is LS-convex at x*, from Proposition 4.5fkL,fkS,k=1,…,rare convex at x*. Also since F is (weakly) continuously differentiable at x*, from Proposition 2.7,fkL,fkS,k=1,…,rare continuously differentiable at x*. Thereforef¯is convex and continuously differentiable at x*, we have∇f¯(x*)=∑k=1rλkL∇fkL(x*)+∑k=1rλkS∇fkS(x*).Therefore from condition (i) and (ii) we obtain(iii)∇f¯(x*)+∑i=1mμi∇gi(x*)=0;(iv)μigi(x*)=0,i=1,…,m.By using Theorem 4.1, we see that x* is an optimal solution of the real valued objective functionf¯subjected to same constraints of (MIP2). Now by using similar arguments as in the Theorem 4.2 we can show thatx*∈XPLSfor (MIP2).□In order to justify the validity of hypothesis of the Theorem 4.3, the following example is furnished.Example 4.8Consider the following programming problem.(10)minF(x)=([x12+x22+1,x12+x22+2],[2x12+2x22+3,2x12+2x22+4]),subjectto1−x1−x2≤0,6−3x1−x2≤0,x1,x2≥0.Then we havef1L(x)=x12+x22+1,f1S(x)=1,f2L(x)=2x12+2x22+3,f2S(x)=1,andg1(x)=1−x1−x2,g2(x)=6−3x1−x2.It is easy to see that the problem (10) satisfies the assumptions of Theorem 4.3. Now according to conditions (i) and (ii) of the theorem we consider the following expression.λ1L[2x12x2]+λ2L[4x14x2]+λ1S[00]+λ2S[00]+μ1[−1−1]+μ2[−3−1]=[00].That is we have to solve the following simultaneous equations:2λ1Lx1+4λ2Lx1−μ1−3μ2=0,2λ1Lx2+4λ2Lx2−μ1−μ2=0.On solving, we obtainx*T=(95,35),λ1L=12,λ2L=14,μ1=0,μ2=6/5Sincegi(x*)=0,i=1,2. Thereforex*T=(95,35)∈XPLSfor problem (10).Next we present some results for weakly Pareto optimal solutions.Theorem 4.4Assume that there is an interval valued function, sayfh,h∈{1,…,r},such that it is LU-convex and continuously gH-differentiable atx*. If there exist (Lagrange) multipliers0<λ∈Rand0≤μi∈R,i=1,…,m,such that the following KKT conditions hold.(i)λ∇(fhL+fhU)(x*)+∑i=1mμi∇gi(x*)=0,μigi(x*)=0,i=1,…,m.Thenx*∈XWPLUfor (MIP2).We define a real valued functionf¯(x)=λ(fhL+fhU)(x).Since fhis LU-convex at x*, from Proposition 4.3, we see thatfhL,fhUare convex at x*. Also since fhis continuously gH-differentiable at x* then by Proposition 2.5,fhL+fhUis continuously differentiable at x*, then the result follows from similar arguments of Theorem 4.2.□Assume that there is an interval valued function, sayfh,h∈{1,…,r},such that it is LS-convex and weakly continuously differentiable atx*. If there exist (Lagrange) multipliers0<λL,λS∈Rand0≤μi∈R,i=1,…,msuch that the following KKT conditions hold.(i)λL∇fhL(x*)+λS∇fhS(x*)+∑i=1mμi∇gi(x*)=0;μigi(x*)=0,i=1,…,m.Thenx*∈XWPLSfor (MIP2).We define a real valued functionf¯(x)=λLfhL(x*)+λSfhS(x*).Since fhis LS-convex at x*, from Proposition 4.3, we see thatfhL,fhSare convex at x*. Also since fhis weakly continuously differentiable at x* then by Proposition 2.5,fhL,fhSare continuously differentiable at x*, then the result follows from similar arguments of Theorem 4.4.□Next we present KKT conditions for (MIP2) using gradient of interval valued objective function f via gH-derivative. For this we consider an interval valued function f, then the gradient of f at x* is defined as follows∇gf(x*)=((∂f∂x1)g(x*),…,(∂f∂xn)g(x*)),where(∂f∂xj)g(x*)is jth partial gH-derivative of f at x*, as it is defined in Definition 2.4. We see from Theorem 2.1 that, if fLand fUare differentiable functions then f is gH-differentiable and in this case,(∂f∂xj)g(x*)=[min{∂fL∂xj(x*),∂fU∂xj(x*)},max{∂fL∂xj(x*),∂fU∂xj(x*)}]is a closed interval.Example 4.9Consider the interval valued functionf(x)=[2x1+3x22,x12+3x22+7].Then we have(∂f∂x2)g(x)=[min{2,2x1},max{2,2x1}],and(∂f∂x2)g(x)=[min{6x2,6x2},max{6x2,6x2}]=[6x2,6x2].So the gradient of f is given by∇gf(x)=([min{2,2x1},max{2,2x1}],[6x2,6x2]).Now if we consider H-derivative of f, then there is no partial derivative(∂f∂x2)H(0,1)and so there is no gradient of f. Thus the gradient of f using H-derivative is restrictive. Further if we consider that f as weakly continuously differentiable, then clearly we cannot talk about gradient as we cannot define partial derivative of f. Therefore the gradient of f using gH-derivative is more general and it is more robust for optimization as we show.Consider the following equation(11)∑k=1rλk∇gfk(x*)+∑i=1mμi∇gi(x*)=0,where0<λk∈R,k=1,…,r,0≤μi∈R,i=1,…,m,fk,k=1,…,rare continuously gH-differentiable functions andgi,i=1,...,mare continuously differentiable real valued functions, given in (MIP2). From Theorem 2.2,fL,fU,k=1,…,rare continuously differentiable at x*. Therefore 4.7 is equivalent to(12)∑k=1rλk∂fkL∂xj(x*)+∑i=1mμi∂gi∂xj(x*)=0=∑k=1rλk∂fkU∂xj(x*)+∑i=1mμi∂gi∂xj(x*),for allj=1,…,n. Equivalently (12) can be written as(13)∑k=1rλk∇fkL(x*)+∑i=1mμi∇gi(x*)=0=∑k=1rλk∇fkU(x*)+∑i=1mμi∇gi(x*),which also implies(14)∑k=1rλk∇fkL(x*)+∑i=1mλk∇fkU(x*)+∑i=1mμ¯i∇gi(x*)=0,whereμ¯i=2μi,i=1,…,m.Theorem 4.6Assume that the (interval) multiobjective function F is continuously gH-differentiable and LU-convex aty*. If there exist (Lagrange) multipliers0<λk∈R,k=1,…,rand0≤μi∈R,i=1,…,m,such that the following KKT conditions hold.(i)∑k=1rλk∇gfk(y*)+∑i=1mμi∇gi(y*)=0,μigi(y*)=0,i=1,…,m.Thenx*∈XPLUandx*∈XPLSfor (MIP2).Since (i) is equation (11) fory*=x*,which is equivalent to (14). That is∑k=1rλk∇fkL(y*)+∑k=1rλk∇fkU(y*)+∑i=1mμ¯i∇gi(y*)=0,whereμ¯i=2μi,i=1,…,m. Assume thatλkL=λk=λkU,k=1,…,r. Then the result follows from Theorem 4.2. This completes the proof.□Consider the following programming problem.(15)minF(x)=([x12,x12+x22],[x22,x12+x22]),subjecttox1+x2≤1,−x1≤0.Then we havef1L(x)=x12,f2L(x)=x22,f1U(x)=x12+x22,f2U(x)=x12+x22.Further,fkL,fkU,k=1,2are convex functions. Also the (interval) multiobjective function F is continuously gH-differentiable onR2. Moreover, the conditions (i) and (ii) of the Theorem 4.6 are satisfied atx*=(0,0). Therefore we see thatx*=(0,0)∈XPLUfor problem (15).Note that the Theorem 4.9 of Wu (2009) can not be used in problem (15) since the (interval) multiobjective function F is not H-differentiable at (0, 0). Therefore Theorem 4.6 is more general than Theorem 4.9 of Wu (2009).Bazarra et al. (1993) Let X be a non-empty feasible set and x* ∈ X. The cone of feasible directions of X at x* is defined as:D={d∈Rn:d≠0,thereexistsδ>0,suchthatx*+τd∈Xforallτ∈(0,δ)}andd∈Dis called feasible direction of X.(Bazarra et al., 1993) LetX={x∈Rn:gi(x)≤0,i=1,…,m}be the feasible set andx* ∈ X. Assume thatgi,i=1,…,mare differentiable atx*. LetI(x*)={i:gi(x*)=0}be the index set for the active constraints. ThenD⊆{d∈Rn:∇gi(x*)Td≤0foreachi∈I}.(Note that this proposition still holds if we just assume that gi are continuous atx*instead of differentiable atx*for i ∉ I).Let f be an interval valued function defined on non-empty convex subset X ofRn. We say that f is strictly L-convex (resp. L-convex) at x* if and only if fLis strictly convex (resp. convex) at x*. We can similarly define strictly U-convex (resp. U-convex) and strictly S-convex (resp. S-convex) by considering fUand fSrespectively.An interval valued function f is said to be(i)LU-decreasing at x* if x* < x if and only if f(x)≺LUf(x*). Wu (2009).LS-decreasing at x* if x* < x if and only if f(x)≺LSf(x*).Finally we present some results for strongly LU-Pareto optimal solutions and strongly LS-Pareto optimal solutions.The Tucker’s theorem of alternative is needed for the proof of the following theorem. It states that for given matrices P and Q, exactly one of the following system has a solution:System 1: Px ≤ 0, Px ≠ 0, Qx ≤ 0 for somex∈Rn;System 2:PTλ+QTμ=0for someλ> 0 andμ≥ 0.Theorem 4.7Assume that there is an interval valued function, sayfh,h∈{1,…,r}such that it is one to one and LU-decreasing, and it is U-convex and continuously gH-differentiable atx*. Also assume that∇fhL(x*)<∇fhU(x*). If there exist (Lagrange) multipliers0≤μi∈R,i=1,…,msuch that the following KKT conditions hold.(i)∇fhL(x*)+∑i=1mμi∇gi(x*)=0,μigi(x*)=0,i=1,…,m.Thenx*∈XSPLUfor (MIP2).Suppose thatx*∉XSPLU,then by Definition 3.1 there exists x ∈ X such that fh(x)⪯LUfh(x*). Since fhis U-convex at x* therefore we have, fUis convex at x*. Hence we see that∇fhU(x*)T(x−x*)≤0.Also,∇fhL(x*)<∇fhU(x*)and since fhis one to one and LU-decreasing, we havex¯−x*>0. Therefore we obtain∇fhL(x*)T(x−x*)<∇fhU(x*)T(x−x*)≤0. Thus we have(16)∇fhL(x*)T(x−x*)<0Letd=x−x*theny=x*+τd=τx+(1−τ)x*∈Xfor τ ∈ (0, 1), since X is a convex set and x, x* ∈ X, this shows thatd∈D,a feasible direction of X. Therefore from Proposition 4.14 we conclude that(17)∇gi(x*)Td≤0foreachi∈I.Where I is index set of active constraints. Let P be the matrix whose rows are∇fhL(x*)Tand Q be the matrix whose rows are ∇gi(x*)T, i ∈ I. Then by using Tucker’s theorem of alternatives we see thatd=x−x*solves system 1. Therefore from (16) and (17) we conclude that there exist no multipliers0<λ∈Rand0≤μ¯∈R,i∈Isuch thatλ∇fhL(x*)+∑i∈Iμ¯i∇gi(x*)=0,which is equivalent to∇fhL(x*)+∑i∈Iμi∇gi(x*)=0,whereμi=μ¯iλ,i∈I. Which is a contradiction to the conditions (i) of the theorem by assuming thatμi=0for i ∉ I. This completes the proof.□The following theorem follows on similar lines.Theorem 4.8Assume that there is an interval valued function, sayfh,h∈{1,…,r}such that it is one to one and LS-decreasing, and it is L-convex (resp. S-convex ) and continuously gH-differentiable atx*. Also assume that∇fhS(x*)<∇fhL(x*)(resp.∇fhL(x*)<∇fhS(x*)). If there exist (Lagrange) multipliers0≤μi∈R,i=1,…,msuch that the following KKT conditions hold.(i)∇fhS(x*)+∑i=1mμi∇gi(x*)=0; (resp.∇fhL(x*)+∑i=1mμi∇gi(x*)=0);μigi(x*)=0,i=1,…,m.Thenx*∈XSPLSfor (MIP2).

@&#CONCLUSIONS@&#
In this paper, we have considered two order relations on interval space, viz. LU and LS relations, which incorporates quantitative properties of width (noise, risk, etc.). Also by using gH-derivative for interval valued functions we have obtained KKT conditions for multiobjective programming problems with interval valued objective functions considering LU and LS order relations. For the case of order relation LU the results obtained are more general then those results obtained in Wu (2009) and for the order relation LS, the results obtained are novel. Moreover, we have considered the gradient for interval valued functions using gH-derivative and have used this to obtain KKT optimality conditions. These results are more general than other similar results obtained using H-derivative and consequently, gradient of interval valued function is more general using gH-derivative.Although the equality constraints are not considered in this paper we can use similar methodology proposed in this paper to handle equality constraints. The constraint functions in this paper are still real valued, in future research, we may extend the constraint functions as the interval valued functions.