@&#MAIN-TITLE@&#
Wize Mirror - a smart, multisensory cardio-metabolic risk monitoring system

@&#HIGHLIGHTS@&#
A multi-sensor device for health self-monitoring and assessment is proposed.A real-time head pose estimation and tracking method is introduced.An inexpensive 3D scanner facilitating facial morphology analysis is described.Face 3D shape analysis facilitates tracking changes in weight and BMI index.The evaluation of stress and anxiety seems possible using dynamic facial features.

@&#KEYPHRASES@&#
Unobtrusive health monitoring,3D face detection,Tracking and reconstruction,3D morphometric analysis,Psycho-somatic status recognition,Multimodal data integration,

@&#ABSTRACT@&#
In the recent years personal health monitoring systems have been gaining popularity, both as a result of the pull from the general population, keen to improve well-being and early detection of possibly serious health conditions and the push from the industry eager to translate the current significant progress in computer vision and machine learning into commercial products. One of such systems is the Wize Mirror, built as a result of the FP7 funded SEMEOTICONS (SEMEiotic Oriented Technology for Individuals CardiOmetabolic risk self-assessmeNt and Self-monitoring) project. The project aims to translate the semeiotic code of the human face into computational descriptors and measures, automatically extracted from videos, multispectral images, and 3D scans of the face. The multisensory platform, being developed as the result of that project, in the form of a smart mirror, looks for signs related to cardio-metabolic risks. The goal is to enable users to self-monitor their well-being status over time and improve their life-style via tailored user guidance. This paper is focused on the description of the part of that system, utilising computer vision and machine learning techniques to perform 3D morphological analysis of the face and recognition of psycho-somatic status both linked with cardio-metabolic risks. The paper describes the concepts, methods and the developed implementations as well as reports on the results obtained on both real and synthetic datasets.

@&#INTRODUCTION@&#
A healthy lifestyle has become universally recognized as a key factor in disease prevention. Efforts at promoting lifestyle improvements are now considered as a viable and effective way for reducing the incidence of pathologies, such as cardiovascular diseases and metabolic disorders. This coupled with the more active role people aspire to have, so as to shift from passive recipients of care towards actively managing their own health, has opened a new important prevention realm for the assistive technologies. The health related self-monitoring and self-assessment are gaining momentum. Many personal well-being and fitness monitoring tools are available on the market, mainly in the form of wearable devices such as wristbands, smart-watches, eye wear and wearable bio-monitors, as well as dedicated apps on smart-devices such as MyFitnessPal, Endomondo, Argus, Googlefit. It has been shown that these technologies are predominantly embraced by the younger generation (25–34 years old) focused on fitness, and the older users (55–64 years old) mainly interested in improving overall health with the aim of improving the quality of life and the life expectancy. Interestingly, in contrast with the increasing acceptance of wearables, many of consumers stop using the device within six months. In other words, in many cases these tools fail to drive long-term, sustained engagement and as a consequence, they fail to make a long-term impact on their users’ health. The authors believe that the key to successful deployment of self-assessment technologies is sustained engagement, based on the promotion of behaviour change towards holistic wellness. Enhancing wellness is an effective way to promote participation and motivate people to change their habits. It is in this context that the European project SEMEOTICONS (SEMEOTICONS, 2013) has been launched. SEMEOTICONS started in November 2013, challenged with the development of a multisensory device in the form of a mirror, called the Wize Mirror, which comfortably fits at home, as a piece of house-ware, but also in pharmacies or fitness centres. By analysing data acquired unobtrusively via a suite of contactless sensors, the Wize Mirror detects on a regular basis physiological changes relevant to cardio-metabolic risk factors. The computation and delivery of a comprehensive Wellness Index enables individuals to estimate and track over time their health status and their cardio-metabolic risk. Finally, the Wize Mirror offers personalized guidance towards the achievement of a correct lifestyle, via tailored coaching messages. The Wize Mirror is designed to meet the two main objectives: stimulating initial adoption and utilization, by providing a positive usage experience; and supporting long-term engagement, by helping people to establish new positive habits. To this end, the main features of the Wize Mirror are: facilitation of daily unobtrusive monitoring; automatic assessment of physiological conditions via advanced integrated sensing and data processing algorithms as well as promotion of sustained behaviour change towards long-term wellness objectives. These functionalities are developed by integrating theories, methods and tools from different disciplines including: computer science, physics, engineering, medicine, psychology, motivation and communication science, social marketing, behavioural theories, and economics.From the technological perspective the Wize Mirror is a multisensory platform in the form of a smart mirror (see Fig. 1) integrating different sensors, including: 3D optical scanner, multispectral cameras and gas detection sensor, collecting multidimensional data of individuals standing in front of the mirror. These data are processed by dedicated algorithms, which extract a number of biometric, morphometric and colorimetric descriptors, including: AGE- product concentration, cholesterol level, endothelium function, heart rate, heart rate variability, face morphometric parameters as well as indicators of stress, anxiety and fatigue levels. The descriptors are integrated to define a virtual individual model for a wellness index traced over time. The Wize Mirror also offers suggestions and coaching messages, with personalized user guidance, aimed at achieving and then maintaining a healthy life-style.The guiding principle behind the design of the Wize Mirror has been that it should easily fit into daily-life settings, by maximising non-invasive and unobtrusive interaction with the users. The focus of this paper is on a subset of sensors, methods and processes deployed on the Wize Mirror using medical semeiotics signs. The principle of medical semeiotics considers the face as an important source of information about the health status of individuals, produced by the combination of physical signs and expressive features. Currently, based on their experience, medical doctors acquire the ability of reading and interpreting the complex semeiotic signs of patients’ faces. These signs usually suggest how to conduct the medical examination and may contribute to the diagnosis. The paper describes a novel set of techniques developed and implemented to acquire and analyse semiotics signs. More specifically the paper describes the processing pipeline enabling face detection, tracking, partition and 3D reconstruction. Whereas the robust real-time face detection and partition facilitates the described analysis of stress and anxiety forming the psycho-somatic descriptor of the cardio-metabolic risk, the 3D reconstruction provides required information for the estimation of the described overweight and obesity index forming part of the morphometric descriptor of the cardio-metabolic risk. Fig. 2gives a visual explanation of the processing pipeline. The performance of the proposed techniques is examined in some depth on real and synthetic datasets.The description of an overall concept of the inexpensive device for self-monitoring and assessment of well-being to promote, improve and maintain a healthy lifestyle is the key novel contribution of this paper. The other technical contributions are linked to different subsystems integrated on the mirror, these include: use of the Kalman filter in conjunction with the random forest for face pose predictions; the processing pipeline integrating face tracking, 3D pose estimation, segmentation, range data scans alignment and fusion for efficient and robust 3D face reconstruction; estimation of body weight and body weight variations using geometric features extracted from the 3D reconstruction of the face; the fusion of motion features from different facial areas for the assessment of the psychological state with focus on stress and anxiety.The remainder of the paper is organised as follows. Section 2 reports on the state of the art of the methods involved in the cardio-metabolic and psycho-somatic analyses performed in this work. Section 3 and 4 provide details about the techniques employed for face pose estimation, tracking, face segmentation and 3D reconstruction. Section 5 shows how the morphological analysis of the face is carried out for assessing cardio-metabolic risks and Section 6 describes the estimation of the face signs used for recognising different psycho-somatic states. Finally, Section 7 summarises the main conclusions of the work presented.Typically, 3D face reconstruction methods integrate raw data from different sensors (colour and/or depth) into a point cloud to produce a 3D face representation. In order to avoid points which belong to the background or the other body parts, 3D head pose estimation and tracking is needed to select the relevant information for processing. By using the pose estimation a face segmentation can be effectively preformed reducing errors in the reconstruction phase. Additionally, the pose estimation and tracking provide information, needed for face normalization and partition, facilitating operations of other subsystems on the mirror, including stress and anxiety analysis as well as multi-spectral measurements.Head pose estimation and 3D tracking play an important role in the automatic face analysis as an essential pre-processing step. There has been a plethora of methods proposed in literature to solve this problem  (Murphy-Chutorian and Trivedi, 2009). Although it is possible to estimate the 3D head pose using only 2D images  (Raytchev et al., 2004), the robustness and accuracy of these methods may not be suitable for many practical applications. On the other hand the pose estimation based on 3D data  (Smeets et al., 2013) could be very robust and accurate, but the 3D data acquisition is costly and computationally intensive. Indeed, the 3D face reconstruction is more challenging than the head pose estimation. The recent advances in range data (2.5 D) sensing technologies and analysis seem to facilitate a suitable compromise between cost, performance and system complexity. The range/depth sensors are getting cheaper, more reliable and widely used. For that reason, the range data is becoming the modality of choice for solving different detection and estimation problems. For example, there are approaches which use the range data in combination with 2D image data. The method explained in  Cai et al. (2010) relies on a regularized maximum likelihood deformable model. The work described in  Seeman et al. (2004) is a neural network based system which runs at 10 fps. The approach introduced in  Bleiweiss and Werman (2010) is model-based and it can maintain real-time performance. The method in  Newcombe et al. (2011) is based on the active appearance model (AAM) and a depth-based constraint. It provides real-time tracking of human faces in 2D and 3D. The mentioned method introduced a new constraint into AAM that uses depth data from sensors like Kinect. To initialise the AAM fitting in each frame, an optical feature tracking is used to provide a location close to the target to improve the convergence. The 3D location accuracy is improved by introducing a depth fitting energy function, which is formulated in a similar way to the iterative closest point algorithm (ICP) (Besl and McKay, 1992). Moreover, the colour-based face segmentation is replaced with the depth-based face segmentation and an L2-regularization term. Using solely depth data, there are methods such as the one described in  Fanelli et al. (2011), enabling a real time 3D head pose estimation using consumer depth cameras. That method uses a random regression forest to estimate the pose. The forest regression can be combined with the Kalman filter as described in Mou and Wang (2012), where the Kalman filter is used to refine the noisy regression result. Another approach, which is based on particle swarm optimization is described in Padeleris et al. (2012). Real-time performance is achieved by the methods introduced in  Malassiotis and Strintzis (2005) and  Choi et al. (2014). The approach in  Malassiotis and Strintzis (2005) uses global features and exploitation of prior knowledge along with feature localization and tracking techniques. In the work reported in Choi et al. (2014) a 3D face model is generated from a single frontal image. Then uniformly distributed random points are extracted and tracked in 2D. Given the correspondences, the 3D head pose is estimated using a RANSAC-PnP process. For the low-cost depth cameras, one of the most widely used methods is described in  Newcombe et al. (2011). That system is able to accurately map complex and arbitrary indoor scenes in variable lighting conditions. All the input depth data is fused into a global surface model in real-time. The sensor pose is estimated by tracking the global model using a coarse-to-fine iterative closest point (ICP) algorithm, and the data fusion is performed by means of a truncated signed distance function (TSDF). Due to the relatively good results obtained by the low-cost depth cameras, they have become a popular choice for face reconstruction, where a great variety of methods can be found, such as ones described in  Hernandez et al. (2015); Huang et al. (2013); Macedo et al. (2013); Zollhofer et al. (2011). The authors of Macedo et al. (2013) presented an extension of the algorithm from  Newcombe et al. (2011) to perform a real-time face tracking and modelling. They proposed changing two steps of the original algorithm, pre-processing and tracking. In the pre-processing stage a face detection algorithm is used to segment the face from the rest of the image. For the tracking, they included an algorithm to solve occlusions and real-time head pose estimation to give a new initial guess to the ICP algorithm when it fails. Marching cubes is another well-known technique for reconstruction and modelling. The system developed in  Huang et al. (2013) can automatically detect the face region and track the head pose while incrementally integrating the new data in a model. ICP is used for tracking the head pose, then, a volumetric integration method is used to fuse all the data. Afterwards, a ray casting algorithm extracts the final vertices of the model and marching cubes algorithm is used to generate the polygonal mesh of the reconstructed face model. The method in Hernandez et al. (2015) produces face models from a freely moving user without relying on any prior face model. The face is represented in cylindrical coordinates in order to perform filtering operations. The reconstruction is initialized with a depth image, and then the subsequent point clouds are registered to the reference one using ICP. Temporal and spatial smoothing are applied to the updated model. Most of the methods rely on ICP rigid registration algorithm, however, the approach in  Zollhofer et al. (2011) introduces the advantages of using a robust non-rigid registration and a deformable model.Back in 1942, D’Arcy Wentworth Thompson expressed the importance of investigating biological form in a fully quantitative manner (Thompson, 1942):The study of form may be descriptive merely, or it may become analytical. We begin by describing the shape of an object in the simple words of common speech: we end by defining it in the precise language of mathematics; and the one method tends to follow the other in strict scientific order and historical continuity.We may say that D’Arcy Thompson’s vision has come true: in the last century, morphometrics came of age, as the discipline dealing with the quantitative study of form Reyment (1996). In medicine, information about body size and shape has been used traditionally by physicians to assess health or nutritional status and guide treatment, and many efforts have been put to recognize the facial gestalt of some dismorphic syndrome (Hammond, 2007). However, most of the studies correlating anthropometric measurements with cardio-metabolic risk deal with the body rather than the face.Simple parameters such as the waist circumference and the abdominal sagittal diameter are known to correlate well with the body fat and have been used as predictors for metabolic disorders and cardiovascular risk (Li et al., 2007). The anthropometric measurements collected by a 3D scanner were recently correlated with metabolic parameters in validation studies (Lin et al., 2004; Wang et al., 2006; Wells et al., 2008). A relevant drawback is that these tools are not standardized: parameters strongly depend on the acquisition device and on the subject pose, and do not provide a complete characterization of the body. Interesting results are presented by Velardo and Dugelay (2010): a model for the weight estimation is retrieved via multiple regression on a set of anthropometric features exploiting a large medical dataset for the model training, and validating the method both in ideal and real conditions; here the set of geometric body measurements used is extracted from the 2D body silhouette. More recently Giachetti and colleagues in Giachetti et al. (2015) presented a pipeline for the automatic extraction of health-related geometrical parameters from heterogeneous body scans. Their aim was the computation of parameters independent of the precise location of anatomical landmarks. The parameters computed included total body mesh volume and area, trunk volume and area, maximal and minimal trunk width, maximal trunk section radius and area, eccentricity of an ellipse approximating the body. They correlated the parameters with body fat values estimated with a DXA (Dual-energy X-rays Absorptiometry) scanner, and found that several values were highly correlated with total body less head (TBLH) fat and trunk fat. Moreover, in Velardo et al. (2012) an automatic vision-based system was proposed for estimating the subjects’ absolute weight from a frontal 3D view of the user, acquired through a low cost depth sensor. Potential applications include extreme environments and circumstances in which a standard scale cannot work or cannot be used: in the space for monitoring astronauts’ weight, or in the hospitals, for medical emergencies.Concerning faces, there is no consensus in the literature about which are the facial morphological correlates of body fat. A study reported the relationship between facial adiposity and Visceral Obesity (VO) and suggested that facial characteristics, such as cheek fat, are indicators of insulin resistance (Sierra-Johnson and Johnson, 2004). An increase in some facial dimensions was observed in a study about the face morphology of obese adolescents (Ferrario et al., 2004): the authors observed that the face of obese adolescents was wider transversally, deeper sagittally and shorter vertically than matched controls. Djordjevic et al. (2013) reports an analysis of the facial morphology of a large population of adolescents under the influence of confounding variables. Though the statistical univariate analysis showed that four principal face components (face height, asymmetry of the nasal tip and columella base, asymmetry of the nasal bridge, depth of the upper eyelids) correlated with insulin levels, the regression coefficients were weak and no significance persisted in the multivariate analysis.The authors in Lee et al. (2012) proposed a prediction method of normal and overweight females based on BMI using geometrical facial features only. The features, measured on 2D images, include Euclidean distances, angles and face areas defined by selected soft-tissue landmarks. The study was completed in Lee and Kim (2014) by investigating the association of visceral obesity with facial characteristics, so as to determine the best predictor of normal waist and visceral obesity among these characteristics. Cross-sectional data were obtained from over 11 thousand adult Korean men and women aged between 18 and 80 years. The study in Lee and Kim (2014) was the starting point of our research. We started by reproducing and evaluating the measurements on 3D data, then we added measures specifically defined on the 3D surface.Psychologists and biomedical scientists have studied stress intensively for over 60 years, and the concept of stress has been the subject of scientific debate ever since its first use in physiological and biomedical research (Selye, 1950). Stress was originally defined as the non-specific response of the body to any unpleasant stimulus. Later, the concept was refined by distinguishing between the terms ‘stressor’ and ‘stress response’: a stressor is a stimulus that threatens homoeostasis and the stress response is the reaction of the organism aimed to regain homeostasis (Koolhaas et al., 2010). Stressful events cause dynamic changes in the human body. They can be observed by changes in the body’s response signals, involuntary caused by the autonomic nervous system. Stress has a severe impact on the immune and cardiovascular systems if it is sufficiently powerful to overcome defence mechanisms, (Sharma and Gedeon, 2012). Nevertheless, the stress response evolved to help individuals survive, so that a lack of a sufficient stress response can often result in an inability to cope with a stressor (Romero, 2004). When a person is under stress, an increased amount of stress hormones are released, accompanied by changes in heart rate, blood pressure, pupil diameter, breathing pattern, galvanic skin response, emotion, voice intonation and body pose. Common techniques for detecting stress include the analysis of physiological signals such as the electroencephalograph, blood volume pulse, heart rate variability, galvanic skin response and electromyograph (Sharma and Gedeon, 2012). The manifestation of stress through visible facial expressions enables non-invasive techniques for detecting and analysis (Sharma and Gedeon, 2012). Facial muscle movements, such as head and mouth movements, have been used to determine stress. Eye gaze spatial distribution, saccadic eye movements, pupil dilation, blink rates, eyebrow movements and mouth deformation are features able to show stress presence (Sharma and Gedeon, 2012). In addition, jaw clenching, grinding teeth, trembling of lips, and blushing are also signs of stress (The American Institute of Stress, 2015c).Anxiety is a very common psychosomatic state, felt as an unpleasant mood characterized by thoughts of worry or fear (Harrigan and O’Conell, 1996; Shin and Liberzon, 1996). A person experiencing anxiety has thoughts that are actively assessing a certain situation, sometimes even automatically and outside of conscious attention, and developing predictions of how well they will cope based on past experiences. People with anxiety disorders may also have recurring intrusive thoughts or concerns that may lead to avoiding certain situations out of worry. They may also have physical symptoms such as sweating, trembling, dizziness or a rapid heartbeat (Anxiety, 2015a). Anxiety has been shown to inhibit social relationships, to impede cognition, learning and performance, to contribute to psycho-physiological disorders and is the primary symptom of a variety of disorders. Indeed, dysfunctional levels of anticipation appear to manifest in a number of anxiety disorders including specific phobia, generalized anxiety disorder, social anxiety disorder and panic disorder (Harrigan and O’Conell, 1996). Individuals with elevated anxiety are more likely to have a wide array of medical conditions than those without anxiety, including cardiovascular, autoimmune, and neuro-degenerative diseases, and are at greater risk of early mortality (Niles et al., 2015). Anxiety and depressive disorders are linked to a higher cardio-metabolic risk and a higher incidence of acute cardiovascular events (Sardinha and Nardi, 2012). Given the impact and the frequency with which anxiety occurs, it is critical to investigate its manifestations, particularly those which may reveal anxiety indirectly through non-verbal indices, such as facial movements. Research in non-verbal manifestation of anxiety is not very common (Chiarugi et al., 2014). Ekman and Friesen (1971) reported that, when a negative effect is experienced, it is often masked by another effect that the individual considers more appropriate. Anxiety is a composite effect with a strong connection to fear and therefore, when someone is anxious, we expect to identify facial movements related to fear such as raised eyebrows, stretched lips horizontally, raised and tensed upper eyelid which widens the eye, lip bite, lip wipe and increased eye movement  (Ekman and Friesen, 1971). Other anxiety specific manifestations are shared with stress, such as increased eye blink rate (Harrigan and O’Conell, 1996) and shortened breath (Anxiety, 2015b). Increased blinking is associated with increased sympathetic nervous system activity that increases involuntary responses when people are emotionally aroused (Harrigan and O’Conell, 1996), as a result, during anxiety the overall activity of facial muscles increases (Gunes and Piccardi, 2007).The proposed approach is based on processing single depth data frame at a time, using a random forest model for face detection and face/head pose regression (Fanelli et al., 2011) and then applying the Kalman filter tracking (Henriquez et al., 2014) to the results from random forest pose regression. As result the random noise of the pose estimates are reduced leading to smoother pose trajectories. Finally, a personalised mask alignment is performed to further improve accuracy of the face pose estimates. The multi-level iterative closest point algorithm registration (Quan et al., 2010) method is applied for face alignment. The personalised mask construction process is explained in Section 4. The proposed face tracking has been designed to track the face pose in real-time within a depth image sequence from the depth sensor. The implemented approach relies on algorithms which are not computationally expensive. The high computational complexity is only required in the training phase, but this phase is performed off-line. Therefore, a face pose can be estimated in each video frame in real-time using a single core processor (2GHz). The face pose tracking results are subsequently used for 3D face reconstruction, described in Section 4, which in turn is used in the face morphological analysis for cardio-metabolic risk assessment (see Section 5). The face pose is also used to perform face partition required as a preprocessing step for the stress and anxiety analysis described in Section 6.In the first stage of the face tracking process, the face pose is estimated using the approach described in Fanelli et al. (2011). A discriminative random regression forest is used to classify depth image patches between two different classes (face or no face) and perform a regression in the continuous spaces of position and orientation. The trees in the forest are trained to maximise two different measures (classification and regression). The data used for training are depth images captured with the Kinect sensor. Each one is labelled with the 3D face pose (x, y, z, pitch, yaw, roll). The optimisation function consists of two main parts as it is shown in Eq. 1, the class uncertainty UCand the regression entropy UR. There are also other parameters such as the depth of the node d, and a λ parameter to balance the importance of classification and regression depending on the depth of the tree node.(1)argmaxk(UC+(1.0−e−dλ)UR).Once the training has been done, the resulting forest can be used for classification and regression of the face pose from a depth image. This process consists of extracting several patches from the image and passing them through the forest. At the nodes, each patch is tested with the sub-patch combination generated in the training stage and continues to the left or right depending on the test result. The test function (Eq. 2) includes F1 and F2 sub-patches size, integral images of these sub-patches (I(q)) and the threshold (τ).(2)|F1|−1∑q∈F1I(q)−|F2|−1∑q∈F2I(q)≥τ.When a patch arrives at a node, the sub-patches are extracted and their integrals are calculated. Depending on the result, the patch is sent left or right. When the sample arrives at a leaf, it produces one vote encoded by the information stored in that leaf. The leaf could be a face leaf or a non-face leaf. After all the patches have passed through all the trees, all the votes are processed by a bottom-up clustering to remove outliers. All the votes inside the distance of the average head diameter are grouped together. Then 10 mean shift iterations are executed in order to localise the centroid of the clusters. Afterwards, if the number of votes exceeds the threshold, a face is considered as detected. The pose result is obtained from the mean of the values stored in the leaves whose votes were selected.The pose parameters, as estimated by the algorithm described in the previous section, are often noisy when they are applied to individual images in a video sequence. This is due to the detection was performed without imposing any temporal constraints. To reduce the random error in the pose estimation and to avoid some missed detections, a tracking method is used for processing of video sequences. This method is explained in detail in Henriquez et al. (2014). The method uses the Kalman filter to perform head pose tracking, by filtering the measurements provided by the face detector. Additionally, it can detect outliers and handle the missing measurements and introduces adaptive covariance estimation, which is useful, for example, when the average head movement speed varies. The noise covariance is updated based on the variance estimates of the most recent measurements using a sliding window.This section describes a technique developed for alignment of a personalised 3D mask to the depth data using the iterative closest point (ICP) registration algorithm  (Quan et al., 2010). Such mask alignment is used in order to further increase pose estimation accuracy. The personalised mask is built for each user, utilising the 3D reconstruction algorithm described in Section 4. When the face is detected in the 3D space, the personalised mask is translated and rotated using the pose parameters calculated in the tracking stage. The rotation matrix is defined by the three Euler angles, and the translation vector containing the coordinates of the head centre (x, y, z). All the points belonging to the mask are transformed by using a rigid transformation model. After applying the transformation estimated by the tracker, the mask can fit the input data or being slightly misaligned (see Fig. 3) due to the error in the face pose estimation. To tackle this problem, the location and orientation are refined by applying a rigid registration process between the personalised mask and the input depth data using the correspondence search.For 3D face alignment the real-time processing was achieved as result of a relatively small number of corresponding points used. With the face pose estimation, the 3D model is initialized close to a correct matching position. Additionally, the random sampling is used in the multi-resolution registration scheme, reducing even more the number of correspondences to be estimated. Random sampling improves also convergence due to reduced correlation bias between points used at the different resolution levels (see Fig. 4). Furthermore, in order to keep the real-time processing constraint at a high frame rate, only four iterations of the ICP are executed as the results showed to be suitable for the post-processing by other functionalities of the system.

@&#CONCLUSIONS@&#
This paper describes a part of the work and the results obtained within the framework of the European SEMEOTICONS (2013) project. The aim of the project is to develop a system which monitors the user’s well-being over a period of time and provides suggestions to improve and maintain a healthy lifestyle. The challenge is to create a non-intrusive platform able to acquire multimodal data to detect signs of cardio-metabolic risks. In particular, the techniques presented in this paper make possible to analyse the morphology of the face in 3D and to recognise the psycho-somatic status of the person in front of the mirror.The important aspect of the project is to design and develop an inexpensive system so it could be deployed in a home environment. This prerequisite imposed a set of constraints on the design, in particular the system has to be constructed using affordable sensors. From the output of these sensors, a 3D reconstruction of the face is created and the face is tracked. The proposed face 3D tracking, based on depth data, has shown to be robust, providing good results for face detection accuracy and face spacial position estimation. The tracking is performed in real time, which is a requirement for the subsequent processing of the Wize Mirror multisensory data. This includes analysis of stress and anxiety, both described in the paper, but also multispectral measurements not discussed in this paper. Additionally, the use of the depth sensor has two more advantages: it can be used as a primary sensor for creating 3D face reconstructions, making the mechanical design simpler; and the face pose estimation can be done just once in 3D space with subsequent projections of the estimated 3D pose onto 2D coordinates of the remaining Wize Mirror image sensors.The proposed 3D reconstruction methodology has been shown to have the required properties, including high repeatability. Suitable results have also been obtained for the 3D face morphological analysis. It has been shown that the described features are able to appropriately encode the fat level. Using such features, a regular pattern is produced which can be used to analyse the fattening of the individual. Hence, via 3D shape analysis, it is possible to automatically assess the weight gain which is one of the main factors of cardio-metabolic risk.Regarding the analysis of stress and anxiety, the proposed algorithms successfully extracted signs of those conditions. Particularly, the signs considered are the eyelid motion, the mouth activity and the head motion. The presented algorithms show the capability of detecting and properly measuring the indicated facial signs with a high accuracy. These signs can then be employed to classify different psycho-somatic states.The work presented shows that having a lifestyle-compatible device for health self-monitoring and self-assessment is a reality. Moreover, the users will not need to change their habits or interact much with the mirror in order to get a wellness assessment. The process of acquiring data is performed while the users are standing in front of it, possibly as a part of their daily routine. In the current implementation, most of the acquisitions require a very short time, from just a couple of seconds for 3D reconstruction, to one minute for emotion recognition. This non-obstructive characteristic is a key requirement for the successful deployment of a self-assessment system.