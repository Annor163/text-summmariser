@&#MAIN-TITLE@&#
Position computation models for high-speed train based on support vector machine approach

@&#HIGHLIGHTS@&#
We increase the positioning accuracy of high-speed train in a new view of advanced computing methods.We formulate a mathematical model based on the analysis of wireless message from train control system.Three positioning computation models and their parameter updating methods are developed.Although LSSVM-based model performs almost the same as SVM-based model, both of them perform much better than the LSM-based model.LSSVM-based model with parameter updating method performs the best among the three models for the online positioning for high-speed trains.

@&#KEYPHRASES@&#
High-speed train,Support vector machine,Least square support vector machine,Positioning error,

@&#ABSTRACT@&#
High-accuracy positioning is not only an essential issue for efficient running of high-speed train (HST), but also an important guarantee for the safe operation of high-speed train. Positioning error is zero when the train is passing through a balise. However, positioning error between adjacent balises is going up as the train is moving away from the previous balise. Although average speed method (ASM) is commonly used to compute the position of train in engineering, its positioning error is somewhat large by analyzing the field data. In this paper, we firstly establish a mathematical model for computing position of HST after analyzing wireless message from the train control system. Then, we propose three position computation models based on least square method (LSM), support vector machine (SVM) and least square support vector machine (LSSVM). Finally, the proposed models are trained and tested by the field data collected in Wuhan-Guangzhou high-speed railway. The results show that: (1) compared with ASM, the three models proposed are capable of reducing positioning error; (2) compared with ASM, the percentage error of LSM model is reduced by 50.2% in training and 53.9% in testing; (3) compared with LSM model, the percentage error of SVM model is further reduced by 38.8% in training and 14.3% in testing; (4) although LSSVM model performs almost the same with SVM model, LSSVM model has advantages over SVM model in terms of running time. We also put forward some online learning methods to update the parameters in the three models and better positioning accuracy is obtained. With the three position computation models we proposed, we can improve the positioning accuracy for HST and potentially reduce the number of balises to achieve the same positioning accuracy.

@&#INTRODUCTION@&#
The high-speed railways (HSRs) have been recognized by the world because of its obvious advantages in high-speed, punctuality and energy-saving [1]. In recent years, HSRs have experienced a rapid development around the world. Furthermore, there are many countries in the world that have developed HSRs to connect major cities, such as Japan, Germany, China, etc. [2].The first HSR, Tokaido Shinkansen, went to commercial operation with the speed of 210km/h in 1964 in Japan [3,4]. E5 series trains were introduced to commercial operation with a speed of 320km/h on March 2011 in Japan. Currently, the length of HSR network in Japan reaches 2387.7km [5]. In Germany, the third generation of Inter City Express(ICE) was tested at the speed of 350km/h in 2006, but with a service speed of around 330km/h at present [6,7]. In 1999, China started to construct the first HSR line. On August 1st 2008, the Beijing-Tianjin Intercity HSR was opened in time for the Beijing Olympic Games with a distance of 117km [8,9]. Moreover, with a operation speed of 350km/h, it has set the record for the fastest high-speed train(HST) in the world at that time. On December 26th 2009, Wuhan-Guangzhou HSR (WG_HSR), connecting two major cities in China, was put into commercial operation at the speed of 350km/h. And the total length of WG_HSR is 1068.8km, which was the fastest and longest HSR in the world at that time. At the end of 2011, China has the world's longest HSR network with a length of 8358km, which is expected to reach 32,000km by the end of year 2015 [10,11].As the operation speed of HST increases, positioning accuracy is becoming more and more important for the train control system. On one hand, high-accuracy positioning of HSR is a key point for ATP (Automatic Train Protection) in calculating protective curves to guarantee the safe operation of the train. On the other hand, the accuracy of positioning partially determines the minimum distance between adjacent HSTs, which greatly affects the operation efficiency of HSR. At present, the real-time positioning of HST mainly relies on track circuit along the railway line and on-train speed sensors [12,13]. Positioning accuracy is very low based on track circuits only, the existence of speed sensors is able to obtain continuous position. However, there is still a big accumulated error resulting from wheel idling and slipping in this positioning method. In Ref. [14], the authors proposed an algorithm to detect and compensate the accumulated error.To eliminate the accumulated positioning error, balise, a positioning device installed between two tracks, is added to the train positioning system to correct the accumulated error by providing the accurate position stored in it when a train is passing it. Shortening the distance between adjacent positioning balises is an effective way to improve the positioning accuracy. However, more balises employed will increase the cost of train positioning system [15]. Generally speaking, a positioning system for HST should have reliable performance, high positioning accuracy and low-cost. Therefore, in order to reduce the positioning error, balises together with speed sensors are introduced to the positioning system of HST. Positioning error of train goes to zero when the train is passing through a balise. However, positioning error between adjacent balises increases as the train moves away from the previous balise.At present, methods for improving positioning accuracy between adjacent balises are mainly based on adding extra equipment, such as radar or GPS receivers. It is clear that this method greatly increases the cost and, the extra equipment introduced has the potential of adding complexity and unreliability for the train control system. In this paper, we focus on applying advanced computing methods to increase the positioning accuracy for HST with balises and speed sensors only. The advanced methods include least square method (LSM), support vector machine (SVM) and least square support vector machine (LSSVM).This paper is organized as follows. In Section 2, we formulate a mathematical model based on the analyzing of wireless message from the train control system to better illustrate the position computation problem. In Section 3, LSM, SVM, and LSSVM models are employed to compute the position of HST based on the model introduced in Section 2. In Section 4, we define six indexes to evaluate the performance of the three position computation models proposed. The first two indices are commonly used in regression problem while the rest of the indices are for this position computation problem in particular. Furthermore, we propose parameter updating method for each position computation model. In Section 5, the three models are compared with ASM model and analyzed in details using field data collected in WG_HSR. Conclusions and future research directions are summarized in Section 6.CTCS is the abbreviation for Chinese Train Control System. CTCS is divided into five application levels, where CTCS-3 system (level-3 CTCS system), is designed exclusively for the HSR and HST. The CTCS-3 system consists of two parts, on-board equipment and ground equipment. Compared with CTCS-2 train control system, CTCS-3 implements bidirectional information transmission based on GSM-R (GSM for railways) [11]. The On Board Unit (OBU) reports the current speed, the location, the running direction and some other data to Radio Block Center (RBC) (a ground equipment) by wireless message via GSM-R. RBC sends the line data, the temporary speed limit information, driving license, and some other data to the OBU under its jurisdiction in return [16,17].As mentioned in Section 2.1, the OBU sends the current information of the train to RBC via GSM-R. The current information is also known as position reporting information, which includes the speed of the train, reporting time, the last related balise number, etc. Fig. 1shows the delivery process of the position reporting information via wireless message. The PRP0 (Position Report Point 0) in Fig. 1 implies the first position reporting point between bailises i and i+1, denoted as Biand Bi+1, respectively. The time interval between adjacent PRPs is typically a few seconds (no more than 7s).Based on position reporting information at each point, we propose a mathematical model for computing the position of HST, which is shown in Fig. 2. From Fig. 2, it is not difficult to see that there are total of (ni,i+1+1) PRPs between Biand Bi+1 (including the PRPs at Biand Bi+1). Liand Li+1 is the kilometer marks of Biand Bi+1, respectively. Li,i+1 is the length from Bito Bi+1 and is calculated by Eq. (1) as follows.(1)Li,i+1=Li+1−Li(Vi,0,Vi,a,···,Vi,ni,i+1)and(ti,0,ti,1,···,ti,ni,i+1)denote the speed of HST and reporting time at each PRP, respectively.(Di,1···Di,ni,i+1)is traveling distance between two adjacent PRPs. Thus, we can obtain the position of train at each PRP as:(2)Pi,j=Li+∑j=1ni,i+1Di,jIn engineering practice, average speed method (ASM) is used to calculate the traveling distance Di,j, defined asDi,jasm=Vi,j−1+Vi,j/2*(ti,j−ti,j−1). Generally speaking, there is a difference between∑j=1ni,i+1Di,jasmand Li,i+1. We define the difference error as ei.(3)ei=Li,i+1−∑j=1ni,i+1Di,jasmAfter testing ASM using the field data collected from WG_HSR, we find that the maximum error eican reach 80m, which is too big for accurate positioning of HSR. Therefore, it is necessary to develop new approaches for computing Di,jto reduce the error ei.As we mentioned earlier, there are many positioning balises installed along the HSR line, which can correct positioning error by using precise location data stored in them. However, it is difficult to get the accurate position for HST running between adjacent balises. In this paper, we assume that the positioning error eifor each traveling distance is proportional to its valueDi,jasm. Through this way, we can reasonably estimate each accurate traveling distance between two adjacent balises. The process of obtaining each accurate traveling distance Di,jin Fig. 2 is illustrated as follows:Step 1: Extracting the information (train speed Vi,j, time ti,j) at each position reporting point with respect to balise Bi.Step 2: Calculating time interval Δti,j−1,jand average speed Vi,j−1,jbetween any two adjacent PRPs in Eq. (4) shown below.(4)Δti,j−1,j=ti,j−ti,j−1,j=1,2,···,ni,i+1Vi,j−1,j=Vi,j+Vi,j−12j=1,2,···,ni,i+1Step 3: Calculating traveling distanceDi,jasmduring any time interval by use of ASM in Eq. (5) shown below.(5)Di,jasm=Vi,j−1,j*Δti,j−1,j,j=1,2,···,ni,i+1Step 4: Calculating the distanceLi,i+1asmbetween Biand Bi+1 (estimated from ASM) by summarizingDi,jasmin Step 3 as shown in Eq. (6).(6)Li,i+1asm=∑j=1ni,i+1Di,jasmStep 5: Obtaining accurate distance Li,i+1 between Biand Bi+1 with the precise location data stored in them by Eq. (1).Step 6: By distributing the error between Li,i+1 andLi,i+1asm, the estimated accurate traveling distanceDi,j*during a certain time interval is obtained by Eq. (7):(7)Di,j*=Di,jasm+Di,jasm*Li,i+1−Li,i+1asmLi,i+1asm,j=1,2,···,ni,i+1After obtaining each estimated accurate traveling distance during a certain time interval, the problem of position computation has been converted into a regression problem. In the following, we will establish three models to find the actual traveling distance Di,jvia the in-speed Vi,j−1, the out-speed Vi,jand the time interval Δti,j−1,j. Thus, we need to find a regression function with Vi,j−1, Vi,j, Δti,j−1,jas inputs, and its output can be as closely asDi,j*. In this paper, we propose three models to identify this function, which are based on Least Square Method, Support Vector Machine and Least Square Support Vector Machine, respectively.Least square method is a mathematical optimization technique which aims at finding the best parameters for a function which matches a set of data by minimizing the sum of the squares of the errors [18,19]. From the mathematical model, we know that the traveling distance is only related to Vi,j−1, Vi,jand Δti,j−1,j. Hence, we establish model 1 based on least square method as shown in Eq. (8).(8)Di,jlsm=f1(Vi,j−1,Vi,j,Δti,j−1,j)=(α1*Vi,j−1+α2*Vi,j)*Δti,j−1,jwhere j varies from 1 to ni,i+1. α1 and α2 are two parameters that need to be optimized. In addition, we assume that there are N+1 balises (B1 to BN+1), then we have N segments between two adjacent balises. The objective function can be defined as follows:(9)min∑i=1N∑j=1ni,i+1(Di,j*−Di,jlsm)2Based on statistical learning theory, support vector machine (SVM) is a universal learning method [20,21]. Moreover, it has been commonly used in solving regression problems and the result is often better than other machine learning methods [22]. Based on the principle of structural risk minimization, SVM not only considers the fitting of training data but also takes the complexity of the training sample into consideration [23,24]. As SVM has good capability of generalization, we propose model 2 based on SVM for computing traveling distance in a time interval as follows:(10)Di,jsvm=f2(Vi,j−1,Vi,j,Δti,j−1,j)=WTϕ(xi,j−1,j)+bHere, xi,j−1,jrepresents vector [Vi,j−1*Δti,j−1,j, Vi,j*Δti,j−1,j]T. ϕ(x) maps the input xi,j−1,jto a vector in a feature space F. And W is a vector in F. The W and b in Eq. (10) are obtained by solving the following optimization problem:(11)minW,b12WTW+C∑i=1N∑j=1ni,i+1(ξi,j+ξi,j*)Di,j*−(WTϕ(xi,j−1,j)+b)≤ɛ+ξi,j(WTϕ(xi,j−1,j)+b)−Di,j*≤ɛ+ξi,j*ξi,j,ξi,j*≥0i=1,⋯,Nj=1,⋯,ni,i+1.where C is penalty factor, ɛ is an insensitive coefficient. Both ξi,jandξi,j*are slack variables [25,30].By introducing Lagrange multipliers, the above optimization problem in Eq. (11) can be written to corresponding Lagrangian function, which in turn leads the initial optimization problem shown in Eq. (11) to a dual optimization problem [26,27]. Given the solution of the dual optimization, the regression function in Eq. (10) can be written as follows:(12)Di,jsvm=f2(Vi,j−1,Vi,j,Δti,j−1,j)=∑h=1N∑k=1nh,h+1(αh,k−αh,k*)K(xi,j−1,j,xh,k−1,k)+bwhere K is a kernel function, xh,k−1,khas the similar meaning as xi,j−1,jin Eq. (10) but with different subscripts h and k. αh,kandαh,k*are Lagrange multipliers, which are obtained by finding the solution of dual optimization [28]. The detailed proof of SVM can be found in Ref. [29].Although SVM has good capability in regression and generalization, the computational complexity of SVM algorithm is greatly increasing with the increased sample size. Due to this limit, the Least Square Support Vector Machine (LSSVM) is proposed (by combining the LSM and SVM approaches) to reduce the complexity [31]. We propose model 3 for computing traveling distance during a certain time interval based on LSSVM, which is shown in Eq. (13) as follows.(13)Di,jlssvm=f3(Vi,j−1,Vi,j,Δti,j−1,j)=WTϕ(xi,j−1,j)+bwhere xi,j−1,j, W and b have the same meaning as those proposed in Eq. (10). However, parameters W and b are obtained by solving a different optimization problem as follows.(14)minW,b12WTW+C2∑i=1N∑j=1ni,i+1ηi,j2Di,j*=WTϕ(xi,j−1,j)+b+ηi,ji=1,⋯,N.j=1,⋯,ni,i+1.where C is penalty factor and ηi,jare slack variables. By introducing Lagrange multipliers, we get the corresponding Lagrangian function. Then, the conditions for optimality can be written immediately as the solution of the following equations [32].(15)01⋯11K(x1,x1)+1C⋯K(x1,xn)⋮⋮⋱⋮1K(xn,x1)⋯K(xn,xn)+1Cbα1⋮αn=0y1⋮ynwhere x1 (xn) represents vector x1,0,1 (xN,nN,N+1−1,nN,N+1), respectively. y1 (yn) is equal toD1,1*(DN,nN,N+1*), respectively; K is a kernel function. Given the solution of Eq. (15) by LSM, then the regression function in Eq. (13) can be written as follows [33]:(16)Di,jlssvm=f3(Vi,j−1,Vi,j,Δti,j−1,j)=∑h=1N∑k=1nh,h+1αh,kK(xi,j−1,j,xh,k−1,k)+bwhere, αh,kis equal to αiin Eq. (15) andi=∑i=1h−1ni,i+1+k.To evaluate the performance of the three models we proposed, some performance indices need to be defined. These indices are used to evaluate whether the computed value obtained from each model is accurate compared with actual traveling distance. We define the difference betweenDi,j*and the computed value of each modelDi,jmasEi,jd.(17)Ei,jd=Di,j*−Di,jmClearly, ifEi,jd(j=1,⋯,ni,i+1)approaches the value of zero, it means the model is able to predict the position of HST accurately. As the position computation problem is converted to a regression problem, we could think of defining two performance indices naturally, i.e., the mean error and the standard deviation. The mean and the standard deviation ofEi,jdare denoted as μc and σc, respectively, and their derivations are shown in Eqs. (18) and (19), respectively. If μc is equal to zero, it means the computation value from model is close to unbiased. While σc is used to evaluate the fluctuation of each model. Smaller σc means the better stability for any model.(18)μc=∑i=1N∑j=1ni,i+1Ei,jd/∑i=1Nni,i+1(19)σc=∑i=1N∑j=1ni,i+1(Ei,jd−μc)2/∑i=1Nni,i+1where ni,i+1 (i=1, ⋯, N) is the number of PRPs from Bito Bi+1.Compared with other regression problem, this position computation problem for HST has some special features: the accurate distance between the adjacent balises can be obtained from the data stored in balises shown in Eq. (1). We define the error between two adjacent balises asEibshown as follows:(20)Eib=Li,i+1−∑j=1ni,i+1Di,jmwhereDi,jmis the traveling distance calculated by any of the three models proposed. Then, we define a group of four special indices, namely, μb, σb, PEb and SAEb as follows.(21)μb=∑i=1NEibN(22)σb=∑i=1N(Eib−μb)2N(23)PEb=∑i=1N|Eib|∑i=1NLi,i+1*100(24)SAEb=∑i=1N|Eib|According to the definitions of these four performance indices, it is not difficult to see that all of them are independent of the accurate traveling distance calculated in Section 3.1. More specifically, μb is the average of the position errorEib. Thus, if μb is close to zero, this model makes an unbiased position computation for HST between two adjacent balises. σb is used to evaluate the variation of positioning errorEib. PEb, the percentage error, indicates the relative positioning error. Clearly, smaller PEb indicates better position estimation. In addition, SAEb is the summation of absolute positioning errors from B1 to BN+1 and an index of the total error.In this paper, we use training data sets to optimize the parameters in three models. The optimized parameters in the three models are the basis for parameter updating methods, which help the models adjust its parameters online and reduce the positioning error dynamically. It works by obtaining current precise location data and producing a new set of training data when a HST passes a new balise. As HST has strict demands on real-time computation, parameter updating method should not be too complex for each model. The proposed parameter updating methods for the three models are discussed below.For model 1, there are two parameters in Eq. (8) that need to be updated, i.e., α1 and α2. When the HST passes through balise Bi+1, the parameters α1 and α2 for computing the traveling distance between Bi+1 and Bi+2 are updated as follows:(25)α1i+1=α1i+η1*Eib*Vi,0α2i+1=α2i+η2*Eib*Vi,ni,i+1where η1 and η2 is learning rate for α1 and α2, respectively. In this paper, we set η1 and η2 as 1e−6 and 7e−7 respectively, based on by many simulations.(α1i,α2i)are the parameters for computing the traveling distance between Biand Bi+1 in the model.Eibis the difference between Li,i+1 and the sum ofDi,jlsmbetween balises Biand Bi+1.For model 2 and model 3, we add the new set of positioning data between two adjacent balises (which are obtained after the HST passes through a balise) into the training data set after removing the oldest set of positioning data. Thus, the size of training data set remains unchanged. In other words, the number of balises in the training data set is still N. The detailed updating process for model 2 and model 3 are shown as follows.For model 2, we define the percentage error between Biand Bi+1 asPEisvmand it is calculated as:(26)PEisvm=Li,i+1−∑j=1ni,i+1Di,jsvmLi,i+1*100In this paper, we choose Radial Basis Function (RBF) as the kernel function, defined as K(xi,j−1,j, xh,k−1,k)=exp(||xh,k−1,k−xi,j−1,j||2/2P2). From the definition of RBF and the optimization problem in Eq. (11), we know that there are three parameters, ɛ, C and P need to be set before training. If the absolute value ofPEisvmis higher than a given threshold, the new training data set will be added to train model 2 and the three parameters will be updated as shown in Eq. (27) to get the updating parameters in Eq. (12) for computing the traveling distance between Bi+1 and Bi+2. Note that ɛ is an insensitive coefficient which is about 1.2 by results shown in some references. And, according to the simulation results, we choose 0.001 as the learning rate. Then, the model is trained again by the new training data set to update other parameters. Otherwise, the parameters in Eq. (12) and the three parameters will be remain unchanged.(27)ɛi+1=ɛi+0.001*EibCi+1=Ci+EibPi+1=Pi+EibFor model 3, we define the percentage error between Biand Bi+1 asPEilssvm.(28)PEilssvm=Li,i+1−∑j=1ni,i+1Di,jlssvmLi,i+1*100As we choose RBF as kernel function and the optimization problem in Eq. (14), we know that there are only two parameters C and P in LSSVM model need to be set before training. Similar to, model 2, the process of parameter updating for model 3 is shown as below: the new training data set will be added to train model 3 to get the updating parameters in Eq. (16) only ifPEilssvmis higher than a given threshold. Otherwise, the parameters in Eq. (16) will be remain unchanged.In order to make the results more comparable, we choose the same threshold value for models 2 and 3. According to the relative change of PEb, we pick up 1% for the thresholds value for both models 2 and 3.The data sets used in this paper were collected from WG_HSR. The series of CRH3 train was put into service on WG_HSR, which is shown in Fig. 3. In addition, Fig. 4illustrates one of the balises used in WG_HSR. In this paper, we only use the operation data of HST from Xianning North Station to Wulongquan East Station as shown in Fig. 5. Note that the time interval between two PRPs varies. The longest, shortest, and average time interval in the data sets are 6.5s, 0.296s and 5.19s, respectively. In addition, there are many balises that are installed along the railway. The density of balises in HSR is related to the line condition and signaling systems. The maximum, minimum, and average distance between two adjacent balises in the field test is 1022m, 44m, and 821.42m, respectively. In the field test, we have a total of 92 balises along the railway with a length of 74,752m. Therefore, we obtain 91 groups of positioning data on adjacent balises, which are shown in Fig. 6.As the speed of HST keeps changing and the distance between two adjacent balises varies, the number of PRPs between two adjacent balises is not a fixed value and it varies from 2 to 16 in our data sets. We have a total of 241 PRPs data sets in the form of (Vi,j, ti,j). Using the hypothesis in Section 3.1, we reorganize the PRPs data sets in the form of(Vi,j−1,Vi,j,Δti,j−1,j,Di,j*). Then, we partition the entire data set into two groups: training data sets and testing data sets. The first 174 PRPs data sets (from balise 1 to balise 48) form the training data set and the rest of the data are testing data sets.We use the training data sets for LSM model, SVM model and LSSVM model, respectively. Note that there are three parameters that need to be set in SVM model before training, namely, penalty factor C, insensitive coefficient ɛ and kernel function K. Selecting the type of kernel and its parameters is typically based on application-domain knowledge which reflects distribution of input values of the training data sets [34,35]. Based on the analysis of training data sets, we choose Radial Basis Function (RBF) as K and kernel function parameter P is set to 200. Applying the selection method proposed in [36], we set C to 700 and ɛ to 1.2. For LSSVM model, there are only two parameters need to be set, namely, penalty factor C and kernel function K. Similar as SVM model, we choose RBF for K and parameter P in RBF is set to 200. Penalty factor C is set to 700.We define the error betweenDi,j*andDi,jmof each model as Edand the error for each group of adjacent balises as Ebon the data sets. Percentage error between adjacent balises is defined as PEb. The Ed, Eband PEbfor the three models on the training data sets are shown in Figs. 7, 8 and 9, respectively. Here, we take the results from ASM model for comparisons.It is not difficult to see that the Edplots of the three proposed models in Fig. 7fluctuate around zero while the plot of ASM model fluctuates around −5m. In Figs. 8 and 9, SVM model and LSSVM model are better than LSM model as they have less variations. We also observe that models 2 and 3 have similar performance as the SVM and LSSVM plots are nearly overlapping in three figures.The detailed comparison results are illustrated in Table 1. It is observed that: (1) the three models are capable of reducing positioning error for HST compared with ASM model in all performance indices expect training time. (2) LSM model is better than ASM model. In index PEb, compared with ASM model, LSM model is decreased by 50.2%. (3) SVM and LSSVM models are much better than LSM model. Compared with LSM model, SVM (LSSVM) model is decreased by 38.8%(36.5%), respectively, in terms of index PEb. (4) In terms of training time, LSSVM model performs better than SVM model since the training time is much shorter. (5) As online position computation is very important for HST, LSSVM achieves the best results in comprehensive considerations.We have obtained the optimized parameters in these three models after training. In order to guarantee the generalization of the obtained models, it is necessary to test them on testing data sets with the parameter updating method proposed in Section 4.3.The plots for Ed, Eband PEbwithout parameter updating methods on testing data sets are shown in Figs. 10, 11 and 12, respectively. Fig. 10indicates that the proposed three models are better than ASM model. From Fig. 11, it is clear that the SVM and LSSVM models can keep Ebin the range of −30–30m while that of LSM model varies from −70m to 20m. The biggest Ebfor LSM model is around −70m, which is not safe for the operation of HST, especially in high speeds. Fig. 12 suggests that the SVM and LSSVM models are a bit better than LSM model in terms of index PEb.The detailed performance indices of the three models and ASM model are shown in Table 2. Here, the testing time for the three model without parameter updating method in Table 2 means the average computation time for the whole traveling distances between adjacent balises. As there is no retraining, the testing time is very short for each model.As there are no parameters in ASM model, we do not need to update its parameters. Thus, there are only three plots in Figs. 13–15, which represent the Ed, Eband PEb, respectively, of three models with parameter updating methods on testing data sets. These figures suggest that SVM andLSSVM models with parameter updating methods are better than LSM model with parameter updating method. The detailed performance indices are also listed in Table 2. The testing time for these three models means the average computation time of the whole traveling distances between adjacent balises, including the re-training time.From Table 2 and Figs. 10–15, we obtain the following results. (1) The proposed parameter updating methods are able to improve most of the performance indices, especially in terms of μb and PEb; (2) The position calculated from these three models are more accurate than ASM model. (3) Generally speaking, SVM and LSSVM models perform better than the other two models. (4) SVM model with parameter updating method requires the longest time. As HST is often operated with high speeds, there is not too much time left to calculate its position. Thus, if taking the testing time into consideration, the LSSVM model with parameter updating method is clearly better than the SVM model. In conclusion, from the testing results, we find that LSSVM model with parameter updating method is most suitable for position computation among the four models.In order to show the stability of each updating parameter, we limit each updating parameter in a small range. Parameter α1 and α2 in LSM model is limited from 0.54 to 0.58 and from 0.40 to 0.44, respectively. The three parameters in SVM model, ɛ, P and C, is set a range from 1.1 to 1.3, from 200 to 300 and from 700 to 800, respectively. To see the process of parameter updating, Fig. 16shows the updating process of two parameters on testing data sets for LSM model and Fig. 17shows the updating process of three parameters on testing data sets for SVM model. Figs. 16 and 17 show that each updating parameter fluctuates within its range in the updating process, which indicates that the updating method for each parameter is stable.

@&#CONCLUSIONS@&#
Based on the analysis of HST position reporting information in the wireless message, we developed a mathematic model to compute the position of HST. Moreover, as the accurate position of HST between adjacent balises is difficult to obtain, we proposed a hypothesis to obtain the estimated accurate traveling distance in a time interval between two adjacent balises. Then, we proposed three models, namely, LSM model, SVM model, and LSSVM model to calculate the traveling distance in a time interval. These three models were trained and tested using field data collected from WG_HSR. We also developed parameter updating methods for each model and tested their performance using the testing data sets.From the training and testing results, we can draw the following conclusions: compared with the results from ASM model used in engineering, the three proposed models can effectively improve the positioning calculation accuracy. The SVM model and LSSVM model perform better than the LSM model in reducing positioning error, especially in reducing PEb in both training and testing. When taking the training time into consideration, LSSVM model is more suitable for position calculation than SVM model. In addition, any model with parameter updating method turns out to be better than that without parameter updating method. Therefore, among these three models, we suggest that LSSVM model with parameter updating method is the best model for HST position computation.As these models can increase the positioning accuracy for HST, the number of balises installed along the railways can be potentially reduced. For example, LSM model can reduce more than 50% of balises and LSSVM model can reduce more than 60% of balises with the same positioning error. Clearly, this will greatly help reduce the cost of the train positioning system. In the future, we will explore more advanced models to further increase the position computation accuracy.