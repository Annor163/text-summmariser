@&#MAIN-TITLE@&#
CURL: Image Classification using co-training and Unsupervised Representation Learning

@&#HIGHLIGHTS@&#
A new classification method via co-training and unsupervised representation learning.Representations are obtained by early and late fusion schemes.Co-training is performed on the representations to enlarge the training set.Three scenarios have been tested: inductive, transductive and self-taught learning.The method outperforms other supervised and semi-supervised learning methods.

@&#KEYPHRASES@&#
Image classification,Machine learning algorithms,Pattern analysis,Semi-supervised learning,

@&#ABSTRACT@&#
In this paper we propose a strategy for semi-supervised image classification that leverages unsupervised representation learning and co-training. The strategy, that is called CURL from co-training and unsupervised representation learning, iteratively builds two classifiers on two different views of the data. The two views correspond to different representations learned from both labeled and unlabeled data and differ in the fusion scheme used to combine the image features.To assess the performance of our proposal, we conducted several experiments on widely used data sets for scene and object recognition. We considered three scenarios (inductive, transductive and self-taught learning) that differ in the strategy followed to exploit the unlabeled data. As image features we considered a combination of GIST, PHOG, and LBP as well as features extracted from a Convolutional Neural Network. Moreover, two embodiments of CURL are investigated: one using Ensemble Projection as unsupervised representation learning coupled with Logistic Regression, and one based on LapSVM. The results show that CURL clearly outperforms other supervised and semi-supervised learning methods in the state of the art.

@&#INTRODUCTION@&#
Semi-supervised learning [1] consists in taking into account both labeled and unlabeled data when training machine learning models. It is particularly effective when there is plenty of training data, but only a few instances are labeled. In the last years, many semi-supervised learning approaches have been proposed [2] including generative methods [3,4], graph-based methods [5,6], and methods based on Support Vector Machines [7,8]. Co-training is another example of semi-supervised technique [9]. It consists in training two classifiers independently which, on the basis of their level of confidence on unlabeled data, co-train each other through the identification of good additional training examples. The difference between the two classifiers is that they work on different views of the training data, often corresponding to two feature vectors. Pioneering works on co-training identified the conditional independence between the views as the main reason of its success. More recently, it has been observed that conditional independence is a sufficient, but not necessary condition, and that even a single view can be considered, provided that different classification techniques are used [10].In this work we propose a semi-supervised image classification strategy which exploits unlabeled data in two different ways: first two images representations are obtained by unsupervised representation learning (URL) on a set of image features computed on all the available training data; then co-training is used to enlarge the labeled training set of the corresponding co-trained classifiers (C). The difference between the two image representations is that one is built on the combination of all the image features (early fusion), while the other is the combination of sub-representations separately built on each feature (late fusion). This strategy has the advantages that only a set of features must be defined and in the co-training the different fusion schemes are used as different views. Moreover, by exploiting both representation learning and co-training, classification can be effectively performed when very few labeled data are available. We call the proposed strategy CURL from the combination of C and URL components. The schema of CURL is illustrated in Fig. 1.In standard co-training each classifier is built on a single view, often corresponding to a single feature. However, the combination of multiple features is often required to recognize complex visual concepts [11–13]. Both the classifiers built by CURL exploit all the available image features in such a way that these concepts can be accurately recognized. We argue that the use of two different fusion schemes together with the non-linear transformation produced by the unsupervised learning procedure, makes the two image representations uncorrelated enough to allow an effective co-training of the classifiers.The proposed strategy is built on two base components: the unsupervised representation learning, and the classifier used in co-training. By changing these two components we can have different embodiments of CURL that can be experimented and evaluated.To assess the merits of our proposal we conducted several experiments on widely used data sets: the 15-scene data set, the Caltech-101 object classification data set, and the ILSVCR 2012 data set which contains 1000 different classes. We considered a variety of scenarios including transductive learning (i.e. unlabeled test data available during training), inductive learning (i.e. test data not available during training), and self-taught learning (i.e. test and training data coming from two different data sets). In order to verify the efficacy of the CURL classification strategy, we also tested two embodiments: one that uses Ensemble Projection unsupervised representation coupled with Logistic Regression classification, and one based on LapSVM semi-supervised classification. Moreover different variants of the embodiments are evaluated as well. The results show that CURL clearly outperforms other semi-supervised learning methods in the state of the art.Summarizing, the contributions of this work are: the proposal of a new classification strategy based on unsupervised representation learning; the use of a single set of visual features to create two new image representations; the use of early and late feature fusion schemes in a co-training workflow to allow effective classification in presence of few labeled data; extensive experiments to demonstrate the effectiveness of the proposed classification strategy under inductive, transductive and self-taught scenarios on different image datasets of heterogeneous contents and cardinalities.

@&#CONCLUSIONS@&#
In this work we have proposed CURL, a semi-supervised image classification strategy which exploits unlabeled data in two different ways: first two image representations are obtained by unsupervised learning; then co-training is used to enlarge the labeled training set of the corresponding classifiers. The two image representations are built using two different fusion schemes: early fusion and late fusion.The proposed strategy has been tested on the Scene-15, Caltech-101, and ILSVRC 2012 data sets, and compared with other supervised and semi-supervised methods in three different experimental scenarios: inductive learning, transductive learning, and self-taught learning. We tested two embodiments of CURL and several variants differing in the co-trained classifier used and in the number of pseudo-labeled examples that are added at each co-training round. The experimental results showed that the CURL embodiments outperformed the other methods in the state of the art included in the comparisons. In particular, the variants that add a single pseudo-labeled example per class at each co-training round, resulted to perform best in the case of a small number of labeled images, while the variants adding more examples at each round obtained the best results when more labeled data are available.Moreover, the results of CURL using a combination of low/mid and high level features (i.e. LBP, PHOG, GIST, and CNN features) outperform those obtained on the same features by state of the art methods. This means that CURL is able to effectively leverage less discriminative features (i.e. LBP, PHOG, GIST) to boost the performance of more discriminative ones (i.e. CNN features).