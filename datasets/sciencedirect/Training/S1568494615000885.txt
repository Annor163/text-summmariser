@&#MAIN-TITLE@&#
Mobile robot path planning using artificial bee colony and evolutionary programming

@&#HIGHLIGHTS@&#
We solve the path planning problem using the combination of two evolutionary methods.First, an artificial bee colony (ABC) finds a feasible path in the free space.Second, evolutionary programming (EP) optimizes the path length and smoothness.The proposed approach was compared to a probabilistic roadmap (PRM) method.The ABC-EP approach outperforms the PRM approach on problems of varying complexity.

@&#KEYPHRASES@&#
Mobile robot,Path planning,Meta-heuristic techniques,Artificial bee colony,Evolutionary programming,Probabilistic roadmap,

@&#ABSTRACT@&#
In this paper, an evolutionary approach to solve the mobile robot path planning problem is proposed. The proposed approach combines the artificial bee colony algorithm as a local search procedure and the evolutionary programming algorithm to refine the feasible path found by a set of local procedures. The proposed method is compared to a classical probabilistic roadmap method (PRM) with respect to their planning performances on a set of benchmark problems and it exhibits a better performance. Criteria used to measure planning effectiveness include the path length, the smoothness of planned paths, the computation time and the success rate in planning. Experiments to demonstrate the statistical significance of the improvements achieved by the proposed method are also shown.

@&#INTRODUCTION@&#
The path planning problem is a fundamental issue in mobile robotics because the need of having algorithms to convert high-level specifications of tasks from humans into low-level descriptions of how to move as stated by LaValle [1]. It can be formulated as follows: given a robot and the description of its working environment, the goal is to plan a trajectory for the robot that joins two specific positions using motion primitives from an available set, and that avoids collisions with the elements present in the robot scenario [2]. The planning algorithms try to provide of autonomy to robots to solve some problems without the intervention of human operators. According to LaValle [1], there are at least two good reasons to study planning algorithms. First, it is very interesting to get machines that can solve some tasks that are difficult to solve for humans, this involves modeling planning problems, designing efficient algorithms and developing robust implementations. Second, planning algorithms have been successfully used in various industries and academic disciplines like robotics, manufacturing, aerospace applications, etc.A chronological review of the advances in the development of path planning algorithms is presented in [3]. There are some general classical methods as: the use of roadmaps, Cell Decomposition, Potential Fields, and Mathematical Programming. In order to improve these classical methods, probabilistic algorithms have been developed, including Probabilistic Roadmap Method (PRM) and Rapidly-exploring Random Trees (RRT). Further details on the implementation of the classical and probabilistic methods can be found in [4].Meta-heuristic algorithms have also been used to solve the path planning problems. The main advantages of the meta-heuristic techniques are: (i) the possibility of inclusion of expert knowledge in the search procedure and, (ii) the potential of working with several candidate solutions simultaneously instead of only exploring a single alternative. In [3] we can observe the considerable increase in works that use heuristic and meta-heuristic techniques to solve the path planning problem. In particular, there are works that use Genetic Algorithms (GA), Ant Colony Optimization (ACO) and Particle Swarm Optimization (PSO) among others. Among these approaches, we can find an evolutionary approach for the path planning and navigation of a mobile robot [5]; a GA-based planner that generates free configurations and tries to connect those configurations with a start and a goal position [6]; an improved genetic algorithm to increase the exploration diversity of candidate solutions and reduce the possibility of being trapped in local minimums [7]; an improved genetic algorithm to generate free-collision paths [8], and a memetic algorithm to generate paths, using operators to evolve candidate solutions based on certain criteria [9]. Other meta-heuristics techniques are the swarm intelligence techniques; they are based on the collective behavior of some social species. Among these kind of approaches, we can find a planner that uses the ACO algorithm and nine motion directions of the robot within the grid representation of the map [10] and PSO-based planners for a mobile robot [11–13]. The Artificial Bee Colony (ABC) algorithm has also been used to solve planning problems as in the Mansury work [14].A detailed review of the main features of the evolutionary approaches in the recent literature are presented below.•With respect to the robot model, previous approaches [6,14,12,15] use a point model for the mobile robot.With respect to the meta-heuristic strategy, the approaches [6,14,12,15] use a single evolutionary technique (GA, PSO, and ABC).In regard of the individual encoding of the meta-heuristic techniques, the approaches [15,12] encode each individual as a collection of cells in a grid map generated by the discretization of the robot scenario. In [14], they encode the path using the parameters of two Ferguson splines, limiting with that the complexity of the path planning problems that can be solved, but being adequate for the Robo-soccer scenario used in their tests. Achour and Chaalal [6] propose to use a set of segments to encode the individual. These segments are evolved into a roadmap of segments that do not collide with the obstacles in the map until finding a free path connecting the start and the goal position.For the fitness function, Achour and Chaalal [6] favor both the minimal total length and the smoothness of the path, however the method is restricted to use only path segments generated by the GA during its evolution. The approaches [12,15] minimize the distance of the cell sequence but their methods are restricted to move the robot cell by cell.Test scenarios used to validate previous approaches are also of variable complexity. Goel and Singh [15] address the path planning problem in dynamic scenarios, but they present only one example and they use a discretized grid of the scenario. Mansury et al. [14] address the problem in a Robo-soccer scenario where there are only three obstacles. Li and Wang method [12] has been validated only in environments with sparse obstacles. Achour and Chaalal [6] consider a continuous representation of the scenario and present some problems including a small number of obstacles and corridors.The main contribution of this paper is the development of new robust algorithm based on meta-heuristic approach to solve the path planning problem of a disk robot. The proposed planning system accomplishes its task in two steps. First, a feasible path planner using the ABC algorithm generates an initial path connecting the start position and the goal position of the robot and that path passes through intermediate configurations from a set of randomly chosen free configurations. Second, the initial path is optimized in a global way by using Evolutionary Programming (EP), that leads to short, smooth, and collision free paths. The proposed method was validated in a large set of path planning scenarios (benchmark maps). This test set includes most of the complex situations that a path planning algorithm can encounter in real world scenarios. The method is extensively validated against the classical PRM algorithm, as suggested by Masehian and Sedighizadeh [11]. Both planning systems are tested in the benchmark maps and compared with respect to measures such as: path length, path smoothness, search cost and planning success rate. We present quantitative and qualitative results of the comparative study.The rest of this paper is organized as follows: Section 2 includes the formulation of the path planning problem in terms of our approach. Section 3 presents the feasible path planner using the ABC algorithm. Section 4 describes the EP in global path planning optimization. Section 5 presents a brief description of the PRM for the sake of completeness. Test and results are presented in Section 6 whilst our main conclusions and findings are presented in Section 7.A scenario W for the robot is considered as a 2D map, that includes a set of static obstacles Oj, (j=1, …, M), and a mobile robot R with instantaneous position represented by its coordinate C(x, y). We assume a circular model of the robot with a radius r (that is, a disk robot). The goal is then to find a sequenceT→of motion commands to let the robot move from a start position S(x, y) to a target position G(x, y). In our approach,T→is composed of rotate and advance motion primitives. That is depicted in Fig. 1.One of the main advantages of soft computing is the possibility of hybridization of different techniques. For the path planning problem, we have experimented on developing methods using a single evolutionary technique as ABC or EP. In our experiments, the use of a method exclusively based on ABC has shown difficulties to find paths that satisfy the optimization criteria. Nevertheless, this approach finds paths that are feasible but not optimal. We have also experimented with a path planner using only EP. This approach encounters problems to avoid collisions in the robot path but it is able to improve the path when it starts with a feasible one.We present a meta-heuristic based planner to generate a trajectory composed of advance and rotate primitives. Firstly, we generate a feasible path free of collision by connecting free configurations from the start position to the goal position. The connections between the path segments are found by local search procedures guided by the ABC algorithm. Secondly, we optimize in a global way the initial path in terms of length and smoothness by using EP. The proposed fitness function favors the generation of paths with the following characteristics: shortness, collision freeness, and smoothness of the plan. The proposed method is hereafter referred as the ABC-EP planner. This method is inspired by the PRM planner, but our method replaces the step of building the visibility graph with a feasible path planner guided by the ABC algorithm.In this section we describe the ABC algorithm as an optimization tool, and then we describe our local search procedures guided by the ABC technique to generate an initial feasible path for the second part of the path planning system.Among evolutionary approaches, the ABC algorithm has been found to perform better or at a same level than others like GA, Differential Evolution (DE), PSO or Evolution Strategies (ES) on a large set of unconstrained test functions by Karaboga et al. [16].The ABC algorithm, proposed by Karaboga in 2005, is an algorithm useful for solving parametric optimization problems. The ABC algorithm simulates the bee colony behavior in its food search procedure [16]. In the ABC algorithm, there is a population of food positions and the artificial bees modify these food positions along time. The colony size is two times the number of food positions. Employed bees are the half of the colony and the onlooker bees are the other half. When an employed bee cannot improve a food position in a number of trials, the employed bee becomes a scout bee. The employed bees exploit the food positions, while the onlooker bees are waiting for information from the employed bees about nectar amount of the food positions. The onlooker bees select food positions using the employed bee information and they exploit the selected food positions. Finally, the scout bees find new random food positions.The general structure of the ABC algorithm is shown in Algorithm 1. A more detailed description follows:Algorithm 1ABC algorithm1:Initialization Phase2:repeat3:Employed Bees Phase4:Onlooker Bees Phase5:Scout Bees Phase6:Memorize the best solution achieved so far7:untilcycle= Maximum Cycle Number (MCN)A food positionxi→(i∈1, …, SN) represents a feasible solution to the optimization problem. Each positionxi→has D parameters to be optimized (xi,j, j=1, …, D). We can initialize the food positions using:(1)xi,j=lj+rand(0,1)(uj−lj)where ljand ujare the lower and upper limits of the parameter j respectively, and rand(0, 1) is a uniform random number between 0 and 1.Each employed bee is associated to a food position. An employed bee searches a new food positionvi→using its current food positionxi→as follows:(2)vi,j=xi,j+ϕi,j(xi,j−xk,j)where k is a random food position index (k≠i), j is a parameter chosen at random and ϕi,jis a random number between [−1, 1].The employed bee computes the nectar amount ofvi→, and then it applies the greedy selection: ifvi→has more nectar amount thanxi→, the food positionxi→is replaced byvi→and its trial counter is reset to zero, otherwisexi→is retained and its trial counter increases by one.An onlooker bee selects a food positionxi→depending of a probability pi:(3)pi=fiti∑j=1SNfitjwhere fitiis the fitness of the food positionxi→.Once that the onlooker bees have selected the food positions, they generate new food positions using Eq. (2). The new food positions are evaluated and the same greedy selection is applicated.When a food position has not improved in a number of trials, limit=SN×D, this solution is replaced by a random food positionxi→using Eq. (1).The objective of this step is to generate a collision free path, a feasible path, joining the start and goal positions using the ABC algorithm. This path is built incrementally, by finding a sequence of nodes from a sample of geometric random configurations in the free space of the scenario. The nodes to be included in the feasible path are found by a local search procedure using the ABC algorithm that finds the next node in the feasible path from a subset of the sample configurations by taking into account its closeness to the goal position and by avoiding nodes that generate path segments in collision with the obstacles.The formal procedure is as follows. First, we generate random configurations in the free space, where each configuration is a punctual object Vi(x, y), (i=1, …, N), see Fig. 2. After that, we find an index sequenceP→of the collision free vertices that connect the start position S(x, y) to the goal position G(x, y) of the robot.A food position represents an index n∈[1, N+1] to the next vertex Vn(x, y), where the configuration VN+1(x, y)=G(x, y). We evaluate each index using the Euclidean distance to the goal:(4)F1(n)=||Vn(x,y)−G(x,y)||+fpen×pnThe problem is then to find n* such that:(5)n*=n↔F1(n*)=minn∈[1,N+1]F1(n)wherefpen=2w2+h2is a penalization factor,(w,h)are the width and the height of the scenario and pnis a penalization counter. A penalization occurs when:•The segment between the current position and the next position is in collision.The distance between a nearest obstacle and the segment of the current position and the next position is less than the robot radius.There is an index n inP→.The best index Best, minimizes Eq. (4). If the robot R has not reached its goal, Best is added toP→and the current position of the robot is updated in VBest(x, y). We search a new next position until the robot reaches its goal. The initial path generation procedure is described in Algorithm 2. This algorithm assumes the next functions: CallABC() that returns the best index using the ABC algorithm, and Add(index) that adds an index to the sequenceP→.Algorithm 2Initial path generation using the ABC algorithm.1:C(x, y)=S(x, y)2:whileC(x, y)≠G(x, y)3:Best= CallABC()4:P→=Add(Best)5:C(x, y)=VBest(x, y)6:end whileWe propose an EP based global path planning optimization. The EP, proposed by Fogel [17], is an extension of the GA that has flexibility in the solution representation. The EP works in the phenotype space whilst the GA works in the genotype space. In EP there is not crossover operator, evolution process is only performed using mutation operators. The general structure of the EP is shown in Algorithm 3.Algorithm 3The Evolutionary Programming Procedure1:Initialize the population2:repeat3:Expose the population to the environment4:Compute the fitness for each member5:Randomly mutate each parent6:Evaluate parents and children7:Select members of new population8:until Some condition is metBy using the feasible initial path, the sequence of nodesP→, we generate an initial population of paths. A pathT→is a linked list of M verticesT→={V1(x,y),…,VM(x,y)}, see Fig. 3. In this representation the last vertex is the goal position of the robot. The solution of the planning problem is an optimized version of the initial path generated by the set of local search procedures.The mutation plays an important role, because, as it is said before, it enables the evolution process. Each path in the population generates a new path by using some mutation operators, as in [5]. However, in difference with [5], the proposed method only works in the feasible trajectory search space. A mutation operator is applied only if it generates a free collision path. In this work, we implemented four operators: delete, smooth, update, and visibility. The probabilities of the operators were selected by trial and error as 0.2, 0.1, 0.1, and 0.6, respectively. The graphical representation of each mutation operator is presented in Fig. 4. The operations implied by the mutation operators are as follows:•Delete. Select at random a vertex in the path, and then delete it.Smooth. Select at random a vertex in the path. Compute a random point A(x, y) in the segment of the past vertex with the selected vertex. Compute a random point B(x, y) in the segment of the selected vertex with the next vertex. The new value of the selected vertex is now the point A(x, y). Insert a new vertex in the next position using the point B(x, y).Update. Find at random a vertex of the path, generate a new free collision vertex, and update the information.Visibility. Select in a random way two vertices, and then the vertices between them are removed.We use an objective function that computes the path length using the Euclidean distance between vertices:(6)F(T→)=∑i=1M−1||Vi(x,y)−Vi+1(x,y)||The problem is then to find T* such that:(7)T→*=T→↔F(T→*)=minT→∈UTF(T→)where UTis the feasible trajectory search space.After applying the mutation operators to the population, the population doubles in size. The best half among the parents and the children is retained, and the other half is discarded.In order to be self-contained, we explain here the PRM algorithm that will be used for evaluation purposes. The PRM is a planner with application in high dimensional configuration spaces path planning problems [18]. The PRM has two phases: a learning phase, and a query phase. In the learning phase, the PRM generates a set of random configurations in the free space, and it connects the set of configurations using a local planner. In the query phase, an initial configuration, and a target configuration are connected to the roadmap. Then, any graph search algorithm can be used to find the shortest path. The PRM procedure is described in Algorithm 4[19].Algorithm 4Operation of the basic PRM1:Generate N points at random2:Connect the points with the local planner and obtain a directed graph G3:for each query of the form, is there path from x to y? do4:Add x and y to point set and attach them to G5:if a path from x to y lies in Gthen6:return the computed path7:else8:return no path is found9:end if10:end forIn this section, we describe the test protocol, we present how to tune the parameters of our method and we present the results of a comparative study of our method with the PRM-Dijkstra in a set of benchmark maps to evaluate the performance of both planning methods. Finally, we implement our planner in a robotic platform to test our planning method in a real mobile robot.The experiment was realized in 46 planar environments.11Maps are available at http://imr.felk.cvut.cz/planning/maps.xml.We show in Fig. 5the set of benchmark maps, while in Table 1we present the identifier of each map with its size in meters.For each scenario, we generate 30 planning problems by modifying the start position and the target position at random of a mobile robot with a radius of 34cm. We show the performance of our planner and the one exhibited by the PRM planner using the Dijkstra algorithm for finding the shortest path between two specific positions. Given its stochastic formulation, both planning systems were tested 100 times for each planning problem. The measures to evaluate the quality of the generated paths are, as suggested by Cohen et al. [20]: the path length, the smoothness of the plan, the total computation time, and the planning success rate. Both planning methods were implemented in the C language, on an Intel Core 2 Duo processor running at 2.66GHz with 4GB of RAM memory.The ABC-EP planner can change its performance by modifying its set of tuning parameters. These parameters are: the ABC parameters, the EP parameters and the number of samples. In order to generate the set of optimal parameters, each module of the system is tested by using some training scenarios. Below, we describe the tuning procedure for each parameter of the system.In this experiment, we use a training scenario of 10m×10m with a corridor. We put the initial position of the robot in (5,9) and the goal position in (5,2). The optimal motion of the robot is that it moves to the goal, crossing the corridor. In this experiment, we fix the number of food positions, SN=10, and the number of samples, 10 per m2. We vary the number of cycles [1,50] of the ABC algorithm. Our objective is to find the number of cycles that the ABC algorithm needs to achieve that the robot moves from the initial position to the goal position. We conclude that we can find the optimal motion with this algorithm in 5 cycles (exploring 10% of the samples).For tuning the EP parameters, we use the double maze scenario (adaptation of the scenario presented by Xiao et al. [5]). We use an initial path found by the set of local search procedures with the ABC algorithm to optimize it. In order to find the optimal values of the EP algorithm, we vary its number of individuals NI∈{10, 20, 30, 40, 50} and its number of generations MGN∈{250, 500, 750, 1000} to generate the best global path (according to the search cost and the path length). For each combination between number of individuals and number of generations, we simulate 100 times. Using a constraint that the system must generate an optimized path in less of 1s, we conclude that with 10 individuals and 500 generations, we can generate the best result.We use the 46 maps and compute the free space of all maps, in order to find the scenario with the largest free space. We find the var_density scenario (Fig. 5(42)) with free space 1803.5527m2. Our objective is to find the number of samples that allows solve a random planning problem with a minimum search cost. We vary the number of samples in the free space [200,1800] in steps of 400 and we observed that with 1000 samples the planner could generate a solution the 100 times of the 100 simulations in 0.4208s (mean search cost), so, we select this number of samples.In Fig. 6, we present the plots of the considered measures in this comparative study: the path length, the smoothness of the plan, and the search cost. The ABC-EP method obtains shortest paths in the majority of the scenarios, except in some problematic ones where also the PRM-Dijkstra method has a low planning success rate as in the tunnel_dogleg scenario (Fig. 5 (37)). Also, we can observe that the ABC-EP system generates smoother paths. An important characteristic for both planning systems is that they generate paths in less than 2s (average time) in all the planning problems using these benchmark maps.Some qualitative results of the generated paths by both methods are shown in Fig. 7. We selected some maps from the repository with the objective of showing the quality of the generated paths by both planning methods; we can observe that the generated paths by our method are shorter and smoother than the PRM-Dijkstra paths. The goal position of the mobile robot is represented by a triangle in the figures, and the path is a set of circumferences. The obstacles in the map are either convex or concave polygons.In order to demonstrate the statistical significance of the improvements in performance of our method with respect to the PRM-Dijkstra planner, we have used the two-sample Z-test for each of the quality measures of the generated paths.The two-sample Z-test assumes that the samples are large (n>30) and that the mean and the standard deviation for both samples are known. We have configured the test as follows:•The null hypothesis Hois(8)Ho:μ1−μ2=d0The alternative hypothesis Hais(9)Ha:μ1−μ2≠d0The degree of confidence α is α=0.05.Considering the path length results, we have found that there is statistical difference in 37 of the 46 scenarios, and that our method generated shorter paths for 25 of these 37 environments. Comparing the smoothness results, we have found that there is statistical difference in 45 of 46 scenarios. For those scenarios, our method generated smother paths in 41 of 45 environments. For the computational time needed to generate a path, our tests show that there is statistical difference in 43 of the 46 scenarios, and in 41 if them, our method is faster. Considering the planning success rate, the proposed method exhibits a better figure in 37 of 46 scenarios with a tie in another 3 environments.We have observed some important characteristics of our planner. The ABC-EP planner has a good performance (according to the search cost and the path length) in scenarios without narrow corridors (specifically, narrow long corridors) and less numbers of obstacles, more free space, as in complex (Fig. 5(9)), bugtrap1 (Fig. 5(3)), bugtrap2 (Fig. 5(4)), hidden_U (Fig. 5(17)) and so on. Although, the ABC-EP system has a better performance than the PRM-Dijkstra (success rate) in some complex scenarios as: bugtrap4 (Fig. 5(6)), rooms (Fig. 5(25)) and slits (Fig. 5(28)). The smoothness of the path is affected when scenarios have distributed obstacles on the map as geometric (Fig. 5(16)), warehouse (Fig. 5(46)) and any variant of var_density (Fig. 5(42-45)). But, in general with the use of our mutation operator (smoothing operator) can improve the smoothness of the paths in any kind of scenario.The planning success rate of the PRM approach can be improved by increasing the number of samples N or the number of neighbors K. Nevertheless, when these parameters are increased, the search cost increases too. In order to validate this statement, we test the PRM planner with a different number of neighbors, K=20 to compare both planning methods. In Table 2the results of all the planning problems on the benchmark test set are presented. Table 2 presents the average and the standard deviation of the measures: path length (Pl), smoothness of the plan (Sp), search cost (Sc) and success rate (Sr). We can observe that the ABC-EP planner generates smoother paths using a lower cost and a better success rate than the PRM (K=10), whilst with respect to the PRM (K=20), it generates shorter and smoother paths in a lower cost (in time) but with a very similar success rate.In order to complete the set of experiments, we have tested the PRM with different number of samples, keeping the number of neighbors in K=10 (using a PC with Intel Core i5 processor running at 2.7GHz and 8GB of RAM memory). For this experiment, we generate a single set of configurations for each scenario with N∈{200, 400, 600, 800, 1000} and we test both systems with the same random problems of the last experiment. We use again the two-sample Z-test with the same characteristics of the last experiment to prove the statistical difference between both planning methods. In Table 3, we present the results of the generated paths by both planning methods in all the planning problems using the same set of samples. We can observe that, with more sparse maps there is not statistical difference in the path length, but the ABC-EP planner remains the best method according to the smoothness of the plan and the search cost. Also, we can observe that the ABC-EP planner has a better success rate than the PRM-Dijkstra. As the success rate increases as the number of samples increase, so, it is important to use scenarios with more samples (for these benchmark maps) to improve the success rate of both planning methods.In order to test our planning method, we have implemented it on a robotic platform: the mobile robot Pioneer 3-AT, see Fig. 8. The mobile robot has a swing radius of 34cm, a rotation speed of 140°/s, and a maximum forward/backward speed of 0.7m/s.Experiments were realized in an environment of 7×3m. As an example, we show in Fig. 9a set up with two static obstacles. The start position of the mobile robot is the circle S, and the goal position is the circle G. The mobile robot executes its path satisfactorily on its workspace, see Fig. 10.A new methodology for the mobile robot path planning has been proposed. This methodology is based in the application of a meta-heuristic strategy combining two evolutionary techniques. The proposed method solves path planning problems in two sequential steps. Firstly, the method generates a feasible path by using the Artificial Bee Colony algorithm to perform local searches that incrementally build a path without collision connecting the start and goal positions of the mobile robot. Secondly, the method performs a refinement of the feasible path by using Evolutionary Programming. A set of mutation operators improves the path in order to obtain short, and smooth collision-free paths. The combined approach has shown to overperform the classical Probabilistic Roadmap Method using the Dijkstra algorithm for exploring the roadmap. Both qualitative and quantitative analysis have been performed on the resulting data to ensure the statistical significance of the improvements in performance attained by the proposed approach in a large set of environments that cover most situations arising for path planning problems. The proposed method generates paths in less time in problems with distributed obstacles (without corridors) on the map, because we avoid to build the visibility graph in the learning phase of the PRM. We replace this step with a set of local search procedures using the Artificial Bee Colony algorithm. The proposed approach has also been implemented in an experimental robotic platform to show its feasibility for practical deployment of the method.Our future work will be directed towards optimizing the mutation operator in the global path optimization phase (either by adding some other mutation operators or by finding optimal probability values according to online analysis of the planning problems). More work is also needed toward improving the local explorations process. Another topic of our work is to extend the method to cope with the multi-robot path planning problem.

@&#CONCLUSIONS@&#
