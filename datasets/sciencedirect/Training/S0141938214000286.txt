@&#MAIN-TITLE@&#
Navigating virtual mazes: The benefits of audiovisual landmarks

@&#HIGHLIGHTS@&#
We compare navigating virtual mazes with visual, auditory and combined landmarks.We examine changes in spatial memory tasks and way finding performance.Audiovisual landmark presentation yields the best performance for map drawing, landmark recollection and wayfinding.

@&#KEYPHRASES@&#
Multisensory perception,Memory,Navigation,

@&#ABSTRACT@&#
It has been shown that multisensory presentation can improve perception, attention, and object memory compared with unisensory presentation. Consequently, we expect that multisensory presentation of landmarks can improve spatial memory and navigation.In this study we tested the effect of visual, auditory and combined landmark presentations in virtual mazes on spatial memory and spatial navigation. Nineteen participants explored four different virtual mazes consisting of nodes with landmarks and corridors connecting them. Each maze was explored for 90s. After each exploration, participants performed the following tasks in fixed order: (1) draw a map of the maze, (2) recall adjacent landmarks for three given landmarks, (3) place all landmarks on the map of the maze, and (4) find their way through the maze to locate five given landmarks in fixed order.Our study shows significant effects of multisensory versus unisensory landmarks for the maze drawing task, the adjacency task, and the wayfinding task. Our results suggest that audiovisual landmark presentations improve spatial memory and spatial navigation performance in virtual environments.

@&#INTRODUCTION@&#
Spatial navigation is the process of planning and following routes to travel from the current location to a target location, and involves one of the most fundamental human cognitive functions (way finding) and motoric functions (locomotion).A good understanding of human way finding strategies [1–3] and underlying perceptual and cognitive processes [1] is of particular importance to optimally support human spatial navigation in virtual environments. Virtual environments can be more complex than natural environments with respect to their scale [4,2], structural complexity and dimensionality [5]. Furthermore, virtual environments often differ from natural environments with respect to the sensory modalities involved, depending on the use of visual, auditory and vestibular displays [6–11] and interaction methods [8]. Thus, an optimal support of human spatial navigation in virtual environments relies on knowing the effects of involving multiple sensory modalities.Finding one’s way in complex environments relies on complex multisensory perceptual processes and on working memory and spatial memory. When no external representations are available (such as a map), spatial navigation is based on internal mental representations (cognitive maps) derived from sensory experiences [12–15].Such mental representations, called cognitive maps, are constructed by perceiving spatial information from multiple sensory cues, by understanding the spatial relationships between important attributes of the environment (i.e. landmarks and their relative positions) and by encoding this (multi)sensory information into internal spatial representations in short- and long-term memory.Cognitive maps in combination with self-motion cues are crucial to continuously maintain a sense of position and orientation and to guide navigational behavior [15]. To optimize navigation performance the various sensory inputs (e.g. visual, auditory, tactile and vestibular) in underlying perceptual, memory and cognitive processes should be optimally combined or integrated.In the acquisition of spatial memory contents, landmarks play an important role [16,17]. Landmarks are typically distinctive objects that stand out in the environment [18,19] and serve as reference points when we are following routes or when we need to determine where we are [4].When navigating the real world, landmarks can be seen (e.g. buildings), heard (e.g. clock towers) and perceived in their combinations. Although our study focuses on audiovisual environments, it is of interest that multisensory navigation is likely to also involve the olfactory and tactile sensory systems. It has been known for a longer time that ants can use olfactory information in order to locate their nest entrance [20] and that pigeons use gradients of volatile organic compounds in the atmosphere for environmental odor-based navigation [21]. But it has only recently been shown that humans have a residual directional smelling ability and process spatial information in the olfactory system [22]. The involvement of the somatosensory system in navigational processes has been studied by Restat et al. [23] who showed that experiencing slanted slopes in a virtual town positively influences navigation performance. Navigation studies in real towns are lacking probably due to the difficulty of maintaining these natural environments controlled.It has been suggested that the integration of the neural responses to multisensory stimuli into coherent and meaningful representations of landmarks can yield ‘superadditivity’ effects, meaning that the multisensory response is greater than the sum of its unisensory parts [24].Research on perceptual integration indicates that multisensory stimuli are generally beneficial for perceptual task performance [25,26]. More specifically, multisensory perception can improve reaction time[27–30], improve stimulus detection[31], and reduce signal variability[32,26,33–35].Memory research has recently shown that multisensory experiences enhance recall and recognition of object identity[36,37] and object location[38].A well accepted Working Memory model is that of Baddeley and colleagues [39–41] which postulates three components: a visuo-spatial sketchpad (for objects and spatial information), a phonological or articulatory loop (for storing auditory and verbal information) and a central executive (to coordinate the systems and bind and manipulate information). The visual-spatial sketchpad and the phonological loop are independent [42], but the central executive relies on shared (attentional) resources. This means that integrating multisensory information in working memory may come at a cost when the central executive has to compete for resources with other information processes. Later Baddeley [43,44] added a fourth component, the episodic buffer, which can be seen as the gateway to long term memory [45], amongst others to explain effects of chunking or binding.The multisensory nature of encoding and decoding information suggests that a multisensory presentation of landmarks may improve the short as well as long term memory processes underlying navigational performance.Enhanced perceptual and memory processes may further improve subsequent multisensory navigation processes. We focus on audiovisual environments.Visual spatial knowledge acquisition and navigation has been studied extensively in natural and virtual environments [46–49]. Furthermore, case studies show that humans are also able to navigate in virtual acoustic environments based on (3D) auditory cues and beacon sounds [50–53].However, fewer studies have investigated the effect of audiovisual presentation on navigation performance [54,55]. Gunther et al. [54] investigated navigation in virtual environments that contained visual objects that could also produce 3D sound. They found that the addition of 3D sound to the virtual environments improved navigation, but did not increase a participant’s spatial memory of the environment. However, the authors explained that the sound was audible even when participants did not look at the objects (i.e., it was audible through the walls) and that this worked as a beacon to guide participants to their destination. Because the sound was often experienced without the corresponding visual object, multisensory interactions may have played no role in this study. Another study on the effects of multisensory presentation in virtual environments was conducted by Ardito et al. [55]. They presented participants with different pieces of classical music in each room of a virtual museum and found that such music could benefit users’ navigation and memory performance, but only when users where informed in advance of the link between the music and the rooms. The authors suggest that for stimuli with a ‘natural’ link (semantic stimuli) the benefit on navigation and memory performance may be automatic. This suggestion is in agreement with the recent studies indicating that meaning plays a critical role in multisensory memory interactions [38,56–58].In conclusion, these studies have suggested, but not conclusively shown, that multisensory object representations can indeed enhance navigation performance. However, the explicit relation between spatial memory and navigation performance has not yet been investigated.We wanted to investigate the effects of meaningful multisensory landmarks on spatial navigation performance in relation to spatial memory performance. For this purpose we constructed several virtual mazes using the game Unreal Tournament 2004. The mazes either contained auditory, visual or audiovisual landmarks. The landmarks were sounds and pictures of meaningful semantic objects. We experimentally investigated the effect of multisensory landmark presentation on the user’s spatial memory and on navigation performance. Our first hypothesis was that multisensory (audiovisual) landmark presentation improves spatial memory of the virtual mazes compared with unisensory presentation. Our second hypothesis was that audiovisual landmark presentation improves navigation performance compared with unisensory presentation.

@&#CONCLUSIONS@&#
