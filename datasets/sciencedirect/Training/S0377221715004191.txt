@&#MAIN-TITLE@&#
Continuous (s, S) policy with MMPP correlated demand

@&#HIGHLIGHTS@&#
We consider dynamic (s, S) policies where demand is modeled by a correlated MMPP.We present an algorithmic approach to calculate the steady state measures of the inventory system.We present heuristics to calculate the optimal policy.The impact of correlation on the demand-count process is investigated.We compare our policy with existing heuristics utilizing the demand-count Normality assumption.

@&#KEYPHRASES@&#
Stochastic demand,Correlated demand,MMPP,Inventory systems,Ordering policies,

@&#ABSTRACT@&#
This work considers a continuous inventory replenishment system where demand is stochastic and dependent on the state of the environment. A Markov Modulated Poisson Process (MMPP) is utilized to model the demand process where the corresponding embedded Markov Chain represents the state of the environment. The equations to calculate the system inventory measures and the number of orders per unit time are obtained for a continuous, infinite horizon and dynamically changing (s, S) policy. An efficient optimization heuristic is presented and compared to the commonly used approach of approximating the demand-count process over the lead time with a Normal distribution. An investigation of the MMPP demand process is considered where we quantify the impact of variability in the demand-count process which is due to auto-correlation. Our findings indicate that when demand correlation is high, a dynamic control, where the (s, S) policy changes with state of the environment governing the MMPP, is highly superior to the commonly used “static” heuristics. We propose two dynamic policies of varying computational complexity, and cost efficiency, depending on the class of the product (one for class A, and one for classes B and C), to handle such high-correlation situations.

@&#INTRODUCTION@&#
Capturing the behavior of the demand process is integral to the analysis of inventory and revenue management systems. This work considers the realistic and widely applicable case where customer demand is dependent on external environmental factors which result in an auto-correlated and possibly bursty demand process. External environmental factors include market competition, state of the economy and weather among others. Ignoring the impact of these exogenous factors can lead to unrealistic models and misleading analysis.The emergence of global markets has increased the number of consumers but also diversified the competition. As consumers are always looking for the next big thing, especially in the increasingly complex market of technical products, Pinto (2013), a gain in market share or possibly market dominance of a product is dependent on the release date of the newest product as well as the release date of competing products. The persistent consumer need for the newer and more complex products results in products which are more difficult and sophisticated to produce and companies are consistently upgrading their products to satisfy the public, Pinto (2013). This results in a fluctuation in the demand process. Song and Zipkin (1993) use an MMPP to describe the fluctuating demand environment where the embedded Markov process within an MMPP represents the state of the world. Examples of the state of the world provided by Song and Zipkin (1993) include the economic environment or the state of the product with respect to the market in terms of novelty or obsolescence.Chen and Yano (2010) consider weather as a significant factor impacting demand where 46 percent of U.S. gross domestic product is impacted by weather. For example, an unseasonably warm spell of warm weather can result in reduced sales of winter apparel. The authors also refer to Wal-Mart, Nestle and Coca-Cola among other companies to have reported weather dependent demand. Chung and Flynn (2001) consider the newsboy problem with a two-stage seasonal demand which are represented by high-demand (high season) and off-peak periods (preseason). In such a case, management is allowed to produce in reaction to the high demand during the high season. This work is extended in Chung, Flynn, and Kirca (2008) for the multi-item case. Ozkan, Karaesmen, and Ozekici (2013) consider fluctuating demand in the context of a resource capacity control problem in revenue management. The authors point out that fluctuation in demand can be due to weather, snow storms or heat waves, or a result of market forces such as currency exchange rates and energy prices. Yin and Rajaram (2007) model demand as fluctuating or state-dependent and investigate a joint pricing and a periodic review inventory control problem over a finite time horizon.Environmental fluctuations are treated as noise in demand models, van Ryzin (2005). In the context of inventory management, specifically when calculating the reorder point, this noise is captured as part of the variability of the demand-count process over the lead time. The commonly used approach is to approximate the mean and variance of the demand-count process over the lead time and fit a Normal distribution. For this reason a portion of this work analyzes the count process of the MMPP and investigates the impact of correlation on the variability of the demand-count process and consequently on the performance of the inventory policies.Auto-correlation in the demand process is investigated in the literature on a limited basis. For example, Urban (2000) investigates the impact of serially-correlated demand on determining the reorder levels where an autoregressive demand process is considered. In addition, Lee and Chew (2005) consider a dynamic replenishment policy for different products that are auto-correlated but independent of each other. In the context of correlated Markovian demand, Yin and Rajaram (2007) consider a setting where pricing and ordering decisions are made at the start of each period, and they illustrate the benefits of dynamic pricing. None of these works consider the effect of correlation on the performance of different (heuristic and optimal) ordering policies under MMPP demand, as we do in this paper.The literature on (s, S) policies with fluctuating demand assumes periodic review and utilizes a dynamic programming approach to obtain the optimal policy, Yin and Rajaram (2007), Sethi and Cheng (1997). Yin and Rajaram (2007) consider a periodic review model over a finite time horizon. Sethi and Cheng (1997) consider periodic review (s, S) policies for finite and infinite horizon nonstationary systems and assume no lead time. The optimality of the (s, S) reorder policies for the considered models is investigated as well as extensions of the model. The main focus of this literature is on proving the optimality of dynamically changing (s, S) policies. The optimality of a “world-dependent” dynamic (s, S) policy for a continuous review inventory system with fixed ordering costs and the demand following a MMPP, over an infinite horizon, is established in Song and Zipkin (1993). Moreover, Sethi and Cheng (1997) and Beyer, Cheng, Sethi, and Taksar (2010) prove the optimality of dynamic (s, S) policies under MMPP for a generalization of classical inventory models.This paper considers a setting similar to that of Song and Zipkin (1993) who focus on proving the optimality of a dynamic (s, S) policy under MMPP demand. Song and Zipkin (1993) also propose finding the optimal (s, S) policy by utilizing a general dynamic programming algorithm with a mean value iteration approach. In this paper, we derive the equations to calculate the long-run cost for a given (s, S) policy which allows us to easily evaluate and compare inventory policies. To elaborate, the main contribution of this paper is proposing computationally efficient numerical techniques to evaluate the expected cost for a given dynamic (s, S) policy coupled with an effective optimization technique to identify cost saving policies. This provides computational improvements over Song and Zipkin (1993), and similar works in the literature. We also obtain managerial insights based on the structure of the obtained policies, mostly, in terms of the effect of demand correlation brought by the MMPP. Song and Zipkin (1993) do not analyze the effect of correlation on the ordering policy.The contribution of this paper is significant given the observed difficulty in evaluating dynamic (s, S) policies. For example, Beyer et al. (2010) point out that existing approaches to calculate the state-dependent parameters of (s, S) policies can be computationally prohibitive. Beyer et al. (2010) further suggest that efficiently identifying optimal (s, S) policy parameters is a difficult but interesting area for future research. This paper is along the line of research suggested by Beyer et al. (2010).We present a computationally efficient approach for evaluating inventory control systems operating under Markovian demand. The approach allows capturing, with ease, realistic factors that cannot be otherwise modeled easily such as correlation and time-dependency. The recent literature on fitting Markovian distributions (such as MMPP) to real-world data (e.g., Gusella, 1991; Nelson & Gerhardt, 2011), further strengthens the contribution of this paper.The remainder of this paper is organized as follows. The notation and model description of the continuous and dynamic replenishment model is presented in Section 2. The characteristics of the correlated demand process which are needed to analyze the inventory system are identified in Section 3, where the equations and algorithms to calculate the corresponding characteristics are also presented. The system of equations to calculate the steady state probability distribution of the inventory position are presented in Section 4. The system costs resulting from holding, backorders and ordering are presented in Section 5, based on steady state measures from the previous sections. Heuristics to determine static and dynamic reorder policies are presented in Section 6. Numerical examples are presented in Section 7 where the reorder policies and costs are calculated, and compared, for the different heuristics. The cases are varied in relation to the impact of correlation on the demand-count process as well as the cost parameters. Section 8 concludes the paper and presents future research directions. For completion, detailed proofs are presented in the appendices as well as the source data for the figures used in the numerical examples.Consider an inventory system with the inter-arrival times of demand following a MMPP. The state of the system is represented by the MMPP embedded continuous time Markov Chain (CTMC). Let {A(t): t ≥ 0} be the state of the embedded-CTMC at time t whereA(t)∈{1,2,…,m}. The demand rate at time t is λnifA(t)=nforn=1,…,m. The transition rate from state i to state j of the embedded-CTMC is σi, jfori,j=1,…,mand i ≠ j. When demand at a time t exceeds the on-hand inventory, it is assumed that excess demand is backordered. The reorder policy changes dynamically according to the state of the environment, i.e., the reorder policy at time t is (sn, Sn) ifA(t)=n. This ordering policy is based on the inventory position at time IP(t), which is equal to the inventory on-hand, plus on-order, minus backorders. An order is placed at time t ifA(t)=nand IP(t) ≤ snforn=1,…,m,where the inventory position is replenished to Sn, IP(t+)=Sn. The order is received after a fixed lead time of L time units. Note that this policy can be represented as an equivalent continuous (rn, Qn) policy, wherern=snand the reorder quantityQn=Sn−sn.Note also that the inventory position is bounded by ℓ ≤ IP(t) ≤ u where ℓ and u are the minimum and maximum attainable inventory position respectively,ℓ=min(sn)+1andu=max(Sn).The system costs include an inventory holding cost of h $/unit/unit time and a backordering cost of b $/unit/unit time. In addition, a fixed ordering cost of ω dollars is charged every time an order is placed. A summary of the notation used in this paper is listed below.MMPP parameters (correlated demand process)•m = number of states in the embedded-CTMC representing the external environment.σi, j= transition rate between states i and j fori,j=1,…,mand i ≠ j.λi= demand rate when the environment (MMPP) is in state i fori=1,…,m.Cost parameters•h: holding cost per unit per unit time.ω: fixed cost per order.b: backorder cost per unit per unit time.Inventory characteristics•NI(t): Net inventory at time t, NI(t) ≡ on-hand inventory (if any) minus the backorder amount (if any) at time t.I(t): Inventory on-hand at time t.B(t): Amount in backorder at time t.O(t): Number of orders placed within the time interval [0, t).IP(t): Inventory position at time t.A(t): State of the embedded-CTMC at time t.L: Lead time.Policy parameters•sn: Reorder point in state n forn=1,…,m.Sn: Reorder level in state n forn=1,…,m.u: Upper limit on IP.ℓ: Lower limit on IP.A dynamic reorder policy is represented by (s¯,S¯) wheres¯={s1,s2,…,sm}andS¯={S1,S2,…,Sm}. Next we consider the demand process and present an approach to calculate demand characteristics over the lead time.In this section, we present an algorithm for computing the demand distribution over the lead time, conditional on the MMPP being in a given state at the beginning of the lead time, and the related conditional moments. This algorithm is based on numerically solving a set of differential equations (Kolmogorov Forward Equations, KFEs), which are described next.The MMPP characteristics are represented by the state transition ratesσ(m × m) and the conditional demand ratesλ(m × 1). The diagonal entries ofσ(m × m) areσi,i=−σi¯whereσi¯=∑j=1j≠imσi,j. We refer the reader to Fischer and Meier-Hellstern (1992) for further details on the MMPP representation.Let {Dt(τ) : t ≥ 0, τ > 0} be the demand-count over the time interval[t,t+τ)whereDt(τ)=0,1,2,…,∞. We augment the demand-count process with the phase of the embedded-CTMC, {A(t), t ≥ 0}, and we define the state space of the demand-count and arrival-phase at timet+τby,{Dt(τ)=c,A(t+τ)=n}. The KFEs of the augmented state space are presented below where the derivative is with respect to τ. (That is,P′(Dt(τ)=c,A(t+τ)=n)=∂P(Dt(τ)=c,A(t+τ)=n)∂τ.) Forc=1,…,∞andn=1,…,m,(1)P′(Dt(τ)=c,A(t+τ)=n)=−λnP(Dt(τ)=c,A(t+τ)=n)+λnP(Dt(τ)=c−1,A(t+τ)=n)+∑j=1mσj,nP(Dt(τ)=c,A(t+τ)=j),forn=1,…,m,(2)P′(Dt(τ)=0,A(t+τ)=n)=−λnP(Dt(τ)=0,A(t+τ)=n)+∑j=1mσj,nP(Dt(τ)=0,A(t+τ)=j).The KFEs presented in (1) and (2) allow for the numerical calculation of the entire probability distribution function of the count process Dt(τ) by conditioning on the state of the Markov process at time t. Based on these KFEs, we present an algorithm to solve for the probability distribution function of the demand-count over an interval of length L conditioned on the state of the embedded Markov chain,Pc|n(L)=P(Dt(L)=c|A(t)=n).Conditional demand-count (CDC) algorithm•Step 0: Setn=1,t=0.Step 1: (Initialize the homogenous system of differential equations (HSDE) in 1 and 2).⊳SetP(D0(0)=0,A(0)=n)=1.SetP(D0(0)=0,A(0)=i)=0fori=1,…,mand i ≠ n.Step 2: Numerically integrate the HSDE in 1 and 2 for τ ∈ [0, L], and forc=0,1,2,…k.Step 3: SetPc|n(L)=∑j=1mP(D0(L)=c,A(L)=j).Step 4: If n < m, setn=n+1and go to Step 2.We refer to the above algorithm by the conditional demand-count (CDC) algorithm. The CDC algorithm finds the conditional demand distribution over the lead time for all possible initial states at the beginning of the lead time,n=1,…m. For computational efficiency purposes this distribution is truncated at an upper limit k, which appears in Step 2 of the algorithm. We select an upper bound k which satisfiesProb(X>k)<ϵwhere X is a Poisson random variable with mean (maxm=1,…,n(λm)L), whereϵis a sufficiently small number. An advantage of this approach for selecting k is that the CDC algorithm becomes independent of the reorder policy.Next, we discuss finding the moments of the demand over the lead time. For this purpose, we need the steady state probability of the embedded-CTMC. Letπ(1 × m) represent the steady state probabilities of the embedded-CTMC where πiis the steady state probability of being in phase i fori=1⋯,m. The steady state probability vector,π, can be calculated by solving the linear equations,(3)πσ=0andπeT=1,where e is a row vector of 1s with length m. Let D(L) be the stationary count process over an interval of length L; i.e.,D(L)=limt→∞Dt(L).It can then be shown that(4)E[D(L)]=(πλ)L.The proof of Eq. (4) is presented in Appendix A. Eq. (4) provides a relatively straightforward approach to calculate the mean of the demand over the lead time, which is independent of the CDC algorithm. To calculate higher moments, the probability distribution resulting from the CDC algorithm can be used. The rth moment of the conditional demand-count forr=1,2,…is calculated as,(5)E[Dr(L|n)]=∑c=1kcrPc|n(L),and the corresponding steady state demand-count moment over L,(6)E[Dr(L)]=∑n=1mE[Dr(L|n)]πn.In the following section, we calculate the steady state characteristics of the system inventory.For a given dynamic reorder policy, (s¯,S¯) wheres¯={s1,s2,…,sm}andS¯={S1,S2,…,Sm},the state of the dynamic inventory position at time t is represented by the value of the inventory position at time t and the state of the embedded Markov chain at time t. Recall (from Section 2) that the inventory position at time t isIP(t)∈{ℓ,ℓ+1,…,u},whereℓ=min(sn)+1andu=max(Sn),and the state of the embedded Markov chain is A(t) ∈ {1, 2, ⋅⋅⋅, m}. The resulting inventory position Kolmogorov Forward Equations (IP-KFEs) are presented in Eq. (7) for sn< i < u, i ≠ Snandn=1,…,m,(7)P′(IP(t)=i,A(t)=n)=−λnP(IP(t)=i,A(t)=n)+∑j=1mσj,nP(IP(t)=i,A(t)=j)+λnP(IP(t)=i+1,A(t)=n),For completion, the entire set of IP-KFEs fori=ℓ…uandn=1,…,mare presented in Appendix B. The next step is to compute the steady state probabilities of the IP states. LetIP=limt→∞IP(t)andPi,n=limt→∞P(IP(t)=i,A(t)=n).Setting the right hand side of Eq. (7) to 0 and t → ∞,(8)−λnPi,n+∑j=1mσj,nPi,j+λnPi+1,n=0.The steady state joint IP-MMPP probabilities, Pi, n, are obtained by solving the linear system of equations in (8) along with,(9)∑i=sn+1uPi,n=πn,forn=1,…,m.The required number of linear equations to solve is∑n=1m(u−sn)≤(u−ℓ+1)m. Finally, The expected IP at steady state is,(10)E[IP]=∑n=1m∑i=sn+1uiPi,n.Here we present the equations to calculate the performance measures that account for the total system cost. We begin with the net inventory where it can be seen that (e.g., Maddah, Jaber, & Abboud, 2004),(11)NI(t)=IP(t−L)−Dt−L(L).Let NI be the net inventory at steady state,NI=limt→∞NI(t). It follows from Eq. (11),(12)E[NI]=E[IP]−E[D(L)].The right hand side terms of Eq. (12) are calculated from Eqs. (4) and (10). Let I(t) be the on-hand inventory at time t andI=limt→∞I(t). The on-hand inventory at time t,(13)I(t)=max(NI(t),0).By conditioning on being in state n at timet−L,it follows that,(14)E[I(t)]=∑n=1mE[I(t)|A(t−L)=n]P(A(t−L)=n),where, utilizing Eqs. (11) and (13) and conditioning onA(t−L)=n,(15)E[I(t)|A(t−L)=n]=∑y=0u∑k=0y−1(y−k)P(Dt−L(L)=k|A(t−L)=n)×P(IP(t−L)=y|A(t−L)=n).LetE[I|n]=limt→∞E[I(t)|A(t−L)=n],(16)E[I|n]=∑y=0u∑k=0y−1(y−k)fD|n(k)fIP|n(y),wherefD|n(k)=Pk|n(L)andfIP|n(y)=P(IP=y|A=n)=P(IP=y,A=n)/P{A=n}=Py,n/πn. Solving for the conditional expectation in Eq. (16) allows us to calculate the expected steady state on-hand inventory as,(17)E[I]=∑n=1mE[I|n]P(A=n)=∑n=1mE[I|n]πn.Solving Eqs. (17) and (12), the expected number of backorder at steady state is calculated using,(18)E[B]=E[I]−E[NI].To obtain the expected ordering cost, we solve for the number of orders placed per unit time. Let R(τ) be the stationary number of orders placed over an interval of length τ. The number of orders per unit time (OPU) is expressed as,(19)OPU=∑n=1m(λnPsn+1,n+∑k=ℓsn∑j=1mσj,nPk,j).The proof of Eq. (19) is presented in Appendix A.Finally, for a given reorder policy, (s¯,S¯), the expected cost per unit time (TCPU) is(20)Φ(s¯,S¯)=hE[I]+bE[B]+ωOPU.Next we summarize the calculation ofΦ(s¯,S¯)by the algorithm presented below which is initialized by computing the conditional demand-count probability distribution, Pc|n(L), via the CDC algorithm in Section 3. The algorithm presented below calculates the cost function per unit time,Φ(s¯,S¯),for any (s¯,S¯) reorder policy. We refer to the following algorithm by the Cost Function (CF) algorithm.Algorithm to solve for the Cost FunctionΦ(s¯,S¯)– CF Algorithm•Step 1: Solve the linear system of equations – Eqs. (8) and (9)⊳−λnPi,n+∑j=1mσj,nPi,j+λnPi+1,n=0∑i=sn+1uPi,n=πn.Step 2: SetE[IP]=∑n=1m∑i=sn+1uiPi,n,Eq. (10).Step 3: SetfD|n(k)=Pk|n(L)andfIP|n(y)=Py,n/πnfory=0,…,u,k=0,…,uandn=1,…,m.⊳SetE[I|n]=∑y=0u∑k=0y−1(y−k)Pk|n(L)fIP|n(y),Eq. (16).SetE[I]=∑n=1mE[I|n]πn,Eq. (17).Step 4: SetE[B]=E[I]−E[NI],Eq. (18).Step 5: SetOPU=∑n=1m(λnPsn+1,n+∑k=ℓsn∑j=1mσj,nPk,j),Eq. (19).Step 6: SetΦ(s¯,S¯)=hE[I]+bE[B]+ωOPU,Eq. (20).In this section, we consider existing reorder policies which are based on the approximation that the demand-count process over lead time, D(L), follows a Normal distribution. We also present an optimization heuristic to calculate the reorder policy which minimizes the expected cost,Φ(s¯,S¯),which is calculated by the CF algorithm in Section 5. We first consider heuristics where the reorder policy is fixed and cannot be changed according to the demand environment, Section 6.1. We refer to such heuristics as static. We then consider dynamic heuristics where the reorder policy is allowed to change with the demand environment, Section 6.2.Consider the static ordering policy as presented in Silver, Pyke, and Peterson (1998) (see also Hadley & Whitin, 1963) which determines the ordering policy based on the demand rate and the standard deviation of the demand-count process over the lead time. The ordering policy is based on the assumption that the demand-count over the lead time follows a Normal distribution with mean E[D(L)] and standard deviation Stdv(D(L))). The reorder point for this heuristic is(21)sh=E[D(L)]+zStdv(D(L)),whereE[D(L)]=(πλ)Lfrom Eq. (4) and Stdv(D(L)) is calculated based on the second moment of D(L) given in Eq. (6) forr=2,and z is the solution to the equation,(22)Gu(z)=QStdv(D(L))(hb+h),where Gu(z) is a function used to calculate the expected amount of backorders per ordering cycle,(23)Gu(z)=∫z∞(u−z)12πe−u2/2du,see Silver et al. (1998) for more details on Gu(z), and Q is calculated as based on the economic order quantity (EOQ) model as(24)Q=2ωλeh,with λebeing the effective demand rate which is derived from Eq. (4) as(25)λe=E[D(τ)]τ=(πλ),The order up to level is then calculated as(26)Sh=sh+Q.We refer to this approach as the Normal approximation static heuristic. LetTCPUS,h=Φ(she,She)be the expected cost per unit time from this heuristic, which is computed based on the CF algorithm in Section 5 (recall that e is a row vector of 1s with length m).A computationally simpler heuristic is to use a one-moment approximation by assuming Poisson arrivals by settingStdv(D(L))=E[D(L)]=(πλ)Lin Eqs. (21) and (22). We refer to this approach as the Poisson approximation heuristic. Let (sp, Sp) andTCPUS,p=Φ(spe,Spe)be the ordering policy and the resulting expected cost per unit time from this heuristic. (The expected cost Φ(spe, Spe) is obtained from the CF algorithm in Section 5.)Finally, we present an alternative heuristic, which attempts to find the best static policy possible. This heuristic relaxes the assumption that the demand-count process over the lead time follows a Normal distribution and calculates an ordering policy (ss, Ss) based on minimizing the expected cost under the static policy Φ(se, Se), where Φ(se, Se) is also obtained from the CF algorithm in Section 5. We refer to this approach as the static ordering policy (SOP) heuristic. For finding the ordering policy (ss, Ss) of this heuristic, we utilize the following one-way search algorithm. The algorithm is initiated with the ordering policy of the Poisson approximation heuristic (sp, Sp). Then, a line search is done on the reorder point sswhile holding the order-up-to-level, S, fixed. The resulting reorder point is then held fixed, and a line search is done on S. This process is repeated until no further improvement is possible. Our numerical study indicates that this algorithm always converges to a local minimum. However, there is no guarantee of global optimality of the resulting solution (over the space of static policies) as the expected cost functionΦ(s¯,S¯)is generally not convex (but rather ω-convex; e.g.  Song & Zipkin, 1993). The resulting expected cost per unit time from the SOP heuristic isTCPUS=Φ(sse,Sse).Static ordering policy (SOP) heuristic•Step 0: (Initialization)⊳Execute the CDC algorithmSet(so,So)=(sp,Sp)Step 1: Set ss=argminsΦ(se, Soe)Step 2: Set Ss=argminSΦ(sse, Se)Step 3: (Termination Condition)⊳Terminate if(ss,Ss)=(so,So),elseSet(so,So)=(ss,Ss)and go to Step 1.We conclude this section by summarizing in Table 1the notation of our three static heuristics.We consider two heuristics where the ordering policy changes dynamically with the MMPP embedded-CTMC. The first dynamic policy assumes a Normal distribution for the conditional demand-count process over the lead time, D(L|n), forn=1,…,m,with mean E[D(L|n)] and standard deviation Stdv(D(L|n)). In this paper, the values for E[D(L|n)] and Stdv(D(L|n)) are obtained from Eq. (5) forr=1,2. The ordering policy in state n, (sn, h, Sn, h), is obtained similar to the static Normal approximation heuristic in Section 6.1 with E[D(L|n)] and Stdv(D(L|n)) replacing E[D(L)] and Stdv(D(L)) in Eqs. (21) and (22). The resulting ordering policy is denoted by (sh¯,Sh¯) wheresh¯={s1,h,…,sm,h}andSh¯={S1,h,…,Sm,h}and the corresponding cost per unit time isTCPUD,h=Φ(sh¯,Sh¯). We refer to this heuristic as the dynamic Normal approximation heuristic.The second approach relaxes the assumption that the demand-count process over the lead time follows a Normal distribution and the ordering policy, denoted by (sd¯,Sd¯)=({s1,d,…,sm,d},{S1,d,…,Sm,d}),is based on minimizing the expected costΦ(s¯,S¯),which is obtained from the CF algorithm in Section 5. We refer to this approach as the dynamic ordering policy (DOP) heuristic. For finding the ordering policy (sd¯,Sd¯) of DOP, we utilize a one-way search algorithm similar to that of SOP heuristic in Section 6.1, with the search carried over m directions instead of two only in SOP. Similar to SOP, DOP is initiated with an ordering policy which is based on the Poisson approximation heuristic (sp, Sp) from Section 6.1. The full algorithm is presented below. Our numerical study indicates that the DOP algorithm always converges to a local minimum, similar to SOP. However, similar to SOP also, there is no guarantee of global optimality because the expected cost function is not convex. The fact, that in our numerical study, DOP always produced ordering policies which are superior (i.e. having lower expected cost) than all the heuristics discussed thus far, coupled with the optimality of the(s¯,S¯)policy structure (e.g.  Song & Zipkin, 1993), lead us to conjecture that DOP indeed produces globally optimal ordering polices.To elaborate on our conjecture on the optimality of DOP, we perform an extensive numerical testing, with a large number of instances. We fail to find any counter examples where DOP produces sub-optimal solutions. However, our numerical study revealed that our cost function,Φ(s¯,S¯)is not in general quasiconvex. This was revealed by a counter example where initializing DOP with an arbitrary solution converged to a solution with a higher objective value than that obtained with the “standard” DOP initialized with the solution of the SOP heuristic. Since cyclic coordinate methods like DOP typically converge to a stationary point (e.g.  Bazaraa, Sherali, & Shetty, 1993, p. 285; Luenberger & Ye, 2008, p. 253), this implies the lack of quasiconvexity. The counter example is included in Appendix E.Given the lack of convexity of the cost function, establishing that DOP always converges to a global optimal solution is hard, especially with the lack of results in the literature on the properties of (s, S) cost functions under correlated demand. However, the excellent performance of DOP suggests that our cost function inherits some of the useful properties of the renewal demand case. Example of these properties, for the static policy case, include convexity in s for a fixed S and pseudoconvexity in S in some settings (e.g.  Sahin, 1982; Zheng & Federgruen, 1991).Dynamic ordering policy (DOP) heuristic•Step 0: (Initialization)⊳Execute the CDC algorithmSet(so¯,So¯)=(spe,Spe)and(so¯,So¯)=({s1o,…,smo},{S1o,…,Smo}).Step 1: Seti=1,j=1.Step 2: (reorder points)⊳Set si=argminsiΦ({s1,s2,…,si,si+1o,…,smo},So¯)Seti=i+1Go to Step 2 if i ≤ m, otherwise go to Step 3.Step 3: Sets¯={s1,s2,…,sm}.Step 4: (order-up-to levels)⊳Set Sj=argminSjΦ(s¯,{S1,S2,…,Sj,Sj+1o,…,Smo})Setj=j+1Go to Step 4 if j ≤ m, otherwise go to Step 5.Step 5: SetS¯={S1,S2,…,Sm}.Step 6: (Termination condition)⊳Terminate if(s¯,S¯)=(so¯,So¯)and set(sd¯,Sd¯)=(s¯,S¯),elseSet(so¯,So¯)=(s¯,S¯)and go to Step 1.The computational efficiency of the DOP algorithm is highly dependent on the computational effort required to calculate the cost functionΦ(s¯,S¯)for any ordering policy(s¯,S¯)as described by the CF algorithm in Section 5. The main complexity involved in the CF algorithm is solving a system of linear equations to calculate the probability distribution of the IP-MMPP states (Step 1 of the CF algorithm), where the number of equations ise=∑n=1m(u−sn). It can be easily seen thate≤(u−ℓ+1)m. The computational complexity is mainly that of inverting a (e × e) matrix which is typically of the order O(mδ) where δ < 3 (e.g.  Press, Teukolsky, Vetterling, & Flannery, 1992). The remaining system measures and costs are calculated as a function of the IP-MMPP probability distribution in steps 2–6 of the CF algorithm. The other numerically demanding part of the DOP algorithm is calculating the demand-count distribution via the CDC algorithm (step 0 of DOP). This requires numerically integrating(m+1)×kdifferential equations, where k is an upper bound on the demand, as described in Section 3. However, this is only executed once as an initialization step of the DOP algorithm. In our numerical examples, we solve the CDC differential equations efficiently utilizing Matlab. This is typically done in few seconds. Matlab utilizes a variant of the Runge-Kutta method. One more factor that contributes further to the efficiency of the DOP algorithm is that it will be typically applied to expensive (class A products), which are typically slow-moving. It is customary to limit the applicability of sophisticated (s, S) policies such as DOP to class A products in order to justify the coding and computational overhead (e.g.  Silver et al., 1998). For slow-moving, class A products, the values of the parameters e and k would typically be small, which reduces the computational effort.In the next section we consider numerical examples where we compare the performance of the heuristics presented in this section. We also report the execution time of the DOP heuristic as a measure of computational efficiency. Table 2presents the notation for the two dynamic heuristics considered in this section.The inter-demand epochs as modeled by the MMPP result in an auto-correlated process. In this section, we consider cases where the expected time spent in an environment is varied and we investigate the impact of correlation on the demand-count process and consequently the system performance measures. Accordingly, we start this section by discussing how to measure the correlation of MMPP. Measures to evaluate and quantify the impact of correlation on the count process has been addressed in the literature. The limit of the index of dispersion of counts, I∞, is utilized as a measure of variability and correlation within the MMPP demand process, see Nelson and Gerhardt (2011) and Gusella (1991), and can be expressed as,(27)I∞=Var(D(∞))E[D(∞)]=cv2(1+2∑k=1∞ρk),where cv2 is the coefficient of variation of the time between consecutive demand epochs and ρkis the lag-k auto-correlation. To quantify the impact of inter-demand auto-correlation on the variability of the demand-count process, we utilize the Coefficient of Variation due to Correlation (CVC),(28)CVC=1−I∞RI∞=2∑k=1∞ρk1+2∑k=1∞ρk,whereI∞Ris the index of dispersion of counts for a renewal process exhibiting the same expected duration between demand epochs and cv2 as the MMPP. The CVC identifies the proportion of variability in the count process, measured by I∞, which is due to correlation. Notice that CVC is 0 for a renewal process and approaches 1 for highly correlated processes. As can be seen from Eq. (28), the CVC is a function of the lag-k inter-demand auto-correlation fork=1,…,∞and the value of CVC is a measure of the impact of the auto-correlation on the demand-count variability. We refer to Nasr, Charanek, and Maddah (2014) for more information on the CVC. The value of cv2 is a measure of inter-demand variability and does not account for auto-correlation.For a two phase MMPP, the CVC can be calculated from Eq. (28) by setting,(29)I∞=1+2σ1,2σ2,1(λ1−λ2)2(σ1,2+σ2,1)2(λ1σ2,1+λ2σ1,2),and(30)I∞R=cv2.We refer to Gusella (1991) for more details on Eqs. (29) and (30). We present the equation to calculate cv2 for a two phase MMPP in Appendix C.Now that we defined the characteristics to quantify the variability and correlation of our MMPP demand, we present numerical results centered around these characteristics. The first set of our numerical examples consider a two-state MMPP modeling an environment with two regimes of high and low demand. Consider a base case with the following parameters,ω=20$/order,h=0.5$/unit/unittime,b=10$/unit/unittime. The lead time isL=4time units and the MMPP parameters areσ1,2=σ,σ2,1=5σ,λ1=1,andλ2=20. These MMPP parameters represent an environment with a high demand regime (state 2 of the MMPP) which is somewhat short and with a high peak in this period. We believe this is the case in many real systems. The parameter σ is an absolute measure of the time spent in a MMPP state, where a low value of σ indicates a long time in each state. We consider ten cases where σ is varied as presented in Table 3, with all other parameters held fixed at their base values. Specifically, we setσ=(κL)−1,where κ is varied according to the values in Table 3. Table 3 also reports the characteristics of the resulting MMPP demand process, where I∞ are measures of variability in the demand count process due to both inter-demand variability and auto-correlation, and CVC is a measure of the fraction of this variability due to correlation.Larger values for κ result in longer stretches of time spent in an environment. As can be seen from Table 3, larger values of κ increase the impact of correlation on the count process (CVC).In Tables 4and 5 we compare the performance of different ordering policies presented in Section 6, on the cases in Table 3. The DOP heuristic outperformed all other policies in all cases of Table 3 (and many other cases not shown here). Accordingly, we benchmark the performance of other heuristics against DOP via a metric measuring the expected cost saving from utilizing DOP. Specifically, the relative saving from using DOP over heuristic X, whereX=S(for SOP), P (for Poisson approximation), S, h (for static Normal approximation), and D, h (for dynamic Normal approximation), is given by(31)ΔX=TCPUX−TCPUDTCPUX.Table 4 compares the SOP and DOP, which are believed to be optimal over the classes of static and dynamic policies, respectively. Table 4 reveals an interesting managerial insight that even the best static policies (like SOP) perform poorly when the demand correlation is high. For example, in Case 1, of Table 4, where demand auto-correlation is high, as reflected by a CVC value of 99.26 percent in Table 3, the saving from using DOP over SOP is ΔS≈ 54 percent. That is, using a highly refined static policy such as SOP will lead to more than the double of the expected cost of the “optimal” dynamic policy. In other words, significant cost savings can be achieved when utilizing dynamic policies when demand correlation is high. A similar observation can be made on Cases 2 and 3 of Table 3, where significant savings of around 39 percent and 20 percent, respectively, are reported from using dynamic (DOP) over static ordering policies (SOP). Table 4 indicates, however, that, when correlation is low, as in Cases 8–10 of this table, where CVC is below 55 percent (Table 3), a static policy, like SOP, performs competitively when compared to an optimized dynamic policy (DOP), with insignificant cost savings of utilizing DOP, which are below 0.35 percent. In terms of contribution to the literature, Table 4 attempts to identify when are dynamic policies beneficial, and to quantify the benefits over static policies. As discussed in Section 1, the literature has been concerned with demonstrating the mathematical optimality of dynamic (s, S) policies without much analysis on quantifying the benefits of adopting these policies in practice, e.g., Sethi and Cheng (1997) and Song and Zipkin (1993). In terms of computational efficiency, our experience with DOP has been quite encouraging, with the execution time of DOP not exceeding 10 seconds in all cases of Table 4.Table 5analyzes the performance of the dynamic Normal approximation heuristic against DOP. This allows us to investigate whether simple dynamic policies (which are computationally efficient and intuitively appealing like the Normal approximation) can substitute sophisticated dynamic policies like DOP (which may be costly to implement in practice). Table 5 indicates a reasonable performance of the dynamic Normal approximation with saving from using DOP below 15 percent in all cases. The saving from using DOP is most significant when demand correlation is high as in Cases 1–3 of Table 5. We conclude that dynamic heuristics, such as the normal approximation, should be applied when (i) demand correlation is high, and (ii) cost savings do not matter much as for non-critical class B and C items. When correlation is high, and cost cutting is important as for critical, class A items, then the optimized DOP policy should be used.11In practice, the ABC product classification is typically based on unit cost times annual demand (value of inventory). Class A products typically account for 20 percent of the products that cover 80 percent of the value, Class B products typically account for 30 percent of the products that cover 15 percent of the value, and Class C typically account for 50 percent of the products that cover 5 percent of the value. See, for example, Silver et al. (1998).Table 6analyzes the performance of static Normal and Poisson approximations heuristics against DOP. This analysis is expected to be useful when correlation is low and a static policy may be appropriate as discussed above. As expected, the static Normal approximation performs well when correlation is low as in Cases 7–10 of Table 6, where the savings from using the refined dynamic DOP policy, measure by ΔS, h, are approximately below 5 percent. This suggests that the static Normal approximation is a good policy when (i) demand correlation is low, and (ii) cost savings do not matter much as for class B and C items. The performance of the Poisson approximation heuristic is of much inferior quality, as reflected by ΔP> 15 percent in most cases of Table 6. This suggests that the Poisson approximation is only good as a starting solution for more refined policies such as SOP and DOP (as we do in Section 6).At this stage, it is useful to summarize the findings from Tables 4 and 5 in terms of when to use the different ordering policies discussed in Section 6, in practice. Table 7summarizes the findings based on two factors (i) demand auto-correlation and (ii) criticality of the product. It is useful to note here that the Normal approximation heuristics suggested for class B and C items in Table 7 can be implemented quite easily in practice by directly estimating the mean and standard deviation of the demand from available data, without utilizing Eq. (5). For the dynamic Normal approximation, the mean and standard deviation should be estimated in each state of the environment.Next we investigate the effect of changing the cost parameters on the performance of different heuristics. We consider a base case which corresponds to Case 3 in Table 3, which is a case exhibiting demand correlation as reflected by a CVC of around 96 percent. In Figs. 1–3, we fix all parameters at their base values, and change the unit holding cost, h, the unit backordering cost b, and the fixed ordering cost ω, respectively. We report on the total cost per unit time for the DOP, dynamic Normal, SOP and static Normal heuristics which are denoted by TCPUD, TCPUD, h, TCPUSand TCPUS, h, respectively. We choose not to report on the Poisson approximation here because it significantly performed worse than other policies in all the tested cases. The optimal order policies for the DOP and dynamic Normal are presented in Tables 11-13 in Appendix D. Figs. 1–3 indicate that the relative saving from using DOP increases as different costs are increased, indicating significant cost savings as a result of adopting “optimal” dynamic policies like DOP. Figs. 1–3 also indicate that for Case 3, which exhibits high demand correlation, the DOP outperforms the other heuristics as the cost parameters are varied. The dynamic Normal approximation is the second best heuristic in most cases, with some exceptions as indicated in Fig. 2, where it is outperformed by SOP.Finally, we consider a set of numerical examples where the state of the world is represented by three phases. A three-state Markov switching approach is commonly used to model the transition between business cycles, see Nickella, Perraudinb, and Varottoa (2000). The business cycle representing the external environment alternates between the states, Trough, Normal and Peak. In our example, the long run proportion of time spent in either the Trough or Peak states is 25 percent and the long run proportion of time spent in a Normal state is 50 percent.Let πt, πnand πpbe the long run proportions of time spent in the Trough, Normal and Peak states, respectively, whereπt=πp=0.25andπn=0.5. Accordingly, the Markov switching between the states of the world is represented by the embedded MMPP state transition rates as follows,σ=γ(−2321234−32341232−2).Notice that the parameter γ is a measure of the time spent in a MMPP state. The expected time spent in a Normal business cycle before transitioning to another cycle isγ−1. Similarly, the expected time spent in a Trough (Peak) business cycle before transitioning to another cycle is(2γ)−1. The parameter γ can be adjusted while keeping the probabilities πt, πnand πpfixed. We assume the following values for the demand rate parameters,λ1=1,λ2=3andλ3=20. Consider a base case with lead timeL=4and cost parameters,ω=20$/order,h=2$/unit/unittime,b=8$/unit/unittime.We consider six cases where γ is varied. We setγ=κLwhere κ is increased according to the values in Table 8. Table 9compares the performance of the DOP heuristic with the performance of the SOP heuristic. According to the results of Table 9, the cases where demand exhibits a CVC exceeding 96 percent (Cases 1–3), the saving of the DOP over SOP, ΔS, range from 34.52 percent to 57.82 percent. This is consistent with the previous observation that the savings are significant when using DOP over SOP for a highly correlated demand process. The performance of the DOP approaches that of the SOP as the expected time spent in a state decreases, with a smaller γ, where the DOP reorder points, si, dand reorder quantity, Si, d(fori=1,2,3), approach the SOP reorder point, ss, and reorder quantity, Ss, respectively.Table 10presents the results of the dynamic Normal heuristic for Cases 1–6 in Table 8.As can be seen from Tables 9 and 10, the savings of implementing the DOP over the dynamic Normal, ΔD, h, are not as significant as the savings of implementing the DOP over the SOP, ΔS, for high demand correlation. This is consistent with the previous observation that dynamic heuristics such as the DOP and the dynamic Normal perform better than static heuristics in fluctuating environments with highly correlated demand (Cases 1–3). However, the savings, ΔD, h, over the six cases range from 13.20 to 16.08 which justifies the added complexity of utilizing DOP especially for Class A items where cost cutting is critical.In this paper, we analyze (s, S) type policies for a continuous review inventory system in a fluctuating demand environment following a MMPP. The main contribution of this work with respect to the literature is proposing an efficient computational scheme for evaluating dynamic and static (s, S) policies under MMPP demand. We also contribute useful managerial insights and practical heuristics tailored by the level of demand correlation and the criticality of the product at hand. We find that even the best static policies, with fixed (s, S) values in all demand environments, cannot replace a good dynamic policy, where the values of the (s, S) control parameters vary with the environment. We also find that Normal approximation-based heuristic provide practical approaches to manage non-critical (class B and C) products with minimal computational effort. It is important, however, to adjust the (s, S) parameters of the Normal approximation policy dynamically with the environment when demand correlation is high.The MMPP is used in the literature to model fluctuating demand processes is adopted in this paper to analyze (s, S) policies. However, the more general Markovian Arrival Processes (MAPs) can be considered as a more general demand model using the same approach presented here. We also point out that the framework presented in this work can be utilized in future research to include time dependency which is applicable to demand exhibiting seasonality. In such a case, the steady state equations do not hold and solving for the system performance measures is possible via numerically solving the time-dependent differential equations.Proof ofEq. (4). Using the KFEs of Eqs. (1) and (2),(32)E′[Dt(τ)]=∑n=1mE′[Dt(τ),A(t+τ)=n]=∑n=1m(∑c=1∞cPc,n′)=−∑n=1m(λn+σ¯n)E[Dt(τ),A(t+τ)=n]+∑n=1m∑j=1mσj,nE[Dt(τ),A(t+τ)=n]+∑n=1mλn(E[Dt(τ),A(t+τ)=n]+P(A(t+τ)=n))=∑n=1mλnP(A(t+τ)=n).Taking the limit as t → ∞ in (32) results in,E′[D(τ)]=∑n=1mλnπn.It follows thatE[D(τ)]=(∑n=1mλnπn)τ=(πλ)τ,which completes the proof.Proof ofEq. (19)Let R(τ) be the stationary number of orders placed over an interval of length τ. LetΓr,i,n=P(R(τ)=r,IP(τ)=j,A(τ)=n)fori=ℓ,…,u,n=1,…,mand r ≥ 0. The corresponding KFEs are,for ℓ < i < u and i ≠ Sn(33)Γr,i,n′=−(λn+σ¯n)Γr,i,n+∑j=1mσj,nΓr,i,j+λnΓr,i+1,n.Fori=Sn,(34)Γr,Sn,n′=−(λn+σ¯n)Γr,Sn,n+∑j=1mσj,nΓr,Sn,j+λnΓr,Sn+1,n+λnΓr−1,sn+1,n+∑k=ℓsn∑j=1mσj,nΓr−1,k,j.Define the partial expected valueE[R;i,n]=E[R(τ),IP(τ)=i,A(τ=n)]fori=ℓ,…,uandn=1,…,m. Referring to Eqs. (33) and (34) the differential equation for the partial expected values where the derivative is with respect to τ, for ℓ ≤ i < u and i ≠ Sn,(35)E′[R;i,n]=∑r=0∞rΓr,i,n=−(λn+σ¯n)E[R;i,n]+∑j=1mσj,nE[R;i,j]+λnE[R;i+1,n].Fori=Sn(36)E′[R;Sn,n]=∑r=0∞rΓr,Sn,n=−(λn+σ¯n)E[R;Sn,n]+∑j=1mσj,nE[R;Sn,j]+λnE[R;Sn+1,n]+λn(E[R;sn+1,n]+Psn+1,n)+∑k=ℓsn∑j=1mσj,n(E[R;k,j]+Pk,j).Summing Eqs. (35) and (36) overi=ℓ,…,u,(37)E′[R,n]=λnPsn+1,n+∑k=ℓsn∑j=1mσj,nPk,j.Summing Eq. (37) over n forn=1,…,m,(38)E′[R(τ)]=∑n=1mE′[R,n]=∑n=1m(λnPsn+1,n+∑k=ℓsn∑j=1mσj,nPk,j).The IP-KFEs,for sn< i ≤ u, i ≠ Snandn=1,…,m,(39)P′(IP(t)=i,A(t)=n)=−λnP(IP(t)=i,A(t)=n)+∑j=1mσj,nP(IP(t)=i,A(t)=j)+λnP(IP(t)=i+1,A(t)=n),fori=Sn,i≠uandn=1,…,m,(40)P′(IP(t)=Sn,A(t)=n)=−λnP(IP(t)=Sn,A(t)=n)+∑j=1mσj,nP(IP(t)=Sn,A(t)=j)+λnP(IP(t)=Sn+1,A(t)=n)+λnP(IP(t)=sn+1,A(t)=n)+∑k=ℓsn∑j=1j≠nmσj,nP(IP(t)=k,A(t)=j),fori=uandn=1,…,m,(41)P′(IP(t)=u,A(t)=n)=−λnP(IP(t)=u,A(t)=n)+∑j=1mσj,nP(IP(t)=u,A(t)=j)+λnP(IP(t)=sn+1,A(t)=n)+∑k=ℓsn∑j=1j≠nmσj,nP(IP(t)=k,A(t)=j),Calculating cv2,(42)cv2=μ2−μ12μ12,where μ1 and μ2 are the first and second moments of the time between consecutive demand epochs. The first moment μ1 is calculated as,(πλ)−1,which follows from Eq. (4). The second moment,(43)μ2=2((λ1+σ1+σ2)σ1+(λ2+σ1+σ2)σ2)(λ1+σ1)(λ2+σ2)(1−c1c2)(λ2σ1+λ1σ2)wherec1=σ1σ1+λ1,c2=σ2σ2+λ2,σ1=σ1,2andσ2=σ2,1(see Gusella, 1991).A counter example (illustrating the sensitivity of DOP to different starting solutions),ExampleLetL=4,b=4,h=2,ω=50. Consider a three-state MMPP demand whereλ1=10,λ2=11,λ3=12andσ=(−123818316−383161838−12).Solving the DOP heuristic with the following starting point(so¯,So¯)=({30, 30, 30}, {80, 80, 80}) results in(s¯,S¯)=({31, 31, 31}, {63, 65, 67}) andTCPUD,h=Φ(s¯,S¯)=43.12.Whereas utilizing the solution of the SOP heuristic as the starting point of the DOP results in,(so¯,So¯)=({33, 33, 33}, {65, 65, 65}) which results in(s¯,S¯)=({33, 33, 33}, {63, 65, 66}) andTCPUD,h=Φ(s¯,S¯)=42.90.

@&#CONCLUSIONS@&#
