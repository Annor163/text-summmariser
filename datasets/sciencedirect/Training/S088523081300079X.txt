@&#MAIN-TITLE@&#
Feature analysis for discriminative confidence estimation in spoken term detection

@&#HIGHLIGHTS@&#
Feature analysis for spoken term detection (STD) on English (meeting domain) and Spanish (read speech) data in a discriminative confidence estimation framework.Feature analysis is based on groups that are defined according to their information sources: lattice-based features, duration-based features, lexical features, Levenshtein distance-based features, position and prosodic features (pitch and energy).Feature analysis employs two well-known and established models: linear regression (a generative approach) and logistic linear regression (a discriminative approach). Individual and incremental analyses are presented for both models.Results demonstrate significant improvement with the 3–5 most informative features compared with using the single best feature for STD confidence estimation.The best feature set comprises features from different groups: lattice-based and lexical features are among the most informative groups in general, and duration and energy are more informative for read speech data.

@&#KEYPHRASES@&#
Feature analysis,Discriminative confidence,Spoken term detection,Speech recognition,

@&#ABSTRACT@&#
Discriminative confidence based on multi-layer perceptrons (MLPs) and multiple features has shown significant advantage compared to the widely used lattice-based confidence in spoken term detection (STD). Although the MLP-based framework can handle any features derived from a multitude of sources, choosing all possible features may lead to over complex models and hence less generality. In this paper, we design an extensive set of features and analyze their contribution to STD individually and as a group. The main goal is to choose a small set of features that are sufficiently informative while keeping the model simple and generalizable. We employ two established models to conduct the analysis: one is linear regression which targets for the most relevant features and the other is logistic linear regression which targets for the most discriminative features. We find the most informative features are comprised of those derived from diverse sources (ASR decoding, duration and lexical properties) and the two models deliver highly consistent feature ranks. STD experiments on both English and Spanish data demonstrate significant performance gains with the proposed feature sets.

@&#INTRODUCTION@&#
The enormous amount of speech information now stored in audio repositories motivates the development of automatic audio indexing and spoken document retrieval methods. Spoken term detection (STD), defined by NIST as searching vast, heterogeneous audio archives for occurrences of spoken terms (NIST, 2006), is a fundamental building block of such systems (Mamou and Ramabhadran, 2008; Can et al., 2009; Vergyri et al., 2007; Akbacak et al., 2008; Szöke et al., 2008, 2008; Thambiratmann and Sridharan, 2007; Wallace et al., 2010; Jansen et al., 2010; Parada et al., 2010; Chan and Lee, 2010; Chen et al., 2010; Motlicek et al., 2010), and its development has been strongly influenced by NIST STD evaluations (NIST, 2006, 2013).The standard STD architecture is comprised of two main stages: indexing by the Automatic Speech Recognition (ASR) subsystem, then search by the STD subsystem, as depicted in Fig. 1. The ASR subsystem transforms the input speech into word or sub-word lattices. The STD subsystem comprises a term detector and a decision maker. The term detector searches for putative occurrences of the query terms in the word/sub-word lattices – it hypothesizes detections – and the decision maker then decides whether each detection is reliable enough to be considered as a hit or should be rejected as a false alarm (FA). A tool provided by NIST is used for performance evaluation. It must be noted that the ASR subsystem must run just once and therefore the STD subsystem cannot make use of the speech signal directly.Searching the output of a Large Vocabulary Continuous Speech Recognition (LVCSR) system, i.e., word lattices, has been shown to work well when the query terms are only composed of in-vocabulary (INV) words, since these will be in the LVCSR system vocabulary and therefore will occur in the word lattices. However, as noted by Logan et al. (2000), about 12% of users’ queries typically contain out-of-vocabulary (OOV) words, which will never be found in the word lattices, because they do not appear in the LVCSR system vocabulary. Common approaches to solve this problem usually involve producing sub-word (typically phone/phoneme) lattices with the ASR subsystem, and then searching for sub-word representations of the enquiry terms (Saraçlar and Sproat, 2004; Mamou et al., 2007; Can et al., 2009; Szöke et al., 2006; Wallace et al., 2007; Parlak and Saraçlar, 2008). Other sub-word units are possible, such as syllables (Meng et al., 2007), graphemes (Wang et al., 2008; Tejedor et al., 2008) or multi-grams (Pinto et al., 2008; Szöke et al., 2008).In STD, a confidence score is assigned to each putative occurrence detected in the lattice, which reflects the possibility of it being a real occurrence. A widely used confidence score that can be derived from the lattice is defined as follows:(1)cf=∑πα,πβp(O|πα,Ktste,πβ)P(πα,Ktste,πβ)∑ςp(O|ς)P(ς)whereKtstedenotes a detection of K, which is a partial path that starts at tsand ends at teand corresponds to the pronunciation of term K. cfis the confidence ofKtste. παand πβdenote paths before and after K respectively, with παstarting from the beginning of the audio and πβending at the end of the audio. ς in the denominator represents any full path in the lattice. Note that a particular term occurrence may correspond to a group of overlapped detections{Ktsitei}. In that case, the detection group is treated as a single detection, and cfis derived by a certain merging scheme (Wang et al., 2011). In this work, we simply choose the best confidence of the group members as cf.Based on the confidence scores, the decision maker determines which putative occurrences are reliable enough to be called detections. If a detection actually appears in the audio, it is called a hit. Otherwise, it is called a false alarm. Any occurrence of the query term in the audio that is not hypothesized by the STD system is called a miss.To evaluate STD system performance, NIST defines an evaluation metric called actual term weighted value (ATWV) (NIST, 2006), which integrates the hit rate and false alarm rate into a single metric and then averages over all search terms:(2)ATWV=1|Δ|∑K∈ΔNhitKNtrueK−βNFAKT−NtrueKwhere Δ denotes the set of search terms and |Δ| represents the number of terms in this set.NhitKandNFAKrepresent the number of hits and false alarms of term K respectively andNtrueKis the number of actual occurrences of K in the audio. T denotes the audio length in seconds, and β=999.9 is a weight factor.Various factors impact the performance of STD systems, such as acoustic properties of speech signals, lexical characteristics of search terms, occurrence rates and positions of terms within the evaluation data. These factors also influence the reliability of detections and hence can be utilized in estimating the confidence of detections. Research has been conducted on confidence estimation utilizing various informative factors, in both automatic speech recognition and keyword spotting, e.g., Rohlicek et al. (1989), Cox and Rose (1996), Bergen and Ward (1997), Kemp and Schaaf (1997), Ou et al. (2001), Ayed et al. (2002), Jiang (2005), and various methods have been employed to combine the heterogeneous informative factors, including decision trees (DT), general linear models (GLMs), generalized additive models (GAMs) and multi-layer perceptrons (MLPs) (Chase, 1997; Gillick et al., 1997; Zhang and Rudnicky, 2001). It has been found that features derived from multiple sources – with appropriate normalization – can be combined to serve as a good measure of confidence, which can in turn be used to evaluate the correctness of a recognition hypothesis or a keyword detection.In STD, Vergyri et al. (2007) used MLPs to combine various informative factors into a discriminative confidence. We extended this to a discriminative confidence normalization technique (Wang et al., 2009). This technique provides a general framework which allows any informative factors, or features, to be combined and integrated into an unbiased confidence measure for STD. For example, Wang et al. (2009) used some term-dependent features to compensate for the high diversity among OOV terms, and Tejedor et al. (2010) extensively studied various prosodic, lexical and duration-based features.Although the MLP-based discriminative confidence normalization approach provides a general solution for integrating multiple informative factors, and leads to improved performance, the integration itself remains a ‘black-box’ to a large extent due to the use of MLPs. Contributions from genuinely informative features and trivial features are not separable and so too many features are used because it is not possible to select only the useful ones. Using more features requires more complex model structures, which may reduce the capacity of the model to generalize to new data. This is particularly problematic when the data for training the MLP model are limited; this is the case when the search terms are OOV, since these never occur in training data.This serves as the motivation for the study on feature analysis presented here. Ideally, we would wish to test the contribution of each potentially-informative feature to overall STD performance, and choose those only that have a significant contribution to discriminative confidence estimation. This not only saves cost in model training and scoring, but more importantly reduces the chance of over-fitting to the training data.We could use the MLP model itself to analyze and select the features, however, this requires relatively heavy computation; more importantly, using such a complex model as an MLP for feature selection could result in coming to conclusions that do not generalize well. We therefore use simple and well-known models to conduct an analysis on feature relevance; we then use the results of this analysis in an STD system built using MLP-based confidence estimation and normalization.In previous work (Tejedor et al., 2010), we employed linear regression (LR) to conduct the relevance analysis and feature selection. We found that STD performance could be reduced by using less-relevant features, while more informative features generally improved performance. This is consistent with our hypothesis that blindly pooling together both informative and uninformative features may lead to lower model generality and hence performance reduction.A particular concern with our previous LR analysis, however, is that LR focuses on the most relevant features, while the STD task, which is essentially a classification problem, requires the most discriminative features. This raises doubts about the LR-based analysis since the most relevant features are not necessarily the most discriminative ones. Moreover, in our particular application, LR is employed to predict binary variables (hit/FA). This is essentially a classification task, for which LR is normally considered to be problematic.We therefore consider the logistic linear regression (LLR) to conduct feature analysis and selection. LLR is an extension of LR, which is more suitable for classification tasks and targets the most discriminative features. An interesting finding is that the relevance-oriented LR analysis and the discrimination-oriented LLR analysis lead to highly consistent feature ranks. This confirms that the simple LR analysis is an effective feature selection approach for STD. Note that some researchers have shown that LR and LLR tend to provide consistent results with abundant training data, which coincides with our findings (Hellevik, 2009).In addition to this extension of previous work, we also extend our paper in two other directions: we include more features (particularly phone-level features) in the analysis; we study two languages (English and Spanish) in two domains (meetings for English; read speech in Spanish) in order to discover general as well as task-specific features.We conduct our analysis on OOV terms. The main reason is that STD usually suffers from significant performance degradation on OOV terms, and the unreliable confidence estimation is known to be a major cause (Wang, 2009). We are interested in tackling this difficulty by involving the most discriminative features within the discriminative confidence normalization framework. For INV terms, the standard lattice-based confidence is usually sufficient to obtain a high ATWV, and thus the complicated feature selection is applicable but not essential.The rest of the paper is organized as follows: in the next section we introduce some background information including a summary of some related work and a short review of the discriminative confidence estimation framework. Then in Section 3 we present the experimental configurations used in this work. Section 4 presents the features considered for study. Individual feature analysis based on histograms, LR and LLR is presented in Section 5. Section 6 presents an incremental feature selection approach based on LR and LLR. Section 7 presents STD experiments based on the two feature selection techniques. The paper is concluded in Section 8 together with some discussion and ideas for future work.The contribution of this paper is to start from a large set of candidate predictive features and find the most informative feature set for STD confidence estimation, based on the discriminative confidence normalization framework. We commence by summarizing some related work, particularly focusing on collecting the candidate feature set, feature selection and feature combination. Given this background knowledge, we then present the discriminative confidence normalization framework on which our analysis is based.

@&#CONCLUSIONS@&#
This paper studied various features for STD within the discriminative confidence estimation framework. Two analysis tools based on linear regression and logistic linear regression are employed to study the contribution of these features to STD individually and as a group. The experiments were conducted on two databases: one contains English meeting speech and the other contains Spanish read speech. Our analysis shows that for both the English data and the Spanish data, the lattice-based confidence, the effective FA rate and the minimum phone duration are generally the most important, and the best feature set is composed of features derived from diverse sources (ASR decoding, duration and lexical properties). Although based on different criteria, the LR and LLR analyses lead to highly consistent feature ranks. This indicates that for STD, the most relevant features are also the most discriminative. In spite of the complexity in methodology and data, the candidate features proposed have been demonstrated to deliver significant performance improvements when compared to a baseline using the single best feature.Future work involves more advanced analyzing approaches, especially various approaches to automatic relevance detection (ARD), and sparse discriminative analysis (SDA). Extending the incremental search to more comprehensive search approaches such as evolutionary algorithms might be another interesting direction.