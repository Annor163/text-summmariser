@&#MAIN-TITLE@&#
Lightweight runtime checking of C programs with RTC

@&#HIGHLIGHTS@&#
RTC is a tool for instrumenting C programs with run-time safety checks.It handles memory violations, arithmetic underflow/overflows, and type violations.The instrumented code can be compiled by any C99 compliant compiler.The runtime framework is extremely lightweight, useful for in situ analysis.The overhead is very low compared to other, similar tools available today.

@&#KEYPHRASES@&#
Runtime monitoring,Source code instrumentation,Static analysis,C,C++,

@&#ABSTRACT@&#
The C Programming Language is known for being an efficient language that can be compiled on almost any architecture and operating system. However the absence of dynamic safety checks and a relatively weak type system allows programmer oversights that are hard to spot. In this paper, we present RTC, a runtime monitoring tool that instruments unsafe code and monitors the program execution. RTC is built on top of the ROSE compiler infrastructure. RTC finds memory bugs and arithmetic overflows and underflows, and run-time type violations. Most of the instrumentations are directly added to the source file and only require a minimal runtime system. As a result, the instrumented code remains portable. In tests against known error detection benchmarks, RTC found 98% of all memory related bugs and had zero false positives. In performance tests conducted with well known algorithms, such as binary search and MD5, we determined that our tool has an average run-time overhead rate of 9.7× and memory overhead rate of 3.5×.

@&#INTRODUCTION@&#
One major trend in computing is the continuing increase in the complexity of software systems. Such an increase is allowed by the expectation of increasingly powerful hardware (faster processors, larger memory and disks) and the increasing diversity of environments in which the software runs. This increase in complexity is expensive; the National Institute for Standards and Technology (NIST) estimated that inadequate infrastructure for software testing costs the US economy $22.2 billion annually [31].Many programming languages allow the use of unsafe programming constructs in order to attain a high degree of flexibility and performance. This makes the construction of correct large-scale software difficult. Unsafe language features allow programmer oversights to introduce software flaws which can create security hazards that can compromise an entire system. Eliminating these software flaws can be addressed on many levels in the software engineering process. Rigid coding standards, restricting the use of a large language to a safer subset, peer review, and the use of static or dynamic analysis tools are some means that can all reduce the exposure to software flaws.Analysis tools can be categorized by how they analyze software. Static tools analyze software without running it. They target source code (occasionally binary) to apply formal analysis techniques such as dataflow analysis, abstract interpretation, and model checking; such techniques often use approximations to arrive at sound but imprecise conclusions about the behavior of programs. Dynamic analysis tools find bugs by observing the behavior of running programs. This is typically accomplished by code instrumentation (source or binary) or by replacing (built-in) library functions (e.g., malloc and free) with custom implementations. Dynamic analysis operates with concrete values and is not prone to combinatorial state explosion. The downside of dynamic analysis tools is that monitoring running programs impacts performance. The quality of the results depends on the tests’ input data and covered program paths. Hybrid analyses combine static and dynamic techniques. Hybrid tools can improve performance by eliminating checks that a static analyzer considers safe in all possible scenarios, or they can improve test coverage by producing input values that cover all possible paths.The history of program analysis research now spans several decades, and dozens of tools and techniques have pushed the envelope on our ability to detect and correct bugs. However, in the area of dynamic analysis, certain fundamental challenges remain, namely high overhead costs and lack of portability. Neither of these challenges have gone unnoted, but have been relatively low priority targets for researchers. Severe overhead, in many respects, has been seen as the cost of doing business, a burden that software developers have been willing to tolerate. For dynamic analysis tools that target binaries for instrumentation (the most popular choice), high overhead costs are difficult to avoid. The most efficient way to reduce overhead is to selectively reduce instrumentation where bugs are unlikely or are rendered impossible, but without access to high-level information (e.g. type information) to guide the pruning process, this can be a risky proposition. Meanwhile, the computing landscape has been historically dominated by only a handful of operating systems and varieties of architecture; meeting the portability requirements of developers meant being able to operate in two or three popular environments.However, as we move towards a future where computing pervades every aspect of our daily lives, these challenges become more substantial and more must be done to address them. The most visible signal of the shift to ubiquitous computing has been the proliferation of smartphones and the thriving ecosystem of services that interface with them. However, the most influential transformations have come from the progressive infiltration of embedded computing systems, from critical control devices in medical care and avionics, to smart televisions and coffee machines. Many of the most popular languages for development in these burgeoning environments are also the least safe (e.g. C and C++), the improper use of which introduces vulnerabilities that threaten reliability and security. Of particular importance is the need to perform in situ analysis, where we are able to leverage multiple devices exposed to real-world inputs in order to expose vulnerabilities quickly and efficiently. Unfortunately, burdensome overhead costs and portability limitations render such analysis impractical if not impossible; many tools currently available are unable to keep pace with the growing demands. The imperative is a simple one: adapt or die.In this paper, we present RTC (Run-Time error check for C programs), a dynamic analysis tool for C99 programs. RTC instruments source code with safety checks and produces another C source file. The resulting source file is portable and can be compiled on any platform and any compiler that can handle C99 and linked to a small runtime system. Choosing to instrument source code instead of binary code has a number of advantages. First, the tool is portable, because the systems where the code is instrumented and the system where the code runs can be different architectures. The only requirement is that there is a C99 compiler available for the target system. Second, by instrumenting source code, the tool processes the code as written by the programmer, and not some code that was generated and possibly optimized by a compiler. Finally, we can choose to validate only a single program module. For example, we may want to check only a single, commonly used library. In such cases, we may want to instrument only that library and not the whole application.Currently, RTC supports C99 and a subset of sequential C++. RTC implements three kinds of safety checks: arithmetic overflow/underflow, memory safety checks to find memory bugs on stack and heap, and run-time type-safety violations. The metadata is kept on the side using a locks and keys approach. Arithmetic overflow/underflow and memory safety checks cover three of the most dangerous software bugs [29]. We tested RTC on several runtime checking benchmarks and on complete programs including grep, crafty, and other C programs in the SPEC2000 benchmark suite.The paper presents the following contributions: (1) automated and portable source code instrumentation and monitoring for C99 programs; (2) lightweight runtime monitoring implementation.The paper is outlined as follows: Section 2 presents background information and related work. Section 3 describes our implementation in detail, and Section 4 discusses how we tested our tool and the obtained results. Section 5 summarizes the paper and discusses possible future research directions.

@&#CONCLUSIONS@&#
