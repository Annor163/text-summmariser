@&#MAIN-TITLE@&#
I-vector based speaker recognition using advanced channel compensation techniques

@&#HIGHLIGHTS@&#
WMMC and SN-WMMC approaches were introduced to i-vector system.WLDA and SN-WLDA approaches were also introduced to i-vector system.SN-WLDA shows significant improvement over baseline approach.SN-WLDA projected GPLDA also shows improvement over standard GPLDA system.

@&#KEYPHRASES@&#
Speaker verification,I-vector,GPLDA,LDA,SN-LDA,WLDA,SN-WLDA,

@&#ABSTRACT@&#
This paper investigates advanced channel compensation techniques for the purpose of improving i-vector speaker verification performance in the presence of high intersession variability using the NIST 2008 and 2010 SRE corpora. The performance of four channel compensation techniques: (a) weighted maximum margin criterion (WMMC), (b) source-normalized WMMC (SN-WMMC), (c) weighted linear discriminant analysis (WLDA) and (d) source-normalized WLDA (SN-WLDA) have been investigated. We show that, by extracting the discriminatory information between pairs of speakers as well as capturing the source variation information in the development i-vector space, the SN-WLDA based cosine similarity scoring (CSS) i-vector system is shown to provide over 20% improvement in EER for NIST 2008 interview and microphone verification and over 10% improvement in EER for NIST 2008 telephone verification, when compared to SN-LDA based CSS i-vector system. Further, score-level fusion techniques are analyzed to combine the best channel compensation approaches, to provide over 8% improvement in DCF over the best single approach, SN-WLDA, for NIST 2008 interview/telephone enrolment-verification condition. Finally, we demonstrate that the improvements found in the context of CSS also generalize to state-of-the-art GPLDA with up to 14% relative improvement in EER for NIST SRE 2010 interview and microphone verification and over 7% relative improvement in EER for NIST SRE 2010 telephone verification.

@&#INTRODUCTION@&#
Recent research in speaker verification has focused on the i-vector features based on front-end factor analysis. This technique was originally proposed by Dehak et al. (2010) to provide an intermediate speaker representation between the high-dimensional Gaussian mixture model (GMM) super-vector and traditional low-dimensional mel-frequency cepstral coefficients (MFCCs) feature representation. The extraction of these intermediate-sized vectors, or i-vectors, was motivated by the existing super-vector-based joint factor analysis (JFA) approach (Kenny, 2005; Kenny et al., 2008). While the JFA approach models the speaker and channel variability space separately, i-vectors are formed by modeling a single low-dimensional total-variability space that covers both the speaker and channel variability (Dehak et al., 2010). This approach was motivated by Dehak et al. finding that i-vectors do not lose any speaker discriminant information, unlike the JFA approach, where some speaker discriminant information is lost in the channel space (Dehak et al., 2010). As the channel variability is included within the total-variability space, Dehak et al. (2010) had investigated a number of standard channel compensation techniques, including linear discriminant analysis (LDA), within-class covariance normalization (WCCN) and nuisance attribute projection (NAP) to attenuate channel variability in the i-vector space.The i-vector framework was extended with a probabilistic linear discriminant analysis (PLDA) approach to model the speaker and channel parts within the i-vector space, and this has been shown to provide an improved speaker verification performance over cosine similarity scoring (CSS) with channel compensation (Kenny, 2010; Matejka et al., 2011; Senoussaoui et al., 2011). We believe that this is because the uncompensated i-vector behavior is heavy-tailed, and heavy-tailed PLDA (HTPLDA) can explicitly model outliers in the i-vector space (Kenny, 2010). Recently, Garcia-Romero et al. have introduced length-normalized Gaussian PLDA (GPLDA) approach in Garcia-Romero and Espy-Wilson (2011), which has shown similar performance as HTPLDA and it is an approach more computationally efficient than HTPLDA.Channel variability can be defined as mismatch between enrolment and verification utterances, arising from the differences in microphones, acoustic environment, transmission channels and the variation in individual speaker's voices. Channel compensation can occur at several levels, such as feature domain, model domain and score domain in an i-vector speaker verification system. Feature warping techniques are commonly used in the feature domain, which provides a robustness to additive noise and linear channel mismatch while retaining the speaker specific information (Pelecanos and Sridharan, 2001). In the model domain, an (WCCN[LDA]) approach, which represents the sequential operation of LDA followed by WCCN approach, was used by Dehak et al. (2010) to show good performance. More recently, this approach was extended by McLaren and van Leeuwen (2011) by proposing a new LDA-based approach, source-normalized LDA (SN-LDA), which improves i-vector-based speaker recognition in both mismatched conditions and conditions for which limited system development speech resources are available. In the score domain, t-normalization addresses the problem of session variability by compensating the mismatch between enrolment and verification conditions (Auckenthaler et al., 2000). The model domain channel compensation approaches are presently the most active area of research, as most of the channel variations are captured at the model domain.The LDA channel compensation technique (including SN-LDA) is based upon the ratio of between-class scatter to within-class scatter, which is used to transform the i-vector space to maximize the between-speaker discriminant information (between-class scatter) while minimizing the within-speaker variability (within-class scatter). The between-speaker scatter depends on speakers’ characteristics, while the within-speaker scatter depends largely on microphones, acoustic environments, transmission channels and differences in individual speaker's voices. In the standard LDA approach the influence of between- and within-class information on the transformed space is fixed, as it is calculated based on the ratio of between-class scatter to within-class scatter. Research in the similar field of face recognition has demonstrated, however, that this shortcoming could be overcome by making use of the weighted maximum margin criterion (WMMC) (Cheng et al., 2008; Baker et al., 2009; Hu et al., 2010), in which the objective function is calculated as the difference between the between-class scatter and the weighted within-class scatter. The first aim of this paper is to investigate the WMMC (including SN-WMMC) as an alternative channel compensation approach to LDA (including SN-LDA) for i-vector speaker verification.Most of the channel compensation techniques take direct advantage of the calculated between- and within-class scatter matrices, and can have problems when classes tend to clump according to characteristics external to class identity. Recently we have investigated the weighted LDA (WLDA) technique (Kanagasundaram et al., 2012), based upon the weighted pair-wise Fisher criteria, that has shown promise in the field of face recognition (Loog et al., 2001; Price and Gee, 2005; Liang et al., 2007), by taking advantage of the discriminatory information between pairs of classes. By applying a weighted parameter to class pairs that weights closer pairs higher, WLDA can provide an improvement in the discriminative ability between classes that would otherwise be difficult to distinguish in an LDA-transformed space. We have presented an introduction to the technique for i-vector speaker verification (Kanagasundaram et al., 2012), no detailed study of the application of this technique to i-vector based speaker verification has been performed in the past. In this paper we will be investigating a range of weighting functions for WLDA (and the related SN-WLDA) technique, which could help to increase the distance between the classes.Previous studies have shown that the best speaker verification performance for CSS classification of i-vectors can be obtained by first reducing the i-vectors dimensionality through LDA, then weighting the dimensions through WCCN (Dehak et al., 2010), and this approach has shown to still work well for more advanced channel compensation techniques, such as SN-LDA, replacing LDA in this process (McLaren and van Leeuwen, 2011, 2012). Accordingly, throughout this paper, we will take a similar approach and test a range of novel advanced channel compensation techniques for i-vector dimensionality reduction, which will then still be followed by a WCCN-based dimensionality weighting. In addition to this chaining approach to channel compensation, we also believe that better performance could be obtained through score fusion of differently channel compensated i-vector systems running in parallel. Accordingly we will also be investigating score fusion of our best channel compensation techniques in this paper to investigate the complementary nature of these techniques.Finally, we also hypothesize that if we train the most recent state-of-the-art system, length-normalized GPLDA, on channel compensated i-vector features, it could achieve further improvement as the channel variations can be compensated through the channel compensation approach as well as the length-normalized GPLDA modelling. The best channel compensation approach, which will be found from CSS i-vector system experiments, will be analyzed with length-normalized speaker verification system.This paper is structured as follows: Section 2 gives a brief introduction to the i-vector based speaker verification system. Section 3 initially details the existing channel compensation techniques and also introduces the novel channel compensation techniques in the latter part. The experimental protocol and corresponding results are given in Sections 4 and 5. Section 6 concludes the paper.The i-vector based system initially proposed by Dehak et al. (2010), which has recently become a popular approach for efficient text-independent speaker verification, is based on CSS. Initially speaker utterances are represented by their mixture-occupying based Baum–Welch statistics, calculated using a gender-dependent universal background model (UBM) parameter for each given speech utterance (Kenny et al., 2008). These statistics are used to train a total-variability subspace that can then be used for CSS classification, as outlined in the following sections.I-vectors represent the GMM super-vector by a single total-variability space, which was motivated by the discovery by Dehak et al. (2009) that the channel space of JFA contains speaker information that can be used to also distinguish speakers. A speaker- and channel-dependent GMM super-vector in the i-vector framework can be represented by,(1)μ=m+Tw,where m is the same UBM super-vector used in the JFA approach and T is a low rank matrix representing the primary directions across all development data. The total-variability factors, w, have a standard normal distributionN(0,1)and are referred to as i-vectors. An efficient procedure of total-variability subspace, T, training and subsequent i-vector extraction is described in Kenny et al. (2008) and Dehak et al. (2010).In this paper, we will be investigating a combined telephone and microphone speaker verification system, and for this approach the total-variability subspace should be trained in a manner that best exploits the useful speaker variability contained in speech acquired from both telephone and microphone sources. McLaren and van Leeuwen (2011) have investigated different types of total-variability representations, such as pooled and concatenation with i-vector systems. For the pooled approach, telephone and microphone utterances are pooled together and for the concatenated approach, individual total-variability subspaces are trained on each source-dependent subset of the training data, then a single subspace is formed through the concatenation of each individual subspaces. McLaren and van Leeuwen found that the pooled approach provided a much better representation for telephone and microphone i-vector speaker verification, and had the additional advantage of being a simpler approach than concatenation (McLaren and van Leeuwen, 2011). In this paper, the pooled total-variability approach will be used for i-vector feature extraction.I-vectors were originally considered as a feature for SVM classification, however, fast scoring approaches using a cosine kernel directly as a classifier were found to provide similar performance to SVMs with a considerable increase in efficiency (Dehak et al., 2009). The CSS classifier operates by comparing the angles between a test i-vector,wˆtest, and a target i-vectorwˆtarget:(2)S(wˆtarget,wˆtest)=〈wˆtarget,wˆtest〉∥wˆtarget∥∥wˆtest∥.The PLDA technique was originally proposed by Prince and Elder (2007) for face recognition, and later it was introduced to speaker verification to model the actual behavior of i-vector features by Kenny (2010), Senoussaoui et al. (2011), and Burget et al. (2011). In his work, Kenny investigated two PLDA approaches, GPLDA and HTPLDA (Kenny, 2010). He found that HTPLDA shows significant improvement over GPLDA as the distribution of the i-vectors is heavy-tailed. Recently, Garcia-Romero et al. have introduced length-normalized GPLDA approach in Garcia-Romero and Espy-Wilson (2011), and it has shown similar performance as HTPLDA, since the length-normalization approach was used to convert the distribution of the i-vectors from heavy-tailed to Gaussian. The length-normalized GPLDA approach is computationally efficient, so we have chosen to use in this paper. As we focus on advanced channel compensation approaches, the length-normalized GPLDA is modelled on channel compensated i-vector features,wˆr, which can be defined as(3)wˆr=w¯+U1x1+ɛrwhere for given speaker recordings r=1, …, R; U1 is the eigenvoice matrix, x1 is the speaker factor and ɛris the residuals. The between-speaker variability in the PLDA model is represented by the low rank U1U1Tmatrix. The within-speaker variability is described by Λ−1. We assume that precision matrix (Λ) is full rank.The details of length-normalization approach and the estimation of model parameters are given in Kenny (2010) and Garcia-Romero and Espy-Wilson (2011). GPLDA based i-vector system scoring calculated using batch likelihood ratio (Kenny, 2010). Batch likelihood calculation is computationally more expensive than CSS. Given two i-vectorswˆtargetandwˆtest, batch likelihood ratio can be calculated as follows,(4)lnP(wˆtarget,wˆtest|H1)P(wˆtarget|H0)P(wˆtest|H0)where H1: the speakers are same and H0: the speaker are different.In CSS based i-vector system, as i-vectors are defined by a single variability space, containing both speaker and channel information, there is a requirement that additional intersession, or channel compensation approaches be taken before verification. While approaches, such as LDA achieve dimension reduction, our aim is to compensate for the channel variability (McLaren and van Leeuwen, 2012). Channel compensation approaches are estimated based on within- and between-class scatter variances. The within-class scatter depends on microphones, acoustic environments, transmission channels and differences in individual speaker's voices. On the other hand the between-class scatter depends on speaker's characteristics. These channel compensation techniques are typically designed to maximize the effect of between-class variability and minimize the effects of within-class variability. Our main aim of this paper is to identify the best channel compensation approach for telephone and microphone based i-vector speaker verification systems.WCCN is used as a channel compensation technique to scale a subspace in order to attenuate dimensions of high within-class variance. For use in speaker verification, a within-class variance matrix, W, is calculated using(5)W=1S∑s=1S∑i=1ns(wis−w¯s)(wis−w¯s)T,wherewisis the i-vector representation of i session of speaker s, the mean i-vector for each speaker (w¯s) is equal to1ns∑i=1nswis, S is the total number of speakers and nsis the number of utterances of speaker s. The WCCN matrix, B1, can be calculated using Cholesky decomposition of B1B1T=W−1.The WCCN channel compensated i-vector (wˆWCCN) can be calculated as follows:(6)wˆWCCN=B1TwLDA is used as channel compensation technique, which attempts to find a reduced set of axes A that minimizes the within-class variability while maximizing the between-class variability through the eigenvalue decomposition of(7)Sbv=λSwv.where the between-class, Sb, and within-class scatter,Sw, can be calculated as follows:(8)Sb=∑s=1Sns(w¯s−w¯)(w¯s−w¯)T,(9)Sw=∑s=1S∑i=1ns(wis−w¯s)(wis−w¯s)T,where S is the total number of speakers, nsis number of utterances of speaker s. The mean i-vectors,w¯sfor each speaker, andw¯is the mean across all speakers are defined by(10)w¯s=1ns∑i=1nswis,(11)w¯=1N∑s=1S∑i=1nswis,where N is the total number of sessions.The LDA channel compensated i-vector (wˆLDA) can be then calculated as follows:(12)wˆLDA=ATwMcLaren and van Leeuwen (2011, 2012) found that the between-class scatter calculated using the standard LDA approach can be influenced by source variation under mismatched conditions, where sources were defined as speech recorded using either microphone or telephone. This influence can be reduced by estimating the between-class scatter using source-normalized i-vectors and fixing the within-class scatter as the residual variations in the i-vector space (McLaren and van Leeuwen, 2011). The source-normalized between-class scatter,Sbsrc, can be composed of the source-dependent between-class scatter matrices for telephone and microphone-recorded speech, which can be calculated as follows:(13)Sbsrc=Sbtel+Sbmicwhere(14)Sbtel=∑s=1Stelns(w¯s−w¯tel)(w¯s−w¯tel)T,(15)Sbmic=∑s=1Smicns(w¯s−w¯mic)(w¯s−w¯mic)T,where the mean i-vector for telephone source (w¯tel) is equal to1ntel∑i=1ntelwitel, and the mean i-vector for microphone source (w¯mic) is equal to1nmic∑i=1nmicwimic. Rather than estimating the within-class scatter separately as in Eq. (9), McLaren et al. calculated the within-class scatter matrix as the difference between a total variance matrix, St, and the source-normalized between-class scatter as:(16)Sw=St−Sbsrc,where(17)St=∑n=1N(wn−w¯)(wn−w¯)T.This approach allowsSwto be more accurately estimated when development dataset does not provide examples of each speech source from every speaker. Similarly to the LDA approach outlined previously, the SN-LDA channel compensated i-vector will be calculated using Eq. (12).In the LDA or SN-LDA approach, the transformation matrix is based on the ratio of between-class scatter to within-class scatter, and the level of importance of within- and between-class scatters cannot be changed. Research in the field of face recognition has found that weighted maximum margin criterion (WMMC) estimation can be used to change the level of importance of within- and between-class scatters by using weighting coefficients (Cheng et al., 2008; Baker et al., 2009; Hu et al., 2010). We will be applying similar techniques with i-vectors to see how performance varies with different level of within- and between-class scatters.The objective function of WMMC under projection matrix A is defined as,(18)J(A)=tr{AT(W×Sw−Sb)A},where an A that maximizes Eq. (18) can be calculated through the following eigenvalue equation:(19)(W×Sw−Sb)v=λv,where the within-class scatter (Sw) and between-class scatter (Sb) are estimated as described in Eqs. (9) and (8). W is a weighting coefficient defining the relative influence of theSwand Sb.In this paper we will be investigating manual weighting coefficients, where performance of WMMC is directly dependent on its weighted coefficient. The WMMC channel compensated i-vector will be calculated using Eq. (12).We have detailed the SN-LDA approach in Section 3.3, which was previously proposed by McLaren et al. to i-vector system. From the basics of SN-LDA approach, we introduce the SN-WMMC approach to i-vector system, which can be used to improve the performance in both mismatched enrolment/verification conditions. In this case, the between-class scatter matrix (Sb), and within-class scatter matrix (Sw) are estimated using Eqs. (13) and (9).Traditional LDA techniques attempt to project i-vectors into a more discriminative lower-dimensional subspace, calculated based on within- and between-class scatter matrix estimations. However, this approach cannot take advantage of the discriminative relationships between the class pairs, which are much closer due to channel similarities, and traditional estimation of between-class scatter matrix is not able to adequately compensate. Weighted LDA (WLDA) technique can be used to overcome this problem (Loog et al., 2001), by weighting the classes that are closer to each other to reduce class confusion. Even though WLDA techniques have been introduced to face recognition recently (Loog et al., 2001), the effective weighting function hasn’t been found, which could help to extract more discriminative information. In this paper, we introduce the WLDA approach to i-vector speaker verification and explore the application of several alternative weighting functions to extract more speaker discriminative information. In the WLDA approach, the between-class scatter matrix is redefined by adding a weighting function,w(dij), according to the between-class distance of each pair of classes i and j. In Loog et al. (2001), the equations, which are used to calculate the within- and between-class scatter estimations, are bit different from equations that are used in i-vector speaker verification (McLaren and van Leeuwen, 2011; Kanagasundaram et al., 2012). So, we have done modifications on weighted between-class scatter estimation. The weighted between-class scatter matrix,Sbw, is defined as(20)Sbw=1N∑i=1S−1∑j=i+1Sw(dij)ninj(w¯i−w¯j)(w¯i−w¯j)T,wherew¯x, and nxare the mean i-vector and session count respectively of speaker x.In Eq. (20), the weighting functionw(dij)is defined such that the classes that are closer to each other will be more heavily weighted. As we show in Appendix A, whenw(dij)is set to 1, the weighted between-class scatter estimations will converge to the standard non-weighted between-class scatter from Eq. (8).In this paper we are introducing the Euclidean distance, Mahalanobis distance and Bayes error weighting functions for speaker verification for the purpose of increasing the discriminant ability.The Euclidean distance weighting function,w(dij)Euc, can be defined as follows:(21)w(dij)Euc=((w¯i−w¯j)T(w¯i−w¯j))−n,wherew¯iandw¯jare the mean i-vectors of speaker i and j respectively, and n is a factor introduced to increase the separation for the classes that are closer. Classification performance will be analyzed with several arbitrary values of n. The Euclidean distance based weighting function is a monotonically decreasing function, so the classes that are closer together will be heavily weighted and classes that are away (outlier classes) will be lightly weighted to increase the discriminant ability.The Mahalanobis distance, Δij, between the means of classes i and j can be defined as,(22)Δij=(w¯i−w¯j)T(Sw)−1(w¯i−w¯j),where the within-class scatter matrix,Sw, is estimated from Eq. (9). If the session i-vectors (w) are uncorrelated in each speaker and are scaled to have unit variance, thenSwwould be the identity matrix and the Mahalanobis distance will converge as the Euclidean distance betweenw¯iandw¯j. We believe that there is some correlation between session i-vectors in each speaker and the within-class scatter is not an identity matrix. It can be shown that the presence of within-class scatter (Sw) of w in the quadratic form in Eq. (22) allows for the different scales on which the variables are measured and for non-zero correlations between the variables.The Mahalanobis distance weighting function,w(dij)Maha, can be defined as follows:(23)w(dij)Maha=(Δij)−2n.where the Mahalanobis distance, Δij, is estimated from Eq. (22). We introduce the Mahalanobis distance weighting function to i-vector speaker verification. It is also a monotonically decreasing function, so it will do the same job as Euclidean distance weighting function. In addition, it can be used to alleviate the dominant role of the outlier classes, so the Mahalanobis distance weighted between-class scatter has more discriminant ability than the Euclidean distance weighting function based weighted between-class scatter.The final weighting parameter is based upon the Bayes error approximations of the mean accuracy amongst class pairs. The Bayes error based weighting functionw(dij)Bayes, can be calculated as:(24)w(dij)Bayes=12(Δij)2ErfΔij22,where the Mahalanobis distance, Δij, is estimated from Eq. (22). The Bayes error based weighting function is also used to heavily weight the classes that are very closer.Once the weighted between-class scatter,Sbw, is estimated for the chosen weighting function, the standard within-class scatterSwand the corresponding WLDA matrix (A) can be estimated and applied as in traditional LDA. Finally, the WLDA channel compensated i-vector will be calculated using Eq. (12).We also introduce the SN-WLDA approach to i-vector system, as an extension of the more basic SN-LDA approach, and analyze several source-dependent and source-independent weighting functions for i-vector speaker verification, which should show an improvement in performance across both matched and mismatched enrolment/verification conditions. Similarly to the SN-LDA between-class scatter calculations, the source normalized weighted between-class scatter matrix,Sbwsrc, can be calculated as follows:(25)Sbwsrc=Sbwtel+Sbwmic,where the telephone-sourced dependent-weighted between-class scatter,Sbwtel, and the microphone-sourced dependent-weighted between-class scatter,Sbwmic, are individually calculated for telephone and microphone sources using Eq. (20).We will be investigating the source-independent Euclidean distance weighting function (Eq. (21)), as it does not depend on any source variations. However, we will be investigating the source-dependent Mahalanobis distance and Bayes error weighting functions instead of source-independent weighting function, calculated using source-dependent within-class scatter variance to capture the source variation. The telephone and microphone source-dependent Mahalanobis distance, Δijteland Δijmic, can be defined as follows:(26)Δijtel=(w¯i−w¯j)T(Swtel)−1(w¯i−w¯j),(27)Δijmic=(w¯i−w¯j)T(Swmic)−1(w¯i−w¯j),whereSwtelandSwmicare telephone and microphone source-dependent within-class scatter matrices, individually calculated from telephone and microphone sources using Eq. (9). Once the source-dependent Mahalanobis distances, Δijteland Δijmic, are estimated from Eqs. (27) and (27), the source-dependent Mahalanobis distance and Bayes error weighting functions will be individually estimated from telephone and microphone sources using Eqs. (23) and (24).In the SN-LDA algorithm, the within-class scatter matrix was estimated as the difference between total variance and the source-normalized between-class variance, but this approach is not taken for SN-WLDA, as the weighting parameters destroy the relationship between the total variance and the between-class scatter variance. For this reason, the within-class variance is estimated independently using Eq. (9) as in the LDA approach.In this section, we will graphically observe how the original i-vector space and channel-compensated i-vector spaces separate the speakers. An overview of all seven channel compensation techniques alongside the raw i-vectors is shown in Fig. 1. All seven channel compensation techniques have been trained on whole development dataset, and the details of development set for channel compensation training is given in Section 4. We then randomly chose four representative speakers to project the original i-vector space into channel compensated reduced space using the channel compensation matrix. In channel compensation matrix estimation, the eigen-vectors were sorted in descending order according to corresponding eigen-values in order to illustrate the larger variation in Fig. 1.It can be observed with the aid of Fig. 1(b) that WCCN projections scale a subspace in order to attenuate the high within-class variance. When we compare the WCCN and LDA projections with the aid of Fig. 1(b) and (c), it can be observed that LDA projection maximizes the between-speaker variability while minimizing the within speaker variability. After that when we observe the LDA and WLDA projections with the aid of Fig. 1(c) and (g), it can be clearly seen that WLDA projection increases the between speaker separability compared to LDA projections. Similarly to LDA and WLDA comparison, when we observe the SN-LDA and SN-WLDA projections with the aid of Fig. 1(d) and (h), it can be clearly seen that SN-WLDA projection increases the between speaker separability compared to SN-LDA projections.In previous sections, we have detailed several individual channel compensation techniques. Individual LDA techniques are generally used to increase the inter-speaker variability while minimizing the intra-speaker variability, and WCCN approach is used to reduce the channel effect by minimizing the intra-speaker variability. Dehak et al. have found that the sequential approach of LDA followed by WCCN extracts more speaker discriminant features than individual LDA and WCCN approaches (Dehak et al., 2010), but continued research has found that any type of LDA followed by WCCN is generally considered the best approach (McLaren and van Leeuwen, 2011; Kanagasundaram et al., 2012). In the first stage of the WCCN[LDA] approach, LDA attempts to find a reduced set of axes A that minimizes the within-class variability while maximizing the between-class variability. The estimation of LDA (A) was briefly described in Section 3.2.In the second stage, WCCN is used as a channel compensation technique to scale a subspace in order to attenuate dimensions of high within-class variance. The WCCN transformation matrix (B2) is trained using the LDA-projected i-vectors from the first stage. The WCCN matrix (B2) is calculated using Cholesky decomposition of B2B2T=W−1, where the within-class covariance matrix W is calculated using(28)W=1S∑s=1S∑i=1ns(AT(wis−w¯s))(AT(wis−w¯s))Twherewisis the i-vector representation of i session of speaker s, the mean i-vector for each speaker (w¯s) is equal to(1/ns)∑i=1nswis, S is the total number of speakers and nsis number of utterances of speaker s.The WCCN[LDA]-channel-compensated i-vector can be calculated as follows:(29)wˆLDA→WCCN=B2TATwThe WCCN[LDA] approach is commonly used to compensate the channel variability in i-vector based speaker verification systems (Dehak et al., 2010). Similarly to the WCCN[LDA] approach outlined previously, we will also be investigating other channel compensation techniques, including SN-LDA, WMMC, SN-WMMC, WLDA and SN-WLDA followed by WCCN.The i-vector based experiments were evaluated using the NIST 2008 and NIST 2010 Speaker Recognition Evaluation (SRE) corpora. Particulary, the NIST 2008 was used for parameter tuning task, and the NIST 2010 was used to validate the tuned parameters. For NIST 2008, the performance was evaluated using the equal error rate (EER) and the minimum decision cost function (DCF), calculated using Cmiss=10, CFA=1, and Ptarget=0.01. NIST 2008 evaluation was performed using the telephone–telephone, interview–interview, telephone–microphone and interview–telephone enrolment-verification conditions (NIST, 2008). The performance for the NIST 2010 SRE was evaluated using the EER and the old minimum decision cost function (DCFold), calculated using Cmiss=10, CFA=1, and Ptarget=0.01, where evaluation was performed using the telephone–telephone, interview–interview, interview–microphone and interview–telephone condition (NIST, 2010).We have used 13-dimensioned feature-warped MFCCs with appended delta coefficients and two gender-dependent universal background models (UBM) containing 512 Gaussian mixtures throughout our experiments. We kept the MFCC features dimension and number of UBM components in low values in order to reduce the computational cost, and it's easy to adapt to real world applications. UBMs were trained on telephone and microphone from NIST 2004, 2005, and 2006 SRE corpora for telephone and microphone i-vector experiments. These gender-dependent UBMs were used to calculate the Baum-Welch statistics before training a gender dependent total-variability subspace of dimensionRw=500, which was then used to calculate the i-vector speaker representations. Total variability representation, channel compensation matrices and length-normalized GPLDA model parameters were trained using telephone and microphone speech data from NIST 2004, 2005 and 2006 SRE corpora as well as Switchboard II. We empirically selected the number of eigenvoices (dimension of U1) equal to 120 as best value according to speaker verification performance. A full precision matrix was used for Λ, rather than the diagonal. ZT normalization was applied to telephone and microphone speech based CSS i-vector system experiments and S normalization was applied to length-normalized GPLDA system experiments. Randomly selected telephone and microphone utterances from NIST 2004, 2005 and 2006 were pooled to form the ZT and S normalization dataset. For the NIST 2008 evaluation, in most of the cases, the system achieved the best performance, when the channel compensation approach dimension was selected as 150. For NIST 2010 evaluation, we have also chosen the channel compensation approach dimension as 150, in order to show that the best value for NIST 2008 evaluation is robust to other dataset as well.Score-level fusion is implemented using the FoCal toolkit (Brummer, 2005) to optimize linear regression parameters. The fusion weights were learned using scores from the NIST 2008 short2–short3 conditions.

@&#CONCLUSIONS@&#
