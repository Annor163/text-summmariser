@&#MAIN-TITLE@&#
An improved particle swarm optimization algorithm for the capacitated location routing problem and for the location routing problem with stochastic demands

@&#HIGHLIGHTS@&#
An improved variant of the particle swarm optimization algorithm is presented.A new formulation of the location routing problem with stochastic demands is given.A new neighborhood topology for PSO suitable for combinatorial optimization problems is proposed.The proposed algorithm is tested in the CLRP and in the LRPSDs.Comparisons with other algorithms from the literature are performed.

@&#KEYPHRASES@&#
Capacitated location routing problem,Location routing problem with stochastic demands,Particle swarm optimization,Expanding neighborhood topology,Combinatorial neighborhood topology,Global and local neighborhood topology,

@&#ABSTRACT@&#
In this paper, a new version of the particle swarm optimization (PSO) algorithm suitable for discrete optimization problems is presented and applied for the solution of the capacitated location routing problem and for the solution of a new formulation of the location routing problem with stochastic demands. The proposed algorithm combines three different topologies which are incorporated in a constriction particle swarm optimization algorithm and, thus, a very effective new algorithm, the global and local combinatorial expanding neighborhood topology particle swarm optimization, was developed. The algorithm was tested, initially, in the three classic sets of benchmark instances for the capacitated location routing problem with discrete demands and, then, as there are no benchmark instances for the location routing problem with stochastic demands, these instances were transformed appropriately in order to be suitable for the problem with stochastic demands. The algorithm was tested in the problem with the stochastic demands using these transformed sets of benchmark instances. The algorithm was compared with a number of different implementations of the PSO and with metaheuristic, evolutionary and nature inspired algorithms from the literature for the location routing problem with discrete and stochastic demands.

@&#INTRODUCTION@&#
In this paper, a new neighborhood structure for the particle swarm optimization (PSO), the global and local combinatorial expanding neighborhood topology (GLCENT), suitable for routing problems is presented. The PSO algorithm has been observed in the past that it is not suitable for application in routing problems as either it does not give very good results or it needs a very strong local search algorithm in order to improve its results. The reason is that as a solution in a routing problem should be represented as a path (or a set of paths), because otherwise a computational inefficient algorithm could be produced as the solutions should be transformed from continuous values (suitable for PSO) to discrete values (suitable for routing problems) and vice versa. Over the last 10 years, researchers have proposed efficient ways to avoid the transformation from continuous to discrete values and vice versa. For example, variants of the particle swarm optimization algorithm for the capacitated vehicle routing problem [62,67,69], the vehicle routing problem with stochastic demands [58,68], the open vehicle routing problem [63], the vehicle routing problem with time windows [71], the probabilistic traveling salesman problem [61] and the location routing problem [60]. These algorithms were competitive with the most effective algorithms from the literature for the solution of routing problems.Two years ago we have proposed a topology, the combinatorial neighborhood topology [67], where the role of the velocities equation has been changed and the position vector was not used at all. Thus, with this topology the PSO algorithm was applied effectively in routing problems, most specifically in capacitated vehicle routing problem, and the results were competitive and in most of the instances equal to the best solutions from the literature. In a following publication we applied an expanding version of this topology in a different more difficult routing problem, the vehicle routing problem with stochastic demands [68], that resulted an algorithm that gave new best solutions in most of the instances used in the tests. The improvement in this algorithm in the part of the combinatorial neighborhood topology was that instead of a global topology in the velocities a local one was used, where, initially, the neighborhood was equal to two neighbors and it was expanding during the iterations until it became equal to a global topology and, then, it was restarted from the beginning (this topology was first applied by my research group in a solution of a flowshop scheduling problem [64] and in a solution of a feature selection problem [66]). In the present paper, the combinatorial neighborhood topology is applied in two more demanding problems, the one is the capacitated location routing problem and the other is the newly formulated location routing problem with stochastic demands. The reason that these two problems were selected was that the location routing problems in general combine two different problems the capacitated facility location problem and the vehicle routing problem where in the capacitated facility location Problem the solution can not be mapped as a path, as in the capacitated vehicle routing problem, but it must be mapped using a binary representation in which the ones mean that the facility is open and the zeros mean that the facility is closed. Thus, the challenge of this paper was to apply effectively the combinatorial neighborhood topology in a solution vector where its one part has values equal to zeros and ones and the other part has a path that represents the routes. The algorithm was tested in both problems as there are two different problems. The one problem has stochastic parameters, the demands of the customers and the other has only deterministic parameters. It is desirable to see how this algorithm can be applied in both problems. In the part of the combinatorial neighborhood topology a combined version of the previous two version, the global and the expanding one was proposed. This was achieved by the addition of a fourth parameter in the equation of velocities. Thus, in the new equation the particle, except from a movement towards a new direction, a movement towards his previous best and a movement towards the global best of the swarm, moves towards the local best of his neighborhood. The reason that this improvement was selected was that as both versions were proved to be very effective when applied separately in different problems, a combination of them would probably give an even more effective algorithm.Particle swarm optimization (PSO) is a population-based swarm intelligence algorithm that was originally proposed by Kennedy and Eberhart [44] and simulates the social behavior of social organisms by using the physical movements of the individuals in the swarm. There is a number of review papers [6,7,86] that have been published for the particle swarm optimization. Initially, most of the review papers focused in all improvements and variants of PSO, in velocities and positions equations, in the topologies (local or global) etc. In recent years with the increased in the applications of PSO such a review is very difficult to be written and to present the most important publications. Thus, nowadays the survey papers are mainly focused on the application of PSO in a problem or in a group of similar problems that can be reviewed together [4,46]. In this paper, as it was mentioned previously, the innovation is the way that a new very challenging topology, which combines a local and a global topology, is applied in two difficult routing problems, the location routing problem and the location routing problem with stochastic demands. In addition, in recent years a number of PSO implementations have been published for routing problems [1–3,17,33,35,47].In the past, a number of algorithms have been published using local neighborhood topologies but most of them are applied in global optimization problems or combinatorial optimization problems and not in routing problems as the ones studied in this paper. The first paper that designs and investigates neighborhood topologies (circle, wheel, star and random) was published by Kennedy [43]. In a following work Kennedy and Mendes [45] proposed a number of population topologies. Mendes et al. [76] proposed another local neighborhood topology, denoted as full informed particle swarm optimization algorithm (FIPS). The first one that published an expanding neighborhood topology for the solution of global optimization problems was Suganthan [97]. Another two earlier adaptations of local neighborhood topologies are presented in [38,83]. In recent years, the adaptations of local neighborhood topologies in PSO have been increased. More precisely, in [104] a hybrid PSO algorithm is presented, which is denoted as DNSPSO where a diversity enhancing mechanism and neighborhood search strategies are used in order to achieve a trade-off between exploration and exploitation abilities. An improved version of this strategy is presented in [100], where an enhanced particle swarm optimization with diversity and neighborhood search (EPSODNS) approach was presented. In [51] a comprehensive learning particle swarm optimizer (CLPSO) was presented. An improvement of this method was proposed in [81], denoted as dynamic neighborhood learning particle swarm optimizer (DNLPSO), which uses a learning strategy whereby all other particles’ historical best information is used to update a particle's velocity. In [105] a multi-layer PSO method (MLPSO) consisting of global MLPSO and local MLPSO by increasing the swarm layers from two to multiple layers was proposed. Another PSO algorithm using a local search topology was presented in [50] where a ring topology is used. In [52], a particle swarm optimization with increasing topology connectivity (PSO-ITC) was proposed to solve unconstrained single-objective optimization problems with continuous search space while in [53] a PSO denoted as PSO with adaptive time-varying topology connectivity (PSO-ATVTC) was proposed where the ATVTC module is used in order to balance the algorithm's exploration/exploitation searches by varying the particle's topology connectivity with time according to its searching performance. A time adaptive topology is proposed for constrained optimization problems in [11]. In [42] an age-group topology particle swarm optimization algorithm (PSOAG) is presented where the concept of age is used to measure the search ability of each particle in local area. The particles are divided in different age-groups by their age and particles in each age-group can only select the ones in younger groups or their own groups as their neighborhoods [42]. A cyclic neighborhood topology is presented in [74]. An analysis of local best topologies is presented in [30].In [102,103] two mutation neighborhood based PSO implementations have been proposed for the solution of fuzzy stochastic programming problems. Especially in [103], a fuzzy random facility location model (VaR-FRFLM) was formulated where the costs and demands are assumed to be fuzzy random variables and the capacity of each facility was not fixed but a decision variable assuming continuous values was used [103]. For the solution of the problem, the authors presented two PSO implementations a continuous Nbest-Gbest-based PSO and a genotype–phenotype-based binary PSO. The first one was used in order to deal with the continuous capacity decision variables and the second one was used in order to deal with the binary location decision variables. Afterwards, a mutation operator is incorporated in order to improve even more the quality of the produced solutions. These are the two most relevant publications in the literature compared the one proposed in this paper. However, a number of differences between them exist. First of all, the authors in [103] solved a facility location problem while in this paper a location routing problem is solved. Thus, while the authors in [103] have to deal with binary variables that concern the assignment of customers in depots, we, in addition, have to solve a routing problem, meaning to find the order that the selected number of vehicles, assigned in each depot, will visit the customers assigned to the depots. Thus, in this paper, in addition with the binary variables a part of the solution will be the paths that the vehicles will follow. In the paper [103] the stochastic variables are treated using a fuzzy approach while in this research the stochastic variables are treated finding the a priori routes of the customers. Also, both researches use a local neighborhood topology for the PSO algorithm. However, in the proposed algorithm in this paper, there is no need to transform any solution to continuous values as the innovation of the method is that a topology, denoted as combinatorial neighborhood topology, is used in order not to transform the solutions from continuous to discrete values and vice versa. This is very important in a routing problem as when a solution (a path) is transformed into continuous values (in order to be suitable for the velocities’ and positions’ equations of PSO), then, good parts of solutions (i.e. a sequence of customers) may be destroyed and, thus, when the solution is transformed back to a path, a completely new path will be created without having any memory of the good sequences of the nodes.In order to give the effectiveness of each one of the features of the proposed algorithm, different versions of the algorithm that use separately each one of the features are implemented and tested and, then, their results are compared with the results of the proposed algorithm. The algorithm is compared with a number of other implementations of PSO algorithm for the solution of the capacitated location routing problem published in [60,65]. Also, it is compared with other algorithms from the literature. The rest of the paper is organized as follows: In the next section, the description of the capacitated location routing problem, the new formulation of the location routing problem with stochastic demands and the presentation of the most important algorithms for the solution of the capacitated location routing problem are given. In Section 3, the proposed algorithm is analyzed and described in detailed. The results of the algorithm when used for the solution of these two problems are presented in Section 4 and, finally, in the last section conclusions and future directions are presented.The location routing problem (LRP) describes the case where several sites are available to be used for storage facilities from where products will be delivered to geographically scattered customers by distribution vehicles. The optimal locations to use for the storage facilities have to be decided. At the same time, the optimal routes for the vehicles have to be found in order to satisfy the demand of the customers. The previous two decisions will be made in a way that the total cost of the routing (distance, fuel, time, etc.) and facility location (running costs, rent or property cost, etc.) will be the minimum [23,78,85]. Extended recent literature reviews can be found in [79,91].The capacitated location routing problem (CLRP) can be stated as follows [23]: Let G=(N, E) be an undirected graph, where N={1, …, n} is the set of nodes and E is the set of edges. Each node can be used either as facility node or customer node or both. Let C=(dfi) be a matrix of costs, distances or travel times associated with the number of edges. If dfi=diffor all f, i∈N, the matrix and the problem is said to be symmetrical, otherwise it is asymmetrical. C satisfies the triangle inequality if and only if dfh+dhi≥dfifor all f, i, h∈N. There can be, at most, k identical vehicles of capacity Qkbased at facility i. It is assumed here that dfiare nonnegative and that all vehicles have the same capacity Q. Every customer has a nonnegative demand qfthat must be served by one single vehicle. Each facility has an opening cost Bi. The number of vehicles used is unknown and is a decision variable. Each route must begin and end at the same depot and its total load must not exceed vehicle capacity and the total load of the routes assigned to a depot must fit the capacity of that depot. The total cost of a route includes the costs of traversed edges. The objective is to find which depots should be opened and which routes should be constructed in order to minimize the total cost (fixed costs of depots plus total cost of the routes).The location routing problem with stochastic demands (LRPSDs) as it is treated in this paper concerns a two phase problem, where in the first phase a capacitated facility location problem (CFLP) is solved and in the second phase for each assignment of the customers in the depots, a vehicle routing problem with stochastic demands is solved. Thus, the objective function of the problem is comprised from two parts. The one part corresponds to the CFLP problem and it calculates the fixed facility location cost while the second part is the calculation of the expected distance (length) of the a priori tour that a vehicle (which is assigned in a specific depot) will travel. The way that we formulate the second part of the problem (VRPSDs) leads to the fact that only one vehicle is needed for each depot for the distribution of the products. The reason that only one vehicle is needed is that we do not know where a route failure will occur, i.e. in which customer the vehicle will not have the necessary quantities to serve him. There is a number of ways to treat this problem. In this paper, a preventive restocking strategy is used [68,58] where a threshold value is calculated and when the residual quantities of a vehicle is less than this value the vehicle returns to the depot for replenishment. The total objective function is the following:(1)min∑i∈UBiyi+∑i∈Ufij(q)whereyi=1,if the facility is located at candidate sitei0,otherwise,zjk=1,if vehiclekoperates out of a facility at candidatesitej0,otherwise,and U is the set of candidate facility sites and j is the customer that belongs to the i open facility. Thus, in order to calculate the objective function, initially, the cost of the open facilities is calculated and, then, for each open facility (depot) a vehicle routing problem with stochastic demands is solved over the customers assigned to it. In the objective function, there is a summation before the routing cost fij(q) as there is not only one a priori tour but the number of the a priori tours is equal to the number of the open depots. The constraints corresponding to the first part are the classic constraints of the CFLP:(2)∑k∈KQkzik≤QBiyi,∀i∈U(3)zik≤yi,∀i∈U,∀k∈K(4)∑i∈Uzik≤1,∀k∈KThe second part of the objective function is analyzed as follows (for each depot) [10,68,58]:(5)fij(q)=Minimum{fijp(q),fijr(q)}where(6)fijp(q)=dj,j+1+∑k≤qfi,j+1(q−k)pj+1,k+∑k>q[2dj+1,0+fi,j+1(q+Q−k)]pj+1,k(7)fijr(q)=dj,0+d0,j+1+∑k=1Kfi,j+1(Q−k)pj+1,kwith boundary condition(8)fin(q)=dn,0,q∈Lnwhere•The customers’ demands (ξj, j=1, …, n) are stochastic variables independently distributed with known distributions.The real demand of each customer is known only when the vehicle arrives to the customer.The demand ξj, j=1, …, n does not exceed the vehicle's capacity Q, and follows a discrete probability distribution pjk=Prob(ξj=k), k=0, 1, 2, …, K≤Q.Biis the fixed cost of locating a facility at candidate site i.QBiis the capacity of each facility i.q is the remaining load of the vehicle after the completion of the service in customer j.fij(q) is the expected cost from the customer j onward (thus, if j=0 then fi0(q) denotes the expected cost of the a priori tour).fijp(q)is the expected cost of the route when the vehicle does not return to the depot but goes to the next customer.fijr(q)is the expected cost when the vehicle returns to the depot for preventive restocking.The capacitated location routing problem (CLRP) is very difficult to be solved with the use of exact algorithms, especially, if the number of customers or the candidate for location facilities are very large due to the fact that this problem belongs to the category ofNP-hard problems, i.e. no polynomial time algorithms are known for their solution. Madsen [57] presented a survey of heuristic methods. Christofides and Eilon [20] were the first to consider the problem of locating a depot from which customers are served by tours rather than individual trips. Other heuristics have been proposed in [5,8,12,15,16,19,24,31,37,40,41,48,49,56,77,80,84,94,96,95,106].Several metaheuristic algorithms have been proposed for the solution of the capacitated location routing problem. Tuzun and Burke [101] proposed a two-phase tabu search architecture for the solution of the CLRP. Tabu Search algorithms for the LRP are, also, presented in [14,18,55,75,90,93]. Wu et al. [107] proposed an algorithm which divides the original problem into two sub-problems, i.e., the location-allocation problem and the general vehicle routing problem, respectively. Each subproblem is, then, solved in a sequential and iterative manner by the simulated annealing algorithm embedded in the general framework for the problem solving procedure. Simulated annealing algorithms for the CLRP are presented in [13,54,55,108]. Prins et al. [88] proposed a greedy randomized adaptive search procedure – GRASP with a path relinking phase for the solution of the capacitated location routing problem. Marinakis and Marinaki [59] proposed a bilevel genetic algorithm for a real life capacitated location routing problem where a new formulation based on bilevel programming was proposed. Other evolutionary approaches for the solution of the CLRP have been proposed in [39,89]. A combination of GRASP with an evolutionary local search algorithm is presented in [26]. Another GRASP approach is presented in [22]. A memetic algorithm for the capacitated location routing problem is presented in [25] while variable neighborhood search algorithms for the LRP are presented in [75]. A branch and cut algorithm for the capacitated location routing problem is presented in [9]. There are not many nature inspired algorithms proposed for the solution of the problem. Ant colony optimization algorithms for the LRP are presented in [13,98]. A hybrid particle swarm optimization algorithm has been presented in [60] while a honey bees mating optimization algorithm has been presented in [70].The proposed algorithm for the solution of the two location routing problems, the global and local combinatorial expanding neighborhood topology particle swarm optimization (GLCENTPSO), is a two phase algorithm that combines three different neighborhood topologies in a new neighborhood structure. The neighborhood topologies that were selected are the combinatorial neighborhood topology (CNT) [67], the expanding neighborhood topology (ENT) [64,66] and the global and local neighborhood topology. In a PSO algorithm, initially, a set of particles is created randomly where each particle corresponds to a solution. Each particle has a position in the space of solutions and moves with a given velocity. One of the key issues in designing a successful PSO for the CLRP or the LRPSDs is to find a suitable mapping between location and routing solutions and particles in PSO. As it will be described in Section 3.4 with the combinatorial neighborhood topology there is no need to transform the solutions of the PSO algorithm to discrete space and vice versa. The representation of each solution is described in Section 3.3.In the proposed two phase algorithm, in the first (location) phase a capacitated facility location problem [28,29] is solved in order to find the locations of the facilities and the assignments of the customers in the facilities and, then, in the second (routing) phase, for each facility, a vehicle routing problem for the CLRP [34,99] (or a vehicle routing problem with stochastic demands [58] for the LRPSDs) is solved in order to find the routes. Concerning the fitness function, it should be noted that in the CLRP, the fitness of each particle is related to the route length (or the a priori route in the LRPSDs) of each circle and to the set up cost of each facility, and since the problem that we deal with is a minimization problem, if a feasible solution has a high objective function value, then, it is characterized as an unpromising solution candidate.Usually in a PSO implementation, the calculation of the new position is given by Eq. (10) (see below) and, thus, the movement of a particle between two positions depends directly from the calculation of the velocities. Thus, the positions of the particles should be transformed appropriately from continuous to discrete values and vice versa. However, in this paper the calculation of the positions using a novel path relinking procedure leads the algorithm to keep in each iteration the path representation of each solution without needing to transform the solutions in the continuous space. Also, the role of the velocities equation is changed (see Section 3.4) and a different velocities equation is proposed which combines a local and a global neighborhood (see Section 3.2) and an expanding neighborhood procedure (see Section 3.5). A local search strategy based on the variable neighborhood search (VNS) algorithm [36] is applied in each particle in the swarm in order to improve the solutions produced from the particle swarm optimization algorithm (see Section 3.6). In each iteration of the algorithm, the optimal solution of the whole swarm and the optimal solution of each particle are kept. The algorithm stops when a maximum number of iterations has been reached. A pseudocode of the algorithm is presented in Table 1.A number of variants of the particle swarm optimization algorithm have been proposed in the last years. In this paper, a global and local neighborhood topology is presented. In the proposed algorithm, the global and local combinatorial expanding neighborhood topology PSO (GLCENTPSO), a different equation for the velocities is given where a fourth term that represents the local neighbors has been added in the equation proposed by Clerc and Kennedy [21] (constriction PSO). Thus, in the new equation the particle, except from a movement towards a new direction, a movement towards his previous best and a movement towards the global best of the swarm, moves towards the local best of its neighborhood. The fourth term in the equation of velocities is added and represents the interaction of each particle with its local best neighbor. With the addition of the fourth term in the equation of velocities we are trying to avoid a fast convergence to a possibly not good initial global best solution and to give to each particle the possibility to follow a local best particle on the purpose of finding a better global optimum. Thus, the proposed equation of velocities becomes:(9)vij(t+1)=χ1(vij(t)+c1rand1(pbestij−xij(t))+c2rand2(gbestj−xij(t))+c3rand3(lbestij−xij(t)))and(10)xij(t+1)=xij(t)+vij(t+1)where t is the iterations’ counter, c1, c2 and c3 are the acceleration coefficients, rand1, rand2 and rand3 are three random variables in the interval (0, 1) and χ1 is the constriction factor.(11)χ1=2|2−c−c2−4c|andc=c1+c2+c3,c>4A particle's best position (pbestij) in a swarm is calculated from the equation:(12)pbesti=xi(t+1),iff(xi(t+1))<f(xi(t))pbesti,otherwiseThe optimal position of the whole swarm at time t is calculated from the equation:(13)gbest∈{pbest1,pbest2,…,pbestNP}|f(gbest)=min{f(pbest1),f(pbest2),…,f(pbestNP)}and the lbestijin Eq. (9) is calculated as follows:(14)lbesti∈{NPi|f(lbesti)=min{f(xi)},∀x∈NPi}and the neighbor NPiis defined by [27]:(15)NPi={pbesti−nNPi,pbesti−nNPi+1,…,pbesti−1,pbesti,pbesti+1,…,pbesti+nNPi}.The capacitated location routing problem or the location routing problem with stochastic demands combine two different problems, the capacitated facility location problem (CFLP) and the capacitated vehicle routing problem (CVRP) (or the vehicle routing problem with stochastic demands (VRPSDs), respectively). The CFLP part of the problem should be encoded in binary form which means that it needs to be represented in a sequence of zeros and ones. This encoding is being used for the depot vector with a size of m elements. Thus, when a depot is open, it is represented with 1 in the corresponding element and when it is closed it is represented with 0. For example, in the case of four possible locations for the depots, if the depots in locations 2 and 4 are open and in the other locations the depots are closed and if the solution is encoded in the way described above, the solution representation is the following: [0101].For the CVRP (or the VRPSDs) part of the problem, the binary encoding can not be used. To represent the routes a routing vector was used with a size of n elements that contains the customers in the sequence they are visited by the vehicles. A pointer vector with size m (it has the same size with the depot vector) was used where the pointer vector in each element corresponding to an open depot has the position i of the routing vector that gives the first customer assigned to that depot. To further clarify this, it is assumed that there are five customers along with the two open depots (2 and 4) of the previous example. If the following routing is produced:•Depot 2→customer 5→customer 2→customer 3→depot 2.Depot 4→customer 4→customer 1→depot 4.routing vector:52341;pointer vector:0104.In the pointer vector zeros mean that the corresponding depot is closed. On the previous example, number 1 in the pointer vector that corresponds to depot 2 means that the first node that is assigned to depot 2 is the first node of the routing vector (node/customer 5) while the number 4 means that the first node that is assigned to depot 4 is the node that is in the fourth position in the routing vector (node/customer 4). In order to simplify some of the processes, a helping assignment vector with a size of n elements is used and in every element referring to a customer the number of the depot that is serving him is inserted. This vector is used for the initial creation of the routing vector and for the validity check of a solution. For example, according to the solution described above, the assignment vector is: [42242], where number 4 means that the customer 1 or customer 4 are assigned to open depot 4 and number 2 means that the customers 2, 3 and 5 are assigned to open depot 2.In this paper, the calculation of the position of each particle is performed using the combinatorial neighborhood topology (CNT) [67]. This calculation will not lead to any losing of information and will speed up the whole procedure. An initial version of this idea was presented in [60,62,69] and, then, was improved in [92]. The final version of the combinatorial neighborhood topology was proposed in [67]. The equation of positions is replaced by a path relinking procedure [32]. The positions equation of the PSO is replaced by the path relinking algorithm as there is a correspondence between the idea behind the path relinking and the idea of the movement of a particle in the particle swarm optimization algorithm [67]. This correspondence is due to the fact that a particle can either follow its own path or go towards to its previous optimal solution or go towards to the global optimal solution (to the best particle in the swarm). The path relinking strategy is applied when the particle decides to follow either the path to its previous optimal solution or the path to the global optimal solution.The most important part of the combinatorial neighborhood topology is how the particle decides to follow its previous best or the global best of the whole swarm. Two versions of the path relinking strategy are used. In the first version of the path relinking strategy, initially, the average value of the velocities equation of each particle is calculated by:(16)averagev=∑j=1dvij(t+1)d.If this value is less than a number L1, then, no path relinking is performed (NOPR), meaning that the particle follows its own path (using a local search procedure as it will be described later), if it is between the numbers L1 and L2 the particle performs a path relinking with its previous best solution (PRPB), and if the value is greater than L2 the particle performs a path relinking with the global best solution (PRGB). In the beginning of the algorithm, L1 and L2 have large values and the values are decreasing during the iterations in order to succeed the increase of the possibility of realizing a path relinking with the global best or the personal best of the particle and the decrease of the possibility the particle to search by its own the solution space using a local search procedure. Thus, the values of L1 and L2 are(17)L1=(ubound−lbound)×w1−w1itermax×t+lboundand(18)L2=(ubound−lbound)×w2−w22*itermax×t+lboundwhere itermaxis the maximum number of iterations, uboundand lboundare the upper and lower bounds for the velocities of each particle. Usually in the literature the values for the upper and lower bounds are +4, −4, respectively. If in some iterations in an element of the particle the value of the velocity violates these bounds, then, this element is initialized with a new value inside the bounds. The parametersw1andw2should have large values as it is desired the value of L1 to be as large as possible in the beginning of the algorithm and to be reduced during the iterations. Also, the value of L2 should be larger than the value of L1 and, thus, the value ofw2should be larger than the value ofw1. Thus, it is selectedw1=0.8and as it is decided to give to the two other strategies (PRPB and PRGB) almost equal selection probability the value ofw2is selected equal to 0.9.In the second version of path relinking, the same procedure is followed but instead of using the average value of the velocities, it is examined for each element of the velocities’ equation of the particle which part of the condition with the L1 and L2 values holds. Thus, in the end of this procedure each particle is divided in three parts. For the elements of the solution that belong to the first part, no path relinking is applied and in these elements a local search is applied, for the elements of the solution that belong to the second part, a path relinking procedure is applied with the previous personal best solution and for the last part, a Path Relinking is applied using the global best solution. The version of Path Relinking procedure is selected randomly for each iteration. As it is possible with the use of the Path Relinking procedure the solutions to converge near to a single solution in a short number of iterations, a solution is not selected if it differs from the optimal solution less than 30% except if this solution improves the optimal solution.In Figs. 1and 2an example of the combinatorial neighborhood topology is presented. An instance with 10 nodes is presented. Before the beginning of the combinatorial neighborhood topology procedure there are three solutions, the current solution (first route in Fig. 1), the personal best solution (third route in Fig. 1) and the global best solution (second route in Fig. 1) for a particle. From the velocities equations it was selected to perform no path relinking for the first 2 nodes (black nodes in the fourth graph in Fig. 1), a PR procedure with starting solution the current solution and target solution the global best solution for the nodes 3–5 and 8–10 (white nodes in the fourth graph in Fig. 1), and, finally, a PR procedure with starting solution the current solution and target solution the personal best solution for the nodes 6–7 (gray nodes in the fourth graph in Fig. 1). As PR is performed with two different solutions, it is possible the same node to exist in two different places in the solution vector and, thus, to create an infeasible solution. In order to avoid this, if the node has been used again, then, the PR procedure is skipped for this node, and in the solution the node of the current solution remains. However, this node can be transferred in another place of the solution vector if it is necessary in the following iterations of the PR procedure as we will see in the example. In Fig. 2, the iterations of the combinatorial neighborhood topology for this example is presented. The black nodes are the nodes that have not yet taken their final position in the solution (thus, their positions will be changed in the following iterations), the gray nodes are the nodes that their final positions in the routes have been found and the white nodes are the nodes that their positions are changed in the current iterations. In the first two iterations (first graph in Fig. 2), the solution remains unchanged as no path relinking procedure is applied and, thus, the two iterations are presented together. In the following iterations, the swaps of the nodes are presented with the white nodes.In this paper, an expanding neighborhood topology (ENT) is used which is a combination of a local and global neighborhood topology [66]. In [64], a particle swarm optimization with expanding neighborhood topology (PSOENT) algorithm was presented and used for the solution of the permutation flowshop scheduling problem (PFSP). In this algorithm, the advantages of a local search neighborhood topology and of a global search neighborhood topology were used. The algorithm started with a local search neighborhood topology where the neighbors for each particle were equal to 2 and in each iteration the neighborhood was increased (expanded) until it became equal to the number of particles. Then, if the maximum number of iterations had not yet been reached, the neighborhood was initialized again and the same procedure was followed until the maximum number of iterations had been reached. Thus, there were no consecutive iterations in which the size of the neighborhood was the same. The exploitation abilities of the algorithm were increased as the particle was moving for a number of iterations in small swarms inside the whole swarm. Also, the exploration abilities of the algorithm were increased as for a number of iterations all the particles were moving as a single swarm. By using an expanding neighborhood topology, each particle participated in each iteration in more than one swarms and, thus, the interchange of the information between the swarms was becoming easier.In [66], the neighborhood topology presented in [64] was modified. In [64], the neighborhood was expanding with the number of iterations while in the algorithm proposed in [66] the neighborhood was expanding based on the quality of the solutions. Each particle had its own neighborhood but, initially, all particles had the same neighborhood topology. When a solution of a particle was not improved for a consecutive number of iterations (itnum), then, only its neighborhood was expanding. With this strategy there is a possibility of having different neighborhood topologies for each particle. This idea of changing the neighborhood topology of the swarm not with the number of iterations but when a particle of the swarm can not improve the global or personal best solution is inspired by the basic idea of changing a neighborhood when the algorithm is trapped in a local optimum in the variable neighborhood search (VNS) algorithm [36]. Thus, as in VNS algorithm the neighborhood is expanding in order to find a better local optimum, in the algorithm proposed in [66] the search for a better direction that the particle will move in its neighborhood was expanding in order to search in a larger neighborhood when the particle was trapped in a local optimum. This incorporation of one of the basic characteristics of variable neighborhood search algorithm in the particle swarm optimization gave a more powerful version of PSO algorithm. Another characteristic of VNS algorithm that was incorporated in the PSO is the reinitialization of the search of the local best neighborhood. In the algorithm proposed in [66], when the number of neighbors became equal to the number of particles, then, the search for the local best neighborhood was reinitialized from a very small neighborhood. In each iteration of the algorithm, the search was realized from a different point (shaking procedure of the VNS) as the current position of each particle was different in each iteration.In Figs. 3–5the expansion of the neighborhood for three different particles (particles 1, 8 and 4) of a solution with 8 particles is presented. The route is not presented and from the figures we can see how the neighborhood is expanded. We can see that, as for each particle the expansion of the neighborhood is realized when the best solution of the particle is not improved for a number of iterations, the three particles have different neighborhoods in each iteration. More precisely, in Fig. 3, initially, the neighborhood of particle 1 is only the nearest particle, then, the neighborhood is expanded and for the next two iterations the neighborhood of particle 1 contains 2 particles. In the following, the neighborhood continues to expand until in the 10th iteration the neighborhood of particle 1 contains all the particles. On the other hand, in Fig. 4 the neighborhood of particle 8 begins, as in the previous figure, with one particle (the nearest particle of particle 8) and, then, it is expanded only one time in iteration 3 and, then, it remains constant until it reaches the 10th iteration. This happens as the only way to expand a neighborhood is not to find a better solution for specific particle. Finally, in Fig. 5 the neighborhood of particle 4 begins with one other particle and, as the solution can not be improved for a number of iterations, in iteration 7 the neighborhood includes all the particles. As there is not an improvement in the solution of the particle, the neighborhood in the 8th iteration is restarted and includes one particle. Thus, in total we can observe that for three different particles three different neighborhoods are produced during the iterations.A local search strategy based on the variable neighborhood search (VNS) algorithm [36] is applied in each particle in the swarm in order to improve the solutions produced from the PSO algorithm. In this paper, the VNS algorithm is used with the following way. Initially, the number of local search algorithms is selected. The local search strategies for the location routing problem are distinguished between local search strategies for the capacitated facility location problem (CFLP) and local search strategies for the vehicle routing problem (VRP). As we do not want to increase the complexity of the algorithm, it is decided to apply in each particle one local search combination of algorithms per iteration. For this reason, a VNS operator CVNSis selected that controls which local search algorithm is applied by comparing its value with the output of a random number generator, randi(0, 1). If the random number is less or equal to the CVNS, then, the first local search algorithm is used, if the random number is less or equal to the 2*CVNS, then, the first two local search algorithms are used, and so on (CVNSoperator is set equal to 0.1). In the following a pseudocode of the procedure is presented (Table 2).The algorithm was implemented in Fortran 90 and was compiled using the Lahey f95 compiler. In the following sections, the results of the proposed algorithm when applied to the capacitated location routing problem and the location routing problem with stochastic demands for various sets of benchmark instances are given.The algorithm was tested on three sets of benchmark instances, the 16 benchmark instances proposed by Barreto [8], the 30 benchmark instances proposed by Prins et al. [87] and the 36 benchmark instances proposed by Tuzun and Burke [101]. In Table 3, the main data (except of the coordinates) of each one of the benchmark instances used in the comparisons are presented. More precisely, in the first column and with the notation B1 to B16 the instances of the first set are presented, in the fifth column and with the notation P1 to P30 the instances of the second set are presented and in the ninth column and with the notation T1 to T36 the instances of the third set are presented. Finally, in columns 2–4, 6–8 and 10–12 the number of customers (n), the number of candidate sites (m) and the vehicle capacity (Q) for the first, second and third sets are presented, respectively.The selected parameters are presented in Table 4. The parameters of the proposed algorithm are selected after thorough testing using as selection criteria for the parameters the quality of the solution and the computational time needed to achieve this solution. A number of different alternative values were tested and the ones selected are those that gave the best computational results concerning both selection criteria. In order to test the efficiency of each of the new features of the proposed algorithm, three more algorithms were created (as it will be described later), each one using only one of the features of the proposed method and comparisons of the three methods with the proposed method were performed. In Table 4, except of the parameters of the proposed algorithm, all parameters for the other algorithms used in the comparisons are presented. After the selection of the final parameters, 10 different runs with the selected parameters were performed for each instance. The same parameters, the same methods (variants of PSO) for comparisons and the same number of runs were used for the location routing problem with Stochastic Demands.The efficiency of the GLCENTPSO algorithm is measured by the quality of the produced solutions. The quality is given in terms of the relative deviation from the best known solution, that isω=(cGLCENTPSO−cBKS)cBKS%, where cGLCENTPSOdenotes the cost of the solution found by GLCENTPSO and cBKSis the cost of the best known solution. In Tables 5–7, the results of the proposed algorithm in the capacitated location routing problem for the three data sets of benchmark instances are presented. Besides the results of the proposed algorithm, they are, also, presented the results of three other versions of PSO with only one of the new features. More precisely, in the CNTPSO algorithm, the PSO algorithm is used only with the combinatorial neighborhood topology, while in the ENTPSO, the PSO algorithm is used only with the expanding neighborhood topology and, finally, in the GLPSO algorithm, the PSO algorithm is used only with the local and global neighborhood topology and with static number of neighbors. The reason that we present, also, these results is that it would be interesting, in addition to the results of the proposed method, to present results of algorithms in which only one of the new features of the proposed method is used at a time and by this way to see how each one of these features affects the proposed algorithm. Thus, in Tables 5–7, in the first column the instances are presented while in the second column the best known solutions (BKS) for each instance are given. In columns 3–8, the best cost of the ten runs and the quality (ω) of the solutions of the CNTPSO (columns 3 and 4), the ENTPSO (columns 5 and 6) and the GLPSO (columns 7 and 8) are presented, respectively. In columns 9–13, the results of the proposed algorithm (the best cost of the ten runs, the quality (ω), the average results (av), the standard deviation (stdev) and the variance (var)) are presented.In Table 5, the results in the Barreto instances are presented. It can be seen that the proposed algorithm in eight out of sixteen instances has reached the best known solutions. For the rest instances, the quality of the solutions is between 0.01 (in three instances) to 2.12. The average quality for the sixteen instances is equal to 0.24. The standard deviation is between 0.00 and 0.97 with average standard deviation equal to 0.53 and the variance is between 0.00 and 0.94 with average variance equal to 0.42. The proposed algorithm gave better results from the other three versions that are used in these comparisons. More precisely, the improvement in the quality of the solutions of the proposed method (GLCENTPSO) from the CNTPSO is between 0.01 and 0.91 with average improvement equal to 0.33, the improvement in the quality of the solutions of the proposed method (GLCENTPSO) from the ENTPSO is between 0.01 and 1.55 with average improvement equal to 0.41, and, finally, the improvement in the quality of the solutions of the proposed method (GLCENTPSO) from the GLPSO is between 0.01 and 1.19 with average improvement equal to 0.31. The next issue that it should be answered is which of the three features helps the algorithm more. As it can be observed none of them outperforms clearly the other two. The CNTPSO performs better than the ENTPSO in 7 instances (worst in 9) and from the GLPSO in 8 instances (worst in 8), while the ENTPSO performs better than the GLPSO in 7 instances (worst in 9).In Table 6, the results in the Prins et al. instances are presented. It can be seen that the proposed algorithm in 13 out of 30 instances has reached the best known solutions. For the rest instances, the quality of the solutions is between 0.09 and 2.54. The average quality for the 30 instances is equal to 0.42. The standard deviation is between 0.00 and 1.52 with average standard deviation equal to 0.80 and the variance is between 0.00 and 2.32 with average variance equal to 0.77. As in the first data set, the proposed algorithm gave better results from the other three versions that are used in these comparisons. More precisely, the improvement in the quality of the solutions of the proposed method (GLCENTPSO) from the CNTPSO is between 0.01 and 0.23 with average improvement equal to 0.08, the improvement in the quality of the solutions of the proposed method (GLCENTPSO) from the ENTPSO is between 0.02 and 0.47 with average improvement equal to 0.14, and, finally, the improvement in the quality of the solutions of the proposed method (GLCENTPSO) from the GLPSO is between 0.02 and 0.37 with average improvement equal to 0.11. The next issue that we have to answer is which of the three features helps the algorithm more. The CNTPSO performs better than both ENTPSO and GLPSO in all instances while the ENTPSO performs better than the GLPSO in 9 instances (worst in 21). As it can be observed, the CNTPSO performs better than the other two methods followed by GLPSO while the ENTPSO has the worst performance.In Table 7, the results in the Tuzun and Burke instances are presented. It can be seen that the proposed algorithm in seven out of thirty six instances has reached the best known solutions. For the rest instances, the quality of the solutions is between 0.07 and 3.10. The average quality for the 36 instances is equal to 0.86. The standard deviation is between 0.34 and 1.12 with average standard deviation equal to 0.86 and the variance is between 0.12 and 1.20 with average variance equal to 0.77. The proposed algorithm gave better results from the other three versions that are used in these comparisons. More precisely, the improvement in the quality of the solutions of the proposed method (GLCENTPSO) from the CNTPSO is between 0.03 and 0.55 with average improvement equal to 0.24, the improvement in the quality of the solutions of the proposed method (GLCENTPSO) from the ENTPSO is between 0.06 and 0.74 with average improvement equal to 0.32, and, finally, the improvement in the quality of the solutions of the proposed method (GLCENTPSO) from the GLPSO is between 0.06 and 0.74 with average improvement equal to 0.27. In these comparisons, it is, also, significant to see which of the three features helps the algorithm more. The CNTPSO performs better than the ENTPSO in 24 instances (worst in 12) and than the GLPSO in 21 instances (worst in 15), while the ENTPSO performs better than the GLPSO in 16 instances (worst in 20). Thus, as in the previous data set, the CNTPSO performs better than the other two versions.In general, the algorithm was tested in 82 instances from three different data sets. The algorithm found the best known solutions in 28 of them, i.e. in 34.14% of all instances. The quality was between 0.01 and 0.50 in 26 instances, i.e. in 31.70% of all instances and it was between 0.51 and 1.00 in 9 instances, i.e. in 10.97% of all instances, while it was between 1.01 and 2.54 in 19 instances, i.e. in 23.82% of all instances. The average quality is equal to 0.58. These results are for the best run of the algorithm. The standard deviation is between 0.00 and 1.52 with average standard deviation equal to 0.78 and the variance is between 0.00 and 2.32 with average variance equal to 0.70. As it was shown earlier, the proposed algorithm gave better results from the other three versions that are used in the comparisons. More precisely, the improvement in the quality of the solutions of the proposed method (GLCENTPSO) from the CNTPSO is between 0.01 and 0.91, the improvement in the quality of the solutions of the proposed method (GLCENTPSO) from the ENTPSO is between 0.02 and 1.55 and, finally, the improvement in the quality of the solutions of the proposed method (GLCENTPSO) from the GLPSO is between 0.01 and 1.19. These results prove that the addition of each one of the features is very important in the effectiveness of the algorithm and each one helps the algorithm to improve its results. Another issue that we have to mention is which of the three features helps the algorithm more. As it can be observed the CNTPSO performs better than the ENTPSO in 61 instances (worst in 21) and than the GLPSO in 59 instances (worst in 23), while the ENTPSO performs better than the GLPSO in 32 instances (worst in 50). Thus, the presence of each of the three features is necessary for the effectiveness of the algorithm. However, the most important of the three features was proved to be the combinatorial neighborhood topology (CNTPSO), followed by the global and local neighborhood topology (GLPSO) and, then, by the expanding neighborhood topology (ENTPSO).The results of the GLCENTPSO algorithm in the capacitated location routing problem were, also, compared (Tables 8–10) with the results of a number of metaheuristic, evolutionary and nature inspired algorithms from the literature. In these implementations, the same instances are used as the ones used in this paper and, thus, comparisons of the results can be performed.More precisely, in Table 8 the results of the proposed algorithm are compared with the results of the following algorithms in Barreto benchmark instances:•A bilevel genetic algorithm (LRPBilevel) [59].A particle swarm optimization algorithm with path relinking (HybPSO) [60].A bilevel particle swarm optimization algorithm (PSOBilevel) [65].A honey bees mating optimization algorithm (HBMOLRP) [70].A combination of simulated annealing and ant colony system (ACO-SA) [13].A clustering based heuristic (CH) [8].A greedy randomized adaptive search procedure complemented by a learning process and a path relinking (GRASP) [88].A memetic algorithm with population management (MAPM) [89].A cooperative Lagrangean relaxation-granular tabu search heuristic (LRGTS) [90].A greedy randomized adaptive search procedure using an evolutionary local search algorithm (GRASP+ELS) [26].A memetic approach (GAHLS) [25].A simulated annealing algorithm (SALRP) [108].A greedy randomized adaptive search procedure using an integer linear programming strategy (GRASP+ILP) [22].A multiple ant colony optimization algorithm (MACO) [98].In Table 9, the results of the proposed algorithm are compared with the results of the following algorithms in Prins et al. benchmark instances:•A memetic algorithm (MSLS) [87].A greedy randomized adaptive search procedure complemented by a learning process and a path relinking (GRASP) [88].A memetic algorithm with population management (MAPM) [89].A cooperative Lagrangean relaxation-granular tabu search heuristic (LRGTS) [90].A memetic approach (GAHLS) [25].A simulated annealing algorithm (SALRP) [108].A greedy randomized adaptive search procedure using an evolutionary local search algorithm (GRASP+ELS) [26].A greedy randomized adaptive search procedure with a learning process (GRASP-LP) [82].A greedy randomized adaptive search procedure with a learning process and path relinking (GRASP-LP-PR) [82].A greedy randomized adaptive search procedure using an integer linear programming strategy (GRASP+ILP) [22].A multiple ant colony optimization algorithm (MACO) [98].Finally, in Table 10, the results of the proposed algorithm are compared with the results of the following algorithms in Tuzun and Burke benchmark instances:•A two phase tabu search algorithm (Tabu) [101].A greedy randomized adaptive search procedure complemented by a learning process and a path relinking (GRASP) [88].A memetic algorithm with population management (MAPM) [89].A cooperative Lagrangean relaxation-granular tabu search heuristic (LRGTS) [90].A memetic approach (GAHLS) [25].A simulated annealing algorithm (SALRP) [108].A greedy randomized adaptive search procedure using an evolutionary local search algorithm (GRASP+ELS) [26].A greedy randomized adaptive search procedure using an integer linear programming strategy (GRASP+ILP) [22].A multiple ant colony optimization algorithm (MACO) [98].From these tables it can be seen that different algorithms are used in the literature for the three data sets of benchmark instances. However, there are 8 algorithms (GRASP, MAPM, LRGTS, GAHLS, SALRP, MACO, GRASP+ILP and GRASP+ELS) that they have been tested in all data sets. Most of the algorithms are based on a GRASP or a memetic variants, there are two algorithms that use tabu search implementations and two others that use a simulated annealing implementations. There are five algorithms that they use nature inspired algorithms, two of them an ant colony optimization variant, one of them a honey bees mating optimization implementation and, finally, two of them use a particle swarm optimization algorithm. In Tables 8–10 the qualities of the results in each set of benchmark instances for all algorithms are presented. The qualities are based on the best known solutions (BKS) presented on Tables 5–7. In all tables where no values exist it means that the authors did not give the values for these instances in the corresponding paper. The total number of best known solutions found is denoted with NB in Tables 8–11.In Table 8, the algorithm that finds the best known solutions in most instances is the SALRP algorithm (in 13 out of 16 instances). In the average qualities of the solutions, the MACO algorithm is ranked second with average deviation from the best solution equal to 0.07 and the GRASP+ELS algorithm is ranked third with average deviation from the best solution equal to 0.08. The GRASP+ILS algorithm is ranked fourth with average quality equal to 0.19. The proposed algorithm is ranked in the fifth place with average quality equal to 0.24 in the total of 15 algorithms used in these data sets. The only other algorithm that its average quality is less than 1 is the GAHLS with average quality equal to 0.49. The average qualities in the solutions for all the other algorithms are between 1.50 (ACO-SA algorithm) to 3.23 (CH algorithm). The most important comparisons are with the HybPSO and PSOBilevel algorithms as these two algorithms are based on variants of the particle swarm optimization algorithm. The improvement in the qualities of the solutions of the proposed method (GLCENTPSO) from the HybPSO is between 0.00 (in four instances) to 8.89 with average improvement equal to 2.89. Also, the improvement in the qualities of the solutions of the proposed method (GLCENTPSO) from the PSOBilevel is between 0.00 (in the same four instances) to 4.48 with average 1.29. The algorithm that found the best known solutions in most instances is the SALRP that finds the best known solutions in 13 instances, the GRASP+ILS in 9 instances, the proposed algorithm found the best known solutions in 8 instances, the GRASP+ELS in 8 instances, the MACO in 8 while the GAHLS in 6 instances. All the other algorithms found the best known solutions in 2–5 instances.In Table 9, the algorithm that finds the best known solutions in most instances is the SALRP algorithm with 25 out of 30 instances. In the average qualities of the solutions the GRASP+ILP is ranked second out of twelve algorithms with average quality equal to 0.09, the MACO is ranked in the third place with average quality equal to 0.37 and the proposed algorithm is ranked in the fourth place with average quality equal to 0.42. The only other algorithm that its average quality is less than 1 is the LRGTS with average quality equal to 0.75. The average qualities in the solutions for all the other algorithms are between 1.08 (GRASP+ELS algorithm) and 8.26 (MSLS algorithm). The algorithm that found the best known solutions in most instances is the SALRP in 25 instances, the GRASP+ILP found the best known solutions in 16 instances, the proposed algorithm found the best known solutions in 13 instances, the GRASP+ELS in 12, the MACO in 12 while the MAPM found the best known solutions in 10 instances. All the other algorithms found the best known solutions in 2–7 instances.Finally, in Table 10, the algorithm that finds the best known solutions in most instances is the GRASP+ILP with 22 best known solutions out of 36 and in the second place is ranked the SALRP algorithm with 15 out of 36. In the average qualities of the solutions in the first place is the GRASP+ILP algorithm with average quality equal to 0.04, in the second place is the SALRP algorithm with average quality equal to 0.39 while the proposed algorithm is ranked in the third place with average quality equal to 0.86. In all the other algorithms the average qualities in all instances is more than one.A summary table containing all the results for all data sets and all algorithms is presented in Table 11. In this Table, for all algorithms they are presented the average qualities (av), the total number of best known solutions found (NB), the total number of tested instances (NI) and the percentage (%) of the best known solutions found (Perc) for all data sets (columns 2–5) and for each data set separately (columns 6–9 for the Barreto data set, columns 10–13 for the Prins et al. data set and columns 14–17 for the Tuzun and Burke data set). As it is shown, only 7 out of 17 algorithms have been tested in all data sets (SALRP, GRASP+ILP, GLCENTPSO, MACO, GRASP, MAPM, LRGTS, GRASP+ELS and GAHLS). The other 10 algorithms have been tested in only one data set each (6 in the Barreto data set, 3 in the Prins et al. data set and 1 in the Tuzun and Burke data set). In total the best performing algorithms are the nine algorithms that have been tested in all data sets and three other algorithms, the PSOBilevel, the ACO-SA that have been tested in the first data set and the GRASP-LP-PR that has been tested in the second data set.The algorithm that performs better than all the other algorithms is the SALRP algorithm that was tested in all instances (82 instances) and found the best known solutions in 53 instances. In the second place is the GRASP+ILP algorithm that found the best known solutions in 47 instances. In the third place we could say that we have three algorithms, the proposed algorithm GLCENTPSO, the GRASP+ELS and the MACO algorithm. These three algorithms have been tested in almost all instances (in 82 the proposed algorithm and MACO and in 79 the GRASP+ELS), they have average quality equal to 0.58 for the proposed algorithm, 0.62 for the MACO and 0.95 for the GRASP+ELS, they found 27, 26 and 25 best known solutions, respectively and the percentages of the best known solutions found are equal to 32.93, 32.91 and 30.48, respectively. Afterwards, we could say that there are 6 algorithms that perform equally well (the MAPM, the LRGTS, the GAHLS, the PSOBilevel, the ACO-SA and the GRASP-LP-PR). Some of them have very good average qualities and some of them have found large numbers of best known solutions and some of them have large percentages in best known solutions found but they have been tested in small number of instances.For the solution of the location routing problem with stochastic demands there are no instances in the literature. Thus, a number of instances were created based on the three set of instances that we used for the solution of the capacitated location routing problem (Section 4.1). Because the problem is treated as a two phase problem, for the second phase, we assume that customer demands are independent Poisson random variables with the mean demand for each customer equal to the deterministic value of the demand given in the corresponding CLRP problem [68,58]. A preventive restocking strategy is applied and in order to avoid the route failure a threshold value is used. If the residual load after servicing a customer is greater than or equal to this threshold value, then, the vehicle proceeds to the next customer, otherwise, it returns to the depot for replenishment [68,58]. As in the literature authors have not formulated the location routing problem with stochastic demands as it is formulated in this paper, there are no any algorithms to compare the proposed algorithm. Thus, the algorithm was compared with the three different versions of PSO (the CNTPSO, the ENTPSO and the GLPSO) used in the comparisons in Section 4.1. The algorithms were executed for 10 times for each instance and in Tables 12–14the results of the best run for each one of the algorithms are presented. In Tables 12–14, besides the results of the best run of each of the algorithms (columns 2–5, respectively), the improvement or deterioration in each pair of the algorithms is presented. Thus, in column 6 with the notation q12 it is denoted the improvement (if the value is negative) or the deterioration (if the value is positive) between the solution of the best run of the algorithms CNTPSO and ENTPSO. Thus, in columns 6–11 the improvement (or deterioration) between the results of a pair of algorithms is presented, where in qijthe index i and index j correspond to a specific method. More precisely, the value of the index equal to 1 corresponds to CNTPSO, the value 2 corresponds to ENTPSO, the value 3 corresponds to GLPSO and the value 4 corresponds to the proposed algorithm.In Table 12, the results in the Barreto instances are presented while in Table 13 the results in the Prins et al. instances are presented and, finally, in Table 14 the results in Tuzun and Burke instances are presented. The results of the proposed algorithm are better than the results of the other three algorithms used in the comparisons as it is presented in the last three columns of the Tables. More precisely, the improvement in the solution of the proposed algorithm from the CNTPSO algorithm in the Barreto instances is between 0.03 and 3.22 (column 9 denoted by q14 for each Table), the improvement in the Prins et al. instances is between 0.01 and 2.22 and, finally, the improvement in the Tuzun and Burke instances is between 0.00 and 2.23. In the instance where the improvement is equal to 0.00 the two algorithms did not find the same solution but the difference was too small (2304.94 the proposed algorithm and 2304.97 the CNTPSO) and, thus, the improvement was calculated equal to 0.00. If we compare the proposed algorithm with the ENTPSO the results are analogous. More precisely, the improvement in the solution of the proposed algorithm from the ENTPSO algorithm in the Barreto instances is between 0.04 and 4.49 (column 10 denoted by q24 for each Table), the improvement in the Prins et al. instances is between 0.03 and 2.38 and, finally, the improvement in the Tuzun and Burke instances is between 0.02 and 1.89.Finally, the comparison of the proposed algorithm with the GLPSO gave the following results: the improvement in the Barreto instances is between 0.03 and 5.40 (column 11 denoted by q34 for each Table), the improvement in the Prins et al. instances is between 0.01 and 2.00 and, finally, the improvement in the Tuzun and Burke instances is between 0.10 and 2.03. When we compare the results of the CNTPSO and ENTPSO (column 6 denoted with q12 for each Table), in the Barreto instances each of the algorithm gave better results in 8 instances. In the Prins et al. instances each of the algorithm gave better results in 15 instances. Finally, in the Tuzun and Burke instances the ENTPSO gave better results in 21 instances while the CNTPSO in 15 instances. In total, the ENTPSO gave better results in 44 instances while the CNTPSO in 38 instances.When we compare the results of the CNTPSO and GLPSO (column 7 denoted with q13 for each table), in the Barreto instances the GLPSO gave better results in 6 and the CNTPSO in 10 instances. In the Prins et al. instances, the GLPSO performs better than previously as it gave better results in 17 instances and the CNTPSO gave better results in 13 instances. Finally, in the Tuzun and Burke instances the GLPSO gave better results in 20 instances while the CNTPSO in 16 instances. In total, the GLPSO gave better results in 43 instances while the CNTPSO in 39 instances. Finally, when we compare the results of ENTPSO with the results of GLPSO (column 8 denoted q23 for each Table), in the Barreto instances the GLPSO gave better results in 6 and the ENTPSO in 10 instances. In the Prins et al. instances the GLPSO performs better than previously as it gave better results in 16 instances and the ENTPSO gave better results in 14 instances. Finally, in the Tuzun and Burke instances the GLPSO gave better results in 15 instances while the ENTPSO in 21 instances. In total, the GLPSO gave better results in 37 instances while the CNTPSO in 45 instances. As it is presented for the comparisons, none of the three algorithms performs clearly better than the other and, thus, each one of the features that are added in the proposed algorithm contribute with a different positive way in the improvement of the results.In Tables 15–17, a last set of comparisons is presented. In these tables, the proposed algorithm is compared with four other evolutionary algorithms in order to give the effectiveness of the proposed algorithm. The first algorithm is an evolutionary algorithm (RVNS) which is not following the classic form of an evolutionary algorithm but the initial solutions are produced using a random way and, then, for each member of the population, a variable neighborhood search algorithm is used for the improvement of the solutions. The iterated local search is used in order to produce a new solution. The second algorithm that it is used is a hybrid genetic algorithm (HGA) with variable neighborhood search and iterated local search. The third algorithm is a hybrid differential evolution (HDE) algorithm with the same local search phases as the ones of the proposed algorithm. For analytical description of the HGA and the HDE please see [73]. The fourth algorithm is a hybrid clonal selection algorithm (HCSA) [72] with the same local search phases as the ones of the proposed algorithm. In all tables, the best results and the quality (ω) of the four algorithms are presented. Also, the best known solutions (BKS) from the literature are given. The BKS is the best solution from the four algorithms used in the comparisons.In Table 15, the results for the first set of benchmark instances (Barreto instances) is presented. The proposed algorithm finds in all instances new best solutions. However, in the Table in the column that the quality is presented, in one instance the quality is equal to 0 which means that the two algorithms find the same solution. It should be noted that in this instance there is an improvement in the best solution from the best known solution but it is very small (the BKS is 43,967.86 while the cost of the solution in the proposed algorithm is equal to 43,967.82) in order to appear in the quality of the solutions. For the other 15 instances, the improvement in the solutions is between 0.02 and 0.41. The same holds for the instances in the other two Tables. In Tables 16 and 17 where the results of the second set of benchmark instances (Prins et al.) and of the third set of benchmark instances (Tuzun and Burke) are presented, respectively, the proposed algorithm finds new best solutions in all instances. However, in some instances (20 out of 30 in the second set and 4 out of 36 in the third set) the improvement of the BKS is very small and it cannot be appeared in the quality (ω) of the solutions. In the other instances (10 of the second set and 32 of the third set) the improvement is between 0.01 and 0.02 in the second set and between 0.01 and 0.08 in the third set.In this paper, a nature inspired approach was introduced for the effective handling of two location routing problems, the classic capacitated location routing problem (CLRP) and the location routing problem with stochastic demands (LRPSDs). More specifically, a new, suitable for combinatorial optimization problems, version of the particle swarm optimization algorithm, the global and local combinatorial expanding neighborhood topology particle swarm optimization (GLCENTPSO) for the CLRP and the LRPSDs was proposed. The main problem of most nature inspired algorithms, except of the ant colony optimization algorithm, when applied to combinatorial optimization problems is the loss of information in the transformation of the solutions from continuous values to discrete values and vice versa. This problem is due to the fact that these algorithms have, initially, been proposed for the solution of continuous optimization problems. The main contribution of this paper is that with the use of the combinatorial neighborhood topology, we did not use any transformation from continuous to discrete values and vice versa. Another two features that were added in the proposed algorithm are the use of the expanding neighborhood topology and the global and local neighborhood topology. These two features gave to the algorithm more exploration abilities.The algorithm was applied for the CLRP in three sets of benchmark instances and gave remarkable results both to quality and computational efficiency. Also, comparisons with algorithms from the literature in the CLRP denote the effectiveness of the proposed algorithm. As a concluding remark from the comparisons we can say that the proposed algorithm performs better than almost all population based algorithms (nature inspired and evolutionary algorithms) and single solution metaheuristics that have been presented for the solution of the CLRP. For the LRPSDs, there are not any instances in the literature that are used for the solution of the problem in the way that is formulated in this research. For this reason, we used the same instances that we used in the CLRP appropriately modified. We compared the results of the proposed algorithm with the results of other implementation of PSO algorithm, the same implementations that were used in the CLRP case, and the general outcome was that the proposed algorithm has the same effective behavior in the LRPSDs as in the CLRP. In the future, the performance of the algorithm will be tested in more difficult combinatorial optimization problems.

@&#CONCLUSIONS@&#
