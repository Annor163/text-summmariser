@&#MAIN-TITLE@&#
Real-time facial shape recovery from a single image under general, unknown lighting by rank relaxation

@&#HIGHLIGHTS@&#
We propose a real-time facial shape recovery algorithm from a single image.An input image is a frontal face under a general, unknown lighting with cast shadow.A bilinear model is linearized by rank relaxation to reduce the time complexity.Faces are accurately reconstructed even if there is a heavy shadow.The method takes average 45ms to reconstruct a 3D face.

@&#KEYPHRASES@&#
Facial shape recovery,Shape from shading,Statistical face model,Bilinear model,Rank relaxation,

@&#ABSTRACT@&#
Statistical shape from shading under general light conditions can be thought of as a parameter-fitting problem to a bilinear model. Here, the parameters are personal attributes and light conditions. Parameters of a bilinear model are usually estimated using the alternating least squares method with a computational complexity ofO((ns+nϕ)2np), wherens,nϕ, andnpare the dimensions of the light conditions, personal attributes, and face image features, respectively, for each iteration. In this paper, we propose an alternative algorithm with a computational complexity ofO(nsnϕ)for each iteration. Only the initial step requires a computational complexity ofO(nsnϕnp). This can be accomplished by reformulating the problem to that of a linear least squares problem, with a search space limited to a set of rank-one matrices. The rank-one condition is relaxed to obtain a possibly full-rank matrix. The algorithm then finds the best rank-one approximation of that matrix. By the Eckart–Young theorem, the best approximation is the outer product of the left and right singular vectors corresponding to the largest singular value. Since only this pair of singular vectors is needed, it is better to use the power iteration method, which has a computational complexity ofO(nsnϕ)for each iteration, than calculating the full singular value decomposition. The proposed method provides accurate reconstruction results and takes approximately 45ms on a PC, which is adequate for real-time applications.

@&#INTRODUCTION@&#
Over the past two decades, model-based approaches in shape from shading (SFS) [1–11] have successfully accommodated the need for an efficient and accurate 3-D reconstruction method without any specialized hardware device. Unlike the early SFS methods [12], these approaches impose model constraints to rule out the ambiguity [13] caused by the ill-posedness of the SFS problems and guarantee a unique solution. Except for a few alternatives, such as the method based on light attenuation [14], the model-based approaches have formed the mainstream of the 3-D reconstruction methods that use a single image, and they are applied in many areas [5,15,16].However, there are some drawbacks to the model-based approaches. Often they are either too computationally expensive or too restrictive in their application. The most prominent work that falls into the former case is the morphable model (MM) [2], which synthesizes a 3-D face shape by minimizing the difference between a face image and a pre-built statistical model of face shape and texture. The MM is an analysis-by-synthesis approach and is actively studied in the area of computer vision [5,15]. The MM-based methods can simultaneously estimate the pose and appearance of a face in an image, but they usually require heavy computation (e.g., they can take a few minutes to reconstruct a face). Many works belong to the group that are too restrictive, such as the work in [1], which was the first attempt to utilize a model-based approach for 3-D face reconstruction, but failed to achieve high reconstruction accuracy. These methods are applied to fixed-pose images under a single, known light source or a fixed light condition and are relatively faster than MM. However, they are too restrictive to use and some of them perform poorly. Reiter et al. [3] and Lei et al. [6] both find a linear mapping between image and depth, based on the features extracted using canonical correlation analysis (CCA) [17]. Lei et al. used near infrared images as input images to mitigate the effects of illumination changes. They applied N-mode singular value decomposition (SVD) [18], which is a generalization of SVD for multi-dimensional data, as an alternative feature extraction method. These methods cannot handle light variations and so require special light conditions. A statistical model of azimuthal equidistant projection of surface normals is proposed in [7] and is combined with Lambert’s law for optimization. It requires the light source to be known and is vulnerable to large albedo variations. A non-stationary stochastic filtering framework [19] is applied to estimate the albedo and illuminance of a face image in [8] as a preprocessing step for SFS algorithms. However, the original SFS algorithms [12] suffer from the ambiguity mentioned above and require that there be a single light source in an image. Kemelmacher-Shlizerman and Basri [9] proposed a novel approach that adjusts the details of a reference face shape to fit a new image. Despite the advantage that it requires only a single reference shape, its performance is poor.To overcome these disadvantages, we proposed a tensor-based optimization approach in [10]. We formulated a bilinear model [20–23] of spherical harmonics [24] by using tensor algebra techniques, such as N-mode SVD, to handle general, unknown light conditions. The method offers high reconstruction accuracy, and takes less than half a second on a PC. As is usual for bilinear models, the fitting problem was solved by the alternating least squares (ALS) method [25]. Since each iteration is a linear least square problem in ALS, the computational complexity for each iteration is in the order ofO((ns+nϕ)2np), wherens,nϕ, andnpare the dimensions of light conditions, personal attributes, and face image features, respectively.In this paper, we propose a novel algorithm with a computational complexityO(nsnϕ)for each iteration andO(nsnϕnp)for the initial step. This is accomplished by reformulating the fitting problem, which becomes a linear least squares problem of a rank-one matrix. By relaxing the rank constraint on the search space, the solution matrix, which may be full rank, can be easily found, and the best rank-one approximation is calculated afterwards. This is somewhat similar to the semidefinite relaxation techniques [26], except that the search space is not limited to the set of symmetric matrices. According to the Eckart–Young theorem [27], the best rank-one approximation is given by the outer product of the right and left singular vectors corresponding to the largest singular value. Since we only need this pair of singular vectors, finding only the largest singular value and its corresponding singular vectors is preferable to calculating the full SVD. This can be done by the power iteration method [28], which is a numerical algorithm that finds the greatest absolute eigenvalue or singular value of a matrix. The computational complexity of the power iteration method is in the order ofO(nsnϕ)for each iteration, which makes the algorithm more efficient. Only the initial step, which solves the least squares problem by relaxing the constraint, requires a computational complexity ofO(nsnϕnp).After finding the solution, a linear mapping is applied to calculate the corresponding depth map. The proposed method provides accurate reconstruction results and performance similar to that of the method in [10], although the computation time of the proposed method is much lower. The average reconstruction time is approximately 45ms on a PC, which is sufficient for real-time applications.The remainder of the paper is organized as follows. The basics of tensor algebra are introduced in Section 2, and the proposed algorithm is explained in Section 3. The performance is evaluated in Section 4, and finally, the paper is concluded in Section 5.In this paper, we use tensor algebra and explanations for standard operations, such as mode-k flatteningA(k), mode-k productA×kM, and N-mode SVD, can be found in [6,18]. In this section, we explain non-standard operations that we use in the rest of the paper.The reshaping of a tensor is denoted asB=RA;n1′,n2′,…,nN′′,whereA∈Rn1×…×nN,B∈Rn1′×…×nN′′, and∏lNnl=∏lN′nl′. Through the reshaping,Bi1′…iN′′=Ai1…iNfor1+∑j=1N′(ij′-1)∏l<jnl′=1+∑j=1N(ij-1)∏l<jnl.For Nth-order tensorA, the mode-1 or mode-N flattenings can be defined by the reshaping operator.A(1)=RA;n1,∏l>1nl,A(N)=RA;∏l<Nnl,nNT.The vectorization operator can be defined in the following way.vecA=RA;∏lnl.The mode-k product of a tensor can be expressed in terms of the reshaping operator and the Kronecker product. LetB=A×1W1×2W2,whereA∈Rn1×n2×n3×…×nN,B∈Rn1′×n2′×n3×…×nN,W1∈Rn1′×n1, andW2∈Rn2′×n2. Then it can be shown after some manipulation that the following relation is satisfied.(1)RB;n1′n2′,∏2<lnl=(W2⊗W1)RA;n1n2,∏2<lnl.In this section, we explain the detailed procedure of our algorithm. We model a face image as a bilinear model having two parameter vectors, one for personal attributes and the other for light conditions, and the bases of the model are trained based on samples beforehand. The parameter vector for personal attributes contains abstract information about the appearance of an individual face, which is independent of light condition. After estimating the parameter vectors from an input image using our efficient rank relaxation technique, we perform a linear mapping from the personal attribute vector to the corresponding 3D depth. This linear mapping is also trained beforehand with a set of face images and depth samples. The reconstruction phase is simple enough to allow real-time reconstruction on a regular PC, even though the algorithm achieves the state-of-the-art reconstruction accuracy.A vector corresponding to a face image in a fixed pose under general lighting can be expressed asI=Hs,whereI∈Rmp,H∈Rmp×ns, ands∈Rnsare the image vector, basis matrix, and light condition vector, respectively. Let us assume thatHis expressed as a linear model of the personal attribute vectorϕ∈Rnϕas(2)H=H×3ϕT,whereH∈Rmp×ns×nϕis a third-order tensor. Then, the overall image model is expressed asI=H×3ϕTs=H×2sT×3ϕT.This is a bilinear model [20] of the light condition and the personal attribute.In order to find the personal attribute vectorϕcorresponding to an imageI, the following optimization problem should be solved.minimizes,ϕI-H×2sT×3ϕT2.Since the imageImay contain noise terms, it is a good idea to cancel out the noise terms in the cost function asQTI-H×2sT×3ϕT2=QTI-T×2sT×3ϕT2,whereQ∈Rmp×np(mp<np) is an orthogonal matrix, andT=H×1QT.Qneeds to be chosen such that the first mode ofHis mainly distributed on the space spanned by the columns ofQ. We can findQusing principal component analysis [29], SVD, or some other similar subspace analysis method.The cost function in the above equation is a fourth-degree polynomial, and is usually solved by the ALS algorithm [10,20]. However, this can be reformulated as a second-degree polynomial if we letX=sϕT, i.e.,(3)minimizeXQTI-T(1)vecX2subject toX=sϕT∈R1ns×nϕ,whereR1ns×nϕis the set ofns×nϕrank-one matrices. This is a linear-least-square problem with a rank constraint, to which the solution may be obtained with reduced computational complexity.Tis a model coefficient tensor derived from the basis matricesHof all subjects. Possible candidates forHare scaled surface normals or spherical harmonics [24]. However, these cannot handle cast shadows, and so an alternative basis that can deal with cast shadows is sought.For this,msimages that contain cast shadows are rendered for each subject. Firstly,msdistinct point light sources have to be determined. The direction of each light source may be chosen randomly, but it is better to distribute the directions evenly. This can be done by evenly distributing2mspoints on a unit sphere, and selecting onlymspoints that are on the upper hemisphere. Sampling of evenly distributed points on a sphere can be done in two different ways [30]: We may randomly spread particles carrying a unit charge on a sphere with a frictional surface, and then find an equilibrium state for the particles. Or more simply, we may slightly move two particles that are the smallest distance apart in opposite directions, normalize each new position to a unit vector, and repeat this process until the particles reach an equilibrium state. After this, a light direction can be obtained from each of these points to the center of the sphere.After sampling the light directions, we render the images containing cast shadows. Each point light source is assumed to be at infinity and have unit intensity. The depth map of each subject is differentiated, normalized, and multiplied by the corresponding albedo map to obtain the corresponding scaled surface normals, and the inner product of the scaled surface normal and the light source vector is calculated for each pixel. If the outcome of an inner product is negative, the pixel is in an attached shadow, and its value is set to zero. In order to find the pixels under cast shadows, a triangle mesh is created based on the depth map of each subject. Then, each pixel is checked to see whether it is occluded from the light source by any other triangles, and a kd-tree [31] is used to accelerate the checking process. The pixels found under cast shadows are again set to zero.Combining all the results of the rendering process, a fourth-order tensorG∈Rmx×my×ms×mϕis created. Note thatmxmy=mpandGijklcorrespond to the(i,j)th pixel of the lth subject under the kth light direction. SinceGcontains redundant information, N-mode SVD is applied toG, and unimportant dimensions are truncated to yield(4)G≈C×1Ux×2Uy×3Us×4Uϕ,whereC∈Rnx×ny×ns×nϕis the core tensor, andUx∈Rmx×nx,Uy∈Rmy×ny,Us∈Rms×ns, andUϕ∈Rmϕ×nϕare the mode matrices. Note thatnx⩽mx,ny⩽my,ns⩽ms, andnϕ⩽mϕ. Based on this result,His calculated asH=RC×1Ux×2Uy;mp,ns,nϕ.Note that the row vectors ofUsandUϕcorrespond to the light condition vectorssTand the personal attribute vectorsϕTfor the rendered images, respectively. This process attempts to model non-local shadowing effects using statistical samples, which is somewhat related to the ‘apparent BRDF’ approach in [37].In order to findQin (3), SVD is performed onRG;mp,msmϕ, but it is very time consuming because the number of elements are very large (12,000×40,000 in the experiment described in Section 4). Fortunately, from (1) and (4), the approximate result of SVD can be found more easily asRG;mp,msmϕ≈RC×1Ux×2Uy×3Us×4Uϕ;mp,msmϕ=(Uy⊗Ux)RC;nxny,nsnϕ(Uϕ⊗Us)T≈(Uy⊗Ux)UcΛcVcT(Uϕ⊗Us)T,whereRC;nxny,nsnϕ≈UcΛcVcTis the truncated SVD, andUc∈Rnxny×np. The size ofRC;nxny,nsnϕisnxny×nsnϕ, which is much smaller thanmp×msmϕ, so the calculation can be performed much faster. It is readily verified from the following relation that the mode matrix(Uy⊗Ux)Ucis orthogonal.(Uy⊗Ux)UcT(Uy⊗Ux)Uc=UcT(Uy⊗Ux)T(Uy⊗Ux)Uc=UcT(UyT⊗UxT)(Uy⊗Ux)Uc=UcT(UyTUy⊗UxTUx)Uc=UcT(E⊗E)Uc=UcTEUc=UcTUc=E,whereEis an identity matrix. The orthogonality of(Uϕ⊗Us)Vccan be proved similarly. Therefore, the orthogonal matrixQ∈Rmp×npcan be set asQ=(Uy⊗Ux)Uc.Finally, the relationT=H×1QTgivesT=RC×1Ux×2Uy;mp,ns,nϕ×1UcT(UyT⊗UxT)=RC;nxny,ns,nϕ×1(Uy⊗Ux)×1UcT(UyT⊗UxT)=RC;nxny,ns,nϕ×1UcT(UyT⊗UxT)(Uy⊗Ux)=RC;nxny,ns,nϕ×1UcT.The goal of this paper is to reconstruct a 3-D shape that corresponds to a face image, and a depth model is also needed. LetD∈Rmx×my×mϕbe a third-order tensor, and its elementDijkis the(i,j)th depth value of the kth subject. Then, by performing N-mode SVD and truncating, we have(5)D≈L×1Vx×2Vy×3Vϕ,whereL∈Rnx′×ny′×nϕ′is the core tensor, andVx∈Rmx×nx′,Vy∈Rmy×ny′, andVϕ∈Rmϕ×nϕ′are the mode matrices. A depth vectordis expressed asd=Wϕd,whereW=RL×1Vx×2Vy;mp,nϕ′, andϕd∈Rnϕ′is the personal attribute vector ford. Note that each row vector ofVϕcorresponds toϕdTof each subject.Because geometric normalization of images and depths is important for the accuracy of the proposed scheme, a simple affine transform or active appearance model [32] may be used. In this paper, all the images and depths are affine-transformed before the first step of the proposed scheme is performed; this would ensure that the center of each pupil and the center of the mouth are located at the designated locations in 2-D coordinates. It should be noted that the rendering process for themsimages for each training subject is done before the affine transformation. The coordinates of the center of each pupil and the center of the mouth are assumed to be known by using other feature detection tools.Now that we have explained how to calculate all the necessary terms, we will discuss how to solve the optimization problem, (3). If the rank constraint onXis relaxed, then the solutionX∗can be readily found asvecX∗=T(1)+QTI,whereT(1)+is the Moore–Penrose pseudo-inverse ofT(1), which can be pre-computed. Here,X∗will generally be a full-rank matrix, ands∗andϕ∗can be found as the best rank-one approximation ofX∗, that is,X∗≈s∗ϕ∗T.According to the Eckart–Young theorem,s∗andϕ∗are the left and right singular vectors that correspond to the largest singular value, and SVD may be performed onX∗to find them. Nevertheless, the power iteration method is more efficient because we only need the pair of singular vectors. Therefore, the following step is repeatedly calculated until convergence, with the initial valueϕ←μ=E[ϕ]=1mϕUϕT1, where1is a vector of ones.s←X∗ϕ,s←s/‖s‖,ϕ←X*Ts,ϕ←ϕ/‖ϕ‖.This iterative procedure can finds∗andϕ∗up to a scale factor, and hence, we have to find a proper scale forϕ∗. Let us look into the covariance matrixSϕ=E[ϕϕT]-E[ϕ]E[ϕ]T≈1mϕUϕTUϕ-1mϕ2UϕT11TUϕ=1mϕE-1mϕUϕT11TUϕ,ofϕ. If the span of the orthogonal matrixUϕin (4) contains1, thenUϕT12=mϕandSϕwill be singular. The face images of a subject are very similar to those of another subject; hence, the mean vectorμof personal attributes will be the dominating component in (2). This means that1will likely be contained in the span ofUϕ. Accordingly, the null space ofSϕis the space spanned by the vector1mϕUϕT1=μ, which is the mean ofϕ. This implies that the variance ofϕalong theμdirection is zero, and consequently, the orthogonal projection ofϕon the null space ofSϕis the same asμ. Therefore,ϕ∗is scaled asϕ∗←bϕ∗,b=μTμμTϕ∗.Likewise,s∗is scaled ass∗←s∗/b.One of the advantages of the proposed algorithm is that it does not need to calculate the detailed information on the light condition of the input image for 3-D reconstruction, unlike the analysis-by-synthesis approaches such as the MM [2]. In this perspective, the proposed algorithm can be seen as a compromise between discriminative and generative approaches. Since we do not need to determine the detailed information, it can be more robust than the analysis-by-synthesis approaches which can be vulnerable to the error in light estimation. Nonetheless, if the detailed information is needed, we can find it using the linear programming. Lets0be the light intensity vector whose element is the light intensity of each light direction. Thens0=Uss∗+Us⊥s′for an unknown vectors′, whereUsTUs⊥=0. Since light intensity should be nonnegative, the following linear programming problem can be formulated.(6)minimizes′1TUs⊥s′subject toUss∗+Us⊥s′⪰0,where⪰is the element-wise inequality. By pre-multiplying1Tto the constraint inequality, we obtain the inequality1TUs⊥s′⩾-1TUss∗, which is the lower bound of the object function. Since it is a linear programming problem, this implies that there exists a finite optimal solution if there is at least one feasible solution.Let us find a linear mapping fromϕtoϕd, which minimizes the following cost function:F=E12ϕd-Pϕ2,whereP∈Rnϕ′×nϕ. By setting the derivative of F to zero, we find the optimal solutionP∗.P∗=EϕdϕTEϕϕT-1=VϕTUϕUϕTUϕ-1=VϕTUϕE-1=VϕTUϕ.The overall procedure for the proposed method is composed of two parts, model building and reconstruction, which are summarized as follows:[Model building]1.Sample m evenly distributed points on an upper hemisphere using the method in [30]. For each training subject and light direction, render an image containing cast shadow as described in Section 3.2. Form tensorGwith all the images.Perform N-mode SVD onGand truncate unimportant dimensions, as shown in (4). Again, perform SVD and truncate the unimportant dimensions, which results inRC;nynx,nsnϕ≈UcΛcVcT. CalculateQ=(Uy⊗Ux)UcandT=RC;nynx,ns,nϕ×1UcT. Find the meanμ=1mϕUϕT1, and pre-computeT(1)+.Perform N-mode SVD on the depth tensorD, and truncate the unimportant dimensions, as shown in (5). CalculateW=RL×1Vx×2Vy;mp,nϕ′.CalculateP∗=VϕTUϕ.[Reconstruction]1.ComputevecX∗=T(1)+QTI.Set initialϕasϕ←μ.Updatesass←Xϕands←s/‖s‖.Updateϕasϕ←XTsandϕ←ϕ/ϕ.Repeat Steps 3 and 4 until convergence.Scaleϕ∗asϕ∗←bϕ∗, whereb=μTμμTϕ∗.The depth is calculated asd=WP∗ϕ.(Optional) Scales∗ass∗←s∗/b.(Optional) Solve the linear programming problem in (6) to find the light conditions0of imageI.We now focus our attention on the reconstruction procedure. Here we can see that the computational complexity of the initial step, Step 1, isO(nsnϕnp). In each iteration, Steps 3 and 4 takeO(nsnϕ). In the experiments described in Section 4, it took between 10 and 20 iterations to achieve convergence. Hence, the initial step (Step 4) takes most of the time in the reconstruction process. If ALS is used instead, then each iteration takesO((ns+nϕ)2np), which is much larger than the proposed algorithm. Therefore, the rank relaxation technique proposed in this paper is efficient and can hence achieve fast computation.It is noted thatQTIin Step 1 can be more efficiently calculated asQTI=UcT(UyT⊗UxT)vecRI;mx,my=UcTvecUxTRI;mx,myUy.Similarly,WPϕin Step 7 can be calculated asWPϕ=RL×1Vx×2Vy;mp,nϕ′Pϕ=L×1Vx×2Vy(3)TPϕ=L×1Vx×2Vy×3PϕT(3)T=RL×3PϕT×1Vx×2Vy;mp,1=vecVxL×3PϕTVyT.Our MATLAB implementation of the proposed reconstruction method can be obtained from http://plaza4.snu.ac.kr/cutybug/rr/.

@&#CONCLUSIONS@&#
