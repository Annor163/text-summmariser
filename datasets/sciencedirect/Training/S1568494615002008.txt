@&#MAIN-TITLE@&#
3D model reconstruction using neural gas accelerated on GPU

@&#HIGHLIGHTS@&#
A 3D reconstruction model method based on neural gases (NG).The method can be used for reverse engineering purposes.NG reconstruction deal with noisy low cost 3D sensor acquisitions.3D models integration in design and manufacturing virtual environments.Parallelization/acceleration onto GPUs is provided.

@&#KEYPHRASES@&#
Neural gas,Topology preservation,3D model reconstruction,Graphics Processing Units,

@&#ABSTRACT@&#
In this work, we propose the use of the neural gas (NG), a neural network that uses an unsupervised Competitive Hebbian Learning (CHL) rule, to develop a reverse engineering process. This is a simple and accurate method to reconstruct objects from point clouds obtained from multiple overlapping views using low-cost sensors. In contrast to other methods that may need several stages that include downsampling, noise filtering and many other tasks, the NG automatically obtains the 3D model of the scanned objects. To demonstrate the validity of our proposal we tested our method with several models and performed a study of the neural network parameterization computing the quality of representation and also comparing results with other neural methods like growing neural gas and Kohonen maps or classical methods like Voxel Grid. We also reconstructed models acquired by low cost sensors that can be used in virtual and augmented reality environments for redesign or manipulation purposes. Since the NG algorithm has a strong computational cost we propose its acceleration. We have redesigned and implemented the NG learning algorithm to fit it onto Graphics Processing Units using CUDA. A speed-up of 180× faster is obtained compared to the sequential CPU version.

@&#INTRODUCTION@&#
A 3D model of a free-form object [1] is constructed by acquiring multiple viewpoints so that its surface is completely covered. These views are then registered into a common coordinate basis and the implicit surface defined by the 3D data is computed obtaining a 3D mesh.Although many algorithms have already been proposed for mesh generation from an unorganized point cloud [2–7], existing techniques have various limitations mainly in terms of their applicability to free-form objects, accuracy, efficiency, and the discriminating capability of the generated representation. An excellent survey of free-form object representation and recognition techniques can be found in [8]. In addition, a brief survey is presented in Section 2 for completeness.The three-dimensional representation of an object provides a higher degree of realism. This factor has been implemented at different stages of production processes in order to improve productivity and quality. Moreover, the combination of the acquired and reconstructed 3D models with virtual and augmented reality environments allows users to interact with them thus developing a virtual manufacturing system as an application of augmented reality to improve several process stages [9], including quality control, human-machine interface and information flows, practicing e-commerce and the possibility of implementing different production philosophies. Oh et al. [10] presented the direct modelling approach, which allows the user to intuitively select geometric entities in real time regardless of the modifications made. This was initially developed for conceptual design and architectural planning [11]. Fiorentino et al. [12] showed the advantages derived from using a semi-immersive environment, combining stereoscopic vision with 3D inputs, addressed to conceptual and aesthetic design.In the last years, neural network approaches have become popular in different fields, including computer graphics. Neural networks have been extensively used for data clustering. In particular, self-organizing models [13] place their neurons so that their positions within the network and the connectivity between different neurons are optimized to match the spatial distribution of activations. As a result of this optimization, existing relationships within the input space will be reproduced as spatial ones among neurons in the network. The final result of the self-organizing or competitive learning process is closely related to the concept of Delaunay triangulation of the input space corresponding to the reference vectors of the neurons in the network. Traditionally, it has been suggested that this triangulation, which is the result of the competitive learning process, preserves the topology of the input space. However, Martinetz and Schulten [14] introduced a new condition which restricts this feature. In this sense, self-organizing maps or Kohonen maps are not topology preserving networks (TPN) as they have traditionally been considered, since this condition only would happen in the event that the topology or dimension of the map and the input space coincide. The Growing Cell Structures [15] are not TPN since the topology of the network is established a priori.In the case of the neural gases like neural gas (NG) [16] or growing neural gas (GNG) [17], the mechanism for adjusting the network through a competitive learning induces a Delaunay triangulation. Martinetz and Schulten [14] proved that these models are TPN.Neural gases have been widely used in recent years for different applications, mainly for clustering or topology learning. In [18], the representation obtained with the neural network structure is used to represent road networks and build an intelligent navigation system. Camastra and Vinciarelli [19] and Ling Zhang et al. [20] use the NG to build character recognition systems. Melato et al. [21] applied the NG to reconstruct 3D surfaces but no quantitative quality of representation data is provided with only qualitative examples and comparisons with the GNG model.There are also a number of works using GNG models for 3D reconstruction tasks [22,5,23,24]. However, based on our previous experience [25,26] we demonstrated that the neural gas model provides a higher quality of representation than the GNG one, so it is more accurate for the proposed problem.Moreover, the NG learning algorithm has a higher level of parallelism and is more suitable to be implemented on Graphics Processing Units (GPUs) compared to other growing self-organizing networks which have been already implemented on GPUs [27,28].In previous works [29,30], we proved, using the GNG algorithm, that self-organizing maps can handle corrupted data and noisy information, being able to interpolate missing data from the input space, thanks to their stochastic nature. This feature makes the NG model advantageous for working with noisy 3D data provided by low-cost RGB-D sensors.We propose the use of the neural gases to reconstruct objects from the point clouds obtained from multiple overlapping views. As a difference with other methods that may need several stages, including downsampling, noise filtering, surface triangulation, and many other tasks, the proposed NG-based algorithm automatically obtains the 3D model from the scanned objects. Moreover, overlapping scanned data may produce unsatisfactory results, as a simple connection of consecutive scan points would lead to wrong surfaces. The proposed algorithm therefore does not make any assumption about the topology of the data. It takes unorganized three-dimensional data points as input and generates a 3D mesh that represents the underlying surface.The main contributions of this paper are the following. An extension of the NG algorithm considering colour information and producing meshes with faces during the learning stage. An accelerated implementation on the GPU, considerably accelerating the original algorithm compared to the CPU version. A fully integrated framework to perform 3D object reconstruction using low-cost RGB-D sensors, and finally an extensive study of the proposed method, comparing the obtained results with those achieved by related methods under different noise conditions. The remainder of this paper is organized as follows. Section 2 reviews the most used methods for 3D surface reconstruction. Section 3 presents the proposed NG-based algorithm and proves its capability to reconstruct 3D models. Section 4 presents an accelerated implementation of the NG algorithm on Graphics Processing Units using CUDA. Next, Section 5 presents several experiments, showing qualitative and quantitative results of the proposed method compared to related works. Finally, in Section 6, the conclusions of the work and further directions of the research are presented.This section will review the most used methods and techniques for the reconstruction of three dimensional surfaces.Reconstruction with Delaunay methods in three dimensions consists of the extraction of tetrahedron surfaces from the initial point cloud. The concept of alpha-shape formalizes the intuitive notion of “shape” for a set of points in the space. One of the earliest approaches is based on α-shapes [31]. Given a finite point set S, and the real parameter α, the alpha-shape of S is a polytope (the generalization to any dimension of a two-dimensional polygon and a three-dimensional polyhedron) which is neither convex nor necessarily connected. For a large α value, the α-shape is identical to the convex-hull of S. If the alpha value decreases progressively, non-convex shapes with cavities are obtained.The algorithm proposed by Edelsbrunner and M”ucke [31] eliminates all tetrahedrons which are delimited by a surrounding sphere smaller than α. The surface is then obtained with the external triangles from the resulting tetrahedron. Another approach is based on labelling the initial tetrahedrons as interior and exterior. The resulting surface is generated from the triangles found in and out. This idea first appeared in [32] and was later performed by Powercrust in [33] and the algorithm called Tight Cocone [34]. Both methods have been recently extended for reconstructing noisy point clouds [34,35].The main advantage of most Delaunay based methods is that they fit very accurately the surface defined by the original point cloud. However, these methods are very sensitive to noise since they are interpolation based methods that produce undesirable results with noisy data. Therefore, the quality of the points obtained in the digitization process determines the feasibility of these methods. Due to the use of the whole point cloud set to obtain the most accurate triangulation, considering the Delaunay rule, the digitized points on the surface with an error considered above the limit, will be explicitly represented on the reconstructed surface geometry.Implicit reconstruction methods (or zero-set methods) reconstruct the surface using a distance function which assigns to each point in the space a signed distance to the surface S. The polygonal representation of the object is obtained by extracting a zero-set using a contour algorithm. Thus, the problem of reconstructing a surface from a disorganized point cloud is reduced to the definition of the appropriate function f with a zero value for the sampled points and different to zero value for the rest. In [36] was established the use of such methods with the algorithm called Marching-Cubes. This algorithm has evolved in different variants, Hoppe et al. [2] used a discrete function f, in [6] a polyharmonic radial basis function is applied to adjust the initial point set. Other approaches include the adjustment function Moving Least Squares [37,38] and basic functions with local support [39], based on the Poisson equation [7].Those methods have the problem of loss of the geometry precision in areas with extreme curvature, i.e., corners and edges. Furthermore, information preprocessing by applying some kind of filtering technique also affects the definition of the corners. There are several studies related to post-processing techniques used for the detection and refinement of corners [38,40] but these methods increase the complexity of the solution.The Voxel Grid filtering technique is based on the input space sampling using a grid of 3D voxels to reduce the number of points. This technique has been traditionally used in the area of computer graphics to subdivide the input space and reduce the number of points [41,42].For each voxel, a centroid is chosen as the representative of all points. There are two approaches: (1) the voxel centroid is selected as the representative and (2) the centroid is calculated by using the points lying within the voxel (mean point). The calculation of the mean point has a higher computational cost, but offers better results. Thus, a subset of the input space is obtained that roughly represents the underlying surface. The Voxel Grid method presents the same problems as other filtering techniques: impossibility of defining the final number of points that represent the surface, geometric information loss due to the reduction of points within a voxel, and sensitivity to noisy input spaces. This method will be compared with our NG based 3D reconstruction method, as it offers similar features for efficient mesh downsampling.Considering the 3D representation problem from a computational intelligence point of view and based on self-organizing maps, a different perspective to obtain 3D reconstructions is proposed. These methods could be considered as flexible and growing models since the selected map has a priori topology or otherwise it grows until a condition is fulfilled. Moreover, we can find some similarities or correspondences between the neural network map and the obtained 3D representation. The nodes of the neural network map correspond to vertices of a mesh and the connections between nodes represent the edges. Therefore, in these methods, the terms node and vertex, and connection and edge are used interchangeably. From this perspective, some methods were proposed based on self-organizing maps.In [43], it is proposed the use of Kohonen's self-organizing map for surface reconstruction using unorganized point clouds as input data. Moreover, since SOMs do not produce regular faces, an edge collapse operation was introduced to remove dangling faces. This approach presents some drawbacks. The SOM learning algorithm has some difficulties to properly approximate the mesh if the real object surface exhibits concave structures. In addition, the Kohonen SOM has a high computational cost, a single thread CPU implementation presented in this work took more than one hour to represent the Stanford bunny model. The presented method was only tested with synthetic data and the bunny model, which is comprised of 34, 834 points. Junior et al. [44], extended [43] introducing new mesh operators that allowed it to perform improvements on the surface geometry: edge swap, edge collapse, vertex split and triangle subdivision. Moreover, the method introduced a new step to remove unstable vertices using the mean distance and the standard deviation of the 3D representation regarding the sampled input space. Although this new approach improved the surface geometry, the method does not deal with concave or non-convex regions and the initial structure of the representation has to be predefined considering the topology of the input space. The fixed structure of the SOM does not learn the spatial relationships between the vertices and therefore does not generate a model that accurately represents the shape of the input space.In [45] the Growing Cell Structures (GCS) [15] algorithm is used to reconstruct object surfaces. Mesh operators are used to change the connectivity of the mesh. Therefore, the final topology is always equivalent to the initial mesh.The Topology Representing Networks (TRN), proposed by Martinetz and Schulten [14], do not have a fixed structure and do not impose any constraint to the connections between the nodes. In contrast, this network has a predefined number of nodes, so it is not able to generate models with different resolutions. The algorithm was also coined with the term neural gas (NG) due to the dynamics of the feature vectors during the adaptation process, which distribute themselves like a gas within the data space. Barhak [46] proposed a NG-based surface reconstruction algorithm since this network has the ability to accurately represent the topology of a point cloud.In [22], the GNG network is employed to model a point cloud and those regions that need further sampling in order to obtain a more accurate model. Rescanning at higher resolution is performed for each identified region of interest and a multi-resolution model is built. In this work, only nodes of the generated map are used as it is focused on sampling capabilities of the GNG. MGNG [23] applied some postprocessing steps in order to perform surface reconstruction once the map is generated using the original GNG algorithm. Most of these approaches were tested against CAD models or synthetic data and only few experiments were performed on objects acquired with 3D sensors. In [47], the GNG algorithm was modified in order to produce topological faces. The extended method was called Growing Self-Reconstruction Maps (GSRM) and some learning steps as the CHL rule and the operation of vertex insertion and removal were also modified. Most experiments of this work were performed on the Stanford dataset, which had been previously filtered so that the surface reconstruction step does not have to deal with noisy input spaces produced by common 3D sensors. In [47,46] the Competitive Hebbian Learning was extended considering the creation of 2-manifold meshes and face reconstruction. However, it was also required to apply some post-processing steps to create a complete model.Although the use of the SOM-based techniques as NG, GCS or GNG for 3D input space representation and surface reconstruction has already been studied and successful results have been reported, there are some limitations that still persist. Most of these works assumed noise-free point clouds. Therefore, applying these methods on challenging real-world data obtained using noisy 3D sensors has not been object of study yet. Moreover, with the advent of low cost RGB-D cameras as the Microsoft Kinect11Kinect for XBox 360: http://www.xbox.com/kinect Microsoft.partial point clouds have to be considered. Besides providing 3D information, these devices also provide colour information, feature that was not considered in the revised works.As the original NG algorithm does not produce faces and the generated map is a wire-frame representation model, we propose an extension of the original algorithm to produce full coloured meshes (faces). In addition, the proposed method will be tested using noisy data obtained from low-cost RGB-D sensors.One way of selecting points of interest in 3D point clouds is to use a topographic mapping where a low dimensional map is fitted to the high dimensional manifold of the shape, whilst preserving the topographic structure of the data. A common way to achieve this is by using self-organizing neural networks where input patterns are projected onto a network of neural units such that similar patterns are projected onto units adjacent in the network and vice versa. As a result of this mapping a representation of the input patterns is achieved [48].Neural gas is an unsupervised soft competitive clustering algorithm that given some input distribution inℝd, creates a graph, or network of nodes, where each node in the graph has a position inℝd. The model can be used for vector quantization by finding the code-vectors in clusters. These code-vectors are represented by the reference vectors (the position) of the nodes. It can also be used for finding topological structures that closely reflect the structure of the input distribution. Neural Gas learning is a dynamic algorithm in the sense that if the input distribution slightly changes over time, it is able to adapt the neural network structure, moving the nodes to the new input space.Neural Gas uses a Competitive Hebbian Learning (CHL) rule. CHL assumes a number of centers (neurons) in Rnand successively inserts topological connections among them by randomly evaluating input signals from a data distribution, in this case the three-dimensional space. This scheme is combined with the neural gas algorithm, allowing the neurons movement based on a decaying scheme. For each input signal ξ adapt the k-nearest centers (neurons) whereby k is decreasing from a large initial to a small final value. This step allows the adaptation of the neurons to the input manifold.The network is specified as:A set A of nodes (neurons). Each neuron c∈A has its associated reference vectorwc∈ℝd. The reference vectors can be regarded as positions in the input space of their corresponding neurons.A set of edges (connections) between pairs of neurons. These connections are not weighted, and its purpose is to define the topological structure. An edge aging scheme is used to remove connections that are invalid due to the motion of neurons during the adaptation process.Neural gas uses parameters that decay exponentially according to time and the distance to the input pattern.The neural gas with CHL algorithm is the following:1Initialize the set A to contain N units ci(1)A={c1,c2,…,cN}With reference vectorsWci∈ℝdchosen randomly according to p(ξ).Initialize the connection set C, C⊂A×A, to the empty set:(2)C=∅Initialize the time parameter t(3)t=0Generate at random an input signal ξ according to p(ξ).Order all elements of A according to their distance to ξ, i.e., find the sequence of indices (i0, i1, …, iN−1) such thatwi0is the reference vector closest to ξ,wi1, is the reference vector second-closest to ξ andwik, k=0, …, N−1 is the reference vector such that k vectorswjexists with||ξ−wj||≤||ξ−wk||. We denote with ki(ξ, A) the number k associated withwi.Adapt the reference vectors according to(4)▵wi=ϵ(t)·hλ(ki(ξ,A))·(ξ−wi)With the following time-dependencies(5)λ(t)=λi(λf/λi)t/tmax(6)ϵ(t)=ϵi(ϵf/ϵi)t/tmax(7)hλ(k)=exp(−k/λ(t))If it does not exist already, create a connection between i0 and i1:(8)C=C∪{(i0,i1)}Set the age of the connection between i0 and i1 to zero (“refresh” the edge):(9)age(i0,i1)=0Increment the age of all edges emanating from i0(10)age(i0,i)=age(i0,i)+1∀i∈Ni0Thereby, Ncis the set of direct topological neighbours of c.Remove edges with an age larger than the maximal age T(t) whereby(11)T(t)=Ti(Tf/Ti)t/tmaxIncrease the time parameter t:(12)t=t+1If t≤tmaxcontinue with step 2In summary, the learning step of the NG is based on the Euclidean distance between the input space (3D points) and the neurons structure. Every iteration, neurons are sorted by their Euclidean distance to the input pattern that has been randomly selected (activated). Neurons are moved towards the selected input pattern during this step using a decaying function based on the previously calculated Euclidean distance and a time function (iteration). Thanks to this learning step, the neural map is adapted to the topology of the input data. The learning step is defined as a single iteration over the steps detailed above.Furthermore, the proposed NG method was modified compared to the original version, considering also original point cloud colour information. Once the NG network has been adapted to the input space and it has finished the learning step, each neuron of the network takes colour information from nearest neighbours in the original input space. Colour information of each neuron is calculated as the average of weighted values of the k-nearest neighbours, obtaining an interpolated value of the surrounding point. Colour values are weighted using Euclidean distance from the input pattern to its closest neuron reference vector. In addition, this search is considerably accelerated using a Kd-tree structure [49]. Colour downsampling is performed in order to transfer colour information from points to mesh triangles.The final result of the self-organizing or competitive learning process is closely related to the concept of Delaunay triangulation. The Voronoi region of a neuron consists of all the points of the input space for which this is the winning neuron. Therefore, as a result of CHL a graph (neural network structure) whose vertices are the neurons of the network and whose edges are connections between them is obtained. This graph represents the Delaunay triangulation of the input space corresponding to the reference vectors of neurons in the network.Traditionally, it has been suggested that this triangulation, result of competitive learning, preserves the topology of the input space. However, Martinetz and Schulten [14] introduces a new condition which restricts this feature.It is proposed thatΦwof V in A preserves the neighbourhood when vectors that are close in the input space V are mapped to nearby neurons from network A. It is also noted that the inverse mapping preserves the neighbourhood if nearby neurons of A have associated feature vectors which are close in the input space.(13)Φw−1:A→V,c∈A→wc∈VCombining the two definitions, the Topology Preserving Network (TPN) can be defined as the network A whose mappingsΦwandΦw−1preserve the neighbourhood.Thus, self-organizing maps or Kohonen maps are not TPN as they have traditionally been considered, since this condition only would happen in the event that the topology or dimension of the map and the input space coincide. Since the network topology is established a priori, possibly ignoring the topology of the input space, it is not possible to ensure that the mappingsΦwandΦw−1preserve the neighbourhood.The Growing Cell Structures [15] are not TPN since the topology of the network is established a priori (triangles, tetrahedra, …). However, they improve the performance in comparison with Kohonen maps [13], due to their capabilities of insertion and removal of neurons.In the case of the neural gases like growing neural gas and neural gas, the mechanism for adjusting the network through a competitive learning induces a Delaunay triangulation, generating a graph obtained from the triangulation which has only edges of the Delaunay triangulation of points which belong to the input space V. Martinetz and Schulten [14] proved that these models are TPN.This capability can be used, for instance, in the application of these models to the representation of objects in different dimensions.In a previous comparative study [25] with Kohonen Maps, Growing Cell Structures and Neural Gas, it was proved that Kohonen Maps and Growing Cell Structures are not topology preserving neural networks. Only NG and GNG are topology preserving networks.The adaptation of the self-organizing neural networks is often measured in terms of two parameters: (1) resolution and)2) degree of preservation of the topology of the input space.The most widely used measure of resolution is the quantization error [13], which is expressed as:(14)E=∑∀ξ∈ℝd‖wsξ−ξ‖·p(ξ)where sξis the closest neuron to the input pattern ξ.However, as NG is used to reconstruct a model from an unorganized noisy point cloud in a reverse-engineering application, it is needed to know the real distance from the generated structure to the input data of the reconstructed model. This measure specifies how close our reconstructed surface is from the original model, removing noisy data generated by 3D sensors and the alignment process. Therefore, calculating the mean square error (MSE) between the filtered point cloud and the input data shows the NG input space adaptation and noise removal capabilities. In order to obtain a quantitative measure of the input space adaptation of the generated map, we computed the mean square error (MSE) of the map against sampled points (input space):(15)MSE1=1|V|∑∀p∈Vmini∈Ad(p−wi)2where V is the input space, p is a sample that belongs to the input space, i is the neuron with the minimum distance to the input space sample andwiis the neuron's weight.d(p−wi)2is the squared Euclidean distance between the closest neuron and the input point p. This measure is computed once the network topology learning step is completed.Moreover, we computed the mean squared error considering distances from the neurons that conform the map to the input space, considering both directions and therefore having a more accurate metric of the input space adaptation.(16)MSE2=1|A|∑∀c∈Amini∈Vd(c−wi)2where A is the generated self-organizing map, c is a neuron that belongs to the map, i is sample of the input space with minimum distance to the selected neuron andwiis the sample weight vector.d(c−wi)2is the squared Euclidean distance between the closest input point and the neuron c. This measure is also computed once the network topology learning step is completed.Combining mean squared distances in both directions we obtain a useful measure of the map adaptation to the input space. For the experiments in Section 5 we will consider the MSE as the product of MSE1 and MSE2.3D reconstruction can be considered as a cluster-seeking problem in which the goal is finding a finite number of points that describe the surface precisely. A representation structure (graph) is automatically created by minimizing the error of the self-organizing map adaptation to the input space to be represented (point cloud).The ability of neural gases to preserve the topology of the input space will be evaluated in this work with the representation of 3D objects. Identifying the points of the input data that belong to objects allows the network to adapt its structure to this input subspace, obtaining an induced Delaunay triangulation of the object.Fig. 1shows various 3D models reconstructed using original NG method. Different number of neurons have been used since original models are represented with different number of points.As we can see in Fig. 1 and as we previously stated, the original NG algorithm only produces a wire-frame representation of the input data. In order to create a complete mesh, we extended the original algorithm considering the face creation step during the learning process. Steps 5, 6 and 7 of the original algorithm introduced before were modified considering face creation.Below we can find the modified steps for considering face creation during the learning process of the NG algorithm5.If it does not exist already, create a connection between i0 and i1:(17)C=C∪{(i0,i1)}5.1.if i0 and i1 have two common neighbours n0 and n15.1.1.if n0 and n1 are already connected thenRemove edge between n0 and n1(18)C=C−{(n0,n1)}Coincident faces to the vertices n0,n1 are removed(19)F=F−{incidentFaces(n0,n1)}Create two faces using n0, n1, i0 and i1(20)F=F∪{(n0,i0,i1),(n1,i0,i1)}if n0 and n1 are not connectedCreate two faces using n0, n1, i0 and i1(21)F=F∪{(n0,i0,i1),(n1,i0,i1)}if i0 and i1 have one common neighbour n0Create one face using n0, i0 and i1(22)F=F∪{(n0,i0,i1)}If a connection between i0 and i1 already exists:Set the age of the connection between i0 and i1 to zero (”refresh” the edge):(23)age(i0,i1)=06.1.if i0 and i1 have common neighbours Nn=n0, n1, n2, …, niFor each common neighbour nicreate a face f using ni, i0, i1.(24)F=F∪{(ni,i0,i1)}if i0 and i1 have zero common neighbours6.2.1.if there are two neighbours n0 and n1 of i1 and i2 respectively that are connected but are not common to i1 and i2 thenTriangulate hole: create two faces.Create two faces using n0, n1, i0 and i1(25)F=F∪{(i0,i1,n0),(i1,n0,n1)}if there are two neighbours n0 and n1 of i1 and i2 respectively that are not connected between them and are not common to i1 and i2 and also have a common neighbour n2 thenTriangulate hole: create three faces.Create three faces using n0, n1, n2, i0 and i1(26)F=F∪{(i0,i1,n2),(i1,n1,n2),(i1,n0,n2)}Finally, we also extended step 7 removing those faces incident to the edges with an age larger than the maximum age T(t) that is defined in the original algorithm (step 7).Thanks to these new changes, the proposed version of the NG algorithm is able to create a mesh instead of a wire-frame representation. Fig. 2shows different 3D models reconstructed using the proposed NG extension for 3D surface reconstruction.Since the NG learning algorithm has a high computational cost, we propose a method to accelerate it using GPUs and taking advantage of the many-core architecture provided by these devices, as well as their parallelism at the instruction level. GPUs are specialized hardware for computationally intensive high level parallelism that uses a large number of transistors to process data and less for flow control or management of the cache, unlike CPUs. We have used the architecture and the programming tools (language, compiler, development environment, debugger, and libraries) provided by NVIDIA to exploit their hardware parallelism.A CUDA compatible GPU is structured as a set of multiprocessors [50]. These multiprocessors, also called Streaming Multiprocessors (SMs), are highly parallel at thread level. Each SM consists of a series of Streaming Processors (SPs) that share the control logic and cache memory. Each of these SPs can be launched in parallel with a huge amount of threads. CUDA architecture reflects a SIMT model: Single Instruction, Multiple Threads. These threads are executed simultaneously working on large data in parallel. Each of them runs a copy of the kernel on the GPU and uses local indexes to be identified. Threads are grouped into blocks to be executed. The number of blocks that are executed depends on the resources available on the multiprocessor, scheduled by a system of priority queues. CUDA architecture also has a memory hierarchy. Different types of memory can be found: constant, texture, global, shared and local registers. In the last few years, a large number of applications have used GPUs to speed up the processing of neural network algorithms [51–56], face representation and tracking [57] or pose estimation [52].In order to identify algorithm steps with a larger computational complexity, a profiling analysis was performed. Steps 3, 4 and 7, corresponding to Euclidean distance calculations, distance sorting, weight updates, and edge removals, were identified as the ones with the larger computational cost. In addition, many of these operations performed in the NG algorithm can be parallelized because they act on all the neurons of the network simultaneously. That is possible because there is no direct dependence between neurons at the operational level. However, there exists dependence in the adjustment of the network, which makes necessary the synchronization after each iteration t.The first stage of the algorithm that was accelerated is the calculation of Euclidean distances. This stage calculates the Euclidean distance between a random pattern and each one of the neurons. This task takes place in parallel by running the calculation of each neuron distance on a separate thread, using as many threads as neurons the network contains. It is possible to calculate more than one distance per thread. This approach increases the level of parallelism as the number of neurons is increased, obtaining a greater speed-up for a large number of neurons.The second parallelized task was the neuron sorting step, corresponding to step 3 of the NG method. For this task, we used a parallel sorting technique implemented in the Thrust library [58]. Thrust dispatches a highly-tuned Radix Sort algorithm [59] which is considerably faster than alternative comparison-based sorting algorithms such as Merge Sort [60].Once neurons have been sorted, weights update step is computed in parallel, launching as many threads as neurons comprise the network. Before continuing with the next possible parallelizable step, the NG learning algorithm establishes that an edge between the first and second winner neurons has to be created (step 5). Moreover, all edges emanating from the winner neuron increment their age (step 6). Steps 5 and 6 are not possible to implement in parallel since they only influence two neurons and their computational cost is really low. Therefore, in order to avoid data communication between CPU and GPU, steps 5 and 6 are performed sequentially on the GPU, launching one GPU thread that performs edge creation and age increment. Finally, step 7, which corresponds to edge age checking, is performed in parallel. By parallelizing the algorithm in this way, all the communication between CPU memory and GPU memory is limited and therefore the main computational bottleneck is avoided.

@&#CONCLUSIONS@&#
In this paper, we have proposed the use of the Neural Gas model to reconstruct objects from the point cloud obtained from multiple overlapping views using low-cost sensors. The main feature of the NG model is that it automatically obtains the 3D model of the scanned objects, in comparison with other methods that may need several stages that include downsampling, noise filtering and many other tasks.To demonstrate the validity of our proposal we tested our method with several models and performed a study of network parameterization by calculating the quality of representation and also comparing results with other neural methods like GNG and Kohonen maps and also traditional ones like Voxel Grid. We also reconstructed models acquired with low cost sensors that can be included in virtual and augmented reality environments for redesign or manipulation purposes.In order to accelerate the NG algorithm we have redesigned and implemented the NG learning algorithm to fit it onto Graphics Processing Units using CUDA and obtaining, in the best case scenario, a speed-up of 180x relative to the CPU version.As a further work we plan to use different sensors to acquire models and accelerate the whole process on GPUs.