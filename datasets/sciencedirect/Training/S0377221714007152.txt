@&#MAIN-TITLE@&#
An Akaike information criterion for multiple event mixture cure models

@&#HIGHLIGHTS@&#
The variable selection method AIC is derived for credit risk studies.Single and multiple event mixture cure survival models are fit with EM algorithms.Different covariates are allowed to be selected in different model parts.The method is implemented in the software R.

@&#KEYPHRASES@&#
Akaike information criterion,Competing risks,EM-algorithm,Mixture cure model,Model selection,

@&#ABSTRACT@&#
We derive the proper form of the Akaike information criterion for variable selection for mixture cure models, which are often fit via the expectation–maximization algorithm. Separate covariate sets may be used in the mixture components. The selection criteria are applicable to survival models for right-censored data with multiple competing risks and allow for the presence of a non-susceptible group. The method is illustrated on credit loan data, with pre-payment and default as events and maturity as the non-susceptible case and is used in a simulation study.

@&#INTRODUCTION@&#
The topic of credit risk modeling has now become more important than ever before. The introduction of compliance guidelines such as Basel II and Basel III has a huge impact on the strategies of financial institutions nowadays. The Basel Accords aim at quantifying the minimum amount of buffer capital so as to provide a safety cushion against unexpected losses (Van Gestel and Baesens, 2008). A key credit risk parameter is the probability of default (PD) measuring the likelihood of an obligor to run into arrears on his/her credit obligation.PD models are typically constructed using classification techniques such as logistic regression (Baesens et al., 2003). However, the timing when customers default is perhaps of even more interest to analyze since it can provide the bank with the ability to compute the profitability over a customer’s lifetime and perform profit scoring. The problem statement of analysing when customers default is commonly referred to as survival analysis (see, e.g., Bellotti and Crook, 2009). It is the purpose of this paper to provide a valid model selection criterion for variable selection inside such survival models, specifically applied to credit risk modeling, with as particular characteristics allowing for defaults, maturity and early repayments in a mixture cure rate model and allowing for right-censored data.In this paper we deal with right-censored failure times in a mixture model context. This implies that there are two sources of incompleteness: (i) the right-censoring causes some of the event times to remain unobserved, it is only known that the event of interest did not yet take place, and (ii) not for all observations it is known to which component of the mixture model they belong; in fact, only when an observation is uncensored, we have this information. For this type of cure rate models no information criteria have yet been derived.For incomplete and partially observed data, Cavanaugh and Shumway (1998) derive a version of the Akaike information criterion (AIC; Akaike, 1973) that makes use of the expected complete data log-likelihood, rather than the observed log-likelihood. They coined the name AICcd to this criterion. The use of the likelihood for the observed cases is discouraged since a comparison of this ‘model’ likelihood to a ‘true’ likelihood for the observed cases only is rarely of interest. By working with the complete data log-likelihood, and considering the Kullback–Leibler (KL) distance between the model and true data generating process for the complete data, the AICcd is able to select models, taking unobserved and latent variables into account. The method uses directly the output of the expectation–maximization algorithm (EM). We explain its definition and use below. For a comprehensive explanation of the AIC, see Claeskens and Hjort (2008, Chap. 2).Similar variations on the AIC are studied by Claeskens and Consentino (2008), who use the output of an EM algorithm to define variable selection methods for models with missing covariate data in a linear regression setting and by Ibrahim et al. (2008) for missing data variable selection in generalized linear models.For the case of right-censored data (not in a mixture), Liang and Zou (2008) work with an accelerated life time model and propose for that model a finite sample correction to the standard AIC, motivated from an exponential model with constant censoring. For parametric survival models Suzukawa et al. (2001) derive a version of the AIC taking the censoring into account, though require a non-standard estimation method for practical use. Fan and Li (2002) used a smoothly clipped absolute deviation penalty for the semiparametric Cox proportional hazard models, Hjort and Claeskens (2006) derived a focused information criterion, while Xu et al. (2009) define an AIC based on the profile likelihood for proportional hazard mixed models, see also Donohue et al. (2011) for a related model selection approach. None of these papers made use of the EM algorithm to define the variable selection criterion, and neither did they consider mixture models.In Section 2 we first consider the Akaike information criterion for the case of a mixture cure model with one event of interest and a group non-susceptible to this event. In Section 3 we extend the applicability of the AIC to the model recently proposed by Watkins et al. (2014) that provides a simultaneous modeling of multiple event times, potentially right censored, in the presence of a non-susceptible group. While parametric survival models can be used as in the approach of Watkins et al. (2014), in this paper we use the semiparametric Cox proportional hazard model for the susceptible part(s) of the mixture model and we use logistic regression for the incidence part. Simulation results are given in Section 4 and an application to credit loan data is presented in Section 5.Mixture cure models were motivated by the existence of a subgroup of long-term survivors, or ‘immunes’ in a medical context. This subgroup, with survival probabilities set equal to one, is incorporated in a model through a mixture distribution where a logistic regression model provides a mixing proportion of the ‘non-susceptible’ cases and where a survival model describes the cases susceptible to the event of interest. Such models were introduced by Farewell (1982) in a parametric version, and later generalized to a semi-parametric mixture model combining logistic regression and Cox proportional hazards regression by Kuk and Chen (1992), see also Sy and Taylor (2000). Recently, Cai et al. (2012) introduced the R-package smcure to estimate such semi-parametric mixture models.Tong et al. (2012) use a mixture cure approach to analyze the credit risk of a specific customer, where the event of interest is the time of default when customers stop paying back their loans. This setting is characterized and distinguishes itself from typical medical settings by a heavy right-censoring, since most customers do not default. A relatively large group of non-susceptible cases is expected to be present. Part of the explanation of this high percentage of censoring is that both prepayments and maturity (loan completely paid back on time) are considered censored for default. For a separate analysis of default and prepayment, see, e.g., Stepanova and Thomas (2002).We denote the ‘true’ event time by U and the censoring time by C. We assume independence between event times and censoring times. Denote by Y a binary random variable where Y = 1 expresses susceptibility to the event of interest and Y = 0 indicates that the event will never happen. When U > C, the event is right-censored; the observed event time T = min (U, C). Let the indicator δ = I(U ≤ C), thus δ = 1 indicates non-censored observations. The combination of values for Y and δ generates three different states:(1)Y = 1 and δ = 1: uncensored and susceptible, so the event takes place during the observation period of the data;Y = 1 and δ = 0: censored and susceptible, no event during the observation period, but it will eventually take place;Y = 0 and δ = 0: censored and non-susceptible, no event is observed, nor will it take place in the future.Note that values for T and δ are fully observed while Y is only observed when δ = 1 and is latent otherwise. Similarly, we do not observe U when δ = 0. The sample information consists of values (Ti, δi), for i = 1, …, n, together with some covariate information.The incidence model component uses logistic regression to model P(Y = 1) = π(z;b) with logit{π(z;b)} =z′bfor a r-vector of covariatesz= (z1, …, zr)′. For the latency model, a semiparametric Cox proportional hazard regression model is used such that the conditional survival probability at time t is modeled asS(t∣Y=1,x;β)=exp(−exp(x′β)∫0th0(u∣Y=1)du),with h0 the unspecified baseline hazard function andxa q-vector of covariatesx= (x1, …, xq)′, which may or may not contain the same components asz. This yields the unconditional survival function(1)S(t,x,z;β,b)=π(z;b)S(t∣Y=1,x;β)+1−π(z;b),and the observed likelihood(2)Lobs(b,β)=∏i=1n{π(zi;b)f(ti∣Yi=1,xi)}δi×{(1−π(zi;b))+π(zi;b)S(ti∣Yi=1,xi;β)}1−δi.The complete likelihood, given full information on Y, can be expressed as:Lcomplete(b,β)=(1−π(zi;b))(1−Yi)(zi;b)Yi×h(ti∣Yi=1,xi;β)δi,YiS(ti∣Yi=1,xi;β)Yi.For estimation of mixture cure models, Cai et al. (2012) explain the use of the EM algorithm to deal with the latent Y values. If Y = Y* would be observed for all cases, the log-likelihood for the data triplets (Ti, δi, Yi) could be used in the AIC to lead to the (infeasible)(3)AICinfeasible=−2logLT,δ,Y(Θ^;Ti,δi,Yi*)+2d,where d counts the number of parameters in the model, andΘ^is the maximum likelihood estimator of the parameter vectorΘ.The AIC estimates the expected value of the Kullback–Leibler discrepancy between the model and the unknown true data-generating process, without having to know this true process. In the general case with random variablesR= (R1, …, Rn), a model f(r;Θ) and the density of the true data-generating process g(r), the KL discrepancy is given byKL{g,f(·;Θ)}=Eg{logg(R)f(R;Θ)},where the subscript g reminds of using the true density function g to compute the expectation. Since Eg[log g(R)] does not vary when searching through several candidate models, minimizing KL{g, f( · ;Θ)} over different models is equivalent with minimizing the quantity DR(Θ) = Eg{ − 2log f(R;Θ)}, where the expectation is computed using the true density function of the data. In our notationR= (T, δ, Y), which can be split in an observed vectorRobs = (T, δ) and a “missing” partRmis = Y indicating that Y is not always observed.By rewriting the true joint density of the vectorRas g(r) = gY|T, δ(y|t, δ) · gT, δ(t, δ), it follows that DR(Θ) = E[T, δ][ − 2Q*(Θ)], with the expected complete data log-likelihood Q*(Θ) = E[log fT, δ, Y(T, δ, Y;Θ)|T, δ]. The AIC procedure estimatesE[DR(Θ^)]using the sample information.DefineΘ0 as the least false parameter value that minimizes the KL discrepancy between the model density f( · ;Θ) and the true density g,Θ0=argminΘKL{g,f(·;Θ)}. As used in the EM algorithm, for two values,Θ1 andΘ2 of the parameter vectorΘ= (b, β) the expected complete-data log likelihood applied to our problem can be estimated by, see also Cai et al. (2012),(4)Q(Θ2∣Θ1)=∑i=1n∫logfT,δ,Y(Ti,δi,Y=y;Θ2)×fY|T,δ(y∣Ti,δi;Θ1)dywhere fT, δ, Ydenotes the joint density of the triplet (T, δ, Y) and where fY|T, δis the probability mass function of Y conditional on (T, δ). Denote the first partial derivativeQ˙(Θ2∣Θ1)=∂∂Θ2Q(Θ2∣Θ1)and the second partial derivativeQ¨(Θ2∣Θ1)=∂∂Θ2∂Θ2′Q(Θ2∣Θ1). The EM approach proceeds by maximizing Q(Θ2∣Θ1) overΘ2, and by replacing the currentΘ1 by the maximizer. These steps are iterated until convergence. The resulting value ofΘis denoted byΘ^.In the context of missing data, Claeskens and Consentino (2008) prove in their Theorem 1 that for a model density f that is two times continuously differentiable with respect toΘ, and which has a bounded expectation of the second derivative in a neighborhood ofΘ0, which belongs to the interior of a compact parameter space, ifn(Θ^−Θ0)′(Θ^−Θ0)is uniformly integrable, with the prime denoting a transpose, thenE[DR(Θ^)−Q(Θ^|Θ^)]/n=trace{I−1(Θ0)·J(Θ0)}/n+o(1/n),whereI(Θ)=E{−Q¨(Θ∣Θ)/n},andJ(Θ)=Var{Q˙(Θ∣Θ)}/n.Following Cavanaugh and Shumway (1998), by first taking a Taylor series expansion ofQ˙(Θ0∣Θ^)aroundΘ^,leads to estimateJ(Θ0) byI(Θ^)Io−1(Θ^)I(Θ^),and further to estimateI(Θ0) byIoc(Θ^),whereIoc(Θ^)=−n−1∂2Q(Θ^∣Θ^)∂Θ·∂Θ′,Io(Θ^)=−n−1∑i=1n∂2logfT,δ(Ti,δi;Θ^)∂Θ·∂Θ′.This leads us to define the complete data AIC by(5)AICcd=−2Q(Θ^∣Θ^)+2trace{Ioc(Θ^)·Io−1(Θ^)},Note that this derivation has relaxed the strong assumption of Cavanaugh and Shumway (1998) to have the model correctly specified, that is, they assumed that g(r) = f(r;Θ0). By working with least false parameter values, we avoided this strong assumption.The computation ofIo,which requires the joint density of (T, δ), not including Y, is facilitated by the use of the supplemented EM-algorithm (Meng and Rubin, 1991). The EM-algorithm implicitly defines a mappingΘ→M(Θ) = (M1(Θ), …, Md(Θ))′ from the parameter space to itself such thatΘ^(m+1)=M(Θ^(m))for m = 0, 1, …. A Taylor series expansion in the neighborhood ofΘ^yields that(Θ^(m+1)−Θ^)′≈(Θ^(m)−Θ^)′DM,whereDM=(∂Mj(Θ)∂Θi)|Θ=Θ^,a d × d-matrix evaluated atΘ=Θ^. Meng and Rubin (1991) further show thatIo−1=Ioc−1(Id−DM)−1,withIda d × d identity matrix. For more details on the computation ofDM, we refer to Chap. 12 of Gelman et al. (2004) and Section 3.3 of Meng and Rubin (1991). Using (5), this leads to the AICcd as we use it in this paper,(6)AICcd=−2Q(Θ^∣Θ^)+2trace(Id−DM)−1=−2Q(Θ^∣Θ^)+2d+2trace{DM(Id−DM)−1}.This criterion differs in two aspects from the infeasible AIC in (3). First, the expected complete data likelihood is used, and second, there is a correction to the penalty term that takes the complexity of the modeling process due to the missing information into account. When all data are observed,DM= 0 and the penalty reduces to the classical one.We wish to mention that the mixture regression criterion of Naik et al. (2007) as an extension of the AIC to select both the number of components in the mixture and the variables within each component is not suitable for our purpose. Indeed, we know exactly the number of components in the mixture from the problem content, moreover even partial cluster membership is known. Only for censored observations the group membership is unknown. In addition, the mixture regression criterion assumes fully observed cases, while these data here are intrinsically censored.An alternative treatment of the censored observations is to treat the censored times as “missing” event times. The model that we wish to find should be well for describing the true event times U, and not only for the observed times T. Therefore, we start by writing the joint log likelihood of (T, U, Y) as, withΘ= (β, b),Ln(Θ;T,U,Y)=∑i=1n{logPYi(zi;b)+logf˜Yi(Ti,Ui;β)},wherePYi(zi)=π(zi;b)when Yi= 1 andPYi(zi)=1−π(zi;b)when Yi= 0. We definef˜Yi(ti;Θ)=f(ti∣Yi=1,β)δiS(ti∣Yi=1,β)(1−δi)when Yi= 1 and takef˜Yi(ti)=1when Yi= 0. The Q-function for use in the EM-algorithm and the AIC can here be defined as,Q(Θ2,Θ1)=∑i=1n(logπ(zi,b2)+Ef[log{f˜Yi(Ti∣Yi=1,Θ2)}∣Ti,Θ1])w1i(Θ1)+∑i=1n(log(1−π(zi,b2))+log{1})(1−w1i(Θ1)),where w1i(Θ1) = P(Yi= 1∣Ti= t;Θ1) and the expectation ‘Ef’ is here computed with respect the model density of T, given Y = 1 and using parameter valueΘ1. With Cithe censoring time for observation i, if Ti≤ Ci, the true event time is observed and Ui= Ti, while if Ti> Ci, the true event time Uiis not observed. Then we have thatEf[log{f˜Yi(Ti∣Yi=1;Θ2)}∣Ti,Θ1]=∑i=1nδilogfUi|Yi(Ti∣Yi=1,Θ2)+∑i=1n(1−δi)Ef[logfUi|Yi(Ui∣Yi=1,Θ2)∣Ti,Θ1].This leads to defining the function Q for use in an EM-algorithm in the following way,Q(Θ2∣Θ1)=∑i=1nlogπ(zi;b2)w1i(b1,β1)+∑i=1nlog(1−π(zi;b2))×{1−w1i(b1,β1)}+∑i=1nδilogf(Ti∣Yi=1,β2)w1i(b1,β1)+∑i=1n(1−δi)∫ci∞logf(ui∣Yi=1,β2)f(ui∣Yi=1,β1)duiP(Ti≥Ci∣Yi=1,β1)×w1i(b1,β1),withw1i(Θ)=P(Yi=1∣Ti=t;Θ)={π(zi,b)f(ti;β)π(zi,b)f(ti;β)+(1−π(zi,b))forδi=01forδi=1.Defining the AICcd proceeds as in Section 2.2 using this function Q. The resulting AICcd has a correct Kullback–Leibler interpretation for right-censored data from a mixture distribution. This way of incorporating the censoring provides (in models without mixture) an alternative to the AIC proposed by Suzukawa et al. (2001).We extend the parametric competing risk model of Watkins et al. (2014) by allowing for the semiparametric Cox proportional hazard model. In this model one distinguishes multiple events (e.g., default, prepayment) for which the time to event is important and considers another class of events (such as maturity) that happen at a fixed time. This class encompasses the group of ‘immunes’ in Section 2. Only those events for which neither event takes place, are considered censored. For the formulation of this model, three indicators are used:(1)Ym, indicating that the loan is considered to be mature, so repayed at the indicated end date of the loan;Yd, indicating that default takes place;Yp, indicating that early repayment takes place.Note that this set of (Ym, Yd, Yp) is exhaustive and mutually exclusive. However, when an observation is censored, it is not known which event type will occur. In analogy to Eqs. (1) and (2), the unconditional survival function can be written asS(t∣xp,xd,z)=πp(z)Sp(t∣Yp=1,xp)+πd(z)Sd(t∣Yd=1,xd)+(1−πp(z)−πd(z)),with Spand Sddenoting the survival functions for, respectively, prepayment and default. Using the subscript ‘1’ for default (d) and ‘2’ for prepayment (p), the corresponding observed likelihood is given byLobs(Θ)=∏i=1n{∑j=1212∏j=12(πj(zi;bj)fj(ti∣Yj,i=1,xj,i;βj))Yj,i×(1−∑j=12πj(zi;bj))Ym,i}δi{∑j=1212(1−∑j=12πj(zi;bj))+∑j=12πj(zi;bj)Sj(tj,i∣Yj,i=1,xj,i;βj)∑j=1212}1−δi,whereΘ= (bp,bd,βp,βd). Note the flexibility of this model; each model part may employ its own set of covariates, hence the vectorsxd,xpandzmay be different. We rewrite this model for use in an EM algorithm such that the AICcd of (6) may be applied for model selection. For this purpose, we start from the complete likelihood, hence the likelihood expression under the assumption that full information onY= (Ym, Yd, Yp) is presentLcomplete(Θ;δi,Yi,Ti)=∏i=1n{∏j=12(πj(zi;bj))Yj,i(1−∏j=12πj(zi;bj))Ym,i}×{∏j=12(hj(t∣Yj,i=1,xj,i;βj)δiSd(tj,i∣Yj,i=1,xj,i;βj))Yj,i}.Converting to the log  likelihood and computing the expected value this time using the model density with parameterΘ1 leads us to the Q-function as given in (4),Q(Θ2∣Θ1)=Ef[logLcomplete(Θ2;Ti,δi,Yi)∣Ti,δi,Θ1]=∑i=1n{∑j=12wjilog(πj(zi;bj))+wmilog(1−∑j=12πj(zi;bj))+∑j=12wjiδilog(hj(ti∣Yj=1,xj,i;βj))+wjilog(Sj(ti∣Yj=1,xj,i;βj))∑j=12}.Note that conditional expectations of Yj, i(j = 1, 2), Ef[Yj, i∣Ti, δi,Θ1], are computed here with respect to the model density using parameterΘ1 and are denoted by wjiwith wmi= 1 − w1i− w2iand for j = 1, 2,wji=wji(Θ)=P(Yj,i=1∣Ti=t;δi;Θ)={πj(zi,bj)Sj(ti;βj)∑k=12πk(zi;bk)Sk(ti;βk)+(1−∑k=12πk(zi;bk))forδi=01forYj,i=1andδi=10forYj,i=0andδi=1.All computations were performed in R, adapting the library smcure(Cai et al., 2012) to produce the AICcd values.Three different simulation settings were used. For each simulation setting, 100 simulation runs with n = 5000 observations and 5 variables were executed. The probability of being susceptible, that is (1 − π(z)) was generated using the relationshipπ(z)=exp(b′z)1+exp(b′z),with variables z1–z5 of which the distributions are stated in Table 1and with parametersbas in Table 2. True Y-values are consequently generated through a sample vector of 0 and 1 using these probabilities π(z). For the uncured part of the population, Weibull default times (shape parameter = 1, scale parameter = 0.5) were generated, using the same five variables (thusx=z) with the distributions and parameter valuesβas in Tables 1and 2. For the first two simulation settings, censoring times were uniformly distributed on the interval [0, 1]. For setting 3, censoring times were uniformly distributed on the interval [0, 20], in order to lower the amount of censoring compared to settings 1 and 2. Each time we performed an exhaustive model search, thus (25 − 1)2 = 961 AICcd’s were calculated for every simulation run.In the first simulation setting, the censoring percentage was 60 percent (hence, around 3000 observations were censored, δ = 0) and 80 percent of the observations were susceptible (Y = 1). For setting 2, we mimicked the situation of the data example (see Section 5), resulting in the uncensored percentage nearly equal to 10 percent, and the susceptible percentage of the observations equal to 20 percent. For setting 3 the censoring time interval was increased from [0,1] to [0,20], resulting in more observed defaults, and less censoring. Because of this, the real default time was observed for 70 percent of the observations, with 80 percent susceptible observations as in setting 1.For comparison purposes, four other versions of AIC were calculated:AICcs=−2logLCox(β^;x)+2dCox,AICcl=−2logLCox(β^;x)+2dCox,Log,AICls=−2logLLog(b^;z)+2dLog,AICll=−2logLLog(b^;z)+2dCox,Log.The first subscript of the AIC’s is either c or l, which stands for “Cox” or “Log” and indicates the likelihood of the survival or logistic part of the mixture only. The second subscript indicates whether a “short” (s) or “long” (l) penalty term was used. A short penalty term means that the parameters accounted for are only calculated by the model specified in the first subscript, and a long penalty term incorporates all the parameters. The penalty is defined to be twice the number of considered parameters.The reason for comparing the AICcd to those at first sight rather naive AIC-calculations, is because in practice, those AICs might by some researchers be in use instead of the corrected version with complete-data log likelihoods when analyzing mixture cure models. We want to investigate whether it is reasonable to use those AICs. We are not aware of other model selection criteria for mixture cure models.Table 3summarizes some model selection aspects of the AICs. The results of all simulation runs were averaged. Next to the type of AIC used, we list the ranking (among the 961 models) of the true model as simulated. The next four columns indicate the average number of variables that were lacking in the selected model ( − ) or were unnecessarily included in the selected model (+) for the log-component and the Cox-component respectively as compared to the “true” model. The last two columns are the joint averaged over- and underselection values.The simulated data were generated using three true variables for the log-model, and two variables for the Cox-model. The first line in Table 3 indicates the maximum value possible for each column of the table. A perfect selection would give a mean rank of 1 ( = the “true” model is always selected), and 0-values for all the other entries, indicating that all necessary variables are present in the model, and all the unnecessary variables are left out. AIC is known to be an efficient model selection method with regard to mean squared prediction error (Claeskens and Hjort, 2008, Chap. 4), though not to be consistent hence we do not expect to find small ranks for the true model here. Moreover, the chosen settings are quite demanding with large percentages of censored data (especially for settings 1 and 2), which are typical to credit risk studies, as opposed to medical studies where those percentages are usually much smaller.The simulation study indicates that for these settings the Cox part of the log-likelihood is dominant, both in magnitude and for model selection purposes. In Table 3, we see that AICcd outperforms the other criteria regarding the mean rank of the true model for all three settings. Overfitting proportions are favorable for the low-censored setting (setting 3), but quite high for settings 1 and 2. On the other hand, underfitting proportions are low for the AICcd compared to the other measures. This is an important result as underfitting (missing important predictors) is considered worse than overfitting. When looking at the change in result as the censoring percentage changes, it becomes clear that high percentages of censored cases on one hand (setting 2) and a big discrepancy between observed versus true defaults (setting 1) have a negative impact on the performance of any information criterion. This gives us a strong indication that it would be advisable to incorporate additional information (such as in the multiple event models) to reduce the number of censored cases.A comparison with the simpler criterion that just counts the number of parameters is for the chosen settings not behaving too badly, since it turns out that the correction term involvingDMtakes values in a bounded range, and is here not influencing the model order too much. Again, we stress that no other information criteria have yet been developed for these mixture models, which could have made the comparison more interesting. For comparisons of AICcd in regression models to other AIC-like versions we refer to Cavanaugh and Shumway (1998).The survival analysis techniques were applied to personal loan data from a major U.K. financial institution. All customers are U.K. borrowers who had applied to the bank for a loan. The data set consisted of the application information of 50,000 personal loans, together with the repayment status for each month of the observation period of 36 months. We note that the same data were also used in Stepanova and Thomas (2002) and later by Tong et al. (2012). In this paper only a subset of the loans with loan term 36 months were used for the analysis (containing n = 7521 observations).An account was considered as a default (censoring indicator = 1) if it was at least 90 days in arrears. When an account was not in arrears or only in arrears for less than 90 days, the account was considered as a non-default (censoring indicator = 0). As for most credit data, the percentage of defaults within the observation period was very low: default was only observed for 376 of the 7521 observations. In Section 5.3 we reconsider this dataset taking prepayments and maturity into account, hereby reducing the number of censored cases.For each observation, we considered eight candidate covariates, see Table 4. In the model selection approach of Section 5.2, we searched through all subsets of the collection of eight covariates, and this for both model components, resulting in (28 − 1)2  =  65,025 AICcd values, where we have excluded empty latency and incidence models. Using the same method of exhaustive search for the modeling approach in Section 5.3 would result in over 16,581,375 AICcd calculations ((28 − 1)3), because this time three different covariate vectors are considered. Therefore, instead of an exhaustive search, a genetic algorithm was used to find a good model, for which we used the package GA in R (Scrucca, 2013). We used this package with AICcd in the binary representation indicating the presence (1) or absence (0) of a specific variable, and with all default settings, i.e., population size 50, crossover probability 0.8, mutation probability 0.1. For the model selection purpose, this algorithm starts with randomly including and excluding some variables. The algorithm consists of several “generations”, and at the end of each generation, the AICcd-values of the inspected models are evaluated, and the models with the lowest AICcd-values are withheld in the next generations. Starting from those models, small changes are made with the purpose to find models with even lower AICcd-values.After calculating the AICcd values for each of the considered models, the models were sorted according to their resulting AICcd values. Seven models will be discussed and compared: the best five models according to the AICcd, the full model and (again according to AICcd) the best model under the restriction that the latency and incidence model should contain the same covariates; see Table 5.We observe that for all the five best models, the same latency model is selected whereas the incidence model covariates vary. For this dataset, the incidence model seems to require more variables. Whereas variables v2 (amount of the loan), v3 (number of years living at a current address) and v8 (frequency of the payment) are never included in the latency part of the best five models, those three variables are also the ones left out in the incidence model, but at the most with two at the same time. The full model only ranks 215th with regard to AICcd value. The same covariate model, for this dataset, uses the same covariates as for the latency part. Its rank is 17, with a difference in AICcd values as compared to the best model equal to about 25, clearly showing the preference for the separate covariate parts.In the credit risk context, a widely used method to evaluate binary classifiers is by means of the receiver operating characteristics curves. These curves give the percentage of correctly classified observations for each possible threshold value. The specific measure of interest is the area under the curve (AUC), which can also be used in the context of survival analysis (Heagerty and Saha, 2000). We computed the AUC values for five models of interest, when predicting default at three different time instances (18, 24 and 36 months). Each time, 2/3 of the data was used as a training set, and 1/3 as a test set. The AUC-values can be found in Table 6.In Table 7, the parameter estimates of the best model according to AICcd can be found. Positiveb-parameters have a positive impact on the probability of being susceptible, and positiveβ-parameters shorten the time until default. As a result, working at the same employer for a longer time period decreases the risk to default, as well as having a home phone and owning a house (binary variables decoded as 1 = no and 2 = yes). The gender of a subject has an ambiguous effect on default: whereas being male lowers the probability of being susceptible, we see that the time until default when susceptible is shorter for men.Fig. 1presents the estimated survival curves for two randomly chosen persons in the dataset (namely a male person, not possessing a home phone and working at the same employer for a relatively short time, and a female person, possessing a home phone and working at the same employer for a relatively long time). We consider estimates obtained in the best mixture cure model with different covariates for both model parts, in the best such model with the same covariates, and in the best Cox proportional hazard model with all variables except for the customer’s gender. This was the model selected by the AIC using the partial likelihood and penalizing for the number of parameters in the model.For the male person, the estimated survival percentages were relatively high, and all three approaches give reasonably close estimates. However, for the female person with lower values for the estimated survival probabilities, we observe a clear difference with the estimates from the mixture model and with that of the Cox proportional hazard model. The estimated proportion in the mixture was equal to 12.81 percent for this subject, clearly suggesting the need of the mixture model. For this data example, the use of the same covariates leads to larger estimated probabilities for survival.As stated before, the multiple event model does not only incorporate default, but also early repayment, resulting in two incidence models and two latency models. For this dataset there are 3.6 percent observations (269 cases) for which maturity has occurred (so, which are belonging to the “cured” fraction), 5 percent (376 cases) were in default, and 39.8 percent (2992 cases) have prepayments. The remaining 51.6 percent are truly censored observations.The genetic algorithm used is part of the package GA in R by Scrucca (2013), with default settings, as described in Section 5.1. Despite the fact that genetic algorithms are quite successful and efficient, it is never certain that the final outcome will yield the overall lowest AICcd value. However, the genetic algorithm we used was also applied to the data example for the mixture cure model in Section 5.2, resulting in precisely the same selected model as with the exhaustive search. The resulting model for the joint analysis of default and prepayment with parameter estimates can be found in Table 8. The interpretation of the parameters in Table 8 is similar to the mixture cure-interpretation. Again, we see that not having a home phone increases the probability and shortens the time for default (both positiveb^- andβ^values). A longer working duration at the same employer, however, decreases the probability of default but has no significant result on the time until default according to the model selected by the genetic algorithm using AICcd. The number of parameters included in the latency model of default has gone from five parameters in the mixture cure model to four parameters in the multiple event incidence model. A possible explanation is that since more information is gained by adding an early repayment part, less predictors are needed for the time until default. For the early repayment parameters, we notice that five variables are included in the latency part. We see that male subjects tend to have a lower chance to belong to the early repayment group (b< 0), but when belonging to that group, they tend to prepay earlier than female subjects. Note that the same variables are included for the two incidence models, where only v7 is not in the incidence model. This is a result of the fact that the respective probabilities are estimated in one multinomial logit model (as we have now three groups: early repayment, default and maturity). The sign ofb^dandb^pgives the relation between default and early repayment respectively, in relation to maturity. For example: the multinomial log-odds for a certain subject to belong to the early repayment-group versus the mature group are expected to increase by 0.083 units (ceteris paribus) when the subject does not have a home phone, however, the log-odds to belong to the default-group compared to the mature group are even more elevated (increase by 0.481 units).As a final illustration, the default and early repayment curves were plotted in Fig. 2for the same two random observations as for the mixture cure model. The male person incurs a higher risk regarding default, and a lower propensity regarding early repayment.

@&#CONCLUSIONS@&#
