@&#MAIN-TITLE@&#
Efficient direct rendering of deforming surfaces via shared subdivision trees

@&#HIGHLIGHTS@&#
We present Shared Subdivision Trees (SST) to rasterize implicit surfaces on GPUs.We address the problem of efficiently rendering implicit surfaces which undergo a nonlinear deformation throughout the rendering process.We map Shared Subdivision Trees well to parallel computing platforms such as CUDA.

@&#KEYPHRASES@&#
Isosurface visualization,GPU rendering,Computational geometry and object modeling,

@&#ABSTRACT@&#
In this paper, we present a subdivision-based approach to rasterize implicit surfaces embedded in volumetric Bézier patches undergoing a nonlinear deformation. Subdividing a given patch into simpler patches to perform the surface rasterization task is numerically robust, and allows guaranteeing visual accuracy even in the presence of geometric degeneracies. However, due to its memory requirements and slow convergence rates, subdivision is challenging to be used in an interactive environment. Unlike previous methods employing subdivision, our approach is based on the idea where for a given patch only one subdivision tree is maintained and shared among pixels. Furthermore, as the geometry of the object changes from frame to frame, a flexible data structure is proposed to manage the geometrically varying Bézier patches. The resulting algorithm is general and maps well to parallel computing platforms such as CUDA. We demonstrate on a variety of representative graphics and visualization examples that our GPU scheme scales well and achieves up to real-time performance on consumer-level graphics cards by guaranteeing visual accuracy.

@&#INTRODUCTION@&#
DeformingB-spline volumes with embedded scalar fields frequently occur in a variety of computer graphics and engineering applications. For instance, in free-form deformation  [1] an implicit surface of a scalar field is deformed by deforming the geometry of its associatedB-spline bounding volume.B-spline volumes are also a fundamental primitive in isogeometric analysis  [2] where they are used to represent the geometry of a physical object. Physical analysis is applied directly to theB-spline volume representation, where the analysis result is represented as an associated attribute. Depending on the simulation scenario, the geometry of the representation may undergo shape changes. For instance, an elastic body deforms when external forces are applied, where stress is an attribute of the deforming object.In this paper, we address the problem of efficiently rendering implicit surfaces which undergo a nonlinear deformation throughout the rendering process. The deformation is performed on a volumetric representation, which can be converted into a set of Bézier volumes. While the topology of the deforming surface may remain the same throughout the animation, its scale may change non-uniformly from frame to frame. Extraction- and sampling-based methods are not only challenged by the changing surface properties and the dynamic volumetric deformations, but also by the reconstruction of all the features present in the implicit surface (for instance, see thin features in Fig. 1).Given this scenario, subdividing the Bézier patches into simpler patches is key. Traditionally, a subdivision-based approach builds a subdivision tree for each pixel, where sub-patches in the tree are kept and only subdivided further if they potentially contain a piece of the surface overlapping with the pixel. In the limit, the leafs of the subdivision tree constitute to that piece of the surface, passing through the pixel. However, subdivision is computationally expensive and only converges linearly to a solution. Therefore, instead of subdividing the patch to pixel size, it is only subdivided until all intersections can be determined using the Newton–Raphson method. Then, the local subdivision tree is discarded. In order to reduce the size of local sub-division trees, a pre-subdivision stage  [3] is employed: before rendering takes place, the patch is first subdivided into a set of simpler patches. The main drawback with this strategy is that a hierarchical data structure has to be maintained, and has to be rebuilt whenever the geometry changes. This poses additional challenges to map such a scheme efficiently to GPU. Furthermore, the hierarchy is view independent, i.e., it may consist of too many (or too few) levels, and also patches which are occluded from the current view.Main contribution: we present a novel concept for GPU, called Shared Subdivision Trees (SST), to rasterize implicit surfaces represented by multiple Bézier patches undergoing a nonlinear deformation during rendering. Conceptually, as illustrated in Fig. 2, for a given patch, a single subdivision tree is maintained which is shared among pixels. A patch in the subdivision tree is only subdivided further if requested by a screen pixel, which eliminates the redundant subdivision work. The proposed method can be seen as moving the pre-subdivision stage into the rendering stage, where the subdivision tree of a given patch is built by exploiting the high parallelism of current GPUs. The visibility problem is solved by a conventional sweep and prune method which allows to handle datasets as they occur in practice. We demonstrate on a variety of representative examples that our scheme is computationally efficient and yields interactive and for some examples even real-time frame rates. In addition, we verify that our scheme scales well with respect to memory requirement and rendering speed.The outline of this paper is as follows. After discussing the related work in Section  2, the mathematical framework used for this work is introduced in Section  3. The proposed algorithm is described in Section  4 and its implementation is discussed in Section  5. Then, three applications and associated studies are presented in Section  6.1. Finally, we evaluate the efficiency of our proposed method in Section  6.2, and conclude the paper in Section  7.Direct rendering on uniform grids: there is a vast body of work to directly render implicit surfaces of volumetric scalar fields. A variety of highly efficient methods exist when the scalar field in world space can be described by a trivariate or piecewise trivariate polynomial. Methods in this category date back to the work by Rockwood  [4] which computes univariate contours from a Bézier volume. Roots of these contours correspond to points on the isosurface. A related approach presented in  [5] converts the algebraic function along the ray into Bernstein form to efficiently and robustly determine all intersections between the ray and the implicit surface. Knoll et al.  [6] present an approach to render implicit surfaces of algebraic functions using interval arithmetic achieving real-time frame rates. Approaches falling into the same category, but which are based on sampled volume data are  [7–9]. More recently, Liu et al.  [10] present an isosurface rasterization approach exploiting cache coherency to further speed up rendering.Due to the polynomial nature of the scalar field, the scalar field along a viewing ray can be represented in closed form. This property results in a lower memory footprint making it easier to solve the problem on the GPU. However, in our scenario, the volume embedding the scalar field undergoes a nonlinear deformation (Fig. 1 and for more examples Figs. 7 and 8). In this case, the scalar field consists of a highly nonlinear term which makes it impossible to express the scalar function along the ray analytically. Because of that, it is unclear how to extend the methods above to also work efficiently in this scenario. In this paper, we present an efficient rasterization method which robustly renders isosurfaces embedded in deformed objects.Extraction-based methods: among the first methods to render scalar data embedded in deformed volumes is  [11]. The method is based on an isosurface sampling approach similar to  [12]: points are iteratively projected onto the isosurface and the surface is rendered using a point-based rendering system such as  [13]. High visual accuracy can be achieved following this strategy. However, determining a point sampling which guarantees visual accuracy is difficult. These methods generally tend to oversample the implicit surface in order to reconstruct thin or smaller features as the one shown in Fig. 2. Extraction based methods face similar problems. Such an approach first extracts the implicit surface using a method such as Marching Cubes  [14], or Marching Tetrahedra  [15]. Then, the extracted triangle mesh approximating the smooth implicit surface is rendered. While extraction can be executed very efficiently, the smooth representation first has to be discretized into a linear format. This requires the sampling of the volumetric patch. Efficiently generating a sampling such that the extracted triangle mesh is accurate up to image resolution is an open problem. Note that, all these challenges are amplified when the implicit surface undergoes a nonlinear deformation every frame.Ray-sampling-based methods: given a ray passing through a pixel and a deformed volumetric patch with embedded scalar field, an intersection of the ray with the implicit surface is computed in two steps: (1) determine the entry and exit point of the ray into the patch; and (2) perform root finding on these bounds to identify where the ray intersects the implicit surface. Since the scalar function cannot be written in closed form, as discussed above, the latter step requires sampling of the scalar field along the ray, where for each sample, the inverse function has to be evaluated using a numerical method. For instance,  [16,17] adaptively sample this function to compute a polynomial interpolant based on a Legendre basis which can be arbitrarily close to the solution. Similarly,  [18] present a GPU ray-caster using a frequency based adaptive sampling approach to account for high variations along the ray. To achieve interactive frame rates, the method stores the volumetric patches in a grid.Ray-sampling methods, such as the ones discussed above, assume that the mapping between the reference element to the deformed patch is bijective. However, this is often not the case in practice. For instance, in physically based animation  [19], patches undergoing a nonlinear deformation may self-intersect or even invert. This results in zero Jacobians, where at these locations the mapping is not bijective and therefore, a numerical method such as Newton–Raphson to compute the inverse cannot be used. This type of data presents severe stability and convergence issues for the rendering approaches mentioned above. Furthermore, boundaries of volumetric patches are often degenerate, e.g., elements along a cylindrical axis, which complicates the computation of entry and exit points. Our proposed method robustly handles these types of scenarios.The introduction of geometric constraint solvers in the pioneering work  [20] is based on subdivision and numerical root-finding, and thus guarantee to find all values satisfying a system of nonlinear geometric constraint equations. The method proposed in  [21] builds up on this framework: for each pixel, a system of three nonlinear equations is solved to determine intersections with the implicit surface. The method results in a tremendous memory overhead, since it constructs a subdivision tree for each pixel independently. Because of this property, it is difficult to map this scheme to the GPU. In this paper, we reformulate the problem in such a way, that the intersection problem can be efficiently solved on a GPU. At the same time, it retains the guarantees of a geometric constraint solver. The key of the proposed method is to share both, the subdivision work and the resulting patches across viewing pixels to robustly compute the implicit surface intersections.In the next section, we introduce the mathematical framework on which we base our method. It also includes a discussion of classical ray/isosurface intersection given this type of data as a rationale to propose Shared Subdivision Trees and its implementation to fully exploit the parallelism of consumer level GPUs in Sections  4 and 5.The input to our method is a volumetric representation with embedded scalar field undergoing a nonlinear deformation in discrete time steps, where we assume that the representation can be converted into a set of Bézier volumes. In this work each frame is treated independently, i.e., calculations of a previous time step are not used in the current time step. In the following paragraphs we solely focus on rendering implicit surfaces embedded in the Bézier volume of a single time step. Fig. 3illustrates the formalities made in the following two paragraphs where for illustrative purposes the input consists of a single rational Bézier volume of degree(l,m,n), formulated as(1)V(u)=∑i=0l∑j=0m∑k=0nwijkcijkθil(u)θjm(v)θkn(w)∑i=0l∑j=0m∑k=0nwijkθil(u)θjm(v)θkn(w).Here, the parameteru={u,v,w}lives in a cubic parameter domain, whereθin(u)is theith Bernstein polynomial  [22] of degreen.cijkdefine control points of a(l+1)×(m+1)×(n+1)control grid, where,cijk={xijk,yijk,zijk,aijk}. The first three components ofcijkrepresent world space positions, and the fourth component is a scalar attribute. Thus,V(u)can be separated into two mappings, i.e.,V(u)={p(u),α(u)}, wherep(u)deforms the unit cube intoΩ∈R3, withα(u)as its associated scalar volume (see Fig. 3).The inversep−1(x)maps a pointx∈Ωback to the unit cube. Given a user-specified isovalueaˆ, an implicit surface residing within the bounds ofΩis defined as the setS={x∣α(p−1(x))=aˆ,x∈Ω}. Due to the rational nature ofp(u), its inversep−1(x)cannot be expressed in closed form. Hence, the inverse of a given pointx∈Ωcan at most be numerically approximated by a valueu∗such that|p−1(x)−u∗|<ϵ, whereϵis sufficiently small. Newton’s method is generally used to improve the accuracy ofu∗. However, if a local self-intersection of the Bézier volume is crossed during a Newton iteration, the method does not succeed.Ray/isosurface algorithms generally give answer to the question, at which point a ray in world space intersectsS. Such an intersection point belongs toSif it satisfies three constraint equations, where the first equation isα(u)−aˆ=0. Furthermore, the point also has to sit along the ray: by following the development of  [23], the ray can be represented as the intersection of two orthogonal planes,〈x,ni〉+di=0, fori=0,1, whereniis the normal of planei. The patchp(u)is substituted into these two equations, yielding the second and the third constraint equations,〈p(u),ni〉+di=0, fori=0,1.Given these three equations, a new Bézier volume,q(u), with control points{〈xijk,n0〉+d0,〈xijk,n1〉+d1,aijk−aˆ}, wherexijk={xijk,yijk,zijk}with associated weightswijkcan be constructed. The point where the ray intersects the isosurface can now be determined by solvingq(u)={0,0,0}foru. This can be robustly achieved by splitting the Bézier volumeq(u)into smaller sub-patches via Bézier subdivision  [24] by only keeping those sub-patches which contain the origin. Martin et al.  [21] combine subdivision and numerical root finding to determine all solutions along the ray following this strategy.This scheme is general: given any ray in world space, the intersection problem can be solved robustly. This generality is especially useful for secondary rays in ray tracing solutions (e.g.,  [25]). However, it comes at the price that for each ray an independent problem has to be solved, i.e., construct an individual subdivision tree for each ray in order to faithfully determine all the intersection points. The pioneering work  [26], and the famous Bézier Clipping method  [27] follow a very similar strategy to directly render parametric surfaces. While local memory might be sufficient to render parametric surfaces, mapping such an approach to the fragment level of a GPU to render isosurfaces of deformed volume data is generally not feasible, because local subdivision trees quickly exceed the local memory size.The following section arrives at a solution which rasterizes the isosurface as seen from the eye, where only a single subdivision tree for a given Bézier volume is maintained and shared among the pixels. This results in a scheme which requires significantly less memory and thus allowing for the efficient implementation and execution on a GPU.Given the mathematical framework introduced above, in this section we propose our isosurface rasterization algorithm to accurately render the isosurfaceSof a given time step from the current camera position. While our method will be applied to objects which are represented as a union of Bézier volumes, for simplicity of discussion, we focus here on a single Bézier volumep(u). For that we assume that its world space coefficients have been transformed by the camera and projection matrix into perspective space. Hence, the isosurfaceSlies within the transformed camera frustum, a cube of size[−1,1]3. The computation discussed in this section is conducted on its front side, corresponding to the camera’s near plane onto which we impose an×nimage.By referring to Fig. 4, given pixel(s,t), the goal is to determine all points which lie on the isosurfaceSand within pixel(s,t). The first constraint is described with the inequality|α(u)−aˆ|≤ϵ, where in our implementationϵ=10−5. The requirement that a point has to lie within the pixel can be described with two constraint inequalities: analogously to the strategy in Section  3.1, given half the pixel widthpw, the two scalars,bs=s/n+pwandbt=t/n+pw, are used to define two perpendicular planes,x−bs=0andy−bt=0, coinciding with the center of the pixel. Note that the first plane passes through all the pixel centers of the image columns, and the second plane passes through all pixel centers of rowt. Substituting patchp(u)={x(u),y(u),z(u)}into the two plane equations yields the second and third constraint inequalities,|x(u)−bs|≤pwand|y(u)−bt|≤pw, respectively.Given these three constraint inequalities, a new Bézier volume with control points{xijk−bs,yijk−bt,aijk−aˆ}with corresponding weightswijkcan be constructed. This Bézier volume is equivalent tos(u)−ost, wheres(u)is a Bézier volume with control points{xijk,yijk,aijk}with the same weights asp(u), andost={bs,bt,aˆ}. All parametersu∗satisfying these constraints can now be determined by solving|s(u)−ost|≤{pw,pw,ϵ}foru, i.e.,p(u∗)lies within the pixel and is sufficiently close to the isosurface. Note that thezcomponent ofp(u∗)is the pixel depth. The offsetostcan be seen as translating the Bézier volumes(u)into the local coordinate system of pixel(s,t), where the pixel center serves as origin. In this formulation, the patchs(u)is independent of the pixel offset, i.e., the patchs(u)can be used by other pixels to solve its individual intersection problems.This suggests an algorithm, called the Shared Subdivision Tree (SST) algorithm, which is based on building only one subdivision tree for a given patchs(u). Initially a subdivision tree consists of the input patch only. This patch is subdivided if required by a pixel. However, since the tree is independent of a given pixel, subdivided patches can be used to determine the root of other pixels by applying the respective offset as discussed above. Semantically, we refer to this behavior as sharing a subdivision tree among pixels, because the relevant patches are shared among various pixels and subdivision work is not performed for each pixel independently. Therefore, this algorithm can be seen as solving the intersection problem globally, which is in contrast to the traditional ray/isosurface intersection discussed in Section  3.1, where the intersection problem is solved independently for each pixel(s,t). In the following we describe the SST algorithm in more detail.The inputs to our algorithm are the screen pixels(s,t), and a listLconsisting of Bézier volumes, constructed as discussed in the previous section.Licorresponds to theith patch inL. The algorithm outputs a solution arrayRof parameter values for each pixel. Here,Rstcontains the solutions for pixel(s,t). Given that, the following three stages are executed until all intersections have been determined.(1) Overlap Stage. Each pixel(s,t)is tested whether it overlaps with bounding boxes of the patches inL. If there is an overlap between bounding box of patchLiand pixel(s,t), the isosurface may overlap with the pixel as well. Therefore, the tuple(s,t,i), whereirefers to patchLi, is added to pixel index listI.(2) Solution Stage. Newton’s method is used on each tuple inIto solve equation|Li(u)−ost|≤{pw,pw,ϵ}, for parameteru, as discussed in the previous section. If Newton succeeds, the tuple is removed fromIand the solutionuis added toRst. If all tuples have been removed fromI, the algorithm terminates. Otherwise it proceeds to Stage 3.(3) Subdivision Stage. For all the remaining tuples inI, patches are subdivided andLis overwritten with the new patches, where patch indices in the tuples are adjusted accordingly. Subpatches which do not have a sign change in their scalar attribute are discarded, as this indicates that they cannot contain a piece of the implicit surface. Go back to Stage 1.After the termination of this loop, in a final step, eachRstis sorted according to the respective pixel depth. For more details, pseudocode of this algorithm is provided in Appendix A. Since all roots for a given pixel are computed, the method can be used to realize independent transparency and to render CSG objects as discussed in Section  6.1. Note that, each stage of this algorithm can be executed in parallel.

@&#CONCLUSIONS@&#
In this paper, we propose Shared Subdivision Trees which efficiently map to the GPU by sharing a single subdivision tree for a given patch across multiple pixels. We demonstrate that Shared Subdivision Trees cannot only be used to efficiently rasterize implicit surfaces embedded in deforming volumes but also to rasterize parametric surfaces undergoing a deformation. Our method, based on a direct rendering approach, is especially useful in applications such as free-form deformation or physically-based animation applied to solids, where methods based on meshing, tessellation, or sampling, are difficult to apply due to the nonlinear deformation of the given surface representation. Input is allowed to be rational, allowing the method to also be used in other applications such as CAD modeling or within isogeometric analysis. The presented algorithm is simple in terms of implementation and executes efficiently on GPU. In the future we plan to embed this algorithm in time critical applications such as 3D animation to render nonlinear effects more robustly and efficiently. We further want to explore our scheme to work directly with more general volumetric representations, such as trivariate NURBS, without converting them first into a Bézier representation.