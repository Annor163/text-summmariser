@&#MAIN-TITLE@&#
Size matters: How population size influences genotype–phenotype association studies in anonymized data

@&#HIGHLIGHTS@&#
Anonymization of large-scale clinical codes allows for reliable genome–phenome analysis.Across various repository sizes full EMR most reliable.Preserves utility for finding genome–phenome associations.

@&#KEYPHRASES@&#
Privacy,Anonymization,Clinical codes,Data publishing,

@&#ABSTRACT@&#
ObjectiveElectronic medical records (EMRs) data is increasingly incorporated into genome–phenome association studies. Investigators hope to share data, but there are concerns it may be “re-identified” through the exploitation of various features, such as combinations of standardized clinical codes. Formal anonymization algorithms (e.g., k-anonymization) can prevent such violations, but prior studies suggest that the size of the population available for anonymization may influence the utility of the resulting data. We systematically investigate this issue using a large-scale biorepository and EMR system through which we evaluate the ability of researchers to learn from anonymized data for genome–phenome association studies under various conditions.MethodsWe use a k-anonymization strategy to simulate a data protection process (on data sets containing clinical codes) for resources of similar size to those found at nine academic medical institutions within the United States. Following the protection process, we replicate an existing genome–phenome association study and compare the discoveries using the protected data and the original data through the correlation (r2) of the p-values of association significance.ResultsOur investigation shows that anonymizing an entire dataset with respect to the population from which it is derived yields significantly more utility than small study-specific datasets anonymized unto themselves. When evaluated using the correlation of genome–phenome association strengths on anonymized data versus original data, all nine simulated sites, results from largest-scale anonymizations (population∼100,000) retained better utility to those on smaller sizes (population∼6000–75,000). We observed a general trend of increasingr2for larger data set sizes:r2=0.9481for small-sized datasets,r2=0.9493for moderately-sized datasets,r2=0.9934for large-sized datasets.ConclusionsThis research implies that regardless of the overall size of an institution’s data, there may be significant benefits to anonymization of the entire EMR, even if the institution is planning on releasing only data about a specific cohort of patients.

@&#INTRODUCTION@&#
Large-scale genotype–phenotype association studies have rapidly increased in prevalence, due to a combination of massively high-throughput technologies [1], lower cost computing platforms, and systems that make information more widely available (e.g., the Database of Genotypes and Phenotypes (dbGaP) [2]). At the same time, it has been shown that data residing in electronic medical records (EMRs) can enable such studies [3–6] finding, for instance, associations with atrioventricular conduction [7], white [8] and red [9] blood cell traits, hypothyroidism [10], and, more recently, the study of pharmacogenetic traits, including clopidogrel-response [11] and warfarin dose [12]. This is further notable because there are indications that learned associations can enable more effective and safe healthcare [13], with early gains in drug dosing [14].Given the increased reliance upon EMRs for big data research projects, it is important for institutions to work towards data sharing strategies [15–17]. Beyond adhering to policy requirements [18], data sharing can support a wide range of activities [19], including validation of published findings and discovery of novel associations [20]. Despite the opportunities that biomedical data sharing holds, there are significant concerns over the privacy implications [21,22].As part of a data protection plan, it is often suggested that biomedical data be disseminated in a manner, such that it is “de-identified” or devoid of explicit identifiers (e.g., personal names) [18,23]. Over the past decade a growing list of investigations have called into question the extent to which de-identification can guard research participants engaged in genomic studies from unsanctioned “re-identification” due to the very act of releasing genomic information itself [24–28]. While we admit that this is an area of concern [29], the likelihood that such attacks will be realized in practice is currently unknown. Thus, in this work, we focus upon linkage risks posed by information that, at the present moment, is more likely to be exploited in re-identification attacks [30].For years, it has been known that certain common demographics, such as date of birth, gender, and 5-digit ZIP code, could be exploited to discern an individual’s identity [31–34]. And, even when demographics are appropriately protected, it may be possible to exploit other features, such as standardized clinical information. This is a concern because it has been illustrated that the set of insurance billing codes (e.g., International Classification of Diseases (ICD)) in a patient’s record are often unique [35]. And, while the abstraction of billing codes (e.g., changing of a code representing that a patient suffered from malignant neoplasm of thyroid gland (code 193) to that of neoplasm (codes 140–249)) can drastically reduce the identifiability of patients within a genome–phenome association studies, it can also have a detrimental impact on the underlying data. Ref. [36] proposed a method of clinical code anonymization that yielded data appropriate for validation of reported findings. However, the attack scenario invoked in that work assumed that an adversary has an almost-complete knowledge of the sample population that is being published (e.g., which individuals in a population were included in the study). While possible, the strength of this attacker may not be reasonable, such that instead, in a scenario where the institution publishing the data has a higher level of (but not complete) trust in the system and recipients of data, we consider a modified attacker with a more limited set of knowledge.An initial examination of the ability to protect clinical data (in regards to re-identifiability) was provided in [37]. In that work, the effects of protection were examined at three naturally-occurring levels within a large academic healthcare system: (1) all patients in the EMR systems, (2) all patients with specimens in a biorepository (a subset of the EMR), and (3) a cohort of patients whose DNA and EMRs were studied to validate certain genotype–phenotype associations (a subset of the biorepository). In these scenarios, the attacker was an individual with knowledge of a patient’s visit to the healthcare institution, and their goal was to identify the patient within the published data. It was observed that by protecting a study’s cohort with respect to the entire group of patients within the system, the disclosed data could support the discovery of findings with significance that exactly match those of the association observed in the original system.These findings suggested such a protection method is viable, but the study was limited because it was evaluated in a specific setting. In particular, it was not clear how these findings might translate to other institutions. For instance, at the time of this study, the biobank of the Vanderbilt University Medical Center (VUMC), contained on the order of 110,000 specimens; yet other institutions involved in the Electronic Medical Records and Genomics (eMERGE) network have considerably smaller biorepositories than VUMC which has approximately 110,000 records in its biorepository1These values correspond to the size of the biorepositories at the end of the first phase of the eMERGE network in 2011.1(e.g., Northwestern University has approximately 15,000 records, and the Mayo Clinic has approximately 20,000). Additionally, other repositories aim for a significant larger population, such as UK Biobank, which plans on over 500,000 participants [38].Thus, in this paper, we examine the issue that other institutions may face when confronted with the prospect of sharing data – namely, that their overall EMR and biorepository may not be the same size or bias (as regards composition of patients in the biorepository versus in the more general hospital population) as was investigated in [37]. For example, two institutions may be developing a biorepository of a similar size. If, however, Institution A targets their development toward a specific phenotype (e.g., congestive heart failure) while Institution B develops a general-use repository, these biobanks will have different biases (e.g., the rate of appearance for ICD codes representative of CHF will be significantly greater in the former) and potentially even different repository sizes.To perform this investigation, we conduct a large-scale sensitivity analysis between privacy (that is, “Can an individual patient be re-identified from published data?”) and utility (“Is the data usable in various genome–phenome association studies?”). We examine how anonymizing different quantities of electronic medical record data and biorepositories (from small groups of 1000 individuals up to a biorepository of 100,000 individuals and an EMR of over 1,000,000 individuals) affects the results of genome–phenome associations after application of a formal data anonymization algorithm.The remainder of this paper is structured as follows: in Section 2, we discuss the relevant background to the anonymization approach. In Section 3, we review the anonymization algorithm, describe the experimental process, and detail the measures by which we analyze the algorithm. In Section 4, we highlight the results of the experiments and provide insight into their implications. In Section 5, we provide some intuition into the larger implications of this work and potential future directions of study.

@&#CONCLUSIONS@&#
There are several important messages that have been shown in these results that should be highlighted. First, the accuracy of association significance does not necessarily increase through the addition of biorepository patients for the privacy protection of individuals involved in a study. This is because there are many factors which may potentially affect this overall quality. The main issue is that of an inherent selection bias within the biorepository, which could present in several ways. For example, only individuals with the same diagnosis code may have been recruited for the biobank. Alternatively, a biobank can bias selection of included patients towards those who visit an affiliated institution more frequently. Even a completely random selection can introduce biases of its own into the resulting data (e.g., rare codes are going to be less represented in the biobank). While avoiding these biases may prove difficult, it is important to investigate the impact they have upon the protection of data within the system in order to determine whether a particular method is well-suited for protection.Second, the results further suggest that randomly selecting records for protection from the overall EMR (even a fairly substantial number when compared to the data to be released) is not sufficient to produce anonymized data with high utility. Instead, we reaffirm the conclusion offered in [37]. An institution can both release rich, useful data and protect the released records against the entirety of their dataset by performing a full-scale anonymization and releasing the needed, specific records. This, in general, provides better results than by trying to determine a “sufficient” number of records against which to protect the sample set.Each simulated data set corresponded to a single randomized selection from our EMR. This may add noise to the results at different data points, which could be resolved with repeated randomization. However, we note that since each dataset was randomized independently, the trend observed across the points in the scalability plots is expected to correspond to the mean result.Our work suggests that institutions should use the data on patients in their biobank (or the entire EMR population) to protect the privacy of those involved in a specific study. However, future work should test this method on additional datasets and report on the usability of subsequent data. Given that this genome–phenome associations frequently take the form of a pooled or meta-analysis, there may even be issues with data protection when the cohort is assembled across multiple, disjoint sites.A second future direction is to consider the impact of time on anonymized releases. For example, if a particular patient is included in multiple study cohorts, it may be possible to track the patient through composition attacks across institutions that violate the principles of a k-type protection [56–58]. Despite such limitations, the presented results provide strong evidence that anonymization of EMR data can be accomplished with minimal impact on association studies and that such approaches benefit when large populations can be drawn upon for protection.