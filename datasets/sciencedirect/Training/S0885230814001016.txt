@&#MAIN-TITLE@&#
Linguistically-augmented perplexity-based data selection for language models

@&#HIGHLIGHTS@&#
Word-level linguistic information for perplexity-based data selection.Evaluation and analysis for four languages: English, Spanish, Czech and Chinese.Combination of models lead to lower perplexity than the state-of-the-art baseline.

@&#KEYPHRASES@&#
Data selection,Language modelling,Computational linguistics,

@&#ABSTRACT@&#
This paper explores the use of linguistic information for the selection of data to train language models. We depart from the state-of-the-art method in perplexity-based data selection and extend it in order to use word-level linguistic units (i.e. lemmas, named entity categories and part-of-speech tags) instead of surface forms. We then present two methods that combine the different types of linguistic knowledge as well as the surface forms (1, naïve selection of the top ranked sentences selected by each method; 2, linear interpolation of the datasets selected by the different methods). The paper presents detailed results and analysis for four languages with different levels of morphologic complexity (English, Spanish, Czech and Chinese). The interpolation-based combination outperforms the purely statistical baseline in all the scenarios, resulting in language models with lower perplexity. In relative terms the improvements are similar regardless of the language, with perplexity reductions achieved in the range 7.72–13.02%. In absolute terms the reduction is higher for languages with high type-token ratio (Chinese, 202.16) or rich morphology (Czech, 81.53) and lower for the remaining languages, Spanish (55.2) and English (34.43 on the English side of the same parallel dataset as for Czech and 61.90 on the same parallel dataset as for Spanish).

@&#INTRODUCTION@&#
Recent years have witnessed a shift in the field of computational linguistics, which has moved from symbolic to statistical approaches. Language models (LMs) are a fundamental piece in statistical applications that produce natural language (e.g. machine translation, speech recognition). The LM is the component of any such system that takes care of fluency. LMs, as any other statistical model, should be trained on data of the same domain, genre and style as the data it will be applied to in order to perform optimally. This poses a problem, as in the majority of scenarios the amount of so-called domain-specific data is limited.A popular strand of research in recent years to tackle this problem is that of training data selection. Given a limited domain-specific corpus and a larger pool of general-domain text, the task consists of finding suitable data for the specific domain in the general-domain sources. The underlying assumption is that a general-domain corpus, if broad enough, contains a subset of data which is similar to the target specific domain. That data, therefore, would be useful for training models for that specific domain.Current data selection approaches (e.g. Moore and Lewis, 2010) support the selection of data from general-domain corpora that result in LMs which perform better (e.g. in terms of perplexity) for a given specific domain than LMs built on the whole general-domain corpora.While these approaches rely solely on the use of surface forms, some research on language modelling looked at using linguistic information, specially for dealing with highly inflected languages. The rationale being that the fact that these languages have a larger set of different surface forms leads to sparsity problems, if the methods applied rely solely on surface forms. For example, research comparing English and Russian (Whittaker and Woodland, 1998) reported that a 65,000 vocabulary has 1.2% out-of-vocabulary (OOV) rate on the British National Corpus, while a vocabulary of the same size for Russian leads to 7.5% OOV rate on a Russian corpus of similar size. A vocabulary size of 375,000 is needed in Russian to achieve 1.2% OOV rate.Work on language modelling for inflected languages has looked at using different types of information such as classes (Whittaker and Woodland, 1998; Brychcin and Konopík, 2011), part-of-speech (PoS) tags (Heeman, 1999), stems and endings (Maučec et al., 2004). LMs built on different types of information (e.g. word and class-based) can then be interpolated to reduce perplexity (Maltese et al., 2001).Given the positive impact brought to language modelling by using linguistic information, we anticipate that this type of information could be useful as well for data selection. In our research, we explore the use of linguistic information for the selection of data from general-domain corpora to train domain-specific LMs. This paper builds upon our previous work (Toral, 2013), in which we showed that the use of linguistic phenomena, in particular named entities (NEs) and lemmas, in data selection and a naïve combination method lead to lower perplexity of the selected LMs for English and Spanish. Here we delve deeper into this topic, by testing and analysing in detail the results of our approach on a broader set of languages, including a highly inflected language (Czech) and a language with a high type-token ratio (Chinese). Another novelty of this paper is the use of a more advanced method to combine the different models (linear interpolation).The rest of the paper is organised as follows. Section 2 presents an overview of the state-of-the-art in data selection, concentrating on perplexity-based approaches, as that is the focus of this work. Section 3 details our methodology for linguistically-augmented data selection, describing the individual models and the combination approaches. Section 4 describes the experimental setting and presents the results obtained. Section 5 delves deeper into the results, analysing the contribution of the different models from a number of perspectives. Finally, Section 6 provides the conclusions and proposals for future work.

@&#CONCLUSIONS@&#
This paper has explored the use of different types of linguistic information at word level (lemmas, NEs and PoS tags) for the task of training data selection for LMs following the perplexity-based approach. By using these types of information, we have introduced five linguistically-motivated models. We have also presented two methods to combine the individual linguistic models as well as the baseline (surface forms): a simple selection of top ranked sentences selected by each method and a linear interpolation of LMs built on the data selected by the different methods.The experiments are carried out on four languages with different levels of morphologic complexity (English, Spanish, Czech and Chinese). Our combination model based on linear interpolation outperforms the purely statistical baseline in all the scenarios, resulting in language models with lower perplexity. In relative terms the improvements are similar regardless of the language, with perplexity reductions achieved in the range 7.72–13.02%. In absolute terms the reduction is higher for languages with high type-token ratio (Chinese, 202.16) or rich morphology (Czech, 81.53) and lower for the remaining languages, Spanish (55.2) and English (34.43 on the same dataset as Czech and 61.90 on the same dataset as Spanish).We have also analysed the models in detail by looking at the vocabulary reduction they achieve, their overlap and their importance. We have shown evidence that all the models are valuable as (i) they bring a significant reduction in vocabulary size when compared to the baseline, (ii) they provide a significant percentage of novel data which is not selected by the baseline and (iii) they are given significant weights in the interpolation.As for future work, we consider three main possible lines of research.The first line regards the exploration of other types of information, instead of word-level linguistic knowledge. In this respect, recent work in language modelling follows an unsupervised approach by using semantic spaces for clustering words (Brychcin and Konopík, 2014). The benefit is obvious, especially for under-resourced languages, as this approach avoids the use of tools such as PoS taggers, lemmatisers and NE recognisers. It would be interesting to compare the performance of linguistic and unsupervised models in data selection.The second line regards the use of different types of information concurrently. While we have used one type of linguistic information in each model, another possibility is to combine different types of linguistic knowledge in a single LM, following for example the factored LM approach (Bilmes and Kirchhoff, 2003).Finally, the third line has to do with the application of our approach to parallel data. This could be done by simply following the extension of the Moore–Lewis method to perform data selection from parallel data (Axelrod et al., 2011) or in combination with other methods which are deemed to be more suitable for parallel data, e.g. (Mansour et al., 2011; Banerjee et al., 2013).