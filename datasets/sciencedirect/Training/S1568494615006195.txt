@&#MAIN-TITLE@&#
A novel stability-based adaptive inertia weight for particle swarm optimization

@&#HIGHLIGHTS@&#
Presents an adaptive method for finding inertia weight in different dimensions for each particle.The success of the particle and displacement in particle's best position are used as the feedback.Stability analysis of proposed model indicates that its performance is usually optimal.The results clearly show the superiority of the proposed model over the existing methods.

@&#KEYPHRASES@&#
Particle swarm optimization (PSO),Adaptive inertia weight,Stability analysis,Radar system design,

@&#ABSTRACT@&#
Particle swarm optimization (PSO) is a stochastic population-based algorithm motivated by intelligent collective behavior of birds. The performance of the PSO algorithm highly depends on choosing appropriate parameters. Inertia weight is a parameter of this algorithm which was first proposed by Shi and Eberhart to bring about a balance between the exploration and exploitation characteristics of PSO. This paper presents an adaptive approach which determines the inertia weight in different dimensions for each particle, based on its performance and distance from its best position. Each particle will then have different roles in different dimensions of the search environment. By considering the stability condition and an adaptive inertia weight, the acceleration parameters of PSO are adaptively determined. The corresponding approach is called stability-based adaptive inertia weight (SAIW). The proposed method and some other models for adjusting the inertia weight are evaluated and compared. The efficiency of SAIW is validated on 22 static test problems, moving peaks benchmarks (MPB) and a real-world problem for a radar system design. Experimental results indicate that the proposed model greatly improves the PSO performance in terms of the solution quality as well as convergence speed in static and dynamic environments.

@&#INTRODUCTION@&#
Particle swarm optimization (PSO) is a stochastic population-based algorithm first introduced by Kennedy and Eberhart [1]. The advantages of this algorithm include fast convergence toward the global optimum, easy implementation and few parameters to adjust. Its effective searching strategy makes it a potential method for solving different optimization problems in a wide variety of applications [2,3].In PSO, each potential solution is treated as a particle. Each particle has several parameters such as the current position, velocity and the best position found by the particle so far. For a D-dimensional search space, these parameters are represented with D-dimensional vectors. The position and velocity of the ith particle is presented as:(1)xi=(xi1,xi2,…,xiD)vi=(vi1,vi2,…,viD)At each time step, the position and velocity of the particles are updated according to the following equations:(2)xi(t+1)=xi(t)+vi(t+1)vi(t+1)=wvi(t)+R1c1(Pi−xi(t))+R2c2(Pg−xi(t))where w is the inertia weight, R1 and R2 are two distinct random values between 0 and 1, c1 and c2 are the acceleration constants known as cognitive and social scaling parameter; Piis give the best previous position of the particle itself and Pg's denote the best previous position of all particles of the swarm. Large values of w facilitate exploration, with increased diversity, whereas a small values promote local exploitation [2,4,5].The balance between global and local search throughout the course of a run is critical to the success of an optimization algorithm [6,7]. In the present work, different inertia weight adaptation mechanisms are examined to bring about a balance between the global and local search, since by changing the inertia weight dynamically, the search capability is dynamically adjusted [4]. Inertia weight is one of the most important parameters of the algorithm and basically tends to memorize the previous direction of each particle. If this quantity is large, the particles will tend to memorize their previous direction, which leads to increasing the convergence speed and sometimes causes increased searching of the environment. But if this quantity is small, particles will not memorize their previous direction.Most of the common strategies of adjusting the inertia weight are efficient if their parameters are set properly based on the fitness landscape and default information (e.g. maximum iterations). In the majority of the problems, such information is not accessible, so the strategies will not necessarily have a good performance. Besides, the inertia weight should be compatible with the problem conditions and the algorithm itself. For example, in multi-swarm particle swarm optimizers, the main population is divided into a number of sub-swarms with the hope of exploring different areas of the search space [8–10]. While the inertia weight is only adjusted according to the iteration number of the overall algorithm, the sub-swarms may be created at any time during a run of the algorithm and hence require awvalue compatible with their needs. In addition, there are some optimization problems that show the need for a new inertia weight adaptation mechanism. For example, in dynamic environments with moving peaks, the global best PSO fails to follow the extrema due to the small velocity values of the particles [11].None of the existing inertia weight adjustment strategies have paid attention to the stability of PSO. As the inertia weight dynamically changes the searching ability, the stability conditions change dynamically. By satisfying the stability conditions in PSO, the speed and precision of the convergence are improved [12,13]. The objective of this paper is to design an adaptive inertia weight considering the stability conditions for the particle swarm optimization method. SAIW uses the historical performance of each particle and its best position for adjusting that particle's inertia weight in different dimensions. The inertia weight is adjusted separately in different dimensions to speed up the convergence speed. By using the inertia weight, SAIW adjusts the acceleration coefficients adaptively to satisfy the algorithm's stability conditions dynamically.The rest of this paper is organized as follows. Section 2 provides a review of different inertia weight adaptation mechanisms. In this section, the inertia weight adaptation mechanisms are classified based on the feedback that they use. In Section 3, a novel adaptive inertia weight mechanism is proposed. The experimental setup and parameters setting are discussed in Section 4. Section 5 is devoted to the performance evaluation of the proposed method and comparison with other methods and Section 6 concludes the paper.Inertia weight is one of the most important parameters of the PSO algorithm. In this section, various inertia weighting strategies are categorized into three classes. The first class contains strategies in which the value of the inertia weight is constant during the search or is determined randomly. None of these methods use any input argument. In the second class, the inertia weight is defined as a function of time or iteration number and hence the strategy is referred to as the time-varying inertia weight strategy. Despite claims made in some other papers, these methods are not considered adaptive since they do not monitor the situation of the particles in the search space. The third class contains those methods which use a feedback parameter to monitor the state of the algorithm and adjust the value of the inertia weight. These three classes are further discussed in the following sections.The inertia weight parameter was originally introduced by Yuhui and Eberhart [14]. They used a range of constantwvalues. They showed that if the value of this parameter is small, particles will tend to get trapped in the local optima and if it is within the range [0.8, 1.2], particles will tend to do global search. Li et al. [15] used a constant value of 0.6 for the inertia weight to optimize the algorithm.These strategies tend to carry out either global or local search, while the algorithm requires the combination of both of them. When these strategies are used, the global and local search ability throughout the course of a run have to be balanced in a different way. For example, Huang et al. [16] proposed an example set of multiple global best particles to update the position of the particle, Wang et al. used a diversity enhancing mechanism and neighborhood search strategies to achieve a trade-off between exploration and exploitation abilities [17], Chen et al. [18] added an aging mechanism to particle swarm optimization (PSO), and Sun et al. [19] used the slave and the master swarm with the clear division of their works.Eberhart [20] used a random value for the inertia weight to enable PSO to track the optima in a dynamic environment:(3)w=0.5+rand()2where rand() is a random number in [0,1]. The inertia weight is then a uniform random variable in the range [0.5, 1]. It is difficult to predict at a given time whether exploration (large values ofw) or exploitation (small values ofw) is required in dynamic environments. So, a random value ofwis selected to address this problem. In this method, when the algorithm needs diversity, the algorithm may not be able to increase the diversity by decreasing the inertia weight. In addition, the algorithm cannot properly converge to the optima since the inertia weight has a limit.An inertia weight determination strategy was introduced in which the value ofwwas adjusted linearly, according to Eq. (4)[21–35]:(4)w(t)=itermax−titermax(wmax−wmin)+wminwhere the value ofwis linearly decreased from an initial value (wmax) to a final value (wmin), t is the current iteration of the algorithm and itermaxis the maximum number of iterations the algorithm is allowed to continue. In this model, the particles’ tendency to local search is increased continuously. So when diversity is needed, the inertia weight cannot help. At the beginning of the run, the particles have a higher global search ability, whereas at the end of the run, they have a higher local search ability [36,37].In other studies, a chaotic term is added to the linearly decreasing inertia weight model [38–40]. Based on the used chaotic model, the inertia weight can either increase or decrease in sequential steps. However, in general, the inertia weight gradually decreases. The proposedwis:(5)w(t)=(wmax−wmin)×itermax−titermax+wmin×Zwhere Z is the chaotic term. Different chaotic models such as Logistic, Lozi, Dissipative, Arnold's Cat, etc. can be used for this term.Some researchers have introduced nonlinear decreasing strategies based on accepting the general idea of decreasing the inertia weight. In these methods, the local and global search ability of the particles are adjusted more properly. Peram et al. [41] have shown that these strategies are more suitable than linear strategies for smoother spaces. Liao et al. [42] proposed a nonlinear decreasing variant of the inertia weight formula based on Eq. (6)(6)w(t)=(itermax−t)d(itermax)d(wmax−wmin)+wminwhere d is the nonlinear modulation index. If the value of d is greater than one (d>1), at the beginning of the run, particles will have global search ability; but after that, they will have local search ability. If d has a value in the range [0,1], the situation will be the opposite. Due to the fast and decreasing nature of exponential functions, these functions have received much attention as an option for a decreasing inertia weight strategy [43]. In [44], based on the sensitivity analysis of the PSO performance, 1/π2 is selected for d to adjust the time-varying inertia weight.Distinct from the widely used decreasing inertia weight, Yong-ling et al. [45,46] proposed a PSO with an increasing inertia weight and confirmed its validity in terms of the convergence speed and solution precision by testing it with four standard test functions. They showed that the PSO with increasing inertia weight (increasing from 0.4 to 0.9) outperforms the PSO with decreasing inertia weight in all benchmarks used in their tests.Another nonlinear increasing inertia weight has been proposed by Jiao et al. [47]. In this model,wis increased over time based on the following equation:(7)w(t)=wmin×utwherewminis selected in the range [0,1] and u is a constant value in the range [1.0001, 1.005]. In the conducted experiments [47], u is set to 1.0002 and the performance of the algorithm is evaluated for different values ofwinitial.Strategies of this class, linearly or nonlinearly, increase or decrease the value of the inertia weight. These strategies try to solve the problems of the constant inertia weight strategy. The major goal of these methods is considering a curve for adjusting the inertia weight which leads to the maximum performance of the algorithm in different environments. The information in this curve can be, for instance, the maximum or minimum value of the inertia weight, the slope of the inertia weight changes, changing the situation between the exploration and exploitation characteristics, and the maximum number of iterations of the algorithm. The fitness landscape is highly effective in the performance of the algorithm with selected curve. Inappropriate parameter adjustment may lead to loosing time because of undue exploration or may lead to loosing exploration appetite. Both of these situations result in the low performance of the algorithm. From the exploration/exploitation perspective, this means that different problems require different amounts of exploration and exploitation. This implies that a good ratio between exploration and exploitation, and hence a proper or good balance, is problem-dependent, too [7].We conclude that to improve the algorithm performance, the shape of the fitness landscape should be known; which is impossible in most of the applications. In many of the strategies reviewed in this section, the maximum number of iterations of the algorithm is assumed to be known by default; an assumption which can be incorrect in some applications (e.g. dynamic environments).The last category of inertia weight determination strategies studied in this paper are those that monitor the search situation and adapt the inertia weight value based on one or more feedback parameters. In [48], w is adapted based on two characteristic parameters in the search course of PSO; namely, the speed factor and the aggregation degree factor. The speed factor is defined as:(8)hit=min(fit(Pit−1),fit(Pit))max(fit(Pit−1),fit(Pit))wherePitis the best position found by particle i until iteration t and fit() is the function to be optimized. The aggregation degree is defined as:(9)S=min(Ftbest,F¯t)max(Ftbest,F¯t)whereF¯tis the mean fitness of all particles in the swarm at the tth iteration and Ftbestis the best fitness achieved by the particles at the same iteration. Using the speed and the aggregation factors, the inertia weight of particle i at iteration t is determined as:(10)wi(t)=wmin−α(1−hit)+βSwhere α and β are two constants typically within the range [0,1]. The performance of the PSO algorithm is evaluated for different values of α and β in [48].There are other researchers who have used the fitness of the particles as a characteristic of the particles to adapt the inertia weight of each particle. In [49], Arumugam use the ratio of the global best fitness and the average of particles’ local best fitness to determine the inertia weight in each iteration:(11)w=1.1−fit(Pg)1n∑i=1nfit(Pi)where n is the number of particles.In the adaptive PSO algorithm proposed by Panigrahi et al. [50], different inertia weights are assigned to different particles based on the ranks of the particles:(12)wi=wmin+(wmax−wmin)Rankinwhere Rankiis the position of the ith particle when the particles are ordered based on their particle best fitness. The rational of this approach is that the positions of the particles are adjusted in a way that highly fitted particles move more slowly compared to the lowly fitted ones.Nickabadi in [4] uses success percentage to compute the inertia weight; and the particle fitness for computing the success percentage:(13)Ps(t)=∑i=1nS(i,t)nS(i,t)=1iffit(pbestit)<fit(pbestit−1)0iffit(pbestit)=fit(pbestit−1)where Ps∈[0, 1] is the percentage of the particles which have had an improvement in their fitness in the last iteration. In [4], a linear function is used to map the values of Psto the possible range of inertia weights as follows:(14)w(t)=(wmax−wmin)Ps(t)+wminIn this strategy, if the success percentage becomes smaller, the inertia weight will become smaller too. And if the success percentage becomes larger, the inertia weight will become larger too.In [2] a simple adaptive nonlinear strategy is introduced. The selected strategy mainly depends on each particle's performance and is determined by the absolute distance of the particle's personal best and the global best position according to the iterations:(15)wi(t+1)=wi(t)−(wi(t)−0.4)×exp−(Pg−Pi)×titermaxIt combines the effects of both the nonlinear and the exponential inertia weights. The large values ofwwhen the particle is very far from the global optimum provide exploration. But as the particles approach the global optimum,wdecreases dynamically to a small value (close to 0.4) which facilitates exploitation.The strategy introduced in [2] incorporates a dying double exponential function; namely the Gompertz function for selecting the inertia weight:(16)wi(t+1)=exp(−exp(−Ri(t)))Ri(t)=|Pg−Pi|×itermax−titermaxFirst a performance index (Ri) is evaluated for each particle at each iteration based on the particle's personal best position and the global best position of the swarm. The performance index is then fed as an input to the Gompertz function to evaluate the momentum for each particle. In this strategy, the inertia weight is about 0.4 at the beginning of the run. Then to speed up the convergence, the inertia weight becomes approximately 1 after some iterations.The strategies in this class do not have the limitations and assumptions of the time-varying inertia weight strategies. However, this does not mean that the adaptive approaches are always better than time-varying based approaches. Especially in multimodal environments, the two approaches are comparable.In this group, the environment should be monitored with some measures which are then used to adjust the parameters of the algorithm. There are two issues about these measures or feedback parameters that should be taken into account before devising an adaptive strategy. The first issue is that they should be acceptable and easy to compute. The other important factor about the feedback parameters is that it should provide good insight into the way that the inertia weight should be changed. The majority of the proposals for adaptive inertia weight use the fitness and its derivations, such as particle's ranks, to adjust the inertia weight. It is clear that the fitness by itself is not a good criterion for evaluating the appropriateness of the inertia weight value [4].Furthermore, in adaptive strategies, the performance of the algorithm changes dynamically, but the algorithm should remain stable based on the stability conditions in [12,13]. Changing the inertia weight adaptively will change the stability conditions adaptively. None of the current works have paid attention to this point.The inertia weight model proposed in this paper, which is called the stability-based adaptive inertia weight (SAIW), is inspired by the following idea. Considering the previous discussion, the adaptive inertia weight adjusting strategy is chosen for improvement. Each particle's situation in the population is important in adjusting the inertia weight [4]; so for adjusting the inertia weight for each particle, its feedback is used. The particle's performance shows its tendency to memorize its last direction. In the proposed strategy, the value of inertia weight is considered different for each dimension, so that the convergence speed increases, especially in asymmetric environments. The value of the inertia weight in each dimension is used to compute the acceleration coefficients adaptively, based on the stability condition [12,13].To provide an adaptive inertia weight strategy, one first needs to determine the feedback parameter for each particle. To achieve this, in addition to the success of the particle, the displacement in its best position is used as the feedback. To be sure of making decisions about the value of the inertia weight, the last two steps during the course of run are analyzed. When a particle successes in some sequential steps, it will have more tendency to memorize its direction. Probably because it will have more successes in this direction. When a particle does not succeed in some sequential steps, it has less tendency to memorize its previous direction. Probably because it will have no more success in this direction.The success of particle i at iteration t+1 in a minimization problem is defined as:(17)δi(t)=1iffit(xi(t+1))<fit(Pit)−1elseFig. 1shows two different situations in which a particle of PSO may succeed during the search. When the Particle's best positions in the last two iterations are close to each other, making decision about memorizing the direction becomes more confident; so the value of the inertia weight changes greatly. In Fig. 1(a), increasing the inertia weight in large amounts results in fast convergence. When two Particle's best positions in last two iteration are not close to each other, making decision about memorizing the direction becomes less confident; so the value of inertia weight changes less. In Fig. 1(b), increasing the inertia weight in small amounts results in fast convergence. If in some sequential steps there is not any improvement in the particle's best position, the inertia weight changes will be the opposite of the previous situation. Based on the above discussion, we introduce Eq. (18) for determining the inertia weight:(18)Wij(t+1)=min1,wij(t)+(1−w0)×exp(xij(t+1)−Pbestij(t))2−2σ2+εif(δi(t)>0andδi(t−1)>0)max0.1,wij(t)−w0×1−exp(xij(t+1)−Pbestij(t))2−2σ2−εif(δi(t)<0andδi(t−1)<0)wij(t)elsewherewij(t+1)is ith particle's inertia weight in the jth dimension, in (t+1)th iteration.w0is the initial inertia weight which is considered equal for all particles in all dimensions. xij(t+1) is the ith particle's position in the jth dimension, in the (t+1)th step. Pbestij(t) is the ith particle's best position in the jth dimension until the (t+1)th step. The Gaussian kernel width (σ) is adjusted in a way that covers the maximum particles’ movement. ɛ is a small positive number (e.g. ɛ=0.005) used to ensure proper increase or decrease of the inertia weight. Its value is not critical. The velocity of the particle is updated according to the sum of three vectorsvi(t),(Pi−xi(t))and (Pg−xi(t)) with their scaling parameters equal tow,R1c1and R2c2. In the worst situation, the value of epsilon scalesvi(t)with 0.005 (constant value as mentioned in this study), but the social learning and cognitive learning vectors are scaled randomly within the range [0,2] by R1c1 and R2c2. Thus, the influence of epsilon is covered by these random numbers.The range of the inertia weight ([wmin,wmax]) is selected to be [0.1, 1]. In the stability analyses in [12,13], the PSO algorithm's stability is proved by Eq. (19). When the inertia weight changes adaptively, it is necessary that the acceleration constants change during the run, too. Otherwise, the following condition will not always be satisfied:(19)1−ωij(t)≥02ωij(t)+2−R1c1,ij(t)−R2c2,ij(t)≥0If similar to [4], the constants c1 and c2 are set equal to each other, the following equation for computing the acceleration will always satisfy the stability condition:(20)c1,ij(t)=c2,ij(t)=cij(t)=ωij(t)+1where cij(t) is ith particle's acceleration in the jth dimension that should be computed in iteration t. In the next section, we will show the appropriateness of the feedback parameter and the proposed inertia weight model at a given iteration during a course of run. The overall structure of the local best PSO algorithm is shown in Fig. 2. This basic PSO is used to clearly show the influence of the inertia weight determination model. The local best topology is selected because it maintains diversity of the swarm better than the global best topology.In order to test and compare different inertia weight strategies reviewed in this paper, a suit of commonly used static test functions and moving peaks benchmark (MPB) as well as a real-world problem for a radar system design are used. Static problems are used to investigate the convergence speed and solution quality of the methods while the dynamic problems are used to evaluate the ability of the methods in tracking the extrema points in a dynamic environment.Dynamic problems are more challenging for adaptive inertia weight strategies since after the convergence of the particles on peaks, the peaks may move and the algorithms should be able to speed up the particles to move toward the new positions of the peaks and then slow them down to refine the results.To investigate the performance of the optimization algorithms, 22 test problems are adopted in this paper. Table 1provides a detailed description of unimodal and un-rotated multimodal problems and Table 2gives a detailed description of rotated multimodal problems and composition problems. The first 8 functions are unimodal functions while the rest of the functions are multimodal optimization problems. Unimodal functions f2, and f4–f8 have asymmetric environment. In Table 2, the same method as that in [32] is used to generate the orthogonal matrix (M). All the selected problems are minimization problems. For each of these problems, the best solution (X*), the best fitness and dimensions considered for functions are shown in Tables 1 and 2.In order to evaluate the extrema tracking performance of the proposed inertia weight, dynamic test functions are generated using the MPB. MPB is a widely used benchmark problem proposed by Branke [51]. The parameters applied to MPB are given in Table 3.In the dynamic test functions, it is important to detect the environmental changes; so a method that detects environmental changes and refreshes particles’ memories are needed. If particles’ memories are not updated, they will not have the ability to track the extrema [52]. The method which is considered for detecting environmental changes is re-evaluating the global best particle before updating the global best particle. If its fitness changes, it indicates that an environmental change has occurred [53].In this section, a 20-dimensional spread spectrum radar polyphase code design problem in dynamic environments is introduced. This problem has been used in a noise-free static environment before [54,55]. Pulse compression technique is the most widely accepted technique in radar systems. The problem is a continuous min-max global optimization problem with numerous local optima. The min-max model is defined as(21)Globalminf(x)=max{ϕ1(X),ϕ2(X),…,ϕ2m(X)}where X={(x1, x2, …, xD)∈RD|0≤xj≤2π}, m=2D−1 and ϕ(X) isϕ2i−1(X)=∑j=iDcos∑k=|2i−j−1|+1Jxk+Nk,i=1,2,…,Dϕ2i(X)=0.5+∑j=i+1Dcos∑k=|2i−j−1|+1Jxk+Nk,i=1,2,…,D−1ϕm+i(X)=−ϕi(X),i=1,2,…,m(22)Noise={(N1,N2,…,ND)∈RD|−0.5≤Nj≤0.5}where Noise changes in every T function evaluations. Any change in Noise is introduced as environmental change. In each environmental change, T is a random number between 2000 and 5000. Thus, it is unknown that how long the algorithm needs to search the parameters under new conditions. Detection of environmental changes and refreshing the particles’ memories is done as discussed in Section 4.2.In all the experiments conducted in this paper, the number of particles in the swarm is 20 and the maximum allowed number of function evaluations is 200,000. The range ofw([wmin,wmax]) for SAIW is [0.1, 1] and the initial value for all particles is 0.729 [16,17,56]. The parameters of other algorithms are set based on the recommended values in their corresponding references. The results of all experiments are averaged over 30 independent runs.In this section, the proposed strategy (SAIW) is compared with some other adjusting inertia weight models. In the first subsection, the stability of SAIW will be analyzed in two static problems with symmetric and asymmetric environments. Then the results are extended to the other problems. In the second subsection, different inertia weight adjusting strategies, including SAIW, are applied to static problems and MPB; then the results are compared based on the final accuracy and the convergence speed. In the third subsection, SAIW is integrated with some recently published PSO variants and the resulting methods are applied to static problems and the radar system design problem.Stable PSO often performs better than an unstable PSO [57]. The upper border stability limit (USL) map will be used to analyze the stability of the SAIW [12]. Every optimization algorithm has a specific USL map for each benchmark considering the way it adjusts the parameters and uses random distributions. The best algorithm performance results if the parameters are tuned close to the optimum area in the USL map [12], although it does not guarantee an optimal solution for different problems.To generate the map, first, the possible values for accelerations and inertia weight are determined in a way that they do not refute the stability condition. Then, these values are divided into specific intervals. The best fitness of the algorithm in these intervals are averaged for 50 independent runs and the normalized average is shown in the map. The distance is considered equal to 0.1. Fig. 3shows the USL map for the two functions Rosenbrock (f5) and Sphere (f1).In this figure,E(w)is the mean inertia weight and E(phi) is the mean acceleration. Using the adaptive inertia weight and adaptive acceleration, the USL map of SAIW has a wide optimum area. If the optimum area is wide, the inertia weight and acceleration will be in this area with a higher probability. Then the performance is optimal in most of the iterations. For example, in Fig. 4the mean of inertia weight, acceleration and the final best value for functions Sphere (f1) and Rosenbrock (f5) are shown. The inertia weight mean and the acceleration mean for these two functions are in the optimum area of their corresponding USL map. Similarly, it can be concluded that the proposed strategy for all of the functions usually selects the inertia weight and acceleration in the optimum area of that problem's corresponding USL map.From all strategies introduced in the previous sections, six strategies are adopted in this study for comparisons: Fine Grained Inertia Weight(FGIW) [2,58], Double Exponential Self-adaptive Inertia Weight (DESIW) [2], Rank-based Inertia Weight (Rank-based) [4], Adaptive Inertia Weight (AIW) [4], Linear Decreasing Inertia Weight (LDIW) [5], Chaotic Descending Inertia Weight (CDIW) [40].The six inertia weight strategies and SAIW are applied to the static test functions. The mean, standard deviation and the best fitness value found by each method are recorded in Table 4. The bold numbers in this table indicate the best solutions for functions according to a t-test with a significance level of 5%.Results indicate that the proposed strategy provides the best accuracy in 17 out of 22 test problems. This good performance results due to the adaptive nature of the inertia weight and acceleration in SAIW. By stability analyses done, the performance of the algorithm is the best one in most of the iterations. Although the algorithm's performance is comparable with those of the other successful algorithms in 5 out of 22 test problems, but SAIW could not sufficiently maintain the particles’ diversity, and thus produced a lower performance.A closer look at the convergence curves of different algorithms for some test functions (Fig. 5) provides more insight into their searching behavior. For most of the functions, the proposed strategy is better than other strategies and particles converge faster to the better value. In addition, inertia weight adjustment in different dimensions has greatly improved the convergence speed in asymmetric environments.The convergence curve in unimodal functions indicates that no matter how far the best particle is from the global optimum, the SAIW's convergence is continuous during a course of run. The convergence speed of the proposed method is also independent from the iteration number. In multi modal environments, keeping diversity is one of the reasons that the algorithms operate appropriately. The proposed method was able to keep diversity in most of the iterations, by adjusting acceleration parameters larger than one, increasing the inertia weight and using local best topology. For the multimodal functions, the horizontal regions of the SAIW curves appear due to the convergence of the algorithm to the optima.Discussions in the next section present more details about the operation of these inertia weight methods in the static environments.In this section, the seven inertia weight strategies are applied to the dynamic test function defined in Section 4.2. The performance measures used to investigate the effectiveness of strategies are the current error and the offline error defined in [59]. Table 5lists the mean and standard deviation of the offline errors found by each method. The bold number indicate the best solution according to a t-test with a significance level of 5%. Based on the information presented in this table, the proposed method (SAIW) operates much better than other methods. The method uses adaptive inertia weight and adaptive acceleration. As a result, it can track the optima despite environmental changes and can converge to the optima better than the other methods. The method adjusts the inertia weight for each particle in each dimension. Thus after environmental changes, diversity increases to improve the ability of tracking the optima.LDIW and CDIW methods use no feedback for adjusting the inertia weight. In these methods, the inertia weight is initially about 1 and in the final iterations, it is about 0.4. Although they could converge to better values in the last steps, because of the big inertia they could not converge to the appropriate value in initial steps; so they do not have the ability to track the optima. The CDIW method has a better performance in comparison to LDIW, because the chaotic parameter in this method randomly increases or decreases the inertia weight in a limited range. Fig. 6(a) and (b) shows the best fitness values of these methods for different iterations.The other methods use feedback to adjust the inertia weight. The number of fitness computations for changing the environment is set to 3000 so that the convergence speeds become comparable. The Rank-based method adjusts the inertia weight for each particle similar to the proposed method. This method has some particles with appropriate inertia weight that can increase the diversity after each objective function change, but it cannot adjust the suitable inertia weight for all of the particles. It sets the inertia weight of half of the particles to a value larger than 0.5. So, this approach needs more function evaluations when improving the convergence ability is needed.Since the AIW method sets the acceleration parameters to 2 and uses the success rate feedback, it can easily increase the diversity and improve the ability of tracking the optima when the environmental change occurs. But in situations where the particles are close to the optima, a high convergence ability is desired, while the success rate will approximately be zero. This happens since most of the particles cannot improve their fitness. Thus, the algorithm operation will depend on the acceleration and the diversity increase is more probable. This operation happens frequently for narrow and asymmetric peaks; so the algorithm needs more function evaluations.The FGIW method highly decreases the inertia weights of the particles which are close to the global best particle, and slightly decreases the inertia weights of the particles which are far from the global best particle. But this method uses a Gaussian kernel for computing the distance which has a large standard deviation close to the maximum number of iterations at the beginning. It does not matter how far the particles from each other are, the inertia weight of all of the particles will be about 0.4 due to the extremely large standard deviation at the beginning of a run. From this point on, since there is no mechanism for increasing the inertia weight, the particles will continue searching with the constant inertia weight of 0.4.The DESIW method is similar to the FGIW method, with the only difference being in determination of the Gaussian kernel standard deviation. This method's standard deviation is initially small and becomes very large in the final steps. DESIW adjusts the inertia weight properly at first; but after several iterations, by increasing the standard deviation of the kernel, the performance index becomes zero and the Gompertz function sets all of the particles’ inertia weights close to 1. Therefore, this method can track the optima in initial iterations, but its convergence ability is low. After several iterations, it loses the ability of tracking the optima. Fig. 6(c) shows the performance of this method.In this section, five state-of-the-art PSO algorithms are selected for integration with SAIW: Comprehensive Learning PSO (CLPSO) [32], Orthogonal Learning Local PSO (OLPSO-L) [34], PSO algorithm with Adaptive Inertia Weight (AIWPSO) [4], PSO with an Aging Leader and Challengers (ALC-PSO) [18], Low-discrepancy Sequence Initialized Particles and High-order Nonlinear Dynamic Varying Inertia Weight (LHNPSO) [44].These PSO algorithms are applied to the static test functions with and without SAIW. Table 6lists the mean, standard deviation and the best fitness value found by each method. The bold numbers in each column indicate the best solutions for each method according to a t-test with a significance level of 5%.Results show that the best accuracy in 15 out of 22 test problems is obtained when CLPSO is integrated with SAIW. Similarly, 21 out of 22 test problems and 17 out of 22 test problems have the best accuracy when OLPSO-L and ALC-PSO are integrated with SAIW. This good performance results due to the adaptive nature of the inertia weight in SAIW. Preservation of diversity in CLPSO, OLPSO and ALC-PSO is one of the reasons that the algorithms operate appropriately. The proposed method was able to balance between exploration and exploitation properly when it was integrated with the above methods.SAIW leads to efficiency improvement for AIWPSO, especially on unimodal functions; but its performance is comparable on multimodal functions, since AIWPSO is affected by mutation. From the exploration/exploitation perspective, the mutation in this method firstly plays exploration role and plays exploitation role at last. Thus, original method loses time because of undue exploration in unimodal function.SAIW did not make any improvement in the performance of LHNPSO. The difference between LHNPSO and the standard PSO is in the way the inertia weight is adjusted. The inertia weight in the LHNPSO method is in the range [0.4, 1]. Thus, the particles’ diversity in this algorithm is maintained for a longer period in comparison with LHNPSO using SAIW.The mentioned PSO algorithms are applied to the radar system design problem defined in Section 4.3. Then the results of the algorithms before and after integration with SAIW are compared based on the offline accuracy (μ) defined as(23)μ=1K∑i=1Kfiwhere fiis the best solution obtained by an algorithm just before the ith environmental change and K is the total number of environments. Table 7lists the mean and standard deviation of the μ found by each method before and after integration with SAIW. The bold numbers in each column indicate the best solution according to a t-test with a significance level of 5%.Results indicate that SAIW leads to efficiency improvement for CLPSO and OLPSO-L. This model, however, cannot change the performance of AIWPSO, since it is affected by mutation. In consequence, the inertia weight has low effect on this algorithm. The inertia weight model used in this algorithm is compared with SAIW in Table 4.Due to the assumed value for the challenge parameter in ALC-PSO and fast environmental change, the ALC-PSO executes the aging challenge for two or three times. Hence, its performance is similar to the standard PSO. In this algorithm, the particles’ diversity decreases very fast and SAIW cannot increase the particles’ diversity due to very high diversity decreasing pressure. LHNPSO is the standard PSO. Thus the problem of fast diversity decrease still exists. But there is a difference: the inertia weight in LHNPSO varies between 0.4 and 0.7. The particles’ diversity in the original algorithm is maintained for a longer period in comparison with LHNPSO using SAIW. Thus in this complex multi-modal problem, SAIW could not improve the results of LHNPSO.

@&#CONCLUSIONS@&#
The balance between global and local search throughout the course of a run is critical to the success of an optimization algorithm. In the PSO algorithm, the inertia weight is introduced for higher balance between the global and local search. When the inertia weight changes dynamically, the search capability is also adjusted dynamically. Many different strategies have been proposed for determining the value of the inertia weight, among which, adaptive approaches were selected for development. Adaptive approaches do not show the limits of have other approaches and can adjust the value of the inertia weight by using appropriate feedback. Adaptive approaches have some shortcomings in selecting proper feedback and disregarding the stability conditions. By changing the inertia weight adaptively, stability conditions change adaptively, too.This paper proposed a new adaptive inertia weight strategy based on the success of particles in the last two iterations and the displacement of its best position. Each particle's situation in the swarm affects the adjustment of the inertia weight. Thus, in the proposed method, each particle has its own inertia weight in different dimensions. In addition, acceleration coefficients are adaptively adjusted with the help of inertia weight and stability condition.Experimental results clearly show the superiority of the proposed model over other inertia weight adjusting models. The comparisons are made in terms of convergence speed and solution accuracy. This method's good experimental results are due to adaptive nature of the inertia weight and acceleration of each particle. With regard to stability analyses in most of the iterations, the proposed algorithm has the best performance. Also it is possible to use a different method for adjusting acceleration adaptively, so that in addition to satisfying the stability condition, it would have more effect on keeping the diversity, if needed.