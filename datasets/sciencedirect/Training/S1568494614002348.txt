@&#MAIN-TITLE@&#
A guided data projection technique for classification of sovereign ratings: The case of European Union 27

@&#HIGHLIGHTS@&#
We consider the problem of sovereign rating from an ordinal regression perspective.A pairwise class distance based projection is considered together with a SVR algorithm.The projected regression estimations are used to visualize and analyse the different countries in a continuous scale.

@&#KEYPHRASES@&#
Ordinal regression,Ordinal classification,Country risk,Sovereign risk,Rating agencies,Financial crisis,

@&#ABSTRACT@&#
Sovereign rating has had an increasing importance since the beginning of the financial crisis. However, credit rating agencies opacity has been criticised by several authors highlighting the suitability of designing more objective alternative methods. This paper tackles the sovereign credit rating classification problem within an ordinal classification perspective by employing a pairwise class distances projection to build a classification model based on standard regression techniques. In this work the ϵ-SVR is selected as the regressor tool. The quality of the projection is validated through the classification results obtained for four performance metrics when applied to Standard & Poors, Moody's and Fitch sovereign rating data of U27 countries during the period 2007–2010. This validated projection is later used for ranking visualization which might be suitable to build a decision support system.

@&#INTRODUCTION@&#
The sovereign rating industry is relatively new and has rapidly grown since Standard & Poors (S&P) published the first ranking of sovereign issuers in January 1961, followed by Moody's in 1974 and Fitch in 1994. Rating the creditworthiness of sovereign issuers has drawn growing attention due to the fact that the national governments are by far the largest borrowers in capital markets, outnumbering 60% of debt issued [1]. Sovereign ratings are a condensed assessment of each government's ability and willingness to service its debts in full and on time [2], distilling a multitude of credit risk information into a single letter on a credit quality scale. The main advantage of the sovereign ratings is the providing of a way of comparing investment and their credit quality to international private investors due to “the lack of consistent standards on government accounting across borders” [1]. Furthermore, in the framework of Basel Accords [3], they play a public function in determining the capital requirements for banks, securities firms and insurance companies according their assets and liabilities [3]. In this way, the role of sovereign ratings in structured finances has been accentuated by both market and regulatory practices.The European debt crisis is a dramatic example of sovereign rating's role in the today financial market functioning and their economic consequences. The rating downgrade was focused on the so-called PIGS countries, i.e., Portugal, Ireland, Greece and Spain, but led significant spillovers across other European countries with solid macroeconomic and fiscal fundamentals [4]. As a result, the Eurozone financial markets have been under the pressure of the widening of sovereign bond and credit default swap spread, threatening the very existence of the European Union [5].In the face of these developments, many policymakers and commentators have stated that Credit Rating Agencies (CRAs) precipitated the European crisis by the timing and extent of the downgrades [1]. Their critics highlight some of the disadvantages of the credit risk assessment process carried out by CRAs, such as their inherent conflict of interest within their business model or their adequacy of performance and lack of transparency [3].The “issuer-pays” model, which is the most common remuneration practice among CRAs, lends to business more than two thirds of their total revenues [3]. CRAs also publish unsolicited ratings [1], being considered less reliable and less accurate because they are based on publicly available data. Therefore, CRAs face a moral hazard problem, in which they have an incentive to overestimate the creditworthiness of the issuers and a restrain to avoid the loss of their credibility with the investors.Besides the above issue, several studies pointed out that CRAs provide different rating for the same entity [6] and the markets react differently to rating changes made by each agency [4]. These disagreements are more frequent for sovereign ratings than for corporate ones [7], between one or two notches in the finer risk-scale [6], and may be explained by the use of varying economic and non-economic factors and different weights on these factors, as well as the different methodologies [8]. Even though CRAs publish their rating methodologies, the precise models are not officially disclosed because of their business practice. In addition, the qualitative part of the rating approach makes it harder to identify the relationship between the assessment criteria and the resulting sovereign ratings [2], aggravating the problem of opacity in the rating process.In order to complement or replace human or institutions decisions, many statistical and machine learning techniques have been applied to financial and business issues [9–12]. In this sense, the sovereign rating problem is a multiclass classification problem in which the items require to be classified into naturally ordered classes. However, even though the ordered nature of most of the financial classification problems, most of the solutions apply nominal classification techniques. This paper deals with the problem of sovereign rating within an ordinal classification framework.Ordinal classification (also known ordinal regression) is often addressed by the so called threshold models [13]. These methods assume that ordinal response is a coarsely measured latent continuous variable, and model it as real intervals in one dimension. Some examples are the Proportional Odds Model (POM) [14], a large margin based algorithm [15] or the Support Vector Ordinal Regression (SVOR) [16]. Other approaches, such as the proposed by Frank and Hall [17], tackle ordinal classification by combining several binary classifiers. The method employed in the present work can be considered in threshold models category, although instead of trying to learn the latent representations of the patterns, this latent positions are imposed by a guided projection procedure called Pairwise Class Distances projection (PCD). The projection is build by considering the relative positions of the patterns in the input space regarding adjacent classes, so that the ordinal structure of the data is exploited for improving the quality of the dimensionality reduction process.The proposal is studied and validated based on a real sovereign rating dataset, which includes the rating assigned by the three leaders agencies to the 27 European Union countries during the period 2007–2010. The performance is compared to single-model state-of-the-art nominal and ordinal classifiers. Experimental results demonstrate the robustness of the method by using four ordinal classification performance metrics. In addition, the projected predicted values for unseen data are studied in the experimental section in order to interpret the classification and within class values of several EU countries.As a summary of our motivation, the main objectives of this paper are the following. First, and more generally, to provide a tool that can complement the rating provided by CRAs. Secondly, to address the sovereign rating modelling with an ordinal perspective, this is, to apply ordinal classification methods and ordinal performance metrics to the task of sovereign rating. Finally, to prove the usefulness of the PCD projection which is not only able to obtain a good classification performance, but also to place a pattern in a relative order within its class, which brings additional information to the predicted class labels that can be helpful for decision making tasks and data analysis. The rest of the paper is organized as follows. Section Machine learning state-of-the-art for sovereign rating briefly presents some related works, specifically highlighting machine learning methods applied to credit rating. Section Ordinal classification presents the problem formulation and the goals of ordinal classification, and also describes and analyses the PCD projection together with the associated classifier. In addition, the section provides basic background in Support Vector Machines (SVM) for the regression case. In the following section, the PCDOC algorithm is compared to other nominal and ordinal methods, and the model is internally analysed to provide additional information for potential decision makers. Final section ends with some conclusions.This section briefly presents the related state-of-the-art works. An in-depth study is out of the scope of the current paper, but there are several review papers regarding statistical and machine learning techniques applied to financial and business issues [9–12].In the accounting and finance domain, bankruptcy prediction and credit scoring are the two major research problems [11]. More related to the current work, sovereign debt rating issue is growing in attention of the machine learning scientific community, although most of the methodologies have been focussing on corporate bonds rather than on sovereign risk [18]. In the second case, to assess the ability of a sovereign to honour its debt, some works applied statistical techniques such as Discriminant Analysis (DA) [19–21]. In spite of the ease to explain behaviour of the statistical models, the issue with applying these methods to the bond-rating prediction problem is that the multivariate normality assumptions for independent variables are frequently violated in financial data sets [22], which makes these methods theoretically invalid for finite samples [23]. This justify the use of alternative methods such as machine learning ones. The literature recognizes the unsuitability of these approaches to deal with sovereign rating problem because they ignore the ordered nature of ratings and ordered response models have been later introduced to overcome this limitation [2,24–27].Machine learning methods have been applied to model sovereign ratings, e.g. Artificial Neural Networks (ANNs), which do not rely on parametric assumptions of normality of data, independence of the explanatory variables, stationary or sample-path continuity. The better performance of ANNs compared to previous statistical methods have been highlighted by Cosset and Roy [28], Cooper [29], Yim and Mitchell [30] and Benell [18], among others. Although this approach is not without its problems, such as the risk of over-fitting, the difficulty entailed in defining the physical structure of the network, and the tendency to fall into local optima [31]. Support Vector Machines (SVM) [32,33] have being widely used for financial problems in the recent years [11], for instance the standard SVM classifier has been applied to financial time series forecasting [34] or to corporate credit rating prediction [35]. Later, new SVM models have been evaluated for credit scoring, for example, weighted SVM models such as the Least Squares SVM (LSSVM), where the hyper-parameters selection and training are based on the Area Under receiver operating characteristics Curve (AUC) maximization [36]. Yu et al. present a modified LSSVM to consider the prior knowledge that different classes may have different importance for model building so that more weight should be given to important classes [37]. Finally, soft computing techniques have been considered for financial problems. For instance, bank performance prediction were tackled with fuzzy SVM models by Chaudhuri and De [38] or with ensemble systems by Ravi et al. [39]. In addition, hybrid machine learning approaches have been applied to credit scoring [40] and bank rating [41].However, most of the machine learning works deals with the problem as a binary classification problem, because several classifiers, such as SVM, are naturally designed for binary classification tasks. This would limit the applicability to evaluate credit as ‘risk’ or ‘non-risk’. More recent approaches not only use a multi-class focus, but a limited number of them also consider an ordinal perspective of the problem. Van Gestel et al. [42] propose a whole process model to develop rating systems. In this work the classifier side is implemented by adding SVM terms to the linear model of the ordinal logistic regression so that the final model is both accurate and readable.This section presents the formulation of the ordinal classification problem, highlighting how threshold models work and presenting some state-of-the-art ordinal classifiers. Then, the PCD projection and the PCD based classifier are presented. Next, for clarifying purposes, the PCD projection is explained by using two of the input variables of one of the datasets considered in this paper. The last subsection is devoted to present the Support Vector Machine for regression, since this is the regressor selected for the experiments.When ordinal regression problems are tackled, the main objective is to map an input space,X, to a finite set,C={C1,C2,…,CQ}, by using a mapping functionϕ:X→C. The important point is that the label set has an order relation C1≺C2≺…≺CQ, where the symbol ≺ denotes the given order between different ranks. For each label, the rank is defined asO(Cq)=q, i.e. the position of the label in the ordinal scale. Patterns are represented by a set where each element contains a K-dimensional feature vectorx∈X⊆ℝKand a class labely∈C. The training dataset T is composed of N patternsT={(xi,yi)|xi∈X,yi∈C,i=1,…,N}, with xi=(xi1, xi2, …, xiK).Considering the above definitions, ordinal classification is different from nominal classification in the evaluation of the classifier performance and also in the fact that the classifier should exploit the ordinal data disposition. For the former, as an example, although accuracy (Acc) has been widely used in classification tasks, it is not suitable for some type of problems, such as imbalanced datasets [43] (very different number of patterns for each class), and ordinal datasets [44]. Then, the performance metrics must consider the order of the classes so that errors between adjacent classes should be considered less important than the ones between separated classes in the ordinal scale. In our sovereign rating example, a misclassification predicting class C3 (Strong payment capacity) when the real class is C1 (Highest quality) should be more penalized than the case when the prediction is C2 (High quality). For this issue, some specific ordinal performance measures are needed [45,46] (see Section Ordinal classification performance metrics for measures definition). On the other hand, according to Hühn and Hüllermeier [47], the nature of the problem implies that the class order is somehow related to the distribution of patterns in the space of attributesX, and therefore the classifier must exploit this a priori knowledge about the input space.Different approaches have been proposed for addressing ordinal classification. For example, Kramer et al. [48] map the ordinal scale by assigning numerical values. Other alternative is to transform the ordinal classification problem into a nested binary classification problem [17,49], and then classification predictions are obtained by combining the results of the binary classifications. These methods can be regarded as general frameworks that can adapt any generic classifier to the ordinal classification methods. Frank et al. [17] propose A Simple Approach to Ordinal Regression (ASAOR), a general method that enables standard classification algorithms to make the use of order information in attributes. For the training process, the method transforms the Q-class ordinal problem into Q−1 binary class problems. More sophisticated schemes are applied in other works, for instance, Li and Lin [50,51] derive the Extended Binary Classification (EBC) framework and apply it to SVM, naming the method to as EBC(SVM).Other approaches are the commonly called threshold models. The current work relies in this kind of models. These methods assume that ordinal response is a coarsely measured latent continuous variable, and model it as real intervals in one dimension. Based on this assumption, the algorithms seek a direction in which the samples are projected and a set of thresholds that divide the direction into consecutive intervals representing ordinal categories. This approach is the most widely used for ordinal classification [13]. From a statistical background, one of the firstly proposed threshold methods is the Proportional Odds Model (POM), specifically designed for ordinal regression [14].Gaussian Processes for Ordinal Regression (GPOR) [52] presents a probabilistic approach to ordinal regression based on Gaussian processes where a threshold model that generalizes the probit function is used as the likelihood function for ordinal variables. SVM have also been adapted to fit into this generic form of threshold models. Chu et al. [16], proposes two new support vector approaches for ordinal regression, Support Vector Ordinal Regression (SVOR) where multiple thresholds are optimized in order to define parallel discriminant hyperplanes for the ordinal scales. Two approaches are presented: SVOR-EX when the inequality constraints are explicitly added to the optimization problem, and SVOR with implicit constraints or SVOR-IM where the samples from different categories are allowed to contribute errors for each threshold.In this article, rather than learning the latent variable, direct hints are provided to the threshold model via a dimensionality reduction process that exploits the a priori knowledge of an ordinal space distribution of patterns in the input space. For each class, the distances of the patterns belonging to that class and to the adjacent classes are used. This projection is named to as Pairwise Class Distances (PCD), and the associated classifier using PCD is called PCD Ordinal Classifier (PCDOC). Here, PCDOC is implemented by using ϵ-SVR [33,53,54] as the base regressor.Threshold models consider the ordinal scale as the result of coarse measurements of a continuous variable, which is assumed to be difficult or impossible to be measured [13]. A threshold model is based on the following equation:(1)f(x,b)=C1,ifg(x)≤b1,C2,ifb1<g(x)≤b2,⋮CQ,ifg(x)>bQ−1,whereg:X→ℝis the function that projects data space into the 1-dimensional latent spaceL⊆ℝand b1<…<bQ−1 are the thresholds that divide the space into ordered intervals corresponding to the classes.In the PCDOC proposal it is assumed that a modelϕ:X→Lcan be found that links data itemsx∈Xwith their latent space representationϕ(x)∈L. For simplicity, b are fixed in opposition to other models such as POM. Instead of paying attention to the thresholds, the keys of the method are the projection procedure, which exploits the ordinal structure of the spaceX, and the explicit compression that the projection does on the margins between classes inL(see Analysis of the PCD projection with sovereign rating datasets section).This section explains the proposed guided projection and how it is used to train a generic regressor for performing ordinal classification.To describe the Pairwise Class Distance (PCD) projection, first, we define a measurewx(q)of “how well” a pattern x(q)11The notation x(q) will be used to indicate that pattern x belongs to class Cq.is placed within all the instances of class Cq. The goodness of its position is given by a function of the Euclidean distance between the evaluated pattern and the patterns in adjacent classes. On the assumption of an ordinal input space, patterns of adjacent classes may be closer than patterns of non-adjacent classes. The minimum distance from a patternxi(q)to patterns in the previous class (δp) is:(2)δpxi(q)=minxj(q−1)||xi(q)−xj(q−1)||,1≤j≤nq−1,where ||x−x′|| is the Euclidean distance between x and x′ and nq−1 represents the number of patterns of class Cq−1. And similarly, the minimum distance from a patternxi(q)to patterns in the next class (δn) is:(3)δnxi(q)=minxj(q+1)||xi(q)−xj(q+1)||,1≤j≤nq+1.Then, the measure of “goodness” of a patternxi(q)is defined as:(4)wxi(q)=δpxi(q)+δnxi(q)maxxj(q)δpxj(q)+δnxj(q),1≤j≤nq,where nqrepresents the number of patterns of class Cqand we setδpxi(1)=0andδnxi(Q)=0to keep into account the extreme classes. In this way, the sum of the minimum distances of a pattern with respect to adjacent classes is normalized across all patterns of the class, so thatwxi(q)has a maximum value of 1 for the best positioned pattern.Fig. 1shows the idea of minimum distances for each pattern with respect to the patterns of the adjacent classes, considering patterns of the second class. As an example, thewx(2)value is obtained for the pattern x(2) (marked with a circle).These values,wxi(q), are used to derive a latent variableli∈L. But, first of all, thresholds need to be fixed so the intervals onLwhich correspond to each class are delimited, and the calculated values for limay be correctly positioned. Moreover, in the test phase, predicted valueslˆiof unseen data would be classified in different classes according to these thresholds (see Section PCD based ordinal classifier) (which is indeed the way all threshold models work). For the sake of simplicity,Lis limited to the interval [0, 1], and the thresholds are uniformly positioned in this interval:(5)b={b1,b2,…,bQ}={1/Q,2/Q,…,Q/Q=1}.Consequently, the centres cqforLvalues belonging to class Cqare defined as:(6)c={c1,c2,…,cQ};c1=0,cQ=1,cq=q−1Q+qQ2,2≤q≤Q−1.A very intuitive idea is now considered to construct livalues for training inputsxi(q). Ifxi(q)has a high value ofwxi(q)(i.e. minimum distances δp and δn are quite similar), the livalue should be closer to ci(because the pattern is clearly well located within its class). If a low value ofwxi(q)is obtained (i.e. δp and δn are very different), this means that the pattern is closer to one of these classes, and the resulting livalue should be closer to the closest adjacent class, q−1 or q+1. The following expression is reflecting this idea:(7)li=ϕxi(q)=c1+(1−wxi(1))·1Q,ifq=1,cq−(1−wxi(q))·12Q,ifq∈{2,…,Q−1}andδp(xi(q))≤δn(xi(q)),cq+(1−wxi(q))·12Q,ifq∈{2,…,Q−1}andδp(xi(q))>δn(xi(q)),cQ−(1−wxi(Q))·1Q,ifq=Q,wherewxi(q)is defined in Eq. (4), and cqis the centre of class interval corresponding to Cq(see Eq. (6)). This expression guarantees that all l values lie in the correct class interval (the threshold vector b delimiting class intervals is defined in Eq. (5)). This methodology for data projection is called Pairwise Class Distances (PCD).Once the PCD projections have been obtained for all training inputs, this projection can be used to construct a classifier based on any regression tool. The regressor, g, will approximate the mapping from the input space to the PCD projections,g:X→L. In other words, a new training set is derived changing the target variable,T′={(xi,ϕxi=li)|(xi,yi)∈T}, where liis obtained from Eq. (7). This dataset is used to construct the regressor g. For the test phase, this regressor will be applied to obtain an estimated latent variable value,lˆ=g(x), and using the thresholds b in Eq. (5) and the general expression of the threshold model in Eq. (1), the predicted class labelyˆwill be obtained.It is expected that formulating the problem as a regression problem would help the model to capture the ordinal structure of the input and output spaces, and their relationship. In addition, due to the nature of the regression problem, it is expected that the performance of the classification task will be improved regarding metrics that consider the difference between the predicted and actual ranks or the correlation between the target and predicted ranks. Experimental results section confirm this hypothesis.For better understanding how the PCD projection takes advantage of the ordinal disposition of the data, two different input variables have been selected from the sovereign rating datasets of Section Data. Our objective is to show how the proposed projection works in a two dimensional representation. The variables selected are “GDP per capita” (PC_GDP) and “Government effectiveness” (GV_EFFECT), for years 2007–2009, their values being standardised. This selection is done because these variables are suitable for showing the ordinal structure of the data in the input space, not because of feature selection criteria, which is out of the scope of this paper. Fitch agency countries patterns labelling is used for this illustration example, as can be seen in Fig. 2. The figure shows that the data have a clear ordinal distribution through the input space, and how a separation in classes is difficult, some of them being clearly overlapped. It can be noticed the majority of patterns of each class are situated in regions of the space having adjacent classes patterns in neighbour regions.Fig. 2 presents the PCD concepts applied to the patterns in Fig. 2. The minimum distances are illustrated with lines of the same colour than the class. The minimum distance of a point to the next class patterns are marked with solid lines, while the minimum distances to the previous class are marked with dashed lines. For some example points (surrounded by a grey circle), the value of the PCD projection using Eq. (7) is shown near the point. It can be easily seen that the l value increases for patterns of the higher classes, and this value varies depending on the position of the pattern x(q) in the space with respect to the patterns x(q−1) and x(q+1) of adjacent classes.The Support Vector Machines (SVM) [32] are perhaps the most common kernel learning method for statistical pattern recognition. Initially formulated for binary classification problems, they have been extended for multi-class environments [55], ordinal classification problems [16] and for standard regression [54]. The later is explained in this section since it is the base regressor used in our proposal to model the PCD projection in the experiments.SVM are linear models with an optimization process that implicitly selects a subset of patterns for building the model. These patterns are named as support vectors. The first formulation of SVM is known as the hard-margin approach, but it presents the overfitting problem, which severally downgrades the generalization performance. In contrast, the soft-margin approach is achieved with the inclusion of slack-variables ξiin the optimization process [32], and it improves the performance of the model.The ϵ-SVR model is defined by the hyperplane given by:(8)f(x)=yˆ(x)=w·ϕ(x)+b,where ϕ is a mapping function which transforms the patterns representation in the attributes or input spaceXto a high dimensional Reproducing Kernel Hilbert Space (RKHS). The reproducing kernel function is used, defined as k(x, x′)=〈ϕ(x)·ϕ(x′)〉, where 〈·〉 denotes inner product in the RKHS. This transformation is known as the kernel trick and it allows to overcome the limitations of linear models. The most common mapping function is the Gaussian kernel, defined as:k(x,x′)=exp−γ‖x−x′‖2where γ is a parameter associated with the width of the Gaussian kernel.The model training consist on finding the weight vector w that minimizes the following regularized error function:C∑i=1NEϵ(yˆ(xi)−yi)−12‖w‖2.whereyˆ(xi)is given by Eq. 8 and Eϵis the ϵ-insensitive error function proposed by [56]:(9)Eϵ(yˆ(x)−y)=0,if|yˆ(x)−y|<ϵ|yˆ(x)−y|−ϵ,otherwise.The Eϵfunction gives zero error if the absolute difference between the predictionyˆ(x)and the actual target y is less than ϵ (being ϵ>0) and it produces more sparse solutions that other functions such as the quadratic error function which is widely used in regression problems [57].The optimization problem can be reformulated by introducing slack variables. For each point xitwo slack variables are needed (ξi≥0 andξi*≥0, where ξi>0 corresponds to a point for which target valueyi>yˆ(xi)+ϵ, andξi*>0corresponds to a point for whichyi<yˆ(xi)−ϵ).A target point lies inside the ϵ-tube ifyˆi(xi)−ϵ≤yi≤yi+ϵ. The inclusion of the slack variables allows points to lie outside the tube provided that the slack variables are non-zero. The corresponding conditions are:yi≤yˆi(xi)+ϵ+ξi,yi≥yˆi(xi)−ϵ−ξi*.At this point, the error function for support vector regression can be written as:C∑i=1N(ξi+ξi*)+12‖w‖2,which must be minimized subject to the constraints ξi≥0 andξi*≥0. The corresponding dual problem for minimizing this function implies using two kinds of Lagrange multipliers (αiandαi*). More details can be found in [57].Finally, predictions of new inputs can be expressed in terms of the kernel function:y(x)=∑i=1N(αi−αi*)k(x,xi)+b,where αiandαi*are the Lagrange multipliers.To conclude this section, Fig. 3shows different ϵ-SVR models for several ϵ values on an artificial regression dataset. The figure shows the support vectors of the model. It can be observed how the ϵ simultaneously determines the suitable fitting of the model to the data, as well as the sparseness of the model.

@&#CONCLUSIONS@&#
In this paper, we have applied the PCD projection as a suitable methodology for data classification and validation. The robustness of the classifier is demonstrated using four performance metrics for comparing the PCDOC classifier to nominal and ordinal classifiers in the three main CRA's datasets. In most cases, the errors committed by the three models implies the misclassification of patterns in only one upper or lower class rather than several ranks in the ordinal rating scale. It supposes an advantage for decision making process based on scenarios considering sovereign ratings.On the other hand, the pattern by pattern analysis indicates that the set of explanatory variables has to be augmented with other qualitative variables for some countries. In this regard, the historical information about a country's economic performance could be completed with data on economic short and medium-term expectations, as a result projected rating would turn into forward-looking evaluation of the country's ability to honour its sovereign debt.This study can be extended in two different ways to increase the accuracy of the proposed models, once data comparable across countries and for periods of less than one year are available. First, by using quarterly or monthly data that provide more detailed information on the economic and financial developments in the context of the high volatility and the repricing of risk in financial markets. Secondly, by including data about country banking sector's exposures to sovereign debt and housing bubble that finally crystallize on the government's balance sheet.