@&#MAIN-TITLE@&#
Multi-channel Bayesian Adaptive Resonance Associate Memory for on-line topological map building

@&#HIGHLIGHTS@&#
MBARAM enables topological map building with little or no human intervention.Does not require high-level cognitive and prior knowledge to function in a natural environment.Multiple sensory sources are processes simultaneously crucial for real-world robot navigation.Results show capability of generating topological map online used for localization.

@&#KEYPHRASES@&#
Adaptive resonance theory,Bayesian,Robot navigation,Simultaneous localization and mapping,Topological map,

@&#ABSTRACT@&#
In this paper, a new network is proposed for automated recognition and classification of the environment information into regions, or nodes. Information is utilized in learning the topological map of an environment. The architecture is based upon a multi-channel Adaptive Resonance Associative Memory (ARAM) that comprises of two layers, input and memory. The input layer is formed using the Multiple Bayesian Adaptive Resonance Theory, which collects sensory data and incrementally clusters the obtained information into a set of nodes. In the memory layer, the clustered information is used as a topological map, where nodes are connected with edges. Nodes in the topological map represent regions of the environment and stores the robot location, while edges connect nodes and stores the robot orientation or direction. The proposed method, a Multi-channel Bayesian Adaptive Resonance Associative Memory (MBARAM) is validated using a number of benchmark datasets. Experimental results indicate that MBARAM is capable of generating topological map online and the map can be used for localization.

@&#INTRODUCTION@&#
With growth in robotics research, it is possible for autonomous robots to move in complex, unknown environments and execute assigned tasks with little or no human intervention. A human-friendly autonomous guided robot with little knowledge about its whereabouts can navigate safely within its environment in order to achieve certain goals [1]. It can construct a map of the environment based on its position and posture (mapping), and estimating its position and posture using a built environment map (localization). Building the representation of the map is crucial to autonomous navigation for improving map maintenance, map-based localization, and path planning in any given environment.In mobile robotics, representations of the world fall into three broad groups, i.e. metric maps [2], topological maps [3], and hybrid models [4,5] that combine both metric and topological information. In the metric mapping framework, the environment is represented as a set of objects with coordinates in a 2D space. The construction of the map is based on a grid occupancy or feature map approach [6]. In the grid occupancy approach, the environment is mapped as an array of cells. This approach however requires complex computation for feature matching which is not reliable for large environments. Pure metric map methods are vulnerable to inaccuracies in both map building and robot position estimation [7].In the topological framework, the environment is described by a collection of places linked by path [8]. Places are defined by information gathered from sensors placed in the environment, which is then stored in nodes. Some of the robot's odometry information, which is gathered while it travels from one place to another is stored in the links of the map. Therefore, a topological map is a sparse representation of the environment that only includes important places used for navigation gathered from sensor information, and connections between these places gathered from the robot's odometry information.One of the advantages of topological maps is they do not require a metric sensor model to convert sensor data into a 2D frame of reference [9]. However, topological maps lack the details found in an environment. To overcome these problems, hybrid approaches [10,11] that combine the topological and metric paradigms have been proposed to compensate for the weakness of each approach. A crucial aspect that restricts the practice of topological maps is the absence of consistence semantics associated with them. For example in [8], nodes are represented as places distinguished by sensor data, and edges as paths between places distinguished by control strategies. On the other hand, maps are constructed by partitioning a probabilistic occupancy grid into regions isolated by narrow paths based on a measure of local clearance [12]. In [13], grid map is transformed into a greyscale image and analyzed for retrieving the topological information. This method however requires massive memory allocation for the grid map storing. As an alternative, the generation of a straightforward topological map using the generalized Voronoi graph (GVG) is presented in [13,14].GVG is however susceptible in dynamic, large-scale environments with sharp-edged obstacles and it requires high computational resources for node extraction and matching. A thinning approach to construct a topological map from a binary grid map is proposed in [15]. Although this method requires less computational resources than the GVG method, the method is based on an existing grid map that limits its application in online map building [16]. Another important factor that impedes the application of the topological map is the online detection and recognition of topological nodes. While artificial landmarks such as wireless beacons, visual patterns, or reflective tape provide reliable recognition of a specific location, we have to consider the possibility of the artificial landmarks not available in unknown environments.Another area of research focused on emulating the biological systems thought to be the basis for mapping and navigation in animals. The hippocampus of rodents is one of the most studied brain regions of any mammal. Early work with rats identified place cells in their hippocampus that appears to respond to the animal's spatial location [17]. Some researchers have uncovered that beta oscillations occur during the learning of hippocampal place cell receptive fields in novel environments [18]. The aim of the Psikharpax project is to create an artificial robotic rat, driven by mapping and navigation algorithms that mimic place cells [19]. Other methods for biologically inspired navigation include RatSLAM [20,21], which builds a topological map with metric information by separating the topological and metric layer. This approach requires proper scaling of the map in advance and is unable to update efficiently during operation.In this paper, we present the Multi-channel Bayesian Adaptive Resonance Associative Memory (MBARAM) for online topological map learning and generation. Each topological node represents a particular region of the environment with location of the robot, while edges connect nodes and stores the robot actions and relative positions of connecting nodes. MBARAM is developed from the Bayesian Adaptive Resonance Theory (Bayesian ART) framework [22]. Despite several optimization algorithms [23–26] being used to solve the SLAM problem, we chose the ART framework for its fast, online, unsupervised learning abilities, and it has been used in explaining place cell learning [27]. In addition, ART addresses the stability-plasticity dilemma [28], which explains how the brain can both quickly learn to categorize information in the real-world and remember it, without forgetting previously-learned knowledge. With these advantages, the proposed method overcomes the problem of online detection and recognition of topological nodes. In addition, MBARAM handles and learn multiple sensory information simultaneously during the mapping process. MBARAM does not require a metric map, it performs self-learning, and maintains the topological map that makes it suitable for work in natural environments.The proposed method has a number of contributions. The first is an incremental and unsupervised learning method that enables map building with little to no human intervention. Next, it does not require high-level cognitive and prior knowledge to make it work in a natural environment. Third, it can process multiple sensory sources simultaneously in continuous space, which is crucial for real-world robot navigation. Finally, the ART architecture overcomes the stability-plasticity dilemma without forgetting previously-learned knowledge. This paper is organized as follows. Section 2 introduces the theoretical framework of the proposed online topological map building approach. The experimental setup and results are detailed in Section 3 with discussions in Section 4. Concluding remarks are finally presented in Section 5.MBARAM integrates the Bayesian ART [22] and an incremental topology-preserving mechanism. Bayesian ART is used as a learning framework for its ability to reduce category proliferation with better classification accuracy. The topology-preserving mechanism was used to construct a topological mapping, in which nodes are connected by edges. In addition, we modified the ARAM network [29] in becoming a multi-channel architecture. This enable it to learn multiple mappings simultaneously across multi-modal feature patterns from multiple sensors.The architecture of MBARAM consists of two layers, as shown in Fig. 1. The input layer is formed by multiple Bayesian ARTs to categorize multiple sensory sources as place regions (nodes) and transmit to the memory layer. In the memory layer, place regions (node) connects to one another by edge when transitions between regions are experienced. Each particular connection contains robot's orientation and bearing when the transition is happened whereas nodes represent distinct places of the environment.As mentioned in Section 1, the nature of MBARAM learning process is biologically inspired, but different from other biologically inspired method, such as RatSLAM [20]. The work in [30] used different techniques for online topological map building. Table 1shows the difference between MBARAM, RatSLAM and work in [30].MBARAM learns in an environment that is perceived from continuous sensory information provided by multiple sensors. The M-dimensional sensory information is transmitted to the Bayesian ART and the map learning undergo three main processes, i.e. node competition, node matching, and node learning. Details of the learning process is detailed in Section 2.1.2.In order to generate a topological map, a number of nodes are created that corresponds to the number of distinct regions determined by the robot, i.e. one node for each region. MBARAM incrementally produces nodes to represent the environment as multiple regions throughout the navigation. It is therefore possible to identify where the robot has already been through a simple comparison of the current sensory information with the nodes already in the topological map (online detection and recognition).In our topological map, nodes are defined as regions, in which perceptions are similar given the robot's position in the area. This method solves the point-of-view problem. The definition is obtained directly through Bayesian ART categorization of sensory information, the category of a perception corresponding to the place where the robot is positioned. Each node contains a multidimensional Gaussian distribution, with mean vectorμˆj, covariance matrixΣˆj, and a prior probabilityPˆ(wj). Table 2summarizes the content of the node in topological map.The network is initialized with three parameters: the maximal hypervolume SMAX, the initial covariance matrixΣˆinit, and initial prior probabilityPˆ(wj)init. Such node definitions are based solely on the robot's perceptual capacities and does not rely on a human definition of the place it is supposed to be. This makes places easier to recognize from sensory information.The learning algorithm grows its network from one node at the first perception. The topological map is continuously updated according to information from the robot's sensors. During learning, the Bayesian ART activates nodes in the topological map that learn recognition categories, or compressed representations of sensory information. These nodes compete with one another to choose the node that receives the largest total input. The winning node, WJis the node that has the highest match value, GJand satisfies the vigilance test.The algorithm consists of three main stages, i.e. node competition, node matching (vigilance test), and node learning.(1) Node competition: In this stage, all existing nodes compete with each other to represent an input pattern. The a posteriori probability of the jth node to represent the M-dimensional patternxis calculated as follows:(1)Mj=Pˆ(wj|x)=pˆ(x|wj)Pˆ(wj)∑l=1Ncatpˆ(x|wl)Pˆ(wl)where Ncatis the number of nodes andPˆ(wj)is the estimated prior probability of the jth node. The likelihood ofwjwith respect toxis estimated using all patterns that have already been associated with the multivariate Gaussian nodewj:(2)pˆ(x|wj)=1(2π)M/2|Σˆj|1/2exp{−0.5(x−μˆj)TΣˆj−1(x−μˆj)}whereμˆjandΣˆjare the estimated mean and covariance matrix of the jth node.If training involves K sensory channels, the Mjfor each node is:(3)Mj=∑k=1Kαk[Pˆ(w(j,k)|xk)](4)Mj=∑k=1Kαkpˆ(xk|wj,k)Pˆ(wj,k)∑l=1Ncatpˆ(xk|wl,k)Pˆ(wl,k)where(5)pˆ(xk|wj,k)=1(2π)M/2|Σˆj,k|1/2exp{−0.5(xk−μˆj,k)TΣˆj,k−1(xk−μˆj,k)}and αkinfluence factor for each channel and the sum of αkis 1.The winning nodeJis the one with the maximum a posteriori probability (MAP):(6)J=argmax(Mj)This proves that theJth nodewJis either more populated than other nodes (i.e. having highPˆ(wj)) or more likely to be the correct node forx(i.e. having highpˆ(x|wj)since it is the closest node tox) or both. Based on both probabilities and Bayes’ theorem [14], the MAP criterion is expected to choose a winning node more accurately than if using only one of the probabilities. For example, the MAP criterion may prefer a category having a priori probability which is higher than that of another node although the normalized by the covariance distance of the former to the pattern is larger than that of the latter.(2) Node matching (Vigilance Test): The node match is to ensure that the chosen node is able to represent the current environment where the robot is located. The test restricts the Jth node hypervolume SJto the maximal hypervolume allowed for a node SMAX:(7)SJ,k≤SMAX,kwhere the hypervolume is defined as the determinant of the Gaussian covariance matrix. For a diagonal covariance matrix, this hypervolume is reduced to the product of the variances each for a dimension:(8)SJ,k≜det(ΣJ,k)=∏d=1MσJd,k2If the winning node fulfills the vigilance criterion in Eq. (7), learning is then performed. The edge connecting the winning node and previous winning node is updated as well. However, if both nodes are not connected, then a new edge is created to link both nodes and store their adjacent angle. If the winning node fails the vigilance criterion, the node is removed from the competition for this sensory input and the Bayesian ART determines another node till one complies with Eq. (7).If all existing nodes in topological map fail the vigilance test, it means the robot is located at a new place. A new node that contains a mean vector which is the input pattern and an initial covariance matrix Σinitthat enables meeting Eq. (7) to represent this distinct place will be added to the map. A new edge is then created to connect the new node and previous winning node, and to store the adjacent angle between the two nodes.(3) Node learning: When a chosen node fulfills the maximal hypervolume criteria in Eq. (7), the node elements are then updated as follows:(9)μˆJ,k(new)=NJNJ+1μˆJ,k(old)+1NJ+1xk(10)ΣˆJ,k(new)=NJNJ+1ΣˆJ,k(old)+1NJ+1(xk−μˆJ,k(new))×(xk−μˆJ,k(new))T*I(11)Pˆ(wJ)=NJ∑l=1NnodeNl(12)NJnew=NJold+1where NJis the number of times thatJth node have been chosen as winner for learning before receiving the current input sensory information andIis the identity matrix.Thus, MBARAM incrementally produces the number of nodes necessary to learn and remember feature patterns for representing the explored environment as regions. The overall algorithm for topological map building is summarized in Algorithm 1.Algorithm 1Algorithm for MBARAM Topological Map Building ProcessRequire:Sensor Data xCovariance MatrixΣˆPrior ProbabilityPˆ(w)Maximal Hypervolume SMAXEnsure:Nodes DEdges ɛInput the sensor data x.if No node in the TopoMap thenAdd x to the TopoMap as new node.D←Di∪{x}; Ni=0Update the weights of the nodeDi(N,μˆ,Σˆ,Pˆ(w))using Eqs. (9)–(12)elseDetermine the winner node using Eqs. 1–6Execute the vigilance test for the winner node using Eq. (7)if Vigilance test fulfilled:Swinner≤SMAXthenUpdate the weights of winner nodeD(NJ,μˆJ,ΣˆJ,Pˆ(wJ))using Eqs. 1–6if No edge between winner and prevWinnerthenAdd edge between the current winner and previous winner nodes ɛ←ɛ∪{winner, prevWinner}elseUpdate Edge that connecting winner and prevWinnerend ifelseReset the winner node and find a new winner from the TopoMap until it fulfill the vigilance testif All nodes are failed with vigilance test thenAdd x to the TopoMap as new node.D←Di+1∪{x}; Ni+1=0Update the weights of the nodeDi+1(N,μˆ,Σˆ,Pˆ(w))using Eqs. (9)–(12)Add edge between the new node and previous winner nodes ɛ←ɛ∪{prevWinner, newnode}end ifend ifend ifIn topological framework, one of the localization method is to search the node that encodes the sensory information the most similar to the current sensor data. Note that for direct comparison, each node of the map must be distinct with each other. In our proposed method, recognizing a node is performed by comparing the current sensor data with the information stored in each of the nodes. To do this, Eq. (1) is used to search for the best node, and vigilance test in Eq. (7) is to ensure that the encoded information of the node is capable to represent the current sensor data. Fig. 2illustrates the concept of the node localization. As mentioned in Section 2.1.1, each node of the map generated by MBARAM contains sensory information with the particular robot location. Therefore, all nodes of the map are unique for representing the environment, which helps to cope with perceptual ambiguities. Eq. (13) shows an example during the nodes comparison. The recognized node holds the highest value of Mjthat fulfilled the vigilance test.(13)Mj=Mjlaser front+Mjlaser back+MjodometryIn this section, the experimental setup and results obtained from the benchmark datasets simulation (Section 3.3) and physical robot implementation (Section 3.4) are detailed. The topological map forms by set of nodes and edges. Nodes are plotted as red color circle at the (x, y) coordinates in the stored position and edges are black color line that connecting all nodes in the map.For simulation experiments, the performance of MBARAM in a topological map construction was verified using various benchmark datasets. Several measures have been used to evaluate the quality of a topological map. A commonly used measurement is the quantization error, which measures the average distance between each data vector and its best matching unit (BMU). Here, the BMU is the winning node that has the highest match value and matches the vigilance parameter. Eq. (14) shows the calculation of the QE, where N is the number of data vectors andmx→iis the best matching node in the correspondingx→ivector:(14)QE=1N∑x→i−mx→ix→i(max)This error evaluates the fit of the topological map to the robot's actual path. Thus, the optimal topological map is expected to yield the smallest average QE. The smaller the QE, the smaller the average of the distance from the best-matching nodes to the robot's actual path, which means that the topological map is closer to the original path [31].Compression ratio (CR) is another measurement used to evaluate the map. It is defined as the ratio between the topological map generated by TGARAM and the robot's actual path and is calculated as shown in Eq. (15).(15)CR=Original robot's path sizeTopological map sizeThe benchmark datasets were downloaded from the Rawseeds Project, which aims to produce benchmarking tools for robotic systems. The project was funded by the European Commission under the Sixth Framework Programme and it has successfully created and published a high-quality benchmarking toolkit [32,33]. These datasets were used as training samples to validate our proposed method, supplemented by odometry and laser scanner datasets. Fig. 3a and b illustrates the locations available to the robot during Rawseeds data gathering. Several indoor and outdoor scenarios have been defined by Rawseeds that each generate a dataset.According to [22], the Bayesian ART maximal category hypervolume parameter was optimized over the range 10−8≤SMAX≤102. For diagonal covariance matrix case, each variance in the initial covariance matrix should be set to a small value to ensure that the node could grow and change its region during map learning [22]. We follow setup in [22] as the optimized values for the Bayesian ART parameters have been determined.First, we set the initial covariance matrix to be sphericalΣinit=σinit2I, where I is the identity matrix, hence the parameterσinit2≪(SMAX)1/M(7), (8) to confirm that the initial category hypervolume is much smaller than the maximal hypervolume allowed. Next, we set the maximal category hypervolume parameter value (SMAX) as 1. Then, we set the value of the initial parameter (σinit2≪11/682) to be two orders of magnitude lower than the maximal category hypervolume parameter which is 0.01. In addition, we set thePˆ(wj)initto 1 for making the mapping between a region deterministic instead of probabilistic.We have configured MBARAM to three channels for taking front and rear laser scanner data and odometry information in our experiments. Therefore, we set the importance factor α=0.4 for each laser scanner channel as the laser scanner is scanning the environment and the data is representing the environment, which is the main factor for map learning process. We set the importance factor α=0.2 for odometry channel as odometry information is used to cope with perceptual ambiguities and not representing the environment condition. Thus, odometry channel important factor must be lower than laser scanner channel. Table 3shows the parameters setting in our experiments.The learning algorithm was written in C++ and compiled with Xcode. In both simulation and physical robot implementation, we have configured MBARAM to three channel for taking front laser scanner data, rear laser scanner data and odometry information. Note that odometry information is involved in map learning because the information is to help to cope with the perceptual ambiguities. In the simulation experiment, we used the Rawseeds laser front dataset, laser rear dataset and odometry dataset for map learning. The procedures of map learning experiments as follow.•Configure MBARAM to 3 channels (k=1–3) and initialize its parameter value, such as α, SMAX,σinit2, andPˆ(wj)init.Input M-dimensional laser front data (xf=x1f,…,xMf) to channel (k=1), l-dimensional laser back data (xr=x1r,…,xlr) to channel (k=2) and robot odometry data (V=Vx, Vy, Vϕ) to channel (k=3) to MBARAM to activate map learning.MBARAM learning starts by adding one node (n=1) to the map that store the first laser front (μj=nk=1=xf), laser back data (μj=nk=2=xr) and robot starting location(μj=nk=3=V).For iteration (t), MBARAM obtains time-frame (t) sensors data.Then, calculate Mj,j=1,…,nin Eq. (4) using time-frame (t) sensors data and information that is encoded in all existing nodes to determine the node J that has the highest MJ(Node competition).Next, calculate winner node J hypervolume SJin Eq. (8) (Node Matching). If SJis larger than SMAX, update node J information using Eqs. (9)–(12) (Node update).Else, reset node J and repeat step 5.Calculate the adjacent angle between node J and previous winner node, and update the edge between them.If all SJless than SMAX, add a new node to store all time-frame (t) sensors data and robot location.Add edge to connect the new node (n+1) and previous winner node, and store the adjacent angle.Map building process stops when all time-frame sensors data are processed.For the physical robot implementation, MBARAM receives sensor data from front laser range finder, rear laser finder and robot odometry system that mounted on the robot. The setup is detailed in Section 3.4.All simulation results using the Rawseeds datasets is shown in Sections 3.3.1 and 3.3.2. For better understanding, part of the topological map learning and building process are illustrated in Figs. 4and 5. Fig. 4 shows that four nodes are generated when robot travel from place A to B, B to C, and C to D. Each node contains robot odometry information and sensory information that represent the particular region. Edges contain connected nodes angle information.In addition, the node learning process was illustrated in Fig. 5. As shown in Fig. 5, the robot has no knowledge about the environment when it was located at place A (no node in the topological map). Therefore, node 1 was added to the topological map. Node 1 stores the current laser scanners data and robot location (node adding). During exploration from A to B, node 1 is chosen as a winner and its information was updated based on received sensory information as it fulfilled the vigilance test in Eq. (7) (node matching and learning). However, sensory information was different half way which caused node 1 to be mismatched and failed the vigilance test (S1<SMAX). Therefore, node 2 was added to represent place B environment by storing sensory information collected at place B. A new edge was then added to connect node 1 and node 2. When robot traveled from place B to C, node 2 is selected to update its information based on received sensory information, as node 2 has the highest match value in Eq. (4) compared to node 1 (Node Competition) and node 2 also fulfilled the vigilance test. Finally, node 3 was added and updated when the robot reached at place C because node 1 and node 2 both failed the vigilance test, which means these nodes are unable to represent environment C. The map learning and building process continues until robot received instructions from human operator.In the first experiment, the odometry dataset and the front and rear laser scanner datasets were used as inputs. Fig. 6shows the exact path the robot took in different environmental conditions such as (from left to right) dynamic with natural lighting, static with artificial lighting, dynamic with artificial lighting, and static with natural lighting. Fig. 7illustrates MBARAM topological map learning result. Results showed all generated maps are almost identical to the robot exploration path. The map learning process is insusceptible to lighting conditions.Table 4summarizes the QE and CR of each topological map generated by MBARAM. Results showed that QE of each topological map are relatively small and almost similar because all datasets are gathered in the same environment. In addition, the maximum CR of the topological maps can reach to 224:1.As with the indoor datasets experiments, the same three channels were configured, i.e. odometry, the preprocessed front, and rear laser scanner dataset. The parameter settings are shown in Table 3. Fig. 8shows the exact robot navigation path for gathering datasets. Fig. 9illustrates the topological maps produced by the MBARAM. From the results, it is shown that the MBARAM was able to learn feature patterns from the outdoor and mixed datasets and produced topological maps that represent the environment.Results showed that the maximum CR can up to 150:1 which almost similar to indoor datasets learning despite the complexity of outdoor environment. In addition, the QE of each generated topological maps are relatively low. Therefore, the learning of MBARAM is stable for both indoor and outdoor environment. Table 5summarizes the number of nodes, QE and CR for each topological map. The number of nodes created in each map and is slightly higher than for indoor datasets because the areas explored are larger.After MBARAM generated topological map for each dataset, the sufficiency of the map for representing the explored environment is verified. In the first experiment, we input all three datasets (odometry, front, and rear laser scanner) to the corresponding map, and MBARAM determines the best matching node for node localization using Eq. (1). If the winning node's weight is matched with robot's current sensory information and fulfils the criterion (7), then the winning node is chosen for localized. Eqs. (16) and (17) are used for further localization validation. If the euclidean distance between the winning node and the robot current location is less than a threshold, the robot is localized successfully and vice versa.(16)Success localization=(xnode−xtarget)2+(ynode−ytarget)2<1(17)Fail localizationn=(xnode−xtarget)2+(ynode−ytarget)2>1In the second experiment, we input only the front and rear laser scanner to verify the localization rate without odometry information. Result of nodes localization for both experiments are shown in Fig. 10. With odometry information, the average of success rate of localization was approximately 97.4%, whereas without odometry information, the success rate was approximately 83.9%. The failure of localization for the first experiment is due to none of nodes in the map match with certain time step sensory information. However, sensory information that matched with topological nodes have similar content with these mismatch sensory information. Therefore, the overall performance is not affected by these mismatches. As in the second experiment, localization failures happened more often due to absence of odometry information which failed to disambiguate similar sensory information at different locations.The following experiments are conducted using an omni-directional robot, equipped with a Hokuyo UTM-30LX front laser scanner and an odometry system as shown in Fig. 11a. Signals from the sensors were sampled at 10Hz. All computation and logging was ran on-board on an Intel Core i5 1.4 GHz processor. The omni-directional robot typical operation speed is 0.1–0.5ms−1, it has obstacle avoidance and wall following capabilities.The experiments were conducted in an area as shown in Fig. 11b, located in an university laboratory corridor that is moderately populated during the day and night. The size of the environment is 5m×40m. The environment was by no means is static, with moving people, re-arrangement of furniture and equipment, changing door states, and lighting conditions. We set the experiment environment to be as natural as possible because we want to validate MBARAM is capable of dealing with random noise such as pedestrians and different object placements, without any assumptions or modifications, which is crucial for robot mapping research.Parameters for the robot system and MBARAM algorithms were set as follows: αodo=0.2, αlaser front=0.4 and αlaser rear=0.4; SMAX=1;σinit2=0.01andPˆ(wj)init=1.The first experiment was to drive the robot through the corridor, while collecting laser data and odometry for topological map construction. During exploration, the robot would automatically learn and build the map by recognizing whether the current sensory data corresponds to a node in the map. If the robot could not recognize the current sensory data, it meant the robot is located at new region, and a new node is added to the map for representing the new region. The robot will continue learning and update the map automatically until it receives instructions from operator.Next, the robot traversed the corridor five times to verify the environment learning and map building. The final topological map built by MBARAM contained 47 nodes for representing the explored environment as shown Fig. 12. Nodes are plotted as red color circles at the (x, y) coordinates in the stored position, where linked nodes are joined with edges (black color line). Each topological node contains robot odometry information and laser range finder weight that represent particular region. Edges provide adjacent angle between connected nodes. Then, the topological map was updating continuously for the remaining exploration. The map is not highly accurate in a Cartesian sense, but need not be for effective navigation.Fig. 13a shows the number of nodes added to the topological map for each traverse. During the first exploration, MBARAM has no knowledge about the environment, which causes it to detect many novel information and the 24 nodes were added to represent the places explored. However, the number of nodes added to the map decreased as the robot continued traversing the corridor. This is due to the topological map contains previously-learning knowledge about the environment after the first exploration, and this knowledge was used to detect new places or places that have been visited for the remaining traverses.Noted that, small amounts of nodes (5–6 nodes in this experiment) are added for the remaining traverse as the robot travel path and environment conditions (pedestrian and placement of objects) vary in each traverse. As such, MBARAM detected some novel sensory information and the map was updated according to the received sensor data. In addition, Fig. 13b shows that the compression results. Compression in this experiment refers to the number of nodes in map per traverse loop. The compression increases for each traverse as the robot receives 1146–1200 scans of sensor data (each loop), and total nodes in the map has small difference from second loop onwards (5 or 6 nodes difference). This proves that MBARAM is converging and capable of maintaining the map during exploration.The map learning is then verified by examining one of the node update process when the robot visited the same area again. Fig. 14shows one of the node learning process when the robot visits the same spot of the corridor for five times. As shown in Fig. 14, the sensory information varies despite the robot traveling to the same spot of the corridor. Thus, MBARAM selects and updates the node that encodes the sensory information that is most similar to the current sensor data to ensure that the topological map is up-to-date for representing the explored environment.After obtaining the topological map of the environment, we placed the robot at the starting point and then instructed the robot to traverse the corridor ten loops for robot localization verification. During navigation, the robot kept searching nodes in the topological map based on its current sensory information for localization. If the winning node's weight matched with robot's current sensory information and fulfilled (as in Eq. (16)), the robot is localized successfully and vice versa.In order to verify the advantages of taking multiple sensory sources, we enabled the robot to obtain odometry and laser scanner information for localization during the first five traverse. After the fifth traverse, we disabled the odometry channel and only laser scanner information fed to the robot. Fig. 15shows the result of robot localization for each traverse. The average of success rate of localization with odometry information was approximately 97.5%, while without odometry information, the robot was still capable of performing localization but the average rate was 86%. Results showed that localization rate is improved when robot obtained more than one sensory source.

@&#CONCLUSIONS@&#
A new network, MBARAM for topological map learning and building is proposed in this paper. It is an incremental and unsupervised learning method that overcomes the stability-plasticity dilemma, which explains how the brain can quickly learn to categorize information in the real-world, and to remember it without forgetting previously-learned knowledge. With odometry information, the proposed method can disambiguate similar sensory information which overcomes the problem of online detection and recognition during learning process. Thus, it does not require high-level cognitive and prior knowledge about the environment to produce a topological map in natural environments. Our method was validated using benchmark Rawseeds datasets and physical robot implementation. Experimental results proved that the proposed method is capable of processing more than one sensory source for map learning, which reduces error measurement effects caused by uncertain sensor data. The topological map provides sensory information, regions location, and traversability information that enables the robot to perform self localization and actions for navigation.In future work, we will utilize other sensor data such as images to improve the map reliability and usability. In addition, we will integrate path planning into MBARAM for robot to perform path planning and to fully utilize the topological map. More experiments in more complex indoor and outdoor environments with different parameters value will be conducted for further validation.