@&#MAIN-TITLE@&#
Medical image classification based on artificial intelligence approaches: A practical study on normal and abnormal confocal corneal images

@&#HIGHLIGHTS@&#
A new intelligent system to tackle the main challenges of confocal corneal imaging is developed.This system underpins the expertise of ophthalmologists.It provides clinically useful factors, saves a useful amount of clinician time in the process.It is able to model the stromal keratocyte cells for better evaluation and fast analysis.Early approval by corneal clinicians.

@&#KEYPHRASES@&#
Cornea,Confocal microscopy,Artificial neural network,Adaptive neuro fuzzy inference system,Texture features,Image classification,

@&#ABSTRACT@&#
Corneal images can be acquired using confocal microscopes which provide detailed views of the different layers inside a human cornea. Some corneal problems and diseases can occur in one or more of the main corneal layers: the epithelium, stroma and endothelium. Consequently, for automatically extracting clinical information associated with corneal diseases, identifying abnormality or evaluating the normal cornea, it is important to be able to automatically recognise these layers reliably. Artificial intelligence (AI) approaches can provide improved accuracy over the conventional processing techniques and save a useful amount of time over the manual analysis time required by clinical experts. Artificial neural networks (ANNs), adaptive neuro fuzzy inference systems (ANFIS) and a committee machine (CM) have been investigated and tested to improve the recognition accuracy of the main corneal layers and identify abnormality in these layers. The performance of the CM, formed from ANN and ANFIS, achieves an accuracy of 100% for some classes in the processed data sets. Three normal corneal data sets and seven abnormal corneal images associated with diseases in the main corneal layers have been investigated with the proposed system. Statistical analysis for these data sets is performed to track any change in the processed images. This system is able to pre-process (quality enhancement, noise removal), classify corneal images, identify abnormalities in the analysed data sets and visualise corneal stroma images as well as each individual keratocyte cell in a 3D volume for further clinical analysis.

@&#INTRODUCTION@&#
Confocal microscopy is a major advance in comparison with normal light microscopy since it allows the user to see not only deep into cells and tissues, but also to create images in three dimensions. The major difference in principle between the optics of a conventional microscope and that of a basic confocal microscope is the presence in the latter of a confocal pinhole, which allows only light from near the point of focus to reach the detector. The resulting advantage of a confocal microscope over a conventional microscope is the production of a series of images (in X–Y) at different depths (Z) in the object, less affected by out-of-focus information. Such a series of images (a stack) is a three dimensional representation of the object being viewed, produced by optical (as opposed to physical) sectioning [1].The corneal images employed in this work were acquired using a NIDEK Confoscan 4 microscope, which uses a confocal slit. Further details about these data sets are presented in Section 3.5. This microscope has the following main features. It has fully automated alignment and scan time is optimised to produce 350 images in around 15s. It has nine internal fixation targets for increased patient fixation stability and device performance. An optional Z-ring attachment is available for this microscope which increases the stability of the examination and the reliability of the Z-scan reference for accurate full thickness optical pachymetry. This feature offers an ability to define the position of any corneal structure and opacity with high precision [2].The main anatomical structure of the human eye is shown in Fig. 1. The cornea is the convex and transparent part of the front of the eye; it provides most of the focusing power required to form the image on the retina. The cornea is a complex 3D structure. It has three main layers separated by two thin membranes, which are (from the anterior to posterior): epithelium (thickness about 50μm), Bowman's membrane, Stroma (thickness about 400μm), Descemet's membrane, and Endothelium (thickness about 30μm). Injuries, dystrophies, and diseases can adversely affect the cornea and lead to visual impairment which can be as severe as complete blindness. Due to the development and increased availability of in vivo confocal microscopes, ophthalmologists can observe the living human eye in situ at the cellular level which overcomes some of the limitations of conventional light and electron microscopy [3].The confocal images can be used to construct three-dimensional models of the corneal layers as each image contains a slice of information acquired at a new depth. However, there are several challenges in the way of processing and reconstructing meaningful 3D models from corneal images. For example, the small movements of the eye during the scanning process due to respiration, cardiac pulse, and other factors cause images of adjacent layers to be displaced laterally (in X and Y) and axially (Z). Corneal images also contain significant amounts of noise and intensity variations both within and between images due to variation of illumination over the field of view and differences in reflectivity of the corneal layers. Accurate classification of the three main corneal layers is very important, as each of these layers has a unique structure which in turn requires an appropriate processing procedure to extract the information, which can benefit ophthalmologists (saving them evaluation time and provide some clinically useful factors/parameters) and hence patients. In addition, the classification of abnormal corneal cases is vital to aiding the detection of disease and identifying the affected layer as early as possible, which can lead to better treatment for the patient.The confocal microscope's generation of a large number of images per patient per scan, makes their analysis a challenging task for an ophthalmologist with a large number of patients in a busy clinical setting. Ophthalmologists could use an efficient system to reduce the analysis time and speed up the treatment process, by giving them the opportunity to look at individual layers on demand, leading to faster and more accurate diagnosis. For example, looking at the stroma layer in 3D could save time, as issues related to the keratocyte cells could be identified by analysing one figure instead of looking at the large number of individual images representing the stroma layer. Based on these ideas our research is aiming to develop a robust system able to analyse confocal corneal data sets, identify abnormalities associated with this data and offer easier clinical analysis through the 3D stroma cell presentation. This aim is to be achieved through the following objectives: first, an efficient pre-processing approach which enhances the quality of the processed confocal images, reduces the level of the noise in these images, and eliminates redundant images; second, an artificial intelligence approach to improve the recognition accuracy of the corneal images into one of the epithelium, stroma and endothelium layers; third, identify abnormalities in the analysed corneal data sets; fourth, 3D visualisation of the whole stroma layer as well as for each individual keratocyte cell for further clinical analysis. This would help the day to day clinical practice in a better understanding of common corneal pathologies of a certain layer in the cornea.The rest of this paper is organised as follows. Section 2 presents the current corneal state of the art research and clinical practices. Descriptions of the normal and abnormal data sets employed in the work, the research methodology as well as system development are presented in Section 3. Section 4 presents the practical implementation and the results achieved by automated analysis, abnormality analysis and image visualisation. Finally, Section 5 presents the conclusions.The existing literature on confocal microscope related corneal image processing and classification is rather limited and includes the following examples. The work presented in [4] on automatic recognition of cell layers in corneal confocal microscopy images is based on image binarisation followed by a description of cell shape obtained using Hu variables. An artificial neural network is employed to classify each image into the three corneal main layers in normal subjects. The resulting system was tested on 46 corneal images. The work presented in [5] addressed the problem of obtaining a 3-dimensional (3D) reconstruction of the cornea starting from a set of confocal microscope images by producing an image stack. Here a registration procedure based on normalised correlation is applied to each image. This method was intended to overcome the effects of eye movements which occur during image acquisition. Removing these shifts in image X and Y directions, a 2D image stack is reconstructed.In the work presented in [6], a programme was written to calculate the cell densities in confocal images obtained from two types of confocal microscopes: the ConfoScan 4 (Nidek, Inc., Freemont, CA), and the Tandem Scanning confocal microscope (Tandem Scanning Corp., Reston, VA). The densities obtained were compared with those obtained manually. This programme corrects the large non-uniformity in brightness across the acquired images by subtracting from each an image of a uniformly scattering standard solution. The measures of keratocyte density can be used in a variety of conditions, including contact lens wear, excimer laser keratorefractive surgery, and corneal transplantation.The work presented in [7] describes a computer based approach to detect the keratocytes in stromal images aiming to provide accurate measurement of these cells and their spatial distribution in the cornea. These images were acquired from ultra-high resolution optical coherence tomography (UHR-OCT). This approach has four main steps including de-speckle, thresholding, cell candidate selection, and finally cell identification.The work presented in [12] describes several approaches to prepare corneal images for 3D volume visualisation. Image displacements laterally and in the anterior–posterior directions, caused by subject movement, were addressed, in the former case, using the speeded-up robust features (SURF) algorithm, as well as the scale invariant feature transform (SIFT). A modification was added to the SURF approach to fit the application of corneal images registration. The structural similarity index measure (SSIM) was used to order the images in the Z direction. The cascade-forward neural network (CFNN) was used to tackle the classification problem, but its performance accuracy dropped when it was used for classifying higher numbers of images. We wanted to improve the classification accuracy in order to provide an accurate system for ophthalmologists which is able to identify abnormality in the processed data set. This aim was pursued by testing different neural networks (including, feed-forward neural networks (FFNN)), increasing the range of the tested number of the hidden neurons, proposing a new set of features consisting of 9 features instead of 144 features, and seeking another classifier (ANFIS) to fuse with the ANN in a committee machine (CM) to further improve performance of corneal layers classification.Adaptive neuro fuzzy inference systems (ANFIS), have been successfully and widely used in different medical applications, but as far as we know have not been previously applied to any type of corneal images until its use in the current study to classify corneal layers obtained using confocal microscopy. ANFIS harnesses the power of the fuzzy logic and neural network, by utilising the mathematical properties of neural network in tuning rule-based fuzzy systems that approximate the human method of processing information. Some examples of research work which have implemented the ANFIS approach are as follows. ANFIS was used in [8] to detect epileptic seizures; the proposed ANFIS model combining the neural network adaptive capabilities and the fuzzy logic qualitative approach. The decision making was performed in two stages: features were extracted using a wavelet transform; the features were then input to an ANFIS which had been trained with the backpropagation gradient descent method in combination with the least squares method. The results achieved showed the ANFIS approach performed better than a solely neural network based model. In another application [9], ANFIS was used to detect changes in electrocardiographs in patients with partial epilepsy. A similar neuro-fuzzy approach presented in [10] was used to classify image pixels into one of three sets: contour, regular, and texture. An advanced fuzzy inference neural network was used in [11] to detect abnormal lesions for selected regions of interest in images obtained by using the M2A swallowable imaging capsule.The benefit of corneal confocal microscopy is that it can be used in vivo and this makes it an exciting ophthalmic diagnostic tool. It is used in the assessment of the living cornea in both the normal and pathological state without the need for a biopsy in some conditions such as infective keratitis [13,14].In certain types of infectious keratitis, such as acanthamoeba and fungal [15–17], it is used routinely to provide prompt diagnosis leading to earlier treatment with the appropriate anti-infective agents and better outcomes with lower morbidity.Acanthamoeba keratitis is usually associated with contact lens wear and poor disinfection. Though it can have a classic presentation as documented in several textbooks, early signs are often wide ranging and can mimic other infective keratitis. As mentioned above, early diagnosis with confocal microscopy in a suspected case is very useful. Confocal microscopy findings include high contrast round bodies, double walled structures of the acanthamoeba ectocyst and endocyst and keratoneuritis showing irregular swelling of the nerve fibres [15,16].In addition, to assessment of the cornea in the acute conditions, it has become a useful tool to qualitatively and quantitatively analyse the cornea in dystrophies [18], wound healing [19], contact lens induced changes [20], peripheral neuropathy [21,22] and keratoectasia [23].For generations, slit lamp bio-microscopy has been used to clinically evaluate corneal dystrophies but this technique does not give detail at the cellular level without invasive biopsy. Numerous investigators have looked at the endothelial layer of the cornea and confocal microscopy has been used to diagnose early presentation of a variety of distinct disease entities, which usually look similar when viewed using slit lamp biomicroscopy, such as Fuchs endothelial dystrophy [24,25], posterior polymorphous dystrophy [26] and iridocorneal endothelial syndrome [27].Although confocal microscopy is a powerful diagnostic tool for corneal diseases, its use is limited, in research centres or large ophthalmic departments, partly due to the cost of the equipment but also due to difficulty in the acquisition and interpretation of the acquired images.Corneal confocal image analysis is an emerging discipline, with few approaches that have been applied to limited datasets of corneal images, focusing on individual layers of the cornea. Until now, no systematic or modular approach to tackle the general challenges in corneal imaging has been presented. The utilisation of advanced high performance analysis approaches will be useful in aiding ophthalmologists in diagnosis, therapy planning and patient care. The need for accurate and fast analysis of large corneal data sets leads us to exploit artificial intelligence (AI) techniques, including two types of artificial neural networks (ANNs) and ANFIS, together in a CM [28,29]. ANFIS was chosen as the second type of classifier for the following reasons: it is distinct from the former, harnessing the power of the fuzzy logic and neural network by utilising the mathematical properties of neural network in tuning rule-based fuzzy systems that approximate the human method of processing information. It has been successfully and widely used in other medical applications. A CM based on ANFIS and feed-forward neural network (FFNN) could potentially improve the layers classification accuracy over the component classifiers. To achieve efficient performance with these approaches, it is necessary to choose suitable input features for them. Therefore feature extraction approaches are discussed in the following section.It is important to choose features to extract from the images under the study, so processing these features at a later stage of the developed system will be more robust than using the original pixels. Choosing an appropriate feature extraction approach for the proposed application is a significant task. Texture-based feature extraction approaches and their important role in the human vision system make them efficient in extracting features from medical images which may contain combination of repetitive and non-repetitive patterns. The textural appearances of objects in these images can be described as complex visual entities composed of patterns, which have characteristics such as brightness, colour, orientation, and size.From a human vision point of view the selection of texture features can be subject to thorough experiment based on the application. There are also some conjectural expectations for certain properties of these features; for instance it can be expected that the entropy feature has bigger value for the more complicated images and a high value of the correlation feature leads to the expectation of linear dependency in the images [30]. Texture analysis approaches were used in [31] to extract the features from tear film images acquired using the Doane interferometer. Texture analysis was useful to segment tear film images based on interference patterns as presented in [32]. Texture analysis was used in the classification process of the still ultrasound images presented in [33].Texture information in the area of interest provides important information about the underlying biological process for the benign or malignant tissue and therefore should be included in the analysis. Looking at texture statistics as a prognostic factor, second order parameters were described in literature as best performing features [34,40]. Second order statistics have been widely applied for texture classification tasks [30,35]. The standardisation of first order statistics, however, showed a significant decrease of prognostic information [36]. The work presented in [37] has used texture features in the development of an automated algorithm for the categorisation of normal and cancerous colon mucosa.Statistical features are widely used for textural analysis in general image processing applications and for medical image classification as well [38]. In this research a number of feature extraction approaches were explored to find the group of features, from the alternatives considered, which yielded the best analysis and classification outputs of the processed data sets. The initial approaches were chosen on the basis of their wide published use in the literature as well as the efficiency of extracted features used by image processing approaches. Moreover, the corneal images in question have been visually analysed to decide which type of features extraction approach can be used. Based on this analysis, it was found that on one hand, we need information about the spatial arrangement of the images intensities and these images have repetitive patterns (e.g. identical cells) as well as non-repetitive patterns. On the other hand we need an approach to help in classification of images in question. Therefore we have investigated the texture features approaches which can meet these needs.The first group of features extracted are based on the first order histogram (FOH), which represents the grey-level distribution of individual pixels in each regions of the image without taking account of the spatial distribution of the grey-levels. This group consists of the six features: mean, standard deviation, smoothness, skewness, energy and entropy [39].The second group of features extracted are based on the second order histogram (SOH), which are statistical features based on grey level co-occurrence matrices. First a grey-level co-occurrence matrix for each image is created for a particular co-occurrence vector. The corneal textures display a full range of possible orientations and this is taken account of by including vector angles of all main directions 0°, 45°, 90° and 135°. The corneal images also contain structures with a range of widths and separations which have been taken account of by including vector distances d of 7, 9, 11, 13, 15, 17 and 21 pixels. Then four distinct texture measures are calculated from each matrix namely contrast, correlation, energy and homogeneity. Then the average of each measure over all vectors is calculated creating the first four values of this group. The five additional features including entropy, means of rows, standard deviations of rows, absolute values and inverse difference moments; are calculated for all vector distances and angles [40,41]. This generates 140 features, making a total of 144 features in this group. Generally, the classification of the fine textures requires small values of d, whereas coarse textures require large values of d. To derive texture measures from the co-occurrence matrices, an appropriate range of vector distances d should be chosen. Experiments were performed on a number of features and to choose the most suitable range of d for the proposed application. These experiments were based on the solution suggested by [42] which uses a statistical test to select the values of d that have the most structure and maximise the value of this statistical test. The experiments were performed on corneal images acquired using ConfoScan 4 with resolution of 768×576 pixel. The obtained distances can give good results as far as they are used for processing this type of images.To simplify the classification step over the use of the previous group we included a set of extracted features based on averages of the second order histogram (ASOH); this group of features reduces to 9 features from the original 144, each averaged over all the considered vector distances and angles. Analysis of several experiments performed on all the processed data sets, found this group of features to give better performance and improved classification accuracy over all the other investigated groups of features. For this reason, this method has been chosen to extract the features from the processed data sets in the final system. The details of the results achieved are discussed in the results and analysis section.The fourth group of features extracted is based on the Laws’ texture energy measures (TEM), and consists of 14 features. This texture description uses the following measurements: average grey level, edges, spots, ripples and waves. Features are derived from three vectors: averaging (L3)=[1,1,2], first difference – edges (E3)=[−1,0,1], and second difference – spots (S3)=[−1,2,−1]. After the convolution of the 3 vectors with themselves and each other, five vectors result as follows: L5, E5, S5, R5, and W5 [43,44]. The last group of features extracted is based on the grey run length matrix (GRLM), which is a statistical approach describing the texture information of a grey level image region using intensity values. This group consists of 16 features [44,45].The artificial neural network (ANN) is one of the AI techniques with the capability to learn from a set of data constructing weight matrices to represent the learning patterns. The ANN has had great success in many applications including pattern classification, decision making, forecasting, and adaptive control. For the purpose of this research cascade-forward neural network (CFNN) and feed-forward neural network (FFNN) are used. The justification for using these ANNs is given in Appendix A, where the results for 14 different ANNs and ANFIS are shown. The FFNN and CFNN achieved the highest accuracies among the neural networks, of 78% and 74% respectively while the ANFIS achieved an accuracy of 86% and this is the performance we want to improve on.In the cascade-forward neural network (CFNN), each subsequent layer has weights coming from the input and all previous layers to keep the influence of the inputs on all the layers; it also has a fast training procedure. We wanted to study the effect of these connections in the proposed corneal application compared with the FFNN which does not have these connections, but can still be used for any kind of input to output mapping. An FFNN with one hidden layer and enough neurons in the hidden layers, can fit any finite input–output mapping problem. The results achieved were compared and the best one, which suits the problem in question, was chosen. The structure, training and the ability of CFNN and FFNN are discussed later on.The employed CFNN consists of three layers (inputs, hidden, output). Each layer's weights and biases are initialised at the beginning then the adaption is done with a Levenberg–Marquardt backpropagation training procedure [46,47]. The input data is randomly mixed then divided into two subsets; 80% for the training, and the other 20% for testing. To reduce the risk of over-fitting, the algorithm is applied repeatedly on randomly sub-sampled validation data. The number of iterations is set to 1000 during the training process. Several experiments varying the number of hidden neurons (H) were performed to achieve the best network performance and structure for the corneal layers classification. Five groups of inputs (feature vectors) were also employed in these experiments, with groups one to five having 6, 144, 9, 14 and 16 features respectively. The number of the hidden neurons in these experiments varied between 4 and 96. Based on these experiments the best network performance was associated with 17 hidden neurons. Each experiment was repeated 10 times (i) and the average and standard deviation of the results used in the evaluation. The following metrics were calculated for each experiment: true positives rate (TPR), false positives rate (FPR), accuracy (ACC), specificity (SPC), positive predictive value (PPV), negative predictive value (NPV), false discovery rate (FDR) and standard deviation (STD). The results achieved by this network are presented in Section 4.As already mentioned, the feed-forward neural network (FFNN) was chosen, for the corneal application because it achieved the highest accuracy among the fourteen ANNs evaluated. It has also been widely employed in the image processing literature, with good classification efficiency reported in medical imaging [46]. The FFNN has three layers (input, hidden and output). Its neuron output is modelled using the following equation:(1)Y(j)=f∑i=1Rw1,i(j)⋅pi(j)+bwhere f is the tangent-sigmoid transfer function for the input vector pi, w1,rare the weights and b is the bias. The weights are updated as follows to obtain an output consistent with the training examples.(2)w1,i(j+1)=w1,i(j)+α*pi(j)*e(j)where α is the learning rate (chosen to equal 0.9), and e(j) is the error calculated by taking the difference between the desired output Ydand the actual output Y:(3)e(j)=Yd(j)−Y(j)The FFNN experiments were conducted similarly to those performed for the CFNN. 1000 iterations were used during the training process; five different types of inputs/feature vectors were also deployed. Several experiments on the number of hidden neurons (H) were performed to achieve the best network performance for the corneal layers classification. The best network performance was associated with 19 hidden neurons. All the experiments were repeated 10 times and the average considered. The TPR, FPR, ACC, SPC, PPV, NPV, FDR and STD measures were also used to evaluate the FFNN performance. After evaluating all the results using the 5 features vectors, the best performance for both neural networks was achieved using the ASOH group of features. The classification accuracy obtained using the FFNN was 4% higher than that using the CFNN, therefore the FFNN was chosen for the proposed system. A flow chart of the employed ANN classifier is shown in Fig. 2. This flow chart represents one block of the complete corneal system which is shown in Fig. 5. A discussion of the detailed results is presented in Section 4.The ANFIS performed best on the initial tests shown in Appendix A and so was chosen to partner the FFNN in a committee machine expecting to improve on both in order to provide more accurate system for ophthalmologists than that can be provided with an FFNN or ANFIS alone. ANFIS architecture and learning is based on a fuzzy inference system (FIS) implemented in a framework of an adaptive network. Using a hybrid learning procedure, an ANFIS can learn an input–output mapping based on human knowledge, which is provided in the form of ‘if–then’ fuzzy rules. An ANFIS performs the identification of an input–output mapping, available in the form of a set of N input–output examples, with a fuzzy architecture, inspired by the Takagi–Sugeno modelling approach [48,49]. The fuzzy architecture is characterised by a set of rules, which are properly initialised and tuned by a learning algorithm. The rules are in the form:Rule1:If(xisA1)and(yisB1)then(f1=p1x+q1y+r1)Rule2:If(xisA2)and(yisB2)then(f2=p2x+q2y+r2)where x and y are the inputs, Aiand Biare the fuzzy sets, fiare the outputs within the fuzzy region specified by the fuzzy rule, pi, qiand riare the design parameters that are determined during the training process [50,51].There are three main steps for applying ANFIS. The first step is initialisation which generates a FIS using subtractive clustering; it then extracts a set of rules that model the data behaviour. The rule extraction method first determines the number of rules and antecedent membership functions and then uses a linear least squares estimation to determine each rule's consequent equations. The second step is training; where a hybrid learning algorithm is used to identify the FIS parameters. The maximum number of training iterations is set to 60 by which point the error has stabilised and stopped decreasing. The training step applies a combination of the least-squares method and the backpropagation gradient descent method for training FIS membership function parameters to emulate a given training data set. The third step is the testing of FIS on different data sets [52]. The testing outputs are evaluated, and if this is not satisfactory then the initialised clustering parameters (range of influence (RI), squash factor (SF), acceptance ratio (AR) and rejection ratio (RR)) are optimised and new FIS is generated. The three step procedure is repeated until a maximum performance is achieved. A flowchart of the ANFIS procedure representing one block in the proposed complete corneal system is shown in Fig. 3.Many experiments were performed using the five groups of extracted features: FOH, SOH, ASOH, TEM, and GRLM having 6, 144, 9, 14 and 16 features respectively, to find the one which, combined with the optimally obtained parameters of the ANFIS approach, leads to the most accurate recognition of the corneal layers. From these experiments the best layers recognition was achieved using the ASOH features. The details of the ANFIS results are discussed in Section 4.The main motivation for combining classifiers is to improve their generalisation ability and to enhance the classification accuracy. Combining a set of imperfect classifiers can be viewed as a way to manage the recognised limitations of the individual classifiers [53]. Each component classifier is known to make errors, however, the fact that the regions/features that are misclassified by the different classifiers are not necessarily the same, suggests that the use of multiple classifiers might enhance the decision made. Training the CM with these classifiers combined in such a way to minimise the overall effect of these errors proves useful. There are several approaches for building a CM [54,55]. In this research the voting, averaging and weighted averaging approaches were tested and the most suitable one chosen.In the voting approach, each individual classifier outputs a decision instead of a score. The correct class is taken to be the one most often chosen by the different classifiers. Thus, the output prediction (Vp) is determined as follows:(4)Vp=x1when∑i=1Kxi>Tx2when∑i=1Kxi<Ttiewhen∑i=1Kxi=Twhere K is the number of classifiers, T is a chosen threshold. There is a potential for a tie when half of the classifiers vote for one class, and the other half vote for the opposition class, in cases where an even number of classifiers is used in the committee machine. The majority vote approach is the most popular approach among maximum, minimum, and median alternatives [56,57].The averaging approach averages the individual classifier outputs for each class across the committee machine. The highest average class output chosen according to Eq. (5) is used as the predicted class.(5)Q(x)=argmaxj=1…N1K∑i=1Kyij(x)N is the number of classes, yij(x) represents the output score of the ith classifier for the jth class of input x, and K is the number of classifiers utilised in the committee machine [56].The weighted average approach is similar to the averaging approach, except that the outputs of all classifiers are multiplied by a prediction weighting as follows [56,57]:(6)Q(x)=argmaxj=1…N∑i=1Kwiyij(x)∑Ki=1wiThe weights wiwhere i=1,…,k are derived by minimising the error eigiven in Eq. (7) of the different classifiers(7)yi(x)=ydi(x)+ei(x)where ydiis the desired output and yiis the actual output of each classifier.The normal data sets consist of 3 sequences of 85, 127, and 144 corneal images from epithelium layer through stroma to endothelium taken from 3 patients. This data is available from [5]. The acquisition instrument was a ConfoScan 4 confocal microscope (Nidek Technologies, Padova, Italy) [2], with the Z ring is installed (producing ordered images), and a field of view of 460μm×345μm at 40× magnification. The acquired monochrome images are saved in JPEG compressed format, and are of size 768×576 pixel [2,5].The abnormal images show 7 different corneal diseases affecting the epithelium, stroma and endothelium layers. The size of these images is 760×560 pixel.Acanthamoeba keratitis is a vision threatening, parasitic infection. This disease was first recognised in 1973, it is mostly seen in contact lens wearers. The possible early signs of this disease include epithelial infiltrates, epithelial irregularities, and pseudodendrites. Mid-stage signs may include epithelial defects, stromal infiltrates (as a ring-shaped, disciform, or numular), radial keratoneuritis, anterior uveitis, scleritis, and satellite lesions, while advanced signs include corneal perforation and stromal thinning. Fig. 4a shows this disease with the hyper-reflective round-shaped cysts arrowed. Another disease is Fusarium keratitis, shown in Fig. 4b, which is an ocular infection with potentially catastrophic visual results. This fungal infection can simulate any microbial keratitis. It begins when epithelial integrity is breached either due to trauma or ocular surface disease. The third disease is a yeast infection, shown in Fig. 4c, which produces characteristic creamy, opaque, pasty colonies on the surface [2,58].Crystalline dystrophy, shown in Fig. 4d, is an autosomal dominant stromal dystrophy [59]. The main symptoms are pain, decreased vision or photophobia. This condition may arise from a multitude of causes, including infection, corneal dystrophy and systemic disease that result in a build-up of metabolic products in the cornea. The fifth stromal disease is fleck corneal dystrophy, shown in Fig. 4e, which is caused by mutations in the ‘PIKFYVE’ gene [60]. Patients with this disease have small opacities scattered in the stroma; some of these opacities resemble flecks, others look more like snowflakes or clouds.Fuchs’ disease is an endothelial dystrophy, where a copper beaten like appearance can be observed in the endothelium. In this degenerative disease the corneal endothelial cells gradually die leading to corneal oedema and loss of clarity of the cornea. This disease is shown in Fig. 4f and advanced Fuchs’ disease is shown in Fig. 4g [61,62].Fig. 5 shows the analysis system proposed for corneal application. The acquired images go from the confocal microscope to a pre-processing step which performs the following operations. First, it checks for and eliminates blank images (some are generated due to the way confocal microscope works in this application). A statistical approach, using the mean, is employed to check for these blank images; any detected mean value in the range 0–10 will cause the associated image to be removed from the processed data sets. This range was chosen after performing tests and cross validation on all the processed data sets. Second, the remaining images are then processed to reduce noise by smoothing, using a band pass filter implemented as a fast discrete Fourier transform and Butterworth filter of order level 4 and range of frequencies 30–120 (Different levels and frequencies ranges were tested on the processed data sets, and best results achieved using these values). Fig. 6a and c shows original stroma and endothelium images respectively, while Fig. 6b and d shows the corresponding pre-processed images. Five groups of feature vectors are then extracted from the processed images based on FOH, SOH, ASOH, TEM, and GRLM. The features are then analysed separately using the ANNs and ANFIS approaches. This separation was important to evaluate the performance of each group of features. The detailed results for each of these approaches are discussed in Section 4.The ANN and ANFIS outputs are fed to the CM to improve the accuracy of the layer recognition. Three combination approaches were tested to find the best one to build the CM. The weighted averaging approach outperformed the voting and averaging approaches and was therefore chosen. The outputs of the CM are mapped and the three main corneal layers are displayed. Finally, statistical analysis for these data sets is performed to help identifying the presence of an abnormality in the related layer of the analysed data sets. Based on the clinical need, stroma corneal images as well as each individual keratocyte cell are processed and visualised in a 3D volume for further clinical analysis.

@&#CONCLUSIONS@&#
This research work concerns a practical study made on corneal images acquired using confocal microscopy which can provide detailed images from the different layers inside the cornea. An efficient corneal layer analysis system for normal and abnormal data has been presented. This system has the ability to exclude the useless images from the processed cornea sequence, enhance the quality of the remaining images, extract five groups of the features from these images (FOH, SOH, ASOH, TEM, and GRLM), classify these images into the correct class (layer), identify abnormalities in the analysed data sets and visualise stroma corneal images as well as each individual keratocyte cell as a volume for further clinical analysis. This helps the ophthalmologists in the diagnosis and gives them the opportunity to analyse a few stroma figures instead of many images. Two types of ANNs, an FFNN and a CFNN, have been thoroughly investigated for the proposed corneal application. Generally, FFNN outperformed CFNN and it was chosen as the first part of the developed CM. An ANFIS approach has given good results with only 5 images misclassified out of all the images. It has been employed as a second half of the CM. The detailed results from these approaches have been presented and discussed earlier. A CM has been deployed; combining the FFNN and ANFIS classifiers, to achieve an improved recognition accuracy of 100% for some classes in the processed data sets and one image misclassified from the EN.The system presented is able to pre-process and analyse the main layers in the corneal data sets, it shows robustness in processing both normal and abnormal data sets. Just one abnormal image from endothelium layer was misclassified while the rest of the processed data were correctly classified. Statistical features have been also employed to predict corneal abnormality. This statistical information can help build a complete prediction system for the corneal abnormalities which can include a clinical description for each detected disease. Such abnormalities detection with the associated measurements could help and speed up the clinician's diagnosis.It is worth mentioning that some of the cornea problems and diseases can occur in one or all of the main cornea layers. Therefore the system developed can serve as a helpful platform to accurately recognise each of the corneal layers leading to abnormality detection. This system will also be able to extract further clinical information associated with a certain disease or evaluating the normal cornea. The processed outputs of the developed system have been visually mapped to highlight the main corneal layers as well as highlighting the presence of any abnormality.The next step in this research is to validate the developed system on different types of corneal diseases as well as extract and analyse the associated features of these diseases for each corneal layer. These features will help build an appropriate map for each corneal disease. Extracting these features could be clinically useful, underpinning the work of ophthalmologists, saving a useful amount of clinician time in the process, and hence improving the patient care in a busy clinical setting. A complete coloured map for the main corneal layers (epithelium, stroma, and endothelium) will be built based on discussions on the clinical needs of the ophthalmologists. This coloured map will cover both normal and abnormal confocal corneal data sets.