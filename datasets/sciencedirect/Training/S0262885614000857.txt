@&#MAIN-TITLE@&#
Generic polar harmonic transforms for invariant image representation

@&#HIGHLIGHTS@&#
We generalize polar harmonic transforms for pattern description/recognition.The generalization maintains beneficial properties of existing transforms.The completeness of the corresponding basis sets is proven.The numerical stability of the computation is discussed.The new generic transforms have superior performance to comparison methods.

@&#KEYPHRASES@&#
Polar harmonic transforms,Harmonic kernels,Rotation invariance,Orthogonal moments,

@&#ABSTRACT@&#
This paper introduces four classes of rotation-invariant orthogonal moments by generalizing four existing moments that use harmonic functions in their radial kernels. Members of these classes share beneficial properties for image representation and pattern recognition like orthogonality and rotation-invariance. The kernel sets of these generic harmonic function-based moments are complete in the Hilbert space of square-integrable continuous complex-valued functions. Due to their resemble definition, the computation of these kernels maintains the simplicity and numerical stability of existing harmonic function-based moments. In addition, each member of one of these classes has distinctive properties that depend on the value of a parameter, making it more suitable for some particular applications. Comparison with existing orthogonal moments defined based on Jacobi polynomials and eigenfunctions has been carried out and experimental results show the effectiveness of these classes of moments in terms of representation capability and discrimination power.

@&#INTRODUCTION@&#
Rotation-invariant features of images are usually extracted by using moment methods [1] where an image f on the unit disk (x2+y2≤1) is decomposed into a set of kernels {Vnm|(n,m)∈ℤ2} asHnm=∬x2+y2≤1fxyVnm∗xydxdy,where the asterisk denotes the complex conjugate. According to [2], a kernel that is “invariant in form” with respect to rotation about the origin must be defined asVnmrθ=RnrAmθ,wherer=x2+y2,θ=atan2yx,Amθ=eimθ,and Rncould be of any form. For example, rotational moments (RM) [3] and complex moments (CM) [4] are defined by using Rn(r)=rn; continuous generic Fourier descriptor (GFD) [5] employs ei2πnrfor Rn(r); and angular radial transform (ART) [6] uses harmonic functions asRnr=1,n=0cosπnr,n≠0.However, the obtained kernels Vnmof RM, CM, GFD, and ART are not orthogonal and, as a result, information redundancy exists in the moments Hnm, leading to difficulties in image reconstruction and low accuracy in pattern recognition, etc. Undoubtedly, orthogonality between kernels Vnmcomes as a natural solution to these problems. Orthogonality meansVnmVn′m′=∬x2+y2≤1VnmxyVn′m′∗xydxdy=∫01RnrRn′∗rrdr∫02πAmθAm′∗θdθ=δnn′δmm′,where δij=[i=j] is the Kronecker delta function. It can be seen from the orthogonality between the angular kernels∫02πAmθAm′∗θdθ=∫02πeimθe−im′θdθ=2πδmm′that the remaining condition on the radial kernels is(1)∫01RnrRn′∗rrdr=12πδnn′.This equation presents the regulating condition for the definition of a set of radial kernels Rnin order to have orthogonality between kernels Vnm.There exists a number of methods that have their radial kernels satisfying the condition in Eq. (1) and they can be roughly classified into three groups. The first employs Jacobi polynomials[7] in r of order n for Rn(r) obtained by orthogonalizing sequences of polynomial functions or by directly using existing orthogonal polynomials. Members of this group are Zernike moments (ZM) [8], pseudo-Zernike moments (PZM) [2], orthogonal Fourier–Mellin moments (OFMM) [9], Chebyshev–Fourier moments (CHFM) [10], and pseudo Jacobi–Fourier moments (PJFM) [11] (see [12, Section 6.3], or [13, Section 3.1] for a comprehensive survey). It was demonstrated recently that the Jacobi polynomial-based radial kernels of these methods are special cases of the shifted Jacobi polynomials [14,15]. Despite its popularity, this group of orthogonal moments however involves computation of factorial terms, resulting in high computational complexity and numerical instability, which often limit their practical usefulness.The second group employs the eigenfunctions of the Laplacian ∇2 on the unit disk as Vnm, similar to the interpretation of Fourier basis as the set of eigenfunctions of ∇2 on a rectangular domain. These eigenfunctions are obtained by solving the Helmholtz equation, ∇2V+λ2V=0, in polar coordinates to have the radial kernels defined based on the Bessel functions of the first and second kinds [16]. In addition, by imposing the condition in Eq. (1) a class of orthogonal moments is obtained [17] and different boundary conditions were used for the proposal of a number of methods with distinct definition of λ: Fourier–Bessel modes (FBM) [18], Bessel–Fourier moments (BFM) [19], and disk-harmonic coefficients (DHC) [20]. However, the main disadvantage of these eigenfunction-based methods is the lack of an explicit definition of their radial kernels other than Bessel functions, leading to inefficiency in terms of computation complexity.And the last group uses harmonic functions (i.e., complex exponential and trigonometric functions) for Rnby taking advantage of their orthogonality:(2)∫01ei2πnre−i2πn′rdr=δnn′,(3)∫01cosπnrcosπn′rdr=12δnn′,(4)∫01sinπnrsinπn′rdr=12δnn′,(5)∫01cosπnrsinπn′rdr=0,n−n′iseven.It can be seen that the integrand in Eqs. (2)–(5) is “similar in form” with that in Eq. (1), except for the absence of the weighting term r which prevents a direct application of harmonic functions as radial kernels. This obstacle was first overcome in [21] by using the multiplicative factor1rin the radial kernels to eliminate r in the definition of radial harmonic Fourier moments (RHFM) as(6)Rnr=1r1,2sinπn+1r,2cosπnr,n=0n>0&nisoddn>0&niseven.Recently, a different strategy was proposed to move r into the variable of integration,rdr=12dr2,in the definition of three different forms of polar harmonic transforms [22]: polar complex exponential transform (PCET), polar cosine transform (PCT), and polar sine transform (PST). The radial kernels of these transforms are respectively defined as(7)Rnr=ei2πnr2,(8)RnCr=1,n=02cosπnr2,n>0(9)RnSr=2sinπnr2,n>0It is straightforward that the radial kernels in Eqs. (6)–(9) all satisfy the orthogonality condition in Eq. (1) and that their corresponding kernels are orthogonal over the unit disk. In addition, the radial kernels of RHFM in Eq. (6) are actually equivalent toRnr=1rei2πnrin terms of image representation, similar to the equivalence between different forms of Fourier series (namely trigonometric and complex exponential functions). The resemblance between the exponential form of RHFM's radial kernels and PCET's radial kernels suggests that they are actually special cases of a generic class of radial kernels that are defined based on complex exponential functions. And each member of this class can be used to define kernels that are orthogonal over the unit disk. Similar observation also leads to generic classes of radial kernels defined based on trigonometric functions.The main contribution of this paper is a generic view on strategies that were used to define orthogonal moments. This leads to the introduction of four classes of radial kernels that correspond to four generic sets of moments and take existing harmonic moments as special cases. This paper proves theoretically that the generic sets of kernels are complete in the Hilbert space of all square-integrable continuous complex-valued functions over the unit disk. It also shows experimentally that the proposed harmonic moments are superior to Jacobi polynomial-based moments and are comparable to eigenfunction-based moments in terms of representation capability and discrimination power. It is also interesting to note that these generic harmonic moments can be computed very quickly by exploiting the recurrence relations among complex exponentials and trigonometric functions [23]. The generalization by introducing a parameter in this paper is similar to the generalization of the R-transform published recently [24].The content of this paper is a comprehensive extension of the research work presented previously in [25]. The next section will derive explicit form of generic classes of radial kernels defined based on complex exponentials and trigonometric functions. The completeness of the sets of orthogonal decomposing kernels is proven in Section 3, along with some beneficial properties obtained from the generalization. Section 4 is devoted to the stability of the numerical computation. Experimental results in terms of representation capability and discrimination power are given in Section 5. And conclusions are finally drawn in Section 6.In order to formulate the generalization, assuming that the harmonic radial kernels have the generic exponential formRnsr=κrei2πnrs, where s∈ℝ and κ is a real functional of r. Then∫01RnsrRn′s∗rrdr=∫01κ2rei2πnrse−i2πn′rsrdr.Since drs=srs−1dr=srs−2rdr then∫01RnsrRn′s∗rrdr=∫01κ2rsrs−2ei2πnrse−i2πn′rsdrs.By lettingκ2rsrs−2=const=C,∫01RnsrRn′s∗rrdr=∫01Cei2πnrse−i2πn′rsdrs=Cδnn′.In order to have orthonormality between kernels, it follows directly from Eq. (1) thatC=12π. Thenκr=srs−22πand Rnshave the following actual definition:(10)Rnsr=κrei2πnrs,or(11)Vnmsrθ=RnsrAmθ=κrei2πnrseimθ.The generic polar complex exponential transform (GPCET) is thus defined as(12)Hnms=∬x2+y2≤1fxyVnm∗xydxdy=∫02π∫01frθκre−i2πnrs+mθrdrdθ.By considering s in the above development as a parameter, it can be seen that Rnsis a true generalization of the harmonic radial kernels of PCET [22]: Rns(r) in Eq. (10) becomes Rn(r) in Eq. (7) when s=2, except for the constant multiplicative factor1π. Thus, a class of harmonic radial kernels can be obtained by changing the value of s. Due to the generic definition, members of this class share beneficial properties to image representation and pattern recognition. However, each member also possesses distinctive characteristics that are determined by the actual value of s, making it more suitable for some particular applications. Some beneficial properties of GPCET will be discussed in Section 3 and be supported by experimental evidence in Section 5. Fig. 1illustrates the phase of GPCET kernels using four different values of s=0.5, 1, 2, 4 for {(n, m)|n, m ∈ [0,2], (n, m) ∈ ℤ2}. It can be seen that the phase of Vnms, unlike that of the kernels defined based on polynomials, is the sum of the phase of Rnsand Am. The phase image of Vnmsthus has a rotational symmetry pattern composing of repetitive slices when n or m≠0. The dependence of this pattern on n, m, and s can be described as follows:–an increase in n results in thinner and longer slices.an increase in m increases the number of slices.a change in s corresponds to a change in the thickness uniformity of each slice.In addition to the harmonic radial kernels of GPCET defined in Eq. (10), there exist three other classes of harmonic radial kernels that result from generalizing the harmonic radial kernels of RHFM (RHns) [21], PCT (RCns), and PST (RSns) [22]. By using similar development procedures, it is straightforward that(13)RnsHr=κr1,2sinπn+1rs,2cosπnrs,n=0n>0&nisoddn>0&niseven(14)RnsCr=κr1,2cosπnrs,n=0n>0(15)RnsSr=κr2sinπnrs,n>0.These three classes of harmonic radial kernels correspond to three classes of transforms: the generic radial harmonic Fourier moments (GRHFM), the generic polar cosine transforms (GPCT), and the generic polar sine transforms (GPST). GRHFM is in fact a variant of GPCET in terms of representation, similar to the equivalence between different forms of Fourier series. It becomes RHFM in Eq. (6) when s=1, except for the constant multiplicative factor12π. In addition, GPCT/GPST arise naturally from GRHFM when the function to be represented by (RHns) is considered as half of an even/odd periodic function. Again, GPCT/GPST become PCT/PST in Eqs. (8)/(9) when s=2, except for the constant multiplicative factor1π.At a specific value of s,VnmsVn′m′s=δnn′δmm′means that(16)Bs=Vnmsrθ=Rnsreimθn,m∈ℤforms a set of kernels that are orthonormal over the unit disk. Similarly, there are three other sets of orthonormal kernels at a specific value of s defined as(17)BsH=VnmsHrθ=RnsHreimθn∈ℕ,m∈ℤ,(18)BsC=VnmsCrθ=RnsCreimθn∈ℕ,m∈Z,(19)BsS=VnmsSrθ=RnsSreimθn∈ℤ+,m∈ℤ.Each of the setsBs,BsH,BsC, andBsScan be used as the set of decomposing orthonormal kernels for GPCET, GRHFM, GPCT, and GPST, respectively. The completeness of these sets is an important issue that needs further consideration (see Section 3).In spite of their common harmonic nature, each of GPCET, GRHFM, GPCT, and GPST captures different image information even at the same value of s, similar to the difference among Fourier (complex exponential and trigonometric), cosine, and sine series. This observation will have experimental evidence in Section 5. Nevertheless, in the remaining of this paper, the theoretical discussions will mainly focus on GPCET with an occasional foray into GRHFM, GPCT, and GPST only when necessary. This is to avoid unnecessary repetition, since GRHFM, GPCT, and GPST essentially have many properties that are identical to those of GPCET. In addition, if not explicitly mentioned, the parameter s will have a fixed value in the remaining discussions.This section discusses the completeness of the sets of orthogonal decomposing kernels defined in Eq. (16) along with some beneficial properties of GPCET for image representation and pattern recognition that result directly from the generalization. Other issues like relation with RM, 3D formulation, rotation invariance, rotating-angle estimation, and computational complexity could also be derived with relative ease [13, Section 3.3].A set of orthogonal kernels is called complete in a Hilbert spaceHif its linear span is dense inH. The completeness of an orthogonal set inHis hence related to the ability of the set in representing functions inH. In the case ofBs,His defined as the space of all square-integrable continuous complex-valued functions over the unit disk, denoted asL2(x2+y2<1). A completeBscan be used as an orthonormal basis, meaning that every function f ∈Hcan be written as an infinite linear combination of the kernels inBsas(20)fsxy=∑n=−∞∞∑m=−∞∞HnmsVnmsxy.In addition, due to the Parseval's identity:∑nm∈ℤ2Hnms2=∬x2+y2≤1fxy2dxdy,it can be seen that GPCET moments, Hnms, are bounded if and only if f is square-integrable. The above identity is in fact stronger than the Bessel's inequality claimed in [22, Eq. (8)], where a loose inequality is used instead of an equality. This is because [22] lacks discussion on the completeness of its proposed orthogonal sets.In this subsection, the completeness ofBsinHis established by means of the interpretation of GPCET through Fourier series by rewriting Eq. (12) asHnms=∫02π∫01frθκre−i2πnrsrdre−imθdθ=12π∫02π∫01gr′θe−i2πnr′dr′e−imθdθ,where r′=rsand(21)gr′θ=2πsr′2−s2sfr′sθ.If g is viewed as a 2D function defined in a Cartesian coordinate system where r and θ are the horizontal and vertical axes, respectively, then the GPCET moments Hnmsof a function f ∈Hare the 2D Fourier coefficients of g formulated as above: first in the radial direction, then in the angular direction. This interpretation transforms the completeness issue ofBsinHinto the convergence issue of 2D Fourier series, leading to the following two questions:–The convergence of partial sums of 2D Fourier series of functions? Almost everywhere convergence of “polygonal partial sums” of 2D Fourier series of functions inL2([0,1]×[0,2π)) was already established in [26].The square-integrability of g? The necessary and sufficient conditions for the square-integrability of g over the domain [0,1]×[0,2π) will be established in Theorem 1.The function g defined in Eq. (21)is inL2([0,1]×[0,2π)) if and only if the function f is inL2(x2+y2<1).From the definition of g:∫02π∫01gr′θ2dr′dθ=∫02π∫012πsr′2−ssfr′sθ2dr′dθ.By changing the variabler=r′s→r′=rsand dr′=srs−1dr, the above equation becomes∫02π∫01gr′θ2dr′dθ=∫02π∫012πsr2−sfrθ2srs−1drsdθ=2π∫02π∫01frθ2rdrdθ=2π∬x2+y2≤1fxy2dxdy.Thus, it is straightforward that∫02π∫01gr′θ2dr′dθ<∞⇔∬x2+y2≤1fxy2dxdy<∞and the theorem is proven.□Thus, the setBs={Vnms|n,m∈ℤ} is complete in the Hilbert spaceHof all square-integrable continuous complex-valued functions over the unit diskL2(x2+y2<1). As a result,Bscan be used as an orthonormal basis forHand writing f as in Eq. (20) is safe (i.e., the partial sums converge to the image function). To our knowledge, there exists no such conclusion for other orthogonal sets over the unit disk where the corresponding radial kernels are defined based on polynomials or eigenfunctions.The number of zeros of the radial kernels is an important indicator since it corresponds to the capability of moments in representing high frequency components of images. In the case of GPCET, Rnsis defined based on complex exponential function and can be rewritten in the following form:Rnsr=κrcos2πnrs+isin2πnrs,and the two equationsrealRnsr=0,imagRnsr=0both have 2n distinct roots in the interval 0<r<1. For a better perception of how large this number is, Table 1provides the number of zeros of the nth-order radial kernel of existing unit disk-based orthogonal moments. It can be seen that, except for ZM, PZM, and GPCET, the nth-order radial kernel of all other methods has approximately n zeros. In the case of GPCET, this number is almost double whereas, for ZM and PZM, it depends on the angular order m. In order to have the same number of zeros n0 as other methods, the order of the radial kernel of ZM and PZM has to be 2n0+m and n0+m, respectively. These numbers are much higher than that of GPCET, which is onlyn02.In addition to the quantity, the distribution of zeros is also an important property of the radial kernels since it relates to the information suppression problem[4]. Suppression is the situation when the computed moments put emphasis on certain portions of image and neglect the rest. When the essential discriminative information is distributed uniformly over the image domain, an unfair emphasis of the extracted moments is known to have a negative impact on their discrimination power. On the contrary, when the essential discriminative information only exists in certain image portions, it is preferable to move the emphasis towards those portions. In the case of GPCET, the distribution of the zeros of Rnscan be controlled by changing the parameter s. In other words, emphasis can be put on the image portions that contain this information. This is the distinctive property of GPCET that existing methods do not have.When s=1, the zeros of Rn1 are distributed uniformly, meaning a uniform emphasis over the image region. The more deviation of the value of s from 1 is, the more “biased” to the inner (when s<1) or outer (when s>1) portions of the unit disk the distribution of zeros is. This in turn corresponds to the more emphasis on the inner or outer portions of image, respectively. Evidence for the observations on the quantity and distribution of zeros of Rnsis given in Fig. 2that contains the plot of real (Rns) and imag (Rns) of orders n=0→4 at s=0.5,1,2,4 (top row to bottom row). It can be seen that the real and imaginary parts of GPCET radial kernel of order n have 2n zeros in the interval 0<r<1. Moreover, the distribution of these zeros is biased towards 0 at s=0.5, uniform at s=1, and biased towards 1 at s=2,4.Accuracy is another concern when moments are computed numerically. Error in the computed moments may result from the discrete approximation of continuous mathematical formulas or from the digital nature of computing systems, where numbers can only be represented in a certain range and to a certain precision. In addition, error also has its root in the mathematical definition of moments. These two error sources and their impacts will be discussed in the remaining of this section.Since moments are originally defined based on a double continuous integral over the unit disk domain, the following discrete approximation of Eq. (12) will incur error in the computed moments:(22)Hnms=∑ij∈CfxiyjVnms∗xiyjΔxΔy,whereCis the set of pixels whose mapped regions lie entirely inside the unit disk; (xi, yj) are the coordinates of the center of the mapped region of pixel [i,j]; and ∆x and ∆y are the dimensions of each mapped region. In the above equation, there are two types of discrete approximations and they correspond to two types of approximation errors [27]: geometric error and numerical error. Geometric error occurs when the domain of integration does not exactly cover the unit disk, due to the difference between circular and rectangular domains. This type of error, however, could be “avoided” if only the pixels that lie entirely inside the unit disk are used and the image function over the remaining regions of the unit disk is assumed to take value 0. Since this strategy will be used for the computation of harmonic function-based moments and comparison methods, geometric error hence does not exist in all experiments in Section 5.Numerical error arises when Vnms∗(xi, yj) ∆x∆y in Eq. (22), which represents the value of the kernel Vnmsover the pixel [i,j], is computed by a numerical integration technique. Since the numerically computed value of Vnms∗(xi, yj) ∆x∆y is just an approximation to its analytical value, this type of error cannot be avoided in any way if one chooses to compute moments by numerical approximation. The magnitude of this type of error, however, could be reduced if only a highly accurate numerical integration technique is employed (e.g., “pseudo” sub-sampling or cubature). It can be seen from the factor ∆x∆y that the effect of numerical error depends on image size: a smaller-sized image will have a more severe effect, and vice versa. The effect of numerical error on harmonic function-based moments and comparison methods will be demonstrated experimentally by means of reconstruction error in Section 5.In computing systems nowadays, a real number is in general approximately represented in floating-point format in order to allow reasonable storage requirement and relatively quick calculations. The typical number that can be represented exactly is of the form:Significand×baseexponent,where significand denotes a signed digit string of a given length in a given base and exponent is a signed integer which modifies the magnitude of the number. As computing systems are binary in nature, floating-point numbers are normalized for representation as±(1+f)×2e, where f is the fraction or mantissa (0≤f<1) and e is the exponent. In 32-bit computers that use the IEEE 754 standard, double precision floating numbers occupy two storage locations, or 64 bits, to store the value of f, e, and the sign: 52 bits for f, 11 bits for e+1023, and 1 bit for the sign. A double number v thus can only be represented with the relative accuracy of one-half the machine epsilon, or12×eps=12×2−52≃1.1102×10−16. This means that, when represented in the ordinary decimal numeral system, only the first 15 leftmost digits of v are significant. Because of the limited range of e, the absolute values of double numbers are additionally limited in the range 2−1022÷(2−eps)21023, or approximately 2.2251×10−308÷1.7977×10308. This finite set of double numbers with finite precision leads to the phenomena of underflow, overflow, and roundoff in computing systems. Due to their nature, it is known in the literature that Jacobi polynomial-based methods suffer from all three types of errors [28] as pointed out below.Underflow error occurs when an absolute value of a computed quantity (except zero) is under the range of its data type. Jacobi polynomial-based methods have this type of error due to the use of powers of r in their definition. At a radial coordinate r that is close to zero, let's say r=0.001, r102=1.0000×10−306 and r103=1.0000×10−309. Thus, any computation that involves r to the power greater than 102 will cause underflow error. It is obvious that this type of error depends on the size of images: a larger-sized image starts to have this error at a lower order. As an example, for an input image of size 1024×1024pixels, the smallest value of r in the computation is11024=2−10=9.7656×10−4, underflow error will start to occur at n=103 onwards for all Jacobi polynomial-based methods.Overflow error occurs when a computed quantity has a value above the range of its data type. Jacobi polynomial-based methods has this type of error due to the use of factorials in their definition. Since 170!=7.2574×10306 and 171!=1.2410×10309, any computation that involves factorial of a number greater than 170 will cause overflow error. From the definition of Jacobi polynomial-based radial kernels, it is straightforward that ZM, PZM, OFMM, CHFM, and PJFM start to have this type of error at n=171, 85, 85, 171, and 84 onwards, respectively.Roundoff error is the difference between an approximation of a number used in computation and its exact (i.e., correct) value. Because of the finite precision in computing systems, this type of error occurs in almost all numerical computation steps. However, Jacobi polynomial-based methods face the problem of large polynomial's coefficients in their radial kernels. These coefficients are sometimes larger than 252 and thus, for the commonly 15-digit precision, computing radial kernels produces error of the order of unity or larger. It is not difficult to determine the order where each Jacobi polynomial-based method starts to have this type of error. They are n=46, 23, 23, 79, and 21 for ZM, PZM, OFMM, CHFM, and PJFM, respectively.The starting orders for each type of error for all Jacobi polynomial-based methods are collected and given in Table 2. Due to their distinct definition, it can be seen that different methods have different orders for overflow and roundoff errors. For underflow error, Jacobi polynomial-based methods have the same order because their radial kernels of the same order have the same polynomial order. Among these three types of representation errors, roundoff error occurs at the smallest order for each Jacobi polynomial-based method. Thus, roundoff error is the main concern in moment computation.From the above definition of three types of representation errors, it can be seen that eigenfunction-based and harmonic function-based methods do not suffer from the underflow and overflow errors. They do have roundoff error because of the nature of numerical computing systems. However, the effect of roundoff error on them is not as severe as on Jacobi polynomial-based methods because their definition does not use large-valued coefficients. In contrast, this effect causes serious problems in Jacobi polynomial-based methods, as will be shown experimentally in the next section. Nevertheless, any of the aforementioned error types is undesirable since it alters the computed values of moments, compromises the orthogonality of moments/kernels, and finally corrupts the overall performance of applications.In theory, GPCET could be defined as in Eq. (12) for every s∈ℝ. However, because the multiplicative term is defined asκr=srs−22π, it should be aware that(45)lims<2,r→0srs−22π=+∞.Evidence for this behavior can be seen in Fig. 2 for the cases s=0.5 and s=1 where the magnitude of the real and imaginary parts of GPCET radial kernels go to infinity as r→0. These phenomena also exist in the other harmonic function-based methods and in CHFM. However, this property does not result in “big” problems because the actual computation is carried out by using Eq. (22), instead of Eq. (12). As long as the center (xi, yj) of the pixel's mapped region does not coincide (0,0), the computed moments are bounded and hence harmonic function-based methods with s<2 and CHFM can still be used for image representation and in pattern recognition problems. The practical usefulness of these methods will be demonstrated by experiments in the following section.

@&#CONCLUSIONS@&#
In this paper, the generalization of existing unit disk-based orthogonal moments using harmonic functions has been pursued where the radial kernels are defined using exponential or trigonometric functions (GPCET or GRHFM), cosine series (GPCT), and sine series (GPST). The sets of harmonic function-based orthogonal kernels have been shown to be complete in the Hilbert space of square-integrable continuous complex-valued functions. In addition, the use of a parameter s in the definition brings in four classes of moments that maintain beneficial properties of the original moments (PCET, RHFM, PCT, and PST) while giving more flexibility in their definition. This flexibility has been demonstrated to be useful both theoretically and experimentally in some particular applications, especially in image compression and pattern recognition problems.In terms of representation capability, harmonic function-based methods suffer from numerical error, like all other methods. However, they do not suffer from representation error as Jacobi polynomial-based methods do. As a result, the well-known numerical instability in Jacobi polynomial-based methods does not exist in harmonic function-based methods. Apart from this numerical instability, the representation power of all unit disk-based orthogonal moments is comparable. However, the ability to control the representation emphasis on certain image regions by changing the value of s is a distinct feature of harmonic function-based methods. It is possible to have a faster reconstruction of the image function in certain regions of interest. This characteristic could lead to potential applications in image compression.In rotation-invariant pattern recognition problems, harmonic function-based methods have been shown to generally perform better than non-orthogonal and Jacobi polynomial-based methods. They also have comparable performance with eigenfunction-based methods. Thus, harmonic function-based moments could be used as region-based feature vector in rotation-invariant pattern recognition problems. In addition, the decisive role of s on the recognition results has been confirmed. It can be used to direct the extracted feature vector to emphasize on certain image regions that contain discriminative information. This ability is also a distinct feature of harmonic function-based methods.Since harmonic function-based moments can be computed very quickly by exploiting the recurrence relations among complex exponentials and trigonometric functions [23], they promise to provide an efficient and useful technique for a number of image processing and pattern recognition applications.Supplementary material.Supplementary data to this article can be found online at http://dx.doi.org/10.1016/j.imavis.2014.04.016.