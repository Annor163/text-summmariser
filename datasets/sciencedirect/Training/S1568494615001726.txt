@&#MAIN-TITLE@&#
Multiobjective design optimization of a nano-CMOS voltage-controlled oscillator using game theoretic-differential evolution

@&#HIGHLIGHTS@&#
Multi-objective design optimization of a nano-CMOS voltage-controlled oscillator (VCO).Frequency of oscillation, average dynamic power and leakage power are the target objectives.The novel game-theoretic differential evolution (GTDE) algorithm is proposed.Differential evolution (DE), particle swarm optimization (PSO) and game-theoretic differential evolution (GTDE) algorithms are implemented.New improved local optimum for the design of the nano-CMOS VCO was obtained.

@&#KEYPHRASES@&#
Multiobjective,Particle swarm optimization (PSO),Differential evolution (DE),Game-theoretic differential evolution (GTDE),Nano-CMOS VCO,Hypervolume indicator (HVI),

@&#ABSTRACT@&#
Engineering problems presenting themselves in a multiobjective setting have become commonplace in most industries. In such situations the decision maker (DM) requires several solution options prior to selecting the best or the most attractive solution with respect to the current industrial circumstances. The weighted sum scalarization approach was employed in this work in conjunction with three metaheuristic algorithms: particle swarm optimization (PSO), differential evolution (DE) and the improved DE algorithm (GTDE) (which was enhanced using ideas from evolutionary game theory). These methods are then used to generate the approximate Pareto frontier to the nano-CMOS voltage-controlled oscillator (VCO) design problem. Some comparative studies were then carried out to compare the proposed method as compared to the standard DE approach. Examination on the quality of the solutions across the Pareto frontier obtained using these algorithms was carried out using the hypervolume indicator (HVI).

@&#INTRODUCTION@&#
Many optimization problems are frequently encountered by engineers and decision makers working with systems involving nano-circuits [1–3]. Currently, standard circuit performance optimization is usually carried out manually. This approach usually takes a lot of time and requires plenty of skills. These difficulties compound drastically especially when optimizing circuits at a nano-level. Besides optimization, debugging and trouble-shooting such circuit designs can take several days and are usually very costly [4]. In most optimization scenarios, the decision-maker deals with conflicting objective functions such as power consumption factors and voltage-controlled oscillator (VCO) frequency [5,6]. In this work, a multi-objective framework is introduced for the performance optimization of a 45nm CMOS VCO.In multi-objective optimization, one approach that has been effective in measuring the quality of the solution set that constructs the Pareto-frontier (in cases where the Pareto frontier is unknown) is the hypervolume indicator (HVI) [7]. Recently, this indicator has been frequently applied in many works involving MO problems [8–10]. The HVI is the only indicator which is strictly Pareto-compliant and can be used to measure the quality of solution sets (degree of dominance) in MO optimization problems [8,11]. In this work, this measurement metric is employed to measure the solution quality and perform comparative analysis.Metaheuristic approaches have become common place in industries where optimization problems are encountered. One such state-of-the-art approach is differential evolution (DE). DE is a population-based evolutionary algorithm that has been derived from genetic algorithms (GA) [12]. DE was introduced in the mid-nineties by Storn and Price [13]. From then, DE has been employed extensively to solve problems which are nonlinear, non-continuous, noisy, multidimensional, have many local minima, constraints or highly stochastic. For more extensive works involving DE in industrial engineering see [14–16]. Recently, DE has also been employed in MO engineering problems. For instance, in Ganesan et al. [14,17], the optimal parameters were identified for the MO cement-bonded mold system using the DE and Hopfield DE strategies. In the works of Li et al. [18] and de Oliviera et al. [19] the DE technique was employed for antenna array design and in graphic processing unit (GPU) optimization.In current times, metaheuristic has become a very common tool when it comes to engineering optimization especially in sectors involving design and operations. For instance, population-based techniques such as DE and Artificial Bee Colony (ABC) [20] have been employed for parametric optimization of turning operations [21–23]. In addition to evolutionary techniques, swarm based algorithms such as Cuckoo Search [24] has also been utilized in milling operations. The central idea in these efforts was to implement metaheuristic techniques to determine the optimal machining parameters for milling [24,25]. Structural design optimization has been a standing problem for many years since this problem is usually multivariate, nonlinear and highly complex. Thus, recently techniques such as evolutionary strategies, particle swarm optimization (PSO) and firefly search have been employed to deal with these problems [26–29]. In these works the metaheuristic is seen to perform well by producing efficient results which often outperform the common practices by a significant margin. Metaheuristics has also been employed in other engineering systems related to assembly line balancing and design optimization in manufacturing [30,31]. In these systems, strategies such as hybrid ABC approaches [32], Taguchi method [33], PSO [34], hybrid simulated annealing [35] and immune system [36,37] have been utilized effectively.The solution method introduced in this work involves the integration of evolutionary game theory (EGT) into DE to enhance specific search functionalities. EGT has been used in combination with metaheuristic algorithms like PSO to solve problems involving the simulations of evolutionary games [38,39]. In addition, this algorithmic form has been also used to solve optimization test functions where the algorithm's performance was benchmarked [40]. The central aim of this work is to solve and obtain a set of Pareto-efficient solution options for the MO performance optimization of a 45nm CMOS VCO. The 45nm CMOS VCO problem was formulated and systematically validated in Chio et al. [40]. The approach proposed in this work is the game-theoretic differential evolution (GTDE). The solutions produced by the GTDE approach is then benchmarked and evaluated using the HVI.This paper is organized as follows. In Section 2 of this paper, the 45nm CMOS VCO problem description is presented. In Section 3 the DE, PSO and GTDE techniques are discussed and this is followed by Section 4 which analyzes the computational results. Finally, this paper ends with the concluding remarks and recommendations for future works.In Kougianos and Mohanty [41], the design of the nano-CMOS VCO was optimized in a MO framework by employing a baseline design. In the mentioned work, three objectives, the frequency of oscillation (FOSC), average dynamic power (Pave) and leakage power minimization (Pleak), were identified. The design parameters are as follows:1.Gate oxidation thickness (Tox)Width to length ratio for the PMOS inverter transistors (β1)Width to length ratio for the NMOS inverter transistors (β2)Width to length ratio for the PMOS current-starved transistors (β3)Width to length ratio for the NMOS current-starved transistors (β4)The objective functions and the constraints of the design parameters are given as follows:(1)Fosc=786.43−93.36Tox+60.3β2(2)Pave=35.05+5.7β4+3.3β3(3)Pleak=376.35−28.58Tox+29.32β1+36.17β2(4)1.4nm≤Tox≤1.7nm5≤β1≤101.72≤β2≤3.445≤β3≤101.72≤β4≤3.44The MO design optimization of the nano-CMOS VCO problem is shown as follows:(5)Max→FoscMin→PaveMin→Pleaksubject to design constraintsDE is a class of evolutionary meta-heuristic algorithms first introduced by Storn and Price [13]. The core idea of this technique is the assimilation of perturbative methods into standard evolutionary algorithms. DE starts by the initialization of a population of at least four individuals denoted as P. These individuals are real-coded vectors with some size N. The initial population of individual vectors (the first generation denoted gen=1) are randomly generated in appropriate search ranges. One principal parent denotedxipand three auxiliary parents denotedxiaare randomly selected from the population, P. In DE, every individual, I, in the population, P, would become a principle parent,xip, at one generation or the other and thus have a chance in mating with the auxiliary parents,xia. The three auxiliary parents then engage in ‘differential mutation’ to generate a mutated vector, Vi.(6)Vi=x1a+F(x2a−x3a)where F is the real-valued mutation amplification factor which is usually between 0 and 1. Next Viis then recombined (or exponentially crossed-over) withxipto generate child trial vector,xichild. The probability of the cross-over, CR, is an input parameter set by the user. In DE, the survival selection mechanism into the next generation is called ‘knock-out competition’. This is defined as the direct competition between the principle parent,xip, and the child trial vector,xichild, to select the survivor of the next generation as follows:(7)xi(gen+1)=xichild(gen)↔f(xichild)better thanf(xip)xip(gen)↔otherwiseTherefore, the knock-out competition mechanism also serves as the fitness evaluation scheme for the DE algorithm. The parameter setting for the DE algorithm is given in Table 1: The algorithm of DE is shown in Algorithm 1.Algorithm 1Differential evolution (DE).Step 1: Initialize individual size N, P, CR and FStep 2: Randomly initialize the population vectors,xiGStep 3: Randomly select one principal parents,xipStep 4: Randomly select three auxiliary parents,xiaStep 5: Perform differential mutation and generate mutated vector, ViStep 6: Recombine Viwithxipto generate child trial vector,xichildStep 7: Perform ‘knock-out’ competition for next generation survival selectionStep 8: If the fitness criterion is satisfied and t=Tmax, halt and print solutionselse proceed to Step 3The PSO approach [34] originates from different ideas related to the flocking habits of certain types of organisms (e.g. birds, ants, and termites) and the study of evolutionary computation. The PSO algorithm works by searching the search space for candidate solutions and gauging them with respect to some evaluation criterion. The candidate solutions are comparable to swarming particles moving in the fitness landscape in search for the optimal solution. Initially the PSO algorithm chooses some candidate solutions (candidate solutions can be randomly chosen or be set with some a priori knowledge). Then each particle's position and velocity (candidate solutions) are evaluated against the fitness function. Then if the fitness function is not satisfied, then update the individual and social component with some update rule. Next update the velocity and the position of the particles. This procedure is repeated iteratively until the all candidate solutions satisfy the fitness function and thus converges into a fix position. It is important to note that the velocity and position updating rule is crucial in terms of the optimization capabilities of the PSO algorithm. The velocity of each particle in motion (swarming) is updated using the following equation:(8)vi(t+1)=wvi(t)+c1r1[xˆi(t)−xi(t)]+c2r2[g(t)−xi(t)]where each particle is identified by the index i, vi(t) is the particle velocity and xi(t) is the particle position with respect to iteration t. The parameters w, c1and c2 are usually defined by the user. These parameters are typically constrained where w=[0,1.2], c1=[0,2], and c2=[0,2]. The range of random numbers are r1=[0,1], and r2=[0,1]. The term wvi(t) in Eq. (8) is the inertial term which keeps the particle moving in the same direction as its original direction. The inertial coefficient w serves as a dampener or an accelerator during the particles motion. The term also known as the cognitive component functions as memory. Hence, the particle tends return to the location in the search space where the particle had a very high fitness value. The term known as the social component serves to move the particle to the locations where the swarm has moved in the previous iterations. After the computation of the particle velocity, the particle position is then calculated as follows:(9)xi(t+1)=xi(t)+vi(t+1)The iterations are then continued until the all candidate solutions are at their fittest positions in the fitness landscape and some stopping criterion which is set by the user is met. The working algorithm of the PSO in this work is shown in Algorithm 2:Algorithm 2Particle swarm optimization (PSO).Step 1: Initialize no of particles, i and the algorithm parameters w, c1, c2, , noStep 2: Randomly set initial position xi(n) and velocity, vi(n)Step 3: Compute individual and social influenceStep 4: Compute position xi(n+1) and velocity vi(n+1) at next iterationStep 5: If the swarm evolution time, n>no+T, update position xiand velocity viand go to Step 3, else proceed to Step 6Step 7: Evaluate fitness swarmStep 8: If fitness criterion satisfied, halt and print solutions, else go to Step 3Game theory has been used to model systems where conflicting factors frequently surface, for instance in biology, economics and other social sciences [42–44]. The main tenet of game theory is that the rational pursuit of individual self-interest collectively produces a self-defeating outcome. A more general form of game theory is the EGT where the system being analyzed consists of a large number of players that meet in pairs in a random fashion. The EGT has been shown to be a better approach for modeling emergence and dynamics as a result of collective/interactive behaviors.In this work, some elements of the EGT are used to modify and enhance the standard DE algorithm. The EGT philosophy is used as a self-tuning mechanism in the DE strategy resulting in the GTDE approach. In the proposed method the offspring and the parent are engaged competitively to achieve the goal in each generation. The goal here is attaining an improved solution that is highly optimal and non-dominated. In this work, the two EGT based strategies are used to construct the self-tuning mechanisms for the DE algorithm. In EGT, strategies are often utilized in pairs which are subdivided into two groups: cooperative and defective strategies. These paired strategies are given in Table 3.In the GTDE approach, two paired strategies exist so that there is always a mechanism for the metaheuristic to employ for the purpose of search diversification and intensification. In every GTDE algorithm, the defective strategy has to be complemented by the cooperative strategy. The EGT framework gives the DE algorithm flexibility such as to modify its mutation factor online (during execution). Therefore, this online modification uses EGT framework as a guide where the principal parent actively plays against the child (offspring). This enhancement of the parent–child interaction strengthens the foundations of the conventional DE technique. Therefore, during execution, the GTDE technique constantly evaluates the solution fitness at each iteration. Then, it selects one of the strategies (defective or cooperative). This selection is not fixed throughout the program execution but rather can change depending on the fitness value at the current iteration. Thus depending on the fitness, the degree of conflict between the principal parent and child is modified through the mentioned mechanisms (mutation factor and child–parent influence). The algorithm for the GTDE approach employing strategy 1 and strategy 2 is as in Fig. 1and Algorithm 3.Algorithm 3Game-theoretic differential evolution (GTDE).Step 1: Initialize individual size N, P, CR and F and randomly initialize the population vectors,xiGStep 2: Randomly select one principal parents,xipand randomly select three auxilary parents,xiaStep 3: Evaluate fitness of current solution relative to the previous solutionStep 4: IF current fitness, FIT(gen) better than previous fitness, FIT(gen−1)Employ Cooperative Strategy between parent and child vectorELSEEmploy Defective Strategy between parent and child vectorStep 5: Perform differential mutation and generate mutated vector, ViStep 6: Recombine Viwithxipto generate child trial vector,xichildStep 7: Perform ‘knock-out’ competition for next generation survival selectionStep 8: If the fitness criterion is satisfied and gen=Tmax, halt and print solutionselse proceed to Step 3The solution sets (approximations of the Pareto frontier) were obtained using the PSO, DE and the GTDE techniques in conjunction with the weighted sum approach. The quality of these solutions was measured using the hypervolume indicator (HVI). This problem involves maximization as well as minimization of the objectives while maintaining solution feasibility. All algorithms used in this work were programmed using the C++ programming language on a personal computer (PC) with an Intel dual core processor running at 2GHz. The nadir point selected for the HVI was (100, 200, 900). The solution dominance is directly proportional to the value of the HVI. 28 solution points for various weights were obtained using both the DE and the GTDE methods. To construct the Pareto frontier, the weights were varied where for each solution:(10)wqp+1=wqp+0.1forwq0=0.1suchthat∑q=1mwqp=1andp∈[1,n]where p is the index that represents the next individual weight for each individual solution set, q is the index for the solution of each objective, m is the maximum number of objectives, n is the maximum number of solution sets for all the weight values andwq0is the initial weight.Since all the techniques employed in this work are stochastic in nature, for each weight value the algorithm was executed 5 times prior to selecting the best solution. Thus for all the solution points each algorithm in this work has been executed 140 times. In this work the GTDE technique was implemented twice by employing two of the paired strategies mentioned in Table 3. Therefore, we shall denote GTDE-1 for the technique that employs Cooperative and Defective strategies numbered 1 and GTDE-2 for the technique that employs Cooperative and Defective strategies numbered 2 in Table 3. The graphical representation of the approximate Pareto frontiers generated from individual solution options (for various scalarization values) using the DE algorithm is given in Fig. 2.Based on the values obtained using the HVI, the best, medium and worst individual solutions were identified. These values are shown in Table 4.The best, median and worst solutions obtained using the DE technique were at scalar weights of (0.2, 0.3, 0.5), (0.1, 0.5, 0.4) and (0.3, 0.5, 0.2) respectively. The values of the HVI at these solutions were 5.97×107, 5.79×107 and 5.55×107. Similarly, the frontier approximated using the PSO approach is given in Fig. 3and the ranked individual solutions are shown in Table 5.The ranked solutions (best, median, worst) obtained using the PSO approach were at scalar weights of (1.2, 0.5, 0.4), (0.4, 0.5, 0.1) and (0.1, 0.3, 0.6) respectively. The values of the HVI at these points were 5.28×107, 5.21×107 and 5.15×107. The approximate Pareto frontiers traced using the GTDE-1 algorithm is shown in Fig. 4.Similarly, the solutions produced by the GTDE-1 algorithm were ranked (maximum/best, median and the minimum/worst) based on the values of the HVI. The values of the objective functions, decision variables and the computational time are provided in Table 6.The solution ranked as best, median and worst options obtained using the GTDE-1 algorithm were at scalar weights of (0.2, 0.6, 0.2), (0.1, 0.5, 0.4) and (0.5, 0.4, 0.1) respectively. The values of the HVI at these solutions were 6.08×107, 5.91×107 and 5.7×107.The solutions that construct the approximate Pareto frontier ascertained by using the GTDE-2 algorithm are shown in Fig. 5.The GTDE-2 algorithm produced individual solutions which were ranked similar to the DE and GTDE-1 techniques (best, median and worst) based on the values of the HVI. The values of the objective functions, decision variables and the computational time are provided in Table 7.The solution ranked as best, median and worst options obtained using the GTDE-1 algorithm were at scalar weights of (0.2, 0.6, 0.2), (0.1, 0.5, 0.4) and (0.5, 0.4, 0.1) respectively. The values of the HVI at these solutions were 5.37×107, 5.34×107 and 5.28×107. The total computational time taken by the DE, GTDE-1 and GTDE-2 algorithms to completely construct the Pareto frontier with individual solutions for their respective scalarization is given in Fig. 6.The DE algorithm takes 6.419s while the GTDE-1 and GTDE-2 algorithms take 13.938 and 8.677s respectively to compute the optimal solutions for the entire Pareto frontier. Similarly this computation is carried out by the PSO approach with the total time of 13.62s. In Fig. 6, it can be observed that the DE algorithm completes the search earlier followed by the GTDE-1 and GTDE-2 algorithms respectively. Factors that may cause this mainly involve the algorithm's search capabilities and its complexity (which is usually interlinked). This causes some of the algorithms (in this work, DE and GTDE-2) to halt prematurely resulting in an incomplete search operation. It can be seen that the GTDE-1 algorithm produces the best individual solutions as compared to the GTDE-2 and the DE algorithms by 13.082% and 1.82%. Therefore, although the GTDE-1 takes longer time for obtaining the Pareto-efficient solutions, nevertheless it does a more complete and thorough search as compared to the GTDE-2 and DE algorithms. As for the PSO algorithm, it can be observed that although the computational time is high, the solutions produced are not as dominant as compared to other techniques employed in this work. Hence, it can be inferred that in the case of PSO, the search procedure itself was not efficient resulting in search efforts conducted in erroneous regions in the objective space. Thus, besides poor results, the execution time was also high.In this work, all numerical techniques performed stable calculations during algorithmic execution. All Pareto-efficient solutions produced by the algorithms developed in this work were feasible and no constraints were compromised. Besides, a local optimum was revealed in this work by the application of the GTDE-1 method (see Table 6).From Tables 4–7 it can be observed that GTDE-1 approach outperforms the GTDE-2, PSO and the DE techniques in terms of obtaining dominant solutions that maximize the frequency of oscillation (FOSC), maximize the average dynamic power (Pave) and minimize the leakage power (Pleak). This may be attributed to the additional optimization capabilities of the game-theoretic component in algorithmic adaptation based on fitness classification during the search process. It should also be noted that the GTDE-2 technique performed poorly as compared to the DE algorithm where the best individual solution obtained by the DE algorithm outweighed the GTDE-2 method by 11.06%. These findings emphasize the significance of the type of strategies employed in the GTDE and their impact on the computational results. As mentioned previously, GTDE-1 and GTDE-2 are essentially the same algorithm employing two different pairs of strategies (refer to Table 3). It can be observed that in this work, the GTDE-1 technique produces far more superior results as compared to the GTDE-2 method (both employing different pairs of strategies) such that the conventional DE approach outweighs the GTDE-2 method.The GTDE method can be considered robust and applicable for a wide range of multi-objective optimization problems assuming the right selection of strategies is employed. With a good selection of strategies the GTDE algorithm could be customized for solving a broader class of optimization problems. This robustness can be mainly attributed to the adaptive capabilities of game-theoretic component to handle factors arising from the various objective space topologies in different types of problems. Due to this enhanced adaptive capabilities in the GTDE method, the stability and the convergence of the computations are assured.A global solution with a better computational time may be obtained by implementing the GTDE-1 method on a high performance computer (HPC). The HPC should be a dedicated system capable of rigorous search and processing. During the execution of all the algorithms on the nano-CMOS VCO design problem, all methods performed very well in terms of solution feasibility. Hence, solutions produced by all methods did not compromise any of the stated constraints in this problem.One method to improve the algorithms employed in this work would be to hybridize or integrate them with other prevalent computing philosophies such as like fuzzy logic [45], Tabu search [46] or other classes of swarm and evolutionary algorithms [47,48]. Such efforts may provide game-theoretic based algorithms with a more efficient system for handling constraints and thus pave the way for obtaining solutions closer to the global optimum.In this work, a new local optimum was obtained by the efficient construction of the Pareto frontier using techniques which integrate EGT and evolutionary algorithms. The GTDE with the paired strategy 1 (GTDE-1) proved to be the best algorithm as compared to other techniques (GTDE-2, DE, PSO) employed in this work. Due to the complexity of solution measurement in a MO setting, the HVI was used to gauge the individual solutions produced by all the algorithms in this work. For future works, other meta-heuristic algorithms such as Artificial Bee Colony [27] and Cuckoo Search (CS) [24] should be integrated with EGT and experimented on other types of optimization problems. In addition, other types of approaches that use evolutionary strategies that enhance competitive interactions in the context of metaheuristics could be explored. In such investigations, new techniques and integration methodologies could be developed to effectively couple EGT-based mechanisms into metaheuristics for performance enhancement. The techniques utilized in this could also be executed with various algorithmic parameter settings where the optimal parameters for maximum performance may be accurately determined.

@&#CONCLUSIONS@&#
