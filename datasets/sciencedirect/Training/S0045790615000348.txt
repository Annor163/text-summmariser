@&#MAIN-TITLE@&#
Fast single image haze removal via local atmospheric light veil estimation

@&#HIGHLIGHTS@&#
A novel strategy is proposed based on the minimum and maximum of each RGB pixel.The concept of local atmosphere light veil is defined in this study.The reflection component of the scene is calculated accurately with imaging physical model.The proposed method yields even better results than the state-of-the-art techniques.

@&#KEYPHRASES@&#
Imaging systems,Image reconstruction techniques,Illumination design,Hazy removal,Image quality assessment,

@&#ABSTRACT@&#
In this study, a novel single-image based dehazing framework is proposed to remove haze artifacts from images through local atmospheric light estimation. We use a novel strategy based on a physical model where the extreme intensity of each RGB pixel is used to define an initial atmospheric veil (local atmospheric light veil). Across bilateral filter is applied to each veil to achieve both local smoothness and edge preservation. A transmission map and a reflection component of each RGB channel are constructed from the physical atmospheric scattering model. The proposed approach avoids adverse effects caused by the error in estimating the global atmospheric light. Experimental results on outdoor hazy images demonstrate that the proposed method produces image output with satisfactory visual quality and color fidelity. Our comparative study demonstrates a higher performance of our method over several state-of-the-art methods.

@&#INTRODUCTION@&#
Performances of outdoor vision systems for object detection, tracking and recognition are often degraded by weather conditions, such as haze, fog or smoke. Haze is the turbid medium (e.g., particles and water droplets) in the atmosphere, which can degrade the performance of the imaging system due to atmospheric absorption and scattering. The amount of scattering depends on the depth of scene and the light irradiance received by the camera attenuated along the line of sight. As a result, the haze-related degradation is varying spatially and the incoming light is scattered in the air forming an atmospheric veil in the physical atmospheric scattering model, i.e., the ambient light is reflected into the line of sight by atmospheric particles. Consequently, the degraded image loses both contrast and color fidelity. The atmospheric scattering model is illustrated in Fig. 1.In the past decades, research on hazy removal has received great attention. Many approaches have been proposed which have advantage of restoring a single hazy image without depending on any other source of information [1–9,15–17]. In [2], Fattal used local window-based operations and graphical models for dehazing. This method achieves reasonable results in separating uncorrelated fields, but is computationally intensive. In comparison, the method proposed by Tan in [1] does not always achieve equally good results on every saturated scene. However, this method is more generic and easier to apply to different types of images. In particular, it works on both color and grayscale images. In [30], the method of Ancuti uses a fusion-based strategy derived from two original hazy image inputs. This method first-demonstrated the utility and effectiveness of a fusion-based technique for dehazing, but the color of the restored image is often less vivid and the contrast may not be correct. Recently, an effective image prior, called the dark channel prior [4] has been proposed to remove haze from a single image. The key observation is that most local patches in outdoor haze-free images contain some pixels whose intensity are significantly lower than other pixels in at least one of the RGB color channels. The intensity of this dark channel is considered to be a rough approximation of the thickness of the haze. The algorithm proposed by Hein [4] applies a closed-form framework of matting to refine the transmission map, and this algorithm works with color image input. Based on He’s study, the dark channel prior was employed in a number of studies for single image dehazing [12,14,24,25]. For example, Tripathi and Mukhopadhyay [8] proposed an efficient algorithm using anisotropic diffusion for refining transmission map based on the dark channel prior.In [4], based on the theory of dark channel prior and atmospheric scattering model, the global atmosphere light is defined as the brightness of an infinity scene, which is an important parameter for the image restoration based on the physical atmospheric scattering model [26]. The restored image is darker if the estimated global atmospheric light is stronger than it should be, and vice versa. In other words, halo or oversaturation effect will occur in the sky area if the estimated value is smaller than the true value [25]. Some experimental results with different global atmospheric light values are shown in Fig. 2. Similar to [4], Xiao et al. [14] chose the brightest pixels (0.2%) in the dark channel to improve the accuracy of the atmospheric light. However, some brightest pixels in white objects may lead to undesirable result of the global atmospheric light value. Yeh et al. [24] determined the range of atmospheric light empirically by selecting the top 0.1% brightest value in dark channel and the top 30% darkest value in the bright channel, then estimated the atmospheric light of the hazy image.Despite the achievements made so far, there still lacks an effective method to accurately estimate global atmospheric light [13]. To improve the efficiency of the physical model based single image restoring algorithm [29,31], and inspired by the patch-based dark channel prior, two major factors which are critical to the quality of the restored images are addressed in details in this study. Our result provides more accurate estimation of the transmission map from which color and brightness of the image can be well restored. The major contributions of this study are outlined as follows.(1)In order to avoid the problem caused by the error in global atmospheric light estimation, we present a strategy to define a local atmospheric light veil A(x,y) from the hazy image patches with the premise that the local illumination of the scene is the same as the local atmospheric light.Both the local atmospheric light veil and the transmission map are calculated, and then the reflection component of the RGB channel is constructed from the atmospheric scattering model. This approach compensates the non-uniform illumination effects on images.The rest of the paper is organized as follows: In Section 2, the atmospheric scattering model, some related works and typical hazy removal algorithms are discussed in detail. Section 3 presents the proposed atmospheric scattering model based on the local atmospheric light veil. Section 4 provides a detailed description of the proposed algorithms. In Section 5, comparative experiments with both subjective and objective evaluations are described. Finally, we summarize our approach and discuss its limitations in Section 6.In computer vision, a widely used mathematical expression for describing the intensity L of a hazy image is established by Koschmieder [9–11]:(1)L(x,y)=L0(x,y)e-kd(x,y)+A(1-e-kd(x,y))where the apparent luminance of the captured image isL(x,y),d(x,y)is the distance of the corresponding object at a scene point(x,y)from the camera,Ais the global atmospheric light constant,L0(x,y)is the haze-free image, which can be defined as the scene radiance, andkdenotes the extinction coefficient of the atmosphere. The relationships among these variables and parameters are shown in Fig. 1.According to the atmospheric scattering model, haze is an exponential decay, given byt(x,y)=e-kd(x,y), where t(x,y) is the transmission function. Haze reduces the visibility and contrast of the object in the scene. The second effect of haze produced by a white atmospheric veilV(x,y)=A(1-e-kd(x,y)), which is an increasing function of the object distanced(x,y). Atmospheric scattering model can be directly extended to a color image by applying the same scheme to each RGB channel, andL(x,y)can be defined asLc(x,y),c∈[R,G,B]. For the sake of conciseness, we just useL(x,y)to represent color images in this paper, andρ(x,y)to represent the reflectance of each R,G or B channel andL0(x,y)=I(x,y)∗ρ(x,y).In order to solve the haze-free imageL0(x,y)from Eq. (1), Koschmieder’s law can be transformed as(2)L0(x,y)=L(x,y)-A(1-e-kd(x,y))e-kd(x,y)According to Eq. (2), the proposed restoration algorithm contains the following steps: (1) inference ofV(x)fromL(x,y)based on the dark channel prior; (2) estimation ofAandt(x,y)fromV(x); and (3) calculation ofL0(x,y)by Eq. (2). According to the atmospheric scattering model and the dark channel prior, the lowest reflectivity in red, green or blue channel at scene point(x,y)is supposed to be close to zero, i.e.ρ(x,y)→0, then atmospheric veilV(x,y)can be constructed from Eq. (1)(3)L(x,y)ρ(x,y)→0→A(1-e-kd(x,y))Assumingd(x,y)→∞andρ(x,y)→0, from Eq. (3), we have(4)L(x,y)ρ(x,y)→0&d(x,y)→∞→ASo, given constraintsρ(x,y)→0andd(x,y)→∞,Acan be estimated from Eq. (4).Based on (3), (4) and (1),t(x,y)andL0(x,y)can be solved. According to the dark channel prior [4],V(x,y)can be roughly estimated by(5)Vdc(x,y)=minc∈{R,G,B}Lc(x,y)Various filtering algorithms have been developed to obtain more accurate A andV(x,y), including soft matting, cross bilateral filtering and guided filtering. The composition of the scene is usually complex, soρ(x,y)→0andd(x,y)→∞cannot be both met in every point, as a result Eq. (5) only provides a severely under-constrained problem of estimation of A, and we will improve the solution based on mathematical modeling.The global atmosphere lightAis a key parameter for constructing the transmission function expressed in (3). A is a global atmosphere light value as observed in (1). If the conditionsρ(x,y)→0andd(x,y)→∞are both met,Acan be calculated. In many single-image dehazing methods, the global atmospheric light A is usually estimated from pixels with the densest haze, for example, in [4,14], the brightest pixels in the dark channel were chosen, which correspond to the foggiest regions. Then A can be estimated from the brightest pixels in the chosen region as shown in Fig. 2(a). However, this method depends on prerequisited(x,y)→∞and we are not sure whether it is true in real scenes as the patches shown in Fig. 2(a). The area in the top red box is obviously the haziest area for calculating A, while the area in the bottom red box is less hazy and does not satisfy all the requirements for applying (4). To show how the value of A affects the restored image, examples of restored results are given in Fig. 2(b) and (c) by the method proposed in [26] with A=162 and A=152. It can be seen that there are some halo effects in Fig. 2(c) as discussed in Section 1. So, global atmospheric light A is a critical factor for haze removal algorithms and a small error will lead to disastrous consequences.For the bottom patch in Fig. 2(a), two restored images are shown. Top image given in Fig. 2(d) is the restored image by the method proposed in [26] and it gets halo effect because the conditions in Eq. (4) cannot be met in this hazy patch. With the proposed method, we get a better restored image as the bottom one given in Fig. 2(d).Inspired by a recent research on global atmospheric light A[24], we focus on how to explain and choose A from the hazy images. In [24], Yeh et al. proposed that the density of haze in different regions of an image is different, and the value of atmospheric light for each pixel should be different accordingly. Based on the pixel-based dark channel prior and bright channel prior, they determined the pixel valueAhighestcof the color channelcwith the highest haze density in the image by selecting the pixel value corresponding to the top 0.1% brightest value in dark channelJdark_pixel, while determining the pixel valueAlowestcof the color channelcwith the lowest haze density in the image by selecting the pixel value corresponding to the top 30% darkest value in bright channelJbright_pixel. In this way, the atmospheric lightA(x)for the imageI(x)and the transmission map can be estimated via haze density analysis and bilateral filter respectively. However, it should be noticed that the color cast effect emerges in the restored image as shown in Fig. 3(l). There are three possible reasons for the color cast. Firstly, some researchers have demonstrated that treating the atmospheric light as a constant in a given image works well as we have given in Eq. (4), and some theoretical analysis should be made to support the transform of atmospheric light from a constant to a variable. Secondly, selections of thresholds in dark and bright channels are purely empirical which cannot be fully justified theoretically, which makes the method less convincing. After all, bilateral filter may not be the best choice for refining the transmission map, which has been shown in several reports [4,14].As discussed in Section 2, it is sometimes severely under-constrained to solve the scene radiance from the physical model given in (1). In this section, we analyze the reflectance of the scene point, and a new concept named local atmospheric light will be proposed to obtain more constraints in local regions.The proposed method attempts to estimate the reflectance of RGB components of each point, which is determined by both the illumination and the perceived image. Illumination of one patch can be estimated as the maximum values among RGB channels (max-RGB), and then the maximal reflectance of RGB channel in this patch will be normalized to 1, which is a very important hypothesis inspired by [28]. The perceived color of one point is determined by the ratio of RGB reflection coefficients, so this hypothesis does not change the tone of the scene, but saturation will be increased because of the normalization. Due to the nonlinearity of the nature scene illumination, it is almost impossible to determine its reflectance for every pixel, but the max-RGB method often gives a good approximation of the reflectance characteristics of the natural scene [18,19].In this paper, we will estimate the atmospheric light value in local patches of the image, and this process will be derived form a new point of view. As stated before, the global atmospheric light in the hazy image can be solved analytically from (3) and (4), provided that the assumptions of zero reflectivity and infinite distance are satisfied. But the major problem is that these conditions are difficult to be met, as a result, new methods with relaxed constraints are needed.According to (1), one effect of the fog is an exponential decay of the scene radiance. Another effect is the addition of an atmospheric veil which is a function of the atmospheric light. We thus assume that the haze is uniform and heavy so that there is no direct sunlight in the scene. In this case, the global atmospheric light is equal to the illumination of the scene, and the uniform illumination of the scene at any point will be A.With the imaging modelL0(x,y)=Aρ(x,y), Eq. (1) can be rewritten as follows:(6)L(x,y)=Aρ(x,y)e-kd(x,y)+A(1-e-kd(x,y))As discussed previously, the highest reflectivity among RGB components of one pixel can be approximated asρ(x,y)→1. For the patches in a hazy image, if any high reflectivity pixel exists, the atmospheric light of patchPican be solved from (6) withρ(x,y)→1. Thus, atmospheric light A of patchPican be estimated by(7)APi=max(x,y)∈Pi,c∈[R,G,B](Lc(x,y))According to Eq. (7), if the hazy image is divided into small patches, then the global atmospheric light should be changed into a local property which we define as the local atmospheric light veil. The constant global atmospheric light A transforms into variableA(x,y), and a new physical atmospheric scattering model can be established by(8)L(x,y)=A(x,y)ρ(x,y)e-kd(x,y)+A(x,y)(1-e-kd(x,y))The same procedures as those for Eq. (1) can used to estimate the parameters in (8).For Eq. (6), the hypothesis is that the sky is cloudy and there is no direct sunlight on the scene, and the unfavorable factors of reflectance of each RGB channel can be confined in a small area by advanced filtering algorithms. Compared with haze removal with the global atmospheric light, the method based on local patches atmospheric light can reduce the risk of influence of errors, and a comparison of restored images with local atmospheric light veil and global atmospheric light are given in Fig. 2(d). Obviously, with the global atmospheric light, some pixels in the patch are oversaturated. This problem can be solved using the proposed local atmospheric light veil.According to (8), we can calculate atmospheric veilVdc(x,y), local atmospheric light veilA(x,y)using Eqs. (5) and (7), respectively. Reflectivityρ(x,y)can be restored from the hazy image.We expectV(x,y)to produce a relatively smooth output image and maintain the edge details of the target. From (5), we can roughly estimateVdc(x,y)by the dark channel prior. After grayscale opening operation onVdc(x,y), we get an estimated value ofVdc′(x,y). LetE=Vdc(x,y)andD=Vdc′(x,y)be the input images as shown in Fig. 3(b) and (c). The filtered image,V(x,y), in the joint spatial-range domain is given by(9)V(x,y)=∑j∈pwChs2hrk1E-Ejhrk2c-cjhs∗Djwherepwis the window for calculatingV(x,y),cis the spatial part,cjis the position surrounding(x,y)withinpw.Ejis the range of the pointcj,k1,k2are the common profile of the kernel used in both domains,hsandhrare the employed kernel bandwidths, andCis the corresponding normalization constant. Thus, the bandwidthh=(hs,hr)is the only parameter to control the size of the kernel. Eq. (9) is illustrated in Fig. 3(d)We used the fast approximation algorithm for cross bilateral filtering [20]. The result is shown in Fig. 3(d), which preserves the computational simplicity while still provides near-optimal accuracy.According to (7), the preliminarily local atmospheric light veil functionA(x,y)can be defined as(10)Amc(x,y)=maxc∈{R,G,B}Lc(x,y)An example ofAmc(x,y)is shown in Fig. 3(e). The local atmospheric light veil function must be obtained before estimating the haze-free image. As discussed above, the basic property of the atmospheric light is its smoothness in a local area, andA(x,y)should be both relatively smooth and capable of maintaining the edge details of the scene [18,19]. Therefore, the cross bilateral filter matches well with these requirements [14,27].In order to get an accurate distribution of the local atmospheric light veil, we modifyAmc(x,y)by performing morphological closing of theAmc(x,y)image with a structural element. The radius of the structural element, which is typically defined as r=min[w,h]/10(w,hare the width and height of input image respectively), can be dynamically adjusted. If appropriate parameters are chosen, vivid color can be preserved in the recovered images. Additionally, the output of the grayscale closing operation on imageAmc(x,y)is defined asAmc′(x,y). By substitutingE=Amc(x,y)andD=Amc′(x,y)into Eq. (9),A(x,y)can be obtained. The assignment specifies that the filtered data at the spatial location(x,y)have range values ofAmc′(x,y)as shown in Fig. 3(f).A(x,y)is given in Fig. 3(g).The procedures of proposed algorithm are given as follows and the corresponding results are given in Fig. 3(a)–(i):1.Input the hazy color imageL(x,y)with RGB channels.According to R, G, and B channels at each pixel location, roughly estimate atmosphere veilVdc(x,y)by Eq. (5) (Fig. 3(b)).Perform opening operation and joint bilateral filtering onVdc(x,y)to estimate atmosphere veilV(x,y)(Fig. 3(c) and (d)).According to R, G, and B channels at each pixel location ofL(x,y), roughly estimate local atmospheric light veilAmc(x,y)by Eq. (10) (Fig. 3(e)).Use closing operation and joint bilateral filtering onAmc(x,y)to estimate local atmospheric light veilA(x,y)(Fig. 3(f) and (g)).SubtractV(x,y)fromL(x,y)to obtain a residual image without atmosphere veilV(x,y).WithV(x,y)=A(x,y)(1-e-kd(x,y))andA(x,y), calculate transmission function (Fig. 3(h)).From Eq. (2), compute the scene radiance byL0(x,y)=A(x,y)ρ(x,y)(Fig. 3(i)). The target reflectanceρ(x,y)is obtained byL0(x,y)/A(x,y)according to Eq. (8). The result is truncated to the range of [01] (Fig. 3(j)).We note that the reflectance image may or may not be the desired output of the algorithm since illumination factors such as shading could be natural components of the object appearance. Therefore, in this paper, we give two choices of outputs, e.g. scene radiance and reflectance as shown in Fig. 3(i) and (j).As we can see, the restored images in Fig. 3(i) and (j) are clearer and brighter than those results given by He [4] and Yeh [24]. Especially, the central area in the restored images exhibit excellent performance and looks brighter and more vivid, while the image in Fig. 3(l) shows some color cast. The flow chart of the proposed algorithm is shown in Fig. 4.

@&#CONCLUSIONS@&#
