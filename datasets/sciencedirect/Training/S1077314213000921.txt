@&#MAIN-TITLE@&#
Dynamic texture segmentation based on deterministic partially self-avoiding walks

@&#HIGHLIGHTS@&#
A video segmentation based on dynamic texture is proposed.The method uses deterministic partially self-avoiding walks and a k-means.The sequence of images is considered as a 3D matrix, which is split into blocks.A feature vector for each block is obtained using the deterministic walks algorithm.k-Means algorithm clusters is used to obtain the video segmentation.

@&#KEYPHRASES@&#
Dynamic texture segmentation,Deterministic partially self-avoiding walks,k-Means algorithm,

@&#ABSTRACT@&#
Recently there has been a considerable interest in dynamic textures due to the explosive growth of multimedia databases. In addition, dynamic texture appears in a wide range of videos, which makes it very important in applications concerning to model physical phenomena. Thus, dynamic textures have emerged as a new field of investigation that extends the static or spatial textures to the spatio-temporal domain. In this paper, we propose a novel approach for dynamic texture segmentation based on automata theory and k-means algorithm. In this approach, a feature vector is extracted for each pixel by applying deterministic partially self-avoiding walks on three orthogonal planes of the video. Then, these feature vectors are clustered by the well-known k-means algorithm. Although the k-means algorithm has shown interesting results, it only ensures its convergence to a local minimum, which affects the final result of segmentation. In order to overcome this drawback, we compare six methods of initialization of the k-means. The experimental results have demonstrated the effectiveness of our proposed approach compared to the state-of-the-art segmentation methods.

@&#INTRODUCTION@&#
Due to the increasing number of multimedia databases and the great potential for applications, dynamic texture is lately receiving growing attention from computer vision community. Although texture has been usually described as a repeating pattern in its exact or with minor variation, texture is much more complex than that. Even a white image containing salt-and-pepper noise could be a texture pattern, for instance an image of marble. Thus, dynamic texture can be defined as visual phenomena that exhibit spatial and temporal regularity. Thus, they can be seen as an extension of static textures to the spatio-temporal domain. Examples of dynamic textures include real world scenes of traffic, moving escalators, boiling water, fire and steam. Various applications using dynamic textures have been reported in the literature, such as video retrieval [1,2], music [3], motion analysis [4], medical images [5,6], among others. There is, thus, an increasing demand for efficient and effective methods for dynamic texture representation.Image or video segmentation is an important step in many computer vision systems. In particularly, dynamic texture segmentation consists of splitting the video into homogeneous regions in space and time. Video segmentation, including dynamic textures, faces a bigger challenge due to the need for consistency among segmentations of each frame, which is obtained by combining temporal and spatial information. Most of the existing approaches for dynamic texture segmentation are based on stochastic dynamical models [7–10]. The main difference between existing approaches relies on the manipulation of these models. In [7], the segmentation problem is managed as a level-set formulation using Martin distance [11] (a distance for non-Euclidean space) and Gauss-Markov model to represent each region. Second-order Ising descriptors governed by an autoregressive exogenous model were used in [10] to solve dynamic texture segmentation as a spatio-temporal variance minimization. Vidal and Ravichandran [4] proposed to model each dynamic texture as a linear dynamical system and a 2-D translational motion model. Then the segmentation is performed by clustering pixels with similar trajectories over time. Accurate segmentation on natural videos were obtained by Fazekas et al. in [12] by using a level set scheme that separates the video into regions obeying different motion assumptions. According to the authors, the motion assumptions based on the brightness conservation and color constancy assumption achieved the best results in segmenting dynamic textures. In [13], the dynamic texture is modeled by an autoregressive moving average model and the Kalman filter is used to estimate the parameters of the model (dynamic texture) and consequently the segmented video. Despite the promising results in dynamic texture segmentation, the methods described above are not able to model multiple regions that belong to different visual process [8] (e.g. video containing a river and grass, flag waving in the wind and a flock of birds flying, among others). To overcome this issue, Chan and Vasconcelos [8] proposed a method that estimates the parameters of k linear dynamical systems using the well-known Expectation Maximization (EM). Recently, an improved version was proposed in [9], which models dynamic textures as a collection of stochastic layers. Each layer models a dynamic texture sampled from a linear dynamical system. The reader can consult [14,15] for a review of dynamic texture methods.In this paper, we propose a dynamic texture segmentation method based on deterministic partially self-avoiding walks [16] and the well-known k-means algorithm. Recently, a method for static textures based on these walks was proposed in [16–18]. Unlike these works, we extend the deterministic partially self-avoiding walks for dynamic textures by performing walks on three orthogonal planes of the video. The first plane (XY) models spatial features, while the two other ones (XT and YT) model motion features. Thus, the proposed extension is able to extract both spatial and motion features from dynamic textures. After the feature extraction, the vectors obtained for each pixel are clustered by the k-means algorithm. Although the k-means algorithm provides robust solutions, it is widely reported in the literature that its performance depends on the initial choice of centroids. To overcome this drawback, this paper also reports experiments using six k-means initialization methods. Experimental results illustrate that our method outperforms the existing ones as it makes feature extraction of dynamic textures more effective and more independent concerning the initial choice of centroids. The three main contributions of this paper are: (i) A robust and effective extension of deterministic partially self-avoiding walks for dynamic textures analysis. (ii) A new method for dynamic texture segmentation that compares favorably the state-of-the-art. (iii) Comparison of six k-means initialization methods for this particular problem of segmenting dynamic textures.The rest of the paper is organized as follows. Image texture representation using deterministic partially self-avoiding walks is described in Section 2. Section 3 describes how to perform deterministic partially self-avoiding walks in sequence of images to extract features from dynamic textures. In Section 4, we present the proposed approach for dynamic texture segmentation. Section 5 describes six initialization methods for the k-means algorithm. Experiments and results are presented in Section 6, which is followed by the conclusion in Section 7.Recently, an approach for grayscale image texture analysis, namely deterministic tourist walk – DTW, was proposed in [16]. Compared to the state-of-the-art, the method proposed by Backes et al. achieved promising results for static texture classification. Following the promising method, a new criterion of motion for the agent was proposed in [17] and a combination of graphs and deterministic partially self-avoiding walks was proposed in [18]. All these works were interested in representing static textures. In this work, we present a new method for dynamic texture representation based on an extension of these walks.Next, we describe the use of deterministic partially self-avoiding walks in static textures since it is the basis for understanding our method of dynamic texture representation. Consider an image of W×H pixels, where each pixel i has a gray-level I(i) that ranges from 0 to 255. Each pixel i has also a set of neighboring pixels η(i) composed by the 8-connected pixels. If j∈η(i), then the weight of connection wijis given by the modulus of difference of intensity:(1)wij=|I(i)-I(j)|The method for static texture representation considers independent agents walking through image pixels. Given that an agent is in pixel i, it moves to one of the neighboring pixels j that minimizes the weight wij. Moreover, the agent avoids returning to pixels visited recently, which are stored in a memory M of size μ. Considering η(i) as the set of neighbors of i, the iterative steps taken by the agent can be described in Eq. (2). The motions of the agent is governed by a criterion of motion din. In Eq. (2), the agent walks toward the neighboring pixel with lower weight wij. This criterion of motion will be referred to as din=min. The agent could also walk towards the maximum weight wijaccording to Eq. (3). This criterion of motion will be referred to throughout this paper as din=max. Since the criterion is chosen, it should not be changed during the walks(2)j=argminj∈η(i){wij|j∉M}(3)j=argmaxj∈η(i){wij|j∉M}After a few steps, the agent produces a trajectory that can be divided into two parts: an initial transient part of size τ that ends in a cycle of period ρ called attractor. During the transient part, the agent walks freely to exploit texture features until it is trapped in an attractor. The attractor consists of a group of ρ pixels whose intensities form a pattern that the agent cannot escape from. Fig. 1shows an example of the trajectory produced by an agent. The transient part of size τ=3 is given by the three green pixels and the attractor of size ρ=6 is given by the orange pixels.To represent an image texture, each pixel is taken as an initial condition for a trajectory. If there are N image pixels, there will be N different trajectories initiated in each image pixel. The transient part and the attractor of each trajectory are combined into a joint distribution Sμ,din(τ,ρ). The joint distribution defines the probability of a trajectory belonging to a transient part of size τ and an attractor of size ρ according to Eq. (4). From the study of these distributions, features able to discriminate image textures can be obtained [16](4)Sμ,din(τ,ρ)=1N∑i=1N1,ifτi=τ,ρi=ρ0,otherwisewhere τiand ρiare the sizes of transient part and attractor from a trajectory initiated in pixel i.Dynamic texture segmentation is a very challenging problem, partly due to the need to extract appearance and motion features. The direct use of the previous method (e.g. 3D connection of the pixels) does not provide satisfactory results, due to lack of an explicit combination of appearance and motion features. For extracting both features from the dynamic texture, we propose to apply deterministic partially self-avoiding walks on three orthogonal planes. The three planes, namely XY, XT and YT planes, can be viewed in Fig. 2. The XY plane enhances appearance features while XT and YT enhance motion features from the dynamic texture. Using this strategy of planes, the steps of the agent are directed to extract each feature, proving better results than considering a 3D connection of the pixels.To apply the idea of the deterministic partially self-avoiding walks to dynamic texture, let I(i)∣i=(xi,yi,ti) be a sequence of images, where xiand yiare the spatial indexes and tiis the temporal index. The aim of the three orthogonal planes is to define the neighboring pixel η(i) and consequently to change and improve the agent’s behavior. The XY plane models the appearance features from the sequence of images. In this plane, the agent can only walk on image pixels belong to the same frame. Thus, the agent extracts the spatial variance of the dynamic texture using each frame independently. On the other hand, the XT and YT planes describe the temporal variation from the sequence of images. In these planes, the agent can walk between frames, so it extracts features related to motion. The definition of neighboring pixels for XY, XT and YT planes are presented in Eqs. (5)–(7), respectively. In previous works, we have evaluated the neighborhood set of pixels [16,17]. These experiments show that using other than this neighborhood (8-connected pixels) does not provide superior results as well as increase the computational time.(5)j∈ηXY(i)if(xi-xj)2+(yi-yj)2⩽2andti=tj(6)j∈ηXT(i)if(xi-xj)2+(ti-tj)2⩽2andyi=yj(7)j∈ηYT(i)if(yi-yj)2+(ti-tj)2⩽2andxi=xjTo combine appearance and motion features, we propose to apply deterministic partially self-avoiding walks on each plane described above using the new definition of neighboring pixel. For this, consider that the agent is in pixel i and it is walking on the XY plane. The next step is to move to one of the neighboring pixels j∈ηXY(i) that minimizes the weight wijand does not belong to the memory M of size μ. The iterative steps taken by the agent walking on the XY plane can be described in Eq. (8) for a criterion of motion din=min.(8)j=argminj∈ηXY(i){wij|j∉M}Following this deterministic rule, the agent is trapped in an attractorρiXYafter a transient partτiXY. Taking each pixel i as an initial step of a walk, the joint distributionSμ,dinXY(τ,ρ)is obtained according to Eq. (9).(9)Sμ,dinXY(τ,ρ)=1N∑i=1N1,ifτiXY=τ,ρiXY=ρ0,otherwiseIn the method proposed here, deterministic partially self-avoiding walks are applied separately on each plane. Thus, three joint distributions are built as described above:Sμ,dinXY(τ,ρ),Sμ,dinXT(τ,ρ)andSμ,dinYT(τ,ρ). From the analysis of these three distributions, our method is able to discriminate dynamic textures. Examples of joint distributions for the three planes are presented in Fig. 3. As can be observed, the four classes of dynamic textures present different joint distributions.Feature extraction from the joint distribution has been extensively studied in previous works [16,19,20]. The histogram of the joint distribution proved to achieve better results [16]. From a joint distribution, a histogramhμ,dinϕ(τ+ρ)is built to summarize the statistics (ϕ stands for one of the planes). This histogram represents the number of trajectories that has a size equal to (τ+ρ) in the joint distribution. It should be noted that τ+ρ is the number of visited pixels, but it does not match the number of different pixels visited since the trajectories can cross themselves. From the histogram, n features are selected to compose the feature vectorψμ,dinϕ. As there are no attractors of size smaller than μ+1, the first descriptor selected has this size:(10)ψμ,dinϕ=hμ,dinϕ(μ+1),hμ,dinϕ(μ+2),…,hμ,dinϕ(μ+n)The joint distribution and the feature vectorψμ,dinϕdepend on the memory size μ and the criterion of motion din (max or min). To capture information of different scales and sources, a feature vector φϕconsidering different values of μ is shown in Eq. (11). This feature vector is composed by concatenating the feature vectorsψμi,dinϕ:(11)φϕ=ψμ1,dinϕ,ψμ2,dinϕ,…,ψμM,dinϕwhere din is the criterion of motion which can be max or min.Using multiple memories helps to characterize texture patterns and has a great potential as a method of image classification [16]. In order to capture appearance and motion features, a strategy combining different planes is used. Thus, the feature vector φ (Eq. (12)) contains information extracted from three planes: XY, XT and YT.(12)φ=[φXY,φXT,φYT]In this section, we describe the proposed approach for dynamic texture segmentation. Fig. 4summarizes the proposed approach: (1) The video is split into overlapping blocks. (2) For each block, a feature vector is obtained using deterministic partially self-avoiding walks applied in the three orthogonal planes. (3) k-Means algorithm clusters the vectors resulting in the video segmentation. The sections below describe the three steps of the proposed method.Given a sequence of T images with w×h pixels, it is split into N= (w×h×T) blocks. For each pixel j, a block βjof p×p×q pixels centered on pixel j is extracted to compose the set of blocks. It is important to note that p and q must be large enough to model texture and motion features, and small enough to not mix different textures. These values depend on the size of the images and usually the values for p varies from 5 to 10 (p=9 in this work, p=7 in [21] and p=5 or 7 in [8,9]) and the values for q varies from 10 to T (− the number of frames.Fig. 5a shows examples of blocks of dimension p×p×q extracted from a sequence of image. If the segmentation boundaries do not change over time (e.g. dynamic textures from Fig. 6do not change their segmentation boundaries), the temporal dimension can be set to the size of the sequence q=T (Fig. 5b). In this case, only the first frame of the sequence needs to be segmented because the boundaries of dynamic textures in the sequence do not move over time.For each block βj, a feature vector φj(Eq. (12)) is extracted using the proposed method described in Section 3. To extract the feature vector, we have to define three parameters: number of features from the histogram n, criterion of motion din and set of memories μ1, …, μM.Statistical analysis on the joint distribution (e.g. taking different elements of Sμ,dinas feature vector in order to analyze the most discriminative and important elements) revealed that the important information for discriminating textures is concentrated in the first elements of the distribution [16]. Following these results, we have used five histogram descriptors n=5:(13)ψμ,dinϕ=hμ,dinϕ(μ+1),…,hμ,dinϕ(μ+5)According to [20], the best results of dynamic texture representation are achieved for din=max. In this case, attractors are formed in heterogeneous regions of the block, i.e., regions, where the changes in intensity are more abrupt, thus characterizing the presence of high frequencies. The combination of memories diminishes the importance of individual value of memory μ and it provides more effective texture representation. Thus, the set of memories consists of five memories ranging from μ=1 to 5 [16]. The feature vector using these parameters is presented in Eq. (14).(14)φϕ=ψ1,maxϕ,ψ2,maxϕ,…,ψ5,maxϕFinally, we concatenate the feature vector for each orthogonal plane. Thus using these parameters, a feature vector of 75-dimensional is obtained for each block.After feature extraction, the vectors φjare clustered by using the k-means algorithm. We have chosen this algorithm because it is a well-established clustering algorithm that is computationally efficient and does not require the specification of many parameters. Also, we have evaluated the Expectation Maximization algorithm which provided similar results but higher computational cost. The k-means is an iterative algorithm that minimizes the within-cluster sum of squared distances from the centroidxi¯by repeatedly movingxi¯to the arithmetic mean of its Voronoi set. The pseudo-code of the k-means algorithm is presented in Algorithm 1.Algorithm 1k-Means algorithmInput: Database X={xj}, Number of groups kOutput: C1, C2, …, CkInitializes each centroidxi¯;repeatdji=‖xj,xi¯‖2|1⩽j⩽N,1⩽i⩽k;nj=argmin1⩽i⩽kdji;Join the vector xjto the groupCnj;Calculate the new centroidsxi¯=1|Ci|∑xm∈Cixm;until No change occurs in groups Ci;Although k-means has been extensively used by the pattern recognition and computer vision community, it is known that its solution depends on the initial choice of centroids. Thus, the solution of the k-means may converge to a partition that is significantly inferior to the global optimum. Various heuristics have been proposed to find a robust initialization for the k-means. The following sections describe the main methods to initialize the k-means.Despite having many limitations and usually providing a local solution, the Random method is one of the most used methods for k-means initialization due to its simplicity. In this method, k vectors of the database are randomly chosen as centroids. Each vector from the database has the same probability of being chosen as an initial centroid.Astrahan [22] has proposed a k-means initialization method based on density. First, it defines a neighborhood radiusr=1N(N-1)∑i=1N-1∑j=i+1Nd(xi,xj), as the average pairwise distances. Then the density of each vector of the database is calculated. The density of a vector xiis calculated by counting the number of vectors that are at a distance less than r. The vector with the highest density is chosen as the first initial centroid. The other k−1 centroids are chosen in descending order of density, since they are at a distance r to all other centroids already chosen.A strategy based on pairwise distances was proposed by Katsavounidis [23]. The idea behind the KKZ method is to select vectors that are further away from each other, following the premise that these vectors probably belong to different groups. The first centroid is the one that has the highest norm (x1¯=argmax‖xj‖, where ∥·∥ is the vector norm). Then, it calculates the shortest distance djbetween each vector xjand the centroids already defined. The vector j with the largest distance djis chosen as the next centroid. Repeat the above steps until the number of groups is equal to k.A common method that presents an interesting solution is to initialize the k-means randomly M times and select the centroids which provide the best partition based on some internal measure. Following [24], a silhouette was chosen as an internal measure because it provides a high correlation with the optimal partition of the data.The PCA method [25] is based on an iterative application of a principal component analysis to split the groups. The method starts with all vectors belonging to the same group. Then, we choose a group Ci(at first only one group is available) with the highest intra-group variance to perform the group division. For the group division, the vectors xj∈Ciare projected towards the first component λ obtained by the principal component analysis. The projected vector is called yj. Then, it splits Ciinto two subgroupsCi(1)andCi(2)according to the rule: ifyj⩽y¯, set xjforCi(1); otherwise, set xjforCi(2). Repeat the above steps until the number of groups is equal to k.In image segmentation, it is common to perform a semi-supervised segmentation. Thus, the user manually divides the regions and the algorithm uses this initial segmentation to refine the solution. In this work, the databases provide the initial segmented regions manually.

@&#CONCLUSIONS@&#
In this paper, we proposed a new dynamic texture segmentation method based on deterministic partially self-avoiding walks and k-means algorithm. It first extracts a feature vector for each pixel using deterministic partially self-avoiding walks on three planes and then, these vectors are clustered using the k-means algorithm. The k-means algorithm experiences from the initial selection of centroids. Thus, this paper also presented a comparative study on six k-means initialization methods applied to the dynamic texture segmentation problem. Promising results on segmentation were achieved by the manual initialization and multiple runs of the k-means. Despite the underperformance, we suggest using the PCA initialization method for real-time applications. To estimate the suitable number of classes for the proposed method, we can perform the k-means using different values of k and taking the value of k which provides the highest silhouette measure as shown in the literature of data clustering [24].Experimental results indicate that our method performs better than existing dynamic texture segmentation methods (e.g. compared with the LDT method, our method achieved a rand index of 0.97 against 0.94 for k=2, 0.95 compared with 0.89 for k=3, and 0.94 compared with 0.92 for k=4). In addition, our method provided results significantly better than the results achieved by the Ising, MDT and GPCA methods.