@&#MAIN-TITLE@&#
A new decision to take for cost-sensitive Naïve Bayes classifiers

@&#HIGHLIGHTS@&#
A study of a conditional risk based on both variable and constant losses.A geometrical interpretation of the decision function of a classifier.An analysis of performance of different Naïve Bayes classifiers compared to SVM.

@&#KEYPHRASES@&#
Cost sensitive learning,Bayesian decision theory,Binary classification,Classical probabilistic models,

@&#ABSTRACT@&#
Practical classification problems often involve some kind of trade-off between the decisions a classifier may take. Indeed, it may be the case that decisions are not equally good or costly; therefore, it is important for the classifier to be able to predict the risk associated with each classification decision. Bayesian decision theory is a fundamental statistical approach to the problem of pattern classification. The objective is to quantify the trade-off between various classification decisions using probability and the costs that accompany such decisions. Within this framework, a loss function measures the rates of the costs and the risk in taking one decision over another.In this paper, we give a formal justification for a decision function under the Bayesian decision framework that comprises (i) the minimisation of Bayesian risk and (ii) an empirical decision function found by Domingos and Pazzani (1997). This new decision function has a very intuitive geometrical interpretation that can be explored on a Cartesian plane. We use this graphical interpretation to analyse different approaches to find the best decision on four different Naïve Bayes (NB) classifiers: Gaussian, Bernoulli, Multinomial, and Poisson, on different standard collections. We show that the graphical interpretation significantly improves the understanding of the models and opens new perspectives for new research studies.

@&#INTRODUCTION@&#
The task of data classification is today commonly applied in many contexts, ranging from customer target marketing to medical diagnosis, from biological data analysis to document categorisation. Practical classification problems often involve some kinds of constraints with respect to the effectiveness of the classifier, which is usually measured in terms of false-positive and/or false-negative rates. In some domains, these two rates may not be equally important. For example, for a spam classification system, a mis-classified legitimate email is generally considered unacceptable, while a spam message classified as non-spam is less serious (Kolcz, 2005).Bayesian decision theory is a fundamental statistical approach to the problem of pattern classification (Duda, Hart, & Stork, 2001). The objective is to quantify the trade-off between various classification decisions using probability and the costs that accompany such decisions. In this cost-sensitive framework, we can choose a learning algorithm and optimise its performance by tuning not only its parameters but also its misclassification costs. For example, in binary classification problems, i.e. when we have only two categoriesc1andc2, the Bayes decision rule can be interpreted as calling for deciding one category for an object o if the likelihood ratio (which is the ratio between the two probabilitiesP(o|c1)andP(o|c2)) exceeds a threshold value t. This threshold is independent of the observation o and can be tuned by means of the misclassification costs (the details of this formulation are presented in Section 3):(1)t<P(o|c1)P(o|c2)where t is the threshold that depends on the misclassification costs and on the priors of the two categories,P(c1)andP(c2). This way of optimising classifiers is very effective for unbalanced binary classification tasks (Almeida, Almeida, & Yamakami, 2011; Metsis, Androutsopoulos, & Paliouras, 2006).In the literature of pattern classification (Duda et al., 2001), NB classifiers have been shown to be one of the most efficient and effective inductive learning algorithms for classification tasks, despite the strong unrealistic assumptions (see Appendix A). The work by Domingos and Pazzani (1997) and the further study by Zhang (2005) define the conditions under which the NB classifier is an optimal classifier. An important consideration to take into account when working with NB classifiers is that there are simple linearly separable cases where the Bayesian classifier fails to predict the correct class; however, quoting (Domingos & Pazzani, 1997) “a simple modification of the Bayesian classifier will allow it to perfectly discriminate all positive examples from negatives: adding a constant to the discriminant function for the concept, or subtracting the same constant from the discriminant function for its negation”. This decision can be written in the following way:(2)P(o|c2)P(c2)<P(o|c1)P(c1)+lThis constant l, which has an empirical justification, hides a more complex interpretation of the costs in the context of cost-sensitive learning. In fact, it cannot be directly derived from the definition of costs in the cost-sensitive learning context. To the best of our knowledge, this simple step, which has been empirically shown to be very effective, has never been formally proven.The main contributions of this paper are:•A formal justification for a decision function under the Bayesian decision framework that comprises both (i) the minimisation of Bayesian risk and (ii) an empirical decision function found by Domingos and Pazzani (1997). The decision have the following linear form:P(o|c2)<mP(o|c1)+qwhere m and q depend on the mis-classification costs and can be seen as the angular coefficient and the intercept of a linear function. Note that forq=0we can derive Eq. (1) withm=P(c2)P(c1)t, while form=1we obtain Eq. (2) withq=l.Since this new decision function has a very intuitive geometrical interpretation that can be explored on a Cartesian plane, we present an adaptation of the Angular Region algorithm (Di Nunzio & Micarelli, 2004) that can efficiently find a (sub)optimal decision on a two-dimensional space.We use this graphical interpretation to analyse different approaches to find the best decision on four different Naïve Bayes (NB) classifiers: Gaussian, Bernoulli, Multinomial, and Poisson, on different standard collection. We show that the graphical interpretation significantly improves the understanding of the models and opens new perspectives for new research studies.The paper is organised as follows: in Section 2, we define the task of binary classification for NB classifiers. In Section 3, we present the Bayesian decision theory framework that is at the base of our formulation of the problem. Section 4 defines the new conditions and costs under which an optimal decision function which merges both Eqs. (1) and (2) can be found. In Sections 5 and 6 we present the experimental analysis and the discussion of the results, respectively. In Section 7, we suggest some of the related works, while in Section 8, we give our final remarks.Binary classification is the task of classifying objects into two classes on the basis of some properties of the objects. The usual notation to indicate these two classes is: c for the class of ‘positive’ examples, andc¯for the class of ‘negative’ examples. Often, real world classification problems have more than two classes, for example a set of classesC={c1,…,ci,…,cn}. In these cases, a common approach in machine learning is to define n binary classification problems, one for each class in the set C. Given an object o and a set of categories C, if we want to decide whether o should be assigned to categoryci∈C, we can build a simple probabilistic classifier that checks the following statement:(3)P(c¯i|o)<P(ci|o)wherec¯i=C⧹ci. Therefore, if the probability of the classciis greater than the probability of its complementc¯iwe can assign the object toci.1You may have noticed an inverted use of the inequality, which is usually written asP(ci|o)>P(c¯i|o). This will help us maintain the same order (less than) when presenting the Bayesian conditional risk in Section 3.1Since we do not know the value ofP(ci|o)of unseen objects (unless an ‘oracle’ tells us what the value ofP(ci|o)), in order to predict the probabilityP(ci|o)we need to reverse it by using the Bayes rule:(4)P(ci|o)=P(o|ci)P(ci)P(o)whereP(ci)is the probability of choosing the categoryciindependently of the object,P(o)is the probability of drawing one object o randomly, andP(o|ci)is the likelihood function.P(o|ci)is the mathematical model of our problem that we need to estimate by means of some training examples. The hypothesis we make about how the mathematical model influences the type of function and parameters we need to estimate. For example, if the objects we want to classify have binary properties, we can model the object as a set of Bernoulli variables, or if the objects have real values we may decide to model the objects as a set of Normal distributions (see Appendix A for examples of different models and details about the use of the independence assumption). In any case, once we have the model we are able to compute the probabilityP(o|ci)and predict the probability of the category given the object.The probabilityP(ci|o)is a combination of three variables:P(o|ci),P(o|c¯i), andP(ci).2P(c¯i)is not a parameter since it can be calculated from its complementP(c¯i)=1-P(ci).2When the marginal probabilities of the two categories are not balanced, i.e.P(ci)≄P(c¯i), and/or the number of properties that describe the object is very large, the Bayes classifier tends to “squeeze” probabilities either to one or zero making the prediction of classification highly biased, usually towards the “stronger” category (Domingos & Pazzani, 1997). For example, suppose thatP(ci)=0.8,P(o|ci)=0.2,P(o|c¯i)=0.7. In this situation, categoryciis more likely than the other (if we pick a random object, it belongs toci80% of the time), but the particular object o we are observing is much more likely to be generated byc¯i. If we predict the category of this object, we obtain:P(ci|o)=0.2·0.80.2·0.8+0.7·0.2=0.53so we would classify it undercieven though there is a high chance of it being a false positive. This example may seem trivial, but, as discussed in depth by Domingos and Pazzani (1997) and Zhang (2005), there are some important consequences for a Bayesian classifier. One consequence, in particular, is that there are simple linearly separable cases where the Bayesian classifier fails to predict the correct class; however, quoting (Domingos & Pazzani, 1997): “a simple modification of the Bayesian classifier will allow it to perfectly discriminate all positive examples from negatives: adding a constant to the discriminant function for the concept, or subtracting the same constant from the discriminant function for its negation”. Which means:(5)P(o|c¯i)P(c¯i)<P(o|ci)P(ci)+lwhereP(o)can be ignored “since it is the same for all classes and does not affect the relative values of their probabilities” and l is some real number that we can adjust to optimise the performance of the classifier. In Section 4, we provide a formal justification of this constant within a Bayesian decision theory framework.Bayesian decision theory is a fundamental statistical approach to the problem of pattern classification (Duda et al., 2001). The objective is to quantify the trade-off between various classification decisions using probability and the costs that accompany such decisions. Whenever we have an object to classify, if we take the decision to classify it underci, we are actually “taking a risk” because we may choose the wrong category. In a decision-theoretic framework, we define a loss functionλ(ci|cj)which tells us what is the loss in taking the decisionciwhen the ‘true’ decision iscj; therefore, it represents the quantity of risk we are taking in choosing that decision. A conditional riskR(ci|o), or expected loss, is defined as the average loss for choosing classcifor the object o, and the definition is (we use the same notation as (Duda et al., 2001)):(6)R(ci|o)=∑j=1nλ(ci|cj)P(cj|o)In this framework, the classification of an object becomes the problem of choosing the ‘less risky’ category given some loss functionλ(·|·). For a binary classification problem, the Bayes decision rule is selecting the action for which the risk is minimum:(7)R(ci|o)<R(c¯i|o)which, by using Eq. (6), is equal to(8)λ(ci|ci)P(ci|o)+λ(ci|c¯i)P(c¯i|o)<λ(c¯i|ci)P(ci|o)+λ(c¯i|c¯i)P(c¯i|o)We can group common terms and obtain:(9)[λ(ci|c¯i)-λ(c¯i|c¯i)]P(c¯i|o)<[λ(c¯i|ci)-λ(ci|ci)]P(ci|o)In binary classification problems, it is very common to use a zero–one loss function. This function has the termsλ(ci|ci)=λ(c¯i|c¯i)=0which means that we have no loss when we give the correct answer, andλ(ci|c¯i)=λ(c¯i|ci)=1which means that we have a cost equal to one every time we assign the object to the wrong category. A zero–one loss function leads to Eq. (3).Different costs can be used to balance the marginal probabilities of the categories:(10)P(c¯i|o)<[λ(c¯i|ci)-λ(ci|ci)][λ(ci|c¯i)-λ(c¯i|c¯i)]P(ci|o)(11)P(o|c¯i)P(c¯i)P(o)<[λ(c¯i|ci)-λ(ci|ci)][λ(ci|c¯i)-λ(c¯i|c¯i)]P(o|ci)P(ci)P(o)(12)P(o|c¯i)<[λ(c¯i|ci)-λ(ci|ci)][λ(ci|c¯i)-λ(c¯i|c¯i)]P(ci)P(c¯i)P(o|ci)For example, we can decide to set the costs of the loss function to completely cancel out the marginal probabilities,λ(ci|c¯i)-λ(c¯i|c¯i)=P(ci)andλ(c¯i|ci)-λ(ci|ci)=P(c¯i). From a conditional risk point of view, the last solution means considering the class with the highest marginal probability as the one with the highest risk of error.If[λ(c¯i|ci)-λ(ci|ci)][λ(ci|c¯i)-λ(c¯i|c¯i)]>1, we can write the discriminant function in terms of the likelihood ratio (Duda et al., 2001):(13)[λ(ci|c¯i)-λ(c¯i|c¯i)][λ(c¯i|ci)-λ(ci|ci)]P(c¯i)P(ci)<P(o|ci)P(o|ci¯)Thus, we can decide to assign o tociif the likelihood ratio exceeds a threshold that is independent of the observation o. We can further simplify the decision by assuming that we are interested only in the ratio of the differences of the costs, that is, we are not interested in knowing the exact cost of a mis-classification, but we do want to know the proportion between the two differences. Therefore, we have only one parameter, and this parameter can incorporate the ratioP(ci)P(c¯i):(14)t<P(o|ci)P(o|c¯i)wheret=[λ(ci|c¯i)-λ(c¯i|c¯i)][λ(c¯i|ci)-λ(ci|ci)]P(c¯i)P(ci)is any real number that can be used as a threshold to optimise the performance of the classifier.3It is very important to remember that the ratioP(o|ci)P(o|c¯i)does not represent the odds ofo|ci.3By following the definition of conditional risk and manipulating the equation, we found a multiplication factor which can be interpreted either as a balancing factor for unbalanced categories or a threshold. In the following section, we use some algebra to generalise (12) by including the additive factor as suggested by Domingos and Pazzani (1997).Domingos and Pazzani suggest using a constant to adjust the decision function of the Bayes classifier (Domingos & Pazzani, 1997). In this Section, we elaborate this idea by adding an additional cost to the definition of loss function, then we isolate this term from the definition of conditional risk by employing some algebra. First, we describe in words what this additional cost means in this framework. The conditional risk of one decision is the sum of all the probabilities of each possible decision weighted by the respective loss. In this context, a constant loss would mean that, given our decision, we always lose something no matter what the ‘true’ decision is. We can give an intuitive explanation of this hypothesis by associating a monetary cost to each decision (Elkan, 2001). For example, when we classify emails into spam and non-spam, we can assign the following costs to the decision ‘categorise as spam’ (numbers are purely indicative): if the message is truly spam, we estimate the cost of CPU power used to perform the classification equal to 0.01$ and the cost of storing the message equal to 0.50$; if the message was non-spam, we add to the cost of processing power 0.01$, a cost for storing the message equal to 0.05$ (this is less than the spam message because spam wastes useful disk space), and a cost for recovering the message equal to 10$. In this simple case, the constant cost that we have to pay regardless the true category of the message is 0.03$.Moreover, in this new elaboration, we also want to weight this constant loss by the probabilityP(o). In fact,P(o)is not equal for all the classes, and we can verify it by just computing it with the law of total probability. This decision is inline with standard approaches for developing cost-sensitive classifiers which weight the training examples according to the ‘costliness’ of misclassifying that example (Zadrozny, Langford, & Abe, 2003).Therefore, we can rewrite the loss function as the sum of two terms: one term is the original loss function, and the other term is proportional to some constant value and inversely proportional toP(o). The idea is that the lower the probabilityP(o), the higher risk we take. The following formula adapts these two terms in the definition of conditional risk:(15)R(ci|o)=∑j=1nλ′(ci|cj)P(cj|o)(16)R(ci|o)=∑j=1nλ(ci|cj)+lciP(o)P(cj|o)where the new costλ′(ci|cj)has been expanded in two addendsλ(ci|cj)+lciP(o): (i) the original lossλ(ci|cj), (ii) a constantlciwhich indicates that for the decision “categorise underci” we have a constant loss, no matter what the true categorycjis, divided by the probabilityP(o)which takes into account the fact that the risk in categorising unfrequent objects is higher.Proposition 1Let us consider a set of categoriesC={c1,…,ci,…,cn}, a decision, for example categorise an object o underci, and a loss functionλ′(ci|cj), if we can find for each categorycja decomposition of the loss function into two termsλ′(ci|cj)=λ(ci|cj)+lciP(o)such that one term is the original loss functionλ(ci|cj)and the other term is a constant equal for allcjdivided by the probabilityP(o), then the conditional risk is(17)R(ci|o)=∑j=1nλ(ci|cj)P(cj|o)+lciP(o)By expanding Eq. (16), we obtain:(18)R(ci|o)=∑j=1nλ(ci|cj)P(cj|o)+lciP(o)P(cj|o)(19)=∑j=1nλ(ci|cj)P(cj|o)+∑j=1nlciP(o)P(cj|o)(20)=∑j=1nλ(ci|cj)P(cj|o)+lciP(o)∑j=1nP(cj|o)︸1(21)=∑j=1nλ(ci|cj)P(cj|o)+lciP(o)□At this point, we can show how our new definition of conditional risk in terms of this new loss function is the bridge between the empirical definition of the discriminant function of Domingos and Pazzani (1997) and the likelihood ratio (Duda et al., 2001).Proposition 2Let us consider a set of categoriesC={c1,…,ci,…,cn}, and a binary classification problem whereci∈Cis the class of positive examples andc¯i=C⧹ciis the class of negative examples. Provided that we can write the conditional risk for bothciandc¯iwith Eq.(17), the optimal decision function which minimises the Bayesian risk is:(22)P(o|c¯i)<[λ(c¯i|ci)-λ(ci|ci)][λ(ci|c¯i)-λ(c¯i|c¯i)]P(ci)P(c¯i)P(o|ci)+lci¯-lciλ(ci|c¯i)-λ(c¯i|c¯i)P(c¯i)Let us assume that the original cost function meets the “reasonableness” conditions (Elkan, 2001) whereλ(c¯i|ci)>λ(ci|ci)andλ(ci|c¯i)>λ(c¯i|c¯i).4These are reasonable conditions in the sense that the loss of a misclassification is always greater than the loss of a correct classification.4If we want to minimise the risk, we assign a new object o tociif:(23)R(ci|o)<R(c¯i|o)(24)λ(ci|ci)P(ci|o)+λ(ci|c¯i)P(c¯i|o)+lciP(o)<λ(c¯i|ci)P(ci|o)+λ(c¯i|c¯i)P(c¯i|o)+lci¯P(o)(25)λ(ci|c¯i)-λ(c¯i|c¯i)P(c¯i|o)<[λ(c¯i|ci)-λ(ci|ci)]P(ci|o)+lci¯-lciP(o)(26)P(c¯i|o)<[λ(c¯i|ci)-λ(ci|ci)]λ(ci|c¯i)-λ(c¯i|c¯i)P(ci|o)+lci¯-lciλ(ci|c¯i)-λ(c¯i|c¯i)P(o)(27)P(o|c¯i)P(c¯i)P(o)<[λ(c¯i|ci)-λ(ci|ci)][λ(ci|c¯i)-λ(c¯i|c¯i)]P(o|ci)P(ci)P(o)+lci¯-lciλ(ci|c¯i)-λ(c¯i|c¯i)P(o)(28)P(o|c¯i)<[λ(c¯i|ci)-λ(ci|ci)][λ(ci|c¯i)-λ(c¯i|c¯i)]P(ci)P(c¯i)P(o|ci)+lci¯-lciλ(ci|c¯i)-λ(c¯i|c¯i)P(c¯i)□A ‘pseudo’ zero–one loss function is a loss functionλ′(ci|cj)which can be rewritten as the sum of two addendsλ′(ci|cj)=λ(ci|cj)+lciP(o), withλ(ci|cj)=0fori=jandλ(ci|cj)=1fori≠j.Eq. (22) contains two important results:•First, it gives a mathematically sound justification for the constant found empirically by Domingos and Pazzani (1997). In particular, whenever we use a decision function like:(29)P(o|c¯i)P(c¯i)<P(o|ci)P(ci)+lit means that we are using a ‘pseudo’ zero–one loss function (Definition 1), and not a proper zero–one loss function. The parameter l incorporates the differencelci¯-lci, the differenceλ(ci|c¯i)-λ(c¯i|c¯i)and the probabilityP(c¯i).Second, it is a generalisation of Eq. (12). In fact, whenlci¯=lci=0, that is when we do not have any additional constant cost for a mis-classification, we obtain:(30)P(o|c¯i)<[λ(c¯i|ci)-λ(ci|ci)]λ(ci|c¯i)-λ(c¯i|c¯i)P(ci)P(c¯i)P(o|ci)In this section, we discuss how Eq. (22) can produce a significant difference in terms of classification performance for a binary classifier. To better appreciate this difference, we will interpret the decision function from a different perspective by following the approach named ‘likelihood projections’ (Singh & Raj, 2004). A ‘Likelihood projection’ uses the likelihood functionsP(o|ci)andP(o|c¯i)for nonlinear projections into a two-dimensional space (Duan, Jiang, & Man, 2006). The coordinates of an object in this two-dimensional ‘likelihood space’ arex=P(o|ci)andy=P(o|c¯i). In this new space, the Bayesian classifier can be viewed as a simple linear discriminant.5Non-linear discriminant functions are also possible but are not presented in this paper.5This linear discriminant function was already implicitly written in Eq. (12); here, we rewrite the equation and group some terms to highlight the terms of the linear function:(31)P(o|c¯i)︸y<[λ(c¯i|ci)-λ(ci|ci)][λ(ci|c¯i)-λ(c¯i|c¯i)]P(ci)P(c¯i)︸mP(o|ci)︸xwhere x and y are the coordinates of the likelihood space, and m is the angular coefficient of the functiony=mx. With a classical conditional risk approach, we can only adjust the slope m of the linear function.On the other hand, if we group the terms of Eq. (22), we obtain:(32)P(o|c¯i)︸y<[λ(c¯i|ci)-λ(ci|ci)][λ(ci|c¯i)-λ(c¯i|c¯i)]P(ci)P(c¯i)︸mP(o|ci)︸x+lci¯-lciλ(ci|c¯i)-λ(c¯i|c¯i)P(c¯i)︸qIn order to show how the intercept q of the linear discriminant function can radically change the decision of a binary classifier, we present two very simple examples. In both cases, we have two classes: the class of triangles with two examples, and the class of circles with only two examples. The class of triangles is our ‘positive’ classci. The class of circles is the ‘negative’ classc¯i. The points are shown in Fig. 1a and b and the coordinates of the points are the values of the Likelihood functions. The solid line represent a possible solution which can be found by Eq. (31), the dashed line another possible solution found by Eq. (22).In Fig. 1a, we can perfectly separate the two classes by adjusting the slope of the line. However, you may notice that a shift of the discriminant line can maximise the distance between the points and the separating plane (in this case the dashed line). In Fig. 1b, we have the same classes and objects, but one of the points of the negative class has just a slightly smaller likelihoodP(o|c¯i). This small change does not allow us to find a separation between the two classes by only adjusting the slope of the discriminant function. This simple example shows the big advantage of reformulating the conditional risk in terms of constant costs.

@&#CONCLUSIONS@&#
In this paper, we have elaborated a formal definition for a new decision function the parameter of which are related to the misclassification costs of a binary classification problem. This new function it is both a generalisation of the likelihood ratio (Eq. (12)) and a mathematically sound justification for the constant found empirically by Domingos and Pazzani (1997).By means of a two-dimensional representation of objects based on likelihood spaces, we have proposed a graphical interpretation of the decision function for differen NB models. This showed, for the first time, why some NB classifiers perform better than other, and how far the optimal solution is compared to classical decision function, for example the zero–one loss function. By having an additional parameter (the intercept of the linear function), we have shown a strategy to improve the performance of each of the classifiers.Finally, we presented a thorough analysis of the influence of each step (choice of the dataset, the model, the background knowledge, and learning algorithm) to the classification performance of NB classifiers. We believe that this new geometrical interpretation of the decision function will open new perspectives on the study and understanding of probabilistic binary classifiers.