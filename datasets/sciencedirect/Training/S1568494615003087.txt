@&#MAIN-TITLE@&#
Emphasizing typing signature in keystroke dynamics using immune algorithms

@&#HIGHLIGHTS@&#
The paper focuses on keystroke dynamics in a one-class scenario.We show that proper data understanding and preprocessing can be crucial in this scenario.Samples from the same user present similarities in what we call typing signature.Rank transformation can take advantage of it to improve classification performance.This transformation was decisive for the performance of some immune algorithms.

@&#KEYPHRASES@&#
One-class classification,Data pre-processing,Immune algorithms,Keystroke dynamics,

@&#ABSTRACT@&#
Improved authentication mechanisms are needed to cope with the increased data exposure we face nowadays. Keystroke dynamics is a cost-effective alternative, which usually only requires a standard keyboard to acquire authentication data. Here, we focus on recognizing users by keystroke dynamics using immune algorithms, considering a one-class classification approach. In such a scenario, only samples from the legitimate user are available to generate the model of the user. Throughout the paper, we emphasize the importance of proper data understanding and pre-processing. We show that keystroke samples from the same user present similarities in what we call typing signature. A proposal to take advantage of this finding is discussed: the use of rank transformation. This transformation improved performance of classification algorithms tested here and it was decisive for some immune algorithms studied in our setting.

@&#INTRODUCTION@&#
The current technological scenario has brought a number of improved services to society, particularly owing to Internet-based applications. However, at the same time, this scenario has contributed to increase data exposure, giving a new momentum to concerns regarding identity theft. Thereby, there is a need to enhanced authentication mechanisms. A possible alternative is by the use of biometrics. In security area, biometrics tries to recognize users by physiological or behavioral features of the person.There are several biometrics technologies currently available. This work focuses on keystroke dynamics, which studies ways to recognize users by their typing rhythm. This technology shows as being a promising alternative due to several reasons [1,2]. Firstly, it usually does not need any additional cost with hardware, as a common keyboard is enough to acquire keystroke data. Other biometric technologies, such as fingerprint or iris recognition, require a specific device to acquire biometric data. Secondly, keystroke dynamics recognition may be performed in background, while the user is typing an e-mail or entering a password. Consequently, day-to-day tasks are not disturbed, what may contribute to a better acceptability of the technology by the user.A keystroke dynamics system should be able to distinguish a legitimate user from potential intruders, a classic binary classification setting in pattern recognition and machine learning. Nonetheless, collecting intruders data can be impractical in day-to-day use of computational systems. This makes a one-class classification setting more appropriate, where the user model is built using data from the legitimate user only.Several algorithms have been applied for classifying users by keystroke dynamics, in both one-class and conventional two-class settings [3–5]. This paper focuses on immune algorithms, which attained good performance in some of our previous works [6–8].In this paper we perform a deeper analysis of immune systems in the context of keystroke dynamics, analysing its performance under various aspects. The main goals are:•Show that proper data understanding and preprocessing can be crucial in keystroke dynamics.Apply rank transformation in keystroke dynamics in order to improve recognition performance. This transformation can emphasize what is called here as typing signature.Dealing with keystroke dynamics requires proper data understanding and preprocessing, as in the case of other areas [9,10]. Without it, classification algorithms may fail to reach optimal performance. This issue is even more crucial in a one-class setting, where one has to rely only on positive data for distinguishing both positive and negative data. In some cases, it may not be possible at all to perform data classification. To the best of our knowledge, there are not many papers dealing with data understanding and pre-processing in keystroke dynamics. This paper shows that some versions of immune systems are heavily affected by data pre-processing techniques, while others are more robust. This paper contributes by investigating how keystroke data behaves and showing a proposal to improve classifiers performance: the rank transformation.In this work, we study the application of several immune algorithms along with an investigation on keystroke data. Several interesting results and conclusions from our research on keystroke dynamics in recent years, such as [8], [6] and [7], are discussed here in the context of data analysis. Next sections are organized as follows: in Section 2, we briefly introduce some previous work in keystroke dynamics; in Section 3, immune algorithms are briefly described in the context of keystroke dynamics; in Section 4, we present the concept of typing signature and how we can take advantage of it for improving classification performance; in Section 5, issues regarding data rescale in keystroke dynamics are discussed and we present our evaluation model; in Section 6, the results of applying rank transformation are discussed along with interesting findings regarding immune algorithms; in Section 7, we compare the performance of rank transformation to decimal rescale; and, in Section 8, we present our conclusions.The area of keystroke dynamics has been studied for several years [5]. In order to identify the state of the art in keystroke dynamics, we conducted a quasi-systematic review [11]. Through the review, we identified main algorithms employed in this area and features extracted from keystroke data.Table 1shows a summary of main classification algorithms used in keystroke dynamics according to our recent review [11]. The number of users considered in each study and the error rate reported are also presented. Concerning the “Error rate” column, when there is a single value it stands for equal error rate (EER), otherwise it refers to false acceptance rate (FAR)/false rejection rate (FRR), respectively. FAR is the rate in which an intruder is wrongly accepted as being the legitimate user, while FRR is the rate in which the legitimate user is wrongly classified as an intruder. EER is the value in which FAR and FRR are equal. FAR, FRR and ERR are the most common evaluation measures employed in the area.A common keyboard provides the instants when each key is pressed and released. Based on these data, a number of features may be extracted in order to generate the feature vector, as shown in Fig. 1. All of these features are computed as time differences. For instance, the feature DU1 represented in Fig. 1 is the time difference between the instants in which a key is pressed and released. Some previous research also investigated the use of the pressure over the keys [23,22], however, it requires a specialized device.Few studies performed a deep analysis of data in keystroke dynamics. However, some previous work deserve to be highlighted due to their different approaches to keystroke data. In [16] and [3], the authors studied the use of discretization over raw data. Each attribute in the feature vector was discretized into five values. The work of [15] applied a process of equalization in keystroke data. A comparison of different feature vectors in keystroke dynamics is done in [1].Next section introduces immune algorithms. Afterwards, we discuss their use in keystroke dynamics.Artificial immune systems are computational systems inspired by the biological immune system and applied to solve problems [24]. These systems have been used in several applications related to pattern recognition, anomaly detection and optimization. This paper focuses on anomaly detection, which involves recognizing whether examples presented to the algorithm are legitimate or not. It is possible to draw a parallel between immune systems and the recognition of users by keystroke dynamics systems. Both need to generate a model of what is normal and be able to distinguish abnormal events (intruders) from this normal model.According to a recent review on immune systems [25], negative selection algorithms are the most used in intrusion detection. This work focuses on these algorithms and also a strongly related class of immune algorithms called positive selection. Next sections present both immune algorithm classes: negative and positive selection.Negative selection was introduced by Forrest[26]. As shown in Fig. 3, this algorithm is composed of two main phases: censoring (training) and detecting (matching). In the first phase, given a set of positive (self) examples, the algorithm generates random detectors and tests each of them against the available positive examples. Any detector which matches a positive example is discarded. This process is executed until a predefined amount of detectors is reached. The main idea is to cover the negative space with detectors (negative detectors), as shown in Fig. 2.Afterwards, in the detecting phase, each example presented to the algorithm is tested against the detector set. If any detector matches it, the example is classified as negative (non-self), otherwise, it is classified as positive (self).A number of negative selection algorithms were presented after the first proposal of Forrest [26]. However, the main principles seen in Fig. 3remained [27]. In keystroke dynamics, feature vectors are real-valued vectors and, therefore, we chose algorithms that are able to cope with this type of data representation. A negative selection algorithm which supports real-valued representation is the constant sized negative selection algorithm (CRNS) [28]. This algorithm was extended to support some variable properties, like variable detector radius [29], resulting in the V-Detector. Next sections present a brief overview of CRNS and V-Detector.In CRNS [28], data are represented in the d-dimensional space [0;1]d. Negative detectors are d-dimensional vectors with radius r, defining a hyper-sphere. An example is matched by the detector if the distance between the center of the detector and the example is equal or less than the radius r of the detector [30]. Usually, Euclidean distance is employed. The detector radius r is constant in CRNS and is defined by the user.The algorithm also needs a self-radius, which is assigned to each example in the positive set and is also set by the user. During training, real-valued vectors are randomly generated. If the generated vector falls outside the space defined by the set of positive examples and their pre-defined self-radius, the vector is accepted as a center of a new negative detector. The detector radius r is them assigned to this center, resulting in a new negative detector. This process of detector generation is performed until a predefined number of detectors is obtained.Another important negative selection algorithm isV-Detector[27]. Instead of using fixed values for the amount of detectors and the radius, as CRNS does, V-Detector generates detectors adapted to each case, defining how many detectors are needed and the radius of each detector in order to maximize coverage of the non-self space. Fig. 4illustrates it. V-Detector has the advantage of usually generating a decreased number of detectors when compared to CRNS, improving matching efficiency.Several versions of V-Detector were proposed, as presented in [29]. In this paper, we adopted the boundary-aware version with statistical coverage estimation due to the improved performance seen in previous work. More details on V-Detector are discussed in [29].Immune positive selection works similarly to negative selection: both are based on the idea of covering spaces using detectors. However, in contrast to negative selection, positive selection generates detectors to cover the positive space, as shown in Fig. 5. A key algorithm which follows this principle is Self-Detector[31].In the training phase, Self-Detector simply copies all the training examples and uses them as positive detectors. These detectors also have a constant radius of coverage. In [31], the radius is defined by a ROC analysis, however, here we used another method to define it, as discussed in Section 5. Afterwards, in the matching phase, when an input example is presented, all detectors are tested against it. If any detector matches the example within its radius of coverage, it is classified as positive (self) and, otherwise, it is classified as negative (non-self). A detector matches a example if the distance between its center and the example is equal or less than its radius, as in the case of detectors in negative selection. It is important to notice that detectors in positive selection are intended to match positive examples. Fig. 6summarizes how positive selection works.In the context of keystroke dynamics, a positive example refers to the legitimate user and a negative example to the intruder. In this paper, we consider keystroke dynamics as a one-class classification problem, in which only examples from the legitimate user are available during training and are used to build the sets of detectors in both negative and positive selection algorithms.To the best of our knowledge, apart from our research, there are other two works which used immune algorithms in keystroke dynamics: [32] and [33]. Both of them performed specific analysis and did not report their results in terms of FAR, FRR or EER, which are common evaluation measures in the area.In [32], the author mentioned that positive selection is more suitable to keystroke dynamics because the positive space is smaller than the negative space. As a result, it would be easier to cover the positive space with detectors. However, that study considered a scenario with only five users, making it difficult to draw any statistical significant conclusion.Another point in favor of positive selection is that its training time of positive selection is almost null, as it only needs to copy training examples and assign them a detector radius. Nevertheless, this may be a drawback when there are too many training examples and detection phase may also be costly.We also studied negative selection application to keystroke dynamics in [6–8]. In these works, we recommended the use of cosine distance (1) instead of the common Euclidean distance (2). We argued that keystroke dynamics may deal with feature vectors of higher dimensionality and Euclidean distance does not scale well in these scenarios. Besides, considering the correlation between keystroke examples showed to be more significant.(1)cosine_dist(x→,y→)=1−∑i=1dxiyi∑i=1dxi2∑i=1dyi2(2)Euclidean_dist(x→,y→)=∑i=1d(xi−yi)2A proper data understanding before applying a classification algorithm is an important step in several areas. This section presents an analysis of keystroke data, followed by a proposal to enhance classification performance by emphasizing the characteristics of such data. In order to perform this analysis, we adopted two benchmarking datasets:•GREYC [34]: 100 users typed the expression “GREYC laboratory” at least 60 times in five sessions, in a period of 2 months. Considering all users, there are more than 7000 examples available in GREYC dataset.CMU [20]: 51 users typed the password “.tie5Roanl” plus Enter key 400 times in eight sessions. Considering all users, a total of 20,400 examples are available in this dataset.In this paper, we extracted the feature UD from keystroke data, which is the time difference between releasing a key and pressing the next key, as presented in Section 2. Fig. 7shows how a feature vector is generated using UD. In GREYC, the feature vector has 15 dimensions (16 keys) and, in CMU, it has 10 dimensions (11 keys). According to our recent review [11], UD is one of the most used features in keystroke dynamics.Next section analyses keystroke data and presents rank transformation for keystroke dynamics.Firstly, in Fig. 8, we show some keystroke examples from two different users in both datasets [8].As shown in these figures, a user may be distinguished from another by the profile of the curve representing the keystroke example. This demonstrates that it is possible to recognize users by their typing rhythm. The profile of the curve is called typing signature here. We can also see that there are some variations between examples from the same user. This is expected, as this data is generated by people, which are subject to tiredness, emotions and motor difficulties. Such variations indicate that keystroke data may contain noise and outliers.Despite such variations, it is possible to notice that a given user tends to type some excerpts of the expressions at higher or lower speeds than others parts. This leads to similar tendencies of ups and downs in the typing curves, what can justify our previous finding that using a correlation measure for computing the distances between examples can be more adequate than simply relying on a standard Euclidean distance [6,7]. In fact, Euclidean distance is not able to properly capture the similarity between the feature vectors in the presence of such variations, and will tend to assign high distances between feature vectors that have a similar patterns but present some local distortions.Therefore, pre-processing data for evidencing the typing signature of the users can be profitable in keystroke dynamics. In the next section, we present the rank transformation, which takes advantage of this insight.A possible way to consider the typing signature is to enhance its pattern. This strategy could, for instance, highlight features which have a low variation range, but are still important to recognize users. Rank transformation is based on this insight.As the name suggests, this transformation consists of assigning rankings to values in the feature vector, as shown in Fig. 9[8]. Afterwards, these rankings are rescaled to [0;1] using Eq. (3), in which xiis the value of index i in the feature vector and RM is the highest ranking value. This rescale is done to keep the transformed feature vectors in the range commonly adopted by the immune algorithms used in this paper. In Fig. 9, the highest ranking is six. The rank transformation is similar to the one in [36], which works with time series. Another similar idea is seen in the Spearman rank correlation coefficient applied in [37] and distance measures studied in [4].(3)xi′=xiRMThe effect of applying the rank transformation on the examples seen in Fig. 8 is shown in Fig. 10[8]. These figures show how some differences in the typing signature were highlighted after applying this transformation.Rank transformation emphasizes the order of the time differences in the feature vector. As a result, parts of the text in which the user spends a longer time have a tendency to always assume high ranking values. It is expected that these rankings are similar for the same user and dissimilar between different users. Consequently, it emphasizes differences in the typing signature between feature vectors of two different users.Additionally, noisy and outliers values may be reduced by using this transformation. In raw data, differences between examples from the same user in terms of magnitude may be close to that of examples between different users. Therefore, the classification may become difficult. The rank transformation, instead, can highlight the difference between examples from different users, improving classification performance. This may also contribute to algorithms based on Euclidean distance, which are highly dependent on comparisons in the magnitude level (e.g. CRNS, Self-Detector).Using rank transformation, data can also become less sparse in the [0;1] space. In summary, rank transformation may potentially reduce the effect of the curse of dimensionality in keystroke dynamics. An important consideration is that the suitability of the use of this transformation should be evaluated for each application domain and classification technique.As described in Figs. 3 and 6, negative and positive selection algorithms have two main phases: training and matching. Nonetheless, during training we must also define proper parameter values for these algorithms, namely self-radius and detector radius in CRNS, number of detectors in both negative selection variants and the self-radius in positive selection.For this parameter tuning and also for obtaining meaningful estimates of the FAR and FRR of the models, the datasets must be divided into training, validation and testing partitions. While training and validation sets are used in parameter tuning and for building the classification model, their test counterpart is used for evaluating the model performance for new and unknown data. Common sampling approaches for generating such data partitions, like cross-validation and leave-one-out, are not suitable to keystroke dynamics as they do not take into account the fact that the user may learn through the time. For example, in the first examples, the user may type in a given way, but the rhythm may slight change as more examples from this user are acquired, mainly due to learning. These sampling procedures ignore this fact, because they can test the classification model using examples captured earlier than those used for model training. In other words, the order in which the data examples are captured is important in this domain and should be considered.In this paper we employ a test model which considers the order of capture, always testing classifiers using examples captured after those used for training. The adopted model is based on that presented in [20] and is composed by two main steps: training and parameter setting and testing (or matching phase). Each of them is detailed in next sections.Since we considered here a one-class classification scenario, only examples from the legitimate user are available during training. As a consequence, training and recognition processes are executed for each user i in the dataset.First, the sequence of examples is divided into windows. Each window defines which examples are used for training and parameter setting and those left for testing. According to [3], classifiers in keystroke dynamics reached low performance when less than 10 examples are used for training, while the required amount of training examples for good performance is around 40. Due to that, we set the size of the windows to 40 here.For parameter setting, each window is further divided, so that the first 30 examples of the window are used for training and the 10 remaining examples are left for validation. Training is performed for several parameter values and the performance achieved when matching the examples in the validation set is recorded. The parameter combination with best validation performance is then chosen. Afterwards, training is performed for the whole sized window (with 40 examples) using the chosen parameter values and the obtained model is evaluated on a test phase, shown in the next section.We defined five windows for each dataset, resulting in five sets of examples for each dataset. Table 2shows the starting point of each window for both datasets. Since there are less examples per user in GREYC, starting points are closer in that dataset. The aim of testing in five different points of the sequence of examples is twofold: firstly, it allows to obtain estimates of the variation of performance of the models for distinct data examples and, secondly, it allows to evaluate the effect that user learning has on the classification performance of the models. We expect that models generated from more recent data will attain better performance, as these models are generated from more fresh data and they are less subject to changes in the typing rhythm of the user.In Fig. 11, we show how the sequence of examples would be divided for user 1. As shown in that figure, examples are divided into three sets: training (which contains positive data only) and validation, which contains both positive (positive recognition) and intruders (negative recognition) data. The presence of negative data in the validation phase is important for a proper parameter setting, as both FAR and FRR must be minimized.Therefore, parameters from all classification algorithms used in this paper are adjusted according to the model illustrated in Fig. 12. As shown in this figure, after obtaining data from a user, features are extracted from raw data (UD), resulting in the examples from the user. Afterwards, training and recognition steps are performed several times in order to test the performance of different parameter values of the classification algorithms in the validation data. The goal is to maximize the average balanced accuracy rate, defined as (sensitivity+specificity)/2. The values adopted for the parameters are presented in A.After defining the models, as discussed in the last section, their test performance is estimated. Now, while all data used for parameter optimization in window j form the training set for window j, the remaining examples are used for matching/recognition, as shown in Fig. 13. Examples in the sequence from the user that were not used in the training phase are regarded as new positive data, while the new examples from the intruders correspond to negative recognition data. It is important to emphasize that examples used for recognition in the testing phase were not previously used for training nor parameter setting. We then record FAR, FRR and balanced accuracy rate values attained by the models for each user i in the datasets.Raw keystroke data has to be rescaled to [0;1] before applying immune negative and positive selection algorithms. When using rank transformation, we have already shown how to scale data within the [0;1] range (Section 4). Nonetheless, when such transformation is not employed, a proper rescale of the data must be performed prior to the use of the immune algorithms.There are a number of techniques to perform rescale in the data mining literature [38]. Some of them are: min–max, z-score and decimal[38]. Min–max normalizes each feature i of a data vectorx→according to Eq. (4)[39]. NewMin are NewMax are the new minimum and maximum values to be adopted, which are 0 and 1 for the immune algorithms used here, respectively. Values min and max are the minimum and maximum values that the feature assumes for all available examples, or when known, the minimum and maximum values that the feature assumes in the problem domain (for all data).(4)xi′=NewMin+xi−minmax–min*(NewMax–NewMin)This normalization is more adequate when the full range of values of each feature is known. However, in a one-class scenario, this is not always the case. As only positive examples (from the legitimate user) are available at training time, it is only possible to obtain values of min and max per user (not globally). In Fig. 14, we show how min and max strongly differ among users. In that figure, we used the first 40 examples (first window of the proposed evaluation model) and only considered the first dimension of the feature vector, without losing generality, as similar variability was observed for other dimensions. We then recorded the minimum and maximum values of the first feature for each user among their 40 typing examples.Fig. 14 shows that there is a large variability in the values of min and max per user. Due to that, the use of normalization factors extracted for a given user to normalize data from another user will tend to produce values outside the range [0;1]. Therefore, this normalization is not recommended for keystroke dynamics in a one-class scenario. A similar problem may occur for z-score [38], which needs to store the standard deviation and mean values per feature, both subject to high variability when considering different users.Another common rescale technique from the literature is known as decimal rescale [38]. It is applied according to Eq. (5) for a feature i, in which j is the highest integer value so that∣xi′∣<1.(5)xi′=xi10jThe value of j may be obtained from Eq. (6), in which y is the highest value that the feature has among all available examples from the user.(6)j=⌈log10(y)⌉Decimal rescale also requires storing the value j per user at the moment of training. However, j does not suffer from such a strong variation per user, as in the case of min and max. Fig. 15shows how this value varies in both datasets for the first feature of the typing vector of GREYC and CMU users. This new figure was built on the same data used for Fig. 14.As this rescale technique transform data in the [−1;1] range, we need to slightly adapt it to use in our context, which works in the [0;1] range. Our approach is to first make all values greater or equal to zero and then applying decimal rescale. In order to do that, Eq. (7) is applied, in whichminuseris the lowest value that all features from the user assume in the whole training dataset.(7)xi′=xi−minuserAs in the case of j, the valueminusermust be also recorded at the moment of training. This factor, however, varies in a smaller range than min and max together, although the variation is larger than that observed for the j value per user, as shown in Fig. 16. This figure was built on the same data from previous graphs from this section. Among the three rescale techniques discussed in this section, we chose decimal rescale to be used in our experiments with standard immune algorithms, which seems less sensitive to high variations of feature values per user. In the experiments, we compare rank transformation to decimal rescale for keystroke dynamics. As rank transformation is performed per example, it is not subject to the problems discussed before. It can also be considered more suitable for a one-class scenario, since it processes each example individually, without needing to know the distribution of other feature vectors.Three immune algorithms were used in the experiments: CRNS, V-Detector and Self-Detector. For all algorithms, we tested the versions using Euclidean distance (“−E”) and the versions using cosine distance (“−C”). Apart from these immune algorithms, we also included two reference one-class algorithms: auto-associative multilayer perceptron (AAMLP) and one-class support vector machine (OCSVM) [40,14]. Table 3shows a summary of all classification algorithms applied in our tests. Note that OCSVM and AAMLP are non-immune algorithms already used in the literature. We performed the tests again with these algorithms in order to compare everything using the same methodology, hence the configuration of the algorithms is different in this paper when compared to the work from other authors. A proper comparison between reported results in studies using different methodologies cannot be directly drawn.All tests were performed in the same computer, using a Intel Core i7 3.40GHz processor. Due to the stochastic nature of some algorithms, all tests were executed 30 times and their results were averaged. Standard deviation values ranges from 0 to 0.015. Statistical tests were applied over the main results [41,42]. Firstly, we present results using rank transformation only [8]. Afterwards, we compare rank transformation to decimal rescale.In order to get a performance overview, we plotted the radar graphs in Fig. 17. These graphs show the balanced accuracy rates from the eight classification algorithms used here in each of the five windows, for both benchmarking datasets. Each axis of the graphs in these figures represents a window, from 1 to 5, where the 5th window is the last window tested in the datasets. The higher the line in the radar, the best is the accuracy performance achieved.Performance rankings among all algorithms remained similar in both datasets. OCSVM was the algorithm with higher ranking variance. Self-Detector-E and Self-Detector-C achieved similar performance and attained very close accuracy rates, what can be noted by the overlapping of the lines representing these two algorithms. Moreover, both Self-Detector versions achieved consistent higher performance than the other algorithms in all windows, for both datasets. Although CRNS-E, CRNS-C and AAMLP had similar performance, they kept the same ranking among them.The worst accuracy rates were observed for V-Detector, for both versions: Euclidean and cosine. This performance drop was notably higher for the GREYC dataset. Additionally, V-Detector reached a FRR above 40% in most of the tests. A possible explanation for this fact is that V-Detector ended up covering a significant part of the positive space with negative detectors. Average detector radius values shown in Table 4support this hypothesis. As shown in this table, V-Detector radius values were higher than those of CRNS in all cases. This may imply in higher coverage of the space using negative detectors, leading to the wrong coverage of part of the positive space. In CRNS, detector radius is constant and defined in the parameter setting phase, while V-Detector has an automatic algorithm to define it. This implied in an increase of the FRR rate, since many positive data can be wrongly rejected as intruders.Still in terms of FRR, we also observed that OCSVM reached the worst FRR values after V-Detector. Due to the low performance of these algorithms when compared to the other ones, we will not include them in further analysis. AAMLP and OCSVM are the reference classifiers to be compared to the immune algorithms. As AAMLP attained better performance than OCSVM, only AAMLP was evaluated in further sections.An important fact to be observed is that, in general, there is a performance improvement for all algorithms for latest windows. This is more prominent in the CMU dataset, where the distances between windows are larger. In GREYC, the average distance between consecutive windows is of 2.5 examples, while in CMU, this average distance is of 87.5 examples. This occurs because, as presented in Section 5.1.1, there are more examples per user in CMU than in GREYC. Such an improvement of performance through the windows indicate that the adaptation of profiles can result in better performance when compared to a static approach.Regarding negative and positive selection, the graphs in Fig. 17 show that positive selection (Self-Detector) obtained better performance than negative selection (CRNS and V-Detector). A possible explanation is that the positive space in keystroke dynamics is smaller than the negative one and, therefore, it would be easier to cover the positive space. A previous work in keystroke dynamics argues that the negative space in keystroke dynamics is infinite and, thus, positive selection is more suitable in this context [32].Also, the overall performance is higher in GREYC dataset when compared to CMU. This may be caused by the fact that the expression analyzed in GREYC is larger than that of CMU, implying in a feature vector containing more features. Usually, as more keys are available, more information can be used to classify the users, what tends to improve accuracy. The expression in GREYC contains 16 keys, while the expression in CMU contains 11 keys. Another explanation for the better performance in GREYC is that the expression in CMU is less common [37]. In other words, the expression is harder to type, what can make the typing rhythms of different examples from a user vary more and also to become closer to that of other users. This also leaves more room for improving (changing) the typing rhythm, what might result in the greater performance improvement for different windows in CMU.In order to better support our findings, we performed a Friedman statistical test [41] with a significance level of α = 0.01. Absolute differences until 0.02 are considered draw for ranking. According to this test, there are significant differences among the classification algorithms in terms of balanced accuracy. Fig. 18shows the groups of algorithms which have significant differences of accuracies according to the Nemenyi post-hoc test. In this figure, the average ranking is the horizontal axis and CD is the critical value of the statistical test. Algorithms without significant difference are grouped by a horizontal line. This test supports that Self-Detector (both versions) attained better performance than other immune algorithms, reaching 87% accuracy for GREYC users and 75% for CMU users in the majority of tests.In this section we show the performance of the classification algorithms in terms of false acceptance and false rejection rates. Figs. 19 and 21show FAR and FRR results, respectively, for all windows in both datasets.As seen in Fig. 19, FAR values have a tendency to decrease for windows ahead, mainly for the CMU dataset. This may be explained by the user learning behavior. In the beginning, all users present greater variance in their typing rhythm, implying in a more tolerant classifier. This can contribute to higher FAR for the first windows, as more variants of the typing rhythm are accepted as legitimate. The classifier is more rigorous for later windows, which contributes to decreases in the false acceptance rate.We also performed a Friedman test [41] and detected significant differences among the classification algorithms in terms of FAR. Using the Nemenyi post-hoc test, the differences are shown in Fig. 20, which illustrates the algorithms that are similar and different from each other. Immune algorithms Self-Detector-E and Self-Detector-C were the best again, although there was no statistical difference to AAMLP according to the post-hoc Nemenyi test.FRR values are shown in Fig. 21. The tendency of reaching better values for windows ahead was also observed for FRR. However, for FFR, this tendency is slightly stronger than in the case of FAR. Another important aspect is that there were more ranking variations between the classification algorithms. This may explain why the Friedman test [41] did not find significant differences in terms of FRR for any algorithm. Even though, CRNS-E showed the best false rejection rates in the majority of tests.In summary, none of the algorithms was able to reach best values in both FAR and FRR. In light of this fact, the algorithm must be chosen according to the application purposes. For greater security, FAR must be reduced. As a consequence, Self-Detector (both versions) would be recommended. Nevertheless, if it is also important to keep a certain level of usability, a balance between FAR and FRR has to pursued. Immune algorithm CRNS-E would be suitable in that case, although no statistical difference was found for FRR.Concerning the overall performance of immune algorithms we can conclude that they are in fact suitable for keystroke dynamics, confirming our statement in previous studies using immune systems [6].This section presents the results in terms of processing time for the algorithms studied in the last section. The results for training and matching times are shown in the boxplots of Figs. 22and 23, respectively, which consider data from all windows.Overall, the tendencies are similar between the two datasets (e.g. ranking among algorithms). Note that Self-Detectors are not shown in Fig. 22. This is because the training time is almost null for these algorithms, which basically copy all training examples and assign them a radius.Regarding the matching time, immune algorithms based on Euclidean distance were faster than those using cosine distance. The greater complexity of the cosine similarity computation may have contributed to this. Another interesting observation is that negative selection algorithms were faster than positive selection algorithms, although the amount of detectors in CRNS was higher than in Self-Detector (50 detectors in CRNS and 40 detectors in Self-Detector). A possible explanation for this behaviour is the imbalance of the datasets [7,8]. For example, in our setup, there are N positive examples against 50*N negative examples for CMU. As a consequence, an algorithm which is slower to classify negative examples has a tendency to be slower in our tests.Self-Detector only classifies an example as negative if all detectors match it. In other words, this algorithm needs to check all detectors to classify an input example as negative. However, CRNS classifies an example as negative if just one detector matches it. Consequently, CRNS does not need to check all detectors to classify an input example as negative. Conversely, Self-Detector has a tendency to be faster for classifying examples as positive, while CRNS would be slower in such cases.After checking processing times, we come to a similar conclusion to that of the FAR/FRR measures: the choice of the classification algorithm will depend on the application scenario. For instance, a scenario where more negative examples are available, negative selection is likely to be faster for recognition. On the other hand, positive selection can be faster for scenarios where most of the attempts are from positive/legitimate users.In order to evaluate whether the use of rank transformation in fact improves classification performance, we compared its use against decimal rescale [8]. According to our analysis in Section 5.2, among three of the most common data rescale methods available in the data mining literature, this can be considered a better rescale method for keystroke dynamics. Tests were performed using all immune approaches plus AAMLP, which attained better performance than OCSVM according to the tests discussed in the last section. Firstly, we studied the performance in terms of accuracy, then we investigated the effect of rank transformation on distance calculations (Euclidean and cosine).In contrast to the last section, now we show the radar plots of balanced accuracy values achieved when decimal rescale is employed (Fig. 24).Some of the tendencies observed in the experiments using rank transformation can also be found here, such as the tendency to improve performance for windows ahead. In addition, the balanced accuracy rate in the GREYC dataset was higher than that achieved in the CMU dataset. However, this accuracy was lower for all algorithms here, but at different levels.The performance drop was stronger for the immune algorithms using the Euclidean distance. For instance, CRNS-E and V-Detector-E reached accuracy below 60% in almost all tests, which is a low performance. A possible explanation for this performance decrease is the fact that decimal rescale left data more sparse, making Euclidean distance more subject to the effects of the curse of dimensionality[43]. Consequently, the differentiation of users just by the magnitude of their feature vectors became less significant. Euclidean distance basically does a simple comparison of vectors by their magnitude, explaining why immune algorithms based on this distance may have attained low performance. Self-Detector demonstrates this effect. Both versions of this algorithm had similar performance using rank transformation, but when decimal rescale is applied, the performance of the Euclidean version strongly decreased.Conversely, immune algorithms based on cosine distance maintained their performance consistently higher than those using Euclidean distance. For example, in the majority of the tests, Self-Detector-C attained accuracy values above 80% in GREYC and above 70% in CMU. For CRNS-C, accuracy was lower, but still above 75% in GREYC and above 65% in CMU in the majority of the tests. A possible explanation for this performance difference lies in the nature of each distance measure. Cosine distance considers the correlation between vectors and not just the magnitude of their differences. As a consequence, cosine distance is, to a certain extent, able to compare typing signatures even without the use of rank transformation. This finding emphasizes once again that the typing signature is a key aspect to be considered in keystroke dynamics.As immune systems based on Euclidean distance do not consider the typing signature, their performance dropped. When rank transformation was used, typing signature was emphasized, also reducing data sparsity. This may explain why immune algorithms using Euclidean distance achieved performance close to that of cosine distance when rank transformation was applied.Our previous work using global min–max normalization in keystroke dynamics verified similar effects: low performance for Euclidean distance and significant improvement when cosine distance is used [6]. This shows that rescale techniques commonly used in data mining literature, such as decimal rescale or min–max normalization, may decisively impair performance of Euclidean distance in keystroke dynamics. Next section explores further how distance measures are affected by data rescale.For demonstrating the impact of data pre-processing on the distance calculations, we plotted the graphs in Figs. 25and 26[8], for Euclidean and cosine distances, respectively. These graphs show how distance values vary between positive examples, shown in green (positive distances) and negative examples, shown in gray (negative distances). The plots correspond to frequencies of the distance values between positive examples and between negative data examples. Since each dataset has several users, those distances were calculated for each user regarding its examples as positive and those of the remaining users are considered negative. This leads to much more negative distances than positive distances. For this reason, positive frequencies were multiplied by the number of users in each dataset for better visualization. The vertical line represents the median of the distribution. All distances were calculated over the first 10 examples from all users in GREYC and CMU datasets.As shown in Fig. 25, rank transformation distributed the distances in an approximately normal way and also increased the separation between positive and negative distances. In these graphs we also observed that the overlapping of the two distributions (positive and negative) reduces when rank transformation is used. This was clearer in GREYC dataset. The results seen in these graphs may also explain why rank transformation improved classification performance of the immune algorithms based on Euclidean distance.The same investigation was performed for cosine distance in Fig. 26. However, as shown in these graphs, the distribution of distances was already approximately normal for decimal rescale. Besides, the overlapping of both distributions was similar for decimal rescale and rank transformation. This may explain the fact that rank transformation did not have an impact in immune algorithms based on cosine distance as huge as seen for their counterparts based on Euclidean distance.

@&#CONCLUSIONS@&#
