@&#MAIN-TITLE@&#
Utility-preserving privacy protection of textual healthcare documents

@&#HIGHLIGHTS@&#
An automatic method to protect individual’s privacy in plain text medical documents is presented.It considers semantically related terms that may disclose the information to protect.Special care has been put to preserve the analytical utility and readability of the protected output.Evaluations are performed over highly sensitive documents and in coherence with legislations on medical data privacy.Results show a noticeable improvement against related works with respect to privacy and utility.

@&#KEYPHRASES@&#
Privacy-protection,Document redaction,Data sanitisation,Healthcare data,Semantics,Information theory,

@&#ABSTRACT@&#
The adoption of ITs by medical organisations makes possible the compilation of large amounts of healthcare data, which are quite often needed to be released to third parties for research or business purposes. Many of this data are of sensitive nature, because they may include patient-related documents such as electronic healthcare records. In order to protect the privacy of individuals, several legislations on healthcare data management, which state the kind of information that should be protected, have been defined. Traditionally, to meet with current legislations, a manual redaction process is applied to patient-related documents in order to remove or black-out sensitive terms. This process is costly and time-consuming and has the undesired side effect of severely reducing the utility of the released content. Automatic methods available in the literature usually propose ad-hoc solutions that are limited to protect specific types of structured information (e.g. e-mail addresses, social security numbers, etc.); as a result, they are hardly applicable to the sensitive entities stated in current regulations that do not present those structural regularities (e.g. diseases, symptoms, treatments, etc.). To tackle these limitations, in this paper we propose an automatic sanitisation method for textual medical documents (e.g. electronic healthcare records) that is able to protect, regardless of their structure, sensitive entities (e.g. diseases) and also those semantically related terms (e.g. symptoms) that may disclose the former ones. Contrary to redaction schemes based on term removal, our approach improves the utility of the protected output by replacing sensitive terms with appropriate generalisations retrieved from several medical and general-purpose knowledge bases. Experiments conducted on highly sensitive documents and in coherency with current regulations on healthcare data privacy show promising results in terms of the practical privacy and utility of the protected output.

@&#INTRODUCTION@&#
New technologies have played a crucial role on improving healthcare delivery. Data digitalisation, in particular, has paved the way for the extensive adoption of Electronic Health Records (EHR) systems that have enabled clinicians and researchers to access, manage and exploit large amounts of valuable patient data easily [23]. Nevertheless, as data becomes more accessible and easily copied and transferred, the confidentiality of the patients is more likely to be jeopardised.Redaction is a privacy-preserving method that aims to avoid (or at least mitigate) the disclosure of raw confidential data, such as textual documents (in contrast with specific privacy protection methods focusing only on relational databases [12,22]). Redaction is based on blacking-out, obscuring or eliminating sensitive terms in the documents prior to their release. Selecting which elements of the document have to be redacted is crucial, because a weak redaction process may disclose sensitive data. On the other hand, a too restrictive redaction may destroy the utility of the document, a situation that goes against the purpose of data releasing.Official regulations have been developed at this respect within the medical context. For example, the Health Insurance Portability and Accountability Act (HIPAA) [11], states safe harbour rules about the kind of personally identifiable information which should be removed in medical documents prior allowing their publication. More specifically, the HIPAA requires 18 data elements (called PHI: Protected Health Information) to be removed from a redacted document. The goal of such regulation is to maintain individual’s anonymity while preserving healthcare outcomes, which are useful for medical research, intact.In other scenarios, such as when medical records are released to insurance companies or legal counsel [34] to be used as a support for legal claims (e.g. workers’ compensation claims and motor vehicle accident claims), privacy protection regulations are focused towards ensuring the confidentiality of individual’s data. In those cases, documents have to be still linked to a patient but any information that may impair her dignity and/or be the cause of discrimination must be removed. Regarding this last point, many US state and federal laws stipulate that elements such as HIV status, drug or alcohol abuse and mental health conditions must be redacted before releasing medical records to third parties [10,20,37].The main side effect of document redaction is that it significantly reduces the utility of the protected content [8]. Another important drawback is that the existence of obscured or blacked-out parts can raise the awareness of the document’s sensitivity in front of potential attackers [4]. This is especially problematic in documents linked to a specific knowledge area such as healthcare, because the number of different textual elements that usually appear on the documents is relatively limited. Therefore, leaving blacked-out parts increases the probabilities for an attacker to determine the redacted terms by means of some characteristics such as their context and their length [21]. A more suitable alternative to document redaction consists on generalising sensitive content instead of removing it, a measure that preserves more content utility [8]. This is usually referred to as document sanitisation[4]. As a result of content generalisation a less detailed but still useful document is obtained, while no explicit clues about the document’s sensitivity are given.In any case, document redaction/sanitisation is significantly hindered by the need to deal with textual data and because of the existence of semantic relationships between the textual terms in the document. The fact that many sensitive terms lack a regular structure (e.g. disease names, in contrast to e-mail addresses or social security numbers) limits the effectiveness of automatic methods based on pattern matching or trained classifiers [23]. Semantic relationships, on the other hand, may enable the re-identification of redacted/sanitised elements from the presence of related terms left in clear form. For example, let us consider the following text in which the sensitive term AIDS has been redacted (i.e. replaced by XXX).“The patient suffers from XXX that was transmitted because of an unprotected sexual intercourse. He was diagnosed when his immune system responded poorly to influenza.”Even though the terms left in clear form “unprotected sexual intercourse”, “immune system” or “influenza” may seem apparently innocuous, an external observer with a certain knowledge on the domain [7] may effectively re-identify the redacted term AIDS by semantic inference; for example, by simply querying the three terms in a Web search engine, most of the resulting web pages are related to AIDS/HIV.Providing privacy protection against an external observer who exploits semantic inferences to re-identify redacted/sanitised elements is a quite challenging task. According to [34], with the help of a Web search engine, an external observer can easily infer facts, reconstruct events and piece together identities from fragments of information collected from different sources. This situation is assumed to be even worse when dealing with medical records, whose tight focus would result quite commonly in the presence of strong relationships between the different elements (diseases, symptoms, treatments, medication, etc.).Due to the above problems, redaction/sanitisation of medical documents is usually performed in a manual way by a human expert (or a team of human experts), who follows regulations and redaction guidelines detailing the correct procedures to sanitise sensitive entities [24]. This task has proven to be burdensome, very time-consuming [16] and prone to disclosure risks [6]. For example, the authors in [4] interviewed the medical records manager for a 10,000+ patient healthcare provider in California, who stated that the act of redacting records takes approximately 20% of her time while the remaining 80% is consumed by the more difficult task of deciding what to redact. In order to deal with textual terms and their potential semantic relationships, this expert maintains lists of names of medications, treatments, etc., which are related to sensitive diseases to be protected, such as HIV.Given the burden of manual document redaction/sanitisation, the development of automatic schemes capable of dealing with textual healthcare data and avoiding the disclosure caused by semantic inference while retaining the utility of the output document, is a clear need for medical organisations. Unfortunately, as it will be discussed in Section 2, methods available in the literature are limited and they only partially cover some of those features.In this paper, we describe an automatic scheme designed to sanitise textual medical documents (e.g. electronic healthcare records) without assuming any kind of structural regularity in the entities to protect. Moreover, it puts special emphasis in the detection and sanitisation of terms that are semantically related to sensitive entities, in order to avoid disclosure via semantic inference. The present work offers the following contributions:•It applies an information theoretic notion of term sensitivity [30] to develop a sanitisation method for textual medical data, which is well-suited to fulfil with the privacy requirements stated by the current legislations on healthcare data protection.It applies and extends the notion of disclosure risk introduced in [31,32] to detect risky semantically related terms. Moreover, it exploits several general-purpose (WordNet [14] and ODP1http://www.dmoz.org (last accessed: November, 2013).1) and healthcare (SNOMED-CT [33]) knowledge bases to preserve data utility.It proposes a more accurate way of computing term disclosure risk using the Web as corpora and a knowledge base to minimise semantic ambiguity.The proposed scheme is evaluated and compared against related works using documents describing highly sensitive medical concepts and realistic use cases based on existing regulations on medical data privacy.The rest of the paper is organised as follows. Section 2 reviews related works in document redaction/sanitisation. Section 3 presents our proposal. Section 4 details the evaluation metrics and compares the results obtained for a collection of highly sensitive documents against previous works. The final section provides the conclusions.

@&#CONCLUSIONS@&#
This paper presents an automatic method to sanitise textual medical data. Several aspects differentiate it from related works. First, several knowledge bases are exploited to retain, as much as possible, the semantics and, thus, the analytical utility and readability of the protected output. Second, on the contrary to methods focusing on specific types of sensitive entities (like e-mail addresses or social security numbers) [2,3,13,15,17–19,25,35,36,40,41], our approach does not make any assumptions on the structure of the terms to protect. As a result, it in can be applied to textual contents regardless the fact that terms (e.g. diseases, symptoms, treatment, etc.) present or not a regular structure. Finally, it carefully considers the disclosure risk caused by the presence of semantically related terms, which is especially critical in the medical context in which most terms appearing in a document are likely to be semantically related up to some degree.To achieve those goals, the proposed method builds on an information theoretic characterisation of term sensitiveness and disclosure risk [30–32] and an accurate calculus of term probabilities from the Web. The fact that the privacy criterion can be defined by simply listing the set of entities that should be considered as sensitive makes our approach intuitive (from the perspective of the privacy guarantees that one may expect from the protected output), and especially suitable to be applied in coherency with legislations on medical data privacy, which are specified in the same manner.The evaluation showed that: (i) the analysis of semantically related terms, (ii) the contextualisation of probability queries and (iii) the replacement (instead of removal) of sensitive terms by appropriate generalisations improved the detection recall of sensitive information (i.e. the practical privacy of the output) while contributing to preserve the output’s utility.As future work, we plan to improve and extend the linguistic analysis of texts by incorporating other terms that may cause disclosure (e.g. verbs in sentences like “he drinks too much”). Ontologies modelling verbs such as WordNet could be used to assist the sanitisation process. A deeper linguistic analysis may also contribute to improve the accuracy by detecting negated assertions (e.g. “AIDS negative”) and thus avoiding unnecessary sanitisations. Further tests will be also performed with sources written in different languages in order to illustrate the applicability of our method given the availability of linguistic parsing tools for such languages. Finally, experiments with real medical data, which is the focus of our system, are also planned.