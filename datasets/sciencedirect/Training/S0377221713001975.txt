@&#MAIN-TITLE@&#
An exact algorithm for the precedence-constrained single-machine scheduling problem

@&#HIGHLIGHTS@&#
The precedence-constrained single-machine scheduling problem is considered.An efficient exact algorithm is proposed based on our previous studies.The SSDP (Successive Sublimation Dynamic Programming) method is employed.Instances of the total weighted tardiness problem with up to 100 jobs are solved.

@&#KEYPHRASES@&#
Scheduling,Single-machine,Precedence constraints,Exact algorithm,Lagrangian relaxation,Dynamic programming,

@&#ABSTRACT@&#
This study proposes an efficient exact algorithm for the precedence-constrained single-machine scheduling problem to minimize total job completion cost where machine idle time is forbidden. The proposed algorithm is based on the SSDP (Successive Sublimation Dynamic Programming) method and is an extension of the authors’ previous algorithms for the problem without precedence constraints. In this method, a lower bound is computed by solving a Lagrangian relaxation of the original problem via dynamic programming and then it is improved successively by adding constraints to the relaxation until the gap between the lower and upper bounds vanishes. Numerical experiments will show that the algorithm can solve all instances with up to 50 jobs of the precedence-constrained total weighted tardiness and total weighted earliness–tardiness problems, and most instances with 100 jobs of the former problem.

@&#INTRODUCTION@&#
In this study we consider the single-machine scheduling problem to minimize total job completion cost subject to general precedence constraints1|prec|∑fj(t). It is often the case in practice that some job should be processed before another job due to limitation of machine functions, tool change restrictions and so on. This type of constraint is called precedence constraint.The precedence-constrained single-machine problem to minimize total weighted completion time1|prec|∑wjCjis well studied in the literature [1–13] and instances with up to 100 jobs were optimally solved even more than 20years ago [3], although it is known to be strongly NP-hard [2]. In contrast, the precedence-constrained single-machine scheduling problem to minimize more general additive costs has not been studied extensively so far. In [14,15], labeling procedures necessary for implementing dynamic programming to solve1|prec|∑fj(t)were proposed. In the numerical experiment of [15], instances of the precedence-constrained single-machine total unweighted tardiness problem1|prec|∑Tiand total weighted tardiness1|prec|∑wiTiproblem were solved by the dynamic programming algorithm. However, these instances were of the ordinary problems without precedence constraints, and job dominance properties in [16] were used as the precedence constraints. In other words, the purpose of the numerical experiment was to demonstrate the effectiveness of the dominance properties for improving the dynamic programming algorithm to solve the ordinary total tardiness problem without precedence constraints. It is true that they are applicable to the problem with precedence constraints that do not originate in dominance properties, but it cannot be expected that they work well especially when precedence constraints are not so restrictive and the number of feasible solutions (job sequences) is still very large. As is a well-known fact, strong dominance properties hold for1∑Tiand the problem is even decomposable into subproblems [17]. On the other hand, only weak dominance properties have been proved for1∑wiTi. The numerical experiment in [15] seems to reflect this fact: Instances with 50 jobs were solved for1∑Ti, but only those with 20 jobs were for1∑wiTi. The more recent study [18] follows this line of research. In [18], Tang et al. proposed a method to treat precedence constraints in a Lagrangian relaxation-based lower bound of the single-machine total weighted tardiness problem. Then, the effect of taking into account the precedence constraints derived from the dominance properties was examined by a numerical experiment.This paper is on an exact algorithm for the precedence-constrained single-machine scheduling problem to minimize general additive costs. The precedence constraints considered in this paper are not those derived from the dominance properties that appear in [15,18], but more general ones as in [3]. To the best of the authors’ knowledge, there has been no study on exact algorithms that consider such general precedence constraints directly for objective functions other than total weighted completion time, although the DP in [15] is applicable as already explained. For the single-machine problem without precedence constraints to minimize general additive objective functions, the first author and his colleagues have already proposed efficient exact algorithms that can solve instances with up to 300 jobs when machine idle time is forbidden [19] and with up to 200 jobs when it is permitted [20]. These results indicate that our algorithms outperform the other exact algorithms proposed so far for these classes of problems without precedence constraints. Therefore, it is expected that our framework is also effective for the precedence-constrained problem. Hence this study will extend these algorithms to the precedence-constrained problem, but only the case when machine idle time is forbidden is considered. Numerical experiments will show that the proposed algorithm can solve all 50 jobs instances of the precedence-constrained total weighted tardiness problem1|prec|∑wiTiand of the precedence-constrained total weighted earliness–tardiness problem without idle times1|prec,noidle|∑(αiEi+βiTi), and most of 100 jobs instances of1|prec∑wiTi.The remainder of this paper is organized as follows. First, in Section 2, the problem considered in this study is formulated as a constrained shortest path problem. Next, in Section 3, our previous algorithms in [19,20] are reviewed and how to extend them to the problem with precedence constraints are shortly stated. Then, in Section 4, Lagrangian relaxations necessary for constructing the proposed algorithm are given and then how to solve them by dynamic programming is explained. In Section 5, the proposed algorithm is summarized. Section 6 shows some numerical results, and finally, Section 7 concludes this study.In this section the precedence-constrained single-machine scheduling problem treated in this study is described formally and it is formulated as a constrained shortest path problem.Suppose that n jobs (job 1,job 2,…,job n) are to be processed on a single machine that can process at most one job at a time. An integer processing time pi>0 is given for each jobi∈N={1,2,…,n}. An integer cost function fi(t) (t⩾pi) is also given for each job i and the cost fi(Ci) is incurred when job i is completed at Ci. On some pairs of jobs i andj(i,j∈N,i≠j), the precedence constraint that job i should precede job j (i→j) is imposed. All the precedence constraints are specified by an acyclic directed graphG¯P=(VP,A¯P)with VP={1,2,…,n} such that i→j when(i,j)∈A¯P.A¯Pis assumed to be transitively closed: if(i,k),(k,j)∈A¯P, then(i,j)∈A¯P. The minimal expression of the precedence constraints is given by GP=(VP, AP), whereAP⊆A¯Pis the transitive reduction ofA¯P. Preemption and machine idle time are forbidden and hence all the jobs should be processed in the interval [0, T] whereT=∑i∈Npi. The objective is to find a job sequence that satisfies the precedence constraints and that minimizes total job completion cost∑i∈Nfi(Ci).We treat this problem as a constrained shortest path problem on an acyclic weighted directed graph G=(V, A, W). Let us introduce a dummy job n+1 with pn+1=1, fn+1(t)≡0 that should be completed twice at time 0 and T+1 to denote the source node vn+1,0 and the sink node vn+1,T+1.1In [19], another dummy job 0 is introduced and the source node is denoted by v00. However, only one dummy node is introduced here according to the newer notation in [20]. In [20], job 0 denotes a unit idle time.1Next, define a node set V by(1)V={vn+1,0}∪VO∪{vn+1,T+1},(2)VO=vit|i∈N,pi+∑(j,i)∈A¯Ppj⩽t⩽T-∑(i,j)∈A¯Ppj.An arc set A is defined by(3)A={(vi,t-pj,vjt)|vi,t-pj,vjt∈V},where the weight (length) W(e) of an arce=(vi,t-pj,vjt)∈Ais given by fj(t). Then, our problem is equivalent to find a shortest path from the source node vn+1,0 to the sink node vn+1,T+1 such that vitis visited exactly once for anyi∈Nand that visand vjtin the path satisfy s⩽t−pjif (i, j)∈AP. The optimal objective value is identical to the shortest path length, and vitvisited in the shortest path corresponds to the completion of job i at t in an optimal solution. Fig. 1shows an example of G for an instance with n=5. The processing times are given by p1=1, p2=2, p3=2, p4=3, p5=1 and a precedence constraint is on jobs 1 and 2 so that 1→2.Hereafter, we use the following notations and definitions. A set of nodes visited in a path from vn+1,0 to vn+1,T+1 is denoted byP, and the path corresponding toPis referred to as “pathP” for simplicity. LetL(P)be the length of a pathP. Namely,L(P)is defined by(4)L(P)=∑vit∈Pi∈Nfi(t).For each job i, the number of occurrences of vitinPis denoted byVi(P), which is defined by(5)Vi(P)=|{vit|vit∈P}|.Then, the constraints that a pathPshould visitvit(i∈N)exactly once can be written by(6)Vi(P)=1,i∈N.In addition, the precedence constraints can be expressed by(7)s⩽t-pj,(i,j)∈AP,vis,vjt∈P,or, equivalently,(8)∑vis∈Ps⩽∑vjt∈Pt-pj,(i,j)∈AP.We denote the set of all the feasible paths satisfying these constraints byQ. Then, our problem (P) can be formulated as follows.(9)(P):minPL(P)s.t.P∈Q.The proposed algorithm is based on the SSDP (Successive Sublimation Dynamic Programming) method [21,22] as our previous algorithms [19,20]. This algorithm is similar to the cutting plane algorithm: It first computes a lower bound by a simple relaxation of the original problem and then improves it successively by adding constraints (cuts) to the relaxation until the gap between the lower and upper bounds vanishes. Since all the relaxations are solved by dynamic programming, it is inevitable that the number of dynamic programming states increases as the number of added constraints increases. To cope with it, unnecessary states are eliminated in the course of the algorithm, which is the key point of the SSDP method. In our previous studies [19,20], several improvements for the original algorithm in [22] were proposed not only to reduce unnecessary states, but also to improve the efficiency of the algorithm. These improvements made the algorithm outperform the existing algorithms and instances even with 300 jobs could be solved optimally. This section gives a brief sketch of our previous algorithms. Then, how to extend it to our problem and where its difficulty lies will be explained shortly.The following Lagrangian relaxations are employed in [19,20]. First, the constraints on the number of job occurrences (6) are relaxed by penalizing their violations. Next, the constraints on successive jobs [24] are added to the relaxation. These constraints forbid such a sub-path in the network representation that nodes representing the same job are visited twice or more. Therefore, they correspond to the cycle elimination constraints that often appear in routing problems (e.g. [23]). Then, the constraints based on the dominance of adjacent pairs of jobs [25,19] are added. These constraints forbid such a processing order of two adjacent jobs that interchanging their order can improve the solution. Finally, the relaxed constraints (6) are gradually recovered until the gap between the lower and upper bounds vanishes. An upper bound is computed in the course of the algorithms by first converting a solution of a relaxation to a feasible solution of the original problem and then by applying the dynasearch [29,30].All these relaxations are solvable by dynamic programming algorithms. However, the number of the dynamic programming states, which corresponds to the size of the underlying network, increases exponentially as the constraints (6) are recovered. Therefore, unnecessary dynamic programming states are eliminated in the course of the SSDP method. In the original algorithm [22], a lower bound to pass through each state is computed by applying dynamic programming in both forward and backward directions, and the state is eliminated when the lower bound is not smaller than the current upper bound. This corresponds to the elimination of a node or an arc in the network representation. In addition to this, the network reduction based on the dominance of more than two successive jobs, the constraint propagation technique, and the compressed network representation were introduced in [20] to reduce the network more.In this paper, we will extend the algorithm in [19] improved by integrating the techniques in [20] to the problem with precedence constraints. Roughly speaking, the following are necessary for this purpose:(a)Relaxations for the problem with precedence constraints that are efficiently solvable by dynamic programming.Extension of the network reduction techniques.Extension of the upper bound computation method.In the next section, we will give the relaxations in the proposed algorithm and show how to solve them by dynamic programming. Then, in Section 5, the proposed algorithm will be summarized together with (c).This section gives the relaxations used in the proposed algorithm. The primary difference from those in the previous algorithms [19,20] is, as already explained in the preceding section, that the violation of all or part of the precedence constraints is penalized by the Lagrangian relaxation technique. However, it does not follow that the original dynamic programming algorithm is applicable to the relaxations considered here. In the following, the dynamic programming algorithm to solve the relaxations will be stated.Let us penalize the constraints on the number of occurrences (6) byμiO(i∈N)and the precedence constraints of the form (8) byμijP⩾0((i,j)∈AP). Then, we obtain the following relaxation (LR0):(10)(LR0):minPL(P)+∑i∈NμiO(1-Vi(P))+∑(i,j)∈APμijP∑vis∈Ps-∑vjt∈Pt+pj.By introducingωi(i∈N)defined by(11)ωi=∑(j,i)∈APμjiP-∑(i,j)∈APμijP.Eq. (10) can be rewritten as(12)(LR0):minPLR(P;μO,μP)+∑i∈NμiO+∑(i,j)∈APμijPpj,whereLR(P;μO,μP)is defined by(13)LR(P;μO,μP)=L(P)-∑i∈NμiOVi(P)+∑(i,j)∈APμijP∑vis∈Ps-∑vjt∈Pt=∑vit∈Pi∈Nfi(t)-∑vit∈Pi∈NμiO-∑vit∈Pi∈Nωit=∑vit∈Pi∈Nfi(t)-μiO-ωit.From (13), we can see that (LR0) for a set of multipliersμO andμP is equivalent to the unconstrained shortest path problem on G=(V, A, W′), where W′(e) is defined by(14)W′((vi,t-pj,vjt))=fj′(t)=fj(t)-μjO-ωjt.The relaxation (LR0) is the same as that of the problem without precedence constraints except the weights of the arcs, and hence can be solved by dynamic programming in O(nT) time (see [24]).To improve the lower bound obtained by (LR0), the following constraints are imposed on (LR0) as in the previous algorithms [22,19,20]:(15)Foranyi∈N,nodesrepresentingjobi,i.e.,vitshouldnotbevisitedmorethanonceinanyλ+1>0successivenodesinapath.These constraints forbid such a sub-path thatvi,t-pi→vitwhen λ=1 andvi,t-pi-pj→vj,t-pi→vitadditionally when λ=2. A set of paths satisfying these constraints on successive nodes is denoted byQλ, and the relaxation with the constraints is denoted by (LRλ). Here, we only consider (LR1) and (LR2) as in [19,20]. By defining(16)AS=A⧹{(vi,t-pi,vit)|vi,t-pi,vit∈VO},we introduce a reduced network GS=(V, AS, W′). Then, (LR1) becomes equivalent to the unconstrained shortest path problem on GS. On the other hand, (LR2) remains the constrained shortest path problem even on GS. Since the precedence constraints are relaxed, the time complexities of (LR1) and (LR2) by dynamic programming do not differ from those in [19] and are given by O(nT) and O(n2T), respectively. It is worth noting that the time complexity of (LR2) is the same as the number of arcs ∣AS∣ in GS because each arc is evaluated once in the dynamic programming algorithm. For the detailed recursive equations, please refer to [19].Fig. 2shows GS derived from G in Fig. 1. In GS, the arcs(vi,t-pi,vit)are eliminated for all i and t from G.The second constraints are derived from the dominance theorem of dynamic programming [26] for adjacent pairs of jobs [25,19,20]. For the problem without precedence constraints, they restrict processing orders of adjacent pairs of jobs by checking their total costs. Here, we should slightly modify them to ensure the consistency with the precedence constraints.Suppose that two jobs i andj(i,j∈N,i≠j)are processed adjacently. If(i,j)∈A¯Pand (i, j)∉AP (or,(j,i)∈A¯Pand (j, i)∉AP), this situation cannot happen because there should exist another job k satisfying(i,k),(k,j)∈A¯P(or,(j,k),(k,i)∈A¯P). In this case, we forbid the two jobs i and j to be processed adjacently. On the other hand, if (i, j)∈AP or (j, i)∈AP, the two jobs can be processed adjacently, but their processing order is restricted by the precedence constraint. If no precedence constraint exists between the jobs i and j, i.e.,(i,j),(j,i)∉A¯P, we compare the total completion costs of the two jobs when they are completed at t: fi(t−pj)+fj(t) when job i precedes job j, and fj(t−pi)+fi(t) when job j precedes job i. Then, the processing order that yields the larger cost is forbidden. If the two costs are identical, either (but not arbitrary) processing order can be forbidden without loss of optimality. To summarize, the processing orders of any adjacent pairs of jobs can be restricted and these restrictions are imposed on (LR2) as constraints. This yields a new relaxation(LR^2).In the network representation, these adjacency constraints eliminate from GS, those edges corresponding to the forbidden processing orders. Thus, we defineG^S=(V,A^S,W′)by(17)A^S=AS⧹{(vi,t-pj,vjt)|jobjcannotbeprecededadjacentlybyjobiatt}.Then,(LR^2)becomes equivalent to the shortest path problem onG^Sunder the constraints (15) on three successive nodes (for λ=2). The time complexity of(LR^2)does not increase from (LR2) and it can be solved in O(n2T) time becauseG^S⊂GS(and|A^S|is O(n2T)). Fig. 3shows an example ofG^Sderived from GS in Fig. 2 under some dominance properties on adjacent pairs of jobs. For example, we assume that the processing order 3→1 is better than 1→3 if they are completed before t=6 and the converse is true when they are completed after t=7. Hence (v1,t−2, v3t) are eliminated for t⩽6 and (v3,t−1, v1t) are eliminated for t⩾7. In addition, (v2,t−1, v1t) are eliminated for all t due to the precedence constraint 1→2.In our previous algorithms without precedence constraints [19,20], the relaxed constraints (6) are gradually recovered to(LR^2). More specifically, for someM={ϕ1,…,ϕm}⊆N,(18)Vϕk(P)=1,1⩽k⩽m,are imposed on the relaxation corresponding to(LR^2). It is easy to see that the relaxation approaches the original problem asm=|M|increases and it becomes equivalent when m=n. Hence, the lower bound obtained by solving the relaxation improves as the relaxed constraints are recovered, and the gap between the lower and upper bounds vanishes in a finite number of iterations. To solve the relaxation in each iteration, it takes O(n22mT) time [19].In this study some of the precedence constraints (7), i.e.,(19)s⩽t-pi,(ϕk,i)∈AP,vϕks,vit∈P,1⩽k⩽m,(20)s⩽t-pϕk,(i,ϕk)∈AP,vis,vϕkt∈P,1⩽k⩽m,are recovered at the same time. In addition,μijPis set to zero ifi,j∈M. Clearly, the relaxation generated in this manner, which is referred to asLR^2m, becomes equivalent to (P) whenM=N. Therefore, an optimal solution of (P) is obtainable in a finite number of iterations by solvingLR^2mwith m increased until the gap between the lower and upper bounds vanishes (in practice, the algorithm can be terminated the gap becomes less than one because the optimal objective value of the original problem (P) is integral). Our claim here is thatLR^2mis solvable in O(n22mT) time and hence the time complexity does not increase even under the existence of the precedence constraints (19) and (20). In the following, it will be shown step by step.First, assume that only the constraints (18) are imposed on(LR^2)and denote the resulting relaxation byLR∼2m. To solve it, define an m-dimensional vectorqim(i∈N)byqim=(qi1,…,qim), where(21)qik=1i=ϕk,0otherwise.Let us also define an m-dimensional vectorqn+1mbyqn+1m=(0,…,0). Next, we introduce a weighted directed graphGSm=(Vm,ASm,W′). The node set Vmis defined by(22)Vm={vn+1,00m}∪VOm∪{vn+1,T+11m},(23)VOm=vitb|vit∈VO,qim⩽b⩽1m,where 0mand 1mdenote m-dimensional vectors whose elements are all zero and all one, respectively. The arc setASmis defined by(24)ASm=(vi,t-pjb-qjm,vjtb)(vi,t-pj,vjt)∈A^S,qim+qjm⩽b⩽1m.Then, the shortest path problem onGSmunder the constraints (15) for λ=2 is equivalent toLR∼2m. To solve it by (forward) dynamic programming, the constrained shortest path from the source nodevn+1,00mtovjtbthroughvi,t-pjb-qjm,vjtbis recursively computed. Since, in this shortest path, the number of occurrences of the nodes representing job ϕk(1⩽k⩽m) is equal to the k-th element ofb, it is ensured thatvϕktbappears exactly once for all k (1⩽k⩽m) in the obtained shortest path fromvn+1,00mtovn+1,T+11m. The time complexity is given by O(n22mT) because ∣Am∣ is O(n22mT) (∣Vm∣ is O(n2mT) and the in-degree of each node is at most n).Fig. 4givesGSmderived fromG^Sin Fig. 3 forM={1}and m=1. It can be verified from the structure of the network that any path cannot reach the sink nodev6,101without passing throughv1t1exactly once for some t. However, the path shown in thick arrows,v6,00→v5,10→v2,30→v3,50→v1,61→v4,91→v6,101, does not satisfy the precedence constraint because it passes throughv2,30beforev1,61.Next, considerLR^2m, i.e.,LR∼2mwith the precedence constraints (19) and (20). As we have already seen, the number of occurrences of the nodes representing job ϕkin the path fromvn+1,00mtovjtbis equal to bk. It implies that this path breaks the precedence constraint (19) if (ϕk, j)∈AP and bk=0. Similarly, it breaks the constraint (20) if (j, ϕk)∈AP and bk=1. Therefore, we can satisfy the precedence constraints (19) and (20), only by removing fromGSmall the nodesvjtbwith suchb. Clearly, the time complexity of the constrained shortest path problem onGSmdoes not change even when some nodes are removed. Hence, we can conclude thatLR^2mis solvable in O(n22mT) time.Notice thatGSmwithϕk∈Monly forbids ϕk→i under the precedence constraint i→ϕk(or i→ϕkunder ϕk→i). Since it is possible that a node representing job i does not appear in a feasible path fromvn+1,00mtovn+1,T+11mifi∉M, we cannot say that i→ϕk(or ϕk→i) is satisfied in this case. However, i→j for any (i, j)∈AP is satisfied whenM=Nbecause the constraints (6) are all recovered and hence all the jobs should appear exactly once in any feasible path.We can apply the above arguments not only to the minimal precedence constraints (i→j for (i, j)∈AP), but also to the transitive closure (i→j for(i,j)∈A¯P), which improves the lower bound and reduces the network more. To summarize, we are to solve the shortest path problem on a directed graphG^Sm=V^m,A^Sm,W′under the constraints (15) for λ=2, where(25)V^m=Vm⧹vitb|∃k,(ϕk,i)∈A¯P,bk=0∪vitb|∃k,(i,ϕk)∈A¯P,bk=1,(26)A^Sm=vi,t-pjb-qjm,vjtb|vi,t-pjb-qjm,vjtb∈ASm,vi,t-pjb-qjm,vjtb∈V^m.Fig. 5showsG^Smderived fromGSmin Fig. 4, wherev2t0are eliminated for all t. It is obvious that this network ensures thatv2•0is never visited before jobv1•1. The path shown in thick arrows,v6,00→v3,20→v1,31→v5,41→v4,71→v3,91→v6,101, is still feasible inG^Sm, wherev2t1is not visited for any t. However, it is eliminated or at least becomes infeasible when job 2 is added toM.Since the precedence constraints (7) are inequality constraints, the lower bound can be improved by converting them to equality constraints with slack variables and then solving optimization problems with regard to the slack variables [4]. We apply this method to all the relaxations(LR1),(LR^2)andLR^2m.Our proposed algorithm utilizes the Lagrangian relaxations(LR1),(LR^2)andLR^2min the preceding section. The algorithm is composed of three stages: (LR1) is solved first,(LR^2)is solved next, and thenLR^2mis solved withM(m=|M|)increased. These correspond to the main loop of the SSDP method that generates and solves better relaxations by adding constraints. Since the size of the networkGSmcorresponding toLR^2mincreases exponentially as the algorithm proceeds and constraints are recovered, it is crucial to suppress the increase of the network size as much as possible.The algorithm is summarized as follows.Stage 1: An initial upper bound UB is computed. Then, the conjugate subgradient algorithm [27,28] is applied to the Lagrangian dual corresponding to (LR1). The algorithm is terminated without entering the next stage if the gap between the best lower bound and UB is less than one.: The multipliers are re-adjusted by the conjugate subgradient algorithm for the Lagrangian dual corresponding to(LR^2). An upper bound is computed every 5 iterations and UB is updated if necessary. The algorithm is terminated without entering the next stage if the gap between the best lower bound and UB is less than one.: The relaxationLR^2mis solved withMincreased fromM=∅. WhenMis increased, an upper bound is computed and UB is updated if necessary. Then, multipliers are re-adjusted by the conjugate subgradient algorithm for a smaller number of iterations than those in Stage 1 and Stage 2. After it terminates, new jobs are chosen fromN⧹Mand added toM. It is repeated until the gap between the lower bound and UB becomes less than one.Elimination of unnecessary dynamic programming states in the SSDP method is performed in the course of the algorithm by the network reduction techniques in [20], which were explained in Section 3. These are applicable to our problem with minor modifications. An upper bound is computed also in a similar way to that in [20]: a solution of a relaxation is converted to a feasible solution of (P), and then the enhanced dynasearch [29,30] is applied to improve it. To convert to a feasible solution, we first remove all the jobs that break the precedence constraints or that occur more than once. Then, the jobs that do not appear in the partial schedule are inserted into it optimally or greedily so as not to break the precedence constraints. To insert the absent jobs optimally, the dynamic programming algorithm in [22] is applied with a modification to satisfy the precedence constraints. However, the time complexity of the algorithm depends exponentially on the number of absent jobs n′ and is given byO((n-n′+1)n′2n′). Therefore, a heuristic algorithm is employed instead to insert the absent jobs one by one according to the SPT (shortest processing time) order, when the number of such jobs is large. It takes only O(n′log n′) for ordering the absent jobs and O((2n−n′+1)n′) for inserting them one by one (the number of candidate positions for the i-th absent job is n−n′+i). The obtained solution is improved by the enhanced dynasearch extended to our problem by forbidding moves in the neighborhood that break the precedence constraints. The dynasearch is a local search algorithm that employs a neighborhood called dynasearch neighborhood. It is defined by solutions obtained via any number of pairwise interchanges (PIs) that do not intersect with each other. In addition to PIs, extraction and forward shifted re-insertions (EFSRs), and extraction and backward shifted re-insertions (EFSRs) are considered in the enhanced dynasearch neighborhood. The primary advantage of these neighborhoods is that the best solution in the neighborhoods is obtainable in polynomial time by dynamic programming although they are composed of an exponential number of solutions. To extend them to the problem with precedence constraints, we simply forbid such PIs, EFSRs and EFSRs that break the precedence constraints, and this does not increase the time complexity of the dynamic programming algorithm. The initial upper bound is computed in the same manner, except that the length of the partial schedule is zero and all the jobs are inserted greedily.In [19,20], the Lagrangian multipliers obtained in Stage 2 are also used in Stage 3, while in the proposed algorithm they are re-adjusted forLR^2min Stage 3. It is because the duality gap of our problem is larger than that of the problem without precedence constraints and hence it is necessary to improve the lower bound as much as possible. Another reason is that if jobs i and j appear inM,μijPis set to zero to remove the corresponding penalty term from the objective function because the corresponding precedence constraint i→j is always satisfied. This affects the optimal Lagrangian multipliers much and thus justifies the re-adjustment.The jobs to be added toMin Stage 3 are determined as follows. For each jobi∈N⧹M,(27)∑(j,i)∈APμjiP+∑(i,j)∈APμijPis computed and a job with a larger (27) is chosen first. By doing this, precedence constraints that affect the objective value are supposed to be satisfied as early as possible. Ties are broken by the occurrences of corresponding nodes inG^Sm, and a job that occurs less frequently is chosen first.The proposed algorithm is applied to the precedence-constrained single-machine total weighted tardiness problem1|prec|∑wiTiand the precedence-constrained single-machine total weighted earliness–tardiness problem without machine idle time1|prec,noidle|∑(αiEi+βiTi). Instances are generated from the OR-Library instances of1∑wiTiwith 40, 50 and 100 jobs that are available from astjjb/jeb/orlib/wtinfo.htmlurlhttp://people.brunel.ac.uk/∼mastjjb/jeb/orlib/wtinfo.html. In the OR-Library instances, the processing time pi, the tardiness weight wiand the duedate diof each job i were generated from the integer uniform distributions [1,100] and [1,10], [T(1−TF−RDD/2), T(1−TF+RDD/2)], respectively. Here, TF and RDD are the tardiness factor and the range of duedates, respectively, and they are chosen from {0.2,0.4,0.6,0.8,1.0}. There are five instances for each combination of n,TF and RDD, and hence 125 instances for each n. To generate instances of1|prec|∑wiTifrom these, precedence constraints are added as in [3,4]: For every pair of i andj(i,j∈N,i<j), whether the precedence constraint i→j is imposed on or not is determined by a specified probability P. The instances of1|prec,noidle|∑(αiEi+βiTi)are generated by adding precedence constraints in a similar way to the instances of1|noidle|∑(αiEi+βiTi)used in [19], which were generated from the OR-Library instances by choosing the tardiness weight βi=wiand by generating the earliness weight αifrom the integer uniform distribution [1,10]. We choose P from {0.005,0.01,0.02,0.05,0.1,0.2} and thus there are 125 instances for each combination of n, P and the problem type. The computation is performed on a desktop computer with Core i7 960 (3.2gigahertz) CPU and 12gigabytes RAM. The maximum memory size for storing the network structure is set to 3gigabytes and the time limit is set to 10,000seconds. For comparison, the dynamic programming algorithm in [15] is implemented and applied to these instances. Since this algorithm was originally proposed for employing dominance properties, the precedence relations derived from the dominance properties summarized in [31] are used for1|prec|∑wiTiadditionally, as far as they are consistent with the original precedence constraints. In other words, the precedence relations are put into GP as far as no cycle is formed. Note that these additional precedence constraints are available only for1|prec|∑wiTibecause no such dominance properties are known for1|prec,noidle|∑(αiEi+βiTi).The results are shown in Tables 1 and 2, where average (ave) and maximum (max) CPU times over optimally solved instances (solved) are given in seconds for the proposed algorithm (Proposed) and the dynamic programming algorithm in [15] (DP in [15]). In “proposed”, the instances without precedence constraints (P=0.0) are solved not by the proposed algorithm but by an improved version of the algorithm in [19]. From the tables, we can verify that the proposed algorithm successfully solved all the instances with 40 and 50 jobs, and almost all the instances with 100 jobs of1|prec|∑wiTi. For the unsolved instances, the proposed algorithm reached the memory limit or the time limit. On the other hand, the dynamic programming algorithm in [15] failed to solve instances only due to the memory limit. The latter algorithm could not solve some instances with 40 jobs. In particular, it could not solve even a single instance of1|prec,noidle|∑(αiEi+βiTi)when n=40 and P=0.0, 0.005, 0.01, 0.02, or 0.05 because dominance properties cannot be exploited for this type of problem. However, the precedence constraints are so restrictive when P=0.2 and the algorithm worked better than the proposed algorithm. Nevertheless, it could not solve some of the instances with n=100 and P=0.2. For both the algorithms, the hardest instances seems those with P=0.02 or P=0.05.Next, the lower bounds obtained in Stage 2 of the proposed algorithm and those by the method in [18] are compared for the instances with n=40. The method in [18] is to exploit precedence constraints in the Lagrangian relaxation based-lower bound obtained by relaxing the machine availability constraint. To apply it, precedence relations derived from the dominance properties in [31] are also used as precedence constraints and put into the precedence graph GP. Since the method in [18] cannot treat the precedence constraints that form an undirected cycle in GP, such cycles are broken randomly.The results are summarized in Tables 3 and 4, where the average (ave) and maximum (max) relative gaps are given in percent. Here, the relative gap is computed by 100((optimal value)−(lower bound))/(optimal value), and when the absolute gap (optimal value)−(lower bound) is less than one, it is regarded as zero. From Table 3, we can see that much better lower bounds are obtained by our algorithm than the method in [18] for1|prec|∑wiTi. On the other hand, the difference is smaller for1|prec,noidle|∑(αiEi+βiTi)in Table 4, and the method in [18] yields rather better lower bounds on average when P=0.02, although it cannot exploit any dominance properties for this class of problem. The reason why the method in [18] yields better lower bounds for1|prec,noidle|∑(αiEi+βiTi)than for1|prec|∑wiTiwill be that taking into account precedence constraints affects the objective value much because the completion cost of a job is zero only when it is just-in-time. In contrast, the completion cost of a job is zero for1|prec|∑wiTiwhen it is before the duedate and hence precedence constraints do not affect the objective value compared to1|prec,noidle|∑(αiEi+βiTi).It is direct to show that the best lower bound obtained by (LR0) and that by the Lagrangian relaxation of the machine availability constraint in [18] are identical when precedence constraints do not exist. Therefore, the advantages of our lower bound are the constraints in Sections 4.2 and 4.3, and the improvement by the method in [4], while the advantage of the method in [18] is that precedence constraints are not relaxed. Therefore, it was expected that the method in [18] yields better lower bounds as P increases, but the results were not so. One reason might be that the method in [18] cannot be applied to the problem with the precedence constraints including cycles and hence such precedence constraints are broken randomly. It follows that precedence constraints that are actually taken into account do not increase much even if P becomes large. On the other hand, all the precedence constraints are penalized in our method and, moreover, exactly considered for every pair of jobs in an adjacent position. This advantage seems to dominate over the advantage of the method in [18]. Nevertheless, the difference between the lower bounds in Stage 2 of our algorithm and those in [18] is not large and it might be difficult to solve the instances of1|prec,noidle|∑(αiEi+βiTi)with n=100 and P=0.02 even if we succeeded in integrating the method in [18] into our SSDP framework.Tables 3 and 4 also suggest difficulties in obtaining good lower bounds for this type of problem. The gaps are large and widely distributed when P≠0 compared to those when P=0. If a precedence constraint i→j is imposed on two jobs i and j that are processed in this order in an optimal solution for the problem without precedence constraints, it has no effect on the gap (when the corresponding Lagrangian multiplier is appropriately adjusted and is set to zero). Since the precedence constraints in the benchmark instances are generated randomly, the number of such precedence constraints also varies randomly. Nevertheless, it will not affect the gap much if the precedence constraints are handled successfully when computing the lower bounds. However, in practice, the gap is widely distributed and totally affected by the randomness of the precedence constraints, which together with the large gap implies the difficulties in obtaining good lower bounds.

@&#CONCLUSIONS@&#
