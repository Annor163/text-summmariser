@&#MAIN-TITLE@&#
High order structural image decomposition by using non-linear and non-convex regularizing objectives

@&#HIGHLIGHTS@&#
The paper provides a family of non-smooth and non-convex regularizing objectives.These objectives operate image structural cartoon-versus-texture image differencing.These objectives reach high level cartooning with piecewise constant edge transitions.From these objectives, segmentation can be seen as instance of image regularization.

@&#KEYPHRASES@&#
Non-convex optimization,Regularization,Image decomposition,

@&#ABSTRACT@&#
The paper addresses structural decomposition of images by using a family of non-linear and non-convex objective functions. These functions rely on ℓpquasi-norm estimation costs in a piecewise constant regularization framework. These objectives make image decomposition into constant cartoon levels and rich textural patterns possible. The paper shows that these regularizing objectives yield image texture-versus-cartoon decompositions that cannot be reached by using standard penalized least square regularizations associated with smooth and convex objectives.

@&#INTRODUCTION@&#
Image decomposition in cartoon and texture patterns plays an important role in high definition (HD) image processing [1–3]. For instance, recent image engines such as ©SONY’s Bravia HD “X-reality-pro” processes images by decomposing them into smooth/texture/color components, enhancing every component separately, then fusing the results. This yields high quality images and videos, even for images issued from a low definition camera.Cartoon-versus-texture image decomposition is possible via certain regularization objectives. Since regularization functions operate differently depending on the image content, the main issue raised by this decomposition is the selection of best regularizers for splitting a given image into its cartoon (smooth11We use the following definition of smoothness: a smooth 2D function is a function having continuous derivatives up to certain order. This function is thus (at least) continuous everywhere. A 2D function that is smooth, excepted on 2D curves, is called piecewise smooth function.or piecewise smooth) part and a purely textural22The textural part of the image is then defined as the complementary with respect to difference operator of the carton part. This includes noise, for noisy image acquisitions.part.Most of the texture-structure decomposition methods available in the literature pertain to the class of least square objectives (quadratic forms) in the sense that these methods are variants of penalized least squares (PLS). The discrete form of a PLS objective can be written in the following form, involving a penalty function Qλ:(1)∥x[i,r]−y∥22+2∑ℓ=i−ri+rQλ(|yℓ|),where λ is a parameter for tuning data fidelity, smoothness and roughness. The PLS problem inherits the convexity [4–13] or non-convexity of Qλ[14–21] (the quadratic term involved in this problem is a convex function). Both convex and non-convex forms have shown relevancy in many image processing applications involving•denoising and deconvolution [2,4,5,8,10,14,15,22–24];cartoon/texture decomposition and image inpainting [6,7,10,25];inverse problems and compressive sampling reconstruction [26–28]; etc.Note that a PLS problem can be expressed in the image input space [5,8], the Fourier domain [7], [10], the wavelet domain [4,11,13] or via Meyer’s oscillatory functions [6,12].Some image regularizing objectives that do not pertain to the PLS class are stack filters [29–31]. Stack filters include the classes of weighted medians and some morphological type filters. In particular, non-convex objectives have been considered in [31] for the design of stack filters. These objectives apply on a binary level image representation obtained from a combination of threshold operators over several positive boolean functions. The optimal solution for these stacked objectives is then determined as the solution of a linear program (see [31] for details). This optimal solution is mainly relevant for denoising purposes, see [29–31], among other references.The objective functions discussed in this paper do not involve any quadratic term. In this respect, their cartoon-versus-texture image decompositions are expected to differ significantly from those issued from PLS objectives.These objectives operate structural image decomposition thanks to fractional ℓpquasi norms. They are non-smooth by construction so as to make sharp cartooning effect and rich texture rendering possible. The insight is to approximate the cartoon part of an image as a piecewise constant field by means of functionals that promote the number of occurrences for any given value in the pixel neighborhood. In this respect, these objectives operate in a way such that image segmentation can be seen as a particular case of image filtering (the gap between filtering and segmentation can be filled by tuning 1 parameter, the order p of the ℓpquasi-norm used).The paper will shows that choosing non-smooth objectives is essential for high level cartooning (few gray levels, sharp edges) of many images since smoothness constraint (for instance, the one induced by gradient concerns in solving PLS problems) is known to yield over-smoothed results. Section 2 introduces the non-smooth and non-convex objectives proposed in the paper and derives the mathematical characterization of their solutions. Section 3 addresses the non-convex and non-linear programming for computing these solutions and provides the interpretation of these solutions with respect to image analysis. Finally, Section 4 concludes the work.LetI={I(m,n)}1⩽m⩽M,1⩽n⩽Ndenotes a gray-level image. A (2r0 + 1) × (2r1 + 1) pixel neighborhood centered on pixel I(m, n) is the set{I(m+j,n+k)}j=−r0,−r0+1,…,r0k=−r1,−r1+1,…,r1.This set is written hereafter in a vectored form by notingx[i,r]=(xi−r,…,xi−1,xi,xi+1,…,xi+r)∈R2r+1where r = ((2r0 + 1)(2r1 + 1) − 1)/2 and xi= I(m, n) (for instance, i = n + (m − 1) × N if we consider line-by-line image scan). This reshaping has no consequence with respect to the regularization problem considered in the paper.The regularizing objectives studied in the paper are given by(2)fp(t,x[i,r])=∥x[i,r]−t∥ℓpp=∑ℓ=i−ri+r|xℓ−t|p,where x[i, r] is the neighborhood set given above andt∈R. The paper addresses three issues:•characterizing function fpgiven by Eq. (2),solving the minimization problem:(3)αp(x[i,r])=argtminfp(t,x[i,r]),andproviding an interpretation of the solutions of the problem given by Eq. (3) in terms of image cartoon and textural contents.Some particular solutions of problem Eq. (3) are widely used statistics in image processing and analysis: α2 is the sample mean33Function f2 is differentiable and convex: solvedf2dt(t)=0to derive that α2 is the mean value:α2=(∑ℓ=i−ri+rxℓ)/(2r+1).and α1 is the sample median44The sample median is such that the median value is constrained to belong to the sample set.[32], the latter being unique because we have considered an odd number of samples in x[i, r].The main differences between objective fpand the above PLS objectives are•fpdoes not involve a quadratic error term (difference with respect to both convex and non-convex PLS approaches).Vector y involved in PLS objective of Eq. (1) is reduced to a constant sequence with constant element t in fpobjective. The search for this optimal constant is restricted to a small pixel neighborhood, expressing local variations with respect to a piecewise constant image model.While ignoring quadratic error terms such as those involved in PLS, we cannot guarantee a reasonable mean squared error and the resulting image can “deviate” significantly from the original image in terms of the mean squared error. However, it is well known that quadratic loss criteria do not promote structural image perceptions whereas our goal is to point out and differentiate structural contents of a heterogeneous image in terms of cartoon/texture decompositions.Problem Eq. (3) is non-convex in general for 0 ≤ p < 1. For instance, when p = 0 (the pseudo-norm ℓ0, associated with a counting process is then used), solution α0 of this problem is the sample mode, this mode being non-unique for distributions having multiple sample points with the same and most occurring value.In what follows, we are interested in problem Eq. (3) for 0 < p < 1 and without any additional constraints such as the linearization performed in [31] (introduction of Boolean operators at stack levels). Sections 2.2 and 2.3 below derive the mathematical characterization of solutions to this problem. These characterizations highlight that the solutions to the problem Eq. (3) pertain to the sample data observed, as in the case of order statistics. However, these characterizations also show that the solutions of problem Eq. (3) are not order statistics in the sense that the regularizing cost acts by modifying order statistics depending on the number of occurrences of every value.In the rest of the paper, we will assume that xi≤ xjif i < j (ordering operation on the vectored pixel neighborhood) since once the pixel neighborhood x[i, r] is extracted, the objective function fpis invariant with respect to re-orderings of data in x[i, r]).Theorem 1Assume that xk< xk + 1. Function fp(·, x[i, r]) defined byEq. (2), when restricted to the set ]xk, xk + 1[, is concave on this interval. Its maximum is the unique real x*, with xk< x* < xk + 1, satisfying:∑ℓ=i−rk|xℓ−x*|p−1−∑ℓ=k+1i+r|xℓ−x*|p−1=0.The result follows by computing and checking the sign of the first two derivatives of fp(t, x[i, r]) for t ∈ ]xk, xk + 1[.□The consequence of the concavity expressed in Theorem 1 is that in interval [xk, xk + 1], the minimum of function fp(·, x[i, r]) is either fp(xk, x[i, r]) or fp(xk + 1, x[i, r]):mint∈[xk,xk+1]fp(t,x[i,r])=min{fp(xk,x[i,r]),fp(xk+1,x[i,r])}.More precisely, by taking into account thatmint∈]−∞,xi−r]fp(t,x[i,r])=fp(xi−r,x[i,r])andmint∈[xi+r,+∞[fp(t,x[i,r])=fp(xi+r,x[i,r])we derive from Theorem 1 that:(4)mint∈Rfp(t,x[i,r])=min{fp(xk,x[i,r])}k=i−r,…,i+rand, for any t ∉ x[i, r]:(5)fp(t,x[i,r])>min{fp(xk,x[i,r])}k=i−r,…,i+r,so that we can formalize:Theorem 2The problemEq. (3)is equivalent to:(6)βp(x[i,r])=min{fp(xk,x[i,r])}k=i−r,…,i+r.From Theorem 2, we derive that function fp(·, x[i, r]) reaches its minimum in the set x[i, r]. Identifying the solutions of problem Eq. (3) thus amounts to evaluating function fpto the values available in this sample set. It follows that if we define(7)gp(t,x[i,r])=∑ℓ=i−ri+r(ap,ℓt+bp,ℓ)1[xℓ,xℓ+1](t),with(8)ap,ℓ={fp(xℓ+1,x[i,r])−fp(xℓ,x[i,r])xℓ+1−xℓifxℓ<xℓ+10ifxℓ=xℓ+1and(9)bp,ℓ={xℓ+1fp(xℓ,x[i,r])−xℓfp(xℓ+1,x[i,r])xℓ+1−xℓifxℓ<xℓ+10ifxℓ=xℓ+1then we derive:Theorem 3The problemEq. (3)is equivalent to:(10)λp(x[i,r])=argtmingp(t,x[i,r]),where function gp is defined byEqs. (7)–(9)above.Function gpis a piecewise linear version of fp: gpcan thus be decomposed into a linear programming problem involving 2r + 2 linear constraints. In this respect, solutions of problem (10) pertain to the vertices of the polyhedron of constraints (open polyhedron involving 2r + 1 vertices (xℓ, gp(xℓ)) for ℓ = i − r,…, i + r). Linear programming methods can thus be used to find solutions of Eq. (3). However, we are not concerned by such methods hereafter since r is small in our context (small pixel neighborhood): we evaluate function fpat the vertices of this polyhedron and find the minimum by sorting the values of fpon points {xℓ}ℓ = i − r,…, i + r.In addition, we have:Theorem 4Assume that:(11)xℓ∈{0,1,…,D−1},foreveryℓ=i−r,…,i+r,where D ≥ 2 denotes the data dynamic (an 8-bit encoded image has a dynamic D = 256). Let 0 < p ≤ q ≤ 1. Then,(12)fp(xℓ,x[i,r])⩽fq(xℓ,x[i,r]).On the one hand, if x[i, r] is a constant sequence, then we have: fp(xℓ, x[i, r]) is zero for every 0 < p ≤ 1.On the other hand, if there exist some k, ℓ ∈ {i − r,…, i + r} such that xk≠ xℓ and Eq. (11) holds true, then we have:•if D = 2, then fp(xℓ, x[i, r]) counts the number of elements that are different from xℓ. In this respect, fp(xℓ, x[i, r]) = fq(xℓ, x[i, r]) for p ≠ q.if D > 2, fp(xℓ, x[i, r]), as a function of p, is derivable and has a non-negative derivative.This ends the proof.□Since fpis concave in all intervals [xℓ, xℓ + 1] for ℓ = i − r, i − r + 1,…, i + r − 1), we derive that the piecewise linear functions gpand f1 verify: gp(t, x[i, r]) ≤ f1(t, x[i, r]) for every p, with 0 < p ≤ 1. Since the minimum of f1 is reached at xi(sample median of x[i, r] by construction) and f1 is convex, it follows that for many sample x[i, r] distributions, the sample median xiinform us of the location of αp(x[i, r]) when p is close to 1.Furthermore, when p is close to 1, the extrema xi − rand xi + rare the worst candidates with respect to αp(x[i, r]) location in general, except if these values have very large occurrences (extrema are not outliers if they have large occurrences).One may think that Theorem 4 relates some order statistics, etc., however, value αpis not an order statistic as highlighted in Fig. 1. Indeed, value occurrences have a higher impact on the location of αp(x[i, r]) than on the location of order statistics (see Fig. 1).The following theorem highlights the role played by sample xkoccurrences in the sample set x[i, r].Theorem 5LetSk={ℓ,i−r⩽ℓ⩽i+r,xℓ≠xk}.We have:(13)fp(xk,x[i,r])⩽fp(xm,x[i,r])+Ck|xm−xk|p,whereCk=#Skand#denotes set cardinality.We havefp(xk,x[i,r])=∑ℓ=i−ri+r|xℓ−xk|p=∑ℓ∈Sk|xℓ−xk|p.Thus,fp(xk,x[i,r])⩽∑ℓ∈Sk|xℓ−xm|p+∑ℓ∈Sk|xm−xk|p.On the one hand,∑ℓ∈Sk|xℓ−xm|p⩽fp(xm,x[i,r]).On the other hand,∑ℓ∈Sk|xm−xk|p=Ck|xk−xm|p.This ends the proof.□Theorems 2 provides an equivalent formulation of the problem Eq. (3): αp(x[i, r]) = βp(x[i, r]).While computing αp(x[i, r]) from Eq. (3) is not straightforward, computing βp(x[i, r]) from Theorem 2 is straightaway: it involves computing 2r + 1 values fp(xk, x[i, r]) for k = i − r,…, i + r, sorting these values and retrieving the index/indices where the minimum value of fpis reached.The computational complexity induced by the direct calculation amounts to•computing a symmetric matrix having zero diagonal and dimension (2r + 1) × (2r + 1), the r × (2r + 1) non-zero elements being those |xk− xℓ|plocated at row/column k and column/row ℓ ≠ k,identifying the row (resp. column) with smallest sum of entries in a row-wise (resp. column-wise) summation.In what follows, quantity αpintroduced above will be associated to image regularization and is computed by using the following recursive approach (notation ℵp):(14)ℵp[i]=argtminfp(t,{ℵp[i−r],…,ℵp[i−1],xi,xi+1,…,xi+r}).From regularization perspective, this recursive computation consists in replacing (over-writing) the central value I(m, n) by ℵp[m, n] before sliding the window to process the next pixel. Note that when considering a line-by-line image scan, then over-writing involved in ℵpcomputation isℵp[m,n]=argtminfp(t,{ℵp(m−r0,n−r1)⋯ℵp(m−r0,n−1)ℵp(m−r0,n)ℵp(m−r0,n+1)⋯ℵp(m−r0,n+r1)⋮⋮⋮⋮⋮ℵp(m−1,n−r1)⋯ℵp(m−1,n−1)ℵp(m−1,n)ℵp(m−1,n+1)⋯ℵp(m−1,n+r1)ℵp(m,n−r1)⋯ℵp(m,n−1)I(m,n)I(m,n+1)⋯I(m,n+r1)I(m+1,n−r1)⋯I(m+1,n−1)I(m+1,n)I(m+1,n+1)⋯I(m+1,n+r1)⋮⋮⋮⋮⋯⋮I(m+r0,n−r1)⋯I(m+r0,n−1)I(m+r0,n)I(m+r0,n+1)⋯I(m+r0,n+r1)}†)where † stands for vectorization of a pixel neighborhood (whatever the vectorization order since ℵpis invariant with respect to set ordering). It is worth mentioning that one can also choose a Peano Hilbert scan of the image, that is: a continuous curve (1D) joining all pixels of I. From such an association, the over-writing concerns pixel preceding position (m, n) with respect to Peano Hilbert 2D grid ordering of I.Operation Eq. (14) provides a value ℵpthat is optimal in the ℓperror-norm sense for representing a pixel neighborhood. Note that ℵ0, the recursive mode, is robust to monotonic changes such as brightness and/or contrast variations. Note also that ℵ1, the recursive sample median, ensuring the least absolute deviations, is robust to the presence outliers. The value ℵpderived from Eq. (14), as a compromise between ℵ0 and ℵ1, is thus expected to be robust to both monotonic changes and the presence of outliers. As shown in Section 3 below, applying Eq. (14) to image I, having size M × N, amounts estimating I by a regularized image ℵpwith the same size and containing q ≪ M × N robust measurements: each ℵp[m, n] having a large occurrence Qi, with∑i=1qQi=M×N. This corresponds to a cartoon-like part of an image that is estimated from the q more robust ℓperror-norm statistics of the image. Other approaches relating robust optimum can be found in [33].In practice, Eq. (14) can lead to multiple solutions. When ℵpdoes not reduce to a singleton, indetermination raised by multiple solutions can be removed by:•increasing/reducing the window size associated with the pixel neighborhood,making the objective convex by adding an appropriate penalty function,sorting and selecting one among the solutions by specifying an additional criterion/constraint.In the current implementation, we have used the third issue and we set the solution to be applicable (only if multiple solutions occur):•the median of {ℵp[m, n]} if#{ℵp[m,n]}is odd,the median of the set {ℵp[m, n]}∪{I(m, n)} when#{ℵp[m,n]}is even.In this respect, the optimumargsf1(s,argtminfp(t,•))is always associated with one of the samples involved in the data (one among the observed values, a remarkable property of the approach discussed in the paper).This section highlights the interest of exploiting non-convex and non-differentiable regularization functions in image cartoon/texture decomposition. A comparison is performed with respect to a convex regularization problem based on the total variation (TV) objective.TV objectives are widely used for cartoon/texture decomposition. TV methods are based on the PLS problem introduced in Section 2.1: these methods involve an ℓ2 based error-norm and an additional penalty function for tuning the smoothness degree. TV cartoon/texture decomposition assumes an observation model having the formx=u+vwhere u denotes the cartoon image and v is the texture image (noise is considered as a ‘stochastic texture’ in this paper and we do not consider an additional term for noise representation).Optimal TV cartoon u* and texture v* images are defined to be solutions to the following minimization problem:(15){u*=arguminμT(x−u)+λC(u)v*=x−u*where•parameters λ, μ make tuning the amount of cartoon/texture possible,quantity C(u) is a TV penalty function promoting cartoon features, this quantity being the energy of the gradient of u (note that u is assumed to follow from samples of a differentiable function):C(u)=∫R∥∇u(t)∥2dtand T(x − u) = T(v),T(v)=12∥v∥22is an ℓ2 error-norm representing the amount of extracted texture. The corresponding TV is called TV-ℓ2, see [8] among other references.Many variants of the above PLS based TV have been proposed in the literature. The variants include weighted Hilbert norms associated with Fourier (notationF) domain representation and a selective filter G:T(v)=12∥WGFv∥22where•G is an all-pass filter and W is a fractional weight function having the formW(ω)=1ϵ+∥ω∥in [10], the corresponding TV being called TV-H−1, orG is associated to a Gabor filter (band-pass on texture frequencies when a priori knowledge is available on frequencies of interest associated with the textural information) in [7], the corresponding TV being called TV Gabor Hilbert norm or simply TV-G. It is usual considering in this TV model, a radial weight functionW(ω)=1−e−(∥ω∥−r)22σ2.The test images given in Fig. 2 are selected to cover different texture types and different image acquisition modalities. “Iguana” and “Barbara” are optical images whereas “Radar” is a synthetic aperture radar image. “Iguana” image has a textured skin showing different type of cells and stripes on its body. In addition, some numerical characters and a signature have been affixed at the bottom-right of the image. “Barbara” image highlights grid-wise and linewise striped textures on clothes and tablecloth. In “Radar” image, the texture is a composition of forest, small urban structures and speckle (stochastic texture issued from reflection, refraction and diffraction of coherent radar waves on ground surface). The black line given in this radar image is an airstrip, the image also includes a volcano (top center of the image) and a part of the city of Goma in Congo (near the airstrip).It is worth mentioning that performance evaluation depends on the a priori norm used: a quadratic regularization function yields optimal performances in the mean squared error sense. An absolute deviation strategy such as median regularization will yield optimal results when performance is evaluated with respect to ℓ1 error-norm55This equivalent is to say that optimality is conditioned by the error-norm chosen for measuring performance: the mean, the median and the mode filters are both optimal filters since these filters correspond respectively to the solutions ℵ2 and ℵ1 and ℵ0. The difference between these optimal filters is the a priori error-norm used to assess their quality.and more generally, an ℓpregularization will lead to minimal ℓperror-norm by construction. Performance expressed in terms of PSNR is thus a biased performance measurement for the purpose of this section, the bias being related to the error-norm used for performance measurements (ℓ2 for PSNR, which relates to mean squared error). Performance evaluation will thus be limited to visual perception of cartoon/texture when the decomposition is performed by using ℵp-value and the TV-G method described above. In all TV-G based experimental results, the regularization parameter λ is fixed at 1000 and different μ parameters are used. Among the effective methods for finding the optimal solution of this TV problem, we first consider the algorithm of [34] based on Split Bregman iterations, with no a priori on the texture of interest (in this respect, G is an all-pass filter).Cartoon versus texture decompositions of the test images of Fig. 2 are given for different ℵp-values and different TV-G μ regularization parameters in Figs. 3–8. For the sake of comparison, these images are displayed without histogram equalization (post-processing commonly used to enhance textural information). Indeed, histogram equalization performs adaptively with respect to the input image histogram and induces a biased comparison. Before comparing, it is worth highlighting that ℵp-value and TV-G capture different textural information and have different dynamics. Furthermore, the textural information quality is known to rely on personal perception: interpretation is left to the reader personal perception of cartoon and textures.“Iguana” cartoon images obtained by using ℵp-values, especially with 7 × 7 window size, are characterized by a high level cartoon description: all iguana cells and stripes have been removed from the cartoon part (see Fig. 3) and placed in the textural part (see Fig. 4). This yields a peeling-like effect of the iguana skin, with an important number of regions with constant values “under the skin” (cartoon) separated from the skin stripes and cells (texture). Results obtained from TV-G on “Iguana” are such that small μ parameters yield remaining textural cells in the cartoon images whereas large μ parameters tend to over-smooth the cartoon image (see Fig. 3) without clearly highlighting the edges/segments between different regions. The best TV-G results are obtained for μ = 500. The corresponding texture (see Fig. 4) involves a smooth trend. In addition, both TV-G cartoon and texture images exhibit oscillating behavior for large μ parameters.The same remarks as above hold true for “Barbara” image (see Figs. 5 and 6): while TV-G performs slightly better on this image than on “Iguana” image, TV-G performs less relevantly than ℵp-value for a complete extraction of textures having non-thin structures. Note also that TV-G continue to introduce oscillations in both cartoon and texture images. In contrast, textures captured by ℵp-value seem to be mainly associated with edges the image. For the specific case of “Barbara” image, substantial results (similar to the ones derived by ℵp-value) have been obtained in [6] and [35].For “Radar” image, ℵp-value makes a segment-wise cartooning effect possible (see Fig. 7) with no visible texture for large window sizes and when p decreases from 1 to 0.25: the deterministic structures and stochastic speckle involved in the original image are relocated in the texture image (see Fig. 8). In contrast to this concise ℵp-value based cartoon/texture decomposition, TV-G “Radar” cartoon and texture images are impacted by a blurring effect (see Figs. 7 and 8). This blurring is probably due to the sensitivity of the TV-G to the smoothness degree of the input data, whereas “Radar” is highly heterogeneous. An adaptation of TV to multiplicative image models (case of “Radar” image) can be found in [36]. Note, however, that ℵp-value performs well on multiplicative type “Radar” image without the need of an adaptation.When analyzing ℵpbased cartoon decompositions associated with different windows sizes and different p-values in Figs. 3, 5, and 7, we observe that no explicit limit from denoising to segmentation exists. The piecewise constant (segmentation-like) behavior induced by ℵpregularization is illustrated in details in Fig. 9 (line sections of test and cartoon images).To conclude this section, a comparison of ℵpand TV-G based decompositions is given in Fig. 10 for a color image (richer visual rendering than a gray level image). A discussion is also provided in Appendix A, for the definition of an ideal concept of cartoon.

@&#CONCLUSIONS@&#
The paper has investigated the properties of some non-convex objectives for the decomposition of digital images in cartoon-versus-texture components. These objectives are associated with regularizing functions that can reach a high level of texture extraction and sharp cartoon edge preservation. The cartooning effect induced by these objectives ranges from denoising (small window sizes and when p parameter of the ℓperror-norm is close to 1) to image segmentation (large window sizes and when p is close to zero). Such a high level cartooning and texture extraction can benefit modern high definition image processing which raises the need of separating an image into fundamental textured and cartoon parts, processing each part separately and fusing the corresponding processed images for increasing definition.A first extension of this work concerns weighted functionals such as the ones involved in TV-G and TV-H−1. Another extension of this work concerns multi-level/multi-scale decompositions such those described in [37–40]. As far as the theoretical point of view is concerned, a non-straightforward extension of this work is a direct seeking of an ideal cartoon model where total variation is constrained by predefined pixel levels and a weight function associated with the number of occurrences of observed levels.