@&#MAIN-TITLE@&#
DEEPEN: A negation detection system for clinical text incorporating dependency relation into NegEx

@&#HIGHLIGHTS@&#
Utilizing Stanford dependency relation to further analyze the negation status of clinical concepts negated by NegEx.Improvement of NegEx algorithm by decreasing the number of false positives.Comparison of NegEx and DEEPEN on clinical reports from two different clinical settings.

@&#KEYPHRASES@&#
Natural language processing,Dependency parser,Negation,

@&#ABSTRACT@&#
In Electronic Health Records (EHRs), much of valuable information regarding patients’ conditions is embedded in free text format. Natural language processing (NLP) techniques have been developed to extract clinical information from free text. One challenge faced in clinical NLP is that the meaning of clinical entities is heavily affected by modifiers such as negation. A negation detection algorithm, NegEx, applies a simplistic approach that has been shown to be powerful in clinical NLP. However, due to the failure to consider the contextual relationship between words within a sentence, NegEx fails to correctly capture the negation status of concepts in complex sentences. Incorrect negation assignment could cause inaccurate diagnosis of patients’ condition or contaminated study cohorts. We developed a negation algorithm called DEEPEN to decrease NegEx’s false positives by taking into account the dependency relationship between negation words and concepts within a sentence using Stanford dependency parser. The system was developed and tested using EHR data from Indiana University (IU) and it was further evaluated on Mayo Clinic dataset to assess its generalizability. The evaluation results demonstrate DEEPEN, which incorporates dependency parsing into NegEx, can reduce the number of incorrect negation assignment for patients with positive findings, and therefore improve the identification of patients with the target clinical findings in EHRs.

@&#INTRODUCTION@&#
Electronic health records (EHRs) contain valuable clinical information that can be used for various applications such as clinical decision support systems, medication reconciliation, public health emergency surveillance, and quality measurements [1]. However these applications are not readily feasible because much of the information in EHR is in free text format. Natural language processing (NLP) systems have been developed to extract clinical concepts from text, yet this is not an easy task because the meaning of a concept is significantly affected by modifiers such as negation. Negative clause is defined as “an assertion that some event, situation, or state of affairs does not hold. Negative clauses usually occur in the context of some presupposition, functioning to negate or counter-assert that presupposition” [2].A study of negation has shown that clinical observations are frequently negated in clinical narratives [3]. Negation detection in clinical language tends to be very trivial in sentences such as “no fracture”, “patient denies headache”, and “she does not have marked dysmenorrhea.”. Therefore simplistic approaches such as NegEx [4] that use negation cue words without considering the semantic of a sentence perform well. However, the simplistic approaches sometimes fail to correctly identify the negation status of clinical concepts in sentences with complex structure. We have faced with this problem while using NegEx in our NLP system that automates the identification and tracking of patients with pancreatic cysts [5]. Table 1shows some examples of such sentences where NegEx incorrectly negates pancreatic cyst concepts.Aiming to reduce the number of missing pancreatic cyst patients in our NLP system inspired us to improve the negation assignment of NegEx by incorporating dependency parsing into NegEx. Dependency relation is a binary asymmetric relation between tokens within a sentence that has been shown to improve various NLP tasks including information extraction [6], negation detection [7], entity disambiguation [8] and many others [9].We developed and tested our negation identification algorithm focusing on only pancreatic cyst concepts using a single institution data set. In order to evaluate its performance on other clinical concepts and dataset, we applied our system on 159 clinical notes from Mayo Clinic where clinical findings such as disorders and signs/symptoms have been annotated. We compared the performance of our algorithm on Mayo Clinic dataset with NegEx.

@&#CONCLUSIONS@&#
