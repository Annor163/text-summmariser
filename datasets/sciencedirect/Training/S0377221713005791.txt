@&#MAIN-TITLE@&#
Distributionally robust mixed integer linear programs: Persistency models with applications

@&#HIGHLIGHTS@&#
We review advances in the distributional analysis of mixed integer linear programs.We discuss complexity results and conic programs for this class of problems.We provide applications in network, choice, random walk, and newsvendor problems.

@&#KEYPHRASES@&#
Distributionally robust bounds,Mixed integer linear program,Conic program,

@&#ABSTRACT@&#
In this paper, we review recent advances in the distributional analysis of mixed integer linear programs with random objective coefficients. Suppose that the probability distribution of the objective coefficients is incompletely specified and characterized through partial moment information. Conic programming methods have been recently used to find distributionally robust bounds for the expected optimal value of mixed integer linear programs over the set of all distributions with the given moment information. These methods also provide additional information on the probability that a binary variable attains a value of 1 in the optimal solution for 0–1 integer linear programs. This probability is defined as the persistency of a binary variable. In this paper, we provide an overview of the complexity results for these models, conic programming formulations that are readily implementable with standard solvers and important applications of persistency models. The main message that we hope to convey through this review is that tools of conic programming provide important insights in the probabilistic analysis of discrete optimization problems. These tools lead to distributionally robust bounds with applications in activity networks, vertex packing, discrete choice models, random walks and sequencing problems, and newsvendor problems.

@&#INTRODUCTION@&#
Consider a mixed 0–1 linear program (LP) in maximization form,(1)Z(c)=max{cTx:x∈X},where the feasible region is described as(2)X=x∈Rn+:ajTx=bj,∀j=1,…,m;xi∈{0,1},∀i∈B⊆{1,…,n}.The set of decision variables {1,…,n} includes 0–1 decision variables indexed by the setBand nonnegative decision variables indexed by{1,…,n}⧹B. The class of mixed 0–1 linear programs has been used extensively in business, engineering, and economic applications, to model diverse types of problems arising from production planning, logistics deployment, scheduling of jobs and machines, among others. However, in practice, the input parameters (i.e.c,aj, bj) are often not known with certainty, and need to be estimated in the modeling process. Since the optimal solution is sometimes very sensitive to the input parameters, one needs to be careful in modeling the uncertainty in these problems. In this review, we focus ourselves on the uncertainty inside the objective coefficient vector,c.Formally, the problem of interest is:Given the mixed 0–1 linear program in (1) and a probability measure θ for the random objective coefficient vectorc, compute the expected optimal value, i.e.,(MEAN)Eθ(Z(c))=∫Z(c)dθ(c).Clearly, computing MEAN is at least as hard as solving the deterministic mixed 0–1 linear program. MEAN is computable in time polynomial in the size of the instance1Here, the “instance” refers to the problem input string that encodes all the necessary parameters of the optimization problem, Z(c), and all the support points ofc.1when the deterministic problem is solvable in polynomial time and θ is a discrete distribution with a polynomial number of support points. However, for general distributions, the computation of MEAN is significantly more challenging than solving the deterministic problem. An example is the problem of finding the longest path on a directed acyclic graph. The deterministic version of this problem is to find a longest path between a source node s and a sink node t in a directed acyclic graphG(V,E)whereVis the set of vertices,Eis the set of edges with associated arc lengths cijfor each arc(i,j)∈E. The longest path problem (LPP) is formulated as the following 0–1 integer linear program,ZLPP(c)=max∑(i,j)∈Ecijxij:∑j:(i,j)∈Exij-∑j:(j,i)∈Exji=bi,∀i∈V;xij∈{0,1},∀(i,j)∈E,where biis defined to be 1 for i=s, −1 for i=t and 0 otherwise. For a fixedc, ZLPP(c) is computable in polynomial time. The linear programming relaxation solves the integer program in this case. The complexity of computing E(ZLPP(c)) for independent discrete distributions was resolved by Hagstrom (1988).Theorem 1Hagstrom (1988)For a directed acyclic graph with arc lengths that are independently distributed and restricted to taking two possible values each, computing the expected value of the longest path is#P-complete. Furthermore it cannot be computed in time polynomial in the number of points in the range of the longest path unlessP=NP.Roughly speaking, the difficulty stems from the observation that an exponential number of support points for the multivariate independent discrete distribution can be supported by an exponential number of optimal solutions. The difficulty of this problem has led to the development of methods such as Monte Carlo simulations (Bowman, 1995; Van Slyke, 1963), PERT approximations (Malcolm, Roseboom, Clark, & Fazar, 1959), exact methods in special instances such as series–parallel graphs (Möhring, 2001) and upper and lower bounds on the expected longest path (Dodin, 1985; Fulkerson, 1962; Kleindorfer, 1971).Explicit formulas for the expected optimal value have been developed in the asymptotic analysis of random combinatorial optimization problems. This area has its roots in the pioneering work of Beardwood, Halton, and Hammersley (1959) who characterized the asymptotic behavior of a traveling salesperson tour length for points randomly generated on the Euclidean plane. The book by Steele (1997) provides an introduction to the asymptotic analysis of combinatorial optimization problems under the Euclidean model. More closely related to the theme of this paper is the probabilistic analysis of combinatorial optimization problems under the mean field model. In the mean field model, the nodes of a graph are assumed to be fixed while the arc lengths are independently chosen from a probability distribution. The arc lengths need not satisfy the triangle inequality. The origins of this model lies in an early paper of Karp (1979) who analyzed the asymmetric traveling salesperson problem and its linear assignment relaxation for distances drawn independently from an uniform distribution in [0,1]. The linear assignment problem (LAP) is formulated asZLAP(c)=min∑i=1n∑j=1ncijxij:∑i=1nxij=1,∀j=1,…,n;∑j=1nxij=1,∀i=1,…,n;xij∈{0,1},∀i,j=1,…,n.Explicit asymptotic expressions for the expected value of the assignment problem under random costs have been developed for uniform and exponential distributions by several authors (see Krokhmal and Pardalos (2009) for a review on this topic). Aldous (2001) in 2001 rigorously proved the following result which was initially conjectured by Mézard and Parisi (1985) in 1985 using ideas in statistical physics.Theorem 2Aldous (2001)Let the random variables cijfor i, j=1,…,n be independent with uniform distribution on [0,1] or exponentially distributed with parameter 1. Thenlimn→∞E(ZLAP(c))=ζ(2)=π26≈1.645.Asymptotic expressions for the expected value of other combinatorial optimization problems have since been developed under the mean-field model (see Aldous & Steele (2003)). However, explicit formulas for finite size instances of combinatorial optimization problems are much more difficult to obtain. One such formula that was conjectured by Parisi in 1998 (Parisi, 1998) and recently proved by two sets of authors is provided next.Theorem 3Linusson and Wästlund (2004) and Nair, Prabhakar, and Sharma (2005)Let the random variables cijfor i, j=1,…,n be independent and exponentially distributed with parameter 1. ThenE(ZLAP(c))=∑i=1n1i2.While this result is elegant and surprising, the techniques in its proof is typically difficult to use for the analysis of general discrete optimization problems with non-identical, or non-independently distributed uncertainties. In this paper, we review an alternate approach for the probabilistic analysis of discrete optimization problems that relaxes the assumption of independence. Instead of fixing the joint distribution of the random parameters, we allow for the joint distribution to be incompletely specified by the partial moment information. Surprisingly, the probabilistic analysis of the problem becomes tractable for a wide class of mixed integer linear programs, under appropriate assumptions of the input distributions. The moment information can be viewed as imposing boundary conditions on the way the scenarios of the extremal distribution are generated so as to guard against extremely unrealistic distributions.In Section 2, the central problem of finding the tight bound on the expected optimal value of a mixed 0–1 linear program is introduced. The formal characterization of the set of probability distributions using the theory of moments is provided in this section. The notion of persistency – the probability that a binary variable attains a value of 1 in the optimal solution is also discussed in this section. In Section 3, conic programming methods to compute the bounds and estimate persistency are reviewed. Polynomial time computable bounds and bounds that areNP-hard to compute are identified in this section. In Section 4, we review applications of this approach in activity networks, vertex packing discrete choice models, random walk and sequencing problems, and newsvendor problems. We conclude in Section 5.Throughout the paper, standard letters such as x denote scalars, bold letters such asxdenote vectors, bold capital letters such asXdenote matrices and calligraphic fonts such asXdenotes sets. The notation c+ represents max(0, c). The transpose of a column vectorcis denoted ascT. For two vectorsxandyof dimension n,xTydenotes x1y1+⋯+xnyn, andx∘ydenotes the column vector (x1y1,…,xnyn)T. The setSndenotes the set of n×n symmetric matrices equipped with the standard inner productA·B=∑i=1n∑j=1nAijBij. The vectorehas all components equal to one, and the vectoreihas 1 in its ith component and 0 otherwise. The cone of n×n nonnegative matrices is defined asNn={A∈Sn:A⩾0}. The cone of n×n positive semidefinite matrices is defined asSn+=A∈Sn:vTAv⩾0,∀v∈Rn. The cone of n×n copositive matrices is defined asCOn=A∈Sn:vTAv⩾0,∀v∈Rn+. The cone of n×n completely positive matrices is defined asCPn=A∈Sn:∃v1,v2,…,vk∈Rn+suchthatA=∑i=1kviviT. For a coneK, the dual cone is defined asK∗={A:A·B⩾0,∀B∈K}. The nonnegative and positive semidefinite cones are self–dual while the copositive and completely positive cones are duals of each other. Namely,(Nn)∗=Nn,Sn+∗=Sn+and(COn)∗=CPn. The closure of a coneKis denoted asK¯and the interior is denoted asInt(K). The convex hull of a setKis given asconv(K).Suppose the exact probability distribution θ of the parameters is unknown. Rather, θ is only known to lie in the set of probability distributions Θ. Formally, the central problem of interest is:Given the mixed 0–1 linear program in maximization form in (1) and a nonempty set of probability measures Θ for the random objective coefficient vectorc, compute the tightest upper bound on the expected optimal value, i.e.,(MEAN-UB)Z=supθ∈ΘEθ(Z(c))=supθ∈Θ∫Z(c)dθ(c).We discuss a few important aspects of this problem next:(a)The most commonly used model in the probabilistic analysis of optimization problems is the independent distribution model. However, modeling data as independent random variables is sometimes unrealistic. For example, in supply chain networks one often needs to deal with correlated demands, and in activity networks one needs to deal with correlated activity durations due to resource dependencies. By dropping the explicit assumption of independence in the description of Θ, it is possible to capture the effect of dependencies.The upper bound of interest is valid across all distributions in the set Θ and is as tight as possible. Tightness implies that either there exists a feasible distribution that attains the upper bound exactly or there exists a sequence of distributions that attains the bound and is feasible in a limiting sense. Hence, this bound is termed as a distributionally robust bound. For the longest path problem on directed acyclic graphs with random arc lengths as arising in activity networks, the upper bound corresponds to a worst-case expected project completion time. For the maximum flow problem with random arc capacities, the upper bound corresponds to the worst-case expected maximum flow that is supported by the network. While MEAN-UB deals with upper bounds for maximization problems, by simply replacingcwith −ctransforms the bounds to lower bounds on minimization problems.Under reasonable assumptions on the set of distributions Θ, the tight bound turns out to be efficiently computable with convex conic programming. In instances where the tight bound is not efficiently computable, conic programming relaxations provide weaker upper bounds. An example of a bound on the expected optimal value of a discrete optimization problem through convex quadratic programming is the following elegant result of Lyons, Pemantle, and Peres (1999) and Lovász (2001).Let Θ be the set of distributions for a nonnegative random vectorcwhose joint survival function S(t1,…,tn)=P(c1⩾t1,…,cn⩾tn) is log-concave.(a)SupposeXis the feasible region for a shortest s-t path problem, minimum s-t cut problem or minimum linear assignment problem. Theninfθ∈ΘEθminx∈XcTx⩾minx∈conv(X)∑i=1nE(ci)xi2.The lower bound in (a) is tight for the setX=x∈Rn+:eTx=1,xi∈{0,1}∀i=1,…,n. The bound is attained by independent exponential random variables, i.e.,minθ∈ΘEθmini=1,…,nci=∑i=1n1E(ci)-1.The bound in Theorem 4(a) is the optimal value to a separable convex quadratic minimization problem over 0–1 polytopes and efficiently computable. This result implies that for independent exponentially distributed random edge lengths in an undirected graph, the expected length of the shortest path between any two nodes is bounded from below by the resistance between the nodes, where the resistance of an edge is defined as the expectation of its length. While the lower bound in Theorem 4(a) is not tight in general (see Example 5, p. 372 in Lovász (2001) for a counterexample), Theorem 4(b) identifies a particular instance where the bound is tight. The models discussed in Section 3 provide tight bounds for general mixed integer linear programs using conic optimization. A formal description of the set of distributions Θ based on the theory of moments is provided next.A simple and popular characterization of the set of distributions Θ is based on only the first two moments – the mean and covariance matrix. Let Ω be a given subset ofRn. DefineM(Ω)+to be the space of finite positive Borel measures defined on the domain Ω. The set of probability measures with first moment vectorμand second moment matrix Π is defined as(3)Θ=θ∈M(Ω)+:1=∫Ωdθ(c),μ=∫Ωcdθ(c),Π=∫ΩccTdθ(c).Under this description, the distributional robust bound is found by solving the generalized moment problem,(4)(MEAN-UB)Z=supθ∈M(Ω)+∫ΩZ(c)dθ(c)s.t.∫Ωdθ(c)=1,∫Ωcdθ(c)=μ,∫ΩccTdθ(c)=Π.For an in-depth discussion of the moment problem, the reader is referred to the classic book of Karlin and Studden (1966). A more recent algorithmic exposition on the moment problem using conic programming is found in the book of Lasserre (2009). We review the results from this theory of moments that are particularly relevant to this paper.The moment feasibility problem characterizes necessary and sufficient conditions that the moments must satisfy so that the set of distributions Θ as defined in (3) is nonempty. Towards this, define the moment cone of order 2 supported onΩ⊆Rnas2The definition of the moment cone based on symmetric matrices inSn+1is a slight modification of the definition from the literature (cf. Karlin & Studden, 1966; Lasserre, 2009) that uses vector notation inR(n+1)(n+2)/2.2M2(Ω)=λ1μTμΠ∈Sn+1:λ⩾0;1=∫Ωdθ(c),μ=∫Ωcdθ(c),Π=∫ΩccTdθ(c),forsomeθ∈M(Ω)+.From the theory of moments, the dual of this moment cone is the cone of all non-homogeneous quadratic polynomials that is nonnegative over Ω and defined byP2(Ω)=M2(Ω)∗=w0wT/2w/2W∈Sn+1:w0+wTc+cTWc⩾0,∀c∈Ω.The dual of the cone of nonnegative polynomials is the closure of the moment cone, namelyP2(Ω)∗=M2(Ω)¯. The dual of the moment problem in (4) is hence formulated as:(5)ZD=infwo,w,Ww0+wTμ+W·Πs.t.w0+wTc+cTWc⩾Z(c)∀c∈Ω,wherew0∈R,w∈RnandW∈Sn. Problems (4) and (5) are related through conic duality.Theorem 5Karlin and Studden (1966) and Lasserre (2009)(a)Weak duality: The optimal primal and dual objective satisfy Z⩽ZD.Strong duality: If the moments lie in the interior of the moment cone, i.e.,1μTμΠ∈Int(M2(Ω)),then the optimal primal and dual objectives are equal and satisfy Z=ZD.Alternate conditions to guarantee strong duality for the moment problem have also been identified in the literature (see Zuluaga & Pena (2005) and Shapiro (2001) for some examples). The primary method to compute Z and ZDuses convex conic programming techniques such as linear and semidefinite programming. The connection between the cone of moments, the cone of nonnegative quadratic polynomials and the semidefinite cone is provided in the next theorem for the domainΩ=RnandΩ=Rn+.Theorem 6Karlin and Studden (1966) and Kemperman and Skibinsky (1992)(a)ForΩ=Rn, the following cones are equivalent,1μTμΠ∈M2(Rn)¯⇔1μTμΠ∈Sn+1+,w0wT/2w/2W∈P2(Rn)⇔w0wT/2w/2W∈Sn+1+.ForΩ=Rn+, the following cones are equivalent,1μTμΠ∈M2Rn+¯⇔1μTμΠ∈CPn+1,w0wT/2w/2W∈P2(Rn+)⇔w0wT/2w/2W∈COn+1.Theorem 6(a) is from Karlin and Studden (1966). Essentially, forΩ=Rn, testing feasibility in the conesM2(Ω)¯andP2(Ω)are easy since these are equivalent to testing the positive semidefiniteness of a symmetric matrix. Theorem 6(b) is from Kemperman and Skibinsky (1992). ForΩ=Rn+, testing feasibility inM2(Ω)¯is equivalent to verifying if a matrix is completely positive, and testing feasibility inP2(Ω)is equivalent to verifying if a matrix is copositive. For a detailed introduction to completely positive matrices, the reader is referred to the book of Berman and Shaked-Monderer (2003). Three recent surveys on completely positive and copositive matrices with emphasis on optimization are found in Bomze (2012), Dür (2010) and Hiriart-Urruty and Seeger (2010). Unlike the positive semidefinite cone, testing feasibility in the completely positive and copositive cones are known to be difficult. For instance, Murty and Kabadi (1987) showed that the problem of verifying if a given matrix is copositive is co-NP-complete. A popular relaxation to the completely positive cone is the doubly nonnegative cone which is defined as the intersection of the positive semidefinite and the nonnegative cone. The following well-known relationship holds among these cones,CPn⊆Sn+∩Nn⊂Sn++Nn⊆COn.Equality holds for the leftmost and rightmost inclusion only for n⩽4 from a result of Diananda (1962). To obtain better approximations to the completely positive and copositive cones, hierarchies of convex cones based on positive semidefinite and nonnegative cones have been developed by several researchers (see Parillo (2000), Lasserre (2001), Bomze & de Klerk (2002), Laurent (2003), & Zuluaga & Pena (2005) for details on these hierarchies). While these hierarchies of cones converge to the completely positive and copositive cones asymptotically, the size of the formulations grow so rapidly that the higher order approximations are intractable from a computational viewpoint. The conic representations in Theorem 6 are extendable to arbitrary setsΩ⊆Rnby using a generalized notion of complete positivity and copositivity over the domain Ω (see Kemperman & Skibinsky (1992) and Sturm & Zhang (2003)).A related parameter in the analysis of optimization problems under uncertainty is the distribution of the optimal decision vector. Define the mappingXopt(c)as the set of all optimal solutions for a givenc,(6)Xopt(c)=x∈X:cTx⩾cTy,∀y∈X.The number of solutions inXopt(c)could be one or many depending on the uniqueness of the optimal solution. For continuous distributions such as the multivariate normal distribution with a positive definite covariance matrix, the probability measure of the support over which there are multiple optimal solutions is zero. This however need not be the case for discrete distributions. For a random vectorc, any optimal solutionx(c)∈Xopt(c)is a random vector. Bertsimas, Natarajan, and Teo (2006) proposed a definition of persistency for combinatorial optimization problems based on the components of the random vectorx(c).Definition 1Bertsimas et al. (2006)The persistency of the binary variable xiis defined as the probability that xitakes the value of 1 in some optimal solution, i.e.,Persistencyofbinaryvariablexi=P(xi(c)=1,forsomex(c)∈Xopt(c))=P(Z(c)=maxx∈X:xi=1cTx).For activity networks, “persistency” is equivalent to the concept of the “criticality index” of an activity. A criticality index of an activity measures the probability that an activity is on the longest path in an activity network. A higher criticality index roughly indicates higher importance of that activity in the successful completion of the project on time. Criticality indices have been previously estimated using simulations (Bowman, 1995; Van Slyke, 1963) and approximations (Dodin & Elmaghraby, 1985). The conic optimization methods discussed in the next section provide an alternate method to estimate the persistency of a binary variable.It is important to point out that an alternate definition of “persistency” for deterministic 0–1 optimization problems has been previously proposed. Adams, Lassiter, and Sherali (1998) and Hammer, Hansen, and Simeone (1984) define an optimal solution to the continuous relaxation of a mixed 0–1 linear program to be persistent if the set of 0–1 variables realizing binary values in the continuous relaxation retain those same binary values in at least one integer optimum. A mixed 0–1 linear program possesses the persistency property if every optimal solution to the continuous relaxation is a persistent solution. Weighted vertex packing is the first example of a combinatorial optimization problem that is shown to possess the persistency property (see Nemhauser & Trotter (1975)). The persistency property has also been identified in unconstrained quadratic 0–1 optimization by Hammer et al. (1984), unconstrained polynomial 0–1 optimization by Lu and Williams (1987), and integer programs with at most two variables per inequality by Hochbaum, Megiddo, Naor, and Tamir (1993). The motivation of identifying the persistency property in this line of research is to reduce the computational time to solve deterministic mixed 0–1 linear programs. This is done through a preprocessing step that solves the continuous relaxation first and fixes the persistent variables to their respective binary values. The reduction in the search space then provides computational benefits in the second step where either the optimal solution or near-optimal solution is found through exact methods or heuristics. Definition 1 of persistency has a similar motivation of helping identify variables that often take a value of 1 in the optimal solution. The main distinction is that while Definition 1 is for the stochastic 0–1 optimization problem, the earlier definition was for the deterministic 0–1 optimization problem.There is a vast literature on moment bounds in areas such as inventory control (Scarf, 1958), queueing systems (Whitt, 1984), finance (Bertsimas & Popescu, 2002; Boyle & Lin, 1997), decision theory (Smith, 1995), activity networks (Birge & Maddox, 1995) and probability and statistics (Lasserre, 2002; Marshall & Olkin, 1960; Vandenberghe, Boyd, & Comanor, 2007). In this section, we review conic optimization based methods to compute MEAN-UB and the corresponding complexity of obtaining the bounds. The following generic “primal” proof technique is adopted in developing the conic programs to compute MEAN-UB:(a)Define the “appropriate” decision variables using moments of the objective coefficient vectorcand the optimal solution vectorx(c).Identify necessary constraints that these variables must satisfy for all distributions in Θ. Express the objective function in terms of the decision variables and find a upper bound on the expected value of Z(c) using conic optimization.Show that the constraints are sufficient by constructing a distribution (or a sequence of distributions) in Θ that attains the upper bound (in a limiting sense). We outline steps (a) and (b) in this section to provide a flavor of the proof technique. The tightness argument of step (c) is found in the specific references. It is also possible to derive these results through an alternative dual approach (see (Bertsimas & Popescu, 2002; Karlin & Studden, 1966; Marshall & Olkin, 1960)).To develop the conic programs to compute MEAN-UB, we make use of three different moment representations for the set of distributions Θ:(a)Cross moments: Given cross moment information that includes the means and covariances, we show that the distributionally robust bound isNP-hard in general. We provide two different conic programming approaches in Section 3.1. The first approach uses a complete enumeration of the extreme points to construct the SDP formulation, whereas the second approach uses the constraint formulation to derive a completely positive conic program for this problem. Both approaches are exact as there are extremal distributions that match the bound.Marginal moments: Given univariate marginal moment information that includes the means and variances, we show that the distributionally robust bound is computationally tractable if the deterministic 0–1 linear program is solvable in polynomial time. In this moment representation, no assumption on the dependency among the random variables is made. We describe the convex formulation for these models in Section 3.2.Nonoverlapping multivariate marginal moments: We conclude by discussing a hybrid approach in Section 3.3, that uses nonoverlapping marginal multivariate information to compute the distributionally robust bound. In this hybrid approach, the random objective coefficients are partitioned into several subsets, and cross moment information for each of the subsets is assumed to be known. However, the dependence structure across different subsets is unknown. A natural application of this approach is in activity networks.Table 1provides a summary of the key results from this section.Computing the bound on the expected optimal value with mean and covariance information is unfortunatelyNP-hard even for the class of polynomial time solvable mixed integer linear programs. The complexity result is formally described in the next theorem.Theorem 7Bertsimas and Popescu (2002) and Bertsimas, Doan, Natarajan, and Teo (2010)(i)ForΩ=Rn+, computingMEAN-UBwith mean and covariance information isNP-hard even when Z(c)=cTxis just a linear function onc.ForΩ=Rn, computingMEAN-UBwith mean and covariance information isNP-hard even for linear programs.The key step that is used to prove the hardness results in Theorem 7 is to show that the separation version of the dual problem isNP-hard. Then from the equivalence of separation and optimization (see Grötschel, Lovász, & Schrijver (1988)), Theorem 7 follows. The separation version of the dual problem is:Given a function Z(·), a setΩ, a scalarw0∈R, a vectorw∈Rnand a matrixW∈Sn+, verify if w0+wTc+cTWc⩾Z(c), for allc∈Ω. Otherwise, find a violated inequality.The separation problem is difficult forΩ=Rn+since it is equivalent to testing if a matrix is copositive (see Murty & Kabadi (1987)). ForΩ=Rn, the separation problem is easy when Z(c) is given by the maximum of a polynomial number of linear functions. However, Bertsimas et al. (2010) showed that the separation problem isNP-hard when Z(c) is the optimal objective value to a linear program where Z(c) is given by the maximum of a exponential number of linear functions. The result is proved by a reduction from the two norm maximization problem over a polytope, which was shown to beNP-hard by Mangasarian and Shiau (1986). We now discuss conic programming formulations and relaxations for theseNP-hard problems.In this section, we discuss an explicit conic program to compute MEAN-UB given a vertex representation of the convex hull of the feasible region for the mixed integer linear program. Let(7)conv(X)=∑k=1Kλkx(k):∑k=1Kλk=1;λk⩾0,x(k)∈X,∀k=1,…,K,wherex(k)’s represent the vertices of the convex hull. Then Z(c) can be evaluated using the vertex based formulation, i.e.,(8)Z(c)=max∑k=1KλkcTx(k):∑k=1Kλk=1;λk⩾0,∀k=1,…,K.Note that in general the number of vertices K is exponential in the size of the problem.Theorem 8Bertsimas and Popescu (2002), Bertsimas et al. (2010), Zuluaga and Pena (2005), Mishra, Natarajan, Tao, and Teo (2012)For the vertex based formulation in(8)with mean and covariance information,MEAN-UBis computed by solving the conic optimization problem:(9)Z=maxλk,wk,Wk,k=1,…,K∑k=1KwkTx(k)s.t.∑k=1KλkwkTwkWk=1μTμΠλkwkT,wkWk∈M2(Ω)¯∀k=1,…,K.Step (a): The decision variables in formulation (9) are defined as the scaled conditional moments,λk=P(x(c)=x(k)),wk=E(c|x(c)=x(k))P(x(c)=x(k)),Wk=E(ccT|x(c)=x(k))P(x(c)=x(k)).Step (b): The objective function is expressed as the weighted sum of conditional moments,E(Z(c))=E(cTx(c))=∑k=1KE(cTx(k)|x(c)=x(k))P(x(c)=x(k))=∑k=1KwkTx(k).A natural implication of this result is that forΩ=Rnwith the number of vertices K polynomially bounded in n, MEAN-UB is computable in polynomial time by solving the semidefinite program in Theorem 8. This problem was first studied by Boyle and Lin (1997) for an option pricing problem with Z(c)=(maxici−k)+ where k is the strike price and the option payoff is determined by the maximum of asset prices. Delage and Ye (2010) extended this result by relaxing the assumption on the exact knowledge of the two moments and incorporating additional support information. In their model, the set of distributions is defined with a compact convex support Ω, meanμand second moment matrix bounded from above in the positive semidefinite order by Π, i.e.,(10)Θ=θ∈M(Ω)+:1=∫Ωdθ(c),μ=∫Ωcdθ(c),Π⪰∫ΩccTdθ(c).Delage and Ye (2010) showed that with the number of vertices K polynomially bounded in n, MEAN-UB is computable in polynomial time for the set of distributions defined in (10) under reasonable assumptions on the convex set Ω.Theorem 8 is useful when the number of vertices K of the feasible region is not too large. However, K is often exponential in the size of the problem. The next theorem provides a completely positive program to compute MEAN-UB for mixed 0–1 linear programs using a constraint based representation. In this part, we work on the original constraint based formulation of Z(c) as defined in (1) and (2). The constraint based formulation is derived using an interesting result of Burer (2009) who showed that any mixed 0–1 linear program with a mixture of binary and continuous variables can be formulated as a completely positive program. Natarajan, Teo, and Zheng (2011) extended this result to mixed 0–1 linear programs under objective uncertainty by formulating a completely positive cross moment model (CPCMM).Theorem 9Natarajan et al. (2011)For the class of mixed 0–1 linear programs with mean and covariance information,MEAN-UBis computed by solving the following completely positive program,(11)Z=maxx,X,Y∑i=1nYiis.t.ajTx=bj∀j=1,…,m,ajTXaj=bj2∀j=1,…,m,Xii=xi∀i∈B⊆{1,…,n},1μTxTμΠYTxYX∈M2Ω×Rn+¯.Step (a): The decision variables in this formulation are defined asx=E(x(c)),Y=E(x(c)cT),X=E(x(c)x(c)T).Step (b): The objective function is expressed asE(Z(c))=∑i=1nE(cixi(c))=∑i=1nYii.The constraint based formulation in Theorem 9 uses the first two moments of the random vectorcand the random optimal solution vectorx(c) as decision variables,(1,E(c),E(x(c)),E(ccT),E(cx(c)T),E(x(c)x(c)T)).By allowing for higher order moments, Lasserre (2010) has generalized the approach to the class of parametric polynomial optimization problems which includes mixed 0–1 linear programs as a special case. Note that binary variables can be modeled in polynomial optimization problems with constraints of the formxi2=xi. The parametric optimization problem studied in Lasserre (2010) is of the form,(13)Z(ξ)=max{f(ξ,x):fj(ξ,x)⩾0,∀j=1,…,m},whereξis a random parameter vector that lies in a compact set Ω with a probability measure θ, andxis the decision vector. Define the setK={(ξ,x):ξ∈Ω,fj(ξ,x)⩾0,∀j=1,…,m}.Let φ denote the joint probability measure on the random vector (ξ,x(ξ)), wherex(ξ) is an optimal solution for a fixedξ. Lasserre (2010) defined the infinite dimensional linear program over the measure φ as(14)supφ∈M(K)+∫Kfdφs.t.projΩφ=θ,where projΩφ denotes the projection of φ on the set Ω. This formulation is referred to as a “joint+marginal” formulation since φ is a joint probability measure on the parameters and optimal solutions while θ is the given probability measure on the parameters. Under appropriate compactness conditions on the feasible region (see Lasserre (2010)), the optimal objective value to (14) is exactly Eθ(Z(ξ)). To solve the infinite dimensional linear program for polynomial functions f(·) and fj(·), Lasserre proposed a hierarchy of semidefinite relaxations that is based on the theory of moments. The optimal objective value to the sequence of semidefinite relaxations converges in the limit to Eθ(Z(ξ)). The attractiveness of this technique is that it is general purpose since it can handle uncertainty in the objective and constraints and is applicable to the class of polynomial optimization problems. However the size of the semidefinite relaxation grows rapidly which makes solving the higher order semidefinite relaxations numerically challenging. In the remaining part of this section, we review sets of distributions Θ where the distributionally robust bound can be found in polynomial time using conic optimization.Suppose that the support space Ωifor each random variable cialong with the mean E(ci)=μiand the second momentEci2=Πiis known. The variance of ciis denoted byσi2. However, the dependence structure among the different random variables is unknown. Let θi=projiθ denote the projection of the multivariate measure θ to the ith random variable ci. The marginal moment representation of the set of distributions isΘ=θ∈M(Ω1×…×Ωn)+:1=∫Ωidθi(ci),μi=∫Ωicidθi(ci),Πi=∫Ωici2dθi(ci),∀i=1,…,n.The upper bound on the expected optimal value with mean and variance information is formulated as(15)Z=supθ∈M(Ω1×…×Ωn)+∫Ω1×…×ΩnZ(c)dθ(c)s.t.∫Ωi1dθi(ci)=1∀i=1,…,n,∫Ωicidθi(ci)=μi∀i=1,…,n,∫Ωici2dθi(ci)=Πi∀i=1,…,n.Moment feasibility in this instance is equivalent to the feasibility of univariate moment sequences. This condition is obviously necessary. Sufficiency follows by constructing a feasible joint measure using the independent distribution. Testing moment feasibility is thus easy for the marginal moment model for bothΩi=RandR+. The next theorem provides a conic programming formulation for the class of 0–1 linear programs, i.e.,X=x∈Rn+:ajTx=bj,∀j=1,…,m;xi∈{0,1},∀i∈{1,…,n}.Theorem 10Bertsimas et al. (2006) and Natarajan, Song, and Teo (2009)(i)For the class of 0–1 linear programs with mean and variance information,MEAN-UBin(15)is computed by solving the following conic optimization problem,(16)Z=maxx,y,z∑i=1nyis.t.x∈conv(X),xiyiyizi,1-xiμi-yiμi-yiΠi-zi∈M2(Ωi)¯∀i=1,…,n.ForΩ=Rn, formulation(16)reduces to the second-order cone program,(17)Z=maxx∈conv(X)∑i=1nμixi+σixi(1-xi).Z is computable in polynomial time for a 0–1 linear program with a compact convex hull.Step (a): The decision variables in formulation (16) are defined asxi=P(xi(c)=1),yi=E(cixi(c))=E(ci|xi(c)=1)P(xi(c)=1),zi=Eci2xi(c)=Eci2|xi(c)=1P(xi(c)=1).Step (b): The objective function is expressed in terms of the decision variables asE(Z(c))=∑i=1nE(ci|xi(c)=1)P(xi(c)=1)=∑i=1nyi.A dual representation of this conic program in Theorem 10 is discussed in Klein Haneveld (1986), Birge and Maddox (1995) and Bertsimas, Natarajan, and Teo (2004). The key implication of Theorem 10 is that MEAN-UB can be found in polynomial time for supports such asΩ=RnandΩ=Rn+for the class of 0–1 linear programs with a compact convex hull representation. This provides tight bounds for combinatorial optimization problems such as the shortest path, linear assignment, and spanning tree problems.The marginal moment model has been extended to general integer programs by Natarajan et al. (2009) with a binary reformulation. Assume that the deterministic integer program with nonnegative integer variables is formulated asZ(c)=maxcTx:∑i=1najixi=bj,∀j=1,…,m;xi∈Xi,∀i=1,…,n,where the setXiconsists of nonnegative integer values from αito βi:Xi={αi,αi+1,…,βi-1,βi}⊆Z+.Defining binary variables yikfork∈Xi,i=1,…,n, the binary expansion of the feasible region is given asY=y:∑i=1n∑k∈Xiajikyik=bj,∀j=1,…,m;∑k∈Xiyik=1,∀i=1,…,n;yik∈{0,1},∀k∈Xi,∀i=1,…,n.There is a unique one to one correspondence between the extreme points of the original feasible region and the binary reformulationY, namely xi=k if and only if yik=1. Based on this, Natarajan et al. (2009) provided a second-order cone program for integer programs with mean and variance information forΩ=Rn.Theorem 11Natarajan et al. (2009)For the class of integer programs with mean and variance information andΩ=Rn,MEAN-UBin(15)is computed by solving the following second-order cone program,(18)Z=max∑i=1nμi∑k∈Xikyik+σi∑k∈Xik2yik-∑k∈Xikyik2:y∈conv(Y).Finding a bound on a function of multiple random variables given only the probability measures of the individual random variables has its origins in the Monge (1781) and Kantorovich (1958) formulation for mass transportation problems. The reader is referred to the book of Rachev and Rüschendorf (1998) for a historical account of this problem. The upper bound on the expected optimal value with given marginal distributions is formulated as(19)Z=supθ∈M(Ω1×…×Ωn)+∫Ω1×…×ΩnZ(c1,…,cn)dθ(c)s.t.projΩiθ=θi∀i=1,…,n.Meilijson and Nadas (1979) solved this problem in a combinatorial optimization setting by estimating an upper bound on the expected longest path in a directed acyclic graph given marginal distributions of the arc lengths. Their motivation was to find the worst case expected project completion time in an activity network across all joint distributions of activity durations that are consistent with the marginal distributions. This bound is thus robust against dependence. Weiss (1986) generalized this bound to combinatorial optimization problems such as the maximum flow, shortest route and reliability problems. The formulation in Meilijson and Nadas (1979) and Weiss (1986) is derived from a dual convex minimization formulation.Theorem 12Meilijson and Nadas (1979)For 0–1 linear programs with given marginal distributions,MEAN-UBin(19)is computed by solving the following convex minimization problem,(20)Z=infdZ(d)+∑i=1nEθi(ci-di)+.Natarajan et al. (2009) provided a primal approach to compute this bound for continuous marginal distributions.Theorem 13Natarajan et al. (2009)For 0–1 linear programs with continuous marginal distributions ci∼Fi(·),MEAN-UBin(19)is computed by solving the following concave maximization problem,(21)Z=supx∈conv(X)∑i=1n∫1-xi1Fi-1(t)dt.In the next example, we compare the probabilistic bounds for combinatorial optimization problems given marginal distributions with and without the assumption of independence.ExampleProbabilistic analysis of combinatorial optimization problems.Bertsimas et al. (2004) applied the marginal distribution model to find the expected value of combinatorial optimization problems when the assumption of independence among the random costs is dropped. For the linear assignment problem with random costs identically distributed cij∼F(·), the tight lower bound on the expected optimal value is found by solving the following convex minimization problem,Let the random variables cijfor i, j=1,…,n be identically distributed with density function f(·) and distribution function F(·). ThenZLAP=n2∫0F-1(1/n)cf(c)dc.A comparison of the bound in Theorem 14 with results for the independence model is provided next:(a)For the uniform distribution in [0,1], the lower bound in Theorem 14 is ZLAP=1/2. This lower bound is tight for all n. Namely there exists a joint distribution with uniform marginals that attains this bound for each n. In contrast under the assumption of independence, only the explicit asymptotic limit limn→∞E(ZLAP(c))=π2/6 is known.For the exponential distribution with parameter 1, the lower bound is ZLAP=n+n(n−1) ln(1−1/n), while under independenceE(ZLAP(c))=∑i=1n1/i2.As highlighted by these examples, the extremal distributions under the marginal distribution model provide new and non-trivial limits on the asymptotic behavior of optimization problems. It is interesting to compare the proof technique for the marginal distribution model with that of the independence model. The proof of the former model is based on convex optimization, while for the later model, the proof is based on sophisticated probabilistic techniques (see Aldous, 2001).Doan and Natarajan (2011) recently developed the bound MEAN-UB for a set of distributions Θ that lies between the two extremes of the cross moment and marginal moment information. In this distribution model, the random objective coefficients are assumed to be partitioned into subsets with information on the moments of the random parameters in each subset. The dependence structure between any random parameters for different subsets is assumed to be unknown. To describe the formulation, we use the example of activity networks. In the directed acyclic graph representation of an activity network, a natural partition is formed by the set of arcs (activities) entering each node. Definecj=(cij)i:(i,j)∈Eto be the sub-vector of random arc lengths for the arcs entering nodej∈V, where n is the total number of nodes in the graph. Denote the dimension ofcjas nj. Suppose that the support Ωjfor each random sub-vectorcjalong with the mean E(cj)=μjand the second moment matrixEcjcjT=Πjis known. For example, in projects where different teams are responsible for the set of activities entering different nodes, it is reasonable to assume that each team is knowledgeable about the joint distribution of the activities for which they are responsible. The project manager is interested in evaluating the worst-case expected project completion time that is compatible with these factors. The correlation among the arc lengths cijand cklentering two different nodes j and l is unknown under this model. Let θjdenote the projection of the measure θ for the random sub-vectorcj. The upper bound on the expected longest path with nonoverlapping mean, variance and covariance information is formulated as(22)ZLPP=supθ∈M(Ω1×…×Ωn)+∫Ω1×…×ΩnZLPP(c1,…,cn)dθ(c)s.t.∫Ωj1dθj(cj)=1∀j∈V,∫Ωjcjdθj(cj)=μj∀j∈V,∫ΩjcjcjTdθj(cj)=Πj∀j∈V.Theorem 15For the longest path problem in a directed acyclic graph with nonoverlapping multivariate marginal moment information at each node,MEAN-UBin(22)is computed by solving the following conic optimization problem:(23)ZLPP=maxxij,wij,Wij,(i,j)∈E∑(i,j)∈EeijTwijs.t.∑j:(i,j)∈Exij-∑j:(j,i)∈Exji=1,ifi=s,-1,ifi=t,0,ifi∈V,xijwijTwijWij∈M2(Ωj)¯∀(i,j)∈E,1μjTμjΠj-∑i:(i,j)∈ExijwijTwijWij∈M2(Ωj)¯∀j∈V,whereeijis a vector of dimension njwith 1 in its ith component and 0 otherwise. ForΩ=Rn,MEAN-UBis computable in polynomial time as a semidefinite program.Step (a): The decision variables in this model are defined asxij=P(xij(c̃)=1),∀(i,j)∈E,wij=E(cjxij(c̃))=E(cj|xij(c̃)=1)P(xij(c̃)=1),∀(i,j)∈E,Wij=E(cjcjTxij(c̃))=E(cjcjT|xij(c̃)=1)P(xij(c̃)=1),∀(i,j)∈E.Step (b): The objective function is expressed asE(ZLPP(c))=∑(i,j)∈EE(cij|xij(c)=1)P(xij(c̃)=1)=∑(i,j)∈EeijTwij.The conic programming method provides a flexible and simple way to analyze mixed integer linear programs with random objective. Since there is a huge number of problems under the umbrella of mixed integer LP, we review only a few applications of the approach.The activity network example in Fig. 1is inspired from Van Slyke (1963) and discussed in more details in Bertsimas et al. (2006). This example serves as a benchmark for comparison of the conic programs with alternative methods for estimating the project completion time and the criticality indices of activities under random activity durations.The deterministic critical path method (CPM) uses the expected value of the activity durations to compute the critical path. The deterministic critical path approach identifies activities (1,2) and (2,4) as being critical with expected project duration of 20.1 irrespective of the number of parallel arcs between nodes 3 and 4. Simulation is a popular approach to analyze activity networks under uncertainty. By simulating durations from a joint probability distribution, it is possible to analyze the project by solving a longest path problem for each sample. However, this comes at the cost of computational expense for large projects comprising of several thousand activities. For this project, we use the multivariate normal distribution to simulate activity durations. Table 2provides a comparison of CPM and the simulation method with the SDP and SOCP methods discussed in Section 3.The simulation results in Table 2 are obtained with independent activity durations. It is clear from the table that the deterministic critical path method severely underestimates the expected project duration. Furthermore it fails to identify activity (1,3) as being the most important especially when the number of parallel arcs between nodes 3 and 4 increases. The criticality index of activity (1,3) is clearly larger than the criticality index of activity (1,2) for n>1 based on the simulation results. This is due to the simple observation that it is very likely that any one of the upper paths will be critical in comparison to the lower path due to the presence of parallel independent arcs. Using a deterministic approach would imply that the project manager focuses on the wrong activity (1,2). For the cross moment and nonoverlapping multivariate marginal moments, SDP is used while for univariate marginal moments, SOCP is used to compute the worst case expected project completion time. All three methods help identify the importance of activity (1,3) under distributional uncertainty. As should be expected, the worst case expected project duration for the cross moment model is lesser than that of the nonoverlapping marginal moment model which in turn is lesser than marginal moment model.In Table 3, the effect of partial correlations is tested on the project performance. Three multivariate normal distributions are simulated. The correlations between all activities are set to zero except for the correlation between activity (1,2) and (1,3), which takes values of −0.9, 0 and 0.9. From Table 3, it is clear that actual criticality index is sensitive to the correlation structure as expected. In fact, as the degree of dependence among activity durations increases, the variation in the criticality indices potentially become significant. Although SOCP based marginal moment model still identifies activity (1,3) as the most critical activity, it does not capture explicit dependence information. In contrast, the more computationally intensive SDP models help provide closer fits to the exact simulation values.In this example, we compare the persistency obtained from the SOCP in formulation (17) with known persistency results for deterministic combinatorial optimization problems. The deterministic weighted vertex packing problem is: Given an undirected graphG(V,E)with weights cifor each vertexi∈V, find a subset of verticesS⊆Vsuch that (i, j)∉E for alli,j∈Swith maximum total sum of the weights of nodes in the setS. The integer programming formulation for the weighted vertex packing problem is(24)ZWVP(c)=max∑i∈Vcixi:xi+xj⩽1,∀(i,j)∈E;xi∈{0,1},∀i∈V,with its linear programming relaxation given as(25)Z¯WVP(c)=max∑i∈Vcixi:xi+xj⩽1,∀(i,j)∈E;xi⩾0,∀i∈V.LetxWVP(c) andx¯WVP(c)denote the optimal solutions to (24) and (25) for objective vectorc. The vertex packing problem has shown to be persistent in the deterministic discrete optimization context (see Nemhauser and Trotter (1975)) – namely for every optimal solution to the linear programming relaxationx¯WVP(c), the set of variables realizing binary values retains the same binary values in at least one optimal solutionxWVP(c). If we allow for uncertainty in the weights, e.g., given E(ci)=μiandVar(ci)=σi2,∀i∈V, then under the marginal moment model, the upper bound on the expected optimal value is computed by solving(26)ZWVP=max∑i∈Vμixi+σixi(1-xi):x∈conv(XWVP),whereXWVPis the feasible region in formulation (24). The persistency of each binary variable xiis obtained by using the optimal solution to the second-order cone program. However, for the vertex packing problem, the convex hull of feasible region is not easily characterizable. In this case, it is appealing to use linear programming relaxation to approximateconv(XWVP). This results in a weaker upper bound,(27)Z¯WVP=max∑i∈Vμixi+σixi(1-xi):xi+xj⩽1∀(i,j)∈E,xi⩾0∀i∈V.ClearlyZWVP⩽Z¯WVP. We use the simple graph in Fig. 2to compare the persistency values.The set of all feasible solutions for this problem isX=(1,0,0,0,0,0),(0,1,0,0,0,0),(0,0,1,0,0,0),(0,0,0,1,0,0),(0,0,0,0,1,0),(0,0,0,0,0,1),(1,0,0,1,0,0),(1,0,0,0,0,1),(0,0,0,1,0,1),(1,0,0,0,1,0),(0,1,0,0,0,1),(0,0,1,1,0,0),(1,0,0,1,0,1),(0,0,0,0,0,0).Assumeσi=σ,∀i∈V. LetxWVP(μ, σ) andx¯WVP(μ,σ)denote the optimal solutions to (26) and (27), respectively. In Table 4, two sets of mean parameters are considered. The first column corresponds to meanμ=(2,1,1,1,1,1) for which the deterministic problem has the unique optimal solution (1,0,0,1,0,1). The second column corresponds to meanμ=(3,1,1,3,6,3) for which the deterministic problem has two optimal solutions (1,0,0,1,0,1) and (1,0,0,0,1,0). In the first example as the standard deviation σ→0,xWVP(μ, σ)→xWVP(μ). However in the second example this is not true due to the presence of multiple optimal solutions. Specifically, the nonlinear part of the objective function∑i∈Vσixi(1-xi)pulls the optimal solution to the middle of the true optimal solutions. The more tractable linear programming formulation has a similar behavior for small values of σ. However for larger values of σ, the two solutionsxWVP(μ, σ) andx¯WVP(μ,σ)can be much further apart.The results described earlier indicate that random discrete optimization problem with a polynomial number of extreme points can be analyzed using compact convex programs. One important example is the class of discrete choice models. These models predict the probability that customers choose an item from a finite set of alternatives. Consider a set of alternativesN={1,…,n}. Assume that the utility that an individual customer assigns to alternativek∈Nis given byck=vk+∊k,where vkis the deterministic component that relates to the known attributes of the alternative, and ∊kis the random error associated with the model due to uncontrolled factors. The random utility maximization problem faced by the customer is then formulated asZ(c)=max∑k∈Nckxk:∑k∈Nxk=1;xk∈{0,1},∀k∈N.Let Pjdenote the probability that alternative j is selected by the customer. This choice probability is the persistency value,Pk=P(xk(c)=1)=P(ck⩾cj,∀j∈N).The classical logit model for choice prediction starts with the assumption that the error terms ∊k’s are modeled by independent extreme value distributions,F(∊k⩽t)=e-e-t,for which the following elegant closed form solution for the choice probabilities can be obtained,Pk=evk∑j∈Nevj.However, this approach has some drawbacks. For example, the formula implies the Independence of Irrelevant Alternatives (IIA) property wherein the relative ratio of the choice probabilities for two alternatives is independent of the remaining alternatives. This property is not always observed in practice where the entire choice set helps in determining the relative probabilities. The probit model, another classical choice prediction model, using correlated normal distributions, can overcome this shortcoming, but at the added cost of finding choice probabilities through extensive simulation. In this case, no simple closed-form solution exists.An alternative approach to find probabilities in discrete choice models is through conic optimization methods we reviewed in the previous section. Suppose that the n dimensional vector of random errors∊is characterized by marginal moments, i.e., the mean vector 0 and the second moment matrix Π≻0. The tight upper bound on the expected random utility is found by solving the following moments problem,(28)Z=sup∫Rnmaxk∈N(vk+∊k)dθ(∊):∫Rndθ(∊)=1,∫Rn∊dθ(∊)=0,∫Rn∊∊Tdθ(∊)=Π.The constraints in (28) ensure that θ is a joint probability distribution consistent with the mean and covariance matrix of the random variables. The equivalent primal semidefinite program using Theorem 8 is(29)Z=maxλk,wk,Wk,k∈N∑k∈NekTwks.t.∑k∈NλkwkTwkWk=1vTvvvT+Π,λkwkTwkWk⪰0∀k∈N,whereekis a vector of dimension n with 1 in its kth entry and 0 otherwise. In this formulation λkis the choice probability that alternative k is selected by the customer under the extremal distribution. Alternatively, we can describe∊by marginal distributions, i.e., ∊j’s distribution function is known as Fj(·). From Theorem 13, the upper bound on the expected random utility is found by maximizing the concave function over the simplex, i.e.,(30)supx∑k∈Nvkxk+∫1-xk1Fk-1(t)dts.t.∑k∈Nxk=1,xk⩾0∀k∈N.In this formulation xkis the choice probability that alternative k is selected by the customer under the extremal distribution. Natarajan et al. (2009) and Mishra et al. (2012) provide detailed numerical comparisons of these conic optimization based choice models with classical discrete choice models such as logit and multinomial probit models.In this section, we discuss the sequencing problem with random costs, which is a notoriously difficult problem. To illustrate the viability of the moment based approach, we compare the persistency values obtained from the SDP models for a simple random walk with the values that are exactly known. This example demonstrates that the distributionally robust assumption in the models are sufficient to obtain near exact approximations to the actual persistency values.Let ci, i=1,…,n be a sequence of independent and identically distributed random variables. For each positive integer k, define the partial sums,Sk=c1+⋯+ck,∀k=1,…,n,and S0=0. The sequence S0,S1,…,Snis a random walk. Let Mn=max{S0,…,Sn} denote the maximum partial sum in the first n steps, and Kn=min{k: Sk=Mn} denote the first time step at which the maximum partial sum is obtained in the first n steps. Note that both Mkand Skare random variables. A basic problem in the random walk theory is to estimate the probability distribution of Kn, i.e.,P(Kn=k)=P(Sk>S0,…,Sk>Sk-1,Sk⩽Sk+1,…,Sk⩽Sn).Define p0=q0=1, pn=P(S1>0,…,Sn>0), qn=P(S1⩽0,…,Sn⩽0), and an=P(Sn>0), for all n⩾1. The random walk theory provides an explicit form for this probability asP(Kn=k)=pkqn-k,∀n⩾k⩾0.For random variables ciwith a symmetric continuous distribution function, the limiting distribution is given by the arcsine law,limn→∞PKnn<x=2πarcsinx,∀x∈(0,1).The corresponding limiting density function is:1πx(1-x).Note that in contrast to common intuition, the arcsine law shows that the two end points (k=0 or k=n) have the highest probability of attaining the maximum, while the minimum takes place around k≈n/2. The problem is similar to a discrete choice problem, where the utility of alternative k is given by the summandSk=∑j=1kcj. Fig. 3shows the choice prediction of the random walk model, based on simulation and the cross moment model, for n=20, where cihas mean μi=0, standard deviation σi=1. The simulation results are based on a multivariate normal distribution. Interestingly, the figure clearly shows that the cross moment model approximately returns the arcsine law behavior of the choice probabilities.These techniques can be used to investigate complex sequencing problems. Consider an oil field exploration problem, where the objective is to determine the optimal sequence to explore a set of n oil fields. The valuation of oil field i is random and denoted by vi. For ease of exposition, assume that the cost to explore each oil field is μiwhere μi=E(vi). With a little abuse of notation, denote the maximum loss given a sequence π of explorations asZ(π)=max0,μπ(1)-vπ(1),(μπ(1)-vπ(1))+(μπ(2)-vπ(2)),…,∑i=1n(μπ(i)-vπ(i)),where π(i)=j indicates that the oil field j is the ith to explore under the sequence π. The goal is to find the optimal sequence that minimizes the expected maximum loss given the joint distribution of the valuations denoted as θ, i.e.,minπEθ(Z(π)).An alternative approach is to use a distributional robust model where the exact joint distribution of the valuations is unknown, and θ is known only to lie in a set of distributions Θ. The distributional robust sequencing problem is formulated asminπsupθ∈ΘEθ(Z(π)).Suppose the valuation vihas mean μiand varianceσi2, and valuations of different fields are uncorrelated to each other. The inner problem is similar to a discrete choice problem, where the utility function of the (k+1)th alternative is described as∑i=1k(μπ(i)-vπ(i)),with mean 0 and varianceσπ(1)2+⋯+σπ(i)2. A simple approximation is to use the marginal moment model which provides a distributional robust approximation to this problem,(31)minπmaxy∑i=1nσπ(1)2+⋯+σπ(i)2yi(1-yi),s.t.∑i=1nyi=1yi⩾0i=1,…,n.It follows simply that the optimal sequence π in formulation (31) is obtained by the smallest variance first rule. I.e., explore the oil fields starting from the smallest to the largest variance. However, this sequencing rule is not optimal in general, when the distributions are explicitly given, or even when the cross moments are known. It remains an open problem to find the optimal sequencing rule in these cases. For other applications of the persistency model in appointment scheduling, we refer the readers to Kong, Lee, Teo, and Zheng (2013).Consider a newsvendor planning problem where the seller needs to determine the order quantity q of an item that maximizes her expected profit under random demandD. The unit cost of the item is c and the selling price is p, with p>c. As the items are perishable, any unsold item will be deemed wasted. It is well known that the optimal ordering quantity q∗ satisfies the critical fractile rule: P(D⩽q∗)=(p−c)/p. Scarf (1958) analyzed a maximin newsvendor problem who finds the optimal ordering quantity only based on the mean μ and variance σ2 of the demand. In the maximin approach, the newsvendor chooses the order quantity that maximizes the minimum expected profit over all possible demand distributions Θ with the given mean and variance, i.e.,(32)maxq⩾0infθ∈ΘpEθ(min(q,D))-cq.To see that this problem fits into our framework, note that min(q,D) can be written asmin{qx+Dy:x+y=1,x,y⩾0}.For given mean and variance only, we have the following distributionally robust formulation for the newsvendor problem:(33)maxq⩾0minλ1,λ2,w1,w2,W1,W2pw1+pqλ2-cqs.t.λ1w1w1W1+λ2w2w2W2=1μμσ2+μ2,λ1w1w1W1⪰0,λ2w2w2W2⪰0,w1,w2⩾0.The inner semidefinite program in (33) decomposes the demand into two events: Event 1 when D<q, and Event 2 when D⩾q. By taking the dual of the inner SDP, the single item minimax newsvendor problem is formulated as a SDP which can be solved analytically as in Scarf (1958). For other results in this area, the reader is referred to the works of Popescu (2007), Chen, Sim, Sun, and Teo (2010), Goh and Sim (2010), Delage and Ye (2010), Doan and Natarajan (2011) and Zymler, Kuhn, and Rustem (2013).We end this section by providing the extension of the maximin approach to the multi-dimensional newsvendor problem. Letq∈Rm+be the vector of resource order quantities, andcbe the unit cost vector of the resources. The matrixAis the technology matrix whose (i, j) component represents the amount of resource i required to produce one unit of product j. Letp∈Rn+be the unit revenue vector for the set of n products. The product demand is random and denoted byD∈Rn+. Harrison and Van Mieghem (1999) formulated the multi-dimensional newsvendor problem as(34)maxq⩾0E(Ψ(q,D))-cTq,where the recourse problem is(35)Ψ(q,D)=maxypTys.t.y⩽D,Ay⩽q,y⩾0.The maximin multi-dimensional newsvendor problem is to find the resource vector that maximizes the minimum expected profit over all nonnegative demand distributions θ with the given mean vectorμand second moment matrix Π, i.e.,(36)maxq⩾0infθ∈ΘE(Ψ(q,D))-cTq.We show that the maximin multi-dimensional newsvendor problem can be reformulated as a copositive program. To see this, consider the more general distributionally robust stochastic linear program,(37)Z=minAx=b,x⩾0(cTx+supθ∈ΘEP[Q(h̃,x)]),where the recourse problem is defined asQ(h̃,x)=minwqTws.t.Ww⩾h̃-Tx.From the strong duality of linear programming problem,Q(h̃,x)=maxp(h̃-Tx)Tps.t.WTp=q,p⩾0.By directly applying Theorem 11 on the inner problem of (37) and taking the dual of the completely positive program, the distributionally robust stochastic program can be formulated as the following copositive program,(38)Z=minx,w1,w2,Y,y,y0cTx+qTw1+(q∘q)Tw2+Q·Y+μTy+y0s.t.y0yT/2(Tx+Ww1)T/2y/2Y-I/2(Tx+Ww1)/2-I/2Wdiag(w2)WT∈CO2n+1,Ax=b,x⩾0,whereIrepresents the identity matrix of appropriate dimension, and diag(w2) denotes the diagonal matrix formed with the diagonal entries being the entries of the vectorw. This formulation provides the generalization of the Scarf formulation to the multi-dimensional newsvendor problem.

@&#CONCLUSIONS@&#
