@&#MAIN-TITLE@&#
Fast and fine quickest path algorithm

@&#HIGHLIGHTS@&#
A novel quickest path algorithm is proposed.The algorithm runs inO(r(m+nlogn))time and usesO(m+n)space.It is a ratio-labeling algorithm working as a Dijkstra-like method.The method enumerates only supported efficient paths.Computational tests show that the algorithm performs very well.

@&#KEYPHRASES@&#
OR in telecommunications,Quickest path,Supported non-dominated path,

@&#ABSTRACT@&#
We address the quickest path problem proposing a new algorithm based on the fact that its optimal solution corresponds to a supported non-dominated point in the objective space of the minsum–maxmin bicriteria path problem. This result allows us to design a label setting algorithm which improves all existing algorithms in the state-of-the-art, as it is shown in the extensive experiments carried out considering synthetic and real networks.

@&#INTRODUCTION@&#
The quickest path problem (QPP) consists of finding a path in a directed network to transmit a given amount of dataσbetween a source node s and a destination node t with minimum transmission time. The transmission time depends on two parameters: an additive function that the represents the path delay, and a bottleneck function that represents the path capacity or bandwidth. The QPP arises in several applications in road transportations, telecommunication networks, convoy movement problems, etc.The QPP was first proposed by Moore (1976), who gave an algorithm running inO(hm+hnlogn)time, where n and m are the number of nodes and arcs, respectively, in the network, and h is a parameter smaller than the number of different capacities greater than the capacity of the shortest path with respect to lead time. Since then, several algorithms solving QPP appeared in the literature. The algorithm of Chen and Chin (1990) transforms the network (r copies of the original network) and then compute shortest paths according to lead time, selecting finally one with the lowest transmission time. The algorithm runs inO(rm+rnlogrn)time and usesO(r(n+m))space for a given value ofσ, wherer⩽mis the number of distinct capacities in the original network. Rosen et al. (1991) developed an alternative algorithm solving the QPP by a sequence of shortest path computations on networks where the minimum capacity increases. They obtain an algorithm running inO(rm+rnlogn)time, but usingO(n+m)space only.Martins and Santos (1997) interpreted the QPP as a bicriteria path problem computing all non-dominated points in the objective space, and finally selecting the non-dominated path with minimum transmission time. The complexity of this algorithm matches the complexity of the algorithm by Rosen et al. (1991).However, Park et al. (2004) have pointed out two drawbacks in the previous algorithms. The first concern is that the existing algorithms must enumerate all non-dominated paths with different capacities. Besides, theσvalue is only used to finally solve the QPP. On the other hand, a Dijkstra (1959) labeling algorithm might fail to solve QPP because this problem does not satisfy the optimality principle of dynamic programming. Thus, they design a label-setting algorithm transforming in an implicit way the original network such that any sub-path of the quickest path is also optimal. The proposed algorithm runs inO(rm+rnlogrn)time and uses at mostO(r(n+m))space, but it is shown that outperforms Martins and Santos (1997) algorithm (the most efficient until this date) in a small experiment presented in their paper.Recently, Calvete et al. (2012) proposed an algorithm combining the simplicity of computing shortest paths with the explicit use in the algorithm of the transmission time and the value ofσ. The time and space complexities match the complexities of the algorithm by Park et al. (2004). The authors claim that their algorithm performs well when comparing it with Chen and Chin (1990), Martins and Santos (1997) and Park et al. (2004) algorithms in an experiment considering a small number of different values of the arc capacities.Pascoal et al. (2006) provide a survey on the quickest path problem. Several authors have also developed some extensions to the QPP problem. See for example (Chen, 1993; Chen and Hung, 1993; Lee and Papadopoulou, 1993; Chen, 1994; Chen and Hung, 1994; Xue, 1998; Xue et al., 1998; Kagaris et al., 1999; Calvete and del-Pozo, 2003; Lin, 2003; Calvete, 2004;Rao, 2004; Pascoal et al., 2005; Pascoal et al., 2007; Ruzika and Thiemann, 2012).The contribution of this paper is a completely new algorithm based on the fact that thes-tpath with minimum transmission time is a supported efficient solution of the bicriteria path problem. This observation allow us to design a (ratio) labeling algorithm running inO(rm+rnlogn)time, and usingO(n+m)space. The proposed algorithm avoids the two drawbacks pointed out by Park et al. (2004). First, the algorithm enumerates the supported efficient solutions of the bicriteria path problem until the optimal solution of the QPP is determined, taking into account the value ofσ. Secondly, the algorithm works in a Dijkstra fashion, that is, only one application of a labeling method is performed, but this is not related to the optimality principle of the classical shortest path method.In addition, Park et al. (2004) and Calvete et al. (2012) forgot a third drawback in their algorithms: the enlarging of the original network. Our algorithm does not need to enlarge implicitly or explicitly the original network. Moreover, we have kept the term O(log nr) (note that O(log n + log r) = O(log n) sincer⩽m<n2) in the time complexities of these algorithms to make clear the difference with our method, because in practice, this term has a computational time and space price.Furthermore, we show that our method outperforms the previous methods in the different extensive experiments that we carried out. In particular, we have used the proposed algorithm to solve the QPP in USA road networks to show the robustness and scalability of the proposed algorithm. We note that only the algorithms of Martins and Santos (1997) and the one proposed in this paper are capable to solve the QPP in these networks. Any other algorithm enlarging the original network becomes impractical in a personal computer when it tries to solve the QPP on these instances.The remaining sections of the paper are as follows: Section 2 introduces the QPP and describes some known results of the literature about of this problem. Section 3 contains the formulation of the QPP as a parametric programming problem and the study of its resolution. Section 4 proposes the ratio-labeling algorithm based on the parametric programming problem. This section provides the worst-case time and space complexity of this new algorithm. In Section 5, the comments on the computational experiment comparing the performance of the proposed algorithm and other known algorithms in the literature are given. Finally, Section 6 contains some additional comments and future lines of research.Consider a directed graphG=(V,A), whereV={1,…,n} is a set of n nodes and A is an arc set with m elements. For each arc(i,j)∈A,cijis a nonnegative real number representing its lead time anduijis a nonnegative real representing the capacity of the arc. That is,uijrepresents the maximum number of items that can flow from node i to node j through arc(i,j)per time unit. The lead timecijis the time required for the items to traverse arc(i,j). Note that items arrive at node j withincijtime units after being sent from node i. Therefore, the required transmission time ofσ>0items through arc(i,j)iscij+σ/uij.For all nodes, we denote byΓi-={j∈V|(j,i)∈A}and byΓi+={j∈V|(i,j)∈A}the sets of predecessor and successor nodes, respectively.The network has two different nodes from the rest: the origin node s and the destination node t. Leti,j∈Vbe two nodes ofG=(V,A), so we define a directed pathpijas a sequence〈i1,(i1,i2),i2,…,il-1,(il-1,il),il〉of nodes and arcs satisfyingi1=i,il=jand for all1⩽w⩽l-1,(iw,iw+1)∈A.The lead time of a directed path p equalsC(p)=∑(i,j)∈pcijand the capacity of p isU(p)=min(i,j)∈p{uij}. Then, the transmission time required to sendσunits of data through pathpstis defined asT(pst)=C(pst)+σ/U(pst).Assumption 1w.l.o.g.The network G contains a directed path from the origin node s to any nodei∈V-{s}. When there is no path in G to some node i, then this node can be removed from G since it cannot lie on anys-tpath.Let P be the set of paths from s to t in G, then the QPP can be formulated as finding as-tpathpst∗=argminpst∈PT(pst). It is clear that there exists an optimal solution of the QPP which is loopless (without repeating nodes). Consider the next minsum–maxmin bicriteria path problemminpst∈P(C(pst),1/U(pst)), where the criteria maxU(pst)appears as min1/U(pst). The objective space is the image of the set of paths P under the previous objective functions.Definition 1A pathp∈Pis called efficient if there does not exist anyp′∈PwithC(p′)⩽C(p)andU(p′)⩾U(p)with at least one inequality being strict. The image(C(p),1/U(p))of p is called non-dominated point.Supported efficient paths are those efficient paths that can be obtained as optimal paths of a weighted sum problemminpst∈P(λ1C(pst)+λ2/U(pst))for someλ1>0andλ2>0. All other efficient paths are called non-supported.The supported non-dominated points lie on the lower-left boundary of the convex hull of the objective space.Since the weighted sum problem withλ1=1>0andλ2=σ>0equals the QPP, we can rewrite the next result in Martins and Santos (1997) as:Theorem 1Letpstσ∈Pbe a quickest path for a givenσ∈R+. Then,pstσis asupportedefficient path.This result was mentioned in Pelegrín and Fernández (1998), but it never was used to design a quickest path algorithm. Now, the question now is how to use this property. Martins and Santos (1997) give an initial answer. LetPE⊆Pbe the set of supported efficient paths and consider that this set is sorted such thatPE={p1,…,pr}whereC(pi)⩽C(pi+1)andU(pi)⩽U(pi+1), for anyi∈{1,…,r-1}. Without loss of generality, we will assume thatC(pi)<C(pi+1)andU(pi)<U(pi+1), for anyi∈{1,…,r-1}withpi∈PE.In other words, we only need to compute all supported non-dominated points of the objective space (in the worst case). If two or more supported efficient paths have the same associated supported non-dominated point in the objective space, it is clear that it is only necessary to identify one of these paths in order to solve the QPP. The result in Martins and Santos (1997) is:Theorem 2(1)p1is a quickest path forσ∈0,C(p2)-C(p1)U(p2)-U(p1)×U(p2)×U(p1)piwithi∈{2,…,r-1}is a quickest path forσ∈C(pi)-C(pi-1)U(pi)-U(pi-1)×U(pi)×U(pi-1),C(pi+1)-C(pi)U(pi+1)-U(pi)×U(pi+1)×U(pi),for anyi∈{2,…,r-1}.pris a quickest path forσ∈C(pr)-C(pr-1)U(pr)-U(pr-1)×U(pr)×U(pr-1),+∞.(See Martins and Santos (1997)).□The proof of this result given in Martins and Santos (1997) follows from elementary calculations to solve a system of inequalities. An alternative proof is based on the observation that the previous intervals correspond with the optimality intervals of the parametric programming problemminpst∈P(C(pst)+θ/U(pst))withθ⩾0(see Saaty and Gass, 1954). In our case, we need to solve the previous parametric programming problem starting withθ=0untilθ⩽σin order to solve the QPP. However, the novel approach is that the second criterion is not linear in this parametric programming problem. Therefore, in the next section, we study the determination of all supported efficient paths associated with the optimal solutions of this particular parametric programming problem forθ⩽σ.Note that we can obtain a shortest path tree minimizing the lead time from node s to node t when we solve the parametric programming forθ=0, but the corresponding shortest path tree could contain a dominated path due to the fact that the second objective is not taken into account. In order to avoid this situation, the method starts with an optimal shortest path treeT∗of the parametric programming problem forθ=ε>0, whereεis sufficiently small.Pathp1derived fromT∗is obtained by solving the lexicographic optimization problemlexminpst∈P(C(pst),1/U(pst))for allt∈V-{s}(see Isermann (1984)). Therefore,p1is a supported efficient path that is an optimal lead time path. This path has an image(C(p1),1/U(p1))in the objective space, which is a vertex on the convex hull of the supported non-dominated points. For this tree, we store the lead time labelsdi, the capacity labelsbiand the predecessor labelspredifor any nodei∈T∗(see Ahuja et al., 1993). Note that labelbiindicates the minimum capacity of the arcs in the shortest path tree from node s to node i (the bottleneck of the path), but a shortest path from node s to node i with a capacity value greater thanbidoes not exist. Now, we must obtain the next supported non-dominated point in order to determine ifp1is a quickest path. In other words, we must identify the optimality interval of the pathp1in the parametric programming problem.We define the reduced cost arc asc¯ij=cij+di-djand the reduced capacity arc asu¯ij=1/bj-1/min{bj,uij}for any arc(i,j)∈A. Note thatc¯ij=0andu¯ij=0for any arc(i,j)∈T∗. These values represent the increase in the labels of node j when the arc(i,j)replaces the arc (predj, j), that is, the current labels(dj,1/bj)becomes(dj+c¯ij,1/bj-u¯ij)after this swap is made. The current optimal solution of the parametric programming remains optimal as long as the reduced cost and capacity labels (in terms of the objective of the parametric programming), are non-negative. We have the following relation between the reduced labels of the arcs:c¯ij-θu¯ij⩾0forall(i,j)∈A,therefore, the current path tree remains optimal for allθin the rangeθk-1⩽θ⩽θk, whereθk=min(i,j)∈Aθijk,θ0=0andθijk=c¯ij/u¯ijifbj<min{bi,uij}+∞otherwiseThat is, ifu¯ij=1/bj-1/min{bj,uij}>0, then the ratio of the arc(i,j)in the current solution k (withk=1initially) isc¯ij/u¯ij. Otherwise, this ratio is infinite (for instance, for all arcs in the current path tree). In order to determine a supported non-dominated point, we must calculate:x,y=arglexmin(i,j)∈Aθijk,uij:θijk<+∞That is, we must determine the arc with the minimum finite ratio. If more than one arc with minimum ratio exists, then we select one from those with minimum capacity. For this reason, the lexmin criterion appears in the above expression.For the sake of simplicity, suppose that node y is node t and that we obtainp2interchanging(predy,y)by(x,y), that is, the next supported path in Theorem 2. It is clear that the interval forp1will be(0,c¯xy/u¯xy](to see this, the expressions ofc¯xyandu¯xymust be considered in the ratioc¯xy/u¯xyto obtain the upper bound of the interval in Theorem 2). Moreover, ifc¯xy/u¯xyis greater than or equal toσ, then we have identified a quickest path. This gives us the idea of the proposed algorithm.Now, we must examine the ratiosθijk+1for all arcs(i,j)∈Awhen arc(predy,y)is substituted by arc(x,y). In this case,(dy,1/by)becomes(dy+c¯xy,1/by-u¯xy), and therefore, only the ratio of the arcs arriving at or leaving from node y could change. We obtain the two next results:Lemma 1Once the labels of node y are modified by the consideration of the arc(x,y), the ratio of any arc(i,y)withi∈Γy-increases or keeps its previous value and, it is always greater than or equal to the ratio of the arc(x,y). In particular, if the ratio of arc(i,y)was equal to the ratio of arc(x,y), the ratio of(i,y)does not change.(See Appendix A). □Once the labels of node y are modified by the consideration of the arc(x,y), the ratio of any arc(y,i)withi∈Γy+increases, decreases or keeps its previous value and, it is always greater than or equal to the ratio of the arc(x,y). However, if the ratio decreases, then the arc(y,i)is discarded for future consideration. In particular, if the ratio of the arc(y,i)was equal to the ratio of the arc(x,y), the ratio of(y,i)does not change.(See Appendix A). □The above lemmas guarantee that the new ratios are greater than or equal to the ratio of the arc(x,y). Moreover, they inform us that only must consider the cases when the ratio of an arc increases or keeps their previous value.Given a supported efficient labels(di, 1/bi)for any node i inV-{s}, we define:(θi,uˆi)=lexminj∈Γi-c¯ji/u¯ji,uji:c¯ji/u¯ji⩽σandbi<min{bj,uji},whereθiis the minimum ratio of the arcs arriving at node i anduˆiis its capacity (in the case that two or more arcs have the same minimum ratio, the tie is broken with the minimum capacity arc among them). The initial labels are obtained fromT∗. From these calculations and definitions, we can establish:Theorem 3The quickest paths for all nodesV-{s}and for a given value ofσcan be calculated starting from a lead time optimal path tree by an iterative sequence of labels updating operations considering the arc(x,y)every time, such that(x,y)=arglexmin(i,j)∈Aθijk,uij:θijk<+∞, until the ratio of any arc in A is greater thanσ.Starting from the supported efficient path tree corresponding to the optimal lead time path tree, we obtain the initial supported efficient labels(di, 1/bi), the ratioθiand the capacityuˆifor any node i inV-{s}. Next, let y the node with minimum finite ratioθy, that is, we have identified the arcx,y=arglexmin(i,j)∈Aθijk,uij:θijk<+∞. Then, we stay on the inferior boundary of the convex hull of the objective space of the QPP from node s to y when(dy,1/by)is updated to(dy+c¯xy,1/by-u¯xy). This is true since the ratio of this arc indicates the minimum slope (in the sense from the right to the left in the objective space) to obtain a solution corresponding to a path from s to y. Moreover, this new solution is optimal for the parametric programming problem withθ0=θxy. This last claim is true since any arc has a ratio greater than or equal toθxy, once the ratios of the arcs arriving at and leaving from node y are updated (see Lemmas 1 and 2). Then, the ratios of the nodes are updated following the expression(θi,uˆi)=lexminj∈Γi-{(min{θi,c¯ji/u¯ji},uji):c¯ji/u¯ji⩽σandbi<min{bj,uji}}, and we keep the minimum finite ratio associated with any node all the time. Therefore, in an iterative way, we enumerate all supported non-dominated labels of the minsum–maxmin one-to all bicriteria path problem. But, in order to solve thes-tQPP, we can stop the method when the minimum ratio of all nodes is greater thanσ.□From this result, in the next section we introduce a labeling algorithm that enumerates all supported non-dominated points of thes-tQPP until the ratio of any arc is greater thanσ.The algorithm starts computing the shortest path tree considering the lead time. For this tree, we store the lead time labelsdiand the capacity labelsbifor any nodei∈V. Note that these labels correspond to the resolution of thelexminpst∈P(C(pst),1/U(pst))problem. This problem can be solved adapting Dijkstra’s algorithm (DA) in such a way that the labels of any node i are modified when the distance labeldiis improved or when there is a tie withdibut the capacity is improved (greater than the current value ofbi).The proposed algorithm works updating the labelsdiandbiof the current solution. Also, it uses a heap to store the labels of any node i in V. These labels are:(θi,uˆi)=lexminj∈Γi-(c¯ji/u¯ji,uji):c¯ji/u¯ji⩽σandbi<min{bj,uji}.That is, the algorithm stores in a heap H, the minimum ratioc¯ji/u¯jiof the arcs(j,i)such that this ratio be non-greater thanσand the current labelbibe less thanmin{bj,uji}, for any node i. In the case that two or more arcs arriving at node i have the same minimal ratio, the algorithm stores in heap H the ratio of the arc with major value ofmin{bj,uji}. However, note that the keys in H are(c¯ji/u¯ji,uji), that is the ratio and the capacity of the corresponding arc, following the selecting criteria rule in Section 3. Note that the algorithm stores the ratioθi, the reduced costcˆi=c¯jiand the capacitybˆi=min{bj,uji}=min{bj,uˆi}in the previous ratio expression to update the labels in an easy way. The following heap operations are needed in our algorithm (see Cormen et al., 2009): CreateHeap(H), insert ({labels},H), find-min(H), decrease-key ({labels},H), and delete-min(H). Also the algorithm keeps a flag inheapifor any node I in V. inheapi is greater than 0 whenever node i belongs to the heap H; otherwise takes the value 0.The below algorithm is a label setting (Dijkstra) algorithm with the exception of lines (9–11). Line 11 represents the calculation of the next ratio for node i when node i becomes the candidate node in the current solution (cases (1)–(4) in the proof of Lemma 1). Lines 9–10 check if the current minimum element in the heap corresponds to node t and verifies if the transmission time is improved in order to determine a QQP. In this case, it is needed to store the labelsdtandbtto identity the optimal path when the algorithm ends. In lines (13)–(18), the ratios and the labels of the successors of node i are scanned and updated following the cases (5)–(6) in the proof of Lemma 2. This operation matches with the relax operation in Dijkstra algorithm. Thus, the algorithm enumerates the sequence of the ratios less than or equal toσcorresponding to the slopes of the segments in the lower convex hull (non-dominated frontier) of the bicriteria minsum–maxmin path problem for all node i in V−{s}. Once the algorithm ends, we must solve a shortest path problem considering the lead time only for those arcs with capacity greater than or equal tobt, in order to determine the sequence of nodes in the QQP.Theorem 4The FFQP algorithm runs inO(r(m+nlogn))time and usesO(n+m)space.The resolution of thelexminpst∈P(C(pst),1/U(pst))using DA needsO(m+nlogn)time (see Cormen et al., 2009). Note that the size of the heap H in the FFQP algorithm is at most n. For instance, inheapi becomes 0 only when node i is extracted from the heap. In addition, any heap operation takes constant time with the exception of the delete-min operation that requires O(logn) time, when a Fibonacci heap is used (see Fredman and Tarjan, 1987). Also note that any node i can be inserted in the heap at most r times since the number of different efficient labels for a node i is at most r. Therefore, r is also a bound of the number of supported non-dominated points for each node i. This is also proved observing that the ratio of a node i only is considered when the corresponding arc follows to increase the labelbi. Thus, the worst-case time complexity of the algorithm isOr∑i∈V-{s}logn+Γi-+Γi+=O(r(nlogn+m)).Finally, it is easy to observe that the space used by the algorithm isO(n+m).□In the next section, we show the good performance of this algorithm, for example indicating that the number of insert operations in the heap made by the algorithm is inferior to rn.This section describes the computational experiments carried out to assess the performance of the FFQP algorithm (FFQPA). First, we detail the experimental setup, and then we analyze descriptively the results obtained from three different experiments that compare the most relevant algorithms in the literature with our new approach.The algorithms taken into account in the experiment are: the Label-Setting algorithm (LSA) given in Park et al. (2004) and Martins and Santos (1997) algorithm (MSA) and the algorithm given by Calvete et al. (2012) (NQPPA). These algorithms were written in C. The codes were tested on a MacBook Pro i7 Intel® Core™ Duo at 2.9GHz processor with 8GB of RAM running OS X. In the implementation of these algorithms, we have used a binary heap data structure where an operation decrease-key was also included. Therefore, all heap operations take log (sizeof (heap)) time in our implementation.We have considered three different experiments to ensure that the experimental framework does not benefit us. We used the NETGEN generator attributed to Klingman et al. (1974), the GRIDGEN generator developed by Lee and Orlin (1991) and, finally, we have considered USA road networks in order to prove the performance of the algorithms in large real networks. Also, we have replicated the experiment in Calvete et al. (2012) that uses the NETGEN generator. Generally, in these last instances, the quickest path equals the optimal lead time path because the number of different capacities of the arcs in these networks is small (2, 5 and 10). Therefore, in this experiment the instances are easily solved and the values of the CPU times obtained were less than 0.05s for all the algorithms. Therefore, we do not reproduce this experiment in this paper because significant differences among the algorithms were not observed.The parameters used in the NETGEN and GRIDGEN experiments are summarized in the following table:In the previous table, r is the number of different capacities of the arcs in the network. This parameter was considered as input data in the experiments developed by Park et al. (2004) and Calvete et al. (2012). Note that the value of this parameter is not an explicit input of the QPP. Moreover, the algorithms NQPPA and LSA need to know a priori the r value. Note that to compute this value is necessary to explore the capacities of the arcs, storing the different values of the capacities found in the network in a sorted vector. In this way, we can know in log rtime if the current capacity has already been considered or not. This effort adds a termO(mlogr)in the time complexity of these algorithms.However, even though we believe that the time employed by this operation must be considered in the comparison among the algorithms, this time is not added to the CPU times reported in the experiments. Notice that MSA and FFQPA do not need to know a priori the value of r. That is, these two algorithms directly work on the original network and the number of different capacities of the arcs in the network has no effect in the implementation of these algorithms.The lead time and the capacity values were generated from a uniform distribution in the range [10,10,000]. We have generated ten replications using different seeds for each combination of the parametersn,m,rand sigma(σ). We report the total CPU times in seconds, averaged over several instances generated with the same parameters. Since all algorithms use a binary heap, we have counted the number of delete-min operations (neHeap) performed by each algorithm. In addition, we reported the number of remainder keys (nrHeap) in the heap when the algorithms NQPPA and LSA finish. This number is 0 for FFQPA and MSA. Note that neHeap+nrHeap equals the number of insert-heap operations made by an algorithm. The implementation of LSA in Park et al. (2004) uses a double bucket data structure and our implementation of LSA uses a binary heap. Our implementation of the DA in MSA uses the following stop criteria: once the label of node t becomes optimal, the execution of DA ends. It is clear that this rule benefices the execution of MSA. Moreover, the times and capacities are integer values in all our experiments. In this case, all operations made by MSA are point-fixed operations since the labels take integer values. Instead, the remainders algorithms make floating-point operations since they use real labels. Again, this difference benefices the execution of MSA.Finally, in the experimentation, we have used a density measurement (density=m/n) to give more insight on the behavior of the algorithms in relation with the arcs in the network.In this section, we detail the most relevant results with regards to the NETGEN experiment. In order to detect the differences among FFQPA and the other algorithms, we have showed the figures corresponding to CPU time, the number of labels extracted from the heap and the number of labels remaining in the Heap. Due to the NQPPA algorithm employs considerably more time than the others algorithm, this algorithm does not appear in all the next figures. The exact values of the CPU time consumed by the algorithms can be consulted in the tables of the additional material associated with this paper.Fig. 1shows the CPU time of the algorithms in the experiment. In particular, Fig. 1a displays the CPU time vs n, Fig. 1b shows the CPU time vs density and Fig. 1c the CPU time vs r and sigma, simultaneously. Increasing the number of nodes enlarges the number of arcs and, therefore, this situation greatly benefits the performance of FFQPA. In Fig. 1, we observe that FFQPA does not exceed a threshold of 0.05s in the CPU time. In this figure, the highest value of the CPU time employed by FFQPA is better than the best CPU time of the other algorithms. The CPU time used by FFQPA is almost linear when we consider the density of the network (Fig. 1b). The gap between the CPU times of the FFQPA and the CPU times of the other algorithms increases as r increases (Fig. 1c).Fig. 2presents the results of two operations concerning to the Heap. The Fig. 2a and b show neHeap and nrHeap vs n and density, respectively. The Fig. 3a–c relation these values vs r and sigma. The sum of the two colors shows the number of insert-heap operations made by each algorithm. Fig. 2 shows that FFQPA generates scarcer labels than other algorithms in average. Observing the number of extracted labels from the heap (neHeap, gray bar), we conclude that FFQPA makes the smallest number of these operations, except whenn=4000, but the difference with LSA is not significant in this case. But, the differences are enormous when the number of insert-heap operations is considered. In Fig. 3, we can view that FFQPA creates much less labels than MSA and LSA. In particular, FFQPA extracts the least number of labels from the heap when the number of different capacities increases. Clearly, the gap is still superior when the insert-heap operations are taken into account.In summary, LSA, MSA and NQPPA’s CPU times grow up while FFQPA keeps a time threshold when the density of the network increases. The same situation occurs when we observe the number labels generated by the algorithms. For example, FFQPA uses 34% less labels than MSA and 53% less labels than LSA, in average. All these elements tell us that FFQPA is faster and generates fewer labels than any other algorithm in the NETGEN experiment.The size of network is an important issue to explore the behavior of the algorithms. Therefore, we evaluated the algorithms on considerable big instances. Table 1has shown us the setting parameters of the network generated by GRIDGEN generator. As in NETGEN generator, NQPPA employed a CPU time higher than MSA, LSA and FFQPA. Clearly NQPPA requires the largest expense CPU time except when the value of r is small. For this generator, NQPPA consumes 91% more CPU time than the others in average. For this reason, the following figures do not incorporate the NQPPA algorithm in order to observe in an easy way the differences among the algorithms.Increasing the density in the networks generated by GRIDGEN makes that the CPU time of the FFQPA grows quasi-linearly (Fig. 4b). In Fig. 4a, the growth of FFQPA appears to be slightly curved. In both figures, our algorithm presents the best of CPU times. The only case when FFQPA employs more time than MSA and NQPPA is whenr=10and sigma is 1,000,000 (Fig. 4c), but the differences are not significant. The reason is that the quickest path often equals the optimal lead time path when r is ten in this experiment, that is, the instance become easy. However, FFQPA is better than the others when r increases. The CPU time employed by FFQPA varies as a linear function of sigma for a fixed value of r. The remainder algorithms show a similar behavior with the exception of MSA.Considering the generated labels by the algorithms, we observe that NQPPA produces a number of labels much larger than the other algorithms. Again, NQPPA creates a number of labels similar to the rest of algorithms only for small values of r and big values of sigma.Fig. 5shows the values of neHeap (gray bar) and nrHeap (blue bar) against n (Fig. 5a) and density (Fig. 5b), respectively. Although LSA uses fewer labels than FFQPA in some occasions, we observe that the number of labels that remain in the heap is outrageously high. That is, LSA performs a large number of insert-heap operations.Finally, we consider the variation of neHeap and nrHeap when r and sigma increase (Fig. 6). FFQPA uses on average 17%, 34% and 30% less labels than the second algorithm that uses fewer labels, regarding to the values 10, 100 and 1000 of r, respectively.We selected seven USA distance-time road networks from the 9th DIMACS Implementation Challenge: The Shortest Path Problem. These networks range from the smallest to the largest USA road networks considering the arc distance and the travel time costs, which appear in Table 2. In this experiment, only the proposed algorithm (FFQPA) and the algorithm of the Martins and Santos (1997) (MSA) have run with success. Note that in these networks the number of different capacities is not bounded a priori (only by the number of arcs that can be millions).We report the values of neHeap and the CPU time in seconds over four instances considering the same origin node s = 1 and the destination node t taking values in {}. Note that these road networks are undirected and, therefore, the paths from s to t are the same as those from t to s. We used these values for t to consider the cases when the destination is close to or remote from the origin node. In summary, the corresponding destinations appear in Table 2.Table 3shows the CPU time in seconds and the values of neHeap grouped by the different values of sigma for each road network and destination enumerated in Table 3. MSA is a better algorithm than FFQA for destinations 3 and 4 in all USA road networks in this experiment with the only exception of COL. But, the instances considering destinations 3 and 4 (destinations close to origin) are easy, because the bicriteria problem contains few supported efficient paths. The instances considering far destinations (1 and 2) are harder to solve, because contains more supported efficient paths than the instances considering destinations 3 and 4. For these instances, FFQPA is a faster algorithm than MSA. For example, MSA needs 38s to solve the QPP in LKS considering destination 2, while FFQPA only need 1s. In these instances, large gaps in the CPU times in favor of FFQPA can be observed. Moreover, FFQA is better algorithm averaging the CPU times for all destinations for each USA road network and averaging the CPU times for all USA road network for a fixed value of sigma. Moreover, the destination has no influence in the FFQA algorithm since it solves the one-to-all QPP. Similarly, the same comments can be made on the observed values of the neHeap.In the USA road networks considered, the number of non-dominated solutions found by MSA belongs to [1,…,92]. Instead, the number of supported non-dominated solutions found by FFQPA ranges in [1,…,4] (when sigma is 1,000,000). MSA employs more time when the nodes s and t are distant than when they are close. The reason is that the bicriteria shortest problem contains more non-dominated solutions for the first problems. Moreover, the value of sigma has not influence in the behavior of the MSA, because this algorithm enumerates all non-dominated solutions. Instead, FFQPA is sensitive for the sigma values. It is clear that the CPU time of FFQA growths when sigma growths.We have observed that our proposed algorithm presents good results. On one hand, it is evident FFQPA robustness against the-state-of-art algorithms to solve QQP. FFQPA not only gets the best time in terms of the growth of the network, but also it does so in a quasi-linear way. One the other hand, we observe that our algorithm reduces the number of labels generated when we observe the labels extracted and the labels remaining in the heap.

@&#CONCLUSIONS@&#
We introduce a novel algorithm to solve the quickest path problem based on the fact that the optimal solution is a supported efficient path of the bicriteria minsum–maxmin path problem. This property allows us to design a ratio-labeling algorithm whose behavior is a Dijkstra-like algorithm. The result is a fastest algorithm generating few labels in all extensive experiments considered. Moreover, the proposed algorithm works on the original network. This is an important advantage from the algorithms expanding the original network. For example, we have tested the algorithms enumerated in the paper on USA road networks. Only the proposed algorithm and the algorithm of Martins and Santos (1997) have run successfully on these big instances. Note that in these networks the number of different capacities is not bounded a priori (only by the number of arcs that can be millions). The algorithms extending the original network cannot work on these instances due the extensive use of memory that they need to run. Finally, future investigations will try to adapt the proposed algorithm to extensions of the quickest path problem appeared in the literature.