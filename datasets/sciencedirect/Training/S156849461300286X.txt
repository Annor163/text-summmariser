@&#MAIN-TITLE@&#
A particle swarm optimization for a fuzzy multi-objective unrelated parallel machines scheduling problem

@&#HIGHLIGHTS@&#
Proposing a fuzzy multi-objective model for unrelated parallel machine scheduling.Presenting an effective multi-objective particle swarm optimization solution method.Comparing the proposed MOPSO algorithm against a conventional MOPSO algorithm.

@&#KEYPHRASES@&#
Fuzzy mathematical programming,Unrelated parallel machine scheduling,Secondary resource constraints,Multiple objective particle swarm optimization,

@&#ABSTRACT@&#
This paper proposes a novel multi-objective model for an unrelated parallel machine scheduling problem considering inherent uncertainty in processing times and due dates. The problem is characterized by non-zero ready times, sequence and machine-dependent setup times, and secondary resource constraints for jobs. Each job can be processed only if its required machine and secondary resource (if any) are available at the same time. Finding optimal solution for this complex problem in a reasonable time using exact optimization tools is prohibitive. This paper presents an effective multi-objective particle swarm optimization (MOPSO) algorithm to find a good approximation of Pareto frontier where total weighted flow time, total weighted tardiness, and total machine load variation are to be minimized simultaneously. The proposed MOPSO exploits new selection regimes for preserving global as well as personal best solutions. Moreover, a generalized dominance concept in a fuzzy environment is employed to find locally Pareto-optimal frontier. Performance of the proposed MOPSO is compared against a conventional multi-objective particle swarm optimization (CMOPSO) algorithm over a number of randomly generated test problems. Statistical analyses based on the effect of each algorithm on each objective space show that the proposed MOPSO outperforms the CMOPSO in terms of quality, diversity and spacing metrics.

@&#INTRODUCTION@&#
Parallel machine scheduling problem (PMSP) is concerned with allocating a set of jobs to a number of parallel machines in order to meet customer's requirements. In the literature, the studies on PMSP can be generally classified into the three categories [1]: identical, uniform and unrelated parallel machine scheduling problem. Among these categories, unrelated PMSP (UPMSP) represents a generalization of the other two categories in which different machines perform the same function but have different processing capabilities or capacities. However, dealing with real-life UPMSPs is a major challenge for researchers and practitioners, due not only to the fact that they are mostly NP-hard except for the objective of minimizing flow time (see [2]), but also more importantly to their special characteristics/requirements in practice. This paper focuses on an UPMSP; which has been addressed much less than the identical and uniform PMSPs in the literature especially when setup times are taken in account (see [3,4]).Kamath [5] present a survey on UPMSP involving makespan considerations. Li et al. [6] and Chyu and Chang [7] examine the UPMSP to minimize the mean flow time, while Cao et al. [8] study the same problem by considering the total cost functions. Lin et al. [9] address the problem to minimize the total tardiness by including the machine-dependent sequence-dependent setup times.Researchers have addressed the more practical versions of UPMSPs by considering other features of real scheduling problems such as secondary resource constraints, non-zero ready times and so on. Chen [10] develops a heuristic method to minimize makespan in an UPMSP with different die types as a secondary resource constraint. Chen and Wu [11], and Chen [12], solve an UPMSP with auxiliary equipment constraints as secondary resource constraints. Lamothe et al. [13] propose a new model in order to minimize total tardiness by considering specific constraints such as secondary resources.As another feature, Bang [14] develops an algorithm for UPMSP with sequence-dependent set-ups and distinct ready times while minimizing total tardiness. Chen [15] develops an iterated local search to minimize the total weighted number of late jobs on UPMSP without preemption, with sequence dependent setup times and ready times.Chang et al. [16] have proven that a single-machine, total weighted tardiness minimization problem with static job releases and static machine availability and weights of all jobs being equal, is strongly NP-hard. Clearly, the single machine case considered by them is a special case of the sequence-dependent unrelated parallel machine-scheduling problem considered in this paper. Therefore, the problem investigated in this paper is also strongly NP-hard. Amiri and Khanmohammadi [17] classified the proposed methods for solving such problems into two categories as classic and intelligent algorithms (IA). While the Dynamic programming [18] and Lagrangian relaxation [19] are classified as former categories, genetic algorithm (GA) [20], PSO [21], ant colony optimization (ACO) [22], neural network (NN) [23–26] and various hybrid IAs [27] are categorized as the later one.Thus, it is unlikely that a polynomial-time algorithm could be developed capable of determining an optimal solution for such UPMSPs like our concerned problem in practice. Hence, many researchers usually apply metaheuristic methods to deal with such problems (see e.g. [28–32]). Among them, Vallada and Ruiz [28] develop a genetic algorithm including a fast local search and a local search enhanced crossover operator. Two versions of the algorithm are proposed after extensive calibrations by using the design of experiments (DOE) approach. They conclude that their methods show an excellent performance when evaluating them over a comprehensive benchmark set of instances. Bozorgirad and Logendran [29] address a sequence-dependent group-scheduling problem on a set of unrelated-parallel machines where the run time of each job differs on different machines. They developed a meta-heuristic algorithm based on Tabu search that could find solutions at least as well as CPLEX but in drastically shorter computational time. Chen [30] considers unrelated parallel machine scheduling with sequence-dependent setup times and unequal ready times aiming to minimize the weighted number of tardy jobs. He proposes an Iterated hybrid meta-heuristic algorithm, which begins with effective initial solution generators to generate initial feasible solutions; then, hybrid meta-heuristics are applied to improve the initial solutions, integrating the principles of the variable neighborhood descent approach and tabu search. Arnaout et al. [31] introduce an enhanced ant colony optimization (ACO) Algorithm and compare its performance to other existing algorithms including ACO I, MetaRaPS, and simulated annealing (SA) on unrelated parallel machines with sequence-dependent setup times. Recently, Ruiz-Torres et al. [32] present a new unrelated parallel machine-scheduling problem with deteriorating effect and the objective of makespan minimization. They design a set of list scheduling algorithms and simulated annealing meta-heuristics and the effectiveness of these approaches are evaluated by solving a large number of benchmark instances.Motivated by a real case study in a wire and cable manufacturer, this research deals with scheduling of a number of jobs on an unrelated parallel machine system with secondary resource constraints in which each job can only be processed if its required machine and other secondary resources (e.g. labor, tools, etc.) are available. Each job has a due date and requires a single operation with non-zero ready time. Moreover, when different jobs received from customers compete for the same resource (i.e. a set of unrelated parallel machines), in addition to agreeing on a specific due date it is customary to specify a weight or degree of importance based upon the job and the kind of relationship that exists between the customer and the producer. In addition, the setup time required for a job on a machine is dependent upon the degree of similarity or dissimilarity that exists between this job and its immediately preceding job. Thus, the problem we consider here is a sequence-dependent UPMSP aiming to minimize the total weighted flow time, the total weighted tardiness, and the machine load variation of all jobs released during the planning horizon simultaneously.The main contributions of this paper can be highlighted as follows:•Proposing a new fuzzy UPMSP model addressing the non-zero ready times, sequence and machine-dependent setup times, and secondary resource constraints for jobs simultaneously to cope with imprecise/ambiguous nature of critical input data as well as some real constraints in practice.Proposing a novel MOPSO solution method with a new solution representation modification procedure to reduce the cost of algorithm by joining the secondary resource and machine constraints’ presentations, and obtaining discrete permutation from a continuous representation.Exploiting new selection regimes within the proposed MOPSO for preserving gbest as well as pbestsolutions.Employing a generalized dominance concept in a fuzzy environment to find locally Pareto-optimal frontier.Applying a fuzzy distance measure for calculating distance between fuzzy completion times and due dates in order to schedule jobs as close as possible to their due dates.Studying the effect of two competent methods (i.e. MOPSO and a conventional MOPSO called CMOPSO) and objective spaces (test problems) on the performance metrics through a novel statistical analysis.The remainder of this paper is organized as follows. The relevant literature in UPMSP is more elaborated in Section 2 by considering the uncertainty issue. In Section 3, we define our notation, state our assumptions and propose a new fuzzy mixed-integer non-linear programming model for the proposed UPMSP problem. An introduction to particle swarm optimization along with particle swarm optimization-based scheduling literature is given in Section 4. After presenting appropriate solution representation and developing a new formulation to obtain distance between two arbitrary fuzzy numbers, we propose a novel particle swarm optimization algorithm based on the new selection regimes to solve the developed fuzzy UPMSP model in Section 5. The proposed MOPSO is validated through two classes of numerical experiments in Section 6. Performance of the proposed MOPSO is compared against a conventional MOPSO (CMOPSO) over a number of randomly generated test problems in Section 7. Finally, some concluding remarks and further research directions are provided in Section 8.The literature review reveals that majority of previous research in this area has focused on developing heuristic methods to find acceptable solutions in a reasonable time relying on the following assumptions:•All of input parameters (e.g. processing times and due dates) are deterministic;Decision variables are deterministic such as jobs’ completion times;Machines are the only limited resource when processing the jobs.There are two major drawbacks for making deterministic assumptions: (1) in many real cases, there is no enough historical data for uncertain parameters, thus, we can rarely obtain the actual value of these parameters and (2) due to inherent imprecision (ambiguousness) in the input data, we cannot measure their exact values. Thereby, because of incompleteness and/or unavailability of required data, it seems to be more realistic to consider inherent imprecision/fuzziness in the critical parameters (such as processing times and due dates). Similarly, many researchers have applied fuzzy based approaches to deal with real empirical or practical application (see e.g. [33–45]). In this way, an imprecise processing time with some tolerance values (e.g. a processing time as 40+- 5 time units) could be modeled as a fuzzy number representing the incompleteness and imprecision of required information.Mula et al. [46] review some of the existing works in the literature of production planning under uncertainty and prove that models for production planning which do not recognize the uncertainty can be expected to generate inferior planning decisions as compared to models that explicitly account for the uncertainty. They present a general classification of different approaches that have been proposed to cope with different forms of uncertainty such as environmental uncertainty and system uncertainty. In the context of PMSP, environmental uncertainty is related to uncertainties in due dates, while system uncertainty includes the uncertainties within the processing times.To cope with uncertainty issue in the context of scheduling, several fuzzy models involving the imprecise parameters have been developed in the literature. Among them, Peng and Liu [47] develop three fuzzy scheduling models: expectation scheduling model, α-scheduling model, and the most credible scheduling model for PMSM with fuzzy processing times. They propose a hybrid intelligent algorithm to solve the proposed models where fuzzy makespan, fuzzy lateness and fuzzy idleness are minimized. Anglani et al. [48] propose a robust approach to minimize total setup cost in PMSP with sequence-dependent setups. Then, a fuzzy mathematical programming model is formulated to provide optimal solution as a trade-off between total setup cost and the necessity degree.To the best of our knowledge, an UPMSP with: non-zero ready times, sequence and machine-dependent setup times, and secondary resource constraints in a fuzzy environment has not been studied before. This paper proposes a fuzzy multi-objective model based on these assumptions to minimize the aforementioned three performance criteria and develops a MOPSO solution method with some new features, which are elaborated in the following sections.We address an unrelated parallel machine scheduling problem with non-zero ready times, job sequence- and machine-dependent setup times, and the auxiliary resource constraints in a fuzzy environment. Minimizing total weighted flow time, total weighted tardiness, and machine load variation are considered as optimization objectives. Weighted flow time is a measure, which reflects work-in-process holding cost. Considering positive correlation between weighted flow time and cycle time, minimizing the former reduces the latter. Furthermore, total weighted tardiness acts as an implicit cost function. Finally, minimizing machine load variation results in a smooth schedule. Considering these three objectives simultaneously can enhance the robustness of obtained solutions.The following assumptions are considered for the problem formulation:•Each job requires an operation that can be done on all machines,Jobs’ setup times are sequence and machine dependent,Jobs may have different arrival (ready) times,Assignment of a job to a machine is permitted if the required secondary resource(s) (e.g. tool, die) is (are) available,Processing times of jobs are machine dependent,Preemption and machine breakdown are not allowed,Processing times and due dates of jobs due to possible fluctuations in real world are subject to epistemic uncertainty (i.e. lack of knowledge in estimating these parameters precisely) and therefore are treated as possibilistic data for each of which a possibility distribution is formulated in the form of a triangular fuzzy number (by relying on available objective data and mainly subjective opinions and knowledge of experts).The indices, parameters and variables used to formulate the problem mathematically are described below.Indicesi,jjob indices (i, j=1,…,N)kmachine index (k=1,…,M)grequired secondary resource index (g=1,…,G)Parametersd˜ifuzzy due date of job iriready time of job iwipriority (relative importance) of job ip˜ikfuzzy processing time of job i on machine ksijksetup time to switch from job i to job j on machine kSgset of jobs that require the secondary resource gM′an arbitrary big numberDecision variablesC˜icompletion time of job iC˜maxtotal completion timeC˜maxklargest completion time on machine kTitardiness of job iFiflow time of job iXijk=1if jobiprecedes jobjon machinek0otherwiseYik=1if jobiis assigned to machinek0otherwise.Zij=1if processing of jobiis finished before processing of jobjstarts0otherwise.According to the aforementioned assumptions and notations, the concerned problem can be formulated as the following fuzzy mixed-integer non-linear programming (FMINLP) model:Problem P:(1)MinZ1=∑i=1NwiFi=∑i=1nwi(C˜i−ri)(2)MinZ2=∑i=1NwiTi=∑i=1nwiD(C˜i,d˜i)(3)MinZ3=∑k=1MD(C˜max,C˜maxk)s.t:(4)∑i=1i≠jN∑k=1MXijk=1;∀j(5)∑i=1i≠jNXijk=Yjk;∀j,k(6)∑j=1j≠iNXijk≤Yik;∀i=1,…,N(7)C˜j+M′(1−Xijk)≥Maxi{C˜i+sijk,rj}+p˜jk;∀i,j,k(8)C˜j+M′(1−Zij)≥Max(C˜i,rj)+∑k=1Mp˜jkYjk;∀i,j∈Sg,i≠j(9)Zij+Zji=1;∀i,j∈Sg,i≠j(10)∑k=1MXijk≤Zij;∀i,j∈Sg,i≠j(11)Ti≥(C˜i−d˜i);∀i(12)Ci≥0;Ti≥0;∀i,Xijk,Yik,Zij∈{0,1};∀i,j,k.The considered objective functions, i.e. total weighted flow time (Z1), total weighted tardiness (Z2), and machine load variation (Z3) are given by Eqs. (1)–(3), respectively. Eq. (4) ensures that each job is only assigned to one position on a machine. Eq. (5) indicates that if job j is assigned to machine k, then it is followed by another job including dummy job 0. Constraint (6) stipulates that at most one job can immediately follow the previously assigned job i on machine k. Constraint (7) calculates the completion time of job j when it is processed immediately after job i on machine k. Constraints (8) and (9) guarantee that if jobs i and j require the same tool, one of them must be completed before starting the other. Constraint (10) establishes the relation between Xijkand Zij. Eq. (11) calculates tardiness of job i. Finally, Constraint (12) shows the non-negativity and integrality constraints.With the development of evolutionary computing, Kennedy and Eberhart [49] proposed a search technique, named particle swarm optimization (PSO) for optimization problems. Like GA, PSO is also a population-based stochastic optimization algorithm, inspired by the social behavior of birds and insects. In PSO, each particle flies like a bird through the solution space of the optimization problem following the particles who have found the best solutions so far. Each particle in a swarm determines its velocity based on its own past experience. The experience is derived from both the particle as an individual and as a member of the entire population. Velocity of each individual is updated with reference to: the best individual found so far by the swarm (gbest), and the best individual found previously by that individual (pbest). Each particle is commonly represented by three d-dimensional vectors: position denoted byX→i=(xi1,xi2,…,xid), velocity denoted byV→i=(vi1,vi2,…,vid), and the best personal position denoted byP→i=(pi1,pi2,…,pid). Particles have also knowledge of the best-visited global position denoted by Pg=(pg1, pg2, …, pgd). Velocity and position vectors of the particles in the solution space are updated according to the following equations:(13)vid(t+1)=w(t)vid(t)+c1r1[pid(t)−xid(t)]+c2r2[pgd(t)−xid(t)](14)xid(t+1)=xid(t)+vid(t+1)Shi and Eberhart [50] first introduced the inertia weight w, which serves as memory of previous velocities so that large inertias favor exploration while small ones favor exploitation. Cognitive and social factors are denoted by c1 and c2 which control the influence of pbestand gbeston the search process, and r1 and r2 show random numbers generated according to the uniform distribution U(0,1).The information sharing approach in PSO differs with other population-based algorithms. PSO does not apply the filtering operations such as crossover and/or mutation, and the information is only socially shared by a gbestor a local lbest[51]. Hsiao et al. [52] proposed an algorithm based on the Einstein's general theory of relativity, which utilized the concept of gravitational field to search for the global optimal solution for a given problem. Ding et al. [53] by adding both historical information and defining an adaptive mass enhance the global search ability and accelerate convergence of the simple central force optimization (SCFO) algorithm. Li et al. [54] utilized two critical operations including the self-update of reference-group and the interactive-update process between the reference-group and floating-group to find global optimum solutions. The selection of social and cognitive leaders (gbestand pbest) is the key point in multi-objective particle swarm optimization. The first attempt in applying particle swarm to multi-objective optimization was done by Moore and Chapman [55]. They modified the p-vector of the particles so that each particle keeps track of all non-dominated solutions (using Pareto preference) experienced by itself.Goh et al. [56] adapt a competitive and cooperative co-evolutionary approach for multi-objective PSO algorithm design, which appears to have considerable potential for solving complex optimization problems by explicitly modeling the co-evolution of competing and cooperating species. Qasem and Shamsuddin [57] introduce a multi-objective PSO that evolves toward Pareto-optimal front defined by several objective functions with model accuracy and complexity. Their proposed approach is simple with faster convergence to Pareto-optimal solutions. It has two main advantages; first, the proposed method can be applied to any real-world problem and second, it shows better performance in terms of error, sensitivity, specificity and accuracy for benchmark data sets. Jia et al. [58] improve multi-objective PSO by employing a novel diversity preservation strategy that combines the information of distance and angle into similarity judgment to select global best and thus the convergence and diversity of the Pareto front is guaranteed. In this manner, they can distribute enough Pareto solutions in the Pareto front evenly. Wang et al. [59] propose a novel hybrid multi-objective PSO based on Baldwinian learning mechanism that improves the local search ability of PSO, and use the Pareto dominance and crowding distance to update the solutions.Due to the simple concept, easy implementation, and quick convergence, PSO has been widely applied in a variety of optimization problems. However, because of the specific algorithmic structure of PSO (updating of position and velocity of particles in a continuous manner), few studies of PSO have been reported in the area of scheduling problems. In order to apply PSO to the scheduling problems successfully, several researchers have extended PSO or designed the encoding schemes for converting the continuous position values into the discrete job sequences. Zhang et al. [60] develop PSO algorithm to solve the multi-objective job-shop scheduling problem with several conflicting and incommensurable objectives. They show PSO which integrates local search and global search scheme possesses high search efficiency. Moslehi and Mahnam [61] present a new approach based on a hybridization of the PSO and local search algorithm to solve the multi-objective job-shop scheduling problem. Niu et al. [62] design a new solution representation based on real number encoding, which can conveniently convert the job sequences to continuous position values. In order to enhance the performance of PSO, they introduce the Clonal Selection Algorithm (CSA) into the PSO thereby proposing a new CSPSO method. Shao et al. [63] propose a hybrid discrete PSO to identify an approximation of the Pareto front for flexible job-shop scheduling problem.In this section, we propose a posteriori optimization approach, i.e. a MOPSO algorithm to solve the problem. Noteworthy, in a posteriori multi-objective approach, which is also known as generation approach, a number of efficient compromise solutions are first generated to estimate the Pareto-optimal frontier without using of any preference information provided by the decision maker. In this way, a set of Pareto-optimal solutions is provided for the decision maker by which she or he will then be able to select her/his final preferred compromise solution based upon her/his preferences.One of the most important decisions when designing a metaheuristic lies in deciding how to represent solutions and relate them in an efficient way to the searching space. Representation should be easy to decode in order to reduce the cost of the running of algorithm. Two different kinds of solution representations are used simultaneously in this research, i.e. the well-known job-to-position and continuous representation. Therefore, each particle would have a job-to-machine and a continuous representation concurrently, each of which is used in different steps of our algorithm. In the next sections, we discuss how they are used:One of the most widely used representations for scheduling problems is job-to-position representation [64]. In this kind of representation, a single row array with the size equal to the number of jobs is first formed. Since, for processing each job, the machine may need a secondary resource simultaneously, we modify the job-to-position representation in which the first row represents the location of jobs in the sequence, the next k rows show the assigned jobs to k parallel machines and the last g rows represent the priority of each job on each secondary resource. A typical job-to-position representation for k machines and g secondary resources has been shown in the Fig. 1. However, decoding this type of solution representation will raise the cost of the PSO algorithm considerably. Hence, in the next section, we take into account the continuous nature of PSO algorithm to cope with this issue.Many researchers have used the representation proposed by Tasgetiren et al. [64] for scheduling problems with continuous values. In an UPMSP, a continuous representation is an array consisting of n real values. These values indicate a particle's position in each dimension of the n-dimensional space they move in. However, the upper bound for these values limits the maximum distance that each particle is allowed to move in each iteration. In this paper, the upper bound is set to 4 while each particle could move between [0,xcmax]=[0,4]. Notably, the use of hard bounds on distance that each particle is allowed to move in each iteration, presents some problems. Obviously, the best value of this bound is problem-specific, but no reasonable rule of thumb is known so far [49]. However, in our problem, maximum distance greater than 4 would lead to growth in the oscillations of the particles, which might eventually leave the region of interest in the search space. Since the position of a particle does not represent a solution throughout the algorithm, a transformation is needed to obtain a permutation from a continuous representation and vice versa. By using a solution representation modification procedure we try to: (1) simply represent a solution and (2) convert a discrete permutation to an equivalent continuous representation and vice versa. The proposed solution representation modification procedure is as follows:1.Form the initial representation (i.e. [X]k×nand [T]g×nmatrices) as shown in Fig. 1,Sort the job position values in the [X]k×nmatrix in an ascending order for each machine,Sort the job position values in the [T]g×nmatrix in an ascending order for each secondary resource,Sort the jobs by considering the steps 2 and 3 where comparing of genes shows the priorities of jobs in using common unique tools. If two jobs with common tool are assigned to the same machine, the preceding job is given priority.For instance, consider an example with five jobs, two machines and two secondary resources. Those jobs requiring the secondary resource g are as: Sg=1={3, 5} and Sg=2={1, 2, 4}. To show the continuous representation, assume that 0.2, 2.2 and 3.7 have been assigned to job numbers 1, 3 and 4 on the first machine and 1.6 and 1.9 to job numbers 2 and 5 on the second machine, respectively as shown in Fig. 2. Based on the proposed procedure, the job position values at each row are first sorted in an ascending order and then the final sequence of jobs on each machine is obtained. Accordingly, the discrete counterpart of above continuous representation has been shown in Fig. 3.Here, the pattern of triangular possibility distribution is adopted to represent each fuzzy parameter (i.e. fuzzy processing times and due dates) in the model. Noteworthy, the possibility distribution of fuzzy processing times and due dates have been derived based on some available objective (historical) data as well as subjective data pertaining to the knowledge and experiences of decision maker(s).In the proposed fuzzy UPMSP, since the processing times and due dates are considered as fuzzy numbers, we reformulate the objective functions (1–3) based on the concept of fuzzy distance. LetA˜=(a1,a2,a3)andB˜=(b1,b2,b3)be two triangular fuzzy parameters. It is well known that the summation operator works according to the following formula:(15)A˜+B˜=(a1,a2,a3)+(b1,b2,b3)=(a1+b1,a2+b2,a3+b3)According to the Zadeh's extension principle, the membership function for the maximum of two fuzzy numbers can be obtained by the following formula:(16)μA˜∨B˜(z)=supz=A˜∨B˜{min[μA˜(x),μB˜(y)]}where ∨ shows the max operation. Based on the extension principle, it can be proved that the result of max operation is always a fuzzy number but not necessarily with a triangular pattern. For simplicity in data acquisition, we use an approximation of max formula introduced by Sakawa and Kuboto [65] as follows:(17)A˜∨B˜=(a1,a2,a3)∨(b1,b2,b3)=˜(a1∨b1,a2∨b2,a3∨b3)The max and sum operations are utilized to calculate the fuzzy starting and completion times of each job, respectively. Let us provide the following parametric definitions.Definition 1A fuzzy number u in parametric form is a pair(u_,u¯)of functionsu_(r),u¯(r),0≤r≤1that satisfy the following requirements:u_(r)is a bounded increasing left continuous function,u¯(r)is a bounded decreasing left continuous function,u_(r)≤u¯(r), 0≤r≤1The membership function for u=(x0, σ, β), a triangular fuzzy number with one defuzzifier x0, left fuzziness σ≻0, and right fuzziness β≻0, can generally be defined as:(18)u(x)=1σ(x−x0+σ)11β(x0+β−x)The parametric form of above membership function can be presented as follows:(19)u_(r)=σ(r−1)+x0,u¯(r)=β(1−r)+x0Definition 2For arbitrary fuzzy numbersu=(u¯,u_), andv=(v¯,v_), the distance between u and v in E can be calculated by using the following formula [66]:(20)D(u,v)=∫01(u_(r)−v_(r))2dr+∫01(u¯(r)−v¯(r))2dr1/2Theorem 1If u=(x0u, σu, βu) andv=(x0v,σv,βv)are two triangular fuzzy numbers, then:(21)D(u,v)=(σu−σv)23+(βu−βv)23+(x0v−x0u)[2(x0v−x0u)+(βv−βu)−(σv−σu)]1/2ProofThe proof can easily be concluded by applying Eqs. (19) and (20).In single objective optimization problems, it is easy to compare one solution to another but in multi-objective problems, a solution that is inferior to another one in one objective, may be better with respect to another objective. Under these circumstances, the concept of non-dominated solution is used.A general multi-objective minimization problem with p decision variables and q objectives (q>1) can be presented as: Miny=f(x)=(f1(x), f2(x), …, fq(x)), where x∈Rp, and y∈Rq. A solution x* is non-dominated (Pareto-optimal) if there is no other solutions x∈Rpsuch that fi(x)≤fi(x*), ∀i with at least one strict inequality.However, for our concerned problem, we are interested not to convert the original fuzzy objective vector into its equivalent crisp vector. To achieve this, we need work with fuzzy non-dominated solutions (see Koduru et al. [67] for more details about the concept of fuzzy dominance).Notably, the most of current approaches concentrate on adapting an evolutionary algorithm to generate the Pareto frontier. Fernandez et al. [68] presented a new idea to incorporate preferences into a multi-objective evolutionary algorithm. They introduced a binary fuzzy preference relation that expresses the degree of truth of the predicate “x is at least as good as y”. On this basis, a strict preference relation with a reasonably high degree of credibility can be established on any population. Panigrahi et al. [69] used fuzzy dominance based sorting procedure to select the Pareto optimal front for multi-objective bacterial foraging optimization technique. Lei [70] proposed multi-objective PSO to solve fuzzy job shop scheduling problem. He formed Pareto archive PSO, in which the global best position selection is combined with the crowding measure-based archive maintenance. Recently, Di Martino and Sessa [71] extended a new Fuzzy PSO algorithm to determine hotspot areas where the data are events geo-referenced as points on the geographic map.In this work, our main objective is to estimate the Pareto-optimal frontier in a fuzzy domain. Consequently, we have developed a fuzzy Multi-objective PSO using fuzzy dominance based ranking methods. Many techniques for ranking fuzzy numbers have been proposed since 1976. Chen and Hwang [72] classified ranking methods into four major categories: preference relation, fuzzy mean and spread, fuzzy scoring, and linguistic expression. However, the centriod-based distance method suggested by Cheng [73] is adopted here due to its strong theoretical foundation and good results reported in the literature, in which fuzzy numbers are ranked based on their Euclidean distance from their centriod points to the origin. Wang et al. [74] refuted the centriod formula provided by Cheng [73] and presented the accurate form.Definition 3For a plane area A, bounded by two continuous curves y=y1(x), y=y2(x) where y1(x)≤y2(x) and two lines x=a, x=b, the static moments and coordinates of the respective centriod are calculated according to the following equations:(22)Mx=12∫ab(y22−y12)dx;My=∫abx(y2−y1)dx(23)xc=MyS;yc=MxSwhere xcand ycare coordinates of the centriod of A, respectively, and S denotes the area of the plane A.Theorem 2If A is characterized by the inverse function of a triangular fuzzy number inFig. 4, then:(24)xc=x0+β−σ3;yc=13ProofThe proof can easily be concluded through applying Eqs. (22) and (23).Finally, the greatest associated Euclidean distanceR=xc2+yc2is used to rank the triangular fuzzy numbers.Real values are considered for velocities because of the fact that positions of particles (denoted by [X]k×n) have continuous form. The size of the velocity matrix is the same as that of the position matrix. Initial velocity matrices are generated as follows:(25)vij(k)=(vmin+(vmax−vmin)*r1)wherevmin=−4,vmax=4, and r1 is a uniform random variable between [0,1]. The range of acceptable velocity values (i.e.[vmin,vmax]) is chosen so that|vij(k)|≤XCmaxwherevij(k)denotes velocity of job j on machine i for the k-th particle.The procedure for updating particle velocities and positions is principally similar to single objective optimization. The difference lies in the way particle movements are updated. In this paper, each particle is allowed to have an archive consisting of its best previous positions. As new pbestsolution are added to the archive, solutions that consequently become dominated are discarded from the archive. As a result, this set will ultimately represent an approximation of Pareto front found by that particle. Despite more complexity of this approach compared to preserving only one pbest, enhanced search capability would compensate for the computational cost.According to the literature, gbestmethods can fall into two categories: unrestricted and restricted. ‘Unrestricted’ approach allows for gbestto be selected for a given member of swarm from anywhere in the archive. In contrast, ‘restricted’ approach constrains the possible gbestfor a given individual by using some form of distance measure. Fieldsend [75] show that although the later group is more desirable, there are some adverse consequences associated with this approach.Our proposed approach employs a combination of these two gbestcategories. In order to maintain diversity of search direction and to avoid premature convergence to local optima, each gbestis given a chance. The employed procedure can be clarified by the following example: assume that 100 individuals and 8gbestarchive-members exist in a given problem. The quotient of 100÷8=12 provide chance of each gbestin updating process of particle velocities. It is clear that some particles (100−12×8=4 particles) are not yet assigned a gbest. Therefore, the gbestswith the highest crowding distance values are given extra chance, i.e. four gbestsare selected 13 times as a social leader, while the remaining gbestswill have a 12-time chance. To allocate a gbestto each individual, the minimal Euclidean distance approach is applied.After determining the appropriate gbestfor each particle, the pbestwith maximum distance from the selected gbestfor each particle is chosen. The reason is that each particle is pushed/pulled toward/from its pbestand gbestoperating points along its current velocity; thereby generating a hypercube in the solution space. Selecting the pbestwith the maximum distance in this situation will expand this bounded region.Finally, the particle velocities and positions are updated using Eqs. (13) and (14). The inertia weight is updated asw(t)=w(t−1)×βwhere β is a decremental factor to control the effect of inertia weight on exploration and exploitation. In each generation, the gbestarchive set is updated as follows. With the new solution being added, solutions that consequently become dominated are excluded from both pbestand gbestarchives. Updating gbestarchive set in each iteration in presence of three objective functions with discrete matrices of decision variables, require considerable time. In order to reduce this time and based upon the observations made during our experimentations, we decided not to put a bound on the archive size. In other words, all non-dominated solutions are maintained in the archive.The above procedure is implemented for a number of predetermined iterations and the final non-dominated gbestarchive set is reported as the result. The following pseudo code summarizes main steps of the proposed algorithm:•Initialize a population of particles with random positions,Generate random velocities using Eq. (25),Construct the personal Pareto archive for each particle to store the best individual found so far,Construct the global Pareto archive which is empty at the beginning,Repeat the following procedure for a predetermined number of iterations:Perform fast-non-dominated sorting,Update the global Pareto archive,Determine the best global position matrix for each particle using the procedure explained in Section 3.5,Determine the best personal position matrix for each particle using the procedure explained in Section 3.5,Update the velocity and position of each particle using Eqs. (13) and (14), respectively.Update the personal Pareto archive of each particle,Report solutions of global Pareto archive as final non-dominated solutions.

@&#CONCLUSIONS@&#
This paper proposes a new fuzzy multi-objective programming model for solving an unrelated parallel machine scheduling problem when non-zero ready times, sequence and machine dependent setup times, and secondary resource constraints are taken into account simultaneously. In order to find locally Pareto-optimal frontier, a posteriori optimization approach, i.e. a MOPSO is proposed to minimize total weighted flow time, total weighted tardiness and total machine load variation concurrently. The centriod-based distance method was used to apply dominance concept in fuzzy environment. In addition, a new selection regime for gbestwas proposed that integrates two common gbestselection methods in the literature (i.e. ‘unrestricted group and ‘restricted’ group). This procedure helps maintaining diversity by pushing particles toward different parts of the Pareto front. It is allowed for each particle to have an archive to store more personal bests by applying Pareto dominance. Performance of the proposed MOPSO algorithm was compared with a conventional approach called CMOPSO. To validate the efficiency and effectiveness of the proposed algorithm, three performance metrics were used. Experimental results show that the proposed MOPSO outperforms the CMOPSO in all of these metrics.There are some possible directions for further research. Among them, it would be nice to include some indications regarding the quality of the solutions obtained using the proposed fuzzy model in comparison with the corresponding “crisp” model. Noteworthy, there are many situations where the consideration of uncertainty leads to better solutions. Many scholars show that a few of scheduling problem studies take uncertainty into account, in particular the imprecision in time estimates [78]. Nevertheless, we proposed a new MOPSO algorithm to cope with both imprecision of some critical input data and computational complexity of formulated multi-objective which demonstrated promising results for solving such scheduling problems in real sizes.