@&#MAIN-TITLE@&#
Multidimensional folding for sinusoidal order selection

@&#HIGHLIGHTS@&#
The order estimation algorithm relies on multidimensional folding combined with ESTimation ERror criterion.Multidimensional folding and unfolding construct two matrix slices that satisfy the shift invariance equality.The ESTER criterion estimates number of harmonics based on shift invariance equality.The algorithm is able to identify significantly more harmonics.The algorithm is robust against colored noise.

@&#KEYPHRASES@&#
Sinusoidal order selection,Harmonic retrieval,Multidimensional folding (MDF),Estimation error (ESTER),Shift invariance equality,

@&#ABSTRACT@&#
Estimation of the number of harmonics in multidimensional sinusoids is studied in this paper. The ESTimation ERror (ESTER) is a subspace based detection approach that is robust against colored noise. However, the number of signals it can detect is very limited. To improve the identifiability, we propose to combine the multidimensional folding (MDF) techniques with ESTER for multidimensional sinusoidal order selection. Our algorithm development is inspired by the shift invariance properties of the two matrix slices resulting from multidimensional folding and unfolding, which have been exploited to extract the spatial frequencies in the literature. The maximum identifiable number of signals of the MDF-ESTER is of the order of magnitude of product of the lengths of all spatial dimensions with uniform spacing, which is significantly larger than that of the conventional multidimensional ESTER methods. Meanwhile, it inherits the robustness of the ESTER against colored noise, and performs comparably to state-of-the-art schemes when the number of signals is small.

@&#INTRODUCTION@&#
Multidimensional sinusoidal frequency estimation or harmonic retrieval (HR) [1] has numerous applications ranging from multiple-input multiple-output (MIMO) radar imaging [2], channel estimation in wireless communication systems [3–5] to nuclear magnetic resonance (NMR) spectroscopy [6,7]. Parametric approaches to N-dimensional (N-D) frequency estimation, e.g., N-D unitary estimation of signal parameters via rotational invariant techniques (ESPRIT) and its variants [8–11], N-D multiple signal classification (MUSIC) [12], multidimensional folding (MDF) [13,14], improved MDF [15], N-D rank reduction estimator (RARE) [16] and principal-singular-vector utilization for modal analysis (PUMA) [17,18] provide super-resolution estimation performance. However, they rely on the a priori knowledge of the number of signals, which is often unknown and must be estimated from the noisy multidimensional measurements. As a matter of fact, it is a challenge to accurately determine the number of complex sinusoids from noisy N-D data, because the noise is usually spatially color, thereby calling for development of robust methodologies for sinusoidal order estimation.In matrix case, it is common to use the eigenvalue spectrum for detecting the number of signals. Classical eigenvalue based order selection rules include the information theoretic criterion based methods [19] such as minimum description length (MDL) [20] and Akaike information criterion (AIC) [21], which are optimal in the fixed dimension-length large sample-size asymptotic regime, and the random matrix theory (RMT) based algorithms [22–25] that are designed for large dimension-length but relatively small sample-size scenarios. All these algorithms rely on the assumption that the noise is independent and identically distributed (i.i.d.) Gaussian. For correlated noise environment, they generally suffer a performance degradation.To handle colored-noise scenarios, a number of subspace based methods that exploit the eigenvectors have been proposed [26–30]. In [26,31], the ESTimation ERror (ESTER) has been proposed for detecting the number of complex sinusoids, namely, uniform harmonics. It utilizes the shift invariance property of the signal subspace spanned by the sinusoids. Later in [27], an improved version of ESTER called subspace based automatic model order selection (SAMOS) is developed by exploiting the singular values of the signal subspace matrix. Although with better performance, the number of identifiable signals of SAMOS is reduced by half compared with ESTER. Compared with the eigenvalue based methods, the subspace based methods are more robust against colored noise.However, these methods do not have direct multilinear counterparts that correspond to the multidimensional sinusoidal order selection problem at hand. To handle that, in [32,33] the ESTER is extended to N-D case based on the higher-order singular value decomposition (HOSVD). By combining the shift invariance equalities of the sinusoidal signal subspace in all dimensions, the N-D ESTER provides an improvement over n-mode ESTER in probability of correct detection (PoD) as well as robustness against colored noise. However, the number of detectable signals is limited to the maximum spatial dimension length minus 2.To improve the identifiability, we propose to apply the MDF techniques [13,14] combined with the ESTER criterion for multidimensional sinusoidal order selection. The idea of multidimensional folding is to extend an N-D tensor to a(2N+1)-D tensor and then nest the augmented tensor to a 3-D tensor (the length of the(2N+1)-th and third dimension are both equal to 2) by dimensionality embedding. The two matrix slices of the resultant 3-D tensor satisfy the shift invariance equation11For undamped (constant-modulus) sinusoidal model, instead of constructing an additional dimension of length 2, forward–backward averaging [34] is exploited to construct the shift invariance equation in [14].based on which the spatial frequencies have been extracted [13,14]. In this work, we exploit the same shift invariance properties of the two matrix slices to estimate the sinusoidal order using the ESTER criterion.The maximum identifiable number of signals of the MDF-ESTER is on the order of magnitude of∏nIn, where n indexes the uniform-spacing spatial modes of the observation tensor, andInis the corresponding dimension length. This indicates a significant improvement over [32,33]. Meanwhile, it inherits the robustness of the ESTER against colored noise, and its performance is comparable to the existing N-D ESTER schemes [32,33] when the number of signals is small.The remainder of this paper is organized as follows. In Section 2, we present the N-D HR data model. In Sections 3 and 4, our proposed algorithms with integration of multidimensional folding and ESTER for N-D sinusoidal order estimation are described. Section 3 is devoted to the single-snapshot case, while Section 4 addresses the multiple-snapshot case. Simulation results are provided in Section 5, and in Section 6, conclusions are drawn.In order to facilitate the distinction between scalars, matrices and tensors, the following notation is used: Scalars are denoted as italic letters (a,b,…,A,B,…,α,β,…), column vectors as lower-case bold-face letters (a,b,…), matrices as bold-face capitals (A,B,…), and tensors as bold-face calligraphic letters (A,B,…). Lower-order parts are consistently named: the(i,j)-entry of a matrixAis denoted asai,j, and the(i,j,k)-entry of a third-order tensorAasai,j,k. The superscripts ⁎, T, H and † stand for complex conjugate, transpose, Hermitian transpose and Moore–Penrose pseudo inverse, respectively. The‖A‖Fand‖A‖2denote the Frobenius norm and spectral norm ofA, respectively. Theσmax(A)andσmin(A)denote the largest singular value and smallest non-zero singular value ofA, respectively. We use ⋄ for the Khatri–Rao (column-wise Kronecker) product of two matrices with common number of columns, ∘ for the outer product,⌈⋅⌉for integer ceiling, and⌊⋅⌋for integer floor.The tensor operations align with [35]: The n-mode vectors of a tensorX∈CI1×I2×⋯×INare obtained by varying the n-th index within its range (1,…,In) and keeping all other indices fixed. The n-mode product ofXandU∈CJn×Inalong the n-th mode, denoted asX×nU∈CI1×I2⋯×Jn⋯×IN, is obtained by multiplying the n-mode vectors ofXfrom the left-hand side byU.The noisy observations are modeled as a superposition of R damped/undamped N-D cisoids sampled on an N-D grid of sizeI1×⋯×INat T subsequent time instants:(1)xi1,…,iN,t=∑r=1Rsr(t)∏n=1Ne(in−1)(ζr(n)+jμr(n))+ni1,…,iN,t(c),in=1,2,…,In,n=1,2,…,N,t=1,2,…,T,whereμr(n)andζr(n)≤0denote respectively the frequency and damping factor of the i-th cisoid in the n-th mode. The cisoid is undamped whenζr(n)=0and damped whenζr(n)<0. Thesr(t)is the complex amplitude of the r-th cisoid at time instant t, andni1,…,iN,t(c)models the additive colored noise component inherent in the measurement process [36–39]. Here,T≥1is the number of snapshots in the temporal dimension, andT=1andT>1correspond to single-snapshot and multiple-snapshot N-D sinusoid models, respectively.Denote(2)ar(n)=a(ζr(n)+jμr(n))=[1eζr(n)+jμr(n)⋮e(In−1)(ζr(n)+jμr(n))]as the array steering vector of the i-th signal in the n-th mode, andsr=[sr(1),…,sr(T)]Tas the amplitude vector of the i-th signal. In tensor form, (1) is expressed as(3)X=∑r=1Rar(1)∘ar(2)∘⋯∘ar(N)∘sr+N(c),whereXandN(c)∈CI1×⋯×IN×Tare the observation and noise tensors, respectively. In the absence of noise,Xis a sum of R rank-one tensors (outer-product of vectors) [40] each of which corresponds to an N-D cisoid. Given the noisy measurement tensorX, our goal is to estimate the number of cisoids R.LetA(n),n=1,2,…,N, be the array steering matrix that collects all the array steering vectors in the n-th mode:A(n)=[a1(1)⋯aR(1)]=[1⋯1eζ1(n)+jμ1(n)⋯eζR(n)+jμR(n)⋮⋱⋮e(In−1)(ζ1(n)+jμ1(n))⋯e(In−1)(ζR(n)+jμR(n))],andS=[s1s2…sR]∈CT×Rcontains the complex amplitudes of R cisoids at all N samples. Using n-mode products, (3) can be rewritten as(4)X=IN+1,R×1A(1)⋯×NA(N)×N+1S+N(c),whereIN+1,Rrepresents the N-D identity tensor of sizeR×R⋯×R, whose elements are equal to one wheni1=i2=⋯=iN+1and zero otherwise.It is worth noting that our proposed detection algorithm can be also applied in the partly uniform multidimensional HR model, where only part (but at least 1) of the factor matricesA(n),n=1,2,…,N, have a Vandermonde structure. Such a partly uniform multidimensional HR model may appear in array processing which employs a uniform linear or rectangular array at the transmitter while a non-uniform antenna array at the receiver, or an antenna array with uniform spacing along one array axis but non-uniform spacing along the other axis [1]. For the partly uniform multidimensional HR model, the (spatial) dimensions with a non-uniform structure are merged with the temporal dimension via block unfolding [41,42] so that the temporal dimension in (1) accounts for these non-exponential dimensions as well.Consider the N-D damped/undamped sinusoidal model and denotezr,n=eζr(n)+jμr(n),r=1,2,…,R,n=1,2,…,N, hereafter for brevity in notation. For the single-snapshot (T=1) case,Xis N-D and the signals along all N dimensions are exponential cisoids. TheXis extended/augmented and then folded into a(2N+1)-D tensorX+, in the same line as [13]:(5)xi1,1,i2,1,i1,2,i2,2,…,i1,N,i2,N,iSI,1+=xi1,1+i2,1+iSI,1−2,i1,2+i2,2−1,…,i1,N+i2,N−1,wherei1,n=1,2,…,I1,n,i2,n=1,2,…,I2,nforn=1,2,…,N, andiSI,1=1,2, with(6a)ISI,1=2(6b)I1,1+I2,1+ISI,1=I1+2(6c)I1,n+I2,n=In+1,n=2,…,NIn (5), the 1-mode vectors ofXof sizeI1×1are arranged as a three-way array of sizeI1,1×I2,1×ISI,1, and its n-mode vectors of sizeIn×1,n=2,…,N, are arranged as a Hankel matrix (a square matrix with constant skew-diagonals) of sizeI1,n×I2,n, as illustrated in Fig. 1. As will be clear later, the dimension indexed byiSI,1is used to construct the shift invariance equality.In the absence of noise,X+∈CI1,1×I2,1×I1,2×I2,2×⋯×I1,N×I2,N×ISI,1is represented in scalar form as(7)xi1,1,i2,1,i1,2,i2,2,…,i1,N,i2,N,iSI,1+=∑r=1Rsrzr,1iSI,1−1∏n=1Nzr,ni1,n−1zr,ni2,n−1,and in tensor form asX+=D2N+1,R×1A1(1)×2A2(1)⋯×2N−1A1(N)×2NA2(N)×2N+1ASI(1),whereD2N+1,Rrepresents the(2N+1)-D superdiagonal tensor of sizeR×R⋯×R, whose elements are all zeros except that the i-th diagonal element is equal tosr,(8)A1(n)=[11⋯1z1,nz2,n⋯zR,n⋮⋮⋱⋮z1,nI1,n−1z2,nI1,n−1⋯zR,nI1,n−1]∈CI1,n×R,(9)A2(n)=[11⋯1z1,nz2,n⋯zR,n⋮⋮⋱⋮z1,nI2,n−1z2,nI2,n−1⋯zR,nI2,n−1]∈CI2,n×Rforn=1,2,…,N, and(10)ASI(1)=[11⋯1z1,1z2,1⋯zR,1]∈C2×R.By merging/unfolding/collapsing the1,3,…,2N−1dimensions and2,4,…,2Ndimensions ofX+into one dimension, respectively, in the same way as described in [13], we obtain(11)X+‾=D3,R×1A1×2A2×3ASI(1),where(12)A1=A1(N)⋄A1(N−1)⋄⋯⋄A1(1)∈CI1,1I1,2⋯I1,N×R,(13)A2=A2(N)⋄A2(N−1)⋄⋯⋄A2(1)∈CI2,1I2,2⋯I2,N×R.The two matrix slices ofX+‾along the third dimension are [40](14)X1+=A1diag{s}A2T∈CI1,1I1,2⋯I1,N×I2,1I2,2⋯I2,N(15)X2+=A1Φ(1)diag{s}A2T∈CI1,1I1,2⋯I1,N×I2,1I2,2⋯I2,Nwhere(16)s=[s1s2⋯sR](17)Φ(1)=diag{[z1,1z2,1⋯zR,1]}.Fig. 2illustrates the multidimensional folding/unfolding process for a two-way tensor (i.e., matrix) of size7×4, whereI1,1=4,I2,1=3,I1,2=2, andI2,2=3.SinceA1andA2are the Khatri–Rao products of N Vandermonde matrices, according to Proposition 4 of [13], when(18)R≤min⁡(I1,1I1,2⋯I1,N,I2,1I2,2⋯I2,N),bothA1andA2are almost surely (a.s.) of full rank R. Therefore,X1+,X2+and hence(19)X+=[X1+X2+]=[A1A1Φ(1)]diag{s}A2Thave rank R. On the other hand, by applying the singular value decomposition onX+, we obtain(20)X+=UΛVHwhereU∈C2I1,1I1,2⋯I1,N×2I1,1I1,2⋯I1,NandV∈CI2,1I2,2⋯I2,N×I2,1I2,2⋯I2,Nare unitary matrices containing the left and right singular vectors, respectively, and Λ is a diagonal matrix collecting the singular values sorted in descending order. Let(21)Ur=[Ur,1Ur,2]collect the r leftmost columns ofU. From the comparison between (19) and (20), it follows that in the absence of noise,(22)UR=[UR,1UR,2]and[A1A1Φ(1)]span the same subspace. Therefore, there exists a non-singular matrixT∈CR×Rsuch that(23)[A1A1Φ(1)]=[UR,1UR,2]T.It follows that(24)A1=UR,1T,A1Φ(1)=UR,2T,and hence there existsΨR=UR,1†UR,2=TΦ(1)T−1such that(25)UR,1ΨR=UR,2.Equation (25) is called the shift or rotational invariance equation. The shift invariance property of the sinusoidal signal model has been used by ESPRIT [43] to estimate the frequencies.The ESTER [26,31] selects an appropriate model order based on the rotational invariance property of the signal subspace spanned by the sinusoids. It was derived by minimizing the error bound induced by passing an under-estimated model order to ESPRIT [43]. In this subsection, we will provide a brief derivation of ESTER based on the new shift invariance equation (25) obtained from MDF.Define(26)Er=Ur,1Ψr−Ur,2,withΨr=Ur,1†Ur,2.In case thatr<R, the shift invariance equation (25) is not satisfied, and we have the following theorem.Theorem 3.1In the absence of noise, for each eigenvaluezˆofΨr, there exists an eigenvaluezrofΨR=UR,1†UR,2such that(27)|zˆ−zr|≤κ2‖Ur,1Ψr−Ur,2‖2where(28)κ2=σmax([A1A1Φ(1)])σmin(A1).ProofThe result can be obtained using the similar derivation process of [26]. For ease of reference, the proof is provided in Appendix A.  □When1≤r<R, Theorem 3.1 indicates that the estimation error‖Er‖2>0. This is because the eigenvalues ofΨR=TΦ(1)T−1andΦ(1)share the same set of eigenvalues{z1,1,z2,1,…,zR,1}, namely, the set of cisoids in the first mode, while in generalzˆ∉{z1,1,z2,1,…,zR,1}and thus|zˆ−zr|>0. On the other hand, whenr>R, it also holds that‖Er‖2>0since the noise eigenvectors do not satisfy the shift invariance property22LetP(r)=II1,1I1,2⋯I1,N−Ur,1Ur,1†be the projector onto the orthogonal complement ofN(Ur,1). Ifr>R,N(UR,2)=N(UR,1)⊂N(Ur,1), thereforeP(r)UR,2=0I1,1I1,2⋯I1,N×R. SinceEr=P(r)Ur,2, the R left columns ofErare zero. However, the(r−R)right columns ofErdo not belong toN(Ur,1)in the general case, therefore the(r−R)right columns ofErare non-zero, and the error bound is positive.[26].Therefore, the minimum of zero of‖Er‖2is reached only atr=R. In practice, noise is present, and the estimated signal number, denoted byRˆMDF−ESTER, is obtained by minimizing the residual error:(29)RˆMDF−ESTER=argminr=1,2,…,Rmax‖Ur,1Ψr−Ur,2‖22,whereRmaxis the largest possible number of detectable cisoids and is stipulated by (18).To maximize the number of detectable cisoids,I1,nandI2,n,n=1,2,…,N, are chosen according to (6) and (18) as(30){ifI1is evenI1,1=I2,1=I1/2ifI1is oldI1,1=I1−12,I2,1=I1+12,and forn=2,…,N,(31){ifInis evenI1,n=In2,I2,n=In+22ifInis oldI1,n=I2,n=In+12.As a result, the maximum number of detectable cisoids is33Note that in addition tor=R, the shift invariance equation (25) is also always satisfied whenr=I1,1I1,2⋯I1,Nin which caseUr,1andUr,2are both square matrices. To exclude this trivial case so that the number of signals R can be correctly detected, we assume that the candidate valuer≤I1,1I1,2⋯I1,N−1.(32)Rmax=⌊I12⌋∏n=2N⌈In2⌉−1For the constant-modulus (i.e.,ζr(n)=0) sinusoidal model, forward–backward averaging (FBA) [34] can be exploited. In addition to bringing a performance improvement (cf. Section 5), the incorporation of FBA yields a pair of matrices that satisfy the shift invariance equality, thus avoiding the need to construct the additional length-2 dimension indexed byiSI,1, as shown below.The N-D noisy signalXis folded (extended) into a 2N-D tensor [14]:(33)xi1,1,i2,1,i1,2,i2,2,…,i1,N,i2,N+=xi1,1+i2,1−1,i1,2+i2,2−1,…,i1,N+i2,N−1,wherei1,n=1,2,…,I1,n,i2,n=1,2,…,I2,n, with(34)I1,n+I2,n=In+1,n=1,2,…,NIn the absence of noise, the scalar and tensor representations of the resultant 2N-D tensorX+are respectivelyxi1,1,i2,1,i1,2,i2,2,…,i1,N,i2,N+=∑r=1Rsr∏n=1Nej(i1,n−1)μr(n)ej(i2,n−1)μr(n),andX+=D2N,R×1A1(1)×2A2(1)…×2N−1A1(N)×2NA2(N),whereA1(n)=[11⋯1ejμ1(n)ejμ2(n)⋯ejμR(n)⋮⋮⋱⋮ej(I1,n−1)μ1(n)ej(I1,n−1)μ2(n)⋯ej(I1,n−1)μR(n)]A2(n)=[11⋯1ejμ1(n)ejμ2(n)⋯ejμR(n)⋮⋮⋱⋮ej(I2,n−1)μ1(n)ej(I2,n−1)μ2(n)⋯ej(I2,n−1)μR(n)].By merging/unfolding/collapsing the1,3,…,2N−1dimensions and2,4,…,2Ndimensions ofX+into one dimension, respectively, along the same line as [14], we obtain(35)X+=A1diag{s}A2T,where(36)Ab=Ab(N)⋄Ab(N−1)⋄⋯⋄Ab(1)∈CIb,1…Ib,N×R,b=1,2Next, we apply conjugation and then sequential rotations of 180 degrees of the entries ofXalong individual dimensions to obtain a new tensorY:(37)Y=.X⁎×1ΠI1⋯×NΠIN,whereΠIndenotes theIn×Inexchange matrix having ones on its antidiagonal and zeros elsewhere.In the absence of noise, the entries ofYcan be shown to be(38)yi1,…,iN=.xI1+1−i1,…,IN+1−iN⁎=∑r=1Rs˜r∏n=1Nej(in−1)μr(n),in=1,2,…,In,n=1,2,…,N,wheres˜r=sr⁎∏n=1Ne−j(In−1)μr(n). We see thatYcontains the same cisoids asX.Following the same procedure as in the construction ofX+fromX, we can construct a matrix fromYas(39)Y+=A1diag{s˜}A2T∈CI1,1I1,2⋯I1,N×I2,1I2,2⋯I2,N,wheres˜=[s˜1s˜2⋯s˜R].Figs. 3 and 4respectively illustrate the forward and backward parts of the folding/unfolding process for a two-way tensor (i.e., matrix) of size7×4, whereI1,1=I2,1=4,I1,2=2, andI2,2=3.According to Proposition 4 of [13], when(40)R≤min⁡(I1,1I1,2⋯I1,N,I2,1I2,2⋯I2,N),bothA1andA2are a.s. full column rank R. Therefore,X+andY+have full column rank R. Let(41)Ur=[Ur,1Ur,2]withUr,1,Ur,2∈CI1,1I1,2⋯I1,N×R, collect the r left singular vectors associated with the r largest singular values of(42)[X+Y+]=[A1diag{s}A1diag{s˜}]A2T.In the absence of noise, there exists a non-singular matrixT∈CR×Rsuch that(43)[A1diag{s}A1diag{s˜}]=URT=[UR,1UR,2]T.From (43), it follows thatA1diag{s}=UR,1T,A1diag{s˜}=UR,2T, and hence(44)UR,1ΨR=UR,2whereΨR=T(diag{s})−1diag{s˜}T−1.In a similar manner of Section 3.1, it can be shown that in the absence of noise,‖Ur,1Ψr−Ur,2‖2>0whenr≠R. In particular, forr<R,‖Ur,1Ψr−Ur,2‖2is lower bounded by the absolute difference between an eigenvaluezˆofΨr=Ur,1†Ur,2and its closest eigenvaluezr∈{s1⁎/s1∏n=1Ne−j(In−1)μ1(n),…,sR⁎/sR∏n=1Ne−j(In−1)μR(n)}ofΨR:(45)|zˆ−zr|≤κ2″‖Ur,1Ψr−Ur,2‖2where(46)κ2″=σmax([A1diag{s}A1diag{s˜}])σmin(A1diag{s}).Therefore, the signal number can be determined as(47)RˆMDF−ESTER=argminr=1,2,…,Rmax‖Ur,1Ψr−Ur,2‖22,whereRmaxis stipulated by (40).To maximize the number of detectable cisoids,I1,nandI2,n,n=1,2,…,N, are chosen as(48){ifInis evenI1,n=In2,I2,n=In+22ifInis oldI1,n=I2,n=In+12.As a consequence, the maximum number of detectable cisoids is(49)Rmax=∏n=1N⌈In2⌉−1For small sensor arrays or large dimensions N and whenI1is odd, (49) represents a non-trivial gain in detectability over (32).For the multiple-snapshot case, the size of the nonexponential/temporal dimension isT>1. When T is sufficiently large, e.g.,T≥I1I2⋯IN, one of the N spatial dimensions of the(N+1)-D tensorXis used to construct the length-2 dimension indexed byiSI,1, while the remaining dimensions stay unchanged, in the same line as [13] (cf. Section VI.C in [13]):xi1,1,i2,…,iN,t,iSI,1+=xi1,1+iSI,1−1,i2,…,iN,t,wherei1,1=1,…,I1,1=I1−1,iSI,1=1,2, and for ease of exposition of the algorithm, we have assumed that the first dimension is chosen for folding.In the absence of noise, the resultant(N+2)-D tensorX+∈CI1,1×I2×⋯×IN×2can be represented in scalar form as(50)xi1,1,i2,…,iN,t,iSI,1+=∑r=1Rsr(t)zr,1iSI,1−1zr,1i1,1−1∏n=2Nzr,nin−1,and in tensor form as(51)X+=IN+2,R×1A1(1)×2A(2)⋯×NA(N)×N+1S×N+2A2(1),where(52)A1(1)=[11⋯1z1,1z2,1⋯zR,1⋮⋱⋮z1,1I1,1−1z2,1I1,1−1⋯zR,1I1,1−1]∈CI1,1×R,(53)A2(1)=[11⋯1z1,1z2,1⋯zR,1]∈C2×R.Denote the two matrix slices ofX+along the(N+2)-th dimension respectively as(54)X1+=AST∈CI1,1I2…IN×T(55)X2+=AΦ(1)ST∈CI1,1I2…IN×Twhere(56)A=A(N)⋄⋯⋄A(2)⋄A1(1)∈CI1,1I2…IN×R,(57)Φ(1)=diag{[z1,1z2,1…zR,1]}.Fig. 5illustrates the folding/unfolding process for a two-way tensor (i.e., matrix) of size7×8, whereT=8is the number of temporal snapshots.According to Proposition 4 of [13], as the Khatri–Rao product of N Vandermonde matrices,Ahas full rank a.s. It follows that when(58)R≤min⁡(I1,1I2…IN,T),we have(59)X+=[X1+X2+]=[AAΦ(1)]SThas rank R. Let(60)Ur=[Ur,1Ur,2],withUr,b∈CI1,1I2…IN×R,b=1,2, collect the r left singular vectors associated with the largest singular values of most columns ofX+. In the absence of noise,(61)UR=[UR,1UR,2]and[AAΦ(1)]span the same subspace and hence there exists a non-singular matrixT∈CR×Rsuch that(62)[AAΦ(1)]=[UR,1UR,2]T.It then follows that(63)UR,1ΨR=UR,2whereΨR=TΦ(1)T−1.Define(64)Ψr=Ur,1†Ur,2.In the case ofr<R, in a similar way of [26] and Theorem 3.1, we can prove that in the absence of noise,‖Ur,1Ψr−Ur,2‖2is lower bounded by the absolute difference between an eigenvaluezˆofΨrand its closest eigenvaluezr∈{z1,1,z2,1,…,zR,1}ofΨR:(65)|zˆ−zr|≤κ2′‖Ur,1Ψr−Ur,2‖2where(66)κ2′=σmax([AAΦ(1)])σmin(A).Whenr>R, it also holds that‖Er‖2>0following a similar argument of Section 3.1 (see the note therein). Therefore, in the absence of noise the minimum of zero of‖Er‖2is reached only atr=R. When noise is present, the signal number can be estimated by minimizing the estimation error:(67)RˆMDF−ESTER=argminr=1,2,…,Rmax‖Ur,1Ψr−Ur,2‖22.Taking into account thatI1,1=I1−1, it follows that the maximum number of detectable signals is(68)Rmax=min⁡(I1,1I2⋯IN−1,T)=min⁡(I1I2⋯IN[1−1I1]−1,T).By choosing the dimension of maximum lengthn0=argmaxnInfor folding, the maximum number of detectable signals is increased to(69)Rmax=min⁡(I1I2⋯IN[1−1In0]−1,T).When T is relatively small, e.g.,T≪I1I2⋯IN, the identifiability stipulated by (69) is limited. To handle that, one or more spatial dimensions can be transformed/splitted into two dimensions via MDF. For instance, supposen0=1in (69) and folding the second spatial dimension yields(70)xi1,1,i1,2,i2,2,i3,…,iN,t,iSI,1+=xi1,1+iSI,1−1,i1,2+i2,2−1,i3,…,iN,t,=∑r=1Rzr,1i1,1−1zr,2i1,2−1zr,2i2,2−1∏n=3Nzr,nin−1⋅sr(t)⋅zr,1iSI,1−1,wherei1,1=1,…,I1−1,iSI,1=1,2,i1,2=1,2,…,I1,2,i2,2=1,2,…,I2,2, withI1,2+I2,2=I2+1.In tensor form, (70) is expressed as(71)X+=IN+3,R×1A1(1)×2A1(2)×3A2(2)×4A(3)…×N+1A(N)×N+2S×N+3A2(1),whereAb(1)andAb(2),b=1,2, are defined in (52)–(53) and (8)–(9), respectively.By merging/unfolding/collapsing the1,2,4,…,N+1dimensions and3,N+2dimensions ofX+into one dimension, respectively, we obtain(72)X+‾=I3,R×1A˜×2S˜×3A2(1),where(73)A˜=A(N)⋄⋯⋄A(3)⋄A1(2)⋄A1(1)∈CI1,1I1,2I3⋯IN×R,(74)S˜=A2(2)⋄S∈CI2,2T×R.The two matrix slices ofX+along the third dimension are(75)X1+=A˜S˜T∈CI1,1I1,2I3⋯IN×I2,2T(76)X2+=A˜Φ(1)S˜T∈CI1,1I1,2I3⋯IN×I2,2Twhere(77)Φ(1)=diag{[z1,1z2,1…zR,1]}.Following similar arguments as previous sections, the maximum number of detectable signals is increased to(78)Rmax=min⁡(I1,1I1,2I3⋯IN−1,I2,2T).When the temporal sample-size is small, e.g.,T≪I1I2⋯IN, (78) represents a non-trivial gain in detectability over (68).We present simulation results demonstrating the performance of the proposed MDF-ESTER schemes in Sections 3 and 4. The measurement data are generated based on the N-D undamped HR model, namely, (1) withζf(n)=0, where the spatial frequenciesμr(n)are drawn from a uniform distribution in[−π,π]. The signal symbols are uncorrelated zero-mean circularly symmetric complex Gaussian (ZMCSCG) random variables with identical power ofσs2.Along the same line as [33,44], the multidimensional colored noise is assumed to have a Kronecker structure:(79)N(c)=N×1L1×2L2⋯×NLN.whereN∈CI1×⋯×IN×Tis a tensor collecting the i.i.d. ZMCSCG noise samples with varianceσn2, andLn∈CIn×In,n=1,2,…,N, is the correlation factor in the n-th dimension of the colored noise tensor. The signal-to-noise ratio (SNR) is defined asSNR=‖X‖F2σn2∏n=1NIn.The noise powerσn2is scaled to obtain different SNRs. For each SNR, 200 independent Monte Carlo runs have been conducted.As in [33,44], the colored noise is modeled as a first-order autoregressive process:(80)nm+1(c)=ρn⋅nm(c)+1−ρn2⋅nm+1,such that the noise covariance matrixCn=LnLnH,n=1,2,…,N, is a function of a single variable, namely, the correlation coefficientρn. As an example,CnforIn=3has the following structure(81)Cn=[1ρn⁎(ρn⁎)2ρn1ρn⁎ρn2ρn1].Note that similar simulation results are observed for other types of noise correlation models.The performance measure is the PoD, i.e.,Pr(Rˆ=R). The PoD's of the following schemes are used as the benchmark: the original N-D ESTER proposed in [32] and its two variants proposed in [33]. The MATLAB codes of all order selection algorithms can be downloaded at http://www.ee.cityu.edu.hk/~hcso/publication.html.For a single-snapshot (T=1) HR model we evaluate the MDF-ESTER proposed in Section 3. Note that for single-snapshot HR model, the N-D ESTER II [33] is not applicable sinceT<R.44The N-D ESTER II relies on the tensor shift invariance equation (defined in (20) of [33]) and that in the absence of noise the tensor signal subspace represented byU(defined in (21) of [33]) and the array steering tensorA(defined in (7) of [33]) span the same subspace in all n-modes. The tensor signal subspaceUis estimated by performing truncation in the HOSVD. In case ofT<R, the problem is degenerate in the temporal mode. As a result, the estimatedUvia the HOSVD will be of rank at most T and less than R, andUcannot span the same subspace asAin the absence of noise.We consider a 2-D array withI1=I2=7. In Fig. 6(a), the PoDs versus SNR of different order selection schemes are compared forR=4signals, where the correlation coefficients of the colored noise are set asρ1=ρ2=ρ3=0.125. We see that the MDF-ESTER outperforms the original N-D ESTER [32] and N-D ESTER I [33]. The MDF-ESTER with FBA performs the best. In Fig. 6(b), the order selection schemes are evaluated for various noise correlation levels, where the SNR is fixed at 30 dB. Here, the correlation coefficients are equal to each other and vary from 0 to 0.999. Note that the MDF-ESTER keeps almost a constant PoD regardless of the noise correlation levels except for very high noise correlation levels.In Fig. 7, the number of signals is increased from 4 to 8. The N-D ESTERs totally fail since they can detect at most 5 signals, as shown in Table 1. Similar observations are obtained except for a larger performance gap between the MDF-ESTER without and with FBA.For a multiple-snapshot (T>1) HR model we evaluate the MDF-ESTER proposed in Section 4.In Fig. 8, we have the same scenario as in Figs. 6 and 7, the number of snapshots is increased fromT=1toT=125. We observe a performance improvement of all algorithms compared to Fig. 6. In addition, Fig. 8(b) indicates a weaker robustness of all algorithms compared to Figs. 6(b) and 7(b). With the increase of the noise correlation level, the PoDs of all algorithms show a slight (but clear) decrease for low-to-intermediateρnfollowed by a sharp drop for highρn>0.8.Moreover, for such a multiple-snapshot scenario with sufficiently large T, the MDF-ESTER can detect much more signals compared to the single-snapshot case. Fig. 9 shows that atR=32the MDF-ESTER is still able to detect the number of signals with a probability of one for sufficiently high SNRs.The maximum numbers of detectable signals of the N-D ESTER methods and our proposed MDF-ESTER for the single-snapshot and multiple-snapshot scenarios are summarized in Table 1.

@&#CONCLUSIONS@&#
