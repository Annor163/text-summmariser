@&#MAIN-TITLE@&#
No-reference image quality assessment based on gradient histogram response

@&#HIGHLIGHTS@&#
A NR image quality assessment based on gradient histogram response (GHR) is proposed.A test image is preprocessed to produce a noise image object and a blur image object.GHR is the gradient histogram variation of an image object under a local transform.GHR performs well for the images degraded by different distortions or mixed distortions.

@&#KEYPHRASES@&#
Gradient histogram response,Object input,Object output,Local image transform,No-reference image quality assessment,

@&#ABSTRACT@&#
In view of the fact that objects with different natures usually respond differently to the same external stimulus, this paper proposes a no-reference image quality assessment based on gradient histogram response (GHR). GHR is the gradient histogram variation of an image object under a local transform. In the metric, through preprocessing, a test image is transformed to a noise image and a blur image, which are taken as two image objects. Each image object is exerted with a local transform as an object input, and its GHR as an object output is extracted in multiscale space. The two GHRs compose a global feature vector and are mapped to an image quality score. Experiments show that GHR outperforms state-of-the-art no-reference metrics statistically in the condition that test images are degraded by different types of distortions. Especially, the metric is feasible for the quality assessment of the images degraded by mixed distortions though the types of these images are not included in the training database.

@&#INTRODUCTION@&#
Image quality assessment (IQA) is widely used in the fields of image preprocessing, fusion, transmission, etc. IQA metrics can be roughly categorized into two groups: subjective metrics and objective metrics. Subjective metrics are simple, intuitive and accurate. But they cannot work without human’s participation. They are infeasible in the condition that there are masses of images to be assessed. Therefore, it is indispensable to attach importance to objective metrics. Objective metrics are further categorized into full-reference (FR) metrics, reduced-reference (RR) metrics and no-reference (NR) metrics. FR metrics are based on the following assumption: the reference image is an available image with the highest quality. With FR metrics, the perceptual quality of a test image is assessed by calculating the similarity between the test image and its reference image [1,2]. RR metrics access partial reference information instead of the full reference image. With RR metrics, the similarity or difference between the test image and its reference image also need to be calculated when assessing the quality of a test image [3,4]. Thus, if the access to any reference information is unavailable, FR and RR metrics cannot work. Compared with FR and RR metrics, NR metrics can assess image quality based on the test image itself, so the reference image is unnecessary [5–18]. In terms of application, NR metrics have more promising prospects. Hence, the research of NR metrics has become the study focus both at home and abroad.According to their feasibilities for specific types of distortions, NR metrics follow two approaches: distortion-specific NR metrics and general (distortion-unspecific) NR metrics. Distortion-specific NR metrics are only applicable to one or more specific types of distortions, such as blocking [7], noise [8], blur [9], etc. They probe into the mechanism of a special type of distortion, and assess image quality only if the distortion type is known in advance. However, in most practical applications, the distortion type is unknown, which limits the applications of the metrics. It is desirable to design a general NR metric which performs well for various types of distortions even without the prior knowledge of distortion type.An ideal general NR metric should perform well for various common types of distortions. As is known, any metric is to be implemented with two phases: feature extraction and quality assessment. Feature extraction is vital to IQA, but it is difficult to choose the types of features which are the most useful to depict image quality. Quality assessment maps the features to a quality score through intelligent algorithms. Statistical models based on natural scene statistics (NSS) are common feature extraction approaches [1,2,10–17]. They assume that natural scenes possess certain statistical properties, and distortion affects these properties. Generalized Gaussian distribution (GGD) statistical model and asymmetric generalized Gaussian distribution statistical (AGGD) model are often used to depict image signal distributions, and reveal the marginal statistics of image signals [10–12,14–17]. The parameters of the estimated models can be used as features to be mapped to quality scores through support vector regression (SVR) [10,12], deep learning [17], etc. Codebook-based model is another common feature extraction approach for NR metrics [13,18]. A codebook is constructed from the local features extracted from labelled training images, and is used for feature space quantization. Local features extracted from the test image are encoded as a vector through quantization. Image quality is assessed by mapping the vector to a quality score using SVR [13,18], example-based method [18], etc. But efforts should still be made to reduce the gaps between subjective scores and objective predicted scores to meet the requirements of actual applications. The present NR metrics work well mainly in the condition that images are degraded by one type of distortion. In the conditions that the images are degraded by different types of distortions or mixed distortions, there is great improvement space in accuracy and stability for NR metrics.This paper proposes a new NR metric—gradient histogram response (GHR). GHR refers to the gradient histogram variation between an image and its counterpart under a local image transform. GHR is extracted in multiscale space to improve the metric’s performance. The metric is irrelevant to the distortion type and the image content. To keep the metric adaptable to different types of distortions, a test image is transformed to a noise image and a blur image through preprocessing. Each of the two images is taken as an unknown image object, and its corresponding local image transform and GHR are taken as its input and output respectively. The two GHRs of the two image objects compose a global feature vector, and are mapped to an image quality score. The rest of this paper is organized as follows. Section 2 establishes an IQA framework, which exerts an image input to the test image, and assesses image quality based on its image response output. Section 3 introduces gradient histogram. Section 4 introduces GHR and feature descriptions. Section 5 investigates the relationship between GHR and noise/blur distortion in detail. Further, Section 6 adjusts the gradient definition and puts forward a NR metric based on GHR. In Section 7, experiments are carried out to verify GHR’s assessment performance. Finally, conclusions are presented in Section 8.Objects with different natures often response differently to the same stimulus input. For an unknown object, its essential nature can be acquired by analyzing the object’s response outputs. In the real world, the assessment (investigation) of an unknown object is a commonly-confronted problem. In control field, a controlled object is an unknown object when its transfer function is measured; in software design field, a new software is an unknown object when its reliability and stability are assessed; in medical field, a patient is an unknown object when his pathologies are diagnosed. In the above fields, to acquire the essential nature of an unknown object, an external stimulus as an input is exerted to the unknown object, and its response output is then analyzed to probe into its intrinsic essential nature [19–21]. A test image to be assessed can be taken as an unknown object, which lays the very foundation for a new IQA framework as shown in Fig. 1. With the test image taken as an unknown object, an external image input is exerted to the object, and then the quality of the object is assessed based on its response output. Here, the image’s external stimulus input is a local image transform (with which an original test image changes into a transformed image); its response output is the corresponding feature variation between the original test image and the transformed image.There are many ways to classify distortions. According to their producing mechanism, they can be classified into JPEG2000, JPEG, WN, GBLUR, FF (Fast Fading), etc. [22]. According to their effects on the local correlation of neighboring pixels, they can be classified into three groups: noise distortion, blur distortion, and noise–blur distortion. Noise distortion such as Gaussian noise distortion weakens the correlation of image neighboring pixels. Blur distortion such as Gaussian-smoothing distortion reinforces the correlation of neighboring pixels. JPEG2000 distortion mainly makes image blur, and also belongs to blur distortion. Noise–blur distortion indicates that the distortion has both noise effects and blur effects. Noise–blur distortion may be shown in many forms. For example, an image can be degraded by noise distortion and blur distortion successively. Then the distortion produced from multiple types of distortions is defined as mixed distortion, which is a common form of noise–blur distortion. JPEG and FF distortions also belong to noise–blur distortion. The edges of the blocks in a JPEG image destroy the correlation of neighboring pixels, while the inner parts of the blocks reinforce the correlation. FF distortion is produced through different proportions of bit errors on JPEG2000 image bitstream. JPEG2000 distortion causes image blur, and bit errors on image bitstream can be seen as random noise. In this section and Sections 4–6, the latter classification approach is adopted to probe into the relationship between gradient histogram response and image quality.An ideal metric should be feasible to assess different types of distortions without the knowledge of distortion type. There are many metrics feasible for blur images and noise images [12–15]. But it is difficult to assess noise–blur images because the effects of noise and blur are converse. In other words, they mutually interfere with each other from visual perception. Image enhancement preprocessing can be used to eliminate blur distortion and enhance noise distortion. Through proper enhancement preprocessing, the effect of blur in the noise–blur image can be approximately eliminated, and the noise–blur image can be considered to be mainly degraded by noise distortion; the effect of noise in the noise image is enhanced, and the IQA sensitivity of noise distortion is improved; the effect of blur in the blur image is degraded, and the IQA sensitivity of blur distortion is slightly deteriorated. On the other hand, image smoothing preprocessing can be used to eliminate noise distortion and enhance blur distortion. Through proper smoothing preprocessing, the noise–blur image can be considered to be mainly degraded by blur distortion; the IQA sensitivity of noise distortion in the noise image is slightly deteriorated; the IQA sensitivity of blur distortion in the blur image is improved. According to the above discussions, the image quality of the noise–blur image can be assessed through noise assessment and blur assessment. The assessments for noise (blur) distortion under image smoothing and image enhancement are complementary. The image quality of the noise (blur) image can also be assessed through noise assessment and blur assessment. Thus, the IQA framework can be further implemented as in Fig. 2. The quality of the test image is assessed based on blur assessment and noise assessment. The test image is preprocessed through enhancement and smoothing to produce a noise image and a blur image. The two images are taken as two unknown image objects. Each image object is exerted with a local transform as an object input, and its GHR is extracted as an object output. Their response features are combined as a global feature vector and mapped to an image quality score. In the framework, the noise image is produced through enhancement preprocessing. In fact, it may not really be a noise image. Similarly, the blur image is produced through smoothing preprocessing and also may not really be a blur image.Gradient histogram is a kind of local feature description, which describes the appearance and shape of a local block image. It counts the gradient vote in gradient orientations across the local block image [23], and has been widely used in image recognition, image quality assessment, image registration, etc. [23–25]. In its extraction, a test image I(x, y) is divided into a series of block images with size of N × N. For a random pixel (x, y) in a block image, its horizontal gradient Gx(x, y) and vertical gradient Gy(x, y) are calculated by Eqs. (1) and (2). Then gradient magnitude M(x, y) and orientation θ(x, y) are calculated by Eqs. (3) and (4).(1)Gx(x,y)=I(x+1,y)−I(x−1,y)(2)Gy(x,y)=I(x,y+1)−I(x,y−1)(3)M(x,y)=G2x(x,y)+G2y(x,y)(4)θ(x,y)=tan−1(Gx(x,y)/Gy(x,y))The orientation histogram, labelled as (g1, … , gn), has n bins covering the 360° range of orientations. Each sample (a gradient of the pixel in the block) is added to the histogram, weighted by its gradient magnitude. The histogram is then normalized to unit length as follows:(5)H=(h1,…,hn)=(g1,g2,…,gn)∑i=1n(gi)2where∑i=1n(gi)2refers to gradient histogram magnitude. The normalized histogram H is used as a local image descriptor to reduce the effect of illumination change.In Section 2, image enhancement is exerted to a test image to produce a noise image, and image smoothing is exerted to the test image to produce a blur image. Image enhancement weakens the correlation among neighboring pixels while image smoothing reinforces the correlation among neighboring pixels. Suppose that a test image and its corresponding image object are I(x, y) and Io, and then image enhancement (image smoothing) can be achieved with Eqs. (6)–(8).(6)Ll=[0101−41010](7)Lp=[000010000]−λ*Hp=[0−λ0−λ1+4λ−λ0−λ0](8)Io=Lp*I(x,y)where Lland Lpare the Laplacian operator and image preprocessing operator respectively, λ is a constant, * refers to convolution operation and Iois taken as an image object for further investigation in the following sections. The Laplacian operator is a second-derivative neighborhood operator and sensitive to isolated points and thin lines, which is often adopted to sharpen images. When λ is greater than zero, Eq. (8) plays a role of image enhancement; when λ is less than zero, Eq. (8) plays a role of image smoothing. To distinguish different roles, the constants are labelled as λnand λbin image enhancement and image smoothing respectively.Gradient histogram is a statistical result of the gradients across a local block image. So it is directly related to horizontal gradient Gx(x, y) and vertical gradient Gy(x, y), which are calculated by Eqs. (1) and (2). Here, the image input Liis defined as follows:(9)Li=[000010000]+η[0−10−120000]=[0−η0−η1+2η0000]where η is a constant. The image input is exerted to an image object as(10)Io′(x,y)=Li*Io(x,y)where * refers to convolution operation, Io(x, y) the image object defined in Eq. (8), andIo′(x,y)the output object. Response features are extracted based on Io(x, y) andIo′(x,y). The image input Liis convoluted with the image object Io(x, y), which directly leads to the variations of horizontal and vertical gradients. To distinguish the constants in the noise image object and the blur image object, they are labelled as ηnand ηbrespectively.Gradient histogram response (GHR) is defined as(11)R=H′−Hwhere H and H′ are the normalized histograms in the image object Io(x, y) and the output image objectIo′(x,y)respectively. In [14], NR BLIIDS-II metric chooses the features, including generalized Gaussian model shape parameter, frequency variation coefficient, energy subband ratio measure and orientation model-based feature, to describe the coefficients in DCT domain, and it has high performance. In the metric proposed in this paper, five features are chosen to describe GHR: gradient histogram distance, generalized Gaussian model shape parameter, variation coefficient, energy subband ratio measure and orientation model-based feature. Among the features, the latter four are based on similar ideas as in BLIIDS-II.Gradient histogram distance (GHD) is defined as(12)ψ=norm(R)It is a Euclidean distance between H and H′, intuitively depicting the difference between the two feature vectors. The histogram distance ψ is pooled in two ways: by computing the highest 10th percentile average and the 100th percentile average of the block scores across the image object. It has been verified that this “percentile pooling” approach can reinforce the correlations with subjective perception of image quality [14]. It is motivated by the fact that subjective perception is heavily influenced by the “worst” distortion in an image. 10th percentile and 100th percentile pooling help inform the predictor whether the distortion is partly severe or uniformly irritating over the whole image.Generalized Gaussian model is often used to depict data distribution [10–13]. This paper adopts the model to describe the distribution of gradient histogram response R in gradient orientation. Let x be a random variable, representing an item of R, and then the univariate generalized Gaussian density is given by(13)f(x|α,β,γ)=αe−(β|x−μ|)γwhere μ, γ, α and β denote the mean, the shape parameter, the normalizing parameter and the scaling parameter of the distribution respectively. The shape parameter γ denotes the decay rate: the smaller the γ is, the more peaked the probability distribution function (PDF) model is; the larger the γ is, the flatter the PDF is. A variety of parameter estimation methods have been proposed for this model. This paper adopts the method given in [14,26] to estimate the parameters of the model. γ is computed for all blocks across the image object. The feature is pooled by averaging over the highest 10th percentile and over the 100th percentile of the block shape parameters across the image object. The motivation behind the percentile pooling strategy is similar to that behind the percentile pooling of GHD.Let x be a random variable, representing an item of the histogram response vector R as in the above paragraph, and then histogram response variation coefficient is defined as follows [14]:(14)ζ=σ|x|μ|x|where μ|x| and σ|x| are the mean and standard deviation of x respectively. The denominator μ|x| measures the center of x magnitude distribution while the numerator σ|x| measures the spread or energy of x magnitudes. Variation coefficient is pooled by the highest 10th percentile average and the 100th percentile average of the local block scores across the image object. The motivation behind the percentile pooling strategy is also similar to that behind the pooling strategy of GHD.The items of R are sorted into 3 equal bands in the ascending order. Then the average energy in band n is defined as the varianceσn2. Energy subband ratio is the ratio of the difference and the sum between the average energy in the nth band and the average energy up to the nth band, defined as follows[14]:(15)χn=|σn2−1n−1∑j<nσj2|σn2+1n−1∑j<nσj2χnis effective on the ground that n is greater than 1. A large ratio corresponds to a large disparity between the energy in the nth band and the average energy in the lower bands. The mean of χ2 and χ3 is computed as the final energy subband ratio. The feature is also pooled by the highest 10th percentile average and the 100th percentile average of the block scores across the image object.Image distortion will affect local orientation energy, which can be reflected in the variation of gradient orientation energy. According to gradient orientation bins, gradient histogram R is modelled in three orientations: [−π−2/3π), [−2/3π 1/3π), [1/3π π). Orientation variation is obtained as in Eq. (14) for each orientation. The variance of orientation variations across the three orientations, labelled as ϕ, is the final orientation feature. The feature is also pooled by averaging over the highest 10th percentile and over the 100th percentile of all the block scores across the image object.Image analysis in multiscale space is a study focus [27]. Successful IQA metrics have been investigated based on multiscale features [14,27]. Multiscale features can generally improve the performance of the metrics. In the similar way, GHR is detected in multiscale space. The multiscale image space is set up through low-pass filtering the image and subsampling it by a factor of 2. The process is repeated twice. The filter is a rotationally symmetric discrete Gaussian filter with its size equal to 3 × 3, mean equal to 0 and variance equal to 0.5. The features in multiscale space form a multiscale feature vector.Gradient histogram response (GHR) is the variation of gradient histogram under an image input. From a micro perspective, it is related to the variation of each pixel’s gradient. From a macro perspective, it is related to the distribution of gradient histogram. Surely, GHR results from a comprehensive function of multiple factors. In the following discussion, the focus is placed upon the key influence factors.First, gradient variation with distortion on GHR from a micro perspective. For a random pixel, its gradient variation can be described by the variations of Gx(x, y) and Gy(x, y) (M(x, y) and θ(x, y)). It is supposed that neither absolute Gx(x, y) nor absolute Gy(x, y) is equal to zero. The relative horizontal gradient variation Δrx(x, y) and the relative vertical gradient variation Δry(x, y) are represented in Eqs. (16) and 17 respectively.(16)Δrx(x,y)=ΔGx(x,y)/Gx(x,y)=(Gx′(x,y)−Gx(x,y))/Gx(x,y)(17)Δry(x,y)=ΔGy(x,y)/Gy(x,y)=(Gy′(x,y)−Gy(x,y))/Gy(x,y)Here ΔGx(x, y) (ΔGy(x, y)) is the horizontal gradient variation (vertical gradient variation); Gx(x, y) (Gy(x, y)) andGx′(x,y)(Gy′(x,y)) are the horizontal (vertical) gradients of the images Io(x, y) andIo′(x,y). The gradient of the pixel, whose Gx(x, y) (Gy(x, y)) is close to zeros, is unstable because a small disturbance will cause a great relative gradient variation. Therefore, it cannot represent the gradient variation tendency of most pixels. Furthermore, the gradient variation tendency of most pixels is also small under a small image input. Hence are chosen the pixels whose absolute horizontal gradients (vertical gradients) are larger than zero and Δrx(x, y) (Δry(x, y)) are less than a predefined threshold. Here, the threshold is set to 50.According to Eqs. (1)–(5) and (11), GHR is related to horizontal gradient, vertical gradient, and horizontal-vertical gradient correlation. Δrx(x, y) and Δry(x, y) are mutually independent (which has been verified as in Fig. 5 in the latter paragraphs), and their correlationρΔrx,Δrytends to zero. Therefore, the effects of Δrx(x, y) and Δry(x, y) can be independently discussed. As shown in Fig. 3, the shaded block is supposed to be a possible relative variation scope. G and G′ are the abbreviations of G(x, y) and G′(x, y), referring to the gradients of the test image and the output image respectively. From a statistical view, each variation is a random value. Although the precise distributions of Δrx(x, y) and Δry(x, y) remain unknown, it is obvious that the wider their scopes are, the larger the variations in gradient magnitude and orientation are.For Δrx(x, y), its distribution is related to ΔGx(x, y) and Gx(x, y), and their correlationρΔGx,Gx. ΔGx(x, y) and Gx(x, y) have similar distributions: the nearer to zero they are, the higher their emergence probabilities are. According to Eqs. (1)–(4), the gradient of a pixel (x, y) is related to its neighboring pixels (x+1,y), (x−1,y), (x, y+1), (x,y−1). According to Eq. (10), the horizontal gradient of the imageIo′(x,y)under an image input Liis as follows:(18)G′x(x,y)=Ii′(x+1,y)−Ii′(x−1,y)=[Io(x+1,y)−Io(x−1,y)]+2η[Io(x+1,y)−(x−1,y)]−η[Io(x,y)−Io(x−2,y)+Io(x+1,y−1)−Io(x−1,y−1)]Then, Eq. (18) can be deduced as follows:(19)G′x(x,y)=Gx(x,y)+η[(Gx(x,y)−Gx(x−1,y))+(Gx(x,y)−Gx(x,y−1))]The mathematical expectations E(Gx(x, y)) and E(ΔGx(x, y)) are as follows(20)E(Gx(x,y))=1n∑(Io(x+1,y)−Io(x−1,y))=1n(∑Io(x,y)−∑Io(x−1,y))≈0(21)E(ΔGx(x,y))=η1n(∑(Gx(x,y)−Gx(x−1,y)+Gx(x,y)−Gx(x,y−1)))=η1n(∑(Gx(x,y))−∑(Gx(x−1,y))+∑(Gx(x,y))−∑(Gx(x,y−1)))≈0Therefore, their distributions can be depicted approximately by means of Gaussian functions with mean equal to zero. The variances of ΔGx(x, y) and Gx(x, y) are labelled asσΔGx2andσGx2. IfρΔGx,Gxis constant, the larger the ratiorσΔGx2,σGx2betweenσΔGx2andσGx2is, the larger Δrxis. In other words, the variation of gradient histogram is larger. On the other hand, if the distributions ofσΔGx2andσGx2are constant, the increase ofρΔGx,Gxindicates the decrease of gradient orientation variation and the increase of gradient magnitude variation. Because the gradient magnitudes in each orientation bin and gradient histogram are all statistical results, the effects of pure gradient magnitude variation will be greatly restrained as in Eq. (5). It means that the variation in gradient histogram has a decreasing tendency asρΔGx,Gxincreases. Therefore, the influence factors of horizontal gradient Δrx(x, y) are transformed torσΔGx2,σGx2andρΔGx,Gx. In the same way, the influence factors of the vertical gradient Δry(x, y) are transformed torσΔGy2,σGy2(the ratio betweenσΔGy2andσGy2) andρΔGy,Gy(the correlation between ΔGyand Gy). The increase ofrσΔGx2,σGx2(rσΔGy2,σGy2) leads to the reinforcing of GHR while the increase ofρΔGx,Gx(ρΔGy,Gy) leads to the weakening of GHR.Second, gradient histogram distribution on GHR from a macro perspective. As shown in Fig. 4, Fig. 4(a) and (c) are two block images, respectively partitioned from a WN image and a GBLUR image with DMOS 65.6539 and 80.0819 respectively. And the WN image and the GLBUR image are both produced from the Rapids image in the LIVE database [22]. The blocks are of 40 × 40 size, corresponding to the same region ([321:360 301:340]) in the Rapids image. DMOS is on a scale of 0–100 with a large DMOS indicating poor visual quality. The main orientation of gradient histogram refers to the orientation of the peak in gradient histogram [23]. Fig. 4(b) and (d) are the corresponding gradient histograms of Fig. 4(a) and (c). For a noise block image, the main orientation of its gradient histogram is not obvious. In contrast, for a blur block image, the main orientation of its gradient histogram is obvious. The gradient orientations of the pixels in the noise region are approximately random, and gradient magnitudes in all the bins are statistically equal. Therefore, its gradient histogram has no obvious main orientation. Conversely, the gradient histogram of the blur image has an obvious main orientation. Variation in gradient magnitude and orientation will lead to a perturbation of gradient histogram. As discussed in the above paragraph, the effects of pure gradient magnitude are greatly restrained due to gradient histogram normalization. In other words, the variation in gradient orientation plays a vital role. The gradient votes in one bin are supposed to be obviously greater than those in its neighboring bins. More gradient votes may shift to its neighboring bins under the same relative pixel gradient variation, which leads to a stronger response. For the noise histogram, it is stable due to unobvious gradient vote differences among neighboring bins; for the blur histogram, it is unstable due to obvious gradient vote differences among neighboring bins.Based on the above discussion, GHR for noise and blur distortions is investigated. GHR is detected over 40 × 40 blocks, which are partitioned from an image object at an interval of 40 pixels along horizontal and vertical axes. Because gradient histogram distance (GHD) ψ can intuitively represent GHR, the following discussion uses its average over all of the block scores across the image object to roughly describe GHR.Since the producing mechanisms of horizontal gradient variation and vertical gradient variation are similar, this paper probes into their producing mechanisms by sampling of horizontal gradient variation. As discussed in Section 5.1, the main influence factors of relative horizontal gradient variation ΔrxincluderσΔGx2,σGx2,ρΔGx,Gxand the distribution of gradient histogram.SetTx,x(x,y)=Gx(x,y)−Gx(x−1,y),Tx,y(x,y)=Gx(x,y)−Gx(x,y−1), andEx(x,y)=Tx,x(x,y)+Tx,y(x,y). According to Eqs. (18) and (19), it can be further deduced as follows:(22)G′x(x,y)=Gx(x,y)+η[Tx,x(x,y)+Tx,y(x,y)](23)G′x(x,y)=Gx(x,y)+ηEx(x,y)(24)ΔGx(x,y)=ηEx(x,y)=η[Tx,x(x,y)+Tx,y(x,y)]In Eqs. (19) and (24), η is a constant, so ΔGx(x, y) has the same variation tendency with Ex(x, y). Ex(x, y) is obtained in a way that can be approximately seen as a first-derivative operator on the horizontal gradient image of the image object. Therefore, Ex(x, y) is more sensitive to image neighboring gray difference compared with Gx(x, y).rσΔGx2,σGx2increases as noise increases. In the similar way,rσΔGy2,σGy2of vertical gradient also increases as noise increases.The correlationρΔGx,Gxbetween ΔGx(x, y) and Gx(x, y) is equal to the correlationρEx,Gxbetween Ex(x, y) and Gx(x, y). To investigateρEx,Gx,the correlationρTx,x,Gxbetween Tx, x(x, y) and Gx(x, y) is analyzed firstly. The gradient correlation is generally related to the spatial Euclidean distance of pixels in the image object. Gradient correlation coefficient decreases as the distance increases. For pixel (x, y), its direct-neighboring pixels include pixels (x+1,y), (x−1,y), (x,y+1), (x,y−1)). Let the horizontal gradient correlation coefficient among the direct-neighboring pixels in the image object be ρ.ρTx,x,Gxcan be represented as follows:(25)ρTx,x,Gx=Cov(Tx,x(x,y),Gx(x,y))D(Tx,x(x,y))D(Gx(x,y))=E(G2x(x,y)−Gx(x,y)Gx(x−1,y))D(Gx(x,y))D(Gx(x,y)−Gx(x−1,y))Let the variance D(Gx(x, y)) be d, and then Eq. (25) can be deduced as(26)ρTx,x,Gx=d−ρd*dd(d+d−4ρd*d))=1−ρ(2−ρ)The differentiation of the above equation can be deduced as follows:(27)d(ρTx,x,Gx)dρ=−2−ρ+(1−ρ)×0.5×(2−ρ)−0.5(2−ρ)=−1+(1−ρ)×0.5(2−ρ)1.5For a pure noise image, its gradient correlation ρ among direct-neighboring pixels is close to zero; for a large-scale smoothed image, its gradient correlation ρ among direct-neighboring pixels is close to 1. Therefore, ρ is within the scope of [0 1]. Within the scope, the value of Eq. (27) is less than zero, which means thatρTx,x,Gxdecreases as ρ increases. In the same way, the tendency of the correlationρTy,x,Gybetween Ty, x(x, y) and Gy(x, y) is similar to that ofρTx,x,Gx. According to Eq. (24), it can be concluded that bothρEx,Gx(ρEy,Gy) andρΔGx,Gx(ρΔGy,Gy) have the tendencies opposite to that of ρ, decreasing as ρ increases.Test noise images are the corresponding noise images of a reference image in the LIVE database. Large DMOS indicates large noise, low ρ, and large gray differences among neighboring pixels. Since the results of all the experiments are similar, the noise images of a reference image Rapids are chosen to describe the general result. The experimental results are shown in Fig. 5(a)–(d). Image input Liwith ηnset to 1 is exerted to the test images. As shown in Fig. 5(a) and (b), both the variance ratiorσΔGx2,σGx2(rσΔGy2,σGy2) and the correlationρΔGx,Gx(ρΔGy,Gy) between gradient variation and gradient in horizontal (vertical) gradient increase as DMOS increases. In Fig. 5(c), it can be seen that the correlationρΔrx,Δrybetween Δrxand Δryis fixed, close to zero. Therefore, from a micro perspective, Δrxand Δry, which are the influence factors of GHR, can be discussed independently. Δrx(Δry) is depicted through its second-order origin moment, labelled asmΔrx2(mΔry2). As shown in Fig. 5(c),mΔrx2/40(mΔry2/40) generally increases as DMOS increases. In Section 5.1, it has been inferred that Δrx(Δry) is mainly related torσΔGx2,σGx2(rσΔGy2,σGy2) andρΔGx,Gx(ρΔGy,Gy). Large variance ratiorΔGx2,Gx2(rΔGy2,Gy2) will lead to large variation in gradient histogram, while the large correlationρΔGx,Gx(ρΔGy,Gy) will weaken the variation in gradient histogram. From a macro perspective, the histogram of a noise block image is stable to external interference. As the noise increases, the gradient votes in all the bins tend to be equal, and gradient histogram is stable through normalization. The final tendency of GHR is the result of comprehensive effects. GHD falls with DMOS ψ increasing as shown in Fig. 5(d), which means that the declining effects play a vital role in this case. It can be approximately inferred that GHR also falls as DMOS increases.The analysis of gradient histogram response for blur distortion is similar to that of gradient histogram response for noise distortion. Because the experimental results also tend to be similar, the blur images of a reference image Rapids are chosen to describe the general result with an example as in the above subsection. Test blur images are the corresponding blur images of a reference image (Rapids) in the LIVE database. The experimental results are shown in Fig. 5(e)–(h). For a blur image, large DMOS indicates large-scale blur, large ρ, and small gray differences among neighboring pixels. According to Fig. 5(e)–(g), both the variance ratiorσΔGx2,σGx2(rσΔGy2,σGy2) and the correlationρΔGx,Gx(ρΔGy,Gy) between gradient variation and gradient in horizontal (vertical) gradient decrease as DMOS increases, opposite to those for noise distortion. The correlationρΔrx,Δrybetween Δrxand Δryis also similarly fixed, close to zero. From a micro perspective, variance ratiorΔGx2,Gx2(rΔGy2,Gy2) weakens gradient histogram variation, while the correlationρΔGx,Gx(ρΔGy,Gy) reinforces gradient histogram variation. From a macro perspective, the histogram of blur image is unstable to external interference. The final tendency of GHR results from the comprehensive effects of multiple factors. When ηbis set to 1.0,mΔrx2/40(mΔry2/40) decreases as DMOS increases, as shown in Fig. 5(g). Fig. 5(h) shows that GHD overall decreases as DMOS increases, which means that the declining factors play a vital role. However, for the image degraded by large-scale blur distortion, its GHD ψ may increase sharply, which is because that its horizontal (vertical) gradient is close to 0, and a small disturbance may lead to a large relative variation in horizontal (vertical) gradient. According to the tendency of GHD, it can be approximately inferred that GHR generally falls as DMOS increases. But GHR may be abnormal for large-scale blur distortion.As discussed in Section 5, GHR decreases as noise and blur distortions increase. But when the gradient magnitude is close to 0, GHR is unstable. Especially for a pixel in a large-scale smoothed image, its gradient magnitude is likely to be small. A small disturbance will lead to a large relative variation, as shown in Fig. 5 (h). Therefore, a constant is added to Gx(x, y) and Gy(x, y) to avoid the abnormal case.(28)Gx(x,y)=Io(x+1,y)−Io(x−1,y)+τ(29)Gy(x,y)=Io(x,y+1)−Io(x,y−1)+τHere, τ denotes a constant. For most pixels in a large-scale smoothed (blur) image, τ can be thought to be relatively larger than the original horizontal and vertical gradients defined in Eqs. (1) and (2). Therefore, gradient relative variation ΔGx(x, y)/Gx(x, y) (ΔGy(x, y)/Gy(x, y)) is approximately equal to ΔGx(x, y)/τ (ΔGy(x, y)/τ).rΔGx2,Gx2(rΔGy2,Gy2) is statistically small, and so is GHR. For most pixels in a large-scale noise image, τis relatively small compared with the original horizontal (vertical) gradient, and can be ignored. Therefore, GHR is also small, similar to that shown in Fig. 5(e). For a small-scale smoothed (blur) image and a small-scale noise image, they are in the transitional stage from blur distortion to noise distortion. It is difficult to precisely decide the tendency of GHR, which is related to image preprocessing, image input and gradient adjustment. But fine performance can be achieved through parameter optimization. To distinguish the constants in the noise image object and the blur image object, they are labelled as τnand τbrespectively.The assessment mechanisms of noise distortion and blur distortion are different. When the two distortions coexist, they will interact with each other, leading to the deterioration of the IQA metric’s performance. Noise distortion will reduce the correlation among neighboring pixels and affect blur distortion assessment. Similarly, blur distortion will reinforce the correlation among neighboring pixels and affect noise distortion assessment. To make GHR work without the knowledge of distortion type, a test image is transformed to a noise image and a blur image through preprocessing. The two images are taken as objects. The quality of the test image is assessed based on the responses of the two objects.In Section 5, the relationships between GHD ψ and DMOS for noise and blur distortions have been shown. But a great amount of information is lost in the process from GHR to GHD. To achieve better performance, it is necessary to extract more features from GHR. Here, five features are chosen as GHR features: gradient histogram distance ψ, generalized Gaussian model shape parameter γ, histogram response variation coefficient ζ, energy subband ratio χ and orientation feature ϕ. The response features of the noise image object (the blur image object) form a vectorFn,i=[f1,…,fv](Fb,i=[f1,…,fv]), where iis the index of an image object to be assessed, and v is the number of feature items. Through the combination of Fn, i(Fb, i) and DMOSi, the pairs [Fn, iDMOSi] ([Fb, iDMOSi]) are obtained.To guarantee the superior performance of GHR, the metric should choose proper parameters, including λn, ηn, τnin noise image assessment and λb, ηb, τbin blur image assessment. The coefficients are determined by experimental performance. In each experiment, 90% of the LIVE images are chosen for training, and the remaining LIVE images for testing. A support vector regression (SVR) [28] is adopted to map feature vectors to DMOSs. After training, the metric is applied to assess image quality of test images, providing predicted DMOSs. The correlation SROCC (Spearson rank order correlation coefficient) between DMOSs and predicted DMOSs of the test images is calculated. Large SROCC indicates high performance. For each group of coefficients, 60 experiments are carried out, and the average of 60 experimental SROCCs is used as a performance criterion to determine coefficients.Based on the coefficient optimization for blur and noise distortions, the response features of both the noise image object and the blur image object, which are produced from the same test image, are combined to form a global vectorFg,i=[f1,…,f2v],where g indicates that the vector is a global vector, i is the index of the image to be assessed, and 2v is the number of feature items. Through the combination of Fg, iand DMOSi, the pairs [Fg, iDMOSi] are obtained. The global feature vector is mapped to an image quality score through SVR once again. Ninety percent of the LIVE images are chosen for training, and the remaining LIVE images for testing. The final result is the average of 60 experimental results. The SROCCs between each item of Fg, iand DMOS are shown in Tables 1and 2. The performance of global feature vectors is to be shown in Section 7.

@&#CONCLUSIONS@&#
GHR, as a no-reference (NR) IQA metric, has superior performance in the condition that test images are degraded by different types of distortions, which means that it can work well in complex conditions without the prior knowledge of distortion types. Especially, it works well for mixed distortions though the types of these images are not included in the training database. Simultaneously, it has relatively good performance when test images are degraded by one type of distortion compared with state-of-the-art NR metrics. Additionally, we think further efforts should be made in the following fields:(1)Application of IQA framework The paper puts forward an IQA framework. In the framework, image quality is assessed based on image object responses. Further efforts can be made to investigate whether the framework can also be used in state-of-the-art metrics, such as PSNR and SSIM, to improve their performance.Image input GHR is a response output under an image input. It is necessary to investigate more proper image inputs to improve GHR’s performance.Response features Response features are vital to image quality assessment. GHR does not work well when the size of the test image is small. It is because the partitioned blocks in the second-scale and third-scale space are not enough to statistically keep GHR features consistent with subjective judgments. Proper response features can further improve the performance of NR metric.