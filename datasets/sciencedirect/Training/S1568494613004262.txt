@&#MAIN-TITLE@&#
Self-adaptive metaheuristics for solving a multi-objective 2-dimensional vector packing problem

@&#HIGHLIGHTS@&#
We study a new multi-objective 2-dimensional vector packing problem.We propose several encoding/decoding strategies whose parameters are embedded in the solution encoding.We compare the presented strategies using two multi-objective population-based metaheuristics namely NSGA-II and PLS-1.

@&#KEYPHRASES@&#
2-Dimensional vector packing problem,Multi-objective combinatorial optimization,Metaheuristics,

@&#ABSTRACT@&#
In this paper, a multi-objective 2-dimensional vector packing problem is presented. It consists in packing a set of items, each having two sizes in two independent dimensions, say, a weight and a length into a finite number of bins, while concurrently optimizing three cost functions. The first objective is the minimization of the number of used bins. The second one is the minimization of the maximum length of a bin. The third objective consists in balancing the load overall the bins by minimizing the difference between the maximum length and the minimum length of a bin. Two population-based metaheuristics are performed to tackle this problem. These metaheuristics use different indirect encoding approaches in order to find good permutations of items which are then packed by a separate decoder routine whose parameters are embedded in the solution encoding. It leads to a self-adaptive metaheuristic where the parameters are adjusted during the search process. The performance of these strategies is assessed and compared against benchmarks inspired from the literature.

@&#INTRODUCTION@&#
The multi-objective 2-dimensional vector packing problem (MO-BPP) aims at packing a set of items each having two sizes in two independent dimensions, say, a weight and a length into a finite number of bins, while concurrently optimizing three cost functions. The first objective is the minimization of the number of used bins. The second one is the minimization of the maximum length of a bin. The third objective consists in balancing the load overall the bins by minimizing the difference between the maximum length and the minimum length of a bin.The MO-BPP is a generalization of the 2-dimensional vector packing problem (2-DVPP). The goal of the 2-DVPP is to pack a set of N items, the ith having two sizes into two independent dimensions, say a weight ciand a length hi(i∈{1, …, N}) in a minimum number of identical bins with two capacities C and H while respecting the capacity constraints in each dimension. The problem is proven to beNP-hard in the strong sense [10] as it is a generalization of the classical one-dimensional bin packing problem.Due to its theoretical and practical relevance, various approximation algorithms [27,14,30] and exact methods [3,28] were proposed to handle the 2-DVPP. Furthermore, many real-world applications for vector packing problems can be pinpointed in scheduling problems with resource constraints and layout design [9,17]. Another application in the steel industry for an efficient coil cassettes is studied in [5]. Other interesting applications were presented in both of the virtual machine consolidation [19] and data placement on disks [27] contexts.The literature on the 2-DVPP focuses on the minimization of wasted space. However, in real-world applications, it is often necessary to take into account multiple objectives simultaneously. Therefore, one can observe an increasing interest for multi-objective approaches in solving packing problems (see among others [7,15,18,26,21,29]). Indeed, the problem addressed in this paper is a good illustration of what can typically be found in the industry. For instance in the computer processor selection with job assignment context, a finite number of real-time jobs (items) have to be assigned to a group of processors (bins). Each job has its own resource demands for CPU time and memory and each processor has processing time and memory resource constraints. The jobs must all run simultaneously and, for a fast time response, all must be memory-resident at all times. An interesting solution should find a good trade-off between the number of processors, the completion time and balance the workload among the processors. The goal is not only to reduce the investment in hardware but also to minimize the cost energy.A classical way for solving packing problems with metaheuristics is to use indirect encodings based on items permutation. The major asset of these indirect approaches is that penalty functions are useless since only feasible solutions are generated. All the problem-specific knowledge is handled by the decoder which is generally a constructive heuristic, whilst the metaheuristic is kept canonical. For the single objective case, the main addressed objective is to minimize the number of bins, and therefore a single decoder dedicated to this criterion is sufficient. However, in the multi-objective framework, using a unique decoder may introduce a bias towards certain regions of the objective space. This would lead to an unbalanced distribution of the whole approximated Pareto front.The main contribution of this work is twofold and can be summarized as follows. First, different encoding/decoding strategies are proposed for the new multi-objective problem, the MO-BPP. A special feature of these strategies is that parameters of the corresponding decoder are added into the solution encoding and iteratively adjusted during the search process, which leads to a self-adaptive metaheuristic. Second, the designed strategies are then embedded in two multi-objective population-based metaheuristics namely NSGA-II [8] and PLS-1 [22]. The incentive behind choosing such metaheuristics is that they are easily accessible through many free and commercial software packages and are good candidates for solving the MO-BPP (see Appendix A). Thus, as an initial step of the experiments, we compare all the proposed encoding/decoding strategies on various benchmark test instances inspired from the literature [3] and discuss their respective behaviors. Next, we assess the performance of both multi-objective metaheuristics PLS-1 and NSGA-II using the best encoding/decoding strategy.The remainder of the paper is organized as follows. In Section 2, we start by recalling some basic concepts of multi-objective optimization. Then, we provide a formal description and a mathematical formulation for the MO-BPP. Section 3 deals with the different indirect encoding approaches. Finally, our computational experiments are reported in Section 4.In this section, we first present some basic concepts and definitions related to multi-objective optimization. Next, we provide a formal description and a mathematical formulation of the MO-BPP.In a multi-objective problem, the decision maker is faced with a set of n≥2 of conflicting objective functions z1, …, znthat have to be simultaneously optimized. The main concern is to find in a single trial not only one optimal solution s but a setS*of Pareto-optimal (i.e., efficient) solutions, which provide insights into the trade-offs between the objectives.In this paper, we use the Pareto optimality concept, which is the most common in the literature. We assume without loss of generality that all n objective functions have to be minimized. LetSdenote the set of feasible solutions in the decision space, andZthe set of feasible points in the objective space. To each decision vectors∈Sis assigned exactly one objective vectorz∈Zon the basis of a vector functionf:S→Zwith z=z(s)=(z1(s), …, zn(s)).Definition 1(Dominance) Letx,y∈S, x dominates y (denoted x ⪰ y) iff ∀i∈{1, …, n}, zi(x) is better than zi(y)∧∃i∈{1, …, n}, zi(x) is strictly better than zi(y). A solutionx∈Sis non-dominated iff∄y∈S,y⪰x.Definition 2(Pareto optimality) A solutionx∈Sis Pareto optimal iff x is a non-dominated solution. Pareto optimal solutions are also called efficient solutions. The set of all Pareto optimal solutions is the Pareto optimal set.Definition 3(Pareto optimal set) Given a multi-objective optimization problem, the Pareto optimal setS*is defined as follows:S*={x∈S|∄y∈S,z(y)⪰z(x)}.Definition 4(Pareto front) Given a multi-objective optimization problem and its Pareto optimal setS*, the Pareto frontZ*is defined as follows:Z*={z(x)|x∈S*}.As we are handling a multi-objective problem with a considerably high complexity, we are faced to potentially exponential number of Pareto optimal solutions. Obviously, it is usually impossible to generate the entire Pareto optimal set. Therefore, one have to identify a good approximation of it, using metaheuristic methods for instance.The MO-BPP can be described as follows. Given a set of N items, to each item i={1, …, N} corresponds a weight ciand a length hi, and a setM¯of bins, whereM¯is an upper bound on the number of bins that can be used (triviallyM¯≤N). To each binj={1,…,M¯}corresponds a weight capacity C. The three objectives that have to be concurrently minimized are the number of used bins, the maximum length of a bin and the difference between the maximum length and the minimum length which guarantees the balance of the load overall the bins. Our linear integer model uses the following set of decision variables•xij: binary variable taking 1 if item i is placed in bin j, 0 otherwise.yj: binary variable taking 1 if bin j is used, 0 otherwise.H: integer variable expressing the maximum length of a non-empty bin.E: integer variable expressing the minimum length of a non-empty bin.The mathematical formulation of the MO-BPP can be stated as follows.(1)minz1(s)=∑j=1M¯yj(2)minz2(s)=H(3)minz3(s)=H−E(4)s.t.∑j=1M¯xij=1,∀i∈{1,…,N}(5)∑i=1Ncixij≤Cyj,∀j∈{1,…,M¯}(6)∑i=1Nhixij−H≤0,∀j∈{1,…,M¯}(7)(1−yj)θ+∑i=1Nhixij−E≥0,∀j∈{1,…,M¯}(8)xij∈{0,1},∀i∈{1,…,N},∀j∈{1,…,M¯}(9)yj∈{0,1},∀j∈{1,…,M¯}(10){H,E}∈ℕ.(11)s=(xij,yj),∀i∈{1,…,N},∀j∈{1,…,M¯}The three objective functions defined in (1), (2) and (3) minimize concurrently the number of used bins, the maximum length of a single bin and the difference between the maximum length and the minimum length of bins. The partition constraints (4) ensure that each item i is assigned to exactly one bin j. Inequalities (5) express that the maximum weight capacity has to be respected in each bin. Note that the right-hand side of each inequality (5) obliges yjto take the value 1 when an item i is assigned to bin j. Inequalities (6) mean that each item size combination into an open bin j must not exceed the maximum length H. Inequalities (7) mean that each item size combination into an open bin j must be at least equal to the minimum length E. Note that we use a large θ value so the inequality (7) for a given j is not active when a bin j is not used.Illustrative exampleConsider the following MO-BPP instance.N=8C=100Items12345678ci2060204010301010hi4030306050401060Fig. 1illustrates a feasible packing solution for the example by scanning the permutation one by one, fitting items into each bin while possible, before starting a new bin. The vector of objective functions is (2, 220, 120) which is not necessarily the best solution for the decision maker.In the indirect encoding approach, the metaheuristic handles a permutation of items, which is passed to a greedy decoder that builds a solution for the problem. One advantage of this approach is that all problem-specific information are contained within the decoder, whilst the metaheuristic is kept canonical.For packing problems, the family of any-fit algorithms is known to provide good approximate solutions. They proceed by sorting the items according to a predefined order, and packing each item in an open bin, or in a new one. This latter choice is made following a given strategy (next-fit, first-fit, best-fit, …). Several metaheuristics for packing problems already adopted the items order as an encoding, and an any-fit algorithm as a decoder [24,25].The main drawback of using any-fit algorithms as a decoder is that they are considered as static strategies in the sense that before the launch of the metaheuristic, the strategy parameters (e.g., the items order, the number of bins, …) are predefined and fixed to guide the search. A better alternative is to use a self-adaptive strategy in which the adjustment of the parameters is carried out in the search process of the metaheuristic.As we are dealing with a multi-objective problem, using a single decoder can make the search biased towards certain regions in the objective space. In order to get a balanced distribution of the generated solutions, we adapt two well-known heuristics from the literature: the dot product[19] and the least loaded[1]. These two basic strategies are complementary in the sense that the dot-product strategy aims to minimize the number of bins. However, the least loaded seeks to balance the load among a given set of bins. Therefore we propose, in addition, three other strategies which are different combinations of these methods. The parameters of the decoding strategies are inserted in the solution encoding and adjusted during the search process which leads to self-adaptive metaheuristics.Two basic encoding/decoding strategies are proposed for the MO-BPP. For both strategies, a specific parameter is added to the solution encoding which serves as an input for the decoder.Given a permutation of items, it remains to choose a bin that can accommodate the incoming item. In the 1-dimensional case, a good choice on average is to select the bin with the smallest residual capacity. This corresponds to the well-known best-fit strategy.As a 2-dimensional problem is addressed, there is not an obvious choice of how to assign a weight to the 2-dimensional vector. A good strategy uses the weighted sum of the two dimension in order to weight the resources according to their importance. A scaling vectorw={w1,w2}is used to normalize the sizes across dimensions. A natural choice ofwis the average size of the items in each dimension:w1=(1/N)∑i=1Nciandw2=(1/N)∑i=1Nhi. This aggregation method was applied in the Dot Product heuristic (DP) for the virtual machine consolidation context [19] which performs well for the single objective vector packing problem.This decoder strategy DP initializes a new bin and starts the iterative process by considering the items in the order given by the permutation. At each iteration, the heuristic considers the vector of remaining capacities of each opened bin j in both dimensions rj={r1, r2} and assigns the incoming item i to the bin j that maximizes the weighted dot product between its vector of remaining capacities rjand the vector sizes of item i without violating the capacity constraints.(12)w1×ci×r1+w2×hi×r2In the MO-BPP, the length capacity constraints are soft. Using a direct implementation of DP with an arbitrarily maximum length would lead to unbalanced solutions toward the minimization of the number of bins. For this reason, an additional parameter is used by the decoder. It corresponds to an upper bound (UB) on the maximal length of a bin H.A fixed value of UB would still lead to biased solutions. Hence, this parameter is embedded into the solution encoding and varies during the search. Consequently, the used neighborhood is based on classical moves for permutations, and moves that modify the UB value. Thus, more diversity is added to the search process.A naive maximum useful value of UB corresponds to the sum of lengths of all items. A better maximum is computed by considering the fact that not all items can fit together into one bin because of the weight capacity constraints. This maximum can be computed by solving a knapsack problem where the items sizes are the weights and the profits are the lengths. The smallest useful value of UB is the largest length among the items that can be packed into a single bin. The template of the DP strategy is described in Algorithm 1. Packable is a Boolean variable that takes true if item i is satisfies the capacity constraints of bin j; otherwise it takes false.Algorithm 1The DP strategy templateInput: A list of items σ=(1, …, n), UBOutput: A packing solutionm←1; // Open a new binH←UB; // Initialize the maximum length of the opened binfori←1 tondoforj←1 tomdoTry to pack item i in bin j;ifPackablethenCompute the dot product between its vector of remaining capacities of the bin j and the vector sizes of item i and keep the maximum value (see Eq. (12));endendifj=m+1 then // It fails to pack itemim←m+1; // A new bin is openedAdd item i into the new bin m;elseConsider the bin j that maximizes Eq. (12);Update the remaining capacities of the bin j;endendBased on Algorithm 1, it is worth to note that all opened bins are scanned whenever an item has to be packed. Hence, the time complexity of the DP algorithm takes exactly Θ(n2) per execution in the worst case.Fig. 2describes a packing solution of the illustrative example described above using DP with UB equal to 240. The associated vector of objective functions is (3, 180, 120).The least loaded heuristic (LL) is another greedy heuristic that chooses the bin where the current item has to be packed. It was proposed in the server consolidation context [1]. The goal of this strategy is to balance the load between the bins. Hence, it deals with the minimization of the maximum length. However, the minimization of the number of bins is not guaranteed.The heuristic initializes a list of m empty bins which corresponds to a lower bound on the number of used bins LB and starts the iterative process by considering the items in the order given by the permutation. At each iteration, LL sorts the m available bins in ascending order of total load and tries to pack the incoming item i into one of the current open bins by choosing the least loaded one while satisfying the weight capacity constraints. If LL fails to pack a selected item into the current open bins, a new bin is opened. The process is stopped when there are no more items to pack. The heuristic can be seen as the well known approximating algorithm List Scheduling [11] for the P||Cmax scheduling problem.In order to adapt the LL algorithm to the 2-dimensional context, a valid least loaded bin is selected in terms of the second dimension (i.e., the length). Since this heuristic needs a theoretical lower bound on the number of used bins as an input, we use the same technique as for the DP strategy: a lower bound (LB) on the number of used bins is used to parameterize the decoder and is embedded into the solution encoding. In addition to classical moves (or mutations) for permutations, moves modifying LB during the search process are considered.Fixing a too small LB value leads to results similar to the first-fit heuristic. We consider the minimum possible value of LB as the minimum number of bins needed to pack all items when the second dimension is relaxed. Since this problem remainsNP-hard, we simply use its basic continuous lower bound. The maximum possible LB value corresponds to the number of items which is not likely to lead to interesting results. However, we do not penalize such values that will lead to bad quality solutions and will not be selected by the metaheuristic. The template of the LL strategy is described in Algorithm 2.Algorithm 2The LL strategy templateInput: A permutation of items σ=(1, …, n), LBOutput: A packing solutionm←LB;fori←1 tondoforj←1 tomdoTry to pack item i into the least loaded bin;ifPackablethenAdd item i in the current bin j;break;endendifj=m+1 thenm←m+1;Add item i into the new bin m;endUpdate the order of the bins to keep the list sorted;endWe now analyze the time complexity of the LL algorithm.Based on Algorithm 2, the number of evaluations required by LL algorithm is at most O(d.n2) time per execution, were d is the difference the lower bound LB and the final number of used bins. Note that, the sorting step used in our algorithm does not require O(nlogn) time but O(n) because only the total load of the bin that has accommodated item i is updated at each iteration.Fig. 3illustrates a packing solution for the illustrative example described above using the LL strategy with LB equal to 3. The vector of objective functions is (3, 140, 60).Applying the basic strategies described above can lead to an unbalanced distribution of the potentially efficient solutions in the objective space. The first decoder DP is biased toward minimizing the number of bins, while the second decoder LL is designed to balance the load between the bins. Mixing both strategies is a way to avoid such biases, and provides more diversity in the search space.We propose two different methods for mixing both strategies. The first consists in hybridizing the two basic decoding strategies into a single decoder. The second will be described in the next section.The first strategy, named Combo, considers the items in the order given by the permutation and builds a feasible solution using LL in the first step, and DP in the second step. Applying this strategy in the decoding process can guide the search toward more balanced regions in the objective space.Various configurations of this strategy can occur depending on the application order of each heuristic. One idea is to define a percentage parameter (%) in the solution encoding and modify this value during the search process. For a given percentage parameter, one of the classical decoders described above (LL or DP) is applied for this percentage of the permutation and the other is performed for the remaining items in the permutation. According to preliminary experiments, using firstly DP, and secondly LL does not lead to good results. Therefore, the order in which the decoders are performed is fixed in our hybridized strategy and consists in performing LL in the first step and DP in the second step. When the % parameter is set to 0, only the DP strategy is applied, whereas the value 100 will perform the LL strategy.Within this hybridized strategy, both UB and LB parameters are added in the solution encoding and used as inputs to decode a permutation. This clearly leads the search toward specific areas of the objective space, and may seem similar to ϵ-constraint methods [12]. Note that although LB is used to initialize the solution with a feasible number of bins, the UB value corresponds the length capacity constraint which has to be satisfied when the DP strategy is performed. Thus a solution with more bins than the LB value can be found. Fig. 4illustrates a packing solution of the illustrative example described above using the Combo decoder with % parameter equal to 30, LB equal to 3 and UB equal to 110. The associated vector of objective functions is (4, 100, 60).Another method for combining the two basic strategies is to use both of them during the search. This can be parameterized in different ways. In this strategy the decoder depends on a parameter λ added within the solution encoding.A simple strategy LL-DP consists in using either LL or DP for decoding the solution. In this case, the hybridized decoder Combo is not used. During the search process, the parameter λ oscillates between two values: 0 for LL, and 1 for DP. This strategy is useful to check whether it really improves the search compared to single decoder strategies and the hybridized decoder strategy Combo.The second strategy ED includes the three decoders LL, DP and Combo. In this case λ can take three different values: 0 for LL, 1 for DP or 2 for Combo. The solution is then decoded by one of the three decoders depending on the λ's value. In this strategy the search space is larger than with a single-decoder strategy and allows to find more diversified solutions. Other parameters of the greedy heuristics could be added to the solution encoding (sorting choice for the bins in LL, aggregation function for the dimensions). However, inserting too many parameters would increase the search space without correcting any remaining bias. Therefore, we only kept four parameters: the choice of the decoder, the percentage of the permutation decoded by LL and DP, and the two bounds UB and LB. Fig. 5presents a packing solution of the illustrative example described above using the ED strategy. The vector of objective functions is (4, 100, 40).It is good to mention that with these decoders (LL-DP and ED), not all parameters are used to construct a pattern. For instance, if LL is selected, the upper bound UB needed by DP will not be useful, just LB is used. A good implementation should take care not to apply non-useful moves or mutations (modifying LB when DP is selected for example).

@&#CONCLUSIONS@&#
