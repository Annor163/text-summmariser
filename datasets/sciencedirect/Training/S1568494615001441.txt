@&#MAIN-TITLE@&#
Object tracking via collaborative multi-task learning and appearance model updating

@&#HIGHLIGHTS@&#
We propose a tracking method using both overall information of object and local representation.The object is divided into m overlapped patches to improve tracking performance in background clutter and partial occlusions.We take the prior information into account for avoiding ambiguity in discriminative model.The dictionary is updated by Metropolis–Hastings to capture the appearance changes.We achieve comparable performances with other methods on challenging sequences.

@&#KEYPHRASES@&#
Visual tracking,Particle filter,Sparse representation,Appearance modeling,Multi-task learning,

@&#ABSTRACT@&#
In this paper, we propose a novel visual tracking algorithm using the collaboration of generative and discriminative trackers under the particle filter framework. Each particle denotes a single task, and we encode all the tasks simultaneously in a structured multi-task learning manner. Then, we implement generative and discriminative trackers, respectively. The discriminative tracker considers the overall information of object to represent the object appearance; while the generative tracker takes the local information of object into account for handling partial occlusions. Therefore, two models are complementary during the tracking. Furthermore, we design an effective dictionary updating mechanism. The dictionary is composed of fixed and variational parts. The variational parts are progressively updated using Metropolis–Hastings strategy. Experiments on different challenging video sequences demonstrate that the proposed tracker performs favorably against several state-of-the-art trackers.

@&#INTRODUCTION@&#
Visual tracking is an important and challenging problem in the field of computer vision. It plays a critical role in everyday life such as image compression, motion analysis and activity recognition. One of the difficult issues is the appearance changes due to varying viewpoints, illumination conditions and occlusions. Although much progress has been made in the past decades, some challenging problems in tracking, such as occlusions, background clutter and abrupt appearance changes, etc., are still unsolved.Tracking algorithms based on different appearance model representations can be categorized into two classes. One is generative model, which first learns an appearance model to represent the tracked object, and then searches for the most similar object appearance to the learned appearance model. These methods, either templates based [1–5] or subspace models based [6], can work well when the size of training data is small. Adam et al. [3] proposed fragments-based tracker using integral histogram. The method split the image patch into multiple rectangular sub-regions to model the appearance representation. The final object state was decided by a vote map and robust to partial occlusions. However, only time-invariant appearance template was used, it was hard to capture appearance changes and might lead to drift. Kwon and Lee [4] decomposed the observation and motion models into multiple basic corresponding models to cover a wide range change of the object appearance. Thida et al. [5] presented a particle swarm optimization algorithm that used a set of interactive swarms to track multiple pedestrians in a crowded scene. The low dimensional subspace representation [6] was utilized during the tracking process to model the variations of object appearance, which was learned incrementally and robust to the illumination changes. However, generative model based schemes throw away some useful information, which can discriminate object from background due to not taking into account background information. They are less effective for tracking in cluttered environments.The other is discriminative model, which formulates tracking as a binary classification problem to separate object from background and update template online. It often outperforms generative methods when amount of training data is available. It makes use of information from both the object and background. Avidan [7] proposed an approach that combined a set of online learned weak classifiers into a strong one to label a pixel as belonging to either the object or the background. Grabner et al. [8] proposed an online AdaBoost classifier to update discriminative features and later a semi-supervise algorithm [9] was proposed to handle the updating process, which combined a prior classifier and an online classifier. These methods enabled the tracker to deal with the appearance variations, but abovementioned methods only used one positive sample (i.e. the tracking result) and multiple negative samples to update the classifier. If the positive sample was imprecise, then an undesirable tracking result was added to the template set or the training classifier, the entire tracking scheme would degrade or even fail. In order to address this problem, Babenko et al. [10] proposed multiple-instance learning (MIL) scheme which put the positive samples and negative ones into bags to train an effective classifier for tracking. Kalal et al. [11] proposed P-N tracker using underlying structure of positive and negative samples to learn effective classifier.Although aforementioned schemes performed well in some scenarios, it was easy to lose the object due to the lack of mutual taught principles. In order to alleviate the drift problem, several hybrid generative discriminative methods have been proposed to exploit the benefits from both types of methods. Zhong et al. [12] adopted an approach to combine the generative and discriminative models. But the experimental results were not satisfactory in some video sequences due to the simple hybrid strategy. An improper combination of the two models generates even worse performance than a generative or discriminative method [13].In this paper, we make the following algorithmic and experimental contributions. (1) We propose a multi-task learning tracking algorithm with the collaboration of the generative and discriminative models (GDMTT), which exploits both overall information of object and local representations to track the object. (2) In the particle filter framework, each particle is regarded as a single task, and we divide each task into m overlapped patches which are regarded as local information of the object. The corresponding patches for all the tasks exploit multi-task learning (MTL) scheme to obtain the joint sparse representation. (3) Our confidence measure for the discriminative model explores the distinction between the current information and prior information; while generative confidence measure takes into account more local information of object to handle partial occlusion. (4) The dictionary are composed of fixed and variation parts. The fixed part is manually initialized in the first frame and never changed during the tracking, while the variational parts are selectively updated via the Metropolis–Hastings (M–H) scheme. (5) Our tracker performs favorably against several state-of-the-art tracking algorithms on several challenging videos.The rest of this paper is organized as follows. In Section 2, we summarize the works most related to ours. Section 3 briefly reviews the motivation of the proposed algorithm. In Section 4, we present the proposed tracking algorithm in details. The experiments are shown and analyzed in Section 5. Section 6 discusses the advantage and disadvantage of the proposed approach and the paper finishes with conclusions in Section 7.

@&#CONCLUSIONS@&#
