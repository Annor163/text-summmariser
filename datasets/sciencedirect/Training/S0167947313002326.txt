@&#MAIN-TITLE@&#
Fast estimation of posterior probabilities in change-point analysis through a constrained hidden Markov model

@&#HIGHLIGHTS@&#
We describe a method to assess uncertainty in a set of prespecified change-points.It obtains exact estimates of posterior probability of locations without resampling.A constrained hidden Markov model estimates probabilities in linear time.Methods are implemented in the R package postCP, available on CRAN.Simulations showed comparable loss to Bayesian implementation in estimating means.

@&#KEYPHRASES@&#
Change-point estimation,Segmentation,Posterior distribution of change-points,Constrained hidden Markov model,Forward–backward algorithm,Fast computation,

@&#ABSTRACT@&#
The detection of change-points in heterogeneous sequences is a statistical challenge with applications across a wide variety of fields. In bioinformatics, a vast amount of methodology exists to identify an ideal set of change-points for detecting Copy Number Variation (CNV). While considerable efficient algorithms are currently available for finding the best segmentation of the data in CNV, relatively few approaches consider the important problem of assessing the uncertainty of the change-point location. Asymptotic and stochastic approaches exist but often require additional model assumptions to speed up the computations, while exact methods generally have quadratic complexity which may be intractable for large data sets of tens of thousands points or more. A hidden Markov model, with constraints specifically chosen to correspond to a segment-based change-point model, provides an exact method for obtaining the posterior distribution of change-points with linear complexity. The methods are implemented in the R package postCP, which uses the results of a given change-point detection algorithm to estimate the probability that each observation is a change-point. The results include an implementation of postCP on a publicly available CNV data set(n=120). Due to its frequentist framework, postCP obtains less conservative confidence intervals than previously published Bayesian methods, but with linear complexity instead of quadratic. Simulations showed that postCP provided comparable loss to a Bayesian MCMC method when estimating posterior means, specifically when assessing larger scale changes, while being more computationally efficient. On another high-resolution CNV data set(n=14,241), the implementation processed information in less than one second on a mid-range laptop computer.

@&#INTRODUCTION@&#
The detection of change-points in heterogeneous sequences is a statistical challenge with many applications in fields such as finance, reliability, signal analysis, neurosciences and biology (Pinkel et al., 1998; Snijders et al., 2001). In bioinformatics in particular, a vast amount of methodology (Olshen et al., 2004; Fridlyand et al., 2004; Hupé et al., 2004) exists for identifying an ideal set of change-points in data from array Comparative Genomic Hybridization (aCGH) techniques, in order to identify Copy Number Variation (CNV).A typical expression of the change-point problem is as follows, given dataX=(X1,X2,…,Xn)of real-valued observations,(S1,…,Sn)corresponding segment indices of the observations, andℳKas the set of all possible combinations ofSfor fixedK⩾2number of segments. The goal is to find the best partitioningS∈ℳKintoKnon-overlapping intervals, assuming that the distribution is homogeneous within each of these intervals.ForKsegments of contiguous observations, the segment-based model expresses the distribution ofXgiven a segmentationS∈ℳKas(1)P(X|S;θ)=∏i=1ngθSi(Xi)=∏k=1K∏i,Si=kgθk(Xi),wheregθk(⋅)is the parametric, or emission, distribution (e.g.: normal or Poisson) of the observed data with parameterθk,θ=(θ1,…,θK)is the global parameter, andSiis the segment index at positioni. For example, ifn=5,K=2, and the distribution changes from position 2 to 3, thenS=(1,1,2,2,2).This paper describes an exact method for obtaining the posterior distribution of the segmentationP(S|X;θ)in linear time. Introducing a prior distributionP(S)on anyS∈ℳKobtains the following expression forP(S|X;θ):(2)P(S|X;θ)=P(X|S;θ)P(S)∑RP(X|R;θ)P(R).To simplify the above expression, a uniform prior sets1P(S)=n−1K−1=|ℳK|.A common alternative to the above segmentation procedure is to consider an unsupervised hidden Markov model (HMM). Assuming thatSis a Markov chain of hidden states, this approach (Rabiner, 1989) can be thought of as being level-based, where the parameter of thekth segment takes its value in the set ofL⩾1levels:{θ1,θ2,…,θL}. This simply is equivalent to the model defined by Eq. (1), with the noticeable difference thatS∈{1,2,…,L}n. With this level-based approachK⩾Lin general, and the HMM is unconstrained in the sense that transitions are possible between any pair of states. Similar to the segment-based model, the choice ofLis critical and is usually addressed through penalized criteria. The conventional HMM is an appropriate model when the conditional distribution within a given segment of contiguous observations may be shared among other segments. While the unconstrained HMM is preferable in many practical situations, the segment-based model as described in this paper requires fewer assumptions and is thus a more general model.A convenient feature of these HMM approaches is in computing efficiently the posterior distributionP(S|X;θ)inO(L2n)using classical forward–backward recursions (Durbin et al., 1998), making them suitable for handling large data sets. This paper focuses on using a computationally efficient exact procedure to characterize the uncertaintyP(S|X;θ)of the estimated change-point locations using a hidden Markov model adapted to the conventional segmentation model as previously described. We exploit the effectiveness of the level-based HMM approach through a constrained HMM corresponding exactly to the above segment-based model, providing a fast algorithm for computingP(S|X;θ).We develop this posterior distribution procedure as the uncertainty in change-point assessment in practical applications becomes more challenging from a computational point of view. For example, emerging high-throughput technologies are producing increasingly large amounts of data for CNV detection. For finding the exact posterior distribution of change-pointsP(S|X;θ), Guédon (2007) suggested an algorithm inO(Kn2), while Rigaill et al. (2011) considered the same quantity in a Bayesian framework with the same complexity. However, the complexity of these approaches provides for very slow processing for large data sets with sequences of tens of thousands or more and with ten or more change-points in the data.Other estimates generally focus on asymptotic behavior whose conditions are delicate due to the discreteness of the problem (Bai and Perron, 2003; Muggeo, 2003), on bootstrap techniques (Hušková and Kirch, 2008), estimating waiting time distributions in HMMs (Aston et al., 2012) and on stochastic methods such as particle filtering (Fearnhead and Clifford, 2003), recursive sampling (Lai et al., 2008), and Markov chain Monte Carlo (Erdman and Emerson, 2008). Furthermore, many of the faster stochastic algorithms assume a normal error structure to speed up the estimation procedures and are thus more difficult to adapt to non-normal data (Lai et al., 2008; Erdman and Emerson, 2008).This paper details our procedure to characterize the uncertainty of a pre-specified set of change-points by an exact method in linear time. As such, the procedure is intended to complement any segmentation obtained by existing detection methods, by estimating the posterior probability of the location of each change-point. It can also be used for further applications such as model selection. While the underlying model from our segmentation approach is different from that of a conventional HMM, we apply constraints specifically to enable the use of efficient HMM algorithms for estimating posterior probabilities of interest. Furthermore, our frequentist approach obtains these probabilities in linear time, without resampling.Section  2 presents a summary of current change-point detection methods, the constrained HMM algorithm and a description of the accompanying R statistical package, Section  3 implements the methods on a published array CGH data set and compares with published results, Section  4 presents examples of simple simulated data sets with comparisons between methods, Section  5 shows an illustrative example of the methods on a larger scale SNP array data set, while Section  6 includes a discussion.

@&#CONCLUSIONS@&#
