@&#MAIN-TITLE@&#
A unified panoramic stitching and multi-projector rendering scheme for immersive panoramic displays

@&#HIGHLIGHTS@&#
Generation of panoramic videos requires alignment and stitching of frames.High resolution immersive projection requires multi-projector alignment and rendering.We present a unified panorama stitching and multi-projector rendering scheme.The scheme provides considerable speed-up over traditional stitching and rendering schemes.

@&#KEYPHRASES@&#
Panoramas,Look up Table,Multi camera,Multi projector displays,

@&#ABSTRACT@&#
Panoramic videos provide a high resolution wide-angle field of view to audience. The rendering of such panoramic videos on large multi-projector curved displays further enhances the experience by providing them an immersive visual environment. Immersive panoramic projection thus comprise of three steps: acquisition of videos, stitching of video frames and their projection using multi-projector display system. Both panoramic stitching and multi-projector rendering require compute intensive geometric and photometric transformations that have to be applied for each frame of a video during stitching as well as rendering process. In this paper, we propose a unified scheme that handles these two separate geometric transformations using a single, combined Look up Table (LUT). The scheme allows projection of planar and cylindrical panoramas on curved cylindrical displays. Experimental results show that the proposed scheme provides a speedup of up to 73% and 83% for projector resolutions of HD and 4K respectively, for a two-camera two-projector panoramic display system. Furthermore, for a 4K projector, the proposed scheme requires 2.278ms for the geometric transformation of its content, thus enabling real time panoramic video projection.

@&#INTRODUCTION@&#
Panoramic videos provide wide field of view of an environment by stitching together synchronized video frames from multiple cameras arranged on a rig [1,2]. Once limited to geological surveys, and surveillance applications [3], their uses have been extended to entertainment industry [4–6], high-resolution gaming and filming of movies and live art performances. Furthermore, watching such high definition media content on large immersive projection surfaces is becoming popular in Tele-broadcasting services (e.g., live sports events) [6]. Such immersive projection environments typically utilize a cylindrical projection surface where the content is projected using multiple partially overlapping, projectors to project high-resolution content, which appears as a single large image to the viewer [7,8]. Fig. 1illustrates an end to end panoramic video acquisition, stitching and rendering system. There are two separate processing steps required for the panoramic video projection on large screens to provide an immersive experience: panoramic stitching and multi-projector rendering. Panoramic stitching is comprised of calculating and applying geometric and photometric corrections to individual cameras’ frames resulting in a seamlessly stitched panorama or panoramic frame. For a panoramic video, the time synchronized frames from all the input cameras are stitched together. An immersive projection system can be setup by placing multiple projectors having partial overlapping field of projection on a cylindrical surface [8,22]. Next, a calibration is conducted, which identifies the content of panorama to be projected from each projector and also computes the required geometric and photometric corrections for each projector required to project a seamless image. Rendering geometric correction ensures that projected content in the overlapping projector region are aligned, whereas the photometric correction ensures seamless blending in the overlapping region. Geometric and photometric transformations, required for the generation and rendering of panoramic images, are computationally intensive and require significantly large amount of memory. These requirements further increase as the resolution of input content increase. As an example, a panoramic video acquisition system using 5 High Definition (HD) 1920×1080 cameras of 30 frames per second (FPS) requires two sets of geometric transformations to be applied on approximately 311million pixels per second. Comparatively, a system using 5 Ultra High Definition (UHD)-4K (3840×2160) cameras of 30 frames per second (FPS) needs to process approximately 1.24billion pixels per second. These analyses provide the motivation to explore computationally efficient schemes for multi-projector rendering of panoramic videos. Conventional practices in this area have handled these two problems separately: the stitching transformations are first applied to generate the panoramic video [9], and then the rendering transformations are applied on the panoramic video to project it using multiple projectors on an immersive cylindrical projection surface [10]. The increased use of low cost projectors in sports bars and other venues for projecting sports events has made the service scenario consisting of panorama stitching and multi-projector rendering a common practice.In this paper, we propose a unified approach that utilizes a combined LUT based transformation to account for both the stitching and multi-projector rendering transformations. The intermediate panoramic video is thus essentially not required to be generated. The proposed scheme utilizes perspective and cylindrical stitching modes [11,12] for geometric correction during stitching and Bezier based geometric correction for multi-projector rendering [8] for projection on planar and quadratic surfaces. This is achieved in two stages: a one-time Combined LUT (C-LUT) generation stage and a rendering stage in which the C-LUT is applied. It is assumed that once the geometric corrections have been assessed during calibration they do not change during the recording interval. Organization of upcoming sections is as follows. Section 2 discusses related research work. Section 3 provides a description of the proposed stitching and rendering scheme based on C-LUT. Section 4 contains results of experiments performed on the proposed stitching and rendering system. Section 5 provides the conclusion.

@&#CONCLUSIONS@&#
