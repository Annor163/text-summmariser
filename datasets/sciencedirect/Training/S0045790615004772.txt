@&#MAIN-TITLE@&#
Automatic river target detection from remote sensing images based on image decomposition and distance regularized CV model

@&#HIGHLIGHTS@&#
A new river target extraction method is proposed based on image decomposition and distance regularized CV (Chan–Vese) model.The original image is decomposed based on tensor diffusion and the river target is contained in the cartoon part.The river target is extracted from the cartoon image using distance regularized CV model.

@&#KEYPHRASES@&#
Remote sensing images,River target detection,Image decomposition,Tensor diffusion,Distance regularized CV model,

@&#ABSTRACT@&#
Graphical abstractImage, graphical abstract

@&#INTRODUCTION@&#
River is an important geography target, extracting river channel information is of great importance in the planning and investigation of water resources, the prevention of flood disaster and navigation of ships [1–2]. Remote sensing imaging has a rapid imaging period and a good real-time performance and the resolution of remote sensing images is usually very high. Remote sensing imaging is gradually becoming an essential measure to extract river information. With the development of digital image processing technology, to automatically extract the river target from remote sensing images is becoming real.The existing automatic river target extraction methods from remote sensing images can be roughly divided into 4 categories. 1) The river extraction methods utilizing the intrinsic features of river. The intrinsic features of river mainly include gradient features, grayscale and geometric features and spectral features. Chen [3] proposed a river target detection method using the image gradient information and Fisher discrimination criterion. Chen [4–5] proposed a method to automatically extract river target using the grayscale and geometric features of river in high resolution satellite remote sensing images. Cui [6] used mathematical morphology to eliminate the burr in the image and determine the position of estuary. He also used the spectral features of river to improve the seeds growing algorithm. 2) The river extraction methods based on edge detection. Wang [7] used wavelet transform, image block growing and wavelet snake algorithm to extract the river edge in the SAR images. The method is composed of the following steps. Firstly, the low resolution SAR image is obtained using atrous wavelet transform and the initial edge of target region is extracted using the image block growing algorithm. Secondly, the wavelet coefficients in different scales are iterated to force the wavelet snake approaching the edge of target region from the initial position. Finally the edges of target region in different scales are fused and the precise edge of target is obtained. 3) The river extraction methods based on feature extraction and classification. Zi [8] proposed a method based on the corner features and support vector machine to detect the river target in high resolution remote sensing images. Klemenjak [9–10] proposed a method to automatically extract the river structure from TerraSAR-X data. The method is based on mathematical morphology and supervised image classification techniques and the training samples are automatically selected. 4) Other river extraction methods. Other river extraction methods mainly include frequency filtering method [11] and directional mathematical morphology [12].Remote sensing images containing the river target can be roughly divided into 2 regions: the river region and the background region. The interior zone of river is very smooth which can be considered as in the cartoon part of image and the grayscale of river region is usually lower compared to the background region. The background region usually contains a lot of texture and small targets which may affect the segmentation process. If the original image is firstly decomposed into a cartoon image and a texture image, the river region will be contained in the cartoon image while the texture and small targets in the background region will be contained in the texture image. The image decomposition method proposed in this paper is mainly based on fast cartoon plus texture image filter proposed by Buades [13] but the isotropic filter is replaced by the anisotropic filter using the tensor diffusion [14]. The tensor diffusion algorithm is implemented using the additive operator splitting scheme [15] and the speed of implementation is fast. After the image decomposition process, the cartoon image is composed of river region with low grayscale and the smooth background region with high grayscale. The cartoon image can be segmented using the active contour model based on regional information such as CV model [16]. A distance regularized term [17] is added in the CV model to avoid the reinitialization problem associated with the common level set evolution methods. The cartoon image will be more easily segmented compared with the original image and the segmentation precision is very high. This paper mainly follows the above idea to segment the river target from remote sensing images.The rest of this paper is organized as follows. The image decomposition method based on tensor diffusion is introduced in Section 2. In Section 3, distance regularized CV model is described. The implementation steps of the proposed algorithm are presented in Section 4. Experimental results and analysis of the proposed algorithm are performed in Section 5 and some comparisons with 6 other methods are made. The 6 other methods include the CV model [16], the region-scalable fitting energy level set model [18], the bias field correction level set model [19] applied to the original image and CV model applied to the cartoon image decomposed using the anisotropic diffusion method [20], the Aujol model [21] and the fast cartoon plus texture filter [13]. Concluding remarks are presented in Section 6.The fast cartoon plus texture image filter [13] first considers the linearization of a general variational framework proposed by Meyer. Meyer's model is formulated as an energy minimization problem:(1)inf(u,v)∈X1×X2{F1(u)+λF2(v):f=u+v}where F1, F2 ≥ 0 are functionals and X1, X2 are spaces of functions or distributions such that F1(u) < ∞ and F2(v) < ∞ if and only if (u, v) ∈ X1 × X2. The constant λ > 0 is a tuning parameter. The variational linear model is formulated as the minimization of the energy:(2)minu{σ4∫|Du|2+∥f−u∥H−12}Minimizing this quadratic functional (2) in u yields in Fourier domain the unique solution:u^=L^σf^, where:(3)L^σ(ξ)=11+(2πσ|ξ|)4The solution(u,v)=(Lσ*f,(Id−Lσ)*f)is a pair of complementary low-pass and high-pass filters. The fast cartoon plus texture filter then considers a nonlinear version to retain its main feature. The linear filter in (3) would blur sharp edges in the original image and the fast cartoon plus texture filter introduces a local indicator to decide at each point x whether it belongs to a textural region or to a cartoon region. The main characteristics of a cartoon region are that its total variation does not decrease by low-pass filtering and the main characteristics of a textural region are its high total variation due to its oscillations. This total variation decreases very fast under low-pass filtering. According to these remarks the local total variation (LTV) at x is defined as:(4)LTVσ(f)(x)=Lσ*|Df|(x)The relative reduction rate of LTV is defined by a function x↦λσ(x), given by:(5)λσ(x)=LTVσ(f)(x)−LTVσ(Lσ*f)(x)LTVσ(f)(x)which gives us the local oscillatory behavior of the function f. If λσ(x) is close to 0, it means that there is little relative reduction of the local total variation by the low-pass filter. If instead λσ(x) is close to 1, the reduction is important and it means that the considered point belongs to a textural region. Thus, a fast nonlinear low-pass and high-pass filter pair can be computed by the weighted averages of f and Lσ*f depending upon the relative reduction of LTV. We can set:(6)fcartoon(x)=w(λσ(x))(Lσ*f)(x)+(1−w(λσ(x)))f(x)ftexture(x)=f(x)−fcartoon(x)where w(x): [0, 1] → [0, 1] is an increasing function that is constant and equal to zero near zero and constant and equal to 1 near 1. The function w(x) given in [13] is defined by:(7)w(x)={0x≤a1(x−a1)/(a2−a1)a1≤x≤a21x≥a2where the parameters a1 and a2 have been respectively fixed to 0.25 and 0.5 in all the experiments.There is only one parameter changing in the fast cartoon plus texture filter which is the texture scale σ. If we analyze Eq. (5) carefully we can see that if σ equals a small number, then the LTV of some regions containing large scale texture will not change much after low-pass filtering. The relative reduction of the LTV of those regions will be small so these points will be considered as in the carton region. Thus the cartoon image decomposed will contain the large scale texture. But when σ equals a large number, the LTV of the edges will change much after low-pass filtering. The relative reduction of the LTV of those regions will be close to 1 so these points will be considered as in the textural region. Thus the texture image decomposed will contain the edges which should belong to the cartoon region. In the experiment we also find that if σ equals a small number then much of the texture will remain in the cartoon image while when σ equals a large number then the cartoon edges will be blurred and there are edges in the texture image. For an image containing texture with different scales, there is no single σ which will give a satisfactory decomposition. The reason is that in the filtering process of the original image, the isotropic filter is used (3) which cannot distinguish between the edge and the textural region with large scale. Here we can improve the fast cartoon plus texture filter by replacing isotropic filter (3) by anisotropic filter using tensor diffusion.The tensor product matrix is defined as follows:(8)J0(∇uσ*)=∇uσ*⊗∇uσ*=∇uσ*∇uσ*Twhereuσ*is an image filtered by a Gaussian kernel and is defined as follows:(9)uσ*(x,t)=(Kσ**u(.,t))(x)(σ*>0)(10)Kσ*(x)=1(2πσ*2)m/2·exp(−|x|22σ*2)where m is the dimension of the image domain and σ* denotes the noise scale.∇uσ*is the gradient ofuσ*. The tensor product matrix reflects the local orientation of the structure and can be averaged component wisely by a Gaussian kernel Kρto form the structure tensor:(11)Jρ(∇uσ*)=Kρ*(∇uσ*⊗∇uσ*)(ρ≥0)Let its eigenvalues μ1, ..., μmbe ordered such that:(12)μ1≥μ2≥...≥μmand let {w1, ..., wm} denote the corresponding orthonormal set of eigenvectors. The integration scale ρ should reflect the characteristic size of the texture. Here we should note that the parameter ρ has similar effect as the parameter σ in fast cartoon plus texture filter but there is significant difference between ρ and σ. The parameter σ in fast cartoon plus texture filter cannot distinguish between the textural region with large scale and the edge but parameter ρ can. We can choose the parameter ρ equals the size of textural region with large scale. The main property of textural region is that the local orientations of nearby pixels are different. After convolution with the Gaussian kernel Kρthe different orientation of pixels in the textural region with large scale will be averaged and the structure tensor matrix of textural region with large scale will not have strongly differing eigenvalues. The main property of edge is that the local orientations of pixels along the edge are nearly the same. The convolution operation will not affect the local orientation of the edge. The averaged orientation of the edge will be the same as the local orientation and the structure tensor matrix of the edge will have strongly differing eigenvalues. We can define a measure which can reflect the strength of orientation as follows:(13)κ=∑i=1m−1∑j=i+1m(μi−μj)2which can be used to discriminate between edge and textural region with large scale.The principle of nonlinear diffusion filtering can be summarized as follows. One calculates a diffused version u(x, t) of f(x) with a scale parameter t ≥ 0 as the solution of a diffusion equation with f as the initial condition and reflecting boundary conditions:(14)∂tu=div(D∇u)onΩ×(0,∞),(15)u(x,0)=f(x)onΩ,(16)<D∇u,n>=0on∂Ω×(0,∞).where, n denotes the outer normal and < ., . > the usual inner product. We construct the diffusion tensor D such that it has the same eigenvectors as Jρand its eigenvalues are given by:(17)λi=11+(κK)fori=1,...,m−1, and by:(18)λm=1K serves as a threshold parameter: for κ ≫ K we get λi≈ 0 which means that when the strength of its orientation is strong, the smoothing along the direction wiis small. For κ ≪ K leads to λi≈ 1 which means that when the strength of its orientation is weak, the smoothing along the direction wiis strong. The tensor diffusion equation can be solved efficiently by additive operator splitting (AOS) scheme.If the isotropic filter (3) is replaced by the anisotropic diffusion filtering using tensor diffusion, the image decomposition formula (6) can be rewritten as:(19)fcartoon(x)=w(λσ(x))TD(f(x))+(1−w(λσ(x)))f(x)ftexture(x)=f(x)−fcartoon(x)where TD(f(x)) is the image f(x) diffused with structure tensor, and the local total variation of f(x) is computed by:(20)λσ(x)=LTVσ(f)(x)−LTVσ(TD(f))(x)LTVσ(f)(x)the function w(x) is the same as in Eq. (7). After the image is decomposed into a cartoon image and a texture image, the cartoon image is segmented using the distance regularized CV model described below.Assume Ω⊂R2 is the image domain, I: Ω → R is the given grey value image. Mumford and Shah [22] modeled the image segmentation problem as follows: given an image I, the object is to find a contour C segmenting the image into non-overlapping regions. They propose to use the following energy functional:(21)FMS(u,C)=∫Ω(u−I)2dx+μ∫Ω∖C|∇u|2dx+υ|C|where |C| is the length of the contour C. To minimize the above Mumford-Shah functional the optimal contour segmenting the original image I can be obtained as well as an image u approximating the original image I. The image u is piece-wise smooth inside the connected region segmented by the contour C. In practice, since the exact location of the contour C is unknown and the energy functional is not convex, it is very difficult to minimize the functional (21).Chan and Vese [16] simplify the above Mumford–Shah problem by assuming the original image I can be represented by piecewise constant function. For an image defined in the image domain Ω, they propose minimizing the following energy functional:(22)FCV(C,c1,c2)=λ1∫outside(C)|I(x)−c1|2dx+λ2∫inside(C)|I(x)−c2|2dx+υ|C|where outside(C) and inside(C) represent the regions outside and inside the contour C respectively, c1 and c2 are constants approximating the image grey values outside and inside the contour C, λ1 and λ2 are parameters representing the regional energy andυis a parameter representing the length of the contour. The energy above can be represented by a level set function and the energy minimization problem is thus transformed into a level set evolution equation. The constants c1 and c2 minimizing the first two terms in the energy functional (22) is the image average grey values outside and inside the contour C.The evolution process of the level set function is to start from an initial level set function and approach the final position gradually. The initial level set function is usually defined as a signed distance function. During the evolutionary process of the level set function it will become irregular causing mistakes in data and will destroy the evolutionary process of the level set function. The traditional method to overcome this phenomenon is to reinitialize the level set function to make it stable during the evolutionary process. The reinitialization procedure is to periodically stop the evolutionary process and make the degraded level set function to be a signed distance function. Although reinitialization can regularize the level set function, it can make the zero level set diverge from the right position and the reinitialization procedure should be avoided.In order to avoid reinitialization, a distance regularized term can be introduced in the energy functional (22). The distance regularized term is defined as follows:(23)Rp(ϕ)Δ=∫Ωp(|∇ϕ|)dxwhere p is a potential function p: [0, ∞) → R. p can be given as follows [17]:(24)p(s)={1(2π)2(1−cos(2πs)),ifs≤112(s−1)2,ifs>1the function p has two local minima which are s = 0 and s = 1.Through adding the distance regularized term in the energy functional (22), the distance regularized CV model can be formulated as:(25)FDRCV(C,c1,c2)=λ1∫Ω|I(x)−c1|2H(ϕ)dx+λ2∫Ω|I(x)−c2|2(1−H(ϕ))dx+υ∫Ωδ(ϕ(x))|∇ϕ(x)|dx+μ[1(2π)2∫Ω(1−cos(2π|∇ϕ|))dxH(1−|∇ϕ|)+12∫Ω(|∇ϕ|−1)2dxH(|∇ϕ|−1)]where H represents the Heaviside function and is defined as follows:H(z)={1,ifz≥00,ifz<0δ represents the Dirac function and is the derivative of H(z), parameter μ represents the energy of the distance regularized term.The level set evolution equation can be obtained from (25) as:(26)∂ϕ(x)∂t=−δ(ϕ(x))(λ1(I(x)−c1)2−λ2(I(x)−c2)2)+υδ(ϕ(x))div(∇ϕ(x)|∇ϕ(x)|)+μ[div(sin(2π|∇ϕ(x)|)2π|∇ϕ(x)|∇ϕ(x))H(1−|∇ϕ(x)|)+div(∇ϕ(x)−∇ϕ(x)|∇ϕ(x)|)H(|∇ϕ(x)|−1)]Eq. (26) can be discretized and can be computed using the following equation:ϕk′+1(x)=ϕk′(x)+ΔtCV∂ϕk′(x)∂twhere k′ and ΔtCV represent the iteration number and time step respectively.In this section we briefly describe the algorithm implementation steps. First the original image is decomposed based on tensor diffusion and a cartoon image and a texture image can be obtained. The river region is contained in the cartoon image. Then the cartoon image is segmented using distance regularized CV model and the river region is thus extracted. The flow chart of the proposed algorithm is shown in Fig. 1.Below we will give a pseudo code for implementing the proposed algorithm.1.Input: the original river image u0 and the parameters a1, a2, σ, σ*, ρ, K, Δt, Tdiff, λ1, λ2,υ, μ, ΔtCV, TCV;a1, a2: parameters in the function w(x)σ: the kernel width of the low-pass filter to calculate the local total variationσ*: the kernel width of the Gaussian kernel to smooth the original image in tensor diffusionρ: the kernel width of the Gaussian kernel to form the structure tensor in tensor diffusionK: threshold parameter of strength of orientationΔt: time step in tensor diffusionTdiff: total iteration number in tensor diffusionλ1, λ2: parameters representing the regional energyυ: parameter representing the length of the contourμ: parameter representing the energy of the distance regularized termΔtCV: time step in CV modelTCV: total iteration number in CV modelDo tensor diffusion to the original image;for k = 0:1:Tdiff2.1Pre-filter the image:uk,σ*=Kσ**uk;Calculate the tensor product matrix:∇uk,σ*⊗∇uk,σ*;Convolve the tensor product matrix to form the structure tensor matrix:Kρ*(∇uk,σ*⊗∇uk,σ*);Do eigenvalue decomposition to the structure tensor matrix;Calculate the diffusion tensor using the results obtained in 2.4;CalculateVk=(I+Δt∑i=12∑j≠iLijk)Uk;CalculateWlk+1=(2−4ΔtLllk)−1Vk(l=1, 2);CalculateUk+1=∑l=12Wlk+1;endAfter doing tensor diffusion, we obtain uTD;Do cartoon-texture decomposition to the original image using the tensor diffusion image uTD;3.1Calculateλσ(x)=LTVσ(u0)(x)−LTVσ(uTD)(x)LTVσ(u0)(x)Calculateucartoon(x)=w(λσ(x))uTD(x)+(1−w(λσ(x)))u0(x)After doing cartoon-texture decomposition, we obtain ucartoon;Segment ucartoon using distance regularized CV model;for k′ = 0:1:TCV4.1Calculate∂ϕk′(x)∂t=−δ(ϕk′(x))(λ1(ucartoon(x)−c1)2−λ2(ucartoon(x)−c2)2)+υδ(ϕk′(x))div(∇ϕk′(x)|∇ϕk′(x)|)+μ[div(sin(2π|∇ϕk′(x)|)2π|∇ϕk′(x)|∇ϕk′(x))H(1−|∇ϕk′(x)|)+div(∇ϕk′(x)−∇ϕk′(x)|∇ϕk′(x)|)H(|∇ϕk′(x)|−1)];Calculateϕk′+1(x)=ϕk′(x)+ΔtCV∂ϕk′(x)∂t;endAfter segmenting, we obtain segmentation resultϕTCV+1(x);Output: segmentation resultϕTCV+1(x).Aiming at the proposed river target detection method from remote sensing images based on the image decomposition and the distance regularized CV model, three remote sensing river images have been used. In order to verify the effectiveness of the method proposed, some comparisons have been done with 6 other methods. The 6 methods include the original CV model [16] (abbreviated as CV in the table), the region-scalable fitting energy level set model [18] (abbreviated as RSF in the table) and the bias field correction level set model [19] (abbreviated as BFC in the table) applied to the original remote sensing images containing the river target and the CV model applied to the cartoon image decomposed by the anisotropic diffusion [20] (abbreviated as AD+CV in the table), the Aujol model [21] (abbreviated as Aujol+CV in the table) and the fast cartoon plus texture filter [13] (abbreviated as FCT+CV in the table). In the experiment, the parameters are set as follows: the scale of the linear filter in (3) isσ=1, the width of the Gaussian kernel in (10) isσ*=1, the threshold parameter in (17) is K = 1000, the width of the Gaussian kernel in (11) isρ=10, the time step in (2.6) isΔt=1, the parameters of the distance regularized CV model areλ1=λ2=1,υ=10−4×2552,μ=0.1andΔtCV=1. Since the texture components in different images are not the same, the iteration number of tensor diffusion is also different. Since remote sensing image 1 contains more texture, the iteration number of remote sensing image 1 should be larger. For remote sensing image 1, the iteration number is 20 and for remote sensing images 2 and 3, the iteration number is 10. The iteration number of the active contour model in all the methods is set to 100. The initial zero level set of the active contour in all the methods is a circle with radius 50 and centered in the center of image. The experimental environment is Intel(R) Atom(TM) CPU D2700 2.13GHz/2.00 GB RAM/MATLAB 7.6.0. The segmentation results of all the methods as well as the cartoon image, the texture image decomposed using the method proposed are shown in Figs. 2, 3and 4, respectively.From the images shown above, we can see that the original remote sensing images contain a lot of texture in the background region while the river region is relatively smooth with low grey value. If the active contour model such as the CV model is directly applied to the original image, the textural part will also be segmented. This can be clearly seen from Figs. 2(b), 3(b) and 4(b). The region-scalable fitting energy level set model and the bias field correction level set model cannot segment these remote sensing images correctly and the convergence speed of these 2 models is very slow compared with the CV model. The next 4 methods are all based on the image decomposition. For images segmented using the anisotropic diffusion decomposition and the CV model, we can see from Figs. 2(e), 3(e) and 4(e) that the number of non-river targets is less than the images segmented using CV model which means that image decomposition can reduce the texture components in the original images and thus reduce the number of non-river targets in the segmentation results. But the number of non-river targets is still very large. This is because anisotropic diffusion decomposition cannot remove much texture components in the original images and those texture components left will be segmented as the non-river targets in the results. For images segmented using the Aujol model and CV model, we can see from Figs. 2(f), 3(f) and 4(f) that the number of non-river targets is very small compared to previous methods but the river target is not segmented precisely which means that the edge of river target has been smoothed. The Aujol model can remove texture from the original image very well but will also blur the edge. This effect will cause imprecise segmentation result of river target. For images segmented using the fast cartoon plus texture filter and CV model, the number of non-river targets is more than the Aujol segmentation method but less than the anisotropic diffusion decomposition segmentation method. But the edge of river target using this method is not very precise. For images segmented using the method proposed, we can see that the number of non-river targets is small and the edge of river target is accurate. We can further look at the cartoon image and the texture image decomposed using the method proposed, from the decomposition results we can see that the texture components are removed and the edge is not blurred which means that the decomposition method proposed is effective.The objective evaluation index including the number of miss classified pixels, the FOM value between the edge of ground truth image and the edge of segmented river target and the running time of the method proposed and 6 other comparing methods are listed in Tables 1, 2and 3, respectively. The best values are presented in bold character. In Table 1, the number of miss classified pixels of RSF and BFC method is not given since these two methods fail in segmenting the river images. For image 1, the number of miss classified pixels of the fast cartoon plus texture filter segmentation method is the smallest and for images 2 and 3, the Aujol segmentation method gets the smallest number of miss classified pixels. The number of miss classified pixels of the method proposed is a little more than the Aujol decomposition segmentation method which agrees with the previous analysis but the FOM values of the method proposed is the highest among all the methods which means that the method proposed is the most accurate. The running time of the method proposed is longer than the CV model segmentation method, the anisotropic diffusion decomposition segmentation method and the fast cartoon plus texture filter segmentation method. Above all, the segmentation results of the method proposed are the best.

@&#CONCLUSIONS@&#
Aiming at the segmentation problem of river target from remote sensing images, a segmentation method based on the image decomposition and distance regularized CV model is proposed. First the original image is decomposed into a cartoon image and a texture image. The isotropic filter in the fast cartoon plus texture filter is replaced by the anisotropic tensor diffusion filter and the textural region with large scale can be removed while the edge will not be blurred. Then the distance regularized CV model is applied to the cartoon image to segment the river target. Compared with 6 other methods, the precision of the method proposed is the highest among all the methods. Using the method proposed, river target can be automatically extracted from remote sensing images for future analysis and research. Here we also point out two main disadvantages of the proposed algorithm. Firstly, there are too many parameters to be set in the proposed algorithm and those parameters have to be set manually. Secondly, the running time of the proposed algorithm is 10% longer compared with CV model. In the future research, we shall find a method to automatically set those parameters.