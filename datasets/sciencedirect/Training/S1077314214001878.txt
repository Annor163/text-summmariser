@&#MAIN-TITLE@&#
Spatial histograms of soft pairwise similar patches to improve the bag-of-visual-words model

@&#HIGHLIGHTS@&#
A new approach to improve image representation for category level classification.We encode pairwise relative spatial information of patches in the bag of word model.A simple approach complementary to the Spatial Pyramid Representation (SPR).Can be combined with SPR and outperforms other existing spatial methods.Experimental validation of the approach is shown on 5 challenging datasets.

@&#KEYPHRASES@&#
Spatial information,Object classification,Angle and distance histograms,Bag-of-words,

@&#ABSTRACT@&#
In the context of category level scene classification, the bag-of-visual-words model (BoVW) is widely used for image representation. This model is appearance based and does not contain any information regarding the arrangement of the visual words in the 2D image space. To overcome this problem, recent approaches try to capture information about either the absolute or the relative spatial location of visual words. In the first category, the so-called Spatial Pyramid Representation (SPR) is very popular thanks to its simplicity and good results. Alternatively, adding information about occurrences of relative spatial configurations of visual words was proven to be effective but at the cost of higher computational complexity, specifically when relative distance and angles are taken into account. In this paper, we introduce a novel way to incorporate both distance and angle information in the BoVW representation. The novelty is first to provide a computationally efficient representation adding relative spatial information between visual words and second to use a soft pairwise voting scheme based on the distance in the descriptor space. Experiments on challenging data sets MSRC-2, 15Scene, Caltech101, Caltech256 and Pascal VOC 2007 demonstrate that our method outperforms or is competitive with concurrent ones. We also show that it provides important complementary information to the spatial pyramid matching and can improve the overall performance.

@&#INTRODUCTION@&#
In category level and scene classification, the bag-of-visual-words (BoVW) method, first introduced by [1,2], has shown excellent results in recent years [3,4]. In this method, an image is represented as a histogram of quantized local features called visual words. However, being orderless, histogram representations do not provide any spatial information. This is considered to be one of the major drawbacks of this very successful method.Different methods have been proposed to incorporate spatial information into the BoVW representation [3,5–8]. Some of these approaches use spatial context before the vocabulary construction step to incorporate spatial information [9–11]. The spatial context is defined at the local feature level as a set of descriptors extracted form neighboring regions so as to enrich the description around a feature point. For example in [11], the authors create pairs of local neighbor SIFT descriptors, concatenate them and construct the vocabulary from these 256-D combined features instead of from the classical individual 128-D SIFT. Alternatively, most of the approaches work at the visual word level. They model the spatial arrangements of visual words on the 2D image space as an additional step [3,5,8,12–17]. These later methods are more popular as they obtain superior classification accuracies. It is due to the fact that they are able to capture both local and global relationships among the visual words.In this context, the Spatial Pyramid Representation (SPR) [3] is probably the most notable work. Its principle relies on the division of an image into sub-windows and the computation of a local BoVW histogram in each. Two images are then compared by using an intersection kernel computed between the two corresponding sets of histograms.Although SPR performs very well, it only captures the information about approximate absolute locations of the visual words in images. An alternative consists in extracting relative spatial interactions between the visual words [7,17,14,18–20]. In these representations, the absolute location of each visual word is lost but, for example, information about visual words that are frequently co-occurring together at a certain distance is taken into account. However, the abundance of visual words in an image makes it computationally expensive to explicitly model relative spatial relationships among visual words. Thus, methods like [6,7] employ vocabulary compression or feature selection and model only local or semi-local spatial information to speed up the computation. Nevertheless, Elfiky et al. [21] have shown that vocabulary compression before spatial information extraction results into declined classification performance. In another work, Parikh [22] examines the human vs machine performance on jumbled images and concludes that existing machine vision techniques are already effective in modeling local information from images, thus future research efforts should be focused on more advanced modeling of global information.Based on these observations, in this work, we propose a way to model the global and local relative spatial distribution of visual words over an image. To do so, we introduce the concept of soft pairwise spatial angle-distance histograms to capture the distribution of similar descriptors. The term “soft” means that we apply a soft weighting strategy in a similar way as soft assignment techniques [23,24].The novelty compared with previous approaches is threefold: (i) enabling infusion of pairwise relative spatial information (modeling both distances and angles between visual words while most of the approaches consider only distances), (ii) adopting a simple word selection scheme that avoid combinatorial explosion, and (iii) combining hard assignment for visual word selection and soft assignment to weight the contribution of descriptor pairs in spatial histograms.We experimentally evaluate our new representation on classification tasks with various challenging data sets. The aim is both to study the influence of various parameters of the method and to compare the performances over state of the art concurrent approaches.The rest of the paper is organized in the following way: the next section describes a review of the related works. Section 3 presents our approach to incorporate spatial information into the BoVW representation. Section 4 describes the implementation details and Section 5 presents the results on different benchmarks and comparisons with several other methods. Section 6 concludes the article pointing towards our future works.

@&#CONCLUSIONS@&#
