@&#MAIN-TITLE@&#
An integrative cooperative search framework for multi-decision-attribute combinatorial optimization: Application to the MDPVRP

@&#HIGHLIGHTS@&#
New methodology for multi-attribute combinatorial optimization.Decomposition method based on decision-set attributes of the problem.New cooperative search framework with adaptive search-guidance mechanism.Extensive numerical experiments to characterize the new methodology.Improve the state-of-art for the multi-depot, periodic vehicle routing problem.

@&#KEYPHRASES@&#
Multi-attribute combinatorial optimization,Integrative cooperative search,Meta-heuristics,Decision-set decomposition,Multi-depot periodic vehicle routing,

@&#ABSTRACT@&#
We introduce the integrative cooperative search method (ICS), a multi-thread cooperative search method for multi-attribute combinatorial optimization problems. ICS musters the combined capabilities of a number of independent exact or meta-heuristic solution methods. A number of these methods work on sub-problems defined by suitably selected subsets of decision-set attributes of the problem, while others combine the resulting partial solutions into complete ones and, eventually, improve them. All these methods cooperate through an adaptive search-guidance mechanism, using the central-memory cooperative search paradigm. Extensive numerical experiments explore the behavior of ICS and its interest through an application to the multi-depot, periodic vehicle routing problem, for which ICS improves the results of the current state-of-the-art methods.

@&#INTRODUCTION@&#
Combinatorial optimization problems prominently appear in many theoretical and real-life settings. A large number of methodological developments targeted these problems proposing exact, heuristic, and meta-heuristic solution methods. Parallel computing enhanced these optimization methods providing the means to accelerate the resolution process and, for meta-heuristics, to obtain higher-quality solutions for a broad range of problems (Crainic & Toulouse, 2010).Yet, although solution methods become more powerful, the combinatorial problems one faces grow continuously in size and difficulty, as defined by the number of interacting characteristics defining their feasibility structures and optimality criteria. Such increasingly larger sets of characteristics severely challenge our methodological capability to efficiently address the corresponding problem settings. Thus, the general approach when addressing such multi-attribute, also informally known as rich, problem settings is to either simplify them, or to sequentially solve a series of restricted problems where part of the overall setting is fixed or ignored. It is well-known, however, that such approaches lead to sub-optimal solutions. Moreover, one observes in many application settings, including vehicle routing, network design, and carrier service network design, the need to comprehensively address the associated combinatorial optimization formulations to simultaneously account for “all” relevant characteristics. The current literature does not offer a satisfactory answer to this challenge in terms of methods able to efficiently address multi-attribute problem settings and provide good solutions. The goal of this paper is to contribute toward addressing this challenge.We focus on decision-based characteristics, called decision-set attributes in the following, i.e., the sets of decisions defining the particular problem setting, and introduce the Integrative Cooperative Search (ICS), a multi-thread cooperative search method. ICS musters the combined capabilities of a number of stand-alone solution methods, exact or meta-heuristic, some of which work on sub-problems defined by suitably selected subsets of decision-set attributes of the problem, while others integrate the resulting partial solutions into complete ones and, eventually, improve them. These methods cooperate through an adaptive search-guidance mechanism, using the central-memory cooperative search paradigm. We present and discuss the ICS concept, its structure, main building blocks, and operating principles, together with a proof-of-concept of its efficiency.To illustrate the efficiency of ICS, one must identify a problem setting sufficiently rich to warrant the application of ICS, while also providing state-of-the-art results for valid comparisons. We selected the Multi-Depot Periodic VRP (MDPVRP), which encompasses decisions on 1) selecting a visit pattern for each customer, specifying the particular periods the customer is to be visited over the multi-period planning horizon, and 2) assigning each customer to a depot for each visit. This multi-attribute problem was considered until quite recently as difficult to address as a whole. New exact (Baldacci, Bartolini, Mingozzi, & Valletta, 2011; Baldacci & Mingozzi, 2009) and meta-heuristic (Vidal, Crainic, Gendreau, Lahrichi, & Rei, 2012) contributions have re-defined the state-of-the-art proposing valuable best-known solutions (BKS) to which the results of ICS are confronted.The main contributions of this paper are to:1.Introduce and formally describe a new meta-heuristic solution framework for multi-attribute combinatorial optimization problems; ICS is general, flexible, and scalable in the number of attributes defining the problem at hand;Define and exploit a functional decomposition of such problems along decision-set attributes;Illustrate ICS through an application to a well-known multi-attribute problem setting, the MDPVRP, for which ICS improves the results of the current state-of-the-art methods and discuss how to apply the methodology to other combinatorial optimization problem classes;Show the interest of the proposed method by experimentally evaluating its components.This paper is organized as follows. Section 2 discusses the motivation for our work and identifies the sources of inspiration for the methodology we propose. Section 3 introduces the fundamental concepts underlining the Integrative Cooperative Search methodology, particularly the decision-set attribute-based decomposition and the ICS algorithmic structure. We illustrate these concepts and methods through an application to the MDPVRP (Section 4.1), as well as an analysis on an extensive set of experiments (Section 4.2.) We finally conclude.We aim to address extended versions of classical combinatorial-optimization problems, which are NP-hard in their basic forms. These versions generally aim to answer the requirements of real-world cases and involve several “new” characteristics that must be considered while searching for feasible solutions of high quality. The set of decisions to be considered is then much broader than for the basic problem settings, each new group of characteristics and decisions compounding the difficulty of the problem and complicating the solution process, particularly when one aims to address them simultaneously.Two examples, selected from major operations research applications, illustrate this observation. Network design aims to select among a set of possible facilities on arcs, nodes, or both, such that the demand for using the resulting network is satisfied at the minimum total cost of selecting the facilities and using the network. Many particular design problem settings have been defined during the years, the vast majority focusing on the facility-selection and demand-flow decisions (Crainic, 2000; Drezner & Hamacher, 2002; Grötschel, Monma, & Stoer, 1995; Magnanti & Wong, 1984). Crainic, Chiara, Nonato, and Tarricone (2006a) describe a realistic setting of a wireless network design problem, where the decision set includes not only the selection of base stations to cover a given territory, but also the selection of the number of antennae for each base station, as well as their height, power, tilt, and orientation.Vehicle routing offers the second example. An extensive literature addresses the Capacitated Vehicle Routing Problem (CVRP), which aims to construct cost-efficient routes to deliver the demand of a given set of customers with a fleet of vehicles of limited capacity operating out of a unique depot (Golden, Raghavan, & Wasil, 2008; Toth & Vigo, 2002), and its many extensions reflecting the variety of applications, e.g., multiple depots, customer requirements for multi-period visits, time windows on service at customers or activities at depots, route restrictions on total distance or time, etc. (Vidal, Crainic, Gendreau, & Prins, 2013). Yet, this proliferation of VRP variants is not sufficient to address many real-world settings (Golden, Assad, & Wasil, 2002), and one increasingly observes the enrichment (the “rich” qualification first appeared in the VRP literature; Hartl, Hasle, & Jansens, 2006) of the set of characteristics considered in routing formulations.Adding characteristics to particular problem elements, e.g., timing concerns in VRPs given time-window customer requirements, makes problems more difficult to address, but may be handled within particular algorithmic components, e.g., route generation and sequencing. Such problem extensions might thus require a more involved algorithmic component (Vidal, Crainic, Gendreau, & Prins, 2015, 2014), but does not change fundamentally the nature of the problem. Adding more decision sets to the problem, on the other hand, makes it significantly harder to address and, thus, the general approach when addressing such multi-attribute problems is to either simplify them, or to sequentially solve a series of particular cases, where part of the overall problem is fixed or ignored, or both (e.g., Golden et al., 2002; Hadjiconstantinou & Baldacci, 1998; Hartl et al., 2006; Homberger & Gehring, 1999, 2005). It is well-known that this leads to sub-optimal solutions.So, how to proceed to build a general, scalable, and efficient method to address multi-attribute combinatorial optimization problems in a comprehensive manner? We were inspired by two major methodological concepts: decomposition and cooperative search.Decomposition is a fundamental technique in mathematical programming (Lasdon, 2002), e.g., the Dantzig–Wolfe decomposition with column generation (Dantzig & Wolfe, 1978), Bender’s decomposition (Benders, 1962), and Lagrangian-based mechanisms (Geoffrion, 1970; Guignard & Kim, 1987), as well as in parallel/distributed computing particularly for domain or low-level functional decomposition (Alba, 2005; Bertsekas & Tsitsiklis, 1989; Crainic, Cun, & Roucairol, 2006b; Crainic & Toulouse, 2010; Gendron & Crainic, 1994; Talbi, 2006). The main objective of all these strategies is to transform a difficult-to-address formulation into a number of “simpler” ones for which efficient solution methods are available. Simplification is thus part of decomposition, the challenge of defining “simpler” sub-problems resting with the search for the right equilibrium between an easy-to-address formulation and the usefulness of the corresponding results. The challenge is present for exact and heuristic decomposition methods alike. Thus, selecting the appropriate set of constraints to dualize in a Lagrangian-based strategy is highly influential of the form and difficulty of the resulting sub-problems (e.g., Crainic, Frangioni, & Gendron, 2001, for network design). In following this decomposition idea for multi-attribute combinatorial optimization problems, we propose a heuristic strategy (Section 3.1) that aims for opportunistic simplification in generating sub-problems for which efficient solution methods already exist or may be easily developed.Decomposition-based methods encompass three main mechanisms. The first, decomposition, defines how the problem is transformed and sub-problems are derived. The second, integration, brings together the results obtained working on the sub-problems, creates complete solutions to the original problem and, eventually, continues the decomposition-based algorithm. The third specifies the information exchanged and defines how the complete method evolves. While the actual definition of a mathematical programming decomposition method embeds these mechanisms, they must be specifically defined for heuristic strategies. We turn to the cooperative-search paradigm to define the mechanisms for the Integrative Cooperative Search method we propose.Cooperative search (Crainic, 2005; Crainic & Toulouse, 2008, 2010) has emerged as one of the most successful meta-heuristic methodologies to address hard optimization problems (see, e.g., the surveys of Crainic, 2008; Crainic & Hail, 2005 and the books of Alba, 2005; Talbi, 2006; Talukdar, Murthy, & Akkiraju, 2003). Cooperative search is based on harnessing the capabilities of several solution methods through cooperation mechanisms providing the means to asynchronously share information while addressing the same problem instance (and create new information out of the exchanged data in advanced settings). Cooperative-search strategies are mainly defined by (1) the solution methods engaged in cooperation (including the same method with different parameter settings or populations); (2) the nature of the information shared, e.g., the current best solution and contextual information about the status of the search; (3) how the sharing proceeds and how the global search is controlled: diffusion among “neighboring” solution methods arrayed in particular communication architectures, e.g., fine-grained, cellular GA (e.g., Cantú-Paz, 2005; Luque, Alba, & Dorronsoro, 2005) and multi-level cooperative search (Toulouse, Thulasiraman, & Glover, 1999); direct exchanges among processes, e.g., coarse-grain, island GA (Cantú-Paz, 2005; Luque et al., 2005), A-teams (Talukdar, Baerentzen, Gove, & de Souza, 1998; Talukdar et al., 2003), and Collegial Asynchronous strategies (Crainic, Toulouse, & Gendreau, 1996, 1997); indirect exchanges through a common data repository and management structure, e.g., adaptive (Badeau, Gendreau, Guertin, Potvin, & Taillard, 1997; Berger & Barkaoui, 2004; Rochat & Taillard, 1995) and central memory (Bouthillier, Crainic, & Kropf, 2005; Crainic et al., 2006a; Crainic et al., 1996, 1997; Jin, Crainic, & Løkketangen, 2014) strategies; (4) how the exchanged information is used globally (if it is used at all), and how each process uses the received information. ICS generalizes the adaptive/central-memory class of cooperative strategies (thereafter called central memory).We now define the fundamental concepts and general framework of the proposed ICS methodology. The instantiation of this framework to particular applications is illustrated in Section 4.1.ICS combines the ideas of opportunistic decomposition and cooperative search. The decomposition mechanism (Section 3.1) yields simpler but meaningful problem settings, in the sense that efficient algorithms, called hereafter solvers, can be “easily” obtained for these partial problems either by opportunistically using existing high-performing methods or by developing new ones. The cooperative-search framework addressing the complete formulation (Section 3.2) brings together the resulting partial problems and their associated solvers (Section 3.3), and the integration mechanisms reconstructing complete solutions (Section 3.4). The central-memory and search-guidance mechanisms are described in Section 3.5.We aim for a decomposition mechanism that takes advantage of and preserves the structure of the problem at hand. We therefore propose a structural problem decomposition along sets of decisions variables.Letx∈Xbe the set of decision variables of the problem at hand, and let δ be a set of indexes identifying a particular subset of x. The decision-set attribute decomposition identifies Δ sets of decision variables and defines a partial-problem formulationΠδ(xδ˜)for each decision set xδ, δ = 1,…,Δ, by fixing the corresponding variables to suitably selected valuesxδ˜(and adjusting constraints, if needed). The setsδ1,…,δΔare not required to induce a partition of the feasible domain. In mathematical-programming terms, the decision-set decomposition may be viewed as a multiple simultaneous restriction (Geoffrion, 1970), where the fixed variables are part of the solution to the restricted formulation. Notice that the proposed decomposition method does not discard variables and, thus, any solution to any partial problem constructed according to this definition may be considered for the complete formulation.The selection of the decision-sets is specific to each application case, decision variables being clustered to yield known or identifiable optimization problem settings. Two examples to illustrate the application of the decision-set attribute decomposition. First, defining the Δ sets of decision variables according to the spatio-temporal characteristics of the problem elements, e.g., node coordinates in a space-time network representation, yields the well-known data-decomposition procedure (e.g., Taillard, 1993, for VRP). Second, fixing the customer-to-depot assignments in the MDPVRP illustration of Section 4.1 yields a periodic VRP, while fixing the patterns for all customers yields a multi-depot VRP.ICS implements the decision-set attribute decomposition described above and takes the form of a self-adaptive cooperative meta-heuristic concurrently evolving and combining several populations, one corresponding to complete solutions to the initial problem, each one of the others addressing specific dimensions of the problem resulting from the decomposition. ICS integrates a purposeful-evolution mechanism geared to produce high-quality complete solutions.Fig. 1illustrates the structure and components of ICS, which are detailed in the following sub-sections. The decision-set decomposition of the original problem yields a number of partial problems. Each partial problem is addressed by a specific Partial Solver Group (PSG), which encompasses one or several solution methods. Two PSGs are illustrated in Fig. 1 schematically showing the respective partial solver sets, the central memories and their content, and the local search coordinators (the LSC hexagonal boxes).Concurrently with PSG activities, integrators select partial solutions from PSGs (represented by full arrows in the figure), combine them to create complete ones and sent them (full arrow) to the Complete Solver Group (CSG). (All solutions are “complete” in ICS; we use the terms “partial” and “complete” only to indicate the solver group of origin.)The Complete Solver Group may include solvers to enhance the complete solutions generated by the integrators, but its main task is to manage the pool of complete solutions and the context information received from the PSGs and to extract out of these the information required by the purposeful guidance of the partial and global searches performed by the Global Search Coordinator (GSC). Dashed-line arrows represent the exchange of information supporting the cooperation.As already mentioned, ICS generalizes the central-memory cooperative search methodology (and includes data parallelism as a special case). ICS tackles the problem in hand through the combined work of several different solvers, which have each been assigned a particular role and which indirectly and asynchronously interact through a two-layer central-memory and guidance mechanism. The cooperation is built on these indirect exchanges through collections of elite solutions, communications being triggered either by the internal logic of each solver deciding when to send its updated information (e.g., new best solution) to the central memory or to request new solutions from it, or by a local or global search coordinator reacting to changes in the status of the memories and the search trajectory. Solvers thus never interact directly, which has been shown to induce very good performance in terms of solution quality, speed, and robustness in its “classical” central-memory applications (see the literature review of the previous section).Cooperation is facilitated by the choice of a unique solution representation for all solvers and solver groups obtained by fixing rather than eliminating variables when defining partial problems, facilitates communications, information extraction and knowledge creation from exchanged solutions, as well as the development of generic solvers. We now examine each component in more details.The number of Partial Solver Groups equals that of the partial problems obtained through the decision-set decomposition. Each PSG is thus dedicated to a specific partial problem and focuses on a particular subset of the original decision variables, the values of the other ones being fixed, directly or indirectly, through communications with the Global Search Coordinator. A PSGiis composed of a set of Partial SolversSi,a central memory, and a Local Search Coordinator (LSC).Partial Solvers may be any exact or heuristic solution method, but need to address efficiently the corresponding partial problem. They are thus application specific. ICS does not impose any limit on the number of solvers within a PSG, but the usual concerns related to an efficient implementation of parallel methods (e.g., computer architecture, communication protocol, programming language, etc.) also apply in this context.Communications and exchanges among solvers within a PSG are performed through the central-memory mechanism, made up of the population of elite solutionsPigenerated by the solvers, and the application-specific context information, under the supervision of the LSC. The solutions of the central memory may have different fixed-variables values. Communications are generally initiated by a solver desiring to deposit or requesting solutions and context information.Guidance instructions are issued by the local or global search coordinators. The LSC functionality may include monitoring the performance of the Partial Solvers and acting when this performance becomes unsatisfactory (e.g., a given Partial Solver did not send any solution for a given time or all its latest contributions to the central memory are weak compared to the current best solution). The LSC could then, for example, force a Partial Solver to restart from a suitable solution in memory (e.g., changing the population of a genetic algorithm), modify the search parameters, or even change the solution method.Similar behavior is also triggered by messages from the Global Search Coordinator (GSC). We discuss in more depth the role of the GSC later in this section, but want to emphasize that a thorough exploration of the solution space of the original problem generally requires the modification of the focus of particular Partial Solver Groups. The modification generally proceeds through changes to thexδ˜values defining the search space of givenΠδ(xδ˜)PSGs, but may also involve the definition of the Δ decomposition set. This modification is communicated to the corresponding LSC that, in turn, instructs Partial Solvers and adjusts (initialize or modify) parameter values.Integrators play an essential role in the ICS methodology. While Partial Solvers address a single aspect of the original problem, with a number of attributes fixed, Integrators build complete solutions by mixing partial solutions with promising features from these various populations. Integrators select solutions in the populations of one or more PSGs, combine them to yield complete solutions, and transmit some or all of these new solutions to the Complete Solver Group.Integration aims for solution quality, the transmission of critical features extracted from the partial solutions, and computational efficiency. Based on the largely acknowledged idea that population diversity contributes to the success of population-based meta-heuristics (e.g., Vidal et al., 2012), integration also aims to generate good but diverse solutions and, thus, increase the diversity of the population of complete solutions. Finally, integration should support the global computational efficiency of the method, by feeding new solutions to the CSG at a sustained pace to avoid unnecessary waiting and idling of the corresponding processes. This can be achieved by including several Integrators in an ICS implementation, as illustrated in Section 4.1.The simplest and most general Integrator consists in selecting partial solutions to pass directly to the Complete Solver Group. It thus provides the means to efficiently add to the population of complete solutions individuals of high quality with respect to solution value or the inclusion of decision combinations frequently encountered in high-quality solutions. The latter characteristic is meaningful in terms of population diversity and the global guidance of the search (Section 3.5). Moreover, the speed of execution implies an almost continuous flow of new solutions toward the CSG, which makes such an integrator a recommended feature of an ICS implementation.More advanced methods combine partial solutions. Population-based methods, genetic algorithms (e.g., Vidal et al., 2012, used in the illustrative application of Section 4.1) and path relinking (e.g., Vahed, Crainic, Gendreau, & Rei, 2013), in particular, have proved their flexibility and stability in combining solution characteristics to yield high-quality solutions. A different methodological approach to heuristic solution integration was recently introduced by Hachemi, Crainic, Lahrichi, Rei, and Vidal (2014). The authors start with a set of solutions, each characterized by a vector identifying the critical variables, i.e., those variables whose values in the respective solution represent desired attributes and propose a number of optimization problems to generate new solutions preserving critical variables. The models differ in the type of input they expect (critical variable-vectors that are disjoint or not) and the requirement to include all or part of the critical variables in their output. We use two of these integrators in the illustrative application of Section 4.1.Integration, except for the simplest one described above, is application specific and so is the number of integrators to include in an ICS implementation. Given the objectives stated above, we suggest at least two: one transferring good partial solutions to the CSG and a second combining partial solutions into complete ones. This number could be slightly increased when several high-quality integrators, and the associated computing resources, are available. We have thus included four integrators on three processors in the application of Section 4.1.The Complete Solver Group (CSG) component of ICS is organized similarly to the PSGs (the complete-solver set is optional, however) and plays an important double role. First, it receives complete solutions from integrators and, when solvers are included, it enhances them thus creating new ones. It is from the complete solution set P that the final solution to the initial problem is extracted once the stopping conditions are verified. We call Complete Solver Coordinator (CSC) the part of the CSG performing these tasks.Second, the CSG includes the guidance mechanism composed of the Global Search Coordinator and the corresponding complete context information. The latter includes various measures characterizing complete solutions in P: the cost or fitness-type of value reflecting multiple solution characteristics, membership to a specific class of solutions (e.g., high, medium, poor quality) information on the solver or integrator that yielded it, etc. It may also include an image of the global search through statistical information (memories) on the evolution of solutions in the complete and partial populations, the contribution of solutions and their components (e.g., routes or arcs in VRP) to the evolution of the search, the relative performances of PSGs and Integrators, etc. Finally, the complete context information contains the complete or partial solutions, and associated measures, generated by the GSC and sent to PSGs and Integrators as part of the guidance process.The Global Search Coordinator fulfills monitoring and guidance tasks. Monitoring is performed by following the evolution of the PSGs (through the information they transmit or by checking the evolution of their central memories—see Section 3.3) and that of the complete context information (built based on this information). Monitoring provides the means to detect undesired situations, e.g., loss of diversity in the partial or complete populations, stagnation in improving the quality of the current best solution, awareness that some zones of the solution space—defined by particular values for particular decision sets—have been scarcely explored, if at all, and that the search should be diversified in that direction, and so on.Thresholds on such global performance measures trigger guidance operations, the GSC performs by sending “instructions” to Partial Solvers and Integrators. The particular type of guidance is application specific, but instructions may modify the valuesxδ˜of the fixed attributes for a specific Partial Solver to orient the search toward a different area, change the attribute subset under investigation (i.e., change the decomposition of the decision-set attributes), or modify/replace the solution method in a Partial Solver or Integrator. The last two types of instructions significantly modify the structure of the global search and should therefore be used rather infrequently to respond to a significant issue in the performance of the method, e.g., a solver is constantly under-performing compared to the others.The first type of instructions, on the contrary, makes up the core guidance mechanism of the method and is implemented in the application discussed in Section 4.1. Such instructions must reflect the particular structure of the problem and solver at hand and it is therefore application specific. In general, they take the form of a particular solution or solution set being sent to re-initialize a given partial solution set (re-initialization may be complete or partial, retaining in the latter case a few very good and diverse solutions) and thus re-start the search of the respective PSG. Additional context information (e.g., the promising arc patterns of Bouthillier et al., 2005) may complete the guiding instructions, to further inflect the search trajectory toward regions that appear promising from the point of view of the global search.The general ICS framework we introduced can be applied to any multi-attribute combinatorial problem class for which a decision set decomposition may be defined. The next section illustrates the application of the ICS methodology to such a problem class, which is then used to analyze the behavior and performance of the proposed method.

@&#CONCLUSIONS@&#
We introduced the Integrative Cooperative Search framework to efficiently address the challenges of rich, multi-attribute combinatorial optimization problems.ICS decomposes such complex problems along decision-set attributes and musters, within a multi-thread cooperative search framework, the combined capabilities of a number of independent exact or meta-heuristic solution methods. A number of these methods work on sub-problems defined by suitably selected subsets of decision-set attributes of the problem, while others combine the resulting partial solutions into complete ones and, eventually, improve them. These methods cooperate through an adaptive search-guidance mechanism, using the central-memory cooperative search paradigm.We illustrated the interest of the Integrative Cooperative Search methodology through an application to the multi-depot, periodic vehicle routing problem, for which ICS enhances the results of the current state-of-the-art methods.To apply ICS to other combinatorial optimization problems, it is sufficient to identify decision-set attributes yielding suitable partial problems. Thus, for example, the recently proposed Unified Hybrid Genetic Search methodology (Vidal, Crainic, Gendreau, & Prins, 2014) offers the means to rapidly devise high-performing meta-heuristics for a wide gamut of vehicle routing problem settings. Similarly, multi-attribute design problems may be addressed through ICS integrating efficient tabu search and path relinking meta-heuristics (Crainic et al., 2006a). This emphasizes the generality and broad applicability of the proposed ICS methodology.