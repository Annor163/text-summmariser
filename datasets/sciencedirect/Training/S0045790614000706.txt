@&#MAIN-TITLE@&#
Cloud model-based method for range-constrained thresholding

@&#HIGHLIGHTS@&#
A cloud model-based framework for range-constrained thresholding with uncertainty.Improving four traditional methods under the new framework.Representing the image using cloud model.Implementing image transformation to focus on mid-region of the image.Cloud model-based framework is efficient and effective.

@&#KEYPHRASES@&#


@&#ABSTRACT@&#
Thresholding is a popular image segmentation method that converts a grayscale image into a binary image. In this paper, we propose a cloud model-based framework for range-constrained thresholding with uncertainty, and improve four traditional methods. The method involves four major steps, including representing the image using cloud model, estimating the automatic threshold for gray level ranges of object and background, implementing image transformation to focus on mid-region of the image, and determining the binary threshold within the constrained gray level range. Cloud model can effectively represent various visual properties of the image, such as intensity-based class uncertainty, intra-class homogeneity, and between-class contrast. The approach is validated both quantitatively and qualitatively. Compared with the traditional state-of-art algorithms on a variety of synthetic and real images, with or without noisy, as well as laser cladding images, the experimental results suggest that the presented method is efficient and effective.

@&#INTRODUCTION@&#
Thresholding is one of the simplest and most important methods for image segmentation, and has served a variety of applications, such as object recognition, image analysis and scene interpretation [1,2]. From a grayscale image, thresholding can be used to create a binary image, corresponding to the background and objects respectively. Over the years, a lot of image thresholding approaches have been proposed, and a number of performance evaluation metrics have been developed. Comprehensive overviews and comparative studies of image thresholding can be found in the literature [3], in which the Otsu method [4], the Kittler method [5] and the Kapur method [6] have been taken as the state-of-art algorithms, and misclassification error (ME) [7] is as the traditional evaluation metric.The Otsu method [4] assumes that the image to be segmented contains two classes of pixels or bi-modal histogram (objects and background), then calculates the optimum threshold separating those classes so that their combined spread (intra-class variance) is minimized and the between-class variance is maximized. The Kittler method [5] views the histogram as an estimate of the probability density function of a Gaussian mixture population, that is, the pixels in the object and the background come from a normal distribution and the normal distributions may have different means as well as variances. Then the optimum threshold is selected so that the relative entropy-based mismatch between Gaussian mixture model and image histogram is minimized. Recently, Xue presented two median-based extensions on the conditions of skew or heavy-tailed class-conditional distributions [8], and then theoretically analyzed the close relationship between the Otsu method and the Kittler method, and stated that the Otsu method can be viewed as a special case of the Kittler method, in which equal sizes and equal variances are further assumed for the two classes [9]. The Kapur method [6] divides the histogram of the image into two probability distributions, one representing the objects and the other representing the background. Then the optimum threshold is selected so that the sum of the entropies of these probability distributions is maximized. In general, these three methods are widely used in many applications. Regarded as the historic standard, they are highly cited by scientific publications, and also typically compared by other new methods [10,11]. Furthermore, the Otsu method is implemented as the default approach to image thresholding in MATLAB, which is widely used in academic and research institutions as well as industrial enterprises, and the Kittler method is ranked as the best by a comprehensive survey [3].Nonetheless, each method has its own advantages, disadvantages and applied situations. These four methods are based on histogram analysis, and depend too heavily on the precise histogram of the given image, but not consider the uncertainty contained in the histogram, and neglect properties of human visual perception. In fact, uncertainty is an inherent part of image thresholding in real world applications [11,12], and the automatic selection of optimum threshold with uncertainty is still a challenge. Therefore, we should further extend and discuss the traditional image thresholding approaches from the developmental point of view. We believe that, cloud model can handle such uncertainty in a better way, since it provides us with more design degrees of freedom, at least the second order uncertainty.In recent years, range-constrained image thresholding has received some attentions. Hu et al. [13] first confined the intensity frequency range of the object in the histogram, and presented a supervised thresholding approach which only analyzes the histogram of a region of interest, where the proportion of the background varies in a range estimated through supervision. Based on the range-constrained approach, Hu et al. [14] produced the transition region with the help of supervision and calculating the threshold from the transition region, and then Li et al. [15] improved this transition region-based method by unsupervised estimation for gray level ranges of object and background. The key issue in the range-constrained methods lies in image transformation, and the image is divided into three portions via the upper and lower bounds for background and object. Li et al. [16] introduced image transformation [15] as a preprocessing step into local entropy-based transition region extraction and proposed a modified thresholding approach. These range-constrained methods have been proved to be useful in some cases. However, all of them have not considered the uncertainty contained in the histogram, and not completely investigated the effect of image transformation. For example, the Li method [15,16] determined the gray level ranges of object and background byTuandTl, which are related with the mean and the standard deviation of the image, and a parameterβautomatically selected by statistical iterations according to the standard deviations of its three portions. Standard deviation is a common statistical measure reflecting degree of deviations between mean and individuals. That is to say, the Li method confined the intensity frequency range by intra-class similarities of the background and foreground, which considers only the intra-class homogeneity [17], but not the histogram contrast or the between-class contrast [10], much less class uncertainty [12].In this context, we propose a cloud model-based framework for range-constrained thresholding with uncertainty, and improve four traditional methods under the new framework. In this paper, our first major contribution is a cloud model-based framework for image thresholding. Our intentions are two-folds: (1) using cloud model to provide a thresholding framework that can handle the uncertainties in a more robust way, and (2) providing an unsupervised approach (parameter-free) under the framework to study accounting for various visual properties of the image, such as intensity-based class uncertainty, intra-class homogeneity, and between-class contrast, which are reflected by the numerical characters of cloud model. Cloud model is a cognitive model between a qualitative concept and its quantitative instantiations [18,19], and has been used in image thresholding with uncertainty [20,21]. The cloud model-based thresholding consists of four steps, including representing the image using cloud model, estimating the automatic threshold for gray level ranges of object and background, implementing image transformation to focus on mid-region of the image, and determining the binary threshold within the constrained gray level range. Under the framework, the performance of image transformation is compared with Li’s method [15,16] in the first group experiment.As the second major contribution, we improve four traditional image thresholding approaches under the cloud model-based range-constrained framework, and the selected approaches are based on grayscale-level threshold optimization using histogram statistics, not pixel-level or others, including the Otsu method, the Kittler method, the Kapur method and the median-based extension for the Otsu method (hereafter referred to as the Xue method). The improved methods process the transformed images by applying the criteria of conventional approaches and search the optimal threshold in a more efficient and effective grayscale range. We have done quantitative and qualitative validation of the proposed approach against several images, with or without noise, as well as laser cladding images. Comparison has been made with respect to the Otsu method [4], the Kittler method [5], the Kapur method [6], and the Xue method [8]. The results demonstrate that our approach is efficient and effective. Theoretically, the efficiency comes from the reducing of the grayscale range for the optimizing search, and the effectiveness roots in the strong relevance between the optimal threshold and the grayscale range, inspired by human vision.The rest of the paper is organized as following: Section 2 provides an introductory explanation of cloud model, and universal principles of human visual perception. Then, Section 3 proposes a cloud model-based framework for threshold selection, and formulates four range-constrained thresholding methods. Section 4 shows the experimental results and discussion. Finally, the conclusion is drawn in Section 5.Cloud model, proposed by Li et al. [19,18], is the innovation and development of membership function in fuzzy theory, and uses probability and mathematical statistics to analyze the uncertainty [18]. In theory, there are several forms of cloud model, successfully used in various application [19,18,22,20,21]. However, the normal cloud model is commonly used in practice, and its theoretical foundation is the universality of normal distribution and bell membership function [19].Let U be a universe set described by precise numbers, and C be a qualitative concept related to U. Given a numberx∈U, which randomly realizes the conceptC,xsatisfiesx∼N(Ex,En′2), whereEn′∼N(En,He2), and the certainty degree of x on C is as below:(1)μ(x)=exp(-(x-Ex)22En′2)then the distribution of x on U is defined as a normal cloud, and x is as a cloud drop.The overall property of a conceptC(Ex,En,He)can be represented by three numerical characters of normal cloud model, expected value Ex, entropy En and hyper-entropy He. Ex is the mathematical expectation of the cloud drop distributed in universal set. En is the uncertainty measurement of the qualitative concept, and it is determined by both randomness and fuzziness of the concept. He is the uncertain measurement of entropy, which is determined by randomness and fuzziness of entropy En[19]. It is worth noting that hyper-entropy He of a cloud model is a deviation measure from a normal distribution, hence, the distribution of cloud drops can be regarded as a generalized normal distribution.The kernel of normal cloud model is the transform between qualitative concept and quantitative data, and it is realized by normal cloud generators. On one hand, forward normal cloud generator is the mapping from qualitative concept to quantitative values, and it produces the cloud drops to describe a concept when three numerical characters and the number of cloud drops are input. On the other hand, backward normal cloud generator provides the transformation from quantitative numerical values to quality concept, and a normal cloud model with three numerical characters is defined by computing mean, absolute central moment with the first order, and variance of sample data. Essentially, the normal cloud generators are two algorithms based on probability measure space [19], these processes are uncertain, and cannot be expressed by a precise function.In the normal cloud model, each cloud drop contributes the concept differently. The Gaussian function satisfies three sigma rule, and as a consequence, normal cloud model has3Enrule. The majority of cloud drops lie within the interval[Ex-3En,Ex+3En], and specifically, cloud drops within the interval[Ex-0.67En,Ex+0.67En], called the backbone elements, only account for 22.33% of the universe set, but contribute 50% of the cloud model. Then, cloud drops within the interval[Ex-En,Ex+En]make up 33.33% of the universe, and contribute 68.26% of the cloud. Similarly, other cases can be also calculated. More information about normal cloud model can be obtained from Ref. [19].In this paper, we confine ourselves to the two-class problem of separating objects (foreground) from background. Without losing generality, we assume that the backgroundCbappears darker than the objectCo. Letf:x→{0,1,…,L-1}be a grayscale image with L levels, andf(x)denotes the intensity value of the pixel x. There are several universal principles in human vision, and the following points, reported by the literature [10–12,17], have been considered while designing the proposed algorithm:(1)Generalized normality of histogram [17]: The histograms of images usually have high intensity values for pixels near a certain value (mostly the mean), or the corresponding images have more structures at intensity values near the mean than that farther from mean. A rough estimate of such a histogram is a Gaussian distribution. We believe that most of the histograms do not satisfy a normal distribution strictly, but they may obey a generalized normality. This characteristic suggests cloud model with a weaker constraint condition compared to the normal distribution is more appropriate.Sensibility of human eye [17]: Human eye is more sensitive to features presenting at the mid-range intensities than both the extreme pixel intensity values. This characteristic means that it should be useful to concentrate about the middle region.Between-class uncertainty [11,12]: Object boundaries in any acquired images exhibit uncertainty because of the blurring or the ubiquitous partial effect introduced by imaging devices. Then, there should have a high value of class uncertainty in the vicinity of the boundaries. This characteristic reveals that it is very difficult to remove ambiguities without any prior knowledge or uncertainty processing.Intra-class homogeneity [10,12]: The intra-class homogeneity uses the within-class variance to measure the intensity homogeneity within the object and background, and it is a popular criteria for thresholding. But it might be questioned when the sizes of two classes are sharply different and one of the class distributions is complex. That is to say that the intra-class homogeneity has serious weakness in some cases, some other criteria should be taken into account.Between-class contrast [10]: Between-class contrast is a key factor of histogram-based thresholding, and it can be set as the mean difference between the object and background. In other words, Between-class contrast captures the intensity difference between the object and background. This characteristic should be combined with intra-class homogeneity in order to overcome the limitation of the latter.Firstly, the cloud model-based thresholding algorithm describes the image using cloud model. Given an image, the corresponding cloud model can be obtained by backward normal cloud generator when inputting the intensity values, andCf(Exf,Enf,Hef)are as its numerical characters.Fig. 1gives an example. The original image, named block, is shown as in Fig. 1(a), and its ground-truth image in Fig. 1(c). Backward normal cloud generator produces the cloud modelCf(53.1,66.9,15.94). In order to verify the validity of cloud model, we input these three numerical charactersEx=53.1,En=66.9,He=15.94, and then generate a series of cloud drops with certainty degree. Fig. 1(b) demonstrates the joint distribution of cloud drops and its certainty degree. In the uncertainty way, cloud model has depicted the gray level distribution of the block image, and it is an approximate normal distribution (or a generalized normal distribution as above) rather than a normal distribution.As shown in Fig. 1(b), the actual universe of grayscale value is[0,255](bordered with a blue rectangle), whereas there are many cloud drops outside this interval. The reason is that the background of this image mainly consists of darker pixels (grayscale near 0), and then the gravity of grayscale values lies closer to 0, which can be found from its histogram (see Fig. 1(d)). In fact, this does not affect, but benefit, the performance of the successive operations. According to the3Enrule of normal cloud model, the backbone elements are almost within[8.277,97.923]and contribute 50% to the image. In other words, the pixels within[0,8]or[98,255]can be removed from consideration and directly simplified as background or object respectively. The details will be further analyzed with Fig. 2(a). Therefore, the above expression has already simplified the original image to some extent, and it should be helpful for image thresholding. Thus, cloud model for an image considers the generalized normality of histogram, as well as the sensibility of human eye.The above analysis shows that, although the distribution of cloud drops, compared with a normal distribution, may be comparatively more complicated, cloud model is still more applicable to represent the intensity values of images, and may be more coincident with the objective world, as well as human vision.Secondly, the cloud model-based thresholding algorithm estimates the threshold for gray level ranges of object and background, i.e., the upper bound of the backgroundLland the lower bound of the objectLr, and certainlyLl⩽Lr. According to the contribution ratio of each cloud drop, the two thresholds can be easily fixed. SupposedLl=Exf-0.67EnfandLr=Exf+0.67Enf, the pixels would be divided into three classes, the low grayscale regionRlthat certainly belongs to the background, the high grayscale regionRrthat certainly belongs to the object, and the middle grayscale regionRmthat likely belongs to either the background or the object. The mathematical expressions are as follows:(2)Rl={x|f(x)<Ll};Rr={x|f(x)>Lr};Rm={x|Ll⩽f(x)⩽Lr}.In these three regions, the between-class uncertainty mainly exists in the middle grayscale regionRm, called as transition region. Based on the above analysis, the regions are shown in Fig. 2(a), whereRl,RrandRmare respectively colored with the green, the blue and the red.As can be seen from Fig. 2(a), most of the pixels are colored correctly and the related partition is approximately accord with the image. Thus, most of the object pixels are classed into the high grayscale regionRr, and most of the background pixels are allocated to the low grayscale regionRl. However, a lot of pixels that can be easier to determine are unadvisedly misclassified into the transition regionRm, since the gray level range for transition region is too broad. Although the rough process may not cause the wrong segmented result, it will drastically increase the difficulty of the next steps and then significantly reduce the performance of the range-constrained approach. Hence, it is still necessary to study how to select the appropriate thresholds more effectively.The remainder of this subsection, we analyze the characteristic of cloud model and present a novel method on automatic threshold for gray level range. LetLl=Exf-κEnfandLr=Exf+κEnf, three regionsRl,RrandRmare determined, then, the respective cloud model for each region are generated by backward normal cloud generator, and finally a criterionJ(κ)related with these cloud models is minimized to obtain the optimalκ. The following algorithm describes the detail about the selection of automatic threshold.Algorithm 1Automatic threshold for gray level range.Input: the original imagef(x)and its cloud modelCf(Exf,Enf,Hef).Output: the upper bound of the backgroundLland the lower bound of the objectLr.Initialization:κ=0,κm=0andκt=+∞;Whileκ≤0.67Obtaining three regions from the original imagef(x)and then generating the corresponding cloud modelsCl(Exl,Enl,Hel),Cr(Exr,Enr,Her)andCm(Exm,Enm,Hem);Calculating the criterionJ(κ)according to Eq. (3);IfJ(κ)is less thanκtUpdate:κm=κandκt=J(κ);End Ifκ=κ+0.01;End WhileReturn:Ll=Exf-κmEnfandLr=Exf+κmEnfIn the Algorithm 1, the criterionJ(κ)is defined as following,(3)J(κ)=expEnl-Enm3Enl+3Enm·expEnm-Enr3Enm+3Enr+exp-EnmHem.The criterionJ(κ)combines three properties of the image, including between-class uncertainty, intra-class homogeneity and between-class contrast. The details are:(1)Entropy En of the cloud model represents the uncertainty measurement of a qualitative concept, and it reflects the dispersing extent of the cloud drops and the range of the universe accepted by the concept. Therefore,3Enl,3Enr,3Enmare the uncertainty measurement of three regions. The values of3Enl,3Enr,3Enmbecome smaller, when the degrees of the corresponding region homogeneity gain higher. And in another way, the smaller3Enl,3Enr,3Enmtend to imply the higher homogeneity. Furthermore,3Enl+3Enmand3Enr+3Enmindicate the intra-class homogeneity of the possible object and background.The intensity contrast by [10] is not an explicit factor inJ(κ), but it is still well considered.Enl-Enmrepresents the degree of difference between intra-class similarities of the low grayscale and transition region, whileEnm-Enrdepicts the degree of difference between intra-class similarities of the transition and high grayscale region.Enl-EnmandEnm-Enrjointly control the intensity contrast of the image.With smaller magnitude ofHem/Enm, the grayscale distribution of pixels in transition region is closer to a normal distribution. In this case, the degree of uncertainty in transition region, or as between the object and background, is least. And extremely, whenHe=0, the distribution of cloud drops is degenerated into a normal distribution. As the measure of between-class uncertainty,exp(-Enm/Hem)is introduced into the criterion as a penalty term.Consequently, the criterionJ(κ)of Eq. (3) actually tries to keep the balance of between-class uncertainty, intra-class homogeneity and between-class contrast simultaneously. To search the optimal threshold for the constrained grayscale range, the criterionJ(κ)makes the best use of the properties of the image, and it should be benefit to the subsequent process of image transformation and thresholding. For the block image in Fig. 1(a), theJ(κ)evolution curve with variedκis shown in Fig. 2(c). As labeled in Fig. 2(c),J(κ)obtains the optimal valueJ=0.6591withκ=0.27, where theJ(κ)criterion achieves a relative balance of influences on between-class uncertainty, intra-class homogeneity and between-class contrast. Under this condition, three regionsRl,Rm,Rrare also demonstrated in Fig. 2(b), where the color scheme is the same as Fig. 2(a). Moreover, the cloud models for these three regions are illustrated as Fig. 2(d). It is evident that the regions bordered by two ellipses exist uncertainty, that is, it is uncertain whether or not the pixels owned these grayscale values belong toRl,Rm,Rr.Thirdly, the cloud model-based thresholding algorithm implements image transformation to confine the image into a narrower grayscale range. Once the bounds for the background and object are obtained, the remaining problem is to determine at which region the image pixels are, that is,Rl,RrorRm. The traditional method yields the partition result by compared the grayscale value of each pixel with the boundsLl,Lr. In the paper, we take three regionsRl,Rr,Rmas cloud concepts, and introduces the maximum determination based on the cloud model.The improved method for image transformation considers the membership degrees of each pixel to three cloud concepts in the set, and selects the concept corresponding to the maximum value. For this purpose, an additional step is added into Algorithm 1 to save three cloud models corresponding to the optimalκ, denoted asCl(Exl,Enl,Hel),Cr(Exr,Enr,Her)andCm(Exm,Enm,Hem). For the pixel x in a given image, the certainty degrees of x to each cloud models can be calculated by substituting the grayscalef(x)into Eq. (1), denoted asμl(x),μr(x),μm(x). The pixel x is divided intoRl, the only way is that its certainty degreeμl(x)is the maximum, and so on. Supposed the transformed imagefRC:x→{Ll,…,Lr}, the process of image transformation is as follows:(4)fRC(x)=Llifμl(x)=max{μl(x),μm(x),μr(x)};Lrifμr(x)=max{μl(x),μm(x),μr(x)};f(x)otherwise.For the block image, the transformed result is shown in Fig. 3(a). As shown in Fig. 3(c), the intensity coverage of the histogram is changed from[0,L-1]to[Ll,Lr]. Compared with the original image in Fig. 2(a), the transformed image is easier to segment because of the range-constrained grayscale. We should note that, in the range-constrained thresholding, image transformation substantially is a rough segmentation, and its result is the only source for the later operation. The transformed image becomes much simpler than the original one, but enough details for final thresholding is well preserved.For a comparison, we also implement image transformation by the Li method [15,16] and list the transformed result in Fig. 3(b). It is very difficult to completely distinguish the image in Fig. 3(b) by the human eyes, although this transformed result does not directly determine the performance of thresholding the block image. The image transformation has critical efforts on the successive operations, and it is the most important step in the range-constrained thresholding. The Li method for image transformation confines the grayscale range too strictly. And for most of images, this process should lead to the difficulties in the following thresholding. Li’s statistical criterionσSpartially and simply considers the intra-class similarities of the background and foreground, and tends to obtain the smaller intensity variance for each region.More specifically, the weight of standard deviation of the transitional class accounts for at least 60% inσSaccording to the section on parameter selection in [15]. Then, minimizing the criterionσSmeans that the transitional class should be more similar. While the criterionσSmust be the only reason for two disadvantages: on one hand, the grayscale range of the transition region is too narrow, and then the transformed result cannot keep enough details on the original image, which is crucial to image thresholding. As can be seen from Fig. 3(d)the range is almost inseparable from the human visual, even so the Li method is based on human visual perception. On the other hand, the grayscale range of the object and background is too wide, and the transformed result will lost abundant of useful details, then misclassify part of pixels during image transformation. However, we believe that Li’s criterion is radically changed from the original intention on range-constrained thresholding. As shown in Fig. 3, it is clearly demonstrated the superiority of our method. And we will further analyze the transformation process in Section 4.1.Finally, the cloud model-based thresholding algorithm determines the binary threshold within the constrained gray level range. In the process, the range-constrained scheme focuses on mid-region of the image, and applies to the transformed image using criteria of conventional approaches. Based on traditional methods [4–6,8], we propose four range-constrained thresholding methods.Based on cloud model, we present a range-constrained Otsu method, denoted as CloudOtsu. Given a thresholdt∈(Ll,Lr), the transformed imagefRCwould be divided into two classesCb,Co, whereCb={x|Ll⩽fRC(x)⩽t}consists of pixels with gray levels[Ll,t], andCo={x|t<fRC(x)⩽Lr}with gray levels in(t,Lr].Supposed the between-class varianceσ2(t)B=ω0ω1(μ0-μ1)2, CloudOtsu obtains the optimal threshold T by maximizing the between-class variance,(5)T=argmaxt∈(Ll,Lr){σ2(t)B}whereω0=∑i∈[Ll,t]pi,ω1=∑i∈(t,Lr]piare the cumulative probability of two classesCb,Co,pirepresents the frequency of gray level i infRC, andμ0=∑i∈[Ll,t]ipi/ω0,μ1=∑i∈(t,Lr]ipi/ω1are the means of these classes.We believe that any posteriori criterions may remain some uncertainties in practice, when the corresponding assumptions are apparently violated. For example, Otsu’s maximization of the between-class variance tends to divide an image into object and background of similar sizes [10]. In other words, for two Gaussian classes with equal variances but distinct sizes or with equal sizes but distinct variances, the Otsu method would perform not as perfectly as for two classes with more equal sizes and more equal variances. One can find that the block image is just so from its histogram.The segmented results are listed in Fig. 4. The evolution curves of relationship between the values of the Otsu criterion and the threshold t are shown in Fig. 4(a). The search space of the optimal threshold is fixed in[0,L-1]by the traditional Otsu method (see the red line in Fig. 4(a)), while that of the CloudOtsu method is confined within[Ll,Lr]because of the rang-constrained approach, instead of the whole grayscale range (see the blue line in Fig. 4(a)). The CloudOtsu method determines the optimal threshold with more special purpose, and it is more accord with human vision. So naturally, the CloudOtsu method improves the search performance and provides the facility for image thresholding. As shown in Fig. 4(b) and (c), the thresholding performance has some essential improvement.Based on cloud model, we present a range-constrained Kittler method, denoted as CloudMET. Given a thresholdt∈(Ll,Lr), the transformed imagefRCis also divided into two classesCb,Co. Supposed the minimum errorK(t)=1+2(ω0lnσ0+ω1lnσ1)-2(ω0lnω0+ω1lnω1), CloudMET obtains the optimal threshold T by minimizing the minimum error,(6)T=argmint∈(Ll,Lr){K(t)}whereσ02=∑i∈[Ll,t](i-μ0)piandσ12=∑i∈(t,Lr](i-μ1)pidenote the class variance, and other parameters are the same as Eq. (6).The segmented results are listed in Fig. 5, the evolution curves of relationship between the values of the Kittler criterion and the threshold t reflect the same trend, and there has no substantial change between the Kittler and CloudMET method. Nonetheless, the outlier or the irregularities outside the grayscale range are moved by the CloudMET method. Compared Fig. 5(b) with Fig. 5(c), the thresholding performance is still improved by the CloudMET method, which appropriately specifies the bounds of the object and background and takes the uncertainty into account using cloud model. More details are quantitatively analyzed with some evaluation metrics.Based on cloud model, we present a range-constrained Kapur method, denoted as CloudKapur. With a thresholdt∈(Ll,Lr), the transformed imagefRCis labeled as the classes of object and backgroundCo,Cb. Let the entropy of object and background pixels be defined as follow,(7)H0(t)=-∑i∈[Ll,t]piω0lnpiω0,H1(t)=-∑i∈[t+1,Lr]piω1lnpiω1then CloudMET obtains the optimal threshold T by maximizing entropy of object and background pixels,(8)T=argmint∈(Ll,Lr){H0(t)+H1(t)}whereσ02=∑i∈[Ll,t](i-μ0)piandσ12=∑i∈(t,Lr](i-μ1)pidenote the class variance, and other parameters are the same as Eq. (8). wherepi,ω0,ω1are defined as Eq. (5).The segmented results are listed in Fig. 6. The CloudKapur method not only reduces the search space of the optimal threshold, but also dramatically enhances the search performance, as shown in Fig. 6(a). And then, such improvement of the CloudKapur method also benefits the final thresholding, which can be seen by comparing the results in Fig. 6(b) and (c).In this subsection, we present a range-constrained Xue method, denoted as CloudXue. Given a thresholdt∈(Ll,Lr), the transformed imagefRCis also divided into two classesCb,Co. Supposed the median-based ruleM(t)=w0MAD0(t)+w1MAD1(t), CloudXue obtains the optimal threshold T by minimizing the rule,(9)T=argmint∈(Ll,Lr){M(t)}whereMAD0(t)=∑i∈(Ll,t]pi|i-m0(t)|/ω0,MAD1(t)=∑i∈[t+1,Lr)pi|i-m1(t)|/ω1denote the mean absolute deviations from the median for the classesCb,Co, andm0(t),m1(t)are the sample medians.Although Xue’s extension for the Otsu method was aimed to improve the robustness to the presence of skew or heavy-tailed class-conditional distributions, it would severely degrade the performance of the Otsu method without the presence. The block image reveals the different performance under this condition before and after the improvement.The segmented results are listed in Fig. 7. Xue’s method is specifically provided for the presence of skew or heavy-tailed distributions, and its resulting image is completely dark because of unsuitable conditions, as shown in Fig. 7(b). Fig. 7(a) demonstrates the optimization process of minimization Xue’s criterion. Through comparison, Xue’s method cannot find the best solution distracted by the outlier or the irregularity outside the grayscale range, while the CloudXue method keeps the possible threshold within the range limit, and then are more likely to obtain a perfect result. The binary image in Fig. 7(c) appears to confirm this.To sum up, the proposed framework for image thresholding is as following:Algorithm 2The cloud model-based framework for range-constrained image thresholding.Input: the original imagef(x).Output: the optimal threshold T and the segmented resultfr(x).Step 1: Given an original imagef(x), calculate the corresponding cloud modelCf(Exf;Enf;Hef)by backward normal cloud generator;Step 2: Using Algorithm 1, obtain the automatic thresholdκmfor gray level range, and the upper bound of the backgroundLland the lower bound of the objectLr.Step 3: According to Eq. (2), transform the image fromf(x)tofRC(x)by confining the image into a more narrow grayscale range[Ll,Lr].Step 4: For the transformed imagefRC(x), search the optimal thresholdT∈(Ll,Lr)by applying the criteria of conventional approaches, Eqs. 5,6,8, and 9, respectively.Step 5: Segment the image with the above threshold T and output the resultfr(x).

@&#CONCLUSIONS@&#
