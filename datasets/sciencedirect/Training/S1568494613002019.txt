@&#MAIN-TITLE@&#
A self-evolving functional-linked wavelet neural network for control applications

@&#HIGHLIGHTS@&#
The proposed self-evolving functional-linked wavelet neural network (SFWNN) can vary its structure dynamically to keep the prescribed approximation accuracy with a simple computation.This paper presents an adaptive self-evolving functional-linked wavelet neural control (ASFWNC) for a class of uncertain nonlinear systems.The proposed ASFWNC system is applied to a chaotic dynamic and a DC motor.Simulation and experimental results verify that the proposed ASFWNC system can achieve high-precision tracking performance.

@&#KEYPHRASES@&#
Adaptive control,Neural control,Functional-linked neural network,Wavelet neural network, Dynamical structure,

@&#ABSTRACT@&#
The structure of a neural network is determined by time-consuming trial-and-error tuning procedure in advance for the reason that it is difficult to consider the balance between the neuron number and the desired performance. To attack this problem, a self-evolving functional-linked wavelet neural network (SFWNN) is proposed. Without the need for preliminary knowledge, a self-evolving approach demonstrates that the properties of generating and pruning the hidden neurons automatically. Then, an adaptive self-evolving functional-linked wavelet neural control (ASFWNC) system which is composed of a neural controller and a supervisory compensator is proposed. The neural controller uses a SFWNN to online estimate an ideal controller and the supervisory compensator is designed to eliminate the effect of the approximation error introduced by the neural controller upon the system stability in the Lyapunov sense. To investigate the capabilities of the proposed ASFWNC approach, it is applied to a chaotic system and a DC motor. The simulation and experimental results show that favorable control performance can be achieved by the proposed ASFWNC scheme.

@&#INTRODUCTION@&#
Since the modeling inaccuracy may have strong adverse effects, the implicit drawback of a model-based control scheme is inevitable when system uncertainties are presented in the associated mathematical models. To attack this problem, a nonlinear controller is becoming an important tool to achieve favorable control performance and robust fault-tolerant behavior. Among the different nonlinear control approaches, there have been considerable interests in exploring the applications of neural network to deal with the uncertain nonlinear systems after sufficient learning [1–4]. However, the most important problem in the neural-network-based nonlinear control systems is the determination of the number of hidden neurons that should be used in the modeling of the unknown system dynamics or the ideal controller. They do not avoid using large number of hidden neurons, but the computation loading is heavy. To solve this problem, several self-evolving schemes for dynamically setting the structure of the neural network have been developed [5–9].Leung and Tsoi [5] combined training and pruning for the construction of a recurrent radial basis function network based on recursive least square learning. An error covariance matrix was used to remove some unimportant radial basis function nodes; however, it required a heavy computation loading. In Ref. [6], a degree measure method was used to find the proper wavelet bases and to minimize the number of wavelet bases generated from input space. The proposed structuring learning can create wavelet bases online; unfortunately, it can not avoid the structure of neural network growing unboundedly. Bortman and Aladjem [7] proposed a recent growing and pruning algorithm for training radial basis function networks; however, the structure would grow large as the input space has variations. Lu et al. [8] proposed a structuring learning to determine if the hidden neurons are generated/eliminated or not according to the Mahalanobis distance. However, the number of fuzzy rules maybe unstable as the input space has large variations. In Ref. [9], a reinforcement evolutionary learning algorithm, which consists of structure learning and parameter learning, was proposed for the self-evolving neural fuzzy inference networks. However, the design procedure was overly complex and it lacked the real-time adaptation ability.To achieve better learning performance of neural networks, some researchers have developed the structure of neural network based on the wavelet functions to construct a wavelet neural network (WNN) which absorbs the advantages of wavelet decompositions and neural learning [10–12]. It has been argued that for a given quality of approximation, fewer nodes may be required for WNNs, when compared to neural networks using sigmoidal functions [10]. In addition, a functional-linked neural network (FLNN) which the functional-link generates a non-linear transformation of the input space before it is fed to the network is proposed [13–15]. The FLNN can capture non-linear input-output relationship by the adequate set of polynomial inputs since the high-order effects are incorporated into the input variables to increase the dimension of input space [13].Recently, there has been considerable interest in exploring the applications of WNN and FLNN to deal with nonlinearity and uncertainties of real-time control system [16–24]. To ensure the system stability, a compensator should be designed to eliminate the effect of the approximation error introduced by neural networks. A switching compensator which requires the bound of the approximation error was proposed in [25]; however, it will result in substantial chattering in the control effort. To remove the undesirable control chattering, a smooth compensator is proposed to guarantee system stable in [26]. The tracking error can exponentially converge to a small neighborhood of the trajectory command. In [27,28], a H∞ tracking control theory was used to attenuate the effects of approximation error. A better control performance can be achieved as a specified attenuation level is chosen smaller. But, it may lead to a large control signal.This paper proposes a self-evolving functional-linked wavelet neural network (SFWNN) which can vary its structure dynamically to keep the prescribed approximation accuracy with a simple computation. It starts with a small number of hidden neurons and adds new hidden neurons if there is no existing hidden neuron can efficiently represent the input space and some of existing hidden neurons can be removed if the removing condition is satisfied. Many neural networks with the learning of the network parameter were done by using backpropagation learning algorithm, but it is based on gradient descents that are easily trapped at local minima. In the last few years, the evolution algorithms have been successfully applied to solve many optimization problems in diverse areas [29,30]. However, it always leads to heavy computational costs and the convergence speed maybe slow. In this approach, an adaptive self-evolving functional-linked wavelet neural control (ASFWNC) system which is composed of a neural controller and a supervisory compensator is proposed. The neural controller uses a SFWNN to online approximate an ideal controller using backpropagation learning algorithm. To overcome the affect of the local minima problem introduced by SFWNN, the supervisory compensator is designed to eliminate the approximation error between the neural controller and ideal controller in the sense of Lyapunov function. Finally, the proposed ASFWNC system is applied to a chaotic system and a DC motor. The simulation and experimental results have been conducted to illustrate the performance and applicability of the proposed ASFWNC system with structure and parameter learning schemes.The network structure of a SFWNN can be considered as a multi-layer feedforward neural network. As shown in Fig. 1, it is comprised of the input layer, the wavelet layer, the functional layer and the output layer. The operation functions of the nodes in each layer are introduced in the following.Layer 1 (Input layer): No function is performed in this layer. Each node in this layer only transmits input variable s to the next layer directly.Layer 2 (Wavelet layer): In this layer, each wavelet function can be represented by [22](1)Θi=hiexp−(s−ci)2σi2fori=1,2,…,mwhere σiand ciare the dilation and translation parameters, respectively, and m is the number of the hidden neurons. The “Mexican hat” mother wavelet function is defined as hi=1−ϖ2(s−ci)2 to construct the wavelet base functions, where ϖ is a position constant designed by the designer.Layer 3 (Functional Layer): The input to a node in Layer 3 is the output from Layer 2 and a FLNN. In this paper, a FLNN considers trigonometric-type functional expansions. The functional expansion of FLNN acts on each input variable by generating a set of linearly independent functions, and then evaluating these functions with the variables as the arguments. In this study, a trigonometric function is adopted as the functional expansions. Consider n orthogonal basis functions as ξ=[ϕ1, ϕ2, …, ϕn]T, the k-output of FLNN can perform the mapping according to(2)μk=∑j=1nwjkϕj=wkTξk=1,2,…,mwherewk=[w1k,w2k,...,wnk]Tis the parameter vectors specified by designers. Each node in this layer can be represented by(3)uk=μkΘk=wkTξΘkfork=1,2,...,mLayer 4 (Output Layer): The output node together with links connected it act. The single node computes the overall output as the summation of all incoming signals. The output of the proposed SFWNN can be represented as(4)unc=∑k=1muk=∑k=1mwkTξΘkIf Θkis used as a nonlinear transformation of hidden nodes andwkTξdenotes the connection weights, it implies that there is a SFWNN can uniformly approximate any nonlinear function [31].Determining an appropriate number of hidden neurons is an important issue because of the trade off between a computation loading and a learning performance. In general, a higher number of hidden neurons results in a smaller approximation error. To attack the problem of structure determination, this paper proposes an online network self-evolving scheme using a Mahalanobis distance (M-distance). The M-distance between the input variable and the existing hidden neurons is defined as(5)di=(s−ci)2σi2fori=1,2,…,mIf a new input variable falls within the existing hidden neurons, it implies that one of the M-distance should be small. Thus, SFWNN will not generate a new hidden neuron but update parameters of the existing hidden neurons. For the traditional self-constructing approaches, a new hidden neuron is generated when a new input variable is too far away from the current clusters. However, the clustering method often suffers from heavy computation loading. According to the M-distance, the criterion of generating a new hidden neuron for new incoming data is described as follow. Find a minimum distance which is defined as(6)dmin=min1≤i≤mdiIf dmin>dgis satisfied, where dgis a pre-given positive constant, the existing hidden neurons are not sufficient to perform a conversion from a crisp point into the existing hidden neurons such that a new hidden neuron should be generated. A too small value of dggenerates more hidden neurons to be easily generated. On the contrary, a too large value of dgmakes a hidden neuron difficultly to grow. The parameters of the new hidden neuron are selected as following(7)cnew=s(8)σnew=σ¯(9)wnew=0whereσ¯is a pre-specified constant. At the sampling period N, the new hidden neuron is adopted and the total number of the hidden neurons is increased as(10)m(N+1)=m(N)+1To avoid the structure of SFWNN growing unboundedly, a pruning algorithm based on the density is introduced to prune the inappropriate hidden neurons in this approach. The density based on M-distance is studied, where each hidden neuron has its own density in each time iterations. The density of the i-th existing hidden neuron is defined as(11)Di(N+1)=Di(N),ifdi>dpDi(N)+1,ifdi≤dpwhere the initial value of density is 0 in each time iterations and dpis a designed constant. If the input variable falls within the existing hidden neurons (di≤dp), the density of the i-th hidden neuron adds one. This operation will prevent the existing hidden neurons, which may be less used but still significant, from being deleted in the training process. It shows that the least-important hidden neuron is the one that has the smallest density. If Di≤Dthin an interaction are satisfied, where Dthis a pre-given positive constant, then the i-th existing hidden neuron is deleted. At the sampling period N, the total number of the hidden neurons is become as(12)m(N+1)=m(N)−1For real-time implementation, if the computation loading is the important issue, a large Dthshould be chosen, so that more hidden neurons can be pruned. The computation loading would be reduced. Then, the number of the hidden neurons would be large enough to achieve favorable control performance and faster parameter convergent speed. In summary, the flowchart of the structure learning algorithm is shown in Fig. 2.Consider a class of nonlinear dynamic system expressed in the following form(13)x˙1=x2x˙2=f(x,t)+g(x,t)u+d(t)where x=[x1, x2]Tis the state vector of the system which is assumed to be available, f(x, t) and g(x, t) are continuous nonlinear system dynamics, u is the control input, and d(t) is the external disturbance. For (13) to be controllable, it is required that g(x, t)≠0 for all x. The control objective is to find a control law so that the system state x can track the state command xcclosely. To design the control law, define a tracking error as(14)e=xc−x1If the system dynamics and external disturbance are known, there exists an ideal controller [32](15)u*=1g(x,t)[−f(x,t)+x¨c+k1e˙+k2e−d(t)]where k1 and k2 are nonzero positive constants. Applying (15) into (13) yields(16)e¨+k1e˙+k2e=0If k1 and k2 are chosen to correspond to the coefficients of a Hurwitz polynomial, it implies thatlimt→∞e=0[32]. Since the terms f(x, t), g(x, t) and d(t) may be unknown or perturbed, the ideal controller cannot be precisely obtained.In Fig. 3, the proposed ASFWNC system is composed of a neural controller and a supervisory compensator, i.e.(17)uaswc=unc+uscwhere a sliding surface is defined as(18)s=e˙+k1e+k2∫0tedτ.The neural controller uncuses a SFWNN to approximate an ideal controller and the supervisory compensator uscis designed to eliminate the approximation error between the neural controller and ideal controller. Substituting (17) into (13) and using (15), the error dynamic equation can be obtained as(19)e¨+k1e˙+k2e=g(x,t)(u*−unc−usc)=s˙Multiplying both sides of (19) by s gives(20)ss˙=sg(x,t)(u*−unc−usc)The parameter learning algorithm of the neural controller is derived based on a gradient descent algorithm and aims to minimizess˙for achieving fast convergence of s. According to the gradient descent method, the correction Δwkapplied to the weight wkis given by [33,34]Δwk(N)=−ηα∂ss˙∂wk=−ηα∂ss˙∂unc∂unc∂wk(21)=ηαsg(x,t)Θkξwhere ηαis a positive learning rate. The weight wkis updated according to the following equation(22)wk(N+1)=wk(N)+Δwk(N)Moreover, the corrections Δciand Δσiapplied to the center and width, respectively, for the i-th hidden neuron can be obtained as [33,34](23)Δci(N)=−ηc∂ss˙∂ci=−ηc∂ss˙∂unc∂unc∂Θi∂Θi∂ci=2ηcsg(x,t)wiξ(s−ci)σi2Θi(24)Δσi(N)=−ησ∂ss˙∂σi=−ησ∂ss˙∂unc∂unc∂Θi∂Θi∂σi=2ησsg(x,t)wiξ(s−ci)2σi3Θiwhere ηcand ησare positive learning rates. The center and width are updated as following(25)ci(N+1)=ci(N)+Δci(N)(26)σi(N+1)=σi(N)+Δσi(N)In some cases, if the system dynamic g(x, t) is unknown, g(x, t) in the learning algorithms can be reorganized asg(x,t)sgn(g(x,t)). Therefore, the learning algorithms shown in (21), (23) and (24) can be reconstructed as(27)Δwk(N)=βαsΘkξsgn(g(x,t))=βαsΘkξ(28)Δci(N)=2βcswiξ(s−ci)σi2Θisgn(g(x,t))=2βcswiξ(s−ci)σi2Θi(29)Δσi(N)=2βσswiξ(s−ci)2σi3Θisgn(g(x,t))=2βσswiξ(s−ci)2σi3Θiin whichβα=ηαg(x,t),βc=ηcg(x,t)andβσ=ησg(x,t); they are taken as new learning rates. Consequently, only the sign of g(x, t) is required in the design procedure and it can be easily obtained from the physical characteristic of the controlled plants. Here, we have sgn(g(x, t))=1.The main property of neural network regarding feedback control purpose is the universal function approximation property. Since the number of hidden neurons is finite for real-time practical applications, there exists an approximation error between the ideal controller and the neural controller, i.e. [31](30)u*−unc=εwhere ɛ denotes the approximation error. Substituting (30) into (19) yields(31)s˙=g(x,t)(ε−usc)The approximation error cannot be easily measured in practical applications. In this paper, the supervisory compensator is designed as(32)usc=εˆ+kswhereεˆdenotes the estimated value of approximation error and k is a small positive constant. Substituting (32) into (31) yields(33)s˙=g(x,t)(ε−εˆ−ks)=g(x,t)(ε˜−ks)whereε˜=ε−εˆ. To guarantee the stability of the ASFWNC system, a Lyapunov function candidate is defined as(34)V(s,ε˜,t)=12s2+12ηεε˜2where ηɛis a positive learning rate. Differentiating (34) with respect to time and using (33) obtainV˙(s,ε˜,t)=ss˙+1ηεε˜ε˜˙=sg(x,t)(ε˜−ks)+1ηεε˜ε˜˙(35)=ε˜[sg(x,t)+1ηεε˜˙]−kg(x,t)s2For achievingV˙(s,ε˜,t)≤0, the error estimation law is designed as(36)εˆ˙=−ε˜˙=ηεsg(x,t)then (35) can be rewritten as(37)V˙(s,ε˜,t)=−kg(x,t)s2≤0Similar to the adaptive laws of neural controller, if g(x,t) is unknown, the adaptive law (36) can be reconstructed as(38)εˆ˙=βεssgn(g(x,t))=βεsin whichβε=ηεg(x,t)is taken as a new learning rate. From (37), it can be know thatV˙(s,ε˜,t)is negative semidefinite andV(s,ε˜,t)≤V(s,ε˜,0). It implies that s andε˜are bounded. Define a functionΩ(τ)≡kg(x,t)s2≤−V˙(s,ε˜,t), and integrate Ω(t) with respect to time, then it is obtained that(39)∫0tΩ(τ)dτ≤V(s,ε˜,0)−V(s,ε˜,t)As a result ofV(s,ε˜,0)is bounded andlimt→∞∫0tΩ(τ)dτ<∞can be concluded by Barbalat's Lemma [32]. Therefore, the stability of the proposed ASFWNC system can be guaranteed.In this section, the proposed ASFWNC system is applied to a chaotic system and a DC motor to verify its effectiveness. It should be emphasized that the development of the ASFWNC system does not need to know the mathematical models of control plants. For practical implementation, the controller parameters and network structure can be online tuned by the proposed algorithm.Chaotic phenomena have been observed in numerous fields of science such as physics, chemistry, biology and ecology [35–37]. It can be observed in many nonlinear circuits and mechanical systems. Consider a Duffing's chaotic system, the system dynamics is described as [35](40)x˙1=x2x˙2=−px2−p1x1−p2x13+qcos(ωt)+u=f(x,t)where t is the time variable, x=[x1, x2]Tis the state vector, ω is the frequency,f(x,t)=−px˙−p1x−p2x3+qcos(ωt)is the system dynamic, u is the control input and p, p1, p2 and q are real constants. Depending on the choices of these constants, the solutions of system (40) may display complex phenomena, including various periodic orbits behaviors and some chaotic behaviors. To observe these complex phenomena, the open-loop system behavior with u=0 was simulated with p=0.4, p1=−1.1, p2=1.0 and ω=1.8. The phase plane plots with an initial condition (0, 0) are shown in Fig. 4(a) and (b)sss for q=2.1 (chaotic) and q=7.0 (period 1), respectively. It is shown that the uncontrolled chaotic system has different chaotic trajectories for different values of q.To illustrate the effectiveness of the proposed SFWNN, a comparison between a WNN and a SFWNN is made. The simulation results of the ASFWNC system which uses a WNN with only parameter learning phase are shown in Figs. 5 and 6for q=2.1 and q=7.0, respectively. The tracking responses of state x are shown in Figs. 5(a) and 6(a), the tracking responses of statex˙are shown in Figs. 5(b) and 6(b), and the control inputs are shown in Figs. 5(c) and 6(c). The simulation results show that the ASFWNC system using a WNN can achieve favorable control performance but the network structure of the used WNN should be determined by some trial-and-error.Then, the ASFWNC system which uses a SFWNN with parameter and structuring learning phases is applied to control the chaotic system again. To show the effectiveness of the proposed self-evolving scheme, an existing structuring learning for dynamically setting the structure of SFWNN in [8] is applied to compare with the proposed self-evolving scheme. The simulation results of the ASFWNC system with existing structuring learning are shown in Figs. 7 and 8for q=2.1 and q=7.0, respectively. The tracking responses of state x are shown in Fig. 7(a) and 8(a), the tracking responses of statex˙are shown in Fig. 7(b) and 8(b), the control inputs are shown in Fig. 7(c) and 8(c), and the numbers of hidden neurons are shown in Fig. 7(d) and 8(d). The simulation results show that perfect tracking responses can be achieved after the learning of controller parameters and network structure. However, the appropriate hidden neurons but may be less used are eliminated as shown in Fig. 8(d). Thus, the convergence speed of the structuring learning phase is slow for controlling an unstable system.Finally, the proposed self-evolving scheme of SFWNN is applied to control the chaotic system again. A density mecha nism is introduced to avoid pruning the appropriate hidden neurons. The parameters of the ASFWNC system are selected as k1=2, k2=1, βα=0.2, βc=βσ=0.001, ηɛ=0.1, k=1,σ¯=0.8, dg=1.2, dp=1.5, and Dth=300. The simulation results of the ASFWNC system with a SFWNN are shown in Figs. 9 and 10for q=2.1 and q=7.0, respectively. The tracking responses of state x are shown in Fig. 9(a) and 10(a), the tracking responses of statex˙are shown in Fig. 9(b) and 10(b), the control inputs are shown in Fig. 9(c) and 10(c), and the numbers of hidden neurons are shown in Fig. 9(d) and 10(d). The simulation results show that perfect tracking responses can be achieved after the learning of controller parameters and network structure.The motion equation of a DC motor can be simplified as [38,39](41)Jθ¨+Bθ˙=Tewhere J is the moment of inertia, B is the damping coefficient, θ is the rotor position and Teis the electric torque. The electric torque Teis defined as(42)Te=Ktiawhere Ktis the torque constant and iais the torque current. The electric equation of a DC motor can be simplified as(43)va=Raia+Kbθ˙+Ladiadtwhere Rais the armature resistance, Kbis the back electromotive force coefficient, Lais the armature inductance andvais the applied voltage. Since the armature inductance can be negligible, the dynamics of the DC motor can be represented in the following form(44)θ˙=ωω˙=f(x,t)+guwhere x=[θ, ω]Tis the system state vector,f(x,t)=−(BJ+KtKbJRa)ωis the system dynamic,g=KtJRa>0is the constant control gain, andu=vais the control input. In this paper, an FPGA-based experimental environment is setup as shown in Fig. 11. The FPGA chip incorporates the architecture of gate arrays and the programmability of a programmable logic device [40]. The circuits and algorithms can be developed by the very high speed integrated circuit hardware description language. To illustrate the effectiveness of the proposed design method, a comparison among the supervisory fuzzy neural network control [25], the adaptive fuzzy PI control [38] and the proposed ASFWNC system is made. The interrupt interval for the interrupt service routine with a 1msec sampling rate is set.First, the supervisory fuzzy neural network control [25] is applied to control a DC motor. The experimental result of the supervisory fuzzy neural network control is shown in Fig. 12. The tracking response is shown in Fig. 12(a) and the control input is shown in Fig. 12(b). Although the tracking performance can be achieved after control parameter learning, there exists the undesirable control chattering in Fig. 12(b). Then, the adaptive fuzzy PI control [38] is applied to control a DC motor again. The experimental result of the adaptive fuzzy PI control is shown in Fig. 13. The tracking response is shown in Fig. 13(a) and the control input is shown in Fig. 13(b). The experimental results show that the undesirable control chattering has not been found but the number of fuzzy rules should be determined through some trial-and-errors. Finally, the proposed ASFWNC system is applied to control a DC motor again. The parameters of the ASFWNC system are selected as k1=k2=4, βα=0.1, βc=βσ=0.001, ηɛ=0.1, k=1,σ¯=1.0, dg=1.2, dp=1.5, and Dth=300. The experimental result of the ASFWNC system is shown in Fig. 14. The tracking response is shown in Fig. 14(a), the control input is shown in Fig. 14(b), and the number of hidden neurons is shown in Fig. 14(c). The experimental results show that the favorable tracking performance can be achieved without the chattering phenomena also the hidden neurons have been automatically constructed. The proposed pruning algorithm based on the density, where the density is the number of times each rule is used, is studied. It required no heavy computation loading, so the proposed structure learning algorithm is suitable for real-time applications.

@&#CONCLUSIONS@&#
In this paper, a self-evolving functional-linked wavelet neural network (SFWNN) is studied. Using the Mahalanobis distance, a new hidden neuron will be generated if the input variable belongs to the existing hidden neurons and existing hidden neurons will be pruned if its used density is smaller than a pre-specified density threshold. Thus, an adaptive self-evolving functional-linked wavelet neural control (ASFWNC) system has been successfully developed. The proposed ASFWNC system is composed of a neural controller and a supervisory compensator. The SFWNN is used as the main controller to approximate the ideal controller in the neural controller, and the supervisory compensator is incorporated with the SFWNN for achieving robust performance that against to the approximation error in the Lyapunov sense. Since all the controller parameters are online tuned based on the gradient descent method and Lyapunov stability function, the proposed ASFWNC system can guarantee system stable even under it is applied to control an unstable nonlinear system. Finally, the proposed ASFWNC system is applied to control a chaotic system and a DC motor. The simulation and experimental results verify that favorable control performance can be achieved by the proposed ASFWNC scheme after the learning of controller parameters and SFWNN network structure.