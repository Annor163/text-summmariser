@&#MAIN-TITLE@&#
Automatic snore sound extraction from sleep sound recordings via auditory image modeling

@&#HIGHLIGHTS@&#
We proposed a novel approach to automatically classify snore and non-snore in the sleep sound recordings.The auditory image model was employed to extract the sound features.The simulation results demonstrate that the proposed method provided high classification accuracy.

@&#KEYPHRASES@&#
Auditory image model,Snore sound,Classification,

@&#ABSTRACT@&#
One of humans’ auditory abilities is differentiation between sounds with slightly different frequencies. Recently, the auditory image model (AIM) was developed to numerically explain this auditory phenomenon. Acoustic analyses of snore sounds have been performed recently by using non-contact microphones. Snore/non-snore classification techniques have been required at the front-end of snore analyses. The performances of sound classification methods can be evaluated based on human hearing, which is considered to be the gold standard. In this paper, we propose a novel method of automatically extracting snore sounds from sleep sounds by using an AIM-based snore/non-snore classification system. We report that the proposed automatic classification method could achieve a sensitivity of 97.2% and specificity of 96.3% when analyzing snore and non-snore sounds from 40 subjects. It is anticipated that our findings will contribute to the development of an automated snore analysis system to be used in sleep studies.

@&#INTRODUCTION@&#
Humans are considered to be able to distinguish between sounds with frequencies separated by only 0.2% [1]. Hearing models have been developed in the past to attempt to numerically explain this auditory phenomenon by using physiological and anatomical data. Helmholtz proposed his pitch perception theory in 1877, which involved considering the ear as a frequency analyzer [2]. Since then, researchers have performed experiments using animals and have developed mathematical models to explain this frequency analysis phenomenon based on basilar membrane vibrations. An auditory filter expressing the frequency analysis made possible by the basilar membrane motion, which was based on psychophysical experiments conducted by Fletcher [3], was proposed in 1974 [4]. Currently, auditory filters are used to determine auditory model inputs [5–7].A number of groups have recently developed computational models to describe the auditory perception process [5–7]. Langner and Meddis et al. proposed models and simulations of periodicity detection by the human auditory system, which were based on physiological data [5,6]. Patterson's group proposed a functional model and simulation method to capture information about the tone of a sound, as well as about its periodicity. This model is referred to as the auditory image model (AIM) [8]. Patterson et al. also simulated the tonal perception process [9,10] for animal noises and musical instrument sounds, as well as the functions of the auditory canal [7,8], and demonstrated that their model could accurately describe phenomena such as the perception of tones that are mutually phase-inverted [11], the missing fundamental effect [12], and the cocktail party effect [13,14], which cannot be explained using conventional auditory models.Acoustic analyses of snore sounds have been performed recently by using non-contact microphones [15–17]. These studies required snore extraction from the sleep sounds that were recorded while the test subjects were asleep. Several automatic snore-extraction methods have been proposed, such as techniques using (i) a network combining mel-frequency cepstral coefficients and the hidden Markov model [18]; (ii) the sub-band energy spectrum, robust linear regression, and principal-component analysis (PCA) [19]; (iii) the sub-band energy distribution, PCA, and unsupervised learning fuzzy c-means clustering [20]; and (iv) a combination of 34 features, multiple acoustic analysis methods, and Ada Boost [21].The studies of these methods indicated that snore and non-snore sounds could be categorized automatically with a high degree of accuracy, but signal processing methods were required to extract the desired features. Since the performances of sound classification methods are generally evaluated based on manual classification, which is considered to be the gold standard [18,21], a high-performance sound classifier could be configured by imitating the human auditory system. Therefore, in the present study, we aimed to develop a method to automatically extract snores from sleep sounds by using an AIM-based snore/non-snore classification system. This paper describes the configuration of the proposed system. The effectiveness of this system was verified by analyzing a sleep sound database comprised of data for 40 test subjects.

@&#CONCLUSIONS@&#
