@&#MAIN-TITLE@&#
Statistical inference for population quantiles and variance in judgment post-stratified samples

@&#HIGHLIGHTS@&#
A quantile inference is developed based on a judgment post-stratified (JPS) sample.A variance estimator is constructed for population variance based on a JPS sample.The procedures have higher efficiencies than the ones in a simple random sample.The procedures have slightly lower efficiencies than the ones in a ranked-set sample.Inference in a JPS sample is asymptotically equal to the one in a ranked-set sample.

@&#KEYPHRASES@&#
Stochastic order,Ranked set sampling,Sign test,Calibration,Imperfect ranking,Median,

@&#ABSTRACT@&#
A judgment post-stratified (JPS) sample is used in order to develop statistical inference for population quantiles and variance. For thepth order of the population quantile, a test is constructed, an estimator is developed, and a distribution-free confidence interval is provided. An unbiased estimator for the population variance is also derived. For finite sample sizes, it is shown that the proposed inferential procedures for quantiles are more efficient than corresponding simple random sampling (SRS) procedures, but less efficient than corresponding ranked set sampling (RSS) procedures. The variance estimator is less efficient, as efficient as, or more efficient than a simple random sample variance estimator for small, moderately small, and large sample sizes, respectively. Furthermore, it is shown that JPS sample quantile estimators and tests are asymptotically equivalent to RSS estimators and tests in their efficiency comparison.

@&#INTRODUCTION@&#
Main motivation behind judgment post-stratification (JPS) and ranked set sampling (RSS) designs is to use a collection of a few number of experimental units without measurement to create homogeneous groups of measured observations. In a ranked set sample, for each measured observation, researcher selects a set ofHexperimental units at random from a population of interest. These units are assigned ranks 1 throughH. Ranks are assigned without measurement based on either some concomitant variables or subjective opinion of the researcher on the size of the units. Out of theseHunits, only one unit is measured, yielding a single observation,X[ri]i, whereriis the rank of the measured unit. The remainingH−1units in the set provide a context for the measured observation, determining its relative standing in the set through its rank. This process is repeatedntimes to construct a ranked set sample of sizen,X[ri]i,i=1,…,n. The square brackets are used to indicate that ranking of the units in the sets may be in error. If the ranking process is error-free, the square brackets are replaced with the round ones. In this case, judgment ranked order statistics become usual order statistics form a simple random sample of sizeH. The judgment ranks in a ranked set sample act like strata in stratified sampling design by putting similar observations in the same judgment group. Hence, efficiency improvement in an RSS design can be anticipated from the general theory or a stratified sampling design.A JPS sample, proposed by MacEachern et al. (2004), starts with a simple random sample and uses additional experimental units to create post-strata among already measured observations. The construction of a JPS sample requires selecting a sample sizenand set sizeH. One then selects a simple random sample,Xi;i=1,…,n, of sizenand measures all of them. For theith measured unit, a JPS sample needsH−1additional units to form a set of sizeH. The units in this set are ranked from smallest to largest without a measurement, and the rank of the measured unit, on whichXiis already measured, is recorded. The full JPS data then consist ofnmeasured values andnranks associated with these measured values,(Xi,Ri),i=1,…,n, whereRiis the rank ofXi. Note that the capital letterRiis used to denote that the ranks in a JPS sample are random variables.It is clear from the description of RSS and JPS samples, there are two major differences between these two designs. The first difference is in the way that the ranking process is applied to the units in each set. In an RSS design, ranking is performed prior to measurement of a unit in a set. On the other hand, ranking is performed after measurement in a JPS design. As a result, the assigned ranks in a ranked set sample design become a part of the measured observations. They cannot be separated from the observed values. Hence, an RSS sample must be analyzed with an appropriate statistical procedure developed specifically for an RSS design. In a JPS sample, since the ranks are assigned after the fact that a simple random sample (SRS) has been collected, it can be analyzed as an SRS by ignoring the ranking information.Another significant difference between a JPS and RSS sample is due to distributional properties of the sample size vector of the judgment rank classes. Letnh,h=1,…,H, be the number of measured observations in thehth judgment class in an RSS sample. The sample size vector of judgment classes in an RSS sample,(n1,…,nH), is a deterministic vector and must be determined prior to the construction of the sample while it is a random vector in a JPS sample. Therefore, a JPS sample could be highly unbalanced for small sample sizes and tends to create empty strata. This additional variation in the sample size vector makes a JPS sample less efficient in comparison with an RSS sample. It is then important to investigate the impact of the random sample size vector on a JPS sample.The JPS sampling design has drawn attention in recent literature. Wang et al. (2008) constructed an estimator for the population mean based on stochastic ordering of judgment class distributions. Stokes et al. (2007) and Wang et al. (2006) constructed several estimators for population mean based on a JPS sample that combines ranking information of multiple rankers. Frey and Ozturk (2011) developed an estimator for the population cumulative distribution function (cdf) that uses a weaker ordering constraint than the stochastic ordering constraint of the judgment class distributions. Ozturk (2012) introduced a sampling scheme that incorporates ranking information from multiple sources to improve the JPS sampling design. For small sample sizes, it is highly possible that the JPS sample may contain empty strata. Wang et al. (2012) introduced an estimator for the population cdf that deals with the empty strata in JPS samples. Frey and Feeman (2012) showed that standard JPS estimator of a population mean is inadmissible and constructed an optimal estimator within a class of unbiased estimators. Ozturk (2013a) developed a class of estimators for population moments and median in an infinite population setting. Ozturk (2013b) constructed estimators for the population mean and total in a finite populations setting. Most recently, Dastbaravarde et al. (in press) provided a theoretical framework to show that JPS moment estimators are less efficient than RSS moment estimators for finite sample sizes.The main contribution of this research is to use a JPS sample to draw distribution-free statistical inference for the population quantile of orderpand the population variance. Section  2 introduces a quantile loss function to estimate thepth quantile of a population. The estimating equation of this quantile function is used to develop a two-sided distribution-free test for the population quantile. The test statistic is calibrated to minimize the impact of possible ranking error in the ranking process. Section  3 constructs a distribution-free confidence interval. Section  4 introduces another estimator for the population quantile that minimizes the quantile loss function under the stochastic ordering constraint of the judgment class cumulative distribution functions (cdf). Section  5 introduces an unbiased estimator for the population variance. Section  6 provides empirical results to evaluate the finite sample properties of the estimators, tests and confidence intervals. Finally, Section  7 provides a concluding remark.Let(Xi,Ri);i=1,…,n, be a JPS sample from a distributionFhaving absolutely continues density functionf. Note that in a JPS sample the ranksRi;i=1,…,n, are random variables having discrete uniform distributions on the set of integers{1,…,H}. LetRbe the rank vector in a JPS sample,R⊤=(R1,…,Rn), and letIi,hbe one ifXihas rankh(Ri=h) and zero otherwise. The number of observations having rankhis then denoted byNh=∑i=1nIi,h. The sample size vectorN⊤=(N1,…,NH)has a multinomial distribution with parameters(n,1/H,…,1/H)withn=∑h=1HNh. SinceNis a multinomial random vector, there is a positive probability (depending on the sample sizen) that some of theNhcould be zero. LetIhbe the indicator function for non-empty judgment classes, i.e.Ihis one ifNh>0and zero otherwise. Letdnbe the number of nonzeroNhin a JPS sample, i.e.dn=∑h=1HIh. It is important to recognize thatdnis a random variable.Letηpbe the quantile of orderpof the distributionF,ηp=inf{x:F(x)≥p}andJh={0Nh=01/NhNh>0.One may wish to draw inference forηpbased on a JPS sample. LetQ(a)=p∑h=1HIhJhdn∑j=1nI(Xj>a)(Xj−a)I(Rj=h)+(p−1)∑h=1HIhJhdn∑j=1nI(Xj≤a)(Xj−a)I(Rj=h)be the quantile loss function for a givenp∈(1,0). An estimator forηpcan be constructed by minimizingQ(a)with respect toa. LetS(a)=−ddaQ(a). It is straight forward to show that(1)S(a)=∑h=1HIhJhdn∑j=1n{I(Xj>a)−(1−p)}I(Rj=h).The minimizer ofQ(a)can be obtained from the solution ofS(ηˆp)=0, whereηˆpis the minimizer ofQ(a). Note that a ranking process is called consistent if the same ranking procedure is applied in allnsets.Lemma 1Let(Xi,Ri)be a JPS sample constructed based on a consistent ranking scheme from an absolutely continuous distributionF. Ifηpis the true value of thepth order quantile ofF, for any sample sizen, the expected value and the variance ofS(ηp)are, respectively,E(S(ηp))=0and(2)V(nS(ηp))=σn,ηp2=Bn,HκH2(ηp)+Cn,HδH2(ηp),whereκH2(ηp)=1H{∑k=1H(p−F[k](ηp))2},δH2(ηp)=1H∑k=1H{1−F[k](ηp)}F[k](ηp),Bn,H=nH−1∑j=1H−1(jH)n−1andCn,H=E(HnI12J1dn2)=nHn−1{1n+∑k=2H∑j=1k−1∑t=1n−k−1(−1)j−1k2tH−1k−1k−1j−1nt(k−j)n−t}.The variance of the sign statistic in an SRS sample is equal toV(nSSRS(ηp))=p(1−p), whereSSRS(ηp)=∑i=1nI(Xi>ηp)/n. Table 1presents the values ofp(1−p)andσn,ηp2for the selected values ofp, sample and set sizes. The table indicates that the variance of the sign statistic in a JPS sample is less than or equal to the variance of the sign statistic in an SRS sample with the exception thatn=3,4,5andH=2. In these cases, the variance of a JPS sample sign statistic is slightly higher than the variance of an SRS sample sign statistic. When the sample size (n≥6) is increased the variance of a JPS sample sign statistic is always smaller than the variance of an SRS sample sign statistic.The variance of the sign statistic in a ranked set sample is given by Hettmansperger (1995), Koti and Babu (1996) and Ozturk (1999),V(nSRSS(ηp))=δH2(ηp). It is clear from Eq. (2) that, for a fixed sample sizen, the variance of the sign statistic in a JPS sample is different from the variance of the sign statistic in an RSS sample. Main difference is due to the coefficientsBn,HandCn,H. It is then important to investigate the large sample behavior ofσn,ηp2through these coefficients. Note thatBn,His a positive finite sum for anyn, by taking the limit in each term in this finite sum, it can be shown that the limit ofBn,His zero as the sample sizengets large.A lower bound forCn,Hcan be given byCn,H=E(HnI12J1dn2)=H2E(N1)E(I12J1dn2)≥H2{E(I1dn)}2=1.The last equality follows from Lemma 2 in the Appendix(E(I1/dn)=1/H). In factCn,Hhas a limiting value at 1 as the following computation showslimn→∞Cn,H=limn→∞E{HnI12J1dn2}=E{Hlimn→∞(nJ1)limn→∞(I1dn)2}=H2H2,where interchanging the limit with the expectation is justified since(HnI12J1)/dn2is positive. This computation immediately shows that the variance of the JPS sample sign statistic is greater than equal to the variance of the RSS sample sign statistic for anyn. To see the large sample behavior of the coefficientsBn,HandCn,H, these coefficients are plotted against sample sizes in Fig. 1. From Fig. 1, it is clear thatBn,Hconverges to zero very quickly. Thus the contribution of the first term in Eq. (2) diminishes very rapidly as the sample size gets large. The convergence ofCn,Hto its limit is very slow. Hence, its plot is expressed in logarithmic scale inx-axis. Fig. 1 indicates thatCn,Hachieves its lower bound for large sample sizes. Based on Fig. 1, one may conclude that the variance of the JPS sample sign statistic is always larger than the variance of the RSS sample sign statistic. The sign statistics based on both sampling designs yield the same variance for the large sample sizes, but the required sample size for the equivalence may be very large.Consider testing the null hypothesisH0:ηp=ηp,0against the alternative hypothesisHA:ηp≠ηp,0. SinceS(a)is a non-increasing function ofa, the proposed test rejects the null hypothesis for extreme values ofS(ηp,0). The construction of the critical region or computation of thep-value requires the null distribution ofS(ηp,0). For finite sample sizes, the null distribution of the test statistic depends on the judgment ranking process. For the construction of the null distribution, one can use the asymptotic distribution of the test statistic and show that the asymptotic results also hold for moderately small sample sizes.Theorem 1Let(Xi,Ri)be a JPS sample constructed based on a consistent ranking scheme from a continuous distributionF. As the sample sizenapproaches to infinitynS(ηp,0)converges to a normal distribution with mean zero and varianceσηp,02, whereσηp,02=1H∑k=1HF[k](ηp,0){1−F[k](ηp,0)}.Note that the asymptotic null distribution of the sign statistic of a JPS sample is the same as the asymptotic null distribution of a sign statistic of an RSS sample. On the other hand, for a finite sample size, the variance of a JPS sample sign statistic is larger than the variance of an RSS sample sign statistic.It is also clear that theσηp,02is not distribution free. It depends on the ranking mechanism and the underlying distribution. It is then important to consider an unbiased estimator forδH2(ηp). LetIh∗be an indicator function for the event that thehth judgment class has at least two measured observations, i.e,Ih∗=I(Nh>1). For notational convenience also defineJh∗={0Nh≤11Nh−1Nh>1.An estimator forδH2(ηp)is then constructed byδˆH2(ηp)=∑k=1HIk∗Jk∗dn∗Nk∑i=1n∑j≠inI(Xi≤ηp)I(Xj>ηp)I(Ri=k)I(Rj=k),wheredn∗is the number of judgment classes having at least 2 measured observations. It can be shown that this estimator is unbiased for any sample sizenand any consistent judgment ranking scheme. By using the conditional expectation one can writeE(δˆH2(ηp))=E[∑k=1HIk∗Jk∗dn∗NkE{∑i=1n∑j≠inI(Xi≤ηp)I(Xj>ηp)I(ri=k)I(rj=k)}|R]=∑k=1HE[Ik∗Jk∗Nk(Nk−1)dn∗Nk]F[k](ηp){1−F[k](ηp)}=E(I1∗dn∗)∑k=1HF[k](ηp){1−F[k](ηp)}.Note that passing from the second equation to the third one is justified from the fact thatIh∗/dn∗,h=1,…,H, are identically distributed. Since∑k=1HIk∗/dn∗=1, one may conclude thatE(I1∗/dn∗)=1/H. Hence, this shows thatE(δˆH2(ηp))=δH2(ηp).Note that one can write∑k=1H{p−F[k](ηp)}2=Hp(1−p)−HδH2(ηp).The estimate ofκH2(ηp)can be obtained fromκˆH2(ηp), whereκˆH2(ηp)=p(1−p)−δˆH2(ηp).An unbiased estimator ofV(nS(ηp))follows fromσˆηp,n2=Bn,HκˆH2(ηp)+Cn,HδˆH2(ηp).Unbiased estimator ofδH2(ηp)requires at least two observations from each judgment class group. Hence, the information of judgment class groups having only one measured observation is ignored. This inflates the variance of the estimatorδH2ˆ(ηp). One of the referees suggested using a consistent estimator forkH2(ηp),k̃H2(ηp)=1dn∑k=1HIk{p−Fˆ[k](ηp)}2,whereFˆ[k](ηp)=Jk∑i=1nI(Xi≤ηp)I(Ri=k). A consistent estimate ofδH2(ηp)is then obtained fromδ̃H2(ηp)={δˆH2(ηp)p(1−p)<k̃H2(ηp)p(1−p)−k̃H2(ηp)p(1−p)>k̃H2(ηp).For small sample sizes,δ̃H2(ηp)andk̃H2(ηp)may have a substantial amount of bias. To reduce the amount of bias, a compromised estimator can be constructedδH∗(ηp)=δ̃H2(ηp)+δˆH2(ηp)2k∗H2(ηp)=p(1−p)−δH∗(ηp).Table 2investigates the finite sample properties of the three estimatorsδˆH2(ηp),δ̃H2(ηp), andδ∗H2(ηp)based on a simulation of size 5000. Table 2 shows thatδˆH2(ηp)appears to be unbiased for all sample sizes, but it has elevated MSE values. The other two estimators are biased but the estimatorδ̃H2(ηp)has smaller bias than the estimatorδ∗H2(ηp). Overall, the estimatorδ̃H2(ηp)has smaller MSE then the other two estimators. Efficiency gain is substantial forp≠0.5and smaller sample sizes(n=5,10).For an arbitrary but consistent ranking scheme, the sign statistic can be calibrated to reduce the impact of the ranking error by any one the three estimators developed forδH2(ηp)andkH2(ηp). This paper uses the estimatorsδˆH2(ηp)andkˆH2(ηp). LetTn=nS(ηp,0)σˆηp,0,n2.For large sample sizes,Tnconverges to a standard normal distribution. On the other hand, our simulation study in Section  6 shows that, for moderately small sample sizes, the null distribution ofTncan be approximated fairly well by Student’st-distribution withn−1degrees of freedom.A distribution-free(1−α)100%confidence interval can be constructed by inverting the rejection region of the sign test. The sign test rejects the null hypothesisH0:ηp=ηp,0in favor of the alternative hypothesisHA:ηp≠ηp,0whenPH0(S+(ηp,0)≥c1)=α/2orPH0(S+(ηp,0)≤c2)=α/2for somec1andc2, whereS+(ηp,0)=S(ηp,0)+1−p. The acceptance region of the test is given byPH0(c2<S+(ηp)<c1)=1−α.The critical valuesc1andc2, respectively, can be computed from the asymptotic distribution ofnS(ηp,0)along with the continuity corrections,PH0(S+(ηp,0)≥c1−cor1)=PH0(n{S+(ηp,0)−(1−p)}σˆηp,0,n≥n{c1−cor1−(1−p)}σˆηp,0,n)≈PH0(Tn≥n{c1−cor1−(1−p)}σˆηp,0,n),whereTnis a random variable from Student’st-distribution withn−1degrees of freedom. For moderately largen, the quantityc1is given byc1=tn−1,α/2σˆηp,0,n/n+cor1+(1−p),wheretn−1,ais theath upper percentile of thet-distribution withn−1degrees of freedom. In a similar fashion, the continuity corrected critical valuec2is given byc2=(1−p)−tn−1,α/2σˆηp,0n/n−cor2.In these equations, the continuity correction factorscor1andcor2need to be determined. LetWk=∑i=1kw(i),k=1,…,n,wherew(i)=JhI(Ri=h)/dnis the weight in the estimating equation (1) that corresponds to theith smallest observations(X(i))amongXi,i=1,…,n.The computation of the correction factorcor1needs an integerksuch thatWk−1≤c1∗≤Wk, wherec1∗=(1−p)+tn−1,α/2σˆηp,0,n/n. The correction factor is then computed fromcor1=(Wk−Wk−1)/2. In a similar fashion, The correction factorcor2needs an integerk′such thatWk′−1≤c2∗≤Wk′. The correction factorcor2is computed fromcor2=(Wk′−Wk′−1)/2, wherec2∗=(1−p)−tn−1,α/2σˆηp,0,n/n.A(1−α)100%confidence interval forηpis constructed by finding the acceptance region of the sign testL=inf{z:S+(z)<c1}andU=sup{z:S+(z)>c2}.SinceS+(z)is a non-increasing function ofz,S+(z)<c1if and only if there arem(1≤m≤n)observations that are greater thanzand the sum of their weights (w(i)) are less thanc1. The smallest of thesemobservations gives the lower limit of the(1−α)100%sign confidence interval ofηp. For the upper limitU, one can observe thatS+(z)>c2if and only if there arem′(1≤m′≤n)observations that are greater thanzand, the sum of their weights(w(i))are greater thanc2. The largest observations among the remainingn−m′observations is the upper limit of the confidence interval.The quantile estimatorηˆpis defined implicitly through the solution of the estimating equation (1). In order to investigate the asymptotic behavior of the estimator, the following theorem constructs a linear approximation for the estimating equationS(ηp).Theorem 2Let(Xi,Ri)be a JPS sample constructed based on a consistent ranking scheme from an absolutely continuous distributionF. Asngoes to infinity for anyM>0, the following representation holdssup|a−ηp|≤M/n|nS(ηp+a/n)−nS(ηp)+af(ηp)|=op(1).This uniform convergence result holds in the compact setn|a−ηp|≤M. By using the monotonicity of the estimating equation it can be shown thatn|ηˆp−ηp|is bounded in probability. The readers are referred to Lemma 3 in Ozturk (2013a) for the proof of this result. One can then replaceηp+a/nwithηˆpin Theorem 2 and write0=nS(ηˆp)=nS(ηp)−n(ηˆp−ηp)f(ηp)+op(1).This representation provides an asymptotic expression for thepth quantile estimatorn(ηˆp−ηp)=nS(ηp)/f(ηp)+op(1).Hence, thepth quantile estimator of a population distribution converges to a normal distribution with mean zero an varianceσηp2/f2(ηp). The linear approximation in Theorem 2 also indicates that the asymptotic Pitman efficacy of the sign test of a JPS sample is the same as the asymptotic Pitman efficacy of a sign test of an RSS sample.Ranking process in a JPS sampling design, under fairly general conditions, creates a stochastic ordering among the cdf of the judgment ranking classesF[h],h=1,…,H. LetF={(F[1],…,F[H]):F[1](y)≥⋯≥F[H](y),for allywith at least one strict inequality}be the space of all stochastically ordered judgment class cdfs. The stochastic order constraint can be used to construct a better estimates for thepth quantile of the populationF. The estimating equation (1) does not enforce the stochastic ordering constraint. In order to accommodate the stochastic ordering constraint in the estimation of thepth quantile ofF, the estimating equation can be rewritten as follows(3)SF(a)=∑h=1HIhdn(p−Fˆ[h](a)),Fˆ[h](a)∈F,whereFˆ[h](a)is the estimate of thehth judgment class cdf in spaceF. For a given value ofa, the stochastically constrained estimators of the judgment class cdfs in spaceFcan be obtained by using Pool-Adjacent-Violators Algorithm (PAVA). For this purpose, R-package can be used in http://cran.r-project.org/package=isotone. LetηˆpSbe thepth quantile estimator ofFobtained under the constraint that judgment class cdfs are in spaceF, i.e,SF(ηˆpS)=0. The estimatorsηˆpScan be computed by using a root-finding algorithm such as bisection methods. For example one can use uni-root function in R- package to computeηˆpS.This section considers an unbiased estimator for the population variance based on a JPS sample. Several authors considered the estimation of population variance in an RSS sample. For a balanced ranked set sample, Stokes (1980) usedσ̃2=1cH−1∑j=1c∑h=1H(X[h]j−X̄)2,X̄=1cH∑j=1c∑h=1HX[h]j,wherecis the cycle size andX[h]jis thehth unit in thejth cycle in a ranked set sample. This estimator is asymptotically unbiased, but it has a substantial amount of positive bias for small sample sizes. MacEachern et al. (2002) proposed an unbiased estimator forσ2σˆM2=12H2∑r≠s1nrns∑i=1nr∑j=1ns(X[r]i−X[s]j)2+12H2∑r=11nr(nr−1)∑i=1nr∑j=1nr(X[r]i−X[r]j)2.This estimator requires at least two observations from each judgment class group. Perron and Sinha (2004) introduced a larger class of estimators that containsσˆM2as a special case. In fact they showed thatσˆM2has the minimum variance among all unbiased estimators in that class.Recently Frey and Feeman (2013) proposed a class of unbiased estimators for the population variance in a JPS sample by conditioning on the observed sample size vector. They further minimize the conditional mean square error of the estimator in this class to construct a conditionally optimal unbiased estimator. In this section we provide an unconditional unbiased estimator for the population variance based on a JPS sample.Letσˆ2=∑r=1H∑s=1Hcrs∑i=1n∑j=1n(Xi−Xj)2Ii,rIj,s,wherecrsare the weights that depend on judgment class sample sizesNh,h=1,…,H, set sizeHand the sample sizen.Theorem 3Let(Xi,Ri);i=1,…,n, be a JPS sample from a distributionFhaving a finite meanμand varianceσ2. Then the selection of weight functioncrs={IrIsJrJs(H−1)2Hdn2{1−1H∑k=1H(kH)n−1}r≠sIrJrJr∗2Hdn∗r=syields an unbiased estimator forσ2, wherednanddn∗are the number of judgment classes having at least one and at least two measured observations.The computation of the variance ofσˆ2requires a tedious calculation and depends on the first four moments ofFand the judgment ranking mechanism. Therefore, Section  6 performs a simulation study to provide empirical evidence for the efficiency of the estimatorσˆ2.This section investigates the finite sample properties of the estimators through a small scale simulation study under varying degree of quality of ranking information. In the simulation study, the JPS samples are generated for sample sizesn=15,30, set sizesH=2,3,4, and the quantile order ofp=0.25,0.5,and0.75. The simulation size is taken to be 5000.The quality of judgment ranking information is modeled with the Dell and Clutter (1972) model. This model uses the joint distribution of the response and ranking variables to assign a rank to measured unit in each set. The quality of ranking information is controlled by the correlation coefficientρbetween the response and ranking variables. In order to maintain the desired correlation coefficient, the response variable is scaled so that it has a variance one. The correlation coefficientρ=1yields perfect ranking whileρ=0yields a random ranking in each set. The other intermediate ranking information can be considered by the selection of a correlation coefficient between 0 and 1 (0≤ρ≤1). Readers are referred to Dell and Clutter (1972) and Ozturk (2013a) for the detailed development of this model. The simulation study selects the correlation coefficient to beρ=1,0.9,0.75, and0.5. The results are reported only forρ=0.75and 1 for the clarity of the presentation.Tables 3–5present the relative efficiencies of the JPS and SRS sample quantile estimators with respect to the JPS sample quantile estimator under the stochastic ordering constraint. LetRE1=MSE(ηˆp)MSE(ηˆpS),RE2=MSE(ηˆp,SRS)MSE(ηˆpS),whereMSEis the mean squared error andηˆp,SRSis the SRS quantile estimator of orderp. Tables 3–5, in addition to relative efficiencies, also contain estimated variance (EV(ηˆp)) ofηˆpfrom equationσˆηp2/f2(ηp)and the simulated variance estimates,SV(ηˆp),SV(ηˆpS), ofηˆpandηˆpS, respectively. The last columns in these tables present the coverage probabilities of the 95-percent confidence intervals ofηp. Data sets are generated from standard normal distribution, Student’st-distribution with three degrees of freedom and standard log-normal distribution.Table 3 presents simulation results for standard normal distribution. It is clear from the relative efficiencies that the quantile estimator under the stochastic ordering constraint on judgment class cdfs yields higher efficiencies than the JPS and SRS quantile estimators of orderp=0.5. Forp=0.25andp=0.75, the JPS estimators may be less efficient for small sample sizes(n=15), but they become as efficient as or more efficient than the SRS quantile estimators for large sample sizes(n=30). In this case estimation of the extreme quantiles requires larger sample sizes. As expected the efficiency gain decreases whenρbecomes smaller.It appears that efficiency ofηˆpandηˆpSare influenced by the set sizeHand sample sizen. For largeHand smalln,ηˆpSoutperformsηˆp, but for largenboth estimators perform equally well. For example, in Table 3,RE1values are 1.134, 1.158, and 1.108 whenn=15,H=4,ρ=0.75, andp=0.25,0.5,0.75, respectively. TheRE1values for the sameH,ρandpvalues but with a larger sample size,n=30, are1.041,1.051, and1.056, respectively. This can be explained from the fact that the stochastic order restriction is more frequently violated for small sample sizes. Hence the estimatorηˆpSmakes a correction on ranking error through the stochastic order constraint and improves the efficiency. For large samples, there is less violation on stochastic order restriction. The estimatorηˆpSmakes less correction on ranking error and yields approximately the same efficiency as the efficiency of the estimatorηˆp. The efficiencies of the estimatorsηˆpandηˆpSwith respect toηˆp,SRSincrease with set sizeH.The simulation results in Table 3 indicate that the estimated variance ofηˆp,EV(ηˆp), are reasonably close to the variance estimates from the simulation,SV(ηˆp). The last column of Table 3 indicates that the coverage probabilities of thep-th order population quantile confidence intervals are reasonably close to the nominal value 0.95 whenn=15andn=30forp=0.5. On the other hand, whenp=0.25orp=0.75, while the coverage probabilities are reasonably close to 0.95 forn=30, they are slightly smaller than 0.95 whenn=15. This indicates that constructing confidence intervals for the extreme quantiles requires a larger sample size.The patterns similar to the ones that have been observed in Table 3 also appear in Tables 4 and 5 for the Student’st-distribution with three degrees of freedom and standard log-normal distributions, respectively. This suggests that the estimators and the confidence intervals are distribution free for sample sizes as small as 15.Another simulation study is performed to investigate the efficiency of the variance estimatorσˆ2. In this part of the simulation, the JPS samples are generated from four distributions, standard normal distribution (N(0,1)), uniform distribution (U(0,1)), gamma distribution with shape parameter 5 and scale parameter 1(G(5,1))and standard exponential distribution (Exp(1)). For the other simulation parameter, the sample sizesn=5,30,200, set sizesH=2,3,4and correlation coefficientsρ=1,0.75,0.50are used. For each of the simulation parameter combination, relative efficiency (RE) values are computed from 2000 JPS samplesRE=V(S2)V(σˆ2),whereS2is the simple random sample variance estimator. The values ofREgreater than one indicate that the proposed estimator is more efficient than the simple random sample variance estimator. It is clear from Table 6that the proposed variance estimator may be less efficient than a simple random sample estimator for small sample sizes and smallρvalues. When the sample size is small, the JPS samples are highly unbalanced producing many empty strata. Hence, the variance of the estimator is inflated. When the sample size increases, the JPS sample approaches to a balanced ranked set sample and the variance estimator becomes as efficient as or more efficient than a simple random sample variance estimator depending on the magnitude of the sample size. For example, for all four distributions in Table 6, the efficiency of the proposed estimator is less than one whenn=5, approximately equal to 1 whenn=30and greater than one whenn=200. For a fixed sample size, sayn=30, larger set sizes produce lower efficiency forσˆ2. For example, for normal distribution, the sample sizen=30and the set sizeH=2yieldRE=0.978,0.974whenρ=0.75,0.50, but the sample sizen=30and set sizeH=4yieldRE=0.935,0.874for the sameρvalues. In this case, the fixed sample size(n=30)is divided into larger number of judgment classes whenH=4. Hence, it produces more unbalanced samples (and possibly empty strata), and reduces the efficiency. Another observation from Table 6 is that the efficiency increases with the quality of ranking information as expected.MacEachern et al. (2004) introduced judgment post-stratified sample to stratify a simple random sample post experimentally based on available auxiliary information. Because of this additional structure, the JPS sample is usually more efficient than an SRS sample but less efficient than an RSS sample to develop inference for the population mean. This research shows that the similar result also holds for the quantile inference of an infinite population. For a finite sample, the efficiency of the quantile estimator of a JPS sample is in between the SRS and RSS sample quantile estimators. It is shown that as the sample size gets large the efficiency of the JPS sample quantile estimator approaches to the efficiency of an RSS sample quantile estimator.JPS uses a ranking process, often subject to a ranking error, to create judgment strata. The main results of the paper do not rely on the perfect ranking assumption. It only requires a consistent ranking scheme. Hence, the results are applicable in a wide range of JPS sampling designs. This paper considers statistical inference for the population quantiles and variance. The results can be generalized to draw inference for other aspects of a population.The appendix first derives the distributional properties ofIh/dh,h=1,…,H. The following lemma is given in Dastbaravarde et al. (in press).Lemma 2In a JPS sample, letIhbe the indicator function that the judgment classhis not empty anddnbe the number of non-empty judgment classes, i.e.dn=∑h=1HIh. For the distribution ofIh/dn, the following equalities can be established.(i)P(Ihdn=w)={{H−1H}nw=01HnH−1k−1∑j=1k(−1)j−1kj−1(k−j+1)nw=1k;k=1,…,H.E(Ihdn)=1H.V(Ihdn)=1H2∑k=1H−1(kH)n−1.Cov(Ihdn,Ih′dn)=−1H2(H−1)∑k=1H−1(kH)n−1,h≠h′.E(IhNhdn2)=1Hn{1n+∑k=2H∑j=1k−1∑nh=1n−k+1(−1)j−1k2nhH−1k−1k−1j−1nnh(k−j)n−nh}.Proof of Lemma 2It is important to note thatIh/dnare identically distributed. It is then sufficient to consider the distribution ofI1/dn.Proof of (i): First consider the caseP(I1/dn=0),P(I1/dn=0)=P(N1=0)=(H−1H)nfordn=1,…,H. The equality above follows from the fact that none of the measured observations are not in judgment class 1. Now considerP(I1/dn=1/k)=P(N1>0,dn=k)which indicates that there must beH−1k−1different combination withknonzero judgment classes andH+1−kempty judgment classes, each of these combinations is equally likely with probabilityP(N1>0,…,Nk>0,Ni=0,;i>k). The distribution ofI1/dncan be written in a compact notationP(I1/dn=1/k)=H−1k−1∑n1,…,nk>0nn1,…,nH1Hn,P(I1/dn=1/k)=1HnH−1k−1∑j=1k(−1)j−1kj−1(k−j+1)n.The last equality can be shown either by using inclusion–exclusion principal or induction.Proof of (ii): The identical distribution ofIh/dn,h=1,…,Himplies thata=E(I1/dn)=⋯=E(IH/dn). It is then easy to establishHa=E(I1+⋯+IHdn)=1. Hencea=1/H.Proof of (iii): The computation ofE(I1/dn2)follows fromE(I1dn2)=∑u=1HH−1u−1u2Hn∑n1,…,nu>0nn1,…,nu=∑u=1HH−1u−1u2Hn∑j=1u(−1)j−1uj−1(u−j+1)n.Letk=u−j+1. By rearranging the terms, the expression above can be written asE(I1dn2)=1Hn∑k=1H(∑j=1H−k+1(−1)j−1k+j−1H−1j−1H−jk−1)kn−1.By considering that∑j=1H−k+1(−1)j−1k+j−1H−1j−1H−jk−1=1/H,one can reduce the expected value ofI1dn2to a simple formE(I1dn2)=1H2∑k=1H(kH)n−1.The variance ofI1dn2follows from the above expectationV(I1dn2)=1H2∑k=1H(kH)n−1−(1/H2)=1H2∑k=1H−1(kH)n−1.Proof of (iv): SinceIhis an indicator functionIh2=Ih. Letb=E(I1I2dn2)=⋯=E(I1IHdn2). We then use the fact that(H−1)b=E(∑h=2HI1Ihdn2)=E(I1(dn−I1)dn2)=1/H−E(I1/dn2). Hence, an expression forbis easily obtained(4)b=1H(H−1)(1−1H∑k=1H(kH)n−1).The proof of (iv) is completed by using the expressionband part (ii) of Lemma 2.Proof of (v): The proof is similar to the one presented in part (iii)E(I1J1dn2)=∑k=1HH−1k−1k2Hn∑n1,…,nk>01n1nn1,…,nk=1Hn(1n+∑k=2HH−1k−1k2∑n1=1n−k+1nn1n1∑n2,…,nk>0n−n1n2,…,nk)=1Hn[1n+∑k=2H∑j=1k−1∑n1=1n−k+1(−1)j−1k2n1H−1k−1k−1j−1nn1(k−j)n−n1].Proof of Lemma 1By using the iterative expectation, one can writeE(S(ηp))=∑h=1HEIhJhdnE(∑j=1n{I(Xj>ηp)−(1−p)}I(Rj=h)|R)E(S(ηp))=∑h=1HEIhJhdnNh{(1−F[h](ηp))−(1−p)}.Using the fact thatIh/dn,h=1,…,H, are identically distributed, the above expression is reduced toE(S(ηp))=E(I1dn)∑h=1H{(1−F[h](ηp))−(1−p)}.Note that consistent ranking assumption yields that∑h=1H(1−F[h](ηp))=H(1−F(ηp))=H(1−p). This completes the proof.For the proof of the variance, use of the conditional variance formula yields that(5)V(nS(ηp))=V(E(nS(ηp)|R))+E{V(nS(ηp))|R}.The first term in the above equation can be written asnV(E(S(ηp)|R))=nV{∑h=1HIhJhdnE∑j=1n{I(Xj>ηp)−(1−p)}I(Rj=h)|R}=nV{∑h=1HIhJhNhdn{1−F[h](ηp)−(1−p)}}=nV{∑h=1HIhdn{1−F[h](ηp)−(1−p)}}=n∑h=1HV(Ihdn){p−F[h](ηp)}2+n∑h≠h′Cov(Ihdn,Ih′dn){p−F[h](ηp)}{p−F[h′](ηp)}.SinceIh/dn,h=1,…,H, are identically distributed, the above equation can be written in a simple formV(E(nS(ηp)|R))=nV(I1dn)∑h=1H{p−F[h](ηp)}2+nCov(I1dn,I2dn)∑h≠h′{p−F[h](ηp)}{p−F[h′](ηp)}.From Lemma 2 one can write thatCov(Ihdn,Irdn)=−1H−1V(Ihdn).Using this equality, the following expression is obtainedV(E(nS(ηp)|R))=nV(I1dn){∑h=1H{p−F[h](ηp)}2−1H−1∑h≠h′{p−F[h](ηp)}{p−F[h′](ηp)}}=nHH−1V(I1dn)∑h=1H{p−F[h](ηp)}2=Bn,HκH2(ηp).In the expressionE(V(nS(ηp))|R)in Eq. (5),E(V(nS(ηp))|R)=nE(V{∑h=1HIhJhdn∑j=1n{I(Xj>ηp)−(1−p)}I(Rj=h)|R}),Xjare conditionally independent for a given set of ranks. This expression then reduces to a simplified fromE(V(nS(ηp))|R)=E∑h=1HnIh2Jhdn2{1−F[h](ηp)}F[[h](ηp)=E(nI12J1dn2)∑k=1H{1−F[k](ηp)}F[[k](ηp)=Cn,HδH2(ηp)which completes the proof.Proof of Theorem 1Note thatNis a multinomial random vector with parametersnand(1/H,…,1/H)⊤. Asngoes to infinityN/nconverges in probability to(1/H,…,1/H)⊤Nn→P(1/H,…,1/H).LetDnbe a diagonal matrix of the vector(n/N1,…,n/NH). It is clear that the matrixDnconverges in probability to a diagonal matrixD0=diag(H,…,H). SinceNh,h=1,…,H, is a multinomial random vector, for largen, there exist a sequence of integersN0,h, for eachh=1,…,Hsuch that(6)NhN0,h→P1,h=1,…,H.LetSNh(ηp,0)=∑i=1nIi,h{I(Xi>ηp,0)−(1−p)}. For largen, by using the results in Eq. (6), a similar definition can be given forSN0,h(ηp,0)=∑i=1nIi,h{I(Xi>ηp,0)−(1−p)}. LetT(ηp,0)=[SN1(ηp,0)N1⋮SNH(ηp,0)NH],T0(ηp,0)=[SN0,1(ηp,0)N0,1⋮SN0,H(ηp,0)N0,H]andW(ηp,0)=[{SN1(ηp,0)−SN0,1(ηp,0)}N0,1N1⋮{SNH(ηp,0)−SN0,H(ηp,0)}N0,HNH].With these definitions, one can writeDnT(ηp,0)=DnT0(ηp,0)+DnW(ηp,0).Lettbe a unit vector (‖t‖2=1). It is easy to observe thatt⊤DnT0(ηp,0)converges to a univariate normal distribution with mean zero and varianceH∑h=1Hth2F[h](ηp,0)(1−F[h](ηp,0)). By using Cramer–Wold device one can conclude thatDnT0(ηp,0)converges in distribution to anH-dimensional normal distribution with mean zero and variance covariance matrixΣ=Hdiag(F[1](ηp,o)(1−F[1](ηp,o)),…,F[H](ηp,o)(1−F[H](ηp,o))).Now it remains to show thatW(ηp,0)converges in probability to zero. Consider thehth component ofW(ηp,0)Wh(ηp,0)={SNh(ηp,0)−SN0,h(ηp,0)}N0,hNh.From Theorem 3.2 in Gut (2005, p. 347), it can be shown thatWh(ηp,0)converges in probability to zero.Letdn⊤=(I1/d1,…,IH/dH). It is clear thatdn⊤almost surely converges to a vector(1/H,…,1/H). Slutsky’s theorem then indicates thatdn⊤DnT0(ηp,0)→DN(0,δH2(ηp,0))which completes the proof.Proof of Theorem 2LetUn(a/n)=S(ηp+an)−S(ηp)a/n.Without loss of generality assume thatηp=0. First consider the expected value ofUn(a/n). By using the conditional expectation given the rank vectorR, one can writeE(Un(a/n))=E∑k=1HIkdn[F[k](ηp)−F[k](ηp+a/n)a/n].SinceIkdnare identically distributed, the limit of this expectation can be written aslimn→∞E(Un(a/n))=limn→∞E(I1dn)∑k=1HF[k](ηp)−F[k](ηp+a/n)a/n=−1H∑k=1Hf[k](ηp)=−f(ηp).Next show that the variance ofUn(a/n)converges to zero asngoes to infinity. By conditioning on the rank vectorR, the variance can be written asV(Un(a/n))=V(E(Un(a/n|R)))+E(V(Un(a/n|R))).By using the argument similar to the one given in Lemma 1, one can obtainV(E(Un(a/n|R)))=HH−1V(I1dn)∑k=1H{A[k](ηp+a/n)−Ā(ηp+a/n)}2,whereA[k](ηp+a/n)=F[k](ηp)−F[k](ηp+a/n)a/nandĀ(ηp+a/n)=1H∑k=1HA[k](ηp+a/n).Asngoes to infinityV(E(Un(a/n|R)))has a limit at zero.To observe the large sample behavior ofE(V(Un(a/n|R))), this expectation can be written asE(V(Un(a/n|R)))=E{V[∑h=1HIhJhdn∑j=1nIj,hI(Xj>ηp+a/n)−I(Xj>ηp)a/n|R]}=E{∑h=1HIh2nJhdn2K[h](ηp+a/n)}=E(I12J1nHdn2)∑h=1HK[h](ηp+a/n)H,whereK[h](ηp+a/n)={F[h](ηp)−F[h](ηp+a/n)}{1−F[h](ηp)+F[h](ηp+a/n)}a2.Asngoes to infinityK[h](ηp+a/n)converges to zero. The proof of the point wise convergence is completed by observing thatE(I12J1nHdn2)is finite. Uniform convergence in the compact set follows from the fact that the estimating equation is non-increasing in its argument.Proof of Theorem 3It should be first observed thatσ2=1H∑k=1Hσ[k]2+1H∑k=1H(μ[k]−μ)2,whereσ[k]2andμ[k]are the variance and mean of thekth judgment class distribution. For the unbiasedness, it is sufficient to show thatE(σˆ2)=σ2.E(σˆ2)=∑r≠sE{cr,s∑i=1n∑j=1nE((Xi−Xj)2Ii,rIj,s|R)}+∑r=1HE{cr,r∑i=1n∑j=1nE((Xi−Xj)2Ii,rIj,r|R)}=E(An)+E(Bn).First consider the expected value ofAnE(An)=∑r≠sE{cr,s∑i=1n∑j=1nE((Xi−Xj)2Ii,rIj,s|R)}=∑r≠sE{cr,sNrNs[σ[r]2+σ[s]2+(μ[r]−μ[s])2]}.Insertingcr,sin the above equation, one can writeE(An)=H−12H[1−1H∑k=1H(kH)n−1]∑r≠sE(IrIsdn2)[σ[r]2+σ[s]2+(μ[r]−μ[s])2].SinceIrIsdn2are identically distributed, the expected value ofAnreduces toE(An)=(H−1)E(I1I2/dn2)2H[1−1H∑k=1H(kH)n−1][2(H−1)∑k=1Hσ[k]2+2H∑k=1H(μ[k]−μ)2].Now insert the value ofE(I1I2/dn2)in Eq. (4) in the above expression to writeE(An)=H−1H2∑k=1Hσ[k]2+1H∑k=1H(μ[k]−μ)2.The expected value ofBnis given byE(Bn)=E[E(B|R)]=2∑r=1HE(cr,rNr(Nr−1)σ[r]2).Insertingcr,rin the above equation, one can obtainE(Bn)=1H2∑r=1Hσ[r]2.The proof is completed by addingE(An)andE(Bn).

@&#CONCLUSIONS@&#
