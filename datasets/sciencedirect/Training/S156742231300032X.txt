@&#MAIN-TITLE@&#
Automated buyer profiling control based on human privacy attitudes

@&#HIGHLIGHTS@&#
We present a novel automated buyer profiling control mechanism.It is based on pseudonym changes performed according to human privacy attitudes.Agents automatically decide whether reusing or changing their pseudonyms.We present the results of an extensive experimental evaluation of the mechanism based on an application scenario.

@&#KEYPHRASES@&#
E-commerce,Privacy,Buyer profiling,Pseudonymity,Automated pseudonym change,Customer profiling,Agent-based e-commerce,

@&#ABSTRACT@&#
In e-commerce applications, vendors can construct detailed profiles about customers’ preferences, which is known as buyer profiling. These profiles can then be used by vendors in order to perform practices such as price discrimination, poor judgment, etc. The use of pseudonyms and, specially, changing pseudonyms from time to time are known to minimize profiling, minimizing the capacity of vendors to perform such practices in turn. Although there are some frameworks and tools that support pseudonym change, there are few proposals that suggest or directly change the pseudonym in an automated fashion. Instead, users are usually provided with the mechanisms to change pseudonyms but without any advise on when they should actually use these mechanisms. In this paper, we present an approach to control buyer profiling by means of automated pseudonym changes performed according to human privacy attitudes. We also present an application scenario and an evaluation of our proposal.

@&#INTRODUCTION@&#
The explosive growth of the Internet in the last decades has caused that more than 2 billion users as of 2012.1http://www.internetworldstats.com/stats.htm.1In this environment, on-line privacy is of great concern. Users are constantly exposed to personal information collection and processing without even being aware of it (Fischer-Hübner and Hedbom 2008). Information collection refers to the process of gathering and storing data about an individual whereas information processing refers to the use or transformation of data that have been already collected (Solove 2006)—even possibly inferring new data from the data already collected. There are some directives that try to regulate this massive collection and processing of information (e.g., EU Directives 95/46/EC, 45/2001/EC, and 2002/58/EC). However, due to the very nature of the Internet itself, there is no global governing body that could effectively enforce these regulations in daily digital activity. Therefore, these practices are still possible with the potential to jeopardize privacy.We focus on a type of information processing in e-commerce environments broadly known as buyer—or customer—profiling (Shaw et al. 2001, Such 2011), in which vendors obtain detailed profiles of their customers based on previous transactions, and subsequently tailor their offers regarding customers’ tastes. These profiles can represent a serious threat to privacy. For instance, these profiles can be used to perform price discrimination (Odlyzko 2003). Vendors could charge customers different prices for the same good according to the customers’ profiles, i.e., if a vendor knows that some good is of great interest to one customer, the vendor could charge this customer more money for this good than other customers for the same good. For instance, in 2000, Amazon started to charge customers different prices for the same DVD titles (Spiekermann 2006). When the story became public, Amazon claimed that this was part of a simple price test and discontinued this practice. Another example of privacy threat due to the use of these profiles is what is known as poor judgment (Smith and Milberg 1996). This is when individuals are judged and subsequently treated according to decisions made automatically based on incorrect or partial personal data. For instance, companies usually divide their potential customers into similar groups based on customers’ characteristics—known as customer segmentation. This practice can lead to exclusion of people from services based on potentially distorted judgments (Spiekermann and Cranor 2009).Hansen et al. (2004) point out that pseudonyms2A pseudonym is an identifier of a subject other than one of the subject’s real names (Pfitzmann and Hansen 2010). Human beings have been using pseudonyms in the real world for a long time. For instance, in the 19th century when writing was a male-dominated profession, some female writers used male names for their writings. Nowadays, in the digital world, there are a great number of pseudonyms such as usernames, nicknames, e-mail addresses, sequence numbers, public keys, etc.2should be used and, most importantly, changed from time to avoid profiling. Indeed, the most privacy-preserving option is to use transaction pseudonyms (Chaum 1985), i.e., to use a different pseudonym for each different transaction. The problem is that users are often provided with the mechanisms and infrastructures that allow them to change their pseudonyms but without any mechanism that aids them to decide when they should actually change their pseudonyms. Even the very few approaches that automate pseudonym change (such as Warnier and Brazier 2010, Fritsch 2008, Fonseca et al. 2007) do not consider the fact that there are many cases in which the user can be interested in reusing the same pseudonym, e.g., users may accept a potential privacy loss when some benefit is expected if they reuse the same pseudonym, such as price discounts, the building of a reputation, etc. (Such et al. 2013a). Indeed, several studies have demonstrated that humans have different general attitudes towards privacy (Ackerman et al. 1999, Westin 1967, Taylor 2003, The Direct Marketing Association DMA (UK) Ltd 2012): privacy fundamentalists are extremely concerned about privacy and reluctant to lose privacy; privacy pragmatists are concerned about privacy but they are willing to lose some privacy when some benefit is expected; and privacy unconcerned do not consider privacy loss.In this paper, we present an agent-based approach to control buyer profiling automatically based on human attitudes towards privacy. In particular, we present an approach in which an agent automatically decides whether or not to change its pseudonym in its next interaction considering an estimation of the privacy loss and the utility of reusing a pseudonym. The crucial point is that this approach does not require human intervention for each pseudonym change decision but agents will comply with its user’s attitude towards privacy. For instance, if a user’s attitude towards privacy is unconcerned, her/his agent will only consider the utility of reusing a pseudonym to decide whether or not it changes its pseudonym in its next interaction.The remainder of this article is organized as follows, Section 2 motivates the main contribution of this paper. Section 3 presents our proposal for pseudonym change. Section 4 describes a privacy loss function for agent-based e-commerce domains. Section 5 describes an application scenario for our proposal. Section 6 presents the experiments we performed and the results we obtained when applying our proposal to this application scenario. Section 7 presents some related work. Finally, Section 8 presents our concluding remarks.

@&#CONCLUSIONS@&#
The main contribution of this paper is, to the best of our knowledge, the first automated mechanism for buyer profiling control based on pseudonym changes in e-commerce environments. To this aim, our proposed mechanism considers both the privacy/utility loss of reusing/changing a pseudonym. In particular, agents decide whether to change a pseudonym or not based on the specific attitude towards privacy of their users. This specific attitude is what determines to what extent an agent values the privacy loss and the utility of reusing/changing a pseudonym. We also contribute a general privacy loss function that can be used in e-commerce environments that measures the accuracy of the profile built by sellers based on previous interactions with them.We also presented an application scenario and the experiments we performed to validate our proposed mechanism. The results we obtained prove that changing pseudonyms can prevent buyer profiling in e-commerce scenarios, though, of course, at the expense of the benefits of re-using a pseudonym—this is actually the reason why a model like the one presented is needed, because different persons with different privacy attitudes will see this expense as acceptable or not to preserve their privacy. The results also validated that the pseudonym changes suggested by our proposed mechanism will follow the privacy attitude of the user involved. Moreover, we obtained results that confirm that there are other factors that will determine the final number of pseudonym changes needed to comply with a particular privacy attitude. In particular, the results we obtained point out that the final number of pseudonym changes to be performed will also depend on the complexity of users’ tastes, i.e., users’ tastes that are more difficult to learn will imply less privacy loss so that less pseudonym changes will be needed. Finally, we also proved that the number of different sellers with whom the buyers interact will also impact the number of pseudonym changes required to comply with a given privacy attitude.Finally, as future work we plan to develop a complete privacy-enhancing agent-based e-marketplace application that will build on our mechanism presented in this paper implemented in agents running on top of the Magentix2 agent platform. To this aim, there are still other functionalities that this application would need to provide and that are beyond the scope of this paper, e.g., models to search for sellers that sell the goods that buyers would like to acquire, models that allow agents to select the most appropriate seller to interact with from all the sellers that provide these goods, etc.