@&#MAIN-TITLE@&#
On a family of run length limited, block decodable codes to prevent payload-induced jitter in Controller Area Networks

@&#HIGHLIGHTS@&#
A family of codes to prevent jitter in Controller Area Networks is proposed.It was proved that the codes are optimal under typical embedded system constraints.A software implementation of the encoder and decoder modules has been carried out.The implementation is portable, compact, fast, and fully deterministic.

@&#KEYPHRASES@&#
Industrial control,Real-time distributed systems,Controller Area Network,

@&#ABSTRACT@&#
Controller Area Networks (CAN) adopt bit stuffing at the physical layer, thus introducing a frame length variability that may adversely affect sensing and actuation jitter. One way to mitigate this issue is to encode the payload by means of a suitable run length limited code, before transmission.In this paper, a family of these codes is defined and thoroughly analyzed from the theoretical point of view, showing its optimality within a set of performance and footprint-related constraints typical of contemporary embedded systems. Experimental results confirm that the proposed technique is amenable to an efficient and deterministic software-based implementation.

@&#INTRODUCTION@&#
Controller Area Network (CAN) [1] is a very popular digital communication protocol that was initially conceived for in-vehicle use. Currently, the most part of the existing cars includes indeed one or more of these networks on board. Besides the automotive field, CAN has been widely used in industrial scenarios [2] and networked embedded control systems as well [3].At the physical layer, CAN relies on a Non Return to Zero (NRZ) encoding with bit stuffing. Although bit stuffing (BS) is quite simple and efficient, it has one drawback. In fact, the exact size of the frames that are sent over the bus depends on the values they carry, which may lead to jitters on actuation and sensing. In [4] an encoding technique was described, namely 8B9B, that completely prevents stuff bits in the data field of CAN frames. A codec was introduced as well, which was characterized by a very small footprint and also achieved really short (and deterministic) execution times. A comparison of the performance of this encoding scheme with other previous solutions available in the literature was carried out in [5], where it was shown that 8B9B is able to ensure higher determinism than plain CAN at the expense of a slightly lower encoding efficiency.In this paper the family of encoding schemes to which 8B9B belongs has been analyzed from the theoretical point of view, and a new enhanced scheme, called Variable-length, High-performance Code for CAN (VHCC), has been introduced. Unlike [4], where the codebook used for the lookup tables in the codec was found empirically, a formal approach is adopted here that permitted us to prove that our solution actually provides the highest encoding efficiency for this kind of approaches. Moreover, an additional mechanism has been defined that, combined with the new codebook, permits to pack additional sub-byte information in the encoded data field of CAN frames.The paper is structured as follows: in Section 2 the bit stuffing mechanism of CAN is briefly recalled and compared with related techniques for other kinds of link. Section 3 defines the framework that permits creating the new codebook by induction, whereas Section 4 provides more detailed information on how both the codebook generator and the encoding and decoding software modules have been implemented in practice. Last, Section 5 contains experimental results about codec footprint and performance on a contemporary microcontroller, Section 6 compares them with related works, and Section 7 draws some conclusions.Bit stuffing in CAN is a line code with the main goal of ensuring that a sufficient number of edges are found in the bit stream sent over the bus, so that the Digital Phase Locked Loop (DPLL) in receivers can recover the transmitter clock correctly. Basically, every time 5 bits at the same value have been transmitted in a row, an additional stuff bit at the opposite level is inserted by the transmitting node, hence creating an edge on which DPLLs can synchronize. Stuff bits are removed by receiver nodes to get back the original frame.Moreover, a well-defined code violation (namely, transmitting 6 consecutive bits at the same value) constitutes an error flag, which is used to signal bus errors and globalize them. As depicted in Fig. 1, BS applies to the part of the frame from the Start Of Frame bit (SOF) to the Cyclic Redundancy Check field (CRC) included. The following part is of fixed format and not stuffed. Similar encoding schemes have been adopted for other kinds of communication links, too, such as High-level Data Link Control (HDLC) [6] and the Universal Serial Bus (USB) [7], up to version 2.0.Because of BS, the exact duration of the transmission of any given frame depends not only on the size of the payload but also on its content. As a consequence, reception times for messages in the same message stream may suffer from unwanted jitters that, in CAN, may be as high as 24 bit times (in theory). This also means that the timing accuracy of actuation and sampling on the networked devices in the system is negatively affected to the same extent. The jitter due to BS is much lower than the uncertainty in transmission times due to the CAN arbitration technique. This explains why this problem is typically overlooked in several contexts, such as the automotive domain. There are, however, other application fields where the ability to carry out frame exchanges with accurate timings is of practical relevance. Possible examples are distributed control systems in factory automation that require precise synchronization and accurate measuring instruments.The problem above is well known: It has been highlighted several times in the literature [8–13] and several remedies have been consequently proposed. Among them, the 8B9B approach [4] has been recently introduced. Basically, 8B9B is a block code that applies to unmodified conventional CAN controllers and prevents the insertion of stuff bits in the data field of CAN frames, by avoiding the occurrence of sequences of 5 or more bits at the same level (denoted primer sequences) in that part of the frame.The related problem of constructing Run Length Limited (RLL) bit sequences to encode information has been studied extensively in the context of data storage systems [14]. However, the design goals of RLL codes for data storage and codes like 8B9B are quite different, and hence, they lead to dissimilar encoding mechanisms.First of all, in the data storage context, the presence of an additional, differentiating decoding stage–often taking place at the level of the physical read/write heads–is implicitly assumed, leading to the use of the Non Return To Zero Inverse (NRZI) code format. Under this hypothesis, the construction of a RLL sequence is accomplished starting from another kind of constrained sequence, called (dk) sequence, and then integrating it.By definition, a (dk) sequence is a bit sequence in which there are at least d bits at zero between two bits at one and that contains no more than k consecutive bits at zero. It can easily be shown that, after integration, the output RLL sequence will have no less than d+1 and no more than k+1 consecutive bits at the same value. Because of inherent limits of the recording medium, the vast majority of data storage codes have d>0, a constraint that does not apply to CAN.Moreover, communication channels like CAN do not have any integrating/differentiating stage on their own, and therefore, they use the NRZ code format instead of NRZI. The explicit addition of such a stage, albeit possible, would be a source of additional overhead–especially in software implementation–because it is a bit-by-bit operation to be carried out on the data stream. For the same reason, other properties of interest for data storage codes, such as the absence of a Direct Current (DC) component in the encoded bit stream and embedded error-detection capabilities, are not as important for CAN.Secondly, most data storage codes are designed for hardware-based encoding and decoding. Therefore, they often trade off additional encoding and decoding complexity for optimal information rate plus the additional properties outlined above. By contrast, the focus of this paper is on an efficient software-based implementation. Because of this, code design was based on the hypotheses of:•memoryless, efficient block encoding and decoding, based on table lookup;direct transmission of codewords through the channel, without intermediate integrating/differentiating elements (by using conventional CAN controllers);possibility of nesting smaller codebooks into larger ones, to encode and decode blocks of varying length with the same tables (in order not to increase codec footprint).The basic principle behind 8B9B is quite simple. Every byte in the original payload of the CAN message is translated separately to a codeword expressed as a 9-bit pattern. The codebook was obtained in [4] by means of a simple C program, and satisfies the basic property that primer sequences can never appear in the encoded data field, irrespective of the original payload.Two mechanisms were also introduced in 8B9B, that corresponds to the break bit (BB) and the padding field (PAD). BB is located in the very first position of the data field, and is set at the opposite value than the least significant bit of the DLC. It prevents the occurrence of a primer sequence on the boundary between the DLC and data fields. The padding, instead, is just a particular filling of the unused portion of the last byte in the encoded data field that, again, is aimed at preventing primer sequences. The bottom part of Fig. 1 shows the usage 8B9B makes of the data field. It is worth noting that 8B9B, as well as any other approach defined so far, is unable to prevent stuff bits in the CRC. Nevertheless, it can be easily shown that no more than 4 residual stuff bits can be added to this field.Although the basic 8B9B mechanism is simple enough to allow for very fast implementations, and intuitively it is able to achieve very good encoding efficiency, there is not any warranty that it is actually the best possible choice. In the following, this problem has been modeled formally using an inductive approach and solved by means of a Prolog[15] program. Results prove that, in practical cases, our solution is actually the optimal one. Moreover, our analysis has also led to a new version of the codebook, which satisfies an interesting nesting property that has been used to further improve the codec.Then, small changes have been brought to the original encoding scheme – and to the codec as well – which permit the amount of information that can be embedded in the encoded frames to be maximized (payload granularity is now one bit instead of one byte). Overall, it is possible to state that the new version of 8B9B, which we have called VHCC, is the best solution available to cope with BS jitters in CAN, among those able to prevent stuff bits in the data field completely.Let us denote with the calligraphic letterUsthe universe of binary strings of length s and with the corresponding uppercase letter Usthe number of elements ofUs, that is, let Us=|Us|. An analogous notation will be used for the other sets defined throughout this section. Obviously, it is:(1)Us=2s.Our goal is to build a set of codebooksGs,l,b,tfor integer values s≥2, l≥1, b≥1, and t≥1, so that each codebook satisfies the following properties:•the elements ofGs,l,b,tare binary strings of length s, that is,Gs,l,b,t⊆Us;all elements g∈Gs,l,b,thave at most l leading bits at the same value, at most b consecutive inner bits at the same value, and at most t trailing bits at the same value;the elements ofGs,l,b,tcontain at least one bit value transition, that is,0…02⏞sbits∉Gs,l,b,t,1…12⏞sbits∉Gs,l,b,t,this condition is included in the previous one when s>min(l, t);Gs,l,b,tcontains enough codewords to uniquely encode a binary string of length s−1, that is, denoting with Gs,l,b,tthe number of elements ofGs,l,b,t:(2)Gs,l,b,t≥Us−1.when all these conditions are satisfied – and provided that l+t≤b – it is trivial to prove that the bit string resulting from the concatenation of any number of elements ofGs,l,b,t, even for varying s, will contain no more than b consecutive bits at the same value at any position, as long as l, b, and t are still kept the same for all codebooks. If the communication channel bit stuffing mechanism is triggered by a sequence of b+1 bits at the same value (one of the primer sequences mentioned in Section 2), this is a sufficient condition for the complete absence of bit stuffing at the channel level. As discussed in Section 2, b=4 for CAN.Other points of interest are to determine the maximum value of s, denoted with smin the following, for which codebook construction is still possible and, in particular, property (2) still holds. For an efficient practical implementation of the encoding and decoding software modules based on lookup tables, which will be discussed in Section 4, it is also important to highlight any relationship between the codebooksGs,l,b,t, for varying s=2,…, sm. This is because any relationship can be leveraged to reduce the size of the lookup tables, and hence, the footprint of the software.In the following, for any s≥1,Qsdenotes the set of strings of length s with exactly s leading (and trailing) bits at the same value. Moreover, for any s≥2 and 1≤k≤s−1, Rs(k) denotes the set of strings of length s with no more than s–k leading bits at the same value and exactly k trailing bits at the same value.A direct consequence of these definitions is that all the elements of Rs(k), regardless of the value of k, always have strictly less than s leading bits at the same value. Moreover, for any value of s, the setQscontains exactly two binary strings composed of either all zeros or all ones, namely:(3)Qs=0…02⏞sbits,1…12⏞sbits∀s≥1.Denoting with Qsthe number of elements ofQs, it is therefore:(4)Qs=2∀s≥1.The construction of the sets Rs(k), as well as the calculation of how many elements belong to them, Rs(k), is slightly more complex, but it can be performed effectively by induction.For s=1, from Eq. (3) and according to the definitions given in Section 3.1:(5)Q1=0212.This is because the two 1-bit strings 02 and 12 both have one leading (and trailing) bit at the same value.For s≥2, it is:(6)Rs1=x≀∼rbxx∈Rs−1k∪Qs−1,1≤k≤s−2(7)Rsk=x≀rbxx∈Rs−1k−1,2≤k≤s−1where the ≀ operator denotes string concatenation and the function rb(x) extracts the least significant (rightmost) bit of the binary string x given as an argument. The ~ operator denotes Boolean one's complement. Informally speaking, the inductive construction of the sets Rs(k) proceeds as follows:•The strings of length s≥2, with strictly less than s leading bits at the same value and exactly 1 trailing bit at the same value, belonging to Rs(1), can be obtained from any string of length s−1, belonging to either Rs−1(k), 1≤k≤s−2, orQs−1, by appending an additional bit that is the complement of the rightmost one as in Eq. (6).The strings of length s≥2 with no more than s–k leading bits at the same value and exactly k trailing bits at the same value, with 2≤k≤s−1 (the elements of Rs(k)), can be built from any sequence of s−1 bits with no more than s−k leading bits at the same value and exactly k−1 trailing bits at the same value (the elements of Rs−1(k−1)) by appending an additional bit that is the same as the rightmost one as in Eq. (7).Although Eq. (3) already gives a direct definition ofQs, it is worth noting anyway that the 2 strings of length s≥1 with s leading (and trailing) bits at the same value, the elements ofQs, can be trivially derived from the 2 sequences of length s−1 with s−1 leading (and trailing) bits at the same value, the elements ofQs−1, by appending an additional bit at the same value as the rightmost one. Namely:(8)Qs=x≀rbxx∈Qs−1,s≥2.Concerning the number of elements of Rs(k), denoted by Rs(k), referring to Eq. (6) we can write:(9)Rs1=∑k=1s−2Rs−1k+Qs−1,s≥2,because the sets Rs−1(k), 1≤k≤s−2, andQs−1 are, by definition, all disjoint for a fixed s. From Eq. (7) we can similarly write:(10)Rsk=Rs−1k−1,2≤k≤s−1.By repeatedly applying Eq. (10) it is:(11)Rsk=Rs−k+11.Substituting Eqs. (4) and (11) into Eq. (9), we obtain:(12)Rs1=∑k=1s−2Rs−k1+Qs−1=∑k=2s−1Rk1+2,s≥2.From the previous expression we can also write:(13)Rs1=Rs−11+∑k=2s−2Rs−k1+2,s≥3,where the rightmost part of the last expression, surrounded by parentheses, corresponds to the definition of Rs−1(1). This is because, by letting j=s−k, we can write:(14)∑k=2s−2Rs−k1=∑j=2s−2Rj1Therefore, it is:(15)Rs1=2Rs−11=2s−2R21,s≥3.Being R2(1)=Q1=2, from Eqs. (4) and (9) we have, in general:(16)Rs1=2s−1,s≥2.From Eq. (11) we can eventually conclude that:(17)Rsk=2s−k,1≤k≤s−1.An additional consistency check of the above statements can be performed by noticing that, for any given s, the sets Rs(k), 1≤k≤s−1, andQsmust cover the universe of the strings of length s:(18)∪k=1s−1Rsk∪Qs=Us,s≥1,Since the sets being considered are all disjoint for a fixed s by definition, it must also be:(19)∑k=1s−1Rsk+Qs=2s,s≥1.In fact, from Eqs. (17) and (4) it is:(20)∑k=1s−1Rsk+Qs=∑k=1s−12s−k+2=2∑j=0s−22j+1=22s−1−1+1=2s.The construction of the sets Rs(k) andQsby induction can also be depicted by means of the data flow diagram shown in Fig. 2. In the figure, circles represent sets; they contain the name of the set and its cardinality. Beside each set, the strings belonging to that set and beginning with 02 are shown. Due to a property to be proved in Section 3.5, the complement of the strings shown in the figure belongs to the same set, too.Thick lines represent the operation of appending to each element x of a set an additional bit equal to its rightmost bit, to obtain a new element y, that is, y=x≀rb(x). Thin lines represent the operation of appending to each element x of a set an additional bit equal to the complement of its rightmost bit, to obtain a new element y, that is, y=x≀~rb(x).The strings of length l+1 belonging to Rl+1(k), 1≤k≤l will be used as a starting point to build longer strings, with at most l leading bits at the same value, by appending further bits. On the contrary, the strings belonging toQl+1 must be excluded, because they have got l+1 leading bits at the same value, and hence, already violate the requirements set forth in Section 3.1.It is possible to use the partial results presented in Section 3.2 to generate strings of length s, with at most l leading bits at the same value and at most b consecutive inner bits at the same value, assuming that b>l. The case b≤l is not of practical interest because it would make the assumption l+t≤b, set forth in Section 3.1, impossible to satisfy.The set denoted by Bs,l,b(k) will be formally defined as the set of strings of length s>l, which have got:•at most l leading bits at the same value, andat most b consecutive inner bits at the same value, andexactly 1≤k≤b trailing bits at the same value.As before, we denote byQs,l,bthe set of “invalid” strings, that is, strings of length s which do not satisfy the property set forth for any of the Bs,l,b(k) for the same s, that is, strings that have got either:•more than l leading bits at the same value, ormore than b consecutive inner bits at the same value.As for Rs(k) andQs, set generation is performed in an inductive way.The base case of the generation are the strings of length s=l+1 belonging to Rl+1(k), 1≤k≤l. Consistently with the hypothesis b≥l, we will let:(21)Bl+1,l,bk=Rl+1k,1≤k≤lBl+1,l,bk=∅,l+1≤k≤b.According to the definition ofQl+1,l,b, we can also let:(22)Ql+1,l,b=Ql+1.For s≥l+2, the induction proceeds according to the following formulae. First of all, it is:(23)Bs,l,b1=x≀∼rbxx∈Bs−1,l,bk,1≤k≤b,because it is possible to build a string of length s that has no more than 1 trailing bit at the same value, by taking a string of length s−1 that has no more than 1≤k≤b trailing bits at the same value, and appending one more bit that is the complement of the rightmost one. This operation preserves the property that no strings generated in this way have either more than l leading bits at the same value or more than b consecutive inner bits at the same value.Secondly, it is:(24)Bs,l,bk=x≀rbxx∈Bs−1,l,bk−1,2≤k≤b,because, by taking a string of length s−1 with up to b consecutive inner bits at the same value, as well as k−1 trailing bits at the same value, and appending one more bit at the same value as the rightmost one, a string of length s is obtained. That string has k trailing bits at the same value and, provided that k≤b, it still has no more than b consecutive inner bits at the same value.Finally, we can also write:(25)Qs,l,b=x≀02x∈Qs−1,l,b∪x≀12x∈Qs−1,l,b∪x≀rbxx∈Bs−1,l,bb,because an “invalid” string of length s can be obtained in two different ways:1.By taking a string of length s−1 that already violates the requirement and appending one more bit, at any value. This case corresponds to the first two terms of Eq. (25).By taking a string of length s−1 that satisfies the requirement, but has exactly b trailing bits at the same value, and adding one more bit at that same value to obtain a string with b+1 trailing bits at the same value. This case corresponds to the last term of Eq. (25).Also in this case, it is worth remarking that the sets Bs,l,b(k), 1≤k≤b andQs,l,bfor a given s coverUs, that is,(26)∪k=1bBs,l,bk∪Qs,l,b=Us.Denoting by Bs,l,b(k) the number of elements of Bs,l,b(k) and referring to Eq. (23), taking into account that the sets Bs−1,l,b(k), 1≤k≤b are all disjoint, it is:(27)Bs,l,b1=∑k=1bBs−1,l,bk.Then, from Eq. (24), it is:(28)Bs,l,bk=Bs−1,l,bk−1,2≤k≤b.Finally, from Eq. (25) we obtain that the number of elements ofQs,l,b, denoted by Qs,l,bis given by:(29)Qs,l,b=2Qs−1,l,b+Bs−1,l,bb,in which the factor 2 comes from the fact that a string belonging to Qs,l,bcan be obtained from an element of Qs–1,l,bby appending a bit at any value, that is, either 02 or 12.By applying Eq. (28) repeatedly, it is:(30)Bs,l,bk=Bs−k−1,l,b1,s≥l+k.Substituting Eq. (30) back into Eq. (27) we can write, for s≥l+b+1,(31)Bs,l,b1=∑k=1bBs−k,l,b1.This formula shows that Bs,l,b(1) can be calculated by means of a generalized Fibonacci sequence of order b. Due to Eq. (30), this property is also valid for Bs,l,b(k), 1≤k≤b when s≥l+k.The construction process of Bs,l,b(k) andQs,l,bfor a case of interest is depicted in Fig. 3. The notation is the same as in Fig. 2, with a double, thin line denoting the operation of appending a bit at any value. To avoid cluttering the figure, only one exemplar string is shown for each set.The last step of the construction of the codebookGs,l,b,tconsists of taking into account the requirement about the maximum number of trailing bits at the same value, which shall be no more than t, with t≤b. This is quite simple because Bs,l,b(k) satisfies all the requirements on s, l, and b and, moreover, contains strings with exactly k trailing bits at the same value.We can therefore write:(32)Gs,l,b,t=∪k=1tBs,l,bk,s≥l+1.By recalling again that all the sets Bs,l,b(k) are all disjoint for a fixed s, it is:(33)Gs,l,b,t=∑k=1tBs,l,bk.Moreover, it is easy to show that, in the corner case s=l, a suitable choice forGl,l,b,t, analogous to Eq. (32), is:(34)Gl,l,b,t=∪k=1minl−1,tRlk.LetGs−1,l,b,t⁎ be the set of strings obtained fromGs,l,b,tby deleting the rightmost bit of its elements. By construction, all the elements ofGs−1,l,b,t⁎ are of length s−1. It can be proved that:(35)Gs−1,l,b,t⊆Gs−1,l,b,t*,s>l+1,which, informally speaking, means that for fixed l, b, and t, the codebooksGs,l,b,tobtained by varying s are all nested into each other.From the implementation point of view, this is very useful because, although all the codebooksGs,l,b,tfor s=2,…, smare needed in a certain application, onlyGsm,l,b,tmust be stored explicitly, because all the smaller codebooks can be obtained from a subset of the biggest one by deleting some of the rightmost bits of its elements.From Eq. (32), since we assume that t≤b, we can write:(36)Gs−1,l,b,t=∪k=1tBs−1,l,bk⊆∪k=1bBs−1,l,bk.From Eq. (23), defining Bs−1,l,b⁎(1) as the set of strings obtained from Bs,l,b,t(1) by removing the rightmost bit of its elements, we can also write:(37)Bs−1,l,b*1=x,x∈Bs−1,l,bk,1≤k≤b,and therefore:(38)Bs−1,l,b*1=∪k=1bBs−1,l,bk.Substituting Eq. (38) back into Eq. (36) we obtain:(39)Gs−1,l,b,t⊆Bs−1,l,b*1.From Eq. (32), being t≥1, it is:(40)Bs,l,b1⊆Gs,l,b,t.Remembering the definition ofGs−1,l,b,t⁎ and Bs−1,l,b⁎(1), this implies:(41)Bs−1,l,b*1⊆Gs−1,l,b,t*.At this point, we obtain Eq. (35) by combining Eqs. (39) and (41). The same nesting property can also be stated in a different way by observing that, due to Eqs. (23) and (32), we can write:(42)x∈Gs,l,b,t⇒x≀∼rbx∈Gs+1,l,b,t,and therefore, by induction:(43)x∈Gs,l,b,t⇒x≀abp∼rbx,s′−s∈Gs′,l,b,t,s′>s,where abp(b, l) is an alternating bit pattern of length l starting with bit b. This alternate formulation will be especially important to reduce the footprint of the reverse lookup table used by the decoder module, to be discussed in Section 4.2.Further codebook storage savings can be achieved by observing that, due to howGs,l,b,thas been defined:(44)g∈Gs,l,b,t⇔∼g∈Gs,l,b,t.Informally speaking, if g belongs toGs,l,b,t, then its one's complement ~g also belongs to the same codebook. It is therefore possible to define a reduced codebookGs,l,b,t+ containing only half of the codewords ofGs,l,b,t, namely, the ones beginning with zero. The amount of storage required forGs,l,b,t+ with respect toGs,l,b,t, in bits, is considerably reduced because:•it contains only half of the entries, andthe leftmost bit of all entries is always zero, and hence, it is unnecessary to store it explicitly.At the same time, it is still possible to calculate the elements of the full codebook from the reduced ones by means of simple and efficient binary operations.Due to Eqs. (6), (7), (21), (23), (24), and (32), the elements ofQ1 become the leftmost bit of any codeword inGs,l,b,t. It is therefore possible to buildGs,l,b,t+ by using the same process (base case and induction) discussed before, but starting fromQ1+={02} instead ofQ1.The implementation activity to be discussed in this paper concerns two complementary software modules, with very different goals and requirements, namely:1.Codebook generator. This module is executed offline, once and for all. For this reason, the focus during software development shall be on correctness, rather than performance. It generates the codebooks Gs,l,b,t, 2≤s≤sm, in a format suitable to be used by the other modules and as compact as possible to reduce their memory footprint.Encoder and decoder. The purpose of this module is to encode the data stream before transmitting it on the channel and, symmetrically, decode the data stream coming from the channel before handing it to the upper layers of the protocol stack. Since it resides in the critical path of the protocol stack, its efficiency is of paramount practical importance.The codebook generator was implemented in ISO Prolog[15] for the SWI Prolog system [16]. The choice of a logic programming language instead of a more traditional one stems from the fact that logic languages in general, and Prolog in particular, directly support the inductive definition of sets. Hence, the program is very concise and its statements closely resemble the mathematical definitions given in Section 3. In turn, this greatly reduces the likelihood of programming mistakes.Listing 1. Prolog definition of Rs(k) and Qs.For instance, the generation of the sets Rs(k) and Qsdefined in Section 3.2 has been programmed as shown in Listing 1. The functors rb(X, Y), neg(X, Y), and app(X, R, Y) correspond to y=rb(x), y=~x, and y=x≀r, respectively. Their definition consists of a few lines of Prolog code and is not further discussed for conciseness. Bit strings are modeled as lists.The base case for the definition of Qsis given at lines 1–2. The two facts concerning the functor in_qs correspond to Eq. (5) and assert the initial contents of Q1. Then, lines 4–6 give the inductive construction of Qsfor s≥2 in terms of Qs−1, as defined in Eq. (8). The inductive construction of Rs(1) is slightly more complex because, as defined in Eq. (6), it entails the enumeration of all elements belonging to Rs−1(k) for 1≤k≤s−2. This is performed by the helper functor in_rs_anyk and its iterator in_rs_anyk_iter at lines 8–16. The inductive construction itself is performed by the two induction rules found at lines 18–24. Finally, the inductive construction of Rs(k) for 2≤k≤s−1, which corresponds to Eq. (7) is given at lines 26–29.With those definitions, the whole set of codewords belonging, for instance, to R4(2) can easily be found with the querybag of (CW, in_rsk(4, 2, CW), CB).The result is bound to variable CB:CB=[[0,1,0,0],[1,0,1,1],[0,0,1,1],[1,1,0,0]].All the other sets presented in Sections 3.3 and 3.4 have been defined in a very similar way and are not shown here for conciseness. It should be noted that, as discussed in Section 3.5, the code shown in Listing 1 can be used to generate either the full codebooks or the reduced ones, by including or excluding line 2, respectively. No modifications to any other part of the code are necessary to this purpose.The codebook generator output can be used for a variety of purposes. First of all, the quantities Gs,l,b,tprovide a mean to evaluate and compare the efficiency of different codebooks for different parameter values. In fact, a codebook composed of Gs,l,b,tstrings of length s is able to encode any string of length(45)s′=log2Gs,l,b,t.The efficiency of the codebook is then given by its information rate R, that is, the ratio(46)R=s′s=1slog2Gs,l,b,t.Fig. 4shows the information rate of the codebooksGs,1,4,3 andGs,2,4,2 as a function of s. Although they both satisfy the requirements needed to prevent CAN bit stuffing, as discussed in Section 2,Gs,2,4,2 has a better efficiency for some values of s, namely, for 5≤s≤9. Another interesting information that can be inferred from Fig. 4 is thatG9,2,4,2 has the best efficiency for any value of s≤18. The result highlights that for a memoryless block encoder for CAN,G9,2,4,2 is the best choice.In order to achieve a better efficiency, it would in fact be necessary to adopt a codebook with s>18. However, in this case, the footprint of the encoding and decoding lookup tables – which is proportional to the codebook size – would be too large, at least for a small embedded system.Moreover, the codebook generator output has also been used to check which codebooks of the formGs,2,4,2 satisfy property (2) and, as a consequence, determine the value of smdiscussed in Section 3.1. Fig. 5compares the two sides of Eq. (2) and shows that, in the case being considered, sm=9. In other words, any codebookGs,2,4,2 with s≤smhas enough elements to encode any string of length s−1, but this property no longer holds for any s>sm.Last, but not least, the codebook generator has been used as the starting point to build the forward and reverse lookup tables for the encoder and decoder module, to be discussed in Section 4.2. As an example, Table 1shows the codebooksGs,2,4,2+, 2≤s≤9, highlighting the nesting property presented in Section 3.5. Defining the inference rules in the right order within the Prolog code – namely, assuring that the inference rule corresponding to Eq. (23) comes before the one corresponding to Eq. (24) – ensures that, when the largest codebookG9,2,4,2+ is being generated, the codebook entries corresponding to the nested, smaller codebooks, are generated first, as shown in the table.Besides dealing with payload encoding and decoding, with the help of the codebook presented in Section 4.1, the actual encoder and decoder software modules must also take care of other important low-level details—for instance, format the encoded message as a whole in a proper way and prevent other parts of the message, namely the header, from injecting part of a primer sequence into the payload. Both goals must be accomplished in an efficient way, where efficiency has got two different, and possibly conflicting, meanings:•space efficiency, to make the best possible use of the limited payload carrying capabilities of CAN;time efficiency, because the encoding and decoding processes must be as fast as possible.For what concerns the break bit (BB), a simple optimization consists of including it only when necessary, that is, when the DLC in the transmitted frame is equal to 7, 8, or 3. In the former two cases it is easy to see that the corresponding DLC bit patterns (01112 and 10002) include 3 bits at the same value at their end. In the absence of BB, it would no longer be ensured that no stuff bit may appear when a codeword is appended. The latter case (00112) leads to the same issue when a stuff bit (at 12) is inserted just after the two initial bits at 02 because the part of header that precedes the DLC ends with 0002.Another drawback of 8B9B is that part of the data field is actually wasted. In fact, the encoded payload is typically not aligned on a byte boundary, because it is made up of an integral number of 9-bit codewords, and must be properly padded at the end. The VHCC encoding scheme overcomes this limitation. In fact, instead of filling the PAD field using a fixed alternating bit pattern – just to prevent bit stuffing – it is now possible to leverage it suitably in order to pack further information. If the PAD field is made up of s bits, the codebookGs,2,4,2+ discussed in Section 3 can be used to efficiently store s−1 bits of additional data. For instance, when the PAD is 7-bit long (as happens when the original payload takes one whole byte and DLC equals 2), it is possible to accommodate a further piece of information comprising up to 6 data bits. This means, 14 bits can be encoded in this case with VHCC versus the 8 bits allowed in 8B9B.In practice, an additional parameter PS (PAD selector) expressed on one byte is provided to the encoding function – besides the original payload – which is used for determining the content of the PAD field (the old name has been retained for simplicity, in spite of the fact its meaning has actually changed). Basically, after all the bytes of the original payload have been converted to the related codewords, one additional translation is carried out using the least significant part of PS. For obvious reasons, not every bit of this byte will be encoded (see Table 2for details). In the case no additional information is available, the user has to provide a dummy value for PS nonetheless, which will never be used on the receiver side. The contents of PS will be encoded anyway, and hence, the PAD field will be set to a value that prevents primer sequences in the data field, as happened in 8B9B with the original, alternating bit pattern.The additional byte PS introduced above can be seen as part of an “extended” payload and appended at byte position n+1. In the following, the notation n.m will be used to denote the size of such a payload, made up of n bytes (base size) and m bits (additional information). In Table 2, details about the enhancements achieved by the VHCC encoding scheme are shown. Particularly, for every DLC value, the maximum size allowed for the payload is reported (expressed as n.m), as well as the presence (and value) of BB. It is worth noting that, in the original 8B9B, encoded frames with a DLC value equal to 1 were forbidden. Instead, in VHCC, this case is permitted and can be used to achieve sub-byte information encoding (up to 7 bits).The approach defined above could be profitably adopted, for instance, when the payload is obtained by collecting together several signals defined at the application level (as for PDO mapping in CANopen) or when information is encoded on more bits than strictly necessary (this happens, e.g., if a small set of enumerated values takes one whole byte, as in the case of the state information found in some NMT messages of CANopen). In these cases, the payload (as seen by the application) is best described as a sequence of bits, instead of bytes—indeed, the requirement that the payload takes an integral number of bytes depends basically on CAN.In Fig. 6, the duration (in bit times) of the data field in the frame sent over the bus is shown for plain CAN and VHCC for different sizes of the payload (also expressed in bits). The other fields of the CAN frame were not taken into account explicitly, because either BS cannot be prevented (CRC), it does not apply (unstuffed trailer part), or it can be tackled by means of a careful selection of the message parameters (i.e., the identifier). It is worth noting that the actual duration in CAN is not fixed, because of the stuff bits possibly added by the CAN controller. In the worst case, up to 2 bits may be added to every original byte. As a consequence, two plots labeled “CAN (min)” and “CAN (max)” were added to Fig. 6, which correspond to the best and worst cases, respectively.It can be seen that, overall, VHCC is often quite close to the best case in CAN, and rarely it happens to be (slightly) worse. The major advantage with respect to plain CAN is the noticeably lower transmission jitter, especially when the payload is large. More specifically, the residual jitter only comes from the CRC field.From the implementation point of view, Table 2 includes two borderline cases:1.The first row of the table corresponds to a completely empty payload (payload size 0.0). To streamline the encoding software, it is assumed that this case – usually related to peculiar classes of messages – will be handled specially in the application layer, so that the encoder will never encounter it.In the penultimate row of the table (payload size 6.1), there is only one PAD bit available. In order to ensure that the payload still ends with no more than 2 bits at the same value – and preserve one of the basic code properties – it would be necessary to set the PAD bit to the complement of the last bit of the last codeword. However, since the proposed scheme does not handle CRC jitter in any way, a more efficient implementation has been obtained by simply using that bit to transfer one more payload bit. It is, in fact, possible to design the encoding and decoding algorithms so that they gracefully fall back to this behavior when executed with a one-bit input and one-bit output. As a side effect, we accept that up to 3 bits at the same value may appear at the end of the payload.However, this choice also explains the apparent anomaly of Table 2, in which the PAD size is always 1 bit more than m (the additional information part of the payload), whereas in this case it is not.The most critical part of the implementation, regarding performance, is how to individually encode and decode each byte of the payload, as well as PS. To attain maximum efficiency, this is performed by means of two lookup tables:1.Forward lookup table. The first 27 entries of the reduced codebook shown in Table 1 embody the forward lookup table of the encoder forG9,2,4,2+. The 8-bit word w to be encoded shall first of all be reduced, by masking off its most significant bit, and then used as an index in the table. The contents of the table will then be either used directly as a codeword, or complemented, depending on whether the most significant bit of w was 02 or 12.The table will be only 8-bit wide instead of 9 when stored in memory, because the leftmost bit is zero in all its entries and it is therefore unnecessary to store it explicitly.To encode a word w according to the smaller codebooksGs,2,4,2+, with 2≤s<9, due to the codebook nesting property, w itself can still be used as an index in the forward lookup table as discussed before. Then, the codeword derived from the table must be shifted/masked to extract its s most significant bits.Reverse lookup table.Table 1 can be used to generate the reverse lookup table forG9,2,4,2+, by inverting it. Namely, if the forward lookup table contains codeword g at index w, with 0≤w<27, the reverse lookup table will contain the value w at index g. Reduced codewords g are 8-bit wide, while w is 7-bit wide, and hence, the reverse lookup table must have 28 7-bit entries.Since only 27 reduced codewords exist, not all entries of the reverse lookup table will be filled in this way. The remaining entries correspond to invalid bit patterns, which are not valid encoder outputs.Due to property (43), the same reverse lookup table can also be used when smaller codebooksGs,2,4,2, 2≤s<9 are needed. In this case, the encoded bit pattern must be padded to the right with an alternating bit pattern, beginning with the complement of its least significant bit, before being used as an index in the reverse lookup table ofG9,2,4,2+. The length of the alternating bit pattern must be chosen to bring the total width of the index to 8 bits.Fig. 7fully describes how the reverse lookup table is handled to decode a single codeword of any size, since this is the most complex operation to be performed. This procedure is used to handle both the 9-bit codewords coming from byte-by-byte payload encoding, as well as the smaller codeword coming from PS encoding.In the flowchart, the function bit(g, p) extracts bit number p from word g. Bits are numbered from zero starting with the least significant bit. Function neg(g, n) returns the complement of the n least significant bits of g. Both functions are straightforward to express in any high-level programming language and are amenable to a very efficient machine-language translation on most modern processor architectures.•The procedure starts with an s-bit pattern g extracted from the CAN message payload. The value of g ranges from 0 to 2s−1, inclusive.The most significant bit of g, called gm, is used to reduce the range of g in preparation to the reverse lookup table access. In particular, if gm=1, g is complemented to make sure that its range is from 0 and 2s−1−1, inclusive.If necessary, g is extended to the right with an alternating bit pattern, in order to make it 8-bit wide. The correct bit pattern to be used (out of the two possible ones) depends on the least significant bit of g before extension, called gl. In the flowchart, both bit patterns are stored in the 2-element array abp[] and glis used as an index into it. However, for efficiency, in the actual implementation they are specified as constants in the code.The reduced reverse lookup table rlt[] is accessed to get the decoded value. Depending on the value of gm, the decoded value is either the value found in the table or its complement.At the end of the procedure, f contains the decoded value in its s−1 least significant bits.The additional consistency checks involving invalid bit patterns are not shown in Fig. 7 for clarity. In addition, when s=9, the operations specified in the gray blocks can be skipped for efficiency.

@&#CONCLUSIONS@&#
