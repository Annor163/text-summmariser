@&#MAIN-TITLE@&#
Dynamic multi-swarm particle swarm optimizer with cooperative learning strategy

@&#HIGHLIGHTS@&#
A new cooperative learning strategy is hybridized with DMS-PSO.Information can be exchanged among sub-swarms before the regrouping process.Experimental results show that DMS-PSO-CLS has a superior performance.

@&#KEYPHRASES@&#
Particle swarm optimizer,Dynamic multi-swarm particle swarm optimizer,Cooperative learning strategy,

@&#ABSTRACT@&#
In this article, the dynamic multi-swarm particle swarm optimizer (DMS-PSO) and a new cooperative learning strategy (CLS) are hybridized to obtain DMS-PSO-CLS. DMS-PSO is a recently developed multi-swarm optimization algorithm and has strong exploration ability for the use of a novel randomly regrouping schedule. However, the frequently regrouping operation of DMS-PSO results in the deficiency of the exploitation ability. In order to achieve a good balance between the exploration and exploitation abilities, the cooperative learning strategy is hybridized to DMS-PSO, which makes information be used more effectively to generate better quality solutions. In the proposed strategy, for each sub-swarm, each dimension of the two worst particles learns from the better particle of two randomly selected sub-swarms using tournament selection strategy, so that particles can have more excellent exemplars to learn and can find the global optimum more easily. Experiments are conducted on some well-known benchmarks and the results show that DMS-PSO-CLS has a superior performance in comparison with DMS-PSO and several other popular PSO variants.

@&#INTRODUCTION@&#
Particle swarm optimization (PSO) is a population based stochastic optimization algorithm which was originally introduced by Kennedy and Eberhart [1,2]. This algorithm is motivated by the emergent motion of the foraging behavior of a flock of birds. PSO consists of a swarm of particles. Each particle represents a potential solution, which is a point in the multi-dimensional search space. The global optimum of PSO is regarded as the location of food. Each particle has a fitness value and a velocity to adjust its flying direction according to the experiences of the particle itself and its neighbors. PSO is simple in implementation and has good convergence properties when compared to evolutionary algorithms [3]. The advantages of PSO have encouraged PSO to become one of the most population optimization techniques. Now, PSO has been successfully extended to many application areas such as function optimization [4], artificial neural network training [5–7], fuzzy system control [8–11], power system [12,13] and image processing [14].Although PSO is considered to be a robust algorithm and results in a fast convergence rate in many applications, it suffers from the premature convergence problem. PSO can be easily trapped into local optima when solving multimodal problems with a huge number of local minima. In the original PSO, the algorithm exhibits a fast-converging behavior, since all particles learn from the global best particle when updating velocities and positions. But the global best particle located at a local optimum may trap the whole swarm and lead to premature convergence [15]. For this reason, the balance between exploration (global investigation of the search place) and exploitation (the fine search around a local optimum) throughout the course of a run is a challenge to the success of PSO algorithms, especially for complex multimodal problems. In order to deal with this problem, a number of PSO variants have been developed. These approaches include tuning the control parameters such as inertia weights, social learning coefficients [16–19], designing different neighborhood topologies [20–22], hybridizing PSO with auxiliary search techniques [23–27].Multi-swarm technique has attracted increasing attention during the last decade [28–31]. It is one of the effective methods maintaining diversity of swarm. In [28], a MSCPSO based on four sub-swarms is presented, which exchange information among themselves to evaluate overall fitness as the basis of the fitness adaptive equation. In [29], MCPSO is presented, which is a master–slave model that consists of one master swarm and several slave swarms. The master swarm updates the particle states based on both its own experience and that of the most successful particles in the slave swarms. In [30], a multi-swarm particle swarm optimization algorithm with a center learning strategy (MPSOCL) is presented with employing a new communicational scheme that each particle within one multi-swarm updates its flying direction combining historical experience from all multi-swarms with the present center position. In [31], a chaotic multi-swarm particle swarm optimization (CMS-PSO) is proposed by modifying the generic PSO with the help of the chaotic sequence for multi-dimension unknown parameter estimation and optimization by forming multiple cooperating swarms.To consider the cooperation among sub-swarms for the multi-swarm technique, a dynamic multi-swarm particle swarm optimizer (DMS-PSO) is introduced [32]. In DMS-PSO, the whole population is divided into many small sub-swarms. These sub-swarms are regrouped frequently by using a certain regrouping schedule, and thus information can be exchanged among the sub-swarms. DMS-PSO achieves great diversity of population. However, the frequent regrouping operation results in the deficiency of exploitation. To overcome this drawback, several improvements have been made. In [33], DMS-PSO is combined with Quasi-Newton method to improve its local searching ability. In [34], the harmony search (HS) algorithm is merged into each sub-swarm of the DMS-PSO. DMS-PSO-HS can make good use of the information in past solutions more effectively. In [35], DMS-PSO is hybridized with modified multi-trajectory search (MTS) and the sub-regional HS (DMS-PSO-SHS), which makes the harmonies search in a larger potential space among different sub-populations.Although the improvements of DMS-PSO have achieved good performance through many experiments, the cooperation among sub-swarms is just confined to the regrouping operation. No matter DMS-PSO-HS or DMS-PSO-SHS, the search capability of sub-swarms is exploited more deeply. However, it is not an efficient way to make best use of the search information for the whole swarm. For example, if some of the sub-swarms are trapped into local minima, the exchanged information among them will be the local optimal information when the regrouping operation arrives. The reason is that the sub-swarms have not cooperated with each other sufficiently. Consequently, the sub-swarms with “wrong track” may go farther with not being corrected timely. The ability of the periodic regrouping operation to exchange particles’ information is constrained or inadequate. There may be a deficiency of exploration.In order to achieve a good balance between the global exploration and the local exploitation, a new cooperative learning strategy is hybridized with DMS-PSO. The new strategy is used to exchange information among sub-swarms before the regrouping operation. For each sub-swarm, each dimension of the two worst particles learns from the better particle of two randomly selected sub-swarms using tournament selection strategy. Each particle can make full use of the best information of the sub-swarms to update its position. Meanwhile, the information among sub-swarms can be exchanged further to achieve a large search space. Owing to the further communication, DMS-PSO-CLS can make better use of the beneficial information and result in a good balance between the global exploration and the local exploitation. It is expected to bring better learning efficiency to PSO and hence better global optimization performance. Its advantages will be demonstrated by comparison with traditional PSOs and other improved PSOs.The article is organized as follows. Standard PSO and the original DMS-PSO algorithm are introduced in Section 2. DMS-PSO-CLS is described in Section 3. Section 4 presents the benchmark functions used for experiments, experimental settings for each algorithm, and the experimental study. Conclusions are presented in Section 5.Potential solution of the optimization problem can be described as a point in D-dimensional space for an optimization problem has D variables to optimize. Each particle has a velocity vector to determine its direction and a fitness value to measure its corresponding optimization state. The position and velocity in D-dimensional search space are adjusted according to the current optimal particle.The process can be converted into a mathematical problem as follows. Suppose that sz particles are used to search the solution. The ith particle in D-dimensional space is represented asxi=(xi1,xi2,⋯,xid,⋯,xiD), wherexid∈[xmin,xmax], d∈[1, D]. The velocity corresponding to the ith particle isvi=(vi1,vi2,⋯,vid,⋯,viD), wherevid∈[vmin,vmax]. The velocity and location update strategy of the ith particle are given below:(1)vid←vid+c1·rand1id·(pbestid−xid)+c2·rand2id·(gbestd−xid)(2)xid=xid+vidwhere c1 and c2 are the acceleration constants. c1 represents the weight that the ith particle tracks its own historical optimum value pbesti. Figuratively speaking, it shows the understanding of itself. Similarly, c2 represents the weight that the ith particle tracks the whole group's optimum value gbest. All particles use the same values c1 and c2. pbestiand gbest are updated all the time according to each particle's fitness value.rand1idandrand2idare two random numbers in [0, 1].To control the flying velocity, an inertia weight or a constriction factor is introduced by Shi and Eberhart [16]. It is modified to be Eq. (3).(3)vid←w·vid+c1·rand1id·(pbestid−xid)+c2·rand2id·(gbestd−xid)wherewusually decreases linearly from 0.9 to 0.4 during the iterative process [36].Substantially, PSO is divided into two versions. The above formula is global PSO, another version is local PSO. For local PSO, each particle adjusts its position and velocity according to its historical best position pbestiand the best position achieved so far from its group lbesti. The velocity update strategy is described as follows:(4)vid←w·vid+c1·rand1id·(pbestid−xid)+c2·rand2id·(lbestid−xid)DMS-PSO is a local version of PSO with a new neighborhood topology. The population is divided into some small sized sub-swarms. They search for better positions in the search space using their own members. However, the sub-swarms are dynamic and they are regrouped frequently by using a regrouping schedule, which is a periodic exchange of information. Particles from different sub-swarms are regrouped to a new configuration through the random regrouping schedule. In this way, the search space of each small sub-swarm is expanded and better solutions are possible to be found by the new small sub-swarms [37].Kennedy claimed that PSO with large neighborhoods would perform better on simple problems and PSO with small neighborhoods might perform better on complex problems [38]. A very small population size (e.g., 3∼5) for DMS-PSO is enough when solving relatively complex problems, which is also one of its significant features [32].In order to illustrate the DMS-PSO algorithm deeply, detailed description is presented. Take the population size sz=9 X=(x1, x2, ⋯, xi, ⋯, x9) and divide them into three sub-swarms L=(L1, L2, L3) randomly. Then each particle works within the sub-swarm where it stays. Its position is updated through Eqs. (4) and (2). The sub-swarms may converge to a local optimum during this period. TThen the pattern is broken and sub-swarms are recombined. Based on this, particles start updating again and the process is repeated. The process mapping is shown in Fig. 1[32].The regrouping period R is a key parameter which has a great influence on the optimization results. If R is set too small, there won’t be enough number of iterations for each sub-swarm to complete an adequate search. If R is set too large, function evaluations will be wasted if the sub-swarms could not further improve. So it should neither be too small nor too large.The whole iterative process is divided into two phases. The top ninety percent of all iterations run as the above description. The process is mostly used to conduct an extensive search. The remaining percents of iterations run as the global version PSO and can be explained as a targeted search procedure. The pseudo-code of DMS-PSO has been given below in Algorithm 1.Algorithm 1The pseudo-code of DMS-PSO.Initialize:sz: size of the whole population; numregion: number of sub-swarms; R: regrouping period; iter_max: max iterations; Initialize each particle's positionxidand velocityvidand divide the particles into numregion sub-swarms;Iterate:1: foriter=1:0.9*iter_maxdo2:   Update each particle using local version PSO;3:   if mod(iter,R)=0then4:   Regroup the sub-swarms randomly;5:   end if6: end for7: foriter=0.9*iter_max:iter_maxdo8:   Update each particle using global version PSO;9: end forAlthough DMS-PSO can solve multimodal problems efficiently, there still exist some drawbacks. In DMS-PSO, each particle in a sub-swarm only learns from its pbest and lbest. Information among different sub-swarms can’t be exchanged until the population is regrouped. Due to the deficiency of cooperative learning among sub-swarms, even after the globally optimal region is found, the particles will not converge rapidly to the globally optimal solution. DMS-PSO achieves great improvement on global exploration but lacks local exploitation. Aiming at this drawback, a cooperative learning strategy is integrated with DMS-PSO, which is used to exchange information among different sub-swarms before the regrouping operation. In this strategy, for each sub-swarm, each dimension of the two worst particles learns from the better particle of two randomly selected sub-swarms using tournament selection strategy. In this way, the collaborative learning among sub-swarms is enhanced and the balance between the global exploration and the local exploitation can be achieved. The cooperative learning procedure is described as follows:(1)For each sub-swarm, we sort the fitness values of the particles and select the two worst particles to be updated.For each particle's each dimension, we select two sub-swarms randomly out of the whole groups which include the sub-swarm where the particle to be updated stays.We compare the fitness values of the two sub-swarms’ lbests and select the better one.We use the winner's lbest as the exemplar to learn from for the corresponding dimension of the particle to be updated.The above procedure is illustrated in Fig. 2. The pseudo-code of the cooperative learning strategy is given in Algorithm 2. Finally, the pseudo-code of DMS-PSO-CLS is shown in Algorithm 3.Algorithm 2The pseudo-code of the cooperative learning strategy.Sort:Sort fitness values of each group's particles; Select the worst two particleslworstik, k=1, 2 and the best one particle lbestiof each sub-swarm;Replace:1: for eachlworstikdo2:   for each dimensionallworstik(d)do3: Select two local best particles lbest1(d), lbest2(d) randomly and compare their fitness values f(lbest1(d)), f(lbest2(d));4:iff(lbest1(d))<f(lbest2(d))then5:lworstik(d)=lbest1(d);6:else7:iff(lbest1(d))>f(lbest2(d))then8:lworstik(d)=lbest2(d);9:end if10:end if11:   end for12: end forAlgorithm 3The pseudo-code of DMS-PSO-CLS.Initialize:sz: size of the whole population; numregion: number of sub-swarms; R: regrouping period; iter_max: max iterations; Initialize each particle's positionxidand velocityvidand divide the particles into numregion sub-swarms; Initialize lbestjof each sub-swarm according to its members.Iterate:1: foriter=1:0.9*iter_maxdo2:   for each particle xido3: Update each particle using Eq. (4) and Eq. (2) and revisexid,vidusingxid=min(xmax,max(xmin,xid)),vid=min(vmax,max(vmin,vid));4:   end for5:   Calculate their fitness values and update pbesti, gbest;6:   Sort fitness values of each group's particles. Select the worst two particleslworstjk, k=1, 2 and the best one particle lbestjof each sub-swarm;7:   for eachlworstjkdo8:for each dimensionallworstjk(d)do9:   Select two local best particles lbest1(d), lbest2(d) randomly and compare their fitness values f(lbest1(d)), f(lbest2(d));10:iff(lbest1(d))<f(lbest2(d))then11:lworstjk(d)=lbest1(d);12:else13:iff(lbest1(d))>f(lbest2(d))then14:lworstjk(d)=lbest2(d);15:end if16:end if17:end for18:   end for19: if mod(iter,R)=0then20:   Regroup the sub-swarms randomly;21: end if22:   Calculate their fitness values and update lbestj;23: end for24: foriter=0.9*iter_max:iter_maxdo25:   Update each particle using global version PSO where w is changed to 0.2 and other parameters remain the same as above;26: end forTo test the performance of the proposed algorithm, eighteen well-known benchmark functions in Table 1are employed. As minimization problems, they present different difficulties to the algorithms and have been widely adopted in PSO community. All the functions can be divided into three categories. The first category includes four unimodal functions. f1−f3 are relatively simple functions and easy to be solved. f4 has a narrow valley from the achieved local optima to the global optimum and it can be treated as a multimodal problem according to its character. The second category includes six complex multimodal functions. f5 has one narrow global optimum basin and many minor local optima. It is the easiest problem among the four multimodal functions as its local optima are shallow. f6 has a component causing linkages among variables, thereby making it difficult to reach the global optimum. f7 is a complex multimodal function with a large number of local optima. f8 is complex because its deep local optima are far from the global optimum, so it is hard to find the global optimum if many particles fall into one of the deep local optima. f9 is continuous but differentiable only on a set of points. f10 has two narrow valley and several local optima. The last category includes five shifted multimodal functions and three rotated multimodal functions selected from the CEC 2010 benchmark suite [39].The global optimal solution x*, the corresponding fitness value f(x*), the search range and initialization range of each function are given in Table 1.The proposed DMS-PSO-CLS algorithm and six other PSO variants are implemented in this section for comparison purpose. They are detailed in Table 2. The parameter configuration are all based on the suggestions in the corresponding references. The first two are traditional PSOs of GPSO [16] and PSO-cf [36]. The third, CLPSO, aims at offering a better performance for multimodal functions by using a CL strategy [26]. The fourth is the Standard PSO (SPSO), which is improved by using a random topology [40]. The fifth is a modified PSO with adding a mutation operator and we abbreviate it to CPSO for convenience [41]. The sixth is the DMS-PSO [32].In order to achieve a better performance for DMS-PSO-CLS,wis typically set to 0.9 (reducing the stepwise movement of each particle, allowing greater initial exploration) reducing linearly to 0.4 (speeding convergence to the global optimum) [42]. Then a greater exploration can be achieved at the beginning and later the emphasis is shifted to a greater exploitation. In DMS-PSO-CLS, each sub-swarm contains 3 individuals which is also the same setting as in the original DMS-PSO.(1) Implementation of search bounds: Search ranges ofxidandvidare important in order to prevent particles moving out of the search bounds. Suppose that the search range ofxidis [xmin, xmax]. One way is to use the equationxid=min(xmax,max(xmin,xid))to restrain a particle on the border. Another way is to calculate the fitness value of a particle before pbestiand gbest being updated and the update process is realized only if the fitness value is in the original scope. Through experiments, different from the original DMS-PSO algorithm, the former one is used here. For the range ofvid, we setvid=min(vmax,max(vmin,vid))in a similar way.(2) The selection of regrouping period R: Some explanation has been introduced above – it should neither be too small nor too large and 3–5 is enough when solving relatively complex problems. In this article, R is set at 5, which is also the same setting as in the original DMS-PSO.In this section, experiments are conducted. One group is for 10-D case, in which the maximum iteration number is set at 100,000. Another group is for 30-D case, in which the maximum iteration number is set at 200,000. The popular size is set at 30. Each function is repeated 20 times independently.(1) Results for the 10-D case: Tables 3and 4present the fitness values in terms of the best, worst, mean, standard deviation (Std) and the h-values of the nonparametric Wilcoxon rank sum tests for each algorithm with D=10. An value of one indicates that the performances of the two algorithms are statistically different with 95% certainty, whereas value of zero implies that the performances are not statistically different [26]. The best results among the seven algorithms are shown in bold. Figs. 3–5present the convergence characteristics of the best fitness value found by the seven algorithms.From these results, it is observed that it is relatively easy to locate the global optimum for unimodal functions. Therefore, DMS-PSO-CLS achieves the same highest accuracy as GPSO and SPSO. However, DMS-PSO-CLS has a large potential search space, so it could not converge as fast as them. Unfortunately, DMS-PSO-CLS doesn’t perform well on f4 which has a narrow valley.For multimodal functions, DMS-PSO-CLS surpasses all other PSOs on f9 since its best result is the most accurate. DMS-PSO-CLS achieves the same best results as GPSO and SPSO on f5 and f10. It achieves the same best result as GPSO and CLPSO on f7 and f10. DMS-PSO-CLS and SPSO have the same best results on f8 while DMS-PSO-CLS is more stable. The results of all the PSOs is not good because deep local optima of f8 are far from the global optimum, so it is hard to find the global optimum if many particles fall into one of the deep local optima. DMS-PSO performs better than DMS-PSO-CLS on f6. Since the search range of f6 is large, it is suitable for PSOs with high exploration ability. While DMS-PSO has a frequently regrouping operation, which results in a large search diversity.However, DMS-PSO-CLS performs better on the more complex shifted and rotated problems when the other PSOs all miss the global optimum basin. f13 and f18 are good examples, DMS-PSO-CLS can achieve the global optimum with a fast speed as all other algorithms trapped into local optima. DMS-PSO-CLS appears to exhibit the strongest search ability and converge to the global optimum zero in about 3×104 iterations. For f13, the other indexes of DMS-PSO-CLS are also the best, which means a stable performance is also achieved. Although CPSO has a more stable performance on f18, it never reach the global optimum. The best results of f11 is similar to f4, on which SPSO performs the best. DMS-PSO-CLS achieves the same best results as GPSO and SPSO on f12, f14 and f15. For f12 and f14, the results of DMS-PSO-CLS are more stable and can achieve the global optimum every time. DMS-PSO-CLS performs better and more stable than the others on f16 with a slight improvement and performs much better than the others on f17.(2) Results for the 30-D case: The experiments conducted on 10-D problems are repeated on the 30-D problems and the results are presented in Tables 5and 6. Figs. 6–8present the convergence characteristics of the best fitness value found by the seven algorithms. From the results, we can observe that the algorithms achieved similar ranking as in the 10-D problems. DMS-PSO-CLS surpasses all other PSOs on f5, f7, f8, f9, f13, f16 and f18 since the best results of DMS-PSO-CLS is the most accurate. DMS-PSO-CLS achieves the same best results as SPSO on f1, f2, f3, f10, f12, f15, f17 and achieves the same best results as GPSO on f1, f2, f3, f6, f10, f12, f15, f17. CLPSO also performe well on f10 and f15 as same as DMS-PSO-CLS and DMS-PSO-CLS achieves very stably results on f15. The results of f4 and f11 is similar to the 10-D case, which SPSO performs the best. All functions become more difficult than their 10-D counterparts and the results are not as good as in 10-D cases, although the maximum fitness evaluation is increased. Better results are achieved on Griewank's function, since this problem is known to become easier as the number of dimensions increased.(3) Comparison of the computational time: The computational time of the seven PSOs is presented in Table 7. The time is for ten times iteration, which is enough to compare the computational time for all the PSOs. It can be observed that the computational time of DMS-PSO-CLS is maximum. That's because the cooperative learning strategy increases the complexity of the algorithm. The information of each sub-swarm is exchanged in each iteration, so that an extra time consumption is produced.(4) Discussions: Experimental results and comparisons verify that the cooperative learning strategy indeed helps the DMS-PSO-CLS perform better than the traditional PSOs and some existing improved PSO variants. DMS-PSO-CLS offers a better performance in global optimization. Based on the analysis of the experimental results, although DMS-PSO-CLS does not perform the best for all the functions, it can achieve a good performance for most of the complex multimodal functions.The following major conclusions of DMS-PSO-CLS can be drawn as below:• DMS-PSO-CLS performs better on more complex problems (complex multimodal problems, shifted and rotated problems) while the other algorithms often miss the global optimum.• DMS-PSO-CLS's convergence speed is not so good as the other PSOs sometimes. Since the fast convergence speed results in the deficiency of search diversity, the other PSOs are easy to encounter premature convergence problem. That's why they can’t do better than DMS-PSO-CLS on some complex problems. According to the no “free lunch” theorem for optimization, “any elevated performance over one class of problems is offset by performance over another class” [26]. There is a cost for tuning the DMS-PSO-CLS to obtain better convergence precision on many multimodal problems, and the cost is the slow convergence speed.• The low standard deviation is not necessarily good. Such as the results for CPSO on f9 with D=10, which always keep the same results but not the best. The standard deviation of DMS-PSO-CLS is not always the best, but relatively small in general. In contrast, DMS-PSO-CLS can obtain a relatively stable and better result on the whole.• DMS-PSO-CLS takes merits of the DMS-PSO and the cooperative learning strategy, and improves the performance of DMS-PSO significantly. Both the convergence speed and the convergence precision are greatly improved.• The computational time of DMS-PSO-CLS is longer than others. The cooperative learning strategy increases the complexity of the algorithm. Much time is consumed on the information cooperation. This is the limitation of DMS-PSO-CLS.According to the comparison analysis above, it is obvious that DMS-PSO-CLS can keep a better diversity to develop the virgin space and has the best ability to reach the optimum. With the novel cooperative learning strategy, more information can be exchanged among the sub-swarms. Due to this, DMS-PSO-CLS not only gives the best convergence accuracy on most optimization problems when compared with other PSO versions but also achieves a high convergence speed. The relative results prove that DMS-PSO-CLS can keep a good balance between the global exploration and the local exploitation. Wholly speaking, DMS-PSO-CLS is a good method to improve the global ability of PSO.

@&#CONCLUSIONS@&#
