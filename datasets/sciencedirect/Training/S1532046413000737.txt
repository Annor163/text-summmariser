@&#MAIN-TITLE@&#
Privacy-preserving screen capture: Towards closing the loop for health IT usability

@&#HIGHLIGHTS@&#
Maximizing health IT effectiveness requires documenting and analyzing usability problems.Such logging should not violate privacy of patients and providers.Such logging can also not rely on access to software internals or structured output.We present a prototype system that solves this problem while abiding by these constraints.

@&#KEYPHRASES@&#
Health IT,Security,Privacy,Usability,Redaction,

@&#ABSTRACT@&#
As information technology permeates healthcare (particularly provider-facing systems), maximizing system effectiveness requires the ability to document and analyze tricky or troublesome usage scenarios. However, real-world health IT systems are typically replete with privacy-sensitive data regarding patients, diagnoses, clinicians, and EMR user interface details; instrumentation for screen capture (capturing and recording the scenario depicted on the screen) needs to respect these privacy constraints. Furthermore, real-world health IT systems are typically composed of modules from many sources, mission-critical and often closed-source; any instrumentation for screen capture can rely neither on access to structured output nor access to software internals.In this paper, we present a tool to help solve this problem: a system that combines keyboard video mouse (KVM) capture with automatic text redaction (and interactively selectable unredaction) to produce precise technical content that can enrich stakeholder communications and improve end-user influence on system evolution. KVM-based capture makes our system both application-independent and OS-independent because it eliminates software-interface dependencies on capture targets. Using a corpus of EMR screenshots, we present empirical measurements of redaction effectiveness and processing latency to demonstrate system performances. We discuss how these techniques can translate into instrumentation systems that improve real-world health IT deployments.

@&#INTRODUCTION@&#
Medical enterprises large and small are replacing paper-based systems with IT-based ones, and upgrading old, piecemeal IT-based systems with new, federated ones. However, as with any large engineering project, it is unlikely that the first solution produced and deployed is exactly right. Standard engineering tenets teach the importance of “closing the loop”; but to do so by understanding and tuning a system requires measuring it, in order for this tuning to be a data-driven process.However, when it comes to health IT systems, even the process of just taking such measurements raises a combination of challenges:Privacy PreservationIn a human-facing IT system, screenshots comprise the natural domain for measurement. However, in health IT, screenshots are full of privacy-sensitive material. First, we have the obvious issues: names and identifying information of patients, images of patients, text regarding diagnoses and medication and other treatments. But there are more subtle issues as well, such as names of providers, details of health IT user interfaces protected by vendor agreements, and non-text indicators (such as “warning” icons) that can betray confidential patient details.A measurement methodology needs to respect these privacy constraints—either by putting cumbersome mechanisms in place to ensure that private data is never leaked throughout the analysis process, or by redacting it in the first place.Traditional work on privacy and confidentiality seeks to hide information. However, to fulfill their purpose of tuning and analysis, redacted health IT screenshots still need to contain information—a blacked-out screen would preserve all privacy, but be useless. We need to balance hiding of privacy-protected information with communication of workflow process context. Our redaction system needs to be effective both at removing sensitive information, but also at retaining (in conjunction with end-user feedback) the system behavior information we were trying to measure in the first place.Medical enterprises deploy IT in order to further their medical mission, within the constraints of various business objectives.A measurement methodology needs to respect these deployment constraints—it cannot make assumptions about underlying applications, operating systems, access to source code, access to structured protocol communications, even access to documentation. Furthermore, a measurement methodology cannot disrupt the underlying system; besides impeding enterprise mission, changes might also (depending on the system) invalidate necessary certification.For clinicians using health IT systems, the primary motivation is helping patients rather than wrestling with computing systems, even to document troublesome scenarios in order to enable these systems to be fixed. Consequently, a measurement methodology needs to minimize the work required and delay experienced by these users: it should work automatically and quickly; users should be able to quickly log some issue and move on with their real mission.This Paper. This paper reports on our research addressing this aspect of “closing the loop”: designing, prototyping, and evaluating technology to enable redaction of privacy-sensitive elements in medical IT (privacy preservation), while preserving usage context and permitting interactively selected unredaction (context preservation), passively acting on raw screen data alone (system impact), and operating automatically in real time (workflow impact). Drawing on algorithmic techniques that have been used for various aspects of image processing, our work is, to the best of our knowledge, the first to explore these techniques in the context of automatic redaction of privacy information in health IT (or other domains).Section 2 motivates this work in the context of closing the loop for health IT usability research and development. Section 3 provides an overview of our prototype system. Section 4 describes our methodologies for text redaction. Section 5 describes the broader system we built around these techniques. Section 6 evaluates the effectiveness of our approaches. Section 7 presents how this work can impact real-world health IT systems. Section 8 reviews related work, and Section 9 concludes.In concurrent work [1], our lab has been cataloging many ways in which clinicians report that health IT systems lead to usability frustration. We list just a few examples:•The age field for a patient does not allow fine enough units to correctly determine medication for newborns—or allow a way to indicate age of patients still in utero.A health IT screen with field-defined data did not allow an experienced clinician to record “smell of breath.”A drop-down menu did not permit easy discovery of the proper diagnosis, leading the clinician to pick a wrong one that was at least “close.”The interface to refer a patient to a stomach cancer specialist requires the non-specialist clinician to first identify which of 52 varieties of stomach cancer the patient has.A health IT system gives each pending lab result an identical title, “Lab Result.”A medication administration system does not recognize that an order for “10mgs” of a medication can be fulfilled by two 5mg tablets.An EMR screen gives three ways to exit—whose consequences differ substantially but which appear the same to the user.Each such scenario demonstrates the need for “closing the loop.” The very existence of this litany of problems indicates that the learned experts who built these health IT systems, even with the best of foresight and stakeholder input, fail to anticipate usability problems that arise in the field. Furthermore, each such problem is likely solvable. For some; small software changes likely suffice; others may require experimental evaluation of proposed solutions or research into new techniques.However, before developers can try these small changes or external researchers can explore new techniques, they need to know about these problems. Unfortunately, current state of the art does not permit the frustrated health IT user to easily capture and document these problems. Photographing or printing the screens violates privacy (both of patients and of providers). Instrumenting the internals of the health IT software requires access to code that is usually proprietary—and then requires modifying mission-critical systems. Often, researchers (such as the first author) cannot even look at usage logs of the system, due to restrictions of the university IRB. Just recording oral complaints does not permit easy reproduction of scenarios—and (as the second author found) other clinicians at the same institution may even disbelieve the scenario ever even existed.A system such as ours—which empowers end-users to record and annotate screenshots automatically redacted of sensitive information without changing the internals of the health IT system being passively monitored—would provide a key component in a solution to systematically alleviate these usability frustrations. We revisit this vision in Section 7.2.Again, in this work we explore a core problem in closing the loop: screencapture of health IT meeting the privacy and logistical requirements outlined in Section 1. Our prototype system applies text and image redaction to KVM feeds from health IT systems—see Fig. 1.Our system includes functionality essential to implementing screen capture for sensitive health IT systems. The basic steps of instrumenting such systems include screen capture, image processing and editing, and data sharing. After capture, the system processes an image to find and redact text. Additionally, the system may search for regions within the image that match a set of image snippets or “templates” and count, redact, or unredact matching regions. Finally, a user may wish to edit the image and further redact or unredact a portion of the processed screenshot.Implementation. The bulk of our system implementation relies on a mixture of C and C++ code spanning multiple open-source libraries and custom-developed libraries and applications, including boost [2], C++ STL [3], OpenCV [4], liblinear [5], and CGAL [6–8]. Altogether, we implemented approximately 9000 lines of code.To remain system-independent, we implemented certain functionality with higher-level APIs; our development environment is a MacBook Pro running OS X 10.5 with 8GB of memory.2We upgraded to OS X 10.6 midway through development and analysis.2Certain low-level OpenCV routines rely on system libraries, but these are transparent to our code—OpenCV is cross-platform.Screen Capture. Our system relies on a virtual network computer (VNC) arrangement to capture screen material from a remote host [9]. In a nutshell, VNC defines a protocol for transporting a computer’s framebuffer, keyboard, and mouse data over the network. By building a system with this protocol, our system can capture and operate on all KVM events in a system-independent fashion. In our test configuration, Mac OS X 10.6 functions as the “Capture System” and the application x11vnc [10] running on an Ubuntu Linux 9.10 running within a VMware [11] instance serves as the “Capture Target.” The client implements read-only functionality and therefore does not pass keyboard/mouse events from the VNC client to the VNC server.Our client connects to the VNC server using TCP. After connecting, the endpoints proceed through a handshake phase and negotiate the protocol version “RFB 003.008⧹n” and the “raw” pixel format to transfer screen updates from the server to the client without compression.Text redaction is a fundamental aspect of the system because it removes sensitive text from screen capture data, relieving the end-user from manually redacting screen captures before sharing. By default, our approach implemented a “deny-all” policy and thus redacts all text it finds. An end-user can then “unredact” small regions as necessary to facilitate their conversation. Because redaction affects just text and a small number of icons, our intention is that overall screen context remains despite removal of potentially sensitive data.In a different approach to redaction, our system could simply redact an entire screen (e.g., turn the entire screen black) and the end-user could unredact whichever small piece supports their needs. We believe this approach provides too little screen context to observers, and would require too much work from end-users. Unredacted, unsensitive screen data provides context to application stakeholders that may help focus their discussion.Image-based text redaction consists of two principal steps: (a) finding text in an image (also known as text segmentation), and then (b) recoloring segmented image regions to “remove” text. (We note that such segmentation is also the first step of optical character recognition—OCR.) Redacting images using this approach ensures that no “hidden” text or other data exists within the final redacted product (as often plagues redaction in standard office document formats).For automatic text redaction, we explored two approaches: Canny Edge Detection [12], which aims to bound text with boxes, and Gabor-wavelet filtering [13], which aims to classify individual pixels as “text” or “non-text.” For Gabor, we looked at both unsupervised classification and supervised classification [14]. (Table 2, at the end of our discussion, summarizes these techniques.)In order to be legible, screenshot text exists with an intensity contrast in relation to its background and thus creates gradient high points. The Canny approach analyzes an image’s intensity gradient and marks edges at gradient high points—thus (in theory) segmenting screenshot text.First, we convert a color screenshot to 8-bit gray scale. We then apply a Gaussian blur using a 3×3 window to reduce image noise—Canny output qualitatively contained less noise with this initial blurring step. Next, we executed Canny using low and high threshold values of 100 and 300 respectively to find edges—the values provide qualitatively-reasonable redaction results for a variety of desktop screenshots. Gradient magnitudes greater than the high threshold are considered edges and traced throughout the image. Values above the low threshold denote edges that branch from an existing trace process. Together, these tunable values reduce noise during edge detection. After executing the Canny algorithm, we find connected components (polygons) using Canny output and an algorithm suitable for doing so [15]. For each polygon discovered, we compute a bounding rectangle and draw a filled version of the rectangle into an image “redaction mask.” Finally, we apply the redaction mask to the original image to produce a redacted image.Fig. 2–4show examples from our prototype. Unfortunately, standard practice in commercial health IT prevents customers from disclosing user interface details (e.g., [16]), so we cannot show the original screenshots used in our experiments, but rather use a representative open-source one. In terms of complexity, this sample would fall at the minimum of our test corpus (Section 6)—e.g., at the bottom left of Fig. 9a.In general, a wavelet is a wave with some orientation and frequency that, when convolved with an image, resonates and creates a detectable signal. Gabor wavelets, which are commonly used in image processing, are comprised of a sine wave modulated by a Gaussian envelope; for our application, they use a two-dimensional envelope. Both real and imaginary components comprise the wavelet, but we follow the model of Jain and Bhattarchee [14] and only use the real, symmetric (cosine) component. When an individual filter is convolved with an image, our system extrapolates border pixels to increase the image size and prevent the filter from “falling off” the image edge (other extrapolation approaches failed in our experiments).Using a bank of filters enables detection of image features of different frequencies and orientations. In the wavelets we used in our application, we considered five standard deviations of the Gaussian (again following Jain and Bhattarchee). This left us two tunable parameters for wavelet functions: wavelength (λ) and orientation (θ). For orientation, we followed Jain and Bhattarchee and choseθ∈{0.0,45.0,90.0,135.0}to detect signals oriented in a uniform variety of positions. For wavelength, we chose powers of twoλ∈{.5,1.0,2.0,4.0,8.0,16.0,32.0}.in order to span a collection of feature sizes. When we ran this on a collection of our screenshot, we found it was effective at detecting the relevant features.Feature Vectors. We apply a Gabor wavelet filter by first convolving the image with this wavelet function.If we have a bank of n filters, we then have n filtered images, yielding (after thresholding) an n-dimensional vector for each pixel in the image. We then append each pixel’s x and y position to each vector, and shift each vector to zero mean and unit standard deviation. Thus, applying a bank of n filters yields an n+2-dimensional feature vector for each pixel.Once we have used our bank of Gabor filters to turn each pixel into a feature vector, we then need to determine which vectors represent text pixels and which represent non-text.Unsupervised Classification. In our first approach, we use the k-means algorithm [17] to cluster features into k classes, where k∈{2,3}. The algorithm assigns each pixel a class label i∈[0,k−1], where one class may correspond to text if text exists. Jain and Bhatterjee [14] clustered into three classes for text analysis; we started with that, but found that some screenshots clustered better visually into k=2 classes.During k-means clustering, the system relied on stopping conditions of the first of 10,000 iterations or an error rate of .0001. We chose the initial cluster centers using a more recent technique [18] and ran the algorithm one time to the stopping conditions before assigning labels. After running k-means, the label i corresponding to text must be chosen manually. The designated “text” pixels form a mask that redacts text when combined with the original image.Supervised Classification. The downside to unsupervised classification is multi-fold: k and i are chosen manually; the approach classifies pixels into k clusters whether or not text exists; and k-means clustering can be slow (particularly with a feature count easily surpassing one million with modern screen resolutions).To address these issues, we also tried supervised classification. Instead of using k-means, we feed each feature vector to a trained classifier that labels the pixel as “text” or “not text.” All pixels labeled as “text” are converted to the color black; all other pixels maintain their values.We chose a linear support vector machine (SVM) to label pixels as members of classes {−1,1}.We experimented with two classifiers: (a) L1-regularized L2-loss support vector classification and (b) L1-regularized logistic regression. We chose these classifiers because after training, they can contain a 0-valued parameter for each feature that remained unused during the training process. Such features can be eliminated from input during future predictions and thus not computed in the first place. Their absence reduces computational overhead in the running system. (Interestingly, in our tests with EMR screenshots, only one feature was not used).To begin machine learning, we first partition our set of screenshots into a training set and testing set. Then to train the classifier, we generate a set of ground-truth feature vectors and labels from the training set. We generate ground-truth by manually choosing the features and labels associated with “best” redaction results using the unsupervised classification technique described above. This ground-truth is fed into a program we implemented that interfaces with the liblinear library [5] to train and save the resultant classifier. The classifier can then be run on any image using another program we wrote to classify pixels as {−1,1} and thus redact text.During the SVM training process, we used default liblinear values for all SVM parameters. We experimented with cross-validation to tune the constant C in the SVM expression (see liblinear for details [5]). However, we experienced minimal performance improvements and therefore relied on default values to train each classifier.Section 4 above described our approaches to automatic text redaction. However, for both clinicians as well as system experimenters, it is important to keep users in the loop. This present section describes two tools we built for this purpose.Our scrubs tool (Fig. 5) captures and redacts screenshot images dynamically, in real time, using Canny. Our prototype uses x11vnc [10], pthreads [19] and the RFB protocol [9].When a health IT user decides some sequence of activity should be logged for later analysis, it is possible that automatic redaction may remove too much information (such as non-sensitive text that would help illuminate the issue requiring analysis) or too little (such as a sensitive logo or image). Consequently, our scrubs tool also provides an edit mode, which pauses display of screen updates and allows the user to click and drag the mouse to define custom redaction and/or unredaction rectangles (Fig. 6). While paused for user edits, the system continually processes and maintains received screen updates in the background, and upon returning to record mode, the system displays a compilation of all updates processed during pause.The Canny Edge approach to text redaction (Section 4.1) overlays a screenshot image with rectangles marking regions of potential text. In our experiments on EMR screenshots, we found that the resulting set of rectangles could often benefit from additional massaging. Thus, for the purpose of exploration and for end-user use, we developed a tool called “five_in_one” (Fig. 7). This tool permits a wide range of interactive operations, including merging, copying and deleting rectangles; toggling display between transparent and solid rectangles; generating (and then automatically applying) redaction templates; overlaying with a grid; and thinning out redundant rectangles. Fig. 8shows one example.

@&#CONCLUSIONS@&#
