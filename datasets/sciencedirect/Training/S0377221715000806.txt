@&#MAIN-TITLE@&#
Decision analysis under ambiguity

@&#HIGHLIGHTS@&#
The quantitative implications of modeling of ambiguity attitudes in decision problems is investigated.Alternative functionals are nested in decision trees.The smooth ambiguity is compared to the minimax and Savage formulations.Insights are discussed for analytical and numerical case studies.

@&#KEYPHRASES@&#
Decision analysis,Ambiguity theory,Decision trees,Certainty equivalents,

@&#ABSTRACT@&#
In selecting the preferred course of action, decision makers are often uncertain about one or more probabilities of interest. The experimental literature has ascertained that this uncertainty (ambiguity) might affect decision makers’ preferences. Then, the decision maker might wish to incorporate ambiguity aversion in the analysis. We investigate the modeling ambiguity attitudes in the solution of decision analysis problems through functionals well-established in the decision theory literature. We obtain the multiple-event problems for subjective expected utility, smooth ambiguity and maximin decision makers. This allows us to establish the conditions under which these alternative decision makers face equivalent problems. Results for certainty equivalents and risk premia in the presence of both risk and ambiguity aversion are obtained. A recent generalization of the classical Arrow–Pratt quadratic approximation allows us to quantify the portions of a premium due to risk–PLXINSERT-, and to ambiguity-aversion. The numerical implementation of the objective functions is addressed, showing that all functionals can be estimated at no additional burden through Monte Carlo simulation. The well known Carter Racing case study is addressed quantitatively to demonstrate the findings.“Management decisions, occur in a behavioral context in which the nature and causes of problems are ambiguous, and critical pieces of information are unavailable or suppressed” (Brittain and Sitkin, 1989, p. 62).

@&#INTRODUCTION@&#
The modern decision making cycle, conceived by the seminal work of Howard (1966) sets forth a systematic sequence of transparent steps for the solution of decision analysis problems (see also Clemen, 1997; Howard, 1988a, p.680; Howard, 2007, chap. 3). A key-step is the development of a quantitative model (Dillon, Paté-Cornell, and Guikema, 2003). However, lack of data or conflicting expert opinions might lead decision makers to face ambiguity (Ben-Tal, Bertsimas, and Brown, 2010; Ellsberg, 1961; Nau, 2007, chap. 3). That is, a decision maker might not be able to specify a unique distribution for the involved uncertainties.Moreover, psychological experiments, originated by the famous Ellsberg’s paradoxes (Ellsberg, 1961), reveal that subjects exhibit alternative attitudes toward ambiguity. These attitudes vary from aversion, to neutrality and, more rarely, to proneness (see Stecher, Shields, and Dickhaut, 2011; Trautmann, Vieider, and Wakker, 2011).Research in decision theory has developed axiomatizations leading to corresponding functionals that capture these alternative attitudes (see Fishburn, 1989; Gilboa and Marinacci, 2013; Nau, 2007; Smith and von Winterfeldt, 2004; Wakker, 2008 for overviews). The works of Wald (1950) and Gilboa and Schmeidler (1989) formalize the minimax functional, which leads to objective functions that capture the strongest aversion to ambiguity [we refer to Ben-Tal et al. (2010) for a thorough overview on robust optimization]. The classical subjective utility functional expresses ambiguity neutrality (Cerreia-Vioglio, Maccheroni, Marinacci, and Montrucchio, 2013). In between, we find axiomatizations for smoothly varying ambiguity attitudes leading to the so-called two-stage functionals (Anscombe and Aumann, 1963; Davis and Paté-Cornell, 1994; Ergin and Gul, 2009; Klibanoff, Marinacci, and Mukerji, 2005; Nau, 2006; 2007; Segal, 1987). Among these, the Klibanoff et al. (2005) functional stands out for several of its properties. Its tractability makes the functional widely used nowadays in applications (Hansen, 2007; Ju and Miao, 2012). It encompasses the minimax and expected utility functionals as limiting cases.Consider now a decision maker facing a multiple event problem in a real life application. She builds an influence diagram or decision tree to support her selection. Following standard practice, in the case she is not capable of assigning a unique probability distribution, she assesses a prior (posterior) over the possible distributions and uses Monte Carlo simulation to quantify uncertainty and to obtain the expected utilities. However, because of ambiguity, she might feel that this modeling would not reflect her attitudes toward this problem fully. This is equivalent to posing comparative statics questions about what optimal policies result when ambiguity attitudes are factored into the analysis. Answering these questions requires solving the decision model by implementing a functional that takes ambiguity attitudes into account. This then leads to a series of implementation questions, concerning both practical and conceptual aspects, which range from result interpretation to determining whether the modeling of ambiguity attitudes nest naturally over current practice.This work contributes in this direction by exploring the quantitative implications of modeling ambiguity attitudes in decision support models. Because our goal is a comparative statics, we do not develop a new model for ambiguity, but rather consider an analyst wishing to make a comparative exercise using functionals consolidated in the literature. We derive the multiple-event problems faced by a von Neumann–Morgenstern (vNM), a subjective expected utility (SEU), smooth ambiguity averse (KMM), and a minimax decision maker. We show that vNM, SEU and smooth ambiguity problems coincide under ambiguity neutrality (a taste feature) and under independence in the second order probability distribution (a state-of-knowledge feature). However, these two conditions are not enough to guarantee that a maximin problem is equivalent to the first three problems.In decision analysis, certainty equivalents and risk premia are often the quantities of interest. The literature has ascertained that, under ambiguity, decision makers may be willing to pay an ambiguity premium(Hogarth and Kunreuther, 1992). We exploit a recent extension of the Arrow–Pratt quadratic approximation (Maccheroni, Marinacci, and Ruffino, 2013; Pratt, 1964), to obtain a general result that quantifies the ambiguity premium in multiple event problems.Revisiting the classic Ellsberg’s paradox allows us to illustrate these findings analytically. Because in complex decision support problems are not usually analytically tractable, we also discuss the Monte Carlo estimation of the vNM, SEU, smooth ambiguity and minimax functionals. The proposed estimators permit to obtain these functionals from the output of subroutines built in common decision analysis software, thus, at no additional burden with respect to standard practice.We then apply the findings to the well known Carter racing case study of Brittain and Sitkin (1989). The investigation shows that by modeling alternative ambiguity attitudes the decision maker gathers a wide range of additional managerial insights while in the presence of uncertainty in probability. She can critically question whether her choice is robust when full credit to the involved uncertainties and her attitude toward them are displayed in the model. Through the quadratic approximation the decision maker is enabled to quantify the premium she is willing to pay, should she opt for the option suggested by an ambiguity-averse functional.The standard decision theoretic framework à la Savage (1954) consists of a state space S, an event algebra Σ defined over S, and the space X of consequences. States are ex-post verifiable, that is, they are observations (urns’ drawings, earthquakes, machines’ failures, and the like). Here we assume that consequences are real numbers, that is,X⊆R(the main example being amounts of money).In Savage’s framework, acts are Σ-measurable maps(1)f:S→Xfrom the state space to the consequence space that associates a consequence to each state. Denote byFthe collection of all acts. decision maker’s preferences among acts are represented by a binary relation ≿ defined overF.Consider then the measurable space (S, Σ) and let Δ(S) be the collection of all (countably additive) probability measures p: Σ → [0, 1]. Denote by σ(Δ(S)) the sigma algebra of subsets of Δ(S) generated by the maps p↦p(E) for each E ∈ Σ and each p ∈ Δ(S). We denote by Δ2(S) the collection of all (countably additive) probability measures μ: σ(Δ(S)) → [0, 1]. In Savage’s theory, bets play a special role among acts because through them subjective probabilities are elicited. In particular, given any two consequences x≻y, denote by xEy the bet on event E, which pays the best consequence x if E occurs and y otherwise. Given any two events E and F, if the decision maker prefers lottery xFy over lottery xEy reveals that the decision maker considers F more likely than E.The two stage structure foresees the decision maker posing two sets of probability models.Suppose that the decision maker knows that observations s are generated by a probability model p ∈ Δ(S) that belongs to a given subset M of Δ(S). Each such p represents aleatory uncertainty, that is, the inherent randomness that observations feature. In other words, the decision maker posits a model space M in addition to the observation space S.We can then take the “aleatory” information M as a primitive and enrich the standard Savage framework with this datum: the decision maker knows that the true model p that generates observations belongs to M. In terms of the basic preference ≿, this translates into the requirement that betting behavior is consistent with datum M. Let F and E be two events and p(F) and p(E) and xFy and xEy bets on events F and E, with x≻y. Then, assume that(2)p(F)≥p(E)∀p∈M⟹xFy≿xEyThat is, if all models in M deem F more likely than E, the decision maker accordingly prefers to bet on F than on E, that is, he deems F more likely than E.Cerreia-Vioglio et al. (2013) show that if ≿ satisfies Savage’s axioms and the above consistency condition, acts are ranked according to the criterion(3)G(f)=∫Δ(S)(∫Su(f(s))dp(s))dμ(p)whereu:X→Ris a utility function that captures risk attitudes (i.e., attitudes toward aleatory uncertainty) and μ: σ(Δ(S)) → [0, 1] is a subjective prior distribution that quantifies the epistemic uncertainty about models. Its support is included in M.11In the paper we will sometime refer to p and μ as, respectively, first order and second order probability distributions.Representation (3) is called Classical Subjective Expected Utility because of the classical statistics tenet on which it relies (Cerreia-Vioglio et al., 2013; Fishburn, 1989). Each prior μ induces a predictive probability pμ∈ Δ(S) through reduction (see also Apostolakis, 1990):(4)pμ(E)=∫Δ(S)p(E)dμ(p)The predictive probability allows one to rewrite representation (3) as:(5)G(f)=∫Su(f(s))dpμ(s)This reduced form is the original Savage subjective expected utility (SEU) representation.22Note that probability measures in Δ(S) can play two conceptually altogether different roles: predictive probabilities and probability models.When M is a singleton{p˜},i.e., there is no epistemic uncertainty, we havepμ=p˜for all priors μ and we thus get the von Neumann–Morgenstern (vNM) Expected Utility representation(6)U(f,p˜)=∫Su(f(s))dp(s)where subjective probabilities do not play any role (since there is no epistemic uncertainty). Classical SEU thus encompasses both the Savage and the vNM representations. Note thatG(f)=U(f,pμ).In order to distinguish between attitudes toward aleatory and epistemic uncertainty, Klibanoff et al. (2005) developed a smooth ambiguity preference model in which decision makers rank acts according to the criterion(7)V(f)=∫Δ(S)ϕ(∫Su(f(s))dp(s))dμ(p)where u and μ are interpreted as in (3), whileϕ:u(X)→Ris a strictly increasing and continuous map that captures ambiguity attitudes.33See Nau (2006) and Ergin and Gul (2009) for different, but related, approaches.A key feature of this model is that it achieves a separation between the perception of ambiguity, identified as a characteristic of the decision maker’s subjective beliefs, and the attitude toward ambiguity, identified as a characteristic of the decision maker’s tastes. Ambiguity aversion is captured by the concavity of ϕ, while ambiguity neutrality corresponds to a linear ϕ. In this latter case, criterion (7) reduces to the classical SEU representation (3).In the criterion V one can distinguish two functions, u and v. In fact, if we setv=ϕ∘u:X→R,so thatϕ=v∘u−1,we can write(8)V(f)=∫Δ(S)(v∘u−1)(∫Su(f(s))dp(s))dμ(p)Hence, v is a utility function that has as argument the certainty equivalents(9)c(p,f)=u−1(∫Su(f(s))dp(s))dμ(p)of act f under model p. As such, it can be seen as representing attitudes toward the epistemic uncertainty that decision makers experience when dealing with alternative possible probabilistic models p that may generate observations. The utility function u represents attitudes toward aleatory uncertainty.Epistemic uncertainty cumulates with aleatory uncertainty that any nontrivial probabilistic model p features. This combination determines in criterion (7) the ambiguity that decision makers face in ranking acts. Attitudes toward ambiguity are captured by the function ϕ . In particular, attitudes toward aleatory and epistemic uncertainty are equal, that is,u=v,if and only if ϕ is linear. In other words, their coincidence amounts to ambiguity neutrality. In contrast, the function ϕ is concave if and only if v is a concave transformation of u, that is, decision makers feature (as plausible) a higher aversion to epistemic than to aleatory uncertainty. In particular, the quantitiesλu(w)=−u′′(w)/u′(w)andλv(w)=−v′′(w)/v′(w)are, respectively, the classic Arrow–Pratt coefficient of risk aversion (Pratt, 1964) and its extension to ambiguity aversion. The concavity of ϕ impliesλv(w)−λu(w)≥0for any w.These observations highlight the analytical tractability of the Klibanoff et al. (2005) functional, which allows one to apply to the study of ambiguity the well developed machinery for dealing with risk(Ju and Miao, 2012, p. 564).Finally, under extreme ambiguity aversion—that is, when ambiguity aversion “goes to infinity”—the smooth ambiguity criterion (7) reduces, in the limit, to the maximin modelW(f)=minp∈M∫Su(f(s))dp(s)of Gilboa and Schmeidler (1989) in its Wald (1950) interpretation. Under this very cautious criterion, the decision maker maxminimizes over all possible models in M.We consider a decision maker selecting the best course of action in a multiple event problem. The decision maker employs a decision support model for constructing the Savage mapping (1) and identifying the (plausible) scenarios that link acts to the end states (Kirkwood, 1993; Shachter, 2007). We write the expected utility of act f as(10)U(f,p)=∑q=1Qpf(q)uq,f=1,2,…,Awhere Q is the number of consequences,44For notation simplicity, we assume that the variables in chance nodes are discrete, so that we have a finite number of consequences.pf(q) is the probability that consequence q is realized and uqis the utility of consequence q. Often consequences are measured in monetary terms. We let wqdenote the monetary payoff of consequence q.uq=u(wq)is then a utility function for money, capturing the decision maker’s risk attitudes. When the decision maker is risk neutral, the expected payoffs of the alternatives are:(11)H(f,p)=∑q=1Qpf(q)wq,f=1,2,…,AIn multiple-event problems, the decision support model factorizes the probability distribution pf(q) in conditional probabilities of the events that lead to the initial node to the end consequence (Kirkwood, 1993; Park and Darwiche, 2004). Fixed f, one calls scenario a combination of outcomes that lead from the initial node to the end-consequence. Once strategy f is selected, a consequence is reached after the realization of r random variablesZ1,Z2,…,Zr.—To clarify: if we use an influence diagram (decision tree), selecting strategy f means fixing decisions nodes; once these are fixed the model becomes a Bayesian network (event tree) with r chance nodes (see Papazoglou, 1998; Shachter, 2007).—We denote scenario k byZk={z1,k,z2,k,…,zr,k},where zl, kdenotes the outcome of node l (the realization of Zl,l=1,2,…,r) in scenario k. LetZqfthe collection of all and sole the scenarios that lead to consequence q, once act f is selected. Then, the probability of reaching consequence q ispf(q)=Pr(Zqf). Then, we have(12)Pr(Zqf)=∑k:Zk∈ZqfPr(Zk)Example 1Consider a decision maker who is choosing between a sure amount (20EUR) and a bet in which she obtains EUR100 if a certain European soccer team totals four points in the next two championship games. The decision tree is represented in Fig. 1. Then, we have two strategies, to bet or not to bet, so thatf=1,2,withf=1denoting the alternative “to bet”. We have three consequences,q=1,2,3,whereq=1denotes receiving 100EUR,q=2denotes receiving 0EUR andq=3denotes receiving 20EUR. Letf=1. If the decision maker decides to bet, we have a total of 9 scenarios (a soccer match can end in a win, loss or a tie), with two possible outcomes per scenario. We haver=2nodes andk=9scenarios. Two scenarios lead to consequence 100, namely, a victory (3 points) in the first game and a tie (1 point) in the second, or tie in the first game and win in the second. Then, the probability of consequence 1 isPr(Z11)=Pr({WinsI,TiesII})+P({TiesI,WinsII}). All other scenarios lead to consequence 0EUR. Conversely, iff=2,there is a unique scenario providing the sure amount of 20EUR.The second equality in (12) holds because two scenarios inZqfcannot be realized at the same time.Pr(Zk)can be further expanded as(13)Pr(Zk)=p(zr,k|zr−1,k,…,z1,k)×p(zr−1,k|zr−2,k,…,z1,k)×···×p(z1,k)wherep(zl,k|zl−1,k,…,z1,k)is the conditional probability of outcome zl, k,l=1,2,…,r. Settingplf,q,k=p(zl,k|zl−1,k,…,zr,k),we can write more synthetically(14)Pr(Zk)=∏l=1rplf,q,kobtaining(15)pf(q)=∑k:Zk∈Zqf∏l=1rplf,q,kIn (16),plf,q,kis a member of a conditional probability table. Letting p denote the collection of all conditional probabilities, (10) becomes(16)U(f,p)=∑q=1Q(∑k:Zk∈Zqf∏l=1rplf,q,k)uq.Thus, we retrieve the usual condition that U(f, p) is multilinear in the conditional probabilities (Felli and Hazen, 2004; Kirkwood, 1993) and additive in the utilities (Nau, 2006, p. 136).Example 2Example 1 ContinuedFor simplicity, let us assume thatu(0)=0. Then,(17)U(1,p)=(Pr(WinsI)Pr(TiesII|WinsI)+Pr(TiesI)Pr(WinsI|TiesII))u1,To illustrate our notation in generic expressions, if we were to number scenarios from 1 to 10, and assign the two scenarios in which consequence 1 is achieved as number 6 and number 8, then Eq. (17) would be rewritten as(18)U(f,p)=(p11,1,6p21,1,6+p11,1,8p21,1,8)u1,wherep11,1,6=Pr(WinsI),p21,1,6=Pr(TiesII|WinsI)andp11,1,8=Pr(TiesI),p21,1,8=Pr(WinsI|TiesII).Letp˜denote the given and unique first order probability distribution of a vNM decision maker. Then, the factorization ofp˜(q)intop˜lf,q,kis directly:(19)p˜(q)=∑k:Zk∈Zqf∏l=1rp˜lf,q,k,that is, the probability of consequence q is the product of the base-case valuesp˜lf,q,kof the probabilities in the conditional probability tables.Problem 1von Neumann–MorgensternGivenp˜a vNM decision maker selects alternative f* such that(20)f*∈argmaxf=1…A{∑q=1Q(∑k:Zk∈Zqf∏l=1rp˜lf,q,k)uq}The results in (19) and (20) encompass what is done in the practice, where we input the utilities and the conditional probability tables at their base case values and the decision support software computes the expected utilities (payoffs) of the available strategies after performing the necessary probabilistic manipulations (e.g., using the folding back method in decision trees). When regarded as a function of probabilities and utilities, the functional in Eq. (20) is a generalization of Bayesian network polynomials, called decision network polynomial in Borgonovo and Tonoli (2014). We refer to Borgonovo and Tonoli (2014) for a thorough discussion of associated mathematical properties.Suppose that probabilities are not given. Then, we exit the vNM framework. However, the decision maker might be willing (and this is often done in the practice, see Felli and Hazen (2004)) to specify a second order probability distribution over p, namely, μ(p). Here, we enter the subjective (or Bayesian) expected utility theoretical framework [Section 2.2]. As for probabilities, Eq. (19) does not relate pf(q) and its factorization intoplf,q,kanymore. Instead, the following holds (see Appendix A for the proof).Lemma 1Under the subjective expected utility framework, assigned μ, letpμf(q)denote the predictive probability of consequence q. Then,(21)G(f)=∑q=1Qpμf(q)uqwhere(22)pμf(q)=∑k:Zk∈Zqf∫Δ(S)(∏l=1rplf,q,k)dμ(p)The expression in (22) suggests thatpμf(q)does not coincide with the direct product and sum of the mean values of theplf,q.k. By Lemma (1), we obtain the following.Problem 2Subjective Expected UtilityGiven μ, a subjective expected utility decision maker selects alternative f* such that(23)f*∈argmaxf=1,2,…,A{∑q=1Qpμf(q)uq}wherepμf(q)is given in (22).Thus, a subjective expected utility decision maker solves a problem formally equivalent to a vNM one, in which we substitutepμf(q)forp˜f(q). These facts take us back to the foundational discussion about uncertainty in probability of Howard (1988b). In Howard (1988b), the assignment of an uncertain probability to its mean value is a logical requirement (Howard, 1988b, p. 92)—Howard’s mean value is preciselypμf(q).—In the light of Cerreia-Vioglio et al. (2013), this assignment corresponds to assuming an underlying subjective (Bayesian) expected utility framework. However, (22) leads us to take some precaution in the mean value assignment when p is factorized through theplq,f,k’s. Assigning theplq,f,k’s to their mean values does not lead topμf(q)unless we assume independence at the level of the second order distribution. For an ambiguity averse decision maker, the following holds.Problem 3SmoothGiven μ, a smooth ambiguity averse decision maker selects alternative f* that solves the problem(24)f*∈argmaxf=1,2,…,A{∫Δ(S)ϕ(∑q=1Q(∑k:Zk∈Zqf∏l=1rplf,q.k)uq)dμ(p)}As for a decision maker who is completely ambiguity averse, it holds:Problem 4MaximinA Maximin decision maker selects alternative f* that solves the problem:(25)f*∈argmaxf=1,2,…,A{minp∈M∑q=1Q(∑k:Zk∈Zqf∏l=1rplf,q,k)uq}Problems 1–4 allow us to set forth the conditions that make the four problems equivalent from a quantitative viewpoint.Theorem 1Given (S, Σ, p), (ΔS, σ(ΔS), μ(p)),f:S→R,(A)Under the following conditions:(i)pμf(q)=p˜f(q)for all q and f;ϕ(u)=u;problems vNM, SEU and KMM are numerically equivalent.Problem Maximin is never equivalent to a vNM nor to a SEU nor to a KMM problem.Concerning assumption (i), we have the following sufficient condition (the necessary algebraic manipulations are in Appendix A).Remark 1Assumption (i) in Theorem 1 holds if, for all k, f, q:(i)the second order distribution is such thatplf,q,kis independent ofpsf,q,k(l,s=1,2,…,r,l ≠ s); andp˜lf,q,kis assigned equal toEμ[plf,q,k]=∫Δ(S)plf,q,kdμ(p).Remark 1 addresses what is done in several practical applications. Analysts assess some base case value of the probabilities (plf,q,k) and then assign plausible variation ranges (supports) and, if possible, second order distributions. If independence is invoked for the second order distribution, and the distributions are chosen in such a way thatEμ[plf,q.k]=p˜lf,q,kthen conditions (i) and (ii) in Remark 1 are met. However, independence at the level of the second order distribution, while representing a practical shortcut, is a conceptually strong assumption.Example 3Consider the following decision problem. A decision maker has to decide whether to license a new plant. The plant failure probability can be computed from the logical configuration of two components in parallel, that is, we register system failure if both components fail, otherwise the system is capable to perform the required mission. The components are assumed to be identical. Then, the probability of the consequenceq={systemfailure}isp˜f(q)=p˜1p˜2,where p1 and p2 are the failure probabilities of components 1 and 2, respectively. If the two components are identical, thenp˜1=p˜2. Then, we findp˜(systemfailure)=p˜1p˜2=p˜2. If the probabilities are not known and we assume a second order distribution, thenpμf(systemfailure)=∫01p2dμ(p). Now,∫01p2dμ(p)is, in general, different fromp˜2so thatpμf(systemfailure)≠p˜2,in general. For instance, ifp˜1=0.5and μ(p) is the uniform distribution in [0, 1], thenpμf(systemfailure)=13≠p˜(systemfailure)=0.25. Thus, assumption (i) is violated for this consequence and Theorem 1 does not apply. In particular, it is the assumption of independence at the epistemic (second order) distribution level which is violated, due to the fact that the two probabilities are perfectly correlated. The reason is that, if the two components are assumed to be identical, then the same number p has to be used to compute the system reliability in the presence of epistemic uncertainty, as per the seminal work of Apostolakis and Kaplan (1981).As for assumption (ii), experimental evidence demonstrates that decision makers display preferences (aversion, usually) for ambiguity. Thus, the assumptionϕ(u)=umight not be realistic. Finally, item B in Theorem 1 suggests that a completely ambiguity averse decision maker faces a problem which is never numerically equivalent to that of either a vNM, or KMM or SEU decision maker.The concepts of certainty equivalent and risk premium are central in decision analysis. Our goal, in this section, is to investigate them under smooth ambiguity aversion. “The certainty equivalent for an alternative is the certain(monetary)amount that is equally preferred to the alternative” (Kirkwood, 2002, chap. 2, p. 19). The corresponding risk premium is the difference between the expected value of the alternative and its certainty equivalent.The expression in (9) defines the traditional certainty equivalent for strategy f under risk and distribution p. When p is not a singleton, the certainty equivalent that includes both ambiguity and risk aversion is defined as (Hansen, 2007; Klibanoff et al., 2005):(26)C(f)=v−1(V(f))=v−1[∫Δ(S)v(c(f,p))dμ(p)]C(f) represents the overall certainty equivalent that accounts for both attitudes toward ambiguity, through the function v( · ), and toward risk, through the traditional u( · ). Observe that C(f) as well as c(f, p) have monetary units. Although a monetary representation of certainty equivalents is more meaningful, we can also define the certainty equivalent in utils as(27)T(f)=ϕ−1(∫Δ(S)v(c(f,p))dμ(p))=u(C(f))Lemma 2For a smooth ambiguity averse decision maker the monetary certainty equivalent of alternative f is given by(28)C(f)=v−1(∫Δ(S)v(u−1[∑q=1Q(∑k:Zk∈Zqf∏l=1Rplf,q.k)uq])dμ(p))The corresponding certainty equivalent in utils is(29)T(f)=u(v−1(∫Δ(S)v(u−1[∑q=1Q(∑k:Zk∈Zqf∏l=1Rplf,q.k)uq])dμ(p))).As mentioned, C(f) in (28) expresses both the ambiguity and risk attitudes of the decision maker. We could then argue that the associated premium includes a portion related to risk aversion and a portion related to ambiguity aversion. To investigate this assertion, we consider a decision maker who is both risk and ambiguity neutral. We have the following (see Appendix A for the proof).Lemma 3The certainty equivalent for a decision maker neutral to both ambiguity and risk is given by(30)H(pμ,f)=∑q=1Qpμf(q)wqObserve that H(f, pμ) in (30) is the expected payoff of alternative f under the predictive probability distribution pμ.Definition 1We call the quantity(31)Π(f):=H(pμ,f)−C(f)risk-and-ambiguity premium of alternative f.Π(f) is an overall premium that includes both ambiguity and risk aversion. To separate them, at least approximately, we can resort to a recent result generalizing the Arrow–Pratt certainty equivalent under ambiguity (Maccheroni et al., 2013). The quadratic approximation finds it motivation in Finance, as a generalization of Markowitz’s portfolio selection model. Here, let w be initial wealth and wfthe wealth added by investment f. As Maccheroni et al. (2013) show, under standard differentiability assumptions on the functions u and v, the certainty equivalent in (26) is approximated by:(32)C(f)≃CAP(f)+ΠAM(f)where(33)CAP(f)=w+Epμ[wf]−12λu(w)σpμ2(wf)is the classical Arrow–Pratt quadratic approximation and(34)ΠAM(f)=−12(λv(w)−λu(w))σμ2(Ep[wf])is the quadratic ambiguity premium.CAP(f) is based on the predictive probability distribution: we eliminate uncertainty through reduction [see Eq. (4)]. CAP(f) allows us to determine the risk premium under the predictive probability distribution pμ:Epμ[wf]is the expected payoff of investment f under the predictive probability distribution, andσpμ2(wf)is the corresponding variance. ΠAM(f), the ambiguity premium (34), is jointly determined by the varianceσμ2(H[p,f]),which captures the scope of epistemic uncertainty that the decision maker perceives, and by the differenceλv(w)−λu(w),which captures the decision maker’s different attitudes toward aleatory uncertainty and epistemic uncertainty. We recall thatλv(w)−λu(w)≥0by the concavity of ϕ(Section 2.3), guaranteeing the negative sign of ΠAM(f).The results in (32)–(34) offer a natural way to perform comparative statics between risk and ambiguity aversion. For quadratic risk-and-ambiguity premia in decision analysis problems we obtain the following result (the proof is in Appendix A; for notation simplicity, in the remainder we write λuor λvinstead of λu(w) and λv(w)).Theorem 2Given μ, for a smooth ambiguity decision maker the Arrow–Pratt certainty equivalent and the ambiguity premium are given by:CAP(f)=w+∑q=1Qpμf(q)wq−12λuσpμ2(f)where(35)σpμ2(f)=∑q=1Qpμf(q)wq2−(∑q=1Qpμf(q)wq)2and(36)ΠAM(f)=−12(λv−λu)(∑q,r=1QCovμ[pf(q),pf(r)]wqwr)whereCov[pf(q),pf(r)]=Eμ[(pf(q)−pμf(q))(pf(r)−pμf(r))],r,q=1,2,…,Q.In Theorem 2, two variances appear,σpμ2(f)andσμ2(H(p,f)). The former is the variance of the payoffs associated with alternative f under the predictive probability distribution; it is the variance that would obtain if only aleatory uncertainty were present and the true distribution were pμ. The latter is the variance of the expected payoff of alternative f generated by our uncertainty about the first order distribution p. This term is null if p is fixed.Finally, lettingw=0,it is interesting to rewrite the quadratic approximation of Π(f) in decision analysis problems as follows:Π(f)=12λu[σpμ2(f)−σμ2(H(p,f))]+12λvσμ2(H(p,f))That is, Π(f) is determined by the sum of two terms, one proportional to the difference between the aleatory variance and epistemic variance through λu, and one proportional to the epistemic variance through λv.To illustrate, we revisit the classic Ellsberg (1961) paradox from a decision analysis perspective. A decision maker is selecting among acts f, g, f′ and g′, whose payoffs depends on three mutually exclusive events R, B and Y that correspond to drawing a red or black or yellow ball from the same urn. Table 1reports the payoffs incurred in each state.The state space isS={R,B,Y},with probabilities P(R), P(B) and P(Y). The decision maker knows thatP(R)=1/3,P(Y)=2/3−P(B),but she is not able to assign a value to P(B). LettingP(B)=p,we have:U(f,p)=13u(100)+23u(0);U(g,p)=(13+p)u(0)+(23−p)u(100)U(f′,p)=(1−p)u(100)+pu(0);U(g′,p)=13u(0)+23u(100)Typically, at this stage, we would perform a one-way sensitivity analysis to study the behavior of the preferred alternative as a function of p. Some simple manipulation shows that, for any possible value assigned to u(100) and u(0) with u(100) > u(0),(i)alternatives f and g are dominated by f′ and g′ for all values of p;if p < 1/3 (resp.,   > 1/3) then f′ has an expected utility greater (resp., smaller) than g′, while ifp=1/3then f′ and g′ have the same expected utility.This analysis is usually displayed as a one-way sensitivity plot. The plot would indicate to the decision maker that, should she believe that 0 ≤ p ≤ 1/3, then f′ should be the preferred alternative, while g′ would be preferred, if she believed that 1/3 ≤ p ≤ 2/3. However, this analysis does not provide a definitive recommendation, becausep˜is not given.Instead, the subjective expected utility, smooth ambiguity and minimax frameworks, allow us to identify the preferred alternative, provided that we assign a second order distribution over p. In Ellsberg’s problem, p coincides with a possible composition of the urn. If the decision maker does not favor some composition over the other, then, by a symmetry argument, she can regard all possible compositions as equally likely:μ(p)={32if0≤p≤230otherwise(we also select this distribution for simplicity in the following calculations).Let us start with the SEU framework. The predictive probability distribution ispμ=(1/3,1/3,1/3). We obtain:G(f)=U(f,pμ)=13u(100)+23u(0);G(g)=U(g,pμ)=23u(0)+(23−p)u(100)G(f′)=U(f′,pμ)=13u(0)+23u(100);G(g′)=U(g′,pμ)=13u(0)+23u(100)Thus, for a classical SEU decision maker, alternatives f′ and g′ are equivalent.On the side, we observe that, by Theorem 1, this result would also be obtained by a vNM decision maker assigningp˜=(1/3,1/3,1/3)(assumptions (i) and (ii) are satisfied). Thus, for all ambiguity neutral decision makers, alternatives f′ and g′ are indifferent. To study the preferred alternative for ambiguity averse decision makers, we utilize the quadratic approximation of certainty equivalents. Lettingw=0,the Arrow–Pratt expressions of the certainty equivalents (33) are given by:CAP(f)=1003−λu2(100003−100009);CAP(g)=1003−λu213(100003−100009)CAP(f′)=2003−λu2(200003−400009);CAP(g′)=2003−λu2(200003−400009)Thus, under risk, g′ and f′ are equally preferred for any value of λu. To distinguish among them, we need to consider the ambiguity part of the risk and uncertainty premium [(34); all calculations are in Appendix A]. We obtain:(37)ΠAM(f)=0;ΠAM(g)=−12(λv−λu)100227ΠAM(f′)=−12(λv−λu)100227;ΠAM(g′)=0Eq. (37) delivers some interesting insights. No ambiguity premium is registered for alternatives f and g′, although they are characterized by the presence of ambiguity.ΠAM(f)=0is due to the fact that the payoffs are zero for outcomes R and Y. Instead, ΠAM(g′) is null because the associated second order varianceσμ2(g′)=0.This occurs not because we are certain about the probabilities of B and Y, but because of the opposite sign of the covariance in (36) with respect to the individual variances that accompany the same consequences [the reader is referred to Appendix A for the analytical details].Eq. (37) allows us to identify the preferred alternative for a smooth ambiguity decision maker. It is C(g′) ≃ CAP(g) whileC(f′)≃CAP(g)−12(λv−λu)100227. Because λv> λu, we have C(g′) > C(f′). Thus, g′ is the preferred alternative for an ambiguity averse decision maker. We observe that our investigation has allowed us to identify the preferred alternative without stating any numerical assumption onλv−λu,nor on the functional form of u( · ) and v( · ).However, we might proceed differently and assign a functional form to u( · ) and v( · ). The most traditional choice in decision analysis is to use an exponential utility function for risk. We write(38)u(w)=−e−αwWe can then also assume a constant ambiguity aversion, writing(39)v(t)=−e−βtIt is then readily seen thatϕ:(−∞,0)→Ris given byϕ(y)=(v∘u−1)(y)=−(−y)βαfor eachy < 0. We can then evaluate the KMM-generalized utility of the four alternatives in consideration of both ambiguity and risk attitudes. We obtain:V(f)=∫023−e−β(−1αln12(e−α·100+2))32dp;V(g)=∫023−e−β(−1αln(13+p+(23−p)(e−α·100)))32dpV(f′)=∫023−e−β(−1αln((1−p)(e−α·100)+p))32dp;V(g′)=∫023−e−β(−1αln(13+23e−α·100))32dpAssigningβ=2/100andα=1/100the numerical values of the expected utilities of the alternatives areV(f)=−0.62;V(g)=−0.64;V(f′)=−0.35;V(g′)=−0.33Thus, g′ is the preferred alternative, followed by f′, g and f.Finally, we come to a maximin decision maker. She would obtain the following Wald utilities to the four alternatives:W(f)=−0.7893;W(g)=−1.0000;W(f′)=−0.7893;W(g′)=−0.5786Thus, g′ is the preferred alternative for a decision maker who is completely ambiguity averse.In realistic applications involving uncertainty in distribution, analytical results such as those obtained for the Ellsberg paradox become soon out of reach. Then, uncertainty is propagated using Monte Carlo simulation (see Chick, 2001 for an overview).The objective functions of interest are multivariate expectations (i.e., multidimensional integrals). Therefore, they fall naturally within the scope of Monte Carlo estimation, with the traditional estimation error decreasing at the rate1/N,where N denotes the Monte Carlo sample size. In the remainder, lower case n denotes a generic Monte Carlo run (n=1,2,…,N).We present the estimators as part of the algorithmic procedure summarized in Table 2.55As for step 1, as suggested by Pearl (1988), one can show that the procedure involved in the assessment of P[P(A)=p] is no different from that involved in the assessment of P(A) and, moreover, that the very information used for calculating P(A) is sufficient for calculating the confidence interval associated with the statement P(A)=p. Typically, one assesses a prior and, if possible, uses data or available evidence to update such distribution. This process is standard in several disciplines, among which the reliability and risk analysis one (Martz and Waller, 1991). Several methods have been developed for the consistent elicitation of probabilities. We recall the important class of scoring rules (Gneiting and Raftery, 2007; Jose, Nau, and Winkler, 2008; Nau, 1985). We also refer to Cooke (1991) and Aspinall (2010) for further discussion on expert elicitation.First step of the analysis is to generate a sample that follows the second order distribution μ(p). The symbols pnandplf,q,k,ndenote the realization of the second order distribution p and of one of its conditional probabilities in the nth Monte Carlo run, respectively. The second step is to evaluate the decision support model in correspondence of pn,n=1,2,…,N. These two steps are the usual ones followed in a probabilistic (or Monte Carlo) sensitivity analysis (Hazen and Huang, 2006).The third step is to estimate the two stage functionals. For the subjective expected utility functional [Eq. (21)], we can introduce two equivalent estimators. The first estimator is(40)G^(f)=∑n=1NU(f,pn)Nwhere pnis the first order probability distribution realized in the nth Monte Carlo run and U(f, pn) the corresponding vNM expected utility. The second is(41)G^(f)=∑q=1Qp^μf(q)uqwhere(42)p^μf(q)=∑n=1Npμf,n(q)N=∑n=1N(∑k:Zk∈Zqf∏l=1rplf,q,k,n)Nis the estimator of the predictive probability distribution. While conceptually equivalent, the estimators in Eqs. (40) and (41) lead to a different practical implementation, which matters if the code is using the folding back method. The estimator in (40) is directly applicable: it requires to execute the decision support model n times and then average its output. The estimator in (41), instead, requires to first evaluate∑k:Zk∈Zqf∏l=1rplf,q,k,n(this evaluation needs to be singled out if we are folding back the tree), then average over n, and then multiply the estimatesp^μf(q)for the corresponding uq.From the estimator in (42), we also obtain the estimator of the expected payoff for a risk and ambiguity neutral decision maker:(43)H^(pμ,f)=∑q=1Qp^μf(q)wqFor the smooth ambiguity functional, the estimator is given by:(44)V^(f)=∑n=1Nϕ(U(f,pn))NEq. (44) evidences the composition of the KMM function ϕ with the expected utility realized at each Monte Carlo run in correspondence with a value of the first order probability. The estimator of the certainty equivalent for a KMM decision maker is then given by(45)C^(f)=v−1(∑n=1Nv(u−1(U(f,pn)))N)Finally, for the minimax functional, the estimator is:(46)W^(f)=minn=1,2,…,NU(f,pn)We observe that all data necessary to implement the above-listed steps are contained in a standard Monte Carlo simulation. Thus, they are produced by software tools traditionally used by decision analysts, such as Treeage, @Risk, Crystal Ball and others. Therefore, the estimators of these functionals demand no additional burden with respect to a traditional Monte Carlo analysis.The problem we are to discuss numerically is the well known Carter Racing case study (Brittain and Sitkin, 1989). This case study is frequently taught in business school, either with an organizational or a decision analytic twist. The next description is made here in a decision analysis setup, reworking the description in Brittain and Sitkin (1989). John Carter, must make a decision under time pressure and considerable uncertainty. The future of his firm is at stake. If the next race (the last of the season) is a success, then, besides the current sponsor at 500 000 dollars, Carter racing will receive a new sponsor bringing in 1 million dollars, thus ensuring a cash position for the start of the new year at around 1 million dollars. In the case of an intermediate success, the old sponsor will remain with an inflow of 500 000 dollars, and with a cash position for the new year of around zero. In the case of engine failure, however, the season will end with a catastrophic cash position of−500000dollars, which would probably rule against the survival of the Carter racing team.John Carter then starts brainstorming about the possible performance of the car in this last race. Given the most recent placements, a good finish seems likely. However, John is concerned about recent engine blowouts, which are the sort of engine blowouts that make advertisers cancel sponsorships (Brittain and Sitkin, 1989, p. 64).John is provided with conflicting opinions by his experts. Paul Edwards, the team mechanic, deems an engine failure likely. Tom Burns, the team engineer, deems an engine failure unlikely.The question is then: Run or Withdraw? Following the decision making cycle, the problem is represented in the form of a decision tree (Fig. 2).The tree in Fig. 2 features two chance nodes, Engine and Classification.66While in some MBA courses the case is represented with a unique event and three branches, we prefer here to explicitly isolate engine failure, because the conflicting expert opinions make this event ambiguous.In Brittain and Sitkin (1989), point values are assigned to the probabilities of all events. Inserting the numbers in the decision-tree of Fig. 2, we obtainH(Run;p)=350andH(Withdraw;p)=0.Thus, the preferred alternative is to run. This result is numerically consistent with the initial survey usually obtained after a first presentation of the case, corresponding to statements such as “I think we should race, because racing is a business of risks ...” (Brittain and Sitkin, 1989, p. 65).This first ”gut feeling” is then subjected to further examinations in the analysis of the case study, in which students are, step by step, asked to critically review their initial statements. From a quantitative viewpoint, the first item to note is that we are in a case of conflicting opinions and these make John uncertain about the probabilities. Let us model this fact.The ambiguous event is engine failure. Paul Edwards’ opinion would make John Carter inclined to consider an engine failure likely. John Burns’ opinion, conversely, would make John consider the failure unlikely. To model John’s view after he has received Paul Edward’s opinion, we assign a beta distribution to the engine failure probability with parameters 2 and 6, so that the predictive probability [Eq. (4)] isp˜Edwards=34. Tom Burn’s opinion, which is antithetic with respect to Paul Edwards’ indication, is modeled through a the symmetric distribution, i.e., a beta with parameters 6 and 2, so that the predictive probabilityp˜Burns=14. Combining the two experts’ opinions, John weighs obtains a predictive probability of engine failure given byp˜=mp˜Edwards+(1−m)p˜Burns. In our next numerical calculations, we selectm=0.10,so that the predictive probability of engine failure,p˜,equals the point estimate engine failure probability in Brittain and Sitkin (1989), namelyp˜=0.3. We then consider that John Carter assigns a 5/7 conditional probability of being in the first 5 given no engine failure (denoted by p5). Byp5=5/7,one re-obtains the unconditional probability of ending in the first five as in Table 2, p. 70, in Brittain and Sitkin (1989).Based on these numbers, also an SEU but risk-and-ambiguity neutral decision maker chooses the option to Run, even when uncertainty in the probabilities is modeled.Consider now that John performs a Monte Carlo simulation, to understand the variability of the payoffs, provided by uncertainty in probability. Using the two-layer sampling procedure of Chick (2001), at a sample of sizeN=1018generated through from the Halton sequence (Owen, 2006) generator of Matlab, one obtains the results of the first graph in Fig. 3.Given the variability of the payoffs in Fig. 3, John might wish to question his decision further, asking whether, after factoring ambiguity aversion in the decision problem, Run remains the preferred strategy.One immediately notes that a maximin decision maker selects Withdraw independently of her risk aversion, because in the worse case scenario this alternative leads to a prospect of 0, while Run has a negative worst outcome (see also the Dirac-δ distribution obtained in the fourth graph of Fig. 3). Then, if John acted as a minimax decision maker, he would chose Withdraw. This choice exposes John to the criticism of selecting a too conservative strategy, what might result inappropriate in a business context. However, John has the option to explore varying degrees of ambiguity aversion using the KMM functional (see Appendix A for details on numerical implementation). In particular, a one-way sensitivity analysis performed over the ambiguity aversion constant β [Eq. (39)] delivers the results in Fig. 4.Fig. 4 shows that, ceteris paribus, if John considers smoothly varying ambiguity attitudes, for β greater than a given threshold (β > 1/130 in this case), Withdraw becomes the preferred alternative.While the value of the ambiguity aversion constant, per se, might not have a direct grasp for a decision maker, we can look at the same insights using certainty equivalents. For illustrative purposes, here we adopt a constant risk aversion withα=1/1000,leavingβ=1/100. Fig. 3, second graph, shows the empirical density of the Monte Carlo distribution of the risk-averse SEU functional.Applying Eq. (26), the KMM risk-and-ambiguity averse certainty equivalent isC(Run)=−147.56,which leads to a risk-and-ambiguity premiumΠ=497.56. Thus, if John is risk-and-ambiguity averse, he would chose Withdraw, paying the above-mentioned premium. Using the quadratic approximation, we can apportion the premium to John’s risk and ambiguity attitudes, respectively. In particular, we obtain−12ασpμ2(wf)=−123.75leading to a risk premium equal to 226.25. From the quadratic approximation, we also obtain an ambiguity premium of(47)ΠAM(Run)=286.65which refers to the portion of the risk-and-ambiguity premium referring to ambiguity. Thus, John is paying a premium equal to 286.65 to ambiguity.Now, ΠAM(Run) is a function of β. If John reputes this ambiguity premium too high, he can repeat the analysis iterating on value of the ambiguity aversion constant till he finds a value of ΠAM(Run) which is acceptable to him.Thus, using a quadratic approximation a manager has an idea about the price for ambiguity and risk she is paying. Then, she can use the findings to refine the analysis and be reassured about the decision she is to take.

@&#CONCLUSIONS@&#
This paper has discussed the modeling of decision analysis problems in the face of risk and ambiguity. We have investigated the subjective expected utility, minimax and smooth ambiguity (KMM) functionals in addition to the classic vNM theoretical framework. We have determined the corresponding decision analysis problems and the conditions under which they become numerically equivalent.The study of certainty equivalents for smooth ambiguity aversion has followed, with focus on the notion of risk-and-ambiguity premium. We have observed that this premium can be split into a portion related to risk aversion and a portion related to ambiguity aversion by exploiting a recently proposed quadratic approximation of smooth ambiguity certainty equivalents.A rereading of the Ellsberg’s paradox in a decision analysis perspective has helped us illustrating our findings. The analysis of well known Carter racing case study has allowed us to propose a procedure to ambiguity modeling that naturally complements current practical approaches.The findings show that by the explicit quantification of ambiguity attitudes, we are able to systematically evaluate the impact of alternative specifications of the decision maker tastes for ambiguity and risk, to appreciate the ambiguity premium, gaining a quantitative understanding about the impact of uncertainty and of our attitudes toward it.