@&#MAIN-TITLE@&#
Lightning search algorithm

@&#HIGHLIGHTS@&#
Totally new optimization method inspired by lightning phenomena is introduced.The concept of projectiles and channel forking is adopted for movement of step leaders.Three types of projectiles are modeled as search mechanisms of LSA.The result of the LSA provides better results compared with the other tested methods.

@&#KEYPHRASES@&#
Benchmark functions,Constrained optimization,Lightning search algorithm,Nature-inspired algorithms,

@&#ABSTRACT@&#
This paper introduces a novel metaheuristic optimization method called the lightning search algorithm (LSA) to solve constraint optimization problems. It is based on the natural phenomenon of lightning and the mechanism of step leader propagation using the concept of fast particles known as projectiles. Three projectile types are developed to represent the transition projectiles that create the first step leader population, the space projectiles that attempt to become the leader, and the lead projectile that represent the projectile fired from best positioned step leader. In contrast to that of the counterparts of the LSA, the major exploration feature of the proposed algorithm is modeled using the exponential random behavior of space projectile and the concurrent formation of two leader tips at fork points using opposition theory. To evaluate the reliability and efficiency of the proposed algorithm, the LSA is tested using a well-utilized set of 24 benchmark functions with various characteristics necessary to evaluate a new algorithm. An extensive comparative study with four other well-known methods is conducted to validate and compare the performance of the LSA. The result demonstrates that the LSA generally provides better results compared with the other tested methods with a high convergence rate.

@&#INTRODUCTION@&#
Optimization is a process of finding the best solution. Solutions are labeled good or bad after determining the objective function that states the relations between system parameters and constraints. The objective function is often formulated based on application, and it can be in the form of fabrication cost, process efficiency, and so on.Numerous techniques have been used to deal with optimization problems. Most classical point-by-point methods (e.g., direct methods and gradient-based methods) use a deterministic procedure to reach the optimum solution [1]. However, finding the optimum solution for such problems using classical techniques becomes complicated as the size of the search space increases with the dimension of the optimization problem [2]. Recently, computational intelligence optimization algorithms have been extensively used to solve complex optimization problems in various domains, including science, commerce, and engineering, because of their ease of use, broad applicability, and global perspective.Computational intelligence optimization algorithms are nature-inspired computational methodologies that address complex real-world problems. These algorithms can be further divided into swarm intelligence methods and evolutionary algorithms (EAs). Swarm intelligence optimization algorithms generally use reduced mathematical models of the complex social behavior of insect or animal groups. The most popular swarm intelligence methods are particle swarm optimization (PSO) [3], artificial bee colony (ABC) [4], and ant colony optimization (ACO) [5]. The PSO mimics the movements of bird flocking or fish schooling [6]. Inspired by the food-searching mechanism of honey bees, the ABC method uses the foraging behavior of these insects [7]. Meanwhile, ACO was developed based on the behavior of ants when seeking the optimal path between their colony and food source [5]. However, these swarm intelligence methods are limited by factors such as trapping in local minima and premature convergence [6–8]. To overcome these problems, variants of these algorithms have been developed with superior performance [6,8–10]. Other swarm intelligence methods, such as the gravitational search algorithm (GSA) [11], the harmony search algorithm (HSA) [12], biogeography-based optimization [13], and the grenade explosion method [14], have also been developed.EAs derive their working principles from natural genetic evolution. At each generation, the best individuals of the current population survive and produce offspring resembling them; hence, the population gradually comprises enhanced individuals. Operations such as recombination, crossover, mutation, selection, and adaptation are involved in this process [15]. The renowned paradigms of EAs are the genetic algorithm (GA) [15], evolutionary programming [16], differential evolution [17], evolutionary strategy [16], and genetic programming [18]. These algorithms are based on the principles of Darwinian theory and evolution theory of living beings. However, each algorithm follows specialized recombination, crossover, mutation, selection, and adaptation strategies. Similar to other metaheuristic algorithms, the aforementioned methods also have some drawbacks, such as slow convergence rate, difficulty in solving multimodal functions, and stagnation in local minima [19–21]. Advanced versions of EAs have been developed in recent years to improve the efficiency and performance of the aforementioned EAs; these advanced algorithms include stud genetic algorithm [21], fast evolutionary programming [20], adaptive differential evolution algorithm [22], and covariance matrix adaptation evolution strategy [23]. Not all algorithms and their variants provide superior solutions to some specific problems. Therefore, new heuristic optimization algorithms must be continuously searched to advance the field of computational intelligence optimization.This study aims to introduce a novel metaheuristic optimization method called the lightning search algorithm (LSA) to solve constraint optimization problems. The LSA is based on the natural phenomenon of lightning. The proposed optimization algorithm is generalized from the mechanism of step leader propagation. It considers the involvement of fast particles known as projectiles in the formation of the binary tree structure of a step leader. Three projectile types are developed to represent the transition projectiles that create the first step leader population N, the space projectiles that attempt to become the leader, and the lead projectile that represent the best positioned projectile originated among N number of step leaders. The probabilistic nature and tortuous characteristics of lightning discharges, which depend on the type of projectile, are modeled using various random distribution functions. The LSA is explained in depth in Section 4.Many real-world optimization problems involve non-linearities and complex interactions among problem variables. Therefore, the capacity of nature-based algorithms to solve different optimization problems effectively and efficiently must be increased. Increasing the problem-solving capacity of these algorithms is generally achieved by modifying existing algorithms, hybridizing algorithms, and developing new algorithms. Several computational intelligence optimization algorithms have been proposed to overcome the limitations of their predecessors. The following descriptions highlight the recent methods published in the scientific literature.The bat-inspired algorithm is a metaheuristic optimization algorithm developed by Xin-She Yang in 2010 [24]. The bat algorithm is based on the echolocation behavior of microbats with varying pulse rates of emission and loudness. Each virtual bat flies randomly with a velocity viat position (solution) xiwith a varying frequency or wavelength and loudness Ai. As the bat searches and finds its prey, the frequency, loudness, and pulse emission rate r are modified using a frequency-tuning technique to control the dynamic behavior of a swarm of bats. Search is intensified by a local random walk. The update of the velocities and positions of bats is similar to the standard updating procedure of PSO [24]. However, the bat algorithm features an intensive local search control, which is implemented by adjusting the loudness and pulse rate. The selection of the best continues until certain stop criteria are met. The main drawback of the standard bat algorithm is the abrupt switching to the exploitation stage by quickly varying A and r. This quick variation may lead to stagnation after the initial stages [25]. Many researchers have recognized this limitation of the bat algorithm and provided strategies to enhance the performance of this algorithm [26–28]. These strategies include using fuzzy logic [26], chaotic sequence [27], deferential operator, and Levy flight concepts [27,28].The FA is a novel nature-inspired metaheuristic algorithm that is used to solve continuous multi-objective optimization problems based on the social behavior of fireflies [29]. The FA is an efficient technique for searching the Pareto optimal set, and its success rate and efficiency are better than those of PSO and the GA for both continuous and discrete problems [30]. The standard FA involves two important issues, namely, variation of light intensity I and formulation of attractiveness β. The attractiveness between fireflies is formulated as a function of the square of distance r between each other and the light absorption coefficient γ. As the fireflies search for the best solution, their movements are updated based on their current position, attractiveness, and a randomization term. When γ tends to be zero, the FA corresponds to the standard PSO [30]. However, the FA is superior to other algorithms because it is capable of automatic subdivision and dealing with multimodality [31].Modeled based on the EA, the BSA is aimed at solving problems that are frequently encountered in EAs, such as excessive sensitivity to control parameters and premature convergence. Similar to the conventional EA, the BSA involves five processes, namely, initialization, initial selection, mutation, crossover, and second selection. In the initial selection, the BSA calculates the historical population as an indicator of the search direction. It can also redefine historical population at the beginning of each iteration in such a way that a population belonging to a randomly selected previous generation acts as a memory until it is changed. The mutation and crossover strategies of the BSA are different from those of the EA and its advanced versions. In generating trail population, only one parameter is used to control the amplitude of the search direction matrix in the mutation phase. However, crossover is complex. Two strategies are used to generate the final trial population. The first strategy uses mix rate to control the number of elements of individuals that will mutate in a trial, and the second strategy allows only one randomly chosen individual to mutate in each trial. In the second selection stage of the BSA, the population is updated using greedy selection, in which only individuals with high fitness values in the trail population are used. Despite its simple structure, the BSA may be memory and time consuming in computation because of the use of the dual population algorithm [32].The KHA is a newly developed swarm intelligence approach for optimization tasks based on the herding behavior of krill individuals [33]. It is a population-based method that consists of an idealized swarm of krills, each of which travels through a multi-dimensional search space to search for food. In the KHA, the positions of krill individuals are considered as different design variables, and the distance of the food from the krill individuals is equivalent to the fitness value of the objective function. In addition, krill individuals alter their position and travel to better positions. The position of each individual is affected by three principal processes: (i) movement affected by other krill individuals, (ii) foraging activity, and (iii) random diffusion [33,34]. The KHA is advantageous because it only requires a few control parameters to regulate. However, the KHA is principally based on random walks during search. It cannot consistently maintain the convergence area to the global optimum value. To improve this premature convergence problem, a krill migration operator was introduced in [35] during krill updating.The TLO algorithm was first introduced by Rao et al. [36]. Similar to other nature-inspired algorithms, the TLO is also a population-based method that uses a population of solutions to proceed to the global solution. The TLO is based on the interaction between students and a teacher in a class [36,37]. The population consists of the learners and the teacher. This algorithm aims to enhance the overall knowledge of the class. In this algorithm, the optimization process is based on two phases, namely, teacher and learner. The teacher phase simulates the learning process from the teacher, and the learner phase mimics learning from other students in the class. In the teacher phase, the students increase their understanding by learning from the teacher. Therefore, in this phase, a good teacher is one who can transmit his or her knowledge to the class [36]. The learner phase is based on the interaction among students. Students can learn from one another through interaction and sharing. These two phases should be applied to students. The principal drawback of the algorithm is that it uses a single teacher concept and a constant teaching factor. The use of a single teacher may cause premature convergence while a constant teaching factor may increase the computation time [37,38]. Many techniques such as the use of multiple teachers and adaptive teaching were suggested in [38,39].The SSO algorithm, which is based on the simulation of the cooperative behavior of social spiders, was first introduced by Erik Cuevas et al. in 2013 [40]. In the SSO algorithm, individuals imitate a swarm of spiders that interact based on the biological laws of the cooperative colony. The algorithm considers two search agents (spiders): males and females. Depending on sex, each individual is conducted by a set of different evolutionary operators that mimic different cooperative behaviors that are typically found in the colony. This procedure incorporates computational mechanisms to avoid critical faults typically present in the popular PSO and ABC algorithms; such faults include premature convergence and the incorrect exploration–exploitation balance [41].The concept behind the development of the DSA is the seasonal migration of different species in search of fruitful living. All organisms form a superorganism and start moving together to discover efficient habitats. During their journey, the individuals of the superorganism check whether their randomly chosen locations meet their transitory criteria. If any location is appropriate for their temporary layover during the journey, the individuals of the superorganism that revealed the stopover immediately settle in that location and carry on their journey from that location. During a stopover, the superorganism tries to explore the sites in the area left between the organisms using a random process similar to the Brownian-like random walk. Then, donors are made by reshuffling all individuals of the superorganism. These donors are appropriate in discovering the stopover site. Randomly selected members of the superorganism move toward the target of the donors to successfully discover the stopover site. This change in site allows the superorganism to continue its migration toward the global minimum. The DSA is suitable for multimodal optimization problems because it has no inclination to correctly select the best possible solution for a given problem. However, similar to PSO, the DSA has two control variables for fine tuning based on the problem under consideration. Further details on the DSA can be found in [42].The CSA is a metaheuristic optimization algorithm first developed by Yang and Deb in 2009 [43] and further developed by Rajabioun [44]. It was inspired by the lifestyle of cuckoo birds. The egg laying and breeding properties of cuckoos are the main concepts used in this algorithm. Each individual cuckoo in the algorithm has a habitat around which it starts to lay eggs. Surviving eggs grow and become mature cuckoos. Then, cuckoos move toward the best habitat to mate. The change during the travel toward the target habitat motivates the population to search for other areas. After some immigration events, all cuckoo populations gather in the same habitat, that is, the area's best position [44]. However, the performance of the CSA is affected by algorithm-dependent control parameters, such as egg laying radius [45].Lightning is a fascinating and impressive natural phenomenon. The probabilistic nature and tortuous characteristics of lightning discharges originate from a thunderstorm. Among the common displays of lightning, downward negative cloud-to-ground lightning flashes (Fig. 1) are the most studied event in lightning research [46].During a thunderstorm, charge separation occurs within the cloud, usually with a positive charge above and a negative charge below. This process creates a strong electric field. Free electrons generated by cosmic radiation or natural radioactivity are generally attached to oxygen molecules to form negative ions [47]. However, under high electric fields, a fraction of the electron velocity distribution possesses enough energy to ionize air, thereby generating additional electrons along with the original ones.When one of these free electrons is accelerated by the electric field in the region where ionization probability is higher than attachment probability, an electron avalanche occurs. This phenomenon eventually causes a negative corona streamer. Nonetheless, the streamers are weak and become electrically isolated from their point of origin when the ionization probability is lower than the attachment probability.The so-called streamer-to-leader transition occurs at high electron densities and temperatures when narrow channels are thermalized. The negative or the step leader's movement from cloud to ground is not continuous but progresses through regular and discrete steps. For the leader to progress, a leader section in the vicinity in front of the old leader channel, called a space leader, develops from the preceding corona streamers. The space leader propagates backward until it connects to the old leader channel forming a long channel with a tip having the same electric potential [48]. A current wave is generated during this process.When this current wave reaches the tip of the new leader, a burst of corona streamers again propagates out in front of the new tip. Afterward, a new space leader originates in front of the current leader tip. The process is then repeated. The development is a stochastic growth process in which the probability of a step to grow in a certain direction is determined by the state of the medium and the projection of the local electric field in this direction [46,49].As the step leaders approach the earth, high-density negative charges at the leader tip stimulate a concentrated positive charge on Earth. When the electric field intensity resulting from the positive charges near the ground becomes large enough, upward positive streamers from the ground are initiated, and the step leader bridges the gap as they move their way down. This phenomenon determines the lightning strike point and the main lightning current path between the cloud and the ground. The step leader is not the lightning strike; it only maps the optimal course that the strike will follow.The proposed optimization algorithm is generalized from the hypothesis presented in [50] as a mechanism of step leader propagation. It considers the involvement of fast particles known as projectiles in the formation of the binary tree structure of the step leader and in the concurrent formation of two leader tips at fork points instead of a conventional step leader mechanism that uses the concept of streamers described above.Hydrogen, nitrogen, and oxygen atoms can be found near the region of thunderclouds. During the intensive freezing of water molecules within a thundercloud, a portion of the water molecules unable to fit in the ice structure are squeezed out of the forming ice at intense speeds. The oxygen and hydrogen atoms are separated during the process and ejected in a random direction as projectiles. After being ejected from the thunder cell, the projectile travels through the atmosphere and provides an initial ionization path or channel through collision and transition to the step leader. In the proposed algorithm, each projectile from the thunder cell is assumed to create a step leader and a channel. In other words, the projectile represents the initial population size. The concept of projectile is highly similar to the term “particle” or “agent” used in PSO and the GSA, respectively. The projectiles suggest random solutions for corresponding problems to be solved by the LSA. In the present study, the solution refers to the tip of the current step leader's energy Ec.A projectile that travels through the atmosphere under normal conditions loses its kinetic energy during elastic collisions with molecules and atoms in the air. The velocity of a projectile is given as(1)vp=1−1/1−(v0/c)2−sFi/mc2−2−1/2where vpand v0 are the current velocity and initial velocity, respectively, of the projectile; c is the speed of light; Fiis the constant ionization rate; m is the mass of the projectile; and s is the length of the path traveled.Eq. (1) clearly shows that velocity is a function of leader tip position and projectile mass. When the mass is small or when the path traveled is long, the projectile has little potential to ionize or explore a large space. It can only ionize or exploit the nearby space. Therefore, the exploration and exploitation abilities of the algorithm can be controlled by using the relative energies of the step leaders.Another important property of a stepped leader is forking, in which two simultaneous and symmetrical branches emerge. This phenomenon rarely occurs because of nuclei collision. Any additional channel created during forking increases the number of projectiles by one and hence the population size. In the proposed algorithm, forking is realized in two ways. First, symmetrical channels are created because the nuclei collision of the projectile is realized by using the opposite number as in Eq. (2)[51].(2)p¯i=a+b−piwherep¯iand piare the opposite and original projectiles, respectively, in a one-dimensional system; a and b are the boundary limits. This adaptation may improve some of the bad solutions in the population. If forking does not improve channel propagation in the LSA, one of the channels at the forking point is illuminated to maintain the population size.In the second type of forking, a channel is assumed to appear at a successful step leader tip because of the energy redistribution of the most unsuccessful leader after several propagation trials. The unsuccessful leader can be redistributed by defining the maximum allowable number of trials as channel time. In this case, the population size of step leaders does not increase.Three projectile types are developed to represent the transition projectiles that create the first-step leader population N, the space projectiles that attempt to reach the best leader position, and the lead projectiles that represent the best position among N numbers of step leaders. In this case, a one-dimensional projectile type is illustrated for clarity.As mentioned previously, a leader tip is formed at an early stage because the transition forms an ejected projectile from the thunder cell in a random direction. Therefore, it can be modeled as a random number drawn from the standard uniform probability distribution on the open interval representing the solution space. The probability density function f(xT) of the standard uniform distribution can be represented as(3)f(xT)=1/b−afora≤xT≤b0forx<aorxT>bwhere xTis a random number that may provide a solution or the initial tip energy Esl_iof the step leader sli; a and b are the lower and upper bounds, respectively, of the solution space. For a population of N step leaders SL=[sl1, sl2, sl3, …, slN], N random projectilesPT=[p1T,p2T,p3T,…,pNT]that satisfy the solution dimension are required.Once the N step leader tips are evolved, the leaders need to move using energetic projectiles by ionizing the section in the vicinity of the old leader tip in the next step step+1. The position of the space projectilePS=[p1S,p2S,p3S,…,pNS]at step+1 can be partially modeled as a random number generated from the exponential distribution with shaping parameter μ. The probability density function f(xS) of an exponential distribution is given by(4)f(xS)=1μe−xS/μforxS≥00forxS≤0Eq. (4) shows that the space projectile position or the direction in the next step can be controlled by shaping parameter μ. In the LSA, μifor a specific space projectilepiSis taken as the distance between the lead projectile pLand the space projectilepiSunder consideration. With this definition, the position ofpiSat step+1 can be written as(5)pi_newS=piS±exprand(μi)where exprand is an exponential random number. IfpiSis negative, then the generated random number should be subtracted because Eq. (4) only provides positive values. However, the new positionpi_newSdoes not guarantee stepped leader propagation or channel formation unless the projectile energyEp_iSis greater than the step leader Esl_ito extend the channel or until a good solution is found. Ifpi_newSprovides a good solution at step+1, then the corresponding stepped leader sliis extended to a new positionsli_new,andpiSis updated topi_newS.Otherwise, they remain unchanged until the next step. Ifpi_newSextendssli_newbeyond the recent, most extended leader during this process, then it becomes the lead projectile.Presumably, the step leader that has traveled nearest to the ground and the projectile associated with it do not have enough potential to ionize large sections in front of the leader tip. Therefore, the lead projectile can be modeled as a random number drawn from the standard normal distribution with the shape parameter μ and the scale parameter σ. The normal probability density function f(xL) is expressed as(6)f(xL)=1σ2πe−(xL−μ)2/2σ2Eq. (6) shows that the randomly generated lead projectile can search in all directions from the current position defined by the shape parameter. This projectile also has an exploitation ability defined by the scale parameter. In the LSA, μLfor the lead projectile pLis taken as pL, and the scale parameter σLexponentially decreases as it progresses toward the Earth or as it finds the best solution. With this definition, the position of pLat step+1 can be written as(7)pnewL=pL+normrand(μL,σL)where normrand is a random number generated by the normal distribution function. Similarly, the new lead projectile positionpnewLdoes not guarantee step leader propagation unless the projectile lead projectile energyEp_iLis greater than the step leader Esl_ito extend to a satisfactory solution. IfpnewLprovides a good solution at step+1, then the corresponding step leader sliis extended to a new positionslL_new,and pLis updated topnewL.Otherwise, they remain unchanged until the next step, as in the case of the space projectile.The whole procedure of the LSA is summarized as a flowchart in Fig. 2.The flowchart and the details given in Section 4 can be used as bases to develop a program code for executing the LSA in any programming language. In this section, the benchmark Sphere function is used to visualize and show the functionality of the LSA. The Sphere function in this illustrative example has two variables, and the number of step leaders created by the transition projectiles in this example is assumed to be 5. Thus, population size is 5×2. The LSA aims to find the global minimum of the two-dimensional Sphere function given in Eq. (8). In this case, the global minimum occurs when x1 and x2 are equal to zero. The search domain is defined as −100≤x, y≤100.(8)f(x)=∑i=1nxi2Five locations of the individual step leaders and the propagations of their channels from its creation using transition projectile (initialization) until the 11th iteration are graphically exhibited in Fig. 3. The status, channel elimination steps, forking events, and projectile movements are clearly shown in the figure. The numerical position of each step leader in the search domain after the 2nd, 5th, 8th, and 11th iteration are shown in Fig. 4(a)–(d). The location of the step leaders moves toward the global minimum and converges as the number of integration increases. From this example and the procedure given in Fig. 2, it should be noted that the main complexity of the LSA lies in the forking mechanism and channel elimination procedure. Furthermore, it is also important to observe that the channel time is the only algorithm dependent parameter of the LSA that requires tuning. Experiments shows that channel time counter with 1–5 percent of the predefined maximum iteration number provide excellent results for most of the benchmark problems.The proposed LSA is first tested and validated using a well-utilized set of 23 benchmark functions created by Rashedi et al. [11], Rao et al. [38], and Yao [20] while developing their optimization algorithms. These functions are characterized as linear, non-linear, continuous, discontinuous, unimodal, multimodal, convex, non-convex, separable, and non-separable. However, functional characteristics such as modality, separability, and dimensionality are considerably important when testing and validating a new algorithm. The modality of a function refers to the number of vague peaks in the function surface. A function is multimodal if it has two or more vague peaks. An algorithm that encounters these peaks while searching may be trapped in one of the local minima. Meanwhile, separability indicates the difficulty level of various benchmark functions. Typically, separable functions are easier to solve than non-separable functions because each variable of a function is independent of the other variables. The difficulty of a problem also increases with function dimensionality. For highly non-linear problems, dimensionality may be a significant barrier for almost all optimization algorithms. In this study, the first 23 benchmark functions are categorized based on modality and separability, and four tests are conducted to evaluate the reliability and efficiency of the proposed algorithm. Secondly, one of the most deeply investigated problems in computational mathematics known as the traveling salesman problem (TSP) [52] involving several constrains (considered as 24th benchmark) is given to LSA as a challenging problem in fifth test. In each test, the performance of the proposed algorithm is compared with other standard heuristic optimization methods, namely, DSA, BSA, FFA, PSO and HSA. For a fair comparison, the population size and maximum iteration are set to 50 and 500, respectively, in all cases. The algorithm-dependent parameter settings for each algorithm in the comparison are listed in Table 1as recommended in the literature [3,12,29,32,42].This test is conducted to evaluate the reliability and efficiency of the LSA in searching the global minimum value when it is subjected to benchmark functions with unimodal and separable characteristics. Table 2presents the details of these functions. This test also compares the LSA with four other methods, namely, DSA, BSA, FFA, PSO and HSA, for validation. Each benchmark function is tested 50 times. The results considering the best, worst, average, median, and standard deviation of the objective function are shown in Table 3. The best performance for each function is boldfaced. The LSA reaches the best global minimum or near global minimum for F1 and F2. For F3, the LSA fails to reach the best solution. However, its performance is acceptable because it has the lowest standard deviation and average global minimum value. This result is also clearly observed in the box plot (Fig. 5) constructed from the data obtained from 50 runs. Fig. 5 shows that the performance of the LSA is satisfactory for all three functions because the 25th and 75th percentiles of the samples collected for the LSA fall toward the minimum solution with a narrow interquartile range. Meanwhile, the median of the sample for the case of HSA and PSO (indicated by a red line) is very far from the best solution value for F1 and F3 respectively.During unimodal function optimization, the performances of the algorithms in terms of computation time are almost similar. Therefore, the convergence characteristic curves shown in Fig. 6are using to compare the performance. From the figure, it can be noted that the LSA converges faster than the other methods and thus possesses superior convergence characteristics for this type of function optimization.To observe the performance and consistency of the LSA in solving the unimodal and non-separable functions, four benchmark functions given in Table 4are experimented on in this test: Schwefel 2.22 (F4), Schwefel 1.2 (F5), Schwefel 2.21 (F6), and Rosenbrock (F7). These functions have the same dimensions (n=30) as those used in Test 1, but the difficulty level is higher because these functions are non-separable. The test results acquired using the LSA are compared with those obtained using the four optimization methods (Table 5). The best performance for each function is boldfaced. Table 5 shows that the LSA can find the best near-optimum solution for functions F4, F5, and F7. For F6, the FFA finds a better solution compared with the LSA. To determine the consistency and overall performance of the LSA, the data obtained from 50 runs are plotted (Fig. 7). The performance of the LSA is relatively satisfactory for all the four tested functions because the 25th and 75th percentiles of the samples collected for the LSA fall toward the minimum solution with a narrow interquartile range. Fig. 8shows the convergence characteristic curves of the various optimization methods obtained while solving benchmark functions F4, F5, F6, and F7. Among the various algorithms, the LSA finds the best solutions in less than 200 iterations on average for F4, F5, and F6. The DSA, BSA, HSA and FFA need additional iterations. For F6, the convergence characteristics of the LSA are similar to those of the FFA.In this test, the difficulty level of the optimization problem is increased by using multimodal and separable functions (Table 6). F8 and F9 are high-dimensional problems while F10 and F11 are low-dimensional problems. Each benchmark function is tested again for 50 times. The results considering the best, worst, average, median, and standard deviation of the objective functions are shown in Table 7. The best performance for each function is boldfaced. All algorithms obtain the best global minimum or near-global minimum for F10 and F11. For F8 and F9, the LSA fails to determine the best solution. For F8, the DSA obtains the best solution. For F9, the FFA outperforms the other algorithms in finding the best solution. However, the comparative results shown in Fig. 9show that the performance of the LSA is acceptable because its results are comparable to those of the other algorithms even when finding the solution for the Rastrigin function (F9). These results prove the capability of the LSA to escape from any local minimum.Fig. 10shows that the convergence rate of the LSA is much faster at the initial stages than at the later stages. Here gain the time taken by various algorithms to find the optimum solutions of test functions are comparable and thus the convergence rate of the LSA highlights its advantages.The exploration and exploitation abilities of the proposed LSA are also tested with 12 multimodal and non-separable high- and low-dimensional benchmark functions. Table 8presents the details of these functions. Similar to the previous test analysis, this test also compares the LSA with five other methods, namely, DSA, BSA, FFA, PSO and HSA, for validation using the same statistical indices (Table 9). The best performance for each function is boldfaced. The LSA reaches the best global minimum or near-global minimum for all tested functions. This result confirms the exploration and exploitation abilities of the proposed LSA. Moreover, the box plots shown in Fig. 11show that the performance of the LSA is comparatively satisfactory for most of the tested functions. Nonetheless, for the Shekel 5 test function (F21), the LSA cannot find satisfactory solutions in most of the test runs because the median and the 25th and 75th percentiles of the samples collected for the LSA extend from the true solution. However, for the other Shekel functions (F22 and F23), the performance of the LSA is acceptable because its median is close to the actual solution. The convergence characteristics of selected functions, namely, F14, F17, F19, and F21, are depicted in Fig. 12.The aim of this test is to find the capability of the proposed LSA in finding the solution for one of the most intensely investigated benchmark problems in computational mathematics known as the traveling salesman problem (TSP). In TSP, for a given a list of cities and the distances between each pair of cities, the objective is to find the shortest possible route that visits each city exactly once and returns to the origin city. The way of visiting all the cities is simply the order in which the cities are visited and the ordering is called a tour. It is an NP-hard problem. Table 10presents the details of TSP functions.Like the previous tests, TSP benchmark function is also evaluated again for 50 times with all the tested algorithms. The results considering the best, worst, average, median, and standard deviation of the objective function obtained by LSA, DSA, BSA, FFA, PSO and HAS are shown in Table 11. The LSA again finds the best minimum distance tour for TSP (F24). Moreover, in terms of consistency, LSA performance is acceptable because it has similar standard deviation and lower average global minimum value compared to FFA, PSO and HSA. This can also be clearly seen in the boxplot shown in Fig. 13. Finally for the completeness of the analysis, the optimum tours obtained by various optimization methods utilized in the comparison are given in Fig. 14together with distance matrix and cities locations. From the figure it can be observed that none of the optimization method gives the same tour (results) like what is experienced in solving other benchmark functions. LSA find the best route in the order 4→13→3→12→8→9→17→10→16→7→20→14→18→2→11→5→15→6→1→19 with minimum tour distance of 43.82.

@&#CONCLUSIONS@&#
