@&#MAIN-TITLE@&#
Evidence theory for high dynamic range reconstruction with linear digital cameras

@&#HIGHLIGHTS@&#
We propose a new unbiased method for HDR reconstruction based on evidence theory.Our method allows to locally minimizing the acquisition noise in the HDR image.Our method is adapted for very high dynamic range acquisition.For average user, no setting and no additional information are needed.Our method is less sensitive to object or people in motion into the scene.

@&#KEYPHRASES@&#
High dynamic range,Image processing,Evidence theory,Image capture,

@&#ABSTRACT@&#
With the advent of the digital camera, a common popular imaging processing is high dynamic range (HDR) that aims to overcome the technological limitations of the irradiance sensor dynamic range. In this paper, we will present a new method to combine low dynamic range images (LDR) for HDR processing. This method is based on the theory of evidence. Without a prior knowledge of the sensor intrinsic parameters and no extra data, it allows to locally maximizing the signal to noise ratio over the entire acquisition dynamic. In addition, our method is less sensitive to object or people in motion into the scene that are causing ghost-like artifacts with the conventional methods. This technique require that the camera be absolutely still between exposures or need a translational alignment. Simulation and experimental results are presented to demonstrate both the accuracy and efficiency of our algorithm.

@&#INTRODUCTION@&#
Most camera systems, if not all, present technical limitations which affect the image acquisition quality. On a conventional photography (LDR), the most visible one is the lack of the irradiance dynamic range between natural scenes which produces over or under-exposure depending on the choice of the exposure time. In order to overcome this limitation, the solution commonly used was a combination of photographs acquired at different exposure times to achieve a high dynamic range image (HDR) [1]. But it is really democratized with the arrival of the digital camera [2]. A increase of the irradiance dynamic range is also possible through a variation of the ISO value [3], or for indoor photographs, the power of the light source [4]. In the field of digital photography, the second technological limitation for the irradiance is the data quantization. However, the HDR imaging methods may be used to decrease the quantization step [4,5].To combine a series of image acquisitions to accurately match an HDR image corresponding to the irradiance variations, it is absolutely necessary to estimate the irradiance value for each pixel in every image. Several methods have been published to determine the irradiance response curve of the acquisition system [6,7], the ratios between the exposure times [8] and more complex transformation from cameras [9]. Then, the HDR algorithms would use a weighted average for each pixel to estimate irradiance value. The weighting function enables to limit the noise acquisition and remove over and under-exposed values resulting from long and short exposure times. The first weighting functions suggested in the literature does not have recourse to additional information in relation to the sensor. Only the response curve is necessary to determine the most appropriate weighting function [2,8,7,10] or more simply a hat function to limit the extreme values [6]. To improve the results, weighting functions which use a noise and acquisition model are proposed [11–13,3]. These provide significant improvements in the visual quality of HDR images and the opportunity to use ISO variations [3]. However, these are much more complex to implement as a noise model and the sensor intrinsic parameters are needed (number of electrons per photosite, shot noise, quantization noise, read noise, etc.). Furthermore, the use of all the estimated irradiance values may be problematic in the instance of very high dynamic range. Indeed, it is essential to use a large number of different acquisitions or significant ratio between various exposure times to acquire a very high irradiance dynamic range. An error of a single quantization step for the lowest exposure time is bound to be very prejudicial for the estimation of low irradiance value. Fig. 1shows the evolution of the irradiance estimation error or the size of the quantization step depending on the exposure time. This error is far more important than the image dynamic range in case of the longest exposure time. In addition, viewing HDR images typically use a tone mapping algorithm which compresses the dynamic, on the one hand and increases the visual errors for low irradiance value on the other [14–18].Last, but not least, if an object or person moves during the various acquisitions, ghosts appear in the HDR image. These artefacts are more or less visible subject to the object’s irradiance, the exposure times and the weighting function. Many algorithms are proposed to remove the ghost artefacts in the final result [19–21].In this paper, we propose a new approach to combine the estimated irradiances for each image based on the theory of evidence [22,23]. Our method consists in estimating the most probable irradiance value for each pixel, according to the predictions of each acquisition time. Furthermore, our method is more robust to noise acquisition or ghosts following the rejection of the least plausible estimates. It is thus possible to obtain a signal to noise ratio (SNR) which is almost identical across the entire irradiance dynamic range from a large image number. Unlike the last weighting methods, it is not necessary to use a noise model and the intrinsic sensor parameters to obtain an HDR image without noise. Our method is very simple to implement and requires no intervention on the part of the user.This article is broken down into four distinct parts. After a brief presentation of the image formation model, the first one introduces the weighted average method of creating HDR images. In a given case of noise free, we indicate the best irradiance estimate with the theory of quantization. Then, we introduce our new method for creating HDR images and demonstrate, in this section, that our approach by the theory of evidence can easily use the weighting functions of the weighted average methods. Finally, we evaluate the performance of our method using simulations and real acquisition examples. In the case of linear digital camera, we demonstrate the performance of our method even though no information relating to the sensor is available. Finally, we demonstrate that our method directly remove the ghosts on a real acquisition.A digital camera is used to convert the light flow into digital values usable by a computer [24]. In a typical image formation model, image irradiance E received by the sensor is related to scene radiance L:(1)E=Lπ4dh2cos4ϕ=Lkwhere h is the focal length of the imaging lens, d is the diameter of its aperture andϕis the angle subtended by the principal ray from the optical axis. Additional optical effects may alter this relationship but these, are calibrated separately. If the imaging system is ideal, the irradiance E expressed in units of electrons per second is converted into photoelectrons by the image sensor in proportion to the exposure time t:(2)I=minEtg+I0+n,Imaxwhere g is the sensor gain which is based on ISO value,I0is a constant offset representing the black point,Imaxis the maximum number of electrons that can be captured and n is the signal and gain-dependent sensor noise. Numerous analog and digital processing are applied to the number of electrons I to obtain a numerical value M:(3)M=f(I)with0<M<2Q-1wheref()is a response function of the acquisition system and Q is the number of bits for quantizing information. For mono-CCDs [25], this function is linear. However, additional processing need to be added in order to obtain a color image such as demosaicing, white balance and data compression. Within the framework of our study, we consider that each image pixel has three linear and independent sensors where only the noise n can alter the measurement. To model the essential properties of noise, we treat the noise as a zero-mean random variable, the variance of which comes from three independent sources [3]:(4)Var(n)=Etg2+σread2g2+σADC2where the first term represents the Poisson distribution of photon arrivals. The other terms represent the readout noise and the analog to digital conversion noise (ADC) which are independent of the scene. Image-dependent noise can be estimated from multiple or a single images [26,27]When the functionf()is known, it is possible to overcome the irradiance range limitations of photographic sensors in terms of dynamic range [2,6,8] or quantization step [5,4]. The idea is to combine a series of U images where exposure timetuor gainguis changed at a fixed or variable ratioχ=tutu+1∀u. For each given image u and each pixel, the aim is to estimate an irradiance valueE^uthat would produce a frame of discernmentθ-=E^1,E^2,…,E^UwhereE^u=gtuf-1MuandMu∀u,(Mu⩾0∧Mu<2Q-1)are not a over or under-exposed value. The combination of these values should limit the impact of noise n on the estimated irradianceE^.The traditional method (WA) combines the LDR estimated irradiance valuesE^uof the frame of discernmentθ-with a weighted average:(5)E^WA=∑uω(Mu)×E^u∑uω(Mu)whereω(Mu)is a weighting function intended to reduce the noise and to exclude the limit values. There are several functions available in the literature and a review of weighting schemes is proposed in [13,12] for linear and logarithmic domains. In the case of noise free acquisition, the estimated irradiance is a function of the weighting function and ratioχbetween exposure times (Fig. 2). Whenχ=0.5andU=2, half estimated irradiance values are dependent on the weighting functionω. Whenχ>0.5and for a same U, the number of possible solution for the final estimated irradiance values is far more important. However, these values are highly dependent on the weighting functionω. For a noise free case, the problem of the weighted average method arises from combining all the values of the frame of discernmentθ-. Indeed, the theoretical noise free simulation shows that only one value is close to the real irradiance value and the use of the other values will introduce an error (Fig. 3). According to the theory of linear quantization and in the noise free case, all values ofθ-are inferior or equal to the real irradiance:E^u⩽E∀u. Thus, the maximum estimation error is equal to the quantization step. As part of the LDR image, the maximum error is the quantum of the analog to digital conversion:(6)∊q=(Et/g)2Q-1whenEt/g=ImaxFor HDR images, this error evolves depending on the real irradiance value and∊qminis obtained fortmax. In order to reduce the quantization noise, it would be much better to use a centered quantization. It is therefore necessary to define the frame of discernmentθ+=E^1+,E^2+,…,E^U+whereE^u+=gtuf-1(Mu+1)andE^u+⩾E∀u. In the frame of discernmentθ+, the nearest estimated irradiance of E isE^max=minθ+. Without noise, the optimal solution would be:(7)E^MM=E^max+E^min2In free noise case, a voltage equivalent to a half quantization step may be added before the analog to digital converter to limit the quantization error to a half step [28]. In practical terms, it is not possible to work out an irradiance value estimation using this method. Indeed, the acquisition noise would reach its maximum level and, hence, HDR images would be extremely noisy.To overcome this problem, we suggest a new approach whereby each exposure time makes a vote on the frame of discernmentθ=θ-∪θ+withϒpossible solutions. For each pixel, each exposure timetudefines a confidence intervalE^u=E^u;E^u+=Auto perform a vote toθ:(8)vuAu=1ifE^j∈Au∀j0otherwisewhereE^jdenotes a singleton assumption of the frame of discernmentθandvuAustands for a possible disjunction of these singleton assumptions. Fig. 4shows an example of a vote withU=3. Without noise, the nearest valuesE^andE^+reach the most positive vote and we achieve the same result asE^MM. To introduce notions of uncertainty for confidence intervalAuand composite hypothesis, we suggest to use the theory of evidence [22,23] to combine all the votesvuand to determine the optimal solution for the real irradiance E. From the frame of discernmentθ, we deduce the set2θof all2ϒsubsets A:(9)2θ=A/A⊆θ=∅,E^1,E^1+,…,E^1∪E^1+,…,θThis set which stands for a reference definition includes not only the singleton assumptions ofθ, but also the set of all possible disjunctions of this assumption. To distinguish the accuracy of a proposal hypothesis from an exposure timetu, the basic probability numbersmθu(·)is allocated to one or more subsets:(10)mθ=2θ→[0,1]and satisfies the following properties:(11)mθ(∅)=0∑A⊆θmθ(A)=1The set of focal elements which are the elements A with the probability numbermθ(A)is not zero, is called the coreNθ:(12)Nθ=A∈2θ/mθ(A)>0In our study, the core is defined as follows:(13)Nθ=v1A1,v2A2,…,vUAUThe contribution of the theory of evidence in relation to voting approach is used to distribute the total probability mass to a subset given by a votevu. Thus, each exposure timetudefines a solution:(14)mθuAu=ω(Mu)mθuAu‾=1.0-ω(Mu)whereω(Mu)may be an adaptation of the weighting function commonly used for HDR image reconstruction. However, this function must be superior or equal to 0.5 which indicates that the intervalAuis more plausible thatAu‾, and strictly less than 1.0 to avoid zero or negative plausibility for the intervalAu‾. Fig. 5shows a possible adaptation of the function used in [6]. This weight functionω(Mu)does not need to be more complex. Undeniably, the theory of evidence allows a suitable combination of mass functions to merge with the confidence interval according to exposition timestu. This combination operator rejects too distant values as opposed to the most plausible one, and is defined as follow:(15)mθ=mθ1⊕mθ2⊕⋯⊕mθUAssuming that the sources are independent, the mass for a subset A from the fusion of two basic probability assignments is defined by:(16)mθ(A)=mθ1⊕mθ2=∑A′∩A″=Amθ1(A′)·mθ2(A″)1-Kwhere(17)K=∑A′∩A″=∅mθ1(A′)·mθ2(A″)Unfortunately, a significant noise in the acquisition may create a conflict between votesvuand the fusion of two basic probability assignments does not exist. Fig. 6shows a representation of the fusion with or without conflict. To take into account the noise in the images, we suggest to distribute all the mass on the neighbor quantization steps for a proposal made by a confidence intervalE^u. Hence, for a pixel, each LDR image performs a series of votes on the frame of discernmentθ. The mass assigned to each of these votes is the function to the number of quantization steps in comparison with the confidence interval. The mass functionmθuvu+ncorrespond to the vote for the image u plus or minus n quantization steps in comparison with the confidence intervalAu=E^u. Fig. 7illustrates an example of fusion of two pixels with a multilevel voting. In this example, the votes of LDR1 and LDR2 images are contradictory, the fusion of all the votes shows that the solution is betweenE^1+andE^2. It is possible to define, for each value, a measure of credibility Cr or a measure of plausibility Pl, and which would be defined through the following equations:(18)Cr(A)=∑A′⊂Amθ(A′)Pl(A)=∑A′∩A≠∅mθ(A′)The example shown in Fig. 7 demonstrates that the plausibility of all hypotheses is always equal to 1. In other words, the plausibility measures the total belief mass that can move into A. For one shutter timetu, the confidence associated with each intervalAuis complete. So, the acquisition noise introduces an estimation error for the irradiance value and makes plausible each solution. In contrast, the credibility of a subset A is the sum of the belief mass associated with hypotheses involving A. It stands for the confidence that may be associated with the subset A if all belief mass involving A were transferred to A. If the acquisition noise is important and for one shutter time only, the probability that an irradiance estimation error occurs becomes important. In the example of Fig. 7, the credibility associated withv1isCr(v1)=0.1and translates as the unlikelihood of having an accurate estimate. By increasing the irradiance interval, i.e. taking into account the neighboring quantization steps, the probability of an accurate estimate increases. Hence, the credibility of having an error greater than 3 quantization steps is zero in this particular example becauseCrv1+3=1. Each of these voting proposals may be weakened in order to take into account the relative reliability of the information provided by the LDR images. Letαu(αu∈[0,1]), the index of reliability associated with the image u according to his reliability, a new basic belief mass set is defined by:(19)mθuα=αu×mθuAu+n∀Au+n≠θmθuα=(1-αu)+αu×mθu(θ)where the functionαumaybe the same as the functionω(Mu)define in Eq. (14). The final outcome is depends on the functions of credibility, plausibility (Eq. (18)) or pignistic probability [29]:(20)∀E^i∈θP(E^i)=∑A∈θE^i⊂A1|A|mθ(A)In this context, the ideal solution is:(21)∀E^i∈θE^ET=maxiFdE^iwhereFdis a function of Eqs. (18) and (20). In practice, and in the presence of conflict between the proposals from the exposure timestu, the maximum plausibility provides the best result [30]. It is certainly possible to take the average or median value of the focal element for which the mass is the most important. The proposed method in [31] illustrates the implement of the algorithms of evidence theory and plausibility is used in this article for the final outcome.For each pixel, our algorithm of high dynamic range image reconstruction was carried out in four steps:1.Create the frame of discernmentθwith U LDR images which definedE^uandE^u+.For each shutter timetu:–define a confidence interval to perform a multilevel votevu+n,define a mass functionmθu·according to all thevu+n,weaken in order to take into account the reliability ofE^uwithαuMuto define the mass functionmθuα·.Perform the fusion of the U basis probability assignments to createmθα·.Compute the function of plausibility for each singleton assumption ofθand estimate E (Eq. (21) withFd·=Pl(·)).

@&#CONCLUSIONS@&#
