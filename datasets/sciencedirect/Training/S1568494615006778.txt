@&#MAIN-TITLE@&#
Two hybrid wrapper-filter feature selection algorithms applied to high-dimensional microarray experiments

@&#HIGHLIGHTS@&#
We propose two new, simple, and efficient Hybrid Feature Selection techniques.We use a feature-based ranking to initialize the Binary Differential Evolution.We also propose a new fitness function influenced by the features in the population.Several statistical tests show the robustness and effectiveness of the proposals.The reducing of the size of the original set of features is larger than 99%.

@&#KEYPHRASES@&#
Hybrid Feature Selection,Binary Differential Evolution,High-dimensional data set,Microarray,

@&#ABSTRACT@&#
Microarray experiments generally deal with complex and high-dimensional samples, and in addition, the number of samples is much smaller than their dimensions. Both issues can be alleviated by using a feature selection (FS) method. In this paper two new, simple, and efficient hybrid FS algorithms, called respectively BDE-XRankand BDE-XRankf, are presented. Both algorithms combine a wrapper FS method based on a Binary Differential Evolution (BDE) algorithm with a rank-based filter FS method. Besides, they generate the initial population with solutions involving only a small number of features. Some initial solutions are built considering only the most relevant features regarding the filter method, and the remaining ones include only random features (to promote diversity). In the BDE-XRankf, a new fitness function, in which the score value of a solution is influenced by the frequency of the features in the current population, is incorporated in the algorithm. The robustness of BDE-XRankand BDE-XRankfis shown by using four Machine Learning (ML) algorithms (NB, SVM, C4.5, and kNN). Six high-dimensional well-known data sets of microarray experiments are used to carry out an extensive experimental study based on statistical tests. This experimental analysis shows the robustness as well as the ability of both proposals to obtain highly accurate solutions at the earlier stages of BDE evolutionary process. Finally, BDE-XRankand BDE-XRankfare also compared against the results of nine state-of-the-art algorithms to highlight its competitiveness and the ability to successfully reduce the original feature set size by more than 99%.

@&#INTRODUCTION@&#
Microarrays are tools which are capable of reporting, simultaneously and in a single testing, thousands of gene expression levels. A microarray experiment can be used to analyze samples of cells under different clinical conditions. The information obtained helps to determine the functionality of the genes, and/or helps in understanding biological processes and the effect of certain treatments. However, all of these activities require analyzing and classifying the samples [1].In a microarray, the samples are complex, highly dimensional and prone to contamination with noise. Therefore, the classification requires special techniques such as Machine Learning (ML) algorithms. These techniques construct a classifier using one of at least two main mechanisms: unsupervised and supervised learning [2]. In this paper, the second mechanism is employed because all of the samples have an assigned class value label.Usually, the quantity of samples in microarray experiments is several orders of magnitude lower than the number of genes in the samples. Considering the additional complexity, the ML algorithms are prone to suffer the curse of dimensionality. This anomaly affects both the reliability and the predictive ability of the classifier. To alleviate these effects, the reduction of the number of features by using a feature selection (FS) method must be employed during the classifier's construction.FS algorithms are designed to identify and select the useful features contained in the samples [3]. To find the best features, FS algorithms must interact with ML techniques. According to the type of interaction, FS algorithms can be grouped into two large classes: filter methods and wrapper methods. On the one hand, the filter methods select the best features from a rank of the whole set of features. Despite the simplicity, speed, and computational efficiency, they are unable to detect indirect relationships between features. On the other hand, the wrapper methods employ the information of the classifier to find the best feature subset. Although, they discover indirect relationships between features, they usually perform computationally expensive searches on the feature space [4].Regarding the wrapper methods, an exhaustive search is the simplest technique. However, it is prohibitive in terms of computational cost. To the contrary, the methods based on stochastic searches have a lower computational cost and maintain simplicity. For example, evolutionary algorithms (EAs) find the best solution by exploring the search space with a population of solutions. EAs have proved to be successful in solving FS problems, e.g., Genetic Algorithms [5,6], Ant Colony Optimization [7,8], Particle Swarm Optimization [9,10].Differential Evolution (DE) is one of the simplest and most effective EAs used to solve high-dimensional optimization problems [11]. In microarray problems, DE could take advantage of the usually small number of the most informative features when initializing the population. Considering all the features arranged into a rank, the initial solutions could include only the most relevant features. However, this initialization of the population could cause a premature lack of diversity, and hence DE could converge to a local optimum. To alleviate this pressure, some initial solutions should be randomly generated.The purpose (and contribution) of this paper is to present two simple and thus computationally efficient algorithms to solve the FS problem in microarray experiments. The proposed algorithms integrate both filter and wrapper methods to obtain two hybrid FS methods. The experimental study was carried out using six high-dimensional well-known microarrays in the public domain. Four simple and efficient ML algorithms (Naive Bayesian, Support Vector Machine, C4.5, and k-Nearest Neighborhood) were used to evaluate the robustness, efficiency, and accuracy of the hybrid FS technique. It is worth mentioning that the simplicity of the four ML algorithms employed prevents an additional increase in the complexity of the proposed technique. The conclusions drawn were validated with several statistical tests. In addition, this paper also introduces a new and interesting fitness function. More precisely, the score of a solution is modified according to the frequency with which of their features appear inside the population.The rest of this paper is organized as follows. Section 2 briefly summarizes the recent developments in hybrid FS methods, including the use of DE as an efficient feature selection method. A detailed description of preliminary concepts is presented in Section 3. The hybrid wrapper-filter FS algorithm is outlined in Section 4. An extensive experimental study and the introduction of a new fitness function is shown in Section 5. Finally, the conclusions and future work are explained in Section 6.Further to briefly reviewing the DE-based FS technique, this section presents a summary of the main approaches related to hybrid FS methods found in the literature. Indeed, some authors have already studied the advantages of combining a feature ranking technique and a search algorithm to create a hybrid FS method. For instance, Xie and Wang [12] and Peng et al. [13] included a feature ranking in a sequential forward search method. The former applies the F-score measure to rank the features. The latter adds a random sampling method to choose features from the ranking. In [14], Lee et al. incorporated a Fisher criterion based ranking inside a binary search.Other authors have used a search method based on a stochastic technique. Zhang et al. [15] proposed including a ranking based on ReliefF estimation in a Genetic Algorithm. The proposal of Bonilla-Huerta et al. [16] is similar. In this case, the ranking is also employed to reduce the solution search space. In addition, the authors present a novel crossover operator based on Fisher's Linear Discrimination Analysis. Kabir et al. [17] used the information gain of the features to modify an ant's position in the Ant Colony Optimization Algorithm. Undoubtedly, there are several relevant papers that use hybrid FS techniques based on stochastic search methods. However, to the best of the authorsâ€™ knowledge, there are only a few proposals that use DE as part of a hybrid FS algorithm. Indeed, there have only been a few attempts to employ DE inside a wrapper FS method.The DE-based approaches can be grouped into two broad categories on the basis of the representation of the solutions. On the one hand, some authors propose representing the solution in terms of a schema of real-valued vectors. He et al. [18] in a short paper, presented the first of these approaches for solving the FS problem. However, a disadvantageous transformation of the solution representation is needed in order to obtain the feature subset. The island-based model of Marinaki and Marinakis [19] has a similar issue. In both cases, the experimental study was conducted on well-known data sets but with very few features. Khushaba et al. [20] investigated the use of DE with respect to one of its more interesting properties: fast convergence. Due to the representation selected, they had to apply a repair method to avoid solutions with replicated features. Al-Ani et al. [21] proposed a novel wheels-based method to deal with real-value vectors. An unfavorable characteristic of this proposal was having to use an upper bound to limit the number of features in the solutions. The experimental analysis of these two approaches was carried out on data sets with a large number of features. On the other hand, an expensive additional transformation is avoided if a binary vector is employed to represent the feature subset. The proposals for solving the FS problem presented by GarcÃ­a-Nieto et al. [22] and Satapathy and Naik [23] are based on one such a schema. The experimental analysis of both proposals was performed on well-known data sets with few features. In both studies, the results showed the effectiveness of DE selecting a small number of features. However, the first approach reported a huge computational time.Regarding the issue of the huge computational cost, Apolloni et al. [24] tackled this drawback using a rank-based method to create the initial population of a binary version of DE. Although the experimental study is simple, the proposal demonstrated remarkable success in selecting a small and highly accurate subset of features at a low computational cost. However, in [24] it was only used SVM as ML algorithm which it is not enough to claim the robustness of the proposal.

@&#CONCLUSIONS@&#
In this paper, we have proposed two simple and efficient hybrid FS algorithms, named respectively BDE-XRankand BDE-XRankf, to deal with the issues related to the classification process of high-dimensional microarray samples. Both proposals combine a filter method with a wrapper method in a two-stage algorithm. In the first stage, a rank-based filter technique sorts the features by the information gain values. In the second stage, a Binary DE-based wrapper method performs the search for a high quality solution. In addition, in our proposals, the BDE initial population is biased using the ranking of features. Therefore, some initial solutions are generated with only highly relevant ranked features. The others are initialized with only random features in order to include diversity in the initial population. A key characteristic of our proposals is that all the initial solutions are generated with a small number of features. Regarding BDE-XRankf, we incorporate a new fitness function in order to propose an enhanced version of the BDE-XRankalgorithm. The score value computed by the new fitness function is influenced by the frequency of the features present in the current population.Six high-dimensional well-known microarray experiment data sets and four ML algorithms (NB, SVM, C4.5, and kNN) have been used, in an extensive experimental study based on statistical tests, to evaluate BDE-XRankand BDE-XRankf. The reported results have shown the robustness of BDE-XRankand BDE-XRankf. Both algorithms are also able to obtain more accurate solutions than BDE-Xat the earlier stages of the evolutionary search. Despite the absence of significant differences in the final results, BDE-XRankfhas also shown a slight improvement in the final accuracy values with respect BDE-XRank. In addition, the comparison with nine proposals of the state-of-the-art has proven the competitiveness of our BDE-XRankf. We must remark that BDE-XRankfand BDE-XRankare able to reduce the original feature/gene set size by more than 99% and, at the same time, obtain highly competitive results.Future work may include a crossover operator that incorporates the ranking information to improve the performance of BDE-XRankf. Also, an informed local search operator may be applied to speed up the convergence of the evolutionary process. Finally, it may also include a biological analysis of the results because it is information of interest to experts in the field of Biology.