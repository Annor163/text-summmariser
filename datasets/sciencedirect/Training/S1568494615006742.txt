@&#MAIN-TITLE@&#
Galactic Swarm Optimization: A new global optimization metaheuristic inspired by galactic motion

@&#HIGHLIGHTS@&#
A new global optimization meta-heuristic inspired by galactic motion is proposed.The proposed algorithm employs alternating phases of exploration and exploitation.Performance on rotated and shifted versions of benchmark problems is also considered.The proposed GSO algorithm outperforms 8 state-of-the-art PSO algorithms.

@&#KEYPHRASES@&#
Global optimization,Galactic Swarm Optimization,Metaheuristics,Benchmark functions,Stochastic optimization,

@&#ABSTRACT@&#
This paper proposes a new global optimization metaheuristic called Galactic Swarm Optimization (GSO) inspired by the motion of stars, galaxies and superclusters of galaxies under the influence of gravity. GSO employs multiple cycles of exploration and exploitation phases to strike an optimal trade-off between exploration of new solutions and exploitation of existing solutions. In the explorative phase different subpopulations independently explore the search space and in the exploitative phase the best solutions of different subpopulations are considered as a superswarm and moved towards the best solutions found by the superswarm. In this paper subpopulations as well as the superswarm are updated using the PSO algorithm. However, the GSO approach is quite general and any population based optimization algorithm can be used instead of the PSO algorithm. Statistical test results indicate that the GSO algorithm proposed in this paper significantly outperforms 4 state-of-the-art PSO algorithms and 4 multiswarm PSO algorithms on an overwhelming majority of 15 benchmark optimization problems over 50 independent trials and up to 50 dimensions. Extensive simulation results show that the GSO algorithm proposed in this paper converges faster to a significantly more accurate solution on a wide variety of high dimensional and multimodal benchmark optimization problems.

@&#INTRODUCTION@&#
For a myriad of applications such as training of neural nets [1–4], power system optimization [5–7], and signal analysis [8,9] the cost function to be minimized is multimodal (many local minima) and depends on numerous variables (high dimensional). Hence, a global optimization technique that can yield robust performance for high dimensional and multimodal functions is of long standing interest. Global optimization can be defined mathematically as:(1)Minimizef(x)wheref:RD→Ris the function to be minimized and D is the dimensionality of x.It is well known that classical deterministic search methods get stuck in local minimum and do not perform well on high dimensional problems. Heuristic approaches like Genetic Algorithms (GA) [10], Tabu Search (TS) [11,12], Ant Colony Optimization (ACO) [13], Simulated Annealing (SA) [14], Particle Swarm Optimization (PSO) [15] use stochasticity to escape from local minima and are more effective in locating an approximation to the global minimum. The general global optimization problem is a NP-complete problem and hence accurate computation of the global minimum will require exorbitant computational resources. Thus heuristic based algorithms that compute a good local minimum are of interest.This paper addresses the frequently arising problem of single objective optimization of multimodal functions by a new metaheuristic framework called Galactic Swarm Optimization (GSO). This framework increases the efficiency and efficacy of the embedded algorithm by providing multiple cycles of exploration and exploitation, thereby improving the odds of locating the global minimum accurately.The GSO algorithm draws inspiration from the motion of stars inside galaxies and motions of clusters and superclusters of galaxies. Analogous to the motion of stars in galaxies under the attractive influence of large masses, the population of potential solutions is divided into subpopulations where each individual solution is attracted towards better solutions. However on a larger scale, entire galaxies appear as point masses and are attracted to other galaxies. In the GSO algorithm this is implemented by treating the best solution found by individual subpopulations as a superswarm. Movement of members of the population towards better solutions can be implemented with other population based strategies, like GAs.Since PSO algorithm has been used as the demonstration vehicle the proposed strategy is termed as Galactic Swarm Optimization (GSO). However, the strategy by itself can be easily extended to other population based algorithms. The choice of PSO algorithm in this work relies on the fact that, it1can be realized using few lines of code,has faster convergence rate andfree from complex constructs such as mutation/crossover or pheromone.The GSO algorithm continues to possess the above mentioned desirable characteristics. Experimental results consistently support the enhanced ability of the proposed algorithm on multimodal cost functions when compared with the other state-of-the-art PSO versions. The proposed algorithm is also competitive in terms of running time and complexity, measured in terms of function evaluations.The rest of the paper is organized as follows. Section 2 reviews the original PSO algorithm and associated limitations. In Section 3, the structure and intuition behind GSO algorithm is presented. In Section 4, experimental results are summarized and discussed. Finally, Section 5 concludes the paper and gives possible future research directions.The PSO algorithm mimics the behaviour of birds and some other species that collectively search for food [15,16]. The initial swarm or population is a set of points in the D-dimensional search space. The components of the vector x are real numbers. The PSO algorithm is initialized with population of particles (or swarm) randomly inside the search space. The swarm movement is guided by the equation stated below:(2)vid(k+1)←vid(k)+c1ϕ1d(pid(k)−xid(k))+c2ϕ2d(gd(k)−xid(k))(3)xid(k+1)←xid(k)+vid(k)wherevi=[vi1,vi2,⋯,viD]is termed as velocity of the particle i; xi=[xi1, xi2, ⋯, xiD] is the position of the particle i. ϕ1dand ϕ2dare uniformly distributed random numbers which differ for each dimension d. For the PSO version used in the paper, the constants ϕ do not change with dimension. Associated with each particle x(i), there is a personal best p(i), a particle that fetched the least function value during one of the past iterations. Associated with the entire swarm x, there is a global best g, a point that gave the least function value during prior movements. c1 and c2 are the acceleration constants that pull the flying direction towards the local best and global best solutions, respectively.Eq. (2) gives the velocity of the next iteration for a given x(i), p(i) and g. The velocity and position vectors are bounded by the same limits to avoid random relocation of the particle, subsequently losing its normal path and momentum [17]. Eq. (3) indicates that the velocity term is added to the position to update the new position. The personal best is updated with new x(i) if f(x(i))<f(p(i)). In each iteration, the global best is updated with the personal best, if the personal best assumes a smaller function value f(p(i))<f(g).Currently there are numerous varieties of PSOs in existence and for a detailed historical summary the reader is referred to [18,19]. For the PSO version used in this paper inertial weight ω is used to narrow the search space with time. The form of inertial weight used in this paper is different from [20] as better experimental results were obtained with the modified inertial weights used in this paper. The Eqs. (2) and (3) are modified as follows:(4)v(i)(k+1)←ωv(i)(k)+c1ϕ1(p(i)(k)−x(i)(k))+c2ϕ2(g(k)−x(i)(k))(5)x(i)(k+1)←x(i)(k)+v(i)(k)ω is reduced linearly from unity to nearly zero with each iteration.As the inertial weight is gradually reduced the explorative ability of the PSO algorithm decreases and the PSO algorithm might prematurely converge to a poor local minimum. The different versions of PSO algorithm discussed in this paper and elsewhere try to address the problem of premature convergence by making particles learn from the historical best of other particles. The efforts in this direction have yielded limited success.One of the common but important issues with heuristic algorithms, including PSO algorithms is the issue of striking a balance between the exploration and exploitation, each of which is obtained at the cost of the other. Most of the heuristic algorithms, including the PSO variants, work under the premise of highly explorative action at the beginning with a gradual transition to highly exploitative action towards the end. Exploration allows a search algorithm to come close to the global minimum or good local minimum and exploitation helps locate the global minimum accurately. Most optimization algorithms have a learning rate parameter that is reduced with time to explore many potential local minima in the beginning and accurately compute a good solution at the end. The scheme breaks down on multimodal functions if the algorithm converges to a poor local minimum during the exploration stage resulting in suboptimal solution.Galactic Swarm Optimization (GSO) provides multiple cycles of exploration and exploitation by dividing the search in terms of epochs, providing the algorithm more opportunity to accurately locate the global minimum.The original PSO algorithm by Eberhart and Kennedy was inspired by swarming like flocking behaviour in birds and schooling behaviour in fish. Both of these swarms do not perform any global optimization and only provide a mechanism for confusing predators and predator avoidance. Since the original PSO algorithm itself is motivated by swarming behaviour that is associated with swarms that do not perform global optimization it is not necessary for other PSO inspired heuristics as well as they perform well on benchmark test functions.The GSO algorithm emulates the movement of stars, galaxies and superclusters of galaxies in the cosmos [21]. Stars are not distributed uniformly in the cosmos but clustered into galaxies which in turn are not uniformly distributed. On a large enough scale individual galaxies appear as point masses. The attraction of stars inside a galaxy to large masses and galaxies themselves to other large masses is emulated in the GSO algorithm as follows: First, individuals in each subpopulation are attracted to better solutions in the subpopulation according to the PSO algorithm. Secondly, each subpopulation is assumed to be represented by the best solution found by the subpopulation and treated as a superswarm. The individual in the superswarm comprising of the best solutions found by each subpopulation also move according to the PSO algorithm. This approach is general and movement of the swarm and superswarm can be accomplished using other population based optimization algorithms. This is analogous to the members of a particular swarm being attracted towards the global best.On a larger scale, individual galaxies appear to be point masses and can be clustered with neighbouring galaxies to form superclusters of galaxies. In the GSO algorithm a galaxy of stars is analogous to a subswarm and a cluster of galaxies is analogous to the superswarm. The cluster of galaxies is identified with the Centre of Mass (CM) of the galaxies. Similarly each individual in the superswarm represents the global best solution of individual subswarms.This analogy of stars clustered into galaxies and galaxies clustered into clusters and superclusters can be extended further and concepts such as super superclusters can be introduced. However in this paper the analogy is restricted to galaxies of stars and clusters of galaxies.In the GSO algorithm the swarm is a set X of D−tuples containing elements (xj(i)∈RD) consists of M partitions, called subswarms Xi, each of size N. The elements of X are initialized randomly within the search space [xmin, xmax]D. The complete swarm framework is defined by:Xi⊂X:i=1,2,⋯,Mxj(i)∈Xi:j=1,2,⋯,NXi∩Xj=ϕ:ifi≠j⋃i=1MXi=XXiis a swarm of size N. The velocity and personal best associated with each particlexj(i)are represented byvj(i)andpj(i), respectively. The nomenclature used in this paper is summarized in Table 1for convenience.At the first level of clustering, PSO is performed independently for each subswarm. Since the swarm X is subdivided in to M groups, the PSO algorithm is run for M times. Each subswarm Xihas an associated global best g(i) and is updated if any of its personal bestspj(i)happen to take a smaller function value than g(i),f(pj(i))<f(g(i)). Particles in each subswarm are attracted stochastically to the best solution found by that particular subswarm. Since the subswarm gbest usually lies in the vicinity of some local minimum the particles in each subswarm are stochastically attracted towards that local minimum. Also the subswarms do not share good solutions as in other approaches so each swarm is attracted towards its own subswarm best (local minimum) which in some cases might overlap. In the GSO algorithm strict subdivision of search region is not imposed.The movement of a subswarm in Xiis independent and has no influence on another subswarm Xjfor i≠j, thereby allowing an unaffected and comprehensive search possible. To take full advantage of this new found exploration ability of multiple subswarms, a galactic best is defined g which is updated whenever any of the global bests g(i) assumes a lower function value, f(g(i))<f(g). The GSO algorithm keeps record of its best solution by updating g.Rather than having a single swarm exploring towards a particular direction, when multiple swarms are present a synergistic effect can be observed resulting in a much improved exploration.Each subswarm independently explores the search space freely on its own. The iteration begins by computing the velocity and position. The expressions for velocity and position updates are:(6)vj(i)←ω1v(i)+c1r1pj(i)−xj(i)+c2r2g(i)−xj(i)(7)xj(i)←xj(i)+vj(i)where the inertial weight ω1, and the random numbers r1 and r2 are given by(8)ω1=1−kL1+1(9)ri=U(−1,1)k is the current integer iteration number that varies from 0 to L1. Eq. (9) indicates that riis a random number chosen in the range between −1 and 1.Global bests participate in the next stage of clustering to form the superclusters. Analogously, a new superswarm Y is created by collecting the global bests from subswarms Xi.(10)y(i)∈Y:i=1,2,…,My(i)=g(i)The velocity v(i) and position vectors y(i) are updated as per the equations given below:(11)v(i)←ω2v(i)+c3r3(p(i)−y(i))+c4r4(g−y(i))(12)y(i)←y(i)+v(i)where p(i) is the personal best associated with the vector y(i). The defining relations of ω2, r3 and r4 are similar to equations Eqs. (8) and (9). At this level g serves as the global best exemplar and is not updated unless the search locates a better point. Since the superswarm concentrates on the global bests from subswarm, it can enhance the exploitation.The superswarm uses the best solution already computed by the subswarms and hence exploits information already computed. Although the individuals of the superswarm are more spread out compared to the subswarm individuals, the superswarm does not perform independent exploration. The following analogy provides some insight. Consider a team leader summarizing the findings of his team members, the leader does not come up with independent ideas or explores new solutions but simply exploits information given to him by his team members.The global bests of the subswarms influence the superswarms, but there is no feedback effect or information flow from the superswarm to the subswarms to preserve diversity of solutions. Avoiding feedback helps the GSO strategy to retain highly diverse subswarms and constant global search ability every epoch.When the next epoch begins, the search starts from where it left off and continues exploring the space again with the same rigor – the subswarms are not restarted. The first level of the GSO algorithm consisting of motion of the subswarms is primarily an exploratory phase and the second level involving the superswarm is primarily an exploitative phase. Thus the GSO algorithm alternates between exploratory and exploitative phases. Hence, the GSO algorithm gets opportunity to search many more local minima; this is important since any local minimum can potentially be the global minimum. This repeated exploration–exploitation cycle can be intuitively reasoned to be responsible for the superior performance of the GSO algorithm on highly multimodal test functions.The relation between galactic motion and optimization is as follows. Firstly, stellar masses in a galaxy experience a force which is given by the negative gradient of the gravitational potential energy. Thus, stellar masses experience a pull in the direction of greatest decrease in the gravitational potential energy, leading to an optimization like behaviour. In particular the well-known Hamilton's Principle of Least Action states that motion of a system of masses always takes place in such a way so as to minimize or maximize the time integral of the Lagrangian function.Individual masses gravitate towards large masses like in our solar system where individual planets are primarily attracted towards the most massive neighbouring object namely the Sun. In the GSO algorithm this is implemented by moving particles stochastically towards better solutions. Also there are two types of motion associated with galaxies: first is the motion of individual masses inside galaxies and second in the motion of the centre of mass (CM) of the galaxies themselves. In the GSO algorithm this is implemented by updating all the subswarms in Level 1 and then forming and updating the superswarm in Level 2. Motion of the superswarm is analogous to the motion of the centre of masses of the galaxies. This is a good analogy since the CM is not a physical point but a mathematically defined average just like the members of the superswarm.Algorithm 1GSO(f)The position of the galactic best after the final epoch g and its fitness value f(g) are returned as locations of minimum and cost of minimum respectively by the algorithm. The complete pseudocode is given in Algorithm 1.Just like the center of mass (CM) of a system of particles the superswarm has no individual or independent existence but only formed temporarily in Level 2 of the GSO algorithm. Since the superswarm exists only temporarily during Level 2 in the GSO algorithm, this is conceptually as well as computationally different from other multi-population or multi-swarm approaches which usually involve a masterswarm that runs continuously and independently while periodically sharing information with the slaveswarms.Fundamental differences between GSO algorithm and a host of many other multi-swarm PSO variants described in [22–26] are that the flow of information between the subswarms and the superswarm is unidirectional to promote exploration and avoid premature convergence. This one way causality implies that the superswarm does not affect the exploration of the subswarms by injecting good solutions like the multiswarm approaches. Solutions computed by the superswarm are not reinserted or into the subswarms (or the subswarms are regrouped) to promote independent exploration of the subswarms.This effect can also be observed in teams of human problem solvers; if different teams working on a problem share information all of them might converge to the first good solution identified by any one team. Since this independence of subpopulations leading to better performance appears to be a general phenomenon one might formally enunciate it as “the principle of independence of subpopulations of problem solvers”.The superswarm is created from the global bests of individual subswarms, evolves for a period of time, updates the global best solution and dies at the end of Level 2. Thus a new superswarm is created again after the completion of Level 1 each time. Level 1 is primarily an exploratory phase where potential good local minima are identified and Level 2 is an exploitative phase. Superswarm exists only temporarily during Level 2 of the GSO algorithm and has no independent or continuous existence unlike master and slave swarms shown in Niu et al. [27].The superswarm was inspired by the concept of CM of a collection of particles (CM of individual galaxies). The location of the CM of a collection of particles does not necessarily coincide with the location of a physical particle but is a mathematically computed average location having no independent physical existence. Similarly the individuals comprising the superswarm have no individual or continuous existence but are created from the subswarm global best solutions and die after completion of Level 1. Thus, the motion of the superswarm represents the motion of galactic CM points.Tables 2 and 3list the benchmark functions that are used to compare different algorithms. All functions given in the table have zero as the global minimum value. The search range is kept wider than usual for Sphere, Rosenbrock, Rastrigin, Ackley and Weierstrass functions to demonstrate the search ability of GSO algorithm on more stringent conditions. A discussion about the nature of benchmark functions follow [28–31]:The Sphere function is continuous, differentiable and scalable. The Sphere function is a unimodal convex function; hence its global minimum can be easily computed. Zakharov is also a unimodal function with a flat region near the minimum. The Rastrigin function is known to have large number of local minima near the global minimum. The Griewangk function is continuous, differentiable, non-separable, scalable and multimodal. The Ackley function is continuous, differentiable, non-separable, scalable, and multimodal. The Weierstrass function is multimodal and continuous everywhere. Rastrigin, Griewangk, Ackley and Weierstrass benchmark functions test the ability of the algorithm to accurately locate the global minimum in the presence of multiple local minima. The minima of the Noisy Sphere function, is offset by a Gaussian random number vector.Rosenbrock's function has a global minimum at [1, 1, …, 1]. The global minimum of Shifted-Rotated Rastrigin and Shifted-Rotated Ackley is randomly located in the hypercube [−2, 2]D. For Shifted-Rotated Weierstrass global minimum is placed randomly in the hypercube [−0.02, 0.02]D. Locating the global minimum for Rosenbrock's function and Shifted-Rotated functions is particularly difficult if the algorithm is biased to find minima closer to the origin.Rotated version of the test function is achieved by multiplying each vector in the search space by an orthogonal matrix. An orthogonal matrix M multiplies the search vector x to produce the rotated vector y. The orthogonal matrix is obtained from Salomon's method and is the same as the work presented in [18]. Locating the global minimum of rotated functions and shift-rotated functions is known to be more challenging than the unrotated versions.The choice of parameters is based on the values used in existing literature [36] for the competing algorithms. The acceleration constants are taken to be 2.05, a value recommended by prior work [32]. In the recent paper by Md Nasir et al. [36], the population size was set to be 50, 100 and 100 for the 10D, 30D and 50D, respectively. The maximum number of iterations was set to 2000, 3000 and 5000 respectively. The number of function evaluations is given by the product of population size and the maximum number of iterations and is presented in Table 5.To make the GSO experimentation identical with [36] the swarm size X is also fixed to be 50, 100 and 100 for the respective dimensions. Choosing M>N assists in maintaining high exploration demanded by the multimodal functions. For example in the 30D case, the population of the subswarm is N=5 and there are M=20 such subswarms. To make the function evaluations for all algorithms comparable the maximum number of epochs EPmaxis fixed as indicated in Table 4which results in Table 5.The values of L1 and L2 must be chosen carefully as it provides the trade-off between exploration and exploitation. In the GSO algorithm exploration and exploitation are given equal importance so that the algorithm is applicable to a wide class of problems. Each member in the population Xiundergoes L1 iterations. One iteration involves one function count and hence the total number of iterations in the first level is M×N×L1.Likewise for the second level the M global bests of the first level are collected and the second level of PSO is run for the superswarm. Using the same reasoning the number of function evaluations turns out to be M×L2. In order to obtain exploitation at level comparable to exploration, the first level and second level should perform equal function evaluations.(13)M×L2≈M×N×L1(14)⇒L2≈L1×NEq. (14) indicates that setting L2=N×L1 should be the ideal choice of obtaining equal exploration and exploitation. The thumb rule of L2=N×L1 is confirmed to give the best experimental results for all dimensions. The Table 4 shows in detail the parameters that are deployed for the GSO algorithm.The performance of the following PSO variants, are compared with the GSO algorithm in this work.1Fully informed particle swarm optimization (FIPS),Unified particle swarm optimizer (UPSO),Comprehensive learning particle swarm optimizer (CLPSO) andDynamic neighbourhood learning particle swarm optimizer (DNLPSO).All the listed algorithms given above attempt to preserve swarm divergence to avoid premature convergence, which is a serious and known issue with the canonical PSO algorithm. The general approach is to keep all members of the population aware of the performance of few of other members thereby keeping the global search ability active at all times.In FIPS (2004), each member is influenced by neighbours which could be from a U-ring topological structure [33]. This algorithm is different from the canonical PSO in which the pbest information of a particle in consideration is shared among predetermined neighbours. The U-ring topology offered the best neighbourhood for information sharing in terms of the results obtained.UPSO (2006) strategy is divided into constrained and unconstrained depending on the position and velocity parameter [34,35] being bounded or unbounded. This scheme also uses neighbourhoods to enhance sharing of information.In CLPSO (2006), the inclusion of global best as an exemplar is abandoned and particles move in the search space influenced by the best pbest positions located by other particles or its own depending upon a random number [18]. This is a major step to increase exploration. However this strategy takes large number of iterations to converge for multimodal functions as there is no gbest to guide the search.In DNLPSO (2012) the velocity depends on the global best along with the particle best of a neighbourhood whose position is determined by a ring topology varying dynamically [36]. DNLPSO is a slight modification of CLPSO in which the pbest information is shared within a small neighbourhood and hence can balance global and local search abilities.All the algorithms discussed above share information either over the entire population or a small neighbourhood making the search vulnerable by getting stuck in a local minimum. The same argument holds for multiswarm based algorithms sharing best solutions. In GSO algorithm, exploration and exploitation are independent from each other making it suitable to find minima for a given multimodal and high dimensional search space. The galactic best g is influenced by both exploration and exploitation phases but g does not influence the exploration by any feedback mechanism. Information sharing is fully avoided in GSO algorithm, making the search uninfluenced towards some local minimum.Each algorithm is tested with the benchmark functions for 50 independent trials and the results are given for the 10 dimensions in Table 6. In this paper each algorithm is tested for 50 independent trials to achieve higher confidence in the results.To capture the statistics better, in each entry the mean (μ), standard deviation (σ), median (md) and the comparison results of Mann–Whitney U test (h) with respect to GSO are provided. The value of h is binary, if h=0 then the null hypothesis that “the medians are equal” cannot be rejected at 5% significance level [37–39]. For, h=1 the null hypothesis can be rejected at 5% level. Mean and standard deviation are sensitive to outliers; hence median is also provided to enable a better comparison. The best solutions are highlighted in bold.From Table 6 it can be seen that for the multimodal functions like Rastrigin, Rotated Rastrigin, Griewangk, Rotated Griewangk, Ackley, Rotated Ackley, Weierstrass, Noisy-Sphere and Zakharov, the GSO algorithm returns zero within machine precision. Since PSO variants are already shown to perform better than the normal PSO in an earlier work [18] comparison with the classical PSO algorithm is not repeated in this work.It is evident from the Table 6 that the GSO algorithm outperforms other algorithms for most of the functions for 10-dimensional problems. DNLPSO, CLPSO and UPSO algorithms have performance similar to GSO algorithm for Rosenbrock function. DNLPSO does better for the Weierstrass test function. Griewangk is known to be difficult [18] for lower dimensions, however GSO algorithm locates global minimum without any impediment. This is in contrast to UPSO which performs well for high dimensional Griewangk function but has difficulties with lower dimensions. For the Shifted-Rotated Rastrigin GSO algorithm shows better results. For the Shifted-Rotated Ackley many competing algorithms show statistically equivalent performance. For Shifted-Rotated Weierstrass function the performance of GSO algorithm is poor compared to all other algorithms for 10-dimensions.Table 7presents the results for 30 dimensions. The situation is similar to the 10D case for Sphere, Rastrigin, Rotated-Rastrigin, Griewangk, Rotated-Griewangk, Ackley, Rotated Ackley, Weierstrass, Non-Continuous Rastrigin, Zakharov. As dimensions increase the performance of all algorithms deteriorate. However, the performance worsens faster for other algorithms when compared with GSO algorithm. This graceful degradation in performance of the GSO algorithm with increasing dimension is evidenced by the significant difference in results observed for Rosenbrock, Noisy-Sphere, Shift-Rotated Rastrigin and Shift-Rotated Ackley. Though GSO's performance has improved relatively, FIPS algorithm still leads in 30-dimensions for Shifted-Rotated Weierstrass.Table 8illustrates the results for the 50-dimensions. The increased dimension seems to have hardly affected the results for the functions Sphere, Rastrigin, Rotated Rastrigin, Griewangk, Rotated Griewangk, Non-continuous Rastrigin, Noisy Sphere, Ackley, Rotated Ackley, Weierstrass, Zakharov as GSO algorithm continuous to be robust. Even in this high dimensional space the GSO algorithm is found to be robust and less susceptible to the “curse of dimensionality”. In case of the Shifted-Rotated Weierstrass function the GSO algorithm is the worst performing algorithm for 10 dimensions. However it is worth noticing that the GSO algorithm performance improves significantly with increasing dimension and the GSO outperforms other algorithms for 50 dimensions. For the functions Rosenbrock, Shifted-Rotated Rastrigin and Shift-Rotated Ackley, GSO algorithm clearly leads all the other algorithms when the dimension is increased to 50.Convergence of the GSO algorithm and other algorithms cannot be shown directly as zero is returned during some runs and hence cannot be plotted on a logarithmic scale. In this paper ϵ0 (machine epsilon at ‘0’) which is equal to 4.9407×10−324 is uniformly added to all plots to shift all the convergence characteristics upward by ϵ0. This is only done because a value of zero cannot be plotted on a log scale. ϵ0 is not added anywhere during the simulations but only in the plots to display the final results (since log(0) is undefined).This has the effect of shifting the entire set of characteristics upward by a fixed amount of ϵ0 and hence does not affect the relative performance of different algorithms. Also ϵ0 being 4.9407×10−324 changes the all the plots only infinitesimally (by the same amount upward). When values are reported in the table the exact number returned by the algorithm is stated without any change (no epsilons added anywhere).The plots are provided for visualization and conclusions can be based purely on statistical analysis of exact numerical values given in the tables. The convergence plots for single run are shown for the 30D case as it is representative of the convergence for 10D and 50D cases.From the convergence graphs for Sphere, Rastrigin, Rotated Rastrigin, Griewangk, Ackley, Rotated Ackley, Weierstrass, Non-Continuous Rastrigin, Noisy Sphere and Zakharov functions shown in Fig. 1, Fig. 3, Fig. 4, Fig. 5, Fig. 7, Fig. 8 and Fig. 9, Fig. 10, Fig. 11 and Fig. 14 respectively it can be seen that the rate of convergence of GSO is rapid for these functions. It is observed that a best cost of zero is obtained by the GSO algorithm within 10,000 function evaluations. Fig. 9 shows that DNLPSO converges quite rapidly for Weierstrass function compared to other algorithms.UPSO algorithm is competitive for Rosenbrock (Fig. 2), Griewangk (Fig. 5) and Rotated Griewangk (Fig. 6) but the GSO algorithm is significantly better. The GSO algorithm converges faster and shows continuous convergence for Shifted-Rotated Rastrigin as can be seen in Fig. 12. DNLPSO converges faster than the GSO algorithm for the Weierstrass test function. For Shifted-Rotated Ackley (Fig. 13) the GSO algorithm converges faster in the earlier 10,000 function evaluations and cost of the best solution shows slow improvement compared to CLPSO and FIPS over the observed range. Fig. 15shows that for Shifted-Rotated Weierstrass function, FIPS and CLPSO algorithms show better convergence properties than the GSO algorithm but CLPSO has not overtaken the GSO algorithm in first 300000 function evaluations. FIPS converges to a lower function value than the GSO algorithm for Shifted-Rotated Weierstrass function as expected.Table 9compares the GSO algorithm and 4 state-of-the-art multiswarm PSO algorithms from recent literature. Results in Table 9 present the best solution for the 30D case averaged over 30 independent trials. To facilitate comparison with already published work on multiswarm algorithms; the same test functions, dimension, number of trials and stopping criteria used by the authors of the multiswarm algorithms has been adopted in this paper. The maximum number of function evaluations is restricted to 200,000 for GSO, DMSPSO-HS and DMSPSO [25]. For the COM-MPSO and COL-MPSO the function evaluations is set to 320,000 [27]. Table 9 indicates that the GSO algorithm significantly outperforms all the multiswarm algorithms taken for comparison. The superior performance of the GSO approach demonstrates that sharing of good solutions between the subswarms and the superswarm must be unidirectional for good performance contrary to popular belief. Comparison with other multiswarm algorithms indicates that inserting good solutions from the masterswarm into the slaveswarm or exchanging information between swarms results in poor quality of the final solution.A major difference between the GSO and MCPSO [27] algorithms is that in the GSO the superswarm comes into existence only temporarily during Level 2 (exploitative phase). Whereas in MCPSO strategies, the master swarm has a continuous and independent existence. The masterswarm retains a memory of good solutions computed in the previous epoch resulting in reduced exploration. In the GSO algorithm since the superswarm is created anew from the best solutions found by the subswarms everytime at the start of Level 2, the GSO algorithm has more opportunity to explore new solutions. This independence of search between two consecutive exploitative phases of the GSO results in better exploration and ultimately better quality of the final solution compared to MCPSO algorithms (both COM-MPSO and COL-MPSO versions).To make a comparison of the running-time complexity of different algorithms, the number of function evaluations is considered to be the most time consuming operation in relation to other operations such as variable updates. Table 5 shows the number of function evaluations for different algorithms from which it is evident that the GSO algorithm converges faster than existing PSO variants.Since the GSO algorithm as well as its competitors analysed in this paper run for a fixed number of iterations rather than a termination condition, the running time complexity is strongly influenced by the maximum number of iterations. The running time complexity is roughly of the order ofO(D×f.eval), where D is the dimensionality and f.eval is the number of function evaluations. Apart from function evaluations, frequent variable updates are also performed in all the algorithms. However, as can be seen from pseudocode given in Algorithm 1, the GSO algorithm employs simple variable updates compared with other competing algorithms. DNLPSO and CLPSO as well as UPSO and FIPS use refreshing and regrouping while updating variables which require complex vector operations. Table 10shows the mean running time over 40 runs for different objective functions. The best results are highlighted in bold. The results shown in Table 10 indicate that GSO has the smallest mean running time due to simpler variable updates. Thus the performance of the GSO algorithm is superior in terms of speed of convergence and accuracy of final solution compared to existing state-of-the-art PSO algorithm variants.

@&#CONCLUSIONS@&#
