@&#MAIN-TITLE@&#
Multidimensional dual-feasible functions and fast lower bounds for the vector packing problem

@&#HIGHLIGHTS@&#
We propose new m-dimensional dual-feasible functions for the vector packing problem.We describe lower bounding procedures based on these functions.The problem arises in areas such as telecommunications, transportation and production planning.Our procedures generate strong lower bounds and improve the convergence of branch-and-bound algorithms.

@&#KEYPHRASES@&#
Dual-feasible functions,Vector packing problem,Fast lower bounds,

@&#ABSTRACT@&#
In this paper, we address the 2-dimensional vector packing problem where an optimal layout for a set of items with two independent dimensions has to be found within the boundaries of a rectangle. Many practical applications in areas such as the telecommunications, transportation and production planning lead to this combinatorial problem. Here, we focus on the computation of fast lower bounds using original approaches based on the concept of dual-feasible functions.Until now, all the dual-feasible functions proposed in the literature were 1-dimensional functions. In this paper, we extend the principles of dual-feasible functions to the m-dimensional case by introducing the concept of vector packing dual-feasible function, and we propose and analyze different new families of functions. All the proposed approaches were tested extensively using benchmark instances described in the literature. Our computational results show that these functions can approximate very efficiently the best known lower bounds for this problem and improve significantly the convergence of branch-and-bound algorithms.

@&#INTRODUCTION@&#
The m-dimensional vector packing problem (mD-VPP, withm∈N⧹{0}) is a generalization of the well known 1-dimensional bin packing problem (1D-BPP). In the latter, items with different lengths have to be packed into a minimum number of larger objects, or bins. In the mD-VPP, there are m feasibility (capacity) constraints, one for each dimension of the problem, i.e. the sum of the lengths of all packed items must not exceed the bin size in any of the m directions. Unlike in m-dimensional bin packing problems, the dimensions of the mD-VPP are independent. As an example, for m=2, these dimensions may represent the volume and the weight of an object. When m=1, the problem reduces to the 1D-BPP. Hence, the mD-VPP isNP-hard in the strong sense (Garey and Johnson, 1978). In this paper, we focus on the 2D-VPP. However, whenever it is possible, we will generalize our results to the m-dimensional case.The mD-VPP was described first in Garey et al. (1976) to address a special multiprocessor scheduling problem with resource constraints. In that paper, the authors analyzed the worst-case behavior of a generalization of the well-known first fit heuristic used for the 1D-BPP, and they explored two variants based on a preordering of the items (the first fit decreasing and the level heuristic).Other approximation schemes and worst-case performance results concerning the mD-VPP were reported in Yao (1980), de la Vega and Lueker (1981), Woeginger (1997), Chekuri and Khanna (1999), and Kellerer and Kotov (2003). In Yao (1980), Yao showed that for any o(nlogn)-time algorithm A, there is an instance where A generates a solution that uses at least m times the number of bins of the optimal solution. de la Vega and Lueker (1981) showed that a solution with m+ε times the optimal number of bins can be found in linear time for the mD-VPP by applying an extension of their algorithm for the 1D-BPP. In Chekuri and Khanna (1999), described an approximation algorithm for the mD-VPP with a better worst-case performance ratio of 1+εm+O(ln ε−1).For the 2D-VPP, Woeginger (1997) proved that there is no polynomial time approximation scheme for this special case unlessP=NP. Recently, Kellerer and Kotov (2003) proposed an O(nlogn)-time algorithm with an asymptotic worst-case performance ratio of 2 for the 2D-VPP. In Chang et al. (2005), described an O(n2)-time algorithm that extends the algorithm of Kellerer and Kotov (2003), and that leads to solutions with no more than 1/(1−ϱ) times the number of bins of the optimal solution plus one, with ϱ representing the largest fraction between the sizes of the items and the sizes of the bins. In Bansal et al. (2006), described polynomial time randomized algorithms for the 2D-VPP with a worst-case ratio of nearly 1.525.Spieksma was the first to propose an exact approach for the 2D-VPP in Spieksma (1994). The author described different lower bounding procedures, and developed a branch-and-bound algorithm that relies on these bounds. In this paper, the author described also a heuristic based on the first fit decreasing rule.The approaches of Spieksma (1994) were later improved by Caprara and Toth in Caprara and Toth (2001). The authors discussed different lower bounding procedures based on bounds for the 1D-BPP and on the linear relaxation of a column generation model. They described algorithms for computing the bounds, they explored the worst-case performance behavior of these bounds, and they proposed heuristics and exact algorithms for the problem. Extensive computational results were reported on instances with up to 200 different items. These results show an improvement compared to previous approaches.The bounds obtained by column generation are of excellent quality. However, they are obtained with a high computational cost. For the 1-dimensional cutting-stock problem, fast lower bounds can be obtained using the so-called dual-feasible functions (DFFs) (Lueker, 1983). These functions are related to dual solutions of the column generation model, and therefore there is always a function leading to the optimal value yielded by this model.One of the contributions of this paper is the extension of the concept of DFFs to the m-dimensional case. Several difficulties arise when one wants to generalize the results obtained for 1-dimensional DFFs. They are induced by the fact that the comparison between item sizes have to be done componentwise, and therefore, monotonicity and superadditivity take a different sense. In this paper, we propose several new families of functions, and we analyze those properties which are relevant to evaluate the quality of the lower bounds that these functions can generate. We describe different lower bounding procedures based on these functions, and we report on the complexity of each one. Our approaches were tested on benchmark instances of the literature. Our computational experiments show that high quality bounds can be obtained for this problem using the vector packing dual-feasible functions proposed in this paper. Furthermore, we tested our lower bounding procedures within a branch-and-bound algorithm to evaluate their potential impact on the convergence of this type of algorithms. We analyzed the behavior of the algorithm with and without our lower bounding schemes. The results obtained show that significant improvements can be achieved with the former approach.The paper is organized as follows. In Section 2, we introduce the notation that will be used throughout the paper, and we describe two integer programming formulations for the mD-VPP. In Section 3, we briefly recall the basics of dual-feasible functions. In Section 4, we define formally the concept of vector packing dual-feasible functions, and we explore some general properties of these functions. The quality of the lower bounds obtained with vector packing dual-feasible functions is discussed in Section 5. In Section 6, we propose and analyze new classes of vector packing dual-feasible functions. The lower bounding procedures that can be derived from these functions and their corresponding complexity are described in Section 7. Extensive computational experiments are reported and discussed in Section 8. Some final conclusions are drawn in Section 9.An instance E≔(n;L;b) of the mD-VPP consists in a set {1,2,…,n} of n items, whose sizes are given in the matrix L=(l11,l12,…,l1m;…;ln1,ln2,…,lnm)∈[0,1]n×m(with libeing the ith row-vector of L) and with order demandsb=(b1,…,bn)⊤∈(N⧹{0})n. In order to simplify the presentation, we will assume that all the sizes are normalized, such that the bins become m-dimensional unit cubes.The m D-VPP consists in finding a partition of the set of items into a minimum number of subsets such that the items in each subset fit into a bin, i.e. the sum of the sizes in each dimension does not exceed 1 for any subset. Hence, a patterna∈Nnis feasible, if the following capacity constraints on all the m dimensions hold:(1)∑i=1nai×ℓid⩽1,d=1,…,m.Letw≔(1,1,…,1)⊤∈Rm. The capacity constraints (1) can be stated as follows: L⊤a⩽w.For given vectorss,t∈Rmthe relation signs ⩽, ⩾, <, and > will be used if the relation is componentwise true. For example, s⩽t will stand for si⩽ti, i=1,…,m. Furthermore, an interval [s,t] will consist of allz∈Rmwith s⩽z⩽t.From this point forward, the null vector will be denoted byo≔(0,0,…,0)⊤∈Rm.Let K be an upper bound for the number of bins that are necessary to pack all the items. The mD-VPP can be formulated using an assignment model similar to the Kantorovich model proposed in Kantorovich (1960):(2)min∑j=1Kyj(3)s.t.∑j=1Kxij⩾bi,i=1,…,n,(4)∑i=1nlidxij⩽yj,d=1,…,m,j=1,…,K,(5)yj∈{0,1},j=1,…,K,(6)xij∈{0,1},i=1,…,n,j=1,…,K.The binary variables yj, j=1,…,K, indicate if the bin j is used (yj=1) or not (yj=0), while the xijvariables, i=1,…,n, j=1,…,K, determine the inclusion of an item i in the bin j. The objective function (2) consists in minimizing the number of bins required to pack the items. Constraints (3) ensure that the demands of the items are fulfilled. The capacity constraints are represented by (4). There is a capacity constraint for each bin and dimension of the problem.This model was presented and discussed also in Caprara and Toth (2001) for m=2. It suffers from the same typical weaknesses of the assignment models for cutting and packing problems: a weak continuous lower bound and symmetry. As shown in Caprara (1998), the lower bound provided by the linear programming (LP) relaxation of (2)–(6), rounded up to the next integer, equals the bound LCgiven by Spieksma in Spieksma (1994). For the general m-dimensional problem, this bound is equal to:(7)maxd=1,…,m∑i=1nlid.In Caprara and Toth (2001), the authors described a column generation model for the mD-VPP which is obtained from (2)–(6) by dualizing the demand constraints (3). The resulting model has an exponential number of columns that represent the feasible patterns satisfying the capacity constraints (1). Let P denote this set of patterns. The model states as follows.(8)min∑p∈Pλp(9)s.t.∑p∈Paipλp⩾bi,i=1,…,n,(10)λp⩾0,and integer,p∈P.The coefficients aiprepresent the number of times an item i is used in pattern p. The integer variables λprepresent the number of times a pattern p is used. The objective function (8) consists in minimizing the total number of patterns (and hence, bins) used to fulfill the item demands (9).This reformulation leads to a pricing subproblem that is a multidimensional knapsack problem. Since this problem does not have the integrality property, the lower bound given by the LP relaxation of (8)–(10) will be at least equal to the bound provided by the LP relaxation of (2)–(6). In practice, this bound is quite strong, but its computation is time consuming for any large scale instances as shown in Caprara and Toth (2001).Dual-feasible functions were first proposed by Johnson in Johnson (1973). These functions can be used to compute lower bounds for different combinatorial optimization problems, and also to derive valid inequalities for integer programming problems (Clautiaux et al., 2010; Fekete and Schepers, 2001). A function f:[0,1]→[0,1] is a dual-feasible function (DFF), if for any finite set{xi∈R+:i∈J}of nonnegative real numbers, the following holds:∑i∈Jxi⩽1⇒∑i∈Jf(xi)⩽1.A DFF f is a maximal dual-feasible function (MDFF), if there is no other DFF g:[0,1]→[0,1] such that g(x)⩾f(x), for all x∈[0,1]. For f:[0,1]→[0,1] to be a MDFF, it is necessary and sufficient (Clautiaux et al., 2010; Rietz et al., 2010) that f is symmetric, i.e.f(x)+f(1-x)=1for allx∈[0,1/2],f(0)=0, and f verifies the following superadditivity condition:f(x1+x2)⩾f(x1)+f(x2)for allx1,x2with0<x1⩽x2<1/2andx1+x2⩽2/3.All the DFFs described in the literature are 1-dimensional functions. One of the contributions of this paper is to extend for the first time the concept of DFF to the m-dimensional case. A comprehensive survey and comparative study of the 1-dimensional DFFs proposed in the literature is provided in Clautiaux et al. (2010). This study allowed to identify the following DFFs as some of the best functions proposed so far. From this point forward, we will use the abbreviation frac(x)≔x−⌊x⌋, for anyx∈R, to denote the non-integer part of the real expression x.•fFS,1, proposed in Fekete and Schepers (2001), withk∈N⧹{0}:fFS,1(x;k)=x,if(k+1)×x∈N,⌊(k+1)x⌋/k,otherwise,fCCM,1, proposed in Carlier et al. (2007), for anyC∈Rand C⩾1:fCCM,1(x;C)=⌊Cx⌋/⌊C⌋,if0⩽x<1/2,12,ifx=12,1-fCCM,1(1-x),if12<x⩽1,fBJ,1 proposed in Burdett and Johnson (1977), withC∈Rand C⩾1:fBJ,1(x;C)=1⌊C⌋×⌊Cx⌋+max0,frac(Cx)-frac(C)1-frac(C).Dual-feasible functions (DFFs) have been used essentially to compute bounds and inequalities for cutting and packing, routing and scheduling problems (Clautiaux et al., 2010). The functions described in the literature are defined exclusively for 1-dimensional domains. Computing lower bounds for the mD-VPP by separating the problem into m instances of the 1D-BPP, and by applying these functions independently to each one of these instances may lead to arbitrarily bad results. In this paper, we introduce the concept of vector packing dual-feasible functions, where the 1-dimensional domain is now replaced by an m-dimensional one. These functions can be applied directly to mD-VPP instances without separating the m dimensions, and hence, they may lead to much stronger lower bounds for the mD-VPP. Our objective is to approximate the lower bounds provided by the LP relaxation of (8)–(10) through efficient (polynomial-time) lower bounding procedures that rely on these m-dimensional dual-feasible functions.In this section, we introduce formally the definitions of vector packing dual-feasible function and maximal vector packing dual-feasible function. We show that some general properties for the 1-dimensional case can be generalized to the multidimensional case, and we give a complete characterization of maximal functions for the m-dimensional case. Finally, we show how to build such maximal functions from non-maximal ones by forcing symmetry.A formal definition of a vector packing dual-feasible function is given next.Definition 1A function f:[0,1]m→[0,1] is a vector packing dual-feasible function (VP-DFF), if for all instances of the mD-VPP and all feasible patternsa∈Nnsatisfying (1), the following inequality holds:∑i=1nai×fli⊤⩽1.A VP-DFF is said to be maximal if there is no other VP-DFF that dominates it in the sense stated in the following definition.Definition 2A VP-DFF f is maximal (VP-MDFF), if there is no other VP-DFF g with g(x)⩾f(x) for all x∈[0,1]m.Some simple VP-DFFs are, for example, the projections to the jth coordinate of the argument-vector (j=1,…,m), i.e. fj(x)=xj. These functions lead to lower bounds for the mD-VPP which are already known from the 1D-BPP.The necessary conditions from the 1-dimensional case stated in Carlier and Néron (2007) for a function to be maximal are still valid for the higher-dimensional case. However, it remains to be checked how the higher-dimensional case can be described and if stronger sufficient conditions are needed. These ideas are explored in the following theorems.Theorem 1Any VP-MDFF f:[0,1]m→[0,1] has necessarily the following properties:1.f is superadditive, i.e. for allx,y∈[0,1]mwithx+y⩽w, it holds that(11)f(x+y)⩾f(x)+f(y);f is non-decreasing:(12)f(x)⩽f(y),ifo⩽x⩽y⩽w;f is symmetric, i.e. for allx∈[0,1]m, it holds that(13)f(x)+f(w-x)=1,and especially f(w)=1 andf12w=1/2.To prove (11), we define first the functiong:[0,1]m→Rasg(x)≔supy∈[o,x]{f(y)+f(x-y)}.We will show that g is a VP-DFF dominating f, and hence g≡f. Sinceg(x)⩾f(o)+f(x)andf(o)⩾0,one has g(x)⩾f(x) for all x∈[0,1]m. Let J be any finite index set, and xi∈[0,1]msuch that∑i∈Jxi⩽w. Due to the construction of g, for all ε>0, there are yi∈[o,xi] with i∈J, such that∑i∈Jg(xi)⩽ε+∑i∈J(f(yi)+f(xi-yi))⩽ε+1,because f is a VP-DFF. Since the inequality∑i∈Jg(xi)⩽ε+1holds for all ε>0, it follows that∑i∈Jg(xi)⩽1, and hence g is a VP-DFF too. That implies g≡f, because f is a VP-MDFF. Since f(x)⩾f(y)+f(x−y) for all x, y∈[0,1]mwith x⩾y, the assertion (11) follows by replacing x by x+y.The property (12) follows, because y⩾x implies y−x∈[0,1]m, and since f(y)⩾f(x)+f(y−x) and f(y−x)⩾0, we have that f(y)⩾f(x).Now, we prove the validity of the property (13) by addressing first the case wherex∈[0,1]m⧹12w. Let r∈{1,…,m}, with xr≠1/2, and let h:[0,1]m→[0,1] be the function defined as follows:h(x)≔f(x),ifxr⩽1/2,1-f(w-x),otherwise.We want to show that h≡f. Clearly, we have h(x)⩾f(x) for all x∈[0,1]m, because f(x)⩽1−f(w−x). Otherwise, f would not be a VP-DFF. To see that h is a VP-DFF too, we choose again a finite index set J and xi∈[0,1]mwith∑i∈Jxi⩽w. Suppose that 1∈J and x1r>1/2. Then, xir<1/2 for all i∈J⧹{1}, and hence∑i∈Jh(xi)=1-f(w-x1)+∑i∈J⧹{1}f(xi)⩽1-f(w-x1)+f∑i∈J⧹{1}xi,due to(11)and because∑i∈J⧹{1}xi⩽w-x1,⩽1,by the monotonicity(12).Since f is maximal, we have f≡h. If xr>1/2, then f(x)=h(x)=1−f(w−x) due to the definition of h. If xr<1/2, then f(w−x)=h(w−x)=1−f(w− (w−x))=1−f(x). Therefore, Property (13) follows except forx=12w.Since f is a VP-DFF, it follows that f(o)=0 andf12w⩽1/2. Analogously to the previous paragraph, we define the function h′:[0,1]m→[0,1] as follows:h′(x)≔f(x),for allx∈[0,1]m⧹12w,andh′12w≔1/2.Similar arguments (withx1≔12w) show that h′ is a VP-DFF, and hence, since f is maximal, it follows that f≡h′. □The properties (11)–(13) of Theorem 1 are also sufficient conditions for a function f:[0,1]m→[0,1] to be a VP-MDFF. However, it is possible to derive sufficient conditions that are more restricted. These sufficient conditions are stated in Theorem 2. This theorem will help to simplify the proofs of maximality that will be described in the next sections. Before introducing these new sufficient conditions, we describe first in Lemma 1 an additional assertion that will be needed to prove the maximality of a VP-DFF.Lemma 1If a VP-DFF f:[0,1]m→[0,1] satisfies the symmetry condition(13), then f is a VP-MDFF.Suppose that there is a VP-DFF g:[0,1]m→[0,1], with g(x)>f(x) for a given x∈[0,1]m. The symmetry of f impliesf(w-x)=1-f(x)>1-g(x)⩾g(w-x),otherwise the contradiction g(x)+g(w−x)>1 would arise. Since f(w−x)>g(w−x), the VP-DFF f is not dominated by any another one, and hence it is a VP-MDFF. □Given two constants r, s∈{1,…,m} and a function f:[0,1]m→[0,1], the following conditions are sufficient for f to be a VP-MDFF:1.Eq.(13)is true for allx∈[0,1]mwith xr⩽1/2;Inequality(11)holds for allx,y∈[0,1]mwithx+y⩽w, and xs⩽ys⩽1/2 and xs+ys⩽2/3.First, we prove that the conditions 1 and 2 imply respectively that (13) and (11) hold for all x, y∈[0,1]mwith x+y⩽w. Then, we will show that f is a VP-DFF and that it is maximal by resorting to Lemma 1.Suppose that y∈[0,1]mwith yr>1/2. Let x≔w−y. That yields x∈[0,1]mwith xr<1/2 such that the condition 1. implies that (13) holds for this x. That gives 1=f(x)+f(w−x)=f(w−y)+f(y), and hence (13) holds also for y and therefore for all x∈[0,1]m.Let x,y∈[0,1]mbe given, with x+y⩽w. Now, we show that (11) holds:•if xs>ys, then we can exchange x and y. That does not change the validity of (11), i.e. the inequality (11) holds now if and only if it was true before. Therefore, we may assume xs⩽ysin the following, and replace the inequality chain xs⩽ys⩽1/2 in condition 2 by xs, ys⩽1/2 without any influence on the validity of the theorem;if ys>1/2, then (13) implies f(x+y)=1−f(w−y−x). Since xs+ (1−xs−ys)<1/2 and 0⩽xs<1/2, the condition 2. implies (11) for the arguments x and w−x−y, because if xs>1−xs−ysthen the same exchange can be done as in the previous paragraph. That yields f(w−y−x)+f(x)⩽f(w−y). Hence, we havef(x+y)⩾1-(f(w-y)-f(x))=1-1+f(y)+f(x),by the symmetry condition (13). Since for ys>1/2, the superadditivity condition (11) holds, we may assume that ys⩽1/2 in the following;if xs⩽ys⩽1/2 and xs+ys>2/3, then 1−xs−ys<1/3 and 1−ys<2/3 (because of xs⩽ysand xs+ys>2/3). Hence, the condition 2 allows to apply the inequality (11) with the arguments x and w−x−y, leading to f(w−y−x)+f(x)⩽f(w−y), and, by symmetry, we havef(x+y)=1-f(w-y-x)⩾1-(f(w-y)-f(x))=f(x)+f(y).Hence, the conditions 1 and 2 imply the superadditivity (11) for all x, y∈[0,1]mwith x+y⩽w.The superadditivity and the range imply the monotonicity (12). For any x, y∈[0,1]mwith x⩽y, one has f(y)⩾f(x)+f(y−x)⩾f(x). Additionally, one gets f(2o)⩾2f(o). Hence f(o)⩽0 and therefore f(o)=0 and f(w)=1 due to the symmetry.These results are used to show that f is a VP-DFF. For any finite index set J and vectors xi∈[0,1]mwith∑i∈Jxi⩽w, it follows from the superadditivity condition (11) by induction that∑i∈Jf(xi)⩽f∑i∈Jxi⩽f(w)=1. Hence, f is a VP-DFF. Furthermore, the function f is maximal because of the symmetry condition (13) and Lemma 1. □In the following propositions, we show that the functions resulting from the convex combination of VP-MDFFs or from the composition of a VP-MDFF with a MDFF remain maximal.Proposition 1Any convex combination of VP-MDFFs is a VP-MDFF.Let be given n′ VP-MDFFs fi, i=1,…,n′, and a set of n′ positive real numbers λi, i=1,…,n′, such that∑i=1n′λi=1. We will denote by f the function obtained through the convex combination of the VP-MDFFs fiwith coefficients λi, i.e.f≔∑i=1n′λi×fi. For any finite set J and vectors xi∈[0,1]mwith∑i∈Jxi⩽w, we have∑i∈Jf(xi)=∑i∈J∑j=1n′λj×fj(xi)=∑j=1n′λj×∑i∈Jfj(xi)⩽∑j=1n′λj×1=1.Hence, f is a VP-DFF according to Definition 1.Now, we will prove that f is symmetric in the sense of (13). That will imply that f is maximal due to Lemma 1. By definition, all the functions fi, i=1,…,n′ are maximal, and hence they must be symmetric according to Theorem 1. As a consequence, one gets for any x∈[0,1]mthatf(x)+f(w-x)=∑i=1n′λi×fi(x)+∑i=1n′λi×fi(w-x)=∑i=1n′λi×(fi(x)+fi(w-x))=∑i=1n′λi=1,and hence the symmetry condition holds also for the function f. Therefore, f is maximal. □The composition of a VP-MDFF f with a MDFF g, i.e. g(f(·)), is a VP-MDFF.Let g: [0,1]→[0,1] be a maximal DFF, and let f: [0,1]m→[0,1] be a VP-MDFF. For any finite set J and vectors xi∈[0,1]msuch that∑i∈Jxi⩽w, we have∑i∈Jg(f(xi))⩽1,since∑i∈Jf(xi)⩽1. Hence, g(f(·)) is a VP-DFF according to Definition 1.By definition, the functions f and g are maximal, and hence they are both symmetric according to Theorem 1. For every x∈[0,1]m, it follows thatg(f(x))+g(f(w-x))=g(f(x))+g(1-f(x))=1,such that g(f(·)) is symmetric too and therefore maximal according to Lemma 1. □In Nemhauser and Wolsey (1998), Nemhauser and Wolsey described valid inequalities for independence systems obtained from superadditive functions. A setS∈Z+nis an independence system, if (0,…,0)⊤∈S, andy⩽x⇒y∈Sholds, for x∈S andy∈Z+n. An additional requirement onS≔x∈Z+n:Ax⩽bis that all the coefficients should be nonnegative integers, and bi⩾maxjaij, for all i and aij∈A. Hence, one obtains an equivalent inequality by division by bi, such that a system of the kind L⊤x⩽w, withx∈Z+nandL∈([0,1]∩Q)n×m, arises like in our vector packing problem. On the contrary, we did not require integrality constraints or that the data should be rational.Analogously to Proposition 2 of Clautiaux et al. (2010), the definition of VP-DFFs immediately yields valid inequalties for the system L⊤x⩽w, with 0⩽ℓij⩽1 andxj∈Z+n, for i=1,…,m and j=1,…,n, namely∑j=1nf(lj)xj⩽1, where ljis the jth column of the matrix L. The proof is straightforward, because∑j=1nf(lj)xj=∑j=1n∑k=1xjf(lj)⩽1, since∑j=1n∑k=1xjlj⩽w.The similarities between Nemhauser and Wolsey and our superadditive, non-decreasing functions are the following. The domainD(b)≔d∈Z+m:d⩽bis replaced by [0,1]m, and the function F is normalized to F(w)=1 and the range [0,1]. Then F has to be non-decreasing and superadditive. F is maximal if and only if it is symmetric in the sense (13).In this section, we show how a VP-MDFF can be built from a superadditive m-dimensional superadditive vector function by forcing symmetry. This result is a generalization of a scheme developed for the 1-dimensional case and described in Clautiaux et al. (2010).Proposition 3Let f: [0,1]m→[0,1] be a superadditive function, and M be any subset of[0,1]m⧹12wsuch that:1.for allx∈[0,1]m⧹12w, the following equivalence holds:(14)x∈M⇔w-x∉M;for anyx,y∈M, it holds that(15)x+y≰w.The following function g: [0,1]m→[0,1] which is built from f is a VP-MDFF:g(x)≔1/2,if2x=w,1-f(w-x),ifx∈M,f(x),otherwise.For this proof, we resort to Theorem 2. That requires to verify that g is both symmetric and superadditive.First, we show that the range of g belongs to [0,1]. Because of the superadditivity and the range of the function f, this function f is also non-decreasing, and hence, we have thatf(w)⩽1andf12w⩽12.Therefore, the range of g belongs to [0,1] too.LetA≔[0,1]m⧹M∪12w. Because of (14), one gets for any x∈M thatg(x)+g(w-x)=1-f(w-x)+f(w-x)=1,and, analogously, for any x∈A thatg(x)+g(w-x)=f(x)+1-f(w-(w-x))=1.Furthermore, we have alsog12w=1/2, and hence, the function g is symmetric.It remains to be proved that g is also superadditive. For that purpose, let x, y∈[0,1]m, with x+y⩽w. Because of (15), one has o∈A, and hence w∈M. The superadditivity of f implies f(2o)⩾2f(o) and f(o)⩽0, and hence we have that f(o)=0 due to the range of f.To show that g is superadditive, we have to resort to the following case distinction that covers all the possibilities concerning which case of the definition of g has to be used, i.e. to which of the setsA,12wor M each of the arguments x, y and x+y belongs.1.If x, y, x+y∈A, then g(x+y)−g(x)−g(y)=f(x+y)−f(x)−f(y)⩾0 due to the superadditivity of f.If x, y∈A andx+y=12w, theng(x)+g(y)=f(x)+f(y)⩽f(x+y)⩽12=g(x+y).If x, y∈A and x+y∈M, then g(x+y)−g(x)−g(y)=1−f(w−x−y)−f(x)−f(y)⩾1−f(w)⩾0.It is impossible thaty=12wand x+y∈A, because in that case, we would have w−x−y∈M andw-x-y⩽12win contradiction to (15).If y=x+y, then x=o, implying g(x)=0, because f(o)=0 and o∈A. Therefore, the superadditivity of g becomes obvious.Ifx∈A,y=12wand x+y∈M, theng(x+y)-g(x)-g(y)=12-f(w-x-y)-f(x)⩾12-f(w-y)⩾0.It cannot occur that y∈M and x+y∈A, because w−x−y∈M and w−x−y+y=w−x contradicts (15).It can also not happen that y∈M andx+y=12w, because of the contradiction 2y⩽w.If x∈A and y,x+y∈M, then g(x+y)−g(x)−g(y)=1−f(w−x−y)−f(x)−1+f(w−y)=f(w−y)−f(w−y−x)−f(x)⩾0.Ifx=y=12w, then g(x+y)=g(w)=1−f(o)=1=g(x)+g(y), because w∈M and f(o)=0.It cannot happen thatx=12wand y∈M, because that would implyy=x+y-x⩽12win contradiction to (15).Because of (15), it is also impossible that x, y∈M.All the remaining cases are obtained by exchanging x and y, and hence, they are similar to the previous cases. Hence, all conditions of Theorem 2 are satisfied, such that g is a VP-MDFF.□The set M in Proposition 3 can be chosen in various ways. For instance, we may haveM≔[0,1]×[0,1]×…×[0,1]×12,1∪[0,1]×…×[0,1]×12,1×12∪…∪12,1×12×…×12(as the union of m parts). For m=2, this set becomes[0,1]×12,1∪12,1×12, i.e. the upper half of the unit square, where only a part of the border belongs to M. Additionally, M could be chosen for example as followsM≔{x∈[0,1]2:x1+x2>1}∪x∈12,1×[0,1]:x1+x2=1.Let E≔(n;l;b) be an instance of the mD-VPP, and f a VP-DFF. A valid lower bound for the number of bins that are necessary to pack the items of E can be computed from f as follows:(16)z[f]≔∑i=1nbi×f(li).Let zCGdenote the optimal value of the LP relaxation of the column generation model (8)–(10). The following proposition shows the relation between zCGand the value given by any VP-DFF.Proposition 4For any VP-DFF f: [0,1]m→[0,1], the bound z[f] is never above zCG. Moreover, there is at least one VP-DFFfˆwithz[fˆ]=zCG.Even if the number of feasible patterns can be huge, it remains finite. Therefore, the theory about linear optimization problems, especially the duality theory, can be applied. Without loss of generality assume that(17)li≠lj,for alli,j∈{1,…,n}withi≠j.The dual of the LP relaxation of (8)–(10) states as follows:(18)maxb⊤π(19)s.t.∑i=1naipπi⩽1,p∈P,(20)πi⩾0,i=1,…,n.Because li∈[0,1]m, every item fits alone into one bin. Therefore, there is a feasible solution to (8)–(10). Because of the non-negativity constraints on the λpvariables of (8)–(10), the objective function (8) is bounded in the direction of the optimization by e.g. zero. Hence, optimal solutions of the LP relaxation of (8)–(10) and the dual problem (18)–(20) exist, and the optimal objective function values of both problems are the same (by the strong duality theorem).For every feasible pattern a, it holds that∑i=1nai∗f(li)⩽1by definition of VP-DFFs. Therefore, πi≔f(li) for i≔1,…,n, fulfills the demand (19). Condition (20) is clearly met due to the range of f. Hence, the chosenπis feasible for the problem (18)–(20), such that z[f]⩽zCGfollows.Letπˆbe an optimal solution of the problem (18)–(20). A VP-DFFfˆ:[0,1]m→[0,1]can be defined byfˆ(x)≔πˆi,ifx=li,i∈{1,…,n},0,ifx≠li,for alli∈{1,…,n}because of the constraints (19) and (20), even iffˆis in general not maximal. This functionfˆis well defined due to the assumption (17) and yieldsz[fˆ]=zCGaccording to the strong duality theorem. □In this section, we propose new classes of VP-MDFFs. When general schemes for generating VP-MDFFs are proposed, we describe and analyze some specific functions that can be obtained from these schemes. To simplify the notation, the parameters of the functions will be omitted whenever it is possible.Our first set of VP-MDFFs is based on the projection of the m-dimensional data into 1-dimensional domains. The following proposition gives a formal definition of these VP-MDFFs.Proposition 5Let g: [0,1]→[0,1] be a MDFF andu∈R+mwithu⊤w=1. The function f: [0,1]m→[0,1] withf(x)≔g(u⊤x)is a VP-MDFF.Each of the projections gj: [0,1]m→[0,1] with gj(x)=xjis a VP-MDFF. To prove that, we resort to Theorem 2. First, the domain and range of these projections are in accordance with Theorem 2. The symmetry is given due togj(x)+gj(w-x)=xj+(1-xj)=1,for any x∈[0,1]m. The superadditivity also holds sincegj(x+y)=xj+yj=gj(x)+gj(y),for all x, y∈[0,1]mwith x+y⩽w.According to Proposition 1, any convex combination of VP-MDFFs is a VP-MDFF, and therefore x↦u⊤x is also a VP-MDFF. Furthermore, as shown in Proposition 2, the composition of a VP-MDFF and a MDFF yields again a VP-MDFF, and hence f is a VP-MDFF. □The function described in Corollary 1 is obtained from Proposition 5 using the MDFF fFS,1 proposed in Fekete and Schepers (2001) as the function g.Corollary 1Letv∈R+msuch thatv⊤w∈N⧹{0,1}. The following functionf:[0,1]m→R+is a VP-MDFF:f(x)≔v⊤xv⊤w,ifv⊤x∈N,⌊v⊤x⌋v⊤w-1,otherwise.Letu≔1v⊤w×v(and hence,u∈R+mwith u⊤w=1), and let k≔v⊤w−1. If we set g≔fFS,1 in Proposition 5 and apply the definition of the function fFS,1, we getfFS,1(u⊤x;k)=u⊤x,if(k+1)×u⊤x∈N,⌊(k+1)×u⊤x⌋/k,otherwise,=v⊤xv⊤w,ifv⊤w×v⊤xv⊤w∈N,⌊v⊤w×v⊤xv⊤w⌋/(v⊤w-1),otherwise,which leads to the definition of the function f(x) of the corollary. □The next function is obtained from Proposition 5 and the MDFF fBJ,1 described in Burdett and Johnson (1977).Corollary 2Letv∈R+mbe any vector withv⊤w⩾1. Then, the functionf:[0,1]m→R+withf(x)≔⌊v⊤x⌋+max0,frac(v⊤x)-frac(v⊤w)1-frac(v⊤w)⌊v⊤w⌋is a VP-MDFF.Letu≔1v⊤w×v(and hence,u∈R+mwith u⊤w=1), and let C≔v⊤w. If we set g≔fBJ,1 in Proposition 5 and apply the definition of the function fBJ,1, we obtainfBJ,1(u⊤x;C)=⌊C×u⊤x⌋+max0,frac(C×u⊤x)-frac(C)1-frac(C)⌊C⌋=⌊v⊤w×v⊤x/v⊤w⌋+max0,frac(v⊤w×v⊤x/v⊤w)-frac(v⊤w)1-frac(v⊤w)⌊v⊤w⌋.□Note that ifv⊤w∈N, then the function f of Corollary 2 is only a convex combination of the projections f1,…,fm.Some of the ideas of the 1-dimensional MDFFs discussed in Clautiaux et al. (2010) can be adapted for the m-dimensional VPP. For instance, the function due to Martello and Toth, which maps small items to zero and large ones to 1, while the other items remain unchanged, can be generalized as follows. Note that the difficulty in this generalization is to find a suitable definition of small and large items when vectors are involved.Proposition 6Leth:[0,1]m→Rbe non-decreasing with h(x)+h(w−x)>0 for allx∈[0,1]m, and let g: [0,1]m→[0,1] be a VP-MDFF. The following functions f1,f2: [0,1]m→[0,1] are VP-MDFFs:f1(x)≔0,ifh(x)⩽01,ifh(w-x)⩽0g(x),otherwise,f2(x)≔0,ifh(x)<01,ifh(w-x)<0g(x),otherwise.For this proof, we resort to Lemma 1. We will show that f1 is a VP-DFF, i.e. that for any x,y∈[0,1]mwith x+y⩽w, it follows that f1(x+y)⩽1. Then, the symmetry will be verified.To start the proof that f1 is a VP-DFF, several situations with respect to x, y∈[0,1]mhave to be analyzed. First, observe that x+y⩽w implies x⩽w−y and h(x)⩽h(w−y), due to the monotonicity of h. We distinguish the following cases:1.If h(w−y)⩽0, then f1(x)=0. Since f1(y)=1, one has f1(x)+f1(y)=1;The case h(w−x)⩽0 is similar to the previous one;Assume that h(w−x)>0 and h(w−y)>0. Then, f1(x)+f1(y)⩽g(x)+g(y)⩽ 1, because g is a VP-DFF.In all cases, it follows that f1(x)+f1(y)⩽1. Using induction, that implies∑i∈Jf1(xi)⩽1, for any finite index set J of vectors xi∈[0,1]mwith∑i∈Jxi⩽w. Hence, f1 is a VP-DFF.To prove that f1 is maximal, according to Lemma 1, it remains to show that f1 is symmetric. For this purpose, recall that g is by definition a VP-MDFF. According to Theorem 1, g must be symmetric. To prove that f1 is symmetric, we distinguish the following cases with regard to x∈[0,1]m:1.if h(x)>0 and h(w−x)>0, then f1(x)=g(x) and f1(w−x)=g(w−x). The symmetry of g yields f1(x)+f1(w−x)=g(x)+g(w−x)=1;if h(x)⩽0, then f1(x)=0 and f1(w−x)=1, and hence f1(x)+f1(w−x)=1;if h(w−x)⩽0, then f1(x)=1 and f1(w−x)=0, and hence f1(x)+f1(w−x)=1.Therefore, f1 is a VP-MDFF. The proof for f2 is similar. □Letu∈[0,12]m, and let g: [0,1]m→[0,1] be a VP-MDFF. The following functions f1,f2: [0,1]m→[0,1] are also VP-MDFFs:f1(x)≔0,ifx⩽uandx≠12w1,ifx⩾w-uandx≠12wg(x),otherwise,f2(x)≔0,ifx<u1,ifx>w-ug(x),otherwise.In that case, we can use in Proposition 6 for exampleh(x)≔0,ifx⩽u∄x≠12w,1,otherwise,orh(x)≔0,ifx<u,1,otherwise,because h(x)=0 for an x∈[0,1]mimpliesx≠12wand x⩽u, hence w−x⩾w−u and finally h(w−x)=1. □Let ∥·∥pbe anLp-norm inRmwith 1⩽p⩽∞, i.e.‖x‖∞=maxr=1,…,m|xr|and‖x‖p=∑r=1m|xr|ppforp<∞.Let g: [0,1]→[0,1] be a VP-MDFF and ε∈(0,∥w∥p/2). The following function f: [0,1]m→[0,1] is a VP-MDFF:f(x)≔0,if‖x‖p⩽ε,1,if‖w-x‖p⩽ε,g(x),otherwise.The function h(x)≔∥x∥p−ε is non-decreasing in [0,1]m. Because ofh(x)+h(w-x)=‖x‖p+‖w-x‖p-2ε⩾‖w‖p-2ε>0for anyx∈[0,1]m,both the prerequisites of h in Proposition 6 are satisfied. Using this function h within f1 in Proposition 6 leads to the function f.□Letg′:[0,1]m→Rbe any non-decreasing function, and let r∈{1,…,m}. The following function f: [0,1]m→[0,1] is a VP-MDFF:(21)f(x)≔0,if2w⊤x<mandg′(x)<0,1,if2w⊤x>mandg′(w-x)<0,xr,otherwise.Here, the function f2(x) of Proposition 6 is used withh(x)≔max{g′(x),-1},if2w⊤x<mandg′(x)<0,2,otherwise.This function h is non-decreasing. If one has for an x∈[0,1]mthat h(x)<2 then 2w⊤x<m, hence 2w⊤(w−x)>m, because w⊤w=m. That implies h(w−x)+h(x)⩾ 2−1>0. Of course, g′(x)<0⇔max{g′(x),−1}<0. Furthermore, the projections x↦xrare used as the function g in the definition of f2 in Proposition 6s, with r=1,…,m. These projections are VP-MDFFs as shown in Proposition 5, and hence, our proof is complete.□In the following proposition, we introduce a new VP-MDFF. We describe first the general function for the m-dimensional case. For the sake of clarity, the function for the 2-dimensional case is given next in Corollary 6. The idea consists in assigning the value zero to very small items and the value 1 to large ones, while another VP-MDFF is applied to the remaining items.Proposition 7Let g: [0,1]m→[0,1] be a VP-MDFF andu∈[0,1/2]m. The following function f: [0,1]m→[0,1]f(x;u)≔0,if∃i∈{1,…,m}withxi<uiand∄j∈{1,…,i}withxj>1-uj,1,if∃i∈{1,…,m}withxi>1-uiand∄j∈{1,…,i}withxj<uj,g(x),otherwise,is a VP-MDFF.The proof relies on Theorem 2. First, we will show that f is symmetric, and then that it is non-decreasing. The latter will be used to prove the superadditivity of f.Recall that since g is a VP-MDFF, it is symmetric due to Theorem 1. To show that f is symmetric, we distinguish the following three cases for a given x∈[0,1]m:1.if u⩽x⩽w−u, then f(x)=g(x) and also f(w−x)=g(w−x), because w−u⩾w−x⩾u. Hence, f(x)+f(w−x)=g(x)+g(w−x)=1;if there is an i∈{1,…,m} with xi<uibut no j∈{1,…,i} with xj>1−uj, then f(x)=0. In that case, one has f(w−x)=1 according to the second line in the definition of f. Hence, f(x)+f(w−x)=1;if there is an i∈{1,…,m} with xi>1−uiand no j∈{1,…,i} with xj<uj, then f(x)=1, and the first line in the definition of f applies to f(w−x). Hence, f(x)+f(w−x)=1.To show that f is non-decreasing, let x, y∈[0,1]mwith x⩽y. We distinguish the following three cases with respect to f(x):1.the monotonicity is obvious for f(x)=0, because 0⩽g(y)⩽1 for all y∈[0,1]m, and hence f(y)⩾0;if there is an i∈{1,…,m} with xi>1−uibut no j∈{1,…,i} with xj<uj, then f(x)=1. It follows that yi⩾xi>1−uiand yj⩾xj⩾uj, for all j∈{1,…,i}, and hence f(y)=1. As a consequence, it holds that f(y)⩾f(x);if the last line in the definition of f applies, then f(x)=g(x) and u⩽x⩽y. Hence, f(y)∈{1,g(y)}, and f(y)⩾g(y) because g(y)⩽1. According to Theorem 1, it holds that g(y)⩾g(x). It follows that f(x)=g(x)⩽g(y)⩽f(y).It remains to show that f is superadditive. For this purpose, let x,y∈[0,1]mwith x+y⩽w. Because of the monotonicity of f, the superadditivity is obvious for the case where f(x)=0 or f(y)=0. Therefore, we will assume that f(x)>0 and f(y)>0. Suppose that there is an i∈{1,…,m} with xi>1−uiand xj⩾uj, for all j∈{1,…,i}. Because of y⩽w−x, it follows that yi<uiand yj⩽1−uj, for all j∈{1,…,i}, and hence, f(y)=0 in contradiction to the assumption f(y)>0. Exchanging x and y would yield a similar result. Therefore, f(x)=g(x) and f(y)=g(y). Since f is non-decreasing and f(x)>0, it follows that f(x+y)>0. Hence, f(x+y)⩾g(x+y) according to the definition of f, because g(x+y)⩽1. Since g is a VP-MDFF, it is also superadditive due to Theorem 1. Therefore, g(x+y)⩾g(x)+g(y)=f(x)+f(y), such that f is superadditive. □The function f: [0,1]2→[0,1] with 0⩽u1, u2⩽1/2 and r, q∈{1,2}, which is defined as(22)f(x;u1,u2,r,q)≔1,ifxq>1-u1or(xq⩾u1andx3-q>1-u2),xr,if1-u1⩾xq⩾u1and1-u2⩾x3-q⩾u2,0,otherwise,is a VP-MDFF.For q=1, this function is a special case of the generalization described in Proposition 7 with m=2, u=(u1,u2)⊤ and g being the projection x↦xr. If q=2, then x1 and x2 are tested in reverse order, i.e. first x2 is compared with u1 and 1−u1, and only if that does not immediately lead to the function value 0 or 1 then x1 is examined. That yields f(x;u1,u2,r,2)=f(x2,x1;u1,u2,3−r,1). That case leads again to a VP-MDFF. □In this subsection, we introduce a new VP-MDFF in its general form, and a similar function for the 2-dimensional case. This VP-MDFF depends on a non-decreasing function whose properties are stated below. At the end of the subsection, we describe how this non-decreasing function should be chosen so as to obtain the best lower bounds with the corresponding VP-MDFFs.Proposition 8Letm∈N⧹{0}, k∈(1/3,1/2], g: [0,1]m→[0,1] be a non-decreasing function with(23)x,y∈[0,1]m,x+y⩾w⇒g(x)+g(y)⩾1,and let M be a subset of[0,1]m⧹12wsuch thatx∈M⇔w−x∉M for allx∈[0,1]m⧹12w.The function f: [0,1]m+1→[0,1] defined as(24)f(x,xm+1;k)≔0,ifxm+1<k,1,ifxm+1>1-k,1/2,ifx1=x2=…=xm+1=1/2,g(x),if1/2<xm+1⩽1-kor(xm+1=1/2andx∈M),1-g(w-x),ifk⩽xm+1<1/2or(xm+1=1/2andw-x∈M),is a VP-MDFF.The proof relies on Theorem 2. First, we verify that the function f is well defined, i.e. for any argument there is exactly one value assigned. Then, we show that f is symmetric, non-decreasing and finally superadditive.If xm+1≠1/2 then depending only on xm+1, exactly one of the first, second, fourth or fifth line of the definition of f is assigned to an argument. The 1st line applies namely for xm+1<k, the 5th line for k⩽xm+1<1/2, the 4th line for 1/2<xm+1⩽1−k and the 2nd line for xm+1>1−k.If xm+1=1/2 then the third, fourth or fifth line is selected depending on x, namely the 3rd line forx=12w, the 4th line for x∈M and the 5th line otherwise. This is so because for any x∈[0,1]mit holds eitherx=12wor x∈M or w−x∈M due to the definition of M.To prove the symmetry of f, we distinguish the following cases with regard to the value of xm+1:1.if x1=⋯=xm+1=1/2, thenf(x,xm+1)=f12w,1/2=1/2=1-f(w-x,1-xm+1);if xm+1<k, then f(x,xm+1)=0 and 1−xm+1>1−k. Hence, f(w−x,1−xm+1)=1;if xm+1>1−k, then f(x,xm+1)=1 and 1−xm+1<k. Hence, f(w−x,1−xm+1)=0;if 1/2<xm+1⩽1−k, then k⩽1−xm+1<1/2. Hence, f(x,xm+1)=g(x) and f(w−x,1−xm+1)=1−g(x);if k⩽xm+1<1/2, 1−k⩾1−xm+1>1/2. Hence, f(x,xm+1)=1−g(w−x) and f(w−x,1−xm+1)=g(w−x);if xm+1=1/2 and x∈M, f(x,xm+1)=g(x), and hence f(w−x)=1−g(w−(w−x));if xm+1=1/2 and w−x∈M, f(x,xm+1)=1−g(w−x) and w−(w−x)∈M. Hence, f(w−x,xm+1)=g(w−x), such that the symmetry is valid in this case too.To prove that f is non-decreasing, let x, y∈[0,1]mand xm+1, ym+1∈[0,1], with x⩽y and xm+1⩽ym+1. We have to show that f(x,xm+1)⩽f(y,ym+1). This is obvious for xm+1<k or ym+1>1−k, since for these cases we have respectively f(x,xm+1)=0 and f(y,ym+1)=1. Therefore, we assume that k⩽xm+1⩽ym+1⩽1−k. To complete our proof concerning the monotonicity of f, we distinguish the following cases with regard to (x,xm+1) and (y,ym+1):1.if for (x,xm+1) and (y,ym+1), the same line in the definition of f has to be applied. Then, x⩽y and the monotonicity of g imply g(x)⩽g(y) and g(w−x)⩾g(w−y), and hence f(x,xm+1)⩽f(y,ym+1);if(k⩽xm+1<1/2)or(xm+1=1/2andw-x∈M)and(1/2<ym+1⩽1-k)or(ym+1=1/2andy∈M),then f(x,xm+1)=1−g(w−x), f(y,ym+1)=g(y) and x⩽y lead to f(x,xm+1)⩽f(y,ym+1), because g(w−x)+g(y)⩾1 due to (23), since w−x+y⩾w;if (k⩽xm+1<1/2) or (xm+1=1/2 and w−x∈M), and y1=⋯=ym+1=1/2, theng(w-x)⩾g12w⩾1/2, sincex⩽y=12w, and hencef(x,xm+1)=1-g(w-x)⩽1/2=f(y,ym+1);The remaining casex1=⋯=xm+1=1/2and((1/2<ym+1⩽1-k)or(ym+1=1/2andy∈M))can easily be handled by the symmetry of f, namely k⩽ 1−ym+1<1/2 or (1−ym+1=1/2 and w−(w−y)∈M), yielding f(w−y,1−ym+1)⩽1/2 due to the previous case. That gives 1/2⩾1−f(y,ym+1) by symmetry, and hence f(y,ym+1)⩾1/2=f(x,xm+1).The superadditivity of f is proved as follows. Let x, y∈[0,1]mand xm+1, ym+1∈[0,1], with x+y⩽w and xm+1+ym+1⩽1. Assume that f(x,xm+1)>0 and f(y,ym+1)>0, otherwise the superadditivity is obvious. Therefore, xm+1⩾k and ym+1⩾k, and hence xm+1+ym+1⩾2k>1−k, implying f(x+y,xm+1+ym+1)=1. The monotonicity and symmetry of f yield alsof(x,xm+1)⩽f(w-y,1-ym+1)=1-f(y,ym+1),and hencef(x,xm+1)+f(y,ym+1)⩽f(x+y,xm+1+ym+1)=1.□Note, here it is not necessary to demand the condition (15) to M.For m=1 andM=12,1, the function (24) becomesf(x1,x2;k)=0,ifx2<k,1,ifx2>1-k,1/2,ifx1=x2=1/2,g(x1),if1/2<x2⩽1-kor(x2=1/2andx1>1/2),1-g(1-x1),ifk⩽x2<1/2or(x2=1/2andx1<1/2).The following VP-MDFF is similar, but it differs for x1∈{0,1}, i.e. it may get other function values in these cases.Proposition 9Let g be a non-decreasing function defined from [0,1] to [0,1], such that(25)g(y)+g(1-y)⩾1,for ally∈[0,1].The function f: [0,1]2→[0,1] with k∈(1/3,1/2] and defined asf(x;k)≔0,ifx1=0or(x1<1andx2<k),1,ifx1=1or(x1>0andx2>1-k),1/2,ifx1=x2=1/2,g(x1),if(1/2<x2⩽1-kand0<x1<1)or(x2=1/2and1/2<x1<1),1-g(1-x1),if(k⩽x2<1/2and0<x1<1)or(x2=1/2and0<x1<1/2),is a VP-MDFF.The proof relies on Theorem 2, and it is organized as the one for Proposition 8. First, we verify that f is well defined, i.e. we assign to any argument exactly one value. Then, we show that f is symmetric, non-decreasing and superadditive. The analysis can be restricted to the cases with x1∈{0,1}, because for 0<x1<1 it is the same as the above given special case of Proposition 8 for m=1 andM=12,1.The function f is defined with the required domain and range. If x1∈{0,1}, then the first or second line in the definition of f applies, while the fourth and fifth line explicitly exclude the case x1∈{0,1}.The symmetry becomes obvious for x1∈{0,1}. If x1=0, then f(x)=0 and 1−x1=1, and hence f(w−x)=1. If x1=1, then f(x)=1 and 1−x1=0, and hence f(w−x)=0.To show that f is non-decreasing, choose any x, y∈[0,1]2 with x⩽y and (x1∈{0,1} or y1∈{0,1}).If x1=0, then f(x)=0⩽f(y). If x1=1, then y1=1, and hence f(y)=1=f(x). The proof for y1∈{0,1} is similar. It remains to show that f is superadditive. Let x, y∈[0,1]2 with x+y⩽w. If f(x)=0 or f(y)=0, then the monotonicity of f implies that f is superadditive. Therefore, we assume that f(x)>0 and f(y)>0. We have x1, y1>0 and x2, y2⩾k, which yields x2+y2⩾2k>1−k and x1+y1>0, and hence f(x+y)=1. Since f is non-decreasing and symmetric, it follows that f(y)⩽f(w−x)=1−f(x). Hence, we have f(x)+f(y)⩽f(x+y) such that f is superadditive. □In the following proposition, we show how the g function in Proposition 9 should be defined so as to get the best lower bound that can be obtained from the corresponding VP-DFF f(x;k) for the 2D-VPP.Proposition 10Given an instance of the 2D-VPP, the best lower bound based on the function f ofProposition 9can be found with the following function g: [0,1]→{0,1/2,1} that depends on the parameterss,t∈Rwith 0⩽s⩽1/2 and s⩽t⩽1−s:g(x)≔0,ifx<s,1/2,ifs⩽x⩽t,1,ifx>t.Assume that we are given a function g: [0,1]→[0,1] that satisfies the prerequisites of Proposition 9, i.e. g is non-decreasing and obeys the condition (25). First, we analyze the structure of the resulting bound (16), then we simplify the function g without decreasing the obtained bound z[f]. We will show that an optimal function g can be found, which has only function values in {0,1/2,1}.If the function f of Proposition 9 is applied to an item of size (y1,y2) and with order demand b, then one of the values 0, b, b/2, b×g(y1) or b−b×g(1−y1) is added in the bound z[f], because f(y)∈{0,1/2,1,g(y1),1−g(1−y1)}. Therefore, applying the function f of Proposition 9 to an instance with n items and a bin size (1,1) yields the lower bound (16) in the form(26)z[f]=c+∑i=1n′aig(xi),withn′∈N,n′⩽n,2c∈Nandai∈Z⧹{0}, while either xior 1−xiare item sizes.Assume without loss of generality that0<x1<⋯<xn′<1. Now we begin to simplify g without affecting the bound (26). Letxn′+1≔1. Especially, g(x)≔g(x1) for all x∈[0,x1) and g(x)≔g(xi) for x∈(xi−1,xi), i=2,…,n′+1, preserves the monotonicity of g and the property (25). In this way, g becomes a staircase function. The xiand the coefficients c and aiare given; the g(xi) have to be selected to maximize the expression (26) under the restrictions of g described in Proposition 9, i.e.0⩽g(x1)⩽…⩽g(xn′)⩽1andxi+xj⩾1⇒g(xi)+g(xj)⩾1for alli,j∈{1,…,n′}. Calculating an optimal function g can be done by considering the following arguments based on dominance:1.if there is an i∈{1,…,n′−1} with ai⩾ 0, then set g(xi)≔g(xi+1), because this is the largest value that is allowed for g(xi) due to the monotonicity condition. Smaller values for g(xi) cannot increase the expression (26). Moreover, if the condition (25) is fulfilled for a given value of g(xi), then it is clearly obeyed for larger values of g(xi) too. Because of g(xi)=g(xi+1), the expression (26) remains unchanged, if one sets ai+1≔ai+1+aiand after that ai≔0. Such terms with ai=0 can be cut out immediately;ifan′⩾0, theng(xn′)≔1is analogously an optimal choice because of the restrictiong(xn′)⩽1. To simplify the expression (26), setc≔c+an′and after that n′≔n′−1, such that the last summand disappears without changing the value of the bound (26);after eliminating the nonnegative coefficients aiaccording to the former points 1 and 2, only negative coefficients aimay remain in the bound (26). If some negative coefficients (and no positive ones) remained, then the further simplifications depend on the xiitself, as stated in the following;ifx1+xn′<1(a1⩽0 andan′⩽0), then g(x1)≔0 is an optimal choice, because it has no influence on condition (25) or on the monotonicity of g;if only one term aig(xi) with ai<0 and 1/2⩽xi<1 remained in the sum (26), then set g(xi)≔1/2 according to the condition (25);If n′⩾2 andx1+xn′-1⩾1, then setg(xn′)≔g(xn′-1)or equivalentlyan′-1≔an′-1+an′and then n′≔n′−1. The monotonicity of g and the condition (25) are not affected by these changes;Ifa1>an′andxn′-1<1-x1⩽xn′, then setg(x1)≔1-g(xn′), because a smaller value of g(x1) is not allowed due to condition (25). Larger values of g(x1) are neither useful for the bound (26) nor necessary. Sinceg(x1)=1-g(xn′), one getsa1g(x1)+an′g(xn′)=a1+(an′-a1)g(xn′), and hence this case can be simplified byc≔c+a1,an′≔an′-a1and then a1≔0.Otherwise, i.e.a1⩽an′⩽0andxn′-1<1-x1⩽xn′, an optimal choice is g(x1)≔0, andg(xn′)≔1to maximize the expression (26) under the given conditions.The simplifications of the bound (26) can be done in a loop, which leads always to g(x)∈{0,1/2,1} for the considered arguments and an optimal staircase function g. Since that holds for all values k, which have to be explored (and that are not more than n+1 ones), the assertion follows. □Let s, t∈(0,1]m, and let u1, u2 be feasible (not necessarily optimal) dual values for an instance of the mD-VPP with two items of sizes s and t, each demanded at least once. The following proposition describes a new family of VP-DFFs. Recall that these functions can be transformed into VP-MDFFs by enforcing symmetry through Proposition 3.Proposition 11The function f: [0,1]m→[0,1] is a superadditive VP-DFF:f(x)≔max{a1u1+a2u2|a1,a2∈N,a1s+a2t⩽x}.First, we show that the range of f belongs to [0,1]. Then, we prove that f is superadditive and finally that f is a VP-DFF.Since u1, u2 are feasible values for the dual problem, it follows that u1, u2⩾0. Because off(x)⩾0u1+0u2=0anda1u1+a2u2⩽1,for alla1,a2∈Nwith a1s+a2t⩽w, the range of f is a subset of [0,1]. To show the superadditivity of f, let x, y∈[0,1]mwith x+y⩽w. Then, we havef(x+y)=max{a1u1+a2u2|a1,a2∈N,a1s+a2t⩽x+y}⩾max{a11u1+a21u2|a11,a21∈N,a11s+a21t⩽x}+max{a12u1+a22u2|a12,a22∈N,a12s+a22t⩽y}=f(x)+f(y).To show that f is a VP-DFF, choose any finite index-set J and vectors xj∈[0,1]m(j∈J), with∑j∈Jxj⩽w. The superadditivity yields∑j∈Jf(xj)⩽f(∑j∈Jxj)⩽1due to the range of f. □Calculating the function requires to solve an integer optimization problem for every argument x, but the complexity remains low, if the possible valuesa1,a2∈Nare bounded by a small constant. Without loss of generality, assume that maxi∈{1,…,m}si⩽maxi∈{1,…,m}ti. Since there are only two items s,t>o, the function value can be easily calculated by trying all possible numbers a2, i.e.a2∈Nand a2⩽min{xi/ti: i∈{1,…,m}}, and setting a1≔⌊mini∈{1,…, m}(xi−a2*ti)/si⌋. The effort for these calculations is the same as for dynamic optimization with exactly two different items. Therefore, the complexity to calculate a1 and a2 is pseudo-polynomial.In this section, we discuss the implementation details of the lower bounding procedures related to the VP-MDFFs proposed above, and we report on the complexity of these procedures. We focus on the specific procedures that were implemented and tested, and whose results are reported in Section 8.First, we recall the complexity of computing lower bounds for the mD-VPP using the column generation approach applied to formulation (8)–(10). The generation of a new column for (8)–(10) requires to solve an m-dimensional knapsack problem, which is well-known to beNP-complete. At each iteration of the column generation algorithm, the corresponding m-dimensional knapsack problem can be solved in pseudo-polynomial time using dynamic programming. Furthermore, the number of columns of (8)–(10) grows exponentially with the number n of items in the problem. Below, we will show that our VP-MDFF based lower bounding procedures for the mD-VPP are much more efficient than the column generation approach. Indeed, all these procedures except the last one are algorithms of polynomial complexity.Below, we identify the specific VP-MDFFs that were considered. A lower bounding procedure for the mD-VPP is defined from each function. These procedures rely essentially on (16). The details of the implementation of each one of these VP-MDFF based lower bounding procedures and their corresponding complexity are discussed next.(a): VP-MDFF of Proposition 5 with g=fCCM,1;: VP-MDFF of Corollary 1 (Proposition 5 with g=fFS,1);: VP-MDFF of Corollary 2 (Proposition 5 with g=fBJ,1);: VP-MDFF of Corollary 3 (using f2 and g obtained from Proposition 5 and fCCM,1);: VP-MDFF of Corollary 4 (with g obtained from Proposition 5 and fCCM,1);: VP-MDFF of Corollary 5 (with g(x)≔∥x∥p−c with constantsp,c∈R, p⩾1);: VP-MDFF of Corollary 6;: VP-MDFF of Proposition 9 with the function g described in Proposition 10.: VP-DFF of Proposition 11 by forcing symmetry as discussed in Proposition 3.Cases (a)–(e)The lower bounding procedures related to (a)–(c) correspond to the lower bounding scheme (16) applied with the VP-MDFFs obtained from Proposition 5 with g∈{fCCM,1,fFS,1,fBJ,1}. The last two functions lead respectively to the functions of Corollaries 1 and 2. The cases (d) and (e) are associated to VP-MDFFs constructed from Corollaries 3 and 4 with g based on Proposition 5 with fCCM,1.In each one of these cases, the use of the corresponding function causes the complexityO(n)in the evaluation of the bound (16). These functions are used with pseudo-random parameters. The number of parameter sets that are tried is a constant for each function, i.e. it is independent from the number n of items.Case (f)The lower bounding procedure related to (f) relies on (16) and on the VP-MDFF of Corollary 5 with g′(x)≔∥x∥p−c and constantsp,c∈R, p⩾1. Let I1≔{i∈{1,…,n}: w⊤li>m/2 and g′(w−li)<0} and(27)I2≔{i∈{1,…,n}⧹I1:w⊤li⩾m/2org′(li)⩾0}.Then, the bound (16) can be rewritten as follows(28)z[f]=∑i∈I1bi+maxr∈{1,…,m}sr, withs≔∑i∈I2bi×li.Using (28) simplifies the search for the best parameter values with low complexity. Computing z[f] from (16) requiresO(n)evaluations of the VP-DFF f for each chosen parameter set. In the form (28), the effortO(n)is needed only once for an initial parameter set. After that, if each change of the parameters modifies the sets I1 and I2 by at most one element, recomputing z[f] requires only the complexityO(1)instead ofO(n). Therefore, if the parameter sets are adapted according to the input data, the total complexity can be reduced by a factor up to n in the evaluation of z[f].Since choosing p optimally is not obvious, an exponential sequence p∈{1,1.1,1.12,…,1.129} is tried. For each of these 30 different values, the remaining parameters c and r in Corollary 5 can be chosen optimally by trying allc∈{m,‖li‖p:i∈{1,…,n}∧w⊤li<m/2}.For given parameters p and c, the set I2 is determined by (27), such that the index r can be found according to (28). The choice c≔m is sufficiently large to assign all items the value 0 or 1, except to items liwith w⊤li=m/2, because‖w‖p=mp⩽m. To achieve a small complexity, we sort the items first, and then a loop with complexityO(mn)is executed. Without sorting the items, it would be necessary to try up to n+1 values of c, and to evaluate each of the n items according to the function f for the given c with complexityO(m), such that the total complexity would rise toO(mn2). Hence, for each p, the computation of the lower bound can be done with complexityO(mnlnn).The details of this procedure are described in Algorithm 1. Items liwith w⊤li=m/2 never get the value 0 or 1 in the first or second line of the definition of the function f in Corollary 5. Therefore, they are separated from the other items and they are always considered in the set I2 in the bound (28). Other items of sizes x and y might be put into one container if w⊤x<m/2<w⊤y and ∥x∥p=∥w−y∥p. Therefore, such items are either considered simultaneously in the set I2 in the bound (28), or none of them. To handle these situations efficiently, including the ordering of the items and the comparisons between them, the following auxiliary functionh:[0,1]m→R+is used:h(x)≔m,ifw⊤x=m/2,‖x‖p,ifw⊤x<m/2,‖w-x‖p,otherwise.Since‖w‖p=mp, it follows that h(x)<m, for all x for which w⊤x≠m/2. Therefore, items liwith w⊤li=m/2 will always be placed in the last positions after the sorting that is done at the beginning of the algorithm.Algorithm 1Lower bounding procedure for the mD-VPP based on the VP-MDFF of case (f)In Algorithm 1, the variable k counts the items which are assigned the value 1 according to Corollary 5, with g′(x)=∥x∥p−c for enough large c, i.e. items liwith w⊤li>m/2∧c>∥w−li∥p. If c⩽0, then g′(x)⩾0 for all x, such that f(x)=xrfor all x∈[0,1]m. In that case, only the material bound is calculated, i.e.s=∑i=1nbi×liand z=maxr∈{1,…,m}sr.When the statement t≔h(li) is reached for a given i, then using c≔t implies h(lj)⩽c for all j∈{1,…,i}, due to the sorting that is done at the beginning. Items lj, with h(lj)=c, will still be counted for s, but all later processed items are assigned values 0 or 1 in the VP-MDFF f of Corollary 5. Therefore, the set I2 does not contain any of the remaining items for this value c, such that it is only necessary to count the number of remaining items, which will get the value 1 due to the function f of Corollary 5. If in the last repeat-until-loop, the counter k is increased, then these items must be put into new containers, but the residual space in these containers can be used for small items. Therefore, it is necessary to subtract k before comparing t with the former bound z.Since the index i is decremented in every passage of the loops, the complexity without the sorting would beO(mn). Sorting n items requiresO(nlnn)comparisons and possible exchanges. Since we have also to consider the dimension m of the items, the complexity becomesO(mnlnn).Case (g)A lower bounding procedure based on (16) and on the VP-MDFF of Corollary 6 is described in Algorithm 2. Since the functions (21) and (22) share some similarities (f(x)=xrfor some x with the parameter r∈{1,…,m}, and f(x)∈{0,1} otherwise), it is again advantageous to rewrite the bound (16) in the form (28), but with other sets I1, I2, namely I1≔{i∈{1,…,n}:ℓiq>1−u1∨(ℓiq⩾u1∄ℓi,3−q>1−u2)} and I2≔{i∈{1,…,n}:u1⩽ℓiq⩽1−u1∄u2⩽ℓi,3−q≤1−u2}, with q∈{1,2}. An optimal choice of u1, u2 for a given q is possible with u1∈{1/2,ℓiq:i∈{1,…,n}∄ℓiq<1/2} and u2∈{1/2,ℓi,3−q:i∈{1,…,n}∄ℓi,3−q<1/2}. Since up to (n+1)2 pairs (u1,u2) have to be tested, and the computation of the bound (28) for one pair (u1,u2) requires a complexityO(n), a naive implementation would have the total complexityO(n3). However, by using a suitable sorting, the complexity decreases toO(n2)as it happens in Algorithm 2. The goal of the sorting is that for fixed variables q and u1, the change of the sets I1 and I2 in every step where u2 is modified applies to at most one element. This objective is achieved by the sorting in Algorithm 2. When u2≔ℓi,3−q⩽1/2 is set for a given i∈{1,…,n}, it follows for all j∈{1,…,i} that either ℓj,3−q⩽u2 or ℓj,3−q>1−u2. Therefore, except for ℓj,3−q=u2, no more items j∈{1,…,i} can belong to I2. Algorithm 2 is used with q=1 and q=2, and the better of the two bounds is chosen.Algorithm 2Lower bounding procedure for the mD-VPP based on the VP-MDFF of case (g)The worst case is reached when all the values ℓiqare different and less than 1/2. In this case, the outer loop is passed n+1 times with u1∈{1/2−ε,ℓiq−ε} and i∈{1,…,n}. Therefore, the complexity of the algorithm isO(n2).The variables k1 and k2 count the number of items that (may) get the value 1 in the comparison with u1,u2 in the VP-MDFF of Corollary 6. If the statement t≔max{s1,s2}−k2 is reached for a given i, then the sorting at the beginning implies ℓj,3−q>1−ℓi,3−qor ℓj,3−q⩽ℓi,3−q, for all j∈{1,…,i}. Therefore, trying u2≔ℓi,3−qcauses f(lj)∈{0,1}, for all j∈{1,…,i∣ℓj,3−q≠u2}, i.e. the set I2 cannot contain later processed items, such that the bound (28) can be computed as in case (f).Case (h)The lower bounding procedure related to (h) relies on the bound (26), which was derived from (16), and on the VP-MDFF of Proposition 9. In our implementation, its complexity isO(n3). The details of our implementation are given in Algorithm 3. The function g used in this VP-MDFF is the one described in Proposition 10. After sorting the items, we chooseO(n)times values of the variable k, namely all k∈{1/2,ℓiq−ε:i∈{1,…,n}∄ 1/3<ℓiq<1/2}, with q∈{1,2} and ε>0 being an enough small constant. If q=2 then the function f of Proposition 9 is taken literally, while for q=1 the first and second dimension are exchanged. For each value of k, the function g is obtained optimally according to Proposition 10. For this purpose, we use a vector of lengthO(n)to represent the function g. This vector is initialized each time with complexityO(n2)in the loop fori2≔ndownto 1 do … in Algorithm 3. For given values k∈(1/3,1/2] and q∈{1,2}, we check first if an itemli2is assigned a value 0, 1 or 1/2 in the function f of Proposition 9. If that is not the case, i.e. the function g plays a role in the evaluation off(li2), then the required data with respect to that item in (26) are collected in a vector, which is sorted in non-decreasing order of the arguments of g. The sorting by insertion requires the complexityO(n2), and since it is executed up to n+1 times, the total complexity of our implementation isO(n3). The simplifications according to the case distinction in the proof of Proposition 10 need only the effortO(n). That is done in Algorithm 3 in the conditional block if (i3>1) then … in the same sequence as in the proof of Proposition 10. At the end, only the number c in the expression (26) remains as bound. Hence, the total complexity of computing the bound through this procedure isO(n3). Finally, the lower procedure described in Algorithm 3 is applied for q=1 and q=2, and the best bound is chosen.Algorithm 3Lower bounding procedure for the mD-VPP based on the VP-MDFF of case (h)Case (i)A lower bounding procedure based on (16) and on the VP-DFF of Proposition 11 with forced symmetry according to Proposition 3 requires first to choose two items as vectors s and t. Since there areO(n2)possibilities, we have to makeO(n2)calls to a subroutine to obtain the optimal values for a1, a2, u1, u2 on which this VP-DFF relies. In this subroutine, we compute first the optimal dual values u1, u2 for the two items of sizes s and t. For this step, we need to solve a linear optimization problem. After that, we compute the values a1 and a2. The complexity of this embedded subroutine is comparable with the one of dynamic optimization and can therefore be high. Without additional restrictions, this complexity will not be simply a polynomial in n, because a2 could be as large as maxi∈{1,…,n}{1/maxd∈{1,…, m}ℓid}. If all input data are integer with the maximum M, i.e. the container is not normalized to the unit cube, then this ratio can reach M, and hence the total complexity becomesO(Mn2), which is pseudo-polynomial. Nevertheless, since we have to consider only two items to evaluate this bound, the complexity may be lower than if n pieces would have been considered.Except for the last function, the complexity of these lower bounding procedures is polynomial. This allows to compute lower bounds much faster than by column generation. As a comparison, four of the five lower bounding procedures discussed in Caprara and Toth (2001) have a complexity that ranges fromO(n)toO(n4lnn)(their fifth bound relies on column generation), while the complexity of eight of our nine procedures (the ninth is the last one that is pseudopolynomial) ranges fromO(n)toO(n3). In the next section, we report on computational experiments that illustrate the efficiency of our procedures.In this section, we report on two sets of computational experiments that we conducted to evaluate both the quality of the bounds and the performance of the lower bounding procedures related to the VP-DFFs described above. As shown in Section 5, the best bound that a VP-DFF can generate is at most equal to the bound zCGof the LP relaxation of (8)–(10). While this bound is well-known to be strong, computing it by solving (8)–(10) through column generation can be very time consuming. Our first set of computational experiments shows that the VP-DFFs can approximate the bound zCGvery efficiently. In practice, it takes usually a fraction of seconds to compute the bounds using VP-DFFs. In our second set of experiments, we focus on the impact that the lower bounding procedures described above may have on the convergence of a branch-and-bound based algorithm for the 2D-VPP.We conducted our experiments on two sets of instances of the 2D-VPP. The first set (instance set I) was proposed in Caprara and Toth (2001) for the vector-packing problem, the second (instance set II) was proposed in Berkey and Wang (1987) and Martello and Vigo (1998) for the two-dimensional bin-packing problem. Within each group of the first set, the instances are further divided into 4 sets of 10 instances each according to the number of items which belongs to {25,50,100,200}. In the second set of instances, each set contains 50 instances divided in 5 sets of 10 instances with a number of items per instance in the set {20,40,60,80,100}. This set originally contains 10 groups of instances. However, for this set, we only kept the groups where the bound of Spieksma is strictly smaller than the column generation lower bound. Therefore, we only report our results for sets 1, 3, 5, 7, 8, 9, 10 of Berkey and Wang (1987) and Martello and Vigo (1998). The indices of these groups of instances have been updated accordingly. All the experiments were conducted on a PC with an Intel Core i3 CPU with 2.27gigahertz and 4gigabytes of RAM.For some of our VP-DFFs, we used the 1-dimensional DFF fCCM,1 proposed in Carlier et al. (2007) and described in Section 3. The results for our first set of experiments are reported in Tables 1–4. The entries in these tables have the following meaning: Inst. stands for the group of instances, n for the number of items, zCrepresents the lower bound given by the LP relaxation of (2)–(6) (equivalent to the bound of Spieksma (1994)) and zCGthe lower bound given by the LP relaxation of (8)–(10). The columns (a)–(i) are associated respectively to the cases (a)–(i) introduced in Section 7.In Tables 1–4, we report on the quality of the lower bounds provided by our VP-DFFs. In these tables, the results related to the VP-DFFs are divided in three parts. In the first part, we give the average lower bound obtained with the corresponding VP-DFF. The second part (Best bound) indicates the number of times the VP-DFFs give the best bound among all the VP-DFFs from cases (a)–(i). The last part of these tables (Equals zCG) shows the number of times the bound given by the VP-DFF is equal to the column generation bound zCG.From Tables 1 and 2, we can observe that the average lower bounds provided by the VP-DFFs are very near from the average column generation bound. The worst case is for the group 9 of instances with n=25. For this case, the relative gap between the bounds based on VP-DFFs is at least 14%. Note that, for these instances, zCand zCGare small values. Furthermore, the difference between zCand zCGfor all the instances of this group is always equal to 1. For all the other instances of this set, one of our VP-DFFs gives always a lower bound whose relative gap compared to the column generation bound is at most 7%. For the instance sets 1, 4, 5, and 10, the lower bounds provided by the VP-DFFs are always equal to the column generation bound zCG, which is in turn always equal to zC.The performance of our VP-DFFs is better illustrated in the final part of Table 1, where we report on the number of times the bounds obtained with the VP-DFFs are as good as the bounds given by the LP relaxation of the column generation model. Almost all the VP-DFFs provide a bound equal to zCGfor a significant number of cases. In fact, for 309 of the 400 instances of set I, one of our VP-DFFs always gives a lower bound that is equal to zCG. For the other instances, the average value of the differences between zCGand the best bounds obtained with a VP-DFF is equal to only 1.87. Note that the bounds obtained with VP-DFFs are computed usually in a few milliseconds, i.e. much more efficiently than using column generation. Furthermore, it is interesting to note that the only group of instances (apart from the sets 1, 4, 5, and 10) where the bound zCGwas reached for all the instances with at least one of our VP-DFFs is the group 8, for which the difference between zCand zCGis large. The best results are obtained for groups 2, 3, and 8. For the two first, the instances were generated uniformly on both dimensions: functions denoted (g), (h) and (i) lead to the best results for them. For group 8, where many items are large on exactly one dimension, functions (a) to (e) perform better.Tables 3 and 4 illustrate the results obtained with the instance set II. For each group, there is always one VP-DFF that provides a lower bound with a relative gap of at most 5% compared to zCG. For this set of instances, the best results are achieved with the VP-DFF of Proposition 11 (and the corresponding lower bounding procedure related to the case (i) introduced in Section 7). In 273 of 350 instances, the best bound is given by this VP-DFF, while for 200 of these instances, this bound is equal to zCG. The VP-DFF of case (i) returns the best results for all instances of groups 1, 2, 3, and 6. For groups 4, 5, and 7, the best results on average are obtained by VP-DFF (g). In the three groups where (g) performs better, the number of items that are large on both dimensions is small (10% on average). For groups 1, 2, 3, and 6, this ratio is much larger, which hints that (i) is well suited to such instances.For 255 of the 350 instances in set II, there is always one VP-DFF that yields a bound equal to zCG. For the remaining instances, the average value of the differences between the bounds provided by the VP-DFFs and zCGis equal to only 1.2. These results confirm the previous ones obtained for the instance set I. For the majority of the cases, the VP-DFFs presented in this paper lead to lower bounds that are as good as the column generation bound. The advantage is that they require only a very small fraction of the computing time that is needed to compute the column generation bound. For the other instances, the lower bounds achieved with these VP-DFFs remain very near from these column generation bounds.The objective of our second set of experiments is to evaluate the impact of our lower bounding procedures on the convergence of a branch-and-bound based algorithm for the 2D-VPP. We consider again the cases (a)–(i) described in the previous section. We compare in particular the impact of our procedures with an alternative approach that relies essentially on column generation. For this purpose, we implemented a branch-and-price algorithm for the 2D-VPP, and we tested two versions of this algorithm: one without the lower bounding procedures related to the cases (a)–(i) and another that resorts to these procedures. In the latter, we tested each one of the cases (a)–(i) separately. The results of these experiments are reported in Tables 5–7.At each node of the branching tree, the LP relaxation of (8)–(10) is solved exactly using column generation. The corresponding restricted master problems are solved using CPLEX 12.2. The pricing subproblems are multidimensional knapsack problems, which are solved also up to optimality using CPLEX 12.2. At each iteration of the column generation procedure, the most attractive column is added to the restricted master problem, which is solved again until there are no more attractive columns. If the solution of the restricted master problem at a given node is not integer, and the node cannot be pruned by bound, two nodes are created using the following branching rule. Let δijdenote the sum of all the variables λpin (8)–(10) that include both the item i and the item j, with i,j∈{1,…,n} and i≠j. Among all the fractional δijat a given branching node, we choose the one that is closer to 0.5. Assume that a and b are the items related to the variable δijthat is selected, and let P′ be the subset of patterns that include both the items a and b. The branching constraints that are enforced stand respectively as follows:∑p∈P′λp=0and∑p∈P′λp=1. Note that this branching scheme works for instances whose items have unit demands bi=1, i=1,…,n. The branching tree is explored using a depth-first search strategy. This pure branch-and-price algorithm is denoted by BP in Tables 5–7.As an alternative, we implemented and tested a version of this algorithm that resorts to the lower bounding procedures related to the cases (a)–(i) described above. At each node of the branching tree, we first apply one of these lower bounding procedures. Let zVPDFFdenote the resulting bound. If the node cannot be pruned immediately using zVPDFF, then we enforce the constraint∑p∈Pλp⩾zVPDFFin the master problem and we solve it using column generation. All the other features of the branch-and-price algorithm remain unchanged. We tested this version of the branch-and-price algorithm with each one of the cases (a)–(i) individually. In Tables 5–7, the results related to each case are given in the columns identified with the corresponding index (a)–(i) of the case.Column opt. in Tables 5–7 represents the number of instances solved up to optimality and t is the corresponding average computing time (in seconds) required to solve these instances. All the experiments were conducted with a time limit of 600seconds. In these tables, we removed the lines of the instance sets for which none of the approaches were able to find an optimal solution for at least one instance within the time limit.The results for the instance set I reported in Table 5 shows that the branch-and-price algorithm with our lower bounding procedures clearly outperforms the pure column generation based version of this algorithm. The reduction in the total computing time required to find an optimal solution goes up to nearly 99%. These results are even more impressive for the group 5 of instances. In this case, the pure branch-and-price algorithm failed in finding the optimal solution within the time limit for all the instances, while the branch-and-price algorithm with our lower bounding procedures could find these optimal solutions in much less than 1second for the majority of the instances. As shown in Tables 6 and 7, most of the instances of the set II are solved efficiently with the pure branch-and-price algorithm. Nevertheless, our lower bounding procedures still improve the convergence of the algorithm and reduces the total computing time to reach an optimal solution by up to nearly 63%. Note that the branching constraints∑p∈P′λp=1are used to eventually strengthen the lower bounds provided by the VPDFFs. These constraints force the items i and j to appear in the same pattern. These items are replaced by a single one with the sum of the sizes in both dimensions, which may impact positively in the quality of the lower bound. Indeed, from this node downward the lower bounds computed with the VPDFFs are obtained from the resulting instance with these aggregated items.

@&#CONCLUSIONS@&#
In this paper, we extended the concept of DFF to the multidimensional case. The functions that were proposed apply directly to the vector packing problem and, as a consequence, we called them vector packing dual-feasible functions. We explored the properties of these functions, and we described different families of such functions. We analyzed also the complexity of the related lower bounding procedures that can be defined from these functions. To evaluate the quality and performance of our approaches, we conducted a set of computational experiments on benchmark instances. Our results show that our functions are able to generate strong lower bounds. The utility of multidimensional dual-feasible functions goes far beyond the computation of lower bounds for vector packing problems. Indeed, these functions can be used to obtain valid inequalities for general mixed integer programs, i.e. any integer programming problem with multidimensional knapsack constraints.