@&#MAIN-TITLE@&#
Measures of dispersion for multidimensional data

@&#HIGHLIGHTS@&#
We propose an axiomatic definition of a dispersion measure for k-dimensional data.We introduce a new taxonomy of the dispersion measures.We consider a relationship between dispersion measures and multidistances.We examine new properties of the interquartile range and sample variance.

@&#KEYPHRASES@&#
Descriptive statistics,Dispersion,Interquartile range,Multidistance,Spread,

@&#ABSTRACT@&#
We propose an axiomatic definition of a dispersion measure that could be applied for any finite sample of k-dimensional real observations. Next we introduce a taxonomy of the dispersion measures based on the possible behavior of these measures with respect to new upcoming observations. This way we get two classes of unstable and absorptive dispersion measures. We examine their properties and illustrate them by examples. We also consider a relationship between multidimensional dispersion measures and multidistances. Moreover, we examine new interesting properties of some well-known dispersion measures for one-dimensional data like the interquartile range and a sample variance.

@&#INTRODUCTION@&#
Various summary statistics are always applied wherever decisions are based on sample data. The main goal of those characteristics is to deliver a synthetic information on basic features of a data set under study. It seems that the most commonly used summary statistics are central tendency measures (like the mean, median, mode, etc.) indicating a typical behavior of the examined variable. However, no measure of central tendency can reveal the whole picture of a variable. Indeed, two or more samples may have the same mean (or other central tendency) although they differ significantly. Therefore, besides central tendency a dispersion of observations in a sample is also of interest. Moreover, in many cases we have to monitor variability as carefully as the location parameters. As a typical example let us consider the Statistical Process Control where no alarm signal found on theX¯-chart cannot be automatically interpreted as the process is under control until the S-chart (or R-chart) confirms no alarm caused by the increase of variability.Many tools have been proposed to characterize dispersion, like the range, interquartile range, sample variance, standard deviation an so on. They differ in construction, properties and situations they are intended for use. It is also worth mentioning that several terms are used in the literature as regards dispersion measures like measures of variability, scatter, spread or scale. Some authors reserve the notion of the dispersion measure only to those cases when variability is considered relative to a given fixed point (like a sample variance which averages squared deviation of the data points from their mean) and then use the term spread as a more general one (see Bickel & Lehmann (1976, 1979); Wilcox (2005)). However, such distinction in terminology is neither consistent nor commonly accepted. Thus in our paper we do not attach importance to such distinctions.Some of the considered tools measure the absolute spread (like those mentioned before), while the other indicate the relative scatter (e.g. the coefficient of variation or Gini coefficient). Most of them are dedicated to quantitative data (ratio scale) but one can found also a few that might be used to characterize qualitative observations (nominal scale).What is interesting is that almost all well-known measures of dispersion could be used only for one-dimensional data. It is rather inconvenient especially that most of the contemporary data sets available and processed in practice is multidimensional. Of course, having such multidimensional data set one may apply univariate dispersion measures to each variable separately, but this way we loose information on possible relations between variables. Then, as a possible remedium, one may consider e.g. a covariance matrix which delivers both variances of all single variables and covariances for all pairs of variables. Hence, having a data set of k-dimensional observations we get a matrix of k2 numbers instead of a single real value of a desired measure of dispersion characterizing somehow the whole multidimensional sample.Keeping in mind all the remarks mentioned above we propose a general definition of a dispersion measure that could be applied for any finite sample of k-dimensional real observations, i.e.x1,…,xn∈Rk. Next we examine basic properties of so defined measures and illustrate them by examples. We also consider the relationship between multidimensional dispersion measures and multidistances introduced by Martín and Mayor (2009, 2011).Recently, Gagolewski (2015) considered the dispersion measures from the aggregation theory point of view. He showed that although aggregation theory mainly focuses on central tendency measures (see Beliakov, Pradera, & Calvo (2007); Calvo, Mayor, and Mesiar (2002); Grabisch, Marichal, Mesiar, and Pap (2009)), it may deliver an interesting insight to measures of spread of one-dimensional quantitative data. In our case we show that some considerations on general multidimensional dispersion measures may also lead to some interesting conclusions for one-dimensional data sets.The paper is organized as follows: In Section 2 we present the desired requirements each measure of dispersion should satisfy. Next, we distinguish two basic types of dispersion measures: unstable and absorptive dispersion measures (Section 3 and Section 4, respectively). Section 5 is devoted to some interesting properties of the interquartile range that appear in practice when we try to estimate it from data. In Section 6 we prove a theorem showing a relation between unstable and absorptive dispersion measures. Finally, in Section 7 we examine the relationship between dispersion measures and multidistances.Consider a sample of n observations from the k-dimensional real space, i.e.x1,…,xn∈Rk. Descriptive statistics, also called summary statistics, provide various measured describing different aspects of the underlying data. Besides central tendency measures, the next group of the most useful summary statistics is formed by measures of dispersion. Although each person has some intuition about measures of dispersion, it seems that a formal definition would be desirable.Definition 2.1A functionΔ:⋃n=1∞(Rk)n→[0,∞)is called a measure of dispersion if Δ is not identically zero function which satisfies the following axioms for anyx1,…,xn∈Rk:(A1)Δ(x,…,x)=0Δ is symmetric, i.e.Δ(xπ(1),…,xπ(n))=Δ(x1,…,xn)for any permutationπ:{1,…,n}→{1,…,n},Δ is translation invariant, i.e.Δ(x1+a,…,xn+a)=Δ(x1,…,xn)for anya∈Rk,Δ is rotation invariant, i.e.Δ(Rx1,…,Rxn)=Δ(x1,…,xn)for any rotation matrixRk(i.e. R is an orthogonal matrix and such thatdetR=1).Sometimes one more axiom is also considered:(A5)there exists a functionρ:R→[0,∞)such thatΔ(ax1,…,axn)=ρ(a)Δ(x1,…,xn)fora∈R+.Usually adding another observation to a data set under study we expect changes in the dispersion measure value, no matter where the new point is located. However, there also exists a class of measures for which by adding new observations we do not change the scatter of the data set (provided those observations belong to some area). To clarify the situation in further sections we indicate two important subfamilies of dispersion measures.Definition 3.1A measure of dispersionΔ:⋃n=1∞(Rk)n→[0,∞)is called unstable if(1)Δ(x1,…,xn,xn+1)≠Δ(x1,…,xn),for almost allxn+1∈Rk.In other words, for any unstable dispersion measure and any data set there exist a set which has the k-dimensional Lebesgue measure zero and such that joining any its point to the data set do not change a value of the dispersion obtained for the initial data set. Let us now discuss some examples and basic properties of the unstable dispersion measures.Example 3.2A one-dimensional sample, i.e.x1,…,xn∈Rprovides many examples of well-known unstable dispersion measures, like different sample variances:s2=1n−1∑i=1n(xi−x¯)2,sb2=1n∑i=1n(xi−x¯)2or corresponding sample standard deviation.Having a samplex1,…,xn∈Rklet us define the following function(2)Ge(x1,…,xn)=∑i=1n∑j=1nde2(xi,xj),where de(xi, xj) denotes the Euclidean distance inRk. It can be shown that (2) is an unstable dispersion measure. To prove it, let us firstly assume thatAm=∑i=1n(xim−x¯m)2,whereximdenotes the mth component of xiandx¯m=1n∑i=1nxim. Then for any j we getAm=∑i=1n(xim−xjm+xjm−x¯m)2=∑i=1n(xim−xjm)2+2∑i=1n(xim−xjm)(xjm−x¯m)=∑i=1n(xim−xjm)2−n(xjm−x¯m)2.Summing up both sides over j we getnAm=∑i,j=1n(xim−xjm)2−nAm,which implies thatAm=12n∑i=1n∑j=1n(xim−xjm)2=1n∑1⩽i<j⩽n(xim−xjm)2and∑i=1n∑j=1nde2(xi,xj)=n∑m=1kAm=n(n−1)∑m=1kSm2,whereSm2denotes the sample variance ofx1m,…,xnm. It is clear that a linear combination of unstable measures is also an unstable dispersion measure.LetΔ1,…,Δmdenote unstable dispersion measures such that for alli=1,…,nandj=1,…,ma set{xi:Δj=0}has a zero Lebesgue measure and let f: [0, ∞)m→ [0, ∞) be a function which is not constant, is continuous andf(0)=0. ThenΔ′=f(Δ1,…,Δm)is also an unstable dispersion measure.Let δ be defined asδ(xn+1)=Δ′(x1,…,xn+1)−Δ′(x1,…,xn).Thenδ(xn+1)=0is an implicit function ofxn+1and the set ofxn+1which satisfy this equation has ak−dimensional Lebesgue measure equal to zero.□LetΣ=[cov(xi,xj)]i,j=1,…,ndenote a sample covariance matrix. By Lemma 3.4 one may easily conclude that such popular tools applied for characterizing a dispersion of multidimensional data like the determinant |Σ| or the trace tr(Σ) of the covariance matrix are unstable dispersion measures. Indeed, if we assume f to be the sum of measures and Δito be the product of sample covariances then we get the result.Let us consider a data setX={x1,…,xn}⊂R2. Moreover, assume that φ is the direction indicated by one of the eigenvectors of the covariance matrix[cov(xi,xj)]i,j=1,…,n.For a fixedN∈Nandφi=φ+iπ2N,i=0,…,N,let us defineSφi2as a sample variance ofXprojected on the direction φiand denote the mean ofSφ02,…,SφN2byV(x1,…,xn). It could be shown that V is an unstable dispersion measure andV(x1,…,xn)=12(Sφ02+SφN2)+CN[sin2φ(SφN2−Sφ02)+2Q0Ncos2φ],where Q0Nis the sample covariance of projections of(x1,…,xn)on φ0 and φN, whileCN=12(N+1)sinπN1−cosπN.Intuitively, it seems that adding a new observation the dispersion of a sample can increase or remain unchanged. But there are also such dispersion measures that can decrease as the data set enlarges. For example, consider a one-dimensional samplex1,…,xn∈Rand the sample varianceSn2=1n−1∑i=1n(xi−x¯n)2. Here the lower index n indicates that the sample variance is calculated using a sample of size n. Now, if we add an extra pointxn+1=x¯then the resulting varianceSn+12will be less thanSn2. In fact,xn+1=x¯is not the only point that decreases the sample variance. This simple remark leads to the following definition.Definition 3.7LetX={x1,…,xn}⊂Rkdenote a data set and let Δ be a dispersion measure. Then a set(3)KΔ={x∈Rk:Δ(x1,…,xn,x)−Δ(x1,…,xn)<0}will be called a collapse region of the dispersion measure Δ with respect toX.It is easily shown that for a one-dimensional sampleX={x1,…,xn}⊂Rwhen adding another observationxn+1the sample varianceSn+12of the enlarged sample could be expressed by the recursive formula as follows:Sn+12=n−1nSn2+1n+1(xn+1−x¯n)2.Hence,Sn+12−Sn2<0for anyxn+1∈Rsuch thatxn+1∈(x¯n−n+1nSn,x¯n+n+1nSn),which defines a collapse region of the sample variance with respect toX.Besides unstable dispersion measures there are also dispersion measures which may not change their value when adding a new observation to the initial data set. The most natural and immediate example is a sample range for one-dimensional data. Supposex1:n,…,xn:ndenote order statistics for a samplex1,…,xn∈R. Then, obviously,R(x1,…,xn)=xn:n−x1:n=R(x1,…,xn,xn+1)for any new observationxn+1such thatx1:n⩽xn+1⩽xn:n. To formalize the suggested property let us consider the following two definitions.Definition 4.1A measure of dispersionΔ:⋃n=1∞(Rk)n→[0,∞)is called absorptive if for each n and somex1,…,xnthere exists a setX*⊂Rksuch that itsk−dimensional Lebesgue measurelk(X*)>0and for anyxn+1∈X*(4)Δ(x1,…,xn,xn+1)=Δ(x1,…,xn).In other words, if Δ is an absorptive dispersion measure then for a certain data set there exists a set having non-zero Lebesgue measure, such that by joining any of its elements to the initial data set we do not change the scatter.Definition 4.2A measure of dispersionΔ:⋃n=1∞(Rk)n→[0,∞)is called strongly absorptive if Δ is absorptive for anyx1,…,xnand a nonempty setX*such thatlk(X*)=0holds only for some choices ofx1,…,xn.To understand better the last definition let us denote a sample space (i.e. a set of all possible outcomes of the experiment) by Ξ. Hence, if Δ is a strongly absorptive dispersion measure then there exist two sets Ξ1 ≠ ∅ and Ξ2 ≠ ∅ satisfyingΞ1∪Ξ2=ΞandΞ1∩Ξ2=∅and such that∀(x1,…,xn∈Ξ1)∃(X1*)lk(X1*)>0∀(xn+1∈X1*)Δ(x1,…,xn,xn+1)=Δ(x1,…,xn)and∀(x1,…,xn∈Ξ2)∃(X2*≠∅)lk(X2*)=0∀(xn+1∈X2*)Δ(x1,…,xn,xn+1)=Δ(x1,…,xn).Example 4.3One can easily see that the sample rangeR(x1,…,xn)=xn:n−x1:ncalculated for a one-dimensional samplex1,…,xn∈Ris not only absorptive, but also a strongly absorptive dispersion measure.Let us consider a data setX={x1,…,xn}⊂Rkand the Euclidean distance deinRk. Then(5)Hr(x1,…,xn)=minx∈Rkmaxxi∈Xde(xi,x)defines the radius of the smallest ball that contains all the points of our data setX.The problem of finding such ball inR2was first introduced in 1857 by Sylvester and is known as the smallest circle problem. It is easily generalized to higher dimensions. The resulting function (5), called the smallest enclosing ball, is a strongly absorptive dispersion measure.A diameter of a data setX={x1,…,xn}⊂Rkis another interesting strongly absorptive dispersion measure. It is defined by(6)Hd(x1,…,xn)=maxxi,xj∈Xde(xi,xj).Actually, dispersion measure (6) can be interpreted geometrically as a diameter ofXwith respect to the Euclidean distance.Rousseeuw, Ruts, and Tukey (1999) proposed a bivariate generalization of the well-known boxplot, called bagplot. The construction of the bagplot is based on the halfspace location depth. An important part of their plot, called bag form a figure which area is a strongly absorptive dispersion measure.Hyndman and Fan (1996) investigated nine different methods implemented in the statistical software to calculate sample quantiles. Sample quantiles providing nonparametric estimators of their population counterparts are based on one or two order statistics from the samplex1,…,xn. Adopting notation used in Hyndman and Fan (1996) let us define the pth percentile given by the ith method as followsQ^i(p)=(1−γ)xj:n+γxj+1:n,j−mn⩽p<j−m+1n,for some constantsm∈Rand 0 ≤ γ ≤ 1 chosen appropriately for each method. The value of γ is a function ofj=⌊np+m⌋andg=np+m−j. Values of these parameters corresponding to particular methods are given in Table 1. For more details on those methods we refer the reader to Hyndman and Fan (1996).Whichever method we choose, the first and the third quartiles given by the ith method are given byQ^i(0.75)=(1−γ)xk:n+γxk+1:n,Q^i(0.25)=(1−γ)xl:n+γxl+1:n,wherek=⌊0.75n+m⌋andl=⌊0.25n+m⌋. Consequently, the interquartile range based on a sample of size n, produced by the ith method (i=1,…,9), has the following form(7)IQRni=(1−γ)(xk:n−xl:n)+γ(xk+1:n−xl+1:n).We will now show that so defined interquartile range is an absorptive dispersion measure for each of the nine methods given in Hyndman and Fan (1996), but it is not – in general – strongly absorptive.Assuming thatk*=⌊0.75(n+1)+m⌋,l*=⌊0.25(n+1)+m⌋the interquartile range based on the enlarged sample of sizen+1could be described as(8)IQRn+1i=(1−γ)(xk*:n+1−xl*:n+1)+γ(xk*+1:n+1−xl*+1:n+1).One may notice that (8) could be expressed asIQRn+1i={(1−γ)(xk*−1:n−xl*−1:n)+γ(xk*:n−xl*:n)ifxn+1⩽xl:n,(1−γ)(xk*:n−xl*−1:n)+γ(xk*+1:n−xl*:n)ifxn+1∈[xl:n,xk:n],(1−γ)(xk*:n−xl*:n)+γ(xk*+1:n−xl*+1:n)ifxn+1≥xk:n.Hence we getIQRn+1i−IQRni=0,forxn+1belonging to a set with a positive Lebesgue measure, if we choose{x1,…,xn}such that, e.g.,xk*:n=xk:n,xl*:n=xl:n,xk*+1:n=xk+1:nandxl*+1:n=xl+1:n. This way we have proved the following proposition.Proposition 5.1The interquartile range(7)is an absorptive dispersion measure for each method given inTable 1.However, not all nine methods given in Table 1 are strongly absorptive. Let us consider the first method. We can distinguish three cases (Q^1adenotes a quartile from the augmented sample):(1)Ifn=4Kfor a certainK∈N,thenQ^1(0.75)=x3K:n,Q^1(0.25)=xK:n,Q^1a(0.75)=x3K+1:n+1,Q^1a(0.25)=xK+1:n+1and henceIQRn+11−IQRn1={0ifxn+1⩽xK:n,xK:n−xK+1:nifxn+1∈[xK:n,x3K:n],c1ifx3K:n⩽xn+1,wherec1=x3K+1:n−x3K:n+xK:n−xK+1:m.Ifn=4K+h,whereh=1,2,thenQ^1(0.75)=x3K+h:n,Q^1(0.25)=xK+1:n,Q^1a(0.75)=x3K+h+1:n+1,Q^1a(0.25)=xK+1:n+1,which yieldsIQRn+11−IQRn1={xK+1:n−xK:nifxn+1⩽xK+1:n,0ifxn+1∈[xK+1:n,x3K+h:n],x3K+h+1:n−x3K+h:nifxn+1≥x3K+h:n.Ifn=4K+3thenQ^1(0.75)=x3K+3:n,Q^1(0.25)=xK+1:n,Q^1a(0.75)=x3K+3:n+1,Q^1a(0.25)=xK+1:n+1,which yieldsIQRn+11−IQRn1={x3K+2:n−x3K+3:n+xK+1:n−xK:nifxn+1⩽xK+1:n,x3K+2:n−x3K+3:nifxn+1∈[xK+1:n,x3K+3:n],0ifxn+1≥x3K+3:n.This proves thatIQRn1is a strongly absorptive dispersion measure. Note that ifn=4K+hthe setX*that appears in Definition 4.1 may contain only one point for some specific data sets.The aforementioned discussion implies that the collapse region of IQR1 is not always empty. Actually, ifn=4KthenKIQR1={[xK:n,x3K:n]ifxK:n<xK+1:n,[xK:n,∞)ifx3K+1:n−x3K:n<xK+1:n−xK:n,while forn=4K+3we obtainKIQR1={(−∞,xK+1:n]ifx3K+3:n−x3K+2:n>xK+1:n−xK:n,[xK+1:n,x3K+3:n]ifx3K+3:n>x3K+2:n.Notice that the endpoints of these intervals are closed which may be considered strange in the context of Definition 3.7.If we consider other methods then, wheneverγ∉{0,1},we can choose a sample such thatIQRn+1i−IQRniis never equal to 0. For example,xl:n≠xl*−1:n,xl:n≠xl*:n,xl+1:n≠xl*:n,xl+1:n≠xl*+1:n,xk+1:n=xk:n=xk*−1:n=xk*:n=xk*+1:n. Therefore, those methods do not lead to strongly absorptive dispersion measures.In the previous sections we have introduced two classes of dispersion measures – the unstable and absorptive ones. One may ask about possible relation between these two classes. Let us start from the following two examples.Example 6.1Consider a data setX={x1,…,xn}⊂R. For any fixed p ≥ 1 let us define the following measure(9)Sp☆=nn1n2∑i=1n(zi−z¯)2,where(10)zi={(p−1)x1:n+xi:np,forxi:n⩽c,(p−1)xn:n+xi:np,forxi:n>c,z¯is the arithmetic mean ofz1,…,zn,c is a point such that x1: n< c < xn: n,n1=#{i:xi:n⩽c}andn2=n−n1. Forp=1we get the scaled standard deviation ofx1,…,xnwhile for any p ≥ 2 the construction ofSp☆provides the scaled standard deviation ofz1,…,znwhich is, as we have mentioned before, the unstable dispersion measure.It could be proved that the sequence of unstable measures(S1☆,S2☆,…)tends to the sample rangeR(x1,…,xn),i.e.limp→∞Sp☆(x1,…,xn)=R(x1,…,xn),which is the absorptive measure.Actually, we havez¯=1pn[(p−1)(n1x1:n+n2xn:n)+∑i=1nxi]=p−1pn1x1:n+n2xn:nn+x¯pandlimp→∞z¯=n1x1:n+n2xn:nn:=z☆.Then, computing the limit we obtainlimp→∞Sp☆(x1,…,xn)=nn1n2[n1(x1:n−z☆)2+n2(xn:n−z☆)2]=nn1n2[n1(n2n)2(x1:n−xn:n)2+n2(n1n)2(xn:n−x1:n)2]=nn1n2n1n22+n12n2n2(xn:n−x1:n)2=xn:n−x1:n,which is the desired result.ForX={x1,…,xn}⊂Rkand any fixed p ≥ 1 let us consider the following dispersion measureΔp☆=minx∈Rk∑i=1ndep(xi,x)p.It is clear that(Δ1☆,Δ2☆,…)form a sequence of unstable dispersion measures. One may easily notice thatlimp→∞Δp☆(x1,…,xn)=Hr(x1,…,xn).By Example 4.4 we know that Hris an absorptive dispersion measure.The above two examples are just special cases of a more general fact expressed by the following theorem.Theorem 6.3For any absorptive dispersion measureH☆:X→R+there exists a sequence of unstable measures(Gp☆)p=1∞,Gp☆:X→R+such that∀(x1,…,xn)⊂Xlimp→∞Gp☆(x1,…,xn)=H☆(x1,…,xn).Let H⋆ and G⋆ be arbitrarily chosen absorptive and unstable dispersion measures, respectively. For any p ≥ 1 let us define the following measureGp☆=2πH☆arctan(p+G☆).It is easily seen thatGp☆for each p satisfies conditions(dsp1)−(dsp)and (end1), which means thatGp☆is the unstable dispersion measure. Moreover,limp→∞Gp☆=H☆,which proves our theorem.□Obviously, the construction shown in the above proof is not unique, i.e. usually one can consider various convergent sequences. However, which one would appear more useful in a given situation depends on particular circumstances and an objective to be achieved. The examples considered at the beginning of this section show that interesting sequences(Gp☆)p=1∞are usually more sophisticated because constructed with more profound knowledge of the properties of the desired measure H⋆.Having a convergent sequence(Gp☆)p=1∞of unstable measures we can consider the corresponding collapse regions which themselves form a sequence. Intuitively, the sequence of collapse regions of(Gp☆)p=1∞should approach the collapse region of the limit absorptive measure H⋆ as p tends to infinity. However, this is not always the case. Consider the dispersion measure (9). LetSp,n☆2:=Sp☆2(x1,…,xn)=nn1n2∑i=1n(zi−z¯n)2.Assume that a new observationxn+1such thatxn+1⩽c,is attached to the data set. ThenSp,n+1☆2=n+1(n1+1)n2∑i=1n+1(zi−z¯n+1)2and after some easy transformations we obtainSp,n+1☆2=n1(n+1)n(n1+1)Sp,n☆2+n(n1+1)n2(zn+1−z¯n)2.HenceSp,n+1☆2−Sp,n☆2<0if and only ifz¯n−n2nSp,n☆<zn+1<z¯n−n2nSp,n☆.Now, taking p → ∞ we get the limiting collapse region of the form(11)KS☆=(x1:n,min{c,x1:n+2n2n(xn:n−x1:n)}).Notice, thatx1:n+2n2n(xn:n−x1:n)≥x1:nso (11) is always non-empty, except for the case whenx1=⋯=xn,while the collapse region of the sample range is always empty. Ifxn+1>cwe have a similar situation with the resulting limit collapse regionKS☆=(max{c,xn:n−2n1n(xn:n−x1:n)},xn:n),which is empty only for the trivial case.It is worth mentioning that the considerations and results shown in this section are not only theoretical but may be also utilized in practice. In the example given below we sketch the idea of the possible application of Theorem 6.3 for designing a new discrimination algorithm.Example 6.4Let us consider a classification problem of data coming from two different classes. Given a set of training data it seems natural to conclude that the most distant observations belong to separate classes. Therefore, these very observations may be treated as representative points of those two classes. The next step is to divide the remaining training data between those two classes with respect to their location from the representative points. This way we find a separating point (in one-dimensional case), separating line (in two-dimensional case) or separating hyperplane (in general).Keeping in mind this general idea one may conclude that the desired discriminant characteristic for discovering the representative points is a suitable absorptive measure, like the range or one of its multidimensional counterparts discussed in Section 4. However, in order to design a border discriminating classes we have to “attract” each remaining training data point to the aforementioned representative point which can be done using an appropriate sequence of unstable measures tending to the absorptive one, as it is shown in Theorem 6.3.To explain it better let us consider the one-dimensional case and measures discussed in Example 6.1. Suppose we have a training set of size n. Then, having the representative points of the two classes given by the rangeR(x1,…,xn)maximization, we assume as the separating point between classes such c which minimizes the difference|R(x1,…,xn)−Sp☆(x1,…,xn;c)|as p tends to infinity, whereSp☆is given by (9) and (10). It is so since as p approaches infinity the resulting value of dispersion measureSp☆tends to the “perfect” separating measure which is the dispersion obtained for the limit dispersion measure R, as it was shown in Example 6.1.We illustrate the proposed method using the Sepal.Length variate from the well-known data-set iris available in R software environment. For the sake of this example we use only the entries corresponding to the species setosa and versicolor. Then 50 randomly chosen observations were used as a training set while the remaining 50 served as a testing set. Forp=1000we minimize the difference(12)Diff(c)=|R(x1,…,x50)−Sp☆(x1,…,x50;c)|with respect to a separating point c. R software producescmin=5.427,while the sample median and mean are equal 5.45 and 5.488 respectively. Using the result on the testing set only one observation was classified incorrectly. Function 12 and the testing data classification results are given in Fig. 1.This is, of course, only a simple concept that can be transferred to more complicated data sets in higher dimensions. However, it will be the topic of our further research in a subsequent contribution.A distance is, roughly speaking, a two-argument function measuring how much any two points of a given space are separated. Martín and Mayor (2009) starting from the question How separated Palma, Inca and Manacor are? extended the conventional definition of distance between two points so that it might be applied to collections of more than two elements. The properties of their multi-argument “distance” function, called a multidistance, were investigated in some further papers Martín and Mayor (2010, 2011); Martín, Mayor, and Valero (2011). Formally, a multidistance is defined as follows.Definition 7.1A functionD:⋃n⩾1(Rk)n→[0,∞)is called a multidistance if it satisfies the following conditions for allx1,…,xn,y∈Rk:(md1)D(x1,…,xn)=0if and only ifx1=⋯=xn.D(xπ(1),…,xπ(n))=D(x1,…,xn)for any permutation π of the numbers1,…,n.D(x1,…,xn)⩽D(x1,y)+⋯+D(xn,y).The last condition (md3) could be perceived as a generalized triangle inequality.At first glance it appears that a multidistance not only aggregates distances between several observations but it also characterizes somehow the scatter of these points. Hence, a natural question arises about possible relation between the classes of multidistances and dispersion measures. Clearly, there are many dispersion measures which satisfy requirements (md1)–(md3). However, in spite of nonempty intersection there is no inclusion between these two classes of functions. Let us consider the following examples.Example 7.2The so-called mean absolute deviation (MAD) of observationsx1,…,xn∈R,given byMAD(x1,…,xn)=1n∑i=1n|xi−x¯|satisfies both the properties of dispersion measures and multidistances.Consider a data setX={x1,…,xn}⊂Rk. By Example 4.5 we know that the diameter (6) of a setXis a dispersion measure. The diameter is also a multidistance, called the maximal multidistance (see Martín and Mayor (2009, Remark 1)). Hence, consequently, in the case of one-dimensional observations on the real line the sample range R is both the dispersion measure and a multidistance.By Example 3.2 we know that a sample variances2=1n−1∑i=1n(xi−x¯)2is the unstable dispersion measure. We also prove that s2 is a multidistance.Theorem 7.4Letx1,…,xn∈Rdenote a sample. If a sample size n ≥ 3 then the sample variance s2is a multidistance.Thus we have to verify if the requirements of Definition 7.1 hold. To do this it is worth remembering that we may express the sample variance in the equivalent way as follows(13)s2=1n(n−1)∑i=1n−1∑j=i+1n(xi−xj)2(see, e.g., Gagolewski (2015, Remark 12)). Therefore, it is obvious that conditions (md1) and (md2) hold. Now let us check (md3), i.e. whether(14)s2(x1,…xn)⩽∑i=1ns2(xi,y)for arbitraryy∈R. However, by (13) and since the arithmetic mean minimizes the sum of squared differences from the sequence of observations, we get∑i=1ns2(xi,y)=12∑i=1n(xi−y)2⩾12∑i=1n(xi−x¯)2⩾1n−1∑i=1n(xi−x¯)2=s2(x1,…xn),provided n ≥ 3. Hence (14) is fulfilled. This shows that (dm3) holds so the sample variance is a multidistance and the theorem is proved.□Let us fix any point z inRk. Then let us define the following function(15)Dm(x1,…,xn)=max{de(x1,z),…,de(xn,z)},for anyx1,…,xn∈Rk,where de(x, y) denotes, as before, the Euclidean distance between x and y. One may easily see that (15) is a multidistance. However, (15) is not a dispersion measure because it does not satisfy (A3). Indeed, ifz∉{x1,…,xn}function Dmis not translation invariant.However, if we consider an aggregation of distances between arguments instead of distances with respect to a fixed point, we can obtain a measure of dispersion. For instance(16)D˜m(x1,…,xn)=max{de(xi,xj):i<j},we obtain a translation invariant function which is not only a multidistance (called the maximal multidistance, see Martín and Mayor (2011)) but a dispersion measure as well.More generally, the following proposition holds.Proposition 7.6If a multidistance D satisfies the properties (A3)–(A5), then it is also a dispersion measure.The proof of this proposition is straightforward as axioms (md1) and (md2) satisfied by each multidistance are the same as requirements (A1) and (A2) for a measure of dispersion.Example 7.7Basing on the drastic distanced(x,y)={1ifx≠y,0ifx=y,many multidimensional extensions can be defined. For instance, in Martín and Mayor (2009) authors proposed the following two multidistances(17)D′(x1,…,xn)={0ifxi=xj∀i,j,1otherwise,and(18)D′′(x1,…,xn)=#{x1,…,xn}−1,where#Xstands for the cardinality ofX.One can easily see that (17) is a strongly absorptive dispersion measure, while (18) is an unstable dispersion measure.Consider a set of points on the plane, i.e.X={x1,…,xn}⊂R2. Let us define the following function(19)Dd(x1,…,xn)=2minx∈R2{maxi=1,…,nd(xi,x)},where d is a distance onR2. Therefore (19) is the diameter of the smallest ball containing the pointsx1,…,xn. It was proved in Martín et al. (2011) that (19) is a multidistance for the distances typically used like the Manhattan distance, the Euclidean distance and the Chebyshev (maximum) distance d∞.Unfortunately, not all multidistances Ddare also dispersion measures – it depends on the distance d. By Example 4.4 we know that a multidistance (19) based on the Euclidean metric is a dispersion measure. However, neither Ddbased on the Manhattan distance, nor based on the Chebyshev distance is a dispersion measure, because in both cases Ddis not rotation invariant, i.e. they do not fulfill condition (A4).Let us consider a data setX={x1,…,xn}⊂Rk. Then the Mahalanobis distance between an observationx∈Rkand the data setXis defined by(20)dM(x,X)=(x−x¯)TΣ−1(x−x¯),whereΣ−1stands for the inverse of the covariance matrixΣ=[cov(xi,xj)]i,j=1,…,n.Now, let DMdenote the radius of the smallest ball that contains all the points fromXobtained with respect to the Mahalanobis distance (20). It is clear that DMas a radius of a ball in some metric is a multidistance. It is also a dispersion measure. Actually, given a rotation matrix R letXRdenote the rotated data set, letΣR=RΣRTstand for its covariance matrix and letxR=Rxbe any point inRk. ThendM(xR,XR)=(x−x¯)TRT·(RT)−1Σ−1R−1·R(x−x¯)=dM(x,X).Other dispersion measures properties obviously hold.

@&#CONCLUSIONS@&#
In this paper we have introduced a general definition of a dispersion measure that might be applied not only for one-dimensional real data but also for multidimensional data. Moreover, we have distinguished two basic families of dispersion measures with respect to their behavior when adding a new observation to the data set, i.e. unstable and absorptive dispersion measures. We have considered many examples of these measures and examined the relationship between the above mentioned two families of dispersion measures. Moreover, we have discussed a relationship between dispersion measures and multidistances. We have also examined some new interesting properties of such well-known dispersion measures for one-dimensional data like the interquartile range and a sample variance.Although we have tried to discuss and to answer many questions on the dispersion measures, many problems are still open and are worth further consideration. Firstly, we have examined in this paper the measures of the absolute spread only. Thus the measures of the relative spread, which are also important in applications, need a thorough interest. Secondly, we have restricted our attention to variability of the quantitative real data. However, the problem how to measure the spread of the qualitative data (nominal scale) seems to be interesting and important too. Thirdly, in our opinion a family of multidistances, which is still not examined completely, might be quite helpful in data analysis. And finally, we agree with Gagolewski (2015) that the methods of aggregation operators used so far for describing central tendency of the data, seem to be very promising in studies on the data spread.