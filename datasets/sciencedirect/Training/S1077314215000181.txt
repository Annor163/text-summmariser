@&#MAIN-TITLE@&#
Learning ramp transformation for single image super-resolution

@&#HIGHLIGHTS@&#
We propose an edge based single image super-resolution algorithm.Our algorithm involves learning how ramp profiles transform across resolutions.Ramp profiles are defined as monotonic pixel profiles across edges.Our results demonstrate several advantages compared to other techniques.

@&#KEYPHRASES@&#
Super-resolution,Segmentation,Low-level vision,

@&#ABSTRACT@&#
We propose the use of explicitly identified image structure to guide the solution of the single image super-resolution (SR) problem. We treat the image as a layout of homogeneous regions, surrounded by ramp edges of a larger contrast. Ramps are characterized by the property that any path through any ramp pixel, monotonically leading from one to the other side, has monotonically increasing (or decreasing) intensity values along it. Such a ramp profile thus captures the large contrast between the two homogeneous regions. In this paper, the SR problem is viewed primarily as one of super-resolving these ramps, since the relatively homogeneous interiors can be handled using simpler methods. Our approach involves learning how these ramps transform across resolutions, and applying the learnt transformations to the ramps of a test image. To obtain our final SR reconstruction, we use the transformed ramps as priors in a regularization framework, where the traditional backprojection constraint is used as the data term. As compared to conventional edge based SR methods, our approach provides three distinct advantages: (1) Conventional edge based SR methods are based on gradients, which use 2D filters with heuristically chosen parameters and these choices result in different gradient values. This sensitivity adversely affects learning gradient domain correspondences across different resolutions. We show that ramp profiles are more adaptive, stable and therefore reliable representations for learning edge transformations across resolutions. (2) Existing gradient based SR methods are often unable to sufficiently constrain the absolute brightness levels in the image. Our approach on the other hand, operates directly in the image intensity domain, enforcing sharpness as well as brightness consistency. (3) Unlike previous gradient based methods, we also explicitly incorporate dependency between closely spaced edges while learning ramp correspondences. This allows for better recovery of contrast across thin structures such as in high spatial frequency areas. We obtain results that are sharper and more faithful to the true image color, and show almost no ringing artifacts.

@&#INTRODUCTION@&#
Super-resolving an image entails estimating the intensities of a high resolution (HR) version of the image from the smaller number of intensities available in the given low resolution (LR) image. For even moderate upscaling factors, this problem is fundamentally very highly ill-posed. Choosing appropriate regularizers or priors for the single image super-resolution (SR) problem has therefore been a major focus of research in this area.Priors for the SR problem can be broadly classified into patch based and edge based priors, depending on the domains in which they operate. Perhaps the simplest patch based priors are those which assume simple models for image smoothness (such as linear or cubic). Super-resolution then simply amounts to interpolation of the patch pixels according to the chosen model to obtain the sub-pixel values [14,15,30]. However, such methods tend to produce overly smooth results, and tend to produces artifacts such as chessboard effect along edges. A popular class of priors that are aimed at preserving sharpness are those which impose constraints on the marginal distributions of filterbank responses of the image [12,17]. Studies on statistical properties of natural images have found that these distributions are well modeled as Laplacians [12] or generalized Gaussians [17]. The constraints therefore occur in terms of fits of these distribution types to the data at hand. These priors, however, are used as a global constraint over the entire image. Spatial localization is incorporated only weakly at best [18].More recently, learning based priors have aimed at estimating the relationship between LR and HR patches using a training database [9,28,27,22,29]. These learnt mappings are then used to predict the HR version of each patch of the given LR image. Freeman et al. [9,10] use a Markov random field (MRF) model to learn the relationship between LR and HR patches. Yeung et al. [29] uses ideas from manifold learning to capture this relationship, wherein the manifold of HR patches is assumed to be locally linear, and patches are expressed as a linear combinations of its neighbors. Yang et al. [27] express image patches as linear combinations of atoms from a dictionary of a fixed set of image patches. This is then extended to the case where the dictionary itself is learnt to support a sparse representation of patches [28,26].While learning based patch priors have demonstrated success, they do have certain shortcomings. Image patches, depending on their size, can exhibit high degrees of complexity and variability and it is not clear how many samples are sufficient to adequately model the variability seen in generic images, and for effectively learning their mappings across resolutions. The choice of patch size in learning based methods is itself rather heuristic, and has a significant effect on the number of patches required for learning and on the SR result as well. Patch based approaches also tend to be susceptible to spurious artifacts near sharp edges, since patches containing sharp transitions in intensities may be difficult to model using limited number of training patches, unless a very similar patch exist in the training set.Edge based priors attempt to overcome some of the limitations of patch based approaches described above. Edge smoothness priors [5,16,24] favor smooth contours (or isophotes) in the image, and are motivated by human perceptual preferences for smooth image boundaries [5,16,24]. These priors have been effective in minimizing artifacts along high contrast boundaries while producing geometrically smooth contours. However, they do not directly consider the sharpness of intensities across edges in the estimated HR image. Edge profile based priors address this issue by modeling 1-D edge profiles of the image and learning (using training data) how these profiles transform across resolutions [21,20,7,23,25]. In [7], statistics of 1-D edge profiles are obtained by computing moments of the profile shape, and their transformation across resolutions is learnt. The gradient profile prior (GPP) approach of [21,20], fits a generalized Gaussian distribution to edge profiles, and uses a sharpness parameter to transform them across resolutions. The aforementioned approaches try to reap advantages of 1-D modeling over 2-D patch modeling. 1-D profiles are of lower dimensionality than rectangular patches, and can be described by one [21] or a few [7] parameters.While existing edge profile methods extract 1-D profiles, these profiles are obtained using gradients, which still invlove 2-D processing using a predefined filter. Computing gradients using predefined 2-D filters requires making strict assumptions about the geometry and scale of structures being detected [1]. Any choice of filter size and coefficients of the gradient operator essentially restricts the type of structures that can be detected, in terms of their scale and geometry. Such restrictions have a particularly detrimental effect on the SR problem, wherein all structures in the image, irrespective of their scale/geometry, need to be upscaled by learning correspondences between LR structures and their HR counterparts. Restrictions and assumptions on the scale/geometry introduced by 2D linear pre-processing causes distortions in learning this mapping, and therefore the advantage of subsequently using 1D profiles gets diminished.In addition, imposing priors on gradients does not impose constraints on the absolute brightness values of the image. This sometimes leads to deviations in the brightness levels of the HR image relative to the given LR image in such methods [7,21]. We show this by an example presented in Fig. 1, which shows an upsampling result obtained by the edge profile based method of [7].In this paper we propose a new edge profile based prior for the SR problem, that overcomes some of the limitations of existing edge based methods as described above. We propose a method which avoids 2-D preprocessing for obtaining edge information. We do so by adopting the definition of image structure as proposed in [2,1]. We treat the image as a layout of homogeneous regions partitioning the image, each surrounded by ramp edges [2,1], as shown in Fig. 3(b). Such a layout is obtained by the simple requirement that the intensity variation within a region interior be strictly less than those in the ramps surrounding it. Ramps are characterized by the property that any path through a ramp pixel, monotonically leading from one to the other side, has monotonically increasing (or decreasing) intensity values along it. Such a ramp profile thus consists of a sharp intensity transition over a relatively narrow area between the interior intensities on the two sides, and thus captures the large contrast between the two regions.Since ramps correspond to areas most affected by a change in resolution (as illustrated by the example in Fig. 2), we propose a prior for the SR problem that learns how ramps transform across resolutions. We model the 1-D ramp profiles using sigmoidal functions, adequately parameterized to allow the variability seen in ramp profiles extracted from natural images. We learn functions that map the ramp profiles from LR images to their HR counterparts using a set of training images. As we demonstrate in Section 2, ramp profiles are more robust descriptors of edge profiles as compared to gradient profiles. We do not use fixed size and fixed coefficient filters or templates for edge extraction. Like other edge based methods, the remaining non-ramp, homogeneous region interiors are super-resolved using the simple intensity conservation constraint [13].Unlike gradient based edge profile priors, ramp profile modeling allows us to formulate our prior in the intensity domain. Gradient domain constraints are unable to accurately preserve brightness [7,20]. Our prior enforces sharpness directly in the image domain, thus avoiding deviations from the original intensities/colors.Current edge profile based methods assume only a one-to-one transformation between an LR edge profile and its HR counterpart. However, we show that edge profiles across thin regions/structures also exhibit a non-trivial inter-dependency since the distance between two ramps (separated by a thin region) in an HR image may be small enough to cause an overlap between their domains of support in the corresponding LR image. We model such inter-edge profile relationship for better recovery of contrast across thin regions and structures.In the next section, we describe the ramp based representation of image structure. In Section 3 we present an overview of the steps involved in our algorithm. Sections 4–7 describe our proposed algorithm in detail. Section 8 shows our results.We now briefly review some of the key ideas of image modeling presented in [2] and the references therein.A ramp profileR(x,θ)at a locationxin an image is defined as the longest sequence (ordered set) of monotonically increasing (or decreasing) pixel values along a path passing throughxin a particular direction θ. Ramp profiles, computed over a sufficiently large number of directions, quantify the intensity variations around a given edge location and capture the local edge structure. Ramp profiles are detected without using any predefined filters (e.g., along horizontal and vertical directions), are fully adaptive to structures of any width or height and they result from a bottom up process, without any prior assumptions [2]. We elaborate a bit more on these advantages in the context of the SR problem by a real world example in Section 3.Using ramp profiles, Akbas and Ahuja [2] develops a low level segmentation algorithm that realizes the properties targeted in [1]: (i) it uses a realistic model of the segments - each region having a smoothly varying interior intensity profile, surrounded by a relatively steep intensity ramps; (ii) it provides a segmentation with quantitatively and qualitatively demonstrated accuracy that does not assume any priors on region geometry (shape, size), and region topology (how many regions neighbor a given region), but rather lets the segmentation structure emerge in a bottom-up fashion; (iii) it provides regions with closed contours as well as the hierarchy of their spatial embedding, the latter not being used in this paper; (iv) the results are perceptually valid.To summarize, for an input image, the algorithm of [2] provides us with the following: (i) A binary valued edge map E, containing closed, single-pixel wide boundaries of smooth, homogeneous regions, withE={e:E(e)=1}, denoting the set of these edge pixels. (ii) For each edge pixele∈E, a set of D ramp profilesR(e,θi),i=1,2,…,D, along D different directionsθ1,…,θDpassing throughe. These ramp profiles characterize the local image structure around the edge pixele. In our work, we compute ramps alongD=4different directions in the 2D image plane - horizontal, vertical and the two diagonals. Also, we deem a ramp profile valid only if it causes a specified minimum change in intensity level across it, which is above the sensor noise level. In our application, we set this threshold to be 15. Therefore, we deem a ramp profile to be valid only if it causes a gray level intensity change of at least 15 across it.Fig. 3(c) shows the edge map obtained via such a segmentation. Fig. 3(b) shows the ramp areas, i.e., areas that are populated by the ramp profiles at the edge pixels, which can be seen as forming a thin border around the edges.To super-resolve a given imageILRdefined in the LR domainΩLR, our algorithm consists of the following steps:(1)We first upscaleILRto the HR domainΩHRby a simple bicubic interpolation to yieldIU.We then use the algorithm of [2] to obtain the low-level edge map E ofIU, and the four ramp profilesR(e,θi),i=1,2,3,4for each edge pixele.To each ramp profile, we fit a sigmoid function parameterized byZl, as detailed in Section 4.We then transformZlto its HR counterpartZh, using a set of transformation functions that we learn from training images, as described in Section 5.The transformed ramp profiles (parameterized byZh) are then used to create a prior imageIpin the HR domainΩHR, as described in Section 6. This prior imageIpessentially contains the ramp based structural information that the HR image is expected to have.We estimate our final HR imageIˆHRusing a regularization framework, by usingIpas a prior constraint, along with the classical backprojection formulation [13] as the data term. This step is described in Section 7.Consider a ramp profileR(e,θ)that is monotonically increasing along a direction θ though the edge pixeleof an image. To fit a parametric model to this ramp profile, we first consider a 1D spatial domaint∈(-∞,∞), centered ate, and along the direction θ. We can assume the ramp profile intensities to be a 1D functionr(t)in this domain, defined at discrete locationst=-N,-N+1,…,0,…,M-1,M.We model this ramp profile using a continuous sigmoid function defined as,(1)f(t;A,B,S)=A+B-A1+exp(-St).A and B denote the intensity values at the ends of the ramp, andH=B-Adenotes the height of the ramp profile. S controls the sharpness or steepness of the ramp profile. Fig. 4(a) shows these parameters schematically.We setA=r(-N), andB=r(M)as the intensity levels at the end of the ramps. The least squares estimate for S can be analytically obtained asS=tTt-1tTr, where,t=N,N-1,…,0,…,-M+1,-MTandr=[r(-N),r(-N+1),…,r(0),…,r(M-1),r(M)]T.Since this parameter estimation is simple and non-iterative, we are able to parameterize a large number of ramps relatively fast. We show a few examples of ramps extracted an image, superimposed with the above sigmoidal fit in Fig. 4(c).To summarize, the above modeling procedure parameterizes the shape of a ramp profileR(x,θ)with a parameter vectorZ=[A,B,S].In order to determine how an LR ramp profile, parameterized byZl, transforms to its HR counterpartZh, we need to learn functions that mapZltoZhusing a set of known pairs of LR and HR ramp profiles{(Zl(i),Zh(i))}i=1T. For this, we collect a set of HR images (of around 1000x1000 pixels), covering a variety of scenes, and then generate the LR images by downsampling using a filterfpsf.For obtaining a pair(Zl(i),Zh(i)), we need to extract a ramp profile from an LR image and find its corresponding ramp in the HR image. We use the segmentation algorithm [2] to obtain the edge pixels and the associated ramp profiles for all the HR images, and the LR images after upscaling (using bicubic interpolation) to the HR domain. We perform this upscaling step to have both the LR and HR image defined over the same resolution domain, as this would facilitate in finding correspondences.For an LR ramp profileRl(el,θ)through the edge pixelelalong direction θ in an LR image, the corresponding ramp profileRh(eh,θ)in the HR image is found at a locationehgiven by,(2)eh=argmine∈N(el)|Hh(e,θ)-Hl(el,θ)|,whereN(el)is the set of edge pixels of the HR image, in a 5×5 neighborhood aroundel. The functionH(x,θ)quantifies the height of the ramp profile through the pixelx, along the direction θ, in the image.Ramp profiles allow for more accurate correspondences to be found, as compared to using gradient profiles. This is illustrated in Fig. 5. We show a cross section of an image from its HR version and its upsampled LR version. The gradient profile is quite sensitive to the type of gradient filter used, and it is difficult to infer the edge location in the HR image and establish correspondence to LR. Making any decision on the type of filter to use imposes strong assumptions of the expected geometry and scale of the image profile. On the other hand, by definition, ramp profiles avoids any such assumptions on scale, and detects structure bottom-up, adaptively. It is able to correctly identify the HR edge in the example shown in Fig. 5.We collect T pairs of LR–HR ramp profiles from the training images, using the matching criterion in (2).To learn a regression function fromZltoZh, we also need to account for the dependency between an HR ramp profile and the closely spaced neighbors (across thin structures etc.) of the corresponding LR ramp profile. Fig. 6shows an example of a ramp profile R (in red), along with its two neighboring ramp profilesR-andR+(in green) in either direction. Without loss of generality, we denote the left neighboring ramp profile with the superscript ‘-’, and the right neighbor with a superscript ‘+’. The intensity values at the ends of the ramps are respectively denoted by A and B, with the appropriate superscript as shown in Fig. 6. Therefore, we also can denote the heights of the neighboring ramps asH-=B--A-andH+=B+-A+respectively.The distance between two neighboring ramps along the same cross section in an HR image may be small enough to cause an overlap between the spatial supports of the corresponding ramps in the LR image. This effect of this dependency is illustrated through a simple example in Fig. 7. In both cases of Fig. 7, as expected, the filtering operation causes a change in sharpness of the ramps. However, in case of Fig. 7(a), due to the presence of a close neighboring ramp, along with sharpness, the height of the filtered rampRf1is also affected. The height remains unaffected if the ramp does not have neighboring ramps such as in Fig. 7(b).To incorporate this dependency of neighboring ramps in our model, we formulate our regression function to be,(3)Zˆh=EZh|Zl,Zl+,Zl-,whereZl+andZl-denote the parameters of the neighboring ramps on either side of the rampZl, along the same cross section of the image. The above equation essentially says that the parameters of the HR rampZhare predicted not only by its corresponding LR rampZl, but also by the LR ramp’s neighbors,Zl+andZl-if they are close enough. We make use of the ramp map (such as in Fig. 3(b)) to determine if the ramps are close enough to require modeling using (3). Neighboring ramp profiles are deemed to be close and dependent on each other if there are no non-ramp pixels between them. In the example shown in Fig. 7(a), the neighboring LR ramps profilesRf1andRf1+do not have any non-ramp pixels between them. Therefore, we use the dependency model of (3) to relate them to the HR ramps profilesR1andR1+. For all other ramp profiles, we drop the dependency onZl+andZl-and simply assume a one-to-one function.We make some simplifying independence assumptions among the variables in (3) in order to make the estimation tractable: By comparing the filtered rampsRf1andRf2in Fig. 7, we notice that the presence of a neighboring ramp essentially reduces the height of the ramp during the filtering process. Therefore, our regression function must be aimed at compensating for this attenuation in the ramp height. Furthermore, we notice that the attenuation in height is caused by change in intensity level at only one end of the ramp, that is closer to the neighboring ramp. We can therefore incorporate the neighborhood dependency by modelingAhandBhas functions of the neighboring LR ramp profiles, in the respective directions. Therefore,(4)Aˆh=EAh|Al,Hl-(5)Bˆh=EBh|Bl,Hl+We assume the sharpness parameter of the HR ramp profileShto always be independent of the neighborhood ramps. We modelShas a function of the height and sharpness of corresponding LR ramp profile, without any neighborhood dependency.(6)Sˆh=ESh|Sl,HlFig. 8shows a graphical representation of the dependence and independence relationship assumed in our model.To estimate the prediction functions (4)–(6), we take a discriminative modeling approach. We approximateSˆh=ESh|Sl,Hlusing support vector regression with a polynomial kernel. We choose the polynomial order to be 3 based on k-fold (k=10) cross validation by partitioning the training data. Fig. 9(a) shows plots of the learntSˆhas a function of the LR sharpnessSl, for different values of LR ramp heightsHl. Clearly, there is a significant dependence of the HR ramp sharpness on not just the LR ramp sharpness, but also the LR ramp heightHl.We use a linear model to estimateAˆhandBˆhin (4) and (5) in terms ofAl,Hl-andBl,Hl+respectively. Fig. 9(b) shows the learntBˆhas a function ofBl, for different values ofHl+.Aˆhbehaves similarly, and we do not show it here.Clearly, the estimation ofBˆhis dependent on the neighboring ramp heightHl+. To better understand the plots in Fig. 9(b), let us first focus on theBˆh=Blline that is shown in the plot for reference. This line shows the case when the intensity level at the end of the HR rampBhis the same as the intensity levelBlat the end of its corresponding LR ramp. Indeed, this is the case if there are no neighboring ramps present. However, due to the presence of a neighboring ramp, the predicted intensity levelBˆhof the HR ramp deviates fromBl. This deviation is dependent on the heightHl+of the neighboring ramp. For example, let’s focus on the red curve, which corresponds to the presence of a neighboring ramp of heightHl+=100. Qualitatively, we show such an example in Fig. 10(b), where the red colored ramp is to be super-resolved, and the green colored ramp is the neighboring ramp of heightHl+. Fig. 10(c) shows the transformed ramp, without incorporating the neighboring ramp dependency. In this case, while the sharpress of the ramp is appropriately transformed, the height of the ramp remains the same as in the LR ramp of Fig. 10(b). However, this height is lower than the ground truth HR ramp height as in Fig. 10(a). To compensate for this smaller height as compared to the ground truth, our neighboring ramp dependency model predicts a lower intensity valueBˆhat the ramp end, as compared to the LR ramp end intensityBl, in Fig. 10(d). This is evident by the plots of Fig. 9(b), such as the red curve. Due tho this lower predicted intensity level of the ramp end, the resultant ramp in Fig. 10(d) is similar in height to the ground truth HR ramp of Fig. 10(a).In case of real world images, the effect of incorporating our neighboring ramp dependency on our SR results is demonstrated in Fig. 11. Thin structures like the bird’s beak show better contrast, owing to the correction provided by the learnt function in Fig. 9(b).Given an LR imageILR(and its bicubic-upsampled versionIU) to be super-resolved, each ramp profile inIUis transformed using the prediction functions learnt above. The transformed sigmoids are then resampled at the positions where the corresponding LR ramp profiles were defined, and the intensities thus obtained are placed in a new imageIp. LetΩR⊂ΩHRdenote the set of pixels ofIUorIpthat is populated by ramp profiles (as shown in the example of Fig. 3(b)).Unlike previous gradient based approaches that model gradient profiles in only one direction (in the direction of the gradient), we extract and transform ramp profiles in four directions. As a result, the valueIp(x)of a particular ramp pixelx∈ΩRis typically predicted by multiple transformed ramp profiles. We perform a weighted average of all these predictions, to get the final predicted value ofIp(x).(7)Ip(x)=∑jSh(x,θj)Hh(x,θj)Ipθj(x)∑jSh(x,θj)Hh(x,θj),x∈ΩR.Sh(x,θj)andHh(x,θj)are the sharpness and height of the (transformed) ramp profiles throughxin directionθj, andIpθj(x)is the intensity predicted atxby the (transformed) ramp profile along directionθjalone. Intensities predicted by high contrast and sharp ramp profiles have higher weight.Due to this averaging, smoothness is automatically achieved between neighboring pixels inIp, without an explicit Markov chain based inference [7,22].For the non-ramp locations inIp, we simply retain the bicubic interpolated values fromIU. This new imageIpserves as our ramp based prior constraint.Fig. 12shows an example where we extract ramps from an upsampled LR image, transform the ramps using the learnt functions, and obtain the prior imageIp.We use the priorIptogether with the intensity conservation constraint in the LR domain to estimate the HR image. The cost function to minimize is therefore,(8)J(IˆHR)=(1-Λ)↓∘(IˆHR∗fpsf)↓-ILR2+Λ∘(IˆHR-Ip)2‘∘’ denotes the Hadamard (entry-wise) product between matrices. Λ is a matrix containing spatially adaptive regularization parameters, defined as,Λ=λM∗g, whereM(x)=1ifx∈ΩR, and 0 everywhere else. M is therefore a binary valued matrix used as a map to indicate the ramp regions. Λ is obtained by smoothing out the map M using Gaussian filter g and rescaling it by λ.Λ gives high weight to our prior in the ramp areas. In smooth regions,J(IˆHR)defaults to the backprojection formulation [13]. We minimize (8) using gradient descent.

@&#CONCLUSIONS@&#
