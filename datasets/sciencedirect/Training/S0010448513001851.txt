@&#MAIN-TITLE@&#
A solution process for simulation-based multiobjective design optimization with an application in the paper industry

@&#HIGHLIGHTS@&#
The challenges of simulation-based multiobjective design optimization are analyzed.A three-stage solution process is proposed, featuring interactive decision making.Demonstrated by a case study of multiobjective design optimization of a paper mill.Applicable to computationally intensive black-box formulations of real-life problems.

@&#KEYPHRASES@&#
Multicriteria decision making,Multiobjective optimization,Pareto optimality,Computational cost,NIMBUS method,PAINT method,

@&#ABSTRACT@&#
In this paper, we address some computational challenges arising in complex simulation-based design optimization problems. High computational cost, black-box formulation and stochasticity are some of the challenges related to optimization of design problems involving the simulation of complex mathematical models. Solving becomes even more challenging in case of multiple conflicting objectives that must be optimized simultaneously. In such cases, application of multiobjective optimization methods is necessary in order to gain an understanding of which design offers the best possible trade-off. We apply a three-stage solution process to meet the challenges mentioned above. As our case study, we consider the integrated design and control problem in paper mill design where the aim is to decrease the investment cost and enhance the quality of paper on the design level and, at the same time, guarantee the smooth performance of the production system on the operational level. In the first stage of the three-stage solution process, a set of solutions involving different trade-offs is generated with a method suited for computationally expensive multiobjective optimization problems using parallel computing. Then, based on the generated solutions an approximation method is applied to create a computationally inexpensive surrogate problem for the design problem and the surrogate problem is solved in the second stage with an interactive multiobjective optimization method. This stage involves a decision maker and her/his preferences to find the most preferred solution to the surrogate problem. In the third stage, the solution best corresponding that of stage two is found for the original problem.

@&#INTRODUCTION@&#
The widespread availability of powerful computers has made it possible to obtain detailed analyses of complex systems quickly and at a relatively low cost. Consequently, computer simulation has become a central tool in the design process across the industries. Computer simulation can be readily used to answer questions such as whether or not a system will meet specified requirements. To answer questions such as what is the maximum system performance and how the system should be designed to achieve the maximum performance, simulation must be combined with optimization. Solving an optimization problem that depends on the output of a simulation model is known as simulation-based optimization. In this paper, we consider computational challenges of simulation-based optimization encountered with real-life design optimization problems and relate them to a case study in the paper industry.A computer simulation of a physical or some other system of interest typically consists of solving a system of algebraic and differential equations. From the optimization point of view, using a simulator as an external solver for a system of equations is equivalent to dividing the decision variables into two groups, the dependent and the independent variables, and substituting the dependent variables with functions of the independent ones. The choice between dependent and independent variables is often dictated by the simulator, which has to take the independent variables as input and provide the values of the dependent variables as output. Considering only the independent variables as decision variables reduces the dimensionality of the problem but, on the other hand, makes it a black-box optimization problem because the functional relationship between the independent and the dependent variables is known only implicitly. This prevents any algebraic manipulation and makes it very difficult to validate the assumptions of, for example, convexity and differentiability that many optimization methods rely on.In a real-life design optimization problem, there is rarely a single performance measure fully appreciating the relative merits of each design. Instead, it is characteristic of a design optimization problem to have multiple, conflicting objectives. When optimization is applied, however, the optimization problem is commonly formulated with a single objective–often by considering a weighted sum of the design objectives or by treating all but one of them as constraints–because most of the optimization algorithms can handle only single-objective problems. A shortcoming of a simplistic single-objective problem formulation is that it provides little support for decision making, often requiring the parameters in the problem formulation to be adjusted by trial and error to achieve the desired outcome. The structure of a design optimization problem can often be reflected more closely by formulating it as a multiobjective optimization problem, in which all the objectives are to be optimized simultaneously. A multiobjective formulation comes with a cost, though, as it necessitates the involvement of a decision maker.With an increasing complexity of design problems, finding an optimal design in real-life applications remains a challenging task  [1–3]. The computational challenges in design optimization that we consider in this paper (and which we have found are the most pertinent ones) are the following.Computational costIn simulation-based optimization, the objective and constraint functions depend on the decision variables not only directly, but also indirectly through the simulation model. Therefore, to calculate the values of those functions, a simulation must be carried out, which may well take from few minutes to several days. Moreover, the simulation must be repeated every time an optimization method needs to evaluate the objective and constraint functions. Thus, the time required for one simulation run on average, or the computational cost of the simulation, is a major factor limiting the practicability of simulation-based optimization.Multiple, conflicting objectives give rise to a set of solutions, called the Pareto optimal set, that correspond to different trade-offs among the objectives and are not self-evidently comparable. This is in contrast to single-objective optimization, in which an optimum, if it exists, is uniquely defined. With multiple objectives, the identification of the preferred solution requires the involvement of a decision maker and sufficient methodological support to explore the alternative solutions. It is, however, challenging to implement a system that can provide a fast enough response for successful decision making when applied to computationally expensive simulation-based optimization.The lack of closed form expressions for the objective and constraint functions effectively requires a design optimization problem to be treated as a global optimization problem. The necessity of global optimization increases the computational cost of design optimization and limits the size of the design optimization problems that can be solved. Fortunately, it is rarely necessary to guarantee global optimality, but instead, a sufficient improvement over an existing design is acceptable.In many real-life design optimization problems, the system of interest is best modeled by a stochastic process. In that case, the model output is a random vector, often with an unknown probability distribution. The model output can be sampled by a computer simulation, although the computational cost of simulating the output increases with the sample size. Moreover, unless the sample size is sufficiently large, sampling error introduces noise to the values of the objective and constraint functions that depend on some statistic of the model output.The above challenges are intertwined in the sense that the presence of each one of them makes the others more difficult to address. For example, global optimization quickly becomes impractical if the computational cost of the design optimization problem increases. Likewise, stochasticity and conflicting objectives both aggravate the difficulties caused by a high computational cost because more computation is required to sample the model output and to assess the trade-offs, respectively.An overview of optimization methods applied to solving multiobjective engineering problems is given in  [4]. Metamodeling techniques have been found to be beneficial tools in supporting design optimization  [5,6]. In multiobjective design optimization, most of the efforts have been devoted to finding a number of Pareto optimal solutions (see, e.g.,  [7–10]) without considering support for a decision maker. Only few applications of interactive multiobjective optimization methods to design optimization problems can be found, e.g., in  [11–16]. For example, Tappeta et al.  [11] have proposed an approach which differs from ours in three aspects. First, it requires constructing individual metamodels for all objective and constraint functions. Second, a local approximation of the Pareto optimal set is considered. Finally, there is no clear distinction between interaction with a decision maker and the demanding computations which would imply long waiting times in case a decision maker wishes to explore different (other than local) Pareto optimal solutions. To our knowledge, there is no off-the-shelf interactive method which could be directly applied to computationally expensive simulation-based multiobjective optimization problems without creating waiting times for a decision maker.We present in this paper a three-stage solution process that is designed to address the challenges of computationally expensive multiobjective design optimization. A wide range of optimization algorithms can be integrated with the solution process, which makes it applicable to many real-life design optimization problems. In the first stage, termed the pre-decision making stage, sufficient information is gathered about the alternative solutions to the multiobjective design optimization problem. In the second stage, termed the decision making stage, a human decision maker is involved by using an interactive method to solve a computationally inexpensive surrogate problem constructed on the basis of the information gathered in the first stage. In the third stage, termed the post-decision making stage, the original design optimization problem is solved with the purpose of finding a solution that best matches the preferred solution to the surrogate problem identified in the second stage.The three-stage solution process has the benefit that it separates the time-consuming simulation-based optimization from the decision making stage. This allows fluent interaction with the decision maker regardless of the computational intensiveness of the simulation model. The solution process is motivated by the PAINT method  [17], which can be used to create a surrogate problem for decision making, as well as by the availability of multiobjective optimization methods such as ParEGO  [18] and SMS-EGO  [19] that provide a finite approximation to the Pareto optimal set of a multiobjective optimization problem.The paper has the following structure. Section  2 covers the main concepts of multiobjective optimization used in this paper. In Section  3, we describe the three-stage solution process we propose for multiobjective design optimization. Section  4 provides a description of a case study of an optimal design of a paper mill concept. Section  5 demonstrates an application of the three-stage solution process to our case study and reports the numerical results obtained in each stage. The paper is concluded in Section  6.In this section, we review the concepts and background in multiobjective optimization and design optimization relevant for the rest of the paper. Readers familiar with these topics may wish to proceed directly to Section  3.A multiobjective optimization problem (MOP) has the form(1)minf(x)=(f1(x),…,fk(x))Tsubject tox∈S,whereS⊂Rnis the feasible set andfi:S→R,i=1,…,k(k≥2), are objective functions that are to be minimized simultaneously. All objective functions are conveniently represented by a vector-valued functionf:S→Rk. A vectorx∈Sis called a decision vector and a vectorz∈Rkan objective vector. Moreover,z∈Rkis said to be attainable if there exists a decision vectorx∈Ssuch thatz=f(x)and unattainable otherwise. Without loss of generality, we consider only minimization because maximization of an objective function can be converted to minimization by multiplication by minus one.We assume that there does not exist a decision vectorx̄∈Ssuch thatx̄minimizesfiinSfor alli=1,…,k. In that case, the objective functionsf1,…,fkin (1) are said to be conflicting. A useful notion of optimality for conflicting objectives is given by Pareto optimality: a decision vectorx∈Sand the corresponding objective vectorz=f(x)are said to be Pareto optimal or nondominated if there does not exist a decision vectorx̄∈Ssuch thatfi(x̄)≤fi(x)for alli=1,…,kandf(x̄)≠f(x). On the other hand, if such a vectorx̄∈Sdoes exist,xandzare said to be dominated byx̄andz̄=f(x̄), respectively. In the following, we use the term Pareto optimal set to refer to both the set of all Pareto optimal decision vectors and the set of all Pareto optimal objective vectors.The order relation appearing in the definition of Pareto optimality is not a total but a partial order, and therefore, the set of all Pareto optimal objective vectors is not, in general, a singleton. Consequently, an optimal solution to (1) is not well defined without additional information, usually provided by a human decision maker (DM). Nonetheless, under the assumption implied by the problem formulation that for all objective functions, the less of any two values is preferred by the DM, it can be shown that the objective vector preferred by the DM to all others is always Pareto optimal. This makes it possible to support the DM in finding the preferred objective vector by excluding from consideration all the dominated ones.Upper and lower bounds are often determined for the Pareto optimal set in the objective space. The bounds are used, for example, to normalize the objective functions and to help the DM set expectations. A lower bound, known as the ideal vector, can be determined by minimizing each of the objective functionsf1,…,fkindependently overSand collecting the outcomes into a vector. In contrast, an analogous upper bound, known as the nadir vector, cannot be readily obtained in general. This is because the objective functions would have to be independently maximized over the Pareto optimal set, which is, in general, a nonconvex subset ofSthat is known only implicitly. Therefore, a rough estimate for the nadir vector is commonly used (see, e.g.,  [20]).Multiobjective optimization methods can be classified into no-preference, a priori, a posteriori, and interactive methods according to the way they involve the DM in the solution process  [20]. No-preference and a priori methods produce only a single Pareto optimal decision vector. The latter require sufficient preference information to be provided up front, whereas the former do not take the preferences of the DM into account at all. Both types of methods allow an MOP to be solved with a computational cost comparable to that of solving a single-objective optimization problem, but their main disadvantage is the lack of a systematic procedure in the case that the DM is not satisfied with the obtained solution.An opposite approach is taken by a posteriori methods, which attempt to produce a set of decision vectors so that the corresponding objective vectors represent the Pareto optimal set in the objective space as closely as possible. Instead of eliciting preference information explicitly, these methods rely on the DM to assess the alternative solutions produced and to ultimately select the preferred one. Unlike in the aforementioned methods, all the computation takes place before the DM is involved. The disadvantage of a posteriori methods is mainly their inability to support the DM in comparing and ranking the provided alternative solutions. They may also consume a lot of computational resources producing decision vectors that are of little or no relevance to the DM.Interactive methods address many of the shortcomings of the other types of methods by eliciting preference information from the DM progressively  [21]. At every iteration, the DM is presented with one or more objective vectors and asked to express preferences relative to them. The methods differ in the type of information presented to and requested from the DM, but they commonly tolerate inconsistencies in the expressed preferences as well as preference information that is valid only locally. Interactive methods facilitate exploring the Pareto optimal set and learning about the problem in a way unmatched by any of the other types of methods. Nevertheless, they can only be applied if there is a DM available who is willing to participate in the solution process. In simulation-based optimization, and in design optimization in general, this may become an issue as the interaction between the method and the DM is constantly interrupted by time-consuming computations when new solution(s) based on the preferences are to be calculated.Many multiobjective optimization methods are based on scalarization of problem (1), that is, substituting a real-valued function onSfor the vector-valued objective functionf. With a properly chosen scalarization, it can be shown that the decision vector obtained by minimizing the scalarized objective function is always Pareto optimal  [20]. Scalarization is used in many interactive methods as a way to generate new Pareto optimal solutions based on the preferences specified by the DM.Scalarization can be used to project vectors in the objective space onto the Pareto optimal set. With a suitable scalarization, it is possible to project attainable and unattainable objective vectors alike. In Section  5, we employ for this purpose an achievement (scalarizing) functionf̄z̄:S→Rdefined for allz̄∈Rkand allx∈Sas  [22,23](2)f̄z̄(x)=maxi=1,…,kfi(x)−z̄izinad−zi⋆⋆+ρ∑i=1kfi(x)zinad−zi⋆⋆,whereznad∈Rkis the nadir vector of (1) andz⋆⋆∈Rkis a Utopian vector, that is, a vector that is strictly less than the ideal vector in all components. Vectorz̄∈Rkis called a reference point, and in addition to being the vector to be projected, it can be interpreted as preference information in the form of desirable levels of the objective function values. The second term is called an augmentation term andρ, which is a strictly positive scalar, an augmentation coefficient. The use of the augmentation term ensures that every (global) minimizer off̄z̄inSis Pareto optimal for (1)   [20].Let us consider a physical system and its mathematical model represented by a multivariate, vector-valued functionΦ. By multiobjective design optimization we understand the determination of the input toΦso as to simultaneously minimize two or more objective functions that depend on the output ofΦ. The input values that are to be determined by optimization are called decision or design variables. If the decision variables constitute only a subset of the model input, the rest are considered to be parameters ofΦ, which must be set to a fixed value before the optimization is carried out. In the terminology of the Introduction, the decision variables and parameters constitute the independent variables, and the output ofΦconstitutes the dependent variables.If the modelΦis stochastic, then its output is a random vector. Therefore, the image of the output ofΦunder the objective functions is also a random vector. To apply optimization, the random objective vector must be substituted with a vector of moments of the distribution, which can be numerically estimated. For example, a multiobjective design optimization problem concerned with the minimization of the expected value of the objective vector can be written as(3)minxE{f(Φ(x,ω))}s.t.x∈S,whereE{⋅}denotes the expected value,fis a vector-valued objective function,xis a decision vector,ωis a random vector which represents the stochasticity in the model, andSis the feasible set.In practice, a numerical simulation modelϕthat is implemented in terms of pseudorandom numbers is used to sample the output of the mathematical modelΦ. This allows, for example, the expected value of the objective vector to be estimated by a sample mean. That is, instead of (3), we consider an MOP(4)minx1N∑i=1Nf(ϕi(x))s.t.x∈S,whereϕi(x)denotes for allx∈Sthe output of theith independent simulation run, or replication, atxandNis the sample size (the number of replications). Problem (4) is a black-box optimization problem because the simulation outputϕi(x)is not known in a closed form as a function ofx, but must be obtained numerically for eachx∈S.Hartikainen et al.  [17] proposed a method to approximate the Pareto optimal set of an MOP. Based on the approximation, they formulated a multiobjective surrogate problem with the same number of objectives, and approximately the same Pareto optimal set, as the original optimization problem. The objectives of the surrogate problem correspond to those of the original problem in the sense that they have the same interpretations, which allows the surrogate problem to be used for decision making in place of the original problem. Moreover, because the surrogate problem is computationally inexpensive, its use eliminates the waiting times in the interactive process and hence improves the applicability of interactive methods to computationally intensive multiobjective optimization.The use of a surrogate problem for real-life decision making consists of steps that fall naturally into three separate stages. In this section, we develop the idea of a three-stage solution process as a way to solve a computationally expensive multiobjective design optimization problem. The consecutive stages can be distinguished by several features such as the computational cost, the level of involvement of the DM, or the type of optimization applied. To emphasize the role of the DM in the process, we refer to the stages by their precedence with respect to decision making as the pre-decision making stage, the decision making stage, and the post-decision making stage. The DM is supposed to be directly involved only in the decision making stage, and all computationally intensive tasks should, thus, be confined to the pre- and post-decision making stages so as not to interfere with the interaction with the DM.The stages along with their main components and the dependences among them are illustrated in Fig. 1. The solution process starts with the pre-decision making stage, in which an a posteriori method is applied to the multiobjective design optimization problem to produce a set of Pareto optimal decision vectors and the corresponding set of objective vectors is used to define a surrogate problem. In the decision making stage, the computationally expensive design optimization problem is substituted with the computationally inexpensive surrogate problem, and the DM is asked to identify the preferred objective vector with the help of an interactive method. In the post-decision making stage, the original multiobjective design optimization problem is solved in a scalarized form to project the objective vector (of the surrogate problem) preferred by the DM to the Pareto optimal set of the original design optimization problem. Thus, the post-decision making stage can be likened to the application of an a priori method to the original design optimization problem.All three stages are necessarily coupled because each one depends on the output of its predecessor. At each stage, a different kind of optimization problem is solved and the result thereof is passed to the following stage. To ease discussion, we refer to the principal output of each stage as its solution. More specifically, a Stage  1 solution is a set of Pareto optimal decision vectors produced in the pre-decision making stage and the corresponding objective vectors are used to define the surrogate problem. A Stage  2 solution is an objective vector indicated by the DM in the interactive decision making stage as the preferred solution to the surrogate problem, and a Stage  3 solution is a projected decision vector obtained in the post-decision making stage by solving a scalarized version of the original design optimization problem.The purpose of the pre-decision making stage is to prepare a surrogate problem that enables an interactive method to be applied in the decision making stage. Additionally, the ideal vector and the nadir vector of the surrogate problem, or their estimates, should be determined.In principle, there are only two requirements for a surrogate problem: it must be solvable by scalarization (employed as a part of an interactive method) with a negligible computational cost and its Pareto optimal set must match that of the original problem, up to some tolerance. We assume that the surrogate problem can be defined on the basis of a set of Pareto optimal decision or objective vectors. Therefore, we define the Stage 1 solution as a set of Pareto optimal decision vectors obtained by applying an a posteriori method to the original design optimization problem.The PAINT method  [17] can be used to formulate a surrogate problem. It produces a piecewise linear approximation of a set of Pareto optimal objective vectors and guarantees that no two vectors in the approximation dominate one another. The surrogate problem based on the approximation is a multiobjective mixed-integer linear optimization problem.The purpose of the decision making stage is, as the name suggests, to help the DM to arrive at the preferred Pareto optimal solution. Because the choice of the preferred Pareto optimal objective vector is entirely subjective, an interactive method, which allows the DM to explore and learn about the problem, is used. We assume that an interactive method employing scalarization is used (see, e.g.,  [20,21]). For an interactive method to be successfully applied, however, it is required that scalarizations of the underlying optimization problem can be solved relatively quickly. Therefore, the surrogate problem defined in Stage 1 is used instead of the original, computationally expensive, design optimization problem.The surrogate problem in itself is like any other multiobjective optimization problem and thus no special provisions are required to solve it with an interactive method. Nonetheless, the DM should be made aware of the fact that a surrogate problem is being solved and that the obtained objective function values are only approximate.The purpose of the post-decision making stage is to determine a decision vector in the Pareto optimal set of the original design optimization problem such that the objective vector corresponding to it is as close to the Stage 2 solution as possible. In principle, it suffices to minimize a scalarization that projects the Stage 2 solution to the Pareto optimal set of the original design optimization problem, but the amount of computation required to do so can be reduced by utilizing the information acquired in Stage 1.Because the optimization problems in Stages 1 and 3 are identical except for the scalarization, the information obtained about the problem in Stage 1 can be used to warm start the optimization in Stage 3. A warm start may consist of selecting a starting point, or an initial population in the case of population-based algorithms, among the decision vectors evaluated in Stage 1 based on the value of the scalarized objective function. It is also possible to warm start optimization algorithms with more complex internal states given that the algorithms employed in the two stages are similar enough so that the internal state of one can be translated into that of the other. In particular, the metamodels of the objective functions maintained internally by many global optimization algorithms can be aggregated to obtain a metamodel of the scalarized objective function.The computational cost of Stage 3 can be reduced virtually to zero by projecting an objective vector not to the Pareto optimal set but to the set of objective vectors corresponding to the Stage 1 solution. This can be done by calculating the scalarized objective function value for all decision vectors in the Stage 1 solution and selecting the one with the least value. Although restricting the minimization to the Stage 1 solution does not, in general, minimize the scalarized objective function over the feasible set, the obtained decision vector is always Pareto optimal. Because of its low computational cost, the projection to the Stage 1 solution may be used also during the interactive decision making in Stage 2 to provide the DM with a rough estimate of the projection of a given objective vector.

@&#CONCLUSIONS@&#
In this paper, we have highlighted some of the computational challenges of solving complex simulation-based design optimization problems involving multiple conflicting objectives and have proposed a three-stage solution process to tackle them. Applying this solution process was demonstrated with a case study where the optimal design of a paper mill was considered. Our case study is very challenging due to the following characteristics: (i) high computational cost, (ii) multiple conflicting criteria, (iii) black-box problem, and (iv) stochasticity. Despite these computational difficulties, the problem was successfully solved following the proposed solution process.In Stage 1, different multiobjective optimization methods tailored for computationally expensive problems were applied to solve the original problem. Although a number of different methods were used to approximate the Pareto optimal set, it is not necessarily recommended that one should always use as many of them. Then based on the Stage 1 solution, a computationally inexpensive surrogate problem was created by the approximation method PAINT. The creation of the surrogate problem took time but solving the surrogate problem in Stage 2 of the solution process was not computationally expensive. The surrogate problem was solved by the interactive multiobjective optimization method NIMBUS without creating waiting times for the DM and enabling an efficient decision making process. In this stage, the DM was involved and asked to express one’s preferences in order to direct the search towards the preferred approximated solution. In Stage 3, a single-objective optimization problem was solved to get a solution best matching the Stage 2 solution by projecting it to the original problem. In order to reduce computational cost, the information obtained in Stage 1 was employed in Stage 3 as a warm start. The three-stage solution process proposed is not application-specific but can be applied in various design optimization problems facing the computational challenges discussed.