@&#MAIN-TITLE@&#
Associating co-authorship patterns with publications in high-impact journals

@&#HIGHLIGHTS@&#
We examined authorship patterns in different academic departments and disciplines.Levels of internal and external collaboration varied significantly by department.Some departmental author networks were more cohesive and integrated than others.Papers with at least one basic science author appeared in higher-impact journals.Teams with professors and research scientists published in high-impact journals.

@&#KEYPHRASES@&#
Co-authorship patterns,Social networking,MEDLINE,Journal impact factor,Evaluation,

@&#ABSTRACT@&#
ObjectivesTo develop a method for investigating co-authorship patterns and author team characteristics associated with the publications in high-impact journals through the integration of public MEDLINE data and institutional scientific profile data.MethodsFor all current researchers at Columbia University Medical Center, we extracted their publications from MEDLINE authored between years 2007 and 2011 and associated journal impact factors, along with author academic ranks and departmental affiliations obtained from Columbia University Scientific Profiles (CUSP). Chi-square tests were performed on co-authorship patterns, with Bonferroni correction for multiple comparisons, to identify team composition characteristics associated with publication impact factors. We also developed co-authorship networks for the 25 most prolific departments between years 2002 and 2011 and counted the internal and external authors, inter-connectivity, and centrality of each department.ResultsPapers with at least one author from a basic science department are significantly more likely to appear in high-impact journals than papers authored by those from clinical departments alone. Inclusion of at least one professor on the author list is strongly associated with publication in high-impact journals, as is inclusion of at least one research scientist. Departmental and disciplinary differences in the ratios of within- to outside-department collaboration and overall network cohesion are also observed.ConclusionsEnrichment of co-authorship patterns with author scientific profiles helps uncover associations between author team characteristics and appearance in high-impact journals. These results may offer implications for mentoring junior biomedical researchers to publish on high-impact journals, as well as for evaluating academic progress across disciplines in modern academic medical centers.

@&#INTRODUCTION@&#
Biomedical research is becoming increasingly interdisciplinary [1]. Numerous organizational factors have been recognized as barriers or facilitators of interdisciplinary research [2]. Although there are significant challenges in projects spanning multiple departments or disciplines [3], interdisciplinary research has been shown to be important for accelerating innovation [4].A variety of analytical approaches, such as social–ecological models, systems thinking and complexity theories, social-determinants paradigms, and hierarchical analytic frameworks [5], have been employed to understand patterns of scientific collaboration. A prior bibliometric study has shown differences in co-authorship patterns across disciplines [6]. However, factors associated with the differences in scientific productivity have not been systematically quantified.Given the central importance of scholarly publications and team-based scientific work, in this study we sought to understand scientific collaborations in biomedical research by investigating co-authorship patterns. Specifically, we sought to identify associations between co-authorship patterns and the impact factors of the journals of the publications. We leveraged the open-access Columbia University Scientific Profiles (CUSP) (http://irvinginstitute.columbia.edu/cusp) to obtain information about published researchers at our institution. Using CUSP, we enriched publication data with institution-internal human resources data, including author academic rank and departmental affiliation. We employed two methodological approaches: analysis of authorship patterns and co-authorship networks. We then compared departments with respect to the ratio of within- to outside-department collaboration, as well as the overall levels of structural integration, all within our institution.Data were retrieved from our institution’s research networking system, CUSP. CUSP was funded by Columbia University’s Clinical and Translational Science Award (CTSA) to facilitate research networking and to help researchers identify experts and potential collaborators at CUMC. CUSP includes grants from institutional financial databases and publications from MEDLINE, along with job title, highest degree completed, and departmental affiliation from institutional human resource data. A core feature of CUSP is ReCiter [8], a method developed by the Columbia University CTSA for author name disambiguation for publications in scholarly databases. Researcher profiling systems often require investigators to populate their own publications manually. ReCiter keeps publications up to date by populating author publication lists automatically in CUSP through monthly feeds from MEDLINE. CUSP is interoperable with the open-source semantic web application VIVO, which enables the discovery of researchers across institutions [7].When determining a time frame appropriate for article selection we sought to include enough articles to provide sufficient statistical power to address our research questions, while also minimizing the effects of missing data in older years. As CUSP only provides a snapshot of researchers currently employed at the university, historical data on academic rank and departmental affiliation were not available for current authors and no data is available for those who have left the university. Since personnel fluctuation is frequent in our university, it is appropriate to use a time period, e.g., a 5-year time period, that is shorter than our standard promotion time window (i.e., 7–11years) for the analysis of patterns of authorship based on academic rank and departmental affiliations (Section 2.2) so that we can assume such information is less likely to have substantially changed during the short time frame.Moreover, due to a recent major upgrade of administrative systems that provides departmental affiliation and rank to CUSP at our institution, year 2011 provided the most complete data at the time of the analysis. Therefore, we retrieved 7997 MEDLINE articles from 2007 to 2011 that included at least one author in CUSP. From this list of articles we identified 182 journals with an impact factor record, in which 10 or more articles were published during the time period. From these 182 journals we identified 3996 articles involving 2001 unique authors for this analysis. In contrast, for the co-authorship network analysis (Section 2.3), as social connections among researchers take time to develop, we sought to ensure that sufficient data on social links would be included. We therefore selected a 10-year period, 2002–2011, corresponding to a data set with 13609 articles, 2893 unique authors, and 2072 journals, from which individual co-authorship networks were generated for each of the top 25 departments in publishing volume (i.e., the 25 most prolific departments).The first goal of this research was to characterize associations of author academic rank and departmental affiliation with publication in high-impact journals. After preliminary descriptive analysis we formulated our research questions as (1) what are the typical co-authorship patterns with respect to five specific author team properties (i.e., total number of authors, mixing of academic rank, inclusion of senior researchers, inclusion of junior scientists, and inclusion of basic or clinician scientists); and (2) which co-authorship patterns are associated with publications in high-impact journals?To assign each article to a distinct journal impact tier we first ranked the articles based on journal impact factor for the year 2012, as reported in the ISI Journal Citation Reports [9]. We then divided the journals into three tiers based on journal impact rank: (1) High: [5.704, 51.658, n=60]; (2) Medium: [3.371, 5.635, n=61]; and (3) Low: [0.871, 3.320, n=61]. We further labeled each article with one of these three journal impact categories.We extracted academic rank and departmental affiliation for all authors having profiles in the CUSP system. For the analyses involving academic rank we included only investigators with an academic rank of postdoc, research scientist, assistant professor, associate professor, or professor (in our author academic rank notation, the term professor is used to denote full professors). Authors for whom academic rank was unavailable (e.g., authors at other institutions and researchers no longer employed at our university) were excluded. Authors were labeled according to their primary department affiliation.In this context, authorship patterns are based on academic rank and on departmental affiliation. Possible combinations based on academic rank might be one professor and one assistant professor, or one associate professor and two postdocs. Similarly, possible combinations based on department type might be one researcher from a clinical department and one researcher from dental medicine, or one researcher from public health and two researchers from basic science departments. We enumerated author patterns for each paper as follows. First, we enumerated distinctive combinations of co-authors based on academic rank irrespective of author order. For example, if one paper had a professor as its first author, an assistant professor as its second author, and another professor as its third author, its academic rank pattern was PPI, representing two professors (P) and one assistant professor (I). More example patterns are provided below: (1) IP=one assistant professor and one professor; (2) OP=one associate professor and one professor; (3) IIP=two assistant professors and one professor; and (4) DP=one postdoc and one professor.Second, we enumerated combinations of co-authors based on department type. A paper was considered to belong to a department type if at least one author on the paper was from the department type; as such, some papers included multiple department types. We calculated the number of departments involved on each paper. In this research we used the term department to refer to major organizational entities at our university, including departments within the school of public health, as well as basic science, clinical, and mixed basic/clinical departments within the medical school, interdisciplinary research centers that were classified administratively as departments, and the schools of Nursing and of Dental Medicine, which were not divided into departments. The distinction of basic vs. clinical vs. hybrid only relates to School of Medicine departments at Columbia University Medical Center (CUMC), where only basic science departments have Ph.D. programs. Clinical departments perform clinical services and research but cannot offer the Ph.D. Hybrid departments have Ph.D. programs and offer clinical services.For each specific author academic rank and author department type combination we calculated numbers of articles published in high, medium, and low-impact journals. We assigned each paper into one of two categories along five separate axes: high (five or more) vs. low (four or fewer) numbers of authors; mixing of academic rank vs. single academic rank; inclusion of at least one professor vs. non-inclusion of professors; inclusion of at least one research scientist vs. non-inclusion of research scientists; and inclusion of at least one basic science author vs. non-inclusion of basic science authors. For each of these subsets we counted the articles published in high, medium, and low-impact journals.The second goal of this research was to characterize authorship networks among the most prolific departments at CUMC. To address this goal we formulated two research questions: (1) which departments have the highest and lowest ratios of within- to outside-department collaborations? and (2) which departments have the highest and lowest levels of overall structural integration?To address these questions we employed social network analysis. Network-based approaches have been applied in mapping of knowledge domains [10], for describing basic principles that govern the structure of co-authorship networks [11], and for helping researchers understand the social aspects of scientific collaboration [12]. Within a given context, e.g. a research department, institution, or scholarly database, individuals are modeled as nodes in a network. Links are assigned between individuals with one or more types of social ties, such as participating on the same research team or service on the same grant review panel. Supplementing bibliographic data with additional author-specific information can lead to new insights [13]. However, since data about various types of social ties between researchers may not exist – or may be time consuming to collect via surveys – co-authorship is commonly used to model relations between researchers.Although co-authorship networks incorporate just one of many possible types of social ties between researchers, they combine two key advantages. First, they are derived from the well-organized endpoint of scholarly work, the published article. Second, co-authorship data are readily available in scholarly databases. Co-authorship network models may be static, reflecting collaborative activity over a period of time (as in the current work), or dynamic, reflecting multiple periods of time.Using author data from all publications in the MEDLINE database for the selected time frame (2002–2011), we then generated a co-authorship network for each of the 25 top departments, with authors represented as nodes, and links assigned between authors and their co-authors. We used the NetworkAnalyzer [14] tool built into the network visualization software Cytoscape [15], to count connected components and measure centralization in each network.To address our first research question we calculated the numbers of within-department and outside-department authors within CUMC. We also calculated the total numbers of authors and publications in each department network between years 2002 and 2011.For our second research question, there are many statistical measures of social network structure. To measure the structural integration of author-networks, we elected to measure numbers of connected components and centralization. Both are measures of overall structural integration of a network. In undirected networks, two nodes are considered connected if there is a path linking them. Within a network all nodes connected in this way form a connected component. Network centralization is a measure of overall topological structure indicating the level of structural integration in the network. It calculates the variation in the centrality scores among all the nodes in the network, while the centrality score of each node is computed according to degree of the nodes, i.e., the number of nodes connected to it. Networks that are more star-like in shape have a high centralization level close to one, while networks having a decentralized shape have a low centralization level close to zero. We used Freeman’s formula [16] for calculating network centralization as follows:CD=∑i=1N[Cd(n∗)-Cd(i)]max∑i=1N[Cd(n∗)-Cd(i)]where N is the total number of nodes, Cd(n*) is the node with the largest centrality, and Cd(i) is the centrality of each node i.

@&#CONCLUSIONS@&#
In this demonstration study we analyzed the patterns of collaboration at one academic medical center. We found specific authorship patterns to be statistically significantly associated with publication in high-impact journals. Inclusion of professors, research scientists, and basic science researchers as authors, in particular, were all strongly associated with publication in high-impact journals. Mixing of academic rank, overall, was also associated with publication in high-impact journals; however, some specific author academic rank combinations involving professors of mixed rank were associated with publication in low-impact journals. We also found marked differences between departments in tendency for authors to publish within vs. outside departments, and in overall co-authorship network cohesion.The results of this research provide original quantitative evidence that might be informative not only for supporting discussions of academic performance appraisal, but also for mentoring junior faculty. Further research is needed to determine whether similar patterns results would occur at other institutions, and to explore patterns of co-author combinations using other author-specific variables. Similar methods might also be used to identify specific departments, which do or do not have a history of collaboration, and to use the resulting data to inform planning of symposia or similar events that may make interdisciplinary initiatives more likely to occur.This publication was supported by the National Center for Advancing Translational Sciences through Grant No. UL1 TR000040. The content is solely the responsibility of the authors and does not necessarily represent the official views of the National Institutes of Health.D.D. assembled input data. M.B., S.B., J.M., S.J, C.W. designed the research methods and experiments. M.B. carried out the analyses and wrote the initial draft of the paper. C.W. made substantial edits to the paper. All authors made substantial contributions to refining the paper and approved the final draft.The authors declare no competing interests.Supplementary data associated with this article can be found, in the online version, at http://dx.doi.org/10.1016/j.jbi.2014.07.015.Supplementary data 1