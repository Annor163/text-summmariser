@&#MAIN-TITLE@&#
Geometric particle swarm optimization for robust visual ego-motion estimation via particle filtering

@&#HIGHLIGHTS@&#
Novel particle filtering based visual ego-motion estimation algorithm robust to abrupt camera motion.Multi-layered importance sampling via particle swarm optimization (PSO)Reformulation of the conventional vector space PSO algorithm by geometric special Euclidean group SE(3)Efficient convergence of PSO and real-time visual ego-motion estimation performance

@&#KEYPHRASES@&#
Visual ego-motion estimation,Visual odometry,Visual SLAM,Particle filtering,Particle swarm optimization,Special Euclidean group,

@&#ABSTRACT@&#
Conventional particle filtering-based visual ego-motion estimation or visual odometry often suffers from large local linearization errors in the case of abrupt camera motion. The main contribution of this paper is to present a novel particle filtering-based visual ego-motion estimation algorithm that is especially robust to the abrupt camera motion. The robustness to the abrupt camera motion is achieved by multi-layered importance sampling via particle swarm optimization (PSO), which iteratively moves particles to higher likelihood region without local linearization of the measurement equation. Furthermore, we make the proposed visual ego-motion estimation algorithm in real-time by reformulating the conventional vector space PSO algorithm in consideration of the geometry of the special Euclidean group SE(3), which is a Lie group representing the space of 3-D camera poses. The performance of our proposed algorithm is experimentally evaluated and compared with the local linearization and unscented particle filter-based visual ego-motion estimation algorithms on both simulated and real data sets.

@&#INTRODUCTION@&#
Visual ego-motion estimation or visual odometry is the process to continuously estimate the 3-D camera pose based on 2-D image sequences captured by a camera. Visual ego-motion estimation plays an important role in various computer vision and robotics applications such as visual simultaneous localization and mapping (SLAM) and augmented reality [1–6].Visual ego-motion estimation can be formulated as a state estimation problem and effectively solved by Bayesian filtering methods [7–9]. Particle filtering also known as sequential Monte Carlo [10,11] is one of the popular Bayesian filtering methods for visual ego-motion estimation because of its inherent ability to deal with nonlinearity present in camera projection [12–14].How to choose the importance function is one of crucial factors for the performance of particle filtering [10]. The most simple choice is to use the state transition density determined by the state equation as the importance function. The well-known problem of the sampling from the state transition density is the waste of particles due to the fact that the recent measurement is not considered in particle sampling.To improve the sampling efficiency and overall performance of particle filtering-based visual ego-motion estimation, we should utilize the optimal importance function that minimizes the variance of particle weights by explicitly considering the recent measurement [10]. Since the closed form of optimal importance function is not available for general nonlinear systems, its adequate approximation is required. In practice, the most feasible way is to approximate the optimal importance function as Gaussian distribution based on the local linearization of a measurement function [10].However, there is an inherent problem in the local linearization-based approximation of the optimal importance function: there always exists a local linearization error for nonlinear measurement functions. When the state predicted by the state equation is fairly close to the true state, the linearization error is negligible and the optimal importance function can be approximated accurately. However, if the predicted state is far from the true state, the optimal importance function cannot be approximated accurately because of a large local linearization error. Fig. 1graphically illustrates this local linearization error arising in approximating the optimal importance function.To overcome the limitation of local linearization-based approximation, the unscented particle filter (UPF) [15] was proposed. The UPF employs a deterministic sampling approach called the unscented transformation (UT) [16,17] to estimate the mean and covariance of optimal importance function using a small number of samples called sigma points. Whereas the local linearization relies on the first order approximation, the unscented transformation can estimate the covariance accurately up to the third order [18] and thus approximate the optimal importance function more accurately. However, it cannot be a perfect solution because it still depends on the Gaussian approximation.In this paper, we focus on abrupt camera motion that can result in large error in approximating the optimal importance function for visual ego-motion estimation. We define the abrupt camera motion as the motion that cannot be well predicted by the state equation. The most probable case is to perform visual ego-motion estimation using a hand-held camera without additional motion sensors (e.g., web-cams). Since there is no available motion estimate, it is usual to use smooth motion models such as constant velocity for the motion dynamics. In this case, the sudden and sharp camera motion especially in orientation between adjacent frames shall not be predicted well by the smooth motion model and result in large error in the optimal importance function approximation. Even with additional motion sensors such as gyros and actuator information of mobile robots, the state can be predicted poorly. One of examples of such cases is to perform visual ego-motion estimation using cameras mounted on mobile robots moving on quite uneven terrain.The first contribution of this paper is to present a novel particle filtering-based visual ego-motion estimation algorithm especially robust to abrupt camera motion. To obtain particles distributed consistently with the recent measurement even for the case of abrupt camera motion, we propose to use multi-layered importance sampling via particle swarm optimization (PSO), which is a meta-heuristic optimization algorithm to effectively find the global optimum using particles sharing information between themselves [19,20]. In our proposed multi-layered importance sampling, the particles sampled from a motion model are moved to higher likelihood region iteratively via PSO. The particles are made to be more consistent with the recent measurement by PSO and can be considered to be similar to those sampled from the optimal importance function. Since our proposed approach does not require the measurement equation approximation and the Gaussian assumption, we can obtain superior visual ego-motion estimation results in the case of abrupt camera motion compared with the local linearization and UT-based approximation methods.Since we employ PSO which is an iterative method, efficient convergence is an important issue toward a real-time visual ego-motion estimation system. The second contribution of this paper is to reformulate the conventional vector space PSO algorithm in terms of the geometry of the special Euclidean group SE(3), which is a Lie group corresponding to the space of camera poses. By employing the proposed geometric PSO on SE(3), less iterations are needed for particle convergence than the vector space PSO, and it results in a real-time implementation of our proposed visual ego-motion estimation algorithm.PSO has been already applied to various vision problems such as visual tracking [21,22] and visual SLAM [23,24]. Here, we concentrate on PSO for visual ego-motion estimation-related problems. Ref. [23] proposed PSO-FastSLAM, where PSO is used to enhance the resampling performance of the ordinary FastSLAM method used for visual SLAM. Hence, PSO-FastSLAM cannot properly deal with the abrupt camera motion. In Ref. [24], PSO is used to cope with the linearization error problem and overcome the ambiguity of repeated ceiling patterns by adopting the concept of multi-swarms. Ref. [24] can be considered to be similar to ours as Ref. [24] employs PSO to reduce the linearization error in approximating the optimal importance function. However, Ref. [24] is much more restricted than ours because it relies on the odometry information. Furthermore, both Ref. [23] and Ref. [24] only deal with 3-DOF ego-motion estimation problems, i.e., the state space is confined to a 2-D plane. Unlike Ref. [23] and Ref. [24], we deal with general 6-DOF ego-motion estimation problems without odometry information. To the best of our knowledge, our proposed algorithm is the first one that employs PSO in a 6-DOF visual ego-motion estimation system, where the unavailable odometry information brings much more difficulties.We demonstrate the robustness of the proposed visual ego-motion estimation algorithm to abrupt camera motion via various experiments with simulated and real sequences. We first show that our proposed algorithm yields superior performance in the presence of abrupt camera motion to the local linearization and UT-based importance functions via simulated experiments. We also verify that the proposed geometric PSO is more efficient than the conventional vector space PSO. Via experiments with the real sequences where abrupt camera motion is prominent, we show that our proposed visual ego-motion estimation algorithm can yield quite accurate results in real-time despite abrupt camera motion.Our visual ego-motion estimation algorithm is quite similar to particle filtering-based SLAM systems [25,26,12–14] because we build a map of landmarks and update it via extended Kalman filter (EKF) based on the estimated camera pose. The important difference between our algorithm and complete SLAM algorithms is that there is no loop closing in our algorithm. Our visual ego-motion algorithm can be equipped with a loop closing algorithm to be used for visual SLAM problems. Alternatively, our proposed multi-layered importance sampling via geometric PSO on SE(3) can be easily plugged into any existing particle filtering-based visual SLAM system to enhance the robustness to the abrupt camera motion.The paper is organized as follows. In Section II, we first briefly review the conventional PSO on a vector space and then present our geometric PSO on SE(3). In Section III, we present our visual ego-motion estimation framework including multi-layered importance sampling using our geometric PSO. In Section IV, we verify the feasibility of the proposed visual ego-motion estimation algorithm via various experiments with the simulated and real sequences, while Section V concludes with a summary.In this section, we present our geometric PSO algorithm formulated in consideration of the geometry of SE(3). We begin with a brief review of conventional PSO on a vector space. The more thorough review of PSO can be found in Ref. [20].The principal idea of PSO is to use interactions between particles sharing information between themselves to find the global optimum efficiently. Consider a set of particles x≙{x1,⋯,xM} randomly distributed on the solution space. Each particlexi∈RNexplores the solution space to find the global optimum based on two relative position vectors pgb−xiand pibi−xi, where pgb is a globally best particle and pibiis the best record of each particle xi.Each particle computes its velocityvi∈RN, which indicates where to go, by summing the two relative position vectors as(1)vi←w⋅vi+c1⋅r1⊗pibi−xi+c2⋅r2⊗pgb−xi,where w is the inertia, c1 and c2 are the weighting coefficients for the two relative position vectors, and ⊗ represents the component-wise multiplication. r1 andr2∈RNare random vectors drawn from a uniform distribution on the interval between 0 and 1, which give stochasticity in optimization. Then each particle ximoves to a new position using vias(2)xi←xi+vi.Finally, pgb and pibiare newly updated as(3)pibi←xiiffxi>fpibi,pgb←xiiffxi>fpgb,where f is a fitness function, i.e., an objective function.By repeating Eqs. (1), (2), and (3) for a number of times, particles can explore the solution space efficiently and convergence can be guaranteed. In order to avoid convergence to local optima, anti-converging particles called quantum particles are employed. At the end of a single PSO iteration, quantum particlesxq∈RNare randomly generated as(4)xq∈Bpgbrcloud,where B(pgb,rcloud) represents the particle cloud centered at pgb within radius rcloud. Newly generated quantum particles are also evaluated by a fitness function and can be selected as the global best particle pgb according to its fitness value. If any of quantum particles finds the better position and selected as pgb, the other particles xican escape the local optima and converge to the global optimum consequently. It is usual to call normal particles neutral particles when quantum particles are employed. An example of optimization using PSO with quantum particles is shown in Fig. 2.A camera pose can be represented by a rigid body transformation matrix of the formRt01in the homogeneous coordinates, where R is a 3×3 rotation matrix and t is aR3vector. The rigid body transformation matrices and the rotation matrices can be identified with matrix Lie groups, i.e., the special Euclidean group SE(3) and the special orthogonal group SO(3), respectively. SO(3) and SE(3) can be formally defined as(5)SO3=R∈R3×3|R⊤R=RR⊤=I,detR=+1and(6)SE3=Rt01,where R∈SO(3) andt∈R3.A Lie group is a differentiable manifold possessing group structure with smooth product and inverse operations. The Lie algebra associated with a Lie group is defined as a tangent vector space at the identity of a Lie group. The Lie algebras associated with SE(3) and SO(3) are denoted by SE(3) and SO(3), respectively. A Lie group and its Lie algebra can be related via the exponential map, i.e., exp:so(3)→SO(3) and exp:se(3)→SE(3). The log map is defined as the inverse of the exponential map. For matrix Lie groups, the matrix exponential and log give the exponential and log maps. SO(3) is a set of 3×3 skew symmetric matrices of the formω=0−ω3ω2ω30−ω1−ω2ω10, and se(3) is given byωv00with ω∈so(3) andv∈R3.In this paper, we represent the camera pose as SE(3) itself not employing vector parametrization of rotation matrices such as Euler angles. By SE(3) representation, we do not suffer from a singularity problem inherent in any kind ofR3vector parametrization of rotation matrices. However, since SE(3) is a curved space not a flat vector space, we should reformulate PSO in consideration of the geometry of SE(3) for better optimization behavior.In order to formulate a geometric PSO algorithm on SE(3), we first consider a general Riemannian manifold case. What we have to consider when formulating PSO on a Riemannian manifold is that the difference between particles should be calculated as the minimal geodesic distance on a manifold. Since the Riemannian log and exponential maps are derived from the minimal geodesics on the Riemannian manifold, we can represent the difference between the elements on the Riemannian manifold as the one on its tangent vector space obtained via the Riemannian log map. In this manner, a particle can be considered to be a point Xion a manifold, and its velocity Vican be defined as the one on the tangent vector space of Xi.The difference between Xiand the individual best Pibican be identified as a vector on the tangent space at Xiobtained vialogXi, the Riemannian log map at Xi, and can be represented aslogXiPibi. The difference between Xiand the global best Pgb also can be represented aslogXiPgb. Then the velocity Viis obtained bylogXiPibiandlogXiPgbsimilarly to Eq. (1) and the particle update with Viis realized viaexpXi, the Riemannian exponential map at Xi, asexpXiVi. Fig. 3depicts this geometric PSO procedure on a general Riemannian manifold. The procedure of PSO on manifolds has some similarity to the nonlinear mean shift on manifolds of Ref. [27] since the required operations are done on the tangent vector space of a manifold.However, it is not straightforward to directly apply this geometric PSO on a general Riemannian manifold to SE(3). The first requirement of geometric PSO is to obtain the Riemannian exponential and log maps on a specific manifold. Since the minimal geodesics on SE(3) is given by the union of the respective geodesics on SO(3) andR3[28], it is hard to obtain a single expression of the Riemannian exponential and log maps for SE(3). Fortunately, the Riemannian exponential and log maps for SO(3) are simply given by the left and right translations of exp and log, which are the matrix exponential and log. Thus, we can perform geometric PSO on SE(3) appropriately by splitting Xi∈SE(3) into Ri∈SO(3) andti∈R3.The calculations of particle velocity VRi∈so(3) and particle update for Riare given by(7)VRi←w⋅VRi+c1⋅r1R⊗logRi⊤Ribi+c2⋅r2R⊗logRi⊤Rgb,Ri←Ri⋅expVRi,where Ribiand Rgb are the rotation parts of the individual and global best particles, respectively. Note that the differences are calculated by log after multiplying Ri⊤ to Ribiand Rgb. Then the exponential of the resulting vector on the tangent vector space is multiplied by Ri. This is to apply the exact Riemannian exponential and log maps of SO(3). In Eq. (7), r1Rand r2RrepresentR3uniform random vectors, and ⊗ represents the component-wise multiplication with SO(3) elements represented inR3column vectors with respect to basis elements of SO(3). The velocity calculation and particle update equations for tican be represented by the ordinary PSO algorithm as(8)Vti←w⋅Vti+c1⋅r1t⊗tibi−ti+c2⋅r2t⊗tgb−ti,ti←ti+Vti,where tibiand tgb are the translation parts of the individual and global best particles, respectively. r1tand r2trepresent uniform random vectors onR3.The quantum particles around Rgb are generated by Rgb⋅exp(e), where e∈so(3) is composed of a uniform random vector onR3with the zero mean. Similarly, those for tgb are generated from the uniform distribution with the mean tgb. After particle update, the fitness function evaluation is performed at the new position determined by merging the newly updated Riand tiinto Xi.We now present our proposed visual ego-motion estimation framework based on particle filtering and PSO. The distinct feature of our framework is the multi-layered importance sampling via our geometric PSO on SE(3), which gives robustness to abrupt camera motion. Our system uses only images from hand-held cameras as sensor input. We consider both monocular and binocular cases with known intrinsic camera parameters. The overall procedure of the proposed framework is summarized in Algorithm 1.Algorithm 1Overall algorithm1.Initializationa.Set the number of particles as N and k=0.b.Set the number of PSO iteration as M.c.For i=1,…,N, set X0i=I, and A0i=0.d.Initialize landmarks with the detected FAST corners.2.Multi-layered importance sampling via PSO on SE(3)a.Set k=k+1.b.Perform FAST corner detection and data association.c.For i=1,…,N, draw Xki∼p(Xk|Xk−1i).d.Perform geometric PSO on SE(3) with M iterations.-Update the particles via Eqs. (7) and (8).-Evaluate f(Xki) and update Pgb and Pibi.-Draw the quantum particles Xq.-Evaluate f(Xq) and update Pgb.-If Eq. (15) is satisfied, finish the iteration.e.For i=1,…,N, compute Akiwith Eq. (10).3.Landmark updatea.For i=1,…,N, landmarks are updated via EKF and the weights wkiare computed via Eq. (16)4.Resamplinga.Resample Xki, Aki, and the associated landmarks according to the normalized wkiand setwki=1N.5.Landmark initializationa.Initialize landmarks from new FAST corners.6.Go to Step 2.To represent the camera pose as SE(3), we need a state equation properly defined on SE(3). The discretized stochastic differential equation on SE(3) previously employed in Ref. [29] is suitable for our purpose. Since we assume hand-held cameras whose odometry information is not available, we employ the auto-regressive (AR) process on SE(3) as the state dynamics, which is similar to the smooth motion models used in other previous work [8,14]. Though the smooth motion model is employed, our framework can work well even with abrupt camera motion by multi-layered importance sampling via geometric PSO on SE(3) that will be detailed in Section III-D. Our state equation on SE(3) is expressed as(9)Xk=Xk−1⋅expAk−1+dWkΔt,where Xk∈SE(3), dWkis the Wiener process noise on SE(3) with a covarianceΣW∈R6×6, and Ak−1 is the AR state dynamics term calculated as(10)Ak−1=alogXk−2−1Xk−1with the scalar AR process parameter a usually set to be smaller than 1.In our framework, we regard a landmark as a 3-D point and represent it as a 6-D vector using the inverse-depth parametrization since it allows us to deal with 3-D points at infinity and initialize landmarks using a single image from a monocular camera [30].With the inverse-depth parametrization, a landmark L is represented as a 6-D vector, which is composed of an initial 3-D pointt^, orientationθ^ϕ^, and inverse depthρ^, with a covarianceΣL∈R6×6representing its uncertainty. Then measurement ykfrom Xkis the 2-D image coordinates of the camera projection of a landmark, which is represented as(11)yk=gXk−1⋅hL+nk,where h is a function transforming a 6-D L into a 3-D position in homogeneous coordinates, g is a camera projection function with the known internal parameters, and nkis Gaussian measurement noise with a covarianceQ∈R2×2. Then the likelihood distribution is given as(12)pyk|Xk=Nyky^kQ,where ykis an observed measurement andy^kis the predicted measurement from Xk. Note that if there are N landmarks in a scene, ykbecomes aR2Nvector in the monocular case.In the binocular camera case, it is possible to use depth information which is computed by stereo triangulation as Ref. [13]. Such depth information, however, is sensitive to noise, especially when a landmark is far from the camera. Thus, we use horizontal differences of stereo pair points as measurement directly without triangulation. Accordingly, we still represent a landmark using the inverse-depth parametrization even in the binocular camera case. In this case, we set a value of a diagonal term of ΣLrelated to the inverse depthρ^in inverse proportion to the disparity of L at initialization because a possible error for a landmark with smaller disparity will be greater than for one with larger disparity. Note that this over-parametrization in the binocular case is intended not to rely on triangulation and the uncertainty ofρ^is usually much smaller than the monocular case.In the binocular camera case, we use the same projection function g for both left and right cameras with the assumption of the rectified binocular camera. Therefore, the measurementy¯kfrom Xkin the binocular case becomes aR4vector composed of projections of a landmark L and can be expressed as(13)y¯k=gXk−1⋅hLgXk⋅TLR−1⋅hL+n¯k,where TLR∈SE(3) represents coordinate transformation from a left camera to a right one, andn¯kis Gaussian measurement noise with a covarianceQ¯∈R4×4. Since we rectify the stereo images to have epipolar lines parallel to the horizontal axis, we set the values ofQ¯related to the vertical coordinates of a right camera image as nearly 0. It means that the degrees of freedom ofy¯kis actually 3. Note that the state Xkrepresents the left camera pose. If there are N landmarks in a scene,y¯kbecomes aR4Nvector. Fig. 4depicts the measurement and the state transition model in the binocular camera case.At the initial frame, we first detect the FAST corners [31] above a certain threshold from an image. A 31×31 patch centered at the selected corner on the image is extracted with landmark initialization and used in data association in future frames. At the future frames, the extracted landmark images are transformed up to the scale and rotation according to the predicted camera pose, and then landmarks are associated with the detected FAST corners on new input images by a normalized cross correlation (NCC) value. To minimize the boundary effect caused by image transformation, only a smaller 21×21 patch of the transformed image is considered in calculating NCC. We newly initialize landmarks based on the remaining corners. We maintain only the most recent 500 landmarks in a built map for computational efficiency.In the binocular camera case, we detect the FAST corners for both images and perform stereo matching based on the corners on the reference camera (a left camera in our implementation). We apply a simple template matching method based on the sum of absolute difference (SAD), and use rectified images to reduce the search range to horizontal lines. Then the so called LR check follows to assure the matching consistency, which enhances the performance of data association. The overall procedure of the data association is briefly shown in Fig. 5.In our multi-layered importance sampling, the state transition density p(Xk|Xk−1) is used as the initial importance function. At time k, we first sample particles Xkivia Eq. (9). Then we perform our geometric PSO on SE(3) to move the initially sampled particles Xkito a higher likelihood region. A single iteration of PSO can be regarded as a single layer of multi-layered importance sampling.In the PSO iteration, we first set Pgb and Pibiaccording to the fitness function f(Xk), which is defined as(14)fXk=−1Ns∥yk−yk∥2,where Nsis the number of matched landmarks. By maximizing the fitness value f(Xk) via geometric PSO on SE(3), we can obtain the particles distributed consistently with the recent measurement yk.It is important for PSO performance how to appropriately set the values for w, c1, and c2 in Eqs. (7) and (8). c1 and c2 control the relative attraction to the Pgb and Pibi, respectively, and it is general to set c1=c2. The convergence speed is mainly affected by w which has a similar role to the temperature in the simulated annealing. Although smaller values of w assure faster convergence, the exploring ability is diminished and it can lead to convergence to local optima. On the other hand, too large values of w slow down the convergence speed. Fig. 6shows an example that how the fitness values change in accordance with different values of the inertia parameter w. We empirically set w=0.5 andc1=c2=1wto yield the best performance in our experiments.The geometric PSO iteration is terminated when the following condition is satisfied:(15)fPgb−fPwst<τ,where Pwst denotes the global worst particle at each iteration. We empirically set τ=1. We also limit the maximum number of iteration to 15 in order to ensure real-time performance of the proposed algorithm.After the particle update, we generate quantum particles as many as 20% of ordinary neutral particles with a radius rcloud around Pgb. Here, we set rcloud to be equal to the diagonal terms of the state covariance ΣW. The quantum particles generated at each iteration play the important role to find the global optimum even in the case of abrupt camera motion. When the multi-layered importance sampling via geometric PSO is finished, Akiare updated with the finally obtained particlesX^kivia Eq. (10).After the multi-layered importance sampling via geometric PSO on SE(3), the landmarks are updated by EKF based on the finally obtained camera poseX^kiand the measurement yk. Although we adopt the notion of multi-layered importance sampling, the weights should be calculated differently from generic multi-layered importance sampling of Ref. [32]. In Ref. [32], it is assumed that different measurements are available for each layer. However, in our framework, each geometric PSO iteration is performed with the same measurement yk.The simplest way to deal with this problem is to assume that we actually have another state equation which propagates particles from Xk−1ito the finally obtainedX^kivia geometric PSO and we sample particles from such state transition density. In this case, the particle weight calculation is simply given by(16)wki=wk−1i⋅pyk|X^kias in the usual case of state transition density-based importance functions. Finally, the optimal state estimationX¯kis computed by the sample mean of SE(3) particles following the formula given in, e.g., Ref. [33].

@&#CONCLUSIONS@&#
In this paper, we have proposed a new particle filtering-based visual ego-motion estimation framework especially robust to abrupt camera motion. We achieved the robustness to abrupt camera motion via multi-layered importance sampling based on our geometric PSO on SE(3). We experimentally demonstrated that our proposed framework yielded superior ego-motion estimation performance to the local linearization and UT-based importance functions in the case of abrupt motion. We also verified that the optimization performance of our geometric PSO was better than that of conventional vector space PSO. Moreover, we finally showed that our framework could run in real time to yield successful results for real sequences where severe abrupt camera motion is present.