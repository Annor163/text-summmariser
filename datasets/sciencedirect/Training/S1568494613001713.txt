@&#MAIN-TITLE@&#
Particle swarm optimization with grey evolutionary analysis

@&#HIGHLIGHTS@&#
Propose a modified grey relational analysis for PSO algorithm.Propose grey evolutionary analysis to evaluate the evolutionary state of a swarm.GEA-based algorithm parameters could adapt to the evolutionary state.GEA-based PSO can perform a global search with faster convergence speed.

@&#KEYPHRASES@&#
Evolutionary computation,Grey evolutionary analysis,Grey relational analysis,Parameter automation strategy,Particle swarm optimization,

@&#ABSTRACT@&#
Based on grey relational analysis, this study attempts to propose a grey evolutionary analysis (GEA) to analyze the population distribution of particle swarm optimization (PSO) during the evolutionary process. Then two GEA-based parameter automation approaches are developed. One is for the inertia weight and the other is for the acceleration coefficients. With the help of the GEA technique, the proposed parameter automation approaches would enable the inertia weight and acceleration coefficients to adapt to the evolutionary state. Such parameter automation behaviour also makes an attempt on the GEA-based PSO to perform a global search over the search space with faster convergence speed. In addition, the proposed PSO is applied to solve the optimization problems of twelve unimodal and multimodal benchmark functions for illustration. Simulation results show that the proposed GEA-based PSO could outperform the adaptive PSO, the grey PSO, and two well-known PSO variants on most of the test functions.

@&#INTRODUCTION@&#
Particle swarm optimization (PSO), introduced by Kennedy and Eberhart in 1995 [1,2], was inspired by the simulation of simplified animal social behaviours including bird flocking, fish schooling, etc. The PSO uses a simple mechanism that imitates their swarm behaviours to guide the particles to search for globally optimal solutions. Similar to other evolutionary computation techniques, it is also a population-based iterative algorithm, but it works on the social behaviour of particles in the swarm. It finds the global best solution by simply adjusting the trajectory of each particle not only towards its own best location but also towards the best particle of the entire swarm at each generation. Owing to its simplicity of implementation and ability to quickly converge to a reasonably good solution [3], the PSO has been successfully applied in solving many real-world optimization problems including electrical power system [4], pattern recognition [5], controller design [6–8], etc.Although the standard PSO has the previous advantages, it may suffer from trapping in the local optimal problem when solving complex multimodal functions [9]. Avoiding the local optimal problem and accelerating the convergence speed therefore become two important issues in the PSO research. A number of variants of PSO have been proposed to achieve these two purposes. Generally speaking, those developments could be categorized as the following three approaches: control of algorithm parameters [10–13], combination with auxiliary search operators [14–19], and improvement of topological structure [20–23]. As far as control of algorithm parameters is considered, the time-varying control schemes, such as the linearly varying inertia weight [10] and the time-varying acceleration coefficients [11], are commonly used to improve the search performance of PSO. Although those two approaches are simple, they may suffer from improperly updating the parameters because no information on the evolutionary state that reflects the diversity of the population is identified or utilized. Zhan et al. therefore proposed the adaptive PSO (APSO) [3] to solve this problem. By evaluating the population distribution and particle fitness, the APSO utilizes an evolutionary state estimation (ESE) technique to identify one out of four defined evolutionary states (i.e., exploration, exploitation, convergence and jumping out) in each generation. Then, based on the identified evolutionary state, the adaptive parameter control strategies are applied to adjust the inertia weight and the acceleration coefficients. Such adaptive strategies could enhance the performance of PSO in terms of convergence speed, global optimality, and algorithm reliability.In order to identify the evolutionary state, the ESE technique must compute the mean distance of each particle to all the other particles in advance. For a swarm with a large population size, the ESE technique may suffer from a heavily computational load. The fact gives rise to the motivation to develop a more efficient ESE technique in this study. Grey relational analysis is a similarity measure for finite sequences with incomplete information [23,24]. For a given reference sequence and a given set of comparative sequences, grey relational analysis can be used to determine the relational grade (similarity) between the reference and each comparative sequence in the given set. While each particle in the PSO is regarded as a comparative sequence and the fittest particle as the reference one, the relationship between a specific particle and the fittest particle can be found by the corresponding relational grade. The larger the relational grade is, the closer the fittest particle and that specific particle are. Therefore the result of grey relational analysis involves some information of population distribution. Based on this characteristic, this study attempts to propose the so-called grey evolutionary analysis (GEA) scheme to improve the identification efficiency of the original ESE approach.In addition, this study also proposes two GEA-based parameter automation approaches for the PSO. One is for the inertia weight and the other is for the acceleration coefficients. Rather than using the adaptive parameter control process as indicated in the APSO [3], the proposed GEA-based algorithm parameters are directly obtained from the corresponding transformation functions. In this study, those functions are determined according to the evolutionary behaviour so as to perform a global search with faster convergence speed.The remainder of this paper is organized as follows. Section 2 briefly presents some background material of grey relational analysis and particle swarm optimization. Grey evolutionary analysis for the PSO is described in Section 3. The proposed GEA-based PSO is described in Section 4. Section 5 presents the search performance of the proposed algorithm for twelve test functions. Finally, Section 6 contains some conclusions of this study.Grey relational analysis is a similarity measure for finite sequences with incomplete information [23]. Assume that the reference sequence is defined as y=(y1, y2, y3, …, yn) and the comparative sequences are given by xi=(xi1, xi2, …, xin), i=1, 2, 3, …, m. The grey relational coefficient between y and xiat the kth datum, k=1, 2, 3, …, n, is defined as follows:(1)r(yk,xik)=δmin+ξ⋅δmaxδik+ξ⋅δmax,where δik=|yk−xik|, δmax=maximaxkδik, δmin=miniminkδik, and ξ∈(0, 1], which is a distinguishing coefficient to control the resolution between δmax and δmin. The corresponding grey relational grade is(2)g(y,xi)=∑k=1n[αk⋅r(yk,xik)],where αkis the weighting factor of grey relational coefficient r(yk, xik) and∑k=1nαk=1.The selection of the weighting factor for a relational coefficient reflects the importance of that datum. In general, we can select it as αk=1/n for all k. The best comparative sequence is determined as the one with the largest relational grade. On the other hand, it can be derived from (1) that r(yk, xik)∈[ξ/(1+ξ), 1]. The result could further imply that g(y, xi)∈[ξ/(1+ξ), 1].In the PSO, a swarm of particles are represented as potential solutions, and each particle i is associated with two vectors, i.e., the velocity vector Vi=(vi1, vi2, …, viD) and the position vector Xi=(xi1, xi2, …, xiD), where D represents the dimensions of the solution space. The velocity and position of each particle are initialized by random vectors within the corresponding ranges. During the evolutionary process, the trajectory of each individual is adjusted by dynamically altering the velocity of each particle, according to its own flying experience (pBest) and the flying experience of the other particles (gBest) in the search space. That is, the velocity and position of the ith particle on dimension d are updated as(3)vid=wvid+c1rand1d(pBestid−xid)+c2rand2d(gBestd−xid),(4)xid=xid+vid,where w is the inertia weight, c1 and c2 are the acceleration coefficients, and rand1dand rand2dare two uniformly distributed random numbers independently generated within [0, 1] for the dth dimension [3]. In (3), pBestirepresents the position with the best fitness found so far for the ith particle, and gBest is the best position discovered by the whole particles.The first part of (3) is the previous velocity, which provides the necessary momentum for particles to roam around the search space. The second part, known as the “self-cognitive” component, represents the personal thinking of each particle. The cognitive component encourages the particles to move towards their own best positions found so far. The third part, regarded as the “social influence” component, expresses the collaborative effect of the particles, in finding the global optimal solution. The social component always pulls the particles to the global best particle found so far.Shi and Eberhart in [10] proposed the PSO with a linearly varying inertia weight (PSO-LVIW) over the generations to improve the performance of PSO. The corresponding mathematical representation is(5)w=wmax−(wmax−wmin)tT,where t is the current generation number and T is a predefined maximum number of generations. Besides, the maximal and minimal weights, wmax and wmin, are usually set to 0.9 and 0.4, respectively [10].The PSO with time-varying acceleration coefficients (PSO-TVAC) [11] is another widely used strategy to improve the performance of PSO. With a large cognitive component and a small social component at the beginning, particles are allowed to move around the search space, instead of moving towards the population best. On the other hand, a small cognitive component and a large social component allow the particles to converge to the global optima in the latter part of the evolutionary process. This modification can be mathematically represented as follows:(6)c1=(c1f−c1i)tT+c1i,(7)c2=(c2f−c2i)tT+c2iwhere c1i, c1f, c2i, and c2fare constants. The best ranges for c1 and c2 suggested in [11] are 2.5–0.5 and 0.5–2.5, respectively. In other words, a larger c1 and a smaller c2 were set at the beginning and were gradually reversed during search.Different from the above two time-varying schemes, the APSO [3] utilizes an evolutionary state estimation approach to identify one out of four evolutionary states, i.e., the states of exploration, exploitation, convergence and jumping out. The ESE approach involves the following three main steps.(1)Calculate the mean distance of each particle i to all the other particles, where the mean distance is defined as(8)d¯i=1N−1∑j=1,j≠iN∑d=1D(xid−xjd)2,where N is the population size.Compute the evolutionary factor f as follows.(9)f=d¯g−d¯mind¯max−d¯min∈[0,1],whered¯grepresents the mean distance of the globally best particle, andd¯maxandd¯minare the maximum and minimum mean distances, respectively.Classify the evolutionary factor f into one of the four evolutionary states with a fuzzy classification option. The membership functions for the four evolutionary states are given in Fig. 1.Once the evolutionary state is identified, the algorithm parameters are adjusted according to the identified state. For example, the inertia weight can be obtained by the following sigmoid mapping(10)w(f)=11+1.5e−2.6f∈[0.4,0.9].Besides, the following adaptive control strategies are applied to adjust the acceleration coefficients. (1) Increasing c1 and decreasing c2 in the exploration state. (2) Increasing c1 slightly and decreasing c2 slightly in the exploitation state. (3) Increasing c1 slightly and increasing c2 slightly in the convergence state. (4) Decreasing c1 and increasing c2 in the jump-out state.Grey PSO, which combines the PSO with grey relational analysis, is a kind of hybrid PSO [25]. While the fittest particle gBest is regarded as the reference sequence and all particles X's are viewed as the comparative ones, grey relational analysis could be applied to analyze the similarity between them. Denote the grey relational grade between the fittest particle gBest and the ith particle Xias gi=g(gBest, Xi). Then the larger the relational grade giis, the closer the fittest particle gBest and the ith particle Xiare. Since the relational grade involves some information of population distribution, the grey PSO utilizes the relational grade gito determine the weight inertia (wi) and acceleration coefficients (c1iand c2i) for the particle i. The corresponding mathematical representations are represented as follows.(11)wi=fw(gi)=wmin−wmaxgmax−gmingi+wmaxgmax−wmingmingmax−gmin,(12)c2i=fc(gi)=cmax−cmingmax−gmingi+cmingmax−cmaxgmingmax−gmin,(13)c1i=4.0−c2i,where the subscripts “max” and “min” represent the maximal and minimal values of the corresponding parameter, respectively, and fwand fcare the transformation functions for the weight inertia w and the acceleration coefficient c2, respectively. Figs. 2 and 3are two possible transformation functions for the grey PSO.As can be seen from (11)–(13), each particle has its own inertia weight and acceleration coefficients whose values are dependent upon the corresponding grey relational grade. Since the relational grade of a particle is varying over the generations, those parameters are also time-varying. Even if in the same generation, those parameters may differ for different particles. With this modification, the updating rule for the velocity of the ith particle on dimension d becomes as(14)vid=wivid+c1irand1(pBestid−xid)+c2irand2(gBestd−xid),where wiis the inertia weight, c1iand c2iare the acceleration coefficients, and rand1 and rand2 are two uniformly distributed random numbers independently generated within [0, 1].During a PSO search process, the characteristic of population distribution varies over the generations. At the early part of the search, the particles may be scattered all over the search space. The population distribution therefore is dispersive. As the evolutionary process goes on, the particles will gradually gather and then converge to a locally or globally optimal point. It is obvious that the information of population distribution is different from that in the early stage. Owing to grey relational analysis with the ability of similarity measure, this section therefore attempts to develop the grey evolutionary analysis for the PSO in order to investigate the relation between the information of population distribution and the result of grey relational analysis.While grey relational analysis is directly applied to the evolutionary algorithm such as the grey PSO [25], grey relational analysis will suffer from the following two problems. The first one is that grey relational analysis is a local-type, but not global-type, approach. That is to say, the determinations of δmax and δmin only take the distribution of particles in that generation into consideration, but do not consider the population distribution in other generations. The maximal factor δmax and the minimal factor δmin given in (1) therefore can be regarded as in the form of “local” version. The second problem is that grey relational coefficient is undefined if δmax=0 and δmin=0. While all the swarm is converged to the optimal point, both δmax and δmin are equal to zero. At this situation, grey relational coefficient (1) becomes undefined.Considering these concerns, a “global” version of grey relational analysis is proposed such that it not only attempts to solve the undefined problem but also can use almost the same metric to measure the relational grades in the evolutionary process. In this study, global-type grey relational analysis is modified from “grey relational analysis with global distance factor” in [26]. Define δid=|gBestd−xid| and δmax=maximaxdδid, where δmax represents the local maximal factor. Denote Δmax as the global maximal factor. At the first generation, the factor Δmax is initialized to be δmax, and then it is updated by the following adaption rule.(15)Ifδmax>Δmax,thenΔmax=δmax;otherwise,Δmaxremains unchanged.With this adaption, the factor Δmax can be guaranteed that it is the global maximal factor found so far. Besides, no matter how the population distribution is, at the first generation, the local best position of a particle, pBest, is equal to the initial position of that particle. Then the initial global best position, gBest, could be discovered from those pBest's and therefore is identical to one of them. Since each particle is regarded as a comparative sequence in the proposed approach, the fittest particle gBest is identical to one of the comparative sequences at the first generation. The local minimal factor δmin therefore is equal to zero at that moment. It could further imply that the global minimal factor Δmin also equals zero. Hence, while grey relational analysis is applied to the PSO, the minimal factor can be omitted. Then, according to (1), grey relational coefficient between the fittest particle gBest and the ith particle Xiat the dth dimension can be rewritten as(16)rid=r(gBestd,xid)=ξ⋅Δmaxδid+ξ⋅Δmax,Since Δmax>0, the relational coefficient given in (16) is well defined. The corresponding relational grade is given as(17)gi=g(gBest,Xi)=1D∑d=1Drid,where D represents the dimensions of the solution space. Besides, rid∈[ξ/(1+ξ), 1] and gi∈[ξ/(1+ξ), 1]. They are consistent with the results obtained by grey relational analysis.Generally speaking, the particles may be scattered all over the search space at the early part of the search process. Since the relational grade of each particle may be widely distributed over the range of [ξ/(1+ξ), 1], the average grade would be small at the beginning. However, in the exploitation or convergence state, the swarm tends to gather together and centre around the fittest particle. It is expected that the relational grade of each particle is close or equal to the maximal grade of 1.0. Thus the average grade would be large in the exploitation or convergence state. While all the swarm is converged to the optimal point, the average grade will be equal to the maximal value of one. Therefore, the average relational grade could reveal the evolutionary state of a swarm. Such an average value hereafter is termed the evolutionary factor and the corresponding mathematical representation is(18)fGEA=1N∑i=1Ngi∈ξ1+ξ,1where N is the population size.The evolutionary factor fGEAcan be roughly classified into three states as shown in Fig. 4. Note that the jumping out state does not take into consideration in this case. Also the membership functions given in Fig. 4 are defined for the distinguishing coefficient with the value of 1.0.In order to attain the evolutionary factor, the ESE approach must determine the mean distance of each particle i to all the other particles. For a swarm with a population size of N, the Euclidian distance between two distinct particles must be computed at least N(N−1)/2 times such that the mean distances between every pair of particles in the swarm can be obtained. However, the GEA approach requires computing the distinct relational grades only N times to obtain the evolutionary factor. Consider N=20, D=30 and the system configuration as given in Section 5, the computational time of evolutionary factor required by the ESE approach, in average, is 1.9375 times as long as that required by the GEA approach. As expected, the proposed GEA approach is faster than the ESE approach.In order to reduce the computational load in the PSO search, the proposed GEA-based PSO directly use the value of evolutionary factor fGEAto determine the inertia weight and the acceleration coefficients at each generation. It is unnecessary to classify the evolutionary factor into an evolutionary state with the fuzzy classification method as shown in Fig. 4.Many researches, including the APSO, have suggested that the value of w should be large in the exploration state and small in the exploitation or convergence state [3,10]. The commonly used setting is that the inertia weight is varying from 0.9 to 0.4 over the generations. However, the main disadvantage of this method is that once the inertia weight is decreased, the swarm loses its ability to search new areas because it is not able to recover its exploration mode [27,28]. On the other hand, the inertia weight w could also play the role of a “forgetting factor” which could provide bias towards more recent data thus placing less emphasis on older data. As w approaches zero, the velocity update equation quickly forgets old inputs (i.e., the first part of (3)) and remembers only the most recent inputs (i.e., the second and third parts of (3)) more clearly.Different from the widely used decreasing approach, the proposed GEA-based inertia weight is increasing with the evolutionary factor fGEA. A possible transformation function can be represented as(19)w(fGEA)=0.4,iffGEA<gcenter,11+1.5e−2.6h(fGEA),elsewhere,where h(fGEA)=2(1+ξ)fGEA−(1+2ξ) and gcenter=(1+2ξ)/[2(1+ξ)] which represents the average of the minimal relational grade and the maximal relational grade, i.e., the centre of the range of [ξ/(1+ξ), 1]. By this way, the inertia weight could adapt to the search environment characterized by the evolutionary factor. Fig. 5(a) shows the transformation function for the inertia weight with ξ=1. At this condition, gcenter=0.75. In the figure, if fGEA≥0.75, then w(fGEA)=1/{1+1.5exp[−2.6(4fGEA−3)]}; otherwise, w(fGEA)=0.4.While the evolutionary factor fGEAis smaller than gcenter, the swarm is treated as in the initial state. In this study, the inertia weight is initialized to 0.4. As the evolutionary process is going on, the evolutionary factor fGEAis gradually increasing. The larger the evolutionary factor fGEAis, the larger the inertia weight w is. When fGEAis relatively small in the range of [gcenter, 1], the search process is at the early stage of the search. A small inertia weight is adopted to not only reduce the tendency of the particle to continue in the same direction it has been travelling, but also place more emphasis on directing each particle to the global optimum or its local best position. In addition, a small inertia weight still could allow the particles to move freely to find the global optimum neighbourhood at the beginning of the search. Therefore it can also avoid premature convergence and maintain the diversity of the swarm in the exploration state. On the other hand, when fGEAis relatively large, the search process is at the exploitation or convergence state. The large inertia weight could maintain the tendency of the particle towards the optimal region to help with fast convergence. At this moment, the recent inputs will benefit the local search.The acceleration coefficients c1 and c2 control the movement of each particle towards its individual and global best position, respectively. That is, they are used to balance the global and local search capabilities. Kennedy and Eberhart suggested a fixed value of 2.0 for each coefficient [1], and this setting has been adopted by many other researchers. Rather than a fixed value of 2.0, Ratnaweera et al. proposed the time-varying acceleration coefficients to efficiently control the local search and converge to the global optimum solution [11]. They suggested that, with a large cognitive component and a small social component at the beginning, particles are allowed to move around the search space, instead of moving towards the population best. Besides, a small cognitive component and a large social component allow the particles to converge the global optima in the latter part of the search.The central idea of the proposed GEA-based acceleration coefficients is based on the concept of the above time-varying approach. Besides, the sum of two acceleration coefficients is fixed at the value of 4.0, i.e., c1+c2=4.0. According to the suggestion given in [11], c1 must be large than c2 at the early stage of the search. In this study, c1 and c2 are initialized to 2.5 and 1.5, respectively. When the swarm is in the initial state (i.e., fGEA<gcenter), the acceleration coefficients c1 and c2 are remained at the corresponding initial values. However, when fGEA≥gcenter, c1 is monotonically decreasing with fGEAbut c2 is monotonically increasing. That is, the GEA-based acceleration coefficients could also adapt to the search environment characterized by the evolutionary factor. In the exploration state, a larger c1 and a smaller c2 could help for exploring local optimums and maintaining the diversity of the swarm. In the exploitation or convergence state, a smaller c1 and a larger c2 could allow the particles to converge to the global optimum.On the basis of the above central idea, a possible transformation function for c1 can be represented as(20)c1(fGEA)=2.5,iffGEA<gcenter,2+0.5cos[h(fGEA)π],elsewhere.where h(fGEA)=2(1+ξ)fGEA−(1+2ξ) and gcenter=(1+2ξ)/[2(1+ξ)]. Once c1 is determined, c2 can be obtained by(21)c2=4.0−c1.Fig. 5(b) shows the transformation function for the acceleration coefficients with ξ=1. In the figure, if fGEA≥0.75, then c1(fGEA)=2+0.5cos[(4fGEA−3)π]; otherwise, c1(fGEA)=2.5.The following procedure can be used for implementing the proposed GEA-based PSO algorithm.(1)Initialize the swarm by assigning a random position and the corresponding velocity vector to each particle. Also determine the necessary parameters such as the grey distinguishing coefficient ξ and the maximum number of generations T.Evaluate the fitness value for each particle.Update the best position for each particle pBest and the global best position gBest.Update the global maximal factor Δmax by (15).Calculate the grey relational grade of each particle i using (16) and (17).Compute the evolutionary factor fGEAby (18).Determine the inertia weight by (19) and the acceleration coefficients by (20) and (21).Update the velocities and positions of all particles using (3) and (4).Repeat steps 2–8 until a stopping criterion is fulfilled (e.g., the maximum number of generations or the goal is reached).In order to demonstrate the search performance of the proposed GEA-based PSO algorithm, twelve benchmark test functions selected from [9,25] are used to verify it. The GEA-based PSO (GEA-PSO) is also compared with the APSO [3], the grey PSO [25], and two well-known PSO algorithms, PSO-LVIW [10], and HPSO-TVAC [11]. As mentioned in [3], the APSO generally outperforms the comprehensive-learning PSO (CLPSO) [9], the dynamic multi-swarm PSO (DMS-PSO) [18], the von Neumann topological structure PSO (VPSO) [21], and the “fully informed particle swarm” (FIPS) algorithm [29] on most of test functions. Therefore the detail numerical results and convergence characteristics of those four variants of PSO are not shown in this study.The following 12 benchmark functions are used to test the search performance of the proposed algorithm. Note that the first six functions are unimodal and the rest are multimodal. The corresponding dimensions, search spaces, global optimum values, and acceptance levels of the test functions are listed in Table 1.(1)Sphere model:f1(X)=∑i=1Dxi2.Schwefel's problem 2.22:f2(X)=∑i=1D|xi|+∏i=1D|xi|.Schwefel's problem 1.2:f3(X)=∑i=1D∑j=1ixj2.Generalized Rosenbrock's function:f4(X)=∑i=1D−1[100(xi+1−xi2)2+(xi−1)2].Step function:f5(X)=∑i=1D(xi+0.5)2.Quartic function, i.e., noise:f6(X)=∑i=1Dixi4+random[0,1).Generalized Schwefel's problem 2.26:f7(X)=−∑i=1Dxisin|xi|.Generalized Rastrigin's function:f8(X)=∑i=1D[xi2−10cos(2πxi)+10].Discontinuous Rastrigin's function:f9(X)=∑i=1D[yi2−10cos(2πyi)+10],whereyi=xi,|xi|<0.5,round(2xi)/2,|xi|≥0.5.Ackley's function:f10(X)=−20exp−0.21D∑i=1Dxi2−exp1D∑i=1Dcos(2πxi)+20+eGeneralized Griewank function:f11(X)=∑i=1Dxi24000−∏i=1Dcosxii+1.Generalized Penalized function:f12(X)=π3010sin2(πy1)+∑i=1D−1(yi−1)2[1+10sin2(πyi+1)]+(yD−1)2+∑i=1Du(xi,5,100,4),where yi=1+(1/4)(xi+1) andu(xi,a,k,m)=k(xi−a)m,xi>a,0,−a≤xi≤a,k(−xi−a)m,xi<−a.In the simulations, all the PSO algorithms were tested using the same population size of 20, a value of which is widely adopted in PSO [3,25]. In order to reduce the statistical errors, each algorithm was run 30 independent trials on every test function with the same maximum number of generations, i.e., T=10,000, for each trial and their mean results are used in the comparison. As for the APSO, the inertia weight is initialized to 0.9, and c1 and c2 to 2.0. Those setting are the same as the initialization given in [3]. As for the PSO-LVIW, the inertia weight was set to change from 0.9 (wmax) to 0.4 (wmin) over the generations. The boundary values of acceleration coefficients for the HPSO-TVAC were set as c1,0=2.5, c1,f=0.5, c2,0=0.5, and c2,f=2.5, which are the best ranges for c1 and c2 suggested in [11]. The best algorithm configuration of the grey PSO given in [25] is represented as follows. The maximal and minimal inertia weights were respectively set as wmax=0.9 and wmin=0.4. The boundary values for the acceleration coefficient c2 were cmin=1.5 and cmax=2.5. In addition, the distinguishing coefficient was set as ξ=1.0 and the weighting factor was αk=1/D for k=1, 2, …, D. The last two parameters are also utilized in the proposed GEA-based PSO.All the programs coded by Matlab version R14 were executed by a personal computer with Intel Pentium Dual CPU @ 1.60-GHz processor, 2.0-GB RAM, and Windows XP2 operating system.The search behaviours of the proposed GEA-based PSO herein are investigated only on the Sphere model f1 (a unimodal function) and the generalized Rastrigin's function f8 (a multimodal function). Figs. 6 and 7depict the corresponding search behaviours. Roughly speaking, those two figures are similar to each other. Also it can be seen from Figs. 6(a) and 7(a) that the evolutionary factor starts from about 0.78, and then rapidly increases to 0.88 at about the 10th generation. Then the rate of rise is slowed down and the factor reaches about 0.92 at the end of the 50th generation. After the 50th generation, the evolutionary factor will slightly increase to 0.95 as shown in Figs. 6(b) and 7(b). Fig. 4 has demonstrated how to roughly classify the evolutionary factor into three states. According to the figure, the PSO would be in the state of exploration during the first 10 generations, and then lead into the exploitation phase in the subsequent 40 generations. Finally, the PSO stands in the convergence state after the 50th generation.At each generation, the GEA-based inertia weight and acceleration coefficients are dependent upon the evolutionary factor which involves the information of population distribution. Therefore those algorithm parameters could adapt to the evolutionary state. The inertia weight shown in Figs. 6(c), (d) and 7(c), (d) confirms that the GEA-based PSO maintains a small w in the exploration state and a large w in the exploitation and convergence states. Figs. 6(e), (f) and 7(e), (f) also show good agreement with the central idea of the GEA-based acceleration coefficients. It can be seen that c1 decreases and c2 increases with the evolutionary factor. In the exploration state, c1 is large than c2. However, in the exploitation or convergence state, c1 becomes small than c2. Besides, while the transformation functions (19) and (20) could be properly determined in advance, the GEA-based PSO can perform a global search over the entire search space with faster convergence speed.Fig. 8shows the convergence characteristics of the evolutionary processes for each PSO algorithm in solving all the test functions. Each curve represents the variation of mean fitness over the generations for a specific PSO. The terminal point of a curve which does not terminate at the 10,000th generation (see functions f1, f2, f3, f5, f8, f9, and f11) represents that all the 30 independent trials of such a specific PSO could achieve the global optimum before the corresponding number of generations. In addition, on functions f1, f2, f8, and f9, the final mean fitness obtained by the APSO is much smaller than that obtained by the PSO-LVIW and HPSO-TVAC. Therefore those exactly final values are given in the corresponding figures.Table 2lists the detail performance on the solution accuracy of each PSO, where the performance is measured in terms of the means and standard deviations of the solutions obtained by 30 independent runs. Boldface in the table indicates the best result(s) among the algorithms. As can be seen, all the PSO algorithms can attain the minimum value of f5. The main reason is that it is a region rather than a single point in f5 that is the optimum. As far as other unimodal functions are concerned, the GEA-based PSO can attain the best accuracy on functions f1, f2, f3, and f6, and rank the second on f4, whereas the APSO has the highest accuracy only on function f4. As for the complex multimodal functions, the GEA-based PSO could also achieve the best accuracy on functions f8, f9, f10, and f11. However, the proposed PSO performs the second best on f7 and rank the third on f12. On those two functions, the APSO could attain the best accuracy. To sum up, except on function f5, the GEA-based PSO can attain the best accuracy on 8 out of 11 functions, while the APSO only on 3 functions. It can conclude that the GEA-based PSO surpasses the APSO and our previous work, the grey PSO [25], on the solution accuracy.Table 3lists the comparisons on the convergence speed of each PSO in terms of the mean number of generations needed to reach an acceptance solution given in Table 1 and the corresponding mean computational time. The APSO attains the smallest mean number of generations on functions f7, f8, and f9, while the GEA-based PSO on the rest 9 functions. However, a shorter evolutionary process cannot imply that it uses a lesser computational time. Many existing PSO variants, including the APSO, grey PSO, and GEA-based PSO, have added extra operations that cost the computational time. As seen in Table 3, the HPSO-TVAC uses the least computational time on f7, whereas the grey PSO costs the shortest time on f8, and f9. The proposed GEA-based PSO could attain the least computational time on other 9 functions. Although the APSO uses the smallest mean number of generations on f7, f8, and f9, it is not the fastest algorithm on those three functions.Based on the final search results of 30 independent trials on every function, Table 4presents the t values and the P values on every function of the two-tailed test with the 5% level of significance between the GEA-based PSO and another PSO variant. In the table, rows “+1 (better),” “0 (same),” and “−1 (worse)” represents the number of functions that the GEA-based PSO performs significantly better than, almost the same as, and significantly worse than the compared algorithm, respectively. Row “General merit” gives the difference between the number of +1's and the number of −1's, which is used to show an overall comparing between the two algorithms. Take the comparison between the GEA-based PSO and the APSO for instance. The former significantly outperformed the latter on three functions (f6, f10, and f11), does as better as the latter on six functions (f1, f2, f3, f5, f8, and f9), and does worse than on three functions (f4, f7, and f12). That yields a “General merit” figure of merit of 3−3=0, indicating the GEA-based PSO generally performs almost the same as the APSO on the solution accuracy. Although the GEA-based PSO performed slightly weaker on some functions, Table 4 also reveals that it generally outperforms the PSO-LVIW, HPSO-TVAC, and grey PSO.Take the solution accuracy (Table 2) and the convergence speed (Table 3) into consideration simultaneously. The GEA-based PSO outperforms the PSO-LVIW, HPSO-TVAC, APSO, and grey PSO on seven out of twelve test functions (f1, f2, f3, f5, f6, f10, and f11). On the rest five functions, those five PSO variants cannot simultaneously attain the best solution accuracy and the fastest convergence speed. For example, the APSO can attain the best accuracy on functions f4, f7, and f12, whereas the grey PSO and GEA-based PSO on f8 and f9. However, the GEA-based PSO has the least computational time on f4 and f12, while the HPSO-TVAC on f7 and the grey PSO on f8 and f9. Besides, the PSO-LVIW generally performs the worst results on the convergence speed as well as the solution accuracy.To sum up, the GEA-based PSO outperforms the APSO, grey PSO, HPSO-TVAC, and PSO-LVIW on the solution accuracy and computational time in most of the considered problems. The fact also reveals that the GEA-based inertia weight and acceleration coefficients could provide global search and deliver faster convergence for the search process.There are two main parameters in grey relational analysis. One is the weighting factor αkand the other is the distinguishing coefficient ξ. In the function optimization problems, each element (dimension) of a particle generally has the identical degree of weightiness. This study therefore adopts the equi-weighting scheme, i.e., αk=1/D for all k's, in the simulations. If the weightiness of each dimension could be obtained in advance, every weighting factor can be determined according to the corresponding weightiness. On the other hand, the distinguishing coefficient is used to control the resolution between Δmax and Δmin. It can affect the magnitude of grey relational grade, that is, gi∈[ξ/(1+ξ), 1] for ξ∈(0, 1]. Theoretically, a smaller distinguishing coefficient will result in a wider distributing range for the grey relational grade. However, the fact cannot guarantee that it will have a better result on the search problems. Generally speaking, the value of distinguishing coefficient is suggested around 0.5 or about 1.0 [25].Table 5demonstrates the search result comparisons for different distinguishing coefficients. In the table, the performance is also measured in terms of the means and standard deviations of the solutions obtained by 30 independent runs. Boldface and italic font indicates that the GEA-based PSO with the corresponding distinguishing coefficient performs better than or equal to the PSO-LVIW, HPSO-TVAC, APSO and grey PSO. Except that ξ=0.10 and 0.15 on f8 and ξ=0.05 on f9, all the distinguishing coefficients can attain the same search result on functions f1, f2, f3, f5, f8, f9, f10, and f11.On the rest four functions, different coefficients generally yield similar results on the identical function. That is to say, the distinguishing coefficient does not heavily affect the solution accuracy of the proposed GEA-based PSO. Generally speaking, the GEA-based PSO with any distinguishing coefficient could outperform the PSO-LVIW, HPSO-TVAC, APSO and grey PSO on nine out of twelve test functions (i.e., f1, f2, f3, f5, f6, f8, f9, f10, and f11).Table 6shows the comparisons on the convergence speed for different distinguishing coefficients in terms of the mean number of generations and the corresponding mean computational time. Boldface and italic font represents that the GEA-based PSO with the corresponding distinguishing coefficient could converge faster than the PSO-LVIW, HPSO-TVAC, APSO and grey PSO. Besides, symbols “+”, “x”, and “≈” denote that the convergence speed of the corresponding distinguishing coefficient is faster than, slower than, and similar to that with the distinguishing coefficient of 1.00, respectively. It can be identified from Table 6 that the distinguishing coefficient of 1.00 performs the fastest speed. Therefore it can conclude that the distinguishing coefficient of 1.00 is the best setting for the proposed algorithm. That is the main reason why the distinguishing coefficient was set as ξ=1.0 in the initial parameter setting of the proposed GEA-based PSO.

@&#CONCLUSIONS@&#
With the help of grey relational analysis, this study has developed the grey evolutionary analysis for the PSO so as to evaluate the evolutionary state of a swarm. In addition, two GEA-based parameter automation approaches were proposed to enable the inertia weight and acceleration coefficients to adapt to the evolutionary state. Those two approaches would improve the search efficiency and hasten the convergence speed. From the results of empirical simulations with twelve of the well-known benchmarks, the GEA-based PSO outperforms the APSO, grey PSO, HPSO-TVAC, and PSO-LVIW on the solution accuracy and computational time in most of the considered problems. The fact also reveals that the proposed GEA-based PSO would perform a global search over the search space with faster convergence speed, owing to the algorithm parameters that utilize the information of grey evolutionary analysis.