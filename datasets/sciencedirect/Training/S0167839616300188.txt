@&#MAIN-TITLE@&#
Revisiting the problem of zeros of univariate scalar Béziers

@&#HIGHLIGHTS@&#
A fast algorithm for computing roots of univariate scalar Béziers is proposed.A speed-up of about an order-of-magnitude is gained compared to previous methods.The proposed algorithm has the ability to count multiplicities of roots.

@&#KEYPHRASES@&#
Polynomial roots,Bézier polynomials,Subdivision,Numerical method,Newton–Raphson, polynomial division,

@&#ABSTRACT@&#
This paper proposes a fast algorithm for computing the real roots of univariate polynomials given in the Bernstein basis. Traditionally, the polynomial is subdivided until a root can be isolated. In contrast, herein we aim to find a root only to subdivide the polynomial at the root. This subdivision based algorithm exploits the property that the Bézier curves interpolate the end-points of their control polygons. Upon subdivision at the root, both resulting curves contain the root at one of their end-points, and hence contain a vanishing coefficient that is factored out. The algorithm then recurses on the new sub-curves, now of lower degree, yielding a computational efficiency. In addition, the proposed algorithm has the ability to efficiently count the multiplicities of the roots. Comparison of running times against the state-of-the-art on thousands of polynomials shows an improvement of about an order-of-magnitude.The problem of numerically finding zeros of univariate polynomials is ubiquitous in computer aided design (Cohen et al., 2001) and engineering. Many geometric problems can be cast into that of finding zeros of polynomials, for instance, computing intersections of curves and surfaces (Sederberg and Meyers, 1988; Sederberg and Parry, 1986), contact analysis of shapes (Kim et al., 2014), kinematic analysis (Bartoň et al., 2009), etc. There have been many approaches to the problem of computing zeros of univariate polynomials in the past (Isaacson and Keller, 1966; McNamee, 1990), such as, based on Newton's method (Grandine, 1989), using Descartes' rule of signs (Eigenwillig et al., 2006; Krandick and Mehlhorn, 2006; Rouillier and Zimmermann, 2004), based on subdivision (Gopalsamy et al., 1991; Mourrain and Pavone, 2009), to name a few.In this work, we use the Bernstein representation for polynomials. Bernstein polynomials have several useful properties such as the variation diminishing property, the convex hull property and numerical stability with respect to perturbation of coefficients (Farouki and Rajan, 1987), which makes such a representation especially amenable for numerical applications.One of the earliest methods to exploit the variation diminishing property of Bézier curves in order to isolate the roots of polynomials was given by Lane and Riesenfeld (1981). In 1990, Sederberg and Nishita (1990) proposed the technique of Bézier clipping for identifying regions of the domain which contain roots. This was done by intersecting the convex hull of the control polygon with the zero axis. In 2007, Bartoň and Jüttler (2007) improved the technique of Bézier clipping using degree reduction to generate a strip bounded by two quadratic polynomials, which encloses the graph of the input polynomial. This strip, when intersected with the zero axis, gives the new interval potentially containing the roots. This approach, that is also known as quadratic clipping, was shown to have quadratic convergence by Schulz (2009). In 2009, Liu et al. (2009) improved quadratic clipping by using cubic polynomials, yielding faster rates of convergence. In 2007, Mørken and Reimers (2007) utilized the close relationship between the spline and its control polygon for computing zeros of polynomials. They use the zeros of the control polygon as an initial guess for tracing the zeros of the polynomial. The control polygon is iteratively refined until the roots are found. In 2013, Ko and Kim (2013) used bounding polygons to reduce the intervals containing roots of Bézier polynomials. A hybrid of the convex hull, sharp bounds (Nairn et al., 2006) and quasi-interpolating bounds (Zhang and Wang, 2006) was used to refine the intervals. Recently, in 2015, Chen et al. (2015) improved the convergence rates achieved by Liu et al. (2009) by bounding the polynomial of interest by a pair of rational cubic polynomials.Our approach, as explained in Section 1.1 uses the fact that polynomials represented in the Bernstein–Bézier form admit efficient algorithms for polynomial multiplication and division (Buse and Goldman, 2007; Goldman, 2002). These are employed to factor out the roots already computed, thus reducing the degree of the polynomial, as part of the solution process.We now give an overview of our method, which exploits several properties of the Bézier curves, for computing zeros of scalar polynomials. The Bernstein basis for an n-degree univariate polynomial is given by the set of functionsθi,n(t)=(ni)ti(1−t)n−i,t∈[0,1], fori=0,…,n. A degree n scalar polynomial in the Bernstein basis is expressed asc(t)=∑i=0npiθi,n(t)where,pi∈Rare the real coefficients of the polynomial. Whilec(t)may have roots outside the domain[0,1], in this paper we focus on finding the real roots ofc(t)in[0,1]. Throughout this paper, we will consider[0,1]to be the domain of definition of all Bézier curves, unless stated otherwise.We will exploit the fact that the Bézier curves interpolate the end-points of their control polygon. Upon finding a root,t0, our algorithm subdividesc(t)att0. Letcl(t)andcr(t)denote the resulting polynomials corresponding to the sub-intervals[0,t0]and[t0,1], respectively, with their domains again mapped to[0,1]. Clearly,cl(t)andcr(t)vanish at 1 and 0, respectively. Since the Bézier curves interpolate the end-points of their control polygon, it follows that the last coefficient ofcl(t)and the first coefficient ofcr(t)are zero.cl(t)may be expressed as(1−t)cL(t)for some Bernstein polynomialcL(t)having one degree less thancl(t). Similarly,cr(t)may be written astcR(t)for some Bernstein polynomialcR(t)with one degree less thancr(t). Factoring out the terms(1−t)and t fromcl(t)andcr(t), respectively (Buse and Goldman, 2007), eliminates the roott0from these two polynomials, yielding polynomials with smaller degrees to recurse upon that preserves all roots butt0, thus giving a computational boost to the algorithm. This is explained schematically in Fig. 1. The graph of polynomialc(t)is shown in red, in Fig. 1(a), along with its control polygon that is shown in green.c(t)has two real roots, att1andt2. Assume we found the root att2. Fig. 1(b) shows the subdivided polynomialscl(t)andcr(t)respectively, both containing the root,t2, at the respective end-point of their domains, and hence have a vanishing coefficient there. Fig. 1(c) shows the lower degree polynomials obtained after factoring out(1−t)and t fromcl(t)andcr(t), respectively.The rest of this paper is organized as follows. Our basic algorithm is explained in Section 2. An interesting efficient feature of our approach to count the multiplicities of roots, along with two more extensions of the algorithm are given in Section 3. One extension lets the search for roots go outside the domain of interest, and another initializes the Newton–Raphson method with better calculated seeds compared to the basic algorithm. We compare the running times of our implementation of the algorithm with those of the state-of-the-art alternatives, on thousands of polynomials. The results of the comparison, as given in Section 4, show an improvement of about an order-of-magnitude. Finally, we conclude the paper, in Section 5, with remarks on future work.In this section, we explain our algorithm for finding the real roots of univariate scalar polynomials, given in Bernstein form. The proposed algorithm is based on subdivisions at detected roots.As explained in Section 1.1, the proposed algorithm achieves a reduction in the complexity of the problem by factoring out all the roots that are already found. A scalar Bernstein polynomialc(t)of degree n withc(0)=0may be expressed asc(t)=tr(t), for some Bernstein polynomialr(t)with degreen−1(Buse and Goldman, 2007). The coefficients ofr(t)are obtained from those ofc(t)asqi=pi+1ni+1, fori=0,…,n−1. The proof appears in Lemma 1, for completeness:Lemma 1A degree n scalar Bernstein polynomialc(t)=∑i=0npiθi,nsuch thatc(0)=0can be written asc(t)=t∑i=0n−1qiθi,n−1=tr(t), where,qi=pi+1ni+1fori=0,…,n−1.ProofSincec(0)=0, the first coefficient,p0, is zero, and we have,c(t)=∑i=0npi(ni)ti(1−t)n−i,=∑i=1npi(ni)ti(1−t)n−i,=t∑i=1npi(ni)ti−1(1−t)n−i,=t∑i=0n−1pi+1(ni+1)ti(1−t)n−i−1,=t∑i=0n−1pi+1ni+1(n−1i)ti(1−t)n−i−1,=t∑i=0n−1qiθi,n−1(t),=tr(t),whereqi=pi+1ni+1, fori=0,…,n−1, are the coefficients of the scalar Bernstein polynomialr(t)having degreen−1. □Clearly, the term t can be factored out fromc(t)in linear time with respect to the number of coefficients inc(t). In a similar way, a degree n scalar Bernstein polynomialc(t)withc(1)=0may be expressed as(1−t)s(t), for some scalar Bernstein polynomials(t)with degreen−1, whose coefficients are obtained from those ofc(t)aspinn−ifori=0,…,n−1. The proof is similar to that given in Lemma 1. More importantly, the following holds:Remark 2Let the set of real roots ofc(t)beRcandc(0)=0. Then,Rc=Rr∪{0},where,c(t)=tr(t)andRris the set of real roots ofr(t).In other words, the set of real roots ofr(t)identifies with the roots ofc(t)up to the root at zero and hence, we can continue working withr(t)instead ofc(t), without missing any root, but in a reduced complexity. A similar remark holds for a polynomialc(t)withc(1)=0.As a first step, our algorithm employs a sufficient condition for discarding sub-domains which do not contain roots, by inspecting the signs of the coefficients ofc(t). If they are either all positive or all negative, the sub-domain does not contain roots and is purged. This follows from the convex-hull property of the Bézier curves.If the domain is not discarded, an attempt is made to find a root in the current domain, numerically. We employ the Newton–Raphson method, which is known to have a quadratic rate of convergence (Isaacson and Keller, 1966), for this purpose and use an initial guess of 0.5 as an initial seed value. Upon successful finding of a root,t0, the polynomialc(t)is subdivided att0. As explained previously, both curves resulting from the subdivision ofc(t)contain the root,t0, at the respective end-points of their domains. The root att0is factored out from these two new curves and the resulting lower degree polynomials are recursed upon. Alternatively, if no root is found by the numeric step,c(t)is subdivided in the middle of the domain and the resulting polynomials are recursed upon. The stopping criteria for the Newton–Raphson method is either a divergent step, or the search going outside the domain, or the number of iterations exceeding a limit, 100 in our case (a case that never occurred in all our tests).Our method is summarized in Algorithm 1. The test for absence of roots (all coefficients positive or all negative) is performed by the routine PurgeProblem in Line 1 of Algorithm 1. The Newton–Raphson method is invoked in Line 4 by the routine NumericStep, with the mid-point (0.5) of the domain as the starting seed. The case when a root is found by NumericStep is handled in Lines 6 to 9 while the case when no root is found is executed in Lines 14 to 16. Note that we assume the curves are always within domain[0,1]. Yet, we keep track of the real domain by propagating the[tmin,tmax]values.Algorithm 1 uses two tolerances, the numeric tolerance, ϵ, and the subdivision tolerance, δ. The roots are searched up to ϵ, i.e., for each root,t0, returned,−ϵ<c(t0)<ϵ, while the minimal width of the domain of any subdivided curve, to be considered by our algorithm, is set by δ. The termination of Algorithm 1 stems from looking at its two sub-cases. If a root is found by the numeric step, the algorithm recurses upon two sub-polynomials of one degree less. If no root is found by the numeric step, the algorithm recurses on two polynomials, each with domain width half that of the original polynomial. Hence, the algorithm terminates when either one of the following conditions holds: (i) the width of the problem domain[tmin,tmax]falls below the subdivision tolerance, or (ii) the control polygon ofc(t)does not cross the t-axis, or (iii) the degree ofc(t)is one.We now consider several extensions of the basic algorithm from Section 2. In Section 3.1, we present an extension for counting the multiplicities of roots. In Section 3.2, we consider an alternative method of initializing the Newton–Raphson method and in Section 3.3, we portray an extended framework which lets the search for roots go outside the domain of interest.The extended ability to count the multiplicities of roots is naturally supported by our computational framework. Each time a root is factored out, the terminal coefficient of the resulting polynomial is inspected again. A vanishing coefficient, again after an elimination of t or(1−t), implies that the root is repeated. Hence, counting multiplicities is reduced to the examination of a single (terminal) scalar coefficient ofcr(t)to be zero, and hence, is highly efficient. This is demonstrated schematically in Fig. 2for a double root. The pseudo-code for counting multiplicities of roots is given in Algorithm 2which replaces Lines 7 and 8 in Algorithm 1. Herein,m0is the desired root multiplicity. For clarity, both input and output curves are designated asclandcrin Algorithm 2 (againstcLandcRin Algorithm 1) due to the recursive computation. This extended ability is examined in Section 4. Note that, the Newton–Raphson method converges linearly to a root with multiplicity greater than one (Isaacson and Keller, 1966).It is known that the control polygon of a Bézier curve is an approximation of the curve itself. One can compute the intersection of the control polygon ofc(t)with the t-axis, in order to supply a better initial value for the Newton–Raphson method, following Mørken and Reimers (2007). Due to the variation diminishing property, the number of intersections of the control polygon with the t-axis is greater than or equal to the number of real roots ofc(t). In this extension option, we examined both the first intersection point as well as the intersection point closest to the mid-point of the domain, between the control polygon and the t-axis. The potential computational benefits of both alternative initializations of the Newton–Raphson method are examined in Section 4.Consider letting the Newton–Raphson search for roots go outside the domain,[0,1], of interest. If such a root is found, it can still be factored out, thus, reducing the degree of the problem. If a root,t0>1, is found, the input polynomialc(t)is subdivided att0to obtain a polynomial,cl, corresponding to the domain[0,t0]and a polynomial,cdcorresponding to the domain[1,t0]. The polynomialcdis immediately discarded, being outside the domain[0,1]. Clearly,cl(1)=c(t0)=0, and as before, the factor(1−t)is removed fromcl. However, hereinclis again subdivided at1t0to bringclback to the original[0,1]domain. A similar sequence of steps are followed when the root is found below zero,t0<0. The potential benefits of this possible extension are also discussed in Section 4.

@&#INTRODUCTION@&#


@&#CONCLUSIONS@&#
