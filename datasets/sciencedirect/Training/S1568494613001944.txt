@&#MAIN-TITLE@&#
A space search optimization algorithm with accelerated convergence strategies

@&#HIGHLIGHTS@&#
We propose a space search evolutionary algorithm with accelerated convergence strategies.The overall framework of the SSEA involves three main search mechanisms.Local space search, global space search, and opposition-based search are handled.Accuracy and speed of convergence are shown especially in case of high-dimensional continuous optimization problems.

@&#KEYPHRASES@&#
Space search optimization algorithm (SSOA),Local and global space search,Simplex method,Cauchy mutation,Opposition-based search,

@&#ABSTRACT@&#
Evolutionary algorithms (EAs), which have been widely used to solve various scientific and engineering optimization problems, are essentially stochastic search algorithms operating in the overall solution space. However, such random search mechanism may lead to some disadvantages such as a long computing time and premature convergence. In this study, we propose a space search optimization algorithm (SSOA) with accelerated convergence strategies to alleviate the drawbacks of the purely random search mechanism. The overall framework of the SSOA involves three main search mechanisms: local space search, global space search, and opposition-based search. The local space search that aims to form new solutions approaching the local optimum is realized based on the concept of augmented simplex method, which exhibits significant search abilities realized in some local space. The global space search is completed by Cauchy searching, where the approach itself is based on the Cauchy mutation. This operation can help the method avoid of being trapped in local optima and in this way alleviate premature convergence. An opposition-based search is exploited to accelerate the convergence of space search. This operator can effectively reduce a substantial computational overhead encountered in evolutionary algorithms (EAs). With the use of them SSOA realizes an effective search process. To evaluate the performance of the method, the proposed SSOA is contrasted with a method of differential evolution (DE), which is a well-known space concept-based evolutionary algorithm. When tested against benchmark functions, the SSOA exhibits a competitive performance vis-a-vis performance of some other competitive schemes of differential evolution in terms of accuracy and speed of convergence, especially in case of high-dimensional continuous optimization problems.

@&#INTRODUCTION@&#
Over the past decade, optimization techniques have been widely utilized in many fields of engineering, sciences, management, and social sciences. Many successful applications of the optimization techniques have been reported, ranging from music composition [1] to financial forecasting [2], aircraft design [3], job-shop scheduling [4], and drug design [5]. Among them, highly successful are evolution algorithms (EAs) [6–8], which is a subfield of artificial intelligence involving continuous optimization and combinatorial optimization. Generally, EAs are mostly applied for solving the optimization problems within context of expensive optimization. One can refer here to numerous evolutionary algorithms, such as genetic algorithms (GAs) [9–10], particle swarm optimization (PSO) [11–14], genetic programming (GP) [15–17], evolutionary programming (EP) [18,19], and evolutionary strategies (ES) [20,21].There have been a series of studies developing adaptive heuristic algorithms based on the space search concept such as differential evolution (DE) [22–26] and memetic evolution (ME) [27,28]. In these algorithms, the operators of crossover and mutation generate new solutions (offsprings) according to the concept of solution space. However, both bio-inspired and space-based evolutionary algorithms are essentially stochastic search techniques realized for the entire solution space. Such random mechanism leads to the following drawbacks:(1)Long computing time. Generally, because of their stochastic nature [24] all population-based optimization algorithms suffer from long computing times. This crucial drawback sometimes limits their applicability making them become suitable to deal with offline problems with little or no real-time constraints [25].Premature convergence. Purely random resampling or selections of solutions from a given population may lead to revisiting non-productive regions of the search space. In fact, most of EAs may suffer from premature convergence.When dealing with some complex problems. In many real-world applications, finding the global optimum may not be practical or even possible.In this study, we propose a space search optimization algorithm (SSOA), which employs an augmented simplex method and opposition-based learning to alleviate limitations of the purely random mechanism that is commonly used in most of EAs. The augmented simplex method is used to speed up the convergence in the local space search, while the opposition-based learning is exploited to accelerate the convergence in the global space search. The SSOA is essentially an evolutionary algorithm, which is inspired by the space search mechanisms. Two operators based on space search mechanism are developed, namely local space search and global space search (Cauchy mutation). Local space search technique that is essentially a fast method with strong search abilities expressed in local space can reduce the long computational time to some extent when implementing the local space search. The global space search is realized with the aid of Cauchy searching, where the approach itself is based on the Cauchy mutation that can help the trapped solutions escape from local optima. Moreover, opposition-based learning employs a so-called “opposite numbers” mechanism to speed up the convergence of an optimization algorithm. Actually, a proof has been reported to show that opposite numbers are more likely to be closer to the optimal solution than those that are purely random [25]. 19 well-known benchmark functions are included to evaluate the performance of the proposed SSOA. They are also contrasted with the performance of DE reported in the literature.The paper is structured as follows. Section 2 provides a description of the SSOA used for solving the optimization problems. The methodologies of local space search, global space search, and opposition-based search are introduced. Section 3 reports on a comprehensive set of experiments. A set of comparative studies between SSOA and suites of DEs is presented. Finally, concluding remarks are covered in Section 4.We consider an optimization problem coming in the following form:(1)Minimizef(x1,x2,…,xn)st:xi∈[1i,ui]i=1,2,…,nwhere liand uidenote the lower and upper bounds of the corresponding variables while n is the number of the initial vertices. For convenience, the population of SSOA is called a solution set and each individual in the population is called a solution.To illustrate the underlying idea of SSOA, let us consider a certain adaptive heuristic search algorithm consisting of the following main steps:(1)Randomly generate a set of feasible solutions with even distribution in the entire solution space.Generate new solutions (offsprings) according the current solution set.Update the current solution set; if the termination condition has not been satisfied, go to step 2.Report the optimal solution.Fig. 1visualizes a process of traversing the search space realized during successive generations of the algorithm. In the consecutive generations, the current solutions are constantly updated by the new solutions, which are positioned closer to the global optimum. At the same time, the search space based on the current solutions becomes smaller. After several generations, the current solutions finally converge to the same global optimum and the corresponding search space contracts to a single point. An underlying problem of the method is to determine a suitable update mechanism.Unfortunately, even if we had developed an effective mechanism, which can form the current solutions approaching the global optimum, a problem remains open. We have to consider the other case that the current solutions may finally arrive at a local rather than a global optimum, as illustrated in Fig. 2.Hence, a suitable heuristics guiding the search algorithm should address the following issues:(1)How to form new solutions approaching the global optimum.How to achieve the global optimum rather than the local one.With these problems in mind, we develop a space search optimization algorithm involving two basic strategies, namely the local space search and global space search. The objective of the local space search is to form new solutions approaching the local optimum, while the global space search is aimed at achieving global rather than a local optimum.Before designing the space search operators, let us remark why an evolutionary algorithm (e.g., DE) can find the optimal solution. It is well known that DE updates the solutions, which are closer to the global optimum one is looking for. If the solutions around the global optimum have the same values of fitness in the local area, as shown in Fig. 3(a), it becomes difficult to update the new solutions which are closer to the global optimum. In this case, DE is not well suited to handle the optimization problem. Therefore, a certain precondition has to be met which makes the problem amenable to be solved by the DE. This precondition is that in most of the local areas, a point (solution) and the other points located in the point's adjacent space have different fitness values, and the fitness value of the solution depends on the distance from the optimal solution. In other words, in most of the local areas, a solution with better fitness is closer to the optimal solution; refer to Fig. 3(b).By taking this observation in account, we introduce a space search mechanism, which is used to update the current solutions and construct the local space search operator. The role of the space search is to generate new solutions from the old ones. The search method is based on the local search operator, which realizes two generic steps: (a) generates a new subspace (local area) and (b) realizes a search of the new space. The search completed in this new space is realized randomly by generating a new solution located in this space. With regard to the generation of the new space, we consider two cases: (a) space search based on M selected solutions (denoted here as Case I), and (b) space search based on a single selected solution (Case II).In Case I, the new subspace (local area) is generated by M selected solutions (individuals). The essential development issue is how to determine the adjacent space based on the M solutions. For convenience, a solution X can be presented in another way: X=(x1, x2, …, xn), where n is the dimension of the solution. Regarding the M solutions, we use the following representation:Xk=(x1k,x2k,…,xnk),k=1,2,…,M. SupposeLi=minj=1Mxij,Ui=maxj=1Mxijdenote the minimum and maximum as lmin, umax of these M solutions. To adjust the size of the new generating subspace, we use a coefficient λ as a proportion parameter, where λ is a given positive number. The adjacent space based on M solutions is given in the following form:(2.1)V1={(x1,x2,…,xn)|xi∈[li,ui]∩[Li−λ(Ui−Li),Li+λ(Ui−Li)],i=1,2,…,n}In Case II, the space search operation is based on a given solution, which is the best solution in the current solution set (population). The role of this operator is to adjust the best solution for overcoming premature to some extent. Assume that the best solution in the current solution set is denoted byXbest=(xibest,x2best,…xnbest), wherexibest∈[li,ui],i=1,2,…,n. We generate the new space V to be in the form:(2.2)V2={Xnew|Xnew=(x1best,x2best,…,xi−1best,xinew,xi+1best,…,xnbest),xinew∈[li,ui]}.With the above observations, we propose a space search-based evolutionary algorithm as shown in Table 1. The operators of Case I and Case II can be considered as local space search and global space search in some degree.Although we obtain a space search-based evolutionary algorithm, two issues need to be discussed. First, the search completed in a new space is realized by some pure random mechanism. Second, the role of operator in Case II is limited when dealing with the premature convergence problem. To overcome these limitations, we employ accelerated convergence strategies and Cauchy searching to further develop the space search-based evolutionary algorithm shown in Table 1. The new algorithm, namely SSOA, is developed as follows:(1)An augmented simplex method is used to speed up the convergence in local space search (Case I);The global space search is completed by Cauchy searching (instead of the strategy described by Case II) to overcome premature convergence problem; andAn opposition-based learning is exploited to accelerate the convergence of the SSOA.We first consider how to generate the new space of local space search operator. Fig. 4depicts three different subspaces generated by M solutions when the dimensionality of a feasible solution is equal to 2 [26]. In this case, M solutions can be presented asXk=(x1k,x2k), wherexik∈[li,ui],i=1,2,k=1,2,…,M. It becomes apparent that the four pointsx1min,x2min,X1max,X2maxare the minimum ofx1k, the minimum ofx2k, the maximum ofx1k, the maximum ofx2k, respectively. In the SSOA, we always generate a new subspace based on the three solutions (M=3).The local space search completed in the new space is realized by generating a new solution (individual) located in this space. To generate a new solution, we use a generation mechanism shown in Fig. 5. We realize this operation with the aid of a technique of augmented simplex method [29,30]. Three basic operators including reflection, expansion, and contraction are developed: the reflection operator is to search M (three) solutions composed space; the expansion operator is to search the extended space; and the contraction operator is to realize a search of the compacted space. In other words, the essence of the local space search operator is to realize a constrained optimization technique in the local feasible solution space. The pseudo-code for the local space search operator is outlined in Table 2. It is apparent that the space search operator case I as shown in Table 1 is similar to the expansion operator without accelerated convergence strategy (generating a new solution just at random).The local space search operator of SSOA can also be viewed as a sequence of the following steps:Step 1. The reflection, expansion, and contraction coefficients, which are the initial parameters of the local space search operator, are set as α=0.55, β=0.5, and γ=2, respectively (the choice of these specific value is a result of intensive experiments; as a matter of fact, these results are close to the values used in the simplex method reported in the literature).Step 2. The initial values of α, β, and γ are specified using the reflection, expansion, and contraction of the simplex. More specifically, we have(2)(I)Reflection:Xr=X0+α(X0−Xh)(3)(II)Expansion:Xe=X0+γ(Xr−X0)(4)(III)Contraction:Xc=X0+β(Xl−X0)Step 3. Xhand Xlare the vertices corresponding to the maximum function value f(Xh) and the minimum function value f(Xl). X0 is the centroid of all the points Xlexcept i=h. The reflection point Xris given by (2) Xl=maxf(Xi), (i=1, 2,…, m),X0=1/(m−1)(∑i=1nXi−Xh), and α=||Xr−X0||/||Xh−X0||. If Xrdoes not satisfy the constraints, a new point Xris generated by taking Xr=(X0+Xr)/2.Step 4. If the reflection process produces a point Xrfor which f(Xr)<f(Xl), i.e., if the reflection produces a new minimum, we expand Xrto Xeby (3), with γ=||Xe−X0||/||Xr−X0||>1. If Xedoes not satisfy the constraints, a new point Xeis generated by Xe=(X0+Xe)/2. This process is repeated until Xesatisfies the constraints. If f(Xe)<f(Xl), we replace the point Xhby Xeand restart the process of reflection. On the other hand, If f(Xe)<f(Xl) we replace the point Xhby Xrand start the process of reflection again.Step 5. If the reflection process produces a point Xrfor which f(Xr)<f(Xi), for all i except i=h. If f(Xr)<f(Xh), then we replace the point Xhby Xr. In this case, we contract the simplex as in Eq. (4), with β=||Xc−X0||/||Xh−X0||. If f(Xr)<f(Xh), we use Xcwithout changing the previous point Xh. If Xcdoes not satisfy the constraints, a new point Xcis generated with Xc=(X0+Xc)/2. This process is repeated until Xcsatisfies the constraints. If the contraction process produces a point Xcfor which f(Xc)<min[f(Xh), f(Xr)], we replace the point Xhby Xc. In the sequel, we proceed with the reflection again. On the other hand, If f(Xc)<min[f(Xh), f(Xr)], we replace all Xiby (Xi+Xl)/2, and start the reflection process again.Step 6. This method is assumed to have converged whenever the standard deviation of the function at the vertices of the current simplex is smaller than some prescribed small threshold (ξ) as follows:(5)Q=∑i=1n+1[f(Xi)−f(X0)]2n+11/2≤ξIf Q does not satisfy (5), go back to step 3.If the best solution falls in some local optima, a Cauchy search (Cauchy mutation) with a given probability may modify this solution. The role of this global space search operator is to help the trapped solution escape from the local optimum. The one-dimensional Cauchy probability density function centered at the origin is defined as follows(6)f(x)=1πtt2+x2,−∞<x<+∞.where t>0 is a scale parameter [30]. The Cauchy distribution function reads as(7)Ft(x)=12+arctanxtAssume that the best solution in the current solution set is denoted by Xbest. The Cauchy search operator is realized as follows(8)Xbestnew=Xbest+cauchy().Here cauchy() is a random number generated by the Cauchy probability density function with the scale parameter t=1.To speed up the convergence of the SSOA, we use a mechanism of opposition-based learning (OBL) [25]. OBL has been shown to be an effective concept to enhance various optimization approaches. Let us recall the basic concept.Opposition-based point [25]: Let P (x1, x2,…, xD) be a point in a D-dimensional space, where x1, x2,…, xD∈R and xi∈[ai, bi], ∀i∈{1, 2,…, D}. The opposite pointP⌣=(x⌣1,x⌣2,…,x⌣D)is completely defined by its componentsx⌣i=ai+bi−xiOpposition-based optimization (OBL) [25]: Let P=(x1, x2,…, xD) be a point in a D-dimensional space (i.e., a candidate solution). Assume f(·) is a fitness function. According to the definition of the opposite point, we say thatP⌣=(x⌣1,x⌣2,…,x⌣D)is the opposite of site P=(x1, x2,…, xD). Now, iff(P⌣)≥f(P), then the point P can be replaced withP⌣. Hence, the point and its opposite point are evaluated simultaneously in order to continue with the one of the highest fitness.Based on this concept, we develop the opposition-based space search operator. Table 3summarizes the procedure for opposition-based space search.The termination condition of the SSOA states that the method terminates once all the solutions in the current population have the same fitness. SSOA can also terminate after a certain fixed number of generations. In the SSOA, there are two basic parameters Cr and Po. Cr denotes the probability of implementing the space search operations, while Pois the parameter for the opposition-based space search (size of opposition population). The pseudo code for the SSOA is listed in Table 4.Global space search operation may efficiently alleviate the problem of the premature convergence. But this operator has to maintain a possibility of exploration of a side area of the solution space so as to avoid premature convergence. For this reason, using the global space search operation, we may rapidly approach a near-optimal solution with the lack of adequate local space search. Taking this into account, we use the local space search operation to ensure the search performance and guarantee convergence to a global optimum.The local space search operation is realized by augmented the simplex concept, which is a powerful approach to determine a local optimum according to the initial values for exploration of the feasible solution space; that is to say, the determination of the global solution depends on the configuration of initial values. If the initial values was set corresponding to the optimal solution (global optimum), this operator may reach the desired low error state faster than the global space search operator. Consequently, it is very important, albeit difficult, to determine the initial values for a searching space area. This suggests the use of global space search operator to form the initial solutions of the local space search operator.The proposed SSOA implements the global space search operator and the local space search operator simultaneously. Under this mechanism, the global space search operator finds the hills (near-optimal solutions), and then hill-climber climbs them. As a hill-climber, the local space search operator is utilized. By using these two operators, SSOA can obtain a global solution (or close to the global solution) not only alleviating the premature convergence in the entire solution space but also improving the accuracy of optimum in the local solution space, at least to some extent.Furthermore, the opposition-based space search operation is utilized to improve the convergence of the method. With this operation, the proposed SSOA alleviates the problems (such as long computational time) resulted from the use of the purely random search mechanism.The most outstanding features of the SSOA can be identified as follows:(1)The SSOA leads to the superb local space searching abilities in comparison with the capabilities of the “standard” DEs. The local space search operator is realized by augmented the simplex concept, which is a sound tool to carry out search in the local space.The SSOA comes with good global space searching abilities to some degree. The global space search operator is realized with the aid of the Cauchy mutation, which has been demonstrated to form an effective approach to alleviate the premature convergence problem, which is always encountered in other optimization algorithms.The SSOA is characterized by fast convergence. The opposition-based space search operator is realized with the aid of the opposition-based concept, which reduces long computing time.To quantify the performance of SSOA, we consider a set of 19 standard benchmark functions. The functions f1(x)–f6(x) were chosen from the first six functions provided by the CEC 2008 Special Session and Competition on Large Scale Global Optimization [31], functions f7(x)–f11(x) were proposed for ISDA 2009 Workshop on Evolutionary Algorithms and other Meta heuristics for Continuous Optimization Problems – A Scalability Test [32], and the functions f12(x)–f19(x) are the hybrid composition functions based by combining two functions that belongs to the set functions f1(x)–f11(x). A detailed description of these benchmark functions can be found in [33]. These benchmark functions (see Tables 5 and 6) can be split into four classes:(1)shifted unimodal functions f1(x)–f2(x);shifted Multimodal functions f3(x)–f6(x);not shifted Unimodal functions f7(x)–f11(x);hybrid composition functions f12(x)–f19(x).We compared the performance of SSOA with the performance achieved by four different DEs on the test functions with D=50, 100, and 200, respectively (here we compared with DEs and MEs, which lead to good performance in the most of cases). The seven algorithms used in this comparison are listed below.(1)Differential evolution (DE) [23];Opposition-based differential evolution (ODE) [25];JADE [34];Self-adaptive differential evolution (SADE) [35];Memetic evolution (ME) [27,28];Cellular memetic evolution (CME) [36];Space search optimization algorithm.For each algorithm, 25 independent runs were completed with a size of population of 150 individuals for each test function. Here we record the mean and standard deviation of f(x)–f(x0), where f(x) are the experimental results of the algorithms and f(x0) are fitness optima of the benchmark functions. The maximum number of fitness evaluations, MAX_FES, is 5000*D, where D is the number of independent variables present in the test functions. Each run stops when the maximum number of evaluations has been achieved. Here we investigate the optimization performance of these algorithms for D=50, D=100, and D=200. The parameter settings of the seven algorithms are summarized in Table 7. The parameters for ME and CME are set as follows: mutation rate M is equal to 0.001, two-point crossover rate C is set as 0.8, both the values of weight W and height H are equal to 10, local search length evaluations EL is equal to 200, and a user-predefined percentage value of population undergoing local search PLS is equal to 20%.This section reports on the results of comparative analysis of SSOA with DE, ODE, JADE, SADE, ME and CME for D=50, D=100, and D=200. The average error of SSOA is compared with those with the above other four algorithms, as shown in Tables 8–13. All the results with the values below 1E−14 have been treated as 0.0. The best results among the seven algorithms are shown in boldface.From the reported results, it becomes evident that the SSOA shows a promising performance on the majority of test functions for each dimensionality while it fails to solve f3 and its hybrid composition functions f13, f17, and f19. However, SSOA performs well in comparison with the other four algorithms studied here. For D=50, SSOA achieves promising results except for only four test functions (f3 and its hybrid functions f13, f17, and f19); For D=100 and D=200, SSOA has better performance than the other four algorithms only except for the three test functions (f3, f17, and f19). It is also observed that SSOA outperforms the other four algorithms especially in case of highly dimensional problems.Fig. 6illustrates the convergence of the method expressed in terms of the number of function evaluations (FES) and the average function error value (denoted here as fitness) for functions f11–f19 with D=50, D=100, and D=200, respectively.For the 50-D f1–f19, SSOA always converges faster than the other methods on 15 test functions f1, f2, f4–f12, f14–f16, and f18 as shown in Fig. 6. Except for the four functions f3, f13, f17, and f19, the performance of SSOA is quite different. For 50-D functions f17, JADE and SADE obtain better results while SSOA performs poorly. For 50-D function f13, DE, ODE, and SADE lead to better performance than SSOA. For 50-D functions f3 and f19, all other four algorithms achieve better results in comparison with SSOA. It is clear that SSOA performs efficiently on majority of 50-D benchmark functions.Fig. 7visualizes the convergence obtained for 100-D test functions f1–f19. The results show that most of the test functions are easily optimized with the SSOA. For 100-D functions f3, f17, the only two algorithms can achieve better performance than SSOA. Those are JADE and SADE, respectively. For 100-D function f19, the three algorithms including DE, ODE, and SADE perform better than the SSOA.For the 200-D test functions f1–f19, SSOA performs much better results on 16 functions f1, f2, f4–f16, and f18 while SSOA fails on the three functions f3, f17, and f19, see Fig. 8. For these three functions, JADE converges faster than SSOA for 200-D function f3, SADE exhibits slight superiority in terms of efficiency in comparison with SSOA for 200-D function f17, and three algorithms DE, ODE and SADE come with the higher speed in reaching the optimal solutions than SSOA for 200-D function f19. We can observe that, when the dimensionality of the problem was increased from 50 to 200, SSOA exhibits higher efficiency in comparison with the efficiency of the other four other algorithms.To assess the contribution of the opposite points, the SSOA is kept untouched and instead of using opposite points for the population initialization and the generation jumping, uniformly generated random points are employed. To show the results, the current interval of the variables are used to generate new random points in the generation jumping phase in order to keep a fair competition in this case. The lines 5, 6, and 8 shown in Table 3 should be deleted.After these modifications, the random version of SSOA (called RSSOA) is introduced. In order to compare convergence speeds, we use the acceleration rate (AR) which is defined as follows, based on the FES for the two algorithms SSOA and RSSOA:(9)AR=FESRSSOAFESSSOAwhere AR>1 states that SSOA is faster.Tables 14–16provide the comparative results of SSOA and RSSOA when executed with the same parameter settings. As seen, SSOA outperforms RSSOA on 19 benchmark functions with the population size of 100. SSOA performs better than RSSOA on most of functions. Just by replacing the opposite numbers with additional random numbers (randomly generated with uniformly distribution). It is clear that the achieved improvements are due to usage of the opposite points in comparison with the random sampling.To investigate the effect of the population size, we set the population size as 50, 100, and 200, respectively. Table 17summarizes the results vis-a-vis different population sizes. In light of the results, SSOA performs better in comparison with RSSOA when the dimensionality of the problems increases. On the other hand, SSOA with a larger population size performs better in comparison with smaller population sizes. Here NUF denotes the number of functions for which the algorithm has not achieved the optimal value, DIM denotes the dimension of benchmark functions, and the average acceleration rate over n test functions are calculated as follows:(10)ARave=1n∑i=1nARiThis paper presents the SSOA and shows its application to continuous optimization problems. Two important aspects are worth highlighting here:(1)The SSOA, as a new heuristic optimization algorithm, is inspired by the space search mechanism. By running a series of benchmark functions, it was shown that SSOA exhibits good performance on the majority of these functions.We compared the SSOA with DE, ODE, JADE, SADE, ME, and CME. On the benchmark functions. On the benchmark, the SSOA produces a small average error and exhibits faster converge than the other four algorithms. It also shows that the SSOA outperforms DE, ODE, JADE, SADE, ME, and CME when dealing with the problems of increasing dimensionality.

@&#CONCLUSIONS@&#
