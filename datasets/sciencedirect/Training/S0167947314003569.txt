@&#MAIN-TITLE@&#
Bayesian network data imputation with application to survival tree analysis

@&#HIGHLIGHTS@&#
Retrospective clinical datasets have often small sample size and many missing data.We use Bayesian networks to impute missing data enhancing survival tree analysis.The Bayesian network is learned from incomplete data and used for the imputation.Our method generally achieved more accurate predictions than widely used approaches.

@&#KEYPHRASES@&#
Bayesian networks,Data imputation,Missing data,Prognostic stratification,Survival tree,

@&#ABSTRACT@&#
Retrospective clinical datasets are often characterized by a relatively small sample size and many missing data. In this case, a common way for handling the missingness consists in discarding from the analysis patients with missing covariates, further reducing the sample size. Alternatively, if the mechanism that generated the missing allows, incomplete data can be imputed on the basis of the observed data, avoiding the reduction of the sample size and allowing methods to deal with complete data later on. Moreover, methodologies for data imputation might depend on the particular purpose and might achieve better results by considering specific characteristics of the domain. The problem of missing data treatment is studied in the context of survival tree analysis for the estimation of a prognostic patient stratification. Survival tree methods usually address this problem by using surrogate splits, that is, splitting rules that use other variables yielding similar results to the original ones. Instead, our methodology consists in modeling the dependencies among the clinical variables with a Bayesian network, which is then used to perform data imputation, thus allowing the survival tree to be applied on the completed dataset. The Bayesian network is directly learned from the incomplete data using a structural expectation–maximization (EM) procedure in which the maximization step is performed with an exact anytime method, so that the only source of approximation is due to the EM formulation itself. On both simulated and real data, our proposed methodology usually outperformed several existing methods for data imputation and the imputation so obtained improved the stratification estimated by the survival tree (especially with respect to using surrogate splits).

@&#INTRODUCTION@&#
Retrospective clinical data are often used to identify features that can help in classifying patients into groups of similar survival and in predicting the survival outcome of patients (i.e. a prognostic patient stratification). The identification of classes of patients with a different clinical course or response to a specific treatment allows the design of the most appropriate approach for the management of each individual patient. The survival tree is a state-of-the-art method to stratify patients for predicting survival on the basis of available clinical parameters (Ciampi and Thiffault, 1986). Although several algorithms exist for its estimation (Davis and Anderson, 1989; LeBlanc and Crowley, 1992, 1993; Segal, 1988; Keleş and Segal, 2002; Hothorn et al., 2006; Fana et al., 2009), the procedure always consists in finding, at each step, the best clinical variable able to divide the patients (with respect to the survival), so that the final stratification of the patients assumes a tree-like structure.In retrospective studies, clinical and survival data may contain many missing values for several reasons. If the study includes data over a long period, some clinical parameters might not have been measured for some patients, because they were not systematically collected at diagnosis, and data might be missing in individual patients due to technical issues. More importantly, data might be missing in some particular subset of patients, causing biases in the analysis: for example, patients with a very aggressive course might have died before performing a test, or a test might have been skipped in patients expected to have a very good clinical course. Therefore, a retrospective study usually contains many missing covariate data, and this can heavily affect the statistical analysis, especially when the sample size is small. This issue worsens if the dataset contains many censored survival data. In fact, the missingness of the covariates added to the censoring issue increases the hardness of identifying an accurate prognostic stratification of the patients. In this work, we denote by missing data only the incomplete information happening in clinical and biological variables that are available in the analysis, and not the incomplete lifetime information of patients (censoring). A naive, still very used, approach to handle this issue consists in discarding all patients with missing variables from the analysis, decreasing the power of any model, which is clearly undesirable. Instead, survival tree procedures decide the best splits to define the tree using only the observed data for each variable, and they resort to surrogate splitting in case of missing values, that is, they use a splitting rule based on another variable which most resembles the behavior of the original missing one (Breiman et al., 1984).Another widely used approach to handle missing data is to impute the missing values, thus considering a complete dataset in further analyses (Little and Rubin, 1987). The data imputation problem regards completing the dataset in some particular manner such that the important characteristics of the dataset are preserved. This is mostly done by assuming that missing data are missing completely at random (that is, their missingness is independent of both unobserved and observed data), which implies that data imputation can be safely performed by analyzing each variable separately. Widely used methods, such as single expected value imputation and single mode imputation, are based on this assumption. However, missing data in clinical datasets can be more realistically considered as missing at random instead of missing completely at random (that is, their missingness, conditional on the observed data, is independent of the unobserved values). In fact, some of the examples discussed before in this introduction are missing at random, but not completely at random. In the literature, many statistical approaches that account for the dependencies among covariates have been used for data imputation. In case of categorical or discrete variables (which is often the case for clinical parameters), these methods are usually based on maximum likelihood (ML) estimation of the joint distribution of the covariates from the partially classified contingency table built using the observed data (Little and Rubin, 1987). Unfortunately, they suffer from the small sample size and tend to overfit, even with a small number of covariates, because they consider all dependencies among all variables.We propose to use a methodology based on Bayesian networks as a way to impute accurately the missing data and improve the quality of the inference, especially in the application to survival tree analysis. For this application, our imputation method is employed only for imputing the covariates (without any knowledge about the survival data) and the survival tree is applied to the (supposedly accurate) completed dataset so obtained. A Bayesian network is a probabilistic graphical model that relies on a directed acyclic graph to encode the structured dependency among random variables and compactly represent a joint probability distribution. Learning and inference in these models benefit from fast and accurate procedures (Koller and Friedman, 2009). More specifically, learning a Bayesian network from data consists in searching for the structure of the network, as well as its parameters, such that some criterion of quality is maximized. The most common criterion for this purpose is the Bayesian Dirichlet Equivalent Uniform (Heckerman et al., 1995), which is based on maximizing the posterior probability of the structure given the data. Although this is a particularly challenging problem when data are incomplete, suitable algorithms do exist (Friedman, 1998; Meila and Jordan, 1998; Singh, 1998; Riggelsen and Feelders, 2005; Ramoni and Sebastiani, 1997; Riggelsen, 2006). These methods are mostly based on turning the incomplete data into a complete dataset (or even directly updating the sufficient statistics), and then recurring to particular methods for complete data. We adopt a meta-search composed of a few distinct methods (Jaakkola et al., 2010; de Campos and Ji, 2011; Cooper and Herskovits, 1992; Silander and Myllymaki, 2006) that selects the best procedure to run depending on the number of covariates and running-time of the methods. The idea is to improve the score in the most efficient way, still with the guarantee of achieving optimality. After the Bayesian networks is learned, data imputation is performed by posterior expected means (and/or modes) computed from the estimated joint probability distribution (encoded by the Bayesian network). Standard belief updating (and/or maximum probable explanation) methods are used (Koller and Friedman, 2009). We use Bayesian networks in a similar way to previous studies (Romero and Salmerón, 2004; Di Zio et al., 2004), but differently from them, we implement a global structure learning method that directly works with the expected sufficient statistics instead of completing the data at each step of the structure learning process, thus achieving more accurate models. Our method for data imputation is freely available online at http://code.google.com/p/csda-dataimputation/.The main contributions of this work are: (i) the design of a new framework that is able to capture the dependencies among variables, which is then used to estimate in a more accurate way the values of missing (categorical) covariates, and (ii) its comparison against other widely used methodologies to deal with missing data for survival tree analysis using both simulated data and real data of lymphoma patients. We empirically show that our proposed methodology may greatly improve: (i) the accuracy of data imputation (especially in case of strong dependencies among the variables) and (ii) the quality of results of the survival tree analysis, even in hard scenarios with a high percentage of missing and/or censoring data (which may occur in practice).In this section we formalize the problem of data imputation and describe how we apply Bayesian networks to perform such task, from the model learning to the missing values’ inference. Since we aim at the application to clinical data and often clinical variables are binary, ordinal or discrete (with few values), we consider here only the case in which the covariates have a finite domain. In general, Bayesian networks can also be defined and learned for continuous variables (see, for example, Koller and Friedman, 2009).LetX=(X1,…,Xm)be a vector of categorical or discrete random variables assuming values inΩX=×iΩXi, whereΩXiis the state space ofXi, for everyi, andΩXis the Cartesian product of them. Letd∈ΩDbe a realization (here, called also state configuration) of a subset of componentsDofX. Suppose we have a datasetDwithnsamples, where, for each sampleu,Durepresents the components ofXwhich are observed in the sample, andZuthe remaining missing ones. Thus,D={d1,…,dn}withdu∈ΩDu. We usedu,ito denote the observed value of the variableXiin sampleu, and we usezu,ito denote a completion of the missing value forXiin the sampleu, such that(du,zu)∈ΩXis a complete configuration ofX, for some given valuezu. We defineIas the indicator function such thatI{condition}=1if the condition is satisfied, and zero otherwise. For example,I{x′=x}=1ifx′=x. As a particular case, we useI{missXi;u}to indicate whether the variableXiis missing in sampleu. The data imputation problem regards completing eachduwith somezuopportunely such that no missing value remains in the dataset. For instance, a single mean (and respectively a single mode) approach would take, for every(u,i):zu,i=∑u(1−I{missXi;u})⋅du,i∑u(1−I{missXi;u})andzu,i=maxxi∈ΩXi∑uI{du,i=xi}.Note that single mode would keep the dataset discrete without changes in the variable’s domains, while single mean would eventually introduce values that were not present before. The problem with these approaches is that they do not consider dependencies between the missing values and the observed ones. This is an acceptable behavior if the missing values are assumed to be missing completely at random (or simply MCAR). However, in many cases one cannot be sure whether the missing data are MCAR, or they might even know that this is not the case. In such cases, the most usual assumption is that missing data are missing at random (or simply MAR), which means that although missing, the process which generated them may depend on the observed data (but not on the unobserved ones). Using the MAR assumption, single mode and single mean imputations are arguably too naive: no information from the other variables has been used in helping to estimate the missing values.Given the MAR assumption, one can perform data imputation such that the likelihood of the observed data, or its posterior probability (as we do here), is maximized. First, they computeM=argmaxM′PrM′(D|M′), whereMis the model which maximizes the probability of the data, and then they use the modelMto compute the expected values (or the mode) for the imputation of the missing data. For everyu,i:zu,i=EM[Xi|du]orzu=maxzu∈ΩZuPrM(zu|du),whereEMandPrMare, respectively, the expectation and the probability with respect toM. However, when the number of variables inXis large, any direct approach that must handle MAR data becomes intrinsically exponential, because even the specification of the joint probability distribution is prohibitive. This situation would happen, for instance, with a direct application of either expectation–maximization or data augmentation, as well as any other method that deals with a full specification of the joint distribution (Little and Rubin, 1987). In such cases, one can resort to more compact representations of the joint distribution, such as the Bayesian networks, which can be learned from the data.We point out that, in general, when the data imputation is based on the conditional distribution of one variable with respect to the others, often only some variables are considered in the conditioning. In that case, when the imputation is performed with the conditional expected value, the resulted imputed dataset may present altered associations among the variables, especially with those not considered in the conditional distribution. One way to overcome this issue would be to impute the data with a random draw from the conditional distribution, but the imputation with a single sampling would not reflect the sampling variability. Thus, usually multiple imputations are preferable, but they require a method for combining the inference across the imputed datasets (Little and Rubin, 1987). Instead, in our methodology, we estimate the joint distribution among all variables, thus the associations among the variables should not be affected by such issue.A Bayesian networkMis a probabilistic graphical model that relies on a structured dependency among random variables to represent a joint probability distribution in a compact and efficient manner. It represents a joint probability distributionPrMover a collection of discrete random variablesX. It can be defined as a tripleM=(G,X,P), whereG=(VG,EG)is a directed acyclic graph (DAG) withVGa collection ofmnodes associated to the random variablesX(a node per variable), andEGa collection of arcs;Pis a collection of conditional probabilitiesPrM(Xi|PAi)wherePAidenotes the parents ofXiin the graph (PAimay be empty), corresponding to the relations ofEG. In a Bayesian network, the Markov condition states that every variable is conditionally independent of its non-descendants given its parents. This structure induces a joint probability distribution by the expressionPrM(X1,…,Xm)=∏iPrM(Xi|PAi). We defineri≥2as the number of values inΩXi,rPAias the number of possible configuration of the parent set, that is,rPAi=∏Xl∈PAirl, andθas the entire vector of parameters such thatθijk=PrM(Xi=xi,k|PAi=pai,j), wherexi,k∈ΩXiandpai,j∈ΩPAi, fori∈{1,…,m},k∈{1,…,ri},j∈{1,…,rPAi}.Given a datasetDwithnsamples, the structure learning problem in Bayesian networks is to find a DAGGthat maximizes a given score function, that is, we look forG∗=argmaxG∈GsD(G), withGthe set of all DAGs over node setX. In this paper, we consider the score functionsDto be the Bayesian Dirichlet Equivalent Uniform (BDeu) criterion (Buntine, 1991; Cooper and Herskovits, 1992). As done before in the literature, we assume parameter independence and modularity (Heckerman et al., 1995). The idea is to compute a score based on the posterior probability of the structurePr(G|D). For that purpose, the following score function is used:sD(G)=log(p(G)⋅∫p(D|G,θ)⋅p(θ|G)dθ),where the logarithmic is often used to simplify computations,p(θ|G)is the prior ofθfor a given graphG, assumed to be a Dirichlet with hyper-parametersα={αijk}ijk:p(θ|G)=∏i=1m∏j=1rPAiΓ(αij•)∏k=1riθijkαijk−1Γ(αijk),whereαijk=α∗rPAiri, for allj,k,αij•=α∗rPAi, for allj, andα∗is the only free hyper-parameter, usually referred to as the Equivalent Sample Size (ESS). We assume that there is no preference for any graph, sop(G)is uniform and vanishes in the computations. Under these assumptions and if the data are complete, it has been shown (Cooper and Herskovits, 1992) that,(1)sD(G)=log∏i=1m∏j=1rPAiΓ(αij•)Γ(αij•+Nij)∏k=1riΓ(αijk+Nijk)Γ(αijk),whereNijkindicates how many elements ofDcontain bothXi=xi,kandPAi=pai,j. The values{Nijk}ijkdepend on the graphG(more specifically, they depend on the parent setPAiof eachXi), so a more precise notation would be to useNijkPAiinstead ofNijk, which we avoid to make things simpler. Moreover, note that we do not really need to know each element ofDto compute the score function, but it is sufficient to haveN={Nijk}ijk.Learning the structure of these networks from data is a very challenging problem, especially when data are incomplete. Assuming that missing values are MAR, we could marginalize missing variables to obtain a function of the observed ones. However, this function becomes hard to evaluate, and other problems arise: for instance, methods that build a cache of local scores based on score decomposability (de Campos and Ji, 2010) cannot be applied anymore. Another solution is the expectation–maximization (EM) algorithm, which was extended to work on the structure learning problem (Friedman, 1998). The idea is to use the E-step to compute the expected counts (which is an expected sufficient statistics for the data) given the current structure and parameters of the network, and then apply such expected counts to learn a new structure. This is done iteratively until no improvement in the structure or parameters is possible. A possible version of the algorithm is as follows:Structure learning algorithmInput: datasetDOutput: Bayesian networkM1.Choose an initial guessG0and parametersθ0.Fort=0,1,….(a)Set the structure ofMtto beGtand run a parameter learning method for incomplete dataDto find new parametersθforMt, using its structure and the parametersθt.ComputeNusingMtto deal with the missing values such that each missingzu,iis associated to the probability mass functionPrMt(Xi|du). Sets′=sN(Gt).Run the learning method that searches for aGt+1that maximizessN. In fact, we stop this step as soon as the value ofsNbecomes greater thans′. If there is noGt+1that improves the previous scores′, go to step 3.SetM=Mt.In order to optimize the score function over the space of possible graphsGin the step (2c) of the algorithm, we have implemented a few algorithms available in the literature, and a meta-algorithm that is able to select the best option according to some problem characteristics and/or running time limits. Namely, we have implemented the K2 local search of Cooper and Herskovits (1992), the branch-and-bound (BB) procedure in de Campos and Ji (2011), a pruned dynamic programming (DP) based on Silander and Myllymaki (2006), and the linear integer programming (IP) of Jaakkola et al. (2010). These methods all require the dataset to be complete, or at least to have a way to compute the sufficient statistics ofDin the step (2b) of the algorithm. We associate to each missing valuezu,ithe corresponding distributionp(Zu,i), usingp(Zu,i)=PrM(Xi|du), just as if the observation forzu,ihad been split into its states proportionally toPrM(Xi|du). Besides that, we employ the properties of the BDeu score of de Campos and Ji (2010) in order to reduce the search space even before calling the structure learning methods.Past literature experiments (Cussens, 2011; de Campos and Ji, 2011; Jaakkola et al., 2010) indicate that DP is the fastest method for small values ofm(fewer than 15–20 variables), IP is the best method from 15–20 to a hundred, and IP and BB are anytime algorithms, so can be run even with large datasets, and then the accuracy keeps improving with time. K2 is the only non-exact method (that is, not guaranteed to converge to a global maximum solution), but it is very efficient, so we try to use the K2 search as much as possible, that is, we use K2 as long as it can find an improving solution with respect to the previous run (if it cannot, then a globally optimal method is used). Therefore, our structure learning starts by running K2 with random initial guesses until a time limit or convergence of K2 is reached. If an improving solution is found, the method stops and returns it. If K2 fails to find an improvement, one of DP, IP or BB is run, depending on the number of variables. DP and IP are given a certain time-limit, which if surpassed, BB is also called.Because the structure learning finds an improving solution (or the computation finishes), the method increases the score at each iteration, and so it converges. Until recently, exact methods to find the best structure were simply prohibitive unless for toy examples, hence structural EM had been developed using only a local search on the space of structures, that is, step (2c) had never been performed with a global search method. As described, we can also make use of approximate methods such as the K2, but we will never decide to stop the search prematurely if there is an improving solution, because in such case we would have run also a global method, which would eventually decide for sure whether there is in fact an improving solution or not. Hence, the source of approximation in this enhanced structural EM is due solely to the use of the EM, which is intrinsic of such idea.In order to perform data imputation, we use the Bayesian network learned by the procedure described in Section  2.2. After all, the Bayesian network we learn simply represents a joint distribution for the variables with the compromise between fitting the (incomplete) dataDand keeping the description compact (thus efficient to compute with). Data imputation can be naturally performed by using either the posterior expected mean (for discrete or ordinal variables):(2)zu,i=E[Xi|du]=∑xixiPrM(xi|du),which corresponds to the belief updating query in the learned Bayesian network (Koller and Friedman, 2009), or the posterior expected mode (for either discrete or categorical variables):zu=maxx∈ΩZuPrM(x|du),which corresponds to the most probable explanation query in the Bayesian network. In both cases, the learned structure is used to compute the desired values in an efficient way (more precisely, their complexity depends exponentially on the treewidth of the network, a measure of the similarity of the network’s graph to a tree). In the particular case of missing values for binary variables, the data completion by the expected value in Eq. (2) can be used even if the variable is nominal, because it represents the preference between categories (in terms of frequencies of choosing the category one).We end this section by discussing on other methods to perform data imputation. Di Zio et al. (2004) also use Bayesian networks for data imputation, but they force the network (and the imputation procedure) to follow a pre-defined order among the variables in the domain. This constraint is known to restrict the learning to sub-optimal Bayesian networks. Romero and Salmerón (2004) use an imputation method that resembles the learning procedure of Section  2.2. The main difference is their use ofk-best most probable explanation sequences (Nilsson, 1998) (for each sample in the dataset) to fill in the missing values at each iteration (they sample an instantiation from thekbest according to their probabilities, which is done to mimic a joint data augmentation approach, while keeping the computational complexity low), instead of working with the (expected) sufficient statistics computed from the data. Riggelsen and Feelders (2005) propose ideas to learn Bayesian networks using imputation, but adopt a data augmentation procedure (Tanner and Wong, 1987) where the missing data are imputed with an importance sampling approach. These ideas seem well suitable when the number of samples are over a thousand (Riggelsen, 2006), which is rarely the case of most medical datasets. Finally, to the best of our knowledge, all previous attempts have used local search methods to deal with the structure learning problem (Di Zio et al., 2004; Romero and Salmerón, 2004; Ramoni and Sebastiani, 1997; Riggelsen and Feelders, 2005; Riggelsen, 2006), while we use a globally optimal procedure.Let us consider the right-censored survival data ofnpatients. The observed time of patientuis denoted byYu=min{Tu,Cu}, whereTuis the failure time (or event time) andCuis the censoring time of that patient. The censoring indicator is denoted byδu=I{Tu≤Cu}, that is,δu=1when the event time is observed (i.e.Yu=Tu). Hence, for each patientuin the dataset, his/her survival information is represented by the pair(Yu,δu). As usual, we assume censoring to be independent of the observations.In survival analysis, it is of interest to estimate the survival functionS(t)=P(T>t), for allt≥0, which represents the probability to be event-free up to timet. More in general, this function is studied conditional on the values of some covariatesX=(X1,…,Xm), that isS(⋅|X), and in our context the covariates may represent clinical and/or biological parameters known at diagnosis. For the definition ofS, it is common to use a proportional hazards model:(3)S(t|X)=e−∫0tλ(s|X)ds=e−h(X)∫0tλ0(s)ds,t≥0,by assuming thatλ(s|X1,…,Xm)=λ0(s)h(X)(i.e.h(X)=λ(s|X)/λ0(s)), for alls≥0, whereλandλ0are the hazard and the baseline hazard function, respectively. As example, choosingh(X)to beexp(β1X1+⋯+βmXm)gives us the Cox proportional hazards model (Cox, 1972).In clinical studies, it is often more interesting to estimate the survival function depending only on few subsets of the space defined by the covariates (that is, few combinations of sets of values or intervals of the covariates), instead of a full continuous model, such as the Cox proportional hazards one. In this way, the patients can be divided in fewer subgroups based on the covariates (that is, each subset in the covariate space correspond to a subgroup) and a more accurate estimation ofScan be done for each subgroup. Consequently, we aim at defining a set of groups of patientsG={g1,…,gnG}, based on the values ofX=(X1,…,Xm), and at estimatingS(⋅|G=g),∀g∈G, whereGis the variable representing the group to which patients belong. By creating more homogeneous groups of patients, we obtain a better survival prediction of a new patient, given its covariates. This problem can be called prognostic patient stratification. For instance, such analysis allows the identification of patients with predicted poor survival, which might therefore take advantage from experimental therapies or more intensive regimens.A well-known and state-of-the-art method for the prognostic patient stratification is the survival tree, which is a regression tree with a split-function that is able to deal with censored data. In this contest, the groups are defined by combinations of the values of the covariates defined by the estimated tree-like structure. The main advantages of such method are that: (1) it selects the covariates useful in the model, considering their dependency; (2) it automatically defines the best cut-points for splitting the values of each covariate in sets or intervals used to form the definition of the groups; (3) it gives a highly informative output since the tree structure also shows a hierarchical dependency among the selected variables (Ciampi and Thiffault, 1986). These characteristics make it more appealing and powerful than more standard procedures, like stepwise Cox’s regression and elastic net Cox’s regression (Simon et al., 2011).Several algorithms exist for the estimation of the survival tree (Davis and Anderson, 1989; LeBlanc and Crowley, 1992, 1993; Segal, 1988; Keleş and Segal, 2002). Most of them are essentially based on the CART algorithm (Breiman et al., 1984), but differ in the definition of the split function. Three well-known ones are based on: the one-step full exponential likelihood deviance (LeBlanc and Crowley, 1992), also implemented in the widely used R package rpart; the two-sample log-rank statistics (Segal, 1988); and the least-squares with martingale residuals (Keleş and Segal, 2002). In the literature it has not been proven any strong outperformance of one of them over the others (LeBlanc and Crowley, 1992; Keleş and Segal, 2002). Another regression tree methodology is the conditional inference tree (Hothorn et al., 2006), which is implemented in the R package party. In case of a censored response variable, the procedure is based on conditional log-rank tests (Peto and Peto, 1972) with multiplicity adjustedp-values. Although this method has good theoretical properties, it has been shown that its performance is comparable with that of the algorithm implemented in rpart, in case of categorical and numerical responses (Hothorn et al., 2006; Schauerhuber et al., 2008). As far as we know, these algorithms have not been fully compared in survival settings where the presence of a high percentage of censored data may increase the difficulty of the estimation. Since the comparison of different survival tree methodologies is out of the aim of this article and none has been shown to always outperform the others, here we employ the procedure implemented in rpart, which is the most widely used.

@&#CONCLUSIONS@&#
