@&#MAIN-TITLE@&#
Metacarpophalangeal joint patterns based personal identification system

@&#HIGHLIGHTS@&#
A new biometric identifier: whole MJP pattern is introduced.An effective, fast and robust MJP based biometric system is developed and presented.Discriminative common vector based method is firstly applied to obtain the feature sets of MJPs.

@&#KEYPHRASES@&#
Biometrics,Metacarpophalangeal joint patterns,Recognition,Identification,Verification,

@&#ABSTRACT@&#
This paper introduces a novel approach for identity authentication system based on metacarpophalangeal joint patterns (MJPs). A discriminative common vector (DCV) based method is utilized for feature selection. In the literature, there is no study using whole MJP for identity authentication, exceptionally a work (Ferrer et al., 2005) using the hand knuckle pattern which is some part of the MJP draws the attention as a similar study. The originality of this approach is that: whole MJP is firstly used as a biometric identifier and DCV method is firstly applied for extracting the feature set of MJP. The developed system performs some basic tasks like image acquisition, image pre-processing, feature extraction, matching, and performance evaluation. The feasibility and effectiveness of this approach is rigorously evaluated using the k-fold cross validation technique on two different databases: a publicly available database and a specially established database. The experimental results indicate that the MJPs are very distinctive biometric identifiers and can be securely used in biometric identification and verification systems, DCV method is successfully employed for obtaining the feature set of MJPs and proposed MJP based authentication approach is very successful according to state of the art techniques with a recognition rate of between 95.33% and 100.00%.

@&#INTRODUCTION@&#
Biometric technology uses certain physiological characteristics or behavioral traits to the automatic recognition of an identity. It is the most convenient and reliable alternative to satisfy the needs for personal authentication [2,3]. Hand-based biometric techniques also exploit varied internal, external and behavioral features that are unique for an individual, like fingerprints, 3D finger geometry, hand geometry, palm prints, hand veins, finger knuckle patterns, nails patterns, signatures and keystroke dynamics [1–6]. The human hand based recognition systems need very less cooperation from users for enrolment of the data whose capturing is non-intrusive. Good quality samples can be collected by low cost devices [7]. Recently, new algorithms and applications of hand-based biometrics have emerged. As these are reliable, low-cost and user-friendly viable solutions to personal authentication, most of these approaches have been well investigated in the literature [8–10]. Hand-based biometric systems also have some advantages over other techniques. These systems include easy and economical data acquisition, suitability for both indoor and outdoor usage including use in several bad weather and lighting conditions, the stability of hand features over time and the fact that they are the most user-friendly techniques in the biometrics field [8,10,11]. Although the hand-back surface may be highly useful in identity authentication due to its containing some unique patterns with rich lines, textures and creases, it has attracted very little attention from researchers [12]. The most commonly used and most popular biometric identifier from back-hand surface is finger knuckle print (FKP) [6,8–22]. Since FKP-based studies have shown significant performances as a result of the use of quick algorithms with very high accuracy, FKP recognition is a well-known technology. There are two different publicly available FKP databases for researchers who want to study FKPs [23,24]. A brief summary of FKP-based studies from the biometrics literature is given below.A study aimed at identity authentication using a 3D finger surface was introduced by Woodard and Flynn. In their study, they have developed a surface representation scheme for the middle, ring and index fingers using hand's 3D range images. The curvature based shape index to represent the fingers’ surface was also used and a Recognition Rate (RR) of between 58% and 98% was obtained [22]. The first studies about the finger-back surface were conducted by Ravikanth and Kumar. They have used various combinations of hand geometry features, Principal Component Analysis (PCA), Linear Discriminant Analysis (LDA) and Independent Component Analysis (ICA). They have obtained an Error Equal Rate (EER) of between 1.94% and 5.81% [21]. The FKP pattern was firstly used in a biometric-based recognition system and introduced as a biometric identifier by Zhang et al. The authors have developed and presented various accomplished studies about FKP recognition. A 2D Gabor filter based FKP recognition method was presented with a 97% RR and 1.09% EER value [19], a feature extraction scheme which combines orientation and magnitude information extracted by Gabor filters was introduced with a 1.51% EER value [20]. They have also used a Band-Limited Phase-Only Correlation based method with an EER of 1.68% for their experiment 1 and an EER of between 0% and 5.5% for their experiment 2 [15]. A feature extraction scheme which combines orientation and magnitude information extracted by Gabor filtering for FKP verification was introduced in the literature [9]. FKP recognition by extracting and assembling local and global FKP features was achieved with a 0.402% EER and 96.80% RR [8]. Kumar and Zhou have developed successful FKP recognition studies. They achieved personal identification using finger knuckle orientation features. A personal identification system via finger images which exploits the orientation features from the random knuckle lines using finite Radon Transform was introduced with 98.6% RR and 1.14% EER [12]. They have also used KnuckleCodes for personal authentication. The enhanced knuckle images were employed to generate KnuckleCodes using localized Radon Transform for FKP-based human identification. They have obtained a 1.08% EER [13]. Kumar and Ravikanth have achieved FKP detection and have used the geometrical features of the finger and FKP patterns for identity authentication with 1.39% EER [11]. Chorás and Kozik have used texture-based knuckle features for personal identification with 1.02% EER [18]. A method applying a Gabor filter to enhance FKP information and a Scale Invariant Feature Transform method to extract the FKP features were introduced by Morales et al. They have used fingers separately in addition to use various combinations of four fingers and obtained highly accurate results from their different experiments [16]. A multi-modal biometric system based on palm print and FKP using a Phase-Correlation Function based matching method was proposed by Meraoumia et al. [10]. DCV based method FKP recognition is also achieved by us recently [6].Inspired by the findings on FKP, we aimed to determine if the MJP that is the biggest single pattern endowed with highly unique features and original formation on the back-hand surface found on the metacarpophalangeal bones was unique or not. We also studied with the MJP, which contains much more lines and creases than FKP, to establish if it could be used securely for personal authentication. In this study, the details of the experimental results of this investigation are presented. When the hand-based biometric literature was reviewed, no study was found on whole MJP for identity authentication. The most similar approach [1] to our work is introduced by Ferrer et al. They used the hand knuckle pattern (HKP) as a biometric identifier. HKP is some part of the MJP. Their processing procedure of the HKP is also very different from our methodology. There are time consuming pre-processing tasks like selecting the region of interest (ROI), converting the HKP image into the gray level, binarization process with a pixel by pixel thresholding, enhancement, masking, dividing the HKP image into small blocks, applying the Fast Fourier Transform and inverse of it for each blocks [1]. Our feature selection method directly employed the gray level images without any enhancement task. In this work, whole MJP is firstly used as a new biometric identifier, DCV is firstly utilized for get the feature set of the MJPs and eventually a robust biometric system with high accuracy that can be applicable for real-time usage is designed.The scheme of the proposed MJP recognition approach is introduced in Section 2. Our experiments with both the publicly available database and the established database are given in Section 3. In addition, the results acquired are also appreciated and commentated on in this section. The paper is finished by stating conclusions in Section 4.In this study, an identity authentication system using MJP, found on the back of the hand, is designed and presented. Enrolment phase is the first step of the proposed approach. Pre-processing tasks are accomplished after image acquisition. In that phase fixed-size MJP images are semi-automatically obtained from the hand images and converted to gray level format. The feature selection duties are achieved afterwards with the help of DCV method. Kumar and Zhou stated in their paper [12] that because of the non-uniform reflections and a highly curved surface of the finger, FKPs have non-uniform brightness and low contrast. This makes the recognition process a complicated and intractable task. Due to the similar structures, MJPs are crucial patterns with their low contrast and non-uniform brightness. In spite of these problems, our feature selection phase extracts the features without any enhancement tasks and the matching phase also achieves the comparison using the obtained feature vectors with the help of the DCV-based method which was firstly introduced by Cevikalp et al. for face recognition [25]. The original formation of the MJP ensures to produce unique feature vectors for DCV based method. After designing the system, evaluation process should be applied. To establish a fair comparison, two different databases are used. The first one is previously used in the literature [1], and the second is a non-uniform MJP database established and used in this study. It is publicly available now for further research efforts [26]. Experimental results for both databases are very promising with RRs between 95.33% and 100%, and offering excellent potential for reliable personal identification. Fig. 1shows the working principles of the proposed system.The performance analysis is critically important for a biometric system. To demonstrate the performance of the system a proper evaluation process should be applied with suitable databases. For evaluating the proposed system two different databases are used: the first one is the database used in [1]. It contains 20 subjects with eight images for any hand. Therefore, there are a total of 160 images in the database. A Sony DSC-PS sensor was used to obtain the hand images. Images were captured in JPEG format and measured 2048×1536. The distance between the hand and a blackboard is fixed to 12cm. Three pegs were placed on the board for positioning the hands. The proposed approach achieved 100% recognition accuracy in this uniform database. Fig. 2shows a set of hand images for a randomly selected person from this database.To point out the superior success of the presented approach a non-uniform database was established and used in this study. For established database, non-uniform means that: it is established in different and changing conditions. Contrary to the first database, there is no specially designed environment like specific imaging system, pegs, fixed distances or settled cameras. The hand images of the established database are from 30 volunteers. 10 images are collected from each hand. Totally, the database consists of 600 hand images which are collected over a period of two weeks, in three phases, with an average interval of about seven days. A digital single-lens reflex camera with 10.2 megapixel DX format CCD is used in the image acquisition process. While taking images, the camera was not set a fixed condition, contrarily, the photos of the hands was taken manually with a variety of environmental conditions like lighting, distance between the camera and the hand, angular positions of the camera and the hand. The size of the hand images is 4608×2592. Since it has been created the database over three days and at varying times of the day in natural light without extra or standard light, there is no uniform illumination in the database. The distance of the camera was randomly changed between 15cm and 25cm from the imaging surface. As reported in [9], these factors significantly reduce the performance of a biometric system, and to avoid these corruptive effects, researchers preferred a uniformly illuminated image acquisition device [9]. The hand image set of a randomly selected person from our established database and ROI of the last image are given in Fig. 3. The images from the established database display large variation within the same class on account of distance, angles, shadows, illuminations and pose changes. These corruptive effects make the recognition task much more stringent duty. In that case, for an ordinary method, some pre-processing tasks for MJP images like enhancement, improvement, translation, rotation are unavoidable. However, DCV-based MJP recognition approach was able to distinguish the MJP images without any of these processes; in spite of all these corruptive effects it performs the tasks with high accuracy.The proposed work has two pre-processing tasks: a fixed-sized ROIs of MJPs are obtained from the hand images and these ROIs are converted to gray level format. A semi-automatic method is used for obtaining the ROIs. It works as follows: User determines the ROI of the MJP by manually clicking the center of the MJP. After determination the center point of the ROI, dedicated software separates the fixed sized rectangle ROIs automatically from the hand images. ROIs of a randomly selected individual from the non-uniform database are given in Fig. 4.In this study, the DCV-based feature extraction method was effectively employed to obtain the discriminative feature sets of MJPs. The DCV is an appearance-based method that was introduced and successfully applied for face recognition by Cevikalp et al. [25]. In this work, it is preferred to use the DCV method as given in that reference. Therefore, a brief explanation of the method and its working principles are borrowed it and given below; more theoretical information about the DCV method, such as the mathematical background, theorems and proofs can be found in that reference. Like other appearance-based approaches, the DCV method handles the images as two-dimensional holistic patterns. In the DCV technique, to get the common vectors within-class scatter matrix of all classes is used. The size of the null space of these matrixes is critically important for the success of the DCV technique. If this size is small, accuracy of the system is expected to be poor. In the DCV-based method, the training set contains C classes each of which are composed of N patterns. In that case, the training set is composed of M=N×C patterns.xmirepresents mth sample from the ith class and it is column vector with d-dimensional. Let d>M−C. SW, SBand STare given as follows in Eqs. (1)–(3).(1)SW=∑i=1C∑m=1Nxmi−μixmi−μiT(2)SB=∑i=1CN(μi−μ)(μi−μ)T(3)ST=∑i=1C∑m=1Nxmi−μxmi−μT=SW+SBIn Eqs. (1)–(3), μ and μirepresent the expected value of all patterns and the expected value of the patterns in the ith class, respectively. MJP patterns were projected onto the null space of SWto obtain the optimal projection vectors W and then the projection vectors were obtained by using PCA. To achieve this task, the spanning vectors of the null space of SWmust be calculated. This computation is demanding and difficult duty because of the huge dimension of SW. To accomplish this task by simplifying in a significantly lower-dimensional space, the orthogonal complement of the null space of SWis used. v and ν⊥ represent the range space of SWand the null space of SW, respectively. v and ν⊥ can be given as follows:(4)ν=span{αk|SWαk≠0,k=1,…,r,αk∈Rd}(5)ν⊥=span{αk|Swαk=0,k=r+1,…,d,αk∈Rd}In Eqs. (4) and (5), d>r and r is the rank of SW. {α1⋯αd} is an orthonormal set while {α1⋯αr} is the set of orthonormal eigenvectors. Every MJP samplexmihas a unique formation as given in Eq. (6).(6)xmi=ymi+zmiIn Eq. (6),ymi=Pxmi=QQTxmi∈V,zmi=P¯xmi=Q¯Q¯Txmi∈V⊥,Q=α1⋯αr,Q¯=αr+1⋯αd.In addition, P is the orthogonal projection operator onto v, whileP¯is the orthogonal projection operator onto ν⊥. For any MJP, the reason for the unique decomposition is that ν⊕ν⊥=Rd. In this case, the aim is to computezmi=xmi−ymi=xmi−Pxmi. Especially, an orthonormal basis for v obtained from the normalized eigenvectors αkregarding to the nonzero eigenvalues of SW. The eigenvectors may be achieved by computing the smaller M×M matrix (ATA)’s eigenvectors.SW=AAT, and A is a d×M matrix given in Eq. (7). In the method, for same class's all patterns, the same unique vector (xcomi) will be acquired. The optimal projection vectors are calculated after obtainingxcominamed the common vectors with Eq. (8). In Eq. (9), W is a matrix. The columns of W are the orthonormal optimal projection vectors wk. In Eq. (10), Scomis the scatter matrix of the common vectors and μcomis the expected value of all common vectors.(7)A=x11−μ1⋯xN1−μ1,x12−μ2⋯xNC−μC(8)xcomi=xmi−QQTxmi=Q¯Q¯Txmi,m=1,…,N,i=1,…,C(9)J(Wopt)=argmaxWTSWW=0WTSBW=argmaxWTSWW=0WTSTW=argmaxWWTScomW(10)Scom=∑i=1Cxcomi−μcomxcomi−μcomT,i=1,…,CThen, wkmay be determined by an eigenanalysis of Scomthat is the d×d matrix (Scom=AcomAcomT). To find the eigenvectors and the nonzero eigenvalues of Scom, the smaller matrix (AcomTAcom) sized C×C is used. Acomis the d×C matrix with the form in Eq. (11).(11)Acom=xcom1−μcom⋯xcomC−μcomIf all the common vectors are linearly independent, the C−1 optimal projection vectors are achieved. If two common vectors are equal, then the same vector is obtained for these two classes, and the system cannot distinguish the classes. For MJP images of the ith classxmithe feature vector can be achieved using the following equation:(12)Ωi=xmi,w1⋯xmi,wC−1TThe projection coefficients of the equationxmi,wkare independent of the sample index m. This independence guarantees 100% recognition accuracy for the train data set. The discriminative common vectors, Ωi, that were given in Eq. (13), are used for the identification process. In the test phase, for classification of the test pattern xtest, the feature vector of xtestis determined by Eq. (14).(13)Ωi=WTxmi(m=1,…,N;i=1,…,C)(14)Ωtest=WTxtestAfter comparison with Ωiof each class, the system response will be produced. In that case, the closest discriminative common vector to Ωtestis found and used to recognize the test image. The common vector obtained from the MJPs given in Fig. 4 is presented in Fig. 5.

@&#CONCLUSIONS@&#
