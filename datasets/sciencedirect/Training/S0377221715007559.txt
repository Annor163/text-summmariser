@&#MAIN-TITLE@&#
DASH: Dynamic Approach for Switching Heuristics

@&#HIGHLIGHTS@&#
We introduce a learning framework for solving general mixed-integer problems (MIP).We analyze the tree-search and visualize the evolution of the problem structure.MIP instances gradually change structure as branching heuristics are applied.Tracing the sub-problems during search allows dynamic heuristic selection.Switching heuristics can improve the standard pure MIP branching.

@&#KEYPHRASES@&#
Mixed-Integer Programming,Algorithm selection,Dynamic search heuristics,

@&#ABSTRACT@&#
Complete tree search is a highly effective method for tackling Mixed-Integer Programming (MIP) problems, and over the years, a plethora of branching heuristics have been introduced to further refine the technique for varying problems. Yet while each new approach continued to push the state-of-the-art, parallel research began to repeatedly demonstrate that there is no single method that would perform the best on all problem instances. Tackling this issue, portfolio algorithms took the process a step further, by trying to predict the best heuristic for each instance at hand. However, the motivation behind algorithm selection can be taken further still, and used to dynamically choose the most appropriate algorithm for each encountered sub-problem. In this paper we identify a feature space that captures both the evolution of the problem in the branching tree and the similarity among sub-problems of instances from the same MIP models. We show how to exploit these features on-the-fly in order to decide the best time to switch the branching variable selection heuristic and then show how such a system can be trained efficiently. Experiments on a highly heterogeneous collection of hard MIP instances show significant gains over the standard pure approach which commits to a single heuristic throughout the search.

@&#INTRODUCTION@&#
Mixed Integer Programming (MIP) is a powerful problem representation aimed at solving constrained optimization problems. The goal is to minimize (or maximize) a linear objective function subject to a set of linear inequalities while restricting a subset of variables to integer values only, the so-called integrality constraints, and allowing the remainder of variables to take real values within some predefined boundaries.mincTxs.t.Ax≤bBx=dl≤x≤uxi∈Z∀i∈Ixi∈R∀i∈N∖IUsing this straight forward formulation, where A is a matrix∈Rmxn,b is a right-hand-side vector∈Rm,c is an objective function vector∈Rn,l and u are lower and upper bound vectors∈Rn,and I is a subset of all variablesN={1,⋯,n},it is possible to define a wide variety of problems ranging from scheduling (Kadioglu, Malitsky, Sabharwal, Samulowitz, & Sellmann, 2011) to production planning (Wolsey & Pochet, 2006) to network design (Balakrishnan, Magnanti, & Mirchandani, 1997) to auctions (Zurel & Nisan, 2001) and many others.The most fundamental strategies to solve problems arising in constrained optimization are branch-and-bound and branch-and-cut techniques (Mitten, 1970; Padberg & Rinaldi, 1991). For both, the main idea is to recursively partition the problem into sub-problems (“branching”) and to systematically explore the resulting search spaces. When the objective of the problem is to maximize, a relaxation of the problem is used to compute an over-estimate of the best solution for a given sub-problem (“bounding”). By comparing this bound with the best previously found solution, it can be discovered that a given sub-problem is incapable of containing improving solutions, which allows us to discard (or “prune”) the sub-problem from further consideration. Branch-and-cut, is similar, but instead of utilizing bounds it adds additional constraints (“cuts”) to the original problem that remove suboptimal regions of the problem. Most modern MIP solvers use a combination of branch-and-bound-and-cut.Among the variety of relaxations which can be computed efficiently, the most commonly used are linear relaxations. When the inference mechanism is exhausted, the alternatives are tried (“search”) by selecting a variable and either adjusting its bounds or assigning it to a value based on a variable/value guiding heuristic. Once the decision is made, the inference engine can resume providing further reasoning, tightening the bounds of variables and the objective value. This process is repeated until an infeasible/sub-optimal solution is found. When such a point is reached, the search backtracks to try remaining alternatives.While the efficiency of a branch-and-bound approach depends heavily on the quality of the bounds, for many problems, standard relaxation techniques are reasonably accurate and they can be improved, for example, by automatically adding valid inequalities. Therefore, a key behind the success or failure of this complete search approach is the order in which the variables are selected. Choosing certain variables can have significant effects on the bounds of other variables and improve the objective value, allowing the inference engine to quickly conclude with an improving solution or with its nonexistence. On the contrary, choosing the “wrong” variables can have dire consequences to efficiency, and might lead to exponentially longer run times.Due to the importance of the selection of the branching variable, a number of heuristics with different characteristics have been designed (Achterberg, 2007; Achterberg, Koch, & Martin, 2004; Linderoth & Savelsbergh, 1997). Several of these are based on simple rules, e.g.; Most/Least Infeasible Branching base their decisions on an integer variable’s fractionality in the linear relaxation. Other heuristics, such as Strong Branching test which of the candidates gives the best progress before actually committing to any of them, and similarly, its less costly variant Pseudo-Cost Branching adapts itself as the search progresses by looking at how much the variables actually tightened the linear relaxation on average. There are also search heuristics geared toward feasibility, such as Active Branching (Patel & Chinneck, 2007). Furthermore, there are also hybrid techniques, e.g.; Reliability Branching, which brings together the positive aspects of Strong Branching and Pseudo-Cost Branching. A detailed overview of these and some other heuristics can be found in Achterberg (2007).While the majority of efficient MIP solvers employ these heuristics, they generally tend to only use one of them during search. There have of course been a number of proposed heuristics which collect information during search, e.g., the aforementioned Pseudo-Cost branching based search (Achterberg et al., 2004). Alternatively, there are approaches that employ portfolio algorithms to predict the best heuristic for the problem at hand (Gomes & Selman, 2001; Leyton-Brown, Nudelman, Andrew, Mcfadden, & Shoham, 2003). There are also approaches that switch heuristics after every restart (Fischetti & Monaci, 2011). Work in portfolios has already shown that there is often no single solver or approach that works optimally on every instance (Kadioglu, Malitsky, Sellmann, & Tierney, 2010; O’Mahony, Hebrard, Holland, Nugent, & O’Sullivan, 2008; Xu, Hutter, Shen, Hoos, & Leyton-Brown, 2012). It is also known that throughout the branching process, as certain variables are assigned and the bounds of others are changed, the underlying structure of the sub-problem changes. Therefore, the main idea behind this work is that the efficiency of the search can be much improved if we could use the correct heuristic at the right time during search.In this paper, we show how to identify changes in the problem structure, and based on that, how to make a decision of when it is the best time to switch the guiding heuristic. This study is focused on the variable selection heuristics, but the same idea can be readily extended to other ones, e.g., branching direction, node selection, local search. A preliminary version of this work was presented in Kadioglu, Malitsky, and Sellmann (2012) which only dealt with the well-known set partitioning problem (SPP). In this paper, we expand the research from the SPP with problem dependent heuristics to the much more general MIP solving. We also provide a detailed analysis of how the problem structure changes over time to bring some insights into this line of research. The effectiveness of the proposed approach is demonstrated on real benchmarks that are of interest to the community using state-of-the-art commercial and open-source MIP solvers;IBMILOGCPLEX(IBM, 2013) andSCIP(Achterberg, 2004).Our approach is built-on the instance-specific learning framework which we review in the next section. Then we show how to go beyond instance-specific algorithm configuration and exploit dynamic heuristic selection in Section 3. To motivate our approach, we provide an analysis and visualization of the MIP solving process in Section 4. Our Dynamic Approach for Switching Heuristics is outlined in Section 5. We take advantage of a variety of variable/value selection heuristics listed in Section 7 with complementary strengths (e.g., an inexpensive-less-informed heuristic vs. an expensive-but-more-informed heuristic). Finally, given a feature space that can capture the underlying structure of a problem and a set of search heuristics, we show how to effectively train such a system and learn the best settings under specific conditions. We demonstrate the effectiveness of our approach by embedding it into two high-performance MIP solvers in Section 9.In recent years there has been a growing drive into research of algorithm selection. This includes approaches like SATzilla (Xu, Hutter, Hoos, & Leyton-Brown, 2008; Xu et al., 2012), 3S (Malitsky, Sabharwal, Samulowitz, & Sellmann, 2012), CPHydra (O’Mahony et al., 2008), ArgoSmart (Nikolic, Maric, & Janici, 2009), and many others. For a continuously updated list of relevant research we refer the reader to Kotthoff (2013). While potentially any of these approaches can be applied to dynamically switch heuristics, this paper utilizes Instance-Specific Algorithm Configuration (ISAC) (Kadioglu et al., 2010) which was successfully applied in the special case of the set partitioning problem in Kadioglu et al. (2012). In addition to being demonstrated effective in other domains, as we later demonstrate, the cluster based method naturally lends itself to visualizing and better understanding the underlying process.ISAC works as follows (see Algorithm 1). In the learning phase, ISAC is provided with a portfolio of solvers P, a list of training instances I, their corresponding feature vectors F, and the minimum cluster size c. First, the gathered features are normalized (line 2) so that every feature ranges from[−1,1],and the scaling and translation values for each feature (s, t) is recorded. This normalization helps keep all the features at the same order of magnitude, and thereby keeps larger values from being given more weight than lower ones. Then, the instances are clustered based on these normalized feature vectors (line 3). Clustering is advantageous for several reasons. First, selecting a solver based on a collection of instances generally provides a more robust choice than one could obtain when using individual instances. That is, selection on a collection of instances helps prevent over-tuning and allows generalization to similar instances. Secondly, clustering provides additional transparency on which solver is better for a particular region in the problem space. Tree-based algorithms can do this too while simultaneously providing a level of feature filtering, but clustering makes it easier to have non-linear boundaries without expressly introducing new features. This advantage can also be compensated for by using forests, but with a loss of interpretability.To avoid specifying the desired number of clusters beforehand, the g-means (Hamerly & Elkan, 2003) algorithm is used. This clustering approach assumes that a good cluster is one that has a Gaussian distribution around its center. Starting with all instances being in a single cluster, g-means iteratively calls 2-means, to split a cluster into two. If the new clusters are more Gaussian than the original, the split is accepted and the procedure continues. Once all the instances are grouped, the clusters with fewer instances than some threshold are absorbed by their larger neighbors. While other strategies are possible, a recent work has shown that this methodology often results in clusters that are superior to those resulting from standard approaches such as k-means, X-means, and hierarchical clustering (Collautti, Malitsky, Mehta, & O’Sullivan, 2013).Robust algorithm selections are obtained by not allowing clusters to contain fewer instances than some chosen threshold, a value which depends on the size of the dataset. In our case, we restrict clusters to have at least 50 instances. Beginning with the smallest cluster, the corresponding instances are redistributed to the nearest clusters, where proximity is measured by the Euclidean distance of each instance to the cluster’s center. The final result of the clustering is a number of k clusters Si, and a list of cluster centers Ci(line 3). Then, for each cluster of instances Si, a favorable solver Aiis chosen (line 5).When running algorithm A on an input instance x, ISAC first computes the features of the input (line 2) and normalizes them using the previously stored scaling and translation values for each feature (line 3). Then, the instance is assigned to the nearest cluster (line 4). Finally, ISAC runs the best solver for the cluster, Ai, on x (line 5).Algorithm selection techniques like ISAC, as described in the previous section, have been shown to improve solver performance in a number of domains by selecting the best solver or approach for a particular instance (for Constraint Satisfaction Problems (CSPs) (O’Mahony et al., 2008), for Boolean Satisfiability (SAT) (Malitsky et al., 2012; Xu et al., 2008; Xu et al., 2012), and for Mixed-Integer Problems (MIPs) (Kadioglu et al., 2012)). Here we argue that additional improvements can be achieved by designing solvers that can dynamically switch between search strategies, selecting the most appropriate heuristic for the sub-problem at hand. The key observation is that given a specific MIP instance, as the tree-search progresses branching on variables and updating bounds, each encountered sub-problem is an instance of the original MIP problem. However, as more decisions are made during search, the structure of the problem can change dramatically, such that the guiding heuristic that was deemed good for the original problem may no longer be the best strategy. Therefore, at a high level, our goal is to create a branch-and-bound solver that also analyzes the structure of the current sub-problem, which we refer to as a sub-instance. Based on a representative set of problem features, this analysis would predict which heuristic is likely to perform best and should thus be employed for subsequent decisions. We refer to such a strategy as a Dynamic Approach for Switching Heuristics (DASH). For this purpose, we would need a feature space and a similarity measure between problem instances.In order to monitor changes in a problem, we need a set of informative features that can capture as many aspects of the problem and its sub-problems as possible without becoming too expensive to compute on-the-fly. In Kadioglu et al. (2012) a set of problem features were proposed in the context of solving MIPs, similar to those used for CSPs (O’Mahony et al., 2008) and SAT Xu et al. (2008)Xu et al. (2012). More specifically, we compute the:•Percentage of unset integer variables in the sub-instance;Percentage of unset integer variables in the objective function of the sub-instance;Percentage of active equality and inequality constraints;Statistics (min, max, avg, std) on the number of active variables in each constraint;Statistics on the number of active constraints in which each variable is used.Features of variables are further broken down by variable type; continuous, integer and binary. The resulting set is composed of 40 features. We also considered including features like the depth of a sub-instance in the branch-and-bound tree, but feature filtering using information gain typically showed these as being insignificant.As our computational results demonstrate, these 40 features can be tracked efficiently during tree-search and can distinctively characterize the sub-instances.The feature space together with the Euclidean distance metric offers a measure of “similarity” between instances. This can in turn be used to partition the data with g-means, a clustering approach employed by the original ISAC methodology. However, unlike for a regular algorithm selection approach, the clustering can not be solely comprised of a representative set of MIP instances. As shown in Kadioglu et al. (2012), the instances that are encountered during the tree-search are likely to be very different from those at the root node. Thus, it is possible to face radically different instances than those in the initial datasets. As a result, this necessitates the extension of the training set to include sub-instances that are sampled by running different heuristics.In particular, we create three such extended datasets. The first dataset, extDatasetC, is generated by runningIBMILOGCPLEXon each instance of the training set. The actual implementation and the set of heuristics is different forSCIP. Therefore a second set, extDatasetS is created which contains the sub-instances encountered when using that solver. For reasons explained later in Section 9.3, we also include a third dataset with only a subset ofSCIPheuristics, extDatasetSr.Our outline of switching heuristics dynamically so far raises a natural question: Do sub-instances fall far enough from an original instance that their cluster changes? To answer this question, we performed an initial analysis on the extended datasets and analyzed the clusters of the sub-instances. The results are presented in Table 1. In fact, more than half of the collected sub-instances belong to different clusters than those of the original problem instances.Furthermore, Fig. 1shows the evolution of the ISAC solving process in the feature space for two representative problem instances pmedcap_p3 and regions-goods200-bids1000. The feature space is projected onto two dimensions using Principal Component Analysis (PCA) (Abdi & Williams, 2010) for visualization purposes. The cluster boundaries are represented by solid lines, and the best heuristic for each cluster is represented by a unique symbol at its center. The nodes are colored based on the depth of the tree showing all observed sub-instances. Throughout the search, we commit to the same solver (heuristic) that ISAC found to be the best for the original cluster. Even though the same heuristic is used at all times, notice how the instances shift toward a different cluster as the depth increases. We argue that this behavior should be monitored, and when such significant change occurs, the search guidance should be switched to the heuristic that best fits the new problem structure.To provide further insight, Table 2shows the distribution of instances and sub-instances for each clusterization of the extended datasets. We can see which clusters contain the original instances, and which clusters emerge when sub-instances are created. Note that there is no relation between clusters of different datasets (for example, cluster 6 on extDatasetC and cluster 6 on extDatasetS have a void intersection).What emerges from the information presented in Table 2 is that the feature space for the extended datasets can be partitioned, demonstrating the highly dynamic aspect of the MIP solving process. For example, cluster 7 of extDatasetC contains 19 percent of the data, while, surprisingly, none of the original instances belong to it. This means that there is a chance that the sub-instances in cluster 7, that are “similar” due to being grouped together, could prefer a different solver than the one assigned for the original instances. Furthermore, the sub-instances of cluster 7 derive from instances that belong to several other clusters, therefore likely to exhibit a different preferred solver. The same observations can be made on cluster 5 of extDatasetS and on cluster 4 of extDatasetSr, that contain respectively 24 and 17 percent of the whole dataset but have no original instance that belong to them. This is exactly where the potential of this work lies; exploiting the fact that structural changes do occur during search, which we can characterize effectively, and react to.Motivated by the analysis presented in the previous section, we present the details of our Dynamic Approach for Switching Heuristics (DASH) in Algorithm 2. In accordance with the Instance-Specific Algorithm Configuration (ISAC) methodology (Kadioglu et al., 2010), DASH assumes that instances that have similar features share the same structure and so will yield to the same algorithm.As outlined in Algorithm 2, DASH is provided with a sub-instance, the heuristic employed by its parent, the centers of the known clusters, and a list of available heuristics. Because extracting features can be computationally expensive and because switching heuristics at lower depths of the search tree (further from the root node) has less impact on the quality of search, DASH only chooses to switch the guiding heuristic up to a certain depth and only at predetermined intervals (line 2), choosing the parent’s heuristic in all other cases (line 10). When a decision needs to be made, the approach computes the features of the provided sub-instance (line 3) and determines the nearest cluster based on the Euclidean distance (line 7). In theory, any distance metric can be used here, but in practice we found Euclidean distance to work well for the general case. Consequently, DASH employs the heuristic that has been assigned to that cluster (line 12). This assignment of heuristics is obtained by determining the best one for each cluster using a tuning algorithm, as later described.The key component of the algorithm that determines the success (or failure) of our approach is the correct assignment of heuristics to clusters. This information is learned during an off-line training phase. Following its success on set partitioning problems, we employ a similar procedure as was first proposed in Kadioglu et al. (2012). For each instance in the training set we compute an assortment of sub-instances that are observed when using each of our heuristics. This extended problem set (extDataset) allows us to get a better overview of the type of sub-instances DASH will be encountering, as opposed to using the original training instances alone. Computing the features of the extended problem set, the instances are clustered using g-means (Hamerly & Elkan, 2003) as described in Section 2.Once all the instances and sub-instances are clustered, a heuristic for each cluster needs to be determined. However, an important caveat in this scenario is that the selection of a certain heuristic for a cluster further affects other decisions. Namely, the sub-instances that will be observed during search heavily depend on the heuristic used at the parent node. Therefore, the learning strategy must consider its decision with respect to the type of problems such a decision would likely generate. That is, we want the selection of a heuristic to be made with the fore-knowledge of sub-problems it could generate. This can be achieved by employing a parameter tuner to simultaneously assign heuristics to all clusters. In our case we use GGA (Ansótegui, Sellmann, & Tierney, 2009), a genetic algorithm for finding parameter assignments that yield improved performance of a solver on a specific benchmark. The main reason for taking this approach is that configuration, and GGA in particular, is known to work well when the effect of changing parameters is a priori unknown.Specifically, the algorithm configurator searches for the best assignment of heuristics to clusters by directly seeing which such assignment leads to the best overall performance. This means that for training, the sub-instances are only used to find the clusters a solver is likely to encounter. Meanwhile the parameters of the solver are categorical values that specify the heuristic for each such cluster. The actual evaluation of assignment of heuristics to clusters, however, is performed only on the original set of training instances. Such an approach thus automatically takes into account the type of sub-instances that would be generated by selecting a particular heuristic at a particular point in the search tree.

@&#CONCLUSIONS@&#
We introduced a method that advances the idea of instance-specific algorithm configuration to the fine-grained level of sub-instance configuration and generalized dynamic heuristic selection for MIP problems. Using a parameter tuner, we showed how to effectively learn an assignment of variable selection heuristics to sub-instances for a rather small set of training instances even when the branching decisions determine the distribution of instances that must be dealt with deeper in the tree. The method can be readily extended to other types of heuristics.We presented a set of descriptive, general features for MIP and showed how they can be monitored efficiently as enhancements to standard off-the-shelf solvers. We traced the problem solving process and used this knowledge dynamically during search to switch the branching heuristic for sub-instances. This approach, named DASH, was implemented in two high-performance MIP solvers and was evaluated on a set of hard, highly heterogeneous MIP instances. It was found that the approach clearly outperformed the readily-available best pure branching heuristic as well as its coarse-grained instance-specific predecessor. We conclude that dynamic heuristic selection can be very beneficial compared to committing to a single heuristic, yet the existence of complementary heuristics, a diverse set of instances, and descriptive features are also important.