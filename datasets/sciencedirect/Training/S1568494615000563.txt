@&#MAIN-TITLE@&#
Using an unsupervised approach of Probabilistic Neural Network (PNN) for land use classification from multitemporal satellite images

@&#HIGHLIGHTS@&#
Using of Probabilistic Neural Network (PNN) to multichannel image classification.Automatic process to transform the supervised PNN classification to unsupervised.Combination of PNN, hierarchical clustering and cluster validity Index.Land use classification gives a precision with about 3.44% of error.Can be used to large surfaces where the information on soil and crops is limited.

@&#KEYPHRASES@&#
Unsupervised classification,Probabilistic Neural Network,Ward's method,Cluster validity index,Land use,LANDSAT and SPOT images,

@&#ABSTRACT@&#
The aim of this work is to develop an unsupervised approach based on Probabilistic Neural Network (PNN) for land use classification. A time series of high spatial resolution acquired by LANDSAT and SPOT images has been used to firstly generate the profiles of Normalized Difference Vegetation Index (NDVI) and then used for the classification procedure.The proposed method allows the implementation of cluster validity technique in PNN using Ward's method to get clusters. This procedure is completely automatic with no parameter adjusting and instantaneous training, has high ability in producing a good cluster number estimates and provides a new point of view to use PNN as unsupervised classifier. The obtained results showed that this approach gives an accurate classification with about 3.44% of error through a comparison with the real land use and provides a better performance when comparing to usual unsupervised classification methods (fuzzy c-means (FCM) and K-means).

@&#INTRODUCTION@&#
The classification is one of the most useful tasks of human behavior. It aims at identifying groups of similar objects in the sense of a homogeneity criterion and therefore helps to discover the distribution of patterns and interesting correlations in large data sets. Its application has an important role for resolving many problems in pattern recognition [1], imaging, color image segmentation [2], data mining [3] and in different domains such as medicine [4], biology [5,6], marketing [7], energy [8], remote sensing especially land use [9–11], etc.There are two main methods used for classification: supervised and unsupervised. In the first one, the user defines the classes which can be conceived as a finite set. The main task is to search the patterns and then construct their corresponding mathematical models. The consistency of those models is evaluated based on the actual data. The most used supervised classification methods are: maximum likelihood classification (MLC) [12], parallelepiped method (PP) [13] and fuzzy sets [14-18], neural networks (NNs) [19,20], support vector machines (SVM) [21,22] and computational intelligence [23]. In other hand, the basic task of unsupervised learning methods is to develop classification labels automatically. Unsupervised algorithms seek out similarity between pieces of data in order to determine whether they can be characterized as forming groups labeled clusters. In remote sensing for example, the unsupervised methods commonly used are split-and-merge [24], ISODATA [25], K-means, fuzzy c-means (FCM) [26,27], NNs based methods [28,29] and scale space techniques [30].Zhang [31] reported that the classification is the most investigated topic of NNs. Furthermore, it has been noted that NNs are a promising alternatives to various conventional classification methods. The advantages of using NNs are due to the following theoretical aspects. First, NNs are self-adaptive methods as they can adjust themselves to data without any explicit specification of functional or distributional form for their underlying structure. The user can adjust parameters of learning by setting up the initial weights of the network and selecting the correct number of hidden layers and nodes at each layer. Second, NNs can approximate any function with arbitrary accuracy [32–34]. So, any classification procedure seeks a functional relationship between the group membership and the attributes of the object. In fact, if the user disposes of different networks with a variety of methods using a multivariate training data formats, it can be easy to get an accurate identification of this underlying function. Finally, NNs are able to estimate the posterior probabilities using the Bayes rule. These probabilities provide the basis to establish classification rule and perform statistical analysis [35]. For classification tasks, the Probabilistic Neural Network (PNN) is one of the most used NN. It is a special form of radial basis function NN (RBFNN). In addition, it is considered as an implementation of the Bayes optimal decision rule in the NN form based on nearest neighbor classifiers [36,37]. Several recent studies [4,8,38–46] used PNN for classification and showed that this method provides satisfactory results if the initial target classes are defined correctly. In this way, finding the basis function centers (classes) with their appropriate number is an important step to achieve suitable classification. This can be proved by several reasons as cited by Tsekouras and Tsimikas [47]. First, the activation of each hidden node depends exclusively on the distance between the center and the current input vector. Second, in the neuron construction, the distribution of neuron's receptive fields across the feature space is strongly linked to the locations of the respective centers. Third, the underlying data structure is revealed by these centers. They affect directly the following neurons output. Fourth, the estimation of the widths directly depends on the locations of the centers. The classification performance depends heavily on selecting appropriate spread values. Too small spread values give very spiky Probability Density Functions (PDFs) whereas too large spread values smooth out the details. The idea of using clustering algorithms in training RBFNN design has been addressed by several authors [47–55]. Pedrycz [50] applied the conditional fuzzy clustering (modified FCM) in the input space. This method has embedded the output data using the clusters weights calculated as feedback information into the input mechanism. Uykan et al. [55] employed the K-means model and showed that the main impact of the input–output clustering is the minimization of an upper bound of network's mean square error. Staiano et al. [54] used fuzzy clustering to generate the clusters in the input space and for each cluster established an input–output relationship through a local linear regression models. Tsekouras and Tsimikas [47] proposed an algorithm to select the optimal values for the basis function centers of RBFNN. This algorithm uses the output space to adjust the input partition by combining input–output fuzzy clustering and particle swarm optimization.Based on the state-of-the-art cited above, it seems that the major challenge in clustering is to determine the optimal number of clusters to better fit a data set. In the most clustering methods, experimental evaluations of 2D/3D-data sets are used in order to visually check the validity of the results (i.e. how well the clustering algorithm discovers the clusters of the data set). But in the case of large multidimensional (more than three dimensions) data sets like multidimensional remote sensing images, effective visualization of the data set would be difficult. Moreover, the perception of clusters using available visualization tools is a difficult task for humans that are not accustomed to higher dimensional spaces and complex sets of data. To overcome this problem, many techniques based on cluster analysis have been developed in order to group either the data or the variables into clusters. To do so, many criteria have been described like partitioning methods, hierarchical clustering, etc. One of the most widespread hierarchical clustering methods is the Ward's method [56–64]. According to Hands and Everitt [64], this method achieves good results than other hierarchical methods (single-link, complete linkage, median, average linkage, etc.) especially when the group proportions are approximately equal.In this paper, we design an unsupervised approach for land classification. It is based on a different way to implement the clustering in PNN (RBFNN design). The Ward's method [56] is used in training the input targets. A cluster validity function, generally applied on fuzzy clustering [65–67], is developed in the hidden layer output space of PNN by varying the number of classes to find the optimal number of clusters. The proposed model is firstly tested for Fischer's Iris data set [75,76], synthetic grayscale and RGB digital images. The consistency of this approach is assessed through a comparison with FCM clustering using the concept of cluster analysis. After, this approach is applied for time series remote sensing images acquired by LANDSAT and SPOT to build land use map. Finally, the obtained results are then validated with the real land use and compared with the results of usual classification methods (FCM and K-means).The region of interest is an irrigated area located in the Haouz plain in the center of the Tensift basin (Central Morocco), 40km east of Marrakech city. The climate is of semi-arid Mediterranean type with an average annual precipitation of about 250mm of which 70% falls during winter and spring. The area covers about 2800ha and is mostly flat. It has been extensively studied during the 2002–2003, 2003–2004 and 2005–2006 agricultural seasons [69–72]. The main land cover classes are cereals; mostly wheat, then barley and a significant portion is left in fallow or not cultivated (Fig. 1). More details about the study area and the climate of region can be found in [68–72]. The vegetation development in this area is affected by a great inter-annual and/or intra-annual heterogeneity [72]. Then, the land cover maps required annual update. Therefore, the effort was directed toward the development of land cover classification methods based on remote sensing data. A time series of images acquired by SPOT and LANDSAT was collected during the growing season of wheat (November 2002–June 2003) in order to extract vegetation profiles. Due to cloudiness or uncertainty in atmospheric corrections, only seven images have been used in this study. These images with the size of 122,500 pixels arranged in 350 columns and 350 rows were radiometrically calibrated and atmospherically corrected based on the reflectance of an invariant objects and transformed to NDVI maps [72]. The NDVI was derived from red and near infrared reflectance bands as follows:(1)NDVI=NIR−REDNIR+REDwhere NIR and RED are the reflectance measured in the near-infrared and red band respectively.Introduced in 1990 by Specht [36,37], the Probabilistic Neural Networks (PNNs) are based on the concept of utilizing a non-parametric estimator (Parzen window) for obtaining multivariate probability density estimates. In contrast to classical RBFs, PNNs are only used for classification and they compute conditional class probabilities p (class k/x) for each of C classes. A typical PNN consists of an input layer, a pattern layer (hidden layer) and a competitive output layer. The structure of a PNN is shown in Fig. 2. Similar to RBFs, PNNs receive D-dimensional feature vectors x=(x1,…,xD) as input. This input vector is applied to the input neurons xi(1≤i≤D) and is passed to the neurons in the hidden layer. Here, the hidden nodes are collected into groups: one group for each of the C classes. Each hidden node in the group for class k (1≤k≤C) corresponds to a Gaussian function centered on its associated feature vector in the kth class (there is a Gaussian for each exemplar feature vector) called Probability Density Function (PDF). PDF for a single sample xkis written as follows:(2)fk(x)=1(2π)D/2σDe−((||x−xk||2)/(2σ2))where σ is the smoothing parameter for Gaussians, D is the dimension of the input vector x and ||x−xk||=∑i(x−xk)2 is the Euclidean distance between vectors x and xk. All of the Gaussians in a class group feed their functional values to the same output layer node for that class, so there are C output nodes. The kth output node sums these multivariate densities to produce a vector of probabilities representing the average of the PDF's for C samples:(3)pk(x)=1(2π)D/2σDC∑k=1Ce−((||x−xk||2)/(2σ2))Finally, a competitive transfer function gives 1 for the input class which has the maximum joint PDF and 0 for all other classes. An unknown input x belongs to class k if: pk(x)>pk′(x) for all k′≠k. Therefore, the neuron in the decision layer determines the class belongingness of the pattern x by (4) in accordance with Bayes's decision rule under the following assumption:(4)c(x)=argmax{pk(x)},k=1,2,…,Cwhere c(x) is the estimated class of the pattern x.PNN is commonly used as supervised classifier in various applications but it is less exploited in remote sensing. Foody [73] proved that PNN was able to accurately map land cover for an agricultural site better than other networks like Multilayer Perceptron (MLP) and RBFNN. Furthermore, the accuracy of the PNN classification could be increased through the incorporation of prior probabilities of class membership. However, the accuracy of each classification could also be degraded by the presence of an untrained class [73]. Thus, it is essential to choose the appropriate classes.PNN algorithm requires initially setting of the modes (centers of the Gaussian functions), which are not evident to find. The choice of modes and their number should be without errors. An evaluation methodology is required to determine and to choose the optimal number of clusters C*. This method is usually called the cluster validity. To make PNN automatic, we used the summation of PDFs in the output of its hidden layer which takes the form of a matrix of probabilities. This matrix will allow to calculate the validity index (V) according to the variation of the class number C in a given interval [Cmin; Cmax] in order to determine the adequate number of clusters. Cminand Cmaxare respectively the minimum and maximum number of possible classes fixed firstly by the user. The optimal number of classes is obtained when V reaches its maximum value. The flowchart (Fig. 3) illustrates the developed automation procedure for PNN. Fig. 4describes its functional stages as summarized in the following steps:(1)Proceed by hierarchical agglomerative classification using Ward's method applied to input data for obtaining the C clusters.Apply the PNN algorithm by implementing the C clusters as targets input founded in step 1.Calculate V corresponding to the obtained classification. V requires the values of the probability matrix produced in the output of PNN's hidden layer (see Section 4.2).Repeat step 1 for different cases of C. The number of classes C can be chosen in an interval [Cmin; Cmax]. Otherwise, all possible numbers of classes are taken.Select the optimal number C* of clusters corresponding to maximum value of V.In statistics, Ward's method [56] is a criterion applied in hierarchical agglomerative clustering. This method consists in providing a set of partitions into less detailed classes obtained by combining successively the parties. The idea is to build a dendrogram or a tree of data that successively merges similar groups of points. This dendrogram is obtained by hierarchical ascending: We combine at first the two closest elements which form a “summit”. It remains only (n−1) objects and we iterate the process until a complete group. The general pseudo code of the hierarchical agglomerative clustering is writing as follow:(1)Begin with N clusters, each containing one object and number the clusters 1 through N.Compute the between-cluster distance dist(A, B) as the between-object distance of the two objects in A and B respectively with A, B=1, 2, …, n. Let the square matrix D=dist(A, B). If the objects are represented by vectors, use the Euclidean distance.Find the most similar pair of clusters r and s, such that the distance dist(A, B) is minimal among all the pairwise distances.Merge A and B to a new cluster C and compute the between-cluster distance dist(C, k) for any existing cluster k≠A, B. Once the distances are obtained, delete the rows and columns corresponding to the old cluster A and B in the D matrix, since A and B do not exist anymore. Then add a new row and column in D corresponding to cluster C.Repeat Step 3 a total of N−1 times until there is only one cluster left.Ward's method is distinct from other methods because it uses an analysis of variance approach to evaluate the distances between clusters and therefore it is very efficient. At each stage, the Ward objective is to find those two clusters whose merger gives the minimum increase in the total error sum of squares of the within-group (or distances between the centroids of the merged clusters). The Ward distance used between two classes is the distance of their centroids squared, weighted by the size of the two clusters. It is defined as follows:(5)dist(A,B)=pApBpA+pBd2(gA,gB)where gAand gBare the gravity centers of classes A and B with the weight pAand pB.Because the Ward method minimizes the sum of within-group sums of squares (squared error criterion), the clusters tend to be hyperspherical, i.e. spherical in multidimensional D-space, and to contain roughly equal numbers of objects if the observations are evenly distributed through D-space. This criterion is the most accurate in hierarchical ascending clustering on Euclidean data particularly when the elements are close. In this paper, we used the Ward's method to obtain the Gaussian functions centers in the hidden layer. In order to reduce the overlap of the centers, the widths of the radial basis functions are locally determined using a spread equal to the half of the minimum distance between the neighbor centers.Cluster analysis aims at identifying groups of similar objects, therefore helps to discover interesting distribution of patterns and correlations in large data sets. Most of clustering algorithms need to know the right number of classes C*. However, it is generally difficult to predict this number for accurate separation of data set. If it is too large, one or more good compact clusters may be broken. In contrast, if it is too small, more than one separate cluster may be merged. The problem for finding C* is usually called cluster validity. A large number of cluster validity indices are available in the literature [65–67,74]. In this paper, the proposed cluster validity function is inspired from the Dave's Modified Partition Coefficient (MPC) used for fuzzy partition [74]. MPC is defined as:(6)MPC(C,U,N)=C∑j=1N∑i=1C(uij)m−NN(C−1)where m is the fuzzification coefficient, N the number of vectors to be classified, C the number of classes and uijis the element of the partition matrix U of size C×N representing the membership of the pattern xjto the cluster Ci.Before introducing the proposed cluster validity index V, we first use the summation of Gaussians produced by the computed clusters at the output of PNN's hidden layer (see Section 3). This latter retrieves the probability matrix P=[pjk]C×Nwhich represents the membership of the kth vector to the jth data input. As P takes the same form of U in Eq. (6) and the PNN's competitive function reaches the maximum of these probabilities, V is given by the following equation:(7)V(C,P,N)=C∑j=1Nmax1≤k≤C(pkj)−NN(C−1)where P=[pjk]C×Nis the matrix membership in the output of PNN's hidden layer representing the kth vector of probabilities for the jth data input and max (P) is the maximum value of P associated to each input. In others words, max (P) represents the closest cluster to the input. The values of V range in [0; 1]. By varying C, the maximum proposed index corresponds to the optimal distribution of clusters and produces the best clustering performance for the dataset.We realized different tests to different types of data. We started with the famous Fischer's Iris dataset then we tested the method to simple case of synthetic grayscale image and finally to digital RGB images. All results are compared with results of the FCM clustering algorithm using the same concept of cluster validity.This dataset contains random samples of flowers belonging to three species of iris flowers setosa, versicolor and virginica [75,76]. For each of the species, fifty observations for four features (sepal length, sepal width, petal length and petal width) are recorded. We applied the proposed algorithm and FCM clustering by choosing the number of classes C in the range [Cmin=2; Cmax=6]. Table 1summarized the obtained results. Both of the methods give the optimal cluster number estimate C*=3 for the Iris data set. But the difference is in the classification accuracy. Table 2shows the detected samples of the three Iris flowers and the accuracy of classification using the two algorithms with a notable advantage of the proposed PNN classifier.We tested the proposed method on a synthetic image representing a gradient of eight levels of gray. In this case, we choose a number of classes C in the range [Cmin=3; Cmax=10] to see if the algorithm is capable to determine the exact number of classes. Table 3summarized the obtained results by the unsupervised PNN and FCM. The maximum validity index (0.969) corresponds to class number of C*=8 for the proposed approach while C*=7 for FCM clustering. Fig. 5represents the original and the classified images using the two methods. We can note easily that FCM has detected a false number of classes.In this case, we increase the color space to three channels (Red, Green and Blue). We used RGB image of Moroccan tile which contains five colors to show if the proposed algorithm is able to give the exact number of colors and to perform meaningful classification. The range of C chosen is [Cmin=2; Cmax=8]. The results are illustrated in Table 4and represented in Fig. 6.We tested the same concept of cluster validity for FCM and PNN on different types of data. The results (Figs. 5 and 6 and Tables 2–4) showed that the proposed method gives the appropriate number of classes where the FCM technique fails. Regardless the number of channels in an image, the proposed method was able to distinguish between different classes. From these performed tests, we can see that the unsupervised PNN is a valid reliable classifier.After testing and comparing the proposed approach with FCM clustering over several data sets (Fischer's iris data, grayscale and RGB digital images), this approach is applied for a sequence of seven time series of NDVI remote sensing images acquired by LANDSAT and SPOT to build land use map. The obtained results of land cover are compared with the real data collected by land sampling in the framework of VALERI Program [72,77].For large data sets like multi-layer remote sensing images, it is desirable to firstly apply spatial classification scene by scene in order to reduce the number of color. Then the results are classified in time.To use an image as feature vector of PNN input, a serialization procedure is applied to transform the matrix image to a vector (taken row by row or column by column) providing that the opposite transformation is done to restore the output classified image.We applied the proposed model to each image of the seven NDVI scenes for different number of classes C in the range [Cmin=5; Cmax=15]. We chose the value 5 as the minimum of classes according to the minimum diversity of the land in the studied area [72]: bare soil, cereals, trees, trees with herbs, fallow, etc. The maximum number of classes chosen is the value 15 in order to represent more levels of NDVI and to keep the majority of the information from each scene. Table 5showed for each scene the optimal number of classes C* obtained by comparing V values. Table 6presents the number of classes obtained in each scene before and after spatial classification. The obtained results showed that after the classification, the scenes with a narrow histogram (7 Nov 2002, 25 Dec 2002 and 27 Jun 2003) took 5 as the minimum number of classes while the scenes with a large histogram (26 Jan 2003, 11 Feb 2003, 31 Mar 2003 and 18 May 2003) took a number of classes greater than 10 (Fig. 7). It is logical and reasonable because in the wheat agricultural season, there is less verdure density in the period from 7 November to 25 December corresponding to cultivation period and harvest (after 27 June) while the period from 26 January to 18 May representing the growth phase showed more verdure density and several types of crops (wheat, barley, fallow, etc.).The spatial classification adopted here is a compression strategy which reduces the number of levels of NDVI values in each scene without affecting the information contained in it. Therefore, the number of NDVI temporal combinations is reduced from 121,493 to 4619 allowing a minimization of the running process time in the following stage.To extract the different temporal behavior of NDVI, we applied the proposed algorithm to the time series of seven scenes spatially classified. Cluster validity index V by varying C in the range [Cmin=5; Cmax=15] is represented in Table 7. As shown in this table, the maximum value of V is about 0.99 which corresponds to fifteen classes. Fig. 8illustrates the temporal evolution of the fifteen obtained NDVI profiles which are used next to identify the main crop types.The crop identification method was designed based on field observations. These field data were made up of some thematic classes, including all the species encountered and their combinations. Based on the temporal evolution of the fifteen obtained NDVI profiles (Fig. 8), they can be merged to six following main classes:-Bare soil class (profile 4) is evident to find. This class has a constant value of NDVI around 0.15 which corresponds to clay soil [71]. Some fluctuations of NDVI could be explained by the variation of soil moisture and by small grown herbs due to the rainfall events.Tree classes are considered as NDVI profile relatively constant over time and above 0.18 taking into account that the majority of them are evergreen trees (olive and citrus trees). Moreover, there are two tree classes. The first one is tree on bare soil class (profile 5) which is clearly identified by NDVI values higher than 0.43 with limited variations in range of 0.17. The other class (profile 6 and 7) is characterized by tree profiles having high NDVI range variations (>0.17) labeled as tree with herbs (i.e. on annual understory).Annual crops (cereals) classes are defined by NDVI values rising above 0.18 showing significant vegetation biomass. Also these classes are characterized by NDVI values below 0.18 at the beginning and at the end of the growth phase (i.e. a period of bare soil) which can make a distinction with evergreen tree classes. Annual crops include mainly cereals like wheat and barley which can be divided in early and late classes considering its temporal NDVI profiles [71]. Five profiles (profile 8, 9, 10, 11 and 12) representing early (wheat/barley) cultivated before 15 December and three others (profile 13, 14 and 15) corresponding to late (wheat/barley) cultivated after 15 January with narrow growth phase.Fallow land class can be defined as land with almost no vegetation or very poorly developed wheat with low NDVI values (i.e. rainfall wheat). This class is characterized by NDVI values less than 0.4 in the growth phase (profile 1, 2 and 3).Table 8showed the land cover classes which brand each NDVI evolution after identification.After merging, the obtained classes give the land cover map illustrated in Fig. 9with the following percentages: 17.24% of bare soil, 12.14% of fallow, 39.47% of late (wheat/barley), 22.44% of early (wheat/barley), 2.57% of trees on bare soil and 6.13% of trees with herbs. The obtained results are in agreement with the previous studies using the same data set but with other techniques of classification [71,72]. Er-Raki et al. [71] used the K-means to classify the cereals and they found two main classes: early and late sowing wheat as it has been found in this work. Simonneaux et al. [72] used the supervised classification method based on the use of simple phenological criteria of each crop. This method is called decision tree [78–80] which uses the minimum, the maximum or the range of NDVI as the phenological criteria. They obtained a general land cover (annual crops, trees, annual crops+trees, bare soils). By comparison with the presented classification, they did not classify the annual crops class on early and late sowing cereals and did not separate it from the fallow land class. In Spain, Julien et al. [9] used the Yearly Land Cover Dynamics (YLCD) approach based on annual behavior of LST (Land Surface Temperature) and NDVI. A time series of LANDSAT-5 images has been used to classify an agricultural area into crop types using the maximum likelihood classification. They obtained the main classes: cereals, irrigated and non-irrigated crops. As in this work, wheat and barley were merged in a single class (cereals) due to their NDVI similarity. While the irrigated and non-irrigated crops were separated in different classes due to strong differences in NDVI and LST annual behaviors.In order to check the accuracy of our approach, we compared the obtained land use with the real one established in the study region. During the 2002–2003 season, data sets were collected by VALERI Program [72,77] on a series of 450 sample plots distributed across the plain (Fig. 10and Table 9). We merged the classes representing the same type of cover: Building is added to bare soil class, olive trees to trees on bare soil class and barleys to cereals class in order to make a comparison with the results of classification. To visualize the performance of the proposed algorithm, a matching matrix is presented in Table 10. This matrix was obtained by comparison of the proposed automatic PNN classification with the validation data mentioned above. Table 11and Fig. 11showed the results of this comparison. The overall accuracy is computed as the proportion of true prediction results (samples correctly classified) [81]. The obtained classes shown in Table 11 are recognized with an overall accuracy of 96.56% which is higher in comparison with other studies [9,72]. This high accuracy demonstrates that the proposed approach is globally able to retrieve automatically and accurately the existing crop types in the region. The class of alfalfa is characterized by a NDVI profile with frequent variation due to several cutting thus it was not recognized. More successive scenes with no cloudiness could overcome this miss-classification.In order to bring to light the performance of the proposed method, a comparative study with other usual classification methods (FCM, K-means) is done by using the same sequence of seven time series of NDVI images. Land cover maps obtained by using FCM and K-means are shown in Figs. 12 and 13, respectively. The performance comparisons between the three methods are displayed in Table 12. As expected, FCM method has given a less accuracy (79%) and a less cluster number estimation. Two classes (trees with herbs and trees in bare soil) are merged due to their similar clusters distribution. Regarding K-means method, it has done a reasonable job with 82.02% of accuracy and detailed classes (good number and type). As a conclusion, the proposed approach using PNN provides better results with higher accuracy (96.56% of overall accuracy) in comparison with other methods.

@&#CONCLUSIONS@&#
