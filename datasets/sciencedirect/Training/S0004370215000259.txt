@&#MAIN-TITLE@&#
Playing with knowledge: A virtual player for “Who Wants to Be a Millionaire?” that leverages question answering techniques

@&#HIGHLIGHTS@&#
We model a virtual player for “Who Wants to be a Millionaire” game.The virtual player uses Question Answering over Wikipedia and DBpedia knowledge.We performed experiments on the Italian and the English version of the game.The virtual player outperforms human players to correctly answer to questions of the game.The virtual player outperforms human players to play real games both in terms of level of the game reached and average income.

@&#KEYPHRASES@&#
Language game,Question answering,Natural language processing,Artificial intelligence,Decision making,

@&#ABSTRACT@&#
This paper describes the techniques used to build a virtual player for the popular TV game “Who Wants to Be a Millionaire?”. The player must answer a series of multiple-choice questions posed in natural language by selecting the correct answer among four different choices. The architecture of the virtual player consists of 1) a Question Answering (QA) module, which leverages Wikipedia and DBpedia datasources to retrieve the most relevant passages of text useful to identify the correct answer to a question, 2) an Answer Scoring (AS) module, which assigns a score to each candidate answer according to different criteria based on the passages of text retrieved by the Question Answering module, and 3) a Decision Making (DM) module, which chooses the strategy for playing the game according to specific rules as well as to the scores assigned to the candidate answers.We have evaluated both the accuracy of the virtual player to correctly answer to questions of the game, and its ability to play real games in order to earn money. The experiments have been carried out on questions coming from the official Italian and English boardgames. The average accuracy of the virtual player for Italian is79.64%, which is significantly better than the performance of human players, which is equal to51.33%. The average accuracy of the virtual player for English is76.41%. The comparison with human players is not carried out for English since, playing successfully the game heavily depends on the players' knowledge about popular culture, and in this experiment we have only involved a sample of Italian players. As regards the ability to play real games, which involves the definition of a proper strategy for the usage of lifelines in order to decide whether to answer to a question even in a condition of uncertainty or to retire from the game by taking the earned money, the virtual player earns € 114,531 on average for Italian, and € 88,878 for English, which exceeds the average amount earned by the human players to a greater extent (€ 5926 for Italian).

@&#INTRODUCTION@&#
The work on intelligent computer games has a long history and has been one of the most successful and visible results of Artificial Intelligence research [34]. Indeed, today artificial systems are able to compete and sometimes challenge human players in several complex games. Most of these games are closed world ones, meaning that they have a finite number of possible choices, which allows the researchers to solve them in a formal way, even though they are hard to play due to the exponential dimensions of the search spaces. A more challenging type of games is represented by open world games, such as sport games or crosswords: they are less structured and, moreover, both the states of the game and the actions of the player cannot be easily enumerated, making the search through the space of possible solutions practically unfeasible. One of the most recent results in this field is the success of Watson, the open-domain question answering system built by IBM Research, which in February 2011 beat the two highest ranked players of the quiz show Jeopardy! [17,18].We are particularly interested to games related to human language. They are classified in word games, in which word meanings are not important, and language games, in which word meanings play an important role [27]. Language games generally require a wide linguistic and common sense knowledge. “Who Wants to Be a Millionaire?” (WWBM) is a perfect example of a language game in which the player provides an answer to a question posed in natural language by selecting the correct answer out of four possible ones. Even though the number of possible answers is limited to four, being able to successfully play this game heavily depends on the player's knowledge, her understanding of the questions and her ability to balance the confidence in the answer against the risk taken in answering.This article describes the architecture of a Virtual Player for the WWBM game, which leverages Question Answering (QA) techniques and both Wikipedia and DBpedia open knowledge sources in order to incorporate the knowledge useful for playing the game. A preliminary work that describes the architecture of the virtual player is presented in [37]. The current work extends the previous work along the following directions: the use of DBpedia; the decision making strategy integrated to manage the “lifelines” characterizing the game; the possibility to retire from the game; the use of machine learning techniques to improve the process of scoring the candidate answers to a question. Extended related work about question answering, answer validation and language games are also provided, along with more extensive experiments on both the Italian and the English versions of the game.Motivated by the challenge to develop an effective virtual player for the WWBM game, in this paper we address two issues, one related to the more general topic of designing effective QA systems, while the other concerns specific aspects of the game. Hence, we investigate the following research questions:•RQ1. To what extent can a QA system be designed in a language-independent way, by preserving its effectiveness?We cope with this question by proposing a general architecture of a QA and Answer Scoring (AS) framework which exploits resources or algorithms specifically designed for a given language exclusively for basic NLP operations, such as part-of-speech tagging or stemming. In order to assess the effectiveness of the framework for at least two different languages, we performed experiments on English and Italian.RQ2. Can Wikipedia and DBpedia serve as effective knowledge bases for answering WWBM game questions?We address this question by developing a virtual player based on the proposed QA framework, which leverages Wikipedia and DBpedia open knowledge sources to find the correct answers. Besides the QA framework, the virtual player adopts a decision making strategy to play the game with all its rules, i.e. usage of “lifelines”, answering in a condition of uncertainty, retiring from the game by taking the earned money. Experiments are performed to compare the accuracy of the virtual player against that of human players.The paper is organized as follows: Section 2 describes the rules of the game, while related work in the areas of language games, QA and AS are presented in Section 3. The architecture of the virtual player, the details of the QA and AS modules, and the decision making strategy adopted to play the game are provided in Sections 4–7. Section 8 reports the results of an extensive evaluation performed on Italian and English versions of the game. Finally, conclusions are reported in Section 9.WWBM is a language game, broadcast by many TV channels in several countries, in which a player must correctly answer a series of 15 multiple-choice questions of increasing difficulty. Questions are posed in natural language and the correct answer is selected among four possible choices.Fig. 1shows an example of the question Who directed Blade Runner?, and the four possible answers A) Harrison Ford B) Ridley Scott C) Philip Dick D) James Cameron. There are no time limits to answer the questions. Moreover, contestants read the question in advance, and then at any time they can decide whether to attempt an answer or quit the game by keeping the earned money. Each question has a certain monetary value (level 1: € 500; level 2: € 1000; level 3: € 1500; level 4: € 2000; level 5: € 3000; level 6: € 5000; level 7: € 7000; level 8: € 10,000; level 9: € 15,000; level 10: € 20,000; level 11: € 30,000; level 12: € 70,000; level 13: € 150,000; level 14: € 300,000; level 15: € 1,000,000). If the answer is correct, the player earns a certain amount of money and continues to play by answering questions of increasing difficulty until either she reaches the last question or she retires from the game by taking the earned money. There are three guarantee points where the money is banked and cannot be lost even if the player gives an incorrect answer to one of the next questions: 3000, 20,000 and 1,000,000 Euros, corresponding to the milestone questions 5, 10, 15, respectively. At any point, the contestant may use one or more of three “lifelines”, which provide her with some form of assistance:•50:50: this lifeline removes two wrong answers, leaving the player with a binary choice between the correct answer and the incorrect one;Poll the Audience: the player asks the studio audience to pronounce about the correct answer. The percentages of the audience for the 4 different answers are given to the player, who has the last word on the choice of the answer;Phone a Friend: the player has 60 seconds to phone a friend, and read the question with the four possible choices, in order to get a suggestion about the right choice.

@&#CONCLUSIONS@&#
In this work we investigated two issues:•To what extent can a QA system be designed in a language-independent way, by preserving its effectiveness?Can Wikipedia and DBpedia serve as effective knowledge bases for answering WWBM game questions?As regards the first issue, this work actually led to the definition of an effective language-independent framework for QA, in which both the Question Answering and Answer Scoring modules were defined using a set of filters that are not related to a specific language. We also defined an effective strategy to combine different criteria for scoring candidate answers through machine learning techniques. Experiments performed on Italian and English showed the effectiveness of the approach.As regards the second issue, we built a virtual player for the WWBM game based on the following modules:•Question Answering: is able to retrieve passages of text relevant to a specific question expressed in natural language, by using Wikipedia and DBpedia open knowledge sources;Answer Scoring: implements several heuristics based on the analysis of the results returned by the Question Answering module, in order to assign a score to the four candidate answers;Decision Making: chooses the strategy to play the game, by exploiting the scores of the four candidate answers, the availability of lifelines, and the current level of the game.The virtual player outperformed human players in terms of average accuracy in correctly answering to questions of the game, and in terms of ability to play real games with their rules.We plan to enhance the decision making algorithm, in order to allow a smarter management of the lifelines, and a less conservative strategy which could lead to a more risk neutral player, with the hope that these refinements will further improve the overall accuracy of the system. Moreover, specific heuristics could be devised to answer to questions which are currently unanswerable for our system (Section 8.1.1) in order to further improve its performance.