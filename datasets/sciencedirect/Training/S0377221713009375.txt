@&#MAIN-TITLE@&#
A combined scalarizing method for multiobjective programming problems

@&#HIGHLIGHTS@&#
A new scalarization technique for multiobjective programming is presented.It is shown that some well-known scalarization methods can be seen as special case of that.We prove some results on (weakly, properly) efficient solutions.We deal with approximate solutions and derive some necessary/sufficient conditions.We summarize the obtained results in two tables.

@&#KEYPHRASES@&#
Multiple objective programming,Scalarization method,Approximate solutions,Properly efficient solutions,ε,-Properly efficient solutions,

@&#ABSTRACT@&#
In this paper, a new general scalarization technique for solving multiobjective optimization problems is presented. After studying the properties of this formulation, two problems as special cases of this general formula are considered. It is shown that some well-known methods such as the weighted sum method, the∊-constraint method, the Benson method, the hybrid method and the elastic∊-constraint method can be subsumed under these two problems. Then, considering approximate solutions, some relationships betweenε-(weakly, properly) efficient points of a general (without any convexity assumption) multiobjective optimization problem and∊-optimal solutions of the introduced scalarized problem are achieved.

@&#INTRODUCTION@&#
One part of mathematical programming is multiobjective optimization programming when the conflicting objective functions must be minimized over a feasible set of decisions. In many areas in engineering, economics, and science new developments are only possible by the application of multiobjective optimization problems (MOPs) and related methods. There are many recent publications on applications of MOPs (Ehrgott, Klamroth, & Schwehm, 2004; Hillermeier & Jahn, 2005; Hutterer & Jahn, 2003; Jahn, 2004; Steuer & Na, 2003), and many others. Various monographs collected many results in theory and methodology (Ehrgott, 2000; Eichfelder, 2009; Ruzika & Wiecek, 2005), or provided a comprehensive review of methods (Marler & Arora, 2003). For solving MOPs, there are a number of methods and algorithms which are classified according to participation of the decision maker in the solution process (Hwang & Masud, 1979). The traditional and common approach for solving MOPs is a reformulation as a parameter scalar optimization problem. In other words, they are most commonly solved indirectly by using conventional (single-objective) optimization techniques by the aid of scalarization. In general, scalarization means the replacement of a vector optimization problem by a suitable scalar optimization problem which is an optimization problem with a real valued objective function. Since the scalar optimization theory has been widely developed, scalarization turns out to be of great importance for the vector optimization theory, as it is done in the well known weighted sum method (Geoffrion, 1968; Marler & Arora, 2010), the∊-constraint method (Chankong & Haimes, 1983; Mavrotas, 2009), the hybrid method (Guddat, Guerra, Tammer, & Wendler, 1985; Huang & Yang, 2002), the Benson method (Benson, 1998), the normal boundary intersection method (Das & Dennis, 1998), and so on. For a survey on the scalarizing technique, the reader is referred to Ehrgott and Wiecek (2005). Our focus in this paper is based on the main idea of the elasticε-constraint method introduced by Ehrgott and Ruzika in Ehrgott and Ruzika (2008). Since theε-constraint method has no result about properly efficient solutions, Ehrgott and Ruzika have presented two modifications of theε-constraint method to remedy this weakness. We use their strategy to constitute a general form. We show that the weighted sum method, the∊-constraint method, the Benson method, the hybrid method and the elastic∊-constraint method can be seen as special cases of our problem. Then, we prove some necessary and sufficient conditions for (weakly, properly) efficient points of a general MOP via optimal solutions of the presented scalarized problem. Researchers have tried to present general formulations for multiobjective optimization problems. For example, Luque, Ruiz, and Miettinen (2011), Romero (2001) and Ruiz, Luque, and Miettinen (2012), introduced a general formulation for several interactive methods. Their general formulation can accomodate some well-known interactive methods. Our formulation in this paper is not for interactive methods and so, is different from the formulation in Luque et al. (2011) and Ruiz et al. (2012). It should be mentioned that there exist several publications about properly efficient solutions (Chankong & Haimes, 1983; Huang & Yang, 2002), and many others, which use terms of stability of the scalarized problem or the K.K.T multipliers. However, our results on proper efficiency are more direct.On the other hand, the importance of approximation solutions for MOPs in recent decades motivated us to investigateε-efficient solutions. The first notion of approximation was suggested by Kutateladze (1979) and extended by Loridan (1984). White (1986) investigated six kinds ofε-approximate efficient solutions. Many authors studied the properties of this kind of solution. Some necessary and sufficient conditions forε-(weak) efficiency can be found in Dutta and Vetrivel (2001), Gutierrez, Jimenez, and Novo (2006, 2007) and others. Engau and Wiecek (2007) investigated scalarization approaches to generateε-efficient solutions of MOPs. Since our presented problems are extensions of methods in Engau and Wiecek (2007), the results in the current paper are extension of those of special cases in Engau and Wiecek (2007). Also, one of the most important notions in multiobjective optimization theory is proper efficiency introduced by Li and Wang (1998). Liu (1999) derived some necessary and sufficient conditions forε-proper efficient solutions of convex MOPs. See also Beldiman, Panaitescu, and Dogaru (2008), Gao, Yang, and Lee (2010), Gao, Yang, and Teo (2011). The methods considered in Engau and Wiecek (2007) have no result onε-proper efficiency. So, Ghaznavi and Khorram (2011) and Ghaznavi, Khorram, and Soleimani-Damaneh (2012), using the elasticε-constraint method, provided some necessary and sufficient conditions forε-(weak, proper) efficiency. Since our problem is a general form and the elasticε-constraint method is a special case of that, the obtained results extend the results obtained in Ghaznavi and Khorram (2011), Ghaznavi et al. (2012) and Engau and Wiecek (2007). It is worth mentioning that the obtained results are general and we do not assume any convexity assumption.The outline of this article is as follows: in Section 2, we provide preliminaries and basic definitions. In Section 3, we present the general formulation and study some properties of this formula. In Sections 4 and 5, two problems are presented which are special cases of the general formula presented in Section 3. Section 6 is devoted to the necessary and sufficient conditions to obtainε-(weakly, properly) efficient solutions in three subsections. The conclusions are derived in Section 7.In this paper, optimization of the multiple objective problem is studied as follows:(2.1)minf(x)=(f1(x),f2(x),…,fp(x))gi(x)⩽0,i=1,2,…,mhk(x)=0,k=1,2,…,ḿwherefj,gi,hk:Ω⊂Rn→R,∀j,i,k,andΩ≠∅. Here, we show all the feasible points by X. In other words,X={x∈Ω|gi(x)⩽0,hk(x)=0,∀i,k}.Now, the following definitions are presented to determine efficient solutions of the MOP.Definition 2.1A feasible solutionx∗∈Xof the MOP is called(1)Efficient optimal solution if there does not exist anotherx∈Xsuch thatfj(x)⩽fj(x∗)for allj=1,2,…,pandf(x)≠f(x∗).Weakly efficient solution if there is nox∈Xsuch thatfj(x)<fj(x∗);j=1,2,…,p.Strictly efficient solution if there does not exist another feasible solutionx≠x∗such thatfj(x)⩽fj(x∗);j=1,2,…,p.LetXE(XwE,XsE)be the set of efficient(weakly, strictly efficient) solutions. Ifx∗is an efficient (weakly efficient) solution,f(x∗)is called a nondominated (weakly nondominated) point. The set of nondominated (weakly nondominated) points is denoted byYN(YwN). In other words,YN≔f(XE)(YwN=f(XwE)).We assume throughout this paper thatY=f(X)is bounded and thatXEis nonempty. This is guaranteed, e.g. if X is compact andfiare continuous (see Ehrgott, 2000).Throughout this paper, we use the following notations:•R>p≔{y∈Rp|yi>0,i=1,2,…,p}.R⩾p≔{y∈Rp|yi⩾0,i=1,2,…,p}⧹{0}.R⩾p≔{y∈Rp|yi⩾0,i=1,2,…,p}.On the other hand, there exists a well-known kind of efficient points which are named properly efficient solutions. Properly efficient points are those efficient solutions that have bounded trade-offs between the objectives. There are some definitions for proper efficiency given by Benson (1979), Borwein (1977) and Hartley (1978) and others. Here we use the definition of proper efficiency in the sense of Geoffrion (1968).Definition 2.2A feasible solutionxˆ∈Xis called properly efficient in Geoffrions’s sense, if it is efficient and if there is a real numberM>0such that for all i andx∈Xsatisfyingfi(x)<fi(xˆ)there exists an index j such thatfj(xˆ)<fj(x)andfi(xˆ)-fi(x)fj(x)-fj(xˆ)<M.The set of properly efficient solutions is denoted byXpE.ε-(weakly) efficient solutions of MOP (2.1) are defined as follows Loridan (1984):Definition 2.3Take into consideration MOP (2.1). Letε∈R≧. A feasible pointxˆ∈Xis called:(1)ε-Weakly efficient if there is no otherx∈Xsuch thatf(x)<f(xˆ)-ε.ε-Efficient if there is no otherx∈Xsuch thatf(x)⩽f(xˆ)-ε.A feasible pointxˆ∈Xis calledε-properly efficient point of problem (2.1), if it isε-efficient and there is a real positive numberM>0such that for alli∈{1,2,…,p}andx∈Xsatisfyingfi(x)<fi(xˆ)-εi, there exists an indexj∈{1,2,…,p}such thatfj(xˆ)-εj<fj(x)andfi(xˆ)-fi(x)-εifj(x)-fj(xˆ)+εj<M.The set of allε-weakly efficient,ε-efficient andε-properly efficient solutions of an MOP will be indicated byXεWE,XεEandXεPE, respectively. Notice that forε=0,ε-weak efficiency,ε-efficiency andε-properly efficiency collapse in the usual definition of weak efficiency, efficiency, (Definition 2.1) and properly efficiency (Definition 2.2).Remark 2.5Obviously,XεPE⊆XεE⊆XεWE.The customary approach to solve a given MOP is to formulate a single objective program (SOP) associated with it. Let us consider an SOP as follows:minx∈Xg(x),whereg:X→R. The notation of optimality,∊-optimality and strict∊-optimality for given SOP are defined as follows:Definition 2.6Let∊⩾0. For the SOP, a feasible solutionxˆ∈Xis called:(1)An optimal solution ifg(xˆ)⩽g(x)for allx∈X.An∊-optimal solution ifg(xˆ)⩽g(x)+∊for allx∈X.A strictly∊-optimal solution ifg(xˆ)<g(x)+∊for allx∈X.In this section, using slack and surplus variables we consider the following formulation which is a general scalarizing method for solving MOP (2.1). The objective function equals the positive weighted sum of objectives, the positive weighted sum of surplus variables and the negative weighted sum of slack variables. This general form can be formulated as follows:(3.1)min∑i=1pλifi(x)-∑i=1pγisi++∑i=1pμisi-,fi(x)+si+-si-⩽αi,1⩽i⩽p,x∈X,s+,s-⩾0,whereλi,μiandγi, for all i, are nonnegative weights, andαi,(∀i)are given upper bounds.In SOP (3.1), the slack and surplus variablessi+andsi-, for all i, might be changed simultaneously by an amount ofβi∈Rwithout effecting the feasibility of the constraints. This proposition has been discussed completely in Ehrgott and Ruzika (2008) and we refer the reader to that for more details.The first property of the SOP (3.1) is stated as the following lemma.Lemma 3.1Letγ⩾0and the set of optimal solutions of SOP(3.1)be not empty. Then SOP(3.1)has an optimal solution such that all theα-constraints are active. Ifγ>0, then all theα-constraints are active in every optimal solution of SOP(3.1).Assume(xˆ,sˆ+,sˆ-)is an optimal solution of SOP (3.1), and there is some j such thatfj(xˆ)+sj^+-sj^-<αj. DefineI(xˆ,sˆ+,sˆ-)={j:fj(xˆ)+sj^+-sj^-<αj}andδj=αj-fj(xˆ)-sj^++sj^->0∀j∈I(xˆ,sˆ+,sˆ-). Now, we definesi∼+=si^+, ifi∉I(xˆ,sˆ+,sˆ-)andsi∼+=si^++δi, ifi∈I(xˆ,sˆ+,sˆ-). Clearly,(xˆ,s̃+,sˆ-)is feasible for SOP (3.1) and all the constraints are active. On the other hand, sinces̃+⩾sˆ+, we have∑i=1pλifi(xˆ)-∑i=1pγisi∼++∑i=1pμisi^-⩽∑i=1pλifi(xˆ)-∑i=1pγisi^++∑i=1pμisi^-.This means that(xˆ,s̃+,sˆ-)yields a better objective function value for SOP (3.1) than(xˆ,sˆ+,sˆ-)(ifγj>0for somej∈I(xˆ,sˆ+,sˆ-)) or the same as(xˆ,sˆ+,sˆ-)(ifγj=0for allj∈I(xˆ,sˆ+,sˆ-)). This contradicts the optimality of(xˆ,sˆ+,sˆ-). □Now, we start analyzing the SOP (3.1) theoretically.Theorem 3.2Let(xˆ,sˆ+,sˆ-)be the optimal solution of SOP(3.1). If(i)λ+γ⩾0or (λ+μ⩾0andsˆ->0), thenxˆis a weakly efficient solution of the MOP(2.1).λ+γ⩾0or (λ+μ⩾0andsˆ->0) andxˆis unique, thenxˆis a strictly efficient solution of the MOP(2.1).λ+γ>0or (λ+μ>0andsˆ->0), thenxˆis an efficient solution of the MOP(2.1).Here, we give the proof of part (iii). The proofs of parts (i) and (ii) are similar and will be omitted.(iii) Assumexˆis not an efficient solution. So, there exists a feasible pointx∈Xsuch that for allifi(x)⩽fi(xˆ)and for some j the inequality is strict. We have:fi(x)+si^+-si^-⩽αi∀i≠j,fj(x)+sj^+-sj^-<αj.We consider two cases:Case (1) Letλ+γ>0. Clearly, there is someν>0such thatfj(x)+sj^+-sj^-+ν⩽αj.Setsi+=si^+fori≠jandsj+=sj^++ν. Obviously,(x,s+,sˆ-)is feasible for SOP (3.1) and yields a better objective function than(xˆ,sˆ+,sˆ-)sinceλj+γj>0.Case (2) Ifλ+μ>0andsˆ->0. So, there is someν>0such thatsj^--ν>0andfj(x)+sj^+-sj^-+ν⩽αj.In this case definesi-=si^-fori≠jandsj-=sj^--ν. Therefore,(x,sˆ+,s-)is feasible for SOP (3.1)and yields a better objective function than(xˆ,sˆ+,sˆ-)sinceλj+μj>0. This contradicts the optimality of(xˆ,sˆ+,sˆ-). □Next, we state an easy approach to check the sufficient condition for identifying properly efficient solutions among the solutions of SOP (3.1). For the proof we need a technical lemma relating properly efficient solutions of the MOP with the feasible set of SOP (3.1) and the set X, respectively. This lemma is very similar to the idea mentioned by Ehrgott and Ruzika in Ehrgott and Ruzika (2008).Lemma 3.3Letxˆbe a properly efficient solution of the MOP with feasible set of SOP(3.1). Let there be a partitionI∪I‾of{1,2,…,p}such thatfi(xˆ)<αifor alli∈Iandfi(xˆ)>αifor alli∈I‾. Then,xˆis a properly efficient solution of the MOP with feasible set X.The proof is similar to the Lemma 3.2 in Ehrgott and Ruzika (2008) and will be omitted here. □Letλ+μ>0andλ+γ>0. If(xˆ,sˆ+,sˆ-)is an optimal solution of SOP(3.1)and also there is a partitionI∪I‾of{1,2,…,p}such thatsi^+=0,si^->0fori∈Iandsi^-=0,si^+>0fori∈I‾, thenxˆis a properly efficient solution of the MOP.Helping part (iii) of Theorem 3.2,xˆis efficient. On the other hand, we have:∑i=1pλifi(xˆ)-∑i=1pγisi^++∑i=1pμisi^-=∑i=1pλifi(xˆ)-∑i∈I‾γisi^++∑i∈Iμisi^-and since(xˆ,sˆ+,sˆ-)is an optimal solution of SOP (3.1) without loss of generality, we can write:=∑i=1pλifi(xˆ)-∑i∈I‾γi(αi-fi(xˆ))+∑i∈Iμi(fi(xˆ)-αi).Thereforexˆis an optimal solution of the weighted sum problemmin∑i∈I‾(λi+γi)fi(xˆ)+∑i∈I(λi+μi)fi(xˆ):fi(xˆ)<αii∈I‾,fi(xˆ)>αii∈I.By Geoffrion’s theorem Geoffrion (1968),xˆis a properly efficient solution of the MOP with additional constraints. Using Lemma 3.3,xˆis properly efficient for the MOP with feasible set X and the proof is completed. □Ifλ=ek,γk=0andμk=0, Theorem 3.4 reduces to Theorem 5.2 in Ehrgott and Ruzika (2008).In the following theorem, we present a necessary condition for properly efficient solutions of the MOP. We will show how properly efficient solutions can be obtained by appropriate choices of parameters.Theorem 3.6Letxˆbe properly efficient for the MOP. Then, there existλ,μ,γ⩾0,α<∞andsˆ+,sˆ-, such that(xˆ,sˆ+,sˆ-)is an optimal solution of SOP(3.1).Setγ=0,sˆ+=0. We setαi≔fi(xˆ),i=1,2,…,p. So, we can choosesˆ-=0. Also, letλ⩾0such that∑i=1pλi=1. Sincexˆis properly efficient, there isM>0such that, for allx∈Xand for all i withfi(x)<fi(xˆ), there existsj≠isuch thatfj(xˆ)<fj(x)and(fi(xˆ)-fi(x))/(fj(x)-fj(xˆ))<M.Now, defineμˆi=M,∀i.Let(x,s+,s-)be a feasible point for SOP (3.1). Sinceγ=0, we can puts+=0ands-as follows:si-=max{0,fi(x)-αi}=max{0,fi(x)-fi(xˆ)},that is the smallest possible value it can take. We need to show that∑i=1pλifi(x)+∑i=1pμisi-⩾∑i=1pλifi(xˆ)+∑i=1pμisi^=∑i=1pλifi(xˆ).Letk∈{1,2,…,p}. We have two possible cases:(case (1)) Iffk(x)⩾fk(xˆ), then(a)fk(x)+∑i=1pμˆisi-⩾fk(xˆ).(case (2)) Iffk(x)<fk(xˆ), setI∗={i:fi(x)>fi(xˆ)}. The setI∗≠∅becausexˆ∈XpE. We can write:fk(x)+∑i=1pμˆisi-=fk(x)+∑i=1pμˆimax{0,fi(x)-fi(xˆ)}=fk(x)+∑i∈I∗μˆi(fi(x)-fi(xˆ)).Sincexˆ∈XpEandfk(x)<fk(xˆ), there isk∗∈I∗such thatfk(xˆ)-fk(x)fk∗(x)-fk∗(xˆ)<M. So, we have(b)fk(x)+∑i∈I∗μiˆ(fi(x)-fi(xˆ))⩾fk(x)+μk∗ˆ(fk∗(x)-fk∗(xˆ))>fk(x)+fk(xˆ)-fk(x)fk∗(x)-fk∗(xˆ)(fk∗(x)-fk∗(xˆ))=fk(xˆ).Applying (a) and (b) we have:∑i=1pλifi(x)+∑i=1pλi∑i=1pμiˆsi-⩾∑i=1pλifi(xˆ),and since∑i=1pλi=1, we have∑i=1pλifi(x)+∑i=1pμiˆsi-⩾∑i=1pλifi(xˆ).The above inequality is true for allμ⩾μˆand the proof is complete. □In Theorem 3.6, the boundedness off(X)cannot be omitted. Examples 3.2 and 4.2 in Ehrgott and Ruzika (2008) shows that iff(X)is unbounded the result is no longer true. Additionally, we can obtain a necessary condition for efficient solutions as follows:Theorem 3.7Letxˆbe efficient for the MOP. Then, there existλ,μ,γ⩾0,α<∞andsˆ+,sˆ-, such that(xˆ,sˆ+,sˆ-)is an optimal solution of SOP(3.1).It is sufficient to setαi=fi(xˆ)for all i,γ=0,μ=0,sˆ+=0andsˆ-=0. Therefore, by Theorem 4.7 in Ehrgott (2000) there existsλ>0such thatxˆis an optimal solution of SOP (3.1).In Sections 4 and 5, we investigate two special cases of the SOP (3.1). We study these two problems with more details. Also, we show that some well-known scalarizing methods for solving the MOP can be seen as special cases of our problems.In this section, we consider problem (3.1) only with slack variables for solving the MOP. The objective function equals the positive weighted sum of objectives and the negative weighted sum of the slack variables. In other words, in SOP (3.1) we putμ=0ands-=0. So, we have:(4.1)min∑i=1pλifi(x)-∑i=1pγisi,fi(x)+si⩽αi,1⩽i⩽p,x∈X,s⩾0,whereλiandγi, for all i, are nonnegative weights, andαi,(∀i)are given upper bounds. We will suppose that in SOP (4.1),αi,(∀i)are selected such that the mentioned problem remains feasible. The SOP (4.1) is the extended form of some of the well known scalarizing methods. Table 1shows these relations.SOP (4.1) has some properties. The first one is that similar to the SOP (3.1) there are always some optimal solutions such that the additional constraints are active at these points. In other words, SPO (4.1) has the properties presented in Lemma 3.1.Depending on the choice of the weight vectors, different results can be derived for SOP (4.1). The next theorem shows some results.Theorem 4.1(1)Let(xˆ,sˆ)be an optimal solution of SOP(4.1)withλ+γ>0. Then,xˆis an efficient solution of MOP(2.1).Let(xˆ,sˆ)be an optimal solution of SOP(4.1)withλ+γ⩾0. Then,xˆis a weakly efficient solution of MOP(2.1).Let(xˆ,sˆ)be an optimal solution of SOP(4.1)withλ+γ⩾0. Ifxˆis unique, thenxˆis a strictly efficient solution of MOP(2.1).Puttingγ=0ands-=0, this theorem is a special case of Theorem 3.2 and the proof is obvious. □The results obtained by Theorem 4.1 are true for the special cases presented in Table 1. In other words, the properties of the weighted sum method, the∊-constraint method, the Benson method, the hybrid method and the elastic∊-constraint method can be considered as special cases of Theorem 4.2 and achieved by that.The next theorem states an easy to check sufficient condition for identifying properly efficient solutions of the MOP among the solutions of SOP (4.1).Theorem 4.2If(xˆ,sˆ)is an optimal solution of SOP(4.1)withλ+γ>0andsˆ>0, thenxˆis a properly efficient solution of MOP(2.1).Since in SOP (4.1)sˆ-=0, we can assume thatμ>0. Hence, the proof is achieved by Theorem 3.4. □Puttingλk=1,λi≠k=0,γk=0, Theorem 3.2 in Ehrgott and Ruzika (2008) can be seen as a special case of Theorem 4.2.Similar to Theorem 3.6, any efficient solution can be considered as an optimal solution of SOP (4.1) with positive weights. So, we have:Theorem 4.4Letxˆbe an efficient solution of the MOP. Then there existα<∞,sˆ,λandγ, such that(xˆ,sˆ)is an optimal solution of SOP(4.1).Notice that in Theorem 4.4 the parametersαi,∀iare finite. So, for some scalarizing technique with infinite values for someαi(see Table 1), we cannot use this theorem. For this kind of scalarized problem more assumptions are needed, i.e. convexity for the weighted sum method or proper efficiency for the elasticε-constraint method and so on.In the following section, we allow the added constraints to be violated and then penalize these violations in the objective function.In this section, we study the problem (3.1) in a special case whenγ=0ands+=0. So, consider the following problem:(5.1)min∑i=1pλifi(x)+∑i=1pμisi,fi(x)-si⩽αi,1⩽i⩽p,x∈X,s⩾0,whereλiandμi, for all i, are nonnegative weights, andαi,(∀i)are given upper bounds. We will suppose that in SOP (5.1),αi,(∀i)are selected such that the mentioned problem remains feasible. Note that if(xˆ,sˆ)is an optimal solution, then we may assume without loss of generality thatsi^=max{0,fi(xˆ)-αi}.It should be mentioned that although the SOP (5.1) is a special case of the SOP (3.1), sinces+=0, it does not have the property of Lemma 3.1. In other words, theα-constraints are not always active in optimality. Hence, some properties of the problem (3.1) and also (4.1) are not true for the SOP (5.1).Remark 5.1Ifλk=1,λi≠k=0andμk=0, the SOP (5.1) reduces to the second modification of theε-constraint method introduced by Ehrgott and Ruzika (2008).The following results obtained by Theorems 3.2 and 3.4, are extensions of the results in Ehrgott and Ruzika (2008).Theorem 5.2Let(xˆ,sˆ)be the optimal solution of SOP(5.1). If(1)λ≠0or (λ+μ⩾0andsˆ>0), thenxˆis a weakly efficient solution.λ≠0or (λ+μ⩾0andsˆ>0) andxˆis a unique solution, thenxˆis a strictly efficient solution.(a)λ>0, thenxˆis an efficient solution.λ+μ>0andsˆ>0, thenxˆis an efficient solution.If(xˆ,sˆ)is an optimal solution of SOP(5.1)withλ+μ>0andsˆ>0, thenxˆis a properly efficient solution of the MOP.Theorem 5.3 extends the result obtained by Theorem 4.1 in Ehrgott and Ruzika (2008).Using Theorem 3.6, we now turn to the problem of showing that properly efficient solutions of the MOP are optimal solutions of SOP (5.1) for appropriate choices ofαandμ.Theorem 5.5Letxˆbe a properly efficient solution of the MOP. Then, there areα<∞,sˆ,λ,μˆwithμˆi<∞for all i, such that(xˆ,sˆ)is an optimal solution of SOP(5.1)for allμ∈Rp,μ⩾μˆ.In SOP (4.1), we use slack variables. Insertion of these variables results in obtaining some information about proper efficiency. The negative sign of the weight coefficients of the slack variables s in objective functions allows s to be as large as possible. On the other hand, the constraints limit the magnitude of slack variables. Besides the additional constraints in SOP (4.1) are inflexible. Thus, we decide to address the inflexibility of the constraints. In SOP (5.1), the constraints are allowed to be violated using the variable s and these violations are penalized in the objective function with positive weight coefficientsμifor each violation. The idea of flexible constraints is that, in some problems, a small deviation in constraints may result in the attainment of a better solution. The SOP (3.1) has the advantages of two SOPs (4.1) and (5.1).In the next section we investigated approximate solutions and obtained some necessary and sufficient conditions forε-(weakly, properly) efficient solutions via approximate solutions of SOPs (3.1), (4.1) and (5.1).In this section, we are going to characterize the approximate (weakly, properly) efficient solutions of the general multi-objective optimization problem (2.1) using the SOPs (3.1), (4.1) and (5.1).In this subsection, we consider SOP (3.1) and provide some necessary/sufficient conditions for characterizing (weakly, properly) efficient solutions of the MOP through SOP (3.1).The following theorem provides sufficient conditions forε-efficiency.Theorem 6.1Assumeε∈R⩾p.(i)Let∊⩽∑i=1p(λi+γi)εi, andλ+γ>0. If(xˆ,sˆ+,sˆ-)is an∊-optimal solution of SOP(3.1), thenxˆis anε-efficient solution of the MOP.If(xˆ,sˆ+,sˆ-)is an∊-optimal solution of SOP(3.1)where0≤ε<sˆ-,λ+μ>0and∊⩽∑i=1p(λi+μi)εi, thenxˆis anε-efficient solution of the MOP.(i)Letxˆ∉XεE. Then, there existsx∈Xsuch thatf(x)⩽f(xˆ)-ε. In other words,fi(x)⩽fi(xˆ)-εifor all i and for some index, namely j, the inequality is strict. So,fi(x)+εi+si^+-si^-⩽fi(xˆ)+si^+-si^-⩽αi,∀i≠j.Also, we havefj(x)+εj+sj^+-sj^-+ν⩽fj(xˆ)+sj^+-sj^-⩽αj,for someν>0. Therefore, if we definesi+=si^++εi,∀i≠jandsj+=sj^++εj+ν, then(x,s+,sˆ-)is feasible for SOP (3.1). So, we have:∑i=1pλifi(x)-∑i=1pγisi++∑i=1pμisi^-=∑i=1pλifi(x)-∑i=1pγisi^++εi-γjν+∑i=1pμisi^-=∑i=1pλifi(x)-∑i=1pγisi^++∑i=1pμisi^--∑i=1pγiεi-γjνand sinceλj+γj>0,<∑i=1pλi(fi(xˆ)-εi)-∑i=1pγisi^++∑i=1pμisi^--∑i=1pγiεi=∑i=1pλifi(xˆ)-∑i=1pγisi^++∑i=1pμisi^--∑i=1p(λi+γi)εi⩽∑i=1pλifi(xˆ)-∑i=1pγisi^++∑i=1pμisi^--∊,which is a contradiction.Letxˆ∉XεE. So,fi(x)+εi+si^+-si^-⩽αi,∀i≠j.It is easy to show that there is someν>0such thatfj(x)+εj+sj^+-sj^-+ν⩽αj,andsj^--εj-ν⩾0.Now, definesi-=si^--εi,∀i≠jandsj-=sj^--εj-ν. So,(x,sˆ+,s-)is feasible for SOP (3.1). With a similar calculation like part (i) we will have:∑i=1pλifi(x)-∑i=1pγisi^++∑i=1pμisi-<∑i=1pλifi(xˆ)-∑i=1pγisi^++∑i=1pμisi^--∊,which is a contradiction. □The following theorem provides some sufficient conditions forε-(weakly) efficient solutions.Theorem 6.2(1)Let∊⩽∑i=1p(λi+γi)εi, andλ+γ⩾0. If(xˆ,sˆ+,sˆ-)is an∊-optimal solution of SOP(3.1), thenxˆis a weaklyε-efficient solution of the MOP.If(xˆ,sˆ+,sˆ-)is an (strict)∊-optimal solution of SOP(3.1)where0≦ε<sˆ-,λ+μ⩾0and∊⩽∑i=1p(λi+μi)εi, thenxˆis a (ε-efficient) weaklyε-efficient solution of the MOP.Let∊<∑i=1p(λi+γi)εi, andλ+γ⩾0. If(xˆ,sˆ+,sˆ-)is an∊-optimal solution of SOP(3.1), thenxˆis anε-efficient solution of the MOP.If(xˆ,sˆ+,sˆ-)is an∊-optimal solution of SOP(3.1)where0≤ε<sˆ-,λ+μ⩾0and∊<∑i=1p(λi+μi)εi, thenxˆis anε-efficient solution of the MOP.Let∊⩽∑i=1p(λi+γi)εi, andλ+γ⩾0. If(xˆ,sˆ+,sˆ-)is a strict∊-optimal solution of SOP(3.1), thenxˆis anε-efficient solution of the MOP.The proofs of all parts are similar to Theorem 6.1 and will be omitted here. □Now, we utilize SOP (3.1) to provide a sufficient condition forε-proper efficiency.Theorem 6.3Letε∈R⩾pand suppose0⩽∊⩽∑i=1p(λi+γi)εi,γ>0and∑i=1pλi=1. If(xˆ,sˆ+,sˆ-)is an∊-optimal solution of SOP(3.1)withfi(xˆ)+si^+-si^-<αifor all i, thenxˆis anε-properly efficient solution to the MOP.From Theorem 6.1 it follows thatxˆ∈XεE. Now, we prove thatxˆis anε-properly efficient solution. By contradiction, assumexˆ∉XεPE. Then there exists sequence{Mβ}of positive scalars such thatlimβ→∞Mβ=∞and for eachMβthere is anxβ∈Xand an indexi∈{1,2,…,p}withfi(xβ)<fi(xˆ)-εiand(6.1)fi(xˆ)-fi(xβ)-εifj(xβ)-fj(xˆ)+εj>Mβ,for eachj≠iwithfj(xˆ)-εj<fj(xβ). Without loss of generality, we can consider an unbounded subsequence of{Mβ}such that index i and the setQ={j:fj(xβ)>fj(xˆ)-εj}is constant for eachβ. Now choosej∈{1,2,…,p}. We have two possible cases:Case 1: Ifj∉Q, then,fj(xβ)⩽fj(xˆ)-εj<αj-sj^++sj^--εj,⇒fj(xβ)+sj^+-sj^-+εj<αj.So, there is someνβj>0such thatfj(xβ)+sj^+-sj^-+εj+νβj⩽αj.Case 2: Ifj∈Q, thenfj(xβ)>fj(xˆ)-εj. Sincef(X)is bounded, by inequality (6.1), we have:limβ→∞fj(xβ)=fj(xˆ)-εj<αj-sj^++sj^--εj.Hence, there existsβ0>0such thatfj(xβ)+sj^+-sj^-+εj<αj∀β⩾β0.Also, for allβ⩾β0there isνβj>0such thatfj(xβ)+sj^+-sj^-+εj+νβj⩽αj.Now, definesβj+=sj^++εj+νβjfor all1⩽j⩽pandβ⩾β0. So,(xβ,sβ+,sˆ-)is feasible for SOP (3.1) for allβ⩾β0. On the other hand, whenj∈Qandβ⩾β0, we havelimβ→∞fj(xβ)=fj(xˆ)-εj,⇒limβ→∞(-fj(xβ)+fj(xˆ)-εj+γ1νβ1)=γ1νβ1>0.So, there exists someβ0́>β0such that for allβ⩾β0́(a)fj(xβ)<fj(xˆ)-εj+γ1νβ1.Ifj∉Q, we also have:(b)fj(xβ)⩽fj(xˆ)-εj.Now, select someβ∗>β0́and put(x¯,s¯+,sˆ-)=(xβ∗,sβ∗,sˆ-). By applying (a) and (b), we can write:∑i=1pλifi(x¯)-∑i=1pγisi‾++∑i=1pμisi^-=∑i=1pλifi(x¯)-∑i=1pγi(si^++εi)-∑i=1pγiνβ∗i+∑i=1pμisi^-=∑i∉Qλifi(x¯)+∑i∈Qλifi(x¯)-∑i=1pγisi^+-∑i=1pγiεi-∑i=1pγiνβ∗i+∑i=1pμisi^-⩽∑i∉Qλi(fi(xˆ)-εi)+∑i∈Qλi(fi(xˆ)-εi+γ1νβ∗1)-∑i=1pγisi^+-∑i=1pγiεi-∑i=1pγiνβ∗i+∑i=1pμisi^-=∑i=1pλifi(xˆ)-∑i=1pγisi^++∑i=1pμisi^--∑i=1p(λi+γi)εi+γ1νβ∗1∑i∈Qλi-∑i=1pγiνβ∗i,and since∑i∈Qλi⩽1,<∑i=1pλifi(xˆ)-∑i=1pγisi^++∑i=1pμisi^--∑i=1p(λi+γi)εi⩽∑i=1pλifi(xˆ)-∑i=1pγisi^++∑i=1pμisi^--∊which is a contradiction and the proof is completed. □The next subsection deals with SOP (4.1) to provide some conditions for approximate solutions.Consider SOP (4.1). Most of the results in this subsection are obtained from Section 6.1, indirectly.It is easy to show that part (i) of Theorem 6.1 and parts 1, 3 and 5 of Theorem 6.2 is true for SOP (4.1).Remark 6.4Considering SOP (4.1) and puttingγ=0,α=∞, Theorem 6.1 reduces to Proposition 3.1 (i) in Engau and Wiecek (2007). Ifγ=0,λk=1,λi≠k=0,αk=∞then, Proposition 3.2 (i) in Engau and Wiecek (2007), ifγ=0,α=f(x0)wherex0is an arbitrary feasible point, then Proposition 3.3 (i) in Engau and Wiecek (2007), ifλ=0,γ=1,α=f(x0)wherex0is an arbitrary feasible point, then Proposition 3.4 (i) in Engau and Wiecek (2007), and finally, ifλk=1,λi≠k=0,αk=∞, then Theorem 4.4 in Ghaznavi et al. (2012) will be obtained.Similar to Remark 6.4, we can obtain the conditions ofε-(weakly) efficiency of the techniques presented in Table 1 as special cases of SOP (4.1) with Theorem 6.6.As a special case of Theorem 6.3, the following theorem utilizes SOP (4.1) to provide a sufficient condition forε-proper efficiency.Theorem 6.6Letε∈R⩾pand suppose0⩽∊⩽∑i=1p(λi+γi)εi,γi>0,∀iand∑i=1pλi=1. If(xˆ,sˆ)is an∊-optimal solution of SOP(4.1)withfi(xˆ)+si^<αifor all i, thenxˆis anε-properly efficient solution to the MOP.In the next subsection, the SOP (5.1) will be investigated.In this subsection, we restrict our attention to SOP (5.1). We provide some necessary/sufficient conditions for characterizingε-(weakly, properly) efficient points of MOP via SOP (5.1).The following theorem provides a sufficient condition forε-weak efficiency.Theorem 6.7Supposeε∈R⩾pand∊⩽∑i=1pλiεi. If(xˆ,sˆ)is an∊-optimal solution of SOP(5.1), then,xˆ∈XεWE.The proof is easily obtained and will be omitted here. □Theorem 6.7 extends Theorem 3.2 in Ghaznavi and Khorram (2011), which is obtained byλ=ekandμk=0.SOP (5.1) satisfies in part (ii) of Theorem 6.1 and parts 2 and 4 of Theorem 6.2. Additionally, in the following theorem, we present more necessary conditions forε-efficiency of the MOP.Theorem 6.9Givenε∈R⩾p.(1)If(xˆ,sˆ)is a strictly∊-optimal solution of SOP(5.1)and∊⩽∑i=1pλiεi, thenxˆ∈XεE.If(xˆ,sˆ)is an∊-optimal solution of SOP(5.1)and∊<∑i=1pλiεi, thenxˆ∈XεE.(1)Supposexˆis notε-efficient. Then, there exists somex∈Xwithf(x)⩽f(xˆ)-ε. It is a simple matter to show that(x,sˆ)is feasible for SOP (5.1). So,∑i=1pλifi(x)+∑i=1pμisi^+∑i=1pλiεi⩽∑i=1pλifi(xˆ)+∑i=1pμisi^,⇒∑i=1pλifi(x)+∑i=1pμisi^+∊⩽∑i=1pλifi(xˆ)+∑i=1pμisi^,a contradiction.Similar to Part (1).By lettingλ=ekandμk=0, Theorem 6.9 reduces to Theorem 3.7 in Ghaznavi and Khorram (2011).The following theorem utilizes SOP (5.1) to provide a sufficient condition forε-proper efficiency.Theorem 6.11Supposeε∈R⩾pand∊⩽∑i=1pλiεi. If(xˆ,sˆ)is an∊-optimal point of SOP(5.1)withλ+μ>0andsˆ>0, thenxˆ∈XεPE.Let us first prove thatxˆisε-efficient. Without loss of generality, assumesi^=max{0,fi(xˆ)-αi}. Sincesˆ>0, it follows thatsi^=fi(xˆ)-αi>0,∀i. Letxˆnot be anε-efficient solution. Therefore, there existsx∈Xsuch thatfi(x)⩽fi(xˆ)-εi,∀iand for at least one indexj,fj(x)<fj(xˆ)-εj. Definesi=max{0,fi(x)-αi}for alli≠j. Sincefj(x)-sj^<αj, there is someν>0such thatfj(x)-sj^+ν⩽αjandsj=sj^-ν>0. Putsi=si^,∀i≠jandsj=sj^+ν. Obviously,(x,s)is feasible for SOP (5.1) ands⩽sˆ, specially,sj<sj^. Becauseλj+μj>0,λjfj(x)+λjεj+μjsj<λjfj(xˆ)+μjsj^,and for alli≠j,λifi(x)+λiεi+μisi⩽λifi(xˆ)+μisi^.So,∑i=1pλifi(x)+∑i=1pμisi+∑i=1pλiεi<∑i=1pλifi(xˆ)+∑i=1pμisi^,⇒∑i=1pλifi(x)+∑i=1pμisi+∊<∑i=1pλifi(xˆ)+∑i=1pμisi^,a contradiction to∊-optimality of(xˆ,sˆ).To show thatxˆis anε-properly efficient point, by our assumptionxˆis an∊-optimal point of the following problem:min∑i=1pλifi(x)+∑i=1pμi(fi(x)-αi)fi(x)>αi,∀ix∈XThis problem can be rewritten as follows:min∑i=1p(λi+μi)fi(x)-∑i=1pμiαifi(x)>αi,∀ix∈XNow, sinceλ+μ>0, employing Theorem 2 in Liu (1999), yieldsxˆas anε-properly efficient point with added constraintsfi(x)>αi,∀i. Then from a result similar to Lemma 3.3, we conclude thatxˆ∈XεPE. □Lettingλ=ekandμk=0, Theorem 6.11 reduces to Theorem 3.14 in Ghaznavi and Khorram (2011).In the following theorem, a necessary condition forε-properly efficient solutions of MOP (2.1) is obtained. This theorem extends Theorem 3.21 in Ghaznavi and Khorram (2011).Theorem 6.13Supposexˆ∈XεPEand∑i=1pλi=1. Then, there areα<∞,sˆ,μˆwithμˆi<∞, such that(xˆ,sˆ)is an∊-optimal point of SOP(5.1)with∊=∑i=1p(λi+μi)εifor allμ⩾μˆ.Letαi=fi(xˆ)-εiandsi^=εifor all i. Sincexˆ∈XεPE, there isM>0such that, for allx∈Xand for all i withfi(x)<fi(xˆ)-εi, there existsj≠isuch thatfj(xˆ)-εj<fj(x)and(fi(xˆ)-εi-fi(x))/(fj(x)-fj(xˆ)+εj)<M.We defineμˆi=M,∀i.Letx∈Xand s be such that:si=max{0,fi(x)-αi}=max{0,fi(x)-fi(xˆ)+εi},the smallest possible value it can take. We need to show that∑i=1pλifi(x)+∑i=1pμisi⩾∑i=1pλifi(xˆ)+∑i=1pμisi^-∊.Letk∈{1,2,…,p}. We have two possible cases:Case (1) Iffk(x)⩾fk(xˆ)-εk, then(a)fk(x)+∑i=1pμiˆsi⩾fk(xˆ)-εk.Case (2) Iffk(x)<fk(xˆ)-εk, setI∗={i:fi(x)>fi(xˆ)-εi}. The setI∗≠∅becausexˆ∈XεPE. We can write:fk(x)+∑i=1pμˆisi=fk(x)+∑i=1pμˆimax{0,fi(x)-fi(xˆ)+εi}=fk(x)+∑i∈I∗μˆi(fi(x)-fi(xˆ)+εi).Sincexˆ∈XεPEandfk(x)<fk(xˆ)-εk, there isk∗∈I∗such thatfk(xˆ)-fk(x)-εkfk∗(x)-fk∗(xˆ)+εk∗<M. So, we have(b)fk(x)+∑i∈I∗μˆi(fi(x)-fi(xˆ)+εi)⩾fk(x)+μk∗^(fk∗(x)-fk∗(xˆ)+εk∗)>fk(x)+fk(xˆ)-fk(x)-εkfk∗(x)-fk∗(xˆ)+εk∗(fk∗(x)-fk∗(xˆ)+εk∗)=fk(xˆ)-εk.Applying (a) and (b) we have:∑i=1pλifi(x)+∑i=1pλi∑i=1pμiˆsi⩾∑i=1pλifi(xˆ)-∑i=1pλiεi,and since∑i=1pλi=1, we have∑i=1pλifi(x)+∑i=1pμiˆsi⩾∑i=1pλifi(xˆ)+∑i=1pμiεi-∊=∑i=1pλifi(xˆ)+∑i=1pμisi^-∊.The above inequality is true for allμ⩾μˆand the proof is completed. □

@&#CONCLUSIONS@&#
