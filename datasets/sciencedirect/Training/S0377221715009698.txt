@&#MAIN-TITLE@&#
A differential evolution algorithm with self-adaptive strategy and control parameters based on symmetric Latin hypercube design for unconstrained optimization problems

@&#HIGHLIGHTS@&#
We propose an adaptive DE algorithm for unconstrained optimization problems.Symmetric Latin hypercube design is employed to initialize the population.Trial vector generation strategy adaptation is introduced.Control parameters adaptation is introduced.Experimental results show that SLADE is better than other DE algorithms.

@&#KEYPHRASES@&#
Evolutionary computations,Differential evolution,Parameter adaptation,Strategy adaptation,Symmetric Latin hypercube design,

@&#ABSTRACT@&#
This paper presents a differential evolution (DE) algorithm, namely SLADE, with self-adaptive strategy and control parameters for unconstrained optimization problems. In SLADE, the population is initialized by symmetric Latin hypercube design (SLHD) to increase the diversity of the initial population. Moreover, the trial vector generation strategy assigned to each target individual is adaptively selected from the strategy candidate pool to match different stages of the evolution according to their previous successful experience. SLADE employs Cauchy distribution and normal distribution to update the control parameters CR and F to appropriate values during the evolutionary process. A large amount of simulation experiments and comparisons have been made by employing a set of 25 benchmark functions. Experimental results show that SLADE is better than, or at least comparable to, other classic or adaptive DE algorithms, and SLHD is effective for improving the performance of SLADE.

@&#INTRODUCTION@&#
The differential evolution (DE) algorithm is a population-based stochastic search technique proposed by Storn and Price (Storn & Price, 1997) for global optimization in real-world applications (Joshi & Sanderson, 1999; Price, Storn, & Lampinen, 2006; Zhang, Avasarala, Sanderson, & Mullen, 2008; Zhang, Avasarala, & Subbu, 2010). The DE algorithm has been applied in many domains, such as signal processing (Storn, 1996), pattern recognition (Ilonen, Kamarainen, & Lampinen, 2003), dynamic systems (Angira & Santosh, 2007), power dispatch (Varadarajan & Swarup, 2008), scheduling (Deng & Gu, 2012; Tsai, Fang, & Chou, 2013), nuclear safety (Di Maio, Baronchelli, & Zio, 2014), and continuous steel casting (Mlakar, Petelin, Tušar, & Filipič, 2015), and achieved better results than most evolutionary algorithms (EAs), including the GA algorithm (Gonçalves & Resende, 2015; Li et al., 2015; Zhang et al., 2014).Like other evolutionary algorithms, DE repeats mutation, crossover, and selection operators generation by generation to evolve its solution toward the global optimum. There are many trial vector generation strategies, and different strategies have different search capabilities for different problems in different stages of the evolutionary process. Moreover, there are three crucial associated parameters, i.e., population size NP, scaling factor F, and crossover rate CR. They may seriously affect the performance of DE (Kovačević, Mladenović, Petrović, & Milošević, 2014; Qin, Huang, & Suganthan, 2009), such as convergence rate, robustness and searching precision. When using DE to solve optimization problems, the trial vector generation strategy and its associated control parameters that best fit a specific optimization problem should be determined by a time-consuming trial-and-error procedure. Several reports in the literatures have shown that some trial vector generation strategies and the associated parameter values of DE are good for global search (Gong, Cai, Ling, & Li, 2011; Price et al., 2006; Qin et al., 2009), while some others are good for local fine tuning (Gong et al., 2011; Mezura-Montes, Velázquez-Reyes, & Coello Coello, 2006; Zhang & Sanderson, 2009). The best trial vector generation strategy and the associated parameter values may be different during different stages of the search process (Brest, Greiner, Boskovic, Mernik, & Zumer, 2006).Therefore, it is important to develop new DE variants with strategy adaptation and control parameters adaptation. Some different adaptation schemes have been proposed by many researchers to avoid the time-consuming trial-and-error procedure. Brest et al. (Brest et al., 2006) proposed a new DE algorithm for adaptively obtaining control parameter values. The control parameter values are encoded into each individual, and constantly updated along with the evolution. The proposed algorithm shows good performance on numerical benchmark problems. Qin et al. (Qin et al., 2009) proposed a self-adaptive differential evolution algorithm. Two mutation strategies are employed, and assigned to each individual according to a given probability. The probability of assigning each mutation strategy is updated according to the number of trial vectors surviving to the next generation. Zhang and Sanderson (Zhang & Sanderson, 2009) proposed an adaptive differential evolution called JADE. JADE implements a new mutation strategy, “DE/current-to-pbest”, with an external archive and automatically updates control parameters according to previously successful experiences. The external archive stores inferior solutions to provide a promising direction for the search process. These operations can not only avoid premature convergence but also diversify the population. Pan et al. (Pan, Suganthan, Wang, Gao, & Mallipeddi, 2011) proposed a self-adaptive differential evolution algorithm called SspDE. In this algorithm, mutation strategy and control parameters have been assigned to each individual. If the obtained offspring is better than its parent, the associated mutation strategy and control parameters will be stored in three winning lists, respectively. After a given number of iterations, the mutation strategy and control parameters will be reassigned to each individual by selecting from the winning lists according to a high probability or randomly generated values. In this way, both the mutation strategy and the control parameters can constantly be adjusted along with the evolution. Elsayed and Sarker et al. (Elsayed, Sarker, & Essam, 2013) proposed an improved differential evolution algorithm that introduces an ensemble of different mutation operators. Moreover, to improve the exploitation ability of the proposed algorithm, a covariance adaptation matrix evolution strategy algorithm is employed for a local search. Zou et al. (Zou, Wu, Gao, & Li, 2013) proposed a modified differential evolution algorithm called MDE. To increase the diversity of the entire population, MDE employs a Gaussian distribution and uniform distribution to generate control parameter values. An external archive is introduced to provide some high quality solutions for selection as candidate solutions. Two common mutation strategies are selected according to the present iteration number. Furthermore, a central solution generated by averaging all of the other candidate solutions provides a potential search direction. Asafuddoula et al. (Asafuddoula, Ray, & Sarker, 2014) proposed an adaptive hybrid DE algorithm. To balance the exploration and exploitation capacity of the algorithm, a binomial crossover is employed in the early stages of evolution, while an exponential crossover is employed in later stages. Moreover, the crossover rate is self-adaptive according to the success rate, which is updated based on the success or failure of the offspring generated. A gradient local search is invoked from the best solution to locate any better solution.In this paper, we propose a differential evolution algorithm, namely, SLADE, with self-adaptive strategy and control parameters, which employs the symmetric Latin hypercube design (SLHD) to initialize the population. During the evolution, a suitable mutation strategy is selected from a candidate pool for each individual according to their previous experience in generating promising solutions. In addition, control parameters are generated according to normal distribution and Cauchy distribution for each individual by learning from previous experience. The experimental results and comparisons indicate that SLADE performs better than the state-of-the-art DE variants such as DE (Storn & Price, 1995), SADE (Brest et al., 2006), JADE (Zhang & Sanderson, 2009), SspDE (Pan et al., 2011) and MDE (Zou et al., 2013) for solving unconstrained optimization problems, and SLHD is effective for improving the performance of SLADE.The remainder of this paper is organized as follows. Section 2 introduces the standard DE algorithms. Section 3 describes the SLADE algorithm in detail. Section 4 lists the benchmark functions from CEC2005(Suganthan et al., 2005). Section 5 introduces the experimental design, and experimental results for the comparisons of SLADE with the other algorithms. Finally, the conclusions are discussed in Section 6.The differential evolution algorithm follows the general procedure of an evolutionary algorithm (Deb & Agrawal, 1994). The initial population PGwhich consists of NP target individuals Xi,G, i =1,2,…,NP, is initialized randomly according to a uniform distribution between predefined search ranges [Xmin, Xmax]D, where D is the dimension of the problem and G is the current generation. Then, mutation, crossover and selection operations are employed, and the above process is repeated until a termination criterion is reached.For each target vector Xi,G, a mutation operation is employed to generate a mutant vector Vi,G. There are many mutation strategies, such as the following five equations (Baatar, Zhang, & Koh, 2013; Chen et al., 2015; Gong & Cai, 2013; Lin et al., 2015; Wang, Cai, & Zhang, 2011):(1)Vi,G=Xr1,G+F×(Xr2,G−Xr3,G)(2)Vi,G=Xbest,G+F×(Xr1,G−Xr2,G)(3)Vi,G=Xi,G+F×(Xbest,G−Xi,G)+F×(Xr1,G−Xr2,G)+F×(Xr3,G−Xr4,G)(4)Vi,G=Xbest,G+F×(Xr1,G−Xr2,G)+F×(Xr3,G−Xr4,G)(5)Vi,G=Xr5,G+F×(Xr1,G−Xr2,G)+F×(Xr3,G−Xr4,G)where F is the mutation scale factor, which is a positive constant. Xbest,Gis the best solution at the current generation G. r1, r2, r3, r4 and r5 are different integers randomly generated within the range [1, NP], which are also different from index i. Furthermore, Eqs. (1)–(5) are known as DE/rand/1/bin, DE/best/1/bin, DE/rand-to-best/2/bin, DE/best/2/bin, and DE/rand/2/bin, respectively.Following the mutation operation, a trial vectorUi,G=(ui,G1,ui,g2,…,ui,GD)is generated from a mutant vector Vi,Gand its corresponding target vector Xi,Gby using a crossover operation. There are two commonly used crossover strategies. One is binomial crossover, and the other is exponential crossover. In this paper, the binomial crossover is selected for the proposed DE algorithm. The binomial crossover is defined as follows:(6)ui,Gj={vi,Gjifrand≤CRorj=njxi,Gjotherwisewhere CR is the crossover rate which is a fixed constant within the range [0, 1). rand is a uniform random number in the range [0, 1], and njis randomly chosen from the set {1,2,…,D}, which is used to ensure that the trial individual Ui,Ggets at least one dimension from Vi.G. Ifui,Gjexceeds[xminj,xmaxj], it will be set toxminjorxmaxj.In thecase of the selection operation, there is a competition between each target individual Xi,Gand its corresponding trial vector Ui,G. The better of Xi,Gand Ui,Gis selected and inserted into the population of the next generation according to their fitness values f(). For minimization problems, this can be expressed as follows:(7)Xi,G+1={Ui,Giff(Ui,G)≤f(Xi,G)Xi,GotherwiseXi,G+1 is used as a parent vector in the next generation.Because the performance of the DE algorithm is mainly affected by the trial vector generation strategy and its associated control parameters CR and F, a reasonable combination of trial vector generation strategy and associated parameter values should be selected when applying the DE algorithm to solve a specific problem. Generally, this reasonable combination is determined by a time-consuming trial-and-error procedure. Moreover, this combination can be different for different problems and even for the same problem during different stages of the search process. To address this problem, this paper presents a novel DE algorithm, called SLADE. First, the symmetric Latin hypercube design is introduced to initialize the population to increase the diversity of the population. Second, the trial vector generation strategy is adaptively selected from the strategy candidate pool according to previous successful experience. Finally, the control parameters CR and F are adaptively adjusted by using Cauchy distribution and normal distribution.In the DE algorithm, the population is initialized randomly by a uniform distribution. The performance of the DE algorithm is seriously influenced by the diversity of initial population. Thus, in this paper, random symmetric Latin hypercube design (SLHD) is introduced to execute the population initialization (Regis & Shoemaker, 2004). All of the sample points of the symmetric Latin hypercube design are more uniformly distributed than those of the Latin hypercube design (LHD). Ye et al. illuminated how SLHD has more advantages over LHD regarding entropy and minimum intersite distance (Ye, Li, & Sudjianto, 2000). The pseudo code of SLHD is presented in Table 1.To verify the performance of SLHD sampling, a comparison with uniform sampling is made. Two groups of sample points are generated between predefined ranges [0, 1]Dby using SLHD sampling and uniform sampling, respectively. To estimate the uniformity of the sample points, the distance between two adjacent points is calculated. The computation of the distance requires sorting the sample points according to the value of each dimension in ascending order. Thereafter, the distance is calculated as follows:(8)Disti=∑m=1D|UPi,m−Ti,m|where i = 1,…, NP-1. Ti,mis the mth dimension of the ith sample point. UPi,mis the mth dimension of one sample point, which is the upper adjacent point of ith sample point on the mth dimension. If there is no upper adjacent point of ith sample point on the mth dimension, set UPi,m= Ti,m. D is the dimension of the sampling space.Comparisons between SLHD sampling and uniform sampling with D = 10, 30, 50 and 100 are made. The number of sample points with D = 10, 30, 50 and 100 are 1000, 3000, 5000, and 10000, respectively. The average values of the means and standard deviations of the distance between two adjacent points over 30 runs are shown in Table 2. Although the means of the distance between two adjacent points generated by SLHD sampling are the same as those by uniform sampling, the standard deviations of the distance between two adjacent points generated by SLHD sampling are much smaller than those by uniform sampling. This means that sample points generated by SLHD sampling are much more uniform than those by uniform sampling. To more vividly illustrate the uniformity of the sample points, Fig. 1is ploted by using experimental data with D = 10, 30, 50 and 100. The horizontal axis is sample points, and the vertical axis is the distance between two adjacent points. Obviously, the change in the distance between sample points generated by SLHD sampling is very small, but the distance between sample points generated by uniform sampling changes significantly. This also indicates that the uniformity of the sample points that generated by SLHD sampling is much better than that by uniform sampling. Hence, the diversity of the initial population has been greatly improved by introducing SLHD into SLADE.The performances of different trial vector generation strategies are not the same when solving different optimization problems (Qin et al., 2009) and even when solving the same optimization problem during different stages of the search process. Some strategies have a better exploration capability, while others have a stronger exploitation capability. Instead of a time-consuming trial-and-error search for the most suitable strategy, a strategy candidate pool composed of several effective trial vector generation strategies is constructed. These effective trial vector generation strategies are introduced in Section 2.1, i.e., Eqs (1)–(5). They will be selected automatically during different stages of evolution. Adaptation of the trial vector generation strategies can be described as follows.During initialization, for the initial population P0, a trial vector generation strategy list named SL =(s1, s2,…, sNP) is randomly generated by using a uniform distribution. s1, s2,…, sNPbelong to the strategy candidate pool, where NP is the number of target individuals. In the mutation operation, each target vector Xi,Gand its associated trial vector generation strategy siare used to produce a new trial vector Ui,G. If Ui,Gis better than its target vector Xi,G, then the associated siwill be stored in a winning list wSL. After each generation, a reassignment procedure for the list SL is invoked.During the reassignment procedure, a probability γ is set to determine whether the new sifor each target vector Xi,Gof the next generation was randomly selected from the list wSL or randomly generated by using a uniform distribution. Note that the list wSL is reset to empty after the above operations are completed. If the list wSL is empty, then the reassignment procedure will not be invoked.Obviously, the more successful a trial vector generation strategy in the current generation is, the greater is its probability of being selected in the next generation. As a result, SLADE can be self-adaptive to select an appropriate trial vector generation strategy to match the specific problem and the specific phase of the evolutionary process.At each generation, the crossover rate CRiof each target vector Xi,Gis separately generated using a Cauchy distribution with location parameter θCRand a scale parameter of 0.1. It can be defined as follows:(9)CRi=Cauchyrand(θCR,0.1)If CRiexceeds (0, 1), then it will be regenerated. Each target vector Xi,Gand its associated CRiare used to produce a new trial vector Ui,G. If Ui,Gis better than its target vector Xi,G, then the associated CRiwill enter a winning set wCR. The location parameter θCRof the Cauchy distribution is initialized to be 0.5. After each generation, the location parameter θCRis updated as follows:(10)θCR=a·θCR+(1−a)·∑CR∈wCRCRNPwhere a is a positive constant within the range (0, 1) and NP is the number of the population size. Note that if the set wCR is empty, then the last θCRis used again.Likewise, at each generation, the mutation scale factor Fiof each target vector Xi,Gis separately generated by using a normal distribution with mean μFand a standard deviation of 0.1. It can be defined as follows:(11)Fi=Normalrand(μF,0.1)If Fiexceeds (0, 1), then it will be set to 1. Each target vector Xi,Gand its associated Fiare used to produce a new trial vector Ui,G. If Ui,Gis better than its target vector Xi,G, then the associated Fiwill enter a winning set wF. The mean μFof the normal distribution is initialized to be 0.5. After each generation, the mean μFis updated as follows:(12)μF=a·μF+(1−a)·∑F∈wFFNPwhere a is a positive constant within the range (0, 1), and NP is the number of the population size. Note that if the set wF is empty, then the last θFis used again.Obviously, control parameter values that generate better individuals should be propagated to the following generations. The successful CRiand Fiof the current generation are archived and used to update the adaptive parameters θCRand μF. The new control parameters CRiand Figenerated by Eqs. (9) and (11) are more suitable for current phase of evolution, and can produce more successful individuals. Furthermore, both Cauchy distribution and normal distribution have randomness, and they are beneficial for diversifying the population. Note that sets wCR and wF are reset to empty after updating θCRandμF.By incorporating the above-mentioned adaptation schemes into the traditional DE algorithm, a self-adaptive DE algorithm called SLADE is developed. During different phases of the search process, SLADE can adaptivelydetermine the best trial vector generation strategy and the associated parameter values to get the best effect when solving the optimization problem. The pseudo code of SLADE is presented in Table 3.To verify the performance of SLADE, 25 benchmark functions in IEEE CEC2005 (Suganthan et al., 2005) are selected. Twenty-five benchmark functions with diverse characteristics are denoted by F1−F25. The characteristics and global optimums of F1-F25 are presented in Table 4. “Fun” denotes function. More details about the 25 benchmark functions can be found in (Suganthan et al., 2005).

@&#CONCLUSIONS@&#
This paper presents an adaptive differential evolution algorithm named SLADE for unconstrained optimization problems. SLADE incorporates a population initialization technology based on symmetric Latin hypercube design (SLHD), an adaptive selection mechanism of the trial vector generation strategies and an adaptive adjustment mechanism of control parameters based on Cauchy distribution and normal distribution. In SLADE, the trial vector generation strategy and control parameters are assigned to each target individual, and can be adaptively adjusted to match different stages of the evolution according to previous experience. The performance of SLADE is strictly evaluated using the set of benchmark functions from CEC2005. Experimental results demonstrate that SLADE shows better or at least competitive optimization performance compared to other classic and adaptive DE algorithms, and SLHD is effective for improving the performance of SLADE. Moreover, it is interesting to extend the current work to solve constraint and multi-objective optimization problems.