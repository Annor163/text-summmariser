@&#MAIN-TITLE@&#
Incorporating self-organizing map with text mining techniques for text hierarchy generation

@&#HIGHLIGHTS@&#
Incorporation of topic identification into SOM learning could be beneficial to text categorization task.Both lateral and hierarchical expansion during SOM learning were achieved according to criteria based on identified topics.The produced text hierarchies outperformed contemporary approaches in quality and performance on text categorization.

@&#KEYPHRASES@&#
Text mining,Self-organizing map,Topic identification,Hierarchy generation,

@&#ABSTRACT@&#
Self-organizing maps (SOM) have been applied on numerous data clustering and visualization tasks and received much attention on their success. One major shortage of classical SOM learning algorithm is the necessity of predefined map topology. Furthermore, hierarchical relationships among data are also difficult to be found. Several approaches have been devised to conquer these deficiencies. In this work, we propose a novel SOM learning algorithm which incorporates several text mining techniques in expanding the map both laterally and hierarchically. On training a set of text documents, the proposed algorithm will first cluster them using classical SOM algorithm. We then identify the topics of each cluster. These topics are then used to evaluate the criteria on expanding the map. The major characteristic of the proposed approach is to combine the learning process with text mining process and makes it suitable for automatic organization of text documents. We applied the algorithm on the Reuters-21578 dataset in text clustering and categorization tasks. Our method outperforms two comparing models in hierarchy quality according to users’ evaluation. It also receives better F1-scores than two other models in text categorization task.

@&#INTRODUCTION@&#
In past decades, lots of artificial neural network (ANN) models had been proposed to emulate the activities, functions, and mechanisms of brain, and focused on the development of learning strategies. Amongst these models, self-organizing map (SOM) [1] model has emerged to be one of the widely used models. According to the bibliography11Accessible from http://www.cis.hut.fi/research/refs/.compiled by the original SOM developing team [2–4], there are more than ten thousands research papers published regarding the SOM up to now covering applications of pattern recognition, text clustering, data visualization, data mining, and many more. Such popularity mainly comes from the fact that SOM could effectively form clusters of high-dimensional data [5]. Besides, it is also easy to be implemented. The major strength of the SOM model is that it could reveal the similarity among high dimensional data and map them onto a low, often 2, dimensional map in a topology-preserving manner. That is, data that are close together in high-dimensional space will also be close in the mapped low-dimensional space. Such capabilities make the SOM being widely applied in data visualization, clustering, and other related tasks.Although the SOM is easy and effective in data clustering, there are three main disadvantages in its learning algorithm. First, the training time of the SOM is often long since the input data is often high-dimensional and the SOM requires repeated training over input data [6]. Second, the size and topology of the map are fixed. That is, the number and formation of neurons in the map should be determined a priori. However, there is no gold standard for determining such size and topology. Some rules of thumb were always suggested to select the appropriate number of neurons. Third, the original SOM can reveal only lateral correlations among data, but not hierarchical ones. That is, SOM can tell that a data point is close to another, but not the subset relation between them. To remedy these deficiencies, several schemes have been proposed [7,8]. To overcome the fixed structure problem, it is often to make the map expandable during training since it is difficult to know the optimal sizes of maps a priori. Generally the map contains a small amount of neurons initially and expands in later training stages according to the distributions of data. Such expanding maps may also reduce the training time since we will not allocate too many neurons for sparse data. On the other hand, there are two major approaches from existing works to conquer the lack of hierarchical relationships. The first is to apply agglomerative hierarchical clustering or divisive hierarchical clustering processes on the two-dimensional map to generate hierarchies. The second is to retrain each cluster in the map using a lower-level map and obtain the hierarchical structure. These approaches on map expansion or hierarchy generation all relies on the characteristics of data to decide when and how to expand the map. Since the SOM will cluster similar data together, many similar data will be clustered into few neurons. Thus we can decide whether to expand the map or not by detecting the distribution of data on the map. Here we may call such approaches the data-centric or data-oriented approaches. Although data-oriented approaches may effectively generate adequate number of clusters or even hierarchies, they provide no insight into the meaning of data, let along guiding the training process.In recent years, the SOM was widely used for text document clustering and categorization [9–16]. Text categorization concerns of classifying documents into some categories according to their contents, characteristics, and properties. When documents are properly categorized, documents in a cluster should have a common theme. However, classical SOM only clusters documents into clusters without specifying their themes or topics. Therefore, another process should be applied to discover the topics of each cluster [17,18]. Furthermore, text categorization tasks usually rely on some categorization taxonomies which are often hierarchical. Obviously classical SOM is not able to fulfill the requirements of such tasks. Techniques for building hierarchies during [18,19] or after [20] SOM training were thus developed to amend such insufficiency. Even in methodologies of developing hierarchies during training, the identification of category topics is performed after the training. An interesting argument is that is it possible to develop a SOM learning algorithm for text categorization based on lessons learned from applying SOM on text categorization? This argument naturally leads to the idea of incorporating topic identification and hierarchy generation into SOM learning, which is the main focus of this work.In this work, we propose a novel self-organizing map algorithm which incorporates text mining techniques. The underlying idea behind the proposed approach is to guide the learning process by cluster topics instead of document centroids. A topic detection process is continuously performed through the entire learning process. We then use these topics to decide if the map needs to be expanded laterally or hierarchically. The core difference between our method and traditional data-centric SOMs lies on the intervention of topics in the learning process. Therefore we named the proposed SOM as topic-oriented SOM, or TOPSOM. Using the higher-level knowledge such as identified topics during training should provide deeper insight of the underlying documents and better guidance of the training. Besides, our method can naturally generate a categorization taxonomy with identified themes and hierarchical structure. Thus it is also well fit for tasks regarding text documents such as text categorization, text clustering, and text hierarchy generation.The remain of this article is organized as follow. Section 2 describes some works related to our research. In Section 3 we will introduce the proposed topic-oriented self-organizing map algorithm. Section 4 gives the experimental result. Finally, we give conclusions and discussions in the last section.

@&#CONCLUSIONS@&#
The self-organizing map model has been widely and successfully used in data clustering and visualization, as well as other wide scope of applications. Traditional SOM models cluster data according to their similarity. Besides, the structure of the map is always fixed. Various models have been proposed to overcome such insufficiency. In this work, we try to develop a novel learning algorithm which is suitable for text organization. When a set of text documents are being trained, we will identify the topics of a neuron which represents a document cluster after SOM training. We then use such topics to decide if a neuron needs to be lateral expanded or hierarchical expanded. Since our method incorporates various text mining approaches in training, it is feasible to use our method on text documents. The experimental results suggest that our method is adequate for developing structure which can be used for text categorization and organization.The major contributions of this work come from the incorporation of topic identification process into expansion of maps during SOM learning. Such incorporation is novel and well fit to text document organization. Various approaches on topic identification and their usage on expanding maps were suggested and tested. There are still problems undermined, such as the choice of parameters. In the next phase of our research, we try to develop a scheme to control the learning process to obtain sub-optimal result. We will also try to confine the learning process to some external constraints.