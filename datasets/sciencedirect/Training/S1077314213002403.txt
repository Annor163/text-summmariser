@&#MAIN-TITLE@&#
Efficient and robust multi-template tracking using multi-start interactive hybrid search

@&#HIGHLIGHTS@&#
We present an efficient and robust multi-template based visual object tracking method.The target is represented by two heterogeneous time-varying templates using Gaussian functions.The template is adaptively updated so that it can address both short- and long-term appearance variations.Target is located by an interactive multi-start hybrid search.Localization method consists of a sampling- and gradient-based algorithm in a unified probabilistic framework.

@&#KEYPHRASES@&#
Adaptive template,Gaussian-based appearance model,Multi-model representation,Parallel optimization,Non-rigid object,

@&#ABSTRACT@&#
This paper presents an efficient, accurate, and robust template-based visual tracker. In this method, the target is represented by two heterogeneous and adaptive Gaussian-based templates which can model both short- and long-term changes in the target appearance. The proposed localization algorithm features an interactive multi-start optimization process that takes into account generic transformations using a combination of sampling- and gradient-based techniques in a unified probabilistic framework. Both the short- and long-term templates are used to find the best location of the target, simultaneously. This approach further increased both the efficiency and accuracy of the proposed tracker. The contributions of the proposed tracking method include: (1) Flexible multi-model target representation which in general can accurately and robustly handle challenging situations such as significant appearance and shape changes, (2) Robust template updating algorithm where a combination of tracking time step, a forgetting factor, and an uncertainty margin are used to update the mean and variance of the Gaussian functions, and (3) Efficient and interactive multi-start optimization which can improve the accuracy, robustness, and efficiency of the target localization by parallel searching in different time-varying templates. Several challenging and publicly available videos have been used to both demonstrate and quantify the superiority of the proposed tracking method in comparison with other state-of-the-art trackers.

@&#INTRODUCTION@&#
Efficiency and reliability of many computer vision applications such as automated visual surveillance systems [1], motion analysis and activity recognition [2,3], vehicle navigation and tracking [4], and intelligent preventive safety systems [5] highly depend on their visual object tracking algorithm. In spite of extensive research, object tracking is still challenging generally due to the inevitable object appearance changes, scale variations, different lighting conditions, noise and outliers, complex motion, and cluttered environments. Specifically, the main difficulty in tracking non-rigid objects – which has been emphasized in this work – is related to the high dimensional complexity and uncertainty in real-world applications [6].In its simplest form, visual tracking can be viewed as the problem of locating and corresponding one or more image regions to a specific object in an image sequence. Visual trackers are roughly classified as either direct (image-based) methods or indirect (feature-based) methods. In the latter approach, different feature descriptors including silhouette [7], contour [8], texture [9], local invariant features [10], Haar-like features [11], and histograms [12,13] are used to model the object appearance. Feature descriptors can – to some degree – handle illumination changes, scale and appearance variations, and outliers. However, their suitability and robustness may significantly change from one application to another depending on the appropriateness of the feature descriptors used. Moreover, those descriptors such as SIFT [10], which can suitably handle the object non-rigidity and scale variations in many cases, are hampered in real-world applications due to the high computational cost of feature extraction and matching algorithms. On the other hand, in direct methods, the object appearance is modeled by one or more sub-images, known as templates, which consist of the image pixel values. Object regions are composed of both appearance and spatial information so that direct methods can track objects more accurately and robustly.Template matching is a well-studied computer vision problem which has been introduced by [14] for the task of visual tracking. In this method, the target region is considered as the templateT(X)whereX=(x,y)is the pixel coordinate, and the goal is to find the best corresponding match in the next imageInbased on the target dynamical modelW(X;Θ)whereΘ={θ1,…,θk}are the template transformation parameters. By minimizing the equation:(1)Θn=argminΘ∑X∈T[In(W(X;Θ))-T(X)]2which is the sum of squared differences (SSD) between the templateT(X)and the candidate sub-imageIn(W(X;Θ))we can find the best match transformation parametersΘn. A gradient-based algorithm to optimize Eq. (1) was introduced in [14]. However, conventional template trackers are not generally robust to significant appearance and scale variations, occlusion, and illumination changes.To address the shortcomings of template matching, in this paper a robust template tracking method based on the Sum of Gaussian Errors (SGE) between the object template and the candidate sub-image is proposed. The object template is modeled by several Gaussian functions which are adaptively updated to handle both the object appearance changes and the “drift” problem.1The problem of gradually updating the object appearance model with irrelevant information such as background pixel values [15].1At every tracking step, a certain number of probabilistic optimization processes with different starting points are performed in parallel to estimate the object location. The proposed method is capable of tracking non-rigid objects with variable appearance, shape, and scale in cluttered environments. It is assumed that the object location is specified either manually or automatically (by any existing object detection method) at the beginning and the main goal is to track the object without any prior knowledge about the object appearance and motion dynamic.The rest of this paper is organized as follows. Related work is reviewed in Section 2. In Section 3, the proposed multi-model target representation is defined. The formulation and algorithm of the proposed multi-start Gaussian-based template tracking method are explained in details in Section 4. In Section 5, the proposed tracker is applied on five challenging image sequences and subsequently the results are compared with four state-of-the-art methods as well as the ground truth data. Concluding discussions and potential extensions for future work will be provided in Section 6.

@&#CONCLUSIONS@&#
An efficient template-based, or direct, tracking method is presented in this paper. The proposed tracker is robust against object appearance, scale, and illumination changes as well as occlusion and cluttered environments. The representation model (i.e., object template) is defined by two heterogeneous adaptive templates consisting of Gaussian functions. A forgetting factor (γ) and an uncertainty margin (σ02) are used to update the Gaussian functions to increase the robustness and adaptability of the appearance model against both long-term and short-term changes over time. In addition, the variance values of the Gaussian functions are updated so that they can reject outliers such as background pixels. At every tracking step, a mixture of Gaussian errors between the object templates and a set of candidate sub-images are minimized using several Gradient-based optimization processes. Each optimization process is initialized with a different starting point to avoid trapping in local minimum and resolve the drift problem. Moreover, the parallel optimization algorithm is designed to improve the overall computational cost of tracking by interactively comparing the solutions. It is shown experimentally that a non-optimized Matlab (R) implementation of the proposed tracker can on average process 31.76 frames per second and hence meets the demand of typical real-time applications.Shown in Table 2, the proposed method performed well in different challenging situations including appearance and pose changes, scale variations, different illumination, and occlusion, however, it occasionally drifted from the target particularly when the target appearance is significantly changed and it is occluded as well. For instance, in Fig. 7 around frame #300,Moreover, it has been observed that the accuracy and robustness of the proposed tracker do not significantly depend on its parameter values (the tracking parameters are the same in all experiments, we have observed that the tracking result is fairly robust with different choice of parameters). However, different parameter values may change the overall performance of the proposed tracker. For instance, a smaller value for the maximum error of the localization optimization (optmax_err) or a greater number of starting points can improve the accuracy of the tracking in the expense of an increased computational cost. In general, the tracking parameters constitute a trade-off between accuracy and efficiency.As a limitation of the proposed tracker, only region-based models can be integrated into the proposed multi-model target representation. However, a modification of the parallel optimization process can be effectively used for both region-based and feature-based multi-model representations. Moreover, it has been observed that this method may fail to re-track the target which has been fully occluded for a long time. To solve this problem, another adaptive template which is robust against the long-term changes can be added to the proposed representation model. As a result, the target can also be tracked under long-term and full occlusion.