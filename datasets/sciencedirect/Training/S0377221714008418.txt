@&#MAIN-TITLE@&#
On the unified dispersion problem: Efficient formulations and exact algorithms

@&#HIGHLIGHTS@&#
We operationalize the partial-sum dispersion model that unifies four classic models.We develop a more compact ILP formulation that is faster on average.We developed an exact method that is orders of magnitude faster.All problem instances can be solved on a medium sized problem in 20 seconds.

@&#KEYPHRASES@&#
Location,Facility dispersion,

@&#ABSTRACT@&#
Facility dispersion problems involve placing a number of facilities as far apart from each other as possible. Four different criteria of facility dispersal have been proposed in the literature (Erkut &#38; Neuman, 1991). Despite their formal differences, these four classic dispersion objectives can be expressed in a unified model called the partial-sum dispersion model (Lei &#38; Church, 2013). In this paper, we focus on the unweighted partial sum dispersion problem and introduce an efficient formulation for this generalized dispersion problem based on a construct by Ogryczak and Tamir (2003). We also present a fast branch-and-bound based exact algorithm.

@&#INTRODUCTION@&#
Facility dispersion problems involve maximizing the separation between facilities to minimize the negative impact they have on each other, minimize potential interaction among hazardous facilities, or enhance the reliability of service and logistic systems. Facility dispersal can be used in a variety of applications including military defense, franchise location, transportation of hazardous materials, layout planning for explosive chemicals (Curtin &#38; Church, 2006) and telecommunication network design (Kim, 2012). Curtin and Church (2007) demonstrate that patterns in the classic central place theory can be replicated using facility dispersal. Facility dispersal has also been deemed as a means to promote the robustness and reliability of critical facilities when it is integrated with other classic location models (Maliszewski, Kuby, &#38; Horner, 2012).To capture the dispersive quality in different applications, multiple models for facility dispersal have been proposed. Four basic constructs have been developed in the literature to disperse facilities from each other. The first was suggested by Shier (1977) in which p-facilities are located while maximizing the minimum distance separating any two facilities. This problem has been called the p-dispersion problem (Moon &#38; Chaudhry, 1984) and has also been termed the Max–Min–Min problem (Erkut &#38; Neuman, 1991). Moon and Chaudhry (1984) proposed a second form of facility dispersal, which involved defining the minimum separation distance for each located facility. They proposed to locate p-facilities in order to maximize the sum of these minimum separation distances. Moon and Chaudhry called this the p-defense problem and Erkut and Neuman classified this problem as a Max–Sum–Min, as this involves MAXimizing the SUM of MINimum separation distances. Kuby (1987) introduced a third form of p-facility dispersal that he called p-dispersion sum. This problem involved maximizing the sum of all separation distances, which has been called the Max–Sum–Sum problem as it involves MAXimizing the SUM (over each facility) of SUMs (the sum of all separations distances for that facility) (Erkut &#38; Neuman, 1991). The last of the four classic facility location dispersal problems was suggested by Erkut and Neuman (1991). This problem deals with the location of p-facilities while maximizing the smallest of the facility defined sums (a facility sum represents the sum of separation distances from a specific facility location to all other facilities) and has been classified as the Max–Min–Sum problem (Erkut &#38; Neuman, 1991).Curtin and Church (2006) added a new dimension to facility dispersal by conceptualizing a multi-type dispersion metric recognizing that the extent to which two facilities ought to be dispersed should depend on their types. The strength of interaction between facilities is modeled using both the traditional separation distance and a type-specific “repulsion” factor in which a smaller repulsion measure reflects a stronger inter-facility interaction. Curtin and Church developed four dispersion models based on the four basic dispersion metrics classified in Erkut and Neuman (1991) and the multi-type metric where each multi-type dispersion model is a multi-type extension of a classic dispersion model.Fernández, Kalcsics, and Nickel (2013) proposed an extended dispersion problem involving locating multiple groups of facilities and applied the multi-group dispersion model to the location of recycling facilities. A dispersion metric corresponding to the Max–Min–Min criterion is maximized for each group of facilities. To ensure even distribution of workload, each facility is assigned a weight value and the sum of weights for each group is constrained to be within a range of a pre-specified target weight value. Equity issues in dispersion modeling have also been addressed in Prokopyev, Kong, and Martinez-Torres (2009).Dispersion problems are related to the maximum independent set problem and the maximum clique problem in graph theory. The p-dispersion problem, for example, can be reduced to the maximum independent set problem by removing edges longer than a given length r and find the maximum independent set on the converted graph (Erkut, 1990). The p-dispersion problem can be solved by solving a series of maximum independent set problems with increasing r values until the size of the maximum independent set is p. Solution methods for the maximum independent set problem have been explored by many researchers. Feo, Resende, and Smith (1994) proposed a parallel Greedy Randomized Adaptive Search Procedure (GRASP) for the maximum independent set problem and found it to be superior in performance to tabu search and simulated annealing methods. Hifi (1997) developed a genetic algorithm for the weighted maximum independent set program, which can be used also to solve equivalent problems such as the maximum clique problem. Gamarnik and Goldberg (2010) presented complexity results of greedy randomized algorithms on constant degree regular graphs.With few exceptions, the majority of research on facility dispersion in the past two decades has involved the four basic dispersion models classified by Erkut and Neuman (1991). Lei and Church (2013) recently proposed a generalized dispersion model based on the concept of partial sums. At the individual facility level, the partial-sum dispersion metric involves accounting for the sum of the smallest L distances to neighboring facilities, weighted by a set of propulsion factors that can be used, for example, to emphasize the interaction of closely located facilities. At the system level, the model considers the sum of the K smallest facility-defined partial sums. This general construct is called the MaxPSumPSum problem (where PSum stands for partial sum). Lei and Church provided an integer linear programming formulation of this general partial-sum dispersion problem based on assignment variables which tracked specific separation distances.The partial sum dispersion metric is a compromise of the one-or-all approach found in the four basic dispersion models and makes more sense in modeling many types of inter-facility interactions. For example, in franchise branch location, stores from the same franchise chain should be located away from each other to minimize cannibalization within the same organization. However, existing dispersion models either considers competition from the nearest store and ignores competition from other nearby stores, or considers competition from all stores in the franchise chain including remote sites that have little effect on a store. It would make more sense to consider a number of closest stores using the partial-sum dispersion metric. As another example, in military defense, it is common wisdom to locate assets such as missile silos apart from one another to minimize the chance that two facilities are destroyed at the same time. However, if avoiding the simultaneous loss of two facilities leads to low average spacing between sites, from management's perspective, it may be desirable to devise a facility layout that minimizes the chance of losing three or more facilities simultaneously.From a theoretical point of view, the MaxPSumPSum construct unifies all four classic dispersion models as special case problems. This means that the MaxPSumPSum problem not only defines a family of new (PSum) dispersion models, but also makes it possible to solve all four existing facility dispersal problems as special case instances. It should be noted that partial-sum dispersion should not be confused with similar partial-sum metrics in median location problems, which involveminimizingpartial sums of demand-to-facility distances either at the individual facility level (Weaver &#38; Church, 1985) or at the system level (Nickel &#38; Puerto, 1999). The reader is referred to Lei and Church (2014) for a median location problem that considers such location criteria in a unified construct.Facility dispersion problems often have high computational complexities. It is well-known that both the p-dispersion problem and the p-dispersion sum problem are NP-hard (see e.g. Erkut, 1990; Pisinger, 2006). In addition, no polynomial-time heuristic procedure (or approximation algorithm) can guarantee to obtain a near optimal solution for the p-dispersion problem that is within any fixed percentage of the optimal value (Tamir, 1991). In the special case where the separation distances satisfy the triangle inequality, a heuristic for the p-dispersion problem exists with an approximation ratio of 2 (Tamir, 1991) and this ratio is the best possible (Ravi, Rosenkrantz, &#38; Tayi, 1994). An approximation algorithm for the p-dispersion sum problem also exists with an approximation ratio of 4 (Ravi et al., 1994).Since it subsumes the four classic dispersion problems as special-cases, the generalized dispersion problem should have a computational complexity that is no less than the special-case problems. Lei and Church (2013) report high computation costs of the generalized dispersion problem in their experiments. Certain medium-sized instances of the MaxPSumPSum problem cannot be solved using their ILP formulation in hours. In fact, one example presented in Lei and Church (2013) involving 55 candidate sites and locating 10 dispersive facilities took a week and half to solve. In many applications, such high computational costs may well prevent the model from being applied in practical analysis.This article aims at operationalizing the generalized dispersion model by developing improved model formulations and efficient, specialized solution procedures. In particular, we focus on a special case of the partial-sum dispersion model defined without the propulsion factors. It should be noted that this version of the partial-sum dispersion problem is still very general because the four classic dispersion models are defined without the propulsion factors and therefore are its special cases. To avoid ambiguity, we refer to the general partial-sum dispersion problem as the weighted partial-sum dispersion problem and the version without propulsion factors as the unweighted partial-sum dispersion problem. We demonstrate that a compact and efficient formulation of the unweighted partial-sum dispersion model can be developed by using a linear program by Ogryczak and Tamir (2003) twice within the model formulation. Our computational experiments show that for the same problem instances solved by Lei and Church (2013), the new formulation can solve the partial dispersion problems faster in a majority of the cases. Moreover, we develop and present an interchange heuristic inspired by Teitz and Bart (1968) in conjunction with a branch and bound search, which are orders of magnitude faster than the integer linear programming approach. As will be shown in the experiment section, the branch and bound procedure can solve the same 55-node problem instance that took the ILP formulations a week and a half in about 3 minutes, which makes the partial-sum dispersion model suitable for location analysis in day-to-day operations.The unweighted partial-sum dispersion problem can be formally defined as follows:Locate a set of p facilities such that the sum of K worst-case facility-based sum of distances is maximized, where each facility-based sum of distances is the partial sum of L smallest distances from its neighboring facilities.To illustrate the concept of the partial sum dispersion problem, consider the following example in Fig. 1, in which three dispersive facilities are located among five candidate sites using a partial sum dispersion metric with K =1, and L =2. In the example, the coordinates for candidate sites (from A to E) are labeled. Distances between sites (in Table 1) are Euclidean distance rounded to the nearest integer.For a particular three-facility set such as {A, C, D}, the partial sum metric is calculated by computing the sum of smallest two inter-facility distances for each facility. Referring to Table 1, the partial sums of distances to L = 2 neighbors for A, C and D are 12, 9 and 11, respectively. Adding the K = 1 partial sums, the partial-sum dispersion metric for this facility set is 9. Enumerating all 10 possible 3-facility combinations, one can verify that the facility set {A, C, D} is actually the greatest possible, and {A, C, D} is an optimal solution for this small example.In a companion paper (Lei &#38; Church, 2013), we developed an assignment formulation (MaxPSumPSumA) of the partial dispersion problem. Here, we show that a more compact formulation of the partial-sum dispersion problem (called MaxPSumPSumC) can be developed using a linear program by Ogryczak and Tamir (2003) that maximizes the sum of the smallest k elements in a set of numbers. The following notation is needed for MaxPSumPSumC:I is a finite set of points representing potential facility sites.i, j are indices used to represent facility sites, where i ∈ I, j ∈ I, I = {1, 2, …, n}.dij= separation distance between sites i and j.dij= the sum of the smallest L + 1 distance assignments for site i, andMi= L · maxj ∈ Idijis a sufficiently large number (which is chosen to be larger than any possible partial sum value for each i).The decision variables are:yi= 1, if a facility is located at site i, and 0 otherwise.t and uiare auxiliary variables used in Ogryczak and Tamir (2003)’s program to compute the sum of the K smallest facility based partial sums. As will be explained shortly, uiis non-zero if i is associated with one of the K smallest partial sums, and zero otherwise.uiand zijare similar auxiliary variables. zijis non-zero when j is one of the L + 1 closest assignments to site i, and zero otherwise.The variable zijserves a similar role as variable uiexcept that it pertains to the sum of L + 1 closest assignments to site i. Note that we need the sum of the L + 1 closest facilities to i because it will include the zero self-distance from i to itself (i.e. dii= 0). That is, the sum of L + 1 smallest distances will equal the sum of distances to the L closest neighboring facilities. With this notation, the model formulation is as follows:MaxPSumPSumC:(1)maximizeKt−∑i∈Iuisubject to:(2)t−ui≤qiforeachi∈I(3)qi=(L+1)si−∑j∈Izijforeachi∈I(4)si−zij≤yidij+Mi(2−yi−yj)foreachi∈I,j∈I(5)∑i∈Iyi=p(6)ui≥0,zij≥0foreachi∈I,j∈I(7)yi∈{0,1}.To understand this formulation, we need to explain the linear program of Ogryczak and Tamir (2003) which maximizes the sum of the K smallest quantities in an array. This linear program has actually been employed twice here. First of all, it is applied at the system level to choose the sum of the K smallest of all facility-based partial sums {qi}, i = 1, 2,...,n. More specifically, the system-level program is:(8)maximizeKt−∑i=1nuisubject to:(9)t−ui≤qiforalli∈I(10)ui≥0foralli∈IA formal proof of the correctness of the linear program (8)–(10) can be found in Ogryczak and Tamir (2003). One can also see why (8)–(10) can select the sum of K smallest facility-based partial-sum {qi} as follows.Let q(s) be the sth smallest member of {qi}and let π(s) be the index of q(s). By (9), the maximizing objective function in (8) clearly satisfies the following inequality:Kt−∑i=1nui≤Kt−∑s=1Kuπ(s)≤∑s=1Kq(s).Thus, the sum of K smallest elements of {qi} (the right hand side) is an upper bound on the objective (the left hand side). But this upper bound can be achieved easily when one sets uπ(s) = 0, for s > k and uπ(s) = t − qπ(s), for s ≤ k on the left hand side. Therefore, the optimal objective value of (8) is equal to the k smallest facility-based partial-sums∑s=1kq(s). This construct is especially valuable in that it is possible to identify the sum of the K smallest elements without ordering them by value and summing the first K smallest elements.Secondly, the same construct (8)–(10) can be modified and used to compute each facility-based partial sum qi. Here, instead of maximizing the sum of K smallest partial sums, we maximize for each site i the sum of the smallest distances to L neighboring facilities. Considering the zero self-distance dii= 0, we need to maximize the sum of smallest L + 1 distances to any given facility i ∈ I, which amounts to solving the following “lower-level” maximization problem for each i ∈ I:(11)maximizeqi=(L+1)si−∑j∈Izijsubject to:(12)si−zij≤yidij+Mi(2−yi−yj)forallj∈I(13)zij≥0forallj=1,2,...,n.Compared with (8)–(10), in the lower-level program (11)–(13), the number of elements to sum is L + 1 instead of K; the elements to be summed are distances to site i (i.e., dij) instead of the facility-based partial sums (qi); and the objective value being maximized is an individual facility-based partial sum qiinstead of the partial sum of the smallest qi’s. Of note, is that in the right hand side of (12), in order to compute the facility-based partial sum we have to select from distances to open facilities only and not just any dij. To achieve this, we resort to using a sufficiently large value Midefined for each site i. The right hand side (RHS) of (12) equals dijonly if both sites i and j are selected for facility location (i.e., yi= 1, yj= 1 ). Otherwise, the RHS of (12) is at least Miand will not be selected into the smallest L + 1 distance values by the definition of Mi.Thirdly, at the higher level we need to maximize the K smallest qi’s obtained from (11) through (13). This amounts to solving the higher level program (8)–(10) with the understanding that qiis defined by the optimal value of (11)–(13). Since the higher-level program also aims to maximize the qi’s, we can simplify the two-level maximization problem into one-level maximization by dropping the “maximize” operator in (11) to obtain (3) and therefore derive the MaxPSumPSumC formulation in (1)–(7).Of note, the Ogryczak and Tamir (2003) program can be used to find the smallest k numbers in an array without explicitly sorting distances. This construct suffices for the partial-sum dispersion problem considered here. However, as discussed in Lei and Church (2013), the multi-level closest assignment (MLCA) constraints (Lei &#38; Church, 2011) will be needed to define the specific ordering of neighboring facilities, if propulsion factors are used based on the relative rank of distances from neighboring facilities. This assignment-based formulation (called MaxPSumPSumA and listed inAppendix A) consequently has a higher problem dimension and involves L times more continuous variables and about 30 percent more constraints than MaxPSumPSumC. The reader is referred to Lei and Church (2013) for properties of the assignment formulation.The general partial-sum dispersion problem (i.e. MaxPSumPSum) is NP-hard since one of its special case problems, the p-dispersion problem, is NP-hard. This means that, in general, no polynomial bounded time algorithm will likely exist to solve the problem optimally. Our experiments, presented in the next section, show that although the MaxPSumPSumC formulation can be used to solve many medium sized problems optimally using commercial Integer-linear programming solvers, the computational cost for the general dispersion problem is still relatively high. The complexity of the general dispersion problem calls for efficient, specialized solution procedures. To address this issue, we have developed a branch and bound solution algorithm for the general dispersion problem. Our experiments show that the method is effective and orders of magnitude faster than the integer linear programming formulation described in the previous section or the assignment formulation in Lei and Church (2013). A heuristic is used to jump-start the branch and bound procedure. We will describe the heuristic first.The heuristic procedure we propose is based on a greedy drop strategy and the interchange heuristics that has been widely used in the operations research literature, including location-allocation problems such as the p-median problem (see e.g. Drezner &#38; Drezner, 2007; Rosing &#38; ReVelle, 1997; Teitz &#38; Bart, 1968; Whitaker, 1982). The work flow is,1.Initially, all sites are added to the set S of selected facilities. For any given S, the dispersion objective Z is calculated according to (1) by summing the smallest L distances for each facility and adding the K smallest partial sums.(Greedy drop) Each facility is tentatively removed from S. The facility that, if removed, generates the greatest PSum dispersion objective Z is deleted from S. This step is repeated until p facilities are left in S.(Interchange) For each facility x in S,Remove x from SFor each site y in I\S,Add y into SUsing (1) to compute the dispersion objective Z associated the p-facility set S, and the new dispersion objective Zyassociated with S∪{y}\{x}. Define the net change δyin the dispersion objective as δy= Zy− Z.If δyis positive and δy> δy' for all previously tested site y', let ymax  = y, xmax  = x.4.Repeat Step 3 until no improvement can be made (i.e. no positive δycan be found). Stop and return S∪{ymax }\{xmax } as the heuristic solution.The exact method we propose is a depth-first branch and bound process inspired by Pisinger (2006). Pisinger (2006) derived multiple upper bounds for the p-dispersion problem and the p-dispersion sum problem, respectively. This includes, in particular, a tight upper bound for the p-dispersion sum problem based on relaxing the cardinality constraint (5) and a symmetric property of the p-dispersion sum problem. More specifically, Pisinger observed that in the p-dispersion sum problem, when the distance dijfrom i to j is in the objective value (i.e. when both i andj are selected), djimust also be in the objective function. Consequently, the distance dijcan be changed to dij+ λij, as long as λijsatisfy λij+ λji= 0. Based on this property, Pisinger (2006) was able to develop tightened upper bounds by minimizing bounds over all λij, subject to λij+ λji= 0. Unfortunately, the generalized dispersion problem does not have this symmetric property as the p-dispersion sum problem does, because djiis not necessarily in the partial sum of j when dijis in the partial sum of i. We develop an upper bound based on relaxing the requirement that each facility can be only linked to open facilities. This requirement corresponds to relaxing the Balinski constraint (20) in the assignment formulation inAppendix A (Lei &#38; Church, 2013), which requires that only distances to open facilities are counted in partial sums.The branch and bound procedure starts from an initial solution, which in our case is the output of the interchange heuristic. The objective function of the initial solution is used as a lower bound on the optimal objective value as it is a feasible solution and any optimal solution will be at least as good as the initial feasible solution. As the branch and bound process progresses, the lower bound is updated with the best/greatest feasible objective value.In our branch and bound tree, a site at any node of the tree can only be in one of the three states: fixed in, fixed out or free. If a site is fixed out, it is excluded from further consideration in any descendants of the current node. If it is fixed in, it must be included in the final solution in any descendants. Otherwise, the site is free. Since the Balinski condition is relaxed, a site i can be assigned to any other site j as long as j is not fixed out. There are two cases that need to be handled. In order to compute an upper bound uifor the partial sum sifor a given site i,a)For sites that are fixed in (i.e. in the final solution), we can safely choose the smallest distances from them to i to include in ui. If a free site that is closer than all current fixed-in sites is fixed in later, the dispersion objective will only be reduced.For sites that are free, we should choose the larger distances from them to obtain an upper bound.Therefore, tocalculate ui, we first sort the fixed-in sites in increasing distance order with respect to i. If the number of fixed-in sites is equal to L (i.e. when a leaf node is reached), we select and add them (excluding the zero self-distance) to obtain the partial sum. If the number of fixed in sites is less than L, we add distances to all other fixed-in sites, and then sort the free sites in decreasing distance order and add the greatest distances until we have L entries to make the partial sum.Our branch and bound procedure traverses the tree in solution space in the depth-first order. If the upper bound computed for any node is less than the best known lower bound, this branch is excluded from further consideration (fathomed). In choosing the order of which tree node to expand first, we try to fix in or fix out the lower indexed sites first. We have experimented with other orders of tree expansion such as alternating between high and low indexed sites, but the solution times were not significantly different. We have also experimented with using other heuristic strategies such as random starts, rather than greedy drop, but they did not appreciably add to the quality of the heuristic results.In this section, we present experimental results for the proposed integer linear programming formulation, the interchange heuristic, and the exact solution procedure. As with Lei and Church (2013), we use the 25 node dataset in Kuby (1987) and the 55 node dataset of Swain (1971), which are widely used in the literature. All computations were performed on an Intel i7 3770 3.4gigahertz CPU with 32gigabytes of system memory, which is the same configuration with the machine used in Lei and Church (2013). The operating system was Microsoft Windows Server 2008 R2. The heuristic and exact branch and bound method were programmed in standard C++ (C++ 2011) and compiled using GNU Compiler Collection (GCC) version 4.8. For solving the MaxPSumPSumC formulation we used IBM ILOG CPLEX 12.4.Computational results for solving the MaxPSumPSumC formulation using CPLEX applied to the Kuby dataset are presented in Table 2. Column 1tabulates the problem parameters p, K and L. We tested the same problems instances as those in Lei and Church (2013). This includes two sets of parameters for dispersing five and seven facilities, respectively. For p =5, problem instances in the first, third, seventh and ninth rows correspond to the p-dispersion problem, MaxMinSum, MaxSumMin and p-dispersion sum problems, respectively. Column 2 tabulates the optimal/best known objective value. Columns 3, 4 and 5 present the computational time in seconds, the number of iterations and the number of expanded nodes by CPLEX, respectively involving the MaxPSumPSumC formulation. Column 6 presents the optimal/best known dispersion pattern. Column 7 gives the computational time for the MaxPSumPSumA model reported in Lei and Church (2013). Compared with the MaxPSumPSumA model, the MaxPSumPSumC model solved 17 out of 21 problems faster than the MaxPSumPSumA model. For example, when p =7, K =7, L =3, MaxPSumPSumC took 95 seconds to solve while MaxPSumPSumA took 1156 seconds. It is important to note that for problem instances where L = p − 1, the MaxPSumPSumA is often faster. For example, when p =7, K =1, L =6, MaxPSumPSumC and MaxPSumPSumA took 55 and 1.4 seconds, respectively. On the average, Model C is considerably faster than the Model A resultsreported by Lei and Church (2013).Table 3 presents results for solving the MaxPSumPSumC formulation using CPLEX involving the Swain dataset. The same problem parameters as Table 2 were tested. A 6 hour time limit was imposed, and the optimality gap is reported in column 6 of the table if a problem instance cannot be solved optimally. Computational times for the larger Swain dataset are greater. However, for MaxPSumPSumC, most (16 out of 21) instances can be solved to optimality. Column 7 presents the results of Lei and Church for the same problems using their MaxPSumPSumA model. The MaxPSumPSumA model was solved to optimality in 14 out of the 21 problem instances within the imposed maximum time limit. Compared with the assignment formulation, the MaxPSumPSumC formulation was able to be solved faster in 14 out of 18 comparable cases. For example, for the p =5, K =1, L =1 case, MaxPSumPSumC and MaxPSumPSumA took 13 and 233 seconds respectively.For more than two thirds of the tested instances in Tables 2 and 3, the MaxPSumPSumC formulation performs better than the assignment formulation. However, when the L value is large, the assignment formulation tends to perform better. While this property is difficult to prove in general, one possible explanation is as follows. In the MaxPSumPSumC formulation, the lower-level program (11)–(13) uses the “big M” method in formulating constraints (12), which is known to be integer unfriendly (for the yivariables) and the larger the value of L is, the larger the natural gap is between the optimal and the relaxed problem. On the other hand, while the assignment formulation does not involve using “big M” based constraints, it does have a greater number of decision variables and constraints, as discussed earlier.Overall, the MaxPSumPSumC is an improved formulation for the generalized dispersion problem, especially for small values of L. The new formulation is advantageous in facility dispersal applications such as franchise branch location, in which only the impact of a (small) number of nearby facilities need to be accounted for. For smaller values of K and L, medium sized problems can be solved optimally within 15 minutes using commercial solvers. However, computational times for larger K and L values may be long even if some of the problem instances were solved optimally within 3 hours. This reveals the combinatorial complexity of the generalized dispersion problem and the limitations of solving them using a general purpose ILP solver. However, it should be noted that the formulation presented here appears to be distinctly better on the average than what has been reported in earlier work by Lei and Church (2013).Table 4 presents the computational results for the interchange heuristic and the exact method on the same problem instances involving the Kuby dataset. Columns 2 and 3 tabulate the dispersion objective value obtained by the heuristic and the running time of the heuristic. Column 4 presents the objective values generated by the exact method and column 5 gives the running times for the exact method. In 22 out of the 25 tested instances, the interchange heuristic generated solutions that are greater than 70 percentof the optimal value (but less than the optimal value itself). Comparing Tables 2 and 4, the exact method generates the same optimal objective values as the ILP formulation. However, the overall solution time improved drastically. All tested instances were solved within a second, while the longest solution time was reduced from 284 seconds to 0.81 seconds when comparing the MaxPSumPSumC model to that of the exact tree search method. In most instances, the exact method is orders of magnitude faster.Table 5 presents computational results of the heuristic and exact methods on the larger Swain dataset. In 20 out of the 25 tested instances, the heuristic generates dispersion objectives that are greater than 70 percentof the optimal. Solution times of the exact method are significantly shorter when compared to the ILP formulations. All problem instances can be solved optimally within 20 seconds. Overall, this represents a dramatic reduction in computational effort. This clearly shows the efficacy of the exact method.For illustration, we show in Fig. 2 an optimal solution of MaxPSumPSum solution with 10 facilities and K =2, L =4 (adapted from Lei and Church, 2013). In this setting, the negative impact from the nearest four facilities is considered, and the two most impacted sites are considered in the dispersion metric. Note that for this example with relatively low K and L values, the assignment formulation took 9.5 days (819,858 seconds) to solve, whereas the branch-and-bound procedure obtained the same optimal value in just 195 seconds.From Fig. 2, we can observe that the optimal solution to the partial sum dispersion problem differs from a traditional p-dispersion solution in that some facilities are allowed to locate relatively close to each other. This is the case, for example, for sites 24 and 35. However, the nearest four facilities are kept far away from any facility on average. This reduces the total negative impact from neighboring facilities, without counting distances of very far facilities in the dispersion objective. In locating missile silos, solutions like Fig. 2 increase the possibility of certain pair of facilities being taken out simultaneously, but reduce the risk that four (or L) facilities are lost simultaneously in one strike.

@&#CONCLUSIONS@&#
