@&#MAIN-TITLE@&#
Novel energy and SLA efficient resource management heuristics for consolidation of virtual machines in cloud data centers

@&#HIGHLIGHTS@&#
A multi criteria resource allocation policy is proposed.A multi criteria policy for determination of underloaded PMs is proposed.A novel holistic resource management procedure is proposed.The results show up to 45% reductions in energy consumption.The results show up to 99% reductions in SLA violation.

@&#KEYPHRASES@&#
Cloud computing,Consolidation,Data center,Energy consumption,Resource allocation,

@&#ABSTRACT@&#
Proliferation of IT services provided by cloud service delivery model as well as diverse range of cloud users have led to the establishment of huge energy hungry data centers all around the world. Therefore, cloud providers are confronted with great pressures to reduce their energy consumption as well as their CO2 emissions. In this direction, consolidation is proposed as an effective method of energy saving in cloud data centers. This paper proposes a new holistic cloud resource management procedure as well as novel heuristics based on multi-criteria decision making method for both determination of underloaded hosts and placement of the migrating VMs. The results of simulations using Cloudsim simulator validates the applicability of the proposed policies which shows up to 46%, 99%, and 95% reductions in energy consumption, SLA violation, and number of VM migrations, respectively in comparison with state of the arts.

@&#INTRODUCTION@&#
Cloud computing has recently been brought into focus in both academic and industrial communities due to the increasing pervasive applications and the economy of scale that cloud computing provides [1,2]. Cloud computing is an operational management model that brings some new modern technologies together to provide extensive services dynamically for all range of cloud users. The research and development community has quickly reached consensus on core concepts of cloud computing such as on-demand computing, elastic scaling, elimination of up-front capital and operational expenses, and establishing pay-as-you-go business model for information technology services [3]. Three main types of cloud computing services are Infrastructure as a Service (IaaS), Platform as a Service (PaaS) and Software as a Service (SaaS) [4]. Users can easily avail of these services on a pay-as-you-use basis without any geographical restrictions [5].As a direct result of cloud computing’s increasing popularity, cloud computing service providers such as Amazon, Google, IBM and Microsoft have begun to establish increasing numbers of energy hungry data centers for satisfying the growing customers resource (e.g. computational and storage resources) demands [6]. Continuous increase in energy consumption of such huge data centers raises a great concern for both governments and service providers to consume energy more effectively. Apart from the overwhelming operating costs and the total cost of acquisition (TCA) caused by high energy consumption, another rising concern is the environmental impact in terms of carbon dioxide (CO2) emissions [7]. The main portion of energy waste in cloud data centers is in their hardware infrastructure including servers, storage, and network devices. Since hardware devices consume their near maximum power level when they are idle, not fully utilizing them leads to enormous energy wastage. Forrester Research states that servers use nearly 30% of their peak power consumption while sitting idle 70% of time [8]. So, the basic reason of energy waste in data centers’ infrastructure is underutilization. Cloud provides scalability using virtualization and host applications which suffer high load at certain times [9].Server consolidation using virtualization is an effective approach to achieve better energy efficiency of cloud data center [1,10,11]. The reason is that at times of low load, VMs are consolidated on a limited subset of the available physical resources, so that the remaining (idle) computing nodes can be switched to low power consumption modes or turned off [6]. Virtualization is an important feature of cloud computing that allows providing multiple VMs on a single physical machine as well as migration of VMs [12]. Due to the heterogeneity of cloud resources, and also the fact that cloud users may have sporadic and dynamic resource consumption, the cloud environment is highly dynamic. On the other hand, considering various goals that sometimes are contradicted with each other makes the resource management problem in cloud data center a challenging issue which needs tuning some trade-offs between targets. Cloud computing infrastructure controller has to guarantee pre-established contracts despite all the dynamism of workload changes and also it has to efficiently utilize resources and reduce resource wastage [13]. The basic online consolidation problem in cloud data centers is divided into four parts [10]: (1) determining when a host is considered as being overloaded; (2) determining when a host is considered as being underloaded; (3) selection of VMs that should be migrated from an overloaded host; and (4) finding a new placement of the VMs selected for migration from the overloaded and underloaded hosts. This paper focuses on the second and the fourth phases and proposes novel heuristics for them.According to [14], solving the resource allocation problem using a vector packing algorithm is the best approach for static workloads. However, the key fact that workloads in cloud environments are dynamic makes this conclusion weak for cloud environments. Moreover, the vector packing problem is NP-hard [10]. So, heuristic algorithms such as Best Fit Decreasing (BFD) algorithm have been developed by researchers to solve it. BFD is shown to use no more than 11/9.OPT+1 bins (where OPT is the number of bins provided by the optimal solution) [15]. For instance, [16,10] model the problem of resource allocation as a bin packing problem with variable bin sizes and prices and solve it by applying Modified Best Fit Decreasing (MBFD) algorithm and Power Aware Best Fit Decreasing (PABFD) algorithm, respectively. The major drawback of current approaches for resource allocation problem in virtualized cloud data center is that they only consider one target such as power consumption in the core of their solutions. However, this paper proposes multi-criteria algorithms based on the Technique for Order of Preference by Similarity to Ideal Solution (TOPSIS) [17] for both resource allocation and underloaded PM determination phases. The proposed policies simultaneously optimize energy consumption, SLA violation, as well as the number of VM migrations. Another major contribution of this paper is proposing novel procedure for the whole process of resource management in virtualized cloud data centers. The main idea behind this policy is solving the resource allocation problem for the VMs that are selected to be migrated from either overloaded or underloaded PMs in one step rather than in separate steps for each one. By doing so, a holistic view of resource allocation can be applied to the aggregated VMs and consequently a more precise solution can be found for the problem.The main contributions of this paper are:•Proposing a novel multi criteria resource allocation method namely TOPSIS Power and SLA Aware Allocation (TPSA) policy that simultaneously optimizes energy consumption, number of VM migrations and SLA violations.Proposing a novel multi criteria method for determination of underloaded PMs including Available Capacity (AC), Migration Delay (MDL), and TOPSIS-Available Capacity-Number of VMs-Migration Delay (TACND) Policies.Proposing Enhanced Optimization (EO) policy for the whole process of resource management in cloud data centers that aggregates the resource allocation phases for the VMs selected to be migrated from either overloaded or underloaded PMs in one single phase.This paper begins by reviewing related works in Section 2. Section 3 presents system models including data center model and the metrics used to evaluate the efficiency of the proposed policies. Section 4 presents our proposed EO policy for the whole process of resource management. Sections 5 and 6 present our proposed resource allocation policy and the policies proposed for determination of underloaded PMs, respectively. Section 7 assesses the applicability of our proposed solutions using Cloudsim simulator. Finally, concluding remarks and future directions are presented in Section 8.As stated in [2], there is a wide area of research in resource management field in cloud computing including resource provisioning, resource allocation, resource adaptation, resource mapping, resource modeling, resource estimation and resource brokering.The authors in [18] have investigated power management techniques in the context of large-scale virtualized systems for the first time. In addition to the hardware scaling and VMs consolidation, they have proposed a new power management method for virtualized systems called “soft resource scaling.” Also, they have suggested dividing the resource management problem into local and global levels. In the local level, the algorithms monitor power management of guest VMs. On the other hand, global policies coordinate multiple physical machines. In this paper, the goal of the proposed model is minimizing energy consumption as well as satisfying performance requirements.The authors in [1] have proposed a number of VM consolidation algorithms for cloud data center energy reduction considering structural features such as racks and network topology of the data center underlying the cloud. More precisely, they have taken into account the cooling and network structure of the data center hosting the physical machines when consolidating the VMs. By doing so, fewer racks and routers are employed, without compromising the service-level agreements, so that idle routing and cooling equipment can be turned off in order to reduce the energy consumption.The authors in [19] have addressed the problem of power management by incorporating five different policies for power management. They have evaluated power consumptions of physical machines individually and distributed power dynamically across them to fulfill the group power budget. They have modeled VM allocation as an integer programming problem. Also, the aims of the proposed algorithms are to minimize power consumption, minimize performance loss, and meet power budget. However, the authors do not provide specific solutions to guarantee service level agreement (SLA) in cases of workload fluctuations.The authors in [12] have proposed efficient consolidation algorithms which can reduce energy consumption and at the same time the SLA violations in some cases. They have introduced an efficient SLA-aware resource allocation algorithm that considers the trade-off between energy consumption and performance. Their proposed resource allocation algorithm takes into account both host utilization and correlation between the resources of a VM with the VMs present on the host. Moreover, they have proposed a novel algorithm for determination of underloaded PMs in the process of resource management in cloud data centers considering host CPU utilization and number of VMs on the host.The authors in [20] have investigated the problem of power- and performance-efficient resource management in virtualized data center environments. The goal of this paper is to maximize the resource provider’s revenue by minimizing power consumption and SLA violation simultaneously. They have addressed the resource management problem using a sequential optimization model and proposed solutions using a limited look-ahead control to estimate future system states over a prediction slot by the help of Kalman filter. Decision goals to be optimized are the following: the number of VMs to be provisioned for each service; the CPU share allocated to each VM; the number of servers to switch on or off; and a fraction of the incoming workload to distribute across the servers hosting each service. However, the key problem with the proposed solution is its complexity such that the execution time of its optimization controller is approximately 30min even for 15 nodes, which is not appropriate for large scale cloud environments.The authors in [5] have proposed a complete data center resource management scheme for the Infrastructure as a Service (IaaS) cloud environment. Their proposed scheme can guarantee user quality of service specified by SLAs and also tries to achieve maximum energy saving and green computing goals. They have achieved consolidation of resources by VM migrations technology and switching low-utilized or idle hosts to power saving mode while ensuring adherence to SLAs. Also, they have applied intelligent method of modified shuffled frog leaping algorithm based on improved extremal optimization to efficiently complete the dynamic allocation of VMs.The authors in [21] have explored the problem of dynamic placement of applications in virtualized systems. Their goal is to minimize power consumption while meeting the requested SLA. The proposed solution contains three managers and an arbitrator. The arbiter coordinates managers’ actions and makes allocation decisions. Performance manager gathers applications information and resize VMs according to current resource requirements and the SLA. Power manager handles hardware power states and applies DVFS when it is necessary. Migration manager coordinates live migration of VMs. However, the proposed algorithms do not support SLAs and the performance of applications can be degraded due to the workload variability.The authors in [22] have proposed a system that uses virtualization technology to allocate data center resources dynamically based on application demands and support green computing by optimizing the number of servers in use. Their aim is to achieve two goals in their algorithm: overload avoidance and green computing. To reach these goals, they have designed a load prediction algorithm that can capture the future resource usages of applications accurately without looking inside the VMs. Furthermore, they have defined a server as a hot spot if the utilization of any of its resources is above a static hot threshold and as a cold spot if the utilizations of all its resources are below a static cold threshold. However, fixed values of utilization thresholds are unsuitable for an environment with dynamic and unpredictable workloads, in which different types of applications can share a physical resource [10]. The system should be able to automatically adjust its behavior depending on the workload patterns exhibited by applications [10].The authors in [16] have proposed an architectural framework and principle for energy-efficient cloud computing aimed at the development of energy-efficient provisioning of cloud resources, while meeting QoS requirements defined by SLA. They divided the VM allocation problem into two parts: the first part is the admission of new requests for VM provisioning and placing the VMs on hosts, whereas the second part is the optimization of the current VM allocations. They have modeled the first part as a bin packing problem and solved it by MBFD algorithm in which they first sort all VMs in decreasing order of their current CPU utilizations, and allocate each VM to a host that provides the least increase of power consumption due to this allocation. Moreover, they have stated that the optimization of the current VM allocations is carried out in two steps: at the first step they select VMs that need to be migrated, at the second step, the chosen VMs are placed on the hosts using the MBFD algorithm.The authors in [6] have presented a dynamic resource management scheme that is able to automatically manage physical resources of a cloud infrastructure in such a way to maximize the profit of the cloud provider by minimizing SLA violations while reducing the energy consumed by the physical infrastructure. Their scheme utilizes both DVFS and server consolidation to minimize power consumption for cloud data centers while providing application-level performance guarantees. They provide each application with the minimum amount of physical resource capacity needed to meet its SLA, and dynamically relocate VMs according to the current resources requirements.The authors in [10] have conducted competitive analysis and proved competitive ratios of optimal online deterministic algorithms for the single VM migration and dynamic VM consolidation problems. They have divided the problem of dynamic VM consolidation into four parts for the first time including: (1) determining when a host is considered as being overloaded; (2) determining when a host is considered as being underloaded; (3) selection of VMs that should be migrated from an overloaded host; and (4) finding a new placement of the VMs selected for migration from the overloaded and underloaded hosts. They have proposed novel adaptive heuristics for all parts. They have used PABFD algorithm to solve resource allocation problem in the fourth part which is similar to MBFD policy that they adopted in their previous work [16].In sum, the main drawback of all the aforementioned studies is that they consider either energy consumption or SLA violation as their main objective and develop their solutions based on that. Another deficiency of the proposed algorithms is lack of holistic view in decision process. However, our study considers all targets including energy consumption, SLA violation, and number of VM migrations at the same time using novel multi-criteria algorithms which leads to notable improvements in output results.The target system model consists of data centers with heterogeneous resources which host various users with different applications who run multiple heterogeneous VMs on data center nodes, resulting in a dynamic mixed workload on each PM. VMs and PMs are characterized with parameters including CPU computation power defined in Millions Instructions Per Second (MIPS), RAM, Disk capacity, and Network bandwidth. The target system model is depicted in Fig. 1which is a modified version of the model described in [10]. This model includes two important parts: a central manager similar to global manager in [10] and the agents similar to local manager in [10]. The central manager is the resource manager of a specific data center which allocates virtual machines to available hosts in the data center based on a predefined goal. Also, it resizes VMs according to their resource needs, and decides when and which VMs should be migrated from PMs. The agents which are implemented in hypervisors are connected to central manager through network interfaces and have responsibility for monitoring PMs as well as sending gathered information to the central manager. Hypervisor performs actual resizing and migration of VMs as well as changes in power modes of the PMs. The main difference between our model and the one proposed in [10] is that both the decision on VMs resizing and the decision on when and which VMs should be migrated are made in central manager rather than in agents which results in having a more holistic view in decision making process. However, if the central manager runs on a single PM and that PM fails, there is no fault-tolerance policy. So, we propose running the central manager on a VM instead of a PM and use FT (fault tolerance) and HA (High Availability) capabilities which are possible; thanks to virtualization technology.Traditionally, recent studies [16,20] have subscribed to the belief that power consumption by servers can be approximated by a linear relationship with CPU utilization. This approximation comes from the idea that CPU is the major power consumer in a data center. A serious weakness with this argument, however, is that by introducing multi-core CPUs with modern power management techniques, as well as utilization of virtualization technique, CPU is not the only major power consumer in data centers anymore [10]. This fact combined with the difficulty of modeling power consumption in modern data centers, makes building precise analytical models a complex research problem [10]. Hence, instead of using a complex analytical model for power consumption of a server, we utilize real data on power consumption provided by the results of the SPEC power benchmark [23]. Table 1shows the power consumption of the servers used in this study which is provided in [10].Moreover, energy consumption is modeled as the summation of power consumed during a period of time according to Eq. (1) which is widely used in the literature such as [16].(1)E(t)=∫tP(t)dtQoS requirements are commonly formalized in the form of SLAs, which can be determined in terms of such characteristics as minimum throughput or maximum response time delivered by the deployed system [10]. As these characteristics can vary for different applications, it is necessary to define a workload independent metric that can be used to evaluate the SLA delivered to any VM deployed in an IaaS such as OTF (Overload Time Fraction) metric defined in [11]. In this study, we use the SLA Violation (SLAV) metric introduced in [10] as defined in Eq. (2) which is composed of multiplication of two metrics: the SLA violation time per active host (SLATAH) and performance degradation due to migration (PDM) as defined in Eq. (3).(2)SLAV=SLATAH×PDM(3)SLATAH=1N∑i=1NTSiTai,PDM=1M∑j=1MCdjCrjwhereTsiis the total time during which the host i has experienced the utilization of 100%;Taiis the total time during which the host i has been in the active state; N is the number of PMs;Cdjis the estimate of the performance degradation of the VMjcaused by migrations which is estimated as 10% of the average CPU utilization in MIPS during all migrations of the VMj;Crjis the total CPU capacity requested by the VMjduring its lifetime; and M is the number of VMs.This study improves the on-line resource allocation process in two aspects. First, it proposes EO policy as a novel flowchart for on-line resource management procedure. EO suggests gathering all the VMs to be migrated from either overloaded or underloaded PMs in the VMs migration list and solving the on-line resource allocation problem at once using novel heuristics rather than in separate steps for them. Second, it proposes TPSA policy as a novel heuristic for off-line and on-line resource allocation problems which will be described in the next section. Solving resource allocation using EO policy has the benefit of applying a holistic view of the whole system and finding the best allocation of VMs on available PMs.The proposed system flowchart based on EO policy is depicted in Fig. 2in which the five boxes that make our flowchart different from state of the arts are highlighted by drawing dashed lines around them. The boxes numbered 2 and 4 emphasize that the VMs to be migrated from either overloaded or underloaded PMs are gathered in the migration list and the final resource allocation is not yet arranged to be executed for them. In box numbered 3, our proposed policies for detection of underloaded PMs are utilized. In boxes numbered 1 and 5, our proposed policies for resource allocation are utilized. A resource optimization cycle is repeated every 300s and PMs’ resource utilizations information are gathered during this management scheduling interval. At the beginning, a resource allocation procedure using TPSA policy is executed and newly arrived VMs are allocated to available PMs.In the next step, PMs are searched one by one to find overloaded PMs until there is no more hotspot. Resource utilization values of each PM are predicted based on the resource utilization history of PMs, using Local Regression (LR) prediction algorithm [10]. If the prediction algorithm forecasts for a PM that its utilization will be more than 100%, then this PM is determined to be an overloaded PM. After that, VMs residing on overloaded PMs are selected for migration based on Minimum Migration Time (MMT) policy [10] until the elimination of hot spots.In the following step, selected VMs are categorized based on their CPU utilization. Then, a resource allocation procedure is executed for the sorted VMs to find their probable migration destination using MBFD allocation policy proposed in [16]. MBFD policy finds the PM that both have enough resource to host the VM as well as the least power increase after allocation of a VM. If the control system finds a proper destination for a VM, then it is added to the migration list.Following that, underloaded PMs are determined. In each searching step to find underloaded PMs, the defined policy for determination of underloaded PMs is executed and a PM is selected as a candidate of being underloaded. VMs from underloaded PMs are added to the migration list until the controlling system cannot find any underloaded PM. In the following step, selected VMs from underloaded PMs are sorted based on their CPU utilization. If the control system can find proper PMs as probable migration destinations for all the VMs residing on an underloaded PM using MBFD policy, then all its VMs are added to the VM’s migration list. Otherwise, none of the VMs are added to the VM’s migration list.At the final step, a new placement is found for all the VMs in the migration list based on our proposed TPSA allocation policy and then migrations are initiated. Major advantage of our proposed flowchart is that the VM placement step is executed in the final step after finding the complete list of VMs to be migrated either from overloaded or underloaded PMs, rather than in separate steps for them. More precisely, other works such as [10] execute VM allocation for the VMs to be migrated from overloaded and underloaded PMs separately during the process of resource optimization. Consequently, our placement has a holistic view of the whole probable allocations rather than executing VM allocations one by one.In this section we present our proposed policy for resource allocation problem in cloud data centers.TPSA policy takes advantage of TOPSIS as a multi-criteria algorithm that considers five criteria depicted in Table 2in its decision process. This policy computes the scores of all the PMs that are candidate for hosting a VM using the method that is described in this section and selects the PM with the highest score. Criteria considered in TPSA policy can have either benefit or cost type. The more the value of criteria with the benefit type, and the lower the value of criteria with the cost type, the closer is the answer to the optimum point. TPSA computes the score of PMs so that the following conditions exist in the answer: (1) the selected PM has the least power increase, (2) the selected PM has the most available resource, (3) the selected PM has the least number of VMs, (4) VMs on the selected PM have the least resource correlation with the VM to be allocated, and (5) the migration delay of the VM to be allocated to the selected PM is the least. In other words, TPSA is a multiple criteria method to identify solutions from a finite set of alternatives based upon simultaneous distance minimization from an ideal point and distance maximization from a nadir point [16].It is important to note that by selecting a PM that has the least number of VMs, the probability that the VM has lower number of competent for shared resources is higher which leads to reduction in SLA violations. Moreover, selecting a PM with the highest available capacity ensures the allocation of resources that the VMs require with higher probability and consequently reduces the SLATAH metric. Besides, considering resource correlation is based on the idea given in [24] that the higher the correlation between applications that use the same resources on an oversubscribed server, the higher probability the server to become overloaded. According to this idea, we find allocation for a VM so that the VM has the least resource correlation with the VMs on a PM. Also, consideration of the migration delay of the VMs to be allocated reduces the SLA violation during migration process and consequently the PDM metric. Also, it reduces the number of VM migrations due to smart decisions and omission of migrations with long delays. More precisely, in TPSA method, the chosen PM has the shortest distance from the ideal positive point (PM+) and the farthest distance from the ideal negative point (PM−). PM+ and PM− are formed as composite of best and worst values of considered criteria for all PMs. Distance from each of these poles are measured in the Euclidean distance.All the information assigned to the PMs in time slot t form a decision matrixMCTV→as shown in Eq. (4).(4)MCTV→=PIPM1ACPM1NVPM1RCPM1MDPM1……………PIPMiACPMiNVPMiRCPMiMDPMi……………PIPMNACPMNNVPMNRCPMNMDPMNwhere PM1, PM2, …, PMNare the available PMs that are candidate of selection by TPSA; PI, AC, NV, RC, and MD are the criteria depicted in Table 2. In order to select the best PM we go through the following steps:Step 1: First, we normalize the decision matrixMCTV→to have dimensionless decision matrixMCTV̲→. The decision matrix is made dimensionless by dividing each entry by maximum value of each column according to Eq. (5).Step 2: In the next step, PM+ and PM− are determined. Each attribute can be considered to have either benefit or cost type. Larger values for a benefit type attribute leads to less distance from PM+ and more distance from PM−, while the opposite condition is hold for a cost type variable. Before determining PM+ and PM−, type of each attribute should be defined which are shown in Table 2. We want to place a VM on a PM so that the PM has the least power increase, the highest available capacity, and the least number of VMs. Also, we want a solution in which the VM has the least resource correlation with the VMs on the PM, and also the delay for migration of the VM to the PM is the least. PM+ and PM− are defined in Eqs. (6) and (7), respectively.Step 3: The relative distance for each criterion of a PM from PM+ and PM− are calculated using Eq. (8).Step 4: Compute the total score of a PM using Eq. (9).Step 5: Rank the PMs according to their score and select the one with the highest score. The PM with the highest score has the maximum distance from PM− and the minimum distance from PM+.In this section we describe our proposed policies for determination of underloaded PMs which are AC, MDL, and TACND.The main idea of this policy is considering available resource capacity instead of resource utilizations as a measure of determining underloaded PMs. This policy selects a PM as being underloaded when its available capacity is the least among all candidate PMs as depicted in Algorithm 1. Since CPU and memory consumptions are correlated in our target system, we compute the capacity of a PM based on its CPU capacity. Traditionally, the utilization percentage was considered to determine underloaded PMs. However, since the cloud environments are heterogeneous, the PMs with equal utilization percentages do not necessarily have equal available capacities. Therefore, AC suggests that between two PMs with equal utilization percentages the one with lower available capacity is a better candidate of being underutilized.Algorithm 1: AC policy for determination of underloaded PMs1Input: Candidate PMs to be underloaded.2Output: Underloaded PM.3Minimum Capacity = Max Value.4For all candidate PMs do5Available Capacity = CPU clock speed × Number of CPU cores.6If (Available Capacity of this PM < Minimum Capacity)7Minimum Capacity = Available Capacity of this PM.8Underloaded PM = This PM.9end10End11Return Underloaded PMThis policy is based on the idea of MMT policy proposed in [10] for VM selection from over-utilized PMs. This policy selects a VM that requires the minimum time to complete a migration relative to other VMs allocated to a host. Likewise, MDL selects a PM as being underloaded when the delay to migrate all the VMs running on it is the least among all candidate PMs. The migration delay for each VM is estimated as the RAM capacity of the VM divided by the available bandwidth of the PM. Taking migration delay into consideration reduces the SLA violations incurred due to migration process.Algorithm 2: MDL policy for determination of underloaded PMs1Input: Candidate PMs to be underloaded.2Output: Underloaded PM.3Minimum Delay = Max Value.4For all candidate PMs do5Migration Delay=∑i=1#VMonthisPMRAMVMiAvailable Network Bandwidth of this PM6If (Migration Delay of this PM < Minimum Delay)7Minimum Delay = Migration Delay of this PM.8Underloaded PM = This PM.9end10end11Return Underloaded PMTACND takes advantage of TOPSIS as a multi criteria decision making method that takes three criteria depicted in Table 3into consideration including available capacity of the PM, number of VMs on the PM, and the migration delays of VMs present on the PM. The process of determination of underloaded PM based on TACND policy is similar to the process described for TPSA policy in the previous section except that the three criteria depicted in Table 3 are considered in TACND. Moreover, the AC criterion is defined as a cost type criterion in TACND while it is defined as a benefit type criterion in TPSA. Therefore, in TACND lower values for AC criterion leads to less distance from ideal positive point and more distance from ideal negative point. Traditionally, the criterion that determines an underloaded PM is resource utilization. However, similar to Section 6.1, we have considered available resource capacity instead of resource utilization as one of important criterion for determination of underloaded PMs. It is important to note that current studies consider a PM with the least utilization as underloaded PM. However, if two PMs have identical utilizations, the PM with lower number of VMs is a better candidate to be underloaded. More precisely, the PM with lower number of VMs has lower probability of utilization increase and also it is more probable that it will remain underloaded. So, we consider number of VMs as one of input criterion in TACND algorithm. Besides, considering migration delay of the VMs present on an underloaded candidate PM results in reduction of migration delays and consequently reduction of SLA violations incurred due to migration process.

@&#CONCLUSIONS@&#
