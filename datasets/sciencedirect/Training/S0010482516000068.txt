@&#MAIN-TITLE@&#
Wheezing recognition algorithm using recordings of respiratory sounds at the mouth in a pediatric population

@&#HIGHLIGHTS@&#
We recorded by Smartphone respiratory sounds at the mouth in pediatric population.Two clinical operators validated the presence or absence of wheezing in 97 toddlers.We used Short-Time Fourier Transform and SVM classifier for wheeze recognition.71.4% Sensitivity and 88.9% Specificity were observed for wheeze detection.An independent test found a fair agreement with a clinical operator.

@&#KEYPHRASES@&#
Automated wheezing detection,Childhood asthma,Bronchiolitis,Support vector machine,ROC analysis,

@&#ABSTRACT@&#
BackgroundRespiratory diseases in children are a common reason for physician visits. A diagnostic difficulty arises when parents hear wheezing that is no longer present during the medical consultation. Thus, an outpatient objective tool for recognition of wheezing is of clinical value.MethodWe developed a wheezing recognition algorithm from recorded respiratory sounds with a Smartphone placed near the mouth. A total of 186 recordings were obtained in a pediatric emergency department, mostly in toddlers (mean age 20 months). After exclusion of recordings with artefacts and those with a single clinical operator auscultation, 95 recordings with the agreement of two operators on auscultation diagnosis (27 with wheezing and 68 without) were subjected to a two phase algorithm (signal analysis and pattern classifier using machine learning algorithms) to classify records.ResultsThe best performance (71.4% sensitivity and 88.9% specificity) was observed with a Support Vector Machine-based algorithm. We further tested the algorithm over a set of 39 recordings having a single operator and found a fair agreement (kappa=0.28, CI95% [0.12, 0.45]) between the algorithm and the operator.ConclusionsThe main advantage of such an algorithm is its use in contact-free sound recording, thus valuable in the pediatric population.

@&#INTRODUCTION@&#
Asthma is the most common chronic disorder in children. Asthma in preschool children can be difficult to diagnose, and doctors must rely on children׳s medical histories, signs and symptoms, and physical exams to make a diagnosis. Wheezing is a whistling or squeaky sound that occurs while breathing and is an important argument for asthma diagnosis. This fluctuating sign is often absent on the day of examination, and doctors have to rely on abnormal respiratory sounds reported by parents. Unfortunately, parental understanding of wheeze may include whistling, squeaking or gasping sounds, or a different style, rate or timbre of breathing. For instance, Cane and McKenzie used a panel of video clips of children with audible wheezing that was shown to 190 parents [1]. The “correct” labeling of wheeze was reported in 59% of the cases. Another difficulty in identifying wheezing is that even its identification by doctors is operator-dependent. It has been shown that the inter-operator agreement ranges between chance and almost perfect agreement [2]. Therefore, it appears crucial to possess an objective tool permitting the identification of wheezing.The acoustical definition of wheezing represents an objective definition. In a recent general review of lung auscultation technique [3], wheezing was defined as a musical, high-pitched sound, heard on inspiration, expiration or both, and was characterized by sinusoidal oscillations with sound energy in the range of 100 to 1000Hz and duration of at least 100ms. The frequency range given for wheeze allows it to be differentiated from another bronchial sound, rhonchus, which has a lower pitch [3]. This definition of wheeze is close to the definition of the European Respiratory Society, which was published in 2000 in the Computerized Respiratory Sound Analysis (CORSA) guidelines [4]. Wheeze was defined by periodic waveforms with a dominant frequency usually over 100Hz and duration of at least 100ms. On theoretical grounds, an objective acoustical definition would solve the problem of wheezing recognition. However, this acoustical definition is somewhat arbitrary and other definitions can be found in the literature [5]. Moreover, the definition probably suffers from a low specificity that has led investigators to record respiratory sounds in quiet environments and use automatic methods of analysis. The automated analysis of respiratory sounds is a rapidly growing field with increasing interest from medical societies (as attested by the recently created Breath sounds Task Force from the European Respiratory Society). One of the most common analysis methods is based on the use of Fast Fourier Transform [6–8]; some other engineering methods are based on “linear predictive coding” [9,10], wavelet transform [11,12] or “mel-frequency cepstral coefficients” (MFCC) [13]. These analysis methods allow the determination of signal-based features that are subsequently used in machine learning algorithms, the most common of which are Logistic Regression, Artificial Neural Network (ANN) [12,14,15], Gaussian Mixture Models [16] or Support Vector Machine (SVM). A review comparing the different machine learning algorithms applied to respiratory sound classification into normal and wheeze classes has been published [16]. In all these studies the authors employed contact sensors for sound acquisition. While the use of contact sensors may have some advantages, such as lower sensitivity to background sounds propagated through air, they also have some drawbacks. For instance, they are more vulnerable to sound conducted through body tissues and spurious rubbing sounds. Moreover contact sensors can be difficult to attach and maintain, especially in pediatric subjects (not to mention the risk of cross contamination of patients). Thus, to our best knowledge this is the first study whose purpose is to analyze wheezing sounds acquired with a contact-free microphone.The objectives of our study were to recognize wheeze in the pediatric population using a sound recording made at the mouth with a Smartphone of a subject presenting abnormal lung auscultation. To this end, we specifically extracted features compatible with wheezing based on its acoustic definition and then evaluated two different machine learning algorithms. To clearly present our research, we present in the Materials and Methods section the block diagram of the proposed algorithm inFig.1, and then in the first and in the second subsections we present the protocol of data acquisition and some preliminary results. The third subsection is devoted to the description of the study population. In the subsequent subsections we explain the used signal analysis algorithm and give the explanatory elements that allowed extracting the features. The last subsection describes the theoretical bases of the various machine learning algorithms. The third section focuses on results: clinical examination and distribution of features between the two groups. The reduced number of features to be used in the machine learning algorithm and the decision threshold are further described. The discussion and conclusions of the paper are assembled in the last section.The diagram of the algorithm is given in Fig. 1. The overall approach consists of four phases: first, recording of the sound with a Smartphone microphone, second, conception of the analysis algorithm that yields a set of features of the signal that are employed in the third phase, in which a pattern classifier is trained. The last step validates the classifier and evaluates its performance.The recording of respiratory sounds is performed with the principal microphone (SP0410HR5H-PB, distributed by Knowles Electronics, Itasca, IL, USA) of the Nexus 4™ Smartphone (Google, Mountain View, CA, USA). This microphone consists of an acoustic sensor, a low noise input buffer, and an output amplifier. Its sensitivity at 94dB SPL @ 1kHz is −42dBV/Pa and has a frequency response curve presenting less than 0.1% variation in the 100–4000Hz zone. This microphone (or similar ones) is used by most of the Smartphone manufacturers on the market.The recording itself was made by the operator of the study (PB) by placing the microphone close to the mouth of the patient (at a target distance of 5–10cm). The duration of the recording was 30s (a range of 20–40s is accepted, based on the cooperation of the child). The recording software used was “Easy Voice Recorder”™ (by Digipom, Longueuil, QC, Canada), which is available for download on Google Play (free license). The sampling frequency was 16kHz and we used the WAV (Waveform Audio File Format) with a single channel. All of the recordings were subsequently downloaded on a PC computer where mathematical analysis and programming were performed using Octave.The site of respiratory sound acquisition in this study was chosen to be a few centimeters away from the mouth of the patient, with the microphone of the Smartphone directed towards the patient. This choice was made as an attempt to achieve contact-free sound acquisition but also to avoid signal distortions from the contact with the skin and from filtering of the signal by the neck wall. In previous studies, authors have chosen more often to apply the microphone to the neck over the trachea [17], but we believe that this method is hindered by the low-pass filtering of the neck wall. To illustrate this, we performed a series of preliminary experiments where recordings were made on the same patient at two sites: over the trachea and close to the mouth (Fig. 2).Fig. 2 shows a recording obtained from a 2 month-old patient, who was hospitalized for bronchiolitis and presented wheezing at lung auscultation (as attested by an experienced pediatric respiratory physician, BM). For this recording, we used a SHURE™ Beta 57A supercardioid dynamic microphone with a 44.1kHz sampling rate.High frequency harmonics are attenuated and the mean frequency of the wheezing signal detected by our algorithm was 250Hz in the case of a recording over the neck (Fig. 2b), whilst it was 900Hz in the case of signal acquired at the mouth (Fig. 2a).The spectrograms of the recordings are in the bottom, recognized signals as wheezing are labeled (“+” signs). The value of the floating variable y is given at the top. It is given a value of 1 if the analyzed segment contains wheezing, and 0 otherwise.The study was carried out on a pediatric population consulting in an emergency medical unit or being hospitalized in the pediatric ward of a general hospital (Centre Hospitalier de Fontainebleau) during the winter season of 2013–2014. A total of 186 recordings were made (see flow chart inFig. 3). Children were eligible if they (1) were between 1 day and 12 years old, (2) were consulting in the emergency medical unit or were hospitalized in the pediatric ward, (3) presented abnormal respiratory sounds at initial clinical evaluation (at least one sound: wheezing, crackles, rhonchus, acute laryngitis, rhinitis), and (4) had chest auscultation according to a standardized protocol. The written informed consent of at least one parent was required before enrollment, and the study protocol was approved by The Institutional Review Board of the French learned society for respiratory medicine (CEPRO 2013-Delclaux).The key exclusion criterion was the presence of baby vocals or crying noises for longer than 50% of the recording length. For that reason, 34 of the 186 initial recordings were discarded.Since it has been demonstrated that the identification of wheezing is operator-dependent, only recordings with operator agreement (two operators) on auscultation diagnosis (presence or absence of wheezing) were included in the training and validation sets of the machine learning algorithm. The first operator was systematically the main investigator (PB: senior year resident), whereas the second operator was either the senior pediatrician or the resident on duty in the emergency unit at the moment of inclusion of the patient.As seen in Fig. 3, for 39 recordings, there was only one operator and those were not used in the development of the algorithm. Nevertheless, these recordings were employed in the testing phase of the algorithm where the agreement between the operator and the pattern recognition algorithm was evaluated.The final set included 95 recordings (68 without wheezing versus 27 with wheezing). Initially, 29 wheezing-containing recordings were identified. The analysis of one of them gave an empty matrix so it was disregarded from the dataset, another one contained repeated clock noises that were artificially selected as wheeze-compatible by the analysis algorithm and was also disregarded from the dataset.We therefore divided this set into a training set, containing 70 recordings (or 60% of the set) with 20 wheeze-containing recordings, and a validation set containing the resting recordings. The groups were assembled in order to obtain approximately the same proportion of wheezing positive recordings in each group, chosen in alphabetical order.The raw data of a given WAV recording was divided into overlapping segments of length 64 ms with 50% overlap using a Hanning window (Fig. 4a). Then, the signal from each interval was filtered using an autoregressive model [9]. This model permits linking the signal at time step, n, to the signal at the p previous time steps:(1)xi[n]=−∑k=1pakxi[n−k]+ε[n]where p is the order of the model,xi[n]is the signal amplitude at the n time step in the ith signal interval,akis the parameter of the model of order k, andε[n]is a random white noise with varianceΔ2.A 61 order autoregressive model using the whitening lattice-filter method of Burg was used to fit the initial data and we present in Fig. 4b the FFT of the autoregressive model and of the initial signal. The order of the model was fit to achieve the best power spectral density peak detection. Thus, we achieved a noise-free model that detected local maxima in the Fourier spectrum permitting the identification of wheezing.A calculation of the power spectral density (PSD) is obtained by the following formula:(2)Pxi(ω)=Δ2|1+∑k=1pake−jkω|2wherePxiis the PSD of the signalxias a function of the frequency ω.We used the function arburg in Octave to obtain an autoregressive model of the signal and the function ar_psd to calculate the power spectral density (PSD) by FFT.Feature selection is a technique of selecting a subset of relevant features for building a robust classifier. We chose to work with a set of 14 features based on the acoustic definition of wheezing and thus expecting to give the best differentiation between the two groups.The calculation of the features was performed over the whole sound recording.We thus definedF1..14as follows:F1,2=mean(fi1..Ni)with i the harmonic order (fundamental or second harmonic), f, the mean frequency of a given wheezing segment and Nithe number of wheezing compatible signals detected in a given recording for each harmonic.F3,4=[max(fi1..Ni)−min(fi1..Ni)]/mean(fi1..Ni)F5,6=mean(PSDi1..Ni)We definedPSDimas the mean PSD over the time intervals included in a given wheezing m for the harmonic i:PSDim=mean∑f∈FPSDif∑flfLPSDfintervalsincludedinwheezingmwhere fl=200Hz and fL=2500Hz are the boundary frequency for the calculation of the mean PSD, while F is the set of frequencies corresponding to the definition of a wheezing peak (Fig. 1).F7,8=[max(PSDi1..Ni)−min(PSDi1..Ni)]/mean(PSDi1..Ni)F9,10=mean(τi1..Ni)where τ is the duration of the ith harmonic of a given wheezing,F11,12=maxτi1..Ni−minτi1..Ni/meanτi1..NiandF13,14=∑k=1NiτikTwith T the total duration of the recording.InFig. 5, we give the spectrogram representation of wheezing identified on lung auscultation (Fig. 5a), and of a cry (Fig. 5b) recorded for the same child. A wheeze compatible signal is defined as having three or fewer detectable harmonics on each time segment [18] and duration of at least 100ms [3] provided the other conditions listed in Fig. 1 are met. The minimal duration of 100ms of each wheezing compatible signal was assured by tracking the spectral crests on successive temporal segments. The maximum frequency variation in a sequence of consecutive time segments admitted in order to consider a given segment as belonging to a wheezing was 20%. In Fig. 5a the represented wheezes are mixed (inspiratory and expiratory) with predominant inspiratory part.The signal analysis algorithm was more thoroughly tested on a set of artificial and clinical sounds (see Supplementary material).In order to achieve better separation of the positive from the negative examples, rescaling was performed on the features.In a further step of the conception of the algorithm, we tried to reduce the dimension of the feature matrix, keeping most of the variance permitting to observe a stable pattern classifier. For that purpose, we computed and diagonalized the covariance matrixΣthat allowed reducing the dimensions of the feature matrix by truncating the eigenvector matrix of dimensions n×n to n×k thus retaining a given fraction of the variance. This fraction is given by the ratio of the sum of the first k eigenvalues divided by the sum of all the eigenvalues.Two machine learning algorithms were used in this work: Logistic Regression (LR) and Support Vector Machine (SVM).The LR algorithm is a linear algorithm, which uses several independent features to estimate the probability of a categorical event. Namely, the probability estimation is given by(3)P(y=1|x;θ)=hϑ(x)=11+e−θTxIn Eq. (3), x is the features vector ofn+1dimensions (x0=1,x1, …,xn) andθis the parameters vector with components (ϑ0,ϑ1, …,ϑn).The output of the algorithm is a probability (continuous variable between 0 and 1) of a categorical event. Applying an optimal threshold (α) results in either “zero” for the absence of wheezing (y=0) or “one” for the presence of wheezing (y=1) in a given recording. There is a “training phase” of the algorithm where labeled examples of wheezing-containing recordings and no wheeze-detected recordings are given to the algorithm. During this phase, a set of parameters is determined by minimizing a cost function.Giving a training set of m examples{(x(1),y(1)),(x(2),y(2)),...,(x(m),y(m))}withx∈ℜn+1andy∈{0,1}one can write the cost function of the LR algorithm as follows:(4)J(θ)=−1m{∑j=1m[y(j)lg(hϑ(x(j)))+(1−y(j))lg(1−x(j))]}+λ2m∑k=1nϑk2In Eq. (4),λis the regularization parameter and the minimizing ofJ(θ)fits the parameters vectorθ.The SVM algorithm is designed to separate more effectively the negative and positive examples by using a cost function that values zero ifθTx(j)≥1(in the case ofy(j)=1) and ifθTx(j)≤−1(in the case ofy(j)=0). The new cost function is written as(5)J(θ)=C{∑j=1m[y(j)cost1(θTx(j))+(1−y(j))cost0(θTx(j))]}+12∑k=1nϑk2In Eq. (5), beside the modification in the cost function, a regularization term is added, the importance of which in the overall cost depends on the constant C, with cost1 and cost0 being the new cost functions corresponding to y=1 and y=0, respectively.We used an SVM algorithm with Gaussian kernels because the decision boundary is expected to be non-linear.When using a Gaussian kernel for a givenx, new features are computed depending on the proximity of a givenxto the landmarksl(1),...,(m). Landmarks are given by the examples in the training set.In this manner, a new set of features is built and in the case of Gaussian kernels, the feature vectorffor a givenxcan be written as follows:(6)f0=1f1=exp(−‖x−l(1)‖22σ2)⋮fm=exp(−‖x−l(m)‖22σ2)In Eq. (6),σ2is a parameter of the Gaussian kernel that defines the steepness of the rise of the feature around the landmark. Hence,f∈ℜm+1and the new cost function can be written:(7)J(θ)=C{∑j=1m[y(j)cost1(θTf(j))+(1−y(j))cost0(θTf(j))]}+12∑k=1mϑk2This cost function is convex and therefore a global minimum is calculated by minimizing Eq. (7).The performances of the classifiers are evaluated by comparing their predictions to the diagnosis given by the physician. The performance of each test is given by its ability to identify true positives while excluding false positives. Thus, the two quantities that are commonly used are the specificity (SP), which is defined as the probability that a normal person is classified as normal, and the sensitivity (SE), which is defined as the probability that a diseased person is classified as diseased:(8)Specificity(SP)=TNTN+FP(9)Sensitivity(SE)=TPTP+FNwhere TP, FN, FP, and TN are the amount of the true positive, false negative, false positive and true negative test results, respectively.The receiver operating characteristic (ROC) curve is the continuous function of sensitivity versus (1-specificity) across all possible values of the threshold above which the test is considered positive. The area under the curve (AUC) provides a single measure that summarizes the discriminative ability of the classifier through a full range of thresholds [19].Following the definition of SE and SP (Eqs. (8 and 9)), it is clear that both quantities depend on the threshold (α) for the probability P (Eq. (3)). We define SEcand SPcas the values of sensitivity and specificity, respectively, which correspond to the conventional threshold α=0.5.Several methods exist permitting the optimal value of α to be determined, resulting in the best tradeoff between SE and SP [19]. We chose the simple method based on the calculation of the F1 score defined as(10)F1=2TN2TP+FN+FPThe number of features to be used in the algorithm was set by the maximum of F1con the validation set while progressively changing the number of features. The optimal value of α is given by the maximum of F1(α) on the validation set.We used the non-parametric two-tailed statistical Mann–Whitney test to compare clinical and signal analysis features between the two groups (with and without wheezing). The significance level of the type I error was set to 5%. We used the Kolmogorov–Smirnov distribution theory to calculate 95% confidence intervals for SE and SP of the algorithms. The AUC was calculated by the trapezoidal rate and parametric statistics are applied to it [20]. Z-score was used to test the null hypothesis and to compare AUC between the LR and the SVM algorithms. In the latter case, the correlation between the classifiers was evaluated by the Kendall tau as the results were obtained from an ordinal scale [21]. In order to address the inter-operator agreement, we used Cohen׳s kappa [22]. These tests were also used to quantify the agreement between a pattern classifier and an operator on the test set. The null hypothesis confounding the value of kappa to be no different from that expected by chance was tested according to Fleiss et al. [23] assuming the superiority of the pattern classifier (one-tailed p value).

@&#CONCLUSIONS@&#
