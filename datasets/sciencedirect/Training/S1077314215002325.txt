@&#MAIN-TITLE@&#
Video Classification via Weakly Supervised Sequence Modeling

@&#HIGHLIGHTS@&#
We proposed a multiple-instance learning algorithm to model sequential data, with novel conditional likelihood formulation.We incorporated temporal correlations into MIL for video classification, by explicitly exploiting the chain CRFs model.Our method showed superior performance on both synthetic data and realistic dataset on action and gesture recognition.

@&#KEYPHRASES@&#
Video classification,Gesture,Action,Weakly supervised,Sequence modeling,Multiple-instance learning (MIL),Conditional Random Fields (CRFs),

@&#ABSTRACT@&#
Traditional approaches for video classification treat the entire video clip as one data instance. They extract visual features from video frames which are then quantized (e.g., K-means) and pooled (e.g., average pooling) to produce a single feature vector. Such holistic representations of videos are further used as inputs of a classifier. Despite of efficiency, global and aggregate feature representation unavoidably brings in redundant and noisy information from background and unrelated video frames that sometimes overwhelms targeted visual patterns. Besides, temporal correlations between consecutive video frames are also ignored in both training and testing, which may be the key indicator of an action or event. To this end, we propose Weakly Supervised Sequence Modeling (WSSM), a novel framework that combines multiple-instance learning (MIL) and Conditional Random Field (CRF) model seamlessly. Our model takes each entire video as a bag and one video segment as an instance. In our framework, the salient local patterns for different video categories are explored by MIL, and intrinsic temporal dependencies between instances are explicitly exploited using the powerful chain CRF model. In the training stage, we design a novel conditional likelihood formulation which only requires annotation on videos. Such likelihood can be maximized using an alternating optimization method. The training algorithm is guaranteed to converge and is very efficient. In the testing stage, videos are classified by the learned CRF model. The proposed WSSM algorithm outperforms other MIL-based approaches in both accuracy and efficiency on synthetic data and realistic videos for gesture and action classification.

@&#INTRODUCTION@&#
Spread of portable multimedia devices, e.g., smartphone, leads to enormous amount of videos produced everyday. For instance, in every minute, 100 h of videos are uploaded to YouTube [1]. Intelligent video classification system benefits video indexing, search, analysis, etc. Conventional pipeline of video classification involves in global video representations encoded by local visual descriptors. Despite of efficiency, such classification manner is applicable only to frame-level annotated video clips for both training and testing; in other words, the used videos should only contain one targeted action or event, from the start frame to the end, without unrelated video frames. However, frame-level annotation requires costly human intelligence and is too time-consuming, thereby, large amount of training videos are inaccessible. Besides, testing videos rely on delicate pre-processing schemes that divide them into clips (e.g., temporal clustering [2]), which prevents these approaches from practical applications. Even with well cut video clips, pooling step (e.g., average pooling [3] or max pooling [4]) in generating holistic representation would unavoidably bring in reductant and noisy information from background, which sometimes overwhelms representative visual patterns of targeted video class. In fact, local features in a small spatial-temporal window could be discriminative enough to indicate presence of one action or event in videos [5,6]. On the other hand, it is more convenient and easier to annotate an entire video rather than individual frames [7], especially the video corresponds to several semantic classes. In terms of web videos, people usually label videos using semantic tags, which means massive data with video-level annotation is available for training.Inspired by the facts above, multiple-instance learning (MIL) based approach seems to be a straightforward option. In conventional MIL setting, training labels are given to sets of samples (bags) instead of individual samples (instances) [8]. The instance labels are given implicitly; a bag is positive if and only if at least one of its instances are positive. In recent years, MIL has enjoyed increasing popularity in computer vision. For example, in image classification and retrieval [9–11], each image is considered a bag. Different image regions are the instances. Instead of annotating each individual region, one only needs to label each training image with contained object names. MIL has also been applied to image segmentation [12,13] and tracking [14].Specifically for video classification, each video sequence is considered as a bag and its segments as instances. As aforementioned, instead of labeling every frame, human experts only need to give the class types of each video, which allows people training video classifiers under MIL setting. However, most previous MIL-based methods assume the instances in a bag are independent and identically distributed (i.i.d.). Such assumption is problematic in many computer vision problems, particularly for tasks involved in sequential data. For video classification, consecutive frames or segments within a video tend to contain similar actions or events. Temporal correlations sometime are the key indicators of an action or an event. As shown in Fig. 1, if we consider each instance as independent, the 3rd frame in the bottom row will be mislabeled as hand rolling (the top row). This mistake can be avoided if we incorporate the temporal domain structure. In MIL literature, these structural information have not been fully explored. Some previous works [15–17] build edges between instances (within a same bag or cross bags) with similar appearance. These edges do enforce label consistency between similar instances; nevertheless they are not as powerful as edges in structured prediction models, e.g., the Conditional Random Fields (CRFs) [18]. CRFs exploit structures among data by modeling conditional distribution of observations and predictions, rather than joint distribution as used in Hidden Markov Model (HMM) [19]. In particular for video classification, the model could learn statistic dependencies existing in rich visual features and could identify an entire activity or event occurring in video clips; or to say, it is capable of make consistent predictions for consecutive frames. Furthermore, modeling label correlations of the intrinsic structure is more natural than enforcing all instances with similar appearance to have similar labels, especially we have explicitly know videos correspond to chain structure in temporal domain.In this paper, we propose Weakly Supervised Sequence Modeling (WSSM) for video classification, a novel weakly supervised algorithm that combines MIL and chain CRFs in a seamless fashion. Our model takes each entire video as a bag and one video segment as an instance. It works in the MIL weakly supervised setting while inheriting the power of CRFs in modeling video sequences. The discriminative visual patterns for the targeted video class are explored through MIL fashion, while intrinsic temporal dependencies between video segments are explicitly modeled by chain CRFs. To estimate the CRFs’ parameters, we formulate a new conditional likelihood which is only based on the video-level labels of training data. This conditional likelihood can be efficiently maximized using an alternating optimization method with a guaranteed convergence. The advantages of this algorithm are twofold. First, the CRF framework enables our model to outperform existing MIL methods in both bag and instance level label predictions for sequential data. Second, it is as easy as the traditional CRF framework in terms of both implementation and efficiency. Our algorithm has no extra parameters except for the regularizer weight, as all other CRF models have. Experiments show that training time of the proposed method is almost linear to the training data size.Our approach is different from previous ones in both theory and application scenario. Deselaers and Ferrari [20] used CRF to solve classical MIL problems. Their method is not designed for structured data, thus cannot be used to incorporate temporal information for video classification. Zha et al. modeled instance labels as hidden variables of the CRFs [21]. However, solving the problem requires marginalizing over the whole space of hidden label configurations, whose size is exponential to the number of instances. Therefore, to solve the problem one has to use Gibbs sampler and convergence divergence at testing and training stages, making the solution inefficient and inaccurate. Several papers have borrowed MIL idea for video classification, for instance, in action recognition [6,22], event recognition [23], and sign language understanding [24,25]. However, temporal dependencies between video segments (instance) are not investigated in these methods.

@&#CONCLUSIONS@&#
In this paper, we proposed a new multiple-instance learning algorithm (WSSM) that seamlessly incorporates CRF model into the weakly supervised setting. Previous MIL methods explored structural information by enforcing label consistency of similar instance. Our WSSM models the conditional distribution of all label combinations of adjacent instances, which is more natural and more powerful. To estimate the CRF parameters, we designed a new conditional likelihood, customized for the setting when only bag labels are given for training. Node marginals of CRFs are used to formulate the conditional likelihood. Such likelihood can be efficiently maximized using an alternating optimization method with a guaranteed convergence. We demonstrated the power of WSSM on both synthetic data and real video classification tasks on gesture and action recognition. Experiments show that our method outperforms existing MIL methods in video classification and also show promising results on frame-level prediction. Moreover, it has good merits in terms of both implementation and efficiency. WSSM has no extra parameters except for the regularizer parameter, and its training time in practice is almost linear to the training data size.In this paper, we mainly focused on chain CRFs for video classification. However, our WSSM algorithm is readily applicable to data of more sophisticated structures, e.g. trees and loopy graphs, by the benefits of marginals. We would like to extend out model to multiple-label CRF. We would also like to investigate the possibility of using multiple modes [58,59] to compute marginals, in order to get a more robust result.