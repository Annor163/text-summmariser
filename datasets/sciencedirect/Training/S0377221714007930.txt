@&#MAIN-TITLE@&#
Using SVM to combine global heuristics for the Standard Quadratic Problem

@&#HIGHLIGHTS@&#
The Standard Quadratic Problem (StQP) is NP-hard with many local minimizers.Global unconstrained heuristics proposed for StQP do not dominate each other.We use Support Vector Machines to combine three global heuristics into one.We prove that our method allows to obtain a good heuristic.We use as benchmark test set the StQP deriving from the max clique problem.

@&#KEYPHRASES@&#
Quadratic programming,Nonlinear programming,Data mining,Maximum Clique Problem,Global optimization,

@&#ABSTRACT@&#
The Standard Quadratic Problem (StQP) is an NP-hard problem with many local minimizers (stationary points). In the literature, heuristics based on unconstrained continuous non-convex formulations have been proposed (Bomze & Palagi, 2005; Bomze, Grippo, & Palagi, 2012) but none dominates the other in terms of best value found. Following (Cassioli, DiLorenzo, Locatelli, Schoen, & Sciandrone, 2012) we propose to use Support Vector Machines (SVMs) to define a multistart global strategy which selects the “best” heuristic. We test our method on StQP arising from the Maximum Clique Problem on a graph which is a challenging combinatorial problem. We use as benchmark the clique problems in the DIMACS challenge.

@&#INTRODUCTION@&#
We concentrate on the Standard Quadratic optimization Problem (StQP) of the form(1)min{f0(y)=12y⊤Ay:y∈Δ}where Δ denotes the standard simplex in n-dimensional Euclidean spaceRn,namely(2)Δ={y∈Rn:e⊤y=1,y≥0},whereA=[aij]∈Rn×nis a symmetric matrix not positive semidefinite, e is the n-vector of all ones and the apex ⊤ denotes the transposition. We note by side that the more general case ofΔK={y∈Rn:c⊤y=K,y≥0}where ci> 0, i = 1, …, n and K > 0 can be converted into problem (1) by the simple transformationciKyi→yi.The problem is non-convex and we look for a global solution y*, i.e. a point y* such that f0(y*) ≤ f0(y) for all y ∈ Δ. It is well known that StQP is an NP-hard problem and that many local minimizers or stationary points that are not global exist. For a review of StQPs we refer e.g. to Bomze (2009) and references therein. Indeed, the StQP has been used as a tool to solve Maximum Clique Problems on the basis of a well-known reduction described by Motzkin and Strauss (Motzkin and Straus, 1965) for the unweighted case, and by Gibbons et al. (1997) for the weighted case. In some cases, the converse reduction, from a StQP to a nonlinear constrained weight clique problem, is used to develop exact and heuristic algorithms for solving a StQP (Scozzari and Tardella, 2008).Problem (1) is a constrained non-convex optimization problem and possible solution techniques can be based on the use of different heuristics. Since the optimal solution is not known a priori and optimality cannot be certified, an heuristic stops returning the best solution found. In general, heuristics can perform differently in terms of best value found and in this sense it is not possible to state that one dominates the others. Hence it may be worthwhile to define a paradigm to combine different heuristics limiting the overall computational effort. Indeed, an obvious way of combining different heuristics consists in using each of them sequentially and store the best value obtained. However, in this way the computational effort grows up. In this framework, although the procedure described below can be applied to a finite number of unconstrained formulations, we focus on combining the different heuristics proposed in Bomze, Grippo, and Palagi (2012) and Bomze and Palagi (2005). Therein, equivalent unconstrained formulations of the original constrained problem (1) have been proposed that allow the use of standard unconstrained methods, in connection with a multistart global strategy. Actually, the results in Bomze et al. (2012) and Bomze and Palagi (2005) showed that none of the three formulations dominates the others in terms of best value found. This motivates the idea of combining the different heuristics in a clever way, so that the overall number of optimization runs is controlled. Indeed, combining sequentially the heuristics without any filter may lead to a great number of local optimizations, useless in locating the best solution.Following this idea, in Cassioli, Di Lorenzo, Locatelli, Schoen, and Sciandrone (2012) an algorithm called LeGO (Learning for Global Optimization) has been proposed as a variation of a multistart unconstrained method. It tries to learn the unknown relationship between the starting condition (initial point or parameters) and the final value obtained by the method. To this aim, using as learning dataset the first runs of the algorithm (epochs) with a given initial setting, Cassioli et al. proposed to use a machine learning tool, in particular Support Vector Machines (SVMs), to estimate the outcome of future runs. In our context this can be directly applied to each single unconstrained formulation, reducing the number of unconstrained minimizations required. However, it may happen that a given starting point is “promising” for every unconstrained formulation so that the local procedure should be applied on each of them. We propose to use SVMs to tackle also this issue. The paper is structured as follows: in Section 2 we recall properties of the StQP and the continuous Maximum Clique formulation proposed in Bomze (1997). In Section 3 we report the three unconstrained formulations introduced in Bomze et al. (2012) and Bomze and Palagi (2005). In Section 4 we present the trivial multistart global strategy THEM that combines sequentially the three unconstrained formulations. In Section 5 we briefly introduce Support Vector Machines and in Section 6 we introduce the Global heuristic Optimization Strategy by SVM (GHOStSVM). Finally in Section 7 we test GHOStSVM on a set of problems arising from a continuous formulation of the Maximum Clique from the DIMACS challenge (Johnson and Trick, 1996). We show that SVMs are a powerful tool to combine different formulations.We concentrate on the NP-hard Standard Quadratic optimization Problem (StQP) of the form (1)min{f0(y)=12y⊤Ay:e⊤y=1,y≥0}.Problem (1) arises in many applications; among them we are particularly interested in a continuous formulation of the Maximum Clique Problem. Given an undirected graph G = (V, E) with vertex V and edge set E⊂V × V, a clique is a subset of V with the property that all the nodes are pairwise adjacent (a complete subgraph of G). The Maximum Clique Problem consists on finding a clique of G of maximum cardinality ω*. This problem has many different continuous formulations as a non-convex optimization problem. For a survey we refer to Bomze et al. (1999). The first continuous formulation of the Maximum Clique Problem as an StQP goes to the so called Motzkin–Strauss formulation (Motzkin and Straus, 1965); the value of the maximum clique ω* is obtained as (1 − f*)−1 where f* denotes the optimal value of the indefinite quadratic programmax{y⊤AGy:y∈Δ}withAGbeing the adjacency matrix of the graph, namely aij= 1 if (i, j) ∈ E and aij= 0 otherwise, and Δ the unit simplex defined in (2). This formulation has the drawback of having spurious solutions, namely local solutions that are not in a one-to-one correspondence with cliques of the original combinatorial problems.Later Bomze (1997) proposed a stronger formulation obtained by perturbing the Motzkin–Strauss objective function adding the term12∥y∥2,so that the Maximum Clique Problem is written as:(3)max{y⊤(AG+12I)y:y∈Δ},which is an StQP of the type (1) with matrixA=−2(AG+12I).The regularized version (3) avoids the drawback of the original Motzkin–Strauss formulation. The main result proved in Bomze (1997) is reported here:Theorem 1Let G be an undirected graph and consider problem (3). Then the following assertions are equivalent:(a)y¯is a strict local maximum for problem (3);(b)y¯is a local maximum for problem (3);(c)y¯=1ω¯∑i∈σeiwhere σ is a maximal clique of cardinalityω¯.If one of the above conditions (and therefore all) is met, the objectivey¯⊤(AG+12I)y¯equals the value1−12ω¯.Assertions (a) and (b) imply that every local solution of (3) is strict, so that there is no problem in identifying a clique σ fromy¯. Indeed a vertex i ∈ σ if and only ify¯i>0andω¯=12(1−f¯)−1. Obviously σ* is a maximum clique of G if and only if y* is the global solution of (3).General constrained algorithms are able to locate points satisfying first order necessary conditions. Since the constraints are linear, the constraint qualifications are met and the Karush–Kuhn–Tucker (KKT) conditions are necessary for optimality. The first-order KKT necessary optimality conditions state that a feasible pointy¯is a local solution of problem (1) if a scalarλ¯exists such that(4){(Ay¯)i+λ¯=0fori:y¯i>0,(Ay¯)i+λ¯≥0fori:y¯i=0,From (4) we get also that the Lagrange multiplier is uniquely determined fromy¯asλ¯=−y¯⊤Ay¯=−2f0(y¯).Of course second-order necessary optimality conditions can also be introduced to refine among KKT points but we are not going to use them in this paper.Problem (1) is a constrained optimization problem and possible solution techniques are based on the solution of equivalent unconstrained non-convex problems, so that well established, robust and efficient unconstrained methods can be used.In Bomze et al. (2012) and Bomze and Palagi (2005) different formulations have been proposed that lead to three unconstrained problems of the type(5)minx∈Difi(x)fori∈{1,2,3}wherefi:Rn→Rare continuously differentiable functions over the open setDi⊆Rnand may depend on a set of parameters Ωito be chosen appropriately, in order to get equivalence between problem (1) and the ith problem (5). The three different formulations have been used in Bomze et al. (2012) and Bomze and Palagi (2005) to define three different simple multistart heuristics hifor solving the StQP.We report in this section the main steps that lead to the three unconstrained problems (5) together with their main properties.The definition of the first two unconstrained problems i = 1, 2 are based on the construction of an intermediate constrained problem, obtained by the substitutionyi=xi2into (1) to get rid of the sign constraints yi≥ 0. Then the condition e⊤y = 1 reads ‖x‖2 = 1, and Bomze and Palagi (2005) obtained the following homogeneous problem of minimizing a fourth-order polynomial over the unit sphere(6)min{12x⊤XAXx:∥x∥2=1:x∈Rn}where X denotes n × n the diagonal matrix with elements xi. It has been proved that any local/global solution of problem (6) provides a local/global solution of problem (1) and vice versa. Problem (6) has the advantage to have a simple constraint that can be tackled easily. The counterpart is that the transformationyi=xi2may produce spurious KKT points which do not satisfy the KKT conditions (4) of the original problem (1), so that problem (6) is not “fully equivalent” to problem (1) in the sense of Di Pillo and Grippo (1989). Bomze and Palagi (2005) proposed the following continuous differentiable globally exact penalty function for problem (6):(7)f1(x)=12x⊤XAXx(3−2∥x∥2)+1ɛ(∥x∥2−1)2which depends on the set of parameters Ω1 = {ɛ} with ɛ freely chosen within(0,ɛ¯]where the upper boundɛ¯can be easily calculated. The choice of the value of the parameter ɛ may cause numerical instability. Function f1(x) is twice continuously differentiable on the whole spaceRn,and its unconstrained minimization lead to the 1st problem (5) withD1≡Rn. Any stationary point of problem (5) with i = 1 corresponds to a KKT point of problem (6) and we can obtain back a feasible solution for StQP by the transformation y = T1(x) withyi=T1(xi)=xi2and its (partial) inverse transformationx=T1−1(y),namelyxi=+yi.A second way of exploiting the constraint of problem (6) relies on the idea in Grippo et al. (2012). Bomze et al. (2012) proposed the following function(8)f2(x)=12x⊤XAXx∥x∥4to be minimize over an open domainD2⊂Rncontaining the unit sphere but excluding the origin, where the function is not continuously differentiable. In this case the set of parameter Ω2 = ∅ and the transformation that gives back a feasible point of StQP is y = T2(x) withyi=xi2∥x∥2and its (partial) inverse transformationx=T2−1(y),namelyxi=+yi.The third unconstrained problem was proposed in Bomze et al. (2012) and it is obtained starting from a different constrained formulation due to Bomze (1998), where the following quadratic problem, over the positive orthant, has been introduced:(9)min{12p⊤Qp−e⊤p:p≥0,p∈Rn},being(10)Q=12A+ϱee⊤and ϱ chosen such that Q is strictlyR+n-copositive. We observe that such value can be calculated by the user fromqij=12aij+ϱif a range of variability for aijis known.In Bomze (1998) and Bomze et al. (2012) it has been shown that a global solution of problem (9) provides a global solution of problem (1). The same one-to-one correspondence holds among KKT points.Bomze et al. (2012) used again the substitutionpi=xi2to eliminate the constraints p ≥ 0, and obtained the following continuously differentiable quartic function(11)f3(x)=12x⊤XQXx−∥x∥2with Q as in (10) and the set of parameters Ω3 = {ϱ}. This leads to the 3rd problem (5) withD3≡Rn. As mentioned before, also in this case the transformationpi=xi2may produce spurious stationary points of f3 which do not correspond to KKT points of problem (9). However we can still get feasible point for StQP by the transformation y = T3(x) withyi=xi2∥x∥2and the (partial) inversex=T3−1(y)withxi=|yi|ϱ+f0(y).Summarizing, all the derived problems (5) are unconstrained non-convex problems for any i = 1, 2, 3. The counterpart of these unconstrained formulations lies in the fact that they are not “fully equivalent” to problem (1) in the sense of Di Pillo and Grippo (1989). Indeed, for all of them it is possible to prove that any global solution of problem (5) for any i ∈ {1, 2, 3} provides a global solution of problem (1) and vice versa. However for any i ∈ {1, 2, 3} spurious stationary points of (5) may exist which do not correspond to KKT points of the original problem (1), while the vice versa is always true. Anyway it is well known that local unconstrained optimization methods can produce only stationary pointsx^iofminx∈Difi(x)for any given i = 1, 2, 3, so that formulations (5) must be carefully used to find solutions of the original StQPs as pointed out in Bomze et al. (2012) and Bomze and Palagi (2005).For the sake of clarity we summarize the correspondence among first order stationary points of the three unconstrained problems and StQP as follows:y¯KKTpointofStQP←x¯=Ti−1(y¯)x¯∈Distationarypointoffi(x)∀i.whereas correspondence among global minimizers holds also in the reverse directiony¯globalminimizerofStQP←x¯=Ti−1(y¯)→y¯=Ti(x¯)x¯∈Diglobalminimizeroffi(x)∀i.Analyzing into details the results in Bomze et al. (2012) and Bomze and Palagi (2005), it is possible to state that starting from a feasible point y0 ∈ Δ with the correspondingx0=Ti−1(y0)∈Di,any unconstrained algorithm applied to the solution of problem (5) for i ∈ {1, 2, 3} converges to a stationary pointx^i∈Diwhich gives a feasible point for the corresponding intermediate constrained formulation (6) or (9). This in turn implies that the corresponding pointy^i=Ti−1(x^i)is feasible for problem (1), i.e.y^i∈Δ,although it may not correspond to a KKT point of problem (1). Further we also have that at any pointx=Ti−1(y)corresponding to a feasible y, the values of the objective functions fiare equals for any i and alsof0(y^i)=fi(x^i). Hence,we have the following relationship(12)f0(y^i)=fi(x^i)≤fi(Ti−1(y0))=f0(y0)∀y0∈Δ∀i∈{1,2,3}.This property can be useful in the definition of the global heuristic.The results reported in the preceding section allow to look for global minimizers of constrained problem (1) by applying an unconstrained procedure to one of the unconstrained problems (5) with figiven in (7), (8) and (11).For the solution of the unconstrained problems we can use any local algorithm for unconstrained optimization. Of course there is no guarantee that any of these algorithms would converge to global minimizers of the selected unconstrained function fiand hence of problem (1). We can only have convergence to a stationary pointx^iof the function fiwith i = 1, 2, 3 and by the inverse transformation we obtain ay^i=Ti−1(x^i)∈Δ. Although we never observe such an occurrence in practice, it may happen that a spurious stationary point is located so thaty^iis not a KKT point of the constrained problem (1). Nevertheless, sincey^iis feasible for (1) and it satisfies (12) we can define a global heuristic for problem (1).We note that the procedure reported in the following can be used in connection with any finite number of unconstrained formulations for the StQP; in the following we restrict to the three unconstrained formulations proposed in Section 3.In order to define a global heuristic we adopt a standard multistart global optimization technique. It consists in repeating M > 1 runs of the same local minimization process starting from different randomly chosen points x0kand selecting the pointx^which provides the best objective value over all the runs. A multistart approach applied to the ith unconstrained formulation leads to an heuristic hifor solving problem (1). In Bomze et al. (2012) and Bomze and Palagi (2005), three heuristics hi, i = 1, 2, 3 have been proposed to solve the StQPs arising from the Maximum Clique Problems; none of them dominates the others in term of best optimal values obtained so that an integrated approach can be useful.A trivial way for combining these three heuristics consists in using all the three unconstrained formulations fiat each random point x0kfor all k = 1, …, M (THEM). The overall number of unconstrained minimizations is 3M.Of course this approach, reported in Algorithm 1, requires a great computational effort which is often useless because many of the 3M runs produce the same solution without improving the best current one. In order to avoid useless optimizations, we propose to extend the approach described in Cassioli et al. (2012), where machine learning tools are used to improve a global multistart strategy. Cassioli et al. (2012) proposed the algorithm LeGO: Learning for Global Optimization, which uses Support Vector Machines to learn the relationship between the starting point of an algorithm and the final outcome, which is usually related to the function value at the point returned by the procedure. We extend this approach to tackle also the choice of the best unconstrained formulation.In this section we briefly present the classification method using Support Vector Machines (SVMs) employed in the following experiments. For a general and more detailed introduction to this topic, the reader can look in Vapnik (1998) and Burges (1998). We refer to a standard two class classification problem aimed to construct a function able to classify correctly new instances. Indeed in our context, the classifier should be able to decide whether a pair (x0k, fi) can be discarded in the sense that a minimization procedure applied to fistarting from x0kwill not probably produce a better solution.In a classification problem, we must refer to a Training SetTdescribed as:(13)T={(xℓ,dℓ),xℓ∈Rn,dℓ∈{−1,1},ℓ=1,…,N}wherexℓ∈Rnrepresents the input (in our case it will be the starting point) and dℓ ∈ { − 1, 1} the output, namely the belonging class (in our case promising or not promising).SVMs are a special class of Kernel methods which uses as notion of similarity among data the inner product in a possible larger feature space. Thus, SVMs implement binary classifiers that learn the possibly nonlinear border between datasets belonging to different classes. The nonlinear classifier functionΦ:Rn→{−1,1}has the general formΦ(x)=sign(∑ℓ=1Nλℓdℓk(x,xℓ)+b)whereλ∈RNandb∈Rare obtained during the training phase by means of an optimization procedure. Among the most common kernels functions k(x, z) are:•Polynomial k(x, z) = (x⊤z + γ)p, where p ≥ 0 and γ ≥ 0 which includes the linear kernel (γ = 0, p = 1);Gaussian k(x, z) = exp( − γ‖x − z‖2), with γ ≥ 0Points xℓ corresponding to an optimal value λℓ > 0 are the so called Support Vector, namely points that are on the boundary of the nonlinear surface separating the two classes.The optimization problem that needs to be solved to find λ and b is a special convex StQP in the dimension|Ti|=Nwhich involves user-defined parameters which appear either in the kernel function used (such as γ or p) and in a “penalization” term of misclassified points. The choice of these parameters may affect the classification performance of the function Φ and their values are often selected by means of a cross-validation procedure using the training data (see e.g. Bishop 2006). A drawback of cross-validation is that the number of training runs that must be performed increases, and this in our context can be more expensive than the computational effort of the several running. Hence we do not use a cross-validation procedure but we rather use a user-defined setting.As we mentioned in the introduction, we intend to define a paradigm to combine different heuristics into a single one by extending the approach proposed in Cassioli et al. (2012). Although the procedure described below can be applied to a finite number of unconstrained formulations for StQP, we focus on the three ones described in Section 3.The purpose of the Global Heuristic Optimization Strategy by SVM (GHOStSVM) is to decide which unconstrained formulation, if any, can produce a good solution for the StQP starting from a given point x0k. To this aim, we use a learning procedure to predict whether a point x0kcould be considered promising for one of the formulations fi, in the sense that the stationary pointx^ikobtained by means of an unconstrained procedure starting from x0kgives a “good value” for the StQP (1). The meaning of “good value” will be specified later in this section. If no formulation is selected, than the point x0kis skipped. Whenever the point x0kis promising for more than one unconstrained formulation, the algorithm must also decide the most suitable among them in order to apply at most a single unconstrained optimization procedure for each x0k.Now we enter details of GHOStSVM which can be divided in two phases. The aim of Phase I is the construction and training of three classifiers SVMi, i = 1, 2, 3 that return if it is worthwhile to start the optimization procedure from x0kusing formulation fi. In order to train the three classifiers, we first need to construct three training setsTi,made up of pairs (x0k, dik) withx0k∈Rnand dik∈ { − 1, 1}, where dik= 1 is assigned to a “good” point. To this purpose we need to define a criterion to establish whether a a point x0kis “good” with respect to formulation i, or not. Actually this issue is quite important. Of course many different criteria can be proposed and any of these may present weak and strength points with respect to the definition of a good training set. In Section 7 we report the results using different criteria. After several trials, we select as default criterion the one that gave the best performance as a tradeoff of the best value found and the computational savings. In particular a point x0kis classified as good with respect to formulation i, if both the returned value of objective functionfi(x^ik)is sufficiently reduced with respect to a reference value fref, and if it is sufficiently far from a region of attraction of a “reference” point. In the numerical experience we tried to use different “reference” point. The precise rules which define the adopted criterion are reported in the sketch Algorithm 2and corresponds to the most robust one.Of course a check whether the training setsTi,i = 1, 2, 3 are balanced must be performed. In particular, the case when for a given fimost or all the labels have the same value must be tackled, in order to overcome possible misclassifications, and we use a standard approach proposed in SVM literature.At the end of Phase I, three classifiers (SVMi)i = 1, 2, 3, which can be used in a multistart procedure to select promising (dik= 1) pairs (x0k, fi), i = 1, 2, 3, are available. At any given point x0kit may happen that dik= 1 for more than one index i while we are interested in selecting just one of them. This selection is based upon the performances achieved in Phase I, namely selecting the unconstrained formulation which had given the best value on average. The sketch of GHOStSVM is reported in Algorithm 3where the stopping criterion in the main loop must still be specified.We observe that the value f* returned by GHOStSVM cannot be worst than the one returned by Phase I and that GHOStSVM performs at least 3N local searches.The computational burden of GHOStSVM is due either to the training of the SVMiusingTiand to the local searches. The training of the three SVMirequires the solution of three small dimension (N ≪ n) single constrained quadratic convex problems that can be performed in a very efficient way (see e.g. Joachims 1998; Lin et al. 2009). We can affirm that the computational burden of training each SVMiis equivalent to a single local search. These three problems inRNare solved once for all at the end of the first N epochs, whereas strictly more than 3N local searches inRnmust be performed. Hence the computational cost related to the training of each SVMiis negligible with respect to the local searches.We focus now on the definition of the stopping criterion missed in the general sketch of GHOStSVM. A first use of GHOStSVM consists in fixing the overall number of starting points generated in Phase I and Phase II to M, so that the stopping criterion requires ♯pt≤ M − N and the number of local searches performed ♯optcan be at most 3N + (M − N) = 2N + M < 3M. We refer to this version as GHOStv1SVM.On the other hand, we can define the stopping criterion considering the overall number of local searches. In particular we stop when the number of local searches reaches ♯opt= 3M, with a safeguard rule on the maximum number of random starting points generated♯pt≤♯ptmax,and we refer to this version as GHOStv2SVM. In this case the computational effort of GHOStv2SVMis equal to the one of THEMand we evaluate the ability of GHOStv2SVMof individuating better values f* than THEM.We consider the StQP test problems arising from the Maximum Clique Problem on a set of graphs from the DIMACS challenge (Johnson and Trick, 1996) that were also considered in Bomze et al. (2012) and Bomze and Palagi (2005). From now on we refer to a maximization problem as in (3) and we report the results in terms of the equivalent value of the best clique ω* obtained asω*=12(1−f*)−1. We recall that a feasible solutiony¯of the StQP (1) gives a clique if and only ify¯is a local maximizer. Hence, recalling that spurious stationary points of fimay occur, we check aty¯the satisfaction of the KKT conditions of (1) and the fact that a clique has been found. Actually, experimental testing showed that such spurious stationary points never occur.GHOStSVM has been implemented in Fortran 90 in the two versions GHOStv1SVMand GHOStv2SVM. We use a pseudorandom number generator for the starting point, as implemented in the Fortran library. As for the unconstrained method to solve problem (5), we use the non-monotone Barzilai–Borwein gradient method proposed in Grippo and Sciandrone (2002). The SVMs were trained by LibSVM (the reader can refer to Chang and Lin 2011 for more details) launched by a shell using a System call from the Fortran code. We run several experiments with different kernels and we select the Gaussian kernel. We do not implement a cross-validation procedure for finding the user-defined parameters γ and C, but we set the kernel parameter to γ = 1 and the penalty on misclassified training data to C = 100. For sake of completeness, we report the effect of changing these parameters on a subset of problems where misclassification occurs.In GHOStSVM: Phase I, we set the dimension N of the training setsTiaccording to the dimension n of the problem as followsN={50ifn≤100070otherwise.It may happen that a training setTiturns out to be unbalanced, that is the percentage of positive instances, dik= 1, with respect to negative ones, dik= −1, is quite different. When this happens the learning procedure may be biased by the most common label. A trivial way to tackle this issue consists in increasing the cardinality N of the training sets to get more information. However this will lead to a larger number of local searches to be performed in the training phase and may not produce a more balanced training set. We prefer to tackle this issue using a particular tool in LIBSVM, which allows to choose different penalty parameters for the two classes in the SVM training problem, by setting different weights w+, w− for the classes. In particular we use as w+, w− respectively the percentage of the negative and positive instances inTi.As a term of comparison, we run the three heuristics over the overall set of 73 problems setting M = 220. The results are in Table A.1of the Appendix A. We report for each problem the best known value (bkv), the best (max), the average (avg) and the worst (min) clique values found by each heuristic i = 1, 2, 3. From the table, we observe that on 19 problems over the 73 used, all the three heuristics find the benchmark value (these problems are: C125.9, the c-fat family, hamming6-2, hamming6-4, hamming8-4, the Johnson family, mann_a9, p_hat300-1, p_hat300-2, p_hat500-1). We classify this problem as trivial ones and we eliminate them from the test set.We note however that this classification is possible only because a certified optimal solution is known. For a generic StQP problem this information may be not available so that even if the heuristics performs the same, none of them may have found the global solution. This actually happens on other 25 problems over the 54 remaining, where each heuristic found the same clique value which is not the optimal one. However, combining the heuristics as in GHOStSVM does not require to have run them separately (otherwise it is of course useless), hence we decide to include them in the benchmark to test the capability of GHOStSVM to perform its different tasks. Over the remaining 29 problems, the three heuristics perform differently and we report for these cases in Table 1the number of wins, ties and losses of each heuristic with respect to the others in terms of the best value obtained. In these problems, none of the three heuristics dominates the others in terms of best clique value found and hence they represent the most challenging ones.We end up with 54 problems in which we tested the two versions of GHOStSVM. First we observe that, as mentioned in Section 6, a crucial aspect for a good performance is the choice of the criterion used in Phase I to define the training set (i.e. assign label ± 1 to points inTi) and the tuning of the parameters %ref and %d. To understand the relevance of these choices, we run GHOStv1SVMwith M = 220 using in Phase I different criteria, namely (i) the default criterion reported in Algorithm 2; (ii) a criterion based only on the function valuefi(x^ik)fref≤%ref(GHOStR1SVM); (iii) a criterion using only the distance∥x0k−xbest0i∥2∥x^ik−xbesti∥2≥%d(GHOStR2SVM), where also different reference points thanxbest0i,xbestihave been tried. After different trials, we set %ref = 1 and %d = 0.95 and to highlight the role of different criteria we summarize the results in a picture. In particular for each criterion, we report the number of problems solved as a function of the number of local optimization calls. We eliminate those problems where none of the three versions reaches the value found by THEMi.e. the best value among the three heuristics (these are nine problems). In Fig. 1we report the three curves: on the x-axis we report the number of optimization calls actually applied during the overall procedure; a point on a curve represents the number of problems solved within the corresponding number of optimization calls. In other words, the smaller the value on the x-axis, the higher the number of starting points discarded. Hence, the best performance corresponds to the highest curve. It turns out that the performance of GHOStR1SVMis comparable to that of GHOStv1SVM,thus the the criterion based on the function values dominates the one based only on the ratio of distances (this is true whatever the reference point is). However the joined use of the two criteria as in GHOStv1SVMproduces a benefit in terms of computational savings and we select this as the default criterion.Finally, we run GHOStv1SVMand GHOStv2SVMover the 54 problems and we report the complete results in Table A.2. As a term of comparison, we report in the same table for each problem the best value (bv) found by each of the heuristics, the best value (bv) and the number of local searches ♯optreturned by THE220, GHOStv1SVMand GHOStv2SVMrespectively. In the following, we analyze the results achieved by GHOStv1SVMand GHOStv2SVMseparately.Concerning GHOStv1SVM,first of all it is important to observe that, since the random points used are the same ones used by the three heuristics, the best value achieved by it cannot be better than the one returned by THEM. Hence in this setting of the experiments, we check whether GHOStv1SVMis able to save optimizations without losing a best pair in the set (x0k, fi)k = N + 1, …, M; i = 1, 2, 3. We can distinguish the analysis among the two subset of problems composing the test set. Indeed, in the 25 problems where the three heuristics perform the same, one can argue that it could have obtained the best value by selecting randomly one of them. However, this is true only if we knew in advance the performance but, when applying GHOStv1SVM,we must assume that we did not have run the heuristics before. GHOStv1SVMalways finds the same value of the three heuristics, hence it achieves one of its tasks, i.e. the “right” pair (x0k, fi) is not lost. In order to classify this problems as wins, ties or losses we consider the percentage of computational saving. In particular, we say that the computational saving is p percent if GHOStv1SVMperforms in Phase II at most the (100 − p) percent of the optimization calls, namely if the overall number of optimization calls satisfies ♯opt≤ 3N + (1 − p/100)(220 − N) (Table 2).We classify these problems as a win of GHOStv1SVMwhenever the best value is found with at least a 40 percent of savings; these are 11 problems and on 5 of them the saving was over 80 percent. We say that there is a tie whenever GHOStv1SVMfinds the best value by saving 10 percent ≤ p < 40 percent; these are 8 problems. On the other hand when the overall saving in less than 10 percent we classify the problem as a loss.Now we analyze the results on the 29 problems where the three heuristics do not perform the same and hence to get the best value we should run THE220 which requires 660 optimization runs. On 18 problems GHOStv1SVMfound the same best value performing a lower number of optimization calls. These problems are classified as wins. On the remaining 11 problems, the value reported by GHOStv1SVMis worse with respect to that of THE220. These cases correspond to misclassification, since GHOStv1SVMdiscard the correct pair (x0k, fi). In order to clarify this aspect, we run on these 11 problems GHOStv1SVMchanging the γ parameter in the Gaussian Kernel used in the SVM model.These results are reported in Table 3where the best value found is in boldface. It is shown that these failures are related to the choice of γ rather than the idea behind the algorithm and that tuning the value of γ is not easy. Indeed a more accurate choice, possible with a suitable cross validation procedure could be applied to find the best setting for the SVM parameters, but this was out the scope of the paper. Hence these problems cannot be easily classified as wins, ties, losses. We summarize the overall performance of GHOStv1SVMover the 54 problems in Fig. 2reporting the percentage of wins, ties, losses and misclassification cases.As regards GHOStv2SVMwe fix the number of local searches to 3 · M = 660 and the competitor is THE220. In this case we focus on the capability of finding a better value than THE220 applying the same number of local searches. When this happens we say that GHOStv2SVMwins over THE220. We define instead a tie when GHOStv2SVMand THE220 return the same value. Otherwise GHOStv2SVMloses. We note that on some problems GHOStv2SVMperforms less than 3M = 660 local searches because it does not accept enough points within the maximum safeguard number.We summarize the numbers of wins, ties and losses of GHOStv2SVMversus THE220 in Fig. 3. The detailed results are in Table A.2 of Appendix A where problems when GHOStv2SVMwins are highlighted in gray and the ones when it loses are in boldface.

@&#CONCLUSIONS@&#
