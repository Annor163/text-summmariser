@&#MAIN-TITLE@&#
A multi-wavelet optimization approach using similarity measures for electrocardiogram signal classification

@&#HIGHLIGHTS@&#
This research paper presents a novel ECG classification method using new wavelets.New wavelet functions (WFs) have been designed using polyphase representation.The approach for generating WFs relies on the similarity between WFs and ECGs.Feature vector is obtained by applying all designed WFs to every single beat.ECG decomposition, application of PCA, and MLP provides the classification scheme.

@&#KEYPHRASES@&#
ECG classification,Wavelet design,Discrete wavelet transform,Similarity measure,Hybrid GA-PSO,

@&#ABSTRACT@&#
One of the main approaches for classifying the ECG signals is the use of wavelet transform. In this paper, a method has been presented for classifying the ECG signals by means of new wavelet functions (WFs). The considered approach for generating the new WFs relies on the degree of similarity between the shapes of the WFs and ECG signals. Thus, by formulating the wavelet design problem in the hybrid GA-PSO framework, and using Euclidean, Dynamic Time Warping, Signed Correlation Index, and Adaptive Signed Correlation Index similarity measures as wavelet design criterion, six WFs corresponding to six common arrhythmias have been designed. Decomposition of ECG signal using designed WFs, and thereafter, application of PCA, and multilayer perceptron classifier provides a classification scheme for ECG signals. Feature vector is obtained by applying all designed WFs to every single beat; so, the main advantage of this method is that the set of WFs used to decompose the beats, always includes a WF similar to those beats. Therefore, the generated features better resolve the various classes. Also, the effects of the number of neurons in the hidden layer and the different training methods of the MLP have been investigated. By performing some tests on the benchmark MIT-BIH arrhythmia database using the proposed method and also the common WFs, the superiority of the proposed approach in the overall accuracy as well as the accuracy of each class has been demonstrated.

@&#INTRODUCTION@&#
An electrocardiogram characterizes the electrical activities of a heart, which are recorded through several electrodes attached to the skin. This quasi-periodic signal contains valuable information on the functioning of a heart and can be used for the detection of heart disease [1]. The automatic detection of arrhythmia, including the detection of abnormal P, QRS and T waves and distinguishing them from normal heart rhythms could be very useful for an early detection of heart disease, especially in real time. One of the complexities of the ECG analysis is the enormous variety of waveforms that exist not only in different arrhythmias, but also within different time intervals for a particular arrhythmia.Using wavelet transform enables us to analyze a signal in different frequency bands. For this reason, the wavelet transform technique is extensively used today in the de-noising, compression and classification of biological signals, especially the ECG signals [2].There are a number of new approaches for the classification of ECG signals. Martis et al. [3] used DWT coefficients and dimension reduction methods to feed SVM, PNN and NN in order to classify five arrhythmias. Using the morphological features and the RR intervals, as the feature vectors, and the mixture of experts (ME) and negatively correlated learning (NCL), Javadi et al. [4] classified ECG signals into normal and abnormal classes. Yu and Chen [5] classified six types of arrhythmias by considering three statistical features of the wavelet coefficients in addition to the RR interval and by employing the PNN. Khazaee and Ebrahimzadeh [6] classified five types of ECG beats by proposing a power spectral-based hybrid Genetic Algorithm and Support Vector Machine (SVMGA) technique. Using 64 features including 48 statistical features of wavelet coefficients and 16 morphological features, Rai et al. [7] classified a number of ECG signals into normal and abnormal ones by applying the MLP, FFN and BPN classifiers.On the other hand, there are some methods using optimization methods to classify ECG beats. Dogan and Korurek [8] classified six types of ECG beats using Ant Colony Optimization for Continuous Domains and a radial basis function neural network. Dilmac and Korurek [9] proposed a new Modified Artificial Bee Colony (MABC) algorithm for data clustering and applied it to ECG signal analysis for classification.It is noticeable that in all the mentioned works, a common wavelet function (WF) has been used. Nevertheless, Senhaji et al. [10] showed that no WF can be considered the most appropriate to use in classifications and that the ultimate decision must be made by comparing the results of different wavelets for each specific case.So, some research works have been carried out to find the most appropriate WF for the classification and denoising of ECG signals. For example, Daamouche et al. [11] presented an innovative approach for generating appropriate WFs used in the classification of ECG signals. In this approach, a polyphase representation of wavelet filter banks has been used and the considered problem has been formulated in the particle swarm optimization (PSO) framework. The results show that the proposed wavelet is superior to the Daubechies and Symlet wavelet families. Tan et al. [12] proposed the Best WF Identification System to identify and select the WF which is better suited to denoising a given ECG signal. Kumari et al. [13] designed two new wavelets by using the polyphase representation of wavelet filter banks and considering the perfect reconstruction conditions as the cost function.As was pointed out, the main approach of all the previous works on the design of WFs is the use of one WF for the classification of all types of beats. In this paper, six different WFs have been used to classify six common arrhythmias. For this purpose, first, by introducing a WF design by means of polyphase representation, an optimization problem is formulated for finding the right angular parameters. By solving this optimization problem for each arrhythmia, the angular parameters that generate the low-pass and high-pass filter coefficients of a WF correspond to that arrhythmia are found. Due to the complexity of the optimization problem, the hybrid GA-PSO approach has been used in order to benefit from the positive characteristics of both the genetic algorithm and the particle swarm optimization approaches. The cost function used in the optimization algorithm expresses the degree of resemblance of the generated WF to the shape of an arrhythmia. To assess the degree of similarity between a WF and the shape of an arrhythmia, Euclidean, Dynamic Time Warping, Signed Correlation Index, and Adaptive Signed Correlation Index similarity measures have been employed. Then by decomposing the ECG signal using these six WFs and by applying the PCA method separately on the approximation and detail coefficients at level 4 and putting together the obtained results, the feature vector used in the classification process have been developed. Then, the MLP classifier has been used to classify the ECG signals. At the end, the performance of the proposed algorithm on MIT-BIH database has been investigated.The remainder of this paper has been organized as follows. Section 2 gives a general review of wavelets, optimization approaches, feature extraction method, and the MLP classifier. Section 3 describes the proposed method. Section 4 deals with database description and performance indices. Results and discussion are provided in Section 5. And finally, the paper concludes in Section 6.In multiresolution framework, a signal is represented at different scales, each having a different resolution. Each scale spans the entire time/spatial range of the input signal, but does not represent the original signal completely [14]. The discrete wavelet transform (DWT) is related to multirate filter banks. It is performed by applying low-pass and high-pass filters on the input signal and then downsampling the signal by two [15]. First, let us introduce the scaling and WFs,(1)ϕ(t)=∑nh0(n)ϕ(2t−n)(2)ψ(t)=∑nh1(n)ϕ(2t−n)Eqs. (1) and (2) are called the dilation and wavelet equations, and ϕ(t) and ψ(t) are called the scaling (corresponding to a low-pass filter) and wavelet (corresponding to a high-pass filter) functions, respectively [16]. The left-hand sides of (1) and (2) are expressed through the sets of functions of the form {ϕ(2jt−n)}, where parameters j and n are the dilation and translation parameters.Fig. 1shows the DWT process for signal x(n). Signal x(n) gets downsampled by two and filtered through filters h0(n) and h1(n). These two filters are called “analysis filters” [14]. After being processed, the signal is filtered by f0(n) and f1(n), which are called “synthesis filters”. The signals from the two channels are upsampled and combined to produce an output signal at the original rate [14]. A filter bank consisting of the filters that allow the original signal to be recovered without any distortion is called a perfect reconstruction (PR) filter bank [15].Let the analysis low-pass filter in a two-channel PR orthonormal filter bank has 2N coefficients as {h0(i)}Then, in the z domain we have,(3)H0(z)=∑i=02N−1h0(i)z−i=∑i=0N−1h0(2i)z−2i+z−1∑i=0N−1h0(2i+1)z−2iH00(z)=∑i=0N−1h0(2i)z−2iH01(z)=∑i=0N−1h0(2i+1)z−2iwhere H00(z) and H01(z) are the polyphase components (even and odd powers of z[17,18]) of H0(z). The following factorization of the polyphase matrix was proposed in [17],(4)Hp(z)=H00(z)H01(z)H10(z)H11(z)=c0s0−s0c0⋅∏i=1N−1100z−1⋅cisi−siciwhere H10(z) and H11(z) are the polyphase components of the high-pass analysis filter H1(z), and ci=cos(αi) and si=sin(αi).This factorization generates all the two-channel PR orthonormal filter banks with an impulse response length of 2N, i.e., any such filter bank can be written in terms of N parameters (αi) by taking the values from interval [0, 2π). A new formulation was proposed in [19] by rewriting the above factorization in the following general recursive form,(5)Hp(k+1)(z)=Hp(k)(z)⋅100z−1⋅cksk−skckk=1,2,…,NwhereHp(1)=c0s0−s0c0and the superscript (k) refers to filters of length 2k. This yields the following recursive formulae for the even-numbered filter coefficients {h0(2i)},(6)h0(k+1)(0)=ckh0(k)(0)h0(k+1)(2i)=ckh0(k)(2i)−skh0(k)(2i−1)i=1,2,…,k−1h0(k+1)(2k)=−skh0(k)(2k−1)whereh0(1)(0)=c0andh0(1)(1)=s0. Similarly, the relations for the odd coefficients will be {h0(2i+1)},(7)h0(k+1)(1)=skh0(k)(0)h0(k+1)(2i+1)=skh0(k)(2i)+ckh0(k)(2i−1)i=1,2,…,k−1h0(k+1)(2k+1)=ckh0(k)(2k−1)Eqs. (6) and (7) express the low-pass coefficients {h0(i)} in terms of N free chosen angular parameters {αi, i=1, 2, …, N}, whose values are from interval [0, 2π). To generate a two-channel PR orthonormal filter bank, one can find the high-pass filter coefficients by,(8)h1(i)=(−1)i+1h0(2N−1−i)So, by choosing N free parameters {αi, i=1, 2, …, N}, a legal two-channel PR orthonormal filter bank can be produced. Therefore, using angular parameters αito design a customized mother WF can be viewed as an optimization problem.Genetic algorithm (GA) is a randomized global search technique, based on the survival and reproduction of the fittest principle, which was first introduced by Holland [20]. GA forms a population of candidate answers. The fitness of each answer is evaluated by the performance function. After finishing the assessment, a biased roulette wheel is used to randomly select the better answers which will undergo genetic operations. The newly created and stronger answers substitute the weaker answers of the previous generation. This evolutionary process will continue until the stopping criteria is satisfied [21].The particle swarm optimization (PSO) algorithm is a stochastic search method developed by Eberhart and Kennedy [22]. Particles, which represent potential solutions in the PSO algorithm, fly in the multidimensional search space, and the position of each particle is adjusted with respect to its previous best position and the neighborhood best or global best [21].The updating of a particle's velocity in the next iteration, from the perspective of inertia weight approach (IWA), has been presented in the following equation [23],(9)vid=w×vid+c1×r1×(Pid−Xid)+c2×r2×(Pgd−Xid)In the above equation,vidis the velocity of particle i, Xiddenotes the current position of particle i, w is the inertia factor, c1 and c2 are the relative influences of the cognitive component and social component, respectively, Pidis the local best of particle i, and Pgdis the global best of the group. r1 and r2 are random numbers. The current position (search point in the solution space) is determined through the following equation [23],(10)Xid=Xid+vidIn this paper, the hybrid GA-PSO approach has been used to take advantage of the benefits of both algorithms. One of the advantages of the PSO over the GA is its algorithmic simplicity [23]. Also, in GA, the information of an individual that does not get selected is eliminated; but the PSO algorithm has a memory to store such information. Another difference between the two algorithms is their ability to control convergence. The major drawback of the PSO is its quick convergence to a stable point which is not necessarily optimal. Also it is difficult for the GA to find the exact solution, it performs well in attaining a global region. The collective interaction in the PSO method facilitates the search to find the optimal solution [24]. Thus, by taking advantage of the strong points of both methods, the global region of the solution can be located and the optimum solution can be found in this region with a higher accuracy.The principal component analysis (PCA) is a linear dimension reduction method that maps the original data into the directions of highest variance [25]. The process of computing the principal components (PCs) consists of computing the covariance matrix of the original data, solving the eigenvalue problem, sorting the eigenvectors in a descending order and selecting the corresponding eigenvectors. The first PC (an eigenvector corresponding to the largest eigenvalue) provides the basis for a direction of highest variance. The second PC provides the basis for the next direction which is orthogonal to the first one, and so on [26]. A percentage of total variance of the original data is set as a criterion for selecting the number of PCs.A multilayer perception (MLP) is the simplest and most common feedforward artificial neural network (FANN) for solving pattern recognition problems. An MLP is a directed graph consisting of at least three layers of neurons (each of which has been completely connected to the next layer): an input layer, at least one hidden layer, and an output layer [27]. The hidden layer(s) makes it possible to form nonlinear decision boundaries for separating the data that are not linearly separable [28].The MLP takes advantage of a supervised learning algorithm to determine the weights of the network during the training phase [29]. Instead of the methods that use the gradient descent algorithm to update the network weights, the resilient backpropagation approach [30] uses the sign of the partial derivative (instead of its value) to update the weights. This is formulated as follows,(11)Δij(t)=η+×Δij(t−1)if∂E∂wij(t−1)∂E∂wij(t)>0η−×Δij(t−1)if∂E∂wij(t−1)∂E∂wij(t)<0η0×Δij(t−1)otherwiseThe update value for every single weight is calculated by means of Eq. (12), and ultimately, each weight is modified by using its own update value,(12)Δwij(t)=−Δij(t)if∂E∂wij(t)>0+Δij(t)if∂E∂wij(t)<00otherwise(13)wij(t+1)=wij(t)+Δwij(t)Another MLP training method is the conjugate gradient (CG) technique [31], which uses the second derivative of the error surface. Each weight update is conjugate to the previous one, and needs a line search to compute its length. The algorithm calculates a search direction which is the direction of the weight step, and the line search finds the minimum point along the search direction [32]. The first search direction is the negative of the error function gradient. In each succeeding iteration, the search direction is computed using the new gradient and the previous search direction, as follows,(14)Δw(t+1)=−η(t)d(t)(15)d(t)=−g(t)+β(t−1)d(t−1)β(t−1) can be calculated using the Polak–Ribiere rule or the Fletcher–Reeves rule [33,34].One of the branches of the CG method is the Newton method. The following equation is used to update the weights in the Newton method,(16)Δwij(t+1)=wij(t)−Hk−1gkIn this equation, H is the Hessian matrix of the performance index at the current weight values. Due to the large volume of computations for the Hessian matrix, usually the quasi-Newton (secant) methods are employed, which do not require the computation of the second degree derivatives [35].For example, the one step secant (OSS) [31] algorithm does not store the complete Hessian matrix; it assumes that at each iteration, the previous Hessian was the identity matrix.As was mentioned in Section 1, numerous research works have been carried out to analyze ECG signals by means of common WFs (CWFs). However, it has been demonstrated in [11] that the classification performance of the ECG signals can be increased by generating a new WF. The optimization problem in [11] uses the classification accuracy as cost function. The proposed method in this paper uses the measure of similarity between the WF and arrhythmia as the cost function. In this approach, by using the polyphase representation for the filter banks, a WF similar to each arrhythmia is designed. The resemblance of the employed WF to an arrhythmia, especially when that signal is contaminated with noise, improves the decomposition of the signal [36]. Then, ECG signal is decomposed using designed WFs, and the coefficients put together to form a feature vector. This feature vector is employed to classify the ECG signals.In polyphase representation approach, by adjusting the value of parameter αiwithin the [0, 2π) interval, a two-channel PR orthonormal filter bank for decomposing a signal with a specific WF can be established. By using Eqs. (6) and (7), the coefficients associated with the analysis low-pass filter are obtained. Then, the analysis high-pass filter coefficients can be determined by means of Eq. (8). By repeatedly upsampling the synthesis high-pass filter coefficients by two and convolving the outputs with the synthesis low-pass filter coefficients, one can obtain the WF. Since it is not easy to adjust parameter αito achieve a desired WF shape, an optimization problem for finding suitable αis is formulated within a hybrid GA-PSO framework.Similarity measures are used to evaluate the degree of similarity of the designed WFs to an arrhythmia. In fact, a similarity measure is a bridge that connects the wavelet design to the optimization method. Due to the existence of time shift, amplitude shift, time scale, amplitude scale and phase shift differences between two signals, adopting an appropriate similarity measure is very important. In recent years, some research works have attempted to compare the similarity measures with one another [37–40]. In this paper, several common similarity measures have been used to generate the WFs similar to the considered arrhythmias. In the following, these methods will be briefly introduced.The simplest way of evaluating the degree of similarity between two signals is the use of the Euclidean distance. This method is exclusively applied to the signals with the same temporal location [40].Dynamic time warping (DTW; [41,42]) is a classic method for computing the similarity between two signals. DTW works by aligning (or ‘warping’) the signals in the temporal domain so that the accumulated cost of this alignment is minimal. This accumulated cost can be obtained by dynamic programming.Correlation analysis has been frequently used to measure the morphological similarity between biological signals. Assuming x and y to be two signals of length M with zero means, their signed correlation coefficient (SCC), which the sign is considered instead of the amplitude of the data [43], is defined as,(17)dSCC(x,y)=∑Mi=1sign(xi)×sign(yi)MOne of the new similarity measures is the adaptive signed correlation index (ASCI) [44]. The ASCI will be obtained as follows,(18)dASCI(x,y)=∑Mi=1txi⊗tyiMwhere tx and ty are the signed product of the two trichotomized signals x and y. Trichotomization is performed by dividing the signal space into three subspaces, which are positive subspace, zero subspace, and negative subspace. There are different methods to define the subspaces; typically, these subspaces are adaptive to a template signal. For more details see [44].Fig. 2shows the flowchart of the proposed method. First, the optimization algorithm considers a specific number of αis in the [0, 2π) interval as an initial guess. With regards to Eqs. (6) and (7), it is found that by choosing N number of αis, filters with 2N coefficients will be produced. In this research, WFs with N=3, …, 7 have been investigated. Next, by using Eqs. (6) and (7), the low-pass filter coefficients ({h0(i)}) and by using Eq. (8), the high-pass filter coefficients ({h1(i)}) are calculated. Now, by changing the signs of the even index entries of the reversed vector, the synthesis low-pass and high-pass filter coefficients ({f0(i)} and {f1(i)} in Fig. 1) are generated. Then by repeatedly upsampling the synthesis high-pass filter coefficients by two and convolving the outputs with the synthesis low-pass filter coefficients, one can obtain the WF.To extract the beats employed for WF generating, first, the R peak position for each beat is determined using database annotation, and then by considering 149 samples before and 150 samples after that, a beat with a length of 300 samples is extracted. Then, the average of all the beats for each arrhythmia is computed. This average beat is used to design a WF similar to the considered arrhythmia. It should be noted that the number of samples of the WF waveform depends on the number of coefficients of the synthesis filters and also the number of convolution steps. Thus, the number of samples of the WF waveform will not necessarily be 300. Since the Euclidean, SCC and ASCI similarity measures evaluate the degree of similarity between two signals of the same length, the length of a signal must be equalized to the length of a WF waveform. Therefore, interpolation can be used to equalize each arrhythmia's average signal length to the length of a WF waveform. It should also be noticed that the amplitude ranges of the WF and the average beat of arrhythmia are not identical; so, before using the similarity measures, these amplitude ranges must be equalized.By considering the normal beat and using one of the mentioned similarity measures, the similarity of the generated WF to the normal beat is evaluated and returned as the optimization algorithm's fitness function value. The hybrid GA-PSO has been employed to design the WFs. First, the GA considers some arbitrary values as the solutions and, by using the genetic operators and the fitness function, produces a new generation of solutions with higher probable qualities. Then the outputs of the GA are fed into the PSO algorithm as inputs, in order to search the solution region and to find more exact solutions, if possible. Then the outputs of the PSO algorithm are considered as the GA inputs and this process is repeated several times (generations of parameters αi). There are two termination criteria for the hybrid GA-PSO algorithm and if either of these criteria is satisfied, the hybrid algorithm will stop running and the output of the GA-PSO algorithm will be considered as the filter coefficients. The first termination criterion is a specific amount of difference between two consecutive fitness function values and the second is a predefined number of algorithm iterations. The values of the first and second criterion have been set as 1e−8 and 100, respectively. In the GA structure, the values of the population size, crossover and mutation parameter have been considered as 50, 0.7 and 0.2, respectively. Also, in the PSO algorithm, population size is 50, constants c1 and c2 are equal to 1.4962 and inertia weight are equal to 0.7298.After generating a WF for normal beat, five WFs are generated for each of the PVC, APC, PACED, RBBB and LBBB arrhythmias according to the mentioned approach.In order to produce a feature vector, a beat is decomposed by all the generated WFs up to four levels, and then the approximation and detail coefficients are chosen. It can be shown that most of the signal variations occur in the frequency band of the 4th level approximation and detail coefficients [45].By putting together the approximation and detail coefficients obtained from decomposing a beat by the six generated WFs, the feature vector is obtained. In view of the large number of wavelet transform coefficients, the PCA is used to reduce the dimensions of the feature vector. The number of PCs is chosen so that it consists of 95% of the total variance.Then the obtained feature vector is employed to train a multilayer perceptron. In this research, an MLP with one hidden layer and S neurons have been used. In the performed tests, the number of neurons (S) has been changed from 5 to 70. This has been done to prevent the affection of the neurons in the hidden on solutions. Also, the performances of three training methods (RPROP, OSS and CGPR) in the classification accuracy have been assessed.The ECG sources of the MIT-BIH database [46], which consist of 4000 Holter records, have been recorded at the laboratory of Boston's Beth Israel Hospital. This database includes 48 records. The signals sampling frequency is 360Hz and the resolution is 200 samples/mV.In this research, a total of 43 records have been used (refer to Table 1for details). The total number of extracted beats is equal to 70012; 163 of these beats (0.23%) have been randomly selected for training and the remaining beats have been used for testing.To assess the effectiveness of the proposed algorithm, four common performance indices in the literature have been used; these indices include the Accuracy (Acc.), Sensitivity (Se.), Specificity (Sp.) and Positive predictivity (Pp.). These performance indices are defined as follows,(19)Acc.(%)=TP+TNTP+TN+FP+FN×100(20)Se.(%)=TPTP+FN×100(21)Sp.(%)=TNTN+FP×100(22)Pp.(%)=TPTP+FP×100where TP is True Positive, TN is True Negative, FP is False Positive, and FN is False Negative.

@&#CONCLUSIONS@&#
