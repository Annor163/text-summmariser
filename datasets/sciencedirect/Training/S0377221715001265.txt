@&#MAIN-TITLE@&#
An interval-valued intuitionistic fuzzy principal component analysis model-based method for complex multi-attribute large-group decision-making

@&#HIGHLIGHTS@&#
Proposed the PCA model for interval-valued intuitionistic fuzzy variables.Applied the model to complex multi-attribute large-group decision-making problems.Considered the independence among attributes and DMs.

@&#KEYPHRASES@&#
Decision analysis,Complex multi-attribute large-group decision-making,Interval-valued intuitionistic fuzzy principal component analysis,Information aggregation,

@&#ABSTRACT@&#
The complex multi-attribute large-group decision-making problems that are based on interval-valued intuitionistic fuzzy information have become a common topic of research in the field of decision-making. Due to the complexity of this kind of problem, alternatives are usually described by multiple attributes that exhibit a high degree of interdependence or interactivity. In addition, decision makers tend to be derived from different interest groups, which cause the assumption of independence between the decision maker preferences in the same interest group to be violated. Because traditional aggregation operators are proposed based on the independence axiom, directly applying these operators to the information aggregation process in the complex multi-attribute large-group decision-making problem is not appropriate. Although these operators can obtain the overall evaluation value of each alternative, the results may be biased. Therefore, we draw the thought from the conventional principal component analysis model and propose the interval-valued intuitionistic fuzzy principal component analysis model. Based on this new model, we provide a decision-making method for the complex multi-attribute large-group decision-making problem. First, we treat the attributes and the decision makers as interval-valued intuitionistic fuzzy variables, and we transform these two types of variables into several independent variables using the proposed principal component analysis model. We then obtain each alternative's overall evaluation value by utilizing conventional information aggregation operators. Moreover, we obtain the optimal alternative(s) based on the ranks of the alternative overall evaluation values. An illustrative example is provided to demonstrate the proposed technique and evaluate its feasibility and validity.

@&#INTRODUCTION@&#
Multi-attribute group decision-making (MAGDM) problems have been the focus of substantial research since the sorting model of group alternatives was developed by the French mathematician Borda in 1781 (Ahn, 2015; Altuzarra, Moreno-Jimenez, & Salvador, 2007; Brunelli & Fedrizzi, 2015; Chen, Chang, & Lu, 2013; Dede, Kamalakis, & Sphicopoulos, 2015; Huang, Chang, & Li, 2013; Lahdelma & Salminen, 2001; Merigó, Casanovas, & Yang, 2014; Ondemir & Gupta, 2014; Peng, Kou, Wang, & Shi, 2011; Wang & Chin, 2009; Xia & Chen, 2015; Xia, Xu, & Chen 2013; Zhu & Xu, 2014). Due to the development of information techniques, the general public can participate in public decision-making problems, which has led to the evolution of the electronic democracy. The traditional MAGDM problem is a type of small-group decision-making process in which the scale of the decision maker (DM) is small (e.g., 3–5 persons), and the complexity of the decision-making problem is not high (e.g., the investment decision-making of the enterprise). However, decision-making in an electronic democracy is a type of public affairs decision-making process that exhibits a greater influence. Chen (2006) referred to these problems as complex multi-attribute large-group decision-making (CMALGDM) problems and characterized them by the following four features: (a) members of the group can render decisions at different times and in different places within a network environment, (b) the group usually consists of more than 20 DMs, (c) connections may exist between various decision attributes, and (d) the preference information of the DMs is uncertain.In an uncertain environment, a fuzzy set (Zadeh, 1965) is limited by its failure to provide a broad description of all the information that is involved in a specific problem. To address this issue, Atanassov (1986) introduced the concept of the intuitionistic fuzzy (IF) set, which simultaneously considers membership and non-membership degree information. Atanassov and Gargov (1989) introduced the concept of the interval-valued intuitionistic fuzzy (IVIF) set, which denotes the degrees of membership and non-membership by closed subintervals of the interval [0, 1]. This approach not only expands the ability of the IF set to handle uncertain information but also improves its ability to solve practical decision-making problems. In this paper, we choose IVIF numbers as the preference information that is provided by the DMs.Similar to MAGDM problems (Tan, 2011a, 2011b), CMALGDM problems involve the following two stages: (a) the aggregation stage, which combines individual preferences to obtain an overall preference value for each alternative, and (b) the exploitation stage, which orders the overall preference values to obtain the best alternative(s). Xu and Chen (2007), Wang, Guan, and Wu (2012), Lin and Zhang (2012), and Yu, Wu, and Lu (2012) developed several aggregation operators for IVIF information. These operators are based on the assumption that the attributes or DM preferences are independent; they are linear operators that are based on additive measures, which are characterized by an independence axiom (Keeney & Raiffa, 1976; Wakker, 1999). However, this assumption is not appropriate in CMALGDM problems. Due to the complexity of the CMALGDM problem, alternatives are usually described by multiple attributes that exhibit a high degree of interdependence or interactive characteristics. Because DMs are normally from a number of interest groups, the assumption of independence between the DM preferences in the same interest group is violated. As a result, we cannot adopt these operators to directly aggregate the alternative evaluation information in the CMALGDM problem.To overcome the limitation of these operators, Tan (2011a, 2011b), Xu (2010), Xu and Xia (2011), and Wei (2012) considered the correlation between attributes or that between DMs from the perspective of fuzzy measures and proposed several Choquet integral (Choquet, 1953) based aggregation operators to aggregate the IVIF information. However, two drawbacks exist: (a) the method to confirm the fuzzy measures of the attributes or DMs is not advanced and (b) the number of fuzzy measures increases exponentially with an increase in the number of attributes or DMs. If there are n attributes or DMs, 2nfuzzy measures are required. In the CMALGDM problem, n is typically a large number, and acquiring 2nfuzzy measures is challenging. Thus, these operators cannot be conveniently applied to solve the CMALGDM problem.Because the traditional aggregation operators are based on the independence axiom, should we treat the attributes and DMs as variables and then transform them into several independent variables? Principal component analysis (PCA) (Hotelling, 1933; Jolliffe, 1986; Peason, 1901) is a well-known multivariate statistical technique that involves the orthogonal transformation of a specific number of correlated variables to an equivalent number of uncorrelated variables named principal components (PCs). Cazes, Chouakria, Diday, and Schektman (1997), Lauro and Palumbo (2000), Palumbo and Lauro (2003), Gioia and Lauro (2006), Guo and Li (2007), Hladik, Daney, and Tsigaridas (2010), D'Urso and Giordani (2004), Douzal-Chouakria, Billard, and Diday (2011), and Wang, Guan, and Wu (2012) generalized the PCA model for interval-valued variables. Based on this previous research, we propose a new PCA model for IVIF variables, called the IVIF-PCA model. Using this model, we compress the attributes and the DMs into several independent variables. This model not only reduces the complexity of the aggregation procedure but also improves the reliability of the aggregation results.The remainder of this paper is organized as follows: In Section 2, we review several basic concepts about the IF set and the IVIF set and briefly introduce the traditional PCA model. In Section 3, we propose new concepts that form the foundation of the IVIF-PCA model. We describe the IVIF-PCA model in Section 4. In Section 5, we adopt the proposed model for the CMALGDM problem and provide a decision-making method. An example is provided to investigate the feasibility and validity of the proposed decision-making method in Section 6. In Section 7, we compare our approach to an interval PCA approach and give the decision-making results for the case in which we neglect the dependence between the attributes and that between the DMs. A practical optimal alternative selection method is also provided in this section. Finally, the conclusions are discussed in Section 8.The basic concepts of the IF set and IVIF set are introduced in Section 2.1. Section 2.2 presents a literature review of the traditional PCA model, which is beneficial for the proposal of the IVIF-PCA model.As a generalization of the fuzzy set, Atanassov (1986) extended the concept of the fuzzy set and introduced the IF set as follows:Definition 1Let X be a non-empty real number set. The IF set A in X is an object in the form(1)A={〈x,μA(x),vA(x)〉|x∈X}.where μA(x) and vA(x) represent the membership degree and non-membership degree, respectively, of the element x in X as mapped to A. That is, μA: X → [0, 1], x ∈ X → μA(x) ∈ [0, 1]; vA: X → [0, 1], and x ∈ X → vA(x) ∈ [0, 1]. In addition, 0 ≤ μA(x) + vA(x) ≤ 1 for every x ∈ X.To simplify the expressions, Xu and Yager (2006) introduced the notation αx= (μA(x), vA(x)) to denote the IF number and to represent the element in IF set, where μA(x) ∈ [0, 1], vA(x) ∈ [0, 1], μA(x) + vA(x) ≤ 1.However, due to the complexity and uncertainty of the objective information, the use of real numbers to accurately express the membership and non-membership degrees in the IF set is challenging, whereas interval numbers are often more suitable. Atanassov and Gargov (1989) generalized the concepts of the IF set and the IVIF set and defined them as follows:Definition 2Let X be a non-empty real number set. Define(2)A˜={〈x,μ˜A˜(x),v˜A˜(x)〉|x∈X}as the IVIF set, whereμ˜A˜(x)=[μ˜A˜L(x),μ˜A˜U(x)]⊂[0,1],v˜A˜(x)=[v˜A˜L(x),v˜A˜U(x)]⊂[0,1], x ∈ X, andμ˜A˜U(x)+v˜A˜U(x)≤1. Ifμ˜A˜L(x)=μ˜A˜U(x)andv˜A˜L(x)=v˜A˜U(x), then the IVIF set is reduced to the ordinary IF set.According to this definition, the basic components of the IVIF set are the ordered intervals of the membership and non-membership degrees of the element x in X as mapped toA˜. Similar to Xu and Yager (2006), Xu (2007) referred toα˜x=(μ˜A˜(x),v˜A˜(x))=([μ˜A˜L(x),μ˜A˜U(x)],[v˜A˜L(x),v˜A˜U(x)])as the IVIF number and used it to conveniently represent the element in the IVIF set, where[μ˜A˜L(x),μ˜A˜U(x)]⊂[0,1],[v˜A˜L(x),v˜A˜U(x)]⊂[0,1], andμ˜A˜U(x)+v˜A˜U(x)≤1. Similar to the intervals of the elements in the IVIF set, these intervals also characterize the uncertainty of humans because people may be more used to giving an interval evaluation rather than a single value evaluation. Xu (2007) introduced the following operational laws of IVIF numbers, which can be regarded as a generalization of the operational laws of IF numbers given by Atanassov (1986). For convenience, we denoteα˜=([a,b],[c,d])as an IVIF number.Definition 3Letα˜1=([a1,b1],[c1,d1])andα˜2=([a2,b2],[c2,d2])be two IVIF numbers. Four operational laws ofα˜1andα˜2can be defined as follows:(1)α˜1⊕α˜2=([a1+a2−a1a2,b1+b2−b1b2],[c1c2,d1d2]).α˜1⊗α˜2=([a1a2,b1b2],[c1+c2−c1c2,d1+d2−d1d2]).λα˜1=([1−(1−a1)λ,1−(1−b1)λ],[c1λ,d1λ]),λ>0.α˜1λ=([a1λ,b1λ],[1−(1−c1)λ,1−(1−d1)λ]),λ>0.Supposeα˜j=([aj,bj],[cj,dj])(j=1,2,…,n)is a series of IVIF numbers. Therefore,(3)IIFWAω(α˜1,α˜2,…,α˜n)=ω1α˜1⊕ω2α˜2⊕…⊕ωnα˜n=([1−∏j=1n(1−aj)ωj,1−∏j=1n(1−bj)ωj],[∏j=1ncjωj,∏j=1ndjωj]),and(4)IIFWGω(α˜1,α˜2,…,α˜n)=α˜1ω1⊗α˜2ω2⊗…⊗α˜nωn=([∏j=1najωj,∏j=1nbjωj],[1−∏j=1n(1−cj)ωj,1−∏j=1n(1−dj)ωj]),whereω=(ω1,ω2,…,ωn)Tis the weight vector ofα˜1,α˜2,…,α˜n, ωj∈ [0, 1],∑j=1nωj=1,and T is the transposition of the vector.After the aggregation, a comparison of the IVIF numbers is usually required for the decision-making problem. Xu (2007) proposed the score function and the accuracy function to rank the IVIF numbers.Definition 5Letα˜=([a,b],[c,d])be an IVIF number. The score function and accuracy function ofα˜can be denoted bys(α˜)=12(a−c+b−d)andh(α˜)=12(a+b+c+d),respectively. Given two IVIF numbersα˜andβ˜,ifs(α˜)<s(β˜),thenα˜<β˜;ifs(α˜)=s(β˜),then(i)ifh(α˜)=h(β˜),thenα˜=β˜;ifh(α˜)<h(β˜),thenα˜<β˜.Because the IVIF-PCA model proposed in Section 4 is based on the concept of the traditional PCA model, the PCA model should be reviewed prior to continuing the analysis. The core idea of the PCA model is to reduce the dimensionality of a data set that is derived from a large number of interrelated variables while retaining most of the variation that is present in the data set (Jolliffe, 1986). This goal can be achieved by transforming these correlated variables into a few mutually independent and orthogonal new variables (i.e., the PCs), which are ordered to ensure that the first few PCs retain the majority of the variation that is presented in the original variables.Given m real variables ξ1, ξ2, …, ξmwith a known covariance matrixΣ, the kth PC is a linear combination of m variables denoted byηk=∑j=1mejkξj(k = 1, 2, …, m). The PCA is the eigendecomposition of the covariance matrix. Beginning with the maximization of the variance of ηksubject toekTel=0(l=1,2,…,m;l≠k),the resulting algebraic derivation isek=(e1k,e2k,…,emk)T, which is an eigenvector ofΣthat corresponds to the kth largest eigenvalue ɛk. Moreover, ekand ɛkare referred to as the PC coefficients and the PC variance, respectively. However, the covariance of the variables is frequently unknown in practice. Thus, it is necessary to evaluate the covariance of the population through observations or samples of the variables. By assuming that we have achieved a centralized or standardized sample matrixξ^=(ξij)n×mof the variables, the covariance matrix of the variables is denoted byS=ξ^Tξ^.We calculate the eigenvalues ɛ1, ɛ2, …, ɛmof S and their corresponding orthonormal eigenvectors e1, e2, …, em. These m eigenvectors are the PC coefficients, η1, η2, …, ηmare the PCs of ξ1, ξ2, …, ξm, andηk=ξ^ek(k = 1, …, m) is the score vector of ηk. The required number of PCs is the smallest value of p for which the chosen percentage of the total variation or the cumulative contribution rate (CCR), for example 90 percent, is exceeded. This percentage can be denoted byCCRp=∑k=1pɛk/∑k=1mɛk.Refer to Jolliffe (1986) for additional information about the traditional PCA.By reviewing the traditional PCA model, we discovered that when numerous correlated variables are obtained, we can construct linear combinations of these variables to form an equivalent number of new variables. These new variables are independent and contain all of the information about the original variables. The coefficients of the combinations (i.e., PC coefficients) are derived by maximizing the variances of these new variables. To solve the correlation problem between the IVIF variables, we should investigate the variance of the linear combination of the IVIF variables.However, because the linear combination of the IVIF variables may no longer be an IVIF variable (this argument can be found in Definition 7), for convenience, we generalize the IVIF number and IVIF set and define the concepts of the generalized IVIF number and the generalized IVIF set. Thus, all of the following definitions are given for the generalized IVIF case, which can be used directly in the IVIF case.Definition 6Let X be a non-empty real number set. For the IVIF numberα˜x=(μ˜A˜(x),v˜A˜(x))=([μ˜A˜L(x),μ˜A˜U(x)],[v˜A˜L(x),v˜A˜U(x)]), eliminate the restriction of the intervalsμ˜A˜(x)andv˜A˜(x)(i.e., the intervalsμ˜A˜(x)andv˜A˜(x)should belong to [0, 1], andμ˜A˜U(x)+v˜A˜U(x)≤1) and obtain two intervalsμ˙A˙(x)andv˙A˙(x). We call the new data typeα˙x=(μ˙A˙(x),v˙A˙(x))=([μ˙A˙L(x),μ˙A˙U(x)],[v˙A˙L(x),v˙A˙U(x)])the generalized IVIF number. Its corresponding setA˙={〈x,μ˙A˙(x),v˙A˙(x)〉|x∈X}is called the generalized IVIF set. The IVIF set and IVIF number are special cases of the generalized IVIF set and the generalized IVIF number, respectively. For convenience, both the IVIF set and the generalized IVIF set will be denoted byA˙, and both the IVIF number and the generalized IVIF number will be denoted byα˙x. Specifically, we retain the general form of the generalized IVIF number asα˙=([a,b],[c,d]).Similar to the addition and numerical multiplication of the interval number(s) (Moore, 1966; Lai, Wang, & Xu, 2002), we provide the concept of linear addition and linear numerical multiplication of generalized IVIF numbers as follows:Definition 7Letα˙=([a1,b1],[c1,d1])andβ˙=([a2,b2],[c2,d2])be two generalized IVIF numbers.(1)The linear addition ofα˙andβ˙is denoted by(5)α˙+β˙=([a1+a2,b1+b2],[c1+c2,d1+d2])The linear numerical multiplication ofα˙is denoted by(6)λα˙={([λa1,λb1],[λc1,λd1]),λ≥0;([λb1,λa1],[λd1,λc1]),λ<0.We provide the visual interpretation of the concept of linear addition whenα˙andβ˙are two IVIF numbers. Suppose the IVIF evaluation information of the attributes, with respect to the alternative given by DM A and DM B, areα˙=([0.6,0.7],[0.2,0.3])andβ˙=([0.7,0.8],[0.1,0.2]), respectively. The meaning ofα˙can be interpreted as follows: the degree of satisfaction with the attribute for DM A is within [0.6, 0.7], and the degree of dissatisfaction with the attribute for DM A is within [0.2, 0.3]. We obtain the corresponding interpretation ofβ˙.From Eq. (5), we determine thatα˙+β˙=([1.3,1.5],[0.3,0.5]),which indicates that the “accumulated” degree of satisfaction with the attribute for the two DMs is within [1.3, 1.5], and the “accumulated” degree of dissatisfaction with the attribute for the two DMs is within [0.3, 0.5]. For the linear numerical multiplication, if λ ≥ 0, the linear numerical multiplication can be regarded as the “scaling” of the DMs’ evaluation. For example, when λ = 2,λα˙=([1.2,1.7],[0.4,0.6]),which represents a doubling of the original evaluation information. If λ < 0, the linear numerical multiplicationλα˙can be regarded as the “scaling” of the image ofα˙.Based on Definition 7, we provide the linear combination of generalized IVIF numbers in Definition 8. This concept is regarded as a generalization of Moore's linear-combination algorithm, which was used to obtain the linear combination of the interval numbers (Cazes et al., 1997; Wang, Liu, & Qin, 2012).Definition 8Ifα˙j=([aj,bj],[cj,dj])(j=1,2,…,m)are m generalized IVIF numbers and λj∈ R (j = 1, 2, …m), the linear combination ofα˙jcan be denoted by(7)y˙=∑j=1mλjα˙j=([a,b],[c,d]),where(8)a=∑j=1mλj(τaj+(1−τ)bj),b=∑j=1mλj((1−τ)aj+bjτ),and(9)c=∑j=1mλj(τcj+(1−τ)dj),b=∑j=1mλj((1−τ)cj+djτ),with(10)τ={0,λj≤0,1,λj>0.Given m generalized IVIF variablesA˙1,A˙2,…,A˙m, each variableA˙j(j=1,2,…,m)has n observations that are represented by([μ˙ijL,μ˙ijU],[v˙ijL,v˙ijU])(i = 1, 2, …, n), and λj∈ R (j = 1, 2, …m). The linear combination ofA˙1,A˙2,…,A˙mcan be denoted by(11)Y˙=∑j=1mλjA˙j.whereY˙is a generalized IVIF variable, the corresponding observations ofY˙can be denoted byY˙=(y˙1,y˙2,…,y˙n), andy˙i(i=1,2,…,n)is the observation ofY˙, which is the linear combination of m generalized IVIF numbers([μ˙ijL,μ˙ijU],[v˙ijL,v˙ijU])(j=1,2,…m).Note that we did not use operational laws in Definition 3 but provide the new operational laws for generalized IVIF numbers for two reasons. (a) The first reason is that the operational laws in Definition 3 do not reflect the definitions of “accumulate” and “scaling” of the DM information. For example, ifα˙=([0.6,0.7],[0.2,0.3])andβ˙=([0.7,0.8],[0.1,0.2]),thenα˙⊕β˙=([0.88,0.94],[0.02,0.06]). This result indicates that the accumulated degree of satisfaction for the DMs is higher than the individual degree of satisfaction for any DM, whereas the accumulated degree of dissatisfaction for the DMs is lower than the degree of dissatisfaction for any individual DM; this is contrary to our intuition. If we double the evaluation, we obtain2α˙=([0.84,0.91],[0.04,0.09])and2β˙=([0.91,0.96],[0.01,0.04]). This result indicates that the degree of satisfaction contradicts the degree of dissatisfaction, which is also contrary to our intuition. (b) Another reason is that the operational laws in Definition 3 are nonlinear; this nonlinearity creates significant challenges for the construction of the IVIF-PCA model. Although the operational laws in Definition 3 are not suitable for the construction of the IVIF-PCA model, they are efficient for the aggregation of IVIF information. For instance, the IIFWA operator and the IIFWG operator, which are proposed based on these operational laws, have been used extensively in the field of decision-making (Xu, Zhou, Gu, and Qin, 2011; Yue, 2011). For this reason, we employ these two operators to aggregate the evaluation information in the final stage of the decision-making method.Prior to proposing the concepts of the sample variance and the sample covariance of generalized IVIF variables, it is beneficial to review these concepts for real variables. Let ξ and η be random real variables with n samples, which can be denoted by the crisp sets C1 = {ξ1, ξ2, …, ξn} and C2 = {η1, η2, …, ηn}, respectively. Let E(ξ) and E(η) be the sample means of the variables ξ and η, respectively, D(ξ) and D(η) be the sample variances of ξ and η, respectively, and COV(ξ, η) be the sample covariance of ξ and η, where,(12)E(ξ)=1n∑i=1nξi,E(η)=1n∑i=1nηi,(13)D(ξ)=1n−1∑i=1n(ξi−E(ξ))2,D(η)=1n−1∑i=1n(ηi−E(η))2,and(14)COV(ξ,η)=1n−1∑i=1n(ξi−E(ξ))(ηi−E(η)).The sample mean of the variable (e.g., E(ξ)) and the difference between the sample and the sample mean (e.g., ξi− E(ξ)) are crucial to the construction of the sample variance and the sample covariance of the variable(s). To replicate the real variable case, we first reproduce the sample mean of the generalized IVIF variable and the difference of the generalized IVIF numbers. The sample variance and the sample covariance of the generalized IVIF variable(s) are then provided.Suppose that X is the finite real number set X = {x1, x2, ⋅⋅⋅, xn}, andA˙={〈x,μ˙A˙(x),v˙A˙(x)〉|x∈X}is an arbitrary generalized IVIF set in X, which can be regarded as the range of the generalized IVIF variableA˙.The element ofA˙is denoted byα˙x=(μ˙A˙(x),v˙A˙(x))=([μ˙A˙L(x),μ˙A˙U(x)],[v˙A˙L(x),v˙A˙U(x)]).Definition 10For a given rangeA˙∈the generalized IVIF set, the sample mean of the generalized IVIF variableA˙is given by(15)E(A˙)=([E(μ˙A˙L(x)),E(μ˙A˙U(x))],[E(v˙A˙L(x)),E(v˙A˙U(x))])=([1n∑i=1nμ˙A˙L(xi),1n∑i=1nμ˙A˙U(xi)],×[1n∑i=1nv˙A˙L(xi),1n∑i=1nv˙A˙U(xi)]).Letα˙=([a1,b1],[c1,d1])andβ˙=([a2,b2],[c2,d2])be two generalized IVIF numbers. The difference betweenα˙andβ˙is denoted by(16)d(α˙,β˙)=1b2−a21b1−a1∫a2b2∫a1b1(x−y)dxdy−1d2−c21d1−c1∫c2d2∫c1d1(s−t)dsdt=12(a1+b1−a2−b2)−12(c1+d1−c2−d2).The differenced(α˙,β˙)consists of two parts: the difference of the membership degree and that of the non-membership degree. Because the membership degree and the non-membership degree are two opposing concepts, the difference of the two generalized IVIF numbers can be reasonably represented by subtracting the difference of the non-membership degree from the difference of the membership degree.For a given rangeA˙={α˙x1,α˙x2,…,α˙xn}∈the generalized IVIF set, the sample variance of the generalized IVIF variableA˙is given by(17)D(A˙)=1n−1∑i=1n(d(α˙xi,E(A˙)))2For two given rangesA˙={α˙x1,α˙x2,…,α˙xn}∈the generalized IVIF set andB˙={β˙x1,β˙x2,…,β˙xn}∈the generalized IVIF set, the sample covariance of the generalized IVIF variablesA˙andB˙can be represented by(18)COV(A˙,B˙)=1n−1∑i=1nd(α˙xi,E(A˙))d(β˙xi,E(B˙))Given the generalized IVIF variablesA˙,B˙,andC˙,we obtain(1)D(A˙+r˙)=D(A˙),wherer˙is a generalized IVIF number;D(λA˙)=λ2D(A˙);COV(A˙,B˙)=COV(B˙,A˙);ifA˙=B˙, thenCOV(A˙,B˙)=D(A˙)=D(B˙),whereA˙=B˙indicates that they share the same range;COV(A˙+B˙,C˙)=COV(A˙,C˙)+COV(B˙,C˙);COV(λA˙,B˙)=λCOV(A˙,B˙);andCOV(A˙+λr˙,B˙+λs˙)=COV(A˙,B˙),wherer˙,s˙are two generalized IVIF numbers.The sample covariance matrix of generalized IVIF variables is proposed in Definition 14 after the concept of covariance is provided.Definition 14LetA˙1,A˙2,…,A˙mbe m generalized IVIF variables. We call C = (cij)m × mthe sample covariance matrix ofA˙j(j=1,2,…,m), wherecij=COV(A˙i,A˙j).By combining Definition 14 with properties (5) and (6) in Proposition 1, we obtain the following corollary, which plays a significant role in the IVIF-PCA model that is proposed in Section 4:Corollary 1Given m generalized IVIF variablesA˙1,A˙2,…,A˙m, the variance of their linear combinationsA˙=λ1A˙1+λ2A˙2+⋯+λmA˙mcan be denoted by(19)D(A˙)=COV(A˙,A˙)=COV(λ1A˙1+λ2A˙2+⋯+λmA˙m,λ1A˙1+λ2A˙2+⋯+λmA˙m)=(λ1,λ2,…,λm)(COV(A˙1,A˙1)COV(A˙1,A˙2)⋯COV(A˙1,A˙n)COV(A˙2,A˙1)COV(A˙2,A˙2)⋯COV(A˙2,A˙n)⋮⋮⋱⋮COV(A˙n,A˙1)COV(A˙n,A˙2)⋯COV(A˙n,A˙n))×(λ1λ2⋮λm)=λTCλ.whereCis the covariance matrix ofA˙1,A˙2,…,A˙m.Based on the new concepts presented in Section 3, we derive the IVIF-PCA algorithm in Section 4.1, which is a new PCA algorithm for IVIF information. Several properties of IVIF-PCA are discussed in Section 4.2. To ensure that the final assessment information appears in the form of IVIF numbers, a transformation method is proposed in Section 4.3.Given m IVIF variablesA˙1,A˙2,…,A˙m,which are similar to the traditional PCA case, the kth PCY˙k(k=1,2,…,m)is a linear combination ofA˙1,A˙2,…,A˙m, (i.e.,Y˙k=A˙ek=∑j=1mejkA˙j), whereA˙=(A˙1,A˙2,…,A˙m), andek=(e1k,e2k,…,emk)Tsubject toekTek=1andekTel=0,∀l≠k.According to Corollary 1, the variation (variance) ofY˙kcan be denoted by(20)D(Y˙k)=COV(Y˙k,Y˙k)=ekTCek.where C represents the covariance matrix ofA˙1,A˙2,…,A˙m.The following derivation is the same derivation for a traditional PCA; i.e., we search for m orthonormalized vectors e1, e2, …, emthat maximize∑k=1mD(Y˙k)withD(Y˙1)≥D(Y˙2)≥⋯≥D(Y˙m)by the following optimization problem:(21)max∑k=1mekTCek,s.t.{ekTek=1,ekTel=0,e1TCe1≥e2TCe2≥⋯≥emTCem,l=1,2,…,m,l≠k.The optimal solution, e1, e2, …, em, of Eq. (21) are the eigenvectors of C that correspond to the eigenvalues ɛ1 ≥ ɛ2 ≥ ⋅⋅⋅ ≥ ɛm. The derivation of the PC coefficients is transformed into the eigendecomposition of the covariance matrix. With e1, e2, …, em, we obtain the PCsY˙1,Y˙2,…,Y˙m. The first p(p ≤ m) PCsY˙1,Y˙2,…,Y˙pare expected to maximize the total variance to represent the original information that is conveyed byA˙1,A˙2,…,A˙m.We can select the first p PCsY˙1,Y˙2,…,Y˙p, whose cumulative contribution rate (CCR) is greater than a chosen percentage. For clarity, the explanation of why we use the CCR to determine the number of reserved PCs is provided in Section 4.2. The previous analysis can be summarized in the following steps:Step 1:Obtain the sample matrix ofA˙=(A˙1,A˙2,…,A˙m),which can be denoted by(22)A˙^=(A˙1,A˙2,…,A˙m)=(α˙ij)n×m=(α˙11α˙12⋯α˙1mα˙21α˙22⋯α˙2m⋮⋮⋱⋮α˙n1α˙n2⋯α˙nm),whereA˙j=(α˙1j,α˙2j,…,α˙nj)Trepresents the range or observations of the jth IVIF variableA˙j.Compute the covariance matrix C ofA˙according to Eqs. (17) and (18).Eigendecompose C for the orthonormalized eigenvectors e1, e2, …, emand the eigenvalues ɛ1 ≥ ɛ2 ≥ ⋅⋅⋅ ≥ ɛm(i.e., the PC coefficients and PC variances).According to the requirement of reality (e.g., the CCR is higher than 90 percent), choose the first p PCsY˙1,Y˙2,…,Y˙p,and their corresponding eigenvectors form the matrix(23)e=(e1,e2,…,ep)=(eij)m×p=(e11e12⋯e1pe21e22⋯e2p⋮⋮⋱⋮em1em2⋯emp).Compute the score matrix of PCsY˙1,Y˙2,…,Y˙pwith Definition 8, which we denote by(24)Y˙^=Ae˙^=(Y˙1,Y˙2,…,Y˙p)=(y˙ik)n×p=(y˙11y˙12⋯y˙1py˙21y˙22⋯y˙2p⋮⋮⋱⋮y˙n1y˙n2⋯y˙np),whereY˙k=(y˙1k,y˙2k,…,y˙nk)Trepresents the score vector of the PCY˙k(k=1,2,…,p),andy˙ik=∑j=1mα˙ijejk(i=1,2,…,n;k=1,2,…,p)is the linear combination of m IVIF numbers.Given m IVIF variablesA˙j(j=1,2,…,m),the PCsY˙k(k=1,2,…,m)derived by IVIF-PCA exhibit the following properties:Proposition 2A˙j=∑k=1mejkY˙k.Let e = (e1, e2, …, em),Y˙=(Y˙1,Y˙2,…,Y˙m),andA˙=(A˙1,A˙2,…,A˙m).BecauseY˙=A˙eandeTe=1,we obtainA˙=Y˙eT.Thus,A˙j=Y˙ejT=∑k=1mejkY˙k.□D(Y˙k)=ɛk.D(Y˙k)=ekTCek=ekTɛkek=ɛkekTek=ɛk.□COV(Y˙k,Y˙l)=0(k=1,2,…,m;l=1,2,…,m),if k ≠ l.COV(Y˙k,Y˙l)=ekTCel=ekTɛlel=ɛlekTek=0.□∑j=1mD(A˙j)=∑k=1mD(Y˙k).∑j=1mD(A˙j)=∑k=1mCOV(A˙j,A˙j)=∑k=1mCOV(∑k=1mejkY˙k,∑k=1mejkY˙k)=∑j=1m∑k=1mejk2COV(Y˙k,Y˙k)=∑k=1mD(Y˙k)∑j=1mejk2=∑k=1mD(Y˙k).□Note that if the sum of the elements of the eigenvector is not 1, the PCs in Eq. (24) may no longer be IVIF numbers. We provide an example to illustrate this condition. Given the IVIF variablesA˙1andA˙2,the first PC isY˙1=e11A˙1+e21A˙2,wheree112+e212=1.If e11 = 0.50, and e21 = 0.87, thenY˙1=0.50A˙1+0.87A˙2.Suppose that the first observations ofA˙1andA˙2areα˙11=([0.3,0.4],[0.5,0.6])andα˙21=([0.6,0.7],[0.2,0.3]), respectively. Subsequently, the first score ofY˙1isy˙11=0.50α˙11+0.87α˙21=([0.67,0.81],[0.42,0.56]). We find that 0.81 + 0.56 = 1.37 > 1; thus,y˙11is not an IVIF number. To construct a better interpretation of the PC scores and facilitate the information aggregation with the operators, we create the global “translation” and “scaling” of the PC scores and ensure that the final information is denoted by the IVIF number.Suppose we obtain the score matrix,Y˙^=(y˙ik)n×p,of the PCs. Lety˙ik=(μ˙ik,v˙ik)=([μ˙ikL,μ˙ikU],[v˙ikL,v˙ikU]).Step 1:Translation. For the kth (k = 1, 2, …, p) column of the score matrixY˙^, letsk=min{μ˙ikL,v˙ikL}(i=1,2,…,n).Translate each element iny˙ikby skand obtainy⌢ik=([μ˙ikL−sk,μ˙ikU−sk],[v˙ikL−sk,v˙ikU−sk])=([μ⌢ikL,μ⌢ikU],[v⌢ikL,v⌢ikU]).We denote the translated score matrix asy⌢=(y⌢ik)n×p.Scaling. For the kth k(k = 1, 2, …, p) column of the translated score matrixy⌢, letlk=max{μ⌢ikU+v⌢ikU},and l = max {lk}(k = 1, 2, …, p). If l > 1, reduce each element in the matrix l times and obtain the new elementy˜ik=([μ⌢ikL/l,μ⌢ikU/l],[v⌢ikL/l,v⌢ikU/l])=([μ˜ikL,μ˜ikU],[v˜ikL,v˜ikU]).If l ≤ 1, we do not perform the “scaling” of the elements in the matrix. After scaling, we denote the obtained score matrix asY˜=(y˜ik)n×p, wherey˜ikis an IVIF number.Each line of the matrix can be regarded as a sample of the variables. When the elements in the matrix consist of interval numbers, Cazes et al. (1997) regarded each line as a hyperrectangle in Euclidean space. Similarly, when the elements are IVIF numbers, we can use two hyperrectangles to represent the information contained in each sample. Thus, the previous transformation procedure can be illustrated from a geometric perspective. We visualize the transformation procedure in Fig. 1for a case in which the dimensionality is two. A dimensionality of two denotes that two PCs will be considered.We transform each PCY˙k(k=1,2,…,p)byY˙k*=(Y˙k−s˙k)/l, wheres˙k=([sk,sk],[sk,sk]).According to property (2) in Proposition 1, we obtainD(Y˙k*)=D(Y˙k)/l2; however, the transformation primarily focuses on all samples. Each sample experiences the same transformation. Therefore, the transformation does not change the relative positions of the samples and does not influence the comparative information among the PC scores. From properties (6) and (7), we ascertain thatCOV(Y˙k*,Y˙l*)=0(k≠l).This finding indicates that the PCs remain independent after the transformation, which is crucial to the application of the operators in the information aggregation.In this section, we provide a brief description of the CMALGDM problem. We then substitute the original variables (attributes or DMs) with their PCs in the IVIF-PCA method and use the operators to correctly aggregate the information. We consider the weights of the PCs according to their contributions. The decision-making steps are provided at the end of this section.A CMALGDM problem involves finding the best alternative(s) from all feasible choices or obtaining rankings for all alternatives based on the information provided by a group of DMs. We suppose that (a) D = {d1, d2, …, ds}(s ≥ 20) represents the DM set, (b) X = {x1, x2, …, xm} indicates the alternative set, and (c) U = {u1, u2, …, un} is the attribute set. LetR˜^j=(r˜ikj)m×n(j=1,2,…,s)be the evaluation information matrix (decision matrix) of the jthj DM, wherer˜ikj=(μ˜ikj,v˜ikj)represents the IVIF evaluation information of the DM dj∈ D against the attribute uk∈ U of the alternative xi∈ X. The CMALGDM information can be represented by the s decision matrices. We aggregate each alternative's evaluation information using the following two steps: (a) aggregate the alternative's attribute informationu˜in each decision matrix and (b) aggregate the alternative's DM informationd˜. The aggregation procedure is illustrated in Fig. 2, where f is the symbol of the operator, and the asterisks represent the IVIF evaluation information.To aggregate the index information with the traditional operators, we need to ensure that the indexes are independent. In the following section, we transform the attributes and the DMs into several independent synthetic variables using the IVIF-PCA model proposed in Section 4.To fully utilize the evaluation information of the DMs, we do not distinguish between the DMs and the alternatives but instead combine all of the evaluated values as samples of the attributes. We include all of the decision information in the matrixR˜^=(r˜ikj)(m•s)×n(i = 1, 2, …, m; j = 1, 2, …, s; k = 1, 2, …, n),R˜^=(R˜^1⋮R˜^s)=((r˜111⋯r˜1n1⋮⋱⋮r˜m11⋯r˜mn1),…,(r˜11s⋯r˜1ns⋮⋱⋮r˜m1s⋯r˜mns))T.Each line in the matrix can be regarded as a sample of the attributes.Based on the sample matrixR˜^and using the IVIF-PCA model, we obtain the score matrixuY˜=(uy˜ikj)(m•s)×p(i = 1, 2, …, m$; $j = 1, 2, …, s; k = 1, 2, …, p),uY˜=(uY˜1,…,uY˜s)=((uy˜111⋯uy˜1p1⋮⋱⋮uy˜m11⋯uy˜mp1),…,(uy˜11s⋯uy˜1ps⋮⋱⋮uy˜m1s⋯uy˜mps))T.where thesymbol u represents that all of the results are derived from the IVIF-PCA of the attributes, p is the number of reserved PCs,uY˜k(k=1,2,…,p)is the score vector of the PCuY˙k, anduy˜ikjis an IVIF number.After we obtain the score matrixuY˜, which is similar to case A, we do not distinguish between the alternatives and the attribute PCs; instead, we consider all of the combined evaluation information as samples of DMs. We can denote the information matrix,uY˜j=(uy˜ikj)m×p,which is provided by the jthj DM, by the vectorD˜j=(uy˜11j,…,uy˜1pj,…,uy˜m1j,…,uy˜mpj)T.Thus, all of the decision information can be included in a new matrixD˜^=(uy˜ikj)(m•p)×s(i = 1, 2, …, m; j = 1, 2, …, s; k = 1, 2, …, p),D˜^=(D˜1,D˜2,…,D˜s)=(uy˜111…uy˜1p1…uy˜m11…uy˜mp1⋮…⋮…⋮…⋮uy˜11s…uy˜p1s…uy˜m1s…uy˜mps)T.Each line in the matrix can be regarded as a sample of the DMs.Based on the sample matrixD˜^and using the IVIF-PCA model, we obtain the score matrixdY˜=(dy˜ikj)(m⋅p)×q(i = 1, 2, …, m; j = 1, 2, …, q; k = 1, 2, …, p),dY˜=(dY˜1,…,dY˜s)=(dy˜111…dy˜p11…dy˜m11…dy˜mp1⋮…⋮…⋮…⋮dy˜11q…dy˜p1q…dy˜m1q…dy˜mpq)T.whered represents that all of the results are derived from the IVIF-PCA of the DMs, q is the number of reserved PCs,dY˜k(k=1,2,…,q)is the score vector of the PCdY˙k, anddy˜ikjis an IVIF number. Most of the evaluation information of the alternatives is contained in the score matrixdY˜.The interpretation capacity of the original variable information differs for each PC. To appropriately aggregate the alternative information, we consider the weights of the PCs in the aggregation procedure. Suppose we obtain p PCs,uY˙1,…,uY˙p,of the attributes, and their corresponding eigenvalues areuɛ1,uɛ2, …,uɛpin order. The weight ofuY˙k(k = 1, 2, …, p) can be denoted by(26)wk=uɛk∑i=1puɛi(k=1,2,…,p).We denote the weight vector of the attribute PCs as w = (w1, w2, …, wp). Similarly, suppose we obtain q PCs,dY˙1,…,dY˙q,of the DMs, and their corresponding eigenvalues aredɛ1,dɛ2, …,dɛqin order. The weight ofdY˙k(k=1,2,…,q)can be denoted by(27)ωk=dɛk∑i=1pdɛi(k=1,2,…,q).We denote the weight vector of the DM PCs asω= (ω1, ω2, …, ωq).We can aggregate the information about the alternatives with the traditional operators as shown in the aggregation procedure in Fig. 3, where “(1)” represents the matrixdY˜,uY˙1,…,uY˙prepresent the attribute PCs,dY˙1,…,dY˙qrepresent the DM PCs,u˜represents the aggregated information of the attribute PCs,d˜represents the aggregated information of the DM PCs, f is the symbol of the operator, and the asterisk represents the IVIF number.We provide the specific decision-making steps for the CMALGDM problem below.Step 1:Collect the decision matrixR˜^j( j = 1, 2, …, s) of the DMs.Using the IVIF-PCA model, we obtain the score matrix,uY˜, of the attribute PCs. From Eq. (26), we obtain the weight vector w = (w1, w2, …, wp) of the attribute PCs.Based onuY˜and using the IVIF-PCA model, we obtain the score matrixdY˜of the DM PCs. From Eq. (27), we obtain the weight vectorω= (ω1, ω2, …, ωq) of the DM PCs.With the operators described in Definition 4, we utilize the IIFWA operator or the IIFWG operator to aggregate the information about the alternatives indY˜as shown in Fig. 3.We compare theinformation about the aggregated alternatives with the method in Definition 5 and determine the best alternative(s).An actual CMALGDM problem is provided as follows. A department that is responsible for a certain river basin in China plans to build a large hydropower station. To ensure scientific decision-making, the department invites 20 DMs dj(j = 1, 2, …, 20), including government departments, environmental experts, engineering experts, regional economy experts and public representatives, to evaluate 5 preliminary design alternatives xi(i = 1, 2, 3, 4, 5) during the preliminary stage of the project. In the evaluation stage, as a numerical example, we consider 7 attributes for each alternative uk(k = 1, 2, …, 7), which are described in Ren (2012). These attributes include the duration of the project's function u1, the level of the project's function u2, the improvement of the regional economy u3, the flood prevention capability u4, the degree of environmental damage u5, the degree of satisfaction of the compensation package u6, and public security u7. In our example, all of the DMs employ IVIF numbers to evaluate the attributes of each alternative. The decision information can be represented by the matrixR˜^j=(r˜ikj)5×7(j=1,2,…,20), which is shown in Table 1. Note that in a real scenario, more than 7 attributes should be considered, and the number of DMs is very large; however, we use 7 attributes and 20 DMs (the least number of DMs for a CMALGDM problem) to illustrate the decision-making process.Step 1:Include all of the decision information in the matrixR˜^=(r˜ikj)100×7(i=1,2,…,5;j=1,2,…,7;k=1,2,…,20).According to Eqs. (17) and (18), we obtain the covariance matrixuC of the attributes as shown in Table 2.With the IVIF-PCA model proposed in Section 4.1, we obtain the variances (eigenvalues) of the attribute PCs (Table 3); their corresponding CCRs are also listed. The CCRs of the first 3 PCs are higher than 95 percent, which sufficiently expresses the majority of the information that is contained in the original attributes. The coefficients of the first 3 PCs are provided in Table 4. Using Eqs. (6) and (7), we obtain the score matrixuY˙^ofuY˙1,uY˙2,anduY˙3, which is presented in Table 5.Using the transformation method proposed in Section 4.3, we translate the columns of the score matrix with s1 = −1.77, s2 = −1.32, and s3 = −0.07. We reduce all of the scores in the new matrix by l = 3.92 and obtain the transformed score matrixuY˜as shown in Table 6.We obtain a transformation ofuY˜and the matrixD˜^. Each line inD˜^represents a sample of the DMs as shown in Table 7. The covariance matrixdC of the DMs is shown in Table 8.Similarly, we obtain the variances and CCRs of the DM PCs with the IVIF-PCA model as shown in Table 9. The first 9 PCs with their coefficients are listed in Table 10. The score matrixdY˙^is presented in Table 11.Using the transformation method, we translate the columns of the score matrix using s1 = −0.16, s2 = −0.04, s3 = −0.03, s4 = −0.09, s5 = −0.05, s6 = −0.04, s7 = −0.07, s8 = −0.14, and s9 = −0.39. We reduce all of the scores in the new matrix by l = 1.10 and obtain the transformed score matrixdY˜as shown in Table 12.By computing the weight vector of the attribute PCs using Eq. (26), we obtain w = (0.672, 0.203, 0.125); then, by computing the weight vector of the DM PCs with Eq. (27), we obtainω= (0.292, 0.224, 0.140, 0.095, 0.074, 0.058, 0.050, 0.035, 0.032). Using the information aggregation procedure shown in Fig. 3, we utilize the IIFWA operator and the IIFWG operator to obtain the overall evaluation information of each alternative. Furthermore, we obtain scores of the alternatives using the score function. The results are shown in Table 13. Using the IIFWA operator, we obtain x2≻x5≻x3≻x1≻x4; with the IIFWG operator, we have x2≻x5≻x1≻x3≻x4. Although there is a slight difference in the order of the alternatives from the two operators, the optimal alternative is x2.This sectioncomprises three main parts. We first compare the IVIF-PCA method with the interval PCA based method, and we then give the decision results for the case in which we do not consider the independence of the attributes as well as that of the DMs. Finally, an optimal alternative determination method is given.This paper proposed the IVIF-PCA method, which developed the PCA method for IVIF information. According to Guo and Li (2010), both IF numbers and IVIF numbers can be transformed into equivalent interval numbers. Guo and Li (2010) noted that an IF number αx= (μA(x), vA(x)) can be transformed into the intervalα¯x=[μA(x),1−vA(x)], and the IVIF numberα˜=([a,b],[c,d])can be written asα˜¯=[a,1−c]. Liu, Shen, Chen, Chen, and Wang (2014) also explained why this transformation is reasonable. Hence, we will first transform the IVIF information into interval information (shown in Table 14) and then use the interval PCA on it to determine the final decision-making result.Research about PCA for interval numbers is abundant because numerous scholars have made significant contributions in this area. Cazes et al. (1997) first explained the concepts of the V-PCA (Vertices PCA) and C-PCA (Centers PCA). Lauro and Palumbo (2000), D'Urso and Giordani (2004), Palumbo and Lauro (2003), Lauro, Verde, and Irpino (2008, chap. 15), Gioia and Lauro (2006), Hladik, Daney, and Tsigaridas (2010), Guo and Li (2007), and Douzal-Chouakria et al. (2011) also studied this topic, which greatly promoted the development of interval PCA methods. In this paper, we choose the error theory-based PCA (ET-PCA) model proposed by Guo and Li (2007) for comparison. We select this method primarily because the concept of interval number analysis is derived from error analysis and experts’ uncertain judgments (Guo and Li, 2007). The membership or non-membership interval numbers that we discussed in this paper are obtained from uncertain judgments of the DMs. It means that the interval numbers are caused by error. Hence, it is appropriate to investigate the PCA of interval numbers from the perspective of error theory.We do not discuss the ET-PCA model in detail; readers may refer to Guo and Li (2007) and Liu, Chen, Shen, Sun, and Xu (2013) for more information. The main idea of ET-PCA can be summarized as follows. Given a set of interval samples, each interval [a, b] can be written in two parts: the midpoint part (a + b)/2 and the radii part (b − a)/2. The ET-PCA states that to obtain the PCA of the intervals, we should obtain the PCA of the midpoints of the interval sample; the final result can then be obtained by adding the error (i.e., the radius). The detailed computation is shown in Liu et al. (2013). Like the CMALGDM method using IVIF-PCA that was proposed in Section 5, the utilization of the ET-PCA to handle decision-making problems can also be summarized in two steps: (1) the ET-PCA for the attributes; and (2) the ET-PCA for the DMs. The general process is similar to that described in Section 5.2. In step 1, we obtain the eigenvalues and CCRs of the attribute PCsuY¯i(i=1,2,…,7), which are shown in Table 15. The coefficients of the 3 selected PCs are shown in Table 16, and the score matrixuY¯is shown in Table 17. In step 2, we obtain the corresponding information of the DM PCs, which is shown in Tables 18–20.With interval algebra, which is reviewed in Gioia and Lauro (2006), we know that given n intervals [a1, b1], [a2, b2], …, [an, bn] as well as their weights wi≥ 0(i = 1, 2, …, n), the weighted average of these intervals can be denoted by f([a1, b1], [a2, b2], …, [an, bn])=[∑i=1nwiai,∑i=1nwibi]. Hence, the overall evaluation of the 5 alternatives can be derived as shown in Table 21. Moreover, to compare these intervals, we introduce the possibility degree formula proposed by Xu (2001). The possibility degree that intervala¯=[aL,aU]is greater thanb¯=[bL,bU]can be expressed byp(a≥b)=max{1−max{bU−aLl(a)+l(b),0},0}, where l(a) = aU− aLand l(b) = bU− bL. Given n intervalsa¯i(i=1,2,…,n), from the pairwise comparison, we can obtain the possibility degree matrix, which is denoted byP=(p11p12…p1np21p22…p2n⋮⋮⋱⋮pn1pn2…pnn)The importanceof the intervala¯ican be denoted bywi=∑j=1npij+n/2−1n(n−1),(i = 1, 2, …, n). Hence, the possibility degree matrix of the 5 alternatives is obtained (Table 22). The importance vector of the alternative is w = (0.129, 0.251, 0.325, 0.249, 0.171); thus, the ranking of the 5 alternatives should be x3≻x2≻x4≻x5≻x1, which is significantly different from the ranking x2≻x5≻x3≻x1≻x4 that was derived from the IVIF-PCA method. We attribute this difference to the information loss in the ET-PCA of the DMs; in fact, the CCR of the first 9 PCs is only 85 percent (the percentage is more than 95 percent in the IVIF-PCA case). We also find some eigenvalues that are less than 0, which means that the performance of the ET-PCA when it is implemented on the DMs is not as good as the IVIF-PCA case. To invalidate this explanation, assume that we omit the step of the ET-PCA on the DMs; namely, we directly perform the interval information aggregation based on the attribute PC scores listed in Table 17. The final overall interval evaluation information and the importance are listed in Table 23. In this case, the ranking of the 5 alternatives is x2≻x4≻x3≻x1≻x5, which is substantially different from the results of the two-step ET-PCA but is similar to the results of the IIFWA operator in the two-step IVIF-PCA (only x4 and x5 switch positions). Although the rank varies more than in the IIFWG case, x2 is still the optimal solution with both methods.In conclusion, we believe that if we can obtain sufficient information during the ET-PCA of the DMs, the difference between these two methods may not be significant.We obtained the optimal alternative for the CMALGDM problem using the proposed IVIF-PCA-based decision-making method. During the procedure, we did not aggregate the attributes or DM information until the attributes or the DMs were transformed into several independent variables. Will the ranking order be affected if we ignore the dependence between the attributes or DMs and only use the operators to aggregate the evaluation information of the alternatives in Table 1? Using the aggregation procedure shown in Fig. 2, we obtain the overall evaluation information about each alternative using the IIFWA operator. We also obtain scores of the alternatives with the score function, which are shown in Table 24. With the IIFWA operator, we obtain the alternative ranking order x2≻x5≻x1≻x3≻x4, which differs slightly from the ranking order that was obtained from the IVIF-PCA-based method. However, in the IIFWG case, we obtained the ranking order x1≻x5≻x3≻x4≻x2, which varies significantly from the ranking order that was derived from the IVIF-PCA based method. Alternative x2, which is the optimal alternative in the IVIF-PCA-based method case, becomes the worst alternative. It is interesting that using different operators on the same data set results in completely opposite results. Generally, the alternative rankings that come from the IIFWA and IIFWG operators should be nearly the same when the scale of the sample set is not large (e.g., each alternative only has 5 attributes that are evaluated by only one DM) and the attributes are independent of each other. However, in the cases in this section, neither of these assumptions is satisfied. Our example uses 7 attributes and 20 DMs and neglects the influence between the attributes and the DMs. Thus, the final performances of the two operators were affected significantly. Therefore, it is essential to consider the dependences of the attributes and the DMs to prevent distortion of the decision results.The goal of decision-making in the real world is typically to find the optimal alternative from a group of alternatives. A large number of decision-making methods have been proposed to rank alternatives. In the real world, to make the result more accurate or less biased, we would not utilize a single decision-making method; we would consider several appropriate approaches and compare their results. A simple but reasonable way to select the optimal alternative is to make the decision based on the “majority principle”. For example, suppose that we adopt 3 methods to address our decision-making problem, 2 of which indicate that x2 is the best alternative, while only one indicates that x1 is the best. In this situation, we would choose x2 as the optimal alternative. However, before using the “majority principle”, we should ensure that all of the approaches that we selected are appropriate. For example, to address the CMALGDM problem in this paper while considering the dependences between the attributes and the DMs, we could use both the IVIF-PCA and the interval PCA based methods and then select the optimal alternative according to the “majority principle”. However, methods that directly use the information aggregation operators, such as the IIFWA and IIFWG operators, should never be taken into account because they are not designed to handle dependences.

@&#CONCLUSIONS@&#
Due to the complexity of the CMALGDM problem, alternatives are usuallydescribed by multiple attributes that exhibit a high degree of interdependent or interactive characteristics. Because DMs may come from different interest groups, the independence between these DM preferences in the same interest group may be violated. Conventional information aggregation operators are proposed based on the independence axiom; as a result, these operators are not suitable for directly aggregating alternative evaluation information in the CMALGDM problem. Several scholars have proposed new operators that are based on the fuzzy measure to solve the independent problem. However, the primary disadvantage of these operators is that the number of fuzzy measures increases exponentially with an increase in the number of attributes or DMs. As a result, these operators cannot be conveniently applied to solve the CMALGDM problem. Based on the traditional PCA model, we developed the concept of the IVIF variable and proposed the IVIF-PCA model. We also developed a decision-making method for the CMALGDM problem by transforming the attributes and the DMs into several independent variables and aggregating the attribute information and DM information of the alternatives using traditional operators. We obtained the optimal alternative(s) by comparing the overall evaluation information of the alternatives. This method not only reduces the complexity of the aggregation procedure but also improves the reliability of the aggregation results.