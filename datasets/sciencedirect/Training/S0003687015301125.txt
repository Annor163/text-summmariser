@&#MAIN-TITLE@&#
Driving while using a smartphone-based mobility application: Evaluating the impact of three multi-choice user interfaces on visual-manual distraction

@&#HIGHLIGHTS@&#
The performance metric is tested against two baseline methods (between- and within-trial).Multi-step filtering approach performed poorly due to the high precision required.Even on a short and ordered list, kinetic scrolling leads to high visual demand.Multi-step filtering approach is worth pursuing with better graphic components.

@&#KEYPHRASES@&#
Driving simulator,Multi-touch application,Visual-manual distraction,

@&#ABSTRACT@&#
Innovative in-car applications provided on smartphones can deliver real-time alternative mobility choices and subsequently generate visual-manual demand. Prior studies have found that multi-touch gestures such as kinetic scrolling are problematic in this respect. In this study we evaluate three prototype tasks which can be found in common mobile interaction use-cases. In a repeated-measures design, 29 participants interacted with the prototypes in a car-following task within a driving simulator environment. Task completion, driving performance and eye gaze have been analysed. We found that the slider widget used in the filtering task was too demanding and led to poor performance, while kinetic scrolling generated a comparable amount of visual distraction despite it requiring a lower degree of finger pointing accuracy. We discuss how to improve continuous list browsing in a dual-task context.

@&#INTRODUCTION@&#
Advances in the area of digital mobility technologies (Fishman, 2012) have led to an increasing number of displays and interactive systems within cars. Although the safety risk of using mobile devices while driving is well documented (Alm and Nilsson, 1995; Young et al., 2007; Treffner and Barrett, 2004; Horberry et al., 2006). Innovative applications targeting In-Vehicle Infotainment Systems (IVIS) are likely to place an increasingly high workload on the driver. Despite the trend towards the integration of IVIS specific devices into high-end car models, smartphones remain a natural and mainstream method of delivering new mobility and trip-centric applications. An example of these new mobility-centric services are the applications being developed within the i-Gear project (McCall and Koenig, 2012; McCall et al., 2013). This project intends to provide drivers with real-time alternative mobility choices in order to avoid traffic jams. For instance, two use-cases are envisioned: the possibility to share a ride with a friend or to engage in an alternative activity, which will consume a certain amount of time but will steer the driver away from the peak hours or the congested roads. The ultimate goal of this application is to improve the traffic situation in cities with a high number of commuters.One major challenge is that providing the driver with more choices displayed on a smartphone will increase visual-manual distraction; as it requires them to interact with visual content and to provide manual inputs. Such an increase in visual-manual distraction while driving is very likely to reduce driving performance and safety (Green, 2004). Visual-manual interactions on modern mobile devices are generally performed through multi-touch gesture inputs on a graphical display (i.e., any finger gestures used on a hand-held or IVIS-specific device); this induces visual-manual distraction and needs to be explored more thoroughly. While general behavioural laws (Fitts, 1954; Hick, 1952) can provide guidance for interface design, specific types of gesture interactions or visual presentations may impact upon the driver's performance and this needs to be empirically assessed.Different methods for interacting with list-based applications have been assessed. For instance, Kujala (Kujala, 2009) studied the effect of grid and linear presentations of icon lists on driving performance and gaze behaviour. They found that the linear list layout results in better visual search patterns and as a consequence should be safer. Scrolling mode was also assessed by (Lasch and Kujala, 2012; Kujala, 2013). In their work, the authors compared button, swipe gesture and kinetic scrolling for grid (Lasch and Kujala, 2012) and linear lists (Kujala, 2013). While button and swipe gestures (i.e. unidirectional finger movement to trigger an action) allow the user to browse through pages with a fixed-number of items, kinetic scrolling allows for a more continuous browsing (i.e. dragging the view-port with finger movement) including scrolling rate control. Both studies concluded that kinetic scrolling performed generally worse and was more distracting than swipe gesture and touch-buttons.Rydström et al. (Rydström et al., 2012) tested multiple widget types and two types of input methods (touch-screen or physical rotary control). They found that while both types of input method affected longitudinal control, touch-screen based interactions impacted lateral control to a greater extent. Moreover, the rotary control impacted on the performance to a lesser extent (better control of the vehicle and fewer off-road glances) for continuous adjustment tasks (e.g. radio, volume or list searching). One possible explanation of these results is that with a rotary control drivers don't have to physically reach the screen and/or rely on poor screen resolution for discriminating between targets. According to Kim and Song (Kim and Song, 2014) gesture-based interactions are more often worse than their classic touch button counterparts when used within an in-car set-up. Only the panning gesture was found to have a small impact on driving performance. In contrast, the flicking gesture (kinetic scrolling) or pinching were found to be very difficult to control. Similarly, Young et al. (Young et al., 2012) found that continuous use of kinetic scrolling when searching for music on an MP3 player significantly impaired driving performance. Finally, Kujala et al. (Kujala et al., 2013) concluded that text entry and kinetic scrolling are major sources of visual-manual distraction in the car.The body of evidence concerning multi-touch gestures in general and kinetic scrolling in particular may be the opposite of what would be expected. Indeed, multi-touch gestures are supposed to require less accuracy in finger pointing than touch button interfaces and hence should be less difficult to use. In theory they should also reduce distraction. However, the opposite appears to be true. One possible explanation is that kinetic scrolling requires continuous visual-manual monitoring thereby decreasing the user's ability to interrupt the secondary task (for instance, as opposed to driving) and as a consequence this results in less safe behaviours (Chiang et al., 2004; Noy et al., 2004). These results emphasise the central role played by the interruptibility of a secondary task in the safe and effective completion of concurrent tasks (Burns et al., 2010). Indeed, the possibility to chunk a secondary task into multiple interaction steps allows for it to be interrupted and resumed when the primary task (in this case driving) necessitates it. Multi-touch gestures, as they require continuous visual-manual control may impair the ability of the user to interrupt the execution of the secondary task.As pointed out by (Kujala, 2013) a page-per-page technique could improve the interruptibility of list browsing tasks; although kinetic scrolling might still be a better fit for long and ordered item lists. Indeed, kinetic scrolling allows users to skip large chunks of the list with only one movement, while the pager technique requires users to go through each page with a swipe or touch gesture. Additionally, as repetitive multi-touch gestures may cause fatigue in the user's wrist (Kim and Song, 2014) it is necessary to reduce the number of occurrences for these types of interactions. These results confirm that the way a user browses lists of items on multi-touch devices could still be improved. In particular when the user may want to browse a long list by skipping non-relevant items.In this work a driving simulator is used to assess three prototype tasks based on two envisioned use cases for the proposed i-Gear applications (McCall and Koenig, 2012; McCall et al., 2013). As we stated earlier, we envisioned two use-cases: one consisting in accepting or not sharing a ride with a friend, and the second one, consisting in selecting an alternative activity on the basis of the required duration of those activities. In this paper we want to assess the impact on driver distraction of those two use-cases if they were implemented in real-time and used while driving. We assess the two use-cases that are envisioned for the final application: As the ”Alternative activities” use-case is potentially the most complex one, it is important to quantify its impact on drivers’ distraction first against the ”car sharing” use-case and then in further details under different implementations.More precisely, we test three prototype tasks: the Help task implemented the ”car sharing” use-case while the Browse and Filter ones are two different implementations of the ”alternative activities” use-case (see Table 1). We present two implementations of the ”alternative activities” use-case because it is potentially more disruptive and the flow of interactions could be organised in a one- or two-step way. To assess the impact of these prototype tasks on the driver's performance, three different types of metrics are used: the application usage performance (error rate and completion time), the telemetry of the car (lateral and longitudinal control) and gaze behaviour (number of off-the-road fixations and their durations). These performance metrics are compared to a baseline with two different methods: (1) between-trial (with and without application trials) and (2) within-trial (when dual-tasking and when driving only).

@&#CONCLUSIONS@&#
In this study we tested three prototype tasks that implemented two possible use-cases for a mobility application. We found that it is not strictly necessary to perform a between-trial baseline comparison, provided that the effects of the experimental manipulations are large enough to be detected in the within-trial comparison. When comparing the different tasks to each other, we found that the Filter task was the most demanding in terms of visual-manual control. Further analysis showed that most of the time spent looking at the device was due to the filter step requiring the control of a slider widget. The amount of gaze duration toward the device during the filter step was comparable with one of the whole Browse task. While manipulating a slider is demanding in terms of visual-manual control (i.e., small target manipulation), it is interesting to note that the kinetic scrolling search performed in a comparable way, reproducing former results from literature on list browsing. The results suggest that it is important to better understand and improve browsing of long documents (lists or maps) and how to design multi-step interactions.