@&#MAIN-TITLE@&#
Multi-sensor distributed fusion filtering for networked systems with different delay and loss rates

@&#HIGHLIGHTS@&#
A distributed fusion filter is designed with time delays and packet losses.Filtering error cross-covariance matrix between any two local filters is derived.The steady-state property of the distributed fusion filter is analyzed.A sufficient condition for existence of steady-state fusion filter is given.

@&#KEYPHRASES@&#
Multi-sensor,Packet loss,Random delay,Distributed fusion filter,Networked system,

@&#ABSTRACT@&#
This paper mainly focuses on the multi-sensor distributed fusion estimation problem for networked systems with time delays and packet losses. Measurements of individual sensors are transmitted to local processors over different communication channels with different random delay and packet loss rates. Several groups of Bernoulli distributed random variables are employed to depict the phenomena of different time delays and packet losses. Based on received measurements of individual sensors, local processors produce local estimates that have been developed in a new recent literature. Then local estimates are transmitted to the fusion center over a perfect connection, where a distributed fusion filter is obtained by using the well-known matrix-weighted fusion estimation algorithm in the linear minimum variance sense. The filtering error cross-covariance matrices between any two local filters are derived. The steady-state property of the proposed distributed fusion filter is analyzed. A simulation example verifies the effectiveness of the algorithm.

@&#INTRODUCTION@&#
During the past decades, the research on networked systems and sensor networks has attracted much attention since they make resources convenient for sharing and have broad applications including target tracking, signal processing, multiple robots, and so on [1–3]. The random delays and packet losses are usually induced by the network congestions during data transmissions of networked systems [4]. Therefore, the design on estimators and controllers for networked systems is challenging [5,6].Several literatures have focused on single sensor systems with packets losses or/and time delays [7–14]. However, the research on multi-sensor systems subject to time delays and losses are not fully reported in the literatures. Multi-sensor information fusion has broad applications in target tracking, navigation and detection since they can fully make use of information from all sensors and overcome the defect of single sensor lying in the limitation of time and space. Thus, the study on multi-sensor information fusion is significant. Distributed fusion estimation plays an important role in information processing for multi-sensor systems. In [15], distributed consensus filters are designed for sensor networks, where each sensor implements the estimate based on the data from neighboring sensors. However, the communication time delays are not taken into account. Since the distributed fusion has better robust and flexibility than the centralized fusion, many results on the distributed fusion estimation have been reported in recent years, including the decentralized filter with the parallel structure [16], the federal Kalman filter [17], the Maximum Likelihood fusion filter [18], the unified optimal linear estimation fusion [19] and distributed fusion weighted by matrices [20]. Several fusion estimation algorithms have been designed for multi-sensor systems with the transmission delays or packet losses in [21–24], where, however, the delays and packet losses are not taken into account simultaneously. In [25–27], distributed and centralized fusion estimators have been respectively designed for packet losses and one-step random delays or variable delays. However, multi-step random delays are not taken into account. Distributed track-to-track fusion on Kalman-type filtering and retrodiction at arbitrary communication rates is also addressed for target tracking in [28,29], where the correlation among local filters is ignored.Recently, a new model to depict the phenomena of multi-step random delays and packet losses during data transmissions in networked systems has been developed and an optimal linear filter has been presented in [30]. In this paper, we will generalize the results for single sensor in [30] to the case of multiple sensors. We will investigate the distributed fusion filtering problem as shown in Fig. 1. Each sensor transmits its measurements to a local processor over imperfect networks which lead to random delays and packet losses. Each local processor produces local estimate based on received measurements from sensor itself and then transmits it to the fusion center over perfect connections without delays and losses. In the fusion center, all local filters are weighted by linear combination to give the fusion state filter. Several groups of Bernoulli distributed random variables with known probabilities are introduced to depict different transmission delay and loss rates from different sensors to local processors. The filtering error cross-covariance matrices between any two local filters are derived, which can be recursively computed with any initial values. Based on the local filters in [30] and the derived filtering error cross-covariance matrices, a distributed fusion filter weighted by matrices is obtained by using the linear minimum variance fusion algorithm [20]. At last, we analyze the steady-state property of the proposed distributed fusion filter. A sufficient condition for the existence of the steady-state fusion filter is given.The rest of this paper is organized as follows. In Section 2, the system model and problem formulation are addressed. In Section 3, the local optimal linear filter is given. In Section 4, the cross-covariance matrices between any two local filters are derived. In Section 5, the stability and steady-state property are analyzed. Section 6 provides an example. Section 7 draws a conclusion.Consider the following discrete time-invariant linear systems with multiple sensors:(1)x(t+1)=Fx(t)+Dw(t)(2)y(i)(t)=C(i)x(t)+v(i)(t),i=1,2,⋯,Lwherex(t)∈Rnis the state,y(i)(t)∈Rmiis the measured output of the ith sensor which will be transmitted to a local processor by networks,w(t)∈Rrandv(i)(t)∈Rmiare the process and measurement noises, respectively. L is the number of sensors, and F, D andC(i)are constant matrices with suitable dimensions.The estimation problem considered is shown in Fig. 1. Suppose that packet losses and random delays exist in data transmissions from individual sensors to local processors. At every time, the packet of each sensor is only sent once in order to avoid the network congestion and only one packet or no packet is available at local processors. The packets received by the ith local processor can be described by the following mathematical model [30]:(3)z(i)(t)=α0(i)(t)y(i)(t)+(1−α0(i)(t)){(1−α0(i)(t−1))α1(i)(t)y(i)(t−1)+[1−(1−α0(i)(t−1))α1(i)(t)]{(1−α0(i)(t−2))(1−α1(i)(t−1))α2(i)(t)y(i)(t−2)+⋯+[1−∏k=0di−2(1−αk(i)(t−di+k+1))αdi−1(i)(t)]∏k=0di−1(1−αk(i)(t−di+k))αdi(i)(t)y(i)(t−di)}⋯}whereαk(i)(t),k=0,1,⋯,di;i=1,2,⋯,Lare mutually uncorrelated Bernoulli distributed random variables with the probabilitiesP{αk(i)(t)=1}=α¯k(i)andP{αk(i)(t)=0}=1−α¯k(i),α¯k(i)∈[0,1]. They are uncorrelated with other random variables.The model (3) describes the phenomena of possible randomdi-step (i=1,⋯,L) delays and packet losses during data transmissions from individual sensors to local processors over the network. In order to explain the model, takingdi=1as an example, then model (3) can be reduced toz(i)(t)=α0(i)(t)y(i)(t)+(1−α0(i)(t))(1−α0(i)(t−1))α1(i)(t)y(i)(t−1). It follows thatz(i)(t)=y(i)(t)ifα0(i)(t)=1, (i.e., received on time);z(i)(t)=y(i)(t−1)ifα0(i)(t)=0,α0(i)(t−1)=0andα1(i)(t)=1, (i.e., one-step delay); andz(i)(t)=0ifα0(i)(t)=0,α0(i)(t−1)=1orα0(i)(t)=0,α1(i)(t)=0, (i.e., packet loss).In this paper, 0 and I denote the zero and identity matrices of suitable dimensions, respectively. Our work is done based on the following assumptions.Assumption 1w(t)andv(i)(t)are correlated white noises with zero mean and variancesQw,Qv(i)=Qv(ii), and cross-covariance matricesS(i)andQv(ij),i≠j, i.e.,(4)E{[w(t1)v(i)(t1)][wT(t2)v(j)T(t2)]}=[QwS(j)S(i)TQv(ij)]δt1t2where E is the mathematical expectation, T is the transpose operator, andδt1t2is the Kronecker delta function.The initial statex(0)is uncorrelated withw(t)andv(i)(t)and satisfies(5)E[x(0)]=μ0,E[(x(0)−μ0)(x(0)−μ0)T]=P0Our objective is to design the distributed fusion filter weighted by matrices in the linear minimum variance sense by the linear combination of the local linear filters from local processors. We first give local linear filters based on the measurement data of individual sensors, then compute the filtering error covariance matrices including auto- and cross-covariance matrices, at last obtain the distributed fusion filter.According to the definition ofαk(i)(t), we have the following results:E[αk(i)(t)]=α¯k(i),E[(αk(i)(t)−α¯k(i))2]=α¯k(i)(1−α¯k(i)),E[αk(i)(t)(1−αk(i)(t))]=0,E[αp(i)(l)αk(i)(t)]=α¯p(i)α¯k(i),l≠torp≠k,E[αp(i)(l)αk(j)(t)]=α¯p(i)α¯k(j),i≠j;i,j=1,⋯,L;k,p=0,⋯,di.In the new recent literature [30], an optimal linear filter has been proposed for single sensor subsystem of (1)–(3). For readability in the latter sections, we give the local filters that are run in local processors in this section.Letθk(i)(t)=[∏j=0k−1(1−αj(i)(t+j))]αk(i)(t+k),k=1,2,⋯,di;i=1,2,⋯,L, withθ0(i)(t)=α0(i)(t), and(6)Yk(i)(t)=θk(i)(t)y(i)(t)+(1−θk(i)(t))Yk+1(i)(t−1),k=1,2,⋯,di−1,Ydi(i)(t)=θdi(i)(t)y(i)(t),i=1,2,⋯,LThen the systems (1)–(3) and (6) can be rewritten as the following form:(7)ς(i)(t+1)=F˜(i)(t)ς(i)(t)+D˜(i)(t)ω(i)(t)(8)z(i)(t)=C˜(i)(t)ς(i)(t)+θ0(i)(t)v(i)(t),i=1,2,⋯,LIt is worth noting that (7)–(8) is a multi-model multi-sensor system, where the augmented statesς(i)(t+1)=[xT(t+1)Y1(i)T(t)Y2(i)T(t)⋯Ydi(i)T(t)]T, noisesω(i)(t)=[wT(t)v(i)T(t)]T, and(9)F˜(i)(t)=[F00⋯0θ1(i)(t)C(i)0(1−θ1(i)(t))Imi⋯0⋮⋮⋮⋱⋮θdi−1(i)(t)C(i)00⋯(1−θdi−1(i)(t))Imiθdi(i)(t)C(i)00⋯0],D˜(i)(t)=[DT0⋯000θ1(i)(t)Imi⋯θdi−1(i)(t)Imiθdi(i)(t)Imi]T,C˜(i)(t)=[θ0(i)(t)C(i)(1−θ0(i)(t))Imi0⋯0]For system (7)–(8), we can obtain the following statistical information:(10)Qω(ij)=E{ω(i)(t1)ω(j)T(t2)}=[QwS(j)S(i)TQv(ij)]δt1t2,S¯(ij)=E{ω(i)(t1)v(j)T(t2)}=[S(j)Qv(ij)]δt1t2whereQω(ii)=Qω(i)and(11)θ¯0(i)=E[θ0(i)(t)]=α¯0(i),θ¯k(i)=E[θk(i)(t)]=∏j=0k−1(1−α¯j(i))α¯k(i),k=1,2,⋯,di;i=1,2,⋯,L,E[(θk(i)(t)−θ¯k(i))2]=θ¯k(i)(1−θ¯k(i)),E[θk(i)(t)θl(i)(t)]=0,k≠l,E[θk(i)(t)θl(i)(j)]=θ¯k(i)θ¯l(i),t≠j;k,l=0,1,⋯,di;i=1,2,⋯,L,E[θk(i)(t)θl(j)(f)]=θ¯k(i)θ¯l(j),i≠j;k,l=0,1,⋯,di.We can also have the following mathematical expectations:(12)F¯(i)=E[F˜(i)(t)],D¯(i)=E[D˜(i)(t)],C¯(i)=E[C˜(i)(t)]which are defined as (9) withθk(i)(t)replaced by their expectationsθ¯k(i).So far, the estimation problem of original system (1)–(3) with random delays and losses has been transformed into that of the system (7)–(8) with stochastic parameters. From the definition of stateς(i)(t)of system (7)–(8), it can be seen that the estimate ofx(t)is just the first n components of the estimate ofς(i)(t). In the sequent sections, we study the local linear filters and cross-covariance matrices for system (7)–(8).Lemma 1(See[30].) For system(7)underAssumptions 1 and 2, the second-order moment matricesh(i)(t)=E[ς(i)(t)ς(i)T(t)]of the augmented statesς(i)(t)are computed by(13)h(i)(t+1)=M(i)(h(i)(t))+Q¯ω(i),i=1,2,⋯,Lwith the initial valuesh(i)(0)=diag(P0+μ0μ0T,0)where the symboldiag(•)denotes a block diagonal matrix.M(i)(h(i)(t))andQ¯ω(i)are given by(14)M(i)(h(i)(t))=F0(i)h(i)(t)F0(i)T+∑k=1diθ¯k(i)F0(i)h(i)(t)Fk(i)T+∑k=1diθ¯k(i)Fk(i)h(i)(t)F0(i)T+∑k=1diθ¯k(i)Fk(i)h(i)(t)Fk(i)T(15)Q¯ω(i)=E[D˜(i)(t)ω(i)(t)ω(i)T(t)D˜(i)T(t)]=D0Qω(i)D0T+∑k=1diθ¯k(i)D0Qω(i)Dk(i)T+∑k=1diθ¯k(i)Dk(i)Qω(i)D0T+∑k=1diθ¯k(i)Dk(i)Qω(i)Dk(i)Twhere(16)F0(i)=[F0000I(di−1)mi000],Fdi(i)=[00C(i)0],Fk(i)=[0000C(i)0−Imi00000]⟶the(k+1)thblock row↓The(k+2)thblock column,k=1,2,⋯,di−1,i=1,2,⋯,L,D0=[D000],Dk(i)=[000Imi00]⟶the(k+1)thblock row,k=1,2,⋯,diFor system(7)–(8), the following results hold:(17)F˜(i)(t)−F¯(i)=∑k=1di(θk(i)(t)−θ¯k(i))Fk(i),C˜(i)(t)−C¯(i)=(θ0(i)(t)−θ¯0(i))C1(i)whereC1(i)=[C(i)−Imi0⋯0].The following Lemma 2 gives the local filters that directly come from the recent reference [30].Lemma 2(See[30].) For system(7)–(8)underAssumptions 1 and 2, the local optimal linear filter and predictor for the ith subsystem are computed by(18)ςˆ(i)(t|t)=ςˆ(i)(t|t−1)+Gf(i)(t)ε(i)(t)(19)ςˆ(i)(t+1|t)=F¯(i)ςˆ(i)(t|t−1)+Gp(i)(t)ε(i)(t)The innovation sequenceε(i)(t)and its varianceQε(i)(t)are computed by(20)ε(i)(t)=z(i)(t)−C¯(i)ςˆ(i)(t|t−1)(21)Qε(i)(t)=θ¯0(i)(1−θ¯0(i))C1(i)h(i)(t)C1(i)T+C¯(i)Pς(i)(t|t−1)C¯(i)T+θ¯0(i)Qv(i)The filtering gain matrixGf(i)(t)and prediction gain matrixGp(i)(t)can be computed by(22)Gf(i)(t)=Pς(i)(t|t−1)C¯(i)TQε(i)−1(t)(23)Gp(i)(t)=[θ¯0(i)(F0(i)−F¯(i))h(i)(t)C1(i)T+F¯(i)Pς(i)(t|t−1)C¯(i)T+θ¯0(i)D0S¯(i)]Qε(i)−1(t)The prediction error variance matrixPς(i)(t+1|t)is computed by(24)Pς(i)(t+1|t)=(F¯(i)−Gp(i)(t)C¯(i))Pς(i)(t|t−1)(F¯(i)−Gp(i)(t)C¯(i))T+Q⌣(i)(t)−Gp(i)(t)S⌣(i)T(t)−S⌣(i)(t)Gp(i)T(t)+Gp(i)(t)R⌣(i)(t)Gp(i)T(t)where(25)Q⌣(i)(t)=M(i)(h(i)(t))−F¯(i)h(i)(t)F¯(i)T+Q¯ω(i),S⌣(i)(t)=θ¯0(i)(F0(i)−F¯(i))h(i)(t)C1(i)T+θ¯0(i)D0S¯(i),R⌣(i)(t)=θ¯0(i)(1−θ¯0(i))C1(i)h(i)(t)C1(i)T+θ¯0(i)Qv(i)The filtering error variance matrixPς(i)(t|t)is computed by(26)Pς(i)(t|t)=Pς(i)(t|t−1)−Gf(i)(t)Qε(i)(t)Gf(i)T(t)The initial values areςˆ(i)(0|−1)=[μ0T0]TandPς(i)(0|−1)=diag(P0,0).From Lemma 2, we see that the local optimal linear filterςˆ(i)(t|t)for system (7)–(8) with stochastic parameters depends on the state second-order momenth(i)(t)given in Lemma 1. This is different from the standard Kalman filter for systems with deterministic parameters.In the preceding section, we have given the local filtering algorithm. To obtain the fusion filter, we need compute the filtering error cross-covariance matrices between any two local filters. In this section, we will solve them. The following preliminary lemma will be used in the derivation of the cross-covariance matrices.Lemma 3For system(7)underAssumptions 1 and 2, the cross-state second-order moment matricesh(ij)(t)=E[ς(i)(t)ς(j)T(t)]between any two local subsystems satisfy(27)h(ij)(t+1)=M(ij)(h(ij)(t))+Q¯ω(ij),i,j=1,2,⋯,Lwhere(28)M(ij)(h(ij)(t))=F0(i)h(ij)(t)F0(j)T+∑k2=1djθ¯k2(j)F0(i)h(ij)(t)Fk2(j)T+∑k1=1diθ¯k1(i)Fk1(i)h(ij)(t)F0(j)T+∑k1=1di∑k2=1djθ¯k1(i)θ¯k2(j)Fk1(i)h(ij)(t)Fk2(j)T(29)Q¯ω(ij)=E[D˜(i)(t)ω(i)(t)ω(j)T(t)D˜(j)T(t)]=D0Qω(ij)D0T+∑k2=1djθ¯k2(j)D0Qω(ij)Dk2(j)T+∑k1=1diθ¯k1(i)Dk1(i)Qω(ij)D0T+∑k1=1di∑k2=1djθ¯k1(i)θ¯k2(j)Dk1(i)Qω(ij)Dk2(j)Twith the initial valueh(ij)(0)=diag(P0+μ0μ0T,0).Using (9) and (16), we can rewrite (7) as follows:(30)ς(i)(t+1)=[F0(i)+∑k1=1diθk1(i)(t)Fk1(i)]ς(i)(t)+[D0+∑k1=1diθk1(i)(t)Dk1(i)]ω(i)(t)Using (30), we readily obtain (27)–(29) by computingE[ς(i)(t+1)ς(j)T(t+1)]. This proof is completed. □Next, we give the computational formulas of the filtering and prediction error cross-covariance matrices.Theorem 1For system(7)–(8)underAssumptions 1 and 2, the filtering and prediction error cross-covariance matrices between the ith and jth (i≠j) subsystems can be computed by(31)Pς(ij)(t|t)=Pς(ij)(t|t−1)−Pς(ij)(t|t−1)C¯(j)TGf(j)T(t)−Gf(i)(t)C¯(i)Pς(ij)(t|t−1)+Gf(i)(t)Qε(ij)(t)Gf(j)T(t)(32)Pς(ij)(t+1|t)=M(ij)(h(ij)(t))−F¯(i)h(ij)(t)F¯(j)T+(F¯(i)−Gp(i)(t)C¯(i))Pς(ij)(t|t−1)(F¯(j)−Gp(j)(t)C¯(j))T+Q¯ω(ij)−θ¯0(j)D¯(i)S¯(ij)Gp(j)T(t)−θ¯0(i)Gp(i)(t)S¯(ji)TD¯(j)T+θ¯0(i)θ¯0(j)Gp(i)(t)Qv(ij)Gp(j)T(t)wherePς(ij)(t|t)andPς(ij)(t+1|t)are the filtering and prediction error cross-covariance matrices, respectively. The cross-covariance matrices of innovationsε(i)(t)andε(j)(t)are given by(33)Qε(ij)(t)=C¯(i)Pς(ij)(t|t−1)C¯(j)T+θ¯0(i)θ¯0(j)Qv(ij)with the initial valuePς(ij)(0|−1)=diag(P0,0).Substituting (8) into (20), we can obtain another form of the innovation as follows:(34)ε(i)(t)=[C˜(i)(t)−C¯(i)]ς(i)(t)+C¯(i)ς˜(i)(t|t−1)+θ0(i)(t)v(i)(t)Subtracting (19) from (7) and using (34), we get the prediction error equation of the ith local predictor as follows:(35)ς˜(i)(t+1|t)=[(F˜(i)(t)−F¯(i))−(θ0(i)(t)−θ¯0(i))Gp(i)(t)C1(i)]ς(i)(t)+(F¯(i)−Gp(i)(t)C¯(i))ς˜(i)(t|t−1)+D˜(i)(t)ω(i)(t)−θ0(i)(t)Gp(i)(t)v(i)(t)where the prediction errorς˜(i)(t|t−1)=ς(i)(t)−ςˆ(i)(t|t−1). UsingE[θ0(i)(t)θ0(j)(t)]=θ¯0(i)θ¯0(j),i≠j,E[F˜(i)(t)−F¯(i)]=0,E[θ0(i)(t)−θ¯0(i)]=0,ς(i)(t)⊥ω(j)(t),ς(i)(t)⊥v(j)(t),ς˜(i)(t|t−1)⊥ω(j)(t)andς˜(i)(t|t−1)⊥v(j)(t), where the symbol ⊥ denotes the orthogonality, we have(36)Pς(ij)(t+1|t)=E[ς˜(i)(t+1|t)ς˜(j)T(t+1|t)]=E{[(F˜(i)(t)−F¯(i))−(θ0(i)(t)−θ¯0(i))Gp(i)(t)C1(i)]ς(i)(t)ς(j)T(t)[(F˜(j)(t)−F¯(j))−(θ0(j)(t)−θ¯0(j))Gp(j)(t)C1(j)]T}+(F¯(i)−Gp(i)(t)C¯(i))Pς(ij)(t|t−1)(F¯(j)−Gp(j)(t)C¯(j))T+Q¯ω(ij)−θ¯0(j)D0S¯(ij)Gp(j)T(t)−θ¯0(i)Gp(i)(t)S¯(ji)TD0T+θ¯0(i)θ¯0(j)Gp(i)(t)Qv(ij)Gp(j)T(t)The first term on the right hand side of (36) can be computed as(37)E[(F˜(i)(t)−F¯(i))ς(i)(t)ς(j)T(t)(F˜(j)(t)−F¯(j))T]−E[(θ0(j)(t)−θ¯0(j))(F˜(i)(t)−F¯(i))ς(i)(t)ς(j)T(t)C1(j)TGp(j)T(t)]−E[(θ0(i)(t)−θ¯0(i))Gp(i)(t)C1(i)ς(i)(t)ς(j)T(t)(F˜(j)(t)−F¯(j))T]+E[(θ0(i)(t)−θ¯0(i))(θ0(j)(t)−θ¯0(j))Gp(i)(t)C1(i)ς(i)(t)ς(j)T(t)C1(j)TGp(j)T(t)]where(38)E[(F˜(i)(t)−F¯(i))ς(i)(t)ς(j)T(t)(F˜(j)(t)−F¯(j))T]=M(ij)(h(ij)(t))−F¯(i)h(ij)(t)F¯(j)T,E[(θ0(j)(t)−θ¯0(j))(F˜(i)(t)−F¯(i))ς(i)(t)ς(j)T(t)C1(j)TGp(j)T(t)]=0,E[(θ0(i)(t)−θ¯0(i))(θ0(j)(t)−θ¯0(j))Gp(i)(t)C1(i)ς(i)(t)ς(j)T(t)C1(j)TGp(j)T(t)]=0In the second equation of (38), we have made use of(F˜(i)(t)−F¯(i))T=∑k1=1di(θk1(i)(t)−θ¯k1(i))Fk1(i)andE[(θk1(i)(t)−θ¯k1(i))(θ0(j)(t)−θ¯0(j))]=0,i≠j. Substituting (38) into (36), we obtain (32).According to (18), the filtering error equation is given as follows:(39)ς˜(i)(t|t)=ς˜(i)(t|t−1)−Gf(i)(t)ε(i)(t)Then, the filtering error cross-covariance matrices are computed as follows:(40)Pς(ij)(t|t)=E[ς˜(i)(t|t)ς˜(j)T(t|t)]=Pς(ij)(t|t−1)+Gf(i)(t)Qε(ij)(t)Gf(j)T(t)−Gf(i)(t)E[ε(i)(t)ς˜(j)T(t|t−1)]−E[ς˜(i)(t|t−1)ε(j)T(t)]Gf(j)T(t)Substituting (34) into (40) and usingς˜(i)(t|t−1)⊥v(j)(t)andE[θ0(i)(t)−θ¯0(i)]=0, we obtain (31). Substituting (34) intoQε(ij)(t)=E[ε(i)(t)ε(j)T(t)], we obtain (33), where we have made use ofς˜(i)(t|t−1)⊥v(j)(t),ς(i)(t)⊥v(j)(t),E[(θ0(i)(t)−θ¯0(i))(θ0(j)(t)−θ¯0(j))]=0andE[θ0(i)(t)θ0(j)(t)]=θ¯0(i)θ¯0(j),i≠j. This proof is completed. □From the definition of the augmented statesς(i)(t)in system(7)–(8), the local optimal linear filters for the statex(t)of system(1)–(3)are computed byxˆ(i)(t|t)=[In0]ςˆ(i)(t|t), the filtering error variance matrices byPx(i)(t|t)=[In0]Pς(i)(t|t)[In0]T, and the cross-covariance matrices byPx(ij)(t|t)=[In0]Pς(ij)(t|t)[In0]T.Based on the local filters in Lemma 2 and the cross-covariance matrices in Theorem 1, we can obtain the following distributed fusion filter by using the matrix-weighted fusion algorithm in the linear minimum variance sense [20]:(41)xˆo(t|t)=∑i=1LΩ(i)(t)xˆ(i)(t|t)(42)[Ω(1)(t),⋯,Ω(L)(t)]=[eTΞ−1(t|t)e]−1eTΞ−1(t|t)(43)Ξ(t|t)=(Px(ij)(t|t))nL×nLwhereeT=[In,⋯,In],Ω(i)(t),i=1,2,⋯,Lare the weighted matrices,Ξ(t|t)is a block matrix whose the (i,j)th block isPx(ij)(t|t). The variance matrix of the fusion filter is given by(44)Po(t|t)=[eTΞ−1(t|t)e]−1Moreover, we havePo(t|t)≤Px(i)(t|t).Remark 3Letςc(t+1)=[xT(t+1),Y1(1)T(t),⋯,Yd1(1)T(t),⋯,Y1(L)T(t),⋯,YdL(L)T(t)]T, we can obtain an augmented system similar to (7)–(8). Then, we can derive the centralized fusion filter by applying projection theory. Though the centralized fusion filter has better accuracy, it has the bad robust. The proposed distributed fusion filter has the parallel structure, which means that local filters can be in parallel run by different local processors. In the fusion center, the linear weighted sum of local filters gives the fusion filter. Moreover, it has better robust, flexibility and reliability [20].In the preceding section, we have obtained the distributed optimal weighted fusion filter in the finite horizon. In this section, we will investigate the distributed fusion steady-state filter in the infinite horizon. Firstly, we give the steady-state local filters. Then, we analyze the steady-state property of cross-covariance matrices. Finally, we give the distributed fusion steady-state filter.Lemma 4(See[30].) For system(7)–(8), the solutionh(i)(t)to Eq.(13)with any initial valueh(i)(0)≥0will converge to the unique positive semi-definite solutionh(i)to the following algebraic Lyapunov equation(45)h(i)=M(i)(h(i))+Q¯ω(i)i.e.,h(i)=limt→∞⁡h(i)(t), provided that F is a stable matrix. Moreover, we haveM(i)(h(i))=limt→∞⁡M(i)(h(i)(t)),Q⌣(i)=limt→∞⁡Q⌣(i)(t),S⌣(i)=limt→∞⁡S⌣(i)(t)andR⌣(i)=limt→∞⁡R⌣(i)(t), whereQ⌣(i),S⌣(i)andR⌣(i)are defined similarly to(25)whereh(i)(t)is replaced byh(i).(See[30].) For system(7)–(8), the solutionPς(i)(t|t−1)to Eq.(24)with any initial valuePς(i)(0|−1)≥0will converge to the semi-definite solutionϒς(i)to the following algebraic Riccati equation(46)ϒς(i)=(F¯(i)−Gp(i)C¯(i))ϒς(i)(F¯(i)−Gp(i)C¯(i))T+Q⌣(i)−Gp(i)S⌣(i)T−S⌣(i)Gp(i)T+Gp(i)R⌣(i)Gp(i)Ti.e.,ϒς(i)=limt→∞⁡Pς(i)(t|t−1), provided that the matrix F is stable and the pair (F¯(i)−S⌣(i)R⌣(i)−1C¯(i),Q¯(i)) is stabilizable, whereQ¯(i)Q¯(i)T=Q⌣(i)−S⌣(i)R⌣(i)−1S⌣(i)T. Further, we haveGp(i)=limt→∞⁡Gp(i)(t),Gf(i)=limt→∞⁡Gf(i)(t)andQε(i)=limt→∞⁡Qε(i)(t).Moreover, the steady-state predictor(47)ςˆs(i)(t+1|t)=(F¯(i)−Gp(i)C¯(i))ςˆs(i)(t|t−1)+Gp(i)z(i)(t)is asymptotically stable.Next, we will present the steady-state cross-state second-order moment matricesh(ij)and the steady-state prediction and filtering error cross-covariance matricesϒς(ij)andPς(ij).We define that(48)A(ij)=F0(i)⊗F0(j)+∑k2=1djθ¯k2(j)F0(i)⊗Fk2(j)+∑k1=1diθ¯k1(i)Fk1(i)⊗F0(j)+∑k1=1di∑k2=1djθ¯k1(i)θ¯k2(j)Fk1(i)⊗Fk2(j)where ⊗ is the Kronecker product andρ(A(ij))is the spectrum radius of the matrixA(ij).If the matrix F is stable, we haveh(ij)=limt→∞⁡(h(ij)(t)). The steady-state cross-state second-order moment matricesh(ij)between any two states of system(7)satisfy(49)h(ij)=M(ij)(h(ij))+Q¯ω(ij),i,j=1,2,⋯,LMoreover, we haveM(ij)(h(ij))=limt→∞⁡M(ij)(h(ij)(t)).According to the stability of F,0<θ¯k1(i)<1,0<θ¯k2(j)<1, and the definition ofFk1(i)in (16), it can be easily known thatρ(A(ij))<1. Then we haveh(ij)=limt→∞⁡(h(ij)(t))satisfying (49). Further, from (28), we haveM(ij)(h(ij))=limt→∞⁡M(ij)(h(ij)(t)). This proof is completed. □If the matrix F is stable and the pair (F¯(i)−S⌣(i)R⌣(i)−1C¯(i),Q¯(i)) is stabilizable, whereQ¯(i)Q¯(i)T=Q⌣(i)−S⌣(i)R⌣(i)−1S⌣(i)T, the steady-state prediction error cross-covariance matrices between any two local predictors satisfy(50)ϒς(ij)=M(ij)(h(ij))−F¯(i)h(ij)F¯(j)T+(F¯(i)−Gp(i)C¯(i))ϒς(ij)(F¯(j)−Gp(j)C¯(j))T+Q¯ω(ij)−θ¯0(j)D¯(i)S¯(ij)Gp(j)T−θ¯0(i)Gp(i)S¯(ji)TD¯(j)T+θ¯0(i)θ¯0(j)Gp(i)Qv(ij)Gp(j)Twhich can be obtained by the following recursive calculation with any initial valuePς(ij)(0|−1):(51)Pς(ij)(t+1|t)=M(ij)(h(ij))−F¯(i)h(ij)F¯(j)T+(F¯(i)−Gp(i)C¯(i))Pς(ij)(t|t−1)(F¯(j)−Gp(j)C¯(j))T+Q¯ω(ij)−θ¯0(j)D¯(i)S¯(ij)Gp(j)T−θ¯0(i)Gp(i)S¯(ji)TD¯(j)T+θ¯0(i)θ¯0(j)Gp(i)Qv(ij)Gp(j)Ti.e.,(52)ϒς(ij)=limt→∞⁡Pς(ij)(t|t−1)Further, we have the steady-state filtering error cross-covariance matrices:(53)Pς(ij)=ϒς(ij)−ϒς(ij)C¯(j)TGf(j)T−Gf(i)C¯(i)ϒς(ij)+Gf(i)Qε(ij)Gf(j)TFrom Theorem 2, we havelimt→∞⁡(h(ij)(t))=h(ij). From Lemma 5, we havelimt→∞⁡Gp(i)(t)=Gp(i). Then (32) reduces to (51) ast→∞.LettingΔ(ij)(t)=Pς(ij)(t|t−1)−ϒς(ij)and subtracting (50) from (51), we have(54)Δ(ij)(t+1)=(F¯(i)−Gp(i)C¯(i))Δ(ij)(t)(F¯(j)−Gp(j)C¯(j))TBy iteration of (54), we have(55)Δ(ij)(t)=(F¯(i)−Gp(i)C¯(i))tΔ(ij)(0)(F¯(j)−Gp(j)C¯(j))TtFrom Lemma 5, we know thatF¯(i)−Gp(i)C¯(i)is a stable matrix. We have(F¯(i)−Gp(i)C¯(i))t→0ast→∞. Thus,Δ(ij)(t)→0ast→∞. Then (52) is obtained.Further, from (33) and (31) we havelimt→∞⁡Pς(ij)(t|t)=Pς(ij)wherePς(ij)satisfied (53). This proof is completed. □Based on the steady-state local filters in Lemma 5 and the steady-state filtering error cross-covariance matrices between any two local filters in Theorem 3, we have the distributed fusion steady-state filter as(56)xˆso(t|t)=∑i=1LΩ(i)xˆs(i)(t|t)(57)[Ω(1),⋯,Ω(L)]=[eTΞ−1e]−1eTΞ−1(58)Pso=[eTΞ−1e]−1wherexˆs(i)(t|t)=[In0]ςˆs(i)(t|t)are the local steady-state filters for the statex(t), andΩ(i)are the steady-state weighted matrices.Ξ=(Pς(ij))nL×nLwherePς(ij)are the steady-state filtering error covariance matrices.Psois the variance matrix of the distributed fusion steady-state filter.Remark 4For the distributed fusion steady-state filter, the local gain matrices, auto- and cross-covariance matrices and fusion weighted matrices can be computed offline. So the online computational cost of the distributed fusion steady-state filter has the order of magnitudeO(∑i=1L(n+dimi)2). With the increase of the number L of sensors, it can reduce the online computational cost compared with the centralized fusion steady-state filter whose online computational cost has the order of magnitudeO((n+∑i=1Ldimi)2).For stochastic parameterized system (7)–(8) induced by random delays and packet losses, from Eqs. (24), (25) and (32), we see that the prediction error covariance matricesPς(i)(t|t−1)andPς(ij)(t|t−1)depend on the state second-order momentsh(i)(t)andh(ij)(t). The stability of matrix F guarantees the detectability of system and the existence of auto- and cross-state second-order moments. Further, the additional condition of stabilizability guarantees the existence of the steady-state solutions of Eqs. (24) and (32), which are general in the steady-state Kalman filtering.Consider a one-order two-channel autoregressive moving average (ARMA) signal:(59)(I2+Aq−1)s(t)=q−1Bw(t)y(i)(t)=C(i)s(t)+v(i)(t),i=1,2,3whereq−1is the backward operator, i.e.,q−1s(t)=s(t−1),A=[−1.3−10.40],B=[10.5],C(1)=[0.9,0],C(2)=[0.8,0],C(3)=[1.2,0].v(i)(t)=ciw(t)+ui(t)wherew(t)andui(t)are mutually uncorrelated white noises with 0 mean. The variance ofw(t)is 1 and the variances ofui(t),i=1,2,3areQu1=1,Qu2=1.25andQu3=2, respectively. The correlation coefficients arec1=1,c2=0.5andc3=0.8. In this simulation, we assume that there are bounded two-step delays and possible multiple packet losses in data transmissions from individual sensors to the local processors, i.e.,d1=d2=d3=2. Takeα¯0(1)=0.2,α¯1(1)=0.5,α¯2(1)=0.8,α¯0(2)=0.6,α¯1(2)=0.4,α¯2(2)=0.7,α¯0(3)=0.4,α¯1(3)=0.6,α¯2(3)=0.5, and the initial valuesxˆ(0|−1)=[1,1]TandP0=0.1I2. The simulation is run based on 100 sampling data. The aim is to obtain the distributed fusion filterxˆo(t|t)weighted by matrices.The state tracking curves are shown in Fig. 2. We see that the distributed fusion filter weighted by matrices has effective tracking performance though there are delays and packet losses. Fig. 3compares the filtering error variances of the local filters and the fusion filters. It is clear that the distributed fusion filter has better accuracy than local filters and worse accuracy than the centralized fusion filter. Meanwhile, Fig. 3 also verifies the steady-state property of the distributed fusion filter. To compare clearly their accuracy, the steady-state values of their filtering error variances are listed in Table 1and Table 2. From the tables, it is clear that the accuracy of the distributed fusion filter is much better than local filters but a little worse than that of the centralized fusion filter. From Remark 4, the online computational cost of the distributed fusion steady-state filter isO(48), while the online computational cost of the centralized fusion steady-state filter isO(64). It means that the online computational cost of the distributed fusion steady-state filter is smaller than the centralized fusion steady-state filter. Moreover, it is more important that distributed fusion filter has better robust, flexibility and reliability [20].Fig. 4shows the filtering error variances at the 100th step asQwranges from 0.5 to 5. It is clear that the filtering error variances become larger with the increase of the variance of process noise. Moreover, the distributed fusion filter has better accuracy than any local filters for allQwranging from 0.5 to 5.Whend1=d2=d3=2, the model (3) can be written asz(i)(t)=α0(i)(t)y(i)(t)+(1−α0(i)(t)){(1−α0(i)(t−1))α1(i)(t)y(i)(t−1)+[1−(1−α0(i)(t−1))α1(i)(t)]{(1−α0(i)(t−2))(1−α1(i)(t−1))α2(i)(t)y(i)(t−2)}}From above equation, we can obtain that the on-time arrival rate of a packet at time t isτ0(i)=Prob{α0(i)(t)=1}=α¯0(i), the one-step delay rate isτ1(i)=Prob{α0(i)(t)=0,α0(i)(t+1)=0,α1(i)(t+1)=1}=(1−α¯0(i))2α¯1(i), the two-step delay rate isτ2(i)=Prob{α0(i)(t+2)=0,α0(i)(t)=0,α1(i)(t+1)=0,α2(i)(t+2)=1,α0(i)(t+1)=1}+Prob{α0(i)(t+2)=0,α0(i)(t)=0,α1(i)(t+1)=0,α2(i)(t+2)=1,α1(i)(t+2)=0}=(1−α¯0(i))2(1−α¯1(i))α¯2(i)(1+α¯0(i)−α¯1(i)), and the packet loss rate isσ(i)=1−α¯0(i)−(1−α¯0(i))2α¯1(i)−(1−α¯0(i))2(1−α¯1(i))α¯2(i)(1+α¯0(i)−α¯1(i)).To study the relation between the filtering accuracy and the communication capacity, we take sensor 1 as a subject of the study. Setα¯0(1)=0.2andα¯1(1)=0.4, then the on-time arrival and one-step delay rates of the local filter 1 areτ0(i)=0.2andτ1(1)=0.256, respectively. Fig. 5shows the variance of local filter 1 as the packet loss rateσ(1)varies from 0.25 to 0.5 at the 100th step under fixed on-time arrival rate 0.2 and one-step delay rate 0.256. Fig. 6shows the corresponding MSEs (mean square errors) under three different loss rates of case 1:σ(1)=0.3, case 2:σ(1)=0.4and case 3:σ(1)=0.5by 500 Monte-Carlo runs. From Fig. 5 and Fig. 6, we see that local filter 1 has worse accuracy with the increase of the packet loss rateσ(1).On the other hand, Fig. 7shows the variance of local filter 1 as the on-time arrival rateτ0(i)varies from 0.1 to 0.6 at the 100th step under fixed packet loss rateσ(1)=0.3and the same one- and two-step delay rates, i.e.,τ1(1)=τ2(1). Fig. 8shows the corresponding MSEs under three different on-time arrival rates of case 1:τ0(i)=0.1, case 2:τ0(i)=0.35and case 3:τ0(i)=0.6by 500 Monte-Carlo runs. From Fig. 7 and Fig. 8, it is clear that local filter 1 has better accuracy with the increase of the on-time arrival rate.

@&#CONCLUSIONS@&#
