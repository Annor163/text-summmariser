@&#MAIN-TITLE@&#
Implicit matrix representations of rational Bézier curves and surfaces

@&#HIGHLIGHTS@&#
Introduction of matrix representations of Bézier curves and surfaces.Algebraic properties of matrix representations are presented.Solving of the inversion problem by means of matrix representations.Numerical behavior of matrix representations through singular value decomposition.Ray-tracing of Bézier surfaces by means of matrix representations.

@&#KEYPHRASES@&#
Implicitization,Moving planes,Bézier patches,Inversion problem,Intersection problems,

@&#ABSTRACT@&#
We introduce and study a new implicit representation of rational Bézier curves and surfaces in the 3-dimensional space. Given such a curve or surface, this representation consists of a matrix whose entries depend on the space variables and whose rank drops exactly on this curve or surface. Our approach can be seen as an extension of the moving lines implicitization method introduced by Sederberg, from non-singular matrices to the more general context of singular matrices. In the first part of this paper, we describe the construction of these new implicit matrix representations and their main geometric properties, in particular their ability to solve efficiently the inversion problem. The second part of this paper aims to show that these implicitization matrices adapt geometric problems, such as intersection problems, to the powerful tools of numerical linear algebra, in particular to one of the most important: the singular value decomposition. So, from the singular values of a given implicit matrix representation, we introduce a real evaluation function. We show that the variation of this function is qualitatively comparable to the Euclidean distance function. As an interesting consequence, we obtain a new determinantal formula for implicitizing a rational space curve or surface over the field of real numbers. Then, we show that implicit matrix representations can be used with numerical computations, in particular there is no need for symbolic computations to use them. We give some rigorous results explaining the numerical stability that we have observed in our experiments. We end the paper with a short illustration on ray tracing of parameterized surfaces.

@&#INTRODUCTION@&#
In geometric modeling, parameterized algebraic curves and surfaces are used intensively. To manipulate them, it is useful to have an implicit representation, in addition to their given parametric representation. Indeed, a parametric representation is for instance well adapted for visualization purposes whereas an implicit representation allows significant improvements in the computation of intersections. Nevertheless, implicit representations are known to be very hard to compute in general. The goal of this paper is to overcome this difficulty by introducing a simple method for computing an implicit representation of a parameterized curve or surface in the form of a matrix. We will call them implicit matrix representations.Matrix-based implicit representations of plane curves and surfaces have already appeared several times in the literature (see e.g.  [1–4]). However, all these approaches aimed at building a non-singular matrix whose determinant is an implicit polynomial equation. The case of plane curves is well understood: it is always possible to build such a non-singular matrix, in particular by means of the moving lines method introduced by Sederberg  [4]. The case of surfaces is much more involved because of their rich geometry and the occurrence of base points (the points where the parameterization is not well defined). Thus, in order to find a non-singular matrix whose determinant is an implicit polynomial equation, one has to consider some very particular classes of parameterizations (see e.g.  [2,5,6]).In this paper, we show that matrix-based implicit representations can be built for (almost all) parameterized algebraic curves, including space curves, and surfaces if the requirement of getting a non-singular matrix is deleted. Indeed, the matrices we will introduce are in general singular matrices, but they still represent the curve or surface: the vanishing of a determinant will be replaced by a drop-of-rank property. Our approach is hence to keep these matrices as implicit representations on their own and to develop their study and use. Added and combined to the parametric representations, we believe that these implicit matrix representations can be a powerful tool.The theoretical foundations of implicit matrix representations have been developed in a couple of papers  [7,8], using tools from algebraic geometry and commutative algebra. We will review their main properties in Section  3. The first contribution of this paper is to adapt the construction of these matrices to the context of Bézier patches (usually obtained from the decomposition of a NURBS). This is the content of Section  2. The rest of the paper, and its main contribution, is a study of implicit matrix representations through a famous tool of numerical linear algebra: the singular value decomposition (SVD). It turns out that combined with this SVD, implicit matrix representations have very nice properties and show very good numerical behavior. In Section  4, a real evaluation function is built from an implicit matrix representation and it is shown that this function is comparable to the classical Euclidean distance. As a by-product, a new determinantal formula for implicitizing a rational Bézier curve or surface over the field of real numbers is obtained. Section  5 is devoted to the study of the numerical behavior of implicit matrix representations. In particular, we show that there is no need for symbolic computations to use them and we prove results that give insights for their numerical stability and robustness that we have observed in our experiments. Finally, the paper ends with a short discussion on the application of implicit matrix representations to intersection problems.In this section, we construct in a general framework a family of matrices that is attached to a given parameterizationϕ. Consider a parameterizationϕof a curve or surface(1)s∈R1orR2⟶ϕ(f1(s)f0(s),f2(s)f0(s),f3(s)f0(s))∈R3wheref0,f1,f2andf3are polynomials in the parametersof degree⩽d. Notice thatsstands for a single parametert∈Rifϕparameterizes a curve, or for a couple of parameters(u,v)∈R2ifϕparameterizes a surface. Similarly, the word degree means a single degree (for curves and triangular surfaces) or a bi-degree (for tensor-product surfaces).LetBd={ϕ1(s),…,ϕnd(s)}be a set of blending functions that form a basis of polynomials of degree at mostdin the parameters. Then, the parameterizationϕis of the formϕ(s)=∑i=1ndwibiϕi(s)∑i=1ndwiϕi(s)where the pointsbi=(xi,yi,zi)∈R3,i=1,…,nd, are the control points andw1,…,wndtheir associated weights. It follows thatf0(s)=∑i=1ndwiϕi(s),f1(s)=∑i=1ndwixiϕi(s),f2(s)=∑i=1ndwiyiϕi(s),f3(s)=∑i=1ndwiziϕi(s).Now, we fix a non-negative degreeνand build a matrixMν(ϕ)as follows. Consider the set of 4-tuples of polynomials(g0(s),g1(s),g2(s),g3(s))such that(2)deg(gi(s))⩽νand∑i=03gi(s)fi(s)≡0.It is clearly a vector space and computing one of its bases, sayL1,…,Lrν, amounts to solving a single linear system. EachLjbeing a 4-tuple of polynomials(g0,g1,g2,g3), it can be identified with the polynomialLj(s;X,Y,Z)≔g0(s)+Xg1(s)+Yg2(s)+Zg3(s).Moreover, we have the freedom to choose an arbitrary basis of polynomials of degree⩽νto express thegi’s. LetBν′={ψ1(s),…,ψmν(s)}be such a basis, then we have(3)Lj(s;X,Y,Z)=(∑i=1mνλ0,i(j)ψi(s))+(∑i=1mνλ1,i(j)ψi(s))X+(∑i=1mνλ2,i(j)ψi(s))Y+(∑i=1mνλ3,i(j)ψi(s))Zwhere theλk,i(j)are real numbers. By rearranging (3), we get(4)Lj=∑i=1mν(λ0,i(j)+λ1,i(j)X+λ2,i(j)Y+λ3,i(j)Z)ψi(s)=∑i=1mνΛi,j(X,Y,Z)ψi(s)whereΛi,j(X,Y,Z)is a linear polynomial inR[X,Y,Z]. The matrixMν(ϕ)is then defined as themν×rν-matrix whose entry(i,j)is the linear polynomialΛi,j(X,Y,Z):(5)Mν(ϕ)≔(Λ1,1Λ1,2⋯Λ1,rνΛ2,1Λ2,2⋯Λ2,rν⋮⋮⋮Λmν,1Λmν,2⋯Λmν,rν).A geometric interpretation of this construction is the following. For any specific value of the parameters0, the equationLj(s0;X,Y,Z)=0defines a plane inR3. When the parametersvaries, this plane varies as well and the equationLj(s;X,Y,Z)=0is hence called (after Sederberg and his co-authors; see e.g.  [4,2]) a moving plane. Moreover, by definition ofLj, we have(6)Lj(s;f1(s)f0(s),f2(s)f0(s),f3(s)f0(s))=0which means that the plane corresponding to the given parameters0always goes through the pointϕ(s0)(if it is well-defined, i.e.f0(s0)≠0) that belongs to the curve or the surface parameterized byϕ. Therefore,L1,…,Lrνis a collection ofrνmoving planes and for any specific values0of the parameters, therνcorresponding planes all intersect at the pointϕ(s0). As we will see in the following, under a suitable hypothesis this point is actually their unique intersection point.Before giving the main properties of the matricesMν(ϕ)in the next section, we give more details on their construction in three particular cases of interest in CAGD.Assume thatϕparameterizes a rational Bézier curve. In this situation, the blending functionsBdare given by the Bernstein polynomialsBid(t)=(di)ti(1−t)d−i,i=0,…,d.Therefore, we haveϕ:t∈R↦∑i=0dwibiBid(t)∑i=0dwiBid(t)=(f1(t)f0(t),f2(t)f0(t),f3(t)f0(t))wherebi=(xi,yi,zi),i=0,…,dare the control points, andw0,…,wdare their weights.Now, we fix a degreeν⩾0and we seek 4-tuples of polynomials(g0,g1,g2,g3)satisfying (2) in the Bernstein basis, that is to say, we chooseBν′={B0ν(t),…,Bνν(t)}so that for allj=0,…,3(7)gj(t)=∑i=0ναj,iBiν(t),αj,i∈R.For that purpose, we form a matrixSνas follows: the first column is filled with the coefficients ofB0ν(t)f0(t)in the Bernstein basisBν+d={B0ν+d(t),…,Bν+dν+d(t)}, the second column with the coefficients ofB1ν(t)f0(t)and so on until the columnν+1which is filled with the coefficients ofBνν(t)f0(t). Then, we continue this way and add three other similar blocks of columns with the polynomialsf1(t),f2(t)andf3(t). The matrixSνis hence a(d+ν+1)×4(ν+1)-matrix that satisfies the equality of matrices[B0ν+d(t)B0ν+d(t)⋯Bν+dν+d(t)]Sν=[B0ν(t)f0(t)⋯Bνν(t)f0(t)B0ν(t)f1(t)⋯Bνν(t)f3(t)].Notice that this matrix is easily filled with simple computations on control points. Indeed, for any polynomialf(t)=∑i=0dciBid(t)andj=0,…,νwe haveBjν(t)f(t)=∑i=0d(νj)(di)(d+νi+j)ciBi+jd+ν(t).By definition ofSν, any vector in its null space is of the form[α0,0,…,α0,ν,α1,0,…,α1,ν,α2,0,…,α2,ν,α3,0,…,α3,ν]Tand yields a 4-tuple of polynomials (7) satisfying (2). Therefore, the null space ofSνcorresponds to a4(ν+1)×rν-matrix of the form(8)Null(Sν)=[Mν,0Mν,1Mν,2Mν,3]where the block matricesMν,0,Mν,1,Mν,2andMν,3are of size(ν+1)×rν. By the definition ofMν(ϕ), we have(9)Mν(ϕ)=Mν,0+XMν,1+YMν,2+ZMν,3.Example 1As a simple illustration, consider the cubic curve withd=3,wi=1for alli=0,…,3andb0=(0,0,0),b1=(1/3,0,0),b2=(2/3,1/3,0),b3=(1,1,1). Then, choosingν=1the matrixS1is of size 5×8 and the computation of its null space yields the matrixM1(ϕ)=[X+Y+ZX+YX−1+Z−1+Y−1+X].Takingν=2,S2is of size 6×12 andM2(ϕ)is equal to[2X+2Y−2X−Y2X+2Y+2Z−3X−2Y−Z−X2X−1+Y1−1+Z3/21/2X−10−1+Y0−1+ZX−10].A triangular rational Bézier surface of degreedcorresponds to a parameterization of the formϕ:(u,v)∈R2↦∑i+j=0dwi,jbi,jBi,jd(u,v)∑i+j=0dwi,jBi,jd(u,v)=(f1(u,v)f0(u,v),f2(u,v)f0(u,v),f3(u,v)f0(u,v))where for all pairs of integersi,jsuch that0⩽i+j⩽d,bi,j=(xi,j,yi,j,zi,j)is a control point,wi,jits weight andBi,jd(u,v)=(di,j)uivj(1−u−v)d−i−j=d!i!j!(d−i−j)!uivj(1−u−v)d−i−jthe corresponding Bernstein polynomial. We proceed similarly to the previous case of curves. We fix an integerν⩾0and seek 4-tuples of polynomials(g0,g1,g2,g3)in the Bernstein basisBν′={B0,0ν(u,v),B0,1ν(u,v),B0,2ν(u,v)…,Bν,0ν(u,v)}:(10)gj(u,v)=∑i+j=0i,j⩾0ναj,iBi,jν(u,v),αj,i∈R.To compute them, we form the matrixSνwhose columns are filled with the coefficients ofBi,jν(u,v)fk(t),0⩽i+j⩽ν,0⩽i,j,k=0,1,2,3in the Bernstein basisBν+d={B0,0ν+d(u,v),B0,1ν+d(u,v)…,Bν+d,0ν+d(u,v)}.The matrixSνhas hence(d+ν+22)rows and4mν=4(ν+22)columns and it satisfies the equality of matrices[B0,0ν+d(u,v)B0,1ν+d(u,v)⋯Bν+dν+d,0(u,v)]Sν=[B0,0ν(u,v)f0⋯Bν,0ν(u,v)f0B0,0ν(u,v)f1⋯Bν,0ν(u,v)f3].Notice that for any polynomialf(u,v)=∑i+j=0dci,jBi,jd(u,v)and any pair of integers0⩽k+l⩽ν,0⩽k,lwe haveBk,lν(u,v)f(u,v)=∑i+j=0i,j⩾0d(νk,l)(di,j)(d+νi+k,j+l)ci,jBi+k,j+ld+ν(u,v).So,Sνcan be filled by simple computations on the control points of the parameterizationϕ. Now, by definition ofSνthe computation of its null space returns a4(ν+22)×rν-matrix of the form (8) where each matrixMν,iis of size(ν+22)×rν. Finally, we getMν(ϕ)=Mν,0+XMν,1+YMν,2+ZMν,3.Example 2As a simple illustration, we consider a parameterization of the unit sphere withd=2,w0,0=1,w0,1=1,w0,2=2,w1,0=1,w1,1=1,w2,0=2,b0,0=(1,0,0),b0,1=(1,0,1),b0,2=(0,0,1),b1,0=(1,1,0), andb1,1=(1,1,1),b2,0=(0,1,0). Choosingν=1we form the 10×12-matrixSνand find the matrixM1(ϕ)=[Y1−X+Y+Z−1+X−Y0Y−2X+2Y−1+X−Y+Z−Y−1−X+Y−2X2XZ].A tensor-product rational Bézier surface of bi-degree(d1,d2)corresponds to a parameterization of the formϕ:(u,v)∈R2↦∑i=0d1∑j=0d2wi,jbi,jBid1(u)Bjd2(v)∑i=0d1∑j=0d2wi,jBid1(u)Bjd2(v)where thebi,j’s are the control points and thewi,j’s their weights. Here again, we proceed as in the previous cases. However, in this case the degree is actually a bi-degree, that is to say a pair of integers that corresponds to the degree in the variableuand the degree in the variablev. In the following, all the inequalities between these bi-degrees are understood component-wise.So, let us fix a bi-degreeν=(ν1,ν2)and seek 4-tuples of polynomials(g0,g1,g2,g3)in the tensor product Bernstein basisBν′={B0ν1(u)B0ν2(v),B0ν1(u)B1ν2(v),…,Bν1ν1(u)Bν2ν2(v)}:(11)gj(u,v)=∑i=0ν1∑j=0ν2αj,iBiν1(u)Bjν2(v),αj,i∈R.Here again, we form the matrixSνwhose columns are filled with the coefficients ofBiν1(u)Bjν2(v)fk(u,v), in the Bernstein basisBν+d={B0ν1+d1(u)B0ν2+d2(v),…,Bν1+d1ν1+d1(u)Bν2+d2ν2+d2(v)}.Hence the matrixSνhas(ν1+d1+1)(ν2+d2+1)rows and4mν=4(ν1+1)(ν2+1)columns and it satisfies the equality of matrices[B0ν1+d1(u)B0ν2+d2(v)⋯Bν1+d1ν1+d1(u)Bν2+d2ν2+d2(v)]Sν=[B0ν1(u)B0ν2(v)f0⋯Bν1ν1(u)B0ν2(v)f0⋯Bν1ν1(u)Bν2ν2(v)f3].Observe that for any polynomialf(u,v)=∑i=0d1∑j=0d2ci,jBid1(u)Bjd2(v)and any pair of integersk,lsuch that0⩽k⩽ν1and0⩽l⩽ν2, we haveBkν1(u)Blν2(v)f(u,v)=∑i=0d1∑j=0d2(ν1k)(ν2l)(d1i)(d2j)(ν1+ν2i+k)(d1+d2j+l)ci,jBi+kν1+d1(u)Bj+lν2+d2(v).The computation of the null space ofSνreturns a4(ν1+1)(ν2+1)×rν-matrix of the form (8) where each matrixMν,iis of size(ν1+1)(ν2+1)×rν. As in the previous cases, we getMν(ϕ)=Mν,0+XMν,1+YMν,2+ZMν,3.Example 3As a simple illustration, we consider a parameterization of a tensor product surface of bi-degree(1,2), i.e. a ruled surface, with the following data:w0,0=1,w0,1=1,w0,2=2,w1,0=1,w1,1=1,w1,2=2,b0,0=(1,0,0),b0,1=(1,0,1),b0,2=(0,0,1),b1,0=(1,1,0),b1,1=(1,1,1), andb1,2=(0,1,0). Choosingν=(1,1), the matrixS(1,1)is of size 12×16 and we find the matrixM1,1(ϕ)=[−1+X1−X+Z0Y−1+X+Z−2XY0−1+X2−2X+Z0Y−1Z−2XY−10].The family of matrices we have built in the previous section is particularly interesting because these matrices can be seen as implicit representations of a parameterized curve or surface, if the degreeνis not too small. In this section, we describe their main properties. Notice that most of them have been already proved in a more general setting using techniques from algebraic geometry and commutative algebra (see  [9,7,8,10]).Hereafter, we take again the notation of Section  2:ϕdenotes the parameterization (1) of a curve or a surface andMν(ϕ)(orMνfor short),ν⩾0, its associated family of matrices.By construction, the entries of the matricesMν,ν⩾0, are linear polynomials inR[X,Y,Z]. Actually, these matrices are a pencil of matrices, that is to say that there exist four matricesMν,i,i=0,…,3, whose entries are real numbers and such that (see (9))Mν(X,Y,Z)=Mν,0+XMν,1+YMν,2+ZMν,3.It follows that the matrixMν=Mν(X,Y,Z)can be evaluated at any pointP∈R3and that this evaluation is very simple since it corresponds to a linear combination of four matrices. In the following, we will denote it byMν(ϕ)(P), or simplyMν(P)if there is no possible confusion.LetP∈R3be a point such thatP=ϕ(s0)for some parameter values0. By construction ofMν, (6) holds and we hence get(12)[ψ1(s0)⋯ψmν(s0)]×Mν(P)=[L1(s0;P)⋯Lrν(s0;P)]=[0⋯0].Therefore, it is clear that a non trivial linear combination between the rows ofMνappears after evaluation at a pointPthat belongs to the image ofϕ(the blending functionsψi’s do not all vanish simultaneously). It turns out that there exists a “critical degree”ν0such that, for all matricesMνwithν⩾ν0, the above property characterizes the pointsPbelonging to the (algebraic) closure of the image ofϕ. For simplicity of presentation, from now on we will denote the image ofϕbyIm(ϕ)and its closure byIm¯(ϕ).To be more precise, we first give explicit values of this critical degree integerν0in each of the three cases treated in Section  2:•Section  2.1: ifϕparameterizes a rational Bézier curve of degreed⩾1thenν0≔d−1.Section  2.2: ifϕparameterizes a triangular rational Bézier surface thenν0≔2(d−1).Section  2.3: ifϕparameterizes a tensor-product rational Bézier surface thenν0≔(2d1−1,d2−1)(or by symmetryν0=(d1−1,2d2−1)).Recall that the integersrνandmνdenote the number of columns and rows, respectively, of the matrixMνfor allν⩾0(see (5)).Fact 1For all degreesν⩾ν0we haverν⩾mν, i.e. the matricesMνhave more columns than rows. In particular,rank(Mν(P))⩽mνfor all pointsP∈R3.Fact 2For all degreesν⩾ν0and all pointsP∈R3,rank(Mν(P))<mνif and only ifP∈Im¯(ϕ).The above properties show that for allν⩾ν0the matricesMν(ϕ)can be used as implicit representations of the parameterizationϕ. Compared to the more classical implicit representations in the form of polynomial equations in the variablesX,Y,Z, they are much more easy to compute and they allow us to treat both parameterized curves and surfaces in the same way.Definition 1For allν⩾ν0, the matricesMν(ϕ)are called implicit matrix representations (M-rep for short) of the parameterizationϕin degreeν.The proofs of Facts 1 and 2 can be found in  [9,8,10] for the cases of rational curves (Section  2.1), triangular (Section  2.2) and tensor-product (Section  2.3) rational surfaces respectively. They are independent of any choice of basis (i.e. choices forBν′andBν+d).Notice that a subtle hypothesis on the parameterizationϕis necessary, namely that the base points (i.e. the common roots off0,f1,f2,f3in the parameter space, including at infinity) have to be locally defined by at most two equations (which is assumed here for the sake of simplicity). If this is not the case, then one has to deal with some extraneous hyperplanes that appear in addition toIm¯(ϕ), but this is not a problem because these hyperplanes are well understood (see  [11] for more details).Notice also that the values given above for the critical degreeν0can be improved in some cases. For instance, for rational curvesν0can be decreased by the smallest degreeνsuch that there exists a non-trivial 4-tuple(g0,g1,g2,g3)satisfying (2), so at least by 1 if the curve is not a line (see  [9]). For the case of triangular rational surfaces,ν0can be decreased by the smallest degree of a curve in the parameter space going through all the base points, which is at least 1 if there exist base points (see  [8]). However, all these improved values depend on particular geometric features of the parameterizationϕand are hence not stable under numerical perturbations. This is why we emphasized the smallest values of the critical degree that only depend on the degree of thefi’s and that are hence numerically stable.Example 4Coming back to the examples given in Section  2, we see thatMνis an M-rep for allν⩾ν0=2in Example 1, butM1is actually also an M-rep because this curve is not a line.In Example 2,Mνis an M-rep of the sphere for allν⩾ν0=2, butM1is also an M-rep because the two cyclic points are base points.In Example 3, the matrixM(ν1,ν2)is an M-rep for all(ν1,ν2)⩾(1,1)(or⩾(0,3)). Notice thatM(1,1)is a square matrix, so a polynomial implicit equation of the ruled surface can be obtained by computing its determinant. A similar property holds forM0,3.Finally, although we choose to work in the affine spaceR3, there is no hidden difficulty at infinity. Indeed, denoting by(W:X:Y:Z)the homogeneous coordinates of the projective spaceP3(R)(with the convention(1:X:Y:Z)=(X,Y,Z)inR3), the pencil of matricesWMν,0+XMν,1+YMν,2+ZMν,3has the properties stated above inP3(R)and hence it provides an implicit matrix representation of the closure of the image ofϕinP3(R). Actually, one can even replace the field of real numbers by any other field (including the field of complex numbers) and the above properties, as well as the construction ofMν, still hold.LetP∈R3be a point such thatP=ϕ(s0)for some parameter values0. For any M-repMνof the parameterizationϕ, we have seen that the equality (12) holds so that the vector(13)[ψ1(s0)⋯ψmν(s0)]Tbelongs to the null space ofMν(P)T(the notation−Tstands for the matrix transpose).Fact 3IfP∈R3is a point such thatPhas a unique (counted properly) pre-image byϕ, then the dimension of the null space ofMν(P)Tis one.This property shows that an M-rep allows us to invert a pointP=ϕ(s0)on the curve or surface parameterized byϕifϕis proper andPdoes not belong to the self-intersection locus (notice that ifϕis not proper or ifPbelongs to the self-intersection locus, then inversion is not well-defined). Indeed, the computation of the null space ofMν(P)Tprovides a single vector[v1⋯vmν]Twhich is proportional to the vector (13). From here, the parameters0can be extracted without any difficulty. For instance, ifϕparameterizes a rational Bézier curve (Section  2.1), then looking at the ratio (but other ratios can be used as well)(v1:v2)=(B0d(s0):B1d(s0))=(1−s0:ds0)we deduce thats0=v2/(dv1+v2)(notice that the denominator can never vanish). Ifϕparameterizes a triangular (Section  2.2) or a tensor-product (Section  2.3) rational Bézier surface, we can proceed similarly and the computation of two ratios yields the two coordinates of the pre-image ofP.With an M-rep, it is hence possible to handle at the same time a non-singular pointP∈Im(ϕ)and its pre-image through a simple null space computation. This property can be very useful in many circumstances, such as for instance for splitting a curve at a point in space, or for dealing with trimmed surfaces.To simplify our notation, in the following we will denote by thecorankof a given matrixMthe difference between its number of rows and its rank. Equivalently,corank(M)is equal to the dimension of the left null space ofM.LetMνbe an M-rep of a parameterizationϕand letPbe a point inR3. We have seen (see Facts 1 and 2) thatcorank(Mν(P))=0if and only ifP∉Im¯(ϕ). Moreover, in Fact 3 we stated thatcorank(Mν(P))=1ifPis a non-singular point of the closure of the image ofϕ. It turns out that some even finer geometric properties ofϕcan be extracted from an M-rep. For the sake of completeness, we briefly mention them.Denote byϕ−1(P)the algebraic set of all the pre-images ofPbyϕin the parameter space over the field of complex numbers. Thus, ifP∉Im¯(ϕ)thenϕ−1(P)is empty. Otherwise,ϕ−1(P)can be either a finite set or an infinite set of points. Ifϕ−1(P)is finite, which is for instance always the case ifϕparameterizes a rational curve, then we denote byNPits cardinal number, counted properly with multiplicities. Ifϕ−1(P)is infinite, which can only occur ifϕparameterizes a surface, then it can be decomposed into the union of an algebraic plane curve and a finite set of points; we denote byDPthe degree of the curve.The proof of the following result is beyond the scope of this paper and can be found in  [12].Fact 4LetPbe a point inR3andMνbe an M-rep ofϕ.•Ifϕ−1(P)is finite, then for allν⩾ν0corank(Mν(P))=NP.Ifϕ−1(P)is infinite, then for allν⩾ν0corank(Mν(P))=DP⋅ν+CP.Two comments are in order about this fact. First, ifϕparameterizes tensor-product rational Bézier surface (Section  2.3),DPis a bi-degree, sayDP=(D1,D2), andDP⋅νis the “scalar product”D1⋅ν1+D2⋅ν2whereν=(ν1,ν2). Second, we mention that the quantityCPhas a geometric meaning. It gathers information about the genus of the curve component ofϕ−1(P)and the cardinal number of the remaining finite part, counted properly with multiplicity. In algebraic geometry, the linear polynomialDP⋅ν+CPis actually known as the Hilbert polynomial ofϕ−1(P)(see e.g.  [13, Chapter 6, Section 4]).A direct consequence of Fact 4 is that the comparison of the corank of two or three successive M-reps (MνandMν+1for a triangular surface andMν,Mν+(0,1),Mν+(1,0)for a tensor-product surface) allows us to determine ifϕ−1(ϕ)is finite or infinite and at the same time to determineNPorDP. Another interesting observation is that a small drop of rank can only arise at pointsPsuch thatϕ−1(P)is finite. We refer the reader to  [12] for more details.In this section, we will define a real evaluation function of an M-repMνat a given pointPby means of the singular values of the matrixMν(P). For any pointP∈R3, we will hence get a real number denotedδMν(P)∈R. We will show that this real evaluation function behaves like a classical Euclidean distance function. As a by-product, we will also get a new determinantal formula for implicitizing a curve or surface over the real numbers. We begin with a quick review of the SVD.LetA∈Rm×rbe a real matrix and assume for ease of presentation thatm⩽r(ifm>rthen simply apply what follows toAT). The singular value decomposition (SVD) ofAis a decomposition of the formA=UΣVTwhereU=[u1,…,um]∈Rm×mandV=[v1,…,vr]∈Rr×rare real orthogonal matrices and the matrixΣ=[σ10⋯00⋯00σ2⋱⋮⋮⋮⋮⋱⋱00⋯00⋯0σm0⋯0]∈Rm×rhas nonnegative diagonal elements appearing in the conventional decreasing orderσ1⩾σ2⩾⋯⩾σm⩾0.The numbersσi, also denotedσi(A), are called the singular values ofAwhile the vectorsuiandviare called the left and right singular vectors ofA, respectively. Notice that the singular values ofAare precisely the lengths of the semi-axes of the ellipsoidal image of the unit sphere under the mappingx→Ax. We refer the reader to  [14, Section 2.5.3] for the proof of the existence of the SVD.The most important property of the SVD for our purposes is that it is a powerful tool for deciding the rank of a matrix. We will come back to this in the next section when dealing with numerical computations. For now, we will only need the following elementary property:(14)rank(A)=max{i:σi(A)≠0}.Consider a parameterizationϕof a curve or surface as in (1) and letMνbe an M-rep ofϕ. Recall from Section  2 that the matrixMνhasmνrows andrνcolumns.Definition 2For any pointPinR3, the real evaluation function ofMνatPis defined byδMν:R3→R⩾0≔{x∈R:x⩾0}P↦δMν(P)≔∏i=1mνσi(Mν(P))whereσi(Mν(P))are the singular values of the matrixMν(P)∈Rmν×rν.For any pointP,δMν(P)⩾0and Fact 2 and (14) imply that(15)δMν(P)=0⇔P∈Im¯(ϕ).Therefore, the functionδMν(P)can be seen as a sort of distance function of the pointPtoIm¯(ϕ)(i.e. the curve or surface parameterized byϕ). This is similar to the algebraic distance function obtained by returning the absolute value of the evaluation of an implicit polynomial equationF(X,Y,Z)=0of a parameterized surface:|F(P)|=0if and only ifPbelongs to the surface.It turns out that the evaluation functionδMν(P)can actually be compared with the usual Euclidean distance function ofPtoIm¯(ϕ)⊂R3. To start, we first show that the square ofδMνis an algebraic function and point out an interesting consequence.LetMνbe an M-rep of the parameterizationϕandPa point inR3. From the SVD ofMνand the definition ofδMν(P), we getδMν(P)2=∏i=1mνσi(Mν(P))2=det(Mν(P)Mν(P)T).Since the entries ofMνare linear polynomials inR[X,Y,Z], we deduce thatδMν(P)2is a polynomial function ofP. Therefore, we define the polynomialΔMν(X,Y,Z)≔det(MνMνT)∈R[X,Y,Z].For anyP∈R3we haveΔMν(P)=δMν(P)2.Theorem 1The real algebraic set{(x,y,z)∈R3:ΔMν(x,y,z)=0}⊂R3is equal toIm¯(ϕ). In other words,ΔMν(X,Y,Z)is a real implicit equation of the curve or surface parameterized byϕ.ProofIt is a direct consequence of the definition of the polynomialΔMνand (15). Another way to see this result is to apply the Binet–Cauchy formula for expanding the determinant of the productMνMνT. Indeed, this formula yields(16)det(MνMνT)=∑1⩽i1<i2<⋯<imν⩽rν([Mν]i1,i2,…,imν)2where[Mν]i1,i2,…,imν(X,Y,Z)is the minor ofMνcorresponding to the columnsi1,i2,…,imν. Then, the conclusion follows from Fact 2.□The matrixMνMνTis a symmetric square matrix of sizemνand its entries are quadratic polynomials inR[X,Y,Z]. Its determinantΔMνis hence a degree2mpolynomial and it is moreover a sum of squares by (16). Looking more precisely at the three cases detailed in Section  2 withν=ν0, we get:•Section  2.1: ifϕparameterizes a rational Bézier curve of degreedthenmν0=ν0+1=d,MνMνTis of sizedandΔMνis a polynomial of degree2d.Section  2.2: ifϕparameterizes a triangular rational Bézier surface of degreedthenmν0=d(2d−1)andΔMνis a polynomial of degree2d(2d−1).Section  2.3: ifϕparameterizes a tensor-product rational Bézier surface of bi-degree(d1,d2)thenmν0=2d1d2andΔMνis a polynomial of degree4d1d2.Theorem 1 shows that implicit matrix representations allow us to produce square matrices whose determinant is an implicit polynomial equation for a parameterized curve or surface over the real numbers. In general, this equation is not of the lowest possible degree, see e.g.  Example 5. Notice too that Theorem 1 can be extended to the field of complex numbers by taking the Hermitian matrix transpose instead of the simple matrix transpose (the Hermitian transpose of a complex matrix is obtained by taking its transpose and then by taking the complex conjugate of each entry).Example 5Taking again Example 2, the computation of the productM1M1Tyields a 3×3-matrix which is symmetric and has quadratic entries inR[X,Y,Z]. Its determinantΔM1(X,Y,Z)is equal to((X−Y+1)2+2Y2+Z2)×(X2+Y2+Z2−1)2.The right factor is the usual implicit equation of the sphere. The left factor vanishes over the real numbers only at the point(X,Y,Z)=(−1,0,0)which belongs to the sphere.In the field of real algebraic geometry, the Łojasiewicz inequality is a classical result that gives information concerning the relative rate of growth of two continuous semi-algebraic functions (see for instance  [15]). In our context, it can be used to compare the growth of the evaluation function given in Definition 2 with the one of the usual Euclidean distance betweenPandIm¯(ϕ). This latter will be denoted byd(P,Im¯(ϕ))≔min{‖P−Q‖2:Q∈Im¯(ϕ)}.Theorem 2LetK⊂R3be a compact semi-algebraic set. Then there exist two positive integersn1,n2and two positive real numbersc1,c2such that∀P∈Kd(P,Im¯(ϕ))n1⩽c1⋅δMν(P)and∀P∈KδMν(P)n2⩽c2⋅d(P,Im¯(ϕ)).ProofBoth functionsδMνandd(−,Im¯(ϕ))are continuous, and they are also semi-algebraic as they are the square roots of positive algebraic functions. Moreover, the zero locus of these two functions are equal:{P∈R3:d(P,Im¯(ϕ))=0}={P∈R3:δMν(P)=0}=Im¯(ϕ).It follows that, after restriction to the compact semi-algebraic setK, all the hypothesis for applying Łojasiewicz inequality are fulfilled (see  [15, Section 6]) and we thus get the two inequalities stated in this theorem.□This result shows that the evaluation functionδMνbehaves similar to a distance function: its value increases as one gets far fromIm¯(ϕ)and decreases as one gets close to it until vanishing exactly on it. The compact semi-algebraic setKcan be taken as a 3D bounding-box, but notice that there exists a version of Łojasiewicz inequality whereKis not assumed to be a compact set (for instanceKcould beR3). Finally, notice that determining the integersn1,n2and constantsc1,c2is in general difficult, although some effective bounds are known. We refer the reader to  [16] (and the references therein; see also  [17]) for more details.Implicit matrix representations are interesting not only for their nice geometric properties, but also because all the experiments we have conducted have shown a particularly good numerical stability. One can expect that this is a consequence of the design of M-reps that makes them very well adapted to the SVD which is one of the basic and most important tool of numerical linear algebra. Indeed, as we will explain in this section, all the properties of M-reps can be exploited using numerical computations by means of the SVD, even their construction. In addition, we provide some rigorous results on the properties of M-reps under numerical computations in order to give more insight on the good numerical behavior of M-reps we have observed in our experiments.In the presence of roundoff errors and data perturbations, every matrix tends to be a full rank matrix and hence determining its original rank becomes nontrivial. A strict and operational definition of “numerical rank”, which is widely used in the field of numerical linear algebra, takes the following form.Definition 3[14, Section 2.5.5]The numerical rank of a matrixA, with respect to the toleranceϵ>0, is given byrank(A,ϵ)=min{rank(B):‖A−B‖2⩽ϵ}.An important property of the SVD is that for all nonnegative integersk<rank(A),(17)σk+1(A)=minrank(B)=k‖A−B‖2which means that the singular valueσk+1(A)indicates how near the matrixAis to a matrix of rankk(see  [14, Theorem 2.5.3]). Therefore, settingrϵ≔rank(A,ϵ), we see thatσ1(A)⩾⋯⩾σrϵ(A)>ϵ⩾σrϵ+1(A)⩾⋯⩾σm(A)with the notationA∈Rm×r,m⩽r. The numerical rank ofAcan hence be determined by inspecting the singular values ofA:(18)rank(A,ϵ)≔max{k:σk(A)>ϵ}.Due to computer arithmetic, the calculated singular values may be different from the exact singular values. However, one can show (see  [14, Section 5.5.8]) that the computed singular values ofAare the exact singular values of a slightly perturbed matrixA+Ewhere‖E‖2⩽ρu‖A‖2; hereuis the roundoff unit (see  [14, Section 2.4.2]) andρis a slowly growing function ofmandr. Therefore, in this context the toleranceϵis usually chosen in this form, so that it makes sense in (18) to use the computed singular values ofAin place of the exact singular values ofA.Letϕbe a parameterization as in (1). As described in Section  2, an M-repMνofϕis obtained as the null space of the multiplication matrixSνwhich is built directly from the control points and weights ofϕ(see e.g. (8)). We will describe how this computation can be done numerically by means of the SVD.Consider a matrixAand its SVDA=UΣVT∈Rm×rwhereV=[v1,…,vr]∈Rr×r. It is easy to check that‖Avi‖2=σi(A),i=1,…,r(settingσi(A)=0ifi>max(m,r)). So, ifσi(A)is “small” compared to the norm‖A‖2=σ1(A), then the corresponding right singular vectorviis “almost” a null vector forA. It follows that the determination of the numerical rankrϵofA, with the toleranceϵ, yields a numerical null space ofAwhich is the vector space spanned by the vectorsvrϵ+1,…,vr.From these considerations, we deduce thatMνcan be read off the SVD of the matrixSν. Indeed, with the appropriate toleranceϵ, this SVD yields a numerical rankrϵand the lastr−rϵcolumns in the matrixVyield the numerical null space ofSν. It is of the form (8) and hence provides a numerical approximation ofMνgiven byMν,0+XMν,1+YMν,2+ZMν,3.The quality of this numerical approximation is essentially governed by the ratioσ1/σrϵ. To be more precise, for a given matrixA, denote byNk(A)the vector space spanned by the vectorsvk+1,…,vr. LetA+Ebe the small perturbation of the matrixAcorresponding to the computation of its singular values (see Section  5.1), so that the computed singular values ofAare the exact singular values ofA+E. It can be shown ([18, Theorem 3.2.1], see also  [14, Section 8.6.1]) that if‖E‖2⩽σk−σk+1, thendist(Nk(A),Nk(A+E))⩽σ1σk⋅‖E‖2‖A‖2wheredist(−,−)stands for the distance between vector spaces (see  [14, Section 2.6.3]). In our setting, we deduce that the SVD ofSνwill give an accurate and robust numerical null space (hence numerical M-repMν), namelyNr−rϵ+1(Sν), if there is a distinct gap betweenσrϵandσrϵ+1with respect toσ1.Example 6Taking again Example 2, the computation of the SVD of the 10×12 multiplication matrixS1returnsσ1=3.52756346141076,σ8=0.452628072697747,σ9=3.31295025717184461×10−11.We deduce that the numerical rank is equal to 8 and hence find a null space of dimension 4. The numerical M-repM1(ϕ)we get this way is printed in Fig. 1.The numerical computation of M-reps have some similarities with approximate implicitization  [19,20], as the use of the SVD, but it is different. In particular, with M-reps there is no need to guess or estimate a good degree for the approximate implicit representation, it is provided by the method: this is the integerν0(see Section  3.2). Its determination is actually the difficult part of the M-rep approach for which tools from commutative algebra and algebraic geometry are necessary.LetMνbe an M-rep of a parameterizationϕas in (1), and letPbe a point inR3. The drop-of-rank property ofMνis the fact that the rank ofMνdrops atPif and only ifP∈Im¯(ϕ). Therefore, it seems quite natural to compute the SVD ofMν(P)for deciding ifPbelongs toIm¯(ϕ). However, one has to be careful because there is a subtle difficulty. Indeed, the theory of the SVD has been shown to be very powerful when dealing with the whole space of dense matrices. For instance, looking at (17) it is clear that the matrixBcan be any matrix without a particular structure, even ifAhas such a particular structure itself. In our setting, we are handling M-reps which are pencils of matrices (see (9)) and hence are very particular. Therefore, there is no guarantee that the detection of a numerical drop of rank at a given pointQcorresponds to the existence of another pointPin its neighborhood such that the exact rank ofMν(P)drops. This is because M-reps have this particular structure of being a pencil of matrices. In general, working with such particular subspaces of matrices may lead to difficulties with the SVD. However, all the experiments we have made with M-reps have always shown a very good numerical behavior. In order to explain and clarify these observations, we prove two results showing that a given pointPis close toIm¯(ϕ)if and only if the numerical rank ofMνdrops atP. In the following, it is assumed that M-reps are computed as explained in Section  5.2. Recall also the notation that an M-repMνis of sizemν×rν.Proposition 1LetP,Qbe two points inR3. For allk=1,…,mν, we have|σi(Mν(P))−σi(Mν(Q))|⩽‖P−Q‖2.ProofWe begin with a useful remark: the matrixMν(P)can be computed as described in Section  3.1, but it is not hard to check that it can also be computed as the product of two matrices. Indeed, to any pointP=(x,y,z)∈R3we associate the following matrix(19)Pν=[diag(1)diag(x)diag(y)diag(z)]where each block is a diagonal matrix of sizemνwith the same repeated element on the diagonal (from top to bottom, the diagonal of the first block is filled with 1, the diagonal of the second block with x, and so on). Then, denoting byNνthe null space ofSν(see (8)), we get that(20)Mν(P)=NνTPν.Now, by applying a classical inequality about singular values (see  [14, Corollary 8.6.2]), we get|σi(Mν(P))−σi(Mν(Q))|⩽‖Mν(P)−Mν(Q)‖2.But using (20) and a standard inequality for the 2-norm of matrices, we obtain‖Mν(P)−Mν(Q)‖2=‖NνT(Pν−Qν)‖2⩽‖NνT‖2‖Pν−Qν‖2.The matrixPν−Qνis made of columns that are orthogonal vectors whose norm is equal to‖P−Q‖2, so‖Pν−Qν‖2=‖P−Q‖2.The matrixNνis made of orthonormal columns (see Section  5.2), so‖NνT‖2=‖Nν‖2=1and the conclusion follows.□Corollary 1LetPbe a point inR3andϵ>0be a tolerance. For all pointsPϵ∈R3such that‖Pϵ−P‖2⩽ϵwe haverank(Mν(Pϵ),ϵ)⩽rank(Mν(P)).ProofFor all integersk>rank(Mν(P)),σk(Mν(P))=0and the conclusion follows by applying Proposition 1.□This result shows that if a pointPis close toIm¯(ϕ)then the numerical rank ofMνdrops atP. Now, we examine the converse.Proposition 2LetPbe a point in compact semi-algebraic setK⊂R3,ϵ>0be a tolerance and setrϵ≔rank(Mν(P),ϵ),σ1≔σ1(Mν(P)). There exist a positive integern1and a constant real numberc1such thatd(P,Im¯(ϕ))⩽(c1σ1rϵϵmν−rϵ)1n1.Moreover,σ1⩽(1+‖P‖22)12.ProofBy Theorem 2, there exist a positive integern1and a constant real numberc1such that for all pointsP∈Kd(P,Im¯(ϕ))n1⩽c1δMν(P)(P)=c1∏k=1mνσk(Mν(P)).Now, by the property of the numerical rank, the singular values ofMν(P)satisfy the inequalitiesσ1⩾⋯⩾σrϵ>ϵ⩾σrϵ+1⩾⋯⩾σmν.Therefore, we deduce that∏k=1mνσk(Mν(P))⩽σ1rϵϵmν−rϵand henced(P,Im¯(ϕ))n1⩽c1σ1rϵϵmν−rϵ.To prove the second claimed inequality, we observe thatσ1=‖NνTPν‖2by (20). It follows thatσ1⩽‖NνT‖2‖Pν‖2. But‖NνT‖2=1(see the proof of Proposition 1) and from the definition of the matrixPν, it is clear that‖Pν‖2⩽(1+‖P‖22)12.From here, the conclusion follows.□This result shows that ifPis a point inR3such that the numerical rank ofMν(P)drops, thenPhas to be “close” toIm¯(ϕ)(notice that ifPis in a bounded box, thenσ1is bounded above in terms of‖P‖2). Moreover, it also shows that the morePis singular (i.e.rϵdecreases), the morePis close toIm¯(ϕ).Notice, however, that Proposition 2 is not very helpful in practice because the constantsn1andc1are difficult to predict (they follow from the Lojasiewicz inequalities). Nevertheless, it reinforces our experimental observations showing the very good numerical behavior of M-reps.Given a parameterization (1), we have shown in Section  3.3 that the inversion problem can be solved by computing a one-dimensional null space. Exploiting the capability of the SVD for computing numerical null space, as explained in Section  5.2, it becomes possible to treat the inversion problem with numerical computations.To be more precise, letMνbe an M-rep of a parameterizationϕ, as in (1), and consider a given toleranceϵ. LetPbe a point inR3that has a unique pre-image viaϕ, i.e. such thatP=ϕ(s0)andcorank(Mν(P))=1. By Fact 3, we know thats0can be extracted from the one-dimensional null spaceNmν−1(Mν(P)T)by a ratio computation (see Section  3.3). We will denote byuthe vector spanning this null space, it is the last column of the matrixUin the SVD ofMν(P).Now, letPϵ∈R3be such that‖Pϵ−P‖2⩽ϵ, so thatrϵ≔rank(Mν(P),ϵ)<mνby Corollary 1. As explained in Section  4.1, determining the numerical rankrϵis done by computing the SVD ofMν(Pϵ)=UϵΣϵVϵT. Denote byuϵ∈Rmνthe vector corresponding to the last column of the matrixUϵ. By the discussion in Section  5.2, we deduce thatdist(uϵ,u)⩽σ1σmν−1‖Mν(Pϵ)−Mν(P)‖2σ1⩽σ1σmν−1ϵσ1.Therefore, it appears that if there is a distinct gap betweenσmν(Mν(Pϵ))andσmν−1(Mν(Pϵ)), then the numerical rank is clearly equal to one andumνyields an accurate approximation of the null space ofMν(P)T. Moreover, ifθdenotes the angle betweenuϵandu, thendist(uϵ,u)=sin(θ)by definition of this distance function (see  [14, Section 2.6.3]). It follows that the numerical values of the pre-images0computed from the ratios ofuϵanduare equal up to the numerical precisionϵ.Example 7Take again the simple Example 2 of the unit sphere. IfP=(1/3,1/3,1/3), then the exact null space ofM1(P)Tis generated by the vector(21)[(3−1)/(3+1)1/(3+1)1/(3+1)]≈[0.26794919250.36602540370.3660254037]where the numerical precision is 10 digits. Notice that we chose the generator of this null space which is normalized with respect to the 1-norm. This is because our M-rep has been built with Bernstein bases which form a partition of unity. Therefore, ifs0=(u0,v0)∈R2is the pre-image ofPthen (21) is equal to the vector[B0,01(u0,v0),B0,11(u0,v0)=v0,B1,01(u0,v0)=u0]T.It follows that(22)u0=v0=1/(3+1)≈0.3660254037.Now, we do the computations by using the numerical M-rep given in Fig. 1 and takePϵas the numerical approximation ofPwith 10 digits precision. The computed singular values ofM1(Pϵ)areσ1=0.7637626159,σ2=0.4902332028,σ3=2.3855877838.10−10and the last column of the matrixUof the SVD is the 2-norm unitary vector[0.45970084310.62796303040.6279630302]T.By normalizing this vector with the 1-norm, we recover, as expected, the same approximation ofu0andv0with 10 digits. Now, we add a perturbation of 10−5 to each coordinate of the pointPϵ. The singular values ofM1(Pϵ)becomeσ1=0.7637701751,σ2=0.4902374484,σ3=0.0000114631and the last column of the matrixUof the SVD is the 2-norm unitary vector[0.45969946810.62796353370.6279635335]T.By normalizing this vector with the 1-norm, we finally getu0≈0.3660257759,v0≈0.3660257758.Comparing these values with (22), we check that up to 5 digits precision, the approximation ofu0andv0are correct.Our main motivation for introducing M-reps was to tackle intersection problems by generalizing the approach initiated by Canny and Manocha for non-singular matrix representations  [3]. This approach consists in combining matrix-based implicit representations with generalized eigenvalues computations. We have extended it to M-reps recently: see  [21,9] for the curve/surface intersection and  [9] for the curve/curve intersection by means of M-reps. Here, we quickly review how the properties of M-reps allow us to intersect a parameterized curve with another parameterized curve or surface that is represented by an M-rep, i.e. a curve/M-rep intersection problem.For simplicity and clarity, let us consider the intersection between a ray and a parameterized surface (e.g. a Bezier patch obtained after the decomposition of a NURBS into Bézier patches [22, Chapter 5, Section 5.3]). This intersection problem is intensively used for ray tracing NURBS. A classical approach consists of computing an implicit representation of the ray as the intersection of two planes given by linear equations inR3. Then, substituting the surface parameterization into these two equations yields a polynomial system that can be solved via the Newton method. The intersection points are then obtained in the parameter space of the surface, so one can compute the normal of the surface at these points without difficulty (this is required for light reflection for instance).Another way to proceed is to compute an implicit equation of the parameterized surface, to substitute the ray parameterization in this equation and solve a univariate polynomial. However, the implicitization step is very hard in general, due to the presence of base points. But M-reps have been designed to overcome this difficulty and are very easy to compute. So, letMνbe an M-rep of the surface parameterization. Substituting the ray parameterization intoMνyields a matrix whose entries are univariate linear polynomials in the parameter of the ray, sayt. Finding the intersection points amounts to finding the values oftsuch that this matrix is not full rank. These values are the generalized eigenvalues of this matrix (which is actually a univariate pencil of matrices) and, after a reduction step based on the SVD, they can be found by using algorithms that have been developed by the community of numerical linear algebra (see for instance  [23, Chapter 4]). Using the ray parameterization, we then obtain the intersection points inR3. Now, thanks to the inversion property of M-reps, one can find the pre-image of these intersection points in the surface parameter space and hence compute the normal to the surface at these points (notice that intersection points that are singular points on the surface do not have a well defined normal vector). We refer the reader to  [21] for the details (see also  [24] for the linearization step in the Bernstein basis instead of in the power basis). Notice too that a study of the numerical accuracy in generalized eigenvalue computations can be found in  [25]. In Fig. 2, a ray tracing of the sphere given in Example 2 is shown. It has been obtained by Valentin Michelet (an engineering student) who developed his own ray tracer from scratch by computing the ray/surface intersection by means of M-reps. Two other illustrations are given in Fig. 3.It should be clear to the reader that the above method can be applied with any parameterization that admits an M-rep. Therefore, parameterized curve/curve and parameterized curve/surface intersections can be treated exactly in the same way. An implementation of these intersections has been done in the algebraic geometric modeler Axel, in the plugin Shape; it is freely available at the URL: http://axel.inria.fr.

@&#CONCLUSIONS@&#
