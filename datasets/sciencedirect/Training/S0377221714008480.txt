@&#MAIN-TITLE@&#
Robust solutions to multi-objective linear programs with uncertain data

@&#HIGHLIGHTS@&#
We consider multi-objective linear programming problems in the face of data uncertainty.The uncertainty affects both the objective function and the constraints.We give a formula for radius of robust feasibility guaranteeing constraint feasibility of the robust counterpart under affine data parametrization.We characterize robust weakly efficient solutions that are immunized against objective matrix rank-one uncertainty.We examine some classes of commonly used constraint data uncertainty sets under which the robust weakly efficiency of robust feasible solutions can be numerically checked.

@&#KEYPHRASES@&#
Robust optimization,Multi-objective linear programming,Data uncertainty,Robust feasibility,Robust weakly efficient solutions,

@&#ABSTRACT@&#
In this paper we examine multi-objective linear programming problems in the face of data uncertainty both in the objective function and the constraints. First, we derive a formula for the radius of robust feasibility guaranteeing constraint feasibility for all possible scenarios within a specified uncertainty set under affine data parametrization. We then present numerically tractable optimality conditions for minmax robust weakly efficient solutions, i.e., the weakly efficient solutions of the robust counterpart. We also consider highly robust weakly efficient solutions, i.e., robust feasible solutions which are weakly efficient for any possible instance of the objective matrix within a specified uncertainty set, providing lower bounds for the radius of highly robust efficiency guaranteeing the existence of this type of solutions under affine and rank-1 objective data uncertainty. Finally, we provide numerically tractable optimality conditions for highly robust weakly efficient solutions.

@&#INTRODUCTION@&#
Consider the deterministic multi-objective linear programming problem(P¯)V-min{(c¯1⊤x,…,c¯m⊤x):a¯j⊤x≥b¯j,j∈J},where V-min  stands for vector minimization,c¯i∈Rn(interpreted as a column vector) for i ∈ I ≔ {1, …, m}, the symbol ⊤ denotes transpose, x ∈Rnis the decision variable, and(a¯j,b¯j)∈Rn×R,for j ∈ J ≔ {1, …, p}, are the constraint input data of the problem. The real m × n matrixC¯whose rows are the vectorsc¯i,i ∈ I, is called the objective matrix. The problem(P¯)has been extensively studied in the literature (see, e.g., the overviews Branke et al., 2008; Ehrgott, 2005), where perfect information is often assumed (that is, accurate values for the input quantities or parameters), despite the reality that such precise knowledge is rarely available in practice for real-world optimization problems.The data of real-world optimization problems are often uncertain (that is, they are not known exactly at the time of the decision) due to estimation errors, prediction errors, or lack of information. Scalar uncertain optimization problems have been traditionally treated via sensitivity analysis which estimates the impact of small perturbations of the data in the optimal value, while robust optimization, which provides a deterministic framework for uncertain problems, has recently emerged as a powerful alternative approach (see, for instance, Ben-Tal and El Ghaoui, 2009; Bertsimas and Sim, 2004; El Ghaoui and Lebret, 1997; Goberna et al., 2013; Jeyakumar and Li, 2010).Particular types of uncertain multi-objective linear programming problems have already been studied, e.g., Sitarz (2008) considers changes in one objective function via sensitivity analysis, while Pando et al. (2013) consider changes in the whole objective functionx↦C¯xand Goberna et al. (2014) considers change in the constraints by using different robustness approaches. The purpose of the present work is to study multi-objective linear programming problems in the face of data uncertainty both in the objective function and constraints from a robustness perspective.Following the robust optimization framework, the multi-objective problem(P¯)in the face of data uncertainty both in the objective matrix and in the data of the constraints can be captured by a parameterized multi-objective linear programming problem of the form(P)V-min{(c1⊤x,…,cm⊤x):aj⊤x≥bj,j∈J}where the input data, ci, i ∈ I, and (aj, bj), j ∈ J, are uncertain vectors,C:=(c1,…,cm)∈U⊂Rn×mand(aj,bj)∈Vj⊂Rn+1,j ∈ J and the setsUandVj,j ∈ J, are specified uncertainty sets that are bounded, but often infinite sets. By enforcing the constraints for all possible uncertainties withinVj,j ∈ J, the uncertain problem becomes the uncertain multi-objective linear semi-infinite programming problem(1)V-min{(c1⊤x,…,cm⊤x):aj⊤x≥bj,∀(aj,bj)∈Vj,j∈J},where(c1,…,cm)∈Uand whose feasible set,(2)X:={x∈Rn:aj⊤x≥bj,∀(aj,bj)∈Vj,j∈J},is called robust feasible set of (P) and x ∈ X is called arobust feasible solution.Following the recent work on robust linear programming (see Ben-Tal and El Ghaoui, 2009), some of the key questions of multi-objective linear programming under data uncertainty include:I.(Guaranteeing robust feasible solutions) How to guarantee non-emptiness of the robust feasible set X for specified uncertainty setsVj,j∈J?(Guaranteeing and identifying robust efficient solutions) Which robust feasible solutions of (P) are robust efficient solutions (see the paragraph below) that are immune to objective data uncertainty and what are the mathematical characterizations that identify robust efficient solutions? How to guarantee the existence of robust efficient solutions?(Numerical tractability of robust efficient solutions) For what specified classes of uncertainty setsUandVj,j ∈ J, the robust efficient solution characterizations can be numerically checked using existing multi-objective programming techniques?In this paper, we provide some answers to the above questions for the uncertain multi-objective linear programming problem (P) in the face of data uncertainty by focusing on two choices of the robust optimal solutions: the first one is called a minmax robust efficient solution or simply robust efficient solution following the approach widely used in robust scalar optimization problem (see also Ehrgott et al. (2014); Kuroiwa and Lee (2012) for recent development), and corresponds to an efficient solution to a deterministic worst-case (minmax) multi-objective optimization problem; the second one is called highly robust efficient solution as in Ide and Schöbel (2013) and Kuhn et al. (2013) (see also Sitarz, 2008; Pando et al., 2013, Section 4), and consists of the preservation of the efficiency for all(c1,…,cm)∈U. So, the existence of this type of solution implies that the uncertainty setUis small in some sense (e.g., Cartesian products of balls inRnor segments inRn×memanating from some fixed data(c¯1,…,c¯m)). To compensate the “smallness” of the uncertainty set, we focus our analysis on the larger class of highly robust solutions: highly robust weakly efficient solutions. On the other hand, in (Pando et al., 2013, Section 4), highly robust efficient solutions are considered instead of highly robust weakly efficient solutions. For the convenience of the reader, other notions of robust solutions are summarized in Appendix A.Our key contributions are outlined as follows:(1)We first introduce the concept of radius of robust feasibility in Section 3, guaranteeing non emptiness of the robust feasible set X of (P) under affinely parameterized data uncertainty. This concept is inspired by the notion of consistency radius used in linear semi-infinite programming in order to guarantee the feasibility of the nominal problem under perturbations preserving the number of constraints (Cánovas et al., 2005, Cánovas et al., 2011). We derive a formula for the effective computation of the radius of robust feasibility that also applies to single-objective linear programming under the same type of uncertainty.We examine the robust weakly efficient solution of an uncertain multi-objective linear programming problem in Section 4, and establish numerically tractable mathematical characterizations of robust weakly efficient solutions under various data uncertainty.We present, in Section 5, an explicit formula for the radius of highly robust efficiency, i.e., the greatest value of certain parameter associated with two families of uncertainty sets for the objective data such that the corresponding multi-objective linear programming problems have highly robust weakly efficient solutions. The mentioned families are formed by Cartesian products of balls inRnand by segments inRm×nin the direction of rank-1 matrices (the same type of uncertainty considered in Pando et al., 2013, Section 4). Recall that rank-1 matrices are the products of non-zero column vectors by non-zero row vectors (see Osnaga, 2005 for other characterizations). These matrices are frequently used in computational algebra (as building blocks for more complex matrices), in conic optimization (as the rank-1 matrices are the extreme rays of the semidefinite cone), and in statistics (as the singular value decomposition gives the best rank-1 approximation of a given matrix with respect to the Frobenius and the spectral norms).We finally provide, in Section 6, numerically tractable mathematical characterizations of highly robust weakly efficient solutions under various data uncertainty.We begin this section introducing the necessary notation and concepts on multi-objective linear programming. We denote by 0nand ‖ · ‖ the vector of zeros and the Euclidean norm inRn,respectively. The closed unit ball and the distance associated to the above norm are denoted byBnand d, respectively. GivenZ⊂Rn,int Z, cl Z, bd Z, and conv Z denote the interior, the closure, the boundary and the convex hull of Z, respectively, whereasconeZ:=R+convZdenotes the convex conical hull of Z∪{0n} . Forx,y∈Rm,we write x ≤ y (x < y) when xi≤ yi(xi< yi, respectively) for all i ∈ I. The simplex Δmin the space of criteriaRmis defined asΔm:={λ∈R+m:∑i=1mλi=1}.The following known dual characterizations of solutions of semi-infinite linear inequality systems play key roles in the next section in developing radius of robust feasibility formulae.Lemma 1Goberna and López, 1998, Corollaries 3.1.1 and 3.1.2Let T be an arbitrary index set. Then,{x∈Rn:ut⊤x≥vt,t∈T}≠∅if and only if (0n, 1)∉cl cone{(ut, vt): t ∈ T}. In that case, u⊤x ≥ v holds for anyx∈Rnsuch thatut⊤x≥vt,∀t ∈ T, if and only if(3)(u,v)∈cl{cone{(ut,vt):t∈T}+R+(0n,−1)}.We now apply Lemma 1 to the robust feasible setX:={x∈Rn:aj⊤x≥bj,∀(aj,bj)∈Vj,j∈J}.Proposition 2Feasibility and polyhedrality of XLet X be as in (2). Then the following statements hold:(i)X ≠ ∅ if and only if(0n,1)∉clcone{∪j∈JVj}.If X ≠ ∅ and the uncertainty setsVjare all polyhedral sets, then X is a polyhedral set too.(i) It is a straightforward consequence of Lemma 1.(ii) Assume that X ≠ ∅. If the uncertainty sets are polyhedral, we can writeVj=convEj+coneDj,withEjandDjfinite sets, for each j ∈ J. Since the cone in (3) iscl{cone{∪j∈JVj}+R+(0n,−1)}=cone{∪j∈J(Ej∪Dj)}+R+(0n,−1)and, by the separation theorem, two non-empty closed convex sets coincide if and only if they have the same linear consequences, we haveX={x∈Rn:a⊤x≥b,(a,b)∈∪j∈J(Ej∪Dj)}.Hence, the conclusion follows.□Concerning Proposition 2, if the uncertainty setVjcontains no line, thenEj,defined as in the proof of (ii) of Proposition 2, is the set of extreme points ofVj. In particular, ifVjis a compact convex set for each j ∈ J and the strict robust feasibility condition(4){x∈Rn:aj⊤x>bj,∀(aj,bj)∈Vj,j∈J}≠∅holds, thencone{∪j∈JVj}is closed (Goberna and López, 1998, Theorem 5.3 (ii)) and this in turn implies (Goberna and López, 1998, p. 81) that the so-called characteristic coneK(V):=cone{∪j∈JVj}+R+{(0n,−1)},(to be used later) is closed too. Moreover, according to Goberna and López, 1998, Theorem 9.3, X is a compact set if and only if(0n,−1)∈intK(V). Particular cases of Proposition 2 (ii) can be found in the literature (see Ben-Tal and El Ghaoui, 2009 and references therein).In this section, we first discuss the feasibility of our uncertain multi-objective model under affine constraint data perturbations. In other words, for any given vectorsc¯i∈Rn,i ∈ I, we study the feasibility of the problem(Pα)V-min(c¯1⊤x,…,c¯m⊤x)s.t.aj⊤x≥bj,∀(aj,bj)∈Vj,j∈J,for α ≥ 0, where the uncertain set-valued mappingVj,for j ∈ J ≔ {1, …, p}, takes the form(5)Vj:=(a¯j,b¯j)+αBn+1,and the linear system{a¯j⊤x≥b¯j,j∈J}is assumed to be feasible.The radius of robust feasibility,ρ(V),associated toV:=∏j=1pVjwithVjas in (5), is defined to be(6)ρ(V):=sup{α∈R+:(Pα)isfeasible}.By Lemma 1, we first observe that the radius of robust feasibilityρ(V)is a non-negative real number since, given j ∈ J,(0n,1)∈(a¯j,b¯j)+αBn+1for a positive large enough α, in which case the corresponding problem (Pα) is not feasible.The next result provides a formula for the radius of robust feasibility which involves the so-called hypographical set(Cánovas et al., 2005) of the system{a¯j⊤x≥b¯j,j∈J},defined as(7)H(a¯,b¯):=conv{(a¯j,b¯j),j∈J}+R+{(0n,−1)},wherea¯:=(a¯1,…,a¯p)∈(Rn)pandb¯:=(b¯1,…,b¯p)∈Rp. We observe thatH(a¯,b¯)is the sum of the polytopeconv{(a¯j,b¯j),j∈J}with the closed half-lineR+{(0n,−1)},so that it is a polyhedral convex set.Lemma 3Let α ≥ 0 and(a¯j,b¯j)∈Rn×R,j ∈ J. Suppose that(0n,1)∈clcone({(a¯j,b¯j),j∈J}+αBn+1).Then, for all δ > 0, we have(0n,1)∈cone({(a¯j,b¯j),j∈J}+(α+δ)Bn+1).Let δ > 0. To see the conclusion, we assume by contradiction that(0n,1)∉cone({(a¯j,b¯j),j∈J}+(α+δ)Bn+1).Then, the separation theorem implies that there exists(ξ,r)∈Rn+1∖{0n+1}such that for all(y,s)∈cone({(a¯j,b¯j),j∈J}+(α+δ)Bn+1)one has(8)r=〈(ξ,r),(0n,1)〉≤0≤〈(ξ,r),(y,s)〉,where 〈 ·, ·〉 denotes the usual inner product, i.e., 〈(ξ, r), (y, s)〉 = ξ⊤y + rs. Recall that(0n,1)∈clcone({(a¯j,b¯j),j∈J}+αBn+1). So, there exist sequences{(yk,sk)}k∈N⊂Rn×R,{μkj}k∈N⊂R+,and{(zkj,tkj)}k∈N⊂Bn+1,j ∈ J, such that (yk, sk) → (0n, 1) and(yk,sk)=∑j=1pμkj((a¯j,b¯j)+α(zkj,tkj)).If{∑j=1pμkj}k∈Nis a bounded sequence, by passing to subsequence if necessary, we have(0n,1)∈cone({(a¯j,b¯j),j∈J}+αBn+1).Thus, the claim is true whenever{∑j=1pμkj}k∈Nis a bounded sequence. So, we may assume that∑j=1pμkj→+∞as k → ∞. Let(y,s)∈Bn+1be such that 〈(y, s), (ξ, r)〉 = ‖(ξ, r)‖. Note that∑j=1pμkj((a¯j,b¯j)+α(zkj,tkj)−δ(y,s))∈cone({(a¯j,b¯j),j∈J}+(α+δ)Bn+1).Then, (8) implies thatr≤0≤〈(ξ,r),∑j=1pμkj((a¯j,b¯j)+α(zkj,tkj))〉−(∑j=1pμkj)δ∥(ξ,r)∥=〈(ξ,r),(yk,sk)〉−(∑j=1pμkj)δ∥(ξ,r)∥.Passing to the limit, we arrive at a contradiction as (ξ, r) ≠ 0n + 1, δ > 0,∑j=1pμkj→+∞and (yk, sk) → (0n, 1).□We now provide our promised formula for the radius of robust feasibility. Observe that, since0n+1∉H(a¯,b¯)by Proposition 2,d(0n+1,H(a¯,b¯))can be computed minimizing ‖ · ‖2 onH(a¯,b¯)(i.e., by solving a convex quadratic program).Theorem 4Radius of robust feasibilityFor (Pα), let(a¯j,b¯j)∈Rn×R,j ∈ J, with{x∈Rn:a¯j⊤x≥b¯j,j∈J}≠∅. LetVj:=(a¯j,b¯j)+αBn+1,j ∈ J, andV:=∏j=1pVj. Letρ(V)be the radius of robust feasibility as given in (6) and letH(a¯,b¯)be the hypographical set as given in (7). Then,ρ(V)=d(0n+1,H(a¯,b¯)).If a given(v,w)∈(Rn)p×Rpis interpreted as a perturbation of(v¯,w¯)∈(Rn)p×Rp,we can measure the size of this perturbation as the supremum of the distances between the vectors of coefficients corresponding to the same index. This can be done by endowing the parameter space(Rn)p×Rpwith the metricd˜defined byd˜((v,w),(p,q)):=supj=1,…,p∥(vj,wj)−(pj,qj)∥,for(v,w),(p,q)∈(Rn)p×Rp.Leta¯∈(Rn)pandb¯∈Rpbe as in (7). Denote the set consisting of all inconsistent parameters by Θi, that is,Θi:={(v,w)∈(Rn)p×Rp:{x∈Rn:vj⊤x≥wj,j=1,…,p}=∅}.We now show that(9)d˜((a¯,b¯),Θi)=d(0n+1,H(a¯,b¯)).By Lemma 1,d(0n+1,H(a¯,b¯))>0.Let(a,b)∈H(a¯,b¯)be such that∥(a,b)∥=d(0n+1,H(a¯,b¯)).We associate with(a,b)∈Rn+1the linear system formed by the inequality a⊤x ≥ b repeated p times, with corresponding parameter(a,b)∈(Rn)p×Rp(the context determines, in each case, the interpretation of (a, b) as either a vector or a parameter). We have 0n + 1 ∈ H1, whereH1:=H(a¯,b¯)−(a,b)=conv{(a¯j−a,b¯j−b),j=1,…,p}+R+{(0n,−1)}.So, there exist λj≥ 0 with∑j=1pλj=1and μ ≥ 0 such that0n+1=∑j=1pλj(a¯j−a,b¯j−b)+μ(0n,−1).This shows that(0n,1)=∑j=1pλjμ+1k(a¯j−a,b¯j−b+1k),k∈N.So,{x:(a¯j−a)⊤x≥b¯j−b+1k,j=1,…,p}=∅. Thus,(a¯−a,b¯−b+1k)∈Θi,and so,(a¯−a,b¯−b)∈clΘi. It follows thatd˜((a¯,b¯),Θi)=d˜((a¯,b¯),clΘi)≤∥(a,b)∥=d(0n+1,H(a¯,b¯)).To see (9), we suppose on the contrary thatd((a¯,b¯),Θi)<d(0n+1,H(a¯,b¯)).Then, there exist ɛ0 > 0, with ɛ0 < ‖(a, b)‖, and(a^,b^)∈bdΘisuch thatd˜((a¯,b¯),(a^,b^))=d˜((a¯,b¯),Θi)<∥(a,b)∥−ɛ0. Then, one can find{(a^k,b^k)}k∈N⊂Θisuch that(a^k,b^k)→(a^,b^). So, Lemma 1 gives us that(0n,1)∈clcone{(a^jk,b^jk):j=1,…,p}=cone{(a^jk,b^jk):j=1,…,p}.Thus, there existλjk≥0such that(0n,1)=∑j=1pλjk(a^jk,b^jk). Note that∑j=1pλjk>0,and so,0n+1=∑j=1pλjk∑j=1pλjk(a^jk,b^jk)+1∑j=1pλjk(0n,−1).Then as k → ∞,∥∑j=1pλjk∑j=1pλjk(a^j,b^j)+1∑j=1pλjk(0n,−1)∥=∥∑j=1pλjk∑j=1pλjk(a^j−a^jk,b^j−b^jk)∥→0.So,0n+1∈clH(a^,b^)=H(a^,b^).It then follows that there exist λj≥ 0 with∑j=1pλj=1and μ ≥ 0 such that0n+1=∑j=1pλj(a^j,b^j)+μ(0n,−1).Thus, we have∥∑j=1pλj(a¯j,b¯j)+μ(0,−1)∥=∥(∑j=1pλj(a¯j,b¯j)+μ(0,−1))−(∑j=1pλj(a^j,b^j)+μ(0n,−1))∥=∥∑j=1pλj((a¯j,b¯j)−(a^j,b^j))∥≤d˜((a¯,b¯),(a^,b^))<∥(a,b)∥−ɛ0,where the first inequality follows from the definition ofd˜and λj≥ 0 with∑j=1pλj=1. Note that∑j=1pλj(a¯j,b¯j)+μ(0n,−1)∈H(a¯,b¯). We see thatH(a¯,b¯)∩(∥(a,b)∥−ɛ0)Bn+1≠∅. This shows thatd(0n+1,H(a¯,b¯))≤∥(a,b)∥−ɛ0which contradicts the fact thatd(0n+1,H(a¯,b¯))=∥(a,b)∥.Therefore, (9) holds.Letα∈R+so that (PC) is feasible for α. Then, (a, b) ∈ Θiimplies thatd˜((a¯,b¯),(a,b))>α. Therefore, (9) gives us thatd(0n+1,H(a¯,b¯))=d˜((a¯,b¯),Θi)≥α. Thus,ρ(V)≤d(0n+1,H(a¯,b¯)).We now show thatρ(V)=d(0n+1,H(a¯,b¯)). To see this, we proceed by the method of contradiction and suppose thatρ(V)<d(0n+1,H(a¯,b¯)). Then, there exists δ > 0 such thatρ(V)+2δ<d(0n+1,H(a¯,b¯)). Letα0:=ρ(V)+δ.Then, by the definition ofρ(V),(Pα0)is not feasible, that is,{x∈Rn:c⊤x≥d,(c,d)∈⋃j=1p{(a¯j,b¯j)+αBn+1}}=∅.Hence, it follows from Lemma 1 that(0n,1)∈clcone{⋃j=1p{(a¯j,b¯j)+αBn+1}}.By applying Lemma 3, we can find μj≥ 0 and(zj,tj)∈Bn+1,j = 1, …, p, such that(0n,1)=∑j=1pμj((a¯j,b¯j)+(α0+δ)(zj,tj)).Let(vj,wj)=(a¯j,b¯j)+(α0+δ)(zj,tj),j = 1, …, p,v:=(v1,…,vp)∈(Rn)pandw:=(w1,…,wp)∈Rp. Then,d˜((a¯,b¯),(v,w))≤α0+δand(0n,1)=∑j=1pμj(vj,wj)∈cone{(vj,wj),j=1,…,p}.So, Lemma 1 implies that{x∈Rn:(vj,wj),j=1,…,p}=∅and hence (v, w) ∈ Θi. Thus,d˜((a¯,b¯),Θi)≤d˜((a¯,b¯),(v,w))≤α0+δ=ρ(V)+2δ.Thus, from (9), we see thatd(0n+1,H(a¯,b¯))≤d˜((a¯,b¯),Θi)≤ρ(V)+2δ.This contradicts the fact thatρ(V)+2δ<d(0n+1,H(a¯,b¯)).So, the conclusion follows.□We would like to note that we have given a self-contained proof for Theorem 4 by exploiting the finiteness of the linear inequality system. This proof is totally different from the one given in (Goberna et al., 2014, Theorem 2.5), where we made a massive use of the very technical stability machinery for linear semi-infinite systems developed in Cánovas et al. (2005); 2011).In the following example we show how the radius of robust feasibility of (Pα) can be calculated using Theorem 4.Example 6Calculating the radius of robust feasibilityConsider (Pα) with n = 3, J = {1, …, 5} andVjas in (5), with(10){(a¯j,b¯j),j∈J}={(−2−1−2−6),(−1−2−2−6),(−100−3),(0−10−3),(00−1−3)}.The minimum of ‖ · ‖2 onH(a¯,b¯),whose linear representation{x1+x2−x3≥−13x1+3x2+3x3−4x4≥9−x1−x2−x3≥1−3x1+x2+x3≥−1x1−3x2+x3≥−1−x1−x2+3x3≥−3}is obtained from (7) and (10) by Fourier–Motzkin elimination, is attained at the point(−13,−13,−13,−3). So,ρ(V)=∥(−13,−13,−13,−3)∥=283.In this section we deal with an uncertain linear multi-objective programming problem(11)(P)V-min(c1⊤x,…,cm⊤x)s.t.aj⊤x≥bj,j∈J,where the constraint data (aj, bj) are uncertain and belong to the bounded uncertainty setVj,for j ∈ J, and the objective data ciare uncertain too and belong to the bounded uncertainty setUi,for i ∈ I, and soU=∏i=1mUi. A (robust) decision maker would assume that, selecting a decision x which is feasible for every possible scenario in the constraint data uncertainty set, each objective functionx↦ci⊤xwill attain its worst possible value (risk)supci∈Uici⊤x. So, the robust counterpart of the above uncertain linear multi-objective programming problem is the convex linearly constrained programming problem(12)V-minf(x)s.t.aj⊤x≥bj,∀(aj,bj)∈Vj,j∈J,wheref(x)=(σU1(x),…,σUm(x))andσUi(x):=supci∈Uici⊤xis the support function ofUifor each i ∈ I. SinceσUi=σclconvUi,the objective function f in (12) is the same for the uncertainty sets{Ui,i∈I}and{clconvUi,i∈I}. Moreover, by Lemma 1 and the separation theorem, the feasible set of (12) is also the same for the uncertainty sets{Vj,j∈J}and{clconvVj,j∈J}asclcone{∪j∈JclconvVj}+R+{(0n,−1)}=clcone{∪j∈JVj}+R+{(0n,−1)}.Hence, we can assume without loss of generality thatUiandVjare all compact convex sets, and then,σUi(x):=maxci∈Uici⊤xis a finite-valued convex function for each i ∈ I.Definition 7Robust weakly efficient solutionWe say that a pointx¯∈X:={x∈Rn:aj⊤x≥bj,∀(aj,bj)∈Vj,j∈J}is a (minmax) robust weakly efficient solution to (P) if it is a weakly efficient solution to its robust counterpart (12), that is, if there is nox^∈Xsuch thatσUi(x^)<σUi(x¯)for all i ∈ I.When X is bounded, the continuous functionσUiattains its minimum on X, for each i ∈ I, and this guarantees the existence of (minmax) robust weakly efficient solutions.It is easy to see that (12) is equivalent to(13)V-min(z1,…,zm)s.t.zi≥ci⊤x,∀ci∈Ui,i∈I,aj⊤x≥bj,∀(aj,bj)∈Vj,j∈J,in the sense that a feasible pointx¯is a weakly efficient solution to (12) if and only if(x¯,f(x¯))∈Rn×Rmis a weakly efficient solution to (13). Consequently,x¯∈Xis a (minmax) robust weakly efficient solution to (P) if and only if(x¯,f(x¯))is a weakly efficient solution to (13).Below, we show that robust solutions for uncertain multi-objective linear programming problems with various objective data uncertainty sets can be found by solving deterministic multi-objective linear programming problems or deterministic linear multi-objective programming problems with cone constraints, and so, can be computed via existing technology of deterministic multi-objective programming problems (cf. Ehrgott, 2005). These classes of commonly used data uncertainty sets include box data uncertainty, norm data uncertainty and ellipsoidal data uncertainty. We note that these data uncertainty sets have been successfully employed in modeling uncertain scalar optimization problem arising in diverse areas such as finance (Costa and Paiva, 2002), management science (Bertsimas and Thiele, 2006), statistical learning (Jeyakumar et al., 2014; Lanckriet et al., 2002; Li et al., 2011) and engineering (Ben-Tal and Nemirovski, 1997; Lorenz and Boyd, 2005). For excellent comprehensive surveys, see Ben-Tal and El Ghaoui (2009) and Bertsimas et al. (2011).Consider the box data uncertainty sets(14)Ui=[c̲i,c¯i],i∈I,(15)Vj=[a̲j,a¯j]×[b̲j,b¯j],j∈J,wherec̲i,c¯i∈Rn,c̲i≤c¯i,i ∈ I, anda̲j,a¯j∈Rn,a̲j≤a¯j,andb̲j,b¯j∈R,b̲j≤b¯j,j ∈ J. Denote the extreme points of[c̲i,c¯i]and[a̲j,a¯j]by{c^i(1),…,c^i(2n)}and{a^j(1),…,a^j(2n)},respectively.Theorem 8Consider the uncertain programming problem (P) with data uncertainty setsUiandVjgiven as in (14) and (15). Then,x¯is a robust weakly efficient solution to (P) if and only ifx¯is a weakly efficient solution to the following deterministic multi-objective linear programming problem:V-min(z1,…,zm)s.t.zi≥(c^i(k))⊤x,i∈I,k=1,…,2n,(a^j(k))⊤x≥b¯j,j∈J,k=1,…,2n.LetUiandVjbe box data uncertainty sets given as in (14) and (15), respectively. Then, the robust multi-objective linear programming problem (12) can be equivalently rewritten as follows,V-min(z1,…,zm)s.t.zi≥maxci∈Uici⊤x,i∈I,min(aj,bj)∈Vj{aj⊤x−bj}≥0,j∈J.Note that a linear function attains its minimum and maximum over a polytope at an extreme point of the polytope. Hence, for each i ∈ I and each j ∈ J we getmaxci∈Uici⊤x=max1≤k≤2n(c^i(k))⊤x,min(aj,bj)∈Vj{aj⊤x−bj}=min1≤k≤2n{(a^j(k))⊤x}−b¯j.Therefore, the conclusion follows.□Consider the norm data uncertainty sets(16)Ui={c¯i+σiu¯i:u¯i∈Rn,∥Miu¯i∥s≤1},i∈I,(17)Vj={a¯j+δjv¯j:v¯j∈Rn,∥Zjv¯j∥s≤1}×[b̲j,b¯j],j∈J,wherec¯i,a¯j∈Rn,b̲j,b¯j∈R,b̲j≤b¯j,σi, δj> 0, Miand Zjare invertible symmetric n × n matrices, i ∈ I, j ∈ J, and ‖ · ‖sdenotes the s-norm, fors∈[1,+∞],defined by∥x∥s={∑i=1n|xi|ss,ifs∈[1,+∞),max{|xi|:1≤i≤n},ifs=+∞.Moreover, we defines*∈[1,+∞]to be the number so that1s+1s*=1.Theorem 9Consider the uncertain programming problem (P) with data uncertainty setsUiandVjgiven as in (16) and (17). Then,x¯is a robust weakly efficient solution to (P) if and only ifx¯is a weakly efficient solution to the following deterministic multi-objective linear programming problem with s-order cone constraints:V-min(z1,…,zm)s.t.zi≥(c¯i)⊤x+σi∥Mi−1x∥s*,i∈I,a¯j⊤x−δj∥Zj−1x∥s*≥b¯j,j∈J.LetUiandVjbe box data uncertainty sets given as in (16) and (17) respectively. Then, the robust counterpart of the uncertain multi-objective linear programming problem (12) can be equivalently rewritten asV-min(z1,…,zm)s.t.zi≥maxci∈Uici⊤x,i∈I,min(aj,bj)∈Vj{aj⊤x−bj}≥0,j∈J.Since the dual norm of the s-norm is the s*-norm, that is,max∥x∥s≤1a⊤x=∥a∥s*for anya∈Rn,then, for each i ∈ I and each j ∈ J, we havemaxci∈Uici⊤x=(c¯i)⊤x+σi∥Mi−1x∥s*,min(aj,bj)∈Vj{aj⊤x−bj}=a¯j⊤x−δj∥Zj−1x∥s*−b¯j.Therefore, the conclusion follows.□Consider the ellipsoidal data uncertainty sets(18)Ui={c¯i0+∑k=1piuikc¯ik:∥(ui1,…,uipi)∥≤1},i∈I,(19)Vj={a¯j0+∑l=1qjvjla¯jl:∥(vj1,…,vjqj)∥≤1}×[b̲j,b¯j],j∈J,wherec¯ik,a¯jl∈Rn,k = 0, 1, …, pi, l = 0, 1, …, qj,pi,qj∈Nandb̲j,b¯j∈R,i ∈ I, j ∈ J.Theorem 10Consider the uncertain programming problem (P) with data uncertainty setsUiandVjgiven as in (18) and (19). Then,x¯is a robust weakly efficient solution to (P) if and only ifx¯is a weakly efficient solution to the following deterministic multi-objective linear programming problem with second order cone constraints:V-min(z1,…,zm)s.t.zi≥(c¯i0)⊤x+∥((c¯i1)⊤x,…,(c¯ipi)⊤x)∥,i∈I,(a¯j0)⊤x−∥((a¯j1)⊤x,…,(a¯jqj)⊤x)∥≥b¯j,j∈J.LetUiandVjbe box data uncertainty sets given as in (18) and (19) respectively. Then, the robust multi-objective linear programming problem (12) can be equivalently rewritten asV-min(z1,…,zm)s.t.zi≥maxci∈Uici⊤x,i∈I,min(aj,bj)∈Vj{aj⊤x−bj}≥0,j∈J.Since max ‖x‖ ≤ 1a⊤x = ‖a‖ for anya∈Rn,then, for each i ∈ I and each j ∈ J, we havemaxci∈Uici⊤x=(c¯i0)⊤x+∥((c¯i1)⊤x,…,(c¯ipi)⊤x)∥,min(aj,bj)∈Vj{aj⊤x−bj}=(a¯j0)⊤x−∥((a¯j1)⊤x,…,(a¯jqj)⊤x)∥−b¯j.Therefore, the conclusion follows.□We finally note that in the case when the objective function is free of uncertainty, the characterization of a robust solution for uncertain multi-objective linear programming problem under ellipsoidal constraint data uncertainty was derived in Goberna et al. (2014).From now on, we consider highly robust solutions for uncertain multi-objective linear programming problems of the form(P)V-min{(c1⊤x,…,cm⊤x):aj⊤x≥bj,j∈J},where the objective and the constraints are uncertain,(c1,…,cm)∈U⊂Rn×mand(aj,bj)∈Vj,and the uncertainty sets are bounded. Recall that the robust feasible set for (P) is given by(20)X:={x∈Rn:aj⊤x≥bj,∀(aj,bj)∈Vj,j∈J}.In what follows the normal cone to X atx¯∈X,N(X,x¯):={w∈Rn:w⊤(x−x¯)≤0,∀x∈X},will play a crucial role.Definition 11Highly robust weakly efficient solutionWe say thatx¯∈Xis a highly robust weakly efficient solution for the uncertain multi-objective linear programming problem (P) if, for each(c1,…,cm)∈U,x¯is a weakly efficient solution to the problem in (1), that is, if, for each(c1,…,cm)∈U,there exists no x ∈ X such thatci⊤x<ci⊤x¯for all i ∈ I.We have shown in Section 4 that X does not change when the uncertainty sets{Vj,j∈J}are replaced by{clconvVj,j∈J}. Next we show that any highly robust weakly efficient solution forUis also a highly robust weakly efficient solution forclU. In fact, ifx¯∈Xis not a highly robust weakly efficient solution forclU,then there exist(c1,…,cm)∈clUandx^∈Xsuch thatci⊤x^<ci⊤x¯for all i ∈ I. Let{(c1k,…,cmk)}k∈Nbe a sequence inUconverging to (c1, …, cm). Then(cik)⊤x^<(cik)⊤x¯for all i ∈ I and k large enough, which implies thatx¯is not a highly robust weakly efficient solution forU. Consequently, we may assume without loss of generality thatVjis a compact convex set, for each j ∈ J , whileUis a compact set.Next we first provide a simple uncertain multi-objective linear programming problem where the set of highly robust weakly efficient solutions is nonempty.Example 12Consider the multi-objective linear programming problem with uncertain objectives and uncertainty-free constraints(21)V-min{(c1⊤x,c2⊤x):x∈[−1,1]2},where (c1, c2) is uncertain and belongs to the uncertainty setU:={C¯+ξM:ξ∈[0,1]},C¯=(−100−1)andM=(2002).The set of weakly efficient solutions with respect toUis{([−1,1]×{1})∪({1}×[−1,1]),if0≤ξ<12,[−1,1]2,ifξ=12,([−1,1]×{−1})∪({−1}×[−1,1]),if12<ξ≤1,and so, the set of highly robust weakly efficient solutions is {(1, −1), ( − 1, 1)}. In this caseUis not a cartesian product, so that there is no minmax robust weakly efficient solution.The relationship between minmax robust solutions and highly robust solutions is established in the following proposition.Proposition 13Let (P) be an uncertain multi-objective linear programming problem as in (11), withU=∏i=1mUi.Ifx¯∈Xis a highly robust weakly efficient solution to (P), thenx¯is also a minmax robust weakly efficient solution to (P).Assume thatx¯∈Xis not a minmax robust weakly efficient solution to (P). Then,(x¯,f(x¯))is not a weakly efficient solution to (13). By the compactness assumption, for each i ∈ I,σUi(x¯)=c¯i⊤x¯for certainc¯i∈Ui. Now, since(x¯,f(x¯))is not a weakly efficient solution to (13), there exists(x˜,z˜)∈Rn×Rmsuch thatx˜∈X,z˜i≥ci⊤x˜for allci∈Ui,i ∈ I, andz˜i<c¯i⊤x¯,∀i∈I.Sincec¯i⊤x˜≤z˜i<c¯i⊤x¯for all i ∈ I,x¯is not a weakly efficient solution to (1) when(c1,…,cm)=(c¯1,…,c¯m)∈Uand so,x¯is not a highly robust weakly efficient solution to (P).□The next example illustrates the fact that the set of highly robust weakly efficient solutions may be empty despite of the existence of minmax robust weakly efficient solutions (the opposite situation holds, e.g., wheneverUfails to be a Cartesian product of subsets ofRnand X is a singleton set).Example 14Consider again the linear multi-objective programming problem stated in (21) with a different uncertainty setU:=U1×U2withU1={(−10)+ξ1(20):ξ1∈[0,1]},U2={(0−1)+ξ2(02):ξ2∈[0,1]}.Its robust counterpart can be formulated asV-min{(supξ1∈[0,1](2ξ1−1)x1,supξ2∈[0,1](2ξ2−1)x2):x∈[−1,1]2},which is equivalent to  V-min {(|x1|, |x2|): x ∈ [ − 1, 1]2}. It can be easily checked that the set of minmax robust weakly efficient solutions is ([ − 1, 1] × {0})∪({0} × [ − 1, 1]) while the set of weakly efficient solutions is{([−1,1]×{1})∪({1}×[−1,1]),if0≤ξ1<12,0≤ξ2<12,([−1,1]×{−1})∪({1}×[−1,1]),if0≤ξ1<12,12<ξ2≤1,[−1,1]2,ifξ1=12orξ2=12,([−1,1]×{1})∪({−1}×[−1,1]),if12<ξ1≤1,0≤ξ2<12,([−1,1]×{−1})∪({−1}×[−1,1]),if12<ξ1≤1,12<ξ2≤1,so that there is no highly robust weakly efficient solution.The existence of highly robust weakly efficient solutions can be frequently guaranteed in the case of affine objective data perturbations of the objectives. For this purpose, consider the parameterized uncertain linear multi-objective programming problem(Pβ)V-min(c1⊤x,…,cm⊤x)s.t.aj⊤x≥bj,∀(aj,bj)∈Vj,j∈J,where(c1,…,cm)∈U=∏i=1m(c¯i+βBn),withc¯i∈Rn,i ∈ I, and β ≥ 0. Inspired by the definition of the radius of feasibility, we define theradius of highly robust efficiencyδ(U)as the supremum of thoseβ∈R+such that (Pβ) has some highly robust weakly efficient solution. When X is bounded and β = 0,U={c¯1,…,c¯m}and the minimizers on X of the scalar functionsx↦c¯i⊤x,i ∈ I, are highly robust weakly efficient solutions of (P0). So,δ(U)∈R+∪{+∞}.Assume that X is a polytope (e.g., the setsVj,j ∈ J, are all polytopes, recall Proposition 2) and denote byEthe set of extreme points of X. So, givenc∈Rn,the function x↦c⊤x attains its minimum on X at some pointe∈E,so that c⊤(x − e) ≥ 0 for all x ∈ X, i.e., − c ∈ N(X, e). Moreover, e is the unique minimizer of x↦c⊤x on X for all c ∈ −int N(X, e). So, the finite family of solid polyhedral convex cones{N(X,e),e∈E}constitutes a tessellation ofRn. The boundary of each cone N(X, e),e∈E,is contained in a finite union of hyperplanes, so that⋃e∈EbdN(X,e)is contained in a finite union of hyperplanes too. Thus, a vector c generated at random inRnbelongs toRn∖⋃e∈EbdN(X,e)=⋃e∈EintN(X,e)with probability 1. This intuitive argument, together with the next result, shows that we can get a positive lower bound forδ(U)>0under a mild condition.Theorem 15Radius of highly robust efficiencyLet X be a polytope and letEbe its set of extreme points. If there exists an index i ∈ I0and a corresponding extreme pointei∈Esuch that−c¯i∈intN(X,ei),thenδ(U)>0.LetX={x∈Rn:pt⊤x≥qt,t∈T}be a linear representation of the polytope X such that ‖pt‖ = 1 for all t ∈ T. The normal cone N(X, e) ate∈Eis the negative polar of the cone of feasible directions of X at e, i.e.,N(X,e)={x∈Rn:pt⊤x≤0,∀t∈T(e)},whereT(e)={t∈T:pt⊤e=qt}is the set of active indices at e. Moreover,intN(X,e)={x∈Rn:pt⊤x<0,∀t∈T(e)}. So, for any c ∈ −int N(X, e), the radius of the greatest ball centered at − c and contained in N(X, e) is(22)d(−c,bdN(X,e))=min{pt⊤c:t∈T(e)}>0.The supremum of any set of positive scalars β such that some extreme point of X which minimizes on X at least one objective functionx↦ci⊤xwhenci∈c¯i+βBnwill be a lower bound forδ(U). We now compute such a lower bound.Denote by I0 the set of indices i ∈ I such that−c¯ilies in the interior of some element of{N(X,e),e∈E}. By assumption, I0 ≠ ∅. For each i ∈ I0 there exists a unique extreme point eiof X such that−c¯i∈intN(X,ei). Then, from (22), one has(23)δ(U)≥max{d(−c¯i⊤,bdN(X,ei)):i∈I0}=maxi∈I0min{pt⊤c¯i:t∈T(ei)}>0.□The assumption that X is a polytope cannot be replaced by the weaker assumption that X is a compact convex set. Indeed, in this case, we still haveX=convEwith{N(X,e),e∈E}being a tessellation ofRn,but we may have int N(X, e) = ∅ for alle∈E(e.g., if X is a closed ball,{N(X,e),e∈E}is formed by all rays emanating from 0n). Observe that the lower bound forδ(U)in (23) can be effectively computed.Below, we provide two examples. The first example illustrates how to use (23) to compute a lower bound for the radius of highly robust efficiency. The second example shows that the lower bound for the radius of highly robust efficiency provided by (23) can be achieved (and so, is the best possible lower bound).Example 16A lower bound for radius of highly robust efficiencyConsider the problemV-min{(c1⊤x,c2⊤x):x∈X},where the feasible set isX:={x∈R2:−x1≥−1,x1≥−1,−x2≥−1,x2≥−1}.The extreme points of X are e1 = (1, 1), e2 = ( − 1, 1), e3 = ( − 1, −1) and e4 = (1, −1).(a) Letc¯1=(−2,−1)⊤andc¯2=(−1,1)⊤. We have−c¯1∈intN(X,e1)and−c¯2∈intN(X,e4)with T(e1) = {1, 3} and T(e4) = {1, 4}, so that (23) yields(24)δ(U)≥max{min{2,1},min{1,1}}=1.(b) The vectorsc¯1=(1,0)⊤andc¯2=(−1,0)⊤belong to⋃i=14bdN(X,ei)and do not satisfy the assumption of Theorem 15. It is easy to see that any element of bd X is a weakly efficient solution. We associate withr∈Nthe couples of perturbed vectors(1,1r)⊤,(−1,1r)⊤and(1,−1r)⊤,(−1,−1r)⊤,whose corresponding sets of weakly efficient solutions are conv{e3, e4} and conv{e1, e2}, respectively. Since conv{e3, e4}∩conv{e1, e2} = ∅, the problem (Pβ) withβ=1rhas no highly robust weakly efficient solutions, and soδ(U)<1rfor allr∈N. Consequently,δ(U)=0.Consider the following multi-objective linear programming problem(EPβ)V-min{(c1x,c2x):x≥1,−x≥−2},where the data (c1, c2) are uncertain and belong to the uncertainty setU=[c¯1−β,c¯1+β]×[c¯2−β,c¯2+β]withc¯1=2,c¯2=−1and β ≥ 0. The extreme points of the feasible set X = [1, 2] are e1 = 1 and e2 = 2, and one has−c¯1∈intN(X,e1)and−c¯2∈intN(X,e2). Let I0 = {1, 2}, p1 = 1, p2 = −1. As T(e1) = {1} and T(e2) = {2}, from (23), we haveδ(U)≥maxi∈I0min{ptc¯i:t∈T(ei)}=2.Indeed, the obtained lower bound 2 is tight. To see this, we first note that, for all(c1,c2)∈[c¯1−2,c¯1+2]×[c¯2−2,c¯2+2],x = 1 is a highly robust weakly efficient solution for the problem (EPβ) with β = 2. On the other hand, for any β > 2, there exist(c1j,c2j)∈[c¯1−β,c¯1+β]×[c¯2−β,c¯2+β],j = 1, 2 such thatc11<0,c21<0,c12>0andc22>0. Note that the set of weakly efficient solutions of (EPβ) is{{1},ifc1>0,c2>0,{2},ifc1<0,c2<0.So, if β > 2, the highly robust weakly efficient solution set for the problem (EPβ) is empty. This shows thatδ(U)=2.We now associate with a given matrixC¯:=(c¯1,…,c¯m)∈Rn×mand given vectorsu∈Rn∖{0n}andv∈R+m∖{0m}the parameterized uncertain linear multi-objective programming problem(Pβ)V-minC⊤xs.t.aj⊤x≥bj,∀(aj,bj)∈Vj,j∈J,where the data C are uncertain and belong to the following uncertainty set(25)U={C¯+ξuv⊤:ξ∈[0,β]}.and β ≥ 0. This data uncertainty set was introduced and examined in (Pando et al., 2013, Section 3) (see also Jeyakumar et al., 2011). We define again the radius of highly robust efficiencyδ(U)as the supremum of thoseβ∈R+such that (Pβ) has some highly robust weakly efficient solution. Obviously,δ(U)≠−∞whenever at least one of the scalar functionsx↦c¯i⊤x,i ∈ I, attains its minimum on X.As a straightforward consequence of the next theorem we shall obtain the following lower bound for the radius of highly robust efficiency:δ(U)≥sup{β∈R+:∃x¯∈X,λ,λ˜∈ΔmsuchthatC¯λ∈−N(X,x¯)and(C¯+βuv⊤)λ˜∈−N(X,x¯)}.Moreover, the supremum in the definition ofδ(U)is attained whenever there existx¯∈X,andλ,λ˜∈Δmsuch thatC¯λ∈−N(X,x¯)and(C¯+δ(U)uv⊤)λ˜∈−N(X,x¯).Theorem 18Characterizing highly robust weakly efficient solutionsConsider the uncertain problem (Pβ) with β = 1, with uncertain setU={C¯+ξuv⊤:ξ∈[0,1]},and letx¯∈X.Then,x¯is highly robust weakly solution if and only if there existλ,λ˜∈Δmsuch thatC¯λ∈−N(X,x¯)and(C¯+uv⊤)λ˜∈−N(X,x¯).Moreover, ifVjis convex for each j ∈ J andK(V)is closed, then the highly robust weakly efficiency ofx¯∈Xis equivalent to the condition that there existλ,λ˜∈Δmand(aj,bj),(a˜j,b˜j)∈Vj,μj,μ˜j≥0,j ∈ J, such thatC¯λ=∑j=1pμjajandμj(aj⊤x¯−bj)=0,j∈J,and(C¯+uv⊤)λ˜=∑j=1pμ˜jajandμ˜j(a˜j⊤x¯−b˜j)=0,j∈J.Letx¯∈Xbe a robust weakly efficient solution. Then, we have for eachC∈U,there exists no x ∈ X such thatC⊤x<C⊤x¯. By Goberna et al. (2013), Proposition 18 (iii), this is equivalent to the fact that(∀C∈U),(∃λ∈R+m∖{0m})(Cλ∈−N(X,x¯)).AsN(X,x¯)is a cone, by normalization, we may assume that λ ∈ Δm, and so,x¯is a robust weakly efficient solution if and only if(26)(∀C∈U),(∃λ∈Δm)(Cλ∈−N(X,x¯)).To see the first assertion, it suffices to show that (26) is further equivalent to(27)(∃λ,λ˜∈Δm)(C¯λ∈−N(X,x¯)and(C¯+uv⊤)λ˜∈−N(X,x¯)).To see the equivalence, we only need to show that (27) implies (26) when u ≠ 0m(otherwiseUis a singleton set). To achieve this, suppose that (27) holds and fix an arbitraryC∈U. Then there existsξ∈[0,1]such thatC=C¯+ξuv⊤. We may assume ξ ∈ (0, 1), otherwise there is nothing to prove.Firstly, ifλ˜⊤v=0,then(uv⊤)λ˜=u(v⊤λ˜)=0n. Hence,(C¯+uv⊤)λ˜=C¯λ˜∈−N(X,x¯),which means that (27) holds forλ=λ˜. So, for any ξ ∈ (0, 1) one has(C¯+ξuv⊤)λ˜=(1−ξ)C¯λ˜+ξ(C¯+uv⊤)λ˜∈−N(X,x¯).Consequently, we may assumeλ˜⊤v≠0. Even more, asv∈R+m∖{0}andλ˜∈Δm,we may assumeλ˜⊤v>0. In the same way, we get that λ⊤v ≥ 0. Hence, one has(1−ξ)λ˜⊤v+ξλ⊤v>0and so,τ:=(1−ξ)λ˜⊤v(1−ξ)λ˜⊤v+ξλ⊤v∈[0,1]andγ:=τλ+(1−τ)λ˜∈Δm. Moreover, we have(28)τξ(uv⊤)λ−(1−ξ)(1−τ)(uv⊤)λ˜=(1−ξ)λ˜⊤v(1−ξ)λ˜⊤v+ξλ⊤vξ(uv⊤)λ−ξλ⊤v(1−ξ)λ˜⊤v+ξλ⊤v(1−ξ)(uv⊤)λ˜=(1−ξ)λ˜⊤v(1−ξ)λ˜⊤v+ξλ⊤vξ(λ⊤v)u−ξλ⊤v(1−ξ)λ˜⊤v+ξλ⊤v(1−ξ)(λ˜⊤v)u=0n.Now,Cγ=(C¯+ξuv⊤)(τλ+(1−τ)λ˜)=τC¯λ+τξ(uv⊤)λ+(1−τ)(C¯+ξuv⊤)λ˜=τC¯λ+τξ(uv⊤)λ+(1−τ)(C¯+uv⊤)λ˜−(1−ξ)(1−τ)(uv⊤)λ˜=τC¯λ+(1−τ)(C¯+uv⊤)λ˜∈−N(X,x¯).where the fourth equality follows from (28) and the last relation follows from (27) and the convexity ofN(X,x¯).To see the second assertion, we assume thatVjis convex, j ∈ J, andK(V)is closed. We only need to showN(X,x¯)={−∑j=1pμjaj:(aj,bj)∈Vj,μj≥0andμj(aj⊤x¯−bj)=0,j∈J∑j=1p}.The system {a⊤x ≥ b, (a, b) ∈ T}, withT:=∪j∈JVj,is a linear representation of X. Thus,u∈N(X,x¯)if and only if the inequality − u⊤x ≥−u⊤x¯is consequence of {a⊤x ≥ b, (a, b) ∈ T}, which is equivalent, according to Lemma 1, to−(u,u⊤x¯)∈cone(T)+R+{(0n,−1)}.This is equivalent to assert the existence of a finite subset S of T, corresponding non-negative scalars λs, s ∈ S, and μ ≥ 0, such that(29)−(u,u⊤x¯)=∑(a,b)∈Sλ(a,b)(a,b)+μ(0n,−1).Multiplying by(x¯,−1)both members of (29) we get μ = 0, so that (29) is equivalent to(30)−u=∑(a,b)∈Sλ(a,b)aandλ(a,b)(a⊤x¯−b)=0,∀(a,b)∈S.Finally, sinceS⊂∪j∈JVj,we can write S = ∪j ∈ JSj, withSj⊂Vj,j ∈ J, and Si∩Sj= ∅ when i ≠ j. Letμj:=∑(a,b)∈Sjλ(a,b),j ∈ J. If μj≠ 0 one has, by convexity ofVj,(aj,bj):=∑(a,b)∈Sjλ(a,b)(a,b)μj∈Vj.Take(aj,bj)∈Vjarbitrarily when μj= 0. Then we get from (30) that−u=∑j=1pμjajandμj(aj⊤x¯−bj)=0,j=1,…,p.Thus, the conclusion follows.□In Theorem 18 we require thatv∈R+m. The following example (inspired in Pando et al., 2013, Example 3.3) illustrates that this non-negativity requirement cannot be dropped.Example 19Non-negativity requirement for rank-1 objective data uncertaintyLetC¯=(−30−1−1−2−2),v=(−11)∉R+2andu=(0−30).Consider the uncertain multi-objective optimization problem(31)V-min{C⊤x:aj⊤x≥bj,∀(aj,bj)∈Vj,j∈{1,2}},where the objective data matrix C is an element of{C¯+ξuv⊤:ξ∈[0,1]}={(−30−1−1−2−2)+ξ(003−300):ξ∈[0,1]}and the uncertainty sets for the constraints are the convex polytopesV1=conv{(−2−1−2−6),(−1−2−2−6)},V2=conv{(−100−3),(0−10−3),(00−1−3)}.Note that the robust feasible set isX={x∈Rn:aj⊤x≥bj,∀(aj,bj)∈Vj,j∈{1,2}}={a¯j⊤x≥b¯j,j∈{1,…,5}},where{a¯j⊤x≥b¯j,j∈{1,…,5}}is the set in (10). It can be checked thatx¯=(1,1,3/2)∈Xand so,N(X,x¯)={μ1(212)+μ2(122):μ1≥0,μ2≥0}.Let λ = (2/3, 1/3)⊤ andλ˜=(1/3,2/3)⊤. Then, we haveC¯λ∈−N(X,x¯)and(C¯+uv⊤)λ˜∈−N(X,x¯).On the other hand, forC=(−30−1−1−2−2)+12(003−300)=(−3012−52−2−2)∈U,and x = (0, 0, 3)⊤ ∈ X, we see thatC⊤x=(−6−6)<(−112−112)=C⊤x¯.So,x¯is not a weakly efficient solution to (31). Thus, the above solution characterization fails.In the case where the constraints are uncertainty free, i.e., the setsVjare all singletons, we obtain the following solution characterization for robust multi-objective optimization problems with rank-1 objective uncertainty.Corollary 20Consider the setUas in Theorem18andVj={(a¯j,b¯j)},j ∈ J. For eachC∈U,consider the uncertain multi-objective linear programming problem (1). Givenx¯∈X,the following statements are equivalent:(i)x¯is a highly robust weakly efficient solution.There existλ,λ˜∈Δmsuch thatC¯λ∈−N(X,x¯)and(C¯+uv⊤)λ˜∈−N(X,x¯).There existλ,λ˜∈Δmandμj,μ˜j≥0,j ∈ J, such thatC¯λ=∑j=1pμja¯jandμj(a¯j⊤x¯−b¯j)=0,j∈J,and(C¯+uv⊤)λ˜=∑j=1pμ˜ja¯jandμ˜j(a¯j⊤x¯−b¯j)=0,j∈J.x¯is a weakly efficient solution to the problems(P0)V-minC¯⊤xs.t.a¯j⊤x≥b¯j,j∈J,and(P1)V-min(C¯+uv⊤)⊤xs.t.a¯j⊤x≥b¯j,j∈J.LetVj={(a¯j,b¯j)},j ∈ J. The equivalences (i)⇔(ii)⇔(iii) come from Theorem 18, taking into account that all the uncertainty setsVjare polytopes. Note that (i)⇒(iv) always holds because of (25) and Definition 11. Finally, the implication (iv)⇒(ii) is immediate by the usual characterization for weakly efficient solutions (e.g., see Goberna et al., 2013, Proposition 18 (iii)). Thus, the conclusion follows.□The equivalence (i)⇔(iii) in Corollary 20, on robust weakly efficient solutions of uncertain vector linear programming problems, can be seen as a counterpart of (Pando et al., 2013, Theorem 3.1), on robust efficient solutions of the same type of problems.Next, we provide various classes of commonly used uncertainty sets determining the robust feasible setX={x∈Rn:aj⊤x≥bj,∀(aj,bj)∈Vj,j∈J},under which one can numerically check whether a robust feasible point is a highly robust weakly efficient solution or not. Throughout this section we assume that the objective function of (1) satisfies the rank-1 matrix data uncertainty, as defined in Section 5. We begin with the simple box constraint data uncertainty.Consider the box data uncertainty set(32)Vj=[a̲j,a¯j]×[b̲j,b¯j],wherea̲j,a¯j∈Rn,a̲j≤a¯j,andb̲j,b¯j∈R,b̲j≤b¯j,j ∈ J. Denote the extreme points of[a̲j,a¯j]by{a^j(1),…,a^j(2n)}.Theorem 22Consider the setUas in Theorem18andVj,j ∈ J, as in (32). For eachC∈U,consider the uncertain multi-objective linear programming problem in (1). Then, the following statements are equivalent:(i)x¯∈Xis a highly robust weakly efficient solution to (P).There existλ,λ˜∈Δmandμj(l),μ˜j(l)≥0such thatC¯λ=∑j=1p∑l=12nμj(l)a^j(l)andμj(l)((a^j(l))⊤x¯−b¯j)=0,j∈J,l=1,…,2n,and(C¯+uv⊤)λ˜=∑j=1p∑l=12nμ˜j(l)a^j(l)andμ˜j(l)((a^j(l))⊤x¯−b¯j)=0,j∈J,l=1,…,2n.x¯is a weakly efficient solution for the following two deterministic multi-objective linear programming problemsV-minC¯⊤xs.t.(a^j(l))⊤x−b¯j≥0,l=1,…,2n,j∈J,andV-min(C¯+uv⊤)⊤xs.t.(a^j(l))⊤x−b¯j≥0,l=1,…,2n,j∈J.(i)⇔(ii) Letx¯be a robust weakly efficient solution to (1). Note that X can be rewritten asX={x∈Rn:aj⊤x−bj≥0forall(aj,bj)∈[a̲j,a¯j]×[b̲j,b¯j],j∈J}={x∈Rn:(a^j(l))⊤x−b¯j≥0,l=1,…,2n,j∈J}.Then, we have(33)N(X,x¯)={−∑j=1p∑l=12nμj(l)a^j(l):μj(l)((a^j(l))⊤x¯−b¯j)=0,μj(l)≥0,∀l,∀j}.The conclusion follows from Theorem 18.(i)⇒(iii) This implication follows by the definition of a highly robust weakly efficient solution.(iii)⇒(ii) By the usual characterization for weakly efficient solutions (e.g., see Goberna et al., 2013, Proposition 18 (iii)), we see that there existλ,λ˜∈Δmsuch thatC¯λ∈N(X,x¯)and(C¯+uv⊤)λ˜∈N(X,x¯). Thus, this implication follows by (33)).□It is worth noting that one can determine from Theorem 22 whether or not a given robust feasible pointx¯under the box constraint data uncertainty is a highly robust weakly efficient solution by solving finitely many linear equalities.Consider the norm constraint data uncertainty set(34)Vj={a¯j+δjv¯j:v¯j∈Rn,∥Zjv¯j∥s≤1}×[b̲j,b¯j],wherea¯j∈Rn,b̲j,b¯j∈R,b̲j≤b¯j,δj> 0, Zjis an invertible symmetric n × n matrix, j ∈ J. Recall that ‖ · ‖sdenotes the s-norm,s∈[1,+∞],ands*∈[1,+∞]is the number so that1s+1s*=1. The following simple fact about s-norms will be used later on:∂(∥·∥s*)(u)={v:∥v∥s≤1,v⊤u=∥u∥s*},where ∂h(x) denotes the usual convex subdifferential of a convex functionh:Rn→Ratx∈Rn,i.e.,∂h(x)={z∈Rn:z⊤(y−x)≤h(y)−h(x)∀y∈Rn}.In this case, we have the following characterization of robust weakly efficient solutions.Theorem 23Consider the setUas in Theorem18andVj,j ∈ J, as in (34). For eachC∈U, consider the uncertain multi-objective linear programming problem in (1). Suppose that there existsx0∈Rnsuch that(35)a¯j⊤x0−b¯j−δj∥Zj−1x0∥s*>0,j∈J.Then, the following statements are equivalent:(i)x¯∈Xis a highly robust weakly efficient solution to (P).There existλ,λ˜∈Δm,μ,μ˜∈R+pandwj,w˜j∈Rn,with ‖wj‖s≤ 1 and∥w˜j∥s≤1,such that−λ⊤C¯⊤x¯=∑j=1pμjb¯jandC¯λ+∑j=1pμj(a¯j−δjZj−1wj)=0n,and−λ˜⊤(C¯+uv⊤)⊤x¯=∑j=1pμ˜jb¯jand(C¯+uv⊤)λ˜+∑j=1pμ˜j(a¯j−δjZj−1w˜j)=0n.x¯is a weakly efficient solution for the following two deterministic linear multi-objective problems with second order cone constraints:V-minC¯⊤xs.t.a¯j⊤x−b¯j−δj∥Zj−1x∥s*≥0,j∈J,andV-min(C¯+uv⊤)⊤xs.t.a¯j⊤x−b¯j−δj∥Zj−1x∥s*≥0,j∈J.(i)⇔(ii) Note that X can be rewritten asX={x∈Rn:a¯j⊤x−bj+δj(v¯j)⊤x≥0forall∥Zjv¯j∥s≤1,bj∈[b̲j,b¯j],j∈J}={x∈Rn:a¯j⊤x−bj+δj(Zj−1u¯j)⊤x≥0forall∥u¯j∥s≤1,bj∈[b̲j,b¯j],j∈J}={x∈Rn:a¯j⊤x−b¯j−δj∥Zj−1x∥s*≥0,j∈J}.SinceVjis a compact convex set for j ∈ J and the strict robust feasibility condition (4) holds as a consequence of (35), the conclusion will follow from Theorem 18 if we show thatN(X,x¯)=N1whereN1:={∑j=1pu∈Rn:∃μj≥0,∥wj∥s*≤1suchthat−u⊤x¯=∑j=1pμjb¯jandu+∑j=1pμj(a¯j−δjZj−1wj)=0n}.To see this, letu∈N(X,x¯). Then,x¯is a solution to the following convex optimization problem,min{−u⊤x:a¯j⊤x−b¯j−δj∥Zj−1x∥s*≥0,j∈J}As the strict feasibility condition (35) holds, by the Lagrangian duality, there exist μj≥ 0, j ∈ J, such that−u⊤x¯=minx∈Rn{(−u⊤x)+∑j=1pμj(−a¯j⊤x+b¯j+δj∥Zj−1x∥s*)}.Asx¯∈X,this implies thatμj(−a¯j⊤x¯+b¯j+δj∥Zj−1x¯∥s*)=0,j ∈ J, and so, the functionh(x):=(−u⊤x)+∑j=1pμj(−a¯j⊤x+b¯j+δj∥Zj−1x∥s*)attains its minimum on X atx¯andminx∈Rnh(x)=−u⊤x¯. This implies that0n∈∂h(x¯). Observe thath(x)=−(u+∑j=1pμja¯j)⊤x+δj∑j=1pμj∥Zj−1x∥s*+∑j=1pμjb¯jand hence,(36)∂h(x¯)=−(u+∑j=1pμja¯j)+δj∑j=1pμj∂(∥Zj−1·∥s*)(x¯).AsZj−1is a symmetric matrix, for each j ∈ JRockafellar (1970), Theorem 23.9 gives us that(37)∂(∥Zj−1·∥s*)(x¯)=Zj−1{wj:∥wj∥s≤1,wj⊤Zj−1x¯=∥Zj−1x¯∥s*}.As a consequence of (36) and the fact that0n∈∂h(x¯)we haveu+∑j=1pμja¯j∈δj∑j=1pμj∂(∥Zj−1·∥s*)(x¯)and so, by (37), there existwj∈Rnwith ‖wj‖s≤ 1 such thatwj⊤(Zj−1x¯)=∥Zj−1x¯∥s*andu+∑j=1pμj(a¯j−δjZj−1wj)=0n.This together withh(x¯)=−u⊤x¯gives us that−u⊤x¯=∑j=1pμjb¯j. Then, we haveN(X,x¯)⊂N1.To see the reverse inclusion, letu∈Rnwithu+∑j=1pμj(a¯j−δjZj−1wj)=0nand−u⊤x¯=∑j=1pμjb¯jfor someμj≥0,∥wj∥s*≤1. Then, for all x ∈ X,u⊤(x−x¯)=u⊤x+∑j=1pμjb¯j=−(∑j=1pμj(a¯j−δjZj−1wj))⊤x+∑j=1pμjb¯j=∑j=1pμj(−a¯j⊤x+b¯j+δj(Zj−1wj)⊤x)≤∑j=1pμj(−a¯j⊤x+b¯j+δj∥Zj−1x∥s*)≤0,where the inequality follows from∥wj∥s*=max∥u∥s≤1wj⊤u(and hence,wj⊤v≤∥wj∥s*∥v∥s≤∥v∥sfor allv∈Rn). So,u∈N(X,x¯)and hence, the conclusion follows.(i)⇒(iii) This implication follows by the definition of a highly robust weakly efficient solution.(iii)⇒(ii) By the usual characterization for weakly efficient solutions (e.g., see Goberna et al., 2013, Proposition 18 (iii)), we see that there existλ,λ˜∈Δmsuch thatC¯λ∈N(X,x¯)and(C¯+uv⊤)λ˜∈N(X,x¯). Thus, this implication follows by noting thatN(X,x¯)=N1.□Theorem 23 shows that one can determine whether a robust feasible pointx¯under norm data uncertainty is a highly robust weakly efficient solution or not by solving finitely many sth-order cone systems (that is, linear equations where the variable lies in the ball determined by the ‖ · ‖s-norm) as long as the strict feasibility condition (35) is satisfied.In this subsection we consider the case where the constraint data are uncertain and belong to the ellipsoidal constraint data uncertainty sets(38)Vj={a¯j0+∑l=1qjvjla¯jl:∥(vj1,⋯,vjqj)∥≤1}×[b̲j,b¯j],wherea¯jl∈Rn,l = 0, 1, …, qj,qj∈Nandb̲j,b¯j∈R,j ∈ J.Theorem 24Consider the setUas in Theorem18andVj, j ∈ J, as in (38). For eachC∈U,consider the uncertain multi-objective linear programming problem in (1). Suppose that there existsx0∈Rnsuch that(39)(a¯j0)⊤x0−b¯j−∥((a¯j1)⊤x0,…,(a¯jqj)⊤x0)∥>0,j∈J.Then, the following statements are equivalent:(i)x¯∈Xis a highly robust weakly efficient solution to (P).There existλ,λ˜∈Δm,μ,μ˜∈R+pandw,w˜∈Rnwith ‖w‖ ≤ 1 and∥w˜∥≤1such that−λ⊤C¯⊤x¯=∑j=1pμjb¯jand−C¯λ−∑j=1pμj(a¯j0−yj)=0nand−λ⊤(C¯+uv⊤)⊤x¯=∑j=1pμjb¯jand−(C¯+uv⊤)λ−∑j=1pμj(a¯j0−yj)=0n,whereyj=((a¯j1)⊤w,…,(a¯jqj)⊤w)⊤.x¯is a weakly efficient solution for the following two deterministic linear multi-objective problems with second order cone constraints:V-minC¯⊤xs.t.(a¯j0)⊤x−b¯j−∥((a¯j1)⊤x,…,(a¯jqj)⊤x)∥≥0,j∈J,andV-min(C¯+uv⊤)⊤xs.t.(a¯j0)⊤x−b¯j−∥((a¯j1)⊤x,…,(a¯jqj)⊤x)∥≥0,j∈J.(i)⇔(ii) Note that X can be rewritten asX={x∈Rn:(a¯j0)⊤x−bj+∑l=1qjvjl(a¯jl)⊤x)≥0forall∥(vj1,⋯vjqj)∥≤1,bj∈[b̲j,b¯j],j∈J)}={x∈Rn:(a¯j0)⊤x−b¯j−∥((a¯j1)⊤x,…,(a¯jqj)⊤x)∥≥0,j∈J}.The conclusion will follow from Theorem 18 if we show thatN(X,x¯)=N2whereN2:={∑j=1pu∈Rn:∃μj≥0,∥w∥≤1suchthat−u⊤x¯=∑j=1pμjb¯jandu+∑j=1pμj(a¯j0−yj)=0n}.To see this, letu∈N(X,x¯). Then,x¯is a solution to the following convex optimization problem,min{−u⊤x:(a¯j0)⊤x−b¯j−∥((a¯j1)⊤x,…,(a¯jqj)⊤x)∥≥0,j∈J}.As the strict feasibility condition (39) holds, by the Lagrangian duality, there exist μj≥ 0, j ∈ J, such that−u⊤x¯=minx∈Rn{(−u⊤x)+∑j=1pμj(−(a¯j0)⊤x+b¯j+∥((a¯j1)⊤x,…,(a¯jqj)⊤x)∥)∑j=1p}.Asx¯∈X,this implies thatμj((a¯j0)⊤x¯−b¯j−∥((a¯j1)⊤x¯,…,(a¯jqj)⊤x¯)∥)=0,j ∈ J, and so, the functionh(x):=(−u⊤x)+∑j=1pμj(−(a¯j0)⊤x+b¯j+∥((a¯j1)⊤x,…,(a¯jqj)⊤x)∥)attains its minimum atx¯andminx∈Rnh(x)=−u⊤x¯. This implies that0n∈∂h(x¯),and so, by using a similar reasoning to that in the proof of Theorem 23, there existsw∈Rnwith ‖w‖ ≤ 1 such that−u⊤x¯=∑j=1pμjb¯jand−u−∑j=1pμja¯j0+∑j=1pμjyj=0n,whereyj=((a¯j1)⊤w,…,(a¯jqj)⊤w)⊤. Then, we haveN(X,x¯)⊂N2.To see the reverse inclusion, letu∈Rnbe such that−u⊤x¯=∑j=1pμjb¯jandu+∑j=1pμj(a¯j0−yj)=0nfor some μj≥ 0, j ∈ J, and ‖w‖ ≤ 1. Then,u⊤(x−x¯)=∑j=1pμjb¯j−∑j=1pμj(a¯j0−yj)⊤x≤∑j=1pμj(−(a¯j0)⊤x+b¯j+∥((a¯j1)⊤x,…,(a¯jqj)⊤x)∥)≤0for all x ∈ X. Thus,u∈N(X,x¯)and so, the conclusion follows.(i)⇒(iii) This implication follows by the definition of a highly robust weakly efficient solution.(iii)⇒(ii) By the usual characterization for weakly efficient solutions (e.g., see Goberna et al., 2013, Proposition 18 (iii)), we see that there existλ,λ˜∈Δmsuch thatC¯λ∈N(X,x¯)and(C¯+uv⊤)λ˜∈N(X,x¯). Thus, this implication follows by noting thatN(X,x¯)=N2.□The above robust solution characterization under the constraint ellipsoidal data uncertainty shows that one can determine whether a robust feasible point is a highly robust weakly efficient solution point or not by solving finitely many second order cone systems as long as the strict robust feasibility condition (39) is satisfied.

@&#CONCLUSIONS@&#
