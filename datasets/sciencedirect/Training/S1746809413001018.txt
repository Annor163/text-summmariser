@&#MAIN-TITLE@&#
Noninvasive diagnosis of melanoma with tensor decomposition-based feature extraction from clinical color image

@&#HIGHLIGHTS@&#
Noninvasive diagnosis of melanoma from clinical color image.Novel feature extraction based on tensor decomposition and nonlinear transformation.Interesting alternative and competitive performance in comparison with state-of-the-art methods.Diagnosis from color RGB image possibly enabling design of cost-effective prescreening devices.

@&#KEYPHRASES@&#
Multidimensional signal processing,Tensor decomposition,Feature extraction,Noninvasive diagnosis,Melanoma,

@&#ABSTRACT@&#
We propose a method for feature extraction from clinical color images, with application in classification of skin lesions. Proposed feature extraction method is based on tensor decomposition of the clinical color image of skin lesion. Since color image is naturally represented as a three-way tensor, it is reasonable to use multi-way techniques to capture the underlying information contained in the image. Extracted features are elements of the core tensor in the corresponding multi-way decomposition, and represent spatial-spectral profile of the lesion. In contrast to common methods that exploit either texture or spectral diversity of the tumor only, the proposed approach simultaneously captures spatial and spectral characteristics. The procedure is tested on a problem of noninvasive diagnosis of melanoma from the clinical color images of skin lesions, with overall sensitivity 82.1% and specificity 86.9%. Our method compares favorably with the state of the art results reported in the literature and provides an interesting alternative to the existing approaches.

@&#INTRODUCTION@&#
Noninvasive diagnosis of tumor is a procedure of identification and discrimination among various types of tumors by exploiting data that is not collected invasively, e.g., by biopsy. The aim of the noninvasive diagnosis is to detect malignant tumors with high accuracy and to simultaneously reduce the number of biopsies of the innocuous benign tumors. In general, methods for automated noninvasive diagnosis rely on sophisticated processing techniques applied on the collected data. The data can be acquired by various imaging modalities, such as multispectral (MSI) or hyperspectral imaging (HSI) [1,2]. Diagnosis is usually obtained by classifying a set of features extracted from the image of the tumor. Consequently, extraction of tumor-specific features is of central importance for accurate diagnosis. This is in line with the reasoning in the machine learning community that feature extraction matters more than the method used for classification [3,4].Malignant melanoma is presently among the leading cancers in the white-skinned population, with rapidly increasing incidence and mortality rates over the last decades [5–7]. While advanced form of the cutaneous melanoma is still practically incurable, early diagnosis can significantly increase probability of survival. In fact, very high degree of curability can be achieved if the surgical excision is performed early enough [8]. The increased occurrence, along with the high lethality in case of an advanced melanoma, implies a demand for a simple and accurate screening test as an alternative to biopsy.In spite of best efforts of researchers, the accuracy of the noninvasive diagnosis of the melanocytic lesions is far from ideal. Even binary problem of distinguishing between malignant melanoma and benign melanocytic lesion without histological examination remains a challenge [9]. One of the most widely used methods for preliminary diagnosis based on visual inspection is the so called ABCDE rule. It is a semi-quantitative diagnosis scheme based on naked eye inspection (i.e., a clinical image) of the skin lesion. The scheme includes examination on the asymmetry (A), border sharpness (B), color variation (C), number of differential structures (D) present in the lesion, and evolution (E) of the lesion in time. Unfortunately, it has shown a limited sensitivity in melanoma diagnosis [7], with overall accuracy depending on the level of expertise of dermatologist. In case of a well-trained dermatologist typical accuracy is around 75% [10]. Since the naked eye inspection achieves such low performance, epiluminescence light microscopy (ELM) or dermoscopy was suggested. The idea of ELM is to improve diagnostic performance by evaluating morphological features of lesions [11]. It was reported that the accuracy of the diagnosis obtained by dermoscopy in case of an expert dermatologists is around 75–84% [5,12]. Despite the formal training of dermatologists and availability of comprehensive atlases, interpretation of the features acquired by dermoscopy is often subjective and not reproducible, especially for an inexperienced clinician. Still, standard approach for classification of skin lesions in clinical practice is dermoscopy-based visual inspection, followed by biopsy and tissue analysis if needed [7].An accurate computer-based automatic diagnostic system is required to reduce the need for highly trained dermatologist and time required for diagnosis. Such system with high levels of sensitivity and specificity (typically above 90%) could provide a second-opinion to dermatologist and also reduce the number of unnecessary biopsies. In [9] a meta-analysis of several studies was performed, and showed that computer-based diagnosis is comparable with performance of a human expert. Also, it was noted that better performance was achieved using dermoscopic images than with clinical images [9,13–16].Opposed to inspection of morphological features, another line of research was focused on the MSI and HSI systems, with discrimination among tumors based on their spectral profiles. In [1], a MSI system with 10 channels in range 430–950nm was designed and used for automatic discrimination between benign nevus and malignant melanoma by using auto-fluorescence of the tumor. A HSI system with 21 channels between 440 and 660nm was used in [2] for automatic discrimination among benign and malignant skin tumors on laboratory mice based on fluorescence induced by fluorophore.While automatic systems based on dermoscopic and high spectral resolution MSI/HSI systems show great potential, it was demonstrated in [9], as well as recently in [17], that automatic diagnosis of melanoma is possible using auto-fluorescent macroscopic (clinical) color images. These methods use clinical red-green-blue (RGB) color images, and achieve sensitivity in range 80–94% and specificity in range 46–95%. While dermoscopic images captures subsurface structure of the lesion, clinical capture what a clinician sees in naked eye inspection [18]. Results of the twelve studies that used clinical images [9] as well as results from [17] are summarized in Table 1. Practical importance of these results is in demonstration that accurate automatic diagnosis of melanoma is possible from clinical images using affordable RGB auto-fluorescence imaging. A more detailed methodological review of computerized analysis of pigmented skin lesions can be found in [18], and references therein.Aim of this paper is to present a novel method for feature extraction, suitable for analysis of MSI data, and to demonstrate it on automated noninvasive diagnosis of cutaneous melanoma from clinical color images. The paper proposes a method for feature extraction from multi-way data using tensor decomposition [19,20], used for analysis of RGB color images. For this purpose experimental multispectral medical image is represented by its Tucker3 decomposition. Dimensionality analysis yields that the extracted features simultaneously contain spatial and spectral information about the image. To account for possible nonlinear nature of the acquired data, images are nonlinearly transformed prior to decomposition. The proposed scheme is demonstrated on noninvasive diagnosis of melanoma from clinical auto-fluorescent color images, and sensitivity and specificity are estimated through a two-fold cross-validation procedure.The rest of the paper is organized as follows. In Section 2 we provide preliminaries on tensor algebra, and define a nonlinear transformation based on kernel methods. In Section 3 we propose a method for feature extraction. The experimental results are presented in Section 4, with concluding remarks contained in Section 5.This section contains basics of multi-way analysis, as well as definition of nonlinear transformation related to kernels. Also, interpretation of multispectral image as tensor is presented, with focus on RGB color image. In the following, scalars will be denoted by lowercase italic letters (e.g., x), vectors by bold lowercase letters (e.g., x), matrices by bold capital letters (e.g., X), and tensors by underlined bold letters (e.g.,X_).Tensors are generalization of matrices and vectors. A tensor can be represented by a multi-way array with arbitrary number of indices, for example, an N-mode tensor has N indices. For clarity, and motivated by application in RGB image analysis, we will focus on tensors with three indices. In this paper an image RGB color image is represented by tensorX_∈ℝ0+I1×I2×I3, that consists of elementsxi1i2i3∈ℝ0+, withℝ0+denoting the set of nonnegative real numbers. Each index in tensor is called way or mode, and number of levels on a mode represents dimension of that mode, e.g., dimension of mode-1 is I1. This is in line with the standard notation used in multi-way analysis [21]. RGB imageX_is a set of I3=3 spectral images, corresponding to red, green and blue color channels [22]. Each spectral image consists of I1×I2 pixels, withxi1i2i3representing brightness intensity at pixel (i1, i2) in spectral band i3. Consequently, two modes of tensorX_are used for spatial information, i.e., rows and columns of the color image, and third mode is for spectral band. By fixing one or two indices of a three-way tensor we can define subtensors. Tensor slice is a matrix (two dimensional array) obtained by fixing a single index in a three-way tensor. For example, frontal slice of three-way tensorX_is obtained by fixing index i3, and its usually denoted asX::i3orXi3. By fixing all indices except inwe obtain an Indimensional vector called nth mode fiber. For example, mode-3 fiber ofX_at position (i1, i2) is a vector denoted asxi1i2orxi1i2:. For illustration, fibers and slices of a three-way tensor are displayed in Fig. 1.Tensor is often transformed to matrix and vice versa. Procedure of rearranging the elements of a tensor into a matrix is known as unfolding or matricization. The mode-n unfolding of tensorX_is a matrixX(n)∈ℝIn×∏k,k≠nIkthat consists of mode-n fibers stacked in the matrix as columns. The particular ordering of mode-n fibers into columns of X(n) is not important as long it is consistent through all computations [19,23]. Important notion is the n-rank of a tensor, defined as the dimension of the space spanned with columns of X(n). If three-way tensor has n-ranks equal to J1, J2, J3 we say that it is a rank-(J1, J2, J3) tensor, i.e., it has multilinear rank (J1, J2, J3).22There are other definitions of rank for tensors besides the multilinear rank, for details see [23].Mode-n product of a tensorY_and matrix A is defined when number of columns of matrix is equal to the dimension of the tensor in mode n. The result is a new tensorZ_=Y_×nA, expressed in unfolded form as Z(n)=AY(n)[19]. For example, mode-1 product of a three-way tensorY_∈ℝJ1×J2×J3and a matrixA∈ℝI1×J1is a three-way tensorZ_=Y_×1A∈ℝI1×J2×J3with elementszi1,j2,j3=∑j1=1J1yj1,j2,j3⋅ai1,j1,whereai1j1∈ℝdenotes element of matrix A on the position (i1, j1).Tensor decompositions are valuable in analysis of multi-way data, and applications in image and signal analysis, neuroscience, chemometrics and psychometrics (for detailed survey see [23]). Basic decomposition of general N-way tensor is the Tucker decomposition [24]. In case of three-way tensors it is often referred to as Tucker3 decomposition, and it is illustrated in Fig. 2. Three-way tensorX_is decomposed into three factor matricesA∈ℝI1×J1,B∈ℝI2×J2,C∈ℝI3×J3, and a three-way core tensorG_∈ℝJ1×J2×J3. For a single element, Tucker3 decomposition can be written as(1)xi1i2i3≈∑j1=1J1∑j2=1J2∑j3=1J3gj1j2j3⋅ai1j1⋅bi2j2⋅ci3j3with J1, J2, and J3 denoting dimensions of the core. Decomposition (1) can be expressed more compactly as(2)X_≈G_×1A×2B×3C.In practice, it is common that the core tensorG_is smaller than the original tensorX_, i.e., Jn<In, and if not stated otherwise we will assume this is fulfilled in remainder of the paper. In this case, tensorX_is approximated by a rank-(J1, J2, J3) tensor on the right side of (2), and (assuming the factor matrices have full rank) dimensions of the core tensorG_determine the multilinear rank of the approximation. By approximating the original tensorX_with a rank-(J1, J2, J3) tensor we effectively perform model reduction. This is the reason why this type of decomposition is of practical interest. Decomposition (2) ofX_can be seen as a composition of directional bases A, B, C in modes 1, 2 and 3, connected through a set of weights contained inG_. The elements in the core can then effectively be considered as features, that describe a sample contained in tensorX_. For example, whenX_represents RGB image the elements of the core connect spatial information (in modes 1 and 2) and spectral information (in mode 3).The Tucker3 decomposition is flexible in modeling complex interactions within the data, since the core tensor allows interaction of factors from all modes. However, this decomposition is, in general, not unique. Proof of uniqueness exists in the special case when the core tensor is diagonal (i.e.,gj1j2j3≠0only for j1=j2=j3), resulting in the canonic polyadic decomposition (CPD), also known as parallel factor analysis (PARAFAC) model, that is essentially unique (up to scale and permutation) under mild conditions [25]. For Tucker3, constraints such as nonnegativity, sparsity and orthogonality are commonly imposed on the factor matrices and the core tensor in order to attain meaningful decomposition. Particular constraints are used to narrow down the solution space and yield a virtually unique decomposition [23,24].An example of orthogonality constrained decomposition is the higher order singular value decomposition (HOSVD), a multilinear generalization of the matrix singular value decomposition33Note that the HOSVD does not give a decomposition of the data tensor with a reduced dimensions of the core tensor. It is an exact decomposition in a set of orthonormal bases, with core tensor of equal size as the original tensor.(SVD) [26]. The HOSVD decomposition of the data tensor has a form (2) with Jn=Inand orthogonal factor matrices in all modes, e.g., for mode-1 factor ATA=I holds. The factor matrix in nth mode is estimated by performing SVD of the nth mode unfolding of the data tensor, e.g., A is equal to the left singular vectors of the unfolding X(1). After obtaining the factor matrices, the core tensor is calculated as(3)G_=X_×1AT×2BT×3CT.Often we are interested in an optimal rank-(J1, J2, J3) approximation of the data tensorX_in the least-squares sense with Jn<In. The optimal approximation can be found by minimizing the Frobenius norm between the data tensorX_and its rank-(J1, J2, J3) Tucker3 decomposition:(4)D[X_(G_,A,B,C)]=X_−G_×1A×2B×3CF2while at the same time imposing orthogonality constraints on factors A, B, C. Actually, it is enough to find factor matrices that maximize functiong(A,B,C)=X_×1AT×2BT×3CTF2,and the core tensor is given with (3)[27]. Several algorithms, such as the higher order orthogonal iteration (HOOI) [27] and algorithms based on the Newton method on Grassmannians (NG) [28,29], optimize (4) through an iterative procedure. The HOOI has proved to be a “workhorse” algorithm in various applications of tensor decompositions [20]. However, note that minimization of (4) is a non-convex optimization problem with multiple local minima [27,29], and there is no guarantee of attaining the global optimum. However, in most situations, orthogonality constraints result in a virtually unique decomposition [30].Another way to obtain rank-(J1, J2, J3) approximation of the data tensorX_is to relax the optimality condition. In this case we can use the truncated HOSVD (trHOSVD) decomposition. This decomposition can be easily computed in two steps: (i) for each n unfold tensor to X(n), and calculate the standard SVD, i.e.,X_(n)=U(n)S(n)V(n)T. The orthogonal factor A is formed by J1 leading left singular vectors of X(1), i.e., the first J1 columns of U(1). Analog procedure is performed for other modes; (ii) compute the core tensor using (3). Since this decomposition is calculated using matrix SVD for each of the modes, it can be very fast, even for large problems. Since it is non-iterative there are no problems with local minima. Although truncated HOSVD (as opposed to truncated SVD in matrix case) does not give the optimal rank-(J1, J2, J3) decomposition, it is a good approximation with upper bound on error given in [26]. This type of low-rank approximation was useful in various applications. For comparison, we performed several tests comparing trHOSVD, HOOI and NG for feature extraction, with no significant difference in overall classification performance. Therefore, we used trHOSVD in the experimental section, as reported in Section 4.One of the essential problems when performing Tucker decomposition is the size of the core tensor. Since in our approach elements of the core tensorG_∈ℝJ1×J2×J3will represent features, the number of features directly depends on dimensions of the core tensor in (2). Estimation of multilinear rank of a tensor is essential, but still very difficult problem in multi-way analysis. This problem is also known as the intrinsic dimensionality problem or model order selection. Several methods have been developed recently, with various applications in signal processing and data analysis [31]. Estimation of rank in each of the modes can be based on the gap in a sequence of parameters, e.g., eigenvalues of the covariance or correlation matrix. Some of the methods in this group are GAP [32,33], RAE (ratio of adjacent eigenvalues) [34], SORTE (second order statistic of the eigenvalues) [32,33], RAESORTE [34], and EIF (empirical indicator function) [35,36]. These methods estimate mode-n rank from the unfolding X(n) by determining the number of dominant eigenvalues of the Gramm matrixX(n)X(n)T, e.g., by searching for a gap between adjacent eigenvalues. Also, information theoretic avenue can be used, resulting in model order selection methods based on Akaike's information criterion (AIC) [37], Kullback–Leibler information criterion (KIC) [38], and minimum description length (MDL) [39]. When applied to tensors, these methods analyze corresponding unfolding X(n) to estimate the intrinsic dimension in mode-n. Other approaches can be derived using Bayesian estimation, an example being automatic relevance determination (ARD) method for multi-way models [40]. The ARD method directly estimates dimensions of the core for the Tucker decomposition.All of the mentioned methods have been used in diverse applications, such as detection of number of clusters [33], dimensionality reduction using principal component analysis (PCA) [41], and the choice of number of sources in linear model [42], as well as in feature extraction [20]. However, due to different theoretical assumptions and noise in the real-world data, they often return significantly different estimations when applied to the same problem [34]. Another related problem arises from the fact that clinical images of skin lesions used in our experiments do not have equal sizes, i.e., dimensions in modes 1 and 2 are not the same for all images. This causes large variation among estimated dimensions of the core tensor for different samples. Additionally, the mentioned methods were designed to find a low-rank approximation with small n-ranks and good fit (small residual between the original tensor and its low-rank approximation). This aim is not of direct importance in feature extraction, since we seek for a decomposition that results in good classification performance. Therefore, dimensions of the core tensor are often determined through cross-validation procedure by estimating classification performance for various decompositions. However, we tested several methods for automatic n-rank estimation, with results presented and commented in more detail in the experimental section of the paper.Representation of the color image by multilinear decomposition (2) can be questioned on the basis of several arguments, see [43,44] for multi- and hyperspectral remote sensing. Taking into account possible nonlinear relations in the data is expected to improve final classification accuracy. This assumption is supported by the Cover's theorem [45]. In a nutshell, this theorem states that a set of samples, that are not linearly separable in the original (low-dimensional) space, are more likely to be linearly separable after being nonlinearly mapped into some higher-dimensional space. Consequently, it is expected that linear relations hold with high probability for the data nonlinearly mapped in a higher-dimensional space [45].In this regard, an implicit nonlinear transformation of the original image into reproducible kernel Hilbert space (RKHS) is performed, based on kernel techniques. Description of the kernel-based nonlinear transformation will be given here due to completeness, but for a detailed theoretical treatment interested reader is referred to [46]. Letk:S×S→ℝbe a real, positive definite kernel, andS⊆ℝIa nonempty set. Then mapΦ:S→ℝScan be defined as s↦Φ(s)≔k(., s), whereℝS≔{f:S→ℝ}is a set of all functions from S toℝ. In this way each input sample s∈S is mapped to a function Φ(s) defined on the input space, which is possibly an infinite dimensional object. However, it is possible to obtain an approximation of the map Φ by evaluating it only on a set of points, since the transformed data is embedded in a subspace of RKHS [46,47]. Letv1,…,vD⊂Sbe a set of points in the input space. Then transformationΦD:S→ℝDdefined ass↦ΦD≔[k(v1,s),…,k(vD,s)]Tis called the empirical kernel map with respect to a set of points {v1, …, vD} [46]. In this way, nonlinearly transformed data is projected into a D dimensional subspace of RKHS, while at the same time all calculations are performed on the original data from the input setS⊆ℝI[46]. Obviously, D≫I must hold to exploit benefits stipulated by the Cover's theorem. Complex problem of selecting the points {v1, …, vD} is known as basis selection. Various basis selection methods were previously proposed, such as kernel PCA [48] and feature vector selection [49]. In experiments we use k-means clustering, with basis vectors estimated as centroids of k=D clusters, as in [47].In this paper we perform nonlinear transformation of the sample tensorX_along the mode 3, i.e., each mode-3 fiber (corresponding to a single pixel), is nonlinearly mapped to a new D dimensional vector,xi1i2:↦ΦD(xi1i2:)=[k(v1,xi1i2:),…,k(vD,xi1i2:)]T. Nonlinear mapping for tensor objectsΦD:ℝI1×I2×I3→ℝI1×I2×DX_↦ΦD(X_)that maps a three-way tensorX_to a new three-way tensorΦD(X_), is defined by replacing each mode-3 fiberxi1i2:with its imageΦD(xi1i2:).44This is actually a slight abuse of notation, since map ΦDwas originally defined for vectors, not tensors. The notationΦD(X_)can also be interpreted in the following sense: we take mode-3 unfolded tensor X(3), perform nonlinear map of each column, and then rearrange columns back to a three-way tensor.As mentioned, basis points {v1, …, vD} are estimated by k-means clustering of mode-3 fibers{xi1i2:}into D clusters. Now, Tucker3 decomposition can be used to represent nonlinearly transformed data as:(5)ΦD(X_)≈G_×1A×2B×3C.Since D≫I3 the core tensor in decomposition (5) can have greater dimension J3 than the core tensor in (2). In the experimental section we use Gaussian kernelk(x,y)=exp(−x−y2/σ2). Also, we experimented with other kernels, such as Laplaciank(x,y)=exp(−x−y/σ2)and polynomialk(x,y)=(1+x,y)d, but this did not result in better results than with the Gaussian kernel.The proposed feature extraction scheme is summarized in Algorithm 1. Let us assume that our dataset consists of K samples (e.g., RGB images of skin lesions), each represented by a three-way tensorX_(k), k=1,…,K. Also, let a class label c(k) be assigned to each sample, e.g., c(k)=1 if kth sample belongs to class 1 (benign nevus), and c(k)=2 if it is from class 2 (melanoma). The proposed feature extraction procedure consists of nonlinear transformation of each sampleX_(k), followed by tensor decomposition using trHOSVD algorithm. Core tensor is calculated directly from the nonlinearly transformed sample by projecting the tensorΦD(X_(k))onto factors A(k), B(k) and C(k) obtained by the trHOSVD. Finally, features are obtained by rearranging elements of the coreG_(k)into a vector g(k), since standard classifiers use vector representation of the samples.55The vectorization procedure was performed by stacking mode-1 fibers of the core tensor. However, ordering of the elements of the core tensor is not important, as long as the same procedure is used for each sample.Note that feature extraction is performed on each sampleX_(k)separately, but with the same parameters (σ, D) for the nonlinear transform and fixed dimensions of the core (J1, J2, J3). In this way, for each image we obtain the same number of features, equal to the number of elements of the core tensor.From feature extraction point of view it is important that the core tensorG_(k)connects two spatial modes with spectral mode of the transformed image. In this way, the core tensor represents a spatial-spectral profile of the lesion present in the imageX_(k)while each elementgj1j2j3(k)of the core tensor can be viewed as a spatial-spectral characteristic of the lesion. This can be seen from the following expressiongj1j2j3(k)=ΦD(X_(k))×1(aj1(k))T×2(bj2(k))T×3(cj3(k))T,whereaj(k)is jth column of A(k). Featuregj1j2j3(k)is obtained by projecting tensorΦD(X_(k))onto appropriate columns of factor matrices. Therefore, factor matrices in (4) can be seen as directional projection matrices for feature extraction in each of the modes. Consequently, we conjectured that the core tensor viewed as a set of features can be used for robust and accurate noninvasive diagnosis of melanoma.Proposed feature extraction method differs from the one recently published in [20], where simultaneous tensor decomposition is performed for all samples in the training set to find projection matrices. Consequently, it is required that all images in the data set have the same dimensions (both in spatial and spectral modes). However, this requirement is not easily met in practice, and method proposed here allows greater flexibility when acquiring clinical images for analysis. Also, separate decomposition of each sample enables us to easily update training set when new labeled sample is available, since it is decomposed independently of other samples previously present in the training set.Introduction of nonlinear transformation prior to tensor decomposition was motivated by practical experience. We performed several experiments with direct decomposition of the original images and results were not satisfactory. Since spectral dimension of RGB images is very low, we introduced a nonlinear transformation that increases dimension in the mode-3, as described in Section 2.3. This resulted in a significant increase of performance, with results reported in experimental section.Algorithm 1Proposed method for feature extraction.Input: three-way tensorX_(k)∈ℝ0+I1×I2×I3, autofluorescent RGB imageParameters: kernel map (σ, D), core size (J1, J2, J3)Do:• nonlinear transformationX_(k)↦ΦD(X_(k))• tensor decompositionΦD(X_(k))≈G_(k)×1A(k)×2B(k)×3C(k)• feature extractionG_(k)=ΦD(X_(k))×1(A(k))T×2(B(k))T×3(C(k))T• vectorization of the core tensorgˆ(k)=vec(G_(k))Output: featuresgˆ(k)∈ℝJ1⋅J2⋅J3Classification system built around the proposed method is displayed in Fig. 3. Feature extraction is performed for each sample in the data set with the same values of parameters σ, D, and Jn, n=1, 2, 3. In this way all of the K core tensors have the same dimensions and for each sample we obtain L=J1·J2·J3 features used for classification. Validation step consists of partitioning the K samples (g(k), c(k)) into two sets: KTRtraining samples(gTR(k),cTR(k))and KTEtest samples(gTE(k),cTE(k)). In the experimental section we used linear support vector machine (linSVM) classifier, and nonlinear SVM with the Gaussian kernel (rbfSVM) and polynomial kernel (polySVM), although other classifiers can be used as well.In order to obtain a reliable estimate of classification performance on an independent data set, we performed a two-fold cross-validation (CV). In general, CV is performed by using some samples from the data set to train the classifier, and remaining samples to test it [4]. In K-fold CV the data set is divided into K equally sized parts so that each contains the same proportion of all class labels. In the kth step classifier is trained on K−1 parts of the data set and tested on kth part of the data set. The procedure is repeated for k=1,…,K and the K results are combined to calculate the final estimate of the classification performance. For example, in case of a two-fold CV samples are divided into two equal sized data sets, each consisting of 50% of samples from class 1, and 50% of samples from class 2. In order to obtain a more reliable estimate of prediction performance, CV is repeated several times and the validation results are averaged.Even though the number of features L is significantly smaller than the number of elements in each of the tensorsΦD(X_(k)), it can still be large. Thus it is reasonable to perform a feature selection (FS) step to identify significant features obtained by the proposed method. We ranked features based on the Fisher score [20], albeit other information criteria can also be used for ranking [50]. For each feature Fisher score is calculated using samples in the training set as:φ(i)=KTR1(g¯TR,i1−g¯¯TR,i)2+KTR2(g¯TR,i2−g¯¯TR,i)2∑k=1KTR(gTR,i(k)−g¯TR,icTR(k))whereKTRcdenotes the number of training samples belonging to the cth class (c=1, 2),gTR,i(k)is ith feature of kth training sample,cTR(k)label of the kth sample,g¯TR,icis the mean of the ith feature calculated over training samples from class c, andg¯¯TR,iis the mean of the ith feature calculated over all training samples. Larger value of Fisher score means that the feature is more discriminative. Feature selection is performed by selecting a number of features with largest Fisher score.

@&#CONCLUSIONS@&#
Tensor representation of a multi-spectral image enables extraction of features that simultaneously capture spatial and spectral characteristics of object present in the image. Proposed feature extraction is performed through Tucker3 decomposition of nonlinearly mapped image. The method relies on well-known computational procedures, such as singular value decomposition, that can be efficiently implemented in embedded devices. As demonstrated, the proposed method compares favorably with the state of the art results reported in the literature. In perspective, an automated system based on a cost-effective, and nowadays ubiquitous, RGB camera could possibly be used for preliminary screening in distant areas and areas without appropriate medical care. The software with diagnostic algorithm could be implemented for some of the widespread smartphone platforms or for an application-specific low-cost device.However, several directions are opened for future research. One possibility is to include additional post-processing of the extracted features. Replacing the feature selection step with an additional feature extraction step could possibly result in better performance. In this case one could apply linear techniques (e.g., linear discriminant analysis), or tensor-based feature extraction [20]. It would be interesting to perform additional experiments using a larger dataset, consisting of images acquired under controlled conditions. Classification performance in different (controlled) scenarios would give a better assessment of the real-world performance, and could provide valuable insight and directions for future development. An important contribution to computer-based analysis of pigmented skin lesions would be to build a benchmark data set with clinical images, which could be used for direct comparison of diagnostic methods.