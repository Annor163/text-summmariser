@&#MAIN-TITLE@&#
Parameter identification of PWARX models using fuzzy distance weighted least squares method

@&#HIGHLIGHTS@&#
A novel fuzzy distance weight matrix based parameter identification method.Fuzzy clustering based algorithm used to find sub-models of HDS.WLS algorithm is used to identify parameters of sub-models.Results validated through simulation experiments.

@&#KEYPHRASES@&#
PieceWise AutoRegressive eXogenous,Hybrid dynamical system,Fuzzy-c-means clustering,Fuzzy distance weight matrix,Weighted least squares,

@&#ABSTRACT@&#
PieceWise AutoRegressive eXogenous (PWARX) models represent one of the broad classes of the hybrid dynamical systems (HDS). Among many classes of HDS, PWARX model used as an attractive modeling structure due to its equivalence to other classes. This paper presents a novel fuzzy distance weight matrix based parameter identification method for PWARX model. In the first phase of the proposed method estimation for the number of affine submodels present in the HDS is proposed using fuzzy clustering validation based algorithm. For the given set of input–output data points generated by predefined PWARX model fuzzy c-means (FCM) clustering procedure is used to classify the data set according to its affine submodels. The fuzzy distance weight matrix based weighted least squares (WLS) algorithm is proposed to identify the parameters for each PWARX submodel, which minimizes the effect of noise and classification error. In the final phase, fuzzy validity function based model selection method is applied to validate the identified PWARX model. The effectiveness of the proposed method is demonstrated using three benchmark examples. Simulation experiments show validation of the proposed method.

@&#INTRODUCTION@&#
Hybrid dynamical systems (HDS) are systems that involve nonlinear continuous dynamics and discrete events with some logical rules [1,2]. A mathematical model of the HDS must change its continuous dynamic as the discrete event occurred in the systems. PieceWise AutoRegressive eXogenous (PWARX) models have been widely adopted by researcher to represent various HDS due to their universal approximation properties of PieceWise Affine (PWA) maps and their equivalence to other classes of the HDS [3–5].The PWARX models comprise a set of classical ARX submodels, each of which is partitioned with a finite number of the polyhedral partitions. The identification of PWARX models involves the estimation for the number of submodels present in the HDS, the parameters of each submodel and the regions of the submodel defining the polyhedral partition. In [6] methods for the identification of the PWA models of the HDS are classified. The identification problem becomes more challenging as it includes the estimation of the number of submodels along with data classification, parameters and method to verify the identified model parameters. According to [5], four procedures for the identification of PWARX models are algebraic procedure [7], clustering-based procedure [8], Bayesian procedure [9] and bounded-error procedure [10]. The PWA system identification using mixed-integer quadratic programming (MIQP) and mixed-integer linear programming (MILP) proposed in [11] which is NP-hard and required more computations. However, the estimation of the number of submodels and the selection of submodels has not been dealt properly in the reviewed literature.The aim of the paper is to show how to estimate the number of submodels and identification of the parameters of the submodels associated with each discrete event along with the classification of the data points with reasonable computational complexity. Clustering algorithms have been widely used in data classification, pattern recognition, system modeling, machine learning and image processing [12]. In the past few years, many clustering algorithms have been developed and used for the classification of the data points for the PWARX models. Works based on clustering algorithms for identification of the PWARX models have been reported on k-means [8,13,14], support vector classifier [5] and fuzzy clustering [15–18]. The clustering based procedure, proposed by [8] and [13] consists of the k-means clustering approach with the assumption that the number of discrete modes given a priori. The statistical clustering based identification approach given in [14], proposed the algorithm for estimating the number of submodels, but it requires an exhaustive search between two predefined limits. However, the k-means clustering procedures suffer from the drawbacks of poor initialization and influence of outliers. In k-means clustering algorithms, data points are partitioned into some clusters such that each data point is assigned to exactly one cluster. However, in fuzzy clustering, a data point may belong to several clusters with degree of membership function. Therefore, the membership function values for a data point will represent the degree to which that point belongs to a particular cluster. The Fuzzy c-means (FCM) clustering is one of the most popular and efficient unsupervised partitioned algorithm used in several applications where the clustering is overlapping [19–21]. Moreover, the FCM can handle uncertainty and noise better when there is no information about the structure of the data. The FCM clustering based identification approach proposed by [15] estimates the number of submodels, but the nonlinear regression vector is used to identify the PWARX model. The fuzzy clustering based technique for PWA approximation proposed by [16,18] assumes that the number of submodels is given for the nonlinear systems. In this paper, the FCM clustering algorithm is used which enables an estimation of the number of submodels present in the PWARX models. We show how to estimate the number of submodels using fuzzy cluster validation approach. In this paper, we present new weighted least squares (WLS) approach for identification of parameters of the submodels based on fuzzy distance weight matrix. Once the data points have been classified according to its discrete events a linear regression is used to compute the parameters of the submodels. However, pure linear least squares do not give the optimal value of the parameter due to classification error and sensitive to outliers [8,22]. In order to solve this shortcoming, fuzzy distance weight matrix based weighted least squares (WLS) approach is proposed which suitably defined confidence measures and reducing the influence of outliers on the given data points by means of membership functions. We also verify the effectiveness of the proposed methodology on two benchmark PWARX systems and a Hammerstein model which is composed of static nonlinearity along with linear system.This paper has been organized as follows: Section 2 represents the formulation of the identification problem for PWARX models. Section 3 provides details of the various phases of the proposed method for the given problem in Section 2. In the same section two illustrative benchmark mathematical examples and a Hammerstein model are used to support the proposed fuzzy weight matrix based parameter identification method. Finally, Section 4 summarizes the contributions of this paper and possible future research work.Consider the discrete-time HDS with input u(t)∈Rnuand output y(t)∈R at time t having discontinuous dynamics where nuis the number of inputs. Let y(t−1) and u(t−1) be past value of inputs and outputs, respectively, generated by the system up to time t−1. PWARX models are described by a relationship between past observations and future output y(t) in the form given below:(1)y(t)=f(x(t))+e(t)where x(t)∈R⊆Rpis referred to as the regression vector in terms of past observations of input and output, e(t)∈R is a white noise added to the output, and f is a piecewise affine map function of the form(2)f(x(t))=θλtTφ(x(t))ifx(t)∈ℛλtwhere the output f(x(t))∈R is a scalar, λt∈{1, …, s} is the discrete events associated with the HDS, s is the number of submodels present in the PWARX model,θλtT∈Rnis the parameter vector defining for each λt in terms of matrixes, and φ(x(t))∈Rmis the linear extended regression vector which is a function of x(t) given by φ(x(t))=[x(t)1]T. The regression vector x(t) with the fixed structure depending only on the past naoutputs and nbinputs are defined as(3)x(t)=[y(t−1)…y(t−na)u(t−1)T…u(t−nb)T]Twhere p=na+nbnu.The polyhedral regions ℛλtform a complete bounded polyhedron partition of ℛ (i.e.ℛ=⋃λt=1sλt) and ℛi∩ℛj=ϕ;∀i≠j. The each region ℛλtis assumed to be convex polyhedron. The switching law between the PWARX models is specified by the rule: if x(t)∈ℛλt, the λtth submodel dynamic is active.Assumption 1The data pointsz(t)={y(t),x(t)}t=1Nare generated from the PWARX model (1) with given number of discrete regions s, the parameter vectors{θλt}λt=1sfor each submodels, the polyhedral regions ℛλtand the dimension p for the regression set with the model orders of the past naoutputs and nbinputs.The data pointsz(t)={y(t),x(t)}t=1Nare generated according to given Assumption 1 and the number of inputs{ℛλt}λt=1sand ℛ are known, the identification problem to solve s linear estimation problem for each partition. The regression vector x(t) can be classified into λt sets of partitions ℱλtaccording to rule if x(t)∈ℛλt, data pointsz(t)={y(t),x(t)}t=1N∈ℱλt.Given a set of data points z(t) which are generated by a hybrid or piecewise linear system of the form (1) and (2) with Assumption 1 hold, the objective is to estimate the number of submodels s present in the systems and the parameter vectors{θλt}λt=1sfor each submodel along with switching condition based on regions ℛλt.The identification of a PWARX model of a finite of data pointsz(t)={y(t),x(t)}t=1Nis a complex problem which requires techniques to estimate the number of discrete modes at the same time classification of the data points according to its discrete events. The considered identification problem consists in finding the PWARX model that involves the estimation for the number of submodels associated with HDS and parameter vector θλtof the each affine submodel.Example 1Consider the following single-input-single-output (SISO) PWARX model [8]:For the given PWARX system na=0, nb=1 are given a priori and 50 input samples, u(t)∈R, are applied randomly according to the uniform distribution on [−4,4] to generate the output samples. Here the regression vector is x(t)=[u(t−1)]Tand data pointsz(t)={y(t),u(t−1)}t=150. The measured output is corrupted by Gaussian noise with variance 0.05. Fig. 1shows 50 sample data points of the given system along with the region of partitions.The problem becomes easy if the number of submodels s is fixed, and the switching conditions are known a priori. The procedure proposed in this paper assumed that the number of submodels present in the given PWARX models and switching mechanism between the submodels are not given a priori. The framework for the identification of the PWARX models is summarized as follows:Phase 1: Estimation of the number of submodels.In this phase, the measured inputs and output data points are used to estimate the number of submodels present in the HDS by using proposed fuzzy clustering based index. Initialize this phase with the assumption of maximum number of submodels and phase complete with the optimum number of submodels represent by s presents in the HDS.Phase 2: Classification of the measured data points.In this phase, the FCM clustering algorithm is applied in order to obtain the classification of measured data points into s partitioned data points for each submodel.Phase 3: Identification of PWARX submodel parameter.This phase represents a novel fuzzy distance matrix weight based weighted least squares (WLS) algorithm in order to obtain PWARX submodel parameter vector{θλt}λt=1s.Phase 4: Submodel selection and validation.This phase shows the effectiveness of the proposed identification method for parameters of the PWARX model. The fuzzy function based selection criteria is used for the measured data to select the appropriate submodel and predict the new output of the hybrid system.The identification algorithm for PWARX models for solving the problem statement mentioned in the last section composed of the four phases explained as below.The main difficulty in solving the mentioned problem is to estimate the numbers of submodels present in the given PWARX model. Xie–Beni's validity index for FCM clustering based approach is used to estimate the number of submodel present in the open loop data points of the HDS. Since FCM partition clustering algorithm is unsupervised, it requires the number of cluster centers or partitions present in the data points. The choice of optimal number of cluster centers or submodels for partitioning the given data points depend upon clear separation between the cluster centers, the minimum volume of the cluster and maximum number of data points concentrated in the vicinity of the cluster center. FCM algorithm of partition clustering allows one piece of data point to belong to two or more clusters with the degree of belongingness. This method (developed by Dunn in 1973 and improved by Bezdek in 1974) is frequently used in pattern recognition [23]. The fuzzy set is distinct from a crisp set that it allows the elements to have a degree of membership function for each cluster.Objects to be clustered are denoted by z(t)=(x(t)1, …, z(t)p)∈Rp; t=1, …, N, vectors in p-dimensional Euclidean space. Given a set of N-observations in p-dimensional Euclidean space, FCM clustering aims to partition it into k subsets (k<N) of cluster centers C such that it minimize the within-cluster Sum of Squares (WCSS). Cluster centers arec(i)=(c(i)1,…,c(i)p)T; i=1, …, k, where k is the number of clusters and abbreviated symbol C=c(1), …, c(k) is used for complete collection of cluster centers. The FCM minimizes the following objective function:(5)J(C)=∑i=1k∑t=1N(μit)m||z(t)−c(i)||2where, N is the number of data points, k is the number of clusters with 2≤k<N, z(t) is tth measure data point in p-dimension, μitis the degree of membership function for data point z(t) in the ith cluster, m∈[1, ∞] is a weighting exponent which determines the degree of fuzziness in the resulting clusters, ||·||2 is any second order norm expressing similarity between any measured data and the cluster center. For normalizing membership function linearly such that it sum is a 1 select value of m=2. As one select value of m is close to 1, then the data point close to the cluster center is given much more weight than the other cluster centers and the algorithm is behave like to hard clustering. The membership matrix U=[μit] and its elements have membership values between 0 and 1.The proposed algorithm for estimation of the number of submodels given in Table 1. The algorithm starts with initializing the value of fuzziness m, termination criteria of the algorithm ɛ∈[0, 1] and maximum number of clusters in the given hybrid system by cmax. Next step is to select k points as the initial number of cluster centers (means) denoted by (c(1)j, …, c(k)j). For the randomly selected cluster centers compute the element of membership matrix U for each data point by minimizing the objective function given in (5) and solution is:(6)μitj=(1/||z(t)−c(i)j||2)1/m−1∑l=1k(1/||z(t)−c(1)j||2)1/m−1Update the vector elements of cluster center C using the membership function elements by minimizing (5) and solution is:(7)c(i)j+1=∑t=1N(μitj)mz(t)∑t=1N(μitj)mRepeat the solution of (6) and (7) until the algorithm satisfies the termination criteria ||Uj+1−Uj||≤ɛ.The data points nearer to the cluster center have highest membership function value and the membership function value gradually decreases as data points move away from the cluster center. The good clustering algorithm should generate clusters with small intracluster deviations, and large inter-cluster separations [24]. The global compactness of FCM partitions of the input data set can be defined as [25](8)comp(k,U)=1N∑i=1k∑t=1N(μit)m||z(t)−c(i)||2The above equation of the compactness matrix is combined with the fuzzy nature of membership function which give more weight to data points which is nearer to the cluster center and less weight to far away data points. For the better partition between data points and cluster center, value of comp(k,U) given in (8) must be smaller. The separation among the cluster centers for the classification of the data points can be calculated by(9)sep(k,U)=mini≠j||c(i)−c(j)||2For complete separation between the cluster centers value of sep(k,U) must be larger which also indicates the proper partitioning of the given data. The ratio of (8) and (9) defined as Xie–Beni's index cluster validity for fuzzy based clustering given in [26,27].(10)cent(k,U)=comp(k,U)sep(k,U)A smaller value of cent(k,U) indicates a compact and clear partitioning of the data points. The proposed algorithm is ended with the number of submodels present in the PWARX systems indicated by s at which the minimum value of cent(k,U).For the given data pointsz(t)={y(t),u(t−1)}t=150of Example 1 above mentioned algorithm is applied with initial value of the maximum number of cluster centers present in the system as cmax=5, fuzzy ness function m=2 and termination criteria ɛ=10−5. The resulting values of cent(k,U) for different values of the cluster center from 2≤k≤5 shown in Fig. 2. The estimated optimal values of the cluster center by applying the proposed algorithm are three, which is the exact number of submodels present in the PWARX model of Example 1. This phase gives the number of submodel presents in the hybrid system which is utilized as the number of cluster centers presented in open loop data of the system for the classification of data points.Once the number of submodels is obtained, then it is required to classify the measured data points according to discrete events present in the HDS. In general clustering algorithms can be classified into two categories: Hierarchical algorithms and Partitional algorithms. Partitional clustering algorithms identify the partition that optimizes (usually locally) clustering criteria. Partitional methods have advantages in applications involving large data sets for which the construction of a dendrogram is computationally prohibitive [28].Conventional partitional clustering algorithms use hard partition derived from the classical set theory: contain μitmembership function value 0 or 1. These algorithms may trap in local minima due to poor initialization. The FCM clustering algorithm uses soft classification using shape membership functions whose values between zero and one. The FCM partitional data classification method separates the data points into clusters based on number of cluster centers given initially. The FCM clustering algorithm is used to classify the measured data point with derived value of the number of cluster centers from phase 1, and denoted as s=min{cent(k, U)}. The FCM clustering algorithm requires an initial value of cluster center s, amount of fuzziness and termination criteria. The FCM clustering based techniques classify the data points based on their membership function, the highest membership function indicates the data point belongs to that cluster. The FCM clustering method classifies the data point into s partitions and also gives the location of the cluster center for each partition. The degree of belongingness of each data point to their respective each cluster center is also derived through membership matrix.For the given Example 1 FCM clustering algorithm is applied to data points denoted asz(t)={y(t),u(t−1)}t=150with m=2 and ɛ=10−5. The value used for number of cluster centers present in the given example derived from phase 1 is s=3. The open loop data classification result is shown in Fig. 3along with location of final cluster centers denoted as □, ♢ and ○ symbols.Once the data have been classified, linear regression can be used to compute the final parameters of the submodels. However, pure least squares are not the optimal choice since they are sensitive to outliers that may be present because of classification errors. In this phase, WLS given in [8] is used to reduce the effect of classification errors and outliers by defining a confidence measure on the data points. Here, FCM clustering algorithm having another advantage that it classified the data according to the submodels and also give cluster centers for each submodels. Now, the cluster centers used to calculate the fuzzy distance weight matrix for each data point based on distance between data points and their respective cluster center. The fuzzy distance based weight matrix denoted by W=[ωit] and the element of given matrix is calculated using s-shape membership function given by(11)ωit=(1/||z(t)−c(i)||2)8∑l=1s(1/||z(t)−c(1)||2)8ifz(t)∈c(i)where i=1, …, s. Each element of the fuzzy distance weight matrix must fulfill the following constraints:•ωit∈[0, 1], 1≤i≤k, 1≤t≤N∑i=1kωit=1,1≤t≤N0<∑i=1Nωit<N,1≤i≤kAs the data points at vicinity of the cluster center value ωithave higher value nearer to one. The λtth submodel parameter is estimated based on the data point collected in the region ℛλt. The parameter vector θλ,tis computed for each submodel by minimizing of the objective function(12)J(θλt,θit)=∑z(t)∈ℛλt(W)||y(t)−θλtTφ(x(t))||2To minimize the objective function (12) optimally, take the derivative with respect to the parameter θλtminθλtJ=(W)(y−θλtTφ)T(y−θλtTφ)∂J∂θλt=2(W)(y−θλtTφ)T(−φ)=0(−φ)T(y−θλtTφ)(W)T=0(13)θλtT=(φTWφ)−1φTWyThe above Eq. (13) gives the optimal value of the parameter vector for each submodel based on the weight, assign to the data points based on distance from the cluster center. To show the effectiveness of the above WLS based method for identification of PWARX model parameters is applied on Example 1. For each data point calculates the weight matrix and applied Eq. (13), then obtained parameter vectors areθ1[1.02571.9150],θ2=[−0.9630−0.0673],θ3=[0.97701.8756]Above identified parameters providing a good approximation of the given PWARX system as in (4). Results are also comparable with [8]. However, in [8] researcher has used double clustering algorithm and region estimation for identified model. In present algorithm we proposed new submodel selection method given in next phase, in which no need to estimate the boundary of hyperplanes still we can obtained the result similar to [8].The purpose of this phase is to select the final model for the estimation of one step ahead prediction output and test the efficiency and precision of the identified PWARX model parameter. The one step ahead prediction for output of HDS based on final submodel selection procedure proposed in [24]. In this procedure predicted output is calculated for all identified submodels from the measured input and output data, but only one output is selected based on validity function vj. The location of the cluster center resulting from phase 2 used to calculate the validity function for the measured data points. The equation to find validity function is given by(14)vj=(1/||x(t)−c(j)||2)∑l=1s(1/||x(t)−c(1)j||2)where 1≤j≤s. The validity matrix is denoted as V=[vj]. The final one step ahead predicted output out of all submodels output is selected based on highest validity matrix element given by(15)yˆ(t)=yj(t)ifj=index(max(v))The complete algorithm to select the submodel for estimation of the final output is shown in Fig. 4. To measure the accuracy of estimated outputyˆ(t)FIT criteria is given by [22](16)FIT=1−||yˆ(t)−y(t)||2||y(t)−mean(y(t))||2×100%where y(t) is the actual output of the hybrid system andyˆ(t)is the estimated output.For Example 1 proposed validation algorithm is applied to a new set of validation data generated with Gaussian measurement noise variance of 0.06. Fig. 5shows the result with actual output as blue lines and the estimated output as red lines. The accuracy of the estimated output measured based on (16), which gives the FIT value 91.8205%. This indicates that the given validation algorithm performs very well despite the amount of noise present in the HDS.Example 2To verify the proposed identification algorithm we consider the second single-input-single-output (SISO) PWARX system with more complexity given in [10,14] asThen consider PWARX system is a function of both input and output terms in parameters and partitions, which makes the identification and estimation task more complex. For the given PWARX system with na=1, nb=1 are given a priori and 200 output samples are generated by applying input samples u(t)∈R and the noise signal ∈(t) randomly according to the uniform distribution on [−5,5] and [−0.2, 0.2], respectively. The 200 data pointsz(t)={y(t),x(t)}t=1200be generated for the given system in (17) where x(t)=[y(t−1)u(t−1)]T. Generated data points are shown in Fig. 6(a) in the regression space R2.For the given data points the number of discrete modes was calculated through the algorithm given in phase 1 with assuming that the maximum number of discrete mode presents in the HDS are 5, fuzziness m=2 and termination criteria ɛ=10−5. The values of s with respect to different values of the cluster center shown in Fig. 7, which give optimal value of the discrete modes present in the system is 3. The estimated number of discrete modes matches with the actual number of submodels present in the system. Once the number of submodels was derived, the measured data points are then required to classify into different clusters. FCM clustering based data classification algorithm applied to classify the data point to a number of cluster center as 3 derived from phase 1. The classification results shown in Fig. 6(b) with location of cluster centers for each cluster. The dash-dotted lines represent the boundaries of hyperplanes regions from left to right.Now, for each data point weights are calculated with respect to their belonging cluster center derive from FCM clustering algorithm using (11). Now, applying the weighted least square algorithm given in phase 3 to calculate the parameter vectors for each submodels and obtained values of it given asθ1=[−0.39020.95861.6511]θ2=[0.3467−0.8094−0.2953]θ3=[−0.21020.4425−2.0834]Above identified parameters gives the best approximation of the given PWARX model in (17). To test the above-derived parameters the validation algorithm given in phase 4 is applied for different validation data set generated by the uniformly distributed noise signal of [−0.2, 0.2]. The validation function is calculated from each measured data points and based on that final estimated output given with red line in Fig. 8. Using Eq. (16), the FIT for the estimated output is 74.426%. Results are also comparable with [10,14]. However, in [10] and [14] researchers have used estimation of the boundary hyperplanes on the regressor space. In present algorithm no need to estimate the boundary of hyperplanes with assumption of regressor space. Still we obtained the result similar to [10,14].Example 3The proposed identification approach is applied to Hammerstein model shown in Fig. 9, which is configured as a series connection of static nonlinear blocks with a dynamic linear time-invariant (LTI) system block. We consider SISO Hammerstein model described in [14]. Let us consider static nonlinearity function ℵ(·) is a static PWA saturation function given asThe plant G is a LTI system whose dynamic is given byy(t)=−0.5y(t−1)−0.1y(t−2)+a(t−1)+∈(t)where ∈(t) is the zero means normally distributed measurement noise with variance of 0.04.The Hammerstein process model shown in Fig. 9 can be expressed as a PWARX model byy(t)=[−0.5−0.102][y(t−1)y(t−2)u(t−1)1]T+∈(t),ifx(t)∈X1=u(t−1)−2>0[−0.5−0.110][y(t−1)y(t−2)u(t−1)1]T+∈(t),ifx(t)∈X2=u(t−1)−2≤0andu(t−1)+1≥0[−0.5−0.10−1][y(t−1)y(t−2)u(t−1)1]T+∈(t),ifx(t)∈X3=u(t−1)+1<0For the given Hammerstein model na=2, nb=1 are given a priori and 200 output samples are generated by applying normally distributed input samples u(t)∈R with zero mean and variance of 4. For the given data pointsz(t)={y(t),x(t)}t=1200, we estimate the number of submodels s with cmax=5, fuzziness m=2 and termination criteria ɛ=10−5. The derived values of s with respect to different values of the cluster center using a proposed estimation algorithm is 3. For s=3, the measure data points are classified using a FCM clustering algorithm. Using (11), weights are calculated with respect to their belonging cluster center for each data point. The parameters for each submodel are obtained using the proposed WLS algorithm given in phase 3 asθ1=[−0.4512−0.04590.07371.6808]θ2=[−0.4672−0.07430.7215−0.0964]θ3=[−0.5113−0.1073−0.0006−0.9736]Above identified parameters gives the best approximation of the given PWARX model in (17). To test the above-derived parameters the validation algorithm given in phase 4 is applied to different data set having measurement noise with variance of 0.05. The validation function is calculated from each measured data points and based on that final estimated data given with dotted lines in Fig. 10. Using (16), the FIT value of the estimated data is 72.826%. This example indicates that the proposed approach is applicable to a Hammerstein model.

@&#CONCLUSIONS@&#
In this paper, a new fuzzy weight matrix based method is used for the identification of hybrid system with unknown number of discrete modes. This method is applicable to complex PWARX model and noisy systems. In the literature [8,11,13,16], the number of submodels has to be given a priori. In order to resolve this issue, Xie–Benni based approach proposed in this paper which requires only maximum number of submodels present in the systems.In work done by Ferrari-Trecate et al. [8] and Bemporad et al. [10], the classification of given input and output data points based on double clustering process. In order to reduce classification errors and the effect of outliers, the FCM clustering algorithm is used in this paper to classify the data points. Classification of the data points using FCM also gives the location of cluster centers, which are used for the identification and prediction of the output. In [15], regression vector obtained as nonlinear functions of past input and output. As in [10,14,15] a parameter of PWARX system is estimated using pure least squares method which is sensitive from outliers and misclassification. For this reason, fuzzy weight matrix based weighted least squares parameter identification method is proposed for linear and affine regression vector.Finally, the proposed method has been designed such that it can validate the identified parameters of PWARX models using model selection criteria. The main contribution of the paper is to propose methodology for PWARX parameter identification, where number of models is not necessary to know, switching surfaces need not to determine and the system dynamics are discontinuous. The suggested methodology has been applied and validated for two different PWARX systems and a Hammerstein model.An interesting issue to decide the order of the PWARX model and implementations of the proposed method to some hybrid and nonlinear systems such as in [29] are still open. Moreover, other possible future topic of research is to design the inputs for the PWARX models such that not only all the affine dynamics are sufficiently excited, but also accurate shaping of the boundaries is possible.