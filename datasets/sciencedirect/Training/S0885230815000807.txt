@&#MAIN-TITLE@&#
Automatic detection of stridence in speech using the auditory model

@&#HIGHLIGHTS@&#
Stridence is appearance of intense and sharp whistling in speech.An algorithm for stridence detection using Patterson's auditory model is presented.Three levels of decision are applied according to the categorical perception.Automatic detection is similar to that obtained by trained speech therapist.

@&#KEYPHRASES@&#
Speech pathology,Stridence,Pathology detection,Auditory model,

@&#ABSTRACT@&#
Stridence as a form of speech disorder in Serbian language is manifested by the appearance of an intense and sharp whistling. Its acoustic characteristics significantly affect the quality of verbal communication. Although various forms of stridence manifestation are successfully diagnosed by speech therapists, there is a need for the automatic detection and evaluation of stridence. In this paper, an algorithm for stridence detection using Patterson's auditory model is presented. The algorithm consists of three processing stages. In the first stage spectral analysis and masking effects are applied using Paterson's auditory model. In the second stage a contour of spectral peaks that best fits characteristic features of the stridence is selected in the time-frequency (TF) representation of the signal obtained by Patterson's auditory model. In the third stage hypothesis testing is performed with three decisions: D0 – no stridence, D1 – stridence, and D2 – unable to decide. The reliability of stridence detection is tested on the speech corpus of 16 speakers without stridence (with correct speech), 16 speakers without stridence but with some other speech sound disorders, and 16 speakers with stridence. Test results show high correspondence of subjective measures and automatic detection.

@&#INTRODUCTION@&#
Fricatives and affricates are groups of phonemes with common problems in pronunciation. Fricatives are articulated by forcing air through a narrow constriction in the vocal tract, resulting in a steady friction noise, while affricates are articulated by forming a complete constriction, which release is accompanied by the friction noise. Like affricates, oral stops are also formed by a complete constriction situated in the vocal tract, but they differ in the manner of the release of the confined air. Oral stops are characterized by abrupt release, while affricates are released with the constricted vocal tract creating the friction of the air passing through. Our study is focused on irregularities in the articulation of fricatives and affricates related to the friction control and synchronized movements of articulators. In the case of normal speech and language development, fricatives and affricates are acquired at the age of 6–7. During the developmental phase, irregularities in the articulation of some fricative speech sounds may occur. These irregularities may be the result of the normal speech development, or may be caused by pathology in sound production. Types of deviations occur depending on the pattern of speech sound groups, and can be language dependent. These deviations manifest themselves as different types of sigmatism, duration, intensity and friction quality impairment (Jovičić et al., 2010). Sigmatism or lisp is an articulatory disorder characterized by defective sibilant sound. Speech therapists recognize five types or lisps: frontal or interdental, lateral, occluded, nasal and strident (Riper and Erikson, 1996). In the case of the Serbian language, strident lisp or stridence is one of the specific forms of deviations that occur in the articulation of fricatives and affricates.Stridence is an acoustic phenomenon that is generated in the mouth when the position of the tongue in relation to the palate and teeth is irregular. This position creates constrictions of various forms. When the airflow reaches a certain speed while passing through constrictions a tone of a certain frequency or a very strong narrowband resonant noise is generated. These sounds are generated simultaneously with the pronunciation of a speech sound, typically fricatives and affricates, and they change the acoustic characteristics of the target phoneme. Perceptually, the stridence is experienced as an unpleasant, whistling, squeaky or coarse sound that influences the quality of the pronounced phoneme.Stridence is also considered to be an abstract phonological distinctive feature (Chomsky and Halle, 1968) and is a phonological feature of many languages. In addition, the term strident lisp is used in order to describe the sibilants characterized by piercing, whistling sounds (Riper and Erikson, 1996). While in some languages whistling fricatives (stridency) are considered as normal pronunciation (Shosted, 2006), in Serbian (Jovicic et al., 2008), Czech (Honova et al., 2003) as well as some other languages it is considered to be an irregular (pathological) pronunciation.In the Serbian language, stridence is most commonly manifested in the articulation of fricative /ʃ/ (according to the IPA classification we used /ʃ/ as most similar to Serbian initial fricative in word “ʃuma”) as: narrowband stable over time and very intensive resonant occurrence in the diffuse noise spectrum, or a twofold stridence with one stable resonance and one very changeable resonance in the time-frequency representation, or a very short stridence with high variability of the resonant frequency (see Fig. 1). As noted in Jovicic et al. (2008), a strong resonant stridence with an intensity over 20dB above the envelope of the surrounding spectrum with a minimal duration longer than 10ms is a necessary condition for resonant occurrence to be perceived as stridence.The algorithm for automatic stridence detection in the Serbian language (Jovicic et al., 2008) uses Burg's maximum entropy method for calculating stridence measure. This algorithm is accurate in cases where stridence is prominent, with no doubt as to its presence. However, in boundary cases, the algorithm's detection differs from the assessment obtained by the speech therapist. The reason can be found in the fact that the algorithm does not exploit psychoacoustic effects.In past decades, a variety of computational models of cochlear processing have been developed to provide representations of complex neural activity patterns that arise in the auditory nerve in response to broadband sounds like speech and music (Hohmann, 2002; Patterson and Allerhand, 1995; Patterson and Holdsworth, 1996; Patterson, 2000; Slaney and Lyon, 1993). All of them simulate processing in cochlea using the following: (a) auditory filter-banks which simulate the basilar membrane motion (BMM), (b) some form of compressive adaptation and nonlinearity, for instance a half wave rectifier (HWR) which simulates neural transduction, and (c) temporal integration (Patterson and Allerhand, 1995; Patterson, 2000) or correlogram calculation (Slaney and Lyon, 1993; Slaney et al., 1994) used for generation of the auditory image.In this paper, a new method for stridence detection based on Paterson's auditory model (Patterson and Allerhand, 1995; Patterson and Holdsworth, 1996; Patterson, 2000) is proposed. Contrary to the original Paterson's auditory model in which strobed integration is applied on each channel independently, we calculated the auditory image along the selected spectral peaks contour. The reason for this is that the central frequency of the signal that represents stridence varies in time across channels of the filter bank.To optimize tracking of the spectral peaks contour, we modified the nonlinear processing in Paterson's auditory model by replacing the half wave rectifier (HWR) with a calculation of the magnitude of the channel signals. Finally, we simplified Patterson's auditory model by omitting the adaptation in the time domain. This is done because stridence detection is applied to the isolated phonemes whose duration is relatively short compared to the relaxation time of the adaptive threshold. The proposed algorithm was tested in an appropriate database of Serbian words with and without stridence and compared with the algorithm proposed in Jovicic et al. (2008).Stridence detection is implemented through three processing stages, as shown in Fig. 2. In the first stage, two time-frequency (TF) representations of the signal are generated in two parallel branches (A) and (B) using the original and modified Patterson's auditory model (Patterson and Allerhand, 1995), respectively. In the second stage, the smooth TF representation obtained by the modified Patterson's auditory model is used for the selection of the spectral peaks contour that can be perceived as stridence. The decision on the presence of stridence is made in the third stage by using Paterson's TF representation from the first processing stage and the selected spectral peaks contour from stage 2. In the following subsections the stages of the algorithm will be explained in detail.Filtering by gammatone filter bank (GFB) in step (i), models the transmission of the acoustic wave to corresponding points on the basilar membrane performing spectral analysis of the sound. Central frequencies and the channel bandwidths are assigned according to the ERB scale (Hohmann, 2002). In this algorithm, the gammatone filter bank is implemented using the fourth order complex filters (Hohmann, 2002). The reason for this is the ability to more precisely determine the envelope of the channels signal, which is important for the spectral peaks contours detection. The multichannel signal at the output of GFB is denoted by s(t, j), where j=1,…,Nch is channel index and Nch is number of channels in the filter bank.The processing step (ii) in branch (A) is a half-wave rectifier (HWR) which is used to model the processes that occur at the inner hair cell receptors (stereocilia). The half-wave rectifier is applied to the real part of the complex signal s(t, j), byx(A)(t,j)=HWR(s(t,j)),HWR(z)=max(real(z),0)where t is the discrete time index and j is the channel index. The output of the HWR is a pulse train x(A)(t, j). Apart from the information about instantaneous power it also contains the information about the phase of the channel signal. The onset of each pulse corresponds to zero phase of the channel signal. The stability of the pulse repetition period affects the shape of the signal in the auditory buffer, which will be discussed in Section 2.3.Contrary to branch (A), step (ii) in branch (B) – magnitude calculation – is applied byx(B)(t,j)=|s(t,j)|=Re(s(t,j))2+Im(s(t,j))2where Re(·) and Im(·) are the real and imaginary parts of the complex number, and output x(B)(t, j) is a smooth envelope of the jth channel signal.Step (iii) in stage 1 is the amplitude compression realized by,xc(q)(t,j)=f(x(q)(t,j)),f(x)=xβ,q∈{A,B},β>0where symbol q denotes either of branches A or B. The constant β>0 defines the compression level (Feldbauer et al., 2005; Patterson and Holdsworth, 1996). A typical value of β is 0.4 (Feldbauer et al., 2005). This step is similar to the logarithmic amplitude compression schemes in ordinary waveform coders (e.g., μ-law).As the spectral peaks carry information about the presence of stridence we applied spectral peaks enhancement in step (iv) in the same way as it was applied in the algorithms (Patterson and Holdsworth, 1996; Taplidou and Hadjileontiadis, 2007). Spectral peaks enhancement is performed in two steps. First, the smoothing of the compressed spectrumxc(q)(t,j)is performed by the moving average (MA) filter with coefficients w(k), k=1,…,2L+1 byy(t,j)=12L+1∑l=j−Lj+Lw(l−j+L+1)xc(q)(t,l),j=L+1,…,Nch−L,where y(t,j) is the output of the MA filter, Nch is the number of channels while j is the channel index. In the next step, an element-by-element difference betweenxc(q)(t,j)and y(t,j) is calculated. The negative difference on the convex parts is set to zero byz(q)(t,j)=max{xc(q)(t,j)−y(t,j),0}However, stridence may be masked by other spectral components particularly in the case of fricatives with strong friction. As a consequence of the natural process of masking, perception of stridence may be absent. The model of the masking effect is implemented in step (v). Spectral components in the Δ vicinity of the resonant frequency f(j) reinforce the impression of stridence. The power of these spectral components is denoted as in-band powerPinBand(q)(t,j). On the other hand, the spectral components outside of this frequency band “decrease” the impression of stridence, playing the role of masking noise. The power of these spectral components is denoted as out-band powerPoutBand(q)(t,j). In-band and out-band powers are calculated byPinBand(q)(t,j)=12Δ+1∑l=j−Δj+Δz(q)(t,l)PoutBand(q)(t,j)=1M−2Δ−1∑l∉{j−Δ,j+Δ}z(q)(t,l)where Δ is an integer constant which defines the bandwidth in a number of neighboring channels. The masking effect is incorporated through the scalar weight α(t,j) which attenuates the masked TF element and enhances the unmasked TF element byzm(q)(t,j)=α(q)(t,j)z(q)(t,j),wherezm(q)(t,j)is the element of the output matrix with enhanced spectral peaks which potentially may be perceived as stridence. The scalar weight α(q)(t, j) is calculated byα(q)(t,j)=min(PinBand(q)/PoutBand(q),1).Outputzm(B)(t,j), for q=B, is used in stage 2 for the selection of the spectral peaks contour which potentially represents stridence. Outputzm(A)(t,j), for q=A, is used in stage 3 for the calculation of the strobed auditory image (Patterson and Allerhand, 1995; Patterson, 2000) along the selected spectral peak contour.In stage 2, the previously calculated matrixzm(B)(t,j)is analyzed and the spectral peaks contour that best represents stridence is selected. This is accomplished through four steps. In step (i) for each instance in time given by the time index t, all spectral peaks are found and denoted. In the next step (ii), the spectral peaks are associated to contours using the following rule: if (t, j) is the last point of a contour at time instance t in channel j, and if there is a local maximum along frequency axes in any of three channels with indices j−1, j, j+1 at time instant t+1, then the contour extends to the point (t+1, jmax), wherejmax=argmaxl(zm(B)(t,l)),l∈(j−1,j,j+1). If not, the contour is interrupted. Local maxima at time t+1 that are not covered by any of the contours of the time instance t, represent the beginning of the new contours.All contours cannot represent stridence. The selection of contours that could be perceived as stridence is done in step (iii). These contours should meet the following two constraints:(c1) Their duration must be greater than the minimum time interval – Tmin. Duration of the minimum time interval is determined experimentally and equals Tmin=9ms. The contours of shorter duration than Tmin cannot be perceived as stridence.(c2) A quasiperiodic stridence signal must have a stable resonant frequency, which is either a constant (the examples displayed in Fig. 1a and b, the first resonance line) or linearly changing in time (the example displayed in Fig. 1c and b, the second resonance line). Otherwise, that part of the signal will not produce the impression of stridence but friction. Each spectral peak contour may be modeled by a simple regression model. The sum of squared residuals of the model is a measure of the resonant frequency stability. In the first approximation we assume that resonant frequency is constant over the short time interval Tmin. In this case, the stability measure is the standard deviation over the sliding window having a width of Tmin. Hence, the standard deviation of the resonant frequency on the sliding window with the width of Tmin has to be less than the previously defined threshold σλ.The contours that satisfy the constraints (c1) and (c2) are potential representatives of stridence. Let us denote the sequence of points of contour pibySi(B)(t),Si(B)(t)=zm(B)(t,pi(t)),t=t1,…,tend,where t1 is the first and tendis last element of contour pi. We will define the local strength measureStri(B)(t)of contour piat discrete time instant t by(1)Stri(B)(t)=∑j=tt+L−1Si(B)(j)forstd(pi(t),…,pi(t+L−1))<σλ0otherwisewhere std(·) is the standard deviation, L is the length of the moving average filter which we set to Tmin. Threshold σλhas to be experimentally determined. In our experiments we set it to one.According to (1), local strength measureStri(B)(t)is sum of elements ofSi(B)(j),j=t,t+L−1if constraint c2 holds. Otherwise, it is equal to zero because this part of the contour with points (t, pi(t)), …, (t, pi(t+L−1)) cannot be perceived as stridence but as noise or friction. Let us denote the strength of the measure on the contour pibyStrimax=max(Stri(B)(t),t=t1,…,tend−L+1)).The contour with the maximum strength measure denoted bypimaxis the best candidate that can be perceived as stridence. Its index isimax=argmaxi(Strimax).We will denote this contour by pmax,pmax=pimaxUnlike the original Patterson's model in which strobed temporal integration is applied in each channel independently (Patterson and Holdsworth, 1996), in our algorithm the auditory strobed temporal integration is applied on the selected contour pmax. The auditory image is created in several steps. In the first step (i) we form a series of points S(A)(t) of the selected contour pmax,S(A)(t)=zm(A)(t,pmax(t)),t=t1,...,tend.A series of points S(A)(t) consists of positive half-periods as it is shown in Fig. 3a.Similar to the process of the auditory imaging by the strobed temporal integration (STI) (Patterson and Holdsworth, 1996; Patterson, 2000), in the next step (ii) trigger pulses T(k), k=1,…,Ntrare positioned at the local maxima of positive half-cycles of the series S(A)(t), see Fig. 3a. Ntris the number of trigger pulses generated on the series S(A)(t), for t=t1,…,tend. Local maxima are detected with respect to the adaptive threshold α(t), marked in Fig. 3a with a thin line. Threshold α(t) decays exponentially with time, and when the trigger pulse occurs, it is set to the value of the local maximum of the signal (Patterson and Holdsworth, 1996; Patterson, 2000). The positions of local maxima are marked by diamonds in Fig. 3a. At the locations of the trigger pulses, the accumulation of the signal in the auditory buffer is activated. The accumulation is calculated by pseudo code:(2)fork=1,…,NtrAbuf(N−T(k)+1:N)=Abuf(N−T(k)+1:N)+S(A)(1:T(k))endwhere Abuf(l), l=1,…,N is the auditory buffer containing N points. The content of the auditory buffer after the previously described STI process is shown in Fig. 3b. For the proposed stridence detection algorithm, only the last element of the auditory buffer Abuf(N) is of importance since it is used as a measure of the presence of stridence dstr,(3)dstr=Abuf(N)The decision about the presence of stridence is made by comparing the stridence measure dstrwith two decision thresholds λd1, λd2, 0<λd1<λd2 according to the ruleD=D0without stridence,fordstr<λd1D1strong stridence,forλd2>dstrD2unable to decide,forλd1≤dstr≤λd2.The decision D0 means that there is no stridence in the pronunciation. The decision D1 means presence of stridence. Decision D2 means that the measure dstris located in an area where we cannot surely assert whether there is or there is not stridence.

@&#CONCLUSIONS@&#
The main idea in the implementation of the algorithm for stridence detection was to bring the results of automatic detection closer to the perceptive assessment of speech and language experts. For this purpose, Patterson's auditory model is used, and experimental results for the detection of stridence with fricative /ʃ/ show significant improvements. The method is applicable to other phonemes from the group of fricatives and affricates where stridence occurs, regardless of whether they are voiced or voiceless. In order to use this algorithm for stridence detection in case of other phonemes, it is necessary to adjust all the parameters of the algorithm according the particular phoneme. The analysis of the errors showed the need for expanding the psychoacoustic effects in the proposed algorithm for stridence detection. Therefore, additional studies are necessary regarding the characteristics of stridence, psychoacoustic effects that contribute to the stridence perception, modeling approaches to individual psychoacoustic effects and their integration.The proposed method for automatic detection of stridence is meant to be implemented as part of a reliable, accurate and non-invasive automatic system for general pathological speech assessment. Such a system could be efficiently used for large scale screening tests for early detection and recognition of speech disorders as well as support in therapy sessions, evaluation of therapy strategies in clinical trials and therapy control.