@&#MAIN-TITLE@&#
Comparative experiments using supervised learning and machine translation for multilingual sentiment analysis

@&#HIGHLIGHTS@&#
We study the possibility to employ Machine Translation (MT) systems and supervised methods for multilingual sentiment analysis.Experiments are done for English, German, Spanish and French.We use three MT systems – Google, Bing and Moses –, different supervised learning algorithms and various types of features.We show how meta-classifiers can be employed to mitigate the noise introduced by translation.Our extensive evaluations show that MT systems can be used for multilingual sentiment analysis.

@&#KEYPHRASES@&#
Multilingual sentiment analysis,Opinion mining,Machine translation,Supervised learning,

@&#ABSTRACT@&#
Sentiment analysis is the natural language processing task dealing with sentiment detection and classification from texts. In recent years, due to the growth in the quantity and fast spreading of user-generated contents online and the impact such information has on events, people and companies worldwide, this task has been approached in an important body of research in the field. Despite different methods having been proposed for distinct types of text, the research community has concentrated less on developing methods for languages other than English. In the above-mentioned context, the present work studies the possibility to employ machine translation systems and supervised methods to build models able to detect and classify sentiment in languages for which less/no resources are available for this task when compared to English, stressing upon the impact of translation quality on the sentiment classification performance. Our extensive evaluation scenarios show that machine translation systems are approaching a good level of maturity and that they can, in combination to appropriate machine learning algorithms and carefully chosen features, be used to build sentiment analysis systems that can obtain comparable performances to the one obtained for English.

@&#INTRODUCTION@&#
Together with the increase in the access to technology and the Internet, the recent years have shown a steady growth of the volume of user-generated contents on the Web. The diversity of topics covered by this data (also containing expressions of subjectivity) in the new textual types such as blogs, fora, microblogs, has been proven to be of tremendous value to a whole range of applications, in Economics, Social Science, Political Science, Marketing, to mention just a few. Notwithstanding these proven advantages, the high quantity of user-generated contents makes this information hard to access and employ without the use of automatic mechanisms. This issue motivated the rapid and steady growth in interest from the natural language processing (NLP) community to develop computational methods to analyze subjectivity and sentiment in text. Additionally, apart from the research on sentiment analysis in the context of user-generated contents, studies have also focused on developing methods for sentiment analysis in newspaper articles. This task is especially relevant to the online reputation management of public figures and organization and to monitoring the reaction to the events described in mainstream media. As such, different methods have been proposed to deal with these phenomena for the distinct types of text and domains, reaching satisfactory levels of performance for English. Nevertheless, for certain applications, such as news monitoring, the information in languages other than English is also highly relevant and cannot be disregarded. Additionally, systems dealing with sentiment analysis in the context of monitoring must be reliable and perform at similar levels as the ones implemented for English.Although the most direct solution to these issues of multilingual sentiment analysis would be the use of machine translation systems, researchers in sentiment analysis have been reluctant to using such technologies due to the low performance they used to have. However, in the past years, the performance of machine translation systems has steadily improved. Public or open access solutions (e.g. Google Translate,22http://translate.google.it/.Bing Translator33http://www.microsofttranslator.com/.) offer more and more accurate translations for frequently used languages.Bearing these thoughts in mind, in this article we study the manner in which sentiment analysis can be done for languages other than English, using machine translation. In particular, we will study this issue in three languages – French, German and Spanish – using three different machine translation systems – Google Translate, Bing Translator and Moses (Koehn et al., 2007) and different machine learning models.We employ these systems to obtain training and test data for these three languages and subsequently extract different features that we employ to build different machine learning models using Support Vector Machines Sequential Minimal Optimization – SVM SMO – (Platt, 1999). We additionally employ meta-classifiers to test the possibility to minimize the impact of noise (incorrect translations) in the obtained data. To have a more precise measure of the impact of quality translation on this task, we create Gold Standard sets for each of the three languages, by translating the data with the Yahoo translation system44http://www.babelfish.com/.and subsequently manually correcting the output.Our experiments show that machine translation systems are reaching a reasonable level of maturity so as to be employed for multilingual sentiment analysis and that for some languages (for which the translation quality is high enough) the performance that can be attained is similar to that of systems implemented for English, in terms of weighted F-measure.

@&#CONCLUSIONS@&#
In this work we propose an extensive evaluation of the use of translated data in the context of sentiment analysis. Our findings show that SMT systems have reached a reasonable level of maturity to produce sufficiently reliable training data for languages other than English. The gap in classification performance between systems trained on English and translated data is minimal, with a maximum of 12% in favor of source language data.Working with translated data implies an increment number of features, sparseness and noise in the data points in the classification task. To limit these problems, we test three different classification approaches, using different types of features and classifiers, showing that using unigrams or tf-idf on unigrams as features, and/or Bagging as a meta-classifier, has a positive impact in the results. Furthermore, in case of good translation quality, we noticed that the union of the same training data translated with various systems can help the classifiers to learn different linguistic aspects from the same data.The proposed approach clearly depends on the availability of the translation engines for the required languages. Although, commercial engines are able to translate from and into a large number of languages, they cannot be used to freely translate large amounts of data (usually not more than a certain number of characters). On the other hand, the parallel corpora needed for training the open source SMT systems cover only the most used languages, and their sizes are not comparable to the dataset used to train commercial engines. These aspects may limit the use of MT in support of other natural language processing sectors, in particular if focused on less resourced languages.In future work, we plan to investigate different document representations, in particular we believe that the projection of our documents in space where the features belong to a sentiment lexica (in conjunction to the types of features we have already employed) and include syntax information can reduce the impact of the translation errors.