@&#MAIN-TITLE@&#
A new descriptor resistant to affine transformation and monotonic intensity change

@&#HIGHLIGHTS@&#
Perform a thorough analysis of the disadvantages of SIFT-based descriptors.Apply an adaptive strategy for the subregion division.Utilize intensity order to construct the descriptor.Explain how the new method is resistant to affine transformation and monotonic intensity change.Demonstrate the effectiveness and efficiency of the new method through extensive experiments.

@&#KEYPHRASES@&#
Local invariant descriptor,Affine transformation,Monotonic intensity change,Intensity order,

@&#ABSTRACT@&#
A substantial number of local feature extraction and description methodologies have been proposed as image recognition algorithms. However, these algorithms do not exhibit adequate performance with regard to repeatability, accuracy, and time consumption for both affine transformation and monotonic intensity change. In this paper, we propose a new descriptor, named Resistant to Affine Transformation and Monotonic Intensity Change (RATMIC). Unlike traditional descriptors, we utilize an adaptive division strategy and intensity order to construct the new descriptor, which is actually resistant to affine transformation and monotonic intensity change. Extensive experiments demonstrate the effectiveness and efficiency of the new descriptor compared to existing state-of-the-art descriptors.

@&#INTRODUCTION@&#
The task of finding correspondences between two images has been a prevalent topic for years. However, even for the simplest objects or scenes, computers still experience difficulty fulfilling their missions of recognition. With the emergence of local invariant features, it is possible to achieve better performance and improved efficiency with several successful applications, including object recognition [1], 3D object reconstruction [2], and image retrieval [3], as well as panoramic image stitching [4]. Moreover, this methodology can be divided into two main steps: the extraction of features and the description of these features. Several algorithms have been proposed for both steps; some are reviewed in the next two subsections.Among these invariant feature extraction methodologies, the Harris corner detector [5], which is based on the computation of the eigenvalues of the Harris matrix, is used to detect corners by curvature, and the Hessian detector, which employs the Hessian matrix, is used to retrieve conspicuous texture information from images. Nevertheless, neither is invariant to affine transformation, which reduces their performance. Thus, the Harris-Affine detector [6–8] and Hessian-Affine detector [6,7] are proposed based on the second moment matrix and automatic scale selection theory [9]. The Maximally Stable Extremal Region (MSER) [10] detects the maximally stable extreme districts to form the affine invariant areas. Based on the Accelerated Segment Test (AST) standard, the Features from AST (FAST) [11,12] utilizes machine learning to establish a decision tree for corner detection. Based on FAST, Mair et al. [13] present the Adaptive and Generic Accelerated Segment Test (AGAST), which finds the optimal decision tree in an extended configuration space and also demonstrates how to combine specialized trees to yield an adaptive and generic AST.The SIFT descriptor [1,14] is the most popular descriptor that it is invariant to scale transformation by means of an image pyramid; it also undergoes robust-to-rotation transformation and intensity change through gradient information. However, it presents certain disadvantages, which will be discussed in detail in Section 2. By utilizing both the integral image and Haar wavelet transformation, the SURF descriptor [15,16] exhibits higher efficiency but lower performance than the SIFT descriptor. By combining the FAST detector with the BRIEF descriptor [17], the ORB algorithm [18] is faster than the SIFT and SURF algorithms by two orders and one order of magnitude, respectively; however, it displays poor performance when a serious affine transformation occurs. The DAISY descriptor [19] performs well for affine transformations and linearly uniform intensity changes. However, due to high dimensions and complex computations, time and space consumptions for the construction of the DAISY descriptor increased accordingly. The Rotation-Invariant Fast Feature (RIFF) [20] descriptor calculates the gradient information based on a local coordinate such that it is invariant under rotation but the descriptor may result in increased computational complexity. The Compact And Real-time Descriptors (CARD) [21] makes effective use of query tables to reduce the construction time of the SIFT algorithm; however, it is still inferior to the SIFT algorithm. To cope with complicated intensity change, the Local Binary Pattern (LBP) descriptor [22] considers intensity order information but still contains high dimensions. Heikkilä et al. [23] combine the SIFT and LBP descriptors to form the Center Symmetric LBP (CS-LBP) descriptor, which can efficiently deal with complex intensity change but experiences the same disadvantages as the SIFT descriptor. For better coping with noises, Gupta et al. [24] presents the Center Symmetric Local Ternary Patterns (CS-LTP) descriptor to establish a dead zone for comparisons of pixel intensity.As discussed previously, development of a new descriptor that can efficiently and effectively handle both affine transformation and complex intensity change is essential. Consequently, we propose the Resistant to Affine Transform and Monotonic Intensity Change descriptor (RATMIC), whose synthetical performance outperforms most of the existing state-of-the-art descriptors. The remainder of the paper is organized as follows. Section 2 discusses the shortages of SIFT-based descriptors. Section 3 introduces our proposed RATMIC descriptor in detail. Case studies are discussed in Section 4, and our conclusions are presented in Section 5.As stated previously, the SIFT algorithm is the most popular algorithm in the fields of invariant feature extraction and description. Consequently, there are many new algorithms deriving from the SIFT algorithm, e.g., SURF, DAISY, and CS-LBP, that are worthy of emphasis. Based on our analyses, we present some disadvantages of SIFT-based descriptors in this section, including extensive time consumption, lack of invariance to non-uniform intensity changes, and reduced accuracy due to predefined subregions.Fig. 1depicts the distribution of time consumption during feature extraction and description by the SIFT algorithm. For the image with a size of 700×1000 pixels, 3354 features are extracted from the raw image. The overall process takes 13,588ms, including 1653ms for features extraction, 2840ms for orientations estimation and 9095ms for descriptors extraction in the experimental environment of Intel Core (TM) i3-2100 CPU 3.10GHZ.As shown in Fig. 1, the most time-consuming stages are the estimation of the principal direction and the construction of the descriptors, which together comprise about 88% of the total process time. The reasons for this proportion are fourfold. First, the gradient computation over the entire region of interest (ROI) for each feature is very large, i.e., provided that there are J (J∈N+) features extracted from the raw image and ROIs centered at different features are of an n2 (n∈N+) size, the computation complexity is up to O(Jn2), where O(·) is the asymptotic time complexity. Second, SIFT-based algorithms divide gradient orientation into several directions; all pixels are then pooled according to their gradient orientations. Subsequently, the direction with the largest magnitude is assigned as the principal direction. Third, to become rotation invariant, the rotation of the ROI relative to the principal direction is required, which consists of a large number of bilinear interpolations. Finally, SIFT-based algorithms divide the ROI into several predefined subregions and construct the descriptor based upon the gradient information of pixels. According to the previous analyses, Most of SIFT-based descriptors are not suitable for real-time applications because they are overly time consuming.The construction of SIFT-based descriptors depends on the gradient computation of pixels in the ROI. If the same intensity increment occurs in the image, the gradient information is invariant, i.e., all pixels in the original image change from I(x,y) to I(x,y)+Δ(x,y), where I(x,y) is the intensity located at (x,y) and Δ is a compatible matrix with a same element representing an equivalent intensity change. This change does not affect the gradient result for they are computed from the pixel differences. Thus, SIFT-based descriptors are invariant to the same incremental intensity change.A change that every pixel multiplies a constant, i.e., the intensity changes from I(x,y) to k×I(x,y), where k is a positive scalar, will multiply the gradient value by the identical constant. To counteract this effect, SIFT-based descriptors are unitized by the Euclidean distance.So the SIFT-based algorithms are capable of handling linear uniform intensity change, i.e., intensity changes from I(x,y) to k×I(x,y)+Δ. Nevertheless, when a non-uniform intensity change occurs, which can be represented as f(x,y)×I(x,y)+Δ′(x,y), where the scale coefficient f(x,y) is a general matrix instead of a scalar and translation coefficient Δ′(x,y) is a matrix with different elements, the gradient computation is unable to eliminate the effect caused by the non-uniform intensity changes. To reduce the influence, D. Lowe thresholds the maximum gradient value and then renormalizes the SIFT descriptor. However, such changes will still affect the construction and performance of SIFT-based descriptors.To take spatial information into consideration, SIFT-based descriptors divide the ROI into several predefined subregions, e.g., the SIFT descriptor divides the ROI into 4×4 square subregions. Unfortunately, SIFT-based descriptors need to determine the principal direction and rotate the ROI relative to the principal direction to obtain rotational invariance. However, this method not only augments time consumption but also reduces accuracy. Its instability was previously pointed out by Bin et al. [25].Aimed at overcoming the aforementioned disadvantages of SIFT-based descriptors, we propose the RATMIC descriptor, which is constructed by the intensity order instead of gradient information. It will improve repeatability and accuracy, as well as decrease time consumption. The construction process can be divided into four steps. First, we employ the affine-invariant detector to extract features from raw images. Second, we adopt a strategy, which is invariant to rotation transformation, to pool pixels in the ROI into different subregions. Third, a ratmic function is applied to different subregions to form their own RATMIC subdescriptors. Finally, all subdescriptors are orderly concatenated to construct the RATMIC descriptor. Further details of this process are provided below.We use the Hessian-Affine detector to extract features in that such detector can obtain spatial information and other affine transformation information from the extracted features, i.e., the Hessian-Affine detector returns not only the spatial information (x,y) but also the set (a,b,c), which can form a symmetric matrix defined as Eq. (1).(1)M=abbcThe different elements in the matrix M can describe ROIs within different ellipses, which are defined as(2)XTMX⩽1where X is a column vector representing the location in ROI. This ellipse incorporates abundant affine transformation information; we will normalize the ellipse to the unit circle for the convenience of matching.Theorem 1Given that M is a symmetric matrix, and X is a column vector representing the location in ROI, we will normalize the ellipse described by M to a unit circle by the transformation defined as(3)Y=M1/2XFor M is a symmetric matrix, we have M=MTand M1/2=(M1/2)Tintuitively. According to Eq. (2), we can deduce that(4)XTMX=XTM1/2M1/2X=XT(M1/2)TM1/2X=(M1/2X)TM1/2X=YTY=1Therefore, we can successfully normalize the ellipse to a unit circle using Eq. (3). Fig. 2provides an example of the ROI normalization procedure.Provided that there is an affine transformation between two ROIs, i.e., XR=AXL, we can separately transform XR, XLintoXR′,XL′by Eq. (3). Then, the affine transformation between XRand XLis converted to the rotation transformation betweenXR′andXL′. Thus, we still have to address the rotation transformation.□To take advantage of the spatial information of the features without introducing errors from the assignment of the principal direction, we adopt the subregion division methodology presented by Bin et al. [25]. We first sort all pixels within the ROI in non-decreasing order according to their intensity value. Then, we divide the sorted sequence into k segments; namely, different pixels are separately allocated to different subregions according to their intensity order. As an example, Fig. 3shows the strategy with k equal to eight. Even if the ROI rotates by a certain angle, the intensity order remains invariant. As a consequence, every pixel is pooled into the same subregion after a rotation transformation, leading the strategy to be invariant to rotation.In this subsection, the construction of subdescriptors in each subregion will be discussed in detail. Instead of gradient information, we consider the intensity order to keep the RATMIC descriptor invariant to both rotation transformation and monotonic intensity change. Provided that I(x1,y1) and I(x2,y2) represent the intensities before transformation, they satisfy I(x1,y1)<I(x2,y2); when the monotonic intensity change occurs, the intensity order still satisfies I′(x1,y1)<I′(x2,y2), where I′(x1,y1) and I′(x1,y1) denote the intensities after the intensity change.As shown in Fig. 4, P is a feature and C is an arbitrary pixel within the ROI centered at P. We sample four pixels in the circle with radial l centered at C. To obtain rotation invariance, the sample process is as follows. Since there are two pixels along the radial direction centered at P, we select the pixel away from P as C1; others are sampled anti-clockwise. Furthermore, the line through C1 and C3 is orthogonal to the line through C2 and C4. To illustrate that the sample strategy remains invariant to rotation, we rotate the pixel C by a certain angle θ to pixel C′. The four neighboring pixels around C are equivalent to the four neighboring pixels around C′. Hence, this sample strategy is invariant to rotation.As gradient information is incapable of coping with non-uniform and non-linear monotonic intensity change, we propose a new methodology to construct the subdescriptor by utilizing the intensity order of Ci(i=1,2,3,4), which is described as follows. First, the comparison between I(xi,yi) andI(ximod4+1,yimod4+1)is performed where 1⩽i⩽4 and mod denotes the modulo operation. IfI(xi,yi)⩾I(ximod4+1,yimod4+1)+thres, where thres is a threshold to reduce the effect of noises. Then, we set Qi=1; otherwise, Qi=0. After the comparison, we concatenate Qito form Q, i.e., Q={Q1,Q2,Q3,Q4}. Second, we define(5)S={γ(Q)∈N|Q∈{0,1}4}where S is a non-negative integer representing the weighted sum of the binary number Qi, i.e.,S=∑i=032i×Qi+1. According to the definition of S, we have0⩽S⩽15. Subsequently, we define(6)W=ϕ(S)∈{0,1}24-1|S∈Nwhere W is a column vector that includes a set of binary numbers denoted as WS, where0⩽S⩽15. The map ϕ sets the corresponding WSto one, e.g., if S=5, W=ϕ(5)=(0,…,0,15,0,…,0)T.In summary, we concatenate Eqs. (5) and (6) to form the ratmic function in Eq. (7).(7)ratmic(X)=ϕ(γ(Q))=(0,…,0,1γ(Q),0,…,0)TwhereX∈R2denotes the location of a feature.An illustration of the ratmic function is shown in Fig. 5, where the threshold is set to four.Finally, the subdescriptor in each subregion is constructed by the sum of the ratmic functions of features belonging to each subregion.After constructing each subdescriptor, we can construct the RATMIC descriptor by concatenating the subdescriptors orderly as Eq. (8).(8)RATMICdescriptor=subdes(1)T,subdes(2)T,…,subdes(k)TTsubdes(j)=∑X∈SubRegion(j)ratmic(X)Moreover, we normalize the RATMIC descriptor to the unit vector by analogy with the SIFT algorithm to better handle the intensity change. The complete construction process is shown in Algorithm 1.Algorithm 1: Construction of the RATMIC descriptor01Smooth the raw image utilizing the Gaussian filter02 Extract J features using the Hessian-Affine detector03fori=1,2,…,J04Normalize the ROI centered at the ith feature according to (3)05Sort the pixels within the normalized ROI in non-decreasing order and divide them into k equal segments06Pool the pixels into different subregions according to their intensity07Calculate the ratmic function of the pixels within the ROI according to (7). Then, add the results to different subdescriptors separately according to (8)08Concatenate all subdescriptors according to the order described in step 5 to construct the RATMIC descriptor09Normalize the RATMIC descriptor to the unit vector10Assign the normalized RATMIC descriptor to RATMIC(i)11end for12returnRATMICAfter the RATMIC descriptor is constructed, it can be seen that either the subregion division or sample strategy of the pixels within the ROI is invariant to rotation; thus, we can deduce that the RAIMIC descriptor is invariant to rotation transformation compared to other algorithms whose principal direction is required. In addition, we make effective use of the intensity order to enable the RATMIC descriptor to cope with monotonic intensity change. Hence, the RATMIC descriptor outperforms most of the gradient-based descriptors due to its characteristics of both resistance to affine transformation and the invariance to monotonic intensity change. In the next section, sufficient experiments are conducted on standard datasets to demonstrate the superiority of the RATMIC descriptor.

@&#CONCLUSIONS@&#
