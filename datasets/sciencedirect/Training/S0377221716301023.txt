@&#MAIN-TITLE@&#
A DEA based composite measure of quality and its associated data uncertainty interval for health care provider profiling and pay-for-performance

@&#HIGHLIGHTS@&#
DEA is used to develop a composite measure of health care quality.An empirical study is carried in US Department of Veterans Affairs nursing homes.DEA identifies fewer high performers but more highly rewards the high performers.Advantages of DEA for developing composite measure make it worth pursuing further.Monte Carlo resampling with replacement is applied to reflect DEA data uncertainty.

@&#KEYPHRASES@&#
Data Envelopment Analysis (DEA),Health care quality,Monte Carlo,Bootstrapping,Performance,

@&#ABSTRACT@&#
Composite measures calculated from individual performance indicators increasingly are used to profile and reward health care providers. We illustrate an innovative way of using Data Envelopment Analysis (DEA) to create a composite measure of quality for profiling facilities, informing consumers, and pay-for-performance programs. We compare DEA results to several widely used alternative approaches for creating composite measures: opportunity-based-weights (OBW, a form of equal weighting) and a Bayesian latent variable model (BLVM, where weights are driven by variances of the individual measures). Based on point estimates of the composite measures, to a large extent the same facilities appear in the top decile. However, when high performers are identified because the lower limits of their interval estimates are greater than the population average (or, in the case of the BLVM, the upper limits are less), there are substantial differences in the number of facilities identified: OBWs, the BLVM and DEA identify 25, 17 and 5 high-performers, respectively. With DEA, where every facility is given the flexibility to set its own weights, it becomes much harder to distinguish the high performers. In a pay-for-performance program, the different approaches result in very different reward structures: DEA rewards a small group of facilities a larger percentage of the payment pool than the other approaches. Finally, as part of the DEA analyses, we illustrate an approach that uses Monte Carlo resampling with replacement to calculate interval estimates by incorporating uncertainty in the data generating process for facility input and output data. This approach, which can be used when data generating processes are hierarchical, has the potential for wider use than in our particular application.

@&#INTRODUCTION@&#
Publicly profiling health care provider performance is seen by policy makers in many countries as a way of motivating provider improvements and increasing information available to consumers in order to encourage better decisions. In the United States, the Centers for Medicare and Medicaid Services (CMS) make available to the public, through its Hospital Compare (CMS, 2013a) and Nursing Home Compare (CMS, 2013b) websites, data on the performance of hospitals and nursing homes respectively. Other systems with metrics on hospital outpatient care, physician practices, and accountable care organizations are in the process of being tested and released. In the British National Health Service, NHS Choices (2013) has developed comparison websites at the procedure or treatment level reporting an array of patient experiences and outcome measures. Other European countries are beginning to make available comparable information as well, though much of their efforts have been at the country level working through the European Commission and the Organisation for Economic Co-operation and Development to standardize information for comparisons across countries (European Commission, 2013).Not only is provider performance on many different metrics increasingly being made available to the public around the world, but performance is being used to adjust payments to providers. In the United States, CMS has implemented the Hospital Value-Based Purchasing program (CMS, 2013c), and other programs mandated by the Affordable Care Act, such as those to adjust payments to new accountable care organizations and physicians, are in the process of being implemented. Similar programs in Europe include more focus on economic evaluation related to measuring cost-effectiveness, since the Europeans are not as market oriented as the systems are in the United States. For example, in the United Kingdom, the National Institute for Health and Clinical Excellence (NICE) is using cost-effectiveness ratings to choose the quality metrics to implement pay-for-performance standards for general practitioners. In Germany, RAND Europe has worked with the German health insurance system to develop a system for incorporating quality indicators into the reimbursement system for their physicians (Nolte et al., 2013).Most existing provider profiling and related research focuses on individual performance indicators. Individual performance indicators are useful in targeting specific areas for improvement and monitoring improvement progress. However, a multitude of individual performance indicators does not allow an easy assessment of how well a provider organization is performing in the aggregate, the level at which assessments for payment and reporting are focused. To assess overall performance, it is useful to aggregate individual indicators into a composite measure (Institute of Medicine, 2006). Our focus in this paper is on indicators of the quality of care provided by health care facilities, where patients may be affected by different attributes of organizational performance and where we can measure these effects at the patient level. In this context, composite measures of quality are a useful summary for management, consumers and other stakeholders of the extent to which the facility has created a culture of quality and designed structures and processes to ensure quality throughout the organization. Composite measures of quality allow senior leaders to better benchmark the quality performance of their organization against high-performing organizations and to monitor changes over time. They provide information useful to patients when they are selecting where to receive their care. They also can be aligned against other relevant measures of performance, such as costs, to help managers and policy makers understand the value organizations are delivering to their clients. And, perhaps most importantly, they provide a basis for facility profiling that focuses on the “big picture.”In pay-for-performance (P4P) programs, performance on individual indicators is usually mapped into a payment adjustment and then the adjustments are added together to determine the overall impact on provider payment. As Shwartz et al. (2011) have shown in the context of hospitals, facilities that do best on a composite measure are often not in the group of highest performers on many of the individual measures. It seems as though facilities have two strategies: (1) to concentrate on some measures at the expense of others; or (2) to attempt to do pretty well on all of the measures, recognizing that as a result they may not be a top performer on very many of the individual measures. It seems reasonable that policies should be designed to recognize and reward both types of behavior. Our main focus in this paper is the composite measure component of a P4P program.Our main innovation in methodology is to illustrate the use of Data Envelopment Analysis (DEA) (Charnes, Cooper, & Rhodes, 1978) to calculate a composite measure of quality and an associated uncertainty interval that exploits the hierarchical structure of the data generating process that leads to the inputs at each facility. To understand the implications of using DEA in this way, it is useful to compare the DEA composite measure we construct to composite measures calculated using other approaches. Specifically, we consider two other approaches: (1) Using opportunity-based weights (OBWs) to combine individual performance indicators into a composite measure. This is the approach used by CMS in its early P4P Demonstration Programs (Kahn, Ault, Isenstein, Potetz, & Gelder, 2006; Reeves et al., 2007) and is a commonly used way of calculating a composite measure from individual measures when the individual measures are proportions. We show later in the paper that OBWs are a form of equal weighting; and (2) Using a Bayesian latent variable model (BLVM) to estimate the “underlying” composite measure (Landrum, Bronskill, & Normand, 2000). The main questions we examine are the sensitivity of the resulting facility ranks and identification of high and low performers to the approach used to calculate the composite measure; and, in the context of a specific type of P4P program, the impact of the different approaches on the percentage of the pool of resources available in the program that are allocated to each facility. We identify high and low performers based on whether interval estimates of performance are below overall mean performance (high performers with lower likelihood of adverse events) or above (low performers with higher likelihood of adverse events). Interval estimates are easily determined for a Bayesian hierarchical latent variable model.The most widely used approach for determining interval estimates in DEA uses bootstrapping with a kernel density estimator applied to the estimated frontier to approximate the DEA frontier data generating process (Simar & Wilson, 1998, 2000a, 2000b, 2011a, Chap. 10; Kneip, Léopold, & Wilson, 2008, 2015). These interval estimates reflect the error in estimating the frontier given the location of a specific set of facilities in multidimensional space. This approach as currently developed does not allow constraints on the DEA weights, something that is important in our context. Also, it takes as fixed each facility's input and output data. However, in our situation, there is uncertainty due to the fact that the inputs are calculated from patients at each facility, i.e., there is a hierarchical structure to our data. The particular set of patients at each facility can be viewed as a random sample from a population of “potential” patients that would use the facility if the health service need arose. Thus, in our situation, there is variation in the estimates of DEA efficiencies due to this source of uncertainty in the inputs. We capture this uncertainty in our interval estimates; they reflect how stable facility performance is likely to be in future periods with different realizations of patient arrivals. Because our approach may be useful in other situations with hierarchical data structures in which DEA is used, we describe the approach in a somewhat more general context than required by our application and provide details in Appendix A.In order to motivate the different approaches to calculating a composite measure, we provide a little background on composite measures and an example that highlights the underlying conceptual distinctions.Different approaches have been proposed to create composite measures of health care provider performance (e.g., Caldis 2007; Jacobs, Goddard, & Smith, 2005; Jha, Zhonghe, Orav, & Epstein, 2005; Landrum et al., 2000; Lied, Malsbary, Eisenberg, & Ranck, 2002; O'Brien et al., 2007; Reeves et al., 2007; Staiger, Dimick, Baser, Fan, & Birkmeyer, 2009; Shwartz, Peköz, Christiansen, Burgess, & Berlowitz, 2013; Werner & Bradlow, 2006; Zaslavsky, Shaul, Zaborski, Cioffi, & Clearly, 2002). In this paper, we step back from the specific ways in which these and other such approaches differ and focus on the bigger picture: what are the conceptual and philosophical differences that underlie several different approaches to profiling and what are the implications of these differences for profiles and payment under P4P programs and indirect incentive systems currently being expanded in the US and other countries.A composite measure calculated from individual indicators is a construct, which can be conceptualized in two different ways: one, as a reflective construct and two, as a formative construct (Edwards & Bagozzi, 2000). The first conceptualization corresponds to what one usually has in mind when thinking of a construct – an underlying latent trait that is manifested in the particular indicators. This latent trait is called a reflective to indicate that the construct is reflected in the individual indicators (in the same sense that a student's underlying mathematics ability is reflected in her scores on a series of mathematics tests). When conceptualized as a reflective construct, the direction of causality is from the construct to the observed indicators, that is, the indicators are high or low because the underlying construct is good or bad. The implication of this conceptualization is that the indicators should be correlated. Traditional analytical approaches for estimating reflective constructs include factor analysis and structural equation modeling. The Bayesian latent variable model approach we use estimates a reflective construct “quality” which is manifested in the observed quality indicators.Alternatively, a construct can be conceptualized as formative. In this case, the construct is formed from or defined by the individual indicators, usually by taking a weighted or un-weighted average of the indicators (Nardo et al., 2005). As an example, an individual's socio-economic status is defined by the particular set of variables used to measure the concept. There is no latent construct “socio-economic status” that “causes” or is reflected in an individual's level of education or income, common variables used to define socio-economic status. In a formative construct, the direction of causality is from the observed indicators to the construct. One would not necessarily expect individual indicators that comprise a formative construct to be highly correlated. In fact, individual indicators are often selected to broaden the definition of the construct and reflect its different dimensions, not to add indicators that are highly correlated with existing indicators. The challenge in creating a formative construct is how to determine the weights. Though there are guidelines that are helpful in deciding whether a construct is reflective or formative (Jarvis, MacKenzie, & Podsakoff, 2003), the decision is often based on perspective and judgment. Composite measures calculated using opportunity-based weights and DEA are examples of formative constructs.Before turning to the specifics of the alternative approaches to creating a composite measure that we examine, it is usual to consider an analogy that highlights the distinctions. Assume you are a teacher and, to evaluate your students, you give 3 exams during a semester, each of which covers material from one-third of the course; you assign a team project done by small student groups; and you assign a score to each student based on their class participation throughout the semester. The “composite measure problem” is how to weight the individual indicators of student performance to arrive at a final score, which you can then use as the basis for ranking students and assigning a final grade. The standard approach is to use your judgment to assign a weight to each indicator, where the sum of the weights is 1. In the simplest case, you might assign equal weight to each indicator. Call these the “baseline” weights. In our example, opportunity-based weights might be thought of as the baseline weights. As an alternative, though not one without controversy, you might decide to give students some flexibility in modifying their particular weights, e.g., at the start of the semester each student is allowed to adjust the weight assigned to each indicator up or down by 25 percent from the baseline. A more radical way in which to provide student flexibility is to allow students to adjust the weights at the end of the semester once they know their scores on the various indicators. The assumption behind this end-of-the-semester approach is that actual performance on the indicators is a set of “revealed preferences” about the relative importance of the indicators to the student. In essence, we give students the “benefit-of-the-doubt” and allow them to assign more weight to those indicators on which they did better under the assumption that they did better because these indicators were more important to them. The DEA-determined weights are one way to operationalize this approach. Finally, we could use a statistically-based approach to solving this problem, for example by using weights derived from variances of the scores. The logic behind this approach is that when scores are more tightly clustered, the indicator provides less insight into who is doing well and who is not, that is, the scores are more likely to reflect noise than signal; when scores are more spread out, the indicator provides a better basis for distinguishing the high from the low performers. This approach might be implemented by using as the weights a rescaling (so the sum is 1) of the loadings of the first principal component in a principal components analysis (variables with higher variance have higher loadings); or, in our case, by a latent variable model. There is no gold standard for combining individual indicators into a final score and thus no basis for saying that one of these approaches is correct, or, even better than another. It really depends upon one's philosophy about grading and assumptions about the way in which alternative weighting schemes might change incentives.

@&#CONCLUSIONS@&#
