@&#MAIN-TITLE@&#
A balance-evolution artificial bee colony algorithm for protein structure optimization based on a three-dimensional AB off-lattice model

@&#HIGHLIGHTS@&#
We propose a novel BE-ABC algorithm for protein structure optimization.The algorithm uses convergence information to manipulate its search intensity.An overall degradation procedure is introduced as a self-adaptive measure.Both artificial (Fibonacci) and real amino-acid sequences are optimized.Results obtained by BE-ABC are the best in the majority of the cases tested.

@&#KEYPHRASES@&#
Protein structure optimization,Amino-acid sequences,AB off-lattice model,Balance-evolution artificial bee colony algorithm,

@&#ABSTRACT@&#
Protein structure prediction is a fundamental issue in the field of computational molecular biology. In this paper, the AB off-lattice model is adopted to transform the original protein structure prediction scheme into a numerical optimization problem. We present a balance-evolution artificial bee colony (BE-ABC) algorithm to address the problem, with the aim of finding the structure for a given protein sequence with the minimal free-energy value. This is achieved through the use of convergence information during the optimization process to adaptively manipulate the search intensity. Besides that, an overall degradation procedure is introduced as part of the BE-ABC algorithm to prevent premature convergence. Comprehensive simulation experiments based on the well-known artificial Fibonacci sequence set and several real sequences from the database of Protein Data Bank have been carried out to compare the performance of BE-ABC against other algorithms. Our numerical results show that the BE-ABC algorithm is able to outperform many state-of-the-art approaches and can be effectively employed for protein structure optimization.

@&#INTRODUCTION@&#
Proteins can be regarded as the primary building blocks in all living organisms (Söding and Lupas, 2003). It is widely acknowledged that the functions of proteins are closely associated with their structures (Freitas et al., 2010), and therefore, understanding the structure of proteins is an important research area in biological sciences (Joshi and Jyothi, 2003; May et al., 2014). In early 2013, there had been approximately 81,700 protein structures deposited in the Protein Data Bank (PDB) database (Bagaria et al., 2013). Most of these protein structures were determined by X-ray diffraction and nuclear magnetic resonance spectroscopy.Due to strict laboratory requirements and heavy operation burdens, however, there is a huge gap between the number of known amino acid sequences and the deposited structures (Venkatesan et al., 2013; Sousa et al., 2006). It was reported that the number of experimentally determined structures is two orders of magnitude behind the number of protein structures (Poole, 2011). Consequently, many researchers in computational biology have focused their interests on predicting protein structures from the given amino acid sequences (Dorn et al., 2014; Kim et al., 2005). Protein structure prediction refers to the prediction of a three-dimensional protein structure through its primary structure information (Zhang et al., 2010). Here, a three-dimensional configuration is constituted through arranging a sequence of basic structure elements (i.e., α-helix, β-strand and coil).The thermodynamic hypothesis, originally proposed by Anfinsen (1973), states that native structures of proteins correspond to free-energy minima. Although Anfinsen’s pioneering work has enabled researchers to pursue the native structures with minimal free-energy values, solving such a problem is still too difficult for realistic protein models (Kim et al., 2005). Therefore, a critical problem in this area is how many trivial details in protein folding mechanisms can be neglected to establish simplified models (Bachmann et al., 2005). The HP lattice model (Dill, 1985) is one such simplified model, in which all the amino acids in a protein are classified into two categories, namely the hydrophobic and the hydrophilic. The HP lattice model requires all the amino acids to be located inside cubic lattices (Huang et al., 2010). An off-lattice generalization of the HP lattice model, namely the AB off-lattice model, was proposed by Stillinger et al. (1993), where all the “binarized” amino acids are linked up by unbendable but free-to-rotate chemical bonds. The AB off-lattice model was first applied in two dimensions and then extended to three dimensions, partially with modifications taking implicitly into account additional torsional energy contributions of each bond (Bachmann et al., 2005).Considering its advantages in terms of flexibility and accuracy when presenting the underlying locations of amino acids, we adopt the three-dimensional AB off-lattice model to describe the mechanisms of protein folding in a relatively precise but nontrivial manner. In doing so, the original protein structure prediction scheme is transformed into a numerical optimization problem. Such an optimization problem has been confirmed to be NP-hard (Unger and Moult, 1993; Hart and Istrail, 1997; Pierce and Winfree, 2002). As an example, Fig. 1shows the increase in the number of local minima versus the protein sequence length (Rossi and Ferrando, 2009). Some previous research studies have shown that the number of local minima would increase exponentially with the number of amino acids in a protein sequence (Stillinger and Weber, 1984; Stillinger, 1999). This gives rise to a large number of intelligent or heuristic computational methods for addressing the problem (Li et al., 2013, 2014; Hsu et al., 2003; Liang, 2004; Chen and Huang, 2006; Kim et al., 2007; Zhang and Cheng, 2008; Zhu et al., 2009; Liu et al., 2009, 2013; Chen et al., 2011; Kalegari and Lopes, 2013).The artificial bee colony (ABC) algorithm is one such method. It is a swarm intelligence algorithm inspired by the foraging behavior of bee swarms (Karaboga and Basturk, 2007). It contains a two-phase searching framework, i.e., local exploitation and global exploration, during the optimization process. Various studies using different numerical benchmark tests have confirmed that the ABC algorithm possesses competitive advantages compared to other well-known evolutionary computation methods (Karaboga and Akay, 2009; Krishnanand et al., 2009; Li et al., 2010). Besides that, the algorithm framework of ABC is relatively simple, making it possible to acquire good results at a low computational cost (Karaboga et al., 2014).In this paper, we present an improved balance-evolution ABC (BE-ABC) algorithm to tackle the protein structure optimization problem based on the three-dimensional AB off-lattice model. The novelty behind our proposed BE-ABC algorithm is that it utilizes convergence information during the search process to strike a balance between local exploitation and global exploration as well as to manipulate the search intensity in the exploration/exploitation phases. In addition, an original overall degradation procedure is introduced as part of the algorithm to efficiently prevent premature convergence. Apart from comparing this new algorithm to some competitive algorithms from the literature (including the conventional ABC algorithm) using the well-known artificial Fibonacci sequences, we also evaluate the performance of BE-ABC on several actual protein sequences listed in the PDB database (http://www.rcsb.org/). Our numerical results indicate that BE-ABC can outperform the other approaches in the majority of the cases tested.The remainder of this paper is organized as follows. Section 2 briefly reviews the three-dimensional AB off-lattice protein model. Then, in Section 3, we describe the conventional ABC algorithm and some issues associated with it. The details of BE-ABC are presented in Section 4, followed by Section 5 where experimental setups and results obtained through this algorithm to tackle the protein structure optimization problem are discussed. Finally, the conclusion is drawn and possibilities for future work are highlighted in the last section.This section describes how a three-dimensional protein structure can be determined by a set of bond/torsional angle parameters and how the corresponding free-energy function value can be calculated.According to the AB off-lattice model, the main driving forces that contribute to protein structure formulation are the hydrophobic interactions (Wang et al., 2013). It assumes that all kinds of amino acids in a protein sequence fall into two categories, namely, ones with hydrophobic residues (represented by A particles) and the others with hydrophilic residues (represented by B particles) (Kim et al., 2005). Particles are linked up sequentially by unit-length chemical bonds, and then form a chain in the three-dimensional space. Conformation of such a chain with N particles will be determined by (2N−5) angle parameters[θ1,…,θN−2;β1,…,βN−3]1×(2N−5)uniquely, which consist of (N−2) bond angles and (N−3) torsional angles. Locations of amino acids in the three-dimensional space are determined by Eq. (1):(1)(xi,yi,zi)={(0,0,0)i=1(0,1,0)i=2(cos⁡(θ1),sin⁡(θ1)+1,0)i=3(xi−1+cos⁡(θi−2)×cos⁡(βi−3),yi−1+sin⁡(θi−2)×cos⁡(βi−3),zi−1+sin⁡(βi−3))4≤i≤N.Here, the first three amino acid particles are defined in the plane of z=0 for the convenience of normalization. Then, locations of the subsequent particles (i.e., when i≥4) can be calculated recursively. Specifically, the location of the ith particle will be based on the location of the (i−1)th one (i≥4). Fig. 2schematically shows how the location of a protein sequence “AABA” is determined by the angle vector [θ1, θ2; β1], where∠A1A2B3=90∘+θ1and∠A2B3A4=180∘−θ1−θ2.The free-energy function consists of two parts, one represents the potential energy of intermolecular interaction among amino acids while the other represents the potential energy of intermolecular interaction between the peptide chain and surrounding solvent molecules. It can be defined as follows:(2)Energy([θ1,…,θN−2;β1,…,βN−3])=∑i=1N−21−cos⁡(θi)4+4∑i=1N−2∑j=i+2N[rij−12−C(ξi,ξj)rij−6],where ξireflects the binary property of the ith particle in the sequence, rijdenotes the distance between particles i and j in the three-dimensional space, and C(ξi, ξj) represents the interaction between those two particles. If particle i is hydrophilic, then ξi=1; otherwise, ξi=−1. The definitions of rijand C(ξi, ξj) are given in Eqs. (3) and (4), respectively:(3)rij=(xi−xj)2+(yi−yj)2+(zi−zj)2.(4)C(ξi,ξj)=18(1+ξi+ξj+5ξiξj).The first sum in Eq. (2) runs over the (N−2) anglesθi∈[−180∘,180∘]of successive bond vectors. This term is the bending energy and the coupling is ferromagnetic, i.e., it costs energy to bend the chain. The second term in the equation partially competes with the bending barrier depending on the distance between particles being nonadjacent along the chain (Bachmann et al., 2005). Through these, one angle vector[θ1,…,θN−2;β1,…,βN−3]will represent one candidate structure andEnergy([θ1,…,θN−2;β1,…,βN−3])is the corresponding free-energy value, withθi,βj∈[−180∘,180∘]for any 1≤i≤N−2, 1≤j≤N−3.In this way, the original protein structure prediction scheme is transformed into a constrained numerical optimization problem. Therefore, for a given protein sequence, we can find the angle vector[θ1,…,θN−2;β1,…,βN−3]that minimizes the free-energy function Energy(·). In the following sections, we will first introduce the conventional ABC algorithm, and then describe the proposed BE-ABC algorithm, both of which can be used for finding the angle vector:[θ1,…,θN−2;β1,…,βN−3]*=arg⁡(min⁡−180∘≤θi,βj<180∘(Energy([θ1,…,θN−2;β1,…,βN−3]))),1≤i≤N−2,1≤j≤N−3.In the preceding section, a description of the three-dimensional AB off-lattice model has been presented. This section and the next focus on how to find an optimal vector[θ1,…,θN−2;β1,…,βN−3]*with the minimal free-energy function value. In this section, we first introduce the basics of ABC. Then, we discuss some underlying issues associated with it.The conventional ABC algorithm employs three kinds of “bees”: scout bees searching for nectar sources randomly, employed bees associated with specific nectar sources, and onlooker bees that keep watch on the employed bees. Typically, half of a bee colony would consist of the employed bees and the other half the onlooker bees (Karaboga and Basturk, 2008). At an initial stage, the scout bees are set out to randomly search for nectar sources. Soon after, they become the employed bees responsible for sharing information (e.g., nectar source quality and their current locations) with other employed bees as well as the onlooker bees by means of “dancing”. The onlooker bees will then randomly select the locations of the employed bees to exploit. It is worth pointing out that the locations with relatively higher quality nectar sources are more likely to be chosen by the onlooker bees for exploitation. The employed bees, on the other hand, will also randomly share their locations with others to explore possible new locations. If an employed bee finds no better nectar source than one that it has previously discovered within a certain time length, it turns into a scout bee again. Its position will be a randomly initialized location in the search space.A location of a nectar source represents a feasible solution to the problem, and the nectar quality is reflected by the objective function value (Karaboga and Akay, 2009). Let X=(X1,X2,…,XD) represent a solution in the feasible solution space, fun(·) be the objective function that needs to be minimized, rand(m,n) be a random number between m and n obeying the uniform distribution, and SN be the population size of a bee swarm. As aforementioned, the number of onlooker bees in a bee colony is SN/2, equaling that of the employed bees. In this work, a solution X=(X1,X2,…,XD)1×Drefers to an angle vector[θ1,…,θN−2;β1,…,βN−3]1×(2N-5)(here D=2N−5) and the objective function fun(·) is Energy(·). At first, as many as SN/2 scout bees are randomly initialized in the feasible solution space. Eq. (5) shows how the jth element of the ith scout bee’s location Xiis calculated:(5)Xij⟵Xmin⁡j+rand(0,1)×(Xmax⁡j−Xmin⁡j),i=1,2,…,SN2,j=1,2,…,D,whereXmin⁡jandXmax⁡jdenote the lower and upper boundaries of this jth element, and D denotes the dimension of a feasible solution. Thereafter, the SN/2 scout bees will become the employed bees and an iterated process begins from here.In each cycle of iteration, an employed bee will share information with a randomly chosen companion and change one randomly chosen element of its location vector fromXijtoXi*jusing the following equation:(6)Xi*j⟵Xij+rand(−1,1)×(Xkj−Xij),k∈{1,2,…,SN2},j∈{1,2,…,D},k≠i.It is necessary to note that j and k are both randomly selected integers. When all the employed bees arrive at their new nectar sources{Xi*,i=1,2,…,SN/2}, they evaluate the quality of these new nectars and then decide whether to stay at the new location or the previous one by means of a greedy selection strategy. Specifically, if the ith employed bee finds thatfun(Xi*)<fun(Xi), it will go to the new locationXi*, i.e.,Xi⟵Xi*; otherwise, it remains at the previous location Xi.When all the employed bees have decided on their locations, a roulette selection strategy will direct the onlooker bees to select “qualified” employed bees to follow. A probability index P is calculated according to Eqs. (7) and (8) to reflect the relative quality of nectar sources at which the employed bees are located.(7)P(i)=∑j=1ifitness(j)∑j=1SN/2fitness(j),i=1,2,…,SN2,(8)fitness(i)={11+fun(Xi)iffun(Xi)≥01+|fun(Xi)|iffun(Xi)<0.Each onlooker bee will search locally around an employed bee. For some ith onlooker bee, a comparison is made between a random number rand(0,1) and P(j). IfP(j)≥rand(0,1), this onlooker bee will search around the jth employed bee; otherwise, a comparison between rand(0,1) and P(j+1) will be made. Even if P(SN/2) happened to be smaller than rand(0,1), such a comparison process is repeated from the first employed bee’s P(1) until a larger P(j) is found. Then, the corresponding jth employed bee will be chosen. The following equation (i.e., Eq. (9)) shows the location of the ith onlooker beeYi=(Xj1,…,Xjk−1,Yik,Xjk+1,…,XjD)that searches locally around the selected jth employed bee.(9)Yik⟵Xjk+rand(−1,1)×(Xmk−Xjk),m∈{1,2,…,SN2},k∈{1,2,…,D},m≠j.Note that in this equation, m and k are randomly selected integers as well. When all the SN/2 onlooker bees have determined their locations, a greedy selection strategy is implemented. This time, however, a comparison is made between fun(Xj) and fun(Yi), i=1,2,…,SN/2. If fun(Yi) is smaller than fun(Xj), the jth employed bee will abandon the current location Xjand go to Yi, i.e.,Xj⟵Yi; otherwise, the jth employed bee remains at Xj.It is interesting to note that every time the greedy selection is carried out, it involves one central employed bee. In the ABC algorithm, besides the probability index P, there is another index that is associated with each of the employed bees, namely trial, which memorizes inefficient information that is relevant to the employed bee. Specifically, trial(i) records the number of times an inefficient search is performed by the ith employed bee or any onlooker bee that searches around the ith employed bee. That is, trial(i) is incremented by one each time when the conditionfun(Xi*)≥fun(Xi)orfun(Yj)≥fun(Xi)is satisfied. At the beginning, each trial(i) is set to zero. As the iteration goes on, when trial(i) reaches a predefined threshold Limit, the ith employed bee will turn into a scout bee again with a randomly initialized location in the search space (based on Eq. (5)).The pseudo-code of the ABC algorithm is given as follows.The ABC algorithm differs from other methods of its type (e.g., nature-inspired or evolutionary algorithms (Chiong et al., 2010, 2012; Chiong, 2009)) in that it carries out a two-layer searching process, executing both the exploration and exploitation procedures in each cycle of iteration. The algorithm framework of ABC is relatively simple, making it possible to acquire good solutions at a low computational cost. However, there are also several issues or limitations associated with the algorithm.First, the exploration procedure of the conventional ABC algorithm is deemed not “global” enough. It is notable that only the value in one dimension of a solution vector (i.e.,Xijin Xifor some specifici∈{1,2,…,SN/2}) is involved in the operation described in Eq. (6). When applied to some higher dimension problems, this exploration procedure will gradually become inefficient. For example, when the dimension of a problem is 10, 10% of the elements of a candidate solution will be modified through the operation as per Eq. (6); when the dimension increases to 100, only 1% will be changed. One may naturally consider that making the number of elements in a candidate solution that are involved in the exploration procedure flexible would overcome the issue. However, we must point out that increasing the dimensions blindly does not make much sense because we cannot be sure of which among the changed dimensions contributes to the change of the objective function value.Secondly, the search efficiency in either the exploration or exploitation phase cannot be guaranteed. In Eq. (6) or (9), a random numberrand(−1,1)determines how “close” a new position is to the existing one. During the exploration phase, when we calculate a new search position, if the random number is very close to 0, such a global search is essentially equivalent to a local search. In other words, since the generation of a random numberrand(−1,1)obeys the uniform distribution, the efficiency of exploration/exploitation thus becomes arbitrary, making the search process uncertain. If the amplitude of such a random number can vary according to the true search demand, the whole convergence performance can be improved.The third issue concerns the re-initialization phase (i.e., lines 32–37 of Algorithm 1) at the end of each iteration in the conventional ABC algorithm framework. Having just one scout bee at most to be generated during the re-initialization phase limits the exploration/exploitation capability of the algorithm. In fact, it has been confirmed in some numerical experiments that directly discarding the scout bees will not necessarily deteriorate the convergence performance (Karaboga and Basturk, 2008).Apart from the three issues raised above, we note that most of the previous studies have focused too much on trying to remedy the ABC algorithm from an “algorithmic” perspective, thus overlooking potentially useful convergence information that lies within the iteration process. If such convergence information can be effectively utilized as feedback to guide the search intensity, the convergence performance may be far more efficient. This has been proven by a number of related recent work (Li et al., 2013, 2014), in which the authors incorporated such a feedback mechanism in the conventional ABC algorithm. According to the roulette selection procedure of conventional ABC, Pireflects the ith employed bee’s relative convergence ability. If Piis large, the number of onlookers it would attract is expected to be large too. In other words, the onlooker bees will know which employed bees are more “qualified” through the values of P. However, apart from P, the variable trial (see Algorithm 1) also contains useful convergence information about the employed bees, and this has been neglected by most of the aforementioned related work.BE-ABC aims to overcome the issues or limitations associated with the conventional ABC algorithm. To do so, a number of improvements have been made in both the exploration and exploitation procedures.During the exploration phase, when the ith employed beeXi=(Xi1,…,Xi2,…,XiD)shares information with a randomly chosen companion Xk, the new search position is calculated by the following equation:(10)Xi*j⟵Xgj+rand(−1,1)×(Xkj−Xij)×μ(i),k,g∈{1,2,…,SN2},j∈{1,2,…,D},k≠i.where the value in the jth elementXijis changed toXi*j. A novel multiplier μ(i) is introduced, defined as follows:(11)μ(i)=trial(i)trial(i)+trial(k).The operation previously described in Eq. (6) is also modified here in Eq. (10) by taking another randomly chosen companion Xginto account.As in the conventional ABC algorithm, trial(i) of BE-ABC records the number of times an inefficient search is performed. However, instead of 0 the lower boundary of trial(i) is set to 1. The upper boundary of trial, meanwhile, is set to D (i.e., Limit=D). Sincetrial(i)∈{1,2,…,D}, it is now feasible to have as many as trial(i) (randomly chosen) elements in the vector Xichanged according to Eq. (10). That is, we randomly choose trial(i) different integers from 1 to D, and then set each of them to j when performing Eq. (10).In the exploitation phase, we add a multiplier μ(i) in a similar way as per the exploration phase. Specifically, the position of the ith onlooker beeYi=(Xj1,…,Xjk−1,Yik,Xjk+1,…,XjD)is calculated by the following equation when it chooses the jth employed bee Xjto follow:(12)Yik⟵Xjk+rand(−1,1)×(Xmk−Xjk)×μ(j),m∈{1,2,…,SN2},k∈{1,2,…,D},m≠j.where m and k are randomly selected integers, and μ(j) is defined as follows:(13)μ(j)=trial(j)trial(j)+trial(m).During the re-initialization phase at the end of each iteration, any trial(i) that has exceeded Limit=D will be reset to D (rather than 0). Before proceeding to the next iteration, the average value of trial (i.e.,2SN∑i=1SN/2trial(i)) is compared toαodr×D, whereαodr∈(0,1)is a user-specified scalar. Ifαodr×Dis smaller than2SN∑i=1SN/2trial(i), the whole swarm is considered to be not working efficiently to a degree ofαodr. Then, as many asround(αodr×SN/2)(randomly selected) employed bees will be re-initialized according to Eq. (5). At the same time, their corresponding trial indices should be reset to 1. If2SN∑i=1SN/2trial(i)is smaller, the current iteration is terminated directly and a new iteration will begin. In this enhanced re-initialization procedure, we do not limit it to just a single scout bee at each iteration. Instead, we accumulate the necessary convergence information and make the required change at once. We call this the overall degradation strategy.The pseudo-code of the BE-ABC algorithm is given as follows.We have systematically conducted a series of simulation experiments, first on a set of artificial Fibonacci sequences (which have been widely used as benchmarks in this field) and then on several actual amino acid sequences. All the simulations were carried out in a Matlab R2013a environment and executed on a 6-core Intel Xeon CPU with 64 GB RAM running at 6×3.06GHz under Mac OS X 10.9 Mavericks.In the first set of experiments, we investigated the convergence performance of our proposed BE-ABC algorithm and compared it to that of the conventional ABC algorithm. In the first part of the first set of experiments, we focused on the evaluation of the initial convergence rates of the ABC and BE-ABC algorithms. We used four artificial Fibonacci sequences (see Table 1) for this evaluation. In each of the four cases, we repeated the simulations for as many as 30 times to ensure that the results are statistically relevant. As already mentioned at the end of Section 2, the two bonds of each candidate solution should beXmin⁡=(−180∘,−180∘,...,−180∘)andXmax⁡=(180∘,180∘,...,180∘). User-specific parameters were set as SN=40 andLimit=D−1(the latter is only for the ABC algorithm).Figs. 3–6show the initial convergence performances of conventional ABC and different versions of BE-ABC (withαodrequals 0.3, 0.5 and 0.9, respectively) based on the four benchmark cases. From the figures, we see that the convergence rates of the ABC algorithm gradually decrease as the number of iterations increases. BE-ABC, on the other hand, is able to further improve its performance when the number of iterations is higher. It is notable that the improved performances of BE-ABC can be observed as early as 100–200 iterations in Cases 1 and 2, while it is taking a longer amount of time to pull away in Cases 3 and 4. This is understandable as the dimension of the optimization problem D increases with the length of the to-be-folded sequence N. The overall degradation procedure of BE-ABC, which overcomes premature convergence, therefore needs more time to take effect.Detailed numerical results of the same comparisons can be seen in Table 2, where “Best” denotes the lowest free-energy value found within the given iterations, and S.D. is the standard deviation. From the table, we observe that the best-ever results obtained by the ABC algorithm are even worse than the average values obtained by the three versions of BE-ABC in Cases 3 and 4. It is interesting to note that the best results for the four cases are always found by the BE-ABC version withαodr=0.9. Meanwhile, the other two versions of BE-ABC have better average values. A possible reason for this may be that, whenαodris set to be relatively large, the trial values will be large too, leading to an increased number of dimensions for the algorithm to deal with. Besides that, μ will approach 0.5 on average. Under that condition, each employed bee would not “trust” the companions sufficiently. When this is the case, they would more often search in a near-random manner. Even though this adds “diversity” to the swarm (and therefore good results can still be obtained), the overall convergence performance may be affected.Besides the overall degradation strategy we introduced in the BE-ABC algorithm, some other improvements may also have contributed to the better results obtained. For the exploration phase, the companion g does not necessarily equal to i as in Eq. (10), which promotes the global search capability of the bee swarm. More importantly, we have increased the dimensions involved in Eq. (10) according to the index of trial. The rationale is that, we will gradually put less “trust” in some ith employed bee’s original location Xias trial(i) increases. For those locations, we are more interested in finding better solutions around them than knowing which change of the dimensions makes sense.Moreover, it is notable thatμ(i)∈[1/(D+1),D/(D+1)]⊆(0,1). When a trial(i) value becomes larger in Eq. (11), μ(i) also gets larger, which implies that we do not expect a better location near the original location Xito be found, as we have already tried(trial(i)−1)times without success around Xi. By having such a convergence multiplier, we are able to adjust the global exploration efficiency in an adaptive manner. The scenarios for the exploitation phase will be quite similar to the exploration phase and therefore we will not discuss them here.In the second part of the first set of experiments, we focused on the final results of the same four artificial Fibonacci cases mentioned above. Figs. 7–10show the best structures obtained for the four cases using BE-ABC, together with their corresponding solution vectors. From the figures, we observe that the hydrophobic amino acids (i.e., the light-colored particles) tend to gather to form a single hydrophobic core, which is regarded as an intrinsic characteristic in an actual protein conformation (Kim et al., 2005; Hansmann and Wille, 2002). The structures observed in Figs. 7–9 each represents a typical, if not perfect, hydrophobic core. In Fig. 10, however, the hydrophobic amino acids have formed more than one hydrophobic core. Particularly, there is a single hydrophobic amino acid located on the edge of the whole conformation, which indicates that there is still room for improvement in the optimization approach we have adopted here.In Table 3, we show the best results obtained for the four cases by BE-ABC as well as other state-of-the-art approaches from the literature. As can be seen, apart from Case 1 the results produced by the BE-ABC algorithm are, as far as we know, currently the best. In other words, BE-ABC has achieved the best results in the literature for three of the four Fibonacci sequences.Having confirmed the competitiveness of BE-ABC using benchmark cases, in the second set of experiments we used it to optimize the structures of three amino acid sequences taken from the real world PDB database. The detailed sequence information is given in Table 4, where I, V, L, P, C, M, A, and G are classified as hydrophobic particles “A” and amino acids D, E, F, H, K, N, Q, R, S, T, W, and Y are hydrophilic particles “B”. Table 5shows the results (i.e., the minimal free-energy values) obtained by BE-ABC as well as other competitive algorithms from the literature that have also been used to solve the same instances. The optimized structures of these instances together with the corresponding reference structures from the PDB database are shown in Figs. 11–13.From the figures, we can see that the directional trends and helical characteristics in the actual structures are partly revealed in the conformations optimized by BE-ABC. Specifically, the α-helices at the bottom of the structure we optimized in Fig. 12 match the actual ones on the right of the same figure. As aforementioned, hydrophobic residues (see the light-colored particles in Figs. 11–13) tend to form a core with a minimum surface area that encounters water molecules. Therefore, such a hydrophobic core is often surrounded by hydrophilic residues. This can be easily observed in the structures we optimized using BE-ABC.Despite the similarities, we notice that there are also some variations between the optimized structures and their corresponding references. Two possible reasons would be: (1) due to the complexity of the optimization model, there are difficulties in finding the “true” global optimum; or (2) the AB off-lattice model we adopted in this work does not fully reflect the characteristics of the amino acids in a sequence. Nevertheless, the results in Table 5 indicate that BE-ABC is the best performing algorithm in the literature based on the instances considered. This points to the likelihood that the simplified AB off-lattice model might not be up to the task for real protein structure optimization. According to the AB off-lattice model, all the amino acid residues are simply classified into the hydrophilic and hydrophobic groups. This could potentially neglect the underlying differences within either of the two groups.In this paper, we have applied the BE-ABC algorithm to optimize the structures of protein in a three-dimensional space based on the AB off-lattice model. Our simulation results clearly demonstrated that BE-ABC can outperform other state-of-the-art approaches from the literature. It is therefore an effective and viable option for the protein structure optimization problem.Despite the positive results, we hope to further enhance the performance of our approach on sequences with more amino acids (e.g., >100). Our future work will therefore examine real-world cases with longer sequences from the PDB database. Besides that, we will also investigate how the folding path of a protein sequence can be identified on the basis of the AB off-lattice model.

@&#CONCLUSIONS@&#
