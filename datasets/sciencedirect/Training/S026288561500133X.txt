@&#MAIN-TITLE@&#
Multi-view facial landmark detection by using a 3D shape model

@&#HIGHLIGHTS@&#
Accurate facial landmark detector coupled with a 6 DoF head pose estimatorA reliable global method followed by a precise local optimizationNovel learning method based on structured output SVMMulti-view detector working on a wide range of viewing angles (frontal-profile). Self-occlusions handled.Comparison with recent state-of-the-art methods on standard “in the wild” datasets with quantitatively favourable results.

@&#KEYPHRASES@&#
Face,Landmarks,Detection,Localization,3D model,Shape,Occlusions,

@&#ABSTRACT@&#
An algorithm for accurate localization of facial landmarks coupled with a head pose estimation from a single monocular image is proposed. The algorithm is formulated as an optimization problem where the sum of individual landmark scoring functions is maximized with respect to the camera pose by fitting a parametric 3D shape model. The landmark scoring functions are trained by a structured output SVM classifier that takes a distance to the true landmark position into account when learning. The optimization criterion is non-convex and we propose a robust initialization scheme which employs a global method to detect a raw but reliable initial landmark position. Self-occlusions causing landmarks invisibility are handled explicitly by excluding the corresponding contributions from the data term. This allows the algorithm to operate correctly for a large range of viewing angles. Experiments on standard “in-the-wild” datasets demonstrate that the proposed algorithm outperforms several state-of-the-art landmark detectors especially for non-frontal face images. The algorithm achieves the average relative landmark localization error below 10% of the interocular distance in 98.3% of the 300W dataset test images.

@&#INTRODUCTION@&#
Facial landmarks refer to points on the face like the corners of the mouth, the corners of the eyes or the tip of the nose that can be annotated by a human. Detection of facial landmarks in images has many potential applications as e.g., animation, morphing, and it is an important step in most face image interpretation tasks. Face images usually need to be aligned and normalized with the help of landmarks prior to recognition of e.g., identity, age, gender, expression.Most facial landmark detectors simultaneously model local appearance around the landmarks and their geometrical configuration. The local appearance is represented either by generative models (e.g. [1]) or by discriminatively trained detectors (e.g. [2]). The geometrical structure of the landmarks is usually modelled by a Point Distribution Model (PDM) [3], which describes the landmark positions on a face in canonical frame, and by a subsequent deviation from the canonical pose in 2D image coordinates. Both PDM of 2D shapes (e.g. [1,4]) and 3D shapes have been proposed (e.g. [5]).Fitting the shape models into the image requires optimization of a highly non-convex fitness function typically carried out as gradient search sensitive to the initial estimate or by regression. The problem with local optima is mitigated either by re-initializing the optimization, by using global but expensive optimization methods (e.g. [6]), or by simplifying the shape model. A prominent example of a simplified 2D shape prior is the Deformable Part Model (DPM) [7] representing the shape by a pair-wise energy function whose global optimum can be found efficiently by dynamic programming. Excellent results of DPM based facial landmark detectors have been demonstrated e.g. in [8,9]. On the other hand, DPM detectors can describe only a limited range of face poses and thus a multi-view detector must be composed of several DPMs (e.g. [8]).Recently, regression methods have been very successful. The methods avoid explicit local or global optimization and learn a cascade of regression functions that map the input image to the target output, which is either directly the landmark locations in the image [10,11] or indirectly a set of parameters of 2D [12] or 3D shape models [13]. Typically, pose-indexed (also known as shape-indexed) features are leveraged. In each stage of the cascade, a regressor extracts features from image locations relative to the current estimate of landmarks to predict a model update. Regression-based methods are usually much faster than optimization-based methods and often run faster than real-time [14,15]. However, like the local optimization methods, these methods require initialization. Another potential difficulty with the regression methods using pose-indexed features has to be overcome for training. Annotation of all landmarks is necessary for every image in the training set. Manual annotation is not always complete because of: (1) self-occlusions due to various pose changes – separate regressors need to be trained for poses with shared subsets of visible landmarks, or (2) occlusion by hairs, hands, or other objects – these images cannot be used, or simply (3) a different set of landmarks is often annotated for datasets – it is then typically not possible to combine multiple datasets for training.Currently, the difference in performance of DPMs fitted by a global method, of the genuine 3D shape models fitted by local methods, and of the regression-based methods is not fully understood.Besides using the intensity image alone, there are approaches that work with RGB-D data (image + depth) to detect landmark and to align 3D faces, e.g. [16,17,18].In this paper we show that a robust and precise landmark detector is obtained by fitting a simple 3D shape model into the image using a full perspective projection. The method jointly fits M shape parameters and the 6 DoF pose (position and orientation) of the 3D face model with respect to the camera, see Fig. 1.In addition, we propose a novel method for discriminative learning of the local detectors that are used to guide the fitting of the model. We learn scoring functions whose value decreases approximately linearly with the Euclidean distance from the true landmark position. The method often produces unimodal peaks around the true landmark positions which helps to make the basin of attraction sufficiently large. The approach differs from the commonly used two-class classification methods, like the Support Vector Machines or AdaBoost, whose learning objective does not take the distance from the true landmark position into account.Related to our approach is the work of [2], a local optimization-based method employing a 3D model, that has a single degree of freedom to capture the shape. However, a simpler camera model is used, weak perspective in [2] vs. full perspective, and a substantially different learning of the local landmark scoring functions is employed, a standard AdaBoost [2] vs. the novel learning method.Another related work is a regression-based method [13] which uses a parametrization similar to ours, but again in conjunction with the weak perspective camera. Due to the nature of the regression that takes the entire face image as an input, this method is sensitive to self-occlusions. If the head is turned so that certain landmarks are not visible in the camera, the occluded landmarks cannot be easily disregarded. In the proposed method, a contribution of the occluded landmarks is easily switched off in the optimization data term. The property leads to accurate results on face images captured from arbitrary view-point and not only on near frontal images. To the best of our knowledge we are not aware of any landmark detector functioning reliably in a multi-view setup.To summarize, the contributions of the paper are:1.A novel precise local optimization-based algorithm coupled with a robust initialization scheme based on a global method is proposed. The initialization gives a raw estimate. Thanks to its global optimality it is likely to be free of outliers.A novel method for learning local landmark detectors is introduced. It produces smooth unimodal score functions with a large basin of attraction.Self-occlusions are explicitly taken into account, which results in an algorithm operating for a broad set of viewing angles, e.g. semi-profile and profile views.A thorough comparison of the proposed method with state-of-the-art implementations of two different DPM based detectors [9,8], and with two recent regression-based method [13] and a multiview implementation of [11] is performed. The proposed method and [9] use the same local detectors, but differ in the used shape prior. The proposed method and [13] have a similar parametric modelThis paper is an extension of [19] with improved 3D model parametrization to capture a wide range of subjects and facial expressions. The optimization scheme is robustified by introducing a reliable initialization strategy. A range of applicable angles is extended by modelling the landmark visibility. We are now estimating up to 49 landmarks as opposed to 7 landmarks in [19].The rest of the paper is structured as follows: The algorithm is presented in Section 2, the justification of the design choices is discussed in Section 3, and its implementation details are given in Section 4. Experimental validation, including both the introspection and comparison with several state-of-the-art methods, is presented in Section 5. Finally, Section 6 concludes the paper.The estimation problem addressed entails: (1) localization of landmarks in the image, (2) estimation of the head pose, i.e., a position and orientation with respect to the camera coordinate system, (3) reconstruction of the landmark points in 3D. Quantities (1–3) are calculated from a single image.The architecture of the proposed algorithm is depicted in Fig. 2. The pipeline consists of two stages: the initialization and the optimization. The three problems (the landmark detection, head pose estimation, and 3D reconstruction) are coupled and are solved as a single optimization problem, see Section 2.2. A parametric 3D shape model is fit to maximize the values of landmark scoring functions. Each landmark scoring function takes the image and for a query pixel returns a score proportional to how likely the landmark occurrence centred at the pixel is, see Section 2.1. The proposed criterion is non-convex, therefore a robust initialization procedure is needed, see Section 2.3. The initialization integrates a multi-view face detector and an implementation of a state-of-the-art DPM. We choose a simpler 2D landmark model working in a low image resolution, which provides a globally optimal solution.Let us define the landmark score function ci(x,I) which estimates the likelihood of the i-th landmark being at position x in the image I. The most likely position isx̂i=argmaxx∈XicixIwhereXidenotes the searched positions. We consider a linearly parametrized score.(1)cixIwi=ΨxIwi,where 〈⋅,⋅〉 denotes a dot product, Ψ(x,I)∈ℜndenotes a feature descriptor extracted from a patch cropped from the image I around the position x and wi∈ℜnis a weight vector associated with the i-th landmark. We construct the descriptor Ψ(x,I) by concatenating the Local Binary Patterns (256 valued code assigned to a 3×3 patch) computed at all positions of the cropped patch rescaled to size 20×20, 10×10 and 5×5 pixels, respectively. By this process we obtain 256(182+82+32)-dimensional sparse (182+82+32 non-zero elements) binary feature descriptor whose values are to some extent robust against scale and lighting conditions. The side of the cropped squared patch is 0.3 of the bounding box side returned by the face detector.The proposed method uses the score functions to guide the search for the most likely configuration of the 3D face pose. It is common to learn the score functions by two-class classification methods, like the Support Vector Machines or AdaBoost, learning the score that best separates example patches collected at the true positions from the patches sampled around the true position. These methods do not take the distance from the true landmark position explicitly into account. In turn, there is no guarantee that the learned score will form unimodal peaks around the true positions.We propose a different approach which learns the score function such that its value decreases at least linearly with the Euclidean distance measured from the truth landmark position. To this end, we define the lossℓixIwi=maxx'∈Xix′−x+Ψx′Iwi−ΨxIwi,where x denotes the true position of the i-th landmark in the image I. We require the score of the correct position to be higher than scores of incorrect positions by a margin. The margin is equal to the distance from the correct position. Any violation of this condition is penalized by the loss. Note that the value ofℓi(x,I,wi) upper bounds the Euclidean distance between the true position x and the position with maximal score, i.e.x̂i=argmaxx∈XicixI.Given a training set {(I1,xi1),…,(Im,xim)} containing pairs (Ij,xij) of images Ijand the ground-truth positions xijof the i-th landmark, we learn the parameters wiof the score function ci(x;wi) by solving(2)wi=argminw∈ℜnλ2w2+1m∑j=1mℓixijIjw,where λ>0 is a positive constant penalizing large weighs in order to prevent over-fitting and its optimal value is tuned on a separate validation set. The problem (2) can be seen as an instance of the Structured Output Support Vector Machines with margin-rescaling loss [20]. The formulation (2) translates learning of the i-th local detector to an unconstrained convex optimization problem which we solve efficiently by the cutting plane algorithm [21].Before presenting the problem formulation, let us introduce the notation: we denote a vector v=(v1,v2,v3)T, its homogeneous extension asv˜=v1v2v31T, and the operator which transforms a vector to Euclidean representation asvE=1v3v1v2T.A perspective camera K[R(Φ)|t], with intrinsic matrix K, rotation matrix R parametrized by Φ=(α,β,γ)T, which are roll, pitch, yaw angles respectively, and the translation t=(tx,ty,tz)Tprojects a 3D landmark point Xi=(Xi,Yi,Zi)Tinto a 2D image point(3)xi=xiyiT=KRΦtX˜iE.A 3D model of a person/expression specific landmark configuration can be expressed as a PCA model. The i-th landmark point(4)Xiη=Xi0+∑j=1MηjSij,where X0 is the mean model, Sjare length normalized eigenvectorsSj=λj,where λjis an eigenvalue corresponding to eigenvector Sjof the shape covariance matrix. Thenη=(η1,…,ηM) is a vector of M parameters encoding the shape.The pose and shape estimation is formulated as a single optimization problem(5)Φ*t*η*=argmaxΦ,t,ηFΦtη,where the criterion(6)FΦtη=DΦtη+ρRηis a sum of data term D and regularization term R. A small positive constant ρ is the weight of the regularizer. Data term(7)DΦtη=∑t=1NViciKRΦtX˜iηE,measures the fit of a model instance to the image. Scores ci(xi) stands for a value of a local scoring function of landmark i located at image position xi, see Eq. (1). An example of the score maps is shown in Fig. 3. Variables Virepresents a visibility, Vi=1 if landmark i is visible and Vi=0 otherwise. Thus contributions of occluded landmarks are switched off. The data term is the sum of values of individual scoring functions for all visible landmarks given the camera pose and shape parameters.Regularization term penalizes a discrepancy between the reconstructed and the mean shape,(8)Rη=−η22=−∑j=1Mηj2.It can be easily shown that this term is approximately the squared Mahalanobis distance between the reconstructed shape and the mean shape R(η)≈(X(η)−X0)TC−1(X(η)−X0). Where C is the shape covariance matrix. This immediately follows from (4). Recall that the eigenvectors are normalized to the length of corresponding eigenvalues. Note that the equality holds precisely when all the eigenvectors are considered.After solving problem (5), the reconstructed 3D model of landmarks Xi⁎ is computed by substitutingη⁎ into (4), and the landmarks in the image xi⁎ are found by projecting the 3D model Xi⁎ by the camera at the optimum rotation and translation {Φ⁎,t⁎} according to (3).The maximum of (6) can be found by any method for smooth optimization. In particular, we use the LBFGS algorithm of [22] which requires only a routine computing the value and the gradient of the objective function. The gradient of the regularization term is zero with respect to the pose parameters and∂R∂ηj=−2ηj. The gradient of the data term has a special structure. To simplify the notation, let us collect all parameters into a tuple Θ=(Φ,t,η) where the first six entries represent the pose while the remaining M entries are the shape parameters. Let us denote the projection of the i-th model point into the image aspiΘ=KRΦtX˜iηE=xiyiT. Then the data term in (6) becomes.(9)DΘ=∑i=1NVicipiΘ.The gradient with respect to the parameters is.(10)dDΘdΘ=∑i=1NVidcipiΘdΘ=∑i=1NVidcipiΘdpiΘdpiΘdΘ,where(11)dcipiΘdpiΘ=∂cixiyi∂xi∂cixiyi∂yi=JcipiΘ,(12)dpiΘdΘ=∂xiΘ∂θ1,…,∂xiΘ∂θ6+M∂yiΘ∂θ1,…,∂yiΘ∂θ6+M=JpiΘ.The gradient is a sum of products of two matrices over the visible landmarks. Matrix Jpi(Θ) is the 2×(6+M) Jacobian matrix. The derivatives are rather complex due to a non-linearity of the mapping pi(Θ), but they are computed analytically. MatrixJcixiyiof size 1×2 is the spatial gradient of the landmark scoring function. The derivatives are computed using a symmetric Gaussian kernel of scale σ and finite differences. The choice of σ has to be carried out carefully since it influences the optimization outcome. A landmark scoring function is evaluated in a window of 4σ×4σ pixels around the target pixel, which can be expensive for large σ. Empirically we found that σ=3 works well and this value is used in all our experiments.The optimization problem formulated in (5) is non-convex. The gradient descent method finds a local optimum only and therefore it needs to be initialized carefully. We propose the following initialization strategy, which is depicted in Fig. 2.First, a scanning window face detector is executed on the input image. We use a Waldboost-based commercial detector11By Eyedea recognition, Ltd. http://www.eyedea.com.[23], that successfully operates in a large range of viewing angles. Besides the bounding box, it also outputs a rough estimate of roll and yaw angles. The roll is the angle of the in-plane rotation while the yaw is the out-of-plane rotation of the head, i.e. from left to right. The pitch angle, i.e. the elevation of the head, is not provided.For each detection, the image is cropped according to the bounding box, rotated so that the faces were upright, and finally normalized into a low resolution 80×60 pixel image In. The original s and normalized snimage coordinates are related by similarity transformationsn=Ans˜E.The normalized image Inis used as in input to the 2D DPM landmark detector [9]. We trained a collection of four DPM models for quantized yaw angles: near frontal (−15∘,15∘), semi-profiles (15∘,45∘) and (45∘,75∘) and profile (75∘,90∘). The remaining three models for yaw angles (−90∘,−75∘), (−75∘,−45∘) and (−45∘,−15∘) are not trained but the solution is obtained by mirroring the image. Each model is independently trained for a particular subset of landmarks which are typically visible in the respective yaw interval, see Fig. 4. The estimate of the yaw angle from the face detector is used to select the model. Finally the 2D DPM algorithm provides 2D landmark positions snand the corresponding visibility vector V=(V1,…,VN) with Vi=1 for landmarks i that were found by the model and zero otherwise. An important advantage of 2D DPM is that it finds a globally optimal solution. Nevertheless, the model has a very simple structure, i.e. MRF on a tree, and since it needs to evaluate all possible configurations, it works in the low resolution image with pixel precision. This causes the final 2D landmark positions s, obtained by back-projecting snto the original high resolution image by An−1, not to be very precise. Due to the global optimality they are likely to be free of gross errors.The final optimization procedure described in Section 2.2 requires an initialization of the pose of the 3D model of landmark configuration. Once landmark points si=(sxi,syi)Tare detected in the image, the pose can be estimated by the PnP algorithm [24,25], which additionally requires intrinsic camera matrix K and a 3D model. We use here a generic (not a person-specific) 3D model Xi0, see (4). Using the correspondences between the 3D model points and 2D image points Xi↔si, it estimates the 6 DOF pose by(13)Φ0t0=argminΦ,t∑i=1NVisi−[K[RΦt]X˜i0]E22,i.e. minimizing the sum of squared geometric re-projection errors ‖si−xi0‖22 over the visible landmarks: It has an algebraic solution for minimal set of points N=3, which leads to a set of polynomial equations with several real solutions. The minimal solution is repeatedly used in a RANSAC scheme [26]. For the consensus set, the problem (13) is solved by iterative Levenberg–Marquardt optimization starting from the solution having the maximum support in RANSAC.Finally the optimization procedure solving the problem (5) is initialized by the pose of a generic model estimated by the PnP solverΦ0,t0. The initial shape parameters are setη=0, which represents the mean shape X(0)=X0. Visibility vector V is the same as for the PnP solver. This way we provide a tight initialization as will be demonstrated by experiments in Section 5.

@&#CONCLUSIONS@&#
