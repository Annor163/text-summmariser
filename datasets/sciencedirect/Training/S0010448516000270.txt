@&#MAIN-TITLE@&#
A framework for geometry acquisition, 3-D printing, simulation, and measurement of head-related transfer functions with a focus on hearing-assistive devices

@&#HIGHLIGHTS@&#
We present a pipeline of geometry acquisition, printing, and HRTF determination.HRTFs are determined from both acoustical measurements and FEM simulations.Monaural spectral features were more similar between measurements than simulations.Binaural ITD cues were very similar among all three HRTF sets.

@&#KEYPHRASES@&#
3D head model,CAD modeling,3D printing,Acoustical measurements,Acoustical simulations,Head-related transfer functions,

@&#ABSTRACT@&#
Individual head-related transfer functions (HRTFs) are essential in applications like fitting hearing-assistive devices (HADs) for providing accurate sound localization performance. Individual HRTFs are usually obtained through intricate acoustic measurements. This paper investigates the use of a three-dimensional (3D) head model for acquisition of individual HRTFs. Two aspects were investigated; whether a 3D-printed model can replace measurements on a human listener and whether numerical simulations can replace acoustic measurements. For this purpose, HRTFs were acoustically measured for four human listeners and for a 3D printed head model of one of these listeners. Further, HRTFs were simulated by applying the finite element method to the 3D head model. The monaural spectral features and spectral distortions were very similar between re-measurements and between human and printed measurements, however larger deviations were observed between measurement and simulation. The binaural cues were in agreement among all HRTFs of the same listener, indicating that the 3D model is able to provide localization cues potentially accessible to HAD users. Hence, the pipeline of geometry acquisition, printing, and acoustic measurements or simulations, seems to be a promising step forward towards in-silico design of HADs.

@&#INTRODUCTION@&#
Human listeners are able to localize sounds in space in terms of assigning direction and distance to the perceived auditory image  [1]. This ability is an essential function of spatial hearing, which involves further perceptual effects like the estimation of the apparent source width, spatial unmasking of speech (cocktail party effect), and externalization (out-of-head perception) of sounds. Generally, spatial hearing relies on physical directional acoustic features which are the consequence of acoustic filtering of the sound by the pinna, head, and torso. The filtering can be described by the head-related transfer functions (HRTFs), which represent the transfer functions from sound sources to a sound receiver, usually placed at the entrance of the ear canal. For far-field sources, HRTFs depend on the direction of sound incidence  [2]. For near-field sources, HRTFs additionally depend on the distance between the source and the ear  [3].An HRTF encodes monaural spectral cues, which are used by human listeners to estimate the sound-source position along sagittal planes (top, down, front, back). For the localization of the source along horizontal planes (left, right), interaural cues are used, namely, interaural time and level differences (ITDs, ILDs). In particular, ITD cues in the frequency range below 1.5 kHz are important for the sound localization in the horizontal planes. The interaural cues are encoded in a binaural pair of HRTFs, thus, a binaural set of HRTFs can be used to describe all directional cues required for spatial hearing.HRTFs can be used for many purposes, e.g., for models of spatial hearing  [4–6], for fitting of hearing aids  [7,8], and for presenting virtual binaural audio signals via headphones in so-called virtual auditory displays  [9,10]. As HRTFs depend on the individual geometry of the listener’s head and ear, HRTFs are listener-specific  [11]. Listener-specific HRTFs are often acoustically measured by placing small microphones at the entrance of the listener’s ear canals. During a measurement session, often consisting of measurements for many spatial positions, the listener must sit still for tens of minutes depending on the measuring facilities  [12–14]. Thus, it is not surprising that in some applications, generic HRTFs, i.e., HRTFs of a manikin representing an average of the human population  [15–17], are used. However, in applications like fitting hearing aids to children  [18] or providing accurate sound localization performance via headphones  [19], it might be important to consider listener-specific HRTFs. As an alternative to demanding acoustic measurements, HRTF can also be numerically calculated from a three-dimensional (3D) representation of a human geometry  [20–23] and established methods have shown good congruence between measured and simulated HRTFs for frequencies below 7 kHz  [23,24].In this study, a method for obtaining listener-specific HRTFs with the focus on virtual product design is evaluated. An application could be optimization of the directional microphone using the Directivity Index as an evaluation criteria, as is performed in.11Optimizing hearing-aid directionality from measurements and simulations, S. Harder, R.R. Paulsen, M. Larsen, M.S. Pedersen, S. Laugesen, M. Mihocic, and P. Majdak, manuscript in preparation.Virtual product design is an emerging discipline that has the potential of reducing production costs and creating more comfortable and better functioning wearables as for example clothes, helmets, and in our case, hearing-assistive devices (HAD), which are commonly used to treat hearing impairment. An example of virtual product design is the size-China project that aims at creating a population statistics on human heads for product design  [25]. In  [26], a parametric model of the entire human body was computed based on 250 full body scans. This model was then used to synthesize plausible body shapes as input to product design. In another example, foot shape was investigated in several studies driven by the large footwear industry and recently, 50 surface scanned feet were used as input to a statistical analysis of shape with the goal to produce optimized shoe lasts  [27]. Similarly, in the design of HADs, the position of the microphones is essential, not only for the design of the casings, but also for capturing spatial acoustic cues. Thus, different types of microphones at various places have been proposed, for a recent review, see  [28]. The measurement of HRTFs with HADs is even more demanding than the measurement done in the ear canal because of the much larger degree of freedom: a simple positioning of the HAD might yield different HRTFs, and many microphone positions have to be considered in the individualization of the HAD. On the other hand, since most of the HADs focus on transmitting frequencies below 8 kHz  [29], the evaluation of HRTFs can be limited to the upper frequency 8 kHz.This paper presents yet another step towards full in-silico design of HADs. The goal is to evaluate whether simulated HRTFs can replace expensive acoustic measurements in the future. We simulate listener-specific HRTFs based on a reconstruction of the listeners’ geometry from a set of 3D surface scans with missing data. An evaluation of methods for optical 3D scanning of human pinnas is available in  [30]. HRTF measurements are expensive with respect to measurement equipment and measuring time for the listener, in particular when measuring HRTFs for different microphone positions in an HAD. In a simulation re-positioning of the microphones does not require additional participation of the listener. HRTF simulations can have a further impact on the future product design: by using statistical shape modeling (as in for example  [26,27]), HRTFs of future HADs could be obtained for hundreds or even thousands of plausible virtual heads, in contrast to the current practice where one or a few generic manikin heads are used because of the time-consuming measurement procedure.In the following, the three stages of investigations are described. First, a high-quality 3D geometrical model of a human listener was used to numerically simulate corresponding HRTFs. Second, computer-aided-design modeling and 3D printing were used to obtain a listener-specific 3D printed head model, from which acoustically measured HRTFs were obtained. Third, acoustical measurements were performed to obtain HRTFs of the corresponding actual human listener. This three-step pipeline allowed for a thorough evaluation of the differences among acoustically measured and simulated HRTFs of the model and the listener. The acoustically measured HRTFs for the printed head model made it possible to distinguish between HRTF deviations caused by differences in shape (human versus obtained 3D model) and differences in method (measurements versus simulations).

@&#CONCLUSIONS@&#
All three kinds of HRTFs were acquired for a single subject, NH167. Very similar spectral cues were observed between the repeated human measurements and between the human and printed-head measurements. More substantial differences were observed between the measurements and the simulations. The ITDs revealed a good agreement among the three different kinds of HRTFs for the same subject, whereas meaningful differences were observed among listeners. The very similar ITDs are encouraging and it is possible that the simulations are useful for virtual prototyping despite the spectral differences observed between simulations and measurements. Applications like optimization of directionality in HADs, where the spatial dependency of HRTFs is more important than the individual monaural cues, are the focus of our future work. The process of printing a head-and-ear geometry seems to be promising considering both the ITDs and the spectral cues.