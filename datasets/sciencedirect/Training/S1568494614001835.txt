@&#MAIN-TITLE@&#
Improved global-best particle swarm optimization algorithm with mixed-attribute data classification capability

@&#HIGHLIGHTS@&#
We address a major problem encountered in the classification domain: datasets with mixed-attribute value.We make a survey of particle swarm optimization approaches to resolve mixed attribute data. We analyze solutions reported in the literature and study possible enhancement.We propose an enhancement of a PSO classification algorithm.We make a data oriented comparative study.

@&#KEYPHRASES@&#
Mixed attribute data sets,Particle swarm optimization,Supervised learning,Classification,

@&#ABSTRACT@&#
This paper describes a novel Particle Swarm Optimization (PSO)-based classification algorithm with improved capabilities in comparison to several alternatives. The algorithm uses a new particle-position update mechanism and a new way to handle mixed-attribute data based on particle position interpretation. The new position update mechanism combines particle confinement and dispersion for improved search space coverage, and the proposed interpretation mechanism uses the frequencies of non numerical attributes instead of integer mappings. As our experimental results have shown, this leads to better cost function evaluation in the description space and subsequently enhanced processing of mixed-attribute data by the PSO algorithm. Our experimental setup consisted of three large benchmark databases, and the obtained recognition accuracies were better than those obtained with well-known classifiers.

@&#INTRODUCTION@&#
Heterogeneous input data consisting of a mixture of discrete, continuous and nominal variables are frequent in classification tasks. For instance, when sorting patients into diagnostic and prognostic groups (healthy and sick) in a hospital, to decide whether to admit them in or treat them as outpatients, the outcome typically relies on indicators that include continuous (e.g. temperature), nominal (e.g. presence or absence of some symptoms) and ordinal measurements (e.g. score). Another example is the analysis of a credit application in a banking context. It usually includes classifying the application as risky or not, based on information such as age (numerical discrete), annual gain (continuous) or marital status (categorical). Finally, one can also think of the technical specifications of an electronic circuit where mixed-attribute data are common.When dealing with mixed data, classifiers typically conduct a preliminary coding stage to map the non numerical values into integer enumerations. Two challenges need addressing when doing so: How to establish an order relation on the transformed data and the potential knowledge representation bias caused by a flat (unweighted) representation of the non-numeric data, with the result that the relative importance of the individual non-numeric values is lost during the coding process. In this paper, we present an approach that avoids these problems by interpreting instead of straight coding. The interpretation mechanism inherently reproduces the weighting semantics of the non-numeric data, and it is easily integrated in a metaheuristic-based classification approach, particle swarm optimization (PSO) in this work.In the remainder of this paper, Section 2 is a brief literature review of PSO approaches for classification. Section 3 provides a concise survey of how previous PSO approaches have dealt with continuous and discrete data. Section 4 presents PSO adaptation for classification tasks and our approach with its computational cost analysis, followed by the experimental results achieved on three large benchmark data sets in Section 5. Related works are discussed in Section 6, and a conclusion ends the paper.Efforts that seek to apply PSO to more diversified problem areas are increasing. Poli [1] defines 26 different categories of applications where PSO has been used successfully. The categorization was the result of analyzing more than eleven hundred publications on PSO stored in the IEEE Xplore database and the study revealed that clustering, classification and data mining represented 4.3% of the total production.PSO has already proven its effectiveness for classification tasks (see De Falco et al. [2] or Section 6). The literature indicates that a particle swarm optimizer constitutes a suitable and competitive technique for such an endeavor, and that it can be successfully applied to demanding problem domains, particularly when accurate yet comprehensible classifiers, fit for dynamic, distributed environments are required [3]. Below is a chronological survey of some recent studies that used PSO for classification tasks11Only studies using plain PSO are mentioned; PSO is commonly combined with other classification approaches in the literature, mainly neural networks.:In [4], PSO is extended by using sequential niching methods to handle multiple minima. It combines feature-based object classification with efficient search mechanisms to visually recognize objects in an image. Each particle in the swarm is a self-contained classifier that “flies” through the solution space seeking the most “object-like” regions. The classifier swarm simultaneously finds objects in the scene, determines their size, and optimizes the classifier parameters. The approach is described as an efficient and effective search mechanism. It is also shown to be very fast and can robustly detect multiple objects in the scene.In [5], the authors describe a self-organizing particle swarm algorithm, SOSwarm that adopts unsupervised learning. The input vectors are projected onto a lower dimensional map space, hence producing a visual representation of the input data similar to that of the SOM (Self-Organizing Map) artificial neural network. The particles in the map react to the input data by modifying their velocities according to the standard PSO update function and, therefore, organize themselves spatially within fixed neighborhoods in response to the input training vectors. SOSwarm was successfully applied to four benchmark classification problems from the UCI Machine Learning repository [34] (namely the Wisconsin breast cancer, Pima Indians diabetes, New Thyroid and Glass) with the algorithm outperforming or equaling the best reported results on all four of the problems analyzed.De Falco et al. [2] offer an evaluation of PSO's efficiency for a set of classification tasks. PSO was applied to data from nine different databases taken from the UCI repository, and the obtained results were compared to those provided by nine classical classification algorithms available within the Waikato Environment for Knowledge Analysis (WEKA) system, release 3.4 [60]. The alternative classification methods were as follows: Multilayer Perceptron (MLP) Radial Basis Functions (RBF) networks, KStar, Bagging, MultiBoostAB, Naïve Bayesian Tree (NBTree), Ripple Down Rule (Ridor) and Voting Feature Interval (VFI). The parameter values in either technique were those set by default in WEKA. The obtained results were that PSO had the best accuracy for three out of nine challenged problems. Some relationships between problem size and PSO performance were also hypothesized from the experimental results [2,6] to the effect that two-class problems can be suitably addressed with PSO, but no clear conclusion can be drawn for three or more class problems. In the latter case, the PSO classification accuracy tended to decrease with increasing class number; it also did so with increasing problem size. These limitations were investigated in [7] where remedial mechanisms for high dimensional datasets were proposed.In [8–10], the authors developed a new PSO-based algorithm, called AMPSO, which can be used to find prototypes. Each particle in the swarm represents a single prototype in the solution space; the swarm evolves using modified PSO equations with both particle competition and cooperation. The experimentation part included an artificial problem and six common application problems from the UCI data sets. When comparing the obtained results to other classifiers (Nearest Neighbor or k-NN, and Linear Vector Quantization or LVQ), AMPSO produced competitive results in all the problems, particularly those where a 1-NN classifier did not perform well. In particular, AMPSO significantly outperformed the other algorithms on the Glass Identification data set, with more than 10% improvement in accuracy on average.The authors in [11] applied PSO to inventory classification and developed a flexible classification algorithm that can be utilized as a single objective algorithm for cost minimization, demand correlation maximization, or inventory turnover ratio maximization. It can also operate as a multi-objective algorithm that takes into account multiple measures at the same time. The algorithm can determine the best number of classification groups. Numerical studies were conducted, and the classification performance of the PSO algorithm was comparable to other approaches.In [12], the authors used the problem of handwritten Arabic numerals recognition to compare PSO with the Bees Algorithm (BA), Artificial Bees Colony Optimization (ABC), a multilayer perceptron neural network (MLP) and a Hybrid MLP-BA algorithm. The comparative study on a variety of handwritten digits showed the classification performance of PSO to be better than that of ABC and MLP and worse than that of BA and MLP-BA, with the best results obtained with MLP-BA.This section gives a recap of continuous PSO in Section 3.1 before focusing on discrete PSO in Section 3.2.The roots of PSO lie in ethological metaphors for computing models [14–16]. For example, the coordinated search that lets a flock of birds spot a promising food location can be modeled with simple rules for information sharing between individuals. Such behavior inspired Kennedy and Eberhart (see [14,17]) to develop PSO as a method for function optimization. In essence, the PSO algorithm maintains a population of particles (the swarm), where each particle is defined by its location in a multidimensional search space (the problem space) and represents a potential solution to the optimization problem at hand. The particles start at random locations and move through the search space looking for the minimum (or maximum) of a given objective function. In the bird analogy, this function would be a measure of the quality or quantity of food at each place, and the particle swarm would search for the place with the best and/or most abundant food supply. The movements of a particle depend only on its velocity and the memory of locations where good solutions have already been found by the particle itself or by other (neighboring) particles in the swarm. This is again in analogy to bird flocking where every individual makes its decisions based on cognitive aspects (good solutions found by the particle itself) and social aspects (good solutions found by other particles). It should be noted that, unlike many deterministic methods for continuous function optimization, PSO uses no gradient information to find solutions.22As a result, there is no continuous error function requirement for computing a derivative.When the neighborhood of a particle is the entire swarm, the best neighborhood position is called the global best, and the resulting algorithm is referred to as gbest PSO; when smaller (local) neighborhoods are used, the algorithm is usually referred to as lbest PSO. The performance of each particle (i.e. how close the particle is to the target) is measured by a cost function whose form depends on the optimization problem.More formally, a PSO algorithm is based on a swarm of M individuals or particles, each representing a potential solution to a problem with N dimensions. Its genotype consists of 2N parameters, the first half representing the coordinates of a particle in the N-dimensional problem space and the second half the corresponding velocity components. A particle moves with an adaptable velocity within the search space and retains in memory the best position it ever reached. The parameters are changed when going from one iteration to the next as follows: For dimension d, the velocityvi,d(t+1) of particle i at time t+1 is a linear combination of its velocityvi,d(t) at time t, of the differencebi,d(t)−xi,d(t) between the position of the best solution found by the particle up to time t and its current position, and of the differencebg,d(t)−xi,d(t) between the best position ever found by the total population and the particle's current position. We have:(1)vi,d(t+1)=w⋅vi,d(t)+c1⋅u(0,1)⊗(bi,d(t)−xi,d(t))+c2⋅u(0,1)⊗(bg,d(t)−xi,d(t))where ⊗ denotes point-wise vector multiplication, u(0,1) is a function that returns a vector whose positions are randomly generated by a uniform distribution in [0,1], c1 is the cognitive parameter, c2 is the social parameter, and w is an inertia factor with values between 0 and 1. The velocity values are within a range defined by two parameters viand vmax.An improvement to the original PSO algorithm was to vary the value of w during execution: starting from a maximal value wmax, it is linearly decremented toward a minimal value wmin as the number of iterations increases:(2)w(t)=wmax−(wmax−wmin)⋅tTmaxIn the previous equation, t and Tmax denote the current iteration and the maximum allowed number of iterations, respectively.The position for dimension d of each particle at the next step is computed by summing up its current position and its velocity (assuming a unit time step):(3)xi,d(t+1)=xi,d(t)+vi,d(t+1)Eqs. (1)–(3) are repeated for up to Tmax iterations, or until some predefined stopping criterion is verified. A typical convergence criterion is the achievement of a minimal error with respect to the optimal solution.As with other stigmergic collaboration algorithms, adequate parameter tuning is important for efficient PSO performance and much work has been done to select a combination of values that work well in a wide range of problems. For instance, Clerc in [23] gave some general directives to choose the good combination. He proposed to use the following:•Swarm size M in [20,40], with a preference for 20 particles.Cognitive parameter c1 in [0,1], with a preference for 0.7.Social parameter c2∼1.5with a preference for a value of 1.43.Maximal velocity component vmax∼(xmax−xmin)/2 where xmax and xmin are respectively the maximum and minimum values taken by a dimension in the search space. vmax is used only if c1>1 and may be different for each dimension.In [54], Engelbrecht explained that the choice of inertia factor in the case of linear variation33The choice of the inertia factor in the static case must be done in conjunction with selecting the values for c1 and c2. Engelbrecht [54] reported a value of: w>(c1+c2)/2−1.as depicted by Eq. (2) could take wmax=0.9 and wmin=0.4 as initial and final values.Tmax the number of iterations is generally chosen as 1000 iterations.Notice that different parameter values lead to better or worse outcomes depending on the problem at hand; the best way to tuning is to make a sensitivity analysis in the context of the problem description.The PSO algorithm is summarized in the following pseudo code:Algorithm A1Standard gbest PSO algorithmMore sophisticated implementations of the algorithm modify the control mechanism for position updating and/or the population initialization. For instance, Liu et al. [18] propose a strategy to drive lazy particles (responsible for stagnation leading to premature convergence) and let them explore better solutions. If a particle's velocity decreases to a minimum threshold, a new velocity is assigned using a turbulence mechanism. The minimum velocity threshold of the particles is tuned adaptively by using a fuzzy logic controller. Coelho and Mariani [19] present a hybrid method where the PSO component uses chaotic sequences generated by a Henon map. The application of chaotic sequences instead of random sequences in PSO is a powerful strategy to diversify the population of particles and improve PSO performance by preventing premature convergence to local minima. More yet, many authors combine PSO and simulated annealing (SA) so that PSO finds a global best solution that is then refined by a local search with SA, or where SA helps to escape from local minima (see [20–22] for typical examples of use)In this work, we are interested in two mechanisms that proved their efficiency in previous work [7]: confinement and wind dispersion. The confinement mechanism acts by limiting position changes to an interval [23]. It consists of bounding the position components of a particle in such a way that, for the dth component in the N-dimensional position space, we have:(3a)xi,d(t+1)=MIN(MAX(xi,d(t)+vi,d(t+1),xmin),xmax)with xmin=0 and xmax=1.The second mechanism, described in [24] as a chaotic search process, is wind dispersion. Wind speed and direction effects are introduced in order to model the search space “biological atmosphere” at the time of updating particle positions. The update of the wind speed is given by the following equation:(4)vw(t+1)=vw(t)+vop⋅rand()+vsu⋅rand()wherevwis the wind velocity, vopis the opposing direction factor equal to −1 and vsuis the supporting direction factor equal to 1, andrandis a random vector generator in [0,1]. The wind speed has one of two effects: a particle's motion can be opposed or supported by it. The opposing effect (wind in opposite direction of particle movement) slows down the particle in reaching the group's global best, whereas the supporting effect (wind in the same direction of particle movement) increases the particle velocity in reaching it. Each particle is separately updated by the wind equation. This is supported by the fact that particles are spatially separated from each other, and thus are subject to different dynamic forces from the atmosphere. When the values of the opposing and supporting wind velocities are equal, a static atmosphere is modeled. The position update equation for the dth dimension in the N-dimensional position space is given by:(3b)xi,d(t+1)=xi,d(t)+vi,d(t+1)+vwd(t+1)When combining this equation with confinement, we get:(3c)xi,d(t+1)=MIN(MAX(xi,d(t)+vi,d(t+1)+vwd(t+1),xmin),xmax)The initial values of wind speed and wind direction play an important role in determining the final convergence of the particles to the optimal solution.Several methods have been adopted to adapt the PSO method to discrete problems, where it is not possible to continuously “fly” particles:A modification of the PSO algorithm for solving problems with binary-valued solution elements was developed by its creators in [25]. The equation for the modified algorithm is:(5)xi,j=1ifrand()<S(vi,j)S(Vij)=11+exp(−Vij)0otherwisewhere vi,jstays as in Eq. (1) for the jth component, S(vi,j) is the sigmoid function, and Eq. (5) replaces Eq. (3). Since particles cannot fly continuously through a discrete-valued space, the significance of the velocity variable was changed to indicate the probability of the corresponding solution element assuming a value of 0 or 1. The velocity is updated in much the same way as in standard PSO, though no inertia coefficient is used here. For assigning a new particle value, the velocity term is mapped into the range (0, 1), and the particle element is randomly set with the probability of picking 1 given by S(vi,j). This prevents the probability of the particle element assuming a value of 0 or 1 from being too high.This discrete-value modification of PSO, henceforth referred to as DPSO, was shown to optimize various discrete-valued problems, but it only applies to problems with binary valued solution elements. Different variants of the DPSO approach have been proposed. For instance, Al-Kazemi and Mohan [26] used a technique where particles are alternatively influenced by their own best position and the best position among their neighbors. In this DPSO strategy, the velocity is updated as in the standard PSO, but the coefficients ciassume only the values 1 and −1, and only a given number of coefficient combinations is possible. The different coefficient combinations are referred to as phases of the particles and they determine their directions of movement. At any given time, each particle is in one of the possible phases, with the next one determined by the current phase and the number of iterations executed so far. The smallest possible non-trivial number of phases used in the DPSO method by [26] consists of two phases. In the first phase, each ith particle uses coefficients (1, −1, 1) by directing the particle movement toward gi, i.e. the best position of its social neighborhood N(i). Instead, in the second phase, each ith particle uses coefficients (1, 1, −1) by directing the particle movement toward its own best position bi. A phase change occurs if no improvement of the best solution to date is obtained within a given number of iterations in the current phase.In [27], the authors developed a DPSO algorithm that considers a larger number of combinations of the coefficients, referred to as quantum states of the particles, and a slightly different update equation for the velocity inspired by the principles of quantum computing. In quantum theory, a bit is the minimum unit carrying information and is always in a state within the range [0,1]. A quantum particle vector is defined as follows:V=[V1,V2,…,VM], whereVi=[v1i, v2i,…, vNi] with 0≤vij≤1 and i=1, 2, …, M, j=1, 2, …, N, M being the swarm size, N the particle length, and vijdenotes the probability of the jth bit of the ith particle being 0. The rule to convert a quantum particle vector to a discrete particle vector is as follows: Assume thatX=[X1,X2,…,XM], whereXi=[x1i, x2i,…,xNi], is the particle denotation for the practical problem. For each vij, generate a random number in the range [0,1]. If the random number is greater than vijthen xij=1 otherwise xij=0. Then, the DPSO algorithm can be described by:(6a)Vlocalbest=α⋅xlocalbest+β⋅(1−xlocalbest)(6b)Vglobalbest=α⋅xglobalbest+β⋅(1−xglobalbest)(6c)V=w⋅V+c1⋅Vlocalbest+c2⋅Vglobalbestwhere α+β=1, 0<α, β<1 are control parameters that indicate the control degree ofV, w+c1+c2=1, 0<w, c1, c2<1. In (6c), the first part represents the inertia of the previous probability, the second part is the “cognition” part which represents the local exploration probability; the third part is the “social” part which represents the cooperation among all quantum particles. So w, c1 and c2 represent the degree of belief in oneself, local exploration and global exploration, respectively. Both methods developed in [26,27] use the same principles as the original DPSO [25] and both are limited to discrete problems with binary-valued variables.Pampara et al. [28] developed an indirect DPSO method by reducing a binary problem to a continuous trigonometric function with only four parameters to optimize, which allowed faster optimization of several problems. This reduction is obtained by means of angle modulation, a popular technique used in signal processing and telecommunications. The standard PSO algorithm [17] is then applied to optimize the four parameters of the continuous trigonometric function. The function is successively sampled at even intervals to produce a continuous value for each interval. If the value is positive, the bit value assigned to the corresponding interval assumes value 1, otherwise the corresponding bit value assumes value 0. The set of all generated bit values associated with the intervals represents the binary solution vector to the original binary problem. The benefit of this technique is that a larger dimensional binary space can be represented by a smaller 4-dimensional continuous space, thus allowing faster convergence of the optimization phase with respect to the other binary PSO methods in the literature. Still, the technique was only applied to binary problems.This method rounds off the continuous particle values to the nearest integer to generate the discrete solution (see [29]). However, the method suffers from slow convergence, as small velocity values (<0.5) are rounded off to 0. Therefore, if the velocity term is too low, the particle will not move during the corresponding iteration. Considering that complex optimization problems require thousands of iterations to complete, the occurrence of small velocity values will significantly slow down the optimization process. The authors in [30] propose to modify the PSO algorithm so that particle positions generate a continuous-valued solution. To convert the continuous-valued positions into discrete form, they propose to use the following equation (originally used to confine neural network datasets within a predefined range):(7)y=round(ymax−ymin)(r−rmin)rmax−rmin+yminwhere y is the discrete-valued particle position, ymin and ymax are the lowest and highest values of the discrete-valued position, and rmin and rmax are the lowest and highest values of the original continuous-valued solution.To use this equation, the continuous-valued solution should be in the range [rmin, rmax], and the desired discrete valued solution should be defined in the range [ymin, ymax]. Thus, optimization is performed with continuous values, but discrete values are used to solve the discrete-form fitness function. After optimization, the optimal continuous-valued solution can be converted back to a discrete value using Eq. (7).Multi-valued PSO (MVPSO) [31] considers variables with multiple discrete values. While the position of each particle is a mono-dimensional array in continuous PSO, and a 2-dimensional array in the case of DPSO, in MVPSO, it is expressed by means of a 3-dimensional arrayxijk, representing the probability that the ith particle in the jth iteration assumes the kth value. To evaluate the fitness of a particle, the solution elementsxijkare probabilistically generated following a sigmoid distribution, thus making the evaluation process inherently stochastic. Because the particle terms are real-valued, this representation allows velocity to be used in the same way as in standard PSO [17], wherevijkrepresents the velocity ofxijk. Therefore, it is still possible to update the velocity vijkby means of the classical equation.JPSO is a new DPSO proposed in [32], and extended in [33]. The approach does not consider any velocity since, from the lack of continuity of movement in a discrete space, the notion of velocity has less meaning; however, the attraction by the best positions is kept. JPSO considers a swarm S of M particles whose positionsxievolve in the solution space, jumping from one solution to another. For each iteration, each particle has a random behavior or jumps to a solution in a manner guided by the effect of an attractor. The algorithm considers three attractors for the movement of a particle i: its own best position to date (bi), the best position of its social neighborhood (gi) interpreted as the best position obtained within the swarm in the current iteration, and the best position to date obtained by all the particles, which is called the global best position (g*). A jump approaching an attractor consists of changing a feature of the current solution by a feature of the attractor. Each particle is further allowed to have a random behavior by performing random jumps. A random jump consists of randomly selecting a feature of the solution and changing its value. An inspiration from nature for this process is found in frogs jumping from a lily pad to another in a pool, hence the name jumping particle swarm optimization. The authors show that JPSO is able to obtain good approximate solutions for large-size datasets.Before presenting our algorithm, we make a recall on particle swarm optimization applied to classification tasks. We end the section by a computational cost study.Supervised classification learning addresses the general problem of finding a plausible C-partition of classes for an input space, given a C-partition of a set of training examples. As PSO is essentially an optimization tool, the problem of retrieving the C classes is expressed in terms of retrieving C optimal particle positions corresponding to the different class centroids. The algorithm performs a traversal of the search space by testing particle fitness according to a similarity semantic44Hereafter, the semantic of dissimilarity, as expressed by a distance, will be expressed with the term ‘cost’ instead of ‘fitness’ to follow the accepted practice for optimization problems.; particles maximizing this fitness will be retained as centroids.The typical PSO approach55We only consider the supervised learning approach, but the same model applies to the unsupervised approach; only the decision step is different.to classification is a variation of basic PSO and follows the steps described in [2,3]. It can be summarized as follows: Given a dataset representing C classes with N attributes, find C real-valued coordinates in N-dimensional space such that each one represents a class centroid. The idea is to start with a swarm of M particles whose coordinates are different tentative solutions to the problem, and iteratively refine the positions during a training stage to find the best centroid to represent each class. In a subsequent validation stage, the found centroids are evaluated with respect to actual class instances in a test set to establish the recognition accuracy (or, equivalently, the percentage of classification errors). Next is a formal description of the procedure:Given a swarm of M particles and C class centroids to find in N-dimensional search space, the ith individual in the swarm at time t is encoded by the tuple:(8)(xi1,…,xiC,vi1,…,viC)twherexjiis the coordinate vector of the jth centroid as given by the current position of the ith particle:(9)xij={xi1j,…xiNj}Similarly, the current velocity vector of the ith particle with respect to the jth centroid is also made of N components:(10)vij={vi1j,…,viNj}Thus, any individual in the swarm is represented by a real-valued vector of 2·C·N dimensions given by Eq. (8), and each of its first C vector components defines one class centroid as found by the particle (Eq. (9)).The cost at time t of the ith individual in the swarm with respect to the centroid of a class c is defined as the average Euclidian distance given by:(11)ψic(t)=1DTrain∑k=1DTraind(ykc,xic(t))whereykcis the kth exemplar of class c in the training set of size DTrain andxic(t) is the current position of the centroid of class c as determined by particle i,66This position is refined during the learning stage (using the training dataset) to become the centroid used during the decision stage (using either a test dataset or new data).both vectors being N-dimensional.When computing the distance, each component in the N-dimensional space is divided by its maximal range, and the sum of distance components is divided by N. With this choice, any distance will be in the interval [0.0, 1.0] and so will the cost function.Given the cost function defined by Eq. (11), finding the class centroids is a typical minimization problem. During the training stage, the smaller this cost is, the more representative the centroid pointed to by the corresponding component in the particle's position is. At each iteration, the best centroid for each class is taken as the one pointed to by the particle with the lowest-cost function for that class. The process is repeated and the centroid positions updated until the end of the training stage, when all the training data have been processed. Then, the best found values for the C centroids are kept to be used for recall.At the end of training, a testing set that is different from the training set is used to determine the classification accuracy of the algorithm. The values of particle positions stored as centroids are reused to be compared to the test patterns. The comparison is based on metrics like Euclidian distance between the corresponding vectors, heuristics like the similarity heuristic of Table 2 (more exactly dissimilarity, defined as 1 – similarity) or a combination of both in the case of mixed-attribute data. The performance of a run is computed as the percentage of instances of the testing set that are incorrectly classified by the best individual (in terms of cost). Notice that the decision procedure is based on an error tolerance threshold cognitively associated to the field. The threshold is the value under which the computed cost is considered satisfactory for recognition. Thus, it is the amount of error accepted in the recognition stage. In this work, we used values in the range of [0.003, 0.027] depending on the processed data and within the limitations of the 5% tolerance usually accepted in statistics.Since most studies were concerned with continuous or discrete PSO problems, a question remains: how would PSO handle nominal data? Classification tasks that involve nominal attributes (defined here as attributes that take a finite number of non-numeric values, either categorical or symbolic) form an important category of classification tasks. Moreover, when dealing with real problem solving, the data description could consist of a mixture of numerical (continuous or discrete) and categorical attributes. To which extent is PSO able to perform a classification task in such situations? In [13], the authors presented a survey of the most important nature-inspired methods used in classification and optimization tasks in relation to their continuous and discrete properties and discrete and continuous data. Amongst multiple examples of nature-inspired methods, PSO was inspected in terms of data, problem domains and inner structure and principles. The conclusion was that two sorts of approaches exist. The first one modifies the regular continuous PSO algorithm for operation in binary or discrete domains; it comprises binary PSO or discrete PSO with crisp representation. The second approach goes the other way and proposes a continuous representation of the discrete problem for use with the classical (or modified) continuous PSO algorithm. This work provides a third solution that is uniformly applicable to classification tasks with nominal, continuous and discrete input data. The main idea is to start from a continuous PSO algorithm and add mechanisms to allow the interpretation of particle positions in the right way.Two spaces are considered: a search space in which particles evolve with continuous coordinates as in standard PSO and a description space reflecting reality, where the input vectors are expressed with continuous, numerical discrete or nominal components (see Fig. 1). It follows that while a particle evolves along continuous axes in the particle space, its positions are interpreted in terms of descriptors (attributes) of miscellaneous natures in the description space. A semantic mapping between the two spaces allows moving from one to the other. It is ensured by a set of interpretation mechanisms that allow the continuous values in the first space to have corresponding continuous, discrete or nominal values in the second. Essentially, one of the following measures is called upon between the search and description spaces:•Identity or affine transformation for continuous attributes. As a result, the continuous particle coordinates map to continuous equivalents in the description space as done in standard PSO.Rounding for integer attributes as often done in discrete PSO. This method rounds off the continuous particle coordinates to the nearest integer to generate the discrete solution in description space (see Section 3.2.2).Frequency substitution for nominal attributes. The corresponding particle coordinates in the search space are interpreted as the attribute frequencies in the description space. A frequency table is built first to implement the mapping. It is populated by parsing the input database to compute the frequency of each attribute value (see Table 1for an example). During learning stage, the table is used to interpret the continuous-valued particle positions in the search space as frequencies related to corresponding categorical entries in the table, with the highest frequency assigned to the most likely nominal value and so on. Table 1 is an extract describing two descriptors from the description space but we have one frequency sub-table for each descriptor. To make the mapping from search space (particle position) to description space (descriptor) we need two entries:•The name of the descriptor (‘race’, ‘sex’…) to determine which sub-table we use.The particle position computed by the algorithm: a numerical value between 0 and 1 (normalized value).Thanks to the interpretation mechanisms, the PSO algorithm keeps functioning as a continuous model; only the interpretation of particle positions changes. The changes occur prior to evaluating the fitness function which still expresses the semantics of the description space. Velocity, position and inertia keep evolving in the continuous search space, and only the fitness function is evaluated with the interpreted values of the mixed attributes in the description space. So, the values ofykcandxicin Eq. (11) refer to attribute values in the description space, although their search space equivalents are used. In other terms, we search in ‘search space’ but compare in ‘description space’.For example, for a partial description based on the attributes ‘Race’ and ‘Sex’, the position (0.85, 0.67) will be interpreted by the couple (Race, Sex)=(‘White’, ‘Male’) as indicated by the frequency wheels depicted in Fig. 2a and b, themselves derived from Table 1.The frequency scope determines the value to choose. For instance, for a numerical value v:•0.0955<v≤0.8667, the interpretation gives the value ‘White’.0.0000<v≤0.0077, the interpretation gives the value ‘Other’.The new PSO algorithm is as follows, where asterisks indicate changes to the original PSO algorithm:Algorithm A2Enhanced gbest PSO algorithm for mixed attribute(*) Changes to the original algorithm.In Section 6 below, we report the learning time consumption of each algorithm that we surveyed when the information was available. The intent is to assess algorithm time consumption to perform comparisons between approaches. However, as this information is often fragmentary or missing, no definite conclusions can be drawn from it. A more robust way to conduct the comparisons is via complexity analysis. In this section, we analyze the computational complexity of our algorithm and position it among existing classification approaches such as continuous PSO, decision trees and neural networks.Given M the number of particles, N the problem space dimension, Tmax the number of iterations, Size the number of instances in the dataset, let us also define cost1 as the initialization cost, cost2 as the fitness computation cost (defined as N*size*cost5), cost3 as the update cost of the global best, cost4 as the updates cost for the current particle, cost5 as the elementary fitness cost and cost6 as the interpretation cost.77Basically, it is given by the cost of the identity operator in the case of a continuous attribute, the cost of the rounding operator in the case of a numerical discrete attribute and the cost of the frequency mapping in the case of a categorical attribute (with a complexity O(number of nominal values in the data set) in the worst case. The complexity could be sub-linear to this number when using a dichotomic search for instance).We can then calculate the computational costs of Algorithm A1 used for continuous classification and Algorithm A2 used for mixed-attribute classification, respectively named CostA1 and CostA2, as:CostA1=M*cost1+Tmax*M*cost2+Tmax*M*cost3+Tmax*cost4=M*cost1+Tmax*M*N*size*cost5+Tmax*M*cost3+Tmax*cost4andCostA2=M*cost1+Tmax*M*cost6+Tmax*M*cost2+Tmax*M*cost3+Tmax*cost4=Mcost1+Tmax*M*cost6+Tmax*M*N*size*cost5+Tmax*M*cost3+Tmax*cost4It is easy to see from the previous two equations that both CostA1 and CostA2 are O(Tmax*M*N*Size) since the only difference between the two costs is the term Tmax*M*cost6 which is negligible in comparison to the previous term. We notice also that the factors on which the cost depends include Tmax and M, which are inherent to the algorithm, and N and Size, which are inherent to the problem. In addition, despite the fact that M≪Tmax and N≪Size, we cannot neglect M or N since they are multipliers of Tmax and Size, respectively. Consequently, a compromise must be made by tuning Tmax and M, since N and Size are out of control.The time complexity of the learning stage is higher than that of several approaches in the literature. For instance, we have the following for the complexity of decision trees and neural networks:Although, at the exploitation stage, the traversal of a decision tree is definitely less time consuming (sub-linear to Size, in general), when analyzing the complexity of ID3 tree building algorithm, we note that data with only nominal features or including real-valued features has a significant impact on the complexity of the algorithm [55]. Building a decision tree on a nominal dataset has complexity O(Size*D) and O(Size2*D) with continuous features,88Decision trees are more suitable for nominal data than continuous. Notice that, in this case, the time complexity is quadratic on size, so it is worse than that of PSO.D being the depth of the generated tree. The time complexity of the standard decision-tree learning algorithm C4.5 is O(Size*D2). Notice that here also the time complexity of C4.5 is higher than O(Size*D2) in the presence of numerical attributes (see [56]).Finally, the complexity analysis of a neural network is O(E3), E being the number of neurons [57].

@&#CONCLUSIONS@&#
