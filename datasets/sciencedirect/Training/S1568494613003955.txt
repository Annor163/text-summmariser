@&#MAIN-TITLE@&#
Hybrid sliding level Taguchi-based particle swarm optimization for flowshop scheduling problems

@&#HIGHLIGHTS@&#
This study is concerned with a multi-objective flowshop scheduling problem.A hybrid sliding level Taguchi-based PSO (HSLTPSO) algorithm is proposed for FSP.As a result, it exhibits a significant improvement in Pareto optimal solutions of FSP.HSLTPSO is an effective means in solving a multi-objective flowshop scheduling problem.

@&#KEYPHRASES@&#
Flowshop scheduling problem,Sliding level Taguchi-based particle swarm optimization,Taguchi-based crossover,

@&#ABSTRACT@&#
A hybrid sliding level Taguchi-based particle swarm optimization (HSLTPSO) algorithm is proposed for solving multi-objective flowshop scheduling problems (FSPs). The proposed HSLTPSO integrates particle swarm optimization, sliding level Taguchi-based crossover, and elitist preservation strategy. The novel contribution of the proposed HSLTPSO is the use of a PSO to explore the optimal feasible region in macro-space, the use of a systematic reasoning mechanism of the sliding level Taguchi-based crossover to exploit the better solution in micro-space, and the use of the elitist preservation strategy to retain the best particles of multi-objective population for next iteration. The sliding level Taguchi-based crossover is embedded in the PSO to find the best solutions and consequently enhance the PSO. Using the systematic reasoning way of the Taguchi-based crossover with considering the influence of tuning factors α, β and γ is presented in this study to solve the conflicting problem of non-feasible solutions and to find the better particles. As a result, it exhibits a significant improvement in Pareto best solutions of the FSP. By combining the advantages of exploration and exploitation, from the computational experiments of the six test problems, the HSLTPSO provides better results compared to the existing methods reported in the literature when solving multi-objective FSPs. Therefore, the HSLTPSO is an effective approach in solving multi-objective FSPs.

@&#INTRODUCTION@&#
In the current era of global industrialization, resource scarcity is becoming a critical problem. Therefore, efficient production scheduling is essential for optimizing the use of available resources and also for satisfying performance measurement criteria. Multi-objective flowshop scheduling is among the most common flowshop scheduling problems (FSPs). Generally, the selections of performance measurement criteria are completion time and tardiness problem. An efficient production scheduling can increase machine availability to promote the profit and competitiveness of the company. The widespread adoption of just-in-time manufacturing, in which jobs are processed only as needed, has expanded the role of tardy production in process planning. The tardiness problems affect the delay in delivery of the next scheduling. It must not only compensate for the customer due to the delay in delivery but also cause the company reputation and image to suffer losses, therefore, reduces market competitiveness. To improve completion time and to minimize the tardiness problem, effective solutions for the FSP are needed to minimize both makespan and maximum tardiness. The FSP refers to the problem of dealing with n jobs on m machines or work centers in a facility in which all jobs are processed on all machines in the same sequence. The scheduling procedure known as the Johnson rule is used to solve the two-machine problem [1]. Problems involving more than two machines or jobs are called NP-complete or NP-hard problems [2].Although genetic algorithms (GAs) have proven effective for solving single-objective optimization problems [3–5], obtaining effective solutions for real world problems often requires simultaneous consideration of multi-objective functions. Another frequently encountered practical problem is that a perfect multi-objective solution that simultaneously optimizes each objective function is virtually precluded by conflicts in the considered objectives. Therefore, when solving multi-objective problems, the ultimate goal is finding the best solution set, i.e., the Pareto best solutions. After considering tradeoffs, the decision maker can then choose the preferred solution. Multi-objective FSPs involving application of meta-heuristics generally require GAs and particle swarm optimization (PSO) to solve NP-hard problems effectively. Many improved GA methods [6–22] have been proposed to solve multi-objective FSPs. The PSO approach [34,35] has proven effective for solving both continuous and discrete optimization problems. However, the PSO literature reviews [23–33] show very few studies on solving the multi-objective FSPs. The detailed reviews about the GA and PSO to solve multi-objective FSPs are described in Section 2.Further improvement in solution performance is needed, although the algorithms reported in [8,11,18,21,31,33] have shown good potential. Therefore, the motivation of this study is to improve the above methods by constructing a novel algorithm for finding Pareto best solutions. The Taguchi method is a robust-design approach in nature. It borrows from statistical experimental design concepts in evaluating and implementing improvements for products, processes or systems of equipment. The Taguchi method has successfully used in GA about optimization design and job shop scheduling problems [45,50–52]. In developing an improved PSO algorithm, one is naturally compelled to ask if the Taguchi method can be incorporated to efficiently generate optimal offspring. Motivated by such curiosity, a hybrid sliding level Taguchi-based particle swarm optimization (HSLTPSO) algorithm is proposed to attempt to improve search performance with two features. Because the performance of PSO with non-linear time varying evolution (PSO-NTVE) approach depends on the choice of tuning factors α, β and γ, the first feature is to use a systematic reasoning way with considering the influence of tuning factors α, β and γ in the Taguchi-based crossover operation to avoid the scheduling conflicting problem and to find an optimal solution instead of a crossover operation based on a random process [8,11]. Two major tools used in the systematic reasoning way are (1) the signal-to-noise ratio (SNR) which measures quality and (2) the orthogonal array (OA) which are used to studying multiple parameters simultaneously. The second feature is to use an easy way to generate the Pareto best solutions found so far so that the best offspring (solutions) can be retained. For simplicity, two levels are set asα,β,γ∈{0.5,1.5}. Therefore, the two-level OA is adopted to perform the experiments. The first three columns of OA are used for the sliding level factors of α, β, and γ. A particle can generate a new particle through PSO process based on OA. The following n columns are used to allocate the n jobs and perform Taguchi-based crossover operation. Therefore, sliding level Taguchi-based PSO (SLTPSO) combines the sliding level PSO with Taguchi-based crossover method. The particle and the generated new particle are selected for the levels 1 and 2 on the Taguchi-based crossover operation. The tuning factors in the sliding level PSO and job factors for Taguchi-based crossover operation are related. Factors are called related when the desirable experimental region of some factors depends on the level settings of other factors. Because of the use of Taguchi-based crossover operation and PSO, the algorithm is robust and achieves quick convergence. Therefore, this study proposes a novel HSLTPSO approach for finding the global optimal solution (GOS) for multi-objective FSPs in which the objectives are to minimize both makespan and maximum tardiness. The proposed HSLTPSO algorithm was compared with the MOGLS algorithm reported by Ishibuchi and Murada [8], with the modified MOGLS algorithm reported by Ishibuchi et al. [11], with the MOGLS algorithm reported by Arroyo and Armentano [21] and with the hybrid Taguchi-based genetic algorithm (HTGA) reported by Yang et al. [18]. The algorithm was then compared with the MOPSO algorithm developed by Li et al. [31] and with the hybrid Taguchi-based Particle swarm optimization (HTPSO) algorithm reported by Yang et al. [33]. The comparison results consistently showed that the HSLTPSO algorithm outperforms all the six algorithms.The rest of this paper is organized as follows. The literature reviews are shown in Section 2. Section 3 introduces the FSP with two objective functions. Section 4 introduces the PSO. Section 5 explains the proposed HSLTPSO for solving the FSPs. Numerical examples are given to illustrate the proposed method in Section 6. Finally, discussions and conclusions are given in Sections 7 and 8, respectively.A review of the GA literature [6–22] shows that the algorithms proposed by Ishibuchi and Murata [8] and by Ishibuchi et al. [11] for solving the FSP are structurally complete. In the multi-objective genetic local search (MOGLS) algorithm reported in [8] and its modification (modified MOGLS) reported in [11], a randomly selected weight value was used to evaluate the fitness function. Although its modification reported in [11] has shown good potential for achieving the ideal outcome by selecting only good offspring as initial solutions for local search, further improvement in solution performance is needed. In [6], a multi-phase approach for minimizing makespan and total weighted tardiness in the hybrid flexible flowshop problem considering sequence-dependent setup times is presented. Three phases are used in this algorithm. First phase uses a simple GA to minimize the combination of objective function. The other two phases are used to improve the solutions of previous phase. Pareto archive concepts had been implemented and the parameters of the proposed algorithm were calibrated by design of experiment method. In [7], a genetic algorithm was hybridized with a novel scheme for combining two local search methods: insertion search and insertion search with cut and repair. Ishibuchi and Murata [9] proposed another algorithm that applied a local search procedure to each solution generated by genetic operation. In [10], a number of individuals are randomly select from current population for each time. Two individuals are selected from the number of individuals for comparison. The individual with better fitness function is selected. It is a good individual. Repeat the procedure until the good individuals is equal to current population. The selected good individuals are used for local search. In order to allocate the available computing time between genetic search and local search, this study struck a balance between genetic and local searches. In [12], an algorithm was reported for selecting individuals for a crossover operation based on a weighted sum of multi-objective functions with variable weights. The proposed preservation strategy considered multiple elite solutions instead of a single elite solution. In [13], the procedure for selecting individuals for a crossover operation was based on a weighted sum of multi-objective functions. For a two-stage bi-criterion FSP, Neppalli et al. [14] considered the objective of minimizing total flow time subject to the optimal makespan. Two GA-based approaches, a vector evaluation approach and a weighted criteria approach, were proposed. In [15], a quantum-inspired GA based on Q-bit representation was applied for exploration. The permutation-based GA was used not only for exploration in permutation-based scheduling space, but also for stressing exploitation to achieve good scheduling solutions. In [16], a solution was presented for a re-entrant hybrid FSP with two objectives, maximizing the utilization rate in the bottleneck and minimizing the maximum completion time. The solution was achieved with a novel multi-objective genetic algorithm based on the Lorenz dominance relationship. The algorithm reported in [17] introduced a new hybrid controller using artificial intelligence to improve the dynamic performance of the self-excited induction generator (SEIG) driven by wind energy conversion scheme. The hybrid artificial intelligence compromises a GA and fuzzy logic controller. GA is used to optimize the parameters of the fuzzy set to ensure a better dynamic performance of the overall system. In the HTGA [18], the use of dynamic weights selected randomly by fuzzy inference system and the application of systematic reasoning way by Taguchi-based crossover operation achieved good search capability [47–49]. The HTGA was compared not only with the MOGLS algorithm reported by Ishibuchi and Murata [8], but also with the modified MOGLS algorithm developed by Ishibuchi et al. [11]. The comparison results show that HTGA is better than both the original MOGLS algorithm and the modified MOGLS algorithm. In [19], the decentralized multi-objective congestion management problem in the deregulated forward power market was modeled under the conflicting objectives of maximizing social welfare and minimizing emission impacts. A modified non-dominated sorting genetic algorithm II with controlled elitism and a dynamic crowding distance was applied. In [20], a static mixed integer non-linear model for distributed generation was defined and solved using a modified NSGA. The multi-objective functions for minimization were defined as the total active loss, investment and operational cost, and environmental pollution. Arroyo and Armentano [21] proposed another MOGLS for a multi-objective FSP and compared the performance of the algorithm with two multi-objective genetic local search algorithms, The first algorithm is MOGLS proposed by Ishibuchi and Murata in [8] (denoted by IM-MOGLS) and another algorithm was proposed by Jaszkiewicz in [22] (denoted by J-MOGLS) for solving a 50-job, 20-machine FSP with objectives of makespan and maximum tardiness. Fig. 8 reported in [21] shows the running results achieved by the same initial set for all algorithms. Their comprehensive performance comparison showed that the MOGLS [21] was superior to the IM-MOGLS and J-MOGLS.Like GA, the PSO [35] is initialized with a population of random solutions. However, one difference is that PSO assigns a randomized velocity to each solution. Each solution is represented by a particle flying through the solution space. Compared to GA, it requires less computation and fewer parameter adjustments. However, although the PSO is easily implemented and achieves quick convergence, it tends to get stuck in near-optimal solutions, which are difficult to improve by further fine tuning. A review of the PSO literature [23–33] shows very few studies of the multi-objective FSP. In [23], a discrete particle swarm optimization (DPSO) algorithm was proposed for solving the no-wait FSP with both makespan and total flow time criteria. Solution quality was improved by hybridizing the DPSO algorithm with the variable neighborhood descent algorithm. Wang and Tang [24] introduced a new velocity and particle update model to generate new population and proposed a self-adaptively diversity control strategy to avoid premature convergence for the discrete particle swarm optimization with blocking to minimize the makespan. A local search method named stochastic variable neighborhood search was used to improve the search ability. In [25], an improved particle swarm optimization algorithm based on the “all different” constraint is proposed to solve the FSP with the objective of minimizing makespan. It is because that the particle's current position and velocity are both denoted as permutations of all jobs which must satisfy the “all different” constraint. This constraint forces every decision variable in a given group to assume a value different from the value of every other variable in that group. This algorithm also combines PSO with genetic operators together effectively. Tasgetiren et al. [27,28] first used the smallest position value (SPV) to convert the position vector to a job permutation. Reported two-objective algorithms include an algorithm for minimizing both makespan and total flow time in [26,27], an algorithm for minimizing makespan and maximum lateness in [28], and an algorithm for minimizing mean completion time and mean tardiness in [30]. Li et al. [31] presented a multi-objective particle swarm optimization (MOPSO) for a multi-objective FSP. Based on ranked-order values, the continuous positions of particles were transformed into job permutations. To enhance exploitation, a local search based on the Nawaz-Enscore-Ham heuristic was applied to good solutions with a specified probability. Search performance was also enhanced by designing a simulated annealing with multiple different neighborhoods and by applying an adaptive Meta-Lamarchian learning strategy to decide which neighborhood is used. The MOPSO applied a random weighted linear sum function to aggregate a multi-objective solution into a single solution for evaluation purposes. They also compared MOPSO with MOGLS (denoted by IM-MOGLS in [31]) in terms of performance in solving a 20-job, 10-machine FSP with objectives of minimizing makespan and maximum tardiness. Fig. 5 in [31] compares the running results achieved by the two algorithms in one experiment. Their comprehensive performance comparison confirmed that the MOPSO [31] was superior to the IM-MOGLS. Yang et al. [33] proposed the HTPSO, which has also shown good search capability. The HTPSO outperformed the optimization methods presented by Ishibuchi and Murata [8], Ishibuchi et al. [11], Yang et al. [18], and Li et al. [31]. Proposed triple-objective algorithms include an algorithm for solving makespan, total flow time, and total machine idle time proposed in [29], an algorithm for solving makespan, average completion time, and maximum tardiness proposed in [31], and an algorithm for solving makespan, mean flow time, and machine idle time proposed in [32].The following discussion uses the symbolsn/m/P/Objto describe the FSP. Given n jobs to be processed on m machines in the same order, P indicates that only the permutation schedules are considered, and Obj denotes the objective functions in which the schedule is to be evaluated. The considered problem is finding the job schedule given the objectives of minimizing both makespan and maximum tardiness. Consider the example of a ten-job and five-machine FSP. The inputs of the problem are ten jobs, five machines, the processing time for each job on each machine, and the due date for each job. The output is to find the jobs schedule for the multi-objective FSP. The objectives are to minimize both the makespan and the maximum tardiness. The main constraint of the problem must be a permutation FSP. Other constraints are as follows:(1)All jobs are available at time zero.Physical buffer space between two successive machines is sufficient.Setup times for the operations are sequence-independent and are included in the processing times.All machines are continuously available.Individual operations are not preemptive.This study applies the weighted sum approach [8,11]. Because the feasible solutions are widely dispersed in the solution space, Ishibuchi et al. [8,11] argued that the fixed weight method may overlook some better solutions because it limits the number of search directions. Therefore, they proposed that dynamic weights find better feasible solutions by increasing the number of searching directions.The sequence of n jobs is denoted by n dimensional vectors(J1,J2,.....,Jn). The n jobs are processed on a series of machines(M1,M2,.....,Mm)in the same sequence where Jidenotes the ith processing job and Mjdenotes the jth machine. The processing time of job i on machine j ispi,j. The completion time of job i is defined asCi,m, i.e., the completion time of job i on the last machine m, where(3.1)C1,1=p1,1,C1,j=C1,j−1+p1,j,forj=2,....,m,Ci,1=Ci−1,1+pi,1,fori=2,....,n,Ci,j=max{Ci,j−1,Ci−1,j}+pi,j,fori=2,....,n,forj=2,....,m.The makespan of the sequence ofnjobs is defined asCmax=Cn,m, i.e., the maximum completion time of the last job n on the last machine m.The tardiness Tiof job i is defined as(3.2)Ti=max{(Ci,m−Di),0},fori=1,2,....,n,andDiistheduedateofjobi.The maximum tardinessTmaxof the schedule is defined as(3.3)Tmax=maxT1,T2,....,TnIn this study, the proposed HSLTPSO searches for all non-dominated solutions for the multi-objective optimization problem. Consider the following multi-objective optimization problem with n objectives:(3.4)Minimizef1(x),f2(x),......,fn(x)wheref1(x),f2(x),......,fn(x)are n objectives to be minimized. When the following inequalities hold true between two solutions x and y, solution y is said to dominate solution x.(3.5)∀i:fi(y)≤fi(x)and∃j:fj(y)<fj(x)A solution that is not dominated by any other solutions for the multi-objective optimization problem is a Pareto optimal solution [31].Particle swarm optimization, which was introduced by Eberhart and Kennedy in 1995 [34,35], is an evolutionary optimization technique based on metaphors for social interaction and communication such as flocks of birds and schools of fish. This stochastic, population-based approach has proven effective for solving both continuous and discrete optimization problems. Each particle in a swarm, which is analogous to a bird in a flock or a fish in a school, moves around in d dimensional search space. Based on its own experience and that of the swarm, it moves toward the best position in the search space.The position and velocity of particle i at iteration t are represented byXitandVit, which can be defined asXit=(xi1t,xi2t,.....,xidt)andVit=(vi1t,vi2t,......,vidt), respectively. At iteration t, the personal best (pbest) of particle i is represented byPit, which denotes the position of particle i with the best fitness value found so far and is defined asPit=(pi1t,pi2t,......,pidt). The global best (gbest) of all particles at iteration t is represented byPgt, which denotes the best position of the particle with the best fitness value in the swarm found so far and is defined asPgt=(pg1t,pg2t,......,pgdt). The new velocity and position of particleican be obtained by Eqs. (4.1) and (4.2), respectively:(4.1)vidt+1=vidt+c1*r1*(pidt−xidt)+c2*r2*(pgdt−xidt)wherevidtis velocity of particle i at iteration t with respect to the dth dimension.vidt+1is new velocity of particle i at iteration t+1 with respect to the dth dimension. c1 and c2 are acceleration coefficients. r1 and r2 are uniform random numbers between 0 and 1. t is current iteration.pidtis position value of the ith pbest at iteration t with respect to the dth dimension.pgdtis position value of the gbest at iteration t with respect to the dth dimension.(4.2)xidt+1=xidt+vidt+1wherexidtis position of particleiat iterationtwith respect to the dth dimension.xidt+1is position of particleiat iteration t+1 with respect to the dth dimension.The first part of Eq. (4.1) represents the current velocity, which provides the momentum needed for the particle to roam in the search space. The second part is the cognition component. The particle in the search space always moves toward its own best position found so far. The third part is the social component. Because of their cooperative relationship, the particles continuously move toward the current gbest.The easy implementation of PSO and its fast convergence to a reasonable solution make it an effective heuristic optimization technique. Although the original PSO performed well in early iterations, it tended to become trapped at the local best solution, and solutions could not be improved by fine tuning. To balance local and global search during the optimization process, Shi and Eberhart [36] modified Eq. (4.1) by introducing the concept of inertia weight ω.The new velocity is expressed by Eq. (4.3):(4.3)vidt+1=ωvidt+c1*r1*(pidt−xidt)+c2*r2*(pgdt−xidt)The inertia weight can be a positive constant or even a positive linear or nonlinear function of time. Whenω>1.2, the velocity item becomes the main item in the search direction of the particle. It extends the search area and finds the global optimum. When ω is between 0.8 and 1.2, three factors, velocity, pbest and gbest, affect the velocity calculation for both local and global search. When ω<0.8, only the pbest and gbest affect the new velocity calculation, which converges to the local optimum. Therefore, the value of inertia weight ω is a tradeoff between the global search and the local search.A literature review [34–42] showed that the NTVE method, proposed by Ko et al. [42], is currently the best tuning method. The inertia weight is the same as that in [41]. The inertia weight starts with a high value ωmax and nonlinearly decreases to ωmin at the maximal number of iterations. However,c1starts with a high valuec1maxand nonlinearly decreases toc1minwhereasc2starts with a low valuec2minand nonlinearly increases toc2max:(4.4)ω=ωmin+itermax−iteritermaxα×ωmax−ωmin(4.5)c1=c1min+itermax−iteritermaxβ×c1max−c1min(4.6)c2=c2max+itermax−iteritermaxγ×c2min−c2maxwhereIterdenotes the current number of iterations andItermaxdenotes the maximum number of iterations. The values α, β, and γ are constant coefficients. In early iterations of NTVE optimization, particles roam throughout the search space, and convergence accelerates toward the global optimum during latter iterations. Because of its proven effectiveness in obtaining the best solution, NTVE is applied in this study.In PSO-NTVE, five levels are set asα,β,γ∈{0,0.5,1,1.5,2}[42]. There are 53 combinations. An OAL25(56)is applied, as shown in Table 1. For simplicity, two levels for each factor are set asα,β,γ∈{0.5,1.5}. At first, the particle in the current population p generates eight different values of ω, c1, and c2. The relationship among ω, c1, and c2 with iterations (for example, itermax=3000) are shown in Fig. 1. Hence, α, β, and γ are used as the factors of sliding levels. A two-level OA is used to deal with the problem. First three columns of OA are used for factors α, β, and γ. The following n columns are used for the allocation of n jobs. For each particle of the current population, the SLTPSO executes the following steps.(1)For each experiment of OA, generate the new particle by using the factors of sliding level α, β, and γ.Firstly, execute sliding lever PSO to generate new velocity and new position. The new position is transformed to a permutation by SPV rule. A new particle Pnewis generated.Execute Taguchi-based crossoverSecondly, select the particle p as level 1 (P1) and new particle Pnewas level 2 (P2) to execute Taguchi-based crossover. A particle after Taguchi-based crossover is generated.Find the best particleFinally, after all experiments are finished, calculate the fitness of the particles after Taguchi-based crossover, the SNRs and effects of various factors (Efl) which are defined as the following steps. The best level is the one with best level value for each factor. An best particle is generated. The details regarding the Taguchi method can be found in [43,44].This section introduces the use of the proposed HSLTPSO for solving FSPs. Its objective is to minimize both makespan and maximum tardiness. The HSLTPSO combines SLTPSO with local search and an elitist preservation strategy. Fig. 2depicts the steps of the HSLTPSO approach, which are described in detail below. The parameters used in the algorithm are set as shown in Table 2.In FSP, a sequence of jobsS=(x1,x2,...,xn)represents the job processing sequence. That is, processing of job x1 is followed by processing of job x2, and so on.In PSO, each particle moves in the n dimensional search space at an assigned velocity. VectorXit=(xi1t,xi2t,......,xint), which represents the ith particle of iteration t, corresponds to n jobs of the FSP. Each dimension represents a job. However, since the particle is not a permutation, the SPV rule must be applied to transform it into a permutation [27,28], as shown in Table 3. The job permutations are found by sorting the dimensions in ascending order of the particle values in each dimension.The first step is randomly generating the initial population of particles with positive integers (1,2,…,n), where n is the number of jobs. The initial position and velocity of the ith particle in n dimensions of the search space are represented byXi0=(xi10,xi20,......,xid0)andVi0=(vi10,vi20,......,vid0), respectively.(1)Generate a set of Pareto best solutions.The steps of generating the set of Pareto best solutions are as follows:1.1Calculate the objective values of the makespan fob1(x) and the maximum tardiness fob2(x) of each particle of the initial population.Rearrange the population by sorting the value of fob1(x) in ascending order and then sorting the value of fob2(x) in descending order. If one value of fob1(x) has more than two values of fob2(x), select only the minimum value of fob2(x).Apply Eq. (3.5) to find the Pareto best solutions. If the inequalities hold true between two solutions x and y, the solution y is a Pareto best solution of the initial population wherefi(x)=fob1(x)andfj(x)=fob2(x).Evaluate the fitness function f(x) by the weighted sum approachThe fitness function is an index of the adaptability of the individual in the population. A high fitness function value indicates a high individual adaptability, a high chance of survival, and a high probability of the individual being inherited in the next iteration.A utility function or weighted function can be used to convert a multi-objective problem into a single-objective problem [15]. Therefore, for a solution x, a fitness function f(x) for the HTPSO algorithm is defined by the weighted sum of n objectives.(5.1)f(x)=w1f1(x)+w2f2(x)+.....+wnfn(x),wheref1(x),f2(x),…,fn(x), are the n objectives to be maximized and wherew1+w2+....wn=1. Therefore, the particles with high fitness values are inherited by the population in the next iteration, and new Pareto best solutions are generated.The purpose of this study is to minimize both makespan and maximum tardiness. The feasible solutions are widely dispersed in the solution space. Ishibuchi et al. [8,11] proposed the use of dynamic weights to find better feasible solutions by increasing the number of search directions. Because these two objectives should be minimized, a fitness function for solution x is defined by the weighted sum of two objectives.(5.2)f(x)=−w1fob1(x)−w2fob2(x),wherew1andw2are the dynamic weights of objective functions fob1(x) and fob2(x), respectively, andw1+w2=1.For each particle of the swarm in the initial state (t=0), set the pbest toPi0=Xi0. Find the particle i with the best fitness value among the entire swarm, and set the gbest of the swarm toPg0=Xi0.The SLTPSO first uses the particle of current population to perform sliding level PSO to generate a new particle. Both of the particle and the new particle are used for the two levels of Taguchi-based crossover operation. It generates a best particle by Taguchi method.The Taguchi method is a robust design approach that uses many statistical and experimental design concepts to evaluate and implement improvements in products, processes and equipment. The fundamental principle is improving product quality by minimizing the effects of the causes of variation without eliminating the causes. Two major tools used in the Taguchi method are (1) the SNR, which is used as a quality measure and (2) OAs, which are used for simultaneously studying multiple parameters.In an experiment involving k factors (variables) and q levels for each factor, qkcombinations generally cannot be tested if the k factors have many values. Therefore, the Taguchi method uses OA to minimize the number of experiments needed for comprehensive testing. A two-level OAα,β,γ∈(0.5,1.5)is used. After executing the Taguchi-based crossover for all experiments, SNR and the effects of various factors (Efl) are calculated. The best level is the one with the best effect value for each factor. The details of the Taguchi method can be found in [43,44].The SNR refers to the mean-square deviation in the objective function. In the case of smaller-the-better, SNR (η) is defined byη=−10log1k∑i=1kyi2, which is measured in decibels. Letyidenote the fitness function value obtained in the experiment, and leti=1,2…k, where k is the number of experiments. Since this case involves only one fitness function value, k is equal to 1. The effects of the various factors (variables) can be defined asEfl=sumofηlfor factor f at level l, where f denotes factor name and l is the level number.The main purpose of a matrix experiment is finding the best level for each factor. After the best levels for each factor are selected, the new best individual of the offspring is obtained by combining the best levels for each factor. In each experiment, the SLTPSO performs a novel Taguchi-based crossover operation and generates a new particle that is unaffected by the scheduling conflict problem. Therefore, the systematic reasoning capability of the Taguchi-based crossover enables consistent selection of better genes when generating representative individuals for new offspring. In short, by using Taguchi experimental design method to enhance the PSO algorithm, the Taguchi-based crossover approach enables robust global exploration.The SLTPSO is described in the following Steps 5 and 6.A suitable two-level OA, Lk+1(2k), is selected with k+1 experiments. The first three columns of the orthogonal array are used to represent the factors of sliding levels, α, β and γ. The following n columns allocate the n jobs.Tsai et al. [45,50,51] and Ho et al. [52] have successfully used Taguchi method in both GA and differential evolution about job shop scheduling problems and optimization design. In this study, Taguchi-based crossover used in the FSP is proposed to find the best or near optimal solutions of the particle after executing the experiments without the conflicting problem of non-feasible solutions. The steps of sliding level Taguchi implementation are described as follows:(1)For each experiment of OA, at first, using α, β, and γ as factors of sliding level, particle p generates the new velocity and the new position with Eqs. (4.3) and (4.2). The new position is transformed to a permutation, pnew, by SPV method. Then, the Taguchi-based crossover is executed.Select level 1 (P1)=p and level 2 (P2)=Pnewto execute Taguchi-based crossover.Generate an n job set randomlyU={1,2,3,....,n}SeparateUintoU1andU2. The job numbers inU1andU2correspond to factor levels 1 and 2 in the executed experiment, respectively, whereU1∪U2=UandU1∩U2=φ. According to the job numbers inU1andU2, sequentially select the new P1 and new P2 from P1 and P2, respectively.According to the executed experiment, a new particle after Taguchi-based crossover is generated.Repeat the above steps, until all the experiments are finished.After all the experiments are finished, calculate the fitness values and η of the experiments. In case of a smaller the better characteristic, the η is defined asη=−10log1k∑i=1kyi2, where yiis the fitness value of the experiment and k is equal to 1 in this study.Calculate the effectsEf1andEf2for various factors. IfEf1≧Ef2, level 1 is the best for factor f. Generate the best level for each factor whereEfl=sumofηlfor factor f at level l.A best particle is generated based on the best level of each factor.Repeat steps (1), (2), (3), (4) and (5) to find the best particle.For example, for a job numbern=10,(1)A suitable two-level OAL16(215), as shown in Table 4, is selected with 16 experiments and first thirteen columns are used for α, β, γ, and ten jobs. Let p=(9,4,3,7,5,6,2,10,8,1). If the experiment no. 3 ofL16(215)is executed, factor levels are (1 1 1 2 2 2 2 1 1 1 1 2 2). A new particle Pnewis generated Pnew=(10,2,5,9,3,4,7,1,6,8).Select level 1 (P1)=p and level 2 (P2)=Pnewto execute Taguchi-based crossover.P1=(9,4,3,7,5,6,2,10,8,1)P2=(10,2,5,9,3,4,7,1,6,8)Randomly generate a set of 10 jobsU=6,2,10,8,9,3,5,1,4,7SeparateUintoU1andU2. If the experiment no. 3 is executed, job levels are (2 2 2 2 1 1 1 1 2 2)Level 1: U1 has 4 jobs, selectU1=9,3,5,1Level 2: U2 has 6 jobs, selectU2=6,2,10,8,4,7Select new P1 and new P2.P1=(9,4,3,7,5,6,2,10,8,1)→new P1=(9,3,5,1)P2=(10,2,5,9,3,4,7,1,6,8)→new P2=(10,2,4,7,6,8)Experiment no. 3 is executed. According to the job levels (2 2 2 2 1 1 1 1 2 2), a new particleX=10,2,4,7,9,3,5,1,6,8is generated.The new particles for all experiment are shown in Table 5.Calculate the fitness values and η of the experiments as shown in Table 5.Calculate the level 1 effectEf1and level 2 effectEf2of the various factors and find the best level of each factor as shown in Table 5.A best particle based on the best level of each factor is generated in Table 5.Repeat steps (1), (2), (3), (4), and (5) to find a best particle as follows.(1)Let P=(9,4,3,7,5,6,2,10,8,1) to generate Pnew=(10,2,5,9,3,4,7,1,6,8), according to the best level of each factor.Let P1=P and P2=PnewP1=(9,4,3,7,5,6,2,10,8,1)P2=(10,2,5,9,3,4,7,1,6,8)Randomly generate a set of 10 jobsU=6,9,10,4,5,2,8,3,7,1SeparateUintoU1andU2. The best level (2,2,2,1,1,2,2,2,2,1) is executed.Level 1: U1 has 3 jobs, selectU1=4,5,1Level 2: U2 has 7 jobs, selectU2=6,9,10,2,8,3,7P1=(9,4,3,7,5,6,2,10,8,1)→new P1=(4,5,1)P2=(10,2,5,9,3,4,7,1,6,8)→new P2=(10,2,9,3,7,6,8)According to the best level (2,2,2,1,1,2,2,2,2,1), a best particle is generated, X=(10,2,9,4,5,3,7,6,8,1).The above steps are repeated until the particles of the population are finished. At last, a best particle swarm is generated.The population is diversified by using the new local search population, which consists of the population after the sliding level Taguchi implementation and three non-dominated solutions Neliterandomly selected from the previous set of Pareto best solutions. The purpose of the local search method is to improve the solutions obtained by the sliding level Taguchi implementation. Two operators used for the local search are the shift change operator and the swap change operator.Fig. 3shows the shift change operator, which functions as follows.(1)One particle is randomly selected from the new local search population.Two points are randomly selected along the sequence.A job at one position is removed and put into another position.The algorithm uses the swap change operator, as shown in Fig. 4, to change the jobs at positions i and j. For the swap change operator [46] of a particle consisting of n jobs, the number of full neighborhood solutions is n(n−1)/2. For example, when n=10, the number of neighborhood solutions that must be examined for a particle is 45, which is a small problem size. Although the full neighborhood solutions are used in this study, computing time may be overly long when the job number is high. Therefore, computing speed is increased by using a single adjacent pairwise interchange neighborhood composed of the following n−1 schedules for(J1,J2,J3,J4,.....,Jn−1,Jn):(J2,J1,J3,J4,.....,Jn−1,Jn),(J1,J3,J2,J4,.....,Jn−1,Jn),(J1,J2,J4,J3,.....,Jn−1,Jn),(J1,J2,J3,J4,.....,Jn,Jn−1).For example, when n=10, only nine adjacent pairwise interchange neighborhood solutions are considered.A new population is generated after local search. The elitist preservation strategy always retains the best particles of the new population in the next iteration. Therefore, the following procedure is used to select the best solutions after local search for the next iteration:(1)Calculate the values of the objective function for the population after local search.Calculate the fitness functions for the population after local search.Sort all particles in the population by fitness function value, and delete those with the lowest fitness function values; obtain a new population for the next iteration.The new population obtained by elitist preservation strategy is used as the population for the next iteration. The particle velocity can be found by(5.3)vidt+1=xidt+1−xidt,(1) Update pbestCompare the fitness value of the current particleXitwith that of the previous pbestPit−1, and update pbest asPit=Xitiff(Xit)≧f(Pit−1); otherwise,Pit=Pit−1.(2) Update gbestCompare the best fitness value for pbest in the populationfht=maxf(Pit)(i=1,2,3,...,q;h∈{i;i=1,2,3,...q})with the fitness value of the previous gbestPgt−1. Then, update the gbest asPgt=Xhtiffht≧f(Pgt−1); otherwise,Pgt=Pgt−1.Unlike the conventional approach, the best Pareto best solutions found so far are always retained in the next iteration, which enhances the solution performance of the proposed approach. The steps of updating the Pareto best solutions are described as follows:(1)Generate a population consisting of the new population for the next iteration and the set of Pareto best solutions for the last iteration.Use the population to update the set of Pareto best solutions.Use the number of iterations as the termination condition. If the current iteration is equal to the number of maximum iterations, then stop; otherwise, go to Step 6.The HSLTPSO gives decision makers the best solutions for the final Pareto front. The decision makers can then select any one of the solutions based on their preferences.This section evaluates the performance of the proposed HSLTPSO approach by comparing its optimization results with those obtained for the same cases by the MOGLS in [8], the modified MOGLS in [11], the MOGLS in [21], the HTGA in [18], the MOPSO in [31] and by HTPSO in [33]. Table 2 shows the HSLTPSO parameter settings. Various performance indices for measuring the quality of Pareto-optimal sets have been proposed to compare the performance of different multi-objective optimization algorithms [53–58]. The four performance indices are often used in terms of the coverage ratio of two sets, the distance-based distribution, the maximum spread, and hyperarea (or hypervolume used with dimension above two) ratio [59–64]. Therefore, they are used in the study for measuring the quality of Pareto-optimal sets and described below.Performance index of coverage ratio for measuring the quality of non-dominated sets obtained from different optimization algorithms was adopted in terms of the coverage ratio of two sets. In a minimization problem, Vectora→dominates vectorb→, notated asa→≻b→, if and only if ∀ i;fi(a→)≤fi(b→)and ∃ i;fi(a→)<fi(b→). When two non-dominated solution sets obtained by different optimizers are compared, the coverage ratio of two sets is shown below.(6.1)C(S1,S2)=|{s2∈S2;∃s1∈S1:s1≻s2}|/S2where C(S1, S2) is the value of ratio. The numerator, on the right-hand side of the equal sign, describes the number of the solutions S2 dominated by S1 and the denominator expresses the number of all solution S2. It is worth mentioning that C(S1, S2) does not have to be equal to 1−C(S2, S1)i. Thus, both C(S1, S2) and C(S2, S1) should be given. The larger the coverage ratio is, the better the performance is.Performance index for distribution can be calculated based on distance. The performance index of the distance-based distribution is spacing (SP). The smaller the SP is, the better the performance is.(6.2)SP(S)=1|S|−1∑i=1|S|(di−d¯)2,(6.3)di=minsk∈S∧sk≠si∑m=1M|fm(si)−fm(sk)|,whered¯is the average of di. It is worth noticing that the distance is computed by the sum of absolute differences along each axis. Only the shortest distance from each point is used without sorting. The distance is summed up from i=1 to |S|. M is the number of objectives.Performance index for measuring maximum spread of S is the distance (max_D) between the boundary solutions in S. The larger the max_D is, the better the performance is.(6.4)D=∑m=1M(maxi=1|S|fmi−mini=1|S|fmi)2.Hyperarea (HA) relates to the size of the area that is dominated by S. The larger the area the solutions can dominate in the fitness space, the better. A normalized HA can be defined by(6.5)HA={∪iareai|Si∈S},where Siis a non-dominated vector and areaiis the area between vector Siand the origin O’. The drawbacks of the performance index are that O’ needs to be given and that convex parts of the Pareto front are more preferable than concave parts.The example given in [8], as shown in Table 6, is used to test the HSLTPSO and to compare performance of the HSLTPSO with that of the MOGLS [8]. Ishibuchi and Murata [8] used dynamic weights selected randomly and traditional two-point crossover in their MOGLS.The OA L16(215) is adopted for systematic reasoning of Taguchi-based crossover. First three columns are used for factors α, β, and γ. The following 10 columns are used for 10 jobs. The full neighborhood solutions are used. The number of global optimal solutions (GOB) obtained by the HSLTPSO in 30 independent runs of four iterations (500, 1000, 2000, and 3000) with weights selected randomly are shown in Fig. 5. The success rate (number of runs with 11 GOS/total number of runs) and their convergence iterations of the HSLTPSO are shown in Fig. 6. From Figs. 5 and 6, the HSLTPSO effectively presents a higher search ability to find GOBs and has a higher success rate with quick convergence.Fig. 7shows the Pareto front of the HSLTPSO and the MOGLS [8] for 10-job and 5-machine FSP. The coverage ratio C(HSLTPSO, MOGLS) of 1 is superior to the ratio C(MOGLS, HSLTPSO) of 0. Table 7shows the results of performance comparisons of HSLTPSO and MOGLS in terms of SP, max_D, and HA. The smaller the SP is and the larger the max_D and the HA are, the better. The SP and HA obtained by the HSLTPSO are superior to those obtained by the MOGLS, while the max_D obtained by the HSLTPSO is smaller than that obtained by the MOGLS. From the simulation results, the HSLTPSO is better than the MOGLS [8] in finding the better Pareto-optimal solutions.This problem uses the example in [11] to compare the HSLTPSO with the modified MOGLS [11]. A 40-job and 20-machine FSP is randomly generated as described in Section IIIA in [8].A systematic reasoning way of Taguchi-based crossover is performed by OA L64(263). First three columns are used for factors α, β, and γ. The following 40 columns are used for 40 jobs. The full neighborhood solutions and 500 iterations are used. The population size is 20. The HSLTPSO are conducted in 12 independent runs.Fig. 8shows the Pareto front of the HSLTPSO and the modified MOGLS [11] for 40-job and 20-machine FSP. The coverage ratio C(HSLTPSO, modified MOGLS) of 0.793 is superior to the ratio C(modified MOGLS, HSLTPSO) of 0. Table 8shows the results of performance comparisons of HSLTPSO and modified MOGLS in terms of SP, max_D, and HA. The smaller the SP is and the larger the max_D and the HA are, the better. The SP and HA obtained by the HSLTPSO are superior to those obtained by the modified MOGLS, while the max_D obtained by the HSLTPSO is smaller than that obtained by the modified MOGLS. From the simulation results, the HSLTPSO is better than the modified MOGLS [11] in finding the better Pareto-optimal solutions.The same problem considered in [21] is used to compare the HSLTPSO with the MOGLS, IM-MOGLS, and J-MOGLS given in [21]. A 50-job and 20-machine FSP is randomly generated according to Section 5.1 in [21].The OA L64(263) is adopted for systematic reasoning of Taguchi-based crossover. First three columns are used for factors α, β, and γ. The following 50 columns are used for 50 jobs. The full neighborhood solutions and 500 iterations are used. The population size is 20. The HSLTPSO are conducted in 12 independent runs.Fig. 9a–c show the Pareto front of the HSLTPSO and MOGLS [21], the Pareto front of the HSLTPSO and the IM-MOGLS [21], and the Pareto front of the HSLTPSO and the J-MOGLS [21], respectively, for 50-job and 20-machine FSP. The coverage ratios C(HSLTPSO, MOGLS) of 0.841, C(HSLTPSO, IM-MOGLS) of 0.926, and C(HSLTPSO, J-MOGLS) of 0.8 are superior to the ratios C(MOGLS, HSLTPSO) of 0, C(IM-MOGLS, HSLTPSO) of 0, and C(J-MOGLS, HSLTPSO) of 0, respectively. Table 9shows the results of performance comparisons of the HSLTPSO, MOGLS, IM-MOGLS, and J-MOGLS in terms of SP, max_D, and HA. The smaller the SP is and the larger the max_D and the HA are, the better. The SP and HA obtained by the HSLTPSO are superior to those obtained by the MOGLS, IM-MOGLS, and J-MOGLS, while the max_D obtained by the HSLTPSO is smaller than that obtained by the MOGLS, IM-MOGLS, and J-MOGLS. From the simulation results, the HSLTPSO is better than the MOGLS [21], IM-MOGLS [21], and J-MOGLS [21] in finding the better Pareto-optimal solutions.This problem uses the example in [18] to compare the HSLTPSO with the HTGA [18]. A 40-job and 20-machine FSP is randomly generated as described in section IIIA in [8].A systematic reasoning way of Taguchi-based crossover is performed by OA L64(263). First three columns are used for factors α, β, and γ. The following 40 columns are used for 40 jobs. The full neighborhood solutions and 500 iterations are used. The population size is 20. The HSLTPSO are conducted in 12 independent runs.Fig. 10shows the Pareto front of the HSLTPSO and the HTGA [18] for 40-job and 20-machine FSP. The coverage ratio C(HSLTPSO, HTGA) of 0.889 is superior to the ratio C(HTGA, HSLTPSO) of 0. Table 10shows the results of performance comparisons of HSLTPSO and HTGA in terms of SP, max_D, and HA. The smaller the SP is and the larger the max_D and the HA are, the better. The SP, max_D, and HA obtained by the HSLTPSO are superior to those obtained by the HTGA. From the simulation results, the HSLTPSO is better than the HTGA [18] in finding the better Pareto-optimal solutions.The problem considered in [31] is used to compare the HSLTPSO with the MOPSO [31] and IM-MOGLS [31]. A 20-job and 10-machine FSP is randomly generated according to Section VB in [31].The OA L32(231) is adopted for systematic reasoning of Taguchi-based crossover. First three columns are used for factors α, β, and γ. The following 20 columns are used for 20 jobs. The full neighborhood solutions and 1000 iterations are used. The population size is 20. The HSLTPSO are conducted in 12 independent runs.Fig. 11shows the Pareto front of the HSLTPSO, the MOPSO [31], and the IM-MOGLS [31] for 20-job and 10-machine FSP. The coverage ratios C(HSLTPSO, MOPSO) of 1 and C(HSLTPSO, IM-MOGLS) of 1 are superior to the ratios C(MOPSO, HSLTPSO) of 0 and C(IM-MOGLS, HSLTPSO) of 0 respectively. Table 11shows the results of performance comparisons of the HSLTPSO, MOPSO, and IM-MOGLS in terms of SP, max_D, and HA. The smaller the SP is and the larger the max_D and the HA are, the better. The SP and HA obtained by the HSLTPSO are superior to those obtained by the MOPSO and IM-MOGLS. The max_D obtained by the HSLTPSO is larger than that obtained by the MOPSO and smaller than that obtained by the IM-MOGLS. From the simulation results, the HSLTPSO is better than the MOPSO [31] and IM-MOGLS [31] in finding the better Pareto-optimal solutions.This problem uses the example in [33] to compare the HSLTPSO with the HTPSO [33]. A 40-job and 20-machine FSP is randomly generated as described in Section IIIA in [8].A systematic reasoning way of Taguchi-based crossover is performed by OA L64(263). First three columns are used for factors α, β, and γ. The following 40 columns are used for 40 jobs. The full neighborhood solutions and 500 iterations are used. The population size is 20. The HSLTPSO are conducted in 12 independent runs.Fig. 12shows the Pareto front of the HSLTPSO and the HTPSO [33] for 40-job and 20-machine FSP. The coverage ratio C(HSLTPSO, HTPSO) of 0.733 is superior to the ratio C(HTPSO, HSLTPSO) of 0. Table 12shows the results of performance comparisons of HSLTPSO and HTPSO in terms of SP, max_D, and HA. The smaller the SP is and the larger the max_D and the HA are, the better. The SP and HA obtained by the HSLTPSO are superior to those obtained by the HTPSO, while the max_D obtained by the HSLTPSO is smaller than that obtained by the HTPSO. From the simulation results, the HSLTPSO is better than the HTPSO [33] in finding the better Pareto-optimal solutions.The solutions for the above six test problems confirm that the proposed HSLTPSO approach effectively solves the FSPs and outperforms the other optimization methods.

@&#CONCLUSIONS@&#
The HSLTPSO is proposed to solve the multi-objective FSPs and various performance indices are used for measuring the quality of Pareto-optimal sets. The HSLTPSO combines PSO, which has the powerful global exploration capability for exploring the optimal feasible region, the sliding level Taguchi-based crossover to exploit the better offspring, and the elitist preservation strategy to retain the best particles. In this study, the detailed steps of the HSLTPSO are presented to solve the multi-objective FSPs. The major contribution of the HSLTPSO is the use of a systematic reasoning way with considering the influence of tuning factors α, β, and γ, and performs Taguchi-based crossover without the conflicting problem of non-feasible solutions to find the global optimal solutions for the FSPs by minimizing both the makespan and maximum tardiness. In each computational experiment of the six test problems, the coverage ratio, SP, and HA obtained by the HSLTPSO are superior to those obtained by the optimization methods reported in [8,11,18,21,31,33]. That is, the proposed HSLTPSO effectively solves the FSPs and outperforms those approaches presented by Ishibuchi and Murata [8], Ishibuchi et al. [11], Arroyo and Armentano [21], Yang et al. [18], Le et al., [31], and Yang et al. [33]. Therefore, the proposed HSLTPSO approach can be used as a multi-objective optimization method for solving FSPs.