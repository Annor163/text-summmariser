@&#MAIN-TITLE@&#
SO-ARTIST: Self-Organized ART-2A inspired clustering for online Takagi–Sugeno fuzzy models

@&#HIGHLIGHTS@&#
We developed self-organized Takagi–Sugeno model for online learning, starting from the scratch, adding new classes any time and independent on database knowledge, not knowing the number of classes.We introduce the solutions for merging and splitting of antecedent and consequent parameters.Our merging and splitting solutions are limited for our novel incremental distance measurement (antecedent part) and recursive least squares (consequent part).We introduce the automated organization of rule and decision making behind it.

@&#KEYPHRASES@&#
Online learning,Self-organized clustering,Takagi–Sugeno fuzzy model,RLS,CCL,Incremental distance,

@&#ABSTRACT@&#
In this paper we introduce a novel online self-organized clustering method based on the ART-2A network for Takagi–Sugeno fuzzy models. To accomplish the self-organization, we introduce an automatic decision algorithm along with solutions for merging and splitting of rules as well as the parameters they operate with, such as our novel incremental distance measurement and competitive recursive least squares. We emphasize the learning algorithm's having an impact for initial as well as long-term learning capabilities. We also emphasize the challenge for online learning, where examples are incoming in real-time and thus are unknown before they can be learned. Therefore, we solve parameter fixing by introducing a parameter free method. We show the performance of our method on various machine learning benchmarks as a highly accurate and low time-consuming method capable of adapting to different databases without the need for fixing any of its parameters according to the database.

@&#INTRODUCTION@&#
Across many fields, such as machine learning, pattern recognition, and document analysis, the need for online learning has become important though challenging. Often, new data are available and to keep up to date the classical pre-learning methods (i.e. offline learning) require long-term processes to perform recognition. On the one hand, incremental learning might seem to be an option, where each new example is learned as an increment to a previously learned model. However, we focus on online learning, where the model is learned incrementally or adapted to actual situations, but at the same time achieves real-time performance. This means that the whole learning process is linked to recognition, so the steps are performed at the same time, in contrast to offline learning. In addition, we emphasize the no-database-knowledge problem, where the model starts from scratch, not knowing the number of classes or their appearance. Thus, this kind of learning needs to provide a strong recognition rate at the very beginning of the recognition process as well as overall.Our main motivation for this research is applications such as handwritten gesture (symbol) recognition for interactive devices, where the user sets his own gestures and the system adapts to his personal needs. In these cases, we do not have any information about the database or its content. That information is collected over time as the user's writing style evolves. The recognition begins immediately after a few samples per class are introduced (generally 1–5), and all classes can be introduced one after another during the process, forgotten in time or recalled after not being used for a long time. These are some of the challenges of online learning, where the distribution of classes is not given and the model has to be elastic enough to cope with them.In this paper we introduce a novel variant for online learning when knowledge of the database is not required. The contributions in this paper are•Self-organized clustering based on the ART-2A neural network (Carpenter et al. [27]), where its parameters are learned automatically and online.Similarity, dissimilarity and error measurement for fuzzy rules.Merging and splitting of parameters for Incremental distance (antecedent part) and parameters for CCL/RLS (consequent part).This work is leveraged on our previous work, ARTIST (Režnáková et al. [56]), in which we introduced the integration of the ART-2A network into the generation of fuzzy rules for a TS fuzzy model. In this paper, we propose a novel method in which the rules are organized by themselves and thus not solely by the ART-2A network. Along with automatic generation, we introduce the merging, splitting and discarding of the rules. In addition, we introduce the automatic learning of a vigilance parameter and a learning rate that for the ART network originally need to be set by user. Thus, this paper presents a novel self-organized method in which the learning starts from scratch with no knowledge of a dataset size or the number of classes, and time classes are introduced. Classes can be added on the fly, with rule organization on the fly, and in an automatic way. All these major features make this work's base-line drastically different from and complementary to the previous work, ARTIST.We evaluate our proposed method on standard datasets in a comparison with our previous model (ARTIST), in which the rules are generated automatically without any self-organization by using fixed parameters. This comparison is performed in contrast to finding the best parameters by using a grid method, showing that our method is capable of finding optimal parameters. At the same time, by this comparison we show that our method is capable of finding the correct organization (fuzzy rules distribution) as a supervised solution.This paper is divided into six sections. In Section 2 we show the state-of-the-art methods for handling the TS fuzzy rules, self-organized clustering methods, and incremental real-time models. Within Section 3 we briefly summarize our previous model, ARTIST, which is based on ART-2A based generation of rules for the Takagi–Sugeno (TS) fuzzy model, along with incremental distance measurement and competitive consequent learning (CCL). In Section 4 we explain our novel self-organized (SO) ARTIST in detail, focusing on our contributions. We conclude this section with an algorithm summarizing the whole novel concept of online learning when starting from scratch with no parameters to set according to the database used. Finally, in Section 5 we show the results of our novel method on several machine learning datasets containing handwritten symbols, which are the main motivation of our research. We end this paper with conclusion and possible future work.

@&#CONCLUSIONS@&#
