@&#MAIN-TITLE@&#
A private DNA motif finding algorithm

@&#HIGHLIGHTS@&#
We propose the first solution to differentially private DNA motif finding.Our solution is based on the n-gram model and is optimized for DNA motif finding.We provide a theoretical utility analysis of our solution.We experimentally show the promise of integrating privacy into DNA motif finding.

@&#KEYPHRASES@&#
Motif finding,Privacy protection,∊-Differential privacy,n-gram model,

@&#ABSTRACT@&#
With the increasing availability of genomic sequence data, numerous methods have been proposed for finding DNA motifs. The discovery of DNA motifs serves a critical step in many biological applications. However, the privacy implication of DNA analysis is normally neglected in the existing methods. In this work, we propose a private DNA motif finding algorithm in which a DNA owner’s privacy is protected by a rigorous privacy model, known as∊-differential privacy. It provides provable privacy guarantees that are independent of adversaries’ background knowledge. Our algorithm makes use of then-gram model and is optimized for processing large-scale DNA sequences. We evaluate the performance of our algorithm over real-life genomic data and demonstrate the promise of integrating privacy into DNA motif finding.

@&#INTRODUCTION@&#
A DNA motif is defined as an overrepresented nucleic acid (sub) sequence that has some biological significance [1]. In the sequel, we use the terms motif and (sub) sequence interchangeably. Finding motifs in genomic DNA sequences is one of the most important and challenging problems in both bioinformatics and computer science. The identification of DNA motifs serves a critical step in a wide spectrum of biological applications [2], such as checking fragment assemblies, comparing gene structures and mapping of cDNA/EST sequences, among others. In the simplest form, the problem of motif finding can be formulated as follows: given a collection of DNA sequences, identify the motifs that occur in at least a given number of sequences or that occur most frequently. The problem is compounded by the fact that motifs are not presented exactly. Motifs include mutations, insertions or deletions of nucleotides.In recent years, with the increasing availability of DNA data, numerous DNA motif finding algorithms have been proposed [1], resulting in better understanding on the mechanisms that regulate the expression of genes. Existing algorithms address the problem of motif finding from different directions. According to Das and Dai [1], they can be roughly classified into three major classes: (1) those that use promoter sequences from a single genome [3–14]; (2) those that use orthologous promoter sequences of a single gene from multiple species [15–19]; and (3) a mixture of the former two classes [20–24].While there is no doubt that DNA data analysis generates interesting findings that could benefit the general public, substantial privacy concerns have been raised on the use of DNA data. Indeed, a personally identifiable DNA segment gives an adversary access to a wealth of information about the person and his or her genetic relatives [25], exposing their privacy to considerable risks. Such privacy concerns have been confirmed by several recent research results. Homer et al. [26] demonstrate that it is possible to detect an individual’s presence within a highly complex genomic DNA mixture using high-density single nucleotide polymorphism (SNP) genotyping microarrays. As a consequence, the US National Institutes of Health (NIH) immediately removed all aggregate results from open-access databases. Later, Gymrek et al. [27] show that they are able to re-identify 50 DNA donors who had participated in the 1000 Genomes Project from their published genomes, even after removing explicit identifying information. All these findings recognize the vital necessity of privacy protection in DNA data analysis.Unfortunately, the existing works have largely neglected the privacy implication in DNA motif finding. Worse, though it has been widely believed that improper use of DNA data poses serious compromise of individual privacy, it is still not clear what types of privacy attacks could be launched on DNA sequences [28]. Therefore, a data holder may not even know what information to protect nor what background knowledge might be used by an adversary to launch privacy attacks. These concerns are exactly the ones addressed by∊-differential privacy[29], one of the strongest privacy notions that has been widely adopted for privacy protection. Intuitively,∊-differential privacy requires that the outcome of any analysis should not overly depend on any single data record (in our problem, any single DNA sequence). It follows that even if a user had opted into a database, there will be almost no difference in any computation based on that database.Due to the desirable privacy property of differential privacy, it has attracted increasing attention from the genetics community for private DNA data analysis. Fienberg et al. [30] study the release of aggregate minor allele frequencies (MAFs),χ2-statistics andp-values under differential privacy. Their method of generating perturbed frequencies primarily relies on the standard Laplace mechanism [29], which normally results in excessive noise and hence less accurate frequencies. Johnson and Shmatikov [31] recently present a set of differentially private data mining algorithms for genome-wide association studies (GWAS). In particular, they develop a general distance-score mechanism to support accurate answering of GWAS queries. We point out that the problem of both of the studies is different from DNA motif finding. They make the fundamental assumption that a candidate set of SNPs (of size on the order of105[31]) have been given. In contrast, the major technical challenge of motif finding is how to accurately identify the candidate set of frequent motifs along with their frequencies from a significantly larger output space (e.g., in our experimental section, we consider output spaces as large as the order of4100) while satisfying differential privacy. It is computationally infeasible to enumerate all possible motifs and then apply the above solutions. Therefore, neither of the solutions [30,31] can be directly applied to DNA motif finding.DNA motif finding is related to the problems of frequent itemset mining (FIM) [32] and frequent sequential pattern mining (FSPM) [33], which have been well studied in the data mining community. There have been some recent works on providing differentially private algorithms for these data mining tasks. Unfortunately, the research on differentially private FIM [34–36] cannot be applied to our problem due to the inherent sequentiality of DNA sequences. The sequentiality of letters in a DNA motif is critical. For example,ACTGis different fromCTGA, though they correspond to the same itemset,{A,C,G,T}. However, the sequentiality is not considered in FIM. Two latest works [37,38] study differentially private FSPM, which takes into consideration the sequentiality. Chen et al. [37] propose a prefix-tree-based solution for publishing sequential transit data. Later, Chen et al. [38] improve the solution in [37] by making use of then-gram model with the goal of constructing a synthetic database for answering counting queries. The method in [38] provides important primitives for finding DNA motifs under differential privacy, but still faces new challenges due to the fact that motifs include mutations, insertions or deletions of nucleotides.In this work, we consider the problem of finding DNA motifs while satisfying∊-differential privacy. This problem involves an interesting trade-off between privacy and data utility. Due to the noise injected for the purpose of privacy protection, we may not be able to generate the same motifs as from the non-private algorithm. The key challenge of a differentially private DNA motif finding algorithm is, given a fixed privacy requirement, how to minimize noise so that the motifs obtained are as close to those obtained by the non-private algorithm as possible. Direct adaptation of existing motif finding algorithms into a differentially private version is very difficult as they are overly sensitive to the change of a single DNA sequence. This implies that excessive noise must be added, resulting in undesirable data utility and thus imprecise motif identification. In contrast, we propose a novel solution that is adapted from [38] and tuned to our problem in order to achieve meaningful data utility and desirable efficiency.In spite of the diverse research on motif finding, to our best knowledge, there is still no research that integrates rigorous privacy requirements into DNA motif finding. In this work, we conduct the first exploration on the possibility of integrating∊-differential privacy, a well-acknowledged rigorous privacy notion, into DNA motif finding while guaranteeing the usefulness of the identified motifs. Our solution is based on then-gram model, which allows to generate longer motifs using a probabilistic prediction model, and is optimized for the problem of DNA motif finding. This enables our algorithm to significantly improve the resultant data utility and scalability. We provide a theoretical utility analysis of our solution and show that it outperforms the approach based on the standard Laplace mechanism. Since motif finding algorithms usually need to handle large-scale DNA sequences, another contribution of our paper is to provide an efficient implementation of the proposed algorithm. Finally, we perform a comprehensive experimental study on real-life genomic data, which demonstrates the great promise of integrating privacy into DNA motif finding.The essence of∊-differential privacy is to mask the presence or absence of a single user from the outcome of any computation over the underlying database, leading to the notion of neighboring databases. Two databases,D1andD2, are neighbors if they differ on at most one record (in our problem, that is a single DNA sequence), denoted by|D1⊕D2|=1.∊-differential privacy demands that any information that can be learned from a database can also be learned from any of its neighbors. Consequently, for a record owner, it ensures that any privacy breach will not be a result of participating in the database. Formally,∊-differential privacy [29] is defined below.Definition 2.1Differential privacyA privacy mechanismAgives∊-differential privacy if for any databasesD1andD2s.t.|D1⊕D2|=1, and for any possible outputO∈Range(A),Pr[A(D1)∈O]⩽e∊×Pr[A(D2)∈O]where the probability is taken over the randomness ofA.□∊-Differential privacy provides strong privacy guarantees that are independent of an adversary’s background knowledge. To achieve∊-differential privacy, we need to quantify the maximal impact of a single user on a function, which is known as the function’s sensitivity.Definition 2.2SensitivityFor any functionf:D→Rd, the sensitivity offisΔf=maxD1,D2||f(D1)-f(D2)||1for allD1,D2s.t.|D1⊕D2|=1.□A standard mechanism to achieve differential privacy is to add properly calibrated Laplace noise to the true output of a function, which is known as Laplace mechanism[29]. It takes as inputs a databaseD, a functionf, and the privacy parameter∊. The noise is generated from a Laplace distribution with the probability density function (pdf)p(x|λ)=12λe-|x|/λ, whereλis determined by bothΔfand the desired privacy parameter∊.LetL(λ)denote a Laplace random variable with the probability density function defined as above.Theorem 2.1For any functionf:D→Rd, the mechanismLaplace(D,f,∊)=f(D)+<L1(λ),L2(λ),…,Ld(λ)>gives∊-differential privacy ifλ=Δf/∊andLi(λ)are i.i.d Laplace random variables.□Since motifs are rarely precisely defined, it is necessary to take into consideration a sequence’s “approximately” identical sequences for computing its frequency. In our problem setting, we follow the convention [2,6,39] to measure the extent of “approximation” based on the Hamming distance model. LetΣ={A,C,G,T}be the alphabet of letters in DNA sequences.Definition 2.3Hamming distanceThe Hamming distance between two DNA (sub) sequences of lengthl,S1=s11s21⋯sl1andS2=s12s22⋯sl2wheresij∈Σ, isdH(S1,S2)=|{i|si1≠si2,1⩽i⩽l}|.□Two sequences are considered approximately identical if and only if they are of the same length and their Hamming distance is within a user-specified error toleranceδ(normally a small positive integer). For example, given the error toleranceδ=2,AATGCandACTTCare approximately identical. For ease of exposition, we denote “all sequences of Hamming distance⩽δto a sequenceS” by “S’s approximate sequences”.In this paper, we aim to identify the top-Nmost “frequent” motifs in a differentially private manner, whereNis a user-specified parameter. Hence it is imperative to clearly define the “frequency” of a motif. In our problem, each motif is associated with three types of frequencies: the number of its occurrences, the number of its approximate sequences’ occurrences and the sum of these two numbers. We refer to the first number simply as frequency, the second number as Hamming frequency, and the sum of these two numbers as consolidated frequency. In the biological setting, we are interested in identifying the motifs with the largest consolidated frequencies. Formally, our problem is defined as follows.Definition 2.4Private motif findingGiven a collection of DNA sequencesS={S1,S2,⋯,S|S|}, an error tolerance thresholdδ, a privacy parameter∊, find the top-Nmotifs of a length in[lL,lU]with the largest consolidated frequencies while satisfying∊-differential privacy, wherelLandlUare user-specified parameters andlL⩽lU.□

@&#CONCLUSIONS@&#
The recent advances in genomic sequence availability have spawned extensive research on DNA motif finding. However, the privacy implication in DNA motif finding has been largely neglected in existing works. In this paper, we make the first effort to apply the rigorous∊-differential privacy model to DNA motif finding. We propose ann-gram-based solution along with an efficient implementation. We theoretically analyze the utility of our solution. We also conduct an extensive experimental evaluation on real-life DNA sequence datasets. The results demonstrate the great promise of integrating privacy into DNA motif finding.