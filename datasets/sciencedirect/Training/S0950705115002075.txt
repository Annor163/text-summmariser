@&#MAIN-TITLE@&#
Uncertainty measures of Neighborhood System-based rough sets

@&#HIGHLIGHTS@&#
We first study the uncertainty of rough sets in binary GrC Model (Third GrC Model).We first propose the rough memberships to depict rough sets.Construct fuzzy entropy based on rough memberships and prove its rationality.We first propose the rough intuitionistic memberships to depict rough sets.Construct intuitionistic fuzzy entropy to measure uncertainty of rough sets.

@&#KEYPHRASES@&#
Neighborhood System (NS),Neighborhood System-based (NS-based),Rough membership function,Rough intuitionistic membership function,Rough fuzzy entropy,Rough intuitionistic fuzzy entropy,

@&#ABSTRACT@&#
Neighborhood System-based (NS-based) rough set theory is an extension of classical rough set theory. This paper aims to investigate the uncertainty measures of rough sets in a Neighborhood System-space (NS-space). We firstly develop a rough membership function and a rough intuitionistic membership function based on binary relationships. Then we propose a fuzzy entropy and an intuitionistic fuzzy entropy of rough sets, and further explore their corresponding properties. Examples show that the methods not only accord with people’s recognition rules of rough sets, but also can be used to depict the case that the NS-based rough sets degenerate into the crisp sets.

@&#INTRODUCTION@&#
The uncertainty and inexactness of information are ubiquitous in many problems. Therefore, how to capture the uncertainty has attracted considerable attention from both academic communities and practitioners worldwide. Currently, the common approaches used to estimate the uncertainty contain fuzzy sets, probabilities, rough sets, topology, and so on.The concept of Neighborhood System (NS) initiated by Lin [12] is derived from the geometric notion of “near” or “negligible distances”. The interior and closure of NS theory [15–17] can be viewed as the upper and lower approximations. Based on such approximations, the new rough set theory can be regarded as the most general rough set theory [19]. Therefore, partitions [23], coverings [39], variable precision [42] and multi-granulation rough sets [27] are all special forms of NS-based rough set theory. In addition, Lin and Syau [18] also showed that NSs can cover Ziarko’s variable precision rough sets and Pawlak’s classical rough sets under a same umbrella. Some other works also showed the advantage of NSs in application. Yang [33] investigated an optimal rough approximations in an incomplete information system, and they [34] further introduced an attribute reduction in a NS. Zhou et al. [40] proposed an order relation to describe the hierarchical structure of a NS, and further discussed two models of NS–based rough sets [41].Other literatures addressed the uncertainty measures of rough sets from other different viewpoints, such as roughness [35], roughness entropy [11,3], fuzziness [4,31], fuzzy entropy [11,21,10] and combination entropy [26,25]. These works discussed the uncertainty of rough sets in Pawlak’s approximation spaces or covering spaces [8,6].With the development of NS theory in recent years, it makes the study on uncertainty of NS-based rough sets become a hot topic. At present, one of the main issues in this area is how to extend the uncertain measure of rough sets from current special NS-spaces into general NS-spaces. The relevant research contains Chen et al. [5] and Tang and Cheng [29]. Chen et al. [5] introduced neighborhood entropy to deal with the uncertainty of a neighborhood information system. Tang and Cheng [29] used neighborhood approximation accuracy based on knowledge granularity to evaluate the uncertainty. However, their approaches do not take into account that the uncertainty has nothing to do with the knowledge granularity in the positive regions.The uncertainty of rough sets originates from two parts of boundary region. One part comprises the elements of the boundary region which belong to the set X, and another part is composed of those not belonging to the set X. In this paper, we aim to estimate uncertainty in the two parts accurately, and propose two fuzzy entropies to capture them.The structure of this paper is organized as follows. Section 2 introduces some preliminary concepts and notations of NS-based rough sets. Then we address the fuzzy entropy based on rough memberships in Section 3. Section 4 proposes an intuitionistic fuzzy entropy based on rough intuitionistic memberships and discusses the properties. Section 5 uses some examples to verify the effectiveness of the proposed methods. Section 6 gives the conclusions.Pawlak’s classical RST is built on the equivalence relation which induces a partition and generates a topology [24]. The upper and lower approximation are equal to the closure and interior in Pawlak’s topology respectively. Topology is an effective tool to study the limit and approximation. Lin [13,14] captured the concept of “near” (topology) and “conflict” (security), and further introduced the NS which generalized rough set methodology to more general settings of granular computing. In this section, we first recall the notion of Binary Neighborhood System (BNS).Definition 2.1[17]Let U be a nonempty set, called the universe, andβ={Rt|t=1,2,…}be a family of binary relations. For anyx∈U, a (right) neighborhood of x is defined asNt(x)={y∈U|(x,y)∈Rt},(t=1,2,…). The collection of all the (right) neighborhoods of x is called a (right) neighborhood system of x, denoted byNS(x), that isNS(x)={Nt(x)|t=1,2,…}.{NS(x)|x∈U}is called a (right) neighborhood system of U, denoted byNS(U). The pair(U,β)is called a Binary GrC Model (or Third GrC Model). The pair(U,NS(U))is called a (right) Neighborhood System-space (NS-space) of β.Similarly, we can define left NS-space based on{y∈U|(y,x)∈Rt}. Note that the right and left NS-space are interdependent of each other. Hereinafter, they are both called NS-spaces.If∀N(x)∈NS(x),x∈N(x), the NS is reflexive. For simplicity, all the following NSs are reflexive NSs.Here we only discuss the case in nonempty finite universes.Since the partition and covering can be regarded as the specific NSs, it is natural to generalize Pawlak’s knowledge representation of equivalence relations and covering knowledge representation of tolerance relations to that of common binary relation in NSs. Lin [15] built the models of approximation sets based on NSs:Definition 2.2[15]Let X be a subset in the NS-space(U,NS(U)). A rough set based on the NS-space, denoted byN(X)=(Apr̲(X),Apr‾(X)), is defined as:Apr̲(X)={x∈U|∃N(x)∈NS(x),N(x)≠∅∧N(x)⊆X};Apr‾(X)={x∈U|∀N(x)∈NS(x),N(x)∩X≠∅},in which,Apr̲(X)andApr‾(X)are called the lower approximation and the upper approximation of X in(U,NS(U)), respectively.WhenApr‾(X)=Apr̲(X), we say X is definable in(U,NS(U)), or call the rough setN(X)is crisp. Otherwise, we say X is rough in(U,NS(U)).Obviously, the upper and lower approximations of NS-based rough sets divide the universe U into three regions, that namely, the positive regionPOSN(X)=Apr̲(X), the negative regionNEGN(X)=U-Apr‾(X), and the boundary regionBNN(X)=Apr‾(X)-Apr̲(X). Moreover, the relationship between the elements in the boundary region and the subset X is uncertain, while the relationship between the elements in the positive region or in the negative region and X is certain. Therefore, the uncertainty of the rough sets should mainly be determined by the elements in the boundary region.Inspired by the hierarchical structure analysis of Pawlak’s rough sets, we define the hierarchical structure of NSs as follows.Definition 2.3Let(U,NS1(U))and(U,NS2(U))be two NS-spaces. If∀X⊆U,Apr1̲(X)⊇Apr2̲(X)andApr1‾(X)⊆Apr2‾(X), we callNS1(U)is finer thanNS2(U), orNS2(U)is coarser thanNS1(U), denoted byNS1(U)⪯NS2(U), orNS2(U)⪰NS1(U), respectively.In this subsection, we address the existing works to measure the uncertainty of NS-based rough sets.Definition 3.1[5]Let X be a subset in the NS-space(U,NS(U)). The roughnessρNS(U)(X)of X is defined asρNS(U)(X)=1-|Apr̲(X)||Apr‾(X)|.Hereinafter,|·|denotes the cardinality.Obviously the roughness does not contain the structural information of its boundary region. The uncertainty of NS-based rough sets originates from the knowledge granularity. Therefore, Chen et al. [5] give the definition of entropy-based roughness as follows:Definition 3.2[5]Let X be a subset in the NS-space(U,NS(U)). The entropy-based roughnesseNS(U)(X)of X is defined aseNS(U)(X)=ρNS(U)(X)∗H(NS(U)).HereH(NS(U))=-∑i=1|U||NS(xi)||U|2log21|NS(xi)|is the neighborhood entropy in(U,NS(U)).Note that Chen et al. [5] discuss the simplest BNS based on the distance function of the elements in the universe, whereNS(x)is decided by the neighborhood parameter δ. It means the above definition is based on a given δ. At this case,NS(x)only has a single neighborhood. This can be regarded as a single granular structure. We show its drawbacks by the following example.Example 3.1SupposeU={x1,x2,x3,x4,x5,x6}andX={x1,x2,x3}. Let(U,NSi(U))be a NS-space based onδi,(i=1,2,3). HereNSi(x)={y|D(x,y)⩽δi},D(x,y)is a Euclidean distance. SupposeNS1(x1)={{x1}},NS1(x2)={{x2}},NS1(x3)={{x3,x4}},NS1(x4)={{x3,x4,x5}},NS1(x5)={{x4,x5}},NS1(x6)={{x6}};NS2(x1)={{x1}},NS2(x2)={{x2}},NS2(x3)={{x3,x4}},NS2(x4)={{x3,x4,x5}},NS2(x5)={{x4,x5}},NS2(x6)={{x5,x6}};NS3(x1)={{x1,x2}},NS3(x2)={{x1,x2}},NS3(x3)={{x3,x4}},NS3(x4)={{x3,x4,x5}},NS3(x5)={{x4,x5,x6}},NS3(x6)={{x5,x6}}.LetApri̲(X)be the lower approximation andApri‾(X)be the upper approximation in(U,NSi(U))(i=1,2,3). Based on Definition 2.2, we haveApr1̲(X)=Apr2̲(X)=Apr3̲(X)={x1,x2}andApr1‾(X)=Apr2‾(X)=Apr3‾(X)={x1,x2,x3,x4}. However, by Definition 3.2, we haveeNS1(U)(X)=0.12,eNS2(U)(X)=0.15andeNS3(U)(X)=0.24.Example 3.1 shows that the entropy-based roughnesses are different with each other in the three NS-spaces, while they have the same sizes and structures of the boundary regions. Therefore, we can conclude that the entropy-based roughness not only reflects the size and structure information of the boundary region, but also takes those in the positive and negative regions into account. However, the uncertainty of NS-based rough sets should only depend on the information of its boundary region and have nothing to do with the thickness of the positive and negative regions. Therefore, this method becomes helpless in the case of neighborhood systems with multi-granular structures.Based on the fuzziness of fuzzy sets, Chakrabarty [4] quantified the membership relation between all the elements of every section with the goal rough sets, derived the fuzzy set and estimated the uncertainty of rough sets. The basic idea is as follows: use a rough membership function to transform rough sets into fuzzy sets, and then use the fuzzy sets to measure uncertainties. Therefore, the key step of this method is to define a rough membership function. Hu [7] proposed an uncertainty measure of rough sets with the aid of the rough membership function in covering approximation spaces. Wei et al. [32] pointed out fuzzy entropy can evaluate the roughness of a rough set in Pawlak’s topology spaces. In this subsection, we discuss how to construct a rough membership function and choose fuzziness which can capture the uncertainty of the rough sets based on NS-spaces.Let us consider the membership relationship between the element x and the subset X in(U,NS(U)). If there exists some neighborhood of x which is totally contained by X, then x surely belongs to X. If there exists some neighborhood of x which does not intersect with X, then x surely does not belong to X. There are another two cases: (1)x∈Xbut every neighborhood of x intersects with the complementary set of X, denoted byXC; (2)x∈XCbut every neighborhood of x intersects with X. In each of these cases, the relationships between x and X are uncertain. Hence, in the given NS-space(U,NS(U))and the given subset X, all the elements can be divided into the following four parts:(1)AX1:x∈AX1, if∃N(x)∈NS(x),N(x)⊆X.AX2:x∈AX2, ifx∈Xand∀N(x)∈NS(x),N(x)⋂XC≠∅.AX3:x∈AX3, ifx∈XCand∀N(x)∈NS(x),N(x)⋂X≠∅.AX4:x∈AX4, ifx∈XCand∃N(x)∈NS(x),N(x)⋂X=∅.Note that the four parts partition the whole universe. In topology spaceAX1,AX4are the interiors of X andXCrespectively, andAX2,AX3are the boundaries of X andXCrespectively. If we introduce them in NS-spaces, we can sayRemarkPOSN(X)=AX1,NEGN(X)=AX4andBNN(X)=AX2⋃AX3.The membership function is used to depict the degree of the membership of x to X in fuzzy theory. Rough set theory is proposed because there exist some amount of roughness due to rough boundary. The roughness can be regarded as a fuzzy degree of the “belongingness”, so we can give Definition 3.3 as follows.Definition 3.3Let X be a subset in the NS-space(U,NS(U)).∀x∈U, the rough membership functionμFXN(x)of x with respect to X is defined as follows:μFXN(x)=1,x∈AX1;1m∑i=1mNi(x)⋂X|Ni(x)||Ni(x)∈NS(x),x∈AX2∪AX3;0,x∈AX4.Hereinafter m denotes the cardinality ofNS(x).It can be regarded as a fuzzy membership function, so the NS-based rough setN(X)can be mapped into the fuzzy setFXN=(x,μFXN(x))x∈Uin U. It is easy to verify some properties ofFXN:Proposition 3.1Let X be a subset in the NS-space(U,NS(U)).FXNis the fuzzy set produced by the rough setN(X)based on the NS, then the following conclusions are founded:(1)x∈POSN(X)if and only ifμFXN(x)=1;x∈BNN(X)if and only if0<μFXN(x)<1;x∈NEGN(X)if and only ifμFXN(x)=0.The proofs are straightforward by Definition 3.3.□The rough setN(X)in the NS-space(U,NS(U))and the corresponding fuzzy setFXNhave the following relationships:(1)Apr̲(X)=KerFXN;Apr‾(X)=SuppFXN.HereKerFXN=xμFXN(x)=1is the kernel of the fuzzy setFXN,SuppFXN=xμFXN(x)>0is the support ofFXN.The proofs are straightforward by Proposition 3.1.□Table 3.1is an information table about cars, which includes the three conditional attributes (PRICE, SIZE and MAX-SPEED) and the decision attribute (PERFORMANCE). SupposeU={x1,x2,x3,x4,x5,x6}. Each car has different NSs based on different conditional attributes:(1)BNS of PRICE-attribute:N1(x1)={x1,x2},N1(x2)={x1,x2},N1(x3)={x3,x4,x6},…;BNS of SIZE-attribute:N2(x1)={x1,x2,x4},N2(x2)={x1,x2,x4},N2(x3)={x3,x5,x6},…;BNS of MAX-SPEED-attribute:N3(x1)={x1,x3,x5},N3(x2)={x2,x4},N3(x3)={x1,x3,x5},….HenceNS(U)can be expressed as follows:NS(x1)={{x1,x2},{x1,x2,x4},{x1,x3,x5}};NS(x2)={{x1,x2},{x1,x2,x4},{x2,x3}};NS(x3)={{x3,x4,x6},{x3,x5,x6},{x1,x3,x5}};NS(x4)={{x3,x4,x6},{x1,x2,x4},{x2,x4}};NS(x5)={{x5},{x3,x5,x6},{x1,x3,x5}};NS(x6)={{x3,x4,x6},{x3,x5,x6},{x6}}.If we select the cars with the fully excellent performance, that isX={x1,x2,x3}. By Definition 2.2, we knowApr̲(X)={x1,x2},Apr‾(X)={x1,x2,x3,x4}andAX1={x1,x2},AX2={x3},AX3={x4},AX4={x5,x6}. According to Definition 3.3, we have:μFXN(x1)=μFXN(x2)=1,μFXN(x3)=0.44,μFXN(x4)=0.5,μFXN(x5)=μFXN(x6)=0. It implies the rough memberships of the elements inPOSN(X)are 1, those inNEGN(X)are 0, and the rest are between 0 and 1.In Table 3.1, we can find the cars,x1andx2, have cheap price, full size and rather high max–speed, so they are really excellent. While the price ofx5andx6are not cheap and the sizes are not large enough, so they are not excellent. These are accordant with the human being recognition.Proposition 3.3Let X be a subset in the NS-space(U,NS(U)). We haveFXNC=FXCN, hereFXNCdenotes the complementary of the fuzzy setFXN.Ifx∈AX1,μFXN(x)=1andx∈AXC4. SoμFXCN(x)=0=1-μFXN(x). It can be similarly proved whenx∈AX4.Ifx∈AX2,x∈AXC3, or ifx∈AX3,x∈AXC2. In any case,∀Ni(x)∈NS(x),|Ni(x)⋂X||Ni(x)|+|Ni(x)⋂XC||Ni(x)|=1.Therefore, Proposition 3.3 is proved.□.For any two subsets X and Y in the NS-space(U,NS(U)), the following holds:(1)FX⋃YN⊇FXN⋃FYN;FX⋃YN=FXN⋃FYNif and only ifX⊆YorY⊆X;FX⋂YN⊆FXN⋂FYN;FX⋂YN=FXN⋂FYNif and only ifX⊆YorY⊆X.We only proveFX⋃YN⊇FXN⋃FYNand the remaining conclusions can be proved in the similar way.Ifx∈AX1orx∈AY1,μFXN⋃FYN(x)=maxμFXN(x),μFYN(x)=1. In addition,∃N(x)∈NS(x),N(x)⊆XorN(x)⊆Y. In any case,N(x)⊆X⋃Y. Sox∈A(X⋃Y)1,μFX⋃YN(x)=1.Ifx∈AX4andx∈AY4,μFXN⋃FYN(x)=0. In addition,∀N(x)∈NS(x),N(x)⋂X=∅andN(x)⋂Y=∅. SoN(x)⋂(X⋃Y)=∅, i.e.x∈A(X⋃Y)4. HenceμFX⋃YN(x)=0.In other cases, sinceμFX⋃YN(x)=1m∑i=1mNi(x)⋂X⋃Y|Ni(x)|=1m∑i=1mNi(x)⋂X⋃Ni(x)⋂Y|Ni(x)|⩾1m∑i=1mmaxNi(x)⋂X,|Ni(x)⋂Y||Ni(x)|=1m∑i=1mmaxNi(x)⋂X|Ni(x)|,Ni(x)⋂Y|Ni(x)|⩾maxμFXN(x),μFYN(x),FX⋃YN⊇FXN⋃FYN.□In the above subsection we transform the NS-based rough set into the fuzzy set by the rough membership function. Now we use the fuzzy entropy to measure the fuzziness of rough sets. Information entropy is a widely adopted method to measure the fuzziness in general fuzzy sets. Imitating the definition of fuzzy entropy in general fuzzy sets, we haveDefinition 3.4Let X be a subset in the NS-space(U,NS(U)). The fuzzy entropy ofN(X), denoted byEFXN, is defined as:EFXN=1|U|∑j=1|U|sμFXN(xj)Hereinafter,s(x)satisfiess(x)=-xlog2x-(1-x)log2(1-x),x∈(0,1);0,x=0orx=1.The definition is produced by the Shannon information entropy of a probability distribution, so it is easy to prove the following proposition:Proposition 3.5Let X be a subset in the NS-space(U,NS(U)). The fuzzy entropyEFXNsatisfies the following properties:(1)0⩽EFXN⩽1;EFXN=0if and only if∀x∈U,μFXN(x)=0orμFXN(x)=1;EFXN=1if and only if∀x∈U,μFXN(x)=0.5.In any NS-space(U,NS(U)), we haveEFUN=EF∅N=0.Let X be a subset in the NS-space(U,NS(U)). We haveEFXN=EFXCN.The proof is straightforward by Proposition 3.5 and Definition 3.4.□Note that if∀x∈U,μFXN(x)=1impliesx∈POSN(X), orμFXN(x)=0impliesx∈NEGN(X). Based on Proposition 3.1, that isBNN(X)=∅. So based on (2) in Proposition 3.5, we can further obtain Proposition 3.6 as follows.Proposition 3.6The fuzzy entropy of the crisp set in the NS-space(U,NS(U))is 0.LetN(X)=(X,X)be a crisp set in(U,NS(U)). IfX=∅orU,N(X)is exact obviously; If∅⊂X⊂U,∀x∈U,x∈AX1orx∈AX4. In any case,s(x)=0. ThereforeE(FXN)=0.□After analyzing the fundamental properties of the fuzzy entropy, we can investigate whether the fuzzy entropy can evaluate the uncertainty of NS-based rough sets. As a granular computing theory, the uncertainty measure of NS-based rough sets should reflect the degree of the granulation comprehensively. Note that if the boundary regions remain unchanged and the positive regions or the negative regions become finer or coarser in their interiors, the measure should remain unchanged. We can prove the fuzzy entropy satisfies these rules in the following proposition.Proposition 3.7Let(U,NS1(U))and(U,NS2(U))be two NS-spaces. Then∀X⊆U, the fuzzy entropyEFXN1andEFXN2satisfy the following properties:(1)EFXN1=EFXN2, ifBNN1(X)=BNN2(X)and∀x∈BNN1(X),μFXN1(x)=μFXN2(x)orμFXN1(x)=1-μFXN2(x);EFXN1⩽EFXN2, if∀x∈U,μFXN1(x)-0.5⩾μFXN2(x)-0.5. Here|·|denotes the absolute value sign.(1)IfBNN1(X)=BNN2(X)and∀x∈BNN1(X),μFXN1(x)=μFXN2(x)orμFXN1(x)=1-μFXN2(x), based on Definition 3.4,sμFXN1(x)=sμFXN2(x)andsμFXN1(x′)=sμFXN2(x′)=0,∀x′∈U-BNN2(X). ThereforeEFXN1=EFXN2.The proof is straightforward by Definition 3.4.□The following example illustrates the results of the above theorem.Example 3.3Continued from Example 3.2According to Definition 3.4 we haveEFXN=0.33.If we changeNS(x2)in Example 3.2 toNS′(x2)={{x1,x2,x4},{x2,x3}}, and changeNS(x6)toNS′(x6)={{x5,x6},{x4,x5,x6}}and the rest keep unchanged, thenApr̲′(X)=Apr̲(X)={x1,x2},Apr‾′(X)=Apr‾(X)={x1,x2,x3,x4}. Obviously, the new NS satisfiesBNN′(X)=BNN(X). FollowingAX1′={x1,x2},AX2′={x3},AX3′={x4},AX4′={x5,x6}, the fuzzy entropy isEFXN′=EFXN=0.33, which meets the uncertainty measure does not change if the boundary region does not change.If we changeNS(x2)in Example 3.2 toNS″(x2)={{x1,x2,x4},{x2,x3,x4,x6},{x2,x5}}, and changeNS(x5)toNS″(x5)={{x2,x5},{x3,x5,x6},{x3,x5}}and the rest keep unchanged, thenApr̲″(X)={x1},Apr‾″(X)={x1,x2,x3,x4,x5}. SoNS″(U)⪰NS(U). FollowingAX1″={x1},AX2″={x2,x3},AX3″={x4,x5},AX4″={x6}, the fuzzy entropy isEFXN″=0.66>EFXN=0.33, which meets the coarser granularity, the larger fuzzy entropy.The above example reflects the uncertainty measures of NS-based rough sets. However, when the NS-spaces degenerate into covering approximation spaces, partition approximation spaces even crisp spaces, does the method meet people’s cognitive rules? The following example can verify the method is effective.Example 3.4SupposeU={x1,x2,x3,x4,x5,x6},X={x2,x4,x6}andC={Ci|i=1,2,…,6}satisfiesC1={x1,x2,x3,x5,x6},C2={x2,x3,x6},C3={x2,x3,x4,x5,x6},C4={x4,x6},C5={x5}andC6={x6}. Obviously⋃i=16Ci=U, so(U,C)is a covering approximation space.Based on the relationship of the covering approximation space and the NS-space, we can defineNS1(x1)={C1},NS1(x2)={C1,C2,C3},NS1(x3)={C1,C2,C3},NS1(x4)={C3,C4},NS1(x5)={C1,C3,C5}, andNS1(x6)={C1,C2,C3,C4,C6}.(U,NS1(U))is a NS-space. ThenApr1̲(X)={x4,x6}andApr1‾(X)={x1,x2,x3,x4,x6}. By Definitions 3.3 and 3.4, we haveEFXN1=0.49.Now we refine the above covering approximation space into the partition space(U,K)based on the equivalence relation K. Herein,U/K={{x1},{x2,x3},{x4},{x5},{x6}}.Based on the relationship of the partition space and the NS-space, we can defineNS2(x1)={{x1}},NS2(x2)={{x2,x3}},NS2(x3)={{x2,x3}},NS2(x4)={{x4}},NS2(x5)={{x5}}, andNS2(x6)={{x6}}.(U,NS2(U))is also a NS-space. Furthermore,Apr2̲(X)={x4,x6},Apr2‾(X)={x2,x3,x4,x6}. SoEFXN2=0.33<0.49=EFXN1.If we continue to refine the partition space into the crisp space, we can obtainNS3(x1)={{x1}},NS3(x2)={{x2}},NS3(x3)={{x3}},NS3(x4)={{x4}},NS3(x5)={{x5}}, andNS3(x6)={{x6}}.(U,NS3(U))is also a NS-space. Furthermore,Apr3̲(X)=Apr3‾(X)={x2,x4,x6}. Hence,EFXN3=0<EFXN2<EFXN1.The example also shows the fuzzy entropy can reflect the degree of granulation in GrC Models.Intuitionistic Fuzzy Set (IFS) as a generalization of Zadeh’s fuzzy sets was first proposed by Atanassov [1,2]. As a general GrC Model, a NS can allow two information granules to intersect with each other. IFS theory defines a pair of intuitionistic membership functions which include a membership degreeμ(x)and a non-membership degreeν(x). In addition it models the hesitancy degreeπ(x)=1-μ(x)-ν(x)to reflect the tolerance relation. Thus, it has more advantages to deal with the vagueness. In this subsection, we use IFSs to represent NS-based rough sets.By Definition 2.2 we havex∈BN(X), if∀N(x)∈NS(x),N(x)∩X≠∅andN(x)∩XC≠∅. Since the influence by each binary relation, the fuzzy entropy ofN(x)could not fully reflect the roughness degree ofN(x)in every NS. Hence we propose the following concept of rough intuitionistic membership function.Definition 4.1Let X be a subset in the NS-space(U,NS(U)).∀x∈U, the rough intuitionistic membership function〈μIFXN(x),νIFXN(x)〉of x with respect to X is defined as follows:μIFXN(x)=1,x∈AX1,⋀i=1mNi(x)⋂X|Ni(x)|Ni(x)∈NS(x),x∈AX2∪AX3,0,x∈AX4.νIFXN(x)=0,x∈AX1,1-⋁i=1mNi(x)⋂X|Ni(x)|Ni(x)∈NS(x),x∈AX2∪AX3,1,x∈AX4.According to Definition 4.1 we can transform the rough setN(X)into the IFSIFXN=(x,μIFXN(x),νIFXN(x))|x∈U. An IFS can not only provide the evidence about supportingx∈X, (i.e. the membership degreeμIFXN(x)), but also give the evidence about opposingx∈X, (i.e. the non-membership degreeνIFXN(x)). At the same time, it produces the hesitancy degreeπIFXN(x). Since the rough intuitionistic fuzzy membership degrees can fully consider the proportion of target rough set in multi-granular spaces, it therefore can reflect the roughness in NS-spaces more accurately.It is easy to prove the following properties about rough intuitionistic membership functions.Proposition 4.1Let X be a subset in the NS–space(U,NS(U))andIFXNbe the IFS produced byN(X). Then the following conclusions are founded:(1)x∈POSN(X), if and only ifμIFXN(x)=1,νIFXN(x)=0;x∈BNN(X), if and only if0<μIFXN(x)<1,0<νIFXN(x)<1;x∈NEGN(X), if and only ifμIFXN(x)=0,νIFXN(x)=1.According to Definition 4.1 we can obtainμIFXN(x1)=μIFXN(x2)=1,μIFXN(x3)=0.33,μIFXN(x4)=0.33,μIFXN(x5)=μIFXN(x6)=0;νIFXN(x1)=νIFXN(x2)=0,νIFXN(x3)=0.33,νIFXN(x4)=0.33,νIFXN(x5)=νIFXN(x6)=1.Let X be a subset in the NS-space(U,NS(U))andIFXNbe the IFS produced byN(X). If∀x∈U, the NS of x contains the single neighborhood of x, thenIFXNcan degenerate into the classical fuzzy set.The proof is straightforward by Definition 4.1.□Let X be a subset in the NS-space(U,NS(U)). We have(IFXN)C=IFXCN.Ifx∈AX1,x∈AXC4. ObviouslyμIFXN(x)=νIFXCN(x)=1andνIFXN(x)=μIFXCN(x)=0. It can be similarly proved whenx∈AX4.Ifx∈AX2,x∈AXC3or ifx∈AX3,x∈AXC2. In any case,∀Ni(x)∈NS(x),Ni(x)⋂X|Ni(x)|+Ni(x)⋂XC|Ni(x)|=1. SoμIFXCN(x)=⋀i=1mNi(x)⋂XC|Ni(x)|=⋀i=1m1-Ni(x)⋂X|Ni(x)|=1-⋁i=1mNi(x)⋂X|Ni(x)|=νIFXN(x)andνIFXCN(x)=1-⋁i=1mNi(x)⋂XC|Ni(x)|=⋀i=1m1-Ni(x)⋂XC|Ni(x)|=⋀i=1mNi(x)⋂X|Ni(x)|=μIFXN(x).Hence, Proposition 4.3 is proved.□For any two subsets X and Y in the NS-space(U,NS(U)), the following holds:(1)IFX⋃YN⊇IFXN⋃IFYN;IFX⋃YN=IFXN⋃IFYNif and only ifX⊆YorY⊆X;IFX⋂YN⊆IFXN⋂IFYN;IFX⋂YN=IFXN⋂IFYNif and only ifX⊆YorY⊆X.We only proveIFX⋃YN⊇IFXN⋃IFYNand the rest conclusion can be proved in the similar way.Ifx∈AX1orx∈AY1, then∃N(x)∈NS(X),N(x)⊆X⋃Y,x∈A(X⋃Y)1. SoμIFX⋃YN(x)=1andνIFX⋃YN(x)=0. Moreover,μIFXN⋃IFYN(x)=max{μIFXN(x),μIFYN(x)}=1andνIFXN⋃IFYN(x)=min{νIFXN(x),νIFYN(x)}=0.Ifx∈AX4andx∈AY4, then∀N(x)∈NS(x),N(x)⋂(X⋃Y)=∅, i.e.x∈A(X⋃Y)4. SoμIFX⋃YN=0andνIFX⋃YN=1. Furthermore,μIFXN⋃IFYN(x)=0andνIFXN⋃IFYN(x)=1.In other cases, sinceμIFX⋃YN(x)=⋀i=1mNi(x)⋂(X⋃Y)|Ni(x)|=⋀i=1mNi(x)⋂X⋃Ni(x)⋂Y|Ni(x)|⩾⋀i=1mmaxNi(x)⋂X,Ni(x)⋂Y|Ni(x)|=max⋀i=1mNi(x)⋂X|Ni(x)|,⋀i=1mNi(x)⋂Y|Ni(x)|⩾maxμIFXN(x),μIFYN(x),andνIFX⋃YN(x)=1-⋁i=1mNi(x)⋂X⋃Y|Ni(x)|=1-⋁i=1mNi(x)⋂X⋃Ni(x)⋂Y|Ni(x)|⩽1-⋁i=1mmaxNi(x)⋂X,Ni(x)⋂Y|Ni(x)|=min1-⋁i=1mNi(x)⋂X|Ni(x)|,1-⋁i=1mNi(x)⋂Y|Ni(x)|⩽minνIFXN(x),νIFYN(x),Hence,IFX⋃YN⊇IFXN⋃IFYN.□According to the rough intuitionistic membership functions, we can construct the reasonable uncertainty measures of NS-based rough sets. As an IFS includes a membership function and a non-membership function, the nature of its entropy is very distinct with the classical fuzzy entropy. For this issue, some literatures defined entropy measures based on distance measures [28,43,30,36,37], and some other literatures transformed IFSs into classical fuzzy sets, and then used the classical fuzziness methods [9,20,22]. Generally, the existing methods can characterize the nature of IFSs at some extent. For example, Zhang [38] proposed the fuzzy entropy based on integral calculus, and showed the result was more exact and reasonable. In this paper, we also adopt this method in the following discussion.Definition 4.2Let X be a subset in the NS-space(U,NS(U)). The intuitionistic fuzzy entropy ofN(X), denoted byIEIFXN, is defined as:IE(IFXN)=1|U|∑i=1|U|h(xi)Hereh(x)=1πIFXN(x)∫μIFXN(x)1-νIFXN(x)s(t)dt,πIFXN(x)≠0,sμIFXN(x),πIFXN(x)=0,andπIFXN(x)=1-μIFXN(x)-νIFXN(x).According to [38], we have the following properties.Proposition 4.5Let X be a subset in the NS-space(U,NS(U)). The intuitionistic fuzzy entropyIEIFXNsatisfies the following properties:(1)0⩽IEIFXN⩽1;IEIFXN=0if and only if∀x∈U,μIFXN(x)=0andνIFXN(x)=1, orμIFXN(x)=1andνIFXN(x)=0, that isIFXNdegenerates into a crisp set;IEIFXN=1if and only if∀x∈U,μIFXN(x)=νIFXN(x)=0.5.In any NS-space(U,NS(U)), we haveIEIFUN=IEIF∅N=0.Let X be a subset in the NS-space(U,NS(U)). We haveIEIFXN=IEIFXCN.IEIFXNdegenerates into the classical fuzzy entropy inDefinition 3.4if∀x∈U,πIFXN(x)=0.The proposition as well as Proposition 4.2 is very important to connect the rough fuzzy entropy with the rough intuitionistic fuzzy entropy.Proposition 4.7Let(U,NS1(U))and(U,NS2(U))be two NS-spaces. Then∀X∈U, the intuitionistic fuzzy entropyIEIFXN1andIEIFXN2satisfy the following properties:(1)IEIFXN1=IEIFXN2, ifBNN1(X)=BNN2(X)and one of the following conditions holds:(i)∀x∈BNN1(X),μIFXN1(x)=μIFXN2(x)andνIFXN1(x)=νIFXN2(x);∀x∈BNN1(X),μIFXN1(x)=νIFXN2(x)andνIFXN1(x)=μIFXN2(x).IEIFXN1⩽IEIFXN2, if∀x∈U,(1)The proof is straightforward by Definition 4.2.IfπIFXN1(x)=πIFXN2(x)=0, the conclusion can be proved by Proposition 3.7.IfπIFXN1(x)=πIFXN2(x)=C>0, the intuitionistic fuzzy entropy is decided by∫μIFXN(x)1-νIFXN(x)s(t)dt. Sinces(t)is a monotonously increasing function in[0,0.5]and a monotonously decreasing function in[0.5,1]. IfπIFXN(x)keeps unchanged,∫μIFXN(x)1-νIFXN(x)s(t)dtreaches the maximum value if and only ifμIFXN(x)=νIFXN(x). Besides that, whenμIFXN(x)⩽νIFXN(x),∫μIFXN(x)1-νIFXN(x)s(t)dtis a monotonously increasing function aboutμIFXN(x); whenμIFXN(x)⩾νIFXN(x),∫μIFXN(x)1-νIFXN(x)s(t)dtis a monotonously decreasing function aboutμIFXN(x)(The specific analysis can be seen in [38]). Then we will discuss the four cases ofμIFXN1(x)-νIFXN1(x)⩾μIFXN2(x)-νIFXN2(x).(a)WhenμIFXN1(x)⩽νIFXN1(x)andμIFXN2(x)⩽νIFXN2(x), we haveνIFXN1(x)-μIFXN1(x)⩾νIFXN2(x)-μIFXN2(x). ConsideringμIFXN1(x)+νIFXN1(x)=μIFXN2(x)+νIFXN2(x), we haveμIFXN1(x)⩽μIFXN2(x).WhenμIFXN1(x)⩾νIFXN1(x)andμIFXN2(x)⩾νIFXN2(x), we haveμIFXN1(x)-νIFXN1(x)⩾μIFXN2(x)-νIFXN2(x). ConsideringμIFXN1(x)+νIFXN1(x)=μIFXN2(x)+νIFXN2(x), we haveμIFXN1(x)⩾μIFXN2(x).WhenμIFXN1(x)⩽νIFXN1(x)andμIFXN2(x)⩾νIFXN2(x), we have1-μIFXN2(x)⩽1-νIFXN2(x)andνIFXN1(x)-μIFXN1(x)⩾μIFXN2(x)-νIFXN2(x). ConsideringμIFXN1(x)+νIFXN1(x)=μIFXN2(x)+νIFXN2(x)=1-C, we haveμIFXN1(x)⩽νIFXN2(x)⩽μIFXN2(x)=1-C-νIFXN2(x)<1-νIFXN2(x).WhenμIFXN1(x)⩾νIFXN1(x)andμIFXN2(x)⩽νIFXN2(x), we have1-μIFXN1(x)⩽1-νIFXN1(x)andμIFXN1(x)-νIFXN1(x)⩾νIFXN2(x)-μIFXN2(x). ConsideringμIFXN1(x)+νIFXN1(x)=μIFXN2(x)+νIFXN2(x)=1-C, we haveνIFXN1(x)⩽μIFXN2(x)⩽νIFXN2(x)=1-C-μIFXN2(x)<1-μIFXN2(x).In any case,∫μIFXN1(x)1-νIFXN1(x)s(t)dt⩽∫μIFXN2(x)1-νIFXN2(x)s(t)dt. Hence,IEIFXN1⩽IEIFXN2.□.Let(U,NS(U))be a NS-space. Herein,U={xi|i=1,2,…,8},X={x1,x2,x3}. SupposeNS(x1)={{x1},{x1,x3},{x1,x6}};NS(x2)={{x1,x2,x3}};NS(x3)={{x1,x3,x6},{x3,x8},{x3,x6,x8}};NS(x4)={{x1,x4,x5,x6,x7,x8},{x2,x4,x5}};NS(x5)={{x2,x5},{x3,x5}};NS(x6)={{x6},{x5,x6},{x4,x5,x6}};NS(x7)={{x7},{x4,x7}};NS(x8)={{x8}}.We can deduceAX1={x1,x2},AX2={x3},AX3={x4,x5},AX4={x6,x7,x8}. Based on Definition 4.1 we haveμIFXN(x1)=μIFXN(x2)=1,μIFXN(x3)=0.33,μIFXN(x4)=0.17,μIFXN(x5)=0.5,μIFXN(x6)=μIFXN(x7)=μIFXN(x8)=0;νIFXN(x1)=νIFXN(x2)=0,νIFXN(x3)=0.33,νIFXN(x4)=0.67,νIFXN(x5)=0.5,νIFXN(x6)=νIFXN(x7)=νIFXN(x8)=1.Hence,IE(IFXN)=0.24.IfNS(x4)is changed toNS′(x4)={{x3,x4},{x1,x2,x4}}and the rest keep unchanged, the four parts also keep unchanged. ButμIFXN′(x4)=μIFXN(x4)=0.5andνIFXN′(x4)=νIFXN(x4)=0.33. So∀i=1,…,8,πIFXN(xi)=πIFXN′(xi)andμIFXN(x)-νIFXN(x)⩾μIFXN′(x)-νIFXN′(x). Based on Definition 4.2 we haveIEIFXN′=0.25>IE(IFXN), which continues to satisfy people’s recognition rules.In this section we use the real databases Iris in Table 5.1and Abalone in Table 5.2from UCI to show the effectiveness of the two uncertainty measures proposed in this paper.LetI=〈U,C∪d,V,f〉be a neighborhood information system, in which U is a nonempty finite universe;C={ai|i=1,2,…n}is a family of conditional attributes; d is decision attribute which provides the partitionU/d={d1,d2,…,dm};V=⋃ai∈CVaiis the union of attribute domains; and f is an information function wheref(x,ai)∈Vaifor eachx∈Uand eachai∈C.Based on a distance function we give the simplify calculating method for constructing a neighborhood. For any attributeaiand any element x, defineNi(x)={y||f(x,ai)-f(y,ai)|⩽δ}is the neighborhood of x. ThenNS(x)={Ni(x)|i=1,2,…,n}.The rough set ofdj(j=1,2,…,m)in(U,NS(U))is defined asApr̲(dj)=x∈U|∃N(x)∈NS(x),N(x)≠∅∧N(x)⊆dj;Apr‾(dj)=x∈U|∀N(x)∈NS(x),N(x)∩dj≠∅.Hence, based on Definition 3.4 the fuzzy entropy with respect toU/dis defined asEFU/dN=1m∑j=1mEFdjN.Meanwhile by Definition 4.2 the intuitionistic fuzzy entropy with respect toU/dis defined asIEIFU/dN=1m∑j=1mIEIFdjN.In order to demonstrate the advantages of the uncertainty measures, we design to choose l conditional attributes from C randomly for composing a selected sub-neighborhood system every time, where l increases from 1 to n.Suppose the distance parametersδ=0.2for fuzzy entropy andδ=0.5for intuitionistic fuzzy entropy in Iris Database. The two uncertainty measures of Iris are shown in Fig. 5.1. At the same time note that in Abalone the magnitudes of different attributes are very different. We first normalized all data based on every conditional attribute. Then suppose the distance parametersδ=0.18for fuzzy entropy andδ=0.1for intuitionistic fuzzy entropy in Abalone Database. The two uncertainty measures of Abalone are shown in Fig. 5.2.It is easy to observe the two uncertainty measures of two databases are decreasing with increasing the numbers of selected attributes, which shows they can evaluate the uncertainty of rough sets accurately. Furthermore, from Fig. 5.1 we find the two uncertainty measures almost keep unchanged when the number of attributes increases from 3 to 4 in Iris. In addition, the fuzzy entropies of Abalone are almost unchanged when the number of attributes increases after 3, while the intuitionistic fuzzy entropy is decreasing until the cardinality of selected attributes is over 4 by Fig. 5.2. In comparison, the intuitionistic fuzzy entropy looks a little better, since it can provide more information for evaluating the uncertainty of NS-based rough sets.

@&#CONCLUSIONS@&#
In this paper, we propose the fuzzy entropy and the intuitionistic fuzzy entropy as the two uncertainty measures of NS-based rough sets.Different from the rough entropy and the granular entropy, we investigate the relationship between the elements in NS-spaces and construct the fuzzy sets and the intuitionistic fuzzy sets. Then we use the fuzzy entropy and the intuitionistic fuzzy entropy to measure the uncertainty. Examples show our methods are effective and useful to capture the uncertainty.In future studies, we will discuss how to construct the fuzzy set in the case of infinite universes and general relational structure (Relational GrC Model). The attribute reduction in neighborhood information systems by the fuzzy entropy and the intuitionistic fuzzy entropy also need development.