@&#MAIN-TITLE@&#
Solving 0-1 knapsack problem by greedy degree and expectation efficiency

@&#HIGHLIGHTS@&#
The idea based on region partition of items for solving 0-1 knapsack problem.Greedy degree algorithm for putting some items into knapsack early.Dynamic expectation efficiency model for obtaining the candidate objective function value.Static expectation efficiency model for updating the objective function value.The proposed algorithm in this paper has correctness, feasibility, effectiveness, and stability.

@&#KEYPHRASES@&#
Economics,Region partition,Greedy degree,Expectation efficiency,Parallel computing,

@&#ABSTRACT@&#
It is well known that 0-1 knapsack problem (KP01) plays an important role in both computing theory and real life application. Due to its NP-hardness, lots of impressive research work has been performed on many variants of the problem. Inspired by region partition of items, an effective hybrid algorithm based on greedy degree and expectation efficiency (GDEE) is presented in this paper. In the proposed algorithm, initially determinate items region, candidate items region and unknown items region are generated to direct the selection of items. A greedy degree model inspired by greedy strategy is devised to select some items as initially determinate region. Dynamic expectation efficiency strategy is designed and used to select some other items as candidate region, and the remaining items are regarded as unknown region. To obtain the final items to which the best profit corresponds, static expectation efficiency strategy is proposed whilst the parallel computing method is adopted to update the objective function value. Extensive numerical investigations based on a large number of instances are conducted. The proposed GDEE algorithm is evaluated against chemical reaction optimization algorithm and modified discrete shuffled frog leaping algorithm. The comparative results show that GDEE is much more effective in solving KP01 than other algorithms and that it is a promising tool for solving combinatorial optimization problems such as resource allocation and production scheduling.

@&#INTRODUCTION@&#
Knapsack problem (KP) is known as a well-studied combinatorial optimization problem and it has been thoroughly studied in the past decades. Generally speaking, KP is classified into separable KP (SKP) in which the items can be split arbitrarily and 0-1 KP (KP01) in which the items cannot be split. KP01 is an important type of KP due to its NP-hardness [1] and it offers many practical applications such as capital budgeting, project selection, resource allocation, cutting stock, investment decision-making, etc. [2]. Therefore, more and more researchers have paid attention to the problem of KP01 optimization. Especially, Martello gave a comprehensive review with further discussions on techniques commonly used in solving KP01 [3]. Since KP01 has been proven to be NP-hard, the methods employed to solve KP01 have been divided into three categories, i.e., exact methods with the exact solutions, meta-heuristic methods and heuristic methods with the approximate solutions.About exact methods, some related research has been carried out. In [4], dynamic programming algorithm was proposed to solve KP01. And then, Rong [5] developed dynamic programming algorithm according to state reduction and Figueira [6] used many complementary dominance relations to improve dynamic programming algorithm. Kolesar [7] proposed branch and bound algorithm to solve KP01 in 1967. Later, Horowitz [8], Martello [9], and Pisinger [10] respectively expanded branch and bound algorithm in 1974, 1981, and 1993. In [11], the procedure based on linear mathematical programming formulation was proposed. In [12], a Lagrangian decomposition based algorithm was proposed. In [13], an algorithm based on surrogate, Lagrangian, and continuous relaxations was proposed. In [14], an algorithm with a single continuous variable for KP01 was proposed. Although they can produce the optimal solutions in solving small-scale problems, these exact algorithms perform poorly when the scale comes to be large.In recent decades, many computational intelligence methods [15] have been developed and regarded as meta-heuristic algorithms to solve KP01. In [16], a global harmony search algorithm was proposed. In [17], Zhang proposed a harmony search algorithm while it adopted the parallel updating strategy rather than serial updating strategy. In [18], Kong proposed a simplified binary harmony search algorithm for large scale KP01. In [19], an algorithm based on amoeboid organism was proposed by transforming the longest path into the shortest path. In [20], a quantum-inspired artificial immune system for KP01 was proposed. In [21], an improved hybrid encoding cuckoo search algorithm was proposed. In [22], a shuffled frog leaping algorithm was proposed. In [23], a particle swarm-based algorithm was proposed. In [24], a human learning optimization algorithm was proposed. In [25], a DNA-based computing method was proposed with fast parallel molecular. Although meta-heuristics can effectively solve KP01, they have to undergo the complex iteration process and set different number of populations with different instances. With that said, it will increase the difficulty of solving KP01, for example, the number of populations for a certain KP01 instance is difficult to set. Furthermore, the complex iteration process is not adapted to the optimization of engineering problem.It becomes increasingly popular for the researchers worldwide to apply heuristic techniques in the optimization problems [26]. Given this, there are a number of effective heuristics for solving KP01. In [27], a hybrid differential evolution approach was studied. In [28], a polyhedral study with disjoint cardinality constraints was proposed. In [29], a population-based incremental learning algorithm based on greedy strategy was presented. In [30], a chemical reaction optimization algorithm with greedy strategy was proposed. In [31], an efficient fully polynomial time approximate scheme for KP01 was proposed. In [32], an iterative rounding search based algorithm was proposed to solve KP01. In [33], a soccer league competition algorithm was proposed. In [34], a thermodynamical selection based discrete differential evolution method was presented. However, they still cost the high time complexity especially in [27–29] and [31]. Thus, an expectation efficiency based on economical model was studied [35] and the time complexity was O(n), which suggested that the expectation efficiency model for solving KP01 is more effective compared to other existing heuristics. In this paper, the expectation efficiency will be studied by combining with greedy degree.Although a large number of KP01s have been resolved successfully by these existing algorithms, some new and more difficult KP01s are always hidden in the real world. Thus, the research on KP01 should be further improved and developed. Furthermore, especially in the industry, it usually focuses on finding the good approximate solution rather than spending a lot of time for the exact solution. Under this context, heuristic methods for KP01 will play more important role than exact methods and meta-heuristic methods. Given this, the heuristic methods should be encouraged so that the optimization and application of KP01 can be enhanced.Given the above consideration, a hybrid algorithm based on greedy degree and expectation efficiency, called GDEE, is proposed which is inspired by region partition of items to solve KP01. The main contributions of this paper are summarized as follows. (a) A greedy degree model inspired by greedy strategy is designed to select the first some items to put into knapsack early and these items are never removed from knapsack in the following operations. (b) A dynamic expectation efficiency strategy is proposed to select some remaining items to put into knapsack, meanwhile, one candidate objective function value is obtained. (c) A static expectation efficiency strategy is also presented as the benchmark to update the candidate objective function value, as a result, a number of new objective function values are generated. (d) To accelerate the update speed of objective function value, the parallel computing method is adopted. (e) Experimental results based on a large number of instances reveal that GDEE is correct, feasible, effective, and stable.The rest of this paper is organized as follows. Section 2 presents the design of GDEE in detail. In Section 3, experimental results based on a large number of instances are reported. Finally, Section 4 concludes this paper and suggests potential future work.Given n items, where item i owns weightwiand profit pi, and a knapsack that holds a fixed capacity cap, the goal of KP01 is to load some possible items into knapsack so that the total profit of the selected items has the maximal value while the total weight of the items is not larger than cap. Mathematically, KP01 can be described as follows.(1)Maximizeoptp=∑i=1npixis.t.∑i=1nwixi≤capwhere optp means the objective function value and xi∈{0, 1}. If xiis 1, item i is in knapsack; otherwise, it is not in knapsack. Let X=(x1, x2, …, xn) means the solution of KP01. Thus, the goal of KP01 is to find a possible X which maximizes optp.Let ridenote the ratio of piandwi. In this paper, n items are rearranged by riin descending order in the first place, which is also done under greedy strategy, backtracking algorithm, and dynamic programming algorithm. Thus, the arrangement will be executed before performing the following GDEE operations. It is well known that greedy algorithm is applied to solve KP01 at the beginning and the obtained solution is local optimal rather than the optimal. As a matter of fact, some items can be still loaded into knapsack from the perspective of greedy algorithm, in other words, the items are determinate while the remaining items are uncertain. Based on this consideration, the determinate items should be loaded into knapsack in advance and never be removed from knapsack. However, how many and which items are determinate? To answer this question, the concept of greedy degree is proposed as follows.Definition 1n items are rearranged, if the first m items can be always loaded into knapsack by greedy strategy, and then m is regarded as the size of greedy degree.The objective function value, the total weight of items, and the number of items can be obtained by greedy algorithm. Let Goptp, GW, and Q represent them respectively, and the constraint conditions are shown as follows.(2)∑i=1jwiGW∧∑i=1jpiGoptp≤λ∑i=1j+1wiGW∧∑i=1j+1piGoptp>λ∑i=1n/2wi+∑i=n/2+1jwiGW∧∑i=1n/2pi+∑i=n/2+1jpiGoptp<ξ∑i=1n/2wi+∑i=n/2+1j+1wiGW∧∑i=1n/2pi+∑i=n/2+1j+1piGoptp≥ξwhere λ and ξ are parameters, λ>ξ and λ, ξ∈(0, 1); j is the serial number of item; X∧Y≤Z means that X≤Z and Y≤Z. Right after this, the greedy degree algorithm is designed and described in Algorithm 1.Algorithm 1Greedy degree algorithmInput:W, P, n and cap//W=(w1,w2,…,wn),P=(p1,p2,⋯,pn)Output:mRun greedy algorithm;Obtain Goptp, GW and Q;whileQ<n/2, don=n/2;end whilewhile inequality (2) is met, dom=j;end whileIn Algorithm 1, the first m items should be loaded into knapsack, and they constitute initially determinate region.The following work is to select some items from the remaining (n-m) items as candidate region (e.g., for ten items, among them, the first four items are loaded into knapsack in advance, and m is four. If the optimal solution consists of eight items, the following is to select four items from the remaining six items as candidate region). In economics, there is a classical expectation efficiency theory which was proposed in 1979 [36] and developed in 1992 by Kahneman and Tversky [37]. It can be applied to wide fields such as stock prediction, psychoanalysis, live-hood economy, etc. Western economics suggests that expectation efficiency can be used to solve the uncertain problem and the expectation results are acceptable [35]. In this paper, it will be treated as a heuristic method to solve KP01, in which the most basic idea is to expect the property of the next item by that of the current item. Let f(i) represent the expectation efficiency of item i, and it is shown as follows.(3)f(i)=picap−∑k=1i−1wk/wicap−∑k=1i−1wkpi−1/wi−1=riri−1Here, f(i) means the potential of item i that can be loaded into knapsack. And, the larger the item expectation efficiency value is, the higher the possibility of the item loaded into knapsack is. To illustrate Eq. (3), an instance KP1 is given in Table 1.In KP1, the first two items are loaded into knapsack early by Algorithm 1, and m is two. Then, f(3), f(4) and f(5) can be obtained by Eq. (3), and they are 0.88, 0.9680 and 0.9783 respectively. Since f(5) is the largest of all, the fifth item should be loaded into knapsack. At last, X=(1, 1, 0, 0, 1) and optp=92 can be obtained. With that said, Eq. (3) may be a nice model.If p5 is 47 not 50 in KP1, then f(5) is changed to 0.9196. In this case, f(4) is the largest of all, and the fourth item should be loaded into knapsack. In similar way, X=(1, 1, 0, 1, 0) and optp=88 can be obtained. However, the optimal solution is still (1, 1, 0, 0, 1) and optp is 89 rather than 88. With this said, Eq. (3) may be not a nice model.The optimal solution of KP01 is related to n,w, p, cap, and i, which can be seen from Eq. (1); and it is also related to r, which can be seen from Eq. (3). Thus, a model involves the six factors should be designed to replace Eq. (3), as follows.(4)f(i,w,p,r,n,cap)∝i,w,p,r,n,capThe following work is to make a concrete model for Eq. (4) due to its abstraction. The remaining capacity of knapsack tends to zero more and more with the item loaded into knapsack one by one. If the item (i−1) is in knapsack and the remaining capacity of knapsack is larger than zero, then the expectation profit which the remaining capacity of knapsack refers to ri−1 can be obtained. Let optp′ represent it, as follows.(5)pi−1wi−1=optp′cap−∑k=1mwk−∑k=m+1i−1wkxk(6)optp′=ri−1cap−∑k=1mwk−∑k=m+1i−1wkxkIt is certain that optp′ is far larger than pi. In order to balance the difference between them, use the average of optp′ subtract pi. The result is Δp, as follows.(7)Δp=ri−1cap−∑k=1mwk−∑k=m+1i−1wkxkn−i+1−piGiven Eqs. (5)–(7), Eq. (4) is defined as follows.(8)Df(i,w,p,r,n,cap)=riri−1*ri−1cap−∑k=1mwk−∑k=m+1i−1wkxk−(n−i+1)picap−∑k=1mwk−∑k=m+1i−1wkxk−(n−i+1)wi,m+1≤i≤nEq. (8) can be converted to Eq. (9) by symbolic substitution.(9)Df(i,w,p,r,n,cap)=f(i)*Ari−1−BA−C,m+1≤i≤nA=cap−∑k=1mwk−∑k=m+1i−1wkxkB=(n−i+1)piC=(n−i+1)wiAmong them,Df(i,w,p,r,n,cap)represents dynamic expectation efficiency function, A represents the remaining capacity of knapsack, Ari−1 represents expectation profit that refers to ri−1, (Ari−1−B) represents the difference between the average of the expectation profit and the profit of the current item, and (A−C) represents the difference between the average of the remaining capacity of knapsack and the weight of the current item. (Ari−1−B) and (A−C) have the balance function on Eq. (8). For Eq. (8), (n−m) dynamic expectation efficiency values can be obtained, and they are denoted by Df(m+1), Df(m+2), …, Df(n).It must be noted that A should be still larger than or equal to zero. Otherwise, some items that are from items (m+1) to n should be removed from knapsack in turn until A≥0. Since Ari−1 is always changing, the expectation process is dynamic. Based on Eq. (8), the candidate region of items can be obtained, as a result, the corresponding candidate objective function value can be also obtained, denoted by Doptp which can be obtained by Algorithm 2 as follows.Algorithm 2Dynamic expectation efficiency algorithmInput:W, P, n, m and capOutput:DoptpInitially:xk=1, 1≤k≤nfork=m+1 to n, doObtain dynamic expectation efficiency values by Eq. (8);whileA<0, doDf(l)=min{Df(m+1), Df(m+2), …, Df(k)};xl=0, m+1≤l≤k;Df(l)=min{{Df(m+1), Df(m+2), …, Df(k)}/Df(l)};//{X, Y, Z}/X means that X is removed from {X, Y, Z}end whileObtain dynamic expectation efficiency values by Eq. (8);ifA==0, thenEnd Algorithm 2;end ifend forfors=m+1 to n, doifxs==1, thenSelect Df(s) and item s;Arrange Df(m+1), Df(m+2), …, Df(s) in descending order;elseDf(s)=0;end ifend forforj=1 to τ, do//τ is the number of items loaded into knapsack from item (m+1) to item nPut item that owes the larger Df into knapsack;Doptp=Moptp + the profit of the current item;end forIn Algorithm 2, some items from (m+1) to n are selected as the candidate region, at the same time, the unknown region is also accomplished. If the candidate region contains u items, then the unknown region contains (n−m−u) items.Doptp obtained by Algorithm 2 cannot be regarded as the best profit, and thus a static expectation efficiency model will be proposed to update it. At first, the range of the best profit is presented and shown in Theorem 1.Theorem 1Let Uoptp=Goptp+pQ+1, and the best profit is in [Goptp, Uoptp).Reduction to absurdity for the proof is adopted.(a)Goptp is one objective function value obtained by greedy algorithm. It's obvious that it is less than or equal to the best profit.Suppose the best profit is equal to Uoptp. The item (Q+1) should be loaded into knapsack when greedy algorithm is run, and Goptp should be equal to Uoptp, which conflicts with Uoptp=Goptp+pQ+1.Suppose the best profit is larger than Uoptp. In similar way, the item (Q+1) should be loaded into knapsack when greedy algorithm is run. It's obvious that Goptp≥Uoptp, which also conflicts with Uoptp=Goptp+pQ+1.To sum up (a)–(c), Theorem 1 is proved.In Section 2.3, the dynamic expectation efficiency model has been introduced, in which Ari−1 is always changing in Eq. (8) when expectation efficiency value is computed. Doptp is one candidate objective function value and that Doptp is equal to the best profit is uncertain, hence it needs to be updated. Given this, one static expectation efficiency model is proposed which is inspired by keeping Ari−1 unchanged in Eq. (8), and it is defined as follows.(10)Sf(i,w,p,r,n,cap,t)=riri−1*optp(t)−∑k=1mwk−∑k=m+1i−1wkxk−(n−i+1)picap−∑k=1mwk−∑k=m+1i−1wkxk−(n−i+1)wi,m+1≤i≤nwhereSf(i,w,p,r,n,cap,t)represents static expectation efficiency function, and optp(t) is defined as follows.(11)optp(t)=Doptp+tThe best profit is in [Goptp, Uoptp) according to Theorem 1. And because the updating process of objective function value should provide the good efficiency, the objective function value that will be obtained by static expectation efficiency model should not be less than Doptp. Based on this, the constraint conditions are shown as follows.(12)Doptp≤optp(t)<Uoptp,Doptp<GoptpGoptp≤optp(t)<Uoptp,Doptp≥GoptpLet Eq. (11) be into inequality (12), as follows.(13)0≤t<Uoptp−Doptp,Doptp<GoptpGoptp−Doptp≤t<Uoptp−Doptp,Doptp≥Goptpwhere t is a positive integer variable. Let it be into Eq. (10) and Eq. (11) with one step length, and many new objective function values will be obtained (please see Section 2.5 for more details). If t keeps unchanged, then optp(t) is certain.For one new objective function value, denoted by NSoptp, it can be obtained by static expectation efficiency model, meanwhile, (n−m) static expectation efficiency values can be obtained, denoted by Sf(m+1), Sf(m+2), …, Sf(n). Based on the above, NSoptp can be obtained by Algorithm 3 as follows.Algorithm 3Static expectation efficiency algorithm/*The principle of Algorithm 3 is similar to Algorithm 2.The differences are summarized as (a) the running equation and (b) the checking constraint condition.(a) Eq. (8) is run in Algorithm 2, and Eq. (10) is run in Algorithm 3.(b) A is checked in Algorithm 2, and T is checked in Algorithm 3.*/T is shown as follows.(14)T=optp(t)−∑k=1mwk−∑k=m+1i−1wkxkIn Algorithm 3, one new objective function value can be obtained to replace candidate objective function value by Algorithm 2.A number of new objective function values can be obtained when t changes. The number of new objective function values is denoted by N, and it is shown as follows.(15)N=Uoptp−Doptp,Doptp<GoptpUoptp−Goptp,Doptp≥GoptpIf these new objective function values are computed with the serial method, then a lot of time will be consumed. Thus, the parallel computing method is adopted in this paper. In other words, the candidate objective function value is updated by Algorithm 3 with different t synchronously. The process of updating objective function value with the serial method and parallel method are depicted in Fig. 1, where the update of objective function value is accomplished with the serial way by N rounds while that is accomplished with the parallel way by one round.If Doptp<Goptp, then N new objective function values are NSoptp(0), NSoptp(1), …, NSoptp(Uoptp−Doptp−1). The best profit is denoted by Boptp, and it can be obtained by Eq. (16). If Doptp≥Goptp, then N new objective function values are NSoptp(0), NSoptp(1), …, NSoptp(Uoptp−Goptp−1), and Boptp can be obtained by Eq. (17).(16)Boptp=max{Doptp,u|u∈{NSoptp(t),0≤t<Uoptp−Doptp}}(17)Boptp=max{Doptp,u|u∈{NSoptp(t),0≤t<Uoptp−Goptp}}If lu items can be loaded into knapsack by updating the candidate objective function value, then the finally determinate region can be accomplished, which contains (m+lu) items.According to the above statements, the process of GDEE for solving KP01 is depicted in Fig. 2. Specifically, at first, n items are rearranged by the ratio of profit and weight in descending order. Secondly, the greedy degree model is used to load the first m items into knapsack and they are never removed from knapsack. Thirdly, the dynamic expectation efficiency strategy is used to load u items from the remaining (n−m) items into knapsack and the last remaining (n−u−m) items are regarded as unknown items region. Fourthly, the static expectation efficiency model with the parallel computing method is used to update the candidate objective function value and lu items are loaded into knapsack. At last, the first m items and the determined lu items constitute finally determinate region. The process can be described in Algorithm 4 as follows.Algorithm 4GDEE algorithmInput:W, P, n and capOutput:BoptpRun Algorithm 1;Obtain m;Run Algorithm 2;Obtain Doptp;Run Algorithm 3 by parallel method;ifDoptp<Goptp, thenObtain Boptp by Eq. (16);elseObtain Boptp by Eq. (17);end ifTheorem 2Algorithm1runs in O(n).ProofAlgorithm 1 consists of three parts, i.e., running greedy algorithm, checking whether Q<n/2 is met or not, and checking whether inequality (2) is met or not. As far as we know, greedy algorithm and the third part both run in O(n). About the second part, n/2 items need to be searched when it begins to be run, and then n/4 items need to be searched. By that analogy, n/2kitems need to be searched in the end. Right now, it is kth round search. Here, n/2kis a positive integer, according to the definition of lower limit function, inequalities are shown as follows.(18)1≤n/2k<2(19)(log2n)−1<k≤log2nAs can be seen from inequality (19), the second part runs in O(logn). Since the three parts work in serial way, Algorithm 1 runs in O(n). To sum up, Theorem 2 is proved.Theorem 3Algorithm2runs in O(n).ProofThe running number of Eq. (8) in the dynamic expectation efficiency model is (n−m), and thus this part runs in O(n). In similar way, the other parts run in O(n). There is no doubt that Algorithm 2 runs in O(n).Theorem 4Algorithm3runs in O(n).ProofThe proof is similar to Theorem 3 since the principle of Algorithm 3 is similar to Algorithm 2.Theorem 5GDEE runs in O(n).ProofGDEE consists of four parts, i.e., running Algorithm 1, running Algorithm 2, running Algorithm 3, and selecting Boptp as the best profit by Eq. (16) or (17). Algorithms 1, 2 and 3 all run in O(n) which can be found by Theorems 2, 3 and 4 respectively. In terms of part four, it needs to search (Uoptp−Doptp) or (Uoptp−Goptp) elements when Boptp is selected as the best profit, and thus this part runs in O(n). Since they work in serial way, GDEE also runs in O(n).Theorem 6Space complexity of GDEE is in O(n2).ProofAt first, let the candidate objective function value Doptp be into static expectation efficiency model, (n−m) static expectation efficiency values are obtained by Eq. (10). And then, to use the method of parallel computing, N new objective function values will be generated by Eq. (15). In total, N*(n−m) static expectation efficiency values are emerged, which needs N*(n−m) space to store. Besides, N=Uoptp−Doptp or N=Uoptp−Goptp by Eq. (15), it keeps the same level with n (i.e., N=n+ν, ν is a constant). In conclusion, the space complexity of GDEE is O(n2).In this section, the performance of GDEE is extensively investigated by a large number of experimental studies with considering running time, best profit, worst profit, and the size of storage space as the indexes of performance evaluation. Since correctness, feasibility, effectiveness, and stability are very important for evaluating the performance of GDEE [38], four groups of simulation experiments according to sixty-five KP01 instances are presented. Firstly, a numerical instance is given to illustrate the computation process and correctness of GDEE. Secondly, fifteen instances are tested to demonstrate the feasibility of GDEE. Thirdly, GDEE is compared with chemical reaction optimization algorithm with greedy strategy in [30] called CROG in this paper and modified discrete shuffled frog leaping algorithm in [22] called MDSFL according to five instances to show the effectiveness of GDEE. Finally, GDEE is run on different test case libraries with forty-four instances to reveal the stability of GDEE. The simulation experiments are conducted with VC++ 6.0 in Intel (R) Core(TM) i7, 2.93GHZ CPU, 4G RAM. Simulation parameters are set as follows: λ=0.7 and ξ=0.5.Given one instance KP2: cap=620, n=20, W=(22,36,32,18,35,26,44,50,45,44,48,50,12,52,24,52,60,28,55,38), P=(56,60,48,25,72,40,55,55,50,37,30,48,18,78,30,60,45,35,70,48). The process of obtaining the best profit is presented as follows.Step1:Rearrange 20 items. W=(22,35,36,26,12,32,52,18,55,38,28,24,44,52,45,50,50,44,60,48), P=(56,72,60,40,18,48,78,25,70,48,35,30,55,60,50,55,48,37,45,30).Step2: Run Algorithm 1. Goptp=848, GW=619, Q=17, and m=10.Step3: Run Algorithm 2. Doptp=848.Step4: Compute the range of the best profit according to Theorem 1. Uoptp=885 and Doptp=Goptp=848, and then optp(t)∈ [848, 885).Step5: Obtain some new objective function values by parallel computing method. Let optp(t) be into Eq. (10), and 37 new objective function values are 848, 849, …, 884 respectively.Step6: Obtain the best profit by Eq. (17) since Doptp=Goptp=848 in Step4. Boptp=max{848, NSoptp(0), NSoptp(1), …, NSoptp(36)} =848.For KP2, the best profit is 848, and the detailed changing process of objective function value is depicted in Fig. 3.In Fig. 3, the best profit can be obtained after 17 iterations. At the beginning, the objective function value is 515, which is the total profit of the first ten items. It keeps unchanged from the first iteration to 10th iteration since the size of greedy degree is ten. And then, dynamic expectation efficiency model, static efficiency model, and parallel computing method are run, and thus the objective function value begins to increase from the 11th iteration. In this process, the determinate items are loaded into knapsack one by one.To demonstrate the feasibility of GDEE, fifteen instances from the Standard Test Case Libraries (STCL) of KP01 are given, and the sizes of items are 5, 8, 10, 10, 20, 23, 50, 50, 80, 80, 100, 100, 100, 200, and 200 respectively. The experimental results are composed of five indexes, i.e., the number of parallel update, best profit, worst profit, the size of storage space and running time, and they are shown in Table 2.As can be seen in Table 2, a number of useful conclusions are presented as follows. (a) GDEE can solve KP01 and obtain the best profit. (b) Although it requires a lot of storage space to place the expectation efficiency values, the memory is cheap nowadays, which can be usually accepted by individuals and enterprises. (c) The running time increases with the increasing of number of items because it requires processing more items with much time spent in general. (d) The number of items is not proportional to the size of storage space since it is determined by the upper bound of the total profit (Uoptp) and the number of items. (e) For some KP01s (e.g., KP4 and KP5), although their number of items are same, they have different best profits since the best profit is determined by six factors (see Eq. (4) for more details). In short, the given fifteen instances can demonstrate the feasibility of GDEE.To further demonstrate the effectiveness of GDEE, it is compared with CROG and MDSFL including best profit, worst profit, difference between best profit and worst profit, population size/the number of parallel update (PS/NPU, i.e., PS and NPU are equivalent), and running time according to five instances which are from Table 1 in [22]. Comparison results among three algorithms are shown in Table 3, and the detailed changing process of the objective function value for f2, f4, f6, f8 and f10 are shown in Figs. 4–8respectively.In Table 3, CROG obtains the best profit by setting PS for 20; MDSFL obtains the best profit by setting PS for 200; and GDEE obtains the best profit by setting NPU for 11, 8, 15, 486, and 11 respectively.In Fig. 4, the objective function value of CROG increases in stages and it begins to change on the 12th, 19th, and 40th iteration, and the best profit can be obtained on the 40th iteration; one of MDSFL increases continually in early stage and keeps unchanged from the 7th to 58th iteration, and the best profit can be obtained on the 59th iteration; one of GDEE keeps unchanged in early stage from the first iteration to 10th iteration and begins to increase continually until the best profit can be obtained on the 17th iteration.In Fig. 5, the objective function value of CROG increases in stages and it begins to change on the 6th and 9th iteration; one of MDSFL obtains the best profit only by one iteration; one of GDEE keeps unchanged on the first four iterations and begins to increase continually until the best profit can be obtained on the 6th iteration.In Fig. 6, the objective function value of CROG increases in stages and it begins to change on the 4th, 9th, 11th, and 15th iteration, and the best profit can be obtained on the 15th iteration; one of MDSFL obtains the best profit only by one iteration; one of GDEE keeps unchanged on the first five iterations and begins to increase continually until the best profit can be obtained on the 7th iteration.In Fig. 7, the objective function value of CROG increases in stages and it begins to change on the 6th, 14th, 17th, and 27th iteration, and the best profit can be obtained on the 27th iteration; one of MDSFL also increases in stages and it begins to change on the 9th and 22nd iteration; one of GDEE keeps unchanged on the first seven iterations and begins to increase continually until the best profit can be obtained on the 13th iteration.In Fig. 8, the objective function value of CROG increases in stages and it begins to change on the 12th, 20th, and 41st iteration, and the best profit can be obtained on the 41st iteration; one of MDSFL increases continually in early stage from first iteration to 16th iteration and increases in stages from the 17th to 53rd iteration, and the best profit can be obtained on the 53rd iteration; one of GDEE keeps unchanged in early stage from the first iteration to 10th iteration and begins to increase continually until the best profit can be obtained on the 17th iteration.As can be seen in Table 3 and Figs. 4–8, some conclusions can be further presented as follows. (a) The best profit and the optimal solution can be obtained by CROG, MDSFL and GDEE. (b) Only for f4 and f6, MDSFL has the fastest convergence speed, but GDEE is still superior to CROG. (c) For f2, f8 and f10, GDEE has faster convergence speed than CROG and MDSFL. (d) From the perspective of difference between best profit and worst profit, GDEE and MDSFL have better performance compared to CROG. (e) In terms of PS/NPU, for f2, f4, f6 and f10, GDEE requires less NPU than CROG and MDSFL. (f) From the perspective of running time, for f4 and f6, MDSFL spends less time in solving KP01 while GDEE spends less time in solving KP01 except f4 and f6. In summary, in comparison with a heuristic algorithm and a computational intelligence algorithm, GDEE is more effective.To demonstrate the stability of GDEE, three STCLs are considered for comparing CROG, MDSFL and GDEE. STCL1 is from [22] with 10 instances and the sizes of items are 10, 20, 4, 4, 15, 10, 7, 23, 5, and 20 respectively; STCL2 is from http://lvjianhui.lingw.net/article-6224551-1.html with 20 instances and the sizes of items are all 20; and STCL3 is from http://lvjianhui.lingw.net/article-6224553-1.html with 14 instances and the sizes of items are 50, 50, 80, 80, 100, 100, 100, 100, 100, 100, 100, 200, 200, and 200 respectively. Comparing CROG, MDSFL and GDEE, the experimental results including average running time and correct rate (i.e., whether the KP01 can be solved or not) are shown in Table 4.As can be seen in Table 4, about STCL1, the average running time of CROG is the largest while that of MDSFL is the smallest. About STCL2, the average running time of MDSFL is the largest while that of GDEE is the smallest. About STCL3, the average running time of CROG is the largest while that of GDEE is the smallest. In terms of the 44 instances from different STCLs, CROG, MDSFL and GDEE can all solve KP01 and obtain the best profit (the correct rate is 100%), which suggests that GDEE has a relative stability.

@&#CONCLUSIONS@&#
KP01 has been widely applied in the real world applications such as capital budgeting, project selection, resource allocation, investment decision-making, etc. In this paper, a new hybrid heuristic algorithm based on greedy degree and expectation, called GDEE, is proposed for solving KP01. In the proposed GDEE, greedy degree model is presented to put the first some items into knapsack early. Furthermore, two expectation efficiency models are designed to generate the objective function value from the remaining items. Moreover, the parallel computing method is adopted to accelerate the update speed of objective function value. In addition, the time complexity of GDEE is analyzed and it runs in O(n), which is appreciable. The space complexity of GDEE is also analyzed and it runs in O(n2), which is acceptable due to the cheap memory nowadays. The performance of GDEE is extensively investigated through a lot of instances in four groups of experiments, where one instance, fifteen instances, five instances and three STCLs demonstrate its correctness, feasibility, effectiveness, and stability respectively. Indeed, GDEE is a promising tool for solving combinatorial optimizations such as resource allocation and production scheduling.Based on the whole in-depth study, the proposed GEDD has some distinguished advantages summarized as (a) the lower time complexity compared to other existing algorithms; (b) the fast convergence speed with parallel computing way instead of serial computing way; and (c) simple and comprehensible computation process without the complex iterations. Furthermore, GDEE has a potential for solving any KP01, and it may also be used to solve multiple-objective KP01 and other combinatorial optimization problems, such as resource allocation in different fields, production scheduling in industry, etc.However, GDEE also has two limitations as follows. On one hand, it has the higher space complexity due to the parallel computing. On the other hand, it relies on greedy degree model too much, in which once the size of greedy degree is inaccurate, the optimal solution is hard to capture. Thus, as a new algorithm, GDEE needs to be further studied and improved. The future work can be carried out in the following directions. Firstly, a better model than greedy degree model in this paper should be designed to put some items into knapsack in advance. And then, both dynamic and static expectation efficiency models need to be modified to increase the convergence speed of the optimal solution. Last but not least, GDEE is expected to solve the real engineering problems such as resource allocation in cloud computing and job scheduling in industry to expand and enhance the application of GDEE. In total, GDEE is a hybrid and novel approach for solving KP01, and it can provide some valuable rationale for the optimization research of KP01.