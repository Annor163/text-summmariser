@&#MAIN-TITLE@&#
Reducing over- and under-estimation of the a priori SNR in speech enhancement techniques

@&#HIGHLIGHTS@&#
We propose a novel approach based on two steps, training and correction of a priori SNR.We have applied this proposed approach to the DD and the TS-NR algorithms.This new approach has given two new algorithms for noise reduction and speech enhancement.The new algorithms are based on a bias-compensated of the a priori SNR estimate.Intensive experiments have shown the efficiency of the proposed algorithms and approach.

@&#KEYPHRASES@&#
Speech enhancement,Noise reduction,A priori SNR,A posteriori SNR,SNR cells,Spectral distortion,

@&#ABSTRACT@&#
Graphical abstract

@&#INTRODUCTION@&#
The problem of enhancing speech degraded by uncorrelated additive noise has been widely studied in the past and is still an active field of research. Although background and applications differ largely, a specific class of these methods is essentially based on the SNR estimation that is used with a gain function to correct the corrupted speech signal. In practice, the deficiency of speech acquisition and transmission system results a speech signal commonly corrupted by noise. The contamination of the speech not only affects its audio quality but also reduces the performance of high-level speech processing applications such as voice communication and automatic speech recognition where efficient noise reduction techniques are required. Depending of the application, the goal of the speech enhancement techniques is to reduce the noise to make the speech intelligible, to decrease annoyance or to improve the overall sound quality. The most challenging case is the single-channel speech enhancement where only a single noisy speech recording is available for recovering the clean speech. Many algorithms have been proposed to solve this problem, such as spectral subtraction (SS) [1], minimum-mean square error (MMSE) estimator [2,3], and Wiener filter based algorithms [4,5]. Such noise reduction techniques rely mainly on the estimation of a short-time spectral gain which is a function of the a priori SNR and/or the a posteriori SNR computed on each frequency component. In [6], the authors highlighted the interest of estimating the a priori SNR thanks to the “decision-directed” (DD) approach initially proposed in [2]. This DD approach has then received a lot of attention due to its low computational complexity and good performance in various noise reduction applications. Unfortunately, the DD approach suffers from inherent errors (or bias) in estimating the spectral SNRs. Such errors affect directly the estimation of the short-time spectral gain, and inaccuracies in estimating the gain function often lead to spectral attenuation (i.e., enhanced spectral components are smaller in magnitude than corresponding clean spectral components) and/or spectral amplification (i.e., enhanced spectral components are larger in magnitude than corresponding clean spectral component). Consequently, the output speech intelligibility may be impacted by the presence of these two kinds of distortions.A first source of bias in the a priori SNR estimate is due to the one-frame delay bias introduced by the decision-directed estimator. This behavior has been analyzed in [5] where the authors have demonstrated that the a priori SNR estimate follows the shape of the a posteriori SNR with a one frame delay in regions of high a priori SNR. Consequently, since the spectral gain depends on the a priori SNR, it does not match the current frame and thus the performance of the noise suppression system is degraded especially at transient periods (speech to non-speech or non-speech to speech). To reduce this effect, a Two-Step Noise Reduction algorithm (TS-NR) has been proposed in [7] that refines the estimation of the a priori SNR. By suppressing the frame delay bias, the TS-NR algorithm removes some of the drawbacks of the DD approach while maintaining its advantage, i.e. a highly reduced musical noise level. Such algorithm has been selected by ITU-T in 2008 as the optional post-filter in the standardized G.711.1 (multi-rate wide-band extension for the well-known ITU-T G.711) to reduce the lower band quantization noise at the decoder [8].Recently, a second source of bias in the a priori SNR estimate has been identified in [9]. To assess the impact of SNR and gain over- and under-estimation on speech intelligibility, the authors in [9] conducted listening tests with different biased spectral gain function. More precisely, by assuming perfect a priori knowledge of the short-time versions of the a priori SNR, such a bias was introduced by including a bias in the a priori SNR estimation. Listening tests indicated that SNR and gain-function over-estimation errors in frequency bins with negative SNR are particularly harmful to speech intelligibility. Furthermore, the authors suggested that better methods are needed to estimate the spectral SNR from noisy observations, particularly at low input SNR levels. Such methods hold promise for improving speech intelligibility.In this work, we focus on the problem of over- and under- estimation of the spectral SNR from noisy observations. The proposed correction technique is applied to DD- and TS-SNR Wiener filters but it could also be applied to any recent MMSE based techniques relying on more than the a priori and a posteriori SNR estimates [10–13]. Starting with the same experiments as those presented in [9]. We consider a baseline noise reduction filter which is implemented as a short-time Wiener filter combined with a DD approach for the estimation of the a priori SNR. By assuming perfect a priori knowledge of the evolution of the short-time SNR, we have analyzed the over- and under-estimation errors of the a priori SNR. However, as oppose to [9], we do not introduce a known bias in the a priori SNR estimation. Instead we use a well-known technique such as the DD approach for the estimation of the a priori SNR and we analyze the SNR bias by comparing this SNR estimate with the perfect a priori knowledge of the evolution of the short-time SNR. By processing several noisy speech sentences from a training database and analyzing the SNR bias for all frequency bins within all short-time frames, we thus obtain an empirical estimate of the 2-dimensional distribution of the SNR bias as a function of two main parameters: the a priori and the a posteriori SNRs. Once this 2-D bias distribution is available, we applied a k-means clustering method (Lloyd's algorithm) to segment the 2-D plane (a priori SNR and a posteriori SNR parameters) into m clusters in which each observation (i.e. the bias) belongs to the cluster with the nearest mean. This results into a partitioning of the a priori-a posteriori SNR space in m Voronoi cells. The mean estimation error in each cluster is then used as bias correction terms of the a priori SNR for all features belonging to that cluster in the 2-D-space. Moreover, it might be worth mentioning that each frequency bin of the estimated SNR is corrected independently according to the estimated bias by the new method that we propose in this paper.The remainder of this paper is organized as follows. Section 2 presents a brief description of speech enhancement techniques that operate in the frequency domain. Then, we focus our analysis on the considered approach which corresponds to a combination of the DD approach and the two step noise reduction (TS-NR) algorithm. The bias effect in the DD a priori SNR estimator is then studied in Section 3. The probability density function of this bias is analyzed in a 2-D space driven by the a posteriori and a priori SNR parameters. Also in this same Section 3, we deal with the partition of the 2-D plane into m clusters in order to retain the main properties of the bias information. We then proposed in Section 4 a refinement of the noise reduction technique in which the DD and TS-NR a priori SNR estimates are modified according to the mean value (i.e. bias) of the error observed in the corresponding cluster. Simulations are carried out in Section 5 to assess the performance of the proposed technique. Objective evaluation in various environmental conditions show that the proposed modification approach is advantageous, particularly for low input SNRs. Excellent noise reduction can be achieved even in the most adverse noise conditions, while avoiding musical residual noise and the attenuation of weak speech components.In the additive noise model, the clean speechs(n)is corrupted by an independent noise signald(n)with zero-mean. The resulting noisy speechy(n)is given in the time domain by(1)y(n)=s(n)+d(n)where n is the discrete time index. To obtain the clean speech from the noisy one, conventional noise reduction techniques used a noise reduction filter whose impulse responseg(n)is designed to produce an enhanced speechsˆ(n)corresponding to a trade-off between noise reduction and speech distortion. At the output of this filter, the enhanced speech is expressed as(2)sˆ(n)=g(n)⁎y(n)where ⁎ is the convolution operator. The residual noise signale(n)is defined as the difference between clean and enhanced speech. Incorporating (1) and (2), the residual noise signal is defined as:(3)e(n)=sˆ(n)−s(n)=[g(n)−δ(n)]⁎s(n)+g(n)⁎d(n),whereδ(n)is the Kronecker delta function. Considering that the observed signaly(n)is divided into overlapping frames by the application of a window function, and analyzed using the short-time Fourier transform (STFT), the time domain residual noise can be equivalently expressed in the frequency domain as:(4)e(p,k)=[G(p,k)−1]S(p,k)︸eS(p,k)+G(p,k)D(p,k)︸eD(p,k)where k represents the frequency bin index, and p the frame index.S(p,k),D(p,k)andG(p,k)represent the kth spectral component of the short-time frame p of the speech signals(n), noised(n), and noise reduction filterg(n), respectively. The two quantitieses(p,k)andeD(p,k)represent respectively, the Kth spectral components of the short-time frame p of the speech and the noise distortions amounts. From (4), it can be seen that the spectral gain functionG(p,k)has a significant impact on the speech signal and the noise components energies. This relation (4) does well highlight the trade-off between speech and noise reduction. This is becauseG(p,k)affects such speech components and noise equally. The higher the degree of noise suppression, the higher is the amount of speech distortiones(p,k). The choice of the distortion measure (which can be modeled by the a priori SNR estimation methods) determines the gain behavior, i.e. the trade-off between noise reduction factor and speech distortion. Such a trade-off is found in the so-called spectral subtraction technique [1] that produces low distortion in the enhanced speech signal at the expense of a high level of musical noise leading to a very poor global quality from a subjective point of view.However, most noise reduction techniques based on short-time spectral modifications of the noisy speech spectra require the evaluation of two main parameters: the a posteriori and the a priori SNRs, respectively defined by:(5)γ(p,k)=|Y(p,k)|2λD(p,k)and(6)ξ(p,k)=|S(p,k)|2λD(p,k)whereλD(p,k)=E[|D(p,k)|2]stands for the noise power spectral density (PSD), and the notationE[•]denotes the expectation operator. As usually assumed when considering spectral modification based noise reduction techniques, the DFT coefficients are considered as independent across time and frequency. In practical implementations of speech enhancement systems, the speech and noise PSDs are unknown since only the noisy speech spectrumY(p,k)is available. Thus, both the a posteriori and the a priori SNRs have to be estimated. The estimation of the noise PSD is beyond the scope of this paper. It can be practically estimated during speech pauses using a conventional recursive estimator [1] or continuously using either the Minimum Statistics [14] technique or the Minima Controlled Recursive Averaging approach [15] to get a more accurate estimate in case of noise level fluctuations. In the following we will assume that such noise PSD is available for each short-time frame and that it will be denotedλˆD(p,k). Once a noise power spectral density estimate is available, the spectral gainG(p,k)is obtained in most noise reduction techniques by a function(7)G(p,k)=f(ξˆ(p,k),γˆ(p,k))depending on the chosen distortion measure (which can be modeled by the a priori SNR estimation). The functionf(•)can be selected among the different spectral gain functions proposed in the literature (e.g. amplitude or power spectral subtraction [1], MMSE STSA [2], MMSE LSA [3], Wiener filtering [4], OM LSA [16]. The resulting speech spectrum is then estimated by applying the spectral gain to the noisy spectrum(8)Sˆ(p,k)=G(p,k)Y(p,k).It should be noted that conventional noise reduction techniques hold some shortcomings. It has been shown that the spectral gainG(p,k)will reach the asymptotic values of 0 or 1 when the SNR is 0 or infinity. However, it is extremely unlikely that the gain will ever reach the value of 1. Therefore, for a given frame, if noise is not present in a frequency component, this component will still be attenuated. This is especially true for speech components that are well below the noise level. They are suppressed along with the noise by conventional noise reduction techniques.In the rest of the paper, we will focus our analysis on a specific noise reduction scheme combining the “decision directed estimator” (DD) and the two step noise reduction (TS-NR) algorithm. The main properties of these two techniques will be briefly recalled in the following subsections.Assuming an estimateλˆD(p,k)of the noise PSD is available at each short-time frame, we define the a posteriori SNR estimate as follows(9)γˆ(p,k)=|Y(p,k)|2λˆD(p,k).This relation to corresponds to a local SNR computed from the data in the current short-time frame. It can be noted that given the noise variance, the a posteriori SNR is not estimated but known at each frame. The so-called a priori SNR estimator represents the information on the unknown spectrum magnitude gathered from previous frames and is evaluated in the “decision-directed” approach [2] by(10)ξˆ(DD)(p,k)=max{β|Sˆ(p−1,k)|2λˆD(p,k)+(1−β)P[(γˆ(p,k)−1)],ξmin}.Asγˆ(p,k)defined by (9), is not necessarily greater than one, the operatorP[.], in (10), is a function which guarantees thatξˆ(DD)(p,k)is always non-negative. In the first term of (10),Sˆ(p−1,k)corresponds to the noiseless signal spectrum value as estimated in the previous frame from relation (8). The a priori SNR estimator (10) represents the information on the unknown spectrum magnitude gathered from previous frames.ξminis a threshold that limits the a priori SNR of (10) to −20 dB. The choice of the value of parameter β is guided by a trade-off between the degree of smoothing of parameterξˆ(p,k)in noisy areas and the acceptable level of transient distortion brought to the signal (typically this parameter is set to about 0.98). Without loss of generality, in the following, the spectral gain functionf(•)in (7) is selected as the Wiener filter, and then(11)G(DD)(p,k)=ξˆ(DD)(p,k)1+ξˆ(DD)(p,k).The approach defined by (9), (10) and (11) is called the DD estimator algorithm. It has been demonstrated in [5] that the DD estimator has interesting properties (the musical noise phenomenon is greatly reduced) but suffers from a one-frame delay. This delay inherent to the DD algorithm is a drawback especially in the speech transients, e.g., speech onsets and offsets. It introduces a bias in gain estimation which limits noise reduction performance and generates either speech distortions (for onsets) or an annoying reverberation effect (for offsets) because the level of the enhanced speech in the previous frame is artificially maintained in the current one due to this one-frame delay.To enhance the noise reduction process, it is proposed in [5] to refine the a priori SNR estimate in a two-step procedure. This technique is based on the observation that the DD algorithm introduces a one frame delay when the parameter β is close to one. Consequently, the spectral gain computed at current frame p matches the previous framep−1. Based on this fact, it is proposed in [7] to compute the spectral gain for the next framep+1using the DD approach and to apply it to the current frame because of the frame delay. This leads to a two step procedure algorithm. The first step consists exactly of the decision directed algorithm and a spectral gainGDD(p,k)is computed as described in (11). In the second step, this gain is re-used to refine the estimate of the a priori SNR as:(12)ξˆ(p,k)=|G(DD)(p,k)Y(p,k)|2λˆD(p,k).We can notice that the TS-NR approach uses the DD estimator as an intermediate step to compute the output spectral gain (12) that is used in the refinement a priori SNR estimate. Finally, another spectral gain is computed:(13)G(TS-NR)(p,k)=h(ξˆ(p,k),γˆ(p,k)),which is used to enhance the noisy speech(14)Sˆ(p,k)=G(TS-NR)(p,k)Y(p,k).By taking the inverse Fourier transform of (14), the enhanced speech signal is then reconstructed in the time-domain signal using the overlap-add method. Note that functionh(•)may be different from the functionf(•)defined in (7). However, without loss of generality, in the following, this gain will be selected as a Wiener filter, and then(15)G(TS-NR)(p,k)=ξˆ(p,k)1+ξˆ(p,k).This algorithm in two steps defined by (9), (10), (12), and (15), is called the TS-NR algorithm. This technique improves the noise reduction performance since the gain matches to the current frame whatever the SNR. The main advantages of this approach are the ability to preserve speech onsets and offsets, and to successfully remove the annoying reverberation effect typical of the DD approach [2,3,5,16,19]. Note that in practice this reverberation effect can be reduced by increasing the overlap between successive frames but cannot be suppressed whereas the TS-NR approach [7] makes it possible with a typical overlap of 50%. Such solution has been selected by ITU-T [8] in 2008 as the optional non-parametric post-filter in the standardized G.711.1.In this section, we concentrate our analysis on several important properties of the a priori SNR estimate as this parameter plays a central role in spectral noise reduction techniques. As described previously, estimating the a priori SNR through the “decision-directed” approach is widely used (instead of the a posteriori SNR) because it reduces the musical noise to an acceptable level. However, as we shall see, this a priori SNR estimate often leads to an under- or over-estimation of the SNR on each frequency component thus reducing the output speech quality. From a subjective point of view, this SNR's over- or under-estimation is at similar to the same effect as in the onset/offset distortions that are created by the one-frame delayed SNR estimation. It should be noted that the a posteriori SNR is a known quantity (that is, given the noise statistics), and it appears to be simply used in this work as an indicator on how to adjust the a priori SNR estimate - which is unknown.To better understand the impact of errors in the estimation of these SNRs, we show in Figs. 1 and 2scatter plots of the a posteriori and the estimated a priori SNRs versus the ‘true’ short-time values of the SNR defined as:(16)ξ(p,k)=|S(p,k)|2λˆD(p,k).To provide this parameter available for the analysis, we assumed knowledge of the magnitude spectrum of the clean speech signal. It should be stated that the true ideal SNR is unobtainable due to the non-stationarity of the speech signal. In this paper, due to the unavailability of this true SNR, we define the ground truth as given by (16), which is appropriate because any noise reduction filter that uses (16) will provide an enhanced speech signal with high noise reduction level and minimum spectral distortions. As a result, let us consider that the a posteriori SNR (Fig. 1) is obtained from (9), and the a priori SNR estimate (Fig. 2) is obtained by relations (10), (11) and (12) using the TS-NR approach (withβ=0.98). In these figures, for each frame and each frequency, we have represented features (or 2-tuples) considered as a point in the two-dimensional space defined by the two SNRs, namely the SNR (estimated a priori or known a posteriori) and ‘true’ SNR defined by (16) which is considered as a reference. Moreover, to focus the analysis on the behavior of the SNR estimators for speech components, only features (about900×257features) corresponding to speech activity periods are represented on this figure. In this experiment, the frame length isL=256for a sampling frequency of 8 kHz. Each of the noisy signal frames are Hanning windowed with a 50% overlap and transformed in the frequency domain with a 2L-point FFT to avoid distortions resulting from the circular convolution effect [27]. The overall input SNR is 13 dB and the background noise is babble. To evaluate the performance of each estimator, the bold line corresponds to a perfect SNR estimator (i.e. zero estimation error) that can be used as a reference. The upper triangular part of this figure corresponds to an over-estimation of the true SNR (respectively under-estimation in the lower-triangular part).From Figs. 1 and 2, it is obvious that the features corresponding to the a posteriori SNR parameter are closer to the reference bold line and are less dispersed than the a priori SNR estimator ones. This is especially true for high signal-to-noise ratio values. Furthermore, to provide mean behavior analysis, we have also represented on Fig. 1 and Fig. 2 the conditional expectations of the two estimated SNRs given the knowledge of the true SNRξ(p,k)which are obtained as follows:(17)E(ξˆ|ξ)=∫RξˆfΞ|P(ξˆ|ξ)dξˆE(γˆ|ξ)=∫Rγˆfϒ|P(γˆ|ξ)dγˆwherefΞ|Pandfϒ|Pare the conditional probability density functions of the estimated SNR knowing the true SNR. We can observe that the conditional mean of the estimated SNR is closer to the perfect estimator for the a posteriori SNR parameter than for the a priori SNR estimator. The available a posteriori SNR values can be viewed as slightly underestimated for high SNR whereas for the a priori SNR the underestimation is large for SNR greater than −17 dB. However, since the dispersion is high for the a priori SNR features, even if the mean is largely underestimated, the case where SNR features are overestimated exists. Furthermore, for SNR smaller than −17 dB, the a priori SNR is overestimated.Let us now examine the behavior of the bias in the a priori SNR estimate as a function of the value of the parameter β in the decision-directed loop (10). To do so, Fig. 3compares for speech activity periods the conditional mean (17) of the a priori SNR estimate for β ranging from 0.3 to 0.98.For frequency bins with low SNR values, we see that the bias increases with decreasing β. Theξˆvalue is over-estimated by as much as 20–40 dB at extremely low (<40 dB) SNR levels. A value of β near one provides the highest noise reduction, while avoiding the musical noise. However, it comes at the expense of a reduction in intelligibility, because important speech transitions are excessively smoothed [6]. On the other end, as β tends to zero, the behavior of the conditional mean curve of the a priori SNR estimate tends to mimic the one of the a posteriori SNR presented in Fig. 1 but this is obtained at the expense of a musical noise which is introduced in the enhanced speech. On the contrary, for frequency bins with high SNR (greater than 0 dB) the bias in the a priori SNR estimate is decreasing with increasing values of β. This bias analysis provides a more comprehensive understanding of the important role of the a priori SNR estimate in noise reduction problems and is in agreement with other experimental observations [5,17].The results confirm that the a posteriori SNR parameter is more reliable than the a priori SNR estimator for high SNR frequency bins (i.e. speech components) but this behavior is obtained at the expense of the insertion of the musical noise in the enhanced speech signal. From these curves, we can predict that the estimation of the spectral gain function (15) will be particularly affected by the perturbations in the a priori SNR values especially in the negative region of the SNR as inaccuracies in the estimation of a priori SNR values (such as under-estimation) directly cause a bias in the gain function (a lower value), thus generating distortion in the output speech.To go further insight the analysis of the role of a priori SNR estimation within the TS-NR algorithm, we now concentrate on the probability density function of this SNR estimate through its corresponding empirical 2-D histogram which is obtained by counting in Fig. 2 the number of features (or 2-tuples) that fall within each 3 dB × 3 dB area. The obtained normalized histograms are represented in Fig. 4as a function of the a priori SNR estimate and true SNR values.One can see in Fig. 4 that the 2-D-histogram of the a priori SNR estimate exhibits two distinct kernels or clusters (denoted by the letters A and B) that are defined as maximal sets of connected dense units in the 2-D plane.In this sense, the empirical histogram corresponds to a mixture density that can be interpreted as being derived in a simple way from an underlying set of other random variables. The connection between these clusters and the inherent properties of the corresponding time-frequency componentsY(p,k)is made clearer by plotting in Fig. 5the spectrogram corresponding to the same speech segment as the one considered in Fig. 4. On this figure, all frequency components corresponding to cluster B (i.e.−30dB<ξˆ(p,k)<−10dB) are represented in ‘red’. Note from (15) that such low values of the a priori signal-to-noise ratio may result in a mean value of −20 dB for the short-time spectral gainsG(TS-NR)(p,k). Thus, we can assume that the corresponding frequency bins will be suppressed within the enhanced speech spectrum. From Fig. 4, we can consider that the remaining features belong to cluster A. However, we can conclude from Fig. 5 that the features corresponding to kernel A are mainly related to speech harmonics (rather than noise components) that should be preserved by the spectral noise reduction filter. From the previous analysis of Figs. 4 and 5, we can expect that the performance of the amplitude estimator (14) will greatly depend on the inherent properties of the a priori SNR estimator used. In the TS-NR approach different behaviors may appear when we estimate the a priori SNR from the nonlinear recursive relation (10) in combination with (11) and (12). Whenγˆ(p,k)stays below 0 dB, the a priori SNR corresponds to a highly smoothed version of the a posteriori SNR over successive short-time frames. The spectral gainG(TSNR)(p,k)in such conditions is lower than −24 dB (as seen for cluster B) and does not exhibit large variations over successive short-time frames. As a consequence, the musical noise phenomenon is reduced. On the contrary, whenγˆ(p,k)is much larger than 0 dB, the a priori SNR is no longer a smoothed SNR estimate. Its short-time evolution follows the one of the a posteriori SNR (cluster A). Such property is particularly important in the case of non-stationary signals.It should be noted that this behavior of the noise reduction filter remains true if the spectral noise reduction gain functionG(TSNR)(p,k)in (15) is replaced by another suppression rules ([2–4], and [14]), evaluated as a function of the decision-directed a priori SNR estimate.In this section, we address the problem of improving the SNR estimation. Several attempts have been made in the past to modify noise reduction techniques. Some of them have tried to modify the short-time spectral gain in a data-driven approach [18,19], or to propose alternative analytical suppression rules [20,21]. Other studies propose new approaches for the a priori SNR estimate such as robust estimators [22,23], or noncausal estimators [24]. However, as seen previously, the a priori SNR estimation represents a crucial parameter and suffers from over- or under-estimation errors thus leading to a local sub-optimal solution for the noise reduction filter. In this section, we aim to design a more accurate a priori SNR estimator that solves the drawbacks of the conventional estimator in order to reduce speech distortion while retaining a high level of noise attenuation in speech absence. In this section, we describe our strategy that relies on the optimization of the mean square error (MSE) in the a priori SNR estimate.As the two contributing SNR components of the conventional decision-directed approach are two direct observations of the true SNRξ(p,k), we can symbolically write(18)ξ(p,k)=T{ξˆ(p,k),γˆ(p,k)}.where the analytical expression of functionT(•)is unknown. However, its main properties can be recovered from the analysis of the correspondence between the experimental time-frequency seriesz(p,k)=(ξˆ(p,k),γˆ(p,k))and the true a priori SNRξ(p,k). Assuming a priori knowledge of the short-time versions ofξ(p,k)in a training phase, we can thus consider in the rest of the analysis that functionT(•)is known from an experimental point of view. To investigate the impact of the estimation errors, we consider the error in the a priori SNR estimate:(19)e(p,k)=ξ(p,k)−ξˆ(p,k)=T{z(p,k)}−ξˆ(p,k)=H{z(p,k)}which is expressed as a functionH(•)of the available a posteriori and the estimated a priori SNRs parameters. For the same reason as previously discussed forT(•), the functionH(•)can be assumed known from an experimental point of view. The optimization process can be realized by minimizing the mean-squared error (MSE), defined asJ=E{e2(p,k)}=∬dJwheredJstands for the infinitesimal MSE defined as:(20)dJ=e2(z)fZ(z)dσ,wheredσis the area differential andfZ(z)denotes a probability density function (that will be estimated by its corresponding normalized 2-D-histogram). By integrating locally the infinitesimal MSE (20) on small surfaces (of 3 dB × 3 dB), we obtain in Fig. 6the behavior of the parameterdJin thez=(ξˆ,γˆ)plane. Notice, that the infinitesimal MSE is represented in decibel in this figure. We can see that the random variablee(p,k)is dominated by two main behaviors: over-estimation errors are introduced for negative values ofdJ(expressed in dB) in spectral components with negative a priori and a posteriori SNR. In contrast, for spectral components withξˆ(p,k)>10dB, the decision-directed and/or TS-NR approaches cause over-estimation errors (positive values in dB). These results are in agreement with the conditional mean analysis presented previously in Fig. 1. On the high-left and low-right corners in Fig. 6, we note that some combinations of the SNRs are highly unlikely and may not often enough have occurred during the training (for clarity of the representation, these points have been assigned a 0 dB value in this figure).To describe our strategy, our goal is to propose a new a priori estimatorξˆ′(p,k)=ξˆ(p,k)−Δ(p,k)which reduces over- and under-estimation errorsJ′=E{ε2(p,k)}whereε(p,k)=ξ(p,k)−ξˆ′(p,k). The correction termΔ(p,k)can be viewed as a bias compensation mechanism for the conventional a priori SNR estimateξˆ(p,k). However, for each frequency bin within each frame, deriving an analytical optimal expression for the compensation factorΔ(p,k)is difficult. As pointed in [18], correcting fully for the bias is difficult because of the nonlinear feedback loop in the decision-directed approach. Instead, our strategy consists in searching in thez=(ξˆ,γˆ)plane for the centroidal Voronoi tessalation{Ωi}i=1m(with generatorszi) and bias compensation factorsΔithat constitute the set{(Δi,Ωi)∈R×R2,i=1,⋯,m}such that(21)J′=∑i=1m∫∫Ωiε2(z)fZ(z)dσ=∑i=1m∫∫Ωi(e(z)+Δi)2fZ(z)dσis minimized.A sub-optimal solution to this problem can be obtained by using an iterative procedure such as the Lloyd–Max algorithm [25]. Starting, at timet=0, with an initial set of generators{zi(0)}i=1,⋯,m, we iterate the following steps:Step 1: Construct the Voronoi constellation{Ωi(t)}i=1,⋯,mfrom previous generators{zi(t−1)}i=1,⋯,m(22)Ωi(t)={z(p,k)∈R2|‖z−zi(t)‖<‖z−zj(t)‖,j≠i}Step 2: Compute the new bias compensation factors such that∂J′/∂Δi=0. The optimal solution is obtained as the mean value of the errore(p,k):(23)Δi(t)=E[e(z)|z(p,k)∈Ωi(t)]Step 3: Take the mass centroids of{Ωi(t)}i=1,⋯,mas the new set of generators:(24)zi(t+1)=E[z(p,k)|z(p,k)∈Ωi(t)]=∬Ωi(t)zfZ(z)dσ∬Ωi(t)fZ(z)dσ.This procedure is continued until global convergence is reached, i.e. until some stopping test criterion is fulfilled. In this work, the algorithm is stopped when further iteration no longer produce any changes in the mean-squared errorJ′=E{ε2(p,k)}or when changes are below a suitable threshold fixed by the user. In this case, an extra-computation time can be observed as the run time is depending on the selected number of clusters. As for all Lloyd–Max algorithms, the initialization of generator's values plays an important role for both the convergence speed and the asymptotic precision and many solutions have been proposed in the literature to initialize the Lloyd–Max's algorithm. As our main interest in this work is not related to the optimization of the convergence speed of the training phase, we used a simple uniform 2-D-rectangular grid (from −30 to +30 dB on each dimension,ξˆandγˆ) for the initial set of generators at timet=0.It should be noted that the considered approach is expected to improve the MMSE estimates as far as the SNR values that have been used as reference informations are perceptually better than the estimated values, In addition, as there is a bias between the estimated and the reference SNRs, we attempt to correct for this bias so that we get closer to these desirable reference values, whether or not they are the true/optimal values.In the previous sections (even in Section 4.2), we have studied the estimation inaccuracies in the a priori SNR by assuming that speech is almost always present in the observation signal. As a consequence, all the previous figures were obtained from noisy speech samples corresponding to speech activity periods (we used a handmade ideal speech detector). However, in reality, speech pauses are always present in the observation signal and this uncertainty should be taken into account in the proposed bias compensation approach. Given two hypotheses,H0(p,k)andH1(p,k)which indicate respectively speech absence and presence in the kth frequency bin of the pth frame, we have:{H0(p,k):Y(p,k)=D(p,k)H1(p,k):Y(p,k)=S(p,k)+D(p,k).The problem we face now is how to incorporate this information into the bias-corrected noise reduction algorithm that has been described in the previous Section 4.1. This problem can be easily solved by considering two different sets of parameters{zi,Δi}i=1,⋯,m(H0)and{zi,Δi}i=1,⋯,m(H1)during the training procedure, each being optimized during speech absence(H0)or presence(H1)in the observed frequency bins. A pseudocode program of the complete training algorithm including uncertainty of speech observation is shown in Algorithm 1. In this algorithm, we use the following definition:x(t)¯|t∈A=1|A|∑t∈Ax(t)to express the arithmetic mean operating on a given set of indices (|A|denotes the cardinality ofA).As previously described, a learning procedure is proposed to estimate the bias compensation parameters{zi,Δi}i=1,⋯,m. For training, we used a speech material which consists of 30 phonetically-balanced sentences recorded for the NOIZEUS database and freely available from the Website of the University of Texas at Dallas. These sentences (15 males and 15 females) were originally sampled at 25 kHz and downsampled to 8 kHz. Noisy speech files were generated by artificially adding noise to the original clean speech. Noticing that in the previous Sections 4.1 and 4.2, the time-varying Fourier coefficients of each process (noise, clean and noisy speech) were considered as (zero-mean) statistically independent random variables (as this is usually the case for a majority of speech-enhancement algorithms operating in the frequency domain), the previous assumptions are actually equivalent to the assumption that the Fourier coefficients are uncorrelated (in practice they will be correlated to a certain degree). Consequently, in the learning phase, only stationary white noise was added to the clean speech data to generate noisy speech at overall SNRs ranging from −15 dB to +25 dB, in steps of 5 dB.Once the training database is available, the previously described training procedure consisting of the combination of (22), (23) and (24) is run on the entire noisy speech database in order to estimate the parameters{zi,Δi}i=1,⋯,m. The block diagram of this procedure is depicted in Fig. 7.An illustration of the resulting Voronoi partition available at the end of training phase is depicted in Fig. 6 form=100clusters. To obtain this figure, we used the following experimental parameters: a Hamming window with a 50% overlap for spectral analysis, and a rectangular window for synthesis for the DFT-based noise reduction algorithm. One notes in Fig. 6 that the previous training procedure generates dense areas of cells that occur when the a posteriori SNR approaches 0 dB.Once the parameters{zi,Δi}i=1,⋯,m(H0)and{zi,Δi}i=1,⋯,m(H1)are known at the end of the ‘training’ phase, our aimed is to propose a bias-compensated noise reduction approach that can be implemented as an enhancement in the DD noise reduction (Proposition I) or in the TS-NR noise reduction algorithm (Proposition II). As shown in the top-level block diagram of Fig. 8, the proposed system is built on a two-stream procedure [18].It consists in running two algorithms in parallel. From relations (10), (9) or (12), a conventional DD (Proposition I) or TS-NR (Proposition II) algorithm is first run in the background to obtain a pair of estimated SNRsz=(ξˆ(p,k),γˆ(p,k))in each frame and in each frequency bin. Then, a second a priori estimateξˆ′(p,k)=ξˆ(p,k)−Δ(p,k)is computed leading to a bias-corrected SNR estimate. For each frequency bin k in each short-time frame p, the value of the bias compensation factorΔ(p,k)is selected according to the current valuez(p,k)of the estimated SNRs in the z-plane but also on the absence/presence of speech in the considered frequency bin. A pseudocode for the computation ofΔ(p,k)is given by,IfH0(p,k)=‘true’theni=argminj=1,⋯,m|z(p,k)−zj(H0)|andΔ(p,k)=Δi(H0)Elsei=argminj=1,⋯,m|z(p,k)−zj(H1)|andΔ(p,k)=Δi(H1)EndOnce the bias correction factorΔ(p,k)is known, the final spectral noise reduction filter and the output speech reconstruction is another stream that usesξˆ′(p,k)in (15) in place ofξˆ(p,k). This procedure guarantees an improvement in terms of theJ′error criterion (21), because the first stream which performs the DD or TS-NR a priori SNR estimate is left untouched (free-running algorithm). Without loss of generality, we present hereafter results obtained for the Wiener spectral gain. A pseudocode program of the complete testing algorithm including uncertainty of speech observation is described in Algorithm 2. All computations are embedded into loops over all frequency indices k and all frame indices p. During our first quality test experiments under various noise conditions, we note that, in non-stationary babble noise, the SNR estimator with bias compensation factors (23) was sensitive to noise bursts that are not tracked by the noise power estimation algorithm. To obtain full potential of the proposed method, we replace (23) by the following rule which tracks the minimum value of the error estimate within each cluster:(25)Δi(t)=minz∈Ωi(t)H(z).Using these modified compensation factors, informal listening tests demonstrate that the enhanced signals had much less speech distortion. It should also be noted that the specific properties of the spectral gain are automatically taken into account during the ‘training/learning’ phase of the proposed bias-compensation approach (see Section 4.3). The degree of compensation of the a-priori SNR bias is indeed adjusted according to the experimental differences observed between the true a priori-SNR values and the a-priori SNR estimates obtained by the considered speech enhancement estimator. In that sense, the proposed bias-compensation mechanism can be considered as a global optimization method that takes into account the intrinsic properties of the speech enhancement estimator, i.e. the gain function (Wiener gain, .... etc).

@&#CONCLUSIONS@&#
