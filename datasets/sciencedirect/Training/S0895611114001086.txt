@&#MAIN-TITLE@&#
Augmented depth perception visualization in 2D/3D image fusion

@&#HIGHLIGHTS@&#
We investigate several concepts enabling improvement of current image fusion visualization.We propose a contour enhanced visualization to circumvent hidden information in the X-ray.We implement a new occlusion and depth color-coding algorithm to improve perception in X-ray.Our occlusion correction provides 100% correctness when determining the position of an aneurysm in X-ray.The color-coding schemes improve visualization in 2D/3D overlay images.

@&#KEYPHRASES@&#
2D/3D registration,Visualization,X-ray,C-arm fluoroscopy,Depth encoding,Depth perception,Color depth encoding,

@&#ABSTRACT@&#
2D/3D image fusion applications are widely used in endovascular interventions. Complaints from interventionists about existing state-of-art visualization software are usually related to the strong compromise between 2D and 3D visibility or the lack of depth perception. In this paper, we investigate several concepts enabling improvement of current image fusion visualization found in the operating room. First, a contour enhanced visualization is used to circumvent hidden information in the X-ray image. Second, an occlusion and depth color-coding scheme is considered to improve depth perception. To validate our visualization technique both phantom and clinical data are considered. An evaluation is performed in the form of a questionnaire which included 24 participants: ten clinicians and fourteen non-clinicians. Results indicate that the occlusion correction method provides 100% correctness when determining the true position of an aneurysm in X-ray. Further, when integrating an RGB or RB color-depth encoding in the image fusion both perception and intuitiveness are improved.

@&#INTRODUCTION@&#
Wilhelm Röntgen's X-ray image is still used as the real-time imaging modality of choice in a majority of interventions [1]. To assist interventionists during procedures pre-operative images can be fused with X-ray. This 2D/3D overlay is obtained via alpha-blending; that is, a compromise in transparency between the data. Even with this shortcoming, the overlay is a gold-standard and widely used in endovascular procedures, neuroradiology, oncology, coronary interventions, electrophysiology studies, and other treatments. Although 3D imaging has the advantage of providing spatial information, intraoperative X-ray remains the focal point and main interest for the interventionist since diagnosing stenosis or aneurysms and positioning a catheter, guide wire, or stent can only be performed by visualizing this modality. Luckily, experienced interventionists have substantial training interpreting X-ray alone [2].Spatial information (or depth) is a main benefit of using 3D datasets in medical procedures. The 2D/3D overlay allows the interventionist to understand the 3D structure more quickly, especially in complex cases. The transfer functions (TFs) defined to create this overlay are crucial and are used to classify data in volume rendering based on intensity, gradient magnitude [3], curvature [4] and/or local structures [5]. The visualization of the overlay must be meaningful for the interventionist, and in this sense depth perception has been an important issue for volume rendering. Recently, Zheng et al. proposed a method for the improvement of perceptually based ordering in volume rendering [6]. They set up an energy function based on quantitative perception models to measure the quality of the images in terms of the effectiveness of depth-ordering and transparency perception. Guided by the function, they use a conjugate gradient method to iteratively and judiciously enhance the results. Alternatively, Kniss et al. proposed an interactive shading model based on volumetric light attenuation effects to incorporate volumetric shadows in volume rendering [7]. Solteszova et al. proposed a new method called chromatic shadowing based on a shadow transfer function to handle the over-darkening problem, thus allowing for better perception of details in the shadowed areas [8]. Bruckner et al. introduced volumetric halos in the volume rendering pipeline to facilitate depth perception. The halos are known as the darkened or brightened regions surrounding the edges of a targeted structure. The added halos help judge the spatial relationships more accurately [9]. Everts et al. presented a technique to create depth-dependent halos for 3D line data [10]. Adding colors for improved perception during rendering has been investigated recently. Chuang et al. suggested reducing color saturation in occluded objects only in the overlap region while keeping its lightness [11]. Wang et al. used cold colors such as green, blue, or cyan to encode the foreground, and warm colors such as red, yellow or magenta to encode background [12].Other volume rendering techniques, such as MIP (maximum intensity projection) and DRR (digital reconstructed radiograph), normally have poor depth perception. Mora et al. introduced the order-independent volume rendering (OIVR) techniques to improve MIP and DRR using gradient signals inside stereo-images. Instead of using only the original signal (the voxel data) to produce the MIP or DRR, gradient magnitude was used in the rendering to convey more information [13]. Lastly, Kersten et al. used a purely absorptive lighting model in DRR rendering to enhance the depth perception of the synthetic X-ray images [2].In 3D angiography visualization of the vascular structure is important. In principle, general rendering techniques are applicable for vascular visualization. Preim et al. give an overview of 3D vascular visualization. They distinguished two classes of approaches: model-based and model-free [14]. Model-based approaches rely on model assumptions to create easy-to-interpret visualizations, while model-free approaches represent the data more faithfully. Depth-perception is also an important task for vascular visualization. Normally the interventionist views the 3D angiograms with an interactive rotation to get a better understanding and perception of the 3D structure. However, the interventionist may not be interested in rotating the 3D visualization during procedure as their hands may be occupied with surgical instruments or contain traces of blood. Ropinski et al. proposed and evaluated several visualization techniques that support the depth perception of angiogram images [15]. Different depth cues, such as depth based color-coding, edge enhancement and depth-of-field effects, are introduced and combined to enhance depth perception of complex vascular systems. Finally, Ritter et al. and Chu et al. proposed real-time rendering pipelines and efficient modeling for illustrative visualization of vascular systems [16,17].The general workflow to attain 2D/3D image fusion is shown in Fig. 1. It becomes increasingly difficult to rapidly recognize and differentiate different structures in fused images. As previously noted, the interventionist's visual is altered since the anatomies from each modality appear floating on top of each other in the overlay. This affects the perception and natural ordering of vascular structures. With these issues in mind we note that all pixels in X-ray, and voxels in pre-operative data, do not have the same importance and contribution to the final fused images. This observation suggests extracting only relevant-based data according to the pixels or voxels [18,19].We now present previous works for visualizing 2D/3D overlays in different medical systems. The first clinical results of 3D roadmapping in neuroangiography are presented by Södermann et al. [20]. The 3D roadmap is a blended image of unsubtracted fluoroscopy with the dataset of the prior volume acquisition. The translucent 3D overlay with enhanced contours preserves much of the 2D information from fluoroscopy, however the depth perception is poor. In 2006, Gorges et al. showcased their work on 3D augmented fluoroscopy in neuroradiology [21]. In their work two visualization options were provided for 2D/3D image fusion: the surface view and the blending view. Almost no catheter/guidewire information is displayed in the surface view whereas no spatial information is visible in the blended view. In 2010, Okumura et al. presented an evaluation of 3D roadmapping for neuroendovascular procedures [22]. An obvious improvement of Okumura's work was the enhanced visualization of catheter projections. Compared to [21], the overlay is almost opaque. Since the catheter information is the main interest for the interventionist, the amplified signal of the 2D projection of the catheter is overlaid on the 3D vessel tree. One problem of this visualization is that signals of other regions are also amplified leading to a noisy image overlay. In contrast, Rossitti et al. presented the 3D roadmapping with syngo iPilot in the treatment of cerebral aneurysms and AVMs [23]. Instead of amplifying the catheter signal, a translucent representation of the 3D vessel tree is overlaid to preserve the 2D information. Another difference is that the subtracted 2D image (i.e. 2D roadmap) is used instead of the native fluoroscopic image. With an accurate 2D/3D registration, the fused 2D/3D roadmap is more efficient in delivering useful information. However, a shortcoming of this visualization is that the vessel tree contains patches of signal noise that are difficult to eliminate. The final rendered result fully depends on the transfer function, and adjusting the transfer function to reach an optimal visualization is difficult. Recently, Wieczorek et al. introduced an interactive X-ray perceptual visualization (IXPV) technique to improve 3D perception in standard X-ray images. With preoperative CT data, it allows the user to interactively manipulate the X-ray image by varying depth [24]. Aichert et al. introduced color transfer functions for the visualization of the overlay with preoperative data [25], while Wang et al. integrated a virtual mirror directly in the X-ray image which provides an interactive and real-time view, to the interventionist, of the 3D preoperative data [26].The methods presented in the cited literature review share a common drawback: there is a strong compromise between 2D and 3D information coupled with weak depth perception. Therefore, the benefit of using 2D/3D overlays is limited by those visualization methods. High transparency keeps the X-ray visible but reduces the 3D overlaid information. In this paper, we hypothesize that there are alternative techniques to improve the visualization for any 2D/3D overlay. First, we propose a contour enhanced visualization to circumvent hidden information in the X-ray image. This allows the perimeter of vessels to remain visually intact for the interventionist. Second, we implement a new occlusion and depth color-coding algorithm to improve depth perception in X-ray. An evaluation using both phantom and clinical data is performed in the form of a questionnaire. In total, 24 participants including ten clinicians and fourteen non-clinicians were asked to partake in the study.

@&#CONCLUSIONS@&#
