@&#MAIN-TITLE@&#
Experimenting a discriminative possibilistic classifier with reweighting model for Arabic morphological disambiguation

@&#HIGHLIGHTS@&#
We perform Arabic morphological disambiguation on unlabeled vocalized corpora.We experiment possibilistic measures for imprecise morphological data classification.We assess the impact of a reweighting model and a possibilistic lexical likelihood.Possibilistic classification is accurate in modern and classical texts disambiguation.

@&#KEYPHRASES@&#
Morphological analysis,Morphological disambiguation,Discriminative possibilistic classifier,Reweighting model,

@&#ABSTRACT@&#
In this paper, we experiment a discriminative possibilistic classifier with a reweighting model for morphological disambiguation of Arabic texts. The main idea is to provide a possibilistic classifier that acquires automatically disambiguation knowledge from vocalized corpora and tests on non-vocalized texts. Initially, we determine all the possible analyses of vocalized words using a morphological analyzer. The values of their morphological features are exploited to train the classifier. The testing phase consists in identifying the accurate class value (i.e., a morphological feature) using the features of the preceding and the following words. The appropriate class is the one having the greatest value of a possibilistic measure computed over the training set. To discriminate the effect of each feature, we add the weights of the training attributes to this measure. To assess this approach, we carry out experiments on a corpus of Arabic stories and on the Arabic Treebank. We present results concerning all the morphological features and we discern to which degree the discriminative approach improves disambiguation rates and extract the dependency relationships among the features. The results reveal the contribution of possibility theory for resolving ambiguities in real applications. We also compare the success rates in modern versus classical Arabic texts. Finally, we try to evaluate the impact of the lexical likelihood in morphological disambiguation.Many applications in the field of Arabic Natural Language Processing (ANLP) need to deal with the complex morphology of this language. Morphological analysis and disambiguation is an important step in Automatic Speech Recognition (ASR) (Diehl et al., 2012; Kirchhoff et al., 2006), Arabic text phonetization (El-Imam, 2004) and summarization (Azmi and Al-Thanyyan, 2012). Besides, information access applications need to index documents and extract relevant features about their meaningful entities (Bounhas et al., 2011b; Elayeb, 2009; Elayeb et al., 2009, 2011, 2014). Indeed, Information Retrieval and Knowledge Extraction Systems (IRKES) require recognizing useful entities in texts such as words, expressions and concepts. The basic level concerns the structure of words; i.e., the morphological level. Indeed, a given word may have many interpretations at this level, what is called morphological ambiguity. This phenomenon is more challenging with morphologically rich languages such as Arabic (Diab et al., 2004). Thus, a non-vocalized Arabic word may have more than 12 interpretations (Habash and Rambow, 2007; Habash et al., 2009b).In this paper, we study existent morphological disambiguation approaches applied for Arabic texts. Then, we present our framework, which allows to, automatically, learn contextual knowledge required for disambiguation from vocalized texts. This framework tries to avoid the limits of existent systems, which require manually encoded knowledge or labeled corpora. It is also an attempt to consider Arabic classical texts; because most of the existent tools were trained and assessed on modern corpora (cf. Section 1.2). Another important concern is lexical likelihood, which differs from one type of text to another. This issue is carefully studied in this paper; we examine, therefore, the effect of this factor on morphological disambiguation. Our framework is illustrated through examples (cf. Section 3) and assessed through experimental results (cf. Section 4). Indeed, the basic version of our possibilistic classifier was presented in two conference papers (Ayed et al., 2012a,b). This new contribution stands out by the following aspects.First, we present a reweighting model which tries to evaluate the discriminative power of attributes. We also take into account the discriminative power of the values of each attribute. Indeed, it is the first time that the necessity measure is being used in possibilistic classification, as the state-of-the art possibilistic classifier used only the possibility measure (Haouari et al., 2009). We also propose a new version of information entropy adapted for attribute reweighting in imprecise data. In the whole, we obtain six different classifiers (combining possibility, necessity and entropy). Besides, we compute, in the training phase, the lexical likelihood to take into account the dependencies between a given word and its features.Second, we fully re-experiment these classifies, thus assessing the impact of these discriminative weights and the lexical likelihood. In addition, this paper is a fully revised version which provides a more detailed interpretation of results. In fact, we employ the Wilcoxon Matched-Pairs Signed-Ranks Test (Demsar, 2006) to assess our results, besides computing the disambiguation rates.Finally, the experiments in Ayed et al. (2012a,b) were performed in a non-standardized traditional corpus. In this paper, we assess our model on the Arabic Treebank, thus showing its performance in a modern standard corpus.Morphological analysis tools, like Hajic's analyzer (Hajic, 2000), allow to recognize the stem of a given word and its flectional marks. The analyzer interprets a given word out of context and returns a set of possible solutions (analyses), each having different morphological features.11POS (verb, noun, particle, etc.), number (singular, dual or plural), gender (male or female), voice (active or passive), mode of the verb (indicative, subjunctive, etc.), person (first, second or third), aspect (perfect or imperfect), etc.A word is ambiguous if it has more than one solution. Disambiguation is the task of choosing, among these solutions, the most appropriate given context of the word (Ayed et al., 2012a, 2014a,b). However, this task is not easy to achieve, because of the complexity of the Arabic language morphology (Kirchhoff et al., 2006).We analyze the main sources of ambiguities in the Arabic language and their consequences as follows. In fact, this language is agglutinative, derivational and inflectional. For example, the word “وضوء” (wDw′) may be analyzed as “وُضُوء” (wuDuw′: ablution),“وَضُوء” (waDuw′: water for ablution) or(Dw′: light). In this example, the letter “و” is interpreted either as a conjunction or as the first letter of the lemma. Even in the second case, we obtain two possible lemmas diacriticized differently. In fact, the main source of ambiguity is the lack of diacritics in most existing Arabic texts. Morphological ambiguities make it difficult to extract simple terms, because the morphological analyzers enumerate for each word many possible lemmas (Bounhas et al., 2011b).Morphological ambiguities affect the other levels of analysis and mislead the results of IRKES. At the syntactic level, it is hard to identify the grammatical function of a word in a sentence. For example, the expression “” may be interpreted as(a whole sentence meaning “The man searched”), where the first word (بَحَثَ, searched) is the verb of the sentence. It may be also read as:(an annexation compound noun meaning “The research of the man”). In the same way, the structure of sentences or expressions in Arabic may affect morphological disambiguation. We mainly talk about a commonly recognized phenomenon in Arabic texts, which is called the “free word order” (Attia, 2008). For example, the previous expression (i.e.,) may be replaced bywithout changing the meaning. However, this may mislead morphological disambiguation tools as we will see in the experimental results (Section 4.2). At the semantic level, the first example (i.e., “وضوء” (wDw′)) shows that a word may have several meanings according to its morphological interpretation. From these examples, it is clear that shorts vowels (diacritics) have a great importance in understanding the grammatical category, the function and the meaning of words. Thus, vocalized texts are less ambiguous than non-vocalized ones.To disambiguate Arabic texts at the morphological level, we may exploit linguistic and/or statistical knowledge. Linguistic approaches employ rules written by linguists to label the morphological features. In related literature, we find approaches based on heuristics, contextual and non-contextual rules (cf. Daoud, 2009; Daoud and Daoud, 2009; Othman et al., 2004 for more reading). For example, Daoud (2009) and Daoud and Daoud (2009) proposed to use Universal Networking Language (UNL) and EnCo22http://libraries.unl.edu/.; a rule-based programming language specialized for the writing of EnConverters (i.e., parsers) to define disambiguation rules. They define several types of rules modeling morphological and syntactic contextual dependencies. However, it is hard to assess the coverage, the reusability and the accuracy of such an approach, especially because the authors did not present any experimental evaluation. In the same perspective, Othman et al. (2004) used a syntactic analyzer to resolve ambiguities in the morphological level. Purely linguistic approaches are fast, efficient and reliable compared to statistical ones (Daoud and Daoud, 2009). However, many of these approaches require syntactic knowledge, while Arabic syntactic analysis tools are not yet mature. Although a lot of work has been done in this field (e.g., Attia, 2008), there are no available tools to exploit in an efficient manner. Besides, the complexity of Arabic texts is hard to handle with rigid grammar formalisms, thus it is required to model several degrees of closeness between tokens and contextual information or to use fuzzy knowledge.To model fuzziness in contextual relations, Support Vector Machines (SVM) (Vapnik, 1999) and several probabilistic models (e.g., Markov Models) are used for Arabic and other languages (Diab et al., 2004; Khoja, 2001; Kirchhoff et al., 2006; Merialdo, 1994; Nguyen and Vogel, 2008; Zitouni and Sarikaya, 2009). While purely linguistic approaches need only the manual intervention of a linguist, approaches using statistical information require a training phase which may be performed in monolingual or bilingual corpora. Thus, some researchers tried to exploit the robustness of morphological taggers in other languages to resolve ambiguities in Arabic texts. For example, Nguyen and Vogel (2008) proposed to use the GIZA++ tool to align an English–Arabic bilingual corpus at the words’ level. However, we must assess the accuracy of the alignment process, which is not guaranteed. As example of approach using a monolingual tagged corpus, we may cite Khoja (2001) and Diab et al. (2004). The former computes two probabilities: (a) the lexical probability: the probability of attributing a given morphological feature (a tag) to a word; and (b) the contextual probability: the probability that a given tag follows another one. From these probabilities, grammatical rules are defined and the whole system reaches more than 90% of accuracy. However, such a tool is a tagger aiming to identify the grammatical categories of words (Par-Of-Speech, POS). Some other tools allow only restoring diacritics for non-vocalized texts. For example, Zitouni and Sarikaya (2009) used Maximum Entropy Models to perform this task.IRKES and ASR need much more information than POS and diacritics, thus covering the other morphological features. MADA (Alkuhlani et al., 2013; Habash and Rambow, 2005, 2007; Roth et al., 2008) is a first attempt for full Arabic morphological analysis and disambiguation, providing rich information about words. It is a unique tool of its type using a SVM classifier, but it was trained on modern texts. For example, it has been integrated in the ASR tool of Diehl et al. (2012).Although a great effort is being done in the field of Arabic morphological analysis and disambiguation, we feel yet the need of new approaches insuring more coverage with less effort in the learning step. Indeed, existing approaches need manually encoded linguistic knowledge or tagged corpora. Manual intervention is hard and time consuming, especially with the richness of Arabic language whose words have several features (cf. Section 2.1). It is also difficult to ensure the coverage of linguistic rules or the tagged corpora. Thus, it is necessary to develop automatic approaches allowing learning from large textual collections. Besides, it is crucial to consider classical Arabic texts, which represent an important side of the Arabic civilization and the content of the actual Web.We present an automatic approach for learning morphological feature dependencies which are used to disambiguate Arabic texts. The approach avoids the manual intervention of the user on the learning step by exploiting vocalized texts which are less ambiguous. We model the disambiguation task as a classification problem as implemented in many state-of-the-art systems (Diab et al., 2004; Habash and Rambow, 2005, 2007; Khoja, 2001; Roth et al., 2008). For example, to solve the ambiguity of the grammatical category (POS), we define, first, the appropriate attributes that describe each instance. The POS of a word is closely related to the features of its preceding and following words. We specify a window that controls the number of words (before and after) considered as attributes describing the class of an instance. In many existent approaches, the size of the window is 2 (e.g., in Habash and Rambow, 2005). Thus, to classify the POS of a specific word w, we define the attributes POS−2, POS−1, POS+1 and POS+2 if the window's size is 2. They indicate, respectively, the POS of the two preceding and the two following words of the word w. We also use the other morphological features of the preceding and the following words to determine the class value of the current word (i.e., its POS). Hence, the first step is to provide the different possible solutions and attributes of words in vocalized texts and non-vocalized texts in input.Unlike existent tools (Diab et al., 2004; Habash and Rambow, 2005, 2007; Khoja, 2001; Roth et al., 2008) which learn from tagged corpora, we build our classifier from untagged vocalized texts. This learning method is widely used for unsupervised disambiguation, because it is less-consuming (Niu et al., 2007; Seo et al., 2004). In our case, the context used to disambiguate a given word is itself ambiguous, thus needing to treat this task as a case of imprecision. Because probabilistic are not suitable to deal with such type of data, we are based on possibility theory which applies, naturally, to this kind of imperfection. To the best of our knowledge, the only operational possibilistic classifier was developed by Haouari et al. (2009). Thus, we adopt possibility theory, as it is the only framework suitable for imprecision treatment, and we present an enhanced version of this classifier (Alkuhlani et al., 2013; Bounhas et al., 2013, 2014). Consequently, our work is the first of its kind which applies this theory for morphological disambiguation.Morphological analysis tools (e.g., Hajic (2000)), try to identify the different features of a given word out of context. In this work, we use an updated version of BAMA 1.2.1 (Buckwalter, 2004) (AraMorph), which can interpret vocalized texts. AraMorph identifies the grammatical categories33http://www.nongnu.org/aramorph/english/grammatical_categories.html.of the prefixes, the suffixes and the stem of each word. We use the same 14 morphological features of MADA (Habash and Rambow, 2005, 2007; Roth et al., 2008), which are: POS, conjunction, particle, determiner, pronoun, person, voice, aspect, gender, number, case, preposition, mode and adjective (Ayed et al., 2012b, 2014a,b). Conjunction, particle, determiner, preposition and adjective have binary values indicating if a word contains or not, respectively, a conjunction, a particle, a determiner, a preposition or an adjective. The value of a feature which starts with the “N” means that this word does not contain it. POS, pronoun, person, voice, aspect, gender, number, case and mode provide the values of the corresponding features (Ayed et al., 2012a,b, 2014a,b).We prepare data by defining, for each vocalized word, an instance extracted from its morphological analysis. An instance is described by a list of attribute values (e.g., POS−2, POS−1, pronoun+2, etc.). Finally, possibility distributions (see Section 2.2.1) are computed for all the available instances (as discussed in Section 2.3). A subset of the generated test collection is used for training and the remaining instances are exploited to assess the accuracy of our classifiers according to the cross-validation method.Possibility Theory was inspired by Gaines and Kohout (1975), invented in 1977 by Zadeh (1978) and developed by several authors (Dubois and Prade, 1985, 1998). It is devoted to deal with incomplete information specifically uncertain and imprecise (Alkuhlani et al., 2013; Bounhas et al., 2013, 2014). Unlike the probability theory, possibility theory differentiates between uncertainty and imprecision. There is imprecision whenever a reality state is equivocal i.e., it is described by a multi-valued propositional variable (fuzzy set (Zadeh, 1978)) (Ayed et al., 2012a). Uncertainty is a further information that supports the fact of not knowing or providing a statement to determine the truth value of a proposal (probability) (Dubois and Prade, 2000, 2010; Jaynes and Bretthorst, 2003). Indeed, the morphological ambiguities are cases of imprecision. Then, to disambiguate a given word, we use the features of the preceding and following words which are themselves ambiguous (i.e., multi-valued propositional variables). In the following sub-sections, we present the main concepts of possibility theory. For more details, we refer to Dubois and Prade (1985, 1998).We denote Ω={ω1, ω2, …, ωn} the universe of discourse that characterizes a set of activities (i.e., states of the real world). We designate π a possibility distribution. It represents a mapping from Ω to an ordered scale (i.e., the interval [0,1]). The possibility degree is the affected value. The possibility distribution provides a thorough knowledge about the actual state ωi. It distinguishes what is plausible from what is less plausible. If a possibility degree is equal to 0, the state ωiis revealed as impossible. The state becomes absolutely possible once the degree is equal to 1.We determine the degree of plausibility and certainty of a state by calculating two measures which are: possibility and necessity. We designate A a subset of states counted in the universe of discourse Ω. We describe the possibility measure of A, given a possibility distribution π (defined on Ω), as follows:(1)Π(A)=maxω∈Aπ(ω)We present the necessity measure (N) which is derived from the possibility measure:(2)N(A)=minω∉A1−π(ω)=1−Π(A¯)A¯symbolizes the complement of A, i.e., the elements of Ω that do not belong to the event A. Π(A) assesses the consistence degree of the event A with the knowledge π whereas N(A) appraises to what extent A is certainly inferred by the knowledge represented by π. It defines the degree to which we expect the occurrence of the event A (Dubois and Prade, 1985).An object or a case is described by the values of a given set of attributes. Classifiers ascribe a class, from a predefined set, to this object or case considering the values of attributes. There are many methods of supervised classification including neural networks (Bishop, 2007), Naïve Bayesian networks (Pearl, 1997), decision trees (Quinlan, 1986), K-nearest neighbors (Cover and Hart, 1967) and Support Vector Machines (SVM) (Vapnik, 1999). Previous works attested the effectiveness of the Naïve Bayesian networks to accomplish an appropriate classification. Nevertheless, these classifiers encounter problems as they are unable to treat imprecision. To treat this problem, Haouari et al. (2009) made out the Naïve Possibilistic Network Classifier. We take advantage of the simplicity and accuracy of this classifier to output a disambiguation approach to which we add the discriminative aspect. Therefore, we present in the next paragraphs, the basic measures and functions used in the training and test phases. Besides, we explain the discriminative aspect and the reweighting model of our classifier.In this step, we train a classifier for each feature. We should take into account the fact that the attributes and/or the classes of the classification instances are imprecise i.e., having many possible values. The imprecision is handled by possibility distributions denoted by π. Let T be a collection of data and Ikthe set of the values of the attributes of the instance number k. We also denote Ajthe attribute number j from this set and ajLa possible value of Aj. Inspired from Haouari et al. (2009) and the possibilistic information retrieval model (Bounhas et al., 2011b; Elayeb et al., 2009; Elayeb, 2009), we compute the normalized frequency of an attribute value (ajL) for a class cias follows:(3)Freq(ajL,ci)=Occ(ajL,ci)MaxL=1|Aj|Occ(ajL,ci)where Occ(ajL,ci) is the number of instances that have the class ciand the value ajLfor the attribute Ajand |Aj| is the number of possible values of Aj. Indeed, we used the MAX operator to obtain the normalized frequencies such used in possibilistic information retrieval (Bounhas et al., 2011b; Elayeb, 2009; Elayeb et al., 2009, 2011, 2014). Then, the sum of the frequencies of all the values of an attribute, given a class ci, is not equal to 1, which is one of the main hypothesizes of possibility theory to deal with imperfect data.In the imperfect case, the number of occurrences of an attribute value is fuzzy:(4)Occ(ajL,ci)=∑k=1|T|βjk*∅ijkLwhere βjkindicates the imprecision rate of the attribute Ajin the instance Ik. As our corpus is unlabeled, we adopt the uniformity assumption which leads to the fact that, in the learning step, if an attribute (or the class) has many possible values, all these values have equal possibility to be correct. Thus, if, in a given instance, an attribute has two possible values and the class has only one possible value, the imprecision rate is 0.5. βjkis computed as follows:(5)βjk=1|Ajk|*|Ck||Ajk| denotes the cardinal of the set of the values of Ajin the instance Ik. In the same way, |Ck| is the number of possible classes for Ik. ∅ijkLis equal to 1 if the value ajLexists in the possible values of Ajin the instance Ik, and the class ciexists in the possible classes of Ikand 0 elsewhere. Thus, the more the instance is imprecise (in its attributes and/or class values), the more this factor βjkis decreased.We compute the possibility of each class cigiven an imperfect instance (Ik) having m attributes. This measure was inspired from the Naïve Possibilistic Network Classifier of Haouari et al. (2009). The possibility measure is the product of the frequencies of all the attributes. However, a specific factor is added for imprecise attributes. For example, if an attribute has three possible values, we compute the product of the frequencies of these three values, then we introduce a weight (βjk) equal to 1/3, as we adopt the uniformity assumption. Hence, we introduce the possibility measure as follows:(6)Π(Ci|Ik)=∏j=1m∏L=1|Ajk|Freq(ajL,ci)*βjkWe finally have:(7)socre(ci|Ik)=Π(ci|Ik)The basic classifier inspired from Haouari et al. (2009) does not evaluate the discriminative power of attribute values, since it uses only the possibility measure (formula (6)). However, we may discover that some values of a given attribute have greater impact in determining the correct class. Possibility theory models this fact by the necessity measure. That is, possibilistic IRKES (Bounhas et al., 2011b; Elayeb, 2009; Elayeb et al., 2009, 2011, 2014) use this measure to evaluate the discriminative power of query terms; i.e., terms which exist only in few documents have greater impact in relevance evaluation. Based on this idea and inspired from previous works (Bounhas et al., 2011b; Elayeb, 2009; Elayeb et al., 2009, 2011, 2014), we propose to compute the necessity measure to classify instances in the testing step as follows:(8)N(ci|Ik)=1−∏j=1m∏L=1|Ajk|(1−φijk/βjk)Here again, we are obliged to consider all the possible values of the imprecise attributes, by computing the product(ΠL=1|Ajk|)and the imprecision rate (βjk). As in IRKES, we have:(9)φijk=log10PnCjL*Freq(ajL,ci)In this formula, P is the number of possible classes and nCjLis the number of classes having a non-null frequency with the value ajL(i.e., Freq(ajl, ci)>0).The necessity may be directly used for classification as follows:(10)socre(ci|Ik)=N(ci|Ik)Also, we may combine it with the possibility measure as defined in possibilistic IRKES (Bounhas et al., 2011b, 2013, 2014; Elayeb, 2009; Elayeb et al., 2009, 2011, 2014):(11)socre(ci|Ik)=Π(ci|Ik)+N(ci|Ik)In our experiments, we will compare three alternatives adopting, respectively formulae (7), (10) and (11) to identify the best class. In all the cases, the best class for the instance Ikis the one having the greater score among all the classes:(12)c*=argmaxciscore(ci|Ik)The reweighting model allows assigning absolute weights to the classification attributes. Disambiguation tools, like MADA (Alkuhlani et al., 2013; Habash and Rambow, 2005, 2007; Roth et al., 2008), implement such models to relatively evaluate these attributes and enhance classification rates. This permits to reduce the contextual space required to disambiguate a given feature and thus simplifying the disambiguation process.In our case, we compute the information gain based on information entropy (Blansché, 2006; Quinlan, 1986), which has been used in many areas of artificial intelligence such as privacy in online services (Krause and Horvitz, 2008), clustering (Liping et al., 2007) and classification (Yue, 2012). The use of entropy in classification is justified by its ability to partition the space into non-overlapping decision regions for classification. This is exactly what is required for morphological disambiguation as the different values of a class (i.e., noun and verb and so on for the POS) allow partitioning the words into completely separated sets. As explained by Lee et al. (2001), “both the complexity and computational load of the classifier are reduced and thus the training time and classification time are extremely short”. In our case, this factor is important as the full morphological analysis is time consuming and our tool will be used in IRKES, which require short response time. In addition, Lee et al. (2001) claim that the “entropy-based feature selection procedure not only reduces the dimensionality of a problem but also discards noise-corrupted, redundant and unimportant features”.The entropy may be used to weight attributes as follows (Quinlan, 1986). However, we will be obliged to adapt the formulae to the imperfect case. The main change is to introduce factors allowing to assign lower weights to the attributes or the classes, which are imperfect (i.e., have many possible values). This change is a constraint imposed by the kind of application, namely the disambiguation task. The examples in Section 3 will explain and show the importance of these factors.Let S be a given set of instances. If we have P classes, then S is segmented into P subsets: S={S1, …, SP} where the instances of each Sibelong to the same class.The information entropy of S, in the perfect case, is given by (Blansché, 2006):(31)I(S)=−∑i=1P|Si||S|log2|Si||S|We suppose that the attribute Ajhas v different values. The entropy or the information required to classify the instances of all the subsets of T, according to the attribute Aj, is given by:(14)E(Aj)=∑L=1vIk∈T|Aj=ajL|T|*I(Ik∈T|Aj=ajL)In the imprecise case, it is not possible to compute directlyIk∈T|Aj=ajL. It is also necessary to adapt formula (14) in order to compute I(Ik∈T|Aj=ajL). Indeed, we cannot attribute a binary value to Aj=ajL, because each attribute may contain several possible values, which are equally weighted.We perform as follows:(15)E(Aj)=∑L=1vFjL|T|*I′(Ik∈T|Aj=ajL)where FjLis a fuzzy count of the instances having the value ajL. It is given by:(16)FjL=∑k=1|T|1|Ajk|*∅jkLwhere ∅jkLis equal to 1 if the value ajexists in the possible values of Ajin the instance Ikand 0 elsewhere. Again, we divide by |Ajk| to decrease the weights of the imprecise case. We also have:(17)I′(Ik∈T|Aj=ajL)=−∑i=1POcc(ajL,ci)FjLlog2Occ(ajL,ci)FjLwhere Occ(ajL,ci) is calculated according to formula (4). The information gain (Blansché, 2006) of the attribute Ajis computed as follows:(18)Gain(Aj)=I′(T)−E(Aj)I′(T) is computed as follows:(19)I′(T)=−∑i=1POcc(ci)|T|log2Occ(ci)|T|where Occ(ci) is a fuzzy count of the instances having the class ci. It is given by:(20)Occ(ci)=∑k=1|T|1|Ck|*∅ikwhere ∅ikis equal to 1 if the value ciexists in the possible classes of the instance Ikand 0 elsewhere.Finally, we introduce the information gain in the possibility and the necessity measures by modifying formulae (6) and (8) as follows:(21)Π(ci|Ik)=∏j=1m∏L=1|Ajk|Freq(ajL,ci)*βjk*Gain(Aj)(22)N(ci|Ik)=1−∏j=1m∏L=1|Ajk|1−φijLβik*Gain(Aj)Every single instance of the training and the test sets describes the attributes values of one word. Thus, the possibilistic classifier does not take into account the word value to determine its accurate analysis (class). Hence, including the word value to compute the possibilistic score (cf. formula (12)) becomes crucial. The lexical likelihood is integrated in the most language taggers (Jurafsky and Martin, 2009). It studies the coexistence of a word with a particular class over a training set. If wiis the word of the test instance Ik, then its lexical likelihood is P(wi|ci). The latest measure defines the probability that the word, in the current test's instance, is wiknowing that the associated class is ci. In other terms, this lexical likelihood answers the question: if we were expecting a class ci, for the instance Ik, how likely is it that the related word would be wi? Therefore, the chosen class for the instance Ikis the one having the highest score combining the feature-based score (score(ci|Ik)) and the lexical likelihood of its word (score(ci|wk)). This score is computed in the same manner; i.e., we can use the possibility and/or the necessity.(23)c*=argmaxci(score(ci|Ik)*socre(ci|wk))The lexical likelihood requires the coexistence of a word wiwith a class value ciin the training set, otherwise, the c* value turns into zero. Thus, this measure is considered that when this condition is fulfilled. If score(ci|wk) is equal to zero then we omit it and we turn to compute the formulac*=argmaxci(score(ci|Ik)).This section presents examples for the different steps of morphological disambiguation; i.e., morphological analysis, training and testing with and without reweighting.We extract information about all the morphological features of each word in vocalized texts. A vocalized word provides often a single analysis. Examples of words from a vocalized text (see Fig. 1) with some of their possible solutions are shown in Table 1. We give a description of each feature in the second column. For instance, ÝóíóÃúßõáõ (faya>okulu: “and then he eats”) contains a conjunction (CONJ); does not contain a particle (NPART), does not contain a determiner (NDET) (since it is not a name), has no case or mode (NCASE and NMODE), does not contain preposition (NPREP) and is not an adjective. This word is an imperfect verb in the 3rd person masculine singular (IV3MS).After analyzing the vocalized words, we build the training set composed of instances which are described by attributes and class values generated by the morphological analyzer. We ascribe to each word an instance. We assume, in this example, that we classify the POS using the attributes describing the POS of the two preceding and the two following words. We consider a training set made up of 4 instances presented in Table 2. The second instance contains an imperfect attribute that is POS−1 (i.e., β11=1/2=0.5). We compute the frequencies as detailed in Table 3.For example, to compute Occ (POS+1=VERB_IMPERFECT, POS=NOUN_PROP), we search for instances which have NOUN_PROP in the class (POS); i.e., the first instance. For this instance, the imprecision rate is 1/2, because the class has two possible values. Thus, we have: Occ (POS+1=VERB_IMPERFECT, POS=NOUN_PROP)=(1/2)*1=0.5. The same approach is used to handle attribute imprecision. That is, the number Occ (POS−1=VERB_PERFECT, POS=NOUN) is equal to 1*(1/2)=0.5, because VERB_PERFECT appears only once in the attribute POS−1 with the class NOUN and the attribute has two possible values.We compute the global information quantity as follows:I′(T)=−2.54log22.54−14log214−0.54log20.54=1.29We, also, compute the information gain of the four attributes as detailed in Table 4.We define a new instance (see Table 5) for which we want to identify the POS, using the POS−2, POS−1, POS+1 and POS+2 attributes, based on our calculus in the training step. This instance is assigned to a non-vocalized word whose POS is ambiguous i.e., has more than one morphological analysis.We compute the possibility measure for the three classes as follows:Π(ci=NOUN|Ik)=Freq(POS−2=NOUN_PROP,ci=NOUN)*0.5*Freq(POS−2=PRON_3MS,ci=NOUN)*0.5*Freq(POS−1=VERB_PERFECT,ci=NOUN)*1*Freq(POS+1=PRP,ci=NOUN)*1*Freq(POS+2=VERB_IMPERFECT,ci=NOUN)*1=0*0.5*0*0.5*0.5*1*0*1*1*1=0Thus, the values of the first attribute (POS−2) are weighted by β1k=0.5, because this attribute has two possible values. In the same manner, we have:Π(ci=VERB_PERFECT|Ik)=0*0.5*1*0.5*0*1*0*1*0*1=0Π(ci=NOUN_PROP|Ik)=0*0.5*0*0.5*0*1*0*1*0*1=0We remark that all the possibility values are null due to the negligible size of the training set. However in real situations much more frequencies will be non-null, thus leading to non-null possibility values.The necessity is computed as:N(ci=NOUN|Ik)=1−[(1−0/0.5)*(1−log10(3/1)*0/0.5)*(1−log10(3/1)*0.5/1)*(1−0/1)*(1−log10(3/1)*1/1)]=0.60For the remaining classes, we obtain: N (ci=VERB_PERFECT|Ik)=0.95 andN(ci=NOUN_PROP|Ik)=0When we introduce the information gain of the attributes, we obtain:Π(ci=NOUN|Ik)=Π(ci=VERB_PERFECT|Ik)=Π(ci=NOUN_PROP|Ik)=0N(ci=NOUN|Ik)=1−[(1−0/(0.5*0.89))*(1−log10(3/1)*0/(0.5*0.89))*(1−log10(3/1)*0.5/(1*0.7))*(1−0/(1*0.54))*(1−log10(3/1)*1/(1*0.54))]=0.92N(ci=VERB_PERFECT|Ik)=1.07N(ci=NOUN_PROP|Ik)=0That is, if we use the necessity or we combine the two measures with or without reweighting, we select “VERB_PERFECT” as a POS for this instance. However, the attribute weights changed the scores assigned to the different classes, which will have greater impact in real situations.This section presents the test collection used in our experiments, the evaluation method and the experimental results highlighting several aspects of our classifiers.The major aim of our approach is to acquire morphological dependencies from vocalized texts and test on non-vocalized ones. Besides, we consider classical Arabic texts, which have been ignored in previous related works. Therefore, we use a collection of Arabic stories i.e., “Hadith”44http://www.islamweb.net/hadith/index.php.which have been the issue of several works (e.g., (Bounhas et al., 2010, 2011b; Harrag et al., 2009, 2013)). Hadiths talk about all the real-life concerns and cover common and universal knowledge. To justify our choice, we assess that the corpus of hadith is one of the few vocalized Arabic corpora. Besides, the hadith corpus is bigger than TreeBanks (Habash et al., 2009a; Maamouri et al., 2009; Maamouri and Bies, 2004), since it contains 1400 vocalized books of hadith, each one holding thousands of Arabic stories.3 The six most famous and reliable books contain more than 2.5 million words and more than 95,000 fragments (titles and paragraphs). Moreover, this corpus is well structured and the titles of chapters and sub-chapters represent relevant contextual information to disambiguate texts (Bounhas et al., 2011b). In addition, the books of hadith are widely used in information retrieval and knowledge extraction, because of their huge size (Harrag et al., 2009, 2013). However, we recognize that most of the hadiths are assigned to one person (i.e., the prophet PBSL), which may make of it not an ideal source for modeling. Nevertheless, many hadiths are speeches of other persons like the companions of the prophet (PBSL) and many narrators add other expressions especially when they narrate stories and not speeches, thus enriching the corpus and making it less specific.We use, among the hadith corpus, the well-recognized six encyclopedic books organized by theme which are: Sahih Al-Bukhari, Sahih Muslim, Sunan Abi Dawud, Sunan Ettermidhi, Sunan Ibn Majah and Sunan Annasaii (Al-Echikh, 1998). As detailed in Table 6, we limit our experiments to three sub-corpora corresponding to the following domains of interest:(Al>$rbp “drinks”),(AlzwAj “marriage”) and(AlThArp “purification”) (Ayed et al., 2012a).The cross-validation method (Kohavi, 1995) is commonly used over a dataset that can be divided into significant sub-sets. Indeed, we apply this method on the six books of hadith to estimate the performance of our possibilistic classifier, thus procuring six combinations. For each combination, five books are used for training and the remaining one is employed for testing. The average success rate is computed over the 5+1 combinations. To get these rates, we perform as follows: (a) the vocalized texts are analyzed and the correct morphological solutions are stored; (b) the short vowels of the same texts are removed; (c) the obtained texts are disambiguated with our classifier and the results are stored; and (d) we compare the two results (Ayed et al., 2012a,b).

@&#INTRODUCTION@&#


@&#CONCLUSIONS@&#
