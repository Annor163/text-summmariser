@&#MAIN-TITLE@&#
Multi-scale prediction of water temperature using empirical mode decomposition with back-propagation neural networks

@&#HIGHLIGHTS@&#
The novel model which combines EMD and BPNN algorithm is presented to predict water temperature in intensive aquaculture..Using EMD technology adaptively decomposed the original water temperature data into a finite set of IMFs and a residue.EMD-BPNN has higher prediction accuracy and better generalization performance than standard BPNN and standard SVR.EMD-BPNN can be used as a suitable and effective modeling tool for predicting water temperature in intensive aquaculture.

@&#KEYPHRASES@&#
Empirical mode decomposition,Back-propagation neural network,Water temperature,Multi-scale prediction,

@&#ABSTRACT@&#
In order to reduce aquaculture risks and optimize the operation of water quality management in prawn engineering culture ponds, this paper proposes a novel water temperature forecasting model based on empirical mode decomposition (EMD) and back-propagation neural network (BPNN). First, the original water temperature datasets are decomposed into a collection of intrinsic mode functions (IMFs) and a residue by EMD yields relatively stationary sub-series that can be readily modeled by BPNN. Second, both IMF components and residue is applied to establish the corresponding BPNN models. Then, each sub-series is predicted using the corresponding BPNN. Finally, the prediction values of the original water temperature datasets are calculated by the sum of the forecasting values of every sub-series. The proposed hybrid model was applied to predict water temperature in prawn culture ponds. Compared with traditional models, the simulation results of the hybrid EMD–BPNN model demonstrate that de-noising and capturing non-stationary characteristics of water temperature signals after EMD comprise a very powerful and reliable method for predicting water temperature in intensive aquaculture accurately and quickly.

@&#INTRODUCTION@&#
In the engineering breeding process of prawn, water temperature that is too high or too low will affect the growth and metabolism of shrimp [1,2], and can directly and indirectly influence other water quality indexes, trigger deterioration of water quality, and lead to disease outbreaks seriously affecting normal production and business operation [3]. Therefore, it is of utmost importance to use intelligent information processing technology to forecast water temperature and dissolved oxygen content [4]. More specifically, accurately predicting water quality not only provides a basis for water quality control and management decisions that can minimize aquaculture risks and optimize the treatment operation, but also ensures the healthy and sustainable development of the shrimp industry [5,6].In recent years, many domestic and foreign experts have studied artificial neural networks (ANN) for water quality prediction [7–10]. For example, Ma et al. utilized backpropagation neural network as a modeling tool for the prediction of water quality in intensive Litopenaeus vannamei shrimp tanks [7]. Faruk proposed a hybrid ANN and ARIMA model to predict a time series of water quality data; their results indicate that the hybrid model produces better predictions than either the ARIMA model or the neural network [8]. Sarkar and Pandey presented a feed forward error back propagation neural network to estimate the DO concentrations at the downstream of Mathura city, India, located at the bank of river Yamuna in the state of Uttar Pradesh, India. The experimental results demonstrate its effectiveness [9]. DeWeber and Wagne developed an artificial neural network (ANN) ensemble model to predict mean daily water temperature in 197,402 individual stream reaches during the warm season throughout the native range of brook trout Salvelinus fontinalis in the eastern U.S. [10]. These studies indicate a growing interest in using ANN as a useful technique for predicting water quality due to the ability to capture subtle functional relationships within empirical data even when the underlying relationships are unknown or difficult to describe [11,12]. They do not require strong model assumptions and can map any nonlinear function without a priori assumption about the properties of the data [13,14] and as such have higher forecasting accuracy. These results encourage the adoption of back-propagation neural networks (BPNN) for studies of water quality forecasting.When using BPNN for water quality prediction, the observed original values of prediction variables are usually directly used for building prediction models [14]. However, as water quality in prawn intensive aquacultures consistently suffers from various factors contributing to instability, including unpredictable weather conditions, biological factors, chemical in the water, dynamic hydrodynamics, human activity and more [5,12,13], the water quality series often shows a highly nonlinear and inherently non-stationary characteristic, which makes capturing its non-stationary properties and accurately describing water quality trends immensely difficult.The empirical mode decomposition (EMD) approach can decompose complicated signal into a series of intrinsic mode functions (IMFs) through the sifting process [14,15]. Each IMF component represents only one mode of oscillation imbedded in the signal at a certain scale or frequency band that is quite distinct from others. It also can reveal hidden patterns and trends of time series, which can effectively assist in designing prediction models for various applications, such as in the prediction of non-stationary wind speed [16,17], automatic bearing fault diagnosis [18], kurtosis forecasting of bearing vibration signal [19], PM2.5 forecasting [20], and electricity demand forecasting [21], among others. However, existing literatures regarding water quality forecasting have not adopted EMD processes. This study attempts to fill this gap.Motivated by previous studies [14,16], we present a novel prediction model based on EMD and BP neural networks models to predict water quality in intensive prawn aquaculture ponds. This paper is organized as follows: Section 2 describes EMD and BP neural networks methods; Section 3 describes the proposed model; Section 4 presents the experimental results; and Section 5 provides the conclusions of this study.Empirical mode decomposition (EMD) is a nonlinear signal adaptive decomposition technique proposed by Huang et al. [22]. It is used to decompose a nonlinear and non-stationary time series into a sum of intrinsic mode function (IMF) components with individual intrinsic time scale properties. In contrast to other data analysis methods, the key innovation embodied in the EMD, which has allowed it to be applied broadly, is that the basic functions are derived directly from the signal itself [23].According to Huang et al. [22], an IMF is a function that represents a hidden oscillation mode embedded in the data series, which must satisfy the following two conditions: (1) the number of extrema and the number of zero crossings are either equal or differ at most by one, which corresponds loosely to finding “narrow-band” signals or eliminating “riding-waves”; and (2) at any point, the mean of its upper and lower envelopes equals zero, which ensure that the instantaneous frequency will not have unwanted fluctuations arising from asymmetric wave forms. The detailed decomposition process of EMD is presented by Huang et al. [16]. Suppose that a data time series x(t) can be decomposed according to the following procedure [22,23]:(1)Identify all the local maxima and minima of x(t).Connect all local extrema by a cubic spline line to generate x(t) upper and lower envelopes xup(t) and xlow(t) of the x(t).Adopt the upper envelope xup(t) and the lower envelope xlow(t) to compute the first mean time series m1(t), i.e., m1(t) = [xup(t) + xlow(t)]/2.Evaluate the difference between the original time series x(t) and the mean time series to achieve the first IMF h1(t), i.e., h1(t) = x(t) − m1(t). Check whether h1(t) satisfies the two conditions of an IMF property. If they are not satisfied, repeat Steps 1 through 3 of the decomposition procedure until the first IMF is found.The EMD extracts the next IMF by applying the above sifting procedure to the residual term r1(t) = x(t) − c1(t), where c1(t) denotes the first IMF. The decomposition process can be repeated until the last residue rn(t) has at most one local extremum or becomes a monotonic function from which no more IMFs can be extracted, at which point the decomposition procedure is halted [23].The original time series x(t) can be reconstructed by summing all the IMF components and the one residue component as follows [22]:(1)x(t)=∑i=1nci(t)+rn(t)where n is the number of IMFs and ci(t) (i = 1, 2, … , n) are the values of each IMF, which are nearly orthogonal to each other, which are different in each frequency band, and which change with variation of time series signal x(t). The rn(t) is the final residue, which represents the central trend of time series signal x(t). Thus, every signal can accomplish decomposition of the data series into n-empirical mode functions and one residue.The back-propagation neural network is a supervised learning technique [24], and it has recently been used to deal with approximation of nonlinear maps. In the network, there is an input layer, an output layer, and one or more hidden layers between them. The topology of the BPNN is shown in Fig. 1.During training, an input pattern is given to the input layer of the network. Based on the given input pattern, the network will compute the output in the output layer. This network output is then compared with the desired output pattern. The aim of the back-propagation learning rule is to define a method of adjusting the weights of the networks. Eventually, the network will give the output that matches the desired output pattern given any input pattern in the training set.The input Ikand output Okto the kth neuron are determined by the following equations:(2)Ik=∑i=1nμi,kOi(3)Ok=f(Ik+ϑk)where μi,kis the weight of the connection from the ith neuron in the previous layer to the kth neuron, f(Ik+ ϑk) represents the activation function of the neurons, Okis the output of neuron k, and ϑkis the biases input to the neuron [25]. In order to improve performance, we adopted the bipolar sigmoid activation function, which is defined as follows:(4)f(x)=21+exp(−x)−1Additionally, we used the mean square error (MSE) to evaluate the learning effects of BPNN. The training continues until the MSE falls below some threshold or tolerance level. The MSE is defined as follows:(5)MSE=1n∑i=1n(yi−y^i)2where n is the number of training patterns, and yiand ŷiare actual and prediction values, respectively.The framework of the water quality forecasting based on EMD–BPNN is shown in Fig. 2. The detailed calculation steps are described as follows:Step 1.Use the EMD to decompose the original water quality into a finite set of different sub-series which can be identified, separately predicted and recombined to achieve aggregate forecasting.Apply the BPNN. Building a forecasting model for the each subseries, the BPNN models are then applied to forecast values of these sub-series for the next ten minutes.The final forecasting value is obtained by the sum of the above predicted results for the original time series.Through the EMD method, raw water quality data having dissimilar characteristics can be displayed on different scales, which allows for more fully capturing the local fluctuations of raw water quality data. Moreover, each IMF (here the different sub-series are considered one IMF) has similar frequency characteristics, simple frequency components and strong regularity, therefore allowing this model to reduce the complexity of BPNN modeling and further improve BPNN forecast efficiency and accuracy.

@&#CONCLUSIONS@&#
