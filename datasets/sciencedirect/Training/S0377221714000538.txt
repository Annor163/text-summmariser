@&#MAIN-TITLE@&#
Testing inference in heteroskedastic fixed effects models

@&#HIGHLIGHTS@&#
We wrote the test statistics as ratios of Gaussian quadratic forms.We used numerical integration to compute their exact null distributions.We compare the limiting null distribution with the exact null distributions.Most accurate asymptotic approximations are obtained with CHC4 and CHCR0 tests.We recommend that inference in FE models be based such quasi-t test statistics.

@&#KEYPHRASES@&#
Distribution,Simulation,Heteroskedasticity,Numerical integration,Longitudinal data,Quasi-t tests,

@&#ABSTRACT@&#
This paper considers the issue of performing testing inference in fixed effects panel data models under heteroskedasticity of unknown form. We use numerical integration to compute the exact null distributions of different quasi-t test statistics and compare them to their limiting counterpart. The test statistics use different heteroskedasticity-consistent standard errors. Our results reveal that the asymptotic approximation is usually poor in small samples when the test statistic is based on the covariance matrix estimator proposed by Arellano (1987). The quality of the approximation is greatly increased when the standard error is obtained using other heteroskedasticity-consistent estimators, most notably the CHC4 estimator. Our results also reveal that the performance of Arellano’s test improves considerably when standard errors are computed using restricted residuals.

@&#INTRODUCTION@&#
Fixed effects (FE) regression models usually display some sort of heteroskedatiscity (non-constant error variance). The fixed effects estimator (FEE) remains unbiased, consistent and asymptotically normal when the error variances are not constant. Its usual covariance matrix estimator, however, is no longer valid since it estimates the wrong covariance matrix. The FEE has been widely used in panel data (PD) econometric analyses to deal with individual heterogeneity. In a heteroskedastic linear FE model, when heteroskedasticity is of unknown form, the common practice is to use the FEE coupled with a consistent estimator for its covariance matrix. The estimator proposed by Arellano (1987), which is an extension of the HC0 heteroskedasticity consistent estimator estimator introduced by White (1980), is the most commonly used estimator in practical applications. It is consistent under both homoskedasticity and heteroskedasticity and allows for whithin group correlation.For instance, when using a FE regression model in two-stage DEA (Data Envelopment Analysis) modeling it is important to account for unequal error variances, i.e., for heteroskedasticity. Banker and Natarajan (2008) note that the second stage can be performed using a log-linear model. It is important, however, that the basic assumptions hold true, as noted by Simar and Wilson (2011). Accordingly, McDonald (2009) and Lee and Johnson (2011) recommend the use of heteroskedasticity-consistent standard errors.The results in our paper are important for those who carry out empirical analyses using FE models. In such analyses, testing inferences are made on the parameters that index the model in order to determine which covariates should be in the model and which covariates should be removed from the model. Testing inference based on the CHC0 estimator available in the literature can be considerably liberal, which means that often one will keep in the model independent variables that are not relevant. Some of the alternative testing strategies proposed (and numerically evaluated) in this paper yield much more accurate inferences.Our main aim in this paper is to consider alternative heteroskedasticity-consistent standard errors and to use numerical integration to compute the exact null distribution of the corresponding quasi-t test statistics. In particular, we consider adaptations to FE panel data modeling of the following covariance matrix estimators: HC2, proposed by Horn, Horn, and Duncan (1975); HC3, introduced by Davidson and MacKinnon (1993); and HC4, proposed by Cribari-Neto (2004). We construct the estimators using both unrestricted and restricted residuals. The exact null distributions we compute are then compared to their asymptotic counterpart in order to assess the quality of the first-order approximation used when performing testing inference. Similar results for linear regressions with cross-sectional data can be found in Chesher and Austin (1991) and Cribari-Neto, Ferrari, and Oliveira (2005). We also report numerical evidence on the powers of the tests.The paper is structured as follows. Section 2 presents the FE model and the different covariance matrix estimators. In Section 3 we write the test statistics as ratios of Gaussian quadratic forms.Numerical results are reported in Section 4. Finally, some concluding remarks are offered in Section 5.The model of interest is the linear FE regression model:(1)yit=αi+xitβ+uit,wherei=1,…,nindexes the individual dimension andt=1,…,Tindexes the time dimension, so that there are T observations on each individual. Here,xitis a1×pvector of covariates anduitis the error component. Theαi’s capture non-observable effects due to heterogeneity and theuit’s are independent and identically distributed (i.i.d.), varying in both i and t.uitit is said to be an idiosyncratic error/disturbance (Wooldridge, 2010).Model (1) can be easily represented in matrix form. By stacking the T observations for each i, (1) becomesyi=αi+Xiβ+ui, where each component indexed by i is a vector of dimensionT×1:yi=yi1,…,yiT′,Xi=xi1,…,xiT′andui=ui1,…,uiT′. By stacking the observations once again, we obtainy=α⊗ιT+Xβ+u,wherey=(y1,…,yn)′,u=(u1,…,un)′andX=(X1,…,Xn)′. The fixed effect is captured byα=(α1,…,αn)′. Here,ιTis aT×1vector of ones and⊗denotes the Kronecker product. Additionally, y is ann×1vector of observations on the dependent variable, X ann×pmatrix of regressors (withp<n),βis ap×1vector of unknown parameters and u ann×1vector of random errors. The three representations are equivalent and will be used interchangeably.The presence of individual effects makes estimation of Model (1) difficult, since the number of such effects grows with n. The FEE follows from the idea of transforming the model in order to eliminate the fixed effects. This can be done by subtracting from each variable its time average. To that end, one can use the following matrix:D=InT-In⊗1T×ıT,whereInTis the identity matrix of ordernT,Inis the identity matrix of order n andıTis the unitT×Tmatrix. Premultiplication of (1) by D yields(2)ỹ=X∼β̃+ũ,whereỹ=Dy,X∼=DXandũ=Du. In other words, premultiplication of both sides of (1) by D eliminates the fixed effects.The FEE ofβis obtained by applying OLS estimation to Model (2), i.e., by minimizing the sum of the squares of the errors:ũ′ũ=(ỹ-X∼β̃)′(ỹ-X∼β̃). The estimator can be expressed in closed-form asβ̃ˆ=(X∼′X∼)-1X∼′ỹ.The following assumptions are usually made:S1(Xi,ui)are i.i.d. in i;E(uit∣Xi)=0;limn→∞n-1∑i=1nX∼i′X∼i=Q∼, whereQ∼is a positive definite matrix;limn→∞n-1∑i=1nE(X∼i′ũiũi′X∼i)=W;E(uiui′∣Xi)=σ2IT, whereITis the identity matrix of order T;E(uiui′∣Xi)=Ωi, a diagonal matrix different fromσ2IT.Under assumptions S1 and S2, the FEE is unbiased and consistent, i.e.,E(β̃ˆ)=βandplim(β̃ˆ)=β. S1 imposes independence among individuals, thus ruling out spatial correlation. It does allow, however, for time autocorrelation and individual heterogeneity. S2 assures the strict exogeneity ofXiand S3 states that there is no exact multicollinearity amongst the explanatory variables. Assumption S4 assures error homoskedasticity. Conversely, if S4’ is valid, then errors do not have constant variance. If S1 through S4 are valid, then the FEE is the best linear unbiased estimator (BLUE) ofβ(Hayashi, 2000).Under S1 to S4’, it follows thatn(β̃ˆ-β)→dN(0,Q∼-1WQ∼-1), where→ddenotes convergence in distribution. That is, the estimator is asymptotically Gaussian.Under S4, the variance ofβ̃ˆcan be easily estimated asvar^(β̃ˆ)=σ̃ˆ2∑i=1nX∼i′X∼i-1,whereσ̃ˆ2=[n(T-1)-p]-1∑i=1nũˆi′ũˆi. It is important to note that this estimator is no longer consistent when S4 is replaced by S4’.Arellano (1987) proposed a heteroskedasticity-consistent covariance matrix estimator ofβ̃ˆin FE regression models under heteroskedasticity of unknown form that can be seen as a generalization of the HC0 estimator introduced by White (1980). His estimator is known as the cluster-robust covariance matrix (CRCM) estimator and has been widely used in practical applications. It is given by(3)var^(β̃ˆ)=(X∼′X∼)-1∑i=1nX∼i′Ω̃ˆi(0)X∼i(X∼′X∼)-1,whereΩ̃ˆi(0)=ũˆiũˆi′. Here,ũˆi=(ũˆi1,…,ũˆiT)′is the FE vector of residuals:(4)ũˆ=ỹ-X∼β̃ˆ=(InT-H∼)ỹ.The matrixH∼=X∼(X∼′X∼)-1X∼′in (4) is known as the ‘hat matrix’. Its diagonal element assume values in0,1. Leth̃itdenote the(i,t)element ofH∼. It can be shown that their average equalsp/(nT). A rule of thumb is to take values ofh̃itlarger than two or three times the average (i.e.,2p/(nT)and3p/(nT)) as indication that the correspondent observations are leverage points.In order to maintain some conformity with the terminology employed in cross-sectional data models, we shall denote the CRMC estimator in (3) by CHC0. All other estimators we consider shall be denoted accordingly: the HC2 estimator applied to FE regression models shal be denoted by CHC2 (Clustered HC2), and so on.The CHC0 estimator does not impose any restrictions on the form of heteroskedasticity; however, independence of errors among individuals is assumed. It is consistent whenn→∞, with T fixed. To guarantee consistency whenT→∞with n fixed or even withn→∞, some additional considerations must be made; see Hansen (2007) and Stock and Watson (2008).The properties of the CHC0 estimator are well known. Kezdi (2005), for instance, analyzes the process of obtaining standard errors when there are both heteroskedasticity and serial autocorrelation. According to the author, researchers often ignore such a problem, probably because the most commonly used statistical software do not provide robust standard errors in FE models. Not surprisingly, this can lead to serious distortions in the estimates of such standard errors. He shows that the finite sample behavior of the estimator is mostly determined by the number of individuals, and not by the sample sizenT.Hansen (2007) analyzes the asymptotic properties of the CHC0 estimator when the number of individuals increases and the time dimension is fixed. The usual analysis is then extended to situations in which both the number of individuals and the number of time observations increase and to situations in which the number of time observations increases but the number of individuals is held fixed. He states conditions under which hypotheses tests based on CHC0 are asymptotically valid.Stock and Watson (2008) proposed a bias-corrected version of the HC0 estimator which is consistent in FE models. Under certain circumstances, their estimator outperforms the CHC0 estimator. Their estimator can be extended to deal with autocorrelated errors.It is well known that the HC0 estimator, albeit consistent, tends to underestimate the true variances in finite samples. A variant of HC0 that incorporates a finite-sample adjustment is the HC2 estimator. It is obtained by replacingΩ̃ˆi(0)byΩ̃ˆi(2)=(ũˆiũˆi′)diag{1-h̃i}-1,whereh̃i=(h̃i1,…,h̃iT)′,h̃itbeing the itth diagonal element ofH∼.The HC3 estimator also incorporates a finite sample correction. It approximates the jackknife estimator and usesΩ̃ˆi(3)=(ũˆiũˆi′)diag{1-h̃i}-2.The HC4 estimator, on the other hand, usesΩ̃ˆi(4)=(ũˆiũˆi′)diag{1-h̃i}-δi,whereδi=min4,h̃i1h̃¯i1,…,min4,h̃nTh̃¯nT′,h̃¯itbeing the average leverage (i.e., the average value of all leverages).The four estimators presented above can be written, in unified fashion, asΨ̃ˆ(s)=(X∼′X∼)-1∑i=1nX∼i′Ω̃ˆi(s)X∼i(X∼′X∼)-1,wheres=0,2,3,4indexes the estimator:s=0for CHC0,s=2for CHC2 ad so on.Our chief goal is to use the numerical integration algorithm developed by Imhof (1961) to compute the exact null distributions of different quasi-t statistics in order to compare them to their asymptotic counterpart. To that end, we need to to assume normality and write the test statistics are ratios of Gaussian quadratic forms. Our interest lies in testingH0:c′β=aagainstH1:c′β≠a, where c is ap×1vector and a is a given scalar. The quasi-t test statistic is given byτ=c′β̃ˆ-avar^(c′β̃ˆ).Under the null hypothesis, the exact distribution ofτconverges toN(0,1)whenn→∞and T is fixed under both homoskedasticity and heteroskedasticity of unkown form; see, e.g., Hansen (2007). Hence, the limiting null distribution of(5)τ2=(c′β̃ˆ-a)2var^(c′β̃ˆ)isχ12.At the outset, note thatvar^(c′β̃ˆ)=c′var^(β̃ˆ)c=c′Ψ̃ˆ(s)c=c′∑i=1n(X∼i′X∼i)-1X∼i′Ω̃ˆi(s)X∼i(X∼i′X∼i)-1c.Letυi(s)=c′(X∼i′X∼i)-1Xi′Φi(s), and letΦi(s)(s=0,2,3,4) be the ith diagonal element of:Φ(0)=InTfor the CHC0 estimator;Φ(2)=diag{(1-h̃1)-1,…,(1-h̃n)-1}for the CHC2 estimator;Φ(3)=diag{(1-h̃1)-2,…,(1-h̃n)-2}for the CHC3 estimator; andΦ(4)=diag{(1-h̃1)-δ1,…,(1-h̃n)-δn}for the CHC4 estimator.The denominator of (5) can thus be written asvar^(c′β̃ˆ)=∑i=1nυi(s)Ω̃ˆi(0)υi′(s). LetVi(s)=(υi′(s)υi(s)). Note that we can writevar^(c′β̃ˆ)=∑i=1n(ũˆi′Vi(s)ũˆi). Here,ũˆ=M∼ỹis the vector of residuals, whereM∼=InT-H∼. ConsiderΩ̃=diag{Ω̃1,…,Ω̃n}andΩ̃i=ũiũi′. It then follows thatvar^(c′β̃ˆ)=ỹ′Ω̃-12Ω̃12∑i=1nM∼n,iVi(s)M∼i,nΩ̃12Ω̃-12ỹ.Therefore,var^(c′β̃ˆ)=z′G(s)z, whereG(s)=Ω̃12∑i=1nM∼n,iVi(s)M∼i,nΩ̃12andz=Ω̃-12ỹ. The vector z has unit covariance. Letw=z-θ, withθ=E(z). We can now write the denominator ofτ2as a quadratic form in a Gaussian random vector that has mean zero and unit variance:var^(c′β̃ˆ)=w′G(s)w.Notice thatβ̃ˆ-β̃=∑i=1n(X∼i′X∼i)-1∑i=1nX∼i′ũi. It is possible to writeβ̃ˆ=β̃+∑i=1n(X∼i′X∼i)-1∑i=1nX∼i′Ω̃iwi;see Hayashi (2000). Hence, the numerator of (5) can be written as(c′β̃ˆ-a)2=(c′β̃-a)′(c′β̃-a)+2(c′β̃-a)c′∑i=1n(X∼i′X∼i)-1∑i=1nX∼i′Ω̃iwi+∑i=1nwi′Ω̃iX∼i∑i=1n(X∼i′X∼i)-1cc′∑i=1n(X∼i′X∼i)-1∑i=1nX∼i′Ω̃iwi.We can now write test statistic given in (5) as(6)τ2=w′Rww′G(s)w+(c′β̃-a)′(c′β̃-a)+2(c′β̃-a)c′∑i=1n(X∼i′X∼i)-1∑si=1nX∼i′Ω̃iwiw′G(s)w,whereR=∑i=1nwi′Ω̃iX∼i∑i=1n(X∼i′X∼i)-1cc′∑i=1n(X∼i′X∼i)-1∑i=1nX∼i′Ω̃iwi.UnderH0, the second term of (6) vanishes and, hence,τ2=w′Rww′G(s)w.Forζ>0, it follows thatPrτ2⩽ζ∣H0is given by(7)Pr0(τ2⩽ζ)=Pr0w′Rww′G(s)w⩽ζ,wherePr0indicates that the probability is computed under the null hypothesis. The probability in (7) can be numerically evaluated using the numerical integration algorithm introduced by Imhof (1961).We shall now use the Imhof algorithm to compute different the quasi-t statistics exact null distributions; the statistics use the consistent covariance matrix estimators discussed in Section 2. The computed distributions are then compared to their asymptotic counterpart. In order to do so, we shall assume normality.The regression model used in our numerical evaluation is(8)yit=β1x1,it+β2x2,it+uit,withβ1=1andβ2=0. The values ofαiwere randomly generated fromN0,1andxitanduitwere generated as follows:1.xit=αi+zit;uit=αi+σitεit.The values ofεitwere randomly drawn fromN(0,1). The values ofxitwere randomly obtained from two different distributions, namely: standard lognormal (data with leverage points) and standard uniform (no leverage point in the data). It is noteworthy that in PD models leverage points can appear in block or isolated. In this study, the CHC’s are assessed in the presence of isolated leverage points. Numerical experiments involving block leverage points were carried out and the results were similar to the ones report below. A thorough discussion of the different types of panel data contamination can be found in Bramati and Croux (2007).Data generation under heteroskedasticity usedσit=exp{γ(x̃1,it+x̃2,it2)}.The strength of heteroskedasticity is measured byλ=maxσit2/minσit2. Hence, whenσit=1, the errors are homoskedastic, and whenσit>1, the data are heteroskedastic; the larger the value ofλthe stronger the heteroskedasticity. Note that the specification ofσituses the transformed valuesx̃it, notxit.Under leveraged data, the values ofγused to generate the data were0.00,0.04,0.08and0.12, the corresponding values ofλbeing1.00,4.62,21.33and98.51. When the data do not contain points of high leverage, the values ofγused we yieldλ=1.00,4.62,21.39,98.91. The null hypothesis isH0:β2=0which is tested againstH1:β2≠0. The test statistic isτ=β̃ˆ2var^(β̃ˆ2),wherevar^(β̃ˆ2)is obtained from one of consistent estimators, namely: CHC0, CHC2, CHC3 or CHC4.In what follows we shall compare the exact null distribution functions ofτ2to the limiting null distribution function (χ12). The closer these two curves, the better the asymptotic approximation used in the test.The presence of leverage points can be identified by looking at the values ofh̃it, i.e., the diagonal elements ofH∼. Table 1presents the maximum and minimum values of theh̃itin the two scenarios; we also report the values of2p/(nT)and3p/(nT), which are commonly used as thresholds. When the covariate values are obtained fromLN(0,1), there are six observations for whichh̃itexceeds3p/(nT).By varying the value ofλ, it is possible to assess the impact of the degree of heteroskedasticity on the asymptotic approximation toPr(τ2⩽ζ∣H0). In particular, it is useful to assess the quality of the approximation usingζ=2.706,3.841and6.635, which correspond to the 10%, 5% and 1% critical values used when performing testing inference.The sample sizes considered weren=20andn=60, withT=5. The covariate values were held constant throughout the numerical evaluations. Initially, a sample fromxitwas generated withn=20andT=5, such thatnT=100. Whenn=60, these values were replicated 3 times (here,nT=300). This procedure assures that the degree of heteroskedasticity does not change with the sample size. All numerical evaluations were performed using Ox matrix programming language.Tables 2 and 3contain the exact tail probabilities computed using different quasi-t test statistics. The probabilities were computed using the asymptotic (χ12) 0.90, 0.95 and 0.99 upper quantiles. From Table 2, we note that, in the presence of leverage points and when the sample size is small (n=20), the worst asymptotic approximation is that for the null distribution of the quasi-t test statistic constructed using Arellano’s estimator (CHC0). For instance, under equal error variances (λ=1), the exact probabilities at the 0.90 and 0.95 asymptotic quantiles are0.8346and0.8949, respectively. The best asymptotic approximation is that for the null distribution of the CHC4 quasi-t test statistic; the corresponding probabilities are0.8846and0.9310. When using the CHC3 test statistic, the probabilities become0.8623and0.9156. It is also noteworthy that the asymptotic null approximation used in the CHC0 test becomes poorer when the strength of heteroskedasticity is increased. For instance, whenλ=98.51, the exact probability computed usingζ=3.841(95% asymptotic quantile) is0.8576. For the CHC2, CHC3 and CHC4 test statistics we obtain, respectively,0.9035,0.9332and0.9652.The probability discrepancies are considerably smaller when the data contain no leverage point, especially for the CHC0 and CHC2 test statistics. Under homoskedasticity andζ=2.706(the0.90asymptotic quantile), the exact probabilities are0.8704(CHC0),0.8762(CHC2),0.8819(CHC3) and0.8811(CHC4). Under heteroskedasticity (λ=4.47), the corresponding probabilities are0.8670,0.8737,0.8802and0.8794. The CHC3 null distribution is the one best approximated by theχ12distribution, closely followed by the CHC4 null distribution.The figures in Table 3 show that the CHC4 test is the most reliable test under leveraged data since its null distribution is best approximated by the limiting null distribution. Whenλ=98.51and under leveraged data, the computed probabilities evaluated at the 0.95 limiting upper quantile are0.8976(CHC0),0.9127(CHC2),0.9267(CHC3) and0.9509(CHC4). The corresponding probabilities when the data contain no leverage point are0.9421,0.9435,0.9449and0.9448. The differences between the computed probabilities decrease when the sample size increases, regardless of whether there are leverage points in the data.Taken together, the results in the two tables show that the first order approximation used in the test becomes poorer when the strength of heteroskedasticity increases. The worst approximations atζ=2.706and3.841are those for the null distributions of the CHC0 and CHC2 test statistics.In what follows we shall plot the exact null distributions of the different test statistics (dashed lines) together with their asymptotic counterpart (solid lines). The closer the two curves, the better the asymptotic approximation used in the test.Fig. 1contains plots of null dstribution functions computed under severe heteroskedasticity (λ≈100) and data with no leverage point. Two sample sizes were considered:n=20andn=60. All dashed lines lie below the continuous lines which implies that all tests are liberal. The exact null distribution functions of the CHC0, CHC2, CHC3 and CHC4 test statistics evaluated at3.841(the asymptotic 5% critical value) equal, respectively,0.9259,0.9307,0.9353and0.9347(see Table 2).Fig. 2contains similar plots, but for leveraged data. As before, there is strong heteroskedasticity. Visual comparison between these panels and those in Fig. 1 reveals that the first order asymptotic approximation becomes less reliable for all test statistics, especially for the CHC0 and CHC2 quasi-t test statistics. It is noteworthy that the approximation to the CHC4 statistic null distribution remains fairly accurate even when the data contain atypical observations.Inspection of Figs. 1 and 2 show that the introduction of leverage points clearly worsens the quality of the first order asymptotic approximation used in quasi-t testing inference. Notice that the distance between the dashed and continuous lines increases under leveraged data. The exact null distribution functions of the four test statistics evaluated atζ=3.841equal0.8976,0.9127,0.9267and0.9509(Table 2). The test based on the CHC4 estimator is the least sensitive to leverage points.With constant error variances the CHC4 (CHC0) test remains the least (most) sensitive to the high leverage data points. As expected, the quality of the first order asymptotic approximations used in the quasi-t tests improves when the sample size increases. The tests also become less sensitive to high leverage observations.1Figures available from the authors upon request.1Some authors base quasi-t testing inference on heteroskedasticity-consistent covariance matrix estimators constructed using restricted residuals, i.e., residuals obtained from an estimated regression in which the null hypothesis is imposed upon estimation; see, e.g., Godfrey (2011). The exact test statistic null distribution function, presented in Section 3, was derived using the vector of unrestricted residuals given byũˆ=M∼ỹ. In order to replaceũˆby the vector of restricted residuals, one must impose the null hypothesis, i.e.,β2=0in (8). The consistent estimators can then be based onũˆR=M∼Rỹ, whereM∼R=InT-X∼1(X∼1′X∼1)-1X∼1′; see Cribari-Neto and Lima (2010) and Baltagi (2011). Hereafter, we shall denote the heteroskedasticity-consistent covariance matrix estimators based on restricted residuals as CHCR0, CHCR2, CHCR3 and CHCR4.The restricted model is given by(9)yit=β1xit,1+uit.Theτ2statistics that employ the CHCR’s have the same formulation as described in Section 3. The only modification is that we now use the vector of residualsũˆiR=(ũˆi1R,…,ũˆiTR)′obtained by applying the FEE to Model (9).In what follows, we shall use numerical integration to compute the exact null distributions of quasi-t test statistics constructed using restricted residuals. Withn=20,λ=21.33and leveraged data, the CHCR0 exact probabilities evaluated at the0.90,0.95and0.99asymptotic quantiles are0.9334,0.9850and0.9996. Notice that they are much closer to their asymptotic counterparts than when the tests statistics were based on unrestricted residuals. Overall, the CHCR0 null distribution is now the one that is best approximated by the limitingχ2distribution. The worst approximation is that for the CHCR4 null distribution. For instance, the corresponding CHCR4 probabilities are0.9935,0.9988and1.0000. When the data have no leverage point, the approximations are considerably more accurate and, as a consequence, the tests become less size distorted. For instance, withn=20,λ=98.91andζ=3.841(the0.95asymptotic quantile), the exact probabilities obtained for the CHCR0, CHCR2, CHCR3 and CHCR4 test statistics are0.9538,0.9582,0.9623and0.9621, respectively.Table 5 presents the probabilities obtained with a larger sample size (n=60). The effect of the leverage points on the tests size distortions is less intense. The best approximation is that for the CHCR0 null distribution. Under severe heteroskedasticity (λ=98.51), the exact probabilities at the 0.90 asymptotic quantile (ζ=2.706) are0.9029(CHCR0),0.9161(CHCR2),0.9285(CHCR3) and0.9504(CHCR4). With no leverage point in the data, the approximation becomes considerably more accurate. For example, whenλ=98.91, the exact probabilities at the0.90asymptotic quantile are0.8988(CHCR0),0.9008(CHCR2),0.9029(CHCR3) and0.9028(CHCR4).In Figs. 3 (homoskedasticity) and 4(severe heteroskedasticity,λ=98.51) we plot the exact null distribution functions of the different quasi-t test statistics constructed using restricted residuals (dashed lines). The sample sizes aren=20,60. Again, the asymptotic null distribution function (χ12) is plotted using a continuous line. To save space, we only present results obtained under leveraged data. The dashed lines are now above the solid curve which means that the tests are conservative. The poorest approximations are those for the null distributions of the CHCR3 and the CHCR4 quasi-t test statistics. The best approximation again is obtained using the CHCR0 test statistic.The approximations tend to worsen when heteroskedasticity becomes stronger. It is noteworthy that the asymptotic approximation to the CHCR4 null distribution is poor. In particular, atζ=2.706the dashed line lies far above the solid line. Additionally, we computed the following exact probabilities atζ=2.706for the CHCR0, CHCR2, CHCR3 and CHCR4 test statistics:0.9577,0.9821,0.9921and0.9979, respectively; see Table 4.The conclusions we draw from these figures are in agreement with our previous conclusions. The main conclusion is that the test that most benefits from the use of restricted residuals is the CHCR0 test, especially under heteroskedasticity.Table 6contains estimated null probabilities corresponding to the 0.95 asymptotic level computed under severe heteroskedasticity (λ≈98) and leveraged data. Several different sample sizes are considered. We report results obtained using both unrestricted and restricted residuals. When unrestricted residuals are employed, the best (worst) results correspond to the CHC4 (CHC0) test statistic. For instance, usingn=20andT=3the computed null probabilities at the 0.95 asymptotic quantile equal0.7354(CHC0),0.7883(CHC2),0.8390(CHC3) and0.9220(CHC4) when unrestricted residuals are used. When restricted residuals are used, the figures become0.9952,0.9981,0.9991,0.9995(CHCR0, CHCR2, CHCR3 and CHCR4, respectively). When the sample size is larger,n=200andT=10, the asymptotic approximation becomes more accurate. The computed null probabilities become0.9462,0.9471,0.9479and0.9496when unrestricted residuals are employed and0.9509,0.9517,0.9526and0.9543when the standard errors are based on restricted residuals.All numerical evaluations so far focused on the test statistics null distribution functions and were carried out using numerical integration. It is also important to evaluate the powers of the tests, that is, one minus the type II error probabilities. We have performed such an evaluation using Monte Carlo simulation. Numerical integration was not used because the results presented in Section 3 are no longer valid when the null hypothesis is not true. The number of Monte Carlo replications is 10,000, there is severe heteroskedasticity (γ=12andλ≈98), the covariate values were obtained as random draws from the standard lognormal distribution and all tests are performed at the 5% nominal level. The null hypothesisH0:β2=0is tested against a two-sided alternative. Data generation was carried out usingβ2=0.25. The tests use exact (estimated from size simulations) critical values, so that all tests are forced to have the correct size. That is, we compare powers of tests that are not size distorted. The simulation was performed using the Ox matrix programming language. The estimated powers are presented in Table 7.The results show that the powers increase with the sample size, as expected. They also show that the tests whose statistics employ unrestricted residuals standard errors display similar performance. The same hold true for the tests based on restricted residuals. A final and important conclusion is that tests based test statistics constructed using restricted residuals clearly outperform those based on unrestricted residuals when the sample size is not large. That is, by using restricted residuals standard errors one reduces the type II error probability.We have considered testing inference in FE regression models under heteroskedasticity of unknown form. In particular, we focused on the quasi-t tests whose test statistic use the Arellano estimator (CHC0) and also on similar tests based on alternative estimators (CHC2, CHC3 and CHC4). We wrote the test statistics as ratios of Gaussian quadratic forms and used numerical integration to compute their exact null distributions, which were then compared to the limiting null distribution. We constructed the heteroskedasticity-consistent covariance matrix estimators using both unrestricted and restricted residuals. The numerical evaluations were carried out under both equal and unequal error variances. We considered regression structures with and without high leverage data points. We also report the results of Monte Carlo simulations that were carried out to evaluate the powers of the different tests. Our numerical evidence shows that CHC0 quasi-t testing inference can be quite unreliable in small samples. Our results also show that the most accurate asymptotic approximations are those used in the CHC4 (unrestricted residuals) and CHCR0 (restricted residuals) tests. We recommend that testing inference in FE regression models be based such quasi-t test statistics.There are several directions for future research. Heteroskedasticity-consistent estimators based on residuals obtained from robust estimation of the FE regression parameters can be considered. It is also important to consider interval estimation, i.e., confidence intervals and regions that are asymptotically correct under heteroskedasticity of unknown form in FE regression models. Finally, it would also be important to obtain bias corrections that can applied to the different covariance matrix estimators since they can be quite biased in small samples.

@&#CONCLUSIONS@&#
