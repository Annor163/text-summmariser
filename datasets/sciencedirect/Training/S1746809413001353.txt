@&#MAIN-TITLE@&#
Activity recognition of the torso based on surface electromyography for exoskeleton control

@&#HIGHLIGHTS@&#
We present an activity mode recognition approach to identify motions of the human torso.Approach uses decision tree classification in order to leverage its computational efficiency.The recognizer uses surface electromyography as the input and CART (classification and regression tree) as the classifier.Results indicate that the recognizer can extract the user's intent with minimal delay.We achieved a low recognition error rate and a user-unperceived latency using sliding overlapped window.

@&#KEYPHRASES@&#
Intent recognition,Real-time,Decision tree,Surface electromyography,Exoskeleton,

@&#ABSTRACT@&#
This paper presents an activity mode recognition approach to identify the motions of the human torso. The intent recognizer is based on decision tree classification in order to leverage its computational efficiency. The recognizer uses surface electromyography as the input and CART (classification and regression tree) as the classifier. The experimental results indicate that the recognizer can extract the user's intent within 215ms, which is below the threshold a user will perceive. The approach achieves a low recognition error rate and a user-unperceived latency by using sliding overlapped analysis window. The intent recognizer is envisioned to a part a high-level supervisory controller for a powered backbone exoskeleton.

@&#INTRODUCTION@&#
Recent technological advances in robotics make possible the development of an exoskeleton that can act as an extension of themselves. Augmenting the upper and lower limbs has been the primary focus of exoskeleton research to-date [1â€“9]. A powered backbone component of an exoskeleton can increase the load carrying capacity of a person and can potentially benefit a wide array of people, ranging from people bringing groceries into their homes, to people suffering from disabilities such as: paraplegia and hemiplegia, since daily activities such as flexion or extension can prove to be very challenging for them. In these respective cases, the benefits could result in improved load carrying capacity and an ability to stand and walk freely. Intuitive control of the device is paramount so that the user does not need to worry about operation and can be more concerned about participating in activities of daily life. But current exoskeleton technology still limits the natural motions of the torso and activities that users are able to participate in since the connection between the upper and lower limbs is a rigid spine. Two methods for inferring user intent are through mechanical sensors embedded in the device such as joint and inertial measurements and surface electromyography (sEMG). sEMG signals are detected over the skin surface and are generated by the electrical activity of muscle fibers during contraction. Multi-channel EMG signals, collected by electrodes placed on the involved muscles, can be used to identify the user's intent activity mode since each activity corresponds to a specific pattern of activation of several muscles. Therefore, sEMG signals are a significant control input for powered prostheses, exoskeleton and rehabilitation robots. Some prior works exist on developing sEMG pattern recognition-based control approach for many other kinds of powered prostheses, such as: A Gaussian mixture model based classification scheme for myoelectric control of powered upper limb prostheses is described in [1]. A volitional control approach of a prosthetic knee using surface electromyography is described in [2]. Other researchers emphasize on describing the development of pattern recognition approach based on EMG signal, such as: An EMG-based pattern recognition approach for identifying locomotion modes by using artificial neural networks (ANN) and linear discriminant analysis (LDA) is presented in [3]. A robust, real-time control scheme for multifunction myoelectric control is presented in [4]. An EMG-based hand gesture recognition approach for real-time biosignal interfacing is described in [5].Current prosthetic devices predominantly utilize sEMG signals from the user's body, in addition to pressure and force sensors, mounted at various locations on the device and along the body. As part of efforts to identify a suitable sensor set to recognize user intent, this paper presents an approach based on a sEMG and uses inertial measurements to classify the training data. EMG signals from the user's body correspond to a local, area specific level, and play the most important role in pattern classification, while inertial measurements correspond to a more holistic and generalized way of intent recognition. Related prior research works include a multimodal interpretation of muscular activities using a body sensor network with electromyogram and inertial sensors [6]. Also, an automatic recognition method of sign language sub-words based on portable accelerometer and EMG sensors is described in [7]. A rule-based control approach of walking by using decision trees and practical sensors is designed in [11]. The objective in our research is to develop a real-time intent recognition system for intelligent, powered backbone exoskeleton. This paper will focus on the activity mode intent recognizer, which is a high-level supervisory controller and its function is to distinguish between the intent activities modes of subject, such as flexion, extension and twisting.

@&#CONCLUSIONS@&#
