@&#MAIN-TITLE@&#
Multi-objectivization Via Decomposition: An analysis of helper-objectives and complete decomposition

@&#HIGHLIGHTS@&#
First known analytic comparison of Pareto frontiers generated by different algorithms.Analytic and empirical study between complete decomposition vs. helper objectives.First study of heuristic strength and decomposition size for multi-objectivization (supplemental material).

@&#KEYPHRASES@&#
Multi-objectivization,Multi-Objectivization via Segmentation (MOS),Helper-objectives,Complete decomposition,Job shop scheduling problem (JSSP),

@&#ABSTRACT@&#
Multi-objectivization has been used to solve several single objective problems with improved results over traditional genetically inspired optimization methods. Multi-objectivization reformulates the single objective problem into a multiple objective problem. The reformulated problem is then solved with a multiple objective method to obtain a resulting solution to the original problem. Multi-objectivization Via Decomposition (MVD) and the addition of novel objectives are the two major approaches used in multi-objectivization. This paper focuses on analysis of two major MVD methods: helper-objectives and complete decomposition. Helper-objectives decomposition methods identify one or more decomposed objectives that are used simultaneously with the main objective to focus attention on components of the decomposed objectives. Complete decomposition, unlike helper-objectives does not explicitly use the main objective and instead uses decomposed objectives that exhaustively cover all portions of the main objective. This work examines the relationship between helper-objective decompositions and complete decomposition using both an analytic and experimental methodology. Pareto dominance relationships are examined analytically to clarify the relationship between dominant solutions in both types of decompositions. These results more clearly characterize how solutions from the two approaches rank in Pareto-frontier based fitness algorithms such as NSGA-II. An empirical study on job shop scheduling problems shows how fitness signal and fitness noise are affected by the balance of decomposition size. Additionally we provide evidence that, for the settings and instances studied, complete decompositions have a better on-average performance when compared to analogous helper-objective decompositions. Lastly we examine the underlying forces that determine effective decomposition size. We argue that it is advantageous to use less balanced decompositions as within-decomposition conflict increases and as heuristic strength increases.

@&#INTRODUCTION@&#
Genetic Algorithms (GAs) are a machine intelligence technique that is inspired by the process of modeling survival-of-the-fittest on a group of solutions. GA terminology has been inspired by similar biological phenomena. An individual, contains decision variables, genes, required to constitute a solution. The GA manages a group of individuals called a population. Populations change over time through several processes. Solution generation occurs through the recombination of individuals. Recombination conveys traits from a set of two or more parents, selected through parent selection, to new child solutions. Children can also be generated through mutation. Mutation is a process that randomly changes genetic material in a solution. Children and parents compete for a spot in the successor population, generation, through a process called survival selection. Both parent and survival selection must create some pressure toward surviving fitter individuals. However, it is also important that a GA maintains diversity in the population so that the global search method does not converge too quickly. Since GAs manage a group of solutions, it is possible to have the algorithm find multiple solutions to a problem simultaneously. The reader is referred to De Jong (2006) for more details on GAs.Evolutionary Multi-objective Optimization (EMO) techniques are genetically inspired techniques that attempt to solve multi-objective problems. Ideally these methods create a variety of solutions along a Pareto efficient frontier so that the decision maker can pick from several alternatives that are Pareto incomparable. These methods must balance two forces that control selection pressure: the dominance relationship between solutions and the diversity of Pareto incomparable solutions. Descriptions for many of the Multi-Objective Evolutionary Algorithms (MOEAs) used in EMO are provided in Coello Coello, Lamont, and Van Veldhuisen (2007).An optimization technique called multi-objectivization has been used to solve several single objective problems with improved results over traditional genetically inspired optimization methods. Multi-objectivization, a term and technique introduced in Knowles, Watson, and Corne (2001), reformulates the single objective problem into a multiple objective problem. The problem is then solved using a multi-objective method such as those used in EMO. These reformulations come in two basic types, the addition of novel objectives, and the decomposition of existing objectives (Handl, Lovell, and Knowles, 2008a). The use of existing components of the objective function as the building blocks for decompositions is termed Multi-objectivization Via Decomposition (MVD) in this paper. MVD has been applied to problems with sum-of-parts objective functions. The Traveling Salesman Problem (TSP) and the Job Shop Scheduling Problem (JSSP) for flowtime are the two most studied problems using MVD to date. The TSP has been studied in Knowles et al. (2001), Jensen (2004), Jahne, Li, and Branke (2008), and Lochtefeld and Ciarallo (2014) and the JSSP has been studied in Jensen (2004) and Lochtefeld and Ciarallo (2011). These problems have a permutation string based representation where the order of the elements in the solution is significant.The two major methods used in MVD to date are helper-objectives (Jensen, 2004) and complete decomposition (Jahne et al., 2008). The only empirical evidence directly comparing these methods to date was accomplished on the TSP in Jahne et al. (2008). We explore more deeply the relationship between helper-objectives and complete decomposition methods. We explore analytically how Pareto efficient frontiers interrelate between the two methods for additive fitness functions. An empirical study on the JSSP is also used to explore the relationship between complete decomposition and helper methods.Multi-objectivization is theorized to improve performance over single-objective methods in two ways. The signal-to-noise principle (Lochtefeld and Ciarallo, 2012) theorizes that some fitness improvements in an objective (signal) are not always recognized and rewarded if they happen to be expressed in a solution at the same time that an offsetting fitness decrement (noise) is generated in another part of the objective. The ratio of the frequency and magnitude of fitness improvements to the frequency and magnitude of fitness decrements determines a Signal-to-Noise Ratio (SNR). SNRs in multi-objectivization are discussed in the context of both SNRs within an objective and SNRs between objectives. Multi-objectivization can be thought of as a method that improves the recognition of fitness improvements between objectives and thus this work discusses signal-to-noise in the context of between objective signal and noise. Based on the signal-to-noise principle, Lochtefeld and Ciarallo (2012) studied the TSP and generated decompositions with improved performance over previous decompositions. The second major way multi-objectivization improves performance is the concept that local optima can be overcome because they may not be present in one or more of the new objectives. Another title for this way of improving performance is the “breakage of epistasis”. Epistasis, the nonlinear interactions in a problem (Reeves and Wright, 1995) can be partially circumvented through the use of multi-objectivization although it is possible to also make a problem harder through the decomposition of objectives (Brockhoff, Friedrich, Hebbinghaus, Klein, Neumann, and Zitzler, 2007).In addition to these principles, several key theoretic results have been proven. Firstly in Knowles et al. (2001), multiobjectivization methods are shown to preserve the global optimal solution as Pareto efficient if either the reformulated problem contains the original objective or the original problem can be decomposed into a sum of several objectives. Secondly, in Handl, Lovell, and Knowles (2008b) multiobjectivization of scalar cost functions are analyzed and it is noted that multi-objectivization of these functions can result in the introduction of additional plateaus in the reformulated problem landscape which may make the problem more difficult for some hill climbing algorithms. Lastly, Brockhoff et al. (2007), working with a well known plateau function, demonstrate that multi-objectivization can both make a problem harder or easier dependent upon the structure of the problem. The work shows that multi-objectivization appears to work best when moderate sized areas of neutral fitness (plateaus in the fitness landscape) must be overcome.In MVD, there are many possible decompositions but only one subset of decompositions is used at a given point in time as the algorithm proceeds. Because there has not existed a good understanding about which decompositions are best, most MVD methods to date switch decompositions after a period of time so that a single decomposition does not overly bias the search (Jahne et al., 2008; Jensen, 2004; Lochtefeld and Ciarallo, 2014). Lochtefeld and Ciarallo (2014) introduced the term degrees of decomposition which indicates the number of objectives in a given decomposition. We use the term decomposed objective to refer to the subset of objective parts that have been assigned to an objective in the multi-objective search procedure. Individual objective parts associated with a decomposed objective are components of the decomposed objective.Helper-objectives were proposed by Jensen (2004). Helper-objectives are additional objectives that are used simultaneously with the main objective because the “additional objectives [can guide] the search” (Jensen, 2004). In the work, both the TSP and the JSSP were studied. Jensen used objectives that were decomposed parts of the main objective as the helper-objectives thus Jensen studied helper-objectives using MVD. The work demonstrated that dynamic switching of various helper-objectives often obtained better results than using a single decomposition throughout the run. Helper-objectives are referred to as helpers subsequently in this document.Prior to Lochtefeld and Ciarallo (2011), previous helper related research on the JSSP studied randomly sequenced helpers chosen from all possible jobs (Jensen, 2004). Lochtefeld and Ciarallo (2011) compared randomly sequenced helpers to a deterministic order of helpers. Improved results were obtained using the Shortest Job First (SJF) rule for sequencing. In the SJF rule, the sequence that jobs are used as helpers is such that shorter jobs are used before longer jobs. The premise of the SJF rule is based upon the well known heuristic in the literature on the management of operations that when optimizing for flowtime it is better to delay a long job by a short job’s time rather than vice-versa (Pinedo, 2009).Subsequent to helper objectives, Jahne et al. (2008) proposed Multi-Objectivization via Segmentation (MOS). Unlike helper methods which use the main objective simultaneously with decomposed objectives that contain a subset of the main objective’s components, MOS assigns all component parts of the main objective into two or more decomposed objectives. MOS does not explicitly use the main objective. Each decomposed objective in MOS was termed a segment. Instead of segmentation, we term this type of MVD complete decomposition. As the name implies, complete decomposition takes all component parts of the main objective and divides them into a number of new decomposed objectives such that each component of the main objective is represented an equal number of times and all decomposed parts are assigned to a decomposed objective. Equal representation of the objective components preserves the original problem as it is decomposed. Unlike previous approaches, several of the decompositions in MOS were adaptive; the decompositions were based on properties of solutions in the current population. The complete decompositions used in MOS generally outperformed the helper methods on the TSP instances studied. Lochtefeld and Ciarallo (2014) studied MOS and proposed a more general version of MOS called Multi-objectivization via Progressive Segmentation (MOPS). When progressive segmentation is not enabled in MOPS, MOPS is identical to MOS. Progressive segmentation increases the degree of decomposition over time as the evidence provided indicated that using more aggressive multi-objectivization later in the run works best.One popular MOEA used in multi-objectivization is the Non-dominated Sorting Genetic Algorithm version II (NSGA-II) which is described in Deb, Pratap, Agarwal, and Meyarivan (2002). NSGA-II uses Pareto dominance relationships between solutions to determine the first order of magnitude of fitness for the solution. Then, between solutions that are within the same front, NSGA-II uses a hyper-boxed based penalty function to reward solutions that are far apart so that solutions, hopefully, do not cluster in the same area on the Pareto front. Recent work on MOEA includes Elaoud, Louckil, and Teghem (2007), Beume, Naujoks, and Emmerich (2007), Chen and Lu (2008) and Gong and Cai (2009).The dominance relationship in NSGA-II is determined as follows. All solutions in the population are searched to find those solutions that are non-dominated, that is, those solutions that are not weakly dominated by any other solution in the population. These non-dominated solutions are all labeled with the front number 1 and are removed from further consideration. Then the remaining population is again searched for non-dominated solutions. These solutions are labeled with the front number 2 and are removed from further consideration. This process proceeds until all individuals in the population have been assigned a front number. In NSGA-II, any individual with a lower front number is considered a more-fit individual than an individual with a higher front number.In practice, helpers in Jensen (2004) and Lochtefeld and Ciarallo (2011) and complete decomposition in Jahne et al. (2008) and Lochtefeld and Ciarallo (2014) seem to share more similarities than differences. The two methods use the same strategy for mitigating a poor decomposition by using new decompositions over time. The methods both swap in new decompositions using the same logic. Also, both methods are MVD methods, dividing the main objective into component parts. The only major difference between the methods is in the definition of the decomposition itself. In helpers the main objective is used in place of the final decomposed objective that would have been used in complete decomposition. Thus in helpers the main objective is explicitly an objective while in complete decomposition the main objective is implicit. A complete decomposition can be created from a helper by paring down the main objective to only those objective components that are not in the helpers. With this in mind, we embarked on a careful direct comparison of complete decompositions versus helpers. For simplicity in the analysis below we assume a minimization problem of an additive and decomposable objective function. Similar analysis holds for maximization of an additive and decomposable objective function.The analysis below explores general relationships that hold between solutions that are compared in the Pareto sense both in helper decompositions and complete decompositions. The definitions for complete decomposition and helper-objectives below relate to all previous works where decomposition was used to generate the objective functions. Complete decompositions were used in a consistent manner to the definitions here in Knowles et al. (2001), Jahne et al. (2008), Neumann and Wegener (2007), Handl et al. (2008a); 2008b), Garza-Fabre, Rodriguez-Tello, and Toscano-Pulido (2012) and Lochtefeld and Ciarallo (2014). Helper-objectives were used in a similar manner to the definitions presented here in Jensen (2004), Jahne et al. (2008), Lochtefeld and Ciarallo (2011, 2012), and Brockhoff et al. (2007). Inconsistent to the definition with helper objectives here are those methods that used novel helper-objectives such as Burke and Landa Silva (2006), Greiner, Emperador, Winter, and Galván (2007), Mouret (2011), and Watanabe and Sakakibara (2007). No complete decomposition methods were found in the literature that were inconsistent with the analysis herein. Building on these fundamentals we develop a mapping of Pareto efficient solutions in helpers to corresponding Pareto efficient solutions in complete decompositions. This leads to the conclusion that solutions in the ith Pareto frontier in helpers appear on the ith or lower frontiers in complete decomposition.We use several definitions of Pareto comparison operators in the work below based upon weak dominance. Weak dominance can be used to identify the subset of solutions in a population that compose a Pareto efficient set. Solution x weakly dominates solution y is represented by the notation x≽y. Solutions x and y are Pareto identical is represented by x ≈ y. Solutions x and y are Pareto incomparable is represented by x≺≻y. Solution y is not weakly dominated by x is represented byx¬⪰y. Deb and Saha (2010) provide a comprehensive set of dominance definitions including the difference between strong and weak Pareto dominance and the strong and weak Pareto optimal set. The analysis of helpers and complete decomposition methods can lead to multiple Pareto comparisons because the decompositions have different objectives, so when needed for clarity in the following development the Pareto operators are augmented with H and C respectively. For examplex⪰Hydenotes that solution x weakly dominates solution y based on a helper-objective structure.We use the following notation to represent how solutions are evaluated with the objectives under helper and complete decompositions when minimizing a sum-of-parts objective function (such as for the TSP or JSSP). This definition only applies when valid solutions are generated such as when a repair mechanism is employed. Let xkdenote the kth objective value associated with solution x. In our work, both helpers and complete decomposition methods contain exactly m simultaneous objectives to be minimized. Thus, in a comparison of two objective values, the lower value is considered desirable. Symmetric definitions exist for a sum-of-parts maximization problem where higher values are desirable. For both methods m indicates the degree of decomposition. For a generic decomposition k ∈ K, where K is a set of objective indices. For complete decomposition k ∈ KC≡ {1, 2, …, m}. For helpers k ∈ KH≡ {1, 2, …, m − 1, M} where M is the main objective and m − 1 is the number of helpers. Note that the set operator symbols for intersection and union used below are ∩ and ∪, respectively.DefinitionThe main objective M is the sum of all decomposed objectives.(1)xM=∑k=1mxk(2)yM=∑k=1mykSolution x weakly dominates solution y, denoted x ≽y, if and only if x is better than y in at least one objective and x is no worse than y in all other objectives (Deb et al., 2002).(3)x⪰yiff[∃k∈K:xk<yk]and[∀k∈K:xk≤yk]x⪰Cyindicates weak dominance in complete decomposition where K = KC.x⪰Hyindicates weak dominance in helpers where K = KH.Solution x is incomparable to solution y, denoted x≺≻y, if and only if x is better than y in at least one objective and x is worse than y in at least one objective.(4)x≺≻yiff[∃k∈K:xk<yk]and[∃k∈K:yk<xk]x≺≻Cyindicates incomparable solutions in complete decomposition where K = KC.x≺≻Hyindicates incomparable solutions in helpers where K = KH.Solutions x and y are Pareto identical, denoted x ≈ y, if and only if each of the corresponding objective values in x and y are identical.(5)x≈yiff[∀k∈K:xk=yk]x≈Cyindicates Pareto identical in complete decomposition where K = KC.x≈Hyindicates Pareto identical in helpers where K = KH.For two solutions x and y, if y is not weakly dominated by x, denotedx¬⪰y,it is straightforward to show that either y weakly dominates x, y is Pareto incomparable to x, or y is Pareto identical to x.(6)Ifx¬⪰ythen[y⪰x]or[y≺≻x]or[y≈x]In complete decomposition, ifx¬⪰Cythen Property1holds for K = KC. In helpers, ifx¬⪰Hythen Property1holds for K = KH.All solutions that are not weakly dominated by any solution are defined to be strongly Pareto efficient. Together these solutions make up a set of solutions called the Pareto efficient frontier (Belton and Stewart, 2002; Kirkwood, 1997). We define the sets C1 and H1 to contain the Pareto efficient solutions in a given population for complete decomposition and helper decomposition, respectively.Definition 4(7)y∈C1iff∀x:x¬⪰Cy(8)y∈H1iff∀x:x¬⪰HyNSGA-II categorizes solutions in the population based on Pareto fronts allowing the algorithm to quickly determine which of the dominated solutions have better fitness. Subsequent fronts are defined by eliminating the solutions in the population in previous fronts from consideration and then, in the remaining solutions, finding the solutions that are not weakly dominated to define a new front. We define the sets Ciand Hito contain all solutions on the ith Pareto frontier for complete decomposition and helpers respectively, for i ∈ {1, …, ∞}, with C0 ≡ ∅ and H0 ≡ ∅. Further define the setsCi+andHi+to contain all solutions in ith Pareto frontier as well as those in the previous frontiers building up to the ith frontier for the associated decomposition method.(9)Hi+=⋃k=1iHk(10)Ci+=⋃k=1iCkIf a solution is contained in theithfrontier, then it is straightforward to show that it is not contained in any of frontiers 1 through i − 1.(11)∀i∈{1,…,∞},ifx∈Cithenx∉Ci−1+(12)∀i∈{1,…,∞},ifx∈Hithenx∉Hi−1+These definitions and properties lead to the following results clarifying the relationship between dominant solutions under complete decompositions versus helper decompositions in multi-objectivization:Proposition 1A solution y that is weakly Pareto dominated by another solution x in complete decomposition is also weakly dominated by that solution in helpers:Ifx⪰Cythenx⪰Hy.Assumex⪰Cy. By (1)–(3), and the property of addition xM< yM. In going from the complete decomposition evaluation of solutions x and y to the helper decomposition evaluation, we remove exactly one objective and replace it with the main objective, M. Thus the conditions in (3) will continue to hold because xM< yM.□Any two solutions that are Pareto incomparable in helpers are also Pareto incomparable in complete decomposition.Ifx≺≻Hythenx≺≻CyAssumex≺≻Hy. We decompose the situation into two mutually exclusive and complete cases: The solutions are either Pareto incomparable in helpers because of two or more conflicting values in the first m − 1 objectives (Case 1) or the solutions are Pareto incomparable in helpers because of the main objective and one or more conflicting values in the other m − 1 objectives (Case 2).Case 1We examine the solutions that are Pareto incomparable in helpers because of two or more conflicting values in the first m − 1 objectives:(13)[∃k∈{1,…,m−1}:yk<xk]and[∃k∈{1,…,m−1}:xk<yk]If in each solution x and y at least one of the m − 1 helper objective values is superior, the solutions are Pareto incomparable in both helpers and complete decomposition since these objectives are common in both decompositions.We examine the solutions that are Pareto incomparable in helpers because of the value of the main objective for solutions x and y, and one or more conflicting values in the other m − 1 objectives. Thus(14)Either[∃k∈{1,…,m−1}:yk<xk]and(xM<yM)or(15)[∃k∈{1,…,m−1}:xk<yk]and(yM<xM)Since the statements in (14) and (15) are symmetric (through interchange of x and y), only the analysis for (14) is shown here.From (14) we know thatyk*<xk*for some k* ∈ {1, …, m − 1} and that xM< yM.1.If xm< ym, together withyk*<xk*for some k* ∈ {1, …, m − 1}, then the condition forx≺≻Cyin Definition 2 is satisfied.If xm≥ ym, assume that yk≤ xkfor all k ≠ k* and k ∈ {1, …, m − 1}. Under this assumption∑k=1mxk>∑k=1myk,indicating xM> yM, which is a contradiction. Thus yk> xkfor at least one k ≠ k* and k ∈ {1, …, m − 1}. Together withyk*<xk*for some k* ∈ {1, …, m − 1} the condition forx≺≻Cyin Definition 2 is satisfied.□Solutions x and y are Pareto identical in helpers if and only if they are Pareto identical in complete decomposition.(x≈Hy)iff(x≈Cy)Case 1Assumex≈Cy,showx≈Hy. By Definition 3: ∀k ∈ {1, …, m} : xk= yk. Using (1) and (2) (xM= yM) which impliesx≈Hy.Assumex≈Hy,showx≈Cy. By Definition 3:  ∀k ∈ {1, …, m − 1} : xk= ykand xM= yM. Using (1) and (2)xm= ymwhich impliesx≈Cy.□The results in Propositions 1–3 are important for reasoning about the dominated solutions under helper and complete decompositions. The following major results demonstrate important characteristics of the relationship between the frontiers of non-dominated solutions in a population under helper and complete decompositions as used in NSGA-II.Theorem AAll solutions in the Pareto efficient frontier (the first Pareto frontier) in helper objectives are also in the Pareto efficient frontier in complete decomposition:If(x¬⪰Hy)then(x¬⪰Cy).Assumex¬⪰Hy,show:x¬⪰Cy. Ifx¬⪰Hythen one of three cases must hold:Case 1:At least one of the m − 1 helper values in y is better than the corresponding helper value in x so that ∃k ∈ {1, …, m − 1}: xk> yk. Since these m − 1 objective values are common to the corresponding complete decomposition, x does not weakly dominate y in complete decomposition.The first m − 1 objective values in x and y are identical in helpers and the main objective in y is better than the main objective in x so that ∀k ∈ {1, …, m − 1}: xk= yk, andxM> yM. Through use of substitution and the property of addition in (1) and (2),  xm> ym. Thus x does not weakly dominate y in complete decomposition.When x and y are Pareto identical in helpers, the first m − 1 objective values in x and y are equal, and the main objectives in x and y are equal so that ∀k ∈ {1, …, m − 1} : xk= ykand xM= yM. By substitution and subtraction in (1) and (2), xm= ym. Thus x does not weakly dominate y in complete decomposition.□All solutions in the ithor lower frontier in helpers are in the ithor lower frontier in complete decomposition:Hi+⊆Ci+.By definition Pareto fronts are mutually exclusive: ∀i, j, (i ≠ j): Hi∩Hj= ∅ and ∀i, j, (i ≠ j): Ci∩Cj= ∅.For the case where i = 1, Theorem A shows the desired result. For the inductive step, assume(16)Hi+⊆Ci+In order to show that(17)Hi+1+⊆Ci+1+The proof of the inductive step will proceed by assuming that (16) does hold and that simultaneously (17) does not hold. Assuming these facts simultaneously leads to a logical contradiction. To achieve this, suppose there exists a point x that is in Hi + 1 but is not inCi+1+. We will reason about x relative to a point y that is in Ci + 1. Suppose(18)∃x,y:x∈Hi+1,x∉Ci+1+;y∈Ci+1;y⪰CxNote the assumptiony⪰Cxis consistent with the assumptions y ∈ Ci+ 1 andx∉Ci+1+because there must be a y in an earlier front than x in complete decomposition wherey⪰Cx. Because of mutual exclusivity of the Pareto fronts(19)Ci+∩Ci+1=∅By (16), (18), and (19),(20)y∉Hi+By the assumption and Proposition 1,y⪰Hx.However, this is a contradiction since x ∈ Hi + 1 by assumption, and only solutions inHi+can weakly dominate x in helpers. Thus x cannot simultaneously be in Hi + 1 and inCi+1+. By (20) and the definition of the Pareto fronts,y¬⪰Hx.(21)∄x∈Hi+1,x∉Ci+1+(22)andfinallyHi+1⊆Ci+1+SinceHi+1+=Hi+∪Hi+1,and by (16),Hi+1+⊆Ci+1+.□The JSSP is a well studied problem in optimization where a number of jobs must be processed through a job shop. Each of the n jobs has a number of operations that must be processed on the machines in the job shop. The operations associated with jobs must be processed through the machines in a specified order. This order is referred to as the set of technological constraints. Each operation has an associated machine and processing time. There are ω machines in a given job shop and each machine is assumed to service a given job no more than once. Assuming all machines service all jobs, the maximum size of a problem is nω operations. The size of problem instances herein is denoted based upon the notation (n × ω). For instance a 10 job problem with 5 machines is denoted as a (10 × 5) problem. In the JSSP there is no preemption—once an operation starts on a machine it cannot be interrupted. For the problems studied there is also no recirculation—each machine is never required more than once by a job. The goal of the JSSP is to minimize some measure of cost such as makespan (the completion time of the final job) or total flowtime (the sum of the times to complete each job).The JSSP formally defined here is adapted from Vaessens, Aarts, and Lenstra (1996) for optimizing flowtime. Four sets are defined: setMwith ω machines, setJwith n jobs, set O with l operations, and A, a set of binary relations. For each operation o ∈ O there is a unique machineM(o)∈Mon which the operation must be processed, a unique jobJ(o)∈Jto which the operation belongs, and a processing timep(o)∈N.Precedence relationships are contained in the set A; if (o, v) ∈ A, then v must be performed after o. Given in set A are the technological constraints. The optimization adds relationships in A representing machine links. If (o, v) ∈ A and there is no u ∈ O with (o, u) ∈ A and (u, v) ∈ A, then M(o) ≠ M(v). The objective is to minimize total flowtime:∑i=1nmax(∀v∈Ji:S(v)+p(v)). A schedule is a functionS:O→N∪{0}that for each o defines a start time S(o). S is feasible if:•∀o ∈ O: S(o) ≥ 0,∀o, v ∈ O, (o, v) ∈ A: S(o) + p(o) ≤ S(v), and∀o, v ∈ O, o ≠ v, M(o) = M(v): S(o) + p(o) ≤ S(v) or  S(v) + p(v) ≤ S(o).A common way to represent schedules using a directed graph is presented in Fig. 1which shows a sample schedule for a notional three job and four machine JSSP instance. Operations are indicated as the circles in the figure. The process time associated with an operation is displayed in the circle. The black solid arrows between the jobs, the conjunctive arcs, indicate the technological constraints which are fixed for the optimization. The dashed arrows, a subset of all possible disjunctive arcs, indicate the machine sequences that were picked by the optimization for each job. A given operation cannot start until all incoming links have finished. Fig. 2a shows a Gantt chart representation of the same schedule in Fig. 1. To calculate total flowtime we add the time that the final operation is completed for each job. In this example the total flowtime for the schedule is 84 minutes. Fig. 2a shows a Gantt chart representation of the schedule from a machine perspective. From this perspective, the idle times of machines are easier to identify.Many of the evolutionary algorithms that attempt to solve the JSSP use a permutation based representation. These types of representations assess and rank the priority of scheduling an operation. Such methods require an interpreter to build a schedule from the priority list. The well established Giffler–Thompson (GT) schedule builder (Giffler and Thompson, 1960) is one such interpreter. The GT schedule builder has been proven to always build locally optimal, active, schedules. The GT schedule builder uses the priority list to pack the schedule one operation at a time so that the operation occurs as early as possible given the constraints and the priorities. The builder is primarily deterministic but does use random draws to resolve tie-breaker situations when they occur.Simple heuristics used to solve the job-shop scheduling problem can be roughly divided into one of two major categories. Job-based heuristics such as Shortest Processing Time (SPT) or Earliest Due Date (EDD) first, base their decisions on properties related to the jobs (Pinedo, 2009). Often these heuristics are static—the decisions of the method do not change as portions of a schedule are created. Machine-based heuristics such as the shifting-bottleneck procedure focus the construction of schedules on machines that will likely impede the progress of the schedule (Adams, Balas, and Zawack, 1988). Unlike the static job-based heuristics, the shifting-bottleneck heuristic is dynamic (Pinedo, 2009). This method iteratively solves single machine problems in order to build a schedule. The reader is referred to Vaessens et al. (1996) for additional details and references on heuristics used in the JSSP.

@&#CONCLUSIONS@&#
