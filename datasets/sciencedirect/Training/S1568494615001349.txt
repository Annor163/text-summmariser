@&#MAIN-TITLE@&#
Systematic selection of tuning parameters for efficient predictive controllers using a multiobjective evolutionary algorithm

@&#HIGHLIGHTS@&#
The objectives in MPC tuning are performance, feasibility and computational cost.A multiobjective problem is posed for tuning Laguerre-based MPC.The multiobjective problem is solved using NSGA-II.Experiments show that NSGA-II can obtain a suitable balance between the objectives.

@&#KEYPHRASES@&#
Predictive control,Feasibility,Performance,Computational cost,NSGA-II,

@&#ABSTRACT@&#
In the design of predictive controllers (MPC), parameterisation of degrees of freedom by Laguerre functions, has shown to improve the controller performance and feasible region. However, an open question remains: how to select the optimal tuning parameters? Moreover, optimality will depend on the size of the feasible region of the controller, the system's closed-loop performance and the online computational cost of the algorithm. This paper develops a method for a systematic selection of tuning parameters for a parameterised predictive control algorithm. In order to do this, a multiobjective problem is posed and then solved using a multiobjective evolutionary algorithm (MOEA) given that the objectives are in conflict. Numerical simulations show that the MOEA is a useful tool to obtain a suitable balance between feasibility, performance and computational cost.

@&#INTRODUCTION@&#
Model based predictive control (MPC) is the general name for different computer control algorithms that use past information of the inputs and outputs and a mathematical model of the plant to optimise the predicted future behavior [27,5,33]. MPC is well established and widely used, but there are still some theoretical and practical problems without a satisfactory answer. For instance, one key conflict is between feasibility, performance and online computational cost. A controller that is well tuned to give high performance will often have a relatively small feasible region unless a large number of decision variables (or degrees of freedom, d.o.f.) are used, which produces an increase of the online computational load of the algorithm. Conversely, with a strategy that focuses on producing a large feasibility region, the result will be a detuned controller with relatively poor performance [37].This issue becomes particularly important when one tries to implement MPC on special purpose hardware, such as FPGA's [21,28], PLC's [32,19,45] or PAC's [18]. For these devices, linear MPC is demanding, as they have limited memory space and very low processing power. In this cases, even a small improvement could be the difference for a successful implementation; for example, Huyck et al. [18] analyses the maximum number of flops and memory space for a particular PLC and the conclusion is that (linear) MPC implementation is not always possible due to the computational cost and memory space needed. In contrast, in Rauová et al. [32] a very limited linear MPC is successfully embedded on a PLC with just 1024 bytes of memory space. Therefore, idea here is to find a suitable balance on the different performance indexes in order to contribute to the solution of this problem.Several authors have proposed different strategies to implement the MPC algorithm and solve this problem; such as multiparametric solutions [3], time-varying control laws [26], fast optimisations [47], interpolations of different control laws [35,34], move-blocking [4,15], among others. Nevertheless, this paper will focus on algorithms with parameterised d.o.f. where the main idea is to form the degrees of freedom in the predictions as a combination of either Laguerre/Kautz polynomials or through generalised orthonormal functions [37,23,22], since they have proven to be very effective at improving the volume of the feasible region with a limited number of d.o.f. with almost no performance loss. The effectiveness of these approaches, is such that, there are successful experimental results on industrial hardware with limited memory and very low processing power [43].Traditionally, conventional MPC controllers have been tuned by trial and error simulations or using thumb rules for the selection of some parameters, see for example the reviews by Rani and Unbehauen [31] and Garriga and Soroush [12]. In the case of automatic tuning, it is common to use some type of simplification [40,1,42] or excluding some particular aspects of the problem; for instance, not considering the horizons [25]. Other authors have been tuning MPC by solving different optimisation problems for specific types of MPC; interesting examples include: using particle swarm optimisation [16,41], fuzzy decision making [46], minimising dynamical indexes as performance measures [11], among others.The original papers, proposing parameterisation of the d.o.f. for MPC algorithms, introduce one or more tuning parameters without guidelines for their selection [37,23,22]. The addition of these parameters make the tuning even more challenging. The tuning task can be particularly difficult since the whole set represents a large array of possible combinations and because many of these parameters have overlapping and/or contrary effects on the closed-loop performance and stability. In this case, the advantage of using an offline multiobjective optimisation tuning method is clear.On the other hand, the use of evolutionary algorithms (EA) is becoming more accepted in the control community, since they offer a flexible representation of the decision variables, which facilitates the evaluation of controller performance [9,20]. Some applications include the solution of constrained combinatorial problems [30] and fuzzy multiobjective bi-level programming problems [8], performance optimisation of electrical systems [48], and the parameter selection of intelligent controllers [29], among others. Therefore, the main contribution of this paper is to propose a procedure to systematise the selection of controller tuning parameters of a MPC algorithm whose d.o.f.s have been parameterised using Laguerre functions. To select the controller parameters a multiobjective optimisation problem is formulated and solved using the Non-dominated Sorting Genetic Algorithm II (NSGA-II) as this EA offers a simple strategy for handling constraints in addition to being easy to adapt into design. Similar experiments of those presented in Khan et al. [23], Valencia-Palomo et al. [44], Rossiter et al. [37] are revised. The results demonstrate that EA is a useful tool to obtain a suitable balance between feasibility, performance and computational cost.This paper is organised as follows: Section 2 gives the necessary background about predictive control and Laguerre optimal predictive control (LOMPC); Section 3 presents the evolutionary algorithm used to solve the multiobjective optimisation problem; Section 4 formulates the multiobjective optimisation problem; Section 5 shows numerical examples; and finally Section 6 presents the conclusions.This section introduces the assumptions used in this paper and background information.Assume a state-space model of the form:(1)xk+1=Axk+Buk;yk=Cxk+Duk;withxk∈ℝn,yk∈ℝl,uk∈ℝm; which are the state vectors, the measured output and the plant input respectively. This work also adopts an independent model approach with optimal feedback K. Let wkthe output of the independent model, hence, the estimated disturbance isdˆk=yk−wk. Disturbance rejection and offset free tracking will be achieved using the offset form of state feedback that is:(2)uk−uss=−K(xk−xss),where xkis the state of the independent model and xss, are estimated values of the steady-states giving no offset; these depend upon the model parameters and the disturbance estimate.Associated to the model are constraints of the form(3)umin≤uk≤umax;△umin≤uk+1−uk≤△umax;ymin≤yk≤ymax.∀k.In the context of predictive control, it is common to take the following quadratic performance index as the objective to be minimised at each sample:(4)J=∑i=0∞(xk+i−xss)TQ(xk+i−xss)+(uk+i−uss)TR(uk+i−uss),withQ∈ℝn×nandR∈ℝm×mpositive definite state and input cost weighting matrices.The key idea of optimal MPC (OMPC) [39,36] is to embed into the predictions the unconstrained optimal behaviour and handle constraints by using perturbations about this. Hence, assuming K is the feedback, the input predictions are defined as follows:(5)uk+i−uss=−K(xk+i−xss)+ck+i;i∈{0,…,nc−1}−K(xk+i−xss);i∈{nc,nc+1,…},where the perturbations ckare the d.o.f. for optimisation; conveniently summarised in vector:c→k=[ckT,ck+1T,…,ck+nc−1T]T.It is known that for suitable M, N, d (e.g. [36]), the input predictions (5) and associated state predictions for model (1) satisfy constraints (3) if:(6)Mxk+Nc→k≤d(k).It is easy to show [36] that optimisation of (4) over input predictions (5) is equivalent to minimisingJ=c→kTWc→k(W=BTΣB+R, Σ−ΦTΣΦ=Q+KTRK, Φ=A−BK) and thus, in the absence of constraints, the optimum isc→k*. Where the unconstrained predictions would violate constraints, non-zeroc→k*would be required to ensure constraint satisfaction.Algorithm 1OMPCThe OMPC algorithm is summarised as Scokaert and Rawlings [39,36]:(7)c→k*=argminc→kc→kTWc→ks.t.Mxk+Nc→k≤d(k)Use the first element ofc→k*in the control law of (5), with K.This algorithm will find the global optimal, with respect to (4), whenever that is feasible and has guaranteed convergence/recursive feasibility in the nominal case.OMPC algorithm has implied linear-quadratic-regulator (LQR) theory and is able to find a global optimum on the objective function. If one chooses a value for K in (5) to become a optimal LQR [39], the feasible region depends only on the class of prediction, and hence also the number of free movements, that is, nc.Definition 2.1Maximum admissible set (MAS)A common method to achieve recursive feasibility is to find the region of the state space where positively invariant sets ensure the action of an unconstraint control law but satisfy all constraints in the future. The greatest invariant set possible for use as the terminal state set is referred as maximum admissible set (MAS) [14]. For a linear discrete system, observable, pre-stabilised by a gain K of state feedback, associated with a set of constraints (3), there exists a set where the constraints are satisfied for all future time intervals:MAS={xk∈ℝn∣Mxk≤d}.Definition 2.2Maximal controllable admissible set (MCAS)It is also possible to define a region in x in which it is possible to find ac→ksuch that the future trajectory satisfies the constraints:MCAS={xk∈ℝn|∃c→k∈ℝncms.t.Mxk+Nc→k≤d}; and this is named maximal controllable admissible set (MCAS).The fundamental weakness of OMPC algorithms is that the d.o.f. are parameterised as individual values at specific samples and have an impact over just one sample and thus have a limited impact on feasibility. Laguerre OMPC (LOMPC) is a dual-mode MPC algorithm where the d.o.f. within the input predictions are parameterised in terms of Laguerre polynomials rather than using the more normal standard basis set. The LOMPC algorithm proposes to replace common decision variables ukand ckwith Laguerre polynomials in OMPC. It has been shown [37,43] that with the parameterisation of d.o.f., LOMPC can achieve a larger feasible region (MCAS) compared to OMPC using the same number of d.o.f.The z-transform of discrete Laguerre polynomials are defined as follows:(8)Γi(z)=1−a2(z−1−a)n−1(1−az−1)n;0≤a≤1;where the parameter a is the pole of the discrete-time Laguerre network and is required to be selected by the user. Letting lk,ndenote the inverse z-transform of Γn(z, a). This set of discrete-time Laguerre functions is expressed in a vector form as: Lk=[lk,1, lk,2, …, lk,n]Twhich satisfies the following difference equation: Lk+1=ALLk. The size of the ALmatrix, is n×n; and it is a function of the parameters a, β=1−a2 and initial condition L0, which yields to:(9)Lk+1=a000⋯βa00⋯−aββa0⋯a2β−aββa⋯⋮⋮⋮⋮⋱︸ALLk,L0=1−a21,−a,a2,…T.The dimension of the state-predictor (9), can be taken as large (or small) as needed to capture the desired polynomial sequences.The basic concept of OMPC is preserved [39,36], that is the predictions take the form of (5), however, a key difference is that the disturbance (terms ck) is defined with Laguerre polynomials instead of taking the d.o.f. individually. The relevant link between Laguerre and predicted values ofc→k, are summarised in the following equation:(10)c→k=L0TL1T…T︸HLη→k=HLη→k.Now,η→kbecomes the ncdecision variable where one uses the first nccolumns of HL. The following defines the LOMPC algorithm:Algorithm 2LOMPCAt each sampling instant, perform the optimisation:(11)η→k*=argminη→kη→kT∑i=0∞ALiL0WL0T(ALi)Tη→k;s.t.Mxk+NHLη→k≤dReconstitute the first value of the predicted input trajectory ukusingck=L0Tη→k*and (5).Evolutionary computation is a broad paradigm within artificial intelligence, focused on the development of global search and optimisation algorithms known as evolutionary algorithms (EAs), inspired on an abstract model of neo-Darwinian evolutionary theory [17,2,10]. In general, an EA performs an iterative search, where an initial set (population) of candidate solutions (individuals) are randomly generated and evaluated based on a given set of performance measures or objectives (fitness). Then, some solutions are chosen (selection) and used to generate new candidate solutions using search operators loosely inspired on genetic processes (crossover and mutation). Finally, the best solutions are kept (survival) for the following iteration (generation) of this cycle, until a predefined termination criteria is met, such as a particular solution quality or a maximum amount of generations. In this process, both selection and survival are biased to those individuals that exhibit the best performance. Moreover, the search operators are stochastic functions that generate new solutions by randomly modifying and/or combining previously chosen solutions. EAs have proven to be powerful search strategies in problems with large search spaces that exhibit a highly multimodal or irregular fitness landscape, or when the objective function is dynamic or noisy. In particular, EAs are a good option when gradient information is not trivially computed or lacking all together.Besides the problem-specific objective functions, a successful application of an EA requires the following. First, based on the decision spaceXof the problem domain, a corresponding search spaceGmust be defined, where∀x∈X∃g∈Gsuch that y(g)=P, where y is a mapping function. In other words,Gis an encoding scheme for solutions inX.Second, based on how the search space is defined, a set of search operators On,mare required, of the formOn,m:G1×…×Gn→G1×⋯×Gm, where n represents the arity of the operator and m is the number of new solutions it generates. For instance, the most common operators are O1,1(g) which is referred to as a mutation, and O2,2(g1, g2) referred to as a crossover. These search operators take n feasible solutions, known as parents, and produce new candidate solutions which are known as offspring.The final component in an EA can be referred to as population management; i.e. the manner in which candidate solutions are selected to be used as parents, and to determine which individuals survive and are used in the following iteration. However, this aspect of the algorithm will depend on whether the problem presents a single objective or multiple conflicting objectives.The simplest form of an optimisation problem is to consider the existence of a single objective, in which case optimality is trivially defined. However, when there are multiple objectives to optimise, and when these objectives are in conflict, then a single optimal solution does not exist. Instead, a set of compromised solutions represent the optimal solution to the problem. These problems are known as multiobjective problems (MOP), which are difficult to solve for traditional gradient based methods, for which computational costs grow quickly as the size of the search space and number of objectives increases [6].In multiobjective optimisation it is necessary to consider two different and complimentary spaces explicitly: one for decision variables and another for the objective functions. In the case of real valued functions, these two spaces are related by the mappingf→:Rn→Rk. The set of constraints on the objective vectorf→(x)=(f1(x),…,fk(x))defines a feasible regionΩ⊂Rnin the decision space along with its corresponding imageΛ⊂Rnon the objective function space. Now, the following concepts define the optimality for a multiobjective problem.•Pareto dominance:Given k objectives andN=1,…,k, an objective vectorf→uis said to dominate another objective vectorf→v(written asf→u⪯f→v) ⇔ ∀ i∈N,fiu≤fiv∧∃j∈N|fju<fjv.Pareto optimality:A solution vectorx*∈Ω is optimal if ∀ x∈Ω it is true that ∀ i∈N, fi(x)=fi(x*) ∨ ∃ i∈N| fi(x)>fi(x*).Pareto-Optimal Set:For a multiobjective problemf→(x), the set of Pareto optimal solutions isP*:=x∈Ω∄x′∈Ωs.t.f→(x)⪯f→(x′).Pareto Front:For a multiobjective problemf→(x)with a Pareto optimal setP*, the Pareto Front is defined asPF*:=u=(f1(x),…,fk(x))|x∈P*.Over recent years, multiobjective EAs (MOEAs) have proven to be powerful and robust strategies for multiobjective problems, particularly since MOEAs rely on a population based search which is well suited to search for multiple solutions concurrently; i.e., the Pareto-optimal set. Therefore, a multiobjective EA (MOEA) should fulfill the following: (1) it must converge towards the true Pareto Front; and (2) it must representatively sample the true Pareto Front.While many algorithms have been proposed most MOEAs follow the same basic design principles [9,49]. Firstly, fitness assignment must considers Pareto dominance relations to rank individuals. Secondly, because a close to uniform sampling of the true Pareto Front is desired, diversity of solutions within the evolutionary algorithm are encouraged, where similarity within objective space is penalised. Thirdly, to bias the search towards the Pareto Front, elitism is encouraged (where the best solutions of each generation are maintained) by employing some form of population archive, storing all non-dominated solutions found during the search.Several types of MOEAs exist, each uses different mechanisms for diversity preservation and Pareto-based selection criteria, with many qualitative and quantitative comparative studies [13,50,49]. In this work, the Non-dominated Sorting Genetic Algorithm II (NSGA-II) proposed by Deb et al. [7] is used. NSGA-II is an improved version of NSGA that modifies the mechanism for diversity preservation and incorporates an explicit mechanism for elitism. In the context of evolutionary multiobjective optimisation, elitism is an operator required to ensure convergence towards the true Pareto Front. In particular, NSGA-II merges both populations of parents and children and selects the non-dominated individuals to form a series of non-dominated fronts; this information establishes the main criterion for selection and survival and employs elitism through an archive of non-dominated solutions, which allows the search to progress towards better approximations of the true Pareto Front.Along with algorithm convergence, it is also desired that an EA maintains a good spread of solutions in the obtained set of solutions. NSGA-II uses the crowding operator to guide the selection process at the various stages of the algorithm towards a uniformly spread out Pareto Front. First, to get an estimate of the density of solutions surrounding a particular solution in the population, NSGA-II calculates the average distance of two points on either side of this point along each of the objective functions. The computation of this distance, called the crowding distance, requires sorting the population according to each objective function value in ascending order of magnitude in order to assign a non-domination rank. NSGA-II uses a binary tournament selection operator but the selection criterion is based on the crowding operator. This operator requires both the rank and crowding distance of each solution in the population.The MOEA literature reveals a variety of different algorithms, each using different assumptions and specialised heuristics [49]. Therefore, choosing the best MOEA for a new problem is not trivially done. Nonetheless, NSGA-II was specifically chosen for this work due to several advantageous features. First, NSGA-II uses tournament selection and a crowding operator to preserve diversity instead of fitness sharing, achieving a more uniform sampling of the Pareto Front without increasing the computational cost relative to other algorithms [24]. A second advantage of NSGA-II over other MOEAs comes when dealing with constrained optimisation problems, Deb et al. [7] has shown that the tournament selection mechanism can be used for constraints handling with better results than other approaches, in addition to being easy to adapt into implement. Moreover, while several improvements to the basic NSGA-II algorithm have been proposed, many of those deal with many-objective problems (where the number of objectives is above two or three) where many well-known MOEAs, such as NSGA-II, tend to fail [49]; however, the problem studied in the current contribution does not fall within this class of MO problems. Finally, a current review of application papers, such as the one provided by Zhou et al. [49], reveals that NSGA-II proposed a quite general methodology that is often replicated by other algorithms in the field, and has proven to be a very robust MOEA with successful applications in a wide variety of research areas and problem domains.Previous work [37,43] have shown that with LOMPC the user has a handle to trade-off between feasible volumes and the number of d.o.f., that is provided by the parameter a; although no generic guarantees are given, examples in those papers show that in many cases slowing convergence by increasing a above zero (a=0 is equivalent to OMPC) can improve feasible volumes, possibly but not necessarily at some expense to performance. Moreover, the computational cost using LOMPC may increase due to the structure of the Hessian in the QP. However, those works do not provide any guidelines to properly choose a and nc, this leaves the burden on the user to heuristically tune these parameters. Therefore, the goal of this work is to pose the task of parameterising LOMPC as a MOP, and to propose an automatic solution strategy based on the NSGA-II MOEA.Consider a discrete control system, represented by a linear state space model and characterised by the state matrices A, B, C, D, according to Eq. (1) and constrains (3). The system uses a predictive controller LOMPC for which the best Laguerre parameters a and ncare unknown. Then, the goal is to determine the best parameter values based on the following criteria:1.Maximise the feasibility region (MCAS) Jϑ.Minimise the performance loss Jβof the system.Minimise the online computational cost Jϱof the controller.Therefore, the objective vector for any feasible pair of LOMPC parameters or decision variables x=(a, nc) is given byf(x)→=(Jϑ, Jβ, Jϱ). Moreover, the constraints for this MOP are given by(12)0≤a<1;1≤nc≤nc,max;ncinteger.where nc,max is the maximum allowable d.o.f. defined by the user. Each component of the objective vector is defined in the following subsections.For MPC algorithms, the feasible set is equal to the set of initial states for which the online optimisation problem is initially feasible. Typically, this is also the region for which stability is guaranteed. Consequently, an important aim is to obtain a feasible region that is as large as possible. To evaluate the feasibility region of the controller is necessary to estimate the corresponding volume. In order to estimate the normalised volume, first a polytope Poptis defined as the global MCAS of OMPC with a large number of degrees of freedom, able to represent the largest feasible region that can be obtained by the controller (usually nc≥20), this is:Popt={(x,c)|Mxk+Nc→k⩽d}. Also a polytopePHLis defined as the MCAS corresponding to the proposed parameterisation:PHL={(x,η)|MLx+NLη→≤d}; wherePHLis the polytope sliced by the parameterisation matrix HL. The volume of PoptandPHLpolytopes, represent the feasible regions or feasible volumes for each type of algorithm. The volume calculation of a high dimensional polytope is a complex task and the computing time for these polytopes can be prohibitive; consequently, this paper approximates the volume by computing the average distance from the origin to the boundary of the associated MCAS (radius). First select a large n-number of equi-spaced (by solid angle) or random directions in the state space i.e. x=[x1, …, xn] and then, the distance from the origin to the boundary of MCAS is determined by solving a linear programming (LP) for each direction xiselected. Greater distances imply a bigger feasible region. The objective function for evaluating the normalised feasible volume is then:(13)Jϑ=vol(PHL)vol(Popt).The performance evaluation is done by computing the cost J for given xipoints, they are represented by the optimised values of the associated cost function, i.e. Jopt(xi) andJHL(xi). To ensure fairness in comparison of these values, xiis scaled and is feasible for all MPC algorithms being compared. The objective function for evaluating the normalised performance is:(14)Jβ=1n∑i=1nJHL(xi)Jopt(xi).It has been demonstrated that the parameterisation of d.o.f. proposed in the LOMPC algorithm is able to achieve larger feasibility regions while maintaining an acceptable local optimality with the same number of d.o.f. compared to conventional OMPC approaches. However, this reduction in d.o.f. not necessarily results in a reduction of the optimisation complexity and therefore the computational cost, since the resulting quadratic programming of reassignment is denser (heavier) than for OMPC. The alternative proposed here is to compare the online computational load for LOMPC and OMPC as a function of the number of floating point operations per second (flops) required for each algorithm. Using a tailored interior point approach the online computational cost for OMPC is linear with respect to the horizon length and cubic with respect to the state and the input dimension (nu), such that:(15)Jϱ(OMPC)=nc+nx3+nu3(flops).For LOMPC, the online computational cost is cubic in number of d.o.f., the state and input dimensions:(16)Jϱ(LOMPC)=nc3+nx3+nu3(flops).The search space Ω for the optimal decision vectors x=(a, nc) is defined asΩ⊂ℝ2, using a linear relaxation for nc; specifically a∈(0, 1) and nc∈[1, 8]. For crossover, the simulated binary crossover (SBX) is used, which closely approximates the tradition Binary Crossover that is used with bit-string representations. For mutation, a polynomial distribution is used to slightly modify each selected individual. The remaining parameters for the MOEA are summarised in Table 1.Finally, Fig. 1presents a flow chart that summarises the methodology of the application of NSGA-II in the LOMPC tuning. All of the tests presented here use the same parameterisation, except for the total number of generations, which are varied to determine the impact of this parameter on the quality of the solutions found.

@&#CONCLUSIONS@&#
In the design of MPC, different strategies to formulate the d.o.f. have been proposed, for example, interpolation methods, triple-mode strategies and others. The results are satisfactory, but the high online computational cost makes them difficult to implement in hardware with limited memory or low processing power. Other alternatives, such as parameterisation of d.o.f. by orthogonal functions, are able to achieve greater feasibility regions without significantly affecting performance and with relatively low computational cost compared to conventional MPC [37,23,22]. Each of these approaches introduces one or more tuning parameters without guidelines for their selection. It is know that a correct selection of the tuning parameters guarantees the best trade-off between closed-loop performance, feasible region and computational cost. It is clear that this is a multiobjective problem with three compromised objectives in a large search space. For this type of problems MOEAs have proven to be a useful tool [24,10,9].In this paper, a method for a systematic selection of the tuning parameters of a MPC parameterised with Laguerre functions has been developed. In order to do this, the LOMPC tuning is posed as a multiobjective problem and solved using the NSGA-II MOEA. Two experiments, similar to those in previous LOMPC research were presented to show the benefits of this approach. The results suggest that it is possible to obtain a set of Pareto non-dominated solutions for the tuning parameters of a LOMPC controller. The set of solutions found exhibit a proper balance (trade-off) between the three objectives: maximise the feasibility region, minimise the computational burden and minimise the performance loss, even for constrained systems. Furthermore, NSGA-II has the advantage of exploring throughout the search space for Pareto optimal solutions, producing a non-conventional parameterisation, with values that have not been reported in previous literature. This is useful because it allows the exploration of the limits of the parameters of the LOMPC and/or to a priori define a search region that considers constraints from the application domain. Further work should include other efficient MPC approaches on systems with more challenging behavior, such as non-minimum phase and nonlinear models, in order to observe its limitations. Moreover, other MO optimisation approaches should be tested, such as other MOEAs or local search approaches, such as Pareto Front continuation methods [38].