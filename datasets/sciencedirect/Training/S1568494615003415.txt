@&#MAIN-TITLE@&#
Memetic algorithm with simulated annealing strategy and tightness greedy optimization for community detection in networks

@&#HIGHLIGHTS@&#
A Memetic algorithm (MA-SAT) is proposed for community detection in networks.Simulated annealing (SA) and tightness greedy optimization (TGO) are used.TGO is designed to improve diversity, increasing little computation cost.The balance between SA strategy and genetic algorithm is analyzed.The abundant results show that the MA-SAT is very efficient and competitive.

@&#KEYPHRASES@&#
Memetic algorithm,Community detection,Genetic algorithm,Simulated annealing,Tightness,Network,

@&#ABSTRACT@&#
Community structure is one of the most important properties in complex networks, and the problem of community detection in the networks has been investigated extensively in recent years. In this paper, a Memetic algorithm (MA) based on genetic algorithm with two different local search strategies is proposed to maximize the modularity density, and a more general version of the objective function is used with a tunable parameter λ which can resolve the resolution limit. One local search strategy is simulated annealing (SA), and the other one is tightness greedy optimization (TGO). SA is employed to find individuals with higher modularity density, which helps to enhance the convergence speed of the MA and avoid being trapped into local optima. TGO adopts the local tightness function which makes full use of local structural information to generate neighbor partition, which increases very little computation cost and benefits the diversity of the population of MA. Experiments on the computer-generated networks, LFR Benchmark networks, and real-world networks show that compared with several state-of-the-art methods, our algorithm (named as MA-SAT) is very efficient and competitive.

@&#INTRODUCTION@&#
In the real world, many complex systems of interest can be represented by networks, such as the Internet, the world-wide-web, collaboration networks, transportation networks, e-mail networks and biological networks. These networks are usually constituted by a group of nodes or vertices and a group of links or edges. Generally, a node or a vertex represents an individual member in network, while a link or an edge between two nodes or vertices means a relation exists. Features of the networks, such as small-world effect and scale-free degree distribution, have been revealed during the past years. Another important property of the network, community structure, has been paid a considerable attention in recent years. But it is necessary to say that, no quantitative definition of community is universally accepted so far. The definition is usually slaved to the current application or specific system at hand. However, from intuition, a metaphysical notion is formed that there must be more edges ‘inside’ the community than edges linking vertices of the community with the rest of the network [1].The problem of community detection has been studied for not a very long time, but many methods and algorithms have been proposed for detecting community structure. These methods can be divided into traditional clustering methods and modern methods [1]. The former involves graph partitioning [2,3], hierarchical, partitional and spectral clustering. The latter mainly refers to the divisive algorithm and function optimization method. One of the most famous modern methods is proposed by Girvan and Newman[4,5]. The method, named as GN algorithm, is a divisive hierarchical clustering method based on an iterative removal of edges from the network, and the edge removal splits the network into communities. Most of these methods do not provide a unique answer. As the search of extrema of a cost function is carried out with approximation techniques, the methods often deliver results depending on random seeds and on the choice of initial conditions. Fortunately, Lancichinetti and Fortunato [6] have shown that consensus clustering can be combined with any existing method, enhancing both the stability and the accuracy of the resulting partitions greatly.Among the function optimization methods, evolutionary algorithm (EA) has been widely used as an important tool [7–10]. Pizzuti [8] proposed a method based on a genetic algorithm (GA) to optimize an objective function called community score (CS) in order to explore the community structure in social networks. Specially, in [9], Tasgin et al. employed a genetic algorithm on community detection by using a fitness function called modularity Q, and the algorithm doesn’t need to know any prior knowledge about the number of communities in the network.Modularity Q, which was proposed by Newman and Girvan [5], is the best known quality function by now. Many different algorithms have been proposed to optimize modularity Q, such as greedy algorithm [11,12], extremal optimization [13], genetic algorithm [9], etc. However, Fortunato and Barthélemy have found that modularity optimization has a risk of failing to identify modules smaller than a scale which depends on the total size of the network and on the degree of interconnection density of the modules, even in extreme cases where modules are unambiguously defined [14]. To overcome this limitation, Li et al. [15] introduced a new quality function named modularity density or D value, including a general version which contains a tunable parameter λ. Li et al. also theoretically reveal the equivalence of modularity density and the objective of kernel k means, which explains the meaning of the criterion from another perspective. Gong et al. [16] proposed a Meme-Net algorithm with a hill climbing strategy to optimize the general version of modularity density, and the algorithm can also be called a general Memetic algorithm.Memetic algorithm (MA) [17] was first introduced to denote a family of metaheuristics that have as central theme the hybridization of different algorithmic approaches for a given problem. ‘Memetic’, which comes from the term ‘meme’ introduced by R. Dawkins [18], denotes an analogy to the gene in the context of cultural evolution. During the process of its evolution, MA is also called as ‘hybrid EA’ or ‘Lamarckian EA’ in literatures. Just like EA, MA is a kind of population-based metaheuristics, and MA blends different search strategies (i.e., global search strategies and local search strategies) in an algorithmic approach. While a particular advantage of MA is that, compared to traditional EAs, MA is intrinsically concerned with exploiting all available knowledge about the problem under study. MA constitutes an extremely powerful tool for tackling combinatorial optimization problems. It has been proved that MA is fit for NP hard optimization problems and a remarkable history of successful applications of MA to such problems have been reported. We employ MA as the algorithm to optimize the quality function, considering the search for optimal modularity density D is an NP-hard problem [15].Simulated annealing (SA) is a compact and robust technique. It is a heuristics algorithm which is based on an analog of thermodynamics with the way metals cool and anneal. In the last two decades, SA has received significant attention for extremal optimization problems, where a desired global minimum (maximum) is hidden among many local minima (maxima) [19]. SA has been used for combinational optimization problems and many combinatorial problems belong to NP-hard problems. Maffioli [20] showed that SA can be considered as one type of randomized heuristic approaches for combinational optimization problems.Combining a kind of global search algorithm with SA, which is used as the local search strategy, will generate a Memetic algorithm with better search ability. Such a Memetic algorithm can also be applied to deal with the problem of community detection by utilizing the modularity Q or modularity density D as the fitness function. However, Q or D is a kind of global structural metric, and evaluating Q or D requires complete knowledge of the entire network, which is usually time consuming. Since the traditional local search operators are used to optimize the same fitness function with that of the global search algorithms, traditional MAs are usually more time consuming than traditional EAs. It is a challenge to design a Memetic algorithm with better performance and less computation complexity. On the other hand, local structural information of complex networks can be utilized to evaluate the quality of a local community. Some methods for identifying communities based on the local link structure of a network or some local metric have been proposed, most of which are greedy algorithms. Various kinds of local community measurements have been presented by measuring the properties and adjacency information of vertices in the networks [21–23]. Lancichinetti et al. [21] presented a fitness function by investigating vertices’ degree information to evaluate the local community quality. Huang et al. [23] put forward a structural similarity-based metric and introduced a function named local community tightness by employing the structural similarity. The tightness value of a local community will increase when the community's internal similarity becomes high and external similarity becomes low. Such local structure optimization based methods usually run faster than those EA based methods, which aim to optimize the global structural metric. But EA based methods still have their own advantages with regard to the ability of global optimization.Therefore, in this paper, we try to design a Memetic algorithm by presenting two kinds of local search operators. One acts as the traditional local search operator to improve the global structural metric. The other acts as a new kind of local search operator to perform a local structure optimization with less computation complexity. Specifically, we propose a Memetic algorithm with two different local search strategies to maximize the modularity density D. One local search strategy is simulated annealing (SA), which helps to find individuals with increased modularity density D. The other one is tightness greedy optimization (TGO), which is used to improve the local community tightness [23] of an individual, without increasing any fitness evaluations. We name our algorithm as MA-SAT. SA helps to enhance the convergence speed of the MA and avoid being trapped into local optima. TGO adopts the local tightness function which makes full use of local structural information to generate neighbor partition, which increases very little computation cost and benefits the diversity of the population.The modularity density D is the fitness function in our MA-SAT and it is a kind of expensive evaluation, while TGO tries to find new individuals by evaluating the local tightness function T which is much less expensive. The idea, to some extent, can be seen as an example of surrogate-assisted EAs [24,25] which usually use efficient computational models to approximate the fitness function. Some existing surrogate-assisted approaches construct an approximate model using samples composed of individuals in one or more generations, which requires highly accurate surrogates in order to obtain the global optima. The others utilize the idea of fitness inheritance, which often needs additional memory space to store fitness values of the parents. Different from the surrogate-assisted methods mentioned above, our MA-SAT makes advantage of the idea of local community which is becoming a tendency in the area of community detection, and substitutes the local evaluation function T for the global evaluation function D in the process of TGO. TGO could find individuals with better partition results using less evaluation cost, which will be analyzed in theory in Section 3.2.2 and demonstrated by experiments in Section 5.4.Experimental results on computer-generated networks [4,26], LFR Benchmark networks [26], and real-world networks [4,27–30] show the effectiveness of our algorithm. Additionally, we compare our algorithm with several state-of-the-art methods, and the experimental results also show our algorithm is competitive.In this section, we will make a brief introduction to the quantitative function modularity density before describing our algorithm in detail.Considering an undirected graph G=(V,E), where V is a set of objects, called nodes or vertices, and E is a set of links or edges, that connect two elements of V. The adjacent matrix of the graph is A. We assume V1 and V2 are two disjoint subsets of V, and then we defineL(V1,V2)=∑i∈V1,j∈V2Aij,L(V1,V1)=∑i∈V1,j∈V1Aij, andL(V1,V1¯)=∑i∈V1,j∈V1¯Aij, whereV1¯=V−V1.Given a partition {V1, V2, …, Vl} of the graph, where Viis the vertex set of subgraph Gifor i=1, 2, …, l, then the modularity density or D value can be formulated as [14]:(1)D=∑i=1ld(Gi)=∑i=1lL(Vi,Vi)−L(Vi,V¯i)|Vi|In general, the larger the value of D is, the more accurate a partition is. Then the problem of community detection can be viewed as a problem of maximizing the modularity density or D value. Compared with modularity optimization, modularity density does not require a null model, i.e., a copy of the original graph which keeps some of its structural properties but has no community structure, and delivers better results. However, it is still affected by a resolution limit [1]. To avoid that, Li et al. [15] proposed a more general definition of their measure, including a tunable parameter that allows exploring the graph at different resolutions. The general version is defined as follows:(2)Dλ=∑i=1l2λL(Vi,Vi)−2(1−λ)L(Vi,V¯i)|Vi|When λ=1, Dλis equivalent to the ratio association; when λ=0, Dλis equivalent to the ratio cut [31]; when λ=0.5, Dλis equivalent to modularity density D. So the general modularity density Dλcan be viewed as a combination of the ratio association and the ratio cut. Generally, optimization of the ratio association algorithm often divides a network into small communities, while optimization of the ratio cut often divides a network into large communities. In this paper, we employ MAs to optimize the general function in the formula (2) by varying the parameter λ to analyze the community structure and hierarchical organization.In this section, we will give a detail description about the proposed algorithm MA-SAT. The framework of the algorithm is given as Algorithm 1.It is necessary to make some explanations about the algorithm framework. We employ the general version of modularity density D described by the formula (2) as the fitness function, which should be maximized. Genetic algorithm is used as the global search algorithm. After initialization, the algorithm will loop until i reaches Gen or maximum number of fitness evaluations for comparison is satisfied [32,33]. During each generation, tournament selection is used to select the parent population (Pparent), and then genetic operation is executed to produce child population (Pchild). Next, the local search procedure is performed on the best individual (best_of_Pchild) in the child population and the final new individual found by local search (l_best) will join in the child population. During the update population procedure, the original population (Pop) and the child population are combined, and then the top Pop-size fittest individuals are selected and retained to the next generation.Two kinds of Local search operators are used to perform the local search. One is the simulated annealing (Local search_SA) strategy. The other is tightness greedy optimization (Local search_TGO). As for SA strategy, it is executed once every four generations, while TGO is performed in other generations. SA is employed to find individuals with higher modularity density D in neighborhood of the “best_of_Pchild”, which helps to enhance both the convergence speed of the MA and the accuracy of the resulting partition. TGO is executed to find individuals with improved local community tightness in the neighborhood of the “best_of_Pchild”. The procedure of TGO increases very little computation cost because it does not need to calculate the fitness function (i.e., modularity density D in this paper), which has to evaluate the entire network and is usually time consuming. TGO helps to produce better individuals with higher community tightness, which also benefits the diversity of the population of MA. The resulting algorithm is denoted as MA-SAT. To illustrate the necessity of the using of TGO, a transitional version named as MA-SA is also provided for comparison which only executes SA as the local search strategy once every four generations.Algorithm 1The algorithm framework of MA-SAT.1: Input: Gen (Maximum number of generations), Pop-size (Population size), Pool(Size of mating pool), Tour-size (Tournament selection size), Pc(Crossover probability), Pm(Mutation probability);2: Pop←Generate initial population (Pop-size);3: For i=1: Gen4: Fitness evaluation (Pop);5:Pparent←Tournament selection (Pop, Pool, Tour-size);6:Pchild←Genetic operation (Pparent,Pc,Pm);7:If mod (i,4)==08:l_best←Local search_SA (best_of_Pchild);9:Pchild←Pchild∪l_best10:else11:l_best←Local search_TGO (best_of_Pchild);12:Pchild←Pchild∪l_best13:end if14:Pop←Update population (Pop, Pchild);15:i=i+1;16: end for17: Output: Output the best partition solution which corresponds to the fittest chromosome.Next we will give a brief introduction about the genetic algorithm operators in Section 3.1 and the two local search operators in Section 3.2.As mentioned above, the general version of modularity density D is used as the fitness function. The genetic representations and operators will be described from Section 3.1.1 to Section 3.1.4.We choose the initialization operator which has been used in [9,16]. We use m dimensions vectors as the chromosomes, where m is the number of vertices in the network. For all chromosomes, each vertex is put into a different community, thus the number of communities for each chromosome in the initial population is m. In genetic algorithms, it is a common practice to give the genetic algorithm not a completely random initial starting point but a biased one in order to speed up the convergence. For each chromosome, we select a vertex randomly and assign its community identifier to its neighbors as shown in Fig. 1, where the neighboring vertices mean the vertices which have links with the selected vertex. We repeat this operation α·m times for each chromosome in the initial population where α is a model parameter and α=0.2 is adopted in our algorithm. This operation is quite fast and results in small communities. But this result is still far away from the ideal partition.Here we have two alternative schemes to choose, one is the commonly used roulette wheel selection and the other is the deterministic tournament selection. The roulette wheel selection may lead to super individual or make the algorithm converge too fast. Moreover, the value of fitness function, i.e., the quality function we use here, may be negative. In view of these facts, we employ the latter scheme, i.e., the deterministic tournament selection.Due to the biased initialization introduced in Section 3.1.1, the general one-point crossover is not compatible in our algorithm. Here we introduce an effective method called one-way crossing over which was proposed in [9]. Given two chromosomes, we take one of them as the source chromosome chsrcand the other as the destination chromosome chdest. The crossing over procedure is as follows. Pick a vertex viat random, determine its community identifier(chsrci)in the source chromosome and the location of all the vertices belonging to the same community in the source chromosome. Then assign this community identifier to the corresponding location in the destination chromosome (i.e.,chdestk←chsrci,∀k∈{k|chsrck=chsrci}).This operation is repeated η·m times on the chromosome. The crossing over rate η is a model parameter and set η=0.2 for the experiments reported in this paper. An example of this procedure is shown in Fig. 2.Here we employ one-point mutation operator. We pick one vertex on the chromosome randomly, and then its community identifier is randomly changed to the community identifier of one of its neighbors. This operation is repeated m times on the chromosome, where m represents the length of the chromosome.In our Memetic algorithm MA-SAT, we employ SA as one of the local search strategies to get a better solution. The SA in this paper is different from the general sense of local search strategy like hill-climbing algorithm and greedy algorithm. The most obvious difference is that, SA will accept a worse solution with a probability [34], which ensures that SA can not only improve the result during search iterations, but also can escape from local optima. Moreover, the cooling process, which is analogical to the cooling of a metal, enables SA to converge gradually to the global optima [35]. The local search procedure is given in Algorithm 2.We need to illustrate some details of this procedure. Te is the temperature, and initial value of it is equal to the variance of the offspring individuals. θ is an annealing fact, and the bigger the θ is, the more slowly the annealing procedure is (it can range from 0.85 to 0.95 actually). Parameter ɛ is the terminal criterion, and it equals to 0.01 in our algorithm. P is an acceptance probability, whose expression is P=exp(−(D(S)−D(S′))/Te). Here D(S) is the D value of partition S calculated according to the formula (2). The Find Neighbors () function is used to produce the neighbors of a partition, we randomly select a vertex in the current chromosome, and determine its community identifier, then assign a different community identifier in the same chromosome to it, and a new chromosome is produced. This procedure is shown in Fig. 3. This procedure is repeated for 4m/5 times, where m is the length of the chromosome. S1 represents the initial solution, and S1, S2, S3, S4, … represent candidate solutions and Step_i means the sequence we select the vertex.Algorithm 2The simulated annealing algorithm procedure.1: Input: best_of_Pchild, Te, θ, ɛ.2: Step 1: S←best_of_Pchild;3: Step 2: Repeat4: While Te>ɛ5:S′←Find Neighbor (S);6:D(S′)←Fitness evaluation (S′)7:If D(S′)>D(S)8:S←S′9:else if P>rand (0,1)10:S←S′;11:End if12:End if13:Te←Te*θ;14: End while15: Output: S;In our Memetic algorithm MA-SAT, we employ tightness greedy optimization (TGO) as the other local search operator by optimizing the local community tightness. Different from SA strategy, TGO does not need to calculate the global fitness function when evaluating the quality of a new generated individual. Instead, it adopts the tightness function which makes full use of local structural information to generate neighbor partition. Next, we will introduce it in detail. Some related concepts are illustrated firstly.Huang et al. adopted a structural similarity to measure the local connectivity density of any adjacent nodes in an undirected network [23]. Considering a network described as a graph G=(V,E), the structural similarity s(u,v) between any two adjacent nodes u and v is shown by the following equation(3)s(u,v)=|Γ(u)∩Γ(v)||Γ(u)|⋅|Γ(v)|where Γ(u) denotes the set of node u and u's neighboring nodes.|Γ(u)∩Γ(v)|means the common neighbors of node u and v. By employing the structural similarity, the local community quality function named community tightness T is then defined as(4)T(c)=SincSinc+SoutcwhereSinc=∑iεc,jεc,{i,j}∈Es(i,j)is the internal similarity of the community c andSoutc=∑iεc,j∉c,{i,j}∈Es(i,j)is the external similarity. Tightness T(c) can be employed to evaluate the quality of a given community c. As a neighboring vertex i is added to community c, the community tightness of c is changed. Then, the tightness increment of a vertex i joining in c is(5)ΔTc(i)=T(c∪{i})−T(c)It can be derived that if ΔTc(i)>0 holds, it is equivalent to τc(i)>0, which is described in (6).(6)τc(i)=SoutcSinc−Souti−Sini2SiniwhereSini=∑{v,i}εE∧vεcs(v,i)andSouti=∑{i,u}∈E∧u∉cs(i,u). Thus the criterion named as Tightness Gain to test whether a candidate node i should join in a community c or not is obtained. If node i can increase the value of tightness, i.e., the criterion satisfies τc(i)>0, then node i is merged into community c and a new neighbor is generated.Next, let us explain why the community tightness T is chosen as a substitute for fitness function D during the local search procedure. As previously mentioned, a community is usually roughly described as a collection of vertices that are densely connected within a group but loosely connected to the vertices outside the group [15]. Thus the task of the community detection algorithms is to discover the community structures in complex networks. That is to say, community detection algorithms should try to find a partition of the complex networks, in which the vertices within a community are closely connected while the vertices between different communities are loosely connected. From formula (1) and (2), it can be intuitively observed that the larger the value of the modularity density D is, the better a partition is. Similarly, the local community tightness T based on the structural similarity could also be applied to solve the community detection problems. According to formula (4), it can be observed that the larger the value of T, the denser the connections of the vertices within a community and the sparser those between different communities, which is consistent with the definition of community. Then, according to the deduced formula (6), τc(i) can be utilized as a criterion to determine whether a candidate vertex i should be included in the community c or not. As τc(i)>0, vertex i will be added into the community c, and thus a new partition is generated with one of its community c acquiring an improved tightness. This procedure is very suitable for generating neighboring partitions in a local search procedure. Comparing the modularity density D and community tightness T, the difference between them is that the modularity density D requires complete knowledge of the entire network to evaluate a partition (i.e., a individual in EAs) while community tightness T only needs to evaluate one local community c by considering adding a neighboring vertex into it or not. However, the general aims of two measures are the same, i.e., to find better partitions in which the connections of vertices within a community are closely while those between different communities are loosely. Therefore, it could be inferred that there is some positive relation between these two measures, which will also be demonstrated in the following experimental section.In addition, it can be found that the local community tightness T is less expensive than modular density D since the former only needs to evaluate the τc(i) of one local community c while the latter requires complete knowledge of the entire network. Specifically, how much less expensive is local community tightness T than modular density D? We will demonstrate it by experiments, which will show that local community tightness T costs much less time than modular density D does. The difference in time consuming between them will become more significant as the size of networks increases.Given the above introduction, the procedure of obtaining a neighbor partition using TGO is provided in Algorithm 3 and further described as follows.1.Determine the total number of communities (i.e., cluster_num) of the partition decided by the chosen best chromosome in Pchild(i.e., best_of_Pchild).Consider the community which is named as community k (i.e., Ck). Then determine the neighborhood set Nkof community k. The neighborhood set Nkmeans the vertices which have links with the nodes in community k.Select the node i with the most possibility to join in community k from the neighborhood set Nkand consider whether the selected node i should be included in community k or not. The vertex which is most likely to join in a cluster means it has the highest similarity with the cluster, i.e.,Siniis the highest. If τk(i)>0, the node i is then inserted into community k and the neighbor partition is obtained. Otherwise, other nodes belonging to the neighborhood set Nkwill be considered in sequence until τk(i)>0.The remaining communities of the chromosome will also be executed by the procedure orderly. New chromosomes are obtained in sequence once the above procedure is executed. During the execution of the process on all the communities, the times Numτof τk(i)>0 are counted. The above procedure will be performed iteratively, and it will not stop until the Numτis smaller than a threshold (here, 1/3×total community numbers of the current chromosome, i.e., cluster_num/3 is used as the threshold) or the number of loop times reaches a pre-set value Tloop(Tloopis set to 20 in experiments). This local search operator utilizes the local structural information of the networks to evaluate a generated neighbor solution, costing little computation.Algorithm 3The TGO operator procedure.1: Input: best_of_Pchild, Tloop.2: Step 1: S←best_of_Pchild; cluster_num←Find number of cluster (S); Numτ←cluster_num; t=13: Step 2: Repeat4: While Numτ≥(cluster_num/3) & t≤Tloop5:Numτ=0;6:For k=1: cluster_num7:Find Nkof Ck8:Find note i (i∈Nk&Siniis highest)9:if τk(i) >010:Numτ=Numτ+1;11:S′←(Find Neighbor (S): Ck←Ck∪i);12:cluster_num←Find number of cluster (S′);13:End if14:End For15:t=t+1;16: End while17:Output: S;We consider a simple example to explain the process described above. Given a small network which consists of 7 nodes and the initial partition can be represented as {1, 1, 1, 2, 2, 3, 3} as shown in Fig. 4(a). The threshold is 1/3×total community numbers, i.e., 1.Community 1 is considered first. It consists of node 1, 2, 3 and the neighborhood set N1 of it is {4, 5, 6}. The similarity between node 5 and cluster 1(i.e., the similarity between node 5 and node 3 since node 5 is only linked with node 3 in community 1) is 0.8165 which is calculated by (3), and node 5 has the highest similarity with community 1. Then τ1(5) calculated by (6) is −0.9169<0, and node 5 cannot be added into community 1. Then community 2 is considered orderly. The neighborhood set N2 of community 2 is {3, 6, 7} and node 6 has the highest similarity with community 2 which is 1.8944. The value of τ2(6) calculated by (6) is 0.9516>0 and node 6 is added into community 2 as shown in Fig. 4(b). Finally community 3 is considered. Community 3 only has one node, i.e., node 7. Its neighborhood set N3 is {4, 6} and node 4 is with the most possibility to join in community 3. The value of τ3(4) calculated by (6) is −0.2906<0 and node 4 cannot added into community 3.Through the above process, a new chromosome L1 is generated and the partition expressed by it is {1, 1, 1, 2, 2, 2, 3}. The Num of τk(i)>0 is 1, which is equal to the threshold. Consequently, communities of the new chromosome will also be executed by the above procedure sequentially. For community 1, node 5 is the most likely choice to add into it and τ1(5)<0. For community 2, the similarity between node 3 and it is 2.2771 which is the highest among the neighbors {3, 7}. τ2(3)>0 and node 3 is added into community 2 as shown in Fig. 4(c). Similarly, for community 3, the adjacency information of it keeps unchanged. τ3(4)<0 and node 4 cannot added into community 3. As a result, another new chromosome L2 {1, 1, 2, 2, 2, 2, 3} is obtained and the Num of τk(i)>0 is 1, which is equal to the threshold as well. Thus the above process will be performed again on L2 and a new chromosome L3 is got. The partition of L3 is {1, 1, 2, 2, 2, 2, 2} as shown in Fig. 4(d). There are 2 communities and thus the threshold is changed into 1/3×total community numbers, i.e., 0.67. For community 1, τ1(3)<0; for community 2, τ2(1)<0. Thus the Num of τk(i)>0 is 0 and it is less than 0.67, which results in the finish of local search_TGO. To sum up, the partition obtained by local search_TGO is {1, 1, 2, 2, 2, 2, 2}.It is necessary to illustrate some design issues of Memetic algorithm. This naturally leads to questions such as the following [36].a.Where and when should local search be applied within the evolutionary cycle?Which individuals in the population should be improved by local search, and how should they be chosen?How much computational effort should be allocated to each local search?How can the genetic operators best be integrated with local search in order to achieve a synergistic effect?In [37,38], Hisao Ishibuchi et al. have made large amount of experiments to discuss the above questions in detail. In other words, these questions can be summarized as the balance between the genetic algorithm (global search) and the local search, or the balance between exploration and exploitation [39].In our algorithm, we employ the local search after the genetic operators. We choose the best individual rather than all chromosomes in the child population as the initial solution for local search. This can reduce much useless computational effort and the performance can be improved largely [38].In MA-SAT, both SA and TGO are employed as the local search strategies. Since TGO does not cost fitness function evaluation, only SA and GA will be considered with regard to the computational effort allocation. We perform the SA operator once every four generations rather than each generation, i.e., PLS=0.25 (PLSis local search application probability). This is because when we use local search too much, almost all the available computation time is spent on local search and global search ability of GA cannot be utilized very well. On the contrary, when we use GA search too much, the local search ability cannot be utilized very well in MA. During the local search procedure of SA, we examine 4m/5 neighbors from the starting point, where m is the length of chromosome. Several parameters of SA such as Te, θ and ɛ affect the computational effort allocation of SA collectively. The parameter analysis will be provided in Section 5.1.In this section, we will perform our algorithms on computer-generated networks [4,26], LFR benchmark networks [26] and several real-world networks [4,27–30]. The results obtained by several state-of-the-art methods are also given for comparison. These results show the effectiveness and multi-resolution ability of our algorithms.Before we show our experiment results, we would introduce several evaluation measures. First of all, the most commonly used measure is Normalized Mutual Information (NMI), which is a similarity measure as describe in [40]. Given two partitions A and B of a network in communities, let C be the confusion matrix whose element Cijis the number of nodes of community i of partition A that are also in the community j of the partition B. The normalized mutual information I (A, B) is defined as:(7)I(A,B)=−2∑i=1cA∑j=1cBCijlog(CijN/Ci.C.j)∑i=1cACi.log(Ci./N)+∑j=1cBC.jlog(C.j/N)Here cAand cBis the number of clusters in the partition A and partition B, respectively. Ci. is the sum of the elements of C in row i, and C.jis the sum of the elements of C in column j, and N is the number of nodes. If A=B, I (A, B)=1. If A and B are completely different, I (A, B)=0.To evaluate the performance of a community detection algorithm, the partition obtained by the algorithm can be regarded as partition A, while the true partition of the tested network as partition B, and then the NMI value, i.e., I (A, B) could be calculated according to formula (7). Therefore, the larger the NMI value is, the more accurate the resulting partition is. For computer-generated networks, LFR benchmark networks and some real-world networks, true partitions can be acquired. Thus, as an objective and impartial measure, NMI becomes the most preferred measure if the true partitions are available.Besides NMI, some other measures such as the fraction of vertices identified correctly (FVIC) [7] also can be utilized as long as the true partitions are known. Similar to NMI, larger FVIC indicates better partition results. In addition, the average number of communities (ANC) [7] detected by the algorithm could be reported to compare with the true number of communities.The measures mentioned above require the true partitions of the tested networks. However, for some real-world networks, the true partitions are unknown. In this case, modularity Q is generally utilized for evaluating the quality of the resulting partitions in practice. If the modularity density D is utilized as the fitness function of EAs, it could also be used as another criterion to evaluate the performance of the EAs.In the following sections except Section 5.7, NMI is preferred as long as the true partitions of tested networks are known. In Section 5.7, FVIC and ANC are used for the comparison with the algorithms proposed in [7]. For some real-world networks with true partitions unknown, the modularity Q is provided for evaluation. Furthermore, since the modularity density D is utilized as the fitness function in this paper, the modularity density D may also be reported if necessary.The parameters we use in MA-SAT are given in Table 1.As mentioned above, several parameters of SA such as Te, θ and ɛ affect the computational effort allocation of SA collectively. Among them, θ is a very important parameter, and affects the convergence rate. By varying θ, with other parameters using the given values, the computational effort allocation between SA and GA can be adjusted, and the balance between local search and global search can be investigated.Since TGO uses local tightness function T rather than fitness function D, the transitional version MA-SA is employed in this section to investigate the balance problem. In order to get the fittest value of θ, we test MA-SA on the GN Extended Benchmark Networks proposed by Lancichinetti et al. [26] with varying θ and different mixing parameter μ for different λ as shown in Fig. 5.From Fig. 5, we can clearly find that, for each sub-figure, it presents a tendency that NMI increases with the increase of θ, and when θ ranges from 0.85 to 0.95, NMIs get higher correspondingly. Therefore, we set θ as 0.95 in the following experiments.In this section, we adopt the benchmark networks proposed by Lancichinetti et al. [26] which is an extension of the classic benchmark network proposed by Girvan and Newman in [4]. Each network consists of 128 nodes divided into four communities of 32 nodes each. The average degree of the network is 16 and the nodes have approximately the same degree, as in a random graph. Every node shares a fraction 1−μ of its links with the other nodes of its community and a fraction μ with the other nodes of the network; μ is the mixing parameter. When μ<0.5 the neighbors of a node inside its group are more than the neighbors belonging to the other three groups, thus a good algorithm should discover them.In this paper, we generated 11 computer-generated networks with different values of mixing parameter μ ranging from 0 to 0.5 and employed NMI to measure the similarity between the true partitions and the detected ones. For each network, we computed the average NMI over 30 independent runs. The results of MA-SAT are shown in Fig. 6.As is shown in Fig. 6, for λ=0.5, when μ≤0.25, our algorithm can find the true partition correctly, which means NMI=1. When the mixing parameter increases, it is more and more difficult to find the true partition, but the detected partition is still close to the true one (when μ=0.35, NMI=0.969). From the figure we can see that when λ becomes bigger, the algorithm tends to find smaller communities. For example, when μ=0.35, for λ=0.7, we can find the true partition (NMI=1); while for λ=0.4, our algorithm regards the network as one large single community (NMI=0). This phenomenon is consistent with the definition in Section 2.In order to state the effect of the local search strategies in MA-SAT, we designed a pure GA version without local search operators. Then we test the GA version on the GN Extended benchmark network when λ=0.5, and the other parameters are the same as the ones in MA-SAT. The maximum number of function evaluations is 100,000. Then we compare the results as shown in Fig. 7. It can be observed that MA-SAT performs much better than GA under the same parameter conditions with the same maximum number of function evaluations, which validates the effectiveness and necessity of the local search strategies used in MA-SAT.The results of MA-SAT and MA-SA are given in Fig. 8. Simultaneously, we compare the values of NMI with those of Meme-Net [16] over 30 independent runs as shown in Fig. 8 to state the effectiveness of our algorithms.To be fair, we compare results of MA-SA and MA-SAT with Meme-Net's under the condition of function evaluations and we select the function evaluation values as 100,000 which make Meme-Net obtain its best results according to the maximum iteration values described in [16]. From Fig. 8, it is clear that MA-SA is much better than Meme-Net for GN Extended Benchmark Networks. For examples, when λ=0.4, μ=0.25, MA-SA can find the true partition (average NMI=1) in 30 independent runs, while Meme-Net can just find an approximately true partition (average NMI=0.971). This situation also happens when λ=0.5, μ=0.3 and when λ=0.6, μ=0.35. Another example is shown in Fig. 8(e), i.e., when λ=0.7, we can see that MA-SA is much better than Meme-Net. Meanwhile, it is obvious that MA-SAT is better than MA-SA. When λ=0.5, μ=0.35, the NMI value of the partition detected by MA-SAT is 0.969 which is greater than MA-SA's. When λ=0.6, μ=0.4, the NMI value obtained by MA-SAT is 0.951 while MA-SA only gets NMI=0.914. We can also see this phenomenon when λ=0.7. Comparison results between MA-SAT and MA-SA indicate that TGO used in MA-SAT is able to improve the performance of the algorithm. Thus in the following experiments only the results of MA-SAT are given to compare with other algorithms.A confusing phenomenon drew our attention. As shown in Fig. 8(a), when λ=0.3, μ=0.25, our algorithms seem to be worse than Meme-Net, though the value of fitness function is higher. How can this happen? We find that Meme-Net doesn’t always converge at the maximum value of fitness function when iterative terminates. We also find that there is no strict positive co-relationship between the value of NMI and the value of fitness function. That is to say, the value of NMI is not always the maximum when the value of fitness function gets maximum. On the contrary, the value of NMI is bigger while the value of fitness function is smaller under some conditions. Due to the Meme-Net algorithm adopts hill-climbing as the local search strategy and hill-climbing algorithm does not accept a solution which is worse than the current, so it may trap into local optima and fail to find the global optima. While SA offsets this drawback, as we have illustrated in previous section.In this section, we will apply our algorithm MA-SAT on four real-world networks, i.e., the Zachary's karate club, the Dolphin social network, the American College football, and the Books about US politics.Zachary's karate club. This network is a well-known graph regularly used as a benchmark to test community detection algorithms. It consists of 34 vertices, the members of a karate club in the United States [27], who were observed during a period of three years. As a divergence broke between the administrator of the club and the club's instructor, this club was separated into two parts ultimately.Dolphin social network. This is a network of 62 bottlenose dolphins living in Doubtful Sound (New Zealand) analyzed by Lusseau [28]. The dolphins were separated in two groups after a dolphin left the place for some time. A tie between two dolphins was established by their statistically significant frequent association. Like Zachary's karate club network, the dolphin social network is also used to test algorithms for community detection.American College football. This network has been used for testing benchmark by Girvan and Newman [4]. It is a presentation of the schedule of Division I games for the 2000 season: vertices in the graph represent teams (identified by their college names) and edges represent regular-season games between the two teams they connect. All of the teams are divided into 12 conferences containing around 8–12 teams each. Games are more frequent between members of the same conference than those between members of different conferences. Inter-conference play is not uniformly distributed; teams that are geographically close to one another but belong to different conferences are more likely to play with one another than teams separated by large geographic distances.Books about US politics. This network has been compiled by Newman [29]. In this network the vertices represent 105 recent books on American politics bought from the online bookseller Amazon.com, and edges join pairs of books that are frequently purchased by the same buyer. Books were divided according to their stated or apparent political alignment, liberal or conservative, except for a small number of books that were explicitly bipartisan or centrist, or had no clear affiliation.For each network, we set the value of λ from 0.2 to 0.8, then for each λ we calculate average value of NMI for 30 independent runs. In this test, we set function evaluations as the iterative termination condition, i.e., the algorithm progress stops when function evaluations i.e., objeval≥160,000. The results of our algorithm MA-SAT are shown in Fig. 9. To investigate the performance of MA-SAT, the corresponding results obtained by Meme-Net algorithm are also given for comparison.For Zachary's karate club, when λ=0.2, our algorithm regards the whole network as a big single community; when λ=0.3, the network is separated into 2 communities i.e., the true partition (NMI=1), as shown in Fig. 10(a); when λ=0.4 or λ=0.5, the network is separated into 3 communities as shown in Fig. 10(b) which splits the left part of the network into two smaller ones; when λ=0.6 or λ=0.7, we find 4 communities, and this solution splits each of the large communities into two smaller ones as shown in Fig. 10(c); when λ=0.8 the network is separated into 5 communities which further splits the right part into 3 communities as shown in Fig. 10(d). When λ gets bigger, more communities can be found which are not shown in Fig. 10 in this paper.For Dolphin social network, when λ=0.3, 2 communities are found and the corresponding NMI=1. This means the partition when λ=0.3 is the true one, which is shown in Fig. 11; when λ=0.4, 3 communities are found and the corresponding NMI=0.822, and we find that the right community is split into two smaller communities and no vertices are misplaced; when λ=0.5, 5 communities are found and the corresponding NMI=0.586, which splits the left community into 2 smaller ones, and the right community into 3 smaller ones; when λ=0.6 or larger, more communities can be found. From the experiments we can see that, by tuning the parameter λ, we could explore the network at different resolutions.For American college football club and Books about US politics network, we didn’t find the exactly true partitions for the complexity of the networks themselves. However, the detected ones are very close to the true partitions. For example, when λ=0.7, on the American college football club network, 11 communities are found corresponding to the best NMI 0.938, only a few vertices are misplaced; when λ=0.2, on the Books about US politics network, 2 communities are detected corresponding to the highest NMI 0.598.From Fig. 9 above we can see that our algorithm MA-SAT is superior to Meme-Net on Zachary's karate club, Dolphin social network and Books about US politics network. However, on American college football club, for λ=0.2 and λ=0.3, MA-SAT seems to be worse than Meme-Net. In order to explain this phenomenon, we made another contrast experiment, the result when λ=0.2 is shown in Table 2.In Table 2, VOF represents the value of fitness function and the value below it is the corresponding NMI. Ave represents average value of VOF or NMI. As shown in Table 2, for λ=0.2, the values of fitness function of Meme-Net are much smaller than MA-SAT, but the corresponding NMI are bigger than that of MA-SAT. For Meme-Net, we tried to enlarge the function evaluations, but the results are no better than before. This situation also happened when λ=0.3. The results show that for λ=0.2 and λ=0.3 on American college football club network, the algorithm of Meme-Net is trapped into local optima while MA-SAT can converge to the global optima nearly all the time; another conclusion is that for some networks, the smaller the tunable parameter λ is, the weaker the correlation between the value of fitness function and NMI is.Considering TGO of MA-SAT evaluates local community tightness T rather than modular density D, several questions about TGO will be investigated in this section.In Section 3.2.2, theoretical analysis is provided which indicates that there is some positive relation between local community tightness T and modular density D. In this section, the positive relation will be demonstrated by experiments.MA-SAT is tested on nine networks. They are five GN Extended Benchmark Networks with mixing parameter μ values ranging from 0.1 to 0.5 and four real-world networks including the Zachary's karate club, the Dolphin social network, the American College football, and the Books about US politics which are described in Sections 5.2 and 5.3, respectively.During one run of MA-SAT, we record the total number of times that τc(i) >0 with SumT. Every time as τc(i) >0, a new partition will be produced by TGO, and its fitness D will be compared with that of the previous unchanged partition. Once the modular density D is increased, one time will be counted. Thus, the total number of times that modular density D is increased which is related to τc(i) >0 can be recorded by SumD. Finally, the ratio of SumDto SumTis calculated. Fig. 12shows the average ratio over 10 runs on different networks.From Fig. 12, it could be found that all the ratios are larger than 0.6 for all the nine networks, and 6 ratios out of 9 are larger than 0.75, and the ratio for ‘Books about US politics’ is even as large as 0.96. The results indicate that as TGO produces a new partition with larger Tightness value, it is highly possible that the new partition produced also has an increased modular density D. Therefore, the positive relation between local community tightness T and modular density D can be proved.In this section, the time for evaluating local community tightness T and modular density D will be tested. The experiment is carried out by Matlab 2012a in a dual computer with its RAM 16G and dominant frequency 2.4GH.We run MA-SAT on five real-world networks, four of which are the same with that used in Section 5.3. The fifth network Netscience with 1589 nodes and 2742 edges will be described in detail in Section 5.6. We record three values, i.e., T-time, D-time, and E-time. T-time is the total time used by evaluating τc(i) in a complete run for MA-SAT. D-time is counted in this way: every time when τc(i) should be calculated, the modular density D is evaluated instead and its time consuming is recorded and added. E-time means the total time that evaluating modular density D takes in our formal version of MAT-SAT.From Fig. 13, it could be observed that as the number of vertices and edges increases, three kinds of time values will increase accordingly. T-time value is much less than D-time value, especially for the large network Netscience, for which D-time value increase to more than 200s, while T-time value is only 1s or so. Compared with E-time ranging from 10s to 100,000s, T-time is negligible which is no larger than 1s. Thus, it could be found that TGO does be able to find better partitions with little time consuming.In this section, we will compare MA-SAT, Meme-Net and GA under the same time condition. Three algorithms utilize the same fitness function, i.e., the general version of modularity density D in formula (2) with λ=0.7. The Computer configuration is same as that described in Section 5.4.2.GN Extended Benchmark Networks are used for testing with mixing parameter μ values ranging from 0 to 0.5. Three values for maximum running time are applied, i.e., 10s, 20s and 30s. 30s are enough for three kinds of algorithms to converge. Since true partitions of GN Extended Benchmark Networks are known, NMI measure is utilized for evaluating the performances.It could be observed from Fig. 14that MA-SAT can obtain better results than Meme-Net and GA under the same time condition. From Fig. 14(c), it could be found that the final results of MA-SAT are significantly better than two others. According to the experimental results in Sections 5.4.1–5.4.3, we could find that MA-SAT is able to find better partitions using the same or less time than Meme-Net and GA, and TGO does cost little time which is negligible. Therefore, for convenience, we will still utilize the number of fitness evaluations as the termination criterion when making comparisons in the following sections.All the vertices of those above benchmark networks mentioned in Section 5.2 have approximately the same degree and all communities have the same size. The new classes of benchmark networks called LFR have been proposed by Lancichinetti et al. [26], in which the distributions of node degree and community size are both power laws with tunable exponents τ1 and τ2, respectively. μ is the mixing parameter; each node shares a proportion 1−μ of its edges with other nodes of its own community and a proportion μ with other nodes in the network.In this paper, we generated 10 computer-generated networks with different value of μ from 0.05 to 0.5 with interval 0.05. Each network contains 1000 nodes and the cluster size ranges from 10 to 50. τ1=2 and τ2=3, the averaged degree for each node is 20 and the max node degree is 50. For each network, we computed the average NMI obtained by MA-SAT over 10 independent runs. In order to illustrate the effectiveness of MA-SAT, results of another two algorithms tested on the same networks reported in [6] are given for comparison. One is a greedy optimization algorithm which is proposed by Clauset, Newman and Moore [12]. This algorithm is labeled as CNM algorithm and it performs a quick maximization of modularity Q which can handle large networks. The other one is the consensus clustering combined with CNM algorithm [6] which is labeled as CC-CNM. Consensus clustering can combine the information of different partitions obtained by CNM algorithm and deliver an improved partition.Here we need to emphasize two points. The first is that we only give the results on LFR benchmark networks when λ=0.7. There are two reasons: the effects of different λ in the general version of modularity density D have been discussed in detail in Sections 5.2 and 5.3; it can be concluded from Section 5.2 that results are best when λ=0.7 for different mixing parameter μ in the GN Extended Benchmark Networks. The second is that the fitness function evaluation times of local search SA are controled in a range between 200,000 and 250,000. The reason is that the larger the scale of networks, the higher the initial temperature of local search SA, which will result in a slower annealing process and influence the speed of our algorithm. Therefore, maximal fitness function evaluation times is used for SA to avoiding too much computation being spent on SA. The comparison results are shown in Fig. 15.As we can see from Fig. 15, the results of MA-SAT is much better than those of CNM algorithm. When μ takes the value from 0.05 to 0.4, our algorithm's results are better than CC-CNM; when μ=0.45 and μ=0.50, the average NMI values obtained by MA-SAT are 0.789 and 0.750, respectively.In this section, we applied our algorithm MA-SAT 10 times independently on two real-world networks, i.e., the SFI network and the netscience network. Different from the real-world networks discussed in Section 5.3, both of the two networks’ real clusters are unknown.SFI network. This network represents 271 scientists in residence at the Santa Fe Institute during any part of calendar year 1999 or 2000, and their collaborators [4]. An edge is drawn between a pair of scientists if they coauthored one or more articles during the same time period. The biggest part of the SFI networks consist of 118 nodes and 200 edges. We only do experiments on this part.Netscience network. This network represents the co-authorship of scientists working on network theory and experiment [30]. This network consists of 1589 nodes and 2742 edges. It is weighted and we handle it as an unweighted one in our experiments.In this part, we will compare our algorithm with CNM algorithm [12], GA-net [8] and Meme-Net [16], which have been introduced in this paper. As the two real-world networks don’t have real partitions, we can not compare the performance of algorithm in terms of NMI values; instead, we calculate the modularity Q values of the best results detected by these algorithms and compare their performance from the perspective of modularity Q. The comparison are shown in Fig. 16. Since Meme-Net is very time-consuming, using hill climbing as the local search strategy, the result of Meme-Net on netscience network is not provided.For SFI network, our algorithm detected a partition when λ=0.5 and this partition owns 11 communities. The value of modularity Q is 0.740 and it is the highest as shown in Fig. 16. For netscience network, the partition detected by our algorithm when λ=0.5 has 326 communities and the corresponding Q value of this partition is 0.902. While the Q value of the partition detected by CNM algorithm is 0.950, which is greater than ours. CNM aims to maximize Q while our MA-SAT aims to maximize D. Considering these factors, it can be drawn that MA-SAT is able to deal with large networks with satisfactory results.In the previous sections, we mainly use NMI or Q value as the criterion for the quality evaluation. In this section, we will use the fraction of vertices identified correctly (FVIC) [7] and the average number of communities (ANC) [7] as the criterion to compare MA-SAT with several other algorithms. They are a multi-objective community detection (MOCD) algorithm [7], CNM algorithm [12] and a two-stage algorithm using influence coefficient where the CNM algorithm is used in the first stage (called CNM-IC) [41]. MOCD has two versions, i.e., MOCD with Max–Q model selection (called MOCD-Q) and MOCD with Max–Min Distance model selection (called MOCD-D). Among the five algorithms, MOCD-D, MOCD-Q and MA-SAT are EA-based algorithms.All algorithms are tested over the artificial networks with 128 nodes grouped in four communities of 32 nodes [4]. Each node has on average zinedges to nodes in the same community and zoutedges to nodes in other communities, and the average degree is 16.Figs. 17 and 18show the FVIC and ANC results of different algorithms versus increasing zoutover 100 graph realizations. In Fig. 17, λ of MA-SAT is 0.75, and in Fig. 18, λ of MA-SAT is 0.8.It can be observed from Figs. 17(a) and 18(a) that all of the algorithms can find the correct partitions when zoutis small. The larger the zoutis, the more difficult to find the true partition. We can see that the FVIC results of all the algorithms decrease with the increasing zout. As zoutincreases to 6 and 7, MA-SAT obtains the highest FVIC value. Both MA-SAT with λ=0.8 and MOCD-D rank first, and MA-SAT with λ=0.75 ranks secondly as zoutis 8. As zoutis 9, the multi-objective algorithm, MOCD-D and MOCD-Q perform better than others. Fig. 17(b) shows that when λ=0.75, MA-SAT can always find the correct number of community as zoutis smaller than 7. When λ=0.8, FVICs obtained by MA-SAT are better than those when λ=0.75, and the number of community found by MA-SAT tends to be larger than the true one. It means that when λ is large, MA-SAT is able to find the correct partition, but it tends to find smaller communities and partition some true community into smaller ones. This phenomenon is consistent with the definition of Dλin Section 2, and also shows the multi-resolution ability of MA-SAT.This section will provide the comparison between different algorithms using the NMI measurement on GN Extended Benchmark Networks with mixing parameter μ ranging from 0 to 0.5. The algorithms include our MA-SAT, Meme-net, GA, CNM, and CNM-IC. The first three algorithms are EAs with the maximum number of function evaluations of 100,000 that optimize modularity density D with λ=0.7, while CNM and CNM-IC are two greedy algorithms that optimize modularity Q. It could be found from Fig. 19that MA-SAT and Meme-net perform better than others. On the whole, MA-SAT could obtain the best NMI values among these algorithms.In this section, we compare MA-SAT with Meme-net, GA, CNM, and CNM-IC using the Wilcoxon signed ranks test [42,43] which is a nonparametric and pairwise test. The first step is to compute the R+ and R− [42] related to the comparisons between MA-SAT and the rest of algorithms based on 11 GN Extended Benchmark Networks with mixing parameter μ values ranging from 0 to 0.5 and 4 real-world networks including the Zachary's karate club, the Dolphin social network, the American College football, and the Books about US politics which are described in Sections 5.2 and 5.3, respectively. Once R+ and R− are obtained, their associated p-values can be computed.Table 3shows the R+, R−, and p-values computed for all the pairwise comparisons concerning MA-SAT (the p-values were computed by using the function in Matlab). As the table indicates, MA-SAT shows a significant improvement over Meme_Net, GA, CNM and CNM-IC with a level of significance α=0.05.

@&#CONCLUSIONS@&#
