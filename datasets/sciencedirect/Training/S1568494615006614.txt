@&#MAIN-TITLE@&#
Automatic network clustering via density-constrained optimization with grouping operator

@&#HIGHLIGHTS@&#
The network clustering is formulated as the density-constrained optimization and an evolutionary algorithm is provided.The proposed clustering algorithm can be free from the resolution limit problem.The performance of the algorithm does not sensitively depend on the parameter.The detection accuracy is also obviously improved by the density constraint.

@&#KEYPHRASES@&#
Automatic network clustering,Density-based technique,Community detection,Graph partitioning,Constrained optimization,

@&#ABSTRACT@&#
Automatic network clustering is an important technique for mining the meaningful communities (or clusters) of a network. Communities in a network are clusters of nodes where the intra-cluster connection density is high and the inter-cluster connection density is low. The most popular scheme of automatic network clustering aims at maximizing a criterion function known as modularity in partitioning all the nodes into clusters. But it is found that the modularity suffers from the resolution limit problem, which remains an open challenge. In this paper, the automatic network clustering is formulated as a constrained optimization problem: maximizing a criterion function with a density constraint. With this scheme, the established algorithm can be free from the resolution limit problem. Furthermore, it is found that the density constraint can improve the detection accuracy of the modularity optimization. The efficiency of the proposed scheme is verified by comparative experiments on large scale benchmark networks.

@&#INTRODUCTION@&#
The task of graph clustering is to partition the nodes of a graph into clusters such that there should be many edges within each cluster and relatively few between clusters [1–5], which is an important issue in the field of data mining and pattern recognition. A detailed review of the graph clustering can be seen in Ref. [6]. Many real-world networks exhibit community (or modular) structure, with dense connections within the communities and sparse connections between them, e.g., social networks, biochemical networks, and information networks [7–9]. Mining those communities is the key to understand the structures and functions of those networks. A network is usually described by a graph, thus the graph clustering is also known as network clustering [10,11], modularity clustering [12], or community detection [8,9,13,14]. In addition to the graph clustering, graph-based techniques are commonly used in various methods of data clustering [15–17], which are closely related to the graph clustering techniques.For a real-world network, it is common that we do not know the number of communities. Thus automatic clustering is usually needed. Automatic clustering is a process that partitions a set of data into a pre-unknown number of clusters such that the data within a cluster are more similar to each other than in different clusters [18,19]. A commonly used scheme for automatic clustering is the optimization of a carefully designed criterion function: by maximizing or minimizing the criterion function over all possible partitions, an optimal partition is obtained [20,21]. For this purpose, various criterion (measure) functions have been proposed, e.g., the Davies-Bouldin index [22], Xie-Beni index [23], Sym-index [24], fuzzy hypervolume index [25], and partition density [25]. But the obtained number of clusters is not always equal to the actual number of clusters. There are two types of mistakes. One is called over-resolution: a real cluster is divided into two or more compact clusters via optimization of the criterion function. The other is low-resolution: two or more real clusters are estimated as one cluster. To the best of our knowledge, there is not a criterion function that is free from both the two types of mistakes for all kinds of data sets.For the automatic network clustering, the most popular criterion function is the modularity (denoted as Q) presented by Newman and Girvan [26,27]. A high value of Q represents a good partition [12,26,27]. By simply optimizing Q over all possible partitions, the best solution can be found. Similar to the above mentioned criterion functions for general data sets, it is found that the modularity always suffers from the resolution limit problem (low-resolution) [13,28]. To overcome the shortcoming, several multi-resolution versions of modularity are introduced [29–31]. But recently, Lancichinetti and Fortunato show that the multi-resolution modularity functions are not suitable to detect communities in networks [32]. This is due to the fact that two opposite effects coexist in the networks: the tendency to merge small subgraphs, which dominates in low-resolution; and the tendency to split large subgraphs, which dominates in over-resolution. When the low-resolution mistake disappears by tuning the resolution, over-resolution mistake usually occurs, and vice versa. Thus the resolution limit problem remains an unsolved challenge for automatic network clustering.Density-based techniques are commonly used in data clustering [33,34]. The network clustering algorithm SCAN [11] is evolved from the traditional density-based clustering algorithm DBSCAN [35], which can detect meaningful clusters, hubs, and outliers of networks. The recently proposed graph-skeleton-based clustering (gSkeletonClu) algorithm is also a density-based network clustering algorithm, which projects a network to its core-connected maximal spanning tree [36]. The clustering problem is converted to detect core connectivity components on the tree.Using the side information of the clustering problem as constraints can improve the performance of the clustering algorithm [37]. Intuitively, communities in a network are clusters of nodes with high-density connections. To overcome the resolution limit problem, instead of maximizing only a single criterion function, the automatic network clustering (community detection problem) is formulated as a constrained optimization problem in this paper: maximizing a criterion function with a density constraint. With this scheme, the criterion functions can be free from the resolution limit. Based on this scheme, density peak algorithm (DPA) is proposed, which detects the skeletons of the communities whose intra-cluster densities are higher than a threshold (density constraint) firstly, then assigns the remaining nodes (usually overlapping nodes) into the skeletons. In fact, the skeletons are density peaks.By using the density as a constraint, the scheme of the DPA for network clustering has the following desirable features. Firstly, the DPA can choose different criterion functions in different situations. For example, choose the HHI (see in Section 2.2) for short runtime or choose the Q for high detection accuracy. Secondly, the performance of the DPA does not sensitively depend on the parameter. In a wide range of the density threshold, the DPA performs well (see in Section 5.1). Thirdly, it is found that the detection accuracy is also improved by the density constraint.The rest of this paper is arranged as follows. In Section 2, the automatic network clustering is formulated as a density-constrained optimization scheme. Section 3 analyzes why the proposed scheme can be free from the resolution limit. Section 4 describes the proposed DPA algorithm in details. Comparative simulations are given in Section 5. Section 6 concludes this paper.Suppose an N-node network has P communities, A=[aij] is the adjacency matrix, where aij=1 if there is an edge between node i and j; otherwise aij=0. Let βik=1 if node i belongs to community k; otherwise βik=0. Because every node belongs to only one community, the following constraint must be satisfied.(1)∑k=1Pβik=1,∀i∈{1,…,N}.Under constraint (1), a node cannot belong to two or more communities and the partitioned communities cannot be overlapped. Overlapping community detection is also a broad research field in network clustering.The intra-community density of community k is defined as follows.(2)Dk=∑i=1N∑j=1Naijβikβjk∑i=1Nβik∑i=1Nβik−1,∀k∈{1,…,P},where∑i=1N∑j=1Naijβikβjkis two times the number of edges in community k,∑i=1Nβikis the number of nodes in community k, and∑i=1Nβik∑i=1Nβik−1is two times the maximum number of the possible edges in community k. To avoid unexpected phenomenon in calculation, the intra-community density of a single node community is set as 1.The proposed DPA for community detection is based on the density-constrained optimization scheme, in which one can select a criterion function from the modularity (Q function) [26,27], general modularity density (Dλfunction) [31], or other functions defined in the literatures [29,30]. The HHI function in economics is used to measure industrial concentration [38,39], which is also used to partition social networks into clusters [40,41]. In the simulations of this paper, along with the modularity and the multi-resolution general modularity function, the HHI is also used as a criterion function for comparison. Here, the HHI is used to illustrate how the density constraint works with those criterion functions.The HHI is defined as the sum of squared community sizes:(3)HHI=∑k=1P∑i=1Nβik2.Maximization of the HHI tends to divide a network into a small number of large communities. Along with maximizing the HHI (or other criterion functions), we impose the following constraint:(4)Dk≥Dth,∀k∈{1,…,P},where Dthis the density threshold for the P communities.The community detection is different from a general constrained optimization problem. Usually for a general constrained optimization problem, the solution can be directly obtained from maximizing the criterion function with the constraint. Here, with constraint (4), it is not all the nodes can be divided into the communities by maximizing a criterion function in general cases, but only the skeletons of the communities can be obtained. Fig. 1shows a network of three communities denoted by circles, hexagons, and triangles, respectively. The intra-community densities can be calculated easily from (2): D1=(2×6)÷(5×4)=0.6 for the circle community, D2=(2×7)÷(5×4)=0.7 for the hexagon community, and D3=(2×3)÷(3×2)=1 for the triangle community. So if 0.6<Dth<0.7 in (4), the circle community should be splitted into two parts: {2, 3, 4, 5} and {1} to satisfy constraint (4) in maximizing the criterion function. If 0.7<Dth<0.83, the hexagon community should also be splitted into two parts: {7, 8, 9, 10} and {6}. It is clear that {2, 3, 4, 5} and {7, 8, 9, 10} can be considered as the skeleton of the circle and hexagon community respectively. As illustrated in this example, if the intra-community density of a community does not satisfy constraint (4), it can be increased by removing the node with the minimum intra-community degree (the node with the minimum number of links in the community). The skeleton of the community is the remaining part of the community obtained by repeatedly removing the node with the minimum intra-community degree until constraint (4) is satisfied.After the skeletons of the communities obtained, the community detection can be accomplished by assigning the remaining single nodes or small communities into the skeletons. Too small a value of Dthmay allocates overlapping nodes into the skeletons, which reduces the detection accuracy of the proposed DPA (please see Fig. 6); on the other hand, too large a value of Dthreduces the size of the skeletons, which is also undesirable. But in a wide range of Dth, the DPA works well (please see in Section 5.1). The recommendation is Dth=p_in, where p_in is the average intra-community density of the network if it can be estimated.The modularity Q of a partition of a network is written as [13,26,27](5)Q=∑s=1PlsL−ds2L2,where lsis the number of links inside community s, dsis the total degree of the nodes in community s, L is the total number of links in the network, and the sum is over the P communities of the partition. Both the compactness and separateness of the communities are incorporated in (5).It is well known that the modularity has the resolution limit problem [13,28,32]. The network shown in Fig. 2consists of 4 communities (cliques) with intra-community density 1, but identifies only 3 communities by maximizing the Q function: two cliques of 20 nodes and a community formed by the joining of the two 5-node cliques. K5 has 5 nodes and 10 edges, and K20 has 20 nodes and 190 edges.Let G=(V, E) be the graph of a network, where V and E are the node and edge sets of the network respectively. The adjacency matrix of the graph is A. If C1 and C2 are two disjoint subsets of V representing two different communities, denoteL(C1,C2)=∑i∈C1,j∈C2aij,L(C1,C1)=∑i∈C1,j∈C1aij,andL(C1,C1¯)=∑i∈C1,j∈C1¯aijThe modularity density in [31] is defined as(6)Dλ=∑i=1P2λL(Ci,Ci)−2(1−λ)L(Ci,Ci¯)Ci,where P is the number of communities. The resolution of Dλcan be controlled by the parameter λ, which makes the modularity density Dλa multi-resolution criterion function. The first and second items of the right side of (6) describe the compactness and separateness of the communities respectively.As analyzed in [32], multi-resolution criterion functions are not suitable for community detection due to the resolution limit problem. By tuning the resolution, over-resolution mistake usually occurs when the low-resolution mistake disappears, and vice versa [32].If the network in Fig. 2 is divided into three communities, Dλ(3)=(844λ−8(1−λ))/10 by (6); or if it is divided into four communities, Dλ(4)=(920λ−20(1−λ))/10. Thus, only when λ>3/22=0.137, one has Dλ(4)>Dλ(3), the four communities can be correctly detected. In practical applications, when finding a suitable λ to get the right partition in a part of the network, mistakes may appear in other parts.In fact, the HHI also has the resolution limit problem. For the graph shown in Fig. 2, HHI(3)=400+400+100=900 when it is divided into three communities, HHI(4)=400+400+25+25=850 when it is divided into four communities. Since HHI(4)<HHI(3), the network is also detected as three communities by maximizing the HHI.With constraint (4), all of the Q, Dλ, and HHI can be free from the resolution limit. By (2), the intra-community densities of the four cliques are 1. When the two 5-node cliques are merged into one community, its intra-community density is 42/90=0.467. When the two 20-node cliques are merged into one community, its intra-community density is 381/(20×39)=0.488. When the 20-node clique and the two 5-node cliques are merged into one community, its intra-community density is 213/(15×29)=0.489. Thus, if the intra-community density threshold is set as Dth>0.489 in (4), all communities’ intra-community density should be larger than Dth, so the merge of communities does not occur, and the real communities can be detected by maximizing any of the criterion functions. With the density constraint (4) of the proposed scheme, maximizing the criterion functions can be free from the resolution limit.Remark 1Both separateness and compactness have important role for any clustering, that is also the basis of network clustering, especially the modularity optimization based methods (including the proposed DPA). The separateness and compactness are cooperated in the definition of the criterion function, e.g., the commonly used modularity function Q and the modularity density Dλ(please see (5) and (6)). In other words, by maximizing a criterion function for community detection (the modularity Q or the general modularity density Dλ), both the effects of separateness and compactness are incorporated (in the extreme case of λ=1 (λ=0) for the modularity density, separateness (compactness) is not considered). The mechanism is: the more “compactness” in the communities, the lager value of the criterion function; the more “separateness” among the communities, the lager value of the criterion function. Many algorithms are designed based on this scheme, e.g., the Denshrink and the BGLL algorithms which are compared with the DPA in the simulations.In a standard genetic algorithm (GA), a partition of a graph is encoded as an integer string(7)X={x(1)x(2)⋯x(i)⋯x(N)}where x(i) denotes the community identification number of node i. Traditionally, after selecting a cross point randomly, a one-point crossover of two chromosomes exchanges all the elements separated by the cross point, and returns two new chromosomes. Tasgin et al. proposed a one-way crossover operator for community detection, which appoints one chromosome as the source and the other as the destination [43]. The crossover process is as follows. Pick up node i at random, determine its community identification number in the source chromosome, make sure that all the nodes (including i) in this community are assigned to the same community in the child chromosome. The remaining nodes’ community identification numbers are the same as that in the destination chromosome. The one-way crossover operator has been modified to a two-way crossover operator recently [44].As for a child chromosome generated from the crossover operators in [43,44], the community identification numbers of the nodes in one community come from a parent chromosome and that of the remaining nodes come from the other parent chromosome. Neither of the two crossover operators can generate a child chromosome that the nodes in two or more communities come from one parent chromosome and the remaining nodes (in two or more communities) come from the other parent chromosome. For example, the crossover process shown in Fig. 3cannot be implemented by those crossover operators. Thus the one-point crossover is inefficient: to reach the result in Fig. 3, two steps are needed for a one-point crossover.To improve the efficiency of the DPA, we choose the encoding and crossover operator introduced by Falkenauer in the grouping genetic algorithm (GGA) [45], which has been used for the blockmodel problem [42]. The specialized chromosome and operator can overcome the problems that typically arise when a standard GA is applied to divide a graph into clusters of nodes [45].In the GGA encoding, the chromosome contains two parts: “Maps” and “Groups”. The “Maps” part is the same as (7) in a standard GA, which maps each node to a community identification number. The “Groups” part lists all community numbers, which allows crossing over two or more communities to generate a child chromosome. For example, supposing there are 8 nodes in a network divided into four communities: C1={1}, C2={2, 4}, C3={3, 5, 7}, and C4={6, 8}, the chromosome is encoded as follows.Maps,X:12323434Groups,G:1234Here, the example shown in Fig. 3 is employed to illustrate the steps of the crossover process (see Fig. 4). The encodings of the two parents can be seen in Fig. 4(a). (a) Selection: select several communities from the “Groups” part of parent 1 randomly. A simple method is to select two cross points from the “Groups” part of parent 1, then all the communities between them are selected. In the example, the two cross points are 1 and 2, and the communities between the two points are C1 and C2 (see the “Groups” part of parent 1 in Fig. 4(a)). The nodes belonging to community C1 and C2 (of parent 1) are 1, 2, 4, 5, and 6. (b) Crossing: the community identification numbers of the nodes in the selected communities are determined by parent 1, and the community identification numbers of the remaining nodes are determined by parent 2. In Fig. 4(b), the community identification numbers of nodes 1, 2, 4, 5, and 6 of the child chromosome are underlined. The “Groups” part of the child chromosome is that of parent 2 added by the selected section of parent 1 (see Fig. 4(b)). (c) Removing empty communities. It is found that there is no node belonging to community 1, 2, 3, and 6, so remove them in the “Groups” part (see Fig. 4(c)). (d) Rearranging. Modify the “Groups” part to be normal. In the example, G=4 5 |1 2| is modified into G=1 2 3 4. Modify the “Maps” part accordingly. The final child chromosome is then obtained.Fig. 5shows the pseudo code of the DPA. The detailed process is described as follows.Step 1: InitializationRandomly generate a population of M individuals (or chromosomes). Randomly generate an integer P between [1,N] as the number of communities for each individual. Then randomly allocate the N nodes into the P communities. If the sub-network of a community for an individual does not satisfy the density constraint (4), rank the nodes by their degrees in the community. Move the node with the minimum degree out of the community and make it a new one-node community. Repeat the process until the density constraint is satisfied by all communities of the individual.Step 2: Calculate the criterion function values (choose one from the HHI, Q, Dλ, or other as the criterion function) of the chromosomes and rank them.Step 3: Selection and crossover to get M child chromosomes.Roulette wheel selection is employed to select parents [46]. Calculate the fitness f by (8) for the chromosomes of the population(8)f=2rM(M+1),where r is the inverse-rank number of the chromosome based on the criterion function value calculated in Step 2, M is the population size. The fitness value f of a chromosome calculated by (8) is the probability to be selected as a parent. The higher the criterion function value is, the greater the possibility of the chromosome to be chosen as a parent will be.The crossover operator has been described in Section 4.1.2. Two parents are selected for crossover and one offspring is generated at each time. Repeat the process until M offsprings are generated as the next generation of the population.Step 4: Repair the child chromosomeAs stated in Section 2.2, since the density constraint (4), many “communities” with only a few or even a single node are generated. These small “communities” are not real communities and should be allocated to the skeletons of the communities, which are accomplished by repairing the child chromosome. In realization of the algorithm, the communities less than Nthnodes are regarded as small communities.Step 4.1: Find the small communities. Given a threshold Nth, all the communities whose number of nodes less than Nthare treated as the small communities. In the simulations of this paper, Nthis the minimum degree of all nodes. The remaining communities are treated as the skeletons of the real communities.Step 4.2: Reassign the nodes of the small communities into the skeletons of the communities. Randomly choose a node of the small communities, find the community which has the most edges to this node. If the intra-community density after adding the node satisfies condition (4), then assign the node to the community. If condition (4) is not satisfied, then try the community with the second most connections, …, until the selected node is assigned or all the skeletons of the communities are checked. Repeat the above process for all the nodes of the small communities.Step 4.3: Reassign the remaining nodes of the small communities that are not allocated to the skeletons of the communities in Step 4.2. Randomly choose a node, allocate it to the community which has the most edges to this node. Repeat the process until all the nodes are allocated to the communities.Step 5: Repeat from Step 2 until the iteration number reaches gmax.The solution of the population which has the largest value of the criterion function (HHI, Q, Dλ, etc.) is the final solution of the community detection.In this section, extensive experiments are done on the LFR benchmark network data [47]. The abbreviation LFR comes from the initials of the authors of Ref. [47]. The LFR benchmark is proposed for testing the performance of network clustering algorithms. The heterogeneities of both the node's degree and community size are embodied in the LFR benchmark, which is an extension of the classical GN benchmark [7]. The LFR benchmark has six parameters: the number of nodes N, the average degree <k>, the maximum degree kmax, the exponent for the degree distribution γ, the exponent for the distribution of the community size β, and the mixing parameter μ. The mixing parameter μ means that each node shares a fraction 1−μ of its connections with the other nodes of its community and a fraction μ with the other nodes of the network. The higher the mixing parameter of a network, the more difficult to reveal the community structure.If the ground truth of the community structure is known, it is easy to get the similarity between the solution obtained by an algorithm and the ground truth. In the simulations, the Normalized Mutual Information (NMI) is used to evaluate the quality of an obtained solution [48,49]. The value of NMI is based on a confusion matrix M=[Mij], where the rows of M correspond to the real communities and the columns correspond to the detected communities. Specifically, Mijis the number of nodes in real community i that appears in the detected community j. LetMi.=∑j=1PdMijandM.j=∑i=1PrMij,where Prand Pdare respectively the number of real communities and the number of detected communities. Then value of NMI is calculated by [48]NMI=−2∑i=1Pr∑j=1PdMijlog(MijN/Mi.M.j)∑i=1PrMi.log(Mi./N)+∑j=1PdM.jlog(M.j/N)The value of NMI is in the range of [0,1]. NMI=1 indicates that the detection result is the same as the ground truth. The larger the NMI value is, the higher the detection accuracy will be. In all the simulations, gmax=200 and the population size M=100.In this simulation, the parameter sensitivity of the DPA on Dthis tested on 30 LFR benchmark networks with identical parameters: N=1000, <k>=15, kmax=40, (γ, β)=(2, 1), and μ=0.4. For each network, different values of Dthare used to detect the communities. The HHI is used as the criterion function of the DPA in the experiments. The simulation results are shown in Fig. 6, in which each point is the average over 30 networks. As it is shown in Fig. 6, the values of NMI obtained by the DPA are high in a wide range of Dth. When Dthin the range of [0.5, 1], all the values of NMI are larger than 0.98. In the simulations of this paper, Dth=p_in, where p_in is the average intra-community density of the LFR benchmark.Many network clustering algorithms detect the communities by maximizing a criterion function without density constraint. Obviously, the DPA can detect communities without the density constraint (4), which is equivalent to maximizing a criterion function only. The aim of this simulation is to test the effects of the density constraint: the performance of the DPA with constraint (4) and without constraint (4).Fig. 7shows the simulation results, which indicate that the detection accuracies for all the three criterion functions are improved by the density constraint. The improvement to the HHI is the most evident. Because the HHI does not consider separateness, without the density constraint (4), the HHI could not be used as a criterion function for community detection, the difference is evident even when μ=0.1. As for the general modularity density Dλ, the difference is evident when μ>0.3, 0,4, 0.5 for λ=0.3, 0.5, 0.7 respectively. The effect of the density constraint to the modularity Q is relatively small on the LFR benchmark networks (only when μ>0.5), which explains why the modularity optimization is popular in community detection. In networks with a higher mixing parameter, the communities are less evident and more difficult to be detected, especially for small communities which are easier to be merged into large communities. The introduced density threshold is helpful in detecting those communities, that is the reason why the effects of density constraint are more evident for networks with higher mixing parameters.To clearly see the differences of the DPA with different criterion functions (HHI, Q, or Dλ), the simulation results in Fig. 7 with density constraint are plotted in Fig. 8(a). Fig. 8(b) is the running time. From Fig. 8(a), it is seen that the modularity Q always obtains the largest NMI. But no matter which criterion function is used, the most difference in NMI is less than 0.07 even when μ=0.6, which indicates that the DPA is not so dependent on a specific criterion function. In running time, the HHI is shorter than others in most cases.In this simulation, the DPA is compared with two algorithms: one is the DenShrink for community detection, which is also a density-based algorithm and has excellent performance [50], and the other is the recent BGLL algorithm [51]. The first experiment is designed as follows: the networks have identical <k>=15 and kmax=40, but with different values of (γ, β). The simulation results are shown in Fig. 9. In the second experiment, the average degree of the networks is increased to <k>=20, and the simulation results are shown in Fig. 10. In the third experiment, the networks have identical values of (γ, β)=(2, 1) and kmax=60, but their average degrees <k> are different. The simulation results are shown in Fig. 11.As shown in Figs. 9–11, the DPA performs better than the other two algorithms in most cases, especially when the mixing parameter is large. The above experiments are done on a personal computer with 2.13GHZ CPU and 2G memory. The running times of the DPA (Matlab version), DenShrink (C++ version), and BGLL (C++ version) on a 5000-node LFR benchmark network are about several 1000s, several 10s, and several seconds respectively. As described in Section 4, the DPA is actually a GA, which usually consumes more running time than other heuristic algorithms. In fact, the density-constrained optimization scheme proposed in this paper for community detection can be implemented by other techniques with high speed.Besides, we test the three algorithms on the ring of 24 cliques (see Fig. 12). The BGLL only finds 12 communities, each of them consists of two cliques. The DenShrink and DPA correctly detect all the 24 cliques as 24 communities. Finally, experiments are done on 5 real world networks that have been studied in Ref [13]: yeast, Escherichia coli, electronic circuits, a social network, and Caenorhabditis Elegans. The first four networks come from Ref. [52], and the last one comes from Ref. [53]. The number of nodes and edges of the five networks are listed in Table 1. As shown in Table 1, the five networks respectively have 57, 76, 70, 21, and 15 communities, but exact detection is not easy. The results of the DPA are more approximate to the ground truth. The parameters of the DPA in detecting the five networks are respectively (Nth, Dth)=(4,0.3), (3, 0.3), (4,0.2), (2,0.6), and (5,0.3).This network is widely used as a benchmark for community detection [4]. The club was partitioned into two parts denoted by circle and square respectively, which can be detected by the DPA. Some researchers also divided the karate club network into three communities [4,54,55], which can also be detected by the DPA as shown in Fig. 13with the same parameters (Nth, Dth)=(2, 0.1).In this network, each node corresponds to a team in the United State college football [4,7]. There are 11 conferences (labeled as C1, C2, …, C11 in Fig. 14) and 5 independent teams (rhombus: 43, 37, 83, 81, and 91). Each edge corresponds to the existence of a match between the connected nodes.The college football network is hard to be exactly detected. Fig. 14 is a detection result by the DPA (with parameters (Nth, Dth)=(5, 0.5)). Node 64 has 9 edges: 2 from C8 and 2 from C6, the other 5 edges come from C2, C3, C10, C11, and an independent team (node 43). So it has almost equal probabilities to allocate node 64 into C6 (correct) and C8 (incorrect, as shown in Fig. 14). Node 64 is connected with 60. If node 64 is correctly allocated into C6, node 60 (with 8 edges) has 2 edges from C6 and equally 2 edges from C8, the remaining 4 edges come from C3, C10, C11, and an independent team (node 37). In other words, node 60 has almost equal probabilities to be allocated into C6 (correct) and C8 (incorrect, as shown in Fig. 14). If node 64 is incorrectly allocated into C8, then node 60 will have 3 edges from C8 and only one edge from C6, so node 60 will definitely allocated into C8. Node 98 has 8 edges and is connected with both nodes 60 and 64. Similarly, if both nodes 60 and 64 are incorrectly allocated into C8, then node 98 has 2 edges from C4, 2 edges from C8, 2 edges from C11, and the remaining two edges come from C10 and C6 respectively. Node 98 will has equal probabilities to be allocated into C4 (incorrect, as shown in Fig. 14), C8 (incorrect), and C11 (incorrect). If one of nodes 60 and 64 is incorrectly allocated into C8 and the other is correctly allocated into C6, similar analyses indicate that node 98 has equal probabilities to be allocated into C4 (incorrect), C6 (correct), and C11 (incorrect). If both nodes 60 and 64 are correctly allocated into C6, then 98 can be correctly allocated into C6. Node 111 has 11 edges and 8 of them coming from C10, the remaining 3 come from C3, C6, and an independent team (node 81), thus it is allocated into C10 as shown in Fig. 14.All the 11 communities are correctly detected by our DPA. Except the nodes mentioned above, the remaining nodes are detected the same as the ground truth.

@&#CONCLUSIONS@&#
The automatic network clustering (community detection) is formulated as a constrained optimization problem, where the constraint is the intra-community density. Based on this formulation the density peak algorithm (DPA) is proposed. With the density constraint, maximizing the modularity, HHI, or other criterion functions, which suffers from the resolution limit problem originally, can be free from the resolution limit. Furthermore, with the density constraint, the accuracy of the detection increases with the same criterion function. The efficiency of the proposed algorithm is verified by comparative experiments on real world and large scale LFR benchmark networks.The DPA scheme is open with keeping the density constraint. The criterion function is not constrained in the HHI, modularity, and the general modularity density. Future works include implementing the proposed constrained optimization scheme with techniques other than an evolutionary algorithm. Existing algorithms based on the modularity optimization can be further improved with the density constraint.