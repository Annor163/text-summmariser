@&#MAIN-TITLE@&#
Fast Dimension-based Partitioning and Merging clustering algorithm

@&#HIGHLIGHTS@&#
This research introduces extremely fast and scalable clustering algorithm.The proposed algorithm detects automatically clusters number.Furthermore, this algorithm uses three insensitive tuning parameters.

@&#KEYPHRASES@&#
Clustering,Subspace clustering,Density-based clustering,

@&#ABSTRACT@&#
Clustering multi-dense large scale high dimensional numeric datasets is a challenging task duo to high time complexity of most clustering algorithms. Nowadays, data collection tools produce a large amount of data. So, fast algorithms are vital requirement for clustering such data. In this paper, a fast clustering algorithm, called Dimension-based Partitioning and Merging (DPM), is proposed. In DPM, first, data is partitioned into small dense volumes during the successive processing of dataset dimensions. Then, noise is filtered out using dimensional densities of the generated partitions. Finally, merging process is invoked to construct clusters based on partition boundary data samples. DPM algorithm automatically detects the number of data clusters based on three insensitive tuning parameters which decrease the burden of its usage. Performance evaluation of the proposed algorithm using different datasets shows its fastness and accuracy compared to other clustering competitors.

@&#INTRODUCTION@&#
Clustering is the process of finding groups of similar objects based on some similarity measures. Clustering techniques are successfully applied in many applications in biology, finance and marketing domains [1,2]. Traditional clustering algorithms are not suitable for processing huge amounts of data with a large number of attributes which are collected in many industrial fields. This is reasoned by their high processing time overhead and quality limits [3].Curse of dimensionality is a well-known problem in clustering high dimensional datasets [4â€“7]. As the number of dataset dimensions increases, measuring distance between dataset objects becomes more meaningless. This is reasoned by increasing the number of dimensions causes points to spread out until they are nearly equidistant from each other which completely masks clusters. One of the problems that arises due to this curse is the probability that a cluster may only exist in some subset of data attributes. Another problem is that these subset of attributes may differ from one cluster to another [2].Clustering algorithms require tuning parameters to be set. Clustering results should be insensitive to these parameters values. If not, clustering process will be more worsen because of the increasing of the burden on the end user. Parameter is considered as insensitive if results could be obtained under a range of parameter settings. This ensures that clustering results are not changed under slight variations of these parameter values. Furthermore, the number of clustering parameters should be small as possible [3].The main contribution of this work is to introduce a fast clustering algorithm called Dimension-based Partitioning and Merging (DPM). This algorithm is used for clustering numeric, multi-dense, large scale, and high dimensional datasets along with automatic clusters number detection using three insensitive tuning parameters. The motivation of this work is that most popular clustering algorithms used for such datasets are time consuming due to the high time complexity of the used processing operations. The proposed algorithm starts with partitioning the data space into small dense partitions by visiting each dimension values only once using dimension histogram. In the next stage, noise is filtered out based on dimensional densities of the obtained partitions. At last, merging stage based on a small number of samples called boundary samples is applied to construct data clusters. Observations demonstrate that the proposed algorithm is extremely fast with the capability of detecting number of clusters compared to other clustering algorithms.The rest of this paper is organized as the following: Section 2 presents some literature review on clustering algorithms. Section 3 discusses the proposed clustering algorithm methodology. Experimental results along with a comparison with other clustering algorithms are presented in Section 4 followed by some conclusions in Section 5.

@&#CONCLUSIONS@&#
