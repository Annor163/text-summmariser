@&#MAIN-TITLE@&#
Ensemble of multiple instance classifiers for image re-ranking

@&#HIGHLIGHTS@&#
A system that constructs multi-instance bags from text-based retrieval order.Ensemble of MI-classifiers is learned using these multi-instance bags.We report image re-ranking performance on multiple datasets.Our system receives on par or better results than the state-of-the-art.

@&#KEYPHRASES@&#
Image retrieval,Image re-ranking,Multiple Instance Learning,

@&#ABSTRACT@&#
Text-based image retrieval may perform poorly due to the irrelevant and/or incomplete text surrounding the images in the web pages. In such situations, visual content of the images can be leveraged to improve the image ranking performance. In this paper, we look into this problem of image re-ranking and propose a system that automatically constructs multiple candidate “multi-instance bags (MI-bags)”, which are likely to contain relevant images. These automatically constructed bags are then utilized by ensembles of Multiple Instance Learning (MIL) classifiers and the images are re-ranked according to the final classification responses. Our method is unsupervised in the sense that, the only input to the system is the text query itself, without any user feedback or annotation. The experimental results demonstrate that constructing multiple instance bags based on the retrieval order and utilizing ensembles of MIL classifiers greatly enhance the retrieval performance, achieving on par or better results compared to the state-of-the-art.

@&#INTRODUCTION@&#
In recent years, there has been an enormous increase in the amount of data stored on the Web, where an important portion of this data is images. Retrieving relevant images according to text-based queries has therefore become an important need. However, text-based image search may perform poorly; the retrieval results are seriously affected by various factors, such as irrelevant or incomplete text surrounding the images, polysemy or synonymy of textual descriptions, and more. Since most of the current search engines (such as Google or Yahoo Image Search) make use of such surrounding textual data, the performance of image retrieval can be relatively lower than expected.In order to increase the performance of such text-based image retrieval systems, approaches on visual re-ranking have been proposed in recent years. In visual re-ranking, the idea is to explore the initial list of returned images by analyzing their visual content and to propose a new ranking in which more relevant images are ranked higher. Such methods are also referred as relevance-based re-ranking methods [1].In this paper, we propose such a re-ranking framework that analyses the visual content of the images returned by text-based search engines and improve image retrieval results, by building candidate bags that are utilized by multiple instance classifiers. Our proposed system is unsupervised, in the sense that, it does not need any explicit manual labeling of the images or any user feedback. The only input is a text query, and by evaluating the visual content retrieved by this query, our approach first automatically builds multiple classifiers and then re-ranks the images based on the outputs of these classifiers.The main idea of the proposed method is to automatically create “bags” that will be used with Multiple Instance Learning (MIL). In MIL, the classification is built upon bags as opposed to single instances. In this respect, Multiple Instance Learning is inherently suitable for retrieval problems, since in retrieval, the relevancy of the retrieved images is unknown. We claim that, by using the initial retrieval order of images, we can intelligently build candidate bags that can be used within the MIL framework. The MI-classifiers can then learn the hidden patterns that are common to those images in these candidate bags. Based on the resulting classifiers, the images can be re-ranked so that query-relevant images are ranked higher.The bag construction step is the key point of the proposed approach. We propose three different ways for building candidate bags, namely dynamic, sliding window and dynamic-sliding approaches. The constructed candidate bags are then used in building multi-instance classifiers. Our algorithm operates on multiple-sized candidate bags, and train classifiers using the visual features extracted from each of the constructed set of bags. An ensemble of MI-classifiers is then formed and the images are re-ranked based on the response of this ensemble. The proposed framework is illustrated in Fig. 1. It is important to note that our aim in this paper is not to introduce a novel ensemble learning method as in [30,31], but to show that with a simple ensemble of MI-classifiers that is only based on visual content of the retrieved images and without using any user feedback, we are able to achieve quite successful re-ranking of the images.We test our algorithm in Google [2] and Web Queries [3] datasets. The results show that by simply using multiple candidate bags and Multiple Instance Learning in conjunction, our algorithm can perform on par with or better than the state-of-the-art.The rest of the paper is organized as follows: In Section 2, we review the related literature over the subject. Section 3 introduces the proposed approach of constructing bags for multiple instance classifiers. Experimental evaluation is provided in Sections 4 and 5 we present our conclusions and discussions over the subject with possible future directions.

@&#CONCLUSIONS@&#
