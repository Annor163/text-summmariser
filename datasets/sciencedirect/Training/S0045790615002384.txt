@&#MAIN-TITLE@&#
Detecting stealthy attacks: Efficient monitoring of suspicious activities on computer networks

@&#HIGHLIGHTS@&#
A scalable monitoring scheme for stealthy attacks on computer networks is presented.Bayesian fusion along with traffic sampling is used as a data reduction method.Stealthy activities can be detected using 10–20% size sampling rates.A tracing algorithm for anonymous stealthy activities to their sources is presented.The effect of network parameters on detection is investigated.

@&#KEYPHRASES@&#
Stealthy attacks,Bayesian fusion,Network simulation,Traffic sampling,Anomaly detection,

@&#ABSTRACT@&#
Stealthy attackers move patiently through computer networks – taking days, weeks or months to accomplish their objectives in order to avoid detection. As networks scale up in size and speed, monitoring for such attack attempts is increasingly a challenge. This paper presents an efficient monitoring technique for stealthy attacks. It investigates the feasibility of proposed method under number of different test cases and examines how design of the network affects the detection. A methodological way for tracing anonymous stealthy activities to their approximate sources is also presented. The Bayesian fusion along with traffic sampling is employed as a data reduction method. The proposed method has the ability to monitor stealthy activities using 10–20% size sampling rates without degrading the quality of detection.

@&#INTRODUCTION@&#
Launching stealthy attacks is one of sophisticated techniques used by skilled attackers to avoid detection, and can take months to complete the attack life cycle. Tools and techniques to launch such attacks are widely available. In order to detect such attempts, it is necessary to maintain a long history of what is happening in the environment and sophisticated computing systems are required for analysis. Most systems cannot keep enough event data to track across extended time intervals for this purpose due to computational constraints. The performance of network can be affected by such overheads and hence to the quality of service. All these facts motivate for a data reduction which can be motivated as long as it preserves the required level of precision for monitoring objectives. This paper examines the feasibility of employing traffic sampling together with a simple, but a systematic, data fusion technique for monitoring such attempts; and if design parameters of a network affect on non-sampling error.The rest of the paper is organised as follows. Section 2 provides a brief overview of intrusion detection in computer systems, and explains why conventional methods for rapid attacks cannot be employed in stealthy activity monitoring. Section 3 presents a monitoring algorithm which identifies Bayesian approach as a method for information fusion. Sampling technique employed by the monitoring scheme is presented in Section 4. Section 5 presents a methodological way to trace anonymous stealthy activities to their approximate sources. Experimental design is presented in Section 6. Sections 7 presents experimental outcomes. Related literature is presented in Section 8. Conclusions are drawn in Section 9.Computer systems are dynamic systems having many components such as clients, servers, switches, firewall and intrusion detection systems (IDSs). At each time interval these components produce large amounts of event based data which, in principal, can be collected and used for security analysis. The signature elements of an attack is scattered spatially and temporally, and often embedded within the totality of events of the distributed systems, and motivation11. An alert of multiple login failures. 2. An execution of cmd.exe. 3. An abuse of legitimate credentials either by individuals or malware.1and source2Using various proxy methods and zombie nodes, manipulation of TCP/IP elements, using relay or random routing.2behind some events are not always certain. In addition there are number of monitoring obstacles in such an attack scenario: evidence scarcity (weak), colluded activities, large attack surfaces, variety of users and devices, high volume high speed environments, normal variations to node behaviours and anomalies keep changing over the time. Due to the above challenges most of the existing anomaly detection techniques solve a specific formulation of the problem which induces by various factors such as data types and types of anomalies of interested, and encourage unsupervised anomaly detection techniques [1]. Proposed monitoring scheme in this paper is an effort to address most of above obstacles in one solution.In signature based intrusion detection an attack scenario signature is needed to distinguish a given attack (say A) from other attacks (B and C) and from normal network activities. When a stealthy attack is progressing the critical challenge is how to correlate these events across spatial and temporal spaces to track various attack scenarios such as A, B and C. The detection accuracy relies on the accuracy of scenario signature as well as the accuracy of event correlation [2]. Maintaining state information of every packets and comparisons between current packets and previous all packets are needed in event correlation. Most systems cannot keep enough event data to track across extended time intervals to do this when a stealthy attack is progressing. As a result the scarcity of attack data within a short period of time allows a stealthy attacker to go undetected hiding her attempts in the background noise and other traffic. Hence using typical signature detection techniques for stealthy activity monitoring is a challenge. The proposed monitoring algorithm in this paper is anomaly based. An intrusion is different from the normal behaviour of the system, and hence anomaly detection techniques are applicable in intrusion detection domain [1]. Intrusive activity is always a subset of anomalous activity is the ordinary belief of this idea. However given the nature of problem domain, anomaly detection techniques need to be computationally efficient to handle large sized of inputs. Hence considering any complex method, e.g. methods like principal components analysis, for information fusion should not be encouraged.A particular emphasis of the proposed algorithm is ability to process uncertain events.3The motivation behind a network event is not always easy to judge. Some suspicious events, e.g. a major router failure could generate many ICMP unreachable messages while some computer worms (e.g. CodeRed and Nimda) generate the same in active probing process, can appear as part of an attack as well as can originate from normal network activities.3Though there are a number of techniques available for dealing with data imperfection (e.g. probability, fuzzy set, rough set and dempster shafer), probabilistic fusion is selected for this work as it has the ability to handle uncertainty of data [3]. The core of the selected method lies the Bayes estimator (Bayesian fusion) which can be applied at each time point to update the probability density of node states by fusing the new piece of data. Hence it is an incremental approach which updates normal node profiles dynamically based on changes in network traffic (events). If some aberrant changes happen in network traffic over the time, it should be reflected in profiles as well and suspicious activities can be raised based on that profiles is the basic assumption. The algorithm has two functions: profiling and analysis.The profiling is the method for evidence fusion across space and time by updating node profiles dynamically based on changes in evidence. It computes a suspicion score for each node in the system during a smaller time window w and that score is updated as time progresses to compute a node score for a larger observation window W. Note that extraordinary levels of security awareness can be attained only through selecting optimal set of relevant variables to the given task, and analysing all of them together [4]. The proposed profiling technique in this paper fuses information gathered from different sources into a single score for a minimum computational cost. It reduces data into a single value which is important to maintain information about node activities for a very long observation period W. The hypothesis for the monitoring algorithm is built as follows.LetH1andH2be two possible states of a node in a network and defineH1– the node acts as an attacker andH2– the node does not act as an attacker. ThenH1andH2are mutually exclusive and exhaustive states.P(H1)is an expression of belief, in terms of probability, that the node is in stateH1in the absence of any other knowledge. Once obtained more knowledge on the propositionH1through multiple information sources (m indicators), in the form of evidenceE={e1, e2, e3, …, em} on attack surface including the human element, the belief can be expressed in terms of conditional probabilities asp(H1/E). Using the well known Bayes’ theorem and assuming statistical independence between information sources:(1)p(H1/E)=∏j=1mp(ej/H1)·p(H1)∑i=12∏j=1mp(ej/Hi)·p(Hi)When likelihoodsp(ej/Hi)and priorp(Hi)are known, the posteriorp(H1/E)can be calculated for a given w. These posterior termsp(H1/E)can be accumulated by time to use as a metric to distinguish suspected nodes from other nodes during a W. Note that distinct types of information sources such as signature based IDSs, anomaly detection components, file integrity checkers, SNMP-based network monitoring systems can be used for this purpose. Hence the assumption on statistical independence above is reasonable. Any influence/interested technical and socio-technical indicators of changes in behaviour (e.g. changes in access patterns, differences in use of language, typing patterns, transferring large amounts of data onto or off the node, etc; if human actors are involved) can be included as input variables (i.e. elements of E) in the profiling algorithm as long as such indicators operate statistically independent. Extending proposed approach to a very large scale attack surface is easy since it is a matter of adding a new indicator (attack vector) in E. Existing domain knowledge will serve to enhance the performance of this monitoring algorithm since it takes advantage of prior knowledge about the parameters. Which is especially useful when technical data is scarce. However prior and likelihoods are the most critical parameters to this approach since Bayes’ factors are sensitive to them. Proposed monitoring algorithm would be useful in monitoring threats listed in Table 1. The potential threats and their indicators in Table 1 is not exhaustive and for illustrating purpose only.

@&#CONCLUSIONS@&#
