@&#MAIN-TITLE@&#
Hybridization strategies for continuous ant colony optimization and particle swarm optimization applied to data clustering

@&#HIGHLIGHTS@&#
This study examines hybridization strategies for the ACOR–PSO applied in data clustering.The proposed hybrid strategies are superior compared to standalone models.A hybrid strategy that preserves diversity in the pheromone-particle table will leads to obtaining superior solutions.

@&#KEYPHRASES@&#
Swarm intelligence,Data clustering,Ant colony optimization,Particle swarm optimization,Hybrid systems,

@&#ABSTRACT@&#
Ant colony optimization (ACO) and particle swarm optimization (PSO) are two popular algorithms in swarm intelligence. Recently, a continuous ACO named ACOR was developed to solve the continuous optimization problems. This study incorporated ACOR with PSO to improve the search ability, investigating four types of hybridization as follows: (1) sequence approach, (2) parallel approach, (3) sequence approach with an enlarged pheromone-particle table, and (4) global best exchange. These hybrid systems were applied to data clustering. The experimental results utilizing public UCI datasets show that the performances of the proposed hybrid systems are superior compared to those of the K-mean, standalone PSO, and standalone ACOR. Among the four strategies of hybridization, the sequence approach with the enlarged pheromone table is superior to the other approaches because the enlarged pheromone table diversifies the generation of new solutions of ACOR and PSO, which prevents traps into the local optimum.

@&#INTRODUCTION@&#
Swarm intelligence (SI) originated from the study of colonies or swarms of social organisms [1]. Among various algorithms in swarm intelligence, the ant colony algorithms (ACO) and particle swarm optimization (PSO) are two commonly used metaheuristic algorithms. In recent years, a large number of related studies have proposed methodologies and applications of the two algorithms.The ant-based algorithm, chiefly used to solve combinatorial optimization problems, was inspired by observations of the foraging behavior of real ants [2,3]. ACO-related researches in various areas are numerous [4–7]. Traditional ACO mainly tackles combinatorial optimization problems. For applying traditional ACO in continuous-valued optimization problems, the continuous variables are usually discretized into discrete variables prior to performing ACO to handle the continuous-valued optimization problems [8,9]. This approach does not generally suffice in accuracy because the length of the discretization interval affects the quality of solutions. Recently, Socha and Dorigo [10] proposed a new ant-based algorithm named ACOR to solve continuous optimization problems, which has attracted research attention [11–13].PSO is inspired by social behavior among individuals, for instance, bird flocks. Particles (individuals) representing a potential problem solution move through the search space [14]. Each particle produces a new acceleration to change the current position of the particle according to three parameters: (1) the best value of the particle itself; (2) the global best value; and (3) the acceleration of the particle. This approach, after several iterations, can find the optimal solution.Premature convergence that leads to a fall into local optimum may exist in metaheuristic algorithms including ACOR and PSO. Premature convergence may be caused by a lack of diversity in the searching process. To improve diversity in the searching process, certain studies have proposed the concept of multiple sub-swarms with different characteristics [15,16], and others have proposed hybrid systems that combine different swarm algorithms [17]. Being applied as a part of a large system, the hybridization can improve the original algorithm and obtain a superior solution quality. Generally, the performance of a single algorithm is inferior to that of the hybrid algorithm [18,19]. Hybridization in swarm intelligence is essential for performance enhancement of a swarm intelligence optimization algorithm.Hybridization of discrete ACO and PSO is popular; nevertheless, the hybridization of ACOR and PSO has not yet been investigated. This study proposes an innovative hybrid model by combining ACOR and PSO, and four types of hybridization strategies to combine the pheromone table and particle swarm. To demonstrate the computational performances, the proposed hybrid models are applied to data clustering, which is a difficult task with continuous-valued variables. Clustering divides large data objects into several clusters with a small similarity of intra-clusters and a large similarity of inter-clusters. Data clustering is applied to different business areas where large transactional and customer data are accumulated, including sales management, marketing analysis, and document management.Swarm intelligence algorithms including ant clustering and particle swarm optimization has been applied to clustering in recent years. To date, numerous studies have applied data clustering by employing ACO or PSO [20,21]. The ACOR, which is designed for continuous numerical optimization problems, is applicable in data clustering; however, the application of ACOR, or ACOR combined with PSO in data clustering, is lacking. In the proposed methodology, this study investigates several approaches for the combination of the pheromone table and the solution of the particle swarm.The remainder of this paper is organized as follows: Section 2 reviews relevant literature including the basic ACO, ACOR and PSO algorithms; Section 3 describes the ACOR–PSO hybrid systems; Section 4 presents the experimental results from the UCI dataset; and lastly, Section 5 provides conclusive remarks.Ant colony optimization (ACO) is an artificial system inspired by the behavior of real ant colonies, and is applied to solve discrete combinatorial optimization problems. The first ACO was developed to solve the classical traveling salesman problem (TSP) [22,2,23]. In the standard ACO, ants make a probabilistic choice based on the transition probability before updating the pheromones along their trail to a food source. In the TSP problem, the transition probability from City i to City j for the kth ant at the time step t is expressed as follows:(1)PROBijk(t)=[τij(t)]α⋅[ηij]β∑j∈Iik[τij(t)]α⋅[ηij]βifj∈Iik0otherwisewhere τij(t) is the amount of pheromone trail on edge (i, j) at the time t; ηijis the a priori available heuristic information; α and β are two factors that specify the relative effects of the pheromone trail and heuristic information; andIlkis the set of feasible neighborhood cities that have not yet been visited by the ant k.After each ant has completed a tour, the pheromone trails are updated by initially lowering them with a constant evaporation rate, and successively allowing each ant to deposit pheromone on the arcs that are a part of its tour, as indicated in the following equation:(2)τij=(1−ρ)⋅τij+∑k=1MΔτijkwhere M is the number of ants, and ρ is the pheromone trail evaporation rate (0<ρ<1). The parameter ρ is used to prevent unlimited accumulation of the pheromone trails and enables the algorithm to “forget” previously made bad decisions. On arcs that are not selected by the ants, the associated pheromone strength declines exponentially with the number of iterations.Δτijk,the quantity per unit of length of the trail substance that is laid on the edge (i, j) by the kth ant, is defined as follows:(3)Δτijk=QLkif antkuses edge(i,j)in its tour0otherwisewhere Lkdenotes the tour length, and Q is a predefined constant.Socha and Dorigo [10] proposed the ant algorithm called ACOR for continuous domain. Following this research, certain studies focused on applying ant colony search to solve continuous optimization problems [24–28]. In the ACOR, each row in the pheromone table represents a solution of a set of decision variables. Each solution has a value of objective function. The new ants of next generation are generated using a roulette wheel probability based on the objective function of each solution in the pheromone table. The detail algorithm of ACOR is as follows:Step 1: For each solution siin the pheromone table, calculate the value of the objective function f(si). Sort the solutions in the pheromone table according to their objective values, that is, for a minimum problem: f(s1)≤f(s2)≤…≤f(si)≤…≤f(sK), where K is number of rows (solutions) in the pheromone table.Step 2: Calculate the weight ω, so that ω1≥ω2≥…≥ωi≥…≥ωK.(4)ωi=1qK2πe−(i−1)2/2q2K2where q represents the learning rate between 0 and 1.Step 3: Compute the probability of the roulette wheel pi, according to the value of ωifor each solution.(5)pi=ωi∑j=1KωjStep 4: Repeat the following steps M times to generate M new ants (M≤K): produce a new value repeatedly for each variable of a new ant by employing the normal distributionN(μid,σid),whereμidis a value selected from the dth value (variable) of the ith solution in the pheromone table by the probability of pi, andσidis defined as follows:(6)σid=ξ∑j=1K|xjd−xid|K−1wherexidis the value of the dth variable of the ith solution, K is the size of the pheromone table, and ξ represents the evaporation rate.Step 5: Evaluate the M new ants and replace the inferior solutions in the pheromone table by the superior solutions from the M new ants.PSO is inspired by the social behavior among individuals. Recently, many PSO variants were introduced including [29–31]. Particles representing a potential solution to the optimization problem move through a search space. Each particle maintains a record of the position of its previous optimal performance called pbest. The optimal performance obtained thus far from the entire swarm is call gbest. A particle calculates its new velocity and updates its new position based on the direction of its previous optimal position and the global best position. Letpbestiddenote the previous optimal position of the dth dimension encountered by the ith particle, and gbestddenote the global best position of the dth dimension. The current velocity of the dth dimension of the ith particle at the iteration t is defined as follows:(7)vid(t)=w×vid(t)+c1×rnd×(pbestid−xid(t−1))+c2×rnd×(gbestd−xid(t−1)),(8)vid∈[−vmax,vmax]In the abovementioned formula, rnd is a random function in the range [0,1]. The positive constants c1 and c2 are the personal and social learning factors, respectively, and w is the inertia weight, which was first introduced by Shi and Eberhart [32]. Inertia weight balances the global exploration and local exploitation. The velocity is restricted to the [−vmax,vmax] range, in which vmax is a predefined boundary value. The value of vmax determines the resolution of the search regions between the present and target position. Eberhart and Shi [33] suggested that vmax should be set at approximately 10–20% of the dynamic range of the variable in each dimension. The new position of a particle is calculated with the following formula:(9)xid(t)=xid(t−1)+vid(t)Studies on hybrid systems in swarm intelligence have recently gained popularity, for instance, those on the integration of PSO with ACO [34–38], ACOR with Hooke and Jeeves local search [39], and ACOR with differentia evolution [39]. The hybrid application combining the ant colony algorithm and particle swarm algorithm is popular. To our knowledge, the hybrid system of mixing the continuous ant colony and particle swarm algorithm has not yet been implemented. This paper investigates the strategy for combining the continuous ant colony algorithm and the particle swarm optimization to improve data clustering performance.Clustering is an unsupervised data segmentation technique for grouping a set of data objects into classes of similar data objects. Certain popular clustering methods can be adopted such as partitioning methods, hierarchical methods, grid-based methods, model-based methods, and density-based methods [40]. Swarm intelligence, including ant algorithms and PSO, has been used in clustering. Ant-based clustering was first introduced by Deneubourg et al. [41] to model ants gathering items to form heaps; other studies have proposed improved versions [42–46]. Another ant-based approach in clustering involves representing a solution as a set of cluster centers, and adopting the ant algorithm to search for the optimal set of cluster centers [38,47].Several studies have applied PSO in clustering [48–53]. These literatures showed that with certain enhancements, PSO can avoid trapping into local optimum, and outperformed a few other traditional clustering algorithms.In our proposed ACOR–PSO hybridization, a solution is represented as a combination of cluster centers. Thus, the length of a solution is equal to the dimensions of a dataset multiplying the number of clusters. The objective function, which is used to evaluate the merit of clustering, is defined as(10)f=∑k=1Nc∑i=1Nsmin||Xi−Ck||2∑k,j=1;k≠jNcd(Ck,Cj)where Nc=number of centers, Ns=sample size,||Xi−Ck||2=distance between sample i to center k, d(Ck, Cj)=distance between center k and center j.The intra-cluster distance is obtained by summarizing all pairwise distances from points in the cluster to the cluster center. The inter-cluster distance between clusters is computed as the distance between the centers. Clusters must be compact, with cluster centers far from each other for good clustering, giving f a small value.All the variables are scaled before clustering. The main advantage of scaling is to avoid attributes in greater numeric ranges dominating those in smaller numeric ranges. Each variable can generally be linearly scaled to the range [0,1], as with the following formula:(11)xnew=x−min(x)max(x)−min(x)where xnewis the scaled value of the variable x, and min(x) and max(x) are the minimum and maximum values of the variable x, respectively.This study hybridizes ACOR and PSO in clustering. In the ACOR, the new ants are generated based on the pheromone table; in the PSO, the new position for each particle is produced based on the current position of the particle. The ACOR (ACOR-Module) provides new solutions at each ant cycle (iteration), where new ants are generated based on the current solutions of the pheromone table, abbreviated as “PHERO”. A pseudocode of the ACOR-Module is presented as follows:Algorithm: ACOR-ModuleDo for each ant, antm, m=1,2, …, MDo for each variablexmdin antm, d=1,2, …, D(1) Choose aμidfrom the pheromone table, PHERO (K dimensions), based on the probability piin Eq. (5), where i∈{1,2, …, K}(2) Calculateσidas follows: if rnd≤∅1, generate a standard deviationσidby Eq. (6). Else, generate a random standard deviationσidusing the uniform distribution U(0,1), where rnd is a random number (0≤rnd≤1), and ∅1 is a predefined threshold between 0 and 1 to generate a random value forσid(3) Produce a new value ofxmdas follows: if rnd≤∅2, generate a new value by the normal distributionN(μid,σid).Else, generate a random value by the uniform distribution U(0,1), where rnd is a random number (0≤rnd≤1), and ∅2 is a predefined threshold between 0 and 1 for generating a random solution forxmdEndDoEndDoReturn new ants with M rows (solutions)In the ACOR-Module, this study introduces two thresholds to improve the exploration ability: ∅1 for generating a random value of standard deviationσid, and ∅2 to generate a random value of the dth variable of the mth ant. A proper setting of the two thresholds via experiments is required.At the iteration t, PSO (PSO-Module) generates new particles based on the current positions of particles, abbreviated as PAR. The basic procedure for the PSO-Module is as follows:Algorithm: PSO-ModuleDo for each particleiin the PAR, i=1,2, …, KDo for each dimension d in particlei, d=1,2, …, DCalculate the new velocityvid(t)by Eq. (7)Update the new positionxid(t)by Eq. (9)EndDoEndDoReturn new positions of particles, PARThe ACOR-Module and PSO-Module are thus combined via four hybridization strategies according to the update strategy for the pheromone table and current position of the particle swarm. The four strategies of hybridization are proposed as follows: (1) sequence approach; (2) parallel approach; (3) sequence with double the size of the pheromone table; and (4) global best exchange. The first three strategies combine the pheromone table and PSO swarm in different manners, while the fourth strategy simply exchanges the global best solution of each algorithm.In the sequential approach, the ACOR and PSO share the same set of solutions, named the “pheromone-particle” table, abbreviated as “PHERO_PAR”, which acts as the pheromone in ACOR and the current solution information in PSO. Based on the pheromone-particle table, the PSO generates new particles and replaces the inferior solutions in the pheromone-particle table with superior solutions from the new particles. Based on the updated pheromone-particle table by the PSO, the ACOR subsequently generates new ants and replaces the inferior solutions in the pheromone-particle table with superior solutions from the new ants. The features of sequential approach are: (1) the superior solutions generated by the PSO and the ACOR can be retained in the pheromone table; and (2) PSO generates new ants and replaces the inferior solutions in the pheromone table; this may diversify the pheromone table, thus preventing the ACOR from trapping into the local optimum. Fig. 1shows the main steps of the sequential update approach, and the detailed algorithm is as follows:Algorithm: Sequential approachCreate and initialize a pheromone-particle table, PHERO_PAR, with K rows (particles) and D dimensions using uniform distributionCalculate fitness using Eq. (10) for each particles in PHERO_PAR, update pbest for each particle, and update gbest with the best fitness value of all the particlesDo until the stopping condition is trueGenerate new positions for all particles in PHERO_PAR by performing PSO-ModuleDo for each particleiin PHERO_PAR, i=1,2, …, KCalculate fitness of particleiusing Eq. (10), and update its pbest if the fitness value of particleiis better than its pbestUpdate gbest if the fitness value of particleiis better than the gbestEndDoGenerate new ants, ANT, with M rows by performing ACOR-Module based on the updated PHERO_PAR performed in the previous stepDo for each antiin the ANT, i=1,2, …, MCalculate fitness of antiusing Eq. (10)Replace the worst solution in PHERO_PAR and update its pbest, if the fitness value of antiis better than that of the worst particle in PHERO_PARUpdate gbest, if the fitness value of antiis better than the gbestEndDoEnddoReturngbest, the optimal solutionBased on the pheromone-particle table, the PSO generates new particles, and the ACOR generates new ants in parallel. The inferior solutions in the pheromone-particle are replaced by the superior solutions from both the K new particles and M new ants. The main difference between the sequential and parallel approach is the manner in which they update the pheromone-particle table. In the parallel approach, the new ants are generated directly from the pheromone-particle table, without being based on the new particles, whereas in the sequential approach, the ants are generated from the updated pheromone-particle that is renewed by the PSO. The diversity of the pheromone table may be different between the two approaches, and this may result in different new solutions. Fig. 2shows the main concept of the parallel update approach, and its detailed algorithm is as follows:Algorithm: Parallel approachCreate and initialize a pheromone-particle table, PHERO_PAR, with K rows and D dimensions using uniform distributionCalculate fitness using Eq. (10), update pbest for each particle, and update gbest with the best fitness value of all the particlesDo until the stopping condition is trueGenerate new ants, ANT, with M rows by performing ACOR-Module based on PHERO_PARGenerate new positions for particles in PHERO_PAR by performing PSO-ModuleDo for each particleiin PHERO_PAR, i=1,2, …, KCalculate fitness of particleiusing Eq. (10), and update its pbest if the fitness value of particleiis better than its pbestUpdate gbest if the fitness value of particleiis better than the gbestEndDoDo for each antiin ANT, i=1,2, …, MCalculate fitness of antiusing Eq. (10)Replace the worst solution in PHERO_PAR and update its pbest, if the fitness value of antiis better than that of the worst solution in PHERO_PARUpdate gbest, if the fitness value of antiis better than the gbestEndDoEnddoReturngbest, the optimal solutionBased on the pheromone-particle table, the PSO generates K new particles, which are successively combined with the pheromone-particle table to form an enlarged pheromone-particle table with the size of 2K. Based on the enlarged pheromone-particle table, the ACOR generates M new ants. Among the new ants and the enlarged pheromone-particle table, the best K solutions are kept to form a new pheromone-particle table. For the PSO, the pbest and gbest are obtained from the updated pheromone-particle table; for the ACOR, the new ants are generated based on the enlarged pheromone table with diversity; thus, this approach prevents trapping into a local optimum. Fig. 3shows the main concept of the sequential approach with the enlarged pheromone-particle table, and its detailed algorithm is as follows:Algorithm: Sequential approach with enlarged pheromone-particle tableCreate and initialize a pheromone-particle table, PHERO_PAR, with K rows and D dimensions using uniform distributionCalculate fitness using Eq. (10), update pbest for each particle, and update gbest with the best fitness value of all the particlesDo until the stopping condition is trueMake a copy of PHERO_PAR′ from PHERO_PAR, and generate new positions of particles in PHERO_PAR′ by performing PSO-ModuleDo for each particleiin PHERO_PAR′, i=1,2, …, KCalculate fitness of particleiusing Eq. (10), and update its pbest if the fitness value of particleiis better than its pbestUpdate gbest if the fitness value of particleiis better than the gbestEndDoCombine PHERO_PAR′ and PHERO_PAR to form an enlarged pheromone table with 2×K rows, named as PHERO_PAR″Generate new ants, ANT, with M rows by performing ACOR-Module based on the PHERO_PAR″Do for each antiin the ANT, i=1,2, …, MCalculate fitness of antiusing Eq. (10)Replace the worst solution in PHERO_PAR′ and update its pbest, if the fitness value of antiis better than that of the worst solution in PHERO_PAR′Update gbest, if the fitness value of antiis better than the gbestEndDoReplace PHERO_PAR by PHERO_PAR′EnddoReturngbest, the optimal solutionThis strategy simply shares only the best solution instead of the entire pheromone/particle table with each other, as shown in Fig. 4. The PSO generates new particles based on its own particle table, and the ACOR generates new ants based on its own pheromone table. The two models exchange their best solution. This approach maintains the original features of the PSO and ACOR respectively. The algorithm of the global best exchange approach is detailed as follows:Algorithm: Global best exchangeCreate and initialize a particle table, PAR, with K rows and D dimensions using uniform distributionCalculate fitness for each particle in PAR using Eq. (10), and update pbest for each particleUpdate gbest with the best fitness value in PARCreate and initialize a pheromone table, PHERO, with K rows and D dimensions using uniform distributionCalculate fitness for each ant in PHERO using Eq. (10)Update bestOfAnt with the best fitness value in PHERO. (Let the global best fitness of the ants is represented as bestOfAnt)Update globalOpt with the best value of gbest and bestOfAnt. (Let the global optimal solution of ACOR and PSO is represented as globalOpt)Do until the stopping condition is trueGenerate new positions of PAR by performing PSO-ModuleDo for each particleiin PAR, i=1,2, …, KCalculate fitness of particleiusing Eq. (10), and update its pbest if the fitness value of particleiis better than the pbest in the previous iterationUpdate gbest if the fitness value of particleiis better than the gbestEndDoGenerate new ants, ANT, with M rows by performing ACOR-Module based on the PHERODo for each antiin the ANT, i=1,2, …, MCalculate fitness of antiusing Eq. (10)Replace the worst solution in PHERO, if the fitness value of anti is better than that of the worst solution in PHEROUpdate bestOfAnt, if the fitness value of antiis better than the bestOfAntEndDoExchange global best as follows: replace the worst particle in the PAR with the bestOfAnt, and replace the worst ant in PHERO with the gbestUpdate globalOpt with the best value from the gbest and bestOfAntEnddoReturnglobalOpt, the optimal solutionThe time complexity of the aforementioned four hybridizations of the ACOR–PSO models are proportional to the number of iterations, the number of particles, and the number of ants, and can be computed according to their main steps, as follows:(12)NIterations×(NNewAnts×TAnt+NNewParticles×TParticle+TUpdate)where NIterations: number of iterations, NNewAnts: number of new ants, NNewParticles: number of new particles, TAnt: runtime for generating a new ant, TParticle: runtime for generating a new particle, TUpdate: runtime for relevant processes including updating the pheromone table, updating the position of a new particle, and other necessary processing times.

@&#CONCLUSIONS@&#
