@&#MAIN-TITLE@&#
Differential Evolution algorithms applied to Neural Network training suffer from stagnation

@&#HIGHLIGHTS@&#
Differential Evolution algorithms applied to ANN training suffer from stagnation.The lack of difference vectors of small magnitude is noted during ANN training by Differential Evolution methods.In case of benchmark problems the lack of difference vectors of small magnitude is only occasionally observed.DEGL algorithm outperforms other Differential Evolution variants for ANN training.Best algorithms found for benchmark problems do not perform well for ANN training.

@&#KEYPHRASES@&#
Differential Evolution,Artificial Neural Networks,Stagnation,Global and Local optimization,Benchmark problems,Algorithm population size,

@&#ABSTRACT@&#
Large number of population-based Differential Evolution algorithms has been proposed in the literature. Their good performance is often reported for benchmark problems. However, when applied to Neural Networks training for regression, these methods usually perform poorer than classical Levenberg–Marquardt algorithm. The major aim of the present paper is to clarify, why? In this research, in which Neural Networks are used for a real-world regression problem, it is empirically shown that various Differential Evolution algorithms are falling into stagnation during Neural Network training. It means that after some time the individuals stop improving, or improve very occasionally, although the population diversity remains high. Similar behavior of Differential Evolution algorithms is observed for some, but not the majority of, benchmark problems. In the paper the impact of Differential Evolution population size, the initialization range and bounds on Neural Networks performance is also discussed.Among tested algorithms only the Differential Evolution with Global and Local neighborhood-based mutation operators performs better than the Levenberg–Marquardt algorithm for Neural Networks training. This version of Differential Evolution also shows the symptoms of stagnation, but much weaker than the other tested variants. To enhance exploitation in the final stage of Neural Networks training, it is proposed to merge the Differential Evolution with Global and Local neighborhood-based mutation operators algorithm with the Trigonometric mutation operator. This method does not rule out the stagnation problem, but slightly improves the performance of trained Neural Networks.

@&#INTRODUCTION@&#
During the recent decade Differential Evolution (DE) [54,60,61], one of the population-based Evolutionary Computation methods, becomes a very popular tool for solving continuous optimization problems. There are probably two reasons of such popularity. Firstly, the good performance of DE for solving benchmark, engineering and real-world problems is widely acclaimed in the literature [15,34,39,50,54]. Secondly, comparing with many other recently developed heuristics, the basic DE is very simple and hence it is easily understood, encoded and implemented even by non-specialists.However, despite the frequent claims of successful applications, the basic DE is not free from drawbacks. It suffers from the limited number of available steps, and hence the possibility of falling into stagnation. The choice of DE control parameters, that is required from the user, is a difficult task that may significantly affect the final performance. The basic DE algorithm is also blamed for slow or premature convergence [15,65]. For fifteen years overcoming the drawbacks of the basic DE method has motivated researchers to propose various improved DE versions. Today a large family of DE algorithms exists; their overview may be found in Refs. [15,42,54]. In Ref. [15] nine DE algorithms developed for single-objective unconstrained continuous optimization problems are granted an “important variant” status, but this is just a tip of the iceberg. Although since the publication of “No Free Lunch Theorems” [69] it has been widely accepted that no single “best” global optimization method can be developed, most novel DE algorithms are empirically shown to outperform the basic DE on many benchmark and real-world problems. However, due to the profusion of methods the choice of proper DE variant for the particular problem is a difficult task.DE algorithms have been applied to a number of scientific problems [7,16,35,58,74], including Artificial Neural Networks (ANN) training [3,6,17,18,20,23,30,46,49]. Although ANN training aims at a bit different goal than classical optimization, as the ANN parameter values that are searched for should allow good generalization capabilities of the model, various metaheuristics have been widely used for such task for many years, as may be found in historical reviews published by Whitley et al. [67] and Yao [72] in 1990 and 1999. In Ref. [29] ANN training was even used together with benchmark problems to validate a good performance of a novel optimization algorithm. The metaheuristics, including DE methods, are usually claimed to be needed for ANN training due to two reasons: the gradient-based algorithms may stick in a local optimum, and some objective functions are not-differentiable. Although DE methods are frequently used for ANN training, the question arises if they are really efficient and successful.In Ref. [30] it was shown that the basic DE method [60] is not suitable for training the Multi-Layer Perceptron ANN (MLP), probably the most popular type of ANN, due to slow convergence and inability of finding “good” optima. However, comparing with gradient-based algorithms, much slower convergence during ANN training is frequently observed when various kinds of Evolutionary Algorithms are used. This is a cost of exploration capabilities. Hence, for example, for ANN training by means of Evolution Strategies Mandischer [40] allowed much larger number of function calls than in cases when gradient-based algorithms were used. However, the slow convergence was not the only disadvantage of the basic DE. Its poor performance and inability to find reasonable ANN parameters were also claimed in Refs. [3,23,46].Some suggestions how to improve DE performance on ANN training have been given in the literature. For example Fan and Lampinen [23] proposed a novel Trigonometric mutation operator to be used within the basic DE framework. Authors of Ref. [17] claimed that the more advanced self-adaptive DE variant proposed in Ref. [8] outperforms the basic DE version [60] on ANN training. Somehow contrary, in Ref. [44] it was found that self-adaptive DE variants do not perform better than the basic DE with control parameters tuned by means of off-line meta-optimization. In Ref. [3] hybridization of self-adaptive DE [8] with conjugant-gradient algorithm was proposed; the hybrid algorithm outperformed the basic DE, but its superiority over simple multiple-restart conjugant gradient was disputable. It must be noted that the large disadvantage of similar memetic approaches is that they cannot be used when objective function is not-differentiable, what is the main reason of searching for proper metaheuristics for ANN training. Authors of Ref. [20] proposed distributed DE algorithm for Pi-Sigma Higher-Order ANN training and found that its performance is only comparable with the back-propagation algorithm. In Ref. [46] six DE algorithms, namely: basic DE [60], Distributed DE with Explorative–Exploitative Population Families [65], Self-Adaptive DE (SADE) [55], DE with Global and Local neighborhood-based mutation operators (DEGL) [13], Grouping DE [45] and JADE [76] were compared with two Particle Swarm Optimization versions and the gradient-based Levenberg–Marquardt method (LM) [27,53] on MLP training for regression problem. The performance of all tested heuristics, with the exception of DEGL, turned out poorer than the performance of LM algorithm, a classic method for ANN training [27,75].There is no doubt that since the publication of Ref. [30] significant improvement of DE methods has been achieved [15] and the novel algorithms outperform the basic DE version on various benchmark and real-world optimization problems. Unfortunately, from the literature survey presented above one may note that when applied to ANN training, where the purpose is to find the model parameters which allow good generalization capabilities, the new DE variants do outperform the basic DE, but not necessarily the gradient-based algorithms.The major goal of the present paper is to clarify why the performance of popular DE algorithms is frequently disappointing when such methods are used to ANN training. This requires some insight into the behavior of a few popular and relatively new DE variants. Such DE variants are applied to ANN training for regression problem, namely daily river runoff forecasting based on large set of hydro-meteorological data, and to optimization of selected popular benchmark functions with the same dimensionality and maximum number of function calls. During algorithms’ run the lowest, median and the largest Euclidean distances between the individuals in the decision space (such distances represent the available magnitudes of difference vectors that may be used by DE mutation operators) and the maximum, minimum and median fitness of all individuals in the current population are monitored. The importance of both features may be explained as follows.DE algorithms are population-based. The population is composed of individuals, which create children in other positions in the decision space (the Euclidean distance between the position of a parent and a child may be termed a step size). The behavior of DE population has been explained in Refs. [24,65], where it has been noted that DE is an atypical Evolutionary Algorithm – most Evolutionary Algorithms require maintaining high population diversity during the whole search process, but for the proper functioning of DE the diversity loss is required. The common feature of DE algorithms is that during the generation the step sizes depend primarily on the difference vectorsxi−xk, where xi, xk∈RDare two individuals from the current population (or points in the decision space) andrepresents the Euclidean norm. Although the scaling factors and crossover values also affect the step sizes, the distances between individuals are of major importance. When individuals are initially randomly generated in the decision space, distances between them are large, and the probability of finding some individuals close to each other is very low (at least in case of multi-dimensional space, see Ref. [59]). At this stage large exploratory steps prevail. As DE algorithms follow greedy selection (only the better of the parent-offspring pair survives to the next generation), when algorithm proceeds the individuals that survive are located in “better” parts of the decision space. In case of most benchmark problems this results in clustering of individuals. The distances between individuals within a cluster become small, but difference vectors of large magnitude are still easily obtained when the chosen individuals belong to different clusters, hence both large explorative and small exploitative steps are possible at that stage. As the time proceeds, the individuals are expected to concentrate around a few clusters and the exploitation steps become more frequent. Finally, if all individuals find their way to a single cluster located close to the most luring optimum, the possible magnitudes of difference vectors (i.e. distances between individuals) diminish and only exploitation is performed.The question arises, what if the population remains scattered in the decision space and the distances between individuals remain large during the whole run. This may happen if fitness landscape is very “rough” and each individual finds its own “niche”. The latter stages described above are not achieved and DE algorithms waist time on exploratory steps. Due to greedy selection all individuals in the current population are better than all its parents and offspring produced by such parents in the past, hence after long time the probability of successful large exploratory steps becomes very small, at least when local optima are not distributed regularly. The regular distribution of local optima is frequent in many benchmark problems, but when real-world data are considered, the regular distribution of local minima is rather uncommon. Montgomery [41] showed empirically that, at least in case of the basic DE, during later part of the run almost exclusively small exploitation steps are successful. Hence, the undesired effect of the lack of difference vectors of small magnitude may be the stagnation of DE algorithms [15,32,65], in other words the situation when the population stops proceeding toward the optimum, although the population diversity remains high. Even if some individuals occasionally generate better children that enter the population, both the average fitness of the population and the fitness of the best found solution do not improve noticeably. In the present paper it is empirically shown that many popular DE variants applied to ANN training may indeed fall into stagnation. Somehow by the way the significance of DE population size, initialization range and bounds of ANN weights is discussed.The basic DE algorithm [60,61] was proposed for single-objective unconstrained optimization problems. Without the loss of generality, the present paper aims at minimization problems. DE evolves a population of NP individualsxi,g={xi,g1,…,xi,gD},i=1,NPduring consecutive generations g to find the global optimum of the function f within the subset∏j=1D[Lj,Uj]in the decision space RD. Initial position of individuals is randomly generated from the uniform distribution:(1)xi,0j=Lj+randij(0,1)⋅(Uj−Lj);j=1,…,D;i=1,…,NPwhererandij(0,1)generates a random value within [0,1] interval for each element of every individual.In the subsequent generations each individual (xi,g), considered as a parent, generates an offspring (ui,g) in two steps: firstly a donor vector (vi,g) is created by means of mutation, then the crossover between the donor and the parent vectors produces an offspring. A greedy selection between a parent and an offspring is performed and only the better one is promoted to the next generation.In the basic DE [61] the so called DE/rand/1 mutation scheme with a scaling parameter F was proposed(2)vi,g=xr1,g+F⋅(xr2,g−xr3,g)Later a number of other mutation strategies have been developed, including(3)DE/best/1vi,g=xbest,g+F⋅(xr1,g−xr2,g)(4)DE/current-to-best/1vi,g=xi,g+F⋅(xbest,g−xi,g)+F⋅(xr1,g−xr2,g)(5)DE/rand-to-best/2vi,g=xi,g+F⋅(xbest,g−xi,g)+F⋅(xr1,g−xr2,g)+F⋅(xr3,g−xr4,g)where r1, r2, r3 and r4 are randomly selected integers from the range [1,NP], such that r1≠r2≠r3≠r4≠i, xbest,grepresents the best individual in the current population at generation g. A number of other mutation operators have been proposed in the literature, see Refs. [15,19,54,77].In the basic DE and most novel DE variants, after mutation a binomial crossover between the target and the parent vectors is performed to produce an offspring (ui,g), what requires specification of the value of CR control parameter:(6)ui,gj=vi,gjif randij(0,1)≤CRorj=jrand,ixi,gjotherwiseSelected CR value should be within [0,1] interval. In Eq. (6)jrand,iis a randomly selected integer from [1,D] range, used to guarantee that an offspring inherits al least one element from a donor vector. In the literature also different crossover schemes have been suggested, but are rarely used in practice–for the detailed discussion on crossover see Refs. [54,73]. Some mutation strategies have also been proposed to generate offspring directly, without crossover, for example DE/current-to-rand/1(7)ui,g=xi,g+K⋅(xr1,g−xi,g)+F⋅(xr2,g−xr3,g)in which K is another control parameter, usually randomly generated within [0,1] for each individual.If ui,gis located outside the decision space, one of constraint handling methods must be applied [38]. Simple rebounding approach is adopted in the present paper:(8)ui,gj=2⋅Lj−ui,gjifui,gj<Lj2⋅Uj−ui,gjifui,gj>Ujthat is repeated while the offspring is outside bounds. Finally, in the basic DE and almost all other DE variants the greedy selection between the offspring and the parent is performed:(9)xi,g+1=ui,giff(ui,g)≤f(xi,g)xi,gotherwiseThe algorithm usually continues the search until the maximum number of iterations is reached.Since the publication of the basic DE algorithm, to overcome some of its drawbacks a large number of improved DE variants have been proposed. For example, basic DE method has three user-dependent control parameters: scale factor (F), crossover (CR), and population size (NP). Their proper selection for particular problem is difficult and time consuming [54]. Unfortunately, apart from CR, which must be selected within [0,1] interval, there is no agreement even on their acceptable range [15,54,65]. For example some researchers accept negative or higher than 1 values of F, but others limit F within [0,1], or [0.4,0.9] range. In some papers NP lower than D is suggested [65], in the others NP about 10D is proposed [13,60]. Another important problem is the choice of a proper mutation strategy, especially since it was observed that at various stages of the run different mutation strategies and control parameter values may be beneficial. To cope with that problems a large number of adaptive and self-adaptive DE algorithms has been proposed [8,39,55,76].Another idea how to improve the basic DE is borrowed from the concept of distributed computing, leading to a number of Distributed DE algorithms [45,65,66]. Also a number of algorithms improving the basic DE method by utilizing the ideas of clustering [9,36], opposition numbers [56] and Global and Local neighborhoods [13] were proposed. The last algorithm (DEGL) aims at modification of the so-called DE/current-to-best/1 mutation strategy (Eq. (4)), which suffers from premature convergence, by using two different mutation models to balance the exploration and exploitation capabilities. The Global mutation model allows for the quick spread of information among individuals. In the Local mutation model the ring topology is introduced and for each individual only information from its closest neighborhood is available. This slows down the convergence and improves exploration capabilities of the greedy DE/current-to-best/1 strategy. DEGL is considered as one of the “important DE variants” [15] and was shown to perform well in a number of applications [14,64], including ANN training [46].The concept of Memetic Computing [31] was recently introduced to DE methods and a number of Memetic DE variants have been developed [10,33,35]. Also the idea of hybridization of DE with other global search Evolutionary Computing or Swarm Intelligence methods, like Particle Swarm Optimization [22], Ant Colony Optimization [11], Biogeography-based Optimization [26,37] or Tabu Search [51] becomes popular. The more detailed survey of DE algorithms may be found in Refs. [15,42,54].As large number of DE algorithms have been proposed so far and application of most of them to the selected task is technically impossible, some selection is needed. In this paper to study the behavior of DE methods during ANN training the attention is focused on a few mutually different DE variants. At first, three of the “important DE variants” [15] are selected, namely:1.DEGL with self-adaptive weight factor [13], that performed well for ANN training in Ref. [46];SADE [55], which is probably the most popular adaptive DE;JADE [76], which proposes a novel mutation strategy and introduces an idea of external archive.Then some more recent approaches are chosen:self-adaptive DE, conceptually much different to SADE (SspDE [43]);a variant of distributed DE (DE-SG [47,48]);an approach that introduces proximity-based mutation into DEGL concept (it was called Pro-DEGL1 in Ref. [21], it is named DEGL-Epitr in the present paper).DE using Trigonometric mutation [23] is also termed “important DE variant” in Ref. [15]. Trigonometric mutation is considered as a local search heuristic that may improve the algorithm speed by enhancing exploitation. Because in the previous studies the good performance of DEGL method for ANN training was confirmed, in the present paper, instead of basic DE method,DEGL is merged with the concept of Trigonometric mutation operator (called Trig-DEGL). The suggested in Ref. [23] 5% probability of using Trigonometric mutation by each individual in every iteration is kept unchanged. For individuals which follow Trigonometric mutation the Global and Local models are not applied and weight factors are not self-adapted;DEGL-Epitr algorithm with Trigonometric mutation operator is also tested (called Trig-DEGL-Epitr). It is applied in a similar fashion as Trig-DEGL.The memetic or hybrid DE algorithms are not considered in this study due to their different features and behavior that depend on the method with which they are hybridized. In addition, for ANN training the LM algorithm is also applied as a classical reference method.Multi-Layer Perceptron is probably the most popular type of Neural Networks. It consists of nodes grouped into input, hidden and output layers. Single hidden layer is considered enough to approximate continuous functions, but there is no widely accepted rule regarding the number of hidden nodes [28,75]. MLP Neural Network is defined as:(10)yP=v0+∑j=1Jvjfwj0+∑k=1Kwjkzkwhere ypis a predicted value of the output variable, zk, k=1,…K represent input variables, w and v are MLP weights (parameters to be optimized), J is the number of hidden units and f is the so-called activation function. In the present paper popular logistic activation function is used:(11)f(a)=11+e−aAs the objective function the widely applied Mean Square Error (MSE) is used(12)MSE(w,v)=minw,v1N∑n=1N(ynP(w,v)−yn)2where y is the measured value of the output variable and N is the number of observations. In the case of MLP it is frequent [75] to linearly normalize the input and the output variables to [0,1] interval, what is also done in the present paper.ANNs are considered to be non-parametric regression models, for which bias/variance dilemma emerges [25]. The main problem with their application is overfitting to the training data, in other words fitting the ANN parameters to both signal and noise, which is usually present in the training sample, especially if real-world measurements are used. To be used in practice for unseen data one needs the robust ANN model, with good generalization properties. Although plenty of approaches to robust optimization may be found [5], a number of methods have been proposed specifically to avoid ANN overfitting to the data [28], from which probably the most popular early stopping approach is chosen in this study. The impact of this choice on the results should be limited, as in Ref. [2] it is suggested that if the number of available training data is over 30 times higher than the number of parameters, like in the present paper, the importance of the method to avoid overfitting is marginal. The early stopping approach is used here following the so-called Generalization Loss (GL) class proposed by Prechlet [52] for the gradient-based algorithms. The data set is divided into three parts: training (TR), validation (V) and independent testing (TE).When classical gradient-based methods are used to train ANN, the derivatives of objective function and the algorithm step size are estimated based on the training data only. If the error for training data diminishes, but the error for validation data increases, it is considered a sign of overfitting. Training terminates after the pre-defined number of function calls or when validation error exceeds its previously noted minimum value by GL%, set in the present paper to 20%. After termination, the best solution is chosen according to the performance for validation data. Such approach is used for LM method.In case of DE there are two major differences which may require a bit different approach to early stopping. Firstly, DE algorithms are global optimizers and, contrary to gradient-based methods, have strong exploration capabilities, hence should not terminate before the maximum number of function calls is reached. Secondly, no derivatives are computed to determine the search direction and the role of training and validation data sets is restricted to selection. The question arises how to make selection between parent and offspring based on training and validation data in order to avoid overfitting. There are many possibilities, of course, and two are checked in this paper (note that although DE methods perform the search until maximum number of function calls is reached, the name early stopping (ES) is retained):ES-1. The selection between ith parent and its offspring is performed as follows:(13)xi,g+1=ui,giff(ui,g,TR)≤f(xi,g,TR)andf(ui,g,V)≤f(xi,g,V)xi,gotherwiseThe offspring (ui,g) is considered better only if its objective function is not higher than the parents’ one according to both the training and the validation data, compared separately. The best individual in the current population (Pg) at generation g (xbest,g) is determined according to the objective function value computed for the training data only:(14)xbest,g∈Pgandf(xbest,g,TR)≤f(xi,g,TR),∀xi,g∈PgThe xbest,gcannot be eliminated from the current population. This approach is different from classical early stopping used in case of gradient-based algorithms. The necessity of fulfilling both criteria together (Eq. (13)) may limit the number of successful offspring and affect the convergence of DE algorithms.ES-2. The optimization process depends exclusively on training data, but the best found so-far solution is determined according to validation data, like in case of the classical early stopping method used for gradient-based algorithms. The selection between the ith parent and the offspring is performed as follows:(15)xi,g+1=ui,giff(ui,g,TR)≤f(xi,g,TR)xi,gotherwiseThe information about the best individual in the current population at generation g (xbest,g) may be used by the algorithm in many mutation operators (see for example Eqs. (3)–(5)). Hence xbest,gmust be determined according to objective function computed for the training data only, following Eq. (14). However, in ES-2 variant xbest,gmay differ from the best individual found so-far by the algorithm during all past generations gp, selected according to the validation data (xBSF,g):(16)xBSF,g∈⋃gp=1gPgpandf(xBSF,g,V)≤f(xhi,g,V),∀xhi,g∈⋃gp=1gPgpThe xhi,gare all historical individuals. Note that xBSF,gmay not belong to the current population Pg, as it could loose to its offspring according to training data (see Eq. (15)). Hence, in case of ES-2 variant the xBSF,gmust be remembered independently from the current population Pgand may have no impact on the future search (like in the case of gradient-based algorithms). This is important for all DE algorithms, but especially those which apply mutation strategies that use the information about the best individual in the current population, like DEGL, SADE or SspDE. Note that the best individual in the current population (xbest,g) may drive such algorithms away from the solution represented by the best individual found so-far (xBSF,g), for which the final performance of the model is evaluated when algorithm terminates.The algorithm initialization and search bounds are another problematic issue. The bounds of ANN parameters are rarely set [4,70], in some works ANN is rather penalized for too large values of weights [28]. However, ANN weights are frequently initialized within a small limited range around 0 [44,63,75]. Somehow contrary, the majority of benchmark problems frequently used to evaluate the performance of Evolutionary Algorithms are bounded [62,71] and DE methods are usually initialized randomly within the feasible decision space. To verify the significance of the initialization range and the bounds during MLP training by means of DE methods, three variants are considered in this study:1.I-1. weights are initialized anywhere within the bounds, which are set very wide [−1000,1000];I-2. weights are initialized anywhere within the bounds, which are set narrow [−10,10];I-3. weights are initialized within [−1,1] interval, but the bounds are set very wide [−1000,1000].In the present study MLP is applied to the real-world regression problem, namely one lead-day runoff forecasting based on 30-year long (1980–2009) hydro-meteorological data from Annapolis River basin, Nova Scotia, Canada. It is an extension of Ref. [46] study, which was based on 10-years long data only, concentrated on hydrological issues and did not try to explain the performance of DE methods used for ANN training. In the present paper the data are divided into training (1980–1989), validation (1990–1999) and independent testing (2000–2009) sets. The choice of MLP architecture, including input variables, number of nodes in the hidden layer and number of hidden layers is a difficult task, frequently done by trial and error [28,75]. In the present paper the choice of MLP architecture is based on the analysis of importance of particular input variables and the number of hidden nodes presented in Ref. [46]. The one lead-day forecasting of runoff ypat Wilmot settlement, Nova Scotia, Canada, is calculated based on seven inputs (z): runoff from two last days, as well as maximum and minimum daily temperatures, total rainfall, total snowfall and thickness of snow cover, measured at the last day. In Ref. [46] the sufficient number of hidden nodes was estimated to five and the same MLP architecture, with D=46 parameters, is used in the present paper.

@&#CONCLUSIONS@&#
The behavior of eight DE variants tested on a few benchmark functions and applied to train MLPs with 46 parameters for a real-world regression problem has been studied in the paper. The major conclusions may be summarized as follows.1.The proper balance between the exploration and the exploitation capabilities of DE algorithms is required for their successful application. Individuals should be able to perform large explorative steps in the decision space in the early part of the search, and small exploitative steps at the final stages. The available step sizes depend mainly on the magnitude of difference vectors. In the paper the Euclidean distances between individuals during algorithms’ run are monitored. It is shown that during search, irrespective of DE variant, the distances between individuals decrease to almost zero (individuals converge to almost a point in the decision space) for some benchmark problems, like rotated Ackley and Griewank functions. In the case of DEGL algorithm such behavior is also observed for rotated Rosenbrock and Whitley functions. If DEGL is merged with the concept of Trigonometric mutation operator, what is proposed in this paper, the decrease of the distances between individuals is observed also for rotated Schweffel and Eggholder functions. However, irrespective of DE variant used, individuals remain scattered in the decision space and difference vectors of small magnitude are rarely available when solving RANA function and MLP training problem. During MLP training all DE variants fall into stagnation, because at the final stages of the run: (a) even the lowest distances between individuals in the decision space are clearly larger then a zero, (b) the individuals in the population do not improve their fitness, or do so very, very rarely, (c) the fitness of various individuals in the population usually differ, hence most of them should be improving but is unable to do so, (d) in most runs the best obtained solution is much poorer than the best known one. The reason of very slow, or lack of, improvement during the later stages of the run is probably the scarcity of difference vectors of small magnitude and hence poor exploitation capabilities. The significance of exploitation capabilities in MLP training is supported by the widely known good performance of Levenberg–Marquardt algorithm that lacks exploration capabilities.The best performance for MLP training was obtained by means of DEGL algorithm merged with Trigonometric mutation operator, proposed in this paper. However, this DE variant does not show very good performance for most benchmark optimization problems, with exception of rotated Eggholder and uni-modal Rosenbrock functions. This, together with the observed differences in the behavior of DE methods applied to different problems, suggests that the choice of DE variant for MLP training should not be based on the performance achieved for the popular optimization benchmark functions.The performance of DE algorithms used for MLP training significantly depends on the initialization range and the bounds. If input and output variables are standardized to [−1,1], the MLP parameters should be initialized within a similarly small range, but the bounds should be much wider.The choice of the population size of DE algorithms used to MLP training is very important. The tested self-adapting and distributed methods require small population size, similar to the dimensionality of the problem, what is rarely the case for benchmark optimization functions. For some self-adaptive or distributed DE variants small population size may mitigate the problem of stagnation. However, DEGL algorithm and its variants perform better when the larger population size is used; the best results were obtained when the population size was five times larger than the dimensionality of the problem.The present work has been restricted to analysis of DE behavior when solving single-objective optimization problems. However, as multi-objective DE algorithms have also been proposed and some of them were applied to ANN training [1,12], the detailed study of their behavior seems to be of high importance and is suggested for future research.