@&#MAIN-TITLE@&#
Integrating tracking with fine object segmentation

@&#HIGHLIGHTS@&#
A novel method for joint tracking and fine object segmentation in videosEfficient integration of EM-based tracking and Random Walker-based image segmentationNo strong constraints are imposed on the target appearance or the camera motion.Experimental evaluation against a large collection of state-of-the-art methodsExplicit and efficient fine object segmentation facilitates drift-free tracking.

@&#KEYPHRASES@&#
Kernel-based object tracking,Video-based object segmentation,Tracking by segmentation,Bayesian Inference,Data fusion,Expectation Maximization,Random Walker,

@&#ABSTRACT@&#
We present a novel method for on-line, joint object tracking and segmentation in a monocular video captured by a possibly moving camera. Our goal is to integrate tracking and fine segmentation of a single, previously unseen, potentially non-rigid object of unconstrained appearance, given its segmentation in the first frame of an image sequence as the only prior information. To this end, we tightly couple an existing kernel-based object tracking method with Random Walker-based image segmentation. Bayesian inference mediates between tracking and segmentation, enabling effective data fusion of pixel-wise spatial and color visual cues. The fine segmentation of an object at a certain frame provides tracking with reliable initialization for the next frame, closing the loop between the two building blocks of the proposed framework. The effectiveness of the proposed methodology is evaluated experimentally by comparing it to a large collection of state of the art tracking and video-based object segmentation methods on the basis of a data set consisting of several challenging image sequences for which ground truth data is available.

@&#INTRODUCTION@&#
Visual object tracking and segmentation constitute two fundamental, challenging computer vision problems. Methodologies that aspire to solve these problems, provide the foundations for addressing a number of other interesting problems and applications such as object recognition, 3D tracking, 3D reconstruction, augmented reality, HCI, etc. Object-based tracking and segmentation are highly interrelated problems. An accurate solution to the segmentation problem provides reliable observations to tracking. At the same time, tracking provides input that can guide segmentation, enhancing its performance. Thus, a method that integrates tracking and segmentation is intuitively appealing. Such a method could benefit from the tight coupling of these problems, address their individual challenges and provide reliable and robust solutions to both.Our approach constitutes an online methodology for integrated tracking and fine segmentation of a previously unseen object in monocular videos captured by a possibly moving camera. No strong constraints are imposed on the appearance and the texture of the target object or the rigidity of its shape. The above may vary dynamically over time under challenging illumination conditions and background appearance.The main goal of our work is to preclude tracking failures by enhancing its target localization performance through fine object segmentation that is appropriately integrated with tracking in a closed-loop algorithmic scheme. A kernel-based tracking algorithm [60], a natural extension of the popular mean-shift tracker [15,14], is efficiently combined with Random Walker-based image segmentation [25,26] in a closed loop algorithmic scheme. Explicit segmentation of the target region of interest in an image sequence enables effective and reliable tracking and reduces drifting by exploiting static image cues and temporal coherence.Two algorithms are presented, both based on the proposed integrated tracking and fine object segmentation framework. A preliminary version of the first one, noted as TFOS, has already been reported in [36]. In the current paper the description of TFOS is more detailed. Additionally, we present several novel enhancements of TFOS that give rise to a new variant noted as TFOS+ that is comparatively evaluated with TFOS and other tracking and segmentation methods.Further than that, we perform (a) an extensive quantitative and qualitative assessment of their performance and a discussion of the additional benefits of them over existing methods, (b) a study on how the defined parameters affect their performance, (c) a comparison with a variety of existing, state of the art tracking and video segmentation methods and (d) an analysis of the proposed methodology and comparison with the two concepts regarding the usage of a different segmentation process other than Random Walks-based method and the usage of no segmentation part in order to assess the additional benefits it introduces and was previously unobtainable by other methods. Experimental results demonstrate that TFOS+ outperforms TFOS. Additionally, both variants outperform most of the existing compared algorithms in most of the employed test sequences, both in not loosing track of the target but also in accurately segmenting it from the scene background.In summary, the study of both TFOS and TFOS+ reveals that the key benefits of the proposed framework are (i) the enhanced object tracking and segmentation performance under challenging shape/color variations, (ii) the capability to track an object from a moving camera (iii) the automatic building and continuous refinement of both the object and the background appearance models based on Random Walks and its effective coupling with robust tracking, (iv) the adaptability of the defined parameters and algorithms based on partial tracking and segmentation performance, (v) its ability to recover from partial failures of segmentation and drifts of tracking based on the closed-loop interplay between them and (vi) the modular workflow of the proposed framework that also eases its extendability by incorporating additional image cues and developing additional mechanisms to track multiple objects.The rest of this paper is organized as follows. Section 2 provides an overview of relevant research efforts. TFOS and TFOS+ are presented in Section 3. An extensive experimental evaluation of the proposed methodology has been carried out. The goal was to evaluate TFOS and TFOS+ quantitatively and qualitatively and to compare their performance to state of the art tracking and video-based object segmentation methods. A large collection of image sequences has been compiled, representing challenging tracking scenarios involving non-rigid and deformable objects, strong illumination changes, moving cameras and background clutter. The qualitative and quantitative experimental results are reported in Section 4. Finally, Section 5 summarizes the main conclusions of this work and suggests directions for future research.

@&#CONCLUSIONS@&#
