@&#MAIN-TITLE@&#
Classification of DNA microarrays using artificial neural networks and ABC algorithm

@&#HIGHLIGHTS@&#
ABC algorithm discovered the best set of genes to classify correctly cancer samples.With less than 1% of information is possible to classify with an accuracy of 93.2%.Multilayer perceptron performs better than radial basis function network.

@&#KEYPHRASES@&#
DNA microarrays,Artificial neural networks,Pattern recognition,Cancer classification,Artificial Bee Colony algorithm,

@&#ABSTRACT@&#
DNA microarray is an efficient new technology that allows to analyze, at the same time, the expression level of millions of genes. The gene expression level indicates the synthesis of different messenger ribonucleic acid (mRNA) molecule in a cell. Using this gene expression level, it is possible to diagnose diseases, identify tumors, select the best treatment to resist illness, detect mutations among other processes. In order to achieve that purpose, several computational techniques such as pattern classification approaches can be applied. The classification problem consists in identifying different classes or groups associated with a particular disease (e.g., various types of cancer, in terms of the gene expression level). However, the enormous quantity of genes and the few samples available, make difficult the processes of learning and recognition of any classification technique. Artificial neural networks (ANN) are computational models in artificial intelligence used for classifying, predicting and approximating functions. Among the most popular ones, we could mention the multilayer perceptron (MLP), the radial basis function neural network (RBF) and support vector machine (SVM). The aim of this research is to propose a methodology for classifying DNA microarray. The proposed method performs a feature selection process based on a swarm intelligence algorithm to find a subset of genes that best describe a disease. After that, different ANN are trained using the subset of genes. Finally, four different datasets were used to validate the accuracy of the proposal and test the relevance of genes to correctly classify the samples of the disease.

@&#INTRODUCTION@&#
DNA microarray is an essential technique in molecular biology that allows, at the same time, to know the expression level of millions of genes. The DNA microarray consists in immobilizing a known deoxyribonucleic acid (DNA) molecule layout in a glass container and then this information with other genetic information are hybridized. This process is the base to identify, classify or predict diseases such as different kind of cancer [1–4].The process to obtain a DNA microarray is based on the combination of a healthy DNA reference with a testing DNA. Using fluorophores and a laser it is possible to generate a color spot matrix and obtain quantitative values that represent the expression level of each gene [5]. This expression level is like a signature useful to diagnose different diseases. Furthermore, it can be used to identify genes that modify their genetic expression when a medical treatment is applied, identify tumors and genes that make regulation genetic networks, detect mutations among other applications [6].Computational techniques combined with DNA microarrays can generate efficient results. The classification of DNA microarrays can be divided into three stages: gene finding, class discovery, and class prediction [7,8]. The DNA microarray samples have millions of genes and selecting the best genes set in such a way that get a trustworthy classification is a difficult task. Nonetheless, the evolutionary and bio-inspired algorithms, such as genetic algorithm (GA) [9], particle swarm optimization (PSO) [10], bacterial foraging algorithm (BFA) [11] and fish school search (FSS) [12], are excellent options to solve this problem. However, the performance of these algorithms depends of the fitness function, the parameters of the algorithm, the search space complexity, convergence, etc. In general, the performance of these algorithms is very similar among them, but depends of adjusting carefully their parameters. Based on that, the criterion that we used to select the algorithm for finding the set of most relevant genes was in term of the number of parameters of each algorithm. In that sense, the ABC algorithm was chosen because it has fewer parameters to adjust compared with other evolutionary algorithms. Moreover, literature reports that the ABC algorithm presents faster convergence than other techniques. According to [13], results to solve multi-modal and multi-variate problems are better or similar to other evolutionary algorithms. Additionally, ABC presents a higher population diversity avoiding premature convergence. However, other bio-inspired techniques, such as differential evolution, particle swarm optimization, etc., will be evaluated and compared in future works.Artificial neural networks (ANN) are excellent computational models that have been implemented to solve different kind of problems. The pattern classification, forecasting and regression problems are areas where the ANN have demonstrated to be an efficient technique [14]. ANN have been widely applied in DNA microarrays. For example, in [15], the authors used a multilayer perceptron (MLP) with back-propagation learning and a dimensional reduction method based on k-means and principal component analysis (PCA) techniques. In [16], the authors described an application based on ANN aimed to cancer studies. In [17], the authors diagnosed disease categories using small round blue cell tumors (SRBCT) by means of reducing the dimensionality data using PCA and training ANN models with no hidden layers. In other works, like [18], the authors selected a set of genes using a filter and k-means technique to train a support vector machine (SVM) and a multilayer perceptron (MLP). In [19], the author used mutual information techniques for selecting the most relevant genes before performing the classification task. In [20], an ANN with a sample filtering algorithm is designed for separating the wrongly labeled samples from the training set, and used to construct one more ANN just for the wrong samples classified. In [21], the authors described the singular value decomposition (SVD) technique for training a single layer feed-forward neural network. The authors in [22] performed a selection of genes based on k-means and PCA; finally, an ANN was training during a recursive feature elimination to classify BRCA1 and BRCA2 mutations and childhood SRBCT. In [23], the authors performed a feature selection in DNA microarrays using an ensambling learning technique. Also, they used an algorithm that converts a multiclass problem into multiple binary classes to reduce the complexity of the problem. In [24], the authors analyzed a generalized radial basis function (GRBF), where the coefficients of the neural network were tuned by a hybrid evolutionary algorithm. In [25], the authors used a neurofuzzy model (NFM) for identify distinct prognostic genes with a carcinogenic pathways.On the other hand, bioinspired and evolutionary algorithms have been widely applied to select the set of genes that best describe a disease. For example, in [26], the authors used the ant colony optimization algorithm (ACO) for selecting the most representative genes from a DNA microarray. A nonparallel plane proximal classifier (NPPC) is described in [27], where the authors used genetic algorithms for selecting genes for a cancer diagnosis and the results are compared against a support vector machine (SVM). In [28], the authors described a genetic bee colony algorithm in order to select the most predictive and informative genes for cancer classification. In [29], the authors presented an improved genetic algorithm that selects the gene subset from the high dimensional gene data for breast cancer diagnosis. In [30], the authors proposed a novel feature selection approach for the classification of high dimensional cancer microarray data, which uses filtering technique such as signal-to-noise ratio (SNR) score and optimization techniques as particle swarm optimization (PSO).In this research, we introduce a new approach for classifying DNA microarray data based on artificial neural networks and dimensional reduction technique, previously described in [31]. The proposed methodology uses the Artificial Bee Colony (ABC) algorithm as an optimization technique for selecting the set of genes, from a DNA microarray, that best described a particular disease. After that, this information is used to train three types of ANN (multilayer perceptron (MLP), radial basis function (RBF) and support vector machines (SVM)) for classifying the DNA microarrays associated to a disease. In order to test the accuracy of the proposed methodology, four different datasets were used.It is important to remark that other strategies, applied to DNA microarrays classification, implement the ANN in the fitness function and at the same time perform a dimensional reduction, provoking that the individual evaluation be more expensive in time and computational resources. The main contribution of this paper is firstly reduced the number of genes by means of the ABC algorithm. The proposed fitness function was computed in terms of the classification error using an Euclidean distance. Then, the reduced genes set is used to train an ANN in order to classify the DNA microarray data.The rest of this paper is organized as follows: Section 2 presents an introduction to DNA microarrays. A brief explanation of ABC algorithm is presented in Section 3. Section 4 presents the basic concepts related to artificial neural networks. In addition, the propose methodology is outlined in Section 5 followed by the experimental results in Section 6. Finally, conclusions of this research are given in Section 7.The human genome sequencing was completed in 2001 [32,33]. This discovery impacted the world because has allowed better diagnostics, to know the genes that participate in an illness for doing a better treatment and even more, to know about the human evolution and other advantages in sciences like biomedics, genetics, biology and so forth. In [34], the authors described the use of DNA microarray technologies, presented an overview of their frequent biomedical applications and described the steps of a typical laboratory procedure to obtain information with this powerful technique.DNA microarray is a container that immobilize DNA molecule, complementary DNA or oligonucleotides for hybridizing with DNA molecule marked to be analyzed. The container is made of glass, nylon or silicone. There are two types of DNA microarrays: the ergonomic and the transcriptomics. The first one is divided into two kinds: that can detect lost or profit genes, and that can detect mutations. The second one measures the mRNA levels [35]. DNA microarray allows to use the genome sequencing information to measure quantitatively the expression level of millions of genes at the same time. This expression level is like a signature useful to diagnose diseases, identify tumors, select the best treatment to resist illness and detect mutations.To obtain the expression level of a DNA microarray sample is necessary to compare the healthy DNA reference, called “data control”, against a testing DNA (the sample to be studied), see Fig. 1[34]. First, the messenger ribonucleic acid (mRNA) of both tissues is isolated. Then, it is necessary to obtain the corresponding complementary DNA (cDNA). Additionally, these molecules should be marked with a different fluorophore: Cy3 for the experimental sample (red color) and Cy5 for the control sample (green color). Furthermore, the marked molecules are mixed for the hybridizing process that consists of the union of the cDNA of each sample [36]. The result is a matrix with many colored spots. The red color indicates that a particular gene (spot) is more expressed in the diseased sample. The green color means that a particular gene is more expressed in the healthy sample. The yellows spots indicate that the gene is equally expressed in healthy and diseased samples.DNA microarray is an efficient technology that presents many advantages. It allows the analysis of thousand of genes at the same time, decreasing the spend time to its study. Also it increases the speed to detect illness, selecting the best treatment for each patient. On the other hand, it also allows to know the iterations between genes under certain conditions that can derivative in amazing discoveries in biology, medicine, informatics and so on. The disadvantage with this kind of data is the enormous quantity of information to be analyzed, patterns with millions of genes. Furthermore, only few samples of different disease are available. In this sense, the application of computational techniques could give valuable information about various tasks related to DNA microarrays, mainly in the selection of the set of genes that best describes a disease, classification of DNA microarrays, etc.An excellent optimization technique is Artificial Bee Colony (ABC) algorithm based on the metaphor of the bees foraging behavior [37]. It is composed of a population of NB beesxi∈ℝn,i=1,…,NBrepresented by the position of the food sources (possible solutions). Three classes of bees are used to achieve the convergence near to the optimal solution i.e. the best set of genes.Employed bees: They search for new neighbor food source near of their hive. After that, they compare the food source against the old one using Eq. (1). Then, a greedy selection is done.(1)vij=xij+ϕij(xij−xkj)in which k∈{1, 2, …, NB} and j∈{1, 2, …, n} are randomly chosen indexes and k≠i.ϕijis a random number between [−a, a].After that, the bee evaluates the quality of each solution based on the fitness function.Onlooker bees: The onlooker bee probabilistically chooses a food source depending on the amount of nectar shown by each employed bee, see Eq. (2).(2)pi=fiti∑k=1NBfitkin which fitiis the fitness value of the solution i and NB is the number of food sources that are equal to the number of employed bees.Scout bees: This kind of bees randomly create new solutions when a food source or solution cannot be improved anymore during a period called “limit” or “abandonment criteria”, see Eq. (3).(3)xij=xminj+rand(0,1)(xmaxj−xminj)The pseudo-code of the ABC algorithm is shown in Algorithm 1.Algorithm 1Pseudo-code ABC algorithm.1:Initialize the population of solutionsxi∀i, i=1, …, NB.2:Evaluate the populationxi∀i, i=1, …, NB.3:forcycle=1 to maximum cycle numberMCNdo4:Produce and evaluate new solutionsvifrom the employed bees by usingvij=xij+ϕij(xij−xkj).5:Apply the greedy selection process.6:Calculate the probability valuespifor the solutionsxiby usingpi=fiti∑k=1NBfitk.7:Produce and evaluate the new solutionsvifor the onlookers from the solutionsxiselected depending onpi.8:Apply the greedy selection process.9:Replace the abandoned solutions with a new one randomly producedxiby scout bees usingxij=xminj+rand(0,1)(xmaxj−xminj).10:Memorize the best solution achieved so far.11:cycle=cycle+112:end forAn artificial neural network (ANN) is a mathematical and computational model that simulates the communication among neurons in the human brain for classifying, forecasting, regression, optimization among some applications. This system performs a mapping between an input and output pattern that represents a real problem [38]. It is composed of a set of neurons (represented by functions) connected to others organized in different layers where each layer is composed of NLneurons. The problem to be solved is represented by input patternsx∈ℝNLwhich are sent through the layers. The information is mapped by means of the corresponding synaptic weightsw∈ℝNL. Notice that NLalso represents the number of synaptic weights that arrives to the neuron in each layer. The neurons in the following layers perform an integration of this information depending on whether there exists a connection between them. In addition, another input called bias is considered. This bias is a threshold that represents the minimum level that a neuron needs for activating and is represented by θ. A typical integration function is presented in Eq. (4).(4)o(w,x,θ)=∑j=1NLxjwj+θThen, the result of the summation is evaluated in a transfer functions F(o) activated by the input neuron. The result is the output neuron, and this information is sent to the other connected neurons until they reach the last layer, see Fig. 2.For the case of a multilayer perceptron (MLP), the output of the NN is obtained by Eq (5).(5)yi=Fi(oi(wi,x,θ))in which the transfer functions F could be represented by sigmoid, Gaussian, piecewise linear, sine, hyperbolic tangent, etc.For the case of the radial basis function (RBF), the output of the ANN is obtained by Eq. (6).(6)yi=oi(wi,ϕ(x),θ))in which ϕ(x) is defined as Eq. (7):(7)ϕ(x)=exp−x−μ2σ2in which μ determines the center of basis function ϕ and σ the standard deviation.For the case of support vector machine (SVM), the typical integration function is presented in Eq. (8).(8)o(w,x,θ)=∑q=1mKx,xqwq+θin which xqis a support vector and m the number of support vectors. Finally, the output of the SVM is obtained by Eq (9).(9)yi=Fi(oi(wi,K(x,xq),θ))in which Fiis defined as the sing function and K(x, xq) is the transformation kernel such as linear (Eq. (10)), quadratic or polynomial (Eq. (11)).(10)K(xp,xq)=xpT·xq(11)K(xp,xq)=(xp·xq+1)din which d is the polynomial degree.The synaptic weight adaptation consists in changing its value until it reaches the desired behavior. The output is evaluated to measure the efficiency of the ANN in terms of the mean square error (MSE) given by Eq. (12). If the output is not the desired, the weights set has to be changed or adjusted in terms of the input patternsx∈ℝN(supervised learning).(12)e=1p·M∑ξ=1p∑i=1M(diξ−yiξ)2Given the training sample Tξ, as defined in Eq. (13), the requirement is to compute the neural network free parameters so that the actual output yξof the neural network due to xξis close enough to dξfor all ξ in a statistical sense [33].(13)Tξ={(xξ∈ℝN,dξ∈ℝM)}∀ξ=1,…,pin which x is the input pattern, d the desired response, M is the size of desired pattern and p is the number of patterns.For the learning task, it is essential to divide the input data into two parts: training and generalization sets. Next, these sets are used in the two stages: training (learning) and testing (generalization). Training consists of adjusting the synaptic weights using the training and validation data. Moreover, the validation set helps to avoid the over-fitting problem in ANN. When the best synaptic weight values of an ANN are found, and the learning phase achieves an acceptable accuracy, the generalization phase is carried out using the testing set. The ANN processes this set and the generalization error is computed. This stage is the most important because the results reflect the ANN capacity to solve a problem.There are several algorithms that adjust the synaptic weights (learning task) to obtain the minimum error. One of the most popular technique is the classical Backpropagation (BP) algorithm [39,40], widely applied for training multilayer perceptrons (MLP) and radial basis function (RBF). This algorithm, like others, is based on the descendant gradient technique.In this section, we introduce a new methodology for solving DNA microarray classification problems. The proposed methodology was divided into two main stages, see Fig. 3. The first one is devoted to the selection of the most relevant features, the choice of the genes that best describes a disease. Due to the number of samples (or patterns), much lower than the number of genes (characteristics), it is necessary to perform a dimensionality reduction. For the dimensionality reduction of each DNA microarray, instead of using the conventional method as PCA, we decided to use an artificial bee colony algorithm as described in [41].It is important to remember that one of the major problems with DNA microarrays is that the number of samples from the dataset is much lower than the number of genes (or features of each sample) and this balance plays a relevant role to classify successfully DNA microarrays. After selecting the set of genes, the number of samples is greater than the number of genes.Once the best set of genes is obtained, during the second stage, we trained an artificial neural network, adjusting its synaptic weights until the learning process achieves the best classification rate, using the set of genes selected in the first phase.The problem to be solved can be defined as follows: Giving a set of p input patterns X={x1, …, xp},xi∈ℝn,i=1…,pand its corresponding set of desired classes associated to each pattern d={d1, …, dp}, where di∈{1, …, K} and K is the number of classes, find a subset of genes G∈{0, 1}nsuch that a function defined by min(F(X|G, d)) is minimized.The problem solution is represented by a subset of genes and is defined by an arrayI∈ℝn. Each individual Iq, q=1, …, NB is binarized using Eq. (14) with a threshold level th. This threshold select the best set of genes defined as Gk=Tth(Ik), k=1, …, n; when the component is set to 1, indicates that this gene will be selected to make up the subset of genes. In other words, th determines the probability that a gene can be selected.(14)Tth(x)=0,x<th1,x≥thTo evaluate the solutions found by the ABC algorithm and determine which is the best solution, it is necessary to define a fitness function. This function is described in the next section.The aptitude of an individual is represented by the classification error function (CER), defined in Eq. (15). This fitness function measures how many samples have been wrongly predicted.(15)F(X|G,d)=∑i=1pargmink=1K(D(xi|G,ck|G))−ditngin which tng is the total number of gene expressions to be classified, D is a distance measure, K is the number of classes and c is the center of each category. Different distance measures could be applied to classify the gene expression samples, for example, classic Euclidean distance given by Eq. (16).(16)D(r,s)=∑j=1n|rj−sj|22in whichr∈ℝnands∈ℝn.Once selected the set of features that best describes the disease, the next step is to train an artificial neural network. In this stage, any artificial neural network can be used. However, we decided to use a multilayer perceptron (MLP), a radial basis function neural network (RBF) and a support vector machine (SVM).These three types of ANN were chosen because they are the most applied to solve different problems. In addition, there are some differences among them, which could be interesting to know. Some differences are that the RBF has a training stage faster than MLP using only one layer with a neurons number increasing while a MLP works with a more that one layer with multiple neurons. In addition, the learning process that is crucial in the performance of an ANN is different between a MLP and RBF because one links the inputs and outputs with hyperplanes by means of a distributed learning, and the other uses hyperspheres by means of a local learning [42]. On the other hand, SVM belongs to a family of generalized linear classifiers and can be interpreted as an extension of the perceptron where simultaneously minimize the classification error and maximize the geometric margin. For these reasons, we decided to include in this paper the results using these types of ANN.The inputs of these artificial neural networks are feed with the genes previously selected using the ABC algorithm. Before starting to train the ANN, the dataset with the best features was partitioned into two datasets: training and testing subsets. After that, the ANN is trained with a defined number of epochs until a goal error is reached.Once trained the ANN, we proceed to evaluate its generalization capabilities using the testing subset. To measure the accuracy of the ANN, we computed the classification performance by means of Eq. (17).(17)CP=npbctpcin which npbc represents the number of patterns well classified and tpc is the total of tested patterns.

@&#CONCLUSIONS@&#
The extensive experimentation allowed us to determine the behavior of the proposed methodology in the classification of DNA microarrays. In the first stage of this proposal, the dimensionality reduction was applied in order to select the set of genes that best describe a particular disease. We posted the problem of dimensional reduction as an optimization problem, due to the dimensional reduction of a DNA microarray could be seen as a combinatorial problem trying to find from millions of genes the most relevant. The results obtained with the proposed methodology suggested that the ABC algorithm is a competitive candidate for reducing the dimensionality of a microarray. The results obtained used less than the one percentage of the genes for performing a detection or classification task. Furthermore, solutions using only one gene were found. On the other hand, we also observed that the threshold value for selecting the best set of genes directly impacted on the accuracy of the proposal.Once discover the best set of genes, we evaluated the accuracy of a simple distance classifier. The results obtained showed that all dataset were solved with a good precision. Nonetheless, in the second stage, we tried to improve the results using an ANN.During the second stage, we evaluated the capabilities of the ANN for correctly classified the different diseases. These ANN were trained using the set of genes discovered by the proposed methodology during the first stage. We also compared the accuracy achieved with three different ANN: the MLP, SVM and the RBF neural networks. Through several experiments, we observed that ANN obtained better results compared to those reached with the distance classifier. Furthermore, the ANN was trained with two different set of genes, the best set of genes and the solution with the less quantity of genes. The results showed that the best accuracy was achieved when the ANN was trained with the best set of genes. Nonetheless, the solution with the less quantity of genes also provide better results than the distance classifier.On the other hand, the experimental results showed that MLP and SVM achieved a better performance than the results obtained with the RBF. In this sense, it is necessary to perform a broad analysis of the parameters, and the topology used to train and design the ANN. Finally, we concluded that the proposed methodology is capable of selecting the correct set of genes to detect, predict and classify a particular disease with an acceptable accuracy.Nowadays, we are evaluating a new fitness function to improve the accuracy of the proposed methodology and reduce, at the same time, the number of genes used to train the ANN. In addition, we are preparing a deep analysis of the parameters used to train the ANN.