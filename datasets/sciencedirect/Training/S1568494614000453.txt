@&#MAIN-TITLE@&#
A support vector machine model for intelligent selection of data representations

@&#HIGHLIGHTS@&#
We focus on the problem of dynamically selecting the most suitable representation for an abstract data type according to the software system's execution context.A support vector machine is proposed for selection of abstract data types implementations during the execution of a software system.The considered computational experiments confirm a good performance of the proposed model and show that using machine learning techniques for the data selection problem is worth being further investigated.

@&#KEYPHRASES@&#
Machine learning,Support vector machine,Abstract data type,Data structure,

@&#ABSTRACT@&#
The design and implementation of efficient abstract data types are important issues for software developers. Selecting and creating the appropriate data structure for implementing an abstract data type is not a trivial problem for a software developer, as it is hard to anticipate all the usage scenarios of the deployed application. Moreover, it is not clear how to select a good implementation for an abstract data type when access patterns to it are highly variant, or even unpredictable. The problem of automatic data structure selection is a complex one because each particular data structure is usually more efficient for some operations and less efficient for others, that is why a static analysis for choosing the best representation can be inappropriate, as the performed operations cannot be statically predicted. Therefore, we propose a predictive model in which the software system learns to choose the appropriate data representation, at runtime, based on the effective data usage pattern. This paper describes a novel approach in using a support vector machine model in order to dynamically select the most suitable representation for an aggregate according to the software system's execution context. Computational experiments confirm a good performance of the proposed model and indicates the potential of our proposal. The advantages of our approach in comparison with similar existing approaches are also emphasized.

@&#INTRODUCTION@&#
Computational intelligence techniques are currently widely used in practical applications such as robotics, image identification and data mining. Data mining is becoming an increasingly important tool for transforming data into knowledge [1]. Since the real data are often imprecise, their distributions and the hidden relations are unknown and very complex, there is a great need for tools that can cope with the lack of information, complexity, and imprecision. Among such methods, the computational intelligence techniques [2] are effective tools for data analysis. The use of soft computing techniques (such as fuzzy systems [3] and fuzzy logic [4], neural networks [5–7] and machine learning [2], cognitive and hybrid intelligent systems, genetic algorithms [8], etc.) in solving data analysis tasks yield to the so called intelligent data analysis field. It attempts to study and model complex phenomena for which conventional methods do not provide complete solutions.Applying data mining [1] methods in software engineering is becoming increasingly important as mining techniques can support several aspects of the software development life-cycle, such as software maintenance, software evolution and software quality. Among the computational intelligence techniques machine learning is extensively used as a data mining tool to discover useful knowledge in data. Through learning, a real system may improve its performance from experiences and it might become able to adapt itself to its dynamic environment.The study of data structures and the algorithms that manipulate them is among the most fundamental topics in computer science [9]. Computer systems spend most of their time with storing, accessing, and manipulating data in one form or another. There are numerous examples from all areas of computer science where a relatively simple application of good data structure techniques resulted in massive savings in computation time and, hence, money. Software applications use abstract data types (ADTs) [10] to model real world entities from the application domain. An ADT can be implemented using different data structures.The problem of selecting and creating the appropriate data structure for implementing an abstract data type arises from practical needs and it has a major importance for software developers. The improper use of data structures in software applications leads to performance degradation and improper memory consumption. These problems can be avoided by properly selecting data structures for implementing ADTs, according to the nature of the manipulated data. This data structure selection problem is not a trivial problem for a software developer, as it is hard to anticipate all the usage scenarios of the deployed application. It is not clear how to select a good implementation for an abstract data type when access patterns to it are highly variant, or even unpredictable. Due to this fact, the software system should choose the appropriate data representation, at runtime, based on the effective data usage pattern. The dynamic selection can be achieved using machine learning techniques [11], which can assure complex and adaptive systems development.This paper approaches the problem of dynamically selecting of the most suitable representation for an abstract data type according to the software system's execution context. Most of the previous approaches rely on compile-time analyses or programmer annotations. These approaches can be inaccurate since they try to predict a program's behavior before it is executed.This paper takes a different view of the data representation selection problem, and presents a machine learning approach to solve the problem. A support vector machine classification model is proposed for the selection of abstract data types implementations during the execution of a software system, in order to increase the system's efficiency. Computational experiments confirm a good performance of the proposed model. To our knowledge, excepting our previous approach from [12], the problem considered in this paper has not been approached using machine learning techniques, yet.The rest of the paper is structured as follows. Section 2 gives a motivation for our work, emphasizing the relevance of the approached problem. The overview of the related work in the direction of automatic selection of data representations is presented in Section 3 and Section 4 presents the fundamentals of support vector machine (SVM) models. Our approach for dynamically identifying the most suitable data structure for implementing an ADT is introduced in Section 5. Section 6 provides an evaluation of the proposed SVM model on two case studies. A comparison of our approach with other similar existing approaches is given in Section 7. An analysis of our approach is given in Section 8 and Section 9 contains some conclusions of the paper and future development of our work.The primary justification for a data structure selection approach is that finding good representations has proven to be difficult. This is mainly due to a lack of awareness of the importance of properly choosing the data structures, which has a major impact on software systems’ performance.Each software system uses abstract data types [10] to model real world entities from the application domain. The most commonly used abstract data types are: collections, sets, lists and maps [13]. Because abstract data types represent the core for any software application, a proper use of them is an essential requirement for developing a robust and efficient system.The design and implementation of efficient abstract data types are important issues for software developers. Selecting and creating the appropriate data structure for implementing an abstract data type can greatly impact the performance of the system. It is not a trivial problem for a software developer, as it is hard to anticipate all the use scenarios of the deployed application. It is not clear how to select a good implementation for an abstract data type when access patterns to it are highly variant, or even unpredictable. Most of the previous approaches rely on compile-time analyses or programmer annotations [14]. These approaches can be inaccurate since they try to predict a program's behavior before it is executed.A common situation is where there are several data structures for implementing an ADT, with one data structure more efficient than the others for certain operations but worst for the remaining operations, and vice versa [14]. The problem is how to choose the most appropriate data structure for implementing the ADT, given that there is no a priori knowledge of what operations, and how often, the ADT will be mostly used for. This is known as the data representation selection problem (DRSP) [15], or data structure selection problem[16]. The problem can be considered for built-in data types (such as List, Collection), as well for user-defined abstract data types which can be implemented with several data structures.The problem of automatic data structure selection is a complex one because each particular data structure is usually more efficient for some operations and less efficient for others, that is why a static analysis for choosing the best representation can be inappropriate, as the performed operations cannot be statically predicted.A “static” approach in solving the above presented problem can be, for example, to design a data structure for implementing the abstract data type based on an asymptotic analysis of the computational complexities [13] of the ADT's operations. Even if the data structure selected this way is not the best possible in every situation, its performance is not too bad for all situations. It is obvious that these “static” methods can be unreliable because they try to predict a program's behavior before it is executed [12].Another problem with the “static” approaches is the following. The considered ADT may be instantiated in the same software system in different contexts. A “static” selection method will indicate the same data structure for implementing all ADT's instantiations. But, it is very likely (as we will indicate in the example from Section 2.1) that in different execution contexts the behavior of the ADT is different. So, the selection of the most appropriate data structure is very probable dependent on the execution scenarios.That is why we propose a “dynamic” approach, i.e. the selection of the most suitable data structure for implementing an abstract data type to be made at run-time, during the execution of the software system.In the following subsections we give two examples in order to illustrate the importance of the analyzed problem, and, moreover, the need for a dynamic data structure selection, instead of a static one.Let us consider that in a software application a Collection ADT (also known as Bag) is used. The main operations supported by a collection of elements are: insertion of an element into the collection, deletion of an element from the collection and searching an element in the collection.The Collection ADT can be implemented with several data structures: a vector (dynamic array), a linked list or a balanced search tree. Denoting by n the current size of the collection, we give in Table 1the worst case time complexities for the operations of the Collection ADT for different implementations.From Table 1, we can conclude the following:•If the collection will be used mostly for insertion operations, then linked list or vector implementation is preferred.If we have a large number of deletions and/or membership queries (searching) operations, then balanced search tree implementation is preferred.Using a “static” analysis and assuming that the three operations in the collection can be used with the same probability (i.e. 1/3), we can conclude that the most appropriate data structure for implementing the collection is the balanced search tree.But, this “static” decision can be incorrect, as the number of operations performed on the collection during the execution of the system cannot be predicted before its execution. More exactly, there is no a priori knowledge of how the collection looks like, including the total number of operations in the collection.For example, let us consider an execution scenario in which the collection has, at a given moment 10 elements. On this collection, we perform 1 searches and 5 insertions. Using the time complexities from Table 1, we obtain the following:•If the collection would be implemented using a vector or a linked list, the needed time would be approximately 1·10+5·1=15.If the collection would be implemented using a balanced search tree, the needed time would be approximately1·log210+∑i=1014log2i≈21.19.So, based on the dynamic analysis, the most appropriate data structure for implementing the collection is the vector or linked list data structure and this decision is different from the “static one”.According to the above presented example, if we know the number of operations performed on the ADT, we can select the ADT implementation that offers the best possible performance for the given usage scenario. We can conclude that the problem of predicting the most appropriate data structure for implementing the abstract data type during the execution has to be done dynamically and is equivalent to predicting the type and the number of operations performed on the ADT, based on the system's execution context.In order to better motivate our approach, we performed an experiment considering the List ADT and three data structures for implementing a List: vector (dynamic array), linked list and balanced search tree. The main operations supported by a list of elements are: insertion of an element into the list (at the beginning, at the end, at a certain position), deletion of an element from the list (a given element or from a given position), searching an element in the list, iterating through the list, accessing an element from the list at a certain position and updating an element from a certain position.We have chosen the List ADT in our experiment, as it is one the most used ADTs in real software systems. For comparing the performance of the considered data structures, we have defined several usage scenarios of a List, where a usage scenario is a set of pairs (operation, usageprobability).In order to outline the practical nature of the considered problem, we have chosen a popular programming language (Java) and three existing implementations of List ADT:1.java.util.ArrayList which implements List functionalities using the vector data structure.java.util.LinkedList which implements List functionalities using the linked list data structure.org.apache.commons.collections.list.TreeList which implements List functionalities using the balanced search tree data structure.Denoting by n the current size of the list, we give in Table 2the worst case time complexities for the main operations of the List ADT for different implementations.From Table 2, we can conclude the following:•If the list will be used mostly for accessing elements from it, then vector implementation is preferred.If the list will be used mostly for adding elements at the beginning and at the end of it, then linked list implementation is preferred.If we have a large number of deletions at random positions and/or membership queries (searching) operations, then balanced search tree implementation is preferred.The experiment was performed as follows. For each List implementation, we have defined seven possible usage scenarios which were executed on lists with 5000 elements. The total number of performed operations was 10,000 at each execution. The type of the executed operations were chosen according to their probabilities within the usage scenario. In order to capture the performance of a certain implementing data structure, the execution time for each scenario was measured.In Fig. 1we illustrate, in each usage scenario, the performance of the data structures used for implementing the List. Higher bars indicate lower execution time and, consequently, better performance.As the number of the elements from the list grows, a proper data structure selection becomes more important. We depict in Fig. 2, for Scenario 2, how the time needed for executing a usage scenario grows with the size of the list.The experiments described in this section confirms the importance of proper data structure selection and reveal the need for a dynamic decision according to the software system's actual usage scenario.In this section we present several existing approaches for the problem of automatic selection of data representations. To our knowledge, so far, there are no existing machine learning approaches for the considered problem, and, moreover, there are no publicly available case studies for it.Low has introduced in [17] a method of choosing the most appropriate representation of a data structure based on data flow analysis, monitoring executions and user interrogations. The monitoring step uses a special compiler in order to acquire data about the number of executions of each statement in a program. Based on the above mentioned information, a selection algorithm will choose the most appropriate representation using a cost function. The criterion used for automatic selection is to minimize the expected space-time product for the execution of the resulting program. The selection process is static, i.e. made at compile time, and uses an iterative technique similar to hill climbing.In [18] and [19], Bik and Wijshoff approach the problem of compiler optimization of sparse codes by automatic data structure selection at compile time – so the programmer does not have to deal with the matrix sparsity explicitly. Nevertheless the dense declared data structures which are actually sparse have to be annotated and the appropriate data representation is generated based on this information.Schonberg et al. present in [16] an algorithm for automatic selection of data representation at compile time in the SETL programming language. In SETL, the objects are (dynamically) assigned appropriate abstract data types, algorithms being implemented without specifying any concrete data structure at all. The authors note that the problem of automatic data structure selection is a complex one because each particular data structure is usually more efficient for some operations and less efficient for others and they are choosing the best representation based on a static analysis of the way in which specific objects are used.In [20], Low et al. discuss about some techniques of automating the choice of data structure representation. They are conducting their experiments in an ALGOL-60 based programming language called SAIL and the paper is also focused on the automatic selection of associative data structures. In particular, the authors are looking for several alternate structures for storing triples in SAIL, using a static selection process. The compiler will choose the representation which minimizes a cost function, this cost function being influenced by both the amount of time and memory. The use of a data structure within the program is also influencing this choice, this information being collected by the compiler after performing a static analysis, from a monitoring phase (information like the frequency of each primitive operation) and also by user interaction (information about the size of certain data structures at a given time).Rovner presents methods for automatically selecting data structures for programs which use associative data in [21]. A library of representations is described and model of associative data is defined based on the idea that classes of associations should be characterized in terms of both operations and properties of data. The process of automatic selection begins with a flow analysis in which the system determines the possible runtime values of item variables at their points of use in the program, and the possible associations that could exist at run-time. The representation selection is done based on a cost function which takes into consideration the memory consumption and execution time.Yellin focuses in [22] on dynamically choosing the implementation of a component in order to provide optimized usage of resources. The proposed approach uses a mechanism to monitor the types of requests the component is receiving, and adaptively switches implementations for optimal application performance. An algorithm for choosing the most appropriate representation is given, but the algorithm is restricted to exactly two possible implementations of the component. The algorithm has been applied for solving the adaptive selection of data structure problem, but with the same restriction of having only two possible implementations.A probabilistic approach to the problem of automatic selection of data representations based on Markov processes is proposed in [23] by Chuang and Hwang. The selection is done at runtime, but the request sequence (operations performed on the ADT) has to be a priori known in form of a probabilistic description. The algorithm has a preprocessing phase for constructing the Markov process using some local heuristics.Predictive modeling [24] is the process by which a model is created or chosen to try to best predict the probability of a certain outcome. From a machine learning perspective, predictive models are generated using supervised learning techniques [25].Support vector machines (SVMs) [26] are a set of related supervised learning methods used for classification and regression. SVM is a classification technique based on statistical learning theory [27,28] that was applied with great success in many challenging non-linear classification problems and on large data sets. The basic idea is that a SVM constructs a hyperplane or a set of hyperplanes in a high-dimensional space, which can be further used for classification, regression, or other tasks. A decision hyperplane built by a SVM optimally splits the training set, being a boundary between a set of objects having different class memberships [29]. The optimal hyperplane can be distinguished by the maximum margin of separation between all training points and the hyperplane.A SVM uses a nonlinear mapping to transform the original training data into a higher dimension [30]. This is a promising new method for the classification of both linear and non linear data. Within this new dimension, it searches for the linear optimal separating hyperplane that is, a “decision boundary” separating the tuples of one class from another.The advantages of the SVM method are as follows [29]:•They are highly accurate.SVM have the ability to model complex nonlinear decision boundaries.SVM are less prone to over fitting than other models.They provide a compact description of the learned model.SVM classifiers have a wide range of applications, being applied to a number of areas, including handwritten digit recognition, object recognition, speech recognition [31], predictions [29].Data structures [10] provide means to customize an abstract data type according to a given usage scenario. The volume of the processed data and the data access flow in the software application influence the selection of the most appropriate data structure for implementing a certain abstract data type. During the execution of the software application, the data flow and volume is fluctuating due to external factors (such as user interaction), that is why the data structure selection has to be dynamically adapted to the software system's execution context. This adaptation has to be made during the execution of the software application and it is hard or even impossible to predict by the software developer. Consequently, in our opinion, machine learning techniques would provide a better selection at runtime of the appropriate data structure for implementing a certain abstract data type.In this section we will present our proposal of using supervised learning for dynamically selecting the implementation of an abstract data type from the software system, based on its execution context. For this purpose, a SVM model is proposed. In fact, selecting the most appropriate implementation of an abstract data type is equivalent to predicting, based on the execution context, the type and the number of operations performed on the ADT, on a certain execution scenario.Let S={s1, s2, …, sn} be an object oriented software system, where si, 1≤i≤n can be an application class, a method from a class or an attribute from a class.We will consider that:•Class(S)={C1, C2, …, Cl}, Class(S)⊂S, is the set of applications classes of the software system S.Each application class Ci(1≤i≤l) is a set of methods and attributes, i.e.,Ci={mi1,mi2,…,mipi,ai1,ai2,…,airi},1≤pi≤n,1≤ri≤n, where mij(∀j, 1≤j≤pi) are methods and aik(∀k, 1≤k≤ri) are attributes from Ci.Meth(S)=⋃i=1l⋃j=1pimij, Meth(S)⊂S, is the set of methods from all the application classes of the software system S.Attr(S)=⋃i=1l⋃j=1riaij, Attr(S)⊂S, is the set of attributes from the application classes of the software system S.Based on the above notations, the software system S can be defined as in Eq. (1):(1)S=Class(S)⋃Meth(S)⋃Attr(S).Let us consider thatTis an abstract data type having in its interface a set of operationsOthat can be performed on an instance ofT. We also consider a setDT={D1,D2,…,Dn}of data structures that can be used in the software system S for implementingT. If a given instance c of a class C∈Class(S) usesT, the selection of the appropriate data structure fromDthat has to be used for implementing (and instantiating)Tdepends on the states of the objects that are in a “neighborhood” of object c. Intuitively, the classes that use directly or indirectly theTADT influence the selection.In order to express the “neighborhood” of an object, we define the distance between any two classes from the software system. In our view, the distance between two classes Ciand Cjexpresses the degree to which class Ciinfluences the behavior of class Cj.In the following we will introduce several auxiliary definitions needed for a formal description of the notion of “neighborhood”.Definition 1Let c and c′ be two objects which are instances of classes C∈Class(S) and C′∈Class(S), respectively. We say that cusesc′ if c invokes a method from c′ or c′ invokes a method from c.Definition 2Let c and c′ be two objects which are instances of classes C∈Class(S) and C′∈Class(S), respectively. The list UC(c, c′)=(c1, c2, …, ck) is called the usage chain between c and c′ if k≥2, ciare instances of classes from S, ciusesci+1 ∀1≤i≤k−1, c=c1 and c′=ck.Intuitively, the usage chain is similar with the idea of stack trace. We denote byUC(c,c′)the set of all existing usage chains between objects c and c′. We mention thatUC(c,c′)can be empty if there is no usage chain between the two objects.Considering the definitions above, we express the distance between objects c and c′ as given in Eq. (2). By |u| we denote the cardinality of set u.(2)d(c,c′)=0ifc=c′∞ifUC(c,c′)=∅minu∈UC(c,c′)|u|otherwise,In defining the distance d between two objects c and c′, as given in Eq. (2), we have started from the intuition that, as smaller the minimum length of an usage chain between the objects is, as it is likely that the state of c′ has a larger influence on c, so c′ is “closer” to c (the distance between c and c′ is smaller). It can be simply proved that d is a semi-metric function.Now, the neighborhood of radiusRof an object o, denoted byNR(c)can be defined as expressed in Eq. (3).(3)NR(c)={c′|c′∈InstClass(S),d(c,c′)≤R}whereR∈Nand InstClass(S)={c|cisaninstanceofC∈Class(S)} is the set of instances of the running software system S.It can be simply observed the following:•The neighborhood of radius 0 of any object c consists only of itself, i.e.,N0(c)={c}.IfRis large enough, then the neighborhood of radiusRof any object c consists of the entire system, i.e.,NR(c)=InstClass(S).Finally, the notion of execution context of radiusRfor the abstract data typeTwill be introduced in Definition 3.Definition 3Execution context ofT. Let c be an instance of a class Ci∈Class(S) that usesT. The execution context of radiusRofTrepresents the state of the objects from the neighborhood of Ciat runtime, whenTis initialized. Consequently, it is defined as a setECR=⋃cj∈NR(c){vj1,vj2,…,vjrj}, wherevj1,vj2,…,vjrj, ∀j, represent the values of the attributes from object cj.As we have shown in Section 2.1, a “static” selection of the most suitable data structure fromDTthat has to be used for an efficient implementation ofDis inappropriate and does not assure an efficient use ofT, as the volume of data manipulated by the implementation ofTis unpredictable at the development stage. That is why a proper selection has to be done at runtime by analyzing the execution context.In Definition 4 we will define the notion of suitable implementation ofTgiven a certain execution context.Definition 4Most suitable implementation ofTgiven the execution contextECT. LetTbe an abstract data type andECTthe execution context ofTin a certain execution scenario. The most suitable implementation ofTgiven the execution contextECTis the data structureDi∈Dthat provides an efficient implementation ofTin the execution scenario, i.e. the time needed for performing the operations onTgiven the execution contextECTis minimized.In fact, the most proper implementation ofTin a given execution scenario depends on the type and the number of operations fromOthat are performed onTduring the execution. Thus, we can conclude that the problem of dynamically selecting the suitable implementation ofTis, in fact, the problem of predicting, based on the execution context, the type and the number of operations performed onTon a certain execution scenario.Considering the example given in Section 2.1, the most suitable implementation of ADT Collection in the execution context in which the collection has 10 elements, and 1 searches and 5 insertions are performed on it is the linked slist.

@&#CONCLUSIONS@&#
