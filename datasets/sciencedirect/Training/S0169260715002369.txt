@&#MAIN-TITLE@&#
High-quality slab-based intermixing method for fusion rendering of multiple medical objects

@&#HIGHLIGHTS@&#
A novel intermixing scheme is proposed for fusion rendering of multiple medical objects.High-quality intermixing results are acquired for intersecting and overlapping surfaces.Our method resolved aliasing and z-fighting problems.

@&#KEYPHRASES@&#
Volume rendering,Surface rendering,Virtual zSlab,Visibility interpolation,Aliasing problem,Z-fighting problem,

@&#ABSTRACT@&#
The visualization of multiple 3D objects has been increasingly required for recent applications in medical fields. Due to the heterogeneity in data representation or data configuration, it is difficult to efficiently render multiple medical objects in high quality. In this paper, we present a novel intermixing scheme for fusion rendering of multiple medical objects while preserving the real-time performance. First, we present an in-slab visibility interpolation method for the representation of subdivided slabs. Second, we introduce virtual zSlab, which extends an infinitely thin boundary (such as polygonal objects) into a slab with a finite thickness. Finally, based on virtual zSlab and in-slab visibility interpolation, we propose a slab-based visibility intermixing method with the newly proposed rendering pipeline. Experimental results demonstrate that the proposed method delivers more effective multiple-object renderings in terms of rendering quality, compared to conventional approaches. And proposed intermixing scheme provides high-quality intermixing results for the visualization of intersecting and overlapping surfaces by resolving aliasing and z-fighting problems. Moreover, two case studies are presented that apply the proposed method to the real clinical applications. These case studies manifest that the proposed method has the outstanding advantages of the rendering independency and reusability.

@&#INTRODUCTION@&#
The visualization of various types of multiple 3D objects has found its increasing usage in medical fields [1]. With the advance of the scanning device in the medical field, it is becoming one of common practice to simultaneously examine multimodality datasets such as CT (Computed Tomography)–PET (Positron Emission Tomography), MR (Magnetic Resonance)-CT, and MR-SPECT [2,3]. And the surgical planning in neurosurgery and implant surgery requires artificial or binary models (e.g., surgery tools or prior-segmented important organs, usually represented in polygonal models or attributed volume [4]) to be rendered along with a 3D scanned object [5,6]. In addition, a 2D cross-sectional image (e.g., transverse, coronal, and sagittal views) superimposed on a 3D object is needed frequently for more comprehensive information of object [7]. In all of those multiple-object rendering applications, the faster and the more accurate (i.e., rendering in a correct z-depth order) is the rendering, the higher is the user satisfaction.Those 3D objects often come in various representations such as multi-modality, volumetric and polygonal, scan and attribute (often derived from a scan data) datasets. This heterogeneity in the data representation makes it difficult to render the multiple objects in a single rendering pipeline as each type of dataset requires a different visualization technique on its own. Even with multiple homogeneous datasets, the simultaneous rendering is not that simple when there is a difference in data configuration (e.g. acquisition precision, coordinate system, etc.) between them.Many of previous multiple-object rendering approaches targeted at polygonal or volumetric datasets only. For the polygonal dataset, lots of approaches have been reported to intermix transparent surfaces in a correct z-depth order, in which the z-depth values for the surfaces projected to the same image pixel are stored in a buffer and then sorted for the intermixing in the correct z-depth order (referred as a buffer-based intermixing method) [8,9]. The buffer-based method has an advantage that the stored information can be reused as needed when constructing a final scene. However, this method cannot be easily extended to volumetric datasets because it just stores the information for discrete positions and thus it is not appropriate for representing volumetric surfaces including a fuzzy boundary.For the volumetric datasets, instead, lots of previous methods adopted the volume ray-casting algorithm [10–12] while intermixing the samples from all the objects at each sampling position. This per-sample intermixing method exhibits high-quality rendering; however, it has some limitations when the datasets have different data configuration. Several approaches for rendering polygonal and volumetric objects simultaneously have been also presented, but they compute the intersection of polygonal and volumetric objects at each sample, resulting in high computational cost.In this paper, we present a novel multi-objects rendering method which provides smooth and consistent visibility on intersecting and overlapping surfaces. We propose an in-slab visibility interpolation method, referred as opacity-based visibility interpolation (OVI), which better represents in-slab structures by avoiding the accumulated opacity from reaching to a high value too early even for high-opacity objects. In addition, we represent the infinitely thin boundary of polygonal surface as a slab with a thickness, called as virtual zSlab, with the intent to render polygonal and volumetric objects simultaneously using an identical mechanism of a slab-based visibility intermixing method. In the intermixing that involves surface geometry represented as infinitely thin boundary, there are artifacts (e.g., jagged edges and alternate visibility known as z-fighting) caused by binary-way visibility decision, which interfere with recognition of the mixing structures such as overlapping and intersecting surfaces. However, combined with our visibility interpolation, the proposed slab-based intermixing method brings more continuous and smoother visibility transition along with more natural intersection of surfaces, compared to the intermixing based on the conventional visibility interpolation. To achieve this easily, we propose a deferred intermixing scheme using multi-pass rendering pipeline [13–15], which considers, at any time, only two intermixing slab sequences in a single rendering stage.The remainder of this paper is organized as follows. In the next section, we review previous works. Section 3 introduces the background and concept for our elaborate opacity-based visibility interpolation in sub-divided slabs. Section 4 describes the slab-based intermixing method along with virtual zSlab. Section 5 describes an implementation scheme for our intermixing pipeline in details. Section 6 presents our experimental results, followed by conclusion and future work in Section 7.

@&#CONCLUSIONS@&#
