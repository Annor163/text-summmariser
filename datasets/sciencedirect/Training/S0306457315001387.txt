@&#MAIN-TITLE@&#
Effective language identification of forum texts based on statistical approaches

@&#HIGHLIGHTS@&#
This investigation deals with the problem of language identification of noisy texts.Two statistical approaches are proposed: High Frequency Approach and Nearest Prototype Approach.The proposed methods are evaluated on forum datasets containing 32 different languages.An experimental comparison is made with LIGA, NTC, Google translate and Microsoft Word.Results show that the proposed approaches are interesting in language identification of forum texts.

@&#KEYPHRASES@&#
Natural language processing,Automatic language identification,Forum texts,Hybrid approaches,Statistical approaches,N-Grams,

@&#ABSTRACT@&#
This investigation deals with the problem of language identification of noisy texts, which could represent the primary step of many natural language processing or information retrieval tasks. Language identification is the task of automatically identifying the language of a given text. Although there exists several methods in the literature, their performances are not so convincing in practice.In this contribution, we propose two statistical approaches: the high frequency approach and the nearest prototype approach. In the first one, 5 algorithms of language identification are proposed and implemented, namely: character based identification (CBA), word based identification (WBA), special characters based identification (SCA), sequential hybrid algorithm (HA1) and parallel hybrid algorithm (HA2). In the second one, we use 11 similarity measures combined with several types of character N-Grams.For the evaluation task, the proposed methods are tested on forum datasets containing 32 different languages. Furthermore, an experimental comparison is made between the proposed approaches and some referential language identification tools such as: LIGA, NTC, Google translate and Microsoft Word. Results show that the proposed approaches are interesting and outperform the baseline methods of language identification on forum texts.

@&#INTRODUCTION@&#
Knowing the actual document language, in advance, is a crucial step before starting any task in Information Retrieval (IR), and that is why language identification represents an important research field in text mining and computational linguistics.In this research work we deal with the problem of language identification in multilingual and noisy texts. Nowadays, there is relatively little research work in this field compared to other text mining (TM) domains, because this task is not considered as a hard problem, and more researchers are interested in the identification of spoken documents (speech language identification) or text categorization into topic or author.In reality, there exist different categories of texts, such as books, news, and forums, for which the task of language identification can be performed. In the framework of this investigation, we are interested in language identification in discussion forum documents. This type of document presents a high level of difficulty in practice. In fact, the forum is organized around an open dynamic platform, allowing different people to communicate and share the communication. Anyone can post a new discussion, or reply to other messages in his own way and his own writing style, without any restriction on the manner of communication. For this reason, the forums present a high level of difficulty and ambiguity in some cases. Moreover, we can find a mixture of different languages in the same message, SMS writing style, HTML special characters and tags, person tags, etc.In the framework of this investigation, we have built a new dataset of forum texts, which we called DLI32, containing 32 different languages. The details of DLI32 can be found at the following website: http://scholarpage.org/ouamour. However, there are some difficulties inherent in this dataset, since it contains some pairs of languages that are quite similar in vocabulary and grammar. It also contains many close languages that share the same character set, at least in part.To deal with the language identification problem, we propose two statistical approaches, which we have called high frequency approach and nearest prototype approach. In the high frequency approach, we have introduced five new algorithms: two algorithms based on characters, an algorithm based on words, and two hybrid algorithms. Within the nearest prototype approach, we have proposed 11 different distance measures such as: Euclidean distance, Cosine distance, Manhattan distance, Chi2 distance, Squared Euclidean distance, Bray Curtis distance, Canberra distance, Correlation distance, Histogram Intersection distance, Bhattacharyya distance and Out of Place distance (introduced by Cavnar et al.). In this last approach, we used character N-Grams as features.In the word based algorithms, we decided to limit our number of features to only 20 common words, unlike several other authors who have used more than 100 words as features to identify the language. Also, in our experiments, we used a small noisy dataset to train the proposed algorithms, whereas most existing research work uses large datasets for the training. Regarding the noise present in the datasets, we propose three preprocessing steps that are based on the removal of insignificant characters and the separation of contracted words.In order to evaluate the objective performances of the proposed algorithms, we have made a comparison of our approaches with some of the state of the art techniques and tools, such as: the LIGA approach, the NTC approach, Google Translate and Microsoft Word.This paper is organized as follows. In Section 2, we present the background and some previous work in language identification. In Section 3, we define our datasets and the character encoding in details. The proposed approaches of language identification are described in Section 4 (high frequency approach and nearest prototype approach). Section 5 presents the results of the experimental tests and comparisons with the state of the art. Finally, the paper ends with a general conclusion and some prospects for this research work.

@&#CONCLUSIONS@&#
