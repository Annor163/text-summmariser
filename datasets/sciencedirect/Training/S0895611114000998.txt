@&#MAIN-TITLE@&#
Literature-based biomedical image classification and retrieval

@&#HIGHLIGHTS@&#
We describe a method for retrieving images from biomedical articles.We describe a method for segmenting the multi-panel figures in biomedical articles.We describe a method for classifying biomedical images according to medical modality.We describe an optimization strategy for search engine parameters.We describe our participation in the 2013 medical track of ImageCLEF.

@&#KEYPHRASES@&#
Image-based retrieval,Case-based retrieval,Modality classification,Compound figure separation,

@&#ABSTRACT@&#
Literature-based image informatics techniques are essential for managing the rapidly increasing volume of information in the biomedical domain. Compound figure separation, modality classification, and image retrieval are three related tasks useful for enabling efficient access to the most relevant images contained in the literature. In this article, we describe approaches to these tasks and the evaluation of our methods as part of the 2013 medical track of ImageCLEF. In performing each of these tasks, the textual and visual features used to represent images are an important consideration often left unaddressed. Therefore, we also describe a gradient-based optimization strategy for determining meaningful combinations of features and apply the method to the image retrieval task. An evaluation of our optimization strategy indicates the method is capable of producing statistically significant improvements in retrieval performance. Furthermore, the results of the 2013 ImageCLEF evaluation demonstrate the effectiveness of our techniques. In particular, our text-based and mixed image retrieval methods ranked first among all the participating groups.

@&#INTRODUCTION@&#
Images are sources of essential information within biomedical literature. Biomedical images are useful for a variety of purposes, including research and education, and their content often conveys information that is not otherwise mentioned in the surrounding text of an article. Given the rapid pace of scientific discovery, it is increasingly difficult to locate informative images within large volumes of literature. In order to enable efficient access to the most relevant images for a given request, various text-based and content-based image classification and retrieval approaches, as well as multimodal methods that combine textual and visual strategies, have been proposed and evaluated within the biomedical domain.Existing classification and retrieval approaches differ in how they represent images and determine their relevance. Text-based methods represent images with descriptive text, such as figure captions, and retrieve or classify images using traditional text-based techniques. Content-based methods represent images using visual descriptors and use these descriptors to retrieve or classify images based on their visual appearance. Visual descriptors describe various aspects of an image's appearance, such as its color or texture. Finally, multimodal techniques represent images with both textual and visual features. For performing retrieval tasks, multimodal approaches allow for the construction of complex information requests consisting of a textual description of the desired image content that is augmented with the visual descriptors extracted from one or more example images. Datta et al. [1] provide a general overview of existing image classification and retrieval approaches.In this article, we describe our literature-based biomedical image classification and retrieval methods and their evaluation as part of the 2013 medical track of ImageCLEF [2]. The medical track of ImageCLEF consists of an image modality classification task, a compound figure separation task, and retrieval tasks. For the classification task, the goal is to classify a given set of images according to 31 modalities (e.g., “Computerized Tomography,” “Electron Microscopy,” etc.). The modalities are organized hierarchically into meta-classes such as “Radiology” and “Microscopy,” which are themselves types of “Diagnostic Images.” For the compound figure separation task, the goal is to segment the panels of multi-panel figures. Figures contained in biomedical articles are often composed of multiple panels (e.g., commonly labeled “a,” “b,” etc.) and segmenting them can result in improved retrieval performance. Finally, in the image retrieval task, a set of ad-hoc information requests is given, and the goal is to retrieve the most relevant images from a collection of biomedical articles for each topic. Although the 2013 medical track of ImageCLEF includes an additional case-based retrieval task, we will focus in this article only on the image retrieval task.An important consideration for each of the above tasks that is often left unaddressed is the relative effectiveness of the various textual and visual features used to represent images. For example, for some biomedical image retrieval tasks, the content of an image's caption might be the most significant indicator of its relevance, whereas for other tasks, an image's color might be the most important feature. Information classification and retrieval systems commonly provide a mechanism to “weight” these features as a means of specifying their perceived significance. However, lacking knowledge of the images that are relevant for a specific set of requests, it is common practice to adjust the feature weights manually based on domain experience rather than determining an ideal allocation automatically.Insight can be gained into literature-based biomedical image classification and retrieval tasks by optimizing the weights a multimodal system allocates to various textual and visual features. Given the well-known challenges associated with determining meaningful multimodal feature combinations [3], feature weight optimization has the potential to result in a significant improvement in image classification and retrieval performance. In addition, an analysis of the most effective features may lead to more sophisticated textual and visual feature integration strategies.In addition to describing our basic approaches for each of the tasks of the 2013 medical track of ImageCLEF, we also describe in this article a feature optimization strategy for the image retrieval task. Much existing work addresses the problem of optimizing the internal parameters of traditional text-based information retrieval systems. Researchers have demonstrated success using a variety of optimization techniques, some of which include direct and interactive optimization, the use of genetic algorithms [4], and gradient-based methods. Among the many proposed strategies, gradient-based techniques, such as those proposed by Taylor et al. [5] and Chapelle and Wu [6], have received considerable attention for their efficiency and ease of implementation. However, to our knowledge, similar techniques have yet to be explored within the context of multimodal biomedical image retrieval.In the following sections, we describe our methods and results. In Section 2, we describe the textual and visual features we use to represent the images contained in biomedical articles and how we organize them in a structure useful for image classification and retrieval tasks. Our approaches are then described for the compound figure separation, modality classification, and image retrieval tasks. After presenting our basic image retrieval methods, we describe in greater detail our image retrieval system and the gradient-based optimization strategy we used to optimize its internal parameters. Also described in Section 2 are each of the runs we submitted as part of the ImageCLEF evaluation. Finally, in Sections 3–4 we present and discuss the results of our image classification and retrieval methods.

@&#CONCLUSIONS@&#
