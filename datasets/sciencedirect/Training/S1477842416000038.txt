@&#MAIN-TITLE@&#
Revisiting actor programming in C++

@&#HIGHLIGHTS@&#
We analyze the problem and design space for actor programming in C++.We find that type-safe message passing interfaces are important for the robustness of actor programs.Pattern Matching as a DSL in C++ eases the definition of message handlers.We introduce an according framework for actor programming in C++ (CAF).Core algorithms and the scalable architecture are thoroughly discussed.Benchmarking CAF against many other frameworks reveals overall performance benefits.

@&#KEYPHRASES@&#
C++ Actor framework,Concurrent programming,Message-oriented middleware,Distributed software architecture,GPU computing,Performance analysis,

@&#ABSTRACT@&#
The actor model of computation has gained significant popularity over the last decade. Its high level of abstraction makes it appealing for concurrent applications in parallel and distributed systems. However, designing a real-world actor framework that subsumes full scalability, strong reliability, and high resource efficiency requires many conceptual and algorithmic additives to the original model.In this paper, we report on designing and building CAF, the C++ Actor Framework. CAF targets at providing a concurrent and distributed native environment for scaling up to very large, high-performance applications, and equally well down to small constrained systems. We present the key specifications and design concepts—in particular a message-transparent architecture, type-safe message interfaces, and pattern matching facilities—that make native actors a viable approach for many robust, elastic, and highly distributed developments. We demonstrate the feasibility of CAF in three scenarios: first for elastic, upscaling environments, second for including heterogeneous hardware like GPUs, and third for distributed runtime systems. Extensive performance evaluations indicate ideal runtime at very low memory footprint for up to 64 CPU cores, or when offloading work to a GPU. In these tests, CAF continuously outperforms the competing actor environments Erlang, Charm++, SalsaLite, Scala, ActorFoundry, and even the raw message passing framework OpenMPI.

@&#INTRODUCTION@&#
In recent times, an increasing number of applications require very high performance for serving concurrent tasks. Hosted in elastic, virtualized environments, these programs often need to scale up instantaneously to satisfy high demands of many simultaneous users. Such use cases urge program developers to implement tasks concurrently wherever algorithmically feasible, so that running code can fully adapt to the varying resources of a cloud-type setting. However, dealing with concurrency is challenging and handwritten synchronization easily lacks performance, robustness, or both.At the low end, the emerging Internet of Things (IoT) pushes demand for applications that are widely distributed on a fine granular scale. Such loosely coupled, highly heterogeneous IoT environments require lightweight and robust application code which can quickly adapt to ever changing deployment conditions. Still, the majority of existing applications in the IoT is built from low-level primitives and lacks flexibility, portability, and reliability. The envisioned industrial-scale applications of the near future urge the need for an appropriate software paradigm that can be efficiently applied to the various deployment areas of the IoT.Forty years ago, a seminal concept to the problems of concurrency and distribution has been formulated in the actor model by Hewitt et al. [1]. With the introduction of a single primitive—called actor—for concurrent and distributed entities, the model separates the design of a software from its deployment at runtime. The high level of abstraction offered by this approach combined with its flexibility and efficiency makes it highly attractive for the parallel multi-core systems of today, as well as for tasks distributed on Internet scale. As such, the actor concept is capable of providing answers to urgent problems throughout the software industry and has been recognized as an important contribution for efficiently using the current system infrastructure.On its long path from an early concept to a wide adoption in the real world, many contributions were needed in both conceptual modeling and practical realization. In his seminal work, Agha [2] introduced mailboxing for the message processing of actors and later laid out the fundament for open and dynamically reconfigurable actor systems [3]. Actor-based languages like Erlang [4] or SALSA Lite [5], frameworks such as ActorFoundry, which is based on Kilim [6], or vendor-specific environments like Casablanca [7] have been published but remained in their specific niches. Today, Scala includes the actor-based framework Akka [8] as part of its standard distribution, after the actor model has largely gained popularity among application developers. The application fields of the actor model also include cluster computing as demonstrated by the actor-inspired framework Charm++ [9]. In previous work [10,11], we reported on our initial steps for bringing a C++ actor library to the native domain.In this work, we revisit and discuss the C++ Actor Framework (CAF).11http://www.actor-framework.org, a predecessor of CAF was named libcppa.CAF has evolved over the last four years to a full-fledged development platform—a domain-specific language in C++ and a powerful runtime environment. Moreover, CAF subsumes components for GPGPU computing, introspection of distributed actor systems, and adaptations to a loose coupling for the IoT [12]. It has been adopted in several prominent application environments, among them scalable network forensics [13].In this paper, we rethink the design of actors with CAF, donating special focus to the following core contributions:1.We present the scalable, message-transparent architecture of CAF along with core algorithms.We introduce type-safe message passing interfaces for enhancing the robustness of actor programs.We illustrate operations and use of the CAF pattern matching facility.We lay out a scheduling infrastructure for the actor runtime environment that improves scaling up to high numbers of concurrent processors.The remainder of this paper is organized as follows. In Section 2, we re-position the use of actors and highlight our platform from a programming and performance perspective. The evolution of the actor approach up to current requirements is discussed in Section 3 together with related work. Section 4 introduces key concepts and technologies that are central for the development of the C++ Actor Framework. The software design for type-safe messaging interfaces between actors are developed in Section 5, followed by the chapter on actor scheduling (Section 6). Extensive performance evaluations are shown in Section 7. We conclude in Section 8 and give an outlook on future research.In a first discussion, we want to shed light on the developing field of C++ actor programming from three motivating perspectives: characteristic use cases, programming characteristics, and performance potentials.Elastic programming for adaptive deployment: The actor approach allows a general purpose software to safely scale up and down by orders of magnitudes, while running in local or distributed environments. Such extraordinary robustness is enabled by assigning small application tasks to a possibly very high number of actors at negligible cost. In consequence, such programs can dynamically adapt to their runtime environment while executing efficiently on a mobile, a many-core server, or Internet-wide distributed hosts. The default domain of this case lies naturally in the cloud.End-to-end messaging at loose coupling: Actors directly exchange messages with each other, while the deployment specific message transport remains transparent. The hosting environment of an actor system may well admit loose coupling, using a stateless transactional transport for example. This extends traditional models of distributed programming like Remote Method Invocation (RMI) [14], which enables direct access to remote methods but requires a tight coupling, or the REST [15] facade, which is designed for loose coupling but adds an indirection. Typical applications can use this capability to directly exchange signals with remote controllers—a light bulb, for example—or to move software instances between sites without reconfiguration. It is worth noting that rigorously defined (typed) message interfaces allow for dedicated ‘firewall’ control, and do not open new vulnerabilities to Internet hosts.Seamless integration of heterogeneous hardware: The abstract transport binding of actors seamlessly covers dedicated peripheral channels that may connect GPUs/coprocessors, semi-internal buses in heterogeneous multi-CPU architectures like big.LITTLE boards, as well as gateway-based network structures in current cars, buildings, or factories. This allows actor systems to transparently bridge architectural design gaps and frees software developers from crafting dedicated glue code.We now want to highlight the actor-based abstraction mechanisms for programming as opposed to traditional object-oriented designs. Consider the class definition in Listing 1.It defines an interface named key_value_store supporting put and get operations. When accessible by multiple threads in parallel, the class has to be implemented in a thread-safe manner. A simple approach is to guard both member functions using a mutex in the implementing class. This does not scale well, mainly because readers block other readers. More scalable approaches require a specific synchronization protocol that is based on read-write locks, for example. Architecturally, though, lock-based solutions are best avoided, as locks do not compose and combining individually thread-safe classes can lead to deadlocks [16]. In any case, the interface itself is not aware of concurrency.Listing 2 illustrates the interface definition of an actor offering put and get operations using our framework. The interface type kvs_actor specifies a message passing interface.Actors can be programmed without knowledge about concurrency primitives, but at the same time support massively parallel access (see Section 7.2). In our example, get requests are sequentially processed without further coordination, as there is no intra-actor concurrency. For parallelization, actors can explicitly redistribute tasks to a set of workers. In this context, we should mention extensions for task-level parallelism at actor level in other frameworks [17]. They can be used to handle read-write concurrency on partitioned data [18]. Our message passing interface uses so-called atoms (see Section 4.4) to identify specific operations instead of member function names.Our actor framework provides network-transparent messaging. When sending a message to a kvs_actor—as shown in Listing 3—the sender can remain agnostic about where the receiver is located. Caller and callee are also not coupled via the type system. This differs from RMI-based designs and reflects the desire for abstracting interfaces from implementations. The typed message handles enable the compiler to statically check input and output types, but do not expose the actual type of the callee. The requester is rather able to send messages with partial type information as the callee may implement additional message handlers for the kvs_actor interface not exposed to the caller.Our third consideration is about performance. High-level abstractions in software design often disregard efficiency. We question whether performance has to suffer when switching from low-level message passing systems to actor frameworks. For an answer, we compare CAF with the well-known high-performance but low-level Message Passing Interface (MPI) [19].We test in a distributed system with an implementation to calculate a fixed number of the Mandelbrot set, using the same C++ program code with distribution done by CAF for actor programming in C+ +, and Boost.MPI. For network communication, CAF uses a network abstraction over TCP sockets based on a middleman (see Section 4.1) with message-based network I/O (see Section 5.5). Boost.MPI is a C++ wrapper for OpenMPI. Both versions exclusively rely on asynchronous communication and reduce synchronization steps to a minimum. Since both programs share one C++ implementation for the calculation, the measurements reveal the overhead added by the distributed runtime system in use. Hence, this setup discloses the trade-offs in performance which developers make when opting for a high-level abstraction like the actor model instead of low-layer primitives. Time measurements were restricted to application program flow and do not include the initial setup phase performed by each platform.Fig. 1shows the runtime results for distributed setups as functions of available worker nodes. In the first evaluation depicted in Fig. 1(a), we have used one host running 4 to 64 virtual machines for worker nodes. Both frameworks admit a quite similar runtime behavior. However, CAF runs 4% faster on 64 worker nodes, indicating a slightly better scalability. To achieve an evenly distributed workload, we added worker nodes in increments of four, as the host machine consists of four AMD Opteron 2.3GHz processors with 16 hardware-level threads each.Our second evaluation compares the performance of CAF and OpenMPI in a physically distributed environment. Fig. 1(b) displays the performance results using 16 identical worker nodes connected in a switched network, each equipped with one quadcore Intel i7 3.4GHz processor. Hence, both setups have a maximum of 64 working actors or MPI processes, respectively. Qualitatively, the physically distributed system attains a behavior close to the virtual environment, while the absolute run times changed with altered CPU types. CAF runs 3% faster with 16 physical worker nodes, again indicating a slightly better scalability.These results clearly illustrate that actors in CAF do not impose a performance penalty when compared to a lower level message passing approach. Consequently, developers are not burdened with trading between a high level of abstraction on the one hand, and runtime performance on the other hand. An efficient implementation of the actor model can even outperform a low-level message exchange.Although formulated in the early 1970s [1], the actor model of computation was primarily used by the Erlang community until recently. The advent of multi-core machines and the growing importance of elastic cloud infrastructure made the model interesting for both academia and industry. In this section, we first discuss open conceptual questions in the current evolution of actor systems that arise from new application domains. Second, we contrast our approach with related work in the field of actor programming.The actor model allows us to scale software from one to many cores and from one to many nodes. This flexibility in deployment makes the approach attractive for many application domains. This includes (1) infrastructure software, (2) Internet-wide distributed or IoT applications, as well as (3) high-performance applications that scale dynamically with demand. Still, available actor model implementations address only a subset of the requirements arising from these scenarios.Robust Composition: Initial definition and implementation of software is only a small fraction of its lifetime. Maintenance and evolution are considered the main tasks of developers [20]. Programming environments should support all parts of the life cycle equally well and statically verify invariants. Still, available systems for actor programming either cannot statically verify inter-actor relationships, or require re-compilation and re-deployment even for minor changes from a monolithic code base. The first approach imposes excessive integration tests or constant model checking, while the latter is not suitable for large infrastructure software with independently maintained software components. Neither approach is robust with respect to existing compositions. Changing one part of the software in a downward compatible way must not affect other parts of the system, while invariants of a system should be statically verified at all times.Native Programming: We believe that writing dynamic, concurrent, or distributed applications using a native programming language such as C++ is ill-supported today. Standardized libraries only offer low-level primitives for concurrency such as locks and condition variables. It requires significant expert knowledge to use such primitives correctly and can cause subtle errors that are hard to find [21]. A naïve memory layout may in addition severely slow down program execution due to false sharing[22]. The support for distribution is even less advanced, and developers often fall back to hand-crafted networking components based on socket-layer communication. Transactional memory—supplied either in software [23] or hardware [24]—and atomic operations can help with implementing scalable data structures [25], but neither account for distribution, nor for communication between software components, nor for dynamic software deployment. A native programming environment based on the actor model leaves full control over all performance-relevant aspects of a system with the developers while remaining at a very high level of abstraction. This enhanced level of abstraction can simplify reasoning about the code [26] without requiring expert knowledge on synchronization primitives. At the same time, the choice of C++ as host language allows programmers to mix actors with other concurrency abstractions if needed. While this seems to be a disadvantage at first, a recent study by Tasharofi et al. [27] showed that integrating legacy components is common practice and shortcomings of an actor framework—the lack of high-level coordination patterns for building HTTP servers for instance—can be compensated by using special-purpose APIs. However, we believe the issue of missing high-level building blocks based on actors will naturally be addressed in the future as more and more developers switch to actor frameworks and consequently more of those building blocks are developed and available to the public.Memory Efficiency: Implementations of the actor model traditionally focus on virtualized environments such as the JVM [28], while actor-inspired implementations for native programming languages focus on specific niches. For example, Charm++ [9] focuses on software development for supercomputers. A general-purpose framework for actor programming that minimizes memory consumption is not available. Still, memory is the limiting resource on embedded devices and massively multi-user infrastructure software requires low per-user memory footprint at runtime in order to scale. In this way, a memory-efficient actor environment broadens the range of applications in both low-end and high-end computing.Heterogeneous Hardware Environment: Specialized hardware components are ubiquitously available. Modern graphics cards in commodity hardware are programmable via GPGPU languages such as CUDA [29] or OpenCL [30]. Algorithms running on such SIMD-components make use of hundreds or thousands of parallel processing units and outperform multi-core CPUs by orders of magnitudes for appropriate tasks. Hybrid coprocessors like the Intel PHI likewise contribute performance boosts while allowing for branching program flows. Custom hardware such as ASICs or reconfigurable hardware such as FPGAs achieve much higher performance than software for tasks like data encryption [31]. Recent trends on mobile devices also couple two general-purpose processors of different complexities and speeds on a single chip [32] that activates the fast but power consuming processor only when needed. In all cases, programmatic access to specialized hardware components requires to use a dedicated API. This makes integration of such devices into existing software systems cumbersome. A heterogeneous system architecture that transparently enables message passing between actors running on different hardware architectures helps developers to integrate heterogeneous components.

@&#CONCLUSIONS@&#
