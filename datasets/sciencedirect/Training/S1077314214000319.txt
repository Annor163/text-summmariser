@&#MAIN-TITLE@&#
Unsupervised edge map scoring: A statistical complexity approach

@&#HIGHLIGHTS@&#
A statistical complexity measure for edge maps and binary images is proposed.The measure is a product of equilibrium and entropy indices.Equilibrium is measured projecting the edge map into a family of predefined edge patterns.Information is measured with the Kolmogorov–Smirnov statistic of goodness of fit.Measure can be used for specific algorithm evaluation and to identify its best parameters.

@&#KEYPHRASES@&#
Unsupervised quality measure,Edge maps,Statistical complexity,Edge patterns,Entropy,Kolmogorov–Smirnov statistic,

@&#ABSTRACT@&#
We propose a new Statistical Complexity Measure (SCM) to qualify edge maps without Ground Truth (GT) knowledge. The measure is the product of two indices, an Equilibrium indexEobtained by projecting the edge map into a family of edge patterns, and an Entropy indexH, defined as a function of the Kolmogorov–Smirnov (KS) statistic.This new measure can be used for performance characterization which includes: (i) the specific evaluation of an algorithm (intra-technique process) in order to identify its best parameters and (ii) the comparison of different algorithms (inter-technique process) in order to classify them according to their quality.Results made over images of the South Florida and Berkeley databases show that our approach significantly improves over Pratt’s Figure of Merit (PFoM) which is the objective reference-based edge map evaluation standard, as it takes into account more features in its evaluation.

@&#INTRODUCTION@&#
In most image processing techniques, the detection and handling of the edge structure of the input image is very important. From object detection to image transmission, the quality of edge manipulation takes great part in the success of the processing. Nevertheless, there is no universal definition of the notion of edge. For Abdou and Pratt, an edge is defined as a local change in luminance or discontinuity in the luminance intensity of the image [1] while Kitchen and Rosenfeld pointed out that the edge concept depends on the type of processing and analysis in which it is involved [2].Therefore, many researchers have designed optimal Edge Detection Algorithms (EDAs) related to different properties of the edge structure, but only a few have studied how to measure the edge strength and quality of general edge maps [3]. Effective and objective Edge Detection (ED) evaluation measures must be developed in order to assess EDA performance.In general, ED evaluation measures can be classified due to the need of a reference map called Ground Truth (GT) (supervised or unsupervised measures) and the type of score that they output, quantitative or qualitative. Some well known examples of quantitative supervised measures, also called discrepancy measures, are Pratt’s Figure of Merit (PFoM) [4], Kappa index [5], and Baddeley’s Delta Metric (BDM) [6]. A comparison between these discrepancy measures and some other supervised statistical measures were performed in [7]. Two main conclusions were drawn from their experiments: (i) up to date, there is no convincing solution for edge image comparison or quality evaluation and (ii) the biases of the measures can be helpful in applications, where there is a particular interest in penalizing or ignoring some specific kind of error. A supervised quality metric for binary documents based on structural pixel matching, taking into account global edge structures introducing a smoothness term in the matching function was proposed in [8]. Examples of binary documents are text files either photocopied, faxed or scanned, with fast publishing resolution. In this kind of binary documents, bad visual word understanding is not always related to classical low scoring. PFoM is known to give high scores to lighter maps, with high rate of false negatives, but it is not acquiescent to human perception [9].Without the guide of a GT, assessing edge maps quality is a more difficult task. The unsupervised ED measures that are found in the literature look for specific characteristics of the input edge map, such as coherence [10], continuity [2], smoothness and good continuation [11,12], or an specific pattern identification [13], among others [14,15]. Bower et al. studied the bias introduced by the search of only one characteristic [16]. They reported a similar conclusion to the one given by [7]: there is no unique solution; moreover, selected best maps are qualitatively different, and bias cannot be estimated without further assumption of the error incurred.Recently, Yitzhaky and Peli proposed an unsupervised evaluation procedure of ED techniques based on the consensus approach [17]. Using the correspondence between different standard EDA results, an estimated best edge map (consensus map) was obtained and later used as an estimated ground truth (EGT). Correspondence was computed by using both a receiver operating characteristics (ROC) analysis and a Chi-square test for standard binary outputs, considering a trade off between structure and noisiness in the detection results. Fernandez-Garcia et al. provided a definition of consensus edge map that is close to the notion of confidence set. They argued that in order to compare ED procedures, it is not esencial to use the best and exact GT; rather it is only necessary to use a reliable EGT that allows correct classification or ranking of the EDA to be obtained [18]. They also noted that their approach may be used to evaluate detections from different EDA (inter-technique performance characterization) only if these detectors aim at the same output format. Our proposed evaluation methods also take into account this assumption.The consensus approach suffers from bias regarding the generation of the candidate edge maps used to define the EGT. If the majority of the edge maps considered are not of adequate quality or fail to extract certain edge structures which are detected by only a small selection of the edge maps, this will be reflected both in the consensus EGT and in the quality of the evaluation methodology derived from it. In a sense, it penalizes algorithms that do not agree with the failures of the other algorithms.In this paper we define a new non-reference measure that does not depend, directly or indirectly, on GT data. As the previous measures, it can be used for ED performance characterization which includes: (i) the specific evaluation of an algorithm (intra-technique process) in order to identify its best parameters and (ii) the comparison of different algorithms with the same output format (inter-technique process) in order to classify them according to their quality.Our proposal, denoted Statistical Complexity Measure (SCM) searches for a compromise between two extreme values in the space of edge maps: a map with few edge points in a perfect shape (Equilibrium) and with many edge points randomly located (Information). The new measure is the product of two indices, an Equilibrium indexEobtained by combining local correlation between the edge map and a family of predetermined edge patterns and an Entropy indexH, defined as a function of the Kolmogorov–Smirnov (KS) statistic. SCM gives value between zero and one, being zero the minimum and one the maximum quality.Konishi et al. defined an statistical ED algorithm which relies on Chernoff information and entropy of probability distributions conditional to edge and non-edge state [15]. Their validation experiments studied elements similar to the indices that are part of our complexity measure. They also noted that maps with scattered random points may give high information regardless the real structure of the image, but the combinations of shape seeking measures with entropy functionals greatly reduces the probability of such anomalies.The paper is organized as follows. In Section 2, a cosine based discrepancy measureQBto score a map against a collection of hand-made GT (supervised case), or against a collection of fixed significant patterns (unsupervised case) is introduced. In Section 3 the concepts behind the Equilibrium indexEand Entropy indexHare introduced, and the final SCMCas the product of both indices is defined. Experiments and results are discussed in Section 4 and conclusions and comments are left for Section 5.In this section, a cosine-based similarity measureQBis introduced as an intermediate step in the definition of the final measureC, along with necessary notation. Let I be an image,ban edge map associated with I, (this is,bis a binary image with the same size as I), andgits GT (if it is available). Fig. 1shows an example of such images. A simple measure of similarity betweenbandgis the cosine of the angle between them [19], when they are seen as 1-D vectors (concatenating all columns one under another).We define the indexQBas the maximum of all similarity values(1)QB(b)=max1⩽i⩽nQ(gi,b)=max1⩽i⩽ngiTbgib,beingx=xTx, andB=g1,g2,…,gna collection of GT images (that could have only one element).The Cauchy Schwartz inequality implies that the index is upper bounded by one thus attaining such bound only when the map is optimalb∈B. Since edge maps and GT images are binary images, the index is lower bounded by 0, attained only in the absence of any similarity (whenbis orthogonal toB). When no GT is available, predefined edge patterns may be locally sought in the edge map with this measure.In this section, a new SCM in the context of unsupervised evaluation of edge maps is introduced. This new measure can be used to identify the optimal parameters of a given algorithm, but also to compare and rank the results of different algorithms. In this framework, the concepts of Equilibrium and Information can be discussed and scoring indices for such qualities in edge maps can be proposed.Following the general structure of complexity measures described by [20], SCM is defined as(2)C(b)=E(b)H(b),whereEis an Equilibrium index,His an Entropy index, andbis an edge map. To define such indices, the concepts of Equilibrium and Information in the context of ED must be discussed. An edge map is well balanced (reached Equilibrium) if it is structurally simple. In this sense, the map in panel(d)of Fig. 2is better balanced than the edge map in panel(c)and in turn, the one in(c)is better balanced than the one in(b). Regarding Entropy, one map has more information than another if the discontinuities, textures and shapes of the analyzed image are better characterized. The overabundance of information produces chaotic (cluttered) edge maps like in(b), but the absence of information produces poor edge maps like in(d). Thus, Equilibrium and Information are two complementary concepts, and the Complexity searches for a balance point between them.Thus, to quantify the Equilibrium of an edge map, we measured local correlation against a family of specific edge patterns assessing the correct identification and value of the usual local characteristics of edges. Since Entropy should measure the amount of information of a system, which is maximized when the system reaches a random state, we assess the randomness of an edge map with an index based on contrasting the statistical distribution of the spatial edge positions against the bidimensional uniform distribution.Abdou and Pratt introduced in their seminal paper the notion of Figure of Merit in order to score fragmented, offset and smeared edge patterns in comparison with the ideal edges present in the GT [1]. The Equilibrium index should perform a similar task in the unsupervised case, thus the GT will be replaced by a familyBof carefully chosen binary edge patterns.Abusing notation, letB={b1,b2,…,bn}be a collection ofN×Nedge patterns transformed into column vectors. Sliding aN×Nwindow over the edge mapb, centered in each edge pixel position k, edge sub-mapsb(k)are extracted and transformed into column vectors. The CSM of each sub-maps with respect to the family of edge patternsBis computed by(3)QB(b(k))=max1⩽j⩽nbjTb(k)‖bj‖b(k).The Equilibrium ofbwith respect to the family of edge patternsBis defined as the average of the local CSM computed only on edge pixels k,(4)E(b)=1|Eb|∑k=1|Eb|QB(b(k)),whereEbis the set of all edge pixels in the binary edge mapb, and|Eb|is the cardinal number of such set.The familyBof edge patterns could be very general, but in this paper, as in [2], only line-like edge patterns are considered (Fig. 3). Being a line segment an essential primitive graphic, it can be used to construct many other objects. Our line patterns are made with an accurate and efficient raster line-generating algorithm defined in [21]. Bresenham stated that his line algorithms provide the best-fit approximations to the true lines by minimizing the error (distance) to the true primitive. Beginning with ray traces that go through the origin, 140 edge patterns of size7×7were constructed and stored in the present database (Fig. 3).In Fig. 4, the values ofQBon different patterns that appear in a Sobel edge map (computed from image block) are shown. The edge pattern(c),(f),(g)and(h)show the performance of the index when the edges are close to line segments. The maps(h)–(k)show the behavior of (Eq. (4)) in presence of thick edges. The maximum value is reached in(h), a pattern of a line of one pixel width. Noisy patterns(b)–(e)reach an index value lower than 0.54.Shannon stated that the information provided by an observation is proportional to how improbable it was [22]. Relating this notion with the edge detection problem, having three points aligned in an edge map implies that the probability of having a fourth point next to them is higher than the probability of having a point further away. Therefore, observing a point in a place with low probability gives more information than observing a point in an expected place. Randomness in space positions is at the core of the notion of edge information.Testing randomness in space is a task usually done by testing the null hypothesis of uniform distribution in the unit square with the use the KS statistic. Such statistic takes values between 0 and 1, rejecting the uniform hypothesis for values close to 1.For a given edge mapb, letϕ=(ϕ1,ϕ2)be an injective function that maps the edge positions(i,j)∈Eto the unit square[0,1]×[0,1], defined byϕ(i,j)=2i-12N,2j-12M, whereN×Mis the image size. LetDbe the KS bidimensional statistic defined by(5)D(b)=max(x,y)∈R2|Fb(x,y)-F(x,y)|,where F is the cumulative distribution function of an uniform distributed bidimensional vector, andFbthe empirical distribution function of the sampleϕ(E)given by(6)Fb(x,y)=|{(i,j)∈E/ϕ1(i)⩽x,ϕ2(j)⩽y}||E|.The entropy measureHis defined as(7)H(b)=1-D(b).D(b)was computed using the efficient algorithm by [23].

@&#CONCLUSIONS@&#
In this paper, new ideas of edge Equilibrium and edge Information are discussed. They lead to the definition of a new SCM for scoring binary maps. To measure edge Equilibrium, a similarity index was defined by projecting the edge map into a family of edge patterns that scores the continuity and width of edges in fixed size windows of the edge map. To measure Information, a new Entropy index based on the KS statistic was defined. The SCM is the product of the Equilibrium and Entropy indices and it is effectively used for performance characterization which includes: (i) the specific evaluation of an algorithm (intra-technique process) in order to identify its best parameters and (ii) the comparison of different algorithms (inter-technique process) in order to classify them according to their quality.Our experiments were made with common edge detectors that are used by a large number of practitioners. More complex edge detectors aim at specific characteristics in the images, thus the measure should be modified accordingly with a pattern database that accommodates those general characteristics. Active contour methods as applied in [31] are based on the statistical distribution of the noise present in PolSAR images. A measure like ours must carefully be modified to score such EDA outputs, which is the scope of another paper. We are also studying alternative definitions for the Entropy index based on edge map histogram functionals that could be tailored to measure the performance of boundary detection algorithms more accurately.