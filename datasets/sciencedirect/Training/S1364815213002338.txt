@&#MAIN-TITLE@&#
A comprehensive evaluation of various sensitivity analysis methods: A case study with a hydrological model

@&#HIGHLIGHTS@&#
A newly developed uncertainty quantification software called PSUADE is introduced.The effectiveness and efficiency of ten sensitivity analysis methods are evaluated.Nine different space-filling sampling techniques are tested.

@&#KEYPHRASES@&#
Uncertainty quantification,Sensitivity analysis,Parameter screening,Space-filling sampling,PSUADE,

@&#ABSTRACT@&#
Sensitivity analysis (SA) is a commonly used approach for identifying important parameters that dominate model behaviors. We use a newly developed software package, a Problem Solving environment for Uncertainty Analysis and Design Exploration (PSUADE), to evaluate the effectiveness and efficiency of ten widely used SA methods, including seven qualitative and three quantitative ones. All SA methods are tested using a variety of sampling techniques to screen out the most sensitive (i.e., important) parameters from the insensitive ones. The Sacramento Soil Moisture Accounting (SAC-SMA) model, which has thirteen tunable parameters, is used for illustration. The South Branch Potomac River basin near Springfield, West Virginia in the U.S. is chosen as the study area. The key findings from this study are: (1) For qualitative SA methods, Correlation Analysis (CA), Regression Analysis (RA), and Gaussian Process (GP) screening methods are shown to be not effective in this example. Morris One-At-a-Time (MOAT) screening is the most efficient, needing only 280 samples to identify the most important parameters, but it is the least robust method. Multivariate Adaptive Regression Splines (MARS), Delta Test (DT) and Sum-Of-Trees (SOT) screening methods need about 400–600 samples for the same purpose. Monte Carlo (MC), Orthogonal Array (OA) and Orthogonal Array based Latin Hypercube (OALH) are appropriate sampling techniques for them; (2) For quantitative SA methods, at least 2777 samples are needed for Fourier Amplitude Sensitivity Test (FAST) to identity parameter main effect. McKay method needs about 360 samples to evaluate the main effect, more than 1000 samples to assess the two-way interaction effect. OALH and LPτ (LPTAU) sampling techniques are more appropriate for McKay method. For the Sobol' method, the minimum samples needed are 1050 to compute the first-order and total sensitivity indices correctly. These comparisons show that qualitative SA methods are more efficient but less accurate and robust than quantitative ones.PSUADECharles TongC++https://computation.llnl.gov/casc/uncertainty_quantification/Free for non-commercial academic research

@&#INTRODUCTION@&#
Computer-based system models have become indispensable in many fields of science and engineering, from finance to life sciences, from quantum physics to earth sciences and environmental engineering. Parameters of these models exert great influence on models' performance. Some of the parameters may be observed or measured, e.g., the physical dimensions of an object or the geomorphological features of a watershed such as slope, area size and elevation. But there are many parameters that are not directly observable, at least not at the scale of modeling units. For example, parameters commonly used in hydrologic models, such as saturated soil hydraulic conductivity or saturated soil matric potential, may be observable at a point scale, but not over a large area. In this case, “effective” values must be estimated so mathematical equations established at a point scale can be extended to an areal scale (Blöschl and Sivapalan, 1995). There is a class of models known as conceptual models whose parameters are generally non-observable and are only related to physical properties indirectly. For example, the parameters in many conceptual rainfall-runoff (CRR) models are not observable and must be calibrated so model simulations closely match observations (Duan et al., 1992).How to specify system model parameters properly is not a trivial issue (Sorooshian and Gupta, 1983; Duan et al., 1992, 2006; Kavetski et al., 2003). The combined effect of several factors, including errors in observational data, choices of calibration methods and criterias, and model formulation errors, makes parameter estimation being a difficult task. This difficulty is further compounded by over-parameterization problems as today's models are getting increasingly complex in a trend to include more and more sub-physics, but the calibration of these models is still done with rather limited data (Jakeman and Hornberger, 1993; Renard et al., 2010; Clark et al., 2011). Over-parameterization, along with parameter interactions (due to high nonlinearity of model equations), causes model parameters to be not uniquely identifiable. Beven (2006) termed this phenomenon as equifinality, i.e., different parameter sets would result in the same or similar model performance measures. Another potential cause for equifinality may be due to a phenomenon known as “numerical daemon” by Kavetski and Clark (2010). One possible way to mitigate over-parameterization/non-identifiability is reducing the number of parameters to a small number that can be sufficiently calibrated with limited data.To discern which parameters have the most influence over model performance and to identify what are the most appropriate parameter values, we need to find a way to screen out sensitive parameters and quantitatively evaluate the influence of each parameter on model performance. Sensitivity analysis (SA) has been used by many people for this purpose (Liu et al., 2004; van Griensven et al., 2006; Campolongo et al., 2007; Borgonovo et al., 2012). SA can identify parameters of which a reduction in uncertainty specification will have the most significant impact on improving model performance measures. Thus, if some non-influential parameters can be identified and fixed reasonably at given values over their ranges, the computational cost may decrease without reducing model performance.There are many different SA approaches. Overall, they can be categorized into two groups: local SA and global SA. The local SA explores the changes of model response by varying one parameter while keeping other parameters constant. The simplest and most common approach is differential SA (DSA), which uses partial derivatives or finite differences of parameters at a fixed parameter location as the measure of parametric sensitivity. Though simple and intuitive, DSA measures only local sensitivity whose value is obviously location dependent. On the other hand, the global SA examines the changes of model response by varying all parameters at the same time. Generalized SA (GSA) method is one of the global SA methods that are designed to overcome the limitations of local SA methods. A version of GSA method, as implemented in Hornberger and Spear (1981), first creates a large number of random parameter sets using the Monte Carlo (MC) (Meteopolis and Ulam, 1949) sampling technique. It then breaks the random parameter sets into behavioral and non-behavioral sets based on a pre-specified threshold for acceptance of model behavior. The frequency density distributions of model performance measures along each parameter axis in the behavioral sub-set are used as indicators of parametric sensitivities. GSA forms the basis for the Generalized Likelihood Uncertainty Estimation (GLUE) method developed by Beven and Binley (1992). GSA is simple to implement and can work with different pseudo-likelihood (i.e., goodness of fit) measures (Beven, 2004), but it is computationally inefficient.Global SA approaches based on design of experiment (DOE) have gained popularity recently because they offer global sensitivity measures while maintaining computational efficiency. A typical DOE-based SA method involves two steps: first, generating a sample set of parameters within the feasible parameter spaces using a chosen design; and then, obtaining a quantitative attribution of model output variation due to the variation of different parameters. There are many sampling techniques, such as MC, Latin Hypercube (LH) (McKay et al., 1979), Orthogonal Array (OA) (Owen, 1992) and Orthogonal Array based Latin Hypercube (OALH) (Tang, 1993), which are commonly used for DOE-based SA. Some DOE-based SA methods, such as Morris One-At-a-Time (MOAT) (Morris, 1991), Fourier Amplitude Sensitivity Test (FAST) (Cukier et al., 1973), and extended Sobol’ method (Saltelli, 2002), require special sampling techniques. More recently, along with the development of response surface methods (RSM), SA based on RSM makes it cheaper for estimating parameter effects (Ratto et al., 2007; Shahsavani and Grimvall, 2011).Saltelli et al. (2008) provided a comprehensive exposition of contemporarily available SA methods. Tong (2005) developed a software package, called a Problem Solving environment for Uncertainty Analysis and Design Exploration (PSUADE) and containing a wide array of different uncertainty quantification (UQ) methods, including many SA methods. PSUADE has been used successfully for many applications. Hsieh (2006) demonstrated the process of using PSUADE for UQ of the Steven Impact Test problem. Wemhoff and Hsieh (2007) used PSUADE to calibrate the Prout–Tompkins chemical kinetic model. Tong (2008) applied a variety of UQ techniques to the study of a two-dimensional soil-foundation structure-interaction system subjected to earthquake excitation using PSUADE. Tong and Graziani (2008) described a global SA methodology implemented in PSUADE that is specifically designed for general multi-physics application of large complex system models. Snow and Bajaj (2010) adopted the PSUADE for uncertainty analysis of a comprehensive electrostatic Micro-Electro Mechanical Systems (MEMS) switch model.The aforementioned works have been focused on applying a subset of the UQ methods available within PSUADE. The purpose of this paper is to explore the effectiveness and efficiency of various SA methods in PSUDAE in identifying sensitive parameters of system models, and provide useful guidance on selecting appropriate SA procedures for other applications. We test all available SA methods with a very simple conceptual hydrologic model – Sacramento Soil Moisture Accounting (SAC-SMA) model (Burnash et al., 1973). The generality of the findings in this paper would need further works on more complex models and more catchments with different characteristics. This paper is organized as follows. Section 2 offers a brief description of the PSUADE software. Section 3 describes the model, data and experimental methods used in the study. Section 4 presents the results and discussion. And finally, we make some concluding remarks in Section 5.PSUADE is a C++ based open-source software package developed to provide an integrated design and analysis environment for performing UQ for large complex system models. This software is available via https://computation.llnl.gov/casc/uncertainty_quantification/. The flow chart for implementing PSUADE for UQ is shown in Fig. 1. The three parts in bold italic are basic elements of PSUADE:•The experimental design techniques (Sample generator)The simulator execution environment (Driver)The analysis toolset (Analysis tool)The first part, as defined in the input file “psuade.in”, is a sample generator specifying sampling technique, sample size, and parameter ranges and distributions. Sampling techniques available in PSUADE are listed in Table 1. PSUADE supports several probability density functions, such as uniform, normal, lognormal, and triangular distribution. Furthermore, it provides adaptive sampling techniques for global and local refinement.The second part provides a “non-intrusive” and user-friendly interface for linking simulation executable code and PSUADE. “Non-intrusive” means that users don't need to modify the code of the model. Users can write their own script in any programming language (PSUADE provides default template in Python or C format), which could be used as the “driver” for running a given computer model and collecting the model outputs to the output file “psuadeData”.The third part provides a variety of mathematical/statistical methods for analyzing the input–output relationships. It has a rich set of tools for basic statistical analysis, sensitivity analysis, response surface analysis, and model calibration, etc. Sensitivity analysis methods available in PSUADE are given in Table 2.This study intends to fully explore the various SA methods available in PSUADE. The SAC-SMA model is used as a test problem. This CRR model developed by Burnash et al. (1973) is the most widely used hydrological model by the River Forecast Centers (RFCs) of the U.S. National Weather Service for catchment modeling and flood forecasting. Readers who are interested in the details of this model should refer to Burnash (1995).There are sixteen parameters in the SAC-SMA model (see Table 3). We consider only thirteen of them as tunable parameters, whose feasible ranges are determined based on their physical interpretations and watershed properties, which have been widely referred to in previous literature (e.g., Duan et al., 1994; Burnash, 1995; Gupta et al., 1998; Boyle et al., 2000). Three other parameters RSERV, RIVA, and SIDE are fixed at pre-specified values according to Brazil (1988).The South Branch Potomac River basin near Springfield, West Virginia in the U.S. was chosen as the study area. The total drainage area upstream of the gauging station (U.S. Geological Survey Station No. 01608500) is about 3800 km2. Historical precipitation, potential evapotranspiration and streamflow observations from January 1st, 1960 to December 31st, 1979 were obtained from the MOPEX database for this study, where MOPEX stands for Model Parameter Estimation Experiment (Duan et al., 2006). The average annual precipitation over this period is 1021 mm, average annual potential evapotranspiration is 762 mm, and average annual runoff is 39.5 m3/s. The hydrological simulations were run at a 6-h time step over the entire data period. To evaluate model response to different parameters, we use mean absolute error (MAE) of the simulated and observed daily streamflow discharge (m3/s) as the objective function, which is a measure of average errors:(1)MAE=1N∑t=1N|Qtfcs−Qtobs|whereQtfcsandQtobsare simulated and observed streamflow discharge values at time t, N is the total number of observations. To reduce the influence of incorrect specification of initial conditions, the simulations from the first three months are excluded in the MAE calculation. Since the sensitivities of model parameters are dependent on the choice of objective functions, other objective functions such as root-mean-square error, Nash–Sutcliffe Efficiency may also be used in practical applications. This study focuses on the evaluation of the effectiveness and efficiency of different SA methods, which are not influenced by the choice of objective functions.All SA methods as shown in Table 2, except Plackett–Burman (PB) (Plackett and Burman, 1946) and Fractional Factorial (FF) (Box and Hunter, 1961) screening methods, are employed to study the sensitivities of the thirteen SAC-SMA model parameters. PB and FF methods implemented in PSUADE are designed only for two-level design experiments, i.e., the parameters can only be evaluated at two fixed levels. Therefore, it is not suited for continuously varying parameters in SAC-SMA. In addition, those methods are effective only for linear or monotonic parameter–response relationship.Correlation Analysis (CA) and Regression Analysis (RA) are traditional approaches that are extensively used to assess the strength of the association between two factors (e.g., parameter and response) due to their relatively simple theories (Crawford, 2006). CA measures parameter sensitivity by correlation coefficients, such as Pearson correlation coefficient (PEAR), Spearman rank correlation coefficient (SPEA) and Kendall tau rank correlation coefficient (KEND). These coefficients measure the strength of a linear or monotonic relationship between model parameters and model responses. In this study we take SPEA as the sensitivity measure for CA. RA evaluates parameter sensitivity by standard regression coefficient (SRC) of a regression function relating model parameters and model responses.MOAT screening is a typical One-At-a-Time (OAT) method for parameter screening (Morris, 1991). Theoretic basis of this method is that the overall effect and interaction effect of each parameter can be approximated by the mean μ and standard deviation σ of the gradients of each parameter sampled from r MOAT paths. Campolongo et al. (2007) proposed a modified mean μ∗, which is an estimate of the mean of absolute gradients, to solve the problem of the effects of opposite signs in gradients. We use the modified mean μ∗ (denoted as MOAT-1) and standard deviation σ (denoted as MOAT-2) as the MOAT sensitivity measures.Multivariate Adaptive Regression Splines (MARS), Delta Test (DT), Sum-Of-Trees (SOT) and Gaussian Process (GP) screening methods can all be regarded as certain types of RSMs, from which one can derive relative scores of parameter overall effects. MARS is an extension of linear models, which makes use of linear regression, the mathematical construction of splines, the binary recursive partitioning and brute search intelligent algorithms (Friedman, 1991; Gutiérrez et al., 2009). It calculates parameter importance scores by refitting the model after dropping all terms involving the parameter in question and calculating the reduction in goodness-of-fit. The least important parameter is the one with the smallest impact on the model quality; similarly, the most important parameter is the one that, when omitted, degrades the model fit the most (Kahng et al., 2010).DT was originally used for residual noise variance estimation. It is based on the hypotheses of the continuity of the regression function, i.e., if two sample points are close in the parameter space, the responses of these two points will be close enough in the response space. Or else, it can be explained by the influence of noise. DT was devised by Pi and Peterson (1994) for identifying parameter dependencies in continuous functions and was demonstrated and applied by Eirola et al. (2008) for parameter screening. It takes the subset of parameters that minimize the noise variance from all the parameter combinations as sensitive ones. However, this procedure needs an efficient and effective search algorithm to find this subset of parameter combinations. This search process can be too time-consuming and usually as it is impossible to do an exhaustive search of all combinations. In PSUADE, DT chooses the best 50 subsets and uses them for scoring. It assesses the final choice using forward sweep and uses genetic algorithm to speed up the search.SOT is the classification (or Bayesian) additive regression tree model based on recursive binary partitioning, which is another useful tool for parameter screening (Breiman et al., 1984; Chipman et al., 2010). Parameter space is recursively split by unbalanced binary tree according to the residual sum of squares of responses until per terminal node has minimum number of sample points. Total number of splittings for each parameter is taken as the ranking criterion.GP characterizes simulation responses over the parameter space as a multivariate Gaussian distribution. A GP can be expressed asY∼GP(μ,C), i.e., random functionYcan be specified by its mean function μ(X) and covariance functionC(X,X'). Different kinds of mean and covariance functions lead to different GPs. Tpros, which is a program written by Gibbs and MacKay (1997) for regression problem using GP, is adopted in PSUADE for parameter screening. Theoretical basis of this approach is that points which are close in parameter space give rise to similar values of response values. A length scale can be found for each parameter that characterizes the distance in a particular parameter direction over which response is expected to vary significantly. A small length scale for a parameter means a more significant influence of this parameter on model response.FAST, McKay main effect (McKay-1) and two-way interaction effect (McKay-2) analysis, and Sobol' sensitivity indices (Sobol) are all variance-based methods which can be used to quantify the main effect and interaction effect of the parameters. FAST was presented by Cukier et al. (1973) for nonlinear SA of multi-parameter model, in which conditional variances are represented by coefficients from the multiple Fourier series expansion of the response function and the ergodic theorem is applied to transform the multi-dimensional integral into a one-dimensional integral in evaluation of the Fourier coefficients.McKay-1 makes ANOVA (i.e., analysis of variance)-like decomposition of response variances for calculating correlation ratio, which is a ratio of the variance of expectation conditioned on one parameter and the total variances of response (McKay, 1995). The significance of parameter main effect increases with the parameter correlation ratio. Tong (2005) extended the idea for main effect analysis to two-way interaction effect analysis for uncorrelated parameters (i.e., McKay-2). A high second-order correlation ratio of any two parameters means that they are taken together as important contributors to the response variability.Another variance-based method in PSUADE is proposed by Sobol' (1993, 2001), which also makes ANOVA-like decomposition of response variances for calculating specific order sensitivity indices. In practice, only the first-order and second-order Sobol' indices are estimated since the number of interaction terms need to be computed for higher order indices will increase exponentially when the number of parameters increases. The statistic “total sensitivity indices”, STi= Si+ Si,ci= 1−Sci, introduced by Homma and Saltelli (1996) offer a simple way of evaluating the total effects for each parameter. Where Si(first-order indices) and Si,ci(high-order indices) represent the main effects and interaction effects of parameter i, respectively; and Sciequals the sum of all the other terms except for the terms related to parameter i. PSUADE provides a response surface based Sobol' SA tool for calculating Sobol' first-order (Sobol-1), second-order (Sobol-2) and total (Sobol-t) indices, which makes the computational cost of Sobol' indices cheaper than the direct calculation based on the original model. The default response surface for Sobol' SA is MARS approach. We take the Sobol-1 and Sobol-t as the Sobol' sensitivity measures.All SA methods described above must use sampling techniques to create samples of parameter sets. The most concerned problems in designing a deterministic experiment are whether the sample points are “space-filling” in the design space (Sacks et al., 1989) and how many sample points are sufficient for the experiment (Loeppky et al., 2009).Among all the sampling techniques available in PSUADE (see Table 1), MC sampling has the longest history and is the most commonly used technique. MC generates sample points randomly from a probability density function over the parameter space. However, large sample size is required to be able to fully explore the parameter space.To improve the representativeness of sample points, McKay et al. (1979) proposed LH sampling. For a n-dimension p-level parameter space, only p sample points are generated by LH sampling, whereby each level exists only once when sample points are projected to any single dimension. Sample size of replicated LH (rLH) sampling is N = λ × p, where λ is the replication times. LH sampling became popular in the 1980s, and a lot of improvements have since been made to it. For example, Owen (1992) used OA to define the generalization of LH sampling. For a n-dimension p-level parameter space, an OA sampling of strength t (t < n) generates ptsample points, such that all possible level combinations for every t-dimension p-level subspace occur exactly once. Sample size of replicated OA (rOA) sampling is N = λ × pt, where p should be a prime number or 4, and t is usually set to 2. Clearly, a strength one OA sampling is equivalent to a LH sampling. Meanwhile, Tang (1993) presented OALH sampling, which uses OA to construct LH. A strength t OALH sampling not only preserves the stratification properties of LH sampling in single-parameter space, but also in t-dimensional space. The sample size of OALH sampling is the same as that of OA sampling.Besides the aforementioned sampling techniques, some other “space-filling” methods also have received much attention over the past few decades. For example, Karypis and Kumar (1998) introduced METIS method for partitioning large irregular graphs and large meshes, and computing ﬁll-reducing orderings of sparse matrices, which is based on multilevel graph partitioning algorithms. Statnikov and Matusov (2002) described LPτ (LPTAU) method for generating deterministic and uniformly distributed sequence of points in a multidimensional space, which provides a way to add more sample points to the initial sample with the same uniformity characteristics.Also, there are some sampling techniques that were designed for specific SA methods, e.g., the sampling techniques for FAST analysis (Cukier et al., 1973), MOAT screening (Morris, 1991) (denoted same as corresponding SA methods), and the sampling technique proposed by Saltelli (2002) for Sobol' sensitivity indices (denoted as SOBOL). They are generally based on simple random sampling, and different conditions need to be satisfied for their sample sizes. FAST transforms a multi-dimensional integral into a one-dimensional integral. Different forms of transformation lead to different distributions of sample points. Minimum sample size of the classic FAST is determined by N = 2 × Ms× ωmax + 1, where Msis the maximum harmonic which should be no less than 4 (usually taken to be 4 or 6) and ωmax is the maximum frequency which is determined by the number of factors.As for MOAT sampling, range of each parameter is partitioned into p−1 equal intervals, thus the parameter space is an n-dimension p-level orthogonal grid, where each parameter can take on values from these p predetermined values. First, r points (r × n sample matrix M0, each row is a n-dimension sample point) are randomly generated from the orthogonal grid; and then, for each of the r points, other sample points are generated by perturbing one dimension at a time under a p/[2 × (p−1)] space step until all the n dimensions have been varied for only one time. Therefore, total sample points will be (n + 1) × r.Sampling technique of SOBOL is similar to that of MOAT. It starts with two random r × n sample matrices M0 and Mn+1 (each row is an-dimension sample point). For each of the r sample points, the ith (i from 1 to n) sample point is generated from both two matrices, where the ith column is the same as Mn+1 while other columns are the same as M0. Thus the total number of sample points will be (n + 2) × r.In evaluating each SA method, we attempt to answer the following questions:(1)Is the method capable of identifying sensitive and insensitive parameters correctly? (effectiveness)Given that a method is effective, what is the minimum number of samples for each specific sampling technique? (efficiency)Table 4shows the experimental setup for analyzing the effectiveness of different SA methods. Of the ten SA methods (McKay-1 and McKay-2 are taken as one method), the first seven are qualitative methods and the last three are quantitative ones. Qualitative methods provide a heuristic score to intuitively represent the relative sensitivity of parameters, while quantitative methods tell how sensitive the parameter is by computing the impact of the parameter on the total variance of model output. A brief description of different SA measures is given in Appendix A. Sampling techniques used for these SA methods are selected according to the recommendation from PSUADE user's manual. A rough rule of thumb about the sample size is that at least 10 × n sample points are needed to identify key factors (i.e., parameters), where n is the number of experimental factors (Levy and Steinberg, 2010). In order to get reliable SA results, we set the maximum sample sizes to between 2777 and 3000, which are more than twenty times the required minimum sample size 130 (=10 × 13). The detailed settings of sample sizes are illustrated as follows. Sample sizes of MC, METIS and LH sampling are set to 3000 since there are no specific requirements for them. Sample size of OA sampling is set to 2890 (=10 × 172). As for FAST, the maximum harmonic Ms= 4, and the maximum frequency ωmax = 347 when n = 13. Therefore, the minimum sample size of FAST is 2777. For MOAT and SOBOL sampling techniques, we use 200 replications, resulting in sample sizes of 2800 and 3000, respectively.All suitable sampling techniques as described above are used to explore the efficiency of effective SA methods. Sample size starts from a large one (result of which will be taken as the benchmark) and decreases sequentially to the minimum size in order to know exactly how many sample points are sufficient for specific sampling techniques. Detailed experimental setups for efficiency analysis of different SA methods are illustrated together with their results.

@&#CONCLUSIONS@&#
