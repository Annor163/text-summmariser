@&#MAIN-TITLE@&#
Bayesian dynamic probit models for the analysis of longitudinal data

@&#HIGHLIGHTS@&#
A dynamic probit model with a first order Markov process was developed.Gibbs sampler using data augmentation approach and forward filtering backward sampling algorithm were presented.The discussion was extended to propose models to generalized models including Studentt-link function.Model fit was compared between static and dynamic probit models.

@&#KEYPHRASES@&#
Markov models,Bayesian inference,Longitudinal data,Dynamic linear models,Model selection,

@&#ABSTRACT@&#
The authors consider a dynamic probit model where the coefficients follow a first-order Markov process. An exact Gibbs sampler for Bayesian analysis is presented for the model using the data augmentation approach and the forward filtering backward sampling algorithm for dynamic linear models. The authors discuss how our approach can be used for dynamic probit models as well as its generalizations including Markov regressions and models with Student link functions. An approach is presented to compare static and dynamic probit models as well as for Markov order selection in these classes of dynamic models. The developed approach is implemented to some actual data.Time varying coefficient models for categorical longitudinal data have been considered by authors such as Carlin and Polson (1992), Shephard and Pitt (1997), Gamerman (1998), Kauermann (2000), and more recently by Fruhwirth-Schnatter and Fruhwirth (2007). Most of the previous works have considered logit-type state-space models. As noted by Fruhwirth-Schnatter and Fruhwirth (2007), Markov chain Monte Carlo (MCMC) approaches proposed by Shephard and Pitt (1997) and Gamerman (1998) for the analysis of these models are based on the Metropolis–Hastings algorithm which requires specification of a proposal density in high dimensions. To alleviate this, the authors proposed a data augmentation based MCMC method for analysis of dynamic logit models. A simple version of a dynamic probit model has been considered by Andrieu and Daucet (2002) where the authors used particle filtering for Bayesian analysis.In what follows, we consider probit-type state-space models and develop an exact Gibbs sampler for Bayesian analysis of this class of models. Our approach is an extension of the data augmentation approach of Albert and Chib (1993) to dynamic probit models where we implement the forward filtering backward sampling algorithm of Fruhwirth-Schnatter (1994). Our approach can be easily generalized to considertdistribution link functions that can be used to consider logit type dynamic models as well as Markov regression models.We consider a binary time seriesXtand we define a dynamic probit model similar to that considered by Andrieu and Daucet (2002) as(1.1)Pr{Xt=1∣πt}=πtwithπt=Φ(Ftθt),whereFtis a1×Kcovariate vector andθtis aK×1vector of regression parameters. We define the dynamic nature of the model via a state equation forθtas(1.2)θt=Gθt−1+wtwithwt’s are uncorrelated multivariate normal error vectors with mean 0 and covariance matrixWθandGis the specified transition matrix of the model. It is most common to assume thatGis an identity matrix implying a steady model in the sense of West and Harrison (1997). Thus, in our development we consider(1.3)θt=θt−1+wt.The procedure can be easily extended for a general known transitionGas well as for certain cases whereGis unknown.We can extend this for longitudinal data for individualsi=1,…,M. In this case we write the above model as(1.4)Pr{Xit=1∣πit}=πitwithπit=Φ(Fitθt),and assume the same state equation (1.3) for all individuals.In Section  2, we introduce Bayesian inference for dynamic probit models and illustrate how an exact Gibbs sampler can be used. Extensions to Markov regression models and Student-tlink functions are considered in Section  3. We illustrate how marginal likelihoods can be obtained and used to compare static versus dynamic probit models in Section  4. We also discuss how the marginal likelihood computations can be easily extended for Student-tlink function case and thus can be used for selecting degrees of freedom. Implementation of our approach is illustrated in Section  5 using real data from the Great Smoky Mountains Study of Costello et al. (1996).We first consider the case for theith individual Following Albert and Chib (1993), we can define the above model by using independent latent variablesZitsuch that(2.1)Xit={1ifZit>00Otherwise .If we assume thatZit’s are normally distributed with meanFitθtand variance 1, that is,Zit∼N(Fitθt,1), then we have the probit model(2.2)πit=Φ(Fitθt).Given the above setup, we can develop a Gibbs sampler for the inference using the data augmentation algorithm of Albert and Chib (1993) with the algorithm proposed by Fruhwirth-Schnatter (1994) for dynamic linear models.Given observed dataD={Xit;t=1,…,T}, we can design a Gibbs sampler using full posterior conditional distributionsp(Θ∣D,ZiT)andp(ZiT∣D,Θ)with vectorsΘ=(θ1,θ2,…,θT)andZiT=(Zi1Zi2⋯ZiT). In obtainingp(ZiT∣D,Θ), we note thatZit’s are independent random variables and use(Zit∣θt,Xit=1)∼N(Fitθt,1)I(Zit>0),and(Zit∣θt,Xit=0)∼N(Fitθt,1)I(Zit≤0).In the implementation of the Gibbs sampler, we can directly draw from the joint posterior distribution ofp(θ1,θ2,…,θT∣ZiT)using the forward filtering backward sampling algorithm of Fruhwirth-Schnatter (1994) which is given in West and Harrison (1997) for Kalman filter type models. It is possible to adopt the algorithm for our case as will be discussed next.We defineZit=(Zit−1,Zit),t=1,…,Tand note that, similar to the Bayesian dynamic linear models of West and Harrison (1997), using the Markov structure of our model we can writep(θ1,θ2,…,θT∣ZiT)as(2.3)p(θT∣ZiT)p(θT−1∣θT,ZiT−1)⋯p(θ1∣θ2,Zi1),where the first termp(θT∣ZiT)is available from standard DLM updating. We can start the sampling fromθTand then sequentially sampleθT−1,…,θ1using densitiesp(θt−1∣θt,Zit−1)fort=T−1,…,2. The required distributions can be obtained using the state equation of the DLM. It follows from the DLM setup that(2.4)(θt−1∣θt,Zit−1)∼Normal(ht−1,Ht−1),where(2.5)ht−1=mt−1+Ct−1Rt−1(θt−mt−1),(2.6)Ht−1=Ct−1+Ct−1Rt−1Ct−1,(2.7)mt=mt−1+RtFit′(1+FitRtFit′)−1et,and(2.8)Ct=Rt−RtFit′(1+FitRtFit′)−1FitRt.In the above setup,et=Zit−Fitmt−1is a scalar, andRt=Ct−1+Wθ.In the case where we have a prior onWθwhich is an inverse Wishart form given by(2.9)Wθ−1∣Σ,r∼Wish(Σ,r),where the scale matrixΣand degrees of freedomr>Kare known quantities, the above results will be all conditional onWθ. The full conditional ofWθis again a Wishart density with degrees of freedom,(r+T), and scale matrix(Σ+∑t=1T(θt−θt−1)(θt−θt−1)′).When we consider data fromMindividuals forTtime periods given byD={Xit;t=1,…,T;i=1,…,M}whereXit’s are conditionally independent across the individuals as well as time, we defineZtas aM×1vector of latent variablesZit. We now assume thatZthas a multivariate normal distribution with independent components denoted asZt∼N(Ftθt,IM)whereFtis aM×Kmatrix of covariates andIMis anM×Midentity matrix. SinceZit’s are conditionally independent random quantities, their full conditionals will stay the same. In updatingθt’s we will have(2.10)mt=mt−1+RtFt′(IM+FtRtFt′)−1etwithet=Zt−Ftmt−1,Rt=Ct−1+Wθand(2.11)Ct=Rt−RtFt′(IM+FtRtFt′)−1FtRtwhereetis aM×1vector. Updating ofWθwill stay the same. Thus, the proposed approach provides an exact Gibbs sampler for Bayesian inference in the dynamic probit model (1.1) with evolution equation (1.2).In the sequel, we consider two extensions of the dynamic model and the Bayesian inference introduced in the above. More specifically, we first illustrate how Markov regression models, including nonhomogeneous Markov chains, can be represented using the dynamic setup. Next, we discuss how a student-tlink function can be used instead of a normal link function in our development.We consider aq-th order nonhomogeneous Markov chain model defined as(3.1)Pr{Xit=1∣πit,Xi,t−1,…,Xi,t−q}=πitwithπit=Φ(Fitθt),whereFit=(1Xi,t−1⋯Xi,t−q)andθt=(θ0tθ1t⋯θqt)′.Thus, the transition probabilityπitis given by(3.2)πit=Φ(θ0t+∑j=1qθj,tXi,t−j).Forq=1we obtain the first-order chain modelπit=Φ(θ0t+θ1,tXi,t−1),implying a transition matrix(3.3)Pt=[Φ(θ0t+θ1,tXi,t−1)1−Φ(θ0t+θ1,tXi,t−1)Φ(θ0t)1−Φ(θ0t)].The above model provides a nonhomogeneous extension of Bayesian Markov regression models of Erkanli et al. (2001) who used logistic link functions. It also gives an alternative class of Bayesian nonhomogeneous Markov chain models considered in Sung et al. (2007).We note that the transition probabilities can also be dependent on covariates and such dependence can be easily incorporated by defining components ofFitθtaccordingly. The Bayesian inference results presented in the previous section can be easily used for analysis of the model.The dynamic probit model setup can be easily generalized to consider at-distribution link function in (2.2). To achieve this, following Albert and Chib (1993), we can assume in (2.1) thatZit’s are student-tdistributed independent random variables with locationFitθt, scale 1, and degrees of freedomη. Thus, we can write (2.2) as(3.4)πit=T(Fitθt),whereT(⋅)denotes the student-tcdf. As noted by the authors, the above can be equivalently obtained as a scale mixtures of normal distributions by assuming unknown scale parametersλi’s forZit’s such that(3.5)(Zit∣θt,λi)∼N(Fitθt,λi),whereλi’s are independent Gamma random variables with shapeη/2and scaleη/2, denoted as(λi∣η)∼Gamma(η/2,η/2).Under the above setup the Gibbs sampler of Section  2 can be easily modified. More specifically, now, in obtaining the full posterior conditional distributions ofZit’s, which are conditional onλi’s, we use(Zit∣θt,λi,Xit=1)∼N(Fitθt,λi)I(Zit>0),and(Zit∣θt,λi,Xit=0)∼N(Fitθt,λi)I(Zit≤0),fort=1,…,T;i=1,…,M.The full conditional distribution ofθt’s, now conditional onλ=(λ1,…,λM)as well, will be normal distributions with mean vector and covariance matrix (2.10) and (2.11), respectively, whereIMis replaced by theM×Mdiagonal matrix(3.6)V=diag[1/λ1,…,1/λM].The full conditionalWθwill still be the Wishart distribution as in Section  2.In obtaining the full conditional ofλi’s, we note that givenθt’s and(T×1)vectorsZi=(Zi1,…,ZiT),i=1,…,M,λi’s are independent of each other. It can be easily shown that the full conditional ofλiis given by the Gamma distributionGamma(ai,bi)where(3.7)ai=(η+T)/2andbi=12[η+∑t=1T(zit−Fitθt)2],fori=1,…,M.It is possible to learn aboutηas discussed in Albert and Chib (1993). If we use a discrete prior forη, sayp(η), then it can be easily shown that the full conditional posterior distribution ofηis proportional to the discrete distribution(3.8)p(η)(η/2)η/2Γ(η/2)∏i=1Mλiη/2−1e−λiη/2.The posterior distribution ofηenables us to infer about different link functions. For example, concentration of the posterior distribution at larger values ofηsuggests the appropriateness of probit link. On the other hand, if it concentrates around degrees of freedom 8 or 9 then it suggests a logistic link function.Note that alternatively, we can compute the marginal likelihood for different values ofηand compare different models. This will be discussed in Section  4.As pointed by Kass and Raftery (1995), Bayesian model comparison/selection is made using Bayes factors which are obtained as the ratio of marginal likelihoodsp(D∣i)under two competing modelsi=1,2. In many problemsp(D∣i)is not available in an analytical form and its evaluation using posterior Monte Carlo samples is not a trivial task. Thus, various alternatives to marginal likelihoods have been suggested for model selection using Monte Carlo samples; see for example Gelfand (1996).However, in certain problems where a Gibbs sampler is used and all the full conditional distributions are known, it is possible to approximate the marginal likelihoods from the posterior samples using a method introduced by Chib (1995). For example, Chib (1995) showed how marginal likelihoodp(D∣i)can be obtained for the static probit regression modeliwith a given set of independent variables. In so doing, Chib (1995) used the data augmentation approach of Albert and Chib (1993) and discussed the computation ofp(D∣i)from the Gibbs sampler output. In what follows we will illustrate how the approach by Chib (1995) can be extended for the dynamic probit model and discuss how the approach can be used for Markov regression model order selection. Thus, we present a Bayesian approach for order selection in nonhomogeneous Markov chains which have not been considered by Sung et al. (2007).Note that suppressing dependence on modelithe marginal likelihood for a particular model is expressed as(4.1)p(D)=p(D∣Θ)p(Θ)p(Θ∣D),whereΘis a vector of parameters. As pointed out by Chib (1995) the above holds for any value ofΘ, sayΘ∗, and the value of posterior densityp(Θ∗∣D)can be estimated bypˆ(Θ∗∣D)using Monte Carlo samples. Sincep(D∣Θ∗)andp(Θ∗)can be evaluated atΘ∗, the log marginal likelihood can be estimated as(4.2)lnpˆ(D)=lnp(D∣Θ∗)+lnp(Θ∗)−lnpˆ(Θ∗∣D).In evaluating (4.2), the only term which is not readily available ispˆ(Θ∗∣D), but as shown in Chib (1995) this can be obtained using the outputs from the Gibbs sampler.In our case, we also have the latent variablesZT=(ZjT;j=1,…,M)and the parameter vectorΘ=(θ1,θ2,…,θT,Wθ−1). To estimatep(Θ∗∣D)we need the full conditionalsp(ZT∣Θ,D)andp(Θ∣ZT,D), that are available to us. We can write(4.3)p(Θ∗∣D)=∫p(Θ∗∣ZT,D)p(ZT∣D)dZT,and note that we have samples available fromp(ZT∣D)via the Gibbs sampler. Thus, (4.3) can be approximated as(4.4)p(Θ∗∣D)≈1G∑g=1Gp(Θ∗∣(ZT)(g),D),where(ZT)(g)are samples from the posterior distributionp(ZT∣D). Note thatp(Θ∗∣ZT,D)can be written as(4.5)p(θT∗∣ZT,Wθ−1∗)p(θT−1∗∣θT∗,ZT−1,Wθ−1∗)⋯p(Wθ−1∗∣ZT).In (4.5) all terms are immediately available except the last one, that is,p(Wθ−1∗∣ZT). We can obtain this term as(4.6)p(Wθ−1∗∣ZT)=∫p(Wθ−1∗∣θT)p(θT∣ZT)dZT,whereθT=(θ1,…,θT). The above can be approximated as(4.7)p(Wθ−1∗∣ZT)≈1G∑g=1Gp(Wθ−1∗∣θ1(g),…,θT(g)),whereθ1(g),…,θT(g)are samples from the posteriorp(θ1,…,θT∣ZT). Note thatp(Wθ−1∗∣θ1,…,θT)is the full conditional which is a Wishart density.Thus, all components of (4.2) are now available and we can evaluatelnpˆ(D)for a given model as reflected by the order of the Markov process and/or by the variables included in (3.1).The marginal likelihood computation can be easily adopted for the Student-tlink function case considered in Section  3.2. In fact,lnpˆ(D)can be computed for different degrees of freedom values,η. In this case, the only additional number of parameters isλ=(λ1,…,λM), that is, we haveΘ=(θ1,…,θT,λ,Wθ−1). Thus, (4.5) will be given by(4.8)p(θT∗∣ZT,λ∗,Wθ−1∗)⋯p(θ1∗∣θ2∗,Z1,λ∗,Wθ−1∗)p(Wθ−1∗∣ZT)p(λ∗∣ZT),where the firstTterms ofθT∗’s will still be available as normal densities,p(Wθ−1∗∣ZT)can still be obtained via (4.7). In order to evaluatep(λ∗∣ZT)we can use(4.9)p(λ∗∣ZT)=∫p(λ∗∣ZT,θT)p(θT∣ZT)dθT,which reduces to(4.10)p(λ∗∣ZT)=∫∏i=1Mp(λi∗∣Zi,θT)p(θT∣ZT)dθT,wherep(λi∗∣Zi,θT)is a Gamma density with parametersaiandbigiven by (3.7). Note that (4.10) can be approximated as(4.11)p(λ∗∣ZT)≈∏i=1M1G∑g=1Gp(λi∗∣Zi,θ1(g),…,θT(g)),whereθ1(g),…,θT(g)are samples from the posterior distributionp(θ1,…,θT∣ZT)as before.As pointed out by one of the reviewers, an alternative way of estimating the marginal likelihood (4.1) using Chib’s (1995) approach is to marginalize over the state variables. In this case, the termp(Θ∗∣D)in the denominator of (4.1) will not depend on the values ofθt’s. Since we do not have a Gaussian likelihood, this would require computation of the likelihood of the model by the particle filtering methods. Even though this might lead to a more efficient estimate of the marginal likelihood, it is not obvious in our problem that the Monte Carlo error accumulated by the particle filter would be small. This would require further investigation which is outside the scope of our paper.Implementation of the proposed exact Gibbs sampler for the dynamic probit models and the order selection approach are illustrated using real life longitudinal data in Section  5.In this section, dynamic probit model and Markov regression model representations, discussed in previous sections, are applied to real data from the Great Smoky Mountains Study (GSMS) (Costello et al., 1996), which is a population based study of youth from western North Carolina counties. The data consists ofM=257subjects who entered the study at age 11 for six annual waves. The binary response variableXittakes the value 1 if thei-th subject reported any use of substances including tobacco, alcohol, and other drugs in the last 3 months of interview conducted yearly around the subject’s birthday fort=1,…,6. Our primary concern here is to assess the gender difference on the progression of substance use over a span of six years.We consider two classes of models in analyzing the data. More specifically, we use probit and Markov regression models to analyze the data. In so doing, in both cases we consider dynamic and static versions of these models and compare their performances.In the dynamic probit model for the probability of substance use at timetwe specifyFit=(1SexiAgeit)andθt=(θ1tθ2tθ3t)′. In the model,θ2tandθ3trepresent the effect of sex (coded 1 for male and 0 otherwise) and age, respectively, on the probability of substance use. In the case of the static probit model, we setWθ=0in (1.3) and obtainθt=θfor allt. Thus, in the static model, we haveθt=(θ1θ2θ3)′for allt.In the dynamic probit model, we set the prior mean and variance matrix ofθ0in standard DLM,m0=(0,…,0)′,C0=diag(10,…,10)whose dimensions areK×1andK×Krespectively. The Wishart prior onWθ−1hasr=Kdegrees of freedom andR=diag(0.1,…,0.1)is ofK×Kdimension. Note that in our caseK=3.Both the dynamic and static models were estimated using the approach presented in Section  2. The approach was implemented in R version 2.12.1 (2005). The inferences were made based on 50,000 posterior samples after 5000 burn-in iterations.Table 1presents the summary statistics for posterior distributions of the mean of continuous latent variableZitthat is,Fitθt, for the dynamic probit model. While the posterior mean values are higher in general for boys than girls except fort=4–5(ages 14 and 15), the values are increasing with time thus resulting in a higher probability of using substances for higher ages.The posterior distributions ofπit’s for the dynamic probit model are illustrated in Fig. 1. As indicated in Table 1, the risk of using substances increased with age but the rate of increase showed quite different pattern before and aftert=5(age 15). In comparison between boys and girls, boys had higher risk than girls overall except ages 14 and 15. When the actual data were overlaid on top of box plots of posterior distributions forπit’s, we can visually see that the posterior distributions quite well represent actual patterns of probability over time for both boys and girls. However, as illustrated in Fig. 2where the patterns ofπit’s, are monotonic, the fit of the static model to the actual data did not seem to be as good as that of the dynamic model. Later in this section the static and dynamic models will be compared using Bayes factors.We next consider dynamic and static forms of the Markov regression models. More specifically, we consider a first order dynamic Markov model withFit=(1SexiAgeitXi,t−1)andθt=(θ1tθ2tθ3tθ4t)′where the sex and age effects are defined the same as before. In this caseθ4trepresents the dependence of current substance use,Xit, on past substance useXi,t−1. The static first order Markov regression model is similarly defined asFit=(1SexiAgeitXi,t−1)andθt=(θ1θ2θ3θ4)′.Fig. 3illustrates how the transition probabilities change over time given the previous status of substance use. For illustrational purposes, only the results for boys are presented. The posterior mean of transition probabilities over time given no previous substance use (state 0) is represented by a solid line and the transition probabilities given previous substance use (state 1) is represented by a dashed line. Dotted lines show 95% posterior credible intervals for each group. We can infer that while the probability of using substances is considerably higher for the group of previous users than nonusers, the risk is increasing with age.Fig. 4compares transition probabilities of using substances for previous users and nonusers using the static Markov regression model. Again, we just show the results for boys. As in the dynamic Markov regression model, the risk of using substances increases with age and the previous substance use. However, the model shows more of a monotonic increase in risk by age and does not show the dynamic change of effect of age on the risk of substance use.To implement a dynamic model witht-distribution link function, we assume that the prior for the scale parameterλiin (3.5) follows a Gamma distribution with shapeη/2and scaleη/2parameters. The prior for degrees of freedomηis assumed to follow a uniform discrete distribution with a finite set {4, 8, 16}. The mode of the posterior degrees of freedom was at the largest value 16. We also fitted several models of thet-distribution link function with specified degrees of freedom of 4, 8, and 16. Posterior means of the probability of substance use are compared to those from the probit link model in Fig. 5. For ease of comparison, the posterior means of probabilities are transformed into logit and the differences in the logits betweent-link and probit models against probit model probabilities are shown in Fig. 5. The differences betweent-link with 4 degrees of freedom are marked with a square for given probit probabilities. Similarly, circle and triangle are used fort-link with 8 degrees of freedom and with 16 degrees of freedom respectively. As we can see from the figure, as expected, thet-link with small values of degrees of freedom has larger absolute differences from the probit model than the model with high values of degrees of freedom.The mixing of the sampling algorithm developed in the present study is evaluated by the simulation inefficiency factors (SIF) as used in Kim et al. (1998). SIF is estimated as the variance of the sample mean divided by the variance of the sample mean from a hypothetical sampler that draws independent random observations from the posterior distribution. (See Meyer and Yu, 2000 for the computation of SIF.) SIF is interpreted as the number of successive iterations needed to obtain near independent draws, thus lower is better. Table 2shows SIF’s for the parameter of sex effect,θ2tfort=1,…,6, and1j-th entry ofWθ−1matrix forj=1,2,3. Overall SIF values are small and indicate that the chains mix well. Static models show better mixing than dynamic models. Models with at-link function are less efficient than probit models for posterior sampling. The values of SIF for other parameters also showed similar patterns indicating fast mixing.Then, sensitivity analysis was conducted to evaluate the effects of different priors on the posterior inferences of parameters. We consider the two different priors for prior mean and variance matrixm0,C0, and the Wishart priorR.Prior 1:m0=(0,…,0)′,C0=diag(10,…,10),R=diag(0.1,…,0.1).m0=(0.5,…,0.5)′,C0=diag(20,…,20),R=diag(0.05,…,0.05).We computed marginal likelihoodslnpˆ(D∣Modeli)using our development in Section  4 to obtain Bayes factors among the proposed models. The estimated marginal likelihoods for the static and dynamic models are shown Table 4. We note that the log of the Bayes factor in favor of dynamic probit model is around 37.3 implying very strong support for the dynamic model.Such a comparison was also made using the first order Markov regression models. This is shown in Table 5. Again we see from the table that the dynamic Markov regression model is supported very strongly by the data as implied by the Bayes factor of 336.97 to 1 in favor of the dynamic model against the static model.Furthermore, if we compare Tables 4 and 5, we note that the inclusion of the previous period’s substance use in the Markov regression model improves the model fit relative to the dynamic probit model.For comparison of the dynamic probit model witht-link function,Φ(Fitθt∗)in (2.2) was replaced withT(Fitθt∗)withηdegrees of freedom. We considered dynamic models with degrees of freedomη={4,8,16,64,200}and obtained the marginal likelihoods. These are shown in Table 6. As can be seen from the table, the model withη=200degrees of freedom had the most support of the data. We note that as the degree of freedomηbecomes large, the log likelihood is getting closer to the value of −840.79 of the probit dynamic model in Table 4. Thus, our analysis suggests that the dynamic probit model is more appropriate for the data than the dynamic models witht-link functions. For example, the log Bayes factors in favor of the dynamic probit model against the dynamic logistic (that is,η=8) is about 61.75.In this paper, we presented an exact Gibbs sampler for Bayesian analysis of the models using the data augmentation approach of Albert and Chib (1993) and the forward filtering backward sampling algorithm of Fruhwirth-Schnatter (1994) for dynamic linear models. We discussed how the marginal likelihoods of these models can be approximated using the approach of Chib (1995). As extensions, we considered Markov regression models where the previous states were given, and estimated transition probabilities. In addition, we generalized the dynamic probit model witht-distribution link function. The models were implemented using real binary data on substance use over time. The models were compared using marginal likelihoods computed from the posterior samples. Our analysis showed that while dynamic models had a better fit than the static models, the dynamic probit models performed a lot better than the dynamic modelst-distribution link functions.

@&#INTRODUCTION@&#


@&#CONCLUSIONS@&#
