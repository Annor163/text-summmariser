@&#MAIN-TITLE@&#
Keep the driver in control: Automating automobiles of the future

@&#HIGHLIGHTS@&#
Driver-initiated automation leads to increased workload and decreased trust.Driver protocols and behavioural observations highlight systems design issues.Recommendations for future systems development discussed.

@&#KEYPHRASES@&#
Automation,Driver trust,Driver workload,Thematic analysis,

@&#ABSTRACT@&#
Automated automobiles will be on our roads within the next decade but the role of the driver has not yet been formerly recognised or designed. Rather, the driver is often left in a passive monitoring role until they are required to reclaim control from the vehicle. This research aimed to test the idea of driver-initiated automation, in which the automation offers decision support that can be either accepted or ignored. The test case examined a combination of lateral and longitudinal control in addition to an auto-overtake system. Despite putting the driver in control of the automated systems by enabling them to accept or ignore behavioural suggestions (e.g. overtake), there were still issues associated with increased workload and decreased trust. These issues are likely to have arisen due to the way in which the automated system has been designed. Recommendations for improvements in systems design have been made which are likely to improve trust and make the role of the driver more transparent concerning their authority over the automated system.

@&#INTRODUCTION@&#
Whilst it is technically feasible to achieve full vehicle automation (Brookhuis et al., 2008), there is growing concern within the Ergonomics and Human Factors community that the role of the driver is not being fully recognised or designed (Norman, 1990; Stanton et al., 2007). Whilst systems designers focus on the tasks that can be automated within the driving system, the driver is left to complete all of the leftover tasks (see Bainbridge, 1983 for a discussion on the ironies of automation). Indeed, ‘hands and feet free’ driving has viable since the early 1990's (for a comprehensive review see Dickmanns, 2002) with each facet of technology being a stepping stone to an increased level of autonomy. Even if the vehicle is capable of controlling all of the physical and cognitive tasks associated with driving, it is unlikely that drivers will willingly become disengaged completely from the task (Banks and Stanton, 2014). This is because in their new supervisory role, they must remain aware of the status of multiple vehicle systems at the same time and respond accordingly in situations where malfunction or failure occurs (Cuevas et al., 2007; Dehais et al., 2012; Stanton et al., 2006; Walker et al., 2009a, 2009b).The automation of longitudinal and lateral control is not an entirely new concept (e.g. Young and Stanton, 2007). However, market-ready technologies have typically aimed at supporting the driver in different driving tasks ranging from navigation support to supporting the driver to stay in lane or maintain speed. This is known as function specific assistance (NHTSA, 2013). However, over recent years, combined function assistance (NHTSA, 2013) has sought to assist the driver in both longitudinal and lateral control. A number of vehicle manufacturers have introduced their own versions of highly automated system architectures to this specification (e.g. General Motor's Super Cruise, Fleming, 2012; Mercedes Distronic Plus with Steering Assist, Daimler, 2013). For safety reasons all of these systems require the driver to permanently monitor the road ahead as well as monitor vehicle systems (Stanton et al., 2011) despite delegating much of the physical workload to the automated system. Although the concept of driver support has often been associated with bypassing human control inputs in an effort to eliminate driver error (Brookhuis et al., 2001), some systems require drivers to intermittently place their hands back on the steering wheel as measured through torque sensor measurements (Pohl and Ekmark, 2003) in an effort to keep the driver in control. However, a proposed driver-initiated system of automation goes further than this and would consider the driver as the key social agent within the system network who is still responsible for overall system safety (Parasuraman and Wickens, 2008) despite much of the physical workload being delegated to the automation. A driver-initiated command and control system, in its most basic form, can be described as a form of management infrastructure (Harris and White, 1987) requiring the driver and automated system to communicate and coordinate their behaviour in order to achieve a common goal (Hoc et al., 2009). The term ‘driver-initiated’ infers that the driver is able to exercise their control and authority over the automated system, keeping them in control of the planning, directing and control of when the resources available from the automation will be used (e.g. Builder et al., 1999). Although command and control socio-technical systems are typically associated with Air Traffic Control (Shorrock and Straeter, 2006; Walker et al., 2010) and military teams (Walker et al., 2009a, 2009b), this paper provides a novel application to the driving domain.The primary purpose of this study was to conduct an initial assessment of a prototype driver-initiated automated control system that combined longitudinal, lateral and auto-overtake capabilities. Driver-initiated design of the overtake manoeuvre meant that an automatic overtake could be performed by the system on the proviso that permission was granted by the driver as signalled by indicator initiation. The main purpose of which was to assess the systems design effects on subjective reports of driver mental workload and trust using direct observational methods as well as some insight into the design of the Human–Machine Interface (HMI). Trust and workload are important concepts to consider in the future implementation of higher level autonomy because inappropriate levels of trust may lead to disuse (i.e. drivers reject the potential benefits of the system) or misuse (i.e. drivers become complacent) (Parasuraman et al., 1993). In addition, a ‘negative’ first time experience in using the system could lead drivers to reject the system completely (i.e. not use it even when it becomes available) (Sheridan, 1988). Systems developers may be underestimating the power of ‘trust’ in determining the success of human-automation performance (Sheridan and Ferrell, 1974). This means that in order for drivers to experience the full benefit afforded by the automation of longitudinal and lateral control, they must have appropriate levels of trust in system operation (Lee and See, 2004). Any violation of a driver's expectation of system functionality is likely to have an effect on subjective ratings of trust. For example, Dzindolet et al. (2002) propose that naive operators are more likely to expect automated assistance to be capable of outperforming them. If the automation fails to perform in the way expected, ratings of trust begin to decline (Wiegmann et al., 2001). The purpose of the latter assessment was so that any potential design weaknesses within the prototype HMI architecture could be highlighted as well as provide recommendations for suitable revision that would make the automated system limits more transparent. The transparency of system feedback is important because it protects against the occurrence of mode error and a misunderstanding of system state (Sarter and Woods, 1995).

@&#CONCLUSIONS@&#
