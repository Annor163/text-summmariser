@&#MAIN-TITLE@&#
Adapting a classification rule to local and global shift when only unlabelled data are available

@&#HIGHLIGHTS@&#
The model addresses binary classification of evolving populations.It bridges the gap between the observation of new features and their class labels.It helps to improve classification even when model re-estimation is impossible.The model addresses local and global drift.

@&#KEYPHRASES@&#
Dataset shift,Concept drift,Local drift,Global drift,Verification latency,

@&#ABSTRACT@&#
For evolving populations the training data and the test data need not follow the same distribution. Thus, the performance of a prediction model will deteriorate over the course of time. This requires the re-estimation of the prediction model after some time. However, in many applications e.g. credit scoring, new labelled data are not available for re-estimation due to verification latency, i.e. label delay. Thus, methods which enable a prediction model to adapt to distributional changes by using only unlabelled data are highly desirable. A shift adaptation method for binary classification is presented here. The model is based on mixture distributions. The conditional feature distributions are determined at the time where labelled data are available, and the unconditional feature distribution is determined at the time where new unlabelled data are accessible. These mixture distributions provide information on the old and the new positions of subpopulations. A transition model then describes how the subpopulations of each class have drifted to form the new unconditional feature distribution. Assuming that the conditional distributions are reorganised using a minimum of energy, a two-step estimation procedure results. First, for a given class prior distribution the transfer of probability mass is estimated such that the energy required to obtain the new unconditional distribution by a local transfer of the old conditional distributions is a minimum. Since the optimal solution of the resulting transportation problem measures the distance between the old and the new distributions, the change of the class prior distribution is found in a second step by solving the transportation problem for varying class prior distributions and selecting the value for which the objective function is a minimum. Using the solution of the transportation problem and the component parameters of the unconditional feature distribution, the new conditional feature distribution can be determined. This thus allows for a shift adaptation of the classification rule. The performance of the proposed model is investigated using a large real-world dataset on default rates in Danish companies. The results show that the shift adaptation improves classification results.

@&#INTRODUCTION@&#
Statistical classification is traditionally based on the assumption that the test data (target data) follow the same distribution as the training data for which the classification rule is estimated. However, in many real-world applications this assumption does not hold due to the evolution of the population. Typical examples here are credit scoring (Crook, Edelman, and Thomas, 2007; Hand, 2006; Kelly, Hand, and Adams, 1999; Yang, 2007), finance (Sun and Li, 2011), spam filtering (Bickel and Scheffer, 2007; Delany, Cunningham, Tsymbal, and Coyle, 2005), natural language processing (Jing and Xiang, 2007; Yamada, Sugiyama, and Matsui, 2010), remote sensing (Dinh, Duin, Piqueras-Salazar, and Loog, 2013), quality control (Forman, 2008), or bioinformatics (Tsymbal, Pechenizkiy, Cunningham, and Puuronen, 2008).A changing population, i.e. a non-stationary environment (Ditzler, Rosen, and Polikar, 2012) is characterised by a change of the joint distribution P(X, Y) of the features (i.e. predictors) X and the class variable Y over the course of time. In the literature, such change is denoted as population drift (Kelly et al., 1999), as concept drift (Schlimmer and Granger, 1986), as dataset shift (Quinnero-Candela, Sugiyama, and Schwaighofer, 2009), as local, or as global drift (Hofer and Krempl, 2013), depending on which distribution changes. Unfortunately, consistent terminology has often been lacking in the drift literature. To simplify scientific discourse Moreo-Torres, Raeder, Alaiz-Rodríguez, Chawla, and Herrera (2012) thus made an attempt to unify frequently used terms. Depending on the distributions that are affected by the change, they distinguished four types of drift: (1), covariate shift, where the unconditional feature distribution P(X) changes but the posterior distributions P(Y|X) remain the same, (2), prior probability shift, where the class prior distribution P(Y) changes but the conditional feature distributions P(X|Y) remain the same, (3), concept shift, where the unconditional feature distribution P(X) is unchanged but the posterior distributions P(Y|X) changes, and (4), dataset shift, where the joint distribution P(X, Y) changes and none of the other cases hold.Other definitions (see for example Ditzler et al., 2012; Krempl and Hofer, 2011), have a strong focus on the time component, i.e. changes are distinguished in terms of whether they are gradual (i.e. drift) or sudden (i.e. shift), fast or slow (further drift types see for example Forman, 2006). Hofer and Krempl (2013) distinguished between global drift and local drift, a distinction that is based on whether changes affect the whole feature space homogeneously or whether they only affect particular subpopulations and thus are observed in particular subregions of the feature space (see also Tsymbal et al., 2008). Global drift is caused by the change of the prior distribution and thus coincides with class prior probability shift as defined by Moreo-Torres et al. (2012), whereas local drift is a consequence of changing conditional feature distributions P(X|Y). Local drift falls into the category of dataset shift according to Moreo-Torres et al. (2012). In this present paper the terms ‘local’ and ‘global’ drift are preferred to the terms ‘dataset shift’ and ‘prior probability shift’, since they are very intuitive.In changing environments the performance of a recently estimated prediction model will deteriorate over the course of time since it becomes less and less optimal with respect to the new distribution. As an example, consider a binary classification problem where the class prior probability of positives is P(Y = 1). According to the Bayesian classification rule a sample with the univariate features X is predicted to be positive when the posterior probability P(X|Y = 1) P(Y = 1) > P(X|Y = 0) P(Y = 0). However, when the class prior probability P(Y = 1) increases, the optimal classification rule which is defined by a single real value will shift to the right or to the left depending on the location of the conditional feature distribution P(X|Y = 1). As a consequence the false negative rate will increase when the old classification rule is still used instead of the new one. The situation becomes much more complicated when the conditional feature distributions P(X|Y) also change, i.e. in the case of local drift.Thus, a dynamic environment requires the re-estimation of the prediction model after some time using new representative, labelled training data. However, in many real-world applications such new labelled data are not available due to a phenomenon called verification latency (Marrs, Hickey, and Black, 2010) or label delay (Kuncheva, 2008). Verification latency denotes the time span until the corresponding labels of given instances become accessible. In particular, it refers to applications in which it is cheap or easy to obtain instances, i.e. unlabelled data, but where it is expensive or impossible to obtain the class labels at the same time. For example, in credit scoring estimating a prediction model for the default of loans with a maturity of three years is based on training data collected three years ago. This results from the fact that the true class labels (default or not) of all training instances are not known before maturity of the loans, but estimation of the prediction model requires a full dataset, including the class labels. Thus, depending on the extent and speed at which changes occur, such data need not be representative, in particular for large time spans, until the class labels are accessible.In the presence of verification latency only an incomplete dataset containing instances and their features, but not their labels, is available for tracking changes. However, since unlabelled data also provide information about the earlier distributional change, methods enabling adaptation of a prediction model using only such data are highly desirable. The procedure introduced in the present paper addresses this problem in the context of classification. In contrast to the previous paper (Hofer and Krempl, 2013) that deals with global changes, the present paper allows for both global and local changes.In the literature a few methods were proposed for adapting a classification rule to local changes of distributions. Biernacki, Beninel, and Bretagnolle (2002) and Beninel, Biernacki, Bouveyron, Jacques, and Lourme (2012) addressed a particular problem of local drift, i.e. changes of distributions that can be described by a linear univariate transformation of the features. Thus, their model is limited to the situation where changes can be expressed in terms of diagonal transformation matrices that may differ between the classes. If the diagonal matrices are known, the means and variances of the test populations can be calculated and thus an adapted classification rule can be constructed. Since the populations in the various classes are Gaussian, the model requires continuous features (for an extension to binary predictors see Jacques and Biernacki, 2008). However, since mixture distributions are not considered, the model is inappropriate when subpopulations within a class behave differently over the course of time.Alaiz-Rodríguez, Guerrero-Curieses, and Cid-Sueiro (2011) introduced an adaptive algorithm for a particular type of local drift based on neural networks. Their method is limited to the case where each class can be decomposed into several (unknown) subclasses, and all changes in data distributions arise from changes in class prior distributions and in prior subclass probabilities, while preserving invariance in subclass conditional densities. The model is not restricted to continuous features.Krempl (2011) proposed a nonparametric method based on kernel density estimation. The author used an EM algorithm for the maximum likelihood estimation of the drift parameters. He showed that the maximisation step of the EM algorithm is equivalent to solving an assignment problem. However, since the assignment is carried out instancewise, the number of training instances and target instances is assumed to be equal. In addition, the method only applies to continuous features.Krempl and Hofer (2011) proposed a method for only local changes where the parameters were estimated by means of an EM algorithm. Some of the disadvantages of this model are that the estimation of particular weights needs labelled data (for a discussion and the use of auxiliary techniques see Krempl and Hofer, 2011), and that the number of components in the mixture distribution is fixed.To overcome the restriction of the above mentioned methods, a more general technique for local shift adaptation is proposed in the present paper. In contrast to Biernacki et al. (2002) and Beninel et al. (2012), it is assumed that the population contains several subpopulations, and that these components do not necessarily behave in the same way as the whole class to which they belong. In contrast to the model in Krempl and Hofer (2011), the number of subpopulations can change over the course of time. The method is based on the idea that unlabelled data give information on the new locations of subpopulations. These new locations can be estimated by a mixture distribution of the unlabelled data, but the class membership of the subpopulations is unknown due to the lack of labels. However, for each class the old locations of subpopulations are known from recent labelled data. Since the unconditional feature distribution is the weighted sum of the conditional feature distributions where the weights are the mixing proportions, a transition model can be constructed that describes how the subpopulations of each class drifted to form the new unconditional feature distribution.The model assumes that the timespan between the estimation of a classification model using labelled data and its adaptation using unlabelled data is not too large, and thus, that the distance covered by the subpopulations is not too large. In particular, it is assumed that the given distribution is reorganised using a minimum of energy. This yields a two-step estimation procedure to estimate the shift. First, for a given class prior distribution the transfer of probability mass is estimated such that the product of distance covered and of mass transferred is a minimum. The objective function value corresponds to the energy that is required to obtain the new unconditional distribution by a local transfer of the old conditional distributions. This energy should be a minimum. This results in a transportation problem. The optimal solution of the transportation problem measures the distance between the old and the new distributions, and it can be used as estimate of the local change.In a second step the change of the class prior distribution is found by solving the transportation problem for varying class prior distributions. The value for which the objective function takes a minimum is then selected to represent the shift of the class prior probability. Since the solution of the transportation problem yields the amount of probability mass that originates in the particular classes, they can be used together with the component parameters of the unconditional feature distribution to determine the new conditional feature distributions. These new conditional feature distributions and the new class prior distribution allow an update of the classification rule.The model proposed is applicable when data are given at two different time points. Thus, the model addresses shift rather than drift. Drift denotes gradual changes that occur systematically over the course of time, whereas shift denotes a change between two particular time points (see for example Krempl and Hofer, 2011). In this respect, the proposed model handles data in batch mode, i.e. the instances arriving in a data stream are not processed upon arrival but, are collected, and then the model is applied to the whole dataset available at that time point.As in Hofer and Krempl (2013) the present paper is based on a comparison of the conditional and unconditional feature distributions. In contrast to Hofer and Krempl (2013), the distributions are estimated as Gaussian mixture models and not as mixtures of normed B-spline basis functions, since B-spline basis functions increase the time complexity of the estimation procedure in the multivariate context.The paper is organised as follows: Section 2 reviews the existing drift literature. In addition to an overview of the different types of drift and drift detection methods, this section discusses different drift adaptation procedures, and it discusses the position of the shift model with respect to the existing literature. Section 3 then describes the proposed shift model, introduces a two-step estimation procedure and shows how a classification rule is updated after the estimation. In addition, it addresses the problem of nominal features in the estimation process. Finally, the model is applied to a large real-world dataset in Section 4.

@&#CONCLUSIONS@&#
