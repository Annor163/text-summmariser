@&#MAIN-TITLE@&#
Empirical analysis of cascade deformable models for multi-view face detection

@&#HIGHLIGHTS@&#
We present a state-of-the-art multi-view face detector based on Cascade Deformable Part Models (CDPM).We propose to combine data-mining and bootstrapping to learn CDPM models from weakly labelled data.We report extensive validation of our models in the FDDB, AFLW, HDDB and COFW databases.We show the suitability of our models for face alignment initialization and face detection under partial occlusions.

@&#KEYPHRASES@&#
Multi-view face detection,Cascade deformable models,FDDB database,AFLW database,HPID database,COFW dataset,

@&#ABSTRACT@&#
Graphical abstract

@&#INTRODUCTION@&#
Face detection is invariably the first step in any automatic face analysis system. With the rapid increase of computational power and modern digital signal processing, face detection is a handy and a customary feature present in many human sensing applications. Still, the key aspect of performance is not only the ability to detect the face quickly, but also reliability and precision. It is indeed common that further processes are initialised upon the face detection output, including face alignment, face modelling, face relighting, face recognition, face authentication, head pose estimation, facial expression recognition, gender/age recognition, and many more [5].For the past decade, face detection has relied on the influential Viola&Jones (VJ) algorithm [6]. Near-frontal face detection suddenly became feasible as the VJ algorithm provides real-time performance for head pose variation up to 30° of yaw and 15° of pitch rotations.Driven by the imminent necessities of technological progress, face analysis recently abandoned the typical controlled scenarios of the lab-produced databases to tackle real world challenges. That is to say, face detection must evolve from restricted settings where near-frontal faces, clean backgrounds, perfect illumination and occlusion-free faces are acquired. This is why the latest challenges in face analysis arise from unconstrained imagery collected over the internet, widely known as the “in-the-wild” databases [2,1].The VJ algorithm was early exhibited as largely insufficient to handle the head pose rotations in databases like the Multi-Pie database [7] and the plethora of in-the-wild databases that followed. It is within this context that Multi-View Face Detection (MVFD) rapidly raised in practical importance.A first attempt to extend the VJ algorithm to MVFD was proposed by Viola and Jones [8]. They proposed a two-stage MVFD, where the face pose is initially estimated, followed by face detection according to pose-wise models. Other subsequent works proposed different modifications to the VJ detector. The most relevant proposals include the use of different cascade architectures, variants of Boosting and modified Haar features.For example, [9] proposed the use of a pyramid of classifiers to deal with MVFD, where lower levels of the pyramid would be increasingly specific to a head pose. FloatBoost was used instead of AdaBoost to avoid the greedy search, and an extension of Haar features was used. Similarly, [10] used Real AdaBoost to train pose-wise experts, while a nested-structured cascade was proposed to replace the cascade architecture of VJ algorithm. Alternatively, [11] proposed a tree-shaped organization of the cascaded search in combination with a variant of Boosting, called Vector Boosting, which allowed classes to share features. This variant aimed at alleviating the impact of class overlap when training pose-wise experts for MVFD. However, most of these works were strictly incremental over the VJ algorithm, and offered no breakthrough.Papers that are more recent have proposed the substitution of Haar-like features. For example, [12,13] attained a large performance improvement by using SURF features, which are equally computable by means of the integral image. Face detection is still attained through a cascade of SURF weak classifiers, trained with billions of samples within one hour. This work resulted on the best performance to date over the FDDB benchmark database [1]. Alternatively, [14] proposed the use of Local Gradient Patterns to build a feature pyramid while maintaining the cascaded AdaBoost as the learning algorithm. The large performance gain of these methods suggests that the representation power of Haar-like features is a bottleneck of the classical VJ framework. However, these articles do not specifically tackle MVFD.New works have emerged applying the vast advances on generic object detection to the specific problem of face detection. For example, [15] proposed to apply methods based on local scale-invariant key-point features to solve the problems of pose-invariant face detection. A similar idea was followed in [16], where SIFT features are detected within the images and then used to score similarity between two images as the number of positive key-points matching. This work reported results on the FDDB database [1] but did not outperform the results reported in [17], where a Gaussian Process Regression scheme was applied to adapt the VJ pre-trained model to the “in-the-wild” domain. Very similar approach was used in [18], where authors trained a Gaussian Mixture Model to also adapt the VJ model to the “in-the-wild”.Recently, a major breakthrough for MVFD was obtained when Zhu and Ramanan [19] proposed to apply another object detection framework, the Deformable Parts Model (DPM), for joint face detection, pose estimation and facial landmark detection. Specifically, they proposed a model formed by 68 part filters per pose, each one corresponding to a facial landmark. Their spatial relations are modelled using a Tree Structure Model (hereafter we will refer to this method as TSM). The absence of loops in the shape model means that minimization can be attained through dynamic programming. Finally, the model was composed of 13 head pose-wise experts, corresponding to the poses present on the Multi-Pie database. This approach showed a much better performance than VJ-like methodologies for MVFD. Essentially, a finer face representation, modelling inner facial structures, Histogram of Oriented Gradients (HOG) features [20] and view-dependent models, lead this method to a better discrimination power.However, the way inner facial structures are modelled appears optimal for facial landmark detection while being suboptimal when only face detection is intended. Firstly, it requires an exhaustive facial landmark labelling, which hugely reduces the amount of training data that can be used. Secondly, the large amount of experts and parts makes the algorithm too slow for face detection in practical applications. The resolution required is higher as the part filters rely on local statistics for a successful detection. Finally, the TSM model lacks a holistic face filter that could speed-up the face detection at lower resolutions and improve its robustness to partial occlusions. We argue that the baseline framework of DPMs as defined in [21] is more suitable for MVFD than the TSM, which is actually derived from [21].Recent contributions to the literature extended the TSM framework [19], to propose structural models for body and face detection [22–24]. These models pursue a double objective, detection of faces, facial parts and/or facial landmarks. Such an ontological dual function also requires more complete facial annotations beyond simple face bounding boxes. Moreover, the method proposed in [22] makes use of contextual information by combining the results of an upper body detector to improve the face detection performance. This increases the complexity of the annotated data required to train such model.The star-structured model of the original DPM has shown excellent detection performance on difficult benchmarks such as the PASCAL datasets [25]. When using star models, facial appearances are modelled using multi-scale DPMs. Further performance improvement is attained by combining Latent Support Vector Machines (LSVM) and data-mining procedures. Finally, a Cascade Deformable Part Model (CDPM) [26] can speed up over 20 times the DPM's detection without sacrificing detection accuracy.In this paper, we present an empirical analysis of CDPMs to address the reliability problem of MVFD. First, we describe a data-mining process to incrementally learn DPMs from partially labelled data using the LSVM algorithm. Second, we derive a post-optimization procedure for the CDPMs training that improves significantly its performance. As a result, we obtain a face detector that outperforms the state-of-the-art face detectors on three challenging “in-the-wild” datasets such as the Face Detection Database (FDDB) [1], the Annotated Facial Landmarks in the Wild [2], and the Caltech Occluded Faces in the Wild (COFW) [4]. Additionally, detailed experimental results on the Head Pose Image Database [3] are discussed. We also provide analyses regarding average face detection times and the accuracy of our MVFD for the initialization of facial landmark detection.One of the most efficient and remarkable frameworks in object detection has been presented by Felzenszwalb et al. [21]. This method proposes to build pictorial structures composed by a set of dual resolution image filters, which are a global object model and a set of parts representing object sub-structures, arranged according to a deformable spatial configuration. Here, we describe an empirical analysis of this DPM to address the problem of efficient MVFD.First, we present the DPM and detail the face detection hypothesis. Second, we explain the process of discriminatively learning a DPM from weakly labelled data using the LSVM algorithm [21]. At this point, we introduce two post-processing procedures, data-mining and bootstrapping, which allow us to refine training sets while increasing the robustness of the model. Finally, we describe cascaded search strategy, where early stages in the cascade use a basic DPM face detector to rapidly scan the image while speeding up face detection without any performance loss.Following the original DPM's framework [21], let us define a DPM with n parts as β={F0,P1,…,Pn,b}, where F0 is a coarse-scale global Root-Filter, Piis a Part-Filter model for the ithpart and b is a bias term. Part filters are defined as Pi={Fi,vi,wi}, where Fiis a fine-scale part filter at twice the resolution of the root filter. The spatial distribution of part filters is defined relative to the root filter by both viand wi, the anchor and deformation penalty, respectively.DPM filters are matrices designed to weight the sub-windows of a pyramidal representation of an image. We employ a variant of the HOG features introduced by Dalal and Triggs [20] to represent the facial appearance. These features have shown to be robust for object detection under challenging conditions such as image noise, scale variation and occlusions [25].Given both a DPM and a HOG feature pyramid of a testing image x, a binary convolution function, Φ(x,β), scans the responses of the model β onto the testing image. The score of a filter with respect to a sub-window of a HOG pyramid is the dot product of the weight vector and the features comprising the sub-window. Thus, the scoring function combines the appearance fitness and a penalization of spatial deformation as follows:(1)Sβx=ΦxF0+∑i=1nmaxδi∈ΔΦxPiδi−wiδiwhere Φ(x,F0) is the root filter response, δigives the displacement of part filters relative to its anchor and the root's position. In this model, each part is expected to keep a specific relative position respect to the root filter, called the anchor point. The part can move away from its anchor point, but it incurs in a penalization, wi(δi), when doing so. This penalization might however be outweighed by the improved matching of the part filter. Thus, Φ(x,Pi,δi)−wi(δi) scores the responses of the part filters under the displacement from the anchor point, δi, and the deformation cost associated with the displacement, wi. We model the deformation as a symmetric two-dimensional Gaussian mask superimposed on the target sub-window, with mean location being the anchor point.A face detection model is implemented as a mixture of DPMs, in which each DPM's component is designed to respond only to a subset of the possible appearances and deformations. In our case each subset corresponds to a distinct range of head poses. Fig. 1shows a DPM example that comprises four mixture components representing near-frontal and profile faces, left and right (only the right view components are displayed). Each mixture component has a root filter (Fig. 1.(a)) and six independent part filters, (Fig. 1.(b)), this is known as 4 ∗ (Roots+6Parts) DPM. Fig. 1(top) shows a face detection example of this DPM, where the red bounding boxes correspond to the maximum combined scored, Eq. (1), and blue boxes display the best configuration of the model part filters.Observe that this DPMs are trained with weakly labelled data, i.e. only the face bounding box is known in opposition to previous works [19,24,23,22]. Consequently, the part filters composing a view-based mixture detector do not correspond to any face part or facial landmark.Training a robust face detector for the “in-the-wild” images requires a large amount of data from a variety of databases. Ideally, we want to learn from both lab-designed and “in-the-wild” databases, but the main challenge is the lack of consensus in the annotations. Therefore, we deal with this issue by adopting a multi-instance learning formulation, Latent Support Vector Machines (LSVM). This consists of training an initial face model using a partially labelled dataset, with homogeneous bounding box annotations. Afterwards, new latent variables are collected in order to extent the primary training set.Now, let us define a classifier that scores an example image x with the following function:(2)Sβx=maxz∈Zzβ⋅Φxzwhere Z(x) defines a set of possible latent variables for an example x, scored using the DPM β and the scoring function in Eq. (1). In our case, these latent variables are obtained by evaluating all DPM view-based components on the hypothesis x. The detection with maximum score is kept and a binary label is assigned to x upon a minimum detection score threshold. In a similar fashion to training an SVM, we use the LSVM algorithm [21] to train a DPM for face detection while obtaining β. To this end, a face DPM is discriminatively trained with labelled examples by minimizing the following loss function via a coordinate descent algorithm:(3)LDβ=β22+c∑i=1kmax0,1−yi⋅Sβxihere,D=x1y1,…,xnyn)is the training set and yi∈{−1,1} are the binary class labels. max(0,1−yi⋅Sβ(xi)) is the standard hinge loss and c is a regularization term.In general, training an LSVM requires optimizing a non-convex function. Still, there are two strategies to ease the LSVM optimization as proven by Felzenszwalb et al. [21]. First, the training of LSVM is made convex by specifying the latent information for the positive training examples, while the negative training examples remain fixed. Second, Sβ(x) is made linear in β by collecting only one latent variable for each positive example, |Z(x)|=1. Bear in mind that at this point we are training linear SVM as a special case of LSVM, using latent variables. Consequently, we obtain the perfect scenario to use of-the-shelf optimization algorithms and large training datasets.DPM combines mixture models able to deal with facial appearance variation due to head pose and facial expressions. Hence, root filters allow discriminating faces from the background while deformable part filters can adapt to expressive faces and head pose variations.Usually face images are labelled with bounding boxes, which enable training of rigid face detection models. A more complete labelling might be used such as the facial landmarks used by Zhu and Ramanan [19]. However, such level of detail combined with the definition of fine inner facial structures make the TSM a suboptimal face detector. Instead, we first train a DPM that contains a mixture of view-based root filters learned from labelled data. Subsequently, the mixture of root filters is used to acquire latent examples that serve as training set for new root and part filters. The initial structure of the part filters is obtained by applying Gaussian Mixture Models (GMM). Next, the gradient descent process of LSVM allows finding the best possible location of the parts relative to the root filter such that the detection score is a maximum of Eq. (1).Afterwards, finding the optimal DPM requires to alternate between the acquisition of latent examples and retraining LSVM until the best performance measure is achieved on a validation set.To train a face detector with high performance, LSVM relies upon the precision of the root filters to extend the training set with new detected faces. This allows incrementally learning root and part filters as latent variables. Felzenszwalb et al. applied this data mining strategy over the positive training samples to learn non-deformable objects. However, face detection presents additional challenges due to a large diversity of head poses and facial expressions. To deal with this appearance variations and high deformability of faces, we propose to split the positive training set, Dp, into easy and hard positives, Depand Dhp, correspondingly.11The initial split could be based on a priori knowledge of the training data, e.g. images taken under controlled illumination and clean backgrounds are easier to learn.Likewise, the negative training set, Dn, is extended with a set of hard negatives,Zhn, which are positively scored detections collected from outside the annotated face bounding boxes.Initially, a mixture of coarse root filters is discriminatively trained using easy positives and negative examples, Depand Dn, respectively. Note that this step of the LSVM is reduced to the simple case of training a binary SVM for view-based mixture component. Once all root filters are obtained, the scoring function, Sβ(x), is globally normalized according to all easy positive examples. This is in order to enable comparisons of detections from different components.To incrementally learn DPMs based on latent variables, the root filters obtained from the easy positives are used to score the training set Dep. Thus, the corresponding set of latent positives,Zep, is obtained. Then, LSVM is applied again to discriminatively train a new mixture of root filters based on the latent easy positives and negative examples,Zepand Dn, respectively. Here, LSVM seeks to minimize the objective functionLZepF0in Eq. (3).As mentioned above, each mixture component consists of a root filter and a set of part filters, which are designed to cope with both face appearance and facial deformation, correspondingly. Therefore, part filters are trained while keeping the previously learned root filters. In fact, root filters are used to score both easy and hard positive examples to produce a complete set of latent positives,Zp=Zep∪Zhp. Subsequently, LSVM is applied to discriminatively learn part filters using Zpand Dn.Differently than learning root filters, the learning of part filters is a constrained optimization process as follows:(4)LZp,Dnβ=min||β||22+c∑i=1kmax0,1−yi⋅Sβzis.t.Sβz=maxz∈Zpzβ⋅Φz.Furthermore, the HOG features of latent part locations,zp∈Zp, are computed at twice the resolution of the root filters. Thereby, part filters are built using higher resolution features computed over highly scored latent positive examples. This combination of dual feature resolution and latent variables enables root filters to capture coarse resolution edges such as the face's boundary while part filters capture details such as eyes, nose and mouth.Face detectors are normally trained with a large number of negative examples. For a feasible discriminative training, the most common practice is to use all positive data and hard negative instances. Yet, to avoid computational overloads, bootstrapping methods propose to train a model with an initial subset of negative examples, and then collect additional negative examples that are incorrectly classified by the initial model. Then, an iterative process is established repeating the extraction of hard negatives and re-training the model until optimal stopping criteria are met.Motivated by the data-mining procedure described in [21] and the necessity to exploit large number of face images, here we combine both data-mining and bootstrapping. We define a margin-sensitive clustering procedure to extend both negative and positive examples into easy and hard latent instances. Given the training set of positive and negative labelled data,D=Dp∪Dn, we define easy and hard examples relative to a face DPM, β, as follows:(5)Zhpβ=xy∈Dp|yi+⋅Sβx<1,Hard−PositivesZepβ=xy∈Dp|yi+⋅Sβx>1,Easy−PositivesZhnβ=xy∈Dp|yi−⋅Sβx<1,Hard−Negatives.It can be seen thatZhpandZhnare positive and negative latent examples incorrectly classified by β, that is, data within the SVM margin. Instead,Zepare correctly classified examples, so they fall outside the margins with a high detection score. Letxp∈Dpandzp∈Zpbe two bounding boxes of a positive annotation and the corresponding detection, respectively. As determined in the PASCAL VOC [25], we measure the Overlapping percentage as follows:(6)Overlapping=areaxp∩zpareaxp∪zp.An initial model β0 is trained with LSVM using only annotated easy positives and negatives,DepandDn, respectively. Subsequently, as detailed in Section 2.1.1, LSVM is used iteratively alternating between caching a set of “good” training samples and updating the cache. For the LSVM training problem, we determine as latent positive example, zp, a detection window such that the Overlapping with xpis greater than 50%. However, an Overlapping of 70% determines whether the zpinstance belongs to eitherZhporZep. This allows to apply data-mining in the positive examples at slow learning rate but with highly scored new latent examples.Like with positive examples, there is a set of hard negatives,Zhn, which are highly scored detections collected fromDp. Thus, a detected window is considered as hard negative if the Overlapping with the annotation xpis lower than 50% but with a high detection score, e.g. Sβ(x)≥0.Accordingly, a bootstrapping stage is performed by updating the cache with latent hard negative examples,Zhn. This post-processing procedure is intended to maximize the correlation between the precision–recall and the score function of the face detector. In addition, both data-mining and bootstrapping procedures contribute to refine the SVM margins while reducing highly scored detections around accurate face detections.This whole data-mining/bootstrapping procedure is repeated upon convergence to the optimal precision–recall computed over a validation set.Felzenszwalb et al. also provide a Star-Cascade (SC) algorithm [26] in order to speed-up the DPM detection without a loss in accuracy. Contrary to the TSM [19], a DPM with start model structure already outperforms the TSM at the first stage of the cascaded classification. The mixture of root filters of the DPM are more efficient proxies than the small facial part-like features of the TSM, resulting in a much larger reduction of the computational cost.To circumvent the bottle-neck of DPMs, a Cascade DPM (CDPM) is trained to find likely object locations that are later validated by the DPM. Although this procedure is not specific to the star model, the CDPM consists of a tailored root filter capable of scanning the image at low resolution whereas part filters are used at high resolution over the locations provided by CDPM's root filter.In our model, we tailor the root filter model and the corresponding parts to be hierarchically applied, resulting in n+2 stages, where n is the number of part filters. The SC algorithm learns a global threshold, τ, which is used to score the most likely locations with the CDPM's root filter, Sc(F0)≥τ. This score is accumulated throughout the stages of a cascade. If Sc(F0) with the first i parts is lower than a threshold τi, the root location is not evaluated for the rest of the cascade. This is known as hypothesis-pruning. SC will also skip locations if the deformation wiis above a threshold τi′. Finally, the SC algorithm will use the CDPM for hypothesis-pruning at early stages as a proxy to highlight faces from the background. Once a candidate location is found, we compute the actual filter convolution of the underlying image features with the face DPM including both roots and part filters. This additional stage in the cascade allows to suppress all but the best detections in a faster manner.Further speed-up can be attained by using PCA-HOG features to encode the appearance of root and part filters of the CDPM. This allows obtaining simplified cascade models with no noticeable loss of information as demonstrated in [26]. That is, the CDPM's filters are projected onto a fix number of eigenvectors achieving a faster face detection while reducing memory requirements. Here, our face CDPMs are trained with filters of 5-PCA-HOG features learned using the corresponding DPM and latent positive examples.Lower dimensional features may improve the precision as consequence of applying PCA, but at the expense of recall loss. Therefore, we propose to lessen this effect with a post-optimization procedure, which improves the CDPM's performance, i.e. precision–recall. We use both labelled and latent (easy and hard) positive examples to build an eigenspace of HOG features. Next, we follow the same steps as in [26] to compute the 5-PCA-HOG features corresponding to the CDPM's root filters.Here, we detail the training procedure followed by both VJ-MVFD and our DPM-MVFD. We used 35, 738 publicly available face images, see Table 1. Images from video sequences were clustered into different views (head poses) using the 3D head pose estimation given by the tracking system in [32]. The training set only contained faces with pitch and roll angles within the range of ±20°.As baseline, we trained a VJ-MVFD because the work in [8] is not publicly available. The training has been carried out using the OpenCV library [33], using a Gentle AdaBoost classifier, the upright Haar-like features and a tree-based cascade structure for an efficient search [34]. We trained a 6-Views MVFD for near-frontal, [0°,30°], half-profile, (30°,60°], and full profile, (60°,90°] faces. The training set of 35, 738 face images from Table 1 was extended to 100, 000 positive examples by flipping the images and applying random distortions. Our training of the VJ-MVFD took approximately four weeks per pose. Bear in mind that this haar-cascade training has several parameters suitable for õoptimization such as number of stages, type of haar-features, minimum hit rate and maximum false alarm rate. However, the major improvement in performance comes from the appropriate combination of pose-specific components.To detect a face, the VJ-MVFD runs all pose-specific detectors in parallel. Next, detections are merged by first using a disjoint-set data structure function [33] to cluster the detected rectangles according to their size and location. Then, clusters with a small number of rectangles are eliminated. Finally, a non-maximum suppression function is used to merge the remaining detections. The detections are scored as the maximum response of the Haar-like features among the view-specific detectors.We trained four different CDPM face detectors to assess the performance depending on the number of root and parts filters. A 4 ∗ (Roots+6Parts) CDPM was trained using images for near-frontal, [0°,±30°], and profile, (±30°,±90°], faces. Face images were flipped, which allows building symmetric view-based models but asymmetric filters, as both left and right views are trained independently. A second model was trained with 8 ∗ (Roots+6Parts) following the annotation structure provided with the Multi-Pie database [7]. For this model, we clustered the images according to the views, (±0°,±30°], (±30°,±45°], (±45°,±60°] and (±60°,±90°]. The same views were used to train a 8 ∗ (Roots+20Parts) CDPM. Lastly, we trained a 13 ∗ (Roots+6Parts) by splitting the head rotation of [−90°,+90°] on every 15°, so that is 13 views were obtained.Using the 35, 738 face images (labelled with bounding boxes) as listed in Table 1, we first learned the root filters of a DPM using the LSVM algorithm as explained in Section 2.1. To avoid scatter root models and benefit from less noisy annotations, we initially train them with easy positives,Dep. AFLW images were used as latent hard positives,Zhp. Hence, we disregarded the provided annotations, and latent bounding boxes were extracted instead by applying the data-mining process explained in Section 2.1.2.We adopt the PASCAL VOC precision–recall protocol for object detection [25]. A hypothesis is considered as a correct detection if the annotation and the estimation are at least 50% overlapped, Eq. (6).The root filters of our DPM models were designed using HOG features extracted from 10×8 pixels cells to match the head aspect ratio of the 75% of the annotated faces. Instead, part-filters are designed with HOG features extracted from square pixel cells of size 6×6. Our DPM models were trained using 32-dimensional HOG features, which were originally proposed by Felzenwalb et al. [21]. Subsequently, 50% of the annotated data are used to train an eigenspace of root-filters of these HOG features. Next, the first 5 eigenvectors of the trained eigenspace are taken as basis to represent the main structure of our CDPM.To train our DPM models with weak labelled and using data-mining and bootstrapping, we found out that the best strategy was alternating these two process in 2×1 stages. As explained in Section 2.1.2, we threshold the latent detections on our training set to distinguish easy positivesZep, hard positivesZhpand hard negativesZhn. This alternating procedure is described as follows:1.Data-mining easy—positives1.1.Obtain latent detections using previous model.Select easy positives using overlapping threshold, Eq. (6).Train DPM using LSVM andZepwhile keeping support vectors from previous model.Data-mining hard—positives2.1.Obtain latent detections using previous model.Select hard positives using overlapping threshold, Eq. (6).Train DPM using LSVM andZhpwhile keeping support vectors from previous model.Bootstrapping hard—negatives3.1.Obtain latent detections using previous model.Select hard negatives using overlapping threshold, Eq. (6).Train DPM using LSVM using all above dataZep+Zhp+Zhnto obtain a new set of support vectors, which generalize for the extended dataset.The above steps (1) and (2) adopt similar strategies as on-line learning methods by adding new support vectors to previous models. This allows increasing the generalization strength of the model based on positive training samples. Finally, a fresh model is trained in step (3) after obtaining all the latent training samples from positives and negatives.The training of each view-based DPM component is initialized with at least 400 to 500 positive annotated samples, which ensures an AP grater than 90% for the first root filters. Then, a first round of the above (1) to (3) steps is conducted for each view-based component while using data corresponding to that view only. However, to achieve highly discriminative view-based components, posterior rounds are advanced using all remaining data, where the view component with highest scored detection will retain that latent sample for further re-training.To obtain a robust mixture of DPMs, we repeat this alternating data-mining and bootstrapping steps at least five times. This has been determined by using a separate validation sample to assess the convergence of the improvement in AP. Additional statistics also ensure that more than 95% of our positive samples have been used while reducing the false positives rate.The full training process of a DPM with four view-based components and six filters can take about a week. The process is slow because involves running face detection on 35,000 images, three times for each of the rounds described in Section 3.2.2. This calculation is done assuming the availability of a pool of 20 workers @ 3.60GHz, 16GB of RAM and Linux 64 bits. The training cost can increase upon the number of root and part filters, where the latter drive the highest computation overload as they require a HOG pyramid at double resolution of the root filters features. However, we believe that both training and running cost can be drastically reduced by optimizing the HOG computation and the use of GPU power.

@&#CONCLUSIONS@&#
We have presented a Multi-View Face Detector (MVFD) algorithm that is robust and accurate for “in-the-wild” scenarios. We adopted the object detection framework of Felzenszwalb et al. [26] to learn MVFD-DPM as well as the cascade version of it, CDPM-MVFD. We trained our models with weakly labelled data via Latent Support Vector Machines (LSVM). Hence, we showed the feasibility of learning models from a reduced number of labelled data. In order to increase the robustness of our MVFD, we combined LSVM with bootstrapping and data mining procedures. This post-processing procedures facilitate the incremental learning of models by progressively extending both positive and negative training sets.We experimentally showed the performance of different variants of our CDPM depending on factors as the number of mixture components and part filters. This benchmark showed that models learned from a more detailed labelling or more granular part filters lead to lower precision.We presented lengthy empirical performance analysis for face detection on a range of unconstrained and challenging databases. We compared our face detector against state-of-the-art methods. We showed that our CDPM model outperforms other state-of-the-art methods for face detection in in-the-wild scenarios by a large margin.Furthermore, we also compared our CDPM-MVFD against the latest state-of-the-art face detectors tested on FDDB [1] benchmark dataset. In this context, our face detector also significantly outperforms these state-of-the-art methods by a large margin. Additionally, we compare against state-of-the-art methods such as the TSM by Zhu et al. [19] and our implementation of a VJ-MVFD [41] on the AFLW.We also presented a specific per-head-pose face detection performance. To this end, we used the HPID [3] database, achieving an average precision over 95% for head poses up to ±60°, whereas head poses up to ±90° can be detected with an average precision of 75%.We showed that the cascade search of our face detection models is much faster than that reported by Zhu et al. [19], and of comparable speed to that of VJ-MVFD, achieving close to real-time performance.Since face detection is often followed by facial landmark detection, we showed how our face detector can support a facial landmark detection process. By simply fitting a mean shape model relative to the face detection bounding box, our CDPM shows promising results in the 300-W database. We compare the accuracy of a single mean shape trained with the VJ-MVFD against four component-wise mean shapes trained with our CDPM. According to the standard MRS error, our face detector achieved higher accuracy than VJ-MVFD. This result indicates that a view-based facial landmark detector using a CDPM-MVFD will have better chances of outstanding results.Lastly, we provide Matlab code for reproducing our experiments. It can be found at http://ibug.doc.ic.ac.uk/resources.33This will be available once this manuscript is accepted for publication, however it will be provided to reviewers as supporting material.