@&#MAIN-TITLE@&#
Developing an early warning system to predict currency crises

@&#HIGHLIGHTS@&#
This study proposes an early warning system (EWS) to predict currency crises.The case study is exemplified via Turkish economy.The results are very promising in terms of high prediction accuracy.The proposed EWS is a generic approach and therefore can be used in other economies.Leading factors for financial crises were ranked via a novel method.

@&#KEYPHRASES@&#
Early warning system,Currency crisis,Perfect signal,Artificial neural networks (ANN),Decision tree,Logistic regression,

@&#ABSTRACT@&#
The purpose of this paper is to develop an early warning system to predict currency crises. In this study, a data set covering the period of January 1992–December 2011 of Turkish economy is used, and an early warning system is developed with artificial neural networks (ANN), decision trees, and logistic regression models. Financial Pressure Index (FPI) is an aggregated value, composed of the percentage changes in dollar exchange rate, gross foreign exchange reserves of the Central Bank, and overnight interest rate. In this study, FPI is the dependent variable, and thirty-two macroeconomic indicators are the independent variables. Three models, which are tested in Turkish crisis cases, have given clear signals that predicted the 1994 and 2001 crises 12months earlier. Considering all three prediction model results, Turkey’s economy is not expected to have a currency crisis (ceteris paribus) until the end of 2012. This study presents uniqueness in that decision support model developed in this study uses basic macroeconomic indicators to predict crises up to a year before they actually happened with an accuracy rate of approximately 95%. It also ranks the leading factors of currency crisis with regard to their importance in predicting the crisis.

@&#INTRODUCTION@&#
A financial crisis is a state which causes economic, social, and political disasters that lead to a shift from equilibrium. This equilibrium creates uncertainty and chaos while causing redistribution of capital. Individuals who can foresee the crisis can use it to their advantage by reallocating capital and can transform the drawbacks of the impending crisis into opportunities. On the other hand, the ones who cannot foresee the crisis would suffer from unemployment and poverty. Therefore, the foresight to predict a crisis has attracted the attention of many researchers in the field of economics. However, due to the complexity of the context and number of factors that cause a crisis, predicting a crisis has been a very challenging problem. More interestingly, these factors have constantly changed over time. Considering all these, it would be a wise approach to take precautions against the potential crisis and prepare accordingly by foreseeing its effects via the past crisis and past economic indicators.There are various methods in literature that have been used to predict the crisis, most of which are statistical and econometric models. Recently, machine learning models have also been effectively utilized in crisis prediction. Therefore, this study is aimed at developing an early warning system with machine learning and statistical models exemplified by the Turkish economy.Market-threatening and effective crises have attracted the attention of many researchers. Studies pertaining to the prediction of financial crises have become more frequent since the 1990s. Some of these studies have focused on predicting crises by using a country’s economic indicators, while some others have focused on determining common significant factors that help explain crises by inclusively considering economic indicators of various countries. The definition of “crisis”, models utilized, and explanatory variables have varied from one study to another.The aforementioned research can be categorized into three groups. The first category refers to the regression models (e.g. Logit–Probit models) in which financial crises are estimated ahead of time via leading indicators. The second category uses potential early warning indicators, and is associated with the Kaminsky, Lizondo, and Reinhart (KLR) Model (1998), which is also known as the signaling approach. The third category focuses on machine learning applications, which are relatively new in forecasting financial crises.Among the earliest studies of regression models, Eichengreen, Rose, and Wyplosz (1995) presented an empirical analysis of speculative attacks on pegged exchange rates in 22 countries between 1967 and 1992. Frankel and Rose (1996) utilized a panel of annual data for over 100 developing countries between 1971 and 1992 to qualify currency crashes. The authors described a “currency crash” as a large change of the nominal exchange rate that substantially increases the rate of change of nominal depreciation. Glick and Rose (1998) demonstrated the effect of currency crises on a cluster of countries, which are tied together by the international trade. In a study by Davis and Karim (2008), it was noted that a country’s policy maker’s objectives can affect their ability in recognizing crises and false alarms. Their study recommended logit estimation as the most suitable technique to predict global banking crisis, and that signal extraction is the best for predicting country-specific crisis as an early warning system. Likewise, Canbas, Cabuk, and Kilic (2005) proposed an integrated early warning system (IEWS) framework that can be used as a decision support tool in the prediction of commercial bank failure via multivariate statistical analysis of financial structures, specifically principal component analysis combined with discriminant, logit, and probit models. The application of the RS Theory was also presented by Sanchis, Segovia, Gil, Heras, and Vilar (2007) to predict the insolvency of insurance companies and financial instability in a country. Furthermore, Premachandra, Bhabra, and Sueyoshi (2009) compared the data envelopment analysis (DEA) approach with the logistic regression (LR) technique and revealed that DEA is an appealing method for bankruptcy assessment.On the other hand, the second category (i.e. the KLR model) computes the deviation of the variables’ values before and at the time of the crises. These variables are selected in a way that they are the best signaling indicators of the crisis. Kaminsky, Lizondo, and Reinhart (1998) was among the earliest studies of this method and used the signaling approach to predict currency crises for a sample of five industrial and 15 developing countries between the years 1970–1995. In their study, an indicator exceeding a specified threshold was interpreted as a warning signal that a currency crisis may take place within the next 24months. They constructed such an early warning system that was proven to be able to accurately forecast the Asian crises. In this regard, their study also confirmed that economies in distress are at the origin of financial crises, such as the Asian crises, far from being of a “new breed”. Kaminsky and Reinhard (1999) analyzed the links between banking and currency crises. They revealed that financial liberalization often precedes banking crises by showing that problems in the banking sector that typically precede a currency crisis. The currency crisis then deepens the banking crisis and causes a vicious spiral. Edison (2003) evaluated how the signal system can be applied to an individual country.Within the last two decades, artificial neural networks (ANN) have been recognized by many researchers as a popular technique in financial prediction studies due to its high prediction accuracy rate (Akkoc, 2012). Results from the study by García-Alonso, Torres-Jiménez, and Hervás-Martínez (2010) indicated that ANN models, specifically product-unit neural networks, have shown the most accurate gross margin predictions in the agrarian sector. Based on the data sample of 220 manufacturing firms, Zhang, Hu, Patuwo, and Indro (1999) indicated that ANNs are also significantly better than traditional regression methods when solving real problems such as bankruptcy prediction. Lacher, Coats, Shanker, and Fant (1995) also revealed that ANN is able to achieve better results in estimating future financial health of a firm. Fethi and Pasiouras (2010) discussed the applications of various artificial intelligence (AI) techniques, such as ANN, decision tree, and support vector machines, in bank failure prediction, assessment of bank creditworthiness, and underperformance. Kumar and Ravi (2007) also examined the application of the same techniques in their study of the bankruptcy prediction issues faced by banks and firms during the 1968–2005 period.In a similar vein, the use of machine learning methods such as artificial neural networks (ANN), decision trees, and support vector machines has recently proven to be a set of commonly used reliable methods in predictive analytics (Delen, Oztekin, & Kong, 2010; Delen, Oztekin, & Tomak, 2012; Oztekin, 2011; Oztekin, Delen, & Kong, 2009; Oztekin, Kong, & Delen, 2011). Oh, Kim, Lee, and Lee (2005) used ANNs and nonlinear programming to examine the construction process of a daily financial condition indicator, which can be used as an early warning signal. Fioramanti (2008) showed that further progress could be achieved by applying ANN to the data on the sovereign debt crises that occurred in developing countries from 1980 to 2004. Lin, Khan, Chang, and Wang (2008) presented a mixed model to predict the occurrence of currency crises by using the neuro-fuzzy modeling approach. The model integrated the learning ability of ANNs with the inference mechanism of fuzzy logic. Nan, Zhou, Kou, and Li (2012) compared neural networks on generating early warning signals of bankruptcy in a given company and reported that ARTMAP outperforms the other models. Yu, Wang, Lai, and Wen (2010) proposed a multi-scale neural network learning paradigm to predict financial crisis events via early warning signals. They applied the proposed paradigm to the exchange rate data of two Asian countries to forecast financial crisis.A detailed analysis of currency crises of the last 30years can be found in Kaminsky’s study (2006). Additionally, a more recent review of financial crisis and banking default literature, according to financial and economic circumstances, is provided by Demyanyk and Hasan (2010).Inspired from the study of Eichengreen et al. (1995), “crisis” is defined as the percentage change of the standardized average of the gross foreign exchange reserves of the Central Bank and the repo rate (in terms of the US Dollar $ exchange rate). This is also referred to as the Financial Pressure Index (FPI) in literature. An increase in the US Dollar exchange rate and the repo rates, as well as a decrease in the gross foreign exchange of the Central Bank, leads to an increase in the FPI. In this study, it is assumed that a financial crisis arises when a threshold of FPI is exceeded. The variables stated in the calculation of the crisis are normalized to compute the FPI as in Eq. (1).(1)FPIt=et-μeσe-rt-μrσr+it-μiσi3where μ and σ represents mean and standard deviation, respectively.(2)et=Et-Et-1Et-1(3)rt=Rt-Rt-1Rt-1(4)it=It-It-1It-1where et, rt, and itare the monthly percentage changes in the dollar exchange rate, monthly gross foreign exchange reserves of the Central Bank, and monthly change of overnight interest rates at month t, respectively. Et, Rt, and Itare the dollar exchange rate, the gross foreign exchange reserves of the Central Bank, and the average overnight interest rate at month t, respectively. The threshold value which signals a crisis is calculated as in Eq. (5).(5)TV=μ+aσThe threshold value (TV) is defined as a slack over the mean μ with a factor, a, of the standard deviation. Subsequently, the presence of a crisis has been defined as in Eq. (6), in which dummy variable K equals 1 if there is a crisis; and 0 if otherwise.(6)K=1ifFPI>TV0otherwiseThe coefficient a takes values between 1.5 and 3 in the financial crisis literature. It is a heuristic value that seeks to improve the signal performance. Means, standard deviations, and weights are country-specific. Table 1summarizes the applications for various values of the coefficient a.The perfect signal is an ideal series of signals that gives a warning of a crisis during the 12-month period before the time at which FPI assumes a crisis is at the door. This signal is defined as in Eq. (7) and based on Bussiere and Fratzscher (2006). The perfect signal takes a value of 1 if a crisis is expected to occur within the upcoming 12months and a value of 0 if otherwise.(7)PSi=1if∃k=1,2,…,12subject toFPIi+k>(μ+aσ)0otherwiseFor instance, if a crisis is assumed in February of 1994, the perfect signal series always takes a value of 1 before the 12-month period of February 1994 as shown in Table 2.It would be naïve to say that the target of the perfect signal is to warn before a crisis occurs. Therefore, it has been considered a false alarm to detect the deterioration in the metrics at the time of the crisis, and consequently a value of 0 has been assigned to the perfect signals during this time. This translates into the fact that the perfect signal would be assigned a value of 1 if there is no crisis within the currently studied month, but it is predicted to be observed within the upcoming 12months.This study is fundamentally based on the “leading indicator” approach. The leading indicator approach assumes that macroeconomic factors would have an abnormal pattern before the time of a crisis and aims to calculate that deviation from the expected pattern (Kaminsky, 2006; Kaminsky et al., 1998; Kibritcioglu, Kose, & Ugur, 2001). A signal for crisis is fired if abnormal changes are observed with respect to predetermined threshold values by inspecting the pattern of factors.This study proposes the following methodology in constructing an early warning system for predicting currency crises:Step 1. Use Eq. (1) to calculate the FPI.Step 2. Determine months with crises using Eq. (6).Step 3. Calculate the perfect signal.Step 4. Determine the leading indicators.Step 5. Build the model using the perfect signal as the desired variable and leading indicators as the input variables.Step 6. Calculate the early warning signal and predict the currency crises.Step 7: Conduct information fusion-based sensitivity analyses to determine the rank order of the most important variables in predicting currency crises.A brief diagram of the proposed methodology can be seen in Fig. 1.Preliminary studies were conducted to determine which models perform better than the others in terms of classification error. Three classification models, two from machine learning field and one from statistics, were shown to outperform the others and the following models were adopted for this study’s proposed approach: artificial neural networks, decision trees, and logistic regression. Brief descriptions of machine learning models used in this study are provided next.Artificial neural networks (ANN) have been popular artificial intelligence-based data mining tools due to their superior prediction performance (Chang, 2011). Therefore, ANNs are widely used in forecasting the following: ATM cash demand, wind speed, foreign exchange rates, intraday electricity demand, and financial failure (Cao, Ewing, & Thompson, 2012; Jardin & Séverin, 2012; Kim, 2013; Sermpinis, Theofilatos, Karathanasopoulos, Georgopoulos, & Dunise, 2013; Venkatesh, Ravi, Prinzie, & Poel, 2014). In this study, Multi-Layer Perceptron (MLP) with back propagation learning algorithm is used due to its superiority over other ANN algorithms such as radial basis function (RBF) and recurrent neural network (RNN). Our pre-experiments also showed that MLP algorithm performs better than other ANN algorithms for this type of classification problem. In fact, Hornik, Stinchcombe, and White (1990) empirically showed that given the right size and structure, MLP is capable of learning arbitrarily complex nonlinear functions at arbitrary accuracy levels. Thus, in this study the optimal values of MLP size and structure with backpropagation learning are searched by genetic algorithms.Quinlan’s ID3, C4.5, C5 (Quinlan, 1986, 1993) and Breiman et al.’s CART (Classification and Regression Trees) (Breiman, Friedman, Olshen, & Stone, 1984) algorithms are well-known decision tree algorithms. Compared to other machine learning methods, decision trees have the advantage of being explained as a series of “if-then rules” instead of being black boxes. This advantage makes them very valuable in forecasting crises. Based on favorable trials in this study, C5 algorithm, which is an improved version of C4.5 and ID3 algorithms, was chosen as the decision tree model. C5 algorithm differs from its predecessors namely C4.5 and ID3 in that it is faster, more efficient (use of less memory), more concise with smaller trees constructed, and allows for boosting, which improves the accuracy (Quinlan, 1993). During the construction of the decision tree, C5 algorithm selects the best variable which splits its set of data points into subsets having more cases/observations in one class. Information gain is adopted as the splitting criterion. The variables are then selected to form the tree and hence to make the decision with respect to their information gain. The same algorithm is recursively employed on the smaller sublists.Logistic regression is a generalization of linear regression which is used to predict a categorical outcome (Hastie, Tibshirani, & Friedman, 2001). It is primarily used in predicting binary or multi-class dependent variables. It cannot be modeled directly by linear regression due to discrete nature of the response variable. Therefore, rather than predicting the point estimate of the event itself, it builds the model to predict the odds of its occurrence. In a two-class problem, odds greater than 50% would mean that the case is assigned to the class designated as “1” and “0” otherwise. While logistic regression is a very powerful modeling tool, the modeler must choose the right inputs and specify their functional relationship to the response variable based on his or her experience with the data and data analysis. In this study, a crisis occurring in the next 12months or not is a two-class problem with odds greater than 50% assigned to the class designated as “1”, indicating a currency crises within the next 12months and “0” if otherwise, indicating a currency crisis will not occur within the next 12months. Logistic regression is a powerful statistical modeling tool in financial crises literature, but it requires carefully chosen input variables. In this study, due to favorable results received, multinomial forward stepwise method is used to select the inputs during calculation steps with regard to their association with the response variable.In this study, the whole data set is divided into two mutually exclusive subsets; a model preparation (training) set and a testing set. Data in the testing set was never used while preparing the early warning models, instead it was used to evaluate the model performance on unseen data.Researchers generally use k-fold cross-validation for machine learning models in order to minimize the bias associated with the random sampling of the training and hold-out data samples (Desai, Crook, & Overstreet, 1996; West, 2000). The whole data set (D) is divided into two mutual subsets as described above. The training subset (DTr) is used only for training whereas the testing subset (DTs) is never used for training. After completing the learning process, the overall generalization ability of the models can be measured by the unseen new data, which is separated at the very beginning as the testing data subset (DTs). In order to fairly measure the prediction accuracy of each early warning model, the same training and testing data subsets are used for each method.In k-fold cross-validation, the complete training data is randomly split into k mutually exclusive sets (the folds:D1Tr,D2Tr,…,DkTr) of approximately equal size. In each epoch, an early warning model is trained on all but one fold (DTr) with tested on the remaining single fold (DTr). The cross-validation estimate of the overall accuracy is calculated as the simple average of the k individual accuracy measures as follows:(8)CV=1k∑i=1kAiwhere CV represents the cross-validation accuracy, k is the number of folds used, and A is the accuracy measure of each fold.In this study, 10-fold cross-validation is used to stop the training process and CV prevents overtraining or memorizing that inhibits the generalization ability of the model.In order to compare early warning models, three performance criteria are adopted as follows:(9)Accuracy=TP+TNTP+TN+FP+FN(10)Sensitivity=TPTP+FN(11)Specificity=TNTN+FPwhere TP, TN, FP, FN are True Positive, True Negative, False Positive, False Negative, respectively. Eq. (9) measures the proportion of correctly classified examples to give an overall probability that the model can correctly classify. Sensitivity and specificity, shown by Eqs. (10) and (11), measure the model’s ability to recognize specific currency crisis groups. For example, sensitivity is the probability that a crisis signal indicates an actual crisis and specificity is the probability that a non-crisis signal indicates a crisis, in fact, will not occur in the next twelve months.A matrix representation of the classification results based on actual classification vs. model classification, as shown in Fig. 2, is called the confusion matrix. In a two-class classification problem, as in our case, the upper left cell denotes the number of samples classified as positive, while they were positive in the actual classification (also called true positives). The lower right cell denotes the number of samples classified as negative, while they were actually negative (also called true negatives). The upper right cell represents the number of samples classified as negative, while they were actually positive (also called false negatives). The lower left cell represents the number of samples classified as positive, while they were actually negative (also called false positives).In data mining, there is no single method that works best for each and every problem. In other words, the performance of a model is derived by the studied scenario and the dataset being utilized (Ruiz & Mieto, 2000). Likewise, it is impossible to state the best strategy to deploy various data mining methods. Therefore, researchers tend to use “composite forecasts” by integrating multiple models in order to receive more accurate and effective results out of a set of data mining models (Batchelor & Dua, 1995). The information fusion outlines the process of combining the information extracted from a set of data mining models. There is a consensus that such a fusion produces more useful information in knowledge discovery in databases (KDD) practices (Armstrong, 2002; Chase, 2000).The information fusion algorithm can be as formulated as in Eq. (12) where the output (dependent) variable is shown by variable y and the input (independent) variables by x1,x2,…,xn(Oztekin, Delen, Turkyilmaz, & Zaim, 2013).(12)yˆ=f(x1,x2,…,xn)Prediction model f can take many forms. For instance, a linear regression model can be written as Eq. (13)(13)f(x1,x2,…,xn)=β+∑i=1naixiwhere β is the intercept and ai’s are the coefficients for xi’s. For a Neural Network model, for a single neuron, it may be written as Eq. (14)(14)f(x1,x2,…,xn)=ϕw0+∑j=1nwjxjwhere ϕ is the transfer function and wi’s are the weights for xi’s.If m number of prediction models is employed, the fusion model can be written as in Eq. (15)(15)yˆfused=ψ(yˆindividual,i)=ψ(f1(x),f2(x),…,fm(x))where the ψ is the operator to fuse/integrate the predictions of models f1(x),f2(x),…,fm(x).If fusing operator ψ is a linear function, as the case in this study, then we can rewrite Eq. (15) as in Eq. (16):(16)yˆfused=∑i=1mωifi(x)=ω1f1(x)+ω2f2(x)+⋯+ωmfm(x)where ω1,ω2,…,ωmrefer to the weighting coefficients of each individual model, namely, f1(x),f2(x),…,fm(x). Also, it can be assumed that the weights are normalized so that∑i=1mωi=1holds true.The weights (ω’s) are assigned proportional to the performance measure of each data mining model. In other words, the higher the accuracy of the data mining model, the higher the weight of that particular data mining model’s results (Oztekin et al., 2013).In addition, determining the rank order of independent variables in terms of their importance in prediction is also critical. In artificial neural networks, sensitivity analysis is the technique to do so for a trained ANN model (Davis, 1989). Through the sensitivity analysis, the learning algorithm of the ANN model is disabled after the learning is accomplished so that the network weights remain unaffected. Hence, the sensitivity score of a given input/independent variable is the percentage ratio of the ANN model error without the specified independent variable to the error of the model with all independent variables (Principe, Euliano, & Lefebvre, 2001). The more the model deterioration is without the particular variable, the higher the importance level of that variable would be. The same philosophy is valid in SVMs as well when determining the variable rank order in terms of their importance, which is quantified as “sensitivity measure” as defined by Eq. (17) (Saltelli, 2002).(17)Si=ViV(Ft)=V(E(Ft|Xi))V(Ft)where Siis the sensitivity score of the ith variable in the model, V(Ft) is the unconditional output variance. In the numerator, the expectation operator E calls for an integral over X−i; that is, over all input variables but Xi, then the variance operator V implies a further integral over Xi. Variable importance is then computed as the normalized sensitivity (Saltelli, Tarantola, Campolongo, & Ratto, 2004).Considering Eqs. (16) and (17) simultaneously, sensitivity measure of the variable n with information fused by m prediction models can then be given by Eq. (18)(18)Sn(fused)=∑i=1mωiSin=ω1S1n+ω2S2n+⋯+ωmSmnwhere ω’s refer to the normalized performance measure (i.e. accuracy value) of each prediction model with m models in total; and Sinis the sensitivity measure of the nth variable in the ith model.

@&#CONCLUSIONS@&#
