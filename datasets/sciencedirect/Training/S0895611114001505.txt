@&#MAIN-TITLE@&#
Difference of Gaussians revolved along elliptical paths for ultrasound fetal head segmentation

@&#HIGHLIGHTS@&#
A new method for the fetal skull segmentation from 2-D ultrasound images.The method is completely automatic and it requires no user interaction.The idea is to construct a template image of the fetal skull parametrized by both the calvarial thickness (the thickness of the skull) and an ellipse modelling the contour of the skull.This method won the fetal ultrasound segmentation challenge in ISBI 2012.The accuracy automatic segmentations are similar to the accuracy of the manual segmentations.

@&#KEYPHRASES@&#
Biparietal diameter,Head circumference,Energy minimization,Fetal biometry,Image analysis,Global optimization,

@&#ABSTRACT@&#
We present a fully automatic method to segment the skull from 2-D ultrasound images of the fetal head and to compute the standard biometric measurements derived from the segmented images. The method is based on the minimization of a novel cost function. The cost function is formulated assuming that the fetal skull has an approximately elliptical shape in the image and that pixel values within the skull are on average higher than in surrounding tissues. The main idea is to construct a template image of the fetal skull parametrized by the ellipse parameters and the calvarial thickness. The cost function evaluates the match between the template image and the observed ultrasound image. The optimum solution that minimizes the cost is found by using a global multiscale, multistart Nelder–Mead algorithm. The method was qualitatively and quantitatively evaluated using 90 ultrasound images from a recent segmentation grand challenge. These images have been manually analyzed by three independent experts. The segmentation accuracy of the automatic method was similar to the inter-expert segmentation variability. The automatically derived biometric measurements were as accurate as the manual measurements. Moreover, the segmentation accuracy of the presented method was superior to the accuracy of the other automatic methods that have previously been evaluated using the same data.

@&#INTRODUCTION@&#
Ultrasound measurements of fetal biometry is a standard method for dating pregnancies and for assessment of fetal growth. Standard biometric measurements include biparietal diameter (BPD), occipito-frontal diameter (OFD), head-circumference (HC), abdominal circumference (AC), crown-rump length (CRL) and femur length (FL). Based on these measurements, the gestational age and size of the fetus can then be estimated using charts or regression formulae [5,15,8]. In particular, biometrics related to the fetal head, i.e., BPD and HC as shown in Fig. 1, are recommended for measuring the gestational age during second or third semester and are used for assessing the fetal size [5,15,13].Currently, expert users perform these measurements manually. This is not only time consuming but also it results in high intra- and inter-observer variability of these measurements. Thus, automating measurement processes could provide significant benefits to both pregnant women and clinicians [2]. However, designing a fully automatic procedure is a challenging task because of the highly variable image quality that is a typical characteristic of ultrasound images. In addition, various image artefacts and surrounding tissues further complicate the automatic measurement of fetal biometrics. These problems are easy to appreciate in Fig. 2, whose panels (a) and (b) show two low quality but still typical ultrasound images.Given the importance of the problem, several automatic and semi-automatic methods for computing biometric measurements from ultrasound images have been proposed. These methods have mostly been based on the segmentation of the ultrasound images [22]. Approaches for the fetal skull segmentation have been based on deformable spline [12] and contour models [4,20], supervised learning [2], and ellipse fitting through (randomized) Hough transform [10,17,27]. The deformable contour or spline model [4,20,12] based approaches rely on the user to indicate a point close to the center of head and construct an initial contour model based on this information. This initial contour model is then deformed by minimizing a cost function.The ellipse fitting approaches first segment pre-processed ultrasound images through clustering or histogram analysis [10,17] or perform edge detection [27], in either case producing a binary image of the fetal skull. The Hough transform [10] or the randomized Hough transform (RHT) [17,27] is then utilized to fit the ellipse model to the binary image. As Hough transform and RHT are very sensitive to image artifacts, these methods require the user to define an initial region of interest (ROI) [27] or their application is limited to images where head contour is complete and is not overlapped by other structures [10].The supervised learning approach of [2] is different from the methods cited above as it directly exploits expert annotations of the images to produce the segmentations. More specifically, the method of [2] searches for a minimal bounding box containing the head of the fetus in the ultrasound image. The method works by training a three-stage classifier, termed constrained probabilistic boosting tree, based on manually segmented images.In this paper, we present a new method for the fetal skull segmentation from 2-D ultrasound images. Based on the skull segmentations, it is then straightforward to compute the biometric measurements of BPD, OFD, and HC. The method is completely automatic and it requires no user interaction unlike many methods cited above. This new method is named Difference of Gaussians revolved along Elliptical paths or DoGEll. The idea is to construct a template image of the fetal skull parametrized by both the calvarial thickness (the thickness of the skull) and an ellipse modelling the contour of the skull. This is unlike previous ellipse fitting methods [10,17,27] that try to fit a single ellipse into the image, i.e., these previous methods do not model the skull as an entity having a finite thickness but instead make use of image processing operations that try to reduce its thickness to a single pixel. In constructing the template image, we assume that the image intensity is high within pixels representing the skull (due to a high acoustic impedance of the bone) and lower immediately inside and outside the skull. The template is then matched to the ultrasound image by minimizing a cost function designed to measure the lack of match between our parametric elliptical image model and the observed image. More specifically, for a given ellipse, we construct a surface that models the pixel values of the skull and surrounding areas by revolving a difference of Gaussians (DoG) along the elliptical path and define the cost function as a negative correlation between the observed image and the surface. This cost function is robust to various image imperfections as demonstrated in Fig. 2. To find the optimum parameters defining the ellipse and calvarial thickness, the cost function is globally minimized by a multiscale multistart Nelder–Mead algorithm [19,14] devised specifically for this purpose. Notice that this new method differs from the previous region based methods [12,2] in that instead of trying to maximize the match the image segmentation (consisting of foreground and background regions) as in the previous methods, it matches a template image constructed based on the skull parameters to the observed image. This way it is possible to reduce the sensitivity of the method to the high intensity artifacts in the background region.This DoGEll method won the first prize of the head sub-challenge in the Challenge US: Biometric Measurements from Fetal Ultrasound Images, held in conjunction with and supported by the IEEE International Symposium on Biomedical Imaging (ISBI) 2012 in Barcelona, Spain [22]. The contributions of the present paper are two-fold. First, we present a detailed account of the winning DoGEll method for the first time. The method has not been published in peer-reviewed literature. A short account of it has been presented in the Challenge proceedings [9] and one paragraph summary was presented in [22]. Second, we present a new, improved implementation of the DoGEll method typically running in under 5 seconds per image, thus yielding a 60 fold savings in computation time as compared to the one winning the segmentation challenge. The difference in the quantitative results between the implementations due to speed ups is minimal and the new, faster implementation would have won the segmentation challenge as well. The main specific differences between the old [9] and new (this paper) method are (i) the new minimization algorithm that uses considerably fewer restarts and embeds an insertion sort strategy to accelerate the Nelder–Mead algorithm, (ii) a cost function (Eq. (3)) that is modified to be better principled mathematically as explained in more detail in Section 2, and (iii) faster image pre-processing.The evaluation of our method is carried out with the dataset used in the Challenge US: Biometric Measurements from Fetal Ultrasound Images. This consists of 90 2-D fetal ultrasound images of the head, some of which are purposely of very low quality, acquired on fetuses at different gestational ages. The segmentations and biometric parameters derived from the automatic DoGEll method are compared to the manual analysis of three independent experts. The evaluation in this paper is based on the same principles as in the challenge, i.e., the method development and evaluation were completely independent and the method developers (AF, MM, AP and JT) did not have access to the manual segmentations nor to the biometric measurements. The evaluation results show that the DoGEll method can automatically segment the fetal skull from ultrasound images with an accuracy similar to the inter-expert variability of the manual segmentation.The paper is organized as follows. In Section 2, we describe the cost function that we minimize to obtain the segmentations. In Section 3, we describe the applied image pre-processing, the algorithm for the minimization of the cost function, and the procedure for computation of biometric parameters based on the segmentation results. Section 4 describes the quantitative validation of the method using ISBI 2012 Challenge data, Section 5 presents the results of the validation, and Section 6 concludes the paper by discussing the methodological contributions and experimental results.In this section, we describe the cost function to segment fetal skulls from ultrasound images. As already mentioned, we assume that the head contour of the fetus can be modeled by an ellipse. The main rationale behind the proposed cost function, as illustrated in Fig. 3, consists of fitting of an image model which comprises of three nested elliptical annuli to the image: the centermost representing the skull of the fetus characterized by high image intensity values (bright pixels); the inner and the outer representing the surrounding areas, usually exhibiting relatively low image intensity values. The image model is constructed based on a single ellipse and a parameter modeling the thickness of the skull. We use a difference of Gaussians, see Fig. 4(a), along each half line leaving from the center of ellipse in modelling the regions.In more detail, we parametrize each ellipse E(a) with 5 parameters: center coordinates c1, c2, semiaxis lengths r1, r2, and rotation angle in radians θ, organized into the vectora=[c1,c2,r1,r2,θ].Leth(x1,x2,a)be the radial half-line leaving from the center (c1, c2) and passing through the point (x1, x2). Usingh(x1,x2,a), we measure the radial distance d(x1, x2, a) between (x1, x2) and the ellipse E(a), as well as the normalized radial distance r0(x1, x2, a) between (x1, x2) and (c1, c2), i.e. the distance between those two points divided by the radius of the ellipse alongh(x1,x2,a). Then we define a surface(1)g(x1,x2,a,s)=fs(d(x1,x2,a))−f3s(d(x1,x2,a))r0(x1,x2,a),where fsand f3sare two univariate Gaussians centered at zero with standard deviations equal to s and 3s, respectively. This is our image model for a given ellipse. An example of the surface g(x1, x2, a, s) is shown in Fig. 4(b) and the rationale for its design is described in Fig. 4(c).Before introducing the cost function based on the image model, we provide a few facts about the function g, including the choice of the standard-deviation parameters of the DoG, geometric properties of g, and its zero-mean radial property.In DoGs, the ratio between the standard deviations of the two Gaussian functions mainly controls the rate at which the negative tails approach zero relative to the width of the central positive lobe. A larger ratio gives longer tails, and hence, in our case, more sensitivity to the surround distant from the skull. As the ratio approaches unity, the DoG approaches the minus second derivative of a Gaussian. In most applications the ratio takes values between 1.5 and 5. For our purposes a value of 3 provides sufficient sensitivity to the surrounding region of the skull [18,16].The numerator of g enjoys two distinct symmetries. First, it is radially symmetric, i.e., the profile along each radial line is one and the same: it is the DoG. Equivalently we can say that the numerator of g is constant along the contour lines. Second, each radial profile is symmetric about the point of intersection between the radius and the ellipse (a trivial consequence of the symmetry of the DoG). Overall, it means that the numerator of g assumes the same value on any two distinct contour lines sharing the same radial distance from the ellipse (one contour line internal to the ellipse, and the other one external). Even though the DoG is by construction a zero-mean function, after elliptical revolution the integral balance is lost due to the nonuniform radial geometry, as shown in Fig. 4(c). In particular, the green patches illustrate two finite area elements. Riemann integration of a bivariate function is the limiting summation over these elements, as their respective area tends to zero. Observe in the figure that the size of the area elements increases proportionally to their radial distance from the center. Therefore, by dividing the numerator by r0, we restore the integral balance.Clearly,∫−∞+∞fs(ξ)−f3s(ξ)dξ=0. However, when defining g, each radial line is bounded, on one side by the center of the ellipse, and on the other side by the image boundary. This means that the argument d(x1, x2, a) ranges from d(c1, c2, a) to a finite positive value attained at the intersection of the radial line with the image boundary. Therefore, the tails of the DoG are formally missing from g. This notwithstanding, due to their exponential decay, the tails are numerically negligible for all parameter combinations of practical relevance.22The DoG is numerically negligible outside of the interval−18s,18s, with the radius 18s being the six-sigma range for the standard deviation 3s of the wider Gaussian f3s. All cases of practical relevance satisfy the inequality d(c1, c2, a)>18s by a large margin, which means that tails of the DoG have no numerical relevance.Thus,(2)∬Θg(x1,x2,a,s)dx1dx2=0for any radial support Θ, such as the wedge drawn in yellow in Fig. 4(c), including as maximal Θ the whole image domain Ω.Consequently, for an image z and an ellipse E(a), the cost function is written as(3)C(z,a,s)=−∬Ωz(x1,x2)g(x1,x2,a,s)dx1dx2+λ(max(0,max(r1,r2)min(r1,r2)−CI))2,where λ=0.5 is a regularization parameter selected experimentally, and the term CI=1.4 is used to model the inverse of the minimal allowable cephalic index, see, e.g., [13] for a justification of this value. The regularization term is introduced to speed up the convergence of the minimization algorithm in those images where the skull is not fully visible (e.g. see the right-most panels in Fig. 2). Practically, the regularization term allows to reduce the number of the re-starts of the minimization algorithm by preventing the convergence of the algorithm to obviously incorrect solutions.The cost function C(z, a, s) is affine with respect to z and, due to the characteristics of g(x1, x2, a, s), it is not affected by the presence of large uniform regions in the image. As observed in Eq. (2), the integral ∬Ωg(x1, x2, a, s)dx1dx2=0 for all reasonable a and s, therefore, if the image is noninformative (has a constant value in every pixel), every ellipse receives the score zero. This property is important because it ensures that an addition of a constant to the image intensities does not alter the value of the cost function, i.e. C(z+B, a, s)=C(z, a, s), where B is a scalar and z+B is to be interpreted as adding B to each intensity z(x1, z2).For an N1×N2 image z, the integral in Eq. (3) is computed as the following discrete sum:(4)C(z,a,s)=−∑i=1N1∑j=1N2z(i,j)g(i,j,a,s)+λ(max(0,max(r1,r2)min(r1,r2)−CI))2,where z(i, j) denotes the intensity of z in the spatial position (i, j). Image padding is necessary for the zero-score condition (2) to hold for the noninformative images whenever the integral is approximated as in Eq. (4). We did not implement the image padding in the original challenge submission and had to compensate for it by introducing a multiplicative regularization term and an additional regularization parameter (γ in Eq. (1) of [9]). However, by implementing the image padding, we can safely eliminate this regularization and the corresponding parameter. Based on the same considerations given in Footnote 1, only a narrow innermost portion of the padding border is numerically significant with respect to the image model g. Our implementation uses a 120-pixel wide padding border, which was found to be sufficient in all experiments.

@&#CONCLUSIONS@&#
