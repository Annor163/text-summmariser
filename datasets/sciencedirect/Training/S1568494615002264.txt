@&#MAIN-TITLE@&#
Information granularity model for evolving context-based fuzzy system

@&#HIGHLIGHTS@&#
A new operational framework to compromise between interpretability and accuracy is proposed.The proposed Evolving Information Granule (EIG) increases the information granules (rules) by partitioning the output domain.The distinct output-contexts are adapted using a constraint which has the dynamic nature.The overfitting criterion is estimated online and approximated from the current and previous evolving stage.The results show that the proposed model achieves a reasonable accuracy with lower number of rules.

@&#KEYPHRASES@&#
Information granule,Evolving system,Output-context fuzzy system,Dynamic constraint,Overfitting state,

@&#ABSTRACT@&#
An information granule has to be translated into significant frameworks of granular computing to realize interpretability–accuracy tradeoff. These two objectives are in conflict and constitute an open problem. A new operational framework to form the evolving information granule (EIG) is developed in this paper, which ensures a compromise between interpretability and reasonable accuracy. The evolving information granule is initiated with the first information granule by translating the knowledge of the entire output domain. The initial information granule is considered an underfitting state with a high approximation error. Then, the EIG starts evolving in the information granule by partitioning the output domain and uses a dynamic constraint to maintain semantic interpretability in the output-contexts. The important criterion in the EIG is to determine the prominent distinction (output-context) in the output domain and realize the distinct information granule that depicts the semantics at the fuzzy partition level. The EIG tends to evolve toward the lower error region and realizes the effective rulebase by avoiding overfitting. The outcome on the synthetic and real-world data using the EIG shows the effectiveness of the proposed system, which outperforms state-of-the art methods.

@&#INTRODUCTION@&#
Information granules are presented as a certain conceptual framework of basic entities [1]. A level of abstraction that is conceived by global knowledge implies interpretability and hence, information granules. Granular computing, which is a unified conceptual and computing framework by the information granules, exhibits the descriptive and functional representation of the global concept [2,3].Conditional or context-based fuzzy granular model was proposed by Pedrycz [3–6], in which conditional fuzzy C-means was considered [6]. The main objective was to define the output context partition and then cluster the corresponding inputs. The number of contexts and clusters per context are predefined and fixed [6]; hence, a computational model of the fuzzy system is manually designed by human experts [7,8]. In addition, the number of output-context and its corresponding input clusters are based on the distinct nature of the data and considered locally distributed. The result is often highly prejudiced and uncertain because prior knowledge of humans to design the fuzzy model is limited. Without considering the input space, the partition on the output domain may cause underfitting or overfitting phenomena that could lead to inaccurate performance. The input space for avoiding the imbalance partition of the output domain needs to be considered when partitioning the output domain because data are unevenly distributed in the input space. This imbalance partition of the output domain maybe referred to as overfitting condition.Error-reducing evolving methods are described in the simplified structure evolving method (SSEM) [9] and evolving-construction scheme for fuzzy system (ECSFS) [10]. In both studies, the structure of the fuzzy rulebase system evolved and errors to fit the changes were reduced within the given system. These evolving processes continued to achieve the desired threshold accuracy. In addition, extremum and inflexion points were computed by using least square method (LSM) to obtain the best accuracy. Learning methods employed in [9,10] are based on global and localized learning for the rule consequent and the rule antecedent parameters, respectively. Without considering the antecedent part, the lack of localized learning in the consequent part may cause an imbalanced partition of the output domain. Self-adaptive fuzzy inference network (SaFIN), self-constructing neural fuzzy inference network (SONFIN), and evolving neural-fuzzy semantic memory (eFSM) were proposed by Tung et al. [11], Juang and Lin [7], and Tung and Quek [12], respectively. These fuzzy systems have attempted to design a consistent and compact fuzzy rulebase system to ensure a clear semantic meaning of fuzzy partitions with reasonable accuracy. Self-adaptation in these fuzzy systems [7,11,12] is applied at the consequent and antecedent parts independently; therefore, structure learning includes pruning inconsistent or identical rules and deleting orphaned rules. Hence, an operational framework for granular computing is needed to synchronize the self-adaptation in both consequent and antecedent parts, and the formation of the distinct information granule is required to consider the aforementioned limitations of the existing methods.Interpretability and accuracy are two contradictory requirements for the fuzzy information granule [4,6–12]. Interpretability is the ability to explain the behavior of an application system in an understandable way. Accuracy is the capability to represent the similarity between the real test data and the proposed fuzzy model. Mean square error (MSE) or root MSE (RMSE) measures the accuracy of how reasonable the model is with respect to the real test data. Nevertheless, interpretability is a subjective property, and its measure remains an open problem [29]. Most researchers use the following aspects for interpretability measure: fewer rules, fuzzy linguistic terms that have semantic property, and rule premises [29]. Table 1summarizes the works that consider interpretability–accuracy tradeoff for fuzzy models grouped by publication year. Information granule should be specific in a way that well-defined semantics are experienced. Therefore, interpretability constraint can be significantly considered for granular computing to provide a descriptive representation of the experimental evidence. Various models consider the interpretability constraint, which is depicted in the eighth column of Table 1. Consequently, various clustering approaches are considered to apply the interpretability constraint (seventh column of Table 1). Nevertheless, few studies considered the context or condition-based approach and overfitting or underfitting situation while the evolving granulation process continues.Furthermore, the concept of justifiable granularity and allocation of information granularity [16,17,20,21,25] consist of the fundamental blocks of granular computing. The optimal allocation of information granularity [21,48] can be employed to group decision making problems [22–24] in which the initial preferences from the decision maker can be adapted to reach higher agreement [48]. Nevertheless, the initial preferences are often arbitrarily decided, and the designed model might not be able to achieve a desirable performance because the granularity depends on the distribution of the application problem. Therefore, granular computing with sequential decision making was proposed in [26,27] where finer granulation level with more detailed information is considered. A relationship between progressive computing and granular computing was proposed in SSEM [9], ECSFS [10], and top-down progressive computing [28]. Progressive computing in these models realizes an evolving granule system from coarser information granulation to finer information granulation. SSEM and ECSFS are used as overfitting and underfitting criteria to continue progressive computing as depicted in Table 1.Models to overcome the interpretability–accuracy tradeoff are well documented in literature. Numerous algorithms to represent fuzzy granular models, adaptive neural fuzzy systems, and evolving fuzzy systems have been developed. Motivated by the aforementioned existing models and Table 1, the following concerns are significant when considering a computing framework for fuzzy information granule: (1) evolving granule process from bloated granularity (coarser partition) to higher granularity (fine partition), (2) interpretability constraint for granular computing, (3) overfitting and underfitting situations in the evolving process, and (4) the stability–plasticity tradeoff.First, the information granule evolves from coarser to fine partition, which consequently provides the oblique decision boundaries [8,31]; thus, the evolving process and its decision boundaries allow us to achieve low model error. For example, ECSFS [11] and SSEM [10] models are error-reducing evolving methods, and boundary constraints are used in the evolving method. Consequently, many studies on fuzzy granular approach focus on the improvement of interpretability constraints (or decision boarders) to achieve a low model error [16,17,20,21,25]; this is a second significant consideration for granular computing. Therefore, evolving granule approach and interpretability constraint are important to coexist concurrently. Hence, this computing framework can be a tradeoff between interpretability and accuracy.The third important consideration is the overfitting and underfitting situations in the evolving granule approach. Underfitting occurs when information granule is too coarse to fit data, thereby resulting in poor testing accuracy. Furthermore, some evolving stages cannot properly represent the data when the evolving granule process continues, which results in an unbalanced state. Therefore, this unbalanced state leads to fuzzy system overfitting (i.e., the data fit is close because of the small and unbalanced information granule), thereby resulting in poor testing accuracy. Hence, evolving granule approach should consider the underfitting and overfitting state of each evolving stage. Moreover, the realization of these unbalanced states can enhance the system performance if stability–plasticity tradeoff is considered. The stability–plasticity tradeoff is the fourth significant consideration to design a granular framework, combines the past and any future knowledge from the training data, and achieves a current and up-to-date system for modeling the application environment [11,12]. Therefore, the stability–plasticity tradeoff is important to develop the interpretability constraint and over/underfitting index.Motivated by these four considerations, EIG is proposed as a bridge between semantics at the fuzzy partition, accuracy, and complexity (number of rules). The proposed EIG is the output-context fuzzy system. The EIG partitions the output domain at a higher error region, in which evolving process then achieves a low model error. An interpretability constraint is considered to be dynamically updated for each training data. Furthermore, over/underfitting index is realized for each evolving stage and depends on the previous evolving stage. Both interpretability constraint and over/underfitting index incorporate the previous and current stages; hence, stability–plasticity dilemma is avoided. The EIG learning technique is a self-organizing method [11,12,30,32,33]. The self-adaptation in both consequent and antecedent parts is realized concurrently, and it learns based on global learning of rule consequent parameters and further localizes learning in both consequent and antecedent parameters. The evolving system in the EIG keeps the semantic value at the fuzzy partitions and finds the distinct information granule.The remainder of this paper is organized as follows: Section 2 elaborates the design methodology of the evolving information granule. Section 2.1 elaborates the preliminaries of the proposed system. Section 2.2 focuses on the formulation of the EIG and description of the underfitting state. Sections 2.3.1 and 2.3.2 describes the evolving information granules and its dynamic constraint. Section 2.3.3 explains the overall algorithm and the overfitting index. Section 2.4 discusses the features of the EIG and the condition of the overfitting state. Section 3 presents examples to evaluate the proposed model, and real-world regression datasets are considered for performance analysis. The main contributions are highlighted in Section 4. Section 5 summarizes the arguments established in this paper.This study focuses on the formation of the meaningful information granule based on experimental evidence. The evidence is the ith training data denoted asx,diwherex=(x1, x2, …, xn) is an input vector, and d is the corresponding output. Information granule has to be translated into significant operational frameworks of granular computing in a way that realizes the interpretability–accuracy tradeoff. Interpretability–accuracy tradeoff of fuzzy models is essential, although these contradicting objectives remain an open problem [27–29]. Therefore, the conflict situation needs to be handled. Hence, two instinctively compelling requirements are considered in the proposed EIG as follows:(i)Evolving information granule: Prominent distinctions are realized in the output domain by using the self-organizing method, and each distinction is considered the centroid of the output-context or information granule. The positions (centers) and spreads of the linguistic levels of the output-context and their corresponding input clusters can be self-determined from the training dataset. The evolving process continues, and each evolving process identifies whether the evolving stage is overfitted or not. Therefore, a reasonable fuzzy rulebase is achieved by avoiding the overfitting condition.Semantic interpretability using dynamic constraint in the output-contexts: The evolving information granule should be specific that well-defined semantics in the output-contexts are experienced. Therefore, highly detailed information granule is required to better reflect existing experimental data. The formation of the information granule has to adhere to the interpretability constraints at the fuzzy partition level; these constraints are considered for the interpretability–accuracy tradeoff.These two requirements are in conflict, and interpretability–accuracy tradeoff appeals from the intuitive perspective [29]. Therefore, the operational framework for evolving information granule is formed in the proposed EIG where a sound compromise can be formed between interpretability and accuracy. Considering the two requirements, evolving information granule for the context-based fuzzy system is described in detail in the following sections. The proposed EIG is an output-context fuzzy system and evolves the information granule as a self-automated process. Fig. 1shows the evolving process to ensure the aforementioned requirements. A flowchart is shown in Fig. 1 to realize the distinct information granule based on experimental evidence. First, the initial information granule is considered as underfitting state (detailed in Section 2.2). Then, the evolving process continues by adapting the distinct output-context and its corresponding input cluster (detailed in Section 2.3.1). In the process, a dynamic constraint is considered for distinct output-context, which has a dynamic nature in that it depends on current and previous stages (detailed in Section 2.3.2). Input clusters of its corresponding output-context are optimally allocated (both centers and variances) by using self-organizing method. Termination occurs in the evolving process when satisfactory accuracy is achieved with respect to existing models. The EIG recognizes the overfitting state and hence, effective rule bases are realized to represent the application environment (detailed in Section 2.4).The sequence of the three boxes in the loop is important to continue the evolving process, which is depicted in Fig. 1. The EIG is an output-context fuzzy system. Therefore, the entire evolving process continues based on the distinct output-context. Considering one evolving stage, a distinct output-context is realized in the first step of the loop. The dynamic constraint is then calculated for this output-context (i.e., the second step of the loop). Finally, adaptation and refinement are performed concurrently in the distinct output-context and its corresponding input clusters (the third step in the loop) based on the dynamic constraint. The detailed algorithm of the evolving information granule to make the fuzzy rulebase is described in Section 2.3.3.Given a modeling problem with n input variables and N data samples, the EIG starts with a single fuzzy rule where an initial global domain is considered for the whole output-context. The ith training data is assumed asx,di, wherexi=x1,x2,…,xp,…,xniis the input vector, and diis the corresponding output and i=1, 2, …, N. An output-context s (s=1, 2, …, St), which encodes an IF-THEN Mamdani-type fuzzy rule at t evolving stage, is represented as follows:(1)Rt,s:IFx1isA1t,(s),andx2isA2t,(s),…,andxpisApt,(s)THENyisCt,(s)where Ct,(s) is the sth consequent part associated with the sth output-context, andApt,(s)is the sth antecedent part associated with the pth input variable. A Gaussian membership function is employed for both linguistic levels Ct,(s) andApt,(s).(2)μ=e−x−c2/σandσ=−ak−bk2lnαwhere c and σ are the center and width of the linguistic levels. ak(orbk) means that data are located at the border of the kth linguistic parts (Ct,(s) orApt,(s)). α>0 is the minimum membership value and is also defined as a distinguishability factor that keeps the semantic value for both Ct,(s) andApt,(s). Let consider sth domain, which belongs to the sth rule (or sth output-context). For the sth consequent part of the output-context (Ct,(s)), ct,(s), and σt,(s) are the distinct center of the sth output-context and its spread, respectively. The antecedent part of the sth output-context is defined as(3)A1,2,…,nt,(s)x=∏domainsμt,(s)x=∏p=1nμt,(s)xpMaximum compatibility grade with the new pattern is used to determine the winner rule. Hence, the winner ruleRt,s*for a new patternxnew={xnew1,…,xnewp,…,xnewn}is defined as(4)μt,(s*)xnew=maxμt,(s)xnew:s=1,2,…,StThe EIG begins with the first fuzzy rule by translating knowledge of the entire output domain. The distinct output-context (or rule) creation for the proposed EIG is shown in Fig. 2. The initial rulebase system in the EIG is an underfitting state with a high approximation error (Fig. 2a). The process begins with the initial evolving stage (t=1) where only the single rule exists (Fig. 2a). The EIG locates the data sample with the largest error means that are too coarse to fit the data (i.e., referred to as the underfitting state). The formation of the first consequent part (when t=1, s=1) of the output-context, C1,(1) can be described as(5)c1,(1)=d1andσ1,(1)=σglobalwhere d1 is the output of the first training data, and σglobal is the spread of the output domain for an initial fuzzy rule that covers the entire output domain. d1 and σglobal of the Gaussian function are embedded in C1,(1). The formation of the antecedent part associated with C1,(1) can be described as:(6)Ap1,(1)x|x∈domains=1=∏domains=1μ1,(s)xpAfter initializing the first fuzzy rule, the evolving process adds more fuzzy rules and terms to find the optimum accuracy at a rational partition of the output-context.After defining the underfitting state (or the first rule) as shown in Fig. 1, the EIG starts evolving the output-context by partitioning the output domain to realize the distinct output-context. Distinct points are the higher error point, and selection of these points to split the system reduces approximation error. Motivated by [34], the approximation errors are quickly and greatly reduced if these distinct points are selected for partitioning. Hence, a balanced fuzzy rulebase is realized and achieves significant accuracy if proper tuning points (distinct points) are found in the output domain; these tuning points are considered the center of the fuzzy levels.Fig. 2 shows the visualization of partitioning the output domain process. The important criterion in the EIG is to discover the prominent distinctions in the output domain. Previous researchers [10,34,35] introduced the selection of the splitting points to reduce approximation errors. However, unlike the SSEM [9] and ECSFS [10] where the LSM algorithm is used to select the optimal consequent parameters, the proposed EIG evolves and self-determines the distinct output-context.At the early stage of the evolving process (i.e., t=1), s=1 (i.e., only a single rule exists). Then, more fuzzy rules and terms will be added. The concept of the self-organizing system is used to ensure the self-determination of the fuzzy levels from each training data. At evolving stage t=2, the first output-context (C2,(1)) is formed as the following equation:(7)σinit1=σ1,(1)=σglobalandc2,(1)=d1andσ2,(1)=σinit2=σinit1−σevolveσevolve is arbitrarily taken where the output partition slowly increases. By assuming an existing output-context, the EIG proceeds by computing the similarities between the presented value (ith training data) and existing output-context. The similarity between the output diof the ith training datax,diand an existing output-context (Ct,(s)) is given as(8)SMdi,Ct,(s)=μt,(s)ct,(s),σt,(s);diThe similarity measure (SM) of two consecutive Gaussian-shaped fuzzy levels is described in [36]. A similarity threshold (β) is considered to identify the best matched output-context with the presented value. If the similarity measure between the output-context and presented value does not exceed the threshold value (SM≤β), a prominent distinction is observed, and the EIG forms a new distinct output-context at t evolving stage associated with the input cluster.(9)ct,(s+1)=di,σt,(s+1)=σinitt=σinitt−1−σevolveandApt,(s+1)x|x∈domains+1=∏domains+1μt,(s)xpConversely, if the similarity measure between the output-context and presented value exceeds the threshold value (SM≤β), the EIG finds the best matched output-context denoted asCt,(s*)where(10)s*=argmaxSM>βSMdi,Ct,(s)Therefore, the best matched output-context is able to provide a satisfactory description of the ith training data. Hence, old knowledge (i.e., existing output-context) in the system coexists with the new information (ith training data). Therefore, merging process is applied to the presented value and the best matched output-context.Remark 1The proposed EIG evolves the distinct output-context. The center of the output-contexts has a distinct nature, which is depicted in Eqs. (7) and (9). Therefore, the merging process is performed inCt,(s*)only for the sigma (width) between two consecutive membership functions by using (11). Nevertheless, the input cluster is adapted by using Eq. (3) to cover all input data associated with the sth output-context. Therefore, merging and adaptation are concurrently performed inApt,(s*)(x)for both width (σpt,(s*)) and center (cpt,(s*)) that are defined in Eqs. (11) and (12), respectively. If an overlap is found after the adaptation of the input clusters, the adaptation is revoked to retain the previous input clusters.In Remark 1, merging criteria are defined for the best matched output context and corresponding input clusters. Assuming that [a1, b1, c1]∈Zexist and [a2, b2, c2]∈Znew, where Zexist and Znew are two fuzzy levels, respectively. The points [a1, a2], [b1, b2], and [c1, c2] denote the left support, right support, and center, respectively. Therefore, the average width and center between fuzzy levels can be written as Eqs. (11) and (12), respectively [12].(11)σavgt,(s*)=12ln2maxb1,b2−mina1,a2(12)cavgt,(s*)=12mina1,a2+maxb1,b2The proposed method restricts σt,(s) in order to realize the distinct output-context because the EIG uses the self-organizing method. SONFIN and eFSM techniques use the self-organizing method and consider the uniform coverage criterion (i.e., threshold) during structured learning. Furthermore, SAFIN integrates the new and old knowledge such that a distinct cluster is formed by averaging the widths of the left and right neighbor. However, the proposed EIG defines a width constraint Fσfor the best matched output-context (when SM>β), and it dynamically updates by calculating FLand FR. L and R are assumed to be the left and right neighbors of the best matched output-context, respectively. In Fig. 3, FLand FRare the left and right support of Fσ, respectively. However, the constraint Fσis considered in the output-context to restrict the overlap to realize the distinct output-context.In this study, the dynamic constraint for the best matched output-context (Ct,(s*)) is defined asDFσ,σavgt,(s*)=minFσ,σavgt,(s*). In addition, FLand FRare arbitrarily taken from the quarter of the width, which is shown in Fig. 3. The lateral positions of FLand FRmay vary except the center points, which means that FL≠ct,(s−1) and FR≠ct,(s+1). If FL=ct,(s−1) and FR=ct,(s+1), then Fσis referred to as a uniform coverage criterion, because the width and center of a cluster remain constant. Hence, Fσwill never dynamically updates with the absence of σt,(s−1) and σt,(s+1), which is proven in Theorem 1.Theorem 1Fσis defined as a parameter of dynamic constraint and {Fσ|FL≠ct,(s−1), FR≠ct,(s+1)}.FLand FRare taken as a quarter of the width (Fig. 3). Therefore, adaptation of the best matched output-context (Ct,(s*)) is defined by using Eq. (2) as follows:On the contrary, FL=ct,(s−1) and FR=ct,(s+1). Therefore, Fσis a constant value because it always selects centers (ct,(s−1) and ct,(s+1)) of the distinct output-contexts and follows a uniform coverage criterion. Hence, Fσis found by using Eq. (15) as follows:(20)Fσ=−ct,(s−1)−ct,(s+1)2lnα=constantFurthermore, the merging process is always adapted in the width (sigma) of the output-context by using (13). Therefore, Fσusing (20) never dynamically updates with the absence of σt,(s−1) and σt,(s+1).The evolving process on the output domain continues until a satisfactory accuracy (or model error) is achieved. The detailed EIG algorithm that is used to make a fuzzy rulebase is shown in Fig. 4.Based on the EIG algorithm, step 6 is used to terminate the evolving process, where a global threshold error called Eglobal is defined in the EIG for termination purpose. The evolving process in the EIG continues until the termination criterion E/(t)≤Eglobal is achieved, where E/(t) is derived from (21), considering either to train or test the dataset.The sum of square error (SSE) of tth evolving process is defined in Eq. (21), where the number of training data denoted as N.oxiandddesiare the model output and desired output of the ith training data, respectively.(21)Et=∑i=1Noxi−ddesi2Step 7 recognizes the effective rulebase(s) by avoiding the overfitting state. The following definition describes the overfitting index where its estimation is fully online, is not based on the predefined threshold, and is approximated from the previous and the current evolving stage.Definition 1Evolving granule error (EGE) index is a straightforward index to recognize the overfitting situation in the evolving process.The EGE(t) index is used to handle the situation of the overfitting state and is a straightforward index used to recognize the imbalance situation in the evolving process and avoid the overfitted evolving stage. The evolving process partitions the output domain at the higher error region (i.e., distinct data as the center for new output-context); therefore, it reduces error and proceeds to the rational partition to obtain optimum accuracy (see Theorem 2 of Section 2.4). A detailed description of the overfitting state is given in Section 2.4.In this study,σinittis referred to as the parameter of the localized learning, and it realizes the distinct output-context that is defined in (9). Therefore,σinittincorporates previous and new information. Furthermore, the EGE index in (22) calculates from previous and current evolving stages, which are considered to avoid overfitting. Hence, the stability–plasticity dilemma [11,12] is avoided in the proposed EIG. Therefore, previous knowledge in the system and new knowledge from the training data are incorporated in the system and provide a more accurate representation of the fuzzy model.This section discusses and presents some properties of the EIG. For each evolving stage, model error (i.e., by using (21)) is reduced with respect to the previous stage, and the evolving process proceeds by decreasing the model error, which is clarified by Theorem 2.Theorem 2Model error at tth evolving stage is lower than that at the previous stage; therefore, E(t)<E(t−1).Let, ot−1 is the model output and{oˆ1t−1,oˆ2t−1,…,oˆqt−1}∈ot−1its fuzzy level. Similarly,{oˆ1t,oˆ2t,…,oˆrt}∈otdepicts the fuzzy level for tth output model, ot. Given,σinitt=σinitt−1−σevolvefrom (9). Thus,σinitt<σinitt−1, and the proposed EIG fits close data at tth stage with respect to the (t−1)th stage. Therefore, (21) may be composed of the form of inequality for tth and (t−1)th evolving stage asEoˆ1t,oˆ2t,…,oˆrt<Eoˆ1t−1,oˆ2t−1,…,oˆqt−1. Therefore, E(t)<E(t−1).As the evolving stage proceeds, the width of the output-context (σinitt) decreases, and the EIG leads to fine partitions in the output domain (Theorem 2). At a specific evolving stage, the width of the output-context becomes significantly small and unbalanced such that it cannot represent the data properly. Therefore, it leads to a fuzzy system with a number of rules that could possibly cause overfitting (i.e., unbalanced fitting to data because of the small width of the output-context). Therefore, the EIG needs to recognize the overfitting state, thereby restricting the number of output-contexts.At a specific evolving stage, the evolving process reaches a condition in which E(t)≥E(t−1), which contradicts Theorem 2. Therefore, the EGE(t) index becomes greater than 1, which means that this evolving process would cause overfitting to the model. Therefore, the effective rulebase may be obtained by avoiding this overfitting state. Thus, this global learning by the EGE(t) index finds the effective fuzzy rulebase systems. Hence, reasonable accuracy is achieved for the testing data.Furthermore, the evolving process in the proposed EIG not always has an additive with regard to rules, which can be proven by Theorem 3.Theorem 3The number of fuzzy rules is greater than or equal to that in the previous stage. Hence, St≥St−1, where Stand St−1 are the number of rules at the evolving stage t and (t−1), respectively.At tth evolving stage,σt,(s)=σinitt=σinitt−1−σevolve. Thus,σinitt<σinitt−1and hence the proposed EIG closely fits the data at stage t with respect to the (t−1) stage. Therefore, more prominent distinction and granules (i.e., fuzzy rule) are realized at tth evolving stage. As a result, St>St−1. Moreover, σevolve has little effect if less contribution is realized in the evolving stages in a way thatσinitt≈σinitt−1. Therefore, a new rule (or distinct output-context) is not created in the next evolving stage. Hence, without loss of generality, we have a relation where St≥St−1.Relating both Theorem 2 and Theorem 3, two conditions and its solution to analyze EGE(t) index as follows:(a)If St>St−1 sinceσinitt<σinitt−1, then E(t)<E(t−1). Therefore, E(t)≥E(t−1) causes the overfitting and avoids the tth evolving stage to find the effective rulebase. Hence, EGE(t) is computed by using Eq. (22).When St=St−1 then a new rule is not created. LetSt=St+1=⋯=St+vandSt−1=St−2=⋯=St−w. Therefore,E(t′−1)=max{E(t−1),E(t−2),…,E(t−w)}. Hence,{E(t)≥E(t′−1),E(t+1)≥E(t′−1),E(t+2)≥E(t′−1),…,E(t+v)≥E(t′−1)}causes the overfitting. Thus, theEGE(t+v)index for the second condition may be defined asThe characteristic equation for EGE index is defined as (24), where the effective and overfitted rulebase(s) are found when EGE<1 and EGE≥1, respectively.(24)EGEt=<1,effective≥1,over-fittingWell-known real-world data automobile miles per gallon (MPG), which is denoted as Dataset 2, is used to evaluate the performance [37]. Fig. 5shows the effective and overfitting regions. Evolving on output domain is valid (i.e., EGE<1) until the number of output-context is 11, and further partition until 16 causes the overfitting, where the fuzzy model cannot represent the data properly. The proposed EIG is the output-context, self-reliant, and fully data driven approach employed for automated formulation of the fuzzy rulebase. This evolving approach ensures that the effective rulebase (or model) sufficiently represents the application environment.In this section, six benchmark nonlinear datasets illustrate and validate the advantages of the proposed algorithm with respect to the existing models. Two synthetic and four real-world datasets are used in this section to evaluate the performance of the EIG. The first dataset is the identification of a non-linear system [38,39]. The next three datasets are taken from the Nakanishi dataset [41], namely, (1) a human-operated chemical plant, (2) a nonlinear system, and (3) a daily price of a stock. The last two datasets are taken from the UCI repository, namely, automobile miles per gallon [37] and Boston area [38], respectively. In the present paper, the similarity threshold (β) is used to identify the similarity between two consecutive fuzzy levels, and α>0 is employed as a minimum membership value where the universe of discourse (UoD) is strongly covered [11]. Sensitivity test for different values of α and β is shown in [11]. In the present study, all datasets consider the similarity threshold β=0.8. Furthermore, α=0.2 is used to strongly cover the UoD and retains the semantic meaning in the EIG model. The evolving constant σevolve is taken arbitrarily to ensure that the rule number slowly increases.The following multiple-input multiple-output nonlinear system is considered.(25)y1t=0.4y1t−1−0.1y2t−13+e1ty2t=0.5y1t−1+ut−1+e2tThe system inputs are u(t)=sin(πt/25) and y1(t−1). Two uncorrelated sequences of Gaussian noise are given by e1(t)∼N(0, 0.012) and e2(t)∼N(0, 0.022). Following the description in [38,39], the first 500 training (t=[1:500]) and the remaining 500 testing (t=[501:1000]) data pairs are generated with initial conditionsu(0),y1(0),y2(0)=(0,0,0). RSA [39] and VSANF [40] techniques propose an integrated framework to optimize the number of inputs and the number of rules simultaneously, which leads to a balanced tradeoff between interpretability and accuracy. The proposed EIG compromises interpretability (number of rules) and accuracy. Therefore, the same inputs, u(t) and y1(t−1) are considered in this dataset to compare with RSA and VSANF.In Table 2, the EIG starts from the underfitting state (single rule) with high training and testing errors. Then, it increases the formation of the fuzzy rules by evolving the output-context, where training and testing error reduces while the evolving process proceeds. The first EGE > 1 is found at the fifth evolving stage whereσinitt=0.007; overfitting occurs at this stage. Training and testing errors also increase in this stage because of the overfitting of the model. The second overfitting is found at the ninth evolving stage whereσinitt=0.003. Nevertheless, the testing error does not increase at the ninth stage because a large number of rules (or output-context) are achieved by the EIG, as described in Section 3.7. Therefore, effective rulebases are found in all evolving stages, except the fifth and ninth stages shown in Table 2. Furthermore, 15 fuzzy rules are realized at both the sixth and seventh evolving stages. The redundant number of rules might be found in the EIG that are described in Theorem 3.The realization of the eleven output-contexts while consideringσinitt=0.008is depicted in Fig. 6. Distinct output-contexts are realized in the EIG by using self-organizing method, and these distinct points are considered the center of the consequent fuzzy level. Table 3shows the performance comparison of the EIG and the existing models. Considering y1 as output, the VSANF achieves testing SSE 0.084 with 25 fuzzy rules, whereas the proposed EIG attains an error of 0.054 with eight fuzzy rules. Furthermore, compared with the RSA, which achieves an error of 0.052 with 15 fuzzy rules, the EIG achieves comparable performance with respect to the RSA and achieves reasonable performance in terms of rules and accuracy while considering y2 as output. The RSA employs forward rule selection, backward rule refinement, and optimization criteria to achieve good tradeoff between interpretability and accuracy. The EIG realizes distinct output-context and uses the dynamic constraint to adapt the output-context. Therefore, the proposed EIG realizes a compact and consistent rulebase.This dataset is used to predict the human operation of a chemical plant. Five input variables and one output variable are given, as described in [41]. The feature selection method in [41] selects the inputs x1 and x3. The dataset is split into groups A, B, and C, where A and B form the training dataset and C is the testing data. Fig. 7(a) depicts the realization of the three distinct points. Three rules are generated by taking the distinct data as the center of the consequent fuzzy level, and Fig. 7(b) shows the output-contexts (or consequents level). The output-contests are highly semantic because dynamic constraint D(.) [using (14)] is used for each training data. The antecedent parts of x1 and x3 are shown in Fig. 7(c) to (d). As in Remark 1, the antecedent parts are adapted to cover all input data associated with the sth distinct output-context.The proposed EIG realizes the effective rulebase for the chemical plant dataset where the numbers of rules are below 6 (Fig. 8). Moreover, an overfitted region can be observed when the numbers of fuzzy rules are greater than five because EGE index reaches its maximum value (i.e., EGE≥1), as shown in Fig. 8.Table 4shows the performance comparison for the human-operated chemical plant dataset. The benchmark for comparisons is the accuracies on the testing data (calculated as the MSE) and the correlations between the model outputs with the testing data (calculated as the Pearson correlation coefficient R). The experimental results of the EIG are subsequently benchmarked against the following models: Mamdani-type models—Hebb-R-R [14], POPFNN [42], RSPOP [43], EFuNN [44], and SAFIN [11]; reasoning models [41]—Sugeno P&P-G, Sugeno P, Sugeno P-G, Mamdani, and Turksen IVCRI; and Takagi–Sugeno–Kang (TSK)-type models—ANFIS [45], DENFIS [46], and FITSK [47]. A comparison table is taken from [14]. In Table 4, the Hebb-R-R considers only x3 as input feature, whereas the RSPOP considers x3 and x4. Furthermore, Hebb-R-R and RSPOP reduce the rules by using rule reduction technique. The proposed EIG realizes the distinct output-contexts, controls the width of the output-context self-adaptively, and obtains better accuracy at the fuzzy model to represent the human-operated chemical plant dataset. Unlike Hebb-R-R, the EIG only considers x3 as the input feature, yet it performs better in terms of MSE and R. Furthermore, the EIG considers x3 and x4 as input features for comparison with the RSPOP and POPFNN. As tabulated in Table 4, the proposed EIG obtains better performance with respect to the existing models in terms of MSE, number of rules, and correlation coefficient. These results show that the interpretability–accuracy tradeoff is achieved by the proposed EIG system.This dataset models a nonlinear system that is described in [41]. The original dataset consists of four inputs (x1–x4) and one output (y) variables. Adopting the approach suggested in [41], only input variables x1 and x2 are used in the modeling. The EIG obtains the overfitted region when the number of fuzzy rules is greater than 5. Hence, five effective rulebases represent this nonlinear system in which numbers of fuzzy rules are 1, 2, 3, 4, and 5. The experimental results of the EIG are subsequently benchmarked against the Mamdani-type models [11,14,42–44], reasoning models [41], and Takagi–Sugeno–Kang (TSK)-type models [45–47] as described previously in Dataset 2. Compared with the existing models in Table 5, the EIG obtains better performance in terms of MSE, number of rules, and correlation coefficient (R). The proposed EIG self-adaptively realizes the distinct output-contexts and uses the width constraint (Fσ) to the output-context. Therefore, compact and consistent rulebases are realized by the proposed EIG system.This problem predicts the stock price by using various features of a stock in a stock market [41]. Selected input variables (x4, x5, and x8) are considered in [41], although 10 input variables (x1–x10) initially exist. The EIG realizes the overfitted region when the number of fuzzy rules is greater than 19. The experimental results of the EIG are subsequently benchmarked against the Mamdani-type models [11,14,42–44], reasoning models [41], and Takagi–Sugeno–Kang (TSK)-type models [45–47]. As tabulated in Table 6, the EIG achieves reasonable performance with respect to some existing models. The proposed EIG system is a compact fuzzy model because the width constraint (Fσ) restricts the information granules. Therefore, if 10-fold cross validation technique is considered, then the EIG achieves good performance with respect to the Sugeno P, Hebb-R-R, and SAFIN. Furthermore, Hebb-R-R, RSPOP, FITSK, and SaFIN use rule reduction technique to reduce the number of rules. For example, Hebb-R-R reduces the number of rules from 50 to 20, and RSPOP reduces the number of rules from 50 to 29. However, the proposed EIG realizes the distinct output-context by using the self-organizing method and recognizes the overfitting state. Therefore, the proposed EIG method is an up-to-date and consistent rulebase.MPG is used to evaluate performance [37]. The output is the automobile's fuel consumption expressed in miles per gallon, and 7 input variables distinguish the actual output. In this process, 5×2 cross validation is applied to train and test the dataset to compare with [6,9]. The training error and its overfitting situation for automobile datasets are described in Section 2.4 and Fig. 5. The figure shows that the proposed EIG realizes the effective rulebase for the automobile datasets when the number of fuzzy rules is less than 11 or greater than 16.Table 7shows the performance comparison of the EIG with the existing models [6,9]. The training errors of the EIG are higher than those of the existing models. Error-reducing evolving method and grid partitioning approach are employed in [9,6] as described in Section 1. The proposed EIG realizes the distinct output-context and evolves rules based on self-organizing technique. Furthermore, it restricts the width of the output-context (consequent fuzzy level) by using Fσas described in Section 2.3.2. Hence, training errors for automobile datasets are high, but errors do not always seem high with respect to the other examples (see Dataset 6 and Table 8). A training error obtained by the EIG depends on the training data under observation. The proposed EIG obtains comparable testing error than the SSEM [9] and linguistic modeling [6]. Therefore, the evolving model in the EIG is significant to compare with existing models.This dataset deals with real estate in the Boston area [38]. The dataset consists of 13 input variables with 506 observations, and the median value of a house is considered an output variable. In this process, 5×2 cross validation is applied to train and test the dataset to compare with [6,9]. The training error and its overfitting situation for Boston datasets are shown in Fig. 9. The proposed EIG realizes the overfitted rulebase for Boston datasets when the numbers of rules are 11 and 16 (Fig. 9). In Fig. 9, an overfitted region could be observed when the number of fuzzy rules is greater than 18. The results are reported in Table 8 and compared with the published existing methods. The same conclusions as Dataset 5 can be drawn where the proposed EIG obtains better accuracy to represent the Boston data. Testing error slightly increases at the evolving stage with number of fuzzy rules 10 as shown in Table 8 because the overfitted rulebase is found when the number of fuzzy rules is 11 (Fig. 9). Similarly, the overfitting region is found when the number of fuzzy rules is greater than 18 (Fig. 9). Therefore, the testing error slightly increases at the evolving stage with 18 fuzzy rules.

@&#CONCLUSIONS@&#
