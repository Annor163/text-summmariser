@&#MAIN-TITLE@&#
Multi-modality sparse representation-based classification for Alzheimer's disease and mild cognitive impairment

@&#HIGHLIGHTS@&#
Multi-modality classification on 113 AD, 110 MCI patients and 117 normal controls.Originally single-modality SRC was extended as a multi-modality framework (wmSRC).The wmSRC performed better than each single-modality based SRC method.The wmSRC performed better or equally well compared to MKL, RF and JRC.

@&#KEYPHRASES@&#
Alzheimer's disease (AD),Mild cognitive impairment (MCI),Multi-modality,Neuroimaging data,Sparse representation-based classification (SRC),

@&#ABSTRACT@&#
Background and objectiveThe discrimination of Alzheimer's disease (AD) and its prodromal stage known as mild cognitive impairment (MCI) from normal control (NC) is important for patients’ timely treatment. The simultaneous use of multi-modality data has been demonstrated to be helpful for more accurate identification. The current study focused on extending a multi-modality algorithm and evaluating the method by identifying AD/MCI.MethodsIn this study, sparse representation-based classification (SRC), a well-developed method in pattern recognition and machine learning, was extended to a multi-modality classification framework named as weighted multi-modality SRC (wmSRC). Data including three modalities of volumetric magnetic resonance imaging (MRI), fluorodeoxyglucose (FDG) positron emission tomography (PET) and florbetapir PET from the Alzheimer's disease Neuroimaging Initiative database were adopted for AD/MCI classification (113 AD patients, 110 MCI patients and 117 NC subjects).ResultsAdopting wmSRC, the classification accuracy achieved 94.8% for AD vs. NC, 74.5% for MCI vs. NC, and 77.8% for progressive MCI vs. stable MCI, superior to or comparable with the results of some other state-of-the-art models in recent multi-modality researches.ConclusionsThe wmSRC method is a promising tool for classification with multi-modality data. It could be effective for identifying diseases from NC with neuroimaging data, which could be helpful for the timely diagnosis and treatment of diseases.

@&#INTRODUCTION@&#
Alzheimer's disease (AD) is the most common form of dementia [1]. The identification of AD and its prodromal stage named as mild cognitive impairment (MCI) from normal control (NC) has attracted much attention in recent decades. Biomarkers based on various neuroimaging modalities such as volumetric magnetic resonance imaging (MRI) and positron emission tomography (PET) measuring either metabolic or pathological burden with different radioactive tracers have been considered to discriminate AD or MCI with promising results [2–4].MRI, which measures the structure of the cerebrum, has turned out to be an efficient tool for detecting the structural changes caused by AD or MCI. For example, the brain atrophy of spatial patterns or the atrophy of brain regions such as hippocampal and parahippocampal have been characterized as efficient biomarkers for the prediction of conversion from MCI to the subsequent AD [5–7]. Furthermore, fluorodeoxyglucose PET (FDG-PET), a technique for measuring glucose metabolism, is also a sensitive biomarker for the detection of AD or MCI. Plenty of FDG-PET studies have identified distinct abnormalities patterns of brain metabolic in individuals that diagnosed with AD or MCI, such as the reduction of glucose metabolism in parietal, frontal and posterior cingulate cortices [6,8–10]. Most recently, the Pittsburgh compound B, florbetapir or flutematmol PET, a means to measure the accumulation of amyloid in the brain non-invasively, has been introduced and demonstrated to be promising for differentiating AD or MCI from NC, such as the higher uptake of florbetapir in the anterior and posterior cingulate cortex, frontal medial cortex for AD or MCI patients [11,12].Each neuroimaging modality could offer valuable information for AD or MCI, and studies reported that biomarkers from different modalities could offer complementary information for different aspects of a given disease process [4,12–15]. Combining these potentially complementary pieces of information from various modalities have been suggested to produce more powerful classifiers [4,16–18]. As a matter of fact, several groups have reported that exploiting the combination of multi-modality data to identify AD or MCI outperforms that based on each single-modality data alone [2,19,20]. Though all these multi-modality explorations reported positive results, the performances of different algorithms (for multi-modality data integration) can vary, and should be interesting to compare.Indeed, there have been numerous reports on various ways of combining multi-modality data for efficient classification. For example, a weighted multiple kernel learning (MKL) model has been widely applied to combine different modalities for AD or MCI classification [2,19,21]; a linear weighted random forest (RF) model can also efficiently discriminate AD or MCI from NC by combining different modalities [4]. Those studies demonstrate that the weighted combination approach is a simple-while-effective way for multi-modality analysis. Furthermore, methods that include joint feature selection for classification, such as the joint regression and classification (JRC) algorithm that was recently proposed by Zhu et al. [22,23] have been indicated to be effective in AD/MCI diagnosis with directly concatenating features from multi-modalities.Sparse representation-based classification (SRC), a relative recently introduced method in pattern recognition and machine learning, has been put forward by Wright et al. and has been indicated to be an efficient tool in face recognition [24,25]. SRC assumes that, if there are sufficient training samples from each class, then each test sample can be expressed as a sparse linear combination of the training samples, and its class label can be assigned with minimum representation residual. Recently, Liu et al. [26] introduced SRC into neuroimaging communities and demonstrated its feasibility and effectiveness for discriminating AD or MCI from NC with MRI data. However, the use of SRC for multi-modality data and its performance for the classification of AD or MCI from NC have not been concerned a lot.In this paper, data from three modalities i.e. MRI, FDG-PET and florbetapir PET were combined, and a weighted multi-modality SRC (wmSRC) method was extended and carried out to examine its robustness and the classification accuracy for AD/MCI. Our experimental results indicated that the wmSRC method could achieve better or comparable classification performance for both AD and MCI classification, compared with some other state-of-the-art multi-modality classification algorithms.

@&#CONCLUSIONS@&#
This paper proposed a weighted multi-modality sparse representation classifier named as wmSRC to combine the multi-modality features for classification of AD and MCI. The main contribution of this paper was to use the weights (optimized by a grid search) to combine the classification results of multiple SRCs from multi-modality features. Experiments on ADNI database had validated the effectiveness of wmSRC. The experimental results suggested that wmSRC was a promising tool for neuroimaging data classification especially diseases diagnosis (classification). Using wmSRC, encouraging identification results can be achieved, which is valuable for the timely diagnosis and treatment of diseases.There are no known conflicts of interest associated with this publication and there has been no significant financial support for this work that could have influenced its outcome.