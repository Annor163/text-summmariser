@&#MAIN-TITLE@&#
Robust estimation in flat fading channels under bounded channel uncertainties

@&#HIGHLIGHTS@&#
Channel equalization for at fading channels.Affine minimax equalization method.Affine minimin equalization method.Affine minimax regret equalization method.

@&#KEYPHRASES@&#
Channel equalization,Flat fading,Minimax,Minimin,Minimax regret,

@&#ABSTRACT@&#
We investigate channel equalization problem for time-varying flat fading channels under bounded channel uncertainties. We analyze three robust methods to estimate an unknown signal transmitted through a time-varying flat fading channel. These methods are based on minimizing certain mean-square error criteria that incorporate the channel uncertainties into their problem formulations instead of directly using the inaccurate channel information that is available. We present closed-form solutions to the channel equalization problems for each method and for both zero mean and nonzero mean signals. We illustrate the performances of the equalization methods through simulations.

@&#INTRODUCTION@&#
In this paper, we study channel equalization problem for time-varying flat (frequency-nonselective) fading channels under bounded channel uncertainties [1–7]. In this widely studied framework, an unknown desired signal is transmitted through a discrete-time time-varying channel and corrupted by additive noise where the mean and variance of the desired signal is assumed to be known. Although the underlying channel impulse response is not known exactly, an estimate and an uncertainty bound on it are given [4–6]. Here, we investigate three different channel equalization frameworks that are based on minimizing certain mean-square error criteria. These channel equalization frameworks incorporate the channel uncertainties into their problem formulations to provide robust solutions to the channel equalization problem instead of directly using the inaccurate channel information that is available to equalize the channel. Based on these frameworks, we analyze three robust methods to equalize time-varying flat fading channels. The first approach we investigate is the affine minimax equalization method [5,8,9], which minimizes the estimation error for the worst case channel perturbation. The second approach we study is the affine minimin equalization method [6,10], which minimizes the estimation error for the most favorable perturbation. The third approach is the affine minimax regret equalization method [4,5,11,7], which minimizes a certain “regret” as defined in Section 2 and further detailed in Section 3. We provide closed-form solutions to the affine minimax equalization, the minimin equalization and the minimax regret equalization problems for both zero mean and nonzero mean signals. Note that the nonzero mean signals frequently appear in iterative equalization applications [11,12] and equalization with these signals under channel uncertainties is particularly important and challenging.When there are uncertainties in the channel coefficients, one of the prevalent approaches to find a robust solution to the equalization problem is the minimax equalization method [9,5,8]. In this approach, affine equalizer coefficients are chosen to minimize the MSE with respect to the worst possible channel in the uncertainty bounds. We emphasize that although the minimax equalization framework has been introduced in the context of statistical signal processing literature [9,5,8], our analysis significantly differs since we provide a closed-form solution to the minimax equalization problem for time-varying flat fading channels. In [5], the uncertainty is in the noise covariance matrix and the channel coefficients are assumed to be perfectly known. Furthermore, note that in [8], the minimax estimator is formulated as a solution to a semidefinite programming (SDP) problem, unlike in here. In this paper, the uncertainty is in the channel impulse response and we provide an explicit solution to the minimax channel equalization problem.Although the minimax equalization method is able to minimize the estimation error for the worst case channel perturbation, however, it usually provides unsatisfactory results on the average [6]. An alternative approach to the channel equalization problem is the minimin equalization method [6,10]. In this approach, equalizer parameters are selected to minimize the MSE with respect to the most favorable channel over the set of allowed perturbations. Although the minimin approach has been studied in the literature [6,10], however, we emphasize that to the best of our knowledge, this is the first closed-form solution to the minimin channel equalization problem for time-varying flat fading channels.The minimin approach is highly optimistic, which could yield unsatisfactory results, when the difference between the underlying channel impulse response and the most favorable channel impulse response is relatively high [6]. In order to preserve robustness and counterbalance the conservative nature of the minimax approach, the minimax regret approaches have been introduced in the signal processing literature [4,13,7]. In this approach, a relative performance measure, i.e., “regret”, is defined as the difference between the MSE of an affine equalizer and the MSE of the affine minimum MSE (MMSE) equalizer [7]. The minimax regret channel equalizer seeks an equalizer that minimizes this regret with respect to the worst possible channel in the uncertainty region. Although this approach has been investigated before, the minimax regret estimator is formulated as a solution to an SDP problem [4], unlike here. In this paper, we explicitly provide the equalizer coefficients and the estimate of the desired signal.Our main contributions are as follows. We first formulate the affine equalization problem for time-varying flat fading channels under bounded channel uncertainties. We then investigate three robust approaches; affine minimax equalization, affine minimin equalization, and affine minimax regret equalization for both zero mean and nonzero mean signals. The equalizer coefficients, and hence, the MSE of each methods have been explicitly provided, unlike in [4,5,8,6,7].The paper is organized as follows. In Section 2, the basic transmission system is described, along with the notation used in this paper. We present the affine equalization approaches in Section 3. First, we study the affine minimax equalization tuned to the worst possible channel filter. We then investigate the minimin approach and the minimax regret approach, and provide the explicit solutions to the corresponding optimization problems. In addition, we present and compare the MSE performances of all robust affine equalization methods in Section 4. Finally, we conclude the paper with certain remarks in Section 5.In this section, we provide the basic description of the system studied in this paper. Here, the signalxtis transmitted through a discrete-time time-varying channel with a channel coefficientht, wherextis unknown and random with known meanxt¯≜E[xt]and varianceσx2≜E[(xt−xt¯)2]. The received signalytis given by(1)yt=xtht+nt,where the observation noisentis independent and identically distributed (i.i.d.) with zero mean and varianceσn2and independent fromxt. We consider a time-varying flat fading channel, where the bandwidth of the transmitted signalxtis much smaller than the channel bandwidth so that the multipath channel simply scales the transmitted signal [14,15]. However, instead of the true channel coefficient, an estimate ofhtis provided ash˜t, whereδht≜h˜t−htis the uncertainty in the channel coefficient and is modeled by|ht−h˜t|=|δht|⩽ϵ,ϵ>0,ϵ<∞, where ϵ or a bound on ϵ is known.We then use the received signalytto estimate the transmitted signalxtas shown in Fig. 1. The estimate of the desired signal is given by(2)xˆt=wtyt+lt=wt(xtht+nt)+lt,wherewtis the equalizer coefficient. We note that in (2), the equalizer is “affine” where there is a bias termltsince the transmitted signalxt, and consequently the received signalyt, are not necessarily zero mean and the mean sequencey¯t≜E[yt]is not known due to uncertainty in the channel.Even under the channel uncertainties, the equalizer coefficientwtand the bias termltcan be simply optimized to minimize the MSE for the channel that is tuned to the estimateh˜t, which is also known as the MMSE estimator [16]. The corresponding equalizer coefficient and the bias term are given by [17,11](3){w0,t,l0,t}=argminw,lE[(xt−w(h˜txt+nt)−l)2].However, the estimatexˆ0,t≜w0,tyt+l0,tmay not perform well when the error in the estimate of the channel coefficient is relatively high [18,4,5]. One alternative approach to find a robust solution to this problem is to minimize a worst case MSE, which is known as the minimax criterion, as(4){w1,t,l1,t}=argminw,lmax|δht|⩽ϵE[(xt−w((h˜t+δht)xt+nt)−l)2],wherew1,tandl1,tminimize the worst case error in the uncertainty region [8,16]. However, this approach may yield highly conservative results, since the estimatexˆ1,t≜w1,tyt+l1,tis formed by using the equalizer coefficientw1,tand the bias terml1,tthat minimize the worst case error, i.e., the error under the worst possible channel coefficient [6,4,5]. Instead of this conservative approach, another useful method to estimate the desired signal is the minimin approach, where the equalizer coefficient and the bias term are given by(5){w2,t,l2,t}=argminw,lmin|δht|⩽ϵE[(xt−w((h˜t+δht)xt+nt)−l)2],wherew2,tandl2,tminimize the MSE in the most favorable case, i.e., the MSE under the best possible channel coefficient [6]. The estimate of the transmitted signalxtis given byxˆ2,t≜w2,tyt+l2,t.A major drawback of the minimin approach is that it is a highly optimistic technique, which could yield unsatisfactory results, when the difference between the actual and the best channel coefficients is relatively high [6].In order to reduce the conservative characteristic of the minimax approach as well as to maintain robustness, the minimax regret approach is introduced, which provides a trade-off between performance and robustness [4,11,7]. In this approach, the equalizer coefficient and the bias term are chosen in order to minimize the worst-case “regret”, where the regret for not using the MMSE is defined as the difference between the MSE of the estimator and the MSE of the MMSE, i.e.,(6){w3,t,lt,3}=argminw,lmax|δht|⩽ϵ{E[(xt−w((h˜t+δht)xt+nt)−l)2]−minw,lE[(xt−w((h˜t+δht)xt+nt)−l)2]}.The corresponding estimate of the desired signalxtis given byxˆ3,t≜w3,tyt+l3,t.In the next section, we investigate and provide closed-form solutions for the three equalization formulations:•affine minimax equalization framework,affine minimin equalization framework,affine minimax regret equalization framework.In this section, we present the affine MMSE equalization framework for completeness [11,16]. Since the channel coefficienthtis not accurately known but estimated byh˜t, a linear equalizer that is matched to the estimateh˜tand minimizes the MSE can be used to estimate the transmitted signalxt. The corresponding equalizer coefficientw0,tand the bias terml0,tare given by (3).We defineH(w,l)=E[(xt−w(h˜txt+nt)−l)2]. Note thatH(w,l)is a quadratic function of the variables w and l where the coefficients of the termsw2andl2are positive. Hence,H(w,l)is a convex function of w and l. It follows that it has a global minimizer(w⁎,l⁎), wherew⁎andl⁎satisfy(7)∂H∂w|w=w⁎=0,∂H∂l|l=l⁎=0.Solving (7), we getw0,t=h˜tσx2h˜t2σx2+σn2,l0,t=xt¯σn2h˜t2σx2+σn2.In this section, we investigate a robust estimation framework based on a minimax criteria [16,19,10]. We find the equalizer coefficientw1,tand the bias terml1,tthat solve the optimization problem (4).In (4), we seek to find an equalizer coefficientw1,tand a bias terml1,tthat perform best in the worst possible scenario. This framework can be perceived as a two-player game problem, where one player tries to pickw1,tandl1,tpair that minimize the MSE for a given channel uncertainty while the opponent pickδhtto maximize MSE for this pair. In this sense, this problem is constrained since there is a limit on how large the channel uncertaintyδhtcan be, i.e.,|δht|⩽ϵwhere ϵ or a bound on ϵ is known.In the following theorem we present a closed-form solution to the optimization problem (4).Theorem 1Letxt,ytandntrepresent the transmitted, received and noise signals such thatyt=htxt+nt, wherehtis the unknown channel coefficient andntis i.i.d. zero mean with varianceσn2. At each time t, given an estimateh˜tofhtsatisfying|ht−h˜t|⩽ϵ, the solution to the optimization problem(4)is given byw1,t={(h˜t−ϵ)σx2(h˜t−ϵ)2σx2+σn2:h˜tϵσx2<ϵ2σx2+σn2,σx2xt2¯h˜t:h˜tϵσx2⩾ϵ2σx2+σn2andl1,t={xt¯σn2(h˜t−ϵ)2σx2+σn2:h˜tϵσx2<ϵ2σx2+σn2,xt¯:h˜tϵσx2⩾ϵ2σx2+σn2,wherext¯≜E[xt]andσx2≜E[(xt−xt¯)2]are the mean and variance of the transmitted signalxt, respectively.Here, we find the equalizer coefficientw1,tand the bias terml1,tthat solve the optimization problem in (4). To accomplish this, we first solve the inner maximization problem and find the maximizer channel uncertaintyδht⁎. We then substituteδht⁎in (4) and solve the outer minimization problem to findw1,tandl1,t.We solve the inner maximization problem as follows. We observe that the cost function in (4) can be written as(8)E[(xt−w((h˜t+δht)xt+nt)−l)2]=w2Δht2xt2¯+2wΔht(lxt¯−xt2¯)+C1,wherext2¯≜E[xt2],Δht≜h˜t+δhtandC1=xt2¯+w2σn2+l2−2lxt¯does not depend onδht. If we definea=xt2¯>0,b=lxt¯−xt2¯,u=wΔhtandC2=C1−b2a, then (8) can be written asE[(xt−w((h˜t+δht)xt+nt)−l)2]=a(u+ba)2+C2,where C2 is independent ofδht. Hence the inner maximization problem in (4) can be written as(9)δht⁎=argmax|δht|⩽ϵE[(xt−w((h˜t+δht)xt+nt)−l)2]=argmax|δht|⩽ϵa(u+ba)2=argmax|δht|⩽ϵ|u+ba|=argmax|δht|⩽ϵ|wδht+lxt¯−xt2¯xt2¯|=argmax|δht|⩽ϵ|w||δht+lxt¯−xt2¯wxt2¯|.If we apply the triangular inequality to the second term in (9), then we get the following upper bound:|w||Δht+lxt¯−xt2¯wxt2¯|⩽|w|[|δht|+|h˜t+lxt¯−xt2¯wxt2¯|]⩽|w|[ϵ+|h˜t+lxt¯−xt2¯wxt2¯|],where the upper bound is achieved atδht⁎=ϵsgn(h˜t+lxt¯−xt2¯wxt2¯), wheresgn(z)=1ifz⩾0andsgn(z)=−1ifz<0. Hence it follows that(10)δht⁎=argmax|δht|⩽ϵE[(xt−w((h˜t+δht)xt+nt)−l)2]={ϵ:h˜t+lxt¯−xt2¯wxt2¯⩾0,−ϵ:h˜t+lxt¯−xt2¯wxt2¯⩽0.Note that ifh˜t+lxt¯−xt2¯wxt2¯=0, thenδht⁎=ϵandδht⁎=−ϵyields the same result.We next solve the outer minimization problem as follows. We first note that the minimum in (4) is taken over allw∈Randl∈R. If we writeu=[w,l]T∈R2in a vector form, defineU={u=[w,l]T∈R2|h˜t+lxt¯−xt2¯wxt2¯⩾0}andV≜{u=[w,l]T∈R2|h˜t+lxt¯−xt2¯wxt2¯⩽0}, then it follows thatU∪V=R2. Hence, the cost function in the outer minimization problem in (4) is given bymax|δht|⩽ϵE[(xt−w((h˜t+δht)xt+nt)−l)2]={E[(xt−w((h˜t+ϵ)xt+nt)−l)2]:[w,l]T∈U,E[(xt−w((h˜t−ϵ)xt+nt)−l)2]:[w,l]T∈V.We first substituteδht=ϵand find the corresponding{w,l}pair that minimizes the objective function in (4) to check whether[w,l]∈U. We next substituteδht=−ϵand find the corresponding{w,l}to check whether[w,l]∈V. Based on these criteria, we obtain the corresponding equalizer coefficient and the bias term pair{w1,t,l1,t}.We first substituteδht=ϵin the objective function of (4) to get the following minimization problem:(11){w⁎,l⁎}=argminw,l{xt2¯+w2((h˜t+ϵ)2xt2¯+σn2)+l2−2lxt¯+2wl(h˜t+ϵ)xt¯−2w(h˜t+ϵ)xt2¯}.We observe that the cost function in (11) is a convex function of w and l yieldingw⁎=(h˜t+ϵ)σx2(h˜t+ϵ)2σx2+σn2,l⁎=xt¯σn2(h˜t+ϵ)2σx2+σn2.However we have(12)xt2¯−l⁎xt¯w⁎xt2¯=h˜t+ϵ+σn2(h˜t+ϵ)σx2>h˜tso that[w⁎,l⁎]T∉U.We next substituteδht=−ϵin the cost function of (4) to get(13){w⁎,l⁎}=argminw,l{xt2¯+w2((h˜t−ϵ)2xt2¯+σn2)+l2−2lxt¯+2wl(h˜t−ϵ)xt¯−2w(h˜t−ϵ)xt2¯}.The cost function in (13) is also a convex function of w and l so that we getw⁎=(h˜t−ϵ)σx2(h˜t−ϵ)2σx2+σn2,l⁎=xt¯σn2(h˜t−ϵ)2σx2+σn2.If the conditionh˜tϵσx2<ϵ2σx2+σn2holds, then we haveh˜t<h˜t−ϵ+σn2(h˜t−ϵ)xt2¯<xt2¯−lxt¯wxt2¯so that[w⁎,l⁎]T∈V. Thus, the corresponding equalizer coefficient and the bias term are given byw1,t=(h˜t−ϵ)σx2(h˜t−ϵ)2σx2+σn2andl1,t=xt¯σn2(h˜t−ϵ)2σx2+σn2, respectively. However, if the conditionh˜tϵσx2<ϵ2σx2+σn2does not hold, then it follows thath˜t+lxt¯−xt2¯wxt2¯=0, which implies that(14)h˜t=−lxt¯−xt2¯wxt2¯.From (8), we observe that(15)E[(xt−w((h˜t+δht)xt+nt)−l)2]=w2Δht2xt2¯+2wΔht(lxt¯−xt2¯)+C1=w2xt2¯[Δht2+2Δht(lxt¯−xt2¯wxt2¯)]+C1=w2xt2¯[Δht2−2Δhth˜t]+C1where (15) follows from (14). If we add and subtractw2xt2¯h˜t2to (15), then we get(16)E[(xt−w((h˜t+δht)xt+nt)−l)2]=w2xt2¯[Δht2−2Δhth˜t+h˜t2]−w2xt2¯h˜t2+C1=w2xt2¯δht2−w2xt2¯h˜t2+C1.Here, if we maximize (16) with respect toδht, then it yields that the maximizerδht⁎is equal to ϵ or −ϵ so that(17)argmax|δht|⩽ϵE[(xt−w((h˜t+δht)xt+nt)−l)2]=w2xt2¯ϵ2−w2xt2¯h˜t2+C1=w2xt2¯(ϵ2−h˜t2)+xt2¯+w2σn2+l2−2lxt¯.If we take the derivative of (17) with respect to l and equate it to zero, then it yieldsl1,t=xt¯.We next substitutel1,tinto (14) to getw1,t=σx2xt2¯h˜t.Hence, we havew1,t={(h˜t−ϵ)σx2(h˜t−ϵ)2σx2+σn2:h˜tϵσx2<ϵ2σx2+σn2,σx2xt2¯h˜t:h˜tϵσx2⩾ϵ2σx2+σn2,l1,t={xt¯σn2(h˜t−ϵ)2σx2+σn2:h˜tϵσx2<ϵ2σx2+σn2,xt¯:h˜tϵσx2⩾ϵ2σx2+σn2.The proof follows. □In the following corollary, we provide a special case of Theorem 1, where the desired signalxtis zero mean.Corollary 1When the transmitted signalxtis zero mean, the solution to the optimization problem(4)is given byw1,t={(h˜t−ϵ)(h˜t−ϵ)2+1S:ϵ(h˜t−ϵ)<1S,1h˜t:ϵ(h˜t−ϵ)⩾1S,l1,t=0,whereS≜σx2/σn2is the signal-to-noise ratio (SNR).The proof directly follows from Theorem 1, therefore, is omitted.  □In this section, we study the minimin equalization framework, where the inner maximization of the minimax framework is replaced with a minimization over the uncertainty set [6,20,10]. We seek to solve the optimization problem (5).The following lemma is introduced to demonstrate that min operators in (5) can be interchanged, which will be used in Theorem 2.Lemma 1For an arbitrary functionf(x,y,z)and nonempty setsX,YandZ, we haveminx∈X,y∈Yminz∈Zf(x,y,z)=minz∈Zminx∈X,y∈Xf(x,y,z),assuming that all minimums are achieved on the corresponding sets.The proof is given in the footnote.11To prove thatminx∈X,y∈Yminz∈Zf(x,y,z)=minz∈Zminx∈X,y∈Xf(x,y,z), we first show thatminx∈X,y∈Yminz∈Zf(x,y,z)⩽minz∈Zminx∈X,y∈Xf(x,y,z). We next show thatminx∈X,y∈Yminz∈Zf(x,y,z)⩾minz∈Zminx∈X,y∈Xf(x,y,z). First, we observe thatminz∈Zf(x,y,z)⩽f(x,y,z). Since this is true∀x∈X,∀y∈Yand∀z∈X, it follows thatminz∈Zf(x,y,z)⩽minx∈X,y∈Yf(x,y,z)∀x∈X,∀y∈Yand∀z∈X. Therefore, we get thatminx∈X,y∈Yminz∈Zf(x,y,z)⩽minx∈X,y∈Yf(x,y,z)∀z∈Z. Then, it follows thatminx∈X,y∈Yminz∈Zf(x,y,z)⩽minz∈Zminx∈X,y∈Xf(x,y,z). Using similar steps, it easily follows that the converse is also true. Hence, the proof follows.In the following theorem we present a closed-form solution to the optimization problem (5).Theorem 2Letxt,ytandntrepresent the transmitted, received and noise signals such thatyt=htxt+nt, wherehtis the unknown channel coefficient andntis i.i.d. zero mean with varianceσn2. At each time t, given an estimateh˜tofhtsatisfying|ht−h˜t|⩽ϵ, the solution to the optimization problem(5)is given byw2,t=(h˜t+ϵsign(h˜t))σx2(h˜t+ϵsign(h˜t))2σx2+σn2andl2,t=xt¯σn2(h˜t+ϵsign(h˜t))σx2+σn2,wherext¯≜E[xt]andσx2≜E[(xt−xt¯)2]are the mean and variance of the transmitted signalxt, respectively.ProofHere, we find the equalizer coefficientw2,tand the bias terml2,tthat solve the optimization problem in (5). We first note that, by Lemma 1, we can interchange min operators in (5) so that the optimization problem in (5) is equivalent to(18)minw,lmin|δht|⩽ϵE[(xt−w((h˜t+δht)xt+nt)−l)2]=min|δht|⩽ϵminw,lE[(xt−w((h˜t+δht)xt+nt)−l)2].Hence, we first solve the inner minimization problem in (18) and find the minimizersw⁎andl⁎. We then substitutew⁎andl⁎in (18) and solve the outer minimization problem to find the minimizerδht⁎, which yields the desired equalizer coefficientw2,tandl2,t.We observe that the objective function in (18) can be written asE[(xt−w((h˜t+δht)xt+nt)−l)2]=xt2¯+w2(Δht2xt2¯+σn2)+l2−2lxt¯+2wlΔhtxt¯−2wΔhtxt2¯,wherext2¯≜E[xt2]andΔht≜h˜t+δht.We first solve the inner minimization problem in the right-hand side of (18) with respect to w and l as follows. We defineF(w,l)=E[(xt−w(Δhtxt+nt)−l)2]. Note thatF(w,l)is a quadratic function of the variables w and l with positive leading term coefficients, i.e., the coefficients ofw2andl2are positive. Hence, it is a convex function of the variables w and l, which implies that it has a global minimum point(w⁎,l⁎). If we set the first derivatives ofF(w,l)with respect to w and l, then it yields the minimizersw⁎andl⁎, respectively, i.e.,w⁎andl⁎satisfy∂F∂w|w=w⁎=0and∂F∂l|l=l⁎=0. The corresponding partial derivative of the cost functionF(w,l)with respect to l is given by∂F∂l|l=l⁎=2l⁎−2xt¯+2w⁎Δhtxt¯=0so thatl⁎=xt¯−w⁎Δhtxt¯. The corresponding partial derivative ofF(w,l)with respect to w is given by∂F∂w|w=w⁎=2w⁎(Δht2xt2¯+σn2)+2l⁎Δhtxt¯−2Δhtxt2¯=0,which implies thatw⁎=Δhtxt2¯−l⁎Δhtxt¯Δht2xt2¯+σn2. Thus, we get thatw⁎=Δhtσx2Δht2σx2+σn2,l⁎=xt¯σn2Δht2σx2+σn2for a givenδht.We next solve the outer minimization problem. If we substitutew⁎andl⁎inF(w,l), then we obtain(19)δht⁎=argmin|δht|⩽ϵminw,lE[(xt−w((h˜t+δht)xt+nt)−l)2]=argmin|δht|⩽ϵF(w⁎,l⁎)=argmin|δht|⩽ϵσn2σx2(h˜t+δht)2σx2+σn2=argmax|δht|⩽ϵ|h˜t+δht|so thatδht⁎=ϵsign(h˜t). Hence, the equalizer coefficientw2,tand the bias terml2,tare given byw2,t=(h˜t+ϵsign(h˜t))σx2(h˜t+ϵsign(h˜t))2σx2+σn2,l2,t=xt¯σn2(h˜t+ϵsign(h˜t))σx2+σn2.Hence, the proof follows.  □In the following corollary, we provide a special case of Theorem 1, where the desired signalxtis zero mean.Corollary 2When the transmitted signalxtis zero mean, the solution to the optimization problem(5)is given byw2,t=(h˜t+ϵsign(h˜t))(h˜t+ϵsign(h˜t))2+1Sandl2,t=0,whereS≜σx2/σn2is the SNR.The proof follows from Theorem 2 whenxt¯=0.  □In this section, we investigate the minimax regret equalization framework, where the performance of an affine equalizer is defined with respect to the MMSE affine equalizer that is tuned to the unknown channel [4,7,11,16]. We emphasize that the minimax equalization framework investigated in Section 3.2 may produce highly conservative results since the equalizer coefficient w and the bias term l are optimized to minimize the worst case MSE [16]. Moreover, the minimin equalization framework introduced in Section 3.3 is a highly optimistic method where the equalizer parameters are optimized to minimize the MSE that corresponds to the most favorable channel [6]. Thus, the minimin approach may also yield unsatisfactory results in certain applications, where the channel estimate is highly erroneous [6]. In this context, the minimax regret equalization framework can be used to improve the equalization performance while preserving the robustness [4,7]. In this approach, we find the equalizer coefficientw3,tand the bias terml3,tthat solve the optimization problem (6).We note that from Section 3.3, the solution to the minimization problem in the objective function is given byminw,lE[(xt−w((h˜t+δht)xt+nt)−l)2]=σn2σx2(h˜t+δht)2σx2+σn2,whereσx2≜E[(xt−xt¯)2]is the variance of the transmitted signalxt. Hence the optimization problem in (6) is equivalent to(20)argminw,lmax|δht|⩽ϵ{E[(xt−w((h˜t+δht)xt+nt)−l)2]−minw,lE[(xt−w((h˜t+δht)xt+nt)−l)2]}=argminw,lmax|δht|⩽ϵ{E[(xt−w((h˜t+δht)xt+nt)−l)2]−σn2σx2(h˜t+δht)2+σn2}.We first expand the termσn2σx2(h˜t+δht)2σx2+σn2in (20) aroundδht=0yieldingσn2σx2(h˜t+δht)2+σn2≈σn2σx2h˜t2+σn2−δht2h˜tσn2σx4(h˜t2σx2+σn2)2.Hence, instead of (6), we solve the following optimization problem:(21){w3,t,l3,t}=argminw,lmax|δht|⩽ϵ{E[(xt−w((h˜t+δht)xt+nt)−l)2]−σn2σx2h˜t2+σn2+δht2h˜tσn2σx4(h˜t2σx2+σn2)2},which provides satisfactory results even under large derivationsδhtas shown in the Simulations section.In the following theorem we present a closed-form solution to the optimization problem (21).Theorem 3Letxt,ytandntrepresent the transmitted, received and noise signals such thatyt=htxt+nt, wherehtis the unknown channel coefficient andntis i.i.d. zero mean with varianceσn2. At each time t, given an estimateh˜tofhtsatisfying|ht−h˜t|⩽ϵ, the solution to the optimization problem(21)is given by[w3,t,l3,t]={[w1⁎,l1⁎]:f⩾0,g⩾0,[w2⁎,l2⁎]:f⩽0,g⩽0,[w3⁎,l3⁎]:f⩾0,g⩽0,[w4⁎,l4⁎]:f<0,g>0,where[w1⁎,l1⁎]=[(h˜t+ϵ)σx2(h˜t+ϵ)2σx2+σn2,xt¯σn2(h˜t+ϵ)2σx2+σn2],[w2⁎,l2⁎]=[(h˜t−ϵ)σx2(h˜t−ϵ)2σx2+σn2,xt¯σn2(h˜t−ϵ)2σx2+σn2],[w3⁎,l3⁎]=argmin[w,l]∈{[w1⁎,l1⁎],[w2⁎,l2⁎]}{max|δht|⩽ϵ{E[(xt−w((h˜t+δht)xt+nt)−l)2]−σn2σx2h˜t2+σn2+δht2h˜tσn2σx4(h˜t2σx2+σn2)2}},[w4⁎,l4⁎]=argmin[w,l]{E[(xt−w(h˜txt+nt)−l)2]−σn2σx2h˜t2+σn2},f≜−ϵ−xt¯2σn2(h˜t+ϵ)2σx2+σn2−σn2(h˜t+ϵ)σx2+h˜tσn2(h˜t+ϵ)2((h˜t+ϵ)2σx2+σn2h˜t2σx2+σn2)2,g≜ϵ−xt¯2σn2(h˜t−ϵ)2σx2+σn2−σn2(h˜t−ϵ)σx2+h˜tσn2(h˜t−ϵ)2((h˜t−ϵ)2σx2+σn2h˜t2σx2+σn2)2.Here,xt¯≜E[xt]andσx2≜E[(xt−xt¯)2]are the mean and variance of the transmitted signalxt, respectively.We first observe that the objective function in (20) can be written as(22)E[(xt−w((h˜t+δht)xt+nt)−l)2]−σn2σx2h˜t2+σn2+δht2h˜tσn2σx4(h˜t2σx2+σn2)2=w2Δht2xt2¯+Δht(2wlxt¯−2wxt2¯+2h˜tσn2σx4(h˜t2σx2+σn2)2)+D1,wherext2¯≜E[xt2],Δht≜h˜t+δht,D1≜xt2¯+w2σn2+l2−2lxt¯−σn2σx2h˜t2+σn2−h˜t2h˜tσn2σx4(h˜t2σx2+σn2)2is independent ofδht. If we definea=w2xt2¯⩾0,b≜2wlxt¯−2wxt2¯+2h˜tσn2σx4(h˜t2σx2+σn2)2andD2=D1−b24a, then (22) can be written asE[(xt−w((h˜t+δht)xt+nt)−l)2]−σn2σx2h˜t2+σn2+δht2h˜tσn2σx4(h˜t2σx2+σn2)2=a(u+b2a)2+D2,where D2 is independent ofδht. Hence, the inner maximization problem in (21) is given by(23)δht⁎=argmax|δht|⩽ϵ{E[(xt−w((h˜t+δht)xt+nt)−l)2]−σn2σx2h˜t2+σn2+δht2h˜tσn2σx4(h˜t2σx2+σn2)2}=argmax|δht|⩽ϵ|δht+h˜t+lxt¯wxt2¯−1w+h˜tσn2σx4w2xt2¯(h˜t2σx2+σn2)2|.By applying the triangular inequality to the cost function in (23), we get the following upper bound:|δht+h˜t+lxt¯wxt2¯−1w+h˜tσn2σx4w2xt2¯(h˜t2σx2+σn2)2|⩽|δht|+|h˜t+lxt¯wxt2¯−1w+h˜tσn2σx4w2xt2¯(h˜t2σx2+σn2)2|⩽ϵ+|h˜t+lxt¯wxt2¯−1w+h˜tσn2σx4w2xt2¯(h˜t2σx2+σn2)2|,where the upper bound is achieved atδht⁎=ϵsgn(h˜t+lxt¯wxt2¯−1w+h˜tσn2σx4w2xt2¯(h˜t2σx2+σn2)2). Hence it follows that(24)δht⁎=argmax|δht|⩽ϵ{E[(xt−w((h˜t+δht)xt+nt)−l)2]−σn2σx2h˜t2+σn2+δht2h˜tσn2σx4(h˜t2σx2+σn2)2}={ϵ:h˜t+lxt¯wxt2¯−1w+h˜tσn2σx4w2xt2¯(h˜t2σx2+σn2)2⩾0,−ϵ:h˜t+lxt¯wxt2¯−1w+h˜tσn2σx4w2xt2¯(h˜t2σx2+σn2)2<0.We next solve the outer minimization problem as follows. If we writeu=[w,l]T∈R2and defineM={u=[w,l]T∈R2|h˜t+lxt¯wxt2¯−1w+h˜tσn2σx4w2xt2¯(h˜t2σx2+σn2)2⩾0}, then it follows thatN≜{u=[w,l]T∈R2|h˜t+lxt¯wxt2¯−1w+h˜tσn2σx4w2xt2¯(h˜t2σx2+σn2)2<0}=R2∖M, i.e.,M∪N=R2andM∩N=∅. Hence, the cost function in the outer minimization problem in (21) is given bymax|δht|⩽ϵ{E[(xt−w((h˜t+δht)xt+nt)−l)2]−σn2σx2h˜t2+σn2+δht2h˜tσn2σx4(h˜t2σx2+σn2)2}={{E[(xt−w((h˜t+ϵ)xt+nt)−l)2]−σn2σx2h˜t2+σn2+ϵ2h˜tσn2σx4(h˜t2σx2+σn2)2}:[w,l]T∈M,{E[(xt−w((h˜t−ϵ)xt+nt)−l)2]−σn2σx2h˜t2+σn2,−ϵ2h˜tσn2σx4(h˜t2σx2+σn2)2}:[w,l]T∈N.We first substituteδht=ϵand find the corresponding{w,l}pair that minimizes the objective function in (21) to check whether[w,l]∈M. We next substituteδht=−ϵand find the corresponding{w,l}to check whether[w,l]∈N. Based on these criteria, we obtain the corresponding equalizer coefficient and the bias term pair{w3,t,l3,t}.We first substituteδht=ϵin the cost function in (21) to get the following minimization problem:(25){w1⁎,l1⁎}=argminw,l{xt2¯+w2(h˜t+ϵ)2xt2¯+w2σn2+l2−2w(h˜t+ϵ)xt2¯−2xt¯l−2xt¯w(h˜t+ϵ)l−σn2σx2h˜t2+σn2+ϵ2h˜tσn2σx4(h˜t2σx2+σn2)2}.Since the cost function in (25) is a convex function of w and l, we get thatw1⁎=(h˜t+ϵ)σx2(h˜t+ϵ)2σx2+σn2,l1⁎=xt¯σn2(h˜t+ϵ)2σx2+σn2.We observe that[w1⁎,l1⁎]∈Mif and only iff≜−ϵ−xt¯2σn2(h˜t+ϵ)2σx2+σn2−σn2(h˜t+ϵ)σx2+h˜tσn2(h˜t+ϵ)2((h˜t+ϵ)2σx2+σn2h˜t2σx2+σn2)2⩾0.We next substituteδht=−ϵin the cost function in (21) to get the following minimization problem:(26){w2⁎,l2⁎}=argminw,l{xt2¯+w2(h˜t−ϵ)2xt2¯+w2σn2+l2−2w(h˜t−ϵ)xt2¯−2xt¯l−2xt¯w(h˜t−ϵ)l−σn2σx2h˜t2+σn2−ϵ2h˜tσn2σx4(h˜t2σx2+σn2)2}.Since the cost function in (26) is a convex function of w and l, we get thatw2⁎=(h˜t−ϵ)σx2(h˜t−ϵ)2σx2+σn2,l2⁎=xt¯σn2(h˜t−ϵ)2σx2+σn2.Note that[w2⁎,l2⁎]∈Nif and only ifg≜ϵ−xt¯2σn2(h˜t−ϵ)2σx2+σn2−σn2(h˜t−ϵ)σx2+h˜tσn2(h˜t−ϵ)2((h˜t−ϵ)2σx2+σn2h˜t2σx2+σn2)2⩽0.There are four cases depending on the values ofh˜t, ϵ,xt¯,xt2¯,σn2:•Case 1:f⩾0andg⩾0.In this case, we havew3,t=(h˜t+ϵ)σx2(h˜t+ϵ)2σx2+σn2andl3,t=xt¯σn2(h˜t+ϵ)2σx2+σn2since[w1⁎,l1⁎]∈Mand[w2⁎,l2⁎]∉N.Case 2:f⩽0andg⩽0.In this case, we havew3,t=(h˜t−ϵ)σx2(h˜t−ϵ)2σx2+σn2andl3,t=xt¯σn2(h˜t−ϵ)2σx2+σn2since[w1⁎,l1⁎]∉Mand[w2⁎,l2⁎]∈N.Case 3:f⩾0andg⩽0.In this case, we have[w1⁎,l1⁎]∈Mand[w2⁎,l2⁎]∈Nso that[w3,t,l3,t]=argmin[w,l]∈{[w1⁎,l1⁎],[w2⁎,l2⁎]}{max|δht|⩽ϵ{E[(xt−w((h˜t+δht)xt+nt)−l)2]−σn2σx2h˜t2+σn2+δht2h˜tσn2σx4(h˜t2σx2+σn2)2}}.Case 4:f⩽0andg⩾0.In the last case, we have the optimum points on the curveh˜t+lxt¯wxt2¯−1w+h˜tσn2σx4w2xt2¯(h˜t2σx2+σn2)2=0. Thereforeδht⁎=0and the corresponding coefficients are given as the solution to the following optimization problem:[w3,t,l3,t]=argmin[w,l]{E[(xt−w(h˜txt+nt)−l)2]−σn2σx2h˜t2+σn2}subject toh˜t+lxt¯wxt2¯−1w+h˜tσn2σx4w2xt2¯(h˜t2σx2+σn2)2=0.We provide numerical examples in different scenarios in order to illustrate the performances of the equalization methods. We first illustrate the performances of the channel equalization methods for a given perturbation bound. We demonstrate that the minimax equalization method yields the best worst case MSE performance among all methods for these simulations since it optimizes the worst case MSE with respect to the worst case channel coefficient. We next present the average MSE performance of each method over different channel perturbations. We show that the minimax regret method has better average MSE performance than the minimax and minimin equalization methods for these simulations.In the first set of experiments, we randomly generate a transmitted signalxtof length 500 with mean 0.01 and variance 1. We also generate a Gaussian channel noisentwith zero mean and unity variance. The channel estimates are constructed usingh˜t=ht+δht, whereht=1.05and the perturbationδhtis randomly generated from a zero mean and ϵ standard deviation Gaussian distribution and truncated to give|δht|⩽ϵwithϵ=0.03for each trial. Here, we label the method in Theorem 1 as “Minimax”, the method in Theorem 2 as “Minimin”, and finally the method in Theorem 3 as “Minimax regret”. For each method and for each random perturbation, we find the corresponding equalizer parameterswtandltto calculate the estimates of the transmitted signalxt. After we calculate the mean-square errors for each method and for all random perturbations, we plot the corresponding sorted errors in ascending order in Fig. 2for 200 trials. Since the minimax equalization method optimizes the worst case MSE with respect to worst possible perturbation, it yields the smallest worst case MSE among all methods for these simulations. However, the overall performance of the minimax method is significantly inferior to the minimax regret method due to its highly conservative nature. Furthermore, we notice that the minimax regret method provides better average performance compared to the minimax and the minimin methods and superior worst case performance compared to the minimin method for these simulations.For the second experiment, we randomly generate 200 random perturbationsδht, where|δht|⩽ϵfor different perturbation bounds and compute the averaged MSEs over 200 trials for the minimax, minimin and the minimax regret methods. In this case, we randomly generate a transmitted signalxtof length 500 with zero mean and variance 1. The channel noisentis generated from a Gaussian distribution with zero mean and unity variance. Here, we construct the estimates of the channel coefficient byh˜t=ht+δht, whereht=1.05and the perturbationδhtis randomly generated from a zero mean and ϵ standard deviation Gaussian distribution and truncated to give|δht|⩽ϵ. In Fig. 3, we present the averaged MSEs for each method where the perturbation bound varies,ϵ∈[0.1,0.3]. We observe that the minimax regret method has the best average MSE performance over different perturbation bounds compared to the minimax and the minimin equalization methods.

@&#CONCLUSIONS@&#
