@&#MAIN-TITLE@&#
An ACO algorithm for makespan minimization in parallel batch machines with non-identical job sizes and incompatible job families

@&#HIGHLIGHTS@&#
Scheduling N jobs with non-identical job sizes from F families on M parallel BPMs is considered.The objective is to minimize the makespan.A meta-heuristic based on MMAS combined with the Multi-Fit algorithm is presented.The performance of the algorithm is compared with several previously studied algorithms.Our results show that the proposed algorithm outperforms the previously studied algorithms.

@&#KEYPHRASES@&#
Parallel batch machines,Max–Min Ant System,NP-hard,Incompatible job families,Makespan,

@&#ABSTRACT@&#
We study the problem of scheduling a set of N jobs with non-identical job sizes from F different families on a set of M parallel batch machines; the objective is to minimize the makespan. The problem is known to be NP-hard. A meta-heuristic based on Max–Min Ant System (MMAS) is presented. The performance of the algorithm is compared with several previously studied algorithms by computational experiments. According to our results, the average distance between the solutions found by our proposed algorithm and the lower bounds is about 4% less than that of the best of all the compared algorithms, demonstrating that our algorithm outperforms the previously studied algorithms.

@&#INTRODUCTION@&#
Batch scheduling problems occur in many industries, such as semiconductor manufacturing, cargo handling in port, transportation, storage systems, and so on. The problem is motivated by the diffusion operation in the wafer fabrication of semiconductor manufacturing. Due to the chemical nature of the process, only jobs with the same recipe can be processed together [1]. All jobs requiring the same recipe can be viewed as a job family, and jobs in the same family have the same processing times. Effective scheduling of these operations is particularly important because of their long processing time requirements, generally 10h as opposed to 1 or 2h for most other processes.In contrast to the classical machine scheduling, a batch processing machine (BPM) can process several jobs in a batch simultaneously. There are two types of batch scheduling problems: s-batch and p-batch. In s-batch, the jobs in a batch are processed in serial and the processing time of a batch is the sum of the processing times of all the jobs in the batch, while in p-batch, the jobs in a batch are processed in parallel and the processing time of a batch is the longest processing time of the jobs in the batch. P-batch scheduling is more important than s-batch scheduling in semiconductor manufacturing [2]. Additionally, p-batch scheduling is often encountered in many modern manufacturing industries such as food, chemical and mineral processing, pharmaceutical and metalworking industries as well as environmental stress screening chamber fabrication [3].In this paper, we consider p-batch scheduling on parallel BPMs with identical machine capacity, non-identical job sizes and incompatible job families. Jobs with non-identical sizes come from different job families. All jobs in the same family have the same processing times, while jobs from different families have different processing times. The jobs have to be grouped into batches such that the total size of the jobs in the batch does not exceed the machine capacity. Moreover, jobs from different families cannot be grouped together in the same batch. The jobs are assumed to be ready at time zero. The processing time of a batch is equal to the longest processing time of all the jobs in the batch [4]; in our case the processing times of all the jobs in a batch are the same. The batches are then scheduled on the machines to minimize the makespan. The problem of minimizing the makespan on a single BPM with non-identical job sizes has been shown to be NP-hard [5]. Thus, our problem is also NP-hard.Like other batch scheduling problems, the problem in this paper can be addressed by solving two independent subproblems: group the jobs into batches and schedule the batches on the parallel BPMs. We propose a Max–Min Ant System (MMAS) algorithm to group the jobs into batches, and then apply the Multi-Fit (MF) algorithm [6] to schedule the batches on the machines.In the literature, there are several articles that deal with incompatible job families [1,30,31,35,36]. The article in [1] assumes that the job sizes are identical, while we deal with arbitrary job sizes. The articles in [30,31] deal with the total weighted tardiness objective, while we study the makespan objective. The articles [35,36] study exactly the same problem as ours. Article [35] studies parallel BPMs while article [36] studies a single BPM. We will be comparing the performance of our heuristic against the heuristics of [35]. As we shall see later, our heuristic outperforms all of the heuristics in [35].The paper is organized as follows. In the following section we review previous related work on BPM scheduling problems as well as the MMAS algorithm. Section 3 formally defines the problem, and a lower bound is provided. The proposed algorithm and its implementation are described in Section 4, and the results of the computational experiment are reported in Section 5. Finally, in Section 6, we conclude the paper with a summary and some directions for future research.Recently, a lot of research has been done on scheduling on BPMs as well as the MMAS algorithm. Previous work related to these two areas will be presented in the next two subsections.We focus on reviewing the literature that have commonalities with the problem assumptions as ours.Ikura and Gimple [7] probably are the first to introduce the batch scheduling problem. They provided an O(n2) algorithm to minimize the makespan on a single BPM with identical job processing times and job sizes, and different job release times. Lee et al. [8] proposed efficient algorithms for minimizing the number of tardy jobs and maximum tardiness under a set of assumptions. They also gave a heuristic with a tight worst-case bound to minimize the makespan on parallel BPMs. Chandru et al. [9] proposed a branch-and-bound algorithm for scheduling on a single BPM to minimize the total completion time. However, their algorithm is only effective on small-scale instances. Chandru et al. [10] demonstrated that the problem of scheduling on a single BPM with a fixed number of job families can be solved in polynomial time. For a fixed number of incompatible job families, Leung [11] provided a polynomial-time algorithm to minimize the makespan on parallel BPMs, assuming unit job sizes. Uzsoy [1] examined a number of problems related to the scheduling on BPMs with incompatible job families and unit job sizes. He developed efficient optimal algorithms to minimize the makespan, maximum lateness and total weighted completion time. He further applied some of the results to parallel BPMs. He also investigated the problem with dynamic job arrivals with the objectives of minimizing the makespan and maximum lateness. Under the assumptions of job number and machine capacity being fixed, Mehta and Uzsoy [12] gave a polynomial-time dynamic programming algorithm for scheduling on a single BPM to minimize total tardiness. They also examined the heuristic which can find near-optimal solutions in reasonable computational time. Lee and Uzsoy [13] studied the problem of scheduling on a single BPM to minimize the makespan, when the jobs have release times. They proposed polynomial and pseudo-polynomial time algorithms for several special cases. They also provided efficient heuristics for the general problem and conduct extensive computational experiments to evaluate the performances of the algorithms.One assumption of the above research is that each job has unit size. However, job sizes are often different in practice. Hence, some researchers turned to study scheduling problems with non-identical job sizes on a single BPM. Uzsoy [5] proved that minimizing the makespan on a single BPM with non-identical job sizes is strongly NP-hard. He provided a number of heuristics and a branch-and-bound algorithm that can solve small-scale problems. Dupont and Jolai Ghazvini [14] provided two heuristics, named the Best-Fit-Longest-Processing-Time (BFLPT) and the Successive Knapsack (SK). BFLPT is based on the Best-Fit algorithm for the bin-packing problem while SK builds a schedule, batch by batch, where the jobs are grouped to minimize the unoccupied space in the batch. Uzsoy and Yang [15] presented a number of heuristics and a branch-and-bound algorithm to minimize the total weighted completion time.Under the assumptions that only jobs from the same family can be batched together and jobs in the same family have the same processing times, Dobson and Nambimadom [16] proposed several heuristics to minimize the total weighted completion time on a single BPM. Azizoglu and Webster [17] developed a branch-and-bound algorithm that can solve problems up to about 25 jobs in reasonable time. To minimize the makespan on a single BPM with non-identical job sizes, Dupont and Dhaenens-Flipo [18] provided a branch-and-bound method. Based on the Longest-Processing-Time (LPT) and the First-Fit (FF) rules, Cheng et al. [19] gave two polynomial-time heuristics to schedule jobs with arbitrary sizes and incompatible families on a single BPM to minimize the makespan and the total batch completion time, respectively. Jolai [20] presented a polynomial-time dynamic programming algorithm to minimize the number of tardy jobs for a fixed number of job families and limited machine capacity. Li et al. [21] provided an approximation algorithm for the general problem with arbitrary release times and job sizes. Yao et al. [22] solved the problem of scheduling on a single BPM with non-identical job sizes and dynamic job arrivals through an improved branch-and-bound algorithm.Recently, meta-heuristics have been applied to solve scheduling problems on a single BPM. Damodaran et al. [23] presented a Simulated Annealing (SA) algorithm to minimize the makespan on a single BPM. Kashan et al. [24] provided two Genetic Algorithms (GAs) for the same problem. Jia and Leung [25] proposed a MMAS algorithm for minimizing the makespan on a single BPM. Based on an Ant Colony Optimization (ACO) algorithm, Li et al. [26] addressed the bi-criteria problem of scheduling jobs with different arrival times, incompatible families, sequence-dependent setup times and the qual-run requirements of advanced process control on parallel BPMs to minimize the Total Weighted Tardiness (TWT) and the makespan simultaneously. To schedule a single BPM with jobs of unequal sizes, dynamical arrivals, and due dates with the aim of minimizing the makespan and the TWT simultaneously. Wang and Chou [27] developed a SA-based Pareto multi-objective algorithm.With the development of new production environments, the study of scheduling on parallel BPMs with identical job sizes has emerged. Lee et al. [8] proposed the LPT heuristic algorithm. To minimize the makespan, maximum lateness, and total weighted completion time, Uzsoy [1] applied a number of algorithms to schedule on single and parallel BPMs with incompatible job families and job release times. Brucker et al. [28] developed a dynamic programming algorithm for scheduling on two identical and parallel BPMs with identical deadline, unit processing time and unit setup time. For the minimization of total weighted tardiness on parallel BPMs with incompatible families, identical job sizes and arbitrary job weights, Mönch and Almeder [29] presented an Ant Colony System (ACS) and a MMAS algorithms. Venkataramana and Srinivasa Raghavan [30] gave an ACO-based algorithm by using the structural properties of the problem. Almeder and Mönch [31] proposed an ACO algorithm and a Variable Neighborhood Search (VNS) approach hybridized with a decomposition heuristic and a local search scheme for the same problem. According to the experimental results, the VNS method shows better performance than the ACO and the GA algorithms in both the running time and the solution quality.Since job sizes are generally non-identical in practice, researchers began to study the scheduling problems with non-identical job sizes on parallel BPMs. Ozturk et al. [32] addressed the makespan minimization problem on parallel BPMs with non-identical job sizes and release dates; they gave a 2-approximation algorithm as well as a MILP model. Chang et al. [33] provided a SA algorithm to minimize the makespan on parallel BPMs with non-identical job sizes. The SA exploits a better neighboring solution after the jobs are grouped into batches and then the batches are assigned to the machines by the LPT rule. To minimize the makespan on parallel BPMs, Damodaran and Chang [34] presented several heuristics and compared their performances with that of the SA (Chang et al. [33]) and CPLEX. Koh et al. [35,36] addressed the problem of scheduling on single and parallel BPMs with arbitrary job sizes and incompatible job families to minimize the makespan, total completion time and total weighted completion time. For each problem, they designed a number of heuristics and compared the solution quality with that of a hybrid GA. Srinivasa Raghavan and Venkataramana [37] used an ACO-based algorithm to minimize the total weighted tardiness on parallel BPMs with incompatible job families. To minimize the makespan and total weighted tardiness simultaneously on parallel BPMs with unit job sizes and incompatible job families, Reichelt and Mönch [38] gave a multi-objective GA. Chiang et al. [39] proposed a memetic algorithm to minimize the total weighted tardiness on parallel BPMs with incompatible job families and dynamic job arrivals. Jia and Leung [40] presented a MMAS algorithm for minimizing the makespan on parallel BPMs with non-identical job sizes.We refer the readers to the articles [4,31,41] for an extensive review of the BPMs problems.ACO, one of the self-adaptive evolutionary algorithms based on the swarm intelligence, is first introduced by Dorigo and Stützle [42]. As a typical distributed algorithm, ACO has been successfully applied to a lot of NP-hard combinatorial optimization problems [43–47]. Over the last few years, ACO has been applied to batch scheduling problems as well [3,29–31,48,49].Due to the improved search strategy, MMAS is one of the most successful ACO algorithms. By enhancing the exploitation of the best solution found during the search, MMAS has the ability to avoid search stagnation in the early stage more effectively [50]. As a result, MMAS has performed better in many applications [51–54].To the best of our knowledge, few efforts [25,29,40] have been dedicated to applying the MMAS algorithm to the BPM problem. Thus, we develop a MMAS-based meta-heuristic to address the parallel BPMs problem with non-identical job sizes and incompatible job families.Using the three-field notation in [55], our problem can be denoted by P∣p-batch, B, F∣Cmax. A set of N jobs, denoted byJ={J1,J2,…,JN}, coming from F different families, denoted byF={F1,F2,…,FF}, is to be grouped into batches. Thus,J=F1∪F2∪⋯∪FF. All jobs in familyFjhave the same processing times, denoted by pj. Let ZN×Frecord the relationship between the jobs and the families, where zij=1 if jobJibelongs to familyFj; otherwise, zij=0. The batch set, denoted byB={B1,B2,…,BK}, is to be scheduled on a set of M parallel BPMs with capacity B, denoted byM={M1,M2,…,MM}.Only jobs from the same family can be batched together, while jobs from different families cannot be grouped in the same batch. The total number of batches K cannot be determined until all the jobs have been grouped. Each jobJihas a size si. All machines have the same capacity denoted by B. We assume that the size of each job does not exceed B. The total size of all the jobs in a batch cannot exceed B. Once the processing of a batch begins, it cannot be interrupted and other jobs cannot be added into or removed from the batch until the processing is completed. The processing time of each batchBk, denoted by Pk, is equal to the processing time of the jobs in the batch. The completion time of machineMm, denoted by Cm, is the sum of the processing times of all the batches scheduled onMm. The makespan of the schedule, denoted by Cmax, is the maximum completion time among all the machines; i.e., Cmax=max{Cm|m=1, 2, …, M}.Let xik=1 if jobJiis in batchBk; otherwise, xik=0. Let ymk=1 if batchBkis scheduled on machineMm; otherwise, ymk=0. The mathematical model of the problem can be formulated as follows:(1)minCmax=max{Cm|m=1,2,…,M}(2)s.t.∑i=1Nxik*si≤B,k=1,2,…,K;(3)∑k=1Kxik=1,i=1,2,…,N;(4)Pk=maxi=1Nmaxj=1F{zij*xik*pj}≥0,k=1,2,…,K;(5)Cm=∑k=1KPk*ymk,m=1,2,…,M;(6)∑m=1Mymk=1,k=1,2,…,K;(7)∑j=1Fzij=1,i=1,2,…,N;(8)xik=1,ifjobJiisgroupedintobatchBk0,otherwise,i=1,2,…,N;k=1,2,…,K;(9)ymk=1,ifBkisscheduledonMm0,otherwise,k=1,2,…,K;m=1,2,…,M;(10)zij=1,ifjobJiisinfamilyFj0,otherwise,i=1,2,…,N;j=1,2,…,F.Objective (1) is to minimize the makespan. Constraint set (2) ensures that the total size of all the jobs in a batch does not exceed the machine capacity. Constraint set (3) ensures that each job is assigned to only one batch. Constraint set (4) defines the processing time of a batch. Constraint set (5) determines the completion time of each machine. Constraint set (6) ensures that each batch can be scheduled on only one machine. Constraint set (7) ensures that each job can only be in one family. Constraint sets (8)–(10) ensure the decision variables xik, ymkand zijto be binary variables.We need a lower bound to evaluate our heuristic. A simple lower bound is given by the following equation.(11)LB=∑j=1F⌈∑Ji∈Fjsi/B⌉*pjM.For each familyFj, a lower bound for the number of batches in the family is⌈∑Ji∈Fjsi/B⌉. Therefore, the total processing time of all the jobs in the familyFjis⌈∑Ji∈Fjsi/B⌉*pj. Summing over all the families and dividing by M gives us a lower bound for the makespan. This is the formula given by Eq. (11).Our problem can be solved in two steps. First, group the job set into batches. Second, assign the batches to the parallel BPMs. For the first subproblem, we propose a MMAS algorithm to batch the jobs. For the second subproblem, we use the MF algorithm to schedule the batches on the machines. In the classical scheduling model, Leung [11] has given an O(logM*N2(F−1))-time algorithm to find a minimum length schedule for a set of N jobs with F different processing times on M identical and parallel machines. After the first step, if we have Z batches, then we can use the algorithm of Leung [11] to construct a minimum length schedule in O(logM*Z2(F−1)) time. However, we choose not to use Leung's algorithm since the running time can be quite large. For a moderate value of F, the running time can be excessive. Moreover, since our first step is a heuristic, the overall algorithm is still a heuristic. Thus, we sacrifice the solution quality for the efficiency of the algorithm.The flow of the proposed algorithm, named MMAS–MF algorithm, is described as follows: First, input the job set. Second, group the jobs into batches by a MMAS algorithm. Third, schedule the batches on the machines by the MF algorithm. Fourth, output the schedule.The MMAS algorithm is one of the best ACO algorithms to solve combinatorial optimization problems. It has been theoretically proved to be convergent [56]. When applying the MMAS to solve the batch scheduling problem, two issues should be considered; i.e., encoding the solution and defining the pheromone trail and the heuristic information.During the process of building batches, the ants select the unscheduled jobs according to the pheromone trails and heuristic information between the jobs and the current batch, and insert the jobs into the batch iteratively. The result of the process is a batch set where the jobs in the same batch can be arranged in any order. Thus, the pheromone trail in iteration h, θik(h), reflects the desirability of assigning the unscheduled jobJiinto the current batchBk. It is defined as follows:(12)θik(h)=∑Jl∈Bkτil(h)∣Bk(h)∣,where τil(h) is the pheromone trail between jobJiand the jobJlin batch Bk. Note that|Bk(1)|=1since we always start a batch by assigning an arbitrary job to it. Also, jobs should be filtered before they are grouped into the batch. This means that the jobs should satisfy the conditions that (1) they are from the same family of the jobs in the current batch and (2) the machine capacity constraint is not violated after the jobs are inserted into the batch. τil(1) is initialized as ((1−ρ)·LB)−1, where ρ is a chosen parameter and LB is the lower bound computed using Eq. (11).We define the heuristic information using the problem-specific knowledge of the objective. Since all jobs in a batch are from the same family and the processing times of the jobs in the same family are the same, the processing time of a batch is determined once the first job is inserted into the batch. Moreover, the processing time of a batch does not change afterwards. To reduce the number of batches, it is better to choose a job whose size is closer to the residue space of the current batch. Hence, we present the heuristic information ηik(h) of inserting jobJiinto batchBkas follows:(13)ηik(h)=11+∣si−(B−∑Jl∈Bksl)∣.Before a job is inserted into the current batchBk, a candidate job setLkis generated. If the unscheduled job satisfies (1) it belongs to the same job family of the jobs in the current batch and (2) the residue space of the batch is able to accommodate the job, then the job will be inserted intoLk. Thus,(14)Lk=Ji∣Ji∈Uk,JiandJl∈Bkareinthesamefamily,si≤B−∑Jl∈Bksl,whereUkis the set of unscheduled jobs. IfUk=∅, then all jobs have been batched, and a batch set is obtained. IfLk=∅, then no more job can be added intoBk, and the ant will start a new batch by randomly selecting one job fromUkas the first job of the new batch. IfLk≠∅, then the ant will choose one job fromLkaccording to the probability pik, and adds it to the current batch. The probability pikis defined as in Eq. (15).(15)pik(h)=(θik(h))·(ηik(h))β∑Jl∈Lk(θlk(h))·(ηlk(h))β,ifJi∈Lk;0,otherwise,where β is a parameter that reflects the relative importance of the heuristic information. The jobJiwith the largest pikwill be chosen to be included in the current batchBk. After a job is chosen,Lkof theBkwill be updated.In the proposed MMAS algorithm, the pheromone trails guide the ants to find better solution. Moreover, the update strategy of the pheromone trails affects the efficiency of the algorithm and the solution quality. Only the global-best solution and the iteration-best solutions are used to update the pheromone trail. If only the global-best solution is used to update the pheromone trail, the search may concentrate around this solution too much, which results in premature convergence. Since the iteration-best solution generally changes during the search, utilizing the iteration-best solution to update the pheromone trail will enhance the diversity of the solutions, which may improve the performance of the algorithm. Thus, the iteration-best solutions and the global-best solution are selected in turn to update the pheromone trail. It is the most important improvement in the MMAS. Specifically, the global-best solution is chosen every μ iterations, while the iteration-best solution is used in the other iterations. Here, μ is a parameter. The update of τilin Eq. (12) is defined by:(16)τil(h+1)=(1−ρ)·τil(h)+Δτil(h),whereΔτil(h)=Q/Cmax*(h)and Q is a parameter. If h is an integral multiple of μ, thenCmax*(h)is the makespan of the global-best solution; otherwise,Cmax*(h)is the makespan of the iteration-best solution.If the pheromone trail in some path becomes too extreme, it may cause a search stagnation. Another significant improvement of the MMAS is to modulate the pheromone trails dynamically by a lower bound τmin and an upper bound τmax[50]. After the pheromone trails are updated in every iteration, the pheromone trails are modulated as follows:(17)τil(h+1)=τmin,τil(h+1)<τmin,τil(h+1),τmin≤τil(h+1)≤τmax,τmax,τil(h+1)>τmax,whereτmax=((1−ρ)·Cmaxgb)−1andτmin=τmax·(1−0.05n)(n/2−1)·0.05n[57]. Here,Cmaxgbis the makespan of the global-best solution.Although the pheromone trails are modulated, the probability of some trails may always be small. It may decrease the diversity of the solutions and result in bad performance. To increase the solution diversification and enhance the performance of the ant system, the pheromone trails are re-initialized [50]. That is, ifCmaxgbhas not been improved for G iterations, the pheromone trails are re-initialized to τmax. Here, G is a parameter.Based on the above description, the batching algorithm, called MMAS, is described as follows.Algorithm 1MMAS(J,M,F)1.Initialize the parameters: the number of ants na; the pheromone evaporation rate ρ; the relative importance of heuristics β; parameter μ for pheromone trail update; the maximum number of iterations Imax; G;Q.Compute the lower bound LB.Initialize pheromone trails: For 1≤i<l≤N, τil(1)←((1−ρ)·LB)−1.h←1. /* The index of the iteration. */g←1. /* The indicator of the variation ofCmaxgb. */While (h≤Imax) do /* Iteratively search. */(a)a←1; /* The index of the ant. */While (a≤na) do /* The ants construct the solutions. */i.k←1;Uk←J;While(Uk≠∅)do /* Construct a new solution. */A.Bk←{Ji}, whereJi∈Fjis an arbitrary job inUk; Pk←pj;Uk←Uk\Bk;Calculate the candidate job setLkaccording to Eq. (14);While(Lk≠∅)do /* Select next job from candidate set according to probability pik. */(1)For eachJi∈Lk, calculate θik(h) and ηik(h) according to Eqs. (12) and (13), respectively;For eachJi∈Lk, calculate pik(h) according to Eq. (15);Bk←Bk∪{Js}, wherepsk=maxJi∈Lk{pik};UpdateUkandLk;k←k+1;Update the current iteration-best and global-best solutions;a←a+1;If((h≥2)and(Cmaxgb(h)=Cmaxgb(h−1)))then g←g+1; else g←1;Compute τmax and τmin according to Section 4.1.4;Update Δτil(h) and τil(h) for all i and l, according to Section 4.1.4;If (g>G) then reinitialize the pheromone trails with τmax; else update pheromone trails according to Eqs. (16) and (17);h←h+1;Output the global-best solution with the batch setB.The MF algorithm has better worst-case performance than the LPT algorithm. In the environment where machines have identical speed, the worst-case ratio of the MF algorithm is 13/11 [58]. We will adopt the MF algorithm to schedule the batches as follows.Algorithm 2The MF algorithm1.Sort the batches generated by the MMAS algorithm in decreasing order of their processing times, and obtain a batch sequenceB′;Compute the lower bound LB* and the upper bound UB* by the following equations:(18)LB*=maxmaxBk∈B′Pk,∑Bk∈B′Pk/M(19)UB*=maxmaxBk∈B′{Pk},2∑Bk∈B′Pk/MT←1;While (UB*>LB* and T<8) do(a)A=(LB*+UB*)/2;Schedule the batches of B′ on the machines by the First-Fit rule; no batch can complete after time A;If all batches can be scheduled, then UB*=A; otherwise, LB*=A;T←T+1.Note that the lower bound LB* is different from the lower bound LB in Section 3. Moreover, it is obvious that LB≤LB*. Therefore, LB* is used in the MF algorithm to obtain a better solution. However, LB* cannot be used as a lower bound of the original instance. It is only a lower bound after the batches are formed, not before the batches are formed. Note that we use less than eight iterations in Step 4 to save some time.To evaluate the performance of the proposed algorithm, a series of computational experiments are performed, where our algorithm is compared with some previously studied algorithms.

@&#CONCLUSIONS@&#
In this paper, we study batch scheduling on parallel BPMs with non-identical job sizes and incompatible job families to minimize the makespan. We present a novel MMAS-based meta-heuristics coupled with the MF algorithm to solve the problem. The jobs are grouped into batches by the MMAS heuristic. The batches are then scheduled on the BPMs by the MF algorithm. The correlation between minimizing the unused space in a batch and minimizing the makespan enables us to concentrate on reducing the unused space in a batch. The strategy of constructing candidate job set is to improve the search performance. Computational experiments show that the MMAS–MF outperforms the other algorithms. The proposed algorithm can find better solutions in an acceptable amount of time.In the future, we will focus on applying the proposed algorithms to scheduling of jobs with delivery dates, release dates, setup times or other constraints, on parallel BPMs with non-identical capacities. Other objectives such as the mean weighted flow time and the maximum lateness are also of interest.