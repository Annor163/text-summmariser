@&#MAIN-TITLE@&#
How bad can the centroid be?

@&#HIGHLIGHTS@&#
The Weber problem is considered with an arbitrary gauge to measure distance.The centroid (centre of gravity) is compared to an optimal solution (1-median).It gives a (1+σ)-approximation in value (σ is the gauge’s asymmetry measure).The 1-median has a 0.5 breakdown point.Centroid to 1-median distance can be up to half of the destination set’s diameter.

@&#KEYPHRASES@&#
Fermat–Weber problem,1-median,2-approximation,Gauge,Breakdown point,

@&#ABSTRACT@&#
In this note we first show that the centroid (or centre of gravity) gives in value a(σ+1)-approximation to any continuous single facility minisum location problem for any gauge with asymmetry measure σ, and thus a 2-approximate solution for any norm.On the other hand for any gauge the true minimum point (the 1-median) remains within a bounded set whenever a fixed proportion of less than half of the total weight of the destination points is moved to any other positions. It follows that the distance between the centroid and the 1-median may be arbitrary close to half the diameter of the destination set.

@&#INTRODUCTION@&#
The Fermat–Weber problem, or single facility minisum Euclidean location problem, is probably the most studied and discussed continuous location model, see e.g. the survey (Drezner, Klamroth, Schöbel, & Wesolowsky, 2003). In its modern form it is stated as follows:Given a finite set of destination pointsA⊂Rdand weights wa> 0 (a ∈ A), find the point x minimizing the sum of weighted (Euclidean) distances to all points of A, i.e. solve(1)min{∑a∈Awa∥a−x∥[−0.2em]0.1em1emx∈Rd}where we assume for notational simplicity and without loss of generality that∑a∈Awa=1. Such a point is also called a Weber-point or (Euclidean) 1-median.It was shown in Bajaj (1988) that no closed algebraic form can solve it in general. Therefore it should be solved through iterative techniques from convex optimisation, the most popular for this particular problem being the almost centenary method developed by Weiszfeld (Weiszfeld, 1937; Weiszfeld & Plastria, 2009), as explained in detail in Plastria (2011).In 1937, Keefer (according to Eilon, Watson-Gandy, and Christofides (1971)—we were unable to verify this information) introduced the so-called centroid (or centre of gravity) method, stating that the solution would be(2)g=∑a∈AwaaSince then, till today, many books on Operations Management, including e.g. Weida, Richardson, and Vazsonyi (2001) (note that Vazsonyi=Weiszfeld, see Vazsonyi, 2002) propose this centroid solution as optimal. This is totally wrong. The centroid g minimizes another objective: the sum of weighted squared Euclidean distances, as is easily established, see e.g. Plastria (2011). Attempts to banish this error have been numerous, but seem not to have been sufficiently heard and still continue to be felt necessary, as exemplified by the writings of Eilon et al. (1971); Schärlig (1973); Vergin and Rogers (1967), and others, up to much more recently (Gehrlein & Pasic, 2009).The difficulty to convince the operations management community of this error should probably be sought for a good part in the fact that in simple examples the centroid seems to give a quite satisfactory approximation of the optimal solution, and, being so much easier to calculate, is therefore preferred. This argument is for example central to the recent paper (Kuo, 2010) that advocates the centroid as a good heuristic solution, and attempts to show so experimentally using randomly generated data, concluding that the approximation grows better and better with increasing number of destinations. This is however no proof of goodness in general at all. In fact it only illustrates the following rather evident fact about the quite exceptional case where the destinations admit a symmetry centre.Lemma 1If the destinations and their weights admit a symmetry centre, i.e. there exists a point s such that for each a ∈ A the symmetric pointas=s+(s−a)∈Aand has the same weight (wa=was), then s is at the same time an optimal solution to(1)and the centre of gravity g, as well as being a point minimizing the weighted sum of any fixed power ( ≥ 1) of distances to the destinations.For any p ≥ 1 the functionfp(x)=∑a∈Awa∥a−x∥pis a convex function of x. Thanks to the assumed existence of s and the symmetry of the Euclidean norm we also have the symmetry property that for anyx∈Rdwe have(3)fp(xs)=fp(s+(s−x))(4)=∑a∈Awa∥a−(s+(s−x))∥p(5)=∑a∈Awa∥x−(s+(s−a))∥p(6)=∑a∈Awas∥as−x∥p(7)=∑as∈Awas∥as−x∥p(8)=fp(x)Buts=0.5x+0.5xsfor any x, so by convexityfp(s)≤0.5fp(x)+0.5fp(xs)=fp(x),showing that s minimizes f p.Takingp=1we obtain that s is an optimal solution to (1), and takingp=2we obtains=g(which, evidently, may be obtained more directly by2g=∑a∈Awaa+∑as∈Awasas=∑a∈Awa(a+as)=2s).□Thus, when the random generation of coordinates and weights is done using a uniform distribution (as is not said, but implicit in Kuo (2010)) the sample test data obtained approximates a symmetric destination set better and better as the sample size increases. And therefore it should be expected that both g and the Weber point will converge to the same asymptotic symmetry centre of the destinations.So, let us have a deeper look at the question how bad the centroid can be for ‘solving’ single facility minisum location problems. As Euclidean distance is a rather restrictive view on modelling real world distances, see e.g. Plastria (1995), we develop our analysis in the much more general setting where distance is measured by an arbitrary finite gauge, the generalisation of a norm that includes possible asymmetry.A first and most common way to check the fit of a solution is to compare it in value to the optimal.Given any gauge ν onRdwe consider the following single facility minisum location problem (see e.g. Plastria, 2009 for general properties of norms and gauges).(9)min{f(x)=∑a∈Awaν(a−x)[−0.2em]0.1em1emx∈Rd}and call any optimal solution m a 1-median. It is well known (see e.g. Pelegrin, Michelot, & F.Plastria, 1985) that multiple optimal solutions might exist, but only when A is aligned and/or ν is not round (i.e. its unit ball is not strictly convex).We investigate the difference between f(g) and f(m).Recall that for the gauge ν we have the triangle inequality, in particularν(w)−ν(v)≤ν(w−v)for anyv,w∈Rd. Due to possible asymmetry of ν the left-hand side of this inequality may not be inversed. Using the skewness σ of the gauge ν, introduced in Plastria (2009) as(10)σ=defmax{ν(−x)[−0.2em]0.1em1emν(x)=1}we haveν(−y)≤σν(y)for anyy∈Rdand so(11)∀v,w∈Rd:|ν(v)−ν(w)|≤σν(w−v).Note that σ ≥ 1, with equality only in case of symmetry, so when ν is a norm. The easiest example of a gauge with skewness σ > 1 is the one-dimensional gauge νσdefined onRas(12)νσ(x)=def{xwhenx≥0−σxwhenx<0Equality in the extended triangle inequality (11) is only possible when v, w andw−vlie on a same (flat) face of ν’s unit ball Bν, meaning either thatv=wor that ν is not round: there exists some p ≠ 0 such thatν(v)=〈p;v〉,ν(w)=〈p;w〉andν(w−v)=〈p;w−v〉.Lemma 2Lipschitz propertyFor allx,y∈Rdwe have|f(y)−f(x)|≤σν(y−x)(13)|f(y)−f(x)|=|∑a∈Awa(ν(a−y)−ν(a−x))|(14)≤∑a∈Awa|ν(a−y)−ν(a−x)|(15)by(11)≤∑a∈Awaσν(y−x)(16)=σν(y−x)□We therefore haveTheorem 3f(m)≤f(g)≤(σ+1)f(m)The first inequality holds because m is a minimum of f.Using Lemma 2 fory=g=∑a∈Awaawe obtain forx=m(17)f(g)−f(m)≤σν(g−m)(18)=σν(∑a∈Awaa−m)(19)=σν(∑a∈Awa(a−m))(20)≤σ∑a∈Awaν(a−m)=σf(m)It follows thatf(g)≤(σ+1)f(m).□The next question is now : can this upper bound of(σ+1)on the approximation factor be reached?Theorem 4If there are at least two different a ∈ A we always havef(g)<(σ+1)f(m)For an equalityf(g)=(σ+1)f(m)we would need equalities instead of inequalities everywhere in the proof of Theorem 3.Now by convexity of ν, inequality (20) only holds if ν is linear on the convex hull of thea−m(a ∈ A). This would mean that there exists a p ≠ 0 such that for all a ∈ A(21)ν(a−m)=〈p;a−m〉from which it also follows by multiplication with waand summation over A that(22)〈p;g−m〉=ν(g−m)≥0For an equality at (17) we need equalities in the proof of Lemma 2, as applied toy=gandx=m.To this end (14) should be an equality, which only holds if allν(a−y)−ν(a−x)have the same sign for all a ∈ A. But sincef(x)=f(m)≤f(g)=f(y)this can only be if for all a ∈ Aν(a−g)≥ν(a−m).Also (15) must be an equality for all a, which by (21) means that alsoν(a−g)=〈p;a−g〉.Putting the two last conclusions together we obtain〈p;a−g〉≥〈p;a−m〉or ⟨ p ; g ⟩ ≤ ⟨ p ; m ⟩. Together with (22) this implies〈p;g〉=〈p;m〉,henceν(g−m)=0and thusg=m. It would follow thatf(m)=f(g)=(σ+1)f(m),and since σ > 0 also thatf(m)=0. But this can only be if there is only a single destination.□The following example shows that the limit of(σ+1)cannot be improved in general by a constant.Example 1Consider any σ ≥ 1. Let there be only two destination points:A={a,b}with weights wa≥ σwb> 0 (wa+wb=1). We may represent these points on the line joining them as numbersa<b∈R,and we assume the direction and scale are chosen such that the norm ν reduces on this line to the gauge νσonRas defined in (12).By the asymmetric extension of Witzgall’s well-known majority rule developed in Plastria (2009), and as is easily checked in this example, we have as median pointm=a,whileg=waa+wbb=a+wb(b−a)=wa(a−b)+b,and thus a ≤ g ≤ b. One then obtainsf(m)=0+wb(b−a)andf(g)=wa(g−a)+wbσ(b−g)=(1+σ)wawb(b−a).It follows thatf(g)f(m)=(1+σ)wa. In concordance with Theorem 4 the limit of(1+σ)can only be reached ifwa=1,which would meanwb=0,so there would in fact only be the single point a in A.However, one can come as close as one wishes to(1+σ),by choosing wasufficiently close to 1. But note that g then also tends to m.For the classical Fermat problem where the gauge ν is the Euclidean norm and all weights are equal (to 1/n, where|A|=n) Durocher and Kirkpatrick (2009) derived the upper bound on the approximation in value given by the centroid solution as2(1−1/n). It is not hard to adapt their proof to the weighted case to obtain an approximation factor off(g)f(m)≤2(1−mina∈Awa)and to see that this bound is reached if and only if A consists of only 2 destinations, in other words, as in Example 1 withσ=1.It is an open question if this bound is also valid for any norm, or if an extended version exists for any gauge.Another way of measuring how good or bad the centroid solution can be, is to look at how far it lies from the real minimum. In other words, how far can g lie from m? For scale invariance this distance should best be compared to the size of the destination set A.Let us first measure this distance using the gauge ν itself and let dν(A) be the ν-diameter of A, i.e.dν(A)=max{ν(b−a)[−0.2em]0.1em1ema,b∈A}. An easy upper bound onν(g−m)is as follows.Lemma 5ν(g−m)≤(1+σ)dν(A)Since g is a convex combination of the a ∈ A we have for any fixed a ∈ A, by (quasi)convexity of ν, thatν(g−a)≤max{ν(b−a)[−0.2em]0.1em1emb∈A}≤dν(A). Therefore(23)f(g)=∑a∈Awaν(g−a)≤∑a∈Awadν(A)=dν(A).Also for any a ∈ A we have, first by triangle inequality for ν, then by definition of σ(24)ν(g−m)≤ν(g−a)+ν(a−m)≤ν(g−a)+σν(m−a).Summing (24) over all a ∈ A after multiplication by wa> 0 we obtainν(g−m)≤f(g)+σ∑a∈Awaν(m−a)(bydefinitionoff)≤f(g)+σf(m)(becausemminimizesf)≤(1+σ)f(g)(by(23))≤(1+σ)dν(A).□But this is certainly a very crude bound since the inequalities used in its derivation are rather loose. However, it is unknown to us how to improve upon it in general. So let us rather see how to make the distance quite large.Example 2We consider the two destination case with the same data as in Example 1. Note that thenwb≤11+σ. Alsodνσ(A)=νσ(a−b)=σ(b−a)We obtain immediately fromm=aandg=a+wb(b−a)thatνσ(g−m)=wb(b−a)=wbσdνσ(A)For fixed σ ≥ 1 a maximal distanceνσ(g−m)is thus reached for the maximal valuewb=11+σ. This is further maximized for the minimal possible valueσ=1. But in that casewb=0.5and νσis a norm so all m ∈ [a, b] are optimal solutions, g being one of these. In other words, the maximal factor of 0.5 may be approximated as closely as wished but cannot be reached in two-destination cases.The minimal distanceν(g−m)is of course 0, obtained forwb=0,i.e. wheng=m=a.In more general cases we know also that g always lies in the convex hull of A. On the line or the plane we know that this also holds for the 1-median m in case ν is any norm (Wendell & Hurter, 1973) (Note that in higher dimension d > 2 this can only be ascertained for ellipsoidal norms, i.e. linearly transformed Euclidean norms, see Plastria, 1983). It follows that in these cases the distance∥g−m∥is always smaller or equal to the Euclidean diameter of A.In what follows we will rather consider the Euclidean distance between g and m and compare it to the Euclidean diameter of A.In Statistics the second skewness coefficient proposed by Pearson as far back as 1895 was3(g−m)/s(where division by the standard deviation s is done for scale invariance) as a measure of skewness of a one-dimensional distribution. In location context this seems somewhat strange, since, as we saw in Example 2, in case only two different values are observed at different frequencies the highest values for this coefficient are obtained for the situations closest to symmetry, i.e. with almost the same frequencies! Perhaps for this reason, among others, the Pearson’s moment coefficient of skewness, based on the third order moment is preferred in Statistics.However, in more recent times, Robust Statistics recognizes a fundamental difference in the properties of the mean and the median in terms of robustness or breakdown point, see e.g. Rousseeuw and Leroy (1987). The breakdown point of an estimator is the (supremum) proportion of incorrect observations (e.g. arbitrary large observations) the estimator can handle before giving an incorrect answer (e.g. arbitrary large). By convention this proportion is at most 0.5, a data set with at least half of the observations erroneous being simply considered as invalid.The one-dimensional median m is maximally robust with breakdown point 0.5, but the mean g is not robust at all (has breakdown point 0). Indeed, taking any observation and moving it to infinity will always move g along beyond any bound, be it at a slower pace. The median m, however, stays fixed even if all data-points with value strictly greater than it (and this can be any fraction < 0.5) move to (any) higher values.An even stronger property holds. Moving any subset of less than half (in frequency) of the data to any new position will possibly make the median move, but always to some point(s) of the convex hull of the original data. This follows because any new median cannot be smaller (nor larger) than all the unmoved points, since these have frequency higher than 0.5, which would contradict the definition of the median; so any new median must lie in the convex hull of the unmoved points. Therefore any median will always remain within a compact set, in this case the convex hull of the original data.We prove below that the 1-median in location theory in any dimension and with any gauge satisfies a similar robustness property with breakdown point 0.5. This result was already obtained for the Euclidean norm by Lopuhaä and Rousseeuw (1991). Our proof is rather technical, having to rely quite heavily on convex analysis in order to make it applicable to any possibly non-differentiable and/or asymmetric gauge. It may be noted that the arguments may be simplified considerably when one assumes that the gauge is differentiable (except at 0) by invoking continuity of the gauge’s gradient at any non-zero vector.Theorem 6Consider the single facility minisum location problem(9)with ν any gauge, and take any fixed 0 < τ < 0.5.There exists a compact set Kτ that contains all optimal solutions to(9)for the given instance and for all instances which are generated by choosing a subset E ⊂ A withwE=∑e∈Ewe≤0.5−τand moving all existing facilities e ∈ E to any arbitrary position inRd.We denoteC=A∖EandwC=∑c∈Cwc=1−wE≥0.5+τ. A point mEis an optimal solution to the single facility minisum location problem (9) if and only if 0 ∈ ∂f(mE), where ∂f(x) denotes the subdifferential of f at x (see e.g. Hiriart-Urruty & Lemaréchal, 2001).By the rules of subdifferential calculus this is equivalent to(25)p+q=0forsomep∈∑c∈Cwc∂ν(mE−c)andq∈∑e∈Ewe∂ν(mE−e)Now we know that(26)∂ν(x)={{r∈Rd[−0.2em]0.1em1emν∘(r)=1,〈r;x〉=ν(x)}whenx≠0{r∈Rd[−0.2em]0.1em1emν∘(r)≤1}whenx=0where ν° denotes the gauge dual to ν, see e.g. Hiriart-Urruty and Lemaréchal (2001); Plastria (1992). Thus, for any x, any r ∈ ∂ν(x) always satisfies ν°(r) ≤ 1.Therefore anyq∈∑e∈Ewe∂ν(mE−e)in (25) is of the formq=∑e∈Eweqewith allqe∈∂ν(mE−e),so with ν°(qe) ≤ 1, and this latter holds for any arbitrary position of E inRd. And since any p in (25) satisfiesq=−pwe must have(27)ν∘(−p)=ν∘(q)=ν∘(∑e∈Eweqe)≤∑e∈Eweν∘(qe)≤wEIn what follows we will construct a compact set Kτ(containing A) such that for any z ∉ Kτand for any choices ofpc∈∂ν(z−c)for each c ∈ C the following inequality holds(28)ν∘(−∑c∈Cwcpc)>wE.The assumptionz=mE∉Kτand any choice ofp∈∑c∈Cwc∂ν(mE−c)would therefore contradict (27) and thus also (25). Thus it will follow that mEmust lie in Kτ, proving that this Kτsatisfies the announced claim and thus terminating the proof.To construct Kτwe use the fact that the subdifferential mapping of any convex functionRd→Ris outer semi-continuous at any pointx∈Rd, see Theorem 6.2.4 p202 in Hiriart-Urruty and Lemaréchal (2001). Using the topological equivalence of all (finite) gauges with the Euclidean norm we may express this property for the convex functionν:Rd→Ras follows(29)∀ɛ>0,∃δ>0:∥y−x∥≤δ⟹∂ν(y)⊂∂ν(x)+ɛBγwhere γ may be any gauge, but here is chosen as the gauge opposite to ν° (i.e.γ(p)=defν∘(−p)), with unit γ-ballBγ={p∈Rd[−0.2em]0.1em1emγ(p)≤1}={p∈Rd[−0.2em]0.1em1emν∘(−p)≤1}=−Bν∘.We will also writeB(x,r)={y[−0.2em]0.1em1em∥y−x∥<r}for the (Euclidean) open ball of centre x and radius r.Set nowɛ=1−0.5−τ0.5+τ>0thenɛ≤1−wEwC. LetS={x∈Rd[−0.2em]0.1em1em∥x∥=1}denote the (Euclidean) unit-sphere, which is a compact set. For every x ∈ S denote a δ corresponding to ε in (29) by δx> 0. Then the setsVx=B(x,δx/2)for x ∈ S form an open covering of the compact set S, from which we may extract a finite subcovering Vt(t ∈ T ⊂ S) of S. Denote finallyΔ=min{δt/2[−0.2em]0.1em1emt∈T}which is positive since T is finite. As a consequence this Δ has the following property(30)∀x∈S,∃t∈T:∥y−x∥≤Δ⟹∂ν(y)⊂∂ν(t)+ɛBγbecause when x ∈ S, it lies in some Vt, so for some t ∈ T we have∥x−t∥≤δt/2,and therefore when∥y−x∥≤Δ≤δt/2we have∥y−t∥≤∥y−x∥+∥x−t∥≤δt,so (29) applies (withx=t).Choose now any fixed pointu∈Rdand letU=max{∥a−u∥[−0.2em]0.1em1ema∈A}. We claim that the Euclidean closed ballKτ=clB(u,U/min{Δ,1})satisfies the sought property (28). Note that Kτdepends only on u, A and τ and not on the particular choice of E. (One may also note in passing that the size of this Kτis minimal when choosing u to be the Euclidean centre of A.)To check this claim, take any z ∉ Kτ. Then on the one hand∥z−u∥>U,so z ∉ C ⊂ A, and on the other hand∥z−u∥>U/Δ.For every c ∈ C let us also take anypc∈∂ν(z−c).Consider thenx=(z−u)/∥z−u∥∈Sand its corresponding t ∈ T guaranteed by (30). Since subdifferentials of norms are (positively) scaling invariant — by (26) we have∂ν(q)=∂ν(λq)for any λ > 0 andq∈Rd— we have also that pc∈ ∂ν(yc) whereyc=defz−c∥z−u∥. Observing that∥x−yc∥=∥c−u∥∥z−u∥≤U∥z−u∥<Δwe may apply (30) to conclude thatpc∈∂ν(t)+ɛBγ. In other words, there is somepc′∈∂ν(t)such that(31)ν∘(pc′−pc)=γ(pc−pc′)<ɛ.In order to conclude we must observe the following well-known property of the dual norm ν°: it is linear on the positive cone generated by any subdifferential of ν, i.e. for anyx∈Rdany p, q ∈ ∂ν(x), any λ, μ > 0 we haveν∘(λp+μq)=λν∘(p)+μν∘(q).It follows (see argumentation afterwards) that(32)ν∘(−∑c∈Cwcpc)=ν∘(∑c∈Cwcpc′−∑c∈Cwc(pc′−pc))≥ν∘(∑c∈Cwcpc′)−ν∘(∑c∈Cwc(pc′−pc))(33)≥∑c∈Cwcν∘(pc′)−∑c∈Cwcν∘(pc′−pc)(34)>∑c∈Cwc−∑c∈Cwcɛ(35)≥wC−wC(1−wEwC)=wEwhich is the claimed property (28). The first inequality (32) stems from triangle inequality for ν°; the second (33) follows from linearity of ν° on the positive cone generated by ∂ν(t) in the first term and sublinearity of ν° in the second term; the third inequality (34) uses in the first term the fact that all subgradients of ν have ν°-length no higher than 1 and in the second term the strict inequality (31) for each c ∈ C.□One should note that Kτincreases unboundedly in size when τ decreases to 0. Indeed, the size of Kτis given by its radius U/min { Δ, 1 }, which is inversely proportional to Δ (when this is small enough) and when τ decreases to 0, ε also decreases to 0, so all δxand therefore also Δ decrease to 0.The ball constructed by Lopuhaä and Rousseeuw (1991) in the Euclidean distance case also has a size proportional with the sample size. We do not know if a uniformly bounded set K might exist in general that would contain all medians for any τ. As observed before this happens in the one-dimensional situation where the convex hull of A may play such a role. We conjecture this is the only case in which a uniform K exists valid for all τ > 0.Using Theorem 6 we may now show how to construct situations for which the (Euclidean) distance between centroid and 1-median for any gauge approximates half of the (Euclidean) diameter of A as closely as wished.Theorem 7Consider the single facility minisum location problem(9)with ν any gauge and let b ∈ A with wb< 0.5. Take any unit direction r with∥r∥=1. Moving b sufficiently far in direction r, the distance∥g−m∥eventually increases towards wb times the diameter of the (new) destination set.Moving b is described by the pointbs=b+srfor s > 0. We denoteA′=A∖{b}. ForAs=A′∪{bs}we write gsfor the centroid and msfor any 1-median for gauge ν.We first havegs=∑a∈A′waa+wb(b+sr)=g+swbr,so gsmoves from g along with bsin direction r, but at the lower speed wb.Let nowasr∈argmax{∥bs−a∥[−0.2em]0.1em1ema∈A′}be a point of A′ that is farthest from bs. From some value of s onasrbecomes a constant ar, and we have for sufficiently large s that the diameter of Asis given byd(As)=max{∥c−d∥[−0.2em]0.1em1emc,d∈As}=∥bs−ar∥. It follows that(36)d(As)≤∥bs−b∥+∥b−ar∥=s+∥b−ar∥By Theorem 6 (usingu=gin its proof) we know that for all s∥g−ms∥is upper bounded by some constant, D say. Therefore(37)∥ms−gs∥≥∥g−gs∥−∥g−ms∥≥wbs−DDividing (37) by (36) we obtain∥ms−gs∥d(As)≥wbs−Ds+∥b−ar∥which converges increasingly to wbwhens→+∞.□This is not really a very surprising result. Moving b out to infinity may also be seen as keeping b fixed at r, but shrinking all A′ simultaneously to the fixed point starting point−b; this is obtained by a division by s (replacings→+∞byt=1/s↓0) followed by a translation over−b,i.e. defining insteadbt=randAt=At−b,for which the corresponding centroidgt=gs/s−band 1-medianmt=ms/s−b. At the limit a two-destination situation is obtained similar to Example 2 in which∥g−m∥=wbd(A).

@&#CONCLUSIONS@&#
