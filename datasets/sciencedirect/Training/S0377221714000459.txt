@&#MAIN-TITLE@&#
A fast approximation algorithm for solving the complete set packing problem

@&#HIGHLIGHTS@&#
We propose a new mathematical formulation for the complete set packing problem.We develop an efficient method for generating near-optimal packing (lower bounds).We develop a method for solving a large MILP for finding tighter upper bounds.The LP relaxation of the WDP in spectrum auctions can be solved efficiently.We test large problems in combinatorial auctions and cooperative games.

@&#KEYPHRASES@&#
Set packing problem,Combinatorial auctions,Winner determination problem,Coalition structure generation,Large-scale MILP,

@&#ABSTRACT@&#
We study the complete set packing problem (CSPP) where the family of feasible subsets may include all possible combinations of objects. This setting arises in applications such as combinatorial auctions (for selecting optimal bids) and cooperative game theory (for finding optimal coalition structures). Although the set packing problem has been well-studied in the literature, where exact and approximation algorithms can solve very large instances with up to hundreds of objects and thousands of feasible subsets, these methods are not extendable to the CSPP since the number of feasible subsets is exponentially large. Formulating the CSPP as an MILP and solving it directly, using CPLEX for example, is impossible for problems with more than 20 objects. We propose a new mathematical formulation for the CSPP that directly leads to an efficient algorithm for finding feasible set packings (upper bounds). We also propose a new formulation for finding tighter lower bounds compared to LP relaxation and develop an efficient method for solving the corresponding large-scale MILP. We test the algorithm with the winner determination problem in spectrum auctions, the coalition structure generation problem in coalitional skill games, and a number of other simulated problems that appear in the literature.The set packing problem and its variants (the set covering and set partitioning problems) are among the most well-studied problems in combinatorial optimisation thanks to their wide ranges of applications, their elegant mathematical formulation, and their special structural properties. In the SPP, there are n objects which can be packed into a number of subgroups among m predefined feasible subsets labelled asS1,…,Sm. Each subsetSjhas a payoff value ofvj. The SPP aims to divide these n objects into non-overlapping subgroups such that their total payoff is maximised. The SPP can be formulated as an MILP as follows:(1)SPP(A,v)≔maxxvtxs.t.Ax⩽e,x∈{0,1}m,wherex=(x1,x2,…,xm)is a vector of binary decision variables withxjindicating whether subsetSjis selected in the packing,A∈Rn×mis a matrix with elementaijin row i and column j indicating whether subsetSjcontains objecti,v∈Rmis a vector of payoffs, ande∈Rnis a vector with all elements being equal to one.The SPP has many applications such as for routing and scheduling trains at intersections in railway operations Zwaneveld, Kroon, and Van Hoesel (2001), for selecting winning bids in combinatorial auctions (De Vries & Vohra, 2003), for surgical operations scheduling Velásquez and Melo (2006), and for packets scheduling and transmission in communication networks Emek et al. (2012). In the context of combinatorial auctions, the winner determination problem (WDP) is essentially a set packing problem. Sandholm (2002) develops an algorithm that utilises the graphical representation of the coalition structure search space for solving the WDP. Fujishima, Leyton-Brown, and Shoham (1999) develop an exact algorithm, where caching and pruning are used to speed up the search, and a heuristic algorithm for solving the WDP.The tractability of the SPP depends on the structure of the underlying IP formulation. Specifically, Müller (2006) and Rothkopf, Pekeč, and Harstad (1998) summarise special cases where the corresponding LP relaxation solutions satisfy the integrality constraints and hence are also solutions of the SPP. These are, however, very restrictive cases and it is generally very difficult to solve the SPP. In fact, Karp (1972) shows that the SPP problem is NP-complete while Sandholm (2002) shows the inapproximability of the problem for general cases. Many methods, both exact and approximation, have been proposed for solving the SPP. Padberg (1973) and Cánovas, Landete, and Marın (2000) show different sets of facets of the set packing polyhedron which can be used to strengthen the LP relaxation solutions. Landete, Monge, and Rodríguez-Chía (2012) present an alternative formulation for the SPP in a higher-dimensional space where a set of facets can be identified.Methods for solving the SPP often start with solving the corresponding LP relaxation problem. De Vries and Vohra (2003) survey different methods such as a constraint generation method for solving the LP relaxation problem and a sub-gradient method for solving the Lagrangian relaxation. The authors also provide interesting insights on how the numerical algorithm is interpreted in the auctioning process. These methods have actually been well-studied in the context of the set covering problem (SCP), a variant of the SPP where the objective is to minimise the total cost of covering all the objects (see Beasley (1987) and Beasley & Jörnsten (1992) for examples). Caprara, Toth, and Fischetti (2000) survey methods to solve the SCP and compare their numerical performance on test problems that appear in the literature.Kochenberger, Glover, Alidaee, and Rego (2004) provide an unified framework for solving combinatorial optimisation problems by transforming them into unconstrained quadratic binary optimisation problems (UQBP). The authors then suggest the use of Tabu search, a metaheuristic method that employs local search and a ‘tabu’-list to keep track of the searched space, for solving the UQBP. Alidaee, Kochenberger, Lewis, Lewis, and Wang (2008) and Lewis, Kochenberger, and Alidaee (2008) apply these methods to the set packing and set partitioning problems and show that the algorithms outperform CPLEX (on the original MILP formulations) on many moderate-sized instances (with up ton=5000objects andm=15,000feasible subsets for the SPP case).There are also many other heuristic methods for solving the SPP. In fact, Hoffman and Padberg (2001) state that “virtually every heuristic approach for solving general integer programming problems has been applied to the set-covering, packing and partitioning problems.” Delorme, Gandibleux, and Rodriguez (2004) develops GRASP, a greedy randomised algorithm for solving the set packing problem. Beasley and Chu (1996) develop a genetic algorithm for solving the set covering problem and this method can be adapted to solve the SPP.In this paper, we aim to solve the SPP for cases whenm=2n, i.e. any subset of objects can be grouped together in a packing, or when m is relatively large compared to n. This setting arises in applications such as combinatorial auctions where bidders submit their bids in the form of value functions on the objects selected. This bidding mechanism is favourable to auction designers and to bidders because the information can be communicated in a more compact way. Another application area is in multi-agent systems, e.g. in a sensor network (Dang, Dash, Rogers, & Jennings, 2006), where players are grouped into coalitions to maximise their total utility. As the number of possible subsets can grow exponentially, existing methods (such as Beasley & Jörnsten, 1992; Caprara et al., 2000; Fujishima et al., 1999; Sandholm, 2002) are not applicable due to the large number of binary decision variables involved.LetN={1,…,n}be the set of all objects and letx=(x1,x2,…,x2n)be a vector of binary variables withxjindicating whether subsetSjis selected in the packing. The CSPP can be formulated as an MILP as follows:(2)CSPP(N,v)≔maxxvtxs.t.ANx⩽e,x∈{0,1}2n,whereAN∈Rn×2nis a matrix with elementaijin row i and column j indicating whether subsetSjcontains object i. For convenience in notation, letaj=(a1j,…,anj)tbe a column vector of binary indicators for eachj∈{1,…,2n}. To avoid ambiguity in the ordering ofaj, we assignajto the binary representation of(j-1). Let us denotevj≡v(aj)≡v(Sj)as the payoff of subsetSj. Forn⩽15, problemCSPP(N,v)can be solved efficiently by CPLEX through a classical branch and bound technique. However, the size of the MILP problem grows exponentially as the number of objects increases and it is impossible for CPLEX to solve instances with more than 20 objects. We aim to develop an approximation method for solving this MILP.Combinatorial auctions have been used in the procurement of London bus routes Cantillon and Pesendorfer (2006), radio spectrum Cramton (1997), and truckload transportation Caplice and Sheffi (2006), among many others. Combinatorial auctions arise in situations where bidders are interested in buying bundles of objects that inherit some level of synergies among themselves. One of the key problems in combinatorial auction is to find the best feasible combination of bids to maximise the total payoff. This problem is equivalent to a complete set packing problem where objects are those to be sold and the payoff of each subset is the maximum bid that the bidders offer. In the combinatorial auction literature, solution approaches such as Fujishima et al. (1999) and Sandholm (2002) often assume that the number of bids are relatively small compared to the number of objects, i.e. a few hundreds of objects and a few thousands of bids at most. However, in many real-life situations such as in spectrum auctions, bidders might be interested in buying any subset of their predefined frequencies. In this case, the bidders may express their interest through a compact value function that involves their objects of interest and their specific synergy parameters (Cramton, Ausubel, McAfee, & McMillan, 1997; De Vries & Vohra, 2003). Therefore, the set of feasible bids from all the bidders is an exponential function of the number of objects. We discuss about one such case in spectrum auctions in subSection 3.1.Cooperative games with transferable utilities belong to a branch of game theory where groups of players can form coalitions in order to jointly achieve the groups’ objectives. Cooperative game theory has many applications in economics and business (e.g. for setting insurance premiums (Lemaire, 1991), and for setting interchange fees for ATM bank networks (Gow & Thomas, 1998)), in law and political science (e.g. for computing voting power (Leech, 2003)), and in artificial intelligence (e.g. for coalition structure formation in multi-agent systems (Chalkiadakis, Elkind, & Wooldridge, 2011)), among many others. One of the key problems in coalitional games is to find a coalition structure, i.e. to divide the set of all players into disjoint subsets called coalitions, such that the total payoff of these coalitions is maximised. This problem is equivalent to a CSPP where players are viewed as objects, coalitions are viewed as subgroups, and a coalition structure is equivalent to a packing. Sandholm, Larson, Andersson, Shehory, and Tohmé (1999) present a coalition structure graph to visualise the set of all possible coalition structures. The authors then show interesting results about the guaranteed bound on the best coalition structure within certain parts of the graph. Since then, new exact methods have been introduced to exploit the special search space of the coalition structures. However, these existing methods are only applicable for games with less than 30 players Rahwan, Michalak, and Jennings (2012).In this manuscript, we develop an approximation method for solving the CSPP. Our contributions include the following:1.We propose a new mathematical formulation for the CSPP that makes use of the subsets suggested by the LP solution (or any heuristic solution and their combination). The new formulation directly suggests an efficient method for generating near-optimal feasible packings.We propose a method to find tighter upper bounds (compared to LP relaxation). This involves a constraint generation framework to solve the corresponding large-scale MILP problem.We demonstrate the algorithm with the winner determination problem that arises in spectrum auctions. We show that the constraint generation problem can be solved in O(n2logn) and that the LP relaxation problem can be solved in polynomial time. We provide numerical results for spectrum auctions instances with up to 200 objects.We also perform numerical tests on the optimal coalition structure generation problem that arises in large weighted coalitional skill games Bachrach, Meir, Jung, and Kohli (2010) and a number of other simulated combinatorial auction settings that are accompanied by underlying economical interpretations Leyton-Brown and Shoham (2006).The structure for the rest of the paper is as follows. We provide an alternative formulation for the CSPP problem in subSection 2.1. This leads to an efficient method for finding feasible packings in subSection 2.2. The upper bounds are obtained by solving the LP relaxation and a large-scale MIP relaxation. These are done via constraint generation frameworks to be described in subSections 2.3 and 2.4. We demonstrate the algorithm through two applications in combinatorial auctions and cooperative games in subSections 3.1 and 3.2. We provide numerical results in Section 4 and finally conclude in Section 5.The set packing problem essentially aims to choose columns in matrixAto maximise the total value of the selected columns while still enforcing the packing constraints. Consider dividing these columns into two subsets; letIbe the indices of columns that we have a high expectation on where the optimal set of subsets will lie on, and letJbe the indices of the remaining columns. For now, we assume thatIandJare given. LetAIandAJbe the sub-matrices ofAthat are formed by columns in setsIandJ, respectively. Suppose for the sake of convenience in notation that the columns ofAare rearranged such thatA=[AI,AJ]. Similarly, letvIandvJbe the vectors of objective coefficients for columns in setsIandJ, respectively, i.e. we have:Av=AIAJvIvJ.The CSPP then can be rewritten as:(3)maxxI,xJvItxI+vJtxJ,s.t.AIxI+AJxJ⩽e,xI∈{0,1}|I|,xJ∈{0,1}|J|,wherex=[xI,xJ]andxIandxJare vectors of binary decision variables indicating whether columns in subsetsIandJare selected in the packing, respectively.For each fixedxI, the remaining columns inJneed to be chosen according to the indicator vectorxJsuch thatAJxJ⩽e-AIxIand such that the total value of the remaining columns selected is maximised, i.e. we solve:(4)g(xI)≔maxxJ∈{0,1}|J|vJtxJ,s.t.AJxJ⩽e-AIxI.Here, we defineg(xI)=-∞if problem (4) is infeasible. Let us denotefIP∗(N,v)as the optimal value ofCSPP(N,v). We also use a shorthand notationfIP∗≡fIP∗(N,v)where there is no confusion for not specifying(N,v). For each choice ofxI, letN⧹AIxIbe the set of remaining objects after subsets inAIhave been selected according to the indicator vectorxI. Letv⧹AIxIbe the corresponding reduced vector of payoffs that subgroups ofN⧹AIxIcan obtain. Then problem (4) is equivalent to another complete set packing problem on the remaining objects,1This definition is similar to the value function of the packing game defined by Deng, Ibaraki, and Nagamochi (1999).1i.e.g(xI)≡fIP∗(N⧹AIxI,v⧹AIxI).Problem (3) can be reformulated as a bi-level optimisation problem:(5)maxxI∈{0,1}|I|vItxI+maxxJ∈{0,1}|J|vJtxJ,s.tAJxJ⩽e-AIxI,s.t.AIxI⩽e,which is equivalent to the following mixed integer non-linear program (MINLP):(6)maxxI∈{0,1}|I|vItxI+g(xI),s.t.AIxI⩽e.It is interesting to note that the reformulation has a smaller number of binary variables, i.e.xI∈{0,1}|I|, instead of2nbinary variables that appear in model (2). However, this comes at a cost of having an unknown non-linear termg(xI). Indeed, this quantity is the payoff of the optimal set packing problem on the remaining objects. This means the problem is still hard but this makes sense since two equivalent formulations should have the same level of complexity. Notice, however, that the reformulation can provide us an idea of how to find a near-optimal solution as will be described next.Instead of maximising the entire quantityvItxI+g(xI), let us approximate the problem by replacing the second termg(xI)with its linear approximationct(e-AIxI)as follows:CSPPsub≔maxxvItxI+ct(e-AIxI),s.t.AIxI⩽e,x∈{0,1}|I|,wherecis the vector of payoffs that individual objects can obtain and(e-AIxI)is the indicator vector of the remaining objects. The corresponding formulation is an MILP with n linear constraints and with|I|variables and could be solved efficiently by CPLEX, or some existing algorithms for solving the set packing problem (e.g. (Beasley & Jörnsten, 1992; Caprara et al., 2000; Fujishima et al., 1999; Sandholm, 2002)) for relatively small|I|. We notice that the objective function is equivalent tovIt-ctAIxIwherevIt-ctAIis the corresponding reduced cost vector forxI. After having foundxI∗, we can solve a new CSPP problem on the remaining objects to findgxI∗. This can be done through an exact algorithm if the number of remaining objects is relatively small, or through an approximation method such as the one we are describing otherwise. Formally, this is described in Algorithm 1.Algorithm 1Approximation algorithm for finding near-optimal set packing (lower bound)Initialisation: Setk=1,N(k)=N,fsub∗=0.whileN(k)≠∅do1. Find the set of candidate subsetsIthat is suggested by an LP relaxation solution.2. SolveCSPPsub. LetxI∗be an optimal solution.3. Update:fsub∗=fsub∗+vItxI∗,N(k+1)=N(k)⧹AIxI,v(k+1)=v(k)⧹AIxI,k=k+1.end whileReturn solutionfsub∗.In step (1) of Algorithm 1, we find an initial set of potential subsets that might appear in the optimal packing. We will use the setIthat is suggested by the LP relaxation solution. A possible method for solving the LP relaxation is described in subSection 2.4. Notice, however, that the algorithm is very flexible in choosing the candidate set. In fact, the setIcan also be obtained from any heuristic solution or from a combination thereof. In step (2) we solve problemCSPPsubto find a near-optimal solution to the reformulation of CSPP in model (6). In step (3) we update the approximated objective value, the set of remaining objects, and their reduced vector of the payoff values. The first result we can see immediately is that the algorithm provides us a feasible packing solution and a lower bound to the CSPP as formally stated in the Lemma 1.Lemma 1Algorithm 1produces a lower bound on the CSPP, i.e.fsub∗⩽fIP∗.Since Algorithm 1 selects no same object twice for different subsets, it produces a feasible packing solution withfsub∗being the packing’s total payoff. Thus,fsub∗⩽fIP∗. □Given the lower bound of CSPP, we are interested in judging how good the bound is. In theory, the quality of the approximated solution depends on how good the linear approximationct(e-AIxI)is compared togxI∗around the truth optimum. In general, the linear approximation is more accurate if‖e-AxI‖is small. In other words, the higher the accuracy of picking the right candidate subsetI, the smaller the size of the remaining set, and hence the more accurate the linear approximation is. It is important that the approximated functionf̃(xI)is close to the original objective functionf(xI)around the optimumxI. Notice also that, due to the discreteness ofxI, it is still possible forf̃(xI)to have the same optimum asf(xI)even though the two functions differ atxI∗. It is easy to extend the algorithm to use a quadratic approximation ofgxI∗and this would enhance the quality of the bound. However, this will come at a cost of having a more computationally expensive approximation and hence the choice would depend on how we want to trade off between the quality of the solution and the computation time. We will use the upper bounds found via LP and MILP relaxation (to be described in subSections 2.3 and 2.4) to estimate the optimality gap of the solutions found by Algorithm 1.In LP relaxation, we relax the binary constraints onxand this provides us with an upper bound to the CSPP. However, due to the excessive relaxation on all the2nbinary variables, the quality of the bound might not be good enough for some instances. With the expectation that the optimal columns are mostly inAI, we develop a better relaxation strategy where only the vectorxJis relaxed while still enforcingxIto be binary as follows:CSPPMIP≔maxxvItxI+vJtxJ,s.t.AIxI+AJxJ⩽e,xI∈{0,1}|I|,xJ⩾0,where the constraintxJ∈{0,1}|J|has been relaxed toxJ⩾0. Notice that we do not have to includexJ⩽1because the packing constraint{AIxI+AJxJ⩽e}has already enforced this. We call this an MIP relaxation and notice that it has|I|binary variables and|J|continuous variables. We will choose|I|relatively small, i.e.|I|∼n≪2n, and henceCSPPMIPis much easier to solve compared to the original MILP but still more difficult than the LP relaxation due to the presence of the binary variablexI. SolvingCSPPMIPwill provide us a better upper bound to the CSPP compared to the LP relaxation, as stated in the following lemma.Lemma 2The following inequalities hold:fLP∗⩾fMIP∗⩾fIP∗⩾fsub∗.The first two inequalities are obvious sinceCSPPLPis a linear relaxation ofCSPPMIP(on variablexI) andCSPPMIPis a linear relaxation ofCSPP(on variablexJ). The last inequality was derived in Lemma 1. □Despite the tighter bound obtained, solvingCSPPMIPgiven its exponential size is very challenging. Due to the presence of the binary variablexI, we cannot apply the classical column generation approach to handle the exponentially large number of columns. In what follows, we will present a new approach for solvingCSPPMIP.We notice thatCSPPMIPcan be reformulated as a bi-level optimisation problem as follows:maxxI∈{0,1}|I|vItxI+maxxJ⩾0vJtxJ,AJxJ⩽e-AIxI,AIxI⩽e.Due to the boundedness and the non-emptiness of the constraint set onxJ, we can replace the LP in the second level with its dual:maxxI∈{0,1}|I|vItxI+minβ⩾0βt(e-AIxI),AJtβ⩾vJ,AIxI⩽e.LetFJ≔β:AJtβ⩾vJ,β⩾0; the bi-level problem can be further reformulated as:(7)maxxI∈{0,1}|I|,δvItxI+δs.t.βt(e-AIxI)⩾δ∀β∈FJ.This reformulation is an MIP with|I|binary variables and one continuous variable, and with a semi-infinite number of constraints (one for eachβ∈FJ). Due to the linearity of the constraints onβ, the semi-infinite constraints are equivalent to a finite set of constraints for all the extreme points and extreme rays{β1,…,βK}ofFJ. Model (7) can be reformulated as:(8)CSPPMIP2≔maxxI∈{0,1}|I|,δvItxI+δs.t.β(k)t(e-AIxI)⩾δ,∀k=1,…,K.The new MIP problem has|I|binary variables, one continuous variable, and K linear constraints where K could be exponentially large. This means the reformulation is still as complex as the original MIP but this makes sense since the two are equivalent. However, the formulation defined byCSPPMIP2allows us to apply a constraint generation framework where only relevant extreme points and extreme rays ofFJare introduced to the model, as described in Algorithm 2.Algorithm 2Constraint Generation Algorithm for Solving MIP relaxationInitialisation: Start with any initial relaxed constraint setM(0)={β(0)}, whereβ(0)is a feasible point inFJand setk=0.loop1. Setk=k+1and solve the relaxed problem:xI(k),δ(k)=argminx,δvItxI+δ:(e-AIxI)tβ(j)⩾δ,∀j∈{0,…,k-1}.2. Solve the constraint generation problem:β(k)=minββte-AIxI(k):AJtβ⩾vJ,β⩾0.ife-AIxI(k)tβ(k)⩾δ(k)thenTerminate the loop.elseUpdateM(k)={M(k-1),β(k)}.end ifend loopReturn optimal solutionxI∗=xI(k)and setfMIP∗=vItxI∗+δ(k).In step (1) of Algorithm 2, we solve a relaxed problem ofCSPPMIP2. This is an MIP and can be handled by CPLEX for reasonably large n (up to a few hundred objects) as long as we keep track of the number of constraints generated, i.e. we keep k below some bound relative to n. In step (2) we solve the constraint generation problem. Notice the problem has exactly the same structure compared to the dual ofCSPPLP. We describe a solution approach for solving this problem in subSection 2.4.It is important to note that we cannot apply a column generation algorithm directly to the original MIP as that would not provide us a proof of optimality even when no further improving column can be found, i.e. we could be trapped in local optimum due to the presence of the binary variablexI. However, with the reformulation inCSPPMIP2, we have a proof of optimality on the constraint generation algorithm once no further violating constraints are found.Consider the dual ofCSPPLP:CSPPLPD≔minety,s.t.ajty⩾v(aj),∀j∈{1,…,2n},y⩾0.The dual problem contains a decision variabley∈Rnand an exponentially large number of constraints. The optimal value of the dual LP relaxation problem, denoted asfLP∗, provides us an upper bound on the optimal value of the original MILP. From this, we obtainfsub∗/fLP∗as a guaranteed optimality bound of the feasible packing found in subSection 2.2. Although this upper bound is not as tight as the MIP upper bound, it is computationally less expensive and might be more appropriate to use in situations with limited computational resources. Forn⩽20, we can solveCSPPLPDeasily by using an LP solver like CPLEX. Forn⩾30, the problem contains more than a trillion constraints and this makes it difficult to solve. However, it is interesting to observe that only a small number of constraints are tight at the optimal solution. This means the remaining non-binding constraints can be relaxed without changing the optimal solution. We can start with a relaxed problem ofCSPPLPDwith a small set of constraints and then keep introducing violating constraints to the relaxed problem until all the constraints are satisfied. At that point, the optimal solution of the relaxed problem is also the optimal solution of the original problem. Formally, the constraint generation method for solvingCSPPLPDis described in Algorithm 3.Algorithm 3Constraint Generation Algorithm for Solving LP relaxationInitialisation: Start with any initial weight vectory(0)and initial relaxed constraint setM(0)and setk=0.loop1. Solve the constraint generation problem:w=argminz∈{0,1}n{zty(k)-v(z)}.ifwty(k)-v(w)⩾0thenTerminate the loop.elseUpdate relax set:M(k+1)={M(k),w}.end if2. Setk=k+1and solve the relaxed problem:y(k)=argminy{ety:zty⩾v(z),∀z∈M(k)}.end loopReturn optimal solutiony∗=y(k)and setfLP∗=ety∗.In step (1) of Algorithm 3, we find a subsetzthat violates constraint{zty(k)⩾v(z)}mostly for the given proposaly(k). Here, a subset is characterised by a binary indicator vectorzwithzi=1if object i is in the subset andzi=0otherwise. We then check the optimality condition. If the worst subset is not violated, then all other subsets satisfy this constraint and hencey(k)is an optimal solution ofCSPPLPD. Otherwise, we introduce the newly generated constraint{wty-v(w)⩾0}to the relaxed problem. In step (2), we solve the updated relaxed problem to obtain a new proposaly(k)before going back to step (1).Notice that the relaxed problem is an LP with smaller size and is easy to solve. The key, and often the difficult part, for a successful constraint generation algorithm is the ability to generate violating constraints efficiently. We will show that the CG problem in the spectrum auction application can be solved in O(n2logn). We will also show that the constraint generation problem in the WCSG games with reasonable size (i.e.n⩽200) can also be solved very efficiently. Some remarks on the constraint generation problem follow.•The constraint generation problem does not have to be solved exactly at every step except for the last step. In fact, any violating constraint could be added to the relaxed problem. It is only in the last step before terminating the loop that we need to obtain an optimal solutionwand to check if{wty(k)-v(w)⩾0}.In some instances, the constraint generation problem might turn out to be very difficult to be solved to optimality. In this case, we can still obtain an upper bound to the CSPP as stated in Theorem 1.Lety(k)be the optimal solution of the relaxed problem at iteration k inAlgorithm 3and let∊=maxjvj-ajty(k); then we have:ety(k)⩽ety∗⩽ety(k)+n∊.Sincey∗is an optimal solution ofCSPPLPD, it is also a feasible solution of any LP relaxation problem at any iteration k. Thus, its objective valueety∗should be at least the optimal valueety(k)of the relaxed LP, i.e.ety(k)⩽ety∗. We can also show thatx=y(k)+∊eis a feasible solution to the relaxed LP by verifying that both the constraintsajtx⩾v(aj),∀j∈{1,…,2n}andx⩾0are satisfied. By the definition of∊=maxjvj-ajty(k)and by the construction of the algorithm, we have∊⩾0before the loop in Algorithm 3 terminates. Thus,x=y(k)+∊e⩾y(k)⩾0. Forj=1we haveaj=0andvj=0and hence the constraintajtx⩾v(aj)holds trivially. Forj⩾2, we have:ajtx=ajty(k)+∊ajte⩾ajty(k)+∊⩾ajty(k)+vj-ajty(k)=vj.Thus,xis a feasible solution toCSPPLPD. Therefore,ety∗⩽etx=ety(k)+∊ete=ety(k)+n∊.□The implication of Theorem 1 is that if∊is sufficiently small relative toety(k), we can stop the CG algorithm and use the upper bound(ety(k)+n∊)instead ofety∗.In a spectrum auction, there are n frequencies (objects) and m bidders. Each bidder is interested in a subset of frequencies. LetΦ∈Rm×nbe a 0–1 matrix whereϕij=1indicates whether bidder i has an interest in frequency j andϕij=0otherwise. We follow the model suggested by Cramton et al. (1997) and De Vries and Vohra (2003) and assume that the individual object j has a payoff value ofvj. Bidder i will value a subsetSof frequencies as∑i∈Svi+μi∑k,q∈S∩ϕivkvqwhereμiis a parameter that models how strong bidder i views the complementarities (De Vries & Vohra, 2003). The largest bid on a subsetSis:(9)v(z)=maxi∈N∑i∈Svi+μi∑k,q∈S∩ϕivkvq.Notice thatv(z)is not given explicitly. To apply existing methods, we would have had to evaluatev(z)for allzjust to obtain the input to the CSPP. This is very expensive computationally. We will show that, by applying our constraint generation framework, we will eliminate this stage and only perform the calculation if needed. Specifically, we can combine the max operator in (9) into the max operator of the CG problem as follows:(10)maxz{v(z)-zty}⇔maxz,i∈N∑i∈Svi+μi∑k,q∈S∩ϕivkvq-zty⇔maxi∈Nmaxz∑i∈Svi+μi∑k,q∈S∩ϕivkvq-zty⇔maxi∈Nmaxzvtz-zty+μi((ϕi⊙v)tz)2⇔maxi∈Nmaxz(btz)2-atz,wherea=y-v, andb=(ϕi⊙v)is the element-wise production of the two vectorsϕiandv.For each fixed i, the CG problem is a quadratic binary optimisation problem (QBP) which is NP-hard to solve except for special cases. Among these, Allemand, Fukuda, Liebling, and Steiner (2001) develop a polynomial time algorithm for solving unconstrained fixed-ranked homogeneous QBP, i.e. one with the formmaxz∈{0,1}n{ztQz}whereQis a symmetric positive definite matrix with a fixed rank. Specifically, the authors show that there is an O(nd-1) algorithm for solving the QBP where d is the rank ofQ. We will extend this result to the case of nonhomogeneous fixed-ranked QBP and show an O(n2logn) algorithm for solving the constraint generation problem.Theorem 2The constraint generation problem described in(10)can be solved inO(n2logn).In the CG problem, we need to maximise{(btz)2-atz}. For eachz∈{0,1}n, letP(z)=(atz,btz)be the corresponding point in a 2-dimensional space, i.e.P(z):{0,1}n→R2. Since there are2nsuch pointsz, we have2ncorresponding pointsP(z)in 2-D. It is very interesting, however, that the convex hall of these points has at most2nextreme points Allemand et al. (2001). Since we are maximising a convex function{P2(z)2-P1(z)}, the maximum is attained at one of the extreme points. In addition, these extreme points can be listed out as follows:Letpi=(ai,bi)and letαi=arctan(ai/bi). We first orderαin an ascending orderα(1)⩽α(2)⋯⩽α(n). The2nextreme points are given by the following equations:Ek=0ifk=0∑j⩽kp(j)if1⩽k⩽n∑j=k+1-nnp(j)ifn+1⩽k⩽2n-1.Once these points have been found, we can compare the objective values{E2(z)2-E1(z)}only among these2nextreme points to find the maximum. This takes O(n) operations and the sorting of vectorαtakesnlog(n)operations. Since we have to solve this problem n times, one for each bidder, the complexity of the algorithm is O(n2log(n)). □Fig. 1demonstrates the algorithm for solving the CG problem for the case ofn=10for some fixed i. Crossed generator pointsp=(p1,p2)are generated randomly withp1following a uniform distribution in[0,1]whilep2=0.2uwith u also following a uniform distribution. These choices of these random points are only for the purpose of clearer demonstration in Fig. 1. The corresponding zonotope has 20 extreme points. The maximum of{P22-P1}is attained atE13. This meansz(j)=0, for1⩽j⩽3andz(j)=1for4⩽j⩽10.Theorem 3The LP dual problemCSPPLPDin spectrum auction can be solved in polynomial time.From Theorem 2, identifying a violating constraint for a givenycan be done in O(n2logn). This means we have an ‘oracle-polynomial time’ to solve the separation problem. Therefore,CSPPLPDcan be solved in polynomial time using the ellipsoid method (see Theorem 6.4.9 in Grotschel, Lovász, & Schrijver (1993)). □The weighted coalitional skill games (WCSG) were proposed by Bachrach and Rosenschein (2008). In this game, there are n players, T tasks and K skills. Each player has a subset of skills and each task requires a subset of skills. LetΨbe the player-skill matrix withψikindicating whether player i has skill k. LetΦbe the task-skill matrix withϕtkindicating whether task t requires skill k. The players can form groups to work collectively and a group can perform a task if the skills required are available. Specifically, for each task t and the skill vectorΦtthat it requires, a coalitionzwill be able to perform the task if, for all skill k, there exists at least one player in the coalition that has skillϕtk. Each task, if performed, returns some reward. The aim of the coalition structure generation problem in the WCSG game is to divide players into non-overlapping subgroups such that the total reward is maximised and this is equivalent to the CSPP problem. Bachrach and Rosenschein (2008) show that the problem is NP-hard except for some very restricted cases, such as with the bounded number of tasks and the bounded width of the tree that represent the skill-graph. In addition, even with these restrictions, the authors only provide a polynomial-time algorithm without any numerical result. We will apply our algorithm to find near-optimal CSPP of general WCSG games.LetΔ(z,t)be the binary indicator on whether coalitionzcan perform task t and it is defined as:Δ(z,t)=1ifΨtz⩾Φt,0otherwise.We consider a weighted average utility function defined asv(S)=∑t∈{1..T}ωtΔ(z,t). In this case, the constraint generation problemminz∈{0,1}n{zty(k)-v(z)}can be reformulated as:minz∈{0,1}nzty(k)-∑t=1TωtΔ(z,t).This is equivalent to:(11)minz,δzty(k)-∑t=1Tωtδt,(12)s.t.Ψtz⩾δtΦt,∀t∈1,…,T,z∈{0,1}n,ψt∈{0,1}m,whereΔ(z,t)has been replaced byδt. The set of constraints in (12) ensures that if the coalitionzdoes not have all the skills required inΦt, thenδtmust be equal to zero. Otherwise,δtshould be equal to one to drive the objective function to the minimum. The constraint generation problem is a mixed-integer programming problem with(n+T)binary variables and with(T∗K)constraints. Although the problem is NP-hard, we will show numerically that CPLEX can solve the game very efficiently for many instances with up to 200 players (with 20 tasks and 10 skills).We perform numerical tests on spectrum auctions with the number of frequencies ranging fromn=25ton=200. The number of bidders is set to be equal to the number of frequencies. MatrixΦis generated randomly using the Bernoulli distribution where each bidder has a 50% chance of having an interest in a frequency. The payoff vectorvand the synergy preferenceμare also generated randomly using the uniform distribution around[0,1].Table 1shows the performance of Algorithms 1–3 when the number of objects varies between 25 and 200. Columns 2–5 show statistics for solving the LP dual problem, columns 6–7 show statistics for finding upper bounds, and column 8 shows the optimality bounds. In each column, the statistics shown are obtained by taking the average overK=10random instances (using fixed random seeds between 1 and K in MATLAB for the purpose of convenient replication). By creating random instances, we can test the robustness of the algorithm when the input data vary.2All the numerical tests that appear in this manuscript are performed on a personal computer, Intel®Xeon®CPU W3520 @2.67GHz with 12GB RAM and under the Windows 7 operating system. The code was written and tested on MATLAB R2012a.2In general, there is an increasing trend with a cubic shape in the total time taken to solve the LP dual problem except for the case ofn=50.3Among 80 random instances generated, there were two outliers for the case ofn=50with random seeds numbers 4 and 5.3The total time taken to solve the LP dual is around 85min for the largest instance. The number of iterations required by the constraint generation method to solve the LP dual is relatively small compared to the problem size. Specifically, to solve the LP dual with2200constraints for the case ofn=200, it took around 3273 iterations, on average, to identify the set of relevant constraints. This means we only need to solve around 3273 constraint generation problems and the same number of small-size LPs, each withn=200columns and with the number of rows ranging between 1 and 3273. The time required to solve the constraint generation problem increases almost in a quadratic trend and this matches with the theoretical complexity of O(n2logn) as derived in Theorem 2. The time taken to find feasible packings is relatively small compared to the time required to solve the LP relaxation with, at most, 20min for the largest instance. The optimality bounds between the feasible solutions and the LP upper bounds are around 91.1%, which are reasonably good given the very large problem size. Notice that this is the guaranteed bounds taken byfsub∗/fLP∗as we have no knowledge of the optimal values. The actual optimality bounds could be higher.We also perform numerical tests on large WCSG games with the number of players n ranging from 25 to 200 while fixing the number of tasks at 20 and the number of skills at 10. For each n, we generateK=10random samples using random seeds between 1 and K. In each instance, the player-skill matrix is generated randomly using the Bernoulli distribution with a 25% chance for each player to have a skill. The task-skill matrix is also generated randomly with a 50% chance that each task requires a skill. The weighted vector is generated uniformly between[0,1].Table 2shows the same statistics as Table 1 but for finding the optimal coalition structures of the WCSG with the number of players varying between 25 and 200 (i.e. columns 2–5 show statistics for solving the LP dual problem, columns 6–7 show statistics for finding upper bounds and column 8 shows the optimality bounds). In each column, the average performance overK=10runs are recorded. There is an increasing trend in the total time taken to solve the LP dual problem (with less than 10min for the largest instance). Most of the time taken is for solving the constraint generation problems. The number of iterations to solve the LP dual is also relatively small with just over 300 iterations for the largest instances tested. The time required to find a feasible packing solution is less than 1 s and this is significantly small compared to the time taken to solve the LP dual problem. The optimality gap is around 99.5% which is quite impressive.The main aim of this manuscript is to find an approximation algorithm for solving large-scale SPP where the number of feasible subsets is very large, and hence cannot be handled by existing methods. Our method is, however, applicable to any SPP game withm≫n. To demonstrate this, we test the algorithm with randomly generated problems that appear in the CATS library developed by Leyton-Brown and Shoham (2006). The value functions used in these instances have arisen in combinatorial auctions where the underlying bids are accompanied with economical interpretations. Tables 3 and 4summarise the optimality bounds and the computational time for various random distributions shown in the first columns. Columns 2–5 show the optimality bounds for(n=100)objects while varying the number of feasible subsets between 2500 and 10000. Columns 6–7 show the same statistics but for fixed(m=5000)while varying n between 50 and 150. The rows show different distributions from the CATS library for generating random instances. For each distribution and each pair of(n,m), we generateK=10random instances. The statistics are taken from the average performance among these K instances. In general, it is interesting to see that the optimality bounds increase with the increase of m. The optimality bounds are 100%, i.e. we obtain optimal solutions, for the ‘paths’ and ‘scheduling’ distributions. The average is 99.3% for all cases. The computational time is less than 1min for the worst instance tested.

@&#INTRODUCTION@&#


@&#CONCLUSIONS@&#
