@&#MAIN-TITLE@&#
Text-to-speech synthesis system with Arabic diacritic recognition system

@&#HIGHLIGHTS@&#
We developed an Arabic text-to-speech system, including a diacritization system.The speech synthesis system is based on statistical parametric.We address the accuracy of diacritic and acoustic models.We proposed a diacritization system based on the position of the current letter.Neural network per unit type based synthesis system generates high speech quality.

@&#KEYPHRASES@&#
Text-to-speech synthesis,Statistical parametric,Deep neural networks,Natural language processing,Diacritization system,

@&#ABSTRACT@&#
Text-to-speech synthesis system has been widely studied for many languages. However, speech synthesis for Arabic language has not sufficient progresses and it is still in its first stage. Statistical parametric synthesis based on hidden Markov models was the most commonly applied approach for Arabic language. Recently, synthesized speech quality based on deep neural networks was found as intelligible as human voice. This paper describes a Text-To-Speech (TTS) synthesis system for modern standard Arabic language based on statistical parametric approach and Mel-cepstral coefficients. Deep neural networks achieved state-of-the-art performance in a wide range of tasks, including speech synthesis. Our TTS system includes a diacritization system which is very important for Arabic TTS application. Our diacritization system is also based on deep neural networks. In addition to the use deep techniques, different methods were also proposed to model the acoustic parameters in order to address the problem of acoustic models accuracy. They are based on linguistic and acoustic characteristics (e.g. letter position based diacritization system, unit types based synthesis system, diacritic marks based synthesis system) and based on deep learning techniques (stacked generalization techniques). Experimental results show that our diacritization system can generate a diacritized text with high accuracy. As regards the speech synthesis system, the experimental results and subjective evaluation show that our proposed method for synthesis system can generate intelligible and natural speech.

@&#INTRODUCTION@&#
Text-To-Speech (TTS) system is one of the most important technologies due to the expanding field of applications, such as: multimedia, telecommunication and aids for handicaps. People that speak Arabic as their native language are more than 442 million around the world. Five million Arabic people are blind around the world (Zaki et al., 2010). Hence, Arabic TTS with intelligible and natural speech quality is required. However, the field of speech synthesis for Arabic language has not sufficient progresses and it is still in its first stage. This could be explained by the fact that:•One of the problems facing computer processing of the Arabic text is the absence of the diacritic marks in the modern text (Elshafei et al., 2006). These marks are used to identify the right pronunciation of the text.It is difficult to obtain an Arabic speech database for speech synthesis task. The solution consists of developing a specific speech database (Chouireb and Guerti, 2008; Hamad and Hussain, 2011).Linguistic researches for Arabic language are limited.Speech synthesis system is the process of generation of speech, as output, from text, as input. The two popular approaches are concatenative speech synthesis (known as corpus-based approach) (Hunt and Black, 1996) and statistical parametric speech synthesis (called also knowledge-based approach) (Black et al., 2007). In the first approach, desired speech is produced by selecting and concatenating required segments from pre-recorded speech by human. Many systems use a corpus of fixed length units, typically phonemes or diphones. Other concatenative systems use more varied, non-uniform units speech segments database. For instance, in (Hamad and Hussain, 2011), the authors developed an Arabic TTS based on allophone and diphone concatenation method. This variety of speech segments allows the generation of more natural speech. The highest speech quality is generated based on unit selection (Hunt and Black, 1996; Clark et al., 2007). The basic concept of this method consists of concatenating speech segments without modification. It uses a large database, including units in different phonetic and prosodic contexts. However, large speech database requires a huge memory storage. Furthermore, to have different voice styles and emotions, another speech database is required for such style or emotion which increases the required storage capacity (Zen et al., 2009). These issues make corpus-based synthesis systems not suitable for devices with limited resources.In direct contrast to the concatenation of pre-recorded speech units approach, Statistical Parametric speech Synthesis (SPS) approach consists of converting a set of parametric representations to speech waveform. During the recent years, SPS approach has been growing fast in popularity and the generated speech quality has been found to be as intelligible as human voice (Zen et al., 2009, 2013; Tokuda et al., 2013; Ekpenyong et al., 2014). In such SPS system, pre-recorded speech database is replaced by a set of generative models (e.g. neural networks, hidden Markov models). These techniques are used to model the acoustic parameters (spectral and excitation parameters) extracted from a speech database. Subsequently, the target speech waveform is reproduced from the appropriate speech parameters through a source-filter model. The main advantages of the SPS approach over the concatenative approach are the small memory footprint and the flexibility of voice characteristics’ modification (e.g. style, emotions) (Nose et al., 2005, 2007; Barra-Chicote et al., 2010).Statistical parametric synthesis systems are composed of two parts: training part (generative model is used to create models that map the linguistic features into acoustic parameters) and synthesis part (reconstruct the speech waveform from the predicted parametric representations using a vocoder, e.g. MLSA-based vocoder: Mel Log Spectrum Approximation (Imai et al., 1983)). Since the last decade, Hidden Markov Models (HMMs) have been widely used in speech synthesis for many languages (Qian et al., 2006; Abdel-Hamid et al., 2006; Fares et al., 2008; Bahaadini et al., 2011; Phan et al., 2013). These models fall within the category of shallow architectures which are based on a single hidden layer of non linear transformation. In the last few years, deep learning has emerged as a new area of machine learning research (Deng and Yu, 2014). Deep learning techniques are impacting a wide range of signal and image processing applications. For instance, deep learning using neural network achieved high performance in many tasks, including speech processing (speech recognition and synthesis) (Martin et al., 2013) and computer vision (Ciresan et al., 2010). Opposed to shallow techniques, deep architectures are based on many layers of non-linear transformations. With the fast development of hardware and software, it became possible to use neural networks with complex architecture (multiple hidden layers) and to train the network with massive data (Ciresan et al., 2010; Deng and Yu, 2014).The aim of this work is to develop and evaluate a TTS system based on statistical parametric approach. This system is dedicated to Arabic language and takes into account the specificities of this particular language. An automatic restoration of Arabic diacritics system is proposed to solve the problem of missing of diacritic marks. The speech database used in this work is composed of non-uniform unit segments. This choice aims at improving the speech quality. In (Zen et al., 2013), the authors mention three factors that impact directly the speech quality, which are: vocoding, accuracy of acoustic models, and over-smoothing. In this paper, we address the accuracy of diacritization and acoustic models. We propose to use deep neural networks. It was shown that this networks outperform the traditional HMM-based synthesis system (Zen et al., 2013). Moreover, we develop the diacritization system based on deep learning techniques which were not applied to the task of diacritics recognition. Along with the use of deep architecture, different methods are proposed in order to increase the accuracy of diacritization and acoustic models.This paper is organized as follows. Arabic language's characteristics are discussed in Section 2. Section 3 gives an overview of the text-to-speech framework. The proposed diacritization system is detailed in Section 4. Section 5 describes the deep neural network based speech synthesis. Evaluation results of the TTS system are presented in Section 6. Conclusion and future work are presented in Section 7.The phonetic system of Modern Standard Arabic has 34 phonemes: 26 consonants, 3 short vowels (Fatha, Dhamma, Kasra), 3 long vowels (,,) and 2 semivowels (,) depending on the context which they appear in the word. Arabic writing system consists of 36 letters representing the consonants. Each letter represents a single consonant with some exceptions (some consonants are written in different forms depending on their position in the word, e.g.,). Arabic diacritical signs are the vowelization marks (Sukun, Fatha, Dhamma, Kasra), the gemination mark (shadda) and the suffixes, known as tanween signs (an, on, in). Sukun mark is usually not written because a consonant without a vowel is considered with sukun. The International Phonetic Alphabet (IPA) classifies the Arabic consonant according to the place and manner of articulation. Table 1shows Arabic consonants based on the IPA classification.Arabic syllables are a number of six which are: CV, CVV, CVC, CVCC, CVVC and CVVCC, where C stands for consonant and V stands for vowel. CV is the frequent syllable, whereas CVVCC is very rare. There is two kinds of syllables: open syllables which finish with vowel (e.g. CV) and closed syllables that finish with consonant (e.g. CVC). Every syllable begins with a consonant followed by a vowel (short or long vowel). The vowel is the nucleus of the syllable. Arabic words contain one or more syllables. The syllables in a word are pronounced with different stress levels. The Arabic studies in prosody defines three lexical stress levels for each syllable in a word: primary stress (PS), secondary stress (SS) and weak or unstressed level (US). The identification of the syllable stress levels in an Arabic word depends on a set of rules which are as follows (Chouireb and Guerti, 2008; Zaki et al., 2010):•If the word is composed of only CV syllables, the first syllable gets the primary stress and the remaining syllables receive unstressed level. For instance,in English “he went” has these lexical stresses:(CV → PS)(CV → US)(CV → US).If the word contains only one long syllable, the long syllable receives the primary stress and the rest of syllables are unstressed. Example,(“sleep”):(CVV → PS)(CV → US).If the word contains two or more long syllables, the long syllable nearest to the end of the word receives the primary stress, the long syllable nearest to the beginning gets the secondary stress and the remaining syllables are unstressed. Example, the word(“their writings”):(CV → US)(CVV → SS)(CVV → PS)(CV → US)(CVC → US).In Arabic, the last syllable in a word never gets a primary or secondary stress, it is always unstressed. The monosyllabic prepositions receive a secondary stress instead of a primary stress.Arabic language is a diacritized language whose alphabet contains only consonants and the diacritic marks are added to specify the pronunciation of the text. Unfortunately, modern Arabic text, books, journals, and internet documents are written without mentioning these marks (Attia, 2005; Badrashiny, 2009; Hamad and Hussain, 2011). Table 2gives the statistics of the occurrence of the Arabic word “” with different diacritics. Based on similar results of other Arabic words, undiacritized Arabic words existing on the internet nowadays are more than 90%.The readers restore the missing diacritic marks based on their knowledge of the language and the context while reading an undiacritized text. In case of a severe ambiguity, the writer puts the diacritics to overcome any problem. However, automatic processing of Arabic text is often hampered by the lack of diacritic signs. For instance, an Arabic TTS would not generate speech from undiacritized text because there are different pronunciations of the same undiacritized word. For instance, the word, when diacritized, could be:(science),(flag) and(he taught). Moreover, the process of syllabification of the input text cannot be performed without diacritic marks. Many Arabic diacritization systems were developed and different methods were proposed. There are few known commercial systems (RDI,11Research & Development International (RDI): http://www.rdi-eg.com.Sakher,22Sakhr: http://www.sakhr.com.Cimos33Cimos: http://www.cimos.com.) whose source code is not available. They are generally used as black boxes in context specific applications. Other non-commercialized systems were developed by researchers using personalized methods. There are three major family of techniques: dictionary method, rule-based method and machine learning method.The first technique is based on the standard Arabic dictionaries. It consists of building a large database of Arabic vocabulary. For each undiacritized word, the system searches the words with the same spelling. Then, a disambiguation phase is performed in order to choose the right diacritized word. Sakher system is based on this method. Although this technique has the advantage of being accurate, it is costly in terms of database collection (difficult to collect all Arabic vocabulary), search process (high access time in the search process) and memory storage capacity (Badrashiny, 2009). Moreover, it has a coverage problem: the largest dictionary may not have some morphologically possible vocabularies (e.g. non used words in some Arabic countries can be used in other countries).Unlike dictionary method, rule-based diacritization systems have the advantage of not being attached to a fixed vocabulary. It applies a complex combination of morphological, syntactic and semantic rules. The morphological analyzer decomposes the undiacritized word into its morphological entities using known patterns or templates. These morphological entities are represented by the quadruple Q = (t: p, r, f, s), where: t is the class of the word (regular derivative, irregular derivative, fixed, or arabized), p is prefix, r is root, f is form and s signifies the suffix. Syntactic rules are then used to determine the case-ending diacritics. Semantic rules help to resolve ambiguous cases. RDI system is developed using this technique. The main drawbacks of this method are the high complexity and the long-timed processing of a given Arabic sentence (Badrashiny, 2009).The third method consists of using machine learning techniques (e.g. HMM, neural networks) to generalize knowledge extracted from a diacritized text to new situations. A generative model is used to model the diacritic marks extracted from a full diacritzed text. Afterward, the system predicts the diacritic marks of the undiacritized text based on the created model. This approach has many advantages over the above-mentioned ones, such as small memory footprint and short time for processing a sentence. HMM is the most common machine learning technique (Elshafei et al., 2006; Khorsheed, 2012).Our aim is to build an automatic diacritization system with small memory footprint, low computational cost and high efficiency. Thus, we propose a diacritization system based on DNN.The overview of the Deep Neural Networks (DNN) based system for Arabic TTS is shown in Fig. 1. Our complete TTS system is composed of two sub-systems. The first one is a diacritization system which is designed to restore the missing diacritic marks of the Arabic text. The second one is a speech synthesis system that transforms the resulting text into speech waveform.The diacritization system is composed of three parts: text-to-linguistic engine (including preprocessing phase, segmentation of the text and input feature extraction module), DNN model to recognize the diacritic mark of each input vector and the diacritization module. The preprocessing phase is very important. In fact, the text is analyzed in order to remove all signs of ambiguity that degrades the performance of the diacritizer system. Therefore the performance of the synthesizer is reduced. The resulting text, a full diacritized Arabic text, which is, then, the input of the second system to generate speech waveform.The speech synthesis system consists of: a phonetic transcription engine, linguistic features extraction module, duration DNN used to predict the duration and the temporal trajectory of each acoustic unit, another three DNNs used to transform the input features into prosodic and spectral parameter vectors (fundamental frequency (F0), energy and Mel-cepstral coefficients) and finally MLSA vocoder (Imai et al., 1983).The diacritization system is developed in order to provide the missing diacritic signs. It is based on DNN. Our algorithm generates diacritized text with determining the final diacritic mark of the word. First, a set of preprocessing steps needs to be fulfilled:•Preprocessing on non lexical elements: transform any non orthographic sign by its meaning in Arabic words. The text analyzer examines all the text and expands digital and numerals into full Arabic words (e.g. numerals, dates, abbreviations, symbols, etc.).Removing any character other than Arabic letters and punctuation.For training and testing purpose, we used a fully diacritized Arabic corpus. The corpus was collected from different Arabic books and articles covering various subjects. Besides, the text corpus was manually checked by Arabic language specialist to correct partially diacritized words. The total number of words in our corpus is 25k words. The corpus was divided in three sets as follows: training set (80%), development set (10%) and test set (10%).To diacritize the Arabic text, our diacritization system is expected to recognize all the Arabic diacritical signs: the vowelization marks (Sukun, Fatha, Dhamma, Kasra), the gemination mark (shadda) and the tanween signs (an, on, in). Two neural networks were used to model them. The first neural network was used to predict seven diacritic marks: the four vowelization marks and the three tanween signs. Six parameters were selected to perform this task with high performance. The input parameters could be grouped into two categories: specific parameters related to the current letter (e.g. current letter orthography, letter position in the word) and contextual parameters (adjacent letters orthography). Table 3presents the input parameters used to predict the diacritic marks.The number n of adjacent letters was determined by testing different levels of adjacent in order to select the optimal number. Multiple neural networks were trained and tested for each adjacent level: multiple hidden layers with different hidden units per layer. The neural networks were trained for 200 iterations. Diacritization evaluation of our experiments is reported in terms of Diacritization Error Rate (DER). To recognize the diacritic mark generated by the DNN, we used the Arg max function which stands for the argument of the maximum. The predicted classiˆwould be:(1)iˆ=argmaxiaiFig. 2gives the DER values relative to each neural network for each adjacent level (3-adjacent, 4-adjacent and 5-adjacent).It can be seen that almost all the experimental results of the diacritization system based on four adjacent letters was better than those obtained by three and five adjacent letters. Thus, training data based on four adjacent letters features was used for further experiments.The second neural network was used to recognize the gemination mark shadda. This network was trained using the same input parameters in Table 3 with the exception of the parameter sign shadda which was used as output parameter rather than input parameter. The process of selection of the number n was performed and 4-adjacent letters gave the best results.Table 4gives an example of coding the input and output parameters used in the diacritization system of the letter “” of the word “” (“thanks”) with one left and right adjacent.

@&#CONCLUSIONS@&#
