@&#MAIN-TITLE@&#
Comparison of evolutionary and swarm based computational techniques for multilevel color image thresholding

@&#HIGHLIGHTS@&#
Multilevel image thresholding by using evolutionary algorithms has been investigated.Algorithms used in the study are Evolution Strategy (ES), Genetic Algorithm (GA), Differential Evolution (DE), Adaptive Differential Evolution (JADE), Particle Swarm Optimization (PSO), Artificial Bee Colony (ABC), Cuckoo Search (CS) and Differential Search Algorithm (DS).The Artificial Bee Colony Algorithm and Differential Search Algorithm are the most robust algorithms.Differential Search Algorithm is the most effective algorithm in terms of CPU running times.

@&#KEYPHRASES@&#
Color image thresholding,Evolutionary optimization algorithms,Swarm-based optimization algorithms,

@&#ABSTRACT@&#
This paper introduces the comparison of evolutionary and swarm-based optimization algorithms for multilevel color image thresholding problem which is a process used for segmentation of an image into different regions. Thresholding has various applications such as video image compression, geovideo and document processing, particle counting, and object recognition. Evolutionary and swarm-based computation techniques are widely used to reduce the computational complexity of the multilevel thresholding problem. In this study, well-known evolutionary algorithms such as Evolution Strategy, Genetic Algorithm, Differential Evolution, Adaptive Differential Evolution and swarm-based algorithms such as Particle Swarm Optimization, Artificial Bee Colony, Cuckoo Search and Differential Search Algorithm have been used for solving multilevel thresholding problem. Kapur's entropy is used as the fitness function to be maximized. Experiments are conducted on 20 different test images to compare the algorithms in terms of quality, running CPU times and compression ratios. According to the statistical analysis of objective values, swarm based algorithms are more accurate and robust than evolutionary algorithms in general. However, experimental results exposed that evolutionary algorithms are faster than swarm based algorithms in terms of CPU running times.

@&#INTRODUCTION@&#
Image thresholding is an important fundamental process for image analysis and interpretation, and generally used to distinguish the objects in a scene from the background; the image is separated into different regions using one or more threshold values. Distinguishing the objects in an image from the background by determining a single threshold value is called bilevel thresholding [1], while separating the image into numerous different regions regarding with their colors by setting multiple threshold values is known as multilevel color image thresholding [2]. Popular applications for image thresholding are video and image compression [3–5], geovideo and document processing [6], particle counting [7,8] and object recognition [9,10].It is possible to determine the optimum threshold in an image by analyzing the image histogram characteristics or by optimizing an objective function [11]. The methods based on optimizing the objective function are carried out through methods such as maximization of the entropy (e.g., Kapur's entropy) [12], maximization of the between-class variance (e.g., Otsu's method) [13], the use of the fuzzy similarity measure [14], and minimization of the Bayesian error [15]. All these techniques were developed originally for the bilevel image thresholding, and then extended to cover the multilevel thresholding. The common problem in using these methods for multilevel thresholding, however, is the exponential increase of the calculation complexity [16]. Therefore, mostly the evolutionary and swarm-based calculation techniques are preferred to solve the multilevel thresholding problem.In determination of the optimum thresholds, the Otsu method and the Kapur's entropy method are the most preferred methods. The Otsu method [13] relies on the discriminant analysis to maximize the separability level of the classes in the gray level image [17]. The Kapur's entropy method, on the other hand, is based the probability distribution of the gray level histogram, and maximizes the entropy. Although numerous methods based on entropy maximization [12,18–20] and entropy minimization [21–23] are suggested to determine the optimum thresholds, Kapur's entropy method has outperformed the other methods on the test images [24]. Therefore, the Kapur's maximum entropy method is selected as the objective function in this study. Furthermore, the entropy tells us the information content of an image. In other words, it indicates the minimum amount of information that must be compressed using a compression method. The compression rate of the images with low entropy is high compared with the images with high entropy. This is achieved by setting the optimum thresholds though maximization of the Kapur's entropy value of each segment in the original image.The evolutionary and swarm-based computing techniques stand out for their ability of avoiding the local minimum. The use of these algorithms has become widespread as they can generate high-quality solutions for difficult problems and generate solutions in acceptable periods thanks to easy adaptation to discrete optimization problems [25]. Considering its advantages, these algorithms are preferred in finding the optimum thresholds for gray level images. For example, the Genetic Algorithm (GA) has been used for many times to solve the multilevel thresholding problem [2,26,27]. Malyszko et al. [28] developed an evolutionary algorithm for rough multilevel thresholding. Rather successful results were obtained using the Differential Evolution Algorithm (DE) [29,30]. Additionally, there are efforts to solve the multilevel thresholding problem with the swarm-based Particle Swarm Optimization (PSO) [31,32], Artificial Bee Colony (ABC) [31,33], Bacterial Foraging (BF) [11,34], Cuckoo Search (CS) [35], Firefly Algorithm (FA) [36], and Honey Bee Mating (HBM) [37] algorithms. Besides, there are also benchmarking studies assessing the successes of the optimization algorithms in solving the multilevel thresholding problem for gray level images [25,38].In this study, well-known evolutionary and swarm-based optimization algorithms are compared while solving the multilevel color image thresholding problem. As the objective function, the Kapur's maximum entropy method is used. Evolutionary algorithms used in the study are Evolution Strategy (ES), Genetic Algorithm (GA), Differential Evolution (DE) and Adaptive Differential Evolution (JADE). In addition to these algorithms, swarm-based algorithms used in the study are Particle Swarm Optimization (PSO), Artificial Bee Colony (ABC), Cuckoo Search (CS) and Differential Search Algorithm (DS).The rest of the paper has been organized as follows: the next section is about the Evolutionary Optimization Algorithms. The subsequent sections are about the Swarm-based Optimization Algorithms, Problem Statement, Experiments, Evaluation of the Experimental Results. The final section gives the Conclusions.Evolutionary optimization algorithms are population based meta-heuristics and build on generation-updating and thus natural selection. In this section evolutionary algorithms employed in this paper, ES, GA, DE and JADE, have been introduced briefly.ES is an optimization algorithm for multimodal, non-differentiable and complex functions. The most well-known type of ES is the (μ+λ)-ES in which μ parents can participate in the reproduction of λ offspring. Afterwards, the obtained μ+λ individuals will be reduced to μ individuals of the next generation by selection. Detailed explanation can be found in [39].GA is an optimization technique used in several research areas to find exact/approximate solutions to the problems. Inheritance, mutation, selection and crossover are the main operators of GA that inspired from evolutionary biology. Population refers to the candidate solutions of the problem. The evolution starts from a randomly generated initial population. For all generations, the fitness (quality) of every individual in the population is evaluated and the genetic operators are applied to obtain a new better population. GA stops evolution when either a maximum number of generations have been reached, or a predefined fitness value has been achieved [45].The DE is a population-based, heuristic algorithm developed for minimization of the real-valued functions. The mutation process applied depending on the difference between the randomly selected vectors improves the performance of the algorithm, allows searching new research regions, and makes the algorithm more stable. In addition to this feature, the DE also has features such as fastness, simplicity, user-friendliness, global optimum convergence ability, parallelism, low calculation cost, easy adaptability to discrete and complex parameter optimization, no need for derivation processes, and usability for noisy and time-dependent objective functions [40]. The literature contains numerous different mutation/recombination strategies for deterministic DE. In this study, the rather frequently preferred DE version (i.e., DE/rand/1/bin) has been used. In the DE/rand/1/bin, F is the scaling factor between [0,1] and Cr is the crossover ratio between [0,1]. Each new vector generated in DE/rand/1/bin is first assessed through the objective function, and then, its cost is compared with the cost of its parent. If the new vector has an equal or lower cost, the new vector replaces the parent vector in the population. Otherwise, the parent vector is not replaced by the new vector, but instead kept in the population. After the members of the next generation have been selected by this selection process, the evolution cycle is repeated until either the problem is solved or all vectors converge to a certain point [29,30,40,41].JADE algorithm includes a new mutation strategy (i.e., DE/current-to-pbest) to use with standard DE[46]. This strategy enforces a randomly selected individual to evolve providing the best solution in the population at that moment. In JADE, mutation coefficient is produced with F∼N (μc,0.1) and crossover coefficient with CR ∼ Cauchy(μF,0.1). Here N (μc,0.1) is a normal distribution function with the average value of μc and standard deviation value of 0.1 and Cauchy(μF, 0.1) is a cauchy distribution function with local parameter value of μFand scale parameter value of 0.1. JADE algorithm solves real-valued optimization problems much more successfully than the standard DE algorithm. Problem-solving success of JADE algorithm has been studied by Zhang and Sanderson in detail[46].Swarm-based optimization algorithms use position-updating for global search. In this section PSO, ABC, CS and DS, swarm-based optimization algorithms used in the experiments, have been introduced briefly.PSO algorithm is inspired from the movements of the swarms of living beings moving as a superorganism (e.g. fishes swimming together, birds flying together) [47]. In PSO, each solution to be solved corresponds to an artificial particle moving together in the search space. The particles used in PSO algorithm benefit from their own individual experience and social experience of the swarm. This behavior simulates communication among the living beings moving as a superorganism. There are several PSO structures in the literature and more successful than standard-PSO structure[48].ABC is a swarm-based algorithm proposed for solving the numerical real-valued optimization problems[50,51]. In the ABC algorithm, it is assumed that a solution for a problem corresponds to a food source and the global minimizer of the problem that is searched by the artificial-bees, assumedly flying to find nectars in the region. The search process used in the ABC is consisted of two steps: Employed-Bee and Scout-Bee. ABC is intended to search more the regions providing better solution in the search space of the problem and this behavior allows the ABC to effectively search the space. The artificial-bees are supposed to the search the space nearest to them. If a food source is not sufficiently rich, it is abandoned after a certain trial and a new food source, randomly produced, is added to the population instead of that solution. The control parameters of the ABC algorithm are limit value and number of employed-bees [50,51]. Mutation strategy used in the ABC algorithm is similar to the DE algorithm. The success of the ABC has been studied [50–52] in detail.Cuckoo Algorithm is a population based elitist search algorithm [53]. In CS, every new solution tries to search around the best solution obtained beforehand. CS is structurally very similar to DE. However, in general, it has a better problem solving success than DE. CS has two control parameters. The structure and problem solving effectiveness of CS have been examined in detail in [52,53].DS is an artificial swarm algorithm developed by Çiviciolu to be used in solving the numerical optimization problems [41]. Four strategy have been defined for standard DS; Bijective DS (B-DS), Surjective DS (S-DS), Elitist-DS (E-DS) and Hybrid DS(H-DS) [42]. In generally, the problem solving success of B-DS and S-DS are better than others. In this paper B-DS strategy have been used for DS. DS able to use some stable distributions for generation of scale factor [42]. This gives it to quasi simulation ability of some stable-walk models such as Le`vy-Walk and Brownian-Walk. Le`vy-Walk and Brownian-Walk models have been intensively used to generate analytically models of migration of some superorganisms [41].In DS, a population composed of the random solutions of the relevant problem represents a migrating artificial superorganism. B-DS does not tend to progress toward the best solution of the problem. Therefore, it has a quite successful search algorithm in solving the multimodal functions. DS has only two control parameter. Detailed tests have been made to find out the optimum value for p1 and p2, and it has been seen that p1=0.30·rand ve p2=0.30·rand values provide the best solutions for all test problems used in this study. B-DS is not oversensitive to the initial values of p1 and p2, and its algorithmic structure is rather simple. This ensures that DS can be applied to different engineering problems easily.In the multilevel thresholding problem, it is aimed to determine the optimum threshold values so that the segmented classes can meet the desired features. Let the image I for the thresholding process has N pixels and L units of gray levels. It is wanted to separate these L units of gray levels into (C1, C2, …, Ck) units of classes using the thresholds of (t1, t2, …, tk)|t1<t2<…<tk.For RGB images there are three color channels (red, green and blue, respectively) instead of only one intensity channel for the gray level images. Here, in order to find out the k units of thresholds, it is necessary to optimize an objective function just like the one in the Eq. (1).(1)T=t1c,t1c,…,tkc=argmaxFTwhere(2)c=1,2,3If image is RGB1If image is GrayAlthough there are numerous objective functions in the literature, Kapur's method based on maximum entropy yields successful results in solving the thresholding problem. Therefore, Kapur's entropy criterion is used as the objective function in this study, and the optimum thresholds have been obtained through maximization of this function that uses the threshold values as parameter. When the threshold values separating the classes are determined accurately, the entropy value is the maximum. Therefore, it is required to determine the thresholds that give the maximum entropy value.For the given image I, the normalized histogram is defined as in the Eq. (3):(3)Pic=hciN|0≤i≤L−1wherehciis the number of the pixels in the image which have the L gray level, c is the component of the image which depends if the image is gray level or RGB, while N is the total number of pixels in the image. For the multilevel thresholding, the Kapur's entropy can be calculated using the Eq. (4).(4)argmaxft1c,t1c,…,tkc=H0c+H1c+H2c+⋯+Hkcwhere(5)ω0c=∑i=0t1−1PicH0c=−∑i=0t1−1Picω0clnPicω0cω1c=∑i=t1t2−1PicH1c=−∑i=t1t2−1Picω1clnPicω1c⋮ωkc=∑i=tkLPicHkc=−∑i=tkLPicωkclnPicωkcIn the Eq. (1),t1c,t1c,…,tkcindicates the k units of threshold values. The calculation of the k units of optimum threshold values can be handled as a k-dimensional optimization problem for gray level images and 3k-dimensional problem for RGB images. The optimum threshold values are acquired by maximizing the Eq. (1). In this study, it is aimed to calculate the k units of optimum threshold values by maximizing the entropy value through the evolutionary and swarm based optimization algorithms for true color RGB images. The overall process of the optimal multilevel color image thresholding problem is demonstrated in Fig. 1.

@&#CONCLUSIONS@&#
In this study, the performances of the evolutionary and swarm-based algorithms used intensively in the multilevel color image thresholding problem that is an important process for many image processing applications like image and video compression, document processing, particle counting, object recognition have been examined in detail. The obtained results can be summarized as follows:•Four methods based on evolutionary algorithms called Evolution Strategies, Genetic Algorithms, Differential Evolution and Adaptive Differential Evolution and four methods based on swarm-based algorithms called Particle Swarm Optimization, Artifical Bee Colony, Cuckoo Search and Differential Search have been evaluated in terms of solution of the multilevel color image thresholding problem.These eight methods have been subjected to detailed comparisons using 20 different true color RGB test images.Although all of the eight meta-heuristic algorithms have statistically similar results for practical applications, the algorithms are sorted as ABC, DS, JADE, CS, GA, ES, PSO and DE in terms of robustness in descending order.When the algorithms are sorted from good to bad in terms of the running time, it is seen that they are sorted in the order of DS, DE, GA, ABC, JADE, ES, PSO, CS. However, in 65% of the experiments evolutionary algorithms are faster than swarm based algorithms.When algorithms are evaluated in terms of their compression performances, it is seen that all methods yield similar results.While it has been seen that the file sizes have been reduced by 82.95% on average when the threshold number is determined as 8.