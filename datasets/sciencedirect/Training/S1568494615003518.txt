@&#MAIN-TITLE@&#
A human learning optimization algorithm and its application to multi-dimensional knapsack problems

@&#HIGHLIGHTS@&#
A novel meta-heuristic named human learning optimization (HLO) is presented.Four learning operators inspired by the human learning process are developed.HLO is applied to solve multi-dimensional knapsack problems.The experimental results show that HLO is a promising optimization tool.

@&#KEYPHRASES@&#
Human learning optimization,Meta-heuristic,Multi-dimensional knapsack problem,Global optimization,

@&#ABSTRACT@&#
Inspired by human learning mechanisms, a novel meta-heuristic algorithm named human learning optimization (HLO) is presented in this paper in which the individual learning operator, social learning operator, random exploration learning operator and re-learning operator are developed to generate new solutions and search for the optima by mimicking the human learning process. Then HLO is applied to solve the well-known 5.100 and 10.100 multi-dimensional knapsack problems from the OR-library and the performance of HLO is compared with that of other meta-heuristics collected from the recent literature. The experimental results show that the presented HLO achieves the best performance in comparison with other meta-heuristics, which demonstrates that HLO is a promising optimization tool.

@&#INTRODUCTION@&#
Optimization problems are wide-ranging and plentiful in our daily life, and therefore methods for solving these problems have been a widely researched topic [1,2]. Traditional gradient-based algorithms like the steepest descent method and the Newton method have been used to solve various optimization problems successfully. However, these approaches heavily rely on the initial starting point, the topology of the feasible region and the surface associated with objective functions [3]. Inspired by physical and biological systems, various meta-heuristics have been developed to deal with complex optimization problems. For instance, genetic algorithms [4] mimic the evolution of living organisms with genetic operators such as the reproduction, crossover and mutation. Simulated annealing [5] resembles the cooling process of molten metals through annealing. Ant Colony Optimization (ACO) [6] takes inspiration from the foraging and path making behaviors of ants. Particle swarm optimization (PSO) [7] copies the behaviors of birds searching for food in a collaborative way. Artificial fish-swarm algorithm [8] imitates the fish-swarm behaviors like the praying behavior, swarming behavior and chasing behavior. Immune algorithm [9] emulates the defense process of the immune system against its invaders in a biological body. Bees Swarm Optimization [10] models the behaviors of honey bees collecting, processing and advertising of nectars. Compared with traditional gradient-based algorithms, these nature-inspired algorithms can tackle NP-hard problems more effectively and efficiently with the advantages of broad applicability, flexibility and ease of implementation. Therefore, meta-heuristic design has been drawing increasing attention from researchers, and novels algorithms have been presented in the latest decade such as the biogeography-based optimization algorithm [11], harmony search (HS) [12], the hunting search algorithm [13], the chemical reaction optimization algorithm [14] and the gravity algorithm [15]. However, most of these algorithms are originally designed to solve the continuous or discrete problems which cannot be directly applied to binary-coding problems such as feature selection and knapsack problems, and therefore various binary variants like the discrete binary PSO algorithms [16,17], discrete binary differential evolution algorithms [18–20], binary HS [21,22] and binary gravitational search algorithm [23] are proposed to extend the applications of algorithms.Compared with real-coded or discrete-coded optimization algorithms, only a few binary-coded algorithms have been proposed in recent years while more and more complicated binary-coding problems arise. On the other hand, for many engineering problems with low precision like the design of controllers [24], binary-coding algorithms may perform better than real-coded algorithms in terms of search accuracy and the convergence speed as infinite search space is mapped into finite solution space. In addition, binary algorithms can be easily used to solve hybrid-coded problems in which real variables, discrete variables and binary variables are included, which is an advantage for engineering applications. Thus, it is essential to develop efficient and effective binary-coded optimization tools. Inspired by human learning mechanisms, a new meta-heuristic algorithm called human learning optimization (HLO) algorithm is presented and applied to multi-dimensional knapsack problems in this work.The rest of the paper is organized as follows. Section 2 introduces the presented HLO in detail. In Section 3, HLO is applied to multi-dimensional knapsack problems and the results are compared with those of other meta-heuristics collected from recent works to validate its performance. Finally, Section 4 concludes the paper and explains our future work.In nature, human learning is an iterative optimization process. People master and improve their skills by learning repeatedly on some complicated tasks and activities such as playing basketball and learning dancing, which is similar to meta-heuristics searching for the global optima iteratively. There are various theories of learning such as individual learning theories, social learning theories and cognitive learning theories. Meanwhile, many factors like the emotional factor and the social factor affect the learning process. The process of human learning is extremely complicated and its study is the part of neuropsychology, educational psychology, learning theory and pedagogy. However, the HLO presented in this paper is built on a simple learning model for easy implementation and four learning operators named the individual learning operator, social learning operator, random exploration learning operator and re-learning operator are designed to search for the optima which imitate the mechanisms commonly existing in the learning process of humans. For instance, a person learns playing basketball through self-practicing (individual learning) and from his or her coach (social learning). During the learning process, he or she may try new strategies to improve his or her skill further which are characterized by randomness due to the absence of prior-knowledge (random exploration learning) and re-learns with new approaches (re-learning) when he or she hits and cannot pass the bottleneck of learning.HLO adopts the binary-coding framework in which each bit corresponds to a basic component of knowledge for solving problems. Therefore, an individual, i.e. a candidate solution, is represented by a binary string as Eq. (1) which is initialized as “0” or “1” randomly assuming that there is no prior-knowledge of problems,(1)xi=xi1xi2⋯xij⋯xiM,1≤i≤N,1≤j≤Mwhere xiis the ith individual, N is the number of individuals of the population, and M is the number of components contained in the knowledge, i.e. the dimension of solutions. After initializing all the individuals, the initial population of HLO is generated as Eq. (2).(2)X=x1x2⋮xi⋮xN=x11x12⋯x1j⋯x1Mx21x22⋯x2j⋯x2M⋮⋮⋮⋮xi1⋮xN1xi2⋮xN2⋯⋯xij⋮xNj⋯⋯xiM⋮xNMxij∈0,1,1≤i≤N,1≤j≤MEvery person learns in conscious or unconscious states, which is a fundamental requirement of existence. Individual learning is defined as the ability to build knowledge through individual reflection about external stimuli and sources. In HLO, an individual learns to solve problems by the individual learning operator based on its own experience which is stored in the Individual Knowledge Database (IKD) as Eqs. (3) and (4).(3)xij=ikipj(4)IKDi=ikdi1ikdi2⋮ikdip⋮ikdiG=iki11iki12⋯iki1j⋯iki1Miki21iki22⋯iki2j⋯iki2M⋮⋮⋮⋮ikip1⋮ikiG1ikip2⋮ikiG2⋯⋯ikipj⋮ikiGj⋯⋯ikipM⋮ikiGM1≤i≤N,1≤p≤G,1≤j≤Mwhere IKDiis the individual knowledge database of person i, G denotes the size of the IKDs, ikdipstands for the pth best solution of person i, and p, a random integer, determines which individual in the IKD is adopted for individual learning.Social learning is a transmission of knowledge and skills through direct or indirect interactions among individuals. In the social context, people can learn from not only their own direct experience but also the experience of the other members, and therefore they can develop further their abilities and achieve the higher efficiency with an effective knowledge sharing. To possess the efficient search ability, the social learning mechanism is mimicked in HLO. Like human learning, each individual of HLO studies the social knowledge stored in the Social Knowledge Database (SKD) with some probability as Eqs. (5) and (6) when it yields a new solution,(5)xij=skqj(6)SKD=skd1skd2⋮skdq⋮skdH=sk11sk12⋯sk1j⋯sk1Msk21sk22⋯sk2j⋯sk2M⋮⋮⋮⋮skq1⋮skH1skq2⋮skH2⋯⋯skqj⋮skHj⋯⋯skqM⋮skHM1≤q≤H,1≤j≤Mwhere H is the size of the SKD and skdqrepresents the qth social knowledge in the SKD, that is, the new generated candidate xirandomly chooses one of best solutions stored in the SKD and copies the corresponding bit.Anyway, people cannot always reproduce their own experience or social knowledge perfectly during the learning process due to various factors such as the disturbance and forgetting, and consequently a random learning is acted. Moreover, human also keeps trying various new strategies to improve performance. And as usually there is no prior knowledge for a new problem, this exploration procedure is characterized by randomness. Simulating these phenomena, HLO performs the random exploration learning with some probability as Eq. (7)(7)xij=RE(0,1)=0,rand<0.51,elsewhere rand is a random number in [0, 1).In HLO, an individual is considered of hitting the bottleneck if its fitness is not improved in the certain number of generations. In this case, the re-learning operator is activated which clears the IKD of the corresponding individual so that it can re-learn with new experience in the following generations, which may help HLO escape from the local optima and obtain better performance, like people re-learning with a new approach to pass the bottleneck.After individuals accomplish learning in each generation, the fitness of new candidate solutions is calculated according to the pre-defined fitness function. The new candidates will be retained in the IKDs if their fitness are better than that of the worst ones in the IKDs or the number of the solutions reserved in the current IKDs is less than G. The SKD of HLO is updated in the same way.In summary, HLO yields a new solution by performing random exploration learning, individual learning and social learning with certain rates as Fig. 1, which can be simplified and formulated as Eq. (8),(8)xij=RE(0,1),0≤rand<prikipj,pr≤rand<piskqj,elsewhere pr is the probability of random exploration learning, (pi−pr) and (1−pi) represent the rates of individual learning and social learning, respectively. When the learning of an individual is trapped in a bottleneck, the re-learning operator is triggered to remove the knowledge in the IKD and thereby ensure that the individual can re-start learning without the influence from its own previous experience. The learning operators and updating operation of HLO are repeatedly run until termination criteria are met. The procedure of HLO can be illustrated as Fig. 2.Although the individual knowledge and social knowledge are both used in PSO and HLO as people and birds are both of the social animals, the ideas of these two algorithms are different. PSO imitates the foraging of birds in which the real-coding strategy is adopted, while the proposed HLO is inspired by a common human learning process and adopts the binary-coding framework where each bit is regards as the block of knowledge. Moreover, besides the individual and global best information, PSO algorithms including the binary PSO variants [16,17,25] search for the optimal solution based on the inertia information of velocity while HLO hunts for the optima by using the random exploration learning operator and the re-learning operator simulating the behaviors in the human learning process.Multidimensional knapsack problems (MKPs) offer many practical applications in computer science, operational research and management science, such as capital budgeting, cargo loading, project selection, and resource allocation in computer networks. The aim of MKPs is to find the maximum profit without the violation of knapsack constraints, which can be described as follows:(9)maxf(x1,x2,...,xn)=∑j=1npjxj(10)s.t.∑j=1nrijxj≤bi,i=1,2,...,m(11)xj∈{0,1},j=1,2,...,nwhere pjis the profit of the jth item, biis the capacity of the ith knapsack, and rijis the weight of the jth item when it is considered for possible inclusion in the ith knapsack with capacity constrain bi. Although MKPs are expressed as a simple formulation, they have been paid attention for a long time due to its importance and widely used as benchmark problems for binary meta-heuristics [26–31].A set of fair parameters, i.e. pr=0.1 and pi=0.85, is chosen for HLO by trial and error in this paper. The re-learning operator is triggered if the current best fitness of an individual is not improved in 100 generations. The risk of HLO being trapped in local optima is reduced with the increasing of the size of the IKDs and SKD, meanwhile the convergence speed of the algorithm is significantly slowed. As MKPs are single-objective optimization problems, the elite strategy is adopted for the IKDs and SKD in this paper to improve the efficiency of HLO, that is, only the personal historical best solution and the global best candidate are reserved in the IKDs and SKD, respectively. The simulator is implemented in Java using Eclipse 4.2.2 and runs 30 times independently on a PC of Intel Core CPU i7-2700K @ 3.50GHz with 8GB RAMs.5.100 instances and 10.100 instances from the OR-library are adopted as the benchmark problems. For a fair comparison, the results obtained by HLO are compared with the optimal results collected from [26–31]. Firstly, the results of HLO are compared with those obtained by the S-CLPSO [28] algorithm, Ant Algorithm (AA) [29] and Ant System Algorithm (ASA) [30]. The population size of HLO equals to the size of MKP instances, i.e. 100, and the maximum number of function calls (MNFC) was set to 2×105 as those of the compared algorithms. Neither additional local search nor the heurist strategy on MKPs is introduced except that the widely used repair operator is applied in HLO to fix infeasible solutions as the other algorithms. The simulation results are given in Tables 1 and 2.Table 1 shows that HLO and AA find 28 and 26 best solutions out of 30 5.100 instances, respectively. For S-CLPSO and ASA, only the results of the first 10 instances are given in [28] and [30]. Both of S-CLPSO and ASA search out eight best solutions while HLO and AA obtain all the best solutions of these 10 instances. The average values of best solutions of HLO are obviously better than those of S-CLPSO, AA and ASA. HLO acquires the best average values on 29 out of 30 instances and is only inferior to AA on the 5.100.10 instance. Table 2 illustrates that HLO finds all the best known solutions of 30 instances while S-CLPSO, AA and ASA gain 5 out of 10 instances, 25 out of 30 instances and 5 out of 10 instances, respectively. Moreover, the average solutions of HLO outperform those of S-CLPSO, AA and ASA on all the 30 instances. Actually, for the first 10 instances, the average values of HLO are even better than the best solutions of S-CLPSO, AA and ASA on 3 instances (10.100.05, 10.100.06 and 10.100.08), 4 instances (10.100.03, 10.100.04, 10.100.05 and 10.100.07) and 4 instances (10.100.04, 10.100.05, 10.100.07 and 10.100.08), respectively.To further evaluate the performance of HLO, we compared HLO with binary ant system (BAS) [27], which is the best ant based algorithm developed to solve MKPs, as well as another two follow-up works, i.e. the hybrid NP+BAS+LP algorithm [31] and artificial bee colony algorithm (ABC) [26]. For a fair comparison, the MNFC of HLO increased to 9×107 as those of the compared algorithms. The experimental results of 5.100 instances and 10.100 instances are given in Tables 3 and 4, respectively.With the increasing of the MNFC, it is no surprise that the results of MKPs are improved. Table 3 displays that all the algorithms find the best solutions of all the 5.100 instances, and HLO, BAS, NP+BAS+LP and ABC obtain 29, 27, 22 and 28 best-known solutions out of 30 instances with the 100% success rate. Compare with the other three algorithms, HLO outperforms BAS, NP+BAS+LP and ABC on 3, 8 and 2 instances and is inferior to them on 1, 0 and 1 instance, respectively. For 10.100 instances, HLO also searches out all the optimal solutions of 30 instances while BAS, NP+BAS+LP and ABC fail on 1, 2 and 1 instance, respectively. Table 4 shows that HLO surpasses BAS, NP+BAS+LP and ABC in terms of the average solutions on 11, 17 and 7 instances, respectively, and equals to them on the rest instances. Moreover, from Table 4 we can notice that the average values of BAS, NP+BAS+LP and ABC are exactly as same as the found best solutions on 10.100.26, 10.100.12 and 10.100.13, respectively, but not the best-known values, which indicates that these algorithms are trapped in the local optima in these cases. Meanwhile, HLO efficiently escapes from the local optima of these instances and reaches the best solutions.For better and comprehensively evaluating the performance of HLO, we finally compared HLO with two new PSO algorithms for MKPs, i.e. self-adaptive check and repair operator binary PSO with time-varying acceleration coefficients (SBPSO-TVACs) and self-adaptive check and repair operator chaotic binary PSO with time-varying acceleration coefficients (SCBPSO–TVACs) [32]. The paired t-test and Wilcoxon signed-rank test (W-test) results, as well as the running time and the numerical results of each algorithm, are listed in Tables 5 and 6, where “1” represents that HLO is significantly better than the compared algorithm at the 95% confidence, “−1” means that HLO is significantly worse than the compared algorithm, and “0” indicates the performance of HLO is comparative. The t-test assumes Gaussian distribution while the W-test does not make such assumption. Thus, the t-test is more powerful than the W-test when the Gaussian assumption is met, and otherwise the W-test could be more powerful. For a fair comparison, the recommended parameter values of SBPSO-TVACs and SCBPSO–TVACs were adopted and the MNFC was set to 2×106 according to [32].Tables 5 and 6 show that HLO achieves the best numerical results on all the instances. The t-test results demonstrate that HLO is obviously better than SBPSO–TVACs and SCBPSO–TVACs on 49 and 49 out of 60 instances, respectively, while it is significantly worse than them on none of 60 instances. The W-test results indicate that HLO significantly outperforms SBPSO–TVACs and SCBPSO–TVACs on 54 and 55 out of 60 instances, respectively, and HLO obtains the comparative result on the rest instances. Besides, due to the simpler implementation and better search ability of HLO, Tables 5 and 6 also show that HLO is more efficient and it costs less running time than SBPSO–TVACs and SCBPSO–TVACs.In summary, the experimental results demonstrate that HLO has excellent global search ability and outperforms the other algorithms on the 5.100 and 10.100 instances. As far as we know, HLO achieves the best results on these two sets of MKPs compared with other publicly reported meta-heuristics. Considering that the implementation and computation of HLO is simpler or equal to S-CLPSO [28], BAS [27] and the other binary variants of meta-heuristics [19,22,26,29–32], and the results are obtained within the same MNFC, it is fair to claim that the proposed HLO is an effective optimization tool. In addition, BAS [27] and ABC [26] use local search to improve solutions which is usually subject to the type of problems and needs prior knowledge while HLO does not introduce these specific local search strategies, which means that HLO is more flexible.

@&#CONCLUSIONS@&#
In this paper, we present a novel human learning optimization algorithm which is inspired by the human learning process. Four learning operators, i.e. the individual learning operator, social learning operator, random exploration learning operator and re-learning operator are designed by emulating different learning phenomena of human beings to search for the optima. The individual learning operator, social learning operator and random exploration learning operator can efficiently exploit the information of individuals and the population while the re-learning operator can help HLO keep exploring search space and avoid being trapped in the local optima. The experimental results demonstrate that the developed HLO is effective and outperforms S-CLPSO, AA, ASA, NP+BAS+LP, BAS, ABC, SBPSO-TVACs and SCBPSO–TVACs on 5.100 and 10.100 benchmark knapsack problems. Considering the characteristics such as ease of implementation and excellent global search ability, HLO is a very promising optimization algorithm.However, as a new algorithm, HLO needs to be studied and improved further. First, a comprehensive and well-designed parameters study on different kinds of problems is necessary to understand HLO better. Second, as mentioned above, human learning is extremely complicated while the proposed HLO is designed only based on a common and simple learning process of humans. And thus, an important direction of HLO is to extract and introduce more phenomena and characteristics of human learning into HLO to enhance its performance. Last but not least, the IKDs and SKD of HLO can reserve multiple best solutions which makes HLO naturally be fit to multi-objective problems. However, the current learning strategy is inefficient for solving Pareto-based multi-objective problems, and thus one of our following works is to modify or develop learning operators to design effective Pareto HLO algorithms.