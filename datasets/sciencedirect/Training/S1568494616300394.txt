@&#MAIN-TITLE@&#
Improved functional link artificial neural network via convex combination for nonlinear active noise control

@&#HIGHLIGHTS@&#
The combination scheme based on adaptive FLANN filter is designed for nonlinear ANC systems.The CNFSLMS algorithm in the filter bank form is derived to obtain an improved convergence behavior.To reduce the computational complexity, the modified CNFSLMS algorithm is proposed by replacing the sigmoid function with a Versorial function.The analysis of the computational complexity is discussed.The steady state performance is analyzed.

@&#KEYPHRASES@&#
Functional link artificial neural network,Active noise control,Filtered-s LMS algorithm,Adaptive combination,

@&#ABSTRACT@&#
A method relying on the convex combination of two normalized filtered-s least mean square algorithms (CNFSLMS) is presented for nonlinear active noise control (ANC) systems with a linear secondary path (LSP) and nonlinear secondary path (NSP) in this paper. The proposed CNFSLMS algorithm-based functional link artificial neural network (FLANN) filter, aiming to overcome the compromise between convergence speed and steady state mean square error of the NFSLMS algorithm, offers both fast convergence rate and low steady state error. Furthermore, by replacing the sigmoid function with the modified Versorial function, the modified CNFSLMS (MCNFSLMS) algorithm with low computational complexity is also presented. Experimental results illustrate that the combination scheme can behave as well as the best component and even better. Moreover, the MCNFSLMS algorithm requires less computational complexity than the CNFSLMS while keeping the same filtering performance.

@&#INTRODUCTION@&#
Over the past decades, active noise control (ANC), which is based on the superposition principle that a noise can be canceled by another noise with the same amplitude but opposite in phase, has attracted increasing attention because of its potential use in low frequency noise control applications [1]. One of the most popular adaptive filtering algorithms is the filtered-x LMS (FXLMS) algorithm due to its simple structure and ease of implementation in ANC systems. However, in actual ANC systems, the performance of the FXLMS algorithm may be degraded, or even failed. Major reason is the fact that the FXLMS algorithm is linear in nature, and not capable of compensating nonlinear distortions under the following situations [2–5]: (1) the reference noise received by a reference microphone may be a nonlinear and deterministic noise process, such as a chaotic noise rather than a stochastic, white, or tonal noise; (2) the primary path noise at the canceling point may exhibit nonlinear distortions when the primary path is nonlinear; (3) the secondary path transfer function of an ANC system has a nonminimum-phase. Consequently, in the design of these ANC systems, the nonlinear adaptive filters should be employed because it can provide satisfactory performance. But, there is no unique theory for modeling and characterizing nonlinear phenomenon.As an effective way of compensating nonlinear distortions in nonlinear ANC systems, the filtered-s LMS algorithm-based adaptive functional link artificial neural network (FLANN) filter (FSLMS) has recently received increasing interest. By utilizing its advantages of low computational complexity and linear outputs-coefficients relationship, the FLANN filters-based trigonometric functional expansions [6,7], polynomial expansions [8] and piece-wise linear expansions [9] have been developed as adaptive controllers in nonlinear ANC systems. To improve the performance of nonlinear ANC systems, various types of FLANN filters have been proposed in recent years, such as reduced feedback FLANN [10], recursive FLANN [11], generalized FLANN [12], nonlinear neuro-controller-based FLANN [13] and hybrid active noise control system-based FLANN [14]. It is worth noting that the FLANN filters are members of the class of causal, shift-invariant, finite memory, nonlinear filters whose output depends linearly on the filter coefficients. Therefore, as in the linear FXLMS algorithm, the FSLMS algorithm using trigonometric functional expansions is most popular in nonlinear cases [15]. However, an important limitation regarding the FSLMS algorithm is that the selection of a certain value for the step size implies a compromise between speed of convergence and steady state performance. That is, a large step size yields a fast convergence rate but a large steady state mean square error (MSE), and a small step size leads to a slow speed with a low steady state MSE. To deal with this disadvantage, some approaches including normalized FSLMS [11,12] and fast FSLMS algorithms [16,17] have been proposed, but it is not easy to establish the same speed vs precision compromise.Inspired by the convex combination approaches in [18–21], a combination scheme based on the normalized FSLMS algorithm (CNFSLMS) is proposed to circumvent the compromise between speed of convergence and precision for nonlinear ANC systems with the linear secondary path (LSP) and nonlinear secondary path (NSP) because of the use of a fixed step size in this paper. The proposed algorithm is constructed by the convex combination of two FLANN filters with different step sizes. Partial work of the algorithm was presented in [22] which only simply discussed the convex combination of two FSLMS algorithms for nonlinear ANC system with the nonminimum-phase LSP. In this paper, the CNFSLMS algorithm is derived in detail. Moreover, the modified CNFSLMS is presented to reduce computational complexity. Furthermore, the performance analysis (including computational complexity and steady state error) for nonlinear ANC system with the LSP and NSP is provided. Simulation results are given for nonlinear active noise control (NANC) with a LSP and NSP. Specifically, we address main contributions in this paper as the following points:(1)The combination scheme based on adaptive FLANN filter is designed for nonlinear ANC systems with the LSP and NSP.The CNFSLMS algorithm in the filter bank form is derived to obtain an improved convergence behavior.To reduce the computational complexity, the modified CNFSLMS (MCNFSLMS) algorithm is proposed by replacing the sigmoid function with the modified Versorial function for nonlinear ANC systems.The analysis of the computational complexity is discussed.The steady state performance is analyzed.The rest of the paper is organized as follows. In Section 2, the brief FLANN filter is presented. In Section 3, we briefly review the normalized FSLMS algorithm. The combination scheme based on adaptive FLANN filter is presented for nonlinear ANC systems in Section 4, where the CNFSLMS and MCNFSLMS algorithms are derived, respectively. In Section 5, the steady state performance of the proposed algorithms is presented. The computational complexity is analyzed in Section 6. The simulation results are provided for nonlinear active noise control (NANC) with a LSP and NSP in Section 6. Finally, we present a brief summary and discussion in Section 7.As a computationally efficient single layer network, the FLANN filter has been developed as an alternative architecture to the nonlinear adaptive filter. Fig. 1depicts the schematic diagram of the FLANN filter, which is a fat net without any need for a hidden layer. Where n is the time index.In a FLANN, each input x(n) to network is expanded by a suitable set of linearly independent functions in the functional expansion block (including Chebyshev, Legendre, and trigonometric), and then the output of the FLANN filter is obtained by(1)y(n)=WT(n)S(n)where T, W(n) and S(n) denotes the transpose operator, the filter coefficient vector and nonlinear functional expansion vector. Due to its simplicity and efficiency, the trigonometric expansion is employed in this paper. Then, the expanded vector S(n) of the input can be given as(2)S(n)=[x(n),sin(πx(n)),cos(πx(n)),…,sin(Pπx(n)),cos(Pπx(n)),x(n−1),sin(πx(n−1)),cos(πx(n−1)),…,sin(Pπx(n−1)),cos(Pπx(n−1))…,x(n−N+1),sin(πx(n−N+1)),cos(πx(n−N+1)),…,sin(Pπx(n−N+1)),cos(Pπx(n−N+1))]Twhere N is the memory size, P is the order of the nonlinear expansion using trigonometric function, and W(n) is defined by(3)W(n)=[w1(n),w2(n),…,w(2P+1)N(n)]TSo the above-mentioned nonlinear functional expansion would result in an increase in the input vector dimensionality, and enhance the performance of networks. By utilizing their advantages of low computational complexity and linear outputs-coefficients relationship, various algorithms-based the FLANN filters have been developed as adaptive controllers in single-channel and multi-channel nonlinear ANC systems, such as FSLMS and fast FSLMS algorithms [11,12,16,17].Fig. 2describes the block diagram of the nonlinear ANC system-based adaptive FLANN filter using the normalized FSLMS algorithm with the filter bank implementation that can reduce the computational complexity.As illustrated in Fig. 2, the output signal y(n) of the secondary path in a filter bank form is generated by adaptive FLANN filter expressed as(4)y(n)=∑i=12P+1yi(n)where yi(n) is the output of the ith sub-filter, and given by(5)yi(n)=wiT(n)si(n)and wi(n) represents the corresponding weight coefficient vector of the ith sub-filter. When the order P is increasing, the nonlinearity of the FLANN filter is higher. According to the approach proposed in [6,7,10–12], the selection of the parameter P is set to be 3 in this paper.In the filter bank representation, the inputs vectors si(n)(1≤i≤2P+1) of each sub-filter are respectively represented as(6)s1(n)=[x(n),x(n−1),…,x(n−N+1)]T,⋮s2P(n)=[sin(Pπx(n)),sin(Pπx(n−1)),…,sin(Pπx(n−N+1))]Ts2P+1(n)=[cos(Pπx(n)),cos(Pπx(n−1)),…,cos(Pπx(n−N+1))]Tand x(n) denotes the reference signal.Then, the normalized update of adaptive FLANN filter for nonlinear ANC systems can be formulated by(7)wi(n+1)=wi(n)+ue(n)si′(n)δ+||si′(n)||2where the step size u controls the convergence performance, δ is a regularization parameter to avoid division by zero. The error signal e(n) is defined by(8)e(n)=d(n)−Aˆ(n)*y(n)and asterisk * denotes convolution operator, the filtered signal vectorsi′(n)is calculated by(9)s′i(n)=[s′i,1(n),s′i,2(n),…,s′i,N(n)]T=Aˆ(n)*si(n)whereAˆ(n)is used as an estimate of the secondary path A(n) which is a LSP or NSP in the practical ANC system.To cope with the compromise between the speed of convergence and the steady state error of the NFSLMS algorithm in nonlinear ANC systems with the LSP and NSP, the novel nonlinear ANC system based on the adaptive FLANN filter using the convex combination of two normalized filtered-s LMS algorithms (CNFSLMS) is designed, as shown in Fig. 3. To achieve a good performance from the convex combination scheme, two adaptive FLANN filters with different step sizes are adapted individually. Moreover, the output signals of the component filters are convex combined by a mixing parameter in such a manner that the advantages of both FLANN filters are kept, i.e., the fast convergence speed from a large step size adaptive FLANN filter, and the low steady state error from the small step size adaptive FLANN filter.As shown in Fig. 3, it is clearly shown that the output sy(n) of the proposed nonlinear ANC system at the error microphone can be calculated using the convex combination form as follows:(10)sy(n)=Aˆ(n)*y(n)=Aˆ(n)*{λ(n)y1(n)+[1−λ(n)]y2(n)}where y(n)=λ(n)y1(n)+(1−λ(n))y2(n) is the output of adaptive combination FLANN filter, output yj(n)(j=1, 2) of the jth adaptive FLANN controller is given as follows:(11)yj(n)=WjT(n)S(n)=∑i=12P+1yj,i(n)=∑i=12P+1wj,iT(n)si(n)and Wj(n) denotes the corresponding weight coefficients, and defined by(12)Wj(n)=[wj,1(n),wj,2(n),…,wj,2P+1(n)]TThe signal matrix S(n) generated by the trigonometric function expansion is given by(13)S(n)=[s1(n),s2(n),…,s2P+1(n)]TAs for the proposed combination scheme, the mixing parameter λ(n) is kept in the interval (0, 1) by the definition via a sigmoid activation function as(14)λ(n)=11+exp[−a(n)]Notice that λ(n) increases monotonically with a(n), and lies between zero and one.Using the expression (14), we can also obtain the a convex combination W(n) of the weights of the overall filter(15)W(n)=λ(n)W1(n)+[1−λ(n)]W2(n)Thus, the filter bank implementation of W(n) is expressed as(16)wi(n)=λ(n)w1,i(n)+[1−λ(n)]w2,i(n),i=1,2,…,2P+1As for the standard FXLMS algorithm, the partial derivatives of the cost function J(n)=E(e2(n)) are calculated using the stochastic approximation(17)∂J(n)∂W(n)=∂E[e2(n)]∂W(n)≅∂e2(n)∂W(n)=2e(n)∂e(n)∂W(n)=−2e(n)∂sy(n)∂W(n)where E[·] is the expectation operator, e(n) represents the overall error at time n, and is defined by(18)e(n)=d(n)−sy(n)When the secondary path is linear, we have(19)∂sy(n)∂W(n)=∂sy(n)∂y(n)∂y(n)∂W(n)=AˆLinear(n)*S(n)For the nonlinear secondary path, the output sy(n) is a nonlinear function of adaptive filter's output y(n), with memory of m samples, as follows:(20)sy(n)=f[y(n),y(n−1),…,y(n−m+1)]TIn this case, it results in(21)∂sy(n)∂W(n)=∑k=0m−1∂sy(n)∂y(n−k)∂y(n−k)∂W(n)We assume that the convex combination W(n) is slowly varying for small step sizes [11], so that(22)∂y(n−k)∂W(n)≈∂y(n−k)∂W(n−k)Now, let us define theAˆNonlinear(n)as(23)AˆNonlinear(n)=[AˆNonlinear(n,0),AˆNonlinear(n,1),…,AˆNonlinear(n,m−1)]T=∂sy(n)∂y(n),∂sy(n)∂y(n−1),…,∂sy(n)∂y(n−m+1)TThus, according to the guidelines indicated in [11] where the concept of a virtual secondary path is introduced to take into account the action ofAˆNonlinear(n), we can get(24)∂sy(n)∂W(n)=AˆNonlinear(n)*S(n)For the sake of simplicity, we can firstly define the estimated vectorAˆ(n)of the secondary path A(n) as follows:(25)Aˆ(n)=AˆLinear(n)whenthe secondary path is linearAˆNonlinear(n)whenthe secondary path is nonlinearwhereAˆLinear(n)andAˆNonlinear(n)denotes the estimated coefficient vectors of the linear secondary path and nonlinear secondary path, respectively.For the proposed combination strategy, the weight of each adaptive FLANN filter is individually adjusted by the NFSLMS algorithm with its own errors. Then, according to the aforementioned discussion, the update rule of the component filter in Fig. 3 can be written as(26)Wj(n+1)=Wj(n)+ujej(n)S′(n)δ+||S′(n)||2,j=1,2where the error ej(n) is computed as(27)ej(n)=d(n)−Aˆ(n)*yj(n)and the filtered signal matrix S′(n) is calculated by(28)S′(n)=[s′1(n),s′2(n),⋯,s′2P+1(n)]T=Aˆ(n)*S(n)According to the implementation in the filter bank form [6,7], we have(29)wj,i(n+1)=wj,i(n)+ujej(n)s′i(n)δ+||s′i(n)||2,j=1,2;i=1,2,…,2P+1Without loss of generality, we can assume that u1>u2. As compared with the coefficient w2,i(n), w1,i(n) have a faster speed of convergence but a larger steady-state MSE. On condition that the fast FLANN filter significantly outperforms the slow one, the weight update Eq. (29) can be modified to improve the performance of CNFSLMS algorithm as follows:(30)w2,i(n+1)=αw2,i(n)+u2e2(n)s′i(n)δ+||s′i(n)||2+(1−α)w1,i(n+1),i=1,2,…,2P+1where the parameter α (0<α<1) is close to 1. By this way, the adaptation of w2 is similar to that of a standard FLANN filter. However, the application of (30) over much consecutive iteration will speed up the convergence of the u2 FLANN filter. As a result, the CNFSLMS algorithm is converged. This weight transfer procedure is only applied if the fast FLANN filter is significantly outperforming the slow one.For the particular case of the FLANN combination scheme, it is the key factor how to adapt the mixing parameter a(n) so that the error of the overall filter can be minimized.As in the classic FXLMS algorithm, we can approximate the ensemble mean J(n) by using the instantaneous value ξ(n) as follows(31)ξ(n)=e2(n)Using the expression (10), it is obvious that the error e(n) of the overall filter can be calculated using the convex combination from(32)e(n)=d(n)−Aˆ(n)*sy(n)=d(n)−Aˆ(n)*[λ(n)y1(n)+[1−λ(n)]y2(n)]=λ(n)[d(n)−Aˆ(n)*y1(n)]+[1−λ(n)][d(n)−Aˆ(n)*y2(n)]=λ(n)e1(n)+[1−λ(n)]e2(n)According to the stochastic gradient descent rule, the variable parameter a(n) is adapted by(33)a(n+1)=a(n)−ua∇ξ(n)2where the step size uais used to keep λ(n) in the interval [0,1], and must be fixed to a very high value, with the result that the convex combination filter is adapted even faster than the fast FLANN filter. However, a disadvantage of this scheme is that a(n) stops updating whenever λ(n) is too close to 0 or 1. To deal with the drawback, we can limit the values of a(n) to the interval [−4,4] [18,19].In (33), ∇ξ(n) denotes the gradient estimator, and is calculated by(34)∇ξ(n)=∇e2(n)=2e(n)∇e(n)=2e(n)∂e(n)∂a(n)=−2e(n)[Aˆ(n)*y1(n)−Aˆ(n)*y2(n)]∂λ(n)∂a(n)=2e(n)[e1(n)−e2(n)]λ(n)[1−λ(n)]Then, we can obtain the update equation of mixing parameter a(n) expressed as(35)a(n+1)=a(n)−uae(n)[e1(n)−e2(n)]λ(n)[1−λ(n)]The selection of the step size uaplays a crucial role in obtaining appropriate filter behavior. Thus, a normalized form of (33) is calculated as follows:(36)a(n+1)=a(n)−uaδ+r(n)e(n)[e1(n)−e2(n)]λ(n)[1−λ(n)]By using this update rule (36), the selection of uais not affected by the signal-to-noise (SNR). Moreover, to further improve performance, a low-pass filtered estimation r(n) is used to instead of the instantaneous value of [e1(n)−e2(n)]2 as follows(37)r(n+1)=βr(n)+(1−β)[e1(n)−e2(n)]2where the parameter β is a constant close to 1.Inevitably, the proposed CNFSLMS algorithm needs calculation of the exponential function, which would result in heavy computational complexity. Therefore, to solve the problem, we use the modified Versorial function to replace the sigmoid function and come up with a modified CNFSLMS (MCNFSLMS) algorithm in the following subsection.The modified Versorial function given in [23] is expressed as follows:(38)λ(n)=1−1Ba2(n)+2a(n)≥01Ba2(n)+2a(n)<0where B is a parameter to adjust the curve shape. Moreover, to guarantee convergence, it requires that B is larger than 1. To select the appropriate value of the parameter B in (38), we can plot the λ(n) curve with different B values (B=1, 2, 3, 4 and 5) as shown in Fig. 4(a). Obviously, it is observed that the modified Versorial function with B=2 is the best approximation of the sigmoid function. Fig. 4(b) describes the normalized mean square error (NMSE) of the proposed MCNFSLMS algorithm with different B values (B=1, 2, 3, 4 and 5) in nonlinear ANC case which is with a secondary path transfer function with minimum-phase. It has shown that the performance of the proposed algorithm with B=2 outperforms other cases. In future works, the parameter B of the modified Versorial function in the proposed algorithm will be theoretically analyzed.Consequently, replacing the sigmoid function of the modified Versorial function, the proposed MCNFSLMS algorithm is achieved in this subsection, and the pseudocode for the MCNFSLMS algorithm is listed in Table 1.In this section, the MSEs of the overall filter and its component filters are analyzed and discussed.To begin with, substituting (32) into the cost function J(n) of the overall filter, we have(39)J(n)=E(e2(n))=E{[d(n)−Aˆ(n)*sy(n)]2}=E{{λ(n)e1(n)+[1−λ(n)]e2(n)}2}=E{λ2(n)e12(n)}+E{[1−λ(n)]2e22(n)}+2E{λ(n)[1−λ(n)]e1(n)e2(n)}Next, assuming that λ(n) is independent of the component filter errors in steady state. When using a reduced adaptation speed for a(n), this assumption is reasonable, and therefore it is better justified when a(n) approaches ±4 in steady state given the fact that in these situations, the factor λ(n)(1−λ(n)) in (35) is close to zero.Using the assumption, and taking the limit as n→∞, (39) becomes as follows:(40)J(∞)=limn→∞J(n)=limn→∞E{λ2(n)}⋅limn→∞E{e12(n)}+limn→∞E{[1−λ(n)]2}⋅limn→∞E{e22(n)}+2limn→∞E{λ(n)[1−λ(n)]}⋅limn→∞E{e1(n)e2(n)}=J1(∞)limn→∞E{λ2(n)}+J2(∞)limn→∞E{[1−λ(n)]2}+2J12(∞)limn→∞E{λ(n)[1−λ(n)]}whereJ1(∞)=limn→∞E{e12(n)},J2(∞)=limn→∞E{e22(n)},(41)J12(∞)=limn→∞E{e1(n)e2(n)}Furthermore, iflimn→∞E{a(n)}=4, thenlimn→∞λ(n)=1, (40) becomes(42)J(∞)=J1(∞)when J1(∞)≤J12(∞)≤J2(∞).In a similar way, iflimn→∞E{a(n)}=−4, thenlimn→∞λ(n)=0, we can obtain(43)J(∞)=J2(∞)when J1(∞)≥J12(∞)≥J2(∞).Thus, the combination scheme performs as the best component filter. Moreover, it can also be shown that the overall filter can reduce the MSE of each filter when the cross-MSE is sufficiently small, specifically J12(∞)≤min{J1(∞), J2(∞)}.As in [6,7], it is a well-known fact that the FSLMS algorithm requires N(2P+1)(L+3)−L multiplications to calculate the output of the filter and to update its weights, and 2NP to calculate the functional expansion by sin(·)/cos(·) functions. Since the proposed combination algorithm combines two FLANN filters, it needs 2N(2P+1)(L+3)−L multiplications for the adaptation of the component FLANN filters, 2NP to compute the sin(·)/cos(·) functions, and more multiply products to calculate the output of allover the proposed filter and to update a(n) (see (35) and (36), respectively). In addition, the sigmoid function is needed to be calculated by the look-up table, and the weight vector W(n) of the proposed combination algorithm requires 2N(2P+1) additional multiplications. Furthermore, if (30) is being applied, it will need 2N(2P+1) extra products at some iterations. Therefore, it is obviously shown that the proposed combination scheme outperform adaptive FLANN filter at the cost of the increasing computational complexity.Compared with the CNFSLMS algorithm, the MCNFSLMS algorithm uses Versorial function to instead of the sigmoid function. Therefore, in implementation, the sigmoid function using a look-up table does not need to be computed for the MCNFSLMS algorithm. According to (38), we can obtain the mixing parameter value by the only a division and 3 multiplications. As a result, the calculation of the MCNFSLMS algorithm requires less time than that of the CNFSLMS algorithm.To illustrate the effectiveness of the proposed combination scheme in applications of nonlinear ANC systems with the LSP and NSP, three experiments (including two examples of NANC systems with a LSP and one example of NANC systems with a NSP) are carried out in this section.For performance comparisons, we use the NMSE achieved by each adaptive controller versus the number of iterations defined as(44)NMSE=10log10E(e2(n))σd2whereσd2is the power of the primary noise at the canceling point.All the parameters of the MCNFSLMS, CNFSLMS, NFSLMS1 (with the large step size), NFSLMS2 (with the small step size) and second-order Volterra FXLMS (VFXLMS) algorithms are summarized in Table 2. Moreover, the same values of parameters are applied to all the experiments, except for experiments 2 with the minimum-phase secondary path. To clearly show the performance of these algorithms, the NMSE curves are computed over 300 independent runs.In this example, the secondary path transfer function A(z) and its estimateAˆ(z)also containing the error path of z−2 are assumed to be an FIR filter with nonminimum-phase as used in [9–17], and shown as(45)A(z)=Aˆ(z)=z−2+1.5z−3−z−4Since the logistic chaotic noise is shown to be a second-order white and predictable nonlinear process, we can choose a logistic chaotic noise used in [2,5–7] as the reference noise source in this experiment. The reference noise is generated using the recursive equation(46)x(n+1)=λx(n)[1−x(n)]where λ=4 and x(0)=0.9. This nonlinear noise process is then normalized to have unit signal power. The primary path P(z), the modified finite impulse response (FIR) filter including an error path of z−2 used in [2,5–7], is expressed by(47)P(z)=z−5−0.3z−6+0.2z−7The secondary path transfer function A(z) and its estimateAˆLinear(z)also containing the error path of z−2 are assumed to be an FIR filter with nonminimum-phase as used in [2,5–7], and shown as(48)A(z)=AˆLinear(z)=z−2+1.5z−3−z−4Fig. 5describes comparable results of the NFSLMS algorithm with the VFXLMS, proposed CNFSLMS and MCNFSLMS algorithms. Obviously, it is observed that the CNFSLMS and MCNFSLMS algorithms both exhibit faster convergence rate and smaller steady state error than the conventional NFSLMS and VFXLMS algorithms. In addition, the MCNFSLMS algorithm has a similar behavior in the convergence with the CNFSLMS. Furthermore, based on a Pentium (R) Dual-core processor with 3.2GHz, the training time for the CNFSLMS and MCNFSLMS algorithms are 0.326805s and 0.281516s, respectively. Therefore, the performance of the MCNFSLMS is as good as that of the CNFSLMS with less computational complexity.To further evaluate the performance of the proposed adaptive controller, we perform simulations assuming that the primary path exhibits high nonlinear behavior. The primary noise at the canceling point is generated based on the following third-order polynomial model:(49)d(n)=t(n−2)+0.08t2(n−2)−0.4t3(n−2)and t(n) is calculated by(50)t(n)=x(n)∗f(n)where f(n) is the impulse response of the following transfer function(51)F(z)=z−3−0.3z−4+0.2z−5and the reference noise x(n) is sinusoidal wave of 500Hz sampled at the rate of 8000 samples/s by(52)x(n)=2sin2π×500×n8000+v(n)and v(n) is a white noise process with the Gaussian distribution. The signal power-to-noise power ratio (SNR) is chosen to be 40dB. For comparison, we also select a secondary path transfer function with minimum-phase as(53)A(z)=AˆLinear(z)=z−2+0.5z−3and nonminimum-phase as Eq. (48).In this experiment, the parameters of all the nonlinear filters are same as those of Experiment-I. But the learning rates u1, u2 and uaof the MCNFSLMS algorithm with the minimum-phase secondary path are set to 0.65, 0.1 and 15, respectively. The steady state NMSE can be obtained after averaging over 100 independent runs each consisting of 2000 iterations.Fig. 6depicts simulation results when the secondary path estimates are of minimum-phase and nonminimum-phase, respectively. Furthermore, the learning curves of the mixing parameter λ(n) of the proposed MCFSLMS algorithm in Fig. 6(b) and (d) are provided to show the transfer procedure of the proposed convex combination strategy. And the periodic reference noise is a white Gaussian with a SNR of 40dB. It is apparent that a significant improvement of the performance is achieved by using MCNFSLMS and CNFSLMS algorithms over the NFSLMS and VFXLMS algorithms in both cases. The result is reasonable since utilizing the convex combination scheme. Moreover, the performance of MCNFSLMS is the same as that of the CNFSLMS algorithm. Furthermore, comparative results of the training time are summarized in Table 3. The training time presented in Table 3 illustrate that the CNFSLMS is obviously longer than that of MCNFSLMS in both cases. The major reason is that the sigmoid function of the CNFSLMS requires more computational operations than the Versorial function of the MCNFSLMS.In this example, we consider the use of the proposed algorithms for NANC systems with a NSP. The nonlinear primary and secondary paths are described as [12](54)d(n)=x(n)+0.8x(n−1)+0.3x(n−2)+0.4x(n−3)−0.8x(n)x(n−1)+0.9x(n)x(n−2)+0.7x(n)x(n−3)and(55)s(n)=y(n)+0.35y(n−1)+0.09y(n−2)−0.5y(n)y(n−1)+0.4y(n)y(n−2)respectively. The input reference signal is random noise with a uniform distribution between −0.8 and +0.8 [12].Fig. 7(a) depicts performance comparison of different nonlinear adaptive filters for NANC systems with a NSP. Moreover, we have provided the learning curve of the mixing parameter λ(n) of the proposed MCFSLMS algorithm in Fig. 7(b). Clearly, it is observed that the proposed MCNFSLMS and CNFSLMS algorithms outperform the NFSLMS and VFXLMS algorithms in this case. This is owing to the utilization of the convex combination strategy. Moreover, the MCNFSLMS is the same to the CNFSLMS algorithm. In addition, to further test the computational burden of the MCNFSLMS and CNFSLMS algorithms, the training times are obtained as 4.252529 (seconds) and 4.459490 (seconds), respectively. Therefore, the computational complexity of the proposed MCNFSLMS is less than that of the CNFSLMS.According to (44), it is clearly shown that the NMSE of the overall filter is in accordance with the MSE J(n). Consequently, it is concluded that the above-mentioned simulation results is in accordance with the theoretic analysis in Section 5.

@&#CONCLUSIONS@&#
