@&#MAIN-TITLE@&#
Symmetry in RLT-type relaxations for the quadratic assignment and standard quadratic optimization problems

@&#HIGHLIGHTS@&#
We study reformulation–linearization technique relaxations for two problems.Namely standard quadratic programming and the quadratic assignment problem.We show how these relaxations relate to known ones from the literature.We show how to exploit symmetry in the problem data when solving RLT relaxations.Thus we compute the best known bounds for some graph partitioning problems.

@&#KEYPHRASES@&#
Reformulation–linearization technique,Sherali–Adams hierarchy,Quadratic assignment problem,Standard quadratic optimization,Semidefinite programming,

@&#ABSTRACT@&#
The reformulation–linearization technique (RLT), introduced in [Sherali, H. D., Adams. W. P. (1990). A hierarchy of relaxations between the continuous and convex hull representations for zero-one programming problems. SIAM Journal on Discrete Mathematics 3(3), 411–430], provides a way to compute a hierarchy of linear programming bounds on the optimal values of NP-hard combinatorial optimization problems. In this paper we show that, in the presence of suitable algebraic symmetry in the original problem data, it is sometimes possible to compute level two RLT bounds with additional linear matrix inequality constraints. As an illustration of our methodology, we compute the best-known bounds for certain graph partitioning problems on strongly regular graphs.

@&#INTRODUCTION@&#
The term reformulation–linearization technique (RLT) was coined by Sherali and Adams in the seminal paper (Sherali & Adams, 1990) (see also Sherali & Adams, 1994). Thus a hierarchy of linear programming relaxations was introduced, based on a linearization technique studied earlier by these authors in Adams and Sherali (1986) (see also Adams & Sherali, 1990); the subsequent development of the RLT-technique is contained in their monograph (Sherali & Adams, 1999).The main idea is the following: if there are two valid linear inequalities for a given setS⊂Rn, for example ifl1⩽v1Txandl2⩽v2Txfor all x∈S, then their product also yields the valid inequality:v1Txv2Tx-l2v1Tx-l1v2Tx⩾-l1l2∀x∈S.Introducing new variables Xijcorresponding to xixj, we can linearize the last inequality:(1)∑i,jv1iv2jXij-∑i(l2v1i+l1v2i)xi⩾-l1l2.An inequality of this type is known as a first-level RLT cut in the variables x and X. This process may be repeated to obtain level two RLT cuts, etc. This type of method has become known as a lift-and-project strategy: the ‘lifting’ refers to the addition of new variables, and the ‘projection’ to projecting the optimal values of the new variables to a feasible point inRnof the original problem; see Laurent (2003) for a comparison of the RLT with related schemes.In this paper we will study the RLT for two specific problems, namely the standard quadratic program and the quadratic assignment problem (QAP). The first level RLT formulation of the QAP was previously studied in Adams and Johnson (1994) and Johnson (1992). Adams, Guignard, Hahn, and Hightower (2007) considered the second level RLT formulation of the QAP. Numerical results presented in Adams et al. (2007) show that the second level RLT relaxation of the QAP often provides significantly better bounds than the first level RLT relaxation, but that it is computationally very expensive to solve. Recently, the third level RLT relaxation of the QAP was also investigated in Hahn, Zhu, Guignard, Hightower, and Saltzman (2012). The numerical results show that this relaxation empirically provides tight bounds for medium-sized instances (where it is still possible to solve the third level relaxation).In this paper, we show how one may solve the second level RLT relaxation with additional semidefinite programming (SDP) constraints in the presence of suitable algebraic symmetry in the problem data. As a result we are able to compute the best known bounds for certain graph partitioning problems involving strongly regular graphs. (These graph partitioning problems have QAP reformulations.) Our results are in the spirit of the recent papers (de Klerk & Sotirov, 2010; de Klerk & Sotirov, 2012; Gijswijt, Mittelmann, & Schrijver, 2012; Laurent, 2007; Schrijver, 2005) where improved semidefinite programming bounds were obtained for various combinatorial problems by exploiting algebraic symmetry. Our results may also be seen as an extension of recent results by Ostrowski (2012), who studied symmetry in (pure) linear programming RLT relaxations of symmetric binary integer programs.We start by describing RLT relaxations of the standard quadratic optimization problem in Section 2, and of the QAP in Section 3. In these sections we also present new results on how the resulting RLT relaxations relate to known relaxations from the literature. This is followed by background material on exploiting algebraic symmetry in the data of SDP problems in Section 4. We apply this methodology to the standard quadratic programming problem in Section 5, and to the QAP in Section 6. Finally, we present numerical results to illustrate the complete approach in Section 7. Throughout, the main (computational) focus is on the QAP, and our treatment of the standard quadratic program serves as a relatively easy introduction to the more complicated analysis of the QAP.We will use the notation from Sherali and Adams (1999, Section 7.1), (see also (Sherali & Tuncbilek, 1992) for RLT in the context of continuous polynomial programs):∏i∈JxiL=XJ,whereJis an index set with elements from {1,…,n} where repetition of elements is allowed. Thus, for example,[x12x2]L=X{1,1,2}or X112, for short. In other words, [·]Lis a “linearization operator” that maps a monomial to a new variable. This operator may be extended to a linear map from general polynomials to linear ones by simply replacing each monomial by its linearization.The standard quadratic program (stQP) is defined asminx∈ΔxTQxwhereΔ={x∈Rn|∑ixi=1,x⩾0}is the standard simplex inRn, andQ=QT∈Rn×nis given.It is easy to verify (see e.g. Sherali & Fraticelli (2002) or Section 8.3 in Sherali & Adams (1999)) that the first level RLT relaxation of (stQP) takes the formminX=XT∈Rn×n{〈Q,X〉|〈J,X〉=1,X⩾0}where 〈Q,X〉=trace (QX), [xixj]L=Xij(i,j=1,…,n), and J is the all-ones matrix. Since X corresponds to the positive semidefinite matrix xxT, we may also add the constraint that X should be symmetric positive semidefinite, denoted by X⪰0, to obtain the stronger relaxation:(stQPSDP+RLT-1)minX∈Dn{〈Q,X〉|〈J,X〉=1},whereDn⊂Rn×nis the doubly nonnegative cone, i.e. the cone of n×n symmetric positive semidefinite matrices that are also entrywise nonnegative.Note that we have removed the original variable x from the formulation; it is worth noting that this will not be possible for the quadratic assignment problem studied in Section 3. The second level RLT relaxation involves the new matrix variablesY(k)=(Y(k))T=[xkX]L(k=1,…,n).SinceYij(k)corresponds to xixjxk, one has the relationsYij(k)=Yjk(i)=Yik(j)i,j,k=1,…,n.In other words,Yij(k)(i,j,k=1,…,n)may be viewed as a fully symmetric 3-tensor, i.e.Yij(k)is invariant under all permutations of i, j, k.The second level RLT relaxation with SDP constraints becomes(stQPSDP+RLT-2)minY(1),…,Y(n)∈Dn,X∈Rn×n〈Q,X〉|〈J,X〉=1,∑k=1nY(k)=X,Yij(k)fullysymmetric.Note that X∈Dnis implied by Y(1),…,Y(n)∈Dnand∑k=1nY(k)=X.The (t−1)-level RLT relaxation ismin∑i1,…,it=1nQi1i2Zi1…it∑i1,…,it=1nZi1…it=1,Z⩾0,Zisfullysymmetric.Since the variableZi1…itcorresponds to the productxi1…xit, the matrix(Zi1…it)ir,is=1ncorresponds to the matrix∏j=1j≠r,stxijxxT, and we can require its positive semidefiniteness. In other words, any matrix obtained from the tensor Z by fixing (t−2) coordinates has to be positive semidefinite. Therefore it is natural to define (stQPSDP+RLT−t) by adding these linear matrix inequality constraints to the level t RLT relaxation of (stQP).We may rewrite problem (stQPSDP+RLT−2) as the conic linear program(2)minX∈C{〈Q,X〉|〈J,X〉=1}=maxt∈R{t|Q-tJ∈C∗},whereCis the following convex cone:(3)C≔X∈Rn×n|X=∑k=1nY(k),Y(k)∈Dn,Yij(k)=Yjk(i)=Yik(j)(1⩽i,j,k⩽n),C∗is its dual cone, and the equality in (2) is due to the conic duality theorem. In a similar way, one may define RLT relaxations of any order, by generalizing the definition of the coneC. We will argue that these generalized cones coincide with a hierarchy of cones introduced by Dong (2010). In Dong’s notation,Mnrdenotes the set of tensors of order r and dimension n, andSnris the set of fully symmetric tensors. Furthermore, for r>0, β∈{1,…,n}randT∈Mnr+2, T[β,:,:] denotes the ordinary matrix obtained by fixing the first r indices of T to β, and the set of such matrices is Slice (T). The operator Collapse (T) is defined as the sum of the slices of the tensor T, that isCollapse(T)[i,j]=∑β∈{1,…,n}rT[β,i,j]=∑P∈Slice(T)Pi,j.Now one may define the following cones:(4)TDnr={X:∃Y∈Snr+2,Slice(Y)⊂Dn,X=Collapse(Y)},where Dnis the cone of doubly nonnegative n×n matrices, as before. Dong (2010) proved that the conesTDnrare dual to cones defined earlier by Peña, Vera, and Zuluaga (2007) (calledQnrthere). The conesTDnrare precisely the generalization of the coneCin (3). In particular, the valuesYjk(i)in (3) correspond to a fully symmetric 3-tensor, and the Y(k) to slices of this tensor. This leads us to the following theorem.Theorem 1The level t RLT bound with semidefinite constraints (stQPSDP+RLT−t) for the standard quadratic program is given by(5)minX∈TDnt-1〈Q,X〉|〈J,X〉=1=maxt|Q-tJ∈Qnt-1(t=1,2,…),where the conesTDnt-1are defined in(4), andQnt-1are the corresponding dual cones (t=1,2,…).The proof is by induction, and is omitted since it is straightforward. □We conclude this section with a brief comparison of the (stQPSDP+RLT−t) bound to other bounds from the literature. These bounds are related to sufficient conditions for matrix copositivity due to Parrilo (2000) (recall that a matrix M is copositive if xTMx⩾0 for all nonnegative vectors x).To explain these bounds, note thatminx∈ΔxTQx=max{t|xTQx⩾t,∀x∈Δ}=max{t|xT(Q-tJ)x⩾0,∀x∈Δ}=max{t|Q-tJisacopositivematrix}.Parrilo (2000) introduced the following hierarchy of sufficient conditions for a matrix M to be copositive, namely∑i,jMijxi2xj2∑i=1nxi2risasumofsquaredpolynomials,for some integer r⩾0.The cone of matrices that satisfy this sufficient condition for a given r is denoted byKn(r). Bomze and De Klerk (2002) studied the following lower bounds for the standard quadratic optimization problem:(6)p(r)≔max{t|Q-tJ∈Kn(r)}=minX∈Kn∗(r)〈Q,X〉|〈J,X〉=1(r=0,1,…)Since it is known thatQnr⊆Kn(r)(r=0,1,…)and equality (only) holds for r=0,1 (Peña et al., 2007), we have the following result.Theorem 2The bound p(t−1)in(6)is at least as tight as the bound from (stQPSDP+RLT−t) in(5)for t=1,2,…,and the two bounds (only) coincide for t=1, 2.Given two symmetric n×n matrices A and B, the quadratic assignment problem (QAP) is defined as:(QAP)minπ∈Sn∑i,j=1nAijBπ(i),π(j)=minP∈Πntrace(APTBP),whereSnis the symmetric group on {1,…,n}, and Πnis the set of n×n permutation matrices.The QAP may be rewritten as(7)min∑i,j,k,laikbjlxijxkls.t.∑i=1nxij=1,j=1,…,n,∑j=1nxij=1,i=1,…,n,xij∈{0,1},i,j=1,…,n.Writing the integrality constraints asxij2=xij(i,j=1,…,n), and introducing new variables Xijkl=[xijxkl]L(i,j,k,l=1,…,n) as before, the first-level RLT relaxation of QAP is the following linear program:(QAPRLT-1)min∑i,j,k,laikbjlXijkls.t.∑i=1nxij=1,j=1,…,n,∑j=1nxij=1,i=1,…,n,∑i=1nXijkl=xkl,j,k,l=1,…,n,∑j=1nXijkl=xkl,i,k,l=1,…,n,x⩾0,Xijij=xij,i,j=1,…,n,Xijkl=Xklij⩾0,i,j,k,l=1,…,n.Povh and Rendl (2009) studied a semidefinite programming (SDP) relaxation for the QAP problem (the resulting lower bound coincides with an earlier bound studied in Zhao, Karisch, Rendl, & Wolkowicz (1998)). We will show that this relaxation may be viewed as a first level RLT relaxation of the QAP with positive semidefiniteness constraints added.In stating and analyzing this SDP relaxation, we will need several properties of the Kronecker product. Recall that the Kronecker product A⊗B of matricesA=(aij)∈Rm×nandB=(bij)∈Rr×sis the mr×ns block matrix with block (i,j) given by aijB (i=1,…,m, j=1,…,n). We will often use the properties that, forA,B,C,D∈Rn×n, (A⊗B) (C⊗D)=AC⊗BD, and trace (A⊗B)=trace (A) trace (B).The Povh and Rendl (2009) relaxation takes the form:(QAPSDP)min〈A⊗B,Y〉s.t.〈In⊗Eii,Y〉=1,〈Eii⊗In,Y〉=1,i=1,…,n,〈In⊗(Jn-In)+(Jn-In)⊗In,Y〉=0,〈Jn⊗Jn,Y〉=n2,Y∈Dn2,where Inand Jnare the identity and all-ones matrices of order n respectively, and Eiiis the n×n diagonal matrix with 1 in position (i,i) and zeros elsewhere.If we define vec (·) as the operator that maps an n×n matrix to an n2-vector by stacking its columns, then we may view the matrix variable Y as a relaxation of vec (X) vec (X)Tfor X∈Πn. Consequently, we may view Y as having the following block structure:(8)Y≔Y(11)…Y(1n)⋮⋱⋮Y(n1)…Y(nn),whereY(ij)∈Rn×n(1⩽i,j⩽n). ThusYik(jl)=[xijxkl]L, andYik(jl)therefore corresponds to the variable Xijklin (QAPRLT−1).Theorem 3([Povh & Rendl, 2009]) A doubly nonnegative matrix Y is feasible for (QAPSDP) if and only if Y satisfies(i)〈In⊗(Jn−In)+(Jn−In)⊗In, Y〉=0,trace(Y(ii))=1∀i,∑i=1ndiag(Y(ii))=e,Y(ij)e=diag(Y(ii))∀i,j,∑i=1nY(ij)=ediag(Y(jj))T∀j,where e denotes the all-ones vector, and the diag (·) operator maps the diagonal entries of a matrix to a vector in the obvious way.We may use Theorem 3 to show that the Povh–Rendl relaxation (QAPSDP) coincides with the first-level RLT relaxation (QAPRLT−1) with positive semidefiniteness constraints added.Theorem 4If Y is feasible for (QAPSDP), thenXijkl=Yik(jl)andxij=Yii(jj)(1⩽i,j,k,l⩽n)is feasible for (QAPRLT−1) with the same objective value. Conversely, if a feasible solution Xijklof (QAPRLT−1) corresponds to a positive definite matrix Y of the form(8)whereYik(jl)≔Xijkl(1⩽i,j,k,l⩽n), then the matrix Y is feasible for (QAPSDP) with the same objective value.By Theorem 3, for every feasible solution Y of (QAPSDP) one has:Y(jl)e=diag(Y(ll))⇒∑iYik(jl)=Ykk(ll)∀j,k,l,∑jY(jl)=ediag(Y(ll))T⇒∑jYik(jl)=Ykk(ll)∀i,k,l.Recalling thatYik(jl)corresponds to Xijklin (QAPRLT−1), it is now straightforward to verify thatXijkl=Yik(jl)andxij=Yii(jj)satisfy all the constraints of (QAPRLT−1), and that the two objective values are the same. The converse proof is similar and therefore omitted. □For the second-level RLT reformulation we introduce the new variableZ(kp)[ij](lq)=[xijxklxpq]L. Thus we obtain the second level RLT relaxation:(QAPSDP+RLT-2)min〈A⊗B,Y〉s.t.〈In⊗Eii,Y〉=1,〈Eii⊗In,Y〉=1i=1,…,n,〈In⊗(Jn-In)+(Jn-In)⊗In,Y〉=0,〈Jn⊗Jn,Y〉=n2,∑iZ[ij]=Yj=1,…,n,∑jZ[ij]=Yi=1,…,n,Z[ij]∈Dn2i,j=1,…,n,Z(kp)[ij](lq)=Z(ip)[kl](jq)=Z(ik)[pq](jl)i,j,k,l,p,q=1,…,n.As before, note thatY∈Dn2is implied byZ[ij]∈Dn2and∑jZ[ij]=Y.Since the level 2 RLT bound is stronger that the level 1 bound, we have the following corollary of Theorem 4.Corollary 5The bound from (QAPSDP+RLT−2) is at least as tight as the Povh–Rendl bound (QAPSDP).In what follows we will show how the RLT relaxations may be reduced in size if the data of the underlying optimization problem exhibits suitable algebraic symmetry. This approach is called symmetry-induced reduction, or symmetry reduction, for short. We will review some basic concepts first.LetSndenote the symmetric group on {1,…,n}. We consider a fixed permutation groupG⊂Sn. With each permutationπ∈G, we associate an n×n permutation matrix Pπ∈Πn, defined by(Pπ)ij=1ifπ(j)=i0else(i,j=1,…,n)Thus π(j)=i if and only if Pπej=eiif eidenotes the ith standard unit vector inRn. Moreover, for anyX∈Rn×none hasPπTXPπij=Xπ(i),π(j)(i,j=1,…,n).We call{Pπ|π∈G}the permutation matrix representation ofG.The centralizer ring (or commutant) ofGis the setAG≔{X∈Cn×n|PπTXPπ=X∀π∈G}.In words,AGis the set of matrices that are invariant under the row and column permutations inG. The centralizer ringAGis a matrix *-algebra, i.e. a linear subspace ofCn×nthat is also closed under matrix multiplication and under taking the complex conjugate transpose.A centralizer ringAG⊂Cn×nhas a basis of 0–1 matrices, say A1,…,Ad∈{0,1}n×n, whered=dim(AG). In addition, one may assume that∑i=1dAi=J, and thatAGcontains the identity. The basis A1,…,Adcorresponds to the orbits of pairs (also called 2-orbits or orbitals) of indices under the action ofG, and forms a coherent configuration; see (Cameron, 2003) for the formal definition of, and more information on, coherent configurations. In particular, the basis A1,…,Adis given by the set of 0–1 matrices with support{(π(i),π(j))|π∈G}for some i, j∈{1,…,n}.The orthogonal projection of a matrixX∈Cn×nontoAGis given byPAG(X)=∑i=1d〈Ai,X〉‖Ai‖2Ai=1|G|∑π∈GPπTXPπ,where‖Ai‖2=〈Ai,Ai〉=traceAi2=〈Ai,J〉, i.e. the norm in question is the Frobenius norm.The projection operator is known as the Reynolds operator ofGand the projection is also called the barycenter of the orbit.For an integer k, the stabilizer subgroupG[k]⊂Gis defined as the groupG[k]={π∈G|π(k)=k},and we will denote the centralizer ring ofG[k]byAG[k].IfAandA′are two matrix *-algebras, then a linear mapϕ:A↦A′is called an algebra *-isomorphism if it is one-to-one,ϕ(XY)=ϕ(X)ϕ(Y)∀X,Y∈Aandϕ(X∗)=(ϕ(X))∗∀X∈A.Each matrix *-algebra that contains the identity is isomorphic to a direct sum of full matrix algebras, in the following sense.Theorem 6cf. Wedderburn (1934)LetA⊂Cn×nbe a matrix *-algebra that contains the identity. Then there exists an algebra *-isomorphism ϕ such thatϕ(A)=⊕iCni×nifor some integers nithat satisfy∑ini2=dim(A).The image ofAunder the isomorphism ϕ is called the Wedderburn (or canonical) decomposition ofA, or the (canonical) block-diagonalization ofA. An accessible proof of the Wedderburn decomposition theorem is given in Gijswijt (2005, Chapter 2). Moreover, this proof is constructive, and shows how to obtain ϕ.The following result relates matrix *-isomorphisms to symmetry reduction for SDP.Theorem 7see e.g. Theorem 4 in de Klerk, Pasechnik, and Dobre (2011)Assume thatAandA′are two matrix *-algebras andϕ:A↦A′a matrix *-isomorphism. Moreover assume that symmetric matricesM0,…,Mk∈Aand a vectory∈Rkare given. One now hasM0+∑i=1kyiMi⪰0⇔ϕ(M0)+∑i=1kyiϕ(Mi)⪰0,where ‘⪰0’ means ‘Hermitian positive semidefinite’.In practice, this means that we may often replace the matrices Miby block diagonal matrices ϕ(Mi) with block sizes much smaller than the size of Mi. This block-diagonal structure may in turn be exploited by interior point solvers.The following example illustrates the definitions above, and will be used later on.Example 8Consider the complete k-partite graph Km,…,mwith n=mk, and letG=Aut(Km,…,m)be the automorphism group of Km,…,m. The centralizer ring ofG[1]is a 12-dimensional subspace ofCn×nand has the following basis. (The matrices A6,…,A12 all have the same block structure, and subscripts that indicate size are therefore only indicated in full for A1 to A6.)A1=101×n-10n-1×10n-1×n-1,A2=011×m-101×(k-1)m0n-1×10n-1×m-10n-1×(k-1)m=A3T,A4=001×m-111×(k-1)m0n-1×10n-1×m-10n-1×(k-1)m=A5T,A6=001×m-101×m0m-1×1Im-10m-1×m0(k-1)m×10(k-1)m×m-10(k-1)m×(k-1)m,A7=0000J-I0000,A8=00000eT⊗J000=A9T,A10=00000000I⊗I,A11=00000000I⊗(J-I),A12=00000000(J-I)⊗J.The centralizer ringAGis isomorphic toC⊕C⊕C⊕C3×3, and the associated algebra *-isomorphism ϕ satisfies:ϕ(A1)=000000000001,ϕ(A2)=m-1000000000100=ϕ(A3)T,ϕ(A4)=(k-1)m0000000000-10=ϕ(A5)T,ϕ(A6)=100100000000,ϕ(A7)=-100m-200000000,ϕ(A8)=(k-1)m(m-1)0000-10000000=ϕ(A9)T,ϕ(A10)=011000010000,ϕ(A11)=0-1m-10000m-10000,ϕ(A12)=m00-10000k-20000.Finally, the following lemma will be crucial for the symmetry reduction in the following section. We supply a proof, since we could not find this result in the required form in the literature.Lemma 9Assume that the permutation groupG⊂Snacts transitively on {1,…,n}, and that its centralizer ringAGhas a 0–1 basis A1,…,Ad. Assume, moreover, that the centralizer ring of the stabilizer subgroupG[1]has a 0–1 basisA1′,…,Ad′′. Finally, letπk∈Gbe such that πk(k)=1(k=1,…,n). Then, for any t∈{1,…,d′}, there exists an f(t)∈{1,…,d} such that∑k=1nPπkTAt′Pπk=n〈At′,J〉〈Af(t),J〉Af(t).Moreover, f(t)∈{1,…,d} is the unique value such that(9)support(At′)⊆support(Af(t)).If we define the following subsets ofG,Gi={π∈G|π(i)=1}(i=1,…,n),then we have thatπi∈Gi(i=1,…,n). Moreover,G1=G[1],Gi=G[1]∘πi(i=1,…,n), where ‘∘’ denotes the composition operation, and(10)G=⋃i=1nGi,Gi∩Gj=∅ifi≠j.Fix t∈{1,…,d′}, and consider the projection ofAt′ontoAG:PAGAt′=1|G|∑π∈GPπTAt′Pπ=1|G|∑i=1n∑σ∈GiPσTAt′Pσ(by(10))=1|G|∑i=1n∑ρ∈G1(PρPπi)TAt′PρPπi(sinceGi=G1∘πi)=1|G|∑i=1nPπiT∑ρ∈G[1]PρTAt′PρPπi(sinceG1=G[1])=|G[1]||G|∑i=1nPπiTAt′Pπi(sinceAt′∈AG[1])=1n∑i=1nPπiTAt′Pπi(since|G|=n|G[1]|).On the other hand, since {A1/∥A1∥,…,Ad/∥Ad∥} is an orthonormal basis ofAG, one hasPAGAt′=∑i=1d〈At′,Ai〉‖Ai‖2Ai=〈At′,J〉〈Af(t),J〉Af(t),if f(t)∈{1,…,d} is the unique value such that (9) holds. (The uniqueness of f(t) follows from the fact thatG[1]is a subgroup ofG, and therefore each orbital ofG[1]is a subset of some (unique) orbital ofG.) This completes the proof. □We may eliminate the matrix variableX=∑kY(k)from the second level RLT relaxation of (stQP) with SDP constraints to obtain:(stQPSDP+RLT-2)minY(1),…,Y(n)∈Dn∑k=1n〈Q,Y(k)〉|∑k=1n〈J,Y(k)〉=1,Yij(k)fullysymmetric.LetGbe the automorphism group of the matrix Q, i.e.(11)G=Aut(Q)≡{π∈Sn|Qij=Qπ(i),π(j)∀i,j∈{1,…,n}}.Lemma 10Assume that Y(k)(k=1,…,n) are optimal for (stQPSDP+RLT−2). ThenY¯(k)=1|G|∑π∈GPπTY(π(k))Pπ(k=1,…,n)are also optimal.Assume that Y(k) andY¯(k)(k=1,…,n)are as in the statement of the lemma.It is trivial to verify that∑k=1n〈J,Y¯(k)〉=1, and that the matricesY¯(k)(k=1,…,n)are doubly nonnegative, by construction.To show the complete symmetry ofY¯ij(k), consider, for fixed i, j, k∈{1,…,n},Y¯ij(k)=1|G|∑π∈GYπ(i),π(j)(π(k))=1|G|∑π∈GYπ(j),π(k)(π(i))≡Y¯jk(i),where the second equality follows from the complete symmetryYij(k)=Yjk(i)=Yik(j).Finally, sincePπTQPπ=Qfor allπ∈G, one has∑k=1n〈Q,Y(k)〉=1|G|∑π∈G∑k=1n〈PπTQPπ,Y(k)〉=∑k=1nQ,1|G|∑π∈GPπY(k)PπT≡∑k=1n〈Q,Y¯(k)〉.This completes the proof. □The next useful observation is that an optimal Y(k) may be assumed to belong to the centralizer ring of the stabilizer subgroupG[k].Lemma 11There exists an optimal solution of (stQPSDP+RLT−2) that satisfiesY(k)∈AG[k](k=1,…,n).By the last lemma, we may assume that an optimal solution satisfiesY(k)=1|G|∑π∈GPπTY(π(k))Pπ(k=1,…,n).Now fix i, j, k∈{1,…,n}, andσ∈G[k]. One now hasYσ(i),σ(j)(k)=Yσ(i),σ(j)(σ(k))=1|G|∑π∈GYπ(σ(i)),π(σ(j))(π(σ(k))).Setting τ=π∘σ, this yieldsYσ(i),σ(j)(k)=1|G|∑τ∈GYτ(i),τ(j)(τ(k))≡Yij(k).ThusY(k)∈AG[k], as required. □Finally, ifGis transitive, we may assume that the matrices Y(k) (k=1,…,n) are not independent, but may all be written in terms of Y(1), as the next lemma shows.Lemma 12IfGacts transitively on {1,…,n}, then there exists an optimal solution of (stQPSDP+RLT−2) that satisfiesY(k)=PπkTY(1)Pπk,for anyπk∈Gsuch that πk(k)=1 (k=1,…,n).By Lemma 10, we may assume that optimal Y(k) (k=1,…,n) satisfyY(k)=1|G|∑π∈GPπTY(π(k))Pπ(k=1,…,n).Fixπk∈Gsuch that πk(k)=1(k=1,…,n). One now hasPπkTY(1)Pπk=1|G|∑π∈GPπkTPπTYπ(1)PπPπk=1|G|∑π∈G(PπPπk)TYπ(1)PπPπk.Denoting σk=π∘πkso that σk(k)=π(1), this becomesPπkTY(1)Pπk=1|G|∑σk∈GPσkTY(σk(k))Pσk≡Y(k),as required. □We may now simplify problem (stQPSDP+RLT−2) by using the results of the last three lemmas. To this end, let A1,…,Addenote a 0–1 basis ofAG[1]given by the 2-orbits ofG[1].By the results of this section, we may assume that an optimal solution takes the formY(1)=∑i=1dyiAi,Y(k)=PπkTY(1)Pπk=∑i=1dyiPπkTAiPπk(k=2,…,n),for some nonnegative scalar variables y1,…,yd, ifGis transitive. Thus,∑k=1n〈J,Y(k)〉=〈J,Y(1)〉+∑k=2n〈J,PπkTY(1)Pπk〉=n〈J,Y(1)〉,so that the constraint∑k=1n〈J,Y(k)〉=1becomes 〈J, Y(1)〉=1/n.The complete symmetry conditionsYij(k)=Yjk(i)=Yik(j)imply that some of the yivariables are equal. To make this precise, note that:Yij(k)=∑u=1dyu(Au)πk(i),πk(j),Yik(j)=∑v=1dyv(Av)πj(i),πj(k),Yjk(i)=∑t=1dyt(At)πi(j),πi(k).If we fix (i,j,k)∈{1,…,n}3, then there are unique (u,v,t)∈{1,…,d}3 such that1=(Au)πk(i),πk(j)=(Av)πj(i),πj(k)=(At)πi(j),πi(k),and it must hold that yu=yv=yt. Note that one always get the same triple (u,v,t) for a fixed (i,j,k) independently from the choice of permutations πi, πj, πk. Indeed, if πiandπ̃iare inGand both map i to 1, then there is a permutation ρ fromG[1]such thatρπi=πĩ. But Auis in the algebraAG[1], that is, it is invariant under the permutation ρ. Therefore(Au)πi(j),πi(k)=(Au)π̃i(j),π̃i(k).Definition 13We will write u∼v if there exists a triple (i,j,k) such that1=(Au)πk(i),πk(j)=(Av)πj(i),πj(k).Thus the total symmetry condition becomes yu=yvif u∼v.In summary, we may write problem (stQPSDP+RLT−2) in the following form.Theorem 14Consider problem (stQPSDP+RLT−2) and assume thatG=Aut(Q)is transitive. Let A1,…,Addenote the 0–1 basis ofAG[1]. Then the optimal value is given by:miny⩾0n∑i=1dyi〈Ai,Q〉∑i=1dyi〈Ai,J〉=1n,yu=yvifu∼v,∑i=1dyiAi⪰0,where the ‘∼’-relation is fromDefinition 13.It is important to remember that the linear matrix inequality∑i=1dyiAi⪰0may be replaced by∑i=1dyiϕ(Ai)⪰0for any algebra *-isomorphism ϕ with domainAG[1].We now consider the symmetry reduction of (QAPSDP+RLT−2) for the QAPminP∈Πntrace(APTBP)in the case when the n×n symmetric matrices A and B have large automorphism groups.First of all, we may eliminate the matrix variable Y from (QAPSDP+RLT−2), by usingY=1/n∑i,jZ[ij], to obtain the formulation:(QAPSDP+RLT-2)min1n∑i,j=1nA⊗B,Z[ij]s.t.∑i,j=1nIn⊗Ekk,Z[ij]=n,∑i,j=1n〈Ekk⊗In,Z[ij]〉=n,k=1,…,n,∑i,j=1n〈In⊗(Jn-In)+(Jn-In)⊗In,Z[ij]〉=0,(QAPSDP+RLT-2)∑i,j=1n〈Jn⊗Jn,Z[ij]〉=n3,∑k=1nZ[kj]=∑k=1nZ[ik],i,j=1,…,n,Z[ij]∈Dn2,i,j=1,…,n,Z(kp)[ij](lq)=Z(ip)[kl](jq)=Z(ik)[pq](jl),i,j,k,l,p,q=1,…,n.To describe the symmetry, we defineGA≔Aut (A),GB≔Aut (B) andGAB≔Aut (A⊗B) as in (11).The following results are analogous to the results for the symmetry reduction of the standard quadratic program. Where possible, we therefore omit the proofs.Lemma 15Let Z[ij](i,j=1,…,n) be an optimal solution of (QAPSDP+RLT−2), and letπA∈GAandπB∈GB. ThenZ∼[ij]=(PπA⊗PπB)TZ[πA(i),πB(j)](PπA⊗PπB)(i,j=1,…,n)is also optimal.One hasIn⊗Ekk,Z∼[ij]=In⊗PπBEkkPπBT,Z[πA(i),πB(j)]=In⊗EπB-1(k),πB-1(k),Z[πA(i),πB(j)],so that∑i,j=1n〈In⊗Ekk,Z∼[ij]〉=∑i,j=1nIn⊗EπB-1(k),πB-1(k),Z[πA(i),πB(j)]=∑i,j=1nIn⊗EπB-1(k),πB-1(k),Z[i,j]=n.In the same way, one may show that∑i,j=1n〈Ekk⊗In,Z∼[ij]〉=n.The matrices I, J−I are invariant under all row and column permutations, so that the constraints∑i,j=1n〈In⊗(Jn-In)+(Jn-In)⊗In,Z[ij]〉=0,∑i,j=1n〈Jn⊗Jn,Z[ij]〉=n3are satisfied byZ[ij]=Z∼[ij].The matricesZ∼[ij](i,j=1,…,n)are doubly nonnegative, by construction. Moreover, for fixed j∈{1,…,n},(12)∑i=1nZ∼[ij]=∑i=1n(PπA⊗PπB)TZ[πA(i),πB(j)](PπA⊗PπB)=(PπA⊗PπB)T∑k=1nZ[k,πB(j)](PπA⊗PπB).Similarly, for fixed i∈{1,…,n},(13)∑j=1nZ∼[ij]=∑j=1n(PπA⊗PπB)TZ[πA(i),πB(j)](PπA⊗PπB)=(PπA⊗PπB)T∑k=1nZ[πA(i),k](PπA⊗PπB).Since∑kZ[i,k]=∑kZ[k,j]for all i, j, the expressions in (12) and (13) are equal. Consequently, the constraint∑k=1nZ∼[kj]=∑k=1nZ∼[ik]is satisfied for all i, j.The tensorZ∼is also fully symmetric, sinceZ∼kp[ij](lq)=ZπA(k),πA(p)[πA(i),πB(j)](πB(l),πB(q))=ZπA(i),πA(p)[πA(k),πB(l)](πB(j),πB(q))=Z∼ip[kl](jq),etc. Finally, the objective value atZ∼[ij]is1n∑i,j=1n〈A⊗B,Z∼[ij]〉=1n∑i,j=1nPπATAPπA⊗PπBTBPπB,Z[πA(i),πB(j)]=1n∑i,j=1n〈A⊗B,Z[ij]〉.This completes the proof. □If Z[ij](i,j=1,…,n) denotes an optimal solution of (QAPSDP+RLT−2), thenZkp∗[ij](lq)=1|GAB|∑πA∈GA∑πB∈GBZπA(k),πA(p)[πA(i),πB(j)](πB(l),πB(q))is also optimal.The result follows immediately from the fact that the optimal set of (QAPSDP+RLT−2) is convex. □The next result is similar to Lemma 11, and its proof is therefore omitted.Lemma 17Problem (QAPSDP+RLT−2) has an optimal solution that satisfiesZ[ij]∈AGAB[i,j], whereGAB[i,j]⊂Sn2is the group with permutation matrix representation{PπA⊗PπB|πA∈GA[i],πB∈GB[j]}.The next lemma is similar to Lemma 12, and shows that – under suitable symmetry assumptions – we may write all the Z[ij] in terms of Z[11]. Once again, we omit the proof, since it is similar to that of Lemma 12.Lemma 18Assume thatGAandGBact transitively on {1,…,n}. LetπkA∈GAandπkB∈GBmap k to 1 (k=1,…,n). Then there exists an optimal solution of (QAPSDP+RLT−2) that satisfiesZ[ij]=PπiA⊗PπjBTZ[11]PπiA⊗PπjB(i,j=1,…,n).In what follows we let{A1,…,AdA}and{B1,…,BdB}denote the 0–1 bases of the centralizer rings ofGAandGBrespectively. Moreover, we letA1′,…,AdA′′denote the 0–1 basis of the centralizer ring ofGA[1], and defineB1′,…,BdB′′similarly. By the last lemma, we may now write the Z[ij] in terms of these bases as follows:Z[11]=∑p=1dA′∑q=1dB′zpqAp′⊗Bq′,and, consequently,(14)Z[ij]=∑p=1dA′∑q=1dB′zpqPπiA⊗PπjBTAp′⊗Bq′PπiA⊗PπjB=∑p=1dA′∑q=1dB′zpqPπiATAp′PπiA⊗PπjBTBq′PπjB.Next, we consider the total symmetry conditions for the Z[ij]. Recalling thatZ(αβ)[ij](γδ)=[xijxαγxβδ]L, the total symmetry conditions are(15)Zαβ[ij](γδ)=Zβi[αγ](δj)=Ziα[βδ](jγ)together with Z[ij]=(Z[ij])T, where all indices range from 1 to n.Clearly, the total symmetry conditions will translate to certain variables zpqbeing equal. In particular, for every index set (i,j,α,β,γ,δ) there is exactly one pair (p,q) such thatZαβ[ij](γδ)=zpq. In particular, one hasZαβ[ij](γδ)=zpqiffPπiATAp′PπiAαβ=1andPπjBTBq′PπjBγδ=1.To proceed, we require some notation analogous to that of Definition 13.Definition 19We define two relations ∼1Aand ∼2Athat partition1,…,dA′as followsp∼1Ap̃⇔∃(i,α,β):PπiATAp′PπiAαβ=1andPπαATAp̃′PπαAβi=1,p∼2Ap̃⇔∃(i,α,β):PπiATAp′PπiAαβ=1andPπβATAp̃′PπβAiα=1,where1⩽p,p̃⩽dA′, and 1⩽i, α, β⩽n.Similarly, we define two relations ∼1Band ∼2Bthat partition1,…,dB′as followsq∼1Bq̃⇔∃(j,γ,δ):PπjBTBq′PπjBγδ=1andPπγBTBq̃′PπγBδj=1,q∼2Bq̃⇔∃(j,γ,δ):PπjBTBq′PπjBγδ=1andPπδBTBq̃′PπδBjγ=1,where1⩽q,q̃⩽dA′, and 1⩽j, δ, γ⩽n.We now state the final form of the total symmetry conditions. The proof is an easy consequence of (14) and (15).Lemma 20Using the notation inDefinition 19, the total symmetry conditions(15)become:(16)zpq=zp̃q̃⇔(p∼1Ap̃andq∼1Bq̃)or(p∼2Ap̃andq∼2Bq̃).The final step in the symmetry reduction of problem (QAPSDP+RLT−2) is to rewrite the constraints:(17)∑k=1nZ[kj]=∑k=1nZ[ik](i,j=1,…,n).Using (14), the left-hand-side may be written as(18)∑k=1nZ[kj]=∑p=1dA′∑q=1dB′zpq∑k=1nPπkATAp′PπkA⊗PπjBTBq′PπjB.By Lemma 9,∑k=1nPπkATAp′PπkA=n〈Ap′,J〉〈AfA(p),J〉AfA(p)where fA(p)∈{1,…,dA} is the unique value such that supportAp′⊆support(AfA(p)). Moreover, we haveBs=∑q∈IB(s)Bq′for some index setIB(s)⊂1,…,dB′. In particular, if we define fBanalogously to fA, then IB(s)={q∣fB(q)=s}.Using these relations, Eq. (18) becomes∑k=1nZ[kj]=∑p=1dA′∑q=1dB′zpqn〈Ap′,J〉〈AfA(p),J〉AfA(p)⊗PπjBTBq′PπjB.In a similar way, one may show that∑k=1nZ[ik]=∑p=1dA′∑q=1dB′zpqPπiATAp′PπiA⊗n〈Bq′,J〉〈BfB(q),J〉BfB(q).Equating coefficients of Ar⊗Bs(1⩽r⩽dA,1⩽s⩽dB) in the last two expressions, we find that (17) will hold if and only if∑p¯:fA(p¯)=r〈Ap¯′,J〉〈Ar,J〉zp¯q=∑q¯:fB(q¯)=s〈Bq¯′,J〉〈Bs,J〉zpq¯∀p∈IA(r),q∈IB(s)(1⩽r⩽dA,1⩽s⩽dB).We end this section by stating the final reformulation of the relaxation (QAPSDP+RLT−2) as a theorem.Theorem 21Consider the QAP problemminP∈ΠntraceAPTBPand assume that Aut (A) and Aut (B) act transitively on {1,…,n}. Let{A1,…,AdA}and{B1,…,BdB}denote the 0–1 bases of the centralizer rings ofGA≔Aut (A) andGB≔Aut (B) respectively. Moreover, letA1′,…,AdA′′denote the 0–1 basis of the centralizer ring ofGA[1], and defineB1′,…,BdB′′similarly.Assume thatπkA∈GAare given such thatπkA(k)=1(k=1,…,n), and defineπkB∈GBin the same way.Then the optimal value of problem (QAPSDP+RLT−2) is given byminn∑r=1dA′∑s=1dB′zrs〈A,Ar′〉〈B,Bs′〉s.t.∑r=1dA′∑s=1dB′zrstraceAr′Bs′ii=1n(i=1,…,n),∑r=1dA′∑s=1dB′zrstraceBs′Ar′ii=1n(i=1,…,n),∑r=1dA′∑s=1dB′zrstraceAr′〈J-I,Bs′〉+traceBs′〈J-I,Ar′〉=0,∑r=1dA′∑s=1dB′zrs〈J,Ar′〉〈J,Bs′〉=n,∑p¯:fA(p¯)=r〈Ap¯′,J〉〈Ar,J〉zp¯q=∑q¯:fB(q¯)=s〈Bq¯′,J〉〈Bs,J〉zpq¯∀p∈IA(r),q∈IB(s)(1⩽r⩽dA,1⩽s⩽dB),∑p=1dA′∑q=1dB′zpqAp′⊗Bq′⪰0,zpq=zp̃q̃ifp∼1Ap̃andq∼1Bq̃orp∼2Ap̃andq∼2Bq̃,z⩾0,where•the relations ‘∼1A’, etc. are defined inDefinition 19,fAand fBcorrespond to f inLemma 9for the groups Aut (A) and Aut (B) respectively,for r∈{1…,dA} and s∈{1,…,dB}, IA(r)={p∣fA(p)=r}, and IB(s)={q∣fB(q)=s}.If we have algebra *-isomorphisms ϕAand ϕBdefined onAGA[1]andAGB[1]respectively, then we may replace the linear matrix inequality∑p=1dA′∑q=1dB′zpqAp′⊗Bq′⪰0in the above formulation by∑p=1dA′∑q=1dB′zpqϕAAp′⊗ϕBBq′⪰0. As before, this may lead to smaller, block diagonal matrices in practice.In this section we will show how the symmetry reduction works for some specific (stQP) and (QAP) problems.We will first consider maximum stable set problems on symmetric graphs formulated as (stQP) problems, followed by QAP formulations of certain graph partition problems on symmetric graphs.An important application of (stQP) is the maximum stable set problem in combinatorial optimization. Recall that a stable set of a graph G=(V,E) is a subset of V′⊂V such that no two vertices in V′ are adjacent. The stability number α(G) of G is the cardinality of a maximum stable set in G. By the Motzkin–Straus theorem (Motzkin & Straus, 1965), one has(19)1α(G)=minx∈ΔxT(A+I)xwhere A is the adjacency matrix of G.The so-called ϑ′(G) upper bound on α(G) is defined asα(G)⩽ϑ′(G)≔max{〈J,X〉|〈A+I,X〉=1,X∈D|V|},where D∣V∣ is the doubly nonnegative cone inR|V|×|V|as before. The ϑ′(G) bound corresponds to our (stQPSDP+RLT−1) bound when applied to problem (19) in the following sense.Theorem 22see Lemma 5.2 in de Klerk and Pasechnik (2002)Let G=(V,E) be a graph with adjacency matrix A, and let val(G) denote the optimal value of (stQPSDP+RLT−1) with Q=A+I. Then one has1val(G)=ϑ′(G).A similar results holds for the (stQPSDP+RLT−2) bound, since it coincides with the bound p(1), defined in (6), if Q=A+I. The reciprocal of this bound was first studied by de Klerk and Pasechnik (2002), and was called ϑ(1) there. To be precise:(20)α(G)⩽ϑ(1)(G)≔max{〈J,X〉|〈A+I,X〉=1,X∈K|V|∗(1)},where the coneK|V|∗(1)is defined in Section 2.1.Theorem 23Let G=(V,E) be a graph with adjacency matrix A, and let val(G) denote the optimal value of (stQPSDP+RLT−2) with Q=A+I. Then one has1val(G)=ϑ(1)(G), where ϑ(1)is defined in(20).The proof is an immediate consequence of Theorem 2.□Consider now the special case where G is the Hamming graph Hn,ddefined as follows: the vertex set is {0,1}n(viewed as binary words of length n), and two vertices are adjacent if their Hamming distance is less than d. The stability number of Hn,dis mostly denoted by A(n,d), and is of fundamental importance in coding theory. Possibly the most famous upper bound on A(n,d) is the linear programming bound of Delsarte (1972), which coincides with ϑ′(Hn,d), as was shown by Schrijver (1979). By Theorem 22, the reciprocal of the (stQPSDP+RLT−1) bound therefore also coincides with the Delsarte bound. Consequently, the reciprocal of the (stQPSDP+RLT−2) bound (i.e. the ϑ(1)(Hn,d) bound) is at least as strong as the Delsarte bound (and sometimes stronger; cf Table 1).Stronger semidefinite programming bounds were introduced by Schrijver (2005), and this has led to further improvements in Gijswijt et al. (2012) and Laurent (2007).The algebraic symmetry of the Hamming graph Hn,dis well-understood. For our purposes it is important to note thatAAut(Hn,d)is the Bose–Mesner algebra of the Hamming scheme, andAAut(Hn,d)[1]is the Terwilliger algebra of the Hamming scheme. Thus one has dim(AAut(Hn,d))=n+1, and dim(AAut(Hn,d)[1])=n+33, and bases for these algebras are known in closed form; see e.g., Chapter 3 in Gijswijt (2005). Moreover, the Wedderburn decompositions of both algebras are also known in closed form; see (Gijswijt, 2005; Schrijver, 2005) for details.We were therefore able to compute the bound (stQPSDP+RLT−2) for problem (19) for the graph Hn,d, and the reciprocal of the bound (=ϑ(1)(Hn,d)) is shown in Table 1 for some values of (n,d). Our purpose was to show the difference between the bounds obtained by level 1 RLT cuts (the Delsarte bound) and level 2 RLT cuts (the ϑ(1)(Hn,d) bound). Note that a few values of ϑ(1)(Hn,d) were already reported in the paper (Gvozdenović & Laurent, 2007), namely (n,d)∈{(17,4), (17,6), (17,8)}, but no details were given there on the symmetry reduction. Our goal here is therefore to compare the bounds for more (and larger) values of (n,d), and also to give details on the symmetry reduction via Theorem 14.Computation was done on a Dell Precision T7500 workstation with 32GB of RAM memory, using the semidefinite programming solver SDPA-GMP (Nakata, 2010).The column A(n,d) in Table 1 contains the best known upper and lower bounds on A(n,d) as taken from the table maintained by Andries Brouwer at http://www.win.tue.nl/aeb/codes/binary-1.html for n⩽28. This table is an update of the table published in Best, Brouwer, MacWilliams, Odlyzko, and Sloane (1978); see also (Agrell, Vardy, & Zeger, 2001). For n>28 the bounds were taken from MacWilliams and Sloane (1977, Appendix A).Note that the ϑ(1)(Hn,d) bound is stronger than the Delsarte bound (Delsarte, 1972) for all instances in the table where the Delsarte bound is not tight, but not as strong as the best known bound for n⩽27. For the values (n,d)∈{(28,12), (30,8), (30,12), (30,14)}, ϑ(1)(Hn,d) coincides with the strongest known bound. (The sources of the strongest bounds for these cases are given in Agrell et al. (2001).) Unfortunately, we were not able to find values of (n,d) where ϑ(1)(Hn,d) improves on the best known upper bound on A(n,d).Finally, we wish to emphasize that computing ϑ(1)(Hn,d) is intractable without the use of symmetry reduction for all but the smallest values of n and d. This is because the number of vertices in the Hamming graph H(n,d) equals 2n, and the size of the SDP matrix variables in the original formulation of ϑ(1)(Hn,d) would therefore be of the order 22n.In this section we will present results for maximum and minimum k-section problems on graphs, formulated as QAPs.Recall that the maximum (resp.minimum) k-section problem, for a graph G=(V,E) on n=∣V∣ vertices and with adjacency matrix A, is to partition the vertices V into k sets of equal cardinality m≔n/k, such that the number of edges between partitions is a maximum (resp.minimum).The QAP reformulation of these problems works as follows: consider the adjacency matrix, say B, of Km,…,m(with any fixed labeling of the vertices), e.g.(21)B≔(Jk-Ik)⊗Jm.If P is a permutation matrix that defines a re-labeling of the vertices, then the adjacency matrix after re-labeling is PTBP.The QAP reformulation of max k-section is therefore given by:(22)12maxP∈Π|V|trace(APTBP),and min k-section is obtained by replacing ‘max’ by ‘min’.An SDP bound for min/max k-section by Karisch and Rendl (1998) is known to coincide with the (QAPSDP+RLT−1) bound considered here, as was shown in Dobre (2011); see also (Sotirov, 2012, Theorem 13). Our goal here is to improve on this bound by computing the stronger (QAPSDP+RLT−2) bound.We will consider min/max k-section problem on strongly regular graphs. Recall that the adjacency matrix A of a strongly regular graph has exactly two distinct eigenvalues associated with eigenvectors orthogonal to the all-ones vector. These eigenvalues are called the restricted eigenvalues, and are usually denoted by r>0 and s<0. A strongly regular graph is completely characterized by the values (n=∣V∣,κ,r,s), where κ is the valency of the graph.For strongly regular graphs, the Karisch and Rendl (1998) bound has a closed form expression, as shown in de Klerk E., Pasechnik, Dobre C., and Sotirov, (2012). Since the closed form expression was only derived for the maximum k-section bound in de Klerk E. et al. (2012), we state the expression here for the minimum k-section bound as well. The proof is similar to that of de Klerk E. et al. (2012), Theorem 7, and is therefore omitted.Theorem 24[cf.Theorem 7 in de Klerk E. et al. (2012)] Let G=(V,E) be a strongly regular graph with parameters (n=∣V∣,κ,r,s) where r and s are the restricted eigenvalues, and κ is the valency. Let an integer k>0 be given such that m=n/k is integer. The Karisch–Rendl bound on the minimum k-section of G is now given by(23)|E|1-minn-κ-1-(s+1)(m-1)-s(n-κ-1)-(s+1)κ,(m-1)/κ.Similarly, the Karisch–Rendl bound on the maximum k-section of G is given by(24)12min{(n-m)(κ-s),κn}.Maximum k-section problems in strongly regular graphs are of interest, since they are related to so-called Hoffman colorings and spreads of these graphs; see (Haemers & Tonchev, 1996) for details and definitions.We first present results for the Higman–Sims graph (Higman & Sims, 1968), where(n=|V|,κ,r,s)=(100,22,2,-8).The max k-section problem on this graph was studied in de Klerk E. et al. (2012), and the best known upper bound of max 4-section was obtained there. In particular, it is known that the Higman–Sims graph has a 4-section into four components of five 5-cycles each. Thus there is a 4-section of weight 1000, but this is not known to be a maximum; for more information on this graph, see the discussion on the web page maintained by Andries Brouwer: http://www.win.tue.nl/aeb/graphs/Higman-Sims.htmlIn Tables 2 and 3we compare different bounds on various max k-section and min k-section problems on the Higman–Sims graph respectively.We computed the bound (QAPSDP+RLT−2) for the max/min k-section of the Higman–Sims graph for several values of k. In order to do so, we used the symmetry of the Higman–Sims graph described in de Klerk E. et al. (2012). Moreover, we used the symmetry of B as described in Example 8.Computation was done on a PC with 8GB RAM memory and an Intel(R) Core (TM)2 Quad CPU Q9550 processor, using the semidefinite programming solver SeDuMi (Sturm, 1999) under Matlab 7 together with the Matlab package YALMIP (Löfberg, 2004).The lower bounds in Table 2, and the upper bounds in Table 3 were obtained by using a iterative local search QAP heuristic.The (QAPSDP+RLT−2) bound gave improvements for max 4-section, min 20-section, and min 25-section. Note that the upper and lower bounds for min 25-section coincide, proving optimality.Moreover, it is worth noting that the computational time required was less than a second for each instance. (The computational time for the Karisch–Rendl bound is negligible, due to its closed form expression in (23).) This shows that it is indeed possible to compute the (QAPSDP+RLT−2) bound when the QAP problem has suitable symmetry.Similar results are shown in Table 4, for min/max 11-section on another strongly regular graph, namely the Cameron graph (Brouwer, 1986) with parameters (n=∣V∣,κ,r,s)=(231,30,9,−3); see also http://www.win.tue.nl/aeb/graphs/Cameron.html for more details on this graph. The column ‘Heuristic’ gives the best heuristic solutions that were obtained with the iterative local search heuristic (i.e. the heuristic solution provides a lower bound for the maximization problem and an upper bound for minimization). For the min-11-section problem, the (QAPSDP+RLT−2) bound is strictly better than the Karisch–Rendl bound (23). Once again, the computational time required to compute the (QAPSDP+RLT−2) bound is of the order of a second after symmetry reduction.

@&#CONCLUSIONS@&#
