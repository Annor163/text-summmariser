@&#MAIN-TITLE@&#
Post-processing approaches for improving people detection performance

@&#HIGHLIGHTS@&#
A people detection filtering subtask with people-background segmentation.Fusion of seven independent people detectors at decision-level.Extensive evaluation of proposed people detection post-processing approaches.

@&#KEYPHRASES@&#
People detection,People-background segmentation,Segmentation confidence map,Segmentation mask,Decision-level fusion,Fusion methods,

@&#ABSTRACT@&#
People detection in video surveillance environments is a task that has been generating great interest. There are many approaches trying to solve the problem either in controlled scenarios or in very specific surveillance applications. We address one of the main problems of people detection in video sequences: every people detector from the state of the art must maintain a balance between the number of false detections and the number of missing pedestrians. This compromise limits the global detection results. In order to reduce or relax this limitation and improve the detection results, we evaluate two different post-processing subtasks. Firstly, we propose the use of people-background segmentation as a filtering stage in people detection. Then, we evaluate the combination of different detection approaches in order to add robustness to the detection and therefore improve the detection results. And, finally, we evaluate the successive application of both post-processing approaches. Experiments have been performed on two extensive datasets and using different people detectors from the state of the art: the results show the benefits achieved using the proposed post-processing techniques.

@&#INTRODUCTION@&#
Within the computer vision field, particularly in the research area of digital image and video processing, there exists a rich variety of algorithms for segmentation, object detection, event recognition, etc., which are being used in security systems. People detection is one of the most challenging problems in this field. The complexity of the people detection problem is mainly based on the difficulty of modeling persons because of their huge variability in physical appearances, articulated body parts, poses, movements, points of view and interactions among different people and objects. This complexity is even higher in real world scenarios such as airports and malls, which often include multiple persons, multiple occlusions and background variability.The main contribution presented in this paper is the application of two subtasks of people detection post-processing. The first one is based on the people-background segmentation. People-background segmentation gives us information about where there are not people in the scene. We can use this information to eliminate or, at least, reduce the number of false positives. The second one is based on the combination at decision-level of multiple people detectors from the state of the art in order to take advantage of their independent strengths and at the same time reduce their drawbacks and limitations. And, finally, we also evaluate the successive application of both post-processing approaches in order to combine both improvements.The remainder of this paper is structured as follows: Section 2 describes the related state of the art; Sections 3 and 4 describe the two different proposed approaches; Section 5 discusses the experimental results. Finally, Section 6 summarizes the main conclusions and future work.As discussed previously, this article is focused on people detection post-processing approaches. For this reason, the following sections include a brief state of the art of people detection and selected post-processing approaches.Every people detection approach consists mostly of two phases: firstly, the design and training (if training is required) of a person model based on characteristic parameters such as motion, dimensions, and silhouette. Secondly, the adjustment of this person model to the candidates to be person in the scene. All candidates that adjust to the model will be detected or classified as person, whilst all the others will not be detected or classified as person. Therefore, these two main critical tasks of people detection (object detection and person model) determine the global detection performance.There are two main conventional object detection approaches: one based on some kind of segmentation of the scene in foreground (objects) and background [1–13] and one based on an exhaustive scanning approach [14–42]. There are also some approaches that try to combine both approaches together [43,44]. In any case, the result of this stage is the location and dimension (bounding box or blob) of the different objects candidates to be a person.In relation to the chosen person model, there are two main discriminative information sources to characterize the people model: appearance and motion. Nowadays in the existing literature, most methods are only based on appearance information or they add robustness to the detection with motion information through tracking algorithms. However, human appearance varies due to environmental factors such as light conditions, clothing, and contrast, apart from the huge intrinsic people variability such as different heights, widths, and poses. For these reasons, there are some approaches which try to avoid these factors using only motion information [1,16].There are many approaches that use appearance information to define the person model. This is because appearance is more discriminant than motion. We classified the appearance models according to simplified human models or complex models. There are simple person models that define the person as a region or shape, i.e., holistic models [2–10,14,15,17–20,23–38,42] and more complex models that define the person as combination of multiple regions or shapes, i.e., part-based models [11–13,43,44,21,22,25,39–41]. Although the vast majority of approaches are mainly based on appearance information, there are some approaches that combine appearance and motion information in order to improve the detection results. Some authors combine appearance and motion expanding previous detectors based on appearance to more than one frame [14,17,19]; in this way they are able to easily introduce motion information in the person model and add robustness to the detector.Lately, the most popular approaches (detection-by-tracking approaches) are those that combine detection and tracking in order to improve the detection results [2,15,18,20–30]. In this case, the motion information is not implicitly part of the person model but it is still useful in order to filter or extrapolate detections over time. On the other hand, [28,30] not only combine detection and tracking information but also propose the combination of two independent and implicit person models: one model based on appearance and another model based on motion.Traditionally, the typical additional preprocessing subtasks in people detection are not oriented to one specific processing task, i.e., they are oriented to enhance/adapt/reduce the video information before being analyzed. For example: camera motion compensation, camera calibration, noise removal, etc. In turn, the typical additional post-processing subtasks are applied over the detection outcome. They are oriented to filter or verify the final detections using any additional information source. The most typical ones are those based on tracking information [45,25,30] which study the detections evolution over time. Other approaches use some kind of scene/contextual restriction (spatial, people size, symmetry, etc.) or motion restrictions. In relation to scene restrictions, Geronimo et al. [46] describes different preprocessing subtasks with a clear focus on driver assistance systems such as exposure time, gain adjustments and camera calibration. On the other side, Eiselein et al. [47] proposes the use of motion restrictions combining people detection and optical flow in order to reduce the number of missing detections in a tracking system.Any fusion technique attempts to combine the information from all available sources into a unified representation. This provides better information for human or machine perception as compared to any of the input sources. One of the data fusion models most commonly used in image processing applications is the three-level fusion model. It is based on the levels at which information is represented [48]. This model classifies data fusion into three levels: data or pixel-level fusion, feature fusion and decision fusion. At the lowest level, the fused pixel is derived from a set of pixels from the multiple input sources. At the intermediate level, the features for each object are independently extracted in each information source; these features crate a common feature space for object classification. Finally, at the highest level, decision-level fusion corresponds to combining decisions from several experts.In the case of people detection, every people detector must build up some form of dense confidence map [26] (explicitly or implicitly), which consists of the continuous detection confidence score for each location and scale. Felzenszwalb et al. [41] combines or fuses the confidence map of several independent body parts at pixel-level in order to obtain a final confidence map. There are some approaches that combine or fuse more than one feature at feature-level in order to improve the detection results: [14,17] combine appearance and motion expanding previous features based on appearance to more than one frame, whilst Gan and Cheng [49] uses the feature HOG-LBP (combination of the HOG [33] and LBP [50] features). Finally, every people detector must compare the previously defined/trained person model with the input image and make a final decision according to a similarity criterion. There are some approaches that combine or fuse multiple detectors at decision-level using multi body part detectors [39] or detectors [28].In this work, we evaluate two new subtasks of people detection post-processing and their successive application in typical video surveillance environments (see Fig. 1). The first one is based on the people-background segmentation [51]. The second one is the combination or fusion of up to six independent, appearance based people detectors at decision-level and their combination with a motion based people detector. In any case, the proposed post-processing subtasks are based only on some kind of people detection information. Therefore, they can be considered as any other additional post-processing step in any people detection system, i.e., they do not interfere or are independent of any other additional improvement using tracking information, scene/contextual restrictions, etc.As already mentioned, every people detector from the state of the art must keep a balance between Precision and Recall rates. For this reason, the global detection performance is mainly limited by the number of possible false detections. Our main idea consists in reducing or relaxing this limitation using people-background segmentation. The proposed filtering approach has been implemented as a post-processing, but it can be used as either a preprocessing or post-processing stage.People-background segmentation [51] is a two-class segmentation ensuring that no people or body parts are appearing in the background class. This type of segmentation is useful not only as a people detection preprocessing or post-processing step, but also for other video analysis processes such as tracking and people density estimation. While the focus of person detection approaches are on obtaining a high detection performance and on reducing false positive detections. People-background segmentation aims at determining the areas without people in the scene by giving a higher penalty to pixels incorrectly classified as background. This results in a segmentation mask with a bias on the background as opposed to a segmentation with a bias on people.The chosen people-background segmentation method [51] uses the DTDP detector [41] in order to detect different body parts and extends this representation by appropriately grouping them. Then, they fuse detection confidence maps according to regions that are expected to be covered by the body parts. The corresponding background segmentation mask is finally generated after binarization and post-processing. Therefore, although the people-background segmentation [51] is based on [41], the objective and result are fairly different from the traditional people detection approaches.In this section, we describe the people detection system that includes a post-processing or filtering stage using the people-background segmentation (see Fig. 2). Firstly, people detections could be obtained using any people detector from the state of the art and the people-background segmentation is obtained with the approach proposed in [51] (see previous Section 3.1). Then, both information sources are combined with the aim of eliminating or reducing the number of false detections while keeping, as much as possible, the number of positive detections. The combination of human detection and people-background segmentation is made with the detections and the people-background confidence map (Dependent Extended Body Parts, DEBP, confidence map [51]) or the binarized and post-processed segmentation mask (Dependent Extended Body Parts Post-processed, DEBP-P, segmentation mask [51]).Our main objective is to demonstrate the utility of combining people-background segmentation instead of traditional foreground-background segmentation techniques. The evaluation with other combination techniques or strategies is out of the scope of this paper, but is part of the extensions of this work in the future.Fig. 2 shows one example where two false positives are eliminated using the people-background segmentation1For interpretation of color in Fig. 2, the reader is referred to the web version of this article.1map (black blobs in Fig. 2b) and the people-background segmentation mask (red blobs in Fig. 2c).In general, any people detection outcome always consists of a list of N detections in each frame t. Each detection n (n=1,…,N) is represented by its position (x,y) and dimensions (w,h), i.e., bounding box (or blob)Bn(x,y,w,h)and a People-detection ConfidencePCn(0⩽PCn≤1). In order to process every detection, it has been defined a People Segmentation Confidence associated with every detectionSCn(0⩽SCn≤1). This associated confidence is the averaged segmentation confidence over the corresponding blob. In the case of the DEBP confidence mapC(x,y), it is the averaged of the confidence valuesSCnC.(1)SCnC=1w·h∑x,y∈BnC(x,y)However, in the case of the DEBP-P segmentation maskM(x,y)(a binarized and post-processed version of the DEBP confidence map), the segmentation confidence corresponds to the percentage of pixels classified as people versus the number of pixels classified as backgroundSCnM.(2)SCnM=1w·h∑x,y∈BnM(x,y)Fig. 3showsSCCandSCMexamples over a positive and a false detection.Then the final list of detections consists of the initial N detections with a new associated confidence. This new confidence is the combination of the detection and segmentation confidencesPSCn(0⩽PSCn≤1):(3)PSCn=PCn·SCnFig. 4shows one additional experimental example where it is shown the people detection performance with and without the proposed post-processing step. Fig. 4a shows the Precision–Recall curve, whilst Fig. 4b shows the relation between the true positive and false positive detection rate. In both cases, we can see how the use of the proposed post-processing step improves detection performance. In the first case, the Precision–Recall curve is significantly improved. In the second case, according to the selected threshold: (1) the number of true positives are maintained while reducing significantly false positives (straight line) or (2) the number of true positives is slightly reduced but reducing more the number of false positives (dotted line).In this section, we evaluate the decision-level fusion of independent appearance based people detectors. All detectors or experts are run in parallel, and the final decision is obtained as a combination of local expert responses using fusion methods widely studied in the literature. However, they are adapted to the particular case of people detection fusion at decision-level [52]: average, product, minimum, maximum, median and majority vote.Every people detector has its advantages and disadvantages, mainly because, each of them is based on different object extraction approaches and/or person models. The objective of this work is neither to evaluate individual detectors nor to analyze the correlation among them, but to evaluate that the fusion improves results. Frame by frame, every detector has different results; the main idea consists in keeping the correct true positive detections selected by a certain number of detectors and, at the same time, eliminating those false positive detections selected by only one or a smaller number of detectors.In relation to the selected fusion techniques, our main objective is to validate the utility of combining multiple detectors in order to improve the final results. Therefore, the detectors and fusion techniques can be replaced by others without great difficulty. The use of different modules (detectors or fusion techniques) will vary the overall performance of the system, but the combination of detectors will be useful for improving the system. The evaluation with other detectors or more complex fusion techniques or strategies is out of the scope of this paper, but is part of the extensions of this work in the future.In order to combine or fuse the different detectors, firstly, it is necessary to find matches or correspondences between every detector with the other detectors; the chosen matching criterion is the Multiple Hypotheses Simplification Criteria (MHSC) [30]. The MHSC allows us to compare hypotheses at different scales using the three evaluation criteria defined by Leibe et al. [53]: relative distance, cover and overlap. The relative distance (dr) measures the distance between the bounding box centers in relation to their size; cover and overlap measure how much of one bounding box hypothesis is covered by the other and vice versa (see Fig. 5). A matching is considered true ifdr≤0.5(corresponding to a deviation up to 25% of the true object size) and cover and overlap are both above 50%.Every people detector l has generally a different outcomeNlin each frame t. The number of detections and the detections themselves are not always matched between approaches (there is no unequivocal relationship between detectors’ outcomes), so we are not able to apply directly the traditional fusion techniques [52]: average, product, minimum, maximum, median and majority vote. Instead, we evaluate the use of the five first mentioned fusion techniques but taking into account the minimum number of matches required in the fusion (variation of majority vote) in order to validate the fusion. Therefore, we perform the fusion and evaluate the five fusion techniques for each possible number of matches m (m=1,…,L). Assuming that one match corresponds actually to no matching, i.e., the detection is presented in only one detector. The final outcome is again a list ofNoutdetections, where each detection n (n=1,…,Nout) is represented by three components: (1) the matched averaged bounding boxBnout, (2) the People-detection Confidence resulting to apply the corresponding fusion techniquePCnout(0⩽PCnout≤1) and (3) the corresponding number of matchesmnout. Each final bounding boxBnoutis obtained as the average of the respective matched bounding boxes, whilst each final People-detection ConfidencePCnoutis obtained applying the corresponding fusion technique over the People-detection Confidence of the respective matched bounding boxes.Fig. 6shows a visual fusion example with three detectors, whilst Algorithm 1 shows the corresponding fusion example pseudo-code. Following the example, we have three different people detectors outputsL=3(l=1,2,3)in Fig. 6(a)–(c); therefore, there are five fusion techniques for each possible number of matches (m=1,2,3) among detectors (each detector hasNl=5,4,4detections respectively). The finalloutin Fig. 6(d) is the list of matched detections between the three detectors outputs. For example, the final detection number 7 is the result of matching the detections 5 and 4 from detectors 1 and 3 respectively. The final bounding boxB7outis the average bounding box between both of them(4)B7out(x,y,w,h)=B51(x,y,w,h)+B43(x,y,w,h)2and the final People-detection ConfidencePCnoutis the corresponding fusion technique over them(5)PCnout=fusionPC51,PC43Algorithm 1People detection fusion example pseudo code.•L=3l=1,2,3.•lout=fusionl=1,N1=5B11,PC11,…,B51,PC51.l=2,N2=4B12,PC12,…,B42,PC42.l=3,N3=4B13,PC13,…,B43,PC43.•Nout=7,lout=B1out=B41,PC1out=PC41,m1out=1,…B7out=B51+B432,PC7out=fusion∗PC51,PC43,m7out=2.∗average,product,minimum,maximumormedian.

@&#CONCLUSIONS@&#
Firstly, we have presented a new subtask for people detection filtering.This subtask enhances people detection results making use of the information about where there are not people obtained with people-background segmentation. The experimental results show the performance of our proposal over the proposed evaluation dataset PDds. There is a global detection improvement in almost every category and original people detection approach, being this improvement more clear in those scenarios with medium or high background complexity. It is logical because those scenarios are more likely to generate false detections. The results also show how the use of motion in addition to our approach obtains the best final results.Secondly, we have evaluated the combination or fusion of six independent appearance based people detectors at decision-level. We have also evaluated their combination with a motion based people detector. In order to fuse the different detectors, we have evaluated a multiple matching criteria and the application of traditional fusion techniques: average, product, minimum, maximum and median. The experimental results show the performance of our proposed approach with the mentioned fusion techniques. The product method shows clearly worse results, whilst the average method provides slightly better results than the other three methods. There is a global detection improvement in every category and original people detection approach. This improvement is more clear in those scenarios with higher complexity, since those scenarios are more likely to generate false detections and missing detections. Again, the results show how the use of motion in addition to the proposed fusion obtains the best final results.And, finally, we have also evaluated the successive application of both post-processing approaches over both chosen evaluation datasets from the state of the art: PDds and PETS2009. The results show the additional improvements obtained in all the cases thanks to the combination of both post-processing stages.As future work, we will try to improve the segmentation confidence using its evolution over time or its combination with another more traditional segmentation strategy: color based, motion based, etc. After showing that this processing allows improving detection results, we will study the use of the people-background segmentation as a preprocessing state in order to maintain/reduce computation cost. In addition, other combinations of detection and segmentation confidences may be explored. In relation to the fusion post-processing approach, we will explore other more complex fusion possibilities, not only fixed fusion rules but also trainable fusion rules or adaptive weights based on online quality estimation, and not only parallel fusion schemes but also cascade, hierarchical or hybrid. It is clear that “independently built” detectors exhibit positive correlation, and this is attributed to the fact that difficult parts of the decision space are difficult for all detectors. So we also propose to explore other independent detectors (e.g., based on motion) or other fusion techniques robust to decision correlations. Finally, we also propose a further evaluation including other different evaluation setups (point of view, occupation, etc.), i.e., other complexity categories over the evaluation datasets.