@&#MAIN-TITLE@&#
Robust image hashing with embedding vector variance of LLE

@&#HIGHLIGHTS@&#
We investigate the use of LLE in image hashing.We find that embedding vector variances of LLE are approximately linearly changed by content-preserving operations.We propose a robust image hashing based on this LLE property.Our hashing outperforms some notable algorithms in classification performances.

@&#KEYPHRASES@&#
Image hashing,Robust hashing,Locally linear embedding,Data reduction,Secondary image,CIE,L,⁎,a,⁎,b,⁎,color space,

@&#ABSTRACT@&#
Locally linear embedding (LLE) has been widely used in data processing, such as data clustering, video identification and face recognition, but its application in image hashing is still limited. In this work, we investigate the use of LLE in image hashing and find that embedding vector variances of LLE are approximately linearly changed by content-preserving operations. Based on this observation, we propose a novel LLE-based image hashing. Specifically, an input image is firstly mapped to a normalized matrix by bilinear interpolation, color space conversion, block mean extraction, and Gaussian low-pass filtering. The normalized matrix is then exploited to construct a secondary image. Finally, LLE is applied to the secondary image and the embedding vector variances of LLE are used to form image hash. Hash similarity is determined by correlation coefficient. Many experiments are conducted to validate our efficiency and the results illustrate that our hashing is robust to content-preserving operations and reaches a good discrimination. Comparisons of receiver operating characteristics (ROC) curve indicate that our hashing outperforms some notable hashing algorithms in classification between robustness and discrimination.

@&#INTRODUCTION@&#
Nowadays, the popularization of imaging device, such as smart cell phone, digital camera and scanner, provides us more and more digital images. Consequently, efficient techniques are needed for storing and retrieving hundreds of thousands of images. Meanwhile, it is easy to copy, edit and distribute images via powerful tools and the Internet. Therefore, digital right management (DRM) (image authentication, image forensics, copyright protection, etc.) is in demand. All these practical issues lead to emergence of image hashing. Image hashing is a novel technology for mapping input image into a short string called image hash. It not only allows us to retrieve images from large-scale database, but also can be applied to DRM. In fact, it has been widely used in image authentication [1], digital watermarking [2], image copy detection, tamper detection, image indexing [3], image retrieval, image forensics [4], and image quality assessment [5].Generally, image hashing has two basic properties [6–8]. The first one is perceptual robustness. It requires that, for those visually identical images, image hashing should generate the same or very similar image hashes no matter whether their digital representations are the same or not. This means that image hashing must be robust against content-preserving operations, such as JPEG compression, brightness adjustment, contrast adjustment, watermark embedding and image scaling. The second property is called discrimination. This implies that, image hashing should extract different hashes from different images. In other words, similarity between hashes of different images should be small enough. Note that the two properties contradict with each other [8]. The first property requires robustness under small perturbations, whereas the second property amounts to minimization of collision probability for images with different contents. High performance algorithms should reach a good trade-off between the two properties. In addition to the basic properties, image hashing should have another property when it is applied to specific applications. For example, it should be key-dependent for image authentication [9].Due to the wide use of image hashing, many researchers have paid attention to hashing techniques. For example, Venkatesan et al. [10] exploited statistics of discrete wavelet transform (DWT) coefficients to generate image hashes. This hashing is robust to JPEG compression and small-angle rotation, but sensitive to gamma correction and contrast adjustment. Lefebvre et al. [11] pioneered the use of Radon transform (RT) to hash extraction. This scheme can resist geometric transform, such as rotation and scaling, but its discriminative capability is limited. Kozat et al. [12] viewed images and attacks as a sequence of linear operators and presented an image hashing with two singular value decompositions (SVDs). The SVD–SVD hashing can tolerate geometric transform at the cost of significantly decreasing discrimination. In another study, Swaminathan et al. [13] proposed to calculate image hashes based on coefficients of Fourier–Mellin transform. This algorithm is robust against moderate geometric transforms and filtering. Monga and Mihcak [14] were the first to use non-negative matrix factorization (NMF) to derive image hashing. This method is robust against many popular digital operations, but sensitive to watermark embedding. Tang et al. [15] found invariant relation in the NMF coefficient matrix and exploited it to design hashing. This scheme is resistant to JPEG compression and watermark embedding, but sensitive to image rotation. In another work, Ou et al. [16] used RT combining with discrete cosine transform (DCT) to generate image hashes. The RT–DCT hashing is resilient to image rotation, but its discrimination is not good enough. Kang et al. [17] introduced a compressive sensing-based image hashing. This method is also sensitive to image rotation. Recently, Sun et al. [18] presented a robust image hashing by using relations in the weight matrix of locally linear embedding (LLE). This LLE-based hashing can tolerate JPEG compression, but is fragile to rotation and its discrimination is also not good enough. Tang et al. [19] exploited structural features to extract image hashes and introduced a novel similarity metric for tampering detection. This method is also sensitive to image rotation. In [20], Li et al. extracted image hashes by random Gabor filtering (GF) and dithered lattice vector quantization (LVQ). The GF–LVQ hashing has better performances than the well-known algorithms [13,17], but its discrimination is also not desirable enough. Zhao et al. [21] exploited Zernike moments (ZM) to calculate image hashes. The ZM-based hashing only tolerates rotation within 5°. Tang et al. [22] investigated the use of color vector angle (CVA) and then exploited CVA and DWT to design image hashing. The CVA–DWT hashing is also robust to rotation within 5°, but its discrimination can be improved.Although many hashing algorithms have been reported, there are still some problems in hashing design. For example, more efforts are still needed for developing high performance algorithms reaching a desirable balance between robustness and discrimination. In this work, we propose a novel LLE-based image hashing, which can achieve a good trade-off between robustness and discrimination. The key technique of our work is an innovative use of LLE, which is based on the property that embedding vector variances are approximately linearly changed by content-preserving operations. Since LLE can efficiently learn global structure of nonlinear manifolds and discover compact representations of high-dimensional data, the use of LLE provides our hashing a good discrimination. Many experiments are conducted to validate the efficiency of our hashing. The results illustrate that our hashing is robust against popular digital operations and reaches a good discrimination. Comparisons indicate that our hashing outperforms some notable algorithms in classification between robustness and discrimination.The rest of this paper is organized as follows. Section 2 introduces the proposed image hashing. Section 3 presents experimental results and Section 4 discusses performance comparisons. Finally, conclusions are drawn in Section 5.Our proposed image hashing is a three-step method, whose block diagram is presented in Fig. 1. In the first step, our hashing converts input image into a normalized matrix by preprocessing. In the second step, our method constructs a secondary image from the normalized matrix. Finally, we apply LLE to the secondary image and exploits LLE results to produce image hash. Details of these steps are described as follows.To make a normalized image for constructing secondary image, some digital operations are applied to the input image. Firstly, bilinear interpolation is used to resize the input image to a standard sizeM×M, which makes our method robust against image rescaling. For RGB color image, the resized image is then converted into CIEL⁎a⁎b⁎color space and theL⁎component is taken for representing the resized image. Here, we chooseL⁎component for image representation. This is based on the consideration that, CIEL⁎a⁎b⁎color space is perceptually uniform and theL⁎component closely matches human perception of lightness [23,24]. For each image pixel, letL⁎be color lightness,a⁎andb⁎be chromaticity coordinates, respectively. Thus, color space conversion [23] can be done by the following rules.(1)L⁎={116(Y1/Y0)1/3−16,ifY1/Y0>0.008856903.3(Y1/Y0),otherwise(2)a⁎=500[f(X1/X0)−f(Y1/Y0)](3)b⁎=200[f(Y1/Y0)−f(Z1/Z0)]whereX0=0.950456,Y0=1.0andZ0=1.088754are the CIE XYZ tristimulus values of the reference white point,f(t)is defined as:(4)f(t)={t1/3,ift>0.0088567.787t+16/116,otherwiseandX1,Y1andZ1are the CIE XYZ tristimulus values [24], which are calculated by the equation.(5)[X1Y1Z1]=[0.41250.35760.18040.21270.71520.07220.01930.11920.9502][RGB]where R, G and B are the red, blue and green components of each image pixel, respectively.Next, theL⁎component is divided into non-overlapping blocks with a small sizes1×s1. For simplicity, let M be the integral multiple ofs1, andM1=M/s1. Thus, to make an initial compression, we calculate block mean and use these means to construct a feature matrix as follows.(6)F=[μ1,1μ1,2...μ1,M1μ2,1μ2,2...μ2,M1............μM1,1μM1,2...μM1,M1]whereμi,jis the mean of the block in the i-th row and the j-th column of theL⁎component (1≤i≤M1,1≤j≤M1). This operation not only achieves initial compression, but also makes our method resistant to small-angle rotation, which can be understood as follows. Although small-angle rotation will alter pixel positions, pixels in a small region have similar values and then block means will not be significantly changed. Note that a big block size helps to improve robustness against large-angle rotation. But a bigger block size leads to fewer features in F, which will inevitably hurt discrimination. In experiments, we choose2×2as block size, which can reach a desirable balance between robustness and discrimination. Finally, a rotationally symmetric Gaussian low-pass filter is applied to the matrix F. This is to reduce the influence of digital operations on F. In practice, the element of Gaussian low-pass filter can be calculated by:(7)G(i,j)=G(1)(i,j)∑i∑jG(1)(i,j)in whichG(1)(i,j) is defined as(8)G(1)(i,j)=e−(i2+j2)2σ2where σ is a given standard deviation of the Gaussian distribution. For example, if the filter size is3×3,−1≤i≤1, and−1≤j≤1. Fig. 2presents an instance of the preprocessing withM=512,s1=2, and3×3filter size, where (a) is the original input image, (b) is the resized image, (c) is theL⁎component of (b), (d) is the matrix F, and (e) is its blurred version.To construct a secondary image for data reduction, we randomly select N blocks sizedn×nfrom F under the control of a secret key. We view each block as a high dimensional vector of sizen2×1via concatenating block entries column by column. Letxibe the corresponding vector of the i-th block (1≤i≤N). Thus, we can obtain the secondary image X as follows.(9)X=[x1,x2,…,xN]Note that, during block selection, there can exist overlapping region between blocks. However, the same selected blocks should be discarded since the same vectors are not expected in the secondary image. Compared with the input image, the secondary image has fewer columns. As column number is equal to vector number that is kept unchanged during data reduction, a small vector number helps to make a short image hash. Fig. 3is the schematic diagram of secondary image construction.Locally linear embedding (LLE) [25] is a well-known algorithm for non-linear dimensionality reduction. It can efficiently discover compact representations of high-dimensional data by computing low-dimensional, neighborhood-preserving embeddings and learning global structure of nonlinear manifolds, such as those generated by face images or text documents [25]. LLE has been indicated better performances than some popular methods, such as principal component analysis (PCA) [26] and multidimensional scaling (MDS) [27]. Actually, LLE has been widely used in many applications, such as data clustering [28], video identification [29], gait analysis [30] and face recognition [31].The classical LLE algorithm [25] consists of three steps, i.e., neighbor selection, weight calculation, and low-dimensional embedding vector computation. For simplicity, suppose thatxiis a vector of dimensionality D, whereD=n2and1≤i≤N. Thus, details of these steps are illustrated as follows.(1) Neighbor selection. For each vectorxi(1≤i≤N), its K nearest neighbors are chosen. This can be determined by Euclidean distance betweenxiand the other vectorxj(1≤j≤Nandj≠i) as follows.(10)U(xi,xj)=∑l=1D[xi(l)−xj(l)]2wherexi(l)andxj(l)are the l-th elements ofxiandxj, respectively. Thus, those vectors corresponding to the K smallest distances are the K nearest neighbors ofxi.(2) Weight computation. Calculate the weight matrixW=(Wi,j)N×K. The weight matrix can best linearly reconstructxifrom its nearest neighbors, and the reconstruction errors are computed by the following cost function ε.(11)ε(W)=∑i=1N|xi−∑jWi,jxj|2whereWi,jis the weight betweenxiandxj. In practice, W can be calculated by minimizing the Eq. (11) subject to two constraints as follows. First,Wi,j=0ifxjis not a nearest neighbor ofxi. Second, the sum of those neighbor weights ofxiis 1, i.e.,∑jWi,j=1.(3) Low-dimensional embedding vector calculation. After the weight matrix is obtained, each high-dimensional vectorxiis then mapped to a low-dimensional vectoryiof dimensionality d. This can be done by minimizing the cost function Φ below.(12)Φ(Y)=∑i=1N|yi−∑jWi,jyj|2whereY=[y1,y2,…,yN]is a matrix forming by all low-dimensional embedding vectors. For more details of LLE algorithm, please refer to [25,32]. The MATLAB code of LLE algorithm can be downloaded from the personal website of Roweis [33].Having obtained these low-dimensional embedding vectors, we calculate statistics of each embedding vector to produce a short image hash. Here we choose variance as the feature for representing low-dimensional embedding vector. This is because variance can efficiently measure the fluctuation of vector elements, and we also find the LLE property that embedding vector variances are approximately linearly changed by content-preserving operations. This LLE property will be validated in Section 3.1. The reason of the LLE property is that the effect of content-preserving operations on the change of embedding vector variances is relatively small and like Gaussian noise disturbance. Note that the use of LLE in our work is different from that of [18], which used LLE weight matrix to construct hash but cannot acquire good classification between robustness and discrimination. The variance ofyiis defined as follows.(13)δi2=1d−1∑l=1d[yi(l)−μi]2whereyi(l)is the l-th element ofyiandμiis the mean calculated by the below equation.(14)μi=1d∑l=1dyi(l)To reduce storage, each variance is quantized to an integer as follows.(15)c(i)=Round(δi2×1000)where Round(⋅) is the rounding operation, and1≤i≤N. Next, by a pseudo-random generator, we scramble the integer sequencec=[c(1),c(2),…,c(N)]to make a secure image hash. Specifically, we can set a secret key as the seed of pseudo-random generator and create N random numbers. Then, we sort these N random numbers and use an arrayP[N]to record the original positions of the sorted elements. Therefore, the i-th hash element is obtained by the below equation.(16)h(i)=c(P[i])Finally, our image hash h is obtained as follows.(17)h=[h(1),h(2),…,h(N)]It is clear that our hash consists of N integers. In experiment, we find that each integer only requires 11 bits at most for storage. Therefore, the length of our hash is 11N bits. This will be validated in Section 3.3.Leth1=[h1(1),h1(2),…,h1(N)]andh2=[h2(1),h2(2),…,h2(N)]be a pair of hashes of two images. In this study, the well-known correlation coefficient is exploited to evaluate similarity betweenh1andh2. Specifically, the used correlation coefficient is defined as follows.(18)S(h1,h2)=∑l=1N[h1(l)−m1][h2(l)−m2]∑l=1N[h1(l)−m1]2×∑l=1N[h2(l)−m2]2+Δswhere Δs is a small constant to avoid zero denominator, andm1andm2are the means ofh1andh2, respectively. The range of correlation coefficient is[−1,1]. The greater the correlation coefficient, the more similar the evaluated hashes and then the more similar the corresponding images. If the correlation coefficient is greater than a threshold, the two images of the input hashes are considered as visually identical images. Otherwise, they are the images with different contents. Here, correlation coefficient is chosen as the similarity metric. This is based on the observation that content-preserving operations approximately linearly change the variances of low-dimensional embedding vectors. Section 3.1 will empirically verify this.

@&#CONCLUSIONS@&#
In this work, we have proposed a robust image hashing based on LLE. The key contribution of our work is the innovative use of LLE. As LLE is good at discovering compact representation by learning global structure of input data, it provides our image hashing a desirable discrimination. More specifically, we have observed the LLE property that embedding vector variances are approximately linearly changed by content-preserving operations, so as to measure hash similarity with correlation coefficient. Many experiments have been conducted to validate efficiency of our image hashing. The results have shown that our image hashing is robust to many common digital operations and reaches a good discrimination. ROC curve comparisons with some well-known algorithms have illustrated that our hashing outperforms the compared algorithms in classification performances with respect to robustness and discrimination.