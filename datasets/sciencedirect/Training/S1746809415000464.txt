@&#MAIN-TITLE@&#
Classification of AAMI heartbeat classes with an interactive ELM ensemble learning approach

@&#HIGHLIGHTS@&#
This paper proposes an ensemble method for the classification of AAMI signals.The extreme learning machine classifier is used for ensemble generation.The classifiers output are fused in a nonlinear way using the IOWA operators.The method allows expert interaction during the classification process.The experiments are conducted on five ECG databases.

@&#KEYPHRASES@&#


@&#ABSTRACT@&#
In recent years, the recommendations of the Association for the Advancement of Medical Instrumentation (AAMI) for class labeling and results presentation are closely followed as a possible solution for standardization. Regardless of the class normalization, this standard basically recommends for performance evaluation to adopt inter-patient scenarios, which renders the classification task very challenging due to the strong variability of ECG signals. To deal with this issue, we propose in this paper a novel interactive ensemble learning approach based on the extreme learning machine (ELM) classifier and the induced ordered weighted averaging (IOWA) operators. While ELM is adopted for ensemble generation the IOWA operators are used for aggregating the obtained predictions in a nonlinear way. During the iterative learning process, the approach allows the expert to label the most relevant and uncertain ECG heart beats in the data under analysis and then adds them to the original training set for retraining. The experimental results obtained on the widely used MIT-BIH arrhythmia database show that the proposed approach significantly outperforms state-of-the-art methods after labeling on average 100 ECG beats per record. In addition, the results obtained on four other ECG databases starting with the same initial training set from MIT-BIH confirm its promising generalization capability.

@&#INTRODUCTION@&#
The electrocardiogram (ECG) signal contains valuable information about patient's heart activity. The monitoring and analysis of ECG signals represents an efficient way for the early detection of different cardiac diseases. To this end, many researchers devoted their efforts over the years to develop computer-based methods for arrhythmia detection and classification. Nevertheless, the comparison across most of these methods could not be performed fairly, due to the lack of standardization in the development and evaluation criteria.In recent years, the recommendations of the Association for the Advancement of Medical Instrumentation (AAMI) for class labeling and results presentation are closely followed as a possible solution for standardization [1–6]. Typically, the AAMI standard defines five classes of interest: normal (N), ventricular (V), supraventricular (S), fusion of normal and ventricular (F) and unknown beats (Q). Regardless of the class definition, this standard recommends essentially for performance evaluation to adopt an inter-patient scenarios, which is not usually adopted in most of the works published in the literature. This requirement renders the automatic classification task very challenging as the test subjects are unseen during the classifier design. Although, various feature representation (e.g., morphological, temporal, wavelets, higher order statistics, etc.) as well as many classifiers (e.g., linear discriminant analysis, neural networks, support vector machines, etc.) were used, the results obtained by the automatic methods remain unsatisfactory.To tackle this issue semiautomatic approaches allowing expert interaction were introduced [7–11]. Usually, these approaches train a global classifier on a large dataset and another local-classifier on the first few minutes from the record under analysis labeled by the expert. Then the outputs of both classifiers are fused using voting rules to classify the entire record. However, this mode of labeling does not take into consideration how much are these signals relevant for boosting the classification accuracy. Indeed, the generalization ability of the classifiers depends strongly on the samples that represent well the statistical distribution of the data. So, it would be necessary to design a system that allows us to define better mechanisms for selecting and labelling samples fundamental to the correct discrimination between the set of considered classes.In this work, we propose a novel ensemble method for the interactive classification of AAMI heart beat classes. The choice of ensemble strategies is mainly motivated by their robustness compared to single-based classifier designs [12–16]. Fig. 1provides a general view of the proposed method which is composed of the following iterative steps: (1) ensemble construction, (2) fusion; and (3) ECG beat selection and labeling. For the ensemble construction step, we use the extreme learning machine (ELM) classifier that gained popularity in recent years as an efficient class of learning algorithms for single-hidden layer feedforward neural networks (SLFNs) [16,17]. The main concept behind the ELM lies in the random choice of the SLFN hidden layer weights and biases, i.e. these hidden layer parameters need not be tuned, unlike regular neural networks or SVM variant methods. The output weights are determined analytically, thus the network is solved with very few steps and with low computational cost. Another interesting feature of the ELM is that it provides a unified learning platform with widespread type of feature mappings which could be done either in a known space similar to neural networks or in an infinite space similar to kernel methods. In addition, it can be used for regression and multi-class classification applications directly.For the fusion step, we use the induced ordered weighted averaging (IOWA) operators [18,19]. This nonlinear operator is an extension of the standard OWA operator proposed by Yager [20]. However, the difference is that the reordering step is done using an auxiliary value, called order-inducing variable, rather than using the actual outputs called argument values. To obtain automatically the weights associated with the IOWA fusion operators, we tailor the prioritized aggregation idea to the classification scenario [21]. Finally in the selection and labeling step, unlike state-of-the-art methods we do not allow the user to label the first few minutes but instead we use uncertainty criteria [22] to rank the ECG beats in terms of their ambiguity with respect to the fusion result obtained in the previous step. The most ambiguous samples are given to the expert for labeling and then injected in the training set for retraining. It is expected that this process will increase the generalization ability of the classification system on the difficult samples for the next iterations. The experimental results obtained on the MIT-BIH arrhythmia database show that the proposed system can provide significant improvements in terms of classification accuracy with a reduced number of expert interaction (on average 100 ECG beat per record). In addition, the results obtained on four other ECG databases using the same initial training from MIT-BIH confirm its promising generalization capability.The rest of the paper is organized as follows. Section 2 provides a detailed description of the proposed interactive classification system. The experimental results obtained on five ECG databases from physionet are reported in Section 3. Finally, conclusions and future developments are drawn in Section 4.Let us considerD=Xi,yii=1Na training set composed of N training ECG feature vectors Xiof dimension d (e.g., morphological and temporal features [1,22]) andyi∈1,…,Nois the corresponding class label where Norepresents the number of classes. Given this training set D, we aim to classify a new ECG test record using the interactive classification system shown in Fig. 1. The following algorithm provides a general description of the proposed approach, whereas details descriptions are provided in next subsections.Algorithm 1 Interactive classificationInput:- Training setD=Xi,Yii=1N- Test record:Rec=Xℓℓ=1M- Ensemble size: P- Number of interactions: ITER- Number signals to label at each iteration: NsOutput: Classification result- Step 1: Generate an ensemble of P diverse training sets each of size L from D with k-means; forIter=1:ITER- Step 2: Train P-ELM estimators on the p training sets;- Step 3: Classify Rec by aggregating the P-ELM predictions with IOWAPA (see Algorithm 2);- Step 4: Rank the signals of the test record Rec based on their uncertainty;- Step 5: Ask an expert to label the top ranked Nssignals;- Step 5: Augment the P training sets with these new labeled signals;- Step 6: Output the final classification result.It is well known that the key success in ensemble methods is to design accurate and diverse models. Diversity can be obtained in many ways such as using different classifiers, different feature representations or by sampling strategies. For more details, we refer the reader to [15] for a comprehensive review. In our context, we address this issue by clustering the global training setD=Xi,yii=1Nwith the k-means clustering algorithm. This choice is clearly justified as the commonly used the training set (composed of 22 records of the MIT-BIH arrhythmia database) is very large and highly unbalanced. To this end, for each AAMI class we run the k-means algorithm to group it into Nclust clusters. Then we select the samples closest to the centeroids of each cluster to form a balanced training set of size L=4×Nclust. This process is repeated P times with different initializations to generate P different training sets.As base learning model, we consider in this work the ELM classifier which is characterized by several attractive proprieties: (i) it has a unified formulation for binary, multiclass and regression problems; (ii) the solution of these problems is given in a unified compact form; (iii) the feature mapping could be done either in known space similar to neural networks or in infinite space similar to kernel methods; (iv) for multiclass classification, ELM uses a configuration of multi-output nodes where the number of nodes is equal to the number of classes. Recently, ELM has shown notable results in several applications compared to other kernel methods [17,23].Lethxi∈ℜ1×Nhbe the row output vector of the hidden layer with respect to xiand β∈ℜNh×Nothe output weights that connect the hidden layer with the output layer (which represents the number of classes). Then, the ELM outputfxi∈R1×Nois given by [16]:(1)fxi=hxiβ,i=1,…,L.ELM aims to determine the weights β by minimizing the following objective function:(2)minβ12βF2+C12∑i=1Lei2Subject to the constraints:(3)hxiβ=ηiT,−eiT,i=1,…,L.where*Fis the Frobenius norm, C is a penalty coefficient on the training errors, ei∈ℜNo×1 is the error vector with respect to the ith training sample and ηi∈ℜNo×1 takes 1 for the entry corresponding to the class label yiand 0 elsewhere.The first term in the objective function (2) is used as regularization to avoid over-fitting problems. By substituting the constraints into the objective function, we obtain the following equivalent unconstrained optimization problem:(4)minβ12βF2+C12Y−HβF2whereH=hx1T,…,hxLTT∈ℜL×Nhis the hidden layer output matrix andY=η1,…,ηNrT∈ℜL×Nois the output target matrix built from the target output vectors.The above optimization problem is known as ridge regression or regularized least squares. By setting the gradient with respect to β to zero and solving, we obtain the following closed form solution:(5)β*=HTHTH+IC−1Ywhere I∈ℜNh×Nhis an identity matrix.As a result, the ELM predictionfxℓ∈ℜ1×Nofor a test sample xℓ can be given as follows:(6)fxℓ=hxℓβ*=hxℓHTIC+HHT−1YThen the test sample xℓ will be assigned to the index of the output node which has the highest value.In the kernel space, the prediction associated with the test sample xℓ is given in the following compact form [16]:(7)fxℓ=kxℓ,x1⋮kxℓ,xLTIC+K−1YThe first term of (8) is a row vector of length Nrand represents, the kernel distances between a particular test point and the training samples. In this case, the number of hidden neurons Nhneed not be given as the kernel matrix K=HHT is only related to the training samples. A typical choice of the kernel function is the RBF kernel given by:(8)kxi,xi=exp−γxi−xj2where γ is a parameter inversely proportional to the width of the RBF kernel.During the training phase, the parameters of ELM (i.e., C and γ) can be estimated according to a m-fold cross-validation (CV) procedure [22]. First, we randomly split the training data into m mutually exclusive subsets (folds) of equal size, then we train m times an ELM classifier modeled with predefined values of (i.e., C and γ). Each time we leave out one of the subsets from training, and use it (the omitted subset) only to obtain an estimate of the classification accuracy. Then, the values of C and γ yielding the best average classification accuracy are selected for training the final ELM classifier.In the rest of the paper and for computation convenience we transform the ELM outputs into probabilities using the softmax function. Also we define the decision profile matrixDPxℓ∈ℜP×Noobtained by the P-ELM classifiers for a test ECG signal xℓ by:(9)DPxℓ=f1xℓ⋮fPxℓ=f11⋯f1N0⋮⋯⋮fP1⋯fPN0In the following the same reasoning holds for any particularclass=1,…,Noi.e.,fpk=fp. If we letvp,fpfor p=1, …, P be the predictions generated by the P-ELM classifiers for the class k. Herevp∈ℜis a measure of importance associated with the output probability row vector fp. The IOWA fusion operator is used to aggregate pairs of the formvp,fp. Within these pairsvpis called the order inducing value and fpis called the argument value. An IOWA fusion operator of dimension P is given as follows:(10)spk=∑p=1Pwpfidpwherespk∈ℜrepresent the support obtained for the class k andw=w1,w2,…,wpTis a weighting vector such that∑p=1Pwp=1withwp∈0,1andfid1,fid2,…,fidPare justf1f2,…,fpreordered in descending order of importance based upon the values ofvp.The IOWA operator is a mean-type aggregation operator; it is commutative, monotonic, bounded, and idempotent. It generalizes many important aggregation functions such as weighted arithmetic mean and the OWA operators. It is worth recalling that with the reordering step, the OWA operator is no longer a standard combination of weighted inputs, but rather a piecewise linear function, with its behavior differing on different parts of the domain. Compared to OWA, the IOWA operators provides a more general framework for this reordering process as it is done by using an auxiliary variable called the order inducing value instead of the actual output which is called the argument value. Recently, these nonlinear fusion operators have shown notable results in several application domains compared to linear fusion operator [24–26].An important issue in applications of the IOWA operators is the determination of the order inducing valuevpand vector of weights w. A possible choice forvpis to compute the difference between the maximum and the second maximum values in the row vector fp. The bigger this value, the higher is the confidence in the classification result fpof this test sample.In the literature, various approaches have been suggested for obtaining the weights w such as argument-based methods, optimization methods, and learning from data methods [18], [27,28]. In this work, we propose a simple yet efficient method based on the concept of prioritized aggregation [21]. To this end, we first usevpto establish a prioritization ordering of between the ELM classifiers (i.e., probability output vectors fp) After ranking the classifiers in order of importance, the values of the weight vector w are successively generated in a simple way as follows: we denoteap−fidpfor p=1, …, P and let a0=1, then we define:(11)Tp=Πk=1pak−1forp=1,…,PThen the weights are generated as follows [21]:(12)wp=Tp∑k=1PTkforp=1,…,P.The following algorithm illustrates the main steps of the proposed fusion scheme termed as IWOAPA.Algorithm 2 Fusion with IWOAPAInputs:Decision profile matrixDPxℓfor a test beat xℓ.Outputssp=sp1,sp2,…,No∈ℜNo: Class support vector.Step 1: for p=1:Pvp=first_maxfp−secondmaxfp;endStep 2: Sortvp,p=1,…Pin descending order;Step 3: Set id∈ℜPas the index vector such that id (p) is the index ofpth largest order inducing value;Step 4: fork=1:NoCompute the weight vectorw=w1,w2,…,wPTfor class k according to (11)–(12);Compute the supportspk=∑p=1Pwpfidpfor class k;endStep 5: Assign xℓ to the class with maximum support.It is interesting to note that this fusion scheme has several desirable proprieties: (i) the weights are dynamic and different for each test sample; (ii) the inducing variablevjallows us to rank the classifiers based on their importance; (iii) high and small weight values will be assigned to the most and the least relevant classifiers, respectively.As mentioned previously, most of the works related to AAMI heart beat classification allow the expert to label the first few minutes of the record without taking into consideration how much are these signals relevant for boosting the classification accuracy. In this work, we use a different approach called active learning (AL). In an AL setting, a user is asked to label a set of beats from the record through an iterative process. The key aspect of AL is to rank the ECG beats of a test record according to an appropriate criterion for selecting the most relevant samples to improve the accuracy, while minimizing the user interaction [29–31]. We recall that AL has been previously adopted for ECG classification to deal with scenarios characterized by limited training samples [22]. Here, we mainly investigate two different selection criteria based on entropy and Breaking-Ties (BT).In the first criterion, we calculate for each test beat the entropy value as follows:(13)Exℓ=∑k=1No−spklogspkThen the Nsbeats with the highest entropy values are selected for labeling. High values of entropy means that the ECG beats are classified with low confidence, and thus adding them to the training set can be useful to improve the classifier decision regions in the feature space.The second criterion called Breaking-Ties (BT), which is based on the posterior probabilities of associating a sample to a given class. In a multiclass context, the difference between the two highest class support valuesfirst_maxsp−second_maxspwheresp=sp1,2,…,spNois indicative of the way a sample is handled by the classifier. When the two highest values are close, the classifier confidence is low. Thus, the NSbeats having low difference between the two highest support values are selected for labeling.

@&#CONCLUSIONS@&#
In this paper, we have proposed a novel ensemble approach for the interactive classification of AAMI heart beat classes which: (1) uses a state-of-the-art multiclass ELM classifier for building robust and diverse ensemble; (2) exploits the well founded IOWA aggregation operators for fusing these set of classifiers in a nonlinear way; and (3) provides to the expert the most relevant ECG beats for labeling and then adds them in the training set for retraining. The experimental results obtained on five different databases show that starting from a relatively small initial training set (build from DS1 of MIT-BIH database) the method can provide significant improvements in terms of classification accuracy particularly using the BT selection mode. It can generalize well on other databases (i.e., cross database settings) through the discriminative ECG beats identified during the interaction process. In future developments, we plan to increase the classification accuracy while decreasing the interaction process by exploiting other advanced feature extraction methods; and the definition of new selection criteria particularly suitable for this configuration.