@&#MAIN-TITLE@&#
Improving label fusion in multi-atlas based segmentation by locally combining atlas selection and performance estimation

@&#HIGHLIGHTS@&#
We address the problem of label fusion in multi-atlas based image segmentation.A modification of a previously published label fusion method is proposed.Our method uses estimates of local segmentation accuracy to discard outliers.The method combines advantages of atlas selection and those of performance estimation.

@&#KEYPHRASES@&#
Atlas-based segmentation,Local atlas selection,Label fusion,Registration,Segmentation,

@&#ABSTRACT@&#
In multi-atlas based segmentation, a target image is segmented by registering multiple atlas images to this target image and propagating the corresponding atlas segmentations. These propagated segmentations are then combined into a single segmentation in a process called label fusion.Multi-atlas based segmentation is a segmentation method that allows fully automatic segmentation of image populations that exhibit a large variability in shape and image quality. Fusing the results of multiple atlases makes this technique robust and reliable. Previously, we have presented the SIMPLE method for label fusion and have shown that it outperforms existing methods. However, the downside of this method is its computation time and the fact that it requires a large atlas set. This is not always a problem, but in some cases segmentation may be time-critical or large atlas sets are not available.This paper presents a new label fusion method which is a local version of the SIMPLE method that has two advantages: when a large atlas set is available it improves the accuracy of label fusion and when this is not the case it gives the same accuracy as the original SIMPLE method, but with considerably fewer atlases. This is made possible by better utilizing the local information contained in propagated segmentations that would otherwise be discarded. Our method (semi-)automatically divides the propagated segmentations in multiple regions. A label fusion process can then be applied to each of these regions separately and the end result can be reconstructed out of multiple partial results. We demonstrate that the number of atlases needed can be reduced to 20 atlases without compromising segmentation quality. Our method is validated in an application to segmentation of the prostate, using an atlas set of 125 manually segmented images.

@&#INTRODUCTION@&#
The segmentation of medical images is often required to support, amongst others, diagnosis and treatment planning. However, manual segmentation is a tedious and time-consuming task, and for this reason automatic image segmentation is currently one of the main challenges of medical image analysis. Among the many approaches to automatic segmentation, classifier combination or ‘label fusion’ strategies have gained popularity in the last decade. Classifier combination, a method that originates in the area of pattern analysis [11], deals with the combination of multiple observations of the same pattern. Label fusion, likewise, combines multiple estimates of the segmentation of a (medical) image. These segmentations or ‘labels’ are generated either manually or automatically.Each of the estimated segmentations contains unique information that may be complementary to the information contained in other estimated segmentations and therefore a combination of multiple estimates leads to a combined result that is more accurate than each segmentation individually (see Fig. 1).Label fusion increases the accuracy of the segmentation process, but also its robustness. Label fusion methods have been shown to better be able to handle statistical outliers than any dedicated classification strategy because they allow individual segmentations to have small errors.In this paper, we target label fusion of segmentations that have been computed automatically in an atlas-based segmentation procedure, which derives segmentations from other, already segmented images (so-called ‘atlases’). Its outline is conceptually simple (see Fig. 2): first, an image registration procedure is used to find a spatial relation between atlas and target image in the form of a transformation T that aligns the two images.Because this same spatial relation exists between the segmentations of atlas and target image, the transformation can then be applied to propagate the atlas segmentation. A more detailed introduction will be given in Section 2.In reality, T will not perfectly propagate the atlas segmentation because it is often not possible to perfectly align two medical images. As a result there will be an error in the resulting segmentation of the target image. By registering many atlases rather than one, the procedure can be made more robust because non-systematic errors in segmentations can be corrected with the help of other segmentations [20]. In a label fusion process, all the propagated atlas segmentations are then combined to form a single segmentation of the target image. The feasibility of atlas-based segmentation using label fusion has been shown in many studies ([1–5,9,10,13,15,19,21]).A critical aspect of atlas-based segmentation is the careful construction of the atlas set. An atlas-based segmentation strategy can only be successful if the atlas set is a good representation of the population of target images. In applications where the shape variability within the population of target images is limited, a small atlas set suffices to get good results. However, in most applications the shape variability is large and therefore a large atlas set is needed to support a robust and accurate atlas-based segmentation strategy.The main obstacles in applying atlas-based segmentation in clinical practice are not only that this requires experts to provide manual segmentations for a large set of atlas images, but also that it requires a large amount of computation time, as every single atlas image must be registered to a target image.Both of these requirements can often not be met in practice and because of these practical limitations small atlas sets are often used. This compromises the robustness of the label fusion process and causes the result of atlas-based segmentation to be sub-optimal in many applications.Previously, we have proposed the SIMPLE algorithm [14], which discards atlases of which the performance is estimated to be poor before including them in the label fusion process. This method has been shown to outperform existing label fusion methods but relies on a large atlas set. Given the above-mentioned considerations, the SIMPLE algorithm may not always be applicable.In this paper, we present a local version of the SIMPLE algorithm that has two advantages. First, when a large atlas set is available we show that the proposed approach yields an accuracy improvement compared with existing methods. Second, when only a small atlas set is available, the local SIMPLE method achieves the same accuracy as the state-of-the-art label fusion methods using a considerably smaller atlas set. We demonstrate our method in an application to prostate segmentation for the purpose of radiotherapy treatment planning. This paper is based on an earlier conference paper [16] in which we presented preliminary results.In Section 2 we will give a short introduction to atlas-based segmentation and provide context and background for our method by referencing some of the existing literature on label fusion. In Section 3 we will define our methodology and in Section 4 we will discuss the division into regions and propose three methods for doing so. We will describe our data and experiments in Section 5 and give results in Section 6. Finally, conclusions and suggestions for further research can be found in Section 7.When a set of atlases Aiis available, atlas-based segmentation is often a successful approach to segmenting an image. An atlas Ai=(Ii,Li) can be defined as a pair of an image Iiand a label Lithat is derived from a manual segmentation. If Itarget denotes the target image one is trying to segment, we can estimate its unknown label Ltarget by registering the atlases images Iito the target image and then propagating each of the corresponding atlas labels Li. Each propagated atlas label is an estimate or classifier of the label of the target image and all these propagated segmentations can be combined into a single estimate of Ltarget in a label fusion process [11].An atlas-based segmentation procedure can be summarized as follows:1.Image registration: a transformation function Ti(Ii)≈Itarget that aligns the atlas images with the target image is computed by registering Iito Itarget.Label propagation: given this transformation, the propagated segmentationLi′is computed asLi′=Ti(Li).Label fusion: an estimate segmentation Lestof the ground truth segmentation Ltarget is computed by combining all labelsLi′in a label fusion procedure.Many papers have been published on image registration, but a review of these methods falls outside the scope of this paper and we refer to the overviews that are available on this topic [17,27] and the references therein. Label propagation is a straightforward process in which atlas segmentations are propagated using the deformation field that results from the registration of the corresponding images.This paper focuses on the label fusion process, in which propagated atlas segmentations are combined into a single segmentation of the target image. A simple way to combine segmentations is a majority voting procedure (e.g. as is done in [10]), in which each voxel in the combined image has the same value as the majority of corresponding voxels in the propagated atlas segmentations. However, in most cases a better result can be achieved by using more advanced strategies that take into account the accuracy of a propagated atlas.A popular approach to more advanced label fusion is performance estimation: by weighing the influence of atlases based on their estimated accuracy or performance, one can reduce the effect of inaccurately propagated segmentations in the label fusion process and increase the effect of highly accurate segmentations. A well-known performance estimation method is the STAPLE method by Warfield et al. [26], which was extended to work for multi-class segmentations both in [26,21]. The algorithm estimates the sensitivity and specificity parameters of the performance of segmentations and that of the ground truth segmentation simultaneously using an expectation–maximization approach. Although the algorithm can be applied to label fusion of automatically generated labels, it is designed to estimate the performance of human raters and may not work optimally in the context of atlas-based segmentation [7].When combining a large number of propagated atlas segmentations without prior knowledge on their performance, an expectation–maximization strategy will likely converge to a local optimum. In [6], a continuous version of the algorithm was presented that also works well for continuous cases, such as for example in the case of tensor images. In this method, a bias and a covariance matrix are used rather than sensitivity and specificity parameters.Recently, an algorithm called COLLATE has been proposed, which takes into account the spatially varying performance that exists due to the fact that some regions in an image (e.g. borders with a sharp contrast) are easier to segment than other regions [3]. It estimates the consensus level for each voxel and takes this into account when locally determining rater behavior. It is shown to outperform STAPLE, especially for small numbers of atlases, but this is shown only for synthetic data.The same authors also presented a local version of STAPLE called Spatial STAPLE, which estimates the bias of a single atlas locally by estimating a regional confusion matrix using the local cross correlation that replaces the global performance estimation during the expectation–maximization procedure [5]. This method is better able to capture the performance of atlases if this performance greatly differs over different regions of an atlas, but still suffers from the same limitations concerning a large shape variance in the atlas set.In [2,9], the performance of atlases is estimated locally by looking at the local image similarity of the atlas image after registration and the target image. However, as noted in [2], the relation between image similarity and segmentation quality is far from optimal. In [24], Sdika proposed to use an accuracy map that is composed by pre-registering the atlas images to each other and measuring the accuracy with which this can be achieved. However, it was shown that this method only provided a significant improvement in combination with an intensity classification method, of which the accuracy is very application-specific.An alternative to performance estimation is atlas selection [20]. In this approach, low quality segmentations are entirely discarded and the remaining atlases are combined into a single segmentation.Aljabar et al. make a selection out of a set of 275 atlases based on the image similarity that results when these atlases as well as the target image are registered to a randomly chosen reference image [1]. This reduces the required computation time because only the target image has to be registered online. It is shown that this method outperforms selection based on meta-data in an application to brain images. However, even if a reduction in computation time can be established, the authors still assume the availability of a large atlas set, which is not a reasonable assumption in most practices.Klein et al. apply atlas-based segmentation to the prostate [13]. Using a smaller atlas set of 50 atlases, they register all atlas images directly onto the target image. A fixed set of atlas images is then selected based on the result of the registration and these images are combined using a majority vote. Because atlas images are directly registered onto the target image, the corresponding image similarity and consequently the selection step will be more accurate than in the approach of Aljabar et al., but this strategy is not feasible for large atlas sets due to the computational burden of having to register a large atlas set.Commowick et al. locally select atlases that are most similar to the target image, and use these local regions to create a patient-specific atlas [6]. However, to save computation time, they only register atlas images to an average atlas image which then in turn is registered to the target image. Although this is considerably more efficient, it may not be a feasible strategy when there is a large shape or appearance variability in the population of target images. Van Rikxoort et al. propose a similar local selection strategy, in which the atlas images are divided into eight blocks of roughly equal volume [19]. Then, it is locally decided which atlases must be registered based on an estimate of how much additional information the propagated atlas segmentation would locally add. The method reduces computation time, but still requires segmentations to be made available for all atlas images and is only validated on a relatively small atlas set (consisting of 39 atlases).Cardoso et al. select atlases locally based on the local normalized cross correlation and then subject the selected atlases to the STAPLE algorithm. They present significant improvements over global selection and, more importantly, conclude that local atlas selection is more robust than global atlas selection. However, as noted before, imaging artifacts and anatomical irregularities may cause image similarity to be a sub-optimal indicator of registration and propagation accuracy.In [14], we proposed the SIMPLE algorithm, which combines performance estimation and atlas selection in an iterative strategy that alternately estimates the performance and makes a selection of the atlases based on this estimated performance. Because discarding atlases with a poor performance will likely improve the results, this is repeated until convergence. In [15], a version of the SIMPLE algorithm was presented that estimates atlas performance locally, but still requires all atlases to be manually segmented and registered to the target image. In this paper, we present a local version of the SIMPLE algorithm that, similar to the algorithm presented in [19], semi-automatically divides a segmentation into regions that are dealt with independently. We show that, when using this method with a large atlas set, the accuracy of label fusion can be improved. When a large atlas set is not available, the method can greatly reduce the number of atlases that is required to approximately 20 atlases without compromising the accuracy of label fusion.

@&#CONCLUSIONS@&#
