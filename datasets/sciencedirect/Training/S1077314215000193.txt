@&#MAIN-TITLE@&#
GOLD: Gaussians of Local Descriptors for image representation

@&#HIGHLIGHTS@&#
A flexible local feature representation leveraging parametric probability density functions.Projection of the covariance matrix from the Riemannian manifold to the tangent Euclidean space.Experiments demonstrate the effectiveness of our descriptor in several challenging datasets.

@&#KEYPHRASES@&#
Image classification,Concept detection,Gaussian distribution,Stochastic Gradient Descent,

@&#ABSTRACT@&#
The Bag of Words paradigm has been the baseline from which several successful image classification solutions were developed in the last decade. These represent images by quantizing local descriptors and summarizing their distribution. The quantization step introduces a dependency on the dataset, that even if in some contexts significantly boosts the performance, severely limits its generalization capabilities. Differently, in this paper, we propose to model the local features distribution with a multivariate Gaussian, without any quantization. The full rank covariance matrix, which lies on a Riemannian manifold, is projected on the tangent Euclidean space and concatenated to the mean vector. The resulting representation, a Gaussian of Local Descriptors (GOLD), allows to use the dot product to closely approximate a distance between distributions without the need for expensive kernel computations. We describe an image by an improved spatial pyramid, which avoids boundary effects with soft assignment: local descriptors contribute to neighboring Gaussians, forming a weighted spatial pyramid of GOLD descriptors. In addition, we extend the model leveraging dataset characteristics in a mixture of Gaussian formulation further improving the classification accuracy. To deal with large scale datasets and high dimensional feature spaces the Stochastic Gradient Descent solver is adopted. Experimental results on several publicly available datasets show that the proposed method obtains state-of-the-art performance.

@&#INTRODUCTION@&#
Object and Scene Recognition have been a major research direction in computer vision, and, in particular, the task of automatically annotating images has received considerable attention. Systems extract some description from a training set of images, train a classifier and then can be used to perform their task on new images. The current “standard” approach for this task is some derivation of the Bag of Words (BoW) [1], and consists mainly of three steps: (i) extract local features, (ii) generate a codebook and then encode the local features into codes, (iii) pool all the codes together to generate a global image representation. In this approach a key step is the codebook generation, because it is the base to define a high-dimensional Bag of Words histogram. Typically this is performed through clustering methods and the most common approach is the use of k-means clustering, because of its simplicity and convergence speed.However, introducing a quantization of the feature space tightly ties dataset characteristics to the features representation, in the choice of both the position and the number of cluster centers to use. For the codewords positions, the quantization is learned from the training set, therefore the cluster centers reflect the training data distribution. The optimal number of cluster centers varies depending on the dataset. For example, in [2], the best accuracy using regular BoW is reached at 4k clusters for the Caltech-101 dataset, while, even if the improvement is progressively lower, in PASCAL VOC 2007 it does not reach saturation even with 25k cluster centers. Another example of this “hidden” dataset dependency inclusion may be found in many specializations of the BoW approach. [3,4] propose two different solutions to learn category specific codebooks and show how this is able to improve the descriptor ability to discriminate between similar categories.The codebook generation step has been introduced in order to obtain a fixed length representation of the distribution of the local features of an image. This is not strictly necessary, since the descriptors distribution could be directly modeled with a parametric distribution [3,5], and the parameters obtained on the single image may provide a summary of the local descriptors. In some contexts though, the information coming from the specific dataset characteristics is able to significantly boost the performance of the classification system.Based on these considerations, in this paper we propose a solution to allow the descriptors to be obtained either in a dataset independent way or to leverage training information in their construction. Using a multivariate Gaussian distribution with full rank covariance matrix or a mixture of them it is possible to tune the system based on the context. We also show how to embed this descriptors in the Spatial Pyramid Representation [6] further removing border effects artifacts. The final image descriptor is then used both with an off-the-shelf batch classifier and with the Stochastic Gradient Descent on-line solver [7], which allows to deal with large scale datasets and high dimensional feature spaces.We name our method Gaussian of Local Descriptors (GOLD) and demonstrate its effectiveness for automatic image annotation and object recognition. The main contributions of our work are:•we provide a flexible local feature representation leveraging parametric probability density functions, that can be independent of the image archive (e.g. for collections that change dynamically) or specific to dataset characteristics;our method employs the projection of the full rank covariance matrix from the Riemannian manifold to the tangent Euclidean space to obtain a fixed length descriptor suitable for linear classifiers based on dot product;we conduct experiments on several public databases (Caltech-101, Caltech-256, ImageCLEF2011, ImageCLEF2013, PASCAL VOC07). Some examples are reported in Fig. 1. The results demonstrate the effectiveness of utilizing our descriptor over different types of local features, both in dataset dependent and independent settings.This paper is organized as follows. We introduce the state of the art on image descriptors focusing on encodings, normalizations and pooling strategies in Section 2. Then we elaborate the formulation of the GOLD descriptor in Section 3, and its combination with the spatial pyramid representation in Section 4. In Section 5 the extension to the mixture of Gaussian distributions is presented. We conduct extensive experiments in Section 6 to verify the advantage of our method for automatic image annotation and object recognition. Conclusions are drawn in Section 7.

@&#CONCLUSIONS@&#
In this paper we presented a new way to summarize local descriptors by means of multivariate Gaussian distributions. While still providing the possibility to include all the techniques which improve system performance, such as spatial pyramids and power normalization, this allows to obtain an image descriptor totally independent on the dataset. The experimental results show that the method achieves performance which are very competitive with state-of-the art approaches on several well-known datasets. This solution could be also employed in many different situations in which the dataset changes dynamically (for example in online services such as Flickr or Google Images), still allowing to use the same feature vectors in different scenarios. Furthermore an extension to a mixture of Gaussians is proposed, enhancing the image description considering context information. Its discriminative capability allows to boost classification results in specific scenarios.