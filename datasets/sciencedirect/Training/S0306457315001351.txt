@&#MAIN-TITLE@&#
Bi-level weighted multi-view clustering via hybrid particle swarm optimization

@&#HIGHLIGHTS@&#
We propose a bi-level fuzzy weighting to discriminate view and feature simultaneously.We develop a hybrid optimization based on particle swarm optimization.We propose a representative based method to determine hyper-parameters.Our method is compared with six clustering algorithm on three real-world datasets.

@&#KEYPHRASES@&#
Multi-view clustering,Feature weighting,k-means,Particle swarm optimization,

@&#ABSTRACT@&#
Many problems in data mining involve datasets with multiple views where the feature space consists of multiple feature groups. Previous studies employed view weighting method to find a shared cluster structure underneath different views. However, most of these studies applied gradient optimization method to optimize the cluster centroids and feature weights iteratively and made the final partition local optimal. In this work, we proposed a novel bi-level weighted multi-view clustering method with emphasizing fuzzy weighting on both view and feature. Furthermore, an efficient global search strategy that combines particle swarm optimization and gradient optimization was proposed to solve the induced non-convex loss function. In the experimental analysis, the performance of the proposed method was compared with five state-of-the-art weighted clustering algorithms on three real-world high-dimensional multi-view datasets.

@&#INTRODUCTION@&#
In real-world applications, data are often collected from multiple sources or represented by multiple feature spaces. For example, web pages usually consist of both page-text and the hyper-links pointing to them, as well as images are often represented by multiple color and texture descriptors (Blum & Mitchell, 1998; Kriegel et al., 2011). Multiple views often provide compatible and complementary information for pattern discovery, so it is natural to integrate them together to obtain better performance rather than relying on a single view (Liu et al., 2013). On the other hand, multiple views are derived from integration of multiple types of measurements from different perspectives, different views could have very different statistical properties and produce different partitions, so tackling disagreement among views is crucial for multi-view clustering (Christoudias et al., 2008).Surprisingly, some previous work on multi-view clustering relies on a core assumption that all views are compatible to each other, i.e. all views are considered as equally important and different views agree on a consensus partition (Bickel & Scheffer, 2004; Chaudhuri et al., 2009; Kumar & Daumé III, 2011; Long et al., 2008; Zhao et al., 2014). For example, the co-training based methods are based on the assumption that the true underlying clustering would assign corresponding points in each view to the same cluster (Kumar & Daumé III, 2011; Zhao et al., 2014). Observing this assumption may lead to performance degradation when noisy or irrelevant views exist, many recent work applied a simple yet efficient method view weighting, i.e. each view is assigned a positive weight to express its importance (Cai et al., 2013; Chen et al., 2013; 2012; Liu et al., 2013; Tzortzis & Likas, 2012; 2010; Yin et al., 2015).Although various existing methods indeed improve the multi-view clustering performance, they often only capture view-wise relationship and ignore the feature-wise importance. For example, Tzortzis and Likas (2012) applied a kernel matrix to each view and then assigned a weight for each kernel; Liu et al. (2013) assigned a weight for each view in the non-negative matrix factorization(NMF) based multi-view clustering; Cai et al. (2013) improved the performance of k-means on multi-view big data also by view weighting. Fortunately, some most recent work discriminated view and weight simultaneously. For example, each view and feature were endowed a weight to represent their respective importance and a negative entropy constraint was imposed on each of them (Chen et al., 2013). The similar idea was implemented using joint structured sparsity-inducing norms, which is often used in multi-task learning (Wang et al., 2013). However, the negative entropy constraints and regulation terms of sparsity-inducing norms make the objective function non-convex and non-smooth, so it is difficult to solve them in general.Inspired by recent advance in multi-view clustering and heuristic optimization, this work proposes a novel weighting method with emphasizing fuzzy weighting on both view and feature. In addition, an efficient hybrid optimization strategy based on particle swarm optimization (PSO) and gradient-descent method is introduced to solve this problem. PSO is a classical global search algorithm that emulates social interaction and individual cognition of bird flocks foraging (Kennedy & Eberhart, 1995). Compared with complex genetic algorithm, PSO has less algorithm parameters yet provides comparable optimization performance. In our previous work, a cooperative PSO is designed for high-dimensional data clustering (Jiang & Wang, 2013). In this paper, this method is extended to the scenario of multi-view clustering. The main contributions of this work are summarized as follows.•In problem modelling, a fuzzy weighting schema is proposed to assign weights for both views and features simultaneously. Then, these weights are coupled within the Euclidean distance function to compute the intra-cluster similarity.In problem solving, an iterative hybrid algorithm based cooperative particle swarm optimization and gradient descent optimization is developed to find the best cluster centroids and weight vectors.A parameter selection method inspired by Clustering Using REpresentative (CURE) (Guha et al., 2001) is proposed and evaluated in this work.In experimental evaluation, we verify the effectiveness of our method with comparison experiments against five state-of-the-art weighting-based clustering algorithm on three real world datasets.The rest of this paper is organized as follows. The related work is given in Section 2. Then, the proposed clustering objective function and the hybrid optimization algorithm are given in Sections 3 and 4, respectively. The parametric study and performance evaluation are provided in Sections 5 and 6, respectively. Finally, Section 7 concludes this paper.

@&#CONCLUSIONS@&#
