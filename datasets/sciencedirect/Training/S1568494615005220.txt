@&#MAIN-TITLE@&#
An Artificial Bee Colony algorithm with guide of global & local optima and asynchronous scaling factors for numerical optimization

@&#HIGHLIGHTS@&#
Build a better searching mechanism for ABC algorithm.Integrate information of global and previous best solutions into search strategy.Introduce two adaptive scaling factors for a better balance between exploration and exploitation.

@&#KEYPHRASES@&#
Artificial Bee Colony algorithm,Population-based optimization,Scaling factors,Global optimization,

@&#ABSTRACT@&#
Artificial Bee Colony (ABC) algorithm is a wildly used optimization algorithm. However, ABC is excellent in exploration but poor in exploitation. To improve the convergence performance of ABC and establish a better searching mechanism for the global optimum, an improved ABC algorithm is proposed in this paper. Firstly, the proposed algorithm integrates the information of previous best solution into the search equation for employed bees and global best solution into the update equation for onlooker bees to improve the exploitation. Secondly, for a better balance between the exploration and exploitation of search, an S-type adaptive scaling factors are introduced in employed bees’ search equation. Furthermore, the searching policy of scout bees is modified. The scout bees need update food source in each cycle in order to increase diversity and stochasticity of the bees and mitigate stagnation problem. Finally, the improved algorithms is compared with other two improved ABCs and three recent algorithms on a set of classical benchmark functions. The experimental results show that the our proposed algorithm is effective and robust and outperform than other algorithms.

@&#INTRODUCTION@&#
In past decade years, population-based optimization techniques have become increasingly popular. Many such optimization techniques have been proposed to solve numerical optimization problems. Genetic Algorithm (GA) simulating the Darwinian law of survival of the fittest was established and applied by Holland [1,2], Ant Colony Optimization (ACO) inspired by the foraging behavior of ant colonies [3], and Particle Swarm Optimization (PSO) simulating the social behavior of bird flocking or fish schooling was introduced by Eberhart and Kennedy [4], and so on. Artificial Bee Colony (ABC) algorithm was developed by Karaboga [5] based on simulating the foraging behavior of honey bee swarm. Due to its simplicity and ease of implementation, ABC has attracted numerous researchers’ attention and been applied to solve many practical optimization problems [6–12] since its invention. The performance of ABC has already been compared with other optimization techniques such as GA, PSO, ACO, Differential Evolution (DE) and Firefly Algorithm in various numerical functions [11]. However, ABC is good at exploration but poor at exploitation. Additionally, it is easy to get trapped into local optima when solving complex multimodal problems. So some modified or improved algorithms have been proposed. They can be roughly categorized into three classes.(i)Improve or modify the search strategy for each kind of bees. A gbest-guided Artificial Bee Colony (GABC) algorithm was proposed by Zhu and Kwong [13]. GABC incorporates the information of global best solution (gb) into the solution search equation of ABC to improve the exploitation of ABC algorithm. Li et al. [9] introduced the best-so-far solution, inertia weight and acceleration coefficients to modify the search process. Xiang and Qin [14] improved a combinatorial solution search equation to accelerate the search process. Aydin et al. [15] presented a dynamic population size in ABC algorithm to combined economic and emission dispatch problem. Jun Luo et al. [16] proposed a modified algorithm called converge onlookers ABC (COABC) algorithm to improve the exploitation capability of algorithm.Change the method for initial statistic swarm distribution. A chaotic search technique is employed on scout bee phase to escape from local minima in [17].Hybrid some search strategies proposed in other intelligent algorithms with ABC. For solving cardinality constrained mean-variance portfolio selection problem, Tuba et al. [18] combined ABC algorithm with Firefly Algorithm. Gao and Liu [19] presented an improved solution search equation inspired by DE.A comprehensive survey for the recent progress of ABC algorithm and its applications in engineering has be reviewed in [20]. The recent comprehensive research on ABC are done by Kiran et al [21] in which five search strategies and counters are used to update the solutions.All techniques mentioned above try to achieve a balance between exploitation and exploration in the process to find a global optimum. This balance is extremely important for the successful performance of an optimization algorithm. Thus this paper will concentrate on the establishment of this balance. For this purpose, we introduce the previous best position (pb) and the current global best position (gb) into the update equation of employed bees and onlooker bees, respectively. The information of the current global best position and previous best position can guide the search direction of new candidate solutions. Furthermore, an adaptive S-type scaling factors is added in employed bees search equation for the balance mechanism between exploitation and exploitation. For escaping to get trap into local solution, scout bees randomly select new food sources to update their positions rather than rely on a parameter, limit, in original ABC in each cycle. This method can increase the population diversity and prevent the algorithm from premature convergence. For convenience, the proposed algorithm in this paper is called the gband pbguided ABC algorithm with adaptive scaling factors (GPSABC).The rest of this paper is organized as follows: Section 2 summarize four population-based algorithms. In Section 3, the GPSABC algorithm is presented in detail. In Section 4, based on the numerical study, we demonstrate the performance of GPSABC and compare it with GABC, GPABC and other three recent algorithms. Our conclusion is drawn in Section 5.As above-mentioned, there are many population-based algorithms in research literatures. In the following descriptions, concentration is given only on the general characteristics of four algorithms. We will compare the performance of our proposed algorithm against them.ABC algorithm is a stochastic optimization algorithm inspired by the foraging behavior of honeybees [5]. The algorithm represents solutions in a given multi-dimensional search space as food sources, and maintains a population of three types of bees, i.e., employed, onlooker and scout, to search for best food sources. There is only one employed bee on each source. The number of employed bees or onlooker bees is equal to the number of food sources [6]. Each iteration cycle in the search process consists of three steps: (i) sending the employed bees onto their food sources and evaluating their nectar amounts; (ii) sending the onlooker bees on the food sources, evaluating the nectar information taken from all employed bees and choosing a food source with a probability related to their nectar amounts; (iii) if a food source cannot be further improved after “limit” iterations, the food source is replaced with a new one that is found by a scout.The original ABC algorithm can be explained as follows.Firstly, the update equation used in the employed bee stage is the same as that in the onlooker stage. The main difference between the employed bee stage and the onlooker stage is that every solution in the employed bee stage involves the update process, while only the selected solutions have the opportunity to update in the onlooker stage. A candidate food position is generated from the previous one by using of the following equation:(1)vij=xij+ϕij(xij−xkj)where xijand xkjrepresent the jth component of a solution vector (i.e., food position) xiand its neighbor xk, respectively. j(∈[1, D]) and k(∈{1, 2, …, SN}) are random integers and k≠i. D is the dimension of decision variable and SN is the size of colony. ϕijis a random number in [−1,1]. Then, a greedy selection is done between xiandvi, which completes the update process.Secondly, an onlooker bee chooses a food source according to a probability value, pi, which associate with that food source and calculated by the equation(2)pi=fiti∑i=1SNfitiwhere fitidenotes the fitness value of the solution xifound by the ith employed bee, which is proportional to the nectar amount of the food source in the position xi. Then the employed bees share their information with the onlookers.Thirdly, if a food source is not improved anymore when limit, a preset parameter, is exceeded, it is assumed to be abandoned by its employed bee and the employed bee associated with that food source becomes a scout to search for a new food source randomly, which would help algorithm to escape from local optima.Based on ABC algorithm, GABC algorithm proposed in [13] takes advantage of the information of the global best solution to guide the search of candidate solutions. GABC incorporates the information of global best solution into the solution search equation to improve the exploitation of ABC. Both employed bees and onlooker bees update their positions by using of the equation(3)vij=xij+ϕij(xij−xkj)+ψij(gjb−xkj)where k≠i,gjbis the jth element of global best solution gb, ϕijand ψijare uniform random numbers in [0, C]. C is a nonnegative constant and plays an important role in balancing the exploration and exploitation of the candidate solution search [13]. Due to current optimum is taken into account in Eq. (3), GABC outperforms in exploitation than original ABC. However, it still is premature in the process of search.Differential search (DS) algorithm is another effective population-based algorithm introduced to solve optimization problems in [22]. DS algorithm searches optimal solution of a problem by simulating the migration carried out by living being.In DS, the population is made up of random outcomes of the artificial-superorganism migrations. An artificial-superorganism will migrate to the global minimum of the problem. During this migration, the artificial-superorganism examines whether some randomly selected positions are suitable temporary positions during the migration. If such a position is suitable to stopover (best solution) temporarily during the migration, the members of the artificial-superorganism (i.e., artificial-organisms) that made such discovery immediately settle at the discovered position and continue their migration from this position. The mechanism of DS for finding a stopover site in the remaining areas between the artificial-organisms can be described by a Brownian-like random walk model (see literature [22] for details).EDS introduces elite individual into search strategy for better convergence [23]. The frame of the EDS algorithm is as below.The algorithm begins with a randomly initiated artificial-organism which utilizes parameter vector within the upper and lower bounds.After initialization, stopover vectors at the areas are generated between the artificial-organisms that can be described by a Brownian-like random walk model. In order to calculate the stopover vectors, the algorithm creates a stopover vector corresponding to each population individual or target vector in the current population.Selection operation is used to choose the next population (i.e., the next artificial-organisms) between the stopover site population and the artificial-organism population.The search process of stopover site can be calculated by the individuals of the artificial organisms of the superorganism.EDS has a faster convergence rate and better search ability [24].Differential evolution (DE) is utilizes the difference of positions between individuals to perturb base vectors and thus generate new mutant individuals [25]. However, the difference between the fitness values of individuals, which may be helpful to improve the performance of the algorithm, has not been used to tune parameters and choose mutation strategies. So there are many improved or modified or hybrid DEs have been proposed in recent literatures [26–29]. Wherein, differential evolution based on covariance matrix learning and bimodal distribution parameter setting (CoBiDE) is one of excellent algorithms in nowadays. In [30], differential evolution based on covariance matrix learning and bimodal distribution parameter setting (CoBiDE) is proposed. In CoBiDE, Covariance matrix learning is introduced to establish an appropriate coordinate system for the crossover operator. Bimodal distribution parameter setting is proposed for the control parameters of the mutation and crossover operators, with the aim of balancing the exploration and exploitation abilities of DE.Teaching–learning-based optimization algorithm (TLBO) [31] is another effective algorithm which is recently proposed for continuous optimization problems. TLBO simulates the teaching and learning phenomenon of a classroom to solve multi-dimensional, linear and nonlinear problems with appreciable efficiency. TLBO algorithm does not require any algorithm-specific parameters except for some common controlling parameters like population size and number of generations for its working.The working of TLBO is divided into two parts, “Teacher phase” and “Learner phase”. During “Teacher phase” a teacher tries to increase the mean result of the class in the subject taught by him or her depending on his or her capability. In “Learner phase”, learners increase their knowledge by interaction among themselves. A learner interacts randomly with other learners for enhancing his or her knowledge. A learner learns new things if the other learner has more knowledge than him or her.Afterwards, several improved or modified TLBOs are proposed in [32,33] to improved TLBO's performance. In order to enhance its exploration and exploitation capacities, the basic TLBO algorithm is improved by introducing the concept of number of teachers, adaptive teaching factor, tutorial training and self motivated learning.In this section, we will propose an improved ABC algorithm in which the whole bees swarm is divided into three sub-swarms, i.e., employed, onlooker and scout bees, by a certain proportion. Employed bees update their positions with guide of the personal best (named pbest) solutions. Furthermore, a S-type scaling factors are taken as weights onto the search direction toward pbest and neighbor for employed bees. Onlooker bees follow elite employed bee with guide of global best (named gbest). Moreover, scout bees randomly update their position solution in search space.In original ABC, employed bee randomly select a neighbor food source position (i.e., solution xkin Eq. (1)) around the source to explore a new position. It may lead to a poor exploitation capability. So we will introduce another best pb, called cognitive knowledge of a bee, to enhance the exploitation capability of the algorithm in the process of employed bees search. Each employed bee memorizes the previous best solution achieved by itself, namely,pibis the best fitness value achieved by the ith employed bee. It does not be shared with other bees. Thus we establish the following equation by which the employed bees update their positions.(4)vij=xij+ϕij(xkj−xij)+ψij(pijb−xij)where ϕijand ψijare random numbers in range of [0, 1]. xijrepresents the position of the abandoned food source which will be replaced by new food source positionvij. xkjis a random neighbor of ith employed bee. The right side of Eq. (4) consists of three terms. The first term is the current position of bee, the second and the third play roles to change the search direction toward xkandpibposition. According to Eq. (4), the solution search equation can keep more potential positions to be explored by bees in the search space.For onlooker bees, GABC algorithm takes advantage of gbto guide the search of candidate solutions in order to improve the exploitation capability of the algorithm [13]. gbreflects the sharable information of food sources for whole bees swarm and it is also called social knowledge of a bee. For sake of the balance of search between the exploitation and exploration of the algorithm for global optimization, xeand gbare introduced into the search strategy of onlooker bees. The onlookers choose an elite bee xeform employed bees in probability p calculated by Eq. (2). Then they update their positions by using of equation(5)vij=xij+ϕij(xije−xij)+ψij(gijb−xij)where xeis the elite bee selected from all of employed bees.Fig. 1shows the bees distribution in ABC, GABC and GPABC at various iteration stages to solve multimodal Six-Hump Camel function, respectively. We can clearly see from Fig. 1 that among three methods, GPABC cannot only find global optimum but also explore widely in search space due to the help of both gbest and pbest. Especially, with the guidance of gbest and pbest, more bees can be attracted toward the optimal region. Additionally, we can observe that GPABC holds better exploration capability than ABC and GABC. As shown in Fig. 1, with the increasing of iterations the most bees stay at global minima and a little part still explore in search space in GPABC. Although the population converges to the optimum quickly in ABC and GABC, their exploitation are weak in later iteration stage.For sake of a better balance of search between the exploitation and exploration of the algorithm for global optimization, two parameters c1 and c2 are introduced into Eq. (4) for employed bee's search. It yields(6)vij=xij+c1ϕij(xkj−xij)+c2ψij(pjb−xij)where c1 and c2 are called asynchronous scaling factors. They respectively represent the bee's own experience and whole bee colonys experience. If c1=c2=1, Eq. (6) will degenerate into Eq. (4). Set a larger value of c1, the bees will engage excessive local search; instead, a larger value of c2, the bees trend towards the global optima. Therefore, in the earlier stage of searching process, a larger c1 and smaller c2 will keep the bees try to diverge in the search space and increase the diversity of the population. In the later stage, a smaller c1 and larger c2 will be of benefit to the algorithm convergence to the global optima. So c1 decreases while c2 increases with iteration number t in the process of operation. Hence, c1 and c2 play an important role in the optimization operation. Here are proposed an asynchronous scaling factors. c1 and c2 vary, respectively, with respect to iteration number t nonlinearly by following equation:(7)c1=cmax−11+e−αt−T2c2=cmin+11+e−αt−T2where cmax, cmin and α are the constants and c1, c2∈[cmin, cmax], t is the current iteration number, t is the maximum number of iterations. The variation curves of c1 and c2 with respect to iteration number t are depicted in Fig. 2.The scout bees update their positions in a certain region with special random flying pattern rather than random flying relying on the parameter limit in original ABC. We take the position of a scout bee as the center and a radius of τ for scanning the search region. Next position of the scout bee is achieved by:(8)vij=xij+rτwhere r is random number in range of [0,1]. The algorithm employs the scout bees to control diversity of the bees in the colony. In the other word, the increasing diversity of population is used as a way to mitigate stagnation problem.At each iteration of the algorithm, the fitness of each bee is calculated and they are sorted based on their fitness values. A predefined percentage of bees which have the worst fitness are selected as scouts, while the first half of rest bees which have better fitness is selected as employed bees and the other half are selected as onlookers. We define the fitness function as follow:(9)fit(x)=11+f(x),f(x)≥01+|f(x)|,f(x)<0Procedure of GPSABC algorithm is described in Algorithm 1.Algorithm 1Procedure of GPSABC algorithm.1:Initialization.The dimension of the problem is D. All of the bees are considered only as scout bees. There is only one bee on each food source.The number of population is SN.Set E, K and Z as the number of employed, onlooker and scout bees in whole colony where E+K+Z=SN.The algorithm starts with randomly producing food source that correspond to the solutions in the search space.2:repeat3:Compute fitness, fit(xi), i=1, 2, …, SN, of all the bees.4:Sort bees based on their fitness. Divide the whole bee colony into three parts: E employed bees, K(K=E) onlookers, and Z scouts.5:fori=1; i<E; i++ do6:iffit(xi)>fit(pib)then7:pib=xi8:end if9:iffit(pib)>fit(gb)then10:gb=pib11:end if12:end for13:Employed bee phase14:fori=1; i<E; i++ do15:forj=1; j<D; j++ do16:Randomly choose an integer j from 1, 2, …, D.17:Computer c1 and c2 by using of Eq.(7).18:Update the position of the i−th employed bee by Eq.(6).19:end for20:end for21:Onlooker bee phase22:fori=1; i<K; i++ do23:Choose an elite bee xefrom employed bees by an onlooker in probability picalculated by Eq.(2).24:Randomly choose integer k(k≠i) from 1, 2, …, SN, integer j from 1, 2, …, D.25:Update the position of onlooker bee by using of Eq.(5).26:end for27:Scout bees phase28:fori=1; i<Z; i++ do29:forj=1; j<D; j++ do30:Scout bees fly randomly in search space for a food source by Eq.(8).31:end for32:end for33:until termination criteria are metSummarily, GPSABC algorithm apply three different strategies different from ones of ABC and GABC in whole search process:(1)A local search process carried out in a region by the employed bees depending on local information of their neighbour's position and pbest position in the memory as defined in Eq. (6).A global search process used by the onlooker bees for discovering promising regions as described by Eq. (5).A certain random search process is carried out by the scouts by Eq. (8).In a better search process for some complex problems, global and local search processes should be carried out together.In order to demonstrate the performance of our improved algorithm GPSABC, 18 benchmark functions will be tested for comparison of the performance of algorithms. All programs were coded in Matlab 8.1.0 (win64) and executed in a Dell computer with Intel(R) Core(TM) i7-4770, double CPU @ 3.40GHz under Windows 7 operation system.We select 18 benchmark functions from [16,21,33,34] and list them in Table 1. These functions consist of many different kinds of problems such as unimodal, multimodal, regular, irregular, separable, non-separable and multidimensional. Specifically, there are 12 non-separable and at least 10 multimodal functions, respectively. Their names, characteristics, ranges, formulas, and optimal values are presented in Table 1. Some of their detail properties and graphs in 2 dimensions can be found at http://www.sfu.ca/∼ssurjano/optimization.html.All of 18 functions of three different dimensions, 5, and 10 are tested. The corresponding maximum numbers of iterations are 1000, and 1500, respectively. Additionally, five functions of 50 dimensions are tested for showing the performance of every algorithm. The colony size is set to 20 for all test functions of different dimensions. The percentage of employed bee, onlooker bee and scout bee are, respectively, 40%, 40% and 20% of the whole colony. Set another three parameters cmin=0, cmax=1 andα=10Tin Eq. (7). The parameter τ=Ub−Lb, where Ub and Lb is respectively upper and lower bound in GPABC and GPSABC. Set limit=100 in GABC.

@&#CONCLUSIONS@&#
