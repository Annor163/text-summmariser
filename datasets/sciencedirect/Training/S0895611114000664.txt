@&#MAIN-TITLE@&#
Multimodal medical information retrieval with unsupervised rank fusion

@&#HIGHLIGHTS@&#
We propose a medical retrieval system supporting text and image queries.It can retrieve either relevant PubMed articles or images from those articles.It supports automatic query term expansion from the MeSH thesaurus.Novel fusion algorithm, ISR, improves results from existing rank fusion algorithms.We got the best result on multimodal case-based retrieval in 2013 ImageCLEFMedical

@&#KEYPHRASES@&#
Medical search,Search interfaces,Assisted query formulation,Multimodal retrieval,Data fusion,

@&#ABSTRACT@&#
Modern medical information retrieval systems are paramount to manage the insurmountable quantities of clinical data. These systems empower health care experts in the diagnosis of patients and play an important role in the clinical decision process. However, the ever-growing heterogeneous information generated in medical environments poses several challenges for retrieval systems. We propose a medical information retrieval system with support for multimodal medical case-based retrieval. The system supports medical information discovery by providing multimodal search, through a novel data fusion algorithm, and term suggestions from a medical thesaurus. Our search system compared favorably to other systems in 2013 ImageCLEFMedical.

@&#INTRODUCTION@&#
A medical information storage and retrieval system is a valuable tool that healthcare professionals can use when investigating medical cases. Furthermore, case-based medical retrieval systems can empower healthcare experts by allowing them to find related publications or explore cases with similar symptoms or conditions [1] in medical information repositories. MEDLINE11http://www.nlm.nih.gov/pubs/factsheets/medline.html.is one of the most valuable medical information resources, containing over of 21 million articles from the life sciences and biomedical domains, covering over 5600 journals in 39 different languages. The PubMed22http://www.ncbi.nlm.nih.gov/pubmed/.search engine was created to enable easier access to this enormous amount of information and therefore, is a major tool for retrieving biomedical literature from MEDLINE. It allows keyword search on different fields such as the main text, author, and date. However, there are some alternatives that enable different data visualization techniques or provide search tools for specific domains. Lu [2] provides an exhaustive survey of web tools for biomedical literature search.Many existing tools focus on the full-text of the article, its categories or keywords. However, a significant percentage of medical articles contain relevant images with extra valuable information that is not referenced in the text (see Fig. 1). These images are an important clinical factor in the medical domain [3,4] and can help uncover hidden visual patterns not contained in the article's text.The goal of our approach is to use medical images to enrich textual queries and to support discovery in medical repositories. We propose a system where healthcare specialists can write textual queries (including long descriptions of the patient's condition) and provide medical images containing additional clues that would be difficult to convey in the formulation of textual queries (see Fig. 2). Medical images can represent multiple types of diagnostic exams – X-ray images, MRI, electronic microscopy – or relevant photos that provide rich visual information about the patient, such as the position of a mass on a MRI. Our system can improve retrieval performance by combining both textual and visual information in a flexible way mixing data-fusion techniques. The key feature of our medical retrieval system interface is the support for rich multi-part queries, that can be composed by free text (with assisted query formulation) and also multiple images.The proposed multimodal medical information system is based on standard retrieval techniques and a simple, yet powerful, design that helps users build their queries with interactive query expansion. It can retrieve articles for medical cases – medical publications and case reports – or the images contained in those articles. It is focused on usability and usefulness, for both health professionals and researchers.We designed the system to enable exploring the bulk of medical articles available in PubMed using images and text, both independently or combined, by leveraging on their implicit correlation (images to captions and article text to article images). For instance, in our system, one can search for a case report using only an image as a query, or search by images using only a textual description. Besides the explicit visual information, the proposed system also provides an intuitive and simplified way of accessing large medical knowledge-bases. It identifies medical terms in real-time and suggests related terms based on the Medical Subject Headings (MeSH) thesaurus. This provides a glimpse of related conditions and diagnosis that can assist users in the formulation of a more useful query. Our system combines the simplicity of web search engines (text queries, auto-complete) with automatic query expansion and image query by simple drag and drop. Moreover, the system supports two types of visualization: medical cases (in the form of articles and case-reports) and medical images (the articles corpus is a subset of PubMedCentral, with over 70,000 articles and over 300,000 images [5]).The system was thoroughly evaluated in the context of the 2013 ImageCLEF Medical track33http://www.imageclef.org/2013/medical.. In this article, we start by reviewing the state-of-the-art in medical information search in Section 2, and describing the overall architecture of the proposed system in Section 3. Details about medical terms expansion, medical images support and multimodal rank fusion are presented in Sections 4–6 respectively. Section 7 details the evaluation and discussion of the results using the most recent ImageCLEF Medical dataset and tasks: ad-hoc image retrieval and case-based retrieval tasks. Section 8 discusses our findings and conclusions.

@&#CONCLUSIONS@&#
In this article, we described our multimodal medical search engine NovaMedSearch, the technology and retrieval methods powering it, and the results and evaluation process of this system on the 2013 ImageCLEF Medical track.The main conclusions to be drawn from our contributions concern four main points: the ISR fusion family of algorithms, an interactive query expansion system and NovaMedSearch, a search engine for the medical domain, with a special focus on usability.The ISR algorithm family is a variant of RR and RRF, aimed at increasing precision at the top of the search engine ranks. We believe that it will help users to get relevant information, reducing frustration.NovaMedSearch combines a powerful framework based on state-of-the-art image and text processing algorithms with a simple yet powerful multimodal search interface with interactive query expansion. Our interactive query expansion system augments user queries with relevant medical terms from the MeSH thesaurus, leveraging on the the explicit declaration of expansion types in query representations for weighting the expanded terms.The framework that combines all search engine components was evaluated on ImageCLEF Medical 2013. Our runs achieved the best results for multimodal case based retrieval, by combining state-of-the-art image and textual retrieval techniques with our novel fusion algorithm family of algorithms. Our Image runs achieved the best results at case-based image retrieval by taking a late fusion approach on multi-image queries and using the articles where the images are present for duplicate detection. Our Textual runs also achieved good results, with a visible improvement after applying pseudo-relevance feedback and weighted query expansion with synonym terms from MeSH.