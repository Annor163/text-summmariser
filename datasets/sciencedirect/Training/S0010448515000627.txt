@&#MAIN-TITLE@&#
Combining volumetric dental CT and optical scan data for teeth modeling

@&#HIGHLIGHTS@&#
A novel teeth modeling framework by combining optical scan data and dental CT images is introduced.Co-segmentation between optical scan data and dental CT images is performed by the graph-cut method simultaneously.The proposed algorithm is automatic and time efficient, and shows high fidelity.Teeth data with defects such as metal artifacts can be completed successfully.

@&#KEYPHRASES@&#
Teeth modeling,Teeth segmentation,Co-segmentation,Graph-cut,Advancing front method,

@&#ABSTRACT@&#
Dental computer-aided design (CAD) systems have been intensively introduced to digital dentistry in recent years. As basic digital models, volumetric computed tomography (CT) images or optical surface scan data are used in most dental fields. In many fields, including orthodontics, complete teeth models are required for the diagnosis, planning and treatment purposes. In this research, we introduce a novel modeling approach combining dental CT images and an optically scanned surface to create complete individual teeth models. First, to classify crown and root regions for each set of data, corresponding pairs between two different data are determined based on their spatial relationship. The pairs are used to define the co-segmentation energy by introducing similarity and dissimilarity terms for each corresponding pair. Efficient global optimization can be performed by formulating a graph-cut problem to find the segmentation result that minimizes the energy. After classifying crown and root regions for each data set, complete individual teeth are obtained by merging the two different data sets. The advancing front method was successfully applied for merging purposes by considering the signed distance from the crown boundary of the surface mesh to the root surface of the CT. The teeth models which have detailed geometries obtained from the optically scanned surface and interstice regions recovered from volumetric data can be obtained using the proposed method. In addition, the suggested merging approach makes it possible to obtain complete teeth models from incomplete CT data with metal artifacts.

@&#INTRODUCTION@&#
Detailed digital models of individual teeth are required for many dental applications including orthodontic planning and simulation, dental implants, and jaw surgery. In the case of orthodontics, individual teeth models should be repositioned for diagnosis and planning purposes as well as simple visualization. Digital teeth models can be typically obtained by optical scanning or computed tomography (CT) scanning. One tooth is mainly composed of an exposed crown region and a root covered by gum or a jawbone. For the purpose of observing the morphology of each tooth, dental CT images are the best solution among current imaging modalities.The importance of individual teeth segmentation has been raised and various approaches have been explored through various works. Gao et al.  [1] extracted individual tooth contours explicitly from dental CT images using 2D level sets for each slice. They divided their algorithm into two stages: a single level set and coupled level sets for roots and crown segmentation, respectively. They also suggested a visualization framework of individual teeth for orthodontics  [2]. Hosntalab et al.  [3] applied variational level sets to the 3D volume directly after generating panoramic images in the coronal view. In addition, there are several modeling services used by practitioners in commercial packages. One of the available commercial packages is Anatomodel of Anatomage Dental (Anatomage Inc., San Jose, CA, USA). However, these tools in dental services require many manual segmentation operations, and they require much time and human resources. In addition, the previous studies listed above, as well as commercial packages, are based only on dental CT images.From a modeling point of view, using only CT images has several drawbacks. Dental CT images are, in general, obtained from cone-beam CT (CBCT) scanners with a low dose exposure and a small field-of-view (FOV) compared to general medical CT scanners. The image quality of CBCT scans has many artifacts and defects for various reasons. These artifacts make CBCT images insufficient in representing the detailed geometries, as shown in Fig. 1(a), which are important for dental implants and prostheses. Another critical problem of automatic teeth modeling with CT images is metal artifacts, as shown in Fig. 1(c).Another major branch of teeth segmentation and modeling has been performed with optical scan data. These data have much higher accuracy (about 0.01 mm) than dental CT images, in general, but only include the exposed area in the mouth without distinction between the teeth and gingival regions, as shown in Fig. 1(b). To classify teeth from the data, several approaches use curvature values as a preprocessing step  [4–7]. Because it is not a trivial task to separate teeth using only geometric information, one group used a training set to extract gingival contours by applying 3D statistical models  [8]. However, it is not enough to extract only gingival contours in many dental applications because there are missing regions such as the geometries of interstices by occlusion. To resolve this problem, another group attempted to recover the geometries of interstices after removing valley-shaped regions  [6]. Recently, Fan et al.  [9] introduced an approach to segment individual teeth in the surface mesh using two phases segmentation. The input surface mesh is divided into small patches by low-level segmentation first, and similar neighboring patches are clustered by comparing the shape compactness. Nevertheless, there are still limitations in recovering unscanned areas because the geometries are basically missing.To resolve this problem, we introduce a novel approach to construct digital teeth models by combining an optically scanned surface and dental CT images. In this approach, we extract crown regions from scanned surfaces with higher accuracy and root parts from dental CT images simultaneously by applying a co-segmentation concept using a graph-cut. The two segmented results are then combined seamlessly by considering the boundary shapes and adjusting different resolutions.Our main contributions can be summarized as the follows:–As we know, this is the first work for teeth modeling by combining dental CT images and an optically scanned surface data for the purpose of teeth modeling.We developed a co-segmentation method using dental CT images and an optically scanned surface data together for better segmentation results.The seamless merging of segmented regions from two different data types was developed to obtain each tooth model.Co-segmentation schemes have been applied to general bitmap images obtained from digital cameras  [10,11] or medical images [12,13]. There has been little study on different data types. Our technical approach for co-segmentation is similar to  [10], but spatial irregularities of the surface mesh have led to a quite different formulation. In addition, we applied the classified results to merge them because our final goal was to obtain complete teeth models.Before describing the technical details of our approach, we will explain the overall procedure first. Fig. 2shows a conceptual diagram of the overall procedure. From the volumetric CT imagesΩ⊂R3, we extract separate individual teethV=V1+⋯+Vn⊂ΩwhereViis a segmented tooth region,Vi∩Vj=ϕandnis the number of teeth. This procedure is performed in 2 steps: first, the initial teeth region is extracted via optimal global thresholding and region growing with local thresholding. For optimal global thresholding, the Otsu’s thresholding method is used to segment hard bone regions, including jaw bones and teeth. In the initial segmentation result, some of the teeth’s surfaces are adjacent to jaw bones. To separate the teeth region only, the seed points for each tooth are marked manually and extracted by region growing with local thresholding. Our local thresholding finds connected voxels that are statistically similar to voxels surrounding the user defined seed points (voxels). The neighboring voxels of the boundary of the current active region are selected if their intensity is within [mean ± SD] of the active region, where SD is the standard deviation. The statistics are updated each iteration. A single seed point may not be sufficient to select the entire tooth region in some cases. This can be simply compensated by multiple selections.From the initially extracted teeth region, morphological erosion is then performed until each tooth is separated. The amount of erosion is dependent on the contact surface between teeth. To determine the size of erosion probe, we construct a Euclidean distance fieldDof the teeth regionVfrom the teeth boundary∂Vas shown in Fig. 3. In the distance field, saddle points{pi}ofD, represented as blue dots in Fig. 3(c), are located on the tooth boundary and the maximum value of{D(pi)}determines the total amount of erosion. Initial teeth region is eroded as amount ofmax{D(pi)}, then each tooth are separated as shown in Fig. 3(d). A cube kernel was used for erosion in our experiments for time efficiency, but a sphere can be also used. We mark the voxels in the separated region as visited and the other initial teeth region as unvisited. The separated regions are then expanded by searching its unvisited neighbor voxels whose distance values are less than or equal to the current voxel. A priority queue is used for the propagation by saving neighbor voxels in reverse order ofD, the distance from∂V. Propagation is performed until all teeth regions fill the initial volumeV. Let us denote the boundary of teeth as∂V=∂V1+⋯+∂Vn, where∂Viis the set of boundary voxels ofVi.We then align optical scan dataS0to∂Vdescribed in the volume coordinates by selecting several feature points from both data sets. The feature points used in the initial transformation are matched pairs selected from both data sets. They are manually selected in the same order from the scan data and CT volume in 3D. The points at the end of central incisors and cusps of molars at both ends are used in our experiments. This initial registration can be improved in an automatic manner by using the well-known iterative closest point (ICP) algorithm  [14]. From this, the data set is prepared for the main steps.Let the registered scan surface beS⊂R3. After obtaining∂VandSvia preprocessing, we then perform the co-segmentation of∂VandSsimultaneously into crown and non-crown regions by finding corresponding pairs. The co-segmentation result may be affected by the initial registration accuracy. To reduce the effect from initial registration, we repeat the registration and co-segmentation steps until the rigid transformation converges. The registration result ofS0to∂Vmay be improved by using only the crown regions obtained from co-segmentation as input for the ICP algorithm. From the co-segmentation results ofS, the crown region of each tooth is smoothly merged with the root region from the corresponding teeth boundary among∂Vi.By performing this merging step for all the teeth, we can obtain a complete teeth model combining the crown region fromSand the root region from∂V. The details of each step are described in Sections  3–5.The main goal of this step is to segment crown parts from two different data sets simultaneously. As described in Section  1, the teeth segmentation from each data set is not a trivial task, and there are limitations due to the acquisition method and the data’s characteristics. To solve this problem, we suggest a co-segmentation method to classify crown and non-crown regions from both data sets in this section.Rother et al.  [11] introduced co-segmentation to classify similar objects lying on different backgrounds. They extended a single segmentation problem based on Markov random fields (MRF) by defining corresponding pairs and introducing an additional term to compare the similarities of histograms between them. Co-segmentation has since been applied to many applications, including medical images  [12,13], large data user-interactions  [15], multi-videos  [16], and 3D surface shapes  [17]. Global optimization of these approaches is efficiently solved by a graph-cut algorithm. Graph-cut algorithms have been extensively studied, especially in the computer vision area  [18]. The concept and various applications can be found in previous studies on images  [18–21] and 3D surface shapes  [12,22–26], even though we do not describe the details here. Graph-cut algorithms are appropriate for binary classification problems such as foreground segmentation from backgrounds and they give an efficient framework for global energy optimization. Co-segmentation can be modeled under the same framework as single model segmentation.Our basic framework is conceptually similar to previous studies applied to a pair of images  [10,11]. In the image segmentation problem  [10], corresponding pairs can be defined as all pairs of the same foreground histogram buckets because the foreground (or object) in the two images are similar. So, similarity values between corresponding pairs can be used to encourage the corresponding pixel of one image to be segmented to the foreground if a pixel of the other image is segmented to the foreground. However, because our problem is to segment crown parts of similar geometric shapes from 3D surfaces and volume data, corresponding pairs can be defined by some geometric properties between them. Furthermore, not only the similarities but also dissimilarities between corresponding pairs can be helpful for classifying non-crown region (root or gum) to non-crown region because it is difficult to classify non-crown regions correctly near the gingival boundary if only optical scan data are used for segmentation (see Eq. (10), Fig. 7 and Section  5.2). As a result, the details of the optimization equation differ from those of the image segmentation problems and both geometric similarities and dissimilarities are used as the meaningful properties to compare two data sets. In addition, for our purposes, the framework should recover data defects of one data type by compensating mutually from the other data type. The details of our approach are explained in the following sections.The first step of our co-segmentation technique is to find the set of corresponding pairs that has a neighboring relationship between two different types of data.Sincludes interstices and gingival regions, which are not included in∂V, as well as crowns. This means that there are no corresponding regions in∂Vfor gingival or interstice regions. Similarly, there are no corresponding regions inSfor the root parts in∂V. That is, only crown parts, which we want to extract, exist in both sides.Because two data sets are registered in the preprocessing step, the same parts in both sides are closely located. We can determine which part has its corresponding pair by a simple distance comparison. However, this cannot be determined by a simple threshold value due to different spatial resolutions, artifacts, and registration errors. The main idea to construct corresponding pairs is conservative rejection; that is, we exclude the points from the pairs that are not expected to be classified as the crown region. For the region where correct classification cannot be determined only with distances, energy minimization is performed, as described in Section  3.2.We denote the center position of the paired voxel ofp∈SbyCS(p)=argminqr∈∂V{|p−qr|}=qtand the corresponding vertex ofq∈∂VbyCV(q)=argminpj∈S{|q−pj|}=pk. Note thatCV(CS(p))does not always returnp. The ordered index set of corresponding pairsCis then defined as Eq. (1).(1)C={(j,r)|pj∈S,qr∈∂V,(qr=CS(pj)orpj=CV(qr)),|pj−qr|<ρ,||pj−CS(pj)|−|qr−CV(qr)||<ε}whereε,ρare user-defined constants. As shown in Eq. (1), the corresponding pairs are determined by two criteria: one is the Euclidean distance and the other is the closeness between bidirectional mapping points. We setρ=2.0mm, which is large enough considering the initial registration errors, andεas the diagonal length of a voxel because the second criterion is affected by the resolution of the sparser data.We denote a set of regions whose vertices are all included in the corresponding pairs defined in Eq. (1) asSPand voxels as∂VP. We then denote the complement ofSPand∂VPasSQ⊂Sand∂VQ⊂∂V, respectively, and these are the sets of regions that are not matched with any corresponding pairs. Fig. 4shows each region.We define binary random variables that compose the energy equation. There are two kinds of variables for single segmentation ofSandV, respectively. The first type is described asxj(S)andxr(V)which represent whether the corresponding vertex or voxel belongs to the crown region or not.xj(S), corresponding topj∈S, is defined as Eq. (2). Similarly,xr(V)forqr∈∂Vis defined as Eq. (3).(2)xj(S)={1ifpj∈Sis classified as crown region0otherwise(3)xr(V)={1ifqr∈∂Vis classified as crown region0otherwise .The other type is introduced to compare the similarities between neighboring nodes of each data type. Here, we use a one-ring neighbor, denoted byN(S), forS, and a 6-neighborhood scheme, expressed asN(V),∂V.(4)yj,k(S)={1ifxj(S)≠xk(S)0otherwise ,yr,t(V)={1ifxr(V)≠xt(V)0otherwise .Using two types of random variables, the Markov random field formulation for the segmentation ofSandVcan be generally expressed as Eqs. (5) and (6), respectively  [18].(5)min∑j∈SIKjxj(S)+∑(j,k)∈NSIBj,k(S)yj,k(S)subject toxj(S)∈{0,1}forj∈SI,j=1,…,myj,k(S)={1ifxj(S)≠xk(S)0otherwise(6)min∑r∈∂VIKrxr(V)+∑(r,t)∈NVIBr,t(V)yr,t(V)subject toxr(V)∈{0,1}forr∈∂VI,r=1,…,pyr,t(V)={1ifxr(V)≠xt(V)0otherwisewhereSIand∂VIrepresent the index set of vertices inSand voxels of∂V, respectively. Similarly,NSIandNVIrepresent the pairwise index set of the neighbors ofSand∂V, respectively.The coefficients of boundary terms,Bj,k(S)in Eq. (5) andBr,t(V)in Eq. (6), are defined as Eq. (7) in our problem. Note thatBj,k(S)is defined by a geometric property, the angle between the normal vectors, becauseSis a surface mesh. In the case of CT data, it is known that the intensity of the enamel region, which only crowns have, is slightly higher than that of the root bone. We can see this in our formulation ofBr,t(V), but it is not meaningful to compute the intensity differences directly because it is hard to detect the exact boundary of the volume data. The intensities are also not consistent. For this reason, we defineBr,t(V)to compute the difference between the average intensities by using neighbor voxels within a certain thickness.(7)Bj,k(S)={τ1−Cj,kif|1−Cj,k|>ξτ/ξotherwise ,whereCj,k=max(nj⋅nk,0)Br,t(V)={max(Δmin,1)|Ir′−It′|if|Ir′−It′|>ξ,1/ξotherwisewhereIr′=1|N|+1(Ir+∑t:(r,t)∈NIt),Δmin=min(r,t)∈N(V)|Ir′−It′|njis the normal vector of thejth vertex inS,τis a user-defined constant, andIris therth voxel intensity inΩ.ξis the tolerance to prevent the denominator from becoming zero, and we setτ=10−3andξ=10−5in our experiments. Ifξis small enough, its value does not affect the segmentation results.In our co-segmentation problem, it was not useful to determine the probability that one vertex or a voxel belongs to the crown by using its own properties. Therefore, we did not determine theKrandKjvalues for a vertex or a voxel that belonged to the crown by using its own properties in the co-segmentation problem. Instead, we applied hard constraints (usingK) to both data terms of the vertices and voxels inSQandVQin order to classify them as non-crown regions. In this study, the value ofKis assigned as:K=1+max(maxj∈S∑k:(j,k)∈N(S)Bj,k(S),maxr∈V∑t:(r,t)∈N(V)Br,t(V)).For the co-segmentation, we can apply a similar concept to the single model segmentation. The two energy equations in Eqs. (5) and (6) can be considered as local regional terms for each data type. The co-segmentation model can be easily extended from Eq. (5) by adding a boundary term between corresponding pairs ofSand∂V[10]. To compare the similarity between corresponding pairs of different data, we define additional binary variables as shown in Eq. (8).(8)mj,r={1ifxj(S)=1andxr(V)=10otherwise ,nj,r={0ifxj(S)=0andxr(V)=01otherwise .Our final co-segmentation model is then composed of two regional terms for each data type, a similarity term and a dissimilarity term, as defined in Eq. (9).(9)minK∑j∈SQIxj(S)+∑(j,k)∈NSIBj,k(S)yj,k(S)+K∑r∈∂VQIxr(V)+∑(r,t)∈NVIBr,t(V)yr,t(V)−∑(j,r)∈Cηj,rmj,r+∑(j,r)∈Cδj,rnj,rsubject toxj(S)∈{0,1}forj∈SI,j=1,…,mxr(V)∈{0,1}forr∈∂VI,r=1,…,pyj,k(S)={1ifxj(S)≠xk(S)0otherwiseyr,t(V)={1ifxr(V)≠xt(V)0otherwisemj,r={1ifxj(S)=1andxr(V)=10otherwise ,nj,r={0ifxj(S)=0andxr(V)=01otherwisewhereηj,randδj,r, are the coefficients for similarity and dissimilarity, respectively. They are computed as defined in Eq. (10).(10)ηj,r={exp(−α|pj−qr|d̄−|pj−qr|)exp(β(|nj⋅∇Ω(qr)|−1)|nj⋅∇Ω(qr)|)if|pj−qr|<d¯andnj⋅∇Ω(qr)≠00otherwiseδj,r={exp(γj|nj⋅∇Ω(qr)||nj⋅∇Ω(qr)|−1)if|nj⋅∇Ω(qr)|<10otherwisenjis the normal vector ofpj∈Sand∇Ω(qr)is the gradient vector ofqr∈∂V.d̄is the mean value of|pj−qr|for all corresponding pairs(j,r)inC.γj=κjmax/κtif (κjmax>|κjmin|andκjmax>κt) otherwiseγj=1.κjmaxis the maximum normal curvature atpj∈S,κjminis the minimum normal curvature, andκtis a threshold value.κt=0.5was used by experiments in our study. In the case ofαandβ, they are the parameters to adjust the sensitivity of sub-terms ofηj,r, which are based on the changes of|pj−qr|and normal vector deviation. We selectα=4.0to make the first sub term almost zero aroundd̄/2, andβ=2.5so that the second sub term becomes almost zero when the angular difference between two normal vectors is bigger than 65° from the experiments.The dissimilarity term is determined by two observations: (1) A negative high curvature area tends to be a part of the boundary between the teeth and gum by the negative minima rule  [27]. (2) A positive high curvature area is usually presented in the crown area.As shown in theηj,rof Eq. (10), the coefficient of the similarity term is composed of two subparts. The first consideration is that the spatially close pairs may be considered as the same region. So the left term of Eq. (10) is assigned the larger value of the spatially close pairs as a similarity reward. However, it is not easy to distinguish gingival contours from crowns using only this term because the spatial distances of these regions are close to the root parts as shown in Fig. 5(a). Corresponding pairs in the same crown region may have similar normal vectors. So, we compare geometric similarities simultaneously by comparing the normal vectors of corresponding pairs. The second term ofηj,rgives the larger value to pairs that have similar normal vectors. As shown in Fig. 5(b), in order to represent values of the second term, most of the corresponding pairs in the gingival contours have values close to zero. Fig. 5(c) of the figure shows theηj,rvalues to multiply two terms. As shown in (c), most of the pairs in the gingival contours have values close to zero because the pairs in this region have larger normal vector deviation, even though the distance is very close. This works fine in that pairs with a positive high curvature in the gum region are segmented easily as non-crown regions. This is because both of theδj,randηj,rvalues are small and their segmentation results are then dependent on the neighbors byBj,k(S)andBr,t(V).ηj,ris a compensation value for crown pairs when they are close and have similar normal vectors. On the other hand,δj,ris the penalty term for the cases where one of them is classified as crowns even though the normal vectors are different. By introducing the additional dissimilarity term as well as similarity, we can classify non-crown regions more accurately. The differences are discussed in Section  5.Our problem can further be converted to a minimum(s,t)-cut problem, the general graph-cut method, similar to the approach introduced in  [10]. LetNx=NS∪NVwhereNSis the set of nodes in the graph corresponding toxj(S)andNVis the nodes corresponding toxj(V). We also subdivideNSandNVintoNS+,NS−,NV+,NV−, which are the set of nodes fromSP,SQ,∂VP, and∂VQ, respectively. In addition,NmandNnare the sets of nodes corresponding toC, where|C|=|Nm|=|Nn|. They also represent similarity and dissimilarity nodes betweenSPand∂VPwhich correspond to the variablesmandn, respectively. The constructed graph isG=(N∪{s,t},A), whereN=Nx∪Nm∪Nn. To convert our problem in Eq. (9) to a min-cut problem, we connect all the nodes corresponding to the vertices inSQand voxels inVQto sink nodetas arcs with the costK. All the similarity nodes inNmare connected to the source nodesas arcs with costηwhile the dissimilarity nodes inNnare connected totwith costδ, which is different from  [10]. They are connected to/from the nodes inNxwith infinite capacity, as shown in Fig. 6. The neighbor nodes ofSand∂Vare connected in both directions.For a finite cut (O∪{s},T∪{t}) ofG, we denote the set of nodes connected to the source nodesinNxbyOxand those inNmandNnbyOmandOn, respectively. In the same way, the nodes that are connected to the sink nodetamongNx,Nm, andNnare denoted byTx,Tm, andTnrespectively. Eq. (9) can then be converted to a minimum(s,t)-cut problem by Theorem 1.Theorem 1The minimum(s,t)-cut cost function of graphG=(N∪{s,t},A)gives the same solution of Eq.   (9)   by settingxi=1when theith node ofNxis included inOthat is connected to the source nodes.mj,r=1for each similarity node inNmis included inTconnected to the sink nodet, andnj,r=1for each dissimilarity node inNnis included inO.ProofLet(O∪{s},T∪{t})be a partition ofN∪{s,t}forming a finite(s,t)-cut inG. This cut corresponds to a feasible solution because ifmj,r=1thenxj=1ofNSandxr=1ofNV. Ifnj,r=0thenxj=0andxr=0; otherwise an infinite cost arc will contribute to the cut capacity which violates the finiteness of the cut. The cut capacity is:C(O∪{s},T∪{t})=∑i∈Ox−K+∑i∈Ox,j∈TxBi,j+∑i∈Tmηi+∑i∈Onδi.BecauseTm=Nm−Om, the cut capacity can be reformulated asK|Ox−|+∑i∈Ox,j∈TxBi,j+(∑i∈Nmηi−∑i∈Omηi)+∑i∈Onδi. Since∑i∈Nmηiis constant, minimizingC(O∪{s},T∪{t})becomes equivalent to minimizingK|Ox−|+∑i∈Ox,j∈TxBi,j−∑i∈Omηi+∑i∈Onδi, which is exactly the same as the objective value of Eq. (9).After solving Eq. (9) with the min-cut/max-flow algorithm, we save a set of resulting faces whose vertices arexj(S)=1asSC⊂Sand a set of voxels where valuexr(V)=1as∂VC⊂∂V. The remaining regionsSN=S−SCand∂VN=∂V−∂VCare also saved, as shown in Fig. 7(b). We then mergeSCand∂VN, as described in Section  4.In many cases of dental CT images, critical artifacts occur due to metallic materials such as implants or prostheses, as shown in Fig. 1(c). This makes it hard to separate teeth from each other and to obtain the geometries of teeth. While our corresponding pair scheme and Eq. (9) give good results for normal dental CT without metal artifacts, it is not enough for other cases. However, the main advantage of co-segmentation is here. We can simply resolve this by complementing undesirable effects in dental CT with scanned data.Since the shape of teeth with metal artifacts are dissimilar between CT and optically scanned data, most of the artifact region do not have corresponding pairs or are classified to the non-crown region by a dissimilarity term if Eq. (9) is applied directly, as shown in Fig. 9(a). Therefore, we detect the artifact region first,VAin Fig. 8(d), and then make a corresponding set forVAby finding the closest vertices from the optically scanned surface.The artifact regions are generally included in∂VQ. In addition, the geometries of artifact regions are significantly different from neighboring regions. We use these two observations to detect artifact regions and perform segmentation.Let the set of voxels be∂VR, which are collected from thez-direction extreme point, an apex of the root, until meetingVP, as shown in Fig. 8(b). The seed regions of artifacts denoted byVSto find the area affected by metal artifactsVAare then determined by∂VS=VQ−∂VRin Fig. 8(c).VAcan then be found by searching fromVSto∂VRwith a simple region growing method, as shown in Fig. 8(d).When we apply Eq. (9) to the model with artifacts, the similarity term is only applied in the case of the corresponding pairs ofVA, except for the dissimilarity term for co-segmentation. If the dissimilarity term is not applied to these corresponding pairs ofVA, the crown is found from the optically scanned data and the matched crown regions inVAare classified by corresponding pairs. Fig. 9 shows our co-segmentation result of the model with metal artifacts.The goal of this study is to obtain a combined teeth model by aggregating strengths of each data type. The selected regions are not generally smoothly connected to∂V, as shown in Fig. 10. For the vertices ofSC, we assign the tooth index with an index of the closest voxel in∂V. The merge step is performed for the separated tooth independently after dividingSCby∪i=1nSCi.The important point in this step is to maintainSCas much as possible, because the accuracy of the optical scan data is much higher than the accuracy of dental CT. In order to achieve our goal, we adopt an approach that creates triangles from the boundaries ofSCwhile keeping the consistency of the surface normal vectors and triangle size. The overall procedure of this step is illustrated in Fig. 11.For our purpose, the concept of the marching triangle algorithm introduced by Hilton et al.  [28] is appropriate for determining new vertex positions and triangles from the boundary ofSC. This approach gives a fine solution to generate iso-surfaces from the arbitrary volume data  [29] with an adaptive mesh size that considers curvature values while maintaining the aspect ratio of the triangles  [30–33] by considering a 3D Delaunay surface constraint  [28]. The difference is that our problem is not to create an iso-surface from a given implicit function or a scalar field, but to generate smoothly combined triangles to∂Vfrom the boundary ofSC. Let us denote the set of boundary edges and vertices ofSCby∂SC. The key idea in this step is to compute signed distances of∂SCfrom∂Vand assign them to the nearest voxels in∂V. By propagating the values to∂VNby using a transition scheme that changes gradually, we are able to find the positions where new vertices lie. The details are described in this section.To determine the vertex positions of the merged surface, we compute signed distance values of vertices in∂SCfrom∂V. We then assign the values to the nearest voxels in∂V. Let the distance value of an assigned voxelqash0(q). We propagate the signed distances to the non-visited neighbor cells in∂VN. The value of the newly selected voxel is determined by averaging the visited neighbor cells to generate a smooth surface. These values represent the distances to the target surface from∂Vand we can determine the position of a new vertex using them during the advancing front method (AFM) procedure.Another consideration is to make the target surface more closely resemble∂Vmoving away from∂SC. We define the modified distance functionH(q)as Eq. (11) to apply this consideration by adopting the geodesic distanced∂VCfrom the nearest voxels of∂SC.(11)H(q)={h0(q)×Dt−d∂VC(q)Dtifd∂VC(q)<Dt0otherwisewhereDtis a user-defined constraint. We use the half value of thez-directional height ofSCasDtfor each tooth. Note thatH(q)is stored atq∈∂V, but the meaning is a target signed distance from∂Vindicating the position of the new vertex of the merged surface.After computing the target signed distances as a preprocessing step, we then find a new vertex position through three steps. At each boundary face,f, whose edgeE∈fis included in∂SC, we can generate a new initial vertexv0on the same plane withfand in the opposite direction at the midpoint ofE, as shown in Fig. 12(a).The next step is to find the normal vector ofv0. We approximate a normal vector ofv0by comparing thek-nearest voxel positions fromv0. We definenv0as shown in Fig. 12(b):nv0=v0−1k∑i∈Nk(x)pi|v0−1k∑i∈Nk(x)pi|.The new positionvnewis then created along thenv0direction fromv0. Finally we can determine the new vertex position using Eq. (13). Since computing an accurate distance value is very time-consuming and not necessary in this application, we approximate the distance by averaging the pre-calculated values at voxels. Rather than simply averagingH(pr), we consider the angular distributions ofpr. The weight ofpris computed as an angular occupancy after projecting to the plane that passesv0and has the normal vector asnv0. Let us denote the projected point ofprasqrand its circumcenter ascr. The weight ofqrisλr(v0), as shown in Fig. 12(c).The target distance to be maintained atv0is then defined in Eq. (12).(12)ht(v0)=∑r∈N(v0)λr(v0)⋅H(prv0),whereλr(v0)=θr2π.The distance at arbitrary positionvcan be computed as Eq. (13) wherenrv0is the normal vector ofprv0; the new vertex positionvnewis then determined by the conditionh(vnew)=ht(v0).(13)h(v)=∑r∈N(v0)λr(v0)(v−prv0)⋅nrv0.Fromv0as the initial value,vnewcan be iteratively found along the projection directionnv0by a binary search. The practical experiments show thatvnewis found in approximately five iterations within 0.001 mm tolerance.As mentioned before, even though our approach is technically similar to marching triangles, we call our method AFM since we do not extract an iso-surface. There are two possible cases where we can create new triangles: one of them is to create a face with existing vertices and the other one is to connect an existing edge and a new vertex generated by the method introduced in Section  4.1. Fig. 13shows the two cases. Fig. 13(a) shows the case involving connection with adjacent edges whose angle is less thanθt. If the angle with an adjacent edge in∂SCis larger thanθt, we check the 3D Delaunay surface constraint to prevent local folding or self-intersections. If there is a vertexviwithin the Delaunay sphere, then we connect it to the current edgeEf. Otherwise, a new vertex is created.The overall procedure of our AFM is described in Fig. 14. First, we initialize the priority queue (PQ), which contains boundary active edges in the order of the angles to the next connected edges shown in Fig. 13(a) in ascending order. To compute angles efficiently and maintain PQ, the boundary edges are stored as a half edge structure. Ifθ>θt, we compute the new vertex positionvnewfor the current active edgeEf, and check the 3D Delaunay surface constraints. If the triangleTsatisfies the constraint, we addTas a new face to the merge result.The 3D Delaunay surface constraint is similar to the Delaunay constraint of 2D triangulation. With a triangular face, the meaning of the condition is that there should be no point inside the sphere, called a Delaunay sphere, whose center and radius are consistent with those of the circumcircle of the triangle  [28]. Fig. 15(a) shows a conceptual diagram and Fig. 15(b),(c) describes cases wherevnewdoes not satisfy this constraint. To maintain a good aspect ratio, we need to make a new triangle by using the existing vertex which satisfies this constraint.If we only create a new triangle when it satisfies the 3D Delaunay surface constraint by checking the vertices as shown in Fig. 15, it may cause numerous cracks  [33]. In the case where the 3D Delaunay surface constraint is not satisfied, we can find candidate vertices{vi}inside the Delaunay sphere. Among them, we select the vertex that satisfies the Delaunay surface constraint when a new triangle is created with it. Fig. 16shows several cases of checking the validity of new triangles and the yellow color represents the solution of each case. Fig. 17shows the result of the merging step suggested in this work. Two different regions are connected successfully while maintaining the details of crown features.Because the resolution between surface meshes and dental CT images are different, we do not need to maintain the scanned surface mesh resolution in a root region higher than CT resolution. A large number of triangles may degrade the efficiency and usability in many applications. For efficiency, triangle sizes adopt the size of the propagated triangle and local curvature with a given errorε. Eq. (14) shows the rule to determine the new edge length of the new triangleT[31].(14)L(T)=2×1(κ|max|)2−(1κ|max|−ε)2whereκ|max|=max(|κmax|,|κmin|)andκmax,κminare the normal maximum curvature and minimum curvature of a voxel, respectively. The normal curvature of volume data can be computed by the method introduced in  [34], and we setε=0.001in our experiments. In Eq. (14),1/κ|max|is the radius of the smallest osculating circle at a tooth’s surface point as shown in Fig. 18. The length of the target edgeL(T)is then calculated by Eq. (14).Fig. 19shows a comparison of the results considering the adaptive size (Fig. 19(c)) and otherwise (Fig. 19(b)) for the same tooth model.To handle metal artifact data in this merging step, we simply remove the crowns that have artifacts from the merging area. Most of the crown surfaces are recovered from the scan data, and the missing part can be restored by smooth hole filling considering the boundary shapes  [6,35–37]. Fig. 20shows the final tooth result with metal artifacts.

@&#CONCLUSIONS@&#
