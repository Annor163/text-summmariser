@&#MAIN-TITLE@&#
A multiple minima genetic algorithm for protein structure prediction

@&#HIGHLIGHTS@&#
A multiple minima genetic algorithm is proposed for protein structure prediction.Multiple minima capability is achieved thorough a phenotype based crowding scheme.The GA was developed under the HP model and later adapted to an all-atom model.Results for the HP benchmark sequences surpass other evolutionary algorithms.Under the atomistic model the GA was able to locate global minimum structures.

@&#KEYPHRASES@&#
Genetic algorithms,Protein structure prediction,HP model,Multiple minima,

@&#ABSTRACT@&#
Protein structure prediction (PSP) has a large potential for valuable biotechnological applications. However the prediction itself encompasses a difficult optimization problem with thousands of degrees of freedom and is associated with extremely complex energy landscapes. In this work a simplified three-dimensional protein model (hydrophobic-polar model, HP in a cubic lattice) was used in order to allow for the fast development of a robust and efficient genetic algorithm based methodology. The new methodology employs a phenotype based crowding mechanism for the maintenance of useful diversity within the populations, which resulted in increased performance and granted the algorithm multiple solutions capabilities. Tests against several benchmark HP sequences and comparative results showed that the proposed genetic algorithm is superior to other evolutionary algorithms. The proposed algorithm was then successfully adapted to an all-atom protein model and tested on poly-alanines. The native structure, an alpha helix, was found in all test cases as a local or a global minimum, in addition to other conformations with similar energies. The results showed that optimization strategies with multiple solutions capability present two advantages for PSP applications. The first one is a more efficient investigation of complex energy landscapes; the second one is an increase in the probability of finding native structures, even when they are not at the global optimum.

@&#INTRODUCTION@&#
The protein structure prediction (PSP) problem is one of the most interesting challenges of modern computational biology [1]. Ab initio protein prediction methods aim at constructing the native tridimensional structure for a given amino acid sequence, without requiring the use of experimental information about related protein structures.Methods for PSP have a wide range of important biotechnological applications, e.g., the design of new proteins and folds [2,3], structure based drug design projects [4], refinement of theoretical models obtained by comparative modeling [5,6], and obtaining experimental structures from incomplete nuclear magnetic resonance data [7,8]. Furthermore, the function of a protein is a consequence of its structure, and to be able to predict the native structures of proteins would help to take advantage of the large amount of biological information that is being generated by genome sequencing projects.Most PSP methods follow the thermodynamics hypothesis, i.e., the conformation adopted by the protein under physiological conditions is the conformation with the lowest Gibbs free energy [9]. Thus the problem is formulated as a minimization problem and can be divided in two sub-problems: (i) to define an appropriate energy function that places the native structure on its global minimum and is able to discriminate correct from incorrect folds; (ii) to develop an efficient and robust search strategy capable of dealing with a large number of variables and a highly degenerated and complex energy landscape.The search for a method capable of predicting the native structure in the absence of known homologous structures is still an open problem. Research efforts are periodically evaluated during the biannual CASP (Critical Assessment of Structure Prediction) meetings. Currently the most promising methods utilize some form of information from known protein structures, nevertheless they are still based on optimizing complex and expensive energy functions [10–12]. This search is often carried out by metaheuristics and, amongst them, Genetic Algorithms (GA) are noteworthy [13] because of their robustness and wide applicability. These advantages can be explained, at least partially, by the GA's stochastic nature and because they work with a population of candidate solutions (that makes this type of method naturally parallel). Another attractive feature is that they do not require differentiability or continuity of the fitness function. Despite their advantages, they usually require a large number of fitness function evaluations in order to reach optimal or near optimal solutions specially when complex models are involved such as those used for PSP with atomic details.It is a common practice to adopt models with reduced complexity in PSP and protein folding related studies [14], e.g., lattice models. By sacrificing atomic details, lattice models may be used to extract essential folding principles, make predictions, and unify the knowledge on several protein properties without the heavy computational cost associated with all-atom models [15–17]. In addition to reducing the number of atomic “types”, one important approximation introduced by lattice models is the discretization of the conformational space. While this makes the construction of an exact protein structure impossible, some key features of the optimization problem are retained. The energy landscape presents massive multimodality, different conformations with the same energy (degeneracy), and large regions with unfeasible conformations. Consequently, methods capable of finding low energy conformation for lattice models have not only the potential to provide insights on the folding process but also can be applied to complex models with atomic details [18]. The first studies of protein structure prediction (PSP) with lattice models considered that the abstract formulations had limited practical applications. However, further studies showed results that could be applied to more detailed models and also that the search methodologies could be adapted to other related problems [19].The simple well defined energy function of lattice models facilitates a faster and more reliable development of robust optimization methodologies. Reliability is an important aspect because when dealing with complex atomistic models the success of a methodology is subject to inaccuracies in the energy models.This paper reports a research on a multiple minima genetic algorithm applied to the hydrophobic-polar (HP) simplified protein model in a cubic lattice. The performance of the GA was analyzed and compared to other methods from the literature. The methodology was then adapted and applied to an all-atom model under a classical force field energy function.Simplified models employed on PSP studies try to reflect general characteristics of protein structures [20]. The HP model's folding process has some behavioral similarities with the folding of real proteic system [21,22]. The hydrophobic–hydrophilic (or hydrophobic-polar, HP) model [23] describes the proteins based on the principle that during the folding process hydrophobic amino acids tend to be hidden from a polar solvent, thus resulting in the formation of a hydrophobic core within the native tridimensional structure. The HP-model abstracts the amino acid sequence to a binary sequence of monomers that are either hydrophobic (H) or polar (P).Conformations are usually bound to some lattice, with each monomer occupying one site and there have been several works describing different types of lattices [18]. In this work, a tridimensional structure is portrayed as a self-avoiding walk on a cubic lattice. The energy is calculated as the negative of the number of hydrophobic–hydrophobic contacts (HH contacts) which are defined as two non-consecutive (non-bonded) monomers occupying adjacent sites on the lattice.A conformation is valid only when no lattice site is occupied by more than one monomer. Invalid conformations are said to contain collisions. For a valid conformation c under the HP model, with n HH contacts, the energy E is given by:(1)E(c)=n·(−1)In spite of the model simplicity, finding optimal structures on a cubic lattice has been classified as aNP-hard problem [24,25]. As a result, several nature-inspired metaheuristics have been applied to the problem [26], such as, Immune Algorithm [27], Ant Colony Optimization [28], Differential Evolution [29], Particle Swarm Optimization [30] and Evolutionary Algorithm [31]. The proposed algorithm belongs to the evolutionary class, more specifically genetic algorithms.The energy landscape of the HP-model has some key features that directed the design of the genetic algorithm implemented in this work. These are (i) considerable multimodality, (ii) high degeneracy, and (iii) large regions of invalid conformations [32,25,33–35]. Another important attribute is that low energy structures may have different topologies which can be very different from the ones observed for global minima [36].Several algorithms have been applied to the PSP-HP problem on cubic lattices and were tested against the same set of benchmark sequences used in this work. Those include evolutionary algorithms, construction based approaches (chain growth) and other heuristics.Unger and Moult [37] employed a hybrid genetic algorithm/Monte Carlo method, using an encoding where individuals (candidate solutions) were represented in a sequence of absolute directions s∈{U, D, L, R, F, B} (Up – Down – Left – Right – Front – Back), for a chain of length n. Only valid conformations were accepted and each genetic operator would iterate until a new valid solution was created. The results showed that the hybrid GA constructed low energy solutions in fewer steps (function evaluations) than a pure Monte Carlo method.In turn, Patton et al. [38] employed a standard GA with a relative encoding, i.e., s∈{U, D, L, R, F} which has the advantage of eliminating return moves, e.g., {L, R}, that under absolute encoding schemes cause collisions. Invalid conformations were tolerated but suffered penalties, that is, collided monomers did not have their HH contacts computed and the total number of HH contacts was decremented by the number of collisions. A crowding scheme, using energy as the crowding criterion, was used to maintain diversity within the populations. Their results for test sequences from [37] showed that structures with lower energies required fewer function evaluations than the hybrid GA/MC.Khimasia and Coveney [39] introduced a “simple GA” using absolute encoding with fitness-based selection and elitism. Conformations with collisions were tolerated, but penalized. The GA was tested with the sequences set from [37] and [40] and performed well with the shorter sequences (27 monomers) from [37]. It was suggested that a multi-point crossover could improve the performance for longer sequences. The study by Krasnogor et al. [34] explored the relative merits of absolute and relative encodings, defining a series of isomorphisms amongst genetic operators for both codifications. They suggested that the most useful operators acted as local optimizers, that is, the new structures remained within the neighborhood of the original ones on the conformation space. They also penalized invalid conformations.A GA was applied with emphasis on local search (a memetic algorithm) following the ideas of Krasnogor et al. [34] and on the implementation of speciation methods based on the genotype (for preserving diversity in the population) [41]. The results on the test sequences set from Yue et al. [40] showed that local search has good potential for increasing the performance when simple operators (one-point crossover and mutation) are used.Custódio et al. [42] introduced a modification to the scoring system of the original HP model in order to generate more natural structures. Additionally, they showed that a simple genetic algorithm could have its performance improved with the use of a new selection scheme (modified elitism) and application of a multi-point crossover. Mansour and Kanj [31] applied a simple genetic algorithm with relative encoding and a heuristic to repair infeasible solutions generated by the operators.In addition to evolutionary algorithms, other methods have been applied to the PSP-HP problem. These are based on heuristics of the folding process, such as cooperativity effects or the existence of a hydrophobic core. It is believed that cooperativity arises from the formation of local optimal structures, that is, on segments of the chain, which allows the global minimum to be reached without an exhaustive search [43].The Hydrophobic Zipper (HZ) strategy is based on the hypothesis that each time a HH contact is formed it can no longer be undone and new contacts are formed in accordance to the already folded segments of the structure (cooperatively) [43]. The Contact Interactions (CI) algorithm [44] combines the ideas from HZ with a Monte Carlo search that attributes a computed conformational flexibility to selected parts of the chain allowing previously formed HH contacts to be separated. The Core-directed Chain Growth (CG) directs chain construction using a heuristic function designed to construct the hydrophobic core as a cube [45]. The Constraint-based Hydrophobic Core Construction (CHCC) builds the structures systematically introducing a set of geometrical restrictions towards a maximally compact hydrophobic core [46]. A similar method was proposed for the face-centered cubic lattice [47]. The complexity of these methods grows exponentially with the sequence length, which is problematic for very long sequences (more than 100 monomers) [39]. Amongst the most successful methods is the Prune-Enriched Rosenbluth Method (PERM) [32,48] and its variation [49]; a chain growth algorithm that evaluates partial conformations and applies enrichment and elimination strategies to explore the most promising solutions. The Constraint-Based Approach is an exact approach to the PSP-HP problem that outperforms all previous methods and was able to show that the CHCC method is incomplete [50].Other methods include a “dynamic” Monte Carlo where long distance movements are used involving chain breaks [51] and an evolutionary Monte Carlo which performed MC optimization on a population. An ant colony optimization algorithm (ACO), enhanced by a local search, showed results for the sequences from Yue [40] equivalent, in terms of the lowest energy found, to the constructive methods (HZ, CG, CHCC and PERM) and surpassing previously described evolutionary algorithms [28]. A Replica Exchange Monte Carlo with pull move neighborhood (REMCpm), was also shown to perform favorably with the same benchmark sequences [52]. A Particle Swarm Optimization (PSO) based algorithm was able to reach previously described energies with fewer energy evaluations [30] using a relative encoding and a repair mechanism.A steady-state genetic algorithm was developed for the PSP-HP problem and implemented in the GAHP program. Chromosomes are said to represent solutions in the genotype space and to encode the tridimensional structure in the phenotype space. The fitness for a solution is given by the energy of the corresponding structure, that is, the search is executed towards the lowest energy solutions. The HP model energy function and its particularities are described in Section 1.1. The following sub-sections describe the details of the GA.A structure under the HP model in a cubic lattice consists of a chain of monomers occupying sites in the lattice where each monomer has its cartesian coordinates (x, y, z) defining the chain conformation. This conformation must be encoded in a chromosome for the GA, however it is not feasible to use the cartesian coordinates directly as it would introduce the necessity to check if movements would violate the chain connectivity at each step of the algorithm. As it was used in the first GA applied to the PSP-HP problem [37] (Section 1.2), the GAHP algorithm uses absolute encoding where for a sequence of n monomers a chromosome containing n−1 positions, or bases, determine the placement of the monomers on the lattice. Fig. 1exemplifies the encoding scheme for a short sequence of ten monomers.The initial population is randomly generated, that is, random directions are selected for each chromosome in the initial population. This invariantly results in the creation of invalid solutions, particularly with longer sequences. Trial runs for a 48-monomer sequence showed that 98% of the individuals in an initial population of size 500 contained at least one collision. Furthermore, approximately 5000 function evaluations were spent until all collisions were eliminated from the population. This prompted the application of a simple repair mechanism to each invalid solution from the initial population. The net result is no function evaluations being spent on the initial untangling of invalid structures.The repair mechanism is applied as the chains are growing, i.e., collisions are checked only in relation to previous monomers on the sequence. The repair changes the base corresponding to the collided monomer to another randomly chosen direction until the growing structure is valid. There are some remarks that limit the application of the repair, e.g., the structure may suffer large geometrical changes that can worsen its energy and it is possible that some structures cannot be repaired (in those cases the total number of HH contacts is considered zero).Six genetic operators were used: standard two-point crossover (2X), multi-point crossover (MPX), segment mutation (SMUT), exhaustive search mutation (EMUT), local move (LM), and loop move (LPM). The MPX operator is similar to 2X, but the number of cut-points, c, is a function of the sequence length, n, given byc=nintn×0.1[42]. The MPX operator was used to promote structural diversity by performing a random shuffle between individuals, although not as thorough as a uniform crossover. Previous work showed that the MPX operator could improve the performance of a GA applied to the 3D HP model [42].The SMUT operator changes a random number of consecutive bases (from two to seven) into new random directions. This operator introduces large conformational changes and has a high probability of creating collisions, thus the repair mechanism is applied on the generated child, if needed.The exhaustive search mutation (EMUT) operator tests all possible directions for a randomly selected base and keeps the one which results in the best score for the whole structure. EMUT demands four fitness function evaluations which are properly accounted in the computational experiments. The EMUT was an attempt to create a hybrid GA with an exhaustive local search. This operator has the drawback of spending four additional function evaluations, but it has great potential for fitness improvement.The LM operator swaps the directions between two randomly chosen consecutive bases (Fig. 2). There are conditions that must be satisfied to avoid the creation of collisions, i.e., the new directions must not create redundant movements. This operator introduces a corner movement [41] leading to small conformational changes. In a similar way, the LPM operator exchanges directions between two bases that are five positions apart on the sequence creating a loop movement (Fig. 2). Both LM and LPM are local movement operators that are particularly useful to generate modifications on compact structures. These can be particularly useful during the later stages of the search when the structures are highly compact.An adaptive procedure based on the algorithm described by Davis [53] was used to dynamically define the operators’ application probabilities. Each operator has its probability adjusted based on its performance in generating improved structures during the GA run. The fitness of each new structure, created by application of one genetic operator in a parent structure, is compared to the current best in the population. If the new structure is better than the previous best, the operator that created it will receive some “credit” that is equal to the fitness improvement, i.e., the difference in the number of HH contacts. Additionally, the operator that created the parent structure receives 50% of the credit (25% for each parent if the new structure was generated by recombination). For each 10 newly generated structures the operators’ probabilities are adjusted according to their current credit amount, taking care that no application probability is below 2%.From the discrete nature of the PSP-HP problem, fitness variations occur only when the number of HH contacts changes. When the search procedure reaches low energy regions on the conformations space (many HH contacts) the creation of a new HH contact by application of an operator becomes a rare event and this can cause stagnation of the values of the application probabilities. Trial runs showed that after the large initial fitness improvements the application probabilities tend to remain static. That is not compatible with the idea of using an adaptive method to apply different operators in different regions of the conformational space. Therefore, a simple ad hoc modification was introduced: if an operator gains no credit after 10,000 calls, it receives a penalty in the form of one unit of negative credit. The effect of this modification is that after some time generating no new best individuals the probabilities slowly return to a uniform distribution, allowing other operators to be tried. The EMUT operator has a greater chance of receiving credit but this comes with the cost of four function evaluations. For that reason any credit gained by the EMUT operator is divided by four.There was no discernible pattern of the operators’ probabilities over time. That is, they vary greatly among different sequences and even among different runs for the same sequence. The only observable pattern was that the crossover operators showed some slight preference during the very initial evaluations (see On-line supplements). These observations reinforce the importance of the use of an adaptive procedure.The selection of parents for the application of the operators was carried out by means of a tournament [54] of four randomly chosen individuals.A critical aspect of methods for PSP-HP is the preservation of diversity within the populations. On a highly multimodal fitness landscape, as in the PSP-HP problem, diversity allows the simultaneous exploration of multiple high fitness regions reducing the chances of convergence to low quality local optima. Amongst the many GA modifications proposed to deal with these situations, fitness sharing [13,55] has the drawback of requiring previous knowledge about the search space, e.g., the estimated distance between optimal solutions [56]. Crowding, introduced by [57] and subsequently improved by Mahfound [58], does not have this disadvantage. A parental replacement method based on crowding was applied to the PSP-HP problem and is described below.A crowding based parental substitution forces competition between the most similar individuals inducing the formation of niches within the population and preserving diversity according to the chosen crowding criterion.For each new individual, a search is performed in the parental population for the individual which is closest to the new one. If the new one has a better energy the parental individual is replaced; if they have equal energies the new one has a 50% chance of replacing the parental one, and if the new individual has a worst energy it is discarded.In this work, a new crowding strategy is employed by using the phenotypes, i.e., the structures themselves. The distance between two individuals is based on the conformation of the structures’ hydrophobic core and is given by the Distance Matrix Error (DME) of the hydrophobic monomers positions:(2)DME=∑i=1,j>iN(pij−qij)2N(N−1)/2,for a structure with N hydrophobic monomers and pij(resp. qij) denoting the distance between H monomers i and j on the parental (resp. new) structure.It has been shown that the hydrophobic core conformation is an useful measure for structure comparison [59–61]. Although the DME of the hydrophobic monomers can be computationally more expensive than the objective function of the HP model, it has the advantage of being easily adopted by an all-atom PSP method, where its cost will be only a fraction of the atomistic energy function.In this section the adaptations, implemented in the GAPF program, of the algorithm to be used under an atomistic model are described. Such model is fundamentally more complex than the HP model in two aspects. First, the number of different “beads”, i.e., beads now represent the atoms themselves with all the types found in proteins. And also, the chain is no longer constrained by a lattice, and backbone dihedrals, with the exception of the peptide bond, are free to rotate.The atomistic model has a more complex behavior, that is, a structure may be more similar to the native structure, but still exhibit higher energies than another highly compact, but unnatural, optimized structure. This originates from the common simplifications introduced, when modeling complex molecular systems, such as, a proper treatment of the solute–solvent interactions, and the effects of the entropy on the system as a whole. On the other hand, the energy model for the PSP-HP problem is completely determined, i.e., the best structure is the one with the higher number of contacts, provided it is free of collisions (although more than one structure with the best energy may be present).The fitness function employed here is based on the energies from the interaction between the atoms of the protein. This energy is calculated using the classical molecular force field GROMOS43. By fixing bond's lengths and angles it is unnecessary to calculate the force field terms related to these parameters. Therefore, the employed fitness function comprises non-bonded terms, i.e., Lennard-Jones potential for modeling short range repulsion and long range attraction, and Coulomb potential for modeling charges interactions. In addition, the term associated with the main chain dihedral torsions (proper dihedrals) is used. The fitness function has the following form:Etotal(ri)=Etorc+ELJ+Ecoul+EsolvEtorc=∑nNϕKϕn[1+cos(nnϕn−δn)]ELJ=∑i≤jNatoms−Aijrij6+Bijrij12Ecoul=∑i<jNatomsqiqj4πɛ0ɛr(rij)rijwhere rijis the distance between atoms i and j, Aijand Bijare Lennard-Jones parameters dependent on the atomic type, qiand qjare the atomic charges of atoms i and j, and ɛris a distance dependent dielectric sigmoid function, which models the attenuation of the attraction between distant charges caused by water as a solvent, and preserves the strong attraction at shorter distances [62]. The parameter Kϕnis the energy constant associated with the torsion of a bond, ϕnis the torsion angle, nnis the period and δnthe phase angle.Structures were encoded in chromosomes with the same length of the target sequences, and each position contained the backbone dihedral angles ϕ, ψ and ω. Although the torsion angles ω of the peptide bonds are explicit on the chromosome they do not change during the execution and are kept in the trans (180°) configuration.Differently from the PSP-HP problem, the initial populations are not completely random. Individuals are initialized in an extended conformation with minor variations, i.e., at most 20° for ϕ and ψ and 2° for ω. A specialized mechanism for dealing with collisions was not implemented and such undesirable traits are intrinsically treated by the energy model, more specifically by the r−12 term of the Lennard-Jones potential which models Pauli's exclusion principle, that is, the short range repulsion between atoms.The recombination operators, 2X and MPX, applied to the PSP-HP problem were directly ported to the atomistic model without modifications. Mutation operators were adapted to the new representation: the SMUT changes up to seven consecutive positions (ϕ and ψ) to new values randomly selected from the interval [−180°, 180°]. The Incremental Mutation (IMUT) operator adds a randomly chosen value from the interval [−10°, 10°] to a randomly selected ϕ or ψ, thus causing relatively small chain movements. The Compensatory Mutation operator (CMUT) randomly increases a ϕ angle and decreases the corresponding ψ by the same magnitude. And the TC operator, which exchanges the contents of two consecutive positions of the chromosome.The application of the operators follows the same adaptive scheme described earlier used in the PSP-HP problem.The same crowding mechanism from the PSP-HP was applied to the atomistic model and the distances used in the DME calculation are those between the alpha carbons of hydrophobic residues classified according to Callebaut et al. [63]. The DME corresponds to a large portion of the total GA's computational cost when used with the HP model. However, as the energy model for the all-atom application is considerably more expensive, the additional cost of using such a distance metric is contextually smaller. Moreover, the computational costs of the DME under all-atom models is reduced because the inter-atomic distances required for its calculation are also used for energy function (fitness) evaluations.Three sets of sequences from the literature were used to evaluate the GAHP algorithm. The first set comprises ten sequences with 48 monomers each that were initially proposed as a challenge to HP model optimization algorithms [40] and were designed to present a maximally compact ground state (lowest energy conformation). These sequences have been studied by the following methods: Contact Interactions Monte Carlo (CI) [44], Standard Genetic Algorithm (SGA) [39], Memetic Algorithm (MA) [41] and Ant Colony Optimization (ACO) [28]. They were also studied by the following construction-based methods: Hydrophobic Zipper (HZ), Constraint-based Hydrophobic Core Construction (CHCC) [40], Core-directed Chain Growth Algorithm (CG) [45] and Pruned-enriched Rosenbluth Method (PERM) [32,49]. CHCC and PERM are said to be guaranteed, i.e., a structure with the global minimum energy is always found, however, these cannot be directly applied to an atomistic model. Conversely the more general approaches by evolutionary algorithms may be applied to more realistic models, with minimal adaptations, as is demonstrated in this work.The second set contains ten 64-monomer sequences randomly generated to exhibit about 40% hydrophobic monomers and were previously studied with a Metropolis Monte Carlo method, a variation of the Monte Carlo method incorporating a GA [37], and two standard GAs [38,39].The third set is composed of five protein-inspired sequences with lengths ranging from 46 to 135 monomers [43] and were studied by the CI method [44]. These sequences are useful in demonstrating the scalability of the GA with longer sequences.The GAHP tests used populations of 500 individuals, which during trial runs proved to be a reasonable size for conserving diversity and allowing deep exploration of different low energy regions on the search space. For each test-sequence 50 independent executions were performed.The test sequences for the atomistic model were short poly-alanine peptides (18ala and 23ala). Their native structure is known to be an alpha helix and they were studied under an assortment of optimization techniques [64], including methods with multiple minima characteristics [65,66].Alpha helix conformations are easier to construct possibly because they are a secondary structure element stable in itself, whereas beta-strands are stable, i.e., are energetically favorable, only when participating in a beta-sheet. Another relevant characteristic of poly-alanines is that they present less complexity compared to sequences containing other amino acid types, because their side-chains do not have degrees of freedom under the model used. Furthermore, under the employed force field alanine residues have side-chains represented as single united atoms, without polarity or charges and, consequently, do not contribute to the electrostatic potential, although they contribute to the Lennard-Jones potential.Two distinct test configurations were investigated, (i) one with charged chain terminals (NH3+; COO−) and (ii) another with neutralized terminals (NH2; COOH). The effective difference between these configurations is that with charged terminals there is a strong electrostatic attraction between the chain extremities. Under the energy function employed and the first configuration (i) the global minimum is an alpha helix and under the second configuration (ii) it is a bent helix with terminals in close proximity. Such conditions are useful for evaluating the algorithm behavior when the conformation of interest may not be at the global minimum of the energy function due to approximations, thus accessing the multiple minima capabilities of the algorithm.During parental replacement DME calculations used the position of all alanine alpha carbons. Tests were performed with populations of 200 individuals.For the set of ten sequences with 48 monomers, executions were allowed for a maximum of 4 million fitness function evaluations. Structures with global minimum energies were found for all ten sequences using GAHP. In comparison to other evolutionary approaches, GAHP found better energies (larger number of HH contacts) than the SGA method for ten sequences and better than the MA method for two sequences. Among other approaches, including construction based methods, GAHP found better energies than those reported by the CI method for seven sequences, than those generated by the HZ method for nine sequences and for one sequence from those reported by the CG approach. The methods ACO, CHCC and PERM found the lowest possible energy (global energy minimum) for all ten 48 monomers sequences, as did the GAHP method. Furthermore, the average energies from 50 independent executions were near the global minimum energy showing a difference of less than three HH contacts (Table 1).These sequences are more difficult for the GAHP because the ground state conformations adopt very compact hydrophobic cores. Thus local minima traps are common because the application of the operators is often not sufficient to construct a path to a global minimum, and frequently causes collisions. Fig. 3shows a ground state conformation for sequence 48.2 possessing 34 HH contacts arranged in a compact hydrophobic core. Another evolutionary approach that uses a crowding methodology is the MA method. Which is based on a genotypic comparison criterion and uses preferential encoding. However, their results were obtained with a higher budget: 6 million function evaluations. It also performs additional evaluations (not accounted for) when carrying out a local search (a memetic process) for the creation of each new individual.When applied to the 64-monomer sequences, GAHP constructed structures with better energies than other evolutionary algorithms. Furthermore, average energies from 50 executions are better (higher number of HH contacts) than the previously reported best energies for seven out of ten sequences (Table 2). Moreover, the number of function evaluations required to reach the same number of HH contacts as Patton et al. [38] is lower than that required by both their SGA and the PSO approach (Table 3).The results with the biology-inspired sequences (Table 4) suggest that GAHP has a performance equal to or superior to the CI method with the shorter sequences of up to 58 monomers. With the longer sequences, GAHP constructed structures with a larger number of HH contacts. Especially noteworthy are the results for the longer sequences, 124 and 136 monomers, for which structures were found with up to five HH contacts more than the best results published. These sequences represent a major challenge for any optimization approach. And, during the executions, the chain would often assume a conformation with two or more hydrophobic cores. The structure shown in Fig. 4is an example of a conformation, for sequence 136, with two hydrophobic nuclei with a total of 52 HH contacts, having been generated from approximately 200,000 function evaluations and being preserved in the population at the end of the execution. This is an indication of populations with rich structural diversity being maintained throughout the executions, a beneficial algorithmic trait for the PSP problem.Analysis of the structures from all populations, at the end of executions, showed that GAHP was able to find multiple low energy solutions for all tested sequences. The number of different structures found (different arrangements showing the same number of HH contacts) decreased as the number of HH contacts increased. A similar profile to that exemplified for sequences 48.1, 64.10, 124 and 136 in Fig. 5was observed for all test sequences. GAHP was able to perform in 50 executions a reasonable sampling of conformations with energy close to the native state in the space of conformations.The profile of solutions distribution along the scale of hydrophobic contacts is suggestive of the type of problem faced by the GAHP. Energies slightly above the lowest found were intensely populated. This reflects the diversity distribution at the end of the executions, for example, for sequence 48.1, 17 different structures were found at the global minimum (32 HH contacts) and many more structures with 28 HH contacts were found. This means that the 28 HH contacts energy region is more accessible to the algorithm than the global minimum region.Our results showed that a multiple-minima approach is efficient in avoiding highly accessible regions in the energy landscape increasing the probability of reaching the global minimum. Moreover, a method capable of finding many different low energy solutions is especially useful for the PSP problem. That is, with all-atom molecular models, it is frequently difficult to decide, among the low energy structures, which is the “correct” (biologically relevant) one. In addition, with a molecular model there is no guarantee that the structure with the lowest energy (global minimum) is actually the native structure. This arises from the approximations made in the energy function, as important physical effects are not modeled correctly, such as, conformational entropy and system solvation. It can be considered as an important advantage the fact that an algorithm performs a more extensive and detailed exploration of several energy minima.Results were obtained from 30 independent executions each with 500,000 function evaluations. Reference alpha helix structures (18ala and 23ala) were generated using the protein structure prediction software suite developed in this work (GAPF), using average values for ϕ and ψ angles in the alpha helix range. After generation, these structures underwent 1000 steps of steepest-descent energy minimization using the Gromacs software [67] and the GROMOS43 force field [68].The alpha helix structure was found, as the global minimum, in 100% of the 30 runs, that is, the alpha helix structure was always the individual with the best fitness in the population at the end of the executions. The average RMSD (root mean squared deviation) of the backbone atoms from these structures to the reference structure was 0.417Å for 18ala and 0.396Å for 23ala. Further analysis showed no correlation between energies and RMSD (Fig. 6). Nevertheless, alpha helix structures showed the lowest energies. Fig. 6 demonstrated that the algorithm was efficient in sampling a wide range of energies and conformations.Maintaining the chain terminals charged, the global minimum found was a compact structure composed of segments of helices with the terminals in close proximity (Fig. 7). In all 30 executions, the final population contained compact conformations in addition to a series of structures in alpha helix with energies up to 3kcal/mol higher than the compact ones. From the analysis of correlation between RMSD (to an idealized alpha helix) and energies in Fig. 8it is possible to identify several conformations with energies close to the alpha helix structures, but with high RMSD (larger than 6.0Å) and compact conformations. This exemplifies the complexity of the energy landscape, even with simple sequences such as poly-alanines. In fact, the compact global minimum structures found with charged terminals are an artifact of the energy model used, which does not account for the entropic effects from the solvent and the peptide chain. This results in the electrostatic collapse of the chain which, in some way, could be avoided by neutralizing the formal charges.To further validate the use of the crowding parental replacement method for PSP, a comparison was performed against the following parental replacement techniques: (i) EMOD – modified elitism (generational AG) [42], (ii) SSGA – standard steady-state genetic algorithm. The comparison was carried out using neutralized poly-alanines verifying diversity in the final populations under the different methodologies.In 30 independent runs for each method, it was observed that for 18ala, the alpha helix structure was found in 100% of the executions using EMOD, in a single run using SSGA, and in 100% of the executions using crowding. Additionally, for the 23ala the alpha helix structure was found in a single run using EMOD, a single run using SSGA, and 100% of the executions using crowding.An essential aspect of parental replacement methods is the preservation of useful diversity within the populations. Using the RMSD in relation to an idealized alpha helix, the structural diversity within the populations was analyzed and it was observed that when using EMOD or SSGA all individuals of the population had the same structure, i.e. the entire population had converged to the same structure (Fig. 9). This convergence was, in many cases, premature because the structure present on the population was not the global minimum. The loss of diversity in the population will cause losses in the performance of the GA, as the exploitation of the search space will be limited to one region. In contrast, all executions using the crowding method ended with very diverse populations, both structurally and energetically. This diversity is the raw material for the evolutionary processes modeled by the GA allowing it to act as an efficient and robust optimization technique. Moreover, the large diversity coupled with competition among similar individuals (concept of niche) result in the simultaneous exploration of more than one low energy region in the search space. This allows for the opportunity of interesting exchanges of useful information between individuals occupying different low energy regions, by application of the of recombination operators, all within a single execution.

@&#CONCLUSIONS@&#
A simplified protein model, the HP model, was used to develop an optimization methodology for protein structure prediction. This methodology was successfully adapted to an all-atom model based on a classical molecular force field. The new methodology is based on GAs and its main differential is the application of a crowding mechanism based on the phenotype. The distance between individuals for crowding is the DME calculated for the position of the hydrophobic monomers in the tridimensional structure. This algorithm was tested with the main HP benchmark sequences and was found to be comparable to construction based approaches, specialized in the HP model, and superior to other evolutionary algorithms. In addition the algorithm proved to be capable of generating multiple conformations for local or global energy minima.The all-atom implementation was tested with poly-alanines peptides. The tests were conducted with two settings, one where the alpha helix structure was the lowest energy conformation and another where the lowest energy structure was a compact conformation. In both cases, the GA was able to find the native structure (alpha helix in a global or local minimum) with a success rate of 100%.The results obtained confirmed previous observations by our research group [69] that a multiple solutions approach to complex problems, such as flexible molecular docking and protein structure prediction, is of great value resulting in methods capable of an efficient exploration of the energy landscape. As in the docking problem, there are important advantages of applying this type of approach to the PSP problem. For example, there are the inherent approximations of the energy function, such as, lack of proper solvation and conformation entropy modeling, consequently the native structure may not be associated with the global minimum of the energy landscape. The conservation of frequently visited sub-optimal structures during the search procedure increases the probability of identifying the native structure, even if it is a local minimum of an imperfect energy function. Furthermore, this strategy can be very useful in obtaining, in a more natural way, other important structural features, such as, partially folded protein states, the folding nucleus or even alternative folds.This work resulted in the development of two new programs. The GA applied to the problem PSP-HP was implemented in a flexible application called GAHP. Additionally, a graphical interface for visualization of HP structures was created. GAHP's source code will be made available on request to the academic community. The program for PSP with atomistic models, GAPF, was developed with care to be easily extensible and configurable. GAPF's use will be made available to users in the near future.