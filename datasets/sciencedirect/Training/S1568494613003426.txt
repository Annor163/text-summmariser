@&#MAIN-TITLE@&#
A modified objective function method with feasible-guiding strategy to solve constrained multi-objective optimization problems

@&#HIGHLIGHTS@&#
A modified objective function method is proposed to handle constraints in CMOPs.A feasible-guiding strategy is adopted to guide the evolution of infeasible individuals.Compared experimental results show the superiority of proposed objective function method.Feasible-guiding strategy promotes the convergence of obtained non-nominated solutions.

@&#KEYPHRASES@&#
Constrained multi-objective optimization,Constraint handling,Modified objective function method,Feasible-guiding strategy,

@&#ABSTRACT@&#
For constrained multi-objective optimization problems (CMOPs), how to preserve infeasible individuals and make use of them is a problem to be solved. In this case, a modified objective function method with feasible-guiding strategy on the basis of NSGA-II is proposed to handle CMOPs in this paper. The main idea of proposed algorithm is to modify the objective function values of an individual with its constraint violation values and true objective function values, of which a feasibility ratio fed back from current population is used to keep the balance, and then the feasible-guiding strategy is adopted to make use of preserved infeasible individuals. In this way, non-dominated solutions, obtained from proposed algorithm, show superiority on convergence and diversity of distribution, which can be confirmed by the comparison experiment results with other two CMOEAs on commonly used constrained test problems.

@&#INTRODUCTION@&#
In real world, we often encounter problems that at least two objectives need to be optimized simultaneously and a set of constraint conditions must be satisfied in the meantime. All these problems are called constrained multi-objective optimization problems (CMOPs). Solving CMOPs is an important part of the optimization field. In contrast to multi-objective optimization problems (MOPs), CMOPs have to deal with various limits on decision variables, the interference resulting from constraints, and the relationship between objective functions and constraints [1].There are a large amount of constraint handling methods in solving constrained optimization problems. According to [2,3], the commonly used constraint handling methods can be roughly classified into four categories:(1)Use of penalty functions:Method based on penalty functions is the simplest and most commonly used constraint handling approach. It combines constraint violations with objective functions through the penalty coefficients that are used to keep the balance between them. For penalty function method, its challenge is how to regulate the penalty coefficients to preserve individuals [1]. It can be classified into different categories according to their values. If the penalty coefficients stay constant during the whole search process, then it is called static penalty function method. If the penalty coefficients change with generation number, then it is dynamic penalty function method. In adaptive penalty function method, a feedback taken from the searching progress is added to control the amount of penalty. In death penalty function method, infeasible individuals are rejected and this method has the drawback of not extracting any information from infeasible individuals [3].Maintaining a feasible population by special representations and genetic operators:According to literature [1], the main purpose of this kind of method is to generate feasible individuals, to remove infeasible region from the search space, or to recover infeasible individuals to feasible individuals. In Lawrence Davis’ handbook of genetic algorithms [4], several special representations and genetic operators were used to solve complex real world problems. GENOCOP [5], a method developed by Michalewicz, which generates feasible individuals by handling linear constraint with eliminating equalities and designing special genetic operators. The drawback of this method is the need of a feasible starting point and only linear constraints exist. In Ray's paper [6], an infeasibility driven evolutionary algorithm was proposed to handle constraints by maintaining a small percentage of infeasible solutions close to the constraint boundaries. In [7–9], some decoders methods were proposed to solve constrained problems, and also some repair algorithms to handle constraints, such as [10–13]. In [14], a gene silencing operator was proposed to solve constrained optimization problems.Separation of objectives and constraints:There are several approaches that a clear distinction is made to handle constraints and objective functions. In [15], a stochastic ranking approach was proposed to balance objective and penalty functions stochastically. A probability factor determines that the rank of each individual is decided by objective functions or penalty functions. In [16], Deb proposed a criteria that feasible solutions always take advantage of infeasible solutions, the individual with better objective value is preferred when two feasible solutions are compared together, and individual with smaller constraint violations is preferred when two infeasible individuals are compared. In [17,18], an α level comparison and ɛ level comparison method was adopted to transform an algorithm for unconstrained problems into an algorithm for constrained problems with some tolerance of constraint violation. In [19], a two-population based method was proposed to solve constrained problems. Solutions that satisfy all the constraints and solutions that are potential for the problem are saved in two populations respectively, and similar method was adopted in [20]. Besides that, there are also some algorithms to solve constrained problems in stages, such as [21].Hybrid method:The property of this category is to combine two or more above constraint handling methods together to achieve better performance since different technique has its own advantages and fits for only a subset of problems [22], such examples can be seen in [1,23,24].In conclusion, the major issue of constraint handling method is how to deal with infeasible individuals throughout the whole searching progress. In recent years, a few researchers have focused their research on MOPs, a number of population based stochastic optimization algorithms such as evolutionary algorithms (EAs), particle swarm optimization (PSO), differential evolution (DE) [1,18,24], the human immune system (HIS) based algorithms [25,26] and some other algorithms inspired by nature [27] have been proposed to handle MOPs. Although there have been many approaches to handle constraints, most of them are aimed to deal with single objective optimization problems with constraints, few researchers focus on dealing with constraint handling and MOPs simultaneously.In [28], a constraint-dominate principle, which feasible solutions always perform better than infeasible solutions and infeasible solutions with lower constraint violation are always better than those with larger constraint violations, was proposed to handle CMOPs. The main drawback of this principle is that it may lose some potential information of the infeasible region.Different from constraint-dominate principle, an algorithm that explicitly maintains a small percentage of infeasible solutions close to constraint boundary was proposed in [6]. It adopted a user-defined parameter that determines the proportion of infeasible solutions and a constraint violation measure that based on the relative constraint violation ranking among the current population. Then, the constraint violation measure, which is sum of the relative constraint rankings, is added to form the modified objectives that can be made a non-dominated sorting in the following process. In this method, good infeasible solutions can rank higher than some feasible solutions so that some potential infeasible region information may come into use.In [29], Ray et al. proposed a more elaborate constraint handling technique based on three different non-dominated rankings, which are objective ranking, constraint violation ranking and the combination of objective and violation ranking. Then the algorithm will perform according to the predefined rules.In [30], CMOPs was converted into MOPs by using the modified objective functions. The final modified objective function formulation includes distance measure and adaptive penalty. Both of them are constituted adaptively by normalized constraint violations and normalized objective functions with a parameter rf, which is decided by the proportion of feasible solutions in current population. Penalty function can make some infeasible solutions with good objective function values and low constraint violation values be selected.In this case, a modified objective function method is proposed to handle constraints in this paper. Objective function values and constraint violation values are simply combined together by feasibility ratio to modify objective functions, which enable infeasible individuals with low constraint violation values and better objective function values participate in the searching of optimal solutions. This approach allows the selection to switch between feasibility and optimality during the evolution process. Different from constraint-dominant principle or ranking-based constraint handling method mentioned above, it is based on modifying objective function to preserve a proportion of infeasible individuals. Although proposed handling method was inspired by [30], it adopts a totally different modifying method for feasible and infeasible individuals in different situation, and the details will be shown in Section 3.1. Furthermore, proposed feasible-guiding strategy makes more use of preserved infeasible individuals to determine a feasible direction with the guide of feasible individuals, that can be treated as a DE/infeasible-to-feasible strategy, with which infeasible individuals in the local region can evolve towards feasible direction on some extent and the infeasible individuals can be fully used but not blindly. These two methods facilitate the searching of Pareto-optimal solutions not only go from feasible space but also from infeasible space. With all these methods, the algorithm is capable of finding feasible solutions even though the feasible region is smaller compared to the infeasible regions. Both of proposed methods can be extended easily to make an improvement on other CMOEAs. The performance of comparison experiments with other two CMOEAs on commonly used constrained test problems shows the superiority of proposed methods.This paper is organized as follows. Section 2 presents a brief description of CMOPs. Then, a detailed description of the proposed constraint handling method is provided in Section 3. Next, experiments on various CMOP test problems are used to evaluate proposed constraint handling method in Section 4. Finally, a conclusion of this paper and future work are given in Section 5.A constrained multi-objective optimization problem (CMOP) can be mathematically formulated as follows:(1)Minimizefi(x)=fi(x1,x2,…,xn),i=1,2,…,kSubject togj(x)=gj(x1,x2,…,xn)≤0,j=1,2,…,phj(x)=hj(x1,x2,…,xn)=0,j=p+1,p+2,…,mxlmin≤xl≤xlmax,l=1,2,…,nwhere x=(x1, x2, …, xn)∈Ω is a n-dimensional decision variable vector, which is bounded in the search space Ω,xlminandxlmaxdefines lower and upper boundaries of each dimension of search space Ω respectively. fi(x) is the ith objective function, and k is the number of objective functions. There are a total of m constraint functions to be satisfied with, of which p are inequality constraint functions, and the rest are equality constraint functions, which divide the search space into feasible space and infeasible space. gj(x) is the jth inequality constraint, and hj(x) is the jth equality constraint. When dealing with CMOPs, individuals that satisfy all these constraints are called feasible individuals while individuals that violate at least one of them are called infeasible individuals. Because of the adding of constraints, the global optimal solutions are more difficult to be found in feasible space.The proposed algorithm uses a modified objective function method to lead a dominance checking in the current population, and then a feasible-guiding strategy to repair the infeasible individuals. The modified objective function consists of two components: normalized objective function and normalized constraint violation. They are combined by an adaptive parameter γf, which is the same with the parameter in literature [30]. The feasible-guiding strategy is some kind of repair operator, which can give guides to infeasible individuals in the search for feasible solutions near boundaries between feasible and infeasible regions. The details of them are discussed in this section.As the method mentioned above, the two components which constitute modified objective function: normalized objective function value and normalized constraint violation, can be calculated as follows.The first step is to obtain the maximum and minimum function values of each objective function using formula (2) in the current population, wherefimaxis the maximum value of the ith objective function andfiminis the minimum value of this dimension. Then the normalized ith objective value can be derived though formula (3) by using them, andfinormis the normalized ith objective value of individual x.(2)fimax=maxxfi(x),fimin=minxfi(x)(3)finorm(x)=fi(x)−fiminfimax−fimin,i=1,2,…,kIn formula (1), gj(x) is the jth inequality constraint, and hj(x) is the jth equality constraint, which means the solution x is feasible only when all the constraint violation values gj(x) are smaller than zero and hj(x) equal to zero. In order to find out which solution is feasible without checking if every constraint violation value is smaller than zero or equals to zero, an easier approach (formula (4)) is usually adopted to see if solution x is feasible or not. In formula (4), the tolerance value δ is adopted since that equality constraint is too strict to be satisfied. It is clear that all the constraint violations are set to zero if a solution is feasible. Thenv(x), an arithmetic mean of normalized constraint violations (formula (5) and (6)) is calculated to represent constraint violation of individual x in formula (7).(4)cj(x)=max{0,gj(x)},1≤j≤pmax{0,|hj(x)|−δ},p+1≤j≤m(5)cjmax=maxxcj(x)(6)cjnorm(x)=cj(x)cjmax(7)v(x)=1m∑j=1mcjnorm(x)At last, the modified objective function is defined as formula (8). In most constraint handling methods, some certain types of individuals such as individuals with low constraint violation or better objective function values are preferred rather than combine two of them in an flexible way. In formula (8), a less rigid parameter γfis adopted to control how these two parts contribute to modified objective function value.fimod(x)=γffinorm(x)+(1−γf)v(x),γf≠0v(x)2+finorm(x)2,γf=0where(8)γf=number of feasible individuals in current populationpopulation size(1)If γf≠0, there are both feasible and infeasible solutions in the current population. From formula (8), we can observe that individuals with both low objective value and constraint violation value in the given dimension will have a good performance in the following process. The parameter γfdecides how objective function values and constraint violation values contribute to the final modified function values.For infeasible individuals in the current population, if the feasibility ratio γfis high, the objective function value will impact more than the constraint violation value in each dimension, otherwise, the constraint violation value will impact more. Hence, which is the better one for two non-dominated infeasible individuals in objective function dimension relies on the constraint violation. Usually the individual with low constraint violation value will dominate another individual in the modified objective function dimension. And it is the objective function values that decide which one is better for two infeasible individuals with almost the same constraint violation values.For a feasible individual x, the constraint violation is zero, so the modified objective function value is reduced toγffinorm(x)in the given dimension. On one hand, a priority is still given to feasible individuals in the searching process and feasible individuals will dominate infeasible individuals with the same or worse objective function values. On the other hand, some infeasible individuals with low constraint violation value and lower objective function values than feasible individuals can be given a priority in the searching process. In this case, the potential information of infeasible individuals can be made use of in some extent.If γf=0, there are no feasible solutions in the current population. Since judging the quality of an infeasible individual just by constraint violation sorting or non-dominated sorting of objective function values is single-faceted, both of these two parts are considered in this condition. It is some kind of difficulty to decide which part is more important for the final selection, so a simple idea called distance value borrowed from literature [30] is adopted. For every infeasible individual in the modified objective function dimension, the closer to the origin infinorm(x)−v(x)space, the better it will be.After all, this constraint handling method provides an easy and flexible way for CMOPs. It allows the searching process to go in an efficient and effective way. Here, we can summarize some properties of this constraint handling method.(1)If there are only infeasible individuals in the current population, a condition which is rare unless the constraint is strict enough, the modified objective functions take both objective function values and constraint violation values into account, in case that the disregard of objective function values may cause the searching to be trapped in a local optimal situation, or the disregard of constraint violation makes it hard to find the feasible solutions.If there are both feasible and infeasible individuals in the current population, a condition which is the most common in the handling of CMOPs, the individual with low objective function values and low constraint violation values will dominate individuals with high objective function values, or high constraint violation values, or both of them.If there are only feasible individuals in the current population, which may happen in later searching process. According to our constraint handling method, all the individuals would be selected just based on objective function values, the same as MOPs.In theory, for CMOPs, part of Pareto optimal solutions may lie on the constraint boundaries, those solutions that are near the constraint boundaries usually contribute a lot to the searching, no matter feasible or infeasible. So the aim of this feasible-guiding strategy is to find feasible solutions close to constraint function space in a feasible direction with the help of infeasible solutions, which is some kind of specific application of DE/rand/1 (formula (9)). The detail description of it is described as follows.DE/rand/1:(9)vi=xr0+F·(xr1−xr2)In Fig. 1, how DE/rand/1 used in CMOPs can be easily understood. The shaded region is infeasible space in decision space and the solutions (xinfi) locate in this area are infeasible, the unshaded region is feasible space and the solutions (xfeai) in this area are feasible, and the dashed-line denotes constraint boundary. First, an infeasible individual and its nearest feasible individual are found. Then a direction from infeasible region to feasible region is confirmed, which is called feasible direction. For example, infeasible individual xinf1, feasible individual xfea1, and the corresponding feasible directiond1. Then, the infeasible individuals in the neighborhood of the selected infeasible individual will mutate toward feasible direction, a new individual is generated finally. In Fig. 1, we can see that individual xinf3 mutates toward F·d1, xinf4 and xinf5 mutate in a direction F·d2. Then some new individuals xnew1, xnew2, xnew3 are generated correspondingly. Maybe not all these newly generated individuals are feasible, but at least they can be less violated. But this method is only suited for those individuals in the neighborhood that they share the similar feasible direction, not for the global search.According to formula (9) and Fig. 1, the main idea of this method can be summarized as formula (10). As mentioned above, xfea1 and xinf1 are a couple of nearest feasible and infeasible individuals lying in the neighborhood of xinf, F is a scaling factor, xnewis the new generated individual.(10)xnew=xinf+F·(xfea1−xinf1)Procedure of the proposed algorithm is as follows:Step1Initialization. Generate N individuals in decision space randomly to form initial population P, and evaluate the objective function value of each individual. Then, select non-dominated feasible individuals into archive, and maximum number of archive is set to N.Modify objective functions. Calculate modified objective function values of each individual in current population P according to the proposed method in Section 3.1.Reproduction.Step2.1Use tournament selection method to select N parents and generate N offsprings to form offspring population Q1.Use feasible-guiding method introduced in Section 3.2 to generate some offsprings Q2. The number of Q2 is γfN, which is decided by the number of infeasible individuals in the current population.Offspring population Q=Q1∪Q2, and calculate objective function values and modified objective function values.Make a non-dominated sorting [28] with the modified objective function value.Archive update. For each feasible individual in Q, remove the individuals in the archive if they are dominated by it, and add it in archive.Current population update. Combine P and Q, recalculate the non-dominated rank and crowding distance. Then select the top N non-dominated individuals into Pt+1 according to modified objective function values.Termination. If the termination criterion is satisfied, the algorithm terminates. Otherwise, set P=Pt+1 and go back to Step2.The operators adopted in the reproduction step are SBX crossover (formula (11)) and nonuniformity mutation (formula (12)).a′ik=0.5[(1+βk)aik+(1−βk)ajk],ifr(0,1)≥0.50.5[(1−βk)aik+(1+βk)ajk],ifr(0,1)<0.5where(11)βk=(2u)1ηc+1,ifu(0,1)≥0.5[2(1−u)]−1ηc+1,ifu(0,1)<0.5In formula (11), aikand ajk(i≠j, k=1, …, n) are the kth dimension of individual i and j respectively, u and r are random numbers range from 0 to 1, and ηcis a distribution index.v′k=vk+δ(uk−vk),ifr(0,1)≥0.5vk−δ(vk−lk),ifr(0,1)>0.5where(12)δ=1−r(1−it/T)λIn formula (12),vk(k=1,…,n)is the kth dimension of an individual, ukand lkis the upper and lower boundary of this dimension respectively. it is current generation number, T is the maximum generation number, and λ is a parameter that tunes the area of local search, which usually ranges from 2 to 5.As this algorithm is proposed on the foundation of NSGA-II, and two methods are added to handle constraint or fix infeasible individuals, the contribution of the two components is shown up correspondingly and the overall effect can be seen in this section.In this paper, the proposed algorithm is compared with NSGA-II and the algorithm in literature [30] (indicated by Woldesenbet's algorithm). 14 benchmark functions are adopted to test the performance of proposed algorithm, which are BNH [31], SRN [32], TNK [33], CONSTR [34], OSY [35], Welded Beam [36], and CTP1–CTP8 [37]. The characteristic of these problems are summarized in Table 1.All the algorithms run 30 times on adopted test problems with a population size of 100, crossover rate 0.8, mutation rate 0.2, distribution index ηc=15, λ=2. To have a fair comparison, all the algorithms use an archive to store Pareto optimal solutions, and the number of archive is set to 100. In order to select appropriate evaluation times, we chose CTP2 as a representative to make an experiment that how IGD values change with evaluation times in Fig. 2, and the evaluation times range from 10,000 to 100,000 in every 10,000 time.IGD[38] is a performance metric that measures both convergence and diversity of the non-dominated fronts obtained from one algorithm. Assume P is a set of uniformly distributed solutions of the true Pareto-front (PF), A is the solution set obtained from optimization algorithm, IGD is defined as average distance from P to A:(13)IGD(A,P)=∑v∈Pd(v,P)|P|whered(v,P)is the Euclidean distance fromvto the nearest point in A. The lower IGD(A, P) is, the more approximate A is.Minimal spacing[39] is an enhanced performance metric of uniformity modified from Spacing. The calculation of minimal spacing(Sm) of set A is described as follows.Step1Normalize all the solutions in A.Separate solutions in A into two parts: calculated set Acand uncalculated set Au. Take all the solutions in A to Au, and randomly mark one solution with ‘true’, the rest with ‘false’.Step2.1Put ‘true’ solution in Auto Ac, and calculate the minimal distance from this true solution to Au. The nearest solution in Auis marked with ‘true’.Repeat Step2.1 until Au=∅.(14)Sm(A)=∑i=1|A−1|(di−d¯)|A−1|where diis the minimal Euclidean distance obtained from Step2.1,d¯is the average value of di. If Sm(A)=0, it represents solutions in A distribute uniformly.(15)ς(A1,A2)=|{a″∈A2;∃a′∈A1:a′≻a″}||A2|ς(A1, A2) [40] ranges from 0 to 1. When ς(A1, A2)=1, it means all the solutions in A2 can be dominated by some solutions in A1, and ς(A1, A2)=0 represents that there are no solutions in A1 can dominate any solutions in A2. It needs to be mentioned that ς(A1, A2) has nothing to do with ς(A2, A1), so it is necessary to calculate both of them respectively.In this paper, we use these three performance metrics to measure the quality of proposed algorithm compared with NSGA-II and Woldesenbet's algorithm. But for test problems CTP3 and CTP4, their PFs are a set of discrete points, for test problem CTP5, its PF is a disjoint curve and some discrete points. It is not reasonable to calculate its uniformity since its true PF distributes ununiformly, so the minimal spacing values of these problems are just actually offered us to work from.In order to compare the performance of three algorithms in a condensed way, we will give the results of simulation and performance metrics on all the selected test problems obtained from three algorithms. Before showing experiment results, we need to make a classification on CTP problems according to the characteristics of their PF [25]. For other problems, we will not classify them since they are not very complicated. As mentioned in [25], the classification is as following. Group1: CTP1 and CTP6, since they both have continuous PFs; Group2: CTP2, CTP7, and CTP8, since the PFs of these problems are a finite number of disconnected regions; Group3: CTP3, CTP4, and CTP5, since PFs of these problems consist of a finite of discrete points.Before a detailed analysis is presented, it is necessary to make an illustration. Following figures (Figs. 3, 5, 7 and 9) show the simulation results obtained from three algorithms. It is noticed that each plot shown in these figures got the best IGD value in 30 runs. In the figures, plots marked with ‘Proposed’ ‘NSGA-II’ and ‘Woldesenbet’ are the simulation results obtained from proposed algorithm, NSGA-II and Woldesenbet's algorithm respectively. True Pareto fronts are marked with red solid lines, while the Pareto optimal solutions obtained from three CMOEAs are marked with small blue circles, and feasible objective spaces of CTP problems are shaded. In Figs. 4, 6, 8 and 10, box plots of performance metrics for these problems are shown respectively. The box plots marked with ‘IGD’ and ‘Sm’ is IGD and minimal spacing metric of three compared CMOEAs respectively, ‘1, 2, 3’ represents proposed algorithm, NSGA-II and Woldesenbet's algorithm in order. In the figures marked with ‘ς of Pro and A’, ‘1’ is ς(proposed algorithm, A) and ‘2’ is ς(A, proposed algorithm).Fig. 3 shows the simulation results obtained from three algorithms on test problem BNH, SRN, TNK, CONSTR, OSY, and Welded Beam. We can see that proposed algorithm gets better performance compared with other two algorithms on TNK, CONSTR, OSY, and Welded Beam. Non-dominated solutions obtained from NSGA-II and Woldesenbet's algorithm distribute not well enough in the smooth part of PF on TNK, while proposed algorithm gets a better spread non-dominated optimal set. For test problem CONSTR, neither NSGA-II nor Woldesenbet's algorithm can attain overall Pareto optimal covered true PF. For test problem OSY, neither NSGA-II nor Woldesenbet's algorithm can find the overall PF. Besides that, NSGA-II can not converge to the true PF. On these test problems, we can clearly see the proposed algorithm can meet our expectation in visual appearance.Fig. 4 is the box plots of performance metrics for test problems BNH, SRN, TNK, CONSTR, OSY, and Welded Beam. In these plots, we can observe that three algorithms have comparative performance on SRN and TNK, but proposed algorithm still get a weak superiority on IGD values. For CONSTR, lower IGD values and almost equal ς values prove the advantage of proposed algorithm on diversity of optimal solutions. For OSY, both box plots of IGD and ς show the priority of proposed algorithm on diversity and convergency, which is the same as visual appearance. Seen from box plots of Sm, optimal solutions got from three comparison algorithms have similar uniformity on these test problems.Fig. 5shows the simulation results obtained from three algorithms on Group1 test problems. Both of them have continuous PF, and the shaded regions in the figure are feasible objective spaces. Seen from simulation results with the best IGD values, we can only derive a conclusion that three algorithms have comparative performance on these problems. In order to make a further comparison among three algorithms, box plots of performance metrics on Group1 test problems are shown in Fig. 6.Fig. 6 shows box plots of performance metrics for Group1 test problems. According to box plots on CTP1, it is obvious to see that proposed algorithm has a better convergence and diversity than other two algorithms. Feasible objective spaces of CTP6 is presented in banded distribution so that it is easy to be trapped in local optimal situation for this problems. IGD box plots of CTP6 shows that proposed algorithms can converge to the true Pareto front, while NSGA-II is usually trapped in local optimum, and Woldesenbet's algorithm has a worse convergence than proposed algorithm. Seen from box plots of Sm, solutions got from three comparison algorithms have similar uniformity on CTP1 and CTP6.Fig. 7shows simulation results obtained from three algorithms on Group2 test problems, from which we can obviously see that Group2 problems have a disconnected PF. Comparing three algorithms on CTP2, no superiority can be seen to derive which algorithm is better. For CTP7, the banded distribution of feasible objective spaces determines that it is not easy to find the overall PF. We can see that proposed algorithm and Woldesenbet's algorithm get comparative performance, while NSGA-II misses a part of disconnected optimal solutions. For CTP8, the feasible objective spaces are distributed in blocks, which determines that it is not only easy to miss part of PF but also to be trapped into local optimum situation. But we can’t see the difference among three algorithms only from the simulation results with best IGD values on CTP8, since all the algorithms performed well.Fig. 8shows the box plots of performance metrics on Group2 test problems, from which we can see the superiority of proposed algorithm. Lower IGD values and better ς values on CTP2 show the weak advantage of proposed algorithm. For CTP7 and CTP8, the superiority of proposed algorithm can be seen obviously. High IGD values and low ς values show the disadvantage of other two algorithms on convergency and diversity of non-dominated solutions. We can see that proposed algorithm strictly dominates other two algorithms on CTP7 and CTP8 since ς(pro, NSGA-II)≈1 and ς(NSGA-II, pro) ≈0, which proves proposed algorithm can find more approximate non-dominated solutions on or near the true PF.As mentioned in [25], it is not suitable for Group2 test problems to measure diversity performance of an algorithm because of the property of PFs, so we adopt the number of disconnected regions found to evaluate it. From Table 2, proposed algorithm has a weak advantage than other two algorithms on CTP2 and CTP7. It can find all the disconnected regions in 30 runs, which confirms that our algorithm can obtain a well distributed and convergent solutions. All the disconnected regions can be found by proposed algorithm on CTP8, while NSGA-II and Woldesenbet's algorithm are easy to trap in local optimum so that they could not find correct PFs.As shown in Fig. 9, an infeasible tunnel needs to be travelled in searching for discrete Pareto optimal points at the end of feasible tunnel for Group3 test problems. The narrower and longer the tunnel is, the more difficult is the search. In order to find all discrete feasible points, some infeasible tunnel must be gone through. Optimal solutions obtained from proposed algorithm have better convergency and diversity compared with other two algorithms on Group2 test problems, especially CTP4. On CTP5, Pareto optimal solutions found by proposed algorithm are more approximate and overall than other two algorithms, but a discrete point near f1=0 is still missed.Fig. 10shows the box plots of performance metrics on Group3 test problems, from which we can see the superiority of proposed algorithm. Lower IGD values and better ς values indicate that proposed algorithm has a better convergency and diversity on these problems than other two algorithms. Especially for CTP4, box plots of ς values prove the capacity of searching discrete points.As mentioned in Section 4.2, it is not reasonable to calculate the uniformity of problem CTP3, CTP4, and CTP5, so we take the number of discrete points found by algorithms instead of box plots of Sm. In Table 3, we can observe that the number of discrete points found by proposed algorithm is more than other algorithms, which prove the effectiveness of proposed algorithm. It is worth noticing that PF of CTP5 consists of a disconnected region and a set of discrete points, but only the set of discrete points are taken into account in Table 3.In order to identify the contribution of modified objective function method and feasible-guide strategy, we choose test problems CTP2–CTP8 as representatives to make comparison study respectively. As mentioned above in Section 4.2, it is not reasonable to use minimal spacing metric to measure the uniformity of all the algorithms since some of their PF are discrete, so we only use IGD and ς(A1, A2) to measure the quality of all the algorithms.Fig. 11shows box plots of IGD obtained from algorithms with different constraint handling methods on the basis of NSGA-II. In Fig. 11, ‘1’ refers to our modified objective function method, ‘2’ refers to constraint-dominate principle, and ‘3’ represents constraint handling method proposed in Woldesenbet's algorithm. We can find that algorithm with the proposed modified objective function method gets better IGD values than other two methods on CTP4, CTP6, and CTP8. For other problems, the difference among three constraint handling methods is not obvious. It is worthy to notice that our proposed modified objective function method can perform better on convergency than other two methods on CTP4, but it is still not good enough seen from IGD value.Fig. 12shows ς values obtained from algorithms with different constraint handling methods on the basis of NSGA-II. For every test problem in Fig. 12, figure on the left is box plot of ς(proposed, NSGA-II) and ς(NSGA-II, proposed), and figure on the right is box plot of ς(proposed, Woldesenbet) and ς(Woldesenbet, proposed). From Fig. 12, it's obvious to see the proposed method gets better results with respect to ς on CTP4, CTP6, and CTP8, as the same performance in term of IGD. For CTP6 and CTP8, we can make a conclusion that our method has a better stability than other two constraint handling methods.Fig. 13shows box plots of IGD obtained from NSGA-II and Woldesenbet's algorithm with and without feasible-guiding strategy. For each test problem, figure on the left refers to box plot of IGD performance metric obtained from NSGA-II with and without feasible-guiding strategy, figure on the right refers to box plot of IGD performance metric obtained from Woldesenbet's algorithm with and without feasible-guiding strategy. All the chosen test problems have improved on IGD, especially CTP4, CTP6 and CTP8. Because of the characteristic of these problems, it stands to reason that the performance of algorithms with proposed feasible-guiding strategy improves a lot with more use of infeasible solutions.Fig. 14shows compared experiment results of NSGA-II and Woldesenbet's algorithm with and without feasible-guiding strategy in term of ς values. For each test problem, figure on the left refers to box plot of ς performance metric of NSGA-II with and without feasible-guiding strategy, figure on the right refers to box plot of ς performance metric of Woldesenbet's algorithm with and without feasible-guiding strategy. From Fig. 14, it is obvious that algorithms with feasible-guiding strategy strictly dominate algorithms without feasible-guiding strategy on CTP3, CTP4, CTP7, and CTP8. For the rest test problems, feasible-guiding strategy still shows weak superiority on convergency.In order to take a further comparison, the performance of algorithm with three other settings (one with feasible-guiding strategy and constraint handling method used in Woldesenbet's algorithm, one without feasible-guiding strategy, and one without both features) is shown in Fig. 15. ‘A, B, C’ in the figure refer to the algorithm without both features, algorithm without feasible-guiding strategy, and algorithm with feasible-guiding strategy and constrained handling method used in Woldesenbet's algorithm, respectively.Seen from Fig. 15, ‘B’ performs better than ‘A’ on CTP3, CTP4, CTP7, and CTP8. ‘C’ performs better than ‘B’ on CTP2, CTP3, CTP4, CTP7, and CTP8. ‘C’ performs better than ‘A’ on CTP2, CTP3, CTP4, CTP5, CTP7, and CTP8. The experiment results demonstrate that using proposed constrained handling method to keep infeasible solutions is better than only keep feasible solutions in handling constrained multiobjective optimization problems, and proposed feasible-guiding method can promote the performance of algorithms even though using different constraint handling methods.As observed from the experimental results, proposed algorithm meets our expectation for exploiting better fitted and well distributed (uniformly and extendedly) non-dominated feasible individuals near or on true Pareto fronts. The reason why proposed algorithm gets better solutions than other two CMOEAs can be summarized as follows. Compared with NSGA-II, proposed algorithm not only allows infeasible individuals to participate in the evolution, but also to combine the constraint violation values with objective function values. On one hand, this kind of constraint handling method overcomes the disadvantage of infeasible individuals always has worse rankings than feasible ones without thinking about the influence of infeasible individuals. On the other hand, to regulate the proportion of constraint violation values and objective function values according to feasibility ratio in current population guides the evolution to find less violated infeasible individuals or better non-dominated feasible individuals. Although inspired by Woldesenbet's algorithm, proposed algorithm still has some advantage over it. We not only take information of infeasible space into account, but also make use of them more motivatively with feasible-guiding strategy, which is the main reason why proposed algorithm has a better performance than Woldesenbet's algorithm.

@&#CONCLUSIONS@&#
In this paper, a modified objective function method with feasible-guiding strategy is proposed to solve CMOPs. Modified objective function method allows the search of Pareto optimal individuals to exploit from both feasible spaces and infeasible spaces. In modified objective function method, constraint violation and objective function values are both considered to select infeasible individuals, only the one with low constraint violations and better objective function values can survive in the selection mood. The feasibility ratio in current population decides the contribution of these two parts, which guides the evolution to search less violated infeasible individuals with better objective function values or to find better non-dominated feasible individuals. Even though there are no feasible individuals in the current population, both of two parts are still considered together in case that the searching traps in the situation of finding individuals that are feasible but not optimal enough. Feasible-guiding strategy makes some feasible individual govern the evolution of infeasible individuals. The cooperation of feasible regions and infeasible regions makes the search process more motivated.Furthermore, both of two methods are implemented on the basis of NSGA-II just because of the popularity of this algorithm. Of course, these methods are easy to be extended on other CMOEAs. The experimental results on test problems indicate that proposed algorithm is able to find well distributed Pareto optimal solutions that spread evenly on or near overall true PF, which provides evidence of the capacity of proposed algorithm. For future work, the author will try to solve more difficult test problems using proposed methods and make it into use to solve more real world problems.