@&#MAIN-TITLE@&#
Design and evaluation of a parallel algorithm for inferring topic hierarchies

@&#HIGHLIGHTS@&#
We propose a novel parallel Algorithm for inferring topic hierarchies using HLDA.We use loosely-coupled parallel tasks that do not require frequent synchronization.The parallel Algorithm is well-suited to be run on distributed computing systems.The proposed Algorithm achieves a predictive accuracy on par with that of HLDA.The parallel Algorithm exhibits a near-linear speed-up and scales well.

@&#KEYPHRASES@&#
Topic modeling,Hierarchical clustering,Information retrieval,Parallel algorithm,Cluster computing,Message passing interface,

@&#ABSTRACT@&#
The rapid growth of information in the digital world especially on the web, calls for automated methods of organizing the digital information for convenient access and efficient information retrieval. Topic modeling is a branch of machine learning and probabilistic graphical modeling that helps in arranging the web pages according to their topical structure. The topic distribution over a set of documents (web pages) and the affinity of a document toward a specific topic can be revealed using topic modeling. Topic modeling algorithms are typically computationally expensive due to their iterative nature. Recent research efforts have attempted to parallelize specific topic models and are successful in their attempts. These parallel algorithms however have tightly-coupled parallel processes which require frequent synchronization and are also tightly coupled with the underlying topic model which is used for inferring the topic hierarchy. In this paper, we propose a parallel algorithm to infer topic hierarchies from a large scale document corpus. A key feature of the proposed algorithm is that it exploits coarse grained parallelism and the components running in parallel need not synchronize after every iteration, thus the algorithm lends itself to be implemented on a geographically dispersed set of processing elements interconnected through a network. The parallel algorithm realizes a speed up of 53.5 on a 32-node cluster of dual-core workstations and at the same time achieving approximately the same likelihood or predictive accuracy as that of the sequential algorithm, with respect to the performance of Information Retrieval tasks.

@&#INTRODUCTION@&#
Automated algorithms and models are required to tackle the scale of the World Wide Web, so that the documents in the web can be automatically organized according to their underlying semantics and any search for information, can be efficiently facilitated. Topics represent the key semantics of a set of documents in a terse manner (Blei, Griffiths, & Jordan, 2010). Topic models are probabilistic graphical models, which have been built by researchers to automatically infer the distribution over a set of topics in a document or across a document set. After the latent topic inference, the document corpus can be organized according to the topics inferred and hence the performance of the subsequent information-retrieval tasks can be enhanced (Blei et al., 2010).The huge amount of information in the web is growing everyday with the evolution of new technologies and web portals like Flickr, Yahoo!, Orkut, Facebook, Twitter, and Google. Such web-scale datasets pose a non-trivial problem to probabilistic graphical model learning algorithms, in the form of the time and space complexity needs of the algorithm (Newman, Asuncion, Smyth, & Welling, 2009). An important aspect of these learning algorithms which is detrimental to their performance is that they are iterative in nature and might run for thousands of iterations before convergence.An iteration of these model building algorithms typically involves computing Bayesian conditional probability estimates of words over different topics in the document corpus (Newman et al., 2009). As there are of the order of millions of words in any web-scale document store, the time required for computing and the memory needed for storing these probability estimates are very high. Thus, the memory available in a typical workstation computer is not sufficient to store the probability estimates and even if we assume the existence of sufficient memory, a model building algorithm might run for weeks before converging to a useful optima, if run on a single processor (Newman et al., 2009).Further with the advent of novel parallel processing platforms like MPI, Open-MP, CUDA and Hadoop there is a pressing requirement to exploit the available processing power of the underlying parallel computer (Multi-core, GPU, cluster of compute nodes). Hence there is an imminent and mandatory need to port state-of-the-art sequential model learning algorithms to their parallel variants to make these algorithms run on web-scale corpuses and to speed them up. Even for document sets that are not of web-scale, their processing can be speed-up considerably by using the parallel variants of the model learning algorithms and the topic models constructed can be used for online applications.Recent research efforts have focussed on parallelizing the learning of a single topic model like Hierarchical Latent Dirichlet Allocation (HLDA). The individual parallel iterations in these algorithms (Newman et al., 2009) are tightly coupled and require a global synchronization step to aggregate all the local parameters of the model from the individual processing elements to get a global set of parameters to be used for the next iteration. This arguably discourages the application of these algorithms to processing elements that are geographically distributed; this geographical distribution is now inevitable with the advent of the grid/cloud computing paradigms. These algorithms also have synchronization overheads and a limited application to a specific topic model. With the arrival of novel topic models, it would be desirable to have a reasonably generic algorithm that can parallelize the learning of a group of similar topic models to be run on a parallel computer.From an orthogonal point of view, the parallel algorithm proposed in this paper can also help in boosting the performance of Information Retrieval (IR) applications by providing a generic parallel framework that can merge compatible topic models generated by disparate learning algorithms and can provide an efficient aggregate topic model to work with.Latent Dirichlet Allocation (LDA) is one of the popular models to infer a set of topics and their distribution across a set of documents in a corpus (Blei, Ng, & Jordan, 2003). The model infers only a flat set of topics based on the concept of co-occurrence of words; to adapt the LDA model to infer a hierarchy of topics, an extended version of LDA called Hierarchical LDA (HLDA) was proposed by Blei et al. (2010). HLDA is motivated by the nested Chinese Restaurant Process (nCRP) to form a hierarchy of topics, in such a way that generic topics are near the top of the tree and as we descend the tree, we see levels containing specific or more concrete topics (Blei et al., 2010). The HLDA training is expensive in terms of computations and hence parallelization becomes inevitable.In this paper, we propose a parallel algorithm for discovering topic hierarchies from web-scale document corpuses. Following are the major contributions of this paper to the existing literature on topic hierarchy formation:•Proposes a novel parallel algorithm to parallelize topic models similar to HLDA.Proposes a parallel algorithm that involves loosely-coupled parallel components which do not require frequent synchronization.Adopts a novel merging strategy to merge the topic trees generated by different processors in parallel.Compares the efficiency of different distance metrics like quadratic chi-histogram distance, earth mover’s distance and KL-divergence in measuring the similarity between two topic trees.Empirically show cases the performance of the proposed parallel algorithm by parallelizing the HLDA model.Section 2 discusses some of the related research efforts and also highlights the key similarities and differences between our work and the existing research efforts. Section 3 details the preliminaries of the HLDA graphical model, which is followed by a discussion on the proposed parallel algorithm in Section 4. Section 5 highlights some of the key empirical observations while testing the algorithm, and the next section summarizes and concludes the paper with some pointers for future research.

@&#CONCLUSIONS@&#
