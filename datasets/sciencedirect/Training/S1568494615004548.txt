@&#MAIN-TITLE@&#
A great deluge and tabu search hybrid with two-stage memory support for quadratic assignment problem

@&#HIGHLIGHTS@&#
A hybrid method combining great deluge and tabu search algorithms is proposed.This hybrid is supported with a two-stage external memory.First stage of acts as a short term memory that is frequently updated.Second stage acts as a long term memory that is updated less frequently.Elements of the second stage are maximally dissimilar in variable space.

@&#KEYPHRASES@&#
Combinatorial optimization,Great deluge algorithm,Memory-based search,Metaheuristics,Quadratic assignment problem,Tabu search,

@&#ABSTRACT@&#
A two-stage memory architecture is maintained within the framework of great deluge algorithm for the solution of single-objective quadratic assignment problem. Search operators exploiting the accumulated experience in memory are also implemented to direct the search towards more promising regions of the solution space. The level-based acceptance criterion of the great deluge algorithm is applied for each best solution extracted in a particular iteration. The use of short- and long-term memory-based search supported by effective move operators resulted in a powerful combinatorial optimization algorithm. A successful variant of tabu search is employed as the local search method that is only applied over a few randomly selected memory elements when the second stage memory is updated. The success of the presented approach is illustrated using sets of well-known benchmark problems and evaluated in comparison to well-known combinatorial optimization algorithms. Experimental evaluations clearly demonstrate that the presented approach is a competitive and powerful alternative for solving quadratic assignment problems.

@&#INTRODUCTION@&#
Combinatorial optimization problems are representative models of many real life optimization tasks. Location of facilities, finding shortest routes, staff and task scheduling, packing and covering and segmentation of images are a few within a large set of combinatorial optimization problems for which development of dedicated solution methods is still an area of hot research. A common nature of many combinatorial optimization problems is their NP-complete type of complexity which directly indicates the computational difficulty of obtaining exact solutions for these problems. In fact, exact solutions are possible for (very) small-size problem instances and finding an approximate solution with close-to-optimum quality is the fundamental problem to be solved in most of the time. Since advanced computational resources enable us to deal with larger-size and more complex problems, development of more efficient solution methodologies, in terms of solution quality and convergence speed, became the ultimate objectives of almost all optimization tasks.Considering the exploration of a solution space using a particular metaheuristic method employing a set of search operators, the two challenging problems to deal with are early stagnation at a locally optimal solution and efficient guidance towards globally optimal solutions. In this respect, searching around multiple promising solutions, particularly at initial iterations of an algorithm, should clearly be a major concern for the design of search algorithms. For this purpose, memory methods using an archive of a number of promising solutions, or reference points, are proposed and they are shown to be useful through experimental evaluations. Accordingly, a memory-based search procedure has two fundamental objectives; one is to intensify the search around the potentially promising solutions found so far while the second is diversifying the exploration within the solution space by using more than one reference template within the maintained memory. This way, early stagnation at a locally optimal solution can be avoided by providing alternative directions for search and more efficient guidance towards globally optimal solutions can be provided by appropriate memory-based search operators and memory update methods.Great deluge algorithm (GDA), which is first proposed by Dueck [1], is a local search algorithm similar to simulated annealing (SA) with the exception that acceptance rule is deterministic and controlled by a threshold parameter called the Level. It uses two other algorithmic parameters, namely, the number of iterations and an estimation of the best fitness value of the objective function. In its search in a solution space, GDA accepts a new solution if its fitness is better than the best solution found so far or the fitness is less than a dynamically updated upper bound, which is the Level. Estimated best fitness value of the objective function is usually set less than or equal to the fitness of the best solution known so far. Level is initially set to the fitness of the initial solution and is lowered iteratively by an additive parameter β computed as a function the initial value of Level and the estimated best fitness value of the objective function.After its initial introduction, improved versions of GDA are proposed in several of publications. These improvements can be considered in two categories: changes in basic algorithm parameters and search operators, and hybridizations with other metaheuristics. Since GDA has basically two parameters, namely the Level and the level decay rate β, algorithmic improvements based on different ways of changing these parameters are the main concern of studies in the first category. Burke et al. implemented a linear decreasing of decay rate beta such that the amount of decay is computed based on the maximum number of iterations. The authors called this strategy as degraded ceiling algorithm [2]. According to published results, this strategy produced most of the best fitness values on examination timetabling benchmark problems. Later, Burke and Bykov developed the flex-deluge algorithm (FGDA) in which the acceptance of uphill moves is controlled by a flexibility parameter [3]. For the solution of exam timetabling problems, FGDA was claimed to provide good results particularly for large-scale problems. The modified great deluge algorithm (MGDA), proposed by Ravi [4], introduced a new neighbourhood search and a new level decay mechanism that depends on the amount of improvement achieved when the current solution is modified to get the new one. Basically, level is decreased if fitness of the new solution is below the current level, whereas it is increased otherwise. This approach is applied for reliability optimization and optimal redundancy allocation problems and was observed to perform as well as ant colony optimization, while it was significantly better than simulated annealing algorithm. Silva and Obit developed the nonlinear great deluge algorithm (NLGDA) that uses a nonlinear decay rate for the level parameter [5]. An exponential expression including four parameters is used to determine the functional shape of decay rate. When used for the solution of course timetabling problems, NLGDA updated the best solutions of four benchmark instances among the eleven in the experimental set. The extended great deluge algorithm (EGDA), developed by McMullan, uses the concept of reheating from simulated annealing such that, if no improvement is obtained within a predefined period, the level parameter is reset to the current objective function value [6]. For a set of course timetabling benchmark problems, EGDA produced ten best solutions for five medium-size problems and for one large-size problem. Nahas et al. used EGDA in two steps as follows: EGDA is used for N1 number of iterations to find a locally optimal solution. Then, best found solution is used as the initial solution for EGDA and improved through another N2, N2<N1, number of iterations [7]. The authors called this approach as iterated great deluge algorithm (IGDA) and, for a set of 48 facility layout problems, IGDA is reported to update the best found results for 17 of them. Ozcan et al. combined reinforcement learning (RL) and the GDA within a hyperheuristic (HH) framework such that RL is used to select one of a set of low-level heuristics, that is applied as a move to generate a new solution, whereas the GDA's level-based decision mechanism is used to accept or reject the move [8]. For a set of thirteen university examination timetabling problems, this approach is observed to be better than simulated annealing and simple random hyper-heuristics for six problem instances.The second category of the improvements includes hybridizations with other metaheuristics or slight modifications of level-based acceptance mechanism. Milli [9] used GDA as a local search procedure within a genetic algorithm (GA) framework for the solution of course timetabling problems. After each generation, GDA is employed to improve the best solution found so far. The author claimed that the proposed combination generated consistently good results for benchmark problems used in experimental studies. Landa-Silva et al. proposed another hybrid of evolutionary algorithms and NLGDA where an individual selected from the current population by tournament selection is modified by mutation and the mutated individual is improved by NLGDA [10]. If the resulting solution is better than the worst solution in GA's population, it replaces that worst solution. The proposed hybrid approach is claimed to perform better than its competitors in most of the benchmark course timetabling problems used for comparative evaluations. A third GDA-related hybrid approach on the solution of course timetabling problem combines particle collision algorithm (PCA) and GDA such that GDA's level-based acceptance criterion is used in the scattering phase of PCA [11]. The experimental results presented in the paper show that the proposed hybrid approach performs better than its eleven competitors for the solution of eleven widely used course timetabling problem instances. In a sequential implementation of Tabu search and GDA, proposed by Abdullah et al. [12], the current solution is first modified by GDA and then the modified solution is improved by tabu search. Finally, the best of the solutions found by the two algorithms is used to start the next iteration. When used for the solution of course time tabling problems, the proposed method is reported to provide the best solutions for most of the benchmark problems. In another publication, Abdullah et al. combined GDA with an electromagnetic-like mechanism to solve the examination timetabling problem [13]. This population based method is implemented in two phases. In the first phase, a positive amount of charge is assigned to each timetable in the population based on their fitness relative to the fitness of the best timetable found so far. Consequently, the total force on each timetable is computed using an analogy to interaction of charged particles and these total force values are used to calculate the estimated qualities of individual timetables in the population. In the second phase, the level decay parameter of GDA is determined based on the estimated qualities of individual timetables and GDA is applied on each timetable of the population for a number of iterations. Among the eleven examination timetabling instances and against the eight competitors in experimental evaluations, the authors reported that this hybrid approach provided the best known solutions for nine problem instances.Among a few GDA hybrids used for real-valued function optimization, Ghatei et al. hybridized GDA and particle swarm optimization (PSO) in which GDA is used as final local search procedure to further improve the best solution found by the PSO algorithm [14]. This approach is tested over four benchmark functions only and it is claimed to be better than GAs and PSO.Considering the above literature review and based on our detailed search for different solution approaches to QAP, a direct application of GDA for the solution of QAP could not be found so far. However, a problem that is most similar to QAP and solved using GDA is the dynamic facility layout problem [7]. In addition to this, even though GDA is not used for the solution of QAP, its success is demonstrated on another subclass of large-size combinatorial optimization problems, namely the timetabling and scheduling problems. Hence, our main reasoning behind the use of GDA for the solution of QAP can be stated as its exhibited success for difficult classes of combinatorial optimization problems, implementation simplicity, adaptive and deterministic decision character, and the objective of demonstrating the effectiveness of a novel two-stage memory architecture within the framework of a metaheuristic for the solution of a provably difficult combinatorial optimization problem. The proposed two-stage memory-based and operator-adapted variation of GDA for QAP, its objectives and comparative level of success are illustrated in the following sections.The fundamental objective of memory based implementation of a metaheuristic algorithm is to use experience based knowledge stored in memory to localize the globally optimal solutions better while the exploration capability of the underlying search methodology is not weakened. Memory based search strategies have already been implemented within several metaheuristic algorithms and they are shown to be more successful compared to memoryless implementations. In fact, memory-based implementations have first been implemented within the framework of genetic algorithms (GAs). Basically, from GAs point of view, memory based implementations aim to adapt the GAs behavior when either the solution quality is not improved over a number of generations, or a change in the problem environment is detected, or further exploration/exploitation of the solution space is required. Contents of the maintained memory can be either full-length representations, or randomly cut segments, or gene sequences randomly extracted from potentially promising solutions. A memory can be maintained either internally by incorporating accumulated experience into algorithmic parameters or externally as an archive to be used for experience-based guidance of the search procedure. A detailed review of memory-based strategies in genetic algorithms (GAs) is given in [15]. In order to give a clear idea on the two types memory organizations, two characteristic examples are presented below.Montgomery et al. proposed the first internally implemented memory-based approach within ant colony optimization (ACO) [17]. The authors adapted the characteristic equations of ACO to include a weighting mechanism that represents the accumulated experience. The weighting is established on the nature of partial solutions reached in the current iteration. Elements showing a higher tendency toward better solutions are valued highly, whereas elements that lean to follow toward poorer solutions are weighed lower. The intention of the researchers of this approach is to present a more direct and objective feedback on the quality of the choices made, as well as to represent normal pheromone level and heuristic cost. It is claimed by the authors that the results attained for travelling salesman problem (TSP) instances are either equally well or better than those achieved using normal ant colony system algorithms.Two population based external-memory approaches in ACO are introduced in [15,16]. In first of these approaches, variable-size solution segments taken from some elite individuals of previous iterations are stored in an external memory. In the second approach, partial permutation sequences extracted from a number of above average individuals are stored in the external memory. In both of the approaches, the memory is initially empty and a standard ACO algorithm runs for a small number of iterations to initialize the external partial solutions memory. Stored partial solutions are associated with their parents’ objective function values that are used as measures for retrieval and updating the memory elements. Both of the approaches are used for the solution of QAP and significant improvements are achieved compared to conventional ACO implementations.This paper is organized as follows: description of QAP and a list of metaheuristics employed for its solution are presented in Section 2. Section 3 presents a detailed explanation of GDA together with its implementation issues and different application areas. The tabu search metaheuristic used as a local search support within our proposed method is described in Section 4. Its algorithmic principles and various improvements are also given in this section. The proposed two-stage memory-powered and operator enhanced GDA approach for the solution of QAP is explained in Section 5. Lists of QAP benchmarks, their properties, best known fitness values and the experimental set up used for the solution of these problems are shown in Section 6. This section also covers detailed self and comparative evaluations of experimental results. Finally, Section 7 presents conclusions and the future work plans.The basic description of QAP is introduced by Koopmans and Beckmann in 1957 [18]. Given a set of N facilities, a set of N locations, distances between pairs of locations, and flows between pairs of facilities, QAP is described as the problem of assigning each facility to a particular location so as to minimize the sum of the product between flows and the distances. More formally, if D=[dij] is the N×N distance matrix and F=[fpq] is the N×N flow matrix, where dijis the distance between locations i and j and fpqis the amount of flow between facilities p and q, QAP can be described by the following equation:(1)minπ∈Π∑i=1N∑j=1Ndπ(i)π(j)fijwhere Π is the set of all permutations of integers from 1 to N, and π(i) gives the location of facility i within the current solution (permutation) π∈Π. The term dπ(i)π(j)fijis the cost of simultaneously assigning facility i to location π(i) and facility j to location π(j).Quadratic assignment problem belongs to the class of NP-hard combinatorial optimization problems and the largest instances that can be solved with exact algorithms are limited to instances of size around 30 [19–21]. Hence, the only feasible way to deal with the solution of large QAP instances is to use heuristic approaches which guarantee to reach a locally optimal solution in reasonable computation times. Several modern heuristics, mostly evolutionary or nature-inspired, are developed since 1980s and successfully applied for the solution of many provably hard optimization problems including the QAP. From 1980 until 2009, detailed reviews of heuristic and metaheuristic algorithms for QAP can be found in [21–23]. As can be seen in these well-prepared surveys, most widely referenced and successful metaheuristics for the QAP are simulated annealing (SA) [24,25], tabu search (TS) [26–29,25], genetic algorithms (GAs) [30–33], ant colony optimization (ACO), [34–36], greedy randomized adaptive search procedure (GRASP) [37,38], memetic algorithms (MAs) [39,40], hybrid methods (HMs) [41,42] and local search (LS) algorithms [43,44]. Recently, new QAP solution methodologies based on adaptation of powerful numerical optimization algorithms are presented. In this respect applications of particle swarm optimization (PSO) [45,46], differential evolution (DE) [47,48], imperialistic competitive algorithm (ICA) [49], and migrating birds optimization (MBO) algorithm [50] are reported to provide promising results compared to well-known metaheuristic algorithms for QAP. Among newly developed metaheuristic algorithms, chemical reaction optimization (CRO) has also been demonstrated to be a competitive algorithm for QAP and other difficult scheduling problems [51–54]. Furthermore, following the formulation of Geoffrion et al. [55], who formulated scheduling of parallel production lines as a QAP, different hard scheduling problems such as DAG scheduling problem can also be formulated as a QAP and solved using the algorithms mentioned above [56–58]. It should also be noted at this point that, the above mentioned metaheuristics exhibit almost similar performance for small-size and easy problem instances, whereas only those algorithms hybridized with a powerful local search method, such as tabu search, reach competitive scores for the difficult and large-size problem instances. Due to its experimentally proven efficiency for the QAP, we also used a variant tabu search, robust tabu search (RTS), algorithm as a local search support within the proposed GDA framework.Great deluge algorithm is a trajectory based optimization algorithm that is similar to simulated annealing (SA) except for its dynamically adjusted level-based acceptance mechanism. The algorithm starts with a randomly constructed initial solution and has three fundamental parameters to be set initially. These are the estimated value of fitness for a globally optimal solution, the maximum number of iterations, and the initial value of the level parameter. Usually, the initial value of the level parameter is set equal to the fitness of the initial solution. Throughout the execution of GDA, the value of the level parameter is decayed linearly or nonlinearly, and the acceptance of new solutions depends on the level parameter. The basic GD algorithm is described in Algorithm 1.Algorithm 1Pseudocode of the basic great deluge algorithm.Iter←0;Build an initial solution, SIter;Compute the fitness of SIter, FOld←F(SIter);FBest←FOld;Set the maximum number of iterations to MaxIter;Estimate the fitness of a globally optimal solution, FGbest;Set the initial value of LevelIter, LevelIter←FOld;Set the level decay parameter, ΔLevel←(FOld−FGbest)/MaxIter;Set Not improving length limit to NILength; /*This is one of termination conditions when the algorithm gets stuck at a locally optimal solution.*/Set Not improving counter to zero, NICount←0;DONE←0;while(Not(DONE)),Generate a new solution, SIter+1, /* starting from SIter, using the available operators and the neighbourhood structure. */Compute the fitness of SIter+1, FNew←F(SIter+1);If FNew<FBest,FBest←FNew;FOld←FNew;NICount←0;elseIf FNew≤LevelIter,FOld←FNew;NICount←0;elseNICount←NICount+1;If NICount==NILength,DONE←1;end ifend ifend ifLevelIter+1←LevelIter−ΔLevel;Iter←Iter+1;end whileThe fundamental distinctions between SA and GDA lies in the acceptance rule. While SA accepts new solutions stochastically based on Boltzmann distribution, GDA applies a deterministic rule using a dynamically changing parameter called Level. In SA, the magnitude of a uphill climbing move is controlled by the temperature parameter that effects the probability of being accepted from approximately all (when T is very large) to approximately none (when T is very small). The temperature is adjusted according to a predefined cooling schedule. In GDA, the magnitude of uphill climbing moves is controlled by the deterministic Level parameter such that all uphill moves with a magnitude less than the Level are accepted. The level parameter is adjusted according to a level decay mechanism. While SA is proved to be globally optimal under asymptotic thermal equilibrium conditions, no such proof exists for GDA. However, GDA is experimentally shown to be faster and more robust than SA for several hard optimization problems, like exam and course timetabling problems [2]. As already stated above, a two-stage memory powered and operator adapted GDA approach for QAP is presented in this paper. Details of its implementation and performance for well-known benchmark problem instances are presented in the following sections.Tabu search (TS) metaheuristic is basically a greedy search algorithm with a memory of forbidden moves for the purpose of pushing the search towards yet undiscovered regions of the search space. This metaheuristic is first formalized by Glover [59–61] and several strategies to improve its efficiency were proposed later. A detailed review of well-known TS strategies can be found in [41]. The basic TS procedure starts with a complete feasible solution and all moves that are applicable (not tabu) on this solution are evaluated for their fitness improvements. Then, the move that is the best alternative for the time being is applied to generate a new solution within the neighbourhood of the parent solution. Consequently, the reverse move causing a return to the parent solution is defined as tabu, added to tabu list, and forbidden for a number of iterations. The number of iterations during which a move remains tabu is termed as its tabu tenure. Depending on the fitness landscape characteristics of the problem and tabu search trajectory within its solution space, a move can be removed from tabu list before the end of its tabu tenure. Considering the improvement provided by the best move, the tabu search procedure includes both downward (causing a decrease in fitness) and upward (causing an increase in fitness) moves. While the downward moves implement a steepest descent search throughout the fitness landscape and get stuck into locally optimal solutions, upward moves provide means for climbing hills and reaching other promising regions of the search space. A generic algorithm describing the basic tabu search procedure is given in Algorithm 2.Algorithm 2Basic tabu search procedure.Tabu_Search(s0,f(s0),Max_Trials,Max_Failures) % s0 is the input solution.DONE←0;while (not DONE),Compute fitness changes of all moves that are applicable within the neighbourhood of s0;Select the best move which is not tabu or it is tabu but satisfies all the aspiration criteria;Apply the move on s0;Update f(s0);Update the tabu list and set tabu tenures of move elements;If fitness change caused by the best move is a strict improvement,Update Best_Solution found so far;elseNum_Failures←Num_Failures+1,end ifNum_Trials←Num_Trials+1;DONE=Check_Termination(Num_Trials, Num_Failures);end whileThe tabu search variant used in our proposal is the robust tabu search algorithm (RTS) developed by Taillard [26]. Compared to the conventional TS algorithm and application to QAP, RTS introduces two basic improvements in terms of the tabu tenure parameter and the aspiration criteria. In this respect, tabu tenure of a move is selected randomly from a given range [lmin, lmax]. Tabu tenure is periodically changed after m iterations that is also chosen randomly from a given range. A move passes the aspiration criterion if both of the components exchanged by the move are not placed to locations which are already tried since the last t iterations.Robust tabu search has successfully been applied for the solution of QAP either alone or as the local search partner of a hybrid metaheuristic. Algorithmic parameters of RTS considered in our experimental evaluations are given in Section 6.This study presents a novel methodology within a metaheuristic framework for the global optimization of a difficult combinatorial optimization problem, namely the QAP. Due to its NP-hard complexity, extraction of exact solutions for most of the QAP instances are computationally infeasible and solution of this problem reduces to finding solutions of near-optimal quality within a countably finite but difficult fitness landscape. Among many approximation methods for optimization problems, metaheuristic algorithms are proved to be effective and computationally feasible alternatives. In fact, they are the best alternative when the trade-off between computational cost and solution quality is considered. Based on the number of potential solutions used in exploration of the solution space, metahueuristics for global optimization can be categorized as population- and trajectory-based algorithms. Trajectory-based algorithms use only one solution at a time to explore the solution space while the population-based methods are employing multiples of solutions for this purpose. The method presented in this paper uses a kind of hybrid approach that uses one solution in exploration of the solution space while two populations of high-quality and diversely distributed solutions are employed to efficiently direct the trajectory towards potentially promising regions of the solution space.In the presented method, a solution vector X and a two-stage external memory M=MFS∪MSSare maintained, where MFSand MSSdenote the first and the second stages of the external memory M, respectively. Elements of M are promising solutions extracted throughout the search process and the reasoning behind the two stage architecture is exploiting the useful information stored within diversely distributed good solutions without causing early convergence or being trapped into locally optimal solutions. In this respect, the first stage memory MFSacts as a short−term memory whose elements are changing frequently whenever a solution better than the worst of its elements is extracted, whereas the second stage memory MSSfunctions as a long−term memory whose components are updated only after a certain number of elements of MFSis updated.As mentioned above, elements of MFSand MSSare elite solutions found in previous iterations. First stage memory MFShas a fixed size |MFS|=L, whereas the maximum size of the second stage memory is |MSS|=K, with the condition that K≤L. That is, the number of elements in MSSis initially K and may decrease up to one with increasing number of iterations due to convergence of solutions to one or more locally (globally) optimal solutions. Both memories are initially empty and MFSis initialized with randomly built solutions. Then, to initialize MSS, similarities between mutual elements of MFSare computed and dissimilar elements of MFSsorted in increasing order of their fitness values are inserted MSS. As indicated before, the number of solutions inserted into MSScan be at most K and initialization of the external memory M is completed this way. Based on our experimental observations, random initialization of MFSresults in a diverse distribution of its elements in the solution space and initial size of MSSis almost always is equal to K.After initialization of the two-stage external memory, the search procedure begins with a randomly built initial solution X, which is evaluated using the objective function f(.) to get its fitness as f(X). In order to implement a controlled diversification through the solution space and exploit the accumulated experience within the external memory, two different crossover operators and a mutation operator are applied probabilistically to convert the current solution X into Xnew. The main objective of the two crossover operators is to direct the search towards promising regions of the search space without causing premature convergence to locally optimal solutions. The mutation operator, implemented through mutating a partially complete solution extracted from a randomly selected element of MSS, aims controlled diversification around potentially promising solutions stored in MSS. In this respect, probabilistic applications of the three search operators used throughout the proposed algorithm is described in Algorithm 3, where randi([IMIN, IMAX]) is the function generating uniformly distributed integer numbers in [IMIN, IMAX], rand() is the function generating uniform random numbers in [0, 1], p1 and p2 are the parameters determining the frequency of selection for each of the three moves. Values of p1 and p2 are determined experimentally.Algorithm 3Probabilistic selection of the three search operators (moves).for i=1 to N,R1←rand();r←randi([1, |MSS|]);if R1≤p1,R2←rand();if R2≤p2,r′←randi([1, |MSS|]); /* */Xnew←Xover1(MSS(r, :), MSS(r′, :));elseXnew←Mutation(MSS(r, :));end ifelseXnew←Xover2(X, MSS(r, :));end ifendforThe first crossover operator is the swap-path crossover (SPC) that was originally developed by Glover and named as path-relinking operator [63]. SPC is one of the very effective operators for permutation-type problems and it is described as follows [62]: let Par1 and Par2 be two parents to be crossed over, c1 and c2 be two different uniformly randomly selected crossover points such that 1≤c1≤c2≤N, and N be the chromosome length that is equal to the number of facilities. Then, the allelic values of the two parents are examined from c1 to c2; if the allelic values of the two parents at a locus are not the same, they are interchanged between Par1 and Par2 so that the allelic of values of the two parents at the current position become the same. An example illustrating the implementation of SPC is presented in Fig. 1.The second move is a mutation operator that was already used in [36] within a memory based ACO framework and found successful in reaching high quality solutions for difficult quadratic assignment problems. In the execution of this operator, first a partial permutation of facilities is extracted from a randomly selected element of the second stage archive MSS. An important property of this partial permutation is that its assigned facilities share the same locations with a promising solution of the second stage archive the elements of which are dissimilar to each other according to a predefined similarity measure. The unassigned facilities of this partial permutation are assigned to empty locations through uniformly random selection. Fig. 2illustrates the implementation of this mutation operator.The third move is a crossover operator taking the current solution and a randomly retrieved element of MSSas its arguments. This crossover operator is implemented in [64] and experimentally shown to be an effective search operator for the multiobjective version of QAP. Considering the current solution X and a randomly retrieved element of MSS, the segment based crossover operator first cuts a randomly located and random length segment from the archive element. Then, this cut segment is pasted over the same positional segment of the current solution X. Elements of the pasted segment that are repeated outside the cut region are replaced by those elements of the current solution previously located in the same area. This replacement is done in the order that the replaced facilities appear in the current solution X. An example demonstrating the application of this operator is given in Fig. 3.Together with the above described memory-based search operators, another novelty brought by the proposed method is the structure and organization of the maintained two-stage external memory. The two-stage architecture allowing the exploitation of accumulated search experience without causing premature convergence works as follows: as explained before, the fixed-size first-stage memory MFSis initially empty and it is filled with randomly constructed solutions. Elements of MFSare updated every time a new solution better than its worst element is discovered. In such a case, the worst element of MFSis replaced by the new better solution. In order to speed up the removal and insertion procedures, elements of MFSare always kept sorted in increasing order of their fitness values. Consequently, elements of MSSare determined as follows: since elements of MSSare required to be potentially promising solutions which are diversely distributed within the solution space, solutions in MFSare checked for variable-space similarity and those elements with similarity scores lower than a predefined threshold λ are labelled as similar. Then, dissimilar elements of MFSare sorted in increasing order of their fitness values and inserted into MSSin order without exceeding its maximum size, K. Diverse distribution and dissimilarity of elements in MSSaims to prevent premature convergence due to initially superior but locally optimal solutions and to explore the solution space around the several promising solutions. Depending on the defined similarity threshold and the current iteration of the optimization procedure, the number of elements in MSSchanges between 1 and K. The distance based variable-space similarity measure used in the proposed approach is the Hamming distance that is defined as the number of locations at which two permutations are different.(2)Sim(X,Y)=Hamming_Distance(X,Y)The Sim(X, Y) score is taken as a measure of closeness between the two vectors X and Y. From the above definition, it is clear that Sim(Y, X)=Sim(X, Y). and when Sim(X, Y) is less than a predefined threshold λ, then the two vectors are classified as similar and one of them is marked not to be insert it into MSS. This way, all elements of MSSare kept maximally apart from each other. This similarity based evaluation of solution vectors in variable space (not in fitness space) allows diverse sampling of promising solutions within the solution space. Hence, representative solutions from different localities allow simultaneous intensification around more than one solution, even when their fitness values are close to each other. Elements of MSSare updated as follows: when elements of MFSare updated for a predefined q number of times, the total external memory M is built as M=MFS∪MSS. Obviously, the size of M, |M|=|MFS|+|MSS|, depends on the iteration at which the union is made because of the iteration dependant size of MSS. Consequently, similarity measure between mutual components of M are calculated using Eq. (2) and only one of those elements that are similar to each other remains unmarked. Unmarked elements of M are sorted in increasing order of their fitness values and they are then inserted into MSSwithout exceeding its maximum limit. This combined evaluation and update methodology for MSSenables the storage of representative solutions from multiple promising regions of the solution space and searching around them until they are replaced by better representative solutions. Hence, the proposed architecture with variable-space similarity evaluation is quite suitable for fitness landscapes with multiple optimal solutions with the same level of fitness values.As pointed out before, for hard permutation-type combinatorial optimization problems like QAP, most of the metaheuristic methods need a local search support to reach competitively good solutions within reasonable computation times. In this respect, tabu search is one of the best local search methods used for the solution of combinatorial optimization problems for which hybridization with metaheuristics is experimentally shown to reach the best found solutions over benchmark problem instances. Accordingly, based on the success of different tabu search variants over the QAP instances, we used the robust tabu search (RTS) that is described in Section 4. However, as shown in Algorithm 5, our use of RTS as a local search support is not as frequent as the other hybrid approaches. RTS procedure is used only after MSSis updated and it is used for the improvement of a few randomly selected individuals of MSSthat stores the most promising and diversely located solutions extracted so far.Based on the above explanations, an algorithmic description of the proposed algorithm is presented in Algorithms 3 and 4. While Algorithm 3 introduces the steps of initializing the starting solution and search procedure parameters, Algorithm 4 describes the fundamental computational details of the proposed method.Algorithm 4Initialization of starting solution and search algorithm parameters.Iter←0,Build an initial solution, SIter;Compute the fitness of SIter, FOld←F(SIter);FBest←FOld;Set the maximum number of iterations to MaxIter;Estimate the fitness of a globally optimal solution, FGbest;Set the initial value of LevelIter, LevelIter←FOld;Set the level decay parameter ΔLevel←(FOld−FGbest)/MaxIter;Set “not improving length limit” to NILength; /*This is the conditions when the algorithm reinitializes the current solution when it gets stuck at a locally optimal solution.*/Set the MSSupdate indicator to q;Set the “similarity threshold” to λ;Set “not improving counter” to zero, NICount←0;Set MSSupdate counter to zero, MSSUpCounter←0;Set |MFS|←L, Max_MSS_Size←K;Initialize MFSwith randomly built solutions and compute fitness values of solutions in MFS;Set MSS←∅;Similarity_Matrix=Compute mutual similarities between elements of MFS(Equation (2));for each row i of Similarity_Matrix,if the ithelement is not marked as similar before,Mark all solution with a similarity measure below λas similar to the ithsolution;end ifend forSort unmarked elements of MFSin increasing order of their fitness values;Insert unmarked elements of MFSinto MSSwithout exceeding its maximum size;Algorithm 5Pseudocode of the two-stage external memory based great deluge algorithm.Iniatilize SIterand Other Search Parameters Using Algorithm 3;DONE←0;while(Not(DONE));Generate a new solution, SIter+1, starting from SIter; (Algorithm 2)Compute the fitness of SIter+1, FNew←F(SIter+1);if FNew<F(MFS(L));Remove Lth(i.e. the worst) element of MFS;InsertIter+1 into MFS; (its positions depends on its fitness value)MSSUpCounter←MSSUpCounter+1;if MSSUpCounter>q,M←MFS∪MSS;Similarity_Matrix=Compute mutual similarities between elements of M;for each row i of Similarity_Matrix,if the ithelement is not marked as similar before,Mark all solution with a similarity measure below λas similar to the ithsolution;end ifend forSort unmarked elements of MFSin increasing order of their fitness values;Insert unmarked elements of MFSinto MSSwithout exceeding its maximum size;MSSUpCounter←0;end ifApply local search RTS for max(1, ⌈0.05*N⌉) randomly selected elements ofMSSand insert the found solutions into MSS;end ifif FNew<FBest,FBest←FNew;FOld←FNew;NICount←0;elseif FNew≤LevelIter,FOld←FNew; NICount←0;elseNICount←NICount+1;if NICount==NILength,Initialize SIter+1 randomly and evaluate its fitness value;NICount←0;end ifend ifend ifLevelIter+1←LevelIter−ΔLevel;Iter←Iter+1;DONE←CheckTermination(MaxIter, NICount);end whileTo evaluate the performance of the proposed algorithm and exhibit its comparative success against well-known metaheuristics, 137 benchmark problems taken from QAPLIB [65], 21 instances named as taixxeyy[66], and the 12 Drezner instances [21,67] are considered. In [43], QAPLIB problems are categorized into four types depending on properties of their flow and distance matrices as follows:I.Unstructured, randomly generated instances for which the elements of distance an flow matrices are generated uniformly randomly within a range of integer values (e.g. taixxa instances). These instances are among the most difficult ones in terms of the computational time required to find a solution closest to the best known one. Table 1 lists the properties of QAP instances in this category where BKS denotes the fitness value of the best known solution (BKS). It is stated in [43] that, in the limit of large instance sizes, the difference between the upper and lower bounds on the optimal fitness values converges to zero. This implies that these instances have a unique or a very small set of optimal solutions.Instances with grid based distance matrices for which the locations are assumed to be on the nodes of an n1×n2 grid and the distances between locations are taken as Manhattan distances between grid nodes (e.g. nugxx and skoxx instances). These problem instances are illustrated in Table 2.Real-life instances stemming from applications of QAP with flow matrices having many zero entries (e.g. chrxxx and escxxx instances). These instances are generally small in size and easy to solve for any powerful metaheuristic with an appropriate local search support. A list of these problem instances are given in Table 3.Randomly generated real-life like instances having flow matrices similar to real-life instances with the exception that the nonzero entries of flow matrices are uniformly distributed within a predefined range of integer values (e.g. taixxb instances). Table 4 shows list of these problem instances.We also considered two sets of moredifficult QAP benchmark instances, namely, the Taillard's taixxeyy instances and the Drezner's drexx instances. Unlike the taixxa instances, the taixxeyy instances are characterized as structured and symmetric such that certain facility permutations (exchanges) do not change the fitness value. That is, fitness-equivalent solutions in the form of different permutations are visited again and again through out the exploration process that makes these QAP instances hard for metaheuristic algorithms. Taixxeyy instances of size 27 and 45 are solved optimally by the proposed method in all trials. The average cpu times for tai27eyy and tai45eyy instances are 0.27 and 17.59min, respectively. Best known fitness values of tai75eyy instances and tai125e01 instance are available in Table 6. Comparative evaluations of the proposed method for these difficult QAP instances are also given in the following subsections.Considering the Drezner instances, they are experimentally shown to be hard QAP instances for metaheuristic methods. In these problems, locations are assumed to be distributed over nodes of a rectangular grid with highly sparse non-zero flow values such that the objective function will change only for a few pair-wise exchanges of facilities and, for those pair-wise facility exchanges causing a change, the fitness function changes quite steeply. This also means that it is hard to reach an optimal solution from its neighbourhood due to very small neighbourhood size and sharply changing fitness landscape [21,67]. Table 7presents characteristics of Drezner problem instances.In experimental studies, except the taixxeyy instances, each benchmark problem is solved in 10 consecutive independent runs with the termination criteria set in terms of maximum 20000×N (N=number of facilities) fitness evaluations for all the benchmark problems and for all the algorithms in the experimental suit. Experiments for taixxeyy instances are conducted 20 times for the purpose of compatibility with the only one reference with results of these instances. Algorithmic parameters of all algorithms are kept the same for all the benchmark problems and no interactive intervention is made throughout the individual runs. All implementations are carried out using Matlab®10 programming language environment and toolboxes, and a personal PC with 8GB main memory and 2.1GHz clock speed.The proposed algorithm contains two sets of parameters to be set as follows: The first set contains the three parameters of the great deluge algorithm as described in Algorithm 1. These are LevelIter, ΔLevel and not improving length limit NILength parameters. Values used for Level and ΔLevel parameters are given in Algorithm 3, and settings for all the other parameters mentioned so far are listed in Table 1. Tabu search aspiration criteria are set as described in [26] and all parameter values are globally used for all executions and for all problem sets.Experiments with QAPLIB problems started with unstructured and uniformly randomly generated type-I instances. As explained above, these are among the hardest problem instances for metaheuristics due to fact that they have unique or very small sets of optimal solutions. Table 2 illustrates the average, best, and worst percent deviations (APD, BPD, WPD, respectively) from the fitness of best known solutions (BKS) where the subscripts in parentheses show the number of times BKS is found out of the 10 runs. All cpu-times are in minutes. It can be seen that the best known solutions are found for most of the problem instances. Among the 28 problems in this category, BKS could not be extracted for only 7 difficult instances. For the difficult problems, from tai40a to taii100a and from lipa70a to lipa90a, the APD values are all less than 1.0%, BPD values are all less than 0.4%, and WPD values are all less than 1.5% of BKS. As will be illustrated in the following subsections, majority of the APD values are better than those of RoTS. Considering the cpu-times, they are within the feasible limits, the largest cpu-time is spent for the solution of tai100a instance for which each trial took around 2 cpu-hours.The second category of QAPLIB problems, with grid-based distances between locations, includes both easy (nugxx) and difficult (skoxx) instances. Experimental results for this category of problems are given in Table 3. Among the 36 QAP problems in this category, only two of them (sko100f and tho150) could not be solved optimally. All nugxx instances are solved optimally in all trials and the cpu-time required for each trial is less than two minutes for the maximum size nug30 instance. The hardest problems of this category are the skoxx instances of size 49 and above. For the 12 sko49-sko100f instances, only sko100f could not be solved optimally. APD value for this problem is 0.013% which shows that the average performance of the proposed method for this difficult instance is very close to optimality. On the other hand, the WPD value for sko100f instance over the 10 trials is 0.262% which is another indication on the effectiveness of the proposed method; the closeness of the worst fitness value to BKS is less than 0.3%. Another problem that could not be solved optimally is the large size tho150 instance. The APD and WPD values for this problem are 0.039% and 0.139%, respectively. The two-stage memory architecture that enables exploration around multiple promising solutions achieved the relative percent quality of the worst solution for this difficult instance is less than 0.15%. Cpu-times are around 2.5 hours for sko100x instances and the will100 instance, while it is 7.5 hours for the tho150 instance.Tables 4 and 5illustrate the results for simple real-life instances with flow matrices having many zero entries. The proposed method found optimal solutions for all problems in this category within short computation times. The largest cpu-times are spent for the solution of ste36a, esc32a and esc128 for which the optimal solutions are found in approximately 2 minutes. For majority of other instances in this category, optimal solutions are reached in less than 0.5 minutes.Experimental results for the last set of QAPLIB instances, randomly generated real-life like instances, with flow matrices containing nonzero entries uniformly distributed within a predefined range of integer values are given in Table 6. Compared to taixxa instances, these taixxb instances are simpler and they are solved optimally up to size 64. For problem size greater than or equal to 80, optimal solutions could not be extracted, however APD, BPD and WPD values listed in Table 6 indicate that the solutions found by the proposed method are very close to BKSs. The largest size instance in this category is tai150b for which the APD, BPD, and WPD values are 0.051%, 0.023% and 0.069%, respectively. All the three indicators are below 0.07% even for this very large size QAP instance.Considering the difficult taixxeyy instances, all tai25eyy and tai45eyy instances are solved optimally in all 20 trials. Running time information for these problems was given above. Since the best known fitness values are for Tai75eyy and tai125e01 were available in [68], these instances are considered in our experimental results for both self and comparative evaluations. Table 7 presents the APD, BPD, WPD and cpu-time scores for these problem instances. The proposed method extracted optimal solutions for all of the 20 tai75eyy instances and the average cpu-time required to complete one experimental trial was around 1.5h. Further evaluations with respect to other algorithms attempted to solve these QAP instances are given below.The last set of QAP instances considered in our experimental evaluations contains the difficult drexx instances. The proposed method solved these instances optimally up to size 42. Table 8illustrates the scores for drexx instances for which the proposed method could not locate optimal solutions for sizes 56 and above, and deviation BKSs increase with increasing problem sizes. Even though the proposed method could not locate BKSs for some of drexx instances, as shown in Table 14, the APD scores achieved are much better than its single competitor.Tables 9–14exhibit the comparative scores of the proposed algorithm against well-known metaheuristics that are frequently referred to in literature. Scores associated with all metaheursitics are taken from [29] and verified over the individual references. Abbreviations used for all algorithms are the same as the ones used in [29] and their corresponding references from which the associated scores are verified are as follows:1DivTS: DivTS restart tabu search approach [29];RTS: Robust tabu search [26,29];GRASP: Greedy randomized adaptive search procedure [37];ACO-GA/LS: A hybrid metaheuristic for QAP [69];ETS1: A tabu search algorithm for QAP [28];GS/TS: GAs hybridized with a ruin and recreate procedure [31];GA/TS/I: An Improved hybrid GA [32];GA-S/TS: GA hybrid with standard TS [30];GA-C/TS: GA hybrid with concentric TS [30];GA/IC-TS: GA hybrid with improved concentric TS [27];I-ILS6: Iterarted local search for QAP [43];ACO2, ACO3: ACO algorithms for QAP [34].Tables below illustrate the APD or BPD scores, whichever is available, for the proposed method and all of its competitors listed above. The proposed method is named as TMSGD-QAP from now on in all tables. It should be noted at this point that, experimental settings, programming platforms and hardware resources of almost all algorithms considered for comparative evaluations are different, hence a true comparison under the same experimental conditions is not possible. Meaningful runtime comparisons are not usually possible also for the same reasons. However, as can be seen from the tables on self-evaluation, cpu-times of TMSGD-QAP for all benchmark problems are within feasible limits compared to the run-times reported by its competitors. For example, run-times reported for RTS and DivTS in [29] are very close to the ones presented in the self-evaluation tables given above. Even if the computational platforms are not exactly the same, this observation can be seen as an indicator on the feasibility of our cpu-time scores. In addition to these, another obstacle making the true comparison impossible is the unavailability of results for all benchmark problems for all algorithms. Blank spaces in table entries indicate the absence of scores between the corresponding problem and metaheuristic entries. These are the main reasons of comparing deviations from best known values without taking implementation details and settings of algorithmic parameters such as maximum number of fitness evaluations into account.Tables 9–12 show the comparative results of TMSGD-QAP and 9 other well-known metaheuristics for QAPLIB benchmark problems. Since APD and BPD results of DivTS were also available for all problems in this set, scores of TMSGD-QAP and DivTS are organized in two columns. Considering Table 9 that illustrates APD and BPD scores for type-I QAPLIB problems, the hardest problems of this set are taixxa and lipaxxa instances. Scores for taixxa instances are available for all metaheuristics, except GRASP, and TMSGD-QAP performs equally well or better than its competitors in 4 of these 9 QAP instances, whereas ETS1 and GA/TS/I are the two best performing algorithms for the remaining taixxa instances. While the proposed algorithm is better than RTS for 5 of 9 taixxa problems, it outperforms ACO2 for all problem instances. Considering the performances of TMSGD-QAP and DivTS, that is a successful variant of RTS for QAP, DivTS performs better than TMSGD-QAP in 5 of the 9 problems with respect to the APD scores, however TMSGD-QAP achieved equally well or better scores in 8 of the 9 instances in terms of the BPD scores. DivTs’ BPD score is better for tai40a problem only. This clearly shows that while exploration capability of the proposed method results in solutions in different regions of the solution space, its intensification capability through using a two-stage memory also makes it possible to locate better solutions even for difficult problem instances. For the second class of difficult problems in type-I instances, lipaxxa instances, DivTS performs better than TMSGD-QAP in 3 of 8 problems with respect to APD scores. The proposed method performs equally well-or better than RTS and GRASP in all of 9 problems. It can also be seen in terms of BPD scores that the solutions extracted by TMSGD-QAP for the large size lipa70a, lipa80a, and lipa90a instances are very close to fitness of BKSs. The use of the two-stage archive storing dissimilar solutions with promising fitness values results in spending part of limited fitness evaluations around several solution that delayed the intensification around the most promising solution (best solution found so far). This is main reason of being slightly behind the DivTS algorithm. On the other hand, if take the number of fitness evaluations into account, the number of fitness evaluations used by DivTS is at least 50000*N, whereas this parameter for TMSGD-QAP is at most 20000*N. That is, the proposed method achieved equally well or better solutions for difficult problem instances through 2.5 times less fitness evaluations, except for only a few large-size problems for which APD and BPD values are less than 0.05% in most of the cases. Other type-I problems are simple and they solved optimally for all algorithms for which the corresponding scores are available.Scores for comparative evaluations of type-II QAPLIB instances are shown in Table 10. The easiest problems of this category are the nugxx instances that are solved optimally by all algorithms that attempted to solve them. The hardest problems of type-II instances are the skoxx instances and, in terms of the APD scores, I-ILS6 is the best performing algorithm in 7 of the 13 problems. However, GA/TS-IC outperforms all of its competitors for skoxx instances of size 90 and above. TMSGD-QAP achieved APD scores of less than 0.03% for all of the skoxx instances, however DivTS's APD scores are better for large-size skoxx problems, except for sko49, sko56 and sko100f instances. BPD scores of TMSGD-QAP and DivTS are also very close to each other. Among 13 skoxx instances, the two algorithms perform equally well in 10 instances; while TMSGD-QAP is better in 2 instances sko90, sko100a, DivTS is better in 1 instance sko100f. The other four type-II instances for which algorithms’ performances differ are tho40, tho150, wil50, and wil100 instances. The best APD score for tho40 instance belongs to I-ILS6, the second place is taken by DivTS, and the third place is shared by TMSGD-QAP and GA/TS-IC methods. None of the algorithm solved large-size tho150 optimally, the proposed method is the second best performing algorithm for this problem and both the APD and BPD scores are very close to the best performing DivTS metaheuristic. GA/IC-TS has zero values for APD scores of wil50 and wil100 instances while the proposed method and DivTS are performing approximately equally well for these two problems. Based on the results associated with the type-II QAPLIB instances, it can still be observed that the capability of searching around diversely distributed promising solutions has the advantage of locating BKSs for most of the difficult problem instances and approaching BKSs quite closely from different directions, however spending some of limited number of fitness evaluations around multiple promising solutions may cause termination of procedure before exactly locating the optimal solutions.Type-III QAPLIB instances are the simplest set of problems for the proposed TMSGD-QAP algorithm. As exhibited in Table 11, all problems in this set are solved optimally and the cpu-time required is less than one minute for most of the problem instances. Comparing the proposed algorithm against DivTS, it can be seen that the proposed method is better then than DivTS in three problem instances, chr20b, chr22b and chr25a, for which the number of times the optimal solution is found over ten trials are all 10 for TMSGD-QAP. Similarly, APD values of the proposed algorithm are better than those of RTS for the three problem instances mentioned above. BPD score of GRASP are comparably poor for these three problems compared to those of TMSGD-QAP and DivTS, while BPD score of ACO-GA/LS is poor for chr20b only. Other algorithms reported APD scores for only a few simple problem instances and a comparison with their scores cannot lead strong conclusions.As explained before, QAP problems in type-IV category are simpler compared to the ones in type-I and type-II categories. Table 12 illustrates the APD and BPD scores for problems in this set. Most of the algorithms solved problems up to size 80 optimally, except GA/TS and ACO2 that have comparably weak scores in 3 of 7 instances of size 60 and below. GA/TS/I seems to be the best performing algorithm in this category. For the larger size instances, tai80b and tai100b, the proposed method's score is very close to that of DivTS, however the achieved score for tai100b is twice better than that of DivTS. The largest-size taib150b is attempted by the proposed method only, for which the APD and BPD values are less than or equal to 0.05%.Experimental scores associated with the set of tai75eyy problem instances are given in Table 13. As explained at the beginning of experimental evaluations, the proposed approach solves all tai27eyy and tai45eyy instances optimally in all trials. In fact, they are also reported as solved optimally by all algorithms listed in Table 13. Hence, scores associated with these problem instances are not tabulated below. Based on our detailed literature search for metaheuristics used for the solution taixxeyy instances, best known results of tai75eyy problems and three algorithms attempted to solve them were available. References from which the corresponding scores are taken, with the names specified in their publications, are also shown in Table 13. Then, since those three metaheuristics’ published scores were based on 20 run, each of these problems is solved over 20 independent runs for comparative evaluations and the corresponding APD values are listed in Table 13. It is clear that the best performing algorithm is HG. The proposed method takes the second place and performs significantly better than cooperative parallel tabu search (CPTS) algorithm. GH, for which the scores of tai75e01 is available only, has a poor performance compared to the other algorithms under consideration. GH is also used for the solution tai125e01 for which the score of TMSGD-QAP is twice better. These results demonstrate that the proposed approach is capable of extracting optimal solution for large-size difficult QAP instances while its average performance is also within acceptable limits.Table 14 illustrates the APD scores for the final set of QAP instances containing the difficult drexx problems. Unfortunately, only one algorithm is found in literature with scores of some of the drexx problems. It is observed that the proposed TMSGD-QAP algorithm solved all drexx problem of size 30 and below optimally in all 10 trials. It was also capable of extracting optimal solutions of dre42 and dre56 instances. For rest of the problems in this set, TMSGD-QAP's APD score increases with increasing problem size, however its performance compared to HG, that was the best performing algorithm for tai75eyy instances, is significantly better. Remembering that the basic characteristic of drexx problems is that many solutions within the neighbourhood optimal solutions have the same fitness values, the use of a two-stage external memory with promising solutions from distant regions of the solution space made it possible to reach better solutions compared to algorithms that concentrate the search around a few initially promising solutions.Three very recently published methods for the solution of QAP are taken into consideration for further comparative evaluations of the proposed algorithm TMSGD-QAP. The first of these methods, proposed by Tosun [71], is a study on the performance of parallel hybrid algorithms (PHA) for the solution of QAP. This hybrid approach combined island parallel genetic algorithms (IPGA) with robust tabu search algorithm (RTS). It is implemented on a cluster computer with 92 cpus, a total of 368 cores, 736 GB of total memory and 6.5 TB of permanent storage capacity. This rich computational resources made it possible to use huge population sizes (5000 individuals for each slave) and a termination condition of approximately 2 million number of failures for the RTS algorithm. As indicated in Table 1, the proposed TSMGD-QAP employs RTS over a few solutions with a total number fitness evaluations equal to 10*N and with much less frequency compared to PHA. Results of PHA and TSMGD-QAP for four types of QAPLIB benchmarks are listed in tables below together with comparative evaluations and interpretations.The second algorithm authored by Benlic et al. is a memetic search algorithm that integrates breakout local search (BLS) within an evolutionary computation framework [72]. This algorithm is executed on a single processor with a maximum of time limit of 2 hours. The authors used BLS for each newly generated offspring after crossover with 5000 local search iterations. This algorithm is named as BMA and its associated results are presented in the following tables.The third algorithm under consideration is proposed by Dokeroglu and it is a hybrid teaching-learning based optimization approach for QAP. The algorithm first optimizes a population of individuals using a teaching-learning based optimization (TLBO) procedure [73]. Individuals within the latest population optimized by TLBO are further improved by the RTS algorithm. Maximum number of failures for RTS is taken as 2000*N. The authors named this algorithm as TLBO-RTS.Tables 15–18illustrate the results of TMSGD-QAP, PHA, BMA and TLBO-RTS for the four types of QAPLIB benchmark problems. As explained above, a fair comparison of all algorithms is not possible due to variations in computational resources (both in hardware and software), number of fitness evaluations, termination conditions, and algorithm parameters such as population size, crossover rate, local search parameters etc. Hence, the cpu-time columns in the following tables are taken from the corresponding references as they are and will be used for performance interpretations rather than comparing algorithm complexities. Table 15 shows results of four algorithms for type-I benchmark problems that contain hard problems for metaheuristics. BMA seems to be the best performing algorithm in terms of solution quality, computational resources and cpu time requirements. Noting that PHA is running on 46 nodes with a population of 5000 individuals on each node (i.e, total population size is 46*5000) and comparably very large local search iterations, its performance is not proportional to richness of its computational resources. For example BMA is better than PHA even though it runs on a single cpu and with a population size of 15 individuals. In this respect, considering that TMSGD-QAP is a trajectory based algorithm (i.e. population size is 1), running on a single cpu and using RTS with much less frequency over a few randomly selected individuals, its performance can certainly be considered better than that of PHA. Problems for which PHA seems to be better than TMSGD-QAP, corresponding cpu times of PHA are 3–5 times larger to achieve around 20% improvement in solution quality. Considering also the number of cpus and storage space used to get this improvement, it can obviously be claimed that it is not worth of this trade off. It can also be seen from Table 15 that TMSGD-QAP is better than TLBO-RTS in terms of both solution quality and cpu-times.For type-II benchmark problems, all algorithms solved nugxx problems optimally however PHA took 10 to 100 times more cpu-time compared to TMSGD-QAP. The fastest algorithm for this set of problems is BMA. For skoxx problems, BMA is again the best performing algorithm whereas TLBO-RTS takes the fourth position in terms of solution quality. PHA solved all skoxx instances optimally in 3 to 10 times more cpu-time than TMSGD-QAP whereas the solution quality improvement stayed in the order 0.001–0.003%. Success of TMSGD-QAP is still better than that of TLBO-RTS for this set of problems also. Type-II benchmarks contains a large size instance tho150 for which TMSGD-QAP performed better than BMA and TLBO-RTS algorithms in terms of the solution quality. PHA's solution quality is the best for this particular instance while its running time is 3 to 10 times more than those of other methods.Type-III problems are the simplest ones that are solved optimally by the four algorithms. PHA is used to solve a few of these problems for which it is the slowest algorithm. The fastest algorithm for this set of problems is BMA whereas the speed of TMSGD-QAP is faster than that of TLBO-RTS for majority of instances.For majority of problems in type-IV category of QAPLIB problems, TMSGD-QAP and its competitors exhibited optimal performance. Similar to the previous comments, PHA is still the slowest and BMA is the fastest and the most successful algorithm. For a few problems in this category, success of TMSGD-QAP and TLBO-RTS are similar to each other. For the second largest QAPLIB problem tai150b, TMSGD-QAP performed slightly better than BMA, PHA is the best performing algorithm that runs almost 7 times slower than TMSGD-QAP.As an overall summary of the above discussions on the performance of TMSGD-QAP against three recently published algorithms, it can be concluded that the proposed two-stage memory support to the trajectory based GDA resulted in a comparably powerful algorithm against its three competitors. BMA is clearly better than our proposal whereas TMSGA-QAP is clearly better than TLBO-RTS and comparisons of these three algorithms are easier and fair since they are executed on similar computing platforms. On the other hand, APH uses enormously larger population size, computing processors, storage space and local search iterations, but it performs worse than BMA that runs on a single cpu with a population of 15 elements. Similarly, APH's performance compared to our trajectory based resource-efficient proposal is not proportional to its huge computational resources. As explained above, APH conducts its search over 46*5000 individuals and takes 3–10 times more cpu-time for an improvement of approximately 17%. These comparative evaluations are all positive evidences on the effectiveness of the proposed two-stage memory support for metaheuristics.

@&#CONCLUSIONS@&#
This study aims to exhibit the effectiveness of the novel two-stage external memory architecture, implemented within the framework of a trajectory based metaheuristic, for the solution of a difficult combinatorial optimization problem, the quadratic assignment problem. The fundamental characteristics of the two-stage memory are maintaining a short-term memory, MFS, based of fitness similarity to catch ongoing improvements in the search space and enabling search around multiple promising (by fitness similarity) and diversely distributed (by positional dissimilarity) solutions thorough using the elements in the long-term second-stage memory MSS.The results obtained for three different sets of QAP benchmarks demonstrated that, the proposed method maintaining a two-stage external memory is a competitive and effective algorithm that was capable of locating optimal solutions for most of the benchmark problem instances. In addition to this, the capability of searching over multiple diversely distributed solutions resulted in extraction of solutions of very-near optimal quality for large-size difficult problem instances. The method was also significantly better in performing search over complex neighbourhoods such as the case in drexx problems. Comparisons with the recently published algorithms also exhibit effectiveness of the proposed method against majority of its competitors.Based on the success achieved over a trajectory based metaheuristic, it can be concluded that the proposed two-stage memory architecture improved the search capability of the underlying metaheuristic framework. Further research is ongoing to implement the proposed method for population-based metaheuristics and for multiobjective optimization combinatorial optimization problems.