@&#MAIN-TITLE@&#
Particle swarm algorithm with adaptive constraint handling and integrated surrogate model for the management of petroleum fields

@&#HIGHLIGHTS@&#
We seek optimum management of waterflooding process in oil reservoirs.Due to high computational cost of simulations, Kriging surrogate models are built.Two formulations are proposed to better control particles’ individual behavior.Adaptive constraint-handling technique developed and integrated into particle swarm algorithm.Particle swarm algorithm with adaptive constraint handling optimizes surrogate model.

@&#KEYPHRASES@&#
Adaptive constraint handling,Global search,Particle swarm,Reservoir simulation,Surrogate-based optimization,Waterflooding management,

@&#ABSTRACT@&#
This paper deals with the development of effective techniques to automatically obtain the optimum management of petroleum fields aiming to increase the oil production during a given concession period of exploration. The optimization formulations of such a problem turn out to be highly multimodal, and may involve constraints. In this paper, we develop a robust particle swarm algorithm coupled with a novel adaptive constraint-handling technique to search for the global optimum of these formulations. However, this is a population-based method, which therefore requires a high number of evaluations of an objective function. Since the performance evaluation of a given management scheme requires a computationally expensive high-fidelity simulation, it is not practicable to use it directly to guide the search. In order to overcome this drawback, a Kriging surrogate model is used, which is trained offline via evaluations of a High-Fidelity simulator on a number of sample points. The optimizer then seeks the optimum of the surrogate model.

@&#INTRODUCTION@&#
The search for the optimum management scheme that maximizes oil production in petroleum fields is one of the major challenges in petroleum engineering. In this context, reservoir simulations and optimization methods are extensively used. Thus, Zhao et al. [1] use a Simulated Annealing based optimizer to determine the optimum steam injection pressure and steam-solvent flooding strategy in a thin heavy oil reservoir in the absence and presence of a bottom water zone.Since the net present value (NPV) is related to the production profit, it is commonly used in reservoir engineering management as the objective function [1–4]. Waterflooding (WF) is the most widespread method used to improve oil recovery after primary depletion, i.e. after exhausting the reservoir's natural energy. The method consists of injecting water to raise the pressure and increase oil production. Horowitz et al. [2] propose four formulations of the WF management problem leading to optimization problems of different complexities, using the NPV as the function to be maximized subject to constraints at platform's total rates. They use a sequential approximate optimization (SAO) procedure with a sequential quadratic programming (SQP) local optimizer. This is a strategy proposed in [5], whose main feature is the sub-division of the original problem into a sequence of sub-problems to be solved in a sub-region of the original space named trust region (TR). Surrogate models to be called by the optimizer are built in the TR domain, which is updated as the search progresses [5–7]. This technique is also used by other researchers in the WF optimization context [3].The concession period is usually subdivided into a number of control cycles with fixed switching times, with the well rates in each cycle set as design variables. Oliveira and Reynolds [4] present a hierarchical procedure to determine appropriate number and duration of control cycles. The well-by-well approach is based on criteria for refining/coarsening of control cycles based on gradients of the objective function and on differences between consecutive well controls at each well. If gradients are not available, only the latter criterion is applicable, in which case the merging potential may be affected if optimal controls tend to be rough.While some of the formulations in [2] result in highly multimodal objective functions, the solutions found by the SQP optimizer are very sensitive to the initial guess. Hence we propose here to use a global search algorithm called particle swarm optimization (PSO). The latter is composed of particles with different settings aimed at displaying complementary capabilities, and a so-called forward topology with time-increasing connectivity for the social network. In addition, since the plain PSO algorithm does not handle constraints on its own, an adaptive constraint-handling technique (CHT) is developed and integrated into the optimizer. However, the fact that PSO is a population-based method also implies that it requires a high number of evaluations of the objective function. Given that the performance of a management scheme cannot be evaluated explicitly but by means of a computationally expensive high-fidelity (HF) simulation, it is not feasible to use it directly to guide the search. Surrogate-based optimization has proved useful to the optimization of computationally expensive simulation-based models in the aerospace, automotive and oil industries [8]. Therefore, it is proposed in this paper that a Kriging surrogate model (KM) [9,10] be used, which is trained offline via evaluations of a HF commercial simulator (IMEX [11]) on a number of sample points. The selection for this technique is based on results from previous work in which several procedures for the surrogate construction of the NPV function were tested [2,12].The WF management problem is of high importance in petroleum engineering, whose objective is to increase productivity in petroleum fields using the rates of injector and producer wells as control parameters, thereby maximizing their economic return. In this paper, we show that a particle swarm (PS) algorithm with adaptive constraint handling and a static Kriging model can be combined to obtain near optimal results without the hassle of extensive numerical trial-and-error testing and tuning on a case-by-case basis. It is important to note that no tuning is carried out in this paper.The layout of the paper is as follows: Section 2 presents the WF problem general formulation and four alternatives according to the operational conditions; Section 3 offers a discussion on surrogate models, in particular on Kriging approximations; Section 4 presents an overview of the PSO method, emphasizing the features that are used in our code; Section 5 presents the proposed PSO algorithm, including the formulation and settings of the particles’ trajectory recurrence relation and neighborhood topology, and the development of a novel adaptive CHT and termination conditions; Section 6 presents the proposed integrated tool (PIT), consisting of the tandem Kriging-PSO for the global surrogate-based optimization of the WF problem; finally, results from computational experiments are offered in Section 7, a discussion of results is carried out in Section 8, whilst conclusions and future work are presented in Section 9.The general formulation for the WF problem can be written as shown in Eq. (1):(1)MaximizeNPV=f(q)=∑t=1nt1(1+d)τt⋅F(qt)Subject to∑p∈Pqp,t≤Ql,max∑p∈Iqp,t≤Qinj,maxqp,tl≤qp,t≤qp,tu;p=1,…,nw∑p∈Pqp,t≤∑p∈Iqp,t≤δ⋅∑p∈Pqp,tt=1,…,ntwhereq=q1Tq2T,…,qntTTis the vector of well rates for all control cycles;qt=q1,t,…,qnw,tTis the vector of well rates at control cycle t; qp,tis the liquid rate of well p at control cycle t; ntis the total number of control cycles; and nwis the total number of wells. In the objective function equation, d is the discount rate; τtis the time at the end of control cycle t; and F(qt) is the cash flow at control cycle t, which represents the oil revenue minus the cost of water injection and water production. This is given by Eq. (2):(2)F(qt)=Δτt⋅∑p∈P(ro⋅qp,to−cw⋅qp,tw)−∑p∈I(cwi⋅qp,t)where Δτtis the time length of control cycle t; P and I distinguish producer from injector wells;qp,toandqp,tware the average oil and water rates at production well p at control cycle t; rois the oil price; and cwand cwiare the costs of producing and injecting water. In Eq. (1), Ql,max is the maximum allowed total production liquid rate and Qinj,max is the maximum allowed total injection rate of the field. Superscripts l and u refer to the lower and upper bounds of design variables, respectively. Superscripts o and w denote oil and water phases, respectively. The last constraint in Eq. (1) requires that, for all cycles, the total injection rate belong to an interval that goes from the total production rate to δ times this value, where δ≥1 is the over injection parameter. The commonly used approach to these problems is to subdivide the concession period into a number of control cycles, nt, with fixed switching times. The design variables are the well rates in each control cycle. Four alternative formulations derived from Eq. (1) are proposed in [2], where they combine different platform operational conditions with and without the inclusion of the switching times of the control cycles as design variables. The operational conditions considered are:Full capacity operation (FCO), in which the sum of both production and injection rates are at maximum platform's total rates. Under this assumption, the last equation presented in Eq. (1) is automatically satisfied. These equality constraints actually simplify the problem, as they result in variables expressed in terms of others, thus reducing the dimensionality of the search-space and removing those constraints from the formulation of the optimization problem.Non-full capacity operation (NFCO), in which the total injection and production rates may vary in order to increase the NPV, while the voidage replacement type constraints (last equation in Eq. (1)) are kept.In this paper, situations where the control cycles are determined by the user are referred to as fixed time (FT) whereas those where the control cycles comprise design variables are referred to as variable time (VT). The cases resulting from the combination of operational conditions and types of switching times are depicted in Table 1. For each case, the number of design variables (n) and the type of constraints involved are shown. In the table, nPis the number of producer wells and nIis the number of injector wells. The mathematical formulation of each of these cases in Table 1 can be found in [2].Surrogate models are built to provide smooth functions accurate enough to capture the general trends of the HF model at a considerably lower computational cost. These properties make them especially adequate for optimization purposes.Surrogate models can be classified by differentiating functional from physical (hierarchical fidelity) categories [9]. The former comprises approaches such as data-fitting, polynomial series, and reduced-order methods, whereas the latter involves physical-based models. In this paper, since the performance of a given management scheme is evaluated by means of a commercial simulator acting as a black-box, a data-fitting type is adequate; in particular, a Kriging data-fitting model [9,13,14] is used. The central idea of this model is to assume that errors are not independent but rather exhibit spatial correlation related to the distance between corresponding points modeled by a Gaussian process around each sample point. The main advantages of this scheme are to easily accommodate irregularly distributed sample data, and the ability to model multimodal functions with numerous peaks and valleys. Moreover, Kriging models (KMs) provide exact interpolation at the sample points.The first step in the construction of a KM is to generate the sampling points in the design space, which can be performed using design of experiments (DoE) Techniques [10,15]. Latin Centroidal Voronoi Tessellation (LCVT) [16] is the DoE technique used in this paper. This selection is based on studies presented in [12], where an extensive surrogate model assessment considering different combinations of data-fitting and DoE techniques were conducted for the NPV response considered here. Once m sample points are generated, predictor expressions are developed to evaluate the function at untried design points.In the KM literature, the true unknown function can be written as in Eq. (3):(3)f(x)=∑j=1kβj⋅Nj(x)+Z(x)In the above equation, the first part is a linear regression of the data with k regressors, in which βjare the unknowns and Z(x) is the error. The latter is a (generally normally distributed) random function with zero mean, σ2 variance, and non-zero covariance. The first term provides a global model or trend over the design space, while Z(x) is responsible for creating a localized deviation from the global model. Polynomials are generally used to construct Nj(x). A traditional approach called ordinary Kriging employs a zero-order (constant) function, so that the true unknown function becomes as in Eq. (4):(4)f(x)=β+Z(x)where β is an unknown constant to be estimated based on m observed response values (samples). The covariance matrix of Z(x) is given by Eq. (5):(5)Cov[Z(xi),Z(xj)]=σ2⋅R⋅[R(xi,xj)]where xiand xjare the sample points and R is the m×m correlation matrix of the stochastic process. Gaussian correlation function is used here. Therefore,(6)Rij=R(xi,xj)=exp−∑k=1nθk⋅xki−xkj2where θkis the kth unknown correlation parameter used to fit the model.Predicted estimates of the response f(x) at any point of the design domain are defined asfˆ(x)=E(f(x)|fs), which stands for the expected value of f(x) given the information in the true values of the function at m sampling points fs=[f1,…,fm].A measure of the amount of error between the KM and the true model can be found introducing the concept of mean squared error (MSE):(7)MSE=E(fˆ(x)−f(x))2By minimizing the MSE in Eq. (7), the best unbiased predictor in [9] is obtained, as shown in Eq. (8):(8)fˆ(x)=βˆ+r(x)T⋅R−1⋅(fs−β⋅f)whereβˆis unknown; f=[1,…,1] is a vector of ones; and r(x) is a correlation vector between untried x and the m sample data points, as shown in Eq. (9).(9)r(x)=[R(x,x1),…,R(x,xm)]As described in [9], the unknown parameters θkpresent at Gaussian correlation function R are found using maximum likelihood estimation, which is reduced to an n-dimensional minimization problem with simple bounds. In this approach, the values forβˆare obtained using generalized least squares, resulting in Eq. (10).(10)βˆ=(fT⋅R−1⋅f)−1⋅fT⋅R−1⋅fsIn KMs, some assessment strategies are required to check a priori if a generated model is adequate. They also provide guidelines for selecting the best surrogate when different options are constructed. The selection of the surrogate model in this paper is as in [12], which is based on results obtained considering two strategies: the Root Mean Square Error (RMSE); and the Predicted Error Sum of Squares (PRESS) [9].Particle swarm optimization (PSO) is a global, population-based and gradient-free search method. In its standard form, it is suitable for single-objective, unconstrained problems with real-valued variables. Nevertheless, adaptations can be made to handle multiple objectives, constraints, and discrete problems [17–25].The method was proposed by Kennedy and Eberhart [26], inspired by cooperative behavior observed in social animals. While finding the global optimum is not guaranteed, it is a global optimizer in the sense that it is able to escape poor local attractors, which is possible due to a parallel search carried out by a swarm of cooperative particles sharing individually acquired information. The method does not necessarily return optimal solutions, as no optimality condition is considered. Nonetheless, it is a robust, general-purpose search method able to cope with problems for which it was not specifically designed or tuned. The method can also be viewed as a generator of good initial guesses for efficient local optimizers [27,28]. For further reading, see [29–33].The ability of the PSO method to optimize stems from decentralized local interactions among a swarm of particles. Its overall behavior can be viewed as the overlap between each particle's individual behavior and the social behavior controlling the way individually acquired information is shared among particles [34]. The individual behavior is governed by Eq. (11):(11)xij(t)=xij(t−1)+ω⋅(xij(t−1)−xij(t−2))+iϕ⋅(pbij(t−1)−xij(t−1))+sϕ⋅(pbkj(t−1)−xij(t−1))wherexij(t)is the jth coordinate of the position of particle i at time-step t; iϕ and sϕ are the individual and social acceleration coefficients, respectively; ω is the inertia weight;pbij(t)is the jth coordinate of the best position found by particle i by time-step t; andpbkj(t)is the jth coordinate of the best position found by particle k, which is a neighbor of particle i, by time-step t. In classical formulations, neighbor k is the best-performing particle in the neighborhood of particle i, and the individual and social acceleration coefficients are as in Eq. (12):(12)iϕ=iw⋅U(0,1)=U(0,iw)sϕ=sw⋅U(0,1)=U(0,sw)0≤(ϕ=iϕ+sϕ)≤(aw=iw+sw)where iw and sw are the individuality and sociality weights; aw is the acceleration weight; and U(a,b) is a random number from a uniform distribution in [a,b].The settings of the coefficients in the trajectory recurrence relation greatly influence the behavior of the system. Pioneering work on the subject was carried out by Kennedy [35]; Ozcan et al. [36]; Clerc et al. [37]; Trelea [38]; and van den Bergh et al. [39]. More recently, Innocente et al. [40] studied the effect of the settings of ω and ϕ on the speed and form of convergence of a deterministic particle pulled by a stationary attractor (p). They propose a more general formulation aiming to control the degree of randomness in ϕ, where iϕ and sϕ are as in Eq. (13) (see also [33]):(13)iϕ=ι⋅[ϕmin+(ϕmax−ϕmin)⋅U(0,1)]sϕ=(1−ι)⋅[ϕmin+(ϕmax−ϕmin)⋅U(0,1)]ι∈[0,1)Within this framework, the classical formulation is given by ϕmin=0 and ι=0.5, whereas the popular Constricted Original PSO (COPSO) formulation of Clerc et al. [37] is as in Eq. (14):(14)ω=2⋅κaw−2+aw2−4⋅awifaw≥4κotherwiseκ∈(0,1);ϕmin=0;ϕmax=ω⋅aw;ι=0.5where the user typically sets aw close to but greater than 4, and κ close to but smaller than 1.Other authors focus on the development of automatic tuning of these coefficients. Thus, Nickabadi et al. [41] identify two situations for a particle during the search:1.The particle and the global best position are far from the optimum, and the particle's displacement sizes are low compared to its distance to the optimum.The global best position is close to the optimum and the particle's position is far from them.They argue that the first case requires high values of ω because the particle is exploring, whereas low values of ω are required in the second case because the particle is exploiting previously found promising regions. They propose using ω as an adaptive parameter to control the exploratory and exploitative behavior of the swarm.Leu et al. [42] propose two parameter automation strategies, one for ω and the other for the acceleration coefficients. Thus, ω and sw are updated adaptively using grey relational analysis with the best particle as reference, and iw=4−sw. The adaptive rules consist of linear functions of the grey relational grade between predefined bounds, where the higher the grade the lower the ω and the higher the sw. This is because higher grades imply higher similarity and hence exploitation; i.e. they argue that lower ω and higher sw for constant sw+iw are desirable during exploitation. Aiming to fix some weaknesses of the grey PSO, Leu et al. [43] propose using grey evolutionary analysis. In this case, the adaptation is based on an evolutionary factor computed using a modified version of the grey relational grade, where the distribution of particles at all previous time-steps is considered. In this approach, both ω and sw increase with the evolutionary factor, with the increase being nonlinear and iw=4−sw. Thus, they consider that ω should be increased during exploitation.Loosely speaking, a particle's individual behavior is controlled by the coefficients in its trajectory recurrence relation; i.e. ω, sw and iw in Eqs. (11) and (12), or ω, ϕmin, ϕmax and ι in Eqs. (11) and (13). In fact, it only depends on ω and ϕ, as shown later in Eq. (16).In turn, particles interact locally by exchanging individually acquired information. This exchange is indirect because a particle accesses information from the memories of neighboring particles without keeping this information in its own memory but having its trajectory influenced by it. This local exchange is controlled by a local sociometry that defines which memories the particle can access. Thus, a particle's social behavior materializes through the update of its social attractor (pbkin Eq. (11)), and also through the stochastically weighted average between its social and its individual attractors (pbk, pbi) to generate its overall attractor (pi):(15)pij(t)=iϕ⋅pbij(t)+sϕ⋅pbkj(t)iϕ+sϕ=iϕ⋅pbij(t)+sϕ⋅pbkj(t)ϕ.Thus, without loss of generality:(16)xij(t)=xij(t−1)+ω⋅(xij(t−1)−xij(t−2))+ϕ⋅(pij(t−1)−xij(t−1)).The social behavior of the swarm as a whole emerges from the individual behavior of every particle combined with their local interactions and with features defined at the global level such as the synchrony of the updates. The overall sociometry results from assembling all local sociometries. For further reading on the subject, refer to [30,44–49] and [33].Hence the convergence speed and the ability of PSO to escape poor suboptimal solutions are controlled by the convergence speed of each particle and by the speed at which information is spread throughout the swarm.In general, we refer to the function to be optimized, f(x), as the conflict function due to the original metaphor that individuals seek agreement by minimizing their conflicts in the space of beliefs [29,50]. The more general denomination of objective function may also be used indistinctively. Other popular names are fitness function, imported from evolutionary optimization, and cost function, imported from the minimization of cost curves in operations research. Similarly, x is the vector of objective variables, also referred to as problem variables, decision variables, or design variables.Constraints bound the regions of the search-space where solutions are admissible. Some optimization methods such as the simplex method or SQP are inherently constrained optimization methods in the sense that the constraint-handling is embedded in the search strategy. Conversely, there is nothing in the standard PSO algorithm that tells particles how to handle constraints. Hence some constraint-handling technique (CHT) must be incorporated for constrained problems.The constrained optimization problem is formulated as in Eq. (17) for convenience in PSO:(17)Minimizef(x)Subjecttogj(x)≤Tolineq;j=1,…,niabs(gj(x))≤Toleq;j=ni+1,…,ni+nemax(0,xi−ui)+max(0,−xi+li)≤0i=1,…,nwhere f(x) is the objective function; gj(x) is the jth constraint function; n is the dimensionality of the problem; ni is the number of inequality constraints; ne is the number of equality constraints; liand uiare the lower and upper bounds for the ith dimension (variable), respectively; Tolineq≥0 is the tolerance for inequality constraints violations; and Toleq>0 is the tolerance for equality constraints violations.A straightforward CHT is the penalization method, where infeasible solutions are penalized by increasing their objective function values and treating the problem as unconstrained. The general rule is that the amount of penalization be linked to the amount of constraint violation. Other CHTs consist of introducing adaptation in the penalization [51]; using augmented Lagrange multipliers [52]; considering the objective function values and the constraint violations separately [53]; or formulating constraints as additional objectives [20,21]. For a survey of CHTs, refer to [54].Not only can PSO be applied directly to optimization problems, but also to a wide range of industrial problems that can be posed as such. Examples of the latter are structural design [52]; scheduling [55]; engineering optimal design [51]; shortest path problems [18]; neural networks training [56,57]; data classification [58]; real-time moving object tracking [59]; reactive power dispatch [60]; software testing [61]; etc. For reviews of PSO applications, refer to [62,63] and [64].Given the strong multimodality resulting from the formulations of the WF management problem, a global optimization algorithm for real-valued variables would be appropriate to seek the management scheme that maximizes oil production. There is a plethora of global search methods available in the literature, among which some of the most popular and widely tested ones are Genetic Algorithms (GAs), evolution strategies (ESs), differential evolution (DE), and PSO. These and other nature-inspired global search methods have a number of settings that affect their behavior. Moreover, there are uncountable variants of each one of them, as well as hybridizations among them and also with classical local search methods. Therefore, it is not possible to identify a best problem-solver matching at the paradigm level. At most, a few specific variants with specific settings could be compared on a specific set of problems with specific characteristics and dimensionality. Clearly, this paper is not aimed at such comparisons.PSO and DE have gained increasing interest for a couple of decades, as numerous successful applications have been reported [62,64–66]. Swagatam et al. [65] provided an overview of these two algorithms, which they claim are currently gaining popularity for their greater accuracy, faster convergence speed and simplicity. In particular, many successful applications of PSO have been reported in which this algorithm has shown advantages over other nature-inspired algorithms, mainly due to its robustness, efficiency and simplicity [63,67–69]. Thus, while the use of other global search methods is certainly feasible, we propose the use of a PSO algorithm to search for a near-optimal solution to the multimodal WF management problem. It is not argued that it is the unquestionably best alternative, but simply that the method performs well on these kinds of problems, where a good candidate solution generally implies that there is a better one in its proximity.Swarm sizes in PSO commonly vary from 10 to 20 particles for simple problems, and from 20 to 100 for complex ones. It can be reported that under testing, no swarm size between 20 and 100 particles produced results that were clearly superior or inferior to any other value for a majority of the tested problems [70]. A swarm of 50 particles is used in this paper, the same as in [70].The speed and form of convergence of the proposed PSO search algorithm is controlled by the settings of the coefficients in Eqs. (11) and (13), combined with the topology of the neighborhood. Note that, as opposed to classical formulations, ϕmin≠0 is allowed in our formulations. The settings of these coefficients affect the way a particle searches around its attractor, having an influence on its convergence speed as well as on the amplitudes and frequencies in its trajectory oscillations.Typically, all particles are identical, having the same coefficients’ settings. We propose to divide the swarm in sub-swarms of particles displaying different individual behaviors; i.e. each sub-swarm has different settings of its coefficients. The aim is to complement their abilities to cope with a range of environments posing different difficulties, thus becoming more general-purpose. This strategy is supported by experiments in [33].Given that cooperation between less than 10–15 particles may not be sufficient for complex problems, we divide our swarm of 50 particles into three sub-swarms of 17, 16 and 17 particles, respectively. While Liang and Suganthan [71] used more and smaller sub-swarms, they implemented a re-grouping mechanism to re-introduce diversity and allow cooperation among sub-swarms. Blackwell and Branke [72] also proposed the use of sub-swarms, but with two different interaction mechanisms, namely a local interaction mechanism between colliding sub-swarms called exclusion, and an information sharing interaction mechanism called anti-convergence.For one sub-swarm, we use the popular Constricted Original PSO (COPSO), which introduces the Type 1″ constriction factor (χ) proposed in [37]. The coefficients’ settings are as recommended in [37]: κ=0.99994 (they actually recommend κ=1) and aw=4.1, which results in χ=0.7298 (see Eq. (14) and settings in [70] and [73]). Translating these settings into our formulation, ω=0.7298, ϕmin=0, ϕmax=2.9922, and ι=0.5. For the other two sub-swarms, we propose using the Behavior Type 1 and Behavior Type 2 formulations discussed in the next two sections. Recall that a particle i is in fact pulled by a single attractor pi(t), as shown in Eqs. (15) and (16).Here we study the average behavior (i.e. ϕ=ϕmean) of a particle pulled by a stationary attractor p. Hence the position variables can be expressed in vectorial form (boldface), and sub-index j in Eq. (16) can be dropped. Given that we are studying an individual particle, sub-index i in Eq. (16) can also be dropped.In line with our formulation in Eq. (13), the idea is to study the average individual behavior of a given particle between updates of its attractor (p), while stochasticity would be introduced as accumulative noise for each dimension independently (not analyzed here).The aim is to find a relationship between ω and ϕmean to cancel the momentum once the particle has overflown the attractor. That is, if the particle overflies the attractor from time-step (t−1) to time-step t, then x(t+1)=x(t) so that the particle does not keep flying away from p in the next time-step. While it is not desirable in a deterministic algorithm to re-evaluate the same position, randomness would ensure that x(t+1)≠x(t). Thus, when the attractor is updated at (t−1), the conditions imposed for the mean behavior are offered in Eq. (18), where it is assumed that x(t−1)=x(t−2) while ϕmean>1 ensures that the particle overflies the attractor from (t−1) to t.(18)x(t)=x(t−1)+ϕmean⋅(p−x(t−1))x(t+1)=x(t)ϕmean>1Since this analysis is between updates of p, it is reasonable to assume that x(t−1)=x(t−2) when an update takes place at time-step (t−1), and therefore the particle does not have an initial momentum. This means that the particle converged to its previous attractor by the time a new attractor is found at (t−1), starting its oscillatory trajectory towards it with x(t−1)=x(t−2). Even if the particle did not converge to its previous attractor, it is reasonable to assume that its momentum would be small for convergent settings of (ω,ϕmean) (hence x(t−1)≈x(t−2)). Thus, after some arithmetic manipulations of Eq. (18):(19)x(t+1)−x(t)=ω⋅(x(t)−x(t−1))+ϕmean⋅(p−x(t))=0ω⋅(p−x(t−1))=−p+x(t)Operating with x(t) in Eqs. (18) and (19), we obtain:(20)ω=ϕmean−1Thus, starting from an update of the attractor at t=1 with x(1)=x(0) (no momentum) and setting ω∈(0,1) and ϕmean such that Eq. (20) holds, the average behavior of the particle consists of overflying the attractor at t=2, losing its momentum thus maintaining its position at t=3, overflying the attractor again at t=4, losing its momentum again and maintaining its position at t=5, etc. Since the condition imposed for x(t+1) in Eq. (18) is the same as the no momentum assumption at the beginning of the analysis (x(t−1)=x(t−2)), this pattern repeats until the particle converges.An interesting case can be observed by extending the behavior to ϕmean=1 and hence ω=0, thus removing the assumption of ϕmean>1: the particle converges in a single time-step. In turn, by extending the behavior to ϕmean<1 and ω∈(−1,0), the particle still maintains its previous position every other time-step, but converges monotonically (i.e. the attractor is not overflown).The convergence conditions for the deterministic trajectory of a particle are [33,34,40]:(1)ω<1ϕ>0ϕ<2·(ω+1)All settings of (ω,ϕ) which satisfy these conditions result in convergent deterministic trajectories. The (ω,ϕ) pairs which satisfy ω∈[0,1] and Eq. (20) are shown in a red dotted line in Fig. 1(top), where the region inside the black dotted parabola is the so-called complex region where the roots of the characteristic polynomial of the recurrence relation are complex. Within this region, the convergence speed of a particle's deterministic trajectory is proportional to ω0.5[33,40]. As can be observed, the segment line of the (ω,ϕ) pairs satisfying ω∈(0,1) and Eq. (20) is within convergent complex region.We define the PSO-RRR1 (with RRR standing for Reduced Randomness Range) as a formulation which displays Behavior Type 1 and introduces stochasticity by defining ϕmin as the average between ϕmean and the left convergence boundary, and ϕmax as the average between ϕmean and the right convergence boundary, as in Eq. (21).(21)ϕmean=ω+1ϕmin=12⋅(ω+1)ϕmax=32⋅(ω+1)As can be observed in Fig. 1 (top), the whole range of ϕ is within complex region for ω>0.072.The deterministic trajectories corresponding to a set of settings with ω∈[0,1] and ϕ as in Eq. (20) in one dimensional space are shown in Fig. 2(center column), where x(0)=100 and p=0.Similar to the previous analysis, the aim now is to reach the attractor (p) in two time-steps from the moment the attractor is updated at time-step (t−1), also starting from stagnation (i.e. x(t−1)=x(t−2)).(22)p−x(t−1)=dx(t+1)−x(t−1)=d(23)x(t)=x(t−1)+ϕ⋅(p−x(t−1))=x(t−1)+ϕ⋅d(24)x(t+1)=x(t)+ω⋅(x(t)−x(t−1))+ϕ⋅(p−x(t))From (23) and (24),(25)x(t+1)=x(t−1)+ϕ⋅d+ω⋅ϕ⋅d+ϕ⋅(p−x(t−1)−ϕ⋅d)(26)ω=1ϕ−2+ϕϕ=2+ω±(2+ω)2−42The (ω,ϕ) pairs which satisfy ω∈[0,1] and Eq. (26) with the positive square root (ϕ≥1) are shown in a red dotted line in Fig. 1 (bottom). As can be observed, the segment line of the (ω,ϕ) pairs satisfying ω∈(0,1) and Eq. (26) is within convergent complex region.We define the PSO-RRR2 as a formulation which displays Behavior Type 2 on the right branch, and introduces stochasticity by defining ϕmax on the right boundary of the convergence region and ϕmin accordingly. Thus, PSO-RRR2 is defined as in Eq. (27).(27)ϕmean=2+ω+(2+ω)2−42ϕmax=2⋅(ω+1)ϕmin=2⋅ϕmean−ϕmaxAs shown in Fig. 1 (bottom), the whole range of ϕ is not kept within complex region for PSO-RRR2.The deterministic trajectories corresponding to a set of settings with ω∈[0,1] and ϕ as in Eq. (26) in one dimensional space are shown in Fig. 2 (left and right columns), where x(0)=100 and p=0. Trajectories on the left column are for ϕ∈(0,1] (left branch) whereas the ones on the right column are for ϕ≥1 (right branch). Trajectories on the same row display the same convergence speed [33]. Recall that PSO-RRR2 requires ϕmean>1 (right column only).As opposed to Behavior Type 1, the condition imposed for x(t+1) in Eq. (22) (x(t+1)=p) is unrelated to the no momentum assumption at the beginning of the analysis (x(t−1)=x(t−2)). Hence the pattern of having no momentum at time-step t and reaching the attractor at time-step (t+2) does not repeat. Thus, starting from an update of the attractor at t=1 with x(1)=x(0), ω∈(0,1) and ϕmean such that Eq. (26) holds, the average behavior of the particle consists of reaching the attractor at t=3, with the momentum taking it away from p at t=4. From then on, the particle converges in a pattern unpredicted by this analysis, with high frequencies (ϕmean>1).Trajectories resulting from Behavior Type 1 and Behavior Type 2 can be compared by observing the trajectories on the same row in the center and right columns in Fig. 2, which share the same convergence speed. Note that both behavior types converge on (ω,ϕ)=(0,1), which results in maximum convergence speed.Thus, our optimizer uses three sub-swarms:(1)PSO-RRR2 formulation, with ω=0.8167.PSO-RRR1 formulation, with ω=0.80.COPSO formulation, with (ω,ϕmax)=(0.7298, 2.9922).The first sub-swarm displays the highest frequency and the largest amplitudes in the oscillations, a medium range of variation of ϕ (ϕmax−ϕmin=2.4667) and it is the only one whose ϕ can reach the right boundary of the convergence region. The second sub-swarm displays medium range frequency in the oscillations, and the lowest range of variation of ϕ (ϕmax−ϕmin=1.8). In turn, the third sub-swarm displays the lowest frequency in the oscillations (even though it has the lowest ω) and has the largest range of variation of ϕ (ϕmax−ϕmin=2.9922).These sub-swarms are independent from one another, interacting only by means of an information sharing mechanism different from those in [71] and [72], which is discussed in the next section.A so-called forward topology is proposed, which shares important characteristics with the classic ring topology. Namely, it allows any number of neighbors (nn) from 0 (no cooperation) to (swarm-size−1) (full cooperation), and the graph that represents it is connected for any nn>0. The difference between the ring and the forward topologies is that interconnections are not bidirectional in the latter, so that a particle is not generally informed by the same particles it informs.A graphical comparison between the ring and the forward topologies is offered in Fig. 3for six particles and two neighbors. Notice that the number of edges in the graphs that need to be traversed to go from a given node to its farthest node are the same in both cases. For instance, the farthest node for node 1 in Fig. 3 is node 4 for the ring topology (traversing nodes 2 and 3) and node 6 for the forward topology (traversing nodes 3 and 5). The reverse is only true for the ring topology: the farthest node for node 4 is node 1 for the ring topology, whereas the one for node 6 in the forward topology is not node 1 – which is actually the closest – but node 5.In our proposed optimizer, an independent forward topology is used within each of the three sub-swarms, where the number of neighbors is time-increasing linearly from one at the first time-step (i.e. the neighborhood of a particle is composed of one neighbor plus the particle itself) until it becomes global when the search reaches the maximum number of time-steps permitted (tmax).The interaction between these three forward topologies takes place by extending the local sociometry of the first particle in each sub-swarm through their access to the individual memory of the other two.The use of the forward topology with linearly time-increasing connectivity and of this so-called individual overlapping for the interaction between sub-swarms is supported by experimental results in [33].Some of the formulations for the WF management problem involve constraints. Therefore, a novel, adaptive CHT is developed and integrated into the optimizer.We make use here of a preserving feasibility with priority rules (PFPR) technique, which consists of rules to decide, whenever two candidate solutions are compared, which one is better. The rules are as follows:(1)If they are both feasible, the one with the lowest objective function value is better.If they are both infeasible, the one with the lowest constraints violation (CV) is better.If one is feasible and the other infeasible, the feasible one is always better.If they are both infeasible with the same amount of constraint violation (CV), the one with the lowest objective function value is better.Similar CHTs have been proposed in the literature [19,53,74,75]. Takahama et al. [19] relaxed these priority rules by means of a control parameter in the comparisons (the so-called ɛ-level comparisons).The PFPR technique has the advantage that an initial feasible swarm is not required and that the objective function is seldom evaluated for infeasible particles. However, when searching highly constrained spaces, most of the search is driven by constraint satisfaction, disregarding the conflict function information. Thus, by the time a particle finds a feasible location, it might be anywhere with respect to the optimum.Since the use of a tolerance for equality CVs in PSO is a must, it is common practice to relax this tolerance at the beginning and decrease it as the search progresses. Usually, the tolerance is relaxed to an arbitrary initial value, and then deterministically decreased. The aim is to temporarily expand the feasible region of the search-space to relax the priority rules in a similar fashion as the ɛ-level comparisons do. However, the impact of a given relaxation on the feasibility ratio (FR) of the search-space is problem-dependent, and can vary greatly. For instance, to obtain a FR∈[0.20,0.25], a tolerance for equality CVs of around 0.26 is required for problem g11 in [33,53,76], whereas a tolerance of around 6.63 is required for problem g13 (both with equality constraints only). Since there are problems involving only inequality constraints which present small FRs, the same concept can be applied. That is, the tolerance for their violations can also be relaxed. Thus, the tolerance required for problem g10 in [33,53,76] to present a FR∈[0.20,0.25] is around 10.83 whereas it is around 2790 for problem g06 (both with inequality constraints only).Therefore, initial self-tuned tolerance relaxations are proposed aiming for a target FR. Here, we arbitrarily set target FR∈[0.20,0.25]. Thus, the self-tuning procedure consists of starting with small, minimum values for the tolerances (0.01 for inequality and 0.1 for equality constraints), and evaluating the constraint functions on 1000 randomly selected positions. The FR is calculated, and the tolerances are adequately increased or decreased. More precisely, if the resulting FR<0.20, the tolerances are increased by a factor for 10 whereas, if the resulting FR>0.25, a bisection search is triggered to find the minimum tolerances which satisfy FR∈[0.20,0.25]. For problems with FRs>0.25, target FR∈[(1.1·FR),(1.1·FR+0.05)], with the obvious limit of 1.The aim is to make the tolerance update adaptive so that updates are performed when they would have a less disruptive effect on the dynamics of the swarm and on maintaining potentially good solutions. Thus, updates are performed when a given minimum percentage (ptgmin) of the particles’ best experiences (pb) are located within feasible space for current tolerances. The coefficient for the exponential update (ktol(t)) is also adaptive, as shown in Eq. (28), while the exponential update of the tolerances is as posed in Eq. (29).(28)ktol(t)=0.99−ktolmin100−ptgmin⋅(100−ptg)+ktolmin(29)Tol(t)=ktol(t)⋅Tol(t−1)Thus, ktol(t)=0.99 for ptg=ptgmin, ktol(t)=ktolmin for ptg=100, with linear variation in between. Therefore, the greater the percentage above a minimum established, the greater the size of the tolerance decrease.Aiming to avoid too many time-steps without a tolerance update, a safety mechanism is implemented by enforcing an update if:(30)tntu≥Δtwhere t is the current time-step, ntu is the number of tolerances updates, and Δt is the maximum permitted average number of time-steps between tolerance updates. When an update is enforced by Eq. (30), the coefficient used in Eq. (29) is ktol(t)=0.99 (i.e. ktolmax).In order to give some time for the particles to find feasible solutions once the tolerances have reached their desired values, it is arbitrarily set that such values must be reached by the time 80% of the maximum search-length (tmax) has elapsed. If the desired tolerances are not reached adaptively by the time 72% of tmax has elapsed, a tolerance update is enforced at every time-step so that the desired values are attained at t=(0.80·tmax). Hence ktol is calculated as in Eqs. (31) and (32), and is kept constant for the remaining (0.08·tmax) time-steps.(31)ktol0.08⋅tmax⋅Tol(0.72⋅tmax)=Tol(0.8⋅tmax)=Toldesired(32)ktol=ToldesiredTol0.72⋅tmax1/0.08⋅tmaxwhere ktol is calculated independently for inequality and equality constraints.For inequality CVs, Toldesiredis typically set to 0. Since this cannot be reached by exponential updates, we set Toldesired=10−5 for the calculation of ktol in Eq. (32), re-setting the tolerance to 0 as soon as it reaches a value equal to or below 10−5 in Eq. (29).The proposed adaptive scheme is coupled with the PFPR technique, which is especially useful in problems with low FRs. By means of the adaptive scheme, the PFPR technique is fooled into using objective function information while searching infeasible space.Thus, the proposed adaptive CHT consists of self-tuning initial tolerance relaxations, and then decreasing these tolerances adaptively while using the PFPR technique to compare particles’ performances within current tolerances. Note that the word pseudo is used in [33] because there are still a few parameters to be set. Nonetheless, the scheme may be viewed as adaptive by fixing these parameters to general-purpose values, as it has been done in this paper.Bear in mind that only problems with side and inequality constraints are considered in this paper. The benefits of this technique are more evident when equality constraints are also present [33].Termination conditions are important for a general-purpose optimizer because they allow setting a high tmax without resulting in unnecessarily large search-lengths for simple problems. Due to its population-based nature, PSO does not lend itself to traditional termination conditions used for single-solution methods. We propose some measures that can be used to infer convergence or stagnation in PSO, dividing them in two groups:(1)Clustering measures: within a single time-step.Evolution measures: between time-steps.In addition, these measures can be computed in terms of the positions in the search-space (preceded by pb_ for position-based) or in terms of the values of the conflict function (preceded by cb_, for conflict-based). They can also be computed in terms of the information currently held by the particles or in terms of their memorized information. Here we use the latter.Two clustering measures are offered in Eqs. (33) and (34) and four evolution measures are offered in Eqs. (35)–(38), where n is the number of dimensions; m is the swarm-size; x is a particle's position; gb is the global best position; cg is the center of gravity of the swarm;c¯is the average conflict in the swarm; cgb is the conflict of the global best position in the swarm; (xjmax−xjmin) is the jth feasible interval; t is the current time-step; and tref is a number of time-steps over which these measures are averaged to smooth their oscillations (see also [33]).For further reading on termination conditions in PSO, refer to [63].(33)pb_me(t)=∑i=t−tref+1t∑j=1n∑k=1m(xkj(i)−gbj(i))2m⋅(xjmax−xjmin)2tref⋅n(34)pb_cge(t)=∑i=t−tref+1t∑j=1ncgj(i)−gbj(i)xjmax−xjmin2tref⋅n(35)cb_av(t)=∑i=t−tref+1tabsc¯(i)−c¯(i−1)tref(36)cb_b(t)=(cgb(t−tref)−cgb(t))tref(37)pb_cg(t)=∑i=t−tref+1t∑j=1ncgj(i)−cgj(i−1)xjmax−xjmin2tref⋅n(38)pb_gb(t)=∑i=t−tref+1t∑j=1ngbj(i)−gbj(i−1)xjmax−xjmin2tref⋅nAt the beginning of Section 5, we argued that nature-inspired global search methods would be appropriate to seek the optimum management scheme in the strongly multimodal waterflooding (WF) problem, and proposed the use of a PSO algorithm. The details of the algorithm were presented in detail in the remainder of the section.In addition to their ability to cope with multimodal problems, another advantage of nature-inspired methods in general and of PSO in particular is that the functions involved do not need to be differentiable, continuous, or even explicit. All that is needed is a way to evaluate the relative goodness of the potential solutions. If this cannot be achieved by the evaluation of an analytical function, it may be achieved by means of computational simulations, approximators, response surfaces, or even experiments.The functions involved in the WF reservoir problem formulation in Section 2 cannot be evaluated analytically. Therefore, a computational simulation is required, for which we have a commercial High-Fidelity (HF) reservoir simulator available [11]. However, every HF simulation requires a high computational effort. For instance, one single simulation using an i7-3.4GHz processor takes over a minute for Reservoir 1 in Section 7.1; over 2min for Reservoir 2 in Section 7.2; while it could take several hours and even days for more complex reservoirs. This presents a problem for a population-based method like PSO, which typically requires a high number of function calls. Therefore, we propose the use of a remarkably cheaper Kriging surrogate model in place of the HF simulator. This model is trained offline using a much smaller number of simulations than would be required for the direct simulation-based optimization.Thus, the proposed integrated tool (PIT) consists of the integration of a commercial HF simulator; a Kriging surrogate model; a DoE technique to train the model offline; and a general-purpose PSO algorithm coupled with an adaptive CHT and termination conditions. A high-level description of the PIT is offered in Fig. 4, where the green text boxes describe modeling modules whereas the red text boxes describe solver modules. The flowchart in Fig. 4 may be described as follows:1.Generate a number of sampling points using LCVT DoE technique.Perform High Fidelity (HF) reservoir simulations on sampling points (IMEX).Train Kriging model (KM) using responses obtained from HF simulations.Search for global optimum of static KM with particle swarm algorithm (PSA) coupled with adaptive CHT (no additional HF simulation).Validate results by evaluating trained KM on the coordinates of the best known solution, and also by performing an additional HF simulation on the coordinates of the best result returned by the PSA.The PIT is applied hereafter to two oil reservoir case studies. The features and settings of the PSA used are as described below, which are supported by experiments carried out on sets of benchmark problems in [33]:•The termination conditions are, either the maximum number of time-steps permitted for the search (tmax) is reached, or the minimum number of time-steps permitted (tmin) is reached and the measures of clustering and evolution reach a maximum value that allows inferring convergence or stagnation. Refer to Section 5.3 and Eqs. (33)–(38) for more details. The settings are as follows:1.Maximum search length tmax=10,000.Minimum search length tmin=500.Termination values for clustering measures: pb_me=pb_cge=10−3.Termination values for evolution measures: cb_av=cb_b=10−6; pb_cg=pb_gb=10−3.tref=10.A swarm of 50 particles is used, split in three sub-swarms. The first sub-swarm is composed of 17 particles governed by PSO-RRR2 formulation with ω=0.8167; the second one is composed of 16 particles governed by PSO-RRR1 formulation with ω=0.80; and the third one is composed of 17 particles governed by COPSO formulation with settings equivalent to ϕmin=0 and (ω,ϕmax)=(0.7298, 2.9922). For all sub-swarms, ι=0.50. Refer to Section 5.1 for further details.An independent forward topology is implemented for each sub-swarm, sharing information among them by means of an individual overlapping. The number of neighbors in each sub-swarm is time-increasing linearly from 1 at the first time-step until it becomes global at t=tmax. Refer to Section 5.1.3 for further details.Particles’ positions are initialized by generating 1000 independent Latin Hypercube Samplings and selecting the one with the maximum minimum distance between particles. Each sub-swarm is initialized independently, and particles are initialized from stagnation. Every best experience (pb) is initialized at the same distance from its corresponding particle (x). Each component of this distance is calculated as the corresponding feasible interval divided by twice the number of particles in the swarm. The sign of the component and hence the direction of the distance vector are randomly generated. For each (x,pb) pair, a comparison is performed so that the best one becomes or stays pb and the other one becomes or stays x before the search begins. Thus, every particle starts the search with the same, moderate acceleration towards its best individual experience (pb).25 runs are performed for each problem.Constraints are handled by the PFPR technique coupled with the adaptive scheme proposed in Section 5.2, where target FR∈[0.2,0.25]. For problems with FR>0.25, target FR∈[(1.1·FR),(1.1·FR+0.05)], with the obvious limit of 1. For problems with side constraints only, the latter are handled by the plain PFPR technique.Note that no tuning is carried out in this paper. While even better results on some problems are likely possible for problem-specific parameter-tuning, the aim behind choosing a PSA with general-purpose settings, sub-swarms with complementary behavior, and an adaptive CHT is to unburden the user of the hassle of performing costly and complex numerical trial-and-error testing and tuning on a case-by-case basis. Instead, the optimizer is run with settings that may be viewed as default. Thus, all problems hereafter are optimized using the same settings. The ultimate goal is to design a fully adaptive tool. Meanwhile, our PIT (see Fig. 4) trains the KM offline, uses general-purpose settings for the search algorithm and an adaptive CHT.Furthermore, note that this PSA, with these settings, has also been tested on several benchmarking problems in [33], including the five unconstrained functions in [38], each with 2, 10 and 30 dimensions; the 13 constrained functions in [53]; the test suite of engineering problems in [77]; and the well-known 10-bar plane truss and 25-bar space truss design problems.We also include results obtained optimizing the same KMs by the proposed PSA but without tolerance relation as well as by three commercial optimizers from the Matlab 2014a Optimization and Global Optimization Toolboxes, namely the local optimizer SQP and the global optimizers GlobalSearch (using Multi-Start SQP) and Genetic Algorithm (GA). While the aim is not to compare optimizers’ performances, these values can be used as frames of reference to assess the benefits of the tolerance relaxation, the benefits of a global search, and also the accuracy of the proposed PSA with adaptive CHT irrespective of the accuracy of the KMs. In our experiments, the initial guess for SQP and Multi-Start SQP is in the middle of the bounding box defined by the feasible intervals, while the Multi-Start SQP considers 1000 potential initial guesses. For the GA, the population-size is set to 200 and tmax=2500 so that the maximum number of objective function evaluations (FEs) permitted is the same one used for the proposed optimizer. All remaining settings are kept as default.Bear in mind that t stands for time-step in the optimization context whereas it stands for control cycle in the reservoir simulation context.The first reservoir has one injection and two production wells, as illustrated in Fig. 5(from [78]). The reservoir has an area of 510m×510m with a thickness of 4m, which is modeled with a mesh of 51×51×1. The main characteristics of the reservoir are given in Table 2.The arrangement of the injection and production wells and their regions are defined according to the horizontal permeability in the reservoir, as can be observed in Fig. 5. The horizontal permeability (kh) in the injection well (I−1) region equals 1000mD; khnear the production well P−1 equals 500mD; whereas khnear the production well P−2 is equal to 1500mD.For this problem, Ql,max equals 40m3/day, and the individual flow cannot exceed 30m3/day. The Qinj,max equals 44m3/day. The rate at the injector is kept fixed whereas the rates at producers are variable during the optimization process. This leads to the following side constraints at producers (P) and at each control cycle (t): 0.25≤xp,t≤0.75. The total concession period considered is 16 years, and the oil price adopted is $25.00/m3. Other values used in the NPV calculations are: discount rate d=0.09; cost of water injection=$2.00/m3; and cost of water production=$5.00/m3.As discussed in Section 2 (see also Table 1), four cases are analyzed here according to the operational conditions and types of design variables:•Case 1: FCO-FT considering different numbers of control cycles (side constrained problem).Case 2: NFCO-FT considering three control cycles.Case 3: FCO-VT considering five control cycles.Case 4: NFCO-VT considering three control cycles.According to [2], inequality constraints are present in this problem for NFCO and/or VT operational conditions. The NFCO condition introduces (3·nt) inequalities whereas the VT condition introduces one inequality. Some statistics of the NPVs returned by our proposed integrated tool (PIT) for each of these cases and sub-cases are shown in Tables 3–5.Table 3 also shows the mean search length, the self-tuned initial relaxation of the tolerance and the resulting estimated FR within that tolerance, as well as problems’ features such as the estimated FR, dimensionality (n), number of inequality (ni) and number of equality (ne) constraints. FRs are estimated by randomly generating 106 sampling points, checking their feasibility, and computing the ratio of the number of feasible over the number of infeasible generated points.Table 4 also shows the best known solution for each problem using a sequential approximate optimization (SAO) procedure equipped with a SQP local optimizer and a trust region (TR) based method for the update of the search-space for each local solution [79]. It also includes the results of the High-Fidelity (HF) evaluations of the coordinates of the best results returned by our PIT, and the results of the evaluation of the KMs on the coordinates of the best known solutions. These last two pieces of information are helpful to evaluate the accuracy of the KMs in the vicinity of the best known solutions and in the vicinity of the best results found by the proposed optimizer. A comparison between the best known solutions and the results returned by our PIT enables the assessment of its accuracy as a whole.Table 5 also shows statistics of NPVs returned by our proposed PSA but without tolerance relation as well as by local optimizer SQP and global optimizers Multi-Start SQP and GA on the same KMs.Three problems with side constraints only and different dimensionalities are considered here, where the number of control cycles equals the number of design variables (n). In order to observe the influence on the NPV response, n=2, n=12 and n=24 design variables are considered. Each design variable represents the rates at producer P1 at one production cycle.The first step is to train the KM, for which 10 sampling points are used per design variable. Thus, 20, 120 and 240 HF simulations are performed, respectively.This problem with n=2, n=12, and n=24 is referred to as Problem 1, Problem 5, and Problem 6, respectively, in Tables 3–5. The control cycles are shown in Fig. 6.These problems have side constraints only, and not even dimensionality seems to pose any difficulty for our PSA. As shown in Tables 3 and 4, every run converged to the same result, and did so very quickly. In fact, the termination condition t≥tmin prevented the search from terminating before 500 time-steps have elapsed for Problem 1 (n=2) and for Problem 5 (n=12), whilst the search was terminated after 647 time-steps have elapsed, on average, for Problem 6 (n=24).As shown in Table 5, all global search algorithms converged to this same NPV in all 25 runs, displaying very small sample standard deviations (smallest for Multi-Start SQP and largest for GA). Note that, since there are no constraints other than side constraints, our proposed PSA with and without tolerance relaxation are the same. Results also show that the very efficient local optimizer SQP falls short on these problems.As shown in Table 4, the best known solutions of these problems are very similar to the best results obtained by our PIT, only differing in 0.01%, 0.15% and 0.07% of the best known solutions.An accuracy check was performed by evaluating the HF simulator on the coordinates of the best results found by our PIT, resulting in errors of our KMs of 0.03% of the HF simulation for Problem 1 (n=2); 0.23% for Problem 5 (n=12); and 0.07% for Problem 6 (n=24). Another accuracy check was carried out by evaluating the KMs on the coordinates of the best known solutions, resulting in errors of our KMs of 0.00% of the best known solution for Problem 1 (n=2); 0.29% for Problem 5 (n=12); and 0.13% for Problem 6 (n=24) (see Table 4).In order to study the impact of more flexible management schedules, we investigate in this section the case of a non-full capacity operation (NFCO) of the problem discussed in the previous section (see Table 1). The control cycles considered are shown in Fig. 7with fixed switching times (FT). Since the rates at all three wells are variable, and the number of control cycles equals 3 (nt=3), this problem presents a total of nine design variables (n=3·nt=9) and nine inequality constraints (ni=3·nt=9) (see Table 3). This problem is referred to as Problem 3 in Tables 3–5.As in the previous cases, 10 sampling points are used per design variable to train the KM, leading to 90 HF simulations.While there is no equality constraint, the problem is still highly constrained with an estimated FR=0.0087%, as shown in Table 3. After the relaxation of the tolerance to 0.4215, the resulting estimated FR=22.75%, which is within the range specified in the settings (20–25%).This problem is noticeably harder than those in the previous section. Nevertheless, as shown in Tables 3 and 4, our optimizer obtains good results consistently: the best NPV found in 25 runs equals 1.7151; the median NPV equals 1.7145; the mean NPV equals 1.7137; and the worst NPV equals 1.6985; with a sample standard deviation (σs) of 0.003. The maximum search-length permitted was reached in every run. Nevertheless, the mean convergence curve is reasonably flat by the end of the search, as shown in Fig. 8(left).Further analysis on the data extracted from the search (not presented for brevity) shows that the difference in coordinates between the best and the median results is minor in every dimension, and therefore they are in the same region of the search-space. In fact, the maximum and average absolute differences between corresponding coordinates of the best and of the median results returned equal 6.14% and 2.45% of the corresponding feasible interval, respectively. Hence it can be inferred that the difference is in fine-tuning. Only in 1 out of 25 runs is the result in a different region of the search-space.As shown in Table 5, the Multi-Start SQP converged to the same NPV, namely 1.7151, in all 25 runs. Our PSA with and without tolerance relaxation is able to find this NPV in some but not all runs, where the one with the tolerance relaxation exhibits better performance in terms of median, mean and σs. In turn, the GA exhibits worse performance whereas the result returned but the efficient SQP is very poor. Thus, results in Table 5 show that our proposed optimizer obtains good results, being the second best among the ones compared on this KM. They also show that a global search is necessary, and that the tolerance relaxation is beneficial.As shown in Table 4, the best known solution of this problem (1.7240) is very similar to the best result returned by our PIT (1.7151), only differing in 0.52% of the best known solution. Comparing this (NFCO-FT) to the FCO-FT operational conditions, it can be concluded that the former improves the NPV with fewer control cycles and fewer design variables.An accuracy check was performed by evaluating the HF simulator on the coordinates of the best result found by our PIT, resulting in an error of our KM of 7.53% of the HF simulation. Another accuracy check was carried out by evaluating the KM on the coordinates of the best known solution, resulting in an error of our KM of 6.09% of the best known solution (see Table 4).In this problem, the switching times for the control cycles are included as design variables for the FCO condition (FCO-VT in Table 1). Five control cycles are chosen, leading to a problem with nine design variables (n=9) and one inequality constraint (ni=1), the latter due to the VT condition (see Table 3). This problem is referred to as Problem 2 in Tables 3–5.As before, 10 sampling points are used per design variable to train the KM, leading to 90 HF simulations.This problem presents a high FR=79.85%, as shown in Table 3. While this is already notably higher than the target FR of 20–25%, the automatic self-tuning mechanism of the CHT relaxes the tolerance to 0.0927, which results in an estimated FR=89.18%. This relaxation is especially useful in cases where the solution lies on or near the boundaries of the feasible region.For this problem, our optimizer obtains the same NPV in every run (1.5167), for which it requires 2739 time-steps on average (see Tables 3 and 4).As shown in Table 5, our proposed optimizer and the Multi-Start SQP converged to the same NPV, namely 1.5167, in all 25 runs. The best and the median of the NPVs obtained by the PSA without tolerance relaxation and also by the GA are also equal to 1.5167, but they fail to achieve this value in some runs. Among these last two algorithms, GA exhibits marginally worse performance in terms of the mean and σs. Once again, the NPV returned but the efficient SQP is the worst one. Thus, results in Table 5 show that our proposed optimizer and the Multi-Start SQP achieve the best results on this KM. They also show that a global search is necessary, and that the tolerance relaxation is beneficial here as well.As shown in Table 4, the best known solution of this problem (1.4936) is similar to the best result returned by our PIT (1.5167), only differing in 1.55% of the best known solution. Comparing this solution (FCO-VT) to those obtained with FCO-FT, it can be concluded that this operational condition marginally improves the NPV.An accuracy check was performed by evaluating the HF simulator on the coordinates of the best result found by our PIT, resulting in an error of our KM of 2.02% of the HF simulation. Another accuracy check was carried out by evaluating the KM on the coordinates of the best known solution, resulting in an error of our KM of 0.76% of the best known solution (see Table 4).This is the most generic formulation defined in Section 2 (see Table 1), resulting in the most flexible reservoir management process. Thus, three control cycles and NFCO-VT operational condition are chosen, leading to a problem with 11 design variables (n=11) and 10 inequality constraints (ni=10). As in Case 2 in Section 7.1.2, the number of inequality constraints due to NFCO with three control cycles equals 9, whilst the VT condition introduces one additional inequality constraint as in Case 3 in Section 7.1.3. This problem is referred to as Problem 4 in Tables 3–5.As before, 10 sampling points are used per design variable to train the KM, leading to 110 HF simulations.While there is no equality constraint, this problem is still highly constrained with an estimated FR=0.008%, as shown in Table 3. After the relaxation of the tolerance to 0.4223, the resulting estimated FR=22.84%, which is within the range specified in the settings (20–25%).For this problem, our optimizer is able to obtain very good results consistently (see Tables 3 and 4), converging to the best NPV in 23 out of 25 runs. Thus, both the best and the median NPVs equal 1.7216; the mean NPV equals 1.7160; and the worst NPV equals 1.6521; with σs=0.019 and an average search-length of 9847 time-steps. All 10,000 time-steps permitted for the search were used up in 24 out of 25 runs. Nevertheless, the mean convergence curve is reasonably flat by the end of the search, as shown in Fig. 8 (right).As shown in Table 5, the Multi-Start SQP converged to the same NPV, namely 1.7216, in all 25 runs. Our proposed optimizer converged to the same NPV in 23 out of 25 runs. In turn, the PSA without tolerance relaxation obtained good results, though not quite as good, whereas the GA was able to achieve considerable worse performance in this case. Strangely enough, the result returned but the efficient SQP is spot on this time. Thus, results in Table 5 show that our proposed optimizer obtains very good results on this KM, almost as good as those obtained by the Multi-Start SQP and by the efficient plain SQP. They also show that the tolerance relaxation is beneficial.As shown in Table 4, the best known solution of this problem (1.7259) is very similar to the best result returned by our PIT (1.7216), only differing in 0.25% of the best known solution. Comparing these results against those obtained with the other operational conditions, this operational condition results in the best optimized NPV, which is achieved considering three control cycles only.An accuracy check was performed by evaluating the HF simulator on the coordinates of the best result found by our PIT, resulting in an error of our KM of 0.68% of the HF simulation. Another accuracy check was carried out by evaluating the KM on the coordinates of the best known solution, resulting in an error of our KM of 12.97% of the best known solution (see Table 4).The second reservoir investigated here is the more realistic, medium-sized reservoir shown in Fig. 9. This case was taken from [78], and is a synthetic form based on the Brush Canyon Outcrop data [80]. It has twelve wells, seven producers and five injectors. The numerical model consists of a grid of 43×55×6 blocks, whose main characteristics are shown in Table 6. According to [2], the FCO condition in this reservoir results in 4·ntinequality constraints (ni=4·nt). The same as in Reservoir 1, the NFCO condition introduces (3·nt) inequalities, whilst the VT condition introduces one more.Thus, three problems are analyzed hereafter with two operational conditions: FCO-FT and NFCO-VT. Some statistics of the NPVs returned by our PIT for these problems are shown in Tables 7–9.Table 7 also shows the mean search length, the self-tuned initial relaxation of the tolerance and the resulting estimated FR within that tolerance, as well as problems’ features such as the estimated FR, dimensionality (n), number of inequality (ni) and number of equality (ne) constraints. FRs are estimated by randomly generating 106 sampling points, checking their feasibility, and computing the ratio of the number of feasible over the number of infeasible generated points.Table 8 also shows the best known solution for each problem using a sequential approximate optimization (SAO) procedure equipped with a SQP local optimizer and a trust region (TR) based method for the update of the search-space for each local solution [79]. It also includes the results of the HF evaluations of the coordinates of the best results returned by our PIT, and the results of the evaluation of the KMs on the coordinates of the best known solutions. These last two pieces of information are helpful to evaluate the accuracy of the KMs in the vicinity of the best known solutions and in the vicinity of the best results found by the proposed optimizer. A comparison between the best known solutions and the results returned by our PIT enables the assessment of its accuracy as a whole.Table 9 also shows statistics of NPVs returned by our proposed PSA but without tolerance relation as well as by local optimizer SQP and global optimizers Multi-Start SQP and GA on the same KMs.This case is analyzed with one and six control cycles, as shown in Fig. 10. This leads to a problem with ten design variables (n=10) and four inequality constraints (ni=4) in the former case, and to a problem with 60 design variables (n=60) and 24 inequality constraints (ni=24) in the latter case. In Tables 7–9, these problems are referred to as Problem 7 for one control cycle, and as Problem 9 for six control cycles.For this problem, 10 sampling points are used per design variable, thus performing 100 HF simulations for the training of the KM.While there is no equality constraint, this problem is still highly constrained with an estimated FR=0.0794%, as shown in Table 7. After the relaxation of the tolerance to 0.2532, the resulting estimated FR=23.65%, which is within the range specified in the settings (20–25%).For this problem, our optimizer obtains very good results consistently (see Tables 7 and 8): the best NPV found in 25 runs equals 300.5358; the median NPV equals 300.5345; the mean NPV equals 300.5341; and the worst NPV equals 300.5305; with a σs=0.0014. The maximum search length permitted of 10,000 time-steps was reached in every run. Nevertheless, the convergence curve in Fig. 11(left) shows that practical convergence has been achieved. CVs are calculated disregarding tolerance relaxation and therefore are actual violations.Further analysis on the data extracted from the search (not presented for brevity) shows that the difference in coordinates between the best and the worst results is minor in every dimension, and therefore they are in the same region of the search-space. In fact, the maximum and average absolute differences between corresponding coordinates of the best and of the worst results returned equal 0.75% and 0.22% of the corresponding feasible interval, respectively. Hence it can be inferred that the difference is in fine-tuning.As shown in Table 9, the Multi-Start SQP converged to the same NPV, namely 300.5359, in all 25 runs. Our proposed optimizer converges around the same solution in every run, despite not being able to complete the fine-tuning of the search; note that the search is terminated due to reaching tmax in every run. In turn, the PSA without tolerance relaxation obtained marginally worse results, whereas the GA displays considerable worse performance in this case. Strangely enough, the result returned but the efficient SQP is spot on this time. Thus, results in Table 9 show that our proposed optimizer obtains very good results on this KM, almost as good as those obtained by the Multi-Start SQP and by the efficient plain SQP. They also show that the tolerance relaxation is beneficial.As shown in Table 8, the best known solution of this problem (303.8614) is similar to the best result returned by our PIT (300.5358), only differing in 1.09% of the best known solution.An accuracy check was performed by evaluating the HF simulator on the coordinates of the best result found by our PIT, resulting in an error of our KM of 5.09% of the HF simulation. Another accuracy check was carried out by evaluating the KM on the coordinates of the best known solution, resulting in an error of our KM of 12.59% of the best known solution (see Table 8).For this problem, only six sampling points are used per design variable, thus performing 360 HF simulations for the training of the KM.While there is no equality constraint, this problem is still highly constrained with FR<10−4%, as shown in Table 7. After the relaxation of the tolerance to 0.4253, the resulting estimated FR=24.14%, which is within the range specified in the settings (20–25%).Search algorithms in general, and PSO in particular, suffer from the curse of dimensionality. This means that the performance of the method quickly deteriorates as the dimensionality of the search-space increases. The PSA used here is a general-purpose one, equipped with no additional strategy to cope with large-scale problems.Nonetheless, our optimizer is able to obtain good results, although not as consistently as before (see Tables 7 and 8): the best NPV found in 25 runs equals 282.7148; the median NPV equals 252.9083; the mean NPV equals 258.5174; and the worst NPV equals 252.3202; with a σs=10.8881. The search went through all 10,000 time-steps permitted in every run.As shown in Fig. 11 (right), the extremely low FR has a strong influence on the dynamics of the search, as compliance with all constraints proves remarkably more difficult than in all previous problems. The adaptive update of the relaxed tolerance is not sufficient to reach zero tolerance by the time 72% of tmax has elapsed. Therefore, additional updates are enforced to ensure that it is reached by the time 80% of tmax has elapsed. Compare this with the tolerance updates for Problem 7 in Fig. 11 (left), which reaches the zero tolerance before 250 time-steps have elapsed. It is also interesting to note that the CV of the best candidate solution in the swarm is consistently higher than the average CV of the swarm. Also note that, while the tolerance is relaxed, the curves of not only the best but also of the average conflict fall below the best feasible candidate solution finally found, which suggests that solutions are being pushed by tolerance updates towards the progressively smaller feasible space. For Problem 7, the curve of the best conflict falls below the best feasible candidate solution finally found only at the early stages of the search, whereas the average conflict is always above.Further analysis on the data extracted from the search (not presented for brevity) shows that only in 4 out of 25 runs did the results converge to the same region of the search-space where the best result was found. The remaining 21 runs return results in different regions of the search-space, not close to one another, all displaying conflicts in the range 252–256.As shown in Table 9, the Multi-Start SQP converged to the same NPV, namely 282.7150, in all 25 runs. Our proposed optimizer converges around the same result (282.7) in 4 out of 25 runs, converging to results in the range of 253–256 for the remaining 21 runs. In turn, the PSA without tolerance relaxation found marginally better results, converging around 282.7 in 6 out of 25 runs, and around results in the range of 252–257 for the remaining 19 runs. The GA exhibits similar performance in this case, whilst the result returned by SQP is similar to the median NPV returned by our PSA with and without tolerance relaxation and by the GA. Thus, results in Table 9 show that our proposed optimizer obtains results on this KM which are worse than those obtained by the Multi-Start SQP and competitive with the other global search algorithms. It seems that the tolerance relaxation does not have a strong beneficial effect if the adaptive scheme does not manage to eliminate it in time, and therefore the search is mostly driven by tolerance updates pushing the best candidate solutions towards the progressively smaller feasible space. This issue needs to be studied further.As shown in Table 8, the best known solution of this problem (287.5235) is similar to the best result returned by our PIT (282.7148), only differing in 1.67% of the best known solution.An accuracy check was performed by evaluating the HF simulator on the coordinates of the best result found by our PIT, resulting in an error of our KM of 1.03% of the HF simulation. Another accuracy check was carried out by evaluating the KM on the coordinates of the best known solution, resulting in an error of our KM of 12.32% of the best known solution (see Table 8).This case is analyzed with three control cycles (nt=3) and NFCO operational condition, leading to a problem with 38 design variables (n=38) and 10 inequality constraints (ni=3·nt+1=10). In Tables 7–9, this problem is referred to as Problem 8.For this problem, 10 sampling points are used per design variable, leading to 380 HF simulations to train the KM.While there is no equality constraint, this problem is still highly constrained with estimated FR=0.3391%, as shown in Table 7. After the relaxation of the tolerance to 0.1799, the resulting estimated FR=24.29%, which is within the range specified in the settings (20–25%).This is a remarkably difficult problem, as it is high-dimensional, highly multimodal, and highly constrained. As shown in Tables 7 and 8, the best NPV found in 25 runs equals 290.5559; the median NPV equals 263.6527; the mean NPV equals 267.3696; and the worst NPV equals 241.2921; with a σs=13.1455. The search used up all 10,000 time-steps permitted in 23 out of 25 runs. Only one run found the best NPV (290.5559); eight runs found an NPV around 280; three runs found an NPV around 270; 10 runs found an NPV of around 260; and the remaining three runs found lower NPVs.Further analysis on the data extracted from the search shows that different runs return different NPVs in different regions of the search-space, suggesting that numerous local optima exist in the KM.As shown in Table 8, the best known solution of this problem (346.3539) differs from the best NPV returned by our PIT (290.5559) in 16.11% of the former.An accuracy check was performed by evaluating the HF simulator on the coordinates of the best result found by our PIT, resulting in an error of our KM of 9.42% of the HF simulation. Another accuracy check was carried out by evaluating the KM on the coordinates of the best known solution, resulting in an error of our KM of 40.86% of the best known solution (see Table 8).

@&#CONCLUSIONS@&#
In petroleum engineering, waterflooding (WF) is the most widespread method used to improve oil recovery after primary depletion. When searching for optimum management of the process, computationally expensive reservoir simulations are required. In addition, according to the formulation of the operational conditions, the optimization problem may also be highly multimodal and/or highly constrained. Therefore, finding a global search method and a computationally cheaper alternative to reservoir simulations are of great interest. In this paper, we proposed using a particle swarm algorithm (PSA) with general-purpose (default) settings, adaptive constraint-handling technique (CHT) and suitable termination conditions integrated with a Kriging model (KM) trained offline using a Latin Centroidal Voronoi Tessellation (LCVT) design of experiments (DoE) technique and high-fidelity (HF) reservoir simulations. The proposed integrated tool (PIT) was applied to nine problems arising from the management of the WF technique in two oil reservoirs with different operational conditions and numbers of control cycles.With regards to the operational conditions, the non-full capacity operation with variable time (NFCO-VT) leads to the highest net present values (NPVs) with fewer design variables and control cycles.With regards to the KMs trained offline, it can be observed that they are reasonably accurate for problems with full capacity operation (FCO) in the first reservoir. For both reservoirs, accuracy decreases for problems with NFCO. It is interesting to note that, in four out of five problems where the accuracy of the KMs is poorer, namely Problems 4, 7, 8 and 9, the accuracy is noticeably better on the coordinates of the best NPV found by our optimizer than on the coordinates of the best known solutions of the actual problems. For the remaining problem (Problem 3), the accuracy of the KM is similar on both locations. This suggests that the optimizer converged towards the better approximations. In other words, the highest accuracies and the highest NPVs of the KMs are located in the same regions.With regards to the proposed optimizer (PSA+Adaptive CHT), it quickly converged to the same result on every problem with FCO and high feasibility ratio (FR) in the first reservoir, irrespective of dimensionality (Problems 1, 2, 5 and 6). Note that these are also the problems for which the KMs are most accurate. For the two problems with NFCO and very low FRs in the first reservoir, the optimizer did not manage to find the exact same result in every run but nearby results of similar quality, thus still showing consistency. For the 10-dimensional problem with FCO and low FR in the second reservoir, the optimizer again converged to the same result in every run. However, the performance deteriorates for the other two problems, which are high-dimensional, highly multimodal and highly constrained. Despite the optimizer finding good results, consistency is remarkably poorer than for the other seven problems.With regards to the adaptive constraint handling technique, its incorporation resulted in smaller sample standard deviations (σs) for every problem tested, and led to undoubtedly better results in highly constrained Problems 3, 4, 7 and 8. It is interesting to observe that the adaptive relaxation of the tolerance was beneficial even for Problem 2, which presents a very high FR of approximately 80%. For Problem 9, the incorporation of the adaptive tolerance relaxation did not lead to clear improvement. In this problem, Fig. 11 shows that the adaptive scheme was unable to drive the tolerance to its desired value smoothly and had to eventually force it. This results in the swarm finding it more difficult to maintain good candidate solutions between tolerance updates. Therefore, the rules for the adaptation of the tolerance relaxation need to be studied further.With regards to the PIT as a whole, which is composed of a PSA with general-purpose settings, sub-swarms with complementary behavior, an adaptive CHT and an integrated static KM, it was shown that it is able to obtain near-optimal results without the hassle of performing costly and complex numerical trial-and-error testing and tuning on a case-by-case basis. However, performance deteriorates for increasing dimensionality and for NFCO condition, which increases multimodality. While dimensionality, multimodality and low FRs do not seem to pose overly difficult problems by themselves, the PIT finds it difficult to deal with them when they occur simultaneously.At a higher level of description, the PIT is composed of a function approximator and a global optimizer. Besides their details, results in this paper suggest that integrating these tools is a good strategy to search for the optimal management of the WF technique. Therefore, different surrogate models, training algorithms, DoE techniques and global optimizers may be considered.Higher accuracy of the surrogate models would noticeably improve performance of the PIT. This could be achieved by increasing the number of sampling points for the training of the model at the expense of higher computational effort. A next cleverer step would consist of implementing an adaptive scheme so that the training of the surrogate model takes place as the optimization progresses. This would increase the accuracy of the model in the regions of interest only, without spending computational effort in training the model away from the global optimum. This adaptive scheme would also eliminate the need for a DoE technique.Finally, our aim is to develop a global optimizer for real-world applications that require no parameter tuning or sensitivity analysis. While a first step was to develop an adaptive CHT and termination conditions which control the search-length and hence the computational effort spent according to the difficulty posed by the problem at hand, the use of general-purpose settings for the PSA is a temporary solution. Moving towards a fully adaptive scheme is the next logical step.