@&#MAIN-TITLE@&#
Comparative performance of meta-heuristic algorithms for mass minimisation of trusses with dynamic constraints

@&#HIGHLIGHTS@&#
Comparative performance of 24 meta-heuristics for solving truss mass minimisation with dynamic constraints.Comparison of penalty function techniques for handling dynamic constraints.Best results for the benchmark problems of truss mass minimisation with dynamic constraints.

@&#KEYPHRASES@&#
Meta-heuristics comparative performance,Truss minimisation,Dynamic constraints,Evolutionary algorithms,Shap and sizing optimisation,Penalty function techniques,

@&#ABSTRACT@&#
This paper investigates the search performances of various meta-heuristics (MHs) for solving truss mass minimisation with dynamic constraints. Several established MHs were used to solve five truss optimisation problems. The results obtained from using the various MHs were statistically compared based upon convergence rate and consistency. It was found that the best optimisers for this design task are evolution strategy with covariance matrix adaptation (CMAES) and differential evolution (DE). Furthermore, the best penalty function technique was discovered while four penalty function techniques assigned with several parameter settings were used in combination with the five best optimisers to solve the truss optimisation problems.

@&#INTRODUCTION@&#
A truss is one of the most used structures in engineering applications due to its simplicity and low cost for construction. Under working conditions, such a structure is subject to multiple types of loads, which can be categorised as being static or dynamic. The structure under dynamic excitation may cause several undesirable vibration phenomena including structural resonance. As a result, truss designers have to find ways to prevent or suppress structural vibration. The problem of truss minimisation subject to natural frequency constraints has been researched [1–6], and it has been found that predefined frequency constraints can prevent vibration resonance from certain frequency bands of dynamic loads. Since its introduction, this special design problem has been problematic because its feasible region is non-convex while the boundaries are highly non-linear [1–3]. This has led to difficulty in the use of gradient-based optimisers. Alternatively, meta-heuristics (MHs) are known to be a better choice. Many researchers in the field of structural optimisation have been interested in the investigation of solving this kind of optimisation problem using MHs. Normally, the problem has an objective in minimising structural mass with multiple frequency constraints while using design variables such as topology [4], sizing [1,7], and a combination of shape and size [2,3,5,6].Meta-heuristic algorithms are widely used for various kinds of optimisation design problems, particularly for engineering applications, due to their derivative-free and global optimisation capabilities. These optimisers are robust and can be used to solve almost any kind of optimisation due to the nature of soft computing. However, a lack of search consistency is unavoidable during the MH search because of procedural randomisation. Also, there is likely to be a slow convergence rate if parameter settings, which are problem-dependent, are not properly assigned. Over the last few decades, numerous MHs have been developed, improved upon, and successfully implemented on a wide variety of optimisation problems [8–14]. New MHs can be proposed as hybridisations of existing algorithms [9–10,13,14] or have been introduced as new search concepts [15–18]. Even with thousands of algorithms in the literature, it can be said that there is no single MH that can outperform other MHs for all design problems. Consequently, it is always useful to compare the performance of a number of well-established and newly developed MHs for solving a newly introduced design problem or a problem that remains difficult to solve. For truss mass minimisation with frequency constraints, there are a number of MHs that have been successfully used including a charged system search algorithm [4], a hybrid version of the charged system search algorithm [3], a genetic algorithm [6,7], a particle swarm algorithm [1,19], a harmony search [2,5] and a firefly algorithm [5]. Nevertheless, since those researchers conducted their work independently, they presented a new meta-heuristic and compared it only with the previously used optimisers in the literature. Usually, the new method was run many times and the best results were taken to show and compare. This is not an appropriate way to compare search performances of MHs since it is unlikely that those optimisers can get the same results with several runs due to randomisation in the process. There are a large number of MHs that have been overlooked and not implemented, while there have been several penalty function techniques being used such as the traditional exterior penalty function technique [2], the fuzzy set theory technique [20], the Kaveh–Zolghadr technique [3], and the Murata–Kim–Sugei technique [21]. The comparison of their effectiveness would be useful for future engineers and researchers.In this comparative study, various MHs (mostly well-established), have been employed to solve a number of traditional test problems for truss optimisation with frequency constraints. Twenty-four MHs were used to solve five test problems. The top five best performers were then used in combination with four penalty function techniques and various sets of their internal parameters to solve the test problems in order to examine the effectiveness of those penalty function techniques. Each optimiser was used to solve each test problem a number of times, while the results obtained from using the various methods were statistically compared. The best meta-heuristics and the most effective penalty function methods will be discussed. What follows in this paper is organised such that: Section ‘Test problems of truss shape and sizing optimisation’ gives details of the test problems for truss mass minimisation with frequency constraints. Section ‘Meta-heuristics’ shows the comparative performance of the 24 meta-heuristic optimisers on solving the five test problems. The top five best optimisers are then used to examine the effectiveness of the penalty function techniques while the comparative results of this study are given in section ‘Comparative study of various meta-heuristic algorithms’. Finally, concluding remarks are provided in section ‘Comparative study of various penalty function techniques’.A typical truss optimisation problem with dynamic constraints can be posed as(1)minf(x)s.t.ωi≤ωi,allfori∈Iωj≥ωj,allforj∈JxL≤x≤xUwhere x is a vector containing design variables having lower and upper bounds as xLand xUrespectively, f is an objective function, ωiis the i-th mode natural frequency of a truss, ωi,allis an allowable frequency for the i-th mode natural frequency, I and J are the sets of mode numbers to be specified by a designer.The objective function is structural mass whereas design variables include, in this work, sizing and shape variables. The sizing design variables include truss element cross-sectional areas while the shape design variables are nodal positions of the structure. It is commonplace that most if not all of MHs can handle optimisation problems with bound constraints. For the design problem (1), a penalty function, which will be detailed later, is adopted to handle the dynamic constraints.Five test problems of shape and sizing optimisation of trusses with frequency constraints commonly found in the literature will be employed in this study. The design problems were assigned to minimise structural mass subject to multiple frequency constraints, and are detailed as follows:Case I: Sizing design of a 2D 10 bar trussThe truss structure is illustrated in Fig. 1[1,3,5,6]. The structure is subject to non-structural mass of 454kg at each free node. The design variables include all simple bar element cross section areas. Material density and modulus of elasticity are 2770.0kg/m3 and 6.98×1010N/m2 respectively. The sizing optimisation is presented to minimise structural mass subject to natural frequency constraints which can be expressed as follows:minxf(x)=structural masss.t.ω1≥7Hzω2≥15Hzω3≥20Hz0.645≤Ai≤50cm2where xT={x1,…,x10}={A1,…,A10} is a design vector, f(x) is structural mass. The variables ω1, ω2 and ω3 are the natural frequencies for the first, second and third modes respectively. Aiare cross-sectional areas of all bar elements.Case II: Shape and sizing design of a 2D 37bar trussThe truss structure is illustrated in Fig. 2[1,2,5,6,19]. The structure is subject to non-structural mass of 10kg at each free node of the lower chord. The elements of the lower chord were set as bar elements with unchanged cross-sectional area of 40cm2 while the other were set as bar elements with initial cross-sectional area 1cm2. The design variables include all bar element cross-sectional areas (except the lower chord bar elements) and y-direction of nodal positions of the upper chord. The design variables are treated so to have a symmetrical structure with respect to the y axis. Material density and modulus of elasticity are 7800.0kg/m3 and 2.1×1011N/m 2, respectively. The shape and sizing optimisation problem is presented to minimise structural mass subject to frequency constraints which can be expressed as follows:minxf(x)=structural masss.t.ω1≥20Hzω2≥60Hzω3≥60Hz1≤Ai≤10cm20.1≤Yi≤3mwhere xT={x1,…,x19} is a design vector. Truss cross-sectional areas are assigned as the first 14 elements of the vector while the nodal positions are assigned as the 15th- 19th elements. The variables ω1, ω2 and ω3 are the natural frequencies for the first, second and third modes respectively. Aiare element cross-sectional areas. Yiare the y-direction of positions of the upper chord nodes (changes in Yi are symmetric about y axis).Case III: Sizing design of a 3D 72bar space trussThe truss structure is illustrated in Fig. 3[1,3,5,7]. Four non-structural masses of 2270kgs are attached to the top nodes. The design variables include all bar element cross-sectional areas which were divided into 16 groups according to Table 1. Material density and modulus of elasticity are 2770.0kg/m3 and 6.98×1010N/m2, respectively. The sizing design problem is assigned to minimise structural mass subject to frequency constraints, which can be expressed as follows:minxf(x)=structural masss.t.ω1=4Hzω2⩾6Hz0.645≤Ai⩽30cm2where xT={x1,…,x16} is a design vector. ω1 and ω2 are the first and second mode natural frequencies respectively. Aiare the cross-sectional areas.Case IV: Shape and sizing design of a 3D 52bar dome trussThe truss structure is illustrated in Fig. 4[1–3,5,6,19]. The structure has non-structural masses of 50kg at each free node. The design variables include all bar element cross section areas which were divided into 8 groups according to Table 2and all free nodes which can move ±2m in all directions in a symmetrical manner. Material density and modulus of elasticity are 7800.0kg/m3 and 2.1×1011N/m2 respectively. The shape and sizing optimisation problem is presented to minimise structural mass subject to frequency constraints which can be expressed as follows:minxf(x)=structural masss.t.ω1⩽15.916Hzω2⩾28.648Hz1⩽Ai≤10cm2where xT={x1,…,x13} is a design vector (eight sizing variables and five shape variables). ω1 and ω2 are the first and second mode natural frequencies respectively. Aiare cross-sectional areas.Case V: Sizing design of a 3D 120bar dome trussThe truss structure is illustrated in Fig. 5[3,19]. The structure has non-structural masses at free nodes as: 3000kg at node 1, 500kg at nodes 2–13, and 100kg at the rest. The design variables include all bar element cross section areas which were divided into 7 groups as show in Fig. 5a. Material density and modulus of elasticity are 7971.810kg/m3 and 2.1×1011N/m2 respectively. The sizing optimisation problem can be expressed as follows:minxf(x)=structural masss.t.ω1⩾9Hzω1⩾11Hz1⩽Ai⩽129.3cm2where xT={x1,…,x7} is a design vector. ω1 and ω2 are the first and second mode natural frequencies respectively. Aiare cross-sectional areas.A meta-heuristic, often regarded as a probabilistic optimisation method, is an optimiser developed as an alternative to a classical gradient-based optimiser. Most of the meta-heuristic algorithms search for optima by using a group of design solutions traditionally called a population. The optimisation procedure starts with an initial population usually created at random. The population of design solutions are then updated or improved by some specific computing operations which are usually related to randomisation. The operators are created and used to achieve intensification and diversification in searching. The population is improved iteratively until a termination criterion is met. As this type of optimiser does not employ function derivatives, the procedure is stopped when no further improvement of a population for several iterations is found or the maximum number of function evaluations is reached. The method can be used to solve almost any kind of optimisation problem. Over the last few decades, there have been a large number of MHs developed for solving various types of optimisation problems. The methods can be classified into many groups such as bio-inspired optimisers, swarm intelligence optimisers, and evolutionary algorithms. MHs are becoming more popular compared to their derivative-based counterparts since they are flexible to modify, improve and use. Furthermore, this research field is still wide open for further investigation and development. For this comparative performance study, 24MHs are employed and they are briefly detailed as:–DE: Differential evolution [22]. DE is a simple but efficient evolutionary algorithm proposed by Storn and Price (1997). The search processes start with an initial population. Then, a set of candidate solutions is generated by two main operators, mutation and crossover. The best between a particular candidate and its parent will be selected for the next generation. DE, since it was proposed, have a number of optimisation strategies which are usually termed DE/x/y/z where x is a solution vector to be mutated, y is a number of solution pairs used for computing vector differentiation in mutation, and z is a crossover scheme.ABC: Artificial bee colony algorithm [15]. The search procedure of ABC imitates bee behaviour in finding food sources. In the ABC algorithm, after randomly creating a population (viewed as food source positions for employed bees), the amounts of nectar (objective function values) are computed. Then, candidate food sources are created in some manners for employed and onlooker bees. It is also useful to use some scout bees to explore new food sources if appropriate. The food source positions are updated iteratively until the procedure is stopped.ACOR: Real-code ant colony optimisation [23]. The very first version of ant colony optimisation was proposed by Dorigo [24] for solving combinatorial optimisation. Since then, it has become one of the most popular optimisers for such optimisation problem with numerous variants having been proposed. The real-code ant colony optimisation [22] was later developed by the same author and it is said to be among the top real-code MHs [25]. Starting with a randomly generated initial population, offspring are then created by means of an ant-based solution construction process involving roulette wheel selection and a Gaussian function [23]. The best solutions from combining the offspring and the parents are selected as the next generation. The procedure is repeated until meeting a termination criterion.ChSS: Charged system search [16]. The search process starts with an initial population regarded as a group of charged particles while charged memories are generated. Then, the position of each charged particle will be updated based on the Coulomb law for electrostatics and the Newton laws of motion. The new charged particles will be compared with the old ones, and the better ones will be stored in the charged memories. The procedure is repeated until the termination criterion is reached.LCA: League championship algorithm [17]. LCA imitates a league environment in some kind of sport, such as football. Initially a league schedule is generated for the whole season (one optimisation run). A member in a population is viewed as an individual team formation while its objective function is team strength. For each week (iteration), those teams participate in the competition. For the next week, a team may change its team formation based on match analysis and comparing playing strength to other teams. The formations of all teams are updated weekly until the season ends.SA: Simulated annealing [8]. SA was first proposed by Kirkpatrick et. al. [26]. The method is one of the state-of-the-art MHs with numerous variants being developed and used in various kinds of applications. For this work, the search procedure of SA starts with an initial solution, which will be called a parent. The parent is then mutated in some manner leading to a set of children or offspring. The best offspring is said to be a candidate to challenge its parent. For minimisation, if the candidate has a lower objective value than that of its parent, the parent is replaced by the candidate. In cases where the candidate has a higher objective function value than its parent, it still has a chance to replace the parent if accepted by a Boltzmann probability. In this version of SA, the best solution will be kept and used for creating offspring along with the parent as detailed in [8].TLBO: Teaching–learning-based optimisation [18]. Starting with a randomly created population with objective function values being evaluated, the best individual (teacher) will be identified. Then, the population will be updated by two stages including teacher and leaner phases. For the former phase, a solution is moved towards the best solution while, for the later phase, it is moved towards a better neighbour. The population is improved iteratively until meeting a stopping criterion.BBBC: Big bang – big crunch algorithm [27]. The method is based on the Big Bang and Big Crunch theory. The search process starts with randomly generating an initial population which is called a big bang phase. Then, the operator called big crunch is applied to find the mass centre. Thereafter, a big bang operator is used to create neighbours of the mass centre. The process is repeated until the stopping condition is met.BPBIL: Population-based incremental learning [28]. BPBIL is an estimation of distribution algorithm based upon a binary searching space. Rather than using a binary population directly as with a genetic algorithm, the search process starts with an initial probability vector which has the length equal to that of a binary design solution. The binary population according to the probability vector is then created where the best solution is found. The probability vector is updated based on the best binary solution while it is also useful to apply mutation with a given (usually low) probability. The vector is updated iteratively until the procedure is terminated.CKS: Cuckoo search [29]. CKS is created mimicking egg-laying behaviour of cuckoos. The procedure starts with an initial set of solutions (host nets). A new solution is created by means of a Levy flight. If it is better than a randomly chosen host nest, replace the old nest with the new one. Some of the worst nests can be discarded with a predefined probability and a new nest is created to replace them. The best nest is recorded and the procedure is repeated until a stopping condition is met.CMAES: Evolution strategy with covariance matrix adaptation [30]. CMAES is an extension of ES for real-code optimisation. The optimiser is said to remove randomisation of strategy parameter settings which is usually a problem in most MHs. The method starts with an initial population, a global step size, and a covariance matrix. The solutions are then updated based on the step size and normally distributed random vectors with such a covariance matrix. Having evaluated objective functions, the step size and covariance matrix are updated using an evolution path. This process is repeated until a stopping condition is met.CPBIL: Continuous population-based incremental learning [31]. The CPBIL algorithm is an extension of BPBIL. A probability vector is use for creating a binary population in BPBIL but, for the continuous version, a probability matrix is used. Having generated a real-code population, the probability matrix is updated according to the best real code solution. Mutation on the probability matrix is activated with the given mutation probability. The algorithm updates the probability matrix iteratively until reaching a termination condition.CSS: Continuous scatter search [32]. The continuous version of scatter search, similarly to its combinatorial version, uses intensification and diversification to improve design solutions towards an optimum. The procedure starts with and initial population obtained by using a diversification generation method. Then an improvement method or local search is employed to improve the solutions. The reference set containing some best and diverse solutions is generated where new candidates are created by applying a solution recombination method on a member in the reference set. Having applied the local search the reference set is updated. The process continues until the stopping condition is fulfilled.ETCS: Enhanced continuous tabu search [33]. The original version of tabu search was developed by Glover [34] for combinatorial optimisation. In the ETCS algorithm, as an initial population is created, the so-called promising list containing some best solutions and the tabu list containing the rest are generated. A new solution is generated by mutation and its function evaluation is carried out if it is not too close to the members in those lists. The tabu and promising lists are updated and the process repeats until being terminated. It should be noted that it is also useful and possible to apply local search to improve the solutions at the end of the search procedure.ES: Evolution strategies [35]. ES was developed in Germany during the same time period as evolutionary programming (EP) and the genetic algorithm (GA). These three optimisers were developed independently but their concepts are surprisingly similar. The first version of ES is called 1+1 ES where one offspring is created from mutating a parent. The later version is μ+λ ES standing for λ offspring are iteratively created from μ parents. Starting with a randomly generated population or a set of design vectors, a real-code recombination is applied to create a set of offspring. The offspring is then mutated based on normal distribution randomisation. The best solutions among the union set of offspring and parents are selected to the next iteration. The process is repeated until fulfilling the stopping condition. To prevent a premature convergence, a tournament selection operator is used instead of choosing best solutions in this paper.EP: Evolutionary programming [35]. EP is somewhat similar to ES since the reproduction process employs normally distributed randomisation for mutation. However, EP does not use a recombination operator while the selection operator is also different.FWA: Fireworks algorithm (FA) [36]: FWA is a simple swarm intelligence optimiser imitating the nature of firework explosion. An initial population is seen as a group of fireworks where design solutions are firework locations. The location of sparks is then simulated, which is a means to reproduce candidate solutions. Having evaluated function values, the best fireworks locations are then selected and kept to the next generation.GA: Genetic algorithm [37]. A genetic algorithm is probably the best known meta-heuristic which, since it was first introduced, has thousands of variants. The method, like its name, can be best thought of as imitating Darwinian natural selection in that offspring are created by mating pairs of their parents. The parents are selected by means of roulette wheel selection to a mating pool and a crossover operator is used to create offspring with a given crossover probability. Then, mutation is allowed to take place with a predefined mutation rate. The process repeats until meeting a termination criterion.GSA: Gravitational search algorithm [38]. GSA is another swarm intelligence optimiser which searches for optima based on the law of gravity and mass interaction. Starting with an initial population, the gravity and mass will be calculated depending on objective function values. Total forces, accelerations and velocities of the design solutions are then calculated and used to update the solution members in a population. The process is repeated until a stopping criterion is reached.HS: Harmony search [39]. HS is an optimisation algorithm which was developed based on improvisation of music players. The search process starts with initialised harmony memories (population). Then, the harmony memories will be updated based on aesthetic estimation which is defined by harmony memory considering rate and pitch adjusting rate. The harmony memories are updated iteratively to meet an optimum.PSO: Particle swarm optimisation [40]. PSO is probably the first swarm intelligent algorithm which was developed imitating the movement of a flock of birds or fishes aiming to find food. Starting with a group of birds or position vectors of particles, initial particle velocities are then defined. The position of each particle is then modified based on its velocity which is influenced by its velocity from the previous generation, the global best solution, and its best found position. The particles move iteratively until reaching an optimum.SGA: Stud genetic algorithm [41]. SGA is an evolution of GA. Rather than creating offspring from crossing over a pair of selected parents, the best binary design solution is used as a stud. To create an offspring, the crossover operator will be applied to the stud and an individual in a population. It is also useful to apply a mutation operator or another diversity-based operator with a predefined probability in order to prevent a premature convergence. The population is updated by mating solutions with the stud iteratively until fulfilling a termination criterion.BAT: Bat-inspired algorithm [42]. A swarm intelligence algorithm BAT is a meta-heuristic inspired by the echolocation of microbats. The extended version of BAT is presented in [43] with slight modification. Bats (design solutions) update their positions using velocities based on varying frequencies and loudness. A random walk is applied for diversification. The positions of the bats are updated repeatedly until the algorithm is stopped.FFA: Fireflies algorithm [44]. A firefly algorithm is another swarm intelligence optimiser. With an initial population of fireflies (design solutions), their objective functions are evaluated and consequently their light intensity values are computed. Each firefly will move to other fireflies based on the light intensity while the degree of attractiveness varies with a distance between a pair of fireflies. The position of the fireflies and their light intensities are updated iteratively until meeting a stopping condition. In this work, the latest version of FFA [45] will be employed.In this work, twenty-four established MHs were compared based on solving the five truss optimisation problems. Given that nPis a population size (unless otherwise specified) and n is a number of design variables, the optimisation parameter settings of those MHs (details of notations can be found in the corresponding reference of each method) are detailed as:DE: DE/best/2/bin strategy is used. A scaling factor, crossover rate and probability of choosing elements of mutant vectors are 0.5, 0.7, and 0.8 respectively.ABC: The number of food sources is set to be nP. A trial counter to discard a food source is 150.ACOR: The parameter settings are q=0.5, and ξ=0.5. Roulette wheel selection is used for ant-based solution construction.ChSS: The number of solutions in the charged memory is 0.2×nP. The charged moving considering rate (CMCR) and the parameter PAR are set to be 0.75 and 0.5 respectively. Charged sphere radius is a=0.10max((xU–xL)). The parameter ε for calculating the separation distance between two charged particles is 0.000001.LCA: The probability of success (Pc) is 0.5 and the decreasing rate to decrease Pcis α=0.5. The lower and upper limits for a retreat coefficient are 0 and 2 respectively. The lower and upper limits for an approach coefficient are 0 and 2 respectively. A new formation is based on best formations.SA: Starting and ending temperatures are 10 and 0.001 respectively where the temperature is increased exponentially for every 10 loops. For each loop, n candidates are created by mutating on the current best solution while other n candidates are created from mutating the current parent. The best of those 2n solutions are set as an offspring to be compared with the parent.TLBO: The teaching factor is TF=rand(1 or 2).BBBC: The current best solution is used as a centre point to create a new population. The search space will be restricted to half after every period of 5 iterations.BPBIL: The learning rate, mutation shift, and mutation rate are set as 0.5, 0.7, and 0.2 respectively.CKS: Discovery rate of alien eggs (pa) is 0.75. The Levy coefficient is β=2/3.CMAES: Parameter settings are not required.CPBIL: The learning rate, mutation shift, and mutation rate are set as 0.5, 0.2, and 0.05 respectively. RPBIL3 in [31] is employed with Tstart=5 and Tend=40.CSS: The BLX-α recombination method is used for reproduction. The simplex downhill method is used for local search. The number of high-quality solutions in the reference set is 0.5×nP, and the number of diverse solutions in the reference set is 0.25×nP.ETCS: The tabu list size is set to be 2×nPwhile the promising list size is 0.5×nP. A linear partitioning on hyper-rectangles is used for generating neighbour solutions.EP: For every period of 3 iterations, the number of randomly selected individuals used for computing a selection function value is increased by 1 where it is set to be 2 for the first loop.ES: Use a three-candidate tournament selection operator and a simple mutation without the effect of a covariance matrix. For each individual solution, all five ES recombination strategies are applied with equal probabilities.FWA: The number of fireworks for each generation is nP/4, the limit of sparks created with algorithm 1 is nP, the amount of sparks created with algorithm 2 is nP/4, the floor parameter for rounding the amount of sparks created with algorithm 1 is 0.004, the ceiling parameter for rounding the amount of sparks created with algorithm 1 is 0.8, and the maximum explosion amplitude is 0.5(xU,i–xL,i).GA: The crossover and mutation rates are 0.7 and 0.3 respectively. Multi-point crossover is used.GSA: The norm in Eq. (8) in [38] is 1. The power of Rijin Eq. (7) in [38] is 2. In Eq. (28) in [38], α=20 and G0=100. In the last iteration, only 10 percent of agents apply force to the others.HS: The parameter settings are: harmony memory size=nP, harmony memory considering rate (HMCR) = 0.8, pitch adjusting rate (PAR) [0.4,0.9] increased linearly, and bandwidth (BW) [0.0001,0.9] decreased exponentially.PSO: The starting inertia weight, ending inertia weight, cognitive learning factor, and social learning factor are assigned as 0.75, 0.0001, 1.5 and 2.5 respectively. The inertia weight is decreased linearly.SGA: The so-far best solution is used as a stud whereas the probability of shuffling binary bits of a binary design solution is 0.2.BAT: The loudness and the pulse rate are set to be 0.9 and 0.1, respectively. The minimum and maximum frequency values are 0 and 2, respectively. The maximum and minimum values of θ are 0.1 and 20, respectively.FFA: The parameters in Equation (15) in reference [45] are set as α=0.75, Ω=0.000001, and β0=0.25.It should be noted that the parameters used for each optimiser are tuned to have proper values that increase the performance of the algorithm. The Case I problem is used for such parameter tuning. Each optimiser is used to solve each truss problem for 30 optimisation runs. The population size is set to be nP=20 whereas the number of iterations is 200 for all test problems. For the optimisers using different population sizes such as simulated annealing, and firework algorithm, their search processes are terminated with the total number of functions evaluations equal to 20×200. The penalty function used in this study is the Kaveh–Zolghadr technique which has some details as:fp(x)=(1+ε1·v)ε2where fpis a penalised function value, ɛ1 and ɛ2 are selected considering the exploration and exploitation rates of the search space.v=∑i-1ngviwhere ng and viare the number of frequency constraints and the constraints violation respectively. At a design solution x, if the ith constraint is not violated, viwill be taken as zero; otherwise, viwill be defined as:vi=1-ωiωi,allwhereωiandωi,allare the ith mode natural frequency and the allowable ith mode natural frequency respectively.

@&#CONCLUSIONS@&#
