@&#MAIN-TITLE@&#
A parallel algorithm for improving the maximal property of Poisson disk sampling

@&#HIGHLIGHTS@&#
A simple algorithm for improving the maximal property of Poisson disk sampling.The algorithm is fully parallel and can be implemented on the GPU.It works for 2D and 3D, and can also be extended to surface in an intrinsic manner.

@&#KEYPHRASES@&#
Poisson disk sampling,Maximal sampling,Parallel algorithm,GPU,Exponential map,

@&#ABSTRACT@&#
This paper presents a simple yet effective algorithm to improve an arbitrary Poisson disk sampling to reach the maximal property, i.e., no more Poisson disk can be inserted. Taking a non-maximal Poisson disk sampling as input, our algorithm efficiently detects the regions allowing additional samples and then generates Poisson disks in these regions. The key idea is to convert the complicated plane or space searching problem into a simple searching on circles or spheres, which is one dimensional lower than the original sampling domain. Our algorithm is memory efficient and flexible, which generates maximal Poisson disk sampling in an arbitrary 2D polygon or 3D polyhedron. Moreover, our parallel algorithm can be extended from the Euclidean space to curved surfaces in an intrinsic manner. Thanks to its parallel structure, our method can be implemented easily on modern graphics hardware. We have observed significance performance improvement compared to the existing techniques.

@&#INTRODUCTION@&#
Poisson disk sampling is a process to distribute all samples that are uniformly and randomly located. It also requires a minimum distance apart from any two samples. LetDdenote the sample domain. Poisson disk sampling is a setX={xi∈D;i=1,2,…,N}ofNsamples having the properties(1)∀xi∈X,∀M⊆D:P(xi∈M)=∫Mdx,(2)∀xi,xj∈X:‖xi−xj‖≥2r,whereP(⋅)is a probability. A Poisson disk sampling is called maximal if there is no room to insert an additional sample, i.e.(3)∀x∈D,∃xi∈X:‖x−xi‖≤2r.Due to its excellent spatial and spectral properties, Poisson disk sampling is widely used in computer graphics and visualization, such as anti-aliasing  [1], global illumination  [2], non-photorealistic rendering  [3], remeshing  [4], texture synthesis  [5], vector field visualization  [6], etc.Dart throwing, proposed by Dippé and Wold  [7], is the first accurate approach to generate Poisson disk patterns inRn. However, this brute-force approach is impractical and inefficient, since a large number of samples are involved in the attempt but only a small percentage of them are eventually inserted into the distribution. Since then, many approaches have been proposed to improve the performance of the dart throwing algorithm, e.g., jittered sampling  [8], spatial data structures  [9,10], procedure tiling  [11–13], and hierarchical sampling  [14,15]. Some algorithms  [16,10,17] are able to generate maximal Poisson disk sampling. Although they are faster than the dart throwing algorithm, these algorithms are still sequential in the sense that the sample or dart is drawn one by one.In contrast to many sequential algorithms, there are relatively few works for computing Poisson disk sampling in parallel. Wei  [18] pioneered the phase group method, which subdivides the sample domain into grid cells and draws samples concurrently from multiple cells that are sufficiently far apart to avoid conflicts. Ying et al.  [19,20] presented a technique to parallel the dart throwing by assigning each sample candidate a random and unique priority that is unbiased with regard to the distribution. Hence, multiple threads can process the candidates simultaneously and resolve conflicts by checking the given priority values. By taking advantage of the modern GPU, these parallel techniques significantly outperform the sequential algorithms. However, none of these parallel algorithms is maximal, i.e., when the algorithm terminates, there is still room for additional samples.Ebeida et al.  [21] presented a parallel algorithm to generate maximal Poisson disk sampling inRd. Their idea is to maintain a flat quadtree structure to keep track of the uncovered region. Their algorithm is theoretically sound and also practical for dimension up to 3 on the GPU. However, compared to the other parallel algorithms, Ebeida et al.’s approach requires large memory due to maintaining all the active cells, which diminishes its application to large scale models due to the limited memory on graphics card. Furthermore, it is not clear whether their flat quadtree data structure can be extended to curved surfaces. Recently, Yan and Wonka  [22] studied the geometry of gaps in disk sets and then proposed efficient algorithms to detect and update these gaps when the Poisson disk distribution is updated (e.g., disks are inserted, deleted, moved or when their radii are changed). Yan and Wonka’s algorithm can fill in the gaps in parallel. Moreover, their algorithm is theoretically sound and can generate maximal Poisson disk distributions with varying radii in the Euclidean space of arbitrary dimension or on a manifold.On the other hand, there are many Poisson disk sampling algorithms on surfaces. However, very few of them could produce the maximal distribution. Due to the fundamental difference between the Euclidean space and the curved surface, efficiently computing a maximal Poisson disk sampling on arbitrary surfaces is still a challenging problem. Fu et al.’s method  [4] produces the maximal distribution on surfaces at a very low performance (only 30–50 samples per second). Bowers et al.’s parallel algorithm  [23] is able to generate 180k samples per second on the Nvidia GTX580, but their algorithm is extrinsic and approximate. Ying et al.  [20] proposed an intrinsic, parallel and accurate algorithm which can produce 350k samples per second. However, neither  [23] nor  [20] could generate a maximal distribution.This paper presents a simple yet effective technique to compute maximal Poisson disk sampling inR2andR3. Taking a non-maximal Poisson disk sampling as input, our algorithm efficiently detects the regions allowing additional samples and then generates Poisson disks in these regions. The key idea is to convert the complicated plane or space searching problem into a simple searching on circles or spheres, which is one dimensional lower than the original sampling domain. Compared to the existing maximal Poisson disk sampling algorithm, our method is memory efficient, very fast and fully parallel, which can generate more than 8 million samples per second inR2and 0.55 million samples per second inR3on the Nvidia GTX580. Furthermore, our algorithm can also be extended to surfaces in an intrinsic manner.The remaining of this paper is organized as follows: we first describe an interesting geodesic problem in Section  2. The solution of such a problem lays the foundation of our algorithm. Then we present our parallel algorithm in Section  3 followed by the experimental results and analysis in Section  4. We compare our method to the existing techniques in Section  5 and conclude the paper in Section  6.Before introducing our algorithm, we discuss an interesting geometric problem, which is closely related to maximal Poisson disk sampling.Problem statement. Consider a set of circlesCi=(ci,ri)inR2(resp. spheresSiinR3) covering a finite domainD⊂R2(resp.R3), whereciandriare the center and radius respectively. Any two circles (resp. spheres) do not intersect. Can we insert a circle (resp. sphere) of radiusrintoDwithout intersecting the existing circles (resp. spheres)?Solution in 2D. For each circleCi=(ci,ri), we draw a new circleCi′=(ci,ri+r)with radiusri+r. Note that these new circlesCi′may intersect due to the increased radius.Now consider two circlesC1′andC2′intersecting atp1andp2(see Fig. 1, whereCiis in solid black andCi′in dashed blue). Clearly, we cannot insert an additional circle of radiusrin the region formed byC1′⋂C2′, since such a circle will intersectC1orC2. Observe that the red arcp1p2̂of circleC1′is completely inside circleC2′. We call this arc “forbidden” since no circle of radiusrcan be inserted intoC1′⋂C2′. Other circlesCi′can also generate forbidden arcs onC1′if they intersectC1′. Then we define the “permitted” arc(s) onC1′as the complement of all forbidden arcs.Thus, in order to find the room to insert an additional circle nearC1, it is equivalent to test whether the circleC1′has at least one permitted arc.Take an arbitrary unit vectoru⃗as the reference axis for circleC1′. Then we compute the anglesα=angle betweenu⃗andc1p1⃗andβ=angle betweenu⃗andc1p2⃗. The forbidden arcp1p2̂is given by(α,β)if the reference axisu⃗does not intersect the arc. Otherwise, we split it into two small arcs, i.e.,(−ϵ,β)and(α,2π+ϵ), whereϵ=1×10−8is a small value. Fig. 1(b) shows a special case where multiple circles intersect at one pointp. In such a situation, a circle of radiusrcan be inserted atp; thus, the pointpis a degenerate but permitted arc. The detailed algorithm to find all permitted arcs is documented in Algorithm 1.Solution in 3D. The 3D problem can be solved by using the above 2D results. For each sphereSi=(ci,ri), we make a new sphereSi′=(ci,ri+r). Due to the increased radius, the spheres may intersect each other. Similar to the 2D case, if two spheresSi′andSj′intersect, we cannot insert a sphere with radiusrin betweenSiandSj.Observe that the intersection of two spheres is a circle, which bounds a disc on each sphere. Similar to the 2D case, we call such a disc forbidden, since it does not allow inserting an additional sphere. Also, the complement of all forbidden discs is called “permitted”. Note that the boundary of the permitted region is a set of permitted arcs. Thus, in order to find the room to insert an additional sphere nearSi, it is equivalent to test whether the permitted region onSi′is non-empty.This permitted region searching problem, on the other hand, can be formulated as finding permitted arcs. As shown in Fig. 2, letC1=Si′⋂S1′andc2=Si′⋂S2′be two intersecting circles onSi′. AndC1andC2also intersect at pointsp1,p2. Thus, we can use the permitted arcs technique to find the permitted region, i.e., a region which is not enclosed by any circles. Therefore, by searching all permitted regions on all spheres, we can find the available spaces for inserting new spheres.Our algorithm takes a non-maximal Poisson disk sampling as input. Although there are many algorithms available, we adopt the priority-based parallel algorithm  [20], which can guarantee that the generated Poisson disk distribution is bias free.Given the non-maximal Poisson disks, our goal is to search the domainDand then find the regions which are big enough to contain additional samples. This is exactly the problem we mentioned in the previous subsection; therefore, it can be solved by searching the permitted arcs on circles or spheres, which is one dimensional less than the sampling domainD. It is also worth noting that the searching operation on a circle or sphere does not have data or control dependency on others, since all circles or spheres are already given. As a result, finding permitted arcs or regions can be implemented in a fully parallel manner.The permitted arcs on circles are computed in two steps. First, we compute the forbidden arcs for each circle by checking its neighboring circles. Then, we sort all forbidden arcs and compute the permitted arcs as mentioned in Section  2. Algorithm 1 shows the pseudocode of finding permitted arcs on circles.For the 3D case, we first compute the intersection discs between spheres and then apply the procedure FindPermittedArcsForCircle() to obtain the permitted arcs on each sphere. Note that the Poisson disk on a sphere is a geodesic disk and the distance between two disks is also measured by geodesic distance. As the geodesic distance on the sphere can be computed analytically, the computation of the angles(α,β)depends only on the radii and the distances between two discs, which is the same as the 2D case. Algorithm 2 shows the pseudocode of finding permitted arcs on spheres.Once the permitted arcs or regions are found, we randomly create a Poisson disk candidate for each permitted arc. Similar to  [20], each candidate is assigned a random and unique priority that is unbiased with regard to the distribution. Hence, multiple threads can process the candidates simultaneously and resolve conflicts by checking the given priority values. The candidates with the higher priority win and are accepted as Poisson disks.After inserting new Poisson disks, we update the permitted arcs or regions and then repeat this procedure until the list of permitted arcs or regions is empty. Fig. 3illustrates the pipeline of our algorithm inR2. Algorithm 4 shows the pseudocode for improving the maximal property of Poisson disk sampling.Borrowing the idea of detecting the forbidden and allowed regions inR2, we propose the algorithm for improving the maximal property of Poisson disk sampling on surfaces. The permitted arcs and the allowed region are defined geodesic circles of radius2r. See the region bounded by red arcs in Fig. 5. However, it is difficult to maintain the arcs due to the lack of the global coordinate system. Observing that the local region is usually very small, we can parameterize the local neighborhood of a Poisson disk and then adopt the existing 2D technique to compute the permitted arcs on surfaces.We adopt the exponential map for our local parameterization. The exponential map defines the geodesic polar coordinate on the surface, which allows us to parameterize the surface locally. The exponential map at the pointpsends a ray on the tangent plane to a unique geodesic curve on the surface. It is bijective on the local neighborhood ofp. Fig. 4shows an example of exponential map on a synthetic surface. We modify the ICH algorithm  [24] such that it can compute both the geodesic distance and the direction of the geodesic path back to the source point. This allows us to build the geodesic polar coordinate system as the local parameterization.Given a dense but non-maximal Poisson disk sampling on the surface, we compute the permitted arcs for each disk as follows: for each diskDi=(ci,ri), we run the ICH algorithm  [24] to compute the exponential map which covers a disk centered atciand with radius(ri+rmax+2r), wherermaxis the maximal radius among all existing Poisson disks, andris the radius of the disk we wish to insert. When computing the exponential map, we can collect all disks that forbidDi, i.e., generating forbidden arcs onDi′=(ci,ri+r). Then we can compute the permitted arcs ofDi′on the tangent plane ofci(see Fig. 5(b)). For surface sampling, each new sample is created on a permitted arc lying on the tangent plane. Thus, we need to project them back onto the surface (again) by using the exponential map. Algorithm 3 shows how to find the permitted arcs on surfaces.Performance. We tested our algorithm on a PC with an Intel Xeon 2.66 GHz CPU and 12 GB memory. The graphics card is an Nvidia GTX580 with 512 CUDA cores and 1.5 GB GPU memory. Our program is compiled using CUDA 4.0. Our algorithm is fully parallel and highly efficient, which is able to generate up to 8 million 2D samples per second, 0.55 million 3D samples per second and 50 thousand surface samples per second. See Fig. 11 for the performance curve. Our method significantly outperforms the existing maximal Poisson disk sampling algorithms  [10,17,4] in terms of speed.Quality. Fig. 7 shows our maximal sampling results inR2andR3. Fig. 6shows the maximal sampling on various 2D shapes. Fig. 9 shows the maximal Poisson disk sampling on surfaces. Fig. 10 shows the frequency spectrum analysis, radial mean and anisotropy of a set of sampling withr=0.003. The radial mean and anisotropy in each row are obtained by running the experiments 10 times and then taking the average. The first row shows the result generated by the maximal sampling algorithm  [21], which is considered as the ground truth. Our algorithm takes inputs with various number of samples and then improves the maximal property by adding new samples on the permitted regions. The value marked in each row is the percentage of the Poisson disk samples added by our algorithm. Our algorithm produces comparable results to the ground truth when the newly samples are less than 20% of the total samples. All of our anisotropy plots are centered around the −10 dB line. Such a good quality is due to the fact that our algorithm takes the accurate sampling result of  [20] as input, which is usually dense enough and close to the maximal sampling.Clearly, the number of samples added by our algorithm depends on the density of the input sampling. The denser the input sampling, the closer it is to the maximal sampling, and the less number of samples added by our algorithm. Fig. 8shows the percentage of the new samples added by our algorithm with respect to the density of the input Poisson disk distribution.The quality of our results also depends on the density of the input sampling, since our method adds the new samples only on the boundary of the allowed region rather than in its interior region. As a result, the generated Poisson disk distribution is biased. If the input sampling is close to the maximal distribution, each allowed region is very small and our method works very well. As shown in rows 2–4 in Fig. 10, when there are less than 20% new samples added by our algorithm, both the radial mean and anisotropy plots are very close to the ground truth. However, if the input sampling is very sparse, adding the samples to the boundary of the allowed region leads to a biased distribution. As a result, the high frequency part of the radial mean plot is very different from the ground truth. See the last two rows in Fig. 10.Exponential map for surface sampling. Our surface sampling algorithm parameterizes each disk’s local neighborhood by using the exponential map, and maintains the permitted arcs and allowed regions on the tangent plane. We adopt the discrete exponential map in the surface sampling mainly because of its simplicity, robustness and good performance. However, note that the exponential map is in general not bijective due to two reasons: first, the globally shortest geodesic path between two points may not be unique, especially when the two points are far from each other. The point where two globally shortest geodesic paths meet is called a cut point, which has two different polar angles. Second, when passing through a saddle vertex (with a total angle more than2π), the inbound geodesic path may split into two or more outbound paths. As a result, all these outbound paths share the same polar angle. In spite of the theoretical defects, we have observed that the exponential map is highly efficient and works very well in practice when the radius of the geodesic disk is small e.g., less than 5× the mean edge length.Fig. 12shows an example of a geodesic disk with large radius (6% of the model diagonal), where the non-bijectivity occurs at the regions away from the center. We want to point out that regardless of the bijectivity of the exponential map, the geodesic distance between two Poisson disks is guaranteed to be greater than or equal to2r.Limitations. Our method cannot guarantee that the resulting sampling is free of bias. This is because our method inserts new samples only on the boundaries of the permitted regions. Ideally, these new samples should be distributed randomly inside each permitted region. In practice, if the input sampling is dense, the permitted regions are relatively small compared to the entire sampling domain. Thus, such bias of the distribution of new samples is very tiny and can be ignored. But if the input sampling is sparse, the distribution bias can compromise the quality of our result. See the last row in Fig. 10. Also, our current implementation is limited to 2D and 3D. Although the idea can be extended to higher dimensional space by recursively reducing the problem fromRdtoRd−1, the implementation would be difficult.There are many elegant algorithms for producing Poisson disk distributions. Table 1compares our method with the existing work in terms of the sampling domain, maximal property, performance and parallel structure. Some algorithms  [16,10,17] guarantee to the maximal condition. However,  [16,10] are sequential algorithms. Ebeida et al.’s algorithm  [17] can be implemented in parallel, but its performance is not as good as ours. In the following, we compare our method with the representative works on parallel sampling.The phase group method, proposed by Wei  [18], is the first parallel Poisson disk sampling technique, which subdivides the sample domain into grid cells and then draws samples concurrently from multiple cells that are sufficiently far apart so that their samples cannot conflict with one another. The phase group method is highly efficient and works for the Euclidean space of arbitrary dimension. However, the generated distribution is not fully random since the sequence of processing the phase groups follows a predefined order. Also, it does not produce maximal Poisson disk sampling. Ying et al.  [20] presented another parallel algorithm which does not require the space partition and guarantees that the distribution is bias free. But their method does not produce maximal sampling either. Our approach extends  [20] by efficiently checking the permitted regions in the sampling domain and then inserts additional samples.Ebeida et al.  [21] proposed a method to generate maximal Poisson disk sampling inRdin a parallel manner. Their idea is to maintain an implicit flat quadtree data structure to keep track of uncovered regions of the domain. The grid cells are further refined (subdivided) during the iteration. A cell is discarded if it is fully covered by a sample. The algorithm terminates when no more active cells remain. Their method also guarantees the maximal distribution and their parallel implementation on GPU is practical forR2andR3. However, it is unclear whether their quadtree structure can be extended to curved surfaces, since there is no natural way to maintain such grid cells as well as quadtree tessellation on arbitrary surfaces.Our parallel algorithm takes a different strategy. We observe that it is expensive to maintain any spatial data structure to track the uncovered region throughout the whole sampling process. In fact, the existing parallel algorithms  [19,18] are highly efficient. Although they are not maximal, the generated distributions are close to the maximal distribution. Thus, we take the non-maximal sampling distribution as input and improve its maximal property in a relatively low cost. Our implementation on the GTX580 can produce 5M samples/s in 2D and 400k samples/s in 3D, while Ebeida et al.’s  [21] algorithm on the GTX580 is able to achieve a speed of 1.7M samples per second in 2D or 130k samples per second in 3D.Note the actual number of samples produced by both  [21] and our algorithm is subject to the available memory on the GPU. Our method is memory more efficient than  [21], since their algorithm needs to maintain a large amount of active cells. For example, given the 1.5 GB memory on the GTX580, their approach can produce at most 900k 2D samples and 300k 3D samples, while our method can make 4.7M 2D samples and 1.7M 3D samples respectively.Very recently, Yan and Wonka  [22] proposed an algorithm for generating maximal Poisson disk sets with varying radii. It takes a non-maximal Poisson disk distribution as input, then detects gaps and updates gaps when the disk distribution is changed. Based on regular triangulations and the power diagram, Yan and Wonka’s algorithm is elegant and works well in both Euclidean space and manifolds. However, their algorithm is not fully parallel since it requires sequential steps, such as regular triangulation and gap clustering. As a result, the implementation of Yan and Wonka’s algorithm on the GPU would be difficult. To compare the performance, we re-implemented the 2D version of their algorithm on a multi-core CPU, where we adopted the CGAL to compute the 2D regular triangulation and the OpenMP library for the parallel gap filling as suggested in  [22]. Their algorithm on the Intel Xeon 2.66 GHz CPU produces 380k samples per second, while our algorithm on the Nvidia GTX580 generates 4M samples per second. We also compared the performance of surface sampling. As reported in  [22], it takes 23.7 s on the 3.33 GHz X5680 CPU for their algorithm to produce 12k samples (with varying radii) on the Bunny model, while our method takes only 2.7 s on the GTX580 to produce similar number of samples (with fixed radius).

@&#CONCLUSIONS@&#
