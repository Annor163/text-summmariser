@&#MAIN-TITLE@&#
Sparsity-promoting polynomial response surface: A new surrogate model for response prediction

@&#HIGHLIGHTS@&#
A new high-fidelity surrogate model for response prediction is proposed here.A series of Legendre polynomials is selected as basis functions whose number is compatible with the sample size.With the “sparsity-promoting” regression method, both the global trend and a reasonable local accuracy are captured.All parameters involved in the surrogate model are automatically determined.A comprehensive comparison between the surrogate model and several representative surrogate models is presented.

@&#KEYPHRASES@&#
Sparsity-promoting,Legendre polynomials,Overfitting,Surrogate model,Response prediction,

@&#ABSTRACT@&#
Computation-intensive analyses/simulations are becoming increasingly common in engineering design problems. To improve the computation efficiency, surrogate models are used to replace expensive simulations of engineering problems. This paper proposes a new high-fidelity surrogate modeling approach which is called the Sparsity-promoting Polynomial Response Surface (SPPRS). In the SPPRS model, a series of Legendre polynomials is selected as basis functions, and its number is compatible with the sample size so as to enhance the expression ability for complex functional relationships. The coefficients associated with basis functions are estimated using a “sparsity-promoting” regression approach which is an ensemble of two techniques: least squares and ℓ1-norm regularization. As a result, only these basis functions relevant to explain the function relationship are picked out, and that dedicates to ease the problem of overfitting for training points. With the sparsity-promoting regression approach, such a surrogate model intends to capture both the global trend of the functional variation and a reasonable local accuracy in the neighborhood of training points. Additionally, Latin hypercube design (LHD) is proved conducive to improving the predictive capability of our model. The SPPRS is applied to seven benchmark test functions and a complex engineering problem. The results illustrate the promising benefits of this novel surrogate modeling technique.

@&#INTRODUCTION@&#
Despite the tremendous promotion in computer processing power, optimization-aided design in real-world problems is usually time consuming and computationally expensive in the evaluation of objective functions [1]. Just taking a single crash testing simulation for example, it is reported that it requires several hours even when performed in a parallel processing environment [2]. Other engineering problems, such as analyses in aircraft multidisciplinary design and optimization (MDO) and the design of structures or a structural component in civil engineering, also require large amounts of computation time. To meet the challenge of increasing model complexity, surrogate models, also called “metamodels”, have been widely used to replace the expensive simulation models [3].A wide variety of surrogate models have been developed in the last few decades. Among these models described in relevant literature, Polynomial Response Surface (PRS) [4] is commonly used and relatively easy to be established. The coefficients of PRS are usually determined according to a least squares procedure. Kriging was developed for modeling spatial data collected in the geo-sciences [5], and then Sacks et al. [6] utilized Kriging to model data from computer experiments. The core idea of Kriging is combining a global regression model and a stochastic model into one interpolation model. Radial Basis Functions (RBF) [7,8] are an interpolating method on all data points. The response of RBF is a linear sum of basis functions with weights which can be estimated by solving a system of linear equations. In addition, there are also other types of surrogate models, including Multivariate Adaptive Regression Splines (MARS) [9], Support Vector Regression (SVR) [10,11], Artificial Neural Network (ANN) [12], etc. In general, PRS is unsuitable for the non-linear, multi-modal, multi-dimensional design landscapes we often encounter in engineering unless the ranges of the variables being considered are reduced, as in trust-region methods [13]. Compared with PRS, RBF provides more accurate results for more non-linear and high-dimensional objective functions, but it takes more computational expense [14]. Kriging has a better performance on non-linear problems than other models due to its excellent ability to interpolate training data and filter noisy data. However, Kriging is difficult to be established and used because a global optimization process is applied to identify the maximum likelihood estimators [15]. SVR was used and tested in [10], which showed that SVR achieved a higher accuracy over all other metamodeling techniques including Kriging, PRS, MARS, and RBF on a large number of test problems. The fundamental reasons why SVR surpasses the others, however, are not clear. In summary, each surrogate model has its own superiorities and defects; therefore, these models present widely different levels of numerical fidelity for various types of problems. More comprehensive reviews of different surrogate models can be found in [16–18].Because of limitations existing in these models mentioned above, some literature proposed the enhanced versions, for example, Moving Least Squares (MLS) (also called Locally Weighted Regression) [19,20], Blind Kriging (BK) [21,22], Extended Radial Basis Functions (ERBF) [23], and so on. To make full use of the resources available for surrogate modeling and eliminate the negative impact brought by poorly fitted models, several kinds of hybrid surrogates were developed in [3,24,25]. Although many efforts have been made to ameliorate the performances of pre-existing models, there are still some deficiencies in these models as following: (i) when constructing a PRS or a Kriging model, the highest order of polynomials is hard to determine without priori information on simulation model, and an inappropriate choice may result in overfitting for training data [26]; (ii) in the PRS model, the coefficients of polynomials are determined by an ordinary least squares estimate which has low bias but large variance [27]; and (iii) some parameters, such as the correlation parameters of Kriging, the parameter c in RBF and the kernel’s parameters of SVR, are generally obtained by a time-consuming procedure based on cross-validation errors [28].Motivated by the previous research, this paper provides a novel approach to develop a new surrogate model, which is called the Sparsity-promoting Polynomial Response Surface (SPPRS). In this model, a series of Legendre polynomials is selected as basis functions, and its number is compatible with the sample size. The coefficients of basis functions are estimated using a “sparsity-promoting” regression approach which is a combination of the least squares procedure and the ℓ1-norm regularization method. Potential benefits of this surrogate model include:•The model has a more powerful ability in distilling correct trends from data set due to its adaptive basis functions.With the “sparsity-promoting” regression approach, this model only picks out these basis functions which are relevant to characterize the function relationship, and that contributes to easing the problem of overfitting for training points.Combined the least squares procedure with the ℓ1-norm regularization, both the global trend of the actual response and a reasonable local accuracy in the neighborhood of training points are captured.All parameters involved in the model are automatically determined.The rest of the paper is organized as follows. In the next section, we present a brief review of Polynomial Response Surface (PRS). Section 3 gives the formulation of this new surrogate model. Then, we discuss the test problems, numerical experiments, and the results supporting our viewpoints. Finally, the paper comes to an end with the summary of some significant conclusions.

@&#CONCLUSIONS@&#
This paper develops a new surrogate modeling technique which intends to simultaneously capture the global trend of the functional variation as well as a reasonable local accuracy. The Sparsity-promoting Polynomial Response Surface (SPPRS) are mainly based on the following features: (i) the number of basis functions is compatible with the sample size; (ii) the Legendre polynomials are selected as basis functions; (iii) the coefficients associated with basis functions are estimated with the sparsity-promoting regression method; and (iv) all parameters involving this model are determined by the model itself. The performance of the surrogate model is assessed using three standard prediction metrics: (i) Root Mean Squared Error (RMSE); (ii) Maximum Absolute Error (MAE); and (iii) correlation coefficient (R).The effectiveness of the SPPRS surrogate model is tested on a series of benchmark functions as well as a real-world problem-the sandwich panel design problem. Preliminary results show that SPPRS can provide good approximations to most test problems considered in our research. From the comparison between SPPRS and LPRS, we find that the “sparsity-promoting” term indeed helps to construct a better model in most situations. Additionally, we also give a useful insight into the performances of several classic approaches.Although the technique proposed in this paper has achieved desirable results, several points should be noted: (i) because the number of basis functions for each order is a combinatorial number with respect to the number of variables and the order, the SPPRS model is more suitable for high-dimensional and low-order problems or low-dimensional and high-order problems; (ii) the SPPRS model should be more robust in response prediction; and (iii) other prediction metrics that can better represent the prediction ability over the entire design space should be investigated. Besides addressing these limitations, future work should include the application of the developed surrogate model to a more diverse set of test problems, to show potential benefits of the method.