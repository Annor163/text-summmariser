@&#MAIN-TITLE@&#
Cooperative estimation of human motion and surfaces using multiview videos

@&#HIGHLIGHTS@&#
We capture human motion and recover the details of surfaces by image based system.Our method is efficient for motion tracking in a high dimensional search space.Local memorization guides to search for the optimal solution that avoids local minima.Self-intersection detection and voxel sampling reduce the computing time.A refinement method is presented to adjust captured motion and surfaces cooperatively.

@&#KEYPHRASES@&#
Articulated human motion,Annealed particle filter,Surface estimation,Model segmentation,

@&#ABSTRACT@&#
We propose a human motion tracking method that not only captures the motion of the skeleton model but also generates a sequence of surfaces using images acquired by multiple synchronized cameras. Our method extracts articulated postures with 42 degrees of freedom through a sequence of visual hulls. We seek a globally optimized solution for likelihood using local memorization of the “fitness” of each body segment. Our method efficiently avoids problems of local minima by using a mean combination and an articulated combination of particles selected according to the weights of the different body segments. The surface is produced by deforming the template and the details are recovered by fitting the deformed surface to 2D silhouette rims. The extracted posture and estimated surface are cooperatively refined by registering the corresponding body segments. In our experiments, the mean error between the samples of the deformed reference model and the target is about 2cm and the mean matching difference between the images projected by the estimated surfaces and the original images is about 6%.

@&#INTRODUCTION@&#
Kinematic human body motion capture and 3D spatiotemporal surface reconstruction, in particular for fast-motion clips, from synchronous multicamera or multiview video sequences, are challenging and fundamental problems for many applications, including 3D animation, movies and games, medical diagnostic motion analysis, and robot motion simulation. Unlike marker-based motion capture systems, which require people to wear skintight clothing with markers, the multiple images in a markerless system can be utilized to generate not only the human motion data, but also realistically complex surfaces, even if loose apparel is worn.Markerless human motion tracking has been studied recently in the context of computer graphics and computer vision. Features such as texture and depth information are generally utilized to calculate correspondences between neighboring frames. It is intuitive to represent human motion in terms of articulated skeleton models by angle rotations of joints and global translation. A sequence of surfaces can then be recovered easily via a skinning method such as linear blend skinning (LBS) or quaternion blend skinning (QBS).In this paper, we employ a volumetric model [1] for 3D pose estimation that is generated directly from multiview images. There are typically about 80,000 voxels for each model, of which about 5% are chosen for motion tracking to reduce the computational cost. The segmented volumetric model of the previous frame is assigned 42 degrees of freedom (DOFs) as a reference volumetric model. It is deformed to discover the corresponding segments in the target model and, simultaneously, to label it for local-matching calculations. A segmented template surface with an underlying skeleton of the first frame is used for surface reconstruction while the articulated posture is extracted.Our method captures the motion of the skeleton model and estimates the 3D surface in a temporal sequence by revealing the correspondences between a presegmented volumetric model and the current frame. The detail in the final surface is recovered using the estimated motion data and silhouette constraints. The contributions of this paper can be summarized as follows:•The template mesh is decomposed into 15 body parts for skin attachment estimation and visual hull segmentation; then, the human motion data can be calculated by revealing the correspondences between a segmented volumetric model and that in the current frame. Our approach is also efficient even when there is no texture information.Aiming to avoid the problem of local minima, we propose a global optimization approach to track human motion. Although global optimization approaches can avoid the local-misalignment problem, it is usually time-consuming and still hard to obtain an optimal solution for tracking, in particular in a high-dimensional search space. Therefore, we propose a modified particle filter method for faster convergence by memorizing the mean squared distance between the samples in the reference and in the current frame for each body segment, and combining them to produce new particles to track the posture of the target. A sampling method for voxel selection is provided to reduce the computational cost, while ensuring that the selected voxels are spread across all the human segments. In addition, a self-collision detection method is utilized to search for real particles in the tracking process.It is reasonable to generate the surface in terms of the previous one, as it will provide a good approximation to the current frame. However, this can cause an error accumulation problem, making it difficult to recover from an error originating in the previous surface. We reduce the accumulation error by simultaneously refining the posture and surface detail in terms of comparison with the posture and surface detail of the first frame using a registration method.This paper is organized as follows. Section 2 explains the related work in this field. Section 3 outlines our method for motion tracking and surface reconstruction. The segmentation methods for the template mesh surface and volumetric models are described in Section 4. The sampling method is described in Section 5. In Section 6, a motion tracking method that aims to generate particles with global optimization and local memorization is introduced. Section 7 introduces the Laplacian deformation framework used to recover the surface details, which forces the reverted 2D images obtained by the estimated surface to match the silhouettes. We propose a cooperative method of refining the captured human motion and generating the reference surface for the next frame in Section 8. We present our experimental results, summarize them and discuss future work in Sections 9 and 10.

@&#CONCLUSIONS@&#
