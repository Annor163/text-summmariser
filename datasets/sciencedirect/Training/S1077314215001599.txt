@&#MAIN-TITLE@&#
Sequential Interval Network for parsing complex structured activity

@&#HIGHLIGHTS@&#
SIN parses structured activity sequence (or time series data in general).SIN is not a time sliced graphical model.SIN is equivalent to a left-right segmental model (HSMM) and allows exact inference.

@&#KEYPHRASES@&#
Activity parsing,Activity prediction,Action recognition,Stochastic context-free grammar,Sequential Interval Network,

@&#ABSTRACT@&#
We propose a new graphical model, called a Sequential Interval Network (SIN), for parsing complex, structured activities whose composition can be represented by a stochastic grammar. By exploiting the grammar, the generated network captures an activity’s global temporal structure while avoiding a time-sliced manner model. In this network, the hidden variables are the start and end times of the component actions, which allows reasoning about duration and observation on interval/segment level. Exact inference can be achieved and yield the posterior probabilities of the timing variables as well as each frame’s component label. Importantly, by using uninformative expected value of future observations, the network can predict the probability distribution of the timing of future component actions. We demonstrate this framework on vision tasks such as recognition and temporally segmentation of action sequence, or parsing and making future prediction online when running in streaming mode while observing an assembly task.

@&#INTRODUCTION@&#
This paper addresses the problem of parsing complex structured activity. By complex activity, we mean extended sequences of multiple component actions, as opposed to being visually complex or how unconstrained the video is. By structured, we mean the extended composite activities are formed by a concatenation of actions whose sequencing are typically constrained by rules. For a variety of activity monitoring tasks ranging from surveillance to work-flow monitoring to quality control inspection, the challenge is to observe some complex activity being performed and to be able to label which action has been performed and often to parse or segment the input sequence into its component actions. Additionally, if a system is intended to respond appropriately and at the correct time with respect to an activity, it is necessary to perform such parsing while the activity is occurring and predict when a component action is like to occur; examples of this last task are seen in the domain of human robot interaction [1,2].Considering the problem of parsing complex structured activities, we recursively define such activities to be compositions of some combination of (sub-)activities and primitive actions. We presume as given the temporal structure and decomposition of the activity, such as a task plan of an assembly process where there may be partially ordered or even optional steps. We further assume that probabilistic low level visual detectors are provided or learned from training examples; these detectors provide noisy evidence as to occurrence of some primitive action. The goal is to develop a probabilistic representation of such activities that leverage the temporal constraints and local sensing and which allows the system to assess, at any moment in time, the probability as to which actions have occurred or will occur and when.The pipeline of our framework is shown in Fig. 1. The input grammar is used to generate a graphical model whose variables encode the start and end times of component actions. All the conditional probability tables (CPT) will be constructed from learned prior probabilities of the primitive actions’ duration and from evidence provided by primitive action detections. Finally exact inference is performed by a forward–backward message passing algorithm. The output of our network will be the posterior probabilities of which of the different courses of actions took place, and the timing of each action, which can be used for recognition and future prediction. From this, we can also compute the posterior of each frame’s label and perform temporal segmentation.It should be noted that our main contribution is not really activity recognition, but a framework for combining available detection result of different component actions leveraging the temporal relationship between them. On previously recorded data, the method can be used as a post-processing step of raw-detection results in place of, say, the common sliding window, non-maxima suppression. In streaming mode, the system can be used to make predictions about which and when different actions are likely to occur. Our method is only applicable when there is known temporal structure information to be exploited. Presented here is an enhanced version of our previous conference paper [3] where we have added more detail and discussion, as well as additional experiments to validate the proposed method.We organize this paper as follows. The related work is discussed in the next section. After describing the grammar representation for modeling the temporal structure of the activity in Section 3, we introduce our graphical model in Section 4 and the inference mechanism in Section 5. In Sections 6 and 7, we perform different activity recognition experiments. Finally we conclude in Section 8.

@&#CONCLUSIONS@&#
