@&#MAIN-TITLE@&#
Robust face hallucination using ensemble of feature-based regression functions and classifiers

@&#HIGHLIGHTS@&#
Propose an example-based face hallucination framework.Proposed ensemble learning for face hallucination.Reconstruct both global and local facial features.Individual ambiguity of system low-resolution inputs is considered in this framework.

@&#KEYPHRASES@&#
Principal component analysis (PCA),Canonical correlation analysis (CCA),Eigenfaces,Facial hallucination,

@&#ABSTRACT@&#
An example-based face hallucination system is proposed, in which given a low-resolution facial image, a corresponding high-resolution image is automatically obtained. In practice, such a problem is extremely challenging since it is often the case that two discriminative high-resolution images may have similar low-resolution inputs. To address this issue, this study proposes an ensemble of image feature representations, including various local patch- or block-based representations, a one-dimensional vector image representation, a two-dimensional matrix image representation, and a global matrix image representation. Notably, some of these representations are designed to preserve the global facial geometry of the low-resolution input, while others are designed to preserve the local detailed texture. For each feature representation, a regression function is constructed to synthesize a high-resolution image from the low-resolution input image. The synthesis process is conducted in a layer-by-layer fashion, with the output from one layer serving as the input to the following layer. Importantly, each regression function is associated with a classifier in order to determine which regression functions are required in the synthesis procedure in accordance with the particular characteristics of the input image. Furthermore, these classifiers can also help to deal with the individual ambiguity of system low-resolution inputs. The experimental results show that the proposed framework is capable of synthesizing high-resolution images from low-resolution input images with a wide variety of facial poses, geometry misalignments and facial expressions even when such images are not included within the original training dataset.

@&#INTRODUCTION@&#
The images captured by a camera in the real-world are often affected by such factors as unfavorable occlusion, poor lighting conditions, low resolution, and so on. Consequently, the images are unsuitable for such applications as facial recognition, humanâ€“computer interaction, or image retrieval. Accordingly, the problem of super-resolution has emerged as a major research topic in the computer vision field. Among the various applications reliant on super-resolution technology, that of face hallucination, in which a low-resolution facial image is converted into an equivalent high-resolution image, is of particular interest since it serves as an important preprocessing step for many face-related applications, including face recognition [4,38] and facial animation [15,18,35].Broadly speaking, super-resolution methods can be classified as either single-image-based super-resolution schemes or example-based schemes. Methods of the former type require just one low-resolution input image, and include such methods as the interpolation-based method [1], the high-frequency enhancement-based method [6,22], and the edge enhancement method [26,34]. By contrast, example-based methods require multiple training examples in order to construct the knowledge required to synthesize a high-resolution image for an unseen input. Typical methods of example-based approach include those proposed in [8,10,13]. Facial images have a specific structure, and consequently most existing face hallucination methods adopt an example-based approach. More specifically, through the assistance of multiple training examples, the synthesis system learns the global and local facial geometry and local detailed texture which characterize the human face and then uses this information to predict (synthesize) the high-resolution facial image for any unknown low-resolution image.The proposed framework is the example-based facial hallucination method, where the aim is to synthesize a high-resolution image which resembles the original low-resolution image to the greatest extent possible. In practice, such a process is extremely challenging since it is often the case that two discriminative high-resolution images may have similar low-resolution inputs. To address this issue, our framework composes an ensemble of image feature representations to include both the global facial geometry and the local geometry/detailed texture information. Notably, that the global facial geometry describes the relative positions and sizes of the individual facial features and facial contours, while the local geometry/detailed texture information describes the skin texture or specific characteristics of the facial features, such as large eyes, double-fold eyelids, and so on. The proposed synthesis process is conducted in a layer-by-layer fashion, with the output from one layer serving as the input to the following layer. Here, each layer composes several regression functions, and each regression function is constructed based on a specified feature representation. Importantly, in order to deal with the individual ambiguity of system synthesized results, each regression function is associated with a classifier that determines if such regression function is required in the synthesis procedure in accordance with the particular characteristics of the input image.

@&#CONCLUSIONS@&#
This study has proposed a face hallucination framework in which the high-resolution image of an unseen input low-resolution image is synthesized using a multiple-layer structure based on an ensemble of facial regression functions. The experimental results have shown that the proposed approach has three major advantages compared to existing face hallucination schemes. First, the proposed framework preserves not only the global geometric structure of the face, but also the local detailed texture. Consequently, the synthesized high-resolution images more accurately resemble the corresponding ground-truth image. Second, the synthesized images are virtually immune to the presence of external factors such as variable misalignments, different input image resolutions, or dataset changes due to the use of an ensemble of feature representations and regression functions and the subsequent weighted linear combination of the synthesis results obtained using each function. Third, images with a wide variety of facial poses and facial expressions can be successfully synthesized even when such images are not present in the training dataset. In a future study, the capabilities of the proposed framework will be enhanced by cooperating with other robust kernel functions and more feature representations.