@&#MAIN-TITLE@&#
Metaheuristic algorithms for approximate solution to ordinary differential equations of longitudinal fins having various profiles

@&#HIGHLIGHTS@&#
Approximate solutions to ordinary differential equations (ODEs) in engineering.Fourier series with the aid of metaheuristics used as suggested approximate method.The GA, PSO and HS are utilized for optimization purposes.Obtained approximate solutions by the proposed method confirm the results by others.Proposed approach offers acceptable accuracy for a wide range of ODEs.

@&#KEYPHRASES@&#
Metaheuristics,Analytical solution,Weighted residual function,Approximate solution,Fourier series,Longitudinal fins,

@&#ABSTRACT@&#
Differential equations play a noticeable role in engineering, physics, economics, and other disciplines. Approximate approaches have been utilized when obtaining analytical (exact) solutions requires substantial computational effort and often is not an attainable task. Hence, the importance of approximation methods, particularly, metaheuristic algorithms are understood. In this paper, a novel approach is suggested for solving engineering ordinary differential equations (ODEs). With the aid of certain fundamental concepts of mathematics, Fourier series expansion, and metaheuristic methods, ODEs can be represented as an optimization problem. The target is to minimize the weighted residual function (error function) of the ODEs. The boundary and initial values of ODEs are considered as constraints for the optimization model. Generational distance and inverted generational distance metrics are used for evaluation and assessment of the approximate solutions versus the exact (numerical) solutions. Longitudinal fins having rectangular, trapezoidal, and concave parabolic profiles are considered as studied ODEs. The optimization task is carried out using three different optimizers, including the genetic algorithm, the particle swarm optimization, and the harmony search. The approximate solutions obtained are compared with the differential transformation method (DTM) and exact (numerical) solutions. The optimization results obtained show that the suggested approach can be successfully applied for approximate solving of engineering ODEs. Providing acceptable accuracy of the proposed technique is considered as its important advantage against other approximate methods and may be an alternative approach for approximate solving of ODEs.

@&#INTRODUCTION@&#
Mathematical formulation of most physical and engineering problems involves differential equations (DEs). The DEs have applications in all areas of science and engineering. Hence, it is important for engineers and scientists to know how to deal with the DEs and solve them. With regard to real life problems, which are highly nonlinear, many problems in engineering and science often include one or more ordinary differential equations (ODEs).Analytical approaches are often inefficient in tackling ODEs. Therefore, approximate analytical methods are applied to obtain estimated solutions of ODEs. A number of analytical methods have been utilized to develop approximate analytical solutions for engineering problems, such as the variational iteration method (VIM) [1,2], the homotopy analysis method (HAM) [3], the method of bilaterally bounded (MBB) [4], and the Adomian double decomposition method (ADM) [5,6].Differential transformation method (DTM), which is based on Taylor series expansion, as widely used approximate analytical method, was first introduced by Zhou [7] for solving linear and nonlinear initial value problems (IVPs) in electrical circuits. The DTM has been widely used to obtain accurate analytical solutions for nonlinear engineering problems [8–11].Recently, many studies have combined the concept of the DTM with finite difference approximation for increasing the capability of their approximate solution [12–14]. Further, approximate analytical procedures such as the VIM, homotopy perturbation method (HPM), and DTM have been combined with Padé approximation technique to overcome the disadvantages faced by these methods in certain cases [15].In particular, many studies have applied approximation methods for solving various types of integro-differential equations (linear/nonlinear) [16–20]. However, each of these numerical approximation techniques has its own operational limitations that strictly narrow its functioning domain. Hence, it is possible that these approximate techniques fail to overcome a specific problem.A few such instances are mentioned in the following. It was reported that the DTM was unable to produce physically reasonable data for the Glauert-jet Problem [11]. Moreover, for some specific parameter values, the HPM and VIM failed to provide accurate results for the motion of a solid particle in a fluid [21,22]. Meanwhile, most of them are based on classical mathematical tools.Despite there being a wide range of approximate methods for solving ODEs, there is a lack of a proper approach that meets most of the engineering demands having unconventional and nonlinear ODEs. It should be very interesting to solve linear and nonlinear ODEs having arbitrary boundaries and/or initial values.Therefore, when analytical methods are not capable of solving differential equations or other types of equations in a logical given time, approximation methods are considered as the best solver. Among approximation methods, metaheuristic optimization algorithms, devised by observing the phenomena occurring in nature, have demonstrated their capabilities in finding near-optimal solutions to numerical real-valued problems [23–26].Nowadays, applications that use metaheuristic methods for finding approximate solution of ODEs have increased considerably. This includes genetic algorithms (GAs) [27,28], particle swarm optimization (PSO) [4], genetic programming [29], and others [30,31]; however, their approaches are different with each other in terms of applied strategy and base approximate function. For instance, in [4], different strategy named method of bilaterally bounded, has been employed along with the PSO.Recently, the concept of Fourier series expansion has been used as a base approximate function for finding the approximate solution of ODEs [32]. For the sake of simplicity, in their approach, the weight function was set to unit weight function [32]. However, this assumption may not help us in obtaining better results for all types of ODEs.Inspired by [32] and in order to improve the efficiency of the proposed approach, lately, Sadollah et al. [33] successfully applied weighted residual method for approximate solving of 10 ODE problems including mechanical vibration problems and more test ODE problems. Also, superiority of using new weight function (instead of using unit weight function) is shown and two metaheuristic algorithms (i.e., the PSO [34] and water cycle algorithm [35]) are utilized for optimization phase.In this paper, using the concept of Fourier series as the base approximate function, other optimizers, including the harmony search (HS) [36], PSO [34], and GA [37] are applied for approximate solving of real life ODEs longitudinal heat transfer fins having various profiles (i.e., rectangular, trapezoidal, and concave parabolic profiles) and properties (i.e., 14 ODEs). In addition, least square weight (LSW) function is proposed for solving the ODEs instead of considering unit weight function.The GA [37], known to be the most famous metaheuristic algorithms, has been applied for optimization phase. The reason of choosing PSO is that to apply the same optimizer to the considered engineering heat transfer problems as did others in the literature [4,32,33]. In case of HS algorithm, in light of its simple concept and coding, we selected this optimizer for having more comparisons.Talking about the considered ODE problems, extended or finned surfaces are extensively utilized in engineering applications where there is a need to increase heat transfer between a hot primary surface and an adjoining coolant. A comprehensive literature review on different facets of extended surface heat transfer theory and experiment over the past several decades has been carried out by Kraus et al. [38].Recently, Torabi et al. [39] investigated the approximate solving of convective-radiative longitudinal fins for different profiles and nonlinearities using the DTM. They compared their obtained approximate results with exact and numerical solutions. The approximated mathematical formulations for different profiles are given in their study [39].Consequently, the nonlinear fin equations have been solved either numerically or using a variety of approximate analytical methods. In this paper, we modeled convective-radiative longitudinal fin problems as an optimization problem and determined their approximate solution using the proposed method.The remainder of this paper is organized as follows: The next section describes problem formulation as a case study and its behavior in form of ODEs accompanied with its detail. In Section 3, suggested approximate approach for tackling considered problems (i.e., ODEs of longitudinal fins) and the applied optimization methods are explained in brief. In addition, the performance criteria for quantitative assessment among other methods are given in Section 3. Section 4 compares statistical optimization results using the suggested approach with the other approximation method. Graphical comparisons between the exact (numerical) and approximate solutions are demonstrated and the obtained approximate mathematical formulations are represented in this section. Finally, conclusions are drawn in Section 5.An array of rectangular fins is widely used in practice to enhance heat dissipation from a hot primary surface. The fin heat transfer model must include simultaneous surface convection and radiation. Fig. 1shows a longitudinal (straight) fin having rectangular, trapezoidal, and concave parabolic profiles, with length L.Each fin draws heat from its base at temperature Tb, and transfers it by convection to the surroundings at temperature Ta, and by radiation to an effective sink at temperature Ts. The fin thermal conductivity k, the convective heat transfer coefficient (h) and the fin surface emissivity (ɛ) are assumed to be functions of temperature of the forms as given follows:(1a)k=ka[1+α(T−Ta)],(1b)h=hbT−TaTb−Tam,(1c)ε=εs[1+β(T−Ts)],where kais thermal conductivity at the convection sink temperature Ta, hbis the convection heat transfer coefficient corresponding to the temperature difference (Tb−Ta), and ɛsis the fin surface emissivity at the radiation sink temperature Ts. The constants α and β are measures of variation of thermal conductivity and surface emissivity with temperature, respectively. Based on one-dimensional (axial) heat conduction in the fin, the general energy balance for longitudinal fins per unit width may be written as [39]:(2)kaddx[1+α(T−Ta)]t(x)dTdx−hbT−TaTb−Tam(T−Ta)−σεs[1+β(T−Ts)](T4−Ts4)=0.Note that the local semi-fin thicknesses is given by t(x)=tb+δ((x/L)n−1), where the exponent n=0, 1, 2 gives the local semi-fin thicknesses for rectangular, trapezoidal, and concave parabolic fins, respectively. The quantity tbis the semi-base thickness, while the quantity δ defines the fin taper (see Fig. 1). The boundary conditions of constant base temperature and adiabatic tip are given as follows:(3a)T(L)=Tb,(3b)dTdxx=0=0.Let us assume the following dimensionless parameters:(4)θ=TTb,θa=TaTb,θs=TsTb,X=xL,C=δtb,Nc=hbL2Tbmkatb(Tb−Ta)m,A=αTb,B=βTb,Nr=σεsL2Tb3katb,ψ=tbL.Therefore, the problem formulation for all three fin profiles considered has the following ODE form [39]:(5)ddX[1+A(θ−θa)][1+C(Xn−1)]dθdX−Nc(θ−θa)m+1−Nr[1+B(θ−θs)](θ4−θs4)=0,with the following boundary conditions:(6a)θ(1)=1,(6b)dθdXX=0=0.Eq. (5) shows that thermal performance (i.e., temperature distribution, fin heat transfer rate, fin efficiency, and fin effectiveness) of a longitudinal fin depends on eight parameters, namely, thermal conductivity parameter A, emissivity parameter B, the exponent m associated with convective heat transfer coefficient, convection-conduction parameter Nc, radiation-conduction parameter Nr, the two temperature ratios, θaand θs, that characterize the temperatures of convection and radiation sinks, and the fin taper ratio, C.In addition, we considered a longitudinal fin of constant cross-sectional area Ac, length L, and perimeter of the cross-section P. Similarly, using Eq. (1), and introducing the following dimensionless parameters:(7)θ=TTb,θa=TaTb,θs=TsTb,X=xL,Nc=hbL2PkaAc,A=αTb,B=βTb,Nr=σεsL2Tb3PkaAc,Eq. (5) transforms to the following ODE given as follows:(8)ddX[1+A(θ−θa)]dθdX−Nc(θ−θa)θ−θa1−θam−Nr[1+B(θ−θs)](θ4−θs4)=0,having different boundary conditions:(9a)θ(0)=1,(9b)dθdXX=1=0.In this paper, using the proposed approximation method, Eqs. (5) and (8) along with their boundary conditions (i.e., Eqs. (6) and (9)) have been approximately solved and have been compared with their numerical and exact solutions.In order to validate the obtained results with the exact solutions, we can consider the simple case of pure convection fins (Nr=0) of constant thermal conductivity of fin material (A=0) operating in a constant heat transfer coefficient (m=0) environment used in Eq. (5). For these fins, the exact analytical solutions with the considered boundary conditions (see Eq. (6)) can be derived as follows [39]:(a)For rectangular profile:(10a)θ(X)=C1eNcX+C2e−NcX+θa,For trapezoidal profile:(10b)θ(X)=C1J02−Nc1+C(X−1)C2+C2Y02−Nc1+C(X−1)C2+θa,For concave parabolic profile:(10c)θ(X)=C1P12C+4Nc−CCCXC(C−1)+C2Q12C+4Nc−CCCXC(C−1)+θa,Eqs. (5) and (8) along with the considered boundary conditions given in Eqs. (6) and (9) were solved numerically using a finite difference technique in conjunction with Richardson extrapolation using the Maple14.0. The iterative process was continued until a convergence criterion of 10−6 was satisfied [39].In mathematics, an ODE is an equality involving a function and its derivatives. An ODE of order n is an equation having the following form:(11)F(x,y,y′,…,y(n))=0,where y is a function of x, y′=dy/dx is the first derivative with respect to x, and y(n)=d(n)y/dx(n) is the nth derivative with respect to x. Nonhomogeneous ordinary differential equations can be solved if the general solution to the homogenous version is known [40].Fourier series is an expansion of a periodic function f(x) in terms of an infinite sum of sine and cosine terms. Fourier series employs the orthogonal relationships of the sine and cosine functions. The computation and study of Fourier series is known as harmonic analysis. This is extremely useful to decompose an arbitrary periodic function into a set of simple terms.Using some basic concepts of mathematics, accompanied with Fourier expansion, and metaheuristic methods, it is straightforward to solve different types of ODEs having different nature (linear/nonlinear) [32].In traditional method for solving DEs, most of the methods are invented to handle the first or second order ODEs, initial and boundary value problems. However, using the proposed approximate method, there are no such limitations. In fact, using the suggested approximate method in combination with metaheuristic optimizers, there is always an acceptable solution for any type of ODEs for higher orders in their implicit forms.Generally, using Fourier series, one can estimate any periodic function having finite terms. In this paper, we used Fourier series as our base approximate function. There are three main reasons for this selection: (1) A powerful theory backs its convergence for a wide variety of continuous functions [41]; (2) It contains sine and cosine terms, which are differentiable up to any order; and (3) A unique form of the approximation function can be utilized for different kinds of ODEs.To clarify further, consider the implicit form of a nonlinear ODE given in Eq. (11), which has to be solved for the interval span x0 to xn, having boundary and initial conditions as defined in Eq. (12), respectively:(12a)y(x0)=y0,y′(x0)=y′0…,y(xn)=yn,y′(xn)=y′n…,(12b)y(x0)=y0,y′(x0)=y′0…,y(n−1)(x0)=y0(n−1).In general, the suggested approximate base function, which is the partial sum of the Fourier series (finite simple terms of sine and cosine functions) with center x0, as follows [41]:(13)y(x)≈Yappx(x)=a0+∑m=1NTamcosmπ(x−x0)L+bmsinmπ(x−x0)L.Accordingly, the derivatives of Eq. (13) are given as follows:(14)y′(x)≈Y′appx(x)=∑m=1NT−mπLamsinmπ(x−x0)L+mπLbmcosmπ(x−x0)Ly″(x)≈Y″appx(x)=∑m=1NT−mπL2amcosmπ(x−x0)L−mπL2bmsinmπ(x−x0)L⋮y(n)(x)≈Yappx(n)(x)=∑m=1NTmπLnamcosmπ(x−x0)L+nπ2+mπLnbmsinmπ(x−x0)L+nπ2.In order to create a weighted residual function (R(x)), Eqs. (13) and (14) are replaced in Eq. (11). In these equations (Eqs. (12)–(14)), xoand xnare the lower and upper bounds of the interval solution; L is the length of the interval solution, which is x0−xn; NT is the number of approximation terms of the sine and cosine functions.Depending on the complexity of the ODEs, different values of NT may be used. It is worth pointing out that, by increasing the number of approximation terms (NT), the accuracy of the approximate solutions increases. However, in practice, using a large number, as NT increases the computational time and effort are increased, which is usually unnecessary.The unknown coefficients in Eq. (13) (i.e., a0, am, and bm), which are the coefficient of Fourier series, can be computed using metaheuristic optimization methods. The coefficients of Fourier series are considered as design variables of our optimization model for the ODEs.An optimization model requires an objective function to estimate the cost function (error) of the ODEs. In order to obtain a numerical measure of error, the weighted residual function (WRF) is considered as a cost function that needs to be minimized. In fact, the WRF assumes that a solution can be approximated analytically or piecewise analytically. The general mathematical form of the WRF is given as follows [42]:(15)WRF=∫D|W(x)|×|R(x)|dx,where W(x) and R(x) are called the weight and residual functions, respectively. R(x) is obtained by substituting the approximate function Y(x) and its derivatives for y(x), y′(x), …, and y(n)(x) in the implicit form of the Eq. (11) as follows:(16)R(x)=f(x,Y(x),Y′(x),...,Y(n)(x)).The optimum value of the cost function (i.e., the WRF given in Eq. (15)) is zero. In fact, the notion in the WRF is to force the residual to zero in some average sense over the domain. When the value of cost function approaches zero, better approximate solutions and more accuracy can be obtained.For solving the cost function given in Eq. (15), any numerical method such as the Trapezoidal or Simpson methods can be used. In this paper, the trapezoidal method is utilized for numerically solving the cost function. In the following section, new suggested approach for weight function is introduced.If the continuous summation of all the squared residuals is minimized, the rationale behind the name can be seen. In other words, a minimum of the following equation needs to be computed:(17)WRM=∫DR(x)×R(x)dx=∫DR2(x)dx,In order to achieve a minimum of this scalar function, the derivatives of the WRF with respect to all the unknown parameters must be zero. That is:(18)∂WRM∂ai=0=2∫D|R(x)|×∂R∂aidx.Therefore, the weight functions are seen to be:(19)Wi(x)=2∂R∂ai.However, the “2” in Eq. (19) can be dropped, because it cancels out in the equation. Therefore, the weight functions for the least squares method are the derivatives of the residual with respect to the unknown constants:(20)Wi(x)=∂R∂ai.The ODE problems in which values are specified at a particular value of y(x0) are called initial value problems (IVPs). There is another class of problems called boundary value problems (BVPs) in which conditions are given at both ends rather than merely at the initial point (x0).It is crucial for the approximate solution to satisfy the conditions of the IVPs and BVPs to fulfill the equation, simultaneously. The constraints for the ODE problems can be in the form of homogeneous or nonhomogeneous conditions. They are given as follows:For homogeneous conditions:(21)y(x0)=0⇒g1(x0)=Yappx(x0)−0y′(x0)=0⇒g2(x0)=Y′appx(x0)−0⋮y(n)(x0)=0⇒gn+1(x0)=Yappx(n)(x0)−0.For nonhomogeneous conditions:(22)y(x0)=y0⇒g1(x0)=Yappx(x0)−y0y′(x0)=y′0⇒g2(x0)=Y′appx(x0)−y′0⋮y(n)(x0)=y0(n)⇒gn+1(x0)=Yappx(n)(x0)−y0(n).Eqs. (21) and (22) represent the constraints of our optimization model. In this paper, all equality constraints were converted into inequality ones, |h(x)|−ɛ≤0 using the degree of violation ɛ=2.2e−16 that was taken from MATLAB. As a constraint handling approach, the absolute violations caused by the boundary or initial conditions (homogeneous or nonhomogeneous) are calculated. Afterwards, using the penalty function approach, the absolute values of imposed violations as penalty term are added to the objective function.To perform a fair quantitative evaluation and judgment between the approximate and exact (numerical) solutions, we investigated the generational distance (GD) and inverted generational distance (IGD) metrics, which are considered as assessment criteria widely used in the literature [43,44]. They were first presented by Veldhuizen and Lamont [45] and Zitzler et al. [46].The main objective of these criteria is to clarify the capability of the WRF and optimizers in finding an approximate solution having the least distance when compared with the exact (numerical) solution. Based on this definition, it is evident that the obtained approximate solution with the minimum GD and IGD has the best convergence to the exact (numerical) solution. These evaluation factors are defined in mathematical forms given as follows [43]:(23)GD=∑i=1ndi21/2n,(24)IGD=∑i=1ndin,where n is the number of points in the approximate solution, and d is the Euclidean distance between point i in approximate solution and the nearest point (minimum Euclidean distance) in the exact (numerical) solution. Lower values of GD and IGD imply that obtained approximate solution must be very close to the optimal Pareto front and cannot miss any part of the whole Pareto front. In this paper, for comparison purposes, the chosen value for n is set to 100 for the ODEs of longitudinal fins. This means that 100 candidate points in the approximate and exact (numerical) solutions are compared with each other in this paper. Fig. 2shows a schematic view of these performance metrics for evaluating the accuracy between the exact (numerical) and approximate solutions.In this section, different optimizers are explained in brief. For solving the ODEs using the approximate WRF method, metaheuristic algorithms can be considered as alternative approaches for finding unknown coefficients for the Fourier series. In this paper, metaheuristic algorithms including PSO, GA, and HS are used to find an approximate solution for the considered ODEs.Particle swarm optimization (PSO) is an evolutionary computation technique for solving the global optimization problems developed by Kennedy and Eberhart [34]. This computation technique functions through individual improvement, population cooperation, and competition. The PSO is based on the simulation of simplified social models, such as bird flocking, fish schooling, and the swarm theory.Researchers found that the synchrony of an animal's behavior was through maintaining optimal distances between individual members and its neighbors. The PSO exhibits common evolutionary computation attributes including initialization with a population of random solutions and searching for optima by updating generations [47].Potential solutions, called particles, are then flown through the problem space by following the current optimum particles. Each particle keeps track of the coordinates in the problem space that are associated with the best solution (fitness) it has achieved so far. This value is called pBest. Another best value, which is tracked by the global version of the PSO, is the overall best value and this location obtained is the best so far by any particle in the population. This location is called gBest.The PSO's concept consists of changing the velocity of each particle toward its pBest and gBest locations. Acceleration is weighted by a random term with separate random numbers being generated for acceleration toward pBest and gBest locations. The basic swarm parameters position and velocity are updated using the following equations [34]:(25)V→i+1=wV→i+c1r1(pBest→i−X→i)+c2r2(gBest→i−X→i),(26)X→i+1=X→i+V→i+1,where w is the inertia weight for previous velocity (between 0 and 1), Xiis the current position for particle i, Vi+1 is the updated velocity of particle i, pBestiis the best solution found by particle i, gBestiis the best solution found by the swarm, r1 and r2 are uniform random numbers in the range of [0,1], c1 is the cognitive component, and c2 is the social component.Here, c1 and c2 are the constants that influence how each particle is directed toward good positions by considering their personal best and global best information, respectively. The role of w is crucial for the convergence of the PSO. It is applied to control the effect of the previous velocity on the current particle velocity [47].Thus, the user-defined parameter w adjusts the trade-off between the global and the local searches in the PSO. A high value of w performs more exploration, while a low value increases the exploitation effects. A suitable value for the w provides balance between the global and local phases, and, thus results in finding better solutions. Based on the practical experiments, it is more desirable to primarily set the w to a large value for having more exploration at early iterations, and gradually decrease it to obtain refined solutions.Since the harmony search (HS) algorithm was first developed in 2001 [36], it has been applied to various research areas and obtained considerable attention in different disciplines [48]. The HS conceptualizes a musical process of searching for a perfect state of harmony. Musical performances seek a fantastic harmony determined by esthetic estimation, as the optimization techniques seek a best state (global optimum) determined by objective function value.Esthetic estimation is performed by the set of the sounds played by musical ensemble, as objective function value is evaluated by the set of the values produced by adjusted variables; the better esthetic sounds can be improved by constant practice, as the minimization/maximization of the objective function can mostly be improved by repeating iteration.More information about the HS can be found in the work of Geem et al. [36] and Kim et al. [49]. The main steps of the original HS are summarized as below:Step 1: Generate random vectors (x1, x2, …, xHMS) equal to the harmony memory size (HMS). Then, store them in harmony memory (HM).(27)HM=x11⋯xn1⋮⋱⋮x1hms⋯xnhmsf(x1)⋮f(xhms)The usage of HM is vital, as it is similar to the choice of the best-fit individuals in the GA. This will ensure that the best harmonies will be transferred to the new candidate solution. In order to use this memory more excellently, it is typically assigned as a user-defined parameter, so called harmony memory considering rate (HMCR, 0≤HMCR≤1). If this value is too low, only few best harmonies are selected and it may converge too slowly. If this rate is extremely high (near 1), almost all the harmonies are used in the HM, then other harmonies are not explored well, resulting immature convergence. Therefore, typically, proper value of HMCR is set from 0.7 to 0.98 [36].Step 2: Generate a new harmony. In generating a new harmony x′, for each componentx′i:•With probability HMCR, pick the stored value from the HM:x′i←xiint(u(0,1)×HMS)+1.With probability (1−HMCR), pick a random value within the allowed range.Step 3: Perform additional task if the value in Step 2 came from the HM.•With probability PAR (pitch adjusting rate; 0≤PAR≤1), changex′iby a small amount:x′i←x′i+bw×Rand(−1,1)for continuous variable. bw is the amount of maximum change in pitch adjustment.With probability (1−PAR), do nothing.The second operator is the PAR determined by a pitch band-width (bw). Indeed, this operator corresponds to generate a slightly different solution in the HS [36]. This step is similar to the mutation operator in the GA. A low value of PAR with a narrow bandwidth can slow down the convergence of HS. On the other hand, a very high value of PAR with a wide bandwidth may cause the solution to scatter around some potential optima performing as a random search. Recommend value of PAR can be chosen in the range [0.1–0.5] [36].Step 4: Calculate the cost function of new generated harmony and update the HM.Step 5: Repeat Steps 2–5 until the termination criterion (e.g., maximum number of function evaluation) is satisfied.Genetic algorithm (GA) is a member of a collection of methodologies known as evolutionary algorithm. The GA inspired by the principals of natural selection and evolution processes [37] and it is identified as robust metaheuristic tools capable of delivering efficient solutions to diverse design problems. In general, GA begins its search with a population of random individuals.Each member of the population possesses a chromosome (individual) which is comprised of genes (design variables). In original GA, a gene may take one of two allele values, either 1 or 0. The first step in creating an offspring population for GA is to construct a mating pool.The mating pool contains N individuals which are copied from the parent population that will be utilized to create the offspring population. To create the mating pool, different selection operators (e.g., tournament and roulette wheel) may be utilized.To begin, two solutions from the parent population are selected to compete in a tournament in order to construct the mating pool. A copy of the winner of the tournament is kept in the mating pool. This process is repeated until each solution in the parent population has competed twice and the N spots in the mating pool have been filled. The resulting mating pool contains more copies of the more desirable solutions in the parent population and fewer copies of the less desirable solutions from the parent population.By completion of mating pool, the task of constructing the offspring population commences. To generate two offspring solutions, one begins by selecting two individuals from the mating pool at random. Once selected, the two individuals undergo crossover to create two offspring solutions which are placed in the offspring population.For exploration purpose, mutation operator applies on a random selected individual from the mating pool [37]. There are many diverse applications of GA in the literature [27]. Particularly, the GA applied for solving ODEs combined with the Nelder–Mead method [28]. However, the approach of solving ODEs using the GA in [28] differs with the proposed approach in this paper. In this paper, using the concept of weighted residual method along with Fourier series, optimization methods have been employed for approximately solving ODEs.In summary, in light of all the concepts mentioned in Sections 3.1–3.5, the objective function of the ODEs (minimization of the WRF) and its constraints are as follows:(28)MinimizeWRF=∫D|W(x)|×|R(x)|dx,subject to the BVP and/or IVP constraints:(29a)giIVP(x0)=0i=1,2,...,nIVPsy0i=1,2,...,nIVPs,(29b)gjBVPx0/xn=0j=1,2,...,nBVPsy0j=1,2,...,nBVPs,where W(x) and R(x) are the weight and residual functions, respectively. Accordingly, Eqs. (29a) and (29b) are considered as the constraints for the initial and boundary conditions. Steps of the approximate method are given as follows:Step 1: Convert the given ODE problem in its implicit form based on Eq. (11).Step 2: Prepare the constraints (initial and boundary conditions) in the proper format given in Eqs. (12a) and (12b).Step 3: Choose an appropriate number of terms for the Fourier series (NT), as in Eq. (13).Step 4: Initiate user parameters for the applied metaheuristic algorithm (e.g., PSO and GA).Step 5: Launch the selected optimizer in order to find the best coefficients for the approximate function (Fourier series). Cost function and constraints are embedded in the optimizer for optimization purposes.Step 6: Report the obtained coefficients of the Fourier series.Step 7: Calculate the GD and IGD performance metrics to assess the goodness of the approximate solution against the exact (numerical) solution.Step 8: Plot the obtained approximate and exact (numerical) solutions in the solution interval from x0 to xn.In the following sections, approximate solutions of longitudinal fins with various profiles and coefficients are investigated using the DTM and proposed WRF technique, respectively. It is worth mentioning that the WRF can be linked with any optimization method. Particularly, in this paper, the PSO, GA, and HS are used for optimization purposes (see Section 4.2).The ODEs given in Eq. (5) along with its boundary conditions (see Eq. (6)) have been solved analytically using the DTM [39]. In the literature, many studies have been utilized and described the DTM in detail [10,11]. By considering Eq. (5) and fundamental operations used in the DTM, the following are the approximate mathematical formulations obtained by the DTM as follows [39]:(a)For rectangular profile for m=0:(30a)(1−Aθa)(k+2)(k+1)Θ(k+2)+A∑v=0kΘ(v)(k+2−v)(k+1−v)Θ(k+2−v)+A∑v=0k(v+1)Θ(v+1)(k+1−v)Θ(k+1−v)−NrB∑m=0kΘ(k−m)∑v=0mΘ(m−v)∑w=0vΘ(v−w)∑u=0wΘ(w−u)Θ(u)+(NrBθs−Nr)∑m=0kΘ(k−m)∑v=0mΘ(m−v)∑w=0vΘ(v−w)Θ(w)+(NrBθs4−Nc)Θ(k)+(Ncθa+Nrθs4−NrBθs5)δ(k)=0.For rectangular profile for m=2:(30b)(1−Aθa)(k+2)(k+1)Θ(k+2)+A∑v=0kΘ(v)(k+2−v)(k+1−v)Θ(k+2−v)+A∑v=0k(v+1)Θ(v+1)(k+1−v)Θ(k+1−v)−NrB∑m=0kΘ(k−m)∑v=0mΘ(m−v)∑w=0vΘ(v−w)∑u=0wΘ(w−u)Θ(u)+(NrBθs−Nr)∑m=0kΘ(k−m)∑v=0mΘ(m−v)∑w=0vΘ(v−w)Θ(w)−Nc∑v=0kΘ(k−v)∑w=0vΘ(v−w)Θ(w)+3Ncθa∑m=0kΘ(k−m)Θ(m)+(NrBθs4−3Ncθa2)Θ(k)+(Ncθa3+Nrθs4−NrBθs5)δ(k)=0.For trapezoidal profile for m=0:(30c)1−Aθa−C+CAθa(k+2)(k+1)Θ(k+2)+(A−CA)∑v=0kΘ(v)(k+2−v)(k+1−v)Θ(k+2−v)+(A−CA)∑v=0k(v+1)Θ(v+1)(k+1−v)Θ(k+1−v)+(C−CAθa)(k+1)Θ(k+1)+CA∑v=0kΘ(v)(k+1−v)Θ(k+1−v)+C−CAθa∑l=0kl+2l+1Θl+2δk−1−l+AC∑m=0kδ(k−1−m)∑v=0m(v+1)Θ(v+1)(m+1−v)Θ(m+1−v)+AC∑m=0kδ(k−1−m)∑v=0mΘ(v)(m+2−v)(m+1−v)Θ(m+2−v)−NrB∑m=0kΘ(k−m)∑v=0mΘ(m−v)∑w=0vΘ(v−w)∑u=0wΘ(w−u)Θ(u)+(NrBθs−Nr)∑m=0kΘ(k−m)∑v=0mΘ(m−v)∑w=0vΘ(v−w)Θ(w)+(NrBθs4−Nc)Θ(k)+(Ncθa+Nrθs4−NrBθs5)δ(k)=0.For trapezoidal profile for m=2:(30d)(1−Aθa−C+CAθa)(k+2)(k+1)Θ(k+2)+(A−CA)∑v=0kΘ(v)(k+2−v)(k+1−v)Θ(k+2−v)+(A−CA)∑v=0k(v+1)Θ(v+1)(k+1−v)Θ(k+1−v)+(C−CAθa)(k+1)Θ(k+1)+CA∑v=0kΘ(v)(k+1−v)Θ(k+1−v)+(C−CAθa)∑l=0k(l+2)(l+1)Θ(l+2)δ(k−1−l)+AC∑m=0kδ(k−1−m)∑v=0m(v+1)Θ(v+1)(m+1−v)Θ(m+1−v)+AC∑m=0kδ(k−1−m)∑v=0mΘ(v)(m+2−v)(m+1−v)Θ(m+2−v)−NrB∑m=0kΘ(k−m)∑v=0mΘ(m−v)∑w=0vΘ(v−w)∑u=0wΘ(w−u)Θ(u)+(NrBθs−Nr)∑m=0kΘ(k−m)∑v=0mΘ(m−v)∑w=0vΘ(v−w)Θ(w)−Nc∑v=0kΘ(k−v)∑w=0vΘ(v−w)Θ(w)+3Ncθa∑m=0kΘ(k−m)Θ(m)+(NrBθs4−3Ncθa2)Θ(k)+(Ncθa3+Nrθs4−NrBθs5)δ(k)=0.For concave parabolic profile for m=0:(30e)(1−Aθa−C+CAθa)k+2k+1Θk+2+A−CA∑v=0kΘvk+2−vk+1−vΘk+2−v+A−CA∑v=0kv+1Θv+1k+1−vΘk+1−v+2C−2CAθa∑l=0kl+1Θl+1δk−1−l+2AC∑m=0kδk−1−m∑v=0mΘvm+1−vΘm+1−v+C−CAθa∑l=0kl+2l+1Θl+2δk−2−l+AC∑m=0kδk−2−m∑v=0mv+1Θv+1m+1−vΘm+1−v+AC∑m=0kδk−2−m∑v=0mΘvm+2−vm+1−vΘm+2−v−NrB∑m=0kΘk−m∑v=0mΘm−v∑w=0vΘv−w∑u=0wΘw−uΘu+NrBθs−Nr∑m=0kΘk−m∑v=0mΘm−v∑w=0vΘv−wΘw+NrBθs4−NcΘk+Ncθa+Nrθs4−NrBθs5δk=0.For concave parabolic profile for m=2:(30f)(1−Aθa−C+CAθa)(k+2)(k+1)Θ(k+2)+(A−CA)∑v=0kΘ(v)(k+2−v)(k+1−v)Θ(k+2−v)+(A−CA)∑v=0k(v+1)Θ(v+1)(k+1−v)Θ(k+1−v)+(2C−2CAθa)∑l=0k(l+1)Θ(l+1)δ(k−1−l)+2AC∑m=0kδ(k−1−m)∑v=0mΘ(v)(m+1−v)Θ(m+1−v)+(C−CAθa)∑l=0k(l+2)(l+1)Θ(l+2)δ(k−2−l)+AC∑m=0kδ(k−2−m)∑v=0m(v+1)Θ(v+1)(m+1−v)Θ(m+1−v)+AC∑m=0kδ(k−2−m)∑v=0mΘ(v)(m+2−v)(m+1−v)Θ(m+2−v)−NrB∑m=0kΘk−m∑v=0mΘm−v∑w=0vΘv−w∑u=0wΘw−uΘu+(NrBθs−Nr)∑m=0kΘk−m∑v=0mΘm−v∑w=0vΘv−wΘw−Nc∑v=0kΘ(k−v)∑w=0vΘ(v−w)Θ(w)+3Ncθa∑m=0kΘ(k−m)Θ(m)+(NrBθs4−3Ncθa2)Θ(k)+(Ncθa3+Nrθs4−NrBθs5)δ(k)=0.Considering θ(0)=a and dθ/dX|X=0=0 for all three fin profiles, and applying the differential transformation, boundary conditions can be stated as follows:(31a)Θ(0)=a,(31b)Θ(1)=0.Accordingly, from a process of inverse differential transformation, Θ(k+2) is calculated in Eq. (30). Finally, the following solution by the differential inverse transform of Θ(k) can be obtained as follows:(32)θ(X)=∑k=0∞XkΘ(k).Using Eq. (31a), the value of a can be determined from boundary condition given in Eq. (6a) using the fsolve command in Maple 14 [39].This section does not aim to investigate the ODEs of longitudinal fins from the analytical point of view. In fact, an applicable approach, with the aid of optimization methods, is applied in this paper for approximate solving of ODEs of convective-radiative longitudinal fins having different profiles (n) and heat transfer coefficients (m).In this paper, three well-known optimization methods, named as the PSO, GA, and HS have been selected to show that the proposed approximate method provides high accuracy approximate solutions. Also, interested readers may apply other optimizers in the literature. Choice of metaheuristic algorithm depends on the user and, therefore, choice of optimization method is optional.The task of optimization related to the optimization part was carried out using 30 independent runs. Regarding the side constraints for unknown coefficients of Fourier series, lower and upper bounds of the design variables are considered between -1 and 1, respectively. Table 1represents the sensitivity analyses of applied optimization methods for the longitudinal fins.Different values have been used for each user parameter for all considered optimizer as can be seen in Table 1. By observing Table 1, the highlighted bold values have provided better statistical results against other selected values. Therefore, the initial parameters for the PSO, based on the results given in Table 1, were as follows; population size of 300, the inertia weight (w) for velocity was 0.75, and the cognitive and social components (i.e., c1 and c2) were 1.5.Accordingly, the user parameters of HS for all considered ODEs were: harmony memory size of 30, the chosen values for the HMCR, PAR, and bw were set to 0.98, 0.3, and 0.01, respectively. Regarding the GA, the user-defined parameters were set as follows: population size of 300, and cross over and mutation rates of 0.8 and 0.05, respectively. For having fair comparison, maximum number of function evaluation (NFEs) of 300,000 was assumed as stopping condition for all reported optimizers.The MATLAB programming software was used for coding and implementation purposes. The NT (number of approximation terms of the sine and cosine in Fourier series) is set to 3 (i.e., seven design variables) for all considered ODEs for the longitudinal fins (i.e., 14 ODEs). Hence, approximate mathematical formulations obtained using the PSO for different profiles having different m are given as follows:(a)For rectangular profile (n=0) for m=0:(33a)θappx=(0.917338)−(0.093953)cos(πX)−(0.054890)sin(πX)−(0.005338)cos(2πX)+(0.026293)sin(2πX)+(0.005953)cos(3πX)+(7.67E−04)sin(3πX).For rectangular profile (n=0) for m=2:(33b)θappx=(0.904644)−(0.113495)cos(πX)−(0.074055)sin(πX)−(0.010344)cos(2πX)+(0.034491)sin(2πX)+(0.007795)cos(3πX)+(0.001691)sin(3πX).For trapezoidal profile (n=1) for m=0:(33c)θappx=(0.908804)−(0.104220)cos(πX)−(0.057281)sin(πX)−(0.007104)cos(2πX)+(0.027046)sin(2πX)+(0.005920)cos(3πX)+(0.001063)sin(3πX).For trapezoidal profile (n=1) for m=2:(33d)θappx=(0.896238)−(0.122556)cos(πX)−(0.076025)sin(πX)−(0.010682)cos(2πX)+(0.035729)sin(2πX)+(0.007988)cos(3πX)+(0.001522)sin(3πX).For concave parabolic profile (n=2) for m=0:(33e)θappx=(0.901403)−(0.110344)cos(πX)−(0.057967)sin(πX)−(0.005595)cos(2πX)+(0.028214)sin(2πX)+(0.006159)cos(3πX)+(5.12E−04)sin(3πX).For concave parabolic profile (n=2) for m=2:(33f)θappx=(0.892889)−(0.127323)cos(πX)−(0.078611)sin(πX)−(0.012050)cos(2πX)+(0.036506)sin(2πX)+(0.008084)cos(3πX)+(0.001865)sin(3πX).Tables 2–4show statistical optimization results obtained by different metaheuristic algorithms for the WRF (cost function), GD, and IGD performance metrics for the series of ODEs given in Eqs. (5) and (6). By observing Table 2 for the cost function (i.e., WRF), all algorithms have tried to reduce (minimize) the existing error between approximate and exact solutions. However, in this competition, the PSO provided better statistical results over the HS and GA offering minimum values for the WRF and evaluation metrics.Talking about the GD and IGD metrics (Tables 3 and 4), all applied optimizers performed well for all profiles (n=0, 1, and 2) and heat transfer coefficients (m). In general speaking, all three optimizers performed well in finding unknown coefficients of Fourier series and confirmed the obtained optimization results.In addition, two statistical analyses (i.e., T-test and Friedman test have) have been included in this paper with the aim of proving that differences in terms of WRF, GD, and IGD are statistically significant with a p-value of 0.01. T-test performs a statistical analysis of the null hypothesis that data in a sample set are a random sample from a normal distribution with mean 0 and unknown variance, against the alternative that the mean is not 0. In simple terms, the T-test compares the actual difference between two means in relation to the variation in the data.Moreover, p-values for Friedman test are included in the last row of Tables 2–4. The null hypothesis of the Friedman test is that the calculated errors obtained from the various optimizers are not different. Such a null hypothesis is rejected if p-value is smaller than the level of significance (less than α=0.01).If the p-value is less than α, we can reject the null at the α level of significance, and we can say there is significance evidence against the null hypothesis. In contrast, if the p-value is greater than α, then we do not have significant evidence against the null hypothesis, and therefore, the null hypothesis cannot be rejected.Indeed, the smaller the p-value, the greater the evidence against the null hypothesis. From Tables 2–4, obtained solutions indicate rejections of the null hypothesis at the 1% significance level for the both reported statistical analyses.Fig. 3demonstrates the reduction rate for the error function, WRF (cost function), using the PSO for the two selected ODEs for the rectangular profile (n=0) with m=0 and concave parabolic profile (n=2) with m=2 for only 100 iterations. Looking at Fig. 3, the PSO has tried to reduce the cost function (i.e., error) at each iteration. Finally, the PSO has converged to its optimized approximate solution after 1000 iterations.In addition, Tables 5–7represent obtained optimization results for the WRF and GD, and IGD evaluators for special cases of a longitudinal fin (i.e., rectangular fin, Eqs. (8) and (9)) for different m. In order to have fair comparisons with the numerical results offered in the literature [50], same values for m are considered for the proposed approach.By observing Table 5, in terms of the WRF's values, the PSO has outperformed the HS and GA, while outperforming the HS over the PSO and GA for the best obtained GD and IGD for almost all cases (see Tables 6 and 7). Looking at Tables 5–7, obtained results prove rejections of the null hypothesis at the 1% significance level for the both considered statistical analyses.In fact, the WRF method equipped with optimization methods has tried to force the residual to be zero in some average sense over the domain. When the value of cost function reaches zero or close to zero, better approximate solutions and more accuracy can be achieved. As can be seen in Tables 3 and 5, the obtained values of WRF are close enough to zero for all profiles having different m.This section aims to compare the obtained approximate solutions by the DTM [39] and numerical solutions by the Maple 14.0 [50] with WRF approach using the reported optimizers (i.e., WRF with PSO, WRF via HS, and WRF using GA). In terms of complexity of approximate functions as seen in Eq. (33), one can be grasped that the obtained approximate functions using the WRF equipped with PSO (WRF-PSO) are in a simpler mathematical forms than those suggested by the DTM (see Eqs. (30)) [39].Table 8shows the comparison between the DTM results and the WRF method for different profiles (n) and m in terms of the GD and IGD metrics and values of BCs. It is worth mentioning that the BC1 and BC2, shown in Table 8, stand for the first (Eq. (6a)) and second (Eq. (6b)) boundary conditions.However, in order to show values of these boundary conditions in a better way (accuracy for satisfying boundary conditions), we considered the differences between the exact (numerical) solutions and estimated boundary conditions (e.g., BC1=1−BC1).Indeed, Table 8 summarizes the results and reports for estimated solutions in more detail. From Table 8, in terms of GD, IGD, and BC values, the DTM has surpassed the WRF-PSO, WRF-HS, and WRF-GA. However, the offered approximate solutions by the WRF equipped with optimization methods have acceptable accuracies and values of BCs are satisfactory.For graphical comparison and presentation, Fig. 4depicts the comparisons of approximate solutions using the WRF-PSO and the DTM [39] against exact and numerical solutions. As can be seen from Fig. 4, the approximate solutions obtained by the WRF-PSO are very close to the solutions attained by the DTM.Except of longitudinal fins having rectangular profile (n=0) for both m (i.e., m=0 and 2), estimated solutions by the WRF-PSO for other profiles (i.e., trapezoidal and concave parabolic profiles) are competitive with those obtained by the DTM (see Fig. 4). Similarly, in order to compare with the numerical solutions for Eqs. (8) and (9), Table 9shows the values of BCs, GD, and IGD metrics for the all considered approaches.Fig. 5demonstrates comparisons among numerical and approximate solutions by the WRF via PSO for different heat transfer coefficients (m). From Fig. 5, the WRF with PSO has obtained approximate solutions with acceptable accuracy close to the numerical solutions in the literature [50].It is worth mentioning that sometimes due to the complexity of an ODE, there is not any analytical way (analytical solution) to solve it, or at least it is a consuming task accompanied with possessing high skills in mathematics. However, using the WRF approach, it is useful to suggest a handy mathematical formulation.However, the DTM has its own operational restrictions that severely narrow its functioning domain. Therefore, it is possible that the DTM fails to overcome a specific problem. For instance, it was reported that the DTM was unable to produce physically reasonable data for the Glauert-jet Problem [11].The DTM is suitable for approximate solving of IVPs, while the WRF approach using metaheuristic algorithms can tackle both IVPs and BVPs. Therefore, there is no restriction for the proposed technique for handling ODEs having different boundary conditions. Meanwhile, the DTM is based on classical mathematical tools and in contrast, for the WRF equipped with metaheuristic algorithms, there are no limitations in terms of orders and natures of a problem.They can handle a wide variety of nonlinear ODEs despite of their orders and natures. The ODEs problems of longitudinal fins were examples of highly nonlinear ODEs which, recently, are actively investigating in literatures [39,50]. Other ODE problems in the literature can be solved using the proposed WRF approach with the aid of optimization methods.In general, firstly, approximate analytical methods give accurate predictions only when the nonlinearities are weak. Second, the approximate analytical methods often involve a complex mathematical analysis leading to analytic expressions with a large number of terms (see Eq. (30) for the DTM). Finally, methods such as the HPM, HAM, ADM, and VIM, if routinely implemented, can sometimes lead to erroneous results as shown and reported in the literature [51].All in all, the WRF approach equipped with LSW and reported optimization techniques has suggested acceptable approximate solution for solving ODEs of longitudinal fins having different profiles and properties.It is worth pointing out that when there is an exact and analytical solution for a problem in a logical time, there is no need to solve the problem using approximate methods. However, real life problems, as we considered in this paper (longitudinal fins having various profiles and features, Eqs. (5), (6), (8) and (9)), are highly nonlinear [39,50] and analytical approaches are often inefficient for tackling ODEs.

@&#CONCLUSIONS@&#
This paper introduced a novel approximate approach for solving ordinary differential equations (ODEs) in engineering, particularly longitudinal fins. Finding the exact solution of an ODE often demands heavy computational effort; moreover, it is not an achievable task sometimes. In this situation, the need for approximate solutions arises. Metaheuristic algorithms are well-known approximate methods for solving and optimizing problems. Using the Fourier series as a base approximate function, the ODEs can be modeled as an optimization problem.The aim is to minimize the error of the weighted residual function (WRF) equipped with new proposed weight function, called least square weight (LSW) function. Boundary conditions and initial values are imposed as constraints. In order to compare the results obtained using the WRF (error function) equipped with metaheuristic methods with the exact (numerical) solutions, the generational distance (GD) and inverted GD (IGD) metrics were used.Longitudinal fins having different profiles and properties were examined using the proposed method. For optimizing purposes, three metaheuristic methods including the particle swarm optimization (PSO), the genetic algorithm (GA), and the harmony search (HS) were applied and compared in terms of statistical optimization results and statistical analyses.The best approximate solutions obtained by the WRF approach were compared with the DTM results. The proposed approach offers approximate solutions having acceptable accuracies compared with numerical solutions. Furthermore, obtained approximate solutions using the WRF approach with finite series of cosines and sins shows its performance in terms of acceptable accuracy (error).Due to the nonlinearity nature and behavior of ODE for the most real life problems, the proposed WRF having LSW function accompanied with optimization methods may consider as an alternative approximate approach for efficiently tackling ODEs particularly longitudinal fins.As further study, other applications of the proposed method may be carried out for solving highly nonlinear ODEs in engineering, physics, economics, fluids, and so forth. Different weight functions may be applied and comparative study with other metaheuristic-based approximate methods given in introduction section may be considered as other contributions among these types of approximation methods.