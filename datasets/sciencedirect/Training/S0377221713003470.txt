@&#MAIN-TITLE@&#
Decision tree analysis for a risk averse decision maker: CVaR Criterion

@&#HIGHLIGHTS@&#
We developed decision tree analysis for a risk averse decision maker under CVaR Criterion.We proved there is an explicit non trivial linear representation of the problem.We showed the geometric underpinnings of the model using disjunctive programming theory.

@&#KEYPHRASES@&#
Discrete scenario space,Sequential decision making,Conditional Value-at-Risk,Risk aversion,

@&#ABSTRACT@&#
Risk aversion is a prevalent phenomenon when sufficiently large amounts are at risk. In this paper, we introduce a new prescriptive approach for coping with risk in sequential decision problems with discrete scenario space. We use Conditional Value-at-Risk (CVaR) risk measure as optimization criterion and prove that there is an explicit linear representation of the proposed model for the problem.

@&#INTRODUCTION@&#
The expected utility criterion is commonly used for modeling the risk aversion of a decision maker but there are serious pitfalls associated with using utility functions in practical decision making problems. First of all, it is hard to extract the utility function of a rational decision maker. Second, the utility values are not sensible in practice. One can compare several alternatives based on their expected utilities, but can hardly tell exactly how much one is better than another. The utility theory as a descriptive model of behavior has long shown its weaknesses but it is still a reasonable model for describing rational behavior or in other words as a normative model. However, even as a normative model, the problem of extracting utilities remains for practical use. It is controversial among behavioral economists as to what the rational behavior should be and whether or not there exists a generally applicable model. For more detailed treatment of choice under uncertainty refer to Kreps (1990) and Anderson et al. (1992).In this paper, we introduce a prescriptive model of decision making which could aid risk-averse decision makers in decision analysis. We use a popular risk measure named Conditional Value-at-Risk (CVaR). Rockafellar and Uryasev popularized CVaR by two seminal papers (see Rockafellar and Uryasev, 2000, 2002). Its popularity comes from its convexity property and its relation to value-at-risk (VaR), a widely used risk measure in finance. Moreover, CVaR is in the class of coherent risk measures (e.g., Artzner et al., 1999). CVaR measure simply computes the conditional mean of 100(1−α) percent of the worst-case values of a continuous random variable X. Since the introduction of coherent risk measures, a lot of variant classes of risk measures have been introduced for one-period decision problems (see, e.g., Föllmer and Schied, 2002; Rockafellar et al., 2006; Ben-Tal and Teboulle, 2007). Moreover, they have been extended to multi-period decision problems (see, e.g., Artzner et al., 2002; Artzner, 2007; Frittelli and Gianin, 2004; Detlefsen and Scandolo, 2005).In this paper, we introduce a new method for analysis of sequential decision-making problems for a risk-averse decision maker while both decision and scenario space are discrete. Our work is related to the work of French (1992). He considered sequential decision problems under interval uncertainty for probabilities of scenarios and developed a sensitivity analysis framework. However, in this paper we assume that we know the probability distribution in advance and develop an efficient approach for risk-averse decision analysis. Moreover, our method can handle risk neutrality situation as its special case. Several papers have used coherent risk measures in multi-period (multi-stage) decision problems. Schultz and Tiedemann Schultz and Tiedemann (2006) investigated two-stage stochastic integer programs with mean-risk criterion and CVaR as the risk measure. They presented a mixed integer linear programming formulation of the problem when the scenario space is discrete. They also provided a Lagrangian based solution algorithm. For some of other researches devoted to optimization of risk measures refer to Ahmed (2006), Ahmed et al. (2007), Miller and Ruszczyński (2011), Collado et al. (2010), Ruszczyński and Shapiro (2006a, 2006b).In Section 2, we will briefly review coherent risk measures and CVaR measure. Section 3 presents a risk-averse model for sequential decision problems with discrete spaces. We then introduce a linear representation of the problem. Finally in section 4, we run some tests to show the computational performance of the linear model.A risk measure is simply a function from a space of random variables to R that computes the risk of a given random variable. But, what does it mean by the risk of a random variable? Depending on the application, the definition of risk may be different and there is no general measure of risk. Up to year 1999, the most structured definition of risk was based on utility functions (e.g., see Arrow, 1971). In 1999, Artzner et al. (1999) introduced four basic properties for a risk measure. They called the risk measure equipped with these four properties a coherent measure of risk. Their definition was based on financial applications. Artzner et al.’s work was a groundbreaking step toward providing a mathematical foundation for risk measures. Since then, other researchers have tried to present partially different sets of properties for risk measures. Föllmer and Schied (2004) provides a thorough review of important works in this area.LetR(X)be a risk measure for random variable X representing cost. It is a coherent risk measure if it satisfies the following four conditions:1.R(a)=afor every scalar a∈R(Convexity)R(λX+(1-λ)Y)⩽λR(X)+(1-λ)R(Y)for arbitrary random variables X and Y and λ∈[0,1](Monotonicity)R(X)⩽R(Y)for X and Y where X⩽Y(Positive homogeneity)R(λX)=λR(X)for λ>0Previous literature has shown that Conditional Value-at-Risk (CVaR) is a coherent risk measure (Rockafellar and Uryasev, 2000, Corollary 12). CVaR has received a growing attention in finance due to its nice computational and conceptual properties.Rockafellar and Uryasev (2000) introduced an alternative formula to compute CVaR as follows:(2.1)CVaRα(X)=minvv+11-αE([X-v]+)Variable v is an auxiliary variable and its optimal value is equal to VaRα(X) if it is unique. The above formula is valid for general distributions. CVaRα(X) has several interesting properties such as:1.CVaRα(X)=E(X) when α=0CVaRα(X) is a continuous function of α∈ (0,1)It is consistent with first and second order stochastic dominanceThe α in CVaRα(X) actually reflects the degree of risk aversion of a decision maker. CVaRα(X) is defined as the average of 100(1−α) percent of the worst values of random variable X in the long run. For instance, consider a random variable that takes value −20 with probability 0.3 and value 100 with probability 0.7. The CVaR of this variable for 1−α⩽0.7 is equal to 100 and for 1−α∈ (0.7,1) is equal toCVaRα(X)=0.71-α100+1-α-0.71-α(-20)When α increases, this average increases. It means that more weight is put on worst values of X. This is consistent with risk aversion attribute. There are two extremes α=0 and α=1−∊ with ∊>0 being very small. At α=0 the decision maker is risk neutral. At α=1−∊, we have limα↗1 CVaRα(X)=supX.Every coherent risk measure has a dual representation (e.g., see Artzner et al., 1999). Suppose random variable X is a discrete and finite random variable with values rs, s∈S and corresponding probabilities ps.Proposition 1The dual representation of CVaR isThe equivalency of (2.1) and (2.2) is not obvious at the first glance. We define Lagrange function l(h,v) while taking constraint∑s∈Shs=1with Lagrange multiplier v into objective function.l(h,v)=∑s∈Srshs-v∑s∈Shs-1,which is equal tol(h,v)=∑s∈S[rs-v]hs+v.Now, using duality theorems for linear programs, we can rewrite the right-hand side of identity (2.2) asminvmaxhl(h,v)|0⩽hs⩽ps1-αwhich is equal tominvv+11-α∑s∈S[rs-v]+psThe above expression is the same as formulation (2.1) for obtaining CVaRα(X).□The proof of the above proposition shows in a simple but insightful way the connection between the dual representation of CVaR and formulation (2.1) when random variable X is discrete. It should be noted that Rockafellar et al. (2002) obtained the dual representation for general random variables by using measure theory.Consider a sequential decision making problem which can be reasonably modeled by decision trees. Throughout the paper, we use the following simple example (Adopted from Raiffa and Schlaifer (1961) with some changes) for better exposition.Example 1We have 1000 urns of two types. Urn type 1 contains 40 red and 60 blue balls and urn type 2 contains 100 red and 10 blue balls. The number of type 1 and 2 urns are 750 and 250 respectively. The game is that you pick one urn and guess which type it is. Based on your guess, you will win or lose some money shown in Table 1. You have also this opportunity to sample one ball from the chosen urn and after seeing its color, guess the type of the urn with a cost of $2.The decision tree of the above problem is shown in Fig. 3.1. The reader can consult Appendix B for derivation of the probabilities.We denote each node by a unique label i and the type of node i by tiwhich is equal to c for chance nodes, d for decision nodes and l for leaf nodes. We also denote the index set of all nodes in subtree starting at node i byNi. In Example 1, for instance, the index set of all nodes in subtree starting at node d1 is defined asNd1={d1,c5,c6,c7,1,2,3,4,5}. We denote binary policy variables by vectorx=(xi)i∈I0where set I0 is the index set of policy variables xi. Each xiis equal to one if its associated decision is made and zero otherwise. In the decision tree, a scenario is defined as a sequence of decision and chance events leading to an outcome. We denote the index set of scenarios by S. As it is clear, each scenario corresponds to a leaf node. So, the index set of scenarios for the subtree starting at node i can be defined as follows:Si={k∈Ni|tk=l}Moreover, S=S0. In this paper, we assume every branch in the tree has three possible types of end node’s pair (d,c), (c,d) and (c,l). We assume each node has only one entering branch except for the root decision node which has none. There is a decision variable, xi, associated with each branch emanating from each decision node. We denote the predecessor of arbitrary node j by a(j) and the index set of successors of node j by B(j). In our example, the root node is indexed by 0 and a(0) is set to zero. We label each decision variable by the label of the end node of its corresponding branch which is a chance node.There is cost rsand probability of occurrence ps(x) associated with each scenario s∈S and policy vectorx. We denote the set of feasible policies byD. In the example, setD≔D0is represented byxc1+xc2+xc3+xc4=1xc5+xc6+xc7=xc1xc8+xc9+xc10=xc1xi∈{0,1}∀i∈{c1,…,c10}We denote the index set of all decision nodes by D0. Similarly in general cases, the set of feasible policiesDcan be defined as follows:D=x∈{0,1}|I0|∀i∈D0,∑j∈B(i)xj=xa(i),x0=1The probability of scenario s under policyxcan be obtained using the value of the last decision variable on the path of s (The path which starts at root node and ends at leaf node s). For instance, the probability of scenario 1 under policyxdenoted by p1(x) can be obtained as follows:p1(x)=P{Redball∩Type1}×xc1×xc5,which can be stated as equal toP{Redball∩Type1}×xc5under constraint setD0. Using formula (2.1), the problem of finding the optimal policy is modeled as the mixed binary non-linear program below.(3.1)[P1]min(x,v)v+11-α∑s∈S[rs-v]+ps(x)(3.2)s.t.x∈DFor a fixed policyx∈D, the optimal value of the objective is just the CVaR of a discrete random variable taking value rswith probability ps(x).ModelP1can be cast as a mixed binary linear model using big M method.(3.3)[P2]minv+11-α∑s∈Spszs(3.4)s.t.(3.5)rs-v⩽zs+M(1-xa(s)),∀s∈S(3.6)x∈D,zs⩾0∀s∈S,where variables zsare auxiliary variables and psdenotes the probability of scenario s, i.e., ps≔ps(x) given all decision variable along the path of scenario s are equal to one or equivalently just the last decision variable. For instance, givenxc5=1, p1=P1(x). M is a sufficiently large number. Taking M⩾maxs∈S{rs}−mins∈S{rs} is sufficient to validate the above model as it is proven in Proposition 2.Proposition 2ModelP2is equivalent to ModelP1if M>maxs∈S{rs}−mins∈S{rs} in the sense that (x,v) is the optimal solution ofP1if and only if (x,z,v) is the optimal solution ofP2with the same objective value where the components of the optimal vectorzare equal to(3.7)zs=0ifps(x)=0[rs-v]+OtherwiseFirst, we prove that if (x,v) is a feasible solution ofP1, then (x,z,v) is a feasible solution ofP2withzdefined by (3.7). For the constraint corresponding to s∈S if ps(x)=0 then it readsrs-v⩽zs+M,which holds due to assumption M>maxs∈S{rs}−mins∈S{rs} and Lemma C.1. For the other case (i.e., ps(x)>0), the inequality holds by the definition of zs. The equality of objective functions is concluded simply by the definition ofzObjectiveofP2=v+11-α∑s∈Spszs=v+11-α∑s∈S[rs-v]+ps(x)=ObjectiveofP1Now, we prove that if (x,z,v) is a feasible solution ofP2then (x,v) is a feasible solution ofP1. This is correct sincex∈D. At this stage, we are ready to prove the proposition. We use contradiction in both directions. First assume that (x,v) is the optimal solution ofP1and (x,z,v)zdefined by (3.7) is not the optimal solution ofP2. Therefore, there exists (x′,z′,v′) which has higher objective value. We know (x′,v′) is a feasible solution ofP1with the same objective value as the objective value of (x′,z′,v′) which is higher than the objective value of (x,z,v). Consequently, the objective value of (x′,v′) is greater than that of (x,v) since (x,z,v) and (x,v) withzdefined by (3.7) have equal objective value. Therefore, we have contradiction and (x,z,v) should be the optimal value ofP2.Now consider the reverse case. If (x,z,v) is the optimal solution ofP2then optimalzis defined by (3.7) and (x,v) is the optimal solution ofP1. First, we show that v is greater than or equal to mins∈S{rs} inP2. We use similar arguments as in proof of Lemma C.1. The optimal value of zswith knowing the values ofxand v and the fact that the coefficients of variables zsin the objective function are nonnegative, should be equal to [rs−v−M]+ if ps(x)=0 and [rs−v]+ otherwise. Then, the optimal objective function is obtained asObjectiveofP2=C1(k)+C2(k)whereC1(k)=v+11-α∑s∈Q(x)[rs-v]+C2(k)=11-α∑s∈Q(x)[rs-v-M]+Assume v=k+mins∈S{rs} in which k is a negative number. Both C1(k) and C2(k) are decreasing functions of k for negative values of k. So k in the optimal solution cannot be negative and thus v⩾mins∈S{rs}. Therefore, [rs−v−M]+=0 and zshave the characterization of (3.7). We again argue by contradiction and assume that (x,v) is not the optimal solution ofP1. Hence, there exists solution (x′,v′) with higher objective value. We know that (x′,z′,v′) is a feasible solution ofP2. Since (x,v) and (x,z,v) have the same objective value, thereby (x′,z′,v′) has higher objective value than (x,z,v) which is a contradiction. This completes the proof. □ModelP2can be solved by existing algorithms. But it would require a solution to a Mixed Integer Nonlinear Program that is generally NP-Hard. We will show that we can do better by finding a more efficient method. It should be mentioned for curious readers that, modelP2can be solved by decomposition methods (see, e.g., Laporte and Louveaux, 1993). Parija et al. (2004) is a good survey of algorithms developed for solving stochastic integer programs like modelP2.P2formulation inspires another formulation based on union and intersection of sets. We define sets Fsfor s∈S as follows:Fs={(z,v)|rs-v⩽zs,z⩾0}From now on, for the simplification in the exposition of sets, we will exclude the nonnegativity constraints in the definition unless it is stated otherwise. For instance, we will show set Fsby {rs−v⩽zs}. The feasible set of problemP2can be obtained by taking intersection at chance nodes and union at decision nodes. In our example, we obtainF0=(((F1∩F2)∪(F3∩F4)∪F5)∩((F6∩F7)∪(F8∩F9)∪F10))∪(F11∩F12)∪(F13∩F14)∪F15To understand the correspondence, consider chance node c5. From formulationP2, we know that if the decisionxc5is taken then both constraints r1−v⩽z1 and r2−v⩽z2 should appear in the definition of the feasible set. That is, set F1∩F2. Furthermore, at the decision node d1, depending on which one of the decisionsxc5, orxc6, orxc7is taken, the constraint sets F1∩F2, or F3∩F4, or F5 should appear in the definition of the feasible constraint set for the problem respectively. Or equivalently, we have ((F1∩F2)∪ (F3∩F4)∪F5).Set F0 defines the feasible set of modelP2on the space of (z,v). Now, we can easily find a recursive equation for defining F0 in the general case.Fi=⋂j∈B(i)Fjifti=c⋃j∈B(i)Fjifti=dFiOtherwiseSo problemP2is equivalent to the following problem on (z,v) space.[P3]min(z,v)v+11-α∑s∈Spszss.t.(z,v)∈clconvF0Because the objective function is linear, we can replace set F0 with the closure of its convex hull, i.e., clconv F0. Closure of set H is defined as the set of all points of H and all limit points of H. Optimal vectorxcan be obtained as a by-product of the optimal solution of problemP3. We will prove this later. We claim that each Fihas a polyhedral representation which can be obtained explicitly. To show this mathematically, we define sets Gias follows:Gi={rixa(i)-va(i)⩽zi}ifti=l⋂j∈B(i)Gjifti=c⋂j∈B(i)Gj⋂∑j∈B(i)xj=xa(i),∑j∈B(i)vj=va(i)ifti=dIn set Gi, all variables xi, ∀i∈I0 and zs, ∀s∈S are nonnegative following the rule we set earlier. We denote the index set of all decision nodes in subtree i by Di. We can prove that set Gihas a linear representation.Lemma 3Each set Gihas an explicit linear representation:rsxa(s)-va(s)⩽zs∀s∈Si∑j∈B(k)xj=xa(k),∀k∈Di∑j∈B(k)vj=va(k),∀k∈DiAllxjandzsarenonnegativeRefer to Appendix C□By defining a new set, denoted by Ki, from Gi, we can find an equivalent linear formulation for problemP2.Ki=(x,z,v,v)∈R+|I0|×R+|S|×R×R|I0|(x,z,v,v)∈Gi∩xi=1,vi=vifta(i)=dxa(i)=1,va(i)=vOtherwiseFollowing Lemma 3, set K0 can be represented as belowrsxa(s)-va(s)⩽zs∀s∈S∑j∈B(i)xj=xa(i),∀i∈D0,x0=1∑j∈B(i)vj=va(i),∀i∈D0,v0=vzs⩾0∀s∈Si&xi⩾0∀i∈D0Proposition 4ProblemP2is equivalent to the following linear program(3.8)[P4]minv+11-α∑s∈Spszs(3.9)s.t.(x,z,v,v)∈K0In the sense that(i)if (x,z,v) is an extreme point ofC2, convex hull of constraints set ofP2, then (x,z,v,v) is an extreme point ofC4, constraints set ofP4where∀j∈I0,vj=vifxj=10Otherwise.if (x,z,v,v) is an extreme point ofC4then (x,z,v) is an extreme point ofC2.Extreme point (x,z,v) is an optimal solution ofP2if and only if extreme point (x,z,v,v) is an optimal solution ofP4.(i)We prove by contradiction. It is easy to verify the feasibility of (x,z,v,v) following feasibility of (x,z,v). If point (x,z,v,v) is not an extreme point ofC4it can be obtained as convex combination of extreme points ofC4. We denote them by Pi. Due to Lemma C.2, we can show that all extreme points (x′,z′,v′,v′) ofC4have corresponding extreme points (x′,z′,v′) inC2. Therefore, we can write (x,z,v) as convex combination of corresponding extreme points, which contradicts the fact that (x,z,v) is an extreme point.Proof of this part is similar to the argument in part (i).If (x,z,v) is the optimal solution ofP2, then (x,z,v,v) is an extreme point ofC4. If it is not the optimal point, then there exists another extreme point (x′,z′,v′,v′) with higher objective value. So following (ii), (x′,z′,v′) is an extreme point ofC2with higher objective value than (x′,z′,v′) and it is a contradiction. The proof of the reverse direction follows a similar argument.According to the Proposition 4, problemP4is equivalent to problemP2and thereby toP1andP3. But, it is a linear problem, which makes it the best choice for finding the solution to problemP1efficiently.It is constructive to know how we came up with linear modelP4for our problem. The following theorem is the most important result in this paper and has the potential to be extended for all problems with linear objective functions and constraints of the type like set F0 which is comprised of finite inclusion-union of polyhedral sets. It uses disjunctive programming theory (Balas, 1998).Theorem 5The closure of convex hull of set Fi, ∀i has a polyhedral representation asclconvFi=proj(z,v)KiThe projectionproj(z,v)(Ki)means the projection of set Kito (z,v) space.We argue by induction. From now on, all projection are onto (z,v) space unless it is stated otherwise. First, we denote the set of all chance nodes in subtree e, i.e.,Ne-De-Seby Ie. We need to consider three cases corresponding to three node types. The induction starts from leaf nodes backwards.Case 1: ti=lIn this case, we haveclconvFi={ri-v⩽zi}=proj({rixa(i)-va(i)⩽zi}∩{xa(i)=1,va(i)=v})=proj(z,v)KiCase 2: ti=cclconvFi=clconv⋂j∈B(i)Fj=⋂j∈B(i)clconvFj=⋂j∈B(i)proj(Gj∩{xi=1,vi=v})=proj⋂j∈B(i)(Gj∩{xi=1,vi=v})=proj⋂j∈B(i)Gj∩{xi=1,vi=v}=proj(Gi∩{xi=1,vi=v})=proj(z,v)KiCase 3: ti=dWe define set A(i,j) as follows:A(i,j)≔Gj∩xj=1,vj=v,xk=0,vk=0∀k∈⋃e∈B(i)-{j}Ie=rsxa(s)-va(s)⩽zs∀s∈Sj∑j∈B(k)xj=xa(k),∀k∈Dj∑j∈B(k)vj=va(k),∀k∈Dixj=1,vj=vxk=0,vk=0∀k∈⋃e∈B(i)-{j}IeThe second equality is followed from the definition of set Gj. We haveclconvFi=clconv⋃j∈B(i)Fj=clconv⋃j∈B(i)clconvFj=clconv⋃j∈B(i)proj(Gj∩{xj=1,vj=v})=clconv⋃j∈B(i)proj(A(i,j))=clconvproj⋃j∈B(i)A(i,j)Fourth equality follows from equality of projections of corresponding sets onto (z,v) space. Note that the sets which the projection is applied on are not the same but have the same projection.By using Lemma A.1 with takingw=v,zj=zjandyj=(xk,vk)k∈Ijwhere Ijdenotes the index set of all chance nodes in subtree j, the set ⋃j∈B(i)A(i,j) can be represented as the projection of the following set on (x,z,v,v) space.Ri=⋂j∈B(i)Gj∩xj=ξj0,vj=ξjv⋂∑j∈B(i)ξj0=1,∑j∈B(i)ξjv=vwe can proceed as follows:clconvFi=clconvproj(z,v)proj(x,z,v,v)Ri=clconvproj(z,v)⋂j∈B(i)Gj⋂∑j∈B(i)xj=1,∑j∈B(i)vj=v=clconvproj(z,v)Gi⋂∑j∈B(i)xj=1,∑j∈B(i)vj=v=proj(z,v)KiRefer to the example in Appendix A for an elaboration on using Lemma A.1.□In this section, we compare the computational performance of modelsP2andP4on 10 randomly generated problems. We used Gurobi 5.1 optimization software. The tests were run on a windows system with four Intel 3.1gigahertz processors. The result of run tests are illustrated in Table 2. The name of each problem partly shows its characteristics. For instance, problem instance C20D4T5 is associated with a tree with length of 5, 4 alternatives for each decision node, and 20 chance states for each chance node. The probabilities for each chance node are drawn from a uniform distribution. The payoffs were uniformly generated in interval [−100,100]. Each table has six columns. We limited the solution time to 600seconds. In case a problem instance was not solved within 600seconds, we recorded the best feasible solution. Column 2 shows the solution time for obtaining the optimal solution in modelP2. Column 3 illustrates the best feasible solution in terms of the objective function value, obtained in at most 600seconds in modelP2. The solution time for obtaining the optimal solution in modelP4are shown in column 4. The solution times are in seconds. The optimal values are illustrated in column 5. Finally, column 6 shows the relative gap between the best solution of modelP2and modelP4, i.e.,Rel.Gap=MIPbest-OptOpt×100.For all problem instances, modelP2gives the optimal solution in less than 600seconds. ModelP4cannot give the optimal solution in the designated time limit for more than half of the problem instances. Moreover, column 6 suggests that the objective function value of the best obtained feasible solutions of modelP2can have quite large gaps in instances that the optimal solution cannot be found within the time limit. While in both problems, the number of variables and constraints are of the same size O(∣S0∣), modelP4has the advantage of linearity due to its integrality constraints being removed. Therefore, it is expected that modelP4keeps its superiority for large-scale problems.For our example, We write down the extensive form of modelP4.min(x,v,z)v+11-α310z1+522z2+310z3+522z4+2955z5+920z6+144z7+920z8+144z9+2655z10+34z11+14z12+34z13+14z14+z15s.t.-58xc5-vc5⩽z1,22xc5-vc5⩽z2,12xc6-vc6⩽z3,-98xc6-vc6⩽z4,2xc7-vc7⩽z5,-58xc8-vc8⩽z622xc8-vc8⩽z7,12xc9-vc9⩽z8,-98xc10-vc10⩽z92xc10-vc10⩽z10,-60xc2-vc2⩽z11,20xc2-vc2⩽z1210xc3-vc3⩽z13,-100xc3-vc3⩽z14,-v4⩽z15vc1+vc2+vc3+vc4=v0,v0=vvc5+vc6+vc7=vc1vc8+vc9+vc10=vc1x∈D0,zs⩾0∀s∈{1,…,15}Table 3Shows the optimal policy, the expected value of the optimal policy and the optimal objective function for different values of α. The interpretation of the optimal policies is straightforward. If the decision maker wants to decide based on 88.75–100% of the worst values of payoff, then his optimal policy is the same as that of expected value criterion. If he considers 33.33–88.75% of the worst values, then the optimal policy is to guess type 1. If the risk aversion of the decision maker is more than 66.67% or equivalently he makes decision based on average of less than 33.33% of the worst values. Then the optimal policy for him is to quit the game.

@&#CONCLUSIONS@&#
