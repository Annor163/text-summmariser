@&#MAIN-TITLE@&#
Quadcopter flight control using a low-cost hybrid interface with EEG-based classification and eye tracking

@&#HIGHLIGHTS@&#
We present a noninvasive and wearable interface to control a quadcopter in 3D space.The hybrid system is low cost and easily wearable.The system hybridizes eye tracking and EEG-based classification.The system allows users to complete their tasks easily with various commands.People can control their flight naturally in everyday life.

@&#KEYPHRASES@&#
Hybrid interface,Brain–computer interface,Mental concentration,Eye tracking,Quadcopter flight control,

@&#ABSTRACT@&#
We propose a wearable hybrid interface where eye movements and mental concentration directly influence the control of a quadcopter in three-dimensional space. This noninvasive and low-cost interface addresses limitations of previous work by supporting users to complete their complicated tasks in a constrained environment in which only visual feedback is provided. The combination of the two inputs augments the number of control commands to enable the flying robot to travel in eight different directions within the physical environment. Five human subjects participated in the experiments to test the feasibility of the hybrid interface. A front view camera on the hull of the quadcopter provided the only visual feedback to each remote subject on a laptop display. Based on the visual feedback, the subjects used the interface to navigate along pre-set target locations in the air. The flight performance was evaluated by comparing with a keyboard-based interface. We demonstrate the applicability of the hybrid interface to explore and interact with a three-dimensional physical space through a flying robot.

@&#INTRODUCTION@&#
Over the past decade, various interface systems have been explored that enable not only healthy but also physically impaired people to immerse themselves in images or videos and interact through voluntary movements such as moving their eyes in various directions. Among the diverse approaches, eye tracking techniques and brain–computer interfaces (BCIs) are those in the spotlight. The two paradigms enable intuitive and natural interaction. This paper proposes a hybrid interface where users׳ eyes and mental states directly influence control systems. In particular, we present a noninvasive and low-cost wearable interface to control a quadcopter in three-dimensional (3D) space.When a human being is able to move their eyes voluntarily, eye tracking is a promising interface scheme [1]. Eye movement recording can be interpreted as control commands without the need of a keyboard or mouse input. In contrast to conventional inputs, eye tracking is wearable. Hence, it can be advantageous for not only physically impaired people but also healthy people in the sense that both hands are still available. It has a high information transmission rate, short preparation time, and omnidirectional controllability [2]. In most of the previous eye movement based tracking work, they usually track pupil contour and estimate eye gaze with a monocular camera. Though such approaches may have been shown to be effective in controllability in the two-dimensional (2D) space, they are not necessarily able to be used in 3D space because depth information is not extractable.Among BCI approaches, electroencephalogram (EEG)-based BCIs enjoy many advantages such as inexpensive equipment, less environmental constraints, and noninvasive measurement [3]. In terms of classification accuracy, recent studies have demonstrated EEG-based BCIs allow users to control machines with multi-states classification [4–6]. Nevertheless, from the perspective of practical applications, consistently classifying multi-class BCI is not easy because of the difficulty of human subjects in maintaining mental concentration and the intensive training required [7]. In this sense, two-class BCI classification is favorable due to its relative simplicity, but has a limit of controllability. To overcome the problem and improve practical applicability, the hybrid BCI paradigm, which uses a brain activity-based interface together with any other multimodal control device, has been a popular topic of investigation [8]. The hybrid BCI paradigm is expected to be a good choice for practical implementation with feasible hardware [9]. Among various choices of control devices for hybridization with BCI, eye-tracking devices are of particular interest because of their omnidirectional controllability in the 2D space.There were attempts [10,11] to attain enhanced interfaces by hybridizing eye tracking and EEG-based classification. The two schemes could be compensatory in function. These attempts were made based on an idea that EEG-based classification can be a way of commanding selections while eye tracking is used to point at target spots. However, its applications to date are limited to the 2D physical space such as cursor control on a computer screen.To further extend the hybridization׳s potential for asynchronous interaction of the exploration of a subject׳s surroundings, considering applications in a 3D physical environment are valuable. Furthermore, applications to challenging tasks such as controlling the flight of an airborne object [12], which is not an easy task even with a nominal interface, would be a more valid study. In this study, fresh look at a hybrid interface combining eye movement and brain activity is considered as way of extending control commands for 3D physical applications; specifically in this study, quadcopter flight control. The combination of eye movement and mental concentration is mapped to all possible flight actuations of a quadcopter. Hence, a human subject can control the quadcopter remotely while simply looking at the computer monitor keeping at a safe distance from its air space. The subject also obtains real-time environmental information from a camera mounted on the quadcopter. Therefore, he or she can make decisions on the flight׳s direction based on this information.The other consideration of this study is the interface׳s practical applicability [13,14]. Currently, standard eye trackers and EEG acquisition systems are very expensive and bulky. They are still mainly used in laboratory environments. To enhance real-life usability, we prepare a low-cost hybrid interface for the present study. In addition, the hybrid interface aims to be easily wearable. Hence, the aim of this study is the development of a low-cost and easy-to-use hybrid interface that interprets eye movements and brain mental activity to allow real-time control of applications in 3D environment. Therefore, the contribution of the proposed system, as an alternative to existing work, is a new interface that addresses the limitations of the previous systems in a single system. The main contributions of this work are two-fold:1.Easy-to-learn and easy-to-use system: hybridizing eye tracking and EEG-based classification allowing users to complete their tasks easily with various commands in 3D physical space.Not only low-cost but also a convenient wearable device: people can control their flight naturally in everyday life.The rest of this paper is organized as follows: Section 2 presents a detailed method of this proposed work. Sections 3 and 4 present experimental setup and results. Section 5 presents some conclusions and discussion.

@&#CONCLUSIONS@&#
