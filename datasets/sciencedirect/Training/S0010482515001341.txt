@&#MAIN-TITLE@&#
A computer-aided automated methodology for the detection and classification of occlusal caries from photographic color images

@&#HIGHLIGHTS@&#
An automated methodology for the diagnosis of occlusal caries is presented.Methodology can be a support to the dentists for making the final decision.Methodology is based on digital photography analysis.Methodology can incorporate new knowledge on caries diagnosis.Detection and classification (7 ICDAS classes) accuracy is 80% and 83%, respectively.

@&#KEYPHRASES@&#
Occlusal caries,Caries diagnosis,ICDAS II,Segmentation,Feature extraction,Feature selection,Classification,Random forests,Digital imaging,

@&#ABSTRACT@&#
The aim of this work is to present a computer-aided automated methodology for the assessment of carious lesions, according to the International Caries Detection and Assessment System (ICDAS II), which are located on the occlusal surfaces of posterior permanent teeth from photographic color tooth images. The proposed methodology consists of two stages: (a) the detection of regions of interest and (b) the classification of the detected regions according to ICDAS ΙΙ. In the first stage, pre-processing, segmentation and post-processing mechanisms were employed. For each pixel of the detected regions, a 15×15 neighborhood is used and a set of intensity-based and texture-based features were extracted. A correlation based technique was applied to select a subset of 36 features which were given as input into the classification stage, where five classifiers (J48, Random Tree, Random Forests, Support Vector Machines and Naïve Bayes) were compared to conclude to the best one, in our case, to Random Forests. The methodology was evaluated on a set of 103 digital color images where 425 regions of interest from occlusal surfaces of extracted permanent teeth were manually segmented and classified, based on visual assessments by two experts. The methodology correctly detected 337 out of 340 regions in the detection stage with accuracy of detection 80%. For the classification stage an overall accuracy 83% is achieved. The proposed methodology provides an objective and fully automated caries diagnostic system for occlusal carious lesions with similar or better performance of a trained dentist taking into consideration the available medical knowledge.

@&#INTRODUCTION@&#
Dental caries, otherwise known as tooth decay, is one of the most prevalent chronic diseases affecting 60–90% of school children and the vast majority of adults [1,2]. It is a microbial disease of the calcified tissues of the teeth, caused by the complex interaction, over time, between acids and many host factors such as teeth and saliva [1]. More specifically, bacteria present in the plaque of the tooth surface metabolize sugar and produce acids which attack the enamel surface and lead to decalcification initially and cavitation later by dissolving the inorganic part of the enamel (loss of calcium and phosphate) [1–3]. Depending on the area of the tooth in which dental caries is developed we find three types of the disease: (a) pit and fissures caries (occlusal caries), (b) smooth surface caries (approximal lingual and buccal) and (c) root surface caries, with the first one being the most common one counting for 50–75% of all dental caries found in the mouth of the individuals [4].Although occlusal caries is readily accessible for visual inspection, compared to approximal surfaces, their visual-tactile or radiographical diagnosis is a difficult task due to the complicated three-dimensional shape of the occlusal surfaces, leading to a wide range of individual diagnostic decisions. The diagnosis of dental caries consists of the detection of the lesion followed by its assessment and classification, in terms of the stage of progress and its activity (whether a lesion is active and continues to progress or is arrested and the progress has stopped).Visual or visual-tactile inspection is a common conventional method for caries detection and classification in the daily clinical practice. However, this assessment is very subjective, since it is primarily based on the experience of the clinician, as well as, to factors related to illumination of the tooth, presence of dental plaque, stains, etc. This diagnostic variability between clinicians leads to different decisions for the management of the carious lesions and several of them might be to the wrong direction [6,7].In an attempt to reduce the variability in clinical diagnosis and improve its accuracy, several techniques have been developed for the detection and assessment of occlusal caries. These include fiber optic transillumination, laser or light or infrared fluorescence, electrical resistance [6–18] and more recently digital radiography, ultrasound, infrared thermography, optical coherence tomography (OCT), terahertz imaging and digital photography analysis [19–21]. Although, digital photography does not provide information regarding the third dimension of the occlusal surfaces literature [22–26] has shown its potentiality in the diagnosis of occlusal caries.In the literature there are also techniques that analyzed digital images of teeth in an attempt to classify the carious lesions. Umemori et al. [22] processed and analyzed digital photographs using image analysis software. They achieved to detect and classify regions of interest with 86% sensitivity and 86% specificity. The authors do not describe the criteria they used to visually classify teeth into the different categories and the classification was based only on the experience of the examiners. Moreover, the diagnosis was verified by preparing the affected teeth not allowing any verification whether the non-carious teeth were classified correctly since they were not prepared. The non-carious teeth though accounted for a great majority of the sample (64%) so if there was any systematic error in assigning teeth in this category would have a substantial effect on the results of the study. Kositbowornchai et al. [23] developed a neural network to diagnose artificial dental caries using images from a charged coupled device (CCD) camera and intra-oral digital radiography. The sensitivity and specificity of their method using images from the CCD camera was 77 and 85%, respectively, while using images form intra-oral digital radiography the sensitivity and specificity was 81 and 93%, respectively. The main drawback of this study is that the system was evaluated using teeth with artificial carries. Artificial caries is completely different from natural caries mainly due to different histochemical composition in terms of the organic material and staining which give different optical properties that interfere with the classification of the lesion. Thus, it is not clear how effectively this technique can identify in vitro strained lesions with different depths. Olsen et al. [24] proposed a system that detects damaged areas on tooth surfaces using digital color images of dental preparations drilled in practice teeth. The images were processed using the Directed Active Shape Modeling (DASM) algorithm in order the tooth and drilled preparation to be segmented. Seven features, the gradient of the color image and six texture measures, were extracted. The feature vectors were the input of the classification algorithm which identifies pixels that represent areas of the tooth surface which are damaged by the caries. The best detection accuracy (96.86%) was achieved using RBF.Ghaedi et al. [25] proposed an automated method for the detection and scoring of the optical images of tooth occlusal surface. They grouped the seven classes of ICDAS II into three as sound occlusal (ICDAS score 0), initial caries (ICDAS Score 1 or 2), moderate to severe caries (ICDAS score 3 to 6). The obtained accuracy, sensitivity and specificity are 86.3%, 83% and 91.7%, respectively.Just considering the number of different systems that have been proposed for caries diagnosis suggests that there is not yet an accurate and reliable one that can be used in clinical practice. The low performance of these systems has led the experts to utilize them only as supplementary means in caries diagnosis. Moreover, most of the times the dentist must interpret the accuracy of the diagnosis from the systems allowing his subjectivity to affect the final diagnosis. Therefore, the development of an accurate carries detection system is very important.The aim of this work is to develop a computer-aided automated methodology (ACDS) for the diagnosis of occlusal caries lesions of posterior permanent teeth according to the International Caries Detection and Assessment System (ICDAS II) from photographic color tooth images. The proposed methodology consists of two stages (a) detection and (b) classification. The methodology is based on the segmentation of photographic color images. More specifically, the k-means algorithm is applied to the color image for the segmentation of the pre-cavitated lesions (PCL), while cavitated occlusal lesions (COL) are detected by the application of image processing operations to each channel (red, green, blue) of the color image. For each detected area, features expressing the shape and the texture of the area are extracted. The combinations of the extracted features through rules, which express medical knowledge, are applied in order areas that correspond to false positives to be eliminated. Once regions of interest are detected classification of these regions into seven classes defined by ICDAS II is applied. The classification stage consists of four steps. For each pixel detected as cavity, a 15×15 neighborhood is created. Then, texture-based and intensity-based features are extracted (first step). A feature selection technique based on the correlation criterion is utilized (second step) to identify the most significant from all extracted features at the previous step. The selected features of each detected pixel are fed to the classification module (third step) to classify them into classes as defined by the ICDAS II. Finally, the classification of the detected regions into one of 7 ICDAS II classes is performed (forth step). Towards this direction, five classifiers, the J48, the Random Tree, the Random Forests, the Support Vector Machine, and the Naïve Bayes are employed and their performance is compared in order to select the most appropriate in terms of classification accuracy.The design and principles of the proposed automated caries diagnostic system (ACDS) are applied for the first time, to our knowledge, for the detection and classification of occlusal caries. The concept behind ACDS was to use the established knowledge of the ICDAS II classification system in order to develop an algorithm that will be trained to reliably and repeatedly classify the carious lesions into the ICDAS II categories based on their optical properties. The main advantage that makes ACDS unique is that it does not require any intervention of the dentist preventing any subjective input and thus providing an objective diagnosis of the caries status of the surface and at the same time the appropriate treatment based on this diagnosis. Moreover, it does not require the patient to be subjected to any radiation exposure (e.g. X-ray), it needs only photographic images of the teeth that can be acquired with a common camera, it can be trained using a bigger training dataset in order to improve its performance and more importantly can be easily adjusted to incorporate any new knowledge on caries diagnosis or on detection and differentiation of further oral clinical findings (e.g. differentiation of stains form caries lesions, differentiation of hypoplasia from white demineralization).For the needs of this study 91 posterior extracted and 12 in vivo human teeth were used. The extracted teeth were collected from the Maxillofacial Surgery Clinic of the Dental School of the National and Kapodistrian University of Athens as well as from private dental offices. Teeth without hypoplastic areas were selected. Teeth were cleaned to remove any tissue present and blood clots and were stored on distilled water at 6°C. Occlusal surfaces were then cleaned with air polishing prophylaxis system which uses air, water and sodium bicarbonate. The air polishing technique was used as it is very effective in removing plaque and inorganic debris from the pit and fissures of the occlusal surfaces of the teeth [27,28]. The in vivo images were photographed using a Canon Rebel XTi 10.1MP digital camera, with lens Canon Macro EF 100mm 1:2.8 USM, flash Macro Ring Light MR14 EX and magnification 1:1. The in vitro images were recorded using the Olympus E-500 Digital 8MP camera with lens Olympus digital 50mm macro and an Olympus 2xTeleconverter (EC-20) giving a magnification almost 1:2. The speed was set at 1/125s and diaphragm at F45 stop at 0.79m focusing distance. The ring flash was a Starblitz (Macrolite-1000 Auto) [29]. The study was performed in a laboratory environment where controlled conditions prevail and it was designed in a way to eliminate as many confounding factors as possible (plaque, light scattering etc.).The images were examined by two experienced in the use of ICADS II System pediatric dentists. The experts were calibrated in a set of 35 digital pictures that were not included in this study. They classified the digital pictures blindly, classifying different parts of the occlusal surface with different ICDAS II score if necessary. Then they compared their results when they had different score they discussed so they will agree on the ICDAS II score of the surface. Then the teeth were annotated based on the final decision of the experts [30,31]. The expert outlined the perimeter of the PCL and COL using a software developed in MATLAB v7.12. The expert picks the pixels that constitute the perimeter of the regions of interest. Once the selection of the pixels is completed, the border of the polygonal region of interest is created within the image. For this purpose, the roipoly Matlab function is utilized. It displays the image on the screen and lets the user specify the polygon using the mouse. Once the selection of points is completed, it draws the selected polygon on the image [32]. The border of each region has a color representing the classification of the specific region provided by the expert (yellow-sound, green-first visual change in enamel, cyan-distinct visual change in enamel, magenta-localized enamel breakdown, blue-underlying dentine shadow, red-distinct cavity with visible dentine, black-extensive cavity within visible dentine). The classification was made according to the International Caries Assessment and Detection System II (ICDAS II) criteria [5]. Within the dataset, 425 regions of interest were identified.The proposed methodology consists of two main stages: (A) detection and (B) classification. The detection process for the two different areas of interest (PCL, COL) runs in parallel. The detection process includes the following steps, which are differentiated depending on the area of interest: (a) pre-processing of the digital color images, (b) segmentation of areas of interest, (c) area characteristics extraction, (d) object elimination, and (e) fusion of the results produced by the detection of the areas of interest. Steps (c) and (d) can be merged into one step called post-processing. The classification stage comprises of four main steps: (a) feature extraction, (b) feature selection, (c) classification of pixels, and (d) classification of regions. A block-diagram of the proposed methodology is presented inFig. 1.The color image is converted into gray scale (grayIm) by eliminating the hue and saturation information while retaining the luminance. More specifically, RGB values are converted to gray scale values by forming a weighted sum of theR,GandBcomponents using the following formula [32]:(1)grayIm=0.2989⁎R+0.5870⁎G+0.1140⁎B,whereR,GandBare the pixel value of the red, green and blue channel, respectively (Fig. 2a).The intensities of the gray scale image are rescaled to the range [0, 1] (resIm) and then the contrast of the image is adjusted by applying the following sigmoid function [33]:(2)newIm(x,y)=1/(1+egain⁎(c−resIm(x,y)),wherenewIm(x,y)is the value of the pixel(x,y)of the image after the application of the sigmoid function,gaincontrols the actual contrast,crepresents the (normalized) gray value about which contrast is increased or decreased andresIm(x,y)is the value of the pixel(x,y)of the image before the application of the sigmoid function (Fig. 2b).The image (newIm) is converted to binary (Fig. 2c). The threshold for this conversion is determined by employing Otsu׳s method [34]. In the image obtained in the previous step neighboring pixels with connectivity eight are grouped together to create the objects depicted in the image. For this purpose, the procedure outlined in [35] is applied. According to [34], if the detected objects are more than one, we compute the area of the objects. The largest obtained object is the tooth region, whose empty areas are filled using the flood fill algorithm (Fig. 2d) [36]. Next, the perimeter of the tooth is extracted (Fig. 2e). A pixel belongs to the perimeter of the tooth if its value is equal to one and it is connected to at least one zero-valued pixel. The perimeter is used for the computation of the center of the tooth. More specifically, the bounding box, the smallest rectangle containing the region of the tooth, is created and the coordinates of the bounding box area are used for the calculation of the center of the tooth (Fig. 2f).For the segmentation of the PCL, the color image is first subjected to the pre-processing procedure described above (Fig. 3a), it is converted to gray scale (Fig. 3b) and then the contrast is adjusted using the sigmoid function (Fig. 3c). Then, the k-means algorithm is employed [37]. The k-means algorithm treats each object as having a location in space. It finds partitions such that objects within each cluster are as close to each other as possible, and as far from objects in other clusters as possible. It requires specifying the number of clusters and a distance metric to quantify how close the two objects are to each other. In our case the number of clusters is 3 and the Euclidean distance is used as the distance metric. The 3 cluster correspond the background of the image, to the area of the tooth and to the PCL. Thek-means algorithm aims at minimizing the following squared error function:(3)J=∑j=1k∑i=1N‖xij−cenj‖2,wherekis the number of clusters,cenjis the center of the clusterj,xijis thei-thdata vector andNis the number of the data vectors of the dataset to be clustered. The clustering is repeated three times to avoid local minima. The k-means returns an index corresponding to a cluster which is used in labeling every pixel in the image with its cluster index (Fig. 4a).The pixel labeling is the input of the cluster selection approach. Based on the pixel labeling three new images are created each one corresponding to a different cluster. Then, the area of objects belonging to each cluster is computed. The cluster with the minimum total area is selected as the one that depicts the objects that correspond to PCL (Fig. 4b) since the other two clusters mainly depict the area of the tooth and the background (Fig. 4c and d).The PCL are recognized as small white areas which are near or adjacent to the fissures of the tooth. Area characterstics such us, the area, the shape and the position of the objects detected in the previous step, are extracted, more specifically:AreaThe area of the object is computed by summing the area of the individual pixels which compose this object. The area of an individual pixel is determined by looking at its 2×2 neighborhood.EccentricityThe eccentricity of the object is the ratio of the distance between the foci of the ellipse that has the same second-moments as the region of the object and its major axis length. Its value is from 0 to 1. An ellipse whose eccentricity is 0 is actually a circle, while an ellipse whose eccentricity is 1 is a line segment.CentroidThe centroid expresses the center of the mass of the region of the object.The elimination procedure takes into account the area characteristics extracted in the previous step. Since the PCL are small in size objects, all objects with area larger than 13,000 pixels or smaller than 100 pixels are removed (Fig. 5a). The fact that regions of interest (ROIs) are adjacent to fissures of the tooth implies that ROIs have line shape. For this purpose objects with eccentricity lower than 0.6 are eliminated (Fig. 5c). Finally, the observation that the fissures of the tooth start from the center and propagate to the perimeter of the tooth leads to the elimination of objects having Euclidean distance of their centroid from the center of the tooth larger than 300 pixels (Fig. 5b). The rules applied for the elimination of false detected PCL are expressed through the following formulas:(4a)area(reg)>13,000||area(reg)<100,(4b)eccentricity(reg)<0.6,(4c)distance(centertooth,centroidregion)>300.The segmentation of the COL is applied to red, green, and blue channel of the color image separately. The results obtained from the three channels are fused. The reason for applying the detection procedure to the three channels separately is the fact that the boundaries of the object are different depending on the channel which is used.The earliest sign of a new carious lesion is the appearance of a chalky white spot on the surface of the tooth, indicating an area of demineralization of enamel. As the lesion continues to demineralize, it may turn brown and if the process continues it will eventually turn into a cavitation. Some of the pre-cavitated or cavitated lesions will become discolored (dark brown to black). Dark brown regions surrounded by regions with different colorations of brown are a common finding in the occlusal surface of teeth when carious process has statrted. These regions of discoloration of the tooth can be detected using the three channels of the color image. More specifically, dark brown regions can be detected from the red channel, lighter brown regions can be detected from the green channel, while regions in the first stages of discoloration can be detected from the blue channel (Fig. 6).From the initial color image the red, green and blue channel are assigned to different images,red_im,green_im, andblue_im, respectively. The contrast of each one of these images is enhanced through regional application of partitioned iterated function systems (PIFS) [37]. More specifically, the technique combines Region Growing [38], for segmenting the subject images into large and smaller regions, with the application of PIFS, for processing the extracted regions. The objective of the proposed algorithm described in [38] is to provide strong contrast enhancement by increasing the mean contrast measurement of the enhanced image without affecting the information stored in the original image. The enhanced imageIenh(x,y)is given by(5)Ienh(x,y)=I(x,y)+λIHP(x,y),whereI(x,y)is the original gray-level image (red_imorgreen_imorblue_im), the parameterλadjusts the contrast gain andIHP(x,y)is the high pass image which is given as(6)IHP(x,y)=I(x,y)−ILP(x,y).TheILP(x,y)is the low pass version of the original image. The low pass image is created by applying the global contractive transformationW, defined in [38], to the original image for low value of the encoding/decoding factorγ. The resutls of the contrast enhancement procedure are depicted inFig. 7. The images produced after the application of the contrast enhancement procedure are converted to binary by applying a theshold computed using the Otsu׳s method (Fig. 8) [34].For the segmentation of COL, the following procedure is applied. First, the mask of the tooth is applied to the binary image from the previous step, in order artefacts presented in the background of the image to be removed (Fig. 9a). The mask that is the same with the one that was created during the preprocessing procedure described in Section 2.2.1 (Fig. 2d). Then the perimeter of the depicted objects is extracted (Fig. 9b). Finally, the perimeter of the tooth is removed (Fig. 9c). This is achieved by finding the pixels which have value 1 both in the image depicting the perimeter of the tooth and in the image depicting the detected objects and converting them to the off situation (pixels with value 0).For each detected region, the area and the centroid are extracted. The area and centroid are computed in the same way which described in Section 2.2.1The elimination of the objects corresponding to COL is achieved by applying rules concerning the area of the object and their distance from the perimeter of the tooth and from the center. More specifically, objects with area lower than 30 pixels or greater than 900 pixels are eliminated. The intensity of pixels of objects which are close to the perimeter of the tooth, is set equal to zero using morphological operators. The dilation operation (with a squared structure element whose width is 10 pixels) is applied on the image of the perimeter and then the resulted image is projected on the image which depicts the cavitated occlusal objects. Finally, objects with distance larger than 1000 pixels from the center of the tooth are eliminated (Fig. 10). It must be mentioned that the application of the rules is made sequentially with the order reported above(7a)area(reg)<30||area(reg)>900,(7b)distance(centertooth−centroidreg)>1000.The threshold values utilized in the object elimination rules (Sections 2.2.2.1.2 and 2.2.2.2.2) were selected employing a grid search technique.The objects that remain from the previous step from each channel of the color image are projected onto the same binary image (Fig. 11a) (fusion_im). To address the fact that the boundaries of the same region of interest are differentiated depending on the channel of the color image the logical operator AND is applied between the images of the different channels. More specifically, the operator AND is applied between the red and green channel and it detects the objects which are depicted in the red channel and overlap with objects depicted in the green channel. The detected objects are removed from the binary image (fusion_im) (Fig. 11b). The operator AND is then applied again between the image of the previous step and the blue channel. The detected objects are removed again (Fig. 11c).The detected objects which correspond to PCL (Fig. 12a) and the detected objects that correspond to COL (Fig. 12b) are projected onto the same image (Fig. 12c). The centroids of the depicted regions are computed (Fig. 12c, symbols with magenta color correspond to the centroids of the PCL and symbols with yellow centroids correspond to the centroids of the COL). The distance between the centroids of the PCL with each one of the centroids of the COL is also computed. If the distance is larger than 320 pixels, the corresponding pre-cavitated regions are eliminated (Fig. 12d). The application of this rule aims to retain only the objects which are close or surround cavitated occlusal objects. Finally, the average contrast is calculated. If the average contrast is lower than the mean average contrast of all objects, the object is removed. The remainig objcets are projected onto the initial image (Fig. 12e).The classification stage consists of four steps: (a) feature extraction, (b) feature selection, (c) classification where pixels of the detected regions are assigned to one of the seven classes defined according to the ICDAS II system using the Random Forests classifier, and (d) classification of the region.A set of features is extracted for each pixel in the region of interest for a 15×15 neighborhood. This set of features consists of texture-based features, such as co-occurrence matrices [40,41] and Local Binary Patterns (LBPs) [42,43] and of intensity-based features [32,40], such as the mean intensity of the neighborhood and the entropy. From the co-occurance matrices, the contrast, homogeneity, energy and correlation are computed for eight different angles (0°, 45°, 90°, 135°, 225°, 270°, 315°) [40]. For the computation of the LBPs the unifrom rotation is utilized [39]. The aforementioned features provide a set of 44 features per pixel. Since the features are extracted for each pixel from the three different color channels a set of 132 features is created per pixel. The features are described by the following formulas:(8a)contrastθ=∑i=1L∑j=1L(i−j)2CMij,(8b)correlationθ=∑i=1L∑j=1LCMij[(i−μi)(j−μj)σi2σj2],(8c)energyθ=∑i=1L∑j=1LCMij2,(8d)homogeneityθ=∑i=1L∑j=1LCMij1+|i−j|,CMij(8e)LBPP,Rriu2={∑p=0p−1s(gp−gc),ifU(LBPP,R)≤2P+1,otherwise(8f)entropy=∑i=0L−1pilog2(1pi)(8g)meanintensity=1M∑(k,l)∈NeiI(k,l)whereCMijis theijelement of the co-occurance matrixCM,Lis the number of gray levels of the imageI,μi=∑i=1L∑j=1LiCMij,μj=∑i=1L∑j=1LjCMij,σi2=∑i=1L∑L(i−μi2)CMij,σj2=∑i=1L∑j=1L(j−μj2)CMij,gcis the gray level of the center pixel,gpis the gray level of the circularly symmetric neighborhood,Pis the number of members of the circularly symmetric neighborhood,Ris the radius of the circle,pi=numberofpixelswithgrayleveli/totalnumberofpixels,Mis the number of pixels belonging to the neighborhoodNeiand(k,l)are the positions of the pixels belonging to the neighborhoodNei.U(LBPP,R)is given by(9)U(LBPP,R)=|s(gP−1−gc)−s(g0−gc)|+∑p=1P−1|s(gp−gc)−s(gp−1−gc)|,wheres(x)={1,x≥00,x<0.To identify the most significant features among the extracted ones in terms of classification performance and also to speed up the process, a correlation based subset selection approach was followed [44]. More specifically, it evaluates the worthof a subset of attributes by considering the individual predictive ability of each feature along with the degree of redundancy between them. Subsets of features which are highly correlated with the class while having low intercorrelation are preferred. For the evaluation of the best subset of features the following formula is applied:,(10)VS=numfrcf¯numf+numf(numf−1)rff¯whereVSis the value of subsetS,numfis the number of the features of the subset andrcf¯is the mean correlation of the features with the class andrff¯is the mean intercorrelation of the features.The application of the above mentioned feature selection algorithm results to a set of 36 features. Energy and homogeneity, for different angles, as well as, mean intensity and local binary patterns from the three color channels are the features that contribute to the differentiation between the defined classes (Table 1).For the classification of the pixels of the detected regions, five different classifiers were employed: J48 [45], Random Tree [46], Random Forests [46,47], Support Vector Machines [48], and Naïve Bayes [49]. The best results (see Section 3) were produced by the Random Forests algorithm. It is a classifier that consists of many decision trees. For the construction of each tree of the forest a new subset of samples is selected from the dataset. The tree is built to the maximum size without pruning. Only a subset of the total set of features is employed as the candidate splitters of the node of the tree. For each selected feature, the Gini index is computed. The feature with the best value of the Gini index is used for splitting the tree node. Once the forest is constructed a new sample runs through each tree in the forest and the tree “votes” the class that the sample belongs to. The predicted class is the one that gains most of the votes [47].In order the region to be classified, the methodology examines the class of the pixels around the center of the region. If those pixels belong to different classes (e.g. ICDAS 2 and ICDAS 4) then it selects the most severe class (in our example, ICDAS 4).

@&#CONCLUSIONS@&#
We presented a fully automated methodology for the assessment of occlusal caries that for the first time address not only the detection but the classification of the specific type of cavities according to ICDAS II. It can provide similar or better performance as a trained dentist in classifying occlusal caries according to the ICDAS II system. It is fully automated excluding any subjective input from the dentist and it does not subject the patients to radiation exposure. It can become a very useful tool assisting the dentist to take a more consistent unbiased and accurate decision for the treatment of occlusal caries. It has the advantage of improving as more pictures with known classification is used to train it and even more importantly the algorithm can always be adjusted to incorporate any new knowledge on caries diagnosis through the utilization of appropriate features and inclusion or exclusion rules. Although the achieved performance is satisfactory, more research is needed to validate the present results with the histological gold standard of the lesions and improve further the performance of the ACDS.