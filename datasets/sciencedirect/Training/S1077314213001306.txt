@&#MAIN-TITLE@&#
Feature-domain super-resolution for iris recognition

@&#HIGHLIGHTS@&#
We propose a framework for iris super-resolution (SR) using Gabor-based nonlinear features.In the literature, there exists only SR using biometric linear features, which are not the most discriminant features, especially for iris.This feature-domain SR framework incorporates iris model information in form of prior probability to constrain the reconstruction.Extensive experiments have confirmed the validity of the framework.This SR framework can also be applicable to any other biometrics modalities.

@&#KEYPHRASES@&#
Super-resolution,Feature-domain super-resolution,Iris recognition,Iris recognition at a distance,

@&#ABSTRACT@&#
Uncooperative iris identification systems at a distance suffer from poor resolution of the acquired iris images, which significantly degrades iris recognition performance. Super-resolution techniques have been employed to enhance the resolution of iris images and improve the recognition performance. However, most existing super-resolution approaches proposed for the iris biometric super-resolve pixel intensity values, rather than the actual features used for recognition. This paper thoroughly investigates transferring super-resolution of iris images from the intensity domain to the feature domain. By directly super-resolving only the features essential for recognition, and by incorporating domain specific information from iris models, improved recognition performance compared to pixel domain super-resolution can be achieved. A framework for applying super-resolution to nonlinear features in the feature-domain is proposed. Based on this framework, a novel feature-domain super-resolution approach for the iris biometric employing 2D Gabor phase-quadrant features is proposed. The approach is shown to outperform its pixel domain counterpart, as well as other feature domain super-resolution approaches and fusion techniques.

@&#INTRODUCTION@&#
Biometric systems enable the automatic identification of individuals based on their physiological and behavioural characteristics such as face, fingerprint, palmprint, gait, iris, retina, and voice. Among the biometrics, the iris has been shown to be one of the most accurate traits for human identification due to its stability and high degree of freedom in texture [1,2]. Most existing iris recognition systems require users to present their iris to a camera at close distance (less than 0.6m), to ensure images of sufficient quality are captured. The research community is interested in enabling iris recognition to be conducted in less constrained environments, such as when the subject is moving and at a distance. The two most significant problems when performing iris recognition at a distance are pixel resolution (i.e. the number of pixels in the iris region) and quality variation of the captured images [3].Super-resolution techniques have previously been employed to address the low resolution problems of imaging systems [4]. There are two differing super-resolution approaches: reconstruction-based and learning-based. Reconstruction-based approaches such as [5–12] fuse the sub-pixel shifts among multiple low resolution images to obtain an improved resolution image. Alternatively, learning-based approaches model high-resolution training images and learn prior knowledge to constrain the super-resolution process [4].Recently, super-resolution techniques have been applied to biometric systems. A number of super-resolution techniques have been successfully developed for face [13–17] and iris [18–21]. Kwang et al. [19] propose a learning-based super-resolution method using multiple MLPs (multi-layer perceptrons). The middle and high frequency components of a low resolution iris image are restored from the trained neural network architecture. Huang et al. [20] propose another learning-based method utilising a CSF (Circular Symmetric Filter). Their algorithm predicts the prior relation between iris feature information of different bands and incorporates this into the process of iris image enhancement. From a reconstruction perspective, Fahmy [18] proposed a reconstruction-based super-resolution technique to restore multiple low-resolution iris frames captured at a distance of 3feet. Nguyen Thanh et al. [21] proposed to incorporate quality metrics into the super-resolution process to improve performance by assigning better quality frames a higher weight when fusing multiple low resolution images. Nguyen Thanh et al. [21] employs an exponential fusion scheme to estimate the high-resolution image from the low-resolution image sequence.One main concern raised by both Gunturk et al. [22] and Nguyen et al. [23] is how to apply super-resolution for a specific biometric modality effectively to improve recognition performance, rather than visual clarity. Two issues have been raised:•The aim of applying super-resolution to biometrics is not for visual enhancement, but to improve recognition performance. Most existing super-resolution approaches are designed to produce visual enhancement. If recognition improvement is desired, why do we not focus on super-resolving only items essential for recognition?Each biometric modality has its own characteristics. Most existing super-resolution approaches for biometrics are general-scene super-resolution approaches. Can any specific information from biometric models be exploited to improve super-resolution performance?Based on these concerns, feature-domain super-resolution techniques have been proposed for face [22,24] and iris [23] to improve recognition performance. These approaches no longer super-resolve images in the pixel-domain, but super-resolve the extracted features that are used for classification in the feature-domain, and the super-resolution output (a super-resolved feature vector) is directly employed for recognition. Different linear features including Principle Component Analysis (PCA) [22,23] and Tensor Face [24] have been investigated to improve the respective biometric modalities. These features are super-resolved to increase the resolution using a maximum a posteriori estimation approach. Specific knowledge of face and iris models are incorporated in the form of prior probabilities to constrain the super-resolution process, to make it robust to noise and segmentation errors. These approaches have been shown to outperform pixel-domain super-resolution approaches for face and iris recognition.However, for the specific case of the iris biometric, the 2D Gabor wavelet has been shown to be one of the most effective encoding techniques since it achieves the best trade-off in both spatial and spectral resolution [25,26]. The major challenge that prevents feature-domain super-resolution from being successfully applied to the 2D Gabor phase-quadrant encoding technique is the non-linear nature of the encoding technique.The existing feature domain super-resolution frameworks of [22–24] are unable to super-resolve non-linear features, and are thus not suitable for use with the 2D Gabor wavelet features. To further improve the performance of feature-based super-resolution for iris recognition, we seek to provide a new feature-domain super-resolution framework to overcome the non-linearity of 2D Gabor wavelet features. Using the proposed framework, a novel feature-domain super-resolution approach using 2D Gabor wavelets and the iris biometric is proposed. We show that the proposed approach outperforms the unenhanced features, the pixel domain super-resolution equivalent, as well as other existing feature domain super-resolution and fusion techniques. It should be noted that the proposed framework can also be applied to other non-linear features and other biometrics.The remainder of this paper is organised as follows: a framework for applying feature-domain super-resolution with nonlinear features is investigated in Section 2; Section 3 describes the proposed feature-domain super-resolution approach for iris images; Section 4 describes the approach to estimate initial parameters of the estimation; Section 5 presents the experimental results; and the paper is concluded in Section 6.Linear encoding techniques such as PCA and LDA have been investigated for feature-domain super-resolution for iris [23] and face [22]. A PCA encoding technique seeks to project an image onto dimensions which best reconstruct the original data. Alternatively, a LDA encoding technique projects an image onto dimensions which maximise the separation of classes. Both methods capitalise on the global trend in the training data to represent each iris image as a linear superposition of fundamental functions (eigenface/eigeniris for PCA and fisherface/fisheriris for LDA). These techniques have been employed to conduct pioneering experiments on iris feature-domain super-resolution [23], and face feature-domain super-resolution [22]. The benefit of using PCA and LDA features is their linear superposition property, which simplifies the estimation of the high resolution features. However, these global features lose spatial information since they decompose the 2D image into a 1D vector [27].For the iris biometric, the phase-quadrant encoding technique based on 2D Gabor wavelets has been shown to extract the most discriminant features of an iris [2,28]. The advantages of this encoding technique are rapid matching, a binomial impostor distribution and a predictable false acceptance rate [26]. Furthermore, 2D Gabor wavelets have also been shown to be highly effective for face recognition tasks [29]. Hence, employing these coarse phase features rather than PCA or LDA within feature-domain super-resolution has the potential to further improve recognition performance, advancing the state-of-the-art biometric systems. Despite these advantages, the non-linear nature of the encoding technique has prevented it from being investigated for feature-domain super-resolution. The non-linearity (due to the use of phase-quadrant encoding) makes the estimation of a high resolution feature from multiple low resolution features very challenging [23], as it makes the relationship between the multiple low resolution features and the high resolution feature very difficult to establish. In the remainder of this section, we analyse this encoding technique to discuss how feature-domain super-resolution can be applied using the non-linear 2D Gabor features.A brief description of the conventional iris encoding technique [2] is illustrated in Fig. 1. Prior to feature extraction, an eye image is segmented to locate and extract the iris region. Two circles are employed to approximate the pupillary and limbus boundaries of the iris region. This region is normalised to a fixed size so that it can be used for comparison. The normalisation process uses a rubber-sheet model to transform the iris texture from Cartesian to polar coordinates. The remapping of the iris image I(x,y) from raw Cartesian coordinates (x,y) to the dimensionless polar coordinates (r,θ) can be represented as,(1)I(x(r,θ),y(r,θ))→I(r,θ),where r is on the unit interval [0,1], θ is an angle in the range [0,2π], x(r,θ) and y(r,θ) are defined as a linear combination of both the set of pupillary boundary points (xp(θ),yp(θ)) and the set of limbus boundary points (xs(θ),ys(θ)), such that,(2)x(r,θ)=(1-r)xp(θ)+rxs(θ),y(r,θ)=(1-r)yp(θ)+rys(θ).Each normalised iris is then demodulated to extract the phase information using quadrature 2D Gabor wavelets,(3)hRe,Im=signRe,Im∫ρ∫ϕI(ρ,ϕ)e-iω(θ0-ϕ)e-((r0-ρ)2/α2+(θ0-ϕ)2/β2)ρdρdϕ,where hRe,Imcan be regarded as a complex-value component whose real and imaginary parts are either 1 or 0 depending on the sign of the 2D integral; I(ρ,ϕ) is the normalised iris image; α and β are the multi-scale 2D wavelet size parameters; and (r0,θ0) represents the two dimensions of the normalised iris image. Only phase information is used for recognition because amplitude information is not discriminant, and depends on extraneous factors such as imaging contrast, illumination and camera gain [2]. Altogether, 2048 phase bits establish the IrisCode.The similarity between two IrisCodes is measured by a bitwise hamming distance given by,(4)HD=∑i=12048((Ai⊗Bi)∩(AiM∩BiM))∑i=12048(Ai⊗Bi),where AMand BMare respectively the masks of IrisCodes A and B, ∩ and ⊗ represents bitwise AND and XOR operator respectively. The masks are employed to exclude the corrupted regions from eyelashes, reflections, eyelids and low signal-to-noise ratio [2].To explore the non-linearity of the conventional phase-quadrant 2D Gabor wavelet, we present the encoding technique from a different point of view. Notice that the encoding process in Eq. 3 is equivalent to 2 sub-steps:1.Calculate the complex-valued 2D Gabor features.Encode the complex features using quadrant encoding technique.The non-linearity of the conventional phase-quadrant 2D Gabor wavelet encoding technique comes from the second sub-step. The complex-valued 2D Gabor features obtained from step 1 are not themselves suitable for recognition as they are affected considerably by changes in illumination [2], thus the quadrant encoding of step 2 is required to obtain features suitable for matching. The complex-valued 2D Gabor features are, however, linear. Instead of performing feature-domain SR on the final non-linear phase-quadrant features, we propose performing feature-domain SR on the intermediate complex-valued 2D Gabor features and then encode the complex-valued super-resolved output with the non-linear phase-quadrant encoding technique. This framework can take advantage of both the linear property of complex-valued 2D Gabor features and the highly discriminant property of phase-quadrant 2D Gabor wavelet encoding. The approach is illustrated in Fig. 2.Note that this framework can be easily extended to most non-linear encoding techniques for iris including the conventional approach proposed by Daugman [2,28], and other recent state-of-the-art approaches such as [26,30,31], since all of them calculate the linear complex-valued features first before encoding them with non-linear techniques. The proposed framework can also be extended to other biometric modalities such as face. The next Section will introduce a novel feature-domain super-resolution approach for the iris biometric based on the proposed framework.Our goal is to estimate the 2D Gabor features of the HR images, which we call the high-resolution (HR) features, from the observed low-resolution (LR) features. To solve this estimation, the relationship between the HR features and the respective observed LR features of the same iris needs to be established. This relation can be estimated from the spatial domain relation between the HR images and the respective LR images in the conventional super-resolution problem. Since the problem of estimation can be regarded as an approach to estimate an unobserved quantity on the basis of empirical data, a Bayesian statistics estimator called maximum a posteriori can be employed to seek the resolution [32]. When solving the estimation, specific information relating to iris models can be exploited to improve the accuracy of the estimation. The proposed five-step algorithm is illustrated in Fig. 3. Details in each step are covered in the remainder of this section.Stage 1: Observation model in the spatial domain.Let x be the original HR iris image, and y(i) be the ith observed LR iris image after being degraded by downsampling, D(i); blurring, B(i); and warping, W(i). The relation between x,y(i) is described as follows [4],(5)y(i)=H(i)x+n(i)=D(i)B(i)W(i)x+n(i),where n(i) is the observation noise. The blur matrix, B(i), models both the optical blur and motion blur, as outlined in [4].Stage 2: Observation model in the feature domain.We seek to transform the observation model from the spatial domain to the feature domain. The phase-quadrant 2D Gabor features (IrisCodes) of HR irises, h, and LR irises, h(i), are represented as follows,(6)hRe,Im=signRe,Im(g),(7)hRe,Im(i)=signRe,Im(g(i)),where g and g(i) are the complex-valued vectors representing 2D Gabor features of HR irises and LR irises respectively given by,(8)g=∫ρ∫ϕxe-((r0-ρ)2/α2+(θ0-ϕ)2/β2)e-iω(θ0-ϕ)ρdρdϕ,(9)g(i)=∫ρ∫ϕy(i)e-((r0-ρ)2/α2+(θ0-ϕ)2/β2)e-iω(θ0-ϕ)ρdρdϕ.Substituting the spatial observation model of Eq. 5 into the HR feature representation of Eq. 9, we have,(10)g(i)=∫ρ∫ϕ(D(i)B(i)W(i)x+n(i))e-((r0-ρ)2/α2+(θ0-ϕ)2/β2)e-iω(θ0-ϕ)ρdρdϕ=∫ρ∫ϕD(i)B(i)W(i)xe-((r0-ρ)2/α2+(θ0-ϕ)2/β2)e-iω(θ0-ϕ)ρdρdϕ+∫ρ∫ϕn(i)e-((r0-ρ)2/α2+(θ0-ϕ)2/β2)e-iω(θ0-ϕ)ρdρdϕ=G1+G2We make the following assumptions:1.For each iris image, blurring and warping factors, which degrade the quality of the iris image, are changing along the image. This explicitly means the blurring and warping level varies according to the location of the pixel in the image. In this case, B(i) and W(i) are a function of ρ and ϕ. However, we can make an approximation and assume that B(i) and W(i) are uniform over the normalised iris image. With this assumption, the first component of Eq. 10 can be represented as,(11)G1=∫ρ∫ϕD(i)B(i)W(i)xe-((r0-ρ)2/α2+(θ0-ϕ)2/β2)e-iω(θ0-ϕ)ρdρdϕ=D(i)B(i)W(i)∫ρ∫ϕxe-((r0-ρ)2/α2+(θ0-ϕ)2/β2)e-iω(θ0-ϕ)ρdρdϕ=D(i)B(i)W(i)gNoise, n(i), is properly assumed to be an Independently Identical Distributed (IID) Gaussian signal. The 2D Gabor wavelet transform can be considered as a local Fourier transform. Moreover, the 2D Fourier transform of a Gaussian signal has a Gaussian form. Hence, the 2D Gabor wavelet transform of the noise, which is the second component in Eq. 10, can be approximated as an IID Gaussian signal.With these two assumptions, Eq. 10 can be re-written as,(13)g(i)=D(i)B(i)W(i)g+v(i).Eq. 13 shows the relationship between the HR and observed LR iris features.In Eq. 13, the blurring matrix, B(i), can be estimated using the approach proposed in [21]. This approach works by measuring the energy of the high frequency components in the images using a spatial 8×8 high pass filter.Estimating the warping matrix ,W(i), is achieved by finding a matrix that registers the frames with a selected reference frame (the reference frame is chosen by the frame with the highest quality score in the sequence). The accuracy of this step is critical for the super-resolution process, and the images must be registered at the sub-pixel level. There are different approaches for registering irises with sub-pixel accuracy such as [33,34]. For the trade off between accuracy and simplicity, in this research, we follow the patch-based registration approach outlined in [33]. A patch size of 7×7 and neighbourhood size of 10×10 are used. Phase correlation is employed to judge the similarity between patches. In our experiments, three peaks are employed in the phase correlation map for estimating the shift of the patch. Iris images usually suffer from image deformation problems. Dividing normalised iris frames into smaller patches and aligning each local patch with the template will compensate for the local deformation.The following sections will discuss a solution to estimate the HR iris features from this equation.Stage 3: Estimating HR features.In Bayes statistics, a maximum a posteriori probability estimate can be used to estimate an unobserved quantity on the basis of empirical data. Using Bayes maximum a posteriori probability estimation, a HR feature can be estimated as,(14)g̃=argmaxgp(g(1),…,g(M)|g)p(g).The estimated HR feature,g̃, is the value that maximises the product of the conditional probability p(g(1),…,g(M)—g) and the priori probability p(g). M is the number of the observed LR images.Stage 4: Incorporating iris model information.To solve the above estimation problem, specific information relating to iris models can be incorporated in the form of two assumptions:•Prior probability is jointly Gaussian,(15)p(g)=1Zexp(−(g−μg)TΛ-1(g−μg)).Noise, v(i), is an Independent Identically Distributed (IID) Gaussian with a diagonal covariance matrix,(16)p(v(i))=1Zexp(−(v(i)−μv(i))TK-1(v(i)−μv(i))).The process of estimating of the statistics of the prior probabilities of the features and the noise from the training set is explained in Section 4.From Eq. 13, the individual conditional probability can be estimated as,(17)p(g(i)|g)=1Zexp(-(g(i)-D(i)B(i)W(i)g-μv(i))TK-1(g(i)-D(i)B(i)W(i)g-μv(i))).From Eq. 13, g(i)−D(i)B(i)W(i)g is IID as a consequence of the fact that v(i) is IID, thus,(18)p(g(1),…,g(M)|g)=∏ip(g(i)|g)=1Zexp-∑i=1M(g(i)-D(i)B(i)W(i)g-μv(i))TK-1(g(i)-D(i)B(i)W(i)g-μv(i)).The estimation problem can then be rewritten as,g̃=argmaxg(p(g(1),…,g(M)|g)p(g))=argmaxg1Zexp-∑i=1M(g(i)-D(i)B(i)W(i)g-μv(i))TK-1(g(i)-D(i)B(i)W(i)g-μv(i))×1Zexp(-(g-μg)TΛ-1(g-μg))=argming∑i=1M(g(i)-D(i)B(i)W(i)g-μv(i))TK-1(g(i)-D(i)B(i)W(i)g-μv(i))+(g-μg)TΛ-1(g-μg).Stage 5: Estimating the solution.The estimation in Stage 4 is an unconstrained optimisation problem. This optimisation can be solved by both iterative steepest descent and iterative conjugate gradients [35]. With a proper choice of the step size and the maximum number of steps, the iterative steepest descent method is capable of converging to the local minimum sharply. However, iterative steepest descent may never reach the true minimum [35]. Instead of employing steepest gradient directions for iterative updating, a conjugate gradients method utilises conjugate directions, which enables the method to converge more accurately in at most n steps, where n is the size of the matrix of the system [35]. Given this, we solve the optimisation problem in Stage 4 by iterative conjugate gradients. Let the cost function E(g) be defined as,(19)E(g)=∑i=1Mg(i)-D(i)B(i)W(i)g-μv(i)TK-1(g(i)-D(i)B(i)W(i)g-μv(i))+(g-μg)TΛ-1(g-μg).The solution for optimisation can be estimated iteratively as follows,(20)gn+1=gn+αnΓgn,where Γgnis defined as,(21)Γgn=▵gn+βnΓgn-1,where ▵gn=−∇gE(gn) andβn=max(0,βnPR), and(22)βnPR=▵gnT(▵gn-▵gn-1)▵gn-1T▵gn-1.αnis the parameter to minimise E(gn+αnΓgn) through a line search. Hence, with an initial estimation g0, the iterative conjugate gradients estimation method will converge to the true high-resolutiong̃which minimises the cost function E(g).The estimation solution as explained in Section 3 requires the statistics of noise and the prior probability of HR features to be estimated before hand. This section describes this prerequisite estimation performed on a training set (details of the training set used in this work are presented in Section 5).For the high resolution images and video sequences, irises are detected, segmented, and transformed into the polar representation. The high resolution features are extracted from these polar representations using the Gabor-based phase-quadrant encoding technique. With each video sequence, there are up to 20 frames with significant variation in quality. As Daugman has claimed in [2], the features extracted using the Gabor-based phase-quadrant encoding technique are robust to some ranges of quality variation. With a small amount of variation, the features are still able to capture the discriminant components from the images. However, if the quality varies significantly, this property of the Gabor-based phase-quadrant encoding technique no longer exists. Therefore, within a video sequence, the very low quality frames do not provide the required discriminant components. These very low quality frames are eliminated using a quality threshold. This threshold is selected through experimentation.Prior probability of the HR features has been assumed to have a Gaussian form with mean vectors μgand covariance matrix Λ given by,(23)μg=1M∑i=1MG(i),(24)Λ=1M∑i=1M(G(i)-μg)(G(i)-μg)T,where G(i) is the HR features of the ith training image, M is the total number of training images.From Eq. 13, 2D Gabor complex features of noise in the observation equation can be estimated as,(25)v(i)=g(i)-D(i)B(i)W(i)g.The statistics of noise in the form of a mean vector μvand a covariance matrix K can be estimated as,(26)μv=1M∑i=1M(g(i)-D(i)B(i)W(i)g),(27)K=1M∑i=1M(g(i)-D(i)B(i)W(i)g-μv)×(g(i)-D(i)B(i)W(i)g-μv)T.The statistics of noise and prior probability estimated here are used to bolster the estimation process described in Section 3.

@&#CONCLUSIONS@&#
