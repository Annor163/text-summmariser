@&#MAIN-TITLE@&#
Segmentation of the spinous process and its acoustic shadow in vertebral ultrasound images

@&#HIGHLIGHTS@&#
Texture descriptors and state-of-the art features allowed accurate segmentation.The features were optimized for vertebral region discrimination in ultrasound.Regularization accounts for geometrical properties of vertebral ultrasound images.

@&#KEYPHRASES@&#
Image processing,Ultrasound,Vertebrae,Image segmentation,Pattern classification,Acoustic shadow,Scoliosis,

@&#ABSTRACT@&#
Graphical abstract

@&#INTRODUCTION@&#
Ultrasound imaging is abundantly used in medical diagnostic and interventional procedures requiring the visualization of soft tissues [34,2,27,24,28,35]. Recently, it has also emerged as a useful, low cost tool for applications that involve imaging bone structures such as guidance for epidural anesthesia [1], bone fracture assessment [13] and scoliosis assessment and monitoring [29,26]. However, the interpretation of bone ultrasound images is very challenging. Ultrasound waves are totally reflected by bone surfaces, creating an acoustic shadow below them and, depending on the orientation of the probe, a bright area at the soft tissue–bone interface.In this paper, we consider the specific context of spine imaging for scoliosis, where ultrasound-based methods have shown potential as a radiation-free alternative to X-ray imaging. Potential applications include deformity assessment [26,5,29], spinal brace adjustment [20,19] and dense 3D spine surface reconstruction [22]. The current gold standard measure for assessing scoliosis (as well as its progression or the effectiveness of a treatment) is the Cobb angle, measured on postero-anterior X-ray images. Most of the work cited above has focused on reproducing this measurement, or rather proxies of this measurement (e.g., using the Spinous Process Angle [19], the Center of Laminae method [22] or the Transverse Process Angle [26]), since the orientation of the vertebral endplates, which define the Cobb angle, cannot be visualized in ultrasound images. The proposed methods of measurement mirror what is typically done in clinical practice with the X-ray images, i.e., they are entirely based on the manual identification of anatomical features, which is time consuming and lacks repeatability. These difficulties are exacerbated by the low perceptual quality of vertebral ultrasound images.In the particular case of the spinous process, which is the prominent bone feature appearing in transverse vertebral ultrasound images, the interface with soft tissue is very short and its brightness is strongly dependent on the orientation of the probe. In addition, while its acoustic shadow could provide useful cues about the shape of the vertebra and the possible location of the laminae and transverse processes, the boundary of this shadow is difficult to delineate accurately in practice. As a first step towards automated vertebral landmark identification, this paper proposes a method to automatically segment the most prominent features appearing in transverse vertebral ultrasound images: the spinous process and its acoustic shadow.Several methods were developed for the automatic detection of key anatomical structures in vertebral ultrasound images in the context of ultrasound-guided epidural needle insertion. Their goal is ultimately to determine where to insert the needle for effective injection of the anesthetic. Automatic extraction of the lamina was proposed by Tran and Rohling [25]. Their method uses a ridge detector followed by matching with a binary template of the lamina to capture all the lamina contained in the image; it then segments the ligamentum flavium (also using template matching) on the regions below the lamina. The method detects the lamina and ligamentum flavium with a success rate of 87%. Kerby et al. [17] proposed a method for the automatic identification of lumbar levels in panoramic ultrasound images. This method extracts a wave-like profile from the image with a median filter and two linear filters operating in the horizontal and vertical directions. Lumbar levels are identified as the local maxima of this profile. Ashab et al. [1] used this method for guidance by projecting the image of the segmented lumbar levels onto the back of the patient. This system was shown to provide needle insertion accuracy within a clinically acceptable range. The previously cited methods are concerned with vertebral ultrasound images acquired in the paramedian view. In our case, we are interested in the transverse view, which provides more information regarding the shape of each vertebra, and, when combined to a freehand 3D acquisition protocol, is better suited to the use of the Spinous Process Angle and the Center of Laminae methods for assessing scoliosis.Recently, a method for automatic detection of the bone and inter-spinous regions in vertebral ultrasound images acquired in the transverse plane was developed by Yu et al. [31]. The method first involves pre-processing the image using a difference of Gaussians filter and local intensity normalization. Then, binary templates describing the transverse processes and the vertebral body are used with a template matching algorithm and a position correlation function in order to identify the key anatomical landmarks of interest. This approach was extended by using machine learning techniques to automatically detect the transverse processes. In this context, Yu and Tan [30] tested a neural network, a cascading classifier [32] and a support vector machine [33] as classifiers. Support vector machines obtained the best results with a success rate of 92.3% for the automatic detection of bone and inter-spinous regions. This work focused on the lumbar region of the spine, where the spinous process is larger and aligned with the vertebral body and the transverse processes. This is not the case in the thoracic region of the spine, which we are also interested in.Alternatively, spinal anatomy could implicitly be detected by establishing correspondence (i.e. registration) between freehand 3D ultrasound data and a generic 3D model (or, more generally, a statistical atlas) of the spine surface, using methods proposed in the context of image-guided epidural anesthesia. Khallaghi et al. [18] optimize the similarity between the ultrasound data and synthetic ultrasound images generated from the 3D spine model using a simulation method. Hacihaliloglu et al. [14] propose instead to match bone surfaces from the model to bone surfaces enhanced using local phase tensor features in the ultrasound image. Dense segmentation of the ultrasound images, as proposed in this paper, and segmentation of acoustic shadow in particular, could certainly be exploited as part of such model-based registration strategies to utilize only meaningful correspondences, as proposed by Coupé et al. [7] in the context of image-guided neurosurgery.Outside the context of spine imaging, automatic segmentation of bone surfaces and acoustic shadows in ultrasound images has been more deeply explored. Daanen et al. [8] proposed a segmentation algorithm for bone surfaces using the main properties of these regions: highly echogenic structures, creation of acoustic shadow, specular reflection, continuous structures and homogeneous contrast within these structures. This algorithm achieved a mean localization error of 1mm for sacrum images. Foroughi et al. [11] combined a local edge detector and the sum of the intensities below each pixel to create a “bone probability map”, then segmented the bone surfaces by minimizing a cost-function based on the continuity and smoothness of these regions. The latter two methods exploited the continuity of bone regions for segmentation, which is very effective for large bone structures, but not for short surfaces like that of the spinous process. Another method proposed by Hacihaliloglu et al. [13] measures the presence of a bone surface in ultrasound images using local phase symmetry. This was applied to ultrasound images of the radius. In vertebral ultrasound images, fat tissues and ligaments are present in addition to bone, and these structures also lead to high phase symmetry, thereby limiting the specificity of the approach. Hellier et al. [15] developed a method to detect the boundary between acoustic shadows and the tissues above them using statistical tests along each scan line, accounting for the geometry of the ultrasound transducer. This method was applied to the shadows cast by brain tumors, with a Dice similarity coefficient of 0.95 at a depth of 6cm. More recently, Karamalis et al. [16] used random walks incorporating a model of ultrasound image formation to create a confidence map which highlights acoustic shadows. A Dice similarity coefficient of 0.85 was obtained for a database of humerus ultrasound images.In preliminary work [3], we developed a method to automatically segment vertebrae in ultrasound images. The method combines a variety of features (many of them borrowed from the papers cited above) to drive a pixel-wise random forest classifier [4]. A spatial regularization step based on context-specific geometrical constraints was used to automatically segment the spinous process and its acoustic shadow post-classification. We obtained good results with classification rates of 81.97% for bone surfaces and 91.01% for acoustic shadow. In this paper, we extend our preliminary work in the following ways:•An additional feature based on Gabor filters is introduced that helps characterize the contrast between the acoustic shadow and the visible surrounding tissues.The regularization step is improved by constraining the segmentation to identify a unique region corresponding to the spinous process and to account for the convexity of the acoustic shadow cast by the spinous process.A feature selection step is also introduced to select the most relevant features. The selected features are rigorously validated based on their classification performance within a learning database.The image databases used for learning and testing now include data from a larger number of individuals as well as images acquired using two different transducers to better demonstrate the robustness of the method.The additional data and features allow us to use conventional linear discriminant analysis (LDA) for classification, which simplifies the segmentation process significantly without compromising accuracy or generalization.The method is thoroughly validated through application on the larger test set, as well as detailed analysis of its sensitivity and specificity. Dice similarity coefficient and Hausdorff distance measures are also computed to further evaluate segmentation accuracy.The rest of this paper is organized as follows: in Section 2, the different steps of the segmentation algorithm and the experimental methodology are described in detail. Our results are presented in Section 3, illustrating the promise of the proposed approach. Conclusions and directions for future work are given in Section 4.The purpose of the method is to classify each pixel of the ultrasound image into one of three categories: “spinous process”, “acoustic shadow” and “other tissues” (which correspond to the other anatomical structures in the image such as muscles, fat, and ligaments). The principle of the method is illustrated in Fig. 1. First, feature extraction is applied to the images of the learning database, providing one feature vector for each pixel. Next, feature selection is performed and pixels representing the three categories are randomly chosen from the images of the learning database to create the data set used to train a LDA classifier. The automatic segmentation of a new image is achieved in three steps. First, features are once again computed for each pixel of the image. Then, these pixels are classified into one of the three categories using the trained LDA classifier. Finally regularization of the different regions of the segmented image is performed to account for geometric constraints specific to vertebral images.The ultrasound images of the spine used in this study were collected from 7 healthy volunteers between 21years and 45years of age at Sainte-Justine Hospital, Montreal, Canada. During the acquisition, the volunteers were lying on a stretcher in prone position, and both the thoracic and lumbar regions of the spine were scanned using a Siemens Acuson S2000 ultrasound system (Siemens Healthcare, Erlangen, Germany). Images were acquired using both a curvilinear ultrasound probe (6C2) with a scanning depth of 6cm and central frequency set to 6MHz and a linear ultrasound probe (14L5) with a scanning depth of 4.5–6cm and central frequency set to 9MHz. A database of 175 images was thus obtained; their sizes varied from (400×260) to (680×553) pixels. The algorithms were implemented with MATLAB R2014a and run on a personal computer (Intel Core i7-4720HQ, 8GB memory and NVIDIA GTX965M).Several feature extraction methods previously used by others for describing bones surfaces, including image gradient, Foroughi et al.'s [11] bone probability map and phase symmetry [13], were implemented. In addition, to characterize the acoustic shadow, the rupture points described by Hellier et al. [15] were also detected. Furthermore, to discriminate the acoustic shadow and the spinous process from other tissues present in the ultrasound images, texture descriptors based on Local Binary Patterns (LBP) [12] and Gabor filters [6] were also extracted. Each of these features is described in more detail below.The intensity image and its gradient obtained with the Sobel gradient operator (Fig. 2) are used as features. Some information about the acoustic shadow and the bone surfaces is naturally provided by the image itself. The gradient image highlights the boundaries between distinct structures.Foroughi et al. [11] proposed a bone probability map based on two key characteristics of bone surfaces in ultrasound images: the presence of a bright ridge due to specular reflection, and the presence of acoustic shadow below this bright ridge. To obtain the bone probability map, a ridge map that highlights potential specular reflections is first built by filtering the image with a Laplacian of Gaussian filter, and this map is multiplied by a map of the quantity of shadow (SH), obtained by computing, for each pixel, the sum of the intensities of pixels lying below it:(1)SH(x,y)=∑j=yHG(j−y)I(x,j)∑j=yHG(j−y),where x and y are pixel coordinates,G(.)andI(.)represent a Gaussian windowing function and the image intensity, respectively, and H is the number of rows in the image. The standard deviation of the Gaussian window was empirically set to 2/3 of the image height. While the resulting bone probability map does highlight the spinous process, it may also highlight other tissues like ligaments or fat near a bone surface (Fig. 3). Such tissues also generate strong reflections and the acoustic shadow created by the nearby bone structure can be incorrectly associated with them.Since bone surfaces are smooth and highly echogenic, Hacihaliloglu et al. [13] use a ridge detector based on local phase symmetry to detect them. Measurements of local phase symmetryPS(x,y)at each pixel position (x,y) (Fig. 4) are obtained by combining the image's responses to Log Gabor filters at 2 different scales and 6 orientations:(2)PS(x,y)=∑r∑m⌊[|erm(x,y)|−|orm(x,y)|]−Tr⌋∑r∑merm2(x,y)+orm2(x,y)+ϵ.In Eq. (2), Tris a noise threshold, anderm(x,y)andorm(x,y)correspond to the responses of quadrature 2D Log Gabor filters [13] with scale r and orientation m in the frequency domain:(3)erm(x,y)=R(F−1(2DLGF(I(x,y)))),(4)orm(x,y)=I(F−1(2DLGF(I(x,y)))),whereF()andF−1()correspond respectively to the forward and inverse Fourier transforms,R()andI()respectively denote real and imaginary parts of a complex number andI(x,y)is the ultrasound image.2DLGdenotes the two-dimensional frequency domain Log Gabor filter defined as [10](5)2DLG(ω,ϕ)=exp(−(log((ω/ω0)22log((K/ω0)2+ϕ−ϕ02σϕ)),where K is the bandwidth of the filter in the radial direction, ω0 is the center frequency, ϕ0 is the orientation of the filter, i.e., the ridge orientation to which it is most sensitive, andσϕis the orientation spacing between the different filters. In this work, all free parameters were set exactly as recommended by Hacihaliloglu et al. [13].Fig. 4 shows the phase symmetry of a vertebral ultrasound image. The phase symmetry image was enhanced and normalized to demonstrate how this feature enhances bone structures but also other interfaces present in the image such as layers of fat and muscle fibers.This feature was developed as part of the acoustic shadow detection method proposed by Hellier et al. [15]. For each scan line of the ultrasound image, a statistical test is applied based on two criteria to detect the boundary of a potential acoustic shadow. The first criterion is a rupture in the signal. For each point of the scan line S, the local symmetric entropy coefficient ρ is computed as(6)ρ(x)=∑i=1n(S(x−i)logS(x−i)S(x+i)+S(x+i)logS(x+i)S(x−i)),where x is depth of the point tested along the scan line and n is a neighborhood size, which we empirically set to 8. Rupture points are then determined to be the maxima of ρ for each scan line. Acoustic shadows are regions where the noise variance is low; thus, the second criterion is based on the similarity between the statistics of the signal below the rupture points and noise model estimated above the rupture points. The image is binarized, associating shadow with regions below the shallowest rupture points failing the statistical test. As demonstrated in Fig. 5, this does provide a coarse indication of the presence of acoustic shadow, but sometimes detects acoustic shadow where there is none.LBPs [12] are often used as image texture descriptors. In this representation, each pixel is assigned two binary patterns derived from the sign s and magnitude m of the dissimilarities observed between this pixel and its neighbors:(7)LBPSignP,R=∑p=0P−1s(gp−gc)2p,s(x)={1x≥00<0and(8)LBPMagP,R=∑p=0P−1m(gp−gc)2p,m(x)=|x|.In Eqs. (7) and (8), gcand gprespectively correspond to the intensities of the central pixel and the neighboring pixels, P is the neighborhood size and R is a scale parameter. In this work, we empirically set P=8. The scale parameter R was optimized in terms of its Fisher score [9] with respect to classification, based on independent treatment of LBP sign and magnitude features:(9)D(FR)=∑c=1Cnc(μcFR−μFR)2∑c=1Cncnc(σcFR)2,where FRis the sign or magnitude LBP feature at scale R and nc, μFRandσcFRcorrespond respectively to the number, mean and standard deviation of FRfor the class c (which can correspond to spinous process, acoustic shadow or other tissues). Fisher scoresD(FR)for different values of R are shown in Table 1, and according to these data, the scale of the LBP was set to 16.LBPs are texture descriptors. When applied to ultrasound images, they especially highlight the speckle, so that there will be a contrast between speckle-free regions (e.g., most of the acoustic shadow) and regions with speckle, as shown in Fig. 6.The combined response of the input image I to a set of Gabor filters at 8 orientations evenly sampled on the interval(0,2π),(10)GTD(x,y)=∑i=18gi(x,y)⁎I(x,y),was used as an additional texture descriptor for the image. In Eq. (10), ‘⁎’ is the convolution operator and gidenotes the ith Gabor filter of orientation θidefined in the spatial domain as(11)gi(x,y)=exp(−xi′2+γ2yi′22σ2)exp(j(2πxi′λ+ψ))ψ∈{0,π},wherexi′=xcos(θi)+ysin(θi)andyi′=−xsin(θi)+ycos(θi)andj=−1. We empirically set the wavelength of the sinusoidal factorλ=1, the filter scaleσ=2.7and the spatial aspect ratioγ=0.4. The results were not found to be especially sensitive to these choices of parameters.The resulting feature enhances bright linear structures. These correspond to bones structures, but also to the layers of fat and muscle fibers in the ultrasound image (Fig. 7). Thus, the contrast between the acoustic shadow and the visible surrounding tissues is enhanced.To determine the most relevant subset of features necessary for classification, we use the sequential floating forward selection (SFFS) method proposed by Pudil et al. [23]. Its principle is to start with an empty set of features, iteratively adding the best features and removing the worst features according to a utility criterion. In our case, we seek to maximize the stability of the classifier. To this end, classification rates are measured each time a feature is added or removed from the set using threefold cross-validation. The algorithm terminates when all the features were added to the set or there is no significant change in classification rate. The resulting set of features is taken to be optimal.We used LDA [21], a generalization of Fisher's linear discriminant, as a classification method because it is simple and fast. Its principle is to create linear sub-spaces, obtained from linear combinations of the features, which maximize the ratios of between-class variance to within-class variance of the learning database. Based on the projections of the training data onto these sub-spaces, linear decision boundaries are computed that optimally separate the data belonging to each class from the data belonging to each of the other classes. New data requiring classification are subsequently projected onto the learned sub-spaces and assigned to a class based on the learned decision boundaries.Pixel classification provides an initial segmentation of the image into regions corresponding to the “spinous process”, “acoustic shadow” and “other tissues” classes. Regularization of the resulting regions is necessary to reflect the following context-specific geometrical constraints (Fig. 8):•Neighboring pixels are more likely to belong to the same region than to belong to different regions: To account for this, opening morphological operations with small structuring elements are first applied to the segmented image.The acoustic shadow of a vertebra is a very large region: In our images, the average acoustic shadow occupies on the order of 200,000 pixels. Thus, connected components initially labeled as “acoustic shadow” are relabeled as “other tissues” if they are smaller than 0.3% of this average size. This operation removes artifacts that could interfere with the next regularization operations.Pixels that are part of the spinous process region lie just above the top of the acoustic shadow: Therefore, connected components classified as “spinous process” which are not in the neighborhood of the top of the acoustic shadow are relabeled as “other tissues”. For each of the remaining connected components, the mean of the bone probability feature (see Section 2.2.2) is calculated. The connected component with the largest bone probability value is the only one to keep its “spinous process” label and the others are relabeled as “other tissues”.A vertebra casts only one acoustic shadow and this shadow has a smooth, convex shape: Therefore, a region of interest around the shallowest “acoustic shadow” pixel is defined and all connected components labeled as “acoustic shadow’ within the region of interest are merged. The region labeled as “acoustic shadow” is then expanded to fill the boundaries of its convex hull. Finally, the (now convex) boundary of the acoustic shadow is smoothed using a median filter.The gold standard used for training and testing the classifiers was a manual segmentation of all images validated by a radiologist. Furthermore, the visual quality of all images in the database were also assessed by the radiologist and the images of exceedingly poor quality were removed from the database. The final database was thus comprised of 107 images (out of the original 175) of reasonable quality. We used 2/3 of the images from each transducer for the learning database and the rest of images formed the testing database.Since the spinous process occupies a much smaller area in the images than the other two regions, using all the pixels from the learning database to train the classifier would lead to a highly unbalanced training set and poor classifier performance. Therefore, while the training set contains all the pixels belonging to the spinous process in the learning database, it does not include all pixels from the other two classes. For these, a total of seven times more pixels than for the “spinous process” class are used, thereby preserving a known, constant and reasonable ratio between the number of pixels for the spinous process and the number of pixels for the other two classes. These pixels are chosen randomly.Four measures are used to assess accuracy of the proposed method:1.Classification rate: The classification rate measures the sensitivity of the segmentation algorithm with respect to each class.Dice similarity coefficient (DSC): The DSC measures the spatial overlap between two point sets A and B:(12)DSC=2|A∩B||A|+|B|.Here, A and B respectively correspond to the automatically and manually segmented spinous processes (or acoustic shadows). DSC=1 corresponds to a complete overlap.Hausdorff distance: The Hausdorff distance, defined as(13)HD=max(h(A,B),h(B,A)),h(A,B)=mina∈Amaxb∈B∥a−b∥,measures how far two sets of points A and B are from each other. In this paper, we evaluate the Hausdorff distance between the boundaries of the automatically and manually segmented acoustic shadows. Only the boundary in a region of interest around the spinous process (see Fig. 8) is considered because the acoustic shadow created in the vicinity of the spinous process is the region which interests us most.Euclidean distance between centroids: We apply this measure to the centroids of the automatically and manually segmented spinous processes to evaluate our algorithm's localization accuracy.

@&#CONCLUSIONS@&#
In this paper, we proposed an automatic method for the segmentation of vertebral ultrasound images in the transverse view. This method automatically and simultaneously segments the spinous process and its acoustic shadow in the image. It is based on a set of features derived and adapted from the literature, and designed to capture the characteristics of bone and shadow in ultrasound images, and their contrast with respect to the background textures. A LDA classifier is used to classify each pixel in three classes: “spinous process”, “acoustic shadow” and “other tissues”. Then, a regularization step is applied to the individually classified pixels to account for some of the geometric properties of vertebral images. The feature set was validated using established feature selection techniques. The segmentation method was then tested on a large database, and we obtained classification rates around 84% for the spinous process, 92% for the acoustic shadow and 91% for “other tissues”. Furthermore, we obtained Dice similarity coefficients of 0.88 for the acoustic shadow and 0.72 for the spinous process, and the centroid of the spinous process was at an average distance of0.38mmfrom the manually segmented spinous process. The high accuracy of spinous process localization using our method is one very encouraging result from a clinical standpoint, which we hope to leverage in future work involving measurements of the Spinous Process Angle on 3D ultrasound data. To improve accuracy further, our automatic segmentation method can easily be extended to utilize new image features. For instance, Hacihaliloglu et al.'s phase symmetry features [13] might advantageously be replaced by their more recently developed local phase tensor features [14]. Future work will also involve optimizing the image acquisition parameters and protocol in order to capture other anatomical structures like the transverse processes, the laminae and the vertebral bodies, which will be integrated as new classes in the segmentation algorithm. The method will also be validated on images from scoliotic patients so that its use may be investigated to assist dense 3D reconstructions of the scoliotic spine as well as intra-operative surgical guidance.None declared.