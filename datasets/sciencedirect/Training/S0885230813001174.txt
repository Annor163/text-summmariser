@&#MAIN-TITLE@&#
Language independent search in MediaEval's Spoken Web Search task

@&#HIGHLIGHTS@&#
“Spoken Web Search” allows users to access an audio database with voice queries independent of the language used.It is a novel application of speech technology to specifically help under-developed communities.Low-resource “query by example” techniques are becoming popular again, and are well suited to solving this problem.Rival and complementary techniques include multi-lingual LVCSR and articulatory feature based modeling.We present a comparative analysis of these techniques as submitted to the MediaEval evaluation series.

@&#KEYPHRASES@&#
Low-resource speech technology,Evaluation,Spoken web,Spoken term detection,

@&#ABSTRACT@&#
In this paper, we describe several approaches to language-independent spoken term detection and compare their performance on a common task, namely “Spoken Web Search”. The goal of this part of the MediaEval initiative is to perform low-resource language-independent audio search using audio as input. The data was taken from “spoken web” material collected over mobile phone connections by IBM India as well as from the LWAZI corpus of African languages. As part of the 2011 and 2012 MediaEval benchmark campaigns, a number of diverse systems were implemented by independent teams, and submitted to the “Spoken Web Search” task. This paper presents the 2011 and 2012 results, and compares the relative merits and weaknesses of approaches developed by participants, providing analysis and directions for future research, in order to improve voice access to spoken information in low resource settings.

@&#INTRODUCTION@&#
In recent years, speech technology has emerged as an enabling technology for increasing the accessibility of information for a number of quite diverse use cases. These include searching large archives of audio-visual material, dialog systems for access to personal information and (mobile) web search, as well as applications in language learning and pronunciation training. A particularly deserving aspect of these is the potential of speech technologies to foster participation of disabled, low-literate, or “minority” users in the information society.The last case has proven to be particularly challenging, because resources of any kind are usually scarce for minority languages, dialects and other non-mainstream conditions, which can therefore not be approached with the typical “there is no data like more data” engineering approach. Clearly, society would benefit greatly from the ability to easily process audio in any language (or dialect), or language independently, without having to spend resources on language-specific development, but significant research is still needed in that area.“Spoken Web Search” involves searching for audio content, within audio content, using an audio query, in a language, dialect, or domain for which only very limited resources are available. The original motivation for this task was to be able to provide voice-based access to spoken documents created by local community efforts in rural India. Because no experts are available to create and maintain dedicated speech dialog systems, acoustic similarity and keyword search could be used to access information. A caller would for example say “weather tomorrow” and retrieve a spoken document which contains the phrase “the weather tomorrow will be …” (in a matching dialect). While such a retrieval-based approach is clearly limited when compared to fully developed dialog systems, it is still preferable to not having any capability to access information at all. The fact that users in such applications will often be repeat callers, and therefore will be familiar with the system, also enhances the potential efficacy of this approach.The main challenge is therefore to develop approaches to spoken term detection (rather than full speech-to-text) that scale to many languages, dialects, and domains very quickly, without requiring data and language or technology experts. An efficient large-scale deployment with many users is desirable, but not the primary goal. To solve this problem, two research avenues present themselves: port existing speech recognition approaches, or build dedicated solutions. When starting from existing speech recognition approaches and resources, techniques have to be found which will make them useful in low-resource settings. Multi-lingual modeling and cross-lingual (or -dialectal) transfer have been used in the past to do that. As an alternative, limited keyword search or acoustic pattern matching systems can be tailored specifically to the target use case. It may therefore be possible to develop them with relatively little data, or even zero (outside) resources.To compare these two approaches, and analyze the trade-offs entailed by such a design decision, “Spoken Web Search” (SWS) was run as a challenge-style task at MediaEval 2011 (Rajput and Metze, 2011) and MediaEval 2012 (Metze et al., 2012). This evaluation attempts to provide a common evaluation corpus and baseline for research on language-independent search and retrieval of real-world speech data, with a special focus on low-resource languages.In Section 2, we survey the field of low-resource acoustic pattern matching and spoken term detection. Section 3 presents the “Spoken Web Search” task as a public data set and evaluation campaign to initiate research and discussion in this research area. A unified view and discussion of the approaches implemented by the participants is given in Sections 4–7, following the different steps of a typical system. In Section 8, we discuss results achieved in the 2011 and 2012 evaluations, and provide research directions for the future.

@&#CONCLUSIONS@&#
