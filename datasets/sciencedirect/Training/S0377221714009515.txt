@&#MAIN-TITLE@&#
Tracking global optima in dynamic environments with efficient global optimization

@&#HIGHLIGHTS@&#
Metamodel-based optimization for expensive dynamic black box functions.Novel adaptation of efficient global optimization to dynamic environments.Four approaches to decrease reliance on old information empirically compared.Comparisons with naive approaches of re-optimization or ignoring change show significant improvement.

@&#KEYPHRASES@&#
Heuristics,Dynamic global optimization,Efficient global optimization,Gaussian processes,Response surfaces,

@&#ABSTRACT@&#
Many practical optimization problems are dynamically changing, and require a tracking of the global optimum over time. However, tracking usually has to be quick, which excludes re-optimization from scratch every time the problem changes. Instead, it is important to make good use of the history of the search even after the environment has changed. In this paper, we consider Efficient Global Optimization (EGO), a global search algorithm that is known to work well for expensive black box optimization problems where only few function evaluations are possible. It uses metamodels of the objective function for deciding where to sample next. We propose and compare four methods of incorporating old and recent information in the metamodels of EGO in order to accelerate the search for the global optima of a noise-free objective function stochastically changing over time. As we demonstrate, exploiting old information as much as possible significantly improves the tracking behavior of the algorithm.

@&#INTRODUCTION@&#
Many practical optimization problems are dynamically changing over time, e.g., because new jobs arrive over time in scheduling, the quality of the raw material changes in production processes, or new information becomes available in portfolio management. In dynamic environments, rather than finding the global optimum, the goal is to track the changing optimum over time. Because tracking usually has to be quick, re-optimization from scratch every time the problem changes is not an option. However, because the problem in most applications changes only slightly from one stage to the next, it should be possible to re-use some information from the search process in previous stages to solve the current stage more quickly. On the other hand, completely relying on old information may be misleading, and prevent the algorithm from finding the new optimum.The idea of using stochastic processes to model a dynamically changing function was first introduced by Kushner (1962) for a one dimensional problem. We are not aware of any other work in this direction. On the other hand, in recent years, dynamic optimization problems have attracted a lot of attention in the evolutionary computation area. Algorithms proposed in this area range from simply continuing with the old population but temporarily increasing the mutation rate in order to allow the algorithm to leave the current local optimum, to sophisticated multi-population approaches that try to simultaneously track multiple optima over time. Recent surveys on this topic can be found in Cruz, González, and Pelta (2011) and Nguyen, Yang, and Branke (2012). In most cases, however, the information transferred from one stage of the problem to the next is information about a set of previously known good solutions.In this paper, we consider the Efficient Global Optimization (EGO) algorithm proposed by Jones, Schonlau, and Welch (1998). This algorithm constructs and sequentially updates a Gaussian process surrogate model (Kriging metamodel) of the fitness landscape, and uses this model to decide where to sample next, based on the principle of the largest expected improvement (EI). EGO has received significant attention in the literature, and is recognized as a powerful global search algorithm in particular for expensive black box optimization problems, where the number of solutions that can be evaluated is severely limited. This is one of the reasons why we consider EGO a suitable candidate for dynamic optimization problems, as dynamic environments usually require a quick response, thus limiting the number of function evaluations. The other reason is that EGO explicitly maintains a model of the entire fitness landscape, whereas evolutionary algorithms (EA) can only do so implicitly by maintaining a small set of solutions in good regions of the search space. Such a model of the entire fitness landscape should capture most of the information relevant to speed up optimization after a change, in particular information about all the “good” regions in the search space.We therefore propose and empirically evaluate in this paper various adaptations of EGO to dynamic optimization problems. These adaptations aim at integrating, in the surrogate model, information from previous stages of the problem, acknowledging, however, the fact that such information is old and not fully reliable. We show that the developed variants significantly outperform the straightforward strategies of simply restarting after a change or ignoring that a change happened.The main contributions of this paper are, first, three out of the four mathematical models for incorporating old and new information together to create a response surface using a Gaussian process. Second, an extensive comparison of the proposed models aiming to help in the model selection according to the dynamics of the problem to be optimized, and third the exploitation of the structure of the EI function to accelerate its maximization using a set of local hill climbers with carefully selected starting points. This paper extends Morales-Enciso and Branke (2014) by introducing three new models, by considering the two dimensional case of the problem, and by comparing all the models in a more thorough manner. Apart from the extended conference proceedings paper, to the authors’ best knowledge, this paper constitutes the first adaptation of the EGO algorithm to approach dynamically changing optimization problems.The paper is structured as follows. We start with a survey of related work in Section 2. Then, in Section 3, the concepts and techniques of Gaussian processes and EGO are explained, which are the bases for the proposed sampling strategies detailed in Section 4. Some numerical experiments and results are provided and analyzed in Section 5. The paper concludes with a summary and some ideas for future work in Section 6.

@&#CONCLUSIONS@&#
An adaptation of EGO to track global optima in dynamic environments has been proposed and tested in this paper. Specifically, four sequential sampling strategies relying on GP to build a surrogate model have been described. Different properties of GP have been exploited to construct the response surface using both old and new information to enhance tracking of the global optima for dynamic expensive black box optimization problems. These four new sampling strategies, together with four other benchmark sampling strategies have been compared through numeric simulations implementing the moving peaks benchmark and using the offline error as performance measure.The poor performance of the random strategy throughout the different experiments confirms the advantages of using informed selection of the points to be sampled. The simple trick of re-evaluating the previous best found solution at the beginning of an epoch highly improves the performance in the experiments considered. This idea has been used in all the newly proposed strategies. The experiments also show that sampling strategies using old information in an explicit way (DIN, TasD + 1, and PSMP) systematically perform significantly better than those which either discard it (reset and reset*) or treat it in the same way as recent information (ignore).Future work in this area might focus on how to combine the different sampling strategies here presented. For example, building a more accurate response surface from old samples using the TasD + 1 method and using it as mean prior for the PSMP strategy. Or perhaps, trying to remove the tuning component for the DIN strategy by learning the amount of noise to be introduced online. Another direction could be to extend this work for dynamic objective functions with continuous changes, as opposed to changes happening only after a given number of function evaluations. Although TasD + 1 could naturally cope with this case, individual levels of noise might be required for each sample if using DIN, and additional modifications would be required for PSMP to work. A more interesting extension would be to extend these strategies to be able to cope with constraints.The methods exposed in this paper could further be adapted for creating response surfaces using information coming from simulations with different fidelities. This case is common while looking for optimal designs in fluid dynamics for instance, where simulations which accurately model all the interactions between particles are computationally extremely expensive whereas simplified models are much faster to run but can only provide rough approximations. By correctly taking into account the origins of the data using adaptations of these models, improved response surfaces can be built.