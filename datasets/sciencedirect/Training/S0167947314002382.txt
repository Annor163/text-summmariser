@&#MAIN-TITLE@&#
An efficient and robust variable selection method for longitudinal generalized linear models

@&#HIGHLIGHTS@&#
We develop a new efficient and robust variable selection approach for generalized linear models with longitudinal data.The rootn-consistency and asymptotic normality of the proposed estimators are established.An efficient algorithm is proposed to implement the procedures.Simulation studies and a real data example have shown that our proposed estimators are superior to some recently developed variable selection methods.

@&#KEYPHRASES@&#
Efficiency,Generalized estimating equations,Generalized linear model,Longitudinal data,Oracle property,Robust estimation,

@&#ABSTRACT@&#
This paper presents a new efficient and robust smooth-threshold generalized estimating equations for generalized linear models (GLMs) with longitudinal data. The proposed method is based on a bounded exponential score function and leverage-based weights to achieve robustness against outliers both in the response and the covariate domain. Our motivation for the new variable selection procedure is that it enables us to achieve better robustness and efficiency by introducing an additional tuning parameterγwhich can be automatically selected using the observed data. Moreover, its performance is near optimal and superior to some recently developed variable selection methods. Under some regularity conditions, the resulting estimator possesses the consistency in variable selection and the oracle property in estimation. Finally, simulation studies and a detailed real data analysis are carried out to assess and illustrate the finite sample performance, which show that the proposed method works better than other existing methods, in particular, when many outliers are included.

@&#INTRODUCTION@&#
Longitudinal data sets arise frequently from many subject-matter studies, such as medical and public health studies. Generalized linear models (McCullagh and Nelder, 1989) are powerful and popular technique for modeling clustered and longitudinal data, in particular, for repeated or correlated non-Gaussian data, such as Binomial or Poisson type response that is commonly encountered in longitudinal studies. The challenge in analyzing longitudinal data is that it is difficult to specify the full likelihood function when responses are non-normal. This motivated Liang and Zeger (1986) to develop an approach of generalized estimating equations (GEE) which is a milestone in the development of methodology for longitudinal data analysis. Moreover, the well-known GEE approach only requires specification of marginal mean and covariance function. Recent research works on the GEE method include Xie and Yang (2003), Wang et al. (2005a), Balan and Schiopu-Kratina (2005) and Wang (2011) and so on. However, the GEE method is in principle very similar to the weighted least squares method, which does not possess robust property. In the longitudinal data set, one outlier in the subject level may generate a set of outliers in the sample due to repeated measurements. Hence, robustness against outliers is a very important issue in longitudinal studies. Recently, the traditional robustM-estimations (e.g. Huber’s estimation) for longitudinal data have attracted much attention and have been discussed in many literatures. An incomplete list of recent works on the robust GEE methods include Fan et al. (2012), He et al. (2005), Qin and Zhu (2007), Qin et al. (2009), Wang et al. (2005b) and Zheng et al. (2013). These above papers all use the Mallows-type weights to downweight the effect of leverage points and adopt the Huber’s score function on the Pearson residuals to dampen the effect of outliers in the response.Although the Huber’s score function is a robust modeling tool, it has limitation in terms of efficiency of estimation, which stimulates a lot of work about finding other bounded score functions to achieve better robustness and efficiency. Here we only list a few. Yao et al. (2012) investigated a new estimation method for the classical nonparametric model based on a local modal regression (LMR). Liu et al. (2013) and Zhang et al. (2013) extended the LMR method to single index models and semiparametric partially linear varying coefficient models respectively. The outstanding merit of the procedure is that it can achieve both robustness and efficiency by introducing an additional tuning parameter. Wang et al. (2013) adopted a similar view and proposed a class of robust regression estimators based on exponential squared loss. To be more specific, for the linear regression modelyi=xiTβ+εi, they estimated the regression parameterβby minimizing(1)Qγ(β)=∑i=1n(1−φγ(ti)),whereφγ(ti)=exp(−ti2/γ)withti=yi−xiTβ,γ>0determines the degree of robustness of the estimation. Ifγis large, we have1−exp(−t2/γ)≈t2/γ. Thereby, the new estimators are similar to the least squares estimators. For observations with large absolute values ofti=yi−xiTβ, we can use a smallerγto downweight the influence of an outlier on the estimators. Obviously, minimizing the objective function (1) is equivalent to solve the following estimating equations(2)∑i=1nxiψγ(ti)=0,whereψγ(t)=φ̇γ(t)=−2tγexp(−t2/γ),ψγ(⋅)is the first derivative ofφγ(⋅). Note thatψγ(t)is also a bounded score function sinceψγ(t)will go to zero whentapproaches infinity. Wang et al. (2013) pointed out that their method loses less efficiency of estimation compared with other existing robust methods, e.g. Huber’s estimate (Huber, 1973), quantile regression estimate (Koenker, 2005), composite quantile regression estimate (Zou and Yuan, 2008), etc. However, as discussed above literatures, the new approach was only considered for independent data. In this paper, we first extend the bounded exponential score functionψγ(t)to longitudinal data analysis for achieving a more robust and effective estimate.Variable selection is a technique of selecting a subset of relevant covariates for constructing reliable statistical models. Various penalty functions (such as Lasso, adaptive Lasso, SCAD) have been used to select significant variables among all the candidate variables for independent data. But variable selection is also a fundamentally important issue for the analysis of longitudinal data, which could greatly enhance the prediction performance of the fitted model and select significant variables. For example, Fan et al. (2012) proposed penalized robust estimating equations with the SCAD penalty for longitudinal linear models. Wang et al. (2012) considered the SCAD-penalized GEE for analyzing longitudinal data with high-dimensional covariates. These variable selection methods mentioned above are based on estimating equations and the SCAD penalty function which is singular at zero. Thereby, these estimation procedures require convex optimization, which incurs a computational burden. Ueki (2009) developed smooth-threshold estimating equations that can automatically eliminate irrelevant parameters by setting them as zero. As far as we know, Ueki’s method is in principle applicable to the procedures based on estimating equations. Moreover, this approach possesses the oracle property in the sense that Fan and Li (2001) suggested. Motivated by the idea of Ueki (2009) and Li et al. (2013) developed smooth-threshold generalized estimating equations (SGEE) for longitudinal generalized linear models. In this paper, we focus on marginal longitudinal generalized linear models and develop an efficient and robust variable selection method based on the bounded exponential score function and smooth-threshold estimating equations. Our contributions are the following: (i) we establish rootn-consistency and asymptotic normality of estimators. (ii) We use the Mallows-type weights to downweight the effect of leverage points and adopt the bounded exponential score functionψγ(t)on the Pearson residuals to dampen the effect of outliers in the response. (iii) The proposed method can automatically eliminate inactive predictors by setting the corresponding parameters to be zero and estimate nonzero coefficients simultaneously.The rest of the paper is organized as follows. The main results are described in Section  2, including the efficient and robust smooth-threshold estimating equations (ERSGEE) and their asymptotic properties and influence function. In Section  3, an efficient algorithm is proposed to implement the procedures. Moreover, we discuss how to select the tuning parameterγand other regularization parameters so that the corresponding ERSGEE estimators are robust and sparse. In Section  4, we apply a number of simulations to assess the finite sample performance of our method by comparing with other variable selection procedures. A real data analysis is also presented in this section to augment our theoretical results. Some concluding remarks are given in Section  5. The proofs of the main results are relegated to the Appendix.

@&#CONCLUSIONS@&#
