@&#MAIN-TITLE@&#
A user study of auditory, head-up and multi-modal displays in vehicles

@&#HIGHLIGHTS@&#
The users were asked to perform several tasks with the aid of a menu while driving.The menu was presented through a visual head-up, an audio and a multi-modal display.The visual and multi-modal displays were more efficient than the audio display.All displays had a similar impact on driving performance.The majority of users selected the multi-modal display as the easiest to use.

@&#KEYPHRASES@&#
Auditory display,Head-up display,Vehicle,

@&#ABSTRACT@&#
This paper describes a user study on the interaction with an in-vehicle information system (IVIS). The motivation for conducting this research was to investigate the subjectively and objectively measured impact of using a single- or multi-modal IVIS while driving. A hierarchical, list-based menu was presented using a windshield projection (head-up display), auditory display and a combination of both interfaces. The users were asked to navigate a vehicle in a driving simulator and simultaneously perform a set of tasks of varying complexity. The experiment showed that the interaction with visual and audio-visual head-up displays is faster and more efficient than with the audio-only display. All the interfaces had a similar impact on the overall driving performance. There was no significant difference between the visual only and audio-visual displays in terms of their efficiency and safety; however, the majority of test subjects clearly preferred to use the multi-modal interface while driving.

@&#INTRODUCTION@&#
Head-up displays (HUDs) are the current state-of-the-art solution to reducing driver errors originating from distractive interfaces, such as on-board entertainment displays or in-vehicle information systems (IVIS). Compared to head-down displays (HDDs), which are integrated into the vehicle's control panel, the frequency and duration of glances towards the display are reduced by presenting information directly on the windshield in the driver's field of vision (Ablassmeier et al., 2007). Consequently, the response time to unanticipated road events is reduced when information is displayed on a HUD instead of a HDD (Horrey and Wickens, 2004; Liu and Wen, 2004; Sojourmer and Antin, 1990), and the number of collisions is significantly reduced (Charissis et al., 2008). Using HUDs also leads to a, generally, more consistent speed control and reduced mental workload (Liu and Wen, 2004), reduced navigational errors (Burnett, 2003), and smaller variances in lateral accelerations and steering wheel angle (Yung-Ching, 2003).However, cognitively switching between two sources of information, i.e., the HUD and traffic, still poses a problem, especially in high-workload situations. The so-called cognitive or attention capture, i.e., when the driver's attention subconsciously shifts away from the road and becomes focused on processing the information presented by the HUD, has been identified as one of the disadvantages of HUDs (Gish and Staplin, 1995; Prinzel and Risser, 2004; Tufano, 1997). The resulting perceptual tunnelling may lead to a delayed reaction or a complete absence of response to situational changes in the environment (Haines, 1991; Thomas and Wickens, 2001).Researchers have proposed to address this issue by utilising auditory interfaces (Lai et al., 2001; Sodnik et al., 2008). They report on the greater attention capturing properties of the auditory channel and the desire to keep attention focused longer on a complex auditory task to prevent a loss of information from the driver's working memory. Wickens et al. (2005) addressed this apparent contradiction in the context of a visual on-going task and an auditory interrupting task. They found that the auditory input improved the interrupting task performance when compared to a visual interrupting task, but degraded the on-going task performance because of an abrupt shift of attention at the onset of the auditory message (see, in addition, Biever, 2002; Horrey and Wickens, 2004).A combination of auditory, especially speech-based, information presentations and text-based information presentations through a HUD may offer the attention and safety benefits of an eyes-free approach with the higher information-processing rate of a visual information presentation. The study presented in this paper was conducted to evaluate the assumption that allowing users to freely switch their attention between visual and auditory information presentations may have less impact on the performance of the primary task than with a single-modal information presentation.

@&#CONCLUSIONS@&#
