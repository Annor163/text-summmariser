@&#MAIN-TITLE@&#
A dynamic learning algorithm for online matching problems with concave returns

@&#HIGHLIGHTS@&#
We consider the online matching problem with concave returns. It is the core model for ad allocation.We propose a dynamic learning algorithm that achieves near-optimal performance for this problem.Our approach is primal-dual based. We overcome the difficulty that arises due to the nonlinearity.We test our algorithm using experimental data and show that it outperforms a myopic approach.

@&#KEYPHRASES@&#
Online algorithms,Primal-dual,Dynamic price update,Random permutation model,Adwords problem,

@&#ABSTRACT@&#
We consider an online matching problem with concave returns. This problem is a generalization of the traditional online matching problem and has vast applications in online advertising. In this work, we propose a dynamic learning algorithm that achieves near-optimal performance for this problem when the inputs arrive in a random order and satisfy certain conditions. The key idea of our algorithm is to learn the input data pattern dynamically: we solve a sequence of carefully chosen partial allocation problems and use their optimal solutions to assist with the future decisions. Our analysis belongs to the primal-dual paradigm; however, the absence of linearity of the objective function and the dynamic feature of the algorithm makes our analysis quite unique. We also show through numerical experiments that our algorithm performs well for test data.

@&#INTRODUCTION@&#
In traditional optimization models, inputs are usually assumed to be known and efficient algorithms are sought to find the optimal solutions. However, in many practical cases, data does not reveal itself at the beginning. Instead, it comes in an online fashion. For example, in many revenue management problems, customers arrive sequentially and each time a customer arrives, the decision maker has to make some irrevocable decisions (e.g., what product to sell, at what prices) for this customer without knowing any of the future inputs. Such a regime is often called online optimization. Online optimization has gained much attention in the research community in the past few decades due to its applicability in many practical problems, and much effort has been directed toward understanding the quality of solutions that can be obtained under such settings. For an overview of the online optimization literature and its recent developments, we refer the readers to Borodin and El-Yaniv (1998), Buchbinder and Naor (2009) and Devanur (2011).In this paper, we consider a special type of online optimization problem - an online matching problem. Online matching problems are considered as fundamental problems in online optimization theory and have important applications in the online advertisement allocation problems. For a review of online matching problems, we refer the readers to Mehta (2012). In the problem we study, there is an underlying weighted bipartite graphG=(I,J,E)with weights bijfor each edge (i, j) ∈ E. The vertices in J arrive sequentially in some order, and whenever a vertex j ∈ J arrives, the set of weights bijis revealed for all i ∈ I, (i, j) ∈ E. The decision maker then has to match j to one of its neighbors i, and a value of bijwill be obtained from this matching. In our problem, the decision maker’s gain from each vertex i is a function of the total matched value to this vertex, and his goal is to maximize the total gain from all vertices. Mathematically, the problem can be formulated as follows (assume|I|=m,|J|=n,and letbij=0for (i, j)∉E):(1)maximizex∑i=1mMi(∑j=1nbijxij)s.t.∑i=1mxij≤1,∀jxij≥0,∀i,j,where xijdenotes the fraction of vertex j that is matched to vertex i.11We allow fractional allocations in our model. However, our proposed algorithms output integer solutions. Thus all our results hold if one confines to integer solutions.In (1), the coefficientbj={bij}i=1mis revealed only when vertex j arrives, and an irrevocable decisionxj={xij}i=1mhas to be made before observing the next input. For each i, Mi(·) is a nondecreasing concave function withMi(0)=0. In this paper, we assume that Mi(·)s are continuously differentiable.As mentioned earlier, online matching problems have a very important application in the online advertisement allocation problem, which we will later refer to as the Adwords problem. In the Adwords problem, there are m advertisers (which we also call the bidders). A sequence of n keywords are searched during a fixed time horizon. Based on the relevance of the keyword, the ith bidder would bid a certain amount bijto show his advertisement on the result page of the jth keyword. The search engine’s decision is to allocate each keyword to one of the m bidders (we only consider a single allocation in this paper). Note that each allocation decision can only depend on the information earlier in the arrival sequence but not on any future data. As pointed out in Devanur and Jain (2012), there are several practical motivations for considering a concave function of the matched bids in the Adwords problem. Among them are convex penalty costs for under-delivery in search engine-advertiser contracts, the concavity of the click-through rate in the number of allocated bids observed in empirical data and fairness considerations. In each of the situations mentioned above, one can write the objective as a concave function. We refer the readers to Devanur and Jain (2012) for a more thorough review of the motivations for this problem. It is worth noting that there is a special case of this problem whereMi(x)=min{x,Bi}. In this case, one can view that the bidder has a budget Biand the revenue from each bidder is bounded by Bi.One important question when studying online algorithms is the assumptions on the input data. In this work, we adopt a random permutation model. More precisely, we assume:1.The total number of arrivalsn=|J|is known a priori.The weights {bij} can be adversarially chosen. However, the order that j arrives is uniformly distributed over all the permutations.The random permutation model has been adopted in much recent literature in the study of online matching problems, see, e.g., Agrawal, Wang, and Ye (2014); Devanur and Hayes (2009); Feldman, Henzinger, Korula, Mirrokni, and Stein (2010), etc. It is equivalent to saying that a set ofB={b˜1,b˜2,…,b˜n}is arbitrarily chosen beforehand (unknown to the decision maker). Then the arrivalsb1,b2,…,bnare drawn randomly without replacement fromB. The random permutation model is an intermediate path between using a worst-case analysis and assuming each input data is drawn independently and identically distributed (i.i.d.) from a certain distribution. On one hand, compared to the worst-case analysis (see, e.g., Buchbinder, Jain, & Naor, 2007; Devanur & Jain, 2012; Feldman, Korula, Mirrokni, Muthukrishnan, & Pal, 2009; Mehta, Saberi, Vazirani, & Vazirani, 2005), the random permutation model is practically reasonable yet much less conservative. On the other hand, the random permutation model is much less restrictive than assuming the inputs are drawn i.i.d. from a certain distribution (Devanur, 2011). Also, the assumption of the knowledge of n is necessary for any online algorithm to achieve near-optimal performance (see Devanur & Hayes, 2009). Therefore, for large problems with relatively stationary inputs, the random permutation model is a good approximation and the study of such models is of practical interest. Next we define the performance measure of an algorithm under the random permutation model:Definition 1 (c-competitiveness)Let OPT be the optimal value for the offline problem (1). An online algorithm A is called c-competitive in the random permutation model if the expected value of the online solutions by using A is at least c times the optimal value of (1), that isEσ[∑i=1mMi(∑j=1nbijxij(σ,A))]≥cOPT,where the expectation is taken over uniformly random permutations σ of1,…,n,and xij(σ, A) is the ijth decision made by algorithm A when the inputs arrive in order σ.In Devanur and Jain (2012), the authors propose an algorithm for the online matching problem with concave returns that has a constant competitive ratio under the worst-case model (the constant depends on the forms of each Mi(·)). They also show that a constant competitive ratio is the best possible result under that model. In this paper, we propose an algorithm under the random permutation model, which achieves near-optimal performance under some conditions on the input.Our main result is stated as follows:Theorem 1Fixϵ∈(0,1/2). There exists an algorithm (Algorithm DLA) that is1−ϵcompetitive for the online matching problem with concave returns Mi(·)s under the random permutation model if(2)n≥Ω(max{log(m/ϵ)ϵb¯2,m2log(m2n/ϵ)F(M,η)ϵ3b¯}),whereb¯=1nmini{∑j=1nbij},η=mini,j{bij|bij>0}maxi,jbij,and F(M, η) is a constant that only depends on each Mi(·) and η.In condition (2),b¯can be viewed as the average bid value of a bidder over time. Given that each bidder is at least interested in some fractions of the keywords, this average will go to a certain constant as n becomes large. Also, η can be viewed as the ratio between the value of the smallest non-zero bid and the highest bid. In practice, this is often bounded below by a constant by enforcing a reserve price and a maximum price for any single bid. The exact functional form of F(M, η) is somewhat complicated, and is given in Proposition 1. Just to give an example, if we chooseMi(x)=xp(0 < p < 1), thenF(M,η)=2η(2−p)/(1−p). Therefore, condition (2) can be viewed as simply requiring the total number of inputs is large, which is often the case in practice. For example, in the Adwords problem, n is the number of keyword searches in a certain period, and for instance, Google receives more than 5 billion searches per day. Even if we focus on a specific category, the number can still be in the millions. Thus, this condition is reasonable. We note that most learning algorithms in the literature make similar requirements, see Agrawal et al. (2014); Devanur and Hayes (2009), and Molinaro and Ravi (2014). Furthermore, as we will show in our numerical tests, our algorithm performs well even for problems with sizes that are significantly smaller than the condition requires, which validates the potential usefulness of our algorithm.To propose an algorithm that achieves near-optimal performance, the main idea is to utilize the observed data in the allocation process. In particular, since the input data arrives in a random order, using the past input data and projecting it into the future should present a good approximation for the problem. To mathematically capture this idea, we use a primal-dual approach. We obtain the dual optimal solutions to suitably constructed optimization problems and use them to assist with future allocations. We first propose a one-time learning algorithm (OLA, see Section 2) that only solves an optimization problem once at timeϵn. By carefully examining this algorithm, we prove that it achieves near-optimal performance when the inputs satisfy certain conditions. However, the conditions are stronger than those stated in Theorem 1. To improve our algorithm, we further propose a dynamic learning algorithm (DLA, see Section 3). The dynamic learning algorithm makes better use of the observed data and updates the dual solution at a geometric pace, that is, at timeϵn,2ϵn,4ϵnand so on. We show that these resolvings can lift the performance of the algorithm and thus prove Theorem 1. As one will see in the proof of the DLA, the choice of the resolving points perfectly balances the trade-off between exploration and exploitation, which are the main trade-offs in such types of learning algorithms.It is worth mentioning that a similar kind of dynamic learning algorithm has been proposed in Agrawal et al. (2014) and further studied in Wang (2012) and Molinaro and Ravi (2014). However, those works only focus on linear objectives. In our analysis, the nonlinearity of the objective function presents a non-trivial hurdle since one can no longer simply analyze the revenue generated in each time segment and add them together. In this paper, we successfully work around this hurdle by a convex duality argument. We believe that our analysis is a non-trivial extension of the previous work. Moreover, the problem solved has important applications.The remainder of the paper is organized as follows. In Section 2, we start with a one-time learning algorithm and prove that it achieves near-optimal performance under some mild conditions on the input. The one-time learning algorithm is easy to understand and shows important insights for designing this class of learning algorithms. However, it only achieves a weaker performance than what is stated in Theorem 1. In Section 3, we propose a dynamic learning algorithm which makes better use of the data and has a stronger performance. Some numerical test results of our algorithm are presented in Section 4, which validate the strength of our algorithm. Section 5 concludes this paper.We first rewrite the offline problem (1) as follows:(3)maximizex,u∑i=1mMi(ui)s.t.∑j=1nbijxij=ui,∀i∑i=1mxij≤1,∀jxij≥0,∀i,j.We define the following dual problem:(4)infv,y∑j=1nyj+∑i=1m(Mi(vi)−Mi′(vi)vi)s.t.yj≥bijMi′(vi),∀i,jvi≥0,∀iyj≥0,∀j.Let the optimal value of (3) be P* and the optimal value of (4) be D*. In Devanur and Jain (2012), the authors proved the weak duality between (3) and (4). In the following lemma, we prove that in fact the strong duality holds. The proof of the lemma is relegated to the Appendix.Lemma 1P*=D*. Furthermore, the objective value of any feasible solution to (4) is an upper bound of P*.Before we describe our algorithm, we define the following partial optimization problem:(5)(Pϵ)maximizex,u∑i=1mMi(ui)s.t.∑j=1ϵnbijϵxij=ui,∀i∑i=1mxij≤1,∀jxij≥0,∀i,j.Now we define the one-time learning in Algorithm 1.Now we provide some intuition for the algorithm. The idea of the algorithm is to use the firstϵninputs to learn an approximateu^and then use it to make all the future allocations based on the complementarity conditions between the primal and dual problems ((3) and (4)). Hereu^is solved from (Pϵ) which projects the allocation in the firstϵninputs to the entire problem. The decision rule in (6) can be explained as choosing the i with the highest product of the nominal bid value bijand the marginal contribution rate to the total projected rewardMi′(u^). Note that a similar idea has been used to construct algorithms for an online matching problem with linear objective functions (see e.g., Agrawal et al., 2014; Devanur & Hayes, 2009; Molinaro & Ravi, 2014). However, the analyses of those algorithms all depend on the linearity of the objective function which we do not possess in this problem. Instead, an analysis with the use of concavity is required in our analysis, making it quite different from those in the prior literature. In the following, we assume without loss of generality that maxi, jbij≤ 1 (we can always scale the inputs to make this hold). We also make a technical assumption as follows:Assumption 1The inputs of the problem are in a general position. That is, for any vectorp=(p1,…,pm)≠0,there are at most m terms among argmaxi{bijpi},j=1,…,n,that are not singleton sets.The assumption says that we only need to break ties in (6) no more than m times. This assumption is not necessarily true for all inputs. However, as pointed out by Devanur and Hayes (2009) and Agrawal et al. (2014), one can always perturb bijby adding a random variable ηijtaking uniform distribution on [0, η] for some very small η. By doing so the assumption holds with probability one and the effect to the solution can be made arbitrarily small. Given this assumption and by the complementarity conditions, we have the following lemma, whose proof is in the Appendix.Lemma 2ϵu^i−m≤∑j=1ϵnbijxi(u^,bj)≤ϵu^i+m.We first prove the following proposition about the performance of the OLA, which relies on a condition of the solution to (Pϵ).Proposition 1For any givenϵ∈(0,1/2),ifminiu^i≥Ω(mlog(m2n/ϵ)ϵ3),then the OLA is a1−ϵ-competitive algorithm.Before we prove Proposition 1, we define some notation.•We define the optimal offline solution to (3) by (x*,u*) with optimal value OPT.Define∑j=1nbijxi(u^,bj)=u¯i,note thatu¯inormally does not equalu^i.We show the following lemma:Lemma 3For any givenϵ∈(0,1/2),ifminiu^i≥12mlog(m2n/ϵ)ϵ3,then with probability1−ϵ,(7)(1−ϵ)u^i≤u¯i≤(1+ϵ)u^i,foralli.The proof will proceed as follows: For any fixedu^,we define that a random sample (the firstϵnarrivals) S is bad for thisu^if and only ifu^is the optimal solution to (5) for this S, butu¯i<(1−ϵ)u^i,oru¯i>(1+ϵ)u^i,for some i. First, we show that the probability of a bad sample is small for every fixedu^(satisfyingminiu^i≥12mlog(m2n/ϵ)ϵ3) and i. Then, we take a union bound over all distinct i andu^is to prove the lemma.To start with, we fixu^and i. DefineYj=bijxi(u^,bj). By Lemma 2 and the condition onu^i,we have(1−ϵ2)ϵu^i≤ϵu^i−m≤∑j∈SYj≤ϵu^i+m≤(1+ϵ2)ϵu^i.Therefore, the probability of bad S is bounded by the sum of the following two terms (N={1,2,…,n}):(8)P(∑j∈SYj≤ϵ(1+ϵ2)u^i,∑j∈NYj>(1+ϵ)u^i)+P(∑j∈SYj≥ϵ(1−ϵ2)u^i,∑j∈NYj<(1−ϵ)u^i).For the first term, we first defineZt=(1+ϵ)u^iYt∑j∈NYjand we haveP(∑j∈SYj≤ϵ(1+ϵ2)u^i,∑j∈NYj>(1+ϵ)u^i)≤P(∑j∈SZj≤ϵ(1+ϵ2)u^i,∑j∈NZj=(1+ϵ)u^i).Then we haveP(∑j∈SZj≤ϵ(1+ϵ2)u^i,∑j∈NZj=(1+ϵ)u^i)≤P(|∑j∈SZj−ϵ∑j∈NZj|>ϵ22u^i,∑j∈NZj=(1+ϵ)u^i)≤P(|∑j∈SZj−ϵ∑j∈NZj|>ϵ22u^i|∑j∈NZj=(1+ϵ)u^i)≤2exp(−ϵ3u^i4(2+ϵ))≤ϵ2m(m2n)m≐δ.Here the second inequality follows from the Hoeffding–Bernstein’s inequality for sampling without replacement, see Lemma 8 in the Appendix. Similarly, we can get the same result for the second term in (8), which is also bounded by δ. Therefore, the probability of a bad sample is bounded by 2δ for fixedu^and i.Next, we take a union bound over all distinctu^s. We callu^andu^′distinct if and only if they result in different allocations, i.e.,xi(u^,bj)≠xi(u^′,bj)for some i, j. DenoteMi′(u^i)=vi. For each j, by the definition in (6), the allocation is uniquely defined by the signs of the following terms:bijvi−bi′jvi′,∀1≤i<i′≤m.There arem(m−1)/2such terms for each j. Therefore, the entire allocation profiles for all the n arrivals can be determined by the signs of no more than m2n differences. Now we find out how many different allocation profiles can arise by choosing different vs. By Orlik and Terao (1992), the total number of different profiles for the m2n differences cannot exceed (m2n)m. Therefore, the number of distinctu^s is no more than (m2n)m. Now we take a union bound over all distinctu^s andi=1,⋯,m,and Lemma 3follows.□Next we show that the OLA achieves a near-optimal solution under the condition in Proposition 1. We first construct a feasible solution to (4):v^i=u^i,y^j=maxi{bijMi′(u^i)}.By Lemma 4,∑j=1ny^j+∑i=1m(Mi(u^i)−Mi′(u^i)u^i)is an upper bound of OPT. Thus, we haveOPT−∑i=1mMi(u¯i)≤∑i=1m(Mi(u^i)−u^iMi′(u^i))−∑i=1mMi(u¯i)+∑j=1ny^j=∑i=1m(Mi(u^i)−Mi(u¯i))+∑i=1m(u¯iMi′(u^i)−u^iMi′(u^i))−∑i=1mu¯iMi′(u^i)+∑j=1ny^j=∑i=1m(Mi(u^i)−Mi(u¯i)+(u¯i−u^i)Mi′(u^i)),where the last equality is because by the allocation rule (6):∑j=1ny^j=∑i=1m∑j=1nxi(u^,bj)bijMi′(u^i)=∑i=1mu¯iMi′(u^i).Now, we claim that if condition (7) holds,∑i=1m(Mi(u^i)−Mi(u¯i)+(u¯i−u^i)Mi′(u^i))≤2ϵ∑i=1mMi(u¯i).We consider the following two cases:•Case 1:u¯i≤u^i. In this case,Mi(u^i)−Mi(u¯i)+(u¯i−u^i)Mi′(u^i)≤Mi(u^i)−Mi(u¯i)≤|u^i−u¯iu¯i|Mi(u¯i)≤2ϵMi(u¯i),where the second inequality holds because of the concavity of Mi(·).Case 2:u¯i>u^i. In this case,Mi(u^i)−Mi(u¯i)+(u¯i−u^i)Mi′(u^i)≤(u¯i−u^i)Mi′(u^i)≤|u¯i−u^iu^i|Mi(u^i)≤ϵMi(u¯i).Again, the second inequality is due to the concavity of Mi(·).Thus, under the condition thatminiu^i≥12mlog(m2n/ϵ)ϵ3,with probability1−ϵ,OPT−∑i=1mMi(u¯i)≤2ϵ∑i=1mMi(u¯i)≤2ϵOPT,i.e.,∑i=1mMi(u¯i)≥(1−2ϵ)OPT.Lastly, we note that the actual allocation in our algorithm for i isu˜i=∑j=ϵn+1nbijxi(u^,bj)(since we ignore the firstϵnarrivals). By Lemma 2, we haveu˜i=u¯i−∑j=1ϵnbijxi(u^,bj)≥u¯i−ϵ(1+ϵ2)u^i.Thus when condition (7) holds,u˜i≥(1−3ϵ)u¯i. Therefore,∑i=1mMi(u˜)≥∑i=1mMi((1−3ϵ)u¯i)≥(1−3ϵ)∑i=1mMi(u¯i).The last inequality is due to the concavity of Mi(·)s and thatMi(0)=0. Therefore, givenminiu^i≥12mlog(m2n/ϵ)ϵ3,with probability1−ϵ,∑i=1mMi(u˜i)≥(1−5ϵ)OPT.Therefore, Proposition 1 is proved. □Proposition 1 shows that the OLA is near-optimal under some conditions onu^. However,u^is essentially an output of the algorithm. Although such types of conditions are not uncommon in the study of online algorithms (e.g., in the result of Devanur & Hayes, 2009; Feldman et al., 2010), it is quite undesirable. In the following, we address this problem by providing a set of sufficient conditions which only depend on the input parameters (i.e., m, n,bs and M(·)s). We show that our algorithm achieves near-optimal performance under these conditions. We start with the following lemma.Lemma 4For any C > 0, suppose the following condition holds:(9)n≥max{12log(m/ϵ)ϵb¯2,4mCF(M,η)ϵb¯}whereb¯=1nmini{∑j=1nbij},η=mini,j{bij|bij>0}and F(M, η) is such thatMi′(ηF(M,η)C)<ηMi′′(C),∀i,i′.Then with probability1−ϵ,u^i≥C,for all i.The proof of Lemma 4 is relegated to the Appendix (it is proved together with Lemma 7). Now combining Proposition 1 and Lemma 4, we have the following result for the OLA:Proposition 2Fix anyϵ∈(0,1/2). Suppose(10)n≥max{12log(m/ϵ)ϵb¯2,4mCF(M,η)ϵb¯}whereb¯=1nmini{∑j=1nbij},η=mini,j{bij|bij>0}and F(M, η) is such that(11)Mi′(ηF(M,η)C)<ηMi′′(C),∀i,i′withC=12mlog(m2n/ϵ)ϵ3. Then the OLA is1−ϵ-competitive under the random permutation model.Here we give some comments on the definition of F(M, η). The definition of F(M, η) basically ensures that we rule out the possibility that one i receives nearly all the allocation while some others receive almost none. Note that such F(M, η) always exists and is finite iflimx→∞Mi′(x)=0for all i. In practice, this is usually true as there is usually an upper bound on the possible reward from each bidder i. In particular, ifMi(·)=M(·)for all i andlimx→∞M′(x)=0,then one can chooseF(M,η)=M′−1(ηM′(C))η,whereM′−1(·)denotes the inverse function of M′(·). For example, if one choosesMi(x)=xp(0 < p < 1), then one can further chooseF(M,η)≥2η(2−p)/(1−p). Therefore, in most practical situations, one can view F(M, η) as a constant. Finally, we want to remark that the conditions in Lemma 4 (or Proposition 2) are only one set of sufficient conditions which have the nice feature of only depending on the problem inputs. In practice, one can always resort to the condition in Proposition 1 (miniu^i≥12mlog(m2n/ϵ)ϵ3) if they are more favorable. In addition, as we will show in our numerical tests in Section 4, our algorithm performs quite well even if some of the conditions in Lemma 4are not satisfied. Therefore, the applicability of our algorithm could be well beyond what the conditions require.In the previous section, we introduced the OLA that can achieve near-optimal performance. While the OLA illustrates the ideas of our approach and requires solving a convex optimization problem only once, the conditions it requires to achieve near-optimality are stricter than what we claim in Theorem 1. In this section, we propose an enhanced algorithm that lessens the conditions and thus improves the OLA.The main idea for the enhancement is the following: In the one-time learning algorithm, we only solve a partial optimization problem once. However, it is possible that there is some error for that solution due to the random order of arrival. If we could modify the solution as we gather more data, we might be able to improve the performance of the algorithm. In the following, we introduce a dynamic learning algorithm based on this idea, which updates the allocation policy every time the history doubles; that is, it computes a newu^at timet=ϵn,2ϵn,4ϵn,⋯and uses it to perform the matching for the next time period. We define the following problem:(Pℓ)maximizex,u∑i=1mMi(ui)s.t.∑j=1ℓnℓbijxij=ui,∀i∑i=1mxij≤1,∀jxij≥0,∀i,j.We further define (xℓ,uℓ) to be the optimal solution to (Pℓ).We define the dynamic learning algorithm as follows:In the following, without loss of generality, we assume thatL=−log2ϵis an integer (otherwise one can just choose a smallerϵand prove the same result). Defineℓk=2k−1ϵn,k=1,…,L,and defineu^k=uℓk. We first prove the following proposition:Proposition 3If for all k,miniu^ik≥Ω{mlog(m2n/ϵ)ϵ2},then the DLA is1−ϵ-competitive under the random permutation model.Before we proceed to the proof, we first define some more notation. We define:u¯ik=∑j=ℓk+1ℓk+1bijxi(u^k,bj),u˜ik=∑j=1nbijxi(u^k,bj),u¯i=∑k=1Lu¯ik.Note that in these definitions,u¯ikis the allocated values for i in the periodℓk+1toℓk+1usingu^k,which is the actual allocation in that period.u˜ikis the allocation for i in all periods ifu^kis used.u¯iis the actual allocation for i during the entire algorithm. We first prove the following lemma bounding the differences betweenu¯ik,u˜ikandu^ik.Lemma 5Ifminiu^ik≥16mlog(m2n/ϵ)ϵ2,then with probability1−ϵ,for all i,(12)(1−ϵnℓk)u^ik≤nℓku¯ik≤(1+ϵnℓk)u^ikand(13)(1−ϵnℓk)u^ik≤u˜ik≤(1+ϵnℓk)u^ik.Lemma 5 shows that with high probability,nℓku¯ik,u˜ikandu^ikare close to each other. In particular, when k is small, the factor(1±ϵn/ℓk)is relatively loose while as k increases, the factor becomes tight. The proof of Lemma 5 is similar to that of Lemma 3 and is relegated to the Appendix. The next lemma gives a bound on the revenue obtained by the DLA.Lemma 6Ifu^ik≥16mlog(m2n/ϵ)ϵ2for all i and k, then with probability1−ϵ,∑i=1mMi(nℓiu¯ik)≥(1−6ϵnlk)OPT.The proof of Lemma 6 can be found in the Appendix.Finally, we prove Proposition 3. We bound the objective value of the actual allocation. Note that the actual allocation for each i can be written as∑k=1Lu¯ik=∑k=1Lαknℓku¯ik,whereαk=ℓkn. By the property of concave functions, we have∑i=1mMi(∑k=1Lu¯ik)=∑i=1mMi(∑k=1Lαknℓku¯ik+(1−∑k=1Lαk)·0)≥∑i=1m∑k=1LαkMi(nℓku¯ik).By Lemma 6, with probability1−ϵ∑i=1m∑k=1LαkMi(nℓku¯ik)≥∑k=1Lℓkn(1−6ϵnℓk)OPT=(1−ϵ)OPT−6ϵ∑k=1LℓknOPT≥(1−16ϵ)OPT,where the last inequality is because∑k=1Lℓkn=12+14⋯≤1+2≤2.5.Therefore, Proposition 3 is proved. □Similar to Lemma 4, we have the following conditions on the input parameters such that with high probability, the conditions in Proposition 3 hold.Lemma 7For any C > 0, suppose the following condition holds:(14)n≥max{24log(m/ϵ)ϵb¯2,4mCF(M,η)ϵb¯}whereb¯=1nmini{∑j=1nbij},η=mini,j{bij|bij>0}and F(M, η) is such thatMi′(ηF(M,η)C)<ηMi′′(C),∀i,i′.Then with probability1−ϵ,u^ik≥C,for all i.The proof of Lemma 7 is given in the Appendix. Finally, we combine Proposition 3 and Lemma 7, and Theorem 1 follows.The same remark after Lemma 4 applies here. In particular, the conditions in Lemma 7 is only one set of sufficient conditions for our algorithm to achieve the target performance. However, one may also use the conditions in Proposition 3 if they turn out to hold in practice. In the next section, we show that the DLA works well even if the conditions in Lemma 7 are not satisfied.In this section, we report some numerical test results for our algorithms (both the OLA and the DLA). The objective is to validate the strength of our approaches and investigate the relationship between the performance of our algorithms and the input parameters.In our numerical tests, we consider the Adwords problem. We assume there are m advertisers (bidders), n keywords arriving sequentially, and bijis the amount bidder i would like to pay to display his advertisement on keyword search j. We introduce a base problem in which we setm=50,n=10,000andMi(x)=xpwithp=0.9. The bidding values bijare generated in the following way:1.Assume there arek=100categories of keywords. For each category k, there is a base valuation of bidder i, denoted byb¯ik,which is generated according to the following distribution:b¯ik={0withprobability0.7U[0.2,1]withprobability0.3,where U[a, b] denotes a uniformly distributed random variable on [a, b].For each arriving keyword, we first randomly choose a category. The probability for each category i, denoted by ρi, is randomly chosen on the simplex{ρi|∑i=1kρi=1,ρi≥0}. Then if category k0 is chosen, the final bid value for bidder i will beb¯ik0·U[0.9,1.1].Although the way bijis chosen seems arbitrary, we believe it reflects some major features of the bid values in practice. In the Adwords problem, each bidder is interested in certain categories of keywords. For example, a sport product company is interested in keywords related to sports. Theb¯iks represent such interest levels. Then the bidder i’s actual bid on such a keyword is the base valueb¯ikmultiplied by a random number, which reflects some level of idiosyncrasies of each keyword arrival. We also tested other ways to generate bij, and the test results are similar. We will report those test results in the end of this section.To evaluate the performance of our algorithms, we introduce the notion of relative loss (RL) defined as follows:RL=1−ActualRevenueOfflineOptimalRevenue.In the numerical experiment, there is one key parameter we need to set in both of our algorithms:ϵ. In Theorem 1 and Proposition 1, we gave sufficient conditions on the inputs such that the algorithms will have expected RL less thanϵ. However, the theoretical results are asymptotic and thus may not represent the best practical choice ofϵ. In Table 1and Fig. 1, we first test both our OLA and DLA with different choices ofϵ. We have the following observations from Table 1 and Fig. 1 (each number in Table 1 is the average RL of 100 independent runs, the standard deviations of the results are insignificant compared to the average value):•For the DLA, choosing a smallerϵimproves its performance. There are two reasons for that. First, choosing a smallerϵreduces the loss due to ignoring the firstϵnbids. Second, it increases the number of price updates which help the decision maker to refine the decision policy and achieve better performance. Therefore one should choose a smallerϵin the DLA.For the OLA, the optimal choice ofϵis more subtle. There are two countervailing forces when one chooses a smallerϵ. On one hand, by choosing a smallerϵ,the loss due to the failure to allocate any bid during period 1 toϵnbecomes smaller, which benefits the algorithm. On the other hand, ifϵis too small, the learned price may not be accurate enough which may lead to poor allocation in the remaining periods. In the test example, the optimal choice isϵ=0.02.The DLA outperforms the OLA for all choices ofϵ.Next we focus ourselves on the DLA. As shown in Table 1, we prefer to choose a smallerϵin the DLA. In the following experiments, we will chooseϵ=0.001. Next we compare the performance of the DLA to a myopic allocation method which simply allocates each incoming keyword to the bidder with the highest bijvalue. We also study the impact of the two parameters, n and p, on the performance of our algorithm. We generate 100 instances of the input bijand compare the average performance. The results of the average RL are shown in Table 2 (the standard deviations are shown in the parentheses) as well as in Figs. 2 a and b.From Table 2, we can see that the DLA consistently performs better than the myopic approach. In particular, the performance of the DLA gradually improves when n increases, while the performance of the myopic approach seems to be insensitive to the size n of the problem. Moreover, even for small values of n, the performance of the DLA is still very good. This means that the DLA works well even for problems whose size is much smaller than what Theorem 1 requires. For the parameter p, we can see that both the DLA and the myopic algorithm deteriorate when p decreases, but the DLA deteriorates much slower. Finally, we comment that these results are computed when we ignore the firstϵnbids. In practice, one does not need to do that and the performance of the DLA would be even better.Finally, we repeat the above test for different setups of the inputs. We fix the parametersm=50,n=10,000,andMi(x)=xpwithp=0.9in the base problem and generate bijs in the following ways:1.bijfollows a normal distribution (truncated at 0 and 1). The parameters of each normal distribution (mean μ and standard deviation σ) are randomly generated from a uniform distribution on [0, 1].bijfollows a Beta distribution. The parameters (α, β) of the Beta distribution are generated from a uniform distribution on [0, 1].bijfollows a mixed normal and Beta distribution. That is, with probability 0.5, bijfollows a truncated normal distribution with mean 0.5 and standard deviation 0.5, and with probability 0.5, bijfollows a Beta distribution withα=β=1/2.Next, we compare the performance of the DLA (chooseϵ=0.001) and the myopic algorithm. For each case, we generate 100 instances of the input bijand compare the average RL. The results are shown in Table 3.From Table 3, we can see that the DLA outperforms the myopic approach under all the above three setups. The RL of the DLA decreases as the problem size grows, while the RL of the myopic policy is not sensitive to n. Also, as p changes, the performance of the DLA is rather stable, while the performance of the myopic algorithm varies a lot. The overall trend of the DLA and the myopic algorithm resembles that in the experiment in the beginning of this section. Finally, we observe that the DLA seems robust toward various problem setups, while the myopic approach does not.

@&#CONCLUSIONS@&#
