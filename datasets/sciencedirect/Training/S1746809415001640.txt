@&#MAIN-TITLE@&#
Is sample entropy based entropic half-life and de-trended fluctuation analysis correlated and do they reflect phase regularity of center of pressure measurements?

@&#HIGHLIGHTS@&#
Entropic half-life (EnHL) is a variable that reflects long range correlation in the COP signal.1/EnHL negatively correlates with the scaling factor α of a de-trended fluctuation analysis.EnHL and the scaling factor α depend on the phase regularity of the COP signal.EnHL and the scaling factor α reflect information about motor control of balance.

@&#KEYPHRASES@&#
Balance,Complexity,Phase surrogate,Long-range correlation,Variability,Postural control,

@&#ABSTRACT@&#
The reshape scale (RS) method computes the transition of Sample Entropy (SEn) from low to large values as the scale is increased. At the largest scale, SEn asymptotically converges to the maximum SEn evaluated using the average of SEn for the fully randomly re-ordered realizations of the original signal. The entropic half-life (EnHL) characterizes such a transition. The EnHL is the scale representing the midpoint of the transition and yields a measure for the temporal degradation of the regularity in a signal. In postural balance studies, the EnHL of the center of pressure (COP) signal can be interpreted as the time elapsed before the old sensory states is no longer utilized by the postural control system to adjust the current COP position. Other equally sensitive measures of regularity, such as de-trended fluctuation analysis (DFA), can be interpreted in the same way; however, it results in a dimensionless measure of regularity and complexity.The primary objective of this study was to experimentally demonstrate the correlation between the scaling exponent α calculated using DFA and the inverse of EnHL. When the COP signal was studied in the Fourier domain, a non-random structure was observed in the phase of the COP signal, which might be related to the neuromuscular characteristics of the postural control system. The second objective of this paper was to demonstrate that the EnHL and α both retain information contained in the phase of the Fourier transformed signal.It is shown in this paper that the EnHL and α are both sensitive to non-random structures of the phase of the Fourier transformed signal. Contrary to α, which is a dimensionless number, the EnHL measures the regularity and complexity of the signal in units of time. Therefore, it was concluded that the EnHL provides a more physically interpretable and intuitively understandable measure of the properties of the control of the COP signal.

@&#INTRODUCTION@&#
Most biological signals recorded from human participants exhibit distinct variations. Previously, these variations were attributed to random noise and were therefore filtered out. Recently, non-linear signal processing techniques have been utilized to study the nature of these variations. The primary question to be addressed by these techniques is whether these variations can be characterized by linear auto-regressive moving average (ARMA) processes, or whether they actually contain structures resulting from subtle mechanistic effects caused by neuro-motor control [1–3]. The primary property of the ARMA process is that it can be fully characterized by its autocorrelation function [1]. A Fourier transform decomposes a given signal into an amplitude and a phase component at each frequency. The autocorrelation of a signal is equivalent to the power of the signal in the Fourier domain. The power of a real signal, at each frequency, is given by the square of the amplitude. Therefore, the power spectral density (PSD) of a real signal, by definition, is independent of the information contained in the phase of the signal. As such, it can be concluded that if a signal can be fully characterized by its autocorrelation function, then the signal has no structure in its phase, in other words, the phase of the signal is random. The assumption that the process can be fully characterized by an ARMA process leads to a null hypothesis that the observed variability in the signal can be readily modelled by a linear ARMA process. Therefore, methodologies are required to assess the regularity, complexity and long range correlations of a signal [4]. One such methodology is surrogate analysis, which was proposed by Theiler [1]. For a special case of this method, the outlined hypothesis can be tested by randomizing the phase of the signal. The surrogated realization of the signal can be recounstructed in the time domain by taking an inverse Fourier transform [1]. A desired statistical measure, such as entropy of the signal, can then be calculated for the surrogate realizations and compared to the corresponding measure calculated for the original signal.Non-linear signal processing measures have been widely used in the field of biological signal analysis. These include: Hurst coefficient, Lyapounov exponent, and scaling exponent α calculated using the deterended fluctation analysis (DFA). These non-linear measures can be added to other signal processing measures such as the already mentioned auto-correlation and spectral analysis, to provide a more complete picture about the signal [5].An important consideration is that the majority of non-linear measures are subtly interrelated. For example α is a dimensionless number between 1.5 and 2 for persistant signals which was first introduced to characterize fractional brownian motion [6]. This measure is related to the Hurst coefficient (H) according to α=H+1 [7,8]. The Hurst coefficient on the other hand is correlated to the maximal Lyapunov exponent [9]. Further details about the interrelations between various non-linear measures as well as their relations to the PSD, and equivalently the autocorrelation, were previously studied and reported [10]. Despite subtle interrelationships, these measures are still informative and complementary to one another as they quantify similar properties of the signal, but from different angles.In the context of information theory, entropy can be viewed as a measure of uncertainty of a random variable [11], which can be defined as the average information that a signal contains. To calculate the entropy of a signal with finite length, several algorithms have been proposed [12–14]. One of the most recently proposed methods to approximate the entropy of a signal is the algorithm for sample entropy (SEn) [12]. In this algorithm, several non-overlapping short vectors of length m are selected from the signal by taking m consecutive points of the signal. A distance, normally not the Euclidian one, is calculated afterwards to characterize the similarity between any such vector pairs. The SEn variable is the negative of the natural logarithm of the conditional probability that if the two m-point sequences are similar within a threshold distance of r, they will remain similar after adding the next point [12].To further study the dynamics of complex signals, the multi-scale coarse graining algorithm has been proposed [15]. This method down samples the signal by taking the mean value of every k (a natural numbers) consecutive time points to create a new signal at “scale k”. The SEn is calculated afterwards for the signal at each scale. A plot of SEn versus scale shows how the SEn changes as the signal gradually becomes smoother [15]. The method, when applied to COP signals, reveals changes of SEn as the time span between consecutive samples increases (scale). However, this algorithm changes the length, standard deviation (SD), and probability density function of the signal [16,17]. The SEn is sensitive to changes of these statistical properties of a signal. Therefore, the pattern of SEn curve in the coarse graining approach might not be representative of the underlying dynamics of the signal alone, but rather be influenced by the combined non-linear effects of the scale and the outlined changes [17].Recently the reshape scale (RS) method, a novel multi-scale entropic analysis technique, was proposed, which does not alter the length, SD, and the probability distribution of the time series [17]. The RS-method synthesizes signals at scales k (a natural number) by taking every kth consecutive data points from the original signal and then calculates the SEn for the scaled signals. When the RS-method was applied to the COP data, a monotonic sigmoid like transition of SEn versus scale was observed [18]. This transition starts from a minimal SEn and ends at a maximal value SEn. To characterize this transition for the COP signal, the scale at which the transition reaches half of the maximum SEn was defined as the entropic half-life (EnHL). The reliability of the EnHL proved to be comparable to the reliability of classical variables widely used to assess the COP signal [18].The EnHL can be viewed as a variable that quantifies the time that elapses before old positional information in the signal is no longer utilized by the control mechanisms, which regulates the movement of the current COP location. The EnHL provides a more intuitively comprehendible way of detecting changes in complexity since it is expressed in units of time, which make it a more physiologically interpretable measure compared to α extracted from a DFA. Yet, the computational methods for determining EnHL and α both rely on the scaling and variability of the data. Therefore, it can be hypothesized that there might be a relationship between EnHL and α, and accordingly, also between EnHL and other non-linear measures such as Hurst coefficient and the Lyapunov exponent.Therefore, the objectives of the current work can be summarized as follows:[Obj1] To show that the scaling exponent α obtained by the DFA is linearly correlated to the inverse of the EnHL (EnHL−1).[Obj2] To test the hypothesis that EnHL and α reveal the presence of a non-random, deterministic structure in the COP signal that is captured in the phase of the COP signal. This will be tested by studying changes in EnHL and α caused by phase randomizations in a surrogate analysis [4]. If EnHL and α change significantly as a result of surrogate realizations, then EnHL represents an entropic measure for the complexity of the phase of the original signal.

@&#CONCLUSIONS@&#
