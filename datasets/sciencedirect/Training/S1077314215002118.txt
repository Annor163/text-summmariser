@&#MAIN-TITLE@&#
Learning hierarchical 3D kernel descriptors for RGB-D action recognition

@&#HIGHLIGHTS@&#
We propose a hierarchical kernel based method to learn the non-linear correlations between RGB and depth action data for action recognition.We employ the efficient match kernels (EMK) in our framework, which allows us to learn nonlinear correlations between body parts.We also apply hierarchical kernel descriptors (HKD) as higher level of our framework to aggregate patch-level features into one representative feature vector for each video.Through extensive experiments we demonstrate the proposed approach achieves superior performance on four standard RGB-D sequences benchmarks.

@&#KEYPHRASES@&#
RGB-D action,Action recognition,Kernel descriptor,

@&#ABSTRACT@&#
Human action recognition is an important and challenging task due to intra-class variation and complexity of actions which is caused by diverse style and duration in performed action. Previous works mostly concentrate on either depth or RGB data to build an understanding about the shape and movement cues in videos but fail to simultaneously utilize rich information in both channels. In this paper we study the problem of RGB-D action recognition from both RGB and depth sequences using kernel descriptors. Kernel descriptors provide an unified and elegant framework to turn pixel-level attributes into descriptive information about the performed actions in video. We show how using simple kernel descriptors over pixel attributes in video sequences achieves a great success compared to the state-of-the-art complex methods. Following the success of kernel descriptors (Bo, et al., 2010) on object recognition task, we put forward the claim that using 3D kernel descriptors could be an effective way to project the low-level features on 3D patches into a powerful structure which can effectively describe the scene. We build our system upon the 3D Gradient kernel descriptor and construct a hierarchical framework by employing efficient match kernel (EMK) (Bo, and Sminchisescu, 2009) and hierarchical kernel descriptors (HKD) as higher levels to abstract the mid-level features for classification. Through extensive experiments we demonstrate the proposed approach achieves superior performance on four standard RGB-D sequences benchmarks.

@&#INTRODUCTION@&#
Despite the many research efforts in recognizing human actions and many encouraging advances in computer vision field, still accurate action recognition is a challenging task due to large intra-class variation and background noise. Introducing low-cost devices such as Kinect sensors has triggered many research activities for achieving concise descriptions in recognition task due to their availability of depth sequences alongside the RGB data. Insensitivity of depth images to different lighting situations and illuminations is an effective advantage compared to color images. Moreover, depth sequences provide additional shape and movement information due to providing accurate distance information for each pixel in image.However, depth sequences [5,6,27] are noisy with undefined depth data and incorrect joint data. Existing work [4,6,27] directly builds on low-level noisy features, which are hardly being linearly separated, and thus this would hurt the performance due to the noisy raw features. In addition, the correlations between human body parts are highly nonlinear. It is difficult to model their joint distribution accurately by extracting features from each of them and concatenating the two features.It would be better to utilize other robust source of information to alleviate the problem of noisy data. In using depth sequences, recent works such as [4] consider the human motion as a posture of the body segments and employ the skeleton tracker to construct a discriminative representation from depth sequences. However, skeleton data are also noisy, and the correlations between skeleton data and depth data are highly nonlinear and difficult to learn. In addition, as presented in [27], utilizing low-level attributes in depth images outperforms recent high-level representations with improvement on capturing joint shape-motion cues. This idea leads us towards employing low-level attributes in depth images in a more elaborate way to capture accurate information in describing action scene.In this paper, we propose a hierarchical kernel based method to learn the non-linear correlations between RGB and depth action data for action recognition. The aforementioned problems are overcome by a novel hierarchical kernel framework motivated by the recent success of kernel descriptors for object recognition task [2]. We propose a 3D gradient kernel descriptor which is a low-level depth sequence descriptor with ability of capturing detailed information by computing pixel-level 3D gradient. The framework of our approach is illustrated in Fig. 1. Our 3D gradient kernel is essentially producing normal vectors on the surface of 3D geometric shape of scene using the gradient in depth images. Moreover, the gradient information is computed along the temporal dimension as well as the spatial dimensions to describe the change in shape of the 3D surface in time. As it was shown in [7], using the normal vectors in depth images provides a rich description of the scene.At higher level, we use two different methods to summarize the mid-level features for classification. The efficient match kernels (EMK) is the first method which allows us to learn nonlinear correlations between body parts. The learned high-order correlations accurately measure the similarities between two RGB-D action videos, and provide rich mid-level information to bridge the semantic gap for classification. We also apply hierarchical kernel descriptors (HKD) as higher level of our framework to aggregate patch-level features into one representative feature vector for each video. These hierarchical kernel descriptors are based on the first layer of our framework where instead of working on pixel-level attributes, they get the patch-level features as input and generate a feature vector for each patch block. Finally, the classification is performed by using linear SVM.This work is an extension of our previous paper [1]. The extensions are: (a) Type of data, here we use both RGB and depth data while in [1] we just focus on depth data. (b) Method used in middle layer of framework. We just use EMK in [1] while here we introduce HKD and show how it improves our results. (c) Extensive experimental result on more datasets.Our work differs from existing normal-based methods [7,27,30]. One major difference is that our method utilize rich information in both color and depth sequences, while [7,27,30] only uses depth information. In addition, we compute nonlinear efficient match kernels for a RGB-D video, while [7,27,30] aggregates local features to build the representative feature vector for each video. Our method is particularly designed for RGB-D actions, while [2,3] were designed for object recognition. We compute 3D gradient in the low-level feature extraction to capture temporal information, while [2,3] uses 2D gradient. We achieve state-of-the-art results on three public RGB-D action datasets, and comparable results on the fourth dataset, while [2,3] was not tested on RGB-D action recognition datasets. We carefully adapted the parameters in the 3D gradient, EMK and HKD, and show the optimal parameters for RGB-D action recognition, as the proposed method is sensitive to those parameters.We show how our framework is applied to RGB-D sequences for achieving discriminative information and surpassing sophisticated learning approaches based on high-level features. Our method is extensively evaluated on four RGB-D datasets, MSR Action 3D [8], MSR Gesture 3D [6], MSR Action Pairs [27], and MSR DailyActivity 3D datasets [4], and show superior performance over state-of-the-art approaches.

@&#CONCLUSIONS@&#
