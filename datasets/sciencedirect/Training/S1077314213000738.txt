@&#MAIN-TITLE@&#
Graph cut segmentation with a statistical shape model in cardiac MRI

@&#HIGHLIGHTS@&#
Challenging segmentation of the right ventricle in cardiac MR images.Use of a statistical shape model based on a signed distance function in order to constrain the segmentation.The shape prior is introduced into a graph cut approach.Results are comparable to the state-of-the-art in RV segmentation.

@&#KEYPHRASES@&#
Image segmentation,Graph cut,Shape prior,MRI,Cardiac ventricle,

@&#ABSTRACT@&#
Segmenting the right ventricle (RV) in magnetic resonance (MR) images is required for cardiac function assessment. The segmentation of the RV is a difficult task due to low contrast with surrounding tissues and high shape variability. To overcome these problems, we introduce a segmentation method based on a statistical shape model obtained with a principal component analysis (PCA) on a set of representative shapes of the RV. Shapes are not represented by a set of points, but by distance maps to their contour, relaxing the need for a costly landmark detection and matching process. A shape model is thus obtained by computing a PCA on the shape variations. This prior is registered onto the image via a very simple user interaction and then incorporated into the well-known graph cut framework in order to guide the segmentation. Our semi-automatic segmentation method has been applied on 248 MR images of a publicly available dataset (from MICCAI’12 Right Ventricle Segmentation Challenge). We show that encouraging results can be obtained for this challenging application.

@&#INTRODUCTION@&#
Magnetic resonance imaging (MRI) is increasingly used as a standard tool in the evaluation of the right ventricle (RV) function [14]. The segmentation of the RV cavity is a prerequisite to the computation of clinical parameters. Although some relatively efficacious methods are commercially available for segmenting the left ventricle (LV) on MR images, such as MASS (Medis, Leiden, The Netherlands) [40] and Argus (Siemens Medical Systems, Germany) [24], the segmentation of the RV is currently performed manually in clinical routine. This lengthy and tedious task requires about 20min by a clinician and is also prone to intra and inter-expert variability. An automatic segmentation method would avoid these drawbacks, but has to deal with the following issues: (i) fuzziness of the cavity borders due to blood flow and partial volume effect, (ii) the presence of trabeculations (wall irregularities) in the RV, which have the same grey level as the surrounding myocardium, (iii) the complex crescent shape of the RV, which varies according to the imaging slice level (see Fig. 1). This is probably one of the reasons why RV functional assessment has long been considered secondary compared to that of the LV, leaving the problem of RV segmentation wide open [27].The literature of RV segmentation is thus much less abundant than the one of LV segmentation. Most of RV segmentation methods are based on a joint segmentation of both ventricles. These methods take benefit from the relative positions of the ventricles and the similarity of the gray levels in their respective blood cavities. For example, this information is used within active contours [29], or within a framework combining thresholding, clustering and morphological operations [4]. Another possibility is to use higher-level prior anatomical information to guide the segmentation process, such as a biomechanical model [33] or statistical shape models. In this latter case, the statistical shape model maybe a Point Distribution Model (PDM), obtained by a principal component analysis (PCA) on the set of aligned shapes, and integrated into the well-known active shape and appearance modeling framework [6]. This technique ensures to have a realistic solution since only shapes similar to the training set are allowed, but at the expense of building a training data set with manually generated segmentations. It has been applied to the segmentation of both LV and RV in [23,25]. Statistical prior information may also take the form of an heart atlas. An atlas describes the different structures present in a given type of image. The segmentation of the ventricles is obtained by registering a single [19] or multiple atlases [15] onto the image to be segmented.Shape prior based segmentation: More generally, automatic organ segmentation can benefit from the use of information regarding shape and/or gray levels, to increase its robustness and accuracy [8]. This especially applies if the nature of the shape does not change much from an example/individual to another. Making use a shape prior for object segmentation involves two steps:(i)The definition of a mathematical shape representation. In the literature, shapes are usually represented by an explicit model such as a point distribution model (PDM) [6] or an implicit one e.g. signed distance function [16]. We discuss both representations, the PDM vs. the SDF in Section 2;The definition of the segmentation framework. Initially proposed in the deform models framework, the PDM representation has been mostly used in the active shape and appearance modeling approaches [6]. The SDF representation allowed to easily extend the use of a shape prior into variational frameworks [16,7], and more recently, the graph cut framework [35,11]. In this paper, our aim is to take advantage of the versatility and the low computational cost of the graph cut, in order to propose an efficient prior-based segmentation approach for the RV in cardiac MRI as described in Section 3.Graph cut with shape prior: The graph cut approach is based on the global optimization of a cost function and is very computationally efficient in 2D [1]. It is also flexible enough to easily take into account shape information. As of today, its use in medical image segmentation has been restricted to a few applications. In [12], a “blob” is created to constraint the segmentation of the entire heart in Computer Tomography (CT) cardiac scans. The shape model may be either an arbitrary fixed template [11], or a parametric curve: an elliptical mask is used for segmenting circular structures (blood vessel) in MRI [35], and circles are used for the LV segmentation in cardiac MRI [46]. But the object to be segmented might not be easily described with a parametric shape. Statistical shape models take into account the variabilities of the shape, at the expense of building a set of manually segmented shapes [36,45]. The use of a specific shape model often imposes an iterative process, with alternates between shape model registration and graph-cut based segmentation, which can be computationally expensive. For example, in [45], the method consists in alternatively searching the PCA, GMM and the pose parameters using gradient descent (maximization step) and segmenting by graph cut using the current shape from the PCA (estimation step), as in an EM framework. Our idea is to design a statistical shape model and to design a graph cut based segmentation framework without the need for an iterative process.In the remainder of the article, we introduce in Section 2 statistical shape models and two possible representations: point-wise based and signed distance function-based. We propose a shape representation, that will be used for the shape prior. We then recall graph cut basics for image segmentation and introduce our method in Section 3. Experiments provided in Section 4 include a comparison to a state of the art, namely Freedman and Zhang’s approach [11]. Conclusion and future works are drawn in Section 5.There has been a lot of work on the building and the use of statistical shape models for image segmentation [13,3,31,34,44,17,10]. The use of such models can indeed be of great help when the boundaries of the objet are ill-defined with occlusions. Point-distribution model (PDM) is one of the most widely used representation, used in the ASM framework. The PDM is an explicit shape representation: objects are represented by a finite number of landmarks [5,43,20]. The PDM requires to have point correspondences before performing an analysis. A problem arises in practice when dealing with PDM. The number of available shapes in the training set is often insufficient, where a manual labeling of medical data can be very tedious while establishing correspondences can also be very challenging. This process is prone to variability if manual, and prone to detection error if automatic.To address this problem, another representation consists in considering the shape as a zero-level set and the values of the remaining voxels by their shortest (usually Euclidian) distance to the boundary [16,7]. This shape representation does not require point correspondences, the shape variability being implicitly represented by the distance variability. Eigenshape decomposition using SDF implicit representation provides tolerance to slight misalignment of object features, since slightly misaligned pixels in a SDF are generally highly correlated. But using a linear (Euclidean) vector space to compute and combine eigenshapes might be an invalid space [30]. However, as point out in [16], the surfaces generally still have advantageous properties of smoothness, local dependence, and zero level sets consistent with the combination of original curves with the use of SDF representation.In the following section, a statistical shape model based on distance map is proposed, derived from SDF as previously introduced in [16,32]. A comparison with the PDM is carried out to show the similarity of both models.PDM is an efficient model to represent shape variability. Our idea is to build a statistical shape model which does not need to match corresponding points, but can represent the shape in a similar way as PDM does, as initially proposed in [16]. Consider a set of n two-dimensional binary aligned images of size H×W composed of shapes of the same class of object. The SDF to each curve is classically defined as H×W samples encoding the distance to the nearest point on the curve, with for example negative values inside the object. Let Z be the matrix of SDF of each curve, where each column vector are the H×W distance samples to the corresponding curve and where each row are the distances for the same location point for each curve of the training set. The objective is to extract shape variations of this matrix Z. The average distance map is considered as the reference by averaging each row of Z:(1)ρ=1n∑i=1nZ.,iρis a vector of length H.W. To capture the variability, we propose a different approach for distance function representation from the one used in the literature [16,37]. Usually, a mean signed distance map is chosen as the reference, which implies that the PCA is performed in the distance function space. As the mean of signed distances is not a signed distance, we reset this map to the distance values. We thus propose to calculate first the mean shape from the mean signed distance maps and then compute its signed distance map. Let p be a point of the image domain included inR2. The binary mean shape is defined as:(2)χρ(p)=-1ifρ(p)⩾0+1ifρ(p)<0LetCbe the set of the curve points of the binary mean shapeχρ(p). The referenceμis computed by determining distances to the contour:(3)μ(p)=χρ(p)×infq∈C|p-q|Individual shapes are centered:(4)M=(Z.,1-μ)⋯(Z.,n-μ)In this way, PCA is performed in the space of shape variations. The variability in shape is captured using a PCA. Using Singular Value Decomposition (SVD), the covariance matrix, defined by1nMMT, is decomposed to find orthogonal modes of shape variation and corresponding singular values:(5)1nMMT=UΣUTwhere U is a matrix whose column vectors represent the set of orthogonal modes of shape variation, namely eigenvectors, and Σ is a n×n diagonal matrix of corresponding singular values, or eigenvalues. Note that dimension of1nMMTis large and belong number of pixels, H.W×eH.W. Eigenvectors and eigenvalues computation of this matrix is computationally expensive. A solution exists to deal with large sample size in PCA [38].In the following, we consider eigenvalues and eigenvectors have been sorted according to size of eigenvalues. Let k⩽n be the number of modes to consider, which defines the amount of retained shape variation. Let z be a novel shape of the same class of object, andzˆan estimation from z, computed with:(6)zˆ=μ+∑i=1kαiUk.,iwhereαiare obtained with:(7)α=UkT(z-μ)withUkTbeing a matrix consisting of the first k columns of U that is used to project z into the subspace.An empirical comparison to illustrate the difference between both representations has been carried out on a dataset of 12 jet images of size 114×114 [37] (Fig. 2). All images are first aligned to the one of them. Both models are then constructed from the aligned images, the PDM being computed on ℓ landmarks. The superposition of both mean shapes and their two principal modes of variation is shown in Fig. 3, that illustrates a similarity of the both mean shapes. Both models do not represent the shape variability in the same space but axes of variation look similar.In the following, we try to quantify the difference between both models, when used to describe a novel shape instance. Each shape of the jet dataset is being reconstructed with both a SDF and a PDM representation, on a leave-one-out basis: n−1 shapes are used to build both shape models and the last one being used for estimation. Note that the PDM consists of ℓ corresponding landmarks on easily identifiable points. Two standard metrics are then computed to compare the estimated shape and the real one: (i) the Dice coefficient DM(A, B), an overlap measure between two shapes A and B defined by:(8)DM(A,B)=2|A∩B||A|+|B|and (ii) the average point-to-curve (P2C) error between two contours, defined by:(9)P2C(A,B)=1|A|∑a∈Aminb∈Bd(a,b)where ∣A∣ denotes the number of points of contour A. Results, shown in Table 1, provide the overlap rates and P2C error in pixels with a varying number of points ℓ and a varying number of eigenvectors k used for the reconstruction. Not surprisingly, reconstruction errors decrease as k increases. Note as well that the PDM seems to capture details slightly better than the SDF representation, whatever the number of points. This can also be observed in Fig. 4, where the reconstruction of two sample shapes by the two representations PDM and SDF are illustrated. Although slightly less accurate, in terms of reconstruction, results obtained by the SDF show that a correct reconstruction of shape can be obtained, without the need for a costly landmark detection and matching process. In summary, the SDF representation has the following advantages over the PDM representation:•It does not require the positioning of several landmark points, a process prone to variability if manual, and prone to detection error if automatic;It does not require landmark matching, a prerequisite before shape analysis, that is difficult to establish;It it more robust than the PDM to initial misalignment of the shapes [16].This SDF representation is thus retained in our segmentation method, described in the next section.In this section, we first outline the graph cut segmentation framework as described in [1]. Then, we introduce the construction of the shape model based on a PCA and show how it can be integrated into the graph cut cost function.Let us consider the image I as a graphG=〈V,E〉, whereVis the set of nodes (pixels) andEthe set of edges. Each pair of nodes(p,q)∈Ein a neighborhoodNis connected by a segment called n-link and weighted by Bp,q, a regularization or boundary term, designed to provide spatial coherence in a neighborhood of pixels. Bp,qis typically defined as:(10)Bp,q∝exp-(Ip-Iq)22σ2.1dist(p,q)where Ipand Iqare the gray levels of pixels p and q, dist(p, q) the Euclidean distance between p and q, and σ a constant usually related to acquisition noise. Consider two additional nodes, called terminal nodes: the sourceSrepresenting the objectO(in our case, the RV cavity), and the sinkTrepresenting the backgroundB. Each nodep∈Vis connected to the terminal nodesSandTby two respective segments called t-links and weighted by the so-called region term, denoted Rpand defined by:(11)Rp(ω)=-lnPr(Ip|ω)where Pr(Ip∣ω) is the likelihood of observing Ipgiven that pixel p belongs to class ω.A cutCin the graph consists in cutting t-links and n-links to attribute a labelOorBto each pixel p of the image, which boils down to segmenting the image. The energy of a cutCis defined by:(12)E(C)=∑p∈VRp(ωp)+λ∑p,q∈NBp,q.δ(ωp≠ωq)where δ(ωp≠ωq) is 0 if p and q have the same label, 1 otherwise. The optimal segmentation is obtained by searching for the cut of minimal energy. This global search can be very efficiently performed due to mincut-maxflow algorithms, in polynomial time [2].To guide the segmentation process, constraints or models for the object can be introduced through an additional term in the energy formulation of Eq. (12). How to incorporate this prior information depends on the available information: either the constraints are weak and are simple assumptions about the general shape of the object (e.g. convex) or the constraints are strong and concern a precise shape to find in the image.Weak constraints. In the literature, the constraints on rough shapes are specified through the n-links, changing the labeling of the neighboring pixels under the assumption made. In [9], the values of the boundary energy Bp, qare modified by prohibiting certain relative positions of p and q, thus promoting compact shapes. The same methodology is used in [41] for more general shapes than convex shapes: it requires that if C is the center of the shape and p a point in the shape, any point q on the line (C, p) after p be also inside the shape. Note that this method has an interesting effect countering shrinkage typically seen in the graph cut segmentation, but implies significant discretization problems. Requiring that the result of segmentation is convex can also be done through an additional energy term as 1−cos (α), where α is the angle between (p, q) and (p, C) where C is the center of the object designated by a user click [12]. This shows how important angles are penalized by high values of energy, encouraging roughly convex cuts in the graph (Fig. 5).Strong constraints. When a model of the object is available, it is generally imposed on segmentation through the t-links, including an additional term in the energy formulation of the graph which may be similar to the regional term Rp. The classical Rpformulations are changed by replacing the intensity models of the object by labels of the shape prior [35] or a map of probability [36,21], in which case the energy associated with the prior takes the form:Es(ωp)=-ln(PrA(ωp))where PrA(ωp) is the probability of a pixel p belongs to the class ωpdepending on the model. Note that the use of a shape prior implies a difficult problem of matching the model with the image. The registration can be done iteratively and therefore computationaly expensive: the pose parameters estimation and the segmentation calculation are alternated [45,46,42,21]. When registration is a prequisite for the segmentation, process is based on a user interaction [11,36]. The model is defined in this case by a distance map or an atlas. Note that these models are limited to represent judiciously variability in shape.A shape model is constructed via a PCA, and summarized in a single map. This map is registered to the image via light user input and is incorporated in the graph cost function. An overview of the method is presented in Fig. 6.Let us consider N binary shapes of the RV endocardium, obtained by manually segmenting the RV on N cardiac MR images. For each binary shape, a signed distance map ϕito the RV contour is computed. Shapes are rigidly aligned on an arbitrary reference shape and averaged into a mean shapeΦ¯(Fig. 7a):(13)Φ¯=1N∑i=1NϕiSince averaging does not ensure to obtain a distance function, we propose to resetΦ¯to a SDF to the RV contour. A PCA is then performed on the set of centered shapes and yields eigenshapes denoted by Φi, with i=1…N, and their associated eigenvalues, denoted λi[37]. A number k⩽N of eigenshapes is retained, with k chosen large enough to account for the most important shape variations present in the training set.Let us now describe how a single prior map is computed from the PCA. Our aim is to isolate areas of variation of the mean shape, for each principal axis. We thus generate highly deformed shape instances for each axis (Fig. 7b and c):(14)γi±=Φ¯±3λiΦi,foralli=1…kThen, the areas of variation of the mean shape for eigenmode i may be obtained with an exclusive OR between the binary mean shape and the binarizedγi±:(15)Γi(p)=H(Φ¯)⊕Hγi++H(Φ¯)⊕Hγi-,foralli=1…kwhereH(·)is the Heaviside function. Γiis a binary map that contains areas of variation of the mean shape, for eigenmode i (Fig. 7d). This map is superimposed to the distance values of the mean shapeΦ¯(Fig. 7e and g):(16)PMi(p)=Γi(p)·Φ¯,foralli=1…kThe k distance maps are averaged into a single distance map (Fig. 7h):(17)PS(p)=1k∑i=1kPMi(p)PSincludes a distance based region where the contour is expected to be and the complementary region filled with null values.Now how can this prior map be integrated into the graph cut framework? In the literature, additional energy terms on the t-links[36,21] or the n-links[11] are added to the graph cost function. In any case, the shape prior must be rigidly registered onto the image to be segmented (see Section 4). We suggest that the shape prior contribute to weighting both t-links and n-links. The region term Rpcan straightforwardly be defined with:(18)RpS(O)=-ln(Pr(O|Ip))ifPS(p)≠0+∞ifPS(p)=0andH(Φ¯(p))=1(Background)0ifPS(p)=0andH(Φ¯(p))=0(Object)(19)RpS(B)=-ln(1-Pr(O|Ip))ifPS(p)≠00ifPS(p)=0andH(Φ¯(p))=1(Background)+∞ifPS(p)=0andH(Φ¯(p))=0(Object)withPr(O|Ip)a posterior probability model computed from the image gray level pixels p such asPS(p)=0andH(Φ¯(p))=0.Our shape prior is contour-based and may be added as a prior term weighting n−links. We thus propose to add a new frontier term denoted byBp,qSand defined by:(20)Bp,qS=PS(p)+PS(q)2The final energy of a cutCfor a graph integrating a shape prior is then:(21)E(C)=λ∑p,q∈NBp,q+γBp,qS.δ(ωp≠ωq)+∑p∈VRpS(ωp)where Bp,qis defined with Eq. (10), λ weights the relative contributions of the n−link and t−link terms and γ weights the frontier shape prior termBp,qSand the image frontier term Bp,q.

@&#CONCLUSIONS@&#
