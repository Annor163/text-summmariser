@&#MAIN-TITLE@&#
Symbolic execution based on language transformation

@&#HIGHLIGHTS@&#
We propose a language-independent symbolic execution framework for languages.The proposed language-independent approach is based on language transformations.We prove that the expected formal properties of symbolic execution.We present a prototype and we use it on several languages.

@&#KEYPHRASES@&#
Symbolic execution,Formal semantics,Programming languages,Program analysis,

@&#ABSTRACT@&#
We propose a language-independent symbolic execution framework for languages endowed with a formal operational semantics based on term rewriting. Starting from a given definition of a language, a new language definition is generated, with the same syntax as the original one, but whose semantical rules are transformed in order to rewrite over logical formulas denoting possibly infinite sets of program states. Then, the symbolic execution of concrete programs is, by definition, the execution of the same programs with the symbolic semantics. We prove that the symbolic execution thus defined has the properties naturally expected from it (with respect to concrete program execution). A prototype implementation of our approach was developed in theKframework. We demonstrate the tool׳s genericity by instantiating it on several languages, and illustrate it on the reachability analysis and model checking of several programs.

@&#INTRODUCTION@&#
Symbolic execution is a well-known program analysis technique introduced in 1976 by King [19]. Since then, it has proved its usefulness for testing, verifying, and debugging programs. Symbolic execution consists of executing programs with symbolic inputs, instead of concrete ones, and it involves the processing of expressions involving symbolic values [25]. The main advantage of symbolic execution is that it allows reasoning about multiple concrete executions of a program, and its main disadvantage is the state-space explosion determined by decision statements and loops. Recently, the technique has found renewed interest in the formal methods community due to new algorithmic developments and progress in decision procedures. Current applications of symbolic execution are diverse and include automated test input generation [20,38], invariant detection [24], model checking [18], and proving program correctness [37,12].The state of a symbolic program execution typically contains the next statement to be executed, symbolic values of program variables, and the path condition, which constrains past and present values of the variables (i.e., constraints on the symbolic values are accumulated on the path taken by the execution for reaching the current instruction). The states, and the transitions between them induced by the program instructions generate a symbolic execution tree. When the control flow of a program is determined by symbolic values (e.g., the next instruction to be executed is a conditional one, whose Boolean condition depends on symbolic values) then there is a branching in the tree. The path condition can then be used to distinguish between different branches.Our contribution: The main contribution of the paper is a formal, language-independent theory and tool for symbolic execution, based on a language׳s operational semantics defined by term-rewriting.11Most existing operational semantics styles (small-step, big-step, reduction with evaluation contexts, etc.) have been shown to be faithfully representable by rewriting [36].On the theoretical side, we define a transformation of languages such that the symbolic execution of programs in the source language is, by definition, the concrete execution in the transformed language. We prove that the symbolic execution thus defined has the following properties, which relate it to concrete execution in a natural way:Coverage: To every concrete execution there corresponds a feasible symbolic one;Precision: To every feasible symbolic execution there corresponds a concrete one.where two executions are said to be corresponding if they take the same path, and a symbolic execution is feasible if the path conditions along it are satisfiable. These theoretical properties have practical consequences, since they ensure that analyses based on symbolic program execution (reachability analysis, model checking, etc.) can be soundly transferred to concrete executions.On the practical side, we present the prototype implementation of our approach inK[29] (version 3.4), a framework dedicated to defining formal operational semantics of languages. AKlanguage definition is compiled into a Maude rewrite theory. Our prototype is based on several transformations which are encoded as compilation steps in theKdefinition compiler. The relationships betweenKlanguage definitions and their compilation into Maude, and between the transformedKdefinitions and their Maude encodings are investigated in [4]. In this paper we briefly describe our implementation as a language-engineering tool, and demonstrate its genericity by instantiating it on nontrivial languages defined inK.We emphasise that the tool uses theKlanguage-definitions as they are, without requiring modifications, and automatically harnesses them for symbolic execution. The examples illustrate reachability analysis, Linear Temporal Logic model checking, and bounded model checking using our tool.The proposed approach uses a generic theoretical framework, which abstracts away details from theKimplementation. In fact,Kdefinitions are particular examples of the abstract notion of language definition presented in Section 3.4.A restriction of our approach is that it requires a clear distinction between code and data. We only deal with symbolic data (e.g., integers, Booleans, etc.), but not with symbolic code. This excludes, for example, higher-order functional languages in which code can be passed as data between functions. The main goal of this work is to provide a language-independent symbolic execution framework on top of which different analysis tools can be developed (i.e., test case generators, program verification tools, etc.). This framework is intended to capture the central concepts of symbolic execution (e.g., symbolic values, path conditions, symbolic execution trees) which are completely independent of the chosen programming language. In practice, up to now, the framework has been successfully used for general purpose languages such as imperative, object-oriented, and scripting languages (as shown in Section 7.2), and for domain specific languages (e.g., OCL [3]).Related work: There is a substantial number of tools performing symbolic execution available in the literature. However, most of them have been developed for specific programming languages and are based on informal semantics. Here we mention some of them that are strongly related to our approach.Java PathFinder [26] is a complex symbolic execution tool which uses a model checker to explore different symbolic execution paths. The approach is applied to Java programs and it can handle recursive input data structures, arrays, preconditions, and multithreading. Java PathFinder can access several Satisfiability Modulo Theories (SMT) solvers and the user can also choose between multiple decision procedures. We anticipate that by instantiating our generic approach to a formal definition of Java (currently being defined in theKframework) we obtain some of Java PathFinder׳s features for free.Another approach consists in combining concrete and symbolic execution, also known as concolic execution. First, some concrete values given as input determine an execution path. When the program encounters a decision point, the paths not taken by concrete execution are explored symbolically. This type of analysis has been implemented by several tools: DART [16], CUTE [34], EXE [8], PEX [10]. We note that our approach allows mixed concrete/symbolic execution; it can be the basis for language-independent implementations of concolic execution.Symbolic execution has initially been used in automated test generation [19]. It can also be used for proving program correctness. There are several tools (e.g. Smallfoot [6,39]) which use symbolic execution together with separation logic to prove Hoare triples. There are also approaches that attempt to automatically detect invariants in programs [24,33]. Another useful application of symbolic execution is the static detection of runtime errors. The main idea is to perform symbolic execution on a program until a state is reached where an error occurs, e.g., null-pointer dereference or division by zero. We show that the implementation prototype we developed is also suitable for such static code analyses.Another body of related work is symbolic execution in term-rewriting systems. The technique called narrowing, initially used for solving equation systems in abstract datatypes, has been extended for solving reachability problems in term-rewriting systems and has successfully been applied to the analysis of security protocols [23]. Such analyses rely on powerful unification-modulo-theories algorithms [14], which work well for security protocols since there are unification algorithms modulo theories involved there (exclusive-or, …). This is not always the case for programming languages with arbitrarily complex datatypes.Rewriting modulo SMT[27] is a recently introduced technique for performing symbolic execution on rewrite theories. Their approach and ours have some common features: a built-in subtheory (for data, in our case) in which constraints are handled by SMT solving; the notion of constrained terms (in our case, Matching Logic patterns); and soundness and completeness results (in our case, precision and coverage). The main difference is that they focus on rewriting-logic specifications, whereas we focus on language definitions.The present paper is an extended version of our SLE 2013 paper [2]. It relies on a more general way of defining programming languages, consisting in using (Topmost) Matching Logic to denote sets of program states and Reachability Logic for the operational semantics of languages. The two logics are briefly introduced in the paper; for details readers can consult [30]. This results in better definitions for essential notions such as symbolic domain (the domain over which symbolic execution “computes”). The new definitions are more suitable because they faithfully capture the essence of what symbolic execution is about: computing with logical constraints denoting sets of program states. By contrast, in [2] the corresponding definitions were purely axiomatic: they required certain abstract diagrams to be commutative. The new approach also extends the range of language definitions for which symbolic execution can be defined: the previous approach [2] is now an instance of the current one. Among the extensions we mention axiomatically defined structures (sets, bags, lists, etc.), with axioms such as associativity, commutativity, unity and combinations thereof. Such structures are intensively used in real-life language definitions in theKframework (C [13], Java [7], etc.). Finally, a technical improvement is that our new definition of the symbolic transition relation does not distinguish among semantically equivalent symbolic states.Structure of the paper: Section 2 introduces our running example (the imperative language imp) and its definition inK.Section 3 introduces a framework for language definitions, making our approach generic in both the language-definition framework and the language being defined;Kand imp are just instances for the former and latter, respectively.Section 4 introduces the notion of symbolic domain, which formalises the domain in which symbolic execution takes place.Section 5 then shows how the definition of a languageLcan be transformed into the definition of a languageLsby replacing the concrete domain with the symbolic one, and by providing the semantical rules ofLwith means to operate in the new, symbolic domain. The coverage and precision results are proved.Section 6 then gives two instances of the framework introduced in the previous section. The first one is isomorphic to that presented in [2], whereas the second strictly generalises the first one by including axiomatically defined structures which, as previously mentioned, are intensively used in real-life language definitions.Section 7 describes an implementation of our approach in theKframework and shows how it is automatically instantiated to nontrivial languages defined inK. Applications to program analysis are given.Section 8 concludes and discusses future work.Our running example is imp, a simple imperative language intensively used in research papers (e.g., [31,28]). The syntax of imp is described in Fig. 1and is mostly self-explanatory since it uses a BNF notation. The statements of the language are either assignments, if statements, while loops, skip (i.e., the empty statement), or blocks of statements. The attribute strict in some production rules means the arguments of the annotated expression/statement are evaluated before the expression/statement itself. If strict is followed by a list of natural numbers then it only concerns the arguments whose positions are present in the list.The operational semantics of imp is given as a set of (possibly conditional) rewrite rules. The terms to which rules are applied are called configurations. Configurations typically contain the program to be executed, together with any additional information required for program execution. The structure of a configuration depends on the language being defined; for imp, it consists only of the program code to be executed and an environment mapping variables to values.Configurations are written inKas nested structures of cells: for imp this consists of a top cellcfg, having a subcellkcontaining the code and a subcellenvcontaining the environment (cf. Fig. 2). The code inside thekcell is represented as a list of computation tasksC1↷C2↷…to be executed in the given order. Computation tasks are typically statements and expressions. The environment in theenvcell is a multiset of bindings of identifiers to values, e.g.,a↦3,b↦1.The semantics of imp is shown in Fig. 3. Each rewrite rule from the semantics specifies how the configuration evolves when the first computation task from thekcell is executed. Dots in a cell mean that the rest of the cell remains unchanged. Most syntactical constructions require only one semantical rule. The exceptions are the conjunction operation and theifstatement, which have Boolean arguments and require two rules each (one rule per Boolean value).In addition to the rules shown in Fig. 3 the semantics of imp includes additional rules induced by the strict attribute. We show only the case of theifstatement, which is strict in the first argument. The evaluation of this argument is achieved by executing the following rules:Here, BE ranges over Boolean expressions, B ranges over the Boolean values{false,true}, and □ is a special variable, destined to receive the value of BE once it is computed, typically, by the other rules in the semantics.Creating a language-independent symbolic execution framework requires specifications of programming languages, which, for each language, define the meanings of the programs in that language. The idea behind our approach is to pass such specifications as parameters to our symbolic execution framework.This section presents some background used in the rest of the paper. We start by giving a brief description of the basics of algebraic specifications, of many-sorted First Order Logic (fol), and of Matching Logic (ml) [30], together with the notation and conventions that we are going to use throughout the paper. Then, we present the general notion of language definition using Matching Logic and Reachability Logic (rl) [30]. The syntax of programming languages and the data types used in their semantics are given using algebraic specifications, while their semantics is given using rl.In this section we briefly introduce some basic definitions and notations regarding algebraic specifications that we use in the paper.The use of algebraic specifications to model computer programs is motivated by the fact that they can manipulate several kinds of sorts of data, in the same way as programs do. For instance, the name Int is a sort and it is part of the syntax. The syntax is called signature, and it consists of a set of sorts. Formally, given S a set of sorts, an S-sorted signatureΣis anS⁎×S-indexedfamily of sets{Σw,s∣w∈S⁎,s∈S}whose elements are called operation symbols. IfS′⊆S, anS′-sortedsignatureΣ′is a subsignature of an S-sorted signatureΣifΣ′⊆ΣasS⁎×S-indexedsets.The BNF syntax of imp (Fig. 1) has a correspondingSimp-sortedsignatureΣimp. Nonterminals in the grammar (e.g. Int, Bool, AExp, etc.) are sorts inSimp, while each grammar production has a corresponding operation symbol inΣimp. For instance, the productionAExp::=AExp+AExphas a corresponding operation symbol_+_:AExp×AExp→AExphaving two arguments of sort AExp and result of sort AExp. An operational symbols without arguments is called constant; e.g., true and false are constants of sort Bool.The meaning of algebraic signaturesΣis given by Σ-algebras, called also Σ-models. A Σ-algebra M consists of an S-indexed set (also denoted M), i.e., a carrier set Msfor each sorts∈S; an elementMc∈Msinterpreting each constant symbol c as an actual element; and a functionMf:Ms1×⋯×Msn→Msinterpreting each operation symbol f as a function. The interpretation of a constant can be seen as a particular (constant) function.An example of Σ-algebra M for imp, used in this paper, interprets the sort Int by the setMIntof integers, the sort Bool by the set of BooleansMBool={false,true}, and the other nonterminals by their corresponding syntactical categories, e.g.MAExpis the set of arithmetical expressions. M also interprets all operation symbols by functions, i.e. the symbol_+Int_is interpreted by a functionM_+Int_:MInt×MInt→MIntwhich is the addition over integers, and_+_is interpreted by a functionM_+_:MAExp×MAExp→MAExpwhich is the expression constructor.Let Var be an S-indexed set of variables. The S-indexed setTΣ(Var)={TΣ,s(Var)∣s∈S}of Σ-terms t is defined byt::=c∣x∣f(t,…,t),where c is a constant,x∈Var, and f is an operation symbol with n arguments. The term Σ-algebraTΣ(Var)has Σ-termsTΣ(Var)as carrier sets and interprets each constant symbol c by itself and each operation symbolf:s1…sn→sby the term constructor functionTs1×⋯×Tsn→Tsthat maps(t1,…,tn)into the termf(t1,…,tn). If Var is ∅, thenTΣ(∅)is the algebra of ground terms (terms without variables), which we denote it byTΣ.Examples ofΣterms are_+_(2,3), and_⁎_(_+_(2,3),x), wherex∈VarAExp. We often use the mixfix notation for terms, e.g. the above ones are written as2 + 3, respectively,(2 + 3)⁎x.A valuation ρ is a functionρ:Var→Mthat maps variables to values from a Σ-model M. A substitution is a mappingσ:X→TΣ(Var)for someX⊆Var. We often denote by σ (resp. ρ) the homomorphic extension of the substitution σ (resp. the valuation ρ) to terms. The composition of substitutions, and of a valuation and a substitution, is denoted by ○ and coincides with the standard notion of function composition. The restriction of a valuationρ:Var→Mto a subsetX⊆Varis denoted byρ|Xand coincides with the standard notion of function restriction. Note that if M is the algebra of terms, thenρ|Xis a substitution. Domains and ranges of functions are denoted as usual, i.e., forf:A→Bwe havedom(f)=A,ran(f)=B. A congruence ≅(over terms) is an equivalence relation, which is compatible with the operations, i.e., for every operation f with n arguments, and argumentst1,…,tn,t1′,…,tn′, ifti≅ti′for all i, thenf(t1,…,tn)≅f(t1′,…,tn′).Given a set S of sorts, an S-sorted first order signature Φ is a pair(Σ,Π), whereΣis an algebraic S-sorted signature andΠis an indexed set of the form{Πw∣w∈S⁎}whose elements are called predicate symbols, wherep∈Πwis said to have arity w. A Φ-model consists of a Σ-algebra M together with a subsetMp⊆Ms1×⋯×Msnfor each predicatep∈Πw, wherew=s1…sn. For instance, we may define<Intas a predicate symbol inΠInt,Intinterpreted by the set of integer pairs (a, b) with a less than b (i.e.,a<Intb).We now define the syntax of fol formulas over a first order signatureΦ=(Σ,Π)and a possibly infinite set of variables Var. Given a fol signatureΦ=(Σ,Π), the set of Φ-formulas is defined byϕ::=⊤∣p(t1,…,tn)∣¬ϕ∣ϕ∧ϕ∣(∃V)ϕwhere p ranges over predicate symbolsΠ, each tiranges overTΣ(Var)of appropriate sort, and V over finite subsets of Var.Given a first order Φ-model M, a Φ-formula ϕ, V a set of S-sorted variables, and a valuationρ:Var→M, the satisfaction relationρ⊨ϕis defined as follows:1.ρ⊨⊤;ρ⊨p(t1,…,tn)iff(ρ(t1),…,ρ(tn))∈Mp;ρ⊨¬ϕiffρ⊨ϕdoes not hold;ρ⊨ϕ1∧ϕ2iffρ⊨ϕ1andρ⊨ϕ2;ρ⊨(∃V)ϕiff there isρ′:Var→Mwithρ′(x)=ρ(x)for allx∉V, such thatρ′⊨ϕ.Let(Σd,Πd)be a subsignature of(Σ,Π)and M be a(Σ,Π)-model. ThenM↾(Σd,Πd)is the(Σd,Πd)-modelMddefined as follows:•Msd=Msfor eachΣd-sort;Mfd=Mffor each functional symbol f inΣd;Mpd=Mpfor each predicate symbol p inΠd.We recall from [30] the (topmost) ml and rl concepts and results used in this paper. First, we present the definition of ml formulas and the corresponding satisfaction relation, and then, the definition of rl formulas and the transition system generated by a set of rl formulas.Definition 1ml formulaAn mlsignatureΦ=(Σ,Π,Cfg)is a first-order signature(Σ,Π)together with a distinguished sort Cfg for states. The set of ml-formulas over Φ is defined byφ::=π∣⊤∣p(t1,…,tn)∣¬φ∣φ∧φ∣(∃V)φwhere the basic pattern π ranges overTΣ,Cfg(Var), p ranges over predicate symbolsΠ, each tiranges overTΣ(Var)of appropriate sorts, and V over finite subsets of Var. The sort Cfg is intended to model program states. We often call the ml formulas patterns.The free occurrences of variables in ml formulas is defined as usual (i.e., like in fol) and we letvar(φ)denote the set of variables freely occurring in φ.Example 1Letφ≜(∃Z)〈〈x=y;skip〉k〈x↦Xy↦Y〉env〉cfg∧(X≤Z∧Z<Y). We havevar(φ)={X,Y}. Program variablesx,yshould not be confused with logical variables X, Y; program variables are constants of sort Id.Excepting the basic patterns, the semantics of ml formulas is similar to that of fol ones:Definition 2ml satisfaction relationGivenΦ=(Σ,Π,Cfg)an ml signature, M a(Σ,Π)-model, φ an ml formula,γ∈MCfga state, V a (S-sorted) set of variables, andρ:Var→Ma valuation, the satisfaction relation(γ,ρ)⊨φis defined as follows:1.(γ,ρ)⊨πiffρ(π)=γ;(γ,ρ)⊨⊤;(γ,ρ)⊨p(t1,…,tn)iffvar(t1,…,tn)⊆Xand(ρ(t1),…,ρ(tn))∈Mp;(γ,ρ)⊨¬φiff(γ,ρ)⊨φdoes not hold;(γ,ρ)⊨φ1∧φ2iff(γ,ρ)⊨φ1and(γ,ρ)⊨φ2; andρ⊨(∃V)ϕiff there isρ′:Var→Mwithρ′(x)=ρ(x), for allx∉V, such thatρ′⊨ϕ.The denotational semantics of an ml formula consists of all concrete configurations that match it:Definition 3Let φ be an ml formula. Then〚φ〛denotes the set of configurations{γ∣(∃ρ)(γ,ρ)⊨φ}.Letφ≜〈〈x=y;skip〉k〈x↦Xy↦Y〉env〉cfg∧(X≥0∧Y≤X)andγ≜〈〈x=y;skip〉k〈x↦7y↦3〉env〉cfg. Thenγ∈〚φ〛, since there exists ρ, withρ(X)=7andρ(Y)=3, such that(γ,ρ)⊨φ.We now recall the definition of rl formulas, which are pairs of ml formulas, and of the transition system induced by a set of rl formulas. We consider a fixed ml signatureΦ=(Σ,Π,Cfg), a set of variables Var, and a fixed Φ-model M.Definition 4rl formula, rl systemAn rl formula is a pairφφ′of ml formulas. An rlsystem is a setSof rl formulas. The transition system defined bySover M is(MCfg,⇒S), where⇒S={(γ,γ′)∣(∃φφ′∈S)(∃ρ)(γ,ρ)⊨φ∧(γ′,ρ)⊨φ′}. We writeγ⇒Sγ′for(γ,γ′)∈⇒S.Letφ≜〈〈x=y;skip〉k〈x↦Xy↦Y〉env〉cfg∧(X≥0∧Y≤X),φ′≜〈〈skip〉k〈x↦Yy↦Y〉env〉cfg∧(X≥0∧Y≤X), and assumeφφ′∈S. Letγ≜〈〈x=y;skip〉k〈x↦7y↦3〉env〉cfgandγ′≜〈skip〉cfg〈x↦3y↦3〉env. Then,(γ,γ′)∈⇒S, using the same valuation ρ as in Example 2.In this section we present the abstract notion of language definition used in the rest of the paper.Klanguage definitions are particular examples of that. In a nutshell, a language definition consists of an ml signature Φ (including the syntax of the language and the configuration), a model for Φ, and a set of rl formulas for the semantics.Definition 5A language definition is a tupleL=((Σ,Π,Cfg),M,S)where:•(Σ,Π,Cfg)is a ML signature,M is a model of(Σ,Π,Cfg),Sis a finite set of RL formulas, of the formπ1∧ϕ1π2∧ϕ2, where the ml formulasπ1∧ϕ1,π2∧ϕ2are over the signature(Σ,Π,Cfg).We emphasise that the model M is part of a language definition. It may includes operations over primitive data types as integers and Booleans, and data structures and their operations used to represent semantical ingredients.In the following, we assume a (strict) subsignature(Σd,Πd)of(Σ,Π)for the language׳s data types (integers, lists, etc.) and a(Σd,Πd)-modelDsuch that M restricted to(Σd,Πd)equalsD, i.e.,M↾(Σd,Πd)=D. The sort Cfg is not a data sort. We sometimes call language definitions languages for simplicity. A language definitionLinduces a transition system(MCfg,⇒S), where⇒Sis given by Definition 4. The next example illustrates all these concepts on imp.Example 4In the case of imp, nonterminals in the syntax (Id, Int, Bool, etc.) are sorts inΣ. Each production from the syntax defines an operation inΣ; e.g, the productionAExp::=AExp+AExpdefines the operation_+_:AExp×AExp→AExp. These operations define the constructors of the result sort. For the sort Cfg, the only constructor is〈〈_〉k〈_〉env〉cfg:Code×MapId,Int→Cfg. The expression〈〈X=I↷C〉k〈X↦0Env〉env〉cfgis a term ofTCfg(Var), where X is a variable of sort Id, I is a variable of sort Int, C is a variable of sort Code (the rest of the computation), andEnvis a variable of sortMapId,Int(the rest of the environment). The data algebraDinterprets Int as the set of integers, the operations like+Int(cf. Fig. 3) as the corresponding usual operation on integers, Bool as the set of Boolean values{false,true}, the operation like ∧ as the usual Boolean operations, the sortMapId,Intas the multiset of mapsX↦I, where X ranges over identifiers Id and I over the integers Int. The value of an identifier X in an environment E is obtained by callinglookup(X,E), and it is updated by callingupdate(X,E,I). Here,lookup()andupdate()are operations inΣd. The other sorts, AExp, BExp, Stmt, and Code, are interpreted in the algebra M as ground terms over the signatureΣ, in which data subterms are replaced by their interpretations inD. For instance, the termif1>Int0thenskipelseskipof sort Stmt is interpreted asifDtruethenskipelseskip.This section is dedicated to defining the symbolic domain, in which symbolic execution takes place. Intuitively, symbolic execution deals with (possibly infinite) sets of concrete configurations, denoted by ml formulas. Since (possibly, infinitely) many ml formulas may denote the same set of concrete configurations, we shall be working with the following equivalence relation on ml formulas:Definition 6Equivalence relation on ml formulasLet φ andφ′be two ml formulas. Thenφ~φ′iff〚φ〛=〚φ′〛.Note thatφ~φ′does not imply, in general,M⊨φ↔φ′. For instance, consider patternsφ≜〈〈x=A+Int1〉k〈〈x↦B+Int5〉env〉cfg∧A<IntBandφ′≜〈〈x=A′〉k〈x↦B′〉env〉cfg∧(A′=IntA+Int1∧B′=IntB+Int5∧A<IntB). We can easily observe thatφ~φ′. However,M⊭φ↔φ′: ifγ≜〈〈x=3〉k〈x↦8〉env〉cfgandρ(A)=2,ρ(B)=3, then(γ,ρ)⊨φbut(γ,ρ)⊭φ′becauseρ(A′)can be different from 3 and/orρ(B′)can be different from 8.For symbolic execution we shall be needing to unify equivalence classes. This notion of unifier builds upon a standard notion of unification for terms. Hereafter we consider a given congruence relation≅onTΣ(Var).Definition 7Unifier modulo congruenceA≅-unifierof two termst1,t2is a substitutionσ:var(t1,t2)→TΣ(Var)such thatσ(t1)≅σ(t2).A set of≅-unifiersfor two terms is complete if every valuation that equates the two terms is an instance of at least one substitution in the set, and a≅-unificationalgorithm computes complete sets of≅-unifiersfor its inputs:Definition 8Complete set of unifiersA set S of≅-unifiersof two termst1,t2is complete if for each valuationρ:Var→Msuch thatρ(t1)=ρ(t2), there existσ∈Sandη:Var→Msuch thatρ|dom(σ)=η○σ.The existence of unification algorithms is essential in the definition of the symbolic execution:Definition 9A ≅-unification algorithm is a function that takes two terms and returns a finite (possibly empty) and complete set of≅-unifiersfor the terms.Since the unification modulo a congruence is undecidable in general, we work under the following assumption:Assumption 1We assume a congruence≅onTΣ(Var)such that for allt1,t2∈TΣ(Var), ift1≅t2thenρ(t1)=ρ(t2)for all valuations ρ.We also assume a≅-unificationalgorithm, hereafter denoted byunif≅(_,_).Unification is now extended to equivalence classes of ml formulas of the formφ≜π∧ϕ,φ′≜π′∧ϕ′. The extension consists in considering ml formulas(∃X)π˜∧ϕ˜and(∃X′)π˜′∧ϕ˜′that are ml-equivalent to φ andφ′, respectively, such thatunif≅(π˜,π˜′)is nonempty; and to define symbolic unifiers as follows:Definition 10Unification on equivalence classesAn abstraction of the patternπ∧ϕis a pattern(∃X)π˜∧ϕ˜with the property thatM⊨π∧ϕ↔(∃X)π˜∧ϕ˜. Given abstractionsφ˜≜(∃X)π˜∧ϕ˜andφ˜′≜(∃X)π′˜∧ϕ′˜of φ andφ′, respectively, a symbolic unifier of the equivalence classes[φ]~,[φ′]~is the fol formula(∃X∪X′∪var(ran(σ)))ϕσ∧ϕ˜∧ϕ˜′whereσ∈unif≅(π˜,π˜′)andϕσdenotes the fol formula⋀x∈dom(σ)(x=σ(x)).The set of symbolic unifiers of[φ]~and[φ′]~is denoted byunif([φ]~,[φ′]~).Unlike unifiers of terms, which are substitutions σ, unifiers of equivalence classes are fol formulas that haveϕσas a subformula. Intuitively,ϕσplays for equivalence classes of ml formulas the role that σ plays for terms. The following sequence of implications/equivalences formalises this observation:σ(π)≅σ(π′)⟶σ(π)~σ(π′)⟺π∧ϕσ~π′∧ϕσ⟶π∧ϕσ∧ϕ˜∧ϕ˜′~π′∧ϕσ∧ϕ˜∧ϕ˜′Example 5Consider the following patterns:π∧ϕ=〈〈I+3〉k〈M〉env〉cfg∧I>Int0,π˜∧ϕ˜=〈〈I+J〉k〈M〉env〉cfg∧(I>Int0∧J=Int3).ThenM⊨π∧ϕ↔(∃J)π˜∧ϕ˜, where M is the model for imp (cf. Example 4). Consider alsoπ′∧ϕ′≜〈〈(A+IntA)+(B+Int1)〉k〈M〉env〉cfg∧A>Int0,π˜′∧ϕ˜′≜〈〈A′+B′〉k〈M〉env〉cfg∧(A′=IntA+IntA∧A>Int0∧B′=IntB+Int1).For≅being the syntactical equality, we haveunif≅(π,π′)=∅butunif≅(π˜,π˜′)≠∅. In particular,σ={I↦A′,J↦B′}∈unif≅(π˜,π˜′)and a symbolic unifierψ∈unif([π∧ϕ]~,[π′∧ϕ′]~)is(I=IntA′∧J=IntB′)∧(I>Int0∧J=Int3)∧(A′=IntA+IntA∧A>Int0∧B′=IntB+Int1).Example 5 emphasises the role of pattern-abstractions for overcoming some problems raised by unification. During symbolic execution, programs may generate expressions such asB+Int1in the example. These are problematic for the unification process (and ultimately, for the symbolic execution itself), because expressions cannot be unified – only variables can. An abstraction(∃X)π˜∧ϕ˜ofπ∧ϕis meant to deal with this issue. For instance,(∃X)π˜∧ϕ˜can be obtained fromπ∧ϕby linearising the basic pattern π, replacing the non-data subterms with variables from X, and then adding the equalities between variables in X and the corresponding subterms toϕ˜[2,27]. This is exactly what happened in the above example. This issue is discussed further in Section 6.We now define the notion of unifiability by a valuation ρ, both for patterns and for equivalence classes.Definition 11Concrete and symbolic ρ-unifiabilityLetρ:Var→Mbe a valuation. Two formulasπ∧ϕ,π′∧ϕ′are said to be concretely ρ-unifiable if there is γ such that(γ,ρ)⊨(π∧ϕ)∧(π′∧ϕ′). Two equivalence classes[π∧ϕ]~,[π′∧ϕ′]~are said to be symbolically ρ-unifiable ifρ⊨ψfor someψ∈unif([π∧ϕ]~,[π′∧ϕ′]~).Letπ∧ϕ≜〈〈X=0〉k〈M〉env〉cfgandπ′∧ϕ′≜〈〈n=A〉k〈M′〉env〉cfg. If we consider a valuation ρ, such thatρ(X)=n,ρ(A)=0, andρ(M)=ρ(M′), thenπ∧ϕandπ′∧ϕ′are ρ-unifiable. Next, let(∃I)〈〈X=I〉k〈M〉env〉cfg∧I=Int0be an abstraction ofπ∧ϕand(∃Y)〈〈Y=A〉k〈M′〉env〉cfg∧Y=Idnbe an abstraction ofπ′∧ϕ′. Ifσ(X)=σ(Y)=U,σ(A)=σ(I)=V, thenρ⊨(∃I,Y,U,V)ϕσbecause there existsρ′, defined byρ′(I)=ρ′(V)=0,ρ′(Y)=ρ′(U)=n,ρ′(X)=ρ(X), andρ′(A)=ρ(A)such thatρ′⊨ϕσ≜X=U∧Y=U∧I=0∧V=0. Also,ψ≜(∃I,Y,U,V)∧I=Int0∧Y=Idn∧ϕσis a symbolic unifier of[π∧ϕ]~,[π′∧ϕ′]~.The following assumption relates concrete and symbolic unifiability. Since concrete unifiability concerns the concrete model M and symbolic unifiability concerns the chosen symbolic modelMs, the assumption restricts the way M is related toMs. We will see in Section 6 actual examples of pairs of concrete and symbolic models satisfying this assumption.Assumption 2CompletenessFor all concretely ρ-unifiable patternsπ∧ϕandπ′∧ϕ′, the classes[π∧ϕ]~and[π′∧ϕ′]~are symbolically ρ-unifiable.In this section we show how a new definition((Σs,Πs),Ms,Ss)of a languageLsis automatically generated from a given definition(Σ,M,S)of a languageL. The new languageLshas the same syntax asL, but its modelMsis the symbolic model defined in the previous section, and its semantical rulesSsadapts the semantical rulesSto deal with the new domain. Then, the symbolic execution ofL-programsis defined to be the concrete execution of the correspondingLs-programs. Building the definition ofLsamounts to:1.extending the signature(Σ,Π)to a symbolic signature(Σs,Πs);extending the(Σ,Π)-modelM to a(Σs,Πs)-modelMs;turning the concrete rulesSinto symbolic rulesSs.Σscontains two new sorts:Cfgsand Bool. The operations of sort Bool include the usual propositional items(⊤,∧,¬), the existential quantifier, as well as an operationp:s1…sn→Boolfor each predicatep∈Πs1,…,sn. The unique operation of sortCfgsis its constructor_∧_:Cfg×Bool→Cfgs. The sortCfgsis used to represent ml formulasπ∧ϕas terms. We naturally identifyΣs-termsof the sort Bool with the corresponding FOL(Σ,Π)-formulas.Πsconsist of one predicatesat, which takes one argument of sort Bool.For the sake of presentation, for the imp example we assume that the new sort Bool extends the existing one with the new operations.The notation〚_〛is extended to arbitrary terms:〚t〛≜{ρ(t)∣ρavaluation}. Then, the definition of the equivalence ~ is extended over arbitrary terms:t~t′iff〚t〛=〚t′〛.Msinterprets the elements ofΣsandΠsas follows:1.sorts s inΣare interpreted as~-equivalenceclasses of terms inTΣ(D),s(Vard), whereVard⊊Varis the (strict) subset of variables having data sorts, and the signatureΣ(D)is the extension of the signatureΣin which elements of the data domainDare declared as constants of the respective sorts;the sortCfgsis interpreted as~-equivalenceclasses of terms of sortCfgs, of the form[π∧ϕ]~, whereπ∈TΣ(D),Cfg(Vard)andϕ∈TΣs(D),Bool(Vard);operations inΣsare interpreted syntactically, i.e. as term constructors;the (unique) predicatesat∈Πsis interpreted as the theoretical satisfiability predicate for fol formulas.IfI∈Vard, thenMsinterpretsI+Int3as the equivalence class[I+Int3]~. For instance,1+IntI+Int2∈[I+Int3]~. IfB∈Vard, then the symbolic configuration〈ifBthenx=1;elsex=0;〉k〈x↦7〉env∧B=Booltrueis interpreted as[π∧ϕ]~, whereπ≜〈ifBthenx=1;elsex=0;〉k〈x↦7〉env∈TΣ(D),Cfg(Vard)andϕ≜B=Booltrue∈TΣs(D),Bool(Vard).For instance,〈ifI<Int8thenx=1;elsex=0;〉k〈x↦I+Int1〉env∧I=Int6∈[π∧ϕ]~.The setSsconsists of a ruleπ˜1∧ξπ2∧ϕ2∧ϕ˜1∧ξfor each ruleπ1∧ϕ1π2∧ϕ2∈Sand each abstraction(∃X)π˜1∧ϕ˜1ofπ1∧ϕ1(cf. Definition 10). Note that both the left-hand side and the right-hand side of the above rule are terms of sortsCfgs.If one is interested only in feasible executions, then the rules inSswill be of the form(π˜1∧ξ)∧sat(ϕ2∧ϕ˜1∧ξ)π2∧ϕ2∧ϕ˜1∧ξNow, the left-hand side of the rule is an ml formula, wheresat(ϕ2∧ϕ˜1∧ξ)is the condition.We shall see later in this section that for practical cases it is enough to consider only one abstraction for each left-hand side of a rule inS, and hence we obtain a one-to-one correspondence betweenSandSs.Example 8Letπ1∧ϕ1π2∧ϕ2∈Sbe〈〈iftruethenS1elseS2〉k〈E〉env〉cfg〈〈S1〉k〈E〉env〉cfgand consider the abstraction(∃X)π˜1∧ϕ˜1ofπ1∧ϕ1:(∃B)〈〈ifBthenS1elseS2〉k〈E〉env〉cfg∧(B=Booltrue).Then, the corresponding rule inSsis〈〈ifBthenS1elseS2〉k〈E〉env〉cfg∧ξ〈S1〉k〈E〉env∧(B=Booltrue)∧ξTo obtain only feasible executions we use of the satisfiability predicate:〈〈ifBthenS1elseS2〉k〈E〉env〉cfg∧ξ∧sat((B=Booltrue)∧ξ)〈〈S1〉k〈E〉env〉cfg∧(B=Booltrue)∧ξIn this section we prove the Coverage and Precision results that relate⇒SsMs(defined byLs) with⇒SM(defined byL). Since we defined the symbolic transition based on unification, and the semantics of programming languages is based on rewriting, we have, in general, only a weaker coverage result. However, if the unification can be achieved by matching, as is the case in practically relevant cases discussed in Section 6, then we have the expected coverage result as stated in the Introduction (Section 1): to every concrete execution there corresponds a feasible symbolic one.Assumption 3Hereafter, whenever a ruleπ1∧ϕ1π2∧ϕ2is applied to a patternπ∧ϕwith a unifier σ, we assume, w.l.o.g., that the variable names are chosen s.t.var(π1,ϕ1,π2,ϕ2)∩var(π,ϕ)=∅, and the unifier σ is chosen s.t.var(ran(σ))∩var(π2,ϕ2)=∅. This is assumed for the symbolic rules as well.Letσ:X→TΣ(Var). Then for allt∈TΣ(X)and all valuationsρ:Var→M, ifρ⊨ϕσthenρ(σ(t))=ρ(t).By structural induction on t.If t is a variable thent∈Xand fromρ⊨ϕσ(≜⋀x∈Xx=σ(x))we obtainρ(t)=ρ(σ(t)), which proves the base step.Assume thatt=f(t1,…,tn)withn≥0andti∈TΣ(X)fori=1,…,n. From the induction hypothesis we know thatρ(ti)=ρ(σ(ti))for alli=1,…,n. Thus,ρ(t)=f(ρ(t1),…,ρ(tn))=f(ρ(σ(t1)),…,ρ(σ(tn)))=f((ρ○σ)(t1),…,(ρ○σ)(tn))=(ρ○σ)(f(t1,…,tn))=ρ(σ(f(t1,…,tn))), which proves the inductive step and the lemma.□Letσ:X→MΣ(Var)be such thatX∩var(ran(σ))=∅. Then for allfolformulas ϕ and all valuations ρ, ifρ⊨ϕσthen (ρ⊨σ(ϕ)iffρ⊨ϕ).We proceed by structural induction on ϕ. The base case (ϕ=⊤) is trivial, so we only focus on the remaining cases:(1)ϕ isp(t1,…,tn)withp∈Π. Thenρ⊨σ(ϕ)⟺ρ⊨p(σ(t1),…,σ(tn))⟺(ρ(σ(t1)),…,ρ(σ(tn)))∈Mp⟺(ρ(t1),…,ρ(tn))∈Mp(byLemma1)⟺ρ⊨p(t1,…,tn)⟺ρ⊨ϕ.ϕ is¬ϕ1. Thenρ⊨σ(ϕ)⟺ρ⊭σ(ϕ1)⟺ρ⊭ϕ1(bytheinductionhypothesis)⟺ρ⊨¬ϕ1⟺ρ⊨ϕ.ϕ isϕ1∧ϕ2. The proof is similar to that of case (2), using (ρ⊨σ(ϕ1)iff ρ⊨ϕ1) and (ρ⊨σ(ϕ2)iff ρ⊨ϕ2) as inductive hypotheses.ϕ is(∃Y)ϕ1. We may assume w.l.o.g. thatY∩(X∪var(ran(σ)))=∅. We haveσ(ϕ)=(∃Y)σ(ϕ1). Thenρ⊨σ(ϕ)⟺(∃ρ′)ρ′⊨σ(ϕ1)⟺(∃ρ′)ρ′⊨ϕ1(bytheinductionhypothesis)⟺ρ⊨ϕ.whereρ′satisfiesρ′(x)=ρ(x)for allx∉Y, which impliesρ(σ(x))=ρ(x)by the hypotheses of the lemma andY∩(X∪var(ran(σ)))=∅.□Lemmas 3 and 4 are essential for proving our weak coverage result.Lemma 3Ifσ:X→TΣ(Var)such thatX∩var(ran(σ))=∅andvar(π∧ϕ)⊆X, thenσ(π∧ϕ)~π∧ϕ∧ϕσ.By Definition 6 of the ~ relation, we have to prove that〚σ(π∧ϕ)〛=〚π∧ϕ∧ϕσ〛. We distinguish two cases:⊆. Assumeγ∈〚σ(π∧ϕ)〛. Then there exists ρ such thatγ=ρ(σ(π))andρ⊨σ(π). Letρ′denote the valuation given byρ′(x)=ρ(σ(x)), ifx∈X, andρ′(x)=ρ(x), ifx∉X. We obviously haveρ′(π)=ρ(σ(π))=γ. SinceX∩var(ran(σ))=∅andvar(π∧ϕ)⊆X, we obtainX∩var(σ(ϕ))=∅, which impliesρ⊨σ(ϕ)iffρ′⊨σ(ϕ). We obtain that(γ,ρ′)⊨π∧ϕ. We also haveρ′(x)=ρ(σ(x))=ρ′(σ(x))for allx∈Xthanks again toX∩var(ran(σ))=∅and to the definition ofρ′, which impliesρ′⊨ϕσ. We may conclude now thatγ∈〚π∧ϕ∧ϕσ〛. Since γ was arbitrarily chosen, we obtain〚σ(π∧ϕ)〛⊆〚π∧ϕ∧ϕσ〛.⊇. Assumeγ∈〚π∧ϕ∧ϕσ〛. Then there exists ρ such thatγ=ρ(π)andρ⊨ϕandρ⊨ϕσ. We obtainρ⊨σ(ϕ)by Lemma 2 andρ(π)=ρ(σ(π))by Lemma 1. Henceγ∈〚σ(π∧ϕ)〛. Since γ was arbitrarily chosen, we obtain〚π∧ϕ∧ϕσ〛⊆〚σ(π∧ϕ)〛.□Let(∃X)π˜∧ϕ˜be an abstraction of the patternπ∧ϕ. Thenπ∧ϕ~(∃X)π˜∧ϕ˜.We have to prove that〚π∧ϕ〛=〚π˜∧ϕ˜〛. Let σ be the substitution such thatϕ˜isϕ∧ϕσ. Then:γ∈〚π∧ϕ〛⟺(∃ρ)(γ,ρ)⊨π∧ϕ⟺(∃ρ′)(γ,ρ′)⊨π˜∧ϕ˜whereρ′(x)=ρ(σ(x))for eachx∈X(=dom(σ)) andρ′(x)=ρ(x)otherwise. We obviously haveρ′(π˜)=ρ(σ(π˜))=ρ(π)=γ. SinceX∩var(ran(σ))=∅we obtainρ′(σ(x))=ρ(σ(x))for allx∈X, which impliesρ′⊨ϕσ.□The next theorem says that every concrete transitionγ⇒Sγ′such thatγ∈〚π∧ϕ〛is simulated by a symbolic transition step. We call the result “weak” because in the symbolic transition step does not start exactly in[π∧ϕ]~, but in a subset of it.Theorem 5One-step Weak CoverageIfγ⇒Sγ′andγ∈〚π∧ϕ〛, then there exist afolformulaϕσand a patternπ′∧ϕ′such thatγ∈〚π∧ϕ∧ϕσ〛,[π∧ϕ∧ϕσ]~⇒SsMs[π′∧ϕ′]~andγ′∈〚π′∧ϕ′〛.Assume thatγ⇒Sγ′. There existπ1∧ϕ1π2∧ϕ2∈Sand a valuation ρ such that(γ,ρ)⊨π1∧ϕ1and(γ′,ρ)⊨π2∧ϕ2by the definition of⇒S. Fromγ∈〚π∧ϕ〛we obtain a valuationρ′such that(γ,ρ′)⊨π∧ϕ. Assumption 3 allows us to takeρ=ρ′since the two valuations affect disjoint sets of variables. Thus,(γ,ρ)⊨π1∧ϕ1and(γ,ρ)⊨π∧ϕ, meaning that andπ∧ϕare concretely ρ-unifiable. By Assumption 2, there isψ∈unif([π1∧ϕ1]~,[π∧ϕ]~)such thatρ⊨ψ. We assume thatψ≜(∃X1∪X∪var(ran(σ)))ϕ˜1∧ϕ˜∧ϕσ, whereM⊨π1∧ϕ1↔(∃X1)π˜1∧ϕ˜2andM⊨π∧ϕ↔(∃X)π˜∧ϕ˜.We haveπ˜1∧ξπ2∧ϕ2∧ϕ˜1∧ξ∈Ssby the definition ofSs. Letρs:Var→Msbe the symbolic valuation such thatρs(x)=[σ(x)]~, for allx∈dom(σ), andρs(ξ)=ϕ˜, andρs(x)=[x]~otherwise. We haveρs(π˜1∧ξ)=[σ(π˜1)∧ϕ˜]~(bythedef.ofρs)=[σ(π˜)∧ϕ˜]~(σisa≅−unifier)=[π˜∧ϕ˜∧ϕσ]~(Lemma3)=[π∧ϕ∧ϕσ]~(π∧ϕ~π˜∧ϕ˜(usingLemma4))andρs(π2∧ϕ2∧ϕ˜1∧ξ)=[σ(π2∧ϕ2∧ϕ˜1)∧ϕ]~(bythedef.ofρs)=[π2∧ϕ2∧ϕ˜1∧ϕσ∧ϕ]~(usingLemma3)The above equalities imply[π∧ϕ∧ϕσ]~⇒SsMs[π2∧ϕ2∧ϕ˜1∧ϕσ∧ϕ]~, so we can takeπ′≜π2andϕ′≜ϕ2∧ϕ˜1∧ϕσ∧ϕ. It remains to prove thatγ∈〚π∧ϕ∧ϕσ〛andγ′∈〚π2∧ϕ2∧ϕ˜1∧ϕσ∧ϕ〛. Sinceρ⊨ψand ψ is existentially quantified, it follows that there isρ′such thatρ′⊨ϕ˜1,ρ′⊨ϕσ, andρ′(x)=ρ(x)for allx∉X1∪X∪var(ran(σ)). We may choose X, X1, and σ such thatvar(π2,ϕ2,ϕ)∩(X1∪X∪var(ran(σ)))=∅. From(γ′,ρ)⊨π2∧ϕ2,ρ⊨ϕ, and the definition ofρ′we obtain(γ′,ρ′)⊨π2∧ϕ2andρ′⊨ϕ, which imply(γ′,ρ′)⊨π2∧ϕ2∧ϕ˜1∧ϕσ∧ϕ. Henceγ′∈〚π2∧ϕ2∧ϕ˜1∧ϕσ∧ϕ〛. We obtain(γ,ρ′)⊨π∧ϕ∧ϕσin a similar way, which impliesγ∈〚π∧ϕ∧ϕσ〛, which finishes the proof.□Recall the semantic rule for the and operator, from the semantics of imp (Fig. 3). The rule can be written as below:π1∧ϕ1π2∧ϕ2≜〈〈trueandB↷C〉k〈M〉env〉cfg∧⊤〈〈B↷C〉k〈M〉env〉cfg∧⊤.Letπ∧ϕ≜〈〈B1andI<Int0↷C′〉k〈M〉env〉cfg∧⊤, and ρ be a valuation which satisfiesρ(B1)=true,ρ(I)=2,ρ(B)=false,ρ(C)=ρ(C′). Thenπ1∧ϕ1andπ∧ϕare concretely ρ-unifiable andγ⇒Sγ′, whereγ=ρ(π1)=ρ(π)andγ′=ρ(π2). We assume thatπ˜1∧ϕ˜1isπ1∧ϕ1. Then the substitution σ given byσ(B1)=true,σ(B)=I<Int0,σ(I)=2,σ(C)=σ(C′)=C″is a unifier ofπ˜1and π, whereϕσisB1=Booltrue∧B=BoolI<Int0∧I=Int2∧C=C″∧C′=C″,andρ⊨(∃C″)ϕσ. Since ϕ,ϕ˜, ϕ1, and ϕ2 are all equal to⊤, we haveπ∧ϕσ⇒SsMsπ2∧ϕσ, i.e. (we replacedC=C″∧C′=C″byC=C′for the sake of presentation):The “One-step Weak Coverage” property stated by Theorem 5 can be transformed into “One-step Coverage”, i.e., the symbolic step covering the concrete one starts exactly from the initial formula (and not from a strengthening of it) if the abstractions of the involved patterns can be defined such that unification reduces to matching.Corollary 6One-step CoverageLetπ∧ϕbe a pattern such that for each ruleπ1∧ϕ1π2∧ϕ2∈Sthere exist abstractions(∃X1)π˜1∧ϕ˜1and(∃X)π˜∧ϕ˜ofπ1∧ϕ1andπ∧ϕ, respectively, such thatσ(π˜1)=π˜for all≅-unifiersσ ofπ˜1andπ˜. Then, for allγ⇒Sγ′withγ∈〚π∧ϕ〛there exists a patternπ′∧ϕ′such that[π∧ϕ]~⇒SsMs[π′∧ϕ′]~andγ′∈〚π′∧ϕ′〛.In the proof of Theorem 5, we use the set of equalities forρs(π˜1∧ξ):ρs(π˜1∧ξ)=[σ(π˜1)∧ϕ˜]~(bythedef.ofρs)=[π˜∧ϕ˜]~(σisa≅-matcher)=[π∧ϕ]~(π∧ϕ~π˜∧ϕ˜)□In Section 6 we present the general conditions under which the hypotheses of Corollary 6 hold, and thus, full coverage holds. This is illustrated in Example 10.Example 10We assume that the ruleπ1∧ϕ1π2∧ϕ2∈Sand the patternπ∧ϕare those given in Example 9. If the abstractionπ˜1∧ϕ˜1ofπ1∧ϕ1is〈〈B′andB↷C〉k〈M〉env〉cfg∧B′=true, then the substitution σ given byσ(B′)=B1,σ(B)=I<Int0,σ(I)=I′,σ(C)=σ(C′)=C″is a unifier ofπ˜1and π,ϕσisB′=BoolB1∧B=BoolI<Int0∧I=IntI′∧C=C″∧C′=C″,andρ⊨(∃I′,C″)ϕσ. Since σ just renames the variables of π, there existsσ′such thatσ′(π1)=πand we haveπ⇒SsMsπ2∧ϕσ′, i.e.:[〈〈B1andI<Int0↷C′〉k〈M〉env〉cfg∧C=C′]~⇒SsMs[〈〈B↷C〉k〈M〉env〉cfg∧B1=Booltrue∧B=BoolI<Int0∧C=C′]~.Now we formulate the coverage result relating concrete and symbolic executions.Corollary 7CoverageUnder the hypothesis ofCorollary 6, for each concrete executionγ0⇒S⋯⇒Sγi⇒S⋯withγ0∈〚π0∧ϕ0〛, there is a symbolic execution[π0∧ϕ0]~⇒SsMs⋯⇒SsMs[πi∧ϕi]~⇒SsMs⋯such that for alli=0,1,…,γi∈〚πi∧ϕi〛.By induction on i using Corollary 6.□Note that a similar coverage result based on Theorem 5 (instead of its Corollary 6) does not hold, because the symbolic steps given by this theorem cannot be “connected” into a symbolic execution.The coverage property is one of the two properties expected from symbolic execution. It relates concrete steps to symbolic ones. The second one, stated by the next result, relates “feasible” symbolic steps to concrete ones.Theorem 8One-step PrecisionIf[π∧ϕ]~⇒SsMs[π′∧ϕ′]~andγ′∈〚π′∧ϕ′〛then there exists a configuration γ such thatγ⇒Sγ′andγ∈〚π∧ϕ〛.Letπ˜1∧ξπ2∧ϕ2∧ϕ˜1∧ξ∈Ssandρs:Var→Msbe such thatM⊨π1∧ϕ1↔(∃X1)π˜1∧ϕ˜1(i),ρs(π˜1∧ξ)=[π∧ϕ]~andρs(π˜2∧ϕ˜2∧ϕ˜1∧ξ)=[π′∧ϕ′]~. Letσsdenote a substitution such thatσs(x)=ρs(x)for all variablesx∈var(π˜1.ϕ˜1,π2,ϕ2), andσs(ξ)=ϕ. Then(ii)[π∧ϕ]~=[σs(π˜1∧ξ)]~(thedef.ofσs)=[σs(π˜1)∧ϕ]~(thedef.ofσs)=[π˜1∧ϕ∧ϕσs]~(Lemma3)and[π′∧ϕ′]~=[σs(π2∧ϕ2∧ϕ˜1∧ξ)]~(thedef.ofσs)=[σs(π2∧ϕ2∧ϕ˜1)∧ϕ]~(thedef.ofσs)=[π2∧ϕ2∧ϕ˜1∧ϕ∧ϕσs]~(Lemma3).Fromγ′∈〚π′∧ϕ′〛and the above equalities we deduce that there areρ′andρ″such thatρ′(π′)=ρ″(π2)=γ′,ρ′⊨ϕ′, andρ″⊨ϕ2∧ϕ˜1∧ϕ∧ϕσs. Sincevar(π2,ϕ2)∩var(π′,ϕ′)=∅by Assumption 3, there exists ρ such thatρ|var(π′,ϕ′)=ρ′,ρ|var(π2,ϕ2)=ρ″, and hence(γ′,ρ)⊨π2∧ϕ2∧π′∧ϕ′. It follows thatπ2∧ϕ2andπ′∧ϕ′are ρ-unifiable and hence there is a symbolic unifierϕσ∧ϕ˜2∧ϕ˜′of[π2∧ϕ2]~and[π′∧ϕ′]~by Assumption 2, whereσ∈unif≅(π2˜,π˜′). We also haveρ⊨ϕσby Assumption 2 and henceγ′∈〚π′∧ϕ′∧ϕσ〛.Letγ≜ρ(π˜1). We also havevar(π˜1,ϕ˜1)∩var(π′,ϕ′)=∅by Assumption 3, and therefore we may assume w.l.o.g. thatρ|var(π˜1,ϕ˜1)=ρ″, and hence(γ,ρ)⊨π˜1∧ϕ˜1. It follows that(γ,ρ)⊨(∃X1)π˜1∧ϕ˜1, which implies(γ,ρ)⊨π1∧ϕ1thanks to the equivalence (i). We have already obtained(γ′,ρ)⊨π2∧ϕ2, thus, we have the theorem׳s first conclusion:γ⇒Sγ′.There remains to prove the second conclusion:γ∈〚π∧ϕ〛. Sinceρ|var(π˜1,ϕ˜1)=ρ″it follows thatγ=ρ″(π˜1). We haveρ″⊨ϕ∧ϕσsby the definition ofρ″, henceγ∈〚π˜1∧ϕ∧ϕσs〛that is equal to〚π∧ϕ〛by (ii), which proves the theorem׳s second conclusion.□We may now formulate the precision result which follows from Theorem 8:Corollary 9PrecisionFor every feasible symbolic execution[π0∧ϕ0]~⇒SsMs⋯⇒SsMs[πi∧ϕi]~⇒SsMs⋯there is a concrete executionγ0⇒S⋯⇒Sγi⇒S⋯such thatγi∈〚πi∧ϕi〛for alli=0,1,….By induction, using Theorem 8.□Remember that coverage and precision have practical consequences: they ensure that results of analyses performed by symbolically executing programs (reachability analysis, model checking, etc.) also hold for their concrete executions, which are, of course, the executions that one is actually interested in.In this section we address some of the issues left open in Sections 4 and 5, in order to ensure a smooth transition between our theoretical language-transformation approach and its implementation given in Section 7. The issues are:1.how to obtain a set of symbolic rulesSswith same cardinality asS(i.e., typically,Sis finite, but the theoretical construction given in Section 5 will generate an infiniteSs, which is impossible to use in practice);how to satisfy Assumption 2 (required by the Theorem 5);how to obtain unification by matching (required by Corollary 6).We first show in Section 6.1 how to solve the first of the above-listed issues. Then, we present two instances of the current theoretical framework, and show how we address the two remaining issues from our list:•the first instance, presented in Section 6.2, coincides with that presented in the earlier paper [2];the second instance, presented in Section 6.3, is an extension of the previous one. It allows one to use axiomatically defined structures (sets, bags, lists, etc.), with axioms such as associativity, commutativity, unity and combinations thereof. Such structures are intensively used in actual language definitions, such as those defined in theKframework.The set of symbolic rulesSs, defined in Section 5.3 is typically infinite, because of the infinitely many abstractions(∃X)π˜1∧ϕ˜1of the left-hand sidesπ1∧ϕ1of rules inS. The algorithm presented below, which we call LDA (for Linearisation and Data Abstraction) produces a unique abstraction for any pattern (and thus, a one-to-one correspondence betweenSandSs).We present the LDA algorithm and illustrate it by examples.1. Linearising basic patterns: Recall that a term is linear if any variable occurs at most once in its left-hand side. A patternπ∧ϕis linear if π is linear. A nonlinear pattern can always be turned into an equivalent linear one, by renaming the variables occurring several times in π and adding the equalities between the renamed variables and the original ones to the condition ϕ.For example,〈〈X〉k〈X↦I〉env〉cfg∧⊤is transformed into〈〈X〉k〈X′↦I〉env〉cfg∧⊤∧X=X′,where we assumed thatX↦Iis not a data term.2. Data abstraction: LetDpos(t)be the set of positions p22For the notion of position in a term and other rewriting-related notions, see, e.g., [5].t|pdenotes the subterm of t at position p.of the term t such thatt|pis a maximal subterm of a data sort. The next step of our pattern transformation consists in replacing all the maximal data subtermsπ|pof π by fresh variables xpand adding the equalities between the fresh variables and the corresponding subterms to the condition ϕ. Formally,π∧ϕis transformed intoπ[xp/π|p]p∈Dpos(π)∧ϕ∧⋀p∈Dpos(π)(xp=π|p)). For instance, the pattern〈〈iftruethenS1elseS2〉k〈M〉env〉cfg∧⊤is transformed into〈〈ifBthenS1elseS2〉k〈M〉env〉cfg∧⊤∧B=true.The above transformations describe an algorithm that builds a unique (up to a renaming of the new added variables) abstraction(∃X)π˜∧ϕ˜for a given patternπ∧ϕ. Moreover,ϕ˜is of the formϕ∧ϕσfor a substitution σ that sends each fresh variablex′into either a variablex∈var(π)(due to the linearisation) or a data subterm πp(due to the data abstraction).We hereafter assume that all rules inSare transformed such that their left-hand sides are abstractions computed by LDA.Example 11The last rule from the original imp semantics (Fig. 3) could have been written as a nonlinear rule:〈〈X⋯〉k〈X↦I⋯〉env⋯〉cfg〈〈I⋯〉k〈X↦I⋯〉env⋯〉cfgin which case it would have been transformed into〈〈X⋯〉k〈X′↦I⋯〉env⋯〉cfgX=X′〈〈I⋯〉k〈X↦I⋯〉env⋯〉cfgThe following rule for if from the imp semantics:〈〈iftruethenS1elseS2⋯〉k⋯〉cfg〈〈S1⋯〉k⋯〉cfgis transformed into〈〈ifBthenS1elseS2⋯〉k⋯〉cfg∧B=true〈〈S1⋯〉k⋯〉cfg.We still have to prove that the instances of our theoretical framework (presented in Sections 6.2 and 6.3 below) still satisfy coverage results (Theorem 5 and Corollary 6) when abstractions of patterns are computed by LDA instead of generating all possible abstractions. The proofs are given in the subsections below, since they depend on other results, which are specific to the particular instances. We note that precision (Theorem 8) is not affected by computing abstractions with LDA. Indeed, if all (feasible) symbolic executions generated by a larger setSshave corresponding concrete ones, then this also holds for a subset of those symbolic executions, generated by a smaller setSs.The two instances differ with respect to their definition of the model M, which is a parameter of any language definitionL=((Σ,Π,Cfg),M,S). Remember from Section 3 that we assumed a subsignature(Σd,Πd)of(Σ,Π), and a(Σd,Φd)-modelD, which interprets the data sorts, operations, and predicates.For the first instance, the model M is defined as follows:•for each item (sort, function/predicate symbol)o∈(Σd,Πd),Mo=Do;for each sort s inΣ⧹Σd, Msis the set of ground(Σ⧹Σd)(D)-terms;for each function symbol f inΣ⧹Σd, Mfis the term constructor f such that for all(t1,…,tn),Mf(t1,…,tn)=f(Mf(t1),…,Mf(tn))(recall that the result sort of f does not belong toΣdby the hypotheses).The ground term〈〈y=x+3;〉k〈x↦5y↦0〉env〉cfgis an element inMCfg, while the ground term〈〈y=x + 3〉k〈x↦1+Int2y↦0〉env〉cfgdoes not belong toMCfgbecause it includes the non-constant data term1+Int2.Even if the elements of M are terms, the valuationsρ:Var→Mare not, in general, substitutions because they involve expressions on data (e.g.,1+Int2in Example 12). Therefore the valuations do not define unifiers directly.The following result shows that Assumption 2 from Section 4 holds for this case. Moreover it ensures that Theorem 5 holds when computing abstractions with the LDA algorithm:Lemma 10Concrete unifiability implies symbolic unifiabilityLetπ1∧ϕ1andπ∧ϕbe two patterns such thatvar(π1∧ϕ1)∩var(π∧ϕ)=∅. Ifπ1∧ϕ1andπ∧ϕare concretely ρ-unifiable then the classes[π1∧ϕ1]~and[π∧ϕ]~are symbolically ρ-unifiable, with a unifierψ=(∃X∪X′∪var(ran(σ)))ϕσ∧ϕ˜1∧ϕ˜, whereσ∈unif(π˜1,π˜),π˜1∧ϕ˜1, andπ˜∧ϕ˜are computed using the LDA algorithm.Let ρ be a valuation such thatπ1∧ϕ1andπ∧ϕare concretely ρ-unifiable. There exists γ such that(γ,ρ)⊨π1∧ϕ1∧π∧ϕ. Let(∃X1)π˜1∧ϕ˜1and(∃X)π˜∧ϕ˜the abstractions ofπ1∧ϕ1andπ∧ϕ, respectively, computed with the algorithm LDA. There existsρ˜such that(γ,ρ˜)⊨π˜1∧ϕ˜1∧π˜∧ϕ˜andρ˜(x)=ρ(x), for allx∉X∪X1. Let σ be the substitution defined byσ(x)=ρ˜(x)forx∈var(π˜1,π˜). Sinceσ(x)∈Mand by the particular form ofπ˜1andπ˜we haveσ(π˜1)=σ(π˜), a ground term in M. Hence σ is a unifier ofπ˜1andπ˜and we haveρ⊨(∃X1∪X)ϕσbecauseρ˜⊨ϕσ. Indeed, becauseσ(x)is a ground term,ρ˜(σ(x))=σ(x)=ρ˜(x)becausevar(ran(σ))∩(X∪X1)=∅by Assumption 3. Henceψ≜(∃X∪X1)ϕ˜1∧ϕ˜∧ϕσis a symbolic ρ-unifier of[π1∧ϕ1]~and[π∧ϕ]~(note thatvar(ran(σ))=∅because σ is a ground substitution).□Considerπ1∧ϕ1≜〈〈X+0〉k〈.Map〉env〉cfg∧⊤andπ∧ϕ≜〈〈2+b+Int1〉k〈.Map〉env〉cfg∧⊤.(N.B.: the operation + is part of the imp syntax whereas+Intis addition in the integer data domain). First, note thatπ1∧ϕ1andπ∧ϕare concretely ρ-unifiable, with ρ satisfyingρ(X)=2andρ(b)=−1. Second, there isγ≜〈〈2+0〉k〈.Map〉env〉cfgsuch that(γ,ρ)⊨π1∧ϕ1and(γ,ρ)⊨π∧ϕ, sinceρ(2+b+Int1)=2+D+Int(ρ(b),1)=2+D+Int(−1,1)=2+0.The abstractions of the two patterns computed as above are(∃X1)π˜1∧ϕ˜1≜(∃I)〈〈X+I〉k〈.Map〉env〉cfg∧I=Int0and(∃X)π˜∧ϕ˜≜(∃A,B)〈〈A+B〉k〈.Map〉env〉cfg∧A=Int2∧B=Intb+Int1.The valuationρ˜is given byρ˜(X)=ρ(X)=2,ρ˜(b)=ρ(b)=−1,ρ˜(I)=ρ(0)=0,ρ˜(A)=ρ(2)=2,ρ˜(B)=ρ(b+Int1)=0.Let σ be the substitution given byσ(x)=ρ˜(x), for allx∈var(π˜1,π˜), i.e.,σ(X)=2,σ(I)=0,σ(A)=2,σ(B)=0. Then σ is a syntactic unifier ofπ˜1andπ˜:σ(X+I)=σ(A+B)=2+0. We obviously haveρ⊨(∃I,A,B)ϕσ, whereϕσisX=Int2∧I=Int0∧A=Int2∧B=Int0.In the proof of Theorem 5 we consider a symbolic unifier ψ whose existence is given by Assumption 2. Lemma 10 is a stronger version of Assumption 2: the unifier ψ is computed using the LDA algorithm. In order to prove that Theorem 5 still holds it is enough to choose, in its proof,ψ=(∃X∪X′∪var(ran(σ)))ϕσ∧ϕ˜1∧ϕ˜, whereσ∈unif(π˜1,π˜),π˜1∧ϕ˜1, andπ˜∧ϕ˜are computed using the LDA algorithm.We still have to show that Corollary 6 holds for this instance. For this, we show that its hypothesis is satisfied, i.e., we have to reduce unification in M to matching. This result is proved in a more general setting by Lemma 14 in the subsection below (we take the set A of axioms to be the empty set).This concludes the description of this instance of our language-transformation approach. This instance is isomorphic with the earlier approach [2].Language definitions in theKframework often use structures such as bags and sets in configurations. In order to symbolically execute programs in such languages, one needs to solve constraints involving bags, sets, etc. One possibility is to consider those structures as data, and to deal with the constraints involving them by SMT solving. But this is a poor solution in practice because SMT solvers have limited support for constraints over bags and sets. Hence, some structures involved in language definitions must be defined axiomatically.Thus, we assume given a set A of structural axioms (e.g., associativity, and/or commutativity, and/or identity) for certain non-data functional symbols and for which there exists a matching algorithm modulo A that produces a finite number of A-matching solutions, whenever such solutions exist. The model M isD↿(Σ,Π)/A. Let[t]A∈Mdenote the A-equivalence class including t.The following lemma generalises Lemma 10 from Section 6.2.Lemma 11Concrete unifiability implies symbolic unifiabilityLetφ1≜π1∧ϕ1andφ≜π∧ϕbe two patterns such thatvar(π1∧ϕ1)∩var(π∧ϕ)=∅. If φ1and φ are concretely ρ-unifiable (N.B. in M) then there exists a symbolic ρ-unifier ψ of[φ1]~and[φ]~, where ψ is computed using the algorithm LDA.We use the same notations as in the proof of Lemma 10. Note that there are γ such that(γ,ρ)⊨π1∧ϕ1∧π∧ϕandρ˜such that(γ,ρ˜)⊨π˜1∧ϕ˜1∧π˜∧ϕ˜andρ˜(x)=ρ(x), for allx∉X∪X1(where(∃X1)π˜1∧ϕ˜1and(∃X)π˜∧ϕ˜are the abstractions of φ1 and φ computed using LDA).Since the elements in M are equivalence classes, the substitution σ is defined byσ(x)∈ρ˜(x)forx∈var(π˜1,π˜). We have[σ(π˜1)]A=ρ˜(π˜1)=ρ˜(π˜)=[σ(π˜)]A, which impliesσ(π˜1)=Aσ(π˜). Hence σ is a=A-unifierofπ˜1andπ˜. We prove now thatρ⊨(∃X1∪X)(ϕσ∧ϕ˜1∧ϕ˜). Since we already haveρ˜⊨ϕ˜1andρ˜⊨ϕ˜, it is enough to prove thatρ˜⊨ϕσ. We haveρ˜(σ(x))=[σ(x)]A=ρ˜(x)becausevar(ran(σ))∩(X∪X1)=∅by Assumption 3. Henceψ≜(∃X∪X1)ϕ˜1∧ϕ˜∧ϕσis a symbolic ρ-unifier of[π1∧ϕ1]~and[π∧ϕ]~.□Thus, Theorem 5 holds with the same argument employed in Section 6.2.The last step is to prove that the conditions of Corollary 6 hold; that is, to reduce unification in M to matching. We hereafter assume that the axioms A are linear, regular, and data collapse-free; these requirements are usual for rewrite theories and all the above-mentioned axioms satisfy them. A term t is linear iff any variable occurs in t at most once, an u=v is regular iffvar(u)=var(v)and it is linear if both sides u and v are linear. An axiom u=v is data collapse-free iff it does not collapse a non-data term into a data term; formally, for any substitution σ neitherσ(u)norσ(v)is a variable of data sort. The next sequence of lemmas leads to the proof that unification in M reduces to matching.In the following lemma we assume thatt˜is obtained from the term t using the algorithm LDA, but forgetting the condition part.Lemma 12Let t,t′∈TΣ. Ift=At′thent˜=At˜′.The congruence=Ais the smallest equivalence relation that include (i)σ(u)=Aσ(v)for each axiom u=v in A and ground substitution σ, and (ii)t0[t1]p=At0[t2]pwhenevert1=At2.We proceed by well-founded induction. We distinguish two cases:1.t=σ(u)andt′=σ(v)for certain u=v in A. Letσ˜the substitution defined byσ˜(x)=σ(x)˜for allx∈var(u)=var(v)(we havevar(u)=var(v)because u=v is regular). Since u and v include only non-data functional symbols (u=v is regular and data collapse-free) and are linear, we obtainσ(u)˜=σ˜(u)andσ(v)˜=σ˜(v). From (i) we haveσ˜(u)=Aσ˜(v), which impliesσ(u)˜=Aσ(v)˜.t=t0[t1]pandt′=t0[t2]pfor certain t0,t1=At2, and position p in t0. We havet˜1=At˜2by the induction hypothesis. Sincet˜=t˜0[t˜1]pandt˜′=t˜0[t˜2]pwe obtaint˜=At˜′using the definition of=A.□Let t be a linear term whose all data subterms are variables and these are the only variables occurring in t (hencet˜=t). If σ is a ground substitution then there exists a variable renaming η such thatη(σ(t)˜)=t.The setdom(σ)includes only data variables by the hypotheses of the lemma. We proceed by structural induction on t.1.t is a variable. Then t has a data sort andσ(t)˜is a variable as well. Thus, we consider η such thatη(σ(t)˜)=t.t=f(t1,…,tn),n≥0. Then f is a non-data functional symbolσ(t)˜=f(σ(t1)˜,…σ(tn)˜). From the inductive hypothesis, there are the variable renamingsη1,…,ηnsuch thatηi(σ(ti)˜)=ti,i=1,…,n. Since t is linear, it follows that the substitution η, given byη(x)=ηi(x)iffx∈var(σ(ti))˜for some1≤i≤nis a variable renaming as well. We haveη(σ(t)˜)=f(η1(σ(t1)˜),…ηn(σ(tn)˜))=f(t1,…,tn)=t.The proof by induction is finished and the lemma is proved.□Finally, we show that, under certain conditions, the unification (in M) reduces to matching:Lemma 14Unification by matchingLet π1be a linear basic pattern whose data subterms are all variables (and henceπ˜1=π1) and π a linear basic pattern whose all variables are of data sort and whose all data subterms are variables (and henceπ˜=π). We further assume thatvar(π1)∩var(π)=∅. If σ is a=A-unifier, i.e. σ is a ground substitution satisfyingσ(π1)=Aσ(π), then there exists a variable renaming η such thatη(σ(π1))=Aπ.We haveσ(π1)˜=Aσ(π)˜by Lemma 12 andη(σ(π)˜)=πby Lemma 13.□Since every=A-unifierσ is a=A-matching, it follows that Corollary 6 (Coverage) holds. If there exists a matching algorithm modulo A that produces a finite number of A-matching solutions, we obtain that a left-hand side of a ruleπ1∧ϕ1and symbolic configurationπ∧ϕare ρ-unifiable iff there exists a matching solution σ such thatρ(x)=[σ(x)]Aandσ(π1)˜=Aπ˜.There are several similarities between our approach in that given in [27]: their built in theory is equivalent to the specification of data, constrained terms are patternsπ∧ϕ, and the abstraction of built-ins for a configuration term π is the same with ourt˜. According to the paragraph preceding Lemma 4 (Matching Lemma) in [27], by A-matching a configuration term π, including only data variables, against a left-hand sideπ˜1of a rule inSprovides a complete unifiability algorithm for ground A-unification of π andπ˜1(the claim was adapted to our notation). More technically, the Matching Lemma in [27] claims that if π andπ˜1are ground A-unifiable, then there is a matching substitution σ such thatσ(π˜1)=Aπ(note the equality modulo A). Since ground A-unifiability is the same with concrete unifiability in the model M, we show below that we may takeunif≅(π˜1,π)to be the set of substitutions given by the matching algorithm. However, we cannot apply directly the Matching Lemma in [27] because it does not establish a direct relationship between unifiers and matchers.This concludes the presentation of the practically relevant instances of our language-transformation approach.

@&#CONCLUSIONS@&#
