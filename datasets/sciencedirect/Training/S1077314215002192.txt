@&#MAIN-TITLE@&#
Localizing activity groups in videos

@&#HIGHLIGHTS@&#
A latent graphical model integrating multi-target tracking, group discovery, and activity recognition is proposed.Performance of activity recognition improves when multi-target tracking and group clustering are incorporated.Group activities are better recognized based on the structured relations within the group and group–group compatibilities.Increasing the connectivity of different groups improves the overall performance.Incorporating activity information leads to robust group localization in the video.

@&#KEYPHRASES@&#
Activity recognition,Latent graph model,Group activity,

@&#ABSTRACT@&#
Beyond recognizing actions of individuals, activity group localization in videos aims to localize groups of persons in spatiotemporal spaces and recognize what activity the group performs. In this paper, we propose a latent graph model to simultaneously address the problem of multi-target tracking, group discovery and activity recognition. Our key insight is to exploit the contextual relations among people. We present them as a latent relational graph, which hierarchically encodes the association potentials between tracklets, intra-group interactions, correlations, and inter-group compatibilities. Our model is capable of propagating multiple evidences among different layers of the latent graph. Particularly, associated tracklets assist accurate group discovery, activity recognition can benefit from knowing the whole structured groups, and the group and activity information in turn provides strong cues for establishing coherent associations between tracklets. Experiments on five datasets demonstrate that our model achieves both significant improvements in activity group localization and competitive performance on activity recognition.

@&#INTRODUCTION@&#
Vision-based human action and activity analysis have attracted much attention in computer vision literature. While recent work typically concentrates on activity recognition of a single person [1,2] or a pair of persons [3–8] in short videos or still images, there is an increasing demand for developing principled approaches to interpret long videos of complex scenes where many people are engaged in various co-occurring activities. In those scenarios, we observe that group activities, i.e. multiple persons performing collective activities in groups, is more common, with typical examples like: shopper queuing in a shopping store to get checked, pedestrians crossing a road, and friends talking together with their kids playing around. In this paper, we go beyond just recognizing each individual’s activity, but seek to simultaneously recognize and localize group activities in videos. We present this problem as activity group localization. In this paper, an activity group is defined as a spatiotemporal group of several people performing collective activities. As shown in Fig. 1, given a video, we localize two activity groups, including a walking group and a talking group. Activity group localization is of great importance since it provides a basis for high level applications such as semantic video indexing, video summarization, and video classification to name a few.Two tasks are involved in this problem. The first is activity recognition. However, recognizing group activities is more complex than recognizing individual activities since they often depend on interactions among participants. One common approach is to incorporate contextual information, for example, to develop contextual descriptors for individuals that characterize what others nearby are doing [9–11] or to jointly infer actions, interactions and activities of all individuals in the scene [12–14]. The second is group localization in a video, which requires tracking persons in the video and further assigning persons to unknown number of groups. It is rather challenging mainly because multi-target tracking in complex scenes is difficult due to occlusions, false detections and background clutter. Moreover, clustering persons into groups based on only trajectory distance is inadequate, since activity groups also share activity potentials. One direct example is that two people waiting for a green light and then crossing the road form two activity groups rather than one.In this paper, we seek to jointly solve these two tasks by exploiting the relations among people. Such relations not only characterize interactions between persons like facing to each other in talking groups, but also include some correlations of primitive actions, motions, and poses among people in the same group such as spreading legs in walking groups. We also explore the relations between two groups, which encode the compatibility of the groups and the scene. For example, a dancing group is more likely to be co-exist with a walking group other than a queuing group. Our hypothesis is that these relations can provide key evidences to group localization as well as group activity recognition. As shown in Fig. 1, it is difficult to identify activity groups based on the observations from each individual. However, if we observe them in a pairwise manner, we can discover that there are a strong interaction facing to each other between two people and correlations spreading legs among multiple people, thus we can cluster them into two different groups. In addition, knowing the relations within the group enables classifying activities on the level of discriminative interactions and correlations rather than the whole appearances, which is intuitively more sensible. For example, two groups can be localized in Fig. 1(b), then based on their intra-group relations and inter-group compatibilities, we can further infer the activities of two groups are walking and talking, respectively. Moreover, the structured groups provide useful contextual cues for multi-target tracking, which leads to more accurate trajectories that in turn assist the relation mining among people. Therefore, we treat these relations as latent variables, and propose a latent graph model to jointly associate fragmented trajectories (tracklets) into trajectories, cluster trajectories into groups, and assign activity labels to groups.The main contributions of our work can be summarized in four-fold: (i) we propose a latent graph model to localize activity groups by jointly addressing the problems of multi-target tracking, group discovery, and activity recognition. (ii) We explore two types of contextual relations, including intra-group relations and inter-group relations. We validate their effectiveness on group localization as well as collective activity recognition. (iii) We propose a novel hierarchial relational graph to describe all relations among people. This relational graph is dynamically inferred to produce the optimal activity groups.The rest of this paper is organized as follows: Section 2 reviews the previous work. Section 3 presents our latent graph model for activity group localization. The details of learning and inference are given in Sections 4 and 5. Section 6 shows our experimental results. Section 7 concludes our paper.

@&#CONCLUSIONS@&#
In this paper, we aim at activity group localization in videos, which includes two distinct but related tasks: group localization and activity recognition. Instead of solving them in isolation, we seek to simultaneously associate tracklets, cluster person tracks, and recognize activities on the spatiotemporal group level. A hierarchical relational graph that encodes rich relations among people is proposed to unify all these tasks, which is dynamically inferred in our model.We demonstrated that the incorporation of group information and tracklet association helps to classify group activities, and it is especially useful for structure-rich activities. With context structured by the relational graph, our proposed model can achieve competitive results comparing with the state-of-the-art approaches using three different validation schemes. In turn, the activity group localization accuracy is also significantly improved by jointly inferring the activities. Experiments on five datasets show that our model is capable of observing some high-level co-occurrences of different groups with respect to their activity labels, and some promising structures within an activity group can be learnt as well.