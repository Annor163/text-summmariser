@&#MAIN-TITLE@&#
A hybrid metaheuristic method for the Maximum Diversity Problem

@&#HIGHLIGHTS@&#
MAMDP is a hybrid metaheuristic for the Maximum Diversity Problem (MDP).MAMDP is assessed on a collection of 7 sets of 120 MDP benchmark instances.MAMDP obtains all previous best know solutions for these instances.MAMDP yields improved solutons for 6 large instances.MAMDP competes favorably with 4 best performing MDP algorithms.

@&#KEYPHRASES@&#
Maximum Diversity Problem,Solution combination,Local search,Constrained neighborhood,Population diversity,

@&#ABSTRACT@&#
The Maximum Diversity Problem (MDP) consists in selecting a subset ofmelements from a given set ofnelements (n>m) in such a way that the sum of the pairwise distances between themchosen elements is maximized. We present a hybrid metaheuristic algorithm (denoted by MAMDP) for MDP. The algorithm uses a dedicated crossover operator to generate new solutions and a constrained neighborhood tabu search procedure for local optimization. MAMDP applies also a distance-and-quality based replacement strategy to maintain population diversity. Extensive evaluations on a large set of 120 benchmark instances show that the proposed approach competes very favorably with the current state-of-art methods for MDP. In particular, it consistently and easily attains all the best known lower bounds and yields improved lower bounds for 6 large MDP instances. The key components of MAMDP are analyzed to shed light on their influence on the performance of the algorithm.

@&#INTRODUCTION@&#
LetN={s1,s2,…,sn}be a set of elements anddijbe the distance between elementssiandsj(dij=dji), withdij>0ifi≠janddij=0otherwise. The Maximum Diversity Problem (MDP for short) consists in selecting a subsetM⊂Nof a given cardinality m(m<n)from N, such that the sum of the distances between every two elements in M is maximized. Formally, the problem can be stated as the following quadratic zero-one integer program (Kuo, Glover, & Dhir, 1993):(1)Maximizef(x)=12∑i=1n∑j=1ndijxixj(2)subject to∑i=1nxi=mwherexiis a binary variable indicating whether an elementsiis selected to be a member of the subset M.MDP is known to be NP-hard and has a high computational complexity (Ghosh, 1996). In addition to its theoretical significance as a difficult combinatorial problem, MDP is notable for its ability to formulate a number of practical applications: location of undesirable or mutually competing facilities (Erkut & Neuman, 1991), decision analysis with multiple objectives (Palubeckis, 2007), composing jury panels (Lozano, Molina, & García-Martínez, 2011), genetic engineering (Martí, Gallego, Duarte, & Pardo, in press), medical and social sciences (Kuo et al., 1993), and product design (Glover, Kuo, & Dhir, 1998). During the past three decades, MDP has been studied under many different names such as maxisum dispersion (Kuby, 1987), MAX-AVG dispersion (Ravi, Rosenkrantz, & Tayi, 1994), edge-weighted clique (Alidaee, Glover, Kochenberger, & Wang, 2007; Macambira & de Souza, 2000), remote-clique (Chandra & Halldórsson, 2001), maximum edge-weighted subgraph (Macambira, 2002), and dense k-subgraph (Brimberg, Mladenović, Urošević, & Ngai, 2009; Feige, Kortsarz, & Peleg, 2001).The computational challenge of the MDP has motivated a variety of solution approaches including exact methods, approximation algorithms and metaheuristic methods. Examples of approximation algorithms are described in Feige et al. (2001) and Hassin, Rubinstein, and Tamir (1997). These approaches provide a performance guarantee, but do not compete well with other methods in computational testing. Three recent examples of exact methods are described in Aringhieri, Bruglieri, and Cordone (2009), Martí, Gallego, and Duarte (2010), and Prokopyev, Dayna, and Martinez-Torres (2009). While these methods have the theoretical advantage of finding optimal solutions to a given problem, their applications are generally limited to problems with some 150 elements.For larger problem instances, heuristics and metaheuristics are often used to find approximate solutions of good quality with a reasonable computing time. This includes tabu search (Alidaee et al., 2007; Aringhieri, Cordone, & Melzani, 2008; Aringhieri & Cordone, 2011; Duarte & Martí, 2007; Macambira, 2002; Wang, Zhou, Cai, & Yin, 2012), iterated tabu search (Palubeckis, 2007), simulated annealing (Kincaid, 1992), iterated greedy algorithm (Lozano et al., 2011), estimation of distribution algorithms (Wang, Zhou, Yin, & Zhang, 2009), genetic algorithms (Feng, Jiang, Fan, & Fu, 2010), variable neighborhood search (Aringhieri & Cordone, 2011; Brimberg et al., 2009), scatter search (Gallego, Duarte, Laguna, & Martí, 2009; Gortázar, Duarte, Laguna, & Martí, 2010), path-relinking method (de Andrade, Plastino, Ochi, & Martins, 2003; de Andrade, de Andrade, Martins, & Plastino, 2005) and memetic search (Katayama & Narihisa, 2005). Another approach that has received considerable attention in the solution of the MDP is greedy randomized adaptive search procedure (GRASP) (de Andrade et al., 2003; de Andrade et al., 2005; Duarte & Martí, 2007; Ghosh, 1996; Santos, Ribeiro, Plastino, & Martins, 2005; Silva, Ochi, & Martins, 2004; Silva, de Andrade, Ochi, Martins, & Plastino, 2007). Finally, a comprehensive survey and an interesting comparison of the most significant heuristic and metaheuristic methods for MDP can be found in Aringhieri and Cordone (2011), Martí et al. (in press).This paper presents MAMDP, a hybrid metaheuristic algorithm integrating a tabu search procedure with a population-based evolutionary algorithm for solving the Maximum Diversity Problem. The proposed algorithm integrates three complementary key components to ensure the high efficiency of the search process. First, to generate promising new solutions, we introduce a dedicated crossover operator which tries to preserve common elements that are shared by parent solutions. The design of this crossover operator is motivated by an experimental observation that high quality solutions share a large number of common elements. Second, to allow the algorithm to explore efficiently the search space around each newly generated solution by crossover, we devise a tabu search optimization procedure which relies on a constrained neighborhood and a dynamic tabu list management strategy. Finally, to maintain the population diversity, we employ a quality-and-distance replacement strategy for population updates.To assess the performance and the competitiveness of our algorithm in terms of both solution quality and computing efficiency, we provide computational results on a total of 120 MDP benchmark instances with up to 5000 elements, showing that the proposed algorithm achieves highly competitive results with respect to the best existing MDP heuristics. Moreover, for 6 large MDP instances, the proposed algorithm is able to provide new improved results.The remaining part of the paper is organized as follows. In Section 2, the ingredients of our algorithm are described, including the dedicated crossover operator, the constrained neighborhood tabu search procedure and the quality-and-distance based pool updating rule. Section 3 is dedicated to the computational results. Section 4 investigates several important components of the proposed MAMDP algorithm and concluding remarks are given in Section 5.Our hybrid metaheuristic algorithm follows the general memetic framework which combines the population-based evolutionary search and neighborhood-based local search (Katayama & Narihisa, 2005; Neri et al., 2012). The basic idea is to take advantage of both a recombination (or crossover) operator that discovers unexplored promising regions of the search space, and a local search operator that finds good solutions by concentrating the search around these regions. In order to be effective, the general memetic framework needs to be carefully adapted to the given problem and to integrate problem-specific knowledge within its search operators and strategies (Hao, 2012, chap. 6). As discussed in Glover (1994) and Glover and Laguna (1997, chap. 9), the MA framework shares ideas with scatter search (Glover, Laguna, & Martí, 2000). In particular, scatter search provides unifying principles for joining solutions by structured combinations of elite solutions from a reference set. Additionally, scatter search pays special attention to both distance and quality when it updates the reference set. Finally, scatter search typically uses tabu search to improve each new solution. In this sense, the proposed algorithm can be considered as a simplified scatter search algorithm.The general procedure of our hybrid metaheuristic algorithm for MDP (called MAMDP) is summarized in Algorithm 1. It is composed of four main basic components: a population initialing procedure, a tabu search procedure, a crossover operator and a population management strategy. Starting from an initial population of local optima obtained by the tabu search procedure (Section 2.2), MAMDP performs a series of cycles called generations. At each generation, two solutionsS1andS2are randomly chosen in the population to serve as parents. The crossover is then used to produce an offspring solutionS0fromS1andS2(Section 2.4). The tabu search procedure is applied to improveS0for a fixed number of iterations (Section 2.3). Afterward, the population updating rule decides whether the improved solutionS0should be inserted into the population and which existing solution should be replaced (Section 2.5). This process repeats until a stop condition is verified, such as a time limit or a fixed number of generation (Section 3.3). In the following, we describe the four main components of the proposed algorithm.Algorithm 1Memetic algorithm for the Maximum Diversity ProblemRequire: A set ofnelementsN={s1,s2,…,sn}, distance matrix[dij]n×n, cardinality of the subsetm(m<n), population sizepEnsure: The best solutionS∗found1: Initialize populationPop={S1,…,Sp}/* Section 2.2 */2:S∗←Best(Pop)/*S∗records the best solution encountered until now */3: while Stop condition is not verified do4: Randomly select 2 parent solutionsS1andS2fromPop={S1,…,Sp}5:S0←Cross_Over(S1,S2)/* Section 2.4, generate a new solution from parents */6:S0←Tabu_Search(S0)/* Section 2.3, improve the offspring */7:iff(S0)>f(S∗)then8:S∗←S0/* Update the best solution found so far */9:end if10:Pop←PopulationUpdate(S0,Pop)/* Section 2.5, update population using a distance-and-quality rule */11: end whileBefore presenting the components of the MAMDP algorithm, we define first the search space explored by the algorithm as well as the evaluation function to measure the quality of a candidate solution.Given that the objective of MDP is to determine a subsetM⊂Nof size m (called m-subset) while maximizing the sum of the distances between every two elements in M, we define our search spaceΩto be the collection of all possible subsets of N of cardinality m, i.e.,Ω={S⊂N:|S|=m}. It is clear thatΩhas a size ofCnm=n!m!(n-m)!which may be very large for reasonable values of n and m.To evaluate the quality of a solutionS∈Ω(i.e., a m-subset), we just sum up the distances between every two elements in S as follows:(3)f(S)=∑su,sv∈S,u<vduvIt is easy to see that this function is strictly equivalent to the function defined in Formula (1).Finally, we mention that to represent each subset S of Ω, we use a binary vectorS¯of length n containing exactly m 1s:S¯[i]=1if elementsi∈Nbelongs to subsetS,S¯[i]=0otherwise. For simplicity reasons, hereafter we will use the set notion S, instead of its vector representationS¯, to designate a solution of Ω even if both are semantically equivalent.Our algorithm begins with an initial population composed of p solutions (p is the population size which is fixed by a parameter). There are different ways to obtain the initial population. One basic technique is random generation which, though easy to apply, can hardly lead to initial solutions of good quality. In this paper, we initialize the population with locally optimal solutions as follows. Starting from a random m-subset S (S∈Ω), we apply the tabu search procedure (see Section 2.3) to improve S until a local optimum S is reached. The resulting improved solution is added to the population if it is not identical to any solution currently in the population. The insertion condition can be stated formally using the distance measure defined in Section 2.5 as follows: the new solution is added to the population if its distance to any existing solution of the population is greater than zero. This procedure is repeated until the population is filled up with3×psolutions from which we finally retain the p best ones with the largest objective values to form the initial population. This procedure allows us to obtain an initial population of relatively high quality. Notice that for some small (or easy) MDP instances, our algorithm can even reach the optimal solutions (or solutions with previous best known objective values) during the phase of initialization of the population due to the high efficiency of the tabu search procedure.One key element of our hybrid MAMDP algorithm is its tabu search procedure which ensures the critical role of intensified search of a limited region. In addition to being applied to generate the initial population as explained in the previous section, the tabu procedure is in particular used to improve the offspring solutions created by the crossover operator (see Section 2.4). Adopting the general method of tabu search (Glover & Laguna, 1997), our tabu procedure (see Algorithm 2) is specifically adapted to the MDP problem by introducing a dedicated constrained neighborhood and a dynamic tabu list management mechanism, which are developed in this section.Algorithm 2Constrained neighborhood tabu search procedure for MDPRequire: A set ofnelementsN={s1,s2,…,sn}, initial solution S, numberMaxIterof tabu search iterationsEnsure: The best solutionS∗found andf(S∗)1:S∗←S/* Records the best solution found so far */2:Iter←0/* Iteration counter */3: Compute the potentialpvaccording to Eq. 4 for each elementsv∈N.4: Initiate the tabu list and tabu tenure5:dmax←max{dij|1⩽i<j⩽n}/*dmaxis the maximum distance between two elements inN*/6: whileIter<MaxIterdo7:dMinInS←min{pi|si∈S}/*dMinInSis the smallest potential inS*/8: Identify subsetX={si∈S|pi⩽dMinInS+dmax}9:dMaxOutS←max{pi|si∈N⧹S}/*dMaxOutSis the largest potential inN⧹S*/10: Identify subsetY={si∈N⧹S|pi⩾dMaxOutS-dmax}11: Choose a best admissibleswap(su,sv)move from the constrained neighborhoodCN(S)defined byXandY12:S←S⧹{su}∪{sv}/* Move to the new solution */13: Update the tabu list and the potentialpvfor eachsv∈N14:iff(S)>f(S*)then15:S∗←S/* Update the best solution found so far */16:end if17:Iter←Iter+118: end whileAs explained in Section 2.1, our search spaceΩis composed of all possible m-subsets from the given set N. To explore this space, one simple and basic way is to start with any initial m-subset S and subsequently swap an element of S with another element ofN⧹Ssuch that the objective value is improved. One advantage of this swap move is that it maintains solution feasibility. Nevertheless, this unconstrained swap leads to a large neighborhood of sizem·(n-m). This unconstrained swap and its associated neighborhood were used in (Ghosh, 1996) and further explored in Duarte and Martí (2007). As indicated in Duarte and Martí (2007), although this unconstrained swap is valuable for local search algorithms, the evaluation of the neighborhood can be computationally expensive. This is particularly the case with tabu search given that at each iteration of the algorithm, we wish to select the best swap move among allm·(n-m)possible moves induced by S andN⧹S.To reduce the computing time needed to examine neighboring solutions and improve the computational efficiency of our tabu search procedure, we devise a constrained neighborhood which is both more focused and smaller-sized. The idea of our constrained neighborhood is to limit the swap move to two specifically identified subsetsX⊆SandY⊆N⧹Ssuch that|X|and|Y|are as small as possible, and the resulting neighborhood contains always the best solutions of the unconstrained neighborhood induced by S andN⧹S.The constrained neighborhood is based on the notion of potential defined for each element of the current solution. Precisely, letS∈Ωbe a solution (i.e., a m-subset of N), we define, for each elementsi∈N, its potentialpiwith respect to the objective valuef(S)as follows:(4)pi=∑sj∈Sdij,forsi∈NLetswap(su,sv)designate the move which swapssu∈Sandsv∈N⧹S. Then, whenswap(su,sv)is applied, the objective variationΔuv, also called the ’move gain’, can be conveniently computed by:(5)Δuv=f(S′)-f(S)=pv-pu-duvwhereS′=S⧹{su}∪{sv}whilepvandpuare respectively the potential ofsvandsuaccording to Formula (4).From Formula (5), we observe that the move gainΔuvofswap(su,sv)depends onpv,puandduv. For the purpose of maximizing the objective function f, we should prefer an elementsv∈N⧹Swith a large potential and inversely an elementsu∈Swith a small potential. In addition, we also need to consider the distanceduvbetweensuandsv. To maximize f, we constrainsuto belong to a specific subsetX⊆Scontaining the elements in S with small potentials, andsvto belong to a specific subsetY⊆N⧹Sincluding the elements inN⧹Swith large potentials.LetdMinInS=min{pi|si∈S}andLetdMaxOutS=max{pi|si∈N⧹S}.Then we define subsets X and Y as follows:X={si∈S|pi⩽dMinInS+dmax}andY={si∈N⧹S|pi⩾dMaxOutS-dmax}where dmax is the maximum distance between two elements in N, i.e.,dmax=max{dij|1⩽i<j⩽n}.To obtain a neighboring solutionS′from S, we swap one elementsu∈Xwith another elementsv∈Y. All possible swap moves induced by X and Y define our constrained neighborhoodCN(S), i.e.,CN(S)={S′|S′=S⧹{su}∪{sv},su∈X,sv∈Y}.Fig. 1shows an illustrative example where S has four possible neighboring solutions and we assume that the tabu list is empty (i.e., no element is forbidden for swap).Our tabu search procedure explores the search spaceΩby following this constrained neighborhood. At each iteration, instead of examining all the swap moves induced by S andN⧹S, our tabu search first identifies the two subsets X and Y associated to S and then selects the best admissibleswap(su,sv)(su∈X,sv∈Y)with the highest move gainΔuv(ties broken randomly). The resulting solution replaces S to become the new current solution. A swap moveswap(su,sv)is admissible if it is not classified tabu (i.e. neithersunorsvis in the tabu list) or if it verifies the aspiration criterion. The aspiration criterion simply states the tabu status of a move is revoked if the move leads to a solution better than any solution found so far.We can see that our constrained neighborhood is a strict subset of the unconstrained neighborhood. Furthermore, assume thatS″is a best admissible neighboring solution in the unconstrained neighborhood, it is easy to verify thatS″∈CN(S). In other words, our constrained neighborhoodCN(S)contains all the best admissible neighboring solutions in the unconstrained neighborhood, while its size is generally much smaller than the unconstrained neighborhood.When aswap(su,sv)move is performed to give a new solution, the potential associated with each elementsiin N can be efficiently updated using the following formula, as shown in Aringhieri et al. (2008) and Aringhieri and Cordone (2011):pi=pi+div,ifsi=su,pi-diu,ifsi=sv,pi+div-diu,ifsi≠suandsi≠sv.Thus, the updating of the potentials associated with the n elements in N can be performed in linear timeO(n).To compute subset X (see also line 7–8 in Algorithm 2), we first examine all the elements in S and identify dMinInS to be the element with the minimum potential among the elements in S. We then check all the elements in S once again, a vertex u is added into X if its potentialpu⩽dMinInS+dmax. Obviously, the procedure for computing subset X can be performed in linear timeO(|S|). Similarly, we compute subset Y by examining all the vertices inN⧹S(see also line 9–10 in Algorithm 2) with a time complexity ofO(|N⧹S|). When the two subsets X and Y are identified, we need to examine all the swap moves induced by X and Y to select the best admissible move with the highest move gain in the constrained neighborhood. This can be achieved with a time complexity ofO(|X|×|Y|). In addition, the time needed to update the potentials associated with the n elements in N is bounded byO(n). Therefore, the total time of each iteration of our algorithm using the constrained neighborhood is bounded byO(n)+O(|X|×|Y|). As shown in Section 4.1, X and Y of our constrained neighborhood are much smaller than S andN⧹S, reducing drastically the computing time of our algorithm.As previously explained, a neighboring solution of S is obtained by applying aswap(su,sv)move to the current solution. To prevent the search from short-term cycling, when such a move is performed, elementsuis marked tabu for the nextTu(called tabu tenure) iterations, during whichsucannot be put back into solution S (except the aspiration criterion is satisfied). Similarly, elementsvis also marked tabu for the nextTviterations andsvcannot be removed from S during this period (except the aspiration criterion is satisfied).It is well known that the performance of a tabu search algorithm depends on the way the tabu tenure is determined (Glover & Laguna, 1997). A too short tabu tenure may lead the search to revisit solutions previously encountered while a too long tabu tenure may exclude high quality solutions during the search. Unfortunately, there does not exist a general way to optimally tune the tabu tenure. In this paper, we adopt a dynamic tabu list management technique. This tabu list management technique was first proposed in Galinier, Boujbel, and Fernandes (2011) and recently explored in Wu and Hao (2012). With this technique, the tabu tenureTuare dynamically adjusted by a periodic step functionTu(Iter)defined over the number of iterationsIter:Iter→Tu(Iter)where Iter is the number of iterations andTu(Iter)is the tabu tenure forTuat iteration Iter. Each period of the step function is composed of 1500 iterations divided into 15 steps.Fig. 2provides an illustration of this step function. As shown in Fig. 2, the tabu tenureTuis equal to α (α is a parameter) for the first 100 iterations[1⋯100], then2×αfor iterations from[101⋯200], followed by α again for iterations [201⋯300] and4×αfor iterations[401⋯500], etc. After reaching the largest value8×αfor iterations[701⋯800],Tudrops again to α for the next 100 iterations and so on. This function repeats periodically this variation scheme every 1500 iterations. Similarly, we use the same strategy to tune the tabu tenureTv. At each iteration of the tabu search,Tvis set equal to0.7∗Tu.One notices that the tabu tenureTuforsu(the element leaving S) is larger than the tabu tenureTvforsv(the element joining S). This can be explained by the simple fact that in general, there are much fewer elements contained in S than inN⧹S(m<n). As a consequence, when an element becomes a part of the solution, we try to keep it in the solution for a longer period.As one observes, this tabu mechanism involves four different tabu tenures (α,2×α,4×αand8×α) which are applied with quite different frequencies: 8/15 for α, 4/15 for2×α, 2/15 for4×αand 1/15 for8×α. Since a shorter (longer) tabu tenure generally implies a more intensified (diversified) search, this tabu mechanism ensures most of the time an intensified examination of the search space followed by punctual diversification phases of different intensities. So if the search with the shortest tabu tenure α is trapped in a local optimum, the subsequent longer tabu tenure2×αis expected to bring the search out of the trap. If this is not sufficient, a still longer tabu tenures4×α, then8×αis applied to break the trap. Each time the search escapes from the local optimum, an intensification phase is resumed with the shortest tenure.Finally, we also experimented two additional tabu tenure methods in addition to the above dynamic tabu tenure method based on the periodic step function. The first one applies in a static way each of the four tabu tenures (α,2×α,4×αand8×α) during the whole search. The second method uses, at each iteration of the algorithm, a tabu tenure randomly taken from the 15-tuple(α,2×α,α,4×α,α,2×α,α,8×α,α,2×α,α,4×α,α,2×α,α). This second method shares similarities with our dynamic method in the sense that the shortest tabu tenure is used more frequently than the three other values. Yet this second method follows a random scheme to alter among the different tabu tenures while the dynamic method uses the periodic step function shown in Fig. 2. Experimental results showed that the dynamic method dominates both cases. Even if other tabu tenure methods would be envisaged, we will see in Section 3 that the adopted method is effective and robust and allows our algorithm to deliver highly competitive computational outcomes.Within the hybrid memetic framework, the crossover operator constitutes another important search operator (Neri et al., 2012). Its main goal is to create new promising candidate solutions by blending existing parent solutions, a solution being promising if it can potentially lead the search process to new search regions where better solutions may be found. For this reason, crossover plays basically an exploratory role which comes to complement the intensification role of the tabu search procedure. It is well known that even if random crossover operators (uniform, one-point, etc.) can be easily applied in the context of binary representation, such a blind operator can rarely guide the search process to effectively explore the most promising search regions. To be effective, a meaningful crossover operator is usually based on some pertinent properties (building blocks) of the given problem and a recombination mechanism to preserve these properties from parents to offspring (Hao, 2012, chap. 6).To identify “good properties” for MDP, we carried out a detailed analysis of samples of locally optimal solutions (see Section 4). This analysis discloses that high quality solutions share a large number of common elements that have high chances to be part of an optimal solution. Therefore, given two high quality solutions, it seems pertinent to preserve the shared elements (building blocks). Our proposed crossover operator follows this idea and operates as follows.Algorithm 3The crossover operator of the MAMDP algorithmRequire: Two parent solutionsS1andS2Ensure: One offspring solutionS01:S0←S1∩S2/*Build first a partial solution by preserving the common elements shared byS1andS2*/2: while|S0|<mdo3: Select fromS1⧹S0the element u with the highest potential with respect toS04:S0←S0∪{u},S1←S1⧹{u}5:if|S0|=mthen6: ReturnS0and Stop7:end if8: Select fromS2⧹S0the element v with the highest potential with respect toS09:S0←S0∪{v},S2←S2⧹{v}10: end while11: ReturnS0Given two parent solutionsS1andS2which are chosen randomly from the population, one offspring solutionS0is constructed as follows (see Algorithm 3). We build first a partial solution by preserving the common elements shared by the two selected parents, i.e.,S0=S1∩S2. Then we completeS0to obtain a feasible solution with a greedy procedure based on the potentialpidefined in Section 2.3.1. The greedy procedure extendsS0in a step-by-step way by adding at each step one element toS0untilS0contains exactly m elements. At the first step, we examine all the elements inS1⧹S0to identify the element with the highest potential with respect toS0and displace it fromS1⧹S0toS0. Afterward, we consider the elements inS2⧹S0, identify the element with the largest potential inS2⧹S0and add it toS0. Then at each step of this greedy procedure, we consider the elements inS1⧹S0andS2⧹S0in turn untilS0reaches the size of m. This offspring solution is usually of relatively high quality and has approximatively the same distance to its two parent solutions.The population updating rule decides whether an offspring solution, which is generated by the crossover operator and further improved by the tabu search procedure, should become a member of the population, and in the affirmative, which existing solution of the population should be replaced. Population management is an important issue since the population updating rule impacts directly the population diversity which conditions the convergence of the search algorithm.In our case, we wish to maintain a healthy diversity of the population during the search. For this purpose, we adopt an updating strategy which takes into account both quality and the distance between the solutions of the population (Lü, Glover, & Hao, 2010; Porumbel, Hao, & Kuntz, 2010). While the notion of quality can be easily understood with respect to the objective function, we need to formally define the notion of distance between solutions.Definition 1Distance between two solutionsGiven two solutionsSaandSb, the distancedist(Sa,Sb)betweenSaandSbis the minimum number of swap moves necessary to transformSbtoSa, i.e.,dist(Sa,Sb)=m-|Sa∩Sb|.Given a populationPop={S1,…,Sp}and the distancedist(Si,Sj)between any two solutionsSiandSj(i,j∈{1,…,p}andi≠j), the distance between a solutionSi(i=1,…,p) and the populationPopis defined as the minimum distance betweenSiand any other solution in the population:Population updating strategyRequire: Offspring solutionS0and PopulationPop={S1,…,Sp}Ensure: Updated populationPop={S1,…,Sp}1: Tentatively addS0to the population:Pop′=Pop∪{S0}2: fori=0,...,pdo3: Calculate the distance betweenSiandPop′according to Eq. (6)4: Calculate the goodness scoreH(Si,Pop′)ofSiaccording to Eq. (7)5: end for6: Identify the solutionSwwith the smallest goodness score inPop′:Sw=argmin{H(Si,Pop′)|i=0,…,p}7: if (Sw≠S0) then8: ReplaceSwwithS0:Pop=Pop∪{S0}⧹{Sw}9: end ifOur population updating strategy is described in Algorithm 4. To update the population, we first tentatively addS0to the population Pop, then we use the scoring function H to identify the solutionSwwith the smallest goodness scoreH(Si,Pop′)inPop′. IfSwis not the offspringS0, then the population is updated by replacingSwwithS0.In this section, we present an extensive assessment of the proposed MAMDP. For this purpose, we show experimental results obtained by MAMDP on a large collection of benchmark instances and make comparisons with the best performing MDP algorithms published in the literature.To evaluate the efficiency of the proposed approach, we carry out extensive experiments on the same sets of 120 test instances as in Palubeckis (2007), which are frequently used to assess algorithms for MDP. The details of the instance sets are described as follows (Duarte & Martí, 2007; Gallego et al., 2009; Martí et al., in press):•Silva instances: This data set consists of 20 instances, which were generated by Silva et al. (2004). The instance sizes are such that forn=100,m=10, 20, 30 and 40; forn=200,m=20, 40, 60 and 80; forn=300,m=30, 60, 90 and 120; forn=400,m=40, 80, 120, and 160; and forn=500,m=50, 100, 150 and 200. These instances can be downloaded from http://www.optsicom.es/mdp/.Random Type I instances (Type1_55, Type1_22 and Type1_52): These instances (60 in total) are based on matrices with real numbers generated from a (0, 10) uniform distribution. Random Type I was introduced by Duarte and Martí (2007) and includes 3 sets of instances. The first set (Type1_55) consists of 20 instances withn=500andm=50, the second set (Type1_52) includes 20 instances withn=500andm=200, and the third set contains 20 instances withn=2000andm=200. Random Type I instances are available at http://www.uv.es/∼rmarti/paper/mdp.html.Random Type II instances (Type2): These instances (20 in total) are based on matrices with real numbers generated from a (0, 1000) uniform distribution. This data set was introduced by Duarte and Martí (2007) and have size ofn=500andm=50. Random Type II instances can be downloaded from http://www.uv.es/∼rmarti/paper/mdp.html.Beasley instances (b2500): This data set consists of 10 instances, which were taken from the OR-Library (Beasley, 1996). All the instances have 10% density withm=2500andn=1000. These instances were used in Brimberg et al. (2009), Lozano et al. (2011), Palubeckis (2007), and Wang et al. (2012) to assess the MDP algorithms and are available at http://people.brunel.ac.uk/∼mastjjb/jeb/orlib/bqpinfo.html.Random larger instances (p3000 and p5000): These instances (10 in total) are based on matrices with integer numbers generated from a[0,100]uniform distribution. For these instances, the distance between some elements is equal to zero and the density of these instances (i.e., the percentage of the non-zero entries) is 10%, 30%, 50%, 80%, 100% respectively. There are five instances withn=3000andm=1500, and five instances withn=5000andm=2500. These instances were tested in Brimberg et al. (2009), Lozano et al. (2011), and Palubeckis (2007), Wang et al. (2012). See http://www.soften.ktu.lt/∼gintaras/max_div.html for the sources of the generator and input files to replicate these instances.The settings of the parameters used by our MAMDP algorithm are given in Table 1. These parameter values have been determined by performing a preliminary experiment on a selection of 10 hard instances (Type1_22.1, Type1_22.2, b2500-1, b2500-3, b2500-5, b2500-7, p3000_1, p3000_3, p5000_2 and p5000_3) which are randomly taken without bias from three groups of the largest benchmark instances (Type1_22, b2500, p3000 and p5000). Instances from these 3 groups are usually hard for the existing MDP algorithms (see Table 7) and are thus appropriate for the purpose of comparisons. We use these 10 selected instances for tuning our parameters as well as for the analysis of Section 4.To set the parameters, we first fix those required by the TS procedure (MaxIter, α) and then determine those used by the memetic algorithm (p,β). For (MaxIter, α), we test values for α in the range [5⋯25] and MaxIter in the range[5000⋯200,000]. For each of the 10 instances, we run the TS procedure 10 times, each run being limited to 60seconds. Table 2reports, for each instance and each parameter combination, the average solution gap to the previous best objective values (i.e.,fprev-favg) (wherefavgrepresents the average objective value obtained with the TS procedure).To see whether there exists significant performance differences in terms of solution quality among the compared parameter combinations of MaxIter and α, we apply the Friedman non-parametric statistical test followed by the Post-hoc test on the results from Table 2. This test calculates, for each problem instance, the rank value of each combination according to solution quality (where rank 25 is assigned to the best combination and rank 1 to the worst one). Then, it computes the average rank values of each combination across all the tested problem instances. The Friedman test reveals that there are statistically significant differences among the 25 tested parameter combinations (withp-value=6.457×10-8). Moreover, the largest 5 associated rank values produced in this experiment are ID13(19.9), ID12(19.5), ID18(18.5), ID23(17.9) and ID19(17.7). This test gives evidence for our choice to select the parameter combinationID13(MaxIter=50,000,α=15) for the TS procedure (see also Table 1). Furthermore, the Post-hoc analysis shows that our chosen setting ID13 (MaxIter=50,000,α=15) is significantly different from some other parameter combinations such asID1toID7,ID10,ID11,ID16andID21.To further investigate the performance of our TS procedure with 25 combinations of MaxIter and α, we show in Fig. 3the box and whisker plots which indicate, for each tested parameter combination, the distribution and range of the obtained results for the 10 used instances. For the sake of clarity, these results are expressed as the average solution gap to the previous best objective valuesfbestreported in the literature. From the box and whisker plot in Fig. 3, we observe a visible difference in the distribution of results among the data sets obtained with the compared combinations. From Fig. 3, we can also see that the five combinationsID13(with MaxIter=50,000 andα=15), ID12 (with MaxIter=50,000 andα=10),ID18(with MaxIter=100,000 andα=15),ID23(with MaxIter=2,000,000 andα=15) andID19(with MaxIter=1,000,000 andα=20) seem to be the most robust ones, since for these combinations, the average solution gaps to the previous best objective values are generally small and the deviations from the best-known results do not vary much from one instance to another.In addition to MaxIter and α, our algorithm requires two other parameters p andβ. We fixedp=10(small populations are often used in memetic algorithms) whileβ=0.6is chosen according to Lü et al. (2010). As we see below, the adopted parameter settings are good and robust enough to allow our algorithm to yield very competitive results for the sets of the tested instances compared with those reported in the literature.Our MAMDP algorithm is programmed in C and compiled using GNU GCC. All the experiments were carried out on a PC running Windows XP with an Intel Xeon E5440 processor (2.83gigahertz and 8gigabytes of RAM).In order to evaluate the relative effectiveness and efficiency of our proposed algorithm, we compared our MAMDP algorithm with 4 recent and best-performing MDP algorithms in the literature:•ITS: Iterated robust tabu search algorithm (2007) (Palubeckis, 2007).VNS: Variable neighborhood search algorithm (2009) (Brimberg et al., 2009).TIG: An fine-tuning iterated greedy algorithm (2011) (Lozano et al., 2011).LTS-EDA: Robust learnable tabu search guided by estimation of distribution algorithm (2012) (Wang et al., 2012).As reviewed and compared in the most recent survey (Martí et al., in press), ITS and VNS seem to be the most powerful algorithms for the MDP among 30 heuristic algorithms. TIG and LTS-EDA are two recently proposed algorithms and thus not included in the recent review (Martí et al., in press). However, experimental results show that TIG and LTS-EDA obtain better or competitive performance than VNS and ITS. Especially, LTS-EDA is able to reach new best solutions (Wang et al., 2012) for some larger random instances. Thus, these 4 reference algorithms are among the most successful approaches for solving MDP actually available in the literature.Moreover, these 4 reference algorithms are tested and compared very recently in Wang et al. (2012) under the same time limit on a Pentium R Dual-Core CPU E5400 processor (2.70gigahertz CPU and 2gigabytes of RAM). According to the Standard Performance Evaluation Cooperation (www.spec.org), this computer is 1.17 time slower than the computer we used for our experiments. To make the comparisons as fair as possible, we divide the cutoff times used in Wang et al. (2012) by 1.17 and use the reduced times as the stop condition for our MAMDP algorithm (see Table 3).First, let us comment that for the four groups of test instances (Silva, Type1_55, Type1_52 and Type2), our MAMDP algorithm can easily and consistently reach all the previous best known results with a success rate of 100% within the given time limits. These instances are easy for our MAMDP algorithm (and other state-of-the-art approaches). Consequently we don’t show the detailed results of these instances in the paper.Tables 4–6respectively show the computational statistics of the MAMDP algorithm on the other three groups of instances (Type1_22, b2500, p3000 and p5000) which are of larger sizes and harder to solve. In these tables, columns 1 and 2 respectively give the name of the instance and the previous best objective values (fprev). Note that the previous best objective values (fprev) are compiled from Tables 4, 6 and 7presented in Palubeckis (2007) and Tables 6 and 11 presented in Wang et al. (2012). To the best of our knowledge, these lower bounds are the current best known results for these instances.Columns 3–8 show our results: the best objective value (fbest), the best solution gap to the previous best known objective valuesgbest(i.e.,fbest-fprev), the average solution gap to the previous best objective valuesgavg(i.e.,favg-fprev) (wherefavgrepresents the average objective value), the standard deviation over the tested runs, the success rate (success) for reaching itsfbestvalue and the average CPU time in seconds (time) over the runs on which thefbestvalue is reached. Given that the MDP is a maximization problem, a negative value forgbestandgavgindicates an improved outcome compared to the current best known result.From Tables 4–6 as well as the results for the other four groups of instances (Silva, Type1_55, Type1_52 and Type2), we can see that for all these 120 instances, our MAMDP algorithm can reach the previous best known results within the time limits given in Table 3. Specifically, for 100 out of 120 instances (83%), MAMDP has a successful rate of 100%, attaining the best known objective value for each of its runs. More importantly, for 6 large and very challenging instances (p3000_1, p5000_1, p5000_2, p5000_3, p5000_4 and p5000_5), our MAMDP algorithm is able to improve on the previous best objective values.In order to further evaluate our MAMDP algorithm, in this section we compare our results with four MDP algorithms in the literature: ITS (Palubeckis, 2007), VNS (Brimberg et al., 2009), TIG (Lozano et al., 2011) and LTS-EDA (Wang et al., 2012). As stated previously in Section 3.3, these 4 reference algorithms are the best performing approaches for MDP currently available.Table 7 shows the best and average results of our MAMDP algorithm compared with the reference algorithms. The results of these 4 reference algorithms are compiled from Tables 6 and 11 from Wang et al. (2012). Note that the results of all these algorithms are obtained under the same time limit (see Section 3.3). Table 7 summarizes the solution difference between the best objective values and the average objective values obtained by these 5 algorithms with the best known objective values on the 40 large size benchmark instances with 2000–5000 elements.From Table 7, it may be observed that the MAMDP algorithm outperforms the 4 reference algorithms, named ITS, VNS, TIG and LTS-EDA. In terms of the best solution, MAMDP matches the best known values on 34 instances and finds new best solutions for 6 out of the 40 instances, while ITS, VNS, TIG and LTS-EDA matched the best known solutions on 2, 10, 5, 19 instances respectively. Concerning the average solution value, the results of our MAMDP algorithm remains competitive when compared with these 4 reference algorithms. Indeed, for each of these 40 instances, our MAMDP algorithm is able to reach an average solution value better than each of those 4 reference algorithms.In order to estimate the validity of our conclusion, we have applied two statistical tests to compare the average results of our MAMDP algorithm with those of the four reference algorithms. The first test is the non-parametric Friedman test. The resulting p-value of2.2×10-16obtained by this test clearly indicates that there are statistically significant differences among the average results obtained with the five compared methods. Moreover, the associated rank values produced in this experiment 5.0(MAMDP), 3.975(LTS-EDA), 2.275(TIG), 2.7(VNS) and 1.05(ITS) shows that our MAMDP algorithm outperforms the reference algorithms. The second test is the non-parametric Wilcoxon test for pairwise comparisons. For this test, the associatedp-value<0.05indicates that there are significant differences between two compared methods. When applying the Wilcoxon test to compare MAMDP with each of the four reference algorithms, we obtain a p-value of1.176×10-14for ITS,1.176×10-14for VSN,1.176×10-14for TIG and1.994×10-14for LTS-EDA respectively. These outcomes indicate that the observed differences between MAMDP and the 4 reference methods are statistically significant.In this section, we investigate the computational gain of the constrained neighborhood compared to the unconstrained neighborhood. In order to isolate the effect of the neighborhood, we use only the tabu search component of our memetic algorithm in this experiment. Precisely, we use CTS to denote the TS procedure using the constrained neighborhood as described in Section 2.3 and UTS to denote the TS procedure using the conventional unconstrained neighborhood. For UTS, at each iteration, it examines all the swap moves induced by S andN⧹Sand selects the overall best swap move to generate the next solution. All the other ingredients are kept the same for both CTS and UTS.Table 8summarizes the comparative results between CTS and UTS on the selection of the 10 hard instances. Both algorithms were run with the same number of neighborhood explorations (withMaxIter=50,000) on each instance. In Table 8, we indicate the computing time in seconds required by both algorithms to realize 50,000 iterations of neighborhood explorations. In addition, since the performance of CTS depends on the size of the two specifically identified subsets X and Y (see Section 2.3), we also indicate the size of these two subsets (averaged over 50,000 iterations) in Table 8. In the last column of Table 8, we show the ratio of the computing time between UTS and CTS.From Table 8, we can see that the constrained neighborhood drastically reduces the computing time of the tabu search procedure compared with the unconstrained neighborhood. Indeed, the reduction ratio ranges from 114.96 to 1280.83 for the 10 tested instances. Furthermore, the sizes of the two subsets X and Y of the constrained neighborhood are very small compared to sizes of S andN⧹S. This experiment confirms clearly the interest of the constrained neighborhood in accelerating the tabu search procedure.As indicated in Section 2.4, our proposed MAMDP algorithm employs a dedicated crossover operator which tries to preserve common elements that are shared by parent solutions. We carried out additional experiments to examine the influence of the crossover operator over the performance of our hybrid algorithm. For this purpose, we compare the performance of the MAMDP algorithm with its underlying TS algorithm. Furthermore, in order to highlight the role of the crossover operators, we weaken the underlying TS of MAMDP by reducing the number of tabu search iterations toMaxIter=500.Experiments were carried out on the selection of the 10 hard instances (Type1_22.1, Type1_22.2, b2500-1, b2500-3, b2500-5, b2500-7, p3000_1, p3000_3, p5000_2 and p5000_3). To solve each instance, we run both methods 20 times under exactly the same timeout limit, which was set to be 300seconds for each run. In order not to penalize the TS algorithm, we use a multi-start technique to restart it every 500 iterations whenever the timeout limit is not reached.Table 9presents the comparative results between MAMDP and TS on the 10 instances. For each instance, the following statistics are provided: the best solution gap to the previous best known objective valuesgbest(i.e.,fbest-fprev) and the average solution gap to the previous best objective valuegavg(i.e.,favg-fprev). From Table 9, we observe that for each of these 10 instances, MAMDP performs far better than its underlying TS in terms of both best and average solution values. Furthermore, we also note that although the performance of its underlying TS algorithm is poor, the results of the hybrid MAMDP algorithm remain competitive compared with the current best known results. Indeed, for 3 instances, the MAMDP algorithm is able to improve on the current best known results. This further confirms our conclusion that the crossover operator makes an interesting contribution to the overall performance of the hybrid algorithm.We demonstrated above that our proposed crossover operator makes a meaningful contribution to the overall performance of the hybrid algorithm. In this section, we provide empirical motivations for this crossover operator. For this purpose, we show an analysis on the structural similarity between local optima of various quality in terms of commonly shared elements. For two local optimaStandSs, we define their similarity assim(St,Ss)=|St∩Ss|m. We can see that the larger the similarity between two solutions, the more common elements they share.For this analysis, we employ the selection of the 10 hard instances used in the previous sections. For each instance, we collect 1000 local optima of different quality using our memetic algorithm as well as its underlying tabu search. Among these 1000 local optima, we select the top 10% (100) with the largest objective values and call them ‘high-quality solutions’. Similarly, we take the bottom 10% (100) with the smallest objective values and call them ‘low-quality solutions’.Table 10contains the data related to the similarity between our 1000 local optima. ColumnsShq,SallandSloreport respectively the average degree of similarity between the 100 high-quality solutions, the average degree of similarity between all the 1000 sampled local optima, and the average degree of similarity between the 100 low-quality solutions. From Table 10, we observe that in most cases, the degree of similarity between high-quality solutions is generally very large, from 0.52 to 0.89. High similarity indicates high quality solutions share a large number of common elements. Assume that high-quality solutions are close to an optimal solution or could themselves be optimal solutions, it is wise for a recombination operator to preserve the common elements shared by two (or more) high quality solutions. This is exactly what the proposed crossover operator undertakes to do.As shown in Section 2.5, our MAMDP algorithm uses a quality-and-distance replacement strategy (denoted by DisQual) for population updates to maintain the population diversity. In order to assess this strategy, we compare it with a traditional strategy (denoted by PoolWorst) which simply replaces the worst solution of the population by the new offspring solution. We show experimental evidences on the selection of the 10 hard instances to confirm the interest of the quality-and-distance replacement strategy. While keeping other ingredients unchanged in the MAMDP algorithm, Table 11summarizes the comparative results between these two population updating strategies. For both strategies, we use the same running conditions as described in Table 3.From Table 11, it can be observed that on the tested instances, MAMDP with DisQual matches or outperforms MAMDP with PoolWorst in terms of the best solution found. For one instance (p5000_2), MAMDP with DisQual is able to achieve a better objective value than with PoolWorst. Concerning the average solution value, MAMDP with DisQual is able to reach an average solution value better than with PoolWorst for 3 instances while a worse result only for one case. The comparative results indicate that MAMDP with DisQual is able to reach a slightly better performance than MAMDP with PoolWorst. However, the associated p-value of 0.179 with the Friedman test does not confirm a clear dominance of one strategy over the other.

@&#CONCLUSIONS@&#
