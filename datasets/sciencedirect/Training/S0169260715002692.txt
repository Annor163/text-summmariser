@&#MAIN-TITLE@&#
Bayesian segmentation of human facial tissue using 3D MR-CT information fusion, resolution enhancement and partial volume modelling

@&#HIGHLIGHTS@&#
Bayesian method provides resolution enhanced segmentation of human head.Segmentation classes incllude muscle, bone, fat, air and skin.Tests were performed on 3D MR and CT images, as well as registered MR-CT images.The most successful results were obtained by the information fusion of MR and CT.Free parameters of the algorithm can be adjusted in a more systematic way.

@&#KEYPHRASES@&#
Image segmentation,Information fusion,Partial volume,Resolution enhancement,Superresolution,Human facial tissue,

@&#ABSTRACT@&#
BackgroundAccurate segmentation of human head on medical images is an important process in a wide array of applications such as diagnosis, facial surgery planning, prosthesis design, and forensic identification.ObjectivesIn this study, a Bayesian method for segmentation of facial tissues is presented. Segmentation classes include muscle, bone, fat, air and skin.MethodsThe method presented incorporates information fusion from multiple modalities, modelling of image resolution (measurement blurring), image noise, two priors helping to reduce noise and partial volume. Image resolution modelling employed facilitates resolution enhancement and superresolution capabilities during image segmentation. Regularization based on isotropic and directional Markov Random Field priors is integrated. The Bayesian model is solved iteratively yielding tissue class labels at every voxel of the image. Sub-methods as variations of the main method are generated by using a combination of the models.ResultsTesting of the sub-methods is performed on two patients using single modality three-dimensional (3D) image (magnetic resonance, MR or computerized tomography, CT) as well as registered MR-CT images with information fusion. Numerical, visual and statistical analyses of the methods are conducted. High segmentation accuracy values are obtained by the use of image resolution and partial volume models as well as information fusion from MR and CT images. The methods are also compared with our Bayesian segmentation method proposed in a previous study. The performance is found to be similar to our previous Bayesian approach, but the presented methods here eliminates ad hoc parameter tuning needed by the previous approach which is system and data acquisition setting dependent.ConclusionsThe Bayesian approach presented provides resolution enhanced segmentation of very thin structures of the human head. Meanwhile, free parameters of the algorithm can be adjusted for different imaging systems and data acquisition settings in a more systematic way as compared with our previous study.

@&#INTRODUCTION@&#
Segmentation of human head images is an active research area. Result of the segmentation is useful in multiple applications such as simulation of facial expressions for craniofacial surgery planning [1], fusion of motion captured animations and muscle activation signals [2], forming a three dimensional (3D) facial biomechanical model for facial expression animations [3]. Measurement on facial tissue also plays a role in diagnosing, analysing and treating patients with neuromuscular disorders [4]. Calculating muscle volume is also a critical measurement for patients with hemifacial microsomia which is a congenital disorder that affects the lower half of the face [5]. Maxillofacial surgery is a surgery which focuses on treating defects and abnormalities in hard tissue of face. The need for preoperative predictions led to studies that involve person specific models [6]. Although computerized tomography (CT) or magnetic resonance (MR) images are generally used to segment facial tissue, there have also been studies which calculate masseter muscle volume from ultrasonography and analyze its relationship with facial morphology [7]. Craniofacial Surgery Planner software was the product of a study on simulation and prediction of craniofacial surgery [8]. Obtaining facial features also carries importance in forensics for the identification of an unknown body [9]. Measurement on the masseter muscle is critical for parameterizing the properties of head tissue in both forensics and anthropology [10]. Reconstruction of the head from medical images also has a critical role in dental treatments [11].On human head images, several techniques were applied to obtain tissue segmentation. One of the studies combined thresholding and morphological operations for skull segmentation in MR images [12]. Marching cubes is a method that obtains isosurfaces and it was used in a study to find bone, skin and tissue contours from CT and MR images [13]. Although using single modality or multiple modalities often yields reasonable segmentation accuracy, an extensive review on 3D image fusion processes in orthodontics and orthognathic surgery planning concludes that image fusion is the most accurate method for analysis [14]. Recently, a superresolution technique was applied on 3D MR images from sets of orthogonal images, acquired at a high in-plane resolution for automatic tongue muscle segmentation [15]. Semi-automatic methods were also used [16] to obtain 3D appearance of the lip muscles using MR image and the 3D Slicer software which is a framework for image visualization and processing [17]. Rezaeitabar and Ulusoy [18] suggested using a region growing algorithm which employed a Markov random field (MRF) model and works with manually placed seed points. Bayesian approach was also used. Shattuck et al. [19] proposed a method which includes a partial volume (PV) model to segment MR images after bias correction and skull removal. In their study, a maximum aposteriori (MAP) classifier with a Gibbs prior was used to estimate the voxel labels.MR has good soft-tissue contrast. However, CT is certainly superior for bone and air segmentation. CT has a better resolution than MR, and it also provides some soft-tissue contrast. MR-CT image fusion has been attempted by a few studies such as [13,14], in which fusion was in the form of extracting bone–air information from CT images and skin/soft-tissue information from MR images. However, considering that both modalities provide soft-tissue information and air–bone information (to a lesser extent by MR), an information fusion scheme where all available information from both modalities is utilized for every tissue type is certainly desirable, which was one of the aims of this study.The Bayesian MRF segmentation model presented in this study is an extension of the model described in [20]. Kale et al. [20] presented a Level Set and a Bayesian method with MR-CT information fusion and partial volume model. When the Bayesian and level set methods were compared, it was concluded that Bayesian result were better. However, there were shortcomings of the Bayesian method. In segmentation of very thin structures, system resolution (blurring) was a significant challenge. Due to this blurring, mean intensity of very thin structures (1–2 pixel thick) get close to their background intensity level, and hence segmented as background class. For that reason, an adaptive approach was developed using shifted mean tissue intensity values for the very thin structure regions. However, this approach is system and data acquisition setting dependent. Moreover, the difference in resolution of MR and CT was not modelled. Finally, CT image noise was not modelled properly, and the priors which could be potentially more useful were not tested.In this study, model extensions of our previous Bayesian method [20] were investigated to address all of the above issues: (i) a system resolution model and a resolution enhancement model for MR and CT were incorporated (which eliminates system or scan setting dependant ad hoc parameter tuning for the very thin structures); (ii) a more realistic CT image noise model (correlated) was used; (iii) an adaptive directional prior particularly targeted for very thin structures was adapted; (iv) the first two extensions required a different type of partial volume model which was also addressed. Finally, all methods were tested with and without information fusion of MR and CT images.

@&#CONCLUSIONS@&#
