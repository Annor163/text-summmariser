@&#MAIN-TITLE@&#
Continuous quadratic programming formulations of optimization problems on graphs

@&#HIGHLIGHTS@&#
Vertex separator problem is reformulated as a continuous bilinear quadratic program.Objective function has equal number of positive and negative eigenvalues.Objective function is convex on edges of constraint polyhedron.

@&#KEYPHRASES@&#
Vertex separator,Graph partitioning,Maximum clique,Continuous formulation,Quadratic programming,

@&#ABSTRACT@&#
Four NP-hard optimization problems on graphs are studied: The vertex separator problem, the edge separator problem, the maximum clique problem, and the maximum independent set problem. We show that the vertex separator problem is equivalent to a continuous bilinear quadratic program. This continuous formulation is compared to known continuous quadratic programming formulations for the edge separator problem, the maximum clique problem, and the maximum independent set problem. All of these formulations, when expressed as maximization problems, are shown to follow from the convexity properties of the objective function along the edges of the feasible set. An algorithm is given which exploits the continuous formulation of the vertex separator problem to quickly compute approximate separators. Computational results are given.

@&#INTRODUCTION@&#
This paper concerns discrete optimization problems on graphs and their formulation as continuous quadratic programming problems. The paper initially focuses on the vertex separator problem, but later observes that the analytical techniques developed to handle this problem are also applicable to other optimization problems on graphs including the edge separator, maximum clique, and the maximum independent set problems.Let G be a simple, undirected graph with verticesV={1,2,…,n},with edgesE⊂V×V, and with nonnegative vertex weightsc1,c2,…,cn, not all zero. Since the graph is undirected,(i,j)∈Eif and only if(j,i)∈E, and since the graph is simple, the elements ofEare distinct and(i,i)∉Efor anyi∈V. A vertex separator of G is a set of verticesSwhose removal breaks the graph into two disconnected sets of verticesAandB. That is,(A×B)∩Eis empty. The vertex separator problem (VSP) is to minimize the sum of the weights of vertices inSwhile requiring thatAandBsatisfy size constraints:(1.1)minA,B⊂V∑i∈ScisubjecttoS=V⧹(A∪B),A∩B=∅,(A×B)∩E=∅,ℓa⩽|A|⩽ua,ℓb⩽|B|⩽ub.Here|A|denotes the number of elements in the setA, andℓa,ua,ℓb, andubare given integer parameters that describe the flexibility in the size of the setsAandB. These parameters should be such that0⩽ℓa⩽ua⩽n⩾ub⩾ℓb⩾0. We assume that (1.1) is feasible. Ifℓa,ℓb⩾1, then this implies G is not complete; that is, for somei≠j∈V, we have(i,j)∉E. Vertex separators have applications to VLSI chip design (Kernighan & Lin, 1970; Leiserson, 1980; Ullman, 1984), to finite element methods (Miller, Teng, Thurston, & Vavasis, 1998), to parallel processing (Evrendilek, 2008), to the computation of fill-reducing orderings for sparse matrix factorizations (George & Liu, 1981), and to network security.An alternative definition of a vertex separator is sometimes used:Sis a vertex separator with respect toAandBif every path fromAtoBpasses through a vertex inS. This definition is helpful, since it generalizes to the notion of a wide separator, a separator in which every path fromAtoBpasses through at least two vertices ofS. While some authors give special treatment to wide separators (see for instance Pothen, Simon, & Liou, 1990 and references therein), it is worth noting that any method for finding vertex separators can also be used to find wide separators by simply adding edges to the graph. In particular, define an edge setEwbe letting(i,j)∈Ewif and only if i and j are connected by a path of length 1 or 2 in G. Note that ifAis the adjacency matrix for G defined byaij=1when(i,j)∈E, andaij=0otherwise, thenEwcorresponds to the nonzero off-diagonal elements ofA+A2. And ifEis replaced byEwin (1.1), then(A×B)∩Ew=∅if and only if every path fromAtoBpasses through at least two vertices inS.The difficulty of solving the VSP and the size of the optimal solution are strongly tied to the structure of the graph. For instance, every tree has an optimal vertex separator consisting of exactly one vertex. For planar graphs, Lipton and Tarjan showed that a separator of sizeO(n)can be found in linear time (Lipton & Tarjan, 1979). However, for general graphs (and even planar graphs), the VSP is NP-hard (Bui & Jones, 1992; Fukuyama, 2006). Hence, heuristic algorithms have been developed for obtaining approximate solutions; for example, see (Benlic & Hao, 2013; Djidjev, 2000; Evrendilek, 2008; Feige, Hajiaghayi, & Lee, 2008; Karypis & Kumar, 1995).In Balas and de Souza (2005), Cavalcante and de Souza (2007) and de Souza and Balas (2005), the authors studied the following exact integer programming formulation of the VSP:(1.2)maxx,y∈BncT(x+y)subjecttox+y⩽1,xi+yj⩽1for every(i,j)∈E,ℓa⩽1Tx⩽ua,andℓb⩽1Ty⩽ub.HereBn={0,1}nis the collection of binary vectors with n components,ciis the weight of vertexi,1is the vector whose entries are all 1, andxandyare the incidence vectors forAandBrespectively; that is,xi=1ifi∈Aandxi=0otherwise. Minimizing the weight of the separator is equivalent to maximizing the weightcT(x+y)of the vertices outside the separator. The componentwise inequalityx+y⩽1is the partition constraint, which ensures thatAandBare disjoint. The conditionxi+yj⩽1when(i,j)∈Eis the separation constraint, which ensures that(A×B)∩E=∅. Finally, the balance constraintsℓa⩽1Tx⩽uaandℓb⩽1Ty⩽ubrestrict the size of the setsAandB.In Balas and de Souza (2005) and de Souza and Balas (2005) the authors studied the program (1.2) in the case whereℓa=ℓb=1. Valid inequalities for the integer polytope of (1.2) were obtained and the program was solved on a variety of small (n⩽200) problem instances using a branch and cut algorithm. In Cavalcante and de Souza (2007) an improved algorithm was presented which made use of Lagrangian relaxation, improving the pool of cutting planes and providing better primal bounds for the nodes in the search tree.In the current paper, we develop conditions under which the VSP is equivalent to the following continuous bilinear quadratic program for some choice of the parameterγ>0:(1.3)maxx,y∈RncT(x+y)-γxT(A+I)ysubjectto0⩽x⩽1,0⩽y⩽1,ℓa⩽1Tx⩽ua,andℓb⩽1Ty⩽ub.We will show that the term-γxT(A+I)yin the objective function amounts to a penalty term for enforcing the separation constraint that there are no edges connectingAandB.We show that (1.3) is equivalent to the VSP if the following conditions are satisfied:(C1)γ⩾cifor all i.The total weight of an optimal vertex separator is less than or equal to(1.4)∑i=1nci-γ(ℓa+ℓb).The equivalence between the VSP and (1.3) is in the following sense: For any solution of (1.3), there is an associated, easily constructed binary solution. Moreover, when (C1) and (C2) hold, there exists a binary solution for which the penalty term vanishes and the separation constraint is satisfied. For such a solution, an optimal separator for the VSP is given by(1.5)A={i:xi=1},B={i:yi=1},andS={i:xi=yi=0}.In some applications such as finite element methods, parallel processing, and sparse matrix factorizations, it is important to obtain an approximate solution to the VSP quickly. We show in Section 7 how the continuous formulation may be incorporated into a multilevel algorithm for finding approximate solutions in a reasonable amount of CPU time. Multilevel algorithms have recently been shown to produce fast and high quality solutions to a variety of graph problems (Hendrickson & Leland, 1995; Karypis & Kumar, 1995; Safro, Ron, & Brandt, 2006a, Safro, Ron, & Brandt, 2006b). Other options for finding approximate separators include the use of standard optimization algorithms applied to (1.3), such as the gradient projection algorithm (see Bertsekas, 1999).In other applications where we need to solve (1.3) exactly, branch and bound techniques can be applied. For illustration, in Hager, Phan, and Zhang (2013) we develop a branch and bound algorithm for the closely related edge separator problem. The continuous formulation of the edge separator problem is the same as (1.3), but with the additional constraintx+y=1. In Hager et al. (2013) we show that a branch and bound algorithm applied to the continuous formulation of the edge separator problem is particularly effective for sparse graphs.As noted earlier, our continuous formulation of the VSP is in some sense an exact penalty method. In most exact penalty methods for solving binary maximization problems, the penalty function is chosen both to make the objective function convex, guaranteeing an extreme point solution (Bauer, 1958), and to force the extreme solution to be binary (Giannessi & Niccolucci, 1976; Raghavachari, 1969). Our penalty formulation differs in these two crucial aspects. In particular, if f is the objective function in (1.3):f(x,y)=cT(x+y)-γxT(A+I)y,then the Hessian is∇2f=-γ0BB0,B=A+I.Ifλi,1⩽i⩽n, are the eigenvalues ofB, then±γλi,1⩽i⩽n, are the eigenvalues of the Hessian. Hence, f is neither convex nor concave, and the number of positive eigenvalues of the Hessian is equal to the number of negative eigenvalues. Nonetheless, we will show that f is convex along the directions parallel to the edges of the feasible set in (1.3). Consequently, the existence of an extreme point maximizer follows from results of Tardella (1990). Furthermore, we show that every extreme point of the constraint polyhedron in (1.3) is binary, and if (C1) and (C2) hold, then there exists a binary maximizer of (1.3) such thatxT(A+I)y=0.The idea of exploiting convexity to obtain an extreme point solution to a continuous maximization problem has a long history. The first result of this type was due to Bauer (1958): The maximum value of a convex function over a compact, convex set is attained at an extreme point of the set. (Also see Rockafellar (1970, Thm. 32.3) and Hirsch & Hoffman (1961)). In a seminal paper, Raghavachari (1969) applied this result to the following binary linear program:(1.6)maxx∈BncTxsubjecttoBx⩽b.Herec∈Rnis an arbitrary vector,b∈Rm, andB∈Rm×n. Observe that the binary constraintx∈Bnis equivalent to the quadratic constraintxT(1-x)=0, where1∈Rnis the vector of all ones. Raghavachari showed that for sufficiently largeγ⩾0, (1.6) is equivalent to the following continuous penalized problem:(1.7)maxx∈RncTx-γxT(1-x)subjecttoBx⩽b,0⩽x⩽1.Since the penalized objective in (1.7) is convex, Bauer’s theorem guarantees that (1.7) has an extreme point solution. Furthermore, whenγis sufficiently large, Raghavachari shows that the penalty term is zero, which implies that the solution is binary.Raghavachari’s result was generalized to nonlinear binary programming problems by Giannessi and Niccolucci (1976). Lower bounds onγwere obtained by Kalantari and Rosen (1987) and Borchardt (2007). More recently, Zhu (2003) found improved lower bounds onγin the case where the objective is quadratic. Alternative choices of the penalty function were considered by Lucidi and Rinaldi (2010) and Rinaldi (2009).As noted by Murray and Ng (2007), one problem with convex formulations of discrete maximization problems is the astronomical number of local maximizers that are created by making the problem convex. When a continuous optimization algorithm is applied to these programs, the iterates typically converge to a stationary point, and hence any one of these local maxima can trap the iterates. On the other hand, since the penalty function in (1.3) is non-convex, the number of local maxima is reduced. Moreover, the program (1.3) has the property that local maximality can be determined in polynomial time as we show in Hager and Hungerford (2013), while for a general indefinite quadratic program, determining whether a stationary point is a local maximizer is NP-hard (Murty & Kabadi, 1987; Pardalos & Schnitger, 1988).At least three other NP-hard optimization problems on graphs have been formulated as continuous quadratic programs: the edge separator problem (Hager & Krylyuk, 1999), the maximum clique problem (Abello, Butenko, Pardalos, & Resende, 2001; Motzkin & Straus, 1965), and the maximum independent set problem (Harant, 2000). As we show in Sections 4–6, the principle underlying these formulations is essentially the same as that of the vertex separator formulation (1.3). In particular, all of these formulations implicitly exploit the fact that the objective function, when expressed as a maximization, is convex along edges of the feasible set. Moreover, in each case a path can be constructed along these edge directions where the function is convex from a given optimal solution of the continuous quadratic program to another optimal solution which corresponds to an incidence vector of an optimal partition or an optimal set in the graph problem.Recently, Povh and Rendl (2007) developed a completely positive linear programming formulation for a minimum cut problem in whichVis partitioned into three sets of given size such that the number of edges between two of these sets is minimized. The graph partitioning problem is a special case of their minimum cut problem corresponding to setting the size of one of the sets to 0. They reformulate the minimum cut problem as a linear program over the cone of completely positive matrices. Moreover, Burer (2009) shows that any mixed integer quadratic program (such as (1.2) or (1.3)) can be formulated as a completely positive linear program. While formulating a discrete problem as a completely positive program does not improve the problem’s tractability, it does provide an avenue for obtaining tractable relaxations (see for instance Povh & Rendl, 2007). A survey of copositive programming is given in Bomze (2012).In Section 2 we give a constructive proof of the equivalence between the continuous bilinear program (1.3) and the integer program (1.2). The proof basically provides an easily implemented algorithm to transform a solution of the continuous program (1.3) into a solution of the binary vertex separator problem (1.2). As pointed out above, there are connections between our continuous formulation of the vertex separator problem and work of Tardella (1990). In particular, we show in Section 3 that the existence of a binary vertex solution for (1.3) follows from the convexity of the objective function along the edges of the constraint polyhedron. In Sections 4–6, we use the concept of edge-convexity to analyze known continuous quadratic programming formulations for the edge separator, maximum clique, and maximum independent set problems. Section 7 shows how the continuous formulation (1.3) of the VSP may be incorporated in a multilevel algorithm in order to quickly approximate an optimal separator. Computational experiments are performed to compare our algorithm with METIS (Karypis & Kumar, 1995) and a recent breakout local search algorithm due to Benlic and Hao (2013).Notation. 0 and 1 denote vectors whose entries are all 0 and all 1 respectively. Their dimension should be clear from context.∇f(x)denotes the gradient of f, a row vector, and∇2f(x)denotes the Hessian of f. For a setZ,|Z|is the number of elements inZ.Ris the set of real numbers andB={0,1}is the set of binary numbers. Ifxandy∈Rn, then[x,y]denotes the vector inR2nobtained by stackingxabovey.ei∈Rndenotes the ith column of then×nidentity matrix. IfA∈Rm×nandI⊂{1,…,m}, thenAIdenotes the submatrix corresponding to the row numbersi∈I. Ifx∈Rn, then the support ofxis defined bysupp(x)={i:xi≠0}.IfAis a set, thenAcis its complement.Let G be an undirected graph on vertex setV={1,2,…,n}with vertex weightsci⩾0not all zero. Let0⩽ℓa⩽ua⩽nand0⩽ℓb⩽ub⩽nbe integers.We start by considering the integer programming formulation of the VSP (1.2), which we restate here for convenience:(2.1)maxx,y∈BncT(x+y)subjecttox+y⩽1,xi+yj⩽1forevery(i,j)∈E,ℓa⩽1Tx⩽ua,andℓb⩽1Ty⩽ub.Recall thatciis the weight of vertex i, andxandyare the incidence vectors forAandBrespectively; that is,xi=1ifi∈Aandxi=0otherwise.Suppose thatxandy∈Bn, and defineA=supp(x)andB=supp(y)be the associated supports. The partition constraintA∩B=∅in (1.1) or the conditionx+y⩽1in (2.1) is equivalent to(2.2)xTy=0.Furthermore, ifAis the adjacency matrix for the graph G defined byaij=1if(i,j)∈E0if(i,j)∉E,then the productxTAycounts the number of edges betweenAandB:(2.3)xTAy=∑i=1n∑j=1nxiaijyj=∑xi=1∑yj=1aij=∑i∈A∑j∈Baij=|(A×B)∩E|.Hence, the separation constraint(A×B)∩E=∅in (1.1) orxi+yj⩽1in (2.1) is equivalent to the condition(2.4)xTAy=0.Since the entries inx,y, andAare all non-negative, (2.2) and (2.4) both hold if and only ifxT(A+I)y=0.Therefore, the vertex separator problem (1.1) or (2.1) is equivalent to the following binary program:(2.5)maxx,y∈BncT(x+y)subjecttoxT(A+I)y=0,ℓa⩽1Tx⩽ua,andℓb⩽1Ty⩽ub.In particular, if(x,y)is a solution to (2.5), then a solution to the vertex separator problem (1.1) is(2.6)A={i:xi=1},B={i:yi=1},andS={i:xi=yi=0}.Now consider the following continuous penalized problem:(2.7)maxx,y∈RncT(x+y)-γxT(A+I)ysubjectto0⩽x⩽1,0⩽y⩽1,ℓa⩽1Tx⩽ua,andℓb⩽1Ty⩽ub.For anyγ⩾0the optimal objective function value in the continuous program (2.7) is at least as large as the optimal value in the binary vertex separator problem (2.5) since there are more constraints in the binary problem – that is, the variables in the relaxed problem (2.7) can have any value between 0 and 1, while in (2.5) it is required thatxT(A+I)y=0. We now show that for an appropriate choice ofγ, the relaxed problem (2.7) and the binary problem (2.5) are equivalent.Theorem 2.1Suppose the vertex separator problem(1.1)is feasible. Letγ∈R.1.The continuous program(2.7)has a binary solution.Every strict local maximizer of(2.7)is binary.If (C1) and (C2) hold, then there exists a binary solution(x,y)to problem(2.7)such that(2.8)xT(A+I)y=0.Moreover, ifγ>max{ci:i∈V}, then every binary solution satisfies(2.8).For any binary solution(x,y)of(2.7)satisfying the condition(2.8), an optimal solution to the vertex separator problem(1.1)isA={i:xi=1},B={i:yi=1},andS={i:xi=yi=0}.We partition the proof into the four parts of the theorem.Part 1. We prove the following stronger result:(P)For any(x,y)feasible in (2.7), there exists an easily constructed feasible point[xˆ,yˆ]∈B2nsuch thatf(xˆ,yˆ)⩾f(x,y).Ifxandyare binary, then (P) holds and we are done. Otherwise, eitherxoryis not binary. Without loss of generality, suppose thatxis not binary.Case 1: Suppose thatxhas exactly one non-binary componentxk. Sinceℓaanduaare integers, we cannot have1Tx=ℓaor1Tx=uasince the sum ofn-1binary numbers and a number in the open interval(0,1)cannot be an integer. Hence the point(x+tek,y)is feasible for all sufficiently small|t|. Let f denote the objective function of (2.7):(2.9)f(x,y)=cT(x+y)-γxT(A+I)y.Since f is bilinear,f(x+tek,y)=f(x,y)+tdfor some scalar d. Ifd⩾0, then chooset>0such thatxk+t=1. Ifd<0, then chooset<0such thatxk+t=0. This takes us to a feasible point(xˆ,y)such thatxˆ∈Bnandf(xˆ,y)⩾f(x,y).Case 2: Supposexhas at least two non-binary components i and j. For sufficiently small|t|the point(x+t(ei-ej),y)is feasible in (2.7) since the constraintℓa⩽1Tx⩽uais unaffected. Again, since f is bilinear,f(x+t(ei-ej),y)=f(x,y)+tdfor some scalar d. Ifd⩾0, then choose the smallestt>0such thatxi+t=1orxj-t=0. Ifd<0, then choose the largestt<0such thatxi+t=0orxj-t=1. The point(x¯,y)=(x+t(ei-ej),y)is feasible, it has at least one more binary component than(x,y), and it satisfiesf(x¯,y)⩾f(x,y). We may iterate this procedure, making non-binary components ofx¯binary without decreasing the objective value, until we reach a point(xˆ,y)such that eitherxˆ∈Bnorxˆhas a single non-binary component, which reduces to Case 1.The same procedure can be applied toyto complete the proof of (P) and part 1.Part 2. This follows from the proof of Part 1. If a strict local maximizer is not binary, then the construction in Part 1 shows how to move to a binary point without decreasing the objective function value. Hence, a strict local maximizer must be binary.Part 3. Suppose (C1) and (C2) hold. Let(x,y)be a binary solution to problem (2.7). Sincex,y, andAare nonnegative, we havexT(A+I)y⩾0. Suppose that(2.10)xT(A+I)y>0.Since the objective function in (2.5) is the weight of the nodes outside a separator, it follows that(2.11)maxin(2.5)=∑i=1nci-min weight of vertex separator⩾γ(ℓa+ℓb),where the inequality is due to (C2). Since the objective function valuef(x,y)in the relaxed problem (2.7) is at least as large as the maximum in (2.5), it follows from (2.11) thatγ(ℓa+ℓb)⩽f(x,y)=cT(x+y)-γxT(A+I)y<cT(x+y)⩽γ1T(x+y).The strict inequality is due to (2.10), and the last inequality is due to the constraint onγ. Therefore, we must have either1Tx>ℓaor1Ty>ℓb.Assume without loss of generality that1Tx>ℓa. Sincexis binary andℓais an integer, we have1Tx⩾ℓa+1.Since the entries inx,y, andAare all non-negative integers, (2.10) implies that there exists an index i such that(A+I)iy⩾1andxi=1(recall that subscripts on a matrix correspond to the rows). Ifxˆ=x-ei, then(xˆ,y)is feasible in problem (2.7) since1Txˆ=1Tx-1⩾ℓa. Furthermore,(2.12)f(xˆ,y)=f(x,y)-ci+γ(A+I)iy⩾f(x,y)-ci+γ⩾f(x,y),since(A+I)iy⩾1andγ⩾ci. Since(x,y)was optimal in (2.7), so is(xˆ,y). We can continue to set components ofxandyto 0 until reaching a binary feasible point(xˆ,yˆ)for whichxˆT(A+I)yˆ=0andf(x,y)=f(xˆ,yˆ). Ifγ>max{ci:i∈V}, then (2.12) is a strict inequality, which contradicts the optimality of(x,y)in (2.7). Hence,xT(A+I)y=0, and the proof of Part 3 is complete.Part 4. A binary solution of the relaxed problem (2.7) satisfying (2.8) is feasible in the discrete problem (2.5). Moreover, the objective function values in the relaxed problem and in the discrete problem are the same. Hence,(x,y)is optimal in the discrete version (2.5) of the vertex separator problem, and a solution of the vertex separator problem is given by (2.6). This completes the proof of Part 4.□We now explain connections between Theorem 2.1 and earlier work of Tardella (1990), which yields some deeper insights on the relationship between the discrete and continuous formulations of the vertex separator problem. In particular, we will show that Part 1 of Theorem 2.1 follows from edge convexity of the objective function of (2.7).Given a matrixB∈Rm×nand a vectorb∈Rm, we define a polyhedron(3.1)P={x∈Rn:Bx⩽b}.A face ofPis a non-empty setH={x∈P:BIx=bI}for someI⊂{1,…,m}. The dimension of a faceH, denoteddim(H), is one less than the maximum number of affinely independent points in the face. Ifdim(H)=1, thenHis an edge ofP, and ifdim(H)=0, thenHis a vertex ofP. Note that a pointv∈Pis a vertex if and only if there exist n linearly independent constraints which are active atv. For the remainder of this section, we use the word vertex only in the sense defined above (an extreme point of a polyhedron).Definition 3.1LetP⊂Rnbe a polyhedron, letEbe an edge ofP, and letd∈Rn. We say thatdandEare parallel if for somex∈E, there exists somet≠0such thatx+td∈E. A setDis an edge description ofPif for each edge ofP, there is a parallel direction inD.f:P→Ris convex alongd∈Rnif for eachx∈P,f(x+td)is a convex function oft∈{s∈R:x+sd∈P}.The following theorem follows directly from Proposition 2.1 and Corollary 3.1.1 of Tardella (1990):Theorem 3.2LetP⊂Rnbe a polyhedron, and letDbe an edge description ofP. Iff:P→Rattains its maximum onPand f is convex along eachd∈D, then f attains its maximum at a vertex ofP.The polyhedronQwhich defines the feasible set in problem (2.7) isQ={[x,y]∈R2n:0⩽x⩽1,0⩽y⩽1,ℓa⩽1Tx⩽ua,ℓb⩽1Ty⩽ub}.To prove that problem (2.7) has a binary solution, we will show that the vertices ofQare precisely the binary feasible points and that the edge convexity condition of Theorem 3.2 is satisfied. For convenience, we refer to the constraints0⩽x⩽1and0⩽y⩽1as the component constraints ofQ, and the constraints on1Txand1Tyas the balance constraints ofQ.Lemma 3.3The set of vertices ofQisQ∩B2n.If[x,y]∈Q∩B2n, then2ncomponent constraints are active at[x,y]; since these constraints are linearly independent,[x,y]is a vertex ofQ. Conversely, suppose that[x,y]is a vertex ofQ. The constraints definingQcan be written in the formBx⩽bwhereBis totally unimodular andbis integer. As a consequence, the vertices ofQare integer vectors. Due to the component constraints, the vertices are binary vectors. Another proof of the converse, which is exploited in the next lemma, is as follows: At a vertex[x,y]ofQ,2nlinearly independent constraints are active. Due to the separable form of the constraints, there are n active linearly independent constraints on each ofxandy. If the n active constraints onxare component constraints, thenxis binary. If there aren-1active component constraints atxalong with a constraint of the form1Tx=ℓaor1Tx=ua, then the single fractional component ofxmust be binary sinceℓaanduaare integer. A similar argument applies toy. □LetD⊂R2nbe defined by(3.2)D=⋃i,j=1i≠jn{[ei,0],[0,ei],[0,ei-ej],[ei-ej,0]}.Lemma 3.4Dis an edge description ofQ. That is, for every edgeEofQ, there exists somed∈Dsuch thatdis parallel toE.LetEbe the edge ofQdefined byE={[x(t),y(t)]:t∈[0,1]},where[x(t),y(t)]=v1+t(v2-v1)andv1=(x1,y1)andv2=(x2,y2)are vertices ofQ. We first show that eitherx1=x2ory1=y2. Suppose to the contrary thatx1≠x2andy1≠y2. Then there exist indices i and j such thatxi1≠xi2andyj1≠yj2. Sincev1andv2are binary by Lemma 3.3, it follows that(3.3)0<xi(t)<1and0<yj(t)<1for allt∈(0,1). In the proof of Lemma 3.3, we saw that when n of the constraints definingQare active atx∈Rn, thenxis binary. Hence, by (3.3), there are at mostn-1constraints active atx(t)and at mostn-1constraints active aty(t)for eacht∈(0,1). Thus, for anyt∈(0,1)the total number of constraints active at(x(t),y(t))is at most2n-2, which contradicts the fact thatEis an edge (for which2n-1constraints should be active). Hence, eitherx1=x2ory1=y2.Suppose, without loss of generality, thaty1=y2.x1andx2can differ in at most two components, since otherwise the edgeEwould contain a point in its relative interior at which less than2n-1linearly independent constraints are active. If there is only one index i such thatxi1≠xi2, thenEis parallel to the vector(ei,0)∈D. If there are two indicesi≠jfor whichx1andx2differ, then the balance constraint on1Txmust be active alongE, since otherwiseEwould contain a point at which only2n-2linearly independent constraints were active. Since the balance constraint is active,1Tx(t)is independent of t. Since all the components ofx(t)are fixed except forxi(t)andxj(t), it follows thatxi(t)+xj(t)is independent of t. Hence, asxi(t)increases,xj(t)decreases. Sincexi(t)andxj(t)are convex combinations of 0 and 1, it follows that the edge is parallel to(ei-ej,0)∈D. Ifx1=x2, then a similar argument shows thatEis parallel to either(0,ei)∈Dor(0,ei-ej)∈Dfor some i and j.□For anyγ, the problem(1.3)has a binary solution.By Lemma 3.4,Din (3.2) is an edge description ofQ. Letf:Q→Rdenote the objective function of (1.3) defined in (2.9). It can be checked thatdT∇2f(x,y)d=0for alld∈D. Hence, f is convex along the edges ofQ, and by Theorem 3.2, f attains its maximum overQat a vertex ofQ. By Lemma 3.3, this vertex is binary. □Remark. The fact that (1.3) has a binary solution may be viewed as a consequence of a more general result due to Konno (see Konno, 1976, Theorem 2.1), which gives conditions under which a general bilinear program has an extreme point solution.In this section, we compare and contrast the formulation (1.3) with a continuous formulation of the edge separator problem given in Hager and Krylyuk (1999). Given non-negative integersl⩽u, the edge separator problem on G is to partition the vertex setVinto two setsAandAcsuch thatℓ⩽|A|⩽uand the number of edges connecting vertices inAandAcis minimized. The edge separator problem is NP-hard (Fukuyama, 2006).In Hager and Krylyuk (1999), the authors demonstrate that the edge separator problem is equivalent to the continuous quadratic program(4.1)minx∈Rn(1-x)T(A+I)xsubjectto0⩽x⩽1,ℓ⩽1Tx⩽u.In particular, there exists a binary solution to (4.1) such that an optimal partition is given by(4.2)A={i:xi=0}andAc={i:xi=1}.Observe that (4.1) may be obtained from (1.3) by imposing the additional constrainty=1-xand lettingℓb=0andub=n. Hence, in a sense the edge separator problem is a constrained version of the vertex separator problem.The argument given in Hager and Krylyuk (1999) for the validity of the formulation (4.1) is similar to the proof of Parts 1 and 4 of Theorem 2.1, and implicitly exploits the concavity of the objective function along the edges of the feasible set. IfQdenotes the feasible set of (4.1), it is easily verified that an edge description forQis given byD=⋃i,j=1i≠jn{ei,ei-ej}.(The proof is along the lines of Lemma 3.4). The concavity of the objective function along the directions inDis verified by checking the signs of the second derivatives:-eiT(A+I)ei=-1⩽0and-(ei-ej)T(A+I)(ei-ej)=-2+2aij⩽0,sinceaijis either 1 or 0. Therefore, the existence of a binary solution to (4.1) follows from Theorem 3.2 and the proof of Lemma 3.3. By (2.3), for any binary feasible point in (4.1), the objective function counts the number of edges between the setsAandAcdefined by (4.2). Thus, any binary optimal solution to (4.1) gives a feasible partition which minimizes the number of edges betweenAandAc, and hence solves the edge separator problem.Necessary and sufficient local optimality conditions for (4.1) and (1.3) are derived using the theory of edge-convexity in Hager and Hungerford (2013). A branch and bound algorithm for solving (4.1) exactly is given in Hager et al. (2013).In this section, we use the tools of Sections 2 and 3 to analyze a continuous formulation of the maximum clique problem on a graph due to Motzkin and Straus (1965). A clique in a graphG=(V,E)is a complete subgraph; that is, a subset of verticesC⊂Vsuch that(i,j)∈Efor every pairi,j∈C, wherei≠j. The maximum clique problem on G is to find a cliqueCwith maximum cardinality|C|. NP-hardness of the maximum clique problem is established in Karp (1972).In Motzkin and Straus (1965), Motzkin and Straus showed that the maximum clique problem is equivalent to the following continuous quadratic program:(5.1)maxx∈RnxTAxsubjecttox⩾0and1Tx=1,whereAis the adjacency matrix for G. More precisely, there exists a solutionxto (5.1) such that(1)Every nonzero component ofxis equal to1/k, where k is the maximum cardinality of a clique in G.The setC=supp(x)is a clique of size k.As in Lemma 3.4, an edge description for the feasible set in (5.1) is given byD=⋃i,j=1i≠jn{ei,ei-ej}.However, since(ei-ej)TA(ei-ej)=-2aij⩽0,the objective function for (5.1) is concave along the edges of the constraint polyhedron. In contrast, our analysis of the vertex separator problem exploited the convexity of the objective function along the edges of the constraint polyhedron. Hence, it appears that the techniques developed in the previous sections are not applicable to the maximum clique problem. Nonetheless, we will show that these techniques are still applicable when used in a selective way. For convenience in the discussion, let us rescalexand focus on the problem(5.2)maxx∈RnxTAxsubjecttox⩾0and1Tx=k,where k is the cardinality of a maximum clique. Note thatxis a solution of (5.1) if and only ifkxis a solution of (5.2). Thus, the solutions of (5.1) satisfying (1) and (2) correspond to binary solutions of (5.2).Motzkin and Straus’ proof (Motzkin & Straus, 1965) of the equivalence between (5.1) and the maximum clique problem is by induction on|V|. Since then, continuous characterizations of the maximum clique problem, including non-inductive proof techniques, have been extensively studied (see, for instance Bomze, 1997; Bomze, Pelillo, & Giacomini, 1997; Gibbons, Hearn, & Pardalos, 1993; Gibbons, Hearn, Pardalos, & Ramana, 1997; Pelillo & Bomze, 1996). In order to highlight the connections between the formulations (5.1) and (2.7), we offer a direct proof of the validity of formulation (5.1) below.Theorem 5.1There exists a binary optimal solution of(5.2), and for any binary optimal solutionx,C=supp(x)is a maximum clique.First, observe that for any binary feasible pointxin (5.2),|supp(x)|=k. By (2.3)xTAxis twice the number of edges between vertices in supp(x). Since there is a maximum clique of size k by assumption, the optimal objective value in (5.2) isk(k-1). Therefore, for any binary optimal solution of (5.2),supp(x)is a maximum clique. This proves the second half of the theorem.Now we will prove that (5.2) has a binary optimal solution. Letxbe any optimal solution withP=supp(x)as small as possible in size. We consider two cases.Case 1:aij=1for everyi,j∈Pwherei≠j. In other words,Pis a clique. In this case, the objective value atxmay be expressed(5.3)xTAx=∑i∈P∑j∈Pxiaijxj=∑i∈P∑j∈Pj≠ixixj=∑i∈Pxi2-∑i∈Pxi2=k2-∑i∈Pxi2,where the last equality follows from feasibility ofx. Sincexis a maximizer in (5.2), (5.3) implies thatxsolves the following problem:(5.4)min∑j∈Pxj2:∑j∈Pxj=k,xj=0forallj∉P.But by strict convexity of the objective in (5.4), the unique minimizer hasxi=k/|P|for eachi∈P. So, by (5.3) the objective value atxisxTAx=k2(1-1/|P|).Since there is a clique of size k, and the incidence vector associated with this clique has an objective valuek(k-1), the optimality ofximplies thatxTAx⩾k(k-1). Thus,|P|⩾k. SincePis a clique and k is the size of a maximum clique, we have|P|⩽k. Hence,|P|=k, which implies thatxi=1for eachi∈P; that is,xis binary.Case 2: There exist verticesi,j∈P,i≠j, such thataij=0. Definex(t)=x+t(ei-ej), whereei∈Rnis the ith column of then×nidentity matrix, and letg(t)=x(t)TAx(t). Sincex(0)is a maximizer of (5.2), we haveg′(0)=0. By direct computation,g″(0)=-4aij=0. Hence, we may increase t from zero without violating feasibility or changing the objective value untilxj(t)=0. This violates the assumption that the support ofPwas as small as possible. Hence, Case 2 cannot occur.□Based on the proof of Theorem 5.1, a solution of the maximum clique problem corresponds to a solution of (5.1) or (5.2) with the smallest possible support. Given an arbitrary solution of (5.2), the size of the support is reduced by choosingi≠j∈supp(x)such thataij=0, and moving along the edge directionei-ej. As seen in Case 2, the objective function is convex along each of these edge directions sinceaij=0. Ifaij=1for everyi≠j∈P, then there are no more available edge directions along which the objective is convex, the support is minimal, and a maximum clique is given bysupp(x).A complementary notion to a clique in a graph is an independent set, a collection of verticesI⊂Vwhich are mutually nonadjacent; that is,(i,j)∉Efor everyi,j∈Iwithi≠j. The maximum independent set problem on G is to find a maximum cardinality independent set in G. Like the maximum clique problem, the maximum independent set problem is NP-hard (Garey & Johnson, 1979).Ifx∈BnandI=supp(x), then by (2.3) withy=x,12xTAxis the number of edges between vertices inI. Hence,Iis an independent set if and only ifxTAx=0, and the maximum independent set problem can be formulated as(6.1)maxx∈Bn1TxsubjecttoxTAx=0.Now consider the following penalized problem in which the binary constraint is relaxed:(6.2)maxx∈Rn1Tx-12xTAxsubjectto0⩽x⩽1.The following theorem is due to Harant (2000). The proof we offer below is a reinterpretation of an algorithm given in Remark 2 of Harant (2000) from the point of view of edge-convexity. Theorem 6.1 should be compared to Theorem 2.1.Theorem 6.11.There exists a binary optimal solution to(6.2)such that(6.3)xTAx=0.For any binary optimal solutionxsatisfying(6.3), a maximum independent set in G is given byI=supp(x).Part 1: An edge description of the feasible set of (6.2) is simplyD=⋃i=1n{ei}.Since the diagonal ofAvanishes,eiTAei=0for all i. Hence, the objective function in (6.2) is convex along the edges of the constraint polyhedron. By Theorem 3.2, (6.2) has a binary optimal solutionx. Now letI=supp(x). Ifaij=0for all i andj∈I, then (6.3) holds and we are done. So suppose instead thataij=1for some i andj∈I. Sincexis binary,xixjaij=1. Hence, ifxiis decreased from 1 to 0, then1Txdecreases by 1,12xTAxdecreases by at least 1 (due to the symmetry ofA), and the objective function can only increase. Hence, sincexis optimal in (6.2), the objective function does not change asxiis dropped from 1 to 0. Continue to drop components ofxto 0 untilaij=0for all i andj∈supp(x). Then (6.3) holds, and the proof of Part 1 is complete.Part 2: Any binary optimal solutionxsatisfying (6.3) is feasible in (6.1), and therefore must be optimal in (6.1) since that problem has more constraints.□As indicated in Section 1, the continuous formulation (1.3) of the vertex separator problem may be incorporated in either a branch and bound algorithm to find a best separator as in Hager et al. (2013), or in an algorithm to quickly compute an approximate vertex separator. In applications, such as sparse matrix reorderings, it is often more desirable to find an approximate separator quickly than to spend additional CPU time finding an exact solution. Therefore, the goal of this section is to incorporate (1.3) into a new algorithm for finding approximate solutions to the VSP in a reasonable amount of computation time. This balance of solution quality and running time is achieved in part through the use of a multilevel framework: the original graph G is approximated by a hierarchy of coarser graphs having successively fewer degrees of freedom, while preserving the overall structure of G. The problem is solved for the coarsest graph, and this coarse solution is propagated back up the hierarchy to obtain a solution for the original graph. Multilevel graph algorithms have recently been shown to produce fast and high quality solutions to a variety of graph problems in the literature (Hendrickson & Leland, 1995; Karypis & Kumar, 1995; Safro et al., 2006a, 2006b).Multilevel graph algorithms consist of three phases: coarsening, solving, and uncoarsening. In the coarsening phase of our algorithm, vertices are visited one after another and each vertex is matched with an unmatched neighbor. Matched vertices are merged to form a single vertex in the coarser graph with a vertex weight equal to the sum of the weights of the matched vertices. During this coarsening process, multiple edges may arise between vertices in the coarse graph. Conceptually, these edges are combined into a single edge, which is assigned a weight equal to the sum of the weights of combined edges (edge weights are equal to one in the finest graph).At the coarser levels of the algorithm, the edge weights are used to match vertices according to a heavy edge rule: a vertex is matched with an unmatched neighbor which has the greatest edge weight. It is believed that matching vertices in this way more carefully preserves the structure of the original graph. This coarsening phase repeats until there are fewer than 100 vertices in the graph.Once the graph is sufficiently coarsened, the VSP is solved for the coarse graph by finding an approximate solution to the quadratic program (1.3) and taking the steps outlined in the proof of Theorem 2.1 to move to a binary solution satisfying (2.8). From this solution, a separator is obtained for the coarse graph via (1.5).In order to exploit the bilinear structure of the quadratic program, we solve (1.3) using a modified version of a Mountain Climbing Algorithm developed by Konno (1976) for general bilinear programs. Pseudocode for this algorithm is given in Fig. 7.1, where f denotes the objective function of (1.3),σis a vector whose ith component stores the size of the ith vertex in the coarse graph (the number of fine vertices it contains), andηis a small positive number. Starting from an initial guess, each iteration solves two linear programs, corresponding to the cases where eitherxoryin (1.3) is held fixed. Ifxˆandyˆdenote these solutions, then the objective valuesf(x,yˆ),f(xˆ,y), andf(xˆ,yˆ)are compared and a full step is taken in the direction of the point with the best objective value. In practice, the algorithm typically alternates between maximizing overxandy(as though one is climbing a mountain) after taking a few steps along the diagonal direction. In our experiments, we used the initial guessxi=ua/nandyi=ub/nfor each i.The iterates of Algorithm 7.1 typically converge to a stationary point of (1.3). In Hager and Hungerford (2013), necessary and sufficient conditions were developed for checking whether a stationary point of (1.3) is a local maximizer. However, these conditions have not been implemented in the present version of our code. Since the program (1.3) is non-concave, a stationary point is not necessarily a global optimum. Therefore, it is important that any algorithm for solving (1.3) incorporate techniques for escaping from local solutions. In the present algorithm, we escape by reducing the penalty parameterγin (1.3) and resolving the problem. From a graph-theoretic perspective, this amounts to relaxing the constraint that there can be no edges betweenAandB, thus encouraging the iterates to explore a larger domain.When the solution at a coarse level is uncoarsened, a partition is obtained at the next finer level by assigning vertices to the same sets as their representatives in the coarse graph. Many multilevel algorithms employ techniques for refining this initial solution. Typically, these techniques are very discrete in nature; for example, the multilevel partitioner METIS (Karypis & Kumar, 1995) refines the solution using a variant of the Fiduccia Matheyses algorithm (Fiduccia & Mattheyses, 1982). In our algorithm, we consider two refinement types: a Fiduccia–Mattheyses heuristic, which is performed by invoking the METIS routine METIS_NodeRefine (see METIS 5.1 Karypis & Kumar, 1995), and the Mountain Climbing Algorithm applied to (1.3), which uses as its starting guess the pair of incidence vectors(x,y)associated with the current partition. The abbreviation QP is used to refer to the algorithm which only uses the Mountain Climbing Algorithm, in both the solution and uncoarsening phases. FM refers to the algorithm in which both the coarse solution and the refinements are achieved using FM only. QP+FM refers to the algorithm where these two techniques have been combined during the solution and uncoarsening phases. At each level during the uncoarsening, refinements are repeated until no further improvement is made at the current level.The algorithm was programmed in C++ and our experiments were run on a Dell T7500 workstation with 96gigabytes memory and Intel Xeon 5600 series processors operating at 3.47gigahertz. The graph adjacency matrix and other structures used during the coarsening process, such as node and edge maps, were stored using the LEMON Graph Library (Dezső, Jüttner, & Kovács, 2011). Computational experiments were performed on three separate test sets.First, in order to evaluate the accuracy of the solutions obtained by our algorithm, the code was run on a set of 104 small problem instances (n=11ton=191) from the Souza-Balas benchmark set found at the following website: http://www.ic.unicamp.br/∼cid/Problem-instances/VSP.html.The test problems are partitioned into 4 sets. The instances labeled DIMACS were taken from the DIMACS graph coloring challenge. The remaining graphs were generated from matrices in the Matrix Market by representing columns of a matrixMas vertices and letting(i,j)∈Ewheneveri≠jand(MTM)ij≠0. The category MM-I contains graphs associated with matrices with between 20 and 100 columns. MM-II contains graphs with between 100 and 200 columns in the matrix. MM-HD is a collection of high density Matrix Market graphs having a density of at least 35%. Optimal separator sizes for these graphs were recorded by Biha and Meurs (2011) for the case whereℓa=ℓb=1andua=ub=2n3. In order to make accurate comparisons, we replicated their upper and lower bounds in our experiments. Table 7.1gives the CPU times for our algorithm on each of these problems, as well as the number of problems which were solved to optimality. Out of 104 problems, QP solved all but 28 problems exactly, while QP+FM obtained exact solutions for all but 18. Of the problems for which an optimal solution was not obtained, each of the separator sizes obtained by QP+FM were within(.05)nof the optimal separator size, having on average between 1 and 2 more vertices than an optimal separator, while separators sizes obtained by QP were each within(.09)nof the optimal separator size, having on average between 2 and 3 vertices more than an optimal separator.Our second test set consisted of several medium sized (n=800) random graphs, toroidal grid graphs, and “almost planar” graphs generated by Helmberg and Rendl (2000). This test set was incorporated into our experiments in order to make comparisons with a recent breakout local search algorithm (BLS) for the VSP developed by Benlic and Hao (2013). BLS is a discrete algorithm which employs random and directed (tabu list based) perturbations to escape poor local minima. For both algorithms, lower and upper bounds on the shores were set toℓa=ℓb=1andua=ub=2n3. Table 7.2compares CPU times and separator sizes for QP and QP+FM with BLS. Observe that BLS obtains a better solution than both versions of our algorithm for 9 out of 12 problems. Separator sizes obtained by our algorithm were within 3% of those obtained by BLS for the Random Graphs, 12% in the case of G13, and 18% for the Almost Planar Graphs. Considering that QP is an algorithm based exclusively on continuous optimization techniques, these results are remarkable. The regularity in CPU times for BLS is due to a stopping criterion which forces the algorithm to terminate after approximately 2seconds. CPU times for our algorithm were longest for the Random Graphs and shortest for the Toroidal Grid Graphs, which is likely a consequence of the fact that the Random Graphs were the most dense (containing approximately 6% of the number of edges in a complete graph), while the Almost Planar and Toroidal Grid Graphs had densities of approximately 1.5% and .05%, respectively. However, CPU times for our algorithm are not optimized and should only be viewed qualitatively, due to the high cost overhead associated with the use of the LEMON Graph Library.Our final test set consisted of 160 large (1000⩽n⩽5000) sparse graphs associated with matrices from the University of Florida Sparse Matrix Collection (Davis, 1994). For each matrix, a graph was constructed by identifying the columns and rows with vertices, and placing edges between vertices whenever the corresponding entries in the matrix were non-zero. Separator sizes were compared with those obtained by the METIS routine METIS_ComputeVertexSeparator. We used upper bounds ofua=ub=⌊(.503)n⌋, since the METIS documentation suggests that the code was designed primarily for solving problems where the shores are roughly equal in size.Fig. 7.2gives a performance profile comparing the separator sizes obtained by QP, FM, QP+FM, and METIS. FM corresponds to the algorithm which uses our techniques for coarsening the graph and METIS’s FM-based techniques for carrying out refinements. The METIS curve in Fig. 7.2 corresponds to the algorithm METIS_ComputeVertexSeparator, in which both the coarsening and refinement phases are handled by METIS. The plot gives the percentage P of problems for which a given algorithm obtained a separator size within a factor ofτof the best separator size obtained by the algorithms. Since the top curve in a performance profile yields the best performance, it appears that QP+FM gave the best quality separators in this experiment. In particular, QP+FM obtains a solution of at least the same quality as METIS for72%of the problems tested, and a solution of strictly better quality for34%of problems.

@&#CONCLUSIONS@&#
