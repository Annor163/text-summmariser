@&#MAIN-TITLE@&#
Belief rule-based inference for predicting trauma outcome

@&#HIGHLIGHTS@&#
A RIMER methodology-based trauma outcome prediction model is developed.The RIMER-based prediction model is fine-tuned and validated using historical data.LR, SVM, and ANN models are developed and compared with the RIMER model.The RIMER model has the best prediction performance among the four models.

@&#KEYPHRASES@&#
Belief rule base,Evidential reasoning approach,Logistic regression,Support vector machine,Artificial neural network,Outcome prediction,

@&#ABSTRACT@&#
A belief rule-based inference methodology using the evidential reasoning approach (RIMER) is employed in this study to construct a decision support tool that helps physicians predict in-hospital death and intensive care unit admission among trauma patients in emergency departments (EDs). This study contributes to the research community by developing and validating a RIMER-based decision tool for predicting trauma outcome. To compare the prediction performance of the RIMER model with those of models derived using commonly adopted methods, such as logistic regression analysis, support vector machine (SVM), and artificial neural network (ANN), several logistic regression models, SVM models, and ANN models are constructed using the same dataset. Five-fold cross-validation is employed to train and validate the prediction models constructed using four different methods. Results indicate that the RIMER model has the best prediction performance among the four models, and its performance can be improved after knowledge base training with historical data. The RIMER tool exhibits strong potential to help ED physicians to better triage trauma, optimally utilize hospital resources, and achieve better patient outcomes.

@&#INTRODUCTION@&#
Trauma has become one of the leading causes of mortality and disability worldwide. Trauma accounts for 16% of the global burden of disease, and 16,000 people die from injury daily. Death and disability from trauma frequently occur in low- and middle-income countries where approximately 90% of the total burden of trauma is reported [1,2]. In developed countries, pre-hospital triage can help stratify trauma patients into different severity levels, and different levels of trauma centers have been established to treat trauma patients with varying degrees of severity [3–5]. Unfortunately, no nationwide initial trauma assessment guidelines or tools exist to aid physicians in pre-hospital environments or emergency departments (EDs) in many less developed countries [6]. In China, a pre-hospital “120” (the ambulance call number used in China) emergency system adopts the principle of proximity to transport a trauma patient to the nearest hospital. Consequently, some severe trauma patients have been sent to low-level hospitals, which cannot treat severe trauma patients, so these patients have to be retransferred to higher-level hospitals. Trauma patient outcomes in China are relatively poor compared with those in developed countries. More than 400,000 people die from injury in China each year, and trauma is the fifth leading cause of death after malignant tumors and cardiac, cerebral, and respiratory diseases. Trauma is considered the most common cause of death of young people aged 18–40 years in China [7]. Research shows that a large proportion of in-hospital mortality can be predicted and prevented if clinical deterioration is recognized early [8,9]. Therefore, for improved patient outcomes and optimal utilization of hospital resources, physicians in EDs need to provide a rapid initial assessment of illness severity for trauma patients immediately after their arrival at the hospital, so as to make appropriate decisions regarding the treatment of patients with a high probability of in-hospital death or intensive care unit (ICU) admission [10].Vital signs including pulse rate, systolic blood pressure, respiratory rate, body temperature, and level of consciousness are used to assign an early warning score [11–14] to assess illness severity. In trauma care, other physiological scoring tools such as the Pre-Hospital Index [15], the Trauma Index [16,17], the Glasgow Coma Score [18,19], and the Revised Trauma Score [20] have been developed to assess trauma severity before detailed diagnoses can be made for trauma patients. The nature of existing physiological trauma severity assessment tools is to assign a severity score to a patient based on physician observations and the instrumentally measured vital signs of the patient. However, the existing trauma scoring tools to aid physicians in EDs are most often used to stratify patients into different severity levels and rarely to predict the probability of in-hospital death and ICU admission. To explore the relationship between clinical variables available for data collection in EDs and trauma outcome, such as in-hospital death and ICU admission, logistic regression (LR) [21,22], support vector machines (SVMs) [23,24], and artificial neural networks (ANNs) [25–28] are usually employed to construct prediction models. None of the LR, SVM, or ANN models require concrete knowledge about the relationship between antecedent factors and dependent outcomes, and these methods are completely data-driven, which means sufficiently large sample data are needed to learn prediction models. The performance and efficacy of data-driven prediction models are determined not only by the learning dataset, but also by the unknown dataset to which the prediction model is applied.In the present study, vital signs are used as antecedent factors to predict in-hospital death and ICU admission. We propose the use of a generic belief rule-based inference methodology using the evidential reasoning approach (RIMER) [29] to develop a clinical decision model. This model is aimed at helping ED physicians predict the probability of in-hospital death and ICU admission for trauma patients [30]. In RIMER, an initial belief rule base (BRB) consisting of belief rules for predicting in-hospital death and ICU admission must first be constructed based on domain expert knowledge and clinical experiences. Inference with the BRB is implemented using the evidential reasoning (ER) approach [31,32], which was originally proposed for combining multiple independent assessments of one alternative on individual criteria or attributes. The ER approach can handle both quantitative and qualitative attributes or criteria under uncertainties [33,34]. In an RIMER-based prediction model, the inputs include the clinical values of vital signs, which are used to infer with or match the belief rules in the BRB. In ER-based inference, the packet antecedent of each belief rule triggered by the inputs is considered a basic attribute with an attribute weight, which is assessed using all possible consequents with belief degrees as presented in the BRB. Thus, assessments on the packet antecedents of multiple triggered belief rules can be combined by the ER approach to achieve aggregated belief degrees in all possible consequents of the BRB. The output of the model is a combined belief degree or probability linked to the trauma outcome, including in-hospital death and ICU admission for each patient. The BRB in the model can be fine-tuned by accumulated historical data. The model is transparent in that all belief rules can be checked by experienced physicians for validity and the inference process is also transparent and can be traced for better informed decision making.In addition, LR-based, SVM-based, and ANN-based prediction models are constructed for comparison using the same dataset, whereas the antecedent variables and dependent outcome of each of these completely data-driven prediction models are the same as those of the RIMER model. To validate the prediction performance of all RIMER-based, LR-based, SVM-based, and ANN-based models, a five-fold cross-validation method is applied.The remainder of this paper is structured as follows. The Materials and methodology section provides a brief introduction to the following: the data source, RIMER methodology, LR analysis, SVM, ANN, five-fold cross-validation method, and area under the receiver operating characteristic (ROC) curve (AUC), which we used to measure prediction performance. The Results section compares the prediction performance of the RIMER-based model before and after BRB training, the LR-based model, an optimal SVM-based model, and an optimal ANN-based model in each training round. Discussion section elaborates on the four different types of prediction models, especially the advantages and limitations of the RIMER model. Conclusions section summarizes this study and presents conclusions drawn from the study.A sample of trauma patients sent to Kailuan Hospital, North China, between 2008 and 2009 was employed for prediction model development and validation. Patients were included for analysis if they met the following criteria: (a) directly sent to the ED from an accident site; (b) with the five vital signs recorded upon their arrival at the ED; and (c) possible to retrieve corresponding in-hospital data. No further restrictions were made on the severity or characteristics of the cases. A total of 1299 trauma patients were directly sent to the ED at Kailuan Hospital within the sampling period, among which 1190 (91.61%) had both ED vital signs data and in-hospital data. The remaining 109 patients had either missing data on vital signs or missing in-hospital data, so they were excluded from data analysis.The primary outcome of this study is a composite one, including in-hospital death and ICU admission.In the RIMER methodology, traditional IF-THEN rules are extended to belief rules by embedding belief degrees in all possible consequents of a rule. Meanwhile, other knowledge representation parameters, including rule weights, antecedent attribute weights, and consequent belief degrees, are embedded in the belief rules. Inference with a BRB in a RIMER system is implemented using ER. The RIMER system presents the advantages of using belief rules to represent clinical domain knowledge under uncertainty and inference with uncertain clinical data using the ER approach. The knowledge representation parameters, including rule weights, antecedent attribute weights, and consequent belief degrees in the BRB, can be fine-tuned or trained using accumulated historical data [35]. The RIMER methodology has been employed to stratify patients with cardiac chest pain [36,37], diagnose lymph node metastasis in gastric cancer [38,39], and many other areas [40–42]. A brief introduction to BRB, inference with BRB, and the training of BRB follows.A belief rule can be described as Rk:(1)IfA1k∧A2k∧⋯∧ATkk,then{(D1,β1k),(D2,β2k),…,(DN,βNk)}(βjk≥0,∑j=1Nβjk≤1),witharuleweightθkandattributeweightsδ1,δ2,…,δTk,k∈{1,…,L},whereAik(i=1,…,Tk)is the referential category or grade of the ith antecedent attribute used in the kth rule;βjk(j=1,…,N;k=1,…,L)is the belief degree assigned to consequent Dj, and it can initially be given by experts;δi(i=1,…,Tk)is the antecedent attribute weight representing the relative importance of the ith attribute; and θkis the rule weight representing the relative importance of the kth rule. L represents the number of all belief rules in the rule base. Tkis the number of all antecedent attributes used in the kth belief rule. N is the number of all possible consequents in the BRB. Traditional IF-THEN rule can be represented as a special case of belief rule with only one consequent, and the consequent belief degree is always 100%.Initial belief rules in this study were provided by domain experts, and the five vital signs, namely, body temperature, respiratory rate, systolic blood pressure, pulse rate, and level of consciousness, are used as antecedent factors in the rule base. The possible consequents of the rule base include “occurrence of in-hospital death or ICU admission” and “nonoccurrence of in-hospital death or ICU admission.” The referential grades of the five vital signs include “normal (N)” and “abnormal (AN).” One example of a belief rule is “IF body temperature is AN, respiratory rate is AN, systolic blood pressure is AN, pulse rate is AN, and level of consciousness is AN, THEN {(occurrence of in-hospital death or ICU admission, 70%), (nonoccurrence of in-hospital death or ICU admission, 30%)},” where {(occurrence of in-hospital death or ICU admission, 70%), (nonoccurrence of in-hospital death or ICU admission, 30%)} means that if the clinical data of one patient satisfy the compact antecedent of the rule, the patient will have in-hospital death or ICU admission with 70% certainty and 30% certainty of eliminating the two adverse events. In total, 32 belief rules in the BRB are listed in Table 1, where A1 represents body temperature, A2 is the respiration rate, A3 is the pulse rate, A4 is the systolic blood pressure, and A5 represents the level of consciousness.Inference with the BRB in the RIMER system is implemented using the ER algorithm [31,43].First, transform numerical values or subjective judgments associated with antecedent clinical variables to belief distributions on corresponding reference categories used in the BRB. This transformation can be implemented by rule- or utility-based equivalence transformation techniques [32]. For example, set the input value for the ith antecedent attribute as Uialong with a belief degree ɛi. The input value can be transformed as(2)S(Ui,ɛi)={(Aij,αij);j=1,…,Ji},i=1,…,Twhere Aijis the jth referential category of the ith antecedent attribute, αijis the degree to which the input Uiwith belief degree ɛibelongs to the referential category Aijwith αij≥ 0 and∑j=1Jiαij≤1(i=1,…,T), and Jiis the number of all referential categories of the ith antecedent attribute.In this study, the degree of “N” or “AN” associated with each vital sign variable is calculated from the severity score assigned to the corresponding vital sign on the basis of physician observation or instrumental measurement. The criteria for the severity score assignment are based on the early warning score, as introduced by Smith et al. [12]. Details of the scoring criteria are shown in Table 2.In Step One of this input transformation, a severity score equal to 0, 1, 2, or 3 is assigned to a patient. This score pertains to his or her vital signs on the basis of physician observations or the numerical values (exact numerical values for body temperature, respiration rate, pulse rate, and systolic blood pressure, and physician observations for level of consciousness). The assignment is based on the early warning score criteria, where a score of 0 means normal status and the scores 1, 2, and 3 mean abnormal status. The degree of abnormality increases with the score. Step Two involves transforming a numerical severity score to a distribution on the referential grades “N” and “AN” based on the following transformation rule. With pulse rate as an example, the pulse rate of a patient is set as “N” with 100% certainty if its associated severity score is 0, “AN” with 100% certainty if its associated severity score is 3, {(N, 66.67%), (AN, 33.33%)} if its associated severity score is 1, and {(N, 33.33%), (AN, 66.67%)} if its associated severity score is 2. For the other four vital signs, that is, body temperature, respiration rate, systolic blood pressure, and level of consciousness, we used the same rules as discussed above for input transformation.Second, calculate the activation weight of each belief rule in the BRB based on the weight associated with each rule and the degrees of belief in various reference categories after input transformation. Supposeωk(k=1,…,L)is the rule activation weight, which measures the degree to which the packet antecedent Akin the kth rule is activated by the inputs. It can be calculated by(3)ωk=θkαk∑j=1Lθjαj=θk∏i=1Tk(αlk)δ¯kl∑j=1L[θj∏l=1Tk(αlj)δ¯jl],k=1,…,Lwhereδ¯ki=δkimaxi=1,…,Tk{δki}(0≤δ¯ki≤1)is transformed from the antecedent attribute weightδki(i=1,…,Tk;k=1,…,L)representing the relative importance of the ith antecedent attribute in the kth rule [29].αik(i=1,…,Tk)is the individual matching degree to which the inputUi(i=1,…,Tk)belongs toAik(i=1,…,Tk;k=1,…,L), which is the referential category of the ith antecedent attribute in the kth rule, and it is generated from the input transformation as described by (2), withαik≥0and∑i=1Tkαik≤1.αk=∏i=1Tk(αik)δ¯ki(k=1,…,L)is the combined matching degree to which the input vector matches the packet antecedent Akin the kth rule. Tkis the total number of antecedent attributes in the kth rule. L is the total number of belief rules in the BRB.Third, use the ER algorithm to aggregate all the activated belief rules in the BRB, thereby generating a distributed trauma outcome prediction with combined belief degrees distributed on all possible consequents or outcomes. The analytic ER algorithm [44] is given as follows:(4)βj=μ×[∏k=1L(ωkβjk+1−ωk∑j=1Nβjk)−∏k=1L(1−ωk∑j=1Nβjk)]1−μ×[∏k=1L(1−ωk)],j=1,…,Nwhereμ=[∑j=1N∏k=1L(ωkβjk+1−ωk∑j=1Nβjk)−(N−1)×w∏k=1L(1−ωk∑j=1Nβjk)]−1, ωkis the rule activation weight calculated by (3), andβj(j=1,…,N)is the final combined belief degree associated with the corresponding consequentDj(j=1,…,N).In this study, all rule weights and antecedent attribute weights are assumed to be equal, and a final combined outcome prediction with belief degrees distributed on “occurrence of in-hospital death or ICU admission” and “nonoccurrence of in-hospital death or ICU admission” was generated for each case that was included for analysis.Note that in this study, all recorded clinical values or clinician judgments were certain values and could be transformed to early warning scores without uncertainty. Therefore, those early warning scores could be further transformed into precise distributed assessments on “N” and “AN” using the previously discussed transformation rules. In other disease diagnoses, there may be ambiguous judgements or missing values of some clinical variables that cannot be measurable at a certain time point.If clinician judgements contain ambiguity and we cannot decide whether the patient is normal or abnormal with 100% certainty, we can convert the uncertain judgments to some degree (α) of normal and some degree (β) of abnormal. If α+β=1, then the inputted information is complete and the transformed inputs are complete distributed assessments on “N” and “AN”, which is the same as the transformation of those early warning scores. Thus the inference is the same as what were discussed above. If α+β<1, it brings ignorance to the inputs and the incomplete inputs would cause incomplete assessments on different consequents. Although the procedures of inference with incomplete inputs are the same as that for the complete inputs, the final distributed assessments on different consequents after aggregating all triggered belief rules should not be the inferred certain belief degrees, because there is also ignorance in the consequents. In the latter situation, the final distributed assessments on different consequents would be interval belief degrees.If missing values for the input clinical variables exist, the BRB with certain consequent belief degrees (Table 1) can be extended to a BRB with interval belief degrees. A belief rule with interval belief degrees can be something like “IF body temperature is AN, respiratory rate is AN, systolic blood pressure is AN, pulse rate is AN, and level of consciousness is unknown, THEN {(occurrence of in-hospital death or ICU admission, [60–70%]), (nonoccurrence of in-hospital death or ICU admission, [30–40%])}.” Inference with this type of BRB with interval belief degrees needs to be implemented using the ER approach for combining multiple independent assessments with interval belief degrees, as proposed by Wang et al. [33]. The inference steps of the BRB with interval belief degrees are similar to the aforementioned steps. All sample data included in this study are certain data; thus, the details of the uncertainty handling capability of the RIMER model will not be discussed. Readers can refer to [33] for details of using the ER approach to deal with interval belief degrees.The belief rules in the initial BRB are provided by domain experts and may not represent the real situation with 100% accuracy. A change in the knowledge representation parameters can lead to changes in the performance of a RIMER-based prediction model. Thus, the knowledge representation parameters need to be fine-tuned or trained using accumulated historical data. Suppose(x^m,y^m)(m=1,…,M)is used to denote input–output pairs of M clinical cases in the training dataset. The process of training BRB from these M datasets can be depicted as in Fig. 1, wherex^mis the clinical inputs of the mth case, ymis the combined degree of belief generated by the RIMER-based model (implemented using Eqs. (2), (3), and (4)) in “occurrence of in-hospital death or ICU admission” with the inputsx^m,y^mis the actual or observed output of the mth case (a binary value), and ξ(P) represents the difference between the observed output and the system-generated output.The objective of BRB training is to determine an optimal set of knowledge representation parameters (βjk, δi, θk) for the BRB by minimizing the discrepancies between system-generated outputs and the observed outcomes for all cases in the training dataset. In this study, all rule weights and antecedent attribute weights were set to be equal, and only consequent belief degrees βjkwere set as training parameters in the BRB training process. The constraints of the training model are given as0≤βjk≤1(j=1,…N;k=1,…,L)and∑j=1Nβjk=1, where L is the number of belief rules, and N is the number of all possible consequents in the BRB. The fmincon function in MATLAB was used to solve the single-objective optimization model. Except for MaxIter set at 60 and TolX at 0.00001, all other options of the function were set to the default values in MATLAB. The fine-tuned consequent belief degrees of each belief rule in the BRB after each training round are presented in the Results section.LR measures the relationship between the categorical dependent variable and one or more independent variables by estimating probabilities. LR is a maximum-likelihood method that has been used in many trauma outcome studies [21,22,25,45,46]. The binary LR model is used in this study. The binary logistic model is used to predict a binary outcome based on one or more predictor variables. In the model, the logit transformation of the probability pilinked to a particular outcome of the ith case is expressed as a linear prediction function of the independent or predictor variables(5)logit(pi)=ln(pi1−pi)=β0+β1x1,i+⋯+βjxj,i+⋯+βmxm,iwherej=1,…,m, and m is the number of predictor variables. The predictors can be categorical dummy variables or continuous variables. The coefficient βjrepresents the change in the logit for each unit change in the associated predictor.Solving for piresults in the individual probability of the particular outcome as(6)pi=exp[β0+β1x1,i+⋯+βjxj,i+⋯+βmxm,i]1+exp[β0+β1x1,i+⋯+βjxj,i+⋯+βmxm,i]Models derived using LR analysis typically employ only variables that are statistically significant predictors of a particular outcome. In LR analysis, a backward stepwise method can be used to eliminate variables without statistical significance from the model in an iterative process, whereas the fit of the model is tested after each variable is eliminated to ensure that the model still adequately fits the training data.For deriving LR models, we have attempted to transform continuous variables, such as body temperature, pulse rate, respiration rate, and systolic blood pressure, to categorical variables in accordance with the early warning score criteria used in the RIMER methodology for input transformation. However, the LR model derived using transformed categorical predictor values obtained a worse prediction performance than the LR model that was derived using original continuous predictor values. Thus, the continuous values of the five vital signs, except level of consciousness, were used in the LR model derivation; only the value pertaining to level of consciousness was categorical like that in the RIMER model. In terms of the predictor variables in the LR model, we used both the backward stepwise method and the simple entering method. The latter method used all available predictors without considering corresponding statistical significance in model derivation. We found that the two LR models constructed with different independent predictor variables showed similar prediction performance. As the RIMER model employed all the five vital signs as antecedent attributes in its BRB, we also used a saturated LR model with the five vital signs as predictors in the LR model to compare the prediction performance of both models in the same prediction environment.In this study, the same dataset used for RIMER training and testing was used for LR analysis. SPSS was employed for LR analysis.SVM [47] is a supervised learning method used to perform dichotomy classification of multidimensional feature vectors. The basic idea under the SVM method is to transform the input features into a higher-dimensional space where the two classes can be linearly separated by a high-dimensional surface known as hyperplane. Given a training dataset{(xi,yi)|xi∈RL,yi∈{−1,+1}}i=1Nwith N samples, where yiis either 1 or −1, indicating the class to which the data point xibelongs. Each xiis one L-dimensional real vector. The decision function of SVM is described as(7)h(x)=wTφ(x)+bwhere φ(x) represents a mapping of sample x from the input space to a high-dimensional feature space, w denotes the normal vector to the learned hyperplane, and b is the model bias.An SVM classifier needs to satisfy the following conditions:(8){wTφ(xi)+b≥1ifyi=+1wTφ(xi)+b≤−1ifyi=−1The equationwTφ(xi)+b=0constructs a hyperplane that discriminates between the two classes, where |b|/w is the perpendicular distance from the hyperplane to the origin, and 1/w is the shortest distance from the hyperplane to the closest positive (negative) sample. A typical two-class problem classified using SVM is shown in Fig. 2. Line H represents the separating hyperplane, and each of the two half spaces separated by H corresponds to one class, H1foryi=+1, and H2foryi=−1. The SVM determines a hyperplane with the maximal margin. The margin of an SVM classifier is the minimal distance of any training point to the hyperplane, which is the distance between the dotted lines H1and H2and the solid line H, as shown in Fig. 2. Therefore, the margin of a hyperplane will be1/w+1/w. Calculating the optimal separating hyperplane is equivalent to maximizing the separation margin or distance between the two dotted lines H1and H2[48]. The training points that lie on the dotted lines H1and H2are referred to as support vectors and are colored in gray in Fig. 2.In practice, a separating hyperplane may not exist. To allow for the possibility of training samples violating the edges of the margin, slack variablesξi(i=1,2,…,N)with ξi≥ 0 are introduced. We can optimize the values of w and b by solving the following optimization problem:(9)minimizew,b,ξi12wTw+C∑i=1Nξisubjecttoyi(wTφ(xi)+b)≥1−ξi,ξi≥0,i=1,2,…,Nwhere C (>0) is the regularization parameter (penalty factor) that regulates the relationship between training accuracy and model generalization, slack variables ξiare used to achieve a soft margin, and φ is a non-linear mapping from an input space into a feature space. By introducing the Lagrange multiplier αi, a corresponding dual problem can be derived as the following quadratic programming problem:(10)maxmizeαi∑i=1Nαi−12∑i=1N∑j=1Nαiαjyiyjk(xi,xj)subjectto∑i=1Nαiyi=0,0≤αi≤C,i=1,2,…,Nwhere k is a kernel function withk(xi,xj)=〈φ(xi),φ(xj)〉, which maps the input vectors into a suitable feature space. Commonly used kernel functions in SVM include linear kernel, polynomial kernel, and radial basis function kernel. Once the dual quadratic programming problem is solved, the resulting decision function at any test data point x is as follows:(11)h(x)=wTφ(x)+b=∑i=1Nαiyik(xi,x)+b=∑i∈svαiyik(xi,x)+bOnly those data points for which αiis nonzero are referred to as support vectors, and they define the decision function.In the test phase, to obtain a binary outcome, we estimate the class of the test data point x based on sign(h(x)). To obtain a binary outcome together with probability information, we need to extend the SVM to provide probabilities. Details of probability estimates obtained using SVM can be found in [49].The present study employed the LIBSVM toolbox (for MATLAB environment) developed by Chang and Lin [50]. The svmtrain and svmpredict functions in the LIBSVM toolbox were used for SVM model training and testing. The procedures of employing svmtrain and svmpredict to obtain an optimal SVM model are as follows. First, we used the general and default kernel function (radial basis function) of LIBSVM to build SVM. Second, we established training samples and called svmtrain in LIBSVM to train SVM. Third, we called svmpredict to predict the samples in the training set using well-trained SVM models. To find an optimal set of parameters C and γ for the radial basis function kernel SVM, we tested different sets of C and γ using a five-round model training method. In this method, the whole dataset was split into five folds (roughly similar data distribution in each fold) and used any four folds for model training in each training round. The ranges of C and γ were set as [1,  24] and[2−5,2−1], respectively, and their initial values were set to be 1 and2−5, respectively. The value assignments of C and γ in the parameter searching process were set as (20,20+step,20+step+step,……,  24) and (2−5,2−5+step,2−5+step+step,……,2−1) (step=1) respectively. Finally, we selected the pair of parameters C and γ with the best average mean squared error (MSE) in the training dataset after five rounds of model training. After the parameters C and γ were determined, the same dataset for LR model training and testing was used for SVM model analysis. Instead of using the originally recorded values of body temperature, respiration rate, pulse rate, systolic blood pressure, and the numerical score of the level of consciousness, we normalized the input values to [0, 1] in the SVM model analysis, as recommended by Hsu et al. [51]. The outcome of the SVM model included two values ranging from 0 to 1, which indicate the probabilities linked to the occurrence and nonoccurrence of ICU admission or in-hospital death, respectively.ANN has different types of structures [52]. One of the most common ANN structures is the multi-layer perceptron network, which is a feedforward type of the neural network [48,53]. A multi-layer perceptron with a back-propagation algorithm was used in the current study. A multi-layer perceptron network consists of multiple layers of neurons: one input layer receiving external inputs, one output layer generating the classification results, and one or more hidden layers. Each layer is fully connected to the next one. A typical multi-layer perceptron network structure with an input layer, a hidden layer, and an output layer is shown in Fig. 3.Except for the input layer, each neuron in the network is a computational element that receives information from neurons of the previous layer, produces an output signal by an activation or transfer function, and passes it on to neurons of the next layer. The principle of the network is that when data are presented at the input layer, the neurons in the consecutive layers run computations until an output value is obtained at each of the output neurons. This output will indicate the appropriate outcome for the input data.Each neuron in the hidden layer receives an activation signal, which is the weighted sum of all inputs that enter into the neuron. The resulting sum is used to generate an output of the neuron through an activation function. This process is defined as follows:(12)vj=∑i=1pxiwij(13)yj=f(vj)where vjis the linear combination of inputsx1,x2,…,xn, wijis the connection weight between the input xiand the jth neuron, f is the activation function used for the neuron, and yjis the output of the neuron. The most commonly used activation function is the sigmoid function, and its general form is expressed as(14)f(t)=11+e−tThe neurons in the output layer receive the following activation signals from the hidden neurons:(15)hk=∑j=1nyjwjkwhere wjkis the weight of the connection between neuron j in the hidden layer and neuron k in the output layer. These activation signals are then transformed again to generate the outputs of the network as follows:(16)ok=f(hk)=11+e−hkwhere okis the output generated by the network.Different algorithms have been developed to learn a multi-layer perceptron network using a set of training samples. The most popular algorithm is the backpropagation algorithm, a gradient descent method that adjusts the weights of interconnections to minimize output error. The error function of the output neuron is defined as(17)E=12∑k(dk−ok)2where dkand okare the observed and network-generated values of the outputs, respectively. The objective of network learning is to minimize the error E for the network to achieve the best performance.All weight vectors w are initialized with small random values from a pseudorandom sequence generator. The following steps are repeated until the convergence (i.e., when the error E is below a preset value).The weights between the hidden layer and the output layer wjkare updated by(18)wjk(t+1)=wjk(t)+Δwjk(t)where(19)Δwjk(t)=−η∂E(t)∂wjk(20)Δwjk(t)=−η∂E∂ok∂ok∂hk∂hk∂wjk=η(dk−ok)f′(hk)yj=ηδokyjwhere η is the learning rate, and δokis the error signal of the neuron k in the output layer given by(21)δok=(dk−ok)f′(hk)To avoid oscillation at large η, the changes in the weights are made to depend on the past changes by adding a momentum term α:(22)Δwjk(t+1)=ηδokyj+αΔwjk(t)Similarly, the changes in the weights between the neurons in the input and hidden layer, Δwij(t), are given by(23)Δwij(t)=−η∂E∂wij=−η∑k(∂E∂ok∂ok∂hk∂hk∂yj∂yj∂vj∂vj∂wij)=ηδyjxiwhere δyjis the error signal of the neuron j in the hidden layer and is given by(24)δyj=f′(vj)∑kδokwjkSimilarly, a momentum term can be added to prevent oscillation.Through the learning process, a set of optimal weights can ensure that the resulting vector generated by the network is the same or sufficiently close to the observed output vector for each input vector.A previous study [52] showed that an ANN with a single hidden layer with a sufficiently large number of neurons can relate any given set of inputs to outputs. Therefore, a three-layer ANN was constructed in this study.The input variables of the ANN were the same as the inputs of the LR models. The only output of the ANN is a value ranging from 0 to 1, which may represent the probability of the primary outcome for each studied sample. Meanwhile, numerous thumb rules are used for determining the number of neurons in the hidden layer. An empirical equation used in this study is as follows.(25)h=m+n+awhere h is the target number, m is the number of neurons in the output layer, n is the number of variables in the input layer, and a is an integer constant with a ∈ [1, 10]. According to the above formula, the number of neurons in the hidden layer may be between 3 and 12.The feedforwardnet, train, and sim functions in MATLAB were employed to create, train, and test ANN models. In creating and training the ANN, the training function was set as traingdm, the transfer function was set as logsig, and all other parameters in the ANN models were set to their default values in MATLAB. To find an optimal network structure, we used the trial-and-error method to train and test different ANN models with various numbers (ranging from 3 to 12) of neurons in the hidden layer. Similar to optimal parameter searching in SVM model analysis, the five-round model training method was used to train different ANN models. An ANN model with the best average MSE in the training dataset was selected after five rounds of ANN training. After the ANN model structure was determined, the same dataset used for SVM model analysis was employed for ANN model training and testing.The five-fold cross-validation method was employed in this study to train and validate all constructed prediction models. The studied dataset was split into five folds with equal cases (with each fold containing roughly the same proportions of the two types of outcome). A single fold out of the five folds is retained as the validation set for model testing, and the remaining four folds are used as the training set for model derivation. Thus, the four constructed models were trained and tested five times using any four folds as the training set and the remaining fold as the test set.Plotting the ROC curve is a commonly used method of illustrating the discriminatory accuracy of a diagnostic tool for detecting or predicting whether a patient has a disease or outcome [54]. In medicine, a person is assessed as diseased (positive) or healthy (negative) depending on whether the corresponding test value is greater than, less than, or equal to a given threshold value. Associated with any threshold value are the probability of a true positive (sensitivity) and the probability of a true negative (specificity). The theoretical ROC curve is a plot of sensitivity versus 1-specificity for all possible threshold values. The most commonly used global index of diagnostic accuracy is the AUC [54]. The AUC has also been employed to measure the performance of prediction models in many trauma studies [25,45,46,55,56].With the observed outcome as the gold standard, the following were used to plot the ROC curves: the final combined belief degree distributed on “occurrence of in-hospital death or ICU admission” generated by the RIMER model, the predicted probabilities of in-hospital death or ICU admission generated by the LR model, the SVM model, and the ANN model in each test fold. The average AUC value was used as a measure to compare the prediction performance of the four different models.

@&#CONCLUSIONS@&#
This study contributes to the research by developing and validating a RIMER-based outcome prediction model to assist ED physicians to predict the probability of in-hospital death and ICU admission among trauma patients. The RIMER model is compared to the most commonly used methods in deriving trauma outcome prediction models, which include LR analysis, SVM, and ANN. The five-fold cross-validation method is employed in this study to validate the RIMER-based, LR-based, SVM-based, and ANN-based prediction models. To compare the prediction performance of the newly developed RIMER model with those of the other three commonly used data-driven models, the AUC values that represent the prediction performance of the four models were obtained. The results show that the RIMER model performs the best. Meanwhile, its initial BRB provided by trauma experts exhibits robust prediction performance, which can be further improved after fine-tuning through historical trauma data. The LR model performs better than the SVM and ANN models. Among all models, the ANN model shows the least AUC.To conclude, the RIMER methodology provides an innovative way for clinical decision science researchers to fully benefit from both expert knowledge and historical patient data to develop a decision support tool to assess illness severity and predict patient outcome. Compared with LR analysis, SVM, and ANN, the RIMER-based model provides the best prediction performance. The RIMER tool exhibits strong potential to help ED physicians to better triage trauma, optimally utilize hospital resources, and achieve better patient outcomes. In our future work, we plan to implement the RIMER-based outcome prediction model in real practice and generalize the RIMER-based outcome prediction model to other diseases and departments.