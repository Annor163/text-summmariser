@&#MAIN-TITLE@&#
Differenced maximum mutual information criterion for robust unsupervised acoustic model adaptation

@&#HIGHLIGHTS@&#
The differenced-MMI (dMMI) is a discriminative criterion that generalizes MPE and BMMI.We discuss the behavior of dMMI when there are errors in the transcription labels.dMMI may be less sensitive to such errors than other criteria.We support our claim with unsupervised speaker adaptation experiments.dMMI based adaptation achieves significant gains over MLLR for 2 LVCSR tasks.

@&#KEYPHRASES@&#
Discriminative criterion,Differenced maximum mutual information,Speech recognition,Acoustic model adaptation,Unsupervised adaptation,

@&#ABSTRACT@&#
Discriminative criteria have been widely used for training acoustic models for automatic speech recognition (ASR). Many discriminative criteria have been proposed including maximum mutual information (MMI), minimum phone error (MPE), and boosted MMI (BMMI). Discriminative training is known to provide significant performance gains over conventional maximum-likelihood (ML) training. However, as discriminative criteria aim at direct minimization of the classification error, they strongly rely on having accurate reference labels. Errors in the reference labels directly affect the performance. Recently, the differenced MMI (dMMI) criterion has been proposed for generalizing conventional criteria such as BMMI and MPE. dMMI can approach BMMI or MPE if its hyper-parameters are properly set. Moreover, dMMI introduces intermediate criteria that can be interpreted as smoothed versions of BMMI or MPE. These smoothed criteria are robust to errors in the reference labels. In this paper, we demonstrate the effect of dMMI on unsupervised speaker adaptation where the reference labels are estimated from a first recognition pass and thus inevitably contain errors. In particular, we introduce dMMI-based linear regression (dMMI-LR) adaptation and demonstrate significant gains in performance compared with MLLR and BMMI-LR in two large vocabulary lecture recognition tasks.

@&#INTRODUCTION@&#
Discriminative criteria have been widely used for automatic speech recognition (ASR) for training acoustic models (Nadas et al., 1988; Povey and Woodland, 2002; McDermott et al., 2007; Heigold et al., 2012), language models (Kuo et al., 2002) or feature transforms (Povey et al., 2005, 2008; Droppo and Acero, 2005; Zhang et al., 2006). Discriminative criteria aim at the direct minimization of classification error. Therefore, they are better correlated to word error than conventional maximum likelihood (ML). Consequently, discriminative training has provided significant performance improvement for many tasks and has became the de facto procedure for training ASR systems.Many discriminative criteria have been proposed, including maximum mutual information (MMI) (Nadas et al., 1988), minimum phone error (MPE) (Povey and Woodland, 2002), and minimum classification error (MCE) (Juang and Katagiri, 1992). More recently, margin-based extensions of these criteria have also been introduced such as soft margin (Li et al., 2006), boosted MMI (BMMI) (Povey et al., 2008) and boosted MPE (Heigold et al., 2008). These various discriminative criteria differ in their formulations, but they share the same principle of aiming at increasing the classification scores for the reference labels, while decreasing the scores for competing recognition hypotheses. As a consequence, discriminative approaches usually require to have high quality reference labels to work properly.In many situations, it is difficult or costly to obtain reference labels without transcription errors. For example, transcribing large amounts of training speech data is not only very expensive but also difficult, especially when dealing with spontaneous speech. Semi-supervised training is a practical approach for addressing this issue. With semi-supervised training, only a part of the training data is transcribed manually, and labels for the rest of the training data are generated automatically using a pre-existing recognizer (Lamel et al., 2002; Wessel and Ney, 2005; Wang et al., 2007). A similar approach is used for the unsupervised adaptation of acoustic models where labels also need to be estimated automatically from the untranscribed adaptation data. In such cases, the estimated reference labels inevitably contain recognition errors. Therefore, using a conventional discriminative criterion in such situations is particularly challenging (Wang et al., 2007).In this paper, we investigate the use of the recently proposed differenced MMI (dMMI) (McDermott et al., 2009, 2010) criterion in the presence of errors in the reference labels. We argue that dMMI is well suited for such situations. dMMI was first introduced as a generalization of existing criteria such as MPE and MMI. dMMI has been successfully used for training acoustic models (McDermott et al., 2010), discriminative feature transforms (Delcroix et al., 2012) and the weights of a weighted finite state transducer (WFST) used for ASR decoding (Kubo et al., 2012, 2012, 2013). dMMI can be derived as the integration over a margin interval of margin-based MPE objective functions. It can also be interpreted as a smoothed version of the BMMI objective function. With dMMI, the reference labels can be defined in a smoothed manner, i.e. as a summation of the contribution of each recognition candidate weighted by margin terms that emphasize the contribution of candidates close to the reference labels. In other words, the numerator of the dMMI objective function does not consist only of the contribution of the reference label, but also considers recognition candidates close to that reference label. Therefore, dMMI has an intrinsic mechanism for mitigating the influence of errors in the reference labels.We demonstrate the robustness of dMMI to errors in the reference labels for unsupervised acoustic model adaptation. Acoustic models must be adapted to mitigate the mismatch that often occurs between training and testing conditions due to unseen speaker or acoustic conditions (Yoshioka et al., 2014). In many cases, the adaptation has to be performed in an unsupervised way because transcribed data may not always be available. There is a great interest in using a discriminative criterion for adaptation. Indeed, discriminative criteria can potentially improve performance compared with the ML criterion and can better preserve the discriminative capabilities of discriminatively trained acoustic models. Therefore, discriminative unsupervised adaptation is an important application in itself. Moreover, it is a good example of an application where the reference labels contain errors and therefore is directly related to semi-supervised training.There have been many investigations of discriminative adaptation (Gunawardana and Byrne, 2001; Uebel and Woodland, 2001; Povey et al., 2003; Chien and Huang, 2006; Wu and Huo, 2007; Wang and Woodland, 2008; Matsuda et al., 2009; Gibson and Hain, 2012). Most approaches are based on the maximum likelihood linear regression (MLLR) (Leggetter and Woodland, 1995; Gales and Woodland, 1996) adaptation, but propose replacing the ML criterion with a discriminative one. Most studies target supervised adaptation. However, some have recognized the challenge of unsupervised discriminative adaptation and proposed approaches for handling the problem caused by inaccurate reference labels (Wang and Woodland, 2008; Gibson and Hain, 2012; Yu et al., 2009). For example, Wang and Woodland (2008) and Gibson and Hain (2012) proposed focusing on adaptation data that are expected to be correctly transcribed. This was achieved by weighting the MPE objective function with a word/phoneme correctness estimation.In this paper, we introduce dMMI-based LR adaptation. We demonstrate both theoretically and experimentally that dMMI-LR is well suited for unsupervised adaptation. Indeed, the smoothed reference definition of dMMI can achieve a similar effect to Wang and Woodland (2008) and Gibson and Hain (2012) without the need for an explicit estimation of the word/phoneme correctness. This paper is an extension of our previous work (Delcroix et al., 2013) and includes additional derivations as well as new experiments using two large vocabulary continuous speech recognition (LVCSR) tasks. These experiments provide new insights and confirm the usefulness of dMMI-LR for various tasks.In the remainder of this paper, Section 2 reviews conventional discriminative criteria and introduces dMMI. We then introduce LR-based adaptation in Section 3 and the proposed dMMI-LR adaptation. Some implementation issues and the relations with existing approaches are also discussed in Section 3. We report experimental results in Section 4 for the corpus of spontaneous Japanese (CSJ) and the MIT OpenCourseWare (MIT-OCW) tasks that demonstrate the robustness of dMMI-LR to errors in the reference labels, and finish with a conclusion.Before introducing dMMI, we first review the main discriminative criteria used for acoustic model training, namely MMI and MPE. We will then present dMMI, which generalizes these criteria.We consider the problem of finding a set of optimal parametersθˆthat maximizes an objective functionF(θ)33Note that in this paper, to clarify the relations between the different criteria, we express all criteria as a maximization problem in the form of Eq. (1) by negating the objective function of the original criteria if necessary.as,(1)θˆ=argmaxθF(θ).Here θ can represent acoustic model parameters such as the mean vectors and covariance matrices of a Gaussian mixture model (GMM)–hidden Markov model (HMM) acoustic model, feature transformation parameters, or adaptation parameters as described in Section 3.To introduce the notations, we first present the ML objective function,FML(θ), which is given as,(2)FML(θ)=∑r=1Rlog(p(Xr|Sr;θ)ψP(Sr)ψη),whereXris the rth training utterance, Srrepresents the reference label associated withXr44For unsupervised adaptation, Srconsists of the 1-best recognition candidate.and r is the total number of training utterances,p(Xr|Sr;θ)is the acoustic likelihood and P(Sr) is the language score. ψ and η are the acoustic scaling and language model weights, respectively. The acoustic likelihood is given as,(3)p(Xr|Sr;θ)=∑β∈B∏t=1Tp(xt|βt;θ)P(βt|βt−1;θ),whereBis the set of all possible state sequencesβ=[β1, …, βT] associated with the transcription Sr. P(βt|βt−1;θ) is the HMM state transition probability and p(xt|βt;θ) is the HMM state emission probability. We model the HMM state emission probabilities using GMMs as,(4)p(xt|βt;θ)=∑nP(n)N(xt;μn,Σn)whereμnandΣnare the mean vector and covariance matrix corresponding to the nth Gaussian component of the GMM.In the following, we introduce the following notation to simplify the expressions,(5)p(Xr,Sr;θ)≜p(Xr|Sr;θ)ψP(Sr)ψη.Note that the acoustic scaling or lattice smoothing factor, ψ, is introduced here for consistency with other criteria that are defined over lattices. It controls the amount of hypotheses in the lattices that will contribute to the objective function (McDermott and Nakamura, 2008).MMI is a well-known discriminative criterion that was first introduced in Nadas et al. (1988). It can be interpreted as the direct optimization of the posterior probabilityp(Sr|Xr;θ). Using Bayes’ rule, the objective function of MMI is obtained as,(6)FMMI(θ)=1ψ∑r=1Rlogp(Xr,Sr;θ)∑np(Xr,Sn;θ),where Snis a recognition candidate associated with the training utteranceXr. As shown in Eq. (6) MMI updates the model parameters by increasing the contribution to the reference model, while the contributions of the competitors are reduced. In Eq. (6) we expressed the MMI objective function in a non-standard way, by introducing the division by the acoustic scaling constant ψ. This follows the notations used in McDermott et al. (2009, 2010) and it enables to show that MMI is a smoothed version of the hinge loss function (McDermott et al., 2009) (this approximation becomes close when ψ takes large values). Moreover, introducing this scaling constant makes the relation between MMI and the other discriminative criteria more explicit as discussed later.The MMI criterion was further extended to include a margin term or boosting factor as follows (Povey et al., 2008),(7)FσBMMI(θ)=1ψ∑r=1Rlogp(Xr,Sr;θ)∑np(Xr,Sn;θ)eψσEn,r,whereEn,rrepresents the number of errors between the reference label Srand the recognition candidate Sn.En,rcan be expressed in terms of word, phone or phone-frame errors. In the following we use phone-frame errors as defined in Zheng and Stolcke (2005).eψσEn,ris a margin or boosting term that makes it possible to emphasize recognition candidates with a large number of errors in the denominator. The boosting term is controlled by a margin parameter, σ. With the boosting term, the model will have to discriminate better reference labels from recognition candidates with a large number of errors to increase the objective function during training. As a result, we may expect that low error candidates will be more likely to be recognized during testing. This is a similar effect to margin maximization in a support vector machine (SVM) (Heigold et al., 2008).To simplify the notations, we introduce a pseudo-probability function, Ψ, defined as (Nakamura et al., 2009),(8)Ψσ(Xr,Sr,θ)=∑np(Xr,Sn;θ)eψσEn,r.We can notice that for σ→−∞ only the term forEn,r=0(i.e. corresponding to the reference) remains in the summation. Using the pseudo-probability function of Eq. (8), we can rewrite the BMMI objective function as,(9)FσBMMI(θ)=1ψ∑r=1RlogΨ−∞(Xr,Sr,θ)Ψσ(Xr,Sr,θ).This expression of the BMMI objective function will allow us to clarify relations between the different discriminative criteria.MPE is another frequently used discriminative criterion (Povey and Woodland, 2002; Heigold et al., 2008). Compared with MMI, MPE aims at a direct minimization of the recognition error, which is a measure that is more relevant for ASR applications. The MPE objective function is given by the mean of the recognition errors over the recognition candidates, where the errors are calculated with respect to the reference labels. Although the name implies phone errors, here we use the same definition of errors as in Section 2.1, i.e. phone-frame error. The MPE objective function is defined as follows (here for brevity, we directly introduce the boosted version of MPE (Heigold et al., 2008)),(10)FσMPE(θ)=−∑r=1R∑kp(Xr,Sk;θ)eψσEk,rEk,r∑np(Xr,Sn;θ)eψσEn,r.Note that we negated the objective function compared with its conventional expression to remain consistent with the problem formulation of Eq. (1).Using the pseudo-probability function defined in Eq. (8), and observing that the numerator in Eq. (10) is the partial derivative of the pseudo-probability function relative to the margin parameter σ modulo acoustic scaling ψ, we can rewrite the MPE objective function as,(11)FσMPE(θ)=−1ψ∑r=1R∂∂σΨσ(Xr,Sr,θ)Ψσ(Xr,Sr,θ),=−1ψ∑r=1R∂∂σlogΨσ(Xr,Sr,θ).Finally, using the definition of a derivative in terms of limits, we can express the MPE objective function as,(12)FσMPE(θ)=−1ψlimϵ→0,σ1=σ,σ2=σ+ϵ∑r=1RlogΨσ2(Xr,Sr,θ)−logΨσ1(Xr,Sr,θ)σ2−σ1,=1ψlimϵ→0,σ1=σ,σ2=σ+ϵ1σ2−σ1∑r=1RlogΨσ1(Xr,Sr,θ)Ψσ2(Xr,Sr,θ).Eq. (12) clarifies the relation between the BMMI and MPE objective functions as the ratio of pseudo-probability function Ψσwith different margin values. For BMMI, the numerator margin σ1 is −∞, while for MPE the numerator and denominator margins tend to the same value. This relation is exploited in the next Section to define the dMMI criterion.The dMMI criterion was first proposed for generalizing BMMI and MPE criteria (McDermott et al., 2009, 2010). The dMMI objective function is defined as,(13)Fσ1,σ2dMMI(θ)=1ψ1σ2−σ1∑r=1RlogΨσ1(Xr,Sr,θ)Ψσ2(Xr,Sr,θ).As with BMMI and MPE, the dMMI objective function is the ratio of two pseudo probability functions. However, with dMMI, the margin parameters for both the numerator and the denominator terms can take arbitrary values. By setting σ1 at a large negative value (i.e. σ1→−∞), dMMI becomes equivalent to BMMI, except for a multiplicative constant.55In theory, this constant does not have any influence on the optimization. However, in practice it can affect the value of the learning rate for gradient optimization or the value of the weight for I-smoothing. In this work, we do not use I-smoothing with dMMI and employ the RPROP algorithm for the optimization, which only relies on the signs of the gradient. Therefore the multiplicative constant has no practical influence in our case.Similarly, looking at Eq. (12), we can see that setting σ1 and σ2 at values close to each other (i.e. σ1→σ2), dMMI becomes equivalent to MPE. Accordingly, dMMI generalizes MPE and BMMI, but also introduces intermediate criteria that will be of particular interest in this paper. The relation between dMMI, BMMI and MPE is summarized in Fig. 1.Note that the margin term of the denominator of dMMI has the same meaning as the conventional margin term of BMMI. Therefore, the margin term σ2 is usually set at a positive value as with BMMI. By setting σ1 at a negative value, the numerator margin enables a smoothed definition of the reference labels, i.e. only the recognition candidates with few errors remain in the summation of the numerator. This smoothed definition of references is expected to make dMMI more robust to errors in the reference labels as often occurs in unsupervised adaptation than MPE or BMMI. In the following sub-sections, we further elaborate this claim by interpreting the dMMI criteria as a smoothed version of BMMI or MPE objective functions.It is possible to interpret the dMMI objective function as a smoothed version of the BMMI objective function, i.e. as a weighted sum of BMMI objective functions that use different recognition candidates as reference labels, each term in the summation being weighted by a factor that decreases as the recognition candidate becomes further from the reference label Sr. Let us rearrange the terms in the denominator of Eq. (13) to reveal the above,(14)Fσ1,σ2dMMI(θ)=1ψ1σ2−σ1∑r=1Rlog∑kp(Xr,Sk;θ)eψσ1Ek,r∑np(Xr,Sn;θ)eψσ2En,keψσ2(En,r−En,k)︸≈1,(15)≈1ψ1σ2−σ1∑r=1Rlog∑kp(Xr,Sk;θ)∑np(Xr,Sn;θ)eψσ2En,k︸≜fσ2BMMI(Xr,Sk)eψσ1Ek,r,(16)=1ψ1σ2−σ1∑r=1Rlog∑kfσ2BMMI(Xr,Sk)eψσ1Ek,r,wherefσ2BMMI(Xr,Sk)is equivalent to the BMMI objective function for a training utteranceXrwhen assuming the kth recognition candidate Skis a reference label. We can make the approximation in Eq. (15) by noting that if we set σ1 at a negative value, the margin termeψσ1Ek,rwill become very small when the number of errors becomes large. This is illustrated in Fig. 2, which plots the margin term as a function of the number of errors for different values of the margin parameter σ1. We observe that for σ1 values smaller than e.g. −10, the margin term becomes very small when there are more than a few errors. Consequently, only the recognition candidates with few errors will remain in the summation term of the numerator, and therefore we can make the following approximations,En,r≈En,kandeψσ2(En,r−En,k)≈1in the denominator of Eq. (14).Eq. (16) reveals that dMMI with σ1 set at a relatively large negative value is a weighted sum of BMMI objective functions that employ different recognition candidates close to Sras reference labels. Therefore, dMMI emphasizes less reference labels Srthan BMMI. We believe that this intrinsic smoothing of dMMI may be beneficial to reduce the sensitivity to errors in the reference labels Sr.We can also interpret the dMMI objective function as the integration of MPE objective functions over a margin parameter interval as follows (McDermott et al., 2009, 2010),(17)1σ2−σ1∫σ1σ2FσMPE(θ)dσ=1ψ1σ2−σ1∑r=1R∫σ1σ2−∂∂σlogΨσ(Xr,Sr,θ)=1ψ1σ2−σ1∑r=1RlogΨσ1(Xr,Sr,θ)Ψσ2(Xr,Sr,θ)=Fσ1,σ2dMMI(θ),where we used the definition of MPE given in Eq. (11).Note that for σ>0,FσMPEcan be understood as the average error obtained by boosting recognition candidates that contain a large number of errors. This boosting effect may be useful to compensate for the potential low occupancy of recognition candidates with large numbers of errors, and therefore forcing the model to be more discriminative. However, when the reference labels contain errors, such a clear distinction between correct and incorrect hypotheses may become difficult and affect performance.When setting σ at a negative value, recognition candidates with a small number of errors are emphasized in the MPE objective function. In this case, the MPE criterion becomes less discriminative because it focuses on reducing errors for recognition candidates with only few errors and the contribution of recognition candidates with larger numbers of errors becomes small.By integrating over a margin interval, dMMI realizes a smoothed version of the MPE criterion. The smoothing is controlled by the margin interval. For example, by setting σ1 at a relatively large negative value, more weights will be given to recognition candidates with small numbers of errors, making the corresponding criterion less discriminative than conventional MPE, but more robust to errors in the labels.From the above discussion and Section 2.3.1, we observe that dMMI can have two distinct interpretations depending on whether we look at it as a generalization of the BMMI or the MPE criteria. In both cases, setting the value of σ1 at an appropriate value in the range (−∞, 0] should define criteria that may be more robust to errors in the reference labels than MPE or BMMI.Our aim is to confirm the robustness of dMMI to errors in reference labels for unsupervised adaptation. For this purpose, we employ LR adaptation, which is frequently used for acoustic model adaptation. After briefly reviewing the principles of LR adaptation, we introduce dMMI-LR and discuss practical implementation issues. Finally, we elaborate on the relation between dMMI-LR and other adaptation approaches.Linear regression-based adaptation such as MLLR (Gales and Woodland, 1996; Leggetter and Woodland, 1995) is widely used for supervised and unsupervised speaker adaptation. It consists of adapting the GMM–HMM acoustic model parameters using a linear regression as follows (Leggetter and Woodland, 1995),(18)μˆl=Alμl+bl=Llξl,whereμlandμˆlare the mean vectors of the lth Gaussian of the acoustic model before and after adaptation. Aland blare a transformation matrix and a bias vector, respectively. The LR transformation can be written in a simplified way as on the right-hand side of Eq. (18), which is obtained by introducing the following notations Ll≜[Albl] andξl≜[μl⊤1]⊤.Eq. (18) expresses adaptation only for the mean vectors of the Gaussians of the acoustic model. It is possible to perform the adaptation of the covariance matrices in a similar way, or by using the same transformation matrices for the mean vectors and covariance matrices as in constrained MLLR (CMLLR) (Gales and Woodland, 1996).66Note that dMMI-based variance adaptation has also been investigated in the context of noise robust ASR (Delcroix et al., 2012).Moreover, several topologies of the LR transformation matrices have been investigated including full, diagonal and block-diagonal matrices. The latter two are often used when the amount of adaptation data is limited. CMLLR can also be used for limited amount of data, since it can be implemented as a feature transformation, which requires fewer parameters and may therefore be less sensitive to over-fitting. In the following we use MLLR with full transform matrices since in our experiments we deal with tasks where the amount of adaptation data is considered to be sufficient.Using different LR transforms for each Gaussian of the acoustic model greatly increases the number of adaptation parameters. Instead, the LR transforms are usually shared among similar Gaussians. This can be realized using the binary tree clustering of the Gaussians of the acoustic model (Gales and Woodland, 1996). During adaptation, the occupancy count of each cluster in the binary tree is computed, but the adaptation parameters are calculated only for the clusters in the tree that have an occupancy count superior to a given threshold. For clusters that have an occupancy count value smaller than the threshold, the adaptation parameters of the parent cluster in the binary tree are used. This procedure ensures a sufficient amount of data with which to calculate the LR transforms.We use Ckto denote the set of Gaussians belonging to the kth cluster, and Lkto denote the corresponding LR transform. The set of all the adaptation parameters θ≜[L1, …, LK] is optimized as,(19)θˆ=argmaxθFθ(Xr,Sr),whereXris the sequence of feature vectors xtassociated with the rth adaptation utterance, i.e.Xr≜[x0,…,xt,…,xT]and Sris the set of corresponding reference labels. For unsupervised adaptation, Sris obtained from a first recognition pass and therefore inevitably contains errors.Conventional MLLR uses the likelihood as an objective function (Leggetter and Woodland, 1995). In this paper we investigate the use of the dMMI objective criterion instead. Note that others investigated the use of MPE or MMI for LR based adaptation (Wallhoff et al., 2000; Uebel and Woodland, 2001; Wang and Woodland, 2004; Gibson and Hain, 2012).We use gradient-based optimization to solve the problem of Eq. (19). We employ a lattice implementation to represent the set of recognition candidates. When using the dMMI objective function in Eq. (19), the gradient with respect to the adaptation parameters can be expressed as,(20)∂Fθ,σ1,σ2dMMI∂Lk=∑t∑q∈Qt∑l∈Ck,qγq,θ,σ1,σ2dMMIγl,tΣl−1(xt−μl)ξl⊤,where Qtis the set of all lattice arcs that contain the feature vector xt, Ck,qis the set of Gaussians within arc q belonging to cluster Ck, γl,tis the posterior probability of Gaussian l andγq,θ,σ1,σ2dMMIis the dMMI arc posterior probability or occupancy. The occupancy can be calculated by running the forward-backward algorithm twice on the same lattice once with σ1 and once with σ2 as (McDermott et al., 2010),(21)γq,θ,σ1,σ2dMMI=γq,θ,σ2−γq,θ,σ1σ2−σ1,where γq,θ,σis the standard BMMI arc posterior probability calculated with the forward-backward algorithm. The term∑q∈Qtγq,θ,σ1,σ2dMMIγl,tΣl−1(xt−μl)in Eq. (20) corresponds to the same statistics accumulated for the discriminative training of the acoustic models. Consequently, dMMI-LR can be implemented by simple modifications of an existing implementation of BMMI discriminative training.Note that for cluster-based LR adaptation, the LR transforms are updated at the clusters of the binary tree that have an occupancy count larger than a certain threshold. For dMMI-LR we use the occupancy counts calculated using the ML criterion instead of that given by Eq. (21) since the latter may take unrealistic values (i.e. negative values). The same strategy has been used for other discriminative criterion based adaptation (Uebel and Woodland, 2001).Several approaches can be employed for gradient optimization. Here we use the RPROP algorithm (Riedmiller and Braun, 1993) as it has been used successfully for discriminative training (McDermott et al., 2007; Heigold et al., 2012). We also employ an early stopping technique, where we fix the number of iterations using a development set.dMMI-LR shares characteristics with other acoustic model adaptation techniques. The use of a discriminative criterion for LR based acoustic model adaptation has been proposed previously, and includes such approaches as MMI-LR (Wallhoff et al., 2000; Uebel and Woodland, 2001), MPE-LR (Wang and Woodland, 2004; Gibson and Hain, 2012), MCE-LR (Wu and Huo, 2007; Hazen and McDermott, 2007) and soft-margin based LR (Matsuda et al., 2009). Most of these techniques target supervised adaptation where the quality of the reference labels is high. For unsupervised adaptation, several approaches have been proposed to mitigate problems with errors in the reference labels. For example, the 1-best recognition results usually used as labels were replaced by lattices for MAP (Matsui and Furui, 1996) and MLLR adaptation (Nguyen et al., 1999; Padmanabhan et al., 2000; Uebel and Woodland, 2001, 2001). Lattice-based MLLR achieves a smoothed definition of the references similar to dMMI-LR. However, it does not include the margin term that makes it possible to focus on recognition candidates with low errors.Another approach consists of calculating adaptation parameters only using words with high confidence scores. Such an approach was used for MLLR (Zeppenfeld et al., 1997; Uebel and Woodland, 2001) and extended to unsupervised discriminative adaptation (Wallhoff et al., 2000; Wang and Woodland, 2008; Gibson and Hain, 2012). In Wang and Woodland (2008) and Gibson and Hain (2012) the authors proposed weighting the terms in the numerator of the MPE objective function with an estimate of the correctness of each word in the reference labels. Accordingly, attention is given to reference labels with few errors in the mean error calculation. The word correctness estimation can be obtained from confusion networks (Wang and Woodland, 2008) or by using an SVM-based binary classifier (Gibson and Hain, 2012). These approaches achieve a similar smoothing effect to the margin term in the numerator of the dMMI objective function. However, for dMMI, the smoothing is intrinsic to the objective function. There are also implementation differences between our work and that of Wang and Woodland (2008) and Gibson and Hain (2012). Wang and Woodland (2008) and Gibson and Hain (2012) requires a separate module to estimate the word correctness. Moreover, they employ different lattices generated with strong and weak language models for the numerator and denominator of the objective function. The proposed dMMI-LR uses the same lattices for the numerator and denominator, which may simplify the implementation.Finally, let us mention another interesting approach for unsupervised adaptation designed to estimate discriminative mapping transforms between MLLR and MPE-LR transforms (Yu et al., 2009). The discriminative mapping transforms can be estimated during training and are therefore unaffected by the quality of the reference labels when performing unsupervised adaptation. In this regard, our approach is fundamentally different because we perform direct adaptation experiments using the test data as adaptation data.

@&#CONCLUSIONS@&#
