@&#MAIN-TITLE@&#
Multisensory texture exploration at the tip of the pen

@&#HIGHLIGHTS@&#
Sketch-a-Scratch is an abstract interactive object for multisensory texture exploration.Only nonvisual feedback induces significant behavioral variations in a steering task over a texture.Regardless of the richness of feedback, a virtual texture is experienced differently from the real one.

@&#KEYPHRASES@&#
Pen-based interaction,Pseudo-haptics,Multisensory textures,Sonic interaction design,

@&#ABSTRACT@&#
A tool for the multisensory stylus-based exploration of virtual textures was used to investigate how different feedback modalities (static or dynamically deformed images, vibration, sound) affect exploratory gestures. To this end, we ran an experiment where participants had to steer a path with the stylus through a curved corridor on the surface of a graphic tablet/display, and we measured steering time, dispersion of trajectories, and applied force. Despite the variety of subjective impressions elicited by the different feedback conditions, we found that only nonvisual feedback induced significant variations in trajectories and an increase in movement time. In a post-experiment, using a paper-and-wood physical realization of the same texture, we recorded a variety of gestural behaviors markedly different from those found with the virtual texture. With the physical setup, movement time was shorter and texture-dependent lateral accelerations could be observed. This work highlights the limits of multisensory pseudo-haptic techniques in the exploration of surface textures.

@&#INTRODUCTION@&#
In everyday interaction with the environment, we experience surface textures mostly through touch and vision, although audition can also contribute to forming multisensory percepts (Klatzky and Lederman, 2010). The importance of haptics for conveying a similar experience in virtual and augmented environments has been widely advocated (Robles-De-La-Torre, 2006), although force-feedback devices are impractical or expensive in many contexts. This explains the emergence of pseudo-haptics (Lécuyer, 2009; Mensvoort et al., 2010), that is the exploitation of multisensory illusions to render forces through alternative sensory channels. The present work belongs to the area of experimental pseudo-haptics, as it seeks evidence of the effectiveness of image, sound and vibration as sensory substitutes of lateral forces in texture exploration tasks. As opposed to most existing works in this area – which rely on physical separation between the pointing device and the locus of visual interaction – we consider interactions where action and feedback are co-located, though mediated by a tool (stylus). This is indeed the typical situation of many manual activities that afford the development of expressiveness and virtuosism, such as painting or drawing.To show if and how modulations of visual, auditory, and vibratory feedback differently affect the perceived lateral forces during surface exploration, we designed a system based on a vibroacoustically augmented graphic tablet and on real-time physics-based simulation of contact mechanics. This apparatus can render surface textures by means of visual, auditory, and vibratory feedback. An experiment was designed to look for behavioral evidence of the effects of different kinds of feedback on constrained gestures. For this purpose, the trajectories and forces were measured by using the digitizing tablet itself. The assumption that these forces and trajectories may be affected by perceived (illusory) shear stresses was experimentally tested. The proposed experiment is markedly different from prior assessments of pseudo-haptic techniques, which were based on subjective estimation or magnitude production. It gives the possibility to further validate or to refute previous claims on the effectiveness of pseudo-haptics.The proposed tool for the multisensory exploration of virtual surface textures qualifies as an abstract interactive object, that is an object designed with the goal of improving our understanding of some interaction primitives (Svanæs, 2013). In particular, we used a constrained steering task to quantify how the feedback in different sensory modalities affects the same surface-rubbing gesture. Since it has been shown that lateral forces do affect accuracy in steering tasks over physical textures (Sun et al., 2012), we looked for similar behavioral effects when multi-sensory pseudo-haptic feedback is used to substitute the actual lateral forces. A qualitative evaluation of the interaction under different combinations of sensory feedback was also made possible by comparison with the physical, real-world realization of such stylus-surface interaction.It has been shown that forces are dominant over geometric features to convey information about surface profiles through active touch (Robles-De-La-Torre and Hayward, 2001). Based on this evidence, attempts have been made to substitute lateral forces by visual vibrations of the mouse cursor and by vibratory feedback at the mouse manipulation point (Hachisu et al., 2011). The frequency of these vibrations would mirror the changes in the speed of the cursor, as they are introduced in the pseudo-haptic paradigm proposed by Lécuyer (2009). This kind of substitution, however, is not trivially transferable to surface-based interactions such as those with touchscreens, since it relies on dynamic changes of the control/display ratio of the input device. Local and dynamic image deformations were also proposed to convey a sensation of stiffness (Argelaguet et al., 2013), and it was shown that they can render several levels of apparent stiffness in manipulations through pointing devices. The effectiveness of these techniques in touchscreens and tablet-based interactions has not been ascertained yet.In order to overcome the difficulties of using sensory illusions in more direct manipulations, such as those found in tablets, some researchers have proposed to stretch a rubber membrane over a frame on top of the touchscreen (Lefebvre and Pusch, 2012). This increases the perceived sense of physicality in the continuous deformation of virtual objects. In this case, the control/display ratio is used to alter the perceived level of resistance of the virtual object, by controlling the extent to which finger movement is translated into object deformation.Bau et al. (2010) proposed TeslaTouch, a tactile feedback for touch interfaces based on electrovibration at the bare finger tip.Harrison and Hudson (2012) demonstrated how shear can expand the range of possible interactions at the touchscreen, and how it can be used to implement a variable control/display ratio, without sacrificing any screen real estate. What they proposed is equivalent to having an isometric pointing stick at the point of touch. Their experimental apparatus was built by mounting a capacitive touchscreen on top of a LCD display. Operating between the display and touchscreen were two analog joysticks. Shear-sensitive touchscreens may be suitable for pseudo-haptic feedback enhancement for texture exploration.McDonald and Kuchenbecker (2013) proposed a haptic simulation model for tool-mediated texture interaction, that is surface texture exploration mediated by a handheld stylus provided with sensors and a vibrotactile actuator. Their measurements show that lateral and axial accelerations at the probe form trains of complex pulses, each corresponding to a contact event between the tip of the tool and a ridge in the texture grating. In their setup, a dynamic model is used for impacts, and forces are transferred from the normal to the transversal plane via friction.In sound synthesis, several models exist that describe the contact phenomena occurring at the interface between an object and a surface. Friction is one such phenomenon based on stick-slip commutation (Avanzini et al., 2005). Other salient phenomena such as rolling are rendered by patterns of impacts (Rath and Rocchesso, 2005). In those studies and models, surfaces are often specified as one-dimensional height profiles, either sampled or generated algorithmically.A flexible sound synthesizer for scratching, rubbing, and rolling sounds has been developed by Conan et al. (2013, 2014): sound generation is based on a dynamic impact model, and impacts are distributed in time and controlled in amplitude according to stochastic models of scratching, rubbing, and rolling. Another synthesis engine is the Sound Design Toolkit (Delle Monache et al., 2010), which offers a set of physics-based sound models organized according to an ecological taxonomy of everyday sounds.A remarkable work that uses the exploration of physical textures for sound-generation purposes is that of Merrill et al. (2008). They proposed to use physical textures as affordances for brushing, scraping, striking, etc., and these gestural actions could be exploited for continuous playback and modification of prerecorded audio samples.Only a few studies have investigated if and how texture sounds can affect motor behavior. Castiello et al. (2010) showed that the sound of fingers on different material textures affects movement duration in a reaching-to-grasp task, with sounds that are congruent with the visual appearance producing shorter movement durations. Moreover, their experiments provided evidence that the contact sound is used by both the planning and the on-line control systems at the neural level. In an experiment aimed at revealing how sound may affect materiality and behavior in the use of touch screens, Tajadura-Jiménez et al. (2014) sensed finger gestures of free exploration and linear displacement to drive synthesized textural sounds of controllable nature and frequency content. They found very small effects of sound quality on movement speed and finger pressure, for blindfolded subjects.Stylus-mediated exploration of a surface can be seen as a trajectory-based task (Accot and Zhai, 1997). The steering-law model, as derived by Accot and Zhai, was proposed to predict the performance of different devices when used for steering constrained paths on a surface (Accot and Zhai, 1999; Kulikov et al., 2005). The typical goal for those tasks, however, is quite different from free exploration, as participants were not free to wander. Conversely, they were usually requested to perform a stroke as quickly and as accurately as possible, without crossing the boundaries of a prescribed corridor.It has been shown that different kinds of error feedback (visual, tactile, auditory, none) have no effect on movement time (Sun et al., 2010). Conversely, the same research showed that accuracy seems to improve with tactile feedback. However, it should be noted that error feedback is not ecological, and is very different from the multisensory feedback that one would get when steering a path with a stylus on a textured surface. In the specific application context of cascading menu selection, the effect of superimposed visual force fields on selection time was measured (Ahlström, 2005). This pseudo-haptic artifice, which manipulates the pointer׳s movement, was shown to reduce selection time.Sun et al. (2012) had the intuition that, when steering a path using a pen, the physical quality of the surface may play a role in the performance. They superimposed sheets of different materials on a graphic tablet and used the steering-law experimental paradigm. Although they did not observe any effect on movement time, they did find that different surfaces affected accuracy and applied force. This provides evidence that people approach the stroke differently, depending on the surface they are drawing on.Andersen and Zhai (2008) checked how handwriting and pen gestures may be affected by different kinds of feedback (no feedback, visual, audiovisual, auditory). Audio-only (continuous sound) and no feedback had an effect in reducing the ability to control the size and the closure of shapes. They also tested different kinds of stimuli such as rhythmic patterns or variable-speed music. Although change in performance was not clearly observed, a large variability of subjective ratings of user satisfaction was reported. They found that people tend to better remember the spatial patterns rather than the auditory patterns, as if gestures would be directly reproduced from memory, and feedback would not add much modulation to this process, except where there are reference points to be crossed.Many examples are found in the literature, of abstract interactive objects or artifacts that were not conceived to address users׳ needs, but rather to afford experimentation and to improve the knowledge and understanding of specific interaction gestalts. The construction of such devices is central in many research-through-design activities (Zimmerman et al., 2007). In haptics, an abstract interactive object based on rolling simulation was proposed by Yao and Hayward (2006). Their realization, for example, allowed to test if a person could rely on either the ball rolling rumble, or the time-to-collision cue, in a length estimation task. Examples in sonic interaction design are the Spinotron (Lemaitre et al., 2009), based on the simulation of a ratcheted wheel, the Flops (Lemaitre et al., 2012), based on pouring virtual balls out of a glass, and the Ballancer (Rath and Rocchesso, 2005), based on a rolling ball simulation. An example of artifact that integrates audio and touch for exploratory purposes is the PebbleBox (O׳Modhrain and Essl, 2013).Two-dimensional textures can be observed visually and acquired as pictures, or they can be experienced with touch through scanning processes. Exploration with the bare finger gives a spatial, intensive measure of roughness. Tool-mediated exploration along a trajectory (indirect touch) produces what is essentially a multidimensional signal in the time variable only, carrying information about surface roughness, hardness, and friction. Indirect touch often produces an audible signal that carries the same kind of information through sound (Klatzky and Lederman, 2010). On the other hand, any sound signal can be interpreted as a surface profile that may be appreciated with the other senses.In this perspective, we designed a tool named Sketch-a-Scratch, that allows us to specify textures in one or two dimensions with different means, and to move seamlessly from vision to touch to audition (Delle Monache et al., 2015):Image→sound/vibration: An image is scanned along a line, and luminance values converted into a one-variable surface roughness profile. This can be explored by scraping, rubbing, or rolling (Fig. 1), and the instantaneous force and displacement of vibrating surfaces are rendered by means of a vibrotactile actuator or a loudspeaker.Vibration↔sound: A physical texture is scanned using a probe, and a piezo sensor is used to capture the resulting vibrations. Alternatively, any sound, especially if inherently textural, can be used as a surface profile to be experienced through touch. Some notable possibilities for the specification of textures in the audio domain are the following:Voice: We naturally use our vocal apparatus to imitate sound textures of many kinds, including those produced by continuous contacts of an object with a surface.Synthesis: Several techniques are available to (re-)synthesize sound textures (Strobl et al., 2006).Sound/vibration→image: Audio or vibrotactile signals (of one variable) can be used to produce an image in different ways. One trivial yet effective transformation used in our tool is the stacking of luminance-translated audio signals to produce rows of pixels. This sound-to-image transformation affords different kinds of subsequent image-based exploration of the sound material (temporal expansion, inversion, interlacing, etc.).Texture-exploration actions can be described by microscopic contact events occurring between the probe and the surface, which can be simulated by impact and friction models (Papetti et al., 2011; Avanzini et al., 2005). While Sketch-a-Scratch affords exploration by scraping, rubbing or rolling, for the sake of this investigation only point-wise micro-impacts were considered. When the full-fledged tool is used, the dynamic nature of the impact and friction models allows one to seamlessly morph between the different kinds of surface exploration, thus opening to performative utilization.In addition to displaying visual textures on its screen, Sketch-a-Scratch implements local image deformations that may be used as a visual pseudo-haptic effect. The image is locally deformed at the point of interaction as if the stylus was exerting superficial vertical and lateral forces.Sketch-a-Scratch uses an impact model that describes two colliding bodies: a point-mass (exciter) and a resonating object. The contact force fiis a function of the object compression x and compression velocityẋ:(1)fi(x,ẋ)={−kxα−λxαẋ,x>00,x≤0where k accounts for the object stiffness, λ represents the force dissipation, and α describes the local geometry around the contact surface. Whenx≤0the two bodies are not in contact.In the current implementation, a surface profile modulates the relative displacement offset between the exciter (stylus) and the resonating object (texture). The normal force applied to the stylus is also used to modulate the impact force calculated by the model.The impact model produces vibratory signals that can be output as sound, as well as used to drive a vibration transducer, rendering respectively the aural and vibrotactile outcome of texture exploration. Although not used in the current realization, the model dynamics also produce forces which could be rendered through a haptic device. Similarly to what done by McDonald and Kuchenbecker (2013), in our experimental apparatus the stylus is actuated by means of a vibrotactile transducer driven by the low-frequency components of the synthesized audio output.Sketch-a-Scratch is based on a13.3in Wacom Cintiq graphic tablet, which offers a high resolution screen (1920×1080pixels) and a stylus. A TactileLabs Haptuator Mark II vibrotactile transducer was attached to the stylus (see Fig. 2, notice that the “eraser tip” is used). A mylar-cone dynamic speaker (Pro Signal ABS-209-RC, diameter: 45mm, frequency response: 500–5500Hz) was taped to the back of the tablet and wired to one of the two channels of a Sonic Impact T-Amp amplifier, the other channel being connected to the vibrotactile transducer. In this way, sound and vibration were consistently produced at the locus of action.On the software side, Sketch-a-Scratch is an application for Max 6.11cycling74.comThe graphical user interface shown in Fig. 3allows one to load images, record audio tracks, and turn them into surface profiles, moving seamlessly from one domain to the other. The surface profiles can be explored with virtual probes of different characteristics, thus simulating scraping, rubbing, or rolling. Exploration can be either automatic by acting on the GUI (passive), or manually driven by the stylus (active).The visual representation of textures displayed by the graphic tablet can be locally distorted to mimic the deformation of a virtual membrane being pushed by the stylus.The micro-impact synthesizer is outlined by the green box in Fig. 3. Impacts are described in terms of stiffness, sharpness, dissipation, and resonances. The vertical penetration of a virtual probe sets the threshold level of the roughness profile above which contact signals are produced, and is controlled by the pressure applied by the stylus.Extensive demonstrations (Delle Monache et al., 2015) and performances with Sketch-a-Scratch let us collect several user comments and expressions of interest. First-person reports confirmed that the addition of sound and vibration can alter the feeling of the surface being explored, as well as the perceived shape of the probe (or pencil, or brush). The overall experience is enriched, and activities such as drawing are described as more engaging. Some illustrators recalled the rich sensory experience of drawing with different pens and pencils on various paper materials, and how they miss it when drawing on tablets. They showed interest in possible applications of Sketch-a-Scratch to simulate different tips and surfaces for drawing purposes.Although anecdotal comments of casual users provided useful confirmation to the design of Sketch-a-Scratch, it is important to have objective measurements of how the design assumptions are reflected in actual use. In particular, a crucial open question is: Can sound or vibration rendering actually affect the action, substituting for lateral forces that are not produced at the smooth surface of the tablet? To investigate this research question, we designed a controlled experiment in which Sketch-a-Scratch is used as an abstract interactive object. The experimental task is that of steering a path within a prescribed corridor, under different feedback conditions.Although the task is similar to what is usually done to derive the parameters of the steering-law, we are not interested in extracting an index of difficulty or other measures of performance for the given apparatus. Instead, we aim to verify if and how the different combinations of feedback modalities affect the time and uncertainty of execution, as well as the applied force.The suggested task clearly differs from the free or performative exploration of a surface texture. However, if we can measure systematic modifications or modulations of action in such constrained conditions, we can reasonably infer that even larger modifications will occur in free or performative exploration. Support for such a generalization comes from the observation, often made in HCI research, that the expressive intentionality of a gesture directs perception towards the sensory information that becomes ready-to-hand (Svanæs, 2013).The design of the experiment and the experimental procedure is described in this section. The results are described in Section 6. Section 7 describes a post-experiment, where measurements were taken on a concrete physical realization of the same virtual texture.All the components of the experimental apparatus (Sketch-a-Scratch) are illustrated in Fig. 2.The Wacom Cintiq tablet displayed the path that the participants were requested to trace. The path was made of rectangular (9×4mm) bars arranged along a cosinusoidal shape (horizontal extension=291mm, vertical extension=46mm). The length and width of the path were chosen after checking the literature (Sun et al., 2010) and informal testing, in such a way that movement times in the range 2–3s would be most likely. In the steering-law studies, the experimental paths are usually either rectilinear or circular (Accot and Zhai, 1999; Sun et al., 2010, 2012), and different combinations of length and width are provided as experimental factors. Conversely, we were interested in having different combinations of feedback modalities as a factor, and to see how they may affect the exploration of textures that exhibit variation along one dominant direction (such as those, for example, derived from vocal signals). We avoided the use of a simple rectilinear path, because we suspected that participants may internalize the movement of a rectilinear stroke, and trigger it without using multisensory feedback but proprioception. The cosinusoidal shape is somewhat harder to internalize and, therefore, participants are more likely to take advantage of all sensory feedback that becomes available. Two yellow markers (visible in Fig. 2) were attached to the tablet frame to indicate the starting and ending positions.The impact model was set to simulate impacts with small metal bars. The luminance values of the displayed path were converted into a corresponding surface profile, whose exploration resulted in contact sounds (at about 51dB(A)) and vibration. Audio or audio-tactile feedback was produced when the stylus encountered the bars along the cosinusoidal path, irrespective of whether the path was visually displayed.During the task execution, the apparatus recorded the following data to separate text files for each trial: elapsed time (in ms), stylus position as x and y screen coordinates, normal force, tilt, lateral acceleration along the x-axis. Normal force, tilt and position of the stylus were read directly from the Wacom driver. The data were sampled at 200Hz, while their resolution varied with the different variables: e.g., the coordinates x and y have pixel resolution (1920×1080), and the normal force has 11-bit resolution (2048 levels).Fourteen volunteers (seven male, seven female, age ranging from 20 to 55, with an average of 33.9 years and standard deviation of 10 years) participated in the experiment. All the participants reported normal hearing, and normal or corrected to normal sight. They performed the test using their preferred hand (three left-handed, eleven right-handed), and all of them chose to perform the task from left to right. The experiment was conducted in an office environment, with normal lighting conditions and background noise not exceeding 45dB(A).The experiment was a 10×11 repeated measures design with ten trials and eleven feedback conditions. The conditions were:1.Visual staticVisual dynamicAuditoryVibratoryVisual static+auditoryVisual static+vibratoryVisual dynamic+auditoryVisual dynamic+vibratoryAuditory+vibratoryVisual static+auditory+vibratoryVisual dynamic+auditory+vibratoryBefore the test, each participant was briefed and exposed to each of the 11 conditions, and then let free to explore them. The task was described as that of tracing the path as fast as possible without leaving the corridor, in a single stroke. It was explained that, in order to stay within the prescribed path, the participant could exploit all the available sensory cues (visual, vibratory, auditory) that were available at the moment.Afterwards, the experimenter started the randomized sequence of trials, whose progression was automatized. A bell sound before each new trial gave a start signal to the participant, who had at most 8s to steer the stylus through the path. A random time interval, ranging from 2s to 4s was added before prompting the next trial.After the test, the participant was debriefed and exposed to a physical realization of the textured path, made of paper and wood (Fig. 2, bottom right). This realization has exactly the same shape and size of the image displayed on screen, but the bars are thin (1mm) wooden rectangular pieces glued over a paper sheet, and a second sheet of tracing paper is overlaid, so that a pen-based exploration of the path would induce surface deformations. Comments about the traversing experience on the tablet under different feedback conditions, as well as on the physical version of the path, were collected.

@&#CONCLUSIONS@&#
