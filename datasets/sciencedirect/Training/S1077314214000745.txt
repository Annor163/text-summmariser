@&#MAIN-TITLE@&#
Active subclustering

@&#HIGHLIGHTS@&#
A novel algorithm is proposed for a new problem called subclustering.An active algorithm for subclustering (human in the loop) is also proposed.An evaluation criterion Subclustering Jaccard’s Coefficient is developed.Experiments on a face and a leaf image dataset are performed.Also a faster version of Partition Around Medoids clustering is proposed.

@&#KEYPHRASES@&#
Subclustering,Clustering,Human in the loop,Active learning,Face images,Leaf images,Subclustering evaluation,

@&#ABSTRACT@&#
Although there are many excellent clustering algorithms, effective clustering remains very challenging for large datasets that contain many classes. Image clustering presents further problems because automatically computed image distances are often noisy. We address these challenges in two ways. First, we propose a new algorithm to cluster a subset of the images only (we call this subclustering), which will produce a few examples from each class. Subclustering will produce smaller but purer clusters. Then we make use of human input in an active subclustering algorithm to further improve results. We run experiments on a face image dataset and a leaf image dataset and show that our proposed algorithms perform better than baseline methods.

@&#INTRODUCTION@&#
Humans often search for images in a large database. For example:•Consider video surveillance data in airports. An analyst may want to search through the surveillance data to find out if person A was present in the airport on a particular day. She might have an image of A or textual descriptions of A. These can be used to perform image retrieval, but the results are often not good enough to guarantee that if A does not appear among the top retrieved images, A is not present in the database. That requires the analyst to exhaustively browse [1] through the database to determine whether A is present. Also retrieval results from an unlabeled database are often redundant as images of the same person may show up many times. However if we can create an organized collection of face images containing a few different images of each person present in the airport, it will be significantly easier for the analyst to browse them to detect the presence of A.There has been interest recently in plant species identification (e.g.: Leafsnap [2–5]). These systems produce large collections of unlabeled images of organisms (e.g.: leaves in Leafsnap) uploaded by users. Biological enthusiasts are often interested in browsing the database to find a species of interest. In this scenario also, it is useful to create a leaf image collection from the unlabeled images that only contains a few images from each class present in the data, allowing easy browsing.In both examples we start with a large collection of unlabeled images. These images can be clustered using traditional clustering algorithms [6–9] to facilitate browsing, allowing a user to examine meaningful subsets of images. Accurate clustering, though, is extremely difficult when there are a large number of clusters. Moreover, clustering based on automatically computed image distances inevitably produces errors, as current algorithms do not fully capture perceptual similarity.To cope with this challenge, we introduce the idea of subclustering, in which we cluster only a small subset of images. Our goal is to create clusters that represent each object in the image set with a few images. For example, in the surveillance scenario, subclustering aims to create clusters containing a few images of each individual. Subclustering has the potential to produce more efficient algorithms, and to produce more accurate clusters by ignoring images that are hard to categorize.We also assume that a modest amount of labeling effort can be obtained from humans to improve subclustering. Human input can take many forms. In this paper we abstract human input to the simple operation of providing constraints on whether or not two images come from the same class.1We will use classes/categories to imply the ground truth and clusters/subclusters to imply algorithms’ output throughout the paper.1This is a widely used assumption in active clustering[10–17]. It is a useful abstraction because often it is difficult for people to assign a label to an image (they may not be able to assign a name to a face in a surveillance video, or to a particular plant specimen), but much easier to assess whether two images come from the same class (humans can compare face images with 99% accuracy [18]). When class labels are available, they may be represented as sets of pairwise constraints.Our two main contributions in this paper are:1.We propose a new passive subclustering algorithm where no human input is required. We propose a cost function suitable for subclustering and optimize it with an algorithm motivated by the Partition Around Medoids (PAM) [7] algorithm. In experiments we show that our approach produces much better subclusters than those produced by several baseline algorithms. Our subclustering algorithm reduces run-time byO(N)compared to a similar complete clustering algorithm like PAM, where N is the total number of images in the dataset (Section 4).We also propose a new active subclustering algorithm that uses pairwise constraints on the clusters. The algorithm repeatedly selects an image pair and asks a user whether they belong to the same category or not. Pairs of images are chosen such that existing errors in a subclustering are corrected with limited human interaction. In experiments we show that we can accurately subcluster a face image dataset with 51,418 images of 200 classes with around 143,000 pairwise constraints from humans (equivalent Mechanical Turk cost: $358). In general active algorithms for complete clustering require much more human supervision [10,17] and are often too slow to run on large scale datasets [16] (Section 5).We run experiments in two different domains: face images (the complete Pubfig dataset [18]) and leaf images [2]. We show that our proposed algorithms perform much better than baseline algorithms. A pipeline of our proposed system for subclustering is depicted in Fig. 1.Clustering images has been an interesting problem for decades [9]. Although automatic clustering algorithms produce reasonable results for datasets with a few clusters, clustering datasets with a large number of clusters is still an open problem. Recently, active/semi-supervised clustering algorithms [10,16,17] where humans provide pairwise constraints (“must-link” and “can’t-link”), have produced much better clustering results. However, as the data size (number of images and classes) increases, the required number of pairwise constraints increases so much that human-in-the-loop clustering algorithms become impractical. Therefore we propose a new problem called subclustering. Subclustering aims to produce a clustering that contains n images from each category withn<Nk(whereNkis the actual number of instances of class k present in the full dataset). This will produce smaller but purer clusters and will require significantly less human input. Since large unlabeled image collections are highly prevalent these days subclustering can have a wide range of applications including browsing image databases, image search, summarizing image databases, category discovery, etc.Input to a subclustering algorithm will include a pairwise distance matrix, the number of clusters and the number of images required (n⩾1) from each class. We emphasize that a subclustering algorithm’s goal is to extract any n images from each class. For large real world applications, where each class is expected to have many (more than 100) images, we find thatn=10is reasonable. It is not too large that subclustering becomes error-prone and also not too small that images from the same class do not show variation. In Fig. 2we show some typical subclusters produced after using our passive and active algorithms. Although the number of examples from each class is small, they have enough intra-class variation that humans can determine how these people look and compare them to a new face image. We note that subclusters are not intended for training classifiers because they are small and may not represent the complete distribution of each class. Subclustering and its use for browsing large image databases is partially motivated by the fact that humans can learn reasonable object models even from a small set of examples [19].Although it is possible to create subclusters from complete clusters, algorithms solely built to solve subclustering create purer subclusters. Intuitively it is clear that points that are difficult to cluster can affect the results of clustering algorithms in a way that degrades the clustering of easier points. That is, it is better to solve the problem we want to solve directly (subclustering), rather than trying to solve a harder problem (clustering) as an intermediate step.

@&#CONCLUSIONS@&#
