@&#MAIN-TITLE@&#
Backward induction algorithm for a class of closed-loop Stackelberg games

@&#HIGHLIGHTS@&#
We propose a new, closed-loop continuum-strategy discrete-time Stackelberg game.We reduce the game to a finite game and give a backward induction algorithm for the solution under payoff convexity.We illustrate how to use the algorithm for game regulation.The finite version of the game is also given with its reduction and solution method.Examples are also given on the application of the results.

@&#KEYPHRASES@&#
Game theory,Closed-loop Stackelberg game,Leader–follower equilibrium,Backward induction algorithm,Game regulation,Dynamic programming,

@&#ABSTRACT@&#
In the paper a new deterministic continuum-strategy two-player discrete-time dynamic Stackelberg game is proposed with fixed finite time duration and closed-loop information structure. The considered payoff functions can be widely used in different applications (mainly in conflicts of consuming a limited resource, where one player, called leader, is a superior authority choosing strategy first, and another player, called follower, chooses after).In case of convex payoff functions and certain parameter values, we give a new particular backward induction algorithm, which can be easily realized to find a (leader–follower) equilibrium of the game (in a certain sequential equilibrium realization from the last step towards the first one with respect to the current strategy choices of the players). Considerations on uniqueness and game regulation (i.e. setting parameters of the game to achieve a predefined equilibrium) are also provided. The finite version of the game (with finite strategy sets) is also given along with its simplification and solution method. Several practical examples are shown to illustrate the comprehensive application possibilities of the results.

@&#INTRODUCTION@&#
Continuum-strategy deterministic Stackelberg games, in which the players’ strategy choices take place in a determined order (von Stackelberg, 2011), form an important and intensively developing field in game theory (Benchekroun & Withagen, 2012; Hoffmann & Rota-Graziosi, 2012; Staňková & De Schutter, 2011; Staňková & Olsder, 2006). An extremely important application area is water resource management, where game theory (and Stackelberg games) plays an increasing and basic role, see e.g. (Madani, 2010).In continuum-strategy games, the players have strategy sets of cardinality of the continuum, in discrete games the strategy sets have finite or even countable cardinality. It may be convenient to normalize the strategy sets of continuum-strategy games if possible, that is if the problem can be reformulated such that the admissible strategies (or their coordinates) are elements of the interval [0,1], see e.g. (Teraoka, Osumi, & Hohjo, 2003). The solution of games with finite strategy sets are generally simpler and can be generated with the well-known dynamic programming (Bertsekas, 2007; Nie, Chen, & Fukushima, 2006).In game modelling, a particular role is played by Stackelberg games where a player, the leader, moves first, followed by the other(s), the follower(s) (leader–follower games). The Stackelberg game with its Stackelberg equilibria (leader–follower equilibria) provides more real representation and better solution of problems in many practical cases than the classical non-cooperative game with Nash equilibria (Bhaskar, Fleischer, & Anshelevich, 2013; Huck, Müller, & Normann, 2001; Sharma & Williamson, 2009). For example Stackelberg outcomes may be equivalent to equilibria in accumulation games (Romano & Yildirim, 2005). The fact that Stackelberg equilibria can be suited for realized game solutions is also supported with measurements (Coleman & Stirk, 1998).Stackelberg games are important in the field of optimization theory as well, since they can be considered as bi-level optimization problems (Brückner & Scheffer, 2011; Dempe & Franke, 2014; Du, Jiao, & Chen, 2014; Jungers, Trélat, & Abou-Kandil, 2011; Motto, 2005; Nie, 2005; Nie et al., 2006). Accordingly, certain optimization tasks can be solved by specifying equilibria of Stackelberg games (Roughgarden, 2004), while others can be solved with a good approximation (with a prefixed error bound) in this way (Roughgarden, 2004; Bhaskar et al., 2013). In view of application in control theory, it should be noted that the solution of certain optimal control problems cannot be only theoretically provided as a Stackelberg equilibrium but also the optimal (or nearly optimal) control can be practically achieved in the way of transforming the problem to a Stackelberg game. For the minimization of the overall total latency in case of several individual users, Sharma and Williamson (2009) and Roughgarden (2004) serve with examples of computer networks and shared machines. The problems are solved with central control, which means mathematically the reformulation of the problems as Stackelberg games.Deterministic theory is fundamental also in case of Stackelberg games charged with uncertainties or stochastic processes, since generally, the problems can be transformed to deterministic forms with appropriate distribution functions (Caldentey & Haugh, 2010; Korzhyk, Conitzer, & Parr, 2011; Korzhyk, Yin, Kiekintveld, Conitzer, & Tambe, 2011).In certain Stackelberg games, the players move in time continuously (as in differential games, see. e.g. (Freiling, Jank, & Abou-Kandil, 1999; Freiling, Jank, & Lee, 2001; Martín-Herrán, Taboubi, & Zaccour, 2005)), which comes from the mathematical formulation of the problems, in other games the players move in discrete time steps sequentially. Several above references correspond to discrete-time games with fixed time duration.Two-player discrete-time dynamic Stackelberg games are characterized with state equations, according to which the game evolves in time, see (Staňková & De Schutter, 2011):at+1=A(at,xt,yt,t) (t=1,…,T−1);T∈N: number of time steps,at∈R: state of the game at time t,xt,yt∈R: strategy of the leader and the follower, respectively, at time t,A: function determining the next state from the current state and current strategies.At each step, the leader chooses a strategy first then the follower.There are three basic types of games according to the information structure: In case of open-loop structure the players know the initial state a1 (see e.g. (Nie, 2005; Staňková & De Schutter, 2011)), in feedback games they know the current state at(see e.g. (Nie et al., 2006; Staňková & De Schutter, 2011)) and in closed-loop games they know all states up to the current one a1,…,at(see e.g. (Staňková & De Schutter, 2011; Vallée, 1998)).Open-loop dynamic Stackelberg games can be essentially rewritten in the form of static games, for which there are straightforward and widely worked out solution procedures in the literature. In static games, players move simultaneously, so there is no sequential order. The solution of closed-loop games remains a challenge (Staňková & De Schutter, 2011). Although there are general solution methods, they are mostly of theoretical significance, their application (the execution of the corresponding mathematical operations) is extremely difficult or unachievable in practice.Classical optimization theory approach can be found in (Başar & Olsder, 1995), where the well-known Hamiltonian–Lagrangian function has to be determined. Among other conditions, strict concavity of the leader’s payoff function is needed for the applicability of the method. An example for application can be found in (Vallée, 1998). In (Nie et al., 2006) feedback Stackelberg games are handled as dynamic bi-level optimization problems, for the solution of which different algorithms are proposed. At each step of the game, the authors assume that there exists a unique solution for the lower level problem. If there are non-unique responses of the followers, it is inconvenient to apply the algorithms. In (Staňková & De Schutter, 2011) solution concept is proposed by means of transforming the game to a team optimum problem, if the transformation can be carried out. The importance of the results is mostly theoretical, although there are two practical examples as well in the work for two short games (with one and two steps). It is described in (Chen & Cruz, 1972), in a conceptual and general manner, how to employ dynamic programming for discrete- and finite-time Stackelberg games. The practical applicability of the method is limited again as well as that of the so-called inducible region concept in (Luh, Chang, & Chang, 1984). Informally, the inducible region is the set of the rational outcomes of the follower for all the leader’s strategies.Since it is difficult to apply general concepts, special solution methods must be used or worked out in case of different conditions and applications. For example in (Motto, 2005), a certain type of Stackelberg games is identified with a nonlinear two-level decision problem, for which conceptual solution is given with linear programming. The lower level problem is a linear programming problem. A dynamic programming algorithm is proposed in (Xia & Conitzer, 2010) for a Stackelberg voting game, which is efficient if the number of alternatives is finite. In (Başar & Selbuz, 1979) explicit solutions are given for deterministic nonzero-sum dynamic games with multiple players, linear state dynamics and quadratic cost functions. Uniqueness theorem and relation for the follower’s best response are given in (Dastidar, 2004) in case of concave demand and strictly convex payoff functions.Because of the difficulties of the closed-loop problems, different approximate or heuristic methods are also often used. For example in (Cardinal et al., 2011), approximate solution algorithms are introduced for the Stackelberg minimum spanning tree game. The rate of convergence is also given for the algorithms. An iterative method is shown in (Kitti, 2000) to determine the Stackelberg equilibrium in case of strict convexity of the follower’s payoff function if the follower’s best response is known a priori. An example for the application of a heuristic method, the genetic algorithm, can be also found in the study. Likewise, genetic algorithm is used in (Alemdar & Sirakaya, 2003) for two-player one-step games. The learning of the algorithm takes place during the repeated playing of the game. Experiments show convergence to the exact Stackelberg equilibrium. An approximate method, based on the evolutionary algorithm, is shown in (Pedroso, 1996; Sadigh, Hashemi, & Hamzeh, 2011).In this study we propose a deterministic continuum-strategy two-player discrete-time dynamic Stackelberg game with fixed finite time duration and closed-loop information structure. The types of the considered payoff functions can be widely used in different applications (mainly in conflicts of consuming a limited resource, where one player, called leader, is a superior authority choosing strategy first, and another player, called follower, chooses after). In case of strictly concave payoff functions, and some additional conditions, the unique (leader–follower) equilibrium always exists and can be directly determined from the zeros of the corresponding derivatives (see Section 2.2 and Remark 2.2 for details). In other cases there is no generally usable solution process to find equilibria that is why a particular (sequential) solution method is worked out in this paper.The main contributions of the present paper are the following:1.We propose a new mathematical model for such Stackelberg games, in which the payoff functions of the players are determined by the amounts used of a given resource. At each step, the follower can choose only from the remaining amount after the leader’s choice. The resource amount remaining after both players’ choices is added to the resource amount pre-fixed for the next step. To our knowledge, the considered game and its proposed mathematical model have not been studied yet.In case of convex payoff functions, we give a new algorithm to find a (leader–follower) equilibrium for the proposed game based on backward induction. The algorithm is run from the last step towards the first one in a certain sequential equilibrium realization with respect to the steps of the game. The algorithm can be started if we can assure that the sub-game equilibrium at the last step consists of only two possible choices of both players and is independent of the former (earlier in the real course of the game) selections of the players and can be continued till some given conditions hold. These conditions make that the above mentioned sequentially realized solution (that is why easy to determine) corresponds to a (leader–follower) equilibrium. The conditions may seem rather special, nevertheless, they are satisfied in many practical cases as it is shown (see Remark 4.2). The algorithm stops at the step, when the given conditions are first not satisfied, because of which the equilibrium is no more independent of the former selections and thus the sequential solution is no more in accordance with the basic concept of leader–follower games that is each player uses the later responses of the other on its actions to realize a best decision. (Then the solution process should be continued in some other way if possible.) Nevertheless, the equilibrium of the sub-game has already been determined for the later steps. This sub-game equilibrium consists of only two possible choices of both players at each step.We give parameter domains for the proposed game, under which a predefined strategy sequence is an equilibrium.If we a priori know that there are only two possible choices for both players, the continuum-strategy problem is reduced to a general finite (or discrete) game. This game can be represented with a finite tree and can be further simplified. Finally, an equilibrium can be effectively determined with the method of dynamic programming.The paper is organized as follows: Section 2 contains preliminary concepts and describes the method of the so-called backward induction algorithm. Section 3 gives a new type of Stackelberg games. Section 4 gives the solution concept of the game. Section 5 contains the conclusions of the paper. In Appendix A, applied lemmas and supplementary derivations are given underlying the main contributions of the paper.Definition 1Let us consider the following deterministic two-player discrete-time game:One of the players is called leader, the other is follower. From now in this paper, leader and follower are denoted with Land F, respectively. The game evolves in discrete (time) steps t(t=1,…,T), with fixed time duration T∈N. At each step, L makes his strategy choice xt∈Xtfirst, then F makes his choice yt∈Yt, where Xtis L’s strategy set, Ytis F’s strategy set at step t.Let the payoffs (payoff functions) be deterministic functions of the strategy choices:L’s payoff isX1×⋯×XT×Y1×⋯×YT→R,(x1,…,xT,y1,…,yT)↦F(x1,…,xT,y1,…,yT),F’s payoff isX1×⋯×XT×Y1×⋯×YT→R,(x1,…,xT,y1,…,yT)↦G(x1,…,xT,y1,…,yT).At each step, the player to move decides as follows:In the knowledge of the earlier strategy choices, he determines the later strategy choices of both players as the response to all his currently possible decisions, and he makes such a strategy choice that maximizes his payoff for the game from step t to step T.This game is called deterministic continuum-strategy two-player discrete-time Stackelberg game with fixed finite time duration.Relating to the above defined type of games, let us further assume the following from now on in the present paper:1.Xt=Yt=[0,1] (t=1,…,T), that is the strategy sets are normalized.The game has complete information structure, that is the strategy sets and the players’ payoff functions are of common knowledge.The game has perfect information structure, that is the player to move knows all strategy choices of both players so far, at each move of each step.Leader–follower equilibriumHereafter, we use the following leader–follower equilibrium (from now, equilibrium in short) concept in the present paper for the studied Stackelberg games:Proceeding backwards from the last step of the game (from step T) to the first step, at step t(t=1,…,T−1) F predicts the later strategy choicesxt+1∗,…,xT∗,yt+1∗,…,yT∗(which may be complicated functions of the earlier choices, e.g. of yt) and maximizes his payoff G by a strategy choiceyt∗∈argmaxytGx1,…,xt,xt+1∗,…,xT∗,y1,…,yt,yt+1∗,…,yT∗. L predicts the later strategy choicesxt+1∗,…,xT∗,yt∗,…,yT∗(which may be complicated functions of the earlier choices, e.g. of xt) and maximizes his payoff F by a strategy choicext∗∈argmaxxtFx1,…,xt,xt+1∗,…,xT∗,y1,…,yt-1,yt∗,yt+1∗,…,yT∗.Assume that all sets included in the above description are nonempty. Then a strategy pairx1∗,…,xT∗,y1∗,…,yT∗containing such strategy choices, which satisfy the above concept is a (leader–follower) equilibrium of the game.In case of t=T, the strategies with indices higher than t are of course omitted.The above concept sketches also a possible solution method to find equilibria that is the so-called backward induction algorithm (see e.g. (Adda & Cooper, 2003)), which is the process of reasoning backwards in time, from the end of the game, to determine a sequence of optimal actions considering optimal responses.Remark 2.11.If the setargmaxxkF(x1,…,xk,xk+1∗,…,xT∗,y1,…,yk-1,yk∗,yk+1∗,…,yT∗)(argmaxykG(x1,…,xk,xk+1∗,…,xT∗,y1,…,yk,yk+1∗,…,yT∗))(k=1,…,T-1), is empty then the above process (backward induction algorithm) stops at step (T−k+1) and there is no equilibrium of the whole game, but the strategy pairxk+1∗,…,xT∗,yk∗,…,yT∗xk+1∗,…,xT∗,yk+1∗,…,yT∗containing the above defined strategy choices is an equilibrium of the sub-game, which begins with F’s move at step k (begins with L’s move at step (k+1)) and finishes with F’s move at step T. This sub-game solution depends on the players’ former strategy choices x1,…,xk, y1,…,yk−1 (x1,…,xk,y1,…,yk).Accordingly, an equilibriumx1∗,…,xT∗,y1∗,…,yT∗is a sub-game perfect equilibrium in the sense that it contains an equilibriumxτ∗,…,xT∗,yτ∗,…,yT∗of each sub-game from any step τ∈{1,…,T} to the last step T.Consider the above backward induction algorithm in the following case:1.Assume that GT:=G is a continuously differentiable function of yT, function∂GT∂yThas a unique zero with respect to yTfor any x1,…,xT, y1,…,yT−1. Denote this zero withyT∗(which is a function of the former strategy choices x1,…,xT, y1,…,yT−1). Assume further that GTis locally concave in yTat the zeroyT∗(x1,…,xT,y1,…,yT-1). It follows that the functionyT∗(x1,…,xT,y1,…,yT-1)is the unique maximum point of GTwith respect to yTfor any x1,…,xT, y1,…,yT−1.Assume thatFTx1,…,xT,y1,…,yT-1:Fx1,…,xT,y1,…,yT-1,yT∗(x1,…,xT,y1,…,yT-1)is a continuously differentiable function of xT, function∂FT∂xThas a unique zeroxT∗with respect to xTfor any x1,…,xT−1, y1,…,yT−1. Assume further that FTis locally concave in xTatxT∗(x1,…,xT-1,y1,…,yT-1). It follows thatxT∗(x1,…,xT-1,y1,…,yT-1)is the unique maximum point of FTwith respect to xTfor any x1,…,xT−1, y1,…,yT−1.…Continuing the process, assuming that the investigated derivatives,∂GT-k∂yT-kand∂FT-k∂xT-k(k=1,…,T−1), are continuous, have unique zerosyT-k∗x1,…,xT-k,y1,…,yT-k-1andxT-k∗x1,…,xT-k-1,y1,…,yT-k-1, respectively, and the corresponding functions (GT−kand FT−k) are locally concave with respect to the corresponding variables (yT−kand xT−k, respectively); the gained strategy pairx1∗,…,xT∗,y1∗,…,yT∗is the unique equilibrium of the game.The concavity of the investigated payoff function at its unique zero ensures that the zero is the global maximum point of the payoff with respect to the corresponding strategy coordinate, so it is the best choice (best response) of the corresponding player at the given step. If one of the conditions on the derivative and on concavity is not satisfied, the process cannot be continued in this way, although a sub-game equilibrium for the later steps (up to step T) has already been determined. The equilibrium strategy choices for the current and the former (earlier) steps (if exist) should be determined in some other way if possible. However, it requires generally other particular solution methods (e.g. approximation methods (Cardinal et al., 2011) or simulations, etc.), in which the particular payoff functions are considered. We very probably encounter such a latter case in particular problems, since the above concavity and other conditions are generally not satisfied, or they are too difficult to check, at each step for the multiple composite (thus generally very complicated) payoff functions.Remark 2.2At any step of the above process, we can get a unique maximum point likewise, if strict monotony is assumed instead of concavity, that is if there are no zeros of the continuous derivatives,∂GT-k∂yT-kand∂FT-k∂xT-k(k=1,…,T-1), with respect to yT−kand xT−k, respectively. In this case, the following hold:yT-k∗(x1,…,xT-k,y1,…,yT-k-1)∈{0,1}andxT-k∗x1,…,xT-k-1,y1,…,yT-k-1∈{0,1}.In this section, we propose a new Stackelberg game according to Definition 1, in which the payoffs of the players are determined by the amounts used of a given resource. At each step, F can choose only from the amount remaining after L’s choice. The resource amount remaining after both players’ choices is added to the amount pre-fixed for the next step.Let us introduce the following terminology for our particular game:NotationRtotal resource reserve in the game,T∈Nnumber of steps,t=1,…,Tcurrent step,xt∈[0,1]proportion of the resource consumed by L from the available reserve at step t,(x1,…,xT)L’s strategy,yt∈[0,1]proportion of the resource consumed by F from the available reserve after L’s choice at step t,(y1,…,yT)F’s strategy,rt∈[0,R]pre-fixed resource amount reserved for step t to rationalize the consumption for the whole duration of the game, from step 1 to step T (note that∑t=1Trt=R),π(ρ)unit price of the resource corresponding to the current reserve ρ∈[0,R] (assumed to be a monotonically decreasing, twice differentiable function),γtgain for F from a unit of the resource used at step t,αrate of the direct gain for L from a unit of the resource used at any step,qtax rate on F’s profit paid to L (q∈]0,1[).Formal variables for the fictional step 0: x0≔0, y0≔0, r0≔0 (in appropriate unit).The total payoffs are the sum of the payoffs for the separate steps:L’s payoff is(1)F(x1,…,xT,y1,…,yT)=∑t=1Tft(x1,…,xt,y1,…,yt),F’s payoff is(2)G(x1,…,xT,y1,…,yT)=∑t=1Tgt(x1,…,xt,y1,…,yt),where(3)ft(x1,…,xt,y1,…,yt)=α-πR-∑i=1t-11-∏k=1t-i1-yt-k(1-xt-k)rixt∑i=1t-1∏k=1t-i1-yt-k1-xt-kri+rt+qγt-πR-∑i=1t-11-∏k=1t-i(1-yt-k)1-xt-kriyt(1-xt)∑i=1t-1∏k=1t-i1-yt-k1-xt-kri+rt,(4)gt(x1,…,xt,y1,…,yt)=(1-q)γt-πR-∑i=1t-11-∏k=1t-i(1-yt-k)(1-xt-k)riyt(1-xt)∑i=1t-1∏k=1t-i(1-yt-k)(1-xt-k)ri+rt.Remark 3.11.The payoff values at any step t depend on the resource amount remaining from the previous steps (explicitly only from step (t−1)), which is the resource remaining from step (t−1), and on rt:ft(x1,…,xt,y1,…,yt)=(α−π [resource remaining from R at step t])xt(available resource at step t)+q(γt−π [resource remaining from R at step t]) yt(1−xt) (available resource at step t), gt(x1,…,xt,y1,…,yt)=(1−q)(γt−π [resource remaining from R at stept]) yt(1−xt)·(available resource at step t),whereresource remaining from R at step t=R – consumed resource till step (t−1),available resource at step t=resource remaining from step (t−1)+rt,consumed resource till step(t-1)=∑i=0t-1ri– resource remaining from step (t−1),resource remaining from step (t−1) =∑i=1t-1∏k=1t-i(1-yt-k)(1-xt-k)ri=(1-yt-1)·⋯·(1-y1)·(1-xt-1)·⋯·(1-x1)r1+(1-yt-1)·⋯·(1-y2)(1-xt-1)·⋯·(1-x2)r2+⋯+(1-yt-1)(1-xt-1)rt-1(assuming that t⩾2, otherwise the expression is simpler).The proposed game is in accordance with dynamic Stackelberg games defined in the Introduction by identifying the resource remaining from step (t−1) as the state of the game at step t, that is as at. Then at+1 is uniquely defined from at, xtand ytaccording to the state equation at+1=A(at, xt,yt,t) (t=1,…,T−1), which could be easily identified, but is not dealt with, since it is not needed in our discussion.It should be mentioned that the proposed game can be considered either as a closed-loop or a feedback dynamic Stackelberg game (see definitions in Section 1), since all earlier states are known by the players at any step (closed-loop game), nevertheless,only the current state, i.e. the resource remaining from step (t−1), affects explicitly the players’ payoffs at any step (see the definitions of payoffs above), so the only state, that affects the determination of the equilibrium from step t to step T is at(feedback game). Consequently, any equilibrium is a closed-loop and a feedback equilibrium in the same time.It should be also noted that the strategy sets are normalized, according to which both xtand ytcan take their values independently from the interval [0,1]. Actually, a strategy always means a proportion of the currently available resource. Thus it is not constrained by the previous strategy choices. Without this normalization, our game would have to be considered as a game with constraints on the strategy sets (for such games in static case, see (Rosen, 1965)).Based on (1)–(4) the payoffs (for the whole game) are linear with respect to the players’ strategy choices for step T (T⩾1) (with respect to xTand yT) and generally nonlinear with respect to the strategy choices for the other steps.Let us assume that such a sub-game equilibrium for stepTxT∗,yT∗can be given which is a constant function of the choices for the former steps (that is a constant function of x1,…,xT−1,y1,…,yT−1). It does not involve the uniqueness of the (sub-game) equilibrium for step T since there may be several such functions (and we use only one of them), so the uniqueness of the equilibrium is not guaranteed, but an equilibrium for the whole game may be determined with the backward induction algorithm.The equilibrium for step T satisfies the requirements if, for example, it is independent of the choices of the former steps.It can be seen from the detailed formulas ((A8) and (A9) in Appendix A) for the payoffs gT, fTfor step T that(gT)xT=1is constant as a function of yT,(gT)yT=0is constant as a function of xT,(gT)xT=0is linear in yT,(gT)yT=1is linear in xT, furthermore,(fT)xT=1is constant in yT,(fT)yT=0and(fT)yT=1are linear in xTand(fT)xT=0is linear in yT(see the functions in Fig. 1).An equilibrium for step T necessarily exists since the payoffs are continuous and the strategy sets of the players are compact intervals: [0,1] (see. Lemma A1 in Appendix A).Sufficient condition in the matter of that an equilibrium for step T can be formed from two strategy choices 0, 1, independently of the choices for the former steps (see the functions in Fig. 1):(C1)1.∂((fT)yT=1)∂xT⩾0for any x1,…,xT,y1,…,yT−1∈[0,1] (that is (C1) holds independently of x1,…,xT,y1,…,yT−1); and(C1a)(fT)xT=0yT=0⩾(fT)xT=1yT=0for any x1,…,xT−1,y1,…,yT−1∈[0,1], then an equilibrium for step T is (0,0) which can be proved with the following train of thought (see Fig. 1a):(C1)⇒(fT)xT=1yT=0⩾(fT)xT=0yT=1, since(fT)xT=1is constant inyT⇒(fT)xT=0yT=0⩾(fT)xT=0yT=1because of (C1a)⇒(gT)xT=0yT=0⩾(gT)xT=0yT=1, since(gT)xT=0yT=0-(gT)xT=0yT=1=1-qq(fT)xT=0yT=0-(fT)xT=0yT=1(see (A8) and (A9) with q∈]0,1[), so a best strategy choice for F is yT=0 for any xT∈[0,1]. L chooses xT=0 because of (C1a). Thus an equilibrium strategy pair is (0,0) for step T.Of course, gTis implicitly involved in the conditions as it can be seen in the above derivation.If (C1) holds for any x1,…,xT,y1,…,yT−1∈[0,1] and(C1b)(fT)xT=0yT=0⩽(fT)xT=1yT=0for any x1,…,xT−1,y1,…,yT−1∈[0,1], then an equilibrium is (1,0) which can be proved with the following train of thought (see Fig. 1b):Because of the linearity of gTwith respect to yT, F chooses yT=0 or yT=1 for any xT∈[0,1]. In either case, L’s best strategy choice is xT=1 because of (C1) and (C1b). Thus an equilibrium strategy pair is (1,0) for step T. (yT=1 is not better for F than yT=0 after that L has consumed all with xT=1. gTis implicitly involved here again).The following could be proved similarly to the case of (C1) and (C1a,C1b):(C2)2.∂((fT)yT=1)∂xT⩽0for any x1,…,xT,y1,…,yT−1∈[0,1]; and(C2a)(fT)xT=0yT=0⩾(fT)xT=0yT=1for any x1,…,xT−1,y1,…,yT−1∈[0,1], then an equilibrium is (0,0), or(C2b)(fT)xT=0yT=0⩽(fT)xT=0yT=1for any x1,…,xT−1,y1,…,yT−1∈[0,1], then an equilibrium is (0,1).If both (C1) and (C2) hold, the equilibrium is chosen according to (C1). If both (C1a) and (C1b) (or (C2a) and (C2b)) hold, the equilibrium is chosen according to (C1a) (or (C2a)).It can be also seen from the graphs of the functions that there is a unique equilibrium for step T if strict inequalities (and no equalities) hold in the sufficient conditions.It can be seen that the above conditions for step T hold for any of the former strategy choices, therefore, if sufficient conditions hold, the corresponding equilibrium applies to step T independently of the former strategy choices.A sufficient condition for (C1) (see (A11)) is(C3)α-qγT1-q⩾π[R-r0-⋯-rT-1].A sufficient condition for (C1a) (see (A15)) is(C3a)α⩽π[R].A sufficient condition for (C1b) (see (A16)) is(C3b)α⩾π[R-r0-⋯-rT-1].A sufficient condition for (C2) (see (A12)) is(C4)α-qγT1-q⩽π[R].A sufficient condition for (C2a) (see (A18)) is(C4a)γT⩽π[R].A sufficient condition for (C2b) (see (A19)) is(C4b)γT⩾π[R-r0-⋯-rT-1].The above results can be summarized in the following theorem:Theorem 4.1Let us consider the Stackelberg game defined in Section3.Then there exists an equilibrium for the last step (step T), which is independent of the strategy choices x0,y0,…,xT−1, yT−1and formed from only two strategy choices 0, 1 if one of the following holds: the equilibrium for step T is the strategy pair (0,0) if(C3)and(C3a)hold, (1,0) if(C3)and(C3b)hold, (0,0) if(C4)and(C4a)hold and (0,1) if(C4)and(C4b)hold.Furthermore, the equilibrium is unique if strict inequalities hold in the corresponding conditions.1.It should be emphasized again that the above conditions for step T hold for any of the former strategy choices, therefore, if sufficient conditions hold, the corresponding equilibrium applies to step T independently of the former strategy choices.The algorithm of Section 2.2 can be continued from this point to determine equilibria for the distinct steps from step (T−1) towards step 1 based on the zeros of the derivatives with respect to the corresponding variables if the corresponding concavity and other conditions hold.It should be emphasized again that F’s payoff (function g) is contained implicitly in conditions (C1), (C1a,b), (C2) and (C2a,b) although this fact cannot be seen explicitly in these final forms.Let T⩾2. If L’s payoff is convex with respect to each variable x1,…,xT−1 and F’s payoff is convex with respect to each variable x1,…,xT−1,y1,…,yT−1, then the method of Section 2.2 based on the zeros of the derivatives cannot be applied, since the desired concavity does not hold at each step. We give a backward induction algorithm below for such a case to determine an equilibrium.Regarding our payoffs, such a case occurs if it holds everywhere (for any x1,y1,…,xT,yT∈[0,1]) that∂2F(x1,…,xT,y1,…,yT)∂xj2⩾0,∂2G(x1,…,xT,y1,…,yT)∂xj2⩾0and∂2G(x1,…,xT,y1,…,yT)∂yj2⩾0(j=1,…,T-1).This is the case if it holds everywhere that∂2fτ(x1,…,xτ,y1,…,yτ)∂xτ-s2⩾0,∂2gτ(x1,…,xτ,y1,…,yτ)∂xτ-s2⩾0and∂2gτ(x1,…,xτ,y1,…,yτ)∂yτ-s2⩾0(τ=2,…,T,s=1,…,τ-1)according to definitions (1)-(4) and Remark A1.A sufficient condition for the latter three inequalities is the following (see Lemma A3):(C5)π″(ρ)⩽2R|π′(ρ)|(ρ∈]0,R[).Remark 4.2(C5) holds for many cost functions applied in the practice, e.g. for concave (linear included) costs and for convex cost functions of the form(5)π(ρ)=c(ρ+ρ0)n(ρ∈[0,R]),if(C6)ρ0⩾(n+1)R2,where c, ρ0, n are positive constants. (See Section A.1.1.)Thus the solution concept proposed below can be widely applied in practice.Suppose that the convexity conditions∂2fτ(x1,…,xτ,y1,…,yτ)∂xτ-s2⩾0,∂2gτ(x1,…,xτ,y1,…,yτ)∂xτ-s2⩾0and∂2gτ(x1,…,xτ,y1,…,yτ)∂yτ-s2⩾0(τ=2,…,T,s=1,…,τ-1)hold everywhere (for any x1,y1,…,xT, yT∈[0,1]) (e.g. by (C5)), there is an equilibrium of the game for the steps from t+1 to T for some t(t=1,…,T−1), which consists of only two strategy choices 0, 1 and is independent of the choices for the former steps (from 1 to t). Let us investigate what conditions assure that the equilibrium can be extended to the game for steps from t to T such that the strategy choices 0, 1 are suitable for step t too (as for the subsequent steps), and the equilibrium is independent of the choices for the former steps (from 1 to (t−1)).Case A, yt+j=1, xt+j=0Let us assume that in the equilibrium for the game of steps from (t+1) to T (for some t (t=1,…,T−1)), (0,1) is the first such strategy pair for a step which is not (0,0). Let it correspond to step (t+j) (for somej(j=1,…,T−t)), so xt+1=yt+1=⋯=xt+j−1=yt+j−1=0, yt+j=1, xt+j=0. Then the payoffs for steps from t to T are the following:L’s payoff: F=ft+⋯+fT=ft+ft+j+cf,F’s payoff: G=gt+⋯+gT=gt+gt+j+cg.cfand cgare the payoffs of the steps after step (t+j), and are independent of the choices for the steps before step (t+j), since the available resource amount remaining and prefixed for step (t+j) is fully exhausted at that step (as yt+j=1), so cfand cgare constant in xtand yt(cf=cg=0 if t+j=T).It can be seen from the detailed formulas ( (A20) and (A21)) of the payoffs and Remark A1, noting that yt+j=1, xt+j=0 and xt+1=yt+1=⋯=xt+j−1=yt+j−1=0, that(gt+gt+j+cg)xt=1is constant in yt,(gt+gt+j+cg)yt=1is linear in xt,(gt+gt+j+cg)xt=0is convex in ytand(gt+gt+j+cg)yt=0is convex in xt, furthermore,(ft+ft+j+cf)xt=1is constant in yt,(ft+ft+j+cf)yt=1is linear in xt,(ft+ft+j+cf)xt=0is convex in ytand(ft+ft+j+cf)yt=0is convex in xt(for any x1,y1,…,xt−1,yt−1∈[0,1]) (see the functions in Fig. 2).Consider the following difference based on (A22):(gt+gt+j+cg)yt=1-(gt+gt+j+cg)yt=0=1-qq((ft+ft+j+cf)yt=1-(ft+ft+j+cf)yt=0)It follows that for any x1,y1,…,xt−1,yt−1∈[0,1]:(gt+gt+j+cg)yt=1>(<)(gt+gt+j+cg)yt=0⇔(ft+ft+j+cf)yt=1>(<)(ft+ft+j+cf)yt=0.Fig. 3shows the possible relative positions of the above functions in xt. The convex continuous(gt+gt+j+cg)yt=0and the linear continuous(gt+gt+j+cg)yt=1function, as well as the convex continuous(ft+ft+j+cf)yt=0and the linear continuous(ft+ft+j+cf)yt=1function, can have at most one intersection point (or they are the same if both are linear). Furthermore, the place of intersection of(gt+gt+j+cg)yt=1and(gt+gt+j+cg)yt=0coincides with the place of intersection of(ft+ft+j+cf)yt=1and(ft+ft+j+cf)yt=0.Similarly to the case of step T, there exists an equilibrium here as well (see Lemma A1). From the convexity of gt+gt+j+cgin yt, it follows that in case of any xt∈[0,1] yt=0 or yt=1 corresponds to an equilibrium, so we can assume that F chooses one of the functionsG(xt,0)=(gt+gt+j+cg)yt=0andG(xt,1)=(gt+gt+j+cg)yt=1, and at the same time, one of the functionsF(xt,0)=(ft+ft+j+cf)yt=0andF(xt,1)=(ft+ft+j+cf)yt=1in case of any xtso that he gains maximum payoff. In this way F’s and L’s payoffs are determined for any xt∈[0,1]. In Fig. 3, thick curves denote the resulted functions corresponding to each player’s payoff for any xt. These curves are convex in all three cases. L will choose such an xtvalue, with which his payoff is maximal, so xt=0 or xt=1 will be convenient for him, since his (resulted) payoff function is continuous in any of the three cases. Thus a strategy pairxt∗,yt∗corresponding to an equilibrium can be selected such thatxt∗,yt∗∈{(0,0),(0,1),(1,0),(1,1)}.Consider functions(ft+ft+j+cf)yt=0and(ft+ft+j+cf)yt=1(see Fig. 3). A sufficient condition in the matter of that an equilibrium for step t (and thus for steps from t to T) is independent of the choices for the former (earlier) steps:(C7)1.∂((ft+ft+j+cf)yt=1)∂xt⩾0for any x1,…,xt,y1,…,yt−1∈[0,1] (that is (C7) holds independently of x1,…,xt,y1,…,yt−1); and(C7a)(ft+ft+j+cf)xt=0yt=0⩾(ft+ft+j+cf)xt=1yt=0for any x1,…,xt−1,y1,…,yt−1∈[0,1], then an equilibrium is (0,0), which can be proved with the following train of thought (see Fig. 3a and b):(C7)⇒(ft+ft+j+cf)xt=0yt=1⩽(ft+ft+j+cf)xt=1yt=1⇒(ft+ft+j+cf)xt=0yt=0⩾(ft+ft+j+cf)xt=0yt=1, since(ft+ft+j+cf)xt=1yt=0=(ft+ft+j+cf)xt=1yt=1and because of (C7a). The same relative positions hold for(gt+gt+j+cg)yT=0and(gt+gt+j+cg)yT=1as for(ft+ft+j+cf)yT=0and(ft+ft+j+cf)yT=1for any xt∈[0,1] because that(gt+gt+j+cg)yt=1>(<)(gt+gt+j+cg)yt=0⇔(ft+ft+j+cf)yt=1>(<)(ft+ft+j+cf)yt=0(see above). Therefore, the strategy choice xt=0 serves with the highest payoff for L if yt=0, and F will choose really yt=0 (after that L has chosen xt=0) because of the mentioned same relative positions for any xt∈[0,1]. Thus an equilibrium strategy pair is (0,0) for step t.Of course, gtis implicitly involved in the conditions as it can be seen in the above derivation.If (C7) holds for any x1,…,xt−1,y1,…,yt−1∈[0,1] and(C7b)(ft+ft+j+cf)xt=0yt=0⩽(ft+ft+j+cf)xt=1yt=0for any x1,…,xt−1,y1,…,yt−1∈[0,1], then an equilibrium is (1,0), which can be proved with the following train of thought (see Fig. 3c):(C7b)⇒xt=1 is a best choice for L, since(ft+ft+j+cf)xt=0yt=1⩽(ft+ft+j+cf)xt=1yt=1because of (C7) and(gt+gt+j+cg)xt=1yt=0=(gt+gt+j+cg)xt=1yt=1. Thus an equilibrium strategy pair is (1,0) for step t. (gtis implicitly involved here again).The following could be proved similarly to the case of (C7) and (C7a,b):(C8)2.∂((ft+ft+j+cf)yt=1)∂xt⩽0for any x1,…,xt,y1,…,yt−1∈[0,1]; and(C8a)(ft+ft+j+cf)xt=0yt=0⩾(ft+ft+j+cf)xt=0yt=1for any x1,…,xt−1,y1,…,yt−1∈[0,1], then an equilibrium is (0,0), or(C8b)(ft+ft+j+cf)xt=0yt=0⩽(ft+ft+j+cf)xt=0yt=1for any x1,…,xt−1,y1,…,yt−1∈[0,1], then the equilibrium is (0,1).If both (C7) and (C8) hold, the equilibrium is chosen according to (C7). If both (C7a) and (C7b) (or (C8a) and (C8b)) hold, the equilibrium is chosen according to (C7a) (or (C8a)).It can be also seen from the graphs of the functions that there is a unique equilibrium for step t if strict inequalities hold in the corresponding conditions.It can be seen that the above conditions for step t hold for any of the former strategy choices, therefore, if sufficient conditions hold, the corresponding equilibrium applies to step t independently of the former strategy choices.A sufficient condition for (C7) (see (A24)) is(C9)α-qγt1-q⩾π[R-r0-⋯-rt-1].Sufficient conditions for (C7a) (see A26, A27, and A28) is(C9a1)qγt+j-α+π[R](1-q)⩾0,or in case of(C9a2)qγt+j-α+π[R](1-q)⩽0:(C9a2/1)(qγt+j-α+π[R](1-q))(r0+⋯+rt-1+rt)+q(rt+1+⋯+rt+j)(π[R-r0-⋯-rt-1-rt]-π[R-r0-…-rt-1])⩾0.A sufficient condition for (C7b) (see. (A29)) is(C9b)(qγt+j-α+π[R-r0-⋯-rt-1](1-q))rt+q(rt+1+⋯+rt+j)(π[R-r0-⋯-rt-1-rt]-π[R])⩽0.A sufficient condition for (C8) (see (A24)) is(C10)α-qγt1-q⩽π[R].A sufficient condition for (C8a) (see A30, A31 and A32) is(C10a1)γt+j-γt⩾0,or in case of(C10a2)γt+j-γt⩽0:(C10a2/1)(γt+j-γt)(r0+⋯+rt-1+rt)+(π[R-r0-⋯-rt-1-rt]-π[R-r0-⋯-rt-1])(rt+1+⋯+rt-j-1+rt+j)⩾0.A sufficient condition for (C8b) (see (A33)) is(C10b)(γt+j-γt)rt+(π[R-r0-⋯-rt-1-rt]-π[R])(rt+1+⋯+rt+j-1+rt+j)⩽0.Case B, yt+j=0, xt+j=1Similar considerations can be used here as in Case A.Let us assume that in the equilibrium for the game of steps from (t+1) to T (for some t(t=1,…,T−1)), (1,0) is the first such strategy pair for a step which is not (0,0) (the case when (1,1) were such a first pair would not differ from this case). Let it correspond to step (t+j) (for some j (j=1,…,T−t)), so xt+1=yt+1=⋯=xt+j−1=yt+j−1=0, yt+j=0, xt+j=1. In Case B, it follows from the detailed formulas of the payoffs and Remark A1 that(gt+gt+j+cg)xt=1is constant in yt,(gt+gt+j+cg)yt=0is constant in xt,(gt+gt+j+cg)xt=0is linear in yt,(gt+gt+j+cg)yt=1is linear in xt, furthermore,(ft+ft+j+cf)xt=1is constant in yt,(ft+ft+j+cf)yt=1is linear in xt,(ft+ft+j+cf)xt=0is convex in ytand(ft+ft+j+cf)yt=0is convex in xt(for any x1,y1,…,xt−1,yt−1∈[0,1]) (see the functions in Fig. 4).Functions(gt+cg)yt=1and(gt+cg)yt=0, and functions(ft+ft+j+cf)yt=1and(ft+ft+j+cf)yt=0may have the relative positions shown in Fig. 5.Since(gt+cg)yt=1and(gt+cg)yt=0are linear and are equal at xt=1, F will choose the same valueyt∗=0oryt∗=1for any xt∈[0,1], by which he chooses, at the same time, the corresponding one of functions(ft+ft+j+cf)yt=1and(ft+ft+j+cf)yt=0. The latter is L’s payoff function, which is linear or convex, soxt∗=0orxt∗=1is surely convenient choice for him to maximize his profit. The existence of an equilibrium according toxt∗,yt∗∈{(0,0),(0,1),(1,0),(1,1)}applies in this case as well.A sufficient condition in the matter of that an equilibrium for step t is independent of the choices for the former steps:(C11)1.∂((gt+cg)yt=1)∂xt⩽0for any x1,…,xt,y1,…,yt−1∈[0,1] (that is (C11) holds independently of x1,…,xt,y1,…,yt−1); and(C11a)∂((ft+ft+j+cf)yt=1)∂xt⩾0for any x1,…,xt−1,y1,…,yt−1∈[0,1], then an equilibrium is (1,0) (which is equivalent to (1,1)), or(C11b)∂((ft+ft+j+cf)yt=1)∂xt⩽0for any x1,…,xt−1,y1,…,yt−1∈[0,1], then an equilibrium is (0,1).(C12)2.∂((gt+cg)yt=1)∂xt⩾0for any x1,…,xt,y1,…,yt−1∈[0,1]; and(C12a)(ft+ft+j+cf)xt=0yt=0⩾(ft+ft+j+cf)xt=1yt=0for any x1,…,xt−1,y1,…,yt−1∈[0,1] or(C12b)(ft+ft+j+cf)xt=0yt=0⩽(ft+ft+j+cf)xt=1yt=0for any x1,…,xt−1,y1,…,yt−1∈[0,1].It can be shown that (C12a) surely holds and (C12b) cannot hold. An equilibrium is (0,0).If both (C11) and (C12) hold, the equilibrium is chosen according to (C11). If both (C11a) and (C11b) hold, the equilibrium is chosen according to (C11a).It can be also seen from the graphs of the functions that there is a unique equilibrium for step t if strict inequalities hold in the corresponding conditions.It can be seen that the above conditions for step t hold for any of the former strategy choices, therefore, if sufficient conditions hold, the corresponding equilibrium applies to step t independently of the former strategy choices.The below conditions could be derived similarly to those ofCase A.A sufficient condition for (C11) is(C13)γt-π[R-r0-⋯-rt-1]⩾0.A sufficient condition for (C11a) is(C13a)α-qγt1-q⩾π[R-r0-⋯-rt-1].A sufficient condition for (C11b) is(C13b)α-qγt1-q⩽π[R].A sufficient condition for (C12) (and for (C12a)) is(C14)γt-π[R]⩽0.The above results can be summarized in the following theorem:Theorem 4.2Let us consider the Stackelberg game defined in Section3in case of T⩾2. Suppose that∂2fτx1,…,xτ,y1,…,yτ∂xτ-s2⩾0,∂2gτx1,…,xτ,y1,…,yτ∂xτ-s2⩾0and∂2gτx1,…,xτ,y1,…,yτ∂yτ-s2⩾0(τ=2,…,T, s=1,…,τ−1) hold everywhere (e.g. by(C5)) for the function π, and there is an equilibrium for the game of steps from (t+1) to T (for some t (t=1,…,T−1)), which is independent of the strategy choices x1,y1,…,xt,ytand formed from only two strategy choices 0, 1. Let the equilibrium strategies for the game of steps from (t+1) to T be denoted withxt+1∗,…,xT∗andyt+1∗,…,yT∗.Then there exists an equilibrium for the steps from t to T, which is an extension of the equilibrium corresponding to the steps from (t+1) to T in the following way:xt∗,…,xT∗,yt∗,…,yT∗=xt∗,xt+1∗,…,xT∗,yt∗,yt+1∗,…,yT∗,where the equilibrium for step t satisfies:xt∗,yt∗∈{(0,0),(1,0),(0,1)}.Case ALet us assume that in the equilibrium for the game of steps from (t+1) to T, (0,1) is the first such strategy pair for a step which is not (0,0). In such a case, if (C9) and (C9a1) (or (C9), (C9a2) and (C9a2/1)) hold then the strategy pair (0,0), if (C9) and (C9b) hold then the strategy pair (1,0), if (C10) and (C10a1) (or (C10), (C10a2) and (C10a2/1)) hold then the strategy pair (0,0), if (C10) and (C10b) hold then the strategy pair (0,1) corresponds to an equilibrium for steptxt∗,yt∗, which is independent of the choices for the former steps x1,y1,…,xt−1,yt−1.Case BLet us assume that in the equilibrium for the game of steps from (t+1) to T, (1,0) is the first such strategy pair for a step which is not (0,0) (if (1,1) were such a first pair we could change that to (1,0)). In such a case, if (C13) and (C13a) hold then the strategy pair (1,0), if (C13) and (C13b) hold then the strategy pair (0,1), if (C14) holds then the strategy pair (0,0) corresponds to an equilibrium for steptxt∗,yt∗, which is independent of the choices for the former steps x1,y1,…,xt−1, yt−1.The equilibrium is unique for step t if strict inequalities hold in the satisfied conditions.Remark 4.31.It should be emphasized again that the above conditions for step t (both in Cases A and B) hold for any of the former strategy choices, therefore, if sufficient conditions hold, the corresponding equilibrium applies to step t independently of the former strategy choices.It should be emphasized again that F’s payoff (function g) is contained implicitly in conditions (C7) (C7a,b), (C8) (C8a,b) and although this fact cannot be seen explicitly in these final forms.If yt+j=xt+j=0 for any j (j=1,…,T−t), then the equilibrium strategy pair for step t can be similarly determined asxT∗,yT∗in Section 4.1 (substituting t for T).Summarizing Theorems 4.1 and 4.2, such a sequential equilibrium realization is resulted with respect to the steps of the game, in which the sub-game equilibrium from any given step consists of only two possible choices of both players and is independent of the former (earlier in the real course of the game) selections of the players (that is why the sequential concept can be used). The algorithm is run from the last step (applying Theorem 4.1) towards the first one and can be continued till the given conditions hold (applying Theorem 4.2). The gained sequentially realized solution corresponds to a (leader–follower) equilibrium, which can be determined as follows:Backwards from the last step (step T), conditions (C3), (C4), (C9), (C10), (C13), (C14) with the corresponding sub-conditions (and the convexity condition of Theorem 4.2) are checked according to whether (0,1) or (1,0) is the first strategy pair differing from (0,0) in the (sub-game) equilibrium for the subsequent steps. (The inquiry on the subsequent steps is of course left in case of the last step, step T.) If one of the above conditions holds (with corresponding sub-condition(s)), the equilibrium strategy pair, consists of only the choices 0 and 1, is fixed for the current step (see Theorem 4.2), and the process is continued for the one former step.If corresponding conditions are satisfied at each step and they are strict inequalities then the strategy pairx1∗,…,xT∗,y1∗,…,yT∗determined in the above detailed way is the unique equilibrium of the whole game (for steps from 1 to T).It might be that neither of the corresponding conditions is satisfied at a step t, nevertheless the (sub-game) equilibrium for the later steps has already been determined, furthermore, this equilibrium can be extended to step t according to Theorem 4.2. We also know that for the equilibrium for step t:xt∗,yt∗∈{(0,0),(1,0),(0,1)}, although this strategy pair may depend on the choices for the former steps. The equilibrium strategy pairs for the current and the earlier steps (if exists) should be determined in some other way if possible. After such a decrease in the number of steps in question, the game can be solved in a lucky case.It should be mentioned that the procedure is very easy to feed into a computer algorithm because of the simple parameter discussion method, and the running time is polynomial.Example 1aThe notation is in accordance with Section 3Suppose that in a region (e.g. in a town) the gas supplying service is interrupted because of some disturbance (e.g. natural catastrophe) for four days (four steps), so the heat demand of the inhabitants and the industry must be satisfied from the heating oil reserve maintained for such situations. The reserve (R, in litre) is rationalized for the corresponding days in the following way: r1=25000l, r2=15000l, r3=20000l, r4=10000l (R=r1+r2+r3+r4).In the beginning of every day (day t), the local authority (L) assigns the proportion (xt∈[0,1], t=1,…,4) of the available resource amount that he pass directly to the inhabitants, then the industry (F) assigns the proportion (yt∈[0,1]) of the remaining amount that he wants to utilize. L has political gain if he supplies the inhabitants with heating oil, which is expressed with the coefficient α, α=3EUR per liter. On the other hand he has financial profit (in the form of tax) from the activity that the industry takes based on the heating oil consumption (heating offices, factory places, etc.), which is expressed with the coefficient q, q=0,3. The economic environment determines the price at which that F is able to sell the produced goods manufactured with the help of the consumed heating oil each day: γ1=11EUR per liter, γ2=8EUR per liter, γ3=7EUR per liter, γ4=10EUR per liter.Suppose that the heating oil price decreases linearly as a function of the reserved oil amount between two values π(R)=0.25EUR per liter and π(0)=1EUR per liter. π(0) corresponds to the oil imported from outside. The price of the consumed oil is paid by L if the inhabitants consume the oil, and the price is paid by F if the oil is consumed by the industry.The problem is in accordance with the Stackelberg game of Section 3. π satisfies (C5), so the algorithm of Section 4.4 can be applied with checking the conditions given there. If we carry out the calculations, it can be seen that the parameters satisfy the following conditions for the distinct days, which correspond to the below equilibrium strategy pairs (see Table 1).Thus the strategy pair of the equilibrium (which is not only realized but unique in this case) isx1∗,x2∗,x3∗,x4∗,y1∗,y2∗,y3∗,y4∗=0,0,0,0,1,0,0,1.The payoff for the local authority is F=208633.9EUR, and for the industry is G=486812.5EUR.The algorithm described in Section 4.4 can be directly used to regulate the game process in a plausible way by choosing the parameter values of α, q, γt, rt(t=1,…,T) and perhaps the cost function π adequately. It depends on the particular problem which parameters are tuneable within what upper and lower limits.Suppose that q and γt(t=1,…,T) can be tuned. The sub-game equilibrium of step T has the best chance to be prescribed since there are two free parameters to satisfy two conditions ((C3) with (C3a) or with (C3b), or (C4) with (C4a) or with (C4b)). It might happen even in this case that we are not able to produce one or more of the equilibria ((0,0), (0,1), (1,0)) for step T because of the additional requirements on the parameters (e.g. 0⩽q<1, 0⩽γt).Proceeding backwards, the equilibrium strategy pairs for further steps might be assured, however its probability decreases, since the number of the conditions to be satisfied to assure a strategy pair for any step is generally more than the number of the still free parameters. For example in step (T−1), two inequalities (C9) and (C9b) must be satisfied for the strategy pair (1,0) (supposing that (0,1) has been prescribed in step T), but the number of the still free parameters are only one: γT−1. q and γThave already been used up to assure the conditions ((C4) and (C4b)) for step T.Let us consider the following example on game regulation:Example 1bReferring to Example 1a, assume that some external economic participant (e.g. the government) wants to assure, with economic incentives, that the inhabitants obtain the heating oil on day four (e.g. because of the expected cold weather), furthermore, he wants the industry (F) to utilize the oil on day three (to maintain the industrial production). (It should be mentioned that the inhabitants have got no oil in Example 1a which may cause problems.)Suppose that the external participant is able to prescribe the values of q and γt(t=1,…,4) (e.g. with edicts on the taxes and on the purchase-prices).Thus the desired (equilibrium) strategy pair is (1,0) on day four and (0,1) on day three. The following conditions ((EX1)–(EX4)) have to be satisfied for this purpose:Day 4 (based on (C3) and (C3b)):(EX1)α-qγ41-q>π[R-r1-r2-r3],(EX2)α>π[R-r1-r2-r3].Day 3 (based on (C13) and (C13b)):(EX3)γ3-π[R-r1-r2]>0,(EX4)α-qγ31-q<π[R].The purpose can be obtained with prescribing parameters q, γ3 and γ4, e.g. with q=0,4; γ3=8EUR per liter and γ4=6EUR per liter. The other parameter values are the same as in Example 1a.It can be seen by checking the conditions for the second and first days that the strategy pair (0,0) is realized on the second day and (0,1) is realized on the first day. Thus the (realized) equilibrium isx1∗,x2∗,x3∗,x4∗,y1∗,y2∗,y3∗,y4∗=((0,0,0,1),(1,0,1,0)).Resulted payoffs: local authority: F=233321.4EUR, industry: G=318375.0EUR.Remark 4.4It is worth mentioning that the given conditions (e.g. (C1), (C2), (C7), etc.) contain relations, which hold independently of the former strategy choices of the players at any step t. This does not mean that L’s and F’s payoff values are independent of the former choices. This only means that the conditions assure that the changes in the former choices (between the values 0 and 1) cannot change the mentioned relations and thus the determined equilibrium for step t is independent of the former choices.Theorems 4.1 and 4.2 and the solution concept of Section 4.4 are not needed if it is known a priori that the investigated problem can have only two possible strategy choices 0 and 1 (xt,yt∈{0,1}). In such a case, the task is reduced to the determination of a (leader–follower) equilibrium of a finite game, which can be represented with a finite game tree, see e.g. (Amir, 1999). The existence of an equilibrium is guaranteed in this case (see Lemma A2). Fig. 6. shows the game tree in case of three steps (T=3).Both players’ payoffs should be determined for every terminal node in the tree by substituting the corresponding strategy pair into the payoff functions then an equilibrium can be found with the method of dynamic programming. (In Fig. 6., the payoffs for the strategy pair ((x1,x2,x3), (y1,y2,y3))=((0,0,0),(1,1,1)) are shown as an example.)The game can be reduced, which should be carried out to decrease the calculation cost of the dynamic programming. The possible reductions are the following if T=3, 2T=6 (see Fig. 6).The strategy pair (1,1) can be excluded at each step and can be replaced with (1,0), which is of the same payoff values, since F’s payoff will be surely 0 after L has used the whole available resource up at that step. In Fig. 6, a triple crossbar denotes F’s excluded choice corresponding to (1,1) at step 1. Thus 1/4 of the terminal nodes of the game have been excluded. Double and simple crossbars denote the strategy pairs excluded at step 2 and 3. This means the exclusion of 1/4 and further 1/4 from the still remaining outcomes (terminal nodes), so1-143·26=343·26possible outcomes have been remained finally from the 26 possible outcomes of the original finite game.This results can be easily generalized for T steps, where34T·22Tpossible outcomes should be considered instead of 22T, so the finite game has been significantly reduced (see Fig. 7).Example 2(The notation is according to Section 3.) Let us consider the solar heating system with 32kilowatt nominal heat power (with 33.3square meter solar collector field) installed at the campus of the Szent István University Gödöllo˝, Hungary (Farkas et al., 2000). The system can heat domestic hot water of a kindergarten or the water of an open-air swimming pool nearby. The change between the two consumers or the exclusion of them can be taken manually with valves.Consider a three-day period (three steps) in early summer, when both the kindergarten and the swimming pool are open, and suppose that the change between the consumers or their exclusion can be carried out once a day in the morning. Thus each day, the sum of the accumulated solar heat from the former days and that produced on the current day is either fully used up by the kindergarten or the swimming pool on the current day or stored for the next day in the (2cubic meter) solar storage. It is assumed that each consumer has such a great daily heat demand that he uses up the whole stored solar heat as well as the heat produced on the current day provided the consumer is connected with the solar heating system, so only two strategy choices 0 and 1 are possible (xt,yt(t=1,…,3)). (There are of course auxiliary heaters for the consumers to satisfy their heat demand if needed, apart from solar energy.)The town council (L) operates the solar heating system as local authority having political gain if the kindergarten consumes the solar heat: α=0.2EUR per kilowatt hour. If the solar heat is not provided for the kindergarten then the swimming pool (F) has the possibility to consume it. The profit of the swimming pool and the available solar heat depend on the weather, which is assumed to be predictable for three days sufficiently well. More solar heat is produced and the swimming pool has more guests if the weather is better (more sunny).Let us calculate with the following values: γ1=0.5EUR per kilowatt hour, γ2=0.7EUR per kilowatt hour, γ3=0.4EUR per kilowatt hour, r1=40kilowatt hour, r2=80kilowatt hour, r3=30kilowatt hour.The price of the solar heat is very favourable because of the renewable energy source, only the electric cost of the pumps has to be paid in essence. On the average, approximately 25kilowatt hour electric energy is needed to utilize 1kilowatt hour solar energy in our system (Kicsiny & Farkas, 2012). Based on this average value and 0.18EUR per kilowatt hour electric energy price, the price of the solar energy is considered constant: π(ρ)=0.0045EUR per kilowatt hour, ρ∈[0, r1+r2+r3], which must be paid by the player corresponds to the current consumer (L pays if the kindergarten consumes the solar energy and the swimming pool pays if he consumes the solar energy).L has a share in the profit of the swimming pool in the form of tax: q=0.3.The problem is in accordance with the Stackelberg game defined in Sections 3 and 4.6, which can be solved with dynamic programming. It is resulted that there is a unique (and realized) equilibrium of the game:x1∗,x2∗,x3∗,y1∗,y2∗,y3∗=((0,0,1),(0,1,0)).Resulted payoffs gained from the solar energy utilization: town (local authority): F=30.9EUR, swimming pool: G=58.4EUR.

@&#CONCLUSIONS@&#
