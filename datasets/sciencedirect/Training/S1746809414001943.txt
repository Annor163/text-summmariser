@&#MAIN-TITLE@&#
Nonsubsampled shearlet based CT and MR medical image fusion using biologically inspired spiking neural network

@&#HIGHLIGHTS@&#
The paper presents an algorithm for fusing the CT and MR medical images.The proposed method is based on the activity level measure and the PCNN model for fusing the image coefficients in nonsubsampled shearlet domain.The proposed method provides better fused images with more detail information compared to others.

@&#KEYPHRASES@&#
Computed tomography (CT),Image fusion,Magnetic resonance (MR),Nonsubsampled shearlet transform (NSST),Pulse coupled neural network,

@&#ABSTRACT@&#
This paper presents a new fusion scheme for the CT and MR medical images that utilizes both the features of the nonsubsampled shearlet transform (NSST) and spiking neural network. As a new image representation with the different features, the NSST is utilized to provide an effective representation of the image coefficients. Firstly, the source CT and MR images are decomposed by the NSST into several subimages. The regional energy is used to fuse the low frequency coefficients. High frequency coefficients are also fused using a pulse coupled neural network model that is used as a biologically inspired type neural network. It also retains the edges and detail information from the source images. Finally, the inverse NSST is used to produce the fused image. The performance of the proposed fusion method is evaluated by conducting several experiments on the different CT and MR medical image datasets. Experimental results demonstrate that the proposed method does not only produce better results by successfully fusing the different CT and MR images, but also ensures an improvement in the various quantitative parameters as compared to other existing methods.

@&#INTRODUCTION@&#
Medical images such as MR and CT are very useful in several health care applications such as medical diagnostics, patient health monitoring and drug evaluation. Besides it, various medical imaging modalities become available to support the radiologist representing the information of the different living organs. The magnetic resonance (MR), computed tomography (CT) and ultrasound (US) images are named as structural medical images that provide the structural information of the organs. Others are functional medical images such as functional magnetic resonance (fMR), single photon emission CT (SPECT) that imparts the functional information of the anatomy with lower resolution images. The complete and accurate information is not provided by any one single modality of medical imaging. For example, the MR images reflect the soft tissue information and the CT images present the bony structure information. Therefore, there is a requirement to design an efficient algorithm to integrate both the features in a composite single image. Medical image fusion is a process of merging the complementary and useful redundant information from the multiple source images obtained from the different imaging modalities into a fused single output image that has special clinical meaning. The fused image is suitable for visual perception, analysis and other computer processing tasks.In the past few years, various algorithms have been reported in the literature in the field of image fusion. Image fusion can be performed at three different processing levels, viz. pixel, feature and decision level. The pixel level image fusion is further classified as spatial and transform domain [1–3]. The pixel level spatial domain fusion algorithms usually lead to reduce the contrast and also distort the spectral characteristics [4]. Currently, lots of research work on image fusion has been concentrated in the transform domain. In this series, Laplacian pyramid and its different variants have been presented for fusing the multisensor data [5,6]. However, it does not provide any spatial orientation selectivity in the decomposition process, and hence often cause blocking effects/artifacts [7]. Wavelet transform (WT) is one transformation technique that is used for the fusion process [7]. It produces better results and also successfully preserves the spectral information of the input images. In addition to this, the WT is able to capture the one dimensional point singularity [8]. However, it fails to reflect the abrupt transitions such as line and curve singularities. In order to rectify the limitations of the WT, ridgelet transform has been evolved to capture the line singularities of the images [9]. However, it is still unable to represent the curve singularities, effectively. Donoho et al. have used curvelet transform (CVT) to represent two-dimensional singularities of the smooth curve [10]. However, the CVT does not provide a multi-resolution representation of the geometry and also the curvelet cannot be built directly in discrete domain [11]. Further in this series, the contourlet transform improves the fusion results [12,13]. However, Gibbs phenomenon is also present as a result of the lack of shift invariance in contourlet transform [14]. To overcome this problem, the nonsubsampled contourlet transform (NSCT) [15] has been introduced and widely used in image fusion schemes. It does not only resolve the problem of capturing the higher dimensional singularity but also inherits a property of shift invariance [14]. However, it has limited number of directions and large computational complexity, whenever it is used in image fusion scheme. To represent more edges, efficiently, Labate et al. introduced a new multiscale geometric analysis tool called shearlet which has all properties like other tools as multiscale, localization, anisotropy and directionality [16], but still it is not able to overcome the problem of shift invariance. Later, Easley et al. [17] proposed nonsubsampled shearlet transform (NSST) that is realized by nonsubsampled Laplacian pyramid (NSLP) and several shearing filters. The NSST provides the variable directional selectivity and shift invariance [14,18,19]. In the recent years, various medical image fusion algorithms based on all these transformation techniques have been reported [11,18,20–27].Recently developed, pulse coupled neural network (PCNN) which is a biologically inspired spiking neural network [28,29] is efficiently utilized in the different applications of image processing [30]. There are several fusion algorithms that are based on the PCNN and different transformation techniques [24,30–37]. On the basis of results obtained from these algorithms, it is observed that they produce good results, but they have some general problems such as contrast reduction and sometimes the most important fine detail information was lost [35,38,39]. However, in most of the PCNN based image fusion algorithms, the neuron is motivated using one pixel coefficient in spatial domain or in the transform domain. Based on the above concept, the NSST transform and the PCNN model are employed to present the proposed medical image fusion method in which the regional energy is used for fusing low frequency NSST coefficients of the image. The novel sum modified Laplacian (NSML) [40] in the NSST domain is given as an input to motivate the neuron of the PCNN model for high frequency coefficients fusion.The rest of the paper is organized as follows. Section 2 illustrates the methodologies which are used to present the proposed fusion method. Section 3 presents the implementation of the proposed image fusion method that is based on the NSST. In Section 4, various experimental results are discussed and compared with the existing fusion methods on the basis of different performance measures. Section 5 depicts the final conclusions.

@&#CONCLUSIONS@&#
In this paper, a new fusion method for the CT and MR medical images is presented that is based on the NSML motivated PCNN as a bio inspired neural network in the NSST domain. In the proposed method, the NSST provides both the multiscale and direction analysis of the original image. The regional energy based an activity level measure is used for fusing the low frequency subband coefficients. Experiments were carried out on the different pairs of CT and MR images to make subjective evaluations. The proposed fusion scheme is also compared with the various fusion rules based on the different transformation techniques, such as the WT, NSCT and NSST. Moreover, the results obtained by the proposed method are also compared with the PCNN based fusion scheme in different domain. From the experimental results, it is observed that the proposed fusion algorithm outperforms others not only in terms of visual analysis, but also in terms of different performance measures by preserving the soft tissue structure from the MR images and bony structure from the CT images.