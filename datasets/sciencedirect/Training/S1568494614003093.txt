@&#MAIN-TITLE@&#
A quick artificial bee colony (qABC) algorithm and its performance on optimization problems

@&#HIGHLIGHTS@&#
We describe a novel algorithm called quick ABC (qABC).This algorithm presents a new definition for the behaviour of onlooker bees of ABC algorithm.Some analyses about the effect of some control parameters on qABC optimization are carried out.The performance of qABC is compared with the state of art algorithms’ performances.New definition significantly improves the convergence performance of standard ABC.

@&#KEYPHRASES@&#
Optimization,Swarm intelligence,Artificial bee colony,Quick artificial bee colony,

@&#ABSTRACT@&#
Artificial bee colony (ABC) algorithm inspired by the foraging behaviour of the honey bees is one of the most popular swarm intelligence based optimization techniques. Quick artificial bee colony (qABC) is a new version of ABC algorithm which models the behaviour of onlooker bees more accurately and improves the performance of standard ABC in terms of local search ability. In this study, the qABC method is described and its performance is analysed depending on the neighbourhood radius, on a set of benchmark problems. And also some analyses about the effect of the parameter limit and colony size on qABC optimization are carried out. Moreover, the performance of qABC is compared with the state of art algorithms’ performances.

@&#INTRODUCTION@&#
Optimization is an issue of finding the best solutions via an objective in the search space of a problem. In order to solve the real world optimization problems – especially NP hard problems – evolutionary computation (EC) based optimization methods that consist of evolutionary algorithms and swarm intelligence based algorithms are frequently preferred. A swarm intelligence based algorithm models an intelligent behaviour/behaviours of social creatures that can be characterised as an intelligent swarm and this model can be used for searching the optimal solutions of various engineering problems. Artificial bee colony (ABC) algorithm is a swarm intelligence based optimization technique that models the foraging behaviour of the honey bees in the nature [1]. This algorithm was first introduced to literature by Karaboga in 2005 [2]. Until today, ABC algorithm has been used in many applications. In [3], a good survey study on ABC algorithm can be found.Although the standard ABC optimization generally produces successful results in many application studies, for getting a better performance from ABC algorithm, some researchers attempted to implement ABC in parallel [4–8] and some integrated the different concepts of the other EC based methods with ABC algorithm [9–20]. Zhu and Kwong are influenced by particle swarm optimization (PSO) and they proposed an improved ABC algorithm named gbest-guided ABC [9]. They placed the global best solution into the solution search equation. For multiple sequence alignment problem, Xu and Lei introduced Metropolis acceptance criteria into the searching process of ABC to prevent the algorithm from sliding into local optimum [10]. They called the improved version of ABC as ABC_SA. Tuba et al. improved GABC algorithm that integrates ABC optimization with self-adaptive guidance [11]. Li et al. used inertia weight and acceleration coefficients to get a better performance on the searching process of ABC algorithm [12]. A new scheduling method based on best-so-far ABC for solving the JSSP was proposed by Banharnsakun et al. [13]. In this method solution direction is biased toward the best-so-far solution rather than a neighbour one. Bi and Wang presented a modification on the scouts’ behaviour in ABC algorithm [14]. They used a mutation strategy based on opposition-based learning and called the new method as fast mutation ABC. Inspired by differential evolution (DE) algorithm, Gao and Liu presented a new solution search equation for standard ABC [15]. The new equation aims to improve the exploitation capability and it is based on that the bee searches only around the best solution of the previous iteration. Mezura-Montes and Cetina-Dominguez presented a modified ABC to solve constrained numerical optimization problems [16]. They modified ABC algorithm with the selection mechanism, the scout bee operator and the equality and boundary constraints. For constrained optimization problems, Bacanin and Tuba introduced some modifications based on genetic algorithm operators to the ABC algorithm [17]. In order to improve the exploitation capability of ABC algorithm, Gao et al. presented an improved ABC [18]. In this improved version, they used a modified search strategy to generate new food source. They used opposition based learning method and chaotic maps to produce the initial population for a better global convergence. For a better exploitation, Gao et al. also presented a modified ABC algorithm inspiring by DE [19]. With this modification, each bee searches only around the best solution of the previous cycle to improve the exploitation. And they also used chaotic systems and opposition based learning method while producing the initial population and scout bees to improve the global convergence. Liu et al. introduced an improved ABC algorithm with mutual learning [20]. This approach adjusts the produced candidate food source using some individuals which are selected by a mutual learning factor.In order to get more powerful optimization technique, some researchers combined ABC algorithm with other EC based methods or traditional algorithms. Kang et al. proposed a hybrid simplex ABC [21]. In [21], they combined ABC with Nelder–Mead simplex method and in another study, they used this new method for inverse analysis problems [22]. Marinakis et al. proposed a hybrid algorithm based on ABC optimization and greedy randomised adaptive search procedure in order to cluster n objects into k clusters [23]. Another different hybrid ABC was described by Xiao and Chen by using artificial immune network algorithm [24]. They applied the hybrid algorithm to multi-mode resource constrained multi-project scheduling problem. Bin and Qian introduced a differential ABC algorithm for global numerical optimization [25]. Sharma and Pant used DE operators with standard ABC algorithm [26]. Kang et al. demonstrated how the standard ABC can be improved by incorporating a hybridization strategy [27]. They suggested a novel hybrid optimization technique composed of Hooke Jeeves pattern search and ABC algorithm. Hsieh et al. proposed a new hybrid algorithm of PSO and ABC optimization [28]. Abraham et al. made a hybridization of ABC algorithm and DE strategy, and called this novel approach as hybrid differential ABC algorithm [29].In this work, instead of presenting a new hybrid ABC algorithm or integrating an operator of an existing algorithm into ABC, our aim is to model the behaviour of foragers in ABC more accurately by introducing a new definition for onlooker bees. By using the new definition proposed for onlooker bees, ABC achieves a better performance than standard ABC in terms of local search ability. So, we called our new algorithm as quick ABC (qABC) [30]. In this work, the qABC algorithm is described in more detailed way and then its performance is tested on a set of test problems larger than that in [30] and the effects of control parameters neighbourhood radius, limit and colony size on its performance are investigated. Also the performance of qABC is compared with the state of art algorithms. The rest of the paper is organised as follows: Section 2 describes the standard ABC and the novel strategy (qABC) is presented in Section 3. The computational study and simulation results are demonstrated in Section 4 and finally, in Section 5, the conclusion is given.The artificial bees are divided in three groups considering the foraging behaviour of the colony in ABC algorithm. The first group consists employed bees. These bees have a food source position in their mind when they leave from the hive. And they perform dances about their food sources on the dancing area in the hive. Some of the bees decide the food sources to exploit by watching the dances of employed bees. This group of bees is called as onlookers. In the algorithm, onlookers select the food sources in a probability that related to the qualities of the food sources. The last different bee group is scouts. Regardless of any information of other bees, a scout finds a new food source and start to consume it, then she continues her work as an employed bee. Hence, while the known resources are consuming, at the same time exploration of the new food sources is provided. At the beginning of the search (initialization phase), all of the bees in the hive work as scouts and they all start with random solutions or food sources. In further cycles, when the food sources are abandoned, the employed bee related to the abandoned resource becomes a scout. In the algorithm, a parameter, limit is used to control the abandonment problem of the food sources. For each solution, the trial number of improvement is taken, in every cycle the solution which has the maximum trial number is determined and its trial number is compared with the parameter limit. If it achieve the limit value, this solution is leaved and searching process continues with a randomly produced new solution.In ABC algorithm, a food source position is defined as a possible solution and the nectar amount or quality of the food source corresponds to the fitness of the related solution in optimization process. Since, each employed bee is associated with one and only one food source, the number of employed bees is equal to the number of food sources.The general algorithmic structure of the ABC optimization is given below:Initialization phaseREPEATEmployed bees phaseOnlooker bees phaseScout bees phaseMemorize the best solution achieved so farUNTIL (cycle=maximum cycle number or a maximum CPU time)In the initialization phase, food sources are randomly initialised with Eq. (1) in a given range.(1)xm,i=li+rand(0,1)*(ui−li)where xm,iis the value of the i. dimension of the m. solution. lirepresents the lower and uirepresents the upper bound of the parameter xm,i.Then, obtained solutions are evaluated and their objective function values are calculated.This phase of the algorithm describes the employed bees behaviour for finding a better food source within the neighbourhood of the food source (xm) in their minds. They leave the hive with the information of the food source position, but when they arrive the target point, they are affected from the traces of the other bees on the flowers and they find a candidate food source. In the ABC optimization they determine this neighbour food source by using Eq. (2).(2)υm,i=xm,i+ϕm,i(xm,i−xk,i)where xkis a food source selected randomly. i is also a randomly chosen dimension and ϕm,iis a random number within the range [−1,1]. After producing the new candidate food source υm, its profitability is calculated. Then, a greedy selection is applied between υmand xm.The fitness of a solution fit(xm) can be calculated from its objective function value f(xm) by using Eq. (3).(3)fit(xm)=1/(1+f(xm))iff(xm)≥01+abs(f(xm))iff(xm)<0When employed bees return to the hive, they share their food source information with onlooker bees. An onlooker chooses her food source to exploit depending on this information, probabilistically.In ABC algorithm, using the fitness values of the solutions, the probability value pmcan be calculated by Eq. (4).(4)pm=fit(xm)∑m=1SNfit(xm)After a food source is selected, as in the employed bees phase a neighbour source υmis determined by using Eq. (2), and its fitness value is computed. Then, a greedy selection is applied between υmand xm. Therefore, recruiting more onlookers to richer sources, positive feedback behaviour appears.At the end of every cycle, trial counters of all solutions are controlled. And abandonment of the solution that has maximum counter value is determined by looking limit parameter. If an abandonment is detected, the related employed bee is converted to a scout and takes a new randomly produced solution using Eq. (1). In this phase, to balance the positive feedback, a negative feedback behaviour arises.In real honey bee colonies, an employed bee exploits the food source that she visited before, but an onlooker chooses a food source region depending on the dances of the employed bees. After reaching that region where she visits for the first time, the onlooker bee examines the food sources in the area and chooses the fittest one to exploit. So, it can be said that onlookers choose their food sources in a different way from employed bees. However, in standard ABC algorithm, this difference is not considered and artificial employed bees and onlookers determine a new candidate solution by using the same formula (Eq. (2)). Onlookers behaviour should be modelled by a different formula from Eq. (2). So, in qABC algorithm, a new definition is introduced for the behaviour of onlookers. This novel definition is given as follows:(5)υNm,ibest=xNm,ibest+ϕm,ixNm,ibest−xk,iIn this formula,xNmbestrepresents the best solution among the neighbours of xmand itself (Nm). A similarity measure in terms of structure of solutions can be used to determine a neighbourhood for xm. At this point, in order to define an appropriate neighbourhood, different approaches could be used. And also, for different representations of the solutions, different similarity measures can be defined. Hence, using this novel formula, Eq. (5), combinatorial or binary problems could be optimised by using qABC algorithm, too. As an instance, the neighbourhood of a solution (xm) could be defined considering the mean Euclidean distance between xmand the rest of solutions for the numerical optimization problems. Representing the Euclidean distance between xmand xjas d(m, j), the mean Euclidean distance for xm, mdm, is calculated by Eq. (6).(6)mdm=∑j=1SNd(m,j)SN−1If a solution of which Euclidean distance from xmis less than the mean Euclidean distance, mdm, it could be accepted as a neighbour of xm. It means that, an onlooker bee watches the dances of the employed bees in the hive and being effected by them, she selects the region which is centred by the food source xm. When she arrives the region of xm, she examines all of the food sources in Nmand chooses the best one,xNmbestto improve. Including xm, if there are S solutions, the best solution is described by Eq. (7) in Nm.(7)fitxNmbest=maxfitxNm1,fitxNm2,…,fitxNmSIn order to determine a neighbour of xm, a more general and flexible definition can be used is given below:(8)ifd(m,j)≤r×mdmthenxjisaneighborofxm,elsenotWith this expression, a new parameter r which refers to the “neighbourhood radius” is added into the parameters of standard ABC algorithm. This parameter must be used as r≥0. In Eq. (8), when r=0, Eq. (5) works same as Eq. (2) and in this situation, qABC turns to be the standard ABC, sincexNmbestbecomes xm. While the value of r increases, the neighbourhood of xmenlarges or its neighbourhood shrinks as the value of r decreases.Detailed steps of qABC algorithm are given below:Initialization phase:Initialize the control parameters: colony size CS, maximum number of cycles MaxNum, limit l.Initialize the positions of the food sources (initial solutions) using Eq. (1), xm. m=1, 2, …, SN.Evaluate the solutions.Memorize the best solution.c=0repeatEmployed bees phase: for each employed bee;Generate a new candidate solution υmin the neighborhood of xm(Eq. (2)) and evaluate it.Apply a greedy selection between xmand υm.Compute the fitness of the solutions by using Eq. (3) and calculate the probability values pmfor the solutions xmwith Eq. (4).Onlooker bees phase: for each onlooker bee;Select a solution xmdepending on pmvaluesFind the best solutionxNmbestamong the neighbours of the xmand itself. These neighbours are determined by expression (8)Generate a new candidate solutionυNmbestfromxNmbest(Eq. (5)) and evaluate it.Apply a greedy selection betweenxNmbestandυNmbest.Memorize the best solution found so far.Scout bee phase: using the limit parameter value l, determine the abandoned solution. If exists, replace it with a new solution for the scout by using Eq. (1).c=c+1until (c=MaxNum)We conducted the experiments with different values of r (r=0, r=0.25, r=0.5, r=1, r=1.5, r=2, r=2.5, r=3, r=∞) and the effect of this parameter was analysed in means of the convergence performance and the quality of the solutions obtained by the algorithm. Results of qABC were compared with the state of art algorithms including genetic algorithm (GA), particle swarm optimization (PSO), differential evolution (DE) algorithm and standard ABC. The results of GA, PSO and DE are taken from [31]. For a fair comparison the same parameter settings and the evaluation number are used as in [31]. So, the colony size is 50 and maximum evaluation number is 500,000. For the scout process, the limit parameter l is calculated with Eq. (9)[31]:(9)l=CS*D2where CS is the colony size and D is the dimension of the problem.Wilcoxon statistical test was also carried out for standard ABC and qABC algorithms. 10 well-known benchmark problems with different characters were considered in order to test the performance of qABC. These test problems, characteristic of the functions (C), dimensions of the problems (D), bounds of the search spaces and the global optimum values for these problems are presented in Table 1. One of these benchmarks is unimodal-seperable (US), two of them are unimodal-nonseperable (UN), three of them are multimodel-seperable (MS) and four of them are multimodel-nonseperable (MN).For each test case, 30 independent runs were carried out with random seeds. The values below the E−15 are accepted as 0. Tables 2–9show the mean values (mean) and the standard deviation values (SD) calculated for the test problems over 30 runs. Moreover, objective function values of the best and the worst of 30 runs are given in these tables too. From the tables, it is very easy to see similar mean and SD values presenting the performances of qABC with different values of the parameter r.The qABC algorithm hits the optimum result for each of 30 independent runs on Sphere and Rastrigin problems for all r values. Tables 7 and 8 present the effect of the parameter r on Schwefel and SixHumpCamelBack functions, respectively. For all r values, qABC can find optimum results in terms of mean, best and worst of 30 runs for these test functions. The same performance comparisons on Rosenbrock function is demonstrated in Table 2. qABC(r=1.5) produces more successful mean, SD and worst results and qABC(r=2.5) is the most successful one in terms of the best of 30 runs among the qABC algorithms with different r values. In Table 9, the effect of the parameter r on Branin function is presented. For all r values, qABC finds the same objective function value which is very close to the optimum result in all columns of the table except SD column on Branin function. Only qABC(r=0) finds the 0 value as standard deviation for this test function. For most of the r values, qABC finds optimum results in Table 3 for Griewank function. Only qABC(r=2.5 and r=3) give different results from the optimum values on mean and SD columns. However, these results are very close to optimum ones. And at least once in 30 runs, qABC finds the optimum solution of Griewank function. Tables 4 and 5 demonstrate the performance results of qABC on Schaffer and Dixon-Price functions, respectively. These results show that, qABC is effected by the value of the parameter r on these test functions. qABC(r=0) presents more successful results in all fields of the table for both functions. And also, only qABC(r=0) finds the optimum result for Schaffer function. Table 6 shows the results of the qABC on Ackley function. For all r values, qABC presents similar results at the end of the optimization process for Ackley function. qABC(r=0) generates the best results in terms of mean and SD of 30 runs. When r is smaller than 1.5, qABC gives better values in the column “worst” of the table on Ackley function.Considering the objective function values and the evaluation numbers, the convergence graphics of qABC with different r values are shown in Figs. 1–10for Sphere, Rosenbrock, Rastrigin, Griewank, Schaffer, Dixon-Price, Ackley, Schwefel, SixHumpCamelBack and Branin, respectively. When these figures are examined, the first six of them present a remarkable difference between qABCs having r≥1 and the other ones. The speed of the convergence looks similar for the r≥1 valued qABC algorithms for these test problems except Schwefel. Although qABC(r=1) has a quicker convergence performance than qABC(r=0) and qABC(r=0.5), in early evaluations its convergence performance is slower than in the case of r>1 for Schwefel function. When the graphics of the first six functions are examined for the values of r smaller than 1, qABC(r=0.5) performs softly better convergence than qABC(r=0) for Griewank, Dixon-Price and Ackley functions. For Schaffer function, the convergence speed of qABC(r=0.5) is considerably better than the performance of qABC(r=0) while there is no significant difference between these two r values on Rosenbrock and Rastrigin functions. Since qABC converges to the optimal values in very early evaluations on Branin and SixHumpCamelBack functions for all r values, comparing the speed of the convergence is meaningless through the optimization process. Actually, it can be said that qABC has a very successful convergence performance on these two 2 dimensional test problems for all considered r values.These graphics show that the parameter r is one of the main factors for the convergence speed of qABC algorithm. It should be reminded that, when r=0, Eq. (5) becomes equal to Eq. (2) and qABC works like the standard ABC. Generally, when r≥1, the standard ABC requires at least two times more function evaluations than qABC to reach the same mean value. When the convergence graphics and the results in the tables are evaluated, it can be generalised that a value around 1 for r is an appropriate value for qABC algorithm. So, in the comparison of qABC with the state of algorithms (GA, PSO, DE, ABC), the results of qABC having the parameter r=1 was used. This comparison results are given in Table 10. In the table, the mean of 30 independent runs and the standard deviations are presented for considered problems. For a fair comparison the table values below E−12 are accepted as 0 as in [31].When Table 10 is examined, it can be seen that GA has the worst performance among the considered algorithms for all problems except Schwefel, SixHumpCamelBack and Branin. It has the best performance on SixHumpCamelBack and Branin functions. However, there is not a really remarkable difference between the performance of the algorithms, we can say that all algorithms perform well on SixHumpCamelBack and Branin test functions. On Rosenbrock function, the standard ABC and qABC algorithms find smaller objective function values than other compared algorithms, and the best mean and SD values belong to the qABC algorithm. qABC and ABC algorithms find optimum results for Rastrigin and Griewank functions while other algorithms do not. Performance of the PSO and DE on Griewank is better than that on Rastrigin function. However GA's performance does not show a remarkable difference on these test functions. PSO and DE algorithms achieve the optimum results in given number of function evaluations, while ABC, qABC and GA orderly converge to the optimum value with some errors on Schaffer function. qABC and ABC algorithms present excellent performance, however other algorithms do not provide so good results on Schwefel and Dixon-Price functions. Both ABC algorithms give the same mean value which is very close to optimum for Schwefel function and ABC hits the optimum mean value of Dixon-Price while qABC does not. For Ackley problem, all of the algorithms find the optimum results except GA and PSO. PSO's result is closer to 0 than the result of the GA.The table clearly shows that ABC and qABC algorithms clearly outperform GA, PSO and DE in these conditions on the considered test problems. However, it is not very clear that there is a significant difference between the performances of the two ABC algorithms which produce very similar results and present the best mean values for six of ten problems among the compared optimization algorithms. So, in order to compare the performance of the qABC and ABC, the Wilcoxon signed rank test was used in this paper. Wilcoxon test is a nonparametric statistical test that can be used for the analyzing the behaviour of evolutionary algorithms [33]. The test results are shown in Table 11. The first column of the table presents the test functions, and the second column gives the mean difference between the results of ABC and qABC. The last column gives the p value that is an important determiner of the test. Since the mean difference column value is 0 for six text functions, there are four test problems that the significance of the difference between the performances of the algorithms can be discussed. Among the four test problem, the p value is different from 0 for only Rosenbrock. So, only for Rosenbrock problem there is not enough evidence to reject the null hypothesis (0.711>0.05). These tests show that in these conditions, the performance of ABC algorithm is significantly better than qABC for other three test functions (Schaffer, Dixon-Price and Branin). It should be emphasised that these tests are based on the final results obtained by the algorithms.Generally, we could interpret the simulation and test results as, when Eq. (5) is used for onlookers to produce new solutions with r≥1, the local convergence performance of ABC is significantly improved especially in the early cycles of the optimization process. So, a good tuning of the parameter r promises a superior convergence performance for qABC algorithm.In this section, a time complexity analysing process is carried out for ABC and qABC algorithms on Rosenbrock function. In order to present the time complexity's relationship with the dimension of the problem, the complexities are calculated for the dimensions: 10, 30 and 50 as described in [32]. The results are shown in Table 12for ABC and qABC algorithms. These analyses were performed on Windows 7 Professional (SP1) on a Intel(R) Core(TM) i7 M640 2.80GHz processor with 8GB RAM and the algorithms were coded by using C Sharp programming language and.net framework 3.5 was used.The code execution time of this system was obtained and demonstrated in the table as T0. Also, the computing time for Rosenbrock function for 200,000 function evaluations is presented as T1 in the table. Each of the algorithms was run 5 times for 200,000 function evaluations and the average computing time of the algorithms are presented asTˆ2. The algorithm complexities were calculated by(Tˆ2−T1)/T0. The time complexity of the qABC is higher than ABC algorithm since there is an additional part in the phase of onlooker bees. However, it should be noticed that the increment rate on the complete computing time of qABC is lower than the increment rate of the dimension, like ABC algorithm. So, it can be indicated that there is not a strict dependence between the dimension of the problem and the complexities of qABC and ABC.For the experiments in this section, four test functions from Table 1 were selected. Each function has different character. These benchmarks are: Sphere, Rosenbrock, Rastrigin and Griewank functions. In the experiments, r was set as 1. The same parameter setting was used with the previous experiments (maximum evaluation number=500,000).The limit value was calculated by using Eq. (9) as indicated before. The qABC algorithm was tested on the mentioned functions for the several different colony size (CS) values: 4, 6, 12, 24, 50, 100, 200 and the results of the experiments are presented in Table 13.The table shows that qABC algorithm gives the optimal results in all fields without being influenced by changing the CS for the values CS>6 and CS>12 on Sphere and Rastrigin functions, respectively. The optimal values are also found by the algorithm on Griewank function with CS=50 and CS=200. Although the algorithm finds the results very close to the optimum for CS=100, when CS<50, there is not efficient convergence to the optimum for Griewank test function. Considering the standard deviations, the mean values are very similar for Rosenbrock problem for the intervals of the CS values 24–200 and 6–12. However, when CS=4, the results of qABC significantly get worse on Rosenbrock function.The same test functions in the previous section were used to test the qABC algorithm for different limit values (10, 50, 187, 375, 750, 1500) to observe the relation between the parameter limit and the performance of the algorithm for this algorithm. The same parameter setting used in the previous experiments (colony size=50 and the maximum evaluation number=500,000) were used. In terms of the mean and standard deviation of 30 independent runs, the simulation results are given in Table 14. On Griewank, Sphere and Rastrigin functions, the results get better as the limit values increase. However, the algorithm achieves the optimum results when the limit value is l≥750 for the Griewank function and l≥375 for the Sphere and Rastrigin functions. When the standard deviation is considered, the difference between the mean objective function values produced for different limit values looks very small on Rosenbrock function except the smallest limit value, 10.The results of these experiments showed that, 750 which is equal to the value calculated by Eq. (9) is a suitable value as the limit parameter.

@&#CONCLUSIONS@&#
