@&#MAIN-TITLE@&#
Generating flexible convex hyper-polygon validity regions via sigmoid-based membership functions in TS modeling

@&#HIGHLIGHTS@&#
A new type of membership function in TS modeling is introduced which can generate flexible convex hyper-polygon validity regions.Based on the introduced membership function, two types of TS models are proposed whose consequent parts of the rules are linear and quadratic functions.An incremental learning algorithm is suggested to identify the proposed TS models.Obtained results demonstrate high accuracy and low redundancy of the suggested TS fuzzy models.

@&#KEYPHRASES@&#
Learning,Takagi–Sugeno fuzzy model,Membership functions,Flexible validity regions,Convex hyper-polygon subspaces,Sigmoid-based functions,

@&#ABSTRACT@&#
Using suitable Membership Functions (MFs) has a substantial impact on increasing of the accuracy and reduction of redundancy in a neuro-fuzzy modeling approach. In this paper, we suggest sigmoid-based MFs which can generate flexible convex hyper-polygon validity regions in Takagi–Sugeno (TS) fuzzy models. To this end, the sigmoid-based function is equal to the product of some sigmoid functions whose arguments are hyperplane equations. It is discussed that such function can represent a soft, convex, flat region with arbitrary number of hyperplane borders (edges). Afterwards, we introduce first-order and high-order TS fuzzy models, where, the suggested sigmoid-based functions are utilized in the premise parts of the fuzzy rules and linear models or quadratic functions are used as submodels in consequence parts. It is shown that utilized submodels can be optimized locally and globally. An incremental learning algorithm is then suggested to identify both first-order and high-order TS fuzzy models. The performance of introduced TS fuzzy models are examined and compared with existing models in prediction of a chaotic time series as well as in function approximation of a sun sensor. Obtained results demonstrate high accuracy and low redundancy of the suggested high-order TS fuzzy model. Finally, the learning performance of two introduced first-order and high-order TS fuzzy models are compared with each other in identification of a steam generator model.

@&#INTRODUCTION@&#
Using parametric nonlinear approaches to model nonlinear systems and processes bears much merit. For this purpose, fuzzy models along with artificial neural networks and classical nonlinear models are commonplace modeling tools. Among various fuzzy models, Takagi–Sugeno (TS) fuzzy models have been vastly tested and developed for many applications [1]. TS fuzzy models can be organized and trained like neural networks; also, they can be deployed in many applications easily due to their interpretable fuzzy rules.Choice of suitable MFs for the TS fuzzy model has a critical impact. Accuracy, computation complexity and redundancy of a TS fuzzy model strongly correlate with the smoothness, sizes and shapes of the fuzzy subspaces represented by MFs. Thus, different types of MFs have been chosen and used in TS fuzzy models.In many TS fuzzy models, choosing simple MFs with few parameters is the main concern [2–13]. Such MFs represent fuzzy subspaces with even shapes, like triangular, trapezoidal or oval. Adaptive Network-based Fuzzy Inference System (ANFIS) [2] is a well-known TS fuzzy model whose suggested triangle or Gaussian MFs are adapted through back-propagation. Dynamic Evolving Neural-Fuzzy Inference System (DENFIS) [3] is another instance of TS fuzzy model, in which triangular or Gaussian MFs are utilized; where, evolving clustering with constrained minimization is used for partitioning data space and determining the MFs. In [4], a TS fuzzy model with affine linear models and normal bell-shaped MFs are suggested. A fuzzy clustering technique is applied to this TS fuzzy model in order to partition the input–output data space into hyperplane-shaped clusters and to tune parameters of MFs. In [5], triangular MFs and quadratic polynomial submodels have been used. Parameters of MFs and submodels are tuned through a version of a parallel genetic algorithm. In [6], a TS fuzzy model with Gaussian MFs is identified through a genetic algorithm. There, the rule structure, the input structure and the MF parameters of the TS fuzzy model are all represented and optimized in one chromosome. In [7], generalized least squares methodology is suggested in nonlinear system identification. To improve parameters of applied Gaussian MF an expectation-maximization algorithm has been used. In [8], a TS fuzzy model with Gaussian MFs is identified through cooperative random learning. In [9], to identify a first order TS fuzzy model with Gaussian MFs, the structural optimizing and parameter tuning are performed sequentially based on an output error index. Sigmoid MFs are another usual choice to create validity regions in TS fuzzy models. In [10], sigmoid functions are utilized as MFs in local linear model structure for the model-based controller design. These MFs provide validity regions for a grid of local linear models. In [11], sigmoid functions have been utilized in combination of local linear models. The resulting local linear models present different regimes of the friction force in motion directions. Also, one can find more literature about using sigmoid MFs [12,13]. In the above mentioned TS fuzzy models – which utilize simple MFs – the accuracy of the model can be improved by increasing the number of rules; however, this may result in too many rules, which gives rise to poor generalization among other problems.One way to fulfill the required accuracy while keeping the number of fuzzy rules low is to utilize flexible MFs that represents the input space with more flexible validity regions. To this end, several strategies are proposed. In [14], Gaussian, Sigmoid and triangle MFs are used simultaneously in a TS fuzzy model. To tune their parameters, genetic algorithm is utilized. Using asymmetric version of typical MFs to make rather flexible validity regions is a second strategy followed in [15–20]. In [15], asymmetric triangular fuzzy sets and in [16] asymmetric RBF MFs have been suggested. In [17] asymmetric Gaussian function are suggested, where results in special shape membership functions without the convex property. In [18], respecting to the considered left side and right side of a focal point, two Gaussian functions with different spread matrices are utilized. In [19], to provide more flexible rules in a general neural fuzzy system pseudo-Gaussian membership functions have been proposed. In [20], from parts of four Gaussian functions, asymmetric interval-valued membership function are constructed to make more flexible validity regions in neural fuzzy systems.In a third strategy to provide more flexible validity regions, MFs are considered as the product of two or more nonlinear functions. In [21], a generalized TS fuzzy model is introduced whose MFs are equal to the product of sigmoid functions and other un-even nonlinear functions which are computed from clustering results. In [22], a variant of TS fuzzy model is introduced whose MFs are equal to the product of sigmoid functions with a quadratic functions, where the sigmoid functions provide flat top hyper-rectangle validity regions while quadratic functions provide flexible validity regions for local linear models.Using split and merge operations on simple fuzzy subspaces can be considered as the fourth strategy to create more flexible validity regions. In [23], each MF is defined as sum of a number of Gaussian functions, which can represent a flexible block-based fuzzy subspace. These MFs are obtained through a split-and-merge procedures in the premise parts of the fuzzy rules. In [24,25], similar to [23], block-based validity regions are generated for local linear models in evolving neuro-fuzzy models for online identification.In this paper, we introduce a new approach to build soft convex hyper-polygon validity regions by using a multiplication of sigmoid-type MFs. The major difference of our method with above-mentioned works is in its potential to generate much more flexible validity regions. In our approach, we can generate arbitrary convex hyper-polygon validity regions in which the number of hyperplanes and their associations are not restricted. Such feature for validity regions allow for accurate TS fuzzy models with much lower number of fuzzy rules. Sigmoid-type functions – as the building block of our MFs – play a vital role in our model. The MFs are defined as the product of typical sigmoid functions whose arguments are hyperplane equations. Flexible MFs along with the proposed learning algorithm result in soft and flexible convex hyper-polygon validity regions. Both linear and quadratic local models are considered in the consequence part of the fuzzy rules. A theorem is proven to characterize both local and global optimization of submodels’ parameters. An incremental identification algorithm is introduced to identify the introduced TS-type fuzzy models.The rest of the paper is organized as follows: In Section 2, sigmoid-based functions are explained. In Section 3, first-order and high-order TS fuzzy models are introduced. In Section 4, an incremental algorithm is proposed for identification of the introduced first-order and high-order TS fuzzy models. Section 5 is devoted to case studies: A function approximation problem is considered, which illustrates how soft, convex, flat fuzzy subspaces are created through sigmoid-based functions. In the next case study, a chaotic time series is identified and predicted through the suggested TS fuzzy model. Also the proposed model is applied to function approximation of a sun sensor. The obtained results are compared. The obtained results in prediction and approximation are put to comparison with other results reported in the literature. Finally, learning performances of introduced TS fuzzy models are compared to each other by applying them to identify a steam generator model. The paper is concluded in Section 6.Consider the n-dimensional data apace: Ω={x|x, ∈Rn}, where x=[x1, x2, …, xn]T. Consider the hyperplane p(x)=wT(x−c), which passes from c∈Ω, and w∈Rnis the normal of the hyperplane. The function φ(x)=(sign(p(x))+1)/2 divides Ω into two positive and negative subspaces:(1)Ω+=x,φ(x)=1Ω−=x,φ(x)=0Actually, φ(x) transients rigidly from zero to one, orthogonal to the direction where p(x)=0. Let p(x) be the argument of a sigmoid function as follows:(2)τ(x)=11+e−2γp(x)where γ≥0 denotes the variation rate of the function. Fig. 1shows the related function diagram when n=2, γ=2 and p(x)=4(x1−1)−(x2−1).As it can be inferred, τ(x) represents a soft version of the subspaces provided through φ(x). It changes softly from zero to one orthogonal to the direction where p(x)=0. In a generalized case, suppose there is a set of N hyperplanes,H=p1(x),p2(x),…,pN(x), which form the linear borders of a convex flat region, A. If the signums of hyperplane equations be positive within A and also their positive subspaces are defined through (1), it can be easily inferred that the intersection of positive subspaces shapes A. In another way, we can define A as follows:(3)A=x,φ¯(x)=1φ¯(x)=∏j=1Nφj(x),φj(x)=(sign(pj(x))+1)/2,pj(x)=wjT(x−cj)As one can understand from (3),φ¯(x)represents A, rigidly. To softly represent A, a sigmoid-based function is defined as follows:(4)μ(x)=∏j=1Nτj(x)τj(x)=11+e−2γpj(x)Generally, a soft, convex, flat region with arbitrary linear borders can be represented softly by (a) setting each linear border of the region as a hyperplane equation in the argument of a sigmoid function; and (b) computing the product of the resulting sigmoid functions.The softness degree of the represented soft, flat regions is dependent on γ. By choosing lower values for γ, softer flat regions are achieved; and contrary for high values of γ. Fig. 2shows some soft, convex, flat regions represented by defined sigmoid-based functions through (4).Consider a TS fuzzy model with M fuzzy rules. We describe the kth fuzzy rule as follows:(5)IFxisμkTHENy˜k=fk(x)where x denotes an n-dimensional input and μkis kth fuzzy set for x (The related Membership Function (MF) is considered as μk(x)).y˜kis a direct mapping of input-space as kth submodel. The overall outputyˆis computed as a weighted mean over all M rules according to:(6)yˆ=∑k=1Mψk(x)y˜k(x)ψk(x)=μk(x)∑h=1Mμh(x)Submodels, if considered linear or nonlinear, will result in first order or high-order TS fuzzy models, respectively.Now, we introduce a general structure of a TS fuzzy model, whose MFs are Sigmoid-based functions. Then, high order and first-order instances of this class of TS fuzzy models are introduced.Here, we suggest the introduced sigmoid-based functions in Section 2 to be used as MFs in a TS fuzzy model. We name such MFs as Sigmoid-based MFs (SBMFs) and the resulting TS fuzzy model as TS-SBMF fuzzy model. The SBMF related to kth fuzzy rule in a TS-SBMF fuzzy model is defined through Hkas a set of Nkhyperplanes:(7)Hk=p1k(x),p2k(x),…,pNkk(x)pjk(x)=wjkT(x−cjk)μk(x)=∏j=1Nkτjk(x)Nk>01Nk=0Fig. 3shows the structure of the TS-SBMF fuzzy model as a network with M nodes. Each node is the product of a SBMF and a submodel shown by SM. σ(·) denotes a typical sigmoid function as defined in (4).Here, we introduce a high-order TS-SBMF fuzzy model, whose submodels are quadratic functions. This model is defined as follows:(8)yˆ=∑k=1Mψk(x)y˜k,y˜k=zTSkzwhere Sk∈R(n+1)×(n+1) is a symmetric matrix andzT=[xT1]. The following theorem presents optimum quadratic functions, which minimizes the Sum of Squared Errors (SSE) of the model (8) locally and globally. Here ⊗ denotes the Kronecker product and vec is an operator used to vectorize a matrix [26].Theorem 1Consider a nonlinear process with a single output, y∈R, and n-dimensional input, x∈Rn×1; Suppose (xi, yi), i=1, 2, …, Q denote observed input–output data points of the process; Consider the represented TS-SBMF fuzzy model in Eq.(8)for this process. It can be shown that:The achievedSk, k=1, 2, …, M from Eq.(9)are optimum answers minimizingJ=∑i=1Q(yi−yˆi)2.The achievedSkfrom Eq.(10)is the optimum answer minimizingJk=∑i=1Qψk(xi)(yi−y˜ik)2.The proof is given in Appendix A. ■Since Bfkand Aiiare symmetric matrices, Bfk=Bkf, and Skis considered symmetric, approximately half of the linear equations (rows of Eqs. (9) and (10)) are redundant. Ergo, to compute Sk, k=1, 2, …, M, one must remove these redundant equations and then solve the remaining set of linear equations.Now, we discuss that how kth optimized quadratic submodel can be used to determine the directions along which the TS-SBMF fuzzy model changes mainly within the kth subspace. This concept will be utilized to define new SBMFs in Section 3.Suppose the matrix is decomposed as follows:(11)Sk=S¯kskskTs0whereS¯k∈Rn×nis a symmetric matrix and sk∈Rn×1; suppose ckis a focal point for kth fuzzy subspace. With respect to (11), we can rewrite kth quadratic function as follows:(12)y˜k=zTSkz=xTS¯kx+2skTx+s0=(x−ck)TS¯k(x−ck)+2(sk+S¯kck)Tx+s0−ckTS¯kck=(x−ck)TS¯k(x−ck)+θkTzθkT=[2(sk+S¯kck)Ts0−ckTS¯kck]As it can be seen, the difference of the initial quadratic function and the extracted linear model is a pure quadratic expression. If we consider it as an independent function:(13)χk(x)=(x−ck)TS¯k(x−ck)We knowS¯k=∑k=1nλdk(vdk)(vdk)Twhereλdkandvdkare eigenvalues and orthogonal unitary eigenvectors ofS¯k. We can, then, rewrite χk(x) as follows:(14)χk(x)=∑d=1nλdk((x−ck)Tvdk)2χk(x) is the sum of n convex functions. Each convex function passes from ckand has main variation in the direction of one of eigenvectors fromS¯k. These eigenvectors are the aforementioned directions along which the fuzzy model changes mainly within the kth subspace.First-order TS-SBMF fuzzy model is easily obtained by using linear models as submodels of the TS-SBMF fuzzy model as follows:(15)yˆ=∑k=1Mψk(x)y˜k,y˜k=θkTzwhere θkdenotes linear parameters of kth fuzzy model. Consider a first-order TS-SBMF fuzzy model instead of the high-order TS-SBMF fuzzy model in the Theorem 1. We can use least squares optimization to provide optimum θk, k=1, 2, , …, M minimizing J as follows ([27]):(16)ζ=(ZTZ)−1ZTYζ=θ1Tθ2T⋯θMTTwhere Y∈RQ×1 and Z∈RQ×M(n+1) are matrices whose ith rows are defined as yiand,[z˜i1Tz˜i2T…z˜iMT], respectively, andz˜ik=ψk(xi)zi. Also, we can use the weighted least squares optimization to provide optimum θkminimizing Jkas follows ([27]):(17)θk=(ZkTZk)−1ZkTYkwhere Yk∈RQ×1 and Zk∈RQ×M(n+1) are matrices whose their ith rows are defined asy⌣ik=(ψk(xi))0.5yiandz⌣ik=(ψk(xi))0.5zi, respectively.In this section, an incremental identification algorithm for the introduced first-order and high-order TS-SBMF fuzzy models is proposed. The equations in parentheses e.g. (Equation x) refer to first-order TS fuzzy model. At first, some important details are explained then the overall algorithm is presented through a flowchart.1.The algorithm is initiated by the identification of the first fuzzy rule. Then, at each stage, one fuzzy rule is chosen and replaced with two new ones.Suppose there are M fuzzy rules. To choose a fuzzy rule, we need to evaluate its related submodels; therefore, we define a local Sum of Square Error (SSE) index for submodel of kth fuzzy rule as follows:(18)Jk=ψk(xi)(eik)2k=1,2,…,Meik=yi−y˜ikThe fuzzy rule whose related submodel has the highest local SSE is chosen(19)kw=argkmaxJ(Jk)For each fuzzy subspace, we define a focal point through normalized SBMF as follows:(20)ck=∑i=1Qxiψk(xi)∑i=1Qψk(xi)To replace kwth fuzzy rule with fuzzy rules k1 and k2, premise parts are determined as two SBMFs through following sets of hyperplanes:(21)H¯1=Hkw∪p1(x)p1(x)=vjkwT(x−ckw)/m1H¯2=Hkw∪p2(x)p2(x)=−vjkwT(x−ckw)/m2m1=maxi(vjkwT(xi−ckw)ψkw(xi)),i=1,2,…,Qm2=maxi(−vjkwT(xi−ckw)ψkw(xi))As it can be inferred, two hyperplanes, p1(x) and p2(x), have been normalized through m1 and m2. They pass fromckwand one of scattering matrix'sS¯kweigenvectors,vjkw, is used to define their normal vectors. The scattering matrixS¯kwis computed from (10) and (11). By applying (7) toH¯1andH¯2two new SBMFsμ¯1(x)andμ¯2(x)are defined. Then, two related submodels, as consequence parts of two new fuzzy rules are optimized through Eq. (10) (Eq. (17)).For each new defined fuzzy rule like, e.g. kth one, we remove redundant hyperplanes. A hyperplane is redundant if the created convex flat region, as defined in (3), does not change.Two training and test sets of data points are provided. By using the train data set, the fuzzy rules of are learned. The algorithm stops if there is no significant reduction in the SSE index. We use the test data set to evaluate the identified model whether we involve it in Hkor not.Through a post-tuning procedure, one can update parameters of submodels globally through Eq. (9) (Eq. (16)).As it is discussed in Section 2, γ determines the softness of convex flat regions. Through numerous simulations of different cases, it is practically determined that choosing γ between 8 and 15 provides favorable results. However, using lower values is suggested for the cases where more extrapolation is required. In this paper, we use γ=12 for both first-order and high-order TS-SBMF fuzzy models.Fig. 4presents a flowchart to identify the introduced first-order and high-order TS-SBMF fuzzy models.In this section, we present the simulation results of applying the introduced learning algorithm to the aforementioned TS-SBMF fuzzy models, in an illustrative example and three different case studies. In the first case study, it is illustrated how soft, convex, flat regions are created through sigmoid-based functions. Next, prediction of the Mackey-Glass (MG) time series is studied. The MG time series is a known benchmark for these purposes. The TS-SBMF is applied to approximate a function for calibration of a sun-sensor, too. Through these case studies, performances of suggested TS-SBMF fuzzy models are compared with some other approaches taken in the literature: MLP (Multi Layer Perceptron), ANFIS, NRBF (Normalized Radial Basis Functions), LOLIMOT [27], TS-SAMC, TS-DLM and DENFIS. Table 1presents important adjustments for these approaches. All other parameters of approaches have been adjusted as their default values. All performed computations and algorithm implementations have been done in software MATLAB R2008a.Also, the performances of two introduced first-order and high-order TS-SBMF fuzzy models are compared with each other by applying them to identify a steam generator model in the third study.Approximation of a Sinc function by the high-order TS-SBMF fuzzy model is considered.(22)y=sinc(x1,x2)=sin(x1)x1sin(x2)x2From the grid points of the range [−10,10]×[−10,10] within the input-space of the Sinc function, 700 training data pairs and 350 test data pairs were selected randomly. To approximate the Sinc function, we applied the explained identification algorithm in Fig. 4 to TS-SBMF fuzzy model. Fig. 5shows RMSE plots of training and test data sets versus the number of rules.As it is seen, the RMSE index reduces as well as the number of rules increases; Fig. 6shows some views of approximated Sinc functions with different number of SBMFs and their corresponding top-views.As it is seen, quadratic functions are localized in input-space through SBMFs. They can be recognized from each other by bold, black line boundaries. It is seen clearly while the number rules in the TS-SBMF fuzzy model is increased, the approximated function becomes more similar to a Sinc function. Also, form 2-dimensional top-views, one can see the generated polygon regions.Here, the TS-SBMF fuzzy model is identified to predict the Mackey-Glass (MG) time series. The MG time series is generated through a delayed differential equation:(23)x˙(t)=0.2x(t−τ1)1+x10(t−τ1)−0.1x(t)The delayed differential equation (23) is solved by fourth-order Runge–Kutta method with time step 0.1 from t=0 up to t=5500 and initial condition x(0)=1.2, as well as delay τ1=17. In this experiment, 3000 evenly sampled data points, for t=201–3200, are extracted as training data; 500 data points, for t=5001–5500, are used as test data. The goal is 85-step-ahead prediction of time series based on its values at the current moment along with 6th, 12th, and 18th lags.(24)yt=x(t+85)xt=[x(t−18),x(t−12),x(t−16),x(t)]TThis particular selection of training and test data as well as xtand ytmakes our results comparable with other reported results [3]. The No Dimensional Error Index (NDEI) which is the ratio of the root mean square error over the standard deviation of the target data is considered for evaluation and comparison purposes. The suggested first-order and high-order TS-SFMF fuzzy models are identified through the proposed identification algorithm for the generated MG time series.Fig. 7shows the RMSE plots of train and test data sets versus number of fuzzy rules. As it is seen by increasing the number of rules, RMSE index decreases continuously. The algorithm stops for M=50 where there is no significant reduction in the RMSE index.Table 2presents the prediction results of MG time series including the number of rules (neurons), number of training epochs, training times and computed NDEI for both training and test data sets. The initial five rows of the table are the same with the ones whose results are reported in [3]. As it is seen in Table 2, the suggested high-order TS-SBMF fuzzy model with post tuning has the least training and testing NDEI and lowest number of fuzzy rules. Although the first-order TS-SBMF with M=50 is not as accurate as high-order one, by increasing the number of fuzzy rules to M=200 the results are much more favorable. Also, it can be seen that using post tuning procedure for high-order TS-SBMF, unlike to first-order one, increases the training time, considerably.Due to memory limitations in embedded systems, it is demanded that the large look-up tables of sensors or actuators be replaced by accurate nonlinear models with concise structures. Here, we apply the proposed first-order and high-order TS with its learning algorithm to approximate the look-up table of a sun sensor utilized in attitude control of satellites (courtesy of Space Research Center of Iran for the use of data). This look-up table has 110 columns and 110 rows. Considering the indices of the rows and columns as inputs, a 3-dimensional surface for the look-up table is formed and is shown in Fig. 8.Due to the rough region appearing in the last 30 rows of the table, they are memorized directly and the rest of the look-up table is considered for approximation. The maximum absolute difference of the estimated and original values of the table, Max, is considered for evaluation. In this case, the accuracy of the model providing Max<900 is satisfactory. We apply the proposed identification algorithm and some other approaches to this case. Table 3presents the achieved comparison results. As it is seen in Table 3, both proposed first-order and high-order TS-SBMF have made best NDEI and minimum absolute of error. However, the training time for the proposed approaches is not optimum.In this case study, we identify a steam generator model with first-order and high-order TS-SBMF fuzzy models and then we compare their learning performances. The data comes from a model of a steam generator at the Abbott power plant in Champaign, IL, United States [28]. This model has four inputs: fuel, air, reference level and disturbance and its considered output is steam flow (kg/s). Totally, 9600 input–output data pints are sampled with sampling rate 3s. We consider half of them randomly for training data set and the rest for test data set. Both first-order and high-order TS-SBMF are applied to identify the steam generator model. Fig. 9shows the resulting RMSE plots of the applied fuzzy models for training and testing data sets.As it is seen, training RMSE for both fuzzy models reduces by increasing the number of fuzzy rules. However, the reduction rate for the high-order TS-SBMF fuzzy model is more than the first-order one, considerably. This quality exists in just a few initial fuzzy rules for testing RMSE. The testing RMSE for the high-order TS-SBMF fuzzy model reduces much faster than the first-order one from M=1 up to M=4 but it increases unevenly for M≥5. This is due to the overfitting problem, where identified local quadratic submodels become over adapted to the training data points and distances from the true operating regimes. As a result, the high-order TS-SBMF has a much better training performance but it may lose its generalization when the number of fuzzy rules is increased due to the overfitting problem.

@&#CONCLUSIONS@&#
