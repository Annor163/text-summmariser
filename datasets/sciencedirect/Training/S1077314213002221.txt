@&#MAIN-TITLE@&#
Classification of hepatic lesions using the matching metric

@&#HIGHLIGHTS@&#
We applied multidimensional persistent homology, the matching metric, and a support vector machine to classify hepatic lesions.We show that a multidimensional filtration is more effective than a one-dimensional filtration in classifying hepatic lesions.Combining geometric information with topological information improves results in lesion classification.We demonstrate that topological features are comparable to more traditional features in hepatic lesion classification.

@&#KEYPHRASES@&#
Medical image processing,Image classification,Persistent homology,Computational topology,

@&#ABSTRACT@&#
In this paper we present a methodology of classifying hepatic (liver) lesions using multidimensional persistent homology, the matching metric (also called the bottleneck distance), and a support vector machine. We present our classification results on a dataset of 132 lesions that have been outlined and annotated by radiologists. We find that topological features are useful in the classification of hepatic lesions. We also find that two-dimensional persistent homology outperforms one-dimensional persistent homology in this application.

@&#INTRODUCTION@&#
Medical imaging technology allows doctors access to portions of the human body which are visually inaccessible to the human eye. Often inspecting these medical images is a labor intensive process performed by diagnostic radiologists. The accuracy of the radiologist is obtained through training and experience [14] but even with extensive training and experience there are variations in interpretations and accuracy among radiologists [4,16]. Despite an increasing emphasis on evidence-based medicine and improved imaging techniques, quantitative ‘gold-standards’ and clear guidelines for a radiologist’s role in quantitative measurements remain elusive [13]. Image processing provides a way of both automating portions of the examination as well as providing standard tools for radiologists to use when reading an image. The qualitative nature of many radiological observations suggests that topological features may be useful in the classification and interpretation of medical images.In this paper, we explore automatic classification methods of computed tomography (CT) scans of hepatic (liver) lesions. We have a dataset of CT scans of 132 hepatic lesions along with an outline, diagnosis and semantic descriptors of the lesion provided by a radiologist. There are nine lesion types represented in the data, with the vast majority of the lesions (90 lesions) evenly split between cysts and metastases, followed by hemangiomas (18 lesions), hepatocellular carcinomas (HCC, 11 lesions), focal nodules (5 lesions), abscesses (3 lesions), neuroendocrine neoplasms (NeN, 3 lesions), a single laceration and a single fat deposit (see Figs. 1 and 2).It has been demonstrated that semantic features are useful for classification in hepatic lesions [14]. This indicates that visually identifiable structures exist within the lesions, but it has been difficult finding quantitative methods of defining these structures. For example, consider the six images in Figs. 3 and 4. The first three show the abscesses contained in our dataset. The second three show hemangiomas (deformations of blood vessels). The abscesses present what is called ‘cluster of grapes’ morphology. But the arrangements of this structure are very different in each lesion. Similarly, the hemangiomas show the characteristic large dark central region with dense white regions on the outer edge of the lesion. Yet, the hemangiomas lack a rotational orientation, different numbers of the two region types exist and the formations vary in size and shape. The qualitative nature of these observations has made it difficult to find quantitative measures of the structures.As mentioned above, semantic features have been one successful method for classifying the liver lesions [14]. This has led to preliminary investigations into using quantitative features to predict semantic features, which can be used to classify the lesions [12]. Additionally, computational features have shown some success in directly classifying liver lesions [12,14,18]. Most of these studies use a large number of various types of features (intensity histograms, wavelets, boundary features, etc.) to classify the lesions. Shape descriptors for liver lesions have also been investigated and found to work well in retrieving similar lesions [17].Persistent homology [5,19] is an approach to extending the notion of shape to point clouds or finite metric spaces, which has been developed over the last 10–15years. It has two directions of application, one which gives understanding of the overall organization of data sets (see e.g. [1,6,15]), and a second which applies to data sets consisting of data points which themselves have complex structure, such as databases of images or of chemical structures. This paper approaches radiological images from the second point of view. Persistent homology depends on a family of simplicial complexes parametrized by a real variable. In many applications, including the ones in the first direction, this parameter is simply a scale variable, which measures distances between points. In applications in the second direction, however, one uses families depending on other parameters, and often uses multiple persistence invariants in conjunction with each other to obtain useful information (see [8,10,11]). In particular, the authors of [11] use size functions to measure symmetry in classifying potential melanocytic lesions. In this paper we will find an appropriate set of parameters and functions of those parameters for classification problems arising in the radiology of liver lesions.In this paper we present a framework for computing persistent homology on images. This framework is flexible and allows the user to tailor the filtrations to the application. We demonstrate this by applying this framework to classifying our set of hepatic lesions and using the bottleneck distance to compare lesions. We find that our method gets comparable results to existing methods and our results demonstrate the possibilities of tailoring multidimensional persistence to a specific application. Additionally, since we use an ‘off-the-shelf’ implementation of the support vector machine to perform the final classification, our results demonstrate that this framework can be easily integrated with existing classification techniques.The work presented in this paper is an application of computational topology to medical image processing. As such, the theoretical material will be presented in a compact, informal manner following [8,10]. Those interested in the details behind the theory are encouraged to read the associated references.Let V be a set of points. A k-simplexS⊆Vof cardinality k+1. A geometric realization of a simplex consists of the convex hull of k+1 affinely independent points inRd,d⩾k. A 0-simplex is a point or vertex, a 1-simplex is an edge, a 2-simplex is a triangle, and a 3-simplex is a tetrahedron. Higher dimensional simplices are difficult to visualize and thus less familiar to our experience. A simplicial complex on V is a set K of simplices on V such that the following holds: If the simplexσ∈K, and the simplexτ⊂σthenτ∈K. A subcomplex of K is a simplicial complexL⊆K. A filtration of a complex K is a nested sequence of complexes∅=Kmin⊆Kmin+1⊆…⊆Kmax=K. We call K a filtered complex. We will often use the term complex to refer to both the complex itself and a geometric realization of the complex.Homology is an algebraic invariant that counts some of the topological invariants of the geometric realization X of a complex in terms of its Betti numbers,βi. Specifically,β0counts the number of connected components ofX,β1counts the number of tunnels through X, andβ2counts the number of voids in X (three-dimensional empty space enclosed by a two-dimensional surface).Consider the filtered complex, a nested sequence of complexes, mentioned above. We can track the topological changes that occur in this sequence via persistent homology, an algebraic invariant which tracks the birth (appearance) and death (disappearance) of topological attributes (Betti numbers) during the evolution of this sequence. The birth (a) and death (b) of a feature can be represented using the interval (a bar)[a,b]⊂R. Counting the number of features in existence at a point i (intervals which contain i) in the persistent homology of the filtered complex gives the homology ofKi. Generally, the longer a feature’s lifetime, the more important the feature is considered to be. Features can have infinite lifetimes if they appear in all complexes after a given point in the sequence.These concepts can be extended to multidimensional filtrations [7]. For example, in a two-dimensional filtration we have a sequence of simplicial complexes such thatKi1,i2⊆Kj1,j2ifi1⩽j1ori2⩽j2. The topological features in the two-dimensional case are more complicated than their one-dimensional counterparts but for the purposes of this application, can be thought of as existing across two-dimensional ‘sheets’ rather than bars. Except where noted, it can be assumed we are referring to one-dimensional filtrations.By computing the persistent homology of a filtered complex, we obtain a descriptor of the complex in the form of a finite multi-set of intervals, called a barcode. Thus, the barcode is useful both as a data structure for storing the results of the computation of the persistent homology of a filtered complex and as a visual representation of the persistent homology. A quasi-metric D, which we define as a metric which can take infinite values, can be defined over the collection of all barcodes allowing us to compare complexes using this quasi-metric on the space of barcodes. We follow [10] in defining D.LetB1andB2be two barcodes or finite multi-sets of intervals. For two intervals, I and J, we define their dissimilarityδ(I,J)to be their symmetric difference:δ(I,J)=μ(I∪J-I∩J), where μ denotes the one-dimensional measure. Note that I, J can be infinite intervals and consequentlyδ(I,J)can be infinite. A matching M onB1andB2is a setM(B1,B2)⊆B1×B2={(I,J)|I∈B1,J∈B2}, where each interval occurs in at most one pair (I, J). Note that in general, M will not have matched all intervals fromB1andB2. Let N be the set of unmatched intervals. We can now defineDM(B1,B2), or the distance relative to M, asDM(B1,B2)=∑(I,J)∈M)δ(I,J)+∑L∈Nμ(L)We define the quasi-metricD(B1,B2)as the best possible matching betweenB1,B2:D(B1,B2)=minMDM(B1,B2)This problem can be recast maximum weight bipartite matching problem and solved using the Hungarian algorithm. See [10] for details. We will abuse nomenclature slightly and refer to D as the matching metric.Each point in our dataset is an image, a two-dimensional collection of pixels (grayscale or intensity values) laid out on a grid with a set of contiguous pixels marked as lesion tissue. To use computational topology to analyze each image, we need a method of forming a filtered complex from an image. We can then use the theory outlined in Section 2 to create a barcode for each image and then use the matching metric to compare various images.Given a two-dimensional image I, we begin with the empty complex K. We then assign a vertex to each pixel in I and add each of these vertices (0-simplices) to K. We then form 1-simplices from these vertices if the associated pixels are adjacent in I (we treat diagonal pixels as adjacent). We then add 2-simplices on the vertices where 3pixels are mutually adjacent. This forms a very regular simplicial complex, a mesh, with the only variations between images being the boundary shape of I. As we are interested only in the hepatic lesions identified in the image by the radiologist, we define I to be the region of pixels contained within the lesion outline, plus a border of healthy tissue around the edge of the lesion. We set the width of this border to 5pixels. We keep this border because it is useful to have some healthy tissue included in the filtered complex for comparison with the lesion tissue.After constructing the simplicial complex K on the image I, we now want to define a filtration on K. A natural approach is to assign a value to each vertex. We can represent this as a functionf:V→R, where V is the vertex set of K. Letfminandfmaxdenote the minimum and maximum values obtained by f on V. We constructKiby including any simplexS∈Kwith the property∀v∈S,f(v)⩽i.(1)Ki=S∈K:∀v∈S,f(v)⩽iIntuitively, f(v) represents the point at which v enters the filtration andmaxv∈Sf(v)determines the point at which a simplexS∈Kenters the filtration. Leti1<i2<…be an increasing sequence of positive values. Then we have the filtered complexKfmin⊆Kfmin+i1⊆Kfmin+i2…⊆Kfmax=K. Notice that if we reverse the inequality in Eq. (1) we get an equally valid filtration,Kfmax⊆Kfmax-i1⊆…⊆Kfmin=K. We will refer to these as the increasing and decreasing filtrations.As each vertex is associated with a pixel in the original image, it is natural to use the pixel intensity (i.e., the grayscale value of each pixel) to assign a value to each vertex. This forms the basis of what we will call the intensity filtration. A toy example of the increasing intensity filtration is shown in Fig. 5a. The colors represent the point in the filtration when the vertices and edges are added (we do not shade triangles for aesthetic reasons).We define an additional filtration by associating the distance from the lesion border, as given by the radiologist, to each pixel. We call this the border filtration. The increasing border filtration produces an ‘annulus’ which grows until it fills the lesion. The decreasing filtration produces a misshapen ‘disc’ which expands from the center of the lesion. While this is clearly not topologically useful for classification, in practice the combination of the border filtration with the intensity filtration gives better classification results than using the intensity filtration alone.To simplify the computational and theoretical difficulties encountered with two-dimensional filtrations, we use one-dimensional filtration slices to approximate the two-dimensional filtrations. This simple sampling method is effective in our application, but the reader interested in a more rigorous treatment of dimensional reductions of multidimensional persistence is referred to [2,3]. LetKibrepresent the border filtration andKjprepresent the pixel intensity filtration. We divide the range of the border-filtration into 20 equally spaced slices. At each slice i, we use the intensity filtration to compute the persistent homology of the subcomplexKib. This gives rise to the filtered complexKifmin=Kib∩Kfminp⊆…⊆Kifmax=Kib∩Kfmaxp=Kib.We can treat each of these one-dimensional barcodes as a different measurement on the lesion. The options of the increasing or decreasing filtration on the border and intensity functions, as well as theβ0andβ1barcodes gives eight barcodes at each slice, yielding a total of 160 barcodes computed on each lesion.To account for differences in the pixel scaling, whether due to image formatting or differing CT scanners, we normalize the pixel range from zero to 1. We stop infinite barcodes at 1.1 so that a differing number of infinite bars does not immediately separate two lesions.To make use of existing machine learning techniques, it is necessary to provide a vector of measurements for each lesion. Using the barcode distance, we can create a vector of relative measurements by computing the matching distance between the barcodes generated on each lesion. In other words, we use the entire set of 132 images as the comparison set to generate a 132×132 square matrix D per barcode. Each entryDijis the distance between the barcode on the lesion i and the corresponding barcode on lesion j. Since we have multiple barcodes for each lesion (160 using the sampled two-dimensional filtration), we compute the distance between all of the corresponding barcodes. This yields many of the square distance matrices mentioned above. We choose to sum all of these matrices to create a single matrix. We can then use the columns of this matrix as feature vectors. We do this even when restricting ourselves to a smaller subset of lesions and simply keep a subset of the same columns (still containing 132 entries). This allows us to obtain information even from the lesion type sets that are too small for classification.This vector can then be used in traditional machine learning algorithms. We choose to use a common implementation of the support vector machine (SVM) called LibSVM to test the classification accuracy on various subsets of the data with the one-dimensional and two-dimensional filtrations [9]. We present the results using a Gaussian kernel (also known as the radial basis function) with the SVM and an explicit definition of this kernel is given in the next section.

@&#CONCLUSIONS@&#
