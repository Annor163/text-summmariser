@&#MAIN-TITLE@&#
Simultaneous analysis of large INTEGRAL/SPI

@&#HIGHLIGHTS@&#
INTEGRAL/SPI X/γ-ray spectrometer data analysis.Large astronomical datasets arising from the simultaneous analysis of years of data.Resolution of a large sparse system of equations; the solution and its variance.The Multifrontal Massively Parallel Solver (MUMPS) to solve the equations.MUMPSA−1feature to compute selected inverse entries (variance of the solution etc.).

@&#KEYPHRASES@&#
Methods: data analysis,Methods: numerical,Techniques: imaging spectroscopy,Techniques: miscellaneous,Gamma-rays: general,

@&#ABSTRACT@&#
Nowadays, analyzing and reducing the ever larger astronomical datasets is becoming a crucial challenge, especially for long cumulated observation times. The INTEGRAL/SPI  X/γ-ray spectrometer is an instrument for which it is essential to process many exposures at the same time in order to increase the low signal-to-noise ratio of the weakest sources. In this context, the conventional methods for data reduction are inefficient and sometimes not feasible at all. Processing several years of data simultaneously requires computing not only the solution of a large system of equations, but also the associated uncertainties. We aim at reducing the computation time and the memory usage. Since the SPI transfer function is sparse, we have used some popular methods for the solution of large sparse linear systems; we briefly review these methods. We use the Multifrontal Massively Parallel Solver (MUMPS) to compute the solution of the system of equations. We also need to compute the variance of the solution, which amounts to computing selected entries of the inverse of the sparse matrix corresponding to our linear system. This can be achieved through one of the latest features of the MUMPS software that has been partly motivated by this work. In this paper we provide a brief presentation of this feature and evaluate its effectiveness on astrophysical problems requiring the processing of large datasets simultaneously, such as the study of the entire emission of the Galaxy. We used these algorithms to solve the large sparse systems arising from SPI data processing and to obtain both their solutions and the associated variances. In conclusion, thanks to these newly developed tools, processing large datasets arising from SPI is now feasible with both a reasonable execution time and a low memory usage.H0=(h11h12h13…h1Nh21h22h23⋱h2Nh31h32h33⋱h3N⋮⋱⋱⋱⋮hM1hM2hM3…hMN)⟼H=(h11000h1200h130h1N…00h2100h22000h23h2N…000h3100h3200h330…h3N⋮⋮⋮⋮⋮⋮⋮⋮⋮⋮⋱⋮000hM100hM20hM30…hMN)

@&#INTRODUCTION@&#
Astronomy is increasingly becoming a computationally intensive field due to the ever larger datasets delivered by observational efforts to map ever larger volumes and provide ever finer details of the Universe. In consequence, conventional methods are often inadequate, requiring the development of new data reduction techniques. The SPI X/γ-ray spectrometer, aboard the INTEGRAL observatory, perfectly illustrates this trend. The telescope is dedicated to the analysis of both point-sources and diffuse emissions, with a high energy resolution (Vedrenne et al., 2003). Its imaging capabilities rely on a coded-mask aperture and a specific observation strategy based on a dithering procedure (Jensen et al., 2003). After several years of operation, it also becomes important to be able to handle simultaneously all the data, in order, for example, to get a global view of the Galaxy emission and to determine the contribution of the various emission components.The sky imaging with SPI is not direct. The standard data analysis consists in adjusting a model of the sky and instrumental background to the data through a chi-square function minimization or a likelihood function maximization. The related system of equations is then solved for the intensities of both sources and background. The corresponding sky images are very incomplete and contain only the intensities of some selected sky sources but not the intensities in all the pixels of the image. Hence, images obtained by processing small subsets of data simultaneously cannot always be combined together (co-added) to produce a single image. Instead, in order to retrieve the low signal-to-noise ratio sources or to map the low surface brightness “diffuse” emissions (Bouchet et al., 2011), one has to process simultaneously several years of data and consequently to solve a system of equations of large dimension. Grouping all the data containing a signal related to a given source of the sky allows to maximize the amount of information on this specific source and to enhance the contrast between the sky and the background.Ideally, the system of equations that connects the data to the sky model (where the unknown parameters are the pixels intensities) should be solved for both source intensities and variability timescales. This problem, along with the description and treatment of sources variability, is the subject of another paper (Bouchet et al., in press).It is mandatory, for example when studying large-scale and weak structures in the sky, to be able to process large amounts of data simultaneously. The spatial (position) and temporal (variability) description of sources leads to the determination of several tens of thousands of parameters, if ∼6 years of SPI data are processed at the same time. Consequently, without any optimization, the systems to be solved can exceed rapidly the capacities of most conventional machines. In this paper we describe a technique for handling such large datasets.

@&#CONCLUSIONS@&#
We have developed algorithms to process years of data and to enhance the production of INTEGRAL hard X/softγ-ray survey catalogs. These methods have been successfully applied to a set of ∼6 years of data (Bouchet et al., 2011). We have shown that, for processing efficiently and accurately years of data, it is critical to use algorithms that take advantage of the sparse structure of the transfer function (matrix), such as those implemented in the MUMPS software.77Available at http://mumps.enseeiht.fr/ or http://graal.ens-lyon.fr/MUMPS/.It was also demonstrated that error bars can be obtained at a relatively inexpensive cost (the same order of magnitude as a simple problem solution) thanks to a recently developed algorithmic feature that efficiently computes selected entries of the inverse of a matrix. In addition, thanks to many efforts in optimization, gains are achieved both in memory usage and in computation time. Hence, it is possible to process large datasets in a reasonable time and to compute the diagonal of the covariance matrix, and thus error bars, in a rather short time. More generally, the ideas described here can be applied to a large variety of problems. Finally, we are today able to solve sparse linear systems with millions, sometimes billions, of unknowns. Although we have not used explicitly parallel computing but instead performed many sequential computations at the same time (for each energy band, etc.), the proposed approach can also be used directly in a parallel setting on massively parallel machines.In the near future, instruments will commonly create datasets of a few tens to a few hundreds of Terabytes for a single observation project. Many of the current tools and techniques for managing large datasets will not scale easily to meet this challenge. Surveys of the sky already require parallel computing in order to be performed. New surveys will demand orders of magnitude increases in the available data and therefore in data processing capabilities. It is also a challenge for scientists who need to extract a maximum of science from the data. Exciting scientific breakthroughs remain to be achieved as astronomers manipulate and explore massive datasets, but they will require advanced computing capabilities, infrastructure and algorithms.