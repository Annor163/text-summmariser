@&#MAIN-TITLE@&#
Statistical 3D face shape estimation from occluding contours

@&#HIGHLIGHTS@&#
A novel 3D face estimation method based on a regression matrix and occluding contours.3D vertices around occluding boundaries and their corresponding 2D pixel projections are highly correlated.The 3D face estimation method resembles dense surface shape recovery from missing data.

@&#KEYPHRASES@&#
Statistical face models,Linear regression,3D shape recovery,

@&#ABSTRACT@&#
This paper addresses the problem of 3D face shape approximation from occluding contours, i.e., the boundaries between the facial region and the background. To this end, a linear regression process that models the relationship between a set of 2D occluding contours and a set of 3D vertices is applied onto the corresponding training sets using Partial Least Squares. The result of this step is a regression matrix which is capable of estimating new 3D face point clouds from the out-of-training 2D Cartesian pixel positions of the selected contours. Our approach benefits from the highly correlated spaces spanned by the 3D vertices around the occluding boundaries of a face and their corresponding 2D pixel projections. As a result, the proposed method resembles dense surface shape recovery from missing data. Our technique is evaluated over four scenarios designed to investigate both the influence of the contours included in the training set and the considered number of contours. Qualitative and quantitative experiments demonstrate that using contours outperform the state of the art on the database used in this article. Even using a limited number of contours provides a useful approximation to the 3D face surface.

@&#INTRODUCTION@&#
Developing techniques for 3D face shape estimation is a subject of special interest in computer vision due to its potential applications in computer graphics and face identification. While the problem is difficult to model through methods based on inverting the image formation process such as geometric [1] and photometric stereo [2], a face consistency constraint may be included in order to enhance results. Usually, this facial consistency is achieved by redefining the problem in terms of a 3D face model prior, which guarantees that the recovered surface lies within the span of the class of human faces. In particular, the idea of constraining 3D face shape recovery using a training set of facial surfaces has attracted the attention of the research community and established itself as a popular approach.Among the different statistical methods for 3D face shape recovery, Principal Component Analysis (PCA) is commonly used as a tool to explain the variations of 3D shape and grayscale values independently [3,4]. However, when separate models are constructed, a fitting strategy has to be performed over the 3D shape and texture parameters of the model in order to deform an initial surface in accordance with the features extracted from one or several input images. The results obtained from these techniques usually deliver accurate approximations, but their success depends on factors such as the distance measure used in the fitting process and the number of features estimated by the method, i.e., 3D structure, texture, pose and illuminations variations. If many factors are included or a complex distance measure is used, the elevated computational time consumed in the 3D face estimation prevents these approaches for being used in realtime applications.Multiple Linear Regression (MLR) methods have been proposed as an alternative to PCA since they are useful to predict 3D face shape from 2D features such as image intensities [5,6]. A review of different MLR techniques was performed in [7] where Partial Least Squares (PLS) was confirmed as the most suitable method for learning shared variations between 3D shape and grayscale images due to its suitability for handling a large number of variables. In the context of the present article, a PLS-based technique is attractive due the possibility of directly estimating a dense 3D mesh from sparse 2D geometrical features obtained from a set of input images. The geometrical information contained in an image of a face can be extracted as separate feature points or as connected components such as edges and contours. Usually, contours refer to the closed boundaries of the face while edges refer to open segments. Edges fall into two categories: inner edges, i.e., the lines contained inside the facial region; and outer edges, which are concerned with the occluding boundaries between the facial area and the background. Binary images represent an alternative representation for contours, as these include not only the boundaries but the whole region of interest of the face. In this work, we will refer to occluding contour as the boundary line depicted between the facial region of the head and the background. Note that the complete shape of the head, i.e., the rear, hair, ears, neck and upper region of the head are not considered in this research in order to focus on the relationship between occluding contours generated only within the facial region.The present work is motivated by the fact that occluding contours represent strong geometrical information attached to both 2D and 3D shape. Being visible as strong edges, occluding contours may be easily estimated from images, representing a meaningful feature for recovering the 3D surface of a face from the video sequence of a rotating camera. Unlike previous MLR approaches exploring the effect of coupling grayscale images and 3D shape, we now focus on studying the effect of 2D features that explain facial shape rather than facial appearance. In this sense, focusing on contours strengthens the relationship between the data used to train our system, leaving aside factors inherently contained in pixel intensities such as texture and illumination variations. While our method does not recover facial appearance as it does not deal with the modeling of pose and illumination parameters, it does provide a simple and straightforward methodology to approximate the shape of a face from a set of occluding edges, having potential applications in computer graphics and identification.This article introduces an MLR-based methodology for estimating 3D face shape information when a set of 2D occluding contours is available from multiple views of a face. Our approach aims to directly estimate the 3D face structure by using a regression matrix built through PLS, where common information between 2D contours and 3D data is retained in the regression process. Modelling this matrix can be achieved using the kernel PLS algorithm, which is computationally efficient and only requires the number of observations (training samples) be the same for the dependent and independent variables. To the best of our knowledge, this article is also the first to investigate the coupling of contours and surfaces, in a linear regression fashion, for modelling shared variations between 2D and 3D geometric features within a statistical shape recovery framework.The paper is organized as follows: Section 2 describes relevant work related to our approach, Section 3 describes the PLS regression, in Section 4 we introduce the methodology proposed in this article and Section 5 presents an analysis of the experimental results. Finally, conclusions and future work are discussed in Section 6.

@&#CONCLUSIONS@&#
This article has introduced a novel methodology for estimating 3D face shape information from a group of contours through a PLS regression matrix. Our approach is based on the idea that occluding contours obtained from multiple image views contain information that is meaningful for a successful prediction of a 3D face mesh. Using contours as 2D training information allows to focus only on geometrical shape variations, leaving aside the modelling of texture and illumination variations. Although this sacrifices modelling appearance, it has potential applications in 3D face modelling, recognition and head pose estimation from video sequences. The major contribution of our MLR based technique is a simple and efficient way for estimating 3D face shape from imagery. For a 1.90 GHz processor with 6 Gb RAM, building the regression matrix takes around 0.7 s while predicting a new example from a set of contours roughly takes 0.01 ms. A limitation of our approach is that either the head or camera poses corresponding to the input images should be estimated in order generate the training samples to build the regression matrix in accordance with the expected inputs. Also, we assume that 2D contours are already available. For this reason, coupling our method with state of the art contour extraction [47] and head pose estimation techniques for video frames [48] is considered as future work. In addition, it is worth to consider using other projections for 2D contours estimation besides orthographic and to combine our direct estimation methodology from contours with texture or shading based data as used in other works.