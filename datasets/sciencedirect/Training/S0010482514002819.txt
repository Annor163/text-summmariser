@&#MAIN-TITLE@&#
Establishing the macular grading grid by means of fovea centre detection using anatomical-based and visual-based features

@&#HIGHLIGHTS@&#
The paper has been reviewed again by an experienced native English speaker.Comments of reviewer 3 have been addressed.Comments of the editor have been addressed.

@&#KEYPHRASES@&#
Retinal diseases,Early diagnosis,Retinal imaging,Establishing macular grading grid,Fovea segmentation,

@&#ABSTRACT@&#
This paper presents a methodology for establishing the macular grading grid in digital retinal images by means of fovea centre detection. To this effect, visual and anatomical feature-based criteria are combined with the aim of exploiting the benefits of both techniques. First, acceptable fovea centre estimation is obtained by using a priori known anatomical features with respect to the optic disc and the vascular tree. Second, a type of morphological processing is employed in an attempt to improve the obtained fovea centre estimation when the fovea is detectable in the image; otherwise, it is declared indistinguishable and the first result is retained. The methodology was tested on the MESSIDOR and DIARETDB1 databases making use of a distance criterion between the obtained and the real fovea centre. Fovea centres in the brackets between the categories Excellent and Fair (fovea centres primarily accepted as valid in the literature) made up for 98.24% and 94.38% of the cases in the MESSIDOR and DIARETDB1, respectively.

@&#INTRODUCTION@&#
Diabetic retinopathy (DR) is a disease of the retina of the eye, derived from complications caused by diabetes mellitus, which is the leading cause of blindness among working age humans in developed countries [1]. The estimated prevalence of diabetes for all age groups worldwide is forecasted to rise from 171 million in 2000 to 366 million in 2030 [2]. Although DR is incurable, laser photocoagulation can prevent major vision loss if the illness is detected in early stages [1], [3]. However, diabetic patients unfortunately do not undergo DR symptoms until visual loss develops, usually in its later stages, when treatment is less effective. In effect to ensure that treatment is received on time, diabetic patients are examined annually by their public health systems [4–6]. Within this context and due to the huge number of patients needing this periodical revision, the use of computer-aided DR diagnosis by means of digital retinal image analysis can improve the effectiveness of the early detection of the illness.The macula plays a key role in assessing DR and other ophthalmic pathology conditions such as age-related macular degeneration or macular edema (ME). Since the macular zone is responsible for sharp central vision, the location of lesions with respect to this influences their clinical relevance. Therefore, successful identification of the macula is of vital importance for the development of systems for the automated diagnosis of DR and other diseases.This paper proposes a new highly reliable methodology for detecting the macula centre and ultimately establishing the macular grading grid. To detect the macula centre, previous studies have usually employed the following approaches: segmentation of the macula centre, or macula centre estimation by means of its a-priori known positional features on the retinal surface. Using the first approach, the macula centre can be obtained more accurately than using the second. However, since the macula centre is not occasionally visible (discussed later) the second approach is more reliable. For these reasons, the work presented in this paper attempts to exploit and combine the benefits of both approaches. The methodology proposes the obtainment of acceptable macula centre location estimation for all cases, and the replacement of this first result with an accurate location when it is safe and possible; this is, when the macula centre is visible.The rest of the paper is structured as follows: characterization of the macula can be found in Section 2. Section 3 reviews the state of art of methods for automated macula centre detection. Section 4 defines the material used in this study. The new methodology is described in Section 5; whereas Section 6 presents the achieved results. Finally, this paper ends with the author’s discussion and conclusion.The macula is a round area in the central region of the retina, which measures about 3 to 4mm in diameter. As commented before, the macula provides the most distinct vision and is responsible for central vision. There is a small depression in the centre of the macula measuring around 1mm in diameter and appears as a round dark area called the fovea. The whole macula is not generally distinguishable in retinal colour images. It exhibits non-specific structure and varies greatly across individuals due to variations in the levels of pigment associated to factors such as ethnicity, age, diet and disease conditions. In spite of this, the fovea is often recognizable as a round region darker than its surrounding retinal tissue (Fig. 1(a)). However, this mark may not be visible due to, for example, the presence of lesions (Fig. 1(b)). Anatomically, the fovea centre is located at 2.5 optic disc (OD) diameters on the average from the OD centre [7]. The fovea location follows the horizontal raphe of the retina, which is a line roughly passing through the OD and the fovea, or more generally separating the superior and inferior regions of the retina determined by the superior and inferior vessels of the vascular tree. This raphe is rotated a few degrees with respect to an imaginary horizontal raster passing through the OD centre. The fovea radius is between one third and one fourth of the macula radius, and the macula radius is approximately equal to one OD diameter [8] (Fig. 2).As the literature points out, two types of criteria for macula segmentation can be clearly recognized. These can be identified as visual and anatomical feature-based criteria. The former criterion includes techniques that attempt to find the macula by exploiting the visual appearance of the fovea. In contrast, the latter criterion involves techniques to obtain an estimation of the fovea centre location making use of its known anatomical features regarding its position on the retinal surface.Sinthanayothin et al. [15] presented a methodology for fovea recognition in which it was assumed to be the darkest area of the fundus image. First, the fovea was correlated to a template of intensities. Then, the location of the maximum response was selected as the location of the fovea as if it was at approximately 2.5 times the diameter of the OD from the OD centre. Gagnon et al. [12] used a similar approach to detect the macula centre. A coarse resolution image was generated in which the darkest pixel was selected. Then, by searching its vicinity for the darkest pixel on the original image, the exact macula centre was found. However, Li and Chutatape [13] combined this approach with the use of the vascular arch to constrain the search area. As a result, a model-based approach was presented in which an active shape model was used to extract the main course of the vasculature based on the location of the OD. This course and the distance criterion of the fovea were used to decide on an area of interest. Finally, the fovea centre was acquired by applying a thresholding scheme to the region of interest. Tobin et al. [10] proposed the automatic location of the fovea using the distance criterion and the vascular arch exclusively. The method started by locating the OD and estimating the vascular arch by using a parabolic model. Based on these two anatomical landmarks, the location of the fovea was ultimately inferred. A similar method for fovea recognition was presented by Fleming et al. [11]. The method found the locations of the OD and the fovea by modelling the major retinal blood vessels. Finally, the position of the fovea was refined based on its local darkening. Then again, Niemeijer et al. [9] proposed a method to model the distribution of all retinal features. The method used an optimization technique to fit a point distribution model to the fundus image. After fitting, the points of the model indicated the location of the normal anatomy. These same authors later presented another paper on fovea detection [14]. First the OD was found and, based on its location, an area of interest for the fovea was determined. Subsequently, after blurring the image, the location was decided as being the pixel with the lowest value within the restricted area. Welfer et al. [16] proposed the fovea centre detection by making use of anatomical knowledge and mathematical morphology. Initially the centre and diameter of the OD were calculated with the aim of extracting a fovea-containing region of interest. Next, a morphological processing was applied with which a set of fovea candidates was obtained. Finally, the fovea centre was selected as being the centroid of the darkest candidate located below an imaginary horizontal line passing through the OD centre. Narasimha-Iyer et al. [17] staged a two-step approach method for locating the fovea centre. Making use of the known distance between the OD and the fovea, a region of interest was extracted and an adaptive threshold was applied to segment the target. A visual-feature based methodology was proposed by Singh et al. [18]. Essentially, a local contrast enhancement was carried out and a dark structure that was identified as the fovea was found. Sagar et al. [19] combined visual and anatomical features to decide on the location of the fovea centre. Primarily, a region of interest in the image was detected using the distance rule between the OD and the fovea. Afterwards blood vessels pixels were masked out in this subimage using morphological operations. Subsequently, the darkest pixels were identified and clustered. The centroid of the largest cluster was selected as being the fovea centre. Sopharak et al. [20] used a similar approach to find the fovea. First, the fovea position was estimated by using the OD diameter and, finally, the high contrast vessels were masked out using morphological processing. Conversely, Sekhar et al. [21] employed morphological processing and thresholding to detect the fovea. Predominantly, the OD centre and its boundary were calculated using morphological processing and the Hough transform. Thenceforth, using the spatial relationship between the OD diameter and the fovea region, a region of interest was extracted. Finally, the fovea centre was attained by applying thresholding and morphological operators. Qureshi et al. [22] proposed the combination of a set of methods for detecting the macula centre. Concretely, the result of all individual methods was calculated to create a map of partial outcomes. Then, the results were weighted according to different principles and combined to decide on the final macula centre. On the other hand, Giachetti et al. [23] made use of the Fast Radial Symmetry transform for fovea-centre detection. Concretely, the centre of symmetry of dark regions was localized applying the transform on vessel-unpainted and coarsened images. Then, they were combined with a vascular density estimator to decide the final result. Gegundez et al. [24] used a-priori known anatomical features to extract a ROI fovea-containing subimage. Subsequently, vessels removal, image smoothing and a multi-thresholding scheme were applied. The fovea centre was finally calculated on a contour map created from the application of the multi-thresholding scheme using gray-level values criteria.The MESSIDOR and DIARETDB1 databases were used for the development and testing of the study presented herein.The MESSIDOR database [25], kindly provided by the MESSIDOR program partners, contains 1200 RGB eye fundus colour images of the posterior pole acquired by the Hôpital Lariboisière Paris, the Faculté de Médecine St. Etienne and the LaTIM—CHU de Brest (France). Eight hundred of these images were captured with pupil dilation (one drop of Tropicamide at 10%) and 400 without dilation using a Topcon TRC NW6 non-mydriatic retinograph with a 45° FOV. The images are 1440×960, 2240×1488 or 2304×1536pixel in size, 8 bits per colour plane and are provided in TIFF format. DR and risk of ME diagnoses were provided by medical experts for each image. Five hundred and forty correspond to healthy patients while 600 images are from patients affected by DR with or without risk of ME.Alternatively, the DIARETDB1 database [26] is composed of 89 RGB colour retinal images of which 84 show DR affection. The images were taken at the Kuopio University Hospital and selected by medical experts. Database’s partners inform that the dataset is biased, so the distribution of cases does not correspond to any “natural” cases distribution. Images were captured using a 50° field-of-view and are 1500×1152pixel in size.

@&#CONCLUSIONS@&#
