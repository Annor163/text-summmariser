@&#MAIN-TITLE@&#
Blind compensation of interchannel sampling frequency mismatch for ad hoc microphone array based on maximum likelihood estimation

@&#HIGHLIGHTS@&#
Modeling of drift as frame shift.STFT-domain compensation as linear phase shift.Probabilistic model of drift.Maximum likelihood estimation of sampling frequency mismatch.Efficient resampling with modified STFT analysis with noninteger frame shift.

@&#KEYPHRASES@&#
Ad hoc microphone array,Drift,Sampling frequency,Maximum likelihood estimation,Blind source separation,

@&#ABSTRACT@&#
In this paper, we propose a novel method for the blind compensation of drift for the asynchronous recording of an ad hoc microphone array. Digital signals simultaneously observed by different recording devices have drift of the time differences between the observation channels because of the sampling frequency mismatch among the devices. On the basis of a model in which the time difference is constant within each short time frame but varies in proportion to the central time of the frame, the effect of the sampling frequency mismatch can be compensated in the short-time Fourier transform (STFT) domain by a linear phase shift. By assuming that the sources are motionless and have stationary amplitudes, the observation is regarded as being stationary when drift does not occur. Thus, we formulate a likelihood to evaluate the stationarity in the STFT domain to evaluate the compensation of drift. The maximum likelihood estimation is obtained effectively by a golden section search. Using the estimated parameters, we compensate the drift by STFT analysis with a noninteger frame shift. The effectiveness of the proposed blind drift compensation method is evaluated in an experiment in which artificial drift is generated.

@&#INTRODUCTION@&#
Microphone array signal processing is a framework for analyzing spatial information of a sound field observed with multiple microphones to perform speech enhancement, source separation, source localization, and so forth, which are difficult by the processing of single-channel observations [1]. Microphone arrays are used in various applications, including teleconferencing, hands-free speech recognition, hearing aids, acoustic monitoring, spatial audio, and computer games. While conventional microphone array signal processing assumes that multichannel signals are observed by a unified analog-to-digital converter (ADC), recently increasing attention has been focused on an extension of the microphone array framework, the so-called ad hoc microphone array, where a combination of observations by independent recording devices is treated as multichannel recording [2]. The non-necessity of wired channels to achieve synchronization enables the downsizing of the recording devices, which is an important attribute for hearing aids [3]. In addition, this framework is suitable for recording meetings because of the easy construction of the microphone array by the combination of widely available portable recording devices, such as cell phones, IC recorders, and video cameras, and the freedom of the microphone arrangement, which enables recording with a high SNR by setting each device close to each speaker [2,4]. Also, considerable effort has been made to develop wireless acoustic sensor networks (WASNs), where the recording devices are connected by wireless networks [5].However, the increased freedom of ad hoc microphone arrays raises various issues that do not arise in conventional array signal processing. For example, the array geometry is unknown [2,6–8], the recording devices have different unknown gains [2], each device starts recording independently [7,8], and the sampling frequencies are not common among the observation channels [9–15]. Also, in WASNs, the efficiencies of communication and distributed computation are important issues to achieve array signal processing with a limited bandwidth and array nodes with low computational power [5].Among these issues of ad hoc microphone arrays, one of the most important is the mismatch of sampling frequencies. Since each ADC is not synchronized with the others, the individual variability of clocks results in a slight mismatch of the sampling frequencies, causing a change in the time difference between channels due to the constant skew, the so-called drift. Array signal processing generally assumes that the sources do not move and utilizes the phase differences inherent to the positions of the sources. However, drift causes the phase differences to constantly change as if the sources are moving, preventing the use of array signal processing to analyze phase differences assuming static sources [10,11]. Also, the asynchronous recording causes offsets of the recording start time. Estimation and compensation of the sampling frequency mismatch and recording start offset are indispensable as preprocesses in array signal processing.While there are two types of methods for estimating the sampling frequency mismatch, i.e., supervised and unsupervised, our research focuses on unsupervised estimation. The former, supervised estimation, mainly estimates the relation between the clock time of the ADC and the absolute time by using the time stamp received from satellites or wireless networks [9,13–15]. While the advantage of this approach is that the recording start offset can be estimated in addition to the sampling frequency mismatch, the disadvantage is the constraint that the recording devices must have the ability to receive the time stamp. Another problem is that the accuracy of the time stamp is generally much lower than that required in array signal processing, and training involving the long observation of time stamps is required for accurate estimation. Unsupervised estimation cannot obtain a precise estimate of the recording start offset without prior information. Inaccurate compensation of the recording start offset is problematic with particular classes of supervised array signal processing which receive time differences of arrival (TDOAs) of positions of specific sources as prior information because the offset changes the relation between the TDOAs and the positions. However, in a blind scenario of array signal processing such as blind source separation (BSS) [16], where only the observation is given, a rough compensation of the recording start offset is sufficient. Therefore, in this paper we focus on the accurate compensation of the drift and the rough compensation of the recording start offset in an unsupervised manner.To the best of our knowledge, there have been few works on the blind estimation of sampling frequency mismatch. Liu et al. proposed a method of estimation involving the iteration of independent component analysis (ICA) and evaluation of the correlation between the estimated independent components by utilizing the property that ICA can extract uncorrelated independent sources only when the drift is well compensated [10]. However, its applicability is limited to determined systems with equal numbers of sources and microphones so that the independent components can be extracted. Markovich-Golan et al. estimated the sampling frequency mismatch as the rate of change of the phase in the interchannel correlation of a noise observation [12]. The modeling of the sampling frequency mismatch using the phase is very similar to our proposed framework, which is discussed later. However, the scenario of this method, which assumes voice activity detection (VAD), is different from our fully blind estimation scenario.In this paper, we propose a novel method for blind drift compensation by maximum likelihood estimation of the sampling frequency mismatch in the short-time Fourier transform (STFT) domain. The basic idea of the maximum likelihood estimation is published in a previous conference proceedings paper [17]. The optimization algorithm is followed by resampling as a modification of the STFT analysis with a noninteger frame shift, which we proposed in another conference proceedings paper [18]. In addition, we newly propose an iterative algorithm for estimating the recording start offset and sampling frequency mismatch, which enables the accurate compensation of drift even with a long observation. We model the drift in the STFT domain as a linear phase by ignoring the drift inside each short time frame. By assuming that the sources are unmoving and have stationary amplitudes, the sound wave to be observed is regarded as stationary regardless of the number of sources. Since the stationarity collapses with the pseudo-movement of the sources caused by drift, the stationarity can be a cue to estimate the drift. Thus, we derive a likelihood function in the STFT domain to measure the stationarity and evaluate the compensation of the sampling frequency mismatch. The maximum likelihood estimate is searched for efficiently by performing a golden section search. We also show that the likelihood function evaluates the coherence between the channels. To compensate the recording start offset, we shift the observed signal in the time domain to maximize the interchannel correlation of the signals with the sampling frequency mismatch compensated. Since the accuracies of the estimation of the offset and the compensations of the drift are mutually dependent, particularly when the observation is long, we iterate these procedures. We evaluate the effectiveness of the proposed method of blind drift compensation in an experiment to emulate the asynchronous recording of an ad hoc microphone array by giving an artificial sampling frequency mismatch.The rest of the paper is organized as follows. In Section 2, we formulate the asynchronous observation of the ad hoc microphone array. In Section 3, we describe our modeling of the drift in the STFT domain. In Section 4, we derive the likelihood function used to estimate the sampling frequency mismatch, carry out an efficient search for the maximum likelihood estimate, and analyze the properties of the likelihood function. In Section 5, we describe STFT analysis with noninteger frame shift for computationally simple resampling. In Section 6, we describe the whole algorithm used in the proposed method of blind drift compensation. In Section 7, we evaluate the effectiveness of the proposed method. Finally, the paper is concluded in Section 8.We suppose that sound pressuresx1(t)andx2(t)on two microphones are sampled by different ADCs, where t denotes the continuous time. The sound pressures are observed as the discretized signals denoted asx1[n]forn=0,…,N1−1andx2[n]forn=0,…,N2−1, where n denote the discrete time, and Nifor i=1, 2 is the number of observed samples of the ith channel, and N1 and N2 are not necessarily the same. Throughout this paper, the notations(·)and[·]are used for denoting continuous and discrete time signals, respectively. Although the signals are available as observation only at the integer-valued discrete times, we accept the noninteger values of the discrete times. We also suppose that the sampling frequency ofx1[n]isfsand that ofx2[n]is(1+ϵ)fsfor a dimensionless number ϵ used to define the sampling frequency mismatch, without loss of generality. In this paper, we assume that the ADCs have common nominal sampling frequencies and that|ϵ|⪯¡1. Note that we focus on the compensation of drift between two channels in this paper, but the extension to an arbitrary number of channels can be carried out easily. The relations betweenxi[n]andxi(t)for i=1,2 are given by(1)x1[n]=x1(nfs),(2)x2[n]=x2(n(1+ϵ)fs+T21),where the origin of the continuous time t=0 is defined as the time when the sampling ofx1[n]starts, and T21 is the continuous time when the sampling ofx2[n]starts. The discrete times of these two channels have independent correspondence to the continuous time as described in (1) and (2), and the phase difference between the channels linearly changes according to the time, hereafter we refer this behavior as drift. Fig. 1shows a conceptual diagram of the asynchronous recording in the case thatx1(t)=x2(t). We denote the pair of discrete times corresponding to the identical continuous time t as n1 for the first channel and n2 for the second channel. Then the discrete time pair n1 and n2 satisfies the following condition:(3)n2=(1+ϵ)(n1−D21),(4)D21=fsT21,where D21 denotes the discrete time of the first channel when the recording of the second channel starts. Note that hereafter we use the notation of the pair n1 and n2 when we consider the correspondence to the identical continuous time.According to the above modeling of the sampling of the asynchronous recording, the discretized signalx^2[n]of the second channel with precise synchronization to the first channel is given as(5)x^2[n]=x2(nfs)=x2[(1+ϵ)(n−D21)].Thus, to achieve the synchronization, we have to obtain the amplitude of the second channel at the noninteger-valued discrete times(1+ϵ)(n−D21), and the problem reduces to resampling. The precise resampling is given by the following infinite convolution of the sinc function:(6)x^2[n]=∑n′=−∞∞sinc((1+ϵ)(n−fsT21)−n′)x2[n′].Since an infinitely long observation is unavailable in practice, the infinite convolution has to be approximated, for example, by a truncated convolution. Additionally, a simplified model is necessary to formulate an effective estimate of the unknown mismatch parameters.Here we discuss the modeling and compensation of the sampling frequency mismatch, which is the basis of the proposed method. Since parameter estimation in array signal processing is generally formulated as statistical optimization in the STFT domain, it is sufficient to compensate for the effect of drift appearing in the STFT domain. Thus, the analysis in the STFT domain is appropriate for the estimation and compensation of drift as a preprocessing step in array signal processing.We define the STFT signalXi(k,m),i=1,2,k=−L/2,…,L/2−1obtained by the frame analysis ofxi[n]centered at the mth sample with a window of length L samples as(7)Xi(k,m)=∑l=0L−1w(l)xi[l+m−L2]exp(−2πjklL),wherew(l)is an appropriate window function, k is the discrete frequency index, andj=−1. We assume that L is even. Note that the discrete Fourier transform is substituted by the fast Fourier transform in practical processing.We discuss the correspondence between n1 and n2 inside the frame centered at sample m in the first channel, i.e.,m−L/2≤n1≤m+L/2−1as shown in Fig. 2. From (3), the following correspondence is obtained:(8)(n2−m)−(n1−m)=ϵm+ϵ(n1−m)−(1+ϵ)D21.Considering that(n1−m)is the time inside the frame, the terms on the right side of (8) have the following properties:•The first termϵmincreases or decreases in proportion to the frame central time m.The second termϵ(n1−m)is proportional to the time inside the frame.The third term(1+ϵ)D21originates from the difference in the recording start times.Let us start from the second term on the right of (8). Suppose that both ϵ and L are small and their product is much smaller than one sampling interval,(9)|ϵL|⪯¡1.Then we obtain the following approximation because−L/2≤n1−m≤L/2−1:(10)(n2−m)−(n1−m)≈ϵm−(1+ϵ)D21,which indicates that the drift inside each frame is sufficiently small to be ignored. In addition, if the frame of the second channel is centered at(11)ϕ21(m)=(1+ϵ)(m−D21),then the frame is synchronous with the frame of the first channel centered at the mth sample because of the correspondence betweenn1=mandn2=ϕ21(m), indicating an identical continuous time.Next, we discuss the third term−(1+ϵ)D21on the right of (8), which is caused by the difference in the recording start times. Although accurate estimation of the difference in the recording start times is difficult, a small error is acceptable for the class of array signal processing without the TDOA prior such as BSS, as described in Section 1. Thus, the satisfactory compensation of the recording start offset with the error much smaller than the frame size is obtained by the time shift with the maximum correlation. We now redefine the discrete time of the second channel so that the recording start offset is compensated asD21≈0, withn2=0corresponding ton1≈0. Then (10) is approximated as(12)(n2−m)−(n1−m)≈ϵm.If, for the central samples m of all the frames, the condition(13)|ϵm|⪯¡Lis satisfied and the shift of the frame is much smaller than the frame size L, the time differenceϵmin (12) can be regarded as a small shift of the whole signal inside each frame. Such a small shift can be compensated by a linear phase in the STFT domain as(14)X^2(k,m;ϵ)=X2(k,m)exp(2πjkϵmL)to obtain the STFT signalX^2(k,m;ϵ)with the sampling frequency mismatch compensated.To obtain the compensation model of (12), we introduced two assumptions in (9) and (13) related to the frame size L. These assumptions contradict each other when the sampling frequency mismatch ϵ is large and the signal lengths N1 and N2 are large, as summarized in the following:1.If L is large, (9) cannot be satisfied and the drift inside each frame becomes too large to ignore.If L is small, (13) cannot be satisfied, and the drift cannot be compensated by a linear phase in the STFT domain as in (14), particularly when the observation is long and|m|takes a large value.The drift inside each frame is unignorable when the sampling frequency mismatch ϵ and the frame length L are large and the condition in (9) cannot be satisfied. As can be seen in Fig. 3, the largest effect of the drift inside the frame appears in both ends of the frame with the error of the discrete time of|ϵL/2|samples. Such that the time error of|ϵL/2|samples corresponds to the error of the phase|πjkϵ|at the discrete frequency k, and the effect of the drift inside the frame is large at high frequencies. The typical quantity of the error is in the order of10μswith the sampling frequency normally in the order of 10−5 and the frame analysis with the length of the order of 0.1s. Note that the effect of the errors is reduced with a typical choice of the window functionw(l)to suppress the amplitude near both ends.In contrast to the condition so that we can ignore the drift inside frames, the condition in (13) to approximate the shift of the signal with the linear phase is that the frame length L is much larger than the signal shift|ϕ21(m)−m|≈|ϵm|. It is hard to satisfy this condition when the observation is long and the sampling frequency mismatch ϵ is large. We show a typical example. Supposing we observe signals of the length 10s with a nominal sampling frequency of 16kHz, andD21≈0. With a sampling frequency mismatch ofϵ=5×10−5and a window length of L=2048, the maximum shift of the signal in the last frame is about 8 samples, which is sufficiently small to be approximated by a linear phase. However, for a longer observation, the time shift becomes closer to the frame length L, and exceeds the frame length in the case of observation for longer than 2560s.To solve the trade-off, we employ the optimization of the STFT analysis with the noninteger frame shift as described in Section 5. With the optimized STFT analysis, we do not need to consider the condition in (13), and the frame length L should be decided considering the condition in (9) and the suitable frame length for the array signal processing.The drift caused by the sampling frequency mismatch causes the TDOAs of each sound source to change slowly with time as if the source is moving. Thus, if the movements of sources are not large, the compensation of the sampling frequency mismatch can be evaluated by considering how static the TDOAs are. Also, by assuming that the sources are stationary, spatial stationarity can be used as a measure of the sampling frequency mismatch. With these assumptions, we derive a likelihood for the sampling frequency mismatch using the compensation model given by (14). Note that in this section we assume that the condition in (13) is satisfied, and the model mismatch is fixed in the algorithm described in Section 6.We assume that all the sources are stationary and that their amplitudes are stationary on a long-term basis. Then the compensated observed signalX^(k,m;ϵ)expressed in vector notation, given by(15)X^(k,m;ϵ)=[X1(k,m),X^2(k,m;ϵ)]T,where{·}Tdenotes matrix transposition, is regarded as a stationary random variable if the sampling frequency mismatch ϵ is estimated accurately. We also assume that the compensated observationX^(k,m;ϵ)with the stationarity recovered by the precise estimation of ϵ has a zero-mean bivariate complex normal distribution for each frequency bin k, whose density of each frequency bin is given by(16)p(X^(k,m;ϵ);V(k))=exp(−X^(k,m;ϵ)HV(k)−1X^(k,m;ϵ))π2detV(k),whereV(k)denotes the covariance matrix. Thus, accurate estimation of ϵ recovers the stationarity ofX^(k,m;ϵ)and maximizes the following log likelihood functionJ(V,ϵ), which evaluates the fit with the zero-mean bivariate normal distribution:(17)J(V,ϵ)=∑k,mlogp(X^(k,m;ϵ);V(k))=∑k,m(−logπ2−logdetV(k)−X^(k,m;ϵ)HV(k)−1X^(k,m;ϵ)),where{·}Hdenotes conjugate transposition. V denotes the group of all covariance matricesV(k)fork=−L/2,…,L/2−1, which can be substituted by the following sample estimate:(18)V(k)←1|∀m|∑mX^(k,m;ϵ)X^(k,m;ϵ)H,where|∀m|denotes the number of frames. By substituting (18) and omitting the constants, a simplified versionJ(ϵ)of the log likelihood functionJ(V,ϵ)is given by(19)J(ϵ)=−∑klogdet∑mX^(k,m;ϵ)X^(k,m;ϵ)H.Note that the sum of the quadratic forms in the last term of (17) is constant with the sample estimate of the covariance matrix given by (18), as(20)∑mX^(k,m;ϵ)HV(k)X^(k,m;ϵ)=∑mX^(k,m;ϵ)H(∑m′X^(k,m′;ϵ)X^(k,m′;ϵ)H|∀m|)−1X^(k,m;ϵ)=2|∀m|.Unfortunately, an estimate of ϵ that maximizes the likelihoodJ(ϵ)cannot be obtained analytically. In addition, as plotted in Fig. 4,J(ϵ)has not only a clear global maximum but also several local maxima. We discuss an effective search method to obtain the global maximum in the following.Since the only parameter to be estimated in the maximization of the likelihood is the sampling frequency mismatch ϵ, the problem reduces to a line search. If we can assume that the log likelihood functionJ(ϵ)is unimodal, efficient optimization can be obtained by performing a golden section search. In the example shown in Fig. 4,J(ϵ)given by (19) is usually locally unimodal around the global maximum. Thus, after specifying the unimodal range including the global maximum, we perform a golden section search.To specify the unimodal range around the maximum, we discretize ϵ roughly and select the discretized value that maximizesJ(ϵ). We generate D uniform samples in the range[−E,E](E>0) and define the discretized values ϵd,d=0,…,D−1as(21)ϵd=−E+2dED−1.Then we compare all the values ofJ(ϵd)and find the optimal index d⁎ that maximizesJ(ϵd)as(22)d⁎=argmaxdJ(ϵd),d=0,…,D−1.The range parameter E can be defined easily by considering the possible range of ϵ. Since the sampling frequency mismatch normally takes a value on the order of 10−5, E can be set to approximately 10−4 or larger. The appropriate choice of D depends on the setting of E and the signal characteristics. At least for the observation of speech, the shape tends to be similar to the example in Fig. 4, and the appropriate value of D should satisfy the condition2E/(D−1)<10−4.After the search of the discretized values to obtain the coarse estimateϵd⁎, the golden section search refines the estimation by narrowing the search range in an iterative manner. We show the algorithm in Table 1. The initial search range is set to[ϵd⁎−1,ϵd⁎+1], and the iteration continues until the range shrinks to the desired resolution ρ(>0). Finally, the estimate ϵ is given as the center of the narrowed search range.Here we discuss the robustness of the evaluation of the log likelihood given by (19) against noise and the mismatch of the Gaussian assumption. Before the discussion of robustness, we simplify the log likelihood function given in (19) by discarding the residual constants. By using the coherenceγ122(k;ϵ)between channels after compensating the sampling frequency mismatch ϵ, defined as(23)γ^122(k;ϵ)=|∑mX1(k,m)⁎X^2(k,m;ϵ)|2(∑m|X1(k,m)|2)(∑m|X^2(k,m;ϵ)|2),the log likelihoodJ(ϵ)is further simplified by separating the constants as follows:(24)J(ϵ)=−∑klog((∑m|X1(k,m)|2)(∑m||X^2(k,m;ϵ)|2)−|∑mX1(k,m)⁎X2(k,m;ϵ)|2)=−∑klog((1−γ^122(k;ϵ))(∑m|X1(k,m)|2)(∑m|X2(k,m)|2))=−∑klog(1−γ^122(k;ϵ))+const.,where{·}⁎denotes the complex conjugate. Note that in (24) we used the equality|X^2(k,m;ϵ)|=|X2(k,m)|, which is trivial from (14).First, we discuss the effect of the non-Gaussianity of the observed signal. The complex amplitudes of the acoustic signal in the STFT domain can be regarded as having zero mean, but it is well known that many sound sources including speech tend to have super-Gaussian complex amplitudes in the STFT domain. As can be seen in (24), only the interchannel coherence is evaluated in the log likelihood functionJ(ϵ), it can be expected that non-Gaussianity does not affect the estimation of the sampling frequency mismatch ϵ so much. We will investigate this by experiments using speech.Next, we discuss the robustness against noise. The estimation of ϵ is possible as long as the amplitudes at the two microphones are correlated because the log likelihood functionJ(ϵ)evaluates only the interchannel coherenceγ122(k;ϵ)by effectively weighting the significant frequency bins. In the frequency bins where only a few unmoving sources are observed, high stationarity is maintained only when drift is compensated properly. Particularly in the frequency where only one source is dominant and the coherenceγ^122(k;ϵ)is close to one, the kth frequency significantly affects the log likelihoodJ(ϵ)with infinitely high value of−log(1−γ^122(k;ϵ)). In contrast,J(ϵ)is not strongly affected by noisy frequency bins with low coherence because of the low value of−log(1−γ^122(k;ϵ))≈0. Therefore, the log likelihoodJ(ϵ)automatically takes only the significant frequency bins into account, and the maximum likelihood function estimation of the sampling frequency mismatch is expected to have high robustness against noise. Fig. 5shows an example of the log likelihood of an asynchronous observation of asynchronous speech mixture used in Fig. 4 with the uncorrelated white Gaussian noise imposed. We can see that the log likelihood functionJ(ϵ)is slightly flattened by the noise but the peak is still clear under this severe condition with the very low SNR of 0dB.Note that we have confirmed that the stationarity can be evaluated satisfactorily usingJ(ϵ)even when there are many sources in the observation. However, the proposed method is weak against the large movement of the sources because the movement degrades the stationarity and causes the time variation of the interchannel correlation.In this section, we describe an efficient resampling method based on modified STFT analysis to estimate the STFT signal with the drift compensated under the condition that the sampling frequency mismatch ϵ and the recording start offset D21 are given. Here we assume that the drift inside each frame can be ignored, as discussed in Section 3.2. This signal estimation procedure is used in both the parameter estimation and the drift compensation as discussed in Section 6. Although it is possible to use various resampling methods to compensate for the drift with the parameters ϵ and D21 given, many of the accurate resampling methods are computationally complex. Our proposed method is a simple modification of STFT analysis and its computational cost is slightly larger than that of the original analysis. Also, the time-domain signal is obtained by inverse STFT (ISTFT) analysis.As we showed in Section 3.2, the drift inside each frame can be ignored under the condition given by (9) that|ϵL|is small, and the drift can be compensated by shifting the frame central time. According to (11), the time of the second channel synchronous with the time m at the center of the frame of the first channel is given byϕ21(m). Thus, we estimate the STFT signalX2(k,ϕ21(m))whose frame center is positioned at the discrete timeϕ21(m).In the beginning, we perform the STFT analysis ofx1[n]as in (7):(25)X1(k,m)=∑l=0L−1w(l)x1[l+m−L2]exp(−2πjklL),with a uniform integer frame shift of R samples, e.g.,m=0,R,2R,…. With such integer values of m, the corresponding frame central timesϕ21(m)of the second channel are generally noninteger-valued. Since the precise estimation of the amplitude at a noninteger discrete time is too complicated as shown in (6), we approximate the frame analysis with the frame center rounded to the nearest integer in the time domain, and compensate the round-off error of the frame center by a linear phase in the STFT domain. The rounded central time is written as⌊ϕ21(m)⌉, where⌊·⌉denotes the rounding operation to the nearest integer, i.e.,(26)⌊ϕ21(m)⌉=argminn|ϕ21(m)−n|,n∈Z.Since the error appears as the delay of(ϕ21(m)−⌊ϕ21(m)⌉)samples, the linear phase compensation givesX2(k,ϕ21(m))as(27)X2(k,ϕ21(m))=∑l=0L−1w(l)x2[l+⌊ϕ21(m)⌉−L2]·exp(2ϕjk(ϕ21(m)−⌊ϕ21(m)⌉)L).Now the obtained STFT signalX2(k,ϕ21(m))is synchronous withX1(k,m), which is analyzed using the frame shift R. Thus, when we need to obtain the time domain signalx^2[n]with the drift compensation, a good approximation is obtained by the ISTFT analysis ofX2(k,ϕ21(m))using the original integer frame shift R.Here we describe an algorithm for blind compensation of the drift combining the maximum likelihood estimation of ϵ and the optimized STFT analysis with the noninteger frame shift. The algorithm iteratively estimates the offset D21 in the time domain and the sampling frequency mismatch ϵ in the STFT domain. Although an error of the estimation of D21 much smaller than the frame length in STFT analysis is accepted in array signal processing without the use of TDOA priors, as described in Section 1, satisfactory estimation cannot be guaranteed under the existence of drift. Also, the unignorable error of D21 degrades the estimation accuracy of ϵ owing to the insufficient STFT analysis. Thus, the estimations of D21 and ϵ are mutually dependent, and the estimation procedures are iterated to resolve the dependence.First we obtain the initial STFT signal with the appropriately compensated offset to evaluate the sampling frequency mismatch in the STFT domain.In this initial frame analysis, we assume that sampling frequency mismatch does not occur, i.e.,(28)ϵ←0.Under this assumption, an integer value of D21 with an acceptable error much smaller than the frame length is obtained to maximize the correlation between channels:(29)D21←argmaxδ∑n=max(0,δ)min(N1,N2+δ)−1x1[n]x2[n−δ],−N2<δ<N1.Note that the error of this estimation of D21 cannot be made sufficiently small when the assumptionϵ≈0in (28) has a large error and the observation length is large. Thus, the estimation of D21 is renewed after the estimation of ϵ in the STFT domain. Using this estimate of D21, we obtain the STFT signalxi′(n), i=1,2 with the redefined discrete time that cancels the offset as(30)x1′[n]←x1[n],(31)x2′[n]←x2[n−D21].Finally, we perform the initial STFT analysis to obtainXi′(k,m), i=1,2 using the uniform frame shift R, e.g.,m=0,R,2R,…, for both channels, as(32)Xi′(k,m)=∑l=0L−1w(l)xi′[l+m−L2]exp(−2πjklL).Here we describe the estimation of the sampling frequency mismatch ϵ. The estimation is given as the update for the estimate of ϵ from the current one. We formulate this problem to obtain a parameterϵ′which updates the estimation of the sampling frequency(1+ϵ)fsas follows:(33)(1+ϵ)fs←(1+ϵ′)(1+ϵ)fs.Although in Section 4 we assumed that the third term−(1+ϵ)D21on the right of (8) is zero, this term should be considered in practical processing even though we do not have accurate estimates of ϵ and D21 here. Since the time-domain signalxi′[n],i=1,2has been given a time shift to maximize the correlation, the gap between the corresponding discrete times|n2−n1|is expected to be minimum around the central sample M of the samples overlapping between the channels, where M is given by(34)M←⌊min(N1−D21,N2)−max(0,D21)−12⌉.Thus, the drift-compensated STFT signalX^′(k,m;ϵ)with the minimal effect of the third term−(1+ϵ)D21in (8) is obtained by a shift of theϵ(m−M)samples toX2′(k,m)as(35)X^2′(k,m;ϵ)=X2′(k,m)exp(2πjkϵ(m−M)L).According to (19), the log likelihood functionJ′(ϵ′)used to evaluate the compensated STFT signalX^2′(k,m;ϵ′)is given as(36)J′(ϵ′)=−∑klogdet∑mX^′(k,m;ϵ′)X^′(k,m;ϵ′)H,(37)X^′(k,m;ϵ′)=[X1′(k,m),X^2′(k,m;ϵ′)]T.The value ofϵ′that maximizesJ′(ϵ′)is estimated by a simple modification of the procedure in Section 4.2, where ϵ is substituted withϵ′andJ(ϵ)is substituted withJ′(ϵ′)in which the current estimate ϵ is treated as a constant.Finally after the estimation ofϵ′by the golden section search, we update ϵ usingϵ′as(38)ϵ←(1+ϵ)(1+ϵ′)−1,which gives the update of the estimated sampling frequency(1+ϵ)fsin (33).Now we describe the update of the estimation of the offset D21. First, we obtain an estimate of the drift-compensated time-domain signalx^2[n]by the procedure in Section 5 with the substitution of the estimated ϵ and the assumptionD21=0. Then the offset D21 is estimated by maximizing the correlation betweenx1[n]andx^2[n]:(39)D21←argmaxδ∑n=max(0,δ)min(N1,N2+δ)−1x1[n]x^2[n−δ],−N2<δ<N1.Finally, we estimate the drift-compensated STFT signalX2(m,ϕ21(m))by substituting the estimated parameters ϵ and D21 again into the procedure in Section 5.The estimation procedure for ϵ in Section 6.2 and that for D21 in Section 6.3 are conducted separately. However, the estimates of these parameters are mutually dependent and the error of one parameter propagates to the other. In particular, when the observation is long and ϵ is large, the initial STFT analysis with the assumptionϵ=0is strongly affected by the mismatch of the assumption in (12) and degrades the estimation accuracy of ϵ in Section 6.2; thus, the estimation accuracy of D21 in Section 6.3 is also subsequently degraded. To achieve accurate parameter estimation in such a long observation, we propose the iteration of these procedures to reduce the propagation of the error in each stage to the next stage.Table 2summarizes the iterative optimization algorithm. After the processing described in Sections 6.1–6.3, we return to the procedure in Section 6.2 after the following update of the STFT signal in the second channelX2′(k,m)for the update of ϵ:(40)X2′(k,m)←X2(k,ϕ21(m)).The procedures in Sections 6.2 and 6.3 after the update given by (40) are repeated until the iteration reaches the maximum number of iterations. The iterative algorithm is summarized in Table 2. Note that such iteration is required only for particularly long observations such as those for 10min.In this section we evaluate the effectiveness of the proposed method of blind drift compensation. First, we evaluate the estimation accuracy of the sampling frequency mismatch by the proposed method. Second, we evaluate the performance of BSS with the drift compensation to assess the suitability of the proposed drift compensation as a preprocessing step in array signal processing.The observed signals are two-channel recordings of two-speaker mixtures made by the convolution of measured impulse responses and speech signals. The speech signals are made by the concatenation of word utterances chosen from the utterances in the ATR Japanese speech database [19]. We evaluated all 12 combinations of two speakers selected from two male and two female speakers. The original sampling frequency of the observation was 16,000kHz, and we modified the sampling frequency of one channel by ±0.5, ±1, and ±1.5Hz. These modifications correspond to sampling frequency mismatches of ±31.25, ±62.5, and ±93.75ppm (parts per minute, 10−6), respectively, which are realistic values for the practical bias of clock generators in real ADCs. To generate an artificial sampling frequency mismatch, we performed resampling with a polyphase filter, which is implemented as a standard command in MATLAB. We used auxiliary-function-based independent vector analysis [20] to conduct two-channel BSS of the two speakers. The placements of microphones and speakers are shown in Fig. 6. The sources are placed 1.5m apart from the middle of the two microphones. We evaluated two different source positions, and the combinations of the horizontal angles of the two sources are [−50°, 30°] and [−60°, −10°]. Other conditions are listed in Table 3.Fig. 7shows the root mean squared errors (RMSEs) of the estimates of the sampling frequency mismatches for different signal lengths. We plotted the results of one and two iterations of the iterative estimation algorithm described in Section 6.4. We can see that the proposed estimation algorithm works appropriately even with short observed signals, and the accuracy improves with increasing length of the observed signals. Also we can see that the iterative procedure performs better when the observation is long, and the improved performance becomes clear for observations longer than 120s. Thus, we confirmed that the estimation algorithm without iteration is satisfactory for short observations, but the iterative estimation algorithm is effective in the case of long observations.We analyzed the behavior of the proposed method of sampling frequency mismatch estimation to evaluate robustness. First, to evaluate the effect of the non-Gaussianity of the observed signal, we analyzed the kurtosis, which is a popular measure of Gaussianity. The kurtosis of complex variables [21] was evaluated in each frequency bin for each observation of 30min, and the results were averaged over all the observations. Note that for the stability of estimation, the fourth-order moments were not obtained from the sample average but from the parameters of the gamma distributions fitted to the absolute squared amplitudes by using maximum likelihood estimators. The estimated kurtosis is shown in Fig. 8. The kurtosis of complex variables with a complex normal distribution is zero, and the kurtosis is larger than one when the variables are super-Gaussian. Fig. 8 shows that in most of the frequency bins the kurtosis is highly super-Gaussian, which is a characteristic of speech. Since accurate estimation was obtained for the super-Gaussian observation, it is confirmed that the non-Gaussianity of the observation does not affect the estimation.To evaluate the robustness against noise, we superimposed uncorrelated white Gaussian noise on the observation and evaluated the RMSEs of the sampling frequency mismatch estimation. We compared the accuracy with a clean observation and noisy observations with SNRs of 20, 10, and 0dB. The result is shown in Fig. 9. The RMSE increases with increasing noise, but the RMSE is only several times larger under a severe condition with an SNR of 0dB than that for the clean observation. Therefore, it is confirmed that the proposed maximum likelihood estimation method is robust against noise as discussed in Section 4.3.Since the proposed maximum likelihood estimation method assumes that the sources do not move so that the stationarity of the observation is maintained, the movement of sources degrades the estimation performance. To evaluate the effect of the movement of the sources, we changed the positions of the speakers from the directions [−50°, 30°] to [−60°, −10°] in the middle of the observation. Fig. 10shows the RMSEs of the sampling frequency mismatch estimation when the speakers changed the positions. Although the estimation does not fail under this condition, the RMSEs increased approximately ten-fold. Thus, the proposed maximum likelihood estimation is weak against position shifts of the sources because of the degradation of stationarity.To assess the contribution of the proposed method of drift compensation to BSS, we evaluated the source separation performance in terms of the signal-to-distortion ratio (SDR) [22] at the first microphone as shown in Fig. 11. The SDRs were averaged for the two sources. We evaluated the following conditions:•Synchronous: BSS without artificial sampling frequency mismatch to obtain an upper limit for this task.Unprocessed: BSS without compensation of the asynchronous recording.STFT-based resampling with true parameters (STFT): BSS of the STFT-based resampling with the true value of ϵ given and D21 estimated by the procedure in Section 6.3.Maximum likelihood linear phase compensation (ML): BSS of the STFT signal obtained by the procedure in Section 4.2 without STFT-based resampling.Without offset reestimation (WO): BSS of the STFT-based resampling without the reestimation of D21 obtained by the procedure in Section 6.3.Proposed: BSS of STFT-based resampling with drift compensation by the procedures in Section 6 without iteration of the procedures. The number of iterations in Section 6.4 was two.Fig. 11 shows a comparison of the BSS performances. Since the SDRs of the unprocessed signal are very low, we can see that BSS is difficult without drift compensation under these conditions. The SDRs in the case of resampling with the true parameters are only 1dB lower than those in the case of synchronous recording. Thus, we can conclude that the error of the signal expression in the STFT-based resampling is insignificant in array signal processing. The degradation in the SDRs of the maximum likelihood linear phase compensation is considerable for observations longer than 20s compared with the other methods. Thus, resampling is essential and the proposed STFT-based resampling is satisfactory. The degradation in the SDRs of the BSS without offset reestimation is also considerable for observations longer than 30s, but the proposed method does not exhibit such degradation. Thus, the effectiveness of the reestimation procedure for the offset described in Section 6.3 is confirmed. The SDRs of the proposed method exhibit insignificant degradation compared with STFT-based resampling with the true parameters, and the degradation from the synchronous recording was only about 1dB. Thus, it is confirmed that the parameter estimation is sufficiently accurate. Therefore, the validity of the proposed compensation algorithm is verified, and its suitability for array signal processing as a process is also confirmed.

@&#CONCLUSIONS@&#
