@&#MAIN-TITLE@&#
Development of expert systems for the prediction of scour depth under live-bed conditions at river confluences: Application of different types of ANNs and the M5P model tree

@&#HIGHLIGHTS@&#
This paper presents expert systems for predicting the maximum scour depth (SD).The methodology is applied to river confluences under live-bed condition.In this paper, MLP, RBF and M5P models are developed and compared to each other.Results show that the MLP model can outperform other expert systems.MLP and RBF are the most accurate models in the low and high SD, respectively.

@&#KEYPHRASES@&#
River confluences,Maximum scour depth,Live-bed conditions,Multi-layer perceptron (MLP),Radial basis function (RBF),M5P model tree,

@&#ABSTRACT@&#
The three-dimensional structure of water flow at river confluences makes these zones of particular importance in the fields of river engineering, fluvial geomorphology, sedimentology and navigation. While previous research has concentrated on the effects of hydraulic and geometric parameters on the scour patterns at river confluences, there remains a lack of expert systems designed to predict the maximum scour depth (dsm). In the present study, several soft computing models, namely multi-layer perceptron (MLP), radial basis function (RBF) and M5P model tree, were used to predict the dsmat river confluences under live-bed conditions. Model performance, assessed through a number of statistical indices (RMSE, MAE, MARE and R2), showed that while all three models could provide acceptable predictions of dsmunder live-bed conditions, the MLP model was the most accurate. By testing the models at three different ranges of scour depths, we determined that while the MLP model was the most accurate model in the low scour depth range, the RBF model was more accurate in the higher range of scour depths.adaptive neuro-fuzzy inference systemartificial neural networkdepth of flow downstream from confluence (m)scour depth (m)maximum scour depth (m)maximum scour depth ratio (=dsm/wd)median size of river bed material (m)densimetric Froude numberfeed-forward back propagation networkgravitational acceleration (ms−2)specific gravitymean absolute errormean absolute relative errormulti-layer perceptron, a type of ANN.a tree type modelis the number of observations in the measured or predicted data setthe ith observed valuethe ith model-predicted valuenumber of observation data inputs in RBF modellive-bed discharge (≡ sediment load) (m3s−1)water discharge in channel downstream from confluence (m3s−1)water discharge in main channel upstream of confluence (m3s−1)water discharge of the tributary upstream of confluence (m3s−1)ratio of live bed sediment discharge to discharge in channel downstream from confluenceratio of tributary discharge to main branch dischargelinear correlation coefficient between measured and estimated dsmReynolds numberradial basis function, a type of ANNroot mean square errorchannel bed slopeset of examples in a model treecenter of the jth radial basis function f in a RBF functionriver flow velocity (ms−1)river flow velocity downstream from confluence (ms−1)width of channel downstream from confluence (m)is the weight of the connection between the jth neuron in a layer with the ith neuron in the previous layer of an ANNwidth of main channel upstream of confluence (m)is the weight of the connection between the hidden and output nodes in a RBF networkwidth of tributary channel upstream of confluence (m)ratio of tributary channel width to channel width below the confluenceWeber numberis the value of the ith neuron in the previous layer of an ANNis the output from the jth neuron in a given layer of an ANNbed elevation difference (m)the network output in RBF modelflow viscosity (kgm−1s−1)density of sediment (kgm−3)tributary-main branch confluence angle (°)force of surface tension (kgs−2)the size of the radius around the RBF center (Uj)the standard deviation of the reduction in M5P model tree

@&#INTRODUCTION@&#
River confluences, the regions where two rivers merge, are important parts of river systems. The mixing of two water flows at such sites results in three-dimensional flow patterns and deep scour holes. These, in turn, can cause changes in river morphology and accelerate the rate of bank erosion. According to Best [1], six distinct zones exist at river confluences, namely stagnation, flow deflection, separation, maximum velocity, flow recovery and shear layer zones (Fig. 1). The flow separation zone, located near the left river bank just downstream of the river confluence is the main cause of a horizontal vortex in this region that leads to the deposition of sediment at the center of the zone and generates a point bar. The zone of maximum flow velocity can accelerate erosion and bank failure on the right river bank and lead to the development of a meander. The flow vortex and high flow velocity in this zone can also create problems for navigation. Because of these practical applications, the study of flow pattern, scour and sedimentation at river confluences has attracted the attention of many researchers.Despite extensive investigations of flow characteristics at river confluences at both the two-dimensional [2–8] and three dimensional level [9–14], few experimental studies have investigated sediment transport and scour at river confluences [15–23]. Mosley [15] conducted experimental tests for Y-shaped river confluences in a small flume, and showed that the dimensions of the scour hole increased rapidly as the river confluence angle (θ) increased from 15° to 75°, but then declined at values of θ. Roy and Roy [16] conducted field measurements on 30 river confluences, and found that, at all locations, the flow area cross-section downstream of the river confluence generally decreased as flow velocity (vf) increased. At the scour hole the vfwas found to reach up to 1.6-fold that of the upstream flow. Biron et al. [17,18] studied bed morphology at the confluences of rivers of unequal depth and showed that, even if river bed morphology changed, scour hole dimensions remain constant. They also found that river morphology at confluences of unequal channel depth differed from that at confluences of equal channel depth. Similarly, Shafai Bejestan and Hemmati [19] showed reduced scour for a discordant bed confluence than a level bed confluence. Using a 90° junction pilot model, Borghei and Nazari [20] showed scour depth (ds) increased with a rise in the ratio of tributary discharge to that in the channel downstream of the confluence (Qtd=Qt/Qd), but decreased with increases in sediment particle size and relative tributary to width of the channel downstream from the confluence(wtd=wt/wd). Ghobadian and Shafai Bejestan [21] showed that (Qtd) was the most important parameter in river confluence studies. Based on their finding that as Qtd, θ, and the densimetric Froude number (Fd) increased, so did ds, they developed a mathematical relation for the prediction of dsat river confluences. Borghei and Jabbari Sahebari [22] studied the scour patterns at the junction of two loose-bed channels under clear-water conditions and showed that the position of dsmtemporally moved to the outer wall and upstream to the main channel, according to the values of θ, wtd, Qtdand the ratio of mean downstream velocity to threshold velocity.Despite the existing body of literature concerning flow patterns and river morphology at river confluences, knowledge regarding local scour under live-bed conditions is more limited. To address this knowledge gap, Balouchi and Shafai Bajestan [23] conducted experiments to determine the effects of the Qtd, Fd, and sediment load (live-bed discharge, Qb) on the dsmat river confluences under live-bed conditions. They found that the quantity of bed load could reduce the dsmup to 35%. Moreover, they found that bed scour and sedimentation patterns under live-bed conditions differed from those which occurred with clear water, particularly with respect to the absence of a point bar in the region of river confluence in the latter case. The authors [23] also presented a regression equation for the prediction of the dsunder live-bed conditions, and, through sensitivity analyses, showed that this equation was most sensitive to Fd.Having drawn considerable attention given their effectiveness at representing complex and nonlinear relationships, artificial intelligence methods such as artificial neural networks (ANN) and adaptive neuro-fuzzy inference system (ANFIS) have been extensively used in the prediction of dsand sedimentation (Table 1) [24–32].In spite of the importance of predicting the dsmat river confluences, there has not yet been, to the best of the authors’ knowledge, any study evaluating the use of intelligent system methods for estimating dsmat river confluences. To address this omission, data-driven simulation models based on data from experimental results were developed for the prediction of dsmat river confluences under live-bed conditions. The multi-layer perceptron (MLP) [24,25,27,33,34] and the radial basis function (RBF) [25,31], both ANN models, as well as the M5P tree model [35–38] have shown a strong performance in accurately predicting complex system responses in the engineering field. As a result, the present study used these three soft computing models to predict dsmat river confluences under live-bed conditions and evaluated and compared their performance on validation data sets of experimentally determined channel confluence scour depths.Two real-life scenarios were investigated in the present study: (i) a river/canal confluence, where the hydraulic conditions of the confluence have changed, e.g., water levels, bed load, and/or discharges of either branch changed due to human and/or natural events, and (ii) a river/canal branch into which another river/canal is newly diverted, e.g. in constructing a dam, or adding a flood bypass canal to prevent flood damage to a residential or historic area.Since under both scenarios dsmat the river confluence will be altered, it is necessary and important to accurately predict dsm. This ability to predict dsmis also of great practical interest in the fields of river engineering, fluvial geomorphology, sedimentology, navigation and hydraulic structures (e.g., setup of a pump station, construction of a bridge pier at river confluences). Given the complexity of flow and scour patterns at river confluences, accurate prediction of dsfor general scenarios can be facilitated by applying an expert system to the existing experimental or field data. However, expert systems for the estimation of dsmat river confluences are generally lacking. In this paper, several experimental data-driven models are proposed for the prediction of dsmat river confluences. The datasets used in the models are based on experimental input-output data of scour depth at channel confluences from Balouchi and Shafai Bajestan [23]. The Qtd, sediment (live-bed) load ratio (Qbd=Qb/Qd) and densimetric Froude number (Fd) were identified through dimensional analysis as appropriate inputs for the artificial intelligence models, while the maximum scour depth ratio(dsm*=dsm/wd)was used as the output variable.The experimental process began by gathering data from a physical model of river confluences under live-bed conditions and using dimensional analysis to identify the most important input variables (Fig. 2). Next, three data-driven simulation models (i.e., the RBF and MLP neural networks and the M5P model tree) were generated and trained based on experimental input-output data. Their relative performance was then evaluated through the use of a validation data set from the same experimental setup. These three main steps of the methodology are explained in greater detail in the following sections.Many parameters can affect the maximum dsat river confluences under live-bed conditions. In order to identify the most important non-dimensional parameters for the prediction of the dsm, the authors had previously carried out a dimensional analysis [23]. This analysis showed that the maximum scour depth (dsm), total channel flow and width downstream of the confluence (Qdand wd, respectively), flow in the main and lateral or tributary channels upstream of the confluence (Qmand Qt, respectively), width of the main and lateral or tributary channels (wmand wt, respectively), angle of river confluence (θ), channel bed slope (S0), water flow velocity and depth downstream of the confluence (vfdand dd, respectively), median size of river bed material (d50), bed elevation difference (ΔZ) and live-bed (sediment) load (Qb) were the parameters of greatest impact on the sedimentation pattern at river confluences under live-bed conditions:(1)fdsm,d50,ρs,Qb,Qt,Qm,Qd,dd,wt,wm,wd,S0,θ,σ,μ,g,ΔZ=0where, μ and ρsare the flow viscosity and density of sediment particles, respectively; g and σ denote the gravitational acceleration and the surface tension force, respectively. Based on the Buckingham theory [39], equation 1 can be rewritten in the following non-dimensional form:(2)dswd=fQtQd,QbQd,wmwt,wdd50,ddd50,θ,S0,ρsρ,We,ΔZwt,Fd,Rewhere, Re is Reynolds number, Weis the Weber number, and Fdis the densimetric Froude number:(3)Fd=vfdgGs−1d50where Gsdenotes the specific gravity.As in the previous study by Balouchi and Shafai Bajestan [23], wm, wtand wdwere kept constant, as were ΔZ and θ (zero and 60°, respectively) in this study. Given that Gurram et al. [3] showed that bed slope (S0) has no significant effect on flow pattern under subcritical conditions, that for high Re values and rough boundaries the Re had no effect on flow pattern, and that the dimensions of the flumes were large enough that the Weber number could be ignored, Eq. (2) could be reduced to:(4)dswd=f2QtQd,QbQd,Fdordsm*=f2Qtd,Qbd,Fdwheredsm*, Qtd, and Qbdare the maximum score depth ratio, the flow ratio and the sediment (live-bed) load ratio, respectively.The experimental setup used by Balouchi and Shafai Bajestan [23] consisted of a main (9m length, 25cm width, 60cm depth) and lateral flume (3m length, 25cm width, 60cm depth), both covered with a fine sand sediment (d50=0.6mm). Water flow was measured with an electronic flow meter precise to the nearest 0.01Ls−1. A general schematic of the experimental setup is shown in Fig. 3.To simulate live-bed conditions, specific ranges for the Qtd, Qbdand Fdwere tested (Table 2).To investigate the dsmunder various hydraulic conditions at river confluences, 38 experimental tests (with different flow ratios, live-bed load ratios and densimetric Froude numbers) were conducted. Fig. 4shows an example of the sedimentation topography pattern in the main flume at Fd=8.22, Qtd=0.2 and Qbd=0, plotted using Surfer® software.The results of these experimental tests served to develop the three soft computing models (MLP, RBF and M5P) to determine the dsmat river confluences under live-bed conditions. These three soft computing models were developed and coded using MATLAB® software. The data was divided into training and validation data sets (70% and 30%, respectively), and the accuracy of the maximum scour depth predictions obtained using each of the models were compared. More details on applications of MLP, RBF and M5P models can be found elsewhere [34–38,40–53].Artificial neural networks (ANN) are mathematical models which were originally developed to mimic human brain neural systems and are generally used to predict the value of an output vector based on known values in an input vector, especially where the relationships between the two are complex or non-linear [34]. A typical configuration for a multi-layer perceptron (MLP) model, a special class of ANN, is shown in Fig. 5. In an MLP network, a set of data (x1; x2; …) is first fed into the network through the input layer, subsequently passes through one or more hidden layers, and is finally outputted as the predicted output y in the output layer [25]. The number of hidden layers determines the complexity of the network, as a greater number of hidden layers increases the number of connections in the ANN.In an MLP, neurons receive inputs from their upstream interconnections and generate outputs by the transformation of these inputs with an appropriate nonlinear transfer function [33]. In the case of the sigmoid transfer function, for example, the output yjfrom the jth neuron in a layer is determined by the function:(5)yj=f∑i=1i=nwijxi=1−e−∑i=1i=nwijxi−1where, wijis the weight of the connection joining the jth neuron in a layer with the ith neuron in the previous layer and xiis the value of the ith neuron in the previous layer.Training of neural networks includes a learning process during which input and known output data are provided to the model and the values of the many wijare adjusted to optimize the accuracy of the model output. The ANN model training process was continued until the error index (e.g., the sum of squared errors) dropped below a pre-determined value or until the number of training epochs exceeded a specific value. After successful training, the model was tested with a validation data set and the accuracy of the model's prediction performance was evaluated by comparing the model output with observed values [27].In this study, a three-layer feed-forward back propagation network (FFBPN) with six neurons in the hidden layer was used for the MLP network. The optimum number of neurons in the hidden layer was determined through trial and error by comparing the accuracy of models with different numbers of hidden layer neurons using the statistical indices of mean absolute relative error (MARE) and regression coefficient (R2). For each neuron number, a loop was developed to consider the effect of random initial weights and biases. A hyperbolic tangent sigmoid function and a linear function were used as the transfer functions in the second and third layers, respectively, and the Levenberg–Marquardt optimization method was used for network training.Always having three neuron layers (e.g., input, hidden and output), RBF networks are a type of ANN which restricts the inputs taken into account by each node to values within a certain “radius” of a central value. Their general structure is illustrated in Fig. 6. The number of neurons in the hidden layer was set to the number of observation data inputs (p), and a Gaussian function was used as the transfer function for this layer. The output of the jth hidden node (yj) was calculated as [25]:(6)yj=fX−Uj2σj2where*and Ujare the Euclidian norm and center of the jth radial basis function f, respectively, while σjrepresents the size of the radius around the RBF center of the jth hidden node (Uj) within which the value of the Gaussian function will differ significantly from zero (i.e., the model will take the input into account) [25]. Thus the Gaussian RBF center of the jth hidden node can be specified by the mean Ujand the standard deviation σj.The network output (zm) is calculated through a linear weighted summation of the outputs of each node in the hidden layer:(7)zm=f(X)=∑j=1j=pyjwmjwhere wmjis the weight of the connection between the hidden and output nodes.Training the RBF models includes two stages: (i) determining the basis functions of the hidden layer nodes and (ii) determining the weights of the connections to the output layer. The former involves finding optimal values of Ujand σj. The optimal values for the spread (σj=10), mean, and number of neurons (16) were determined by trial and error (in the same manner as for the MLP model). A Gaussian transfer function was utilized. A more detailed description of RBF models and their applications can be found elsewhere [31,45,46,48].A decision tree is a tree in which each branch node represents a choice between a number of alternatives and each leaf node represents a classification or decision [36]. M5P model trees split the input progressively. The set T of examples is either associated with a leaf, or some test is chosen that splits T into subsets corresponding to the test outcomes [37]. The same process is applied recursively to the subsets [38]. Splits are based on minimizing the intra-subset variation in the output values down each branch. In each node, the standard deviation of the output values for the examples reaching a node is taken as a measure of the error of this node and calculating the expected reduction in error as a result of testing each attribute and all possible split values. The attribute that maximizes the expected error reduction is chosen. The standard deviation of the reduction (σred) is calculated as [35]:(8)σred=σ(T)−∑i=1i=nσ(Ti)⋅TiTwhere T is the set of examples that reach the node and T1, T2, …, Tnare the sets that result from splitting the node according to the chosen attribute (in the case of multiple split). Splitting in M5P ceases when the class values of all the examples that reach a node only vary slightly, or only a few examples remain [35]. This very active division process often produces overly elaborate structures that must be pruned back, for example, by replacing a sub-tree with a leaf. In the final stage, a smoothing process is performed to compensate for the sharp discontinuities that will inevitably occur between adjacent linear models at the leaves of the pruned tree, particularly for some models constructed from a smaller number of training examples. In the smoothing process, the adjacent linear equations are adjusted in such a way that the estimated outputs for similar input vectors that correspond to different equations remain close nonetheless. It should be noted that based on its algorithm the M5P model in the present study formed only one branch. More details about the M5P model and its applications can be found elsewhere [43,44].The validation data set was divided into three different ranges ofdsm*(0≤dsm*<0.24,0.24≤dsm*<0.34, and0.34≤dsm*<0.44), and the performance of the models was analyzed separately for each data subset. The accuracy of the three models’ predictions were analyzed using several standard statistical measures, including the mean absolute relative error (MARE), root mean square error (RMSE), mean absolute error (MAE) and the linear correlation coefficient between measured and predicted values (R2) (Eqs. (9)–(11)):(9)RMSE=1n∑i=1i=n(Oi−Pi)2(10)MAE=1n∑i=1i=nOi−Pi(11)MARE=100n∑i=1i=nOi−PiPiwhere n is the number of observations in the data set and Oiand Piare, respectively, the ith observed and predicted values of dsm.

@&#CONCLUSIONS@&#
