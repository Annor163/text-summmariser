@&#MAIN-TITLE@&#
Echocardiography noise reduction using sparse representation

@&#HIGHLIGHTS@&#
Noise reduction in echocardiography images is proposed.Filtering framework is based on temporal information and sparse representation.Proposed method consists of smoothing intensity variation time curves assessed in each pixel.A smooth version of signal can be reconstructed by using a proper sparse recovery which is followed by an adaptive thresholding method to locate the most important atoms.After a comprehensive comparison of sparse recovery algorithms, three were selected for our method: Bayesian Compressive Sensing (BCS), Bregman Iterative algorithm, and Orthogonal Matching Pursuit (OMP).The proposed method preserves the edges and rapidly moving structures.

@&#KEYPHRASES@&#
Echocardiographic images,Noise reduction,Temporal information,Sparse representation,Adaptive thresholding,

@&#ABSTRACT@&#
Graphical abstractImage, graphical abstract

@&#INTRODUCTION@&#
The presence of speckle noise in ultrasound images frequently limits their contrast, adversely affecting both human interpretation and computer-assisted analysis, including edge detection, segmentation, tracking and registration [1]. Researchers have developed various methods to filter out speckle noise. However, these methods have several crucial limitations. The primary limitations of all existing filters are that they do not use the temporal information in echocardiography sequences and use only single images or sets of a few images. These limitations both decrease the efficiency of the filter and negatively impact on image results, causing the blurring of rapidly moving structures and object edges.In a previous publication [2], we demonstrated how the temporal information in echocardiographs can be analysed as intensity variation time curves (IVTCs) and the speckle can be interpreted as high-frequency variations added to the IVTCs. In this paper, we introduce a new method that utilizes sparse representation of IVTCs to filter speckle noise adaptively.In recent years, sparse representation has attracted growing interest in the field of signal and image processing [3]. Many signals, including IVTCs, are sparse—that is, they contain many coefficients close to or equal to zero in a specific domain. The goal of sparse signal representation is to transform the signal into a new domain using a dictionary of functions (called atoms) which efficiently reconstruct the signal with a linear combination of a few of the dictionary atoms. Two methods based on dictionary learning approaches have already been proposed for the de-speckling of ultrasound and SAR images [4,5]. However, these methods do not apply to temporal information.This paper demonstrates the application of sparse representation to IVTCs. Adding the constraint of sparsity allows IVTC reconstruction by only a small number of non-zero coefficients or a sparse number of atoms in the dictionary. A smooth version of the signal can be reconstructed using a proper sparse recovery method which is followed by adaptive thresholding to locate the most important atoms. After a comprehensive comparison of sparse recovery algorithms, three were selected for our method: Bayesian Compressive Sensing (BCS) [6], the Bregman Iterative algorithm [7], and Orthogonal Matching Pursuit (OMP) [8].The schematic in Fig. 1is a stepwise portrayal of the method. In the first step, the IVTC signals are extracted by assessing the pixels of sequential echocardiography images. In the second step, prior knowledge of the original IVTC signals is used to select appropriate functions to build an over-complete dictionary. In the third step, a sparse number of atoms from this dictionary are used to represent the signals (i.e. sparse recovery). In the fourth step, an adaptive threshold is set to reconstruct a smooth version of the original signal with reduced speckle noise.In Section 2, we will review currently available filtering methods and outline their limitations. We will then summarize the use of IVTCs and detail the compilation of an over-complete dictionary of functions via the application of sparse representation. In Section 3, we outline the use of this dictionary to choose an appropriate sparse recovery algorithm via a comprehensive comparison. We will demonstrate how a smooth version of the signal can be reconstructed with an adaptive threshold chosen to filter the results by preserving the most significant coefficients and eliminating the near-zero coefficients. In Section 4, we compare the performance of the proposed filter against that of some currently available filters by applying objective image quality metrics. We present our conclusions in Section 5.The development of an accurate speckle noise model is an essential step towards achieving an efficient de-speckle filter design. There are two noise models that can be considered, depending on whether the envelope signal is captured before or after logarithmic compression. The multiplicative noise model pertains to signals obtained before logarithmic compression. The additive noise model pertains to signals obtained after logarithmic compression, where the speckle noise becomes very similar to white Gaussian noise [1]. Various speckle reduction methods have been proposed based on these two models. Some well-known filters such as the Lee filter, the Kuan filter, and the Frost filter are prominent examples that presume a multiplicative model. Other filters, such as the median filter, Wiener filters, speckle reducing anisotropic diffusion filter, and wavelet filters are based on the additive noise model.Although each of these methods provides certain benefits, crucial limitations persist [1]. In some filters, window size affects the quality of the processed image. Both ends of the spectrum are affected, as filtering capacity is reduced for larger and smaller windows: on one hand, blurring increases with large window size, resulting in loss of fine detail in the image; on the other hand, a small window will result in an ineffective filter which does not suppress the noise sufficiently.Dependency of some filters on thresholds which have to be estimated by trial and error is another limitation. In other de-speckle filters, smoothing of the image near the edges is inhibited in order to preserve edge details, leading to speckles remaining in this vicinity [2]. But the primary limitation of existing filters is that they are applied to a single image and do not use the temporal information in echocardiography sequences. De-speckling consecutive images is highly time-consuming, since each echocardiograph frame must be filtered separately. Averaging consecutive frames is a simple method for temporal filtering, but it is inefficient because it both blurs the moving edges and decreases the frame rates. Schistad and Taxt have proposed a method for temporal filtering by increasing the number of dimensions of spatial filters from two to three, and considering only two neighbourhood frames—one before and one after [9]. However, this method is time consuming and causes the blurring of fast-moving edges. A motion-adaptive temporal filtering method for speckle reduction in echocardiography images has been proposed in [10] which uses eight consecutive frames for filtering. Convergence of this algorithm depends on sensitive parameters and, because of the iterative nature of the method, the computational complexity is high.Olstad has proposed a method for speckle reduction in time-varying images based on 1-D anisotropic diffusion [11]. Since the quality of anisotropic filtering is dependent on a boundary detector, a time-consuming method was proposed to find the boundary locations on 1-D signals.In our previous research, we have proposed a method for filtering the long-term temporal pixel signal of echocardiography frames [2]. These intensity variation time curves (IVTCs) (assessed for each pixel) were passed through a Butterworth low-pass filter. The bandwidth of the low-pass filter was chosen by trial and error and may not be applicable to other echocardiographic data. Furthermore, detection of fast-moving objects by simple thresholding, again through trial and error, may not be adaptive enough.To prevent these limitations, the method presented in this paper applies temporal information using a sparse representation approach, which enables adaptive thresholding.The first step of our proposed method involves extracting intensity variation time curves (IVTC) for each pixel of consecutive echocardiographic frames. These curves can be defined by p(x,y,t) for the pixel in coordinate (x,y) at the frame time t. The parameter t is in the range of (1 … T), in which T is the total number of frames. A sample IVTC from a fixed coordinate (x,y) of 128 consecutive frames is illustrated in Fig. 2.In ultrasound imaging, the back-scattered acoustic pulses in the receiver may be in or out of phase. These constructive and destructive interferences appear as a granular pattern of speckle noise on the image texture. The video frames recorded by the transducer pass through attenuation correction and logarithmic transformation of the intensity value. Therefore, the noise model can be assumed to be additive. These patterns can be interpreted as high-frequency variations added to the IVTCs and can be suppressed by low-pass filters [2].The canonical form of reconstruction algorithms for the sparse signal recovery can be defined as a compressive sensing problem, and therefore expressed as a linear regression formula [12]:(1)x=Φw+ɛwhere x represents a M × 1 signal vector, w is a N × 1sparse coefficient vector, Φ is a M × N dictionary matrix whose columns contain a possibly over-complete basis (i.e. N > M) and ɛ is noise. The main goal is to find the sparse solution w based on the signal x and the pre-designed over-complete dictionary Φ.The sparsest representation of a signal can be formulated by finding a vectorw ∈ RNwith the smallest number of non-zero elements. That is:(2)w^=argminw∥w∥0s.t∥x−Φw∥22≤δin which δ is the noise variance. However, this optimization problem requires exhaustive searching and is both numerically unstable and NP-hard11Non-deterministic polynomial-time hard..Many efficient schemes to find the sparsest solution have been proposed in the literature. These solutions can be divided into four categories as follows:(1)Convex relaxation algorithmsIn this category, a convex optimization problem is solved through linear programming by converting the l0- norm penalty to the l1- norm penalty:(3)w^=argminw{∥x−Φw∥22+ρ∥w∥1}This group includes Basis Pursuit (BP) [13], Basis Pursuit De-Noising (BPDN) [14], Least Absolute Shrinkage and Selection Operator (LASSO) [14] and Dantzig Selector [15]. These methods are accurate but computationally complex.Greedy iterative algorithmsIn the second category, the algorithm is used to find active coefficients in an iterative procedure. The informative criterion to decide which coefficients are practically active is the correlation between the signal and the atoms of the dictionary. Examples of this group are Matching Pursuit (MP) [16], Orthogonal Matching Pursuit (OMP) [8], Stage-wise OMP (StOMP) [17]. When the signal is not very sparse, greedy iterative algorithms become costly; but otherwise these methods have low implementation cost and a high speed of recovery compared to convex relaxation algorithms.Iterative thresholding algorithmsThis class of algorithms are faster than the convex optimization algorithms. A soft or hard iterative thresholding is performed to decrease the l1 norm of the coefficients and a gradient descent is also applied to decrease the value of∥x−Φw∥22. This category includes Two-step Iterative Shrinkage Thresholding (TwIST) [18], GPSR [19], Bregman iterations [7] and SpaRSA [20]. The advantages of this approach include low computational complexity and easy implementation.Probabilistic algorithmsIn probabilistic approaches, the problem is solved in a Bayesian framework. Sparse Bayesian Learning (SBL) [21] and Bayesian Compressive Sensing (BCS) [6] are the most popular probabilistic approaches. The major disadvantages of SBL algorithms are high computational costs and large memory requirements. The BCS method demonstrates superior performance in speed and has sharp reconstruction in contrast to most CS algorithms. BCS can be considered a much faster variational formulation of SBL which uses the fast Relevance Vector Machine (RVM) algorithm [6].For this project, we compared sparse recovery algorithms and introduced superior methods for de-noising IVTCs that reduced processing time and reconstruction errors.There are two methods for designing an over-complete dictionary. The first method involves compiling the dictionary using a set of pre-specified functions, while the second method utilizes a learning process whereby a given set of signal examples are used to compile a more relevant dictionary. However, in many cases, designing the dictionary based on a pre-specified transform matrix is more attractive because it is simpler and enables faster evaluation of the sparse representation.In this paper we report use of the first methodology to design an over-complete dictionary. Based on our prior knowledge of the IVTC signals’ nature, we compiled a set of pre-specified functions which included four wavelet families and sine and cosine functions. The sine and cosine parts are considered in the dictionary because of the periodic nature of the cardiac cycle; the wavelet parts are considered for the small variations and rapid transitions which are added to sine–cosine signals.In choosing a proper wavelet family, important concepts were considered; the main one being the application of orthogonal wavelet families rather than biorthogonal wavelets. In wavelet analysis, a signal can be explained by the wavelet function ψ(x) and the scaling function ϕ(x) [22]. In orthogonal wavelets there is one scaling and one wavelet function, and the same number of coefficients in each. In contrast, in the biorthogonal case, there are two scaling functions and accordingly two different wavelet functions, each with a different number of coefficients. Therefore, for simplicity and reduced complexity of dictionary structure, we chose the orthogonal wavelets. The available orthogonal wavelets are: Haar, Daubechies, Symlet, Coiflets and Discrete Meyer. From among these available orthogonal wavelets, four wavelet families were chosen which have the desired shape for constructing the IVTC. These wavelets consist of the following families: Daubechies 4 (db4), Symlet 2 (sym2), Symlet 4 (sym4) and Discrete Meyer (dmey) [22]. It should be noted that since the IVTC is not smooth, the small vanishing moments such as 2 and 4 are proper for Daubechies and Symlet families.The following paragraphs describe the dictionary in two parts: first, the wavelet functions, and second, the sine–cosine functions.In the wavelet part of the dictionary, for a length of the temporal signal IVTC (T), we create T signals which are zero except in position t(t=1,…,T). Each signal is then convolved with the wavelet and scaling functions to produce the basis atoms in our dictionary. Fig. 3shows an example for creating the 75th basis atom of the db4 wavelet function.Accordingly, for a signal with length T, for each wavelet family, we have 2 × T atoms of which T atoms correspond to the convolution of shifted pulse signals with the scaling functions; the other T atoms correspond to the wavelet functions. Overall, for 4 wavelet families, the number of columns in the wavelet part of the dictionary are 4 × 2 × T. For the sine–cosine part of the dictionary, we simply generate sine and cosine functions sin (k × t/T) and cos (k × t/T),k=1,…,T/2,t=1,…,T. Hence, we have T/2 atoms for the sine part and also T/2 atoms for the cosine part. Therefore, the over-complete dictionary has T rows and 9 × T columns (atoms). Note that each atom is normalized to the energy of the atoms of the corresponding family.Fig. 4shows the creation of some atoms in the dictionary in both wavelet and sine–cosine parts; the matrix schematic of the input signal, designed dictionary and corresponding sparse coefficient is illustrated in Fig. 5.Once our over-complete dictionary contains all the candidate basis functions to be considered in the reconstruction, the remaining task is to apply the sparse recovery algorithm that allows us to solve for w in Eq. (1).The following section illustrates the experimental results of applying sparse recovery algorithms on IVTC signals and then reconstructing a smooth version of the signals by the most significant atoms using an adaptive threshold.

@&#CONCLUSIONS@&#
