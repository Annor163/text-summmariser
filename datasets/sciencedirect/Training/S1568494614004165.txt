@&#MAIN-TITLE@&#
A novel self-tuning control method based on regulated bi-objective emotional learning controller's structure with TLBO algorithm to control DVR compensator

@&#HIGHLIGHTS@&#
Presenting self-tuning PI controller based on human brain emotional learning to control DVR.Suggesting a bi-objective structure for emotional controller to satisfy voltage sag and THD.Considering sensitivity of the controller's coefficients, they are regulated by an algorithm.TLBO algorithm is used to optimize emotional controller's parameters.Convergence speed and final answer are great better in TLBO algorithm than PSO algorithm.

@&#KEYPHRASES@&#
DVR,Power quality's indices of sensitive load,Self-tuning PI controller,Human brain emotional learning controller,Bi-objective control structure,TLBO algorithm,

@&#ABSTRACT@&#
DVR is one of the custom power devices for compensating power quality indices. A self-tuning controller with a bi-objective structure is presented for controlling the DVR compensator in order to improve the THD and voltage sag indices of a sensitive load in the network. In this paper, the emotional controller which is based on emotional learning of human brain is proposed for controlling the DVR compensator. This controller has such a structure that makes it capable of considering a second objective in the control process of the system. So far, this capability of the emotional controller has not been used in any researches. The results of the paper demonstrate that compensating and controlling the voltage THD signal in the control process has caused more improvement in the voltage sag of the sensitive load. It was reported that the performance of the emotional controller depends on the selection of the values of its coefficients. Therefore, in order to better improve the proposed controller, these coefficients are tuned by an optimization algorithm. Teaching–learning-based optimization algorithm is considered as optimization algorithm to regulate these coefficients. According to simulation results, it works significantly better than classic PI controller and some intelligent controllers that have introduced in other researches already.model outputAmygdala unit outputorbitofrontal unit outputstimulant inputequivalent gain of Amygdala unitequivalent gain of orbitofrontal unitemotional signallearning rate in Amygdala unitlearning rate in orbitofrontal unitweight coefficient of voltage sag error signalweight coefficient of computational model error signalweight coefficient of voltage THD error signaldynamic voltage restorertotal harmonic distortionsuperconducting magnetic energy storageinsulated gate bipolar transistorgenetic algorithmchaotic accelerated particle swarm optimization

@&#INTRODUCTION@&#
Nowadays by increasing the number of sensitive loads, demand for access to stable and high quality electrical power has increased significantly. In industrial competitive environment, with the development of commercial production of power electronic devices, computer processors and nonlinear loads, any interruption or diversion from the standard range causes economic losses. The realization of this economic loss can be studied in such frameworks as production competition opportunity loss, efficiency reduction and production cost increase, low-quality products, reduced equipment lifetime and increased repair cost, production interruption and energy losses. Thus, access to high power quality, applies a great influence on the asset savings and economic advantages for a firm [1].Disturbance in power distribution system causes harmful defects in distribution system such as interruption, voltage sag, voltage swell, and flicker. Among the above disturbances the most important is voltage sag. According to the IEEE standard, it is defined as a sudden voltage decrease in the range of 10–90% for 0.5 cycles to 1min [2]. That is the result of natural phenomena such as system asymmetric errors and electromagnetic phenomena such as start and inrush current.“Custom power” device have been introduced by experts in order to compensate the harmful effects of disturbances on sensitive loads. Among these devices, DVR is capable to compensate voltage sag and swell effects for sensitive loads devices. The structure of DVR in simple terms consists of: electrical storage source, voltage source inverter and coupling transformer. Recognizing voltage sag in feeder connected to the sensitive load, DVR generates proper voltage using coupling transformer which is in series with sensitive load and injects proper voltage to the network and decrease voltage sag effect.The control system of a DVR plays an important role. It should have a fast response in presence of voltage sags and variations in the connected load. The main purpose of the control system is to preparation of a constant voltage for sensitive load, under system disturbances [3]. The performance analysis and control of the DVR, with different control strategies, have been studied and examined by researchers. Most of the published works on the DVR have used an ordinary proportional-integral (PI) controller in a synchronous frame [4]. The classical PID method has poor flexibility since its parameters cannot be changed. Furthermore, when it is applied to such complicated systems as power system in fault conditions specially, proper results cannot be obtained in most cases [5]. Therefore, control strategies such as predictive control [6], sliding mode [7] and robust control [8] are used in order to control injected voltage. Also in [9] and [10]H∞ controller and a controller based on iteration are used respectively for having better operation in steady and transient states. A multi-level inverter with optimal predictive control structure is used in [11]. These controllers are based on classical and nonlinearity control theory. The problems of control plants that arise in systems such as power systems and its components such as DVR can be classified under three categories. The first problem is complex computation of DVR control. Therefore these theories are rarely used in practical systems. The second is the presence of nonlinearities in these systems that make the control problem complicated. The last is uncertainty in these systems. Necessary information required in the mathematical model of these systems such as intensive dynamic behaviors in normal and fault mode. Most classic and nonlinear control methods are model base. Hence it is possible that they have complexity in control. Therefore, based on the nonlinear control theory as fine as the human ability to comprehend, reason and learn, intelligent methods may be used to overcome the these problems [12]. Thus some researchers investigated on intelligent techniques in order to control DVR compensator. Emotional controller is implemented as an adaptive controller in [13] in DVR control. In [14–16], improving voltage THD index has also been considered as an objective and a control criterion. In [14,15] is introduced a multi-objective PSO and multi-objective modified PSO (CAPSO) algorithms to optimize voltage sag and THD. An adaptive neural network controller based on Hebb learning theory discussed in [16]. This controller was made bi-objective with fuzzification of goals. However, in all of the aforementioned references, algorithms are complex. Although applied control strategies are capable to reduce impulses caused by voltage sag in sensitive loads, but most of these approaches do not consider reducing voltage THD. In many sensitive loads such as medical equipment and adjustable speed motor drives, this level of sensitivity can be very important.In most of the aforementioned researches, it is tried to utilize a stable controller to have a robust system in the presence of fault conditions. Refs. [14,15] are one the rare researches which has tried to improve sensitive load voltage THD and voltage sag together. In this research evolutionary algorithms have been used to optimize two-objective mentioned together in DVR. This approach has two shortcomings. Firstly, power systems and compensators have a completely nonlinear nature. This may cause that these algorithms operate based on random search to encounter the problems and converge to a local optimum. Also, it is necessary to say that in real power systems this search process takes long time. Secondly, power systems have different dynamic behaviors especially during fault conditions. Therefore, PID controllers which are optimized by off-line search algorithms may not have a good performance under these conditions. In this paper it is tried to solve these problems. Consequently, a controller based on intelligent systems with two-objective structure should be better. We try to create a controller that has more accuracy in DVR control. This controller is based on emotions called emotional controller and it is adaptive based on intelligent control. In the following, we introduce this controller.The adaptive method which is inspired by learning nature of human brain is used as a self-tuning PI controller. In order to put capability of having an appropriate performance during voltage sag and voltage THD for sensitive load, a two-objective structure is proposed. Proper regulating of emotional controller's parameters is enormous essential to have better performance [17]. Hence we decide to regulate these parameters with an optimization algorithm. Considering some drawbacks of most optimization algorithms, in this paper we use TLBO algorithm for regulating these parameters. Most optimization methods require algorithm parameters that affect the performance of the algorithm. For instance, GA requires the crossover probability, mutation rate, and selection method; PSO requires learning factors, the variation of weight, and the maximum value of velocity. The proper tuning of the algorithm specific parameters is very crucial factor, which affect the performance of the above mentioned algorithms. The improper tuning of algorithm-specific parameters either increases the computational effort or yields the local optimal solution [18–20]. Considering this fact, Rao et al. [21] introduced the teaching–learning-based optimization (TLBO) algorithm which does not require any algorithm parameters to be tuned, thus making the implementation of TLBO simpler [21]. Therefore in this paper, TLBO algorithm is used for regulating bi-objective emotional controller's coefficients to have appropriate performance. Also we use PSO algorithm for regulate parameters of this controller to compare this PSO algorithm with TLBO algorithm. To investigate efficiency of the proposed algorithm, performance of DVR compensator is tested during various faults in a typical network and compared with those of emotional and classic PI controller and other controllers which are introduced in previous researches. Also, in this paper in order to have better comparison, some other controllers based on intelligent systems have been used. These controllers are such as PI controller regulated with multi-objective PSO and CAPSO algorithm [14,15], Hebb learning controller and its bi-objective version [16].DVR operation is introduced in Section 2; PI emotional controller and its multi-objective structure (proposed controller) are introduced in Sections 3 and 4 respectively. The final section contains the simulation and results.DVR is one of the “custom power” devices in distribution network which is series with transmission line. Load voltage becomes balance by injecting three controlled voltages during disturbance in the power system. Thus DVR is based on injection of appropriate voltage during voltage sag in order to compensate it. DVR functionality can be categorized as two modes: standby mode and injection mode [13–22]. In the standby mode a low voltage inject into the network in order to cover voltage sag caused by transformer reactance. Second mode is in presence of voltage sag. DVR injects appropriate voltage to sensitive load. DVR circuit includes five main components. They are shown in Fig. 1.(1)Series transformer: That its primary winding is connected to the inverter and its secondary winding is connected to the distribution network and sensitive load.Voltage inverter: The inverter is connected to the injection transformer. Energy storage equipment has been considered for inverter. This inverter includes IGBT switches self-commutation by shunt diodes and control technique is PWM.Energy storage equipment: Power storage resources such as batteries, capacitor banks, SMES and flywheels that have been used for providing adequate voltage and active power and compensating sag [13].Passive filter: It is connected to the high voltage side of inverter to eliminate harmonics produced by switching.Control system: Logical fundamental of control system is based on voltage sag detection, and providing appropriate switching strategies for inverter.Control system uses the abc–dq transformation to calculate vd and vq. In balance condition, the voltages vd=1 and vq=0. But in fault condition, these voltages change [10]. We can control the variations of these signals by comparing these voltages with their references and giving their error signals to a PI controller.In 2000, this controller was introduced for the first time by Moren and Balkenious. These researchers started to develop computational models of those parts of the human brain which carry out emotional processing. In [23], a new model for performance of the brain emotion processing parts consisting of Amygdala, orbitofrontal cortex, thalamus, and finally sensory cortex has been presented in Figs. 2 and 3.Considering the aforementioned model and according to new theories, the Amygdala-orbitofrontal system carries out the learning process in two stages. First, the input stimulant signals are evaluated and in the next stage, this evaluation is used as amplifier coefficients in response affected by the stimulant. Amygdala is one of the primary structures of the brain which exists in an almost uniform way in large scale structures among different species of animals.Amygdala is a small part in temporal lobe which carries out the emotional evaluation of stimulant. These evaluations are used in emotional states and reactions, attention signals, also in long-term memory. Some of inherent stimulants such as: hunger, pain, some smells, etc., can stimulate the Amygdala. The Amygdala's response to these stimulants is used in learning part.The scientist's investigations show that the animals which their Amygdala is damaged have problems in learning and this fact confirms that learning takes places in Amygdala. On the other hand, the orbitofrontal cortex plays its role as the modifier of inappropriate responses and reactions of Amygdala. Numerous experiments on patients with damaged orbitofrontal-cortex have revealed that they are not able to adapt themselves to new conditions (in the other words, previous learning does not let them understand and respond to new conditions).Neglecting the details, the schematic view of brain emotional learning system is shown in Fig. 3. Next, this will be used to explain the proposed computational model for Amygdala-orbitofrontal emotional learning system. The computational model output MO (the response of Amygdala-orbitofrontal emotional learning system to input stimulant SI, and emotional) is equal to:(1)MO=AO−OCOwhere AO and OCO are the Amygdala and orbitofrontal unit outputs respectively and are equal to:(2)AO=Ga⋅SIOCO=Goc⋅SIwhere, Ga and Goc are the equivalent gains of Amygdala and orbitofrontal units respectively.Learning law in orbitofrontal and Amygdala units is shown in Eq. (3) respectively.(3)ΔGa=k1⋅max(0,EC−AO)≥0ΔGoc=k2⋅(MO−EC)where, K1, K2 are the learning rates in Amygdala and orbitofrontal unit respectively. As it is clear from the above equation, because of using the max operator, the Amygdala unit gain is doomed to have a monotonously increasing variation and of course this is consistent with the physiological fact mentioned in previous paragraph i.e. the Amygdala unit is not able to forget what it has learned before.In the other words, the desired operational conditions (which are reflected in great values of emotional signal, EC) gradually cause the Amygdala unit gain to increase to its physical ceiling. Now, if these desired conditions become undesired in the future for any reason (with a small value of emotional signal, EC) the Amygdala unit will not be able recognize this problem and modify its response and it will respond analogous to desired conditions. At any rate, the orbitofrontal unit gain is allowed to have positive/negative variations in order to be able to carry out proper modification on inappropriate responses of Amygdala unit.By combining Eqs. (1)–(3):(4)MO=(Ga−Goc)⋅SI≡G(SI,EC,…)⋅SIIn the other words, the Amygdala–orbitofrontal emotional learning system output is equal to a varying gain G (which is dependent to various factors such as emotional signal EC, input stimulant SI, etc.,) multiplied by input stimulant SI [24]. Due to the value and high performance of self-tuning PID controller in DVR performance control domain, a simple and appropriate suggestion to formulate stimulant input signal is a template similar to PID.(5)SI=kP⋅ew+KI⋅∫0tewdt+KD⋅e˙wwhere, ew=wref−w is the voltage sag signal tracking error of closed-loop system. For various reasons such as noise of measurement tools and sometimes severe switching necessity in compensator converter circuit, the derivative operator worsens the system performance so that in the best state, the PID type DVR controller will not have a better performance than PI type [24]. The emotional signal EC generally must show the desirability of the DVR controller and closed-loop system performance. Therefore, EC could be written as a weighted combination of primary/secondary objectives in application domain. In the proposed approach in this paper, voltage THD which is measured from sensitive load bus is used as second objective. Therefore, EC signal can be obtained as Eq. (6).(6)EC=aec1⋅eSAG+aec2⋅MO+aec3⋅eTHDIn this equation aec1, aec2, aec3 are the weight coefficients of voltage sag error, computational model error and voltage THD error signals respectively. In the equation, voltage sag error signal (eSAG) and voltage THD error signal (eTHD) are deference between reference value and from real value of each signal. Computational model error is named control effort feedback signal that lead to better performance rather than lots of controllers. The proposed control strategy and DVR control structure is observed in Figs. 4 and 5.In which the rotating phase angle θ is derived from phase lock loop (PLL).When the voltage sags occur, injected voltage vector Vinj(t) is provided by DVR to restore the sensitive load voltage vector. At this time, should react as fast as possible and inject an ac voltage to the grid. It can be implemented using a feedback control technique based on the voltage reference and instantaneous values of sensitive load voltage. The control algorithm produces a three phase reference voltage to the series converter that tries to maintain the load at its reference value. The voltage sag is sensed by measuring the error between the dq voltages of sensitive load. The d-reference component is set to a rated voltage and the q-reference component is set to zero. In Fig. 3b, the sensitive load voltage is connected to a transformation block that converts stationary frame to αβ-frame. Output of this block is connected to a phase lock loop (PLL) and another transformation block that converts αβ-frame to rotating frame (dq), which determines the phase and changes the axis of the sensitive load voltage. We can control the variations of these signals by comparing these voltages with their references and feeding their error signals to PI controllers. Bi-objective emotional learning controllers are PI. Output signal of controllers in dq frame convert to three phase voltage. The injection voltages generate by three phase voltage and apply to the voltage source converter (VSC) to produce the preferred voltage.TLBO algorithm, originally developed by Rao et al. [21], is a population-based optimization algorithm. In TLBO algorithm a population of solutions is utilized to proceed to the global solution. To this end, in TLBO algorithm, a group of learners is chosen as population and different design variables are considered as different subjects offered to the learners and learners’ result is similar to the ‘fitness’ value of the optimization problem [25–27]. In the whole population, the best solution is considered as the teacher.The two elementary components of this algorithm are teacher and learners. Based on two basic modes of the learning, through teacher (known as teacher phase) and interacting with the other learners (known as learner phase), the procedure of TLBO is divided into two parts, (1) teacher phase and (2) learner phase.The first part of the algorithm is teacher phase where learners learn through the teacher. During this phase, a teacher endeavors to increase the mean result of the classroom from any value. Since it is practically impossible, a teacher can improve the mean of the classroom to other better value depending on the class capability. Consider M_i be the mean and T_i be the teacher at any iteration i. T_i will try to enhance existing mean M_i towards it so the new mean will be T_i designated as M_new. The solution is updated according to the difference between the existing and the new mean given by [21](7)Difference_meani=ri(meannew−TFMi)where T_F is the teaching factor which decides the value of mean to be changed, and r_i is the random number in the range [0,1]. The teaching factor T_F is generated randomly during the algorithm in the range of 1–2, in which 1 corresponds to no increase in the knowledge level and 2 corresponds to complete transfer of knowledge. The value of T_F is randomly opted with equal probability as(8)T_F=round[1+rand(0,1){2−1}]According to this Difference_Mean, the existing solution is updated as follows:(9)Xnew,i=Xold,i+DifferenceMeanjIn this phase, the learners can enhance their knowledge via interaction among themselves randomly. A learner learns new things if the other learner has more knowledge than him or her. The learning phenomenon of this phase at any iteration i for two different learners X_i and X_j where i≠j are given by(10)Xnew,i=Xold,i+rj(Xi−Xj),Iff(Xi)<f(Xj)(11)Xnew,i=Xold,i+rj(Xj−Xi),Iff(Xj)<f(Xi)The pseudo-code of TLBO algorithm can be summarized as follows:Step 1: Determine the optimization problem in hand and initialize the optimization parameters.Step 2: Initialize the population (i.e. learners’) with random generation and evaluate them.Step 3: Choose the best learner of each subject as a teacher for that subject and calculate mean result of learners in each subject.Step 4: Evaluate the difference between current mean result and the best mean result according to (7) using the teaching factor T_F given in (8).Step 5: Update the learners’ knowledge by the help of teacher's knowledge according to (9).Step 6: Update the learners’ knowledge by the knowledge of some other learner according to (10) and (11).Step 7: Stop if a stopping criteria is achieved, else go to Step 3.When a stopping criterion occurs, the result is the best answer for the problem in hand (the best estimated parameters).

@&#CONCLUSIONS@&#
