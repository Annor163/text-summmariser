@&#MAIN-TITLE@&#
Multiobjective shortest path problems with lexicographic goal-based preferences

@&#HIGHLIGHTS@&#
We find all Pareto optimal paths in a graph satisfying a set of lexicographic goals.A new label setting algorithm is developed, using a special pruning condition.The algorithm accepts heuristic cost estimates to speed up search.The algorithm explores only a subset of the labels explored in a full Pareto search.Experiments reveal significant performance improvements over full Pareto search.

@&#KEYPHRASES@&#
Combinatorial optimization,Multiobjective shortest path problem,Label-setting search,Heuristic search,Goal programming,

@&#ABSTRACT@&#
Multiobjective shortest path problems are computationally harder than single objective ones. In particular, execution time is an important limiting factor in exact multiobjective search algorithms. This paper explores the possibility of improving search performance in those cases where the interesting portion of the Pareto front can be initially bounded. We introduce a new exact label-setting algorithm that returns the subset of Pareto optimal paths that satisfy a set of lexicographic goals, or the subset that minimizes deviation from goals if these cannot be fully satisfied. Formal proofs on the correctness of the algorithm are provided. We also show that the algorithm always explores a subset of the labels explored by a full Pareto search. The algorithm is evaluated over a set of problems with three objectives, showing a performance improvement of up to several orders of magnitude as goals become more restrictive.

@&#INTRODUCTION@&#
Goal programming is one of the most successful models of Multicriteria Decision Theory (Chankong & Haimes, 1983). Virtually hundreds of applications can be found in the literature (Romero, 1991; Tamiz, Jones, & El-Darzi, 1995). This paper explores the application of the goal-based decision paradigm to multicriteria shortest path problems.Multicriteria shortest path problems arise naturally in many fields, such as robot surveillance (Delle Fave, Canu, Iocchi, Nardi, & Ziparo, 2009), robot path planning (Fujimura, 1996), satellite scheduling (Gabrel & Vanderpooten, 2002), and route planning in different contexts (Delling & Wagner, 2009; Clímaco, Craveirinha, & Pascoal, 2003; Jozefowiez, Semet, & Talbi, 2008; Machuca & Mandow, 2012). A number of shortest path algorithms have been proposed to tackle different multicriteria decision models. The work of Hansen (Hansen, 1979) presented a bi-objective extension of Dijkstra’s label setting algorithm. Martins (Martins, 1984) proposed a general multiobjective label setting algorithm. A recent evaluation of several multiobjective shortest path algorithms can be found in (Raith & Ehrgott, 2009).The multiobjective shortest path problem is computationally harder than the single objective one. The number of label expansions can grow exponentially with solution depth, even for the two objective case (Hansen, 1979). With the assumption of bounded integer costs and a fixed number of objectives the problem becomes tractable for polynomially sized graphs, but still harder than single objective search (e.g. see (Mandow & Pérez de la Cruz, 2009; Müller-Hannemann & Weihe, 2006)).Search efficiency can be improved in single destination (one to one) problems using lower bound distance estimates in a similar way as algorithm A∗ improves over Dijkstra’s (Pearl, 1984). Several multiobjective extensions of A∗ have been proposed. These can be grouped in two classes: those that perform node expansion as its basic operation (like MOA∗ (Stewart & White, 1991)), and those that perform label expansion (like Tung and Chew’s algorithm (Tung & Chew, 1992) andNAMOA∗(Mandow & Pérez de la Cruz, 2010)). The interest in these algorithms with lower bounds is justified by the fact that: precise lower bound estimates can be efficiently precalculated for a large class of problems (Tung & Chew, 1992); and the use of such estimates still guarantees an exact solution, i.e. the algorithms find the set of all Pareto optimal solutions to the problem.Several algorithms extended the node expansion policy of MOA∗ to different contexts, like algorithms MOA∗∗ for search with nonconsistent lower bounds (Dasgupta, Chakrabarti, & DeSarkar, 1999), BCA∗ for compromise solutions (Galand & Perny, 2006), or METAL-A∗ for goal based preferences (Mandow & Pérez de la Cruz, 2001). The latter are the subject of this work. However, recent empirical and formal analyses (Machuca, Mandow, Pérez de la Cruz, & Ruiz-Sepulveda, 2012; Pérez de la Cruz, Mandow, & Machuca, 2013) have shown that lower bounded search with node expansion can perform much worse than blind search algorithms and, more precisely, that performance can seriously degrade with better lower bound estimates. In practice, this result ruins the primary purpose of using lower bounds in these algorithms in the first place.On the other hand, label expansion algorithms with lower bounds have successfully improved performance over blind search algorithms. The efficiency ofNAMOA∗has been formally shown to improve with better informed lower bound estimates and, in fact, it has been shown to optimally exploit such estimates among the class of admissible algorithms (Mandow & Pérez de la Cruz, 2010). Empirical results confirm thatNAMOA∗performs consistently better than blind search, and that better informed lower bounds result in faster search with less space requirements (Machuca et al., 2012). Experiments on problems like bicriteria route planning reveal that time, rather than space, is the practical limiting factor in the calculation of the full Pareto set of solutions (Machuca & Mandow, 2012; Machuca, Mandow, & Pérez de la Cruz, 2009). Recent attempts to improve this algorithm include parallel search (Sanders & Mandow, 2013) and the use of specific efficient data structures (Mali, Michail, & Zaroliagis, 2012).Many problems do not require in practice the calculation of the full Pareto optimal set of solutions. In this work we investigate the possibility of further improvements over the efficiency ofNAMOA∗through the introduction of lexicographic goal based preferences. A set of goals can be proposed to bound the area of interesting solutions. More precisely, given a set of goals, we tackle the problem of finding the subset of Pareto optimal paths that satisfy the goals or, if these cannot be satisfied, finding the subset of Pareto optimal paths that minimize deviation from the goals. We propose a new multicriteria label-setting algorithm with lower bounds and label expansion that finds such goal-optimal solutions. The new algorithm explores a subset of the labels explored byNAMOA∗, achieving important performance improvements.Section 2 reviews relevant concepts from multicriteria decision theory and introduces the concept of pruning preference. Section 3 describes the algorithm. Important properties concerning admissibility and efficiency are presented in Section 4. An empirical evaluation is described and discussed in Section 5. Finally some conclusions and future work are outlined.First of all, we review the concepts of attribute, objective, and goal, as defined in Romero (1991). Let X be the set of solutions to a decision problem. An attribute is a measurable propertyg(x):X→R. An objective represents the desired improvement of an attribute, i.e. maximization or minimization. A goal combines an attribute with a specific target value, or aspiration levelt∈R, stated by the decision maker to define his/her preference. Goals for multiobjective shortest path problems are always of the formg(x)⩽t. Goals are not constraints, i.e. feasible solutions may not satisfy all goals.Let us consider a set of q attributesgi:X→R,1⩽i⩽qgrouped in l priority levels sorted in order of decreasing preemptive importance. Each priority level k comprises a setIkof one or more attributes. Goals are defined by setting targetstifor each attribute,gi(x)⩽ti.A solution to a goal problem is satisfactory when all the goals can be satisfied. We seek nondominated satisfactory solutions. If there are no satisfactory solutions to a problem, we seek nondominated solutions that minimize deviation from the targets. In lexicographic goal problems, the deviation of a set of goals is measured separately for each priority level. Minimizing the deviation of goals at level k is infinitely more important than minimizing deviation at levelk+1.Several methods have been proposed to measure the deviation from a set of goals. In this work, the minimization of the weighted sum of deviations is employed. Letg→=(g1,g2,…,gq)be a vector with all attributes (costs) of a given solutionx∈X. We can calculate a deviation vector forg→with one component for each priority level,d→(g→)=(d1(g→),d2(g→),…,dl(g→)). For each level k, its deviationdkcan be defined as:(1)dk(g→)=∑i∈Ikwi×max(0,gi-ti)wherewiis the relative weight of goal i in level k.We define the optimum achievement vectord∗→=(d1∗,d2∗,…,dl∗)as the minimum lexicographic deviation vector among all solutions. Thus, the set of goal-optimal solutions consists of all nondominated feasible solutions with a deviation equal tod∗→. If there is a satisfactory solution, then the optimum achievement vector is equal to0→.We will now reproduce some standard definitions and introduce some new preference relations between cost vectorsy→,y′→∈Rq.•Dominance (≺) or Pareto-optimal preference is defined as follows,(2)y→≺y′→⇔∀iyi⩽yi′∧y→≠y′→Dominance is a strict partial order. Given a set of vectors X, we shall defineN(X)the set of nondominated vectors in set X in the following way,(3)N(X)={x→∈X|∄y→∈Xy→≺x→}We shall find it useful to denote by⪯the relation “dominates or equals”.Let us denoteαi=minx→∈N(X){xi}, andβi=maxx→∈N(X){xi}. The setN(X)is bounded by the ideal pointα→=(α1…αq), and the nadir pointβ→=(β1…βq). The ideal point can be calculated optimizing each objective separately. However, forq>2it is difficult to calculate the nadir point without computing the whole set of nondominated solutions.Lexicographic order≺Lis defined as follows,(4)y→≺Ly′→⇔∃jyj<yj′∧∀i<jyi=yi′The lexicographic order is a strict total order. The lexicographic optimum of a set of vectors is trivially a nondominated vector.We define lexicographic goal preferences (≺G) as a partial order relation,(5)y→≺Gy′→⇔d→(y→)≺Ld→(y′→)∨(d→(y→)=d→(y′→)∧y→≺y′→)It is easy to see that≺Gis a strict partial order (it is irreflexive and transitive). Given a set of vectors X, we shall defineOG(X)the set of optimal vectors in X according to lexicographic goal preferences (i.e. goal-optimal vectors) as,(6)OG(X)={x→∈X|∄y→∈Xy→≺Gx→}Notice that an optimal solution according to≺Gis also a nondominated solution, i.e.OG(X)⊆N(X).Let us consider a goalyk⩽tk, the slack variableskfor this goal is defined as(7)sk=max(0,tk-yk)Let us assume two vectorsy→,y′→∈Rqand a level j such thatdj(y→)<dj(y′→). Let us denoteΔj(y→,∊→)=dj(y→+∊→)-dj(y→). Obviously, if∊→⪰0→,Δj(y→,∊→)⩾0. We define the cross-slackδj(y→,y′→)=max∊→∈R+q(Δj(y→,∊→)-Δj(y′→,∊→)), i.e. the greatest relative increment of the deviations ofy→andy′→at level j when adding any∊→∈R+q. Notice thatδj(y→,y′→)⩾0and generallyδj(y→,y′→)≠δj(y′→,y→).Fig. 1shows that for eachi∈Ijfour different cases can arise: (1)yi′,yi⩾ti; (2)yi′⩾tiandyi<ti; (3)yi′<tiandyi⩾ti; (4)yi′,yi<ti. It is straightforward that the greatest relative increment in cases 1 and 2 is 0, since the slack variablesi′equals 0, while in cases 3 and 4, the greatest relative increment iswi×(si′-si). Therefore, an operative way of calculating the cross-slackδj(y→,y′→)ofy→,y′→at level j is(8)δj(y→,y′→)=∑k∈Ijwk×max(0,sk′-sk)We define the pruning preference≺Pby imposing on the lexicographical goal preference additional conditions concerning cross-slacks:(9)y→≺Py′→⇔∃j(dj(y→)<dj(y′→)∧δj(y→,y′→)<dj(y′→)-dj(y→)∧∀i<j(di(y→)=di(y′→)∧δi(y→,y′→)=0))i.e.y→≺Py′→when (i)y→≺Gy′→; (ii) the cross-slacks ofy→andy′→are zero for the first levels (where deviations are the same); and (iii) for the first level where deviations differ, the cross-slack ofy→andy′→is strictly smaller than the difference between deviations.It can be easily checked that≺Pis irreflexive and transitive. Therefore≺Pis a partial order relation. We ready→≺Py′→as «y→allows to pruney′→».In the following, we shall be concerned with the evaluation of goals in multiobjective graphs, where the following definitions apply. LetG=(N,A,c→)be a locally finite labeled directed graph, of|N|nodes, and|A|arcs(n,n′)labeled with positive cost vectorsc→(n,n′)∈Rq. Let a path in G be any sequence of nodesP=(n1,n2,…,nk)such that for alli<k,(ni,ni+1)∈A, and the cost vector of each pathg→(P)=(g1(P),g2(P),…,gq(P))be the sum of the costs vectors of its component arcs.A problem over a multiobjective graph is defined by a start nodes∈N, and a destination2Graph search literature often refers to this node as goal node. However, in this article we refer to it as destination node to avoid overloading the meaning of the word “goal”.2node t. Each path in the graph,P=(s,…,ni,ni+1,…,t), represents a feasible solution to the problem. A lower bound functionh→:N→Rqreturns an estimateh→(n)of the minimum cost of all paths from n to t. A lower bound functionh→(n)is monotone if for all arcs(n,n′)in the graph, the following condition holds,h→(n)⪯c→(n,n′)+h→(n′).h→is admissible ifh→(n)never overestimates the cost of any path from n to t.In the following we consider that the preference between solution paths is defined by a set of lexicographic goals. The solution to the problem is the set of all goal-optimal solutions (see Eq. (5)). We define the set of nondominated solutions asC∗and the set of goal-optimal solutions asCG∗, respectively. By definition,CG∗⊆C∗.This section introducesLEXGO∗, a multiobjective label-setting search algorithm for lexicographic goal preferences with lower bound estimates. The pseudocode ofLEXGO∗is shown in Table 1. The inputs are a multiobjective graph G, a start node s, a destination node t, a set of weighted goals grouped in preemptive priority levels, and a monotone lower bound function.LEXGO∗outputs the set of all goal-optimal solution paths between s and t. The following data structures are managed by the algorithm:•SG: A search graph that records partial solution paths emanating from s and their costs. Each node n in SG stores the following information:–Gop(n): Set of cost vectors (labels)g→nof paths reaching node n which have not been explored yet.Gcl(n): Set of labels reaching node n which have already been explored.OPEN: A priority queue of unexplored labels. For each node n in SG and each cost vectorgn→∈Gop(n), there is a label(n,gn→)in OPEN. In fact, labels are extended to include also evaluation vectors and their deviation from goals. Each extended label(n,d→n,f→n,g→n)denotes that node n is reached by a path with costg→n, deviation vectord→n, and evaluation vectorf→n. We definef→n=g→n+h→(n). For the sake of simplicity, we will denoted→(f→n)asd→n. Initially,(s,d→s,f→s,g→s)is the only label in OPEN. Labels in OPEN are sorted lexicographically according to deviation vectors. In case of ties they are ordered lexicographically according to evaluation vectorsf→. This ensures that the first element in the queue has a goal-optimal evaluation.COSTS: The set of cost vectors of solution paths found to the destination node.Best achievement: Vectord→Bamong all solutions already found.The structure ofLEXGO∗is similar to previous label-setting multiobjective algorithms with label expansion, but incorporating elements of lexicographic goal preferences to guarantee that only a subset of the labels explored by a full multiobjective search will need to be explored.The algorithm has five main steps. The first one is devoted to data structure initialization. The second one is devoted to label selection from OPEN, and lazy filtering. At each iteration the algorithm selects the first label(n,d→n,f→n,g→n)from OPEN, which has a goal-optimal evaluation vector. The label is removed from OPEN, and moved fromGop(n)toGcl(n). The third step recovers and returns the solution subgraph whenever some termination condition is satisfied. The fourth step records the solution whenever a destination node is selected. COSTS andd→Bare updated accordingly. Finally, the selected label is expanded in step 5, i.e. all the extensions of the selected label are considered for inclusion in the search graph and the OPEN set.The algorithm iterates over steps 2, 3, 4 and 5 until OPEN is empty, ord→B≺Ld→n, i.e. all potential goal-optimal solutions have been examined. In such case, the algorithm terminates returning a solution subgraph, made up of all goal-optimal solution paths. COSTS stores the set of distinct goal-optimal costs.During path expansion two different conditions may prevent an extension from consideration: filtering and pruning. These are described in detail below.Regrettably, the optimality principle does not hold for lexicographic goal preferences, i.e. a goal-optimal path is not made of goal-optimal subpaths. The following example illustrates this fact.Example 1Let us consider a search problem in a multiobjective graph with start node s, a destination node t, and the following preferences over three different attributes,(10)Level1:g1⩽20,w1=1.0Level2:g2⩽20,w2=0.5g3⩽20,w3=0.5Let us further assume the graph has two different pathsP1andP2reaching some node n, where∀nh→(n)=(0,0,0), and the following costs and associated deviations,g→(P1)=f→(P1)=(15,16,22)⇒d→(P1)=(0,1)g→(P2)=f→(P2)=(20,12,16)⇒d→(P2)=(0,0)We observe thatf→(P2)≺Gf→(P1), sinced→(P2)≺Ld→(P1). However, we cannot discardP1in favor ofP2. Let us now consider there is only one additional pathP3=(n,…,t)from n to the destination node with costg→(P3)=(4,4,4). It is easy to show now that the concatenationP1P3is the only goal-optimal solution,g→(P1P3)=(19,20,26)⇒d→(P1P3)=(0,3)g→(P2P3)=(24,16,20)⇒d→(P2P3)=(4,0)Therefore, pruning and filtering using goal preferences would not yield an admissible label setting algorithm in this case. Nevertheless,LEXGO∗includes two pruning conditions that improve search efficiency and, at the same time, guarantee that no goal-optimal solution will be pruned, (see Theorem 2 in Section 4 below):•Pareto pruning. As in other Pareto search algorithms likeNAMOA∗, we prune any dominated path to any node. A new label(m,d→m,f→m,g→m)to node m is pruned whenever(11)∃g→∈Gop(m)∪Gcl(m)|g→≺g→mDeviation-based pruning. We propose an additional specific pruning condition based in the pruning preference defined by Eq. (9). We prune a new label(m,d→m,f→m,g→m)to node m whenever,(12)∃g→∈Gop(m)∪Gcl(m)|g→+h→(m)≺Pf→mLet us assume the same preference as in Example 1 and two paths P andP′reaching the same node n from s with the following evaluation vectors,f→=f→(P)=(22,22,12)⇒d→(P)=(2,1)f→′=f→(P′)=(22,18,26)⇒d→(P′)=(2,3)We observe thatd→(P)≺Ld→(P′). We can also easily check that the extra conditions for pruning,δ1(f→,f→′)=0andδ2(f→,f→′)=1<3-1=2, also hold,δ1(f→,f→′)=1×max(0,s1′-s1)=max(0,0-0)=0δ2(f→,f→′)=0.5×max(0,s2′-s2)+0.5×max(0,s3′-s3)=0.5×max(0,2-0)+0.5×max(0,0-8)=1Therefore, pathP′will never lead to a better goal solution than P and can be safely pruned.Filtering is the process of discarding labels that will never lead to a solution better than one already found. Two different conditions allow a label(n,d→n,f→n,g→n)to be filtered,•Pareto filtering. This is the standard dominance filtering in Pareto search algorithms,(13)∃c∗→∈COSTS|c∗→≺f→nDeviation based filtering. We introduce a specific filtering condition for goal-based preferences when a known solution has better goal satisfaction,(14)d→B≺Ld→nWhen a new solution is found, or the best achievement vector is updated, no new label satisfying the above conditions will be allowed to enter OPEN.LEXGO∗applies lazy filtering, as described in (Sanders & Mandow, 2013), i.e. we do not explicitly filter existing labels when a new solution is found. Labels are tested and, if necessary, filtered only after selection. This prevents a costly update operation.This section illustrates the algorithm with a simple example. The decision maker’s preference involves two levels of goals:Level1cost1(P)⩽10,w1=0.5cost2(P)⩽10,w2=0.5Level2cost3(P)⩽10,w3=1Let us consider the sample graph in Fig. 2, where s is the start node, and t the destination node. A lower bound functionh→(n)has been calculated using the method proposed by Tung and Chew (Tung & Chew, 1992) and is presented in Table 2. A trace of the OPEN list is shown in Table 3. At each iteration the selected label is indicated with an arrow and pruned labels are crossed out.At iteration 1, SG has only node s as its root and its corresponding label is selected from OPEN. Labels for the three descendantsn1,n2andn3of s are added to OPEN. At iteration 2, two labels in OPEN have the same deviation vector, so the best lexicographicf→is used to break the tie. Hence, the label ton1is selected. Its two successorsn3and t are added to OPEN. Addition ofn3toGop(n3)prunes the alternative already stored forn3, since(10,9,7)≺P(12,10,4). Notice that both evaluation vectors are nondominated, however, the pruning condition presented in Eq. (12) is applied, sinceδ1((10,9,7),(12,10,4))<d1(12,10,4)-d1(10,9,7)⇒0<1-0. At iteration 3, the label ton2is selected and expanded, generating new paths to the successorsn3and t. The extension ton3is pruned, since the cost vector(5,5,8)from path(s,n2,n3)is dominated by the cost(5,5,5)from path(s,n1,n3). The second successor, t, is also pruned due to the existence of another label inGop(t)such that(10,8,10)≺P(12,8,8). At iteration 4, the first path to a destination node is selected, the corresponding cost vector is added toCOSTS={(10,8,10)}andd→Bis updated to(0,0). This means that there is at least one path which satisfies all the goals provided.At iteration 5,n3is selected, and a new path to t is generated and added to OPEN. At iteration 6, the only label in OPEN is selected. The cost vector(10,9,7)represents another solution since t is the destination node, its cost is not dominated by any vector in COSTS and it can also satisfy all goals. Finally, in the next iteration OPEN is empty and the algorithm would search backward from t returning the solution subgraph with the two paths with costs (10,8,10) and (10,9,7).This section proves some relevant properties ofLEXGO∗. First, we will show thatLEXGO∗is efficient, i.e. it always expands a subset of the labels expanded byNAMOA∗. Then, we will show that it is admissible, i.e. it always returns the set of all goal-optimal solutions.Let us consider first the question of efficiency.LEXGO∗is essentially a version ofNAMOA∗with additional pruning and filtering rules. However, including additional rules does not necessarily guarantee that the algorithm explores a subset of the labels expanded byNAMOA∗. The example in Fig. 3illustrates the case for an arbitrary pruning rule. Let us assume∀nh→(n)=0→. There are two nondominated paths from s ton1with costs (8,6) and (9,1), respectively. Let us assume that by a certain arbitrary rule the path with cost (8,6) prunes the one with cost (9,1). There are two paths from s ton2throughn1with costs (9,14) and (10,9). The latter dominates the path from s ton2with cost (10,10). However, due to the pruning rule, it will never be generated, and the dominated path with cost (10,10) will need to be expanded. In other words, the inclusion of an arbitrary pruning rule may lead to the exploration of labels never considered byNAMOA∗.So we must formally show that the additional rules ofLEXGO∗guarantee that only a subset of the labels expanded byNAMOA∗are actually considered. To do so, Lemma 1 analyzes the relation between pruning, goal, and Pareto preferences. Then, Theorem 1 proves the desired efficiency ofLEXGO∗, and finally, Theorem 2 establishes its admissibility.Lemma 1Assume∊→⪰0→. Then(a)Ify→≺Py′→theny→+∊→≺Gy′→+∊→.Ify→≺Py′→theny→+∊→≺Py′→+∊→.Ify→≺Py′→andy′→≺y″→, theny→≺Py″→.Notice that, by definition,(15)δi(y→,y′→)=0⇒∀k∈Iisk⩾sk′Additionally, assumedi(y→)=di(y′→). Sincey→has greater or equal slack thany′→for all goals in level i, then it is straightforward that,(16)∀∊→⪰0→,di(y′→+∊→)⩾di(y→+∊→)Notice again that, by definition,(17)δj(y→,y′→)<dj(y′→)-dj(y→)⇒∀∊→⪰0→,dj(y′→+∊→)>dj(y→+∊→)Property (a) follows then from the definition of goal preferences. Assumey→≺Py′→, and that∃jdj(y→)<dj(y′→)∧(∀i<jdi(y→)=di(y′→)). Then, from Eqs. (16) anf (17),y′→+∊→will not have better deviation overy→+∊→for any of the first j levels, and will have strictly worse deviation for at least one of them, i.e.y→+∊→≺Gy′→+∊→.For part (b) we still have to prove the additional constraints imposed on cross-slacks. Let us denote bysk″andsk‴the slack for goal k of vectorsy→+∊→andy′→+∊→respectively. For all levelsi<jwe have,δi(y→,y′→)=0⇒∀k∈Iisk⩾sk′⇒∀k∈Iisk″⩾sk‴⇒δi(y→+∊→,y′→+∊→)=0and alsodi(y′→+∊→)⩾di(y→+∊→).If for somem<jdm(y′→+∊→)>dm(y→+∊→), thenδm(y→+∊→,y′→+∊→)=0<dm(y′→+∊→)-dm(y→+∊→), and the property holds. Otherwise, we need to prove that the condition on cross-slacks still holds for level j. Let us defineδi(y→,y′→)=wi×max(0,si′-si). The following is an alternate definition of formula (8),δj(y→,y′→)=∑m∈Ijδm(y→,y′→)Analogously, let us definedi(y→)=wi×max(0,yi-ti). Then,dj(y→)=∑m∈Ijdm(y→)Now, we analyze for each goalm∈Ijits influence in deviations and cross-slack. We have three cases to consider,•Whensm=sm′, deviations increase in the same amount (i.e. their relative difference does not change) andδm(y→+∊→,y′→+∊→)=δm(y→,y′→)=0.Ifsm>sm′, thendm(y′→)-dm(y→)⩽dm(y′→+∊→)-dm(y→+∊→), i.e. the relative difference between deviations can never decrease. Sinceδm(y→,y′→)=δm(y→+∊→,y′→+∊→), the condition will hold for the goal.Ifsm<sm′, then we have to consider three distinct cases,–When0⩽∊m⩽sm<sm′, both deviations are zero, their relative difference remains zero andδm(y→,y′→)does not change.Whensm<∊m⩽sm′, we have[dm(y′→)-dm(y→)]-[dm(y′→+∊→)-dm(y→+∊→)]=wm×(∊m-sm). However, we also haveδm(y→,y′→)-δm(y→+∊→,y′→+∊→)=wm×(∊m-sm), i.e. it decreases in the same amount as before, and the inequality still holds for goal m.Whensm<sm′<∊m, we have[dm(y′→)-dm(y→)]-[dm(y′→+∊)-dm(y→+∊)]=wm×(sm′-sm). However,δm(y→,y′→)-δm(y→+∊→,y′→+∊→)=wm×(sm′-sm), i.e. it also decreases in the same amount as before, and the inequality still holds for goal m.Part (c) is quite straightforward. Notice that,(18)y′→≺y″→⇒∀l∀k∈Ilsk′⩾sk″Ify→≺Py′→, then we have that for all levelsi<j,δi(y→,y′→)=0,δi(y→,y″→)=0, anddi(y″→)⩾di(y′→)=di(y→).Let us examine level j. From Eq. (18) it follows thatδj(y→,y′→)⩾δj(y→,y″→)and from dominancedj(y″→)⩾dj(y′→). In consequence,(19)dj(y″→)-dj(y→)⩾dj(y′→)-dj(y→)>δj(y→,y′→)⩾δj(y→,y″→)and thereforey→≺Py″→.□When the lower bound function is monotoneLEXGO∗explores a subset of the labels explored byNAMOA∗, i.e. ifNAMOA∗does not explore a label(n,g→),LEXGO∗will not explore it either.A label(n,g→,f→)is not explored byNAMOA∗if: (a)∃c∗→∈C∗such thatc∗→≺f→, or (b)g→is dominated in n.It is quite straightforward thatLEXGO∗never explores a label discarded byNAMOA∗by condition (a). SinceCG∗⊆C∗, for allc∗∈C∗, eitherc∗∈CG∗, ord→B=d∗→≺Ld→(c∗→). In the latter case, if for somef→,c∗→≺f→, thend∗→≺Ld→(c∗→)⪯Ld→(f→). Therefore,LEXGO∗filters the labels with Eqs. (13) and (14).Let us consider now labels discarded byNAMOA∗by condition (b). Let us assume a nondominated pathP=(s,n,…,ni,…,nk)tonkrepresented by label(nk,g→,f→), and its two subpathsP1=(s,n,…,ni)andP2=(ni+1,…,nk). Let us also assume a dominated pathP′=(s,…,nk)tonkin OPEN with label(nk,g′→,f′→). Finally, lets assume thatP1is the largest subpath of P to enter OPEN, with label(ni,g→1,f→1). This situation is depicted in Fig. 4.Let us assume label(ni,g→1,f→1)is in OPEN. Since the lower bound function is monotone, as defined in Section 2.3,g→1+h→i⪯g→+h→k≺g′→+h→kandP′can never be selected byLEXGO∗. If eventually,ni=nkP′is dominated and pruned by P.On the other hand, if(ni,g→1,f→1)is never selected and not in OPEN, then there must be some other pathP3that prunedP1, i.e.f→(P3)≺Pf→(P1). By Lemma 1(b), we havef→(P3P2)≺Pf→(P1P2). This fact, together with the fact thatf→(P1P2)≺f→(P′), leads us to conclude by virtue of Lemma 1(c), thatf→(P3P2)≺Pf→(P′), i.e. if a path prunes some other nondominated path, then the extensions of the former will also prune those that would be pruned by the latter. Therefore, the property holds.□Once the efficiency ofLEXGO∗has been established, we turn our attention to admissibility, i.e. to prove that the subset of labels explored byLEXGO∗still includes all goal optimal solutions. A scalar algorithm is said to be admissible if it is guaranteed to return an optimal solution whenever a solution exists. We extend the definition as follows: a multiobjective search algorithm with goal-based preferences is admissible if it terminates with the set of all goal-optimal solutions to the problem.The proofs presented in this section rely on a set of reasonable assumptions, analogous to those presented in (Mandow & Pérez de la Cruz, 2010) to prove the admissibility ofNAMOA∗and other multiobjective label-setting algorithms:1.The graphG=(N,A)to be searched is locally finite, i.e. only a finite number of arcs emanate from each node.The lower bound functionh→(n)is admissible.AlgorithmLEXGO∗is admissible.LEXGO∗is a label-setting algorithm that generates partial paths from the start node to the destination. Each partial path is either expanded, filtered, or pruned. A goal-optimal solution could be pruned by pruning conditions (11) or (12) from Section 3.1, or could be filtered by filtering conditions (13) or (14) from Section 3.2. By definition, a goal-optimal solution has a nondominated cost. Since the optimality principle holds for dominated costs, neither pruning condition (11) nor filtering condition (13) will ever discard a goal-optimal solution.The proof for condition (12) follows. Let us assume two pathsP1=(s,…,n)andP2=(s,…,n), leading to the same node n, and an additional Pareto-optimal pathP3=(n,…,t)leading from n to a goal node. Let us callf1→=f→(P1)=g→(P1)+h→(n),f2→=f→(P2)=g→(P2)+h→(n). Since the lower bound is optimistic, we know thath→(n)⪯g→(P3). Let us calle→=g→(P3)-h→(n)⪰0→. ExtendingP1andP2withP3, the costs of both solutions are respectivelyf13→=g→(P1)+g→(P3)=g→(P1)+h→(n)+e→=f1→+e→andf23→=g→(P2)+g→(P3)=g→(P2)+h→(n)+e→=f2→+e→.Let us assume thatP1prunesP2in virtue of condition (12). Thenf1→≺Pf2→and, by Lemma 1(a),f13→=f1→+e→≺Gf2→+e→=f23→, so by this expansionP2does not lead to a better solution thanP1. Since no assumptions were made aboutP3, the result holds for every expansion of n, thereforeP2does not lead to a better solution thanP1and the pruning is correct.Finally, let us consider filtering condition (14), due to the lexicographic selection policy, the deviation of the first solution foundd→B=d→tis trivially equal or lexicographically better than the deviation of any other label in OPEN. No goal-optimal solution costc∗→∈CG∗with deviationd→(c∗→)can have worse lexicographical deviation thand→BTherefore, filtering condition (14) never filters goal-optimal solutions.Since LEXGO∗ never prunes nor filters goal-optimal solutions, the only remaining possibility is that they are all selected and found before termination, i.e.LEXGO∗is admissible.□

@&#CONCLUSIONS@&#
Multiobjective shortest path problems are computationally harder than single objective ones. Current exact algorithms can solve moderately sized problems with two objectives, but time quickly becomes a limiting factor as the size of the graph or the number of objectives grows. This paper explores the possibility of more efficient multiobjective analysis for those cases where the interesting portion of the Pareto front can be initially bounded. In practice, the efficient calculation of cost estimates described by Tung and Chew provides important information about the problem to be searched. In particular, the ideal point and at least an estimate of the nadir point are known before actual multiobjective search takes place.We introduceLEXGO∗, a new algorithm that returns the subset of the Pareto front defined by a set of lexicographic goal preferences. We define goal-optimal solutions as the subset of Pareto-optimal solutions that satisfy all goals or, when these cannot be satisfied, the subset of Pareto-optimal solutions that minimize deviation from the goals. Under reasonable assumptions the algorithm is formally guaranteed to return the set of goal-optimal solutions, and to explore a subset of the labels explored byNAMOA∗, the state-of-the-art multiobjective search algorithm. The algorithm is evaluated over a set of standard multiobjective problems with three objectives. As goals become more restrictive, results show a dramatic reduction of up to several orders of magnitude in the number of explored labels and execution time. In general, the improvement in performance is related to the reduction in the number of explored labels. However, in problems were goals are not satisfied, the special pruning condition developed forLEXGO∗can also have a fundamental influence in time performance.In cases where the interesting portion of the Pareto front can be bounded,LEXGO∗can be an algorithm of choice to reduce execution time from hours to seconds, or to explore harder multiobjective problems.