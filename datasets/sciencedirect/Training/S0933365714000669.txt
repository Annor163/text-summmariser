@&#MAIN-TITLE@&#
Cross-hospital portability of information extraction of cancer staging information

@&#HIGHLIGHTS@&#
We evaluate the portability across hospitals of machine learning-based text mining systems for colorectal cancer staging (TNM and ACPS).We present an architecture based on feature selection that allows to build a portable classifier with minimum cost, and we reach state-of-the-art performance.The results show that it is feasible to apply an existing TNM classifier to a new hospital without extra training, given that there is a feature normalisation step.

@&#KEYPHRASES@&#
Machine learning,Text mining,Information extraction,Cancer staging detection,Colorectal cancer,

@&#ABSTRACT@&#
ObjectiveWe address the task of extracting information from free-text pathology reports, focusing on staging information encoded by the TNM (tumour-node-metastases) and ACPS (Australian clinico-pathological stage) systems. Staging information is critical for diagnosing the extent of cancer in a patient and for planning individualised treatment. Extracting such information into more structured form saves time, improves reporting, and underpins the potential for automated decision support.Methods and materialWe investigate the portability of a text mining model constructed from records from one health centre, by applying it directly to the extraction task over a set of records from a different health centre, with different reporting narrative characteristics. Other than a simple normalisation step on features associated with target labels, we apply the models from one system directly to the other.ResultsThe best F-scores for in-hospital experiments are 81%, 85%, and 94% (for staging T, N, and M respectively), while best cross-hospital F-scores reach 84%, 81%, and 91% for the same respective categories.ConclusionsOur performance results compare favourably to the best levels reported in the literature, and—most relevant to our aim here—the cross-corpus results demonstrate the portability of the models we developed.

@&#INTRODUCTION@&#
As new technologies for health care are deployed, increasing access to electronic information opens opportunities for improved productivity and decision support. Pathology reports are one rich source of valuable patient information: these contain cell and tissue data and are often critical in determining presence of certain diseases and performing diagnosis. Pathology reports are typically semi-structured, containing distinguishable components but with most information in free text (though often abbreviated or terse). One specific important use of information in certain pathology reports is in determining cancer staging, i.e., describing the extent of cancer within a patient. This is most usually represented via the TNM (tumour-node-metastases) scale (described below), a global standard defined by the American Joint Committee on Cancer (AJCC) and International Union Against Cancer (UICC) [1]. Information to determine cancer staging is typically contained within the text of pathology reports but needs to be extracted, in particular for conversion to the TNM scale. While there is a proposed move towards synoptic (highly structured) reports, few reports (historically, virtually none) are in this format and text processing is required to automatically access the required information.Identifying cancer stage is a critical clinical and analytic task. For an individual patient, staging information is essential for clinical decision making and determining optimal treatment [2]. For population-based cancer registries, staging data is crucial in determining overall treatment outcomes and planning research and resource allocation [3]. However extracting data from free-text pathology reports is a resource-intensive activity requiring skilled staff to manually process each report. Even when protocols for collection exist, different studies have found serious problems with completeness [4–6], along with manual encoding errors [4,5,7,8]. These problems are considered sufficiently large to be part of the Cancer Australia's National Cancer Data Strategy, where it is noted that “Traditional methods of clinical cancer registration are likely to be too labour-intensive to be sustainable”.11canceraustralia.gov.au/publications-resources/cancer-australia-publications/national-cancer-data-strategy-australia (accessed 17 April 2014).Consequently, the ability to automatically extract staging data from pathology reports will assist both individual patient care and population-based analysis of outcomes. We explore the application of text mining, a combination of natural language processing (NLP) and machine learning (ML) techniques, to this task.Text mining tools that perform well on the task of extracting staging information from pathology reports are likely to have important impact on clinical practice and collection of data for cancer registries and population-based studies. They can also be the building blocks of data mining methods that exploit large data for cancer prognosis [9,10]. The main challenges for developing widely-applicable text mining tools are the need for expert domain knowledge (by means of hand-coded rules or manual annotation), and the portability to different environments. However a recent systematic literature review [11] has shown limitations of existing text mining tools for the biomedical domain, which tend to be very context-dependent and not readily portable. The question of portability has been little studied, but is central to developing systems robust enough for wide clinical implementation.In this paper, we describe a text mining tool based on using machine learning with light training-data annotation needs, for the task of extracting cancer-staging information for colorectal cancer. Our tool relies on manually annotated pathology reports for learning and for evaluation, where domain experts provide the cancer staging codes that correspond to the textual information in each pathology report. Our annotation requirement is at document level, i.e., labels are assigned to full documents (e.g., a full report is given the “staging N1” category) rather than finer linguistic levels (e.g., the phrase “3 positive lymph nodes” is given the “staging N1” category). This considerably alleviates the annotation effort (cf. [12]) and makes the techniques more scalable, given that we can address portability across different styles of pathology reports.We specifically investigate the issue of portability of our system across distinct data sets from different hospitals. We extend our previous work on this topic [13], and apply an information extraction model that was trained from a collection of reports obtained from one health precinct—Melbourne Health—directly to a collection of reports from another—Barwon Health: these are two distinctly different health centres covering different geographical regions in the state of Victoria in Australia. The data involves differences in pathology reporting formats and authoring patterns, but also different linguistic characteristics in the authored reports. Initial performance was improved by adding a simple term-mapping approach, directed by a feature selection algorithm, resulting in clear performance stability.Initial work over this multi-site dataset was previously reported in [14]. In the current article, we extend the analysis of the performance of our system, and also compare our results with the use of an open-source tool—MedKAT/P[15]—for automatically processing pathology reports. Our analysis demonstrates the limitations of off-the-shelf systems, and highlights the importance of using feature selection for normalising different datasets.

@&#CONCLUSIONS@&#
We have described and evaluated a text mining approach for extracting staging information from pathology reports. The method uses multi-class classification models developed from training data that was only very lightly annotated: i.e., the main categories were annotated only at document level, and not at the level of clinical concepts or shorter spans of text.The main focus of this paper was to demonstrate the portability of the constructed models by using corpora from two different hospitals (RMH, Barwon) and training on one corpus and testing on the other. We used feature selection for tuning the classifiers, and simple rules to identify numeric values for “staging N”. A simple rule was used to map feature-labels, but otherwise the models were run as trained on the alternative corpus. We showed strong performance for TNM classification, even across corpora, with F-scores of 81–84% for T, 85–96% for N, and 87–91% for M. Our performance results compare favourably to the best levels reported in the literature, and—most relevant to our aim here—the cross-corpus results demonstrate the portability of the models we developed.For future work we aim to work on optimising the parameters of the different algorithms we tested, and on applying our framework to different hospitals. We would also like to analyse the annotation processes for “staging ACPS”, which was been the most challenging category in our study.