@&#MAIN-TITLE@&#
Distributed parameter system identification using finite element differential neural networks

@&#HIGHLIGHTS@&#
We proposed a method to solve the identification of uncertain distributed parameter systems.We developed a novel DNN structure based on the finite element method.We derived adaptive learning laws using Lyapunov's second method.The identification algorithm is developed in Nvidia's CUDA/C to reduce the execution time.The FEM-DNN algorithm that we present was compared with a neural network trained using group search optimization or GPO-NN, and showed a superior performance.The algorithm was validated with a 3D simulated DPS and tested on a physical 2D experiment.

@&#KEYPHRASES@&#
Distributed parameter systems,Non-parametric identification,Differential neural network,Finite element method,CUDA/C,Parallel numerical solutions,

@&#ABSTRACT@&#
Most of the previous work on identification involves systems described by ordinary differential equations (ODEs). Many industrial processes and physical phenomena, however, should be modeled using partial differential equations (PDEs) which offer both spatial and temporal distributions that are simply not available with ODE models. Systems described by a PDE belong to a class of system called distributed parameter system (DPS). This article presents a method for solving the problem of identification of uncertain DPSs using a differential neural network (DNN). The DPS, assumed to be described by a PDE, is approximated using the finite element method (FEM). The FEM discretizes the domain into a set of distributed and connected nodes, thereby, allowing a representation of the DPS in a finite number of ODEs. The proposed DNN follows the same interconnection structure of the FEM, thus allowing the DNN to identify the FEM approximation of the DPS in both 2D and 3D domains. Lyapunov's second method was used to derive adaptive learning laws for the proposed DNN structure. The identification algorithm, here developed in Nvidia's CUDA/C to reduce the execution time, runs mostly on the graphics processing unit (GPU). A physical experiment served to validate the 2D case. In the experiment, the DNN followed the trajectory of 57 markers that were placed on an undulating square piece of silk. The proposed DNN is compared against a method based on principal component analysis and an artificial neural network trained with group search optimization. In addition to the 2D case, a simulation validated the 3D case, where input data for the DNN was generated by solving a PDE with appropriate initial and boundary conditions over an unitary domain. Results show that the proposed FEM-based DNN approximates the dynamic behavior of both a real 2D and a simulated 3D system.

@&#INTRODUCTION@&#
Many industrial processes and physical phenomena belong to a class of system called distributed parameter system (DPS). Heat transfer, wave propagation, particle diffusion, stress analysis, electric and magnetic fields are only a few examples of problems and real world phenomena that fall into the DPS class. Partial differential equations (PDEs) are widely used in different fields of physics and engineering to model DPSs. Systems modeled by PDEs present temporal and spatial distributions that are not available with ordinary differential equation (ODE) models. Analytical solutions for PDEs, however, are usually very hard to obtain. When no analytical solution can be achieved, numerical methods can be implemented to approximate a solution to these equations. Among the available methods finite differences [1], weighted residual procedures [2] and the finite element method (FEM) [3] are the most popular. These techniques can give an approximate solution to the system modeled by PDEs with a certain degree of accuracy; however, the PDE structure must be known a priori.When there is not sufficient information or insight about the underlying dynamics of the system such that a differential equation cannot be derived with sufficient accuracy, non-parametric identification techniques based on measured data can be employed to approximate the dynamic system. One modeling technique is based on artificial neural networks which, for simplicity, will be referred as neural networks (NNs), the selection of this soft computing approach is the deepest mathematical analysis that can be done with NN instead of other methods. Previous researches have shown that a static single hidden layer feedforward NN can approximate any continuous nonlinear function arbitrarily well [4,5]. Unfortunately, they are inadequate for system identification of dynamic systems since they can only encode limited temporal information using delays in both inputs and outputs. One alternative to NNs resides in using a dynamic neural network (DyNN), introduced by Hopfield [6], which differ from the static NNs in that DyNNs have at least one feedback loop. This feedback loop produces a nonlinear dynamic behavior. A continuous time DyNN whose equation can be described by a differential equation is called a differential neural network (DNN). DNNs are appropriate for identification, since most systems are nonlinear and dynamic and are assumed to be described by differential equations [7].NN have been successfully applied to approximate the trajectories of differential equations. Lagaris et al. developed a method to solve initial and boundary value problems for both ODEs and PDEs using feedforward NNs [8]. The equation, however, must be known and the method is limited to finding an approximate solution to the given equation. Ramuhalli et al. proposed a method that embeds the finite element model in the structure of a NN, allowing faster execution than the regular FEM. The authors also performed parametric identification for a 2D Poisson's equation. Their method assumes that the structure of the PDE and boundary and initial conditions are completely known [9].Narendra et al. presented one of the first works that used DNNs in the context of identification [10,11]. They introduced the concept of dynamic back propagation to train DNNs that were used for identifying several simulated nonlinear ODEs. The stability of the identification error, however, could not be guaranteed and their method was limited to ODEs. Subsequently, Rovithakis and Christodoulou used Lyapunov's second method to derive adaptive learning laws which did guarantee the stability and convergence of the identification error [12]. Since then, several researchers have used this Lyapunov-based approach to derive adaptive learning laws for each of their DNNs [13–18]. Nevertheless, all of these approaches assume that the identified system can be described by ODEs not allowing the use of PDEs; hence, most of the work with DNNs for identification focus on problems only in 1D.To deal with DPSs, González-García et al. integrated a static NN with the finite difference method (FDM). Their method, however, was not adaptive requiring offline training data to minimize the static NN error [19]. Recently, Fuentes et al. developed a DNN based on the finite difference method (FDM) that worked in 3D space [20]. In contrast to [19], they used a DNN with adaptive learning laws derived from the Lyapunov method. Even though the FDM method used by Fuentes et al. allows the DNN to work in 3D domains, their method required an evenly distributed mesh; therefore, the shape of the domain of the system was limited. Later, Fuentes et al. [20] used DNNs to approximate the dynamic behavior of the FEM approximation of a 2D DPS. In that work, a NN followed the trajectory of each element and then a global DNN was used to assemble the solution of the DNNs at each node [21]. Aggelogiannaki et al. presented a radial basis function (RBF) neural network to model the dynamics of DPS in two parts; in the fist one, RBF network model is used to describe only the temporal part of the system. In a second step, the sequences of temporal coefficients are used to train the NN model, in which past values of the manipulated variables provide the input information [22]. In [23], Bisoi et al. presents an IIR filter based on dynamic neural network (DyNN) and an optimized adaptive unscented Kalman filter for forecasting price indices of four different stocks. Four different learning strategies are used to adjust the DyNN weights. Even when the method is innovative, a DPS application of the method is not presented. On the other hand, Kumar Singh et al., in [24], presents a dynamic classification of different ranges of ballistic missiles for air defense application where a dynamic classification is formulated using real-time neural network (RTNN) and hidden Markov model. The idea behind these algorithms is to calculate the output in a single pass rather than training and computing over a large number of iterations. Chen et al. proposed a collaborative intelligence approach that takes into account the different points of view provided by a group of domain experts who configure the fuzzy feed-forward NN to forecast the yield based on their views. Wang et al. propose an adaptive ANN model for nonlinear parabolic DPSs. The improved group search optimization (IGSO) approach is proposed to optimize the connection weights and thresholds of the NN to solve the problem of falling into the local optima [25]. The authors report that their method can effectively capture the slowly changing of a process dynamics while decreasing the computational cost.This article proposes an identification algorithm to solve the problem of identification of uncertain DPSs. The DPS, assumed to be described by a PDE, is approximated using the FEM. The algorithm uses a DNN with a structure that follows the FEM connecting rules to identify the FEM approximation to the PDE. No other works use hidden layers in the approximation of PDE. This method allows the DNN to deal not only with ODEs, but also PDEs with 2D and 3D arbitrary domains. In contrast to [21], each state of the DNN tracks one node of the FEM discretization of the domain with no intermediate element results. Additionally, the DNN is implemented in such a way that it runs mostly on the graphics processing unit (GPU) thus taking advantage of the highly parallel nature of these devices, and thereby reducing the execution time significantly. In particular, NVIDIA's Compute Unified Device Architecture (CUDA) is employed in order to implement the aforementioned algorithm. This proposed identification algorithm is then validated with a simulated 3D DPS and then experimentally with a physical 2D DPS. Finally, a comparison between the proposed algorithm performance and the method reported by [25,26] is done.The finite element method (FEM) is widely used for solving problems in almost every field of engineering analysis. Initially, this method was used to solve problems in structural mechanics; with the emerging computational power, however, scientists and engineers soon realized the capabilities of the FEM to solve physical engineering problems described by a set of differential equations [3]. The key idea behind the finite element procedures is to replace a continuous function with a set of algebraic equations or ODEs for transient problems. To achieve this, the domain must be partitioned into smaller subdomains called elements which may take different shapes, for example triangles for 2D problems and tetrahedra for 3D.The finite element method is a special case of the Galerkin formulation in which the trial functions are selected as piecewise continuous functions defined by nodal values. The nodal values come from a discretization of the domain into small subdomains called finite elements. These elements can take different shapes depending on the domain and accuracy needed. The most common type of element in 2D domains is the triangular element, which is formed by three nodes (Fig. 1). For two dimensional linear elements (this can easily be extended to the 3D case) the solution inside the element e is assumed to have the form:(1)u¯e=a1+a2x+a3ySince these interpolation functions must represent the values at each of the three nodes of the element, we haveuie=a1+a2xie+a3yiefor i=1, 2, 3, where the subscript i represents the nodes conforming element e. Solving for each ajand substituting back to Eq. (1) we obtain a solution inside the element e with the form:(2)u¯e=H1e(x,y)u1e+H2e(x,y)u2e+H3e(x,y)u3ewhereu¯eis the solution inside the element e and eachHpe(x,y), for p=1, 2, 3, depends on the node coordinates and size of the element. Moreover,upefor p=1, 2, 3 represent the three nodes conforming element e (Fig. 2). By using the Galerkin method and expressing it in vector form we have:(3)u¯e=H1eH2eH3eu1eu2eu3e,we=∂u¯e∂aj=H1eH2eH3eSubstituting into the weak form of the problem we can express these equations as Keue=fe, whereKe∈R3×3, e represents the current element,ue=[u1eu2eu3e]⊤is a vector containing the nodal values, andfe=[f1ef2ef3e]⊤comes from the right hand side of the weak form of the problem. The equation for each element is assembled into a global matrix with a resulting equation:(4)Ku=fwhereK∈Rn×nis called the stiffness matrix and n represents the number of nodes. The f term corresponds to the source term in the PDE or ODE that is being solved. The problem is now solving u in the system in Eq. (4). More information about the set-up and assembly of these equations is available in [27].Let us consider the following DNN structure:(5)uˆt=Auˆ+W1σ(V1uˆ)whereuˆ=uˆ(x,y,z,t)∈Rpis the state of the system,σ:Rp→Rpis a vector of sigmoid functions for nonlinear state feedback,A∈Rp×pis a Hurtwitz matrix representing the linear state feedback,W1=W1(t)∈Rp×pandV1=V1(t)∈Rp×pare weight matrices for the DNN nonlinear state feedback. The matrix V1 represents a hidden layer which improves the approximation capabilities of the DNN [7]. Notice that there is not an input term in Eq. (5), each state of the DNN is determined by its own value and that of its connected states. This connection is given by the structure of matrices V1 and W1.The main difference between our approach and previous approaches is that the states of a single DNN are connected following the FEM connecting rules, thereby allowing the identification of the FEM approximation of DPSs in two or three dimensions. The DPS is discretized following the FEM, generating n nodes. Each state of the DNN in Eq. (5) is assigned to one node of the DPS, thus p=n. Throughout the rest of this article each state of the DNN is referred as a node of the DNN.Both matrices V1 and W1 have the same structure as the stiffness matrix K of the finite element method (Eq. (4)). This means that each elementW1ij=0andV1ij=0if Kij=0, where the subscripts i, j represent the row and column respectively, regardless of the partition used for the DPS. The non-zero elements of both matrices are obtained by solving Eq. (10).Matrix V1 resulting structure for a 2D domain with triangular elements is a sparse matrix. As is the case with the FEM, each element of this matrix V1,V1ijis non-zero if node j contributes to the value of node i and zero otherwise. The matrix W1 in Eq. (5) has the same form as V1, which means thatW1ij=0if, and only if,V1ij=0for all t. Notice that the structure of both V1 and W1 is determined by the domain partition and the type of elements used to generate the mesh. In the case of a 3D domain, the resulting matrix is similar to V1 but with more non-zero elements per row, since each node is affected by all of its neighbors. For example, in using tetrahedral elements, each row of the matrix has up to 15 non-zero elements, since each node has at most that number of neighboring nodes contributing to its value, including the node itself. The DNN in Eq. (5) with weight matrices that have the structure of V1 will be referred as FEM DNN throughout the rest of this document.Consider a 3D DPSs described by PDEs that is discretized according to the FEM connecting rules with n nodes:(6)ut=f(x,y,z,t,u,ux,uy,uz,uxx,…,uzx,…,uxyz,…)+ξ(x,y,z,t)whereu=u(x,y,z,t)∈Rnis defined, without lost of generality, in a domain x∈[0, 1], y∈[0, 1], z∈[0, 1] and uh=uh(x, y, z, t), where h represents t, x, y, z, xx, …, xy, …, zx, … andξ(x,y,z,t)∈Rnis a perturbation in the system, which is assumed to be bounded as:ξΛξ=ξ⊤Λξξ≤γwhereΛξ∈Rn×nis a positive definite matrix andγ∈R+. Eq. (6) is assumed to be a well-posed PDE problem with an appropriate set of initial and boundary conditions such that u exists and has a unique solution. In Eq. (6) and throughout the paper,ut=∂u∂t,ux=∂u∂x,uxx=∂2u∂x2,uzx=∂2u∂z∂xand so forth.For the given DNN structure in Eq. (5), it is assumed that there exists a set of parametersV∘1∈Rn×n,W∘1∈Rn×nsuch that the DPS in Eq. (6) can be represented by a DNN with the structure of Eq. (5) as:(7)ut=Au+W∘1σ(V∘1u)+ξ+f˜wheref˜=f˜(x,y,z,t)represents the modelling error and is defined asf˜=ut−[Au+W∘1σ(V∘1u)+ξ]Additionally, we assume that they are bounded as:f˜Λ3=f˜⊤Λ3f˜≤η¯whereΛ3∈Rn×nis a positive definite matrix andη¯∈R+. Additionally,σ:Rn→Rnis a vector of sigmoidal functions, commonly used in NNs. This function satisfies the following conditions:(8)‖σ(v1˜)−σ(v2˜)‖2≤Lσ‖v1˜−v2˜‖2σ˜⊤Λ1−1σ˜≤Δ⊤Λ1−1Δ(σ˜′)⊤Λ2σ˜′≤(V˜uˆ)⊤Λ2(V˜uˆ)where Δ=Δ(x, y, z, t) is the identification error defined asΔ=uˆ−u. Moreover,σ˜=σ(V∘1uˆ)−σ(V∘1u),σ˜′=σ(V1uˆ)−σ(V∘1uˆ)and Λ1, Λ2 are known normalizing positive constant matrices. Because the sigmoid function σ is differentiable and satisfies the Lipschitz condition, it can be verified that(9)σ˜′=‖σ(V1uˆ)−σ(V∘1uˆ)‖≤DV˜1uˆ+νD=maxZ∈Rn∂σ(Z)∂Z,νΛ22≤lV˜1uˆΛ12,l>0V˜1=V1−V∘1The weight matrices in Eq. (5) are adaptive and each termW1ijandV1ijis, by itself, an ODE and must be solved simultaneously with the DNN equation. These weight equations are called the “learning rules” for the DNN and are given by the following equations:(10)W1˙=−K1PΔσ⊤+K1PΔuˆ⊤(V1−V10)DV˙1=−K2D⊤W1⊤PΔuˆ⊤−l2K2Λ2(V1−V10)uˆuˆ⊤whereK1,K2∈Rn×nare positive definite matrices and P is the positive definite solution (P>0) of the algebraic Riccati equation:(11)PA+A⊤P+PRP+Q=0whereR=W¯1+Λ3+ΛξandQ=Q0+Λ1−1, Q0 is a positive definite matrix andW∘1(Λ1+Λ2−1)W∘1⊤≤W¯1. The Special Class of the Riccati equation (Eq. (11)) has a positive solution if the given conditions in [7] are fulfilled.The main result described in this paper is given in the following theorem:TheoremConsider the uncertain and perturbed non-linear system described by a PDE and approximated by the FEM in Eq.(6). It is assumed that it is possible to have discrete measures at all the nodes which correspond to a finite number of points on the domain. The measured data define the system state vector u(t). Moreover, suppose the structure of the non-parametric adaptive identifier in Eq.(5). The dimension of the state vector of the identifier is defined according to the number of available nodes. Each node of the system is assigned to one state of the FEM DNN. The parameters of the identifier are adjusted according to the adaptive learning laws given in Eq.(10). If there exists a positive definite matrix Q such that the Riccati equation (Eq.(11)) has a positive definite solution P, then the identification error Δ satisfies the following tracking performance:(12)limT→∞sup1T∫0TΔ⊤Q0Δdt≤η¯+γProofThe detailed proof is given in Appendix A. □

@&#CONCLUSIONS@&#
This article presented a method to solve the problem of identification of uncertain 2D and 3D distributed parameter systems (DPSs) using a DNN with a structure based on the FEM. The DPS, described by PDEs, can be approximated by using the FEM to form a system of ODEs that correspond to the solutions for the nodes on the domain. The DNN with a structure that follows the FEM connecting rules. These connecting rules allow DNNs, which have usually been used with ODEs, to deal with approximated PDEs in 2D and 3D spatial domains. A Lyapunov approach was used to derive adaptive learning laws for the weight matrices. The method was validated numerically both on a simulated 3D system and on a real 2D physical system. The DNN identification MSE was shown to be stable in both cases. The experiments showed that the DNN tracked the trajectory of both systems within the initial 0.1s. A comparison between GPO-NN and FEM DNN algorithms showed that the identifier proposed in this work presents a superior performance. This comparison only considered the mean square error (MSE) measure, our approach produced the lowest MSE among the two identification algorithms. This approach is useful for the non-parametric identification of DPSs in which the system is discretized and approximated using the FEM.Proof of the TheoremThe candidate Lyapunov function is defined as:(A.1)V(Δ,W1˜,V1˜)=∥Δ∥P2+tr(W1˜⊤K1−1W1˜)+tr(V1˜⊤K2−1V1˜)Taking the full time derivative:(A.2)dV(t)dt=dVdt(Δ(t),W1˜(t),V1˜(t))=2(Δ(t))⊤PdΔdt(t)+2tr(W1˜(t))⊤K1−1dW1˜dt(t)+2tr(V1˜(t))⊤K2−1dV1˜dt(t)SinceΔ(t)=uˆ(t)−u(t), and considering (5) and (7) we have:dΔ(t)dt=AΔ(t)+W1(t)σV1(t)uˆ(t)−W∘1σ(V∘1u(t))−f˜(x,y,z,t)−ξ(x,y,z,t)Adding and subtracting the termsW∘1σ(V1uˆ)andW∘1σ(V∘1uˆ):(A.3)dΔ(t)dt=AΔ(t)+W1˜(t)σ(V1(t)uˆ(t))+W∘1σ˜′(t)+W∘1σ˜(t)−f˜(x,y,z,t)−ξ(x,y,z,t)whereW1˜(t)=W1(t)−W∘1. Substituting (A.3) in (A.2) we have:(A.4)dV(t)dt=2(Δ(t))⊤P[AΔ(t)+W1˜(t)σ(V1(t)uˆ(t))+W∘1σ˜(t)+W∘1σ˜′(t)−f˜(x,y,z,t)−ξ(x,y,z,t)]+2tr(W1˜(t))⊤K1−1dW1˜dt(t)+2tr(V1˜(t))⊤K2−1dV1˜dt(t)Using the matrix lambda inequalityX⊤Y+(X⊤Y)⊤≤X⊤Λ−1X+Y⊤ΛYwhich is valid for anyX,Y∈Rm×kand for any matrix positive defined0<Λ=Λ⊤∈Rm×m, the terms2Δ⊤PW∘1σ˜,−2Δ⊤Pf˜and −2Δ⊤Pξ can be estimated as:(A.5)2Δ⊤PW∘1σ˜≤σ˜⊤Λ1−1σ˜+Δ⊤PW∘1Λ1W∘1⊤PΔ(A.6)−2Δ⊤Pf˜≤f˜⊤Λ3−1f˜+Δ⊤PΛ3PΔ(A.7)−2Δ⊤Pξ≤ξ⊤Λξ−1ξ+Δ⊤PΛξΔUsing (8) and (9) and substituting (A.5), (A.6) and (A.9) in (A.4)(A.8)dV(t)dt≤(Δ(t))⊤[PA+A⊤P+PW∘1Λ1W∘1⊤P+PΛ3P+PΛξP]Δ(t)+2(Δ(t))⊤PW1˜σ(Vuˆ)+(σ˜(t))⊤Λ1−1σ˜(t)−2(Δ(t))⊤PW1˜(t)DV1˜(t)uˆ(t)+2(Δ(t))⊤PW1(t)DV1˜(t)uˆ(t)+2(Δ(t))⊤PW∘1ν+(f˜(x,y,z,t))⊤Λ3−1f˜(x,y,z,t)+(ξ(x,y,z,t))⊤Λξ−1ξ(x,y,z,t)+2tr(W1˜(t))⊤K1−1dW1˜dt(t)+2tr(V1˜(t))⊤K2−1dV1˜dt(t)The term2(Δ(t))⊤PW∘1νcan be estimated as:(A.9)2(Δ(t))⊤PW∘1ν≤(Δ(t))⊤PW∘1Λ2−1W∘1⊤PΔ+l‖V1˜uˆ‖Λ22Adding and subtracting (Δ(t))⊤Q0Δ(t) and substituting (A.7) in (A.8) we have:(A.10)dV(t)dt≤−(Δ(t))⊤Q0Δ(t)+(f˜(x,y,z,t))⊤Λ3−1f˜(x,y,z,t)+(ξ(x,y,z,t))⊤Λξ−1ξ(x,y,z,t)+(Δ(t))⊤[PA+A⊤P+PRP+Q]Δ(t)+2tr(W1˜(t))⊤K1−1dW1˜dt(t)+2(Δ(t))⊤PW1˜(t)σ(V1(t)uˆ(t))−2(Δ(t))⊤PW1˜(t)DV1˜(t)uˆ(t)+2tr(V1˜(t))⊤K2−1dV1˜dt(t)+2(Δ(t))⊤PW1(t)DV1˜(t)uˆ(t)+lΛ2V1˜(t)(uˆ(t))⊤uˆ(t)whereR=W∘1(Λ1+Λ2−1)W∘1⊤+Λ3+Λξ,Q=Q0+Λ1−1. From the weight Eqs. (10) and the special class of Riccati equation (11):dV(t)dt≤−(Δ(t))⊤Q0Δ(t)+(f˜(x,y,z,t))⊤Λ3−1f˜(x,y,z,t)+(ξ(x,y,z,t))⊤Λξ−1ξ(x,y,z,t)≤−(Δ(t))⊤Q0Δ(t)+η¯+γIntegrating both sides from 0 to T:∫0T−(Δ(t))⊤Q0Δ(t)dt≤−∫0TdV(t)+(η¯+γ)TDividing both sides by T:1T∫0T−(Δ(t))⊤Q0Δ(t)dt≤V(0)T+(η¯+γ)Taking the superior limit as T→∞ we have (12). □