@&#MAIN-TITLE@&#
Modeling false positive error making patterns in radiology trainees for improved mammography education

@&#HIGHLIGHTS@&#
A method for predicting trainees’ false positive locations in mammography is proposed.This is the first exploratory study on the topic using computer algorithms.Predictions are made using 133 imaging features and a random forest classifier.The predicted locations are more accurate than the locations selected randomly.The method can select educational material with more challenging locations.

@&#KEYPHRASES@&#
Breast cancer,Radiology education,Computer vision,Machine learning,

@&#ABSTRACT@&#
IntroductionWhile mammography notably contributes to earlier detection of breast cancer, it has its limitations, including a large number of false positive exams. Improved radiology education could potentially contribute to alleviating this issue. Toward this goal, in this paper we propose an algorithm for modeling of false positive error making among radiology trainees. Identifying troublesome locations for the trainees could focus their training and in turn improve their performance.MethodsThe algorithm proposed in this paper predicts locations that are likely to result in a false positive error for each trainee based on the previous annotations made by the trainee. The algorithm consists of three steps. First, the suspicious false positive locations are identified in mammograms by Difference of Gaussian filter and suspicious regions are segmented by computer vision-based segmentation algorithms. Second, 133 features are extracted for each suspicious region to describe its distinctive characteristics. Third, a random forest classifier is applied to predict the likelihood of the trainee making a false positive error using the extracted features. The random forest classifier is trained using previous annotations made by the trainee. We evaluated the algorithm using data from a reader study in which 3 experts and 10 trainees interpreted 100 mammographic cases.ResultsThe algorithm was able to identify locations where the trainee will commit a false positive error with accuracy higher than an algorithm that selects such locations randomly. Specifically, our algorithm found false positive locations with 40% accuracy when only 1 location was selected for all cases for each trainee and 12% accuracy when 10 locations were selected. The accuracies for randomly identified locations were both 0% for these two scenarios.ConclusionsIn this first study on the topic, we were able to build computer models that were able to find locations for which a trainee will make a false positive error in images that were not previously seen by the trainee. Presenting the trainees with such locations rather than randomly selected ones may improve their educational outcomes.

@&#INTRODUCTION@&#
Mammography is the most widely used screening technique for breast cancer early detection, which plays an important role in reducing the mortality of breast cancer. However, interpretation of mammograms is a very challenging task due to overlapping tissue that might both obscure signs of cancer (false negative errors) as well as create patterns that resemble true abnormalities and unnecessarily alert a radiologist (false positive errors) [3].Our group has been working on the development of an adaptive computer-aided education system for mammography education. Specifically, in [12], we proposed a general framework for such a system and demonstrated that image features can be used to predict errors made by a trainee. In [13], we presented models for prediction of errors in assignment of BI-RADS features of masses and images. In [14], we investigated the use of collaborative filtering algorithms to model resident errors in mammography. Other work on the adaptive mammography education is limited; however, some related studies are available. Sun et al. [18,19] presented initial studies on developing an ontology related educational training system based on differences between radiologists. The studies by Mello-Thoms et al. [15], Tourassi et al. [22], Voisin et al. [23] investigate visual attention and spatial frequency representations, human perception and cognition, and eye gaze tracking to study error making in mammography. Some work in computer-aided detection is also relevant to our study in terms of the computer vision methods used, such as the studies presented by Masotti et al. [11], Wei et al. [24], and Mudigonda et al. [16].In this paper we focus on a topic largely unexplored in the context of radiology education: false positive error making. Specifically, the task that we approach is to automatically find locations that will cause a trainee to make a false positive error. For this purpose, we propose an algorithm that identifies challenging locations using computer vision algorithms and machine learning models. The models are constructed individually for each trainee based on their prior interpretations to capture their individual error making patterns.To our knowledge, this is the first study in which future false positive locations are predicted. It differs from our previous studies in which we focused on false negative errors [8], errors in distinguishing benign and malignant masses [12], and errors in assessment of BI-RADS features [13]. Predicting false positive locations is a difficult task as it requires analysis of the entire image and finding those locations that might cause difficulty to the trainee while dismissing all the locations that will not. While our experiments confirm the high difficulty of the task, they also show the promise of our approach. One practical application of our approach is to identify locations that would result in false positive errors for each trainee so that they can focus their training on such locations, potentially improving their training.To validate our algorithm for predicting false positive errors, we used data from a reader study in which 10 radiology trainees along with 3 expert radiologists interpreted 100 mammographic cases independently. Among the 10 trainees, 7 were radiology residents with at least four weeks of formal breast imaging training and 3 were novices (2 medical imaging researchers and 1 medical student) with no formal training. We included the three novices to simulate radiology residents at the very beginning of their residency program. The threeexpertradiologists were all fellowship trained in breast imaging with 7–14years of experience. The experts and the trainees were not aware of patients’ age and medical history. The 100 mammographic cases are balanced with 50 cases originally deemed as normal and 50 abnormal cases. Each case contained 4 standard mammographic views: left craniocaudal (LCC), right craniocaudal (RCC), left mediolateral oblique (LMLO), and right mediolateral oblique (RMLO). All participants were asked to identify actionable abnormalities by clicking on them. We asked the participants to ignore microcalcifications as the focus of our study was on masses. Institutional Review Board approval was secured for this study.We used the marks provided by the three experts to find the actual actionable masses. Specifically, if a region contained at least two out of three experts’ marks and the distance between two marks was smaller than a predefined threshold Td, we considered this region to be associated with an actionable mass. The centers of actual actionable masses were determined as the centroids of the expert annotations. Consequently, if the distance between a trainee’s mark and its nearest actionable mass center is bigger than Td, this mark is defined as a false positive error. Otherwise, it is defined as a true positive. Because the average radius of the breast masses is 9mm [21] and the pixel spacing of the images used in the reader study was 0.0941mm, the threshold was set to Td=9mm/0.0941mm=96 pixels in our study.

@&#CONCLUSIONS@&#
