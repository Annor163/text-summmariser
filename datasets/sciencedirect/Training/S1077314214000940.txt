@&#MAIN-TITLE@&#
Quadra-embedding: Binary code embedding with low quantization error

@&#HIGHLIGHTS@&#
Novel binary code embedding method reducing quantization error is proposed.We assign two bits for each projection to reduce errors near its boundary.A distance function and a partitioning criteria are tailored to our method.We obtain higher accuracy in nearest neighbor search.It can be easily applicable to most of binary hashing methods.

@&#KEYPHRASES@&#
Large-scale image retrieval,Binary code embedding,Hashing,Quantization,

@&#ABSTRACT@&#
Thanks to compact data representations and fast similarity computation, many binary code embedding techniques have been proposed for large-scale similarity search used in many computer vision applications including image retrieval. Most prior techniques have centered around optimizing a set of projections for accurate embedding. In spite of active research efforts, existing solutions suffer from diminishing marginal efficiency and high quantization errors as more code bits are used.To reduce both quantization error and diminishing efficiency we propose a novel binary code embedding scheme, Quadra-Embedding, that assigns two bits for each projection to define four quantization regions, and a binary code distance function tailored to our method. Our method is directly applicable to most binary code embedding methods. Our scheme combined with four state-of-the-art embedding methods has been evaluated and achieves meaningful accuracy improvement in most experimental configurations.

@&#INTRODUCTION@&#
Scalable and efficient similarity search plays a key role in many large-scale computer vision applications dealing with high-dimensional data space. One example is the web-scale image retrieval. Common image descriptors, e.g., Bag-of-visual-Words or GIST, used for image retrieval have hundreds or thousands of dimensionality, and there are billions of images available on the web.Traditional solutions adopting hierarchical structures (e.g., kd-trees) [1,2] do not provide sufficient scalability in terms of both computational time and storage costs for high-dimensional, large-scale data sets. Recently, embedding high-dimensional data to short binary codes has been recognized as one of the most promising approaches to address both high-dimensionality and scalability issues of data, since it can provide a compact representation for data and efficient similarity search. Consequently, a lot of binary code embedding algorithms have been studied lately [3–12]. The core goal of binary code embedding methods is to preserve similarities among original high-dimensional data in the corresponding binary codes, i.e. neighbor data points in the original high-dimensional space should be encoded to similar binary codes.Most binary embedding methods compute a binary code of each data element using multiple projections, which can be categorized into two groups: data-independent and data-dependent methods. Data-independent methods construct the projections based on vectors randomly drawn from some specific distributions. The well-known work in this category is locality-sensitive hashing (LSH) [13]. LSH is extended to various similarity metrics [4,6,7]. However, recent researches give more attentions to data-dependent methods for designing more data-friendly projections in order to achieve the higher accuracy. Notable examples include spectral hashing [5], sequential projection [8], joint optimization [9], and iterative quantization [10].Despite the intensive research efforts to obtain effective projections, there are still remaining issues; (1) diminishing returns as the number of projections increases, and (2) quantization errors in high-density regions. The main cause of the diminishing return is the growing difficulty of defining both independent and informative projections, as the number of projections increases. In regard to the quantization error, quantization boundaries are usually within dense regions, causing that neighbor data points are assigned to different binary codes [14]. In this paper we aim to resolve these two issues. More precisely, our contributions are:•For each projection, we assign two bits to define four quantization regions as shown in Fig. 1a instead of the conventional binary regions based on a single bit (Section 3.2). In addition we propose a novel distance measure between two binary codes tailored to our binary code embedding scheme (Section 3.3).We formulate an optimization problem to decide partitioning boundaries of four regions suitable for our distance metric by minimizing the quantization error (Section 3.4).According to our best knowledge, only two existing approaches, Hierarchical Hashing (HH) [11] and Double-Bit Quantization (DBQ) [14] aimed for similar goals that our method strives for. HH allowed each projection to have four quantization states, but used the common Hamming distance that does not exploit all the benefits of having four states. DBQ quantized projection values into three different states with two bits and used the Hamming distance (see Fig. 1). In contrast, our method fully utilizes four states that two bits can encode, and adopts a specialized distance metric that further lowers down the quantization error caused by having four regions. To demonstrate benefits of our method, we have tested our method in three well-known image retrieval benchmarks in the context of two different types of nearest neighbor search, k-NN andε-NN, in Section 4. Our method achieves significant improvements in accuracy over other prior encoding schemes across different hashing methods including LSH [4], spectral hashing [5], shift-invariant kernel-based LSH [7], and iterative quantization [10].This paper is an extended version of our earlier work initially presented at ACCV 2012 [15]. Additional materials for the extension include a simple thresholding strategy (Section 3.4) and detail descriptions on various components of our earlier work [15] with empirical results (Section 4.6 and Section 4.7).

@&#CONCLUSIONS@&#
