@&#MAIN-TITLE@&#
Structured forests for pixel-level hand detection and hand part labelling

@&#HIGHLIGHTS@&#
Introduce structured learning to pixel-level hand labelling task.Robust & efficient for binary hand detection and multi-class hand part labelling.Novel structured split criterion.Superior performance due to better utilizing training data.

@&#KEYPHRASES@&#
Hand detection,Egocentric vision,Random forests,Hand part labelling,

@&#ABSTRACT@&#
Hand detection has many important applications in Human-Computer Interactions, yet it is a challenging problem because the appearance of hands can vary greatly in images. In this paper, we present a new approach that exploits the inherent contextual information from structured hand labelling for pixel-level hand detection and hand part labelling. By using a random forest framework, our method can predict hand mask and hand part labels in an efficient and robust manner. Through experiments, we demonstrate that our method can outperform other state-of-the-art pixel-level detection methods in ego-centric videos, and further be able to parse hand parts in details.

@&#INTRODUCTION@&#
Hand detection has many important applications in Human-Computer Interactions. It enables computers to consider the flexible movement of human hands in 3D space as a new type of high dimensional user input, and to understand the natural interaction of hands with other objects in various scenarios. However, hand detection is a challenging problem because the appearance of hands can vary greatly in images. For instance, the shape of a hand can change dramatically due to the articulation of fingers as well as changes in viewpoint. A hand can be (partially) occluded while interacting with other objects. The colour of a hand can vary greatly under different illuminations, and a hand can even appear to be textureless under extreme illuminations. Traditional Methods [1–4] based on gradients or skin detection often cannot handle practical unconstrained hand images well due to insufficient training data. Furthermore, ego-centric cameras have become more and more popular. Images captured by such cameras often have a dynamic background, which makes hand detection even more difficult. Nonetheless, hands play a major part in these images, and it is of great interest and importance to detect hands in detail robustly for further higher level analysis.In this paper, our goal is to improve pixel-level hand detection and hand part labelling within the random forest framework. Rather than predicting per-pixel labels independently as in [5], we aim at exploiting the inherent structure from the label output space and predicting a patch region, which corresponds to a binary shape mask in hand detection and a multi-class label patch in hand part labelling. Technically, our approach is inspired by Semantic Texton Forests [27] and recent work on semantic image labelling [28]. During their training process, only limited number of pixels of a patch were considered in the split function. In order to consider more pixels, we propose to use an intermediate mapping, which groups the training patches for each node into certain amount of clusters by means of unsupervised learning methods. As shown in Fig. 1, our method detects hand regions more robustly than previous methods and is able to parse a hand into different parts.Our proposed approach has the following contributions:•we explicitly model the labelling of a pixel together with its local neighbourhood as a structured output to better utilise the inherent topological information in the training data and enforce such information as constraints during estimation;a novel structured split criterion is proposed to enable an efficient training and consider more pixels of our structured forests by incorporating unsupervised learning methods;we extend the binary hand detection to multi-class hand part labelling within our unified framework to solve these problems in an efficient and robust manner;throughout the experiments, our method outperforms the state-of-the-art methods. We also present a comprehensive analysis on different factors affecting the performance of our method on both tasks.Next, we briefly review related work on pixel-level hand detection in Section 2. In Section 3, we describe our proposed structured forests for hand detection. In Section 4, we extend our structured forests to handle more general output and apply them to hand part labelling. In Section 5, we show the experimental results for both hand detection and hand part labelling. Finally, we conclude our method in Section 6.

@&#CONCLUSIONS@&#
We have presented a new approach to exploit the inherent contextual information from structured hand labelling for pixel-level hand detection and hand part labelling. By using a random forest framework, our method can predict the hand mask and hand part labels in an efficient and robust manner. Through experiments, we demonstrate that our method can outperform state-of-the-art pixel-level detection methods in ego-centric videos, and further be able to parse hand parts in details. This may provide us better information for gesture analysis and hand-object interaction.