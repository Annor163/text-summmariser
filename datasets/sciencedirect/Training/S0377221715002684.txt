@&#MAIN-TITLE@&#
Building up time-consistency for risk measures and dynamic optimization

@&#HIGHLIGHTS@&#
We give a framework for stochastic optimization problems and dynamic risk measures.We provide common sets of assumptions that lead to time-consistency for both.Main assumptions are decomposability, commutation and monotonicity of aggregators.We give examples of applications considering non-additive costs.

@&#KEYPHRASES@&#
Dynamic programming,Time-consistency,Dynamic risk measures,

@&#ABSTRACT@&#
In stochastic optimal control, one deals with sequential decision-making under uncertainty; with dynamic risk measures, one assesses stochastic processes (costs) as time goes on and information accumulates. Under the same vocable of time-consistency (or dynamic-consistency), both theories coin two different notions: the latter is consistency between successive evaluations of a stochastic processes by a dynamic risk measure (a form of monotonicity); the former is consistency between solutions to intertemporal stochastic optimization problems. Interestingly, both notions meet in their use of dynamic programming, or nested, equations.We provide a theoretical framework that offers (i) basic ingredients to jointly define dynamic risk measures and corresponding intertemporal stochastic optimization problems (ii) common sets of assumptions that lead to time-consistency for both. We highlight the role of time and risk preferences — materialized in one-step aggregators — in time-consistency. Depending on how one moves from one-step time and risk preferences to intertemporal time and risk preferences, and depending on their compatibility (commutation), one will or will not observe time-consistency. We also shed light on the relevance of information structure by giving an explicit role to a state control dynamical system, with a state that parameterizes risk measures and is the input to optimal policies.

@&#INTRODUCTION@&#
You come across time-consistency in two different mathematical fields. You are time-consistent if, as time goes on and information accumulates, you do not question the original assessment of stochastic processes (dynamic risk measures) or planning of policies (stochastic optimal control).We propose a general mechanism to build up time-consistent dynamic risk measures, that serve as criteria for optimal control problems under uncertainty, which henceforth inherit time-consistency. We show how in a few words.Consider two setsT1andT2,representing sets of time periods (T1={1,2,3},T2={4,5}for instance). Consider two setsW1andW2,representing possible values of uncertainties. For any setS,denote byL(S)the set of functionsS→R∪{+∞},and byGS:L(S)→R∪{+∞}a mapping. You can assess any functionA:T1×T2×W1×W2→R∪{+∞},•either by block-aggregation: start by aggregating by time, yieldingGT2GT1:W1×W2→R∪{+∞},then by uncertainty, yieldingGW2GW1GT2GT1A∈R∪{+∞},or by nested-aggregation, yieldingGW2GT2GW1GT1A∈R∪{+∞}.We will show that nested-aggregation produces both time-consistent dynamic risk measures and optimal control problems, and that so does block-aggregation when a commutation property holds true. For example, sum and integral are commuting operators and a block-aggregation is equivalent to a nested-aggregation as shown in the following equality∫∫∫X×Y×Z[c1(x)+c2(x,y)+c3(x,y,z)]dxdydz=∫X[c1(x)+∫Y[c2(x,y)+∫Zc3(x,y,z)dx]dy]dz.Now, let us be more specific.In stochastic optimal control, one deals with sequential decision-making under uncertainty; with dynamic risk measures, one assesses stochastic processes (costs) as time goes on and information accumulates. We discuss the definition of time-consistency in each setting one after the other (see also Rudloff, Street, & Valladão, 2014 for another analysis of links between both notion).In optimal control problems, we consider a dynamical process that can be influenced by exogenous noises as well as decisions made at every time step. The decision-maker (DM) wants to optimize a criterion (for instance, minimize a net present value) over a given time horizon. As time goes on and the system evolves, the DM makes observations. Naturally, it is generally more profitable for the DM to adapt his decisions to the observations. He is hence looking for policies (strategies, decision rules) rather than simple decisions: a policy is a function that maps every possible history of the observations to corresponding decisions.The notion of “consistent course of action” (see Peleg & Yaari, 1973) is well-known in the field of economics, with the seminal work of (Strotz, 1955–1956): an individual having planned his consumption trajectory is consistent if, reevaluating his plans later on, he does not deviate from the originally chosen plan. This idea of consistency as “sticking to one’s plan” may be extended to the uncertain case where plans are replaced by decision rules (“Do thus-and-thus if you find yourself in this portion of state space with this amount of time left”, Richard Bellman cited in Dreyfus, 2002): Hammond (1976) addresses “consistency” and “coherent dynamic choice”, Kreps and Porteus (1978) refer to “temporal consistency”.In this context, we loosely state the property of time-consistency in optimal control problems as follows (Carpentier, Chancelier, Cohen, De Lara, & Girardeau, 2012). The decision maker formulates an optimization problem at time t0 that yields a sequence (planning) of optimal decision rules for t0 and for the following increasing time steps t1, …, tN= T. Then, at the next time step t1, he formulates a new problem starting at t1, that yields a new sequence of optimal decision rules from time steps t1 to T. Suppose the process continues until time T is reached. The sequence of optimization problems is said to be time-consistent if the optimal strategies obtained when solving the original problem at time t0 remain optimal for all subsequent problems. In other words, time consistency means that strategies obtained by solving the problem at the very first stage do not have to be questioned later on.Now, we turn to dynamic risk measures. At time t0, you assess, by means of a risk measureρt0,T,the “risk” of a stochastic process{At}t=t0tN,that represents a stream of costs indexed by the increasing time steps t0, t1, …, tN= T. Then, at the next time step t1, you assess the risk of the tail{At}t=t1tNof the stochastic process knowing the information obtained and materialized by a σ-fieldFt1. For this, you use a conditional risk measureρt1,Twith values inFt1-measurable random variables. Suppose the process continues until time T is reached. The sequence{ρt,T}t=t0tNof conditional risk measures is called a dynamic risk measure.Dynamic or time-consistency has been introduced in the context of risk measures (see Artzner, Delbaen, Eber, Heath, & Ku, 2007; Cheridito, Delbaen, & Kupper, 2006; Cheridito & Kupper, 2011; Detlefsen & Scandolo, 2005; Riedel, 2004 for definitions and properties of coherent and consistent dynamic risk measures). The dynamic risk measure{ρt,T}t=t0tNis said to be time-consistent when the following property holds. Suppose that two streams of costs,{A̲t}t=t0tNand{A¯t}t=t0tN,are such that they coincide from time tiup to time tj> tiand that, from that last time tj, the risk of the tail stream{A̲t}t=tjtNis more than that of{A¯t}t=tjtN(i.e.ρtj,T({A̲t}t=tjtN)≥ρtj,T({A¯t}t=tjtN)). Then, the whole stream{A̲t}t=titNhas higher risk than{A¯t}t=titN(i.e.ρti,T({A̲t}t=titN)≥ρti,T({A¯t}t=titN)).We observe that both notions of time-consistency look quite different: the latter is consistency between successive risk assessments of a stochastic process by a dynamic risk measure (a form of monotonicity); the former is consistency between solutions to intertemporal stochastic optimization problems. We now stress the role of information accumulation in both notions of time-consistency, because it highlights how the two notions can be connected. For dynamic risk measures, the flow of information is materialized by a filtration{Ft}t=t1tN. In stochastic optimal control, an amount of information more modest than the past of exogenous noises is often sufficient to make an optimal decision. In the seminal work of (Bellman, 1957), the minimal information necessary to make optimal decisions is captured in a state variable (see Whittle, 1982 for a more formal definition). Moreover, the famous Bellman or Dynamic Programming Equation (DPE) provides a theoretical way to find optimal strategies (see Bertsekas, 2000 for a broad overview on Dynamic Programming (DP)).Interestingly, time-consistency in optimal control problems and time-consistency for dynamic risk measures meet in their use of DPEs. On the one hand, in optimal control problems, it is well known that the existence of a DPE with state x for a sequence of optimization problems implies time-consistency when solutions are looked after as feedback policies that are functions of the state x. On the other hand, proving time-consistency for a dynamic risk measure appears rather easy when the corresponding conditional risk measures can be expressed by a nested formulation. In both contexts, such nested formulations are possible only for proper information structures. In optimal control problems, a sequence of optimization problems may be consistent for some information structure while inconsistent for a different one (see Carpentier et al., 2012). For dynamic risk measures, time-consistency appears to be strongly dependent on the underlying information structure (filtration or scenario tree). Moreover, in both contexts, nested formulations and the existence of a DPE are established under various forms of decomposability of operators that display monotonicity and commutation properties.Our objective is to provide a theoretical framework that offers (i) basic ingredients to jointly define dynamic risk measures and corresponding intertemporal optimization problems under uncertainty (ii) common sets of assumptions that lead to time-consistency for both. We wish to highlight the role of time and risk preferences, materialized in one-step aggregators, in time-consistency. Depending on how you move from one-step time and risk preferences to intertemporal time and risk preferences, and depending on their compatibility (commutation), you will or will not observe time-consistency. We also shed light on the relevance of information structure by giving an explicit role to a dynamical system with state x.The paper is organized as follows. In Section 2, we define dynamic uncertainty criteria (“cousins” of dynamic risk measures) and their time-consistency. Then, we introduce the notions of time and uncertainty-aggregators, define their composition, and show two ways to craft a dynamic uncertainty criterion from one-step aggregators: in the nested-aggregation case, we prove time-consistency; in the block-aggregation case, we have to add a commutation property for this. In Section 3, we introduce the basic material to formulate intertemporal optimization problems under uncertainty from dynamic uncertainty criteria, and define their time-consistency. In the nested-aggregation case, we prove time-consistency by displaying a DPE; in the block-aggregation case, we have to add a commutation property for this. We end with applications in Section 4, before concluding.We fix notations used throughout the paper:•〚a, b〛is the set of integers between a and b (included);F(E,F)is the set of functions mapping E into F;{ut}0Tis the sequence {u0, …, uT};R¯=R∪{+∞};W[0:s]is the Cartesian productW0×⋯×Ws;Gis used to refer to an aggregator with respect to uncertainty;ϕ is used to refer to an aggregator with respect to time.Furthermore, the superscript notation indicates that the domain of the mappingG[t:s]isF(W[t:s];R¯)(not to be confused withG[t:s]={Gr}r=ts).In Section 2.1, we lay out adapted uncertainty processes and dynamic uncertainty criterion, cousins of adapted processes and dynamic risk measures, then propose a definition of time-consistency. Then, in Section 2.2, we introduce the notions of time and uncertainty-aggregators, define their composition, and outline general ways of building a dynamic uncertainty criterion from one-step aggregators. Further, in Section 2.3 we define nested criterion and give a time-consistency result relying on monotonicity of one-step aggregators. Finally, in Section 2.4 we define a commutation property between time and uncertainty aggregators. This commutation property allow to give a time-consistency result for a block-aggregated dynamic uncertainty criterion.Inspired by the definitions of risk measures and dynamic risk measures in mathematical finance, and motivated by intertemporal optimization, we introduce the following definitions of dynamic uncertainty criterion, and Markov dynamic uncertainty criterion. Such criteria are not restricted to assess measurable mappings (as stochastic processes would be), and we pay the price by letting +∞ be a possible assessment (for instance, the “mathematical expectation” of a non-measurable function is +∞).Mimicking the definition of adapted processes in probability theory, we first introduce the following definition of adapted uncertainty processes.Definition 1We say that a sequenceA[0:T]={As}0Tis an adapted uncertainty process ifAs∈F(W[0:s];R¯)(that is,As:W[0:s]→R¯), for all s ∈〚0, T〛. In other words,[F(W[0:s];R¯)]s=0Tis the set of adapted uncertainty processes.A dynamic uncertainty criterion is a sequence{ϱt,T}t=0T,such that, for all t ∈〚0, T〛,•ϱt, Tis a mapping(1a)ϱt,T:[F(W[0:s];R¯)]s=tT→F(W[0:t];R¯),the restriction of ϱt, Tto the domain11WhereF(W[t:s];R¯)is naturally identified as a subset ofF(W[0:s];R¯).[F(W[t:s];R¯)]s=tTyields constant functions, that is,(1b)ϱt,T:[F(W[t:s];R¯)]s=tT→R¯.A Markov dynamic uncertainty criterion is a dynamic uncertainty criterion parametrized at each step t by a state xtbelonging to a state spaceXt.We establish a parallel between uncertainty criteria and risk measures. For this purpose, when needed, we implicitely suppose that each uncertainty setWtis endowed with a σ-algebraWt,so that the setW[0:T]of scenarios is naturally equipped with the filtration(2)Ft=W0⊗⋯⊗Wt⊗{∅,Wt+1}⊗⋯⊗{∅,WT},∀t∈〚0,T〛.Notice that, when the σ-algebraWtis the complete σ-algebra made of all subsets ofWt,F(W[0:t];R¯)is exactly the space of random variables that areFt-measurable.We provide a definition of time-consistency for Markov dynamic uncertainty criteria, inspired by the definition for dynamic risk measures. If two streams of random costs coincide up to time t, but that the tail streams can be ranked pointwise, so will their risk measure.The Markov dynamic uncertainty criterion{{ϱt,Txt}xt∈Xt}t=0Tis said to be time-consistent if, for any couple of times0≤t̲<t¯≤T,the following property holds true.If two adapted uncertainty processes{A̲s}0Tand{A¯s}0T,satisfy(3a)A̲s=A¯s,∀s∈〚t̲,t¯〛,(3b)ρt¯,Tx¯({A̲s}t¯T)≤ρt¯,Tx¯({A¯s}t¯T),∀x¯∈Xt¯,then we have:(3c)ρt̲,Tx̲({A̲s}t̲T)≤ρt̲,Tx̲({A¯s}t̲T),∀x̲∈Xt̲.We introduce the notions of time and uncertainty-aggregators, define their composition, and outline general ways of constructing a dynamic uncertainty criterion from one-step aggregators.For notational clarity the argument of time-aggregators are written between curly braces ({·}) whereas the argument of uncertainty aggregators are written between straight brackets [·].Definition 4A multiple-step time-aggregator is a function mappingR¯kintoR¯,where k ≥ 2. When k = 2, we call one-step time-aggregator a function mappingR¯2intoR¯. A one-step time-aggregator is said to be non-decreasing if it is non-decreasing in its second variable.LetΦ1:R¯2→R¯be a one-step time-aggregator andΦk:R¯k→R¯be a multiple-step time-aggregator. We define the compositionΦ1⊙Φk:R¯k+1→R¯by(4)(Φ1⊙Φk){c1,c2,…,ck+1}=Φ1{c1,Φk{c2,…,ck+1}}.The composition of multiple one-step time-aggregator is defined recursively by(5)(⊙s=tT−1Φs)(c[t:T])=Φt{ct,(⊙s=t+1T−1Φs)(c[t+1:T])}.If each one-step time-aggregators is simply the sum of two terms (Φt{ct, ct + 1} = ct+ ct + 1), their composition is just the total sum:(⊙s=tT−1Φs)(c[t:T])=∑s=tTcs.More generally, consider the sequence{Φt}t=0T−1of one-step time-aggregators given by(6)Φt{ct,ct+1}=αt(ct)+βt(ct)ct+1,∀t∈〚0,T−1〛,where (αt)t ∈〚0, T − 1〛and (βt)t ∈〚0, T − 1〛are sequences of functions, each mappingR¯intoR. With the convention that αT(cT) = cT, we have(7)(⊙s=tT−1Φs){cs}tT=∑s=tT(αs(cs)∏r=ts−1βr(cr)),∀t∈〚0,T−1〛.Definition 5Let t ∈〚0, T〛and s ∈〚t, T〛. A [t: s]-multiple-step uncertainty-aggregator is a mappingG[t:s]fromF(W[t:s];R¯)intoR¯. When t = s, we callG[t:t]a t-one-step uncertainty-aggregator. A [t: s]-multiple-step uncertainty-aggregator is said to be non-decreasing if it is monotonous with respect to the pointwise partial order of functions. To a [t: s]-multiple-step uncertainty-aggregatorG[t:s],we attach a mapping(8)G[t:s]:F(W[0:s];R¯)→F(W[0:t−1];R¯),obtained by freezing the first variables (seen as parameters).We define the notion of chained sequence of uncertainty-aggregators and their composition as follows.Definition 6Let t ∈〚0, T〛and s ∈〚t + 1, T〛. LetG[t:t]:F(Wt;R¯)→R¯be a t-one-step uncertainty-aggregator, andG[t+1:s]:F(W[t+1:s];R¯)→R¯be a [t + 1: s]-multiple-step uncertainty-aggregator. We define the [t: s]-multiple-step uncertainty-aggregatorG[t:t]⊡G[t:s]by, for all functionAt∈F(W[t:s];R¯),(9)(G[t:t]⊡G[t:s])[At]=G[t:t][wt↦G[t+1:s][w[t+1:s]↦At(wt,w[t+1:s])]].We say that a sequence{Gt}t=0Tof one-step uncertainty-aggregators is a chained sequence ifGtis a t-one-step uncertainty-aggregator, for all t ∈〚0, T〛.Quite naturally, we define the composition of chained sequences by(10)⊡s=TTGs=GTand(⊡s=tTGs)=Gt⊡(⊡s=t+1TGs).After having introduced the ingredients of one-step aggregators and their composition, we now cook up nested dynamic uncertainty criterion and prove that they are time-consistent.Definition 7A monotonous pair(Φ,G)of sequences of aggregators consists in•a sequence{Φt}t=0T−1of non-decreasing one-step time-aggregators,a chained sequence{Gt}t=0Tof non-decreasing one-step uncertainty-aggregators.From a monotonous pair(Φ,G),we build a dynamic uncertainty criterion by successive compositions.Definition 8We inductively define a nested dynamic uncertainty criterion{ϱt,TN}t=0Tby(11a)ϱTN(AT)=GT[AT],(11b)ϱt,TN({As}s=tT)=Gt[Φt{At,ϱt+1,TN({As}s=t+1T)}],∀t∈〚0,T−1〛,for any adapted uncertainty process{As}s=0T.The following Theorem 9 states that monotonicity is enough to ensure the time-consistency of nested dynamic uncertainty criteria.Theorem 9Let(Φ,G)be a monotonous pair of sequences of aggregators. Then, the nested dynamic uncertainty criterion{ϱt,TN}t=0Tdefined by(11)is time-consistent (in the sense ofDefinition 3).Lett̲<t¯be both in〚0, T〛. Consider two adapted uncertainty processes{A̲s}0Tand{A¯s}0T,whereAsandA¯smapsW[0:T]intoR¯,such that(12a)A̲s=A¯s,∀s∈〚t̲,t¯〛,(12b)ϱt¯,TN({A̲s}t¯T)≤ϱt¯,TN({A¯s}t¯T),We show by backward induction that, for allt∈〚t̲,t¯〛,the following statement (Ht) holds true:(13)(Ht)ϱt,TN({A̲s}tT)≤ϱt,TN({A¯s}tT).First, we observe that(Ht¯)holds true by assumption (12b). Second, by (Ht), and asA̲t−1=A¯t−1monotonicity of Φt − 1 yieldsΦt−1{A̲t−1,ϱt,TN({A̲s}tT)}≤Φt−1{A¯t−1,ϱt,TN({A¯s}tT)}.Monotonicity ofGt−1then givesGt−1[Φt−1{A̲t−1,ϱt,TN({A̲s}tT)}]≤Gt−1[Φt−1{A¯t−1,ϱt,TN({A¯s}tT)}].By definition ofϱt−1,TNin (11), we obtain (Ht − 1).□In Definition 8, we build nested aggregators, first starting by aggregating with respect to time, second with respect to uncertainty. If we aggregate first with respect to uncertainty, second with respect to time, we obtain the dynamic uncertainty criterion given byϱTN′(AT)=GT[AT],ϱt,TN′({As}s=tT)=Φt{Gt[At],Gt[ϱt+1,TN′({As}s=t+1T)]},∀t∈〚0,T−1〛.It is shown in (Leclère, 2014, Chap. 2) that monotonicity is also sufficient to yield time-consistency.Nested uncertainty criteria carry the time-consistency property in the very manner they are built. However, nested uncertainty criterion are not the most natural candidates to assess risk and their economic interpretation is delicate. In practice, uncertainty criterion are more often given in block-aggregation form — integrate with respect to all times, then with respect to all uncertainties — than in nested form.We first propose a commutation property that will allow to go from one formulation to the other, and that will stand as one of the key ingredients for a DPE and lead to the time-consistency result in Theorem 14.Definition 11Let t ∈〚0, T〛and s ∈〚t + 1, T〛. A [t: s]-multiple-step uncertainty-aggregatorG[t:s]is said to commute with a one-step time-aggregator Φ if(14)G[t:s][w[t:s]↦Φ{c,Dt(w[t:s])}]=Φ{c,G[t:s][w[t:s]↦Dt(w[t:s])]},for any functionDt∈F(W[t:s];R¯)and any extended scalarc∈R¯.We say that a(Φ,G)is a commuting pair of sequence of aggregators ifGtcommutes with Φs, for any 0 ≤ s < t ≤ T.If(Wt,Ft,Pt)is a probability space and if(15)Φ{c,ct}=α(c)+β(c)ct,whereα:R¯→Randβ:R¯→R+,then the extended22We set β ≥ 0, so that, whenCt∈F(Wt;R¯)is not integrable with respect toPt,the equality (14) still holds true.expectationG[t:t]=EPtcommutes with Φ.The following lemma shows how commutation of time-step aggregators leads to commutation of multi-step aggregators.Lemma 12Consider a commuting pair(Φ,G)of aggregators. Then,⊡s=tTGscommutes with Φr, for any 0 ≤ r < t ≤ T, that is,(16)⊡s=tTGs[Φr{cr,A}]=Φr{c,⊡s=tTGs[A]},∀0≤r<t≤T,for any extended scalarc∈R¯and any functionA∈F(W[0:T];R¯).Beware that, for a given time t, we require the commutation of all subsequent uncertainty-aggregatorsGt+1,⋯,GTwith the time aggregator Φt(see Definition 11). The proof of Lemma 12, by induction, is detailed in Appendix B.1.We now define block dynamic uncertainty criteria and prove their time-consistency under a commutation property.Definition 13We define the block dynamic uncertainty criterion{ϱt,TB}t=0Tby(17)ϱt,TB=(⊡s=tTGs)∘(⊙s=tT−1Φs),∀t∈〚0,T−1〛.The following Theorem 14 is our main result on time-consistency in the block-aggregation case.Theorem 14Let(Φ,G)be a commuting and monotonous pair of sequences of aggregators. Then the block dynamic uncertainty criterion{ϱt,TB}t=0Tdefined by (17) is time-consistent.Since, for any 0 ≤ s < t ≤ T,Gtcommutes with Φs, the block - dynamic uncertainty criterion{ϱt,TB}t=0T,given by Definition 17, coincides with{ϱt,TN}t=0T,given by Definition 8. Indeed, we prove that{ϱt,TB}t=0Tsatisfies the backward induction (11).With the convention that(⊙r=TT−1Φr)is the identity mapping, we haveϱTB=GT,that is, (11a).Then, let t be fixed. For any{As}tT∈[F(W[0:s];R¯)]s=tT,we have:ϱtB({As}s=tT)=⊡r=tsGr[⊙r=tT−1Φr{{As}s=tT}]by(17),=Gt[⊡r=t+1sGr[⊙r=tT−1Φr{{As}s=tT}]]by(10),=Gt[⊡r=t+1sGr[Φt{At,(⊙r=t+1T−1Φr){As}s=t+1T}]]by(5),=Gt[Φt{At,⊡r=t+1sGr[(⊙r=t+1T−1Φr){As}s=t+1T]}]by(16)=Gt[Φt(At,ϱt+1B({As}s=t+1T))]by(17).Thus,{ϱt,TB}t=0Tsatisfies the backward induction (11).□In Definition 13, we build block-aggregators, first starting by aggregating with respect to time, second with respect to uncertainty. If we aggregate first with respect to uncertainty, second with respect to time, we obtain another dynamic uncertainty criterion. However, to show time-consistency would require monotonicity and another notion of commutation, less widespread than Definition 11. See (Leclère, 2014, Chap. 2) for more details on the subject.In (Leclère, 2014, Chap. 2), the construction of this Section 2 is extended to Markovian aggregators. Roughly speaking, the time-step time and uncertainty aggregators are parametrized by a state, that follows a control dynamical system. All results remain true if the commutation property holds true for every possible value of the underlying state.In Section 2, we considered dynamic uncertainty criterion that value (the risk of) a stream of costs. We now use such criteria to formulate intertemporal optimization problems under uncertainty. In Section 3.1, we lay out the basic material to formulate intertemporal optimization problems. Then, we provide definition of time-consistency in Section 3.2, and time-consistency results in Section 3.3.In Section 3.1.1, we recall the formalism of Control Theory, with dynamical system, state, control and costs. In Section 3.1.2, we show how to produce adapted uncertainty processes of costs, that will be the inputs to dynamic uncertainty criteria.Let T ≥ 2 be an integer. We define a control T-stage dynamical system as follows. We consider sequences of sets of states ({Xt}0T), controls ({Ut}0T−1), and uncertainties ({Wt}0T). We also consider sequences of functions representing dynamics ({ft}0T−1,whereft:Xt×Ut×Wt→Xt+1) constraints ({Ut}0T−1,whereUt:Xt⇉Utis a set-valued function), and costs ({Jt}0T−1withJt:Xt×Ut×Wt↦R¯being instantaneous cost functions) andJT:XT×WT→R¯the final cost function.33For notational consistency with the Jtfor t =〚0, T − 1〛, we will often write JT(x, u, w) to mean JT(x, w).A policyπ=(πt)0T−1is a sequence of functionsπt:Xt→Ut,and we denote by Π the set of all policies. More generally, for all t ∈〚0, T〛, we call (tail) policy a sequenceπ=(πs)tT−1and we denote by Πtthe set of all such policies.We restrict our search of optimal solutions to so-called admissible policies belonging to a subset Πad⊂Π. An admissible policy π ∈ Πad always satisfies:πt(x)∈Ut(x),∀x∈Xt,∀t∈〚0,T−1〛.We can express in Πadother types of constraints, such as measurability or integrability ones when we are in a stochastic setting. Naturally, we setΠtad=Πt∩Πad.Definition 16For any time t ∈〚0, T〛, statex∈Xtand policy π ∈ Π, the flow{Xt,sx,π}s=tTof the dynamics{ft}0T−1is defined by the forward induction:(18)∀w∈W[0:T],{Xt,tx,π(w)=x,Xt,s+1x,π(w)=fs(Xt,sx,π(w),πs(Xt,sx,π(w)),ws),∀s∈〚t,T〛.The expressionXt,sx,π(w)is the statexs∈Xsreached at time s ∈〚0, T〛, when starting at time t ∈〚0, s〛from statex∈Xtand following the dynamics{fr}0T−1with the policy π ∈ Π along the scenariow∈W[0:T].Remark 17For 0 ≤ t ≤ s ≤ T, the flowXt,sx,πis a function that maps the setW[0:T]of scenarios into the state spaceXs:(19)Xt,sx,π:W[0:T]→Xs.By (18),•when t > 0, the expressionXt,sx,π(w)depends only on the inner part w[t: s − 1] of the scenario w = w[0: T], hence depends neither on the head w[0: t − 1], nor on the tail w[s: T],when t = 0, the expressionX0,sx,π(w)in (18) depends only on the head w[0: s − 1] of the scenario w = w[0: T], hence does not depend on the tail w[s: T].This is why we often consider that the flowXt,sx,πis a function that maps the setW[t:s−1]of scenarios into the state spaceXs:(20)Xt,sx,π:W[t:s−1]→Xs,∀s∈〚1,T〛,∀t∈〚0,s−1〛.A state trajectory is a realization of the flow{X0,sx,π(w)}s=0Tfor a given scenariow∈W[0:T]. The flow property(21)Xt,sx,π≡Xs′,sXt,s′x,π,π,∀t,s,s′,t<s′<s,∀x∈Xtexpresses the fact that we can stop anywhere along a state trajectory and start again.With a policy and a scenario, we obtain state and control trajectories that we plug into the instantaneous cost functions Jsto deliver streams of costs.Definition 18For a given policy π ∈ Π, and for all times t ∈〚0, T〛and s ∈〚t, T〛, we define the uncertain costs evaluated along the state trajectories by:(22)Jt,sx,π:w∈W[0:T]↦Js(Xt,sx,π(w),π(Xt,sx,π(w)),ws).By Remark 17, we consider thatJt,sx,πis a function that maps the setW[t:s]of scenarios intoR¯:(23)Jt,sx,π:W[t:s]→R¯,∀s∈〚0,T〛,∀t∈〚0,s〛.As a consequence, the stream{J0,sx,π}s=0Tof costs is an adapted uncertainty process (see Definition 1).By (22) and (18), we have, for all t ∈〚0, T〛and s ∈〚t + 1, T〛,(24)∀w[t:T]∈W[t:T],{Jt,tx,π(wt)=Jt(x,πt(x),wt),Jt,sx,π(wt,{wr}t+1T)=Jt+1,sft(x,πt(x),wt),π({wr}t+1T).We relate dynamic uncertainty criteria and optimization problems as follows.Definition 20Given a Markov dynamic uncertainty criterion{{ϱt,Txt}xt∈Xt}t=0T,we define a Markov optimization problem as the following sequence of families of optimization problems, indexed by t ∈〚0, T〛, andx∈Xt:(25)(Pt)(x)minπ∈Πadϱt,Tx({Jt,sx,π}s=tT).Each Problem (25) is indeed well defined by (1b), because{Jt,sx,π}s=tTbelongs to[F(W[t:s];R¯)]s=tTby (23).With the formalism of Section 2.1, we can now give a definition of time-consistency for Markov optimization problems.For the clarity of exposition, suppose for a moment that any optimization problem(Pt)(x)in (25) has a unique solution, a policy that we denoteπt,x={πst,x}s=tT−1∈Πtadto stress that it parametrically depends on t, x as(Pt)(x)does. Consider0≤t̲<t¯≤T. Suppose that, starting from the statexat timet, the flow (18) drives you to(26)x¯=Xt̲,t¯x̲,π(w),π=πt̲,x̲at timet¯,along the scenariow∈W[0:T]and adopting the optimal policyπt̲,x̲∈Πt̲ad. Arrived atx¯,you solve(Pt¯)(x¯)and get the optimal policyπt¯,x¯={πst¯,x¯}s=t¯T−1∈Πt¯ad. Time-consistency holds true when(27)πst¯,x¯=πst̲,x̲,∀s≥t¯,that is, when the “new” optimal policy, obtained by solving(Pt¯)(x¯),coincides, after timet¯,with the “old” optimal policy, obtained by solving(Pt̲)(x̲). In other words, you “stick to your plans” (here, a plan is a policy) and do not reconsider your policy whenever you stop along an optimal path and optimize ahead from this stop point.To account for non-uniqueness of optimal policies, we propose the following formal definition.Definition 21We say that the Markov optimization problem (25) of Definition 20 is time-consistent if, for any couple of timest̲≤t¯in〚0, T〛and any statex̲∈Xt̲,the following property holds: there exists a policyπ♯={πs♯}s=t̲T−1∈Πt̲adsuch that•{πs♯}s=t̲T−1is optimal for ProblemPt̲(x̲);the tail policy{πs♯}s=t¯T−1is optimal for ProblemPt¯(x¯),wherex¯∈Xt¯is any state achieved by the flowXt̲,t¯x̲,π♯in (18).We stress that the above definition of time-consistency of a sequence of families of optimization problems is contingent on the state x and on the dynamics{ft}0T−1by the flow (18). In particular, we assume that, at each time step, the control is taken only in function of the state: this defines the class of solutions as policies that are feedbacks of the state x (such restriction is justified in the Markovian case, for example).We now provide time-consistency results, differing whether in the nested-aggregation or in the block-aggregation case.We define the nested Markov optimization problem formally by(28)(PtN)(x)VtN(x)=minπ∈Πtadϱt,TN({Jt,sx,π}s=tT),∀t∈〚0,T〛,∀x∈Xt,where the functionsJt,sx,πare defined by (22), and the nested uncertainty criterion{ϱt,TN}t=0Tby (11).The following Proposition 22 expresses sufficient conditions under which any Problem(PtN)(x),for any time t ∈〚0, T − 1〛and any statex∈Xt,can be solved by means of a Dynamic Programming Equation (DPE).Proposition 22Let(Φ,G)be a monotonous pair of sequences of aggregators. Assume that there exists an admissible policy π♯ ∈ Πadsuch that(29)πt♯(x)∈argminu∈Ut(x)Gt[Φt{Jt(x,u,·),Vt+1N∘ft(x,u,·)}],∀t∈〚0,T−1〛,∀x∈Xt.Then, π♯is an optimal policy for any Problem(PtN)(x),for all t ∈〚0, T〛and for allx∈Xt,and the value functions Vt satisfy the DPE(30a)VTN(x)=GT[JT(x,·)],∀x∈XT,(30b)VtN(x)=minu∈Ut(x)Gt[Φt{Jt(x,u,·),Vt+1N∘ft(x,u,·)}],∀t∈〚0,T−1〛,∀x∈Xt.It may be difficult to prove the existence of a measurable selection among the solutions of (29). Since it is not our intent to consider such issues, we make the assumption that an admissible policy π♯ ∈ Πad exists, where the definition of the set Πad is supposed to include all proper measurability conditions.The proof of Proposition 22 is detailed in the appendix.The following Theorem 9 is our main result on time-consistency in the nested-aggregation case.Theorem 24Let(Φ,G)be a monotonous pair of sequences of aggregators. Then1.the nested dynamic uncertainty criterion{ϱt,TN}t=0Tdefined by (11) is time-consistent;the Markov optimization problem{{(PtN)(x)}x∈Xt}t=0Tdefined in (28) is time-consistent, as soon as there exists an admissible policy π♯ ∈ Πadsuch that (29) holds true.We define the block Markov optimization problem formally by(31)(PtB)(x)minπ∈Πtadϱt,TB({Jt,sx,π}s=tT),∀t∈〚0,T〛,∀x∈Xt,where the functionsJt,sx,πare defined by (22), and the block uncertainty criterion{ϱt,TB}t=0Tby (17).The following Theorem 25 is our main result on time-consistency in the block-aggregation case. We do not give the proof since it directly follows from Theorem 9 and Theorem 14.Theorem 25Let(Φ,G)be a monotonous and commuting pair of sequences of aggregators. Then1.the block-aggregated dynamic uncertainty criterion{ϱt,TB}t=0Tdefined by (17) is time-consistent;the Markov optimization problem{{(PtB)(x)}x∈Xt}t=0Tdefined in (31) is time-consistent, as soon as there exists an admissible policy π♯ ∈ Πadsuch that (29) holds true.Theorem 24 and 25 are given for criteria obtained via time followed by uncertainty aggregation. When uncertainty precedes time aggregation, we can obtain similar results, at the price of a different definition of commuting aggregators (Leclère, 2014, Chap. 2).In (Leclère, 2014, Chap. 2), the time consitency result is extended to Markovian aggregators, made of one-step time and uncertainty aggregators parameterized by the state. All results remain true if the commutation property holds true for every possible value of the state.We end by providing classes of dynamic uncertainty criteria and corresponding intertemporal optimization problems that display time-consistency, as well as examples of applications.We introduce a class of dynamic uncertainty criteria, that are related to coherent risk measures, and we show that they display time-consistency. We thus extend, to more general one-step time-aggregators, results known for the sum (see e.g. Ruszczyski, 2010; Shapiro, 2012).We denote byP(Wt)the set of probabilities over the setWtendowed with the σ-algebraWt. LetP0⊂P(W0),...,PT⊂P(WT). If A and B are sets of probabilities, then A⊗B is defined as(32)A⊗B={PA⊗PB|PA∈A,PB∈B}.Let (αt)t ∈〚0, T − 1〛and (βt)t ∈〚0, T − 1〛be sequences of functions, each mappingR¯intoR,with the additional property that βt≥ 0, for all t ∈〚0, T − 1〛. We set, for all t ∈〚0, T〛,(33)ϱt,Tco({As}tT)=supPt∈PtEPt[⋯supPT∈PTEPT[∑s=tT(αs(As)∏r=ts−1βr(Ar))]⋯],for any adapted uncertain process{At}0T,with the convention that αT(cT) = cT.Proposition 27Time-consistency holds true for•the dynamic uncertainty criterion{ϱt,Tco}t=0Tgiven by (33),the Markov optimization problem(34)minπ∈Πadϱt,Tco({Jt,sx,π}s=tT),∀t∈〚0,T〛,∀x∈Xt,whereJt,sx,π(w)is defined by (22), as soon as there exists an admissible policy π♯ ∈ Πadsuch that, for all t ∈〚0, T − 1〛, for allx∈Xt,πt♯(x)∈argminu∈Ut(x)supPt∈Pt{EPt[αt(Jt(x,u,·))+βt(Jt(x,u,·))Vt+1∘ft(x,u,·)]},where the value functions are given by the following DPE(35a)VT(x)=supPT∈PTEPT[JT(x,·)],(35b)Vt(x)=minu∈Ut(x)supPt∈Pt{EPt[αt(Jt(x,u,·))+βt(Jt(x,u,·))Vt+1∘ft(x,u,·)]}.The setting is that of Theorem 14 and Proposition 22, wherethe one-step time-aggregators are defined by(36a)Φt{ct,ct+1}=αt(ct)+βt(ct)ct+1,∀t∈〚0,T−1〛,∀(ct,ct+1)∈R¯2,and the one-step uncertainty-aggregators are defined by(36b)Gt[Ct]=supPt∈PtEPt[Ct],∀t∈〚0,T−1〛,∀Ct∈F(Wt;R¯).The DPE(35) is the DPE(30), which holds true as soon as the assumptions of Theorem 14 hold true (mainly that we have a commuting monotonous pair of operators).First, we prove that, for any 0 ≤ t < s ≤ T,Gscommutes with Φt(this is a special case of Proposition 30 shown in appendix). Indeed, letting ctbe an extended real number inR¯and Csa function inF(Ws;R¯),we haveGs[Φt{ct,Cs}]=supPs∈Ps{EPs[α(ct)+β(ct)Cs]}by(36b)and(36a),=αt(ct)+βt(ct)supPs∈Ps{EPs[Cs]}asβt≥0,=αt(ct)+βt(ct)Gs[Cs]by(36b),=Φt{ct,Gs[Cs]}by(36a).Second, we observe thatGtis non-decreasing (see Definition 5), and thatct+1∈R¯↦Φt{ct,ct+1}=αt(ct)+βt(ct)ct+1is non-decreasing, for anyct∈R¯.□The one-step uncertainty-aggregatorsGtin (36b) correspond to a coherent risk measure (see Artzner, Delbaen, Eber, & Heath, 1999). In fact, our result extends to aggregators of the formθsupP∈PEP+(1−θ)infQ∈QEQ,with θ ∈ [0, 1], and even to more complex convex combinations of infima and suprema as shown in Proposition 31 in Appendix A.Our result extends to a Markovian setting where one-step aggregatorsGtand Φtare indexed by the state x. More precisely, the coefficient αtand βtand the set of probabilityPtcan depend on the state x.Our result differs from the work of Ruszczyski (2010, Theorem 2) in two ways. On the one hand, Ruszczyński provides arguments to show that there exists an optimal Markovian policy among the set of adapted policies (that is, having a policy taking as argument the whole past uncertainties would not give a better cost than a policy taking as argument the current value of the state). We do not tackle this issue since we directly deal with policies as functions of the state. Where we suppose that there exists an admissible policy π♯ ∈ Πad such that (29) holds true, Ruszczyński gives conditions ensuring this property. On the other hand, where Ruszczyński restricts to the sum to aggregate instantaneous costs, we consider more general one-step time-aggregators Φt. For instance, our results applies to the product of costs.We introduce a class of dynamic uncertainty criteria, that are related to convex risk measures (see Föllmer & Schied, 2002), and we show that they display time-consistency. We consider the same setting as in Section 4.1, with the restriction that βt≡ 1 in (33) and an additional data (Υt)t ∈〚0, T〛.LetP0⊂P(W0),...,PT⊂P(WT),and (Υt)t ∈〚0, T〛be sequence of functions, each mappingP(Wt)intoR¯. Let (αt)t ∈〚0, Tbe sequence of functions, each mappingR¯intoR. We set, for all t ∈〚0, T〛,(37)ϱt,Tcx({As}tT)=supPt∈PtEPt[⋯supPT∈PTEPT[∑s=tT(αs(As)−Υs(Ps))]⋯],for any adapted uncertain process{At}0T,with the convention thatαT(cT)=cT.Proposition 28Time-consistency holds true for•the dynamic uncertainty criterion{ϱt,Tcx}t=0Tgiven by (37),the Markov optimization problem(38)minπ∈Πadϱt,Tcx({Jt,sx,π}s=tT),∀t∈〚0,T〛,∀x∈Xt,whereJt,sx,π(w)is defined by (22), as soon as there exists an admissible policy π♯ ∈ Πadsuch that, for all t ∈〚0, T − 1〛, for allx∈Xt,πt♯(x)∈argminu∈Ut(x)supPt∈Pt{EPt[αt(Jt(x,u,·))+Vt+1∘ft(x,u,·)]−Υt(Pt)},where the value functions are given by the following DPE(39a)VT(x)=supPT∈PTEPT[JT(x,·)]−ΥT(PT),(39b)Vt(x)=minu∈Ut(x)supPt∈Pt{EPt[αt(Jt(x,u,·))+Vt+1∘ft(x,u,·)]−Υt(Pt)}.We follow the proof of Proposition 27, wherethe one-step time-aggregators are defined by(40a)Φt{ct,ct+1}=αt(ct)+ct+1,∀t∈〚0,T−1〛,∀(ct,ct+1)∈R¯2,and the one-step uncertainty-aggregators are defined by(40b)Gt[Ct]=supPt∈PtEPt[Ct]−Υt(Pt),∀t∈〚0,T−1〛,∀Ct∈F(Wt;R¯).We show that, for any t ∈〚0, T − 1〛and s ∈〚t + 1, T〛,Gscommutes with Φt(we could also apply Proposition 31). Letting ctbe an extended real number inR¯and Csa function inF(Ws;R¯),we haveGs[Φt{ct,Cs}]=supPs∈Ps{EPs[α(ct)+Cs]−Υs(Ps)}by(40a)and(40b)=αt(ct)+supPs∈Ps{EPs[Cs]−Υs(Ps)}=αt(ct)+Gs[Cs]by(40b)=Φt{ct,Gs[Cs]}by(40a).This ends the proof.□The one-step uncertainty-aggregatorsGtin (40b) correspond to a convex risk measure (see Föllmer & Schied, 2002). Moreover, Proposition 31 shows that we could also consider any positive linear combination of suprema and infima of expectation.A special case of coherent risk measures consists of the worst case scenario operators, also called “fear operators”. For this subclass of coherent risk measures, we show that time-consistency holds for a larger class of time-aggregators than the ones above.For any t ∈〚0, T − 1〛, letW˜tbe a non empty subset ofWt,and letΦt:R¯2→R¯be a function which is continuous and non-decreasing in its second variable. We set, for all t ∈〚0, T〛,(41)ϱt,Twc({As}tT)=sup{ws}tT∈W˜t×⋯×W˜TΦt{At({ws}tT),Φt+1{⋯,ΦT−1{AT−1(wT−1,wT),AT(wT)}}},for any adapted uncertain process{At}0T.Note thatϱt,Twcis the fear operator on the Cartesian productW˜t×⋯×W˜T.Proposition 29Time-consistency holds true for•the dynamic uncertainty criterion{ϱt,Twc}t=0Tgiven by (41),the Markov optimization problem(42)minπ∈Πadϱt,Twc({Jt,sx,π}s=tT),whereJt,sx,π(w)is defined by (22), as soon as there exists an admissible policy π♯ ∈ Πadsuch that, for all t ∈〚0, T − 1〛, for allx∈Xt,πt♯(x)∈argminu∈Ut(x)supwt∈W˜tΦt{Jt(x,u,wt),Vt+1∘ft(x,u,wt)},where the value functions are given by the following DPE(43a)VT(x)=supwT∈W˜TJT(x,wT),(43b)Vt(x)=minu∈Ut(x)supwt∈W˜tΦt{Jt(x,u,wt),Vt+1∘ft(x,u,wt)}.We follow the proof of Proposition 27, where(44)Gt[Ct]=supwt∈W˜tCt(wt),∀t∈〚0,T−1〛,∀Ct∈F(Wt;R¯).We prove that, for any t ∈〚0, T − 1〛and s ∈〚t + 1, T〛,Gscommutes with Φt. Letting ctbe an extended real number inR¯andCsa function inF(Ws;R¯),we haveGs[Φt{ct,Cs}]=supws∈W˜s[Φt{ct,Cs(ws)}]by(44),=Φt{ct,supw∈W˜s[Cs(ws)]}bycontinuityofΦt{ct,·},=Φt{ct,Gs[Cs]}by(44).This ends the proof.□We consider the following long term investment problem. Let Jt(xt, ut, wt) be the cost incurred at time t in the state xt, under decision utand uncertainty wt. The state xtincludes economic indicators, one of them affecting the discount factore−rt(xt). Hence, the time-aggregation of the cost process is given by(45)∑t=0T−1e−rt(It)Jt(Xt,Ut,Wt).We suppose that the one-step uncertainty aggregators are coherent risk measures(46)Gtxt[·]=supQ∈P(xt)EQ[·],where the probability setP(xt)of beliefs is allowed to depend on the economic indicators in xt.Such an optimization problem, where both discounting and beliefs depend on the state, falls into the framework developped in Section 4.1 in its Markovian version.In environmental economics literature, when time spans across generations (like with climate change issues), scholars discuss the use of additive time preferences. Indeed, additivity implies possible compensations between distant generations, and discounting can lead to myopic decisions (Clark, 1990; Weitzman, 2007). The so-called Rawls or maximin criterion (De Lara & Doyen, 2008)(47)min{J0(x0,u0,w0),⋯,JT−1(xT−1,uT−1,wT−1)}is a possible alternative, which can be obtained by aggregation of one-step time-aggregators Φt{ct, ct + 1} = max {ct, ct + 1}. Now, when the uncertainty aggregator is the worst-case operator over the Cartesian productW˜t×⋯×W˜T−1,the resulting optimization problem falls into the framework developped in Section 4.3.We consider a family of risk-sensitive optimization problems(48)minlog(E[exp(∑t=t0T−1Jt(Xt,Ut,Wt))])Xt+1=ft(Xt,Ut,Wt),Xt0=x0Ut∈Ut(Xt).This family is time-consistent, after an equivalent reformulation as follows. First, as the function log  is increasing, it is equivalent to minimize its argument. Second, denotingJ˜t(Xt,Ut,Wt)=exp(Jt(Xt,Ut,Wt)),we arrive at the following optimization problemminE[∏t=t0T−1(J˜t(Xt,Ut,Wt))]Xt+1=ft(Xt,Ut,Wt),Xt0=x0Ut∈Ut(Xt).Hence, by changing costs, we are falling into the setting of Proposition 27, and we can write a time-consistent Markov decision problem equivalent to Problem 48.

@&#CONCLUSIONS@&#
