@&#MAIN-TITLE@&#
Joint view-identity manifold for infrared target tracking and recognition

@&#HIGHLIGHTS@&#
We propose a new joint view-identity manifold (JVIM) for multi-view shape modeling.JVIM is well-suited for target tracking and recognition (ATR) in infrared (IR) imagery.We propose a new GPLVM-based algorithm for JVIM learning and inference.Experimental results on both the synthetic CAD data and recent IR database demonstrate JVIM’s advantages over several recent shape models.

@&#KEYPHRASES@&#
Automatic target tracking and recognition,Manifold learning for shape modeling,Generative models,GPLVM,Shape interpolation,

@&#ABSTRACT@&#
We propose a new joint view-identity manifold (JVIM) for multi-view and multi-target shape modeling that is well-suited for automated target tracking and recognition (ATR) in infrared imagery. As a shape generative model, JVIM features a novel manifold structure that imposes a conditional dependency between the two shape-related factors, view and identity, in a unified latent space, which is embedded with one view-independent identity manifold and infinite identity-dependent view manifolds. A modified local linear Gaussian process latent variable model (LL-GPLVM) is proposed for JVIM learning where a stochastic gradient descent method is used to improve the learning efficiency. We also develop a local inference technique to speed up JVIM-based shape interpolation. Due to its probabilistic and continuous nature, JVIM provides effective shape synthesis and supports robust ATR inference for both known and unknown target types under arbitrary views. Experiments on both synthetic data and the SENSIAC infrared ATR database demonstrate the advantages of the proposed method over several existing techniques both qualitatively and quantitatively.

@&#INTRODUCTION@&#
With the ability to detect, track and recognize both known and unknown targets, automated target tracking and recognition (ATR) is widely used in a variety of military and civilian applications. Most ATR algorithms involve a motion (or dynamic) model and an appearance representation of the target-of-interest that can play complementary roles for ATR inference [1]. Particularly, appearance modeling is a critical issue in vision-based ATR methods since the target’s appearance can change dramatically due to the variation of viewpoints and its own 3D structures. An ideal model should have a few attributes. (1) It should be flexible enough to adapt to different imaging conditions (e.g., different viewpoints) and a wide range of possible target types; (2) It should be accurate to reflect detailed appearance variability; (3) It should be robust under noise and occlusion. In this work, we are primarily interested in the first aspect, and our research is conducted in the context of infrared (IR) ATR, which is challenging due to a host of factors including low target contrast, heavy clutter, low resolution, poor signal-to-noise ratios (SNR), and the variations of target appearance resulting from changing environmental and imaging conditions [2]. Specifically, we study multi-view shape-based target modeling due to its simplicity and robustness for most ATR applications.There are three main approaches for handling view changes in IR appearance modeling. First, the single view-based methods usually require a learning mechanism to update the model “on-the-fly”, e.g., [3,4]. The tracking and recognition results could be sensitive to the viewpoint initialization and the learning strategy. Second, the multi-view methods use multiple snapshots to approximate or interpolate unknown or intermediate views from a given set of training samples. For example, templates [3,5], histograms [6], edge features [7], and SIFT [8], etc., are popular non-parametric representations for these snapshots. When needed, appearance interpolation can be performed in the high-dimensional data space or in a low-dimensional latent space [9]. This is theoretically supported by the psychophysical evidence presented in [10], which suggests that the human visual system is better described as recognizing objects by 2D view interpolation than by alignment or other methods that rely on object-centered 3D models. However, these methods can normally only deal with known objects by involving a discrete identity variable. Third, a 3D target model can also be used to handle the view-induced appearance changes, e.g., [11], and a 3D to 2D projection is generally required to project the 3D model onto the 2D image plane subject to the view angle. These methods are mainly focused on known targets and may require substantial memory and computational resources to operate on 3D models.On the other hand, manifold learning has been proven to be a popular approach to shape modeling which creates a variety of meaningful shape priors to assist or constrain the inference process for both visible-band and infrared vision applications, e.g., [12]. Normally, a shape manifold embedding in a low-dimensional latent space can be learned from a set of shape exemplars which can effectively capture the shape variability due to different views, objects, poses or other shape-related factors. For example, in [13] a non-linear tensor decomposition method was used to learn an identity-independent view manifold for multi-view dynamic motion data modeling. In [9], a cylindrical manifold embedding was used to represent 1D hand pose variation and cyclic viewpoint variation and applied to IR hand modeling. In [14,15], a couplet of view and identity manifolds (CVIM) was applied to shape modeling where two manifolds were coupled independently into a compact shape generative model via non-linear tensor decomposition.In this paper, we propose a new joint view-identity manifold (JVIM) for multi-view and multi-target shape modeling that is suited for a variety of ATR applications. In JVIM, the two shape related variables, identity and view, are jointly represented through a shared manifold structure which involve one view-independent identity manifold and infinite identity-dependent view manifolds in a unified latent space. JVIM is learned by a modified topologically constrained GPLVM (LL-GPLVM) [16] where two joint topology priors, one for view manifolds and the other for the identity manifold, were incorporated to encourage a sensible manifold in the low-dimensional latent space. Specifically, the issue of local neighborhood selection along the topology priors plays three important roles in JVIM learning and inference. First, the topology constraint is specified by using local linear embedding [17] that involves a set of neighbors for each reference point in the latent space. Second, inspired by the stochastic gradient descent method in [18], we develop a local model learning algorithm that involves topology-aware neighborhood selection. Third, in a similar spirit, a local inference technique is proposed to support fast shape interpolation where a new shape is synthesized by involving a small set of neighbors instead of the whole training set.Essentially, the proposed JVIM is a new latent variable model that has some distinctions from it peers and precedents. First, compared with most GPLVM-based methods [19–21,16] where only one continuous-valued variable (e.g., the pose in human motion modeling) is explicitly defined in the latent space, JVIM supports multiple continuous-valued latent variables in a joint latent space (both view and identity). Also, different from non-linear tensor techniques [22,9,14] which provide a multi-factor deterministic representation via nonlinear mapping followed by tensor decomposition, JVIM is learned by an iterative probabilistic optimization that not only provides the uncertainty for each interpolated shape, but also can be used as a shape prior for statistical inference. Additionally, the stochastic gradient-based learning and local inference make JVIM efficient and practical for real-world ATR applications where a large number of training samples is usually involved. In this work, we evaluate JVIM against Nearest Neighbor (NN), GPLVM [19,20], LL-GPLVM [16] and CVIM [14] for multi-view shape modeling on synthetic CAD data, and examine its performance on the SENSIAC infrared ATR database [23] by comparing with NN, LL-GPLVM and CVIM.The remainder of this paper is organized as follows. Related work in the area of manifold-based shape modeling is reviewed in Section 2. Some background materials are presented in Section 3. JVIM is discussed in detail in Section 4 and the results of shape interpolation and ATR experiments against real IR data are given in Section 5. Finally, we draw conclusions in Section 6.

@&#CONCLUSIONS@&#
