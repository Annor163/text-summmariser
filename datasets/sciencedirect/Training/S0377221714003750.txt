@&#MAIN-TITLE@&#
Infrastructure security games

@&#HIGHLIGHTS@&#
We introduce novel static and dynamic security game models that treat crowds as moving targets.We show that the static game has the unique equilibrium in closed form and the equilibrium is of threshold type.An algorithm for the dynamic patrol game through an illustrative example is provided.

@&#KEYPHRASES@&#
Uncertainty modeling,Game theory,Matrix game,Bayesian game,Moving targets,

@&#ABSTRACT@&#
Infrastructure security against possible attacks involves making decisions under uncertainty. This paper presents game theoretic models of the interaction between an adversary and a first responder in order to study the problem of security within a transportation infrastructure. The risk measure used is based on the consequence of an attack in terms of the number of people affected or the occupancy level of a critical infrastructure, e.g. stations, trains, subway cars, escalators, bridges, etc. The objective of the adversary is to inflict the maximum damage to a transportation network by selecting a set of nodes to attack, while the first responder (emergency management center) allocates resources (emergency personnel or personnel-hours) to the sites of interest in an attempt to find the hidden adversary. This paper considers both static and dynamic, in which the first responder is mobile, games. The unique equilibrium strategy pair is given in closed form for the simple static game. For the dynamic game, the equilibrium for the first responder becomes the best patrol policy within the infrastructure. This model uses partially observable Markov decision processes (POMDPs) in which the payoff functions depend on an exogenous people flow, and thus, are time varying. A numerical example illustrating the algorithm is presented to evaluate an equilibrium strategy pair.

@&#INTRODUCTION@&#
The September 11, 2001 attacks introduced the term homeland security into the public consciousness around the world. In the United States, this term is defined as “a concerted national effort to prevent terrorist attacks within the United States, reduce America’s vulnerability to terrorism, and minimize the damage and recover from attacks that do occur” (Homeland Security Act 2002 Congress, 2002). Within this effort, protecting critical infrastructure has become an utmost priority for governments (Moteff, 2005). Executive Order 13010 (Clinton, 1996) signed by President Clinton in 1996 identifies transportation infrastructure as a critical system supporting the national security and economic well-being of this nation. Moreover, as the Bali and Madrid bombings illustrate, terrorists also target large crowds. Public transit systems, used daily by 32million mass transit riders in the United States, and places of mass gathering such as shopping malls and stadiums are considered part of the critical infrastructure (Bennett, 2007; Boin & Smith, 2006; Rothery & Branch, 2005). Public transit systems by design are open structural environments equipped to move large numbers of mass transit patrons in an effective and efficient manner. Therefore, mass transit systems are considered soft targets similar to the other public places that are inherently vulnerable and susceptible to terrorist attacks and which, because of the continuous hours of service, cannot be closed and secured as may other sectors of the area transportation system (Loukaitou-Sideris, Taylor, & Fink, 2006). Successful and attempted terrorist attacks throughout the world such as New York, Bali, Madrid, London, Mumbai, Russia, and Norway clearly demonstrate that terrorists’ primary mission remains to be to cause mass human casualties in addition to panic and chaos (Bennett, 2007). The threat to any given infrastructural component or “infrastructure” could be substantially reduced by analyzing the risk associated with each transit infrastructure, mitigation planning, and employing best prevention and response policies.There has been a recent interest in issues related to infrastructure security. A major tool for risk assessment, probabilistic risk analysis (PRA) (Kaplan & Garrick, 1981), has also been applied to terrorism risks (Garcia, 2005; Garrick et al., 2004; McGill, Ayyub, & Kaminskiy, 2007; Paté-Cornell, 2002a; Paté-Cornell, 2002b). On the other hand, the National Research Council N.R.C. of the National Academies, 2008 has emphasized game theoretic models (Cournot, 1971; Isaacs, 1965; Nash, 1951; Von Neumann & Morgenstern, 1944; Von Neumann, Morgenstern, Rubinstein, & Kuhn, 2007) to counter the need for adaptation to the dynamic behavior of the terrorism events and adversarial decision-making processes of terrorists. One such model, ARMOR (Paruchuri et al., 2007, 2008; Paruchuri, Tambe, Ordez, & Kraus, 2005, 2006; Pita et al., 2008), casts the interdiction problem as a Bayesian Stackelberg game (Basar & Olsder, 1999), and has been deployed to secure the Los Angeles International Airport. However, this model is static in the sense that it is solved every day with new parameters and the payoff functions for players remain the same throughout the day and the players are assumed to be rational. Aside from the ARMOR game, Brown, Carlyle, Salmeron, and Wood (2006) consider various Stackelberg games, while others study network interdiction games (Atkinson, Cao, & Wein, 2008; Atkinson & Wein, 2008; Johnson & Gutfraind, 2011; Gutfraind & Hagberg, 2009; Lim & Smith, 2007; Morton, Pan, & Saeger, 2007; Washburn & Wood, 1995; Wein & Atkinson, 2007; Wein, 2009; Wood, 1993), secrecy and deception (Dighe, Zhuang, & Bier, 2009; Zhuang & Bier, 2007, 2009; Zhuang, Bier, & Alagoz, 2010), passenger classification (Nie, Batta, Drury, & Lin, 2009a; Nie, Batta, Drury, & Lin, 2009b), and optimal placement of suicide bomber detectors in a grid structure (Nie, Batta, Drury, & Lin, 2007). Hochbaum and Fishbain (2011) investigate the allocation of mobile sensors in an urban environment in order to detect dirty bombs. Note that the models in Nie et al. (2009a, 2009b) and Nie et al. (2007) involve only a single controller and not multiple decision makers as in game models.In this paper, we approach the infrastructure security problem via game theory by modeling it via hide-and-seek games (Alpern, Baston, & Gal, 2008; Alpern & Gal, 2003; Alpern, Morton, & Papadaki, 2011; Dobbie, 1968; Garnaev, 2000; Hespanha, Prandini, & Sastry, 2000; Hohzaki, 2007; Jotshi & Batta, 2008; Alpern et al., 2011; Suzuki & Yamashita, 1992; Thomas & Washburn, 1991). There are two settings for such games: static and dynamic. In the static model, a first responder (emergency-management center) allocates resources (emergency personnel, or personnel-hours) to sites of interest in an attempt to find an object (person or bomb, “adversary”) that has been hidden, while the adversary selects a set of best sites to attack. Once the object is hidden, it cannot move during the search process. Similarly, the first responder can act only once. Various different games have been defined for dynamic situations depending on the mobility of the agents. Search games (Gal, 1980) involve a mobile defender and an immobile adversary, while ambush games (Ruckle, 1981) have a mobile adversary and an immobile defender, who waits for the adversary to appear. Finally, if both agents are mobile, such games could be pursuit–evasion games (Isaacs, 1965; Hespanha et al., 2000) or infiltration games (Alpern, 1992; Garnaev, Garnaeva, & Goutal, 1997). Most research has focused on the case in which the cells are identical. However, Neuts (1963) and later on Sakaguchi (1973) consider a zero-sum dynamic search game with node dependent inspection costs. Moreover, there may be a possibility of type 1 error, i.e., false negative, associated with each node, i.e., the probability that the first responder finds the adversary given that the adversary is in the searched node may be less than 1. In general, in the hide-and-seek games there are no attack targets, in fact, the adversary is the target. One exception arises in the interdiction games (Washburn & Wood, 1995; Wood, 1993) in which the adversary tries to reach a target while the defender tries to prevent the adversary from reaching the target, thereby protecting the target. Recently, interdiction games with various targets have been considered. Such games are called protection games (please see Basilico, Gatti, & Amigoni (2012) and the references therein).In this paper, we study protection games. Focusing on severe attacks, we consider the loss of human life as the consequence of the attack, i.e., the payoff to the adversary. This measure typically depends on the occupancy level of the facility and we assume that the occupancy level can be estimated over time. Hence the crowds are the targets in this game and since they are moving over time they are dynamically moving targets. The static version of this game becomes a simple zero-sum game related to the one considered by Neuts (1963) and Sakaguchi (1973). However, contrary to their case we observe that in our game a continuum equilibrium for the adversary may exist under certain conditions. In the dynamic game model, we assume that the first responder can move among the nodes to search for a hidden immobile adversary. This game is called as patrolling game (Alpern et al., 2011; Basilico et al., 2012) with the additional feature of multiple mobile targets. We sometimes refer to resources allocated to the nodes also as first responders. The main idea here is that if the emergency-management center has a finite number of first responders, it then allocates fractions of first responders to the nodes. Throughout we use first responder and defender, and, respectively, adversary and attacker, synonymously.The contributions of this paper are itemized below.•A new static game is introduced that considers the occupancy of a node as the payoff to the adversary. This game is shown to have a unique equilibrium for the first responder in closed form. However, the adversary may have a continuum of equilibria, also given in closed form. The equilibria are of threshold type, i.e., the resources are allocated to the nodes with occupancy higher than a threshold value.A novel protection game with dynamically moving targets is introduced, and its solution algorithm through an illustrative example is provided.The structure of the paper is as follows. In Section 2, we consider the static game and present the unique equilibrium in closed form. In Section 3, a people flow model is introduced. In Section 4, a dynamic game between an immobile adversary and a mobile first responder is discussed. In Section 5, we present a numerical example for the dynamic game. Finally, further applications and future research directions are discussed in Section 6.In this section, we consider the one-step security problem. The adversary and the first responder simultaneously choose their strategies over the potential sites. Payoff matrices for both responder and adversary are based on the occupancy level of each site in the infrastructure. Even when both rivals are at the same site, there is a probability that the first responder may not detect the adversary. We do not consider the possibility of type 2 error, false positive, and assume that if an attacker is found then s/he is the adversary with certainty.We assume that the infrastructure can be partitioned into nodes. This could be achieved, for example, as described in Kolling and Carpin (2008) and Portugal and Rocha (2012). We further assume that the impact of an attack will be based upon the occupancy level of the specific node at which the attack happens and can only endanger the people at that node. People in neighboring nodes will not be hurt directly due to this attack. We assume that the probability of detection, and the occupancy of each node, are known to both rivals.Although we represent the infrastructure in the figures as an m by n grid, it will be considered as an undirected graph withN=mnnodes, which the responder and the adversary can occupy (possible actions for both players). Bold case letters represent vectors; for example, the occupancy vector is denoted asOwhereO(i)is the occupancy level of nodei=1,2,…,N, which is a random variable. LetCidenote the number of casualties if node i is attacked. Assuming that the attack causes maximum damage, the number of casualties will be equal to the occupancy of the cell. This value may, in addition, include a term accounting for the occupancy of the adjacent nodes. However, for the sake of brevity, we assumeCi=O(i).Let(i,j)denote the location of the first responder and the adversary, respectively. In the case in which both of them are at the same node,(i,i), the adversary can be found by the responder with detection probability given byPD(i,i)=▵di, otherwisePD(i,j)=▵0fori≠j. Therefore, the(i,j)-th component of the payoff matrix for the responder when the responder is searching node i and the adversary is attacking node j is,rij=-(1-PD(i,j))Cjfor alli,j=1,…,N. Under the above assumptions, the payoff matrix R for the first responder is anN×Nmatrix with the following elements for the action pair(i,j)of the first responder and the adversary, respectively:withdi∈(0,1].Letx=(x1,x2,…,xN)Tbe a (mixed) strategy column vector for the first responder wherexiis the probability of searching node i. Clearly,∑i=1Nxi=1, andxi⩾0, for alli∈{1,…,N}. A (mixed) strategy for the adversary,y, is similarly defined, whereyiis the probability of attacking node i. We assume that the rivals know only expected values ofCianddi, namely, they know thatCi=Cik,manddi=dik,mwith probabilityqik,m, wherek∈[1,K]andm∈[1,M], for some K and M. In Remark 2 when we discuss the Bayesian game, we will associate K with the number of first responder types and M with the number of adversary types. The expected payoff to the first responder if the rivals apply mixed strategiesxandyis given as follows:(2.1)v(x,y)=-∑m=1M∑k=1K∑i=1Nxi∑j=1NCjk,mqjk,myj-dim,kCik,mqik,myi=-∑i=1NE(Ci)-E(Cidi)xiyiwithE(Ci)=▵Ci^=∑m=1M∑k=1KCik,mqik,mandE(Cidi)=▵diCi^=∑m=1M∑k=1KCik,mdik,mqik,m. Clearly,v(x,y)⩽0for all strategy pairs(x,y). The payoff to the adversary is-v(x,y), thus giving a zero-sum game. Note that(x∗,y∗)is a saddle point (Nash equilibrium) if and only if the following inequalities hold:(2.2)v(x,y∗)⩽v(x∗,y∗)⩽v(x∗,y)forany(x,y).When the saddle point exists,v=v(x∗,y∗)is the value of the game.This game is closely related to a multistage game of Neuts (1963) and a two-sided search game suggested by Sakaguchi (1973), but our game has one interesting particular phenomenon as is shown in the next theorem; namely, under particular conditions continuum equilibria could arise.For the sake of brevity, we assume that(2.3)C1^>C2^>⋯>CN^.Next we present a brief version of the theorem that shows the game has a unique defender equilibrium in closed form. However, the adversary may have a continuum of equilibria under certain conditions, also given in closed form. The equilibria are of threshold type, i.e., the resources are allocated by both rivals to the nodes with value higher than a threshold as given below. The detailed statement and proof of the theorem can be found in Appendix A.Theorem 1Ifv∗≠-Ck^, then the game has the unique equilibrium(x∗,y∗)given in terms of the indexk∈{1,…,N}such thatφk⩽1<φk+1, where{φi}is a strictly increasing sequence defined asφi=∑j=1i(Cj^-Ci^)/djCj^, fori∈{1,…,N,}andφN+1=∞.The strategy of the defender is of threshold type given byxi∗=1/(diCi^)∑j=1k1(djCj^)1-∑j=1kCj^-Ci^djCj^fori⩽k, and 0 ifi⩾k.The strategy of the adversary is also of threshold type given byyi∗=[1/(diCi^)]∑j=1k1/(djCj^), fori⩽k, and 0 otherwise.The value of the game is given byv∗=1-∑j=1kCj^/Cjdj^∑j=1k1/(djCj^).In the case in which some of the node values are the same, the equilibrium policies will be essentially similar to the one given in Theorem 1; however, the exact values for the equilibrium would be more cumbersome.Remark 1If all the nodes have the same detection probability, i.e.dim,k=dfor everyi,m,k, then the equilibrium strategies are monotonic, namely,xi∗’s are decreasing in i, i.e.x1∗>x2∗>⋯>xk∗, and meanwhileyi∗’s are increasing, i.e.y1∗<y2∗<⋯<yk∗.If the rivals have different knowledge about the values ofCianddi, the robust game (Aghassi & Bertsimas, 2006) or Bayesian (Harsanyi, 1967; Harsanyi, 1968a, 1968b) approaches have to be applied. In the Bayesian approach several scenarios can arise depending on the information the rivals have. For example, only the first responder may know the exact values of thedi’s, but the adversary does not know them. Differentdi’s may be caused, for example, by the level of sensor technology used, or the difference in the training level of the first response teams. Let the detection probability of the i-th node bedik, fork∈[1,K]and assume that the adversary only knows that it isdikwith probabilityqk. Similarly, the adversary may know the exact values of theCi’s, but the first responder does not know them. Differences inCican be caused, for example, by the difference of attack devices the adversary could use. Let the number of casualties at node i beCim, form∈[1,M]and assume that the first responder only knows that it isCimwith probabilitypm. This situation can also be described as if each rival is of different type. Letxk=(x1k,…,xNk)andym=y1m,…,yNmbe strategies of the type k and type m of the first responder and the adversary, respectively.Then the payoff to the adversaryvAmof type m and to the first responder of type k are given as follows:vAm(X,ym)=∑k=1Kqk∑i=1NCim1-dikxikyim,vRk(xk,Y)=∑m=1Mpm∑i=1NCimdikxik-1yim,withX=(x1,x2,…,xK)andY=(y1,y2,…,yM).The Bayesian equilibrium(X∗,Y∗)satisfies the following inequalities for any(X,Y):vAm(X∗,ym)⩽vAmX∗,y∗m,∀m,vRk(xk,Y∗)⩽vRkx∗k,Y∗,∀k.Note that in this case a non-zero-sum game arises. Computing Bayesian equilibrium is commonly addressed by reducing the Bayesian game into a complete information game (see, for example Shoham & Leyton-Brown (2008)) and computing a Nash equilibrium. Fig. 1shows the payoff to the adversary as a function of the probabilityγ, and the value of node4,t, forN=4,C=(1.8,1.5,1,t)witht∈[0.5,2.3],d1=(0.1,0.2,0.3,0.5),d2=(0.5,0.3,0.2,0.1)andq=(γ,1-γ). Here t may be thought of as a continuum of adversary types differentiated by the value of the fourth node. The game is played against each type of adversary separately. This example illustrates the importance of keeping the first responder’s detection devices secret since the uncertainty about the available sensors can lead to a reduction in the possible damage.Next, we discuss the exogenous people flow model that will be used in the dynamic game in order to estimate the occupancy level of each node.We first develop an exogenous people flow model that influences the decision making of the game players. A number of researchers have used simulation models to describe the characteristics of pedestrian flow (Yue, Hao, Chen, & Shao, 2007; Hanisch, Tolujew, Richter, & Schulze, 2003; Rindsfüser & Klügl, 2007). Yue et al. (2007) introduce a simulation model based on cellular automata on the square lattice with two-way and four-way pedestrian flow. In this simulation framework, pedestrian movement is more flexible and adaptive to dynamic conditions than in vehicular flow. Hanisch et al. (2003) develop an online simulation tool for pedestrian flow in large public buildings, such as train stations, airports, and shopping centers. There is also research that concentrates on occupancy estimation (Meyn, Surana, Lin, Oggianu, et al., 2009; Niedbalski, Mehta, & Meyn, 2007, 2008). Meyn, Surana, Lin, Oggianu, et al. (2009) introduce a sensor-utility-network (SUN) method for occupancy estimation in buildings. Other studies have focused on the pedestrian flow in public buildings following special events, such as football matches, emergency fires, and terrorist attacks, with crowd control and optimal evacuation as the main objectives (Deng, Chen, Mehta, & Meyn, 2008; Helbing, Farkas, Molnar, & Vicsek, 2002; Klüpfel & Meyer-König, 2004a, 2004b; Meyn, Surana, Lin, & Narayanan, 2009; Tomastik, Narayanan, Banaszuk, & Meyn, 2010). Alternating periods of congestion and slow movement dominate these cases, and most research on this topic relies on simulation models as in Bauer, Seer, and Brandle (2007) and Deng et al. (2008).For our purposes, we model people flow in a public building as a linear, stochastic dynamic system, and assume that some sensory information is available to be used in correcting the occupancy estimates. In this paper, we will not take into account the effects of special events, and also we will not consider crowd control problems.At the microscopic level, people move as if they were in an open queuing network where each node is considered as a queueing station. Time is discretized, and the time horizon is finite and is equal to T. Nodes may have external arrivals and departures, from and to the outside, respectively, if there is direct connection to the outside, such as entrance doors, or train platforms from which people get on or off the train. Other nodes in the building could be ticket offices, waiting rooms, food courts, shops, hallways, etc.For those nodes with entrances, an arrival rate is estimated, captured in a vectorλ∈RNwhose elements are arrival rates for each node per unit time. Arrival rates may be time varying, asλ(n), representing peak and off peak hours during the day. At each time period, people move from one node to the other according to the probabilities given by the routing matrix,F. We assume that pedestrians are all similar, and thus, they all have the same routing probability. These assumptions result in the following stochastic linear dynamic system of equations representing the pedestrian flow:On+1=FT·On+λn+1+Wn+1,Wn+1∼N(0,Q)Zn=H·On+Γn,Γn∼N(0,Ξ).The first equation is the state equation, in whichOndenotes the occupancy vector, andWndenotes the process noise at time n, which is assumed to be normally distributed with covariance matrix Q. The second equation is the observation equation.Zn∈RMis the measurement vector of actual occupancies at timen,His the measurement matrix, andΓdenotes the measurement noise which is normally distributed with covariance matrixΞ. These measurements are obtained from video cameras, sensors, and other inspection methods. Here M may be less than N, meaning that not all node occupancies may be available. However, we assume that the system is observable.A Kalman filter is used to predict and correct the occupancy level estimates. The Kalman filter is an efficient recursive filter that estimates the state of a linear dynamic system from a series of noisy measurements (Kalman, 1960, 1962; Kalman & Bucy, 1961; Gürsoy & Baykal-Gürsoy, 2010). At each time period, the responder will observeZn, the occupancy vector, and then use these measurements to correct occupancy level forecasts. The equations for the Kalman filter are as follows:(3.1)O^n+1-=FT·O^n+λn+1;(3.2)O^n+1=O^n+1-+Kn+1·Zn+1-HO^n+1-;(3.3)Pn+1-=FT·Pn·F+Q;(3.4)Pn+1=(I-Kn+1H)·Pn+1-wherePnandPn-are the posterior and prior estimation error covariance matrices, respectively.Kn+1is the Kalman gain given byKn+1=Pn+1-HT·HPn+1-HT+Ξ-1.In these equations,O^n+1-andPn+1-are the forecast values that are used to determine the initial position and initial patrol sequence.O^n+1andPn+1are the corrected values after each measurement. They are used at the beginning of each time period to reevaluate and update the original patrol sequence.Example 1Fig. 2shows an example representing the node occupancies in a2×2grid. This figure is taken from the simulation package we have developed for this application. The number in each node represents the current occupancy level. Nodes are numbered from 1 to 4, the top left node being 1, and the bottom right node being 4. Assuming that there are entrances at nodes 1 and 4, we have the following arrival rate vector:λT=(λ1,λ2,λ3,λ4)=(λ1,0,0,λ4),where bold letters denote vectors, and the superscript T denotes the vector transpose. Below is a4×4matrix representing the routing matrix.F=0.20.30.300.20.300.50.400.10.500.30.20.2.From this matrix, notice that people leave the infrastructure from node 1 with probability1-0.2-0.3-0.3=0.2, will go to node 2 and 3 with the same probability 0.3, and will stay at node 1 with 0.2 probability. Similarly, people leave node 4 with probability1-0.3-0.2-0.2=0.3. Again, those nodes in which people can enter or leave correspond to entrance doors, the train platforms where they can get on and off trains, etc.In this section, we consider a mobile first responder dynamically choosing nodes to search for an immobile adversary. The first responder’s objective is to develop a “best” patrol strategy to find the adversary with maximum reward or minimum cost. We assume that if the adversary is not caught within a finite time, say T, the adversary will launch the attack and destroy occupants in the node s/he is in at time T. The first responder does not know the exact location of the adversary. Furthermore, the responder may not also have the current occupancy information. However, some sensory data are assumed to be available in order to develop for example, the above discussed people flow model, and make accurate estimates. Next, we describe the methodology to obtain best strategies for both players.Occupancy estimates together with the detection probabilities establish the performance measure on the infrastructure grid. Note that only the first responder is mobile. Thus, after choosing the initial locations the first responder can patrol the premises to find the adversary while the adversary remains at its initial location. Next, we describe the first responder’s patrol strategy starting from an initial position. Then, we will discuss the first responder’s and adversary’s strategies for choosing the best initial location.Consider discrete time periods{n=0,1,2,…,T}and the grid structure representing the infrastructure. The state of the system is given bylnf,lna,On,Pn, wherelnfandlnadenote the position of the first responder and the adversary, respectively, at time m. Since the adversary is immobile,lna=la. However, the adversary’s location cannot be observed and the first responder has information only about his/her own location, i.e.,lnfandPn; thus, arises the need to use the POMDP (partially observable Markov decision process) model to solve this problem.Let the first responder’s belief state bebn=lnf,pna,O^n,Pn. Here,pnais the vector of belief probabilities of the adversary’s location.O^nis the estimated occupancy vector at time n. The value function for the responder at timen=0,…,T-1is given by(4.1)Vnf(bn)=maxk∈Af{lnf}r(bn,k)+δ·(1-Pr{D|bn,k})·Vn+1f(ln+1f,pn+1a,O^n+1-,Pn+1-),wherer(bn,k)denotes the one-step expected reward function for the responder in belief statebnwhen action k is applied, andδdenotes the discount factor with(δ⩽1),kdenotes the responder’s action, i.e., the next node in the patrol route, andAf{lnf}denotes the set of the responder’s possible actions at the next time period when the responder’s current location islnf. This set is defined by the topology of the graph, i. e., the adjacency matrix. Note that throughout, we assume that the travel time between adjacent nodes is one time unit.Pr{D|bn,k}is the probability of detecting the adversary given the belief statebnand applying action k. We assume that when the responder successfully finds the adversary, the game will end, and no more rewards will be earned.O^n+1-andPn+1-are the corresponding forecast values of the occupancy levels and the error covariance matrix. The one-step expected reward function is written as(4.2)r(bn,k)=Pr{D|bn,k}O^n(k).HerePr{D|bn,k}is equal to(4.3)Pr{D|bn,k}=dkpna(k).Since the attack will materialize at the end of period T, the terminal value function is given as the negative of the expected casualty due to this attack,(4.4)VTf(bT)=-∑k=1NpTa(k)·O^T(k).Note that transitions fromO^nandPmtoO^n+1andPn+1, respectively, are associated with the people flow model and are given through Eqs. (3.1)–(3.3) and (3.4) deterministically. Also because action k identifies the location of the first responder in the next time period, the transition probability for the POMDP from statebntobn+1=k,pn+1a,O^n+1,Pn+1is as follows:(4.5)Prbn+1|bn,k=1-Pr{D|bn,k},forpn+1aasinEqs.(4.6) and (4.7)Pr{D|bn,k},forpn+1a=ek.In both cases above, the first responder moves to node k to search for the adversary, so the location of the first responder at timen+1is node k. In the first case, the first responder is not able to detect the adversary at node k, so the belief probabilities will be updated through Eqs. (4.6) and (4.7) given below. In the second case, the responder finds the adversary in node k, so the belief probability vector isek, the kth coordinate vector. The dynamic security game terminates after finding the adversary, at which point all future value functionsVnfwill be 0, and so the corresponding term in Eq. (4.1) is eliminated.We can write the Bayesian update equations for belief probabilities. If the responder fails to detect the adversary at time m in node k, then the belief probability of node k is reduced while the belief probabilities of other nodes are increased as given by(4.6)pn+1a(k)=Prla=k|pna,Detection Failed=(1-dk)·pna(k)1-dk·pna(k),(4.7)pn+1a(j)=pna(j)1-dk·pna(k)forj≠k,wheredkis the detection probability for node k.The Bellman Eq. (4.1), representing the POMDP, together with the terminal value function in Eq. (4.4), can be solved using dynamic programming algorithms. The solution provides a sequence of actions (patrol strategy) for the first responder, as well as the total expected risk or reward for the responder, i.e., the value functionVnf(bn). In most cases, given the initial position of the first responder, the patrol strategy is deterministic. However, due to different detection results and changing occupancy levels, this patrol strategy will be reevaluated after each search based on the current flow information.Next, we will discuss the initial position game between the responder and the adversary.The responder and the adversary must decide on their initial positions first. This is a static game between two players. To obtain the elements of the payoff matrix, say the(i,j)th element, first, the POMDP model generates an optimal patrol sequence starting from the initial position of the first responder (node i). Then, given the initial position of the adversary (node j), the expected payoffs are calculated based on this patrol sequence. The expected payoffs will be different from the value function obtained in the POMDP. The value function in the POMDP is the expected reward for every possible location of the adversary, however, the payoffs we obtain for this static game are the expected payoffs for the fixed location combination(i,j)of the first responder and the adversary. In this initial position game, since future sensory information is not available at the time, forecast occupancy levels are used. The elements of the reward matrix are obtained as follows:(4.8)Rf(i,j)=∑n=0T-1Pr{D at timen|S,la=j}δnO^n,j-Pr{NoDwithinT|S,la=j}δTO^T,j,whereSis the patrol sequence obtained through the POMDP withS(n)denoting the node searched at time n, andS(0)=i.Pr{NoDwithinT|S,la=j}denotes the probability that the adversary will not be detected, and thus, the attack at time T will materialize, and is given asPr{No D withinT|S,la=j}=∏m=0n-11-I{S(m)=j}dj,whereI{·}denotes the indicator function for the event represented inside the parentheses, i.e., if the event happens then the function takes value 1, otherwise its value is zero.Pr{Dattimem|S,la=j}denotes the probability that detection of the adversary happens exactly at time m, given the first responder’s patrol sequence and adversary’s position, which can be written asPr{D at timen|S,la=j}=Pr{No D withinn-1|S,la=j}I{S(n)=j}dj=∏m=0n-11-I{S(m)=j}dj·I{S(n)=j}dj,(0<n<T),Pr{D at time0|S,la=j}=I{S(0)=j}dj.This static game is then solved to obtain the mixed strategy of initial position for the first responder and the adversary. Note that with this randomized initial position for the first responder, the optimal patrol sequence will also be randomized.In this section, we use an example to explain details of the POMDP model and initial position game. First, we describe the POMDP procedure, and then we present the results of the initial position game between the responder and the adversary. Together, an optimal patrol strategy for the first responder is developed.A3×3grid infrastructure is considered, and nodes are numbered from 1 to 9 from top left to bottom right. The total number of time periods isT=7. The flow transition probabilities are given below as a9×9matrix:F=0.10.300.2000000.10.20.400.3000000.30.1000.40000.2000.10.400.30000.100.20.40.100.20000.200.30.1000.40000.2000.10.3000000.300.10.20.4000000.100.20.1.Arrival rates to each node from outside the infrastructure is as follows:λ=[25,0,20,0,0,0,10,0,15]T.The numbers of arrivals per period in the various nodes are Poisson random variables with the above arrival rates. From this, we can see that there are gates at nodes 1, 3, 7 and 9 in this facility. Initial occupancy levels are given asO0=[50,32,41,42,80,35,51,45,39]T.Q is a diagonal matrix with diagonal elements given as[25,36,50,40,37,28,48,35,40].Ξis a diagonal matrix with diagonal elements given as[10,6,8,7,8,9,4,15,10].P0is a diagonal matrix with diagonal elements given as[4,5,5,3,9,2,5,4,3].And H is an identity matrix in this example, which means that the measurements are observations of the actual occupancy levels.The detection probabilities for each node ared=[0.8,0.9,0.7,0.9,0.6,0.7,0.8,0.75,0.8]T.The prior adversary-location belief probabilities are equally distributed among 9 nodes.Detection costs are all assumed to be negligible. The discount factor isδ=1, since this is a short period game, it is appropriate to assume that penalty and reward are not discounted in such a short period.First, assuming that the initial position of the responder is known, we use the POMDP model to optimize the responder’s patrol strategy for each time period. At each time period, the responder will observeZn, the occupancy vector through video cameras, sensors or other methods, and then use these measurements to correct occupancy level forecasts. The actual occupancy levels and measurements for each time period are given as follows:(5.1)O=50975242474546393239676362656351419259795464505842544444484342538079911111131151131123535564557445043516034321645273045425950495353533971507464645959,Z=103533949434442377063656565519057795463496057474448404255779210710911311111037594760465240613732154428324256424551575773547567736161.The matrix of actual occupancy levels O is a9×8matrix, formed by column vectorsO0,O1,…,O7. MeasurementsZnfor each time period are given in the matrix Z (9×7), and column n ofZ,Zn, represents the measurements on actual occupancy levels at time n.Let the first responder start from node 4. If measurements in Z are not available, then the optimal patrol sequence for the responder is{4,5,8,9,6,3,2}. However, if they are available, then the first responder will correct the forecasts on occupancy levels, and then use the POMDP to develop a new patrol sequence which will only be used for the next move. The optimal patrol sequence in this case is{4,5,2,3,6,9,8}. This is different from the previous patrol sequence due to the Kalman filter correction procedure. Both patrol sequences will check the same nodes, but in different orders, and thus will generate different expected rewards for the first responder.The following two matrices contain patrol sequences for the first responder, starting from every initial node, either without or with actual measurements. The first matrix gives the patrol sequences when Z is not available, and the second matrix are patrol sequences when Z is available. Each row represents one patrol sequence.(5.2)145236921458963214589458963258963216985412741258989632549854123145236921456983214589452369858963216985214741258989632549854123.Most of the patrol sequences are similar under both cases, except starting from initial nodes2,4, and 6. The patrol sequences will be updated due to the information obtained through measurements. Updated patrol sequences usually generate better rewards for the first responder.When the responder and the adversary decide on their initial positions, the responder does not have the information about future measurements provided in Z. So Z is not needed in this procedure. For each initial position of the first responder, the optimal patrol sequence is already given in the first matrix of Eq. (5.2), based only on the forecast occupancy levels. The people flow model forecasts the future occupancy levels to provide expected risk measures throughout the finite time period T.Given the position of both the first responder and the adversary, and the patrol sequence, the expected rewards can be easily calculated by using Eq. (4.8). So,Rf, the payoff matrix for the first responder in the initial position game can be built.Given the simplest case, in which the initial position game is a zero-sum game, the following Nash Equilibrium strategies for the first responder and the adversary are obtained:X∗=(0.1464,0.0000,0.0000,0.4776,0.0000,0.0000,0.3556,0.0000,0.0204)TY∗=(0.0014,0.0000,0.4691,0.0000,0.0000,0.0038,0.5256,0.0000,0.0000)T.One can see that the first responder can choose from nodes1,4,7, and 9 as its initial position, and the adversary can choose from nodes1,3,6, and 7 as its attacking position. The game value for this initial position game is −5.1602. This means that the expected payoff to the first responder is negative, so the first responder needs to improve the probability of detection by either using better sensor technology, by deploying more first responders to perform the search, or by better training of the first response teams.Note that this game value is calculated based on the forecast occupancy levels without any correction. To calculate the actual expected payoff to the first responder under strategy(X∗,Y∗), the actual occupancy levels O in Eq. (5.1) are used. Both the updated and non-updated patrol sequences are given in Eq. (5.1). The actual expected reward obtained under the updated patrol sequence is −3.2757, while it is −5.6281 when updates are not available. Clearly, the updated patrol sequence is better. However, due to the random nature of the patrol sequence obtained via the POMDP this is not always the case; there exist some cases in which updated sequences generate less payoff than non-updated sequences. Generally speaking, when people flow experiences unusual shocks, such as sudden influx or outflux of people, or the measurements are more reliable, the updated patrol sequence will work much better.On the other hand, if the first responder improves the detection probability to 1 for all nodes, the actual expected rewards for non-updated and updated patrol sequences become3.8816and3.9608, respectively. Updated patrol sequences generate slightly better reward for the first responder in this case too. They both are much better than the original case with lower detection probabilities. Of course, in this case, non-updated and updated patrol sequences, and the mixed strategy for the initial position(X∗,Y∗), will all be different from the original case.In this paper, we have considered static and dynamic game models for infrastructure security problem. In these models, costs are based upon the occupancy level at each location in the infrastructure, and thus may be dynamically changing. Our models can be used in obtaining real time strategies for infrastructure security personnel.For the static game, we have proved that a unique equilibrium exists under certain conditions. The equilibrium and the value of the game are obtained in closed form. In addition, the equilibrium is shown to be of threshold type; both rivals distribute their resources to nodes with value higher than a threshold. We also discuss a Bayesian game. While for the dynamic game in which the first responder is mobile we have presented a solution methodology that is based on the POMDP model. Throughout, examples have been provided.The dynamic game considered in the manuscript can be extended to include multiple first responder teams. Next, we plan to study the two-controller resource allocation problem in which a number of sites (targets) are attacked by the adversary and are defended by the first responders. Depending on the players’ objectives, such a problem can be modeled as a zero-sum stochastic game (Baykal-Gürsoy, 1989, 1991; Avsar & Baykal-Gürsoy, 1999, 2006; Shapley, 1953), or a Nash game (Avsar & Baykal-Gürsoy, 2002). Our planned approach is to consider discrete and known environments, and incorporate risk measures into the objective function.

@&#CONCLUSIONS@&#
