@&#MAIN-TITLE@&#
Category-based task specific grasping

@&#HIGHLIGHTS@&#
A probabilistic approach for task-specific category based grasping is proposed.The grasp stability is maximized probabilistically over shape uncertainty.The approach integrates information over all training objects for better generalization.The technique can cope with a sparser training set than most data-driven methods.Only incomplete point clouds obtained from a single RGB-D image are needed.

@&#KEYPHRASES@&#
Category-based grasping,Task-specific grasping,Probabilistic grasping,Shape uncertainty,

@&#ABSTRACT@&#
The problem of finding stable grasps has been widely studied in robotics. However, in many applications the resulting grasps should not only be stable but also applicable for a particular task. Task-specific grasps are closely linked to object categories so that objects in a same category can be often used to perform the same task. This paper presents a probabilistic approach for task-specific stable grasping of objects with shape variations inside the category. An optimal grasp is found as a grasp that is maximally likely to be task compatible and stable taking into account shape uncertainty in a probabilistic context. The method requires only partial models of new objects for grasp generation and only few models and example grasps are used during the training stage. The experiments show that the approach can use multiple models to generalize to new objects in that it outperforms grasping based on the closest model. The method is shown to generate stable grasps for new objects belonging to the same class as well as for similar in shape objects of different categories.

@&#INTRODUCTION@&#
Interaction with objects is an important ability for a robot acting in a real environment. Most manipulation tasks require grasping of objects. Grasping has been traditionally studied in the context of attaining a form or force closure but not all stable grasps are viable for all tasks. For example, tools usually need to be grasped by their handles for them to be usable. Task-specific grasps are then primarily meaningful in cases where the object belongs to a category compatible with the required task. Thus, for more complex tasks task-specific grasping relates then either to grasping of a known object or grasping a familiar object, i.e., an object of a known category.Category-based grasping is most often performed by data-driven approaches. In case when a comprehensive database of objects and appropriate grasp configurations are available, the problem is relatively easy to solve because there is always a model in the database that is a good fit to the particular object to be grasped. In practice this is not realistic because constructing such databases is computationally expensive and time consuming. Moreover, determining the correct object in the database is not trivial because fitting of incomplete and noisy measurements obtained with e.g. an RGB-D sensor is difficult.This paper proposes a task-specific grasping method that (a) is able to generalize from a sparse set of examples of objects and related grasps to novel objects; and (b) can cope with incomplete measurements included in a single RGB-D image. The main contributions of the work are: (i) a probabilistic approach for task-specific stable grasping of objects with shape variations inside the category is proposed; (ii) the idea of maximizing the grasp stability is taken in the novel context to cover the shape uncertainty; (iii) the approach accounts for all training objects in the category during the optimization process, which allows to better generalize for new objects and handle larger shape variations; (iv) the techniques can cope with a sparse training set unlike most data-driven methods; (v) the method uses incomplete point clouds obtained from a single RGB-D image.With task-based grasps, e.g., grasping an object to pour liquid from it, the category is usually known as the actions only make sense when using an object from a compatible category. To concentrate on grasping, we assume that the category is known from task planning and the closely connected problem of category recognition is left outside the scope of the paper. Similarly, the detection of affordances, i.e. if an object affords a particular action, is not considered.The paper is structured as follows: after discussing related work in the next section, we will present our general category-based task specific grasping framework as well as details of models in Section  3. In Section  4, we describe our experimental setting in simulation environment and discuss the results for the mugs and bottles categories and several tasks. In Section  5 we show how our technique allows to generalize for similar objects in other categories. Next, we present the implementation of our approach on a real robot and analyze the experimental results in Section  6. Finally, we discuss the benefits and improvements of the method in Section  7 and conclude in Section  8.

@&#CONCLUSIONS@&#
