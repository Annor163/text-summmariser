@&#MAIN-TITLE@&#
Representation learning for mammography mass lesion classification with convolutional neural networks

@&#HIGHLIGHTS@&#
Innovative representation learning framework for breast cancer lesion classification.A hybrid CNN method to learn image-based features in a supervised way.New breast cancer benchmarking dataset to support computer-aided diagnosis methods.

@&#KEYPHRASES@&#
Breast cancer,Feature learning,Convolutional neural networks,Computer-aided diagnosis,Mammography,

@&#ABSTRACT@&#
Background and objectiveThe automatic classification of breast imaging lesions is currently an unsolved problem. This paper describes an innovative representation learning framework for breast cancer diagnosis in mammography that integrates deep learning techniques to automatically learn discriminative features avoiding the design of specific hand-crafted image-based feature detectors.MethodsA new biopsy proven benchmarking dataset was built from 344 breast cancer patients’ cases containing a total of 736 film mammography (mediolateral oblique and craniocaudal) views, representative of manually segmented lesions associated with masses: 426 benign lesions and 310 malignant lesions. The developed method comprises two main stages: (i) preprocessing to enhance image details and (ii) supervised training for learning both the features and the breast imaging lesions classifier. In contrast to previous works, we adopt a hybrid approach where convolutional neural networks are used to learn the representation in a supervised way instead of designing particular descriptors to explain the content of mammography images.ResultsExperimental results using the developed benchmarking breast cancer dataset demonstrated that our method exhibits significant improved performance when compared to state-of-the-art image descriptors, such as histogram of oriented gradients (HOG) and histogram of the gradient divergence (HGD), increasing the performance from 0.787 to 0.822 in terms of the area under the ROC curve (AUC). Interestingly, this model also outperforms a set of hand-crafted features that take advantage of additional information from segmentation by the radiologist. Finally, the combination of both representations, learned and hand-crafted, resulted in the best descriptor for mass lesion classification, obtaining 0.826 in the AUC score.ConclusionsA novel deep learning based framework to automatically address classification of breast mass lesions in mammography was developed.

@&#INTRODUCTION@&#
Breast cancer is the most common cancer in women worldwide, with nearly 1.7 million new cases diagnosed in 2012 (second most common cancer overall); this represents about 12% of all new cancer cases and 25% of all cancers in women.11World Cancer Research Fund International http://www.wcrf.org/int/cancer-facts-figures/data-specific-cancers/breast-cancer-statistics, Accessed May 20, 2015Breast cancer has a known asymptomatic phase that can be detected with mammography, and therefore, mammography is the primary imaging modality for screening. Double-reading (two radiologists independently read the same mammograms) has been advocated to reduce the proportion of missed cancers and it is currently included in most screening programs [1]. However, double-reading incurs in additional workload and costs. Alternatively, computer-aided diagnosis (CADx) systems can assist a single radiologist when reading mammograms providing support for their decisions. These systems can be used as second opinion criteria by radiologists, playing a key role in the early detection of breast cancer and helping to reduce the death rate among women with breast cancer in a cost-effective manner [2].A successful approach to build CADx systems is to use machine learning classifiers (MLC). MLC are learned from a set of labeled data samples capturing complex relationships in the data [3–5]. In order to train a MLC for breast cancer diagnosis, a set of features describing the image is required. Ideally, features should have high discriminant power that allows inferring whether a given image is from a malignant finding or not. This is, however, a challenging topic that has gathered the focus of research in several sciences, from medicine to computer vision. Thus, several types of features may be used to infer the diagnosis. Many CADx systems use hand-crafted features based on prior knowledge and expert guidance. In particular, strategies based on feature selection [6] and hand-crafted features that characterize geometry and textures [7] has been proposed for mass classifications. As an alternative, the use of machine learning strategies to learn good features directly from the data is a new paradigm that has shown successful results in different computer vision tasks. One such paradigm is deep learning.Deep learning methods have been widely applied in recent years to address several computer perception tasks [8]. Their main advantage lies in avoiding the design of specific feature detectors. In turn, deep learning models look for a set of transformations directly from the data. This approach has had remarkable results, particularly in computer vision problems such as natural scene classification and object detection [9]. Deep learning models have also been adapted to different medical tasks such as tissue classification in histology and histopathology images [10,11], Alzheimer disease diagnosis [12–15], and knee cartilage segmentation [16] among others.However, only few works have explored deep learning methods to address the automatic classification of identified lesions in mammography images [17]. In [18] stacked deep auto-encoders were used to estimate breast density score using multiscale features. Lately, this has been extended by including breast tissue segmentation and scoring of mammographic texture [19] with a convolutional neural network (CNN) model. CNN model is the most successful deep learning strategy applied to image understanding [9]. In [20,21] CNNs are used as representation strategy to characterize microcalcifications. Finally, the most recent work developed in this area was done in [22] which uses Adaptive Deconvolutional Networks to learn the representation in order to classify malign/benign breast lesions. Such strategy was evaluated on 245 lesions in a bootstrap fashion, reporting the area under the ROC curve (AUC) AUC=0.71. In this work, we also use convolutional architectures, however the features are learned in a supervised way during CNN training, taking advantage of expert knowledge represented by previously identified lesions in breast imaging, manually segmented by expert radiologists in both mammographic views (mediolateral oblique and craniocaudal).The remainder of the paper is organized as follows: Section 2 describes the proposed approach to perform classification of identified lesions in mammography images. Section 3 details the experimental setup used to evaluate the proposed approach. Finally, Sections 4 and 5 show results and present the main conclusions of this work.

@&#CONCLUSIONS@&#
This paper presented a framework to address classification of mass lesions in mammography film images. Instead of designing particular descriptors to explain the content of mammography images, the proposed approach learns them directly from data in a supervised way. CNNs were used as the representation learning strategy. The proposed neural network architecture takes the raw pixels of the image as input, to learn in a hierarchical way a set of nonlinear transformations to represent the visual content of an image. The model is composed of a set of local filters with a rectified linear unit activation function, maxpooling layers, a fully-connected layer with maxout activation function and a softmax layer. Our approach outperformed the state-of-the-art image features, HOG and HGD descriptors [3], increasing the performance from 0.787 to 0.822 in terms of AUC. Interestingly, this model also outperforms a set of hand-crafted features that take advantage of additional information from segmentation by the radiologist. Finally, the combination of both representations, learned and hand-crafted, resulted in the best descriptor for mass lesion classification, obtaining 0.826 in the AUC score.Our future work includes larger architectures as well as the inclusion of other image modalities to enhance the representation. It also would be worth to evaluate the proposed strategy on BCDR-DM images since this suppose a new challenge due to the high resolution images.