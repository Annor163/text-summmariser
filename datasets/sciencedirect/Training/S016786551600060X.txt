@&#MAIN-TITLE@&#
Vector Taylor series based model adaptation using noisy speech trained hidden Markov models

@&#HIGHLIGHTS@&#
Novel relation between training and test noisy speech in the cepstrum domain is derived.Noisy speech trained HMM is adapted to the test speech using the noise corruption model.Better performance is observed compared with the state-of-the-art model adaptation methods.Easy to implement by adapting directly the conventional ML trained HMM.

@&#KEYPHRASES@&#
Noisy speech recognition,Vector taylor series,Model parameter adaptation,

@&#ABSTRACT@&#
Conventionally, in vector Taylor series (VTS) based compensation for noise-robust speech recognition, hidden Markov models (HMMs) are usually trained with clean speech. However, it is known that better performance is generally obtained by training the HMM with noisy speech rather than clean speech. From this viewpoint, we propose a novel VTS-based HMM adaptation method for the noisy speech trained HMM. We derive a mathematical relation between the training and test noisy speech in the cepstrum-domain using VTS and the mean and covariance of the noisy speech trained HMM are adapted to the test noisy speech in an iterative expectation-maximization (EM) algorithm. In the experimental results on the Aurora 2 database, we could obtain about 10–25% relative improvements in word error rates (WERs) over multi-condition training (MTR) method depending on speech front-ends and the HMM complexity.

@&#INTRODUCTION@&#
Speech recognition in noisy environments still remains a difficult problem despite many technical advances that have been made in this field. The techniques which try to mitigate the mismatch between test noisy speech and clean speech HMM can be generally categorized as noise-robust speech feature extraction, speech enhancement, and feature compensation and model parameter adaptation [1–6].Among these methods, we focus on the HMM parameter adaptation methods because they are very powerful in improving noisy speech recognition accuracy compared with other approaches and many new research efforts are still actively going on in these areas. Maximum likelihood linear regression (MLLR) is one of the earliest and most popular model adaptation methods [6]. A set of linear transformations is used to adapt the means and covariance matrices of the HMM. Some variants of MLLR have been used to cope with the large amount of adaptation data required to estimate the transformation matrices [7]. Originally, developed for speaker adaptation, MLLR can be also effective for noise robust speech recognition. However, since it does not take into account actual noise corruption process, its performance is generally lower than the model adaptation methods such as parallel model combination (PMC) and VTS adaptation [3,4] that consider explicitly the relationship between clean and noisy speech signal.Besides their superior performance, PMC and VTS require quite less adaptation data compared with MLLR. Especially, VTS adaptation is performed at runtime just using the test noisy speech and its performance is known to be better than PMC since the nonlinear approximation based on a first-order Taylor series expansion is more accurate than the lognormal approximation used in PMC. Joint uncertainty decoding (JUD) adapts HMM parameters by explicitly modeling the joint probability density function (PDF) of noisy and clean speech signal [8]. Compared with VTS and PMC, JUD requires less computation time by considering the joint PDF for a small set of regression classes rather than for each mixture component of the HMM at a small decrease in performance. The joint PDF in JUD can be obtained either by using stereo data consisting of noisy and clean speech signal or by applying the conventional model adaptation methods like PMC/VTS.Although the aforementioned model adaptation methods have shown very successful results in noisy speech recognition, they use HMMs trained with clean speech as the baseline, which have some limitation in improving noisy speech recognition accuracy due to the inevitable mismatch between the observed test noisy speech and the adapted HMM parameters. This comes from the inaccuracies in the assumed noise corruption model and the mathematical approximations such as the first-order Taylor series expansion in the VTS adaptation.As a different point of view from the model adaptation approaches for noise robust speech recognition, training HMMs directly with noisy speech has been proposed to show very promising results in noisy speech recognition [9–11]. For example, in the multi-condition training (MTR) method, noisy speech signals under various noise conditions are collected to train one set of HMMs [9]. Also, multiple HMM sets corresponding to various noise types and signal-to-noise ratio (SNR) values are constructed during training in a multiple-model based speech recognition (MMSR) framework [10]. The resulting noisy speech trained HMM significantly reduces the mismatch with the test noisy speech and performs much better than the clean speech HMM.Some research efforts have been proposed to incorporate the conventional feature and model parameter compensation methods to the noisy speech trained HMM. This is motivated by the idea that the noisy speech trained HMM is more advantageous to performance improvement than the clean speech HMM. One of the earliest approaches to adapt the parameters of the noisy speech trained HMM is Jacobian adaptation (JA) [12]. Since it is based on a simple linear approximation of the nonlinear cepstral distortion, it seems to have difficulty in accurately reflecting the changing noise conditions into the HMM parameters. A noise-type dependent minimum mean square error (MMSE) estimation of the feature vectors has been applied successfully in the MMSR framework [13]. In our previous study, the nonlinear relation between the test and training noisy speech in the log-spectrum domain was used to re-estimate the test noisy speech feature vector to make it match better with the noisy speech trained HMM [14]. In recent studies, VTS and JUD based approaches have been popularly used in the feature and model compensation for the noisy speech trained HMM [15–17]. For example, in [15], an MTR trained HMM is transformed into a pseudo-clean HMM during training by using VTS. Then, the pseudo-clean HMM is used for recognition instead of the clean speech HMM to reduce environmental variations due to the noise leading to successful recognition results.In this letter, we propose a new approach to adapt the parameters of the noisy speech trained HMM to the test noisy speech at recognition. It is based on a novel relation between the training and test noisy speech in the cepstrum domain. Compared with the recent model adaptation methods which adapt the pseudo clean speech HMM, the proposed algorithm is relatively simple in its implementation since it does not require estimate the parameters of the pseudo clean speech HMM [15]. In addition, the proposed method improves performance by adapting directly the MTR trained HMM, which makes it possible to take advantage of the inherent noise robustness of the noisy speech trained HMM.In this section, we derive an adaptation formula for the mean vectors and covariance matrices of the noisy speech trained HMM using VTS approximation. Contrary to the conventional VTS algorithms which require clean speech HMM, the noisy speech HMM trained by MTR method is used in the proposed adaptation algorithm. A novel relation between the training and test noisy speech is first derived in the cepstrum-domain. The non-linear relation is approximated using VTS to obtain the mean vectors and covariance matrices corresponding to the test noisy speech assuming that the additive and channel noises are known. An iterative EM algorithm is employed to update both the noise and HMM parameters.It is generally assumed that the clean speech x and the test noisy speech y contaminated with additive and channel noise n, h is related in the cepstrum domain as follows:(1)y=x+h+Clog(i+exp(C−1(n−x−h))where i is a unity vector and C andC−1represent the discrete cosine transformation (DCT) and its inverse, respectively.Assuming there is no channel noise in the training noisy speechyTr, it can be expressed as follows:(2)yTr=x+Clog(i+exp(C−1(nTr−x))where nTrrepresents the additive noise in the training speech and is determined during training.We can derive the following equation by taking inverse DCT and exponents on both sides of (2)(3)exp(C−1x)=exp(C−1yTr)−exp(C−1nTr)Substituting (3) into (1) and (2), the relation between the test noisy speech y and training noisy speech yTrcan be expressed as follows:(4)y=yTr+h+g(yTr,n,h,nTr)(5)g(yTr,n,h,nTr)≡Clog(i+exp(C−1(n−h−yTr))−exp(C−1(nTr−yTr)))Eq. (4) is expanded using a first-order VTS [18] around the initial value{μyTr,0,μn,0,h0}of {yTr, n, h} as follows:(6)y≈μyTr,0+h0+g(μyTr,0,μn,0,h0,nTr)+GyTr(yTr−μyTr,0)+Gn(n−μn,0)+Gh(h−h0)whereGyTr, Ghand Gnare the Jacobians of (4) with respect to yTr, h and n, respectively, which will be explained in more detail in the following.LetμyTr,smandΣyTr,smdenote the mean vector and diagonal covariance matrix of the mth Gaussian component in the sth state of the MTR trained noisy speech HMM. The additive noise n of the test noisy speech is assumed to be Gaussian with meanμnand covarianceΣn. Also, the alignment between speech frame and the corresponding Gaussian component of the HMM does not alter due to the change in noise conditions.By taking the expected value of the terms in (6), the mean vectorμy, smand covariance matrixΣy, smof the adapted HMM can be estimated as follows:(7)μy,sm=μyTr,sm+h0+g(μyTr,sm,μn,0,h0,μnTr)+Gn,sm(μn−μn,0)+Gh,sm(h−h0)(8)Σy,sm≈GyTr,smΣyTr,smGyTr,smT+Gn,smΣnGn,smT(9)[GyTr,sm]il=∑kCikCkl−11+Bk−Ak(10)[Gh,sm]il=∑kCikCkl−1(1−Ak)1+Bk−Ak(11)[Gn,sm]il=∑kCikCkl−1Bk1+Bk−Ak(12)Ak=exp(∑jCkj−1(μnTr,j−μyTr,sm,j))(13)Bk=exp(∑jCkj−1(μn,0,j−h0,j−μyTr,sm,j))(14)Cik=[C]ik,Cik−1=[C−1]ikAs mentioned above,GyTr,sm, Gh, smand Gn, smare the Jacobians of (4) with respect to yTr, h and n, respectively, evaluated at the point{μyTr,sm,μn,0,h0}. In (7),μnTris the mean of the training noise vector nTr, which is obtained by averaging the first and last 15 frames from all the training utterances. The variance of nTris not considered in this paper for the simplicity of implementation.μn, 0, are the initial values ofμnand h in the test noisy speech, respectively.μn, 0 is initialized using the non-speech samples of the test noisy speech and the channel noise h is initialized to zero. The channel noise h is treated simply as a parameter, not a random variable. The subscript j in (12) and (13) is used to represent the Jth component of the vectors. [⋅]ilrepresents an element in the ith row and lth column of a matrix.The means and covariances corresponding to the delta and acceleration feature vectors can be similarly adapted using the continuous-time approximation [18,19] as follows:(15)μΔ,y,sm=GyTr,smμΔ,yTr,sm,ΣΔ,y,sm=GyTr,smΣΔ,yTr,smGyTr,smT+Gn,smΣΔnGn,smTμΔΔ,y,sm=GyTr,smμΔΔ,yTr,sm,ΣΔΔ,y,sm=GyTr,smΣΔΔ,yTr,smGyTr,smT+Gn,smΣΔΔnGn,smTAn iterative EM algorithm is used to re-estimate the noise parameters,μnand h in (7). The covariance matrixΣnof the additive noise is not updated in this letter.Given a sequence of the test noisy speech feature vectorsY={y1,y2,…,yT}, the noise parameterφ={μn,h}is re-estimated by maximizing an auxiliary functionQ(φ|φ¯)defined as follows:(16)Q(φ|φ¯)=∑t=1T∑s∑mγtsmlogp(yt|st=s,mt=m,φ,Λy)where φ andφ¯are new and old noise parameters. s and m denote, respectively, states and mixtures in a state of the HMM, stand mtindicate the state and mixture component, respectively, at time t. γtsmis the posterior probabilityp(st=s,mt=m|Y,φ¯,Λ¯y)whereΛ¯yis the old HMM parameters.p(yt|st=s,mt=m,φ,Λy)is the Gaussian probability density function N(yt;μy, sm,Σy, sm) with mean vectors and covariance matrices from (7), (8) and (15).To maximize the auxiliary function, we take the derivative of (16) with respect toμn, h and set the derivative equal to zero to obtain the following re-estimation formula.(17)μn=μn,0+{∑t,s,mγtsmGn,smTΣy,sm−1Gn,sm}−1·×{∑t,s,mγtsmGn,smTΣy,sm−1(yt−μyTr,sm−h0−g0,sm)}(18)h=h0+{∑t,s,mγtsmGh,smTΣy,sm−1Gh,sm}−1·×{∑t,s,mγtsmGh,smTΣy,sm−1(yt−μyTr,sm−h0−g0,sm)}(19)g0,sm≡g(μyTr,sm,μn,0,h0,μnTr)In summary, the iterative EM algorithm for the HMM parameter adaptation is performed by first updating the HMM parameters using initialized noise parametersμn, 0, h0 as in (7), (8), (15). Then, the noise parameters are re-estimated as in (17), (18) using the updated HMM parameters, which are used to update the HMM parameters again. The re-estimation process can be repeated until the log-likelihood of the test noisy speech converges, but single iteration was performed in our experiments to reduce the computation time.

@&#CONCLUSIONS@&#
In this letter, we proposed an HMM parameter adaptation method for noise robust speech recognition. Contrary to conventional adaptation methods where the baseline recognizer is trained with clean speech, the proposed method adapts the parameters of the MTR trained noisy speech HMM. The method is based on a novel relation between the test and training noisy speech in the cepstrum domain. By using VTS approximation, the mean and covariance of the MTR trained HMMs are adapted to the test noisy speech in an iterative EM algorithm, where additive and channel noise parameters are also re-estimated. We have shown that the proposed method achieves about 10% and 25% relative improvement over the MTR trained HMM when using CBE script for FE and AFE front-ends, respectively. It also performed better than NAT algorithm which is one of the recent HMM adaptation methods based on noisy speech HMM. The superior performance of the proposed method may be attributed to the direct adaptation of the noisy speech HMM. Also, the relative simple implementation compared with other noise adaptive training methods is another merit of the proposed method.