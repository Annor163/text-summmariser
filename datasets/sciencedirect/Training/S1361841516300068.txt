@&#MAIN-TITLE@&#
Automatic optimal filament segmentation with sub-pixel accuracy using generalized linear models and B-spline level-sets

@&#HIGHLIGHTS@&#
Filament segmentation is a recurrent task in light-microscopy image analysis.We combine the advantages of level-set and curve-fitting methods in a new model.We present an optimal solver algorithm for the model, implemented in Fiji/ImageJ.We derive a lower bound of the error in general filament-segmentation problems.We show that our method asymptotically reaches the bound.

@&#KEYPHRASES@&#
Filament segmentation,Level set,B-spline,Axoneme,Light microscopy,Microtubule,

@&#ABSTRACT@&#
Biological filaments, such as actin filaments, microtubules, and cilia, are often imaged using different light-microscopy techniques. Reconstructing the filament curve from the acquired images constitutes the filament segmentation problem. Since filaments have lower dimensionality than the image itself, there is an inherent trade-off between tracing the filament with sub-pixel accuracy and avoiding noise artifacts. Here, we present a globally optimal filament segmentation method based on B-spline vector level-sets and a generalized linear model for the pixel intensity statistics. We show that the resulting optimization problem is convex and can hence be solved with global optimality. We introduce a simple and efficient algorithm to compute such optimal filament segmentations, and provide an open-source implementation as an ImageJ/Fiji plugin. We further derive an information-theoretic lower bound on the filament segmentation error, quantifying how well an algorithm could possibly do given the information in the image. We show that our algorithm asymptotically reaches this bound in the spline coefficients. We validate our method in comprehensive benchmarks, compare with other methods, and show applications from fluorescence, phase-contrast, and dark-field microscopy.

@&#INTRODUCTION@&#
Filamentous structures are ubiquitous in biology and are routinely imaged using different modalities. Examples range from cytoskeletal filaments, like microtubules (Ruhnow et al., 2011) and actin filaments (Gittes et al., 1993), to polymers (Graham et al., 2014), axonemes (Mukundan et al., 2014), sperm flagella (Rikmenspoel and Isles, 1985), nematodes (Geng et al., 2004; Ramot et al., 2008), and rodent whiskers (Clack et al., 2012). From the acquired images, one often aims to extract quantitative information about the filaments, such as their length (Ruhnow et al., 2011), curvature (Mukundan et al., 2014), bending (Gittes et al., 1993; Graham et al., 2014), or motion dynamics (Rikmenspoel and Isles, 1985). Doing so manually is prohibitive for large data volumes. Moreover, manual analysis introduces significant intra- and inter-rater variability and bias. Image segmentation techniques are available to automate the process. However, the problem of filament segmentation is not trivial because the thickness of the imaged filaments is often below the resolution limit of the microscope, and the signal-to-noise ratio (SNR) of the images is routinely low. While the former calls for filament localization with sub-pixel precision, the latter amplifies localization errors.Addressing the problem of localization precision and error control in filament segmentation has been explored in various methods over the past decades. These methods can generally be classified into region-segmentation methods (e.g., Paul et al., 2013; Fuller et al., 2005), curve-fitting methods (e.g., Smith et al., 2010; Clack et al., 2012; Valdman et al., 2012; Xu et al., 2014), and combinations of the two (e.g., Ruhnow et al., 2011). Region-segmentation methods detect a connected region of pixels within which the filament lies, represented as either a pixel mask (Fuller et al., 2005; Goldstein et al., 2010; Paul et al., 2013), particles (Florin et al., 2005; Cardinale et al., 2012), or a closed active contour (Kass et al., 1988; Ronfard, 1994; Yezzi et al., 1997; Butenuth and Heipke, 2012; Zhang et al., 2012a; 2012b; Bernard et al., 2009). Usually, a closed active contour is implicitly represented as the zero-level set of a higher-dimensional function, which is called level-sets methods (Sethian, 1999).While region-segmentation methods narrow down the localization of the filament, they do not segment a filament in the sense of a curve. Curve-fitting methods account for this by fitting a smooth open curve to the image in order to represent the filament (Wong et al., 1998; Sarry and Boire, 2001; Smith et al., 2010; Clack et al., 2012; Valdman et al., 2012; Xu et al., 2014), because characterizing a filament as a region of pixels is especially inappropriate if sub-pixel accuracy or smoothness are required. This is typically the case when quantifying filament polymerization kinetics by computing time derivatives of the filament length.In both paradigms, the segmentation result can either be derived by solving an optimization problem (Paul et al., 2013; Fuller et al., 2005; Florin et al., 2005; Cardinale et al., 2009; Smith et al., 2010), or using filters (Saban et al., 2006; Danuser et al., 2000; Clack et al., 2012; Rigort et al., 2012). Formulating the task as an optimization problem, e.g. maximizing the Bayesian posterior of the segmentation to explain the image, provides principled ways of including prior knowledge about the imaged filaments and the imaging modality in the form of the object and forward models.Solving the resulting optimization problem, however, may be difficult. For discrete problems over pixel masks or filament pieces, dynamic programming (Clack et al., 2012) or graph-cuts (Kolmogorov and Zabin, 2004; Boykov and Kolmogorov, 2004; Boykov and Funka-Lea, 2006) can find the globally optimal solution. When using continuous filament representations, such as splines, active contours, or level-sets, however, optimization is mostly done locally, e.g., using gradient-descent (Zhang et al., 2012a; 2012b) or shape-gradient flow (Tsai et al., 2003; Law and Chung, 2009; Paul et al., 2013). For level-sets methods, variational approaches are popular, relaxing the requirement of previously having to know the number of the filaments to be segmented (Goldstein et al., 2010; Paul et al., 2013; Bernard et al., 2009). The main limitation of such local approaches is that image noise can cause the result to converge in a sub-optimal local minimum (Smith et al., 2010; Xu et al., 2014). In addition, curve-fitting methods usually require prior knowledge of the number of filaments present in the image (Wong et al., 1998; Sarry and Boire, 2001; Valdman et al., 2012).Methods from both paradigms usually assume Gaussian image noise and the use of a certain type of microscopy, e.g., fluorescence microscopy. These assumptions may be inappropriate in some cases, for example when using phase-contrast microscopy, or in low-light conditions where the noise is Poissonian.Despite these shortcomings, both paradigms also have unique advantages. Specifically, region-segmentation methods can localize multiple filaments automatically and in a computationally efficient way. When using a level-set segmentation method, the number of filaments present in an image does not need to be previously known or imposed. While curve-fitting methods require prior knowledge of the number of filaments to be fitted, they can properly characterize the geometry of filaments as open curves.These observations motivate us to combine the two paradigms in a novel way. We propose a method that represents filaments as open curves, hence providing sub-pixel resolution in a geometric representation of the correct dimensionality, just as existing curve-fitting methods do. At the same time, however, rather than directly using a 1D curve representation, we use a level-set representation of these curves. This means that, unlike in curve-fitting methods, our method does not require the number of filaments to be previously known. It automatically handles multi-filament cases, as long as the filaments do not cross.We show how to formulate the resulting optimization problem in a globally convex way (Paul et al., 2013) by measuring distances between segmentations and the image using the Bregman divergence (Banerjee et al., 2005; Bregman, 1967). We further derive an analytical expression for the gradient of the energy functional, enabling us to efficiently solve the convex problem by an easy-to-implement gradient-descent optimizer. The segmentation produced is the best possible one for the given model and image data. We also exploit the model-based framework to account for key physical properties of the microscope (i.e., image-formation model), which are rarely considered in other methods. This renders our method fully automatic in the sense that it does not require prior manual segmentation or image pre-processing (e.g., inversion or smoothing).Technically, this is made possible by representing the filaments as a vector level-set with level functions represented as B-spline surfaces (Bernard et al., 2009). The evolution of those surfaces is driven toward the optimal segmentation by a convex Bregman energy (Paul et al., 2013), which derives from a generalized linear model (GLM) (McCullagh, 1984; Nelder and Wedderburn, 1972) for the noise in the image (see (Paul et al., 2013) for details). This allows for any pixel-wise noise distribution from the exponential family, which includes the most common cases in microscopy, such as Gaussian, Poisson, and Bernoulli noise (Paul et al., 2013). This relaxes the assumption of Gaussian pixel noise, rendering the model more flexible.In order to confirm the optimality of our solution, we derive an information-theoretic lower bound for the segmentation error in filament segmentation. This lower bound defines how well any unbiased algorithm can possibly perform given the information in the image. We find that the algorithm presented here asymptotically reaches the bound in the spline coefficients, showing that the bound is attainable.In summary, our method can (1) automatically detect and optimally segment a previously unknown number of filaments as smooth open curves with sub-pixel resolution, and (2) be adapted to different types of image data from different microscopy modalities. The method is easy to implement, since it amounts to standard gradient descent over a convex function.The paper is organized as follows: in Section 2, we present the optimization framework, mathematically formalizing the filament segmentation problem. The algorithm design and the theoretical lower bound for the segmentation accuracy are introduced in Sections 3 and 4, respectively. Results of comprehensive benchmarks and experiments are shown in Section 5, and we conclude this work in Section 6.Before providing the details of our method, we mathematically formulate the filament segmentation problem. The first thing we need is a mathematical representation of the filaments.We represent filaments as vector level-sets, because by using a single level function the level set is necessarily a closed curve. In order to represent open curves, we use a vector level-set with two components. The zero level set of the first component ϕ describes a closed curve that contains the filament (black circle in Fig. 1a). The part of that closed curve where the second component ψ is positive then is the actual open filament (black arc in Fig. 1b). The vector level function is represented as a B-spline surface. This geometric model can represent an arbitrary number of non-crossing and non-overlapping filaments. Filaments are overlapping as soon as they are too close to each other for the microscope optics to resolve them as two.Based on this filament representation, it is possible to predict the image that one expects to see when imaging those filaments with a particular microscope. This forward model hence simulates the generative process of image formation. The so-predicted model image is then compared with the actually observed image data. The difference between the two (measured in a suitable metric) then drives the evolution of the filament representation so as to minimize this difference. A regularizer is used to avoid over-fitting. The data-fitting term and the regularizer together form the energy functional that is to be minimized in order to find the best possible segmentation. The variables of the optimization problem are the coefficients of the B-spline vector level-set surfaces. They evolve such that the represented filaments lead to an expected image that is as close as possible to the actually observed image.The forward model assumes that each filament has a uniform intensity along its length, and that the background is uniformly homogeneous. If these assumptions are not met, the algorithm will still work, but the result is no longer guaranteed to be globally optimal, as we show below. The (unknown) intensities of the filament and background are thus represented by a 2-vectorβ=[β1,β2]T. Let Hf(x) be an indicator function such thatHf(x)=1means that the pointxlies on a filament,Hf(x)=0is background. Hence, the intensity distribution in the model sample before imaging is(1)μ(x,β)=β1Hf(x)+β2(1−Hf(x)).The indicator function Hf(x) is represented by the vector level set. In order to represent non-intersecting filaments, we use two level functions ϕ(x) and ψ(x). Open-curve filaments are then represented by(2)Γ(x)={x:ϕ(x)=0∩ψ(x)>0,x∈ΩI},whereΩIis the image domain. The level setϕ(·)=0describes a closed contour, while the condition ψ(·) > 0 cuts the closed contour to an open curve since only a subset ofxonϕ(x)=0can yield ψ(x) > 0. The above indicator function Hf(x) is then given by(3)Hf(x)=δ(ϕ(x))H(ψ(x)),where δ(·) is a Dirac and H(·) a Heaviside distribution. This is equivalent to condition (2) because ifϕ(·)=0and ψ(·) > 0,Hf(·)=1,meaning thatxbelongs to a filament. OtherwiseHf(·)=0,meaning the point belongs to the background.As an illustrating example explaining the vector level-set representation, in Fig. 1a, a closed contour (shown as a black circle) is represented by the first level setϕ(x)=0. This closed contourϕ(x)=0is cut so as to satisfy ψ(x) > 0, which directly interprets condition (2). In Fig. 1b, the resulting indicator function Hf(x) in Eq. (3) is shown in the 2D image domain. The image ofHf(x)=1(red curve) presents an open curve, whileHf(x)=0is the dark background. This forms a solution space for filament segmentation, since different indicator functions Hf(·), represented by the two level functions, correspond to different segmentation results.The resulting expected model image is then formed by running the hypothetical scenery μ through the image-formation forward model. This predicts what the image would look like in expectation when seen through that particular microscope.The two level functions ϕ(x) and ψ(x) can be represented in a number of ways. A common choice is to use signed-distance functions. This, however, requires re-initialization (or penalization) during contour evolution in order to ensure that the signed-distance property is not lost (Sethian, 1999). In our application, we do not require distance information in the filament domain. Following earlier works, we hence simplify the representation by using B-spline functions (Maeland, 1988; Farin, 1996; Bernard et al., 2009) for both level-set functions. Representing the level functions as B-spline surfaces moreover provides an analytical form (polynomial) of each segmented filament, which provides direct access to geometric features such as gradients, normals, and curvature (Bernard et al., 2009). Using ϕ(x) as an example (ψ(x) is analogous), the function is(4)ϕ(x)=∑k∈Z+2cϕ[k]bn(xh+1−k),whereZ+2is a 2D mesh grid of positive integers that has the same size as the image domainΩI,k is an integer 2-index, cϕ[k] is the spline coefficient set, andbn(xh+1−k)is an nth-order basis function with the size h controlling the spacing between two consecutive nodes.The dimensionality of the resulting optimization problem is given by the number of spline coefficients used to represent the level functions. This number is controlled by h. We illustrate B-spline surfaces of different sizes h in Fig. 2. Forh=0,the B-spline function has one coefficient (node) per image pixel. Forh=1,one pixel is left empty between any two consecutive nodes, thus quartering the number of coefficients in 2D. Thus, increasing h reduces the resolution of the spline, but also reduces the dimensionality of the resulting optimization problem.On the one hand, smaller h allow the segmented filaments to trace smaller undulations. On the other hand, smaller h increases the computational cost and renders the segmentation more sensitive to noise. We investigate the trade-off of the scaling size h in simulation results in Section 5.3, and provide good parameter choices.The energy functional is a criterion that evaluates the quality of a given segmentation with respect to the image data. If the model image shows the correct filaments, the energy should be minimal. Following the standard approach, we use an energy functional composed of two parts: a data-fitting term that measures the distance between the model image and the data image, and a regularization term that penalizes over-fitting.The data-fitting term measures how closely the image one expects to see under the current segmentation hypothesis matches the observed data image. This includes a simulation of the image-formation process in the given microscope, and a pixel noise model. We model image formation as a convolution with a kernel K, which is known from optics or calibration measurements. The expected model image hence is K*μ(x, β). This simulates how the imaging system maps the scene to an image. In fluorescence microscopy, K is the point-spread function (PSF). For phase-contrast microscopy, K is given by a non-linear imaging model that involves Bessel functions, as previously described (Yin et al., 2010).The second component is the noise process, providing a likelihood to compare the model image to the image data. Assume that the intensity value u(x) at locationxis a realization from a stochastic process with probability density function (p.d.f.) p(u(x) |θ) and unknown parametersθ. In our problem, the unknown parameters are the mean intensities β1 and β2 of the forep.f.f and background, respectively. The likelihood of a segmentation given in the image data is ℓ(μ(x, β) | u(x)). This likelihood increases as the model (i.e., segmentation) μ( ·, ·) converges to the correct solution.To estimate the unknown parameters β1 and β2, we use a linear predictor for the parameters of any p.d.f. from the exponential family (EF) of distributions. A non-linear link function correlates the linear predictor to the unknown parameters. This is the standard GLM framework in statistics.We give a brief example to illustrate the GLM idea. We are given a set of pixels sampled from a probability distribution with unknown mean. We can estimate the mean as the average of the samples. In this case, the linear predictor of the GLM is an averaging operation, and the link function is the identity function because we let the mean directly equal the average of the samples. In the general case, we can specify an arbitrary link function. If we for example let the log  of the parameters equal the sample average, we enforce positivity of estimated intensity values. Hence, a GLM generalizes the classical estimation of the mean by the average, allowing additional flexibility.In our problem, the linear predictor is the model μ(x, β). We further use the link functiong(E(u(x)))=K*μ(x,β),orE(u(x))=g−1(K*μ(x,β))whereg−1(·)is the inverse link function.11Ifg−1(·)is the identity function, i.e.,1(·), this reduces to the classical method of estimating the mean as the average of the samples.The likelihood of the model can then be written as(5)ℓ(μ(x,β)|u(x))=p(u(x)|g−1(K*μ(x,β))).Though it would be possible to directly maximize the likelihood in Eq. (5), likelihoods of some p.d.f.’s from the EF are complicated. For example, the p.d.f. of a Poisson distribution contains factorials and is a discrete function. More importantly, some p.d.f.s are not globally convex and, as a result, global optimality cannot be guaranteed. Hence, a better data-fitting term is needed.We address these problems by replacing the likelihood with the Bregman divergence (Bregman, 1967) induced by that specific p.d.f. from the EF. The Bregman divergence generalizes the familiar squared Euclidean distance to a class of distances that all share similar properties. The most important property for our purpose is that a Bregman divergence is globally convex. This guarantees global optimality of the solution.The form of the Bregman divergence varies according to the p.d.f. chosen as the noise model. For example, assuming p(·) to be Gaussian, the Bregman divergence is the squared Euclidean distance∥u(x)−K*μ(x,β)∥22. If p(·) is a Poisson distribution, the corresponding Bregman divergence is the relative entropyu(x)logu(x)K*μ(x,β)+K*μ(x,β)−u(x). The Bregman divergences associated with any p.d.f. from the EF are given in Table 1 of Paul et al. (2013). We denote byBp*(·∥·)the Bregman divergence induced by the noise model p.d.f. p*. Integrating over the image domainΩI,the final data-fitting energy term then reads(6)Ed(x,β)=∫ΩIBp*(u(x)∥g−1(K*μ(x,β))dx.The regularizer is required to prevent over-fitting the noise in the image. It is a necessary component of any segmentation energy function and plays the role of a Bayesian prior in the estimation problem. We here use the popular total variation (TV) regularizer:(7)Er(x,β)=∫ΩI∥∇μ(x,β)∥2dx,where ∇μ is the gradient of the model image.The total energy functional is then given by(8)ET(x,β)=Ed(x,β)+λEr(x,β),where the scalar regularization coefficient λ > 0 weights the regularizer term. This function is convex, since bothEdandErare convex, multiplying a convex function by a positive constant leaves it convex, and the sum of two convex functions is convex. Increasing λ increases the penalization of small undulations of the segmented filaments. Both λ and the scaling size h of the B-spline functions affect the robustness against noise and the segmentation precision of the method.Now we can state the filament segmentation problem more formally: The goal is to design an algorithm that finds the optimal coefficientscϕ*[k]andcψ*[k]such that the energy in Eq. (8) is minimized, hence(9)(cϕ*[k],cψ*[k])=argmincϕ[k],cψ[k]ET(x,β).Since the spline coefficients are normalized to[−1,1](see Section 3.2.2), the domain of the optimization variables is the hypercube[−1,1]|k|,which is a convex set. Minimizing a convex function over a convex domain constitutes a globally convex optimization problem. The result will hence be a globally optimal filament segmentationHf*(x).We provide an algorithm that globally optimizes the coefficients cϕ[k] and cψ[k] of the two B-spline level-set functions and estimates the mean intensitiesβof the fore- and background regions. We use alternating minimization (Gunawardana and Byrne, 2005) over the energy functional in Eq. (8). We first introduce the method to estimate the intensitiesβ, followed by the procedure used to optimize the level-set coefficients. Since both the level-set optimization problem and the intensity estimation problem are convex, the alternating minimization scheme is guaranteed to converge (Gunawardana and Byrne, 2005). Note that the two problems are likely not jointly convex, but separately convex, which is enough for convergence (Gunawardana and Byrne, 2005). If needed, a jointly convex formulation could possibly be derived by extending recent works (Brown et al., 2012). A post-processing step then extracts parametric polynomial curves for all filaments.Photometric estimation aims to estimate the mean intensity vectorβfor fixed Hf(x). For a perfect imaging process (i.e., ifK=1), estimatingβis trivial, as we can directly use the average intensity of a region as its mean. With an imaging-distortion kernel K acting on μ(·), however, the optimal value forβis not a simple average (Paul et al., 2013).In this case, we minimize the data-fitting term to find the most likely value ofβ. This convex problem is efficiently solved using the Fisher scoring algorithm (McCullagh, 1984; Nelder and Wedderburn, 1972). We use the freely available solver from Paul et al. (2013), and refer to it as the region statistics solver. This solver is called multiple times in the alternating minimization framework. After each call, Hf(x) is re-optimized using the new photometries, iterating until convergence (which is guaranteed for a separately convex problem). For this geometric optimization step, the spline coefficients are optimized using gradient descent.The gradient-descent procedure iteratively evolves the coefficients for the two B-spline level-set functions ϕ(·) and ψ(·), going from iteration i toi+1as(10)cϕ(i+1)(k)=cϕ(i)(k)−αGϕ(i)(k)cψ(i+1)(k)=cψ(i)(k)−αGψ(i)(k),where α is the step-size (automatically adapted as described below), andGϕ(i)(k)andGψ(i)(k)are the energy gradients for the two level-set functions, respectively. Instead of numerically approximating the gradients, we directly compute and use the regularized analytical gradients.The gradient of the energy cannot directly be computed because of the Dirac and Heaviside distributions in Hf. In order to get a continuously differentiable energy, we hence regularize them as previously described (Bernard et al., 2009):(11)Hϵ(x)=11+e−ϵHxδϵ(x)=1π(ϵδ/(x2+ϵδ2)).Since the level function is normalized to[−1,1],we fix the regularization parameters toϵH=20andϵδ=0.1(Bernard et al., 2009).The parametric representation of the level-set functions as B-splines allows us to directly compute the analytical gradients of the energy with respect to the spline coefficients using the chain rule for differentiation. For the data-fitting termEd(·),we have(12)Gϕd(k)=∂Ed(x,β)∂cϕ[k]=(β1−β2)∫ΩIBp*′(·∥·)K*δϵ′(ϕ)Hϵ(ψ)bn(xh+1−k)dx,Gψd(k)=∂Ed(x,β)∂cψ[k]=(β1−β2)∫ΩIBp*′(·∥·)K*δϵ(ϕ)δϵ(ψ)bn(xh+1−k)dx.For compactness of notation, we omit the arguments of the Bregman divergence, hence readBp*(·∥·)asBp*(u(x)∥g−1(K*μ(x,β))andBp*′is the derivative with respect to the B-spline coefficients in μ. For the regularizer termEr(·),we have(13)Gϕr(k)=∂Er(x,β)∂cϕ[k]=∫ΩIK*∥∇δϵ′(ϕ)Hϵ(ψ)∥2bn(xh+1−k)dx,Gψr(k)=∂Er(x,β)∂cψ[k]=∫ΩIK*∥∇δϵ(ϕ)δϵ(ψ)∥2bn(xh+1−k)dx.The prime (′) means derivative with respect to the only variable of that function. The total gradient is the weighted sum of these two parts:(14)Gϕ(k)=Gϕd(k)+λGϕr(k),Gψ(k)=Gψd(k)+λGψr(k).These analytical gradients can be efficiently evaluated numerically. Specifically, Eq. (14) can be rearranged as follows (takingGϕ(k)as an example):(15)Gϕ(k)=∫ΩIK*((β1−β2)Bp′(·∥·)δϵ′(ϕ)Hϵ(ψ)+λ∥∇δϵ′(ϕ)Hϵ(ψ)∥2)︸afunctionωϕ(x)·bn(xh+1−k)dx.It can hence be interpreted as a convolution of the function ωϕ(x) with the spline basis bn(·). This simplifies the gradient calculation for each coefficient in cϕ[k] to(16)Gϕ(k)=ωϕ(x)*bn(xh+1−k),Gψ(k)=ωψ(x)*bn(xh+1−k).

@&#CONCLUSIONS@&#
We have presented a new algorithm to solve the filament segmentation problem for curved one-dimensional filaments in two-dimensional digital images. The presented method has only two parameters and does not require prior knowledge about the number of filaments in the image. It provides segmentation results with sub-pixel accuracy as open polynomial curves. This enables high-resolution studies of filament dynamics and provides access to spatial and temporal derivatives of the curve and its time evolution. Open curves are represented by a vector level-set, which enables topological changes during contour evolution. The method is flexible to accommodate different noise models and image-acquisition models. The segmentation result is guaranteed to be optimal for the given model. This is the result of a convex formulation of the underlying optimization problem, using Bregman divergences to measure the similarity between images, and a GLM model for the image pixel statistics. In other words, our method exploits prior knowledge about the physical properties of the imaging system in order to improve segmentation quality. Note that the geometric and photometric problems are likely not jointly convex, but separately convex, which is enough for convergence. If needed, a jointly convex formulation could possibly be derived extending recent works (Brown et al., 2012).We provided an efficient algorithm to compute the optimal filament segmentation under the postulated models. The algorithm combines the analytical energy gradients with a fast convolution-based gradient evaluation. We have also for the first time shown an information-theoretic lower bound on the segmentation error in filament segmentation. No algorithm can possibly do better than this bound given the information in the image. We have shown that for the specific bound of B-spline level sets, the presented algorithm is asymptotically optimal for high SNR. For low SNR, the presented algorithm is not the best one could do, as it remains slightly above the theoretical bound. This, however, is due to parameter choices, as discussed. Quantifying the residual fitting uncertainty could, for example, be done using particle filters in an outer loop, as previously described (Cardinale et al., 2009).Comprehensive simulations were conducted to illustrate the major differences with prior works, show main features of our method, quantitatively evaluate the performance on synthetic images, and demonstrate applications on real biological images. The benchmarks have also identified recommended choices for the algorithm parameters h and λ: for fluorescence images with SNR between 4 and 30, one should set h to 1, for phase-contrast imageh=0. The λ value is largely inconsequential. A default value of10−5should yield good results.The time required by the algorithm to segment an image depends on the image size and on how far the initialization is form the final segmentation. It does not depend on the number of filaments in the image. The current MATLAB implementation processes a 512 × 512 pixel 8bit image in about 30 seconds using MATLAB 2013b on a single core of an Intel Core i7 2.2 GHz processor.In its current form, the method has a number of limitations. Probably the most restrictive one is that filament crossings and overlaps are not allowed. This is an inherent limitation of the two-component vector level-set description of filaments. Handling crossing filaments would require using more than two level functions (three to allow single crossings, four for tripple points, etc.). Currently, the method is also limited to 2D images. Segmenting filaments in 3D images would require the use of three level functions. A limitation of the current theoretical derivation is that the intensities of the filaments and the background are assumed to be uniform. As we have shown, however, the segmentation is still asymptotically optimal even when these assumptions are not fulfilled, with a bounded increase in the error. Intensity variations along a filament could then be read out during post processing and used as biological readouts, but the tips of the filaments may be inaccurately estimated, especially when the filaments get dimmer towards the tips.There are a number of directions along which future work could improve on the present framework. An obvious thing to do would be to extend to more than two level functions in order to handle crossing filaments and higher-dimensional images. Extending the method to allow for shaded fore- and background intensities in a theoretically optimal way is less straightforward and requires more research in convex relaxation theory. A more short-term goal could be to include a line search over h in a scale-space pyramid (i.e., automatically repeating the segmentation for successively lower h) to find the optimal h that leads to the lowest global energy minimum in each case. Together with a default value for λ, this would effectively render the algorithm parameter-free.We provide an open Matlab implementation of the presented algorithm as a reference. In addition, the algorithm has also been implemented in Java, as part of the open-source MOSAICsuite plugin for the user-friendly image-analysis environments ImageJ (Schneider et al., 2012) and Fiji (Schindelin et al., 2012). Both implementations are freely available from the MOSAIC Group’s web site mosaic.mpi-cbg.de. The main contributions of the present paper were to: (1) show an information-theoretic lower bound on the segmentation error for filaments, providing a baseline against which algorithms can be compared; (2) introduce the vector level-set idea for filament segmentation, uniting the advantages of both region-segmentation and curve-fitting methods; (3) showing that the resulting optimization problem can be solved efficiently and in a globally optimal way; (4) providing a practical framework for filament segmentation across different imaging modalities and noise models.Conceived the project: IFS and JH; developed the theory and the algorithm: XX and IFS; wrote the manuscript: IFS and XX; made the figures: XX; generated benchmark data: XX and VFG (FIESTA); preparation of biological samples, microscopy, and image acquisition: VFG; Edited and approved the final manuscript: all authors.