@&#MAIN-TITLE@&#
A sparse representation-based algorithm for the voltage fluctuation detection of a power system

@&#HIGHLIGHTS@&#
Convert the fundamental signal estimation problem to a convex optimization problem.Estimate the voltage fluctuation based on signal inpainting and sparse representation.Develop the upper bound on the recover error of the voltage fluctuation component.

@&#KEYPHRASES@&#
Power system,Voltage fluctuation,Signal inpainting,Sparse representation,Orthogonal matching pursuit,

@&#ABSTRACT@&#
This paper proposes a novel algorithm for the voltage fluctuation detection of a power system based on sparse representation modeling. The contents of this research mainly include: (1) By first constructing a proper objective function of the frequency and phase, we convert the fundamental signal estimation problem to a simple mathematical convex optimization problem, which can be easily solved using an exhaustive search strategy. (2) From the viewpoint of signal restoration, we regard the voltage fluctuation detection as a signal inpainting problem and then develop anl0norm-based optimization equation that exploits the sparsity prior of fluctuation component to recover the desired representation vector. (3) With the assumption that the voltage envelope changes smoothly, we establish anl2norm-based regularization equation to further improve the regularity of the result. Experimental results show that the proposed algorithm performs well on demodulating the fundamental signal and voltage fluctuation component, with good ability of noise robustness, when compared to the classical Hilbert transform-based detection method and square demodulation method.

@&#INTRODUCTION@&#
Voltage fluctuation is a phenomenon of voltage amplitude instability that originates from fast load variations [1], and it is considered to be a major factor that degrades the power quality. In this paper, we address the classic voltage fluctuation detection problem(1)s(t)=u(t)(1+v(t))+e(t)wheres(t)stands for the measured voltage signal,u(t)=a0cos(ω0t+φ0)andv(t)=∑i=1Kaicos(ωit+φi)denote the fundamental signal and voltage fluctuation component, respectively.e(t)is a zero-mean white Gaussian noise with identically distributed entries, drawn fromN(0,σ2). We desire to develop an algorithm to demodulate the fundamental signalu(t)and the fluctuation componentv(t), getting as close as possible to the true one.Voltage envelope tracking plays a key role for voltage fluctuation detection. Over the past 20 years, extensive works on this problem are reported in the literature, using various techniques. Fast Fourier transform [2,3], Kalman filtering [4–7], wavelet transform [8–11], Hilbert transform [12–15], neuron network [16,17], S-transform [18,19], genetic algorithm [20], energy operator [21,22], and more, are some of the many directions explored in dealing with this problem. Each family of algorithms has its own merits and weak points, and choosing between these various options depends on the practical application and situation at hand.The demodulation ofv(t)is the core task for voltage envelope tracking, which is of the formw(t)=a0(1+v(t))and appears as a linear function ofv(t). The voltage envelope tracking is important, not only because the evident applications it serves but also it provides a platform that algorithms toward various inverse problems can be tested and perfected. The voltage signal observation model defined by equation (1) in fact describes a typical signal restoration problem, wherex(t)=1+v(t)goes through a point-wise degradation operationu(t), followed by an additive noise. Whenu(t)is known and contains zeros, equation (1) specializes to the inpainting problems(t)=u(t)x(t)+e(t), which can also be regarded as a generalized signal interpolation problem where the mask (sub-sampling) operatoru(t)randomly nulls samples fromx(t)and is highly ill-posed with infinite solutions.Signals in the real world are sparse in essential, because most of them are spatially and temporally correlative, implying that they can be represented at a relatively low dimension. As a research hotspot, using sparse representations with specific choices of a redundant dictionary as a driving force for signal restoration has drawn a lot of attention and achieves great success in noise removing [23–25], deconvolution [26], inpainting [27,28], super-resolution [29,30], and so on. Generally speaking, these methods can lead to the best known performance in their respective fields, and rank among the best performing methods that define the current state-of-the-art. In our opinion, the key for success of these sparse representation-based methods is that they have well exploited the sparsity prior of signals. Based on this insight, this paper proposes a novel algorithm for voltage fluctuation component demodulation based on signal inpainting using sparse representation modeling. The rest of the paper is organized as follows. In Section 2, we construct a proper objective function and convert the fundamental signal estimation problem to a simple mathematical convex optimization problem and use the exhaustion method to solve it. In Section 3, we develop anl0norm-based optimization equation that exploits the sparsity prior ofv(t)and use the orthogonal matching pursuit (OMP) sparse coding algorithm [31] to recover the desired representation vector of the fluctuation component, which is then used to evaluate the flicker severity by computing the short-term flicker indicatorPst. With the assumption thatv(t)is piecewise smooth, anl2norm-based regularization equation, with a closed-form solution, is established to further improve the regularity of the result. Details of the numerical algorithm for solving the above optimization equations are provided in Section 4, followed by the experimental validations of the proposed method and comparisons, visually and quantitatively, with the classical Hilbert transform-based detection method and the square demodulation method in Section 5. Conclusions are given in Section 6.Using the product-to-sum formula, the voltage signals(t)formulated by equation (1) can be expended to a set of cosine functions with different frequencies and phases(2)s(t)=a0cos(ω0t+φ0)+∑i=1Ka0ai2cos((ω0+ωi)t+φ0+φi)+∑i=1Ka0ai2cos((ω0−ωi)t+φ0−φi)+e(t).Recall that the cosine function has orthogonality such that(3)1π∫02πcos(jt)cos(kt)dt={1,j=k0,j≠kIn this section, we uses(t)as the integral kernel to construct an objective function that is similar to equation (3) and then use it to recover the fundamental signalu(t)by searching the optimal parameters to maximize it.Define(4)G(ω,φ)=limT→∞⁡2T∫0Tcos(ωt+φ)s(t)dtω∈[Ωumin,Ωumax],φ∈[0,2π)which can be expended as(5)G(ω,φ)=limT→∞⁡2T∫0Ta02cos((ω+ω0)t+φ+φ0)dt+limT→∞⁡2T∫0Ta02cos((ω−ω0)t+φ−φ0)dt+limT→∞⁡2T∫0Ta02∑i=1Kai2cos((ω+ω0+ωi)t+φ+φ0+φi)dt+limT→∞⁡2T∫0Ta02∑i=1Kai2cos((ω+ω0−ωi)t+φ+φ0−φi)dt+limT→∞⁡2T∫0Ta02∑i=1Kai2cos((ω−ω0+ωi)t+φ−φ0+φi)dt+limT→∞⁡2T∫0Ta02∑i=1Kai2cos((ω−ω0−ωi)t+φ−φ0−φi)dt+limT→∞⁡2T∫0Tcos(ωt+φ)e(t)dt=G+ω0+G−ω0+G+ω0+ωi+G+ω0−ωi+G−ω0+ωi+G−ω0−ωi+Ge.Supposing thatω0∈[Ωumin,Ωumax]andωi∈[Ωvmin,Ωvmax], the ranges of the frequency variantsω+ω0,ω+ω0+ωi,ω+ω0−ωi,ω−ω0+ωiandω−ω0−ωican be obtained as(6)R(ω+ω0)=[2Ωumin,2Ωumax]R(ω+ω0+ωi)=[2Ωumin+Ωvmin,2Ωumax+Ωvmax]R(ω+ω0−ωi)=[2Ωumin−Ωvmax,2Ωumax−Ωvmin]R(ω−ω0+ωi)=[Ωvmin−ΔΩu,Ωvmax+ΔΩu]R(ω−ω0−ωi)=[−Ωvmax−ΔΩu,−Ωvmin+ΔΩu]whereΔΩu=Ωumax−Ωvmin. In the condition that(7)Ωvmin>ΔΩuandΩvmax<2Ωuminit is easy to know that none of the ranges in expression (6) contains zero elements. Thus, the corresponding integrals in equation (5) become(8)G+ω0=limT→∞⁡2a0T(ω+ω0)sin(τT+φ+φ0)|τ=0τ=ω+ω0=0G+ω0+ωi=limT→∞⁡a0T(ω+ω0+ωi)sin(τT+φ+φ0+φi)|τ=0τ=ω+ω0+ωi=0G+ω0−ωi=limT→∞⁡a0T(ω+ω0−ωi)sin(τT+φ+φ0−φi)|τ=0τ=ω+ω0−ωi=0G−ω0+ωi=limT→∞⁡a0T(ω−ω0+ωi)sin(τT+φ−φ0+φi)|τ=0τ=ω−ω0+ωi=0G−ω0−ωi=limT→∞⁡a0T(ω−ω0−ωi)sin(τT+φ−φ0−φi)|τ=0τ=ω−ω0−ωi=0.Moreover, by exploiting the inequality(9)Ge≤limT→∞⁡2T∫0T|cos(ωt+φ)|e(t)dt≤limT→∞⁡2T∫0Te(t)=2E(e(t))=0we plug these two expressions into equation (5) and get(10)G(ω,φ)=limT→∞⁡2T∫0Ta02cos((ω−ω0)t+φ−φ0)dtwhich can be easily computed by(11)G(ω,φ)={a0cos(φ−φ0),ω=ω00,ω≠ω0.Clearly, whenω=ω0andφ=φ0, the objective functionG(ω,φ)reaches its maximal valuea0. This means that the estimation of the fundamental signalu(t)=a0cos(ω0t+φ0)becomes a simple convex optimization task ofG(ω,φ).For the digitalized voltage signal with sampling frequencyfs(according to the Nyquist sampling theory,fsshould be no less than2f0=ω0/π), the number of samples per period ofu(t)isM=2πfs/ω0, which corresponds to a phase interval ofΔφ=2π/M=ω0/fs. Thus the restoration error ofφ0satisfies(12)|φˆ0−φ0|≤Δφ2=ω02fs.It is evident that a largefsleads to a small error bound but at the price of more computation and memory usage.Denote(13)y(t)=s(t)−u(t)=u(t)v(t)+e(t)and rewrite the expression above equivalently in matrix form(14)y=Uv+ewhereU∈Rn×nis a diagonal matrix with the main-diagonal containingu(1),u(2)…u(n)on the main-diagonal and represents a pointwise multiplication operator on the desired fluctuation vector v. Using the sparse representation modeling, suppose that v can be formulated as a linear combination of the columns (normalized) of a redundant dictionaryA∈Rn×mwithn<m(15)v=Ax.By recovering the sparsest solution(16)xˆ=argminx‖x‖0subject tov=Axa plausible estimation ofvˆ=Axˆcan be obtained.At first glance, solving equation (16) seems to be an impossible task because we do not have access to the true vector v. To find a good approximation toxˆ, we turn to solve the alternative equation(17)x⋆=argminx‖x‖0subject to‖y−UAx‖22≤ρnσ2and discuss how good this approximation will be in terms of the mean-squared-error (MSE) betweenx⋆andxˆ. A constant value of ρ is used in equation (17) to control the error tolerance.Consider the upper bound of‖y−UAx‖22such that(18)‖y−UAx‖22=‖U(v−Ax)‖22=‖U(v−Ax)‖22‖v−Ax‖22⋅‖v−Ax‖22≤λmax(UTU)⋅‖v−Ax‖22=umax2⋅‖v−Ax‖22where the definition of thel2-induced matrix norm,‖U‖22=maxc⁡‖Uc‖22/‖c‖22=λmax(UTU), is exploited, which is equal to the largest eigenvalue ofUTU. Replace‖y−UAx‖22by this bound in equation (17), leading to(19)‖v−Ax‖22≤ρnσ2umax2.The above expression implies that the sparsest solutionx⋆of equation (17) is also a feasible solution to equation (19). Denotespark(A)as the sparse rank of matrix A that equals the smallest number of columns from A that are linearly dependent. According to the stability of the sparsest solution theory [32], we know that when the number of non-zeros entries ofx⋆satisfies‖x⋆‖0≤0.5⋅spark(A), the sparsest solution of an error-tolerant version of equation (16)(20)xϵ=argminx‖x‖0subject to‖v−Ax‖22≤ϵ2must obey(21)‖xϵ−xˆ‖22≤4ϵ21−μ(A)(2‖x⋆‖0−1)whereμ(A)is the mutual-coherence of matrix A, which is defined as the largest absolute normalized inner product between different columns such that(22)μ(A)=maxi≠j⁡|aiTaj|‖aiTaj‖22=maxi≠j⁡|aiTaj|.Letϵ2=ρnσ2/umax2. Whenx⋆is sparse enough, we can regard it as a good approximation to the sparsest solutionxϵof equation (20), and thus(23)MSE(x⋆,xˆ)=1m⋅‖x⋆−xˆ‖22≤nm⋅4ρσ2umax2(1−μ(A)(2‖x⋆‖0−1)).Furthermore, the MSE error betweenv⋆=Ax⋆andvˆcan also be bounded by(24)MSE(v⋆,vˆ)=1n⋅‖A(x⋆−xˆ)‖22≤1n⋅‖A‖22⋅‖x⋆−xˆ‖22≤4ρσ2λmax(ATA)umax2(1−μ(A)(2‖x⋆‖0−1))where the matrix compatibility inequality‖PQ‖22≤‖P‖22⋅‖Q‖22is exploited.According to the Gershgorin disk theorem [33], the i-th eigenvalue ofATA=Gsatisfies(25)|gi,i−λi(G)|≤Ri(G)=∑j=1,j≠im|gi,j|.For the left hand side we have(26)|gi,i−λi(G)|≥λi(G)−|gi,i|=λi(G)−1.For the right hand side, by exploiting the definition of the mutual-coherence, we know that|gi,j|=|aiTaj|≤μ(A), and this leads to(27)∑j=1,j≠im|gi,j|≤(m−1)μ(A).Plugging the two bound above into equation (25), we obtain(28)λi(ATA)≤λmax(ATA)≤1+(m−1)μ(A)and thus(29)MSE(v⋆,vˆ)≤4ρσ2(1+(m−1)μ(A))umax2(1−μ(A)(2‖x⋆‖0−1)).Equation (29) poses an upper bound on the recover error when using equation (17) to approximately estimate the fluctuation vectorvˆ, which is determined by equation (16). As seen in this expression, the choice of the dictionary has a crucial effect on the performance of our algorithm. Indeed, equation (29) provides a criterion that guides us on how to choose a proper dictionary, which should have the two following properties: (1) a small mutual-coherenceμ(A)and (2) an ability to sparsely represent the fluctuation vector v, which is aligned with a small‖x⋆‖0. However, it is always hard to find an ideal dictionary that can meet the above two properties at the same time, because they often conflict with each other. For example, a family of matrices with randomized entries named Grassmannian Frames may be a good choice for a dictionary because they lead to the smallest possible mutual-coherence,μ(A)=(m−n)/(n(m−1))≈1/n, but the produced representation vectorx⋆is not necessarily the sparsest one. In this paper, we do not intend to discuss the details of how to wisely choose an optimized dictionary but simply use the 2D separable redundant DCT matrices with a redundancy factor of 4 as the dictionary, which is created by a Kronecher-product of two 1D-DCT matrixA=A1D⊗A1D. The j-th atomajofA1Dis computed bycos((i−1)(j−1)/4π),i=1,2…4n. All atoms apart from the first are further processed by removing their mean.With the assumption that the voltage envelope changes smoothly (which implies thatv(t)is composed of piecewise smooth curves), we construct an optimization equation to update the coefficients of the sparse solutionx⋆over its supportSby using a derivative expression to penalize non-smooth behavior in order to promote better regularity in the solution(30)x˜S⋆=argminxS‖y−Uv‖22+η‖Dv‖22=argminxS‖y−UASxS‖22+η‖DASxS‖22=argminxSL(xS)where D is a first-order differential matrix andASandxSpresent the sub-dictionary and sub-vector that belong to A and x overS, respectively. Constant η is used for controlling the weight of the smoothness constraint contributing to the penalty function. Taking a derivative ofL(xS)with respect toxSand setting it to zero gives(31)∂L(xS)∂xS=−ASTUT(y−UAS)+ηASTDTDASxS=0and the solution is given in closed-form as(32)x˜S⋆=(ASTUTUAS+ηASTDTDAS)−1ASTUTy.Similar to the analysis in equation (12), the phase accuracy ofv(t)is also affected by the sampling frequencyfssuch that|φˆi−φi|≤ωi/2fs(without considering the error introduced by equation (29)), whereφistands for the phase of the i-th Fourier expansion component ofv(t)andfs≥2fi=ωi/π.Oncev(t)is found, the instantaneous flicker sensing functionJ(t)can be computed from the diagram shown in Fig. 1, which is used to simulate the response of the lamp-eye-brain chain.The transfer functions of the weighting filter in block 1 and first order sliding mean filter in block 2 are(33)FWF(s)=kq1ss2+2γs+q12⋅1+s/q2(1+s/q3)(1+s/q4)and(34)FMF(s)=11+0.3swhere the parameters k, γ,q1,q2,q3andq4used in equation (33) are 1.7480,2π⋅4.0598,2π⋅9.1549,2π⋅2.2798,2π⋅1.2254and2π⋅21.9, respectively. Using the operatorv(t)∘F(s)to notate the filtering process on signalv(t)with transfer functionF(s), the relation betweenJ(t)andv(t)can be written as(35)J(t)=(v(t)∘FWF(s))2∘FMF(s).Denoting the frequency distribution function ofJ(t)ash(k)=P(J(t)=k), the cumulative probability function ofJ(t)can be expressed as(36)H(k)=∫k∞h(p)dp=P(J(t)≥k)=P((v(t)∘FWF(s))2∘FMF(s)≥k).Based onH(k), the flicker severity can be evaluated by the short-term flicker indicatorPstby(37)Pst=K0.1P0.1+K1P1s+K3P3s+K10P10s+K50P50swhereP1s=(P0.7+P1+P1.5)/3,P3s=(P2.2+P3+P4)/3,P10s=(P6+P8+P10+P13+P17)/5andP50s=(P30+P50+P80)/3.Px=H(xJmax/100)stands for the probability thatJ(t)exceedsx%times its peak valueJmax. The parametersK0.1,K1,K3,K10andK50are 0.0314, 0.0525, 0.0657, 0.28 and 0.08, respectively.DenoteQ(k)as the half period RMS voltage characteristics of signals(t)(38)Q(k)=1Th∫kTh(k+1)Ths2(t)dt,k=0,1,2…whereTh=π/ω0=1/2f0equals the half period of fundamental signalu(t). Based onQ(k), we use the maximum relative voltage change indicator to evaluate the voltage fluctuation severity(39)q=Qmax−QminUNwhereQmaxandQminare the maximum and minimum values ofQ(k), respectively.UNis the nominal voltage of the measured signal. According to the signal model posed in equation (1), this value isa0/2.Using the Schwartz inequality, equation (38) satisfies (without considering the noise terme(t))(40)Q(k)=1Th∫kTh(k+1)Th(u(t)+u(t)v(t))2dt≤1Th∫kTh(k+1)Thu2(t)dt+1Th∫kTh(k+1)Thu2(t)v2(t)dt=a02+1Th∫kTh(k+1)Thu2(t)v2(t)dt.Similarly, the lower bound ofQ(k)can also be obtained as(41)Q(k)≥a02−1Th∫kTh(k+1)Thu2(t)v2(t)dt.Combining the two bounds above with equation (39), we have(42)q=2(Qmax−Qmin)a0≤22a0⋅1Th∫kTh(k+1)Thu2(t)v2(t)dt=22⋅1Th∫kTh(k+1)Thcos2(ω0t+φ0)v2(t)dt.The right-hand-side of the above expression imposes an upper bound on the voltage fluctuation severity indicator q. Clearly, this bound explicitly depends on the voltage fluctuation signalv(t).To sum up, we use the algorithm listed below for the voltage fluctuation detection:•Estimate the fundamental signal u(t):(a)Search through the collection of(ω,φ),ω∈[Ωumin,Ωumax],φ∈[0,2π)with accuracy Δω and Δφ to find the optimal(ωˆ0,φˆ0)that maximizes the objective functionGmax(ω,φ)=G(ωˆ0,φˆ0)=aˆ0.The fundamental signal is recovered byuˆ(t)=aˆ0cos(ωˆ0t+φˆ0).Estimate the fluctuation component v(t):(a)Computey=s−uˆand partition y into overlapping segmentsy1,y2…yNwith length of L.For each segmentyi:–Apply the OMP sparse coding algorithm to solve equation (17) to obtain the representation vectorxi⋆and its supportS.Use equation (32) to update the desired solutionx˜iS⋆.Recover the i-th fluctuation vector segmentvˆi=ASx˜iS⋆.Merge the recovered segmentsvˆ1,vˆ2…vˆNby averaging them one on top of the other to obtain an estimate of the fluctuation vectorvˆ.

@&#CONCLUSIONS@&#
