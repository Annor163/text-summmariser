@&#MAIN-TITLE@&#
Contour-based focus of attention mechanism to speed up object detection and labeling in 3D scenes

@&#HIGHLIGHTS@&#
Fast focus of attention mechanism based on 3D contour featuresIndividual contour features cast a vote for the presence of the entire object.Model parts are obtained to generalize across intra-class variations.Considerably speed up is achieved in comparison to a sliding window approach.

@&#KEYPHRASES@&#
3D contour-based features,Object center voting,Focus of attention,

@&#ABSTRACT@&#
Graphical abstract

@&#INTRODUCTION@&#
Over the past few years, the increasing availability of low-cost 3D sensors has made it possible for the problem of detecting and localizing objects in 3D scenes to receive a great deal of attention. Recently, category-level detection and viewpoint estimation were addressed in [1] using 2D images to detect rigid 3D objects. A serious effort has been made to design robust and discriminative 3D features [2–7] with the purpose of finding correspondences between 3D point sets. Depending on their descriptiveness, 3D features may be complex and computationally demanding, sometimes making them unsuitable for real-time applications. While many of these methods use local image patches as basic features both for whole image classification [8–10] and object recognition [11–14], several approaches based on contour features have been recently proposed to address the class-level localization problem [15,16]. When working in complex scenarios, more edges are detected and, consequently, more contour features are extracted. Some of these features correspond to the boundaries of the object of interest and others to the background. The advantage of using contour features is that the information on object contours can be isolated from the background. This is especially true in 3D, where the extraction of contour features is influenced by the physical positioning of objects, making it robust to variations in color or lighting conditions. Image patch-based methods tend to fail due to interactions with the varying background.In this paper, a 3D object detection pipeline is presented, see Fig 1. The first stage in the pipeline consists of a 3D contour based feature extraction process. The extracted features correspond to a 3D version of the features presented in the work of Ferrari et al. [17]. Since these features are not only fast to compute but also less discriminative than others, which are more complex, they are used to quickly obtain rough estimates for an object's position in the scene.During the training phase, representative features for each class are extracted to construct a part-based model of the object class. During the testing phase, the extracted features are matched with object models.The second stage of the pipeline consists of a focus of attention mechanism based on a Hough-style object center voting scheme. Since each feature and object part have their associated local reference frame, the matching of their invariant descriptors induces a translation and a rotation, casting a vote for the presence of the object at a particular position in a 3-dimensional Hough space.The basic idea of this mechanism consists of obtaining object center hypotheses that, though they may contain many false positives, are fast to compute. These hypotheses will guide the detection carried out by more descriptive features and speed up the overall detection procedure without losing performance.The last stage of the pipeline performs object detection and labeling in the 3D scene using the excellent algorithm presented by Lai et al. in Ref. [18]. In order to speed up the detection, object center hypotheses obtained in the previous stage of the pipeline are thresholded and taken into account to compute object probability maps. Instead of scanning the entire scene to determine object positions, the HoG based sliding window feature extraction and classification algorithm has been modified. The goal of this modification is to compute features and apply classification filters at the positions where the votes of the previous stage indicate the presence of an object.This paper is organized as follows: Section 2 gives an overview of different approaches in the field of 2D and 3D object recognition using contour-based methods. Section 3 presents the contour features used in this paper. Section 4 introduces the model part mechanism employed to match features and describes the voting approach that serves as a focus of attention system for the subsequent detection steps. Finally, Section 5 provides some results for the algorithm presented in this paper tested on some scenes. Some of these scenes are taken from the RGB-D dataset [19] while others are newly acquired. These results are also compared with those in Ref. [18].

@&#CONCLUSIONS@&#
In this paper, a focus of attention mechanism to speed up the detection and labeling of objects in 3D scenes has been presented. With this method, HoG features extraction and window based classification filters are applied to certain positions of the image where the objects are predicted to be located. Detection performance and computation time results are compared to a sliding window detection approach. The results show that the proposed method considerably speeds up the detection process without sacrificing any performance in terms of object detection.