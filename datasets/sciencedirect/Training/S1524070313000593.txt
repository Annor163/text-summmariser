@&#MAIN-TITLE@&#
A new sketch-based 3D model retrieval approach by using global and local features

@&#HIGHLIGHTS@&#
A novel sketch-based 3D model retrieval approach using global and local features.Employ hybrid feature lines to generate representative views for 3D models.An improved bag-of-features method to extract local features and their relations.An efficient two-stage matching strategy to evaluate the relevance.

@&#KEYPHRASES@&#
Sketch-based 3D model retrieval,Global features,Local features,Semantic relations,

@&#ABSTRACT@&#
With the rapid growth of available 3D models, fast retrieval of suitable 3D models has become a crucial task for industrial applications. This paper proposes a novel sketch-based 3D model retrieval approach which utilizes both global feature-based and local feature-based techniques. Unlike current approaches which use either global or local features, as well as do not take into account semantic relations between local features, we extract these two kinds of feature information from the representative 2D views of 3D models that can facilitate semantic description and retrieval for 3D models. Global features represent the gross exterior boundary shape information, and local features describe the interior details by compact visual words. Specifically, an improved bag-of-features method is provided to extract local features and their latent semantic relations. In addition, an efficient two-stage matching strategy is used to measure the distance between the query sketch and 3D models for selection and refinement. Experiment results demonstrate that our approach which combines these two kinds of complementary features significantly outperforms several state-of-the-art approaches.

@&#INTRODUCTION@&#
With the rapid increase in the number of available 3D models, the ability to fast retrieve suitable 3D models has become more and more crucial in many industrial applications. A common way is keyword-based retrieval such as Google 3D Warehouse where users input keywords and models are returned by matching the input text and the pre-specified model tags. Because the tags are general text descriptions provided by users and sometimes cannot describe models clearly, keyword-based retrieval often returns unexpected results. Another important alternative is content-based retrieval [1]. Model retrieval by example requires users to provide an example model as the initial input, but it is not applicable when the example model is not at hand. Instead, sketch-based retrieval is much more intuitive and convenient, where users can just draw a 2D sketch as the input. In fact, a sketch is the more natural way for 3D model retrieval. As a sketch is rough and only contains partial information about a 3D model, effective sketch-based retrieval is challenging and difficult.Several studies have sought to improve sketch-based 3D model retrieval effectiveness [2–4]. They matched the 2D query sketch with multiple views of 3D models, and encoded sketches and views with feature descriptors. According to the feature descriptors used, existing methods can be classified into two categories, i.e., global feature-based methods and local feature-based methods. The global features-based methods extract global shape information from 2D views of 3D models, and describe the views as global descriptors such as Spherical Harmonic descriptor [2] and Light Field descriptor [3] to support global shape matching. The local features-based methods consider the views as bag of independent visual words, which can facilitate partial shape matching by using bag-of-features descriptors [4]. So far, most methods utilize only global shape descriptors to represent 2D views. Very recently, local features have been widely used in many computer vision applications [5]. The utilizations of local features usually achieve better performance than the traditional methods using only global descriptors. Moreover, to the best of our knowledge, current local feature-based methods still have some drawbacks, for example, they do not take into account semantic relations between local features, leading that the retrieval results cannot meet the user’s needs. The purpose of this research is to improve retrieval effectiveness and efficiency by combining global and local features.In the paper, we propose a novel sketch-based 3D model retrieval approach by combining both the global feature-based and local feature-based techniques to capture complementary features and improve retrieval effectiveness. Our approach takes a simple 2D sketch of the desired model as the input and compares this sketch to a set of representative 2D projection views of each model in a 3D model database. The approach utilizes global features to rapidly locate candidate models. Improved local features are exploited to further refine these candidate models. The effectiveness of our approach is demonstrated by comparative and evaluative experiments. The main contributions of this paper are summarized as follows:1.We propose a novel sketch-based 3D model retrieval approach by utilizing both the global and local visual features and taking into account the semantic relations between local features.We employ the hybrid feature line generation and best view selection techniques to generate a good set of representative views for 3D models.We adopt the integrated descriptors to represent global features of views from multiple aspects. We further present an improved bag-of-features method to extract local features of views and represent them as distributions of compact visual words.An efficient two-stage matching strategy is proposed to evaluate the relevance between the input sketch and 3D models.We evaluate our approach over the public standard dataset. The experimental results show that our approach can achieve significantly better retrieval performance compared with the state-of-the-art methods.The rest of this paper is organized as follows. In Section 2, we introduce related work about sketch-based 3D model retrieval. Section 3 gives an overview about our approach. Feature extraction and retrieval algorithms are presented in Sections 4 and 5, respectively. Section 6 reports the experimental results. Section 7 concludes the paper and discusses future work.

@&#CONCLUSIONS@&#
