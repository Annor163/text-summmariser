@&#MAIN-TITLE@&#
Face recognition using support vector model classifier for user authentication

@&#HIGHLIGHTS@&#
We present an online SVM-based face-recognition system using user facial features.The Olivetti, NCKU, and FERET Research Lab database of user facial features were used.The global precision of face recognition was over 97% with cross-validation scheme.Our scheme provided a higher precision of face recognition than that of the existing schemes (89%).

@&#KEYPHRASES@&#
E-commerce,SVM,Face recognition,Wavelet transforms,Local binary pattern,

@&#ABSTRACT@&#
Most existing user authentication approaches for detecting fraud in e-commerce applications have focused on Secure Sockets Layer (SSL)-based authentication to inspect a username and a password from a server, rather than the inspection of personal biometric information. Because of the lack of support for mutual authentication or two-way authentication between a consumer and a mercantile agent, one-way SSL authentication cannot prevent man-in-the-middle attacks. In practice, in user authentication systems, machine learning and the generalisation capability of support vector models (SVMs) are used to guarantee a small classification error. This study developed an online face-recognition system by training an SVM classifier based on user facial features associated with wavelet transforms and a spatially enhanced local binary pattern. A cross-validation scheme and SVMs associated with the Olivetti Research Laboratory database of user facial features were used for solving classification precision problems. Experimental results showed that the classification error decreased with an increase in the size of the training samples. By using the aggregation of both the low-resolution and the high-resolution face image samples, the global precision of face recognition was over 97% with tenfold cross-validation scheme for an image data size of 168 and 341, respectively. Overall, the proposed scheme provided a higher precision of face recognition compared with the average precision for low-resolution face image (approximately 89%) of the existing schemes.

@&#INTRODUCTION@&#
E-commerce applications have been increasing rapidly. Service providers are expected to guarantee secure transaction authentication for Web services. While Web services provide e-commerce applications that offer valuable opportunities, Web services face major challenges since consumers are reluctant to avail e-commerce services in the absence of service provider guarantees regarding the security of their information. In particular, Secure Sockets Layer (SSL)-based authentication provides an efficient and economical means of using the standard username/password convention. However, one-way SSL authentication cannot prevent cyber attacks such as phishing and man-in-the-middle attacks, which is a major obstacle to consumer adoption of e-commerce. Generally, when using a banking mobile app to access banking services online, people never think that they could become a victim of identity theft. According to reports released by privacy IT Security in the United States, hackers had gained root access to 90 servers of a financial institution’s servers in 2014, and the access enabled the hackers to transfer funds, disclose customer information, open new accounts, and even close accounts without prior knowledge of the affected customers (IT Security 2015). Because of the nondenial requirements of remote user identity authentication schemes, such access is most commonly achieved using a biometrics-based approach.Identity theft is therefore one of the most severe threats to the security of online transactions associated with e-commerce services. Consequently, it is imperative that service providers have the means to authenticate the identity of every user for detecting fraud. Efficient user authentication schemes are required to build trust in e-commerce, and mutual authentication schemes are crucial for e-commerce applications. As the sophistication of tools used by malicious users continues to increase, the data processed in e-commerce are at increased risk of attack. Consequently, there is an urgent need for robust authentication schemes that can confine data access to legitimate, authorised users by preventing malware from tracking transactions during authenticated sessions.Multifactor authentication approaches in which digital certificates are provided to users by a public key infrastructure mechanism have been developed for user authentication systems. These approaches enable detecting fraudulent use of user identity because they involve using face-recognition information, radio frequency identification (RFID) tags, and machine learning (ML) techniques. Numerous two-factor improvement methods (Min et al. 2011, Jing et al. 2009, Nguyen et al. 2012, Yang et al. 2012, Battaglia et al. 2014) have been proposed. Authors incorporated a face-recognition feature into a smart card, and images of each user with different facial expressions were stored in a server database and used as the basis for identity authentication. The front-end smart cards served as a secondary source and stored only a small amount of the identity information.The online face-recognition system proposed in this study employs a support vector model (SVM) classifier and has the following advantages: (i) It provides privacy protection by classifying users by using a signature-based SVM classifier (SVC) based on multilevel wavelet transformation; multilevel wavelet transformation, which is also used in the face image approach, involves using a spatially enhanced local binary pattern (LBP) (Mirza et al. 2013) of a user feature and enables accurately determining the user identity in online transactions. (ii) The proposed scheme uses a complete face image rather than partial image information to increase the recognition precision. (iii) The multilevel wavelet transformation of the face images enables the system to perform hierarchical decision-making, which increases the flexibility of the system. Experimental results reveal that the proposed system provides a secure approach for protecting a user’s biometric privacy and achieves high-precision face recognition, features that are crucial in e-commerce security mechanisms.The remainder of this paper is organised as follows: Section 2 reviews previous studies in the fields of face recognition and ML. Section 3 introduces the model that was used to construct the proposed recognition system. In Section 4, the proposed approach is presented by considering the case of a user with various facial expressions, and the approach is demonstrated by employing it in an e-commerce security system. Section 5 examines the Radial Basis Function (RBF) kernel function for using the SVM approach in the proposed approach. Finally, Section 6 provides concluding remarks.This section reviews the use of three crucial techniques—SVMs, face-recognition schemes for user authentication, and wavelet transforms—applied in face recognition for biometric authentication.SVMs are used for clustering data into two categories according to maximum boundary geometry. SVMs are supervised learning models associated with learning algorithms, and they are used to analyse data and recognise patterns. Generally, the results from SVM classification algorithms are more accurate than those derived from other ML approaches involving nonoptimised search methods, such as those involving artificial neural networks, least squares, k-nearest neighbour, Bayesian probability, and classification and regression trees, particularly when collect only limited training data. In an SVM training algorithm, examples are assigned to a category depending on whether nonlinear or linear binary classifiers are obtained from a set of training examples. SVMs have been shown to be useful tools for performing clustering and classification analyses (An and Liang 2013, Abe 2015). In particular, SVM theory has been developed gradually from linear SVCs to hyperplane classifiers (Devi et al. 2015); in other words, SVMs can efficiently perform nonlinear classification by using a kernel function, and their inputs can be mapped into high-dimensional feature spaces by selecting an appropriate kernel function. Furthermore, a favourable classification result is achieved by using a hyperplane that is the farthest from the nearest training data point of any class (Wikipedia 2015). The basic SVM theory is as follows (Vapnik 1995).Consider a given training datasetD(xi,yi), wherexidenotes n observations of malware signatures (xi∈RN,i=1,…,N) andyiis the corresponding class label of which the value is either 1 or −1 (i.e., malicious or benign); in other words,yiindicates the class to which the pointxibelongs, withyi∈{1,-1},and ayiis assigned to each observationxi. Each facial featurexiis of dimension d, which corresponds to the number of propositional variables.(1)D={(xi,yi)|xi,∈RN,yi∈{1,-1}}i=1NA typical clustering problem is the determination of the maximum margin of a hyperplane that divides the points corresponding toyi=1from those corresponding toyi=-1. Any hyperplane can be written as the set of points x satisfying the following formula:(2)w.xi+b=0∀iwhere the dot in the first term denotes the dot product and W denotes the normal vector of the hyperplane. The parameterb||w||determines the offset of the hyperplane from the origin in the direction of the normal vector W. Generally, a decision functionD(xi)is defined for clustering, withD(xi)=w.xi+b.As shown in Fig. 1, the Lagrange multiplier in the dual optimisation theory was used to determine the maximal and minimal optimisation functions, which provided a viable solution. To solve the problem of identifying the maximum margin of a hyperplane, the Lagrange function is expressed as follows:(3)LP=L(w,l)=||w||22-∑i=1Nli[yi(w.xi)+b]-∑i=1Nliwherelirepresents the Lagrange parameter. Theoretically, solving the problem of maximising the geometric boundary requires seeking the minimum of the normal |w2|, which can be transformed to minimise the Lagrange optimisation function Lp subject to the constraintyi(w.xi)+b-1⩾0:MINLP∀i(4)subject toyi(w.xi)+b-1⩾0∀iwithli⩾0∀i.To obtain the feasible solutions by using the Lagrange dual optimisation theory, a set of support vectors xisatisfying two constraints according to the classification decision functionD(x):sgn[∑i=1Nli(yi(wxi)+b)]must be identified.A traditional linear SVM has a major drawback: assuming that the training data are linearly separable, the SVM cannot be valid when applied to practical real cases. Bernhard et al. (1992) suggested a novel approach to generating nonlinear classifiers; in the approach, a kernel function is used to obtain the maximum margins of hyperplanes. The nonlinear classification algorithm is formally similar to the linear SVM, except that each dot product (i.e.,φ(xi)·φ(xj)) is replaced by a kernel function. This enables the algorithm to map the maximum margin hyperplane in a transformed feature space (i.e.,Φ:Rd→F). However, rationally selecting a suitable mapping function Φ is a research topic that must be discussed.The effectiveness of the SVM depends on the kernel selected and the parameters of the kernel. The considerations for selecting kernel functions are listed in Table 1. As shown in Table 1, the linear (Gunn 1998) and the radial basis function(RBF) (Buhmann 2003) were used as the kernel function of the SVC to establish the face-recognition system after the features and limitations of the four kernel functions were considered. To improve classification accuracy, a combination of two model parameters (i.e., soft margin parameter C and gamma γ) for the RBF was regularly selected using a grid search scheme to determine the optimised parameters of an SVC. The final model, which was used for testing and classifying new data, was then trained on the entire training set by using the kernel parameters.Automated biometric-recognition systems, which are based on the unique physiological features of users, are now widely used in the automotive, information technology, and banking industries. In general, the physiological characteristics include the individual’s shape of face fingerprint, vein pattern, and DNA.Certain fraud methods involve acquiring a users’ private information by using copied or hedge techniques, such as smart card duplication and identity theft. Two fundamental issues arise when users applying face-recognition approach to e-commerce. First, if client data is to be processed thru the Internet, it must be encrypted to ensure its privacy. As a result, efficient key management schemes are required to enable the encryption on users’ private information. Second, as the sophistication of the tools used by malicious users continues to increase, the data processed is at increasing risk of attack. Consequently, there is an urgent requirement for robust remote authentication schemes including biometric authentication system based on individual’s physiological characteristics to ensure that the data can be accessed only by legitimate, authorized users.Automatically detecting malicious users for preventing unauthorised access is a challenging task for an online e-commerce security system. Many face-recognition approaches involve LBP algorithms for user authentication. Numerous face-recognition techniques have been used in analysis algorithms for achieving high authentication precision. They include principal component analysis (Ahonen et al. 2006) and approaches involving LBPs (Jing et al. 2009), local ternary patterns (LTPs) (Tan and Triggs 2010), and spatially enhanced LBPs (Mirza et al. 2013). These face-recognition schemes are summarised in Table 2.As shown in Table 2, most existing proposals are invariably based on the assumption of employee honesty. In practice, this assumption cannot also be guaranteed in practical applications, and many real cases have been reported in which fraudulent interior staffs have stolen clients’ authentication details including biometric information from the signature server for financial gain. To resolve the security issues, the present study proposes a new remote authentication scheme based on a secret-splitting concept (Wang et al. 2011) with distributed facial features for an online e-commerce security system.The fundamental concept of wavelet transform is that the transform should permit changes only in time extension, but not in the shape, on the basis of suitable basis functions. In mathematics, a wavelet series is the representation of a real- or complex-valued function by an orthonormal series that is generated by a wavelet (Charles 1992). Currently, wavelet transformation is one of the most prevalent time-frequency transformation techniques. This paper provides a formal, mathematical definition of an orthonormal wavelet and of the integral wavelet transform. In practice, a wavelet transform is a multiresolution wavelet-analysis technique. During first-order decomposition, the face image is subjected to an LL1,LH1,HL1, orHH1band of decomposition, as shown in Fig. 2. Fig. 2(a) shows the first and second orders of decomposition based on wavelet transformation; each cell has a different resolution. Fig. 2(b) shows examples of the decomposition shown in Fig. 2(a), and LL2 represents a decomposed second-order image in Fig. 2(b-1). Wavelet conversion decomposes a face image into two parts for feature extraction: (i) a lower-resolution image and (ii) a higher-resolution image. The more common facial features appear as part of the lower-resolution information, whereas the high-resolution portion contains most of the facial features, such as local variations in illumination, expression, and dress. Conversely, inverse wavelet transformation combines the two parts of the face image into the original image through an information-reconstruction process.This section presents a face-recognition model with distributed facial features for an online e-commerce security system. The proposed model comprises two phases, namely the registration phase and verification phase.Numerous face-recognition techniques have been proposed to enhance identity recognition precision. To achieve high processing efficiency in an identity authentication system, numerous studies on face recognition have employed LBPs to obtain a low-resolution face image from captured facial features. The present study proposed a face-recognition technique based on a secret-splitting concept (Wang et al. 2011). In this concept, only some of the facial features of the user, extracted using two-dimensional wavelet transformation and an LBP scheme, are stored in a smart card to avoid the risk of having the complete biometric data stored in a repository being stolen. Unlike existing schemes, the system provides the benefit of complete privacy protection through distributed storage, in which the smart card stores images of different facial expressions and a database contains records of face images.This study proposes using a smart card and an SVM-based face-recognition model with distributed facial features in an online e-commerce security system (Fig. 3); the model involves wavelet transformation and provides multilevel analytical diagrams with information integrity. The wavelet transformation decomposes the face image into a face image with a low resolution, called a low-resolution image feature (LRIF), and a face image with a high resolution, called a high-resolution image feature (HRIF). The LRIF is stored in a smart card, and the HRIF is stored in a signature database for comparison. Notably, this study used both wavelet transformation and an LBP technique to extract regional (partial) facial features for enabling comparison in an online e-commerce security system. The wavelet transformation of a face image can be decomposed into two types of face images: (i) a series of LRIFs with different poses and (ii) a set of HRIFs corresponding to the LRIFs. An LBP technique is a simple and fast texture-handling approach; sheets of high-resolution characteristics of the face are transformed into feature histograms based on various spectral types.When a smart card manufacturer accepts an order from a service provider, the manufacturer incorporates various security parameters into the cards and then sends the cards to the service provider. The detailed procedure is shown in Fig. 4, which presents a function flow diagram of the proposed face-recognition scheme; the figure also illustrates the two subphases in the user authentication process: the registration phase and verification phase.In the registration phase, various expressions in the face images of registered users are decomposed into LRIFs and HRIFs for face recognition in an access control system. The LRIFs are stored in a compressed format and encrypted in a smart card, and the HRIFs are stored in a signature database. As shown in Fig. 4, the registration phase comprises the following four steps:(1) User Ui with identity IDi wants to register with the server. The user chooses a smart card, and then LRIFs are protected by the encryption mechanism of the smart card.(2) A face image of User Ui is obtained through a Web camera, and the features are extracted from this image to form a face feature Fi which are separated into two parts FiA and FiB, where FiA and FiB represent Part A (i.e., the LRIF) and Part B (i.e., the HRIF), respectively.(3) The terminal computes hEAi=h(FiA ⊕ ANi) and EBi=(FiB ⊕ ANi), where h(.) is a public one-way hash function and ⊕ represents the exclusive-or operator (XOR).(4) The card manufacturer arbitrarily selects a large prime number p and a 128-bit string K as the key for symmetric encryption and keeps the parameter set (p, AN, K) secret. The terminal sends (IDi, EBi, p, K) to the server over a secure channel. The terminal then stores (IDi, hEAi) in the smart card, and the signature server stores (IDi, EBi) in the database of an access control system.In the verification phase, the LRIFs of registered users are retrieved from the encrypted smart card for the first-phase comparison. The HRIFs are then retrieved from the database for the second-phase comparison. Fig. 4 shows the details of the verification phase.(5) User Uiplaces his or her RFID card on the terminal. If the RFID card is validated, AN is extracted; otherwise, the login request is rejected.(6) Users provide their images through a Web camera, and the facial features are then compared with those stored in both the smart card and signature server. Let Fi represent the facial features extracted by the Web camera. The image processing unit separates Fi into FiA and FiB and then computes hEAi=h(FiA ⊕ AN) and EBi=(FiB ⊕ AN); here, h represents a cryptographic hash function, such as a secure hash algorithm.(7) To verify the user’s legal identity using the SVM algorithm, part A of facial feature, hEAi is retrieved for comparison. If a pose of facial image with a hyperplane that has the largest distance from the nearest training data point of any class, which is selected as one of candidates with SVM classifier in first verification phase.(8) Similarly, the server sends EBi via a secure channel to the terminal for comparison purposes using the SVM algorithm. Use the selected candidates in step 7 to compare the alternatives for the maximum-margin hyperplane based on LBP feature histograms of HRIF for face image. If a match is obtained using the SVM classifier algorithm for HRIF image classification of EBi’, the verification process proceeds to invoke an authorized application; else it terminates.Because the SVC is an effective scheme for data classification, it is used to match the face features used for identifying the hyperplane that has the largest minimum distance from the training examples in Fig. 1.In decision-making for face recognition, we tested the classification of a sample by using LBP feature histograms and HRIF matching; a decision functionD(xi)was used to determine the SVC. The decision function was given byD(xi)=w.xi+b. The training process was performed to select the hyperplane, and the classification system substituted the trained model parameters derived from the training data into the SVM to categorise the sample class for testing the data. In other words, the positive class (+1) was predicted ifD(xi)>0, and the negative class (−1) was predicted otherwise.Two precision metrics, recognition precision for both the LRIF and the HRIF in Section 3.2.2 are used for assessing the global precision rate is described as follows.(1)Determine the number of remaining alternatives in the facial feature database after performing the successful recognition for the LRIF as(5)Nremaining=Ccardinality([u1,...,un]-[u1,...,un]LRIF),(2)To increase the precision rate of face recognition, a set of the extra alternatives of successful recognition for the HRIF which are located in the remaining set[u1,...,un]-[u1,...,un]LRIFis decide by(6)[u1,...,un]HRIF_EXTRA=[u1,...,un]HRIF∩([u1,...,un]-[u1,...,un]LRIF)The global precision rate for the proposed scheme which synthesizes two precision rates for both the LRIF and the HRIF is given by(7)P=faggregation(PLRIF,PHRIF)=PLRIF+Ccardinality([u1,...,un]HRIF_EXTRA)Nremaining×100%

@&#CONCLUSIONS@&#
This paper presents a face-recognition SVM model based on a smartcard-based secret-splitting concept for preserving user privacy; Compared to existing schemes, the system has a number of important advantages, namely (i) provides the benefit of complete privacy protection through distributed storage, in which the smart card stores images of different facial expressions and a database contains records of face images; (ii) the model uses multilayered analytical diagrams for wavelet conversion and a dual pattern of a spatially enhanced LBP feature-histogram spectrum, and it improves the face recognition precision. An SVM algorithm was used for cross-validation scheme verification and favourable experimental results were obtained. Overall, the proposed approach can enhance the recognition precision compared with approaches proposed in (Ojala et al. 1996, Jing et al. 2009, Tan and Triggs 2010, Nguyen et al. 2012, Yang et al. 2012, Battaglia et al. 2014), reduce the possibility of disclosure of private user information in the registration and authentication phases, and protect the users’ information against the theft of the user’s facial features by interior dishonest staff by using secret-splitting mechanism.