@&#MAIN-TITLE@&#
An interval type-2 fuzzy logic system-based method for prediction interval construction

@&#HIGHLIGHTS@&#
Quantification of uncertainties using prediction intervals.Interval type-2 fuzzy logic system-based prediction intervals.Training of interval type-2 fuzzy logic systems using a prediction interval-based cost function.Constructing quality prediction intervals.

@&#KEYPHRASES@&#
Interval type 2 fuzzy logic,Uncertainty,Prediction interval,

@&#ABSTRACT@&#
This paper introduces a new non-parametric method for uncertainty quantification through construction of prediction intervals (PIs). The method takes the left and right end points of the type-reduced set of an interval type-2 fuzzy logic system (IT2FLS) model as the lower and upper bounds of a PI. No assumption is made in regard to the data distribution, behaviour, and patterns when developing intervals. A training method is proposed to link the confidence level (CL) concept of PIs to the intervals generated by IT2FLS models. The new PI-based training algorithm not only ensures that PIs constructed using IT2FLS models satisfy the CL requirements, but also reduces widths of PIs and generates practically informative PIs. Proper adjustment of parameters of IT2FLSs is performed through the minimization of a PI-based objective function. A metaheuristic method is applied for minimization of the non-linear non-differentiable cost function. Performance of the proposed method is examined for seven synthetic and real world benchmark case studies with homogenous and heterogeneous noise. The demonstrated results indicate that the proposed method is capable of generating high quality PIs. Comparative studies also show that the performance of the proposed method is equal to or better than traditional neural network-based methods for construction of PIs in more than 90% of cases. The superiority is more evident for the case of data with a heterogeneous noise.

@&#INTRODUCTION@&#
Zadeh [1] introduced the type-2 fuzzy set (T2 FS) as an extension of the concept of an ordinary type-1 fuzzy set (T1 FS). Fundamental theories of the type-2 fuzzy logic system (T2 FLS), and in particular the interval T2 FLS (IT2FLS), were developed in late 90s and early 20s [2–5]. IT2FLSs are characterized by secondary membership functions (MFs) that only take the value of one over their domain. This significantly reduces the computational requirements needed for the type reduction stage. The extension of the type-1 FLS (T1 FLS) to its T2 counterpart allows the decision maker to account for more uncertainties present in data or operation of systems. The structure of an IT2FLS is similar to the structure of a T1 FLS. The only difference is the output processing block. In the T1 FLSs, this only includes a defuzzifier that produces a crisp output. The output processing block in IT2FLSs includes a type reduction unit that transforms a T2 FS into a T1 FS. This type-reduced set is then defuzzified into a crisp value [6].In light of the work done by Mendel and his team and further studies conducted in recent years [7–9], it is already known that IT2FLSs are a promising tool for processing uncertain data. Often, both qualitative and quantitative (numerical) uncertainties in data may translate into rule uncertainties, destroying performance of a model. IT2FLSs with additional degrees of freedom make it possible to manage and minimize the effects of uncertainties, even better than traditional T1 FLSs [5]. The recent literature is rich in application of IT2FLSs in fields such as control [10], path planning [11], decision-making [12], and forecasting [13,14].Research works on FLSs and their application for point forecast and prediction are abundant. However, there are two problems with those forecasts: (i) models become unreliable in the presence of uncertainty and (ii) no indication of accuracy of point forecasts is provided. One approach to quantify uncertainties associated with forecasts is to construct prediction intervals (PIs). Compared to point forecasts, PIs not only possess an indication of their accuracy, called the confidence level, but they also provide more reliable information about the future realization of the underlying target. A (1−α)% PI for a future observation, yf, has the form [Ln, Un] whereP(Ln≤yf≤Un)→P(1−α)%as the sample size n→∞. Lnand Unare the lower and upper bounds of the PI respectively. Also (1−α)% is the prescribed confidence level associated with PIs.For the case of neural networks (NNs), several methods have been proposed in the literature for quantification of associated uncertainties [15–20]. PI construction methods can be broadly divided into parametric and non-parametric methods. In the former group, methods usually assume that the quantitative uncertainty (noise) is independently and identically distributed and follow a known distribution with unknown parameters. They then try to optimally estimate parameters of this distribution using available data. Once estimated, they use the distribution to construct intervals for model forecasts. The point is that data in many real world problems does not follow a priori known distribution. So application of parametric methods for construction of PIs in those cases is questionable. Non-parametric methods construct PIs without making any special assumption about the data and noise distributions. So, they have more flexibility and are theoretically more appropriate than parametric methods for practical applications.The focus of this paper is on developing a framework for construction of PIs using IT2 Takagi–Sugeno–Kang FLSs (IT2 TSK FLSs). IT2 TSK FLSs have been widely used for system identification [21], control [22], and filter design [23]. This research is inspired by the fact the type reduced set carries valuable information about spread of the targets estimated by an IT2 TSK FLS model. This spread can provide valuable information about the level of uncertainty affecting estimations and forecasts. If wide (large spread), there is a high level of uncertainty associated with forecasts and they should be used with care. If narrow (small spread), forecasts are reliable and can be used confidently. Once the type-reduced set is defuzzified, this information is lost. Therefore, the proposed method here for construction of PIs using IT2 TSK FLSs does not require the defuzzification stage.The major contribution of this paper is the introduction of a novel non-parametric method for construction of PIs using IT2 TSK FLSs. In contrast to parametric methods, the proposed method requires no special assumption regarding the data and its distribution to construct PIs. It also does not require calculation of complicate matrices and derivatives required by traditional PI construction methods. It is possible to build an empirical distribution for data by constructing PIs for different confidence levels ranging between zero to one. As a distribution-free (non-parametric) method, the IT2 TSK FLS-based method for construction of PIs is robust against violations of the normality assumption and offers a promising method for rapid construction of reliable PIs.The proposed method is applied to construct PIs for seven synthetic and real-world benchmark case studies. The level of uncertainty in the synthetic data sets is controlled by adding homogeneous and heterogeneous noise. It is demonstrated that the proposed method generates high quality PIs, which are theoretically valid and practically informative. Also, the performance of the proposed method is stable in different replicates of experiments, which indicates it effectively and efficiently handles prevailing uncertainties in data. We also compare performance of the proposed method with two traditional NN-based methods for construction of PIs.The rest of this article is organized as follows: Section 2 introduces IT2 TSK FLSs. PI assessment measures and indices are briefly discussed in Section 3. Section 4 describes the proposed method for PI construction using IT2 TSK FLSs. Simulation results are demonstrated in Section 5. Finally, we draw conclusions in Section 6.The lth rule of an IT2 TSK FLS having p inputs, x1∈X1, …, xp∈Xp, and one output, y∈Y, is expressed as [3,5],(1)Rl:Ifx1isF˜1l,x2isF˜2l,…,andxpisF˜pl,thenyl=C0l+Cl1x1+⋯+Cplxpwhere l=1, …, M, and M is the number of rules.F˜ilis the ith IT2 FS (i=1, …, p) composed of a lower and upper bound MF,(2)μF˜il(xi)=[μ_F˜il(xi),μ¯F˜il(xi)]Cilis also an interval set, where its center and spread arecilandsilrespectively,(3)Cil=[cil−sil,cil+sil]where i=0, …, p.Cilare the consequent parameters of the IT2 TSK FLS model. Given an input x=(x1, x2, …, xp), the result of the input and antecedent operations (firing strength) is an interval type-1 set,Fl=[f_l,f¯l],(4)f_l(x)=μ_F˜1l(x1)*μ_F˜2l(x2)*⋯*μ_F˜pl(xp)(5)f¯l(x)=μ¯F˜1l(x1)*μ¯F˜2l(x2)*⋯*μ¯F˜pl(xp)where * represents a t-norm. It is assumed that the singleton fuzzifier is used in obtaining (4) and (5).ylin (1) is the output from the lth If-Then rule, which is a T1 FS,yl=[yll,yrl], and is evaluated as,(6)yl=[yll,yrl]=∑i=0pcilxi−∑i=0psil|xi|,∑i=0pcilxi+∑i=0psil|xi|where x0≡1. The final output of the IT2 TSK FLS model is obtained through combining the outcomes of M rules,(7)y=[yl,yr]=∫y1∈[yl1,yr1]⋯∫yM∈[ylM,yrM]∫fl∈[fll,frl]⋯∫fM∈[flM,frM]1∑l=1Mflyl/∑l=1MflThe type-2 fuzzy output is then processed by the type-reduction operation, which combines the output sets and performs a centroid calculation that leads to a type-1 fuzzy set. yland yrin (7) can be calculated using the iterative Karnik–Mendel (KM) procedure [24]. The centroid lies between the two end points calculated using the KM method. According to the KM method, yland yrare calculated as below,(8)yl=∑l=1Lf¯ilyll+∑l=L+1Mf_ilyll∑l=1Lf¯il+∑l=L+1Mf_il(9)yr=∑l=1Rf_ilyrl+∑l=R+1Mf¯ilyrl∑l=1Rf_il+∑l=R+1Mf¯ilwhere L and R are switch points computed by the KM algorithm. Finally, the defuzzified crisp output from the IT2 TSK FLS is the mean of yLand yR,(10)y=yl+yr2The design of an IT2 TSK FLS model consists of the selection of MFs for inputs and the determination of the parameters of premise (MF parameters) and consequent (linear coefficients) parameters.PIs can be examined from two perspectives: their validity and their informativeness. Here, a few measures are described for evaluation of the quality of PIs from these perspectives.Once constructed, the most important characteristic of PIs is their actual coverage probability. PI coverage probability (PICP) is measured by counting the number of target values covered by the constructed PIs (expressed as a percentage),(11)PICP=100n∑t=1nctwhere ct=1 if yt∈[Lt, Ut], otherwise ct=0. Ltand Utare the lower and upper bounds of the tth PI respectively. PICP is a measure of validity of PIs constructed with an associated confidence level. PIs are always constructed with a prescribed confidence level. Theoretically, PICP≥(1−α)%; otherwise, the constructed PIs are not reliable.A satisfactory PICP greater than the nominal confidence level can be easily achieved by generating excessively wide PIs. However, narrow PIs are practically more informative than wide PIs, and therefore more useful for decision-making. So, another measure is required to examine how much informative PIs are. PI normalized average width (PINAW) assesses PIs from this aspect and measures how wide they are (expressed as a percentage),(12)PINAW=100nR∑t=1n(Ut−Lt)where R is the range of the underlying target. PINAW is the average width of PIs as a percentage of the underlying target range. If the minimum and maximum values of targets are used for the lower and upper bounds of PIs, all targets will be bracketed by PIs. Therefore, we will have PICP=100% and PINAW=100%.While PICP is related to the correctness (validity) of intervals, PINAW is a measure of their informativeness. A combinational coverage width-based criterion (CWC) is used for simultaneous evaluation of the quality of constructed PIs from both perspectives,(13)CWC=PINAW(1+γe−η(PICP−μ))where γ=0 if PICP≥μ; otherwise γ=1. η and μ in (13) are two hyperparameters controlling the location and amount of CWC jump. The design of CWC is based on two principles: (i) if PICP is less than the nominal confidence level, (1−α)%, CWC should be large regardless of the width of PIs (measured by PINAW), and (ii) if PICP is greater than or equal to its corresponding confidence level, then PINAW should be the influential factor. The exponential term in (13) is eliminated whenever PICP≥μ and CWC becomes equal to PINAW. Further information about these measures and hyperparameters η and μ can be found in [25,15] (Fig. 1).This section specifically investigates how PIs can be constructed for targets predicted by an IT2 TSK FLS. The Karnik–Mendel (KM) [6] and Wu–Mendel [26] algorithms for type reduction compute the left and right end points needed to characterize IT2 FSs [27]. These two end points can be considered as the upper and lower bounds of an interval, where the corresponding target lies somewhere between them. The issue is that this interval cannot be called a PI, as it ignores the concept of the confidence level. The confidence level is a prescribed probability associated with PIs. As defined before, in an infinite run of the PI construction method, the coverage probability of PIs should asymptotically approach the nominal confidence level. How the current intervals (left and right end points obtained from the type reduced set) can be linked to the concept of confidence level is the question to be answered.The key idea here is to train IT2 TSK FLS models based on the characteristics of intervals that they are going to generate. Put in other words, training should be done using a PI-based cost function, rather than traditional error-based cost functions. The most important characteristic of PIs is their coverage probability. PICP≥(1−α)% is the essential condition of valid PIs. While wide PIs can easily satisfy this requirement, those are less informative and therefore, practically less useful. To further clarify on the importance of informativeness of PIs, lets consider the case that PIs are generated for the amount of power generated in a wind farm. The wind farm has a nominal capacity, where it can be used as an upper bound for PIs. The lower bound of PIs can also be set to zero which means no power is supplied by the wind farm. The coverage probability of such PIs is 100%, however, they are so wide that operators cannot make any decision based on them. Ideally, PIs should be valid and as narrow as possible to be useful for wind farm operators.To construct narrow, yet valid PIs, CWC can be applied as the cost function for training of IT2 TSK FLSs. The rationale is that CWC covers both important characteristics of PIs. Using CWC, premise and consequent parameters of IT2 TSK FLSs can be adjusted such that the constructed PIs using the end points of the type-reduced set satisfy the coverage probability requirement, i.e., PICP≥(1−α)%. During the training, if PIs are invalid with a PICP less than the associated confidence level, CWC takes a large exponential value. Otherwise, CWC becomes equal to PINAW and the training algorithm tries to make PIs narrower. It is important to note that CWC does not allow excessively narrow PIs that may result in an unsatisfactorily low PICP. In fact, reaching a tradeoff between validity and informativeness of PIs is the goal of the training process.The proposed method for construction of PIs using IT2 TSK FLSs is as follows:1.Available data samples are split into two training (Dtrain) and test (Dtest) sets.An IT2 TSK FLS model is built and its parameters are initialized. The initialization of MF parameters is performed such that the range of each input is covered by its IT2 MFs.Premise and consequent parameters of the IT2 TSK FLS model are then adjusted through minimization of CWC as the cost function. In each iteration/epoch of the optimization process, PICP, PINAW, and the cost function values are calculated for the PIs constructed using the new set of parameters. Optimization continues until no further improvement is achieved for several iterations.In mathematical terms, the training procedure can be described as follows. Letwbe the set of all premise and consequent parameters of the IT2 TSK FLS model. According to this, the training procedure will be,(14)wopt=argminwCWCsubject to the set of constraints imposed on the parameters of MFs. These constraints depend on the type of employed MFs in the model. For instance, if the Gaussian MFs with a constant mean and two uncertain standard deviations are considered in the model, the first standard deviation should be smaller than the second stand deviation. Constraints like this can be easily expressed in the form of linear inequalities for matrices.The process of training is terminated after several iterations/steps without improvement in the cost function. Once training is over, the trained model is used for construction of PIs for test samples in Dtest.CWC as the cost function is nonlinear in the parameter space and has several sharp peaks and deep valleys. This is due to the fact that CWC is highly sensitive to model parameters. A small change in a parameter may result in invalid PIs with a low PICP, which consequently causes an astronomical increment in the CWC value. CWC is also discontinuous with regard to the parameters of IT2 TSK FLS models. Therefore, it cannot be minimized using traditional gradient descent-based methods, as they rely on derivatives of the cost function. Besides, those methods are likely to be trapped in local minima of the cost functions.Alternatively, gradient-free global optimization methods can be effectively applied for minimization of CWC as the cost function. These methods avoid falling in local minima and do not require calculation of computationally expensive derivatives. Examples of these methods are genetic algorithm, simulated annealing, and particle swarm optimization.Adjustable parameters η and in particular μ enable easy adaptation of the cost function to the specific requirements of PIs. Setting μ to a value greater than (1−α)% generates a kind of bias in construction of PIs. By doing this, we aim to form a larger gap between PICPtrainand the confidence level. This is done to ensure that PICPtestwill be satisfactory. The cost that has to be paid for achieving this goal is construction of wider PIs. This is in fact a conservative approach in training of IT2 TSK FLS models. If η is set to a small value, such as less than ten, the amount of penalty for invalid PIs will not be heavy. So, the training algorithm will adjust parameters of an IT2 TSK FLS model resulting in narrow PIs. While this approach will lead to more informative PIs compared to the former approach, one has to bear the risk of having a PICPtestless than the prescribed confidence level. The precise setting of η and μ values depends on the data and the amount of risk one can tolerate in case of having very narrow PIs.Seven synthetic and real-world benchmark case studies with homogenous and heterogeneous noise are considered in this study to examine the performance of the proposed method. The first case study (CS1) is the two dimensional version of Rastrigin's function, which is based on the function of De Jong with the addition of cosine modulation in order to produce frequent local minima. One thousand random data points are generated with a uniform distribution between −5.12 and 5.12, i.e., −5.12≤xk,i≤5.12, i=1, 2, …, 1000, k=1, 2. The function has the following form,(15)yi=20+∑k=12[xk,i2+10cos(xk,i)]+ϵiwhereϵi∼N(0,5). Rastrigin's function is a typical example of a non-linear multimodal function and is quite often used as a benchmark case study in the field of optimization.The datasets for the other three synthetic case studies come from a univariate function with heterogeneous noise. One thousand random data points, x1, x2, …, x1000, are generated with a uniform distribution in the interval [−10, 10]. Target values, y1, y2, …, y1000, are then calculated using the following model,(16)yi=g(xi)+ϵiwhereg(xi)=xi2+sin(xi)+2. ϵialso follows a Gaussian distribution with mean zero and a non-constant variance g(xi)/τ. Three values are considered for τ: 10, 5, and 1. Hereafter, we refer to these three case studies as CS2 (τ=10), CS3 (τ=5), and CS4 (τ=1) respectively. The smaller the τ, the greater the noise variance. So, the level of uncertainty in the data samples of CS4 is higher than the level of uncertainty in the data samples of CS2 and CS3.Data sets for case study 5 (CS5) and 6 (CS6) come from a real-world baggage handling system. The time required for processing of bags is affected by several controllable and uncontrollable events occurring during the operation of the baggage handling system. There is a high level of uncertainty associated with travel times of bags through the system. Targets in CS5 and CS6 are the required time to process 70% and 90% of bags for each flight respectively. The check-in gates and exit points are used as the independent variables to predict targets in these two case studies.Data for the last case study, case study 7 (CS7), comes from an industrial dryer [28]. The underlying target is the moisture content of raw material. The purpose is to estimate this target using fuel flow rate, hot gas exhaust fan speed, and flow rate of raw material. Again accurate forecasting is problematic due to a high level of uncertainty in data.The characteristics of all case study datasets are outlined in Table 1and cited references. All data sets are available from the authors on request.The available samples in each case study are first split into training set, Dtrain, and test set, Dtest. These account for 80% and 20% of samples, respectively. In all case studies, all data points are preprocessed to have a zero mean and unit variance. The IT2 TSK FLS is first trained using training samples, where the fitness function (CWC) is minimized using the simulated annealing (SA) method [33]. Then, the quality of PIs constructed for the test set is quantitatively examined. To avoid misleading results and subjective judgment, experiments are repeated ten times for each case study and average results are reported.Table 2summarizes parameters used for implementing the proposed method and conducting experiments. PIs are constructed with three confidence levels: 70% (α=0.3), 80% (α=0.2), and 90% (α=0.1). μ is set to 1−α, because the prescribed level of confidence of PIs is (1−α)%. Also, η is selected to be 50 in order to highly penalize PIs when PICP<90%. SA uses a geometric cooling schedule with a cooling factor of 0.9. Also, the initial temperature is set to 10 to allow for uphill movements and to avoid getting trapped in local minima.Each input domain of IT2 TSK FLS is partitioned by three Gaussian MFs with a constant mean and two uncertain standard deviations,(17)μF˜il(xi,k)=exp−12xi,k−milσil2=N(mil,[σi,1l,σi,2l])where i=1, …, p, l=1, …, M, and k indicates the sample index. The uncertain standard deviation helps to capture the non-stationary behavior of the targets.The delta [34] and Bayesian [35] methods are also implemented here for comparison purposes. In the delta method, a NN model is first linearized around its optimal set of parameters (a first order Taylor expansion), then PIs are constructed based on asymptotic theories of linear regression. The Bayesian technique is based on Bayesian statistics and has a strong mathematical foundation [35,36]. Previous studies show that these are of the best methods for construction of PIs when there is a high level of uncertainty in data or operation of complex systems [34,37–39,31,40].The number of neurons in the hidden layer of single layer NNs is determined using a five-fold cross validation technique. The maximum number of neurons is fixed such that the number of parameters of the biggest NN is slightly greater than the number of corresponding IT2 TSK FLS model. This ensures that different model types have an equal flexibility and freedom for construction of PIs.For ease in notation, the following abbreviations will be used when demonstrating and reporting results: ‘D’ for the delta method, ‘Bays’ for the Bayesian method, and ‘FLS’ for the IT2 TSK FLS method for PI construction.Fig. 2shows the cost function versus the iteration number for the first replicate of CS1 with a CL of 70%. In the early iterations when the cooling temperature is large, the SA method allows for uphill movements. So, there are several solutions resulting in the increment of CWC. As the optimization process continues, these transitions gradually vanish and the SA method becomes greedy. During these iterations, SA continuously decreases and converges to its global minimum. The optimization process terminates when no further improvement is achieved for several iterations. It is important to notice that there is a huge difference between the initial and final values of the cost function. This is due to the fact that the initial PIs have a PICP much lower than the nominal confidence level. This results in an astronomical CWC value. During the optimization, the quality of PIs is significantly improved and their coverage probability moves towards the confidence level. So, the cost function continuously falls. Upon the termination of the optimization process, PICPtrainis greater than 70% and CWC is equal to PINAW.Fig. 3displays how the shape of the second MF in replicate one of CS2 varies during the training procedure. MFs corresponding to the early iterations of the training algorithm are light-shaded. The dark-shaded MFs correspond to the final iterations of the training process. As the three parameters of this MF are optimally adjusted, its center moves to the left and right and its footprint of uncertainty becomes bigger or smaller. The final value of the MF center is on the right-side of its initial value and the footprint of uncertainty is narrower than its original shape.PICPFLS/D/Bays,70%, PICPFLS/D/Bays,80%, and PICPFLS/D/Bays,70% are displayed in Figs. 4–6for seven case studies. In each figure, the top plot corresponds to the PICP values obtained by FLS models, the middle plot shows PICP values generated by the delta method, and the bottom plot demonstrates PICP values of Bayesian-based PIs. Also, the confidence levels are shown with a dashed line in each figure. With the exception of a few rare cases, PICPFLSin all three figures are greater than the nominal confidence level, yet close to it. This indicates that the PIFLShave an acceptable coverage probability which is highly correlated with the associated confidence level. For the case of the delta method, there are more instances where the PICP is not satisfactory and the PICP values fall below the drawn dashed line. This issue is more serious for the first case study with a confidence level of 70% and 80%. For almost all case studies and for all three confidence levels, the PICPBaysdoes not oscillate much and is always well above the nominal confidence level. This is an indication of the fact that the quality of PIs is not much affected by the level of confidence.The bar chart in Fig. 7plots the percentage of valid PIs constructed using three methods for three confidence levels. The values are calculated by adding up the number of replicates where PICP≥(1−α)% and then dividing it by the total number of case study replicates (70), i.e., [#(PICP≥(1−α%))]/70. According to this figure, PIFLSare valid in most cases with a success rate even greater than the traditional NN-based PI construction methods. For the case of PIBays, the validity percentage is 100% for the first two confidence levels, as PICP is constant and always greater than the nominal confidence level. However, we will show that a huge cost has to be paid to achieve this. It is important to mention here that Fig. 7 is only an indicative bar chart that has been generated for comparative studies. It is used here to show that the proposed method has a very similar and even better performance than traditional methods in generating valid PIs with different confidence levels.Figs. 8–13display the box plots of CWCFLS, CWCD, and CWCBaysfor ten replicates of seven case studies. Each box plot shows the values for the upper quartile (75th percentile), the lower quartile (25th percentile), the median, and the minimum and maximum values of CWC. With the purpose of a similar visualization, all y-axis upper limits have been readjusted to 140. Also, Table 3summarizes the median values of CWCD,70/80/90%, CWCBays,70/80/90%, and CWCFLS,70/80/90% for test samples of seven case studies.Before going further, we would like to highlight the following points:•A long inter quartile range (IQR) is an indication of the inability of a method to generate consistent results. This means that the performance of the method is too sensitive to the experiment parameters and the way experiments are run, e.g., initialization process.If PICP≥(1−α)%, then CWC=PINAW. So, valid PIs can be objectively analyzed and compared based on the CWC values.If any quartile of CWC is greater than 100%, it means that the corresponding PICP is unsatisfactorily low (less than the nominal confidence level), constructed PIs are too wide, or both. In either case, the quality of constructed PIs is poor.The smaller the CWC quartile, the better the quality of the corresponding PIs. Of particular interest is the median of CWC values in ten replicates of each experiment. It will be used as the main tool for analyzing results and driving conclusions. Discussion based on the mean value of CWC could be misleading, as CWC values are occasionally too large (due to not satisfying the coverage probability requirements).The higher the confidence level, the wider the PIs. So, it is expected for each case study, we should have CWCMed,90%≥CWCMed,80%≥CWCMed,70%, where ‘Med’ stands for median.For all case studies, we have median(CWCFLS,70%)≤median(CWCFLS,80%)≤median(CWCFLS,90%). This rational result is not maintained by the other two methods in all cases. For instance, median(CWCCS2,D,80%)≤median(CWCCS2,D,90%)≤median(CWCCS2,D,70%) and median(CWCCS5,Bays,80%)≤median(CWCCS5,Bays,70%)≤median(CWCCS5,Bays,90%). These observations indicate that while PIFLSbecome wider as the confidence level increases, PIDand PIBaysshow less consistent behavior. The consistency of FLS-based PIs is due to the fact that IT2 TSK FLS models are directly trained through minimization of a PI-based cost function. For the case of PIDand PIBays, NN models are trained through minimization of error-related cost functions. As the confidence level is not directly used in the training process of these models, consistent results are not guaranteed (Fig. 14).The median values of CWCFLS,70/80/90% are smaller than their corresponding median values of both CWCD,70/80/90% and CWCBays,70/80/90% in 13 out of 21 cases. The difference between the median values is larger in particular for the synthetic case studies with a homogeneous and heterogeneous noise. There are also 6 cases that the median values of CWCFLS,70/80/90% are very close to or even smaller than the CWC median values of one of the other two methods. There are only two cases (CWCCS5,90% and CWCCS7,90%) where the median values of CWCFLSare greater than the median values of CWCDand CWCBays. These figures indicate that in more than 90% of cases, the performance of the proposed method is equal (28%) or better (62%) than traditional methods for construction of prediction intervals.It is also important to notice that the median value of CWCFLSis always smaller than 100. In contrast, there are several cases where the median values of CWCDand CWCBaysare significantly greater than 100. This is more evident for CS1–CS4, where both the delta and Bayesian methods struggle to generate valid PIs. Both methods widen PIs to satisfy the confidence level requirement, which in turn results in less informative PIs. In some cases, even making PIs wider is not satisfactory and constructed PIs are not reliable due to a PICP less than the nominal confidence level. As mentioned before, these issues ruin the quality of constructed PIs and make them either theoretically invalid (PICP≤(1−α)%) or practically uninformative (too wide).The IQR of CWCBaysis the smallest amongst three methods. This is an indication of the ability of this method to generate similar results, although this comes with the huge cost of excessively wide PIs. CWCFLSalso have a small IQR in the majority of the investigated case studies. There are some rare cases, such as CWCCS5,FLS,70% or CWCCS7,FLS,70%, where the IQR is surprisingly longer than other cases. In all these cases, the gap between the median and the upper quartile is large and the median is very close to the lower quartile. According to this, we can conclude that these are rare cases and their appearance is mainly attributable to the SA method used for training of IT2 TSK FLS models. For the case of the delta method, the IQRs are the longest for synthetic case studies. This indicates that this method is more sensitive to the initialization procedure and shows a less consistent performance in the presence of homogeneous and heterogeneous noise in the data.These results indicate that the IT2 TSK FLS models trained using the proposed method can generate valid PIs that can successfully cover all numerical uncertainties present in data. A key advantage of the proposed method is that PIs are constructed in just one stage. Traditional PI construction methods such as the delta and Bayesian methods require firstly estimation of targets, and secondly calculation of some complex derivatives to construct PIs. In the proposed method here, PIs are constructed in the same way that IT2 TSK FLS models are used for target estimation, without requiring the defuzzifier stage.

@&#CONCLUSIONS@&#
