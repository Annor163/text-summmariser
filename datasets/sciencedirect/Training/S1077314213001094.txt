@&#MAIN-TITLE@&#
Head direction estimation from low resolution images with scene adaptation

@&#HIGHLIGHTS@&#
A head pose estimation method that adapts to individual scenes is proposed.The method automatically collects training dataset for head pose estimators.The method handle appearance differences within the same scene.The method demonstrate high performance without manually collected training data.

@&#KEYPHRASES@&#
Head direction estimation,Low resolution image,Appearance-based approach,Scene adaptation,Graph-based image segmentation,Unsupervised learning,

@&#ABSTRACT@&#
This paper presents an appearance-based method for estimating head direction that automatically adapts to individual scenes. Appearance-based estimation methods usually require a ground-truth dataset taken from a scene that is similar to test video sequences. However, it is almost impossible to acquire many manually labeled head images for each scene. We introduce an approach that automatically aggregates labeled head images by inferring head direction labels from walking direction. Furthermore, in order to deal with large variations that occur in head appearance even within the same scene, we introduce an approach that segments a scene into multiple regions according to the similarity of head appearances. Experimental results demonstrate that our proposed method achieved higher accuracy in head direction estimation than conventional approaches that use a scene-independent generic dataset.

@&#INTRODUCTION@&#
Estimating the human visual focus of attention has recently become a popular research trend, as such research has numerous applications in our daily life. For example, it can be used to estimate the attention of people walking along the street [1,2]. Having attention information enables us to easily infer interaction between people and to consequently analyze human interaction or identify on-going activities without requiring any human assistance [3,4]. Head direction is known to be an important factor in inferring the focus of attention of humans. Therefore, techniques for estimating head direction are considered important and have attracted great interest recently.Various image-based approaches have been proposed for estimating eye gaze. However, most of them1We refer readers to [5] for a recent survey on approaches to head pose estimation.1require high resolution images [6,7] or special equipment such as depth cameras [8,9] or actively controlled pan-tilt-zoom cameras [10]. Hence, one of the major remaining technical challenges is how to estimate human gaze or head direction with low resolution images. In some application scenarios such as visual surveillance, the head regions in input images are often quite small. Small images contain limited information; accurately estimating head direction in such cases remains a challenging task.The use of appearance-based approaches is thought to be promising for estimating head directions from low resolution images. Compared with model-based methods such as active appearance models [11,12], which rely on geometric facial models and require localization of facial elements, appearance-based methods directly use pixel values of an image as an input to extract image features and are known to be effective even with low resolution images.Appearance-based head direction estimation approaches rely heavily on a dataset used for training estimators. This is due to the fact that head appearances can change significantly from scene to scene. Even in the same scene, there could be substantial differences in head appearance due to extreme differences in illumination or camera viewing angle. Therefore, a training dataset is best taken from the same location as the target data. However, collecting ground-truth training samples is a labor-intensive and time-consuming task, and it is prohibitively expensive to collect ground-truth data manually every time a head direction estimation method is applied to different scenes.We propose an appearance-based head direction estimation method in order to overcome these problems. Our method is based on two key ideas: automatically acquiring a training image dataset with ground-truth head directions and segmenting a scene into multiple regions with similar head appearances. We first construct a training image dataset by tracking pedestrians in a scene of interest to capture head images where their walking directions are regarded as a ground truth head orientation. To address the problem of appearance differences within a scene, the scene is segmented into multiple regions based on the similarity of head appearances, and a head direction estimator is then trained for each region. This approach enables us to test each head image with the estimator trained with data taken from the same region. Higher accuracy can thus be expected because the data used to train the estimator have a similar appearance to the test data.This paper is organized as follows. Section 2 describes related works on head direction estimation from low resolution images. Section 3 explains the details of our proposed framework. Section 4 describes the method to automatically acquire a scene-specific dataset. Section 5 introduces an adaptive scene segmentation method that solves the problem of appearance differences within a scene. We describe detailed experiments and a thorough analysis of the proposed method in Section 6, and we conclude the paper in Section 7.

@&#CONCLUSIONS@&#
