@&#MAIN-TITLE@&#
Situated incremental natural language understanding using Markov Logic Networks

@&#HIGHLIGHTS@&#
We use situation, discourse, words, linguistics to infer interpretation.We use Markov Logic Networks to jointly use information sources.We show that our model works well with speech and hand-annotated data.We offer some interesting analysis of the model and how it works incrementally.

@&#KEYPHRASES@&#
Incremental,Situated,Natural language understanding,Dialog systems,Markov Logic Networks,

@&#ABSTRACT@&#
We present work on understanding natural language in a situated domain in an incremental, word-by-word fashion. We explore a set of models specified as Markov Logic Networks and show that a model that has access to information about the visual context during an utterance, its discourse context, the words of the utterance, as well as the linguistic structure of the utterance performs best and is robust to noisy speech input. We explore the incremental properties of the models and offer some analysis. We conclude that mlns provide a promising framework for specifying such models in a general, possibly domain-independent way.

@&#INTRODUCTION@&#
Spoken conversation is situated in time and space. Speech by necessity unfolds sequentially in time; and in a conversation, all speech but that of the opening utterance is preceded by other speech belonging to the same conversation. In many, if not most, conversational situations, speaker and addressee are co-located in space and their speech may refer to their shared situation. Most current spoken dialogue systems attempt to abstract from this fact, however. They work in domains where physical co-location is not necessary, such as information look-up, and they quantize time into discrete turn units by endpointing utterances (see discussion in Aist et al., 2007; Schlangen and Skantze, 2009).In this paper we present our current work on overcoming this abstraction for the task of natural language understanding (nlu).22This paper follows from and extends Kennington and Schlangen (2012).We have created a statistical model that can be trained on conversational data and which can be used as an nlu module for an incremental, situated dialogue system (such as that described in Buß et al., 2010a). We show that this model outperforms baseline approaches by a wide margin, and that making available the full set of information comprising visual context, discourse context, words of the utterance, and linguistic structure gives significantly better results than when one of those information sources is ignored. We further show promising results from noisier input, as coming out of an automatic speech recogniser (asr).The paper is structured as follows: we first discuss related work and introduce some background, then describe in detail our set of experiments, and present and analyse our results, including some analysis of our model. We close with a general discussion of this work and possible future extensions.In this section, we will briefly introduce statistical nlu. We explain that the nlu we focus on is situated and incremental, and give a notion of what “good” incremental nlu is. This section then finishes with a very brief overview of Markov Logic Networks (mln), the particular machine learning approach we use in this paper.An important part of a dialogue system is the nlu component. This component is the point where input from any modality (asr, visual context, gestures, etc.) is combined and used to infer the meaning of an utterance and the intent of the speaker. One popular approach to representing meanings and intentions is to use semantic frames (inspired by Fillmore and Baker, 2001), and we follow this tradition here. A frame is an attribute-value matrix where the attributes classify aspects of the overall meaning, and their values the concrete instantiations of these aspects. An example frame is given in Fig. 1.Traditional statistical nlu (snlu) focuses on predicting a meaning representation (slot attributes), where the intention (slot values) are words as extracted directly from the utterance. snlu has often been treated as a simple tagging task; specifically concept tagging, where the concept tags that are predicted become the slot attributes. Meurs et al. (2008) apply mln as a way to predict the concept tag sequence. Their more recent work, Meurs et al. (2009), applies dynamic Bayesian networks (dbn). Hahn et al. (2008) compared various machine-learning techniques used for concept tagging; namely, log-linear models, stochastic finite state transducers, conditional random fields, support vector machines, as well as an approach taken from machine translation. This comparison was more recently extended into multiple languages in Hahn et al. (2011), which also compared dbns.Other approaches to slu that do not use frames as a meaning representation also exist; Zettlemoyer and Collins (2007) and Zettlemoyer and Collins (2009) used a semantic representation to infer a meaning, Liang et al. (2011) created dependency-based compositional semantics, and Huang and Er (2010) made use of neural networks as a meaning representation. All of these approaches stop at predicting a meaning representation; they do not infer a user intention that is represented by anything beyond the words of the utterance, that is, they do not ground these representations in their context of use.Our approach to snlu differs from previous approaches in that we work in a situated domain and cannot make the assumption that the slot fillers are sufficiently specified by the words of the utterance (in the way that the city New York may be by the words “New York”). For example, if an object in a shared context is referred, it is not enough to fill a slot with the words that contributed to that object description (i.e., the red ball on the left); what's required is to actually resolve the object, that is, identify it from other objects (i.e., by an identifier object5). Fig. 1 represents a frame where the argument slot represents an inferred entity rather than extracted words. In order to effectively resolve this kind of object in a visual space, information from various sources need to be incorporated, which is another difference in our work to that of previous snlu work; predicting a speaker intention (i.e., a referred object) requires some level of grounding where the utterance and visual world are somehow connected (as in Roy, 2005). For example, an effective model would learn that the word red would give more credence to an rgb value that represents the color red, rather than green. These kinds of object descriptions are sufficiently complex such that they require incorporating linguistic information to some degree (also often ignored), and many references are resolved using pronouns, something which requires incorporation of previous discourse context, which is also often unnecessary in snlu. This paper represents work that incorporates visual, linguistic, and context information to infer a speaker intention, represented as slot values, as in Fig. 2.Dialogue systems that process input incrementally produce behavior that is perceived by human users to be more natural than systems that end-point on larger sentence-length segments or use a turn-based approach (see Aist et al., 2006; Skantze and Schlangen, 2009; Buß et al., 2010b; Skantze and Hjalmarsson, 2010). There have been many recent advancements in incremental dialogue in various areas such as speech recognition (Baumann et al., 2009), speech synthesis (Buschmeier et al., 2012), and dialogue management (Buß and Schlangen, 2011; Selfridge et al., 2012). Furthermore, architectures for incremental dialogue systems have been proposed (Schlangen and Skantze, 2009), and various incremental toolkits are available like InproTK (which we use in this paper) (Baumann and Schlangen, 2012).33http://sourceforge.net/projects/inprotk.If nlu is concerned with filling a frame, then incremental nlu (inlu), attempts to fill as much of the frame as it can, as early as possible, contingent upon the incremental input of the ongoing utterance. This is important in dialogue systems that are responsive and work better in real-time. Fig. 3shows how an utterance, rotate the gray piece below the yellow piece clockwise, incrementally fills the slots, where the utterance has reference to the shared visual context in Fig. 4. By the time the word piece in step 4 is uttered, it interprets the argument as the object identifiers of the gray pieces on the board, distinguishing them from the non-gray pieces as the possibly referred objects. As the utterance continues, one gray piece is singled out as the referred object (the object in A:4), which is an example of the task of reference resolution.There are various ways to approach inlu. We follow the view given by Heintze et al. (2010) that inlu has a continuum with two end points, where on one extreme the input into the nlu component is incremental and the output is also incremental (which we will denote as fully incremental), meaning slots are only predicted when there is sufficient input to contribute to that slot. On the other extreme, the input is incremental, but a full frame is always predicted and so the output of nlu is not incremental (which we will denote as predictive). Fig. 5illustrates the two extremes: fully incremental is represented on the top; the predictive, full frame output extreme is on the bottom for the utterance rotate the gray stairs clockwise. Slots that have bold-faced values denote a change in the prediction for that slot. Note that a predicted value can change at each increment, even if it was correct at an earlier step.Arguably, an ideal incremental system would follow the fully incremental strategy, where a meaning hypothesis is incremented in lockstep with incremental recognition of the utterance, and links between the words of the utterance and their contribution to the utterance meaning would be recorded. There are ways, however, to move the technically more straightforward prediction approach where possibly incomplete utterances (or utterance prefixes) are classified more towards that ideal. DeVault et al. (2009) use a second classifier to determine when to trust the (full frame) prediction of the first one, and so deal to an extent with the problem of instability of early hypotheses. Another approach, discussed in Heintze et al. (2010) and followed here as well is to predict the frame elements separately (but constrained by global considerations), allowing for an additional unknown class. This has the effect of letting the frame ‘grow’ incrementally, even if no direct link between words and parts of the semantic representation is kept.In summary, our approach in this paper differs from previous nlu approaches in that the model we work with is incremental, can use linguistic structure, and learns from conversational data a semantics that connects the utterance to its visual and discourse context. We have looked at individual components of this before (grounded semantics in Siebert and Schlangen, 2008; incremental reference resolution in Schlangen et al., 2009; incremental general nlu in Heintze et al., 2010; interaction between incremental parsing and reference resolution in Peldszus et al., 2012), but use a more sophisticated model in this work and show that tackling these tasks jointly improves performance. Furthermore, previous contributions to inlu (such as DeVault et al., 2009, 2011; Aist et al., 2007; Schlangen and Skantze, 2009) have not dealt with learned grounded semantics.We apply Markov Logic Networks (mln; Richardson and Domingos, 2006) as the machine learning technique in our experiments. mlns have recently received attention in language processing fields like co-reference resolution, Chen (2009), semantic role labeling, Meza-Ruiz and Riedel (2009), spoken (albeit neither situational nor incremental) nlu, Meurs et al. (2008), and web information extraction, Satpal et al. (2011).Markov Logic is a statistical relational learning language based on First Order Logic (fol) and Markov Networks. Markov Logic can extend fol to allow formulae to be weighted rather than be strictly true or false; that is, a fol formula can be violated with a penalty.44We follow the succinct presentation of Meza-Ruiz and Riedel (2009) here.From another viewpoint, Markov Logic is an expressive template language that uses fol formulae to instantiate Markov Networks of repetitive structure. A mln, then, is a set of these weighted fol formulae. Formally, a mlnM is a set of pairs (ϕ, ω) where ϕ is a first order formula and ω a real weight. M assigns the probability given in (1) to a possible world y.(1)p(y)=1Zexp∑(ϕ,ω)∈Mω∑c∈Cϕfcϕ(y)Cϕis the set of all possible bindings of the free variables in ϕ with the constants of the given domain.fcϕis a feature function that returns 1 if in the possible world y the ground formula we get by replacing the free variables in ϕ by the constants in c is true, and 0 otherwise. Z is a normalization constant. Thus, the mln framework offers a convenient way of specifying factor functions on sets of random variables for undirected graphical models in such a way that the factors correspond to the weighted, grounded fol formulae.We apply mln here by specifying our models using fol formulae (see below) such that the grounding of constants that takes place in the mln learning and inference steps corresponds to grounding language with the visual world. The model we specify equates to using a single log-linear classifier for each slot that is to be predicted.

@&#CONCLUSIONS@&#
Markov Logic Networks are effective in expressing models for situated incremental natural language understanding in a domain like Pentomino. We have shown that various aspects of situated dialogue like previous context and the current state of the world all play a role in nlu. mlns are very well suited to grounding of language to a visual context, can act robustly to noisy input, and can implicitly learn how to handle spatial language and pronoun resolution to a certain extent. However, there is a trade-off in that mlns take some time to design, which still is an intellectual task. Furthermore, inference in mlns is still not as efficient as other methods in terms of speed, which can cause a slowdown in applications where very many inference steps are required, like inlu.For future work, we will look at other ways of modeling the situation that provide more efficiency in terms of speed, but retain some of the expressiveness found in mln. Our focus will be on interactive systems that use real-time asr data, as well as other modalities.