@&#MAIN-TITLE@&#
On the use of supervised features for unsupervised image categorization: An evaluation

@&#HIGHLIGHTS@&#
We compared high- and low-level features for unsupervised image categorization.We verified that high-level features significantly outperform low-level features.We assessed how much the performance depends on the dimensionality of the feature vectors.We verified that a simple clustering on supervised features outperform strategies specifically designed for this task.

@&#KEYPHRASES@&#
Unsupervised image categorization,Supervised features,Primitive features,Image clustering,

@&#ABSTRACT@&#
Recently, new high-level features have been proposed to describe the semantic content of images. These features, that we call supervised, are obtained by exploiting the information provided by an additional set of labeled images. Supervised features were successfully used in the context of image classification and retrieval, where they showed excellent results. In this paper, we will demonstrate that they can be effectively used also for unsupervised image categorization, that is, for grouping semantically similar images. We have experimented different state-of-the-art clustering algorithms on various standard data sets commonly used for supervised image classification evaluations. We have compared the results obtained by using four supervised features (namely, classemes, prosemantic features, object bank, and a feature obtained from a Canonical Correlation Analysis) against those obtained by using low-level features. The results show that supervised features exhibit a remarkable expressiveness which allows to effectively group images into the categories defined by the data sets’ authors.

@&#INTRODUCTION@&#
Unsupervised categorization, often done through the use of clustering algorithms, is one of the most powerful techniques available to the designer of image management systems, as it allows categorization with no other information than that contained in the data themselves. Grouping images into semantically homogeneous classes is often a sine qua non for efficiently processing, structuring, querying, and browsing large collections of images. For instance, representative images can be extracted from each class to stand for the collection contents [1]; grouping similar images can also be useful for the design of effective user interfaces for browsing and visualization of image collections; image categories may be used to speed up database queries by pre-filtering the images to be searched [2], and so on. Alas, unsupervised categorization is also a very difficult problem. Without the information provided by class labels it is very difficult to obtain a reliable classification in semantically meaningful classes, and the performance of unsupervised classification is often nowhere near that of supervised methods. On the other hand, in applications one often faces the problem of categorizing a large, unstructured set of images not only without labeled training sets but, often, without a priori knowledge of the classes that are present in the collection.Several authors have begun exploring features that, in addition to the image data, use semantic information in the guise of a set of labeled images belonging to a collection of pre-defined classes. These classes are not, in general, the same that we are interested in identifying in an unsupervised way, and the related labeled images come from a data set different from that which we are interested in classifying. In this paper we will consider specifically the work of Torresani et al. [3], Ciocca et al. [4], Li et al. [5] and Gordo et al. [6]. We shall refer to the features used in these papers as supervised, in a sense that will be clarified in the next section.The purpose of this paper is to evaluate the performance of supervised features for unsupervised image categorization. First of all we verified if these features bring a significant improvement with respect to low-level features (which we shall call primitive). To this end we selected four data sets of different nature and four state-of-the-art clustering algorithms, and we compared the performance obtained by using supervised features with those obtained by using primitive features. We also verified how much the clustering performance depends on the dimensionality of the feature vectors. Finally, we determined whether the combination of a simple clustering algorithm and supervised features could outperform other strategies, specifically designed for unsupervised image categorization. With these experiments we try to identify strengths and weaknesses of the different supervised features in dealing with different type of images.In the last years, a huge amount of work and resources have been devoted to the evaluation of algorithms and systems for the supervised classification of images. This effort led to the collection of standard data sets and to the definition of experimental protocols culminating with the organization of public contests and challenges. The same cannot be told for the problem of unsupervised categorization. In this context, even though the focus of this paper is the evaluation of supervised features, we believe that it could also serve as a useful source of information about the performance of low-level state-of-the-art features.The paper is organized as follows: Section 2 provides the definition of primitive and supervised features; presents a brief review of state-of-the-art high-level descriptors; and details the features included in the evaluation. Section 3 describes the four clustering algorithms considered. The experiments, including the performance measure, the data sets, and the results are reported in Section 4 and discussed in Section 5. Finally, Section 6 concludes the paper.

@&#CONCLUSIONS@&#
In this paper we addressed the problem of unsupervised image categorization by using supervised features. The features we considered are derived from multiple image classifiers or object detectors trained to identify a set of semantic categories. Their capability of capturing the semantic content of the images make it possible to use standard clustering algorithm to automatically partition image collections into meaningful categories. This is demonstrated by our experiments where these features allowed to identify the ground truth categories in several data sets of variable difficulty.On the basis of the results obtained we can conclude that supervised features are able to dynamically characterize new, unseen, categories which are quite different from those used to build them. So far, supervised features have been heuristically defined. In our future work we will take advantage of the insights provided by the results obtained here in order to address some open issues. In particular, we will investigate how to identify the categories that should be used for a specific task; how much the performance depends on the similarity between these and the target categories; and how many categories are required to obtain good results.In this appendix we report the classification rates obtained on two additional data sets. These data sets have been chosen to verify the limitation of supervised features. Since these features have been defined on labeled images depicting objects and/or scenes, it is possible that their descriptive power is severely reduced for other kinds of images. In particular we considered a data set of textures and one of aerial images.This data set consists of 4752 images collected by capturing 44 samples of 11 different categories (see Fig. A.15). Each sample has been captured 108 times at different scales and under different illumination conditions [61]. Table A.13reports the classification rates obtained on this data set. It is not surprising that on this data set the gap between the performance of supervised and primitive features is quite small. Still, supervised features obtained the best results.This is a 21 class land use image data set [62]. There are 100 images for each of the following classes: agricultural, airplane, baseball diamond, beach, buildings, chaparral, dense residential, forest, freeway, golf course, harbor, intersection, medium residential, mobile homepark, overpass, parking lot, river, runway, sparse residential, storage tanks, tennis court (see Fig. A.16). Table A.14reports the classification rates obtained on this data set. On this data set the best performance have been obtained by using the Fisher Vectors. The other primitive features obtained classification rates slightly below those of the supervised ones.The conditional entropy is an alternative to the classification rate for the evaluation of unsupervised categorization [7]. For a joint distribution P overX×Yit is defined as:(B.1)H(Y|X)=∑x∈X∑y∈YP(x,y)log21P(y|x).LetNijbe the number of images of category i that have been placed in the cluster j, then the conditional entropy can be estimated as follows:(B.2)H=1∑i∑jNij∑i∑jNijlog2∑kNkjNij.The conditional entropy is measured in bits. Tables A.15,A.16,A.17reports the conditional entropies obtained on the Simplicity, scene recognition, and event data sets.