@&#MAIN-TITLE@&#
Using Choquet integral as preference model in interactive evolutionary multiobjective optimization

@&#HIGHLIGHTS@&#
The Choquet integral is used for the first time in multiobjective evolutionary optimization.The interactive procedure involves preference information in terms of pairwise comparisons.The method starts from simple linear value function and switches to the Choquet integral only if necessary.Results on several test problems show the effectiveness of the method in comparison with its competitors.

@&#KEYPHRASES@&#
Multiobjective optimization,Evolutionary algorithms,Interaction between criteria,Choquet integral,

@&#ABSTRACT@&#
We propose an interactive multiobjective evolutionary algorithm that attempts to discover the most preferred part of the Pareto-optimal set. Preference information is elicited by asking the user to compare some solutions pairwise. This information is then used to curb the set of compatible user’s value functions, and the multiobjective evolutionary algorithm is run to simultaneously search for all solutions that could potentially be the most preferred. Compared to previous similar approaches, we implement a much more efficient way of determining potentially preferred solutions, that is, solutions that are best for at least one value function compatible with the preference information provided by the decision maker. For the first time in the context of evolutionary computation, we apply the Choquet integral as a user’s preference model, allowing us to capture interactions between objectives. As there is a trade-off between the flexibility of the value function model and the complexity of learning a faithful model of user’s preferences, we propose to start the interactive process with a simple linear model but then to switch to the Choquet integral as soon as the preference information can no longer be represented using the linear model. An experimental analysis demonstrates the effectiveness of the approach.

@&#INTRODUCTION@&#
Multiobjective optimization involves several conflicting objectives that compete for the best solution in a constrained multidimensional space of decision variables. In general, there is no single optimal solution (as in single-objective optimization), but a set of alternatives for which it is not possible to improve one objective without deteriorating another one, called Pareto-optimal solutions. Despite the existence of multiple Pareto-optimal solutions, in practice, usually only one of these solutions is to be chosen. Thus, in multiobjective optimization, there are two equally important tasks: an optimization task for finding Pareto-optimal solutions by a search procedure, and a decision aiding task for recommending a single most preferred solution. The “most preferred” refers to the value system of a particular user, also called decision maker (DM). Thus, decision aiding necessitates some preference elicitation from the user.As to procedures searching for Pareto-optimal solutions, in the last two decades we have been able to observe a growing popularity of algorithms adopting the principles of natural evolution. A distinguishing feature of these evolutionary algorithms is that they work with a population of solutions. This is of particular advantage in the case of multiobjective optimization, as they can search for several Pareto-optimal solutions simultaneously in one run, providing the user with a set of feasible solutions to choose from. In the early stage of development of evolutionary algorithms for multiobjective optimization, the efforts were focused on efficient generation of the whole set of Pareto-optimal solutions (or of a good approximation thereof), leaving the decision aiding task to the post-optimization stage. Later, researchers started interlacing the optimization and preference handling in interactive procedures, which allows to converge more quickly to the most preferred region of the Pareto-optimal front (Branke, Deb, Miettinen, & Słowiński, 2008).Most interactive procedures for multiobjective evolutionary optimization assume a particular mathematical model of user’s preferences. This model drives the search procedure towards the most preferred Pareto-optimal solutions. The model building involves preference information supplied by the user. In case of simple preference models, one may expect that the user can provide directly the values of model parameters. However, simple models, like the weighted sum of objectives, fail to represent more subtle user’s preferences (see Section 4). For this reason, there is a tendency to use more complex preference models built from indirect preference information which is much easier to elicit by the user than the direct preference information. In many previous studies on interactive multiobjective optimization, the indirect preference information had the form of pairwise comparisons of some solutions from a current population (Branke, Greco, Słowiński, & Zielniewicz, 2010; 2015; Greenwood, Hu, & D’Ambrosio, 1997; Phelps & Köksalan, 2003). In particular, the NEMO-I11NEMO: Necessary preference enhanced Evolutionary Multiobjective Optimizer.method (Branke et al., 2010) is defining a set of value functions compatible with the preferences elicited from the DM, expressed in terms of pairwise comparisons of solutions. These compatible value functions are used in Robust Ordinal Regression (ROR) (Corrente, Greco, Kadziński, & Słowiński, 2013; Greco, Mousseau, & Słowiński, 2008) to build a necessary preference relation (≿N) on the current population of solutions. More precisely, a≿Nb if a is at least as good as b for all compatible value functions. NEMO-I is adopting the scheme of NSGA-II (Deb, Agrawal, Pratap, & Meyarivan, 2000), however substituting the dominance relation by the necessary preference relation in the ranking. While NEMO-I has shown a satisfactory convergence to the best compromise solution, the calculation of the necessary preference relation requires a considerable computational effort. Therefore, in this paper, we are using an alternative method called NEMO-II, which overcomes the problem of prohibitive computational effort. NEMO-II accepts any type of value function. We are considering four types of value functions within NEMO-II: linear, additive piecewise-linear, general additive, and (for the first time in combination with evolutionary multiobjective algorithms) the Choquet integral (Choquet, 1954; Grabisch, 1996).The paper is organized as follows. In Section 2, we review interactive evolutionary multiobjective algorithms (MOEAs). Then, in Section 3, we present the general scheme of NEMO-II. Further, in Section 4, we describe the four above mentioned value functions. The new procedure, called NEMO-II-Ch, is introduced in Section 5. A computational experiment with the proposed procedure and its main competitors on a set of benchmark problems is presented in Section 6. Section 7 summarizes our conclusions and suggests avenues for future research.Evolutionary multiobjective optimization (EMO) has become very popular because of its ability to generate a set of non-dominated solutions in one run, from which the DM can choose a favorite solution without eliciting any preference information a priori. Nonetheless, in recent years, there has been a growing interest in EMO algorithms that are able to take into account user’s preference information in the search process. This is motivated by the following expected advantages.1.Instead of a diverse set of solutions (many of them clearly irrelevant to the DM) a search based on the DM’s partial preferences will provide a more suitable sample of all Pareto-optimal solutions. It could either be a smaller set of only the most relevant solutions, or a more fine-grained resolution of the relevant parts of the Pareto frontier.By focusing the search onto the relevant part of the search space, one may expect the optimization algorithm to find these solutions more quickly.As the number of objectives increases, it becomes more and more difficult to identify and represent the complete Pareto-optimal frontier. This is partly because of the increasing number of Pareto-optimal solutions, but also because with an increasing number of objectives almost all solutions in the population become non-dominated, rendering dominance as selection criterion useless. User’s preference information allows re-introducing the necessary selection pressure.The literature contains today quite a few techniques that allow the incorporation of full or partial preference information into MOEAs, and previous surveys on this topic include Branke (2008), Branke (2015, chap. 22), Coello (2000), Coello, Veldhuizen, and Lamont (2002) and Rachmawati and Srinivasan (2006).Many of the techniques integrate partial user’s preferences a priori, e.g., by allowing the DM to specify a reference point (Fonseca & Fleming, 1993; Jaimes, Montano, & Coello, 2011; Said, Bechikh, & Ghedira, 2010), maximal and minimal trade-offs (Branke, Kaußler, & Schmeck, 2001), or desirability functions (Wagner & Trautmann, 2010). In the following, we focus on the literature that is most related to our paper, namely interactive approaches that learn user’s preferences over the course of the optimization based on the DM’s (partial) ranking of small sets of solutions. They allow to accumulate preference information and thus refine the internal preference model over time, and because they engage the DM in the optimization process, they initiate a learning process on the DM’s side as well. These approaches are surveyed in the following, divided into methods that attempt to learn a representative user’s value function, and those that focus on the set of value functions compatible with the elicited preference information. Some interactive approaches based on other paradigms include Deb and Chaudhuri (2007), Karahan and Köksalan (2010), Said et al. (2010) and Thiele, Miettinen, Korhonen, and Molina (2009).We will use the following notation: A is the set of solutions in a considered population; AR⊆A is the set of reference solutions in population A;f1,…,fnare n objective functions such that each solution a ∈ A is associated with the vector of evaluations(f1(a),…,fn(a)).For simplicity, we sometimes only write ajinstead of fj(a). Unless specified otherwise, we suppose, without loss of generality, that the objective functions have to be maximized.The approaches in this section use the elicited preference information to derive a single value function to approximate user’s preferences. Value functions can have different complexity, ranging from simple linear functions to the highly non-linear functions considered in the non-parametric approaches, such as artificial neural networks or support vector machines. Most approaches simply use the derived value function for ranking individuals, sometimes as secondary criterion after non-dominance, but other uses can also be found.Phelps and Köksalan (2003) proposed an interactive evolutionary algorithm that periodically asks the DM to compare pairs of solutions. Assuming linear value functions (actually, the objectives are modified before the optimization to the squared distance from a reference value, which effectively results in ellipsoidal iso-utility curves), the method determines the most discriminant weight vector compatible with the preference information. Most discriminant here means the weight vector that maximizes the minimum value difference over all pairs of solutions compared by the DM.Denote by ≻Pthe binary relation on the set AR, representing the preference information provided by the user in terms of pairwise comparisons. Then, the following linear program (LP) identifies the most discriminant value function:(1)maxɛ,subjectto∑j=1nwjfj(a)−∑j=1nwjfj(b)≥ɛ,foralla≻pb∑j=1nwj=1,wj≥0.}The resulting weight vector is then used for ranking individuals in the evolutionary algorithm that works as a single objective evolutionary algorithm between user interactions. If the LP is overconstrained and no feasible solution is found, the oldest preference information is discarded until feasibility is restored.Deb, Sinha, Korhonen, and Wallenius (2010) derive a polynomial value function model. The user is shown a set of (five in the paper) solutions and asked to (at least partially) rank them. Then, similar to the approach by Phelps and Köksalan (2003), the most discriminant value function is determined. However, due to the polynomial value function model, fitting the model to the specified preferences is a non-linear optimization problem, and the authors propose to use sequential quadratic programming to solve it. The most discriminant value function is used in the MOEA’s ranking of individuals. Basically, the objective space is separated into two areas: all individuals with an estimated value (according to the approximated value function) better than the solution ranked second by the DM are assumed to dominate all the solutions with an estimated value worse than the solution ranked second. The authors additionally use the approximated value function to perform a local single-objective optimization starting with the solution ranked best by the DM.Todd and Sen (1999) use artificial neural networks to represent the DM’s value function. Periodically, they present the DM with a set of solutions and ask for a score. The set of solutions is chosen such that they represent a broad variety regarding the approximated value function, and the estimated best and worst individual of the population are always included. Information from several interactions is accumulated after normalizing preference scores.Another model that allows representation of complex value functions are support vector machines (SVMs). Battiti and Passerini (2010) use SVMs in the setting of an interactive MOEA. Periodically, the DM is presented with a set of solutions and asked to (at least partially) rank them. This information is then used to train the SVM, with cross-validation employed to select an appropriate kernel. The derived approximate value function is then used to sort individuals in the same non-dominance rank based on their value according to the learned value function. The paper examines the influence of the number of solutions shown to the DM (assuming full ranking) and the number of interactions with the DM. The results suggest that a relatively large number of solutions need to be ranked for the SVM to learn a useful value function (around 10–20), but only two interactions with the DM seem sufficient to come very close to results that would have been obtained had the DM’s “true value function” been known from the beginning. The authors recommend to not start interaction until the MOEA has found a reasonable coverage of the entire Pareto frontier, which somewhat defeats the purpose of narrowing down the search early on. In Campigotto and Passerini (2010), the approach’s robustness to incorrect (noisy) DM preferences is examined and it is shown that the algorithm can cope well with noise.Branke, Greco, Słowiński, and Zielniewicz (2015) have recently compared various ways to define a representative value function and found that the function that maximizes the sum of values of individuals in the population actually performed slightly better than the most discriminant value function, and much better than a value function that minimizes slope changes. They showed that their approach, called NEMO-0, which is able to learn arbitrary monotonic additive value functions, can perform well in cases where a linear value function model is not sufficient to represent the user’s preferences.Rather than deriving a single value function, Jaszkiewicz (2007) notes that there may be several value functions compatible with the specified user’s preferences and samples the preference function used in each generation from the set of preference functions (in this case linear weightings are assumed). The proposed approach uses the value function also for local search. In the interactive version, preference information from pairwise comparisons of solutions is used to reduce the set of possible weight vectors.Greenwood et al. (1997) suggested the imprecise value function approach which considers all compatible linear value functions simultaneously. The procedure asks the user to rank a few solutions, and from this derives constraints for the weightings of the objectives consistent with the given ordering. Then, these are used to check whether there is a feasible linear weighting such that solution a would be preferred to solution b.Then, to compare any two solutions a and b from set A, one has to consider all value functions compatible with the user’s preferences: a is considered at least as good as b if for all compatible value functions a gets a value not smaller than b. To make this conclusion, the following linear program (LP) has to be solved:(2)ɛ*=maxɛ,subjectto∑j=1nwjfj(b)−∑j=1nwjfj(a)≥ɛ∑j=1nwjfj(c)−∑j=1nwjfj(d)≥ɛ,forallc≻pd∑j=1nwj=1,wj≥0.}EN(a,b)If the set of constraints EN(a, b) is infeasible or ε* ≤ 0, it can be concluded that there is no compatible value function such that b would be strictly preferred to a, and therefore a is at least as good as b for all compatible value functions. If ε* > 0, then we know that b is possibly preferred over a, and we would proceed by checking whether b is always at least as good as a by solving EN(b, a). Overall, the method requires to solve one or two LPs for each pair of solutions in the population.In Korhonen, Wallenius, and Zionts (1984), the value function model is only implicit. Under the assumption of quasi-concave value functions, specified preferences between solutions can be generalized to preference cones. This idea is used by Fowler et al. (2010) to partially rank the non-dominated solutions in an MOEA. The DM is asked to consider a set of six solutions and specify the best and worst. From this information, six preference cones are derived (five 2-point cones involving the best and any of the other solutions, and one 6-point preference cone specifying that five solutions are better than the worst). All generated cones are kept throughout the optimization run, even if the solutions defining the cone are deleted from the population. The solutions shown to the DM are selected from the set of non-dominated solutions that cannot already be ranked with the existing cones.Branke, Greco, Słowiński, and Zielniewicz (2009) and Branke et al. (2010) proposed a method called NEMO-I. It is similar to the imprecise value function approach by Greenwood et al. (1997), but rather than being restricted to linear value functions, it allows for piecewise-linear (Branke et al., 2010) or general monotonic additive (Branke et al., 2009; 2010) value functions. NEMO-I replaces the use of the dominance relation in the non-dominance sorting step of NSGA-II by the necessary preference relation. Additionally, it computes a representative value function used for scaling in the crowding distance calculation.The procedure used in NEMO-I is computationally very expensive because it requires solving at least one LP for each pair of solutions (a, b) ∈ A × A. This means that, for a population composed of s solutions, one has to solve up tos(s−1)LP problems in each iteration where we get new preference information. For this reason, in this paper, we are using a new variant, called NEMO-II, which requires significantly less computational effort. It has first been proposed in Branke et al. (2015) as part of a general framework but it is implemented here for the first time.In this section, we shall introduce the NEMO-II method presented as Algorithm 1. The procedure starts, as a classical MOEA, by randomly generating a population of solutions. Then, after ordering the population into fronts by using the dominance relation, two solutions in the first non-dominated front are chosen randomly to be compared by the user. The preference of the user on this pair of solutions is converted into a linear inequality involving the unknown value function. After introducing these constraints to the set of constraints defining the set of value functions compatible with the user’s preferences, one has to check if the augmented set of constraints is feasible, which means that there exists at least one value function compatible with the preferences of the user. If this is not the case, a sufficient number of constraints being the cause of the inconsistency should be removed. For this reason, the procedure starts with removing the constraints representing the oldest pairwise comparisons. After the set of constraints becomes feasible, the method tries to reintroduce the removed constraints that were not the cause of the infeasibility in a reverse order (therefore starting from the newest pairwise comparison) as long as the feasibility is maintained.The ordering of the population is done as in NSGA-II, putting the solutions into different fronts but, differently from NSGA-II, NEMO-II does not use the dominance relation. For each solution a in the current population A, NEMO-II checks whether there exists at least one compatible value function for which a is the most preferred solution in the current population, by solving the following LP problemɛa=maxɛ,subjecttoU(a)−U(b)≥ɛforallb∈A∖{a},[C1]U(c)−U(d)≥ɛforallc≻pd,[C2]monotonicityandnormalizationconstraints,[C3]}Eawhere constraints [C1] are used to impose that a is the most preferred among the considered solutions; constraints [C2] translate the preferences of the user, while constraints [C3] are monotonicity and normalization constraints depending on the type of the adopted value function that shall be described in the next section.If Eais feasible and εa> 0, then there exists at least one value function for which the solution a is the most preferred solution and, therefore, it is included in the first front. After removing all solutions going in the first front, the same procedure is applied to build the other fronts until each solution is assigned to a front. Within the same front, the solutions are ordered by using the crowding distance on the objective space.22The crowding distance of a solution a is the sum of distances between a′s left and right neighbor in each dimension, and infinity if a is an extreme solution Deb, Agrawal, Pratap, & Meyarivan, 2000.So, although NEMO-I and NEMO-II both take into account all value functions compatible with the user’s preference information, NEMO-I makes pairwise comparisons between solutions, while NEMO-II compares each solution to all other solutions in the current population. The NEMO-II method has two advantages. First it substantially reduces the computational effort required. While in NEMO-I the construction of a front in a population of s individuals requires the solution of up tos(s−1)LPs, in NEMO-II, the same can be done by solving only s LP problems, one for each solution in the population. Second, NEMO-II is slightly more precise in the sense that it only puts solutions in the best rank for which there exists a value function that makes them most preferred compared to all other solutions in the population, whereas NEMO-I may include some solutions for which no compatible value function exists that would prefer them over all other solutions, as long as no other solution is necessarily preferred in pairwise comparisons. Each front in NEMO-II is a subset of the front in NEMO-I that, in turn, is a subset of the non-dominated front.A small example may illustrate the difference. Consider the case of three solutions a, b, c, evaluated with respect to the value functions U1 and U2 as follows:U1(a)=1,U1(b)=0.5andU1(c)=0;U2(a)=0,U2(b)=0.5andU2(c)=1. If U1 and U2 were the only value functions compatible with the user’s preferences, NEMO-II would not put solution b into the first rank, as it would not be the most preferred under either value function. According to NEMO-I however, neither a nor c are necessarily preferred over b (because U2(b) > U2(a) and U1(b) > U1(c)) and thus NEMO-I would put solution b into the first rank.For these reasons, we base our new algorithm on the NEMO-II paradigm. The procedure is repeated until the assumed number of iterations has been reached.Among many preference models considered in the literature, the most popular is an additive value function defined on A, such that(3)U(a)=∑j=1nuj(fj(a))=∑j=1nuj(aj),where ujare non-decreasing marginal value functions,uj:Gj→R,j ∈ G, Gjis a value set of objectivefj,j=1,…,n,and G is the set of all indices of the objectives.This model assumes one of the two forms of the marginal value functions uj(aj):(i)piecewise-linear,general, non-decreasing.In case (i), the ranges [αj, βj] are divided into γj≥ 1 sub-intervals[aj0,aj1],[aj1,aj2],…,[ajγj−1,ajγj],whereajk=αj+kγj(βj−αj),k=0,…,γj,and j ∈ G, while αjand βjare the worst and the best performances on objective fj, respectively. The marginal value of solution a ∈ A with respect to objective fjis obtained by linear interpolation,(4)uj(aj)=uj(ajk)+aj−ajkajk+1−ajk(uj(ajk+1)−uj(ajk)),ifaj∈[ajk,ajk+1],wherek∈{0,…,γj−1}.The piecewise-linear additive model is completely defined by the marginal values at the breakpoints, i.e.,uj(aj0)=uj(αj),uj(aj1),uj(aj2),…,uj(ajγj)=uj(βj). Considering this type of preference function, one has to consider the following monotonicity and normalization constraints:•for all j ∈ G and for allk=0,…,γj−1,uj(ajk)≤uj(ajk+1);for all j ∈ G,uj(αj)=0,and∑j∈Guj(βj)=1.In case (ii), the characteristic points of marginal value functions uj, j ∈ G, are fixed in evaluation points of considered solutions. Let τjbe the permutation on the set of indices of solutions from A that reorders them according to non-decreasing evaluation on objective j, i.e.,aτj(1)≤aτj(2)≤…≤aτj(m−1)≤aτj(m),j∈G,m=|A|.The general non-decreasing additive model is completely defined by the marginal values at the characteristic points, i.e.,uj(αj)=uj(aτj(1)),uj(aτj(2)),…,uj(aτj(m))=uj(βj). Note that in this case, no linear interpolation is required to express the marginal value of any reference solution.Considering this type of value function, the monotonicity constraints have the formuj(aτj(k))≤uj(aτj(k+1)),for allk=1,…,m−1,while normalization constraints are the same as in case (i).The simplest additive value function model is the weighted sum, obtained by assigning a non-negative weight wjto each objective fj, j ∈ G, and giving to each a ∈ A the value(5)U(a)=∑j=1nwjfj(a)=w1f1(a)+⋯+wnfn(a).The weighted sum has some limitations in representing user’s preferences, which are shown in the following example. Let us underline that in this example we shall speak of evaluation criteria, being in Multiple Criteria Decision Aiding (MCDA) the equivalent of the objective functions in multiobjective optimization.ExampleThe manager of an international company wants to rank three candidates (Smith, Johnson and Brown), taking into account their performances on criteria experience (Ex) and age (Ag), given on a [0, 10] scale (see Table 1).Since candidates having good experience are not necessarily young, and vice versa, if there is a good performance on one of the two criteria, one does not expect a good performance also on the other criterion. Consequently, a candidate being good both on experience and age is well appreciated. Therefore, in the manager’s mind there is a positive interaction (synergy) between the performance on experience and the performance on age. In other words, the two criteria are not preferentially independent (Keeney & Raiffa, 1993). For this reason, the manager prefers Johnson to Smith and Brown.If one would like to represent the preferences expressed by the manager using the weighted sum model, the following inequalities should be satisfied:wEx·6+wAg·10<wEx·8+wAg·8,wEx·10+wAg·6<wEx·8+wAg·8,where wExand wAgare the weights of experience and age, respectively. It can be easily verified that the above inequalities are contradictory since:wEx·(−2)+wAg·2<0<wEx·(−2)+wAg·2.Thus we have to conclude that, due to the positive interaction between the performances on experience and age, the weighted sum is not able to represent the manager’s preferences.In order to represent preferences in case of interaction between criteria, non-additive integrals are often used (Grabisch & Labreuche, 2005). The best-known non-additive integral in the literature is the Choquet integral Choquet (1954). The Choquet integral is based on the concept of capacity (fuzzy measure) that assigns a weight to each subset of criteria rather than to each single criterion. More precisely, denoting by 2Gthe power set of G (i.e., the set of all subsets of G), the function μ: 2G→ [0, 1] is called capacity on 2Gif the following properties are satisfied:1a)μ(∅)=0andμ(G)=1(boundary conditions),∀ T⊆S⊆G,  μ(T) ≤ μ(S) (monotonicity condition).Intuitively, for all T⊆G, μ(T) can be interpreted as a comprehensive importance of the criteria from T considered as a whole.Example (continuation)To represent the importance and the interaction of the performances on experience and age, one can setμ({Ex})=0.4,μ({Ag})=0.3andμ({Ex,Ag})=1. The differenceμ({Ex,Ag})−μ({Ex})−μ({Ag})=0.3represents the positive interaction between experience and age because it measures how much greater is the importance of experience and age considered as a whole (μ({Ex, Ag})) comparing to the sum of their importances when they are considered separately (μ({Ex})+μ({Ag})).The Choquet integral involving capacity μ assigns to each alternative a ∈ A the following value:(6)Cμ(a)=∑j=1n[f(j)(a)−f(j−1)(a)]μ(Nj),where ( · ) stands for a permutation of the indices of criteria, such that(7)f(0)(a)≤f(1)(a)≤f(2)(a)≤⋯≤f(n)(a),Nj={(j),…,(n)}andf(0)(a)=0.Observe that (7) requires that the values taken by objective functionsfj,j=1,…,n,have to be non-negative. If this is not the case, one can recode the values fj(a), a ∈ A, with a translationfj*(a)=fj(a)+cwithc≥−minj∈G,b∈Afj(b),so that we getfj*(a)≥0for allj=1,…,nand all a ∈ A.A meaningful reformulation of the capacity μ and of the Choquet integral can be obtained by means of the Möbius representation of the capacity μ (see Rota, 1964) which is a functionm:2G→R(Shafer, 1976) defined as follows:μ(S)=∑T⊆Sm(T).Note that if S is a singleton, i.e.,S={j}withj=1,…,n,thenμ({j})=m({j}). Moreover, if S is a pair of criteria, i.e.,S={i,j},thenμ({i,j})=m({i})+m({j})+m({i,j}).The Möbius representation m(S) of capacity μ(S) can be obtained as follows:m(S)=∑T⊆S(−1)|S−T|μ(T).In terms of the Möbius representation, properties (1a) and (2a) are, respectively, restated as (see Chateauneuf & Jaffray, 1989):(1b)m(∅)=0,∑T⊆Gm(T)=1,∀j∈Gand∀S⊆G∖{j},∑T⊆Sm(T∪{j})≥0,while the Choquet integral may be reformulated as follows:(8)Cμ(a)=∑T⊆Gm(T)minj∈Tfj(a).Geometrically, in the case of two objectives (G={f1,f2}), the iso-value curve of the Choquet integral can be decomposed into two linear functions, one above the linef1=f2and one below the linef1=f2. Using (8) we can writeCμ(a)={(m({1})+m({1,2}))f1(a)+m({2})f2(a),iff1(a)≤f2(a)m({1})f1(a)+(m({2})+m({1,2}))f2(a),iff1(a)≥f2(a)Example (continuation)The value assigned to Smith (S) by the Choquet integral with capacity μ is the following:(9)Cμ(S)=fEx(S)·μ({Ex,Ag})+(fAg(S)−fEx(S))·μ({Ag})=7.2.This value can be explained as follows. The performancefEx(S)=6is attained by the two criteria and thus it is multiplied by μ({Ex, Ag}) which is the weight assigned to experience and age considered as a whole. The performancefAg(S)=10is attained only on criterion age and therefore the differencefAg(S)−fEx(S)is multiplied by μ({Ag}) which is the weight assigned to age considered alone. Analogously, we getCμ(Johnson)=8andCμ(Brown)=7.6,so that we have Cμ(Johnson) > Cμ(Smith) and Cμ(Johnson) > Cμ(Brown), and thus we can conclude that the Choquet integral is able to represent the manager’s preferences.Observe, moreover, that the Möbius representation m of the capacity μ givesm({Ex})=0.4,m({Ag})=0.3andm({Ex,Ag})=0.3. Therefore, the Choquet integral referring to Smith can be reformulated as follows in terms of the Möbius representation m:Cμ(S)=fEx(S)·m({Ex})+fAg(S)·m({Ag})+min(fEx(S),fAg(S))·m({Ex,Ag})=7.2.This value can be explained as follows. The performances on experience and on age are multiplied by m({Ex}) and m({Ag}), respectively, representing the relative weights of the two criteria. However, the value obtained by summation of the two weighted components has to be corrected by adding min (fEx(S), fAg(S)) · m({Ex, Ag}) representing the positive interaction between the performance on experience and the performance on age. The Choquet integral of Johnson and Brown can be analogously reformulated in terms of the Möbius representation.□In order to reduce the number of parameters to be elicited and to avoid an overprecise description of the interactions among criteria, Grabisch (1997) introduced the concept of fuzzy k-additive capacity. A capacity is called k-additive ifm(T)=0for T⊆G, such that |T| > k. In particular, in case of a 1-additive capacity, the Choquet integral is the standard weighted sum model.In MCDA, it is easier and more straightforward to consider 2-additive capacities, since then the users have to express preference information on positive and negative interactions between two criteria only, neglecting possible interactions among three, four and, generally, r criteria,r=2,…,n. Moreover, by considering 2-additive capacities, the computational effort needed to determine the parameters is reduced since onlyn+(n2)coefficients have to be assessed; specifically, in terms of the Möbius representation, a value m({i}) for every criterion i, and a value m({i, j}) for every pair of criteria {i, j}. The value that a 2-additive capacity μ assigns to a set S⊆G can be expressed in terms of the Möbius representation as follows:(10)μ(S)=∑i∈Sm({i})+∑{i,j}⊆Sm({i,j}),∀S⊆G.With regard to 2-additive capacities, properties (1b) and (2b) have, respectively, the following forms:1c)m(∅)=0,∑i∈Gm({i})+∑{i,j}⊆Gm({i,j})=1,{m({i})≥0,∀i∈G,m({i})+∑j∈Tm({i,j})≥0,foralli∈G,andforallT⊆G∖{i},T≠∅.In this case, the Choquet integral of a ∈ A is calculated as:(11)Cμ(a)=∑i∈Gm({i})fi(a)+∑{i,j}⊆Gm({i,j})min(fi(a),fj(a)).As one can observe, the use of the Choquet integral is based on several parameters (capacity μ(T) for each subset T⊆G or a value m(T) for each subset T⊆G in case of the Möbius representation of capacity μ). To determine these parameters, a direct and an indirect technique known from the literature can be applied. In the direct technique, the user has to provide the parameters directly, while in the indirect technique the user has to provide some preference information from which parameters compatible with this information are retrieved by ordinal regression. The latter technique is much more realistic than the former because it requires less cognitive effort from the user. The indirect technique for the Choquet integral has been firstly proposed in Marichal and Roubens (2000). When using the indirect technique, it is possible that more than one set of parameters is compatible with the preference information given by the user. For this reason, selection of only one of these compatible sets of parameters is somewhat arbitrary. To take into account all sets of parameters compatible with the user’s preferences, Robust Ordinal Regression (ROR) (Greco, Mousseau, & Słowiński, 2008) has been recently proposed. Taking into account all the sets of parameters compatible with the preferences of the user, ROR presents a recommendation in terms of necessary or possible preference relations which, for a pair of alternatives a and b, hold if a is at least as good as b for all or for at least one set of compatible parameters, respectively. ROR has been applied to the Choquet integral in Angilella, Greco, and Matarazzo (2010) under the name of Non-Additive Robust Ordinal Regression (NAROR).Observe also that, besides determination of the capacity, the use of the Choquet integral involves another specific problem that is the construction of a common scale for the considered criteria permitting to compare the performances on different criteria and to compute in a meaningful way their difference. Indeed, looking at the definition of the Choquet integral in (6), we can observe that on one hand, permutation ( · ) of the considered performances on different criteria is required, while on the other hand, the computation of the Choquet integral requires also that the differences between the performances on criteria g(i) andg(i−1),i=1,…,n,are meaningful. In the provided example this is obvious because, for instance, considering candidate Smith, the performance of 10 on age is clearly more valuable than the performance of 6 on experience, and their difference is 4. But, considering the case of a decision about cars, which is more valuable between a maximum speed of 200 kilometers per hour and a price of 35,000 euros? This means that in case of criteria with heterogeneous scales, the performances on all criteria have to be mapped to a common scale which permits to compare them and also to compute their difference. Very often a normalization of performances on each criterion is done considering an “unacceptable” and an “optimal value” for each criterion and considering a linear interpolation between these two extremes (see, e.g., Grabisch, Labreuche, & Vansnick, 2003). A more sophisticated methodology permitting to construct a common scale and a capacity for the Choquet integral on the basis of preference information supplied by the DM has been proposed in Angilella, Greco, Lamantia, and Matarazzo (2004) and further developed in Angilella, Corrente, and Greco (2015). In this paper, as we shall explain in detail in Section 5, we consider an intermediate approach consisting in first normalizing the performances on each criterion, and then rescaling them through multiplication by a set of weights that ensure comparability between performances on different criteria. We explain this procedure in the continuation of the previous example, in which the performances on considered criteria are already normalized but they need to be rescaled so that the preferences of the DM can be represented by the Choquet integral.Example (continuation)Suppose that two new candidates have to be added to the three previously considered. Their performances with respect to experience and age are presented in Table 2.After reflecting a little, the manager arrived at the conclusion that he has the following preferences with respect to the five candidates:Baker≻Johnson≻Miller≻Brown≻Smith.When trying to apply the Choquet integral to represent the current manager’s preferences, we realize that it is not possible. Indeed, by computing the Choquet integral of the performances of the candidates Brown and Smith we get(12)6·μ({Ex,Ag})+(10−6)·μ({Ex})>6·μ({Ex,Ag})+(10−6)·μ({Ag})while comparing Baker and Miller we get(13)7·μ({Ex,Ag})+(9−7)·μ({Ag})>7·μ({Ex,Ag})+(9−7)·μ({Ex}).From Eq. (12) we get μ({Ex}) > μ({Ag}) while from Eq. (13) we get μ({Ag}) > μ({Ex}), which are of course incompatible.Observe, however, that if you rescale the criteria experience and age multiplying the relative performances of the candidates by 0.56 and 0.44, respectively, we get the performances shown in Table 3. Computing the Choquet integral of the five candidates considering the capacity previously defined (μ({Ex})=0.4,μ({Ag})=0.3andμ({Ex,Ag})=1), we get the values in the last column of Table 3 which represent the preferences of the manager.□Let us conclude this section discussing the use of Choquet integral in case the DM prefers smaller objectives function values, i.e. for all a, b ∈ A, if fj(a) ≤ fj(b), then a is at least as good as b with respect to objective fj. In this case, the objective functions fjcan still be aggregated using the Choquet integral, but then solutions with a smaller Choquet integral would be preferred, i.e., for all a, b ∈ A if Cμ(a) ≤ Cμ(b), then a is comprehensively at least as good as b. In this case, the aim is to minimize rather than to maximize the value of the Choquet integral.Because most benchmark problems in evolutionary multiobjective optimization are minimization problems, in the following description of NEMO-II and of the empirical analysis, we assume that objective functions as well as a supposed users’ utility are to be minimized. Compared to the discussion above, the only difference is that while with maximization, the preference of an alternative a over an alternative b was translated into the constraintU(a)≥U(b)+ɛ,now the preference is translated into the constraintU(a)+ɛ≤U(b). In case of indifference between a and b, the corresponding constraint isU(a)=U(b).Let us first consider a problem with two objectives f1 and f2 to be minimized. As observed in Section 4.2, due to some interactions between the considered criteria it could happen (as in the case shown in Fig. 1), that the linear model is not able to represent the preferences of the DM. For this reason, we suggest using the Choquet integral preference model that is able to take into account interactions between criteria. In Pirlot, Schmitz, and Meyer (2010), it has been shown experimentally that the Choquet integral has a greater capacity of representing the preferences of a DM than the weighted sum model.While a greater flexibility of the preference model allows to capture more complicated user preference information and is thus desirable, usually, it also has more parameters, and more preference information is required before the set of compatible value functions is curbed sufficiently to be useful in narrowing down the search. For this reason, we propose to keep the complexity of the preference model low as long as it is sufficient to capture all preference information, but switch to a more complex preference model when this is no longer the case, following the procedure described in Algorithm 2. In particular, we start with assuming a linear preference model. Once we can no longer find a linear value function compatible with all elicited preference relations, we switch to a 2-additive Choquet integral.To check whether there exists a set of weightsw=(w1,…,wn)such that the linear model is able to restore the preferences of the DM, one has to solve the following LP,maxɛ,subjecttoU(a)−U(b)+ɛ≤0foralla≻pb,∑j=1nwj=1wj≥0,forallj=1,…,n}EDMlinearwhereU(a)−U(b)≤ɛare the constraints translating the preferences of the DM while the other two constraints are used to ensure that weights are non-negative and normalized.There is a w compatible with the preferences of the DM if and only ifEDMlinearis feasible and εlinear> 0 whereɛlinear=maxɛsubject toEDMlinear. In this case, one can proceed to order the population by using the same procedure described in the previous section, checking, for each solution x, whether there exists a set of weightsw=(w1,…,wn)such that x is the best among the considered solutions. To this end, one has to solve the following LP.maxɛ,subjecttoU(a)−U(b)+ɛ≤0foralla≻pb,U(x)−U(y)+ɛ≤0forally∈A∖{x},∑j=1nwj=1wj≥0,forallj=1,…,n}Exlinearwhere constraintsU(x)−U(y)≤ɛensure that x is preferred to all other solutions in A.IfExlinearis feasible andɛxlinear>0whereɛxlinear=maxɛsubject toExlinear,then there exists a set of weights w such that x is the preferred solution and therefore it is included in the first front. After ordering all the solutions into different fronts, the solutions in the same front are ordered by computing the classical crowding distance of NSGA-II.If there exists no vector w such that the linear model would be able to restore the preference information provided by the DM, we need to use a more complex model such as the Choquet integral in order to represent the preferences expressed by the DM. As we shall justify later, we use the 2-additive Choquet integral here that has a parameter m({j}) for each objective j and a parameter m({i, j}) for each pair of objectives {i, j}.As already discussed in Section 4.2, the use of the Choquet integral assumes that all objectives are expressed on the same scale. Indeed, when using the original formulation of the Choquet integral involving the capacity μ (see Eq. (6)), for each solution x we need to order all values of each individual’s objective from the worst to the best. Analogously, using the Choquet integral expressed by means of the Möbius decomposition m (see Eq. (8)), for each solution x and for each subset of objective functions, we need to know the minimum value. Since we cannot assume that the scales of the different objectives are comparable, the scaling becomes part of the model. In other words, in addition to the usual parameters of the Choquet integral, we also need to consider a scaling weight for each objective.Let us consider the example shown in Fig. 2. If the user states that Q ≡ (1.75, 0.4) is preferred to P ≡ (1.25, 1.05) and R ≡ (2.75, 1.9) is preferred to S ≡ (3.75, 0.4), there is no Choquet integral compatible with these preferences. The preferences correspond to the inequalities0.5m({1})−0.65m({2})−0.65m({1,2})<0andm({1})−1.5m({2})−1.5m({1,2})>0which contradicts the monotonicity constraint 2c). This is also apparent from the fact that all four alternatives are located under the linef1=f2,where the iso-utility function of the Choquet integral is linear, and no linear model is able to reflect the preferences.However, if we scale the objectives appropriately (which “moves” thef1=f2line), then it is possible to represent the preference information using a Choquet integral. For example, let us multiply the two objectives by the weightsw1=0.31andw2=0.69. The four points become Q ≡ (0.5425, 0.276), P ≡ (0.3875, 0.7245), R ≡ (0.8525, 1.311) and S ≡ (1.1625, 0.276) while the constraints translating the preferences of the user become0.155m({1})−0.4485m({2})−0.1115m({1,2})<0and0.31m({1})−1.035m({2})−0.5765m({1,2})>0,being compatible with the Möbius decompositionm({1})=0.9,m({2})=0.4andm({1,2})=−0.3.Mathematically, determining whether the preferences can be represented by an appropriate scaling and Choquet integral translates into the following non-linear program:(14)maxɛ,subjecttoCμ(w1f1(a),…,wnfn(a))−Cμ(w1f1(b),…,wnfn(b))≤ɛforalla≻pb,∑j=1nwj=1m(∅)=0,∑j=1nm({j})+∑{i,j}⊆{1,…,n}m({i,j})=1,m({j})≥0,forallj=1,…,n,m({j})+∑i∈Tm({i,j})≥0,forallj=1,…,n,andforallT⊆{1,…,n}∖{j},T≠∅.}EDMChThe user’s preferences can be represented if an only if the solution to this optimization problem results inɛDMCh>0,whereɛDMCh=maxɛsubject toEDMCh.Since the optimization problem is non-linear, to solve it, we use the Nelder–Mead algorithm (Nelder & Mead, 1965) to search the space of weights while maximizing ε, with an LP being solved in every iteration to determine the best Möbius parameters for the weights in the current iteration. The algorithm is aborted as soon as an ε > 0 has been found. If after a few iterations (we chose 40 in the experiments below), no such weight/Choquet coefficient combination has been found, we stop the search and remove some of the DM’s preference information, starting from the oldest, until the feasibility is regained.Once it has been found that the preference information provided by the DM can be represented by using the Choquet integral preference model (possibly after removing some pieces of information), the solutions are put into different fronts by using the same procedure as described previously. For each solution x ∈ A, one has to check whether this solution might be the most preferred one by solving the following optimization problem:(15)maxɛ,subjecttoCμ(w1f1(x),…,wnfn(x))−Cμ(w1f1(y),…,wnfn(y))≤ɛ,forally∈A∖{x},EDMCh}ExChBecause, again, the optimization problem (15) is non-linear, in a first step we try to simplify the solution by fixing the vector of weightsw′=(w1′,…,wn′)such thatw1′f1(x)=⋯=wn′fn(x)and then checking, by using linear programming optimization, if there exists a set of Choquet coefficients such thatɛxCh>0,whereɛxCh=maxɛs.t.ExCh(indeed, if we fix the weights(w1,…,wn),then the optimization problem (15) becomes an LP problem). We found that in many cases, this will find a feasible solution if there exists one. If not, then we use the Nelder–Mead method explained above to check whether the optimization problem allows forɛxCh>0.Note that for more than 2 dimensions, we still restrict our model to 2-additive Choquet.

@&#CONCLUSIONS@&#
In this paper, we presented the NEMO-II-Ch method. NEMO-II-Ch is an interactive evolutionary multiobjective procedure guided by user’s preferences towards the most preferred part of the Pareto-optimal set. The novelties brought by the method consist in the following features:•It is the first implementation and empirical evaluation of the NEMO-II idea.It does not work by considering only one model to translate the preferences of the DM but it starts from the simplest one (the linear model) and passes to a more complex one (the 2-additive Choquet integral model) when it is not possible to represent the DM’s preferences using the linear model.The use of the Choquet integral preference model has never been considered in the evolutionary multiobjective optimization field for its relative complexity, however, we have demonstrated that it is able to deal efficiently with problems where preferences involve interactions among criteria, which additive preference models are unable to represent.In order to demonstrate the effectiveness of the presented method, as well as the quality of its solutions, we have compared NEMO-II-Ch with NSGA-II and a variant of Greenwood’s method (NEMO-II-L) on a variety of benchmark problems in 2D, 3D and 5D.In almost all performed simulations, NEMO-II-Ch clearly obtained better results than the other tested methods.Further developments will include to study how the increase of the number of interacting objectives in the k-additive Choquet integral for k > 2 influences the performance of the interactive procedure based on this preference model.