@&#MAIN-TITLE@&#
A swarm-inspired re-ranker system for statistical machine translation

@&#HIGHLIGHTS@&#
We design and implement a novel reranker system for statistical machine translation, which it is used a swarm algorithm.We introduce sort of new features, which they can be computed easily from n-best list generated by SMT.We examine our system in English–Persian dataset.

@&#KEYPHRASES@&#
Re-ranking system,Quantum-behaved particle swarm optimization,Perceptron,BLEU,

@&#ABSTRACT@&#
Recently, re-ranking algorithms have been successfully applied on statistical machine translation systems. Due to the errors in the hypothesis alignment and varying word order between the source and target sentences and also the lack of sufficient resources such as parallel corpora, decoding may result in ungrammatical or non-fluent outputs. This paper proposes a re-ranking system based on swarm algorithms, which makes the use of sophisticated non-syntactical features to re-rank the n-best translation candidates. We introduce plenty of easy-computed non-syntactical features to deal with SMT system errors plus the quantum-behaved particle swarm optimization (QPSO) algorithm to adjust the weights of features. We have evaluated the proposed approach on 2 translation tasks in different language pairs (Persian→English and German→English) and genres (news and novel books). In comparison with PSO-, GA-, Perceptron- and averaged Perceptron-style re-ranking systems, the experimental study demonstrates the superiority of the proposed system in terms of translation quality on both translation tasks. In addition, the impacts of the proposed features on the translation quality have been analyzed, and the most positive ones have been recognized. At the end, the impact of the n-best list size on the proposed system is investigated.

@&#INTRODUCTION@&#
Statistical Machine Translation (SMT) is a well-known approach to automatic translation based on the statistical models. These systems are the current paramount research projects for machine translation which have attracting remarkable commercial interest in recent years (Specia, 2013). Despite the remarkable advances in SMT system, its output often contains diverse errors. The errors could be lack of a main verb, wrong word order, wrong lexical choice, missing content words, incorrect punctuation and so on (Och et al., 2004a,b).In SMT systems, performance improvements could be achieved by using a re-ranker system with two processing steps (Carter and Mon, 2011; Federico and Bertoldi, 2005). First, a decoder provides an n-best list of translation candidates. Next, the final translation is recognized by re-scoring and re-ranking the N-best list through additional scores. The scores are computed thereby using more sophisticated features. The additional features indeed reward better translations found among the n-best list entries of the decoder.The present study aims at dealing with the aforementioned problems by exploring a variety of new sophisticated features and introducing a new learning algorithm based on QPSO to re-rank and re-score the translation candidates. The proposed features are estimated directly and easily on the language and translation models, n-best list of translation candidates and part-of-speech tags. They are classified into six specific groups; i.e., (1) Language model features set which consists of an n-gram and an adaptive n-best list language model features. (2) Translation model feature set. (3) N-best list feature set which contains an n-best source/target position word feature, and a Levenshtein distance feature. (4) Length feature set. (5) Anchor matcher and Part-of-Speech tag feature sets. (6) Morphological feature set.The proposed re-ranking system makes use of a scoring function to assess the translation candidates. The scoring function returns the weighted feature scores optimized by a development data set. A popular method for adjusting the features weights is to apply swarm optimization algorithm because it can be utilized relatively easy and it is applicable to a very wide range of problems (Sun, 2004a,b). Therefore, our re-ranking system is based on quantum-behaved particle swarm optimization (QPSO), a form of particle swarm optimization algorithm. QPSO is introduced by integrating the classical PSO philosophy and quantum mechanics in order to enhance performance of PSO (Sun, 2004a,b). It has been shown that QPSO outperforms original Particle Swarm Optimization (PSO) considerably on several widely known benchmark functions (Sun, 2004a,b; Sun et al., 2005a,b). In QPSO, the only setting parameter is contraction-expansion coefficient, which is gradually decreased with the number of iterations (Sun et al., 2005a,b). Using a new re-ranking system with the sophisticated features and global-convergence algorithm, QPSO, to tune feature weights would have a positive impact on translation quality.Two translation tasks with different language pairs (Persian→English and German→English) and genres (news and novel books) have been used, and several evaluations have been performed to imply the accuracy and efficiency of our re-ranking system. The evaluation scenarios are described as follows. (1) The performance of our system has been compared to the well-known algorithms such as PSO, GA, Perceptron- and averaged Perceptron. The results illustrate the superiority of our approach in terms of translation quality. The results show an increase about 1.03 BLEU score over the baseline on Persian→English translation task and 1.73 on German→English translation task. (2) The impacts of the proposed feature sets have been computed. The contribution of features in the re-ranking system has been reported and the effect of each feature is successively computed. (3) The impact of the n-best list size has been examined. The findings of experimental studies indicate that using more than 1000-best list does not improve the translation quality significantly.Generally, we believe the actual new contributions of our work are the extension of previously introduced features to the sophisticated, easy-computed and non-syntactical feature sets, plus the use of the new optimization algorithm to adjust the features weights.The paper is organized as follows. In Section 2, the parameter estimation algorithms are introduced. In Section 3 and Section 4, the features and experimental studies are presented. Related works are reviewed in Section 5. Finally, we draw some conclusions in Section 6.Applying new models in a re-ranking system to achieve better results is a standard technique in SMT (Kumar and Byrne, 2004). In a re-ranking approach, SMT outputs a list of the top n translation candidates (an n-best list) and then the re-ranking algorithms take these n-best lists and re-rank them according to a weight vector and a function f(·), which maps a sentence into a feature space. At the end, the best hypothesis is then returned as a selected translation. Different weighting algorithms such as the Perceptron and averaged Perceptron to estimate the weight vector w are widely used in NLP applications (Carter and Mon, 2011; Liang et al., 2006b; Shen and Joshi, 2005; Tillmann and Zhang, 2006). However, because of the advantages of QPSO (Sun, 2004a,b) that lies on its simple concept, easy implementation and quick convergence, we decided to implement QPSO-based re-ranking system. In the next subsection, we intent to describe this algorithm in more details.Sun (2004b) proposed a global convergence-guaranteed swarm based search technique, quantum-behaved particle swarm optimization algorithm (QPSO), whose performance is superior to the standard PSO.The standard PSO optimizes a problem by moving its particles around in the solution space according to the particle's position and velocity. Because of the limited velocity, the solution space of the standard PSO is a restricted area and it cannot explore the entire feasible space. Therefore, the algorithm could not guarantee convergence to global optimal solution (Sun et al., 2012).In QPSO with M individuals, a partial solution to an optimization problem is shown as a particle in D dimensional search space, with the position Xi=(xi1,xi2,…,xiD). The best previous value of each particle is registered (the position giving the best fitness value) as pbesti=(pbesti1,pbesti2,…,pbestiD) called personal best position. At each iteration, each particle competes with its neighbors or in the whole population for the best particle (with best fitness value entire search space) with best position gbesti=(gbesti1,gbesti2,…,gbestiD) called global best position.In QPSO, the particles move according to the following iterative equation:(1)xid(t+1)=gid±β|mbestd−xid(t)|ln(1/u)where(2)gid=φ.pbestid+(1−φ)gbestdand(3)mbestd=∑i=1mPid/mmbest is defined as the mean value of all particles’ best position,φand u are random numbers distributed uniformly on [0,1], respectively, and m is the number of particles. The parameter,β, called contraction-expansion coefficient, is the only parameter in QPSO algorithm.In order to utilize QPSO to adjust features weights, we should primarily determine an encoding of particle's position and a fitness function, and then introduce an algorithm that updates particles position according to QPSO manner and fitness function.In this work, the particle's position is made of features weights. Fig. 1shows the particle's position encoding.Another important factor is a fitness function, which checks the quality of each potential solution (particles). QPSO tries to minimize the fitness function. In this work, the fitness function is scored by Eq. (4) as follows:(4)fitness(w→)=1BLEU(FirstBest(X¯,w→))whereX¯is the set of the n-best lists, and BLEU(·) function calculates the BLEU metric of the first best sentences with respect to the references in the development set.FirstBest(X¯,w→)also determines the first best sentences of the n-best lists,X¯, regarding to the weight vectorw→. Eq. (5) shows FirstBest function:(5)FirstBest(X,w):∀x∈Xargmax(xi∈x)f(xi).wwhere xiis a hypotheses in the n-best list x and the feature extractor f(·) is a vector of n functions f=(f1,…,fn), and each function fj(y) maps a feature y to a real value fj(y). All utilized features will be explained more in Section 3.In order to introduce the new scoring function (learning a new classifier), QPSO firstly initializes all features weights randomly and then updates them according to the evaluation of the best sentences found by FirstBest function with the help of BLEU metric. Generally, QPSO iterates over the n-best lists in a sequential manner and finds the best scoring function to select the best hypothesis in terms of quality and fluency. The following is a procedure of QPSO for the re-ranking system.Step 1: Initialize the population by randomly generating the position vector Wi of each particle and set pbesti=Wi.Step 2: Run FirstBest function (Eq. (5)) to find the best sentence with respect to the position vector Wi for each n-best list inX¯and evaluate the fitness value of each particle by Eq. (4),Step 3: Update the personal best position (pbesti) and obtain the global best position (gbest) across the population.Step 4: If the stop criteria are met, go to step 6; or else go to step 5.Step 5: Update the position vector of each particle (Wi) according to Eq. (1) and go to step 2.Step 6: Output the gbest as the best feature weights.Two stop criteria based on maximum number of iterations and oracle best sentences have been employed. Eq. (6) shows the stop criterion based on oracle best sentences.(6)sBLEU(Oracle(X))-sBLEU(FirstBest(X,W))<εOracle(X¯) determines the best translation (oracle sentence) for each n-best lists (xi). Note that BLEU does not work at the sentence level. Several sentence-level implementations of BLEU known as smoothed BLEU have been proposed (Liang et al., 2006b; Lin and Och, 2006). For example, in (Liang et al., 2006b; Lin and Och, 2006), a smoothed BLEU, illustrated in Eq. (7), has been proposed. In the proposed system, we utilize this measure as sentence level BLEU.(7)sBLEU=∑i=1BLEUi(cand,ref)24−i+1The only setting parameter of QPSO is the contraction-expansion coefficient (β) which is gradually decreased for the interval (0, 1] with the number of iterations.In order to introduce new features aimed at improving translation quality of SMT systems, first of all the essential problems of SMT system should be identified, and then several features are introduced to deal with SMT system errors. In the following subsection, we intend to explain typical SMT errors.A Phrase-based SMT (Koehn et al., 2007) has been trained by 400K sentence pairs of an English-Persian parallel corpus11For other language pairs, see Vilar et al. (2006) and Llitj’os (2004).called TPC22Tehran Parallel Corpus.(Mansouri and Faili, 2012), and its output have been analyzed in more details. By exploring 400 translated sentences emerged randomly from TPC, 7 classes of main errors have been recognized according to the error typology presented in (Vilar et al., 2006). The complete error statistics are shown in Fig. 2.As shown in Fig. 2, the errors have been classified into 7 main error groups. The “others” contains the “Unknown words”, “Incorrect style” and “Incorrect idioms” errors (Vilar et al., 2006). The error groups are described as follow:•Lack of main verb: 50% of sentences were detected problematic merely due to the lack of main verb in Persian sentences. Two sorts of errors were often committed. There was no verb in the translated sentence, or there was a defected verb in the translated sentence because of the absence of verbal part in the compound verbs. The verbal part of compound verbs in Persian are usually aligned wrongly to their corresponding English sides.Wrong word order: The percentage of errors made due to the wrong word order equaled 27.7%. This is the case due to the fact that there are many differences between English and Persian sentences in word order. Persian sentences use SOV (Subject (S), Object (O) and Verb (V)) word order whereas English sentences use SVO structure. Also, the modifier comes after the modified word in Persian whereas English is vice versa. The local word reordering as a short distance reordering could be handled by the phrase and language models. But the non-local word reordering is still an open problem. Neither the translation nor the language model is able to handle a long distance reordering problem.Wrong lexical choice: This class of error was caused by the wrong lexical choice (66.8%). It was found when the translation system did not find the correct translation of a given word (Duh et al., 2010). Usually, the lack of sufficient bilingual resources is the main reason. Lexical granularity gaps between two languages may intensify the problem, too.Incorrect form of words: This kind of error was caused when the translation system was not able to produce the correct form of a word, although the translation of the base form was correct. This category of errors considers verb tense, verb person and concordance problem between noun and verb in term of number. The percentage of errors due to the incorrect form of words amount to 31.9%. This sort of error becomes more common when the system deals with a highly inflectional language, like Persian.Missing function words and punctuations: The errors due to the missing function word and punctuation together amount to 33.3%. This sort of errors was caused by the absence of suitable function words and punctuations in the translated sentences. It also occurred when the translation system was unable to translate the function words like “/che/what”, “/ke/that” or to find correct punctuations like “:”, “;” and so on.Almost all levels of probable errors have been explained in more details by Vilar et al. (2006).The aim of introducing additional features is to deal with the aforementioned problems by exploring a variety of new sophisticated features to reward better translations found among the n-best entries of the decoder. Some features such as the language model, adaptive language model, translation model and so on are borrowed from the previous publications (Carter and Monz, 2010; Hildebrand and Vogel, 2008; Liang et al., 2006a; Och et al., 2004a,b) whereas the plenty of easy-computed and non-syntactical features such as the n-best list feature set, anchor and punctuation matcher feature set and so on have been introduced in this paper. According to the feature characteristics, the features can be classified into six sets as follows.A language model feature set, which includes a language model and an adaptive language model feature, has been explained as follows:A language model is one of two main models in the decoding phase of SMT system which is used to promote fluency in translation. Using high order n-grams is useful to control long distance dependencies in the target sentence. It is borrowed from (Och et al., 2004a,b).An adaptive language model feature is another member of the language model feature set. This feature is calculated through the n-best list n-grams probabilities. The counts of n-grams are collected on the n-best list entries for one source sentence only. The aim of defining this feature is to dedicate the importance of n-grams repeated more than others in the n-best list, and to overcome the wrong lexical choice and wrong word order problems. This feature is calculated as follows:(8)score(Es)=log(∏pn−best(ei|ei−n+1i−1))(9)pn−best(ei|ei−n+1i−1)=countn−best(ei,ei−n+1i−1)countn−best(ei−n+1i−1)where Esis sth hypothesis. Note that in our re-ranking system, n is set to 6. It is borrowed from (Hildebrand and Vogel, 2008).By getting help from a statistical word-to-word translation model, a probabilistic dictionary, the word translation log probability of each entry is calculated as translation feature score. It is borrowed from (Och et al., 2004a,b). This feature is estimated as follows:(10)score(Es,F)=log(1(N(F)+1)∏i∑jt(ei|fj))where Esand F are target and source sentences, respectively. eiand fjare ith target and jth source words, respectively. t(·) is a word to word translation probability and N(F) is number of words of the source sentence.The translation and language model features provide a rough guide for translation, but they are far too coarse to fix specific mistakes. Therefore, the re-ranking system is equipped by several sophisticated features. The n-best list features set is one of them which utilizes information provided by the n-best list. It consists of three creative features. The wrong word order, especially the global word reordering, and the wrong lexical choice problems can be addressed by such a feature set.This feature is estimated by the probability of the occurrence of a word in a special position of the target sentence. This feature is calculated as follows.(11)score(Es)=log(∏i=1N(Es)pn−best(ei|i))where N(Es) is the length of hypothesis Es, eiis ith word of Esand pn-best(ei|i) is the probability of the occurrence of eiin ith position of Esthat is calculated as follows:(12)p(e|i)=1Nh(F)∑h=1Nh(F)γ(ei,h,e)where Nh(F) is the number of hypotheses generated for source sentence F and ei,his ith word of hth hypothesis in the n-best list.γ(ei,h,e)also is defined as follows.(13)γ(ei,h,e)=1ei,h=e0ei,h≠eThe aim of this feature is to fight with the wrong lexical choice problems.The agreement score of a word f occurring in position i (the source sentence) and ith translations occurring in the position j (the target sentence) is calculated as the relative frequency of the Nhtranslation hypotheses in the n-best list. (j,fi) denotes the translation of fi(ith source word) occurs in the position j (the target sentence). This feature tries to capture how many entries in the n-best list are on the same word order. Fig. 3shows the different alignments of a source word in the n-best list. It is designed to overcome the wrong word order problem.The feature is calculated as follows.(14)score(Es,F)=log(∏j=0N(Es)∑i=1N(F)pn−best(j|fi))where N(F) and N(Es) are the length of the source and the length of sth hypothesis, respectively. pn-best(j|fi) is the probability of the occurrence of the translation of fiin j target position. Note that because of the existence of NULL alignments, j must be started by 0.(15)pn−best(j|fi)=1Nh(F)∑k=1Nh(F)γ(alignk(fi),j)where alignk(fi) returns the target position that fihas been aligned to andγ(i,j)denotes as follows.(16)γ(i,j)=1i=j0i≠jThe Levenshtein distance is a measure of similarity between two strings (Snover et al., 2006). It calculates the similarity between one hypothesis and other hypotheses in the n-best list.(17)score(Es,F)=log(N(F)∑Ej∈n−bestlist(F)LD(Es,Ej))where LD(Es,Ej) calculates the Levenshtin distance between Esand Ej.It contains the hypothesis length and average hypothesis length features. It is borrowed from (Carter and Monz, 2010).The ratio of the target sentence length to the source sentence length is determined by the Poisson distribution with specificλ(Meng et al., 2009). Eq. (18) shows the Poisson distribution.(18)ppoisson(J|I)=λJe−λ(J)!where J and I are the lengths of the target and source sentences, respectively. With the help of maximum likelihood estimation,λis calculated by the maximum likelihood estimation method (see (Meng et al., 2009) for more details).(19)λ=∑Is∑Jswhere Jsand Isare sth target and source sentence of the parallel corpus, respectively. Investigating 400k sentence pairs in English-Persian parallel corpus showed thatλ=1.1. Therefore, Eq. (20) calculates the target sentence score as follows:(20)score(Es,F)=log(ppoisson(N(Es)|N(F))The feature scores a translated sentence according to its length and average hypotheses length. Eq. (21) calculates the feature score.(21)score(Es,F)=log(1|N(Es)−N¯(F)|+1)whereN¯(F)is the average length of translated hypotheses of the source sentence F.This feature leads to sentences whose lengths are close to the average length of hypotheses.One of the main problems of SMT systems is missing the function words and punctuations. Therefore, the anchor matcher feature set tries to overcome the problem. This set includes Punctuation, Day, Month and Number matcher features as follows.This feature is used to handle the punctuation mismatching problem in the source and target sentences. It is calculated by Eq. (22) as follows:(22)score(Es,F)=log(1Npunc(F)∑pf∈punc(F)pe∈punc(Es)γ(pe,pf))where punc(F) is a list of the punctuation tokens of F, and Npunc(F) is the number of the punctuation tokens of F.‘Day’, ‘Month’, ‘Number’ and ‘Pronoun’ matcher features are other similar matcher features calculated by Eq. (23).(23)score(Es,F)=log(1Nanchor(F)∑pf∈anchor(F)pe∈anchor(Es)γ(pe,pf))where anchor(·) can be ‘Day’ or ‘Month’ or ‘Number’ or ‘Pronoun’. Note that for matching ‘Day’ or ‘Month’ or ‘Number’ or ‘Pronoun’, we use a bilingual dictionary. These features can potentially overcome missing function words and punctuation problems.A POS-based feature set includes a POS-based language model and a POS tag matcher feature. The features aim at overcoming the lack of the content words and wrong word order problems.A POS-based language model feature is a discriminative feature shown by Eq. (24).(24)score(Es)=log(∏p(POS(ei)|POS(ei−n−1i−1)))where POS(ei) is a POS tag of ei. Note that in this project n is set to 6. The feature aims at improving the quality of SMT output in terms of grammar. It is borrowed from (Liang et al., 2006a).This feature controls the existence of a special POS tag in both sides (source and target sides). In other words, the number of nouns, verbs, adjectives and adverbs in both sides should be the same. The difference between the number of nouns, verbs, adjectives and adverbs illustrates that the hypothesis may suffers from the lack of the content words. Therefore, this feature is employed to prefer the hypotheses that the number of the nouns, verbs, adjectives and adverbs of both sides are the same or somewhat similar.State of the art SMT systems tend to perform poorly when translating into rich morphological languages. When multiple morphemes inflect a single word stem, the total lexicon of surface forms can be enlarged, and many surface forms may occur rarely in a text, leading to a significant data sparseness problem (Popovi et al., 2006). Therefore, the morphological analysis of verbs and nouns can be useful to find the better hypothesis in the n-best list. The person (first, second, third person), number (singular vs. plural), tense (present, past, future), complex tenses (complex present, complex past, complex future), mood (indicative, imperative, subjunctive, etc.) and voice (active vs. passive) are verb and noun properties that have been extracted via morphological analysis and considered in this feature set. The score of morphological feature set is calculated by using Eq. (25).(25)score(Es,F)=log(1Nproperty(F)∑pf∈property(F)pe∈property(Es)γ(pe,pf))where property (F) returns a list of the property of verbs and nouns of F, and Nproperty(F) returns the number of the property of F. The goal of this feature is to assign higher score to the sentences so that a higher percentage of their nouns and verbs are correctly translated.In order to compare the performance of the proposed algorithm with GA, PSO, Perceptron- and averaged Perceptron-style algorithms, and also to demonstrate the effectiveness of different features on the translation quality, an English→Persian and a German→English SMT systems have been trained by an English-Persian parallel corpus called TPC33Tehran Parallel Corpus.(Mansouri and Faili, 2012) and Europarl (Koehn et al., 2005), respectively. Three evaluation scenarios have been performed with the help of two translation tasks: (1) The performance of the proposed approach has been compared to GA-, PSO- Perceptron- and averaged Perceptron-style systems. (2) The impact of feature sets has been estimated. (3) The impact of the n-best list size has been examined.First, two translation tasks and system configurations are clarified in more details. Then the evaluation scenarios are explained and the results are analyzed.Two translation tasks with different language pairs, sizes and even domains have been employed to evaluate the proposed approach. TT-EnFa is an English-Persian translation task which is trained by TPC (Mansouri and Faili, 2012). TPC is constructed by high quality English-Persian texts extracted from novel books. Table 1reports some statistics about TPC. Moreover, PCTS44Parallel Corpus Test Set.(Mansouri and Faili, 2012) is employed as development and test sets. It is a set of 400 Persian sentences which are randomly emerged from TPC and translated manually by 4 human language experts. TMC55The largest freely available monolingual corpus for Persian language – more than 250M words in total www:http:\\ece.ut.ac.ir\nlp\resources.html (emitted for blind reviewing).(Mansouri and Faili, 2012) which is also free Persian monolingual corpus is utilized to build the target 3-gram language model using the SRILM toolkit with modified Kneser–Ney smoothing (Stolcke, 2002). TT-GeEn is another translation task which is built on German→English SMT system. It utilizes dataset from workshop 2007 on statistical machine translation (WMT07). The training data contains about 50K sentences of parallel news commentary and about 1.1M sentences of Europarl (Koehn et al., 2005). We also use about 1.3M sentences out of monolingual data for language model. Newstest2007 and Newstest2006 are employed to tune and test, respectively. Basic statistics about the translation tasks are reported in Table 1. Due to the high computational cost, we have to remove sentences with more than 50 words in length.We select Moses as a baseline Phrase-based SMT (Koehn et al., 2007) which uses multiple stacks to generate translation candidates. The setting parameters are: stack size of 100, distortion limit of 6, and phrase table limit of 20. Alignments have been extracted by using the GIZA++ toolkit in words level (Och and Ney, 2003). Additionally, BLEU is used for scoring the translations (Papineni et al., 2002). All SMT systems have been optimized on development sets via minimum-error rate training (MERT) (Och, 2003) with an unique 100-best list and optimizing toward BLEU. The data set is split into 8 folds in which 7 folds are used as a development set (dev set) to optimize the setting parameters. The resulting setting is employed by the re-ranking system to re-rank the remaining fold. The algorithms are coded in C# and runs have been done on an Intel core 2 Dou CPU 1.5GHz computer with 2GB memory. All algorithms run on equivalent conditions. Specific parameter settings of the algorithms are described in Table 2. It should be noted that the initial populations of all algorithms consist of random individuals. Each experiment (for each algorithm) was repeated 10 times with different random seeds.In order to compare the performance of the Perceptron-, averaged Perceptron-, GA-, PSO- and QPSO- style algorithms, 100-best lists have been generated by SMT systems, and runs have been done with different random seeds on the development and test sets under the same conditions. Table 3reports mean, standard deviation, the worst and best solution found over 10 trials. Because of the superiority of the Perceptron-style algorithms over the minimum error rate algorithm (Shen and Joshi, 2005), the minimum error rate algorithm is not compared.In comparison to QPSO, other algorithms do not gain good results. As shown in Table 3, for TT-EnFa translation task, the best BLEU score of QPSO, PSO, GA, averaged Perceptron and Perceptron are about 32.19, 32.19, 32.19, 31.91 and 31.91, respectively. QPSO on average achieves +0.27, +0.67, +1.04, +1.03 and +1.09 point improvements in BLEU comparing to PSO, GA, averaged Perceptron, Perceptron and baseline, respectively. The standard deviation of solution values obtained by QPSO is also the smallest among all approaches. The findings of experiments on TT-GeEn have been shown that the best BLEU score of QPSO, PSO, GA, averaged Perceptron and Perceptron are about 22.42, 22.42, 21.73, 21.73, 21.73 and 21.73, respectively. QPSO on average achieves +0.42, +0.86, +1.17, +1.22 and +1.73 point improvements in BLEU comparing to PSO, GA, averaged Perceptron, Perceptron and baseline, respectively. The standard deviation of solution values obtained by QPSO and GA are about 0.09 whereas the standard deviations of other algorithms are above 0.1.In order to determine if any of the differences in the mean of the algorithms are significant, a t-test is performed over QPSO and the other algorithms. Table 4shows p-value of paired t-test with 95% confidence interval of the differences. The results illustrate that the mean of QPSO to be statistically significantly better than the mean of the other algorithms.Fig. 4compares maximum iterations required to reach the best solution for all algorithms.The results demonstrate the superiority of QPSO over all the other approaches in terms of maximum number of iterations required to reach the best solution.In general, the comparison of algorithms’ performance establishes the superiorities of QPSO-style algorithm in terms of the mean and best solution quality over the well-known algorithms. As far as the standard deviations are concerned, QPSO and PSO outperformed the others. It implies that the proposed approach is robust. A comparison of maximum iteration required indicates that QPSO and PSO are better than others in terms of convergence speed. In comparison with other mentioned algorithms, it can be argued that the only advantage of the Perceptron and averaged Perceptron is to implement the easiest ones. We run experiments by Eq. (26) as fitness function in order to compare convergence speed of Eqs. (4) and (26) as fitness functions.(26)fitness(w→)=1−BLEU(FirstBest(X¯,w→))whereX¯is the set of the n-best lists, and BLEU(·) function calculates the BLEU metric of the first best sentences with respect to the references in the development set.FirstBest(X¯,w→)also determines the first best sentences of the n-best lists,X¯, regarding to the weight vectorw→. As shown by Fig. 5, the result shows that QPSO with Eq. (4) as fitness function has bigger speed of convergence that QPSO with Eq. (26) as fitness function. Eq. (4) is needed fewer iterations to achieve good approximation.In order to explore the question which feature set contributes the most to the improvement in translation quality, we run baseline (mentioned by b66All of the used abbreviations are mentioned in Section 3.) with each feature set on the dev and test sets. Figs. 6 and 7show the results for TT-EnFa and TT-GeEn, respectively.Table 5also summarizes the impact of each feature sets.The n-best list and language model feature sets for TT-EnFa and POS and language model feature sets for TT-GeEn have the most positive impact on translation quality whereas the translation feature set has the least impact for both because of using the low quality probabilistic dictionary. The probabilistic dictionary is built by IBM model 1 aligning algorithm. Since the n-best list generated by SMT usually consists of limited set of words with less morphological diversity, the impact of the morphological feature set is not salient. The morphological feature set plays more important role when translated candidates come from different machine translation with different lexicons. One of the most important problems in English→Persian SMT is that the translated Persian sentences are much shorter than English ones, which causes to get more penalties in BLEU measuring. To overcome the problem, the length feature set has been used. Fig. 8also shows the accumulative impact of all feature sets.As shown in Fig. 8, the piecemeal addition of features to the re-ranking system (forward selection) improves its quality. The most positive impact belongs to the language model (lm) whereas translation model (tm) has no effect. The punctuation matcher feature (punc_m) is the only member of the anchor matcher feature set indicating positive effect whereas the number (num_m) and day (day_m) matcher features show no effect on BLEU score because their effects have been covered by other features. Investigating the impact of n-best feature set members shows that the n-best target position word feature (nb_tp) and n-best source position word feature (nb_sp) have positive impact whereas the Levenshtein distance feature (id) has no effect. Note that the n-best source position word feature (nb_sp) has more positive impact than the n-best target position word feature (nb_tp). Both members of length feature set proved to be positive especially the hypothesis length feature.The n-best list size is one of the most effective parameters in re-ranking system quality. To find the optimal size for the n-best list, the results of using list sizes from 50-best up to 2000-best have been compared. Fig. 9shows BLEU score on different n-best list sizes. Fig. 10shows the training time of re-ranking system. Fig. 11also presents the running time of re-ranking system. By increasing the size of the n-best list, both the quality and training time of re-ranking system do increase. Based on our results, it is figured out that using an n-best list longer than 1000 entries does not help to improve the translation quality and the difference between using 1000- and 2000-best list is neglectable.

@&#CONCLUSIONS@&#
