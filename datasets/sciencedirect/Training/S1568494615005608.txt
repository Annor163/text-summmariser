@&#MAIN-TITLE@&#
Continuous reinforcement learning to robust fault tolerant control for a class of unknown nonlinear systems

@&#HIGHLIGHTS@&#
Proposing two robust adaptive FTC systems based on machine learning approaches.Presenting adaptation laws in the sense of the proposed Lyapunov function.Using an intelligent observer for unknown nonlinear systems in presence of faults.Adapting the critic and actor of continuous RL based on the Lyapunov function.

@&#KEYPHRASES@&#
Fault tolerant control,Neural network,Continuous reinforcement learning, Actor-critic learning,Adaptive control,Variable structure control,

@&#ABSTRACT@&#
This paper proposes two strategies to design robust adaptive fault tolerant control (FTC) systems for a class of unknown n-order nonlinear systems in presence of actuator and sensor faults versus bounded unknown external disturbances. It is based on machine learning approaches which are continuous reinforcement learning (RL) and neural networks (NNs). In the first FTC strategy, an intelligent observer is designed for unknown nonlinear systems when faults occur or not. In the second strategy, a robust reinforcement learning FTC is proposed through combining reinforcement learning to treat the unknown nonlinear faulty system and nonlinear control theory to guarantee the stability and robustness of the system. Critic and actor of continuous RL are adopted based on the behavior of the defined Lyapunov function. In both strategies, to generate the residual a Gaussian radial basis function is used for an online estimation of the unknown dynamic function of the normal system. The adaptation law of the online estimator is derived in the sense of Lyapunov function which is defined based on adjustable parameters of the estimator and switching surfaces containing dynamic errors and residuals. Simulation results demonstrate the validity and feasibility of proposed FTC systems.

@&#INTRODUCTION@&#
Fault tolerant control (FTC) has been an active research topic during past two decades for increasing the safety and reliability of dynamical systems. A FTC system is capable both of automatically compensating for effects of faults and maintaining the performance of the controlled system, at some acceptable level, even in the presence of faults.There are survey papers [1–5] published for explaining the FTC problem, introducing the solving approaches, and describing the research improvements in this domain. According to [1–5], FTC systems can be classified into passive and active FTC systems. In a passive FTC system, the controller is fixed and designed to be robust against a class of presumed faults. This approach has limited fault-tolerant capabilities. Contrast of the passive FTC system, active FTC systems react to the system component faults and failures actively by reconfiguring control actions such that the stability and acceptable performance of the entire system can be maintained [4,6,7]. Normally, faults occur at two places: the actuators and sensors. Actuator faults act on the system, resulting in the deviation of the process variables. The result is the command (control) signal sent to this device has no effect. Sensor faults act on the sensors what measure the system variables, and do not directly affect the process. The source of mentioned faults could be wear and tear of the sensor leading to inaccurate readings, or a total failure of the sensor. Sensors faults could be also from drift, poor calibration, and extreme process conditions. These faults will affect the process if output measurements are used for generating the input control signal [8,9].FTC of nonlinear systems is a significant problem and can be framed as a reinforcement learning (RL) task. In RL framework, the agents can learn optimal behaviors in an unknown environment through on-line, trial and error exploration when certain conditions are satisfied [10]. Therefore, using RL techniques as a part of a controller can be an approach for regaining the loss of performance caused by the conservative design [11–14]. In the literature, a number of research results have been reported for applying RL in the continuous state and action space [15–17].The goal of this paper is to present active FTC systems based on neural networks (NNs) and RL for a class of unknown nonlinear systems in presence of actuator and sensor faults versus external disturbances. It is assumed that the input and output of the nonlinear system are merely accessible. In the first FTC strategy, a Gaussian radial basis neural network is used for observing all states of the faulty system. The adaptation law of the NN is derived in the sense of defined Lyapunov function. The FTC law has been established in the sense of Lyapunov stability theorem. In the second strategy of FTC, a robust reinforcement learning FTC is proposed through combining RL to treat the unknown nonlinear faulty system and nonlinear control theory to guarantee the stability and robustness of the system. The critic and actor are adopted based on the behavior of the defined Lyapunov function and switching surfaces ensuring the stability of the error dynamics in variable structure control. To generate the residual, the difference between the system output and the output of the normal model of the system, an online estimator is utilized for estimating the unknown dynamic function of the system. The adaptation law of the online estimator is derived in the sense of Lyapunov function defined based on the variable structure control method and adjustable parameters of the estimator. Effectiveness of proposed strategies is investigated on two benchmarks of faulty systems; a Van-Der-Pol oscillator system and a hypersonic aircraft system.The rest of this paper is organized as follows. In Section 2, FTC problem is formulated for a class of unknown nonlinear systems. In Section 3, two proposed strategies for designing the FTC systems are explained. In Section 4, the neural FTC system designed. Also, the stability is proven. Designing the reinforcement FTC system and its proof are presented in Section 5. Also, the stability of it is proven. Simulations results are presented in Section 6 to show the effectiveness of the proposed strategies. Results are discussed in this section. At the end, the paper is concluded in Section 7.The aim of the FTC system is to increase the safety and reliability of dynamical systems versus the occurrence of faults via designing control algorithms capable to maintain the stability and performance.Consider a class of n-order nonlinear systems as follow:(1)x˙1=x2x˙2=x3⋮x˙k=xk+1⋮x˙n=f(x1,x2,x3,…,xn)+uNy=x1whereX=x1,x2,…,xnT∈Rn×1is the state vector of the system assumed not available for measurements, y is the output of the system assumed to be available. f(X) is an unknown real continuous function of states, which means the dynamic function of the system. uN(t)∈R is the control input.If the nonlinear system works in normal conditions without occurring any faults and disturbances, Eq. (1) presents the normal (faultless) system. In contrast to normal system, when the system works in presence of the actuator faults, sensor faults, and bounded external excitation, the formulation of the faulty nonlinear system is as follow:(2)x˙1f=x2fx˙2f=x3f⋮x˙kf=xk+1f⋮x˙nf=f(x1f,x2f,x3f,…,xnf)+Fa+d+ufyf=x1f+FswhereXf=x1f,x2f,x3f,…,xnfTis the state vector of the faulty system assumed not to be available for measurements, yfis the output of the faulty system assumed to be available. f(Xf) is an unknown real continuous function of the faulty system's states. uf(t)∈R is the control input of the faulty system. Faand Fsare respectively the additive actuator and sensor faults. Also, it is assumed thatFa<αa, andFs<αswhere αfand αsare real positive constant parameters. d(t) is the bounded external disturbance thatd<αdwhere αdis a real positive constant parameter.The control objective of FTC is to force the state vectorXf=x1f,x2f,x3f,…,xnfTof the faulty system for following the specified desired trajectoryXd=xd,x˙d,x¨d,…,xdn−1Tas close as possible. In order to achieve the above control objective, some assumption of the nonlinear system and desired trajectory are given as; (1) The nonlinear f(Xf) is bounded if the state vector Xfis bounded, (2) The desired trajectoryXd=xd,x˙d,x¨d,⋯,xdn−1Tis bounded.Let us define the state errors of the normal and faulty systems as:EN=e1N,e2N,e3N,…,enNTandEfe1f,e2f,e3f,…,enfTbe defined asei(=1,2,…,n)N=xi(=1,2,…,n)N−xd(i−1)andei(=1,2,…,n)f=xi(=1,2,…,n)f−xd(i−1), so error dynamics of normal and faulty systems are respectively obtained as Eqs. (3) and (4):(3)e˙1N=e2Ne˙2N=e3N⋮e˙kN=ek+1N⋮e˙nN=f(x1,x2,x3,…,xn)−xd(n)+uNand(4)e˙1f=e2fe˙2f=e3f⋮e˙kf=ek+1f⋮e˙nf=f(x1f,x2f,x3f,…,xnf)+Fa+Fs(n)+d−xd(n)+ufOn the other hand, the consistency of the system with the normal model can be checked at every time t by determining the difference R=yf−yN, which is called a residual [6]. In the faultless case, the residual vanishes or is close to 0. A non-zero residual indicates the existence of faults. Let us define the residual dynamics vectorR=R1,R2,R3,…,RnTas Ri(=1,2, …,n)=y(n−1),f−y(n−1),N, so residual dynamics are obtained as follow:(5)R˙1=R2R˙2=R3⋮R˙k=Rk+1⋮R˙n=fx1f,x2f,x3f,…,xnf−fx1N,x2N,x3N,…,xnN+Fa+Fs(n)+d+uf−uNNotice that according to the definition of the tracking error vector for normal and faulty systems and the residual vector, these vectors are related by the following equation as:(6)Ef(t)=EN(t)+R(t)The control goal considered in this section is that for any given target orbit Xd(t), a FTC system is designed such that the tracking error and residual vectors satisfy the below equation:(7)limt→∞Ef(t)→0where⋅is the Euclidean norm of a vector. According to Eqs. (6) and (7) can be written as:(8)limt→∞EN(t)+R(t)→0In the next section, two strategies are presented to design efficient FTC systems.In this section, two schemes are proposed to design FTC systems for unknown nonlinear systems. Assume that the system is in presence of the actuator fault, sensor faults and external disturbances.In the first FTC scheme demonstrated in Fig. 1, an intelligent nonlinear observer is designed as a full-order observer for a class of unknown nonlinear systems when faults occur. A Gaussian radial basis neural network is used for observing all states of the system. The adaptation law of the intelligent observer is derived in the sense of Lyapunov function defined based on the variable structure control method and adjustable parameters of the neural network. The FTC law has been established in the sense of Lyapunov stability theorem. This scheme is named as neural FTC (NFTC) system.In the second FTC scheme demonstrated in Fig. 2, a robust reinforcement learning FTC is proposed through combining RL to treat the unknown nonlinear faulty system and nonlinear control theory to guarantee the stability and robustness of the system. An actor-critic method is utilized for the continuous RL. Critic and actor are adopted based on the behavior of the defined Lyapunov function and switching surfaces adopted to ensure the stability of error dynamics in variable structure control. This scheme is named as reinforcement FTC (RFTC) system.In both proposed schemes (see Figs. 1 and 2), the same strategy is utilized to generate the residual. A Gaussian radial basis function is used for an online estimation of the unknown dynamic function of the normal system. The adaptation law of the online estimator is derived in the sense of Lyapunov function defined based on switching surfaces containing dynamic errors, residuals, and adjustable parameters of the estimator.Both proposed FTC strategies use the variable structure (VS) control technique as a part of the control method. First, designing switching surfaces and the VS control are described to solve the FTC problem in the next section, and then each strategy is explained.Designing the VS control contains two steps: (1) A suitable switching surface is chosen such that the sliding motion on the sliding manifold is stable and ensures that the error vector converges to 0. (2) A robust control law is established such that it guarantees the existence of the sliding manifold which is 0.The switching surface is defined as [18]:(9)S(t)=ddt+λn−1e(t)where λ is a real positive constant parameter. The rate of convergence to the switching surface is governed by the value assigned to parameter λ. In this method, coefficients of Eq. (9) are Newtonian expanded terms, then Eq. (9) can be rewritten as the below form Eq. (10) for dynamic errors of normal and faulty systems, and the residual dynamics as:(10)SN=n−10enN+n−11λ1en−1N+⋯+n−1n−3λn−3e3N+n−1n−2λn−2e2N+n−1n−1λn−1e1NSf=n−10enf+n−11λ1en−1f+⋯+n−1n−3λn−3e3f+n−1n−2λn−2e2f+n−1n−1λn−1e1fSince the system dynamic function of the nonlinear system is unknown or perturbed in practical applications, identifying it can be beneficial to precisely control of the system. Hence, a Gaussian radial basis function (GRBF) estimator is utilized for an online approximation of the unknown dynamic function.The GRBF estimator can be designed as one layer feed forward neural network with nonlinear element. The GRBF estimator output can perform the mapping according to:(11)fest.(z)=∑j=1rwjGj(zj,cj,σj)where z=[z1, z2, …, zm]T∈Rnis the input vector, Gj(zj, cj, σj)∈Rn, j=1, 2, …, m is the Gaussian radial basis function, wjis the weight of the output layer, σj∈R is the spread of Gaussian function, cjis the mean value of Gaussian function and m is the number of neurons. Each Gaussian radial basis function can be presented by:(12)Gj(zj,cj,σj)=expzj−cj2σj2Let Eq. (11) be in a compact vector form as:(13)fest.(z,w,c,σ)=wnTGn(z,c,σ)wherewn=[w1,w2,…,wm]T, Gn=[G1, G2, …, Gm]T, c=[c1, c2, …, cm]T, and σ=[σ1, σ2, …, σm]T.There exists an ideal GRBF estimator f* such that satisfies the universal approximation theorem:(14)fest.=f∗(z)+Δ=wn*TGn(z,c∗,σ∗)where Δ represents the approximation error. It is assumed to be bounded. w*, c* and σ* are respectively the optimal parameter vectors of w, c and σ. The optimal parameter vectors, which are required for the best approximation of a given nonlinear function, are demanding to determine. Therefore, the estimate function can be presented as:(15)fˆn(z,wˆn,cˆ,σˆ)=wˆnTGn(z,cˆ,σˆ)wherewˆ,mˆandσˆare the estimation of w*, c* and σ*, respectively. For notational convenience let us denote:(16)Gn*=Gn(z,c∗,σ∗)and(17)Gˆn=Gn(z,cˆ,σˆ)Let us define(18)w˜n=wn*−w˜nNotice that optimal values are not unique.The adaptation law of the online estimator is derived in the sense of defined Lyapunov function which involves the switching surfaces and adjustable parameters of the estimator. Which is presented in the next section.Therefore, the model of normal system is calculated as follows:(19)xˆ˙1N=xˆ2Nxˆ˙2N=xˆ3N⋮xˆ˙kN=xˆk+1N⋮xˆ˙nN=fest.(XˆN)+uNyˆN=xˆ1NwhereXˆN=xˆ1N,xˆ2N,…,xˆnNT∈Rn×1is the estimated state vector of the normal system and available,yˆNis the estimated output of the system.fest.(XˆN)is an estimation of the dynamic function obtained via the on-line GRBF estimator. uN(t)∈R is the control input of the system.Consider the faulty system presented in Eq. (2). As mentioned before, the input and output of the system are accessible. An intelligent observer is designed for a class of unknown nonlinear faulty systems. A Gaussian radial basis neural network (GRBF-NN) is used for observing all states of the system. The GRBF-NN structure is the same as what is presented in the previous section. The GRBF-NN output can perform according to the compact from as:(20)fobs.(z,w,c,σ)=wfTGf(z,c,σ)where z=[z1, z2, …, zm]T∈Rnis the input vector,wf=[w1,w2,…,wm]Tis the weight vector of the output layer, Gf=[G1, G2, …, Gm]Tis the Gaussian radial basis function, σ=[σ1, σ2, …, σm]Tis the spread of Gaussian function, c=[c1, c2, …, cm]Tis the mean value of Gaussian function and m is the number of neurons. So, an estimate function is defined as:(21)fˆf(z,wˆf,cˆ,σˆ)=wˆfTGf(z,cˆ,σˆ)wherewˆ,cˆandσˆare the estimation of w*, c* and σ*, respectively. Let us define(22)w˜f=wf*−wˆfNotice that optimal values are not unique.The adaptation law of the intelligent observer for the faulty system is derived in the sense of defined Lyapunov function based on switching surfaces and adjustable parameters of the estimator. It is presented in the next section.Therefore, by using the designed observer, the observed state vectorXˆf=xˆ1f,xˆ2f,xˆ3f,…,xˆnfTof the faulty system is obtained and accessible.As mentioned above, residuals and its dynamics can be calculated by the estimated state vectorXˆNof the normal system and the observed state vectorXˆfof the faulty system.Using RL technique, the agent can learn how to act as maximizing the sum of rewards in an unknown environment through trial and error exploration. From the reward function, each action is evaluated and an optimal policy π∗ is derived. The π∗ is obtained as:π∗=argamaxV(s)=argamaxEπ∑k=0∞γkrt+k+1St=S, where r is the reward, and γ is the discount factor, Strepresents the current states. In this study, a continuous actor-critic learning agent is adopted to handle continuous nonlinear systems.The actor learns the control law to maximize the sum of the expected reward. The proposed system learns that the actor becomes the optimal controller in meaning of getting the great tracking performance. Both actor and critic are constructed by NNs. Both NNs are updated by using TD error; therefore it can learn continuous state variables (different from the use of Q-table).Actor: It is constructed for the FTC system to create the great tracking performance by using learning through observing control results of the FTC. The actor is constructed by GRBF-NN, and ɛ - greedy method is used as the policy of the actor for decisions of the behavior, so RL actor signal is expressed as:(23)uR=wactTGact(z,c,σ),prob.(1−ε)wactTGact(z,c,σ)+nR,prob.(ε)where z=[z1, z2, …, zm]T∈Rnis the input vector,wact=[w1,w2,…,wm]Tis the weight vector of the output layer, Gact=[G1, G2, …, Gm]Tis the Gaussian radial basis function, σ=[σ1, σ2, …, σm]Tis the spread of Gaussian function, c=[c1, c2, …, cm]Tis the mean value of Gaussian function and m is the number of neurons. nRis a noise for searching of the optimal signal. ɛ is a rate of exploration.Critic: It calculates the expected reward P. Then, the critic is adjusted to make TD error decrease. The critic is constructed by GRBF-NN, and the expected reward P(t) is as:(24)P(t)=wcTGc(z,c,σ)TD error: The actor and critic learning use the TD error. TD error is as:(25)rˆ(t)=r(t)+γP(t+1)−P(t)where r is the reward, γ(0<γ≤1) is the discount rate.As shown in Fig. 1, the control system provides the normal control input uNand the tolerant control input uT, then the suitable control input to apply the faulty system is calculated as follows:(26)uf=uN+uTTheorem 1Consider the FTC problem presented by Eq.(4). If the control input uf(t) is suitably designed as Eq.(26), such that the normal control input uNand the tolerant input control uTare designed as:(27)uN=−ηNsgnSN−n−10fˆn(XˆN)−xd(n)−n−11λ1enN−⋯−n−1n−2λn−2e3N−n−1n−1λn−1e2N(28)uT=−ηRsgnSR−n−10fˆf(Xˆf)−fˆn(XˆN)−n−11λ1Rn−⋯−n−1n−3λn−3R4−n−1n−2λn−2R3−n−1n−1λn−1R2wherefˆn(XˆN)=fest.(XˆN)is obtained via the online model of the normal system presented in Eq.(19),fˆf(Xˆf)=fobs.(Xˆf)is obtained via the intelligent observer of the faulty system. In addition, SNand SRare the switching surfaces defined in Eq.(10). ηN, ηRand λ are positive constant parameters, and ηR≫(αa+αs+αd).The adaptation law of the online estimator for modeling the normal system is as follows:(29)wˆ˙n=−w˜˙n=SN−SRGn(⋅)where Gnis the GRBF presented in Eq.(15). SNand SRare the switching surfaces defined in Eq.(10).Moreover, the adaptation law of the intelligent observer for the faulty system is as follows:(30)wˆ˙f=−w˜˙f=SRGf(⋅)where Gfis the GRBF presented in Eq.(20). SNand SRare the switching surfaces defined in Eq.(10).Then, the tracking error and residual dynamics will asymptotically converge to 0. Eqs.(7) and (8)will be satisfied.Define a Lyapunov function as:(31)VT=12SN2+12SR2+12w˜nTw˜n+12w˜fTw˜fwhere SNand SRare the switching surfaces defined in Eq. (10).w˜nis the weighted error vector (presented in Eq. (18) of the adjustable parameters) of the online estimator for modeling the normal system, andw˜fis the weighted error vector (presented in Eq. (22) of the adjustable parameters) of the online estimator for modeling the normal system.Differentiating Eq. (31) with respect to time is defined as:(32)V˙T=SNS˙N+SRS˙R+w˜nTw˜˙n+w˜fTw˜˙fAs mentioned above, SNand SRare the switching surfaces defined in Eq. (10). So, the first derivative of Eq. (10) with respect to time is:(33)S˙N=n−10e˙nN+n−11λ1enN+⋯+n−1n−3λn−3e4N+n−1n−2λn−2e3N+n−1n−1λn−1e2N(34)S˙R=n−10R˙n+n−11λ1Rn+⋯+n−1n−3λn−3R4+n−1n−2λn−2R3+n−1n−1λn−1R2By substituting Eqs. (3) and (5) respectively into Eqs. (33) and (34), we have:(35)S˙N=n−10f(XN)−xd(n)+uN+n−11λ1enN+⋯+n−1n−3λn−3e4N+n−1n−2λn−2e3N+n−1n−1λn−1e2N(36)S˙R=n−10f(Xf)−f(XN)+n−10Fa+Fs(n)+d+uf−uN+n−11λ1Rn+⋯+n−1n−3λn−3R4+n−1n−2λn−2R3+n−1n−1λn−1R2Substituting Eqs. (35) and (36) into Eq. (32), it can be written as:(37)V˙T=SNn−10f(XN)−xd(n)+uN+SNn−11λ1enN+⋯+SNn−1n−3λn−3e4N+SNn−1n−2λn−2e3N+SNn−1n−1λn−1e2N+SRn−10f(Xf)−f(XN)+SRn−10Fa+Fs(n)+d+uf−uN+SRn−11λ1Rn+⋯+SRn−1n−3λn−3R4+SRn−1n−2λn−2R3+SRn−1n−1λn−1R2+w˜nTw˜˙n+w˜fTw˜˙fLet(38)uf=uN+uTwhere,(39)uN=−ηNsgnSN−n−10fˆn(XˆN)−xd(n)−n−11λ1enN−⋯−n−1n−2λn−2e3N−n−1n−1λn−1e2N(40)uT=−ηRsgnSR−n−10fˆf(Xˆf)−fˆn(XˆN)−n−11λ1Rn−⋯−n−1n−3λn−3R4−n−1n−2λn−2R3−n−1n−1λn−1R2Notice thatfˆn(XˆN)=fest.(XˆN)is obtained via the online model of the normal system presented in Eq. (19). Also,fˆf(Xˆf)=fobs.(Xˆf)is obtained via the intelligent observer of the faulty system. ηNand ηRare positive constant parameters.Then, by substituting Eq. (38) into Eq. (37), it can be rewritten as:(41)V˙T=−ηNSN−ηRSR+w˜nTw˜˙n+w˜fTw˜˙f+SNn−10f(XN)−fˆn(XˆN)+SRn−10f(Xf)−fˆf(Xˆf)+SRn−10Fa+Fs(n)+d−SRn−10f(XN)−fˆn(XˆN)Eq. (41) can be rewritten in simplified form as:(42)V˙T=−ηNSN−ηRSR+w˜nTw˜˙n+w˜fTw˜˙f+SN−SRf(XN)−fˆn(XˆN)+SRn−10f(Xf)−fˆf(Xf)+SRn−10Fa+Fs(n)+dLetf(XN)=wn∗TGn(⋅)andfˆn(XˆN)=wˆnTGn(⋅), then:(43)f(XN)−fˆn(XˆN)=wn∗T−wˆnTGn(⋅)=w˜nTGn(⋅)Similar to the above mentioned way,(44)f(Xf)−fˆf(Xˆf)=wf∗T−wˆfTGf(⋅)=w˜fTGf(⋅)Then, by substituting Eqs. (43) and (44) into Eq. (42), it can be rewritten as:(45)V˙T=−ηNSN−ηRSR+SN−SRw˜nTGn(⋅)+SRw˜fTGf(⋅)+SRFa+Fs(n)+d+w˜nTw˜˙n+w˜fTw˜˙fEq. (45) can be rewritten in simplified form as:(46)V˙T=−ηNSN−ηRSR+w˜nTSN−SRGn(⋅)+w˜˙n+w˜fTSRGf(⋅)+w˜˙f+SRFa+Fs(n)+dIf the adaptation laws of the online estimator and the intelligent observer are considered as:(47)wˆ˙n=−w˜˙n=SN−SRGn(⋅)(48)wˆ˙f=−w˜˙f=SRGf(⋅)Then, by substituting Eqs. (47) and (48) into Eq. (46), it can be rewritten as:(49)V˙T=−ηNSN−ηRSR<0where ηNand ηRare positive constant parameters such that ηR≺(αa+αs+αd).Therefore, the normal and tolerant control inputs designed in Eqs. (39) and (40) by considering the adaptation laws of the online estimator and the intelligent observer obtained in Eqs. (47) and (48) will asymptotically stabilize the faulty system. Tracking error and residual dynamics will converge to 0. Due to the fact that Eq. (8) is satisfied, Eq. (7) is satisfied. Also, weights of the GRBF estimator and GRBF-NN will converge to optimal values.As shown in Fig. 2, the control system provides the normal control input uNand the tolerant input control uT, then the suitable input control to apply the faulty system is calculated as Eq. (26).Theorem 2Consider the FTC problem presented by Eq. (4). If the control input uf(t) is suitably designed as Eq.(26), such that the normal control input uNis designed as Eq.(27)and the tolerant control input uTis designed as:(50)uT=−uR−ηRsgnSRwhere uRis the RL actor presented in Eq.(23). In addition, SRis the switching surface defined in Eq.(10). ηRis a positive constant parameter.The adaptation law of the online estimator for modeling the normal system is as follows:(51)wˆ˙n=−w˜˙n=SNGn(⋅)where Gnis the GRBF presented in Eq.(15). SNis the switching surfaces defined in Eq.(10).If the reward signal for RL agent is as:(52)r(t)=−λRSRS˙Rwhere SRandS˙Rpresented respectively in Eqs.(10) and (36)are the defined switching surface based on residual dynamics and its first derivation with respect to time. λRis a positive constant parameter. The adaptation laws of actor and critic neural networks are as:(53)Δwact=−ηaλRrˆ(t)SRGact(⋅)(54)Δwc=−ηcrˆ(t)Gc(⋅)where Gactand Gcis the GRBF presented in Eqs.(23) and (24), respectively. SRis the switching surfaces defined in Eq.(10).rˆ(t)is the TD error presented in Eq.(25). ηaand ηcare the learning rates. Then, tracking error and residual dynamics will asymptotically converge to 0. Eqs.(7) and (8)will be satisfied.Before starting to prove Theorem 2, let us express the below lemma. It explains the reaching condition of the switching mode.LemmaThe motions of the switching surfaces presented in Eq.(9)are asymptotically stable, if the following reaching condition is satisfied:(55)S(t)⋅S˙(t)<0Proof of the LemmaLet us define the Lyapunov function as:(56)V(t)=12S2(t)According to Lyapunov stability theory, condition presented in Eq. (55) ensures that(57)V˙(t)=S(t)⋅S˙(t)<0Then, S(t) is toward the switching surface and the switching mode, Eq. (9) is asymptotically stable.To prove Theorem 2, Let us define a Lyapunov function as:(58)VT=12SN2+12SR2+12w˜nTw˜nwhere SNand SRare the switching surfaces defined in Eq. (10).w˜nis the weighted error vector (presented in Eq. (18) of the adjustable parameters) of the online estimator for modeling the normal system. Eq. (58) can be rewritten as:(59)VT=VN+VRwhere(60)VN=12SN2+12w˜nTw˜nand(61)VR=12SR2Differentiating Eqs. (60) and (61) with respect to time is defined as:(62)V˙N=SNS˙N+w˜nTw˜˙n(63)V˙R=SRS˙RAs mentioned above, SNand SRare switching surfaces defined in Eq. (10). So, the first derivative of it is presented in Eqs. (35) and (36). Substituting Eq. (35) into Eq. (62), it can be written as:(64)V˙N=SNn−10f(XN)−xd(n)+uN+SNn−11λ1enN+⋯+SNn−1n−3λn−3e4N+SNn−1n−2λn−2e3N+SNn−1n−1λn−1e2N+w˜nTw˜˙nLet us substitute Eq. (27) into Eq. (64):(65)V˙N=−ηNSN+SNf(XN)−fˆn(XˆN)+w˜nTw˜˙nwhere ηNis a positive constant parameter.Substituting Eq. (43) into Eq. (65):(66)V˙N=−ηNSN+w˜nTSN−SRGn(⋅)+w˜˙nIf the adaptation laws of the online estimator is considered as:(67)wˆ˙n=−w˜˙n=SNGn(⋅)Then, by substituting Eq. (67) into Eq. (66), it can be rewritten as:(68)V˙N=−ηNSN<0where ηNis a positive constant parameter.According to the mentioned Lemma, the switching surface is asymptotically stable if the hitting condition presented in Eq. (55) is satisfied. So, the reward signal is defined as:(69)r(t)=−λRSRS˙Rwhere SRandS˙Rpresented respectively in Eqs. (10) and (35) are defined switching surfaces based on the residual dynamics, and its first derivation with respect to time. λRis a positive constant parameter.If the hitting condition(SR⋅S˙R<0)is satisfied, then the reward signal has a positive value. If the hitting condition is not satisfied such that(SR⋅S˙R>0), then the reward signal has a negative value. Also, if(SR⋅S˙R=0), then the reward signal is equal to 0. It means that the switching surface is converged to 0.Since the RL agent learns in order to increase the expected reward, the hitting condition will be satisfied. Therefore,(70)V˙R=SRS˙R<0According to Eqs. (68) and (70),(71)V˙T=V˙N+V˙R<0Learning algorithm to adopt the critic and actorLearning of the critic is carried out in order to decrease the TD error, and that of the Actor is carried out in order to increase the expected reward. As a result, the actor gains the output property to get high reward. In this study, learning of actor and critic NNs are based on the error back propagation (BP) algorithm. The evaluation function of BP is as:(72)E(t)=12rˆ2(t)Specifically, neural networks learn by updating weights of connections as:(73)Δwact=−ηa∂E∂wact=−ηa∂E∂rˆ⋅∂rˆ∂r⋅∂r∂S˙R⋅∂S˙R∂uf⋅∂uf∂uT⋅∂uT∂uR⋅∂uR∂wact=−ηaλarˆ(t)SRGact(⋅)(74)Δwc=−ηc∂E∂wc=−ηc∂E∂rˆ⋅∂rˆ∂P⋅∂P∂wc=−ηcrˆ(t)Gc(⋅)where Gactand Gcare the GRBF presented in Eqs. (23) and (24), respectively. SRis the switching surface defined in Eq. (10).rˆ(t)is the TD error presented in Eq. (25). ηaand ηcare the learning rates.Therefore, the normal and tolerant control inputs designed in Eqs. (27) and (50) by considering the adaptation law of the online estimator in Eq. (67) will asymptotically stabilize the faulty system and tracking error and residual dynamics will converge to 0. Due to the fact that Eq. (8) is satisfied, Eq. (7) is satisfied. Also, the weights of the GRBF estimator, critic and actor NNs will converge to optimal values.For a class of unknown nonlinear systems in presence of unknown actuator and senor faults, the design procedures are developed via combining machine learning approaches and classic control based on Lyapunov stability theory which can realize the fault tolerant. To show the effectiveness of proposed strategies, comprehensive simulation studies are presented in this section. Van Der Pol oscillator and Hypersonic aircraft systems are presented as examples for detailed description. These applications are particularly important in order to point out the applicability of proposed methods to unknown nonlinear systems.In this study, actuator and sensor faults are considered as intermittent faults. Results obtained via all experiments are written in discussion section, but some figures are presented. Fault effects are additive on the process model. The proposed FTC strategies are active FTC systems. Actuator and sensor faults are assumed to be bounded as:fa(t)≤αa,fs(t)≤αswhere αa, αsare the positive constant values which are the maximum power of actuator and sensor faults occur in the nonlinear system.Example 1 Van Der Pol oscillatorIn this section, proposed FTC schemes are simulated on a nonlinear second-order dynamic system, the Van Der Pol oscillator, described by [19]:(75)x¨+2ωςcy2−1x˙+ω2x=u+βt−T0ϕxwhere ω, ς, and c are positive constant parameters. u is the control input. β represents the time profile of a fault and ϕ is the system due to the fault. Notice, ϕ(x)=θsin(x), whereθ∈−1.51.5. Eq. (75) can be rewritten as follows:(76)x˙1=x2x˙2=f(x1,x2)+Fa+uy=x1+Fswhere x1=x,x2=x˙are state variables,f(x1,x2)=2ωςcx12−1x2+ω2x1, Fa=β(t−T0)ϕ(x1),Fa<αa, andFs<αs. αaand αsare positive constant parameters which are the maximum power of actuator and sensor faults. The simulation is performed with the following nominal system parameters: ω=0.9, ς=0.9, c=0.95. The initial condition of the systems is as:x1(0)x2(0)T=[1−1]T. The desired trajectories are defined as regular and periodic trajectories.The system is in presence of actuator and sensor faults demonstrated in Fig. 3(a) and (b), respectively. Figs. 4–7are related to faults shown in Fig. 3 when the regularization of the output is considered. The system output regulated via NFTC and RFTC are demonstrated in Fig. 4. Control efforts of the NFTC and RFTC systems are shown Fig. 5. Switching surfaces based on residuals depicted in Fig. 6(a) converge asymptotically to 0. Also, residuals are shown in Fig. 6(b). Modeling errors of the normal system via NFTC and RFTC are illustrated in Fig. 7(a). In addition, the error of the intelligent observation of the faulty system via NFTC is demonstrated in Fig. 7(b).Figs. 8–11are related to faults shown in Fig. 3 when the periodic trajectory is considered as a desired trajectory. Fig. 8 shows that the system output tracks the desired trajectory via NFTC and RFTC systems. Control efforts of the NFTC and RFTC systems are shown in Fig. 9. Switching surfaces based on the residuals illustrated in Fig. 10(a) converge asymptotically to 0. Also, residuals are depicted in Fig. 10(b). Modeling errors of the normal system via NFTC and RFTC are illustrated in Fig. 11(a). In addition the error of the intelligent observation of the faulty system via NFTC is demonstrated in Fig. 11(b).The proposed schemes are simulated on a nonlinear longitudinal model of hypersonic aircraft cruising at a velocity of 15mach, at an altitude of 110,000ft. The control objective is to track a desired trajectory in presence of various modeling uncertainties and elevator segment failures. The nominal model of the system is [20–22]:(77)α˙=q−γ˙q˙=MyyIyyγ˙=L+TsinαmV−(μ−V2r)cosγVr2where α and γ are angles of attack and flight-path, respectively. V is velocity and q is pitch rate. T is thrust and L is Lift. r is the distance from the center of the earth. Myyis the pitching moment and Iyyis the moment of inertia. Details of the full order model can be found in [23].As modeling uncertainties are inherent to any realistic system model, unmatched uncertainties will be introduced in order to make the simulation studies more meaningful. The state space representation is given by(78)x˙1=x2x˙2=x3x˙3=f(x1,x2,x3)+g(x1,x2,x3)u+Fay=x1+Fswhere x1=γ,x2=−a10γ˙sin(γ)−a1α˙−a2α˙cos(α),x3=−a10γ¨sin(γ)−a10γ˙2cos(γ)−a1α¨−a2α¨cos(α)+a2α˙2sin(α), and f(x1, x2, x3) and g(x1, x2, x3)=−a1b−a2bcos(α) is calculated from Eqs. (5) and (6).Notice,a1=−0.0427,a2=−3.4496×10−4,a3=5×10−5,a4=0.0014,a5=−4.2006a6=1.0821,a7=−3.6896,a8=0.1637,a9=−0.1242,a10=0.0014,b=0.8.u is the control input.Fa<αaandFs<αs. αa, αfand αsare positive constant parameters which are the maximum power of actuator and sensor faults which happen in the system. The initial condition of the systems is defined as:x1(0)x2(0)x3(0)T=[1−1−1]T. The desired trajectory is defined as a periodic trajectory. The system is in presence of actuator and sensor faults demonstrated in Fig. 12(a) and Fig. 12(b), respectively. Figs. 13–15are related to faults shown in Fig. 12. Moreover, Fig. 13 shows that the system output tracks the desired trajectory via NFTC and RFTC systems. Control efforts of the NFTC and RFTC systems are shown Fig. 14. Switching surfaces based on the residuals illustrated in Fig. 15(a) converge asymptotically to 0.Simulation results confirm that proposed FTC strategies have good performances. FTC objectives are satisfied.In presence of intermittent actuator faults, reinforcement FTC system can compensate faults better than neural FTC system. Despite actuator faults, when intermittent sensor faults happen, neural FTC system performs better than reinforcement FTC system. So, the sensor fault effect on the performance of the faulty system controlled via neural FTC system is smoother than the performance of the faulty system controlled via reinforcement FTC system. Moreover, in presence of large sensor faults occur, the faulty system controlled via reinforcement FTC system cannot tolerate faults. Hence, the system output does not converge to the bounded value.

@&#CONCLUSIONS@&#
