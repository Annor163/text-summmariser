@&#MAIN-TITLE@&#
Local histogram specification for face recognition under varying lighting conditions

@&#HIGHLIGHTS@&#
We improve the TT preprocessing method using local histogram specification.Our methods can remove both the low and high frequency illuminations on face images.Our methods can enhance face features lying in the low frequency part of face images.We report the recognition rate of 81.6% on the CAS-PEAL-R1 database.

@&#KEYPHRASES@&#
Local histogram specification,Local histogram statistics,Face recognition,High frequency illumination,Low frequency face features,

@&#ABSTRACT@&#
High frequency illumination and low frequency face features bring difficulties for most of the state-of-the-art face image preprocessors. In this paper, we propose two methods based on Local Histogram Specification (LHS) to preprocess face images under varying lighting conditions. The proposed methods are able to significantly remove both the low and high frequency parts of illumination on face images, as well as enhance face features lying in the low frequency part. Specifically, we first apply a high-pass filter on a face image to filter the low frequency illumination. Then, local histograms and local histogram statistics are learned from normal lighting images. In our first method, LHS is applied on the entire image. By contrast, in the second method, the regions contain high frequency illumination and weak face features on a face image are identified by local histogram statistics, before LHS is applied on these regions to eliminate high frequency illumination and enhance weak face features. Experimental results on the CMU PIE, Extended Yale B and CAS-PEAL-R1 databases demonstrate the effectiveness and efficiency of our methods.

@&#INTRODUCTION@&#
Face recognition is one of the most popular issues in the area of pattern recognition, computer vision, etc. Making face images robust to illumination variations is one of the most challenging and crucial problems in the field of face recognition, and it has been proven that the variation caused by illumination is more significant than the intrinsic face features among individuals [1]. To address this problem, many approaches against varying lighting conditions have been proposed for face recognition during the past few decades. These methods can be briefly divided into three categories: appearance-based ones, normalization-based ones and illumination-insensitive extraction based ones.The appearance-based ones aim to represent the original images in a subspace that is robust to illumination variations, such as dimensionality reduction (DR) methods: eigenfaces [2], fisherfaces [3], laplacianfaces [4], etc. However, these methods are general DR methods, and are not specific tactics to tackle illumination variations. To analyze illumination variations, Belhumeur and Kriegman [5] proved that a convex object with a Lambertian reflectance function, illuminated by an arbitrary number of point light sources at infinity, forms an illumination cone. In Ref. [6], Chen et al. proved that illumination invariants do not exist for an object with Lambertian reflectance. Based on the illumination cone models, Georghiades et al. [7] reconstructed the shape and albedo of a face using a generalized bas-relief (GBR) transformation [8], and the construction, in turn, could be used to synthesize images of the face in novel poses and illumination conditions. By representing lighting using spherical harmonics, Basri and Jacobs [9] proved that images of Lambertian objects under a wide variety of lighting conditions lie close to a 9D linear subspace. Ramamoorthi [10] showed, under appropriate assumptions, that the principal components of the images produced by an object are identical to the spherical harmonics. Zhang and Samaras [11] proposed two methods for face recognition under arbitrary unknown lighting. The first method estimated the spherical harmonic basis images from just one image taken under arbitrary illumination conditions by learning a statistical model based on a collection of 2D basis images. The second method combined the spherical harmonic illumination representation and a 3D morphable model [12] of human faces to recover basis images from images across both poses and illumination. The above-mentioned methods either need a number of training images under various lighting conditions to construct basis images spanning the illumination space for an object, or require the 3D information to estimate the albedo of a face image. However, gathering face images under various lighting conditions is difficult in practice and collecting the 3D scans of a face increases the cost of a practical face recognition system.The normalization-based ones try to adjust the images to a normal lighting condition. Histogram Equalization (HE) [13] and Histogram Specification/Matching (HS/HM) [13] are two basic methods in this category. HE aims to transform the histogram of an input image to have the uniform distribution, while HS attempts to transform the histogram of an input image to a specified shape. However, in the discrete case, HS cannot produce exact histograms. The exact histogram specification (EHS) [14] and its variants [15–17] are proposed to transform the histogram of the original image exactly to a desired shape. Compared to global HE and HS, the Local/Adaptive HE (LHE/AHE) [13,18] and Local HS/HM (LHS/LHM) [13,19–24] are more powerful and flexible. Villegas et al. [21,22] applied the LHS, LHM, and Local Normal Distribution (LNORM) to preprocess face images prior to feature extraction. In LHM [21,22], histograms of local regions of a well illuminated average face are used as the specified histograms, and all the pixels in each sliding window need to be transformed. Besides, Wang et al. [25] proposed the Self-Quotient Image (SQI), where a weighted Gaussian filter is designed to filter the low frequency part of an image by referencing one smoothed image. Chen et al. [26] proposed the LTV model to further improve SQI by enhancing its edge-preserving ability and lessening its parameter selection problem. Lee et al. [27] proposed the Oriented Local Histogram Equalization (OLHE) for illumination compensation in face recognition. Instead of transforming the central pixel in each sliding window in LHE, OLHE transforms the pixels along the eight directions around the central pixel in the sliding window. OLHE can catch the edge orientations of face images. However, due to the drawbacks of HE, such as noise amplification, OLHE is not able to deal with face images under extreme lighting conditions very well (see Fig. 11 IV).The illumination-insensitive extraction based ones extract the outline of a face image, such as geometrical or derivative features, e.g., the Local Binary Patterns (LBP) [28,29], Gabor features [30–33], etc. The TT [34] proposed by Tan and Triggs, the Retina filter [35] and the natural delighting filters (NDF) [36] are effective methods which belong to this category, providing the state-of-the-art recognition rates on some standard illumination variation datasets. TT and the Retina filter both employ the Difference of Gaussian (DoG) filter to eliminate low frequency illumination. NDF is based on Wiener filter in the frequency domain to best separate the illumination-invariant features from an image. However, as stated in Ref. [34], although TT significantly reduces the influence of lighting variations, it cannot completely remove the effects of hard shadowing, because some face features, that are originally supposed to lie in the high frequency part of the spectrum, may be severely compressed due to extreme lighting conditions so that they distribute in the low frequency part (see Fig. 1(a)). This is also supported by the recently proposed [36,37]. Therefore, when DoG is performed on such images, these face features might be impaired or even filtered. Moreover, illumination may exist in the high frequency part of the spectrum of face images (e.g. the obvious boundaries between dark and bright regions of the original images). Fig. 1(b) shows an image preprocessed by TT. Remarkably, there are two evident zero-crossing impulses on the TT-preprocessed image (see the white box in Fig. 1(b)). Because DoG tends to let the high frequency signal pass, the obvious boundaries between dark and bright regions of original images will always result in evident zero-crossing impulses on the processed images. As a result, it is the fact that face features have weak low frequencies and illumination has weak high frequencies that bring about the difficulty to design methods robust to illumination variations.This paper is an extended version of Ref. [24] and mainly deals with face recognition under varying lighting conditions. To this end, we try to eliminate both the low frequency and the high frequency illumination, and enhance the weak features on face images. We have three main contributions in this paper:1)We apply local histograms specification for local illumination normalization on face images.We introduce the local histogram statistics to detect the high frequency illumination and low frequency face features on face images.We report the state-of-the-art recognition rate of 81.6% on the CAS-PEAL-R1 database under the standard experimental protocol [38].Since TT is able to remove low frequency part of illumination, we first adopt TT to preprocess the images to filter low frequency illumination. Then, local histograms and local histogram statistics are learned from the ideal face images (face images captured under the controlled normal lighting conditions). In our first proposed method, LHS is applied on the entire image using the learned local histograms as the specified histograms. By contrast, in the second method, the regions contain high frequency illumination and weak face features on a face image are identified by the local histogram statistics, before LHS is applied on these regions to eliminate high frequency illumination and enhance the weak face features. The two main benefits of our methods are that: 1) both the low and high frequency parts of illumination on face images are dramatically reduced; and 2) intrinsic face features lying in the low frequency part of face images can also be enhanced. Experimental results on the CMU PIE [39], Extended Yale B [40] and CAS-PEAL-R1 databases [38] demonstrate the effectiveness and efficiency of our methods.In the rest of this paper, we review histogram specification (HS) in Section 2. In Sections 3 and 4, we introduce the two versions of our proposed methods. Section 5 discusses some issues on the ideal face images. Experimental results are presented in Section 6 and finally we draw some conclusions in Section 7.Histogram specification (HS) [13] is an effective image enhancement technique. Let u={uij} be a H×W discrete input digital image with L gray levels, and letL={0,1,…,L−1}. The histogram or gray level probability density of an image is defined by(1)pul=NlN,∀l∈Lwhere N=H×W, and Nlis the number of pixels that have gray level l. The cumulative distribution function (CDF) of puis given by(2)Pux=∑k=0xpuk,∀x∈L.Let Pv(y),∀y∈L, be the specified CDF. HS attempts to find a transformation function y=F(x) to map the gray level x in the original image to y so that the transformed image could have the similar histogram as the specified one. In order to preserve the intrinsic information of the original image, function F should be the monotonically increasing function. Such a function can be found by the following equation:(3)Pvy=Pux.Hence, the mapped gray level y can be obtained by:(4)y=Pv−1Pux.where Pv−1 denotes the inverse function of Pv. Thus, the transformation function is F(⋅)=Pv−1[Pu(⋅)].In the discrete case, the inverse function of Pvtypically does not exist. Eqs. (3) and (4) are usually replaced by the following optimal objective function to approximate y for a particular gray level x:(5)y=argmink|Pux−Pvk|.With such a transformation rule, each gray level x is able to be mapped to y. Thus, the mapped image would have the histogram close to a desired one.In this section, we propose the Local Histogram Specification using Learned local histograms (LHS-L) from the ideal face images for face recognition. Since TT is able to remove the low frequency part of illumination, we first adopt TT to eliminate the low frequency illumination on face images.As LHS-L is performed on local regions of an image, the size of a window will be (2r+1)×(2r+1) if we name r the “radius” of the window. Such a window will not be too small, so the borders of an image should not be neglected. In this paper, we address this problem by attaching borders to the images. The attached borders are filled by the pixels of the inner borders (see Fig. 2(a) for details). Note that the size of the bordered image is (H+2r)×(W+2r), and in the bordered image, the coordinates range in (1−r,H+r) vertically and (1−r,W+r) horizontally, where H and W denote the height and width of the original image, respectively.In LHS-L, each standard histogram corresponding to each window of the face images needs to be specified. These histograms could be learned from the ideal face images.Given a set of ideal face images I={I1,I2,…,In} and Ik∈LH×W,k=1,2,…,n, we use the method described in the previous subsection to get their bordered images X={X1,X2,…,Xn}, Xk∈L(H+2r)×(W+2r), and k=1,2,…,n. Thus, the window centered at (i,j) with a radius r in image Xkcan be expressed as Xij(k)=Xk(i−r:i+r,j−r:j+r) andij∈A≡12…H×12…W. LetB={1−r,…,H+r}×{1−r,…,W+r} be the set of coordinates of the bordered image. The set of coordinates within a window centered at (i,j) with a radius r is given by:(6)Sijr=uv|uv∈B∧|u−i|≤r∧|v−j|≤r~~(i,j)∈A.Apparently,|Sijr|=2r+12. Note that, for a set, |⋅| denotes the cardinality of the set. The histogram of window Xij(k) is defined as(7)hijkl=uv|uv∈Sijr∧xuvk=lSijr,∀l∈L.The local normalized histogram hij={hij(0),hij(1),…,hij(L−1)} of a local region of all the ideal face images is learned by(8)hijl=1n∑k=1nhijkl,∀l∈L.It can be verified that Σl=0L−1hij(l)=1.Essentially, hij(l) is the frequency of gray level l in a local region of the ideal face images. Therefore, hijreflects the distribution of the gray values in a particular region of the face images as well as the lighting condition. We regard these learned histograms as local specified histograms. We calculate the histogram hijof each location (i,j) of the ideal face images in advance and store them.Once the local histograms of the ideal images are learned, they are used as the specified histograms. Given a test image Y∈LH×W, the processing steps are summarized as follows:Step 1Attach borders to image Y∈LH×Wto get its bordered image Z∈L(H+2r)×(W+2r).For each sub-image Zij=Z(i−r:i+r,j−r:j+r) centered at (i,j) (i=1,…,H and j=1,…,W) with radius r, perform HS on Zijusing the learned histogram hijdescribed in Section 2, but only the central pixel Z(i,j) is transformed.The preprocessed image is Z:=Z(1:H,1:W).Finally, the processed image is adjusted to have the lighting condition analogous to those of training ones. Fig. 3(a) and (b) illustrates the images preprocessed by TT and LHS-L. Compared to TT, LHS-L is able to significantly reduce the high frequency part of illumination (Fig. 3(a) III), and enhance intrinsic face features lying in the low frequency part of an image (Fig. 3(b) III). Histograms in Fig. 3 indicate that LHS-L processed images have lighting conditions closer to those of ideal images.The window size is determined by the radius r defined in Section 3.1. Such an r is a crucial parameter in LHS-L. If r is too small, the window will not reflect the intrinsic information of a face. In this case, when applying LHS-L to an image, such an image will be transformed similarly to the average face of the training set, which is contrary to our motivation that we hope only the lighting condition of the test image is transformed close to those of ideal images. Besides, a too small r will lead to over-enhancement. Conversely, a larger r would bring about a higher computational complexity. Fortunately, an appropriate radius is not difficult to find, because the recognition rates grow sharply as r increases at the beginning, but later, the recognition rates remain almost stable (see Fig. 2(b)). Such a good quality allows us to easily choose a good r. In our experiments, r is set to 10.HS is a simple, effective, and efficient image enhancement technique, but it often leads to over-enhancement. In fact, the exact HS methods [14–17] can be used in LHS-L. However, when applied on local regions, they become very time-consuming because all the pixels in each sliding window need to be sorted. For a practical face recognition system, we do not hope that the preprocessing procedure takes up too much time.In this section, we utilize the statistical information of histograms for image enhancement. With histogram statistics [13], we propose a flexible version of the LHS-L method named f-LHS-L. Let us consider the mean and the variance of a window centered at (i,j) with a radius w on an image:(9)mij=1Sijw∑uv∈Sijwxuvσij2=1Sijw∑uv∈Sijwxuv−mij2.We are interested in the mean and variance or standard deviation of a local region on an image, because the mean reflects the average gray level of the region, and the variance or standard deviation represents the average contrast of the image [13]. Specifically, if mijis too small (out of normal range of the local region on a face, similarly hereinafter), then the region may be too dark; otherwise, it may be too bright. For σij, if it is too small (except the case of constant areas, which will be discussed separately below), then the local region of an image would have low contrast, therefore it needs to be enhanced; if it is too large, the region may be over-enhanced or it may contain a two dimensional zero-crossing signal.Based on the above analysis, we hope to enhance the areas that the means and standard deviations are out of the normal range, while leaving other areas where the image quality acceptable untransformed. We define the normal ranges of mijand σijas follows:(10)mijmin≤mij≤mijmaxandσijmin≤σij≤σijmax.Since it is a problem for HS to enhance constant areas, whose standard deviation is zero, we set a lower bound for σij, signifying that pixel xijdoes not need to be enhanced, by requiring that:(11)σij2≤ϵ2w+12where ϵ is a very small positive constant, and (2w+1)2 is the area of a window. In our method, we set ϵ=0.01. By combining Eqs. (10) and (11), we give the following condition:(12)mijmin≤mij≤mijmaxandσijmin≤σij≤σijmaxorσij2≤ϵ2w+12.If the local mean mijand standard deviation σijsatisfy Eq. (12), then the central pixel xijof this region does not need to be transformed. Otherwise it needs to be transformed using HS, or other sophisticated HS methods. By doing this we have two merits:1)Pixels that have good quality are less likely to be over-enhanced by HS.It will be more efficient in comparison with transforming all the pixels of the image.In this subsection, we try to estimate the bounds mijmin, mijmax, σijmin, and σijmax for each local region using learned local histogram statistics from ideal images. Let Mijand Sij, respectively, denote random variables representing the mean value and the standard deviation of the region X(i−w:i+w,j−w:j+w) centered at (i,j) with a radius w of the ideal face images. Since we need to find the lower and upper bounds for mijand σij, without knowing the true distribution of Mijand Sij, a viable way is to estimate the expectationE⋅and varianceD⋅for both Mijand Sij. Let(13)μijM=EMij,σijM2=DMij,μijS=ESij,σijS2=DSij.The above four statistics can be estimated by using ideal face images:(14)μ^ijM=1n∑k=1nmijk,σ^ijM=1n∑k=1nmijk−μ^ijM2,μ^ijS=1n∑k=1nσijk,σ^ijS=1n∑k=1nσijk−μ^ijS2where mij(k) and σij(k) are defined like Eq. (9) but denote the mean and the standard deviation of the local region of the k-th image.Letμ^M,σ^M,μ^S, andσ^Sbe the H×W matrices withμ^Mij=μ^ijM,σ^Mij=σ^ijM,μ^Sij=μ^ijS, andσ^Sij=σ^ijS. Fig. 4shows theμ^M,σ^M,μ^S, andσ^Slearned from all the images in the gallery set of the CAS-PEAL-R1 database. With the estimatedμ^ijM,σ^ijM,μ^ijS, andσ^ijS, we give the lower bounds mijmin and σijmin, and the upper bounds mijmax and σijmax for mijand σijas follows:(15)mijmin=max0,μ^ijM−ασ^ijM,mijmax=μ^ijM+ασ^ijM,σijmin=max0,μ^ijS−ασ^ijS,σijmax=μ^ijS+ασ^ijSwhere α is a user defined parameter for all local regions. The bounds are defined as α-standard-deviation away from the mean. If α=0, then this flexible method f-LHS-L overwhelmingly degenerates to LHS-L proposed in the previous section. In our experiments, we investigate the performance of f-LHS-L with respect to (w.r.t.) α=0,1,…,7. Next, we define f(⋅) to indicate whether a pixelxij,ij∈A, needs to be enhanced:(16)fxij=01ifmijmin≤mij≤mijmaxandσijmin≤σij≤σijmaxorσij2≤ϵ2w+12otherwise.Fig. 5shows the effectiveness of the proposed method. The zero-crossing signals on the TT-processed image can be detected by the f(⋅) function. Fig. 6provides a flow chart for our proposed LHS-L and f-LHS-L. Part of the process of f-LHS-L is in the dotted box in this figure.After HS is performed on local regions of images, there may exist some over-enhanced pixels. These pixels tend to be the salt and pepper noises. Thus, we use the median filter to smooth all the pixels that have been processed by HS. The set of the coordinates of these pixels is given by:(17)Smed=ij|ij∈A∧fxij=1.In our method, an image to be preprocessed is segmented into two parts (see Fig. 5(d)). After LHS is applied on the poor quality part, there will be an obvious boundary between the two parts. The boundary is a high frequency signal, therefore a mean filter is proper to eliminate this signal. So, we apply a mean filter on these candidate pixels that are on the boundaries between the two regions. LetSijddenote the coordinates within the mean filter window centered at (i,j) with a radius d. We define the set of the coordinates of the candidate pixels as follows:(18)Smean=ij|ij∈A∧∑uv∈Sijd∩Afxuv∉0,|Sijd∩A|.If∑uv∈Sijd∩Afxuv=0, or∑uv∈Sijd∩Afxuv=|Sijd∩A|, then it means that pixel xijis at least d-pixel distance away from any boundary. So,Smeandefined above is the set of pixels that are d-pixel distance within the boundaries on the original image. These pixels need to be smoothed using the mean filter.In our methods LHS-L and f-LHS-L, the standard histograms and histogram statistics need to be learned from the ideal face images. In this section, we shall discuss some issues on the ideal face images, including 1) the acquisition of these images, 2) the number of these images required for learning the standard histograms and histogram statistics, and 3) the robustness of the ideal images to face detection error.The ideal face images could be regarded as the face images captured under controlled normal lighting conditions. For example, on the CMU PIE and the Extended Yale B databases, the images illuminated by the light from the most frontal light source are chosen as the ideal face images (see Fig. 7(a) and (b)). On the CAS-PEAL-R1 database, the images from the gallery set are regarded as the ideal face images (see Fig. 7(c)). For a practical face recognition system, face images enrolled in the system generally have normal lighting conditions. Therefore, these face images could be chosen as the ideal face images.As each location on a face image has its own standard histogram and histogram statistics, transferring the standard histograms and histogram statistics across different databases should follow two rules: 1) the image size on different databases should be the same; and 2) the locations of the eye centers of the images on different databases should be the same, since eye features are very important features on a face [41]. Because histograms of most regions on TT-preprocessed images tend to have Laplace distribution except the eye regions, for face images with expression, pose, age variations, as long as they are cropped and aligned according to the above two rules, the histograms and histogram statistics learned on other databases could be applied to these images. Therefore, LHS-L and f-LHS-L are robust to variations, such as expression, pose, age variations, on face images following the above two rules.Firstly, we try to estimate how many ideal images are required for learning the standard histograms. We achieve this goal by comparing the differences between the histograms learned from n ideal images and n−1 ideal images. Let [hij]nand [hij]n−1 denote the histograms of the window centered at (i,j) learned from n and n−1 ideal images, respectively. We define the Average Histogram Increment (AHI) by:(19)AHIn=1HW∑i=1H∑j=1Wχ2hijnhijn−1,n≥3where χ2(⋅,⋅) is the histogram distance defined by χ2(a,b)=∑l∈L(al−bl)2/(al+bl) [28]. AHI measures the average distance between the local histograms learned from n and n−1 ideal face images. Fig. 8(a) plots the AHI w.r.t. n on CMU PIE, Extended Yale B, and CAS-PEAL-R1 databases. Although the ideal images of the three databases belong to different individuals and the image sizes of the three databases are also different, the AHI curves of three databases coincide perfectly. This demonstrates the robustness of the AHI measurement. In Fig. 8(a), as n increases from 3 to 20, the AHI curves drop dramatically. When n is larger than 20, the values of AHI are close to 0. Fig. 8(b) plots the recognition rates of the CMU PIE database and the Extended Yale B subsets. Therefore, according to Fig. 8(a) and (b), the minimum number of ideal face images for learning the standard histograms is empirically set to 20.Next, we investigate the number of ideal images required for learning the histogram statistics. Letμ^Mnσ^Mnμ^Snσ^Snandμ^Mn−1σ^Mn−1μ^Sn−1σ^Sn−1denote the sets of histogram statistics learned from n and n−1 ideal face images, respectively. Similar to the definition of AHI, we define the Average Statistics Increment (ASI) as follows:(20)ASIn=14HW(||μ^Mn−μ^Mn−1||F2+||σ^Mn−σ^Mn−1||F2+||μ^Sn−μ^Sn−1||F2+||σ^Sn−σ^Sn−1||F2),n≥3where ||⋅||Fdenotes the Frobenius norm. ASI measures the average distance between the histogram statics learned from n and n−1 ideal face images. Fig. 9(a) plots the ASI w.r.t. n on the CAS-PEAL-R1 database. As n grows from 3 to 50, the ASI curve declines steeply from approximately 23 to near 0, and when n continues growing, the ASI curve remains stable and is almost 0. The recognition rate on the CAS-PEAL-R1 database achieved by f-LHS-L shown in Fig. 9(b) is consistent with the ASI curve. The recognition rate grows sharply as n increases from 3 to 50, where the recognition rate is 75.0%. When n is larger than 50, the recognition rate remains stable, being no less than 75.0%. As a result, the minimum number of ideal face images for learning the histogram statistics can be set to 50.In this subsection, we shall discuss the robustness of learning the standard histograms and histogram statistics to detection error, generally several pixels' misalignment. When we wish to calculate the standard histogram of a window centered at (i,j) on an ideal face image, due to detection error, the ground truth center of this window may be several pixels away from (i,j). Denote by (i′,j′) the random vector representing the ground truth center of the window which should be centered at (i,j) (see Fig. 10). Let Δx=|j−j′| and Δy=|i−i′| denoting the random variables signifying the absolute offsets of ground truth center (i′,j′) from (i,j) along the horizontal and vertical directions, respectively.Let A be the random variable denoting the area of non-overlapping area of the two windows, one centered at (i,j) and the other centered at (i′,j′) (the shadowed area in Fig. 10). Therefore, A is the function of Δxand Δy. Let A=g(Δx,Δy), and g(⋅,⋅) is defined as follows:gxy=0,ifx<0ory<022r+1x+y−xy,if0≤x≤2r+1and0≤y≤2r+122r+12,otherwiseLet A(k) be the random variable denoting the same area as A does, but for the k-th ideal image. Since the detection error for each image is independent, A, A(1), …, A(n) are i.i.d. random variables. Denote byhi′j′and hijthe ground truth standard histogram and the actually learned histogram, respectively. The upper bound of the ℓ1-norm distance betweenhi′j′and hijcan be calculated as follows:(21)||hij−hi′j′||1=∑l∈L|1n∑k=1nhijkl−1n∑k=1nhi′j′kl|≤1n∑l∈L∑k=1n|hijkl−hi′j′kl|≤1n∑k=1nAk2r+12=12r+121n∑k=1nAk.Since the detection error is only several pixels in general, the expectation of A (EA) exists. Recall that A, A(1), …, A(n) are i.i.d. random variables. According to Kolmogorov's strong law of large numbers [42], we have:(22)Plimn→∞1n∑k=1nAk=EA=1.Further, we have:(23)Psupn→∞||hij−hi′j′||1=EA2r+12=1.Eq. (23) means that the upper bound of||hij−hi′j′||1converges toEA/2r+12with probability 1. Therefore, the larger r, the smaller difference between the ground truth histogramhi′j′and the learned histogram hij. Generally,EA≪2r+12for detection error, therefore, the learned histogram hijis robust to minor misalignment.Next, we shall discuss the robustness of the histogram statisticsμ^M,σ^M,μ^S,σ^Sto detection error. From Fig. 4(a) and (b), we find that theμ^Mis very smooth, and the corresponding standard deviation imageσ^Mis very dark, suggesting that its intensities are very small. This implies that the mean images, {m(k)}k=1nwith size of m(k) being H×W and (m(k))ij=mij(k), of the ideal images are very close toμ^M, and further suggests that mean images {m(k)}k=1nare also very smooth. Therefore, several pixels away from the ground truth will not impactμ^M,σ^Mmuch. The same analysis could also be applied toμ^S,σ^S. Hence, the histogram statisticsμ^M,σ^M,μ^S,σ^Sare not sensitive to minor misalignment.

@&#CONCLUSIONS@&#
To eliminate high frequency illumination and enhance low frequency face features on face images are two most difficult problems and have been overlooked by most of the state-of-the-art face image preprocessors. In this paper, we try to address the two problems based on LHS. With the local histograms and local histogram statistics learned from the ideal face images, the proposed LHS-L and its flexible version f-LHS-L are able to significantly remove both the low and high frequency parts of illumination on face images, as well as enhance face features lying in the low frequency part. The ideal face images are face images captured under normal lighting conditions, and we suggest that the minimum numbers of ideal face images required for learning local histograms and histogram statistics be 20 and 50, respectively.The preprocessed face images show that LHS-L and f-LHS-L are able to produce better image qualities than the state-of-the-art methods. The recognition rates show that LHS-L is competitive with or better than the state-of-the-art methods even using the simple χ2 distance metric. By combining multiple face descriptors LBP, Gabor, and MBC-O, and fusing feature extraction methods KLDA and BFLD, we show that significant improvement could be achieved owing to the combination of the heterogeneous features and feature extractions methods.In the future work, we will try to use some sophisticated histogram specification methods and apply the local histogram specification method directly on the original images.