@&#MAIN-TITLE@&#
Search with evolutionary ruin and stochastic rebuild: A theoretic framework and a case study on exam timetabling

@&#HIGHLIGHTS@&#
This paper presents a new search method which tries to learn and adapt to the changing environments during the search.It improves the original R&R idea by implementing a phase of Evolutionary Ruin to mimic an evolution within single solutions.It achieves optimisation by an iterative process of component evaluation, solution disruption and stochastic constructive repair.It presents a formal framework and implements a Markov chain analysis on some theoretical properties of the approach.Experimental results on exam timetabling benchmark problems have demonstrated the strength of the approach.

@&#KEYPHRASES@&#
Metaheuristics,Evolutionary algorithm,Stochastic process,Combinatorial optimisation,Exam timetabling,

@&#ABSTRACT@&#
This paper presents a state transition based formal framework for a new search method, called Evolutionary Ruin and Stochastic Recreate, which tries to learn and adapt to the changing environments during the search process. It improves the performance of the original Ruin and Recreate principle by embedding an additional phase of Evolutionary Ruin to mimic the survival-of-the-fittest mechanism within single solutions. This method executes a cycle of Solution Decomposition, Evolutionary Ruin, Stochastic Recreate and Solution Acceptance until a certain stopping condition is met. The Solution Decomposition phase first uses some problem-specific knowledge to decompose a complete solution into its components and assigns a score to each component. The Evolutionary Ruin phase then employs two evolutionary operators (namely Selection and Mutation) to destroy a certain fraction of the solution, and the next Stochastic Recreate phase repairs the “broken” solution. Last, the Solution Acceptance phase selects a specific strategy to determine the probability of accepting the newly generated solution. Hence, optimisation is achieved by an iterative process of component evaluation, solution disruption and stochastic constructive repair. From the state transitions point of view, this paper presents a probabilistic model and implements a Markov chain analysis on some theoretical properties of the approach. Unlike the theoretical work on genetic algorithm and simulated annealing which are based on state transitions within the space of complete assignments, our model is based on state transitions within the space of partial assignments. The exam timetabling problems are used to test the performance in solving real-world hard problems.

@&#INTRODUCTION@&#
By definition, a solution to a combinatorial problem is always made of components which are elaborately interlocked together. Not only should each solution component be a strong candidate in its own right but also it has to fit well with other components in the surrounding environment or current setting. To deal with these components, Schrimpf, Schneider, Stamm-Wilbrand, and Dueck (2000) proposed a technique called Ruin and Recreate (R&R) principle for some classical problems (including the traveling salesman problem, vehicle routing and network optimisation), and claimed that it could be a general approach for various combinatorial optimisation problems. Since then, R&R has been successfully applied to many different types of discrete optimisation problems, such as quadratic assignment (Misevicius, 2003), paratransit scheduling (Häll & Peterson, 2013), the permutation flow shop problem and one-dimensional bin packing problem (Burke et al., 2009), etc.The R&R method uses the concepts of simulated annealing (Kirkpatrick, Gelatt, & Vecchi, 1983) or threshold accepting (Dueck & Scheuer, 1990) with large moves instead of smaller ones. The method is sometime called very large neighbourhood search, and thus bears some resemblance to variable neighbourhood search (Hansen & Mladenović, 1999) which obtains better results by a perturbation of an existing solution and a following improvement procedure. High quality solutions are obtained by applying this type of treatment frequently. Hence, R&R method can be thought of as an iterative process of reconstructions and improvements applied to solutions. The advantage of the method over the well-known random multi-start method is that, instead of generating new solutions from scratch, a better idea is to reconstruct a portion of the current solution to make use of the information gained from the previous search.For simple structured problems such as the traveling salesman problem, the need of using large moves is not obvious, because there is no/little feasibility issue, and small moves are usually sufficient for the algorithms to generate near optimal solutions. Of course, the larger the size of moves, the better the results would be but at the cost of much higher computation time. For instance, Iterated Lin-Kernighan, one of the best approaches for the traveling salesman problem, does use large local moves. However, for complex problems such as exam timetabling problems, difficulties arise if we always use such small moves, because local moves do not give small changes in the objective function: if taking one move from a current solution to its neighbouring solution, the qualities of the resulting solutions might be significantly different due to the ruggedness of the landscapes in these problem areas. The situation may be alleviated by a better choice of solution representation and neighbourhood function, but this study is beyond the scope of this paper.Solutions of complex problems usually come with a number of soft and/or hard constraints, which makes it difficult to get just feasible solutions. Neighbouring solutions of complex schedules, for instance, are mostly infeasible solutions. Walking in such a complex fitness landscape from one feasible solution to another feasible neighboured solution would be hard. The common method of avoiding the infeasibility problem for many classical algorithms in the literature is to impose artificial penalty functions, but this method would typically make the algorithms stuck in solutions which are nearly feasible but are not allowed at all.Naturally, one will think in such as paradigm: Ruin and Recreate. Unlike a local search which implements search by doing perturbation on a small number (usually up to 3) of components, we ruin a large portion of the solution and try to rebuild the solution as best as we can, with the hope that the new solution is improved. The R&R approach is based on this idea. Of course, the R&R can also destroy a small portion of the solution (say 1–2 components), then under this circumstance it behaves the same as an ordinary local search algorithm. Hence, it is reasonable to believe that problems with many side conditions, or with complex objective functions, are more tractable using special-designed large moves.Based on the R&R principal, in this paper we embed some evolutionary features into the decision process and present a more advanced technique called Evolutionary Ruin and Stochastic Recreate (ER&SR). Its general idea is to break a solution down into its components and assign a score to each component by an evaluation function which works under dynamic environments. The scores (or fitness values) determine the chances for the components to survive in the current solution.The ER&SR applies two operators of Selection and Mutation as the ruining strategies, trying to mimic the survival-of-the-fittest mechanism happening on single individuals (or solutions). Each component in the solution has to continuously demonstrate its worthiness to remain in the current solution (or environment). Hence in each iteration, some components would be treated not worth keeping. The evolutionary strategy adopted may also remove some worthy components with fixed or variable low probabilities. The removed component is then reintroduced by using a specific algorithm. The addition of a new component is determined by a dynamic evaluation function, which computes how well the candidate component would fit in with others that already exist in the current solution. The above processes are repeated together with the remainder of the classical R&R. Hence, search is based on an iterative improvement process of components evolution, solution disruption and reconstructive process.The proposed ER&SR algorithm comprises the following four phases: Solution Decomposition, Evolutionary Ruin, Stochastic Recreate and Solution Acceptance. It executes these phases in sequence on a single solution until a predefined stopping criterion is met. The first Solution Decomposition phase is based on the fact that solutions of the combinatorial optimisation problems all consist of components which are intricately woven together. Each component in a current solution may not only be a strong candidate in its own right, but also need to fit well with other components. Hence, the key problem in this phase is about what measurement to use to evaluate the fitness of individual components. To address this, we may employ an expert's domain knowledge to break a solution down into components and assign a score to each. The higher the score, the fitter the associated component is.The second Evolutionary Ruin phase is based on the consideration that the incumbent solution must be changed not only locally but also over a macroscopic scale, depending on the solution composition defined by the proceeding Solution Decomposition phase. This phase employs two evolutionary operators of Selection and Mutation to destroy a certain portion of the entire solution. The Selection operator removes some components based on Darwin's survival of the fittest mechanism, while the Mutation operator further removes a small number of components at random. Hence, the destroyed part of the solution would sometimes be large enough such that the impact of the “bomb” that is thrown on the solution will be noticeable not only locally but in the whole system. On the other hand, the destroyed part would sometimes be small enough so that at least a main portion of the solution (i.e. a skeleton) remains to ease the rebuild for the next solution.The third Stochastic Recreate phase follows to reintroduce the removed components by a somewhat stochastic method in order to have a better chance to jump out of the local optima. The fourth Solution Acceptance phase selects a specific strategy to determine the probability of accepting the newly generated solution.This paper presents a probabilistic model based on the state transition process between the abovementioned phases, and implements a Markov chain analysis to derive some theoretical properties of the approach. The well-known exam timetabling problems are used to test the availability of the approach in solving real-world hard problems.The remainder of the paper is structured as follows. Section 2 elaborates a formal framework of the ER&SR, from the state transition point of view. Section 3 introduces an implementation of the ER&SW for exam timetabling, and Section 4 presents the computational results of this approach. Section 5 contains some concluding remarks and possible future work.Following the general introduction of the ER&SR in Section 1, this section presents its formal framework in a similar way to that of the evolutionary squeaky wheel optimisation (Li, Parkes, & Burke, 2011b), and then presents a Markov chain model for a simplified version of the algorithm. The basic idea of the algorithm was initially and briefly presented in Li, Qu, and Shen (2012b). The session brings a deeper insight on the working mechanism of the algorithm.Four phases are performed in sequence at each iteration of the ER&SR algorithm. They are Solution Decomposition, Evolutionary Ruin, Stochastic Recreate and Solution Acceptance (see the flow chart in Fig. 1).The first phase, Solution Decomposition, does not change the current state on its own, since it only collects information about the local fitness value of each component of the current state. The Evolutionary Ruin phase (comprising two operators of Selection and Mutation) changes the present state by removing a set of selected components from a current solution, based on the results of the preceding Solution Decomposition phase. Neither the Selection operator nor the Mutation operator can directly result in a destination state, that is, a state in which each of the componential variables is assigned a value. What is obtained after an Evolutionary Ruin is an intermediate state in which at least one component is removed. An intermediate state corresponds to an incomplete assignment, with a set of unassigned components.A source state Xt, t = 1, 2,…, |S|, corresponds to a complete solution in the state space S. Xtconsists of m componential variables xidenoted as Xt= (x1, …, xm)t, and each (xi)ttakes one of its domain values, i.e.(xi)t∈{j1(i),j2(i),j3(i),…}. The assignment of a valuejk(i)to a variable is denoted as(xi)t=jk(i). A solution is a complete assignment if each variable xihas a domain value assigned, regardless of the satisfiability on the constraint set. For each iteration, the value of m may be fixed or not, depending on the nature of the problem. For example, for the assignment problem it is usually fixed, while for the set covering problem it is changing if the objective is just to minimise the number of components in the solution.Let f((xi)t, (xi)t∈ Xt) ∈ (0, 1) be the local fitness value of component (xi)tin a solution Xtcalculated by the Solution Decomposition phase. The larger the f((xi)t, (xi)t∈ Xt), the smaller the chance that (xi)tis selected for removal. The probabilities, pS((xi)t), at which component (xi)tis selected from Xtto convert to a ‘#’ (i.e. the unassigned situation) is calculated as(1)pS((xi)t,(xi)t∈Xt)=1−f((xi)t,(xi)t∈Xt)∑k=1m(1−f((xk)t,(xk)t∈Xt)),∀i∈{1,…,m},Xt∈S.An intermediate state X'tcorresponds to a partial solution with at least one of m components unassigned. Let PS(X't|Xt) be the conditional probability that intermediate state X't= (x'1, …, x'm)tis generated from a present state Xt= (x1, …, xm)tby the Selection operator. We may obtain(2)PS(Xt′|Xt)={0,if∃i∈{1,…,m},(xi)t≠(x′i)tand(x′i)t≠`#";∏i=1mpS((xi)t)(1−pS((xi)t))1−H((xi)t,(x′i)t),otherwise.where(3)H((xi)t,(xi′)t)={1,if(xi)t≠`#"and(x′i)t=`#";0,if(xi)t=(x′i)t≠`#".The Mutation operator further transforms the present intermediate state X'tto another intermediate state X''tby removing the set of mutated components from X't. The probabilities that component (x'i)tis selected from tuple X't= (x'1, …, x'm)tto re-instantiate by the later Stochastic Recreate operator is denoted aspM(t), wherepM(t)∈(0,1)is the same for each component x'iand can be either fixed or changing for each iteration. Let pM(X''t|X't) be the transition probability that tuple X''t= (x''1, …, x''m)tis generated from tuple X't= (x'1, …, x'm)tby Mutation. Then we have(4)PM(Xt′′|Xt′)={0,if∃i∈{1,…,m},(x′i)t≠(x′′i)tand(x′′i)t≠`#";∏i=1m((pM(t))H((x′i)t,(x′′i)t)(1−pM(t))1−H((x′i)x,(x′′i)t))1−λ,otherwise.where(5)H((xi′)t,(xi′′)t)={1,if(x′i)t≠`#"and(x′′i)t=`#";0,if(x′i)t=(x′′i)t≠`#".(6)λi={1,if(x′i)t=(x′′i)t=`#";0,otherwise.The Stochastic Recreate phase then generates a new destination state Xt + 1 from the present intermediate state X''t, by carrying out probabilistic moves among different possible destination states. Let PS(Xt + 1|X''t) be the transition probability that tuple Xt + 1 = (x1, …, xm)t + 1 is generated from tuple X''t= (x''1, …, x''m)tby the Stochastic Recreate. We have(7)PS(Xt+1|Xt′′)={0,if∃i∈{1,…,m},(x′′i)t≠(xi)t+1≠`#";1,if∀i∈{1,…,m},(x′′i)t=(xi)t+1;F(Xt+1)∑X∈N(X′′t)F(X),otherwise.where F(·) is the objective function (for a maximisation problem in this context) for destination states, and N(X''t) is the set of all reachable destination states from intermediate state X''t. The first two cases of Equation (7) are automatic constraints which ensure that the constructor can only assign values to unassigned componential variables (i.e. variables with ‘#’ values). The third case defines a Stochastic Recreate whose purpose is to introduce some randomness but still to favour the construction of fitter solutions. However, when applying the constructor in practice, there is a computational difficulty due to the size of N(X″) which is(8)|N(Xt′′)|=∏k=1lnk,where l is the number of unassigned componential variables in X″, and nkis the number of domain values that the kth unassigned componential variable may take.One may see from Equation (8) that the number of one-step reachable states from X''tincreases exponentially with the number of variables having ‘#’ values in X''t. To reduce the amount of computation, we add one more case to Equation (7) which says that all the neighbouring states have the same chance to be reached if the number of ‘#’s is larger than a pre-defined threshold value t, t ≥ 2. The extra case is formulated as(9)PS(Xt+1|Xt′′)=1∏k=1lnk,ifl>t;Recall that Xtdenotes the source state that the Stochastic Recreate previously reaches. The fourth Solution Acceptance phase accepts the new complete state Xt + 1 at probability PA(Xt + 1|Xt). For the simplest situation where each of the resulting solutions is accepted, PA(Xt + 1|Xt) = 1. If using simulated annealing with a time-varying parameter T called temperature, then(10)PA(Xt+1|Xt)={1,if(F(Xt+1)−F(Xt))≥0;exp(F(Xt+1)−F(Xt)T),if(F(Xt+1)−F(Xt))<0.A Markov chain is a sequence of random variables X1, X2,…, Xtwith the Markov property, that is, given the present state, the future and past states are independent (Tijms, 2003). A discrete-time Markov chain is denoted as(11)Pr{Xt+1=x|X1=x1,X2=x2,…,Xt=xt}=Pr{Xt+1=x|Xt=xt}.At each step, the system may transit its state from state i to state j according to a probability distribution. For state transitions within a space of finite set S, the transition probability distribution can be represented by a matrix P, whose (i, j)th entry is(12)pij=Pr{Xt+1=j|Xt=i},i,j∈S.For the search space of the ER&SR algorithm, assume a solution Xtconsists of m componential variables xidenoted as Xt= (x1, …, xm)t, and each xitakes one of the domain values, i.e.(xi)t∈{j1(i),j2(i),j3(i),…}. For the Evolutionary Ruin phase, its Selection operator may be deemed as a linear map from space S of cardinality∏k=1mnkto space S# of cardinality∏k=1m(nk+1), as each variable after Selection can take an additional ‘#’ value denoting that the variable is marked as “selected” for later instantiation. The Mutation operator transits states within space S#, and the Stochastic Rebuild phase transfers a partial assignment (i.e. a state with a mixture of # and non-# symbols) in S# back to a complete assignment in space S.For each iteration of the ER&SR algorithm, a state transition (or a one-step move) is carried out from a source state to a destination state. For a given present state, the probability of its future state is conditionally independent of the past states. Hence, each step of transitions between states of complete solutions (i.e. Xtand Xt+1) has the Markov property.After defining the state transitions after each phase of Selection, Mutation, Stochastic Recreate and Solution Acceptance, we may give an expression for the overall transition probability between any two connected states. The transition probability from a source state Xtto a destination state Xt+1, via two intermediate states X'tand X''t, can be expressed as(13)P(Xt+1|Xt)=PS(Xt′|Xt)·PMXt′′|Xt′)·PS(Xt+1|Xt′′)·PA(Xt+1|Xt)Hence, we may see that these four phases work as a whole to implement a linear transformation from state space S to itself, by an overall transition matrix P whose entries are defined by Equation (13). If a fixed rate of mutation pMis used, the Markov chain formed by the ER&SR algorithm is homogeneous as the transition matrix does not depend on time. Accordingly, we can apply some of the standard results on Markov Chain analysis straightaway.Definition 1A Markov chain is called an ergodic chain if it is possible to go from every state to every state (not necessarily in one move). Ergodic Markov chains are also called irreducible.For a transition matrix P = (pij), if π = (π1, …, πj, …) is a probability distribution such thatπj=∑i∈Sπipij,∀j∈S, then π is a stationary distribution.(Koralov & Sinai, 2007) Given a Markov chain with an ergodic transition matrixP, there exists a unique stationary probability distribution π. The n-step transition probabilities converge to the distribution π, i.e.limn→∝pij(n)=πj. The stationary distribution satisfies πj> 0 for all j ∈ S.For our ER&SR algorithm, we can easily verify that its P is positive (i.e. every element in P is a positive number), and thus the corresponding Markov chain is ergodic. By Theorem 1, there exists a unique stationary probability distribution π = (πj) and πj> 0. Hence, the ER&SR algorithm visits a global optimum of the optimisation problem after a finite number of transition steps with probability one. However, it does not converge to the optimal solutions because of πj> 0, i.e. each of the states has a non-zero probability value.In real-world implementation, an ER&SR algorithm always retains the best solution. Under this circumstance, a state does not correspond to a single solution, rather, it corresponds to a tuple of two solutions (x*, x), where x* and x denote the previous best and the current solution, respectively. If x* = s* where s* is the only optimal solution, then obviously all the solution pairs containing s* consist of a single closed set from which no external state is reachable. Therefore, by the extension of Theorem 1 on reducible Markov chain, the probability of staying in the set of non-closed states converges to zero. That is, the ER&SR algorithm maintaining the best found solution converges to the global optimum of the problem.We then study the condition on which the stationary probabilities are equally distributed. We can easily prove that, for any finite Markov chain with a positive matrix P, the stationary probabilities (πi|j ∈ S) are uniformly distributed, at a value of 1/|S|, on each state if P is symmetric. For an ER&SR algorithm, the symmetric requirement on P is satisfied if the local fitness value f((xi)t, (xi)t∈ Xt) is the same for each componential variable (xi)tin the solution. In this case, the ER&SR reduces to a simple algorithm where its phases of Evolutionary Ruin and Stochastic Rebuild are purely randomised.Naturally, for real-world problem solving, one would like to seek an algorithm where the stationary probabilities are not always uniformly distributed. For the ER&SR algorithm, we may observe that the stationary distribution π = (πi|j ∈ S) on each state is controllable through a proper combination of the Selection function, the Mutation rate, the Stochastic Recreate method and Solution Acceptance strategy. This suggests that, even if we do not keep the best solution found during the algorithm execution, it is still possible to get a stationary probability close to one on the optimal solution of the given problem. The above statement is, however, just a conjecture. To confirm this, a much deeper study is needed to further explore and understand the interactions among the various phases in an ER&SR algorithm.This section presents an application of the ER&SR algorithm to the exam timetabling problem which is well studied but is open (no optimal solution known). Starting from an initial timetable generated by any method, the steps described in Sections 3.2–3.4 are repeatedly executed in sequence until a user specified termination condition is met. Throughout the iterations, the best is retained and finally returned as the preserved timetable.Exam timetabling occurs frequently throughout an institution's academic calendar, and needs to be tackled on a regular basis. The problem has attracted a significant level of research interest since the 1960’s. The general timetabling problem comes in many different guises such as nurse rostering (Aickelin, Burke, & Li, 2007; Burke, Li, & Qu, 2010b; Cheang, Li, Lim, & Rodrigues, 2003; Li, Burke, Curtois, Petrovic, Qu, 2012a), sports timetabling (Easton, Nemhauser, & Trick, 2004), transportation timetabling (Furini & Kidd, 2013) and educational timetabling (Carter, Laporte, & Lee, 1996; Petrovic & Burke, 2004; Qu, Burke, McCollum, Merlot, & Lee, 2009b; Schaerf, 1999). Educational timetabling problems are probably the most widely studied.Since exam timetabling problems are generally NP-hard, meta-heuristics have attracted the most attention, including genetic algorithms (Erben, 2001; Paquete & Fonseca, 2001), tabu search (Burke, Kendall, & Soubeiga, 2003; White, Xie, & Zonjic, 2004), ant algorithms (Dowsland & Thompson, 2005), simulated annealing (Thompson & Dowsland, 1998). Various other methods have also been studied, such as knowledge-based systems (Burke, Petrovic, & Qu, 2006), local search-based heuristics (Burke & Newall, 2003; Casey & Thompson, 2004), and hyper-heuristics (Qu & Burke, 2009).Exam timetabling can be considered as the process of assigning a set of exams into a certain number of timeslots subject to a set of hard and soft constraints. A hard constraint is the one that cannot be violated, for example, two exams attended by the same students cannot be scheduled to the same timeslot. A soft constraint is one that should be satisfied if possible, for example, exams taken by the same students should be spread out over the available timeslots to get some break. Solutions that satisfy hard constraints are called feasible solutions. The more soft constraints are satisfied, the better the timetables would be.In terms of assessing the quality of potential schedules, to favour schedules in which exams are well spaced out or in which the number of undesirable assignments is low, Carter et al. (1996) proposed a proximity cost wswhenever a student has to attend two exams scheduled s periods apart: these weights are w1 = 16, w2 = 8, w3 = 4, w4 = 2 and w5 = 1. The following objective function is therefore used in a number of benchmark problems to calculate the cost of violations F(X) within a resulting feasible solution X (Burke, McCollum, Meisel, Petrovic, & Qu, 2007), in which exams of s timeslot away actually means “s slot in between, or s + 1 period apart”:(14)MinF(X)=∑s=04(ws×Sts)/St,where, ws= 2s, s ∈ {0, 1, 2, 3, 4}, is the weight that represents the importance of scheduling exams with common students either 4, 3, 2, 1, or 0 timeslots away in timetable X; Sts, s ∈ {0, 1, 2, 3, 4}, is the number of students that sit two exams of j timeslots away; St is the number of students in the problem.This phase evaluates the current assignment for each exam ei, i ∈ [1, …, m], in a timetable, by computing the fitness of each exam allocation. Its purpose is to determine which exams are assigned in positions that contribute more toward the overall cost reduction for the resulting schedule. We design a normalised evaluation function f((ei)t), k ∈ (1, …, m), to evaluate eiat the tth iteration as follows:(15)f((ei)t)=max(C((e1)t),…,C((em)t))−C((ei)t)max(C((e1)t),…,C((em)t))−min(C((e1)t),…,C((em)t)),(16)C((ei)t)=∑r=1i−1(wj×Sir)+∑r=i+1m(wj×Sir),(17)j=|tr−ti|−1,j∈{0,1,2,3,4}.where, C((ei)t) is the cost value caused by exam (ei)t; wjtakes the same definition as in Equation (14); trand tiare the timeslots of (er)tand (ei)t, respectively; Siris the number of students involved in both exams (ei)tand (er)t, if j = |tr− −ti| < 5.This phase determines if an exam of a current timetable should be removed or not. For the tth iteration of the Evolutionary Ruin, a single random numberrS(t)∈(0,1)is generated. The Selection operator then compares the fitness value f((ei)t) torS(t). Iff((ei)t)≥rS(t), then (ei)twill stay in its current timetable Xt, otherwise it will be removed. By Selection, an exam (ei)twith larger f((ei)t) value has a higher probability to survive. On the other hand, the Mutation operator follows to mutate the retained exams, i.e. randomly discarding them from the partial timetable at a small ratepM(t)to help a quicker convergence. Another random numberrM(t)is generated. IfpM(t)≥rM(t), then (ei)twill stay in its current timetable Xt, otherwise it will be removed.The Stochastic Recreate phase rebuilds a partial timetable by assigning unscheduled exams to their available timeslots. For a specific exam waiting for rescheduling, the following two steps are executed: Step 1 finds all its available timeslots without any conflict exams; Step 2 chooses the timeslot with the smallest increase on the overall cost defined by Equation (14).One of the basic construction approaches is to construct the timetable by sequentially placing exams into timeslots according to some heuristic measure of how difficult the exams are to schedule. Carter et al. (1996) used some graph colouring heuristics to achieve the task, based on the fact that a simplified timetabling problem without taking into account soft constraints can be reduced to a graph colouring problem, where vertices of the graph represent exams and edges represent the conflicts between exams (i.e. with common students). However, it should be note that the simplified graph colouring model where the goal is to minimise the number of colours is not a good model for our exam timetabling problem since the number of colours (timeslots) is fixed at the start and thus is not minimised in the problems used for the numerical results. We only use some of those simple graph colouring heuristics to determine an order in which the exams are rescheduled although many other heuristics can also be applied.Here we use the following four graph colouring heuristics: Largest Degree first (LD), Largest Weighted Degree first (LWD), Largest Colour Degree first (LCD) and Least Saturation Degree first (LSD). Let pi1, pi2, pi3 and pi4 be the probabilities of using heuristics LD, LWD, LCD and LSD to reschedule exam ei, respectively. These heuristics are alternatively used in each step of construction process, satisfying∑j=14pij=1.The LD heuristic orders exams in a descending order by the number of conflicts they have with other exams. It schedules first the exams which have the most conflicts in the following way: going through the pre-calculated conflict values for the unscheduled exams and then proceeding to Steps 1 and 2 mentioned above.The LWD heuristic orders exams in a descending order by the number of conflicts, each of which is weighted by the number of students involved. Among exams with the same degree, it schedules first those with a larger number of students involved. Like LD, LWD first goes through the weighted conflict values for the unscheduled exams, and then executes Steps 1 and 2.The LCD heuristic orders exams in a descending order according to the number of conflicts with the other exams that have already been placed in the timetable. The degrees of the exams not yet scheduled are changing according to the situations encountered at each step of the solution construction. Unlike LD and LWD, the conflict value for each exam is firstly updated before an exam is scheduled. This involves the update of an ancillary matrix containing the conflict values between any pairs of an unscheduled exam and a scheduled exam. LCD then goes through the new conflict values for the unscheduled exams, and implements Steps 1 and 2.The LSD heuristic orders exams in an ascending order according to the number of available timeslots without violating hard constraints. The priorities of exams to be ordered and scheduled are changing during the construction process. The number of available timeslots for each exam is firstly calculated before an exam is rescheduled. LSD then goes through the saturation degree numbers for all the unscheduled exams, and proceeds to Steps 1 and 2 as the other heuristics do.The criterion for Solution Acceptance is not problem specific, and thus any of the strategies available in the literature (such as hill-climbing, simulated annealing, threshold acceptance, great deluge, or falling tide) can be used to determine whether the newly resulting solution by the Stochastic Recreate phase is accepted or not.

@&#CONCLUSIONS@&#
