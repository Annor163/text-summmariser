@&#MAIN-TITLE@&#
Facial neuromuscular signal classification by means of least square support vector machine for MuCI

@&#HIGHLIGHTS@&#
Recognizing ten facial gestures through analyzing facial neuromuscular signals.EMG analysis including filtering, segmentation, feature extraction (RMS).Classification of facial gestures by multi-class LS-SVM.Tuning the kernel parameters automatically and manually.Constructing different LS-SVM models.48 automatic and 8 manual LS-SVM models were constructed.The models were compared in terms of classification accuracy and complexity.The best performance was gained by the model tuned manually including RBF and OVA.LS-SVM was compared with popular classifiers FCM, SVM and FGGC.

@&#KEYPHRASES@&#
Facial neuromuscular signal,Electromyogram,Least square support vector machine,Facial gesture recognition,Muscle computer interface,Classification,

@&#ABSTRACT@&#
Facial neuromuscular signal has recently drawn the researchers’ attention to its outstanding potential as an efficient medium for Muscle Computer Interface (MuCI) applications. The proper analysis of such electromyogram (EMG) signals is essential in designing the interfaces. In this article, a multiclass least-square support vector machine (LS-SVM) is proposed for classification of different facial gestures EMG signals. EMG signals were captured through three bi-polar electrodes from ten participants while gesturing ten different facial states. EMGs were filtered and segmented into non-overlapped windows from which root mean square (RMS) features were extracted and then fed to the classifier. For the purpose of classification, different models of LS-SVM were constructed while tuning the kernel parameters automatically and manually. In the automatic mode, 48 models were formed while parameters of linear and radial basis function (RBF) kernels were tuned using different optimization techniques, cost functions and encoding schemes. In the manual mode, 8 models were shaped by means of the considered kernel functions and encoding schemes. In order to find the best model with a reliable performance, constructed models were evaluated and compared in terms of classification accuracy and computational cost. Results reported that the model including RBF kernel which was tuned manually and encoded by one-versus-all scheme provided the highest classification accuracy (93.10%) and consumed 0.98s for training. It was indicated that automatic models were outperformed since they required too much time for tuning the parameters without any meaningful improvement in the final classification accuracy. The robustness of the selected LS-SVM model was evaluated through comparison with Support Vector Machine, fuzzy C-Means and fuzzy Gath-Geva clustering techniques.

@&#INTRODUCTION@&#
Human computer interaction (HCI) is a promising approach which offers various opportunities noticeably in designing assistive technologies for daily life tasks. Such systems aim to provide a reliable pathway between people with severe motor dysfunction and the world around them. Common means of HCI that have been widely employed are human hands, voice, head and gaze [1,2]. Biosignal-based HCIs have been recently proposed which are executed by voluntary signals generated from either a brain activity known as brain computer interaction (BCI) or a body muscle called muscle computer interaction (MuCI). It is reported that, BCI is preferred when the use of MuCIs is not feasible [3]. There are numerous studies on the potential of MuCI systems including multifunction prosthesis [4–6], power exoskeleton control [7], electric-powered wheelchairs [8,9], robotic control [10] and grasping control [11].Most of the mentioned interfaces are designed based on hand, wrist and finger muscle movements; however, these communication channels are unserviceable for individuals with crucial disabilities like those who cannot even move their neck. Hence, MuCI systems based on facial muscle movements have been proposed [12]. Face contains complicated muscles capable of generating delicate movements (facial gestures/expressions) that carry different information and can be detected through superficial sensors. According to [3], the myoelectric signal activity pattern of different facial gestures is diverse and this phenomenon has motivated researchers to classify such patterns in order to recognize various facial gestures. Ang et al. [13] introduced an EMG-based recognition system of the three facial expressions happiness, anger and sadness through three pairs of electrodes. They extracted four different features: mean, standard deviation, Root Mean Square (RMS) and the power spectrum density (PSD) from the rectified filtered EMGS. They reported 94.44% recognition accuracy by utilizing a minimum distance classifier. The use of facial neuromuscular activities to control an electrically powered wheelchair was investigated by Kim et al., [14]. Hidden Markov Model (HMM) was applied to classify the extracted linear prediction coefficients (LPCs) features from eye blink, clenching left, right and both molars. Finally, a mean accuracy of 96.8% was obtained from handicapped and healthy participants. Gibert et al. [15] proposed a recognition system based on six basic expressions: anger, surprise, disgust, happiness, sadness and neutral. They used eight pairs of bipolar surface sensors to capture the EMGs. Absolute value features were extracted from low-passed filtered signals and used as the main characteristics to project each expression by simple Gaussian model. They calculated the Bhattacharyya distance between the Gaussian models to measure the separability of expressions in classification and a mean accuracy of 92% was reached. Recognition of facial movements during unvoiced speech was investigated through four EMG recording channels by Arjunan and Kumar [16]. They tried to identify the unspoken vowel based on the normalized integral moving RMS (MRMS) values of EMGs. They finally stated that the features of surface EMG signals were suitable for characterizing muscle activation during unvoiced speech and subtle gestures. In [12], an interface was designed for a hands-free control system by means of multi-channel facial EMGs to control a virtual robotic wheelchair. Three pairs of bipolar electrodes were employed to acquire the considered facial gestures: smile, frown and pulling up lip corners. They reported 89.75%-100% classification accuracy while mean absolute value (MAV) and support vector machine (SVM) were adopted for feature extraction and classification respectively. Their work was expanded by Rezazadeh et al. [17] to control a virtual interactive tower crane through five different facial gestures. They reached 92.6% recognition accuracy by extracting RMS features and classifying them with subtractive fuzzy c-means (SFCM) clustering method. In their recent study [18], they attempted to classify eight gestures using SFCM plus adaptive neuro-fuzzy inference system (ANFIS). By considering only EMG signals, 93.02% discrimination accuracy was attained.In our previous studies we focused on developing this technology. To decrease the rate of computational load during processing, we proposed a two channel-based facial gesture recognition system [19] where 90.8% accuracy was obtained by FCM for recognizing five gestures. A comparative study was carried out where FCM outperformed SVM in classifying eight facial expressions recorded by three bipolar channels [20]. A multipurpose interface was designed through ten facial gestures for human machine interface (HMI) applications and 90.41% discrimination rate was achieved by FCM. Moreover, the best combinations of facial gestures were introduced for different applications with two to ten control commands [21]. The effectiveness of six different types of facial EMG features namely integrated EMG (IEMG), variance, wave length (WL), mean absolute value slope (MAVS), MAV and RMS were compared and evaluated for the classification of ten gestures where RMS outperformed the other features [22]. In [23], the effectiveness of conventional Multilayer Perceptron (MLP) and RBF Neural Networks were investigated and compared in order to classify the facial myoelectric signals. Although RBF could provide more reliable performance in both terms of accuracy and speed, the obtained accuracy was lower than previous studies. Recently, a versatile elliptic basis function neural network (VEBFNN) classifier was studied for recognizing the facial gestures [24]. Results indicated that, despite very low computational cost for training the network, classification accuracy was not improved.According to the mentioned experiments, as long as the maximum number (ten) of facial gestures is concerned, FCM provided a high level of accuracy for classification with a slow performance whereas VEBFNN performed very fast with a lower accuracy. However, a promising classifier should meet the major pre-requisite of real-time MuCI systems which is a reliable trade-off between speed and accuracy. This requires the implementation of a more efficient learning agent capable of classifying complex facial neuromuscular patterns. Different nonlinear methods have been proposed to classify different states of neuromuscular signal activities among which SVM has shown its robustness in coping with the randomness and non-stationary essence of EMGs [25]. The most important feature of SVM is that optimization problems are intrinsically convex and have no local minima which is derived from employing Mercer's conditions on the characterization of the kernels [26]. Solving quadratic optimization problems in SVM requires high computational cost; thus, a modified version called least-square support vector machine (LS-SVM) was proposed by Suykens and Vandewalle [27]. In this method, equality constraints are used instead of inequality ones employed in the SVM. It is stated that the efficiency underlying the induction of LS-SVM classifier significantly depends on the appropriate selection of hyperparameters values [28]. This has been addressed by introducing a range of methods such as cross-validated model selection, extensive grid search and heuristic optimization rules [29,30]. Despite the reported success of employing LS-SVM in numerous researches such as [31–34], to the best of our knowledge the capability of LS-SVM classifier has not yet been examined in terms of EMG analysis, especially for the classification of different facial neuromuscular signals.In this paper, a multiclass LS-SVM was proposed to classify ten different facial gestures EMGs. Since the efficiency of this method depends significantly on the appropriate selection of kernel hyperparameters, a range of scenarios were investigated to tune the parameters manually and automatically with respect to different performance measures. LS-SVM models were constructed by considering various kernels, optimization methods, multiclass encoding schemes and cost functions. These models were evaluated and compared in order to find the one with the best performance in both terms of classification accuracy and computational cost. This investigation also revealed the most efficient optimization technique and encoding scheme of LS-SVM for facial EMG classification in this study. Finally, the suggested model that provided the best result was evaluated and compared with other popular classifiers.The remaining parts of this paper are outlined as follows. Next Section presents summarized background information of LS-SVM. Methodologies used for data acquisition, experiments, analysis and evaluation are described in Section 3. Subsequently, the experimental results and statistical findings are investigated and the impact of different kernels, optimization functions and encoding schemes are explored. Finally, in Section 5, conclusions are reported.SVM is a nonparametric machine learning algorithm which is originally designed for binary classification [35]. Considering the given training data sets{(xi,yi)}i=1Nwith yi∈{±1}, SVM maps the input patterns xi∈ℜminto a higher dimensional feature space by means of some nonlinear mapping function, ϕ:ℜm→ℜn. SVM finds a classification function that separates data classes with the maximum margin through a hyperplane,wTϕ(x)+bin ℜnwhere w is formed by a linear mixture of the set of nonlinear data transformationsw=∑i=1Nβiyiϕ(xi)andb=−0.5w,xr+xsin which βiis the Lagrange multiplier, xrand xsare data points near the optimal hyperplane known as “support vectors” from each class satisfying βr>0, yr=−1;βs>0, ys=1. In the conventional SVM, optimal separating hyperplane is obtained by considering margin maximization and training error minimization through solving the quadratic programming (QP)minw,b(1/2)(wTw)+γ∑i=1nϑisubject to the constraintsyi(w×φ(xi)+b)≥1−ϑi, for i=1, ..., n. Where γ is a regularization hyperparameter and ϑiare slack variables measuring the error between yiand the actual SVM output. In order to facilitate solving QP problem, the use of kernel functions are proposed. A kernel function enables the operation to be carried out in the input space rather than in the high dimensional feature space. Various kernel functions deliver different feature spaces and therefore different generalization susceptibility of the resultant classifier. In this paper, linear kernelK(xi,xj)=xi.xjTand RBF kernelK(xi,xj)=exp(−xi−xj2/2σ2)are considered where σ denotes the kernel parameter [36].For multiclass classification, the problem reforms into a set of binary classification problems by considering the multiple hyperplane separations where input vectors and training labels are specified as{xi,yic}i=1,c=1i=n,c=C, in which n and C are the training pattern index and the number of classes respectively. There are various multiclass categorization techniques and encoding schemes introduced to address the multiclass problems. Four popular methods are one-vs-one (OVO), one-vs-all (OVA), Minimum Output Coding (MOC), and Error Correcting Output Coding (ECOC). OVO applies SVMs to the selected pairs of classes where C(C−1)/2 hyperplanes separate the classes. OVA creates C hyperplanes which discriminate each class from the rest. Encoding schemes represent each class Mc, c=1, ..., C, by a unique binary output code-word Mc∈{−1, +1}Lof L bits. Then, L binary classifiers are trained to discriminate two opposing subsets with different output bits. MOC is applied to solve the multiclass problem using the minimum number of bits (L) to encode up to 2Lclasses while ECOC uses redundant bits to encode each class. There are several decoding schemes for assigning the multiclass label to a new input x. In this paper, Hamming distance decoding [37] is used which computes the output vector y∈{−1, +1}Las the sign of the outputs of the L binary discriminants. The class label Mcis then assigned to the corresponding code-word mcwith minimal Hamming distance to the output vector y.Solving quadratic optimization problem during the training stage in SVM causes a high degree of computational cost. To address this issue, a least squares type of SVM is introduced by Suykens and Vandewalle [27]. In this method, the least squares cost function with equality restraints is considered in order to obtain an optimal solution through solving a set of linear equations to be used for training. LS-SVMs are closely related to regularization networks [38] and Gaussian processes [39] but additionally emphasize and exploit primal-dual interpretations. Multiclass LS-SVM is trained byminwk,bk,ϑi,k(1/2)∑k=1mwkTwk+(γ/2)∑i=1n∑k=1mϑi,k2where m is the number of classes. Detailed information about LS-SVM can be found in [27,40].Facial EMGs have small amplitude and they are contaminated by external and internal factors like motion artifacts, eye movement, brain activity and recording device itself. In addition, they are inherently non-stationary and their characteristics vary within different muscle movements and subjects even during the isotonic muscle movements. Moreover, signal amplitude of different subjects which is the major component of EMGs for classification vary based on active motor units and their activation rate. So, in order to record high quality EMGs with desirable signal to noise ratio (SNR) and to minimize inter-subject variations, several considerations must be taken into account. In this study, at first, the positions of electrodes on participant's face were cleaned from any sweat and dust by using alcohol pad to minimize the impedance between electrodes and skin and remove the motion artifacts. Then, the lead wires were secured via adhesive tape and sufficient numbers of electrodes were placed on the most optimum face sites to capture all facial gestures EMGs with high amplitude [41]. In addition, to eliminate the common noise, bipolar electrodes configuration was applied where signals between the two electrodes were amplified differentially with respect to the reference electrode. Thus, as shown in Fig. 1(a) six electrodes were used for recording signals through three channels simultaneously. Channel 1 was placed on Frontails muscle (above the eyebrows), channel 2 and 3 were located on right and left Temporalis muscle and one electrode was positioned on the boney part of left wrist as the ground. There was a distance of about 2cm between electrodes in each channel. As another solution for inter-subject variations, EMGs were recorded in consecutive sections by keeping the electrodes on the same location [42].The protocol of this experiment was approved by the Universiti Teknologi Malaysia Human Ethics Research Committee. In the present experiment, facial EMGs were recorded via BioRadio 150 (Clevemed) and they were sampled at ∼1000Hz using a 12 bit A/D converter. EMGs were passed through a notch (50Hz) and high-pass filters with a cut-off frequency of 0.1Hz in order to remove undesirable artifacts from user movements and inference line noises. A band-pass filter within the range of 30–450Hz was also employed to envelope the most significant spectrum of signals. Ten healthy volunteers including five male and five female in the age range of 20–37 participated in this study. The facial gestures considered were smiling with both sides of the mouth, smiling with left side of the mouth, smiling with right side of the mouth, opening the mouth (saying ‘a’ in the word apple), clenching the molars, gesturing ‘notch’ by raising the eyebrows, frowning, closing both eyes, closing the right eye and closing the left eye (Fig. 1). All subjects were asked to perform each facial gesture five times lasting for 2s with 5s rest between to reduce the effect of muscle exhaustion. Since for each gesture, 10 (5×2)s was informative and EMGs were captured through three channels simultaneously, a three dimensional data set[Ch1;Ch2;Ch3]3×10Twas achieved. Therefore, for each subject ten (number of gestures) data sets of 3×10s were collected for further processing.Feeding all conditioned signals directly to a classifier is not practical because of the enormous amount of data and some non-informative EMGs. Therefore, signals must be mapped into lower dimension information vectors (feature vectors) to highlight the most important properties of EMGs. Accordingly, data need to get segmented into a sequence of time portions prior to feature estimation. It is reported that, a short segment results in bias and variance in feature extraction whereas a long one leads to high computational cost and may fail real-time operations [25]. In this study, filtered signals were segmented into non-overlapped windows with 256ms length and therefore 39 segments were obtained (10,000÷256≈39) for each gesture in each channel. Fig. 2illustrates the first four segments of clenching molars in channel one.Feature extraction tends to highlight the most important properties of EMGs to avoid processing a huge amount of data. A suitable feature should carry proper information to discriminate facial gestures and have low computational complexity to be applicable for real-time MuCI applications. Features have direct role on the classifiers performance in both terms of accuracy and computational cost; efficient features facilitate the training procedure and provide a feature space with maximum margin within different class patterns. Many studies have examined various types of time-domain (TD), frequency-domain (FD), and time-scale features for MuCI control systems. Literature shows that there are some restrictions when analyzing facial EMGs through their spectrums since they contain similar frequency components. Therefore, EMGs cannot be processed either by FD or time-frequency distribution algorithms for facial gesture recognition [20,43]. More appropriate characteristics of facial EMGs are TD ones as they are easy to compute and they work base on signal amplitudes. Amplitude is affected by the number of active motor units (muscle fibers+motor neuron) and their activation rate, action potential resulting from different muscle movements, signaling source and innervation ratio of muscles [44]. So, facial EMG amplitude represents activation level, signal energy and contraction duration of the muscles involved in forming different facial gestures. It is reported that EMG power usually identified by RMS TD feature [45] is an excellent measure since in a stable force and non-fatiguing contraction it gives the best estimation of amplitude when a signal is formed as a Gaussian random process. The high potential of this type of feature for facial gesture recognition has already been examined in [19,21]. The efficiency of this feature was also compared to other popular TD features MAV, MAVS, IEMG, WL and signal variance [22]. It was indicated that RMS resulted in maximum classification accuracy as it provided more discriminative information and delivered more clean boundaries within different facial gestures patterns. Therefore, in this study, RMS was computed and extracted from each signal segment which resulted in 39 RMSs for each gesture in each channel. By considering three channels, the feature vector was constructed as[Ch1;Ch2;Ch3]3×39Tfor each gesture and consequently[Ch1;Ch2;Ch3]3×390Tfor each subject. In order to have more separable feature vectors, log transform was employed on extracted features to spread the concentrated features [46].In order to classify and discriminate the RMSs extracted from the facial neuromuscular activities, LS-SVM technique was implemented in this study. As stated earlier, LS-SVM is a non-parametric supervised method with a robust theory for solving non-linear classification problems. Since EMG data are non-stationary and their characteristics vary with time, LS-SVM may perform better in classification of different facial gestures than the conventional supervised classifiers. In order to investigate the behavior and efficiency of LS-SVM on facial gesture classification, different models of this classifier were constructed and examined so as to find a desirable one. As depicted in Fig. 3, the models parameters were at first initialized; then they were tuned manually and automatically; and finally the model training was performed. This procedure was carried out in MATLAB 8.1 by means of LS-SVMlab toolbox version 1.7 [47] as the core of a multiclass LS-SVM classifier. The experimental platform was composed of Intel core i7 CPU, 1.73GHz with 8GB physical memory.In this step, LS-SVM models architecture were initialized by setting the type of kernel function, Linear or RBF. Both of these kernels contain regularization (γ) parameter which determines the trade-off between training error minimization and smoothness of the estimated function. Low and high γ emphasize minimizing the model complexity and good fit of the training data points respectively. Smoothing (σ2) is another RBF kernel parameter which is commonly the squared bandwidth and a larger σ2 indicates stronger smoothing [48]. These parameters must be optimally tuned in order to deliver accurate performance for LS-SVM which is explained in the next section.As stated earlier, LS-SVM model parameters need to be tuned properly so as to select the most optimum ones that can deliver the best performance; consequently, some kind of model selection (parameter search) must be done. Global optimization methods are the well-known techniques to estimate the tuning parameters but very slowly. Due to the observed shortcomings, ensuring convergence to a global optimum might be impractical therefore faster convergence techniques could be more suitable solutions. Accordingly, Simulated Annealing (SA) algorithms [49,50] and other heuristic based techniques have been introduced. A typical method is grid-search which searches over a manually specified subset of parameters and performs a cost function for each of the grid values to select the best ones. Another method is Simplex which is well-defined for problems with derivatives that may not be known [51] and can be used when the number of hyper-parameters is quite small. This method finds a local minimum of a function starting from an initial point. The local minimum is located via the Nelder–Mead simplex algorithm which does not require any gradient information. However, this technique is a heuristic search method that can converge to non-stationary points [52]. These two methods often get trapped in poor optima because of the speed-up procedures. A better alternative for tuning parameters is an extension to the well-known SA algorithm [50] with variance control, Coupled Simulating Annealing (CSA) [53]. This method aims to escape from local optima and improve the solution quality without compromising the speed of convergence too much. As a main difference with SA, CSA presents a new form of acceptance probabilities functions to be employed on ensemble of optimizers. This technique considers several current states which are coupled together by their energies in their acceptance function. Moreover, parallelism is an intrinsic feature of CSAs and it is reported that they are more efficient than multi-start gradient descent optimization [54]. Another benefit of CSA is that it controls the variance of the acceptance probabilities via the acceptance temperature. This results in improved optimization efficiency since it reduces the algorithm sensitivity to the initialization parameters while guiding the optimization process to quasi-optimal runs.In this article, model parameter tuning was carried out manually and automatically. In the former, a wide range of model parameters (γ, σ2) values were tested manually to pick those which resulted in the best performance. In the latter, the model parameters (γ, σ2) were tuned in two steps to overcome the drawbacks of the mentioned single optimization techniques. At first, good initial start values were determined by means of CSA with the use of five multiple starters [55] and then Simplex or Grid-search were performed using the previous result as the start value for fine-tuning (Fig. 3). This procedure led to more optimal tuning parameters and hence better performance. The search limits of the CSA method were set toexp(−10),exp(10). Finally, the performance of the models was examined through three cost functions Leave-one-out cross-validation (LOOCV), K-fold CV (KCV) where K=5, and Generalized CV (GCV) in order to validate the models and select the parameters which delivered the optimum model performance.In this study, the whole RMS feature set ([Ch1;Ch2;Ch3]3×390T) was shuffled and divided into about 75% and 25% for training ([Ch1;Ch2;Ch3]3×300T) and testing ([Ch1;Ch2;Ch3]3×90T) stages respectively. Training the LS-SVM model was conducted in three steps (Fig. 3) as follows: at first, the preprocessing assigned a label to the train feature set of each class. For instance, label ‘1′ was assigned to the first 30 RMSs (indicating class #1, clenching the molars), label ‘2’ for the second 30 RMSs (indicating class #2, raising the eyebrows) and so forth. Then, they were rescaled to the binary labels −1 and +1. After that, RMSs served to predict the LS-SVM model and multi-class problem was decomposed in a set of binary classification problems using encoding techniques OVO, OVA, MOC and ECOC. These encoding schemes resulted in corresponding codebooks to represent each class. Finally, to detect the classes of a disturbed encoded signal given the corresponding codebook, Hamming distance (HD) function was employed to decode the generated code-words into original form.For classification, different LS-SVM models were formed by considering various methods in each step. This paper aimed to find the best model with the best performance. As shown in Table 1, for automatic and manual modes 48 and 8 models were made respectively. Methods used for preprocessing and decoding scheme in all models were the same and CSA was used as the first optimization technique in all automatic models. The models of automatic mode included orderly kernel function, second optimization technique, cost function and encoding scheme whereas in the manual mode only kernel function and encoding scheme varied in the models.In order to evaluate the behavior and effectiveness of constructed models for facial gesture recognition, two main performance metrics classification accuracy and computational cost were considered. The accuracy of testing session was computed and finally considered as the classification performance. Moreover, the time consumed during tuning and training stages was measured as the computational cost index. Tuning time was only considered for the models in automatic mode while training time was calculated for both automatic and manual models. All mentioned experiments were statistically analyzed to interpret the results.

@&#CONCLUSIONS@&#
