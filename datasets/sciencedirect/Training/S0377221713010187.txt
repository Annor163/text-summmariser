@&#MAIN-TITLE@&#
Inferring robust decision models in multicriteria classification problems: An experimental analysis

@&#HIGHLIGHTS@&#
We examine the robustness of inferring multicriteria classification models.Analysis of the relationship between robustness and the quality of the models.Introduction of a new model inference procedure based on the Chebyshev center.

@&#KEYPHRASES@&#
Multiple criteria analysis,Robustness,Disaggregation analysis,Monte Carlo simulation,

@&#ABSTRACT@&#
Recent research on robust decision aiding has focused on identifying a range of recommendations from preferential information and the selection of representative models compatible with preferential constraints. This study presents an experimental analysis on the relationship between the results of a single decision model (additive value function) and the ones from the full set of compatible models in classification problems. Different optimization formulations for selecting a representative model are tested on artificially generated data sets with varying characteristics.

@&#INTRODUCTION@&#
The elicitation, modeling, and representation of preferential information are crucial steps in providing decision-makers (DMs) with sound decision analysis and aiding tools. Multiple criteria decision aid (MCDA) provides a wide arsenal of techniques and approaches to address such issues in the context of decision problems involving multiple (conflicting) criteria. Among others, MCDA techniques employ information on the preferential system of the DM to build criteria aggregation models for evaluating a set of alternative ways of action.Information on the DM’s preferential system and judgment policy can be obtained either directly or indirectly. In this paper we concentrate on the latter approach, referred to as “preference disaggregation analysis” (PDA, Jacquet-Lagrèze & Siskos, 2001). The disaggregation framework does not require the DM to provide the analyst with specific details on the parameters that define the criteria aggregation model. Instead, the model building process is based on the analysis of a small set of representative decision instances (reference set), using non-parametric regression techniques.The quality of models resulting from disaggregation techniques depends not only on the information embodied in the sample of decision instances but also on the properties of the model fitting process. In this context, the issue of robustness has recently received much attention (Roy, 2010). The research in the area of building robust multicriteria decision models and obtaining robust recommendations with disaggregation techniques has adopted two main approaches. The first is based on the use of analytic methodologies for: (a) formulating preference relations and recommendations based on characterizations of the range of decision models compatible with the DM’s judgments on the reference set (Greco, Mousseau, & Słowiński, 2010; Kadziński, Greco, & Słowiński, 2012) and (b) building robust decision models that best represent the information embodied in the reference data (Bous, Fortemps, Glineur, & Pirlot, 2010; Doumpos & Zopounidis, 2007; Greco, Kadziński, & Słowiński, 2011). The second line of research has focused on using simulation techniques to sample different decision models compatible with the DM’s preferences in order to form robust recommendations (Kadziński & Tervonen, 2013), thus enriching analytic procedures with a more detailed/explicit view of the outputs that can be obtained from the universe of compatible models.Vetschera, Chen, Hipel, and Kilgour (2010) conducted an experimental investigation of the robustness of the information embodied in a reference set in the context of multicriteria classification problems. In this study we extend this analysis by focusing on the robustness and performance of representative decision models fitted on a set of reference alternatives using different optimization formulations. Using a good decision model that best represents the information provided by the DM on the reference data and provides robust results is of major importance in the context of decision aiding. Having an analytic or simulation-based characterization of all compatible models provides the DM with a comprehensive view of the range of possible recommendations that can be formed. On the other hand, a single representative model is easier to use as it only requires the DM to “plug-in” the data for any alternative into a functional, relational, or symbolic model. Furthermore, the aggregation of all evaluation criteria in a single decision model enables the DM to get insight into the role of the criteria and their effect on the recommendations formulated through the model (Greco et al., 2011).Traditional disaggregation techniques such as the family of the UTA methods (Siskos, Grigoroudis, & Matsatsinis, 2005) use post-optimality techniques based on linear programming in order to build a representative additive value function (AVF) defined as an average solution of some characteristic models compatible with the DM’s judgments. Recently, a number of other approaches have been proposed. For example, Greco et al. (2011) proposed a procedure (which implements max–min optimization models) for building a representative AVF that provides recommendations on possible assignments corresponding to the most stable results of a robust ordinal regression analysis. The proposed procedure is iterative allowing the DM to specify (interactively) at each iteration different targets that a representative model should achieve. Similar processes can also be used for the construction of representative AVFs in a group decision making context (Kadziński, Greco, & Słowiński, 2013). Kadziński and Tervonen (2013) extended this approach through its combination with a simulation process, which enhances the results of robust ordinal regression with assessments on the acceptability (i.e., confidence) of the assignments and proposed an optimization model to construct a model that best represents the simulation results. Instead of interactive and iterative model building procedures, other studies have focused on the introduction of optimization formulations based on new model fitting criteria. For instance, Doumpos and Zopounidis (2007) proposed a formulation based on the regularization principle of statistical learning, whereas Bous et al. (2010) presented a model based on the concept of the analytic center.In this study we analyze such approaches (also introducing a new linear programming model) in order to examine the way in which their results represent the information provided by the DM’s reference judgments and their relationship with the robust recommendations that can be formulated on the basis of this information. Among others, the objectives of the analysis include the investigation of: (a) the association between robustness and the selection of representative decision models defined by parameters that lie near the “center” of the set that consists of all models compatible with the DM’s preferences, (b) the connection between the complexity of a decision model and its robustness and accuracy, and (c) the ability of different model inference procedures to cope with models of increasing complexity and the impact that the characteristics of the data have on the robustness of the inference process. The analysis is based on simulated data generated with different characteristics, in the context of multicriteria classification problems, which have recently received much attention among MCDA researchers (Zopounidis & Doumpos, 2002). We focus on decision models expressed in the form of linear and piecewise AVFs, which are widely used in MCDA. The results of the analysis contribute in improving the understanding of the features of disaggregation approaches that aim towards identifying representative decision models, as well as clarifying the relationship between the results of such approaches with the concept of robustness in decision aid.The rest of the paper is organized as follows. Section 2 presents different optimization-based approaches for constructing AVFs in classification problems that best represent the set of models compatible with the DM’s judgments on some decision examples. Section 3 discusses the experimental setting used for the comparison of the selected approaches, whereas Section 4 presents and analyzes the obtained results. Finally, Section 5 concludes the paper and outlines some future research directions.AVFs constitute a simple and easy to use modeling approach to decision aiding problems. They are based on a sound theoretical framework (multiattribute value theory), and despite their reliance on specific preferential independence conditions (Keeney & Raiffa, 1993), they are widely used in decision aiding and modeling.Assuming that K criteria are used in a multicriteria evaluation context, an AVF introduces a criteria aggregation model, under which the global value (performance) of an alternative i is obtained as follows:(1)V(xi)=∑k=1Kwkvk(xik)wherexi=(xi1,xi2,…,xiK)is the vector with the data for alternative i on the evaluation criteria,wk⩾0is the trade-off coefficient for criterion k (the normalizationw1+w2+…+wK=1is often used) andvk(·)is the marginal value function of criterion k. The marginal value functions define the partial performance of the alternative on each criterion, usually in a scale between 0 and 1.Under the decision model (1) an alternative i is preferred over an alternative j if and only ifV(xi)>V(xj), whereas the alternatives are indifferent ifV(xi)=V(xj). In a multicriteria classification setting, each alternative should be classified in a set of N pre-defined categories{C1,…CN}ordered such that categoryC1includes the best alternatives and categoryCNthe worst ones. An AVF model can be easily used to classify any alternative i as follows:(2)tℓ<V(xi)<tℓ-1⇔Alternativeibelongs to classCℓwheret0=1>t1>t2⋯>tN-1>tN=0is a set of thresholds that distinguish the categories. Cases whereV(xi)=tℓclearly lead to some ambiguity in the assignment of alternative i to one of the predefined categories (i.e., it can be assigned toCℓorCℓ+1). In the context of this study we assume that any test alternative i withV(xi)=tℓis assigned to categoryCℓ.The construction of the AVF can be simplified by settinguk(xk)=wkvk(xk), which leads to a rescaled set of marginal value functionsu1,…,uKnormalized in[0,wk]. With this transformation, the AVF model (1) is expressed in the following equivalent form:(3)V(xi)=∑k=1Kuk(xik)The AVF model can be linear or nonlinear depending on the form of the marginal value functions. A convenient and flexible way to take into consideration a wide class of monotone marginal value functions, is to assume that they are piecewise linear. Under this scheme the scale of each criterion k is split intosk+1subintervals defined byskbreak-pointsβ0k<β1k<⋯<βsk+1k, between the least and the most preferred levels of the criterion (denoted byβ0kandβsk+1k, respectively). Thus, the marginal value of any alternative i on criterion k can be expressed as:(4)uk(xik)=∑r=1skpikrdkrwheredkr=uk(βrk)-uk(βr-1k)⩾0is the difference between the marginal values at two consecutive break-points of criterion k and(5)pikr=0ifxik<βr-1kxik-βr-1kβrk-βr-1kifxik∈βr-1k,βrk1ifxik>βrkTherefore, the AVF (3) can be expressed as a linear function of the step differences in the marginal values between consecutive break-points in the criteria’s scale:(6)V(xi)=∑k=1Kpik⊤dkwherepik=pik1,pik2,…,pikskanddk=(dk1,dk2,…,dksk).In a preference disaggregation framework for classification problems, the DM provides a reference set consisting of decision examples for M alternatives. The reference alternatives are classified into the pre-defined categories, and the objective is to infer the parameters of the AVF model (i.e., the vectorsd1,…,dKand the classification thresholds) that are consistent with the classification of the alternatives. Thus, the inferred model of the form (6) should satisfy the following set of linear constraints:(7)V(xi)⩾tℓ+δ∀alternativeifrom categoryCℓ(1⩽ℓ⩽N-1)(8)V(xi)⩽tℓ-1-δ∀alternativeifrom categoryCℓ(2⩽ℓ⩽N)(9)∑k=1K1⊤dk=1(10)dk⩾0k=1,…,Kwhere1=(1,1,…,1)is a vector of ones. Constraints (7) and (8) ensure that the model is consistent with the classification of the reference alternatives on the basis of the classification rule (2). In these constraintsδis a small positive constant used to avoid arbitrary results that arise when the global value of an alternative equals a classification threshold. Constraint (9) normalizes the AVF such that an ideal alternative (i.e., with the most preferred levels in each criterion) receives a global value equal to one, whereas the non-negative constraints (10) on the parameters of the AVF model ensure that the marginal value functions are non-decreasing (assuming that all criteria are expressed in maximization form).If the DM’s classifications of the reference alternatives are consistent with an AVF evaluation model, then the polyhedron defined from the above constraints will be non-empty, thus implying that there is an infinite number of alternative AVFs (each corresponding to a feasible solution) consistent with the DM’s judgments of the reference set. This raises the issue of how can a single representative AVF be chosen from the set of feasible solutions of the above constraints. This issue is even relevant when inconsistencies exist in the decision examples of the reference set, as these inconsistencies can be resolved (algorithmically or interactively with the DM; Mousseau, Figueira, Dias, Gomes da Silva, & Clímaco, 2003), thus making the robustness concern still relevant in this case too.In the following subsections we present the alternative approaches considered in this study for selecting a single AVF representing the DM’s classifications of the reference alternatives. The selected approaches, include: (a) a post-optimality procedure that was the first to be introduced in order to explore some characteristic feasible solutions to the polyhedron (7)–(10) and obtain a “central” decision model, (b) a max–min formulation that has been used in several studies in a robust PDA context, (c) a recently proposed analytic center formulation that operationalizes the “centrality” concept in a more rigorous manner (compared to ad hoc post-optimality procedures), and (d) a new model based on the concept of the Chebyshev center of a polyhedron, which can be identified with a linear programming formulation.To cope with the existence of multiple decision models compatible with the DM’s evaluations of the reference alternatives, Jacquet-Lagrèze and Siskos (1982) introduced a heuristic post-optimality procedure, which involves the solution of K pairs of linear programs, corresponding to the maximization and the minimization of the trade-off constant for each criterion k, i.e.:(11)max/min1⊤dk|s.t.:(7)–(10)The2Ksolutions obtained from this post-optimality process are some characteristic extreme solutions of (7)–(10), and their average can be used to form a “representative” AVF model as an approximation of the polyhedron’s centroid solution. Such a centroid solution can be considered as representative of the feasible polyhedron of compatible models as it is less likely to be affected by changes in the DM’s judgments on the reference alternatives (i.e., thus being more robust).Max–min optimization formulations are often used in PDA in order to infer the parameters of decision models from assignment examples. For instance, in the context of multicriteria classification problems, such formulations have been used by Zopounidis and Doumpos (2000) in the MHDIS method, Dias, Mousseau, Figueira, and Clímaco (2002) in the ELECTRE method, whereas Greco et al. (2011) used max–min formulations to infer a representative value function in robust multiple criteria classification procedure. Similar models, in the context of ranking problems where also considered by Beuthe and Scannella (2001).In the PDA setting considered in this study, a max–min formulation to infer a model compatible with the DM’s judgments on a set of reference decision instance can be expressed as follows:(12)maxδ|s.t.:(7)–(10)This formulation seeks to maximize the minimum separating gap between two consecutive classes. Bous et al. (2010) note that such a formulation shrinks the original polyhedron, thus forming a more “central” set and yielding solutions that are away from the boundaries of the original polyhedron (i.e., the obtained decision model satisfies the DM’s preferences in a clearer and more robust manner).The above max–min approach can also be explained on the grounds of the regularization principle, which is a popular approach in statistical and machine learning for improving the robustness of prediction models with respect to changes in the reference set (Hastie, Tibshirani, & Friedman, 2001). Based on this approach, Doumpos and Zopounidis (2007) introduced a formulation, which in the case of a consistent reference set, can be expressed as follows (a regularization approach to construct an additive preference model in the context of the dominance-based rough set approach has also been presented by Dembczyński, Kotłowski, & Słowiński (2006)):(13)min∑k=1K1⊤dk|s.t.:(7), (8), (10)The main feature of the model is that the normalization constraint (9) is no longer taken into consideration. Instead, the AVF model is normalized after the solution of the above problem is obtained. In particular, denoting byF∗the optimal objective function value of (13), the normalized AVF model is simply obtained by dividing the optimal solution of (13) withF∗(Doumpos & Zopounidis, 2007 described the conditions under which it is possible to haveF∗=0; nevertheless, this is not possible when the reference set is consistent). The following theorem shows the connection between formulations (12) and (13).Theorem 1The solutions of problems(12)and(13)are equivalent.Suppose that (13) is solved for some user-definedδ=δ0>0and letF∗>0be the optimal objective function value. The optimal solution of (13) normalized with the procedure described above, is feasible to (12) and yields an objective function value for (12) equal toδ0/F∗. If there was a solution to (12) withδ>δ0/F∗, then rescaling it (i.e., multiplying) byδ0/δleads to a feasible solution for (13) with objective function valueδ0/δ<F∗, which contradicts the initial hypothesis thatF∗is the minimum value for the objective function of problem (13).Similarly, suppose that (12) is solved and letδ∗>0denote its optimal objective function value. This solution is feasible to (13) forδ=δ∗and the corresponding objective function value is equal to one. If there was another solution to (13) with objective function value F such that0<F<1, then dividing it by F leads to a solution that is feasible to (12) with objective function valueδ∗/F>δ∗, which contradicts the initial hypothesis thatδ∗is the maximum objective function value for problem (12).Thus, the optimal solutions of the two problems only differ by a scaling factor. In that regard they are equivalent. □The third modeling approach used in this study is based on the analytic center formulation introduced by Bous et al. (2010). The analytic center of a polyhedron is defined by a feasible solution that maximizes the logarithmic barrier function of the constraints’ slacks. In the context of this study we adapt the optimization model of Bous et al. (2010) to find the analytic center of the polyhendron defined by (7)–(10). This is performed through the solution of the following convex nonlinear program, which is easily solvable with existing algorithms (e.g., Newton’s method).(14)max∑i=1Mlnsi++lnsi-+∑k=1K1⊤lnyksubject to:V(xi)-tℓ-si+=δ∀i∈Cℓ,1⩽ℓ⩽N-1V(xi)-tℓ-1+si-=-δ∀i∈Cℓ,2⩽ℓ⩽Ndk-yk=0k=1,…,K∑k=1K1⊤dk=1si+,si-,tℓ,yk,dk⩾0∀i,ℓ,kCompared to the previous approaches, this formulation is based on a more rigorous definition of “centrality” for the resulting decision model. Furthermore, from an optimization perspective the solution to the above problem is unique (Bous et al., 2010), thus minimizing the ambiguity that often arises due to the existence of multiple optimal solutions in linear programming formulations for inferring the parameters of decision models.The last model that we test in this study is a new variant-extension of model (12). Effectively, (12) constructs an AVF such that the minimum “satisfaction” of the constraints (7) and (8) is maximized (i.e., the minimum separating gap between the categories). However, there is no rigorous association between this optimality objective with the characteristics of the polyhedron (7)–(10) and its robustness. The analytic center model described earlier seeks to address this issue, by focusing on identifying the analytic center of the polyhedron.Alternatively, it is possible to construct an AVF model from the Chebyshev center of the polyhedron. The Chebyshev center corresponds to a feasible solution from which the largest possible ball of radius r can be inscribed within the polyhedron (Boyd & Vandenberghe, 2004). In this study we employ this approach to find the Chebyshev center of the polyhedron (7)–(10). The following linear programming model is used for this purpose (for details see Boyd & Vandenberghe, 2004):(15)maxrsubject to:V(xi)-tℓ-air⩾0∀i∈Cℓ,1⩽ℓ⩽N-1V(xi)-tℓ-1+bir⩽0∀i∈Cℓ,2⩽ℓ⩽Ndk-1r⩾0k=1,…,K∑k=1K1⊤dk=1dk,tℓ,r⩾0∀ℓ,kwhereaiandbiare the Euclidean norms of the decision variables’ (the vectorsd1,…,dKand the classification thresholds) coefficients in each of the constraints (7) and (8), e.g.ai=‖(pi1,pi2,…,piK,-1)‖2.The models presented in the previous section are tested and compared through a Monte Carlo simulation study based on artificially generated data, adopting an approach similar to the one used by Vetschera et al. (2010).All data used in the experimental analysis are generated from the multivariate normal distribution with zero mean, unit variance and correlations uniformly distributed in [0,0.2]. Similarly to Vetschera et al. (2010) we take into consideration different settings for the dimensionality of the data, as defined by the number of alternatives in the reference set, the number of criteria and classes, as follows:•Number of classes:N=2,3,4.Number of reference alternatives per class:M/N=3,5,10,15.Number of criteria:K=3,5,7.With these specifications, the reference sets used in the analysis involve both low dimensionality and complexity data (e.g., six alternatives from two categories with three criteria), up to larger and more complex ones (up to 60 alternatives in four classes with seven criteria). In all cases, a secondary test sample is also used consisting of 50 alternatives from each category.For each combination of the above three factors, 100 simulation runs are performed.1As a robustness check, the analysis was repeated with an additional set of 100 simulations. The differences between the two tests were found to be statistically insignificant even at the 10% level according to the Mann–Whitney non-parametric test.1To generate the data in each run, two data pools are first generated, each consisting of 1000 alternatives. The first pool is used to select (at random) the alternatives of the reference set, whereas the test alternatives are drawn from the second pool.The classification of the alternatives is performed with the following procedure. First, all alternatives in the two data pools are evaluated with a random AVF and their global values (scores) are obtained. Then, appropriate classification thresholds1>t1>t2>⋯>tN-1>0are specified at predefined percentiles of the global values of the alternatives in the data pool used to formulate the reference set (i.e., the definition of the thresholds is done independently of the data pool from which the test data are derived). In particular, for two-class problems the thresholdt1that distinguishes between the two categories is set equal to the median of the global values. For the three-class problems we use the 30% and 70% percentiles to sett2andt1, respectively, whereas for the four-class problems the 20%, 50%, and 80% percentiles are used to define the thresholdst3,t2,t1. Thus, in the multi-class instances, more alternatives are distributed in intermediate categories than the extreme ones, which is a realistic assumption. With these thresholds, all alternatives in the two data pools are assigned to the predefined number of categories. Finally, from each category a random selection is performed to formulate the reference and test sets with the composition (number of alternatives per category) noted above.For simplicity, it is assumed that the DM’s preferences are compatible with a linear AVF. Thus, a randomly generated linear AVF is used in each run of the simulation experiment to classify the alternatives in the two data sets. It should be noted, however, that employing a linear AVF model is not a restrictive setting, as piecewise linear additive models are also linear with respect to their parameters (i.e., they are expressed in the linear form (6)). Nevertheless, given that, in realistic cases, the actual preferential structure of the DM is not really known, an analyst may decide to employ a more general modeling form (e.g., piecewise linear AVF) than the one implied by the reference data in order to be able to get more general conclusions and gain insights that a simpler model (e.g., linear AVF) may fail to capture. When working with additive value models, this is based on the fact that a piecewise linear AVF completely covers a linear AVF, and consequently whatever result is derived by a linear AVF can also be obtained with a piecewise linear model, while the opposite is generally not true. However, as piecewise linear AVFs have more degrees of freedom, their robust inference from small reference sets is more involved and a poor PDA formulation may fail to provide good results. Thus, the robustness properties of the feasible polyhedron (7)–(10) are not only affected by the characteristics of the reference data, but also by the form of the decision model (e.g., as the AVF model becomes more complex, the polyhedron widens and the choice of a representative solution becomes more challenging). From this perspective, we also consider the inference of piecewise linear AVFs (with three subintervals for all marginal value functions of the criteria) from the reference data described above, in order to analyze how the above issue affects the robustness and quality of the results obtained with different PDA formulations (i.e., how the results of PDA formulations are affected when the set of alternative compatible models becomes larger).All computational experiments were performed in MATLAB® R2012b using a PC with a quad-core Intel i7-2600K/3.4GHz processor and 16GB of RAM.

@&#CONCLUSIONS@&#
In this study we presented an experimental investigation of some typical and recently proposed approaches for building a single AVF decision model representing the DM’s judgments on a set of reference examples in a PDA framework for classification problems. A new approach based on the Chebyshev center of the feasible polyhedron for the decision model’s parameters was also introduced.The obtained results lead to conclusions and suggestions, which analysts, researchers, and DMs should consider when using PDA approaches for inferring preferential information and constructing decision models from data. Among others, the following main points can be highlighted:•There is a strong positive association between the robustness of the recommendations obtained from a multicriteria decision model with central solutions of the polyhedron that describes the model’s parameters. This was confirmed by the similarity of the results obtained under the robust and centroid classification rules as well as the good results that the analytic and Chebyshev center formulations provided compared to other model inference approaches.The differences between alternative model inference formulations become larger in cases where the polyhedron of the model’s parameters is wide.Among the characteristics of the reference data, the number of reference alternatives from each category seems to be the most decisive factor, whereas on the modeling side, the number of free parameters of a model (i.e., its degrees of freedom) is also critical issue. On the other hand, robustness comparisons between problems with different number of categories can be troublesome (as alternative robustness measures may lead to conflicting indications).These findings suggest that the use of a good model inference formulation can indeed make a significant difference in a PDA context, particularly when working with small reference sets and complex models. Approaches that operationalize the search for central solutions seem to be the best options in such situations. On the other hand, the aggregation of a limited set of (rather arbitrary selected) extreme feasible solutions generated with post-optimality techniques may yield poor results. In any case, larger reference sets should be sought (whenever possible), which will not only improve the formulation of more robust recommendations and accurate models, but also reduce the impact of the model inference approach employed.However, the results of this study indicate that there is still room for developing new improved model inference formulations. Despite the good performance (relative to the other approaches considered in this study) of the models based on the concepts of the Chebyshev and the analytic center, their results were found to be inferior compared to the ones obtained with the robust and centroid rules. Thus, it is worthwhile to investigate the possibility of introducing new approaches (including interactive procedures, e.g., Greco et al. (2011)) that will facilitate the inference of better and more robust models, based on improved considerations of the concept of “centrality” for the feasible polyhedron.Except for the above issue, the robustness concern should also be explored in a more general context of model selection, considering not only model complexity (that was considered in this study), but also the effect of using different modeling forms (i.e., other functional, relational or symbolic models such as outranking methods and decision rule approaches), including cases where the selected type of model has incompatibilities with the DM’s system of preferences (e.g., when a model is inadequate to represent a complex preference structure). Other problem settings such as ordinal regression and choice problems can also be considered, together with further experimentation on real-world data. Finally, emphasis should be given to the construction of well-founded and meaningful indicators for measuring robustness with PDA approaches in a unified context applicable to different instances.