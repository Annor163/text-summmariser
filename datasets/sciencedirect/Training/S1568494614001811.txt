@&#MAIN-TITLE@&#
Elucidating multiprocessors flow shop scheduling with dependent setup times using a twin particle swarm optimization

@&#HIGHLIGHTS@&#
This study examines the multiprocessor flow shop problems with an objective function to minimize total weighted earliness and tardiness and machine idle time.We formulate an integer programming for the constrained due window and setups multiprocessor flow shop scheduling problems.Introduction to the proposed twin particle swarm optimization (TPSO).Various approaches are compared in small and large scale problems.Computational test results demonstrate the outstanding performance of the proposed method for the attempted problems.

@&#KEYPHRASES@&#
Twin particle swarm optimization,Multiprocessors flow shop scheduling,Setup time,

@&#ABSTRACT@&#
Particle swarm optimization (PSO) is a novel metaheuristic, which has been applied in a wide variety of production scheduling problems. Two basic characteristics of this algorithm are its efficiency and effectiveness in providing high-quality solutions. In order to improve the traditional PSO, this study proposes the incorporation of a local search heuristic into the basic PSO algorithm. The new, hybrid, metaheuristic is called “twin particle swarm optimization (TPSO)”. The proposed metaheuristic scheme is applied to a flow shop with multiprocessors scheduling problem, which can be considered a real world case regarding the production line. This study, as far as the multiprocessors flow shop production system is concerned, utilizes sequence dependent setup times as constraints. Finally, simulated data confirm the effectiveness and robustness of the proposed algorithm. The data test results indicate that TPSO has potential to replace PSO and become a significant heuristic algorithm for similar problems.

@&#INTRODUCTION@&#
Operations scheduling is implemented so as to optimize the use of resources, thus enhancing both production efficiency and customer satisfaction. The classification of production management combines distributing operational activities in order to reduce earliness, tardiness, machine idle cost, inventory cost and other operational costs. Many approaches, for solving a scheduling problem, can be found, offering a variety of results. In practical situations, the multiprocessors flow shop scheduling constitutes the most ordinary production scenario. This property is common in wafer fabrication facility, mold-making and accessories shop processing environments. Johnson [9] discussed the flow shop scheduling problem in his pioneer paper. In flow shop problems, various jobs go through a predetermined path and the sequence of machines is the same for all jobs. Baker [1] indicated that a common approach considered by most researchers is to find the minimum makespan solution. Huq et al. [8] pointed out that optimization algorithms did not always produce reasonable results when applied job shop and flow shop problems. Researchers have developed increasingly efficient heuristics and algorithms for solving different scheduling problems. Sriskandarajah and Sethi [15] proposed heuristic methods using LPT rule for the case of equal number of processors for a two-stage flow shop. Testing results demonstrated that this method efficiently solves problems. Dorigo et al. [3] applied the ant system using a population of co-operating agents, communicating via a distributed and shared memory system and proved that the proposed algorithm can be applied to combinatorial optimization problems. Kahraman et al. [10] developed a parallel greedy algorithm (PGA) for solving hybrid flow shop scheduling with multiprocessor task (HFSMT) problems. Test results indicate that the proposed parallel greedy algorithm approach is a valuable and effective method for solving complex optimization problems with reduced total completion time. Moslehi and Mahnam [14] proposed a Pareto method using particle swarm optimization and local search to solve the minimum of makespan, total and max workload cost of a flexible job-shop scheduling problem. Results indicated that this method efficiently solves this kind of problems. Engin et al. [4] proposed an efficient genetic algorithm (GA) program using a full factorial experimental design to solve the hybrid flow shop scheduling with multiprocessor task problem. Computational results indicated that the proposed approach efficiently solves the problem of makespan. In order to develop a practical methodology applicable in real world conditions, this paper investigates the essential multiprocessors flow shop scheduling problem, given the sequence dependent setup time.Regarding the machine idle time, Gupta et al. [5] proposed a full complexity classification model for two-stage no-wait scheduling with separate setup and removal time with the aim of minimizing the total completion time. Tang et al. [16] applied tabu search (TS) algorithm to solve steelmaking and refining coordinated scheduling problem. The objective is to minimize the sum of maximum completion time, idle time penalties and waiting time penalties satisfying waiting time constraints. Considering the computational results and the worst case scenario analysis, the applied algorithm efficiently solves this kind of problems. Furthermore, Huang and Lin [7] adopted a new bee colony optimization algorithm using idle-time-based filtering scheme based on the processes of the Forward Pass of bee's foraging behaviors. That is, less machine idle time saves resource and production costs with efficiency.Kennedy et al. [11] initially developed particle swarm optimization as an evolutionary computation technique mainly for continuous optimization problems through individual improvement plus population cooperation and competition. PSO has an excellent ability to solve scheduling problems in recent years. Nevertheless, PSO suffers limitations due to the varied nature of problems that can be encountered. Accordingly, various improvements to PSO have been proposed. Zhang and Sun [17] proposed an alternative two-phase particle swarm optimization algorithm called ATPPSO for solving the flow shop scheduling problem with the objective of minimizing makespan. The approach adopts a two-point reversal crossover operator including two processes, the attractive process and the repulsive process which execute alternatively. Test results show that the proposed ATPPSO algorithm is a valuable and effective PSO model for solving complex optimization problems. Choong et al. [2] proposed two hybrid heuristic algorithms that combine particle swarm optimization with simulated annealing (SA) and tabu search. Experimental results demonstrated that the method solves the problem with efficiency and produced improved solutions over conventional methods with faster convergence.This study examines the multiprocessors flow shop scheduling problem with dependent setup time, since this problem is more common and practical than most other problems. Due the complexity of the problem, a novel algorithm named twin particle swarm optimization based on PSO is proposed. This study adopts a new type of local search rule using twin particles to update the new velocities according to their previous velocity and the distance of their current local and global position. This local heuristic may assist the individual particles in efficiently identifying their next position. Compared to the basic PSO, the searching ability of the proposed algorithm is reinforced.Related definitions and notifications:F2(m1,m2)|stijk|C1×∑i=1nEi+C2×∑i=1nTi+C3×∑k=1mMIkThe problem is as follows: F2(m1, m2) represents a multiprocessors flow shop environment involving k machines; diis the due date; stijkrepresents different setup times on each machine;C1×∑i=1nEi+C2×∑i=1nTi+C3×∑k=1mMIkindicates that the objective is to minimize the sum of weighted earliness, lateness and total machine idle time.n=Total number of jobsm=Total number of machinesJi=Job of number iJij=The j-th operation of JiMkJi=Machine of number kJij=Jijis processed on MkOpi=Number of operations to finish JiStrtijk=Starting time of Jijkstijk=Sequence dependent setup time of Jijon Mkprijk=Processing time of Jijkdi=due date of JiZijstk=Fi=Completion time (Flow time) of JiFijk=Completion time of JijkEi=Earliness time of JiTi=Tardiness time of JiC1=Cost coefficient of earlinessC2=Cost coefficient of latenessC3=Cost coefficient of total machine idle timeObjectives formulation:(1)MinC1×∑i=1nEi+C2×∑i=1nTi+C3×∑k=1mMIk;i=1,2,…,n;k=1,2,…,mEq. (1): this model minimizes the sum of weighted earliness, tardiness and total machine idle time.Subject to:(2)Ei=Max(di−Fi,0);i=1,2,…,nEq. (2): earliness is the largest of (di−Fi) and 0.(3)Ti=Max(Fi−di,0);i=1,2,…,nEq. (3): lateness is the largest of (Fi−di) and 0.(4)Fi=Max(Fijk);i=1,2,…,n;j=1,2,…,Opi;k=1,2,…,mEq. (4): completion time of Jiis the maximum completion time on each machine.(5)Fijk=Strtijk+stijk+prijk;i=1,2,…,n;j=1,2,…,Opi;k=1,2,…,mEq. (5): completion time of Jijkis the sum of its starting time, setup time and processing time.(6)Fi(j−1)≤Strtij;i=1,2,…,n;j=1,2,…,OpiEq. (6): as for job Ji, the starting time of the j-th operation exceeds the completion time of the (j−1)-th operation.(7)Fijk×Zijstk≤Strtstk;i=1,2,…,n;j=1,2,…,Opi;y=1,2,…,m;s=0,1,…,n;t=1,2,…,Opo;k=1,2,…,m;i≠sEq. (7): when Zijstk=1, Jijkis processed before Jstk, and thus the starting time of Jstkis larger than the completion time of Jijk; meanwhile, when Zijstk=0, Jstkis processed before Jijk, and the starting time of Jstkexceeds 0.(8)Fstk−(Fstk+1)×Zijstk≤Strtijk;i=1,2,…,n;j=1,2,…,Opi;k=1,2,…,m;s=0,1,…,n;t=1,2,…,Opo;i≠sEq. (8): when Zijstk=1, Jijkis processed before Jstk, and thus the starting time of Jijkis larger than 0; meanwhile, when Zijstk=0, Jstkis processed before Jijk, and thus the starting time of Jijkis larger than the completion time of Jstk.(9)Cmax=Max(Fi);i=1,2,…,nEq. (9): makespan is the maximum completion time of Ji.(10)MIk=Cmax−∑i=1nFi∀i=1,2,…,n;k=1,2,…,mEq. (10): machine idle time is makespan minus the total processing time of Ji.Scientists have identified that corvids share food and help each other in difficult situations. In order to observe how well rooks would cooperate in finding optimal food sources, Holden [6] demonstrates that rooks, like chimpanzees, can cooperate in such tasks. Inspired by peer's cooperation, this study proposes the twin particle swarm optimization (TPSO), which enhances the new type of local search rule to find less neighbor function value, helps particles rapidly find the next position and solve the problem quickly. This adaptation process features proper operations on each scheduling sequence. Furthermore, artificial flocks can examine the fitness of the next feasible positions when adjusting to a better position regarding the food source. Accordingly, while searching for a better solution, the nearby function value found by twin particles decreases, then, more particles shift to there by updating inertia and velocity. Therefore, the following particles are more likely to choose this feasible position in definite search space.TPSO utilizes a new type of local search rule compared to the original PSO in order to update the inertia and velocity. Eq. (11) and (12) present the local search rule of TPSO.(11)Veqt=In×Veqt−1+c1×r1×(Plqt−1−Xqt−1)+c2×r2×(Pgqt−1−Xqt−1)+c3×ηIn Eq. (11), Xq=[x1, x2,…, xq] and Veq=[v1, v2,…, vq], represent the position and velocity of the ith particle in the search space, respectively. Each particle has its own best position (local best) Plq=(Pl1, Pl2,…, Plq) corresponding to the individual best objective value obtained so far. Pgqdenotes the global best particle (global best), that means the best particle found so far at time t. In represents the inertia weight and c1, c2 and c3 are constants called acceleration coefficients, r1 and r2 are two independent random numbers uniformly distributed in the range of [0,1]. η denotes the peer searching function finding better neighbor positions.In the peer searching rule, the function first sets a value ω, a randomly generated number, and peer ratio ξ, a constant that controls number of peer neighbor particles. If ω≥0.5, peer particles at current position apply the exploitation rule, and choose better positions nearby based on Eq. (12). ς comprises the inertia weight and velocity of all particles, i.e.,ς=In×Veqt−1. If ω<0.5, peer particles choose the exploration rule and select to a better position using the peer searching function to update inertia weight and velocity.(12)η=(1−ω)×ς×(peerPgqt−1−Xqt−1)+ω×ς×(peerPlqt−1−Xqt−1)Therefore, the position of each particle is updated in an iteration according to the following equation:(13)Xqt=Xqt−1+VeqtGenerally, the value of each component in Veqby Eq. (11) is limited to the range [−vmax, vmax] to control excessive wandering of particles outside the search space. Then, the particle's current position is updated according to Eq. (13). This process is repeated until a pre-defined stopping criterion is reached.The purpose of peer searching rule is to reinforce the visibility of the better neighbor position, increasing the probability of a position selected to pursue the optimal solution, and converging the algorithm by peer's cooperation.Despite the peer searching rule and global/local update rules, TPSO follows the same reasoning as the basic PSO. The algorithm first releases a certain number of particles in a singular iteration, searches for the best position, and memorizes the positions on the best scheduling sequence using global and local best update. The algorithm stops using a termination criterion; for example, a certain number of loops of iteration or convergence.This section presents small scale and large scale simulated data tests to confirm the solution capacity of TPSO. Substantial evidence based on test results indicates that TPSO transcends the original PSO (Lian, [12]; Zhang et al. [18]; Liu et al. [13]; Zhao et al. [19]).This study examines the following subject scheduling problem ofF2(m1,m2)|stijk|C1×∑i=1nEi+C2×∑i=1nTi+C3×∑k=1mMIk. The following parameters are considered in generating test data: total number of jobs (n), total number of machines (m), job processing time (prij), sequence dependent setup time (stij), due date (di), and cost coefficient of measuring criteria (C1, C2andC3). Parameters related to TPSO and PSO algorithms include: inertia weight (In), velocity (Veq), peer ratio (ξ), iterations (loop) and number of particles in each iteration (x).Due to the limitations of integer programming, this study adopts small and large scale number of jobs. The range of small scale job number is n=6, 7, 8, 9, 10, the number of machines in two stages is assumed to (2,2), (5,5), the range of large scale job number is n=40, 80, 120, 160, 200 and the number of machines in two stages is assumed to (10,10), (20,20), (30,30), (40,40). Sequence dependent setup time stijalso follows a U[10,30], a uniform distribution between 10 and 30. Job processing time prijalso follows a U[50,100], a uniform distribution between 50 and 100 assuming that job processing times exceed setup times but remain in a sensible range.Regarding the weights of measuring criteria, the real business decision process takes into consideration. Companies requirements in terms of criteria measurement weights vary according to their priorities. Higher earliness cost coefficient prevents firms from finishing jobs early and reduces inventory costs; higher lateness cost coefficient prevents late delivery and fulfills customer demands; a higher total machine idle time cost coefficient can decrease cost of resource in process. This study utilizes three weight conditions: C1=1, C2=1, C3=2; C1=1, C2=2, C3=1; C1=2, C2=1, C3=1. The advantage of using three conditions, rather than just one, is that all possible conditions are thoroughly evaluated.The parameter settings in the proposed algorithm are decided during pre-test, as listed in Table 1. All tests are performed on a personal computer with Intel Pentium Quad Core2 Q6600, 2.40GHz, 2.40GHz, 2.00GB RAM. Finally, the test results are compared and analyzed.Owing to the excessive processing time, small scale problems are identified as problems from 6 to 10 jobs. Thus, this study involves three measuring criteria weight conditions. This study thus adopts all possible conditions not just using unique weight cost, but divides weighted costs into three categories (C1=1, C2=1, C3=2; C1=1, C2=2, C3=1; C1=2, C2=1, C3=1). Each of these settings is examined using integer programming (IP), PSO and TPSO for 30 randomly generated problems. Average solutions and CPU times (in seconds) are maintained to present the effectiveness and efficiency of the proposed TPSO algorithm. The results are listed in Tables A.2–A.4 in Appendix.According to the cost weight conditions, the CPU times of both PSO and TPSO exhibit no obvious difference. This study determines that TPSO and PSO have the same excellent solution efficiency in tests involving small scale problems.The average solutions of TPSO all exceed those of PSO. Regarding the improvement percentage of TPSO, the effectiveness improvement ratio is calculated as follows.Effectiveness improvement ratio:OutcomePSO−OutcomeTPSOOutcomePSO×100%Table A.5 lists the effectiveness improvement ratio of the target value between TPSO and PSO in small scale problems in Appendix.A randomly generated problem is tested 30 times using TPSO and PSO on three cost weights conditions involving from 6 to 10 jobs. IP is presented once to compare the results. This study calculates the worst solution, best solution, average solution, standard deviation and CPU time (inseconds) in each situation. The results are listed in Tables A.6–A.8 in Appendix.The result of the robustness test of TPSO conforms with the effectiveness test in small scale problems. All CPU times are within 4s, and do not obviously differ from PSO. This study confirms that TPSO can efficiently solve the problem.The best solutions of TPSO closely approximate IP solution in the robustness test. Furthermore, TPSO outperforms PSO in terms of the worst solution, best solution and average solution. To further examine how TPSO outperforms PSO in terms of robustness, this study calculates the robustness improvement ratio as follows.Robustness improvement ratio:Outcomeσ2(PSO)−Outcomeσ2(TPSO)Outcomeσ2(PSO)×100%Table A.9 lists the result of comparing the robustness of TPSO with that of PSO in Appendix.Table A.9 shows that robustness improvement ratios are definite and outstanding in each test set. The total improvement in robustness ratio is 15.60%. This result clearly demonstrates an improvement in the robustness of TPSO relative to PSO in solving small scale multiprocessors flow shop scheduling problems.In real business scheduling problems, the contrast between the largest scale of the total number of jobs and machines and the small scale of problems should be studied. Based on previous tests, it has been observed that as the total number of jobs grows, IP's solving CPU time grows exponentially. Given 11 jobs, the CPU time of IP exceeds 240h, and the optimal solution remains unidentified. Owing to this limitation, the IP solution is omitted in tests of large scale problems. This study chose to compare the solving capacity of TPSO with that of PSO in large scale problems.The total job number large scale problems ranges from 40 to 200 with increments of 40. Three cost weight conditions combined with the total number of jobs can construct 60 large scale problems. Moreover, 30 examples are randomly generated and tested using TPSO and PSO for each problem. The average solution and CPU time (inseconds) are demonstrated to compare the effectiveness and efficiency of TPSO and PSO. The results are listed in Tables A.10–A.12 in Appendix.According to these cost weight conditions, no obvious differences exist between the CPU times of TPSO and PSO. This result demonstrates that TPSO and PSO have the same problem-solving efficiency.All average solutions of TPSO outperform those of PSO. Accordingly, effectiveness improvement ratios are calculated and listed in Table A.13 to demonstrate the effectiveness improvement of TPSO in Appendix.Table A.13 shows that in any cost weight conditions, TPSO significantly outperforms PSO. The total improvement ratio is 1.42% in the large scale problem test revealing that TPSO demonstrates the same solving efficiency either in the small or large scale problems. The result conforms with the improvement made by TPSO in small and large scale problems.As for large scale problem robustness tests, an example is randomly generated for each problem, and 30 repeated tests are run with TPSO and PSO, respectively. The best solution, worst solution, average solution, standard deviation and CPU time calculated using repeating algorithm are listed in Tables A.14–A.16 in Appendix.Consequently, robustness test reveals that there is no obvious difference in solving time between TPSO and PSO. Among these problems, TPSO has better worst solution, best solution and average solution, and smaller standard deviation than PSO. Consequently, this study confirms that TPSO is more robust than PSO.Notably, the average solutions of TPSO are closer to best solutions. Because of the feature of the TPSO algorithm, the particles are assigned to search for a better position with peer's cooperation when finding food. Owing to this method, a better position is more likely to be chosen. Meanwhile, under rare circumstances, particles are snared in the local optimal solution and linger in the worst solutions areas, causing them to find a much worse solution when searching for food. Owing to the sternness and rarity of this result, the worst solution frequently causes larger deviation to the average solution than the best solution.According to the small scale problem test, robustness improvement ratios are also calculated for large scale problems, as illustrated in Table A.17 in Appendix.Table A.17 shows that for all test problems, TPSO is more robust than PSO. The total improvement of robustness was 13.98%, and the evidence demonstrates that TPSO is more robust than PSO in large scale multiprocessors flow shop scheduling problems. The result depends on the small scale robustness test, and confirms the excellent stability of TPSO.

@&#CONCLUSIONS@&#
