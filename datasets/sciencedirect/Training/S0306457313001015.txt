@&#MAIN-TITLE@&#
Expert group formation using facility location analysis

@&#HIGHLIGHTS@&#
Using facility location analysis as a well known branch of Operation Research to solve an applied problem in information retrieval.Proposing a unified framework to solve three types of problems for expert group formation.Testing our framework on a real test collection.Proof of optimality of the solution.

@&#KEYPHRASES@&#
Expert group formation,Expert finding,Topic model,Facility location analysis,Greedy approach,Linear programming,

@&#ABSTRACT@&#
In this paper, we propose an optimization framework to retrieve an optimal group of experts to perform a multi-aspect task. While a diverse set of skills are needed to perform a multi-aspect task, the group of assigned experts should be able to collectively cover all these required skills. We consider three types of multi-aspect expert group formation problems and propose a unified framework to solve these problems accurately and efficiently. The first problem is concerned with finding the top k experts for a given task, while the required skills of the task are implicitly described. In the second problem, the required skills of the tasks are explicitly described using some keywords but each expert has a limited capacity to perform these tasks and therefore should be assigned to a limited number of them. Finally, the third problem is the combination of the first and the second problems. Our proposed optimization framework is based on the Facility Location Analysis which is a well known branch of the Operation Research. In our experiments, we compare the accuracy and efficiency of the proposed framework with the state-of-the-art approaches for the group formation problems. The experiment results show the effectiveness of our proposed methods in comparison with state-of-the-art approaches.

@&#INTRODUCTION@&#
The success of a project directly depends on the expertise of the people who are involved. Since the assignment of experts to a task/project must be based on both the required skills of the project and knowledge about the expertise of all candidate experts, it is not an easy task and it is challenging to optimize the assignment. As a result, expert group formation offers a new direction in research and also poses some brand new challenges. Here, the key problem is how to assign a group of experts to a given set of tasks/projects. The problem has attracted considerable interest from different domains. For example, several works have been made for conference paper-reviewer assignment (Karimzadehgan & Zhai, 2012; Karimzadehgan, Zhai, & Belford, 2008; Mimno & McCallum, 2007; Taylor, 2008), expert group formation in social networks (Kargar & An, 2011; Lappas, Liu, & Terzi, 2009) and optimal team formation in Operation Research problems (Wi, Oh, Mun, & Jung, 2009; Baykasoglu, Dereli, & Das, 2007).In real scenarios, while several and sometimes diverse skills are needed to perform a task successfully and completely, these skills are implicitly expressed in the task descriptions. Besides the required skills of a task, in many cases, the relevant skills of experts are also implicitly reflected in their resume. The implicit notion of required skills/expertise aspects makes it difficult to assign an optimal group of experts to a given multi-aspect task. The main challenges of the expert group formation problem are:Implicit Notion of Aspects: Textual description of projects can only implicitly express the required skills of them, thus a method is needed to transform the textual description of a project into the set of required skills of that project. Similarly, because of implicit notion of expertise, a method is needed to transform the expertise documents (e.g. resume, professional profile, etc.) of each expert into the set of his/her skills.Coverage Condition: In an ideal expert matching, all required skills of a project should be covered by the union of the skills of the assigned members in a complementary manner.Confidence Condition: In an ideal expert matching, besides covering all required skills of a project, it is preferable that each member of the group individually be able to cover as many as possible the required skills of that project.Load Balancing: In many applications of expert group formation, there is a limit on the number of tasks to be done by each expert. To balance the load and conform to the capacity of each expert, it is necessary to set up the problem as to simultaneously assign tasks to all the available experts with consideration of task-load balancing.As a case study of the expert group formation problem, we consider the problem of review assignment. Review assignment is a common task that many people such as conference organizers, journal editors, and grant administrators would have to do routinely. In this problem, top k relevant reviewers (i.e. a group of experts with k members) should be assigned to each paper (i.e. task) such that all above mentioned criteria are satisfied. Firstly, the required skills for reviewing a paper can be explicitly determined by some keywords or can be inferred from the abstract/body of the paper. Secondary, the related research areas/skills of each reviewer (i.e. expert) can be explicitly expressed by some keywords or can be inferred from his/here previous publications. Thirdly, in an ideal matching, the assigned group of reviewers for a paper should be able to cover all aspects of that paper in a complementary manner. Fourthly, it is preferable that each assigned reviewer of a paper be able to cover as many as possible aspects of the paper. Finally, each member of the program committee (i.e. each reviewer) can only be involved in the review process of a limited number of papers.Considering expert group formation as a top k retrieval problem, it can be solved by using a standard retrieval model (e.g. the baseline language model proposed in Karimzadehgan et al. (2008)), which computes the relevance score of each expert individually and then returns the k experts with the highest relevance scores. However, as the inter-relationships among the relevant experts are ignored, the top k search results are often quite alike and cannot cover all required aspects of a given task. In order to resolve the query aspects and avoid the information redundancy, it is necessary to optimize the top k search results collectively.In this paper, we formalize the expert matching problem within the unified framework of Facility Location Analysis (FLA) (Gonzalez, 2007) taken from Operation Research, as a way to account and optimize the expert assignment. In the facility location problem, given a set of customer “locations” D, we would like to find a subset S⊂D to open k “facilities” there, so as to optimize a graph-theoretic objective function that is dependent on the cost of opening a facility at each location and also the distance between each pair of customer and facilities. Specifically, facilities such as warehouses, hospitals, and fire stations, should be placed as close as possible to their customers. Since a customer would just go to the closest facility, there is a competitive relationship among those k-facilities. Similarly, in our proposed framework, we consider the top-k reviewers of each paper as the desirable facilities to be placed as close as possible to their customers (i.e. aspects of papers).We show that our proposed method can improve the performance of expert matching in comparison with the state-of-the-art techniques for multi aspect/ skill expert matching such as Greedy Next Best (Karimzadehgan et al., 2008) and Integer linear programming (Karimzadehgan & Zhai, 2012). According to different conditions of the expert matching problem, we define three problems that can be solved by the proposed frame work of FLA. These problems are modeled using the unified framework of facility location analysis. In these problems, given a set of N papers and M reviewers, each paper should be assigned to a group of exactly k reviewers. The above mentioned three problems are given below.•Problem 1 (Implicit Aspects – Unconstraint Matching): In this problem, we assume the aspects (i.e. required skills) of each paper are implicitly represented in the abstract of the paper and the skills of each reviewer can be inferred from the expertise document of that specific reviewer. Generally, the expertise document of an expert can be his/her resume but in this paper, we consider the concatenation of one’s publications as his/here expertise document.In this problem, while each paper should be assigned to a group of k reviewers such that the skill coverage and confidence of the assigned group be maximal, there is no limitation on the capacity of reviewers (i.e. arbitrary number of papers can be assigned to a reviewer).Problem 2 (Explicit Aspects – Constraint Matching): In this problem, we assume that the set of the required skills of each paper and also the set of the relevant skills of each reviewer are explicitly determined (for example by using the ACM Categories and Subject Descriptors1http://www.acm.org/about/class/2012.1keywords for computer science related papers). Given a limited number of reviewers, each paper should be assigned to a group of k reviewers such that: firstly, in an ideal matching, all aspects of allpapers should be covered by the skills of the assigned groups (i.e. maximal coverage). Secondly, in an ideal matching, each member of the assigned groups for a paper should be able to cover as many as possible required skills of that specific paper (i.e. maximal confidence) and finally each reviewer should only be involved in review process of a limited (predefined) number of papers (i.e. load balancing).Problem 3 (Implicit Aspects – Constraint Matching): This problem is the combination of the first and the second problems. In this problem, we assume that the underlying aspects/skills of papers and reviewers are implicit and on the other hand, each expert has a limited capacity to review the assigned papers. The goal of this problem is to simultaneously maximize the coverage and the confidence of the assigned groups while the capacity condition is satisfied.The basic idea of our work has been published in a paper of the ADCS conference (Neshati, Beigy, & Hiemstra, 2012). However, the conference paper does not have a complete description of the proposed algorithms due to the page limit. This paper is a significant expansion of the previous paper to add a new automatically generated test collection, more complete description of the algorithms, a new set of scalability and gap analysis experiments, and two theorems in paper which indicate the optimality of the proposed solution.The rest of the paper is organized as follows. We first discuss facility location problems in Section 2 and our proposed framework for expert matching in Section 3. We then discuss related work in Section 4. In Section 5, we describe our experimental design and evaluation measures. In Section 6, we present our evaluation results. We conclude the paper in Section 7.Facility location analysis is a branch of Operations Research (OR) (Gonzalez, 2007) and Computational Geometry (CG) (Berg, Cheong, Kreveld, & Overmars, 2008) concerning itself with mathematical modeling and solving problems which find the optimal placement of facilities in order to minimize transportation costs, avoid placing hazardous materials near housing, outperform competitors’ facilities, etc. Desirable k-facility placement (Gabor & Van, 2005) is a type of facility location problems concerned with the selection of k optimal locations among M candidate locations to build k facilities such that the total cost of setup of these facilities and the transportation cost of the customers would be minimal. The goal of optimization in this problem is twofold:•To minimize the total cost of opening those k facilities.To minimize the weighted distances from the customers locations to their closest facilities.The set of facility locations or simply, facilities, and the set of customers form a part of the input for facility location problems. We denote the set of facilities by F and the set of customers by C. Typically, we are required to open a subset of the facilities and serve the demands of customers by assigning them to one of the open facilities. The distance between a pair of points fi∈F, cj∈C is denoted by D(fi,cj). If a customer j is served by a facility i in a solution, then the distance D(fi,cj) is said to be the communication cost of customer j. The sum of communication costs of all customers is the Communication Cost of the solution. In the facility location problems, there is a cost associated with opening each facility i∈F, denoted by cost(fi). For a given solution, the cost of opening all the open facilities is called its Building Cost.Various types of the facility location problems are defined in the literature for different usages (Gonzalez, 2007). Two main types of these problems are uncapacitated and capacitated facility location problems that can be useful to model the expertise matching problems. In this paper, we formally model the unconstraint (i.e. Problem 1) and constraint2In this paper, by constraint expert matching, we mean expert group formation by considering the load balancing condition.2expert matching problems (Eqs. (1) and (3)) using uncapacitated and capacitated facility location problems, respectively. In the following subsections, we give these problems as well as their approximate and exact solutions.In Uncapacitated Facility Location (UFLA) problem, exactly k facility locations should be selected among M available facility locations; such that while each customer is assigned to its nearest facility, the overall building cost of facilities and the communication cost of the solution would be minimal. In this problem, an arbitrary number of customers can be assigned to a facility. In other words, there is no constraint on the assignment of customers to the facilities.Given the set of facilities F, the set of customers C, the distance between each customer cjand facility location fias D(fi,cj), the demand of each customer cjas demand(cj), and the building cost of each facility fias cost(fi), the overall cost of selection k facilities can be calculated as follows Gonzalez (2007):(1)cost(S)=λ∑i=1kcost(fi)︷BuildingCost+(1-λ)∑j=1|C|demand(cj)minf∈SD(f,cj)︷CommunicationCost.In this equation, S={f1,…,fk} indicates the set of selected facilities (i.e. the solution set) and λ∈[0,1] is a parameter. According to the above objective function, the total cost equals the sum of the Building Cost (i.e. the first summation) and the Communication Cost (the second summation).Fig. 1illustrates an instance of uncapacitated facility location problem in which the location of the customers and the facilities are indicated by circles and squares, respectively. Assuming equal building cost for all candidate locations (i.e. cost(fi)=cost(fj), ∀i, j∈{1,…,5}), the optimal 3 facility locations and also the assignment of the customers to their nearest location is illustrated in this figure. As indicated in Fig. 1, exactly 3 facilities are selected among 5 available facility locations which minimize the overall communication cost.As an integer linear programming problem, the uncapacitated facility location problem can be represented by the optimization of the ILP problem indicated in Eq. (2). In this integer linear program, Uiand X(i,j) are the decision variables and demand(cj) and D(fi,cj) are input parameters. Uiis a binary decision variable (according to constraint T4) which indicates whether facility fiis a member of final selected facilities (i.e. set S) or not. Constraint T1 indicates exactly k facilities should be selected in final solution. X(i,j) is also a binary variable (according to constraint T5) which indicates whether customer cjis assigned to facility fiin final solution or not. Constraint T2 indicates that each customer cjshould be assigned to at least one facility and constraint T3 indicates that customer cjcan be assigned to facility fionly if fiis selected in the final solution.(2)minimizeλ∑i=1MUicost(fi)+(1-λ)∑j=1|C|∑i=1Mdemand(cj)D(fi,cj)X(i,j)subjecttoT1:∑i=1MUi=kT2:∀j:1⩽∑i=1MX(i,j)T3:∀i,j:X(i,j)⩽UiT4:∀i:Ui∈{0,1}T5:∀i,j:X(i,j)∈{0,1}The UFLA in general belongs to the class of NP-hard problems, which can be proved by reduction, for example, from the set cover problem (Gonzalez, 2007). Since this problem has an explicit objective function, it is possible to approximately optimize it using Greedy Local Search (GLS), a.k.a. Hill Climbing, as shown in Algorithm 1.Algorithm 1Greedy Local Search for UFLA problemInput:F: (candidate facility locations), k (the cardinality of solution set)Output:S: top k facility locationsS⇐{f1,…,fk}repeatfor f∈S doforf′∈F−S doS′⇐(S−{f})∪{f′}IfCost(S′)<Cost(S) thenS⇐S′endIfendIfendIfUntilS does not changeThe algorithm first initializes set S (i.e. the solution set) with a set of k random facilities and then iteratively refines S by swapping a facility location in S and an available non-selected location in F, until the process converges. Finally, the k selected facilities in S are an approximate solution for the problem.Capacitated facility location placement is another type of facility location problem with the same objective function as the uncapacitated facility location problem (i.e. Eq. (1)), but in this problem, each facility has a limited capacity to serve the assigned customers and therefore only a limited (and predefined) number of customers can be assigned to a facility (Gabor & Van, 2005). In this problem, the goal is finding the k facilities with minimal overall cost while the load balancing condition is satisfied. The inputs of this problem are the set of facilities F, the set of customers C, an integer k (i.e. the size of solution), the distance between each customer cjand facility location fias D(fi,cj), the demand of each customer cjas demand(cj), the building cost of each facility fias cost(fi) and the capacity of each facility fi(i.e. capacity(fi)).As an example, Fig. 2illustrates the same customer and facility locations indicated in Fig. 1. Assuming equal building cost and equal capacity of two for each facility, Fig. 2 indicates the optimal four facilities for this CFLA problem. As indicated in this figure, each facility is responsible to serve to at most two customers and similar to the UFLA problem, each customer is assigned to the nearest opened/selected facility location. Clearly, this problem has no solution for k=3 and capacity(fi)=2, because the number of customers is more than 3*2=6.While CFLA problem is in general NP-hard, various approximation algorithms (Charikar & Guha, 1999; Chudak & Williamson, 2005) are proposed for this problem. Specifically, Charikar and Guha in Charikar and Guha (1999) proposed an efficient linear programming solution for this problem. Although, we can use these approximated algorithms for modeling the expert matching problem, but because of the small size of the problem in our real applications and efficiency of linear programming, we chose to exactly solve the matching problem following the idea of linear programming. The explanation of our solution for constraint expert matching using the linear programming will be described in Section 3.4.In this section, we describe how to model the expert matching problems using the facility location framework. The list of symbols used in this paper is represented in Table 1.Before describing the facility location framework for expert matching, we describe the author topic modeling method introduced in Karimzadehgan et al. (2008), which is used for implicit topic matching problems (i.e. Problems 1 and 3 described in Section 1).The notion of related aspects of papers and reviewers in Problems 1 and 3 of expert matching (described in Section 1) is implicit, making it difficult to find the optimal group of reviewers for a given paper considering the coverage and the confidence conditions. However, we can assume that the related aspects of a paper can be inferred from its abstract and the skills/aspects of reviewers can also be represented by his/her sample publications. To find the optimal group of reviewers, in this section, we describe a method to find a topic representation for each paper and each reviewer.Following the idea of reviewer modeling introduced in Karimzadehgan et al. (2008), we can assume that there is a space of T topic aspects, each characterized by a unigram language model such that the papers and the expertise documents can be represented as the mixture of these topics. Let τ=(τ1,…,τT) be a vector of topics where τiis a unigram language model and p(w∣τi) is the probability of word w for the topic τi.Given M reviewer’s expertise documents,3In this paper, the concatenation of a reviewer’s publications is used as his/here expertise document.3arbitrary number of latent topic/aspects can be learned using Probabilistic Latent Semantic Analysis (PLSA) (Hofmann, 1999). Let R={r1,…,rM} be the set of expertise documents where document riis the expertise document of reviewer ei, the log likelihood of the expertise document collection according to the PLSA (Hofmann, 1999) equals to:(3)log(P(R|τ))=∑i=1M∑w∈Vc(w,ri)log∑a=1Tp(τa|θi)p(w|τa),where V is the set of all words in the vocabulary, c(w,ri) is the count of word w in the expertise document riand p(τa∣θi) is the selection probability of topic τafor document ri.EM algorithm can be used to compute the maximum likelihood estimation of all parameters including p(τa∣θi) and p(w∣τa). After learning all the parameters, each expert eican be represented using the topic vector τidenoted by (τ1i,…,τTi) such that τ1i=p(τa∣θi). Furthermore, using the estimated values of p(w∣τa), we can also infer the topic representation for each paper pjas τ′jdenoted by (τ′1j,…,τ′Tj) such that τ′1j=p(τa∣θj). Using the above topic modeling method, given N papers, M reviewers, and the number of latent topics T, the set of papers and reviewers can be represented by the paper-topic AN×Tand reviewer-topic BM×Tmatrixes. The elements of these matrixes are real numbers in [0,1], which indicate the relevancy of corresponding paper or reviewer to a topic.Note that if the relevant topics of papers and reviewers are explicitly given using some keywords (i.e. the Problem 2 of expert matching), then the paper-topic and reviewer-topic will be zero-one matrixes which can be defined as follows where aspect(pj) indicates the set of relevant aspects of paper pj.A(j,t)=0ift∉aspect(pj)1ift∈aspect(pj)B(i,t)=0ift∉aspect(ei)1ift∈aspect(ei)After representing papers and reviewers using the above matrixes, now we can describe the matching algorithm for retrieving the k-top reviewers for a given paper.Note that the proposed method for topic learning in this section is applicable, if we have enough papers for a candidate reviewer to infer his/her skills. However, For “cold-start” reviewers (i.e. a reviewer who has not enough papers to infer his/her skills directly), following the idea of Deng, King, and Lyu (2012), it is possible to infer the related topics using the venue (or an specific section of the venue) in which his/her paper is published. For example, for reviewers who previously published a paper in “personalization and user modeling” section of the SIGIR conference, we can easily extract related aspects/skills of them. But in this method, we can only infer the general aspects of a reviewer profile and this method is not able to precisely detect the specific skill aspects of candidate reviewers. As another method, following the idea of relevance propagation (Qin, Liu, Zhang, Chen, & Ma, 2005), it is possible to infer the related aspects of a candidate reviewer using the aspects of his/her co-authors. Temporal topic modeling (AlSumait, Barbará, & Domeniconi, 2008; Daud, 2012) and also temporal expert finding (Hashemi, Neshati, & Beigy, in press) methods can also be used to more precisely infer the related topics of each reviewer.The expert group formation problem is concerned with the assignment of N papers to M reviewers such that the following conditions are satisfied:C1(Top-k retrieval): Each paper pjshould be assigned to a group of exactly k relevant reviewers.C2(Maximal Coverage): In an ideal matching, the group of reviewers assigned to paper pjshould be able to cover all aspects/topics (i.e. required skills) of paper pjin a complementary manner.C3(Maximal Confidence): In an ideal matching, each reviewer eiassigned to paper pjshould be able to cover as many as possible of the topics of paper pj.While above conditions are common in all group formation problems, the following condition should also be satisfied in constraint group formation problems (i.e. Problems 2 and 3 described in Section 1).C4 (Load Balancing): Reviewer eihas a limited capacity and can only be involved in review process of a limited and predefined number of cipapers.Following the general idea of facility location analysis, we can reduce each expert group formation problem to a facility location placement problem. These two problems are similar to each other in many aspects:1.While exactly k facilities should be selected in a k-facility placement problem, in expert group formation, each paper should also be assigned to exactly k reviewers.4The value of k is not necessarily equal for all papers.4While each customer in a facility location problem should be assigned to its nearest facility, in expert group formation, each topic of a paper should be assigned to a reviewer who is able to cover that specific topic. If all aspects of a paper pjis assigned to at least one relevant reviewer, then the maximal coverage condition can be satisfied.While in the facility location problems, each facility has a specific value of opening cost, in expert group formation problem, each reviewer has a specific confidence level for a given paper. So, if we appropriately define the assignment cost of each reviewer for a given paper, then the maximal confidence condition can be satisfied.In capacitated facility location, each facility has a limited capacity to serve customers; similarly, in constraint expert group formation, each expert should be assigned to a limited number of papers. Therefore, using capacitated facility location framework, the load balancing condition can be satisfied.According to the above similarities between facility location placement and expert group formation problems, we can imagine each reviewer eias a facility and each topic/aspect τ of paper pjas a customer that should be assigned to a facility/reviewer. Given the set of papers, reviewers, paper-topic matrix, reviewer-topic matrix and the number of reviewers for each paper, we should define the building and communication costs to complete the facility location framework. In the following subsections, we will define these costs for each of the group formation problems.The first problem of expert matching is concerned the assignment of N papers to M reviewers such that the conditions C1,C2, and C3 are satisfied. In this problem, we assume that each reviewer has infinite capacity. So, we can assign each of N papers to all available reviewers independent of other papers. In other words, we can independently solve the matching problem for each paper.Using the topic modeling method described in Section 3.1, we can infer the paper-topic A and reviewer-topic B matrixes. As mentioned in Section 3.2, selection of k reviewers is equivalent to the selection of k facilities in our framework. For a given paper, we have T customers (i.e. T topics) and M candidate facility locations (i.e. M reviewers) and the objective function in UFLA is composed of two parts:1.Building Cost: The building cost indicates the cost of opening a facility at a specific candidate location.Communication Cost: The communication cost indicates the access cost of a customer to its nearest facility in the optimal solution.In expert matching problem, the first part corresponds to the cost of selection of an expert eifor a paper pjand the second part indicates the cost of coverage for a topic of a paper pjby the most relevant assigned reviewer. Therefore, we can define the building cost and communication cost in our framework as follows.1.Building cost of assignment of reviewer eito paper pjequals to:cost(ei)=D(ei→‖pj→),whereei→andpj→correspond to the topic vector of reviewer ei(i.e. the ith row of the reviewer-topic matrix B) and the topic vector of paper pj(i.e. the jth row of the paper-topic matrix A) andD(ei→∥pj→)indicates the Kullback–Leibler (KL)5For discrete probability distributions P and Q, the KL divergence is defined to beDKL(P∥Q)=∑ilnP(i)Q(i)P(i)It is the expectation of the logarithmic difference between the probabilities P and Q, where the expectation is taken using the probabilities P. The KL divergence is only defined if P and Q both sum to 1 and if Q(i)=0 implies P(i)=0 for all i (absolute continuity). If the quantity 0 ln 0 appears in the formula, it is interpreted as zero becauselimx→0xln(x)=0(Kullback & Leibler, 1951). This interpretation makes sense in our problem, because a zero-weight topic of a paper should not affect its distance from reviewers (i.e facilities).5divergence value of these vectors.Intuitively, if the topic distributions of vectorsei→andpj→are very similar to each other, then we expect that they might be related to the same topics and also their KL divergence value will be very small. As a result, the facility (i.e. the reviewer) eiwill be a very low building cost facility candidate for paper pj.Communication cost of assignment of aspect a of paper pjto reviewer eiequals tocost(ei,τaj)=D(ei→‖va→),whereei→is topic vector of reviewer ei, τajis the weight of topic a in topic vector of paper pjandva→indicates the unit vector with all zero elements except for topic a.In this case, if reviewer eiis able to cover skill a, then we expect that the weight of topic τain his/her topic vectorei→be higher in comparison with other topics and accordingly the communication cost of customer a (i.e. topic a) and facility ei(i.e. the reviewer) will be low.According to the above definitions for building and communication costs, the objective function of unconstraint expert matching problem can be represented as follows:(4)Cost(S,pj)=λ∑i=1kD(ei→‖pj→)+(1-λ)∑a=1Tτajmins∈SD(s→‖va→),where S is the set of selected reviewers for paper pjand τajindicates the weight of topic a in topic vector of paper pj. To optimize the above objective function we use the greedy local search method given in Algorithm 1. The output of the algorithm is the top-k reviewers for paper pjwhich have not only the maximum confidence but also collectively can cover all aspects of that paper.The second problem of expert matching (i.e. Explicit Aspects – Constraint Matching) is concerned with the assignment of N papers to M reviewers such that in addition to the conditions C1,C2 and C3, the load balancing condition (i.e. C4) is also satisfied.In contrast with the first problem of expert matching, in this problem, we assume that the aspects/skills of the papers and experts are explicitly determined. This is a valid assumption because in many applications, the required skills of a project and also the related skills of an expert can be explicitly described by some few keywords. For example, in the paper-reviewer assignment problem, the relevant topics of each paper and reviewer can be described by some few keywords.The constraint C4 makes the matching problem very hard, indeed this matching problem belongs to the class of NP-hard problems; furthermore, in this problem the conditions C2 and C3 are in competition with each other. Specifically, maximizing the global average confidence of the assigned groups may result in formation of the non-optimal converging groups. In this section, we formally model this problem using the Capacitated Facility Location Analysis (CFLA) (Chudak & Williamson, 2005) and also propose an exact linear programming solution for it.Similar to Section 3.3, in the CFLA framework of constraint expert matching, each aspect/topic of paper pjis considered as a customer and each reviewer is considered as a candidate facility location.Algorithm 2 indicates the linear programming formulation (Gonzalez, 2007) for this CFLA problem. In this linear program, matrix Ujiis a N×M binary decision matrix that indicates the assignment of papers to the reviewers. Specifically, element uji=1 if and only if, in the final solution, the paper pjis assigned to the reviewer ei. As a binary decision variable, X(i,j,a) indicates the assignment of topic a of paper pj(i.e. a customer) to reviewer ei(i.e. a facility); specifically, X(i,j,a)=1 if and only if, topic a of paper pjis assigned to reviewer ei, and finally, AN×Tis the binary paper-topic matrix; where A(j,a)=1 if and only if, paper pjis related to topic a.Algorithm 2Linear programming formulation of CFLAminimize∑j=1N∑i=1M(λUjiBCost(i,j)+(1-λ)∑a=1TCCost(i,j,a)X(i,j,a))subject toT1:∀j:∑i=1MUji=kT2:∀i:∑j=1NUji⩽ciT3:∀j,a:A(j,a)⩽∑i=1MX(i,j,a)T4:∀i, j, a:X(i,j,a)⩽UjiT5:∀i, j:Uji∈{0,1}T6:∀i, j, a:X(i,j,a)∈{0,1}In the linear program given in Algorithm 2, constraint T1 shows that the sum of elements of each row of matrix U should be equal to k; this means that each paper should be assigned exactly to k reviewers. This constraint can satisfy the top-k retrieval condition (i.e. the condition C1).Constraint T2 indicates that the sum of elements of each column of U should be less than or equal with ci(i.e. the capacity of the ith reviewer); this means that reviewer eican only be assigned to at most cipapers. This constraint can satisfy the load balancing condition (i.e. the condition C4).Constraint T3 indicates that for each related topic of paper pj(i.e. for topics that A(j,a)=1) at least one reviewer should be assigned. On the other hand, T4 indicates that the topic a of the paper pjcan be assigned to the reviewer eionly if paper pjis assigned to the reviewer ei. In other words, if the decision variable X(i,j,a)=1, then the element ujiof the assignment matrix should be equal to 1; As we will see later, these constraints can guarantee the optimal coverage assignment (i.e. the condition C2).The objective function in Algorithm 2 is the same as the objective function given in Eq. (4) with this difference that in Algorithm 2, it is defined to globally optimize the matching of all papers simultaneously (i.e. the outer sum is defined on all papers). On the other hand, the minimum distance in Eq. (4) is replaced by decision variable X(i,j,a) which models the same concept (i.e. the best assigned reviewer for topic a).Intuitively, by minimizing the objective function, both the coverage and the confidence conditions of the matching problem (i.e. C2 and C3 conditions) can be satisfied. Firstly, paper pjis assigned to reviewer ei(i.e. uji=1) when the building cost (i.e. BCost(i,j)) of this selection is low; this part of objective function can satisfy confidence maximization (i.e. condition C3). On the other hand, minimization of the communication cost for the relevant topic a of paper pj(i.e. CCost(i,j,a)) results in the assignment of topic a to a reviewer eisuch that eiis able to cover this topic; therefore this part of the objective function can satisfy the coverage maximization condition (i.e. condition C4). The parameter λ can be used to make a tradeoff between confidence and coverage conditions. In order to maximize the coverage and confidence of the assigned groups, we can define the building and communication cost as follow.(5)BCost(i,j)=1-aspect(pj)∩aspect(ei)aspect(pj)(6)CCost(i,j,a)=0ifa∈aspect(ei)1ifa∉aspect(ei).In above equations, aspect (ei) indicates the set of relevant topics for reviewer eiand aspect (pj) is the set of relevant topics of paper pj. Intuitively, BCost(i,j) indicates the fraction of aspects of paper pj, which cannot be covered by the reviewer riand CCost(i,j,a) indicates whether the assigned reviewer rifor topic a of paper pjis able to cover it or not. In next two theorems, we prove that Algorithm 2 can produce the optimal coverage and confidence expert assignment.Theorem 1Coverage optimalityIn the second problem of expert matching, if communication cost is defined by Eq.(6)and λ=0, thenAlgorithm 2will produce the optimal converging groups.Let U be the M*N binary assignment matrix where uij=1 when paper pjis assigned to reviewer riin the final solution. According to the definition of the coverage measure (Section 5.2), the average value of coverage for N papers according to assignment matrix U is the average value of coverage of each paper and can be computed as followsCoverage(U)=∑j=1NCoverage(pj)N=1N∑j=1N|aspect(pj)|-|NCaspect(pj)||aspect(pj)|.where ∣aspect (pj)∣ indicates the number of aspects of paper pjand ∣NCaspect (pj)∣6NCaspect=Not Covered aspects.6indicates the number of its aspects, which are not covered by the assigned group of reviewers according matrix U. Coverage(U) indicates the average value of coverage for all papers and Coverage(pj) is the coverage measure for paper pj. With simple mathematic operations, Coverage(U) can be computed using the following equation.(7)Coverage(U)=1-1N∑j=1N|NCaspect(pj)||aspect(pj)|.On the other hand, setting λ=0 in Algorithm 2 results in the following objective function.OBJ1=∑j=1N∑i=1M∑a=1TCCost(i,j,a)X(i,j,a)By minimizing the above objective function, the value of decision variables X(i,j,a) are determined as follows.1.if Aja=0, then for all values of i the value of X(i,j,a)=0. In other words, if paper pjis not related to topic a, then this topic will not be assigned to any reviewer.if Aja=1, then only for exactly one value of i=i1 (i.e. the best available reviewer) the value of X(i1,j,a)=1 and for all other values of i value of X(i1,j,a)=0. In other words, for each relevant topic a of paper pjexactly one reviewer will be assigned. This assigned reviewer may be able to cover topic a or not (i.e. CCost(i1,j,a) can be zero or one). So, if reviewer i1 is able to cover topic a then the value of objective function does not change; otherwise it increases by 1.In the second problem of expert matching, if building cost is defined by Eq.(5)and λ=1, thenAlgorithm 2will produce the optimal confidence groups.According to the definition of the average confidence (Section 5.2), the average confidence score of an assigned group to paper pjcan be computed as followConfidence(pj)=∑i=1M∑a=1TUjiBiaAja|aspect(pj)|k.Therefore, the average value of average confidence for all assignments according to the matrix U is like follows.Confidence(U)=1N∑j=1N∑i=1M∑a=1TUjiBiaAja|aspect(pj)|k,where A, B, U are the paper-topic, the reviewer-topic and the assignment matrixes respectively, and k is the number of reviewers assigned for each paper. The above equation can be re-written as follows.(8)Confidence(U)=1N∑j=1N∑i=1MUji|aspect(pj)|k∑a=1TBiaAjaOn the other hand, by setting λ=1, the objective function of Algorithm 2 becomes as follows.OBJ2=∑j=1N∑i=1MUjiBCost(i,j)According to definition of BCost(i,j) (i.e. Eq. (5)), we have:|aspect(pj)⋂aspect(ri)|=|aspect(pj)|(1-BCost(i,j)).On the other hand, Eq. (9) is true because the term BiaAjais equal to one when both Biaand Ajaare equal to one (both paper pjand reviewer riare relevant to topic a).(9)∑a=1TBiaAja=|aspect(pj)bigcapaspect(ri)|So, we have the following equality:(10)∑a=1TBiaAja=|aspect(pj)|(1-BCost(i,j))According to Eqs. (8) and (10), we haveConfidence(U)=1N∑j=1N∑i=1MUji1-BCost(i,j)kWith simple modifications, we obtain:Confidence(U)=1kN∑j=1N∑i=1MUji-∑j=1N∑i=1MUjiBCost(i,j)According to condition T1 in Algorithm 2, we have the following equation.∑j=1N∑i=1MUji=kNSo the following equation is always true:Confidence(U)=1kN(kN-OBJ2)=1-OBJ2kN.According to the above equation, it is obvious that by minimizing the OBJ2, the confidence measure will be maximized.□The above theorems show that the linear programming solution can produce the optimal solution in terms of the coverage and confidence measures. Parameter λ can be used to make a trade-off between these measures.The constraints in the third problem of expert matching (i.e. Implicit Aspects – Constraint matching) are similar to the second problem but in this problem the topics/aspects of papers and reviewers are not predetermined. So, we use the topic modeling method introduced in Section 3.1 to infer the paper-topic and reviewer-topic matrixes. Fortunately, the linear programming method proposed in Algorithm 2 can be used to solve this matching problem. We only need to define the building and communication cost appropriately for implicit aspects. Similar to the method proposed for unconstraint implicit matching in Section 3.3, we define the building and communication cost in the same way described in Eq. (4).Once our problem is formulated, we can use many algorithms to solve it. In our experiments, we use the commercial ILOG CPLEX 12.5 package7Refer to http://www-01.ibm.com/software/integration/optimization/cplex-optimizer/.7to solve our reviewer matching problem.ILOG CPLEX optimizer is able to solve the linear programs with millions of constraints. Specifically, CPLEX uses the Branch-and-Cut (Mitchell, 2002) algorithm, which is an exact algorithm consisting of a combination of a cutting plane method with a Branch and-Bound algorithm, to solve the integer linear programs.The idea of the Branch-and-Bound algorithm is to take a problem and decompose it into smaller problems such that a solution to a smaller problem is also a solution to the given problem. The algorithm recursively decomposes the original problem until it can be solved directly or is proven not to lead to an optimal solution.In order to solve our integer linear program, using the LP relaxation, the original problem is transformed to a linear programming sub problem which is easy to solve optimality. This linear program without integer constraints is solved using the simplex algorithm. Branch and cut involves running a branch and bound algorithm and using cutting planes to tighten the linear programming relaxations. Specifically, when the optimal solution for the non-integer sub problem is founded, a cutting step tries to add additional constraints. In other words, the cutting step is to generate valid inequalities for the integer hull of the current sub problem and add them to the LP relaxation of the sub problem. At this point, the problem is divided into two sub problems: one is to explore values greater than or equal to the smallest integer greater than the current value, and the other is to explore values less than or equal to the next lesser integer. These new linear programs are then solved using the simplex method and the process repeats until a solution satisfying all the integer constraints (or binary constraints) is found. For complete information about the algorithm, a reader is referred to Mitchell (2002).

@&#CONCLUSIONS@&#
