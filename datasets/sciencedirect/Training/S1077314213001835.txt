@&#MAIN-TITLE@&#
Object tracking using learned feature manifolds

@&#HIGHLIGHTS@&#
A local feature based manifold representation for object tracking.Learn a manifold for each feature and approximate it by a set of linear subspaces.Represent the object by a manifold graph which encodes object structures.Apply manifold representation to tracking and update manifold status adaptively.Show our tracking results and compare our tracker with state-of-the-art methods.

@&#KEYPHRASES@&#
Feature manifold,SIFT,Tracking,

@&#ABSTRACT@&#
Local feature based object tracking approaches have been promising in solving the tracking problems such as occlusions and illumination variations. However, existing approaches typically model feature variations using prototypes, and this discrete representation cannot capture the gradual changing property of local appearance. In this paper, we propose to model each local feature as a feature manifold to characterize the smooth changing behavior of the feature descriptor. The manifold is constructed from a series of transformed images simulating possible variations of the feature being tracked. We propose to build a collection of linear subspaces which approximate the original manifold as a low dimensional representation. This representation is used for object tracking. Object location is located by a feature-to-manifold matching process. Our tracking method can update the manifold status, add new feature manifolds and remove expiring ones adaptively according to object appearance. We show both qualitatively and quantitatively this representation significantly improves the tracking performance under occlusions and appearance variations using standard tracking dataset.

@&#INTRODUCTION@&#
Object tracking is a central problem in computer vision with many applications, such as activity analysis, automated surveillance, traffic monitoring, and human-computer interaction. It is essentially the problem of finding the most likely estimate of the object state given a sequence of observations. Object tracking is challenging because of:•Complex object appearance. The object may have complicated appearance which is hard to model. Furthermore, it may undergo significant changes due to the pose and scale variations as well as non-rigid object motions.Occlusions. The object may be occluded by the background or other moving objects, making it difficult to be localized.Complex object motion. This is caused by either the moving pattern of the object or by camera motion accompanied by object motion.There are two key components in an object tracking algorithm: object representation and dynamics. Object representation tries to model the object as accurately as possible so that the tracking algorithm can accurately describe the complex object appearance. Object dynamics model how the object appearance evolves over time to be able to handle appearance variations. The two problems are usually coupled together: the object representation should be designed to be easily updated to model appearance variations, while the object dynamics should be able to take advantage of the characteristics of object representation for model update.Traditional methods for representing the object, such as global histogram based approach in meanshift tracking [1] and PCA subspace based approach in EigenTracking [2], are global approaches which describe the object to be tracked as a whole. Such methods work well in many practical applications, but have several intrinsic limitations. First, it is usually very difficult for a global representation to capture local details and as a result unable to model complex appearances. Second, global representations are not robust to partial occlusion. Once the object is occluded, the whole feature vector of object representation is affected. Third, global representations are hard to update.Recently, local representations have opened a promising direction to solve these problems by representing an object as a set of local parts or sparse local features. Part-based trackers generally use sets of connected or global visual properties incorporated local parts or components [3–6]. The parts used for object representation are updated during tracking by removing old parts that exhibit signs of drifting and adding new ones for easy accommodation of appearance changes. Feature-based trackers often represent the target by a set of sparse local features such as SIFT [7] and affine invariant point detectors [8] which are often invariant to changes in rotation, scale, illumination and viewpoint. These approaches first localize the features at a sparse set of distinctive image points by feature detectors. Then the feature vectors, usually named as descriptors, are computed based on the local image statistics centered at these locations. Two major advantages of sparse local features are the invariance to image changes and robustness to occlusions. Existing local feature based approaches typically model how the local features vary using prototypes. However, this discrete representation cannot capture the gradual changing property of local appearance.In this paper, we propose a local feature based manifold representation for object tracking. The object is represented by a set of sparse local feature manifolds. Each local feature manifold is computed from a series of SIFT feature descriptors [7] that correspond to different appearances of the same object feature under simulated variations of practical situations. To build it, we first detect a set of interest points on the object by the state-of-the-art feature detectors. For each feature point, we transform the image regions surrounding it for simulating real object changes. A feature manifold is thus obtained by exploring the ensemble of descriptors extracted on the transformed image regions. Such a manifold is an informative yet robust representation in that it captures the local appearance variations of a part of the object over time, making the local representation more robust against object changes. The local feature variation is complicated and nonlinear in practice as an example illustrated in Fig. 1which shows a feature on a walking man. As can be observed, the feature appearance changes dramatically during the move. As a result, the feature manifold is a highly nonlinear appearance manifold. For computational efficiency, we apply incremental principal component analysis to it and yield a collection of linear subspace approximation.To model geometric relations among local features, the feature manifolds are organized as a feature manifold graph which is used to represent the target object to be tracked. Each local feature manifold describes object appearance details and relationships among them encode object structure. Such geometric relationships are elastic and have the flexibility to handle objects with coherent motion and a certain amount of variations caused by viewpoint changes and articulated motions. An advantage of the feature manifold graph is that locally the manifold graph reinforces the power of feature description and characterizes variations of object appearance by learning a series of descriptors, while globally it encodes object structure with the geometric relations among those manifolds. Such characteristics make it suitable for many vision tasks.We apply the feature manifold graph to object tracking as an application. With the feature manifold graph representation, the target object is tracked based on graph-based feature-to-manifold tracking. During tracking, features are extracted in a candidate region of the current frame and then matched with the manifold. Object position is located by integrating all matching in the manifold graph. Since features may appear and disappear due to viewpoint changes and occlusions, our dynamic model is designed to be able to add new feature manifolds and remove expiring ones adaptively and dynamically. To the best of our knowledge, this is the first paper that applies manifold learning to local features for object tracking.The rest of this paper is organized as follows. Section 2 describes the related work on object tracking. We present our feature manifold model in Section 3. Section 4 shows our main tracking paradigm. Experiments and analysis are given in Section 5, and the whole paper is concluded finally.

@&#CONCLUSIONS@&#
We have proposed the feature manifold model, a new object representation, which represents the object as local feature manifolds. The feature manifold as the core of this representation is more informative and robust compared with an individual feature in that it explores the ensemble of a series of features extracted on the transformed image regions simulating possible variations of practical situations. We apply the feature manifold model to object tracking. Object position is located by a feature-to-manifold matching process based on the feature manifold model constructed using the first video frame. Our tracking module updates the manifold status, adds newly appeared feature manifolds and removes expiring ones adaptively according to object appearance. The experiments on challenging video sequences show that the feature manifold model-based object tracker can stably track the dynamic objects. We intend to further explore applications of the feature manifold object representation to other vision tasks such as object recognition in future.