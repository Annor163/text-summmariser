@&#MAIN-TITLE@&#
Texture modelling with nested high-order Markov–Gibbs random fields

@&#HIGHLIGHTS@&#
Texture models with heterogeneous sets of features are learnt sequentially.Parameter learning can be omitted.Local binary patterns with learnt offsets are introduced as MGRF features.Methods of gradually or immediately selecting the offsets are compared.The models are promising for texture synthesis and inpainting.

@&#KEYPHRASES@&#
Texture synthesis and analysis,High-order MRFs,Local binary patterns,Structure learning,

@&#ABSTRACT@&#
Currently, Markov–Gibbs random field (MGRF) image models which include high-order interactions are almost always built by modelling responses of a stack of local linear filters. Actual interaction structure is specified implicitly by the filter coefficients. In contrast, we learn an explicit high-order MGRF structure by considering the learning process in terms of general exponential family distributions nested over base models, so that potentials added later can build on previous ones. We relatively rapidly add new features by skipping over the costly optimisation of parameters.We introduce the use of local binary patterns as features in MGRF texture models, and generalise them by learning offsets to the surrounding pixels. These prove effective as high-order features, and are fast to compute. Several schemes for selecting high-order features by composition or search of a small subclass are compared. Additionally we present a simple modification of the maximum likelihood as a texture modelling-specific objective function which aims to improve generalisation by local windowing of statistics.The proposed method was experimentally evaluated by learning high-order MGRF models for a broad selection of complex textures and then performing texture synthesis, and succeeded on much of the continuum from stochastic through irregularly structured to near-regular textures. Learning interaction structure is very beneficial for textures with large-scale structure, although those with complex irregular structure still provide difficulties. The texture models were also quantitatively evaluated on two tasks and found to be competitive with other works: grading of synthesised textures by a panel of observers; and comparison against several recent MGRF models by evaluation on a constrained inpainting task.

@&#INTRODUCTION@&#
Texture modelling is central or important to many computer vision and image processing tasks such as image segmentation, inpainting, texture classification or synthesis, anomaly (defect) detection, and image recognition. Although successful specialised algorithms for texture classification, synthesis and segmentation have been developed, generative probabilistic models which offer relatively complete models of statistics of individual textures are appealing. They may be applied not only to all of the above tasks, but to anywhere appearance priors or feature extraction are needed, and they are also of interest to understanding human vision. Generative models must capture most of the features of a texture that are significant to human perception in order to be successful, whereas texture features used for discrimination need not.The most prevalent tool for image and texture modelling are Markovian undirected graphical models, a.k.a. Markov random fields (MRFs). An MRF together with an explicit Gibbs probability distribution (GPD) is called herein a Markov–Gibbs random field (MGRF). MGRFs are particularly popular for image analysis involving the determination of boundaries (as in segmentation) or enforcing smoothness (e.g. in stereoscopic matching and image denoising). In these cases the Markov networks are usually sparse, with the directly interacting neighbours of each variable being close by. Some high-order MGRF models have been proposed for such tasks (e.g. [1,2,11]), and for binary variables efficient maximum a posteriori (MAP) algorithms exist, such as graph cuts [3]. However things are different in the domain of image and texture modelling, where inference needs to be performed on real-valued or highly multivalued image variables in dense Markov networks. The networks used in this paper typically have Markov blankets containing 50–100 nearby and distant pixels, and even sampling from the models proves to be difficult.MGRFs and other probabilistic texture models reduce images g to a vector of statistics of image features f(g), which are assumed sufficient to describe the texture. The model is completed by assigning an energy ϕ to each feature vector, giving a Gibbs probability distribution over images:(1)p(g)∝exp(−ϕ(f(g))).Historically statistics of pairs of pixels [4–6] were used. However higher-order MGRFs (which cannot be expressed in terms of lower order ones), have become more common as they are recognised to be necessary for more expressive models of natural images and textures (e.g. [2,7–11]). Higher order interactions in image models allow for abstracting beyond pixels, building upon larger scale image attributes like edges, and for context and complex structures to be captured. In addition, since regularly tiled textures have strong long range correlations between nearby tiles it is natural to learn an interaction structure (i.e. the pattern of statistic dependences between pixels) specific to the texture. Yet it is still almost unheard of in computer vision and image modelling for higher-order MRF structure to be learned rather than hand selected.However, selection of high-order features poses significant problems. The cardinality of a space of possible feature functions grows combinatorially in the order, due to both freedom in the shape of the support (variables/pixels to select as input), and the need to reduce or manage its high dimensional input domain. In other words the features should be parameterised with a reasonable number of parameters. The higher-order MGRFs in use nearly exclusively apply linear filters as feature functions, with statistics of the filter responses, such as means and variances [12], correlations [13], or histograms [14] forming a description vector. For texture classification many other methods of extracting useful information out of a high dimensional pixel co-occurrence matrix have been investigated (e.g. [15,16]). Dimensionality can be reduced by making assumptions such as that images are invariant to contrast and offset changes. However this approach has seemingly been little-applied to generative texture models.In order to tackle these problems, we build texture models by a model nesting procedure which greedily selects features and can build higher order features by composing lower order ones. Unlike some other works (e.g. [13,14]) we do not attempt to provide a fixed set of statistics/texture features to distinguish between all textures (a goal with the Julesz conjecture [17] as its origin), but rather learn texture-specific features. This potentially provides compact representations while still allowing a large and varied space of descriptors. Each nesting iteration corrects statistical differences between the training image and the textures class given by the previous model, as sketched in Fig. 1.Contributions of this paper are as follows: (i) We efficiently select high-order features by “nesting” models with heterogeneous features/potentials, while coping with the difficulties of inference in dense MGRF texture models. Unlike the model nesting used previously in [14,18] we do not learn maximum likelihood estimate (MLE) of parameters at each nesting iteration, which is very expensive, but instead generate images which match the current statistical constraints (Section 4.3). These are equivalent to samples from the ideal maximum likelihood (ML) model. Correct parameter learning can be delayed until afterwards. We use no hidden variables as is currently popular which eases learning and inference, with parameter learning remaining convex in theory. (ii) We extend the very popular local binary pattern (LBP) descriptors of images by learning the offsets of the surrounding pixels (Section 4.6) for use as high-order ‘binary pattern’ (BP) MGRF texture features. These are quite different from the common high-order linear filtering or Potts potentials, and faster to compute than responses of large linear filters. LBPs have apparently never been used in this way despite enormous popularity as image descriptors. Experiments into texture synthesis using MGRFs with LBP histograms as sufficient statistics can provide insight into the visual features actually captured by the LBPs. (iii) We compare several families of nested texture models utilising different high-order features, including different methods of selecting BP offsets. The resulting texture models have heterogeneous feature sets composed of second-order grey level difference (GLD) features, and of up to 13th-order BP features or Laplacian of Gaussian and Gabor filters. The use of learned long range GLD interactions allows almost-regular (tiled) textures in particular to usually be synthesised well. (iv) The ability of the proposed procedure to learn characteristic features across different types of textures is demonstrated with texture synthesis across a varied set of greyscale textures, also evaluated by a panel of observers, along with several other comparisons. (v) In order to improve generalisation and to attempt to allow partially inhomogeneous training images a variant of the MLE was used, such that the training image is split into pieces and the minimum of the likelihoods of the pieces rather than their product is maximised.

@&#CONCLUSIONS@&#
