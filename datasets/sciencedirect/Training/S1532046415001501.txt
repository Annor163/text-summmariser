@&#MAIN-TITLE@&#
Challenges in clinical natural language processing for automated disorder normalization

@&#HIGHLIGHTS@&#
Disorder normalization in clinical text has wide-ranging applications.Clinical normalizers must handle ad-hoc formatting, jargon, and ambiguous acronyms.Disorder vocabulary is richer in clinical text than biomedical abstracts.Normalization with pairwise learning to rank handles rich vocabulary.Further normalization improvements require improved named entity recognition.

@&#KEYPHRASES@&#
Natural language processing,Electronic health records,Information extraction,

@&#ABSTRACT@&#
BackgroundIdentifying key variables such as disorders within the clinical narratives in electronic health records has wide-ranging applications within clinical practice and biomedical research. Previous research has demonstrated reduced performance of disorder named entity recognition (NER) and normalization (or grounding) in clinical narratives than in biomedical publications. In this work, we aim to identify the cause for this performance difference and introduce general solutions.MethodsWe use closure properties to compare the richness of the vocabulary in clinical narrative text to biomedical publications. We approach both disorder NER and normalization using machine learning methodologies. Our NER methodology is based on linear-chain conditional random fields with a rich feature approach, and we introduce several improvements to enhance the lexical knowledge of the NER system. Our normalization method – never previously applied to clinical data – uses pairwise learning to rank to automatically learn term variation directly from the training data.ResultsWe find that while the size of the overall vocabulary is similar between clinical narrative and biomedical publications, clinical narrative uses a richer terminology to describe disorders than publications. We apply our system, DNorm-C, to locate disorder mentions and in the clinical narratives from the recent ShARe/CLEF eHealth Task. For NER (strict span-only), our system achieves precision=0.797, recall=0.713, f-score=0.753. For the normalization task (strict span+concept) it achieves precision=0.712, recall=0.637, f-score=0.672. The improvements described in this article increase the NER f-score by 0.039 and the normalization f-score by 0.036. We also describe a high recall version of the NER, which increases the normalization recall to as high as 0.744, albeit with reduced precision.DiscussionWe perform an error analysis, demonstrating that NER errors outnumber normalization errors by more than 4-to-1. Abbreviations and acronyms are found to be frequent causes of error, in addition to the mentions the annotators were not able to identify within the scope of the controlled vocabulary.ConclusionDisorder mentions in text from clinical narratives use a rich vocabulary that results in high term variation, which we believe to be one of the primary causes of reduced performance in clinical narrative. We show that pairwise learning to rank offers high performance in this context, and introduce several lexical enhancements – generalizable to other clinical NER tasks – that improve the ability of the NER system to handle this variation. DNorm-C is a high performing, open source system for disorders in clinical text, and a promising step toward NER and normalization methods that are trainable to a wide variety of domains and entities. (DNorm-C is open source software, and is available with a trained model at the DNorm demonstration website: http://www.ncbi.nlm.nih.gov/CBBresearch/Lu/Demo/tmTools/#DNorm.)

@&#INTRODUCTION@&#
The application of clinical natural language processing to the clinical narratives in electronic health records has the potential to make a significant impact in many aspects of healthcare and biomedical research. Recent work has demonstrated this potential at the point of care (such as with clinical decision support [1,2]), for patients understanding their own records [3], for public health (e.g. biosurveillance [4]), and in biomedical research (e.g. cohort identification [5,6], identifying novel potential clinical associations [7,8] or pharmacovigilance [9,10]).A common task in clinical natural language processing is the identification of key clinical variables mentioned in the text, such as disorders or treatments. This subtask includes both locating mentions of key entities (named entity recognition) and identifying mentions found (normalization) with respect to a controlled vocabulary such as SNOMED-CT [11]. An example sentence from a clinical narrative, together with annotations for disorder mentions and their respective concepts can be seen in Fig. 1. The results of these subtasks are then used by downstream components to provide the higher level processing required by the end task, making the result highly dependent on the quality of the normalization results obtained.While clinical natural language processing has been an area of increasing attention, progress still trails the general and biomedical domains [12]. While this is partially due to the relative scarcity of clinical narrative corpora due to privacy concerns, it is also partially due to the additional difficulties encountered in clinical narrative text. Biomedical text is written to communicate research results to a wide audience and is edited for clarity. Clinical narrative text, on the other hand, is written by health care professionals to communicate the status and history of a single patient to other health care professionals or themselves. These notes record the reason the patient was seen (i.e. the chief complaint), document treatments given, the findings of any tests administered, and other information needed to make informed decisions regarding care for a single patient. Typical notes include progress notes documenting treatment provided, consult reports communicating the results of diagnostic tests, and discharge summaries recording the entire course of a hospital stay. As these notes each have different purposes, they are highly heterogeneous in their content and level of detail. Moreover their format is typically unstructured, resulting in a wide variety of ad-hoc structural components.We illustrate many of the problems clinical narrative text presents for natural language processing with examples in Table 1. In general, systems which process clinical narratives cannot expect the clear structure and communication common in published text. Instead, clinical narrative is prepared under considerable time pressure, using a combination of ad-hoc formatting, eliding words which could be inferred from context, and with liberal use of parenthetical expressions, jargon and acronyms to increase the information density.In this article, we approach the task of normalization of key entities in clinical narrative using disorders as a case study. While disease normalization in biomedical publications is a difficult task due to the wide variety of naming patterns for diseases, ambiguity, and term variation, the idiosyncrasies of clinical text cause additional difficulties. Disorder normalization in clinical text has been previously attempted using both lexical and rule-based techniques [13–17]. In this line of research, the task has often been to identify diagnoses, as in ICD-9 coding [18], or only a specific subset of problems [19]. In this study, we instead describe a system to identify and normalize all disorders mentioned in a clinical narrative. We employ DNorm, a machine learning method for learning the similarity between mentions and concept names from a specified controlled vocabulary directly from training data. Previous work with DNorm demonstrated state-of-the-art performance in biomedical publications [20]. Our participation in the recent ShARe/CLEF eHealth shared task resulted in the highest normalization performance of any participant [3], but also demonstrated performance significantly reduced compared to biomedical publications. In this manuscript we demonstrate that that the vocabulary used to describe disorders in clinical text is richer than in publications – and hence more difficult to model – while the variability in overall language use is similar (see Methods Section). We use this insight to make improvements to the named entity recognition component to handle the richer disorder vocabulary.

@&#CONCLUSIONS@&#
