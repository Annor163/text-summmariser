@&#MAIN-TITLE@&#
A semantic approach for automated test oracle generation

@&#HIGHLIGHTS@&#
TAO provides a declarative framework for automated test and oracle generation.TAO integrates test and oracle generation as a whole to promote better automated software testing.TAO is the first attempt to apply the methodology of denotational semantics in test and oracle generation.

@&#KEYPHRASES@&#
Software testing,Test case generation,Test oracle,Denotational semantics,

@&#ABSTRACT@&#
This paper presents the design, implementation, and applications of a software testing tool, TAO, which allows users to specify and generate test cases and oracles in a declarative way. Extended from its previous grammar-based test generation tool, TAO provides a declarative notation for defining denotational semantics on each productive grammar rule, such that when a test case is generated, its expected semantics will be evaluated automatically as well, serving as its test oracle. TAO further provides a simple tagging mechanism to embed oracles into test cases for bridging the automation between test case generation and software testing. Two practical case studies are used to illustrate how automated oracle generation can be effectively integrated with grammar-based test generation in different testing scenarios: locating fault-inducing input patterns on Java applications; and Selenium-based automated web testing.

@&#INTRODUCTION@&#
With the increasing dependence on software by all sectors of industry, critical software failures can have significant impact on safety and have economic and legal ramifications. Software testing takes up a significant portion of the software development effort and budget in most IT organizations [2]. The main purposes of software testing are to detect software failures and locate failure causes, so that software defects can be properly fixed to improve software quality and reliability. Failure detection is typically done by comparing the running behaviors from a software under test (SUT) against its expected behaviors.Due to the importance and scale involved, testing groups are typically looking for ways to introduce automation into the test case generation [3,4], testing frameworks [5,6], and failure cause localization [7–10]. To further bridge automation of the above processes, software testing depends on the availability of a test oracle[11–14], a method of obtaining expected results of an SUT and determining testing failure by comparing with its actual results. There have been many successful methodologies for automated test generation, however, finding out whether a software, given a generated test case, runs correctly has been a long time difficulty, thus significantly impairing the practicability of automated test generation [15]. One could judge the correctness of software behaviors manually based on their expertise and experiences, however, accuracy and cost are often the main obstacles.Previous efforts on test oracle automation can be summarized into three types of approaches. The first type is utilizing a formal specification on input–output analysis on a specific domain. For instances, Li and Offutt [16] recently studied test oracle strategies for model-based testing by checking state invariants, object members, return values and parameter members specified in UML state machine diagrams. Xie and Memon [17] presented automated GUI test oracles by specifying expected states after a sequence of GUI events. A test oracle can also be generated from program documentation which contains formal mathematical functions and relations using tabular expressions [18]. Day and Gannon [19] introduced an automated oracle based on semantic rules for translating from an input sequence to an output sequence; e.g., a semantic rule may require that the list of words in the input and the output sequence must be the same. For data-driven software applications, the input–output relationship can also be used to avoid combinatorial explosion of expected results by identifying unique combinations of program inputs that may influence program outputs [20]. The second type of oracle generation approaches mainly relies on a customized system model with model checking techniques [21–27], which assert expected temporal behaviors as oracles for software testing. The third type of approaches is based on heuristic strategies or previous versions. It has been argued [28] that it is often theoretically possible, but practically too difficult or expensive to determine the correct system behaviors. For this reason, heuristic test oracle techniques are often adopted to reduce testing heuristically to know simpler testing cases [29] or approximate ones [30,12]; and some techniques adapt the existing outputs from previous version for regression oracle checking [31,32,17].In this paper, the author presents a new software testing tool, TAO, which performs automated test and oracle generation based on the methodology of denotational semantics [33–35]. TAO, developed in Java, is an extended version of its previous version, Gena, an automatic grammar-based test generator [36], with new capabilities on automated test oracle generation and a tagging variable mechanism to embed semantics into test cases. TAO provides users a simple Java interface to define semantic domains as well as their associated semantic methods, and a declarative approach to specify a context-free grammar (CFG) and its respective denotational semantics. Semantics are defined on each grammar rule, such that when a test case is generated by TAO, its expected semantics is automatically evaluated simultaneously. TAO further allows users to define tagging variables to catch intermediate semantics results and embed them with test cases generation automatically.Two practical applications of TAO are reported in this paper: testing a set of Java programs which perform arithmetic calculations and locating their fault-inducing patterns, and a Selenium-based web testing automation. The experimental results demonstrate the effectiveness on test and oracles generation using TAO and its successful applications on software testing.The semantic approach on oracle generation aligns with the research line of using a formal specification [14]. The approach applies the methodology of denotational semantics on specifying expected behaviors, by assigning mathematical meanings to structured inputs or running scripts in a recursive way. Different from previous works [16–20], TAO provides a general declarative framework allowing users to define semantics domains and to specify both CFGs and their semantics for automated test and oracle generation. TAO integrates test and oracle generation as a whole to promote better automated software testing. Previous work of TAO on grammar-based test generation can be found in [36]. An online version of TAO is available at [37].As far as the author knows, TAO is the first attempt to apply the methodology of denotational semantics in test and oracle generation for various application domains. Due to the natures of context-free grammar and denotational semantics, this approach is particularly suitable for those systems under test (SUTs) which require structured input data, such as text processing tools and software product lines, for generating executable testing scripts or methods for those SUTs which involve user-interactive events, such as web applications, reactive systems, and database applications. SUTs requiring complex inputs are often difficult to test systematically; testers tend to link failure causes to input patterns which are not correctly processed, and use these fault-inducing patterns as a guide to pinpoint the locations of the faults. On the other hand, preparing testing scripts or methods are often done with the help of software IDE; and maintaining testing scripts for sufficient testing coverage is a difficult and tedious job.The rest of the paper is organized as follows. Section 2 gives a brief introduction on the denotational semantics methodology. Section 3 illustrates the overall design architecture of TAO. Section 3.1 describes how automated test generation is supported in the early version, Gena. Sections 4 and 5 present important design features on automated oracle generation and their implementation, respectively. Section 6 shows experimental results on two application domains. Section 7 addresses other related issues and future works. Finally, conclusions are given in Section 8.Denotational semantics [33–35] is a formal methodology for defining language semantics, and has been widely used in language development and practical applications [38,39]. Denotational semantics of a language contains three components:•syntax: the appearance and the structure of sentences, typically specified as a context-free grammar;semantics: basic mathematical domains along with associated operations, used to denote the mathematical meanings for sentences;valuation functions (or denotation): the connection from syntax to semantics.Broadly speaking, for a SUT which requires grammar-based structured inputs, the specification of the structured inputs is a formal language; for those testing scripts (or methods) running together with a SUT, the specification of those scripts is a formal language. Denotational semantics is concerned with finding mathematical objects called domains that capture the meaning of an input sentence – the expected result of the SUT, or the semantics of a testing script – the running behavior of the script itself along with the SUT. The denotation of a sentence in a language is typically defined using recursive valuation functions over its syntactic structures.Example 1Consider a Java application, which takes an infix arithmetic expression and performs its integer evaluation. The syntax of the input language, integer arithmetic expressions, is given as follows in Fig. 1(a), where[N], a symbolic terminal denoted by a pair of squared brackets, is an abstract notation for a finite domain of integers, from 1 to 100.The semantics of arithmetic expressions, as their expected results in the Java application, are typically interpreted as integers with assistance of a set of standard arithmetic binary operators, including add, sub, mul, and div. The denotational semantics is thus defined by three valuation functions:E,F, andT, which map their corresponding grammatical structures to their respective semantics as shown in Fig. 1(b), where a pair of double brackets represent grammatical structures, a derivation subtree in practice. Each valuation function (e.g.,E) defines a semantic function for a grammar variable (e.g., E). Also, the symbol [N] is treated as a symbolic terminal [40], which is substituted by a random element from its given domain during test generation.For example, consider an input expression,5+3⁎8. Its denotationE[[5+3⁎8]], based on the above denotation semantics, can be evaluated as follows. Note that the valuation functionEis applied on the grammatical structure of the expression5+3⁎8, rather than the linear input of the expression itself; and so are the functionsFandT:E[[5+3⁎8]]=E[[5]]addF[[3⁎8]]=F[[5]]add(F[[3]]mulT[[8]])=T[[5]]add(T[[3]]mul8)=5add(3mul8)=5add24=29The denotational semantics function maps the grammatical structure of an input expression to its expected result in the SUT. The mapping procedure is more abstract than the actual operational semantics of the SUT, since no computation steps need to be specified for the actual implementation, except its abstract mathematical results.Fig. 2illustrates the design architecture of TAO, which integrates the methodology of denotational semantics into automated test and oracle generation for software testing. TAO extended Gena, an automatic grammar-based test generator [36], with a formal framework supporting the three components of denotational semantics. The extension allows TAO to provide users a general mechanism to define a semantic domain and its associated operations as a Java class, which can be integrated with TAO for supporting semantic evaluation. TAO takes as inputs a context-free grammar and its corresponding semantic valuation functions, and produces test cases along with their expected behaviors in a fully automatic manner.The paper focuses on the design and implementation issues of TAO, particularly on its automated test and oracle generation, and its general applications on software testing. TAO is able to generate either test data for those SUTs which require structured input data or executable test scripts that can run along with SUTs. As shown in Fig. 2, this approach may allow users to synthesize a test case and its expected behavior in a declarative way into an executable testing script.Given a CFG, automatic grammar-based test generation is typically done by simulating the leftmost derivation from its start variable. The essential problem is how to generate a terminal string without getting lost into recursion. Naive grammar-based test generation is problematic due to the fact that random generation is often non-terminating due to the self-cycle complication of recursive production rules [41–43], and test generation with explicit annotations often causes unbalanced testing coverage [44–46].As an early version of TAO, Gena [36] is an automatic grammar-based test generator, implemented in Java. It takes as inputs a standard context-free grammar (CFG) and a total number of test cases to request, and produces well-distributed test cases for software testing, in terms of the coverage of productive grammar rules and their combinations. Gena utilizes a novel dynamic stochastic model where each variable is associated with a tuple of probability distributions, which are dynamically adjusted along with the derivation. The more a production rule has contributed to self-cycles while generating a test case, the lower the probability that the same rule will be applied in the future.Each grammar variable has a degree tuple, initially all 1׳s, which records the degrees of recursion caused by each of its applicable production rules. Once a recursion of E, caused by an applicable ruleR, is detected, the degree tuple of E will be adjusted by doubling the degree of recursion associated with the contributing production ruleR. Such an adjustment is said a double strategy[36]. The main purpose of maintaining a table of degree tuples is determining a dynamic probability distribution for selecting a next production rule. Given a degree tuple(d1,d2,…,dn), wheren≥1is the number of rules for a variable, its corresponding probability distribution(p1,p2,…,pn)is determined as follows:pi=wiT,wherewi=d1diandT=∑i=1nwi,where a probability weight wiis a ratio showing the relative degrees of the first rule over the ith production rule.Example 2Consider the following CFG, where the third production rule of E is a recursive rule and its second one is a double recursion:E⩴[N]∣E+E∣E−[N][N]⩴1‥1000Fig. 3shows a coverage tree [36], which records the distribution of 5 test cases and how each of them is generated, given the CFG in Example 2. Each node in a coverage tree contains a partially derived substring, starting from a leftmost variable E, and a local probability tuple for E. Each label along the edge from a parent node to a child node, if any, shows a terminal substring, just before the leftmost variable, derived from the parent node. Thus, each path from the root to a leaf node corresponds to a complete leftmost derivation for generating a test case, where each edge corresponds to one or more derivation steps, and a leaf node, represented by a little gray box, denotes the completion of the derivation. A test case is the concatenation of the labels along the path. Note that a coverage tree always starts with a root node containing the start variable of grammar; and the starting position of each edge on the node tells which production rule has been applied. Note that each occurrence of[N]is substituted by a random integer between 1 and 1000 in practice.When a new node is created with a derived substring whose leftmost variable is E, its local probability tuple is calculated based on the current degree tuple of E. For example, when the root node E in Fig. 3 was initially created, its local probability tuple is(0.33,0.33,0.33), which tells that at this point, equal probability is assigned to each of the three possible derivation branches. Stochastically, the test generator will take one branch with equal probability to continue a test generation. Once a derivation branch has been fully explored for test generation, its local probability tuple will be adjusted dynamically for future test generation, which prevents that a same structured test case will be generated. See the present status of the root node E in Fig. 3, its local probability tuple has been updated to(0.00,0.50,0,50)because the first branch, corresponding to the ruleE:≔[N], has been fully explored.The table in Fig. 3 shows how the double strategy pushes the derivation in the middle path of the coverage tree to terminate at runtime, assuming that the middle one is the very first test case generated by Gena. The probabilities for E among three production rules are evenly distributed initially, and then dynamically adjusted based on detection of recursion. When E is derived toE+E, due to the recursion caused by the second production rule, the double strategy is applied to adjust the degree tuple of E to(1,2,1)and hence the probability tuple to(0.4,0.2,0.4). Other derivation steps in the table can be followed similarly. The more a production rule has contributed to self-loops while generating a test case, the significantly less probability the same production rule will be selected in the future due to the double strategy applied. Note that the strategy detects a self-loop by actually seeing a same variable during its own derivation, instead of by selecting a potential recursive rule; therefore, the non-recursive rule, no matter how many times it has been applied, its corresponding degree of recursion will not be doubled, leaning the derivation toward the non-recursive one. Note in the last line of the table, the first probability is updated to 0 because the last branch by applying the non-recursive rule is fully explored.Gena exhibits the following stable behaviors on generating test cases, given an unambiguous proper CFG.11A CFG is called proper if it has neither inaccessible variables nor unproductive variables.•termination: It will always terminate generating a test case.diversity: Every generated test case is structurally different.similarity: Peer grammatical structures have equal opportunities of occurrences in generated test cases.reachability: Each accessible and productive variable should have an assessable chance to get derived during test generation.Refer to [36] for detailed explanations on the stable behaviors of Gena.TAO has been extended to support test oracle generation by specifying and evaluating denotational semantics. The extension includes the following three main components: (i) a Java interface on implementing semantic domains as well as associated operations to support the evaluation of semantics; (ii) an extended declarative notation to define a semantic valuation function for each CFG production rule; and (iii) automated oracle generation along with test generation.TAO provides a general interface for users to define a semantic domain and its associated operations as a Java class, named Domain.java. For testing the application in Example 1, the Java class Domain.java may contain an integer variable, which will eventually hold the semantic result, and a set of methods, such as intAdd, intSub, intMul, and intDiv supporting the basic integer arithmetic operations. The prototype of semantic domain is given as follows:Semantic Domain: intSemantic Functions:intAdd:int×int→intintSub:int×int→intintMul:int×int→intintDiv:int×int→intTo support semantic evaluation, each CFG production rule is equipped with a Lisp-like list notation denoting a semantic valuation function, separated by a delimiter ‘@@’ from the CFG rule. Fig. 4shows an example of valuation functions for each CFG rule. A semantic valuation function, named a semantic term in this context, can be one of the two following formats:•a singleton, such as a variable in the associated CFG production rule or any constant. For simplicity, if a singleton is the same as the first token in the body of CFG rule, the semantic rule can be omitted, since it has been implicitly supported by TAO.a fully parenthesized prefix list notation denoting a semantic valuation function, where the leftmost item in the list (or nested sublist) is a semantic operation defined the Java class, Domain.java.Consider the rule in line(2); it means that if the test case contains a grammar structureE+F, its corresponding semantic value can be calculated via a λ-expressionλE.λF.(intAddEF), where the formal arguments E and F are omitted due to their implication in the CFG rule itself, and the λ-expression body is represented in a Lisp-like semantic term convention. The functor intAdd is defined in the semantic domain class, and the occurrences of E and F on the right of ‘@@’ denote their respective semantic values, which are obtained recursively during evaluation.If the semantic term is a singleton (e.g., in line (1)), it simply returns the semantic result of the singleton. By default, if a CFG rule is given without specifying a corresponding semantic function (e.g., lines (8) and (9)), an implicit function, which returns the semantic value of the leftmost syntax token of the CFG rule, is defined. Therefore, the following rule is equivalent to the rule (8):T⩴[N]@@[N]TAO allows valuation functions to be nested, as shown below:E⩴3*F@@(intAddF(intAddFF)).Different from the context-free property in CFG, multiple occurrences of a same variable F in a semantic function denote the expected semantic value of their same corresponding syntax token F. However, for a grammar rule with multiple occurrences of a same variable in the grammar part, TAO adopts indexes in a left to right order to distinguish the different instances in its valuation function. For example,E⩴E−E@@(intSubE#1E#2)In automated test script generation, it would be ideal that runtime assertions can be automatically embedded into a test script, so that when a test script is invoked for software testing, the running result immediately indicates either success or failure of testing; otherwise, a post-processing procedure is typically required to check the running result against the oracle.TAO provides an easy tagging mechanism for a user to embed expected semantic behaviors into a generated test case. It allows users to create a tagging variable as a communication channel for passing semantic results from oracle generation to test generation. A tagging variable is in a form of$[N], where N can be any non-negative integer. A tagging variable can be defined in front of any semantic term<SemTerm>, either a singleton or a fully parenthesized prefix list notation, in a form of$[N]:<SemTerm>.Example 3Consider adding the following two grammar production rules at the beginning of the CFG in Fig. 4,(1)TD⩴E‘=’Assert@@$[1]:E(2)Assert⩴$[1]where TD is the new main CFG variable deriving an arithmetic expression and its expected evaluation result as well. Thus, a possible test case could be:3⁎(8−4)=12, where 12 is the expected semantic value obtained by the tagging variable,$[1].Each tagging variable has its application scope on deriving a test case. Let$[N]be a tagging variable defined in the $[N]:<SemTerm>of the following grammar rule:H⩴B0,B1,…,Bn@@$[N]:<SemTerm>The application scope of$[N]is inB0,B1,…,Bnand their recursive CFG rules. In Example 3, the grammar rule (1) on TD allows the tagging variable$[1]to record the value of the semantic term E, and allows any occurrences of$[1]to be replaced by its recorded value within the scope of deriving “E=Assert” during test generation. Therefore, when the non-terminal Assert is derived to ‘$[1]’, it will be replaced by its recorded semantic value automatically. If a tagging variable is used out of its application scope, it will be shown as the variable name itself in test scripts.For Example 3, the derivation of3⁎(8−4)=12can be described as follows:TD⇒E=Assert▹rule(1)inExample3⇒⁎3⁎(8−4)=Assert▹rulesinFig.4⇒3⁎(8−4)=$[1]▹rule(2)inExample3⇒3⁎(8−4)=12▹thevalueof$[1]isreadywhenthederivationofTDisdoneThe tagging variable and its replacement mechanism is achieved in the TAO implementation by firstly generating a test data of TD and evaluating its corresponding semantics, secondly storing the semantic value into a tagging variable if the variable is specified, and finally substituting the occurrences of the tagging variable by its recorded semantic value. Intermediate semantic values can also be recorded and embedded into test scripts, if necessary, since the derivation procedure in the test generation is performed recursively and a corresponding semantic tree is evaluated in a bottom-up way.Each CFG rule and its associated semantic term (e.g.,<SemTerm>) has a default tagging variable,$[0], which is implicitly defined to record the result of<SemTerm>. Therefore, the following rule generates the same result as Example 3:TD⩴E’=’$[0]@@EEven though$[0]is implicitly defined to record the result of<SemTerm>, TAO allows users to redefine$[0]to record intermediate semantic results (e.g., nested semantic subterms). Note that in TAO, it is the recorded value of$[0]which returns to a parent semantic function, and the value of$[0], if redefined, may not be the same as the semantic result of<SemTerm>. Also, TAO allows users to define multiple tagging variables in a single semantic function. Such a design enables users to catch intermediate semantic results and check properties on semantic results for runtime assertion purposes.Example 4Consider the CFG in Fig. 4. Suppose users want to embed a runtime assertion into a test case to check the parity of the evaluation result of a generated arithmetic expression, but still generate the evaluation result serving the purpose of oracle. A new rule can be added as follows:TD⩴’Theparityof’E’is’$[1]@@$[1]:(getParity$[0]:E)where getParity is a semantic operation, defined in Domain.java, to check whether a given number is even or odd. In such a case, the whole semantic term is applied to get an assertion property value in test generation, while the default tagging variable$[0], recording the value of a nested term, is returned to a parent semantic function, serving for other test oracle purposes, if necessary.TAO takes inputs a CFG and a total number of test cases to request, and produces test cases well-distributed over grammar production rules. Symbolic terminals [40] are adopted to hide the complexity of different terminal inputs which share syntactic as well as expected testing behavior similarities. TAO utilizes a novel dynamic stochastic model where each variable is associated with a tuple of probability distributions, which are dynamically adjusted along with the derivation. To achieve the dynamic adjustment, the author used a tabling strategy [47] to keep track of re-occurrences of grammar variables. The tuple associated with a grammar variable records the degrees of recursion caused by each of its rules. These tuples eventually determine the probability distribution of selecting a next rule for further derivation. The dynamic stochastic approach almost surely guarantees the termination of test case generation, as long as a proper CFG, which has no inaccessible variables and unproductive variables, is given.A coverage tree is dynamically maintained during test generation, where each path from the root to a leaf node corresponds to a generated test case. Not only does the tree show the distribution of test cases and how each of them has been generated, but it also supports implicit balance control mechanism based on local probability distribution on each node. Once a derivation branch has been fully explored for test generation, local probability distribution will be adjusted accordingly for future test generation. As a result, the test generation algorithm guarantees that every generated test case is structurally different as long as the given CFG is unambiguous. More implementation details on grammar-based test generation can be found in [36].To support automated oracles, TAO maintains a semantic tree dynamically entangled with the procedure of test generation, where each grammar variable is bound with a corresponding semantic node, such that whenever a grammar variable is fully derived to a terminal string, its corresponding semantic node will be completely extended for evaluation as well.There are mainly two types of semantic nodes, a regular node and a λ-node, both of which are a three tuple. ‘^’ is used to denote a null link. A regular node contains the following parts:itema semantic terminal, a grammar variable, or a tagging variable;a link to a semantic subtree obtaining the semantic value of a variable or a semantic valuation function; anda link to a peer semantic node.And a λ-node, as shown as a black bold-line node in Fig. 5, contains:lambdaa link to the formal argument part of a λ-expression;a link to the function part of the λ-expression; anda link to a list of defined tagging variables, where$[0](denoted by the index 0 in Fig. 5) is defined by default.Fig. 5 shows a partial semantic tree for a partial derivationE(1)⇒E(2)+F(3)⇒⋯,where a variable with a superscript (e.g.,E(1)) tells that the variable is bound with a semantic node with the same label. To facilitate such a recursive extension, TAO binds each underived variable in test generation with a corresponding regular semantic node, so that when a variable is derived by applying a grammar rule, its bound semantic node will be expanded with a semantic subtree, rooted at a λ-node, corresponding to its associated valuation function. A double-line node as well as a label is used to denote a semantic node bounded with a derivation variable in Fig. 5. The start variableE(1)of the derivation is initially bound with the semantic node(1). AsE(1)is derived toE(2)+F(3)by applying the ruleE⩴E+F@@(intAddEF),a corresponding semantic structure, rooted by a λ-node, is loaded as a def value of the semantic node (1), and more importantly, the two underived variablesE(2)andF(3)are bound with the semantic nodes (2) and (3), respectively, which are maintained in a runtime derivation stack for further expansion. In the semantic subtree which represents the function “(intAdd E F)”, the node, whose item and next links are null, indicates that it is a semantic term in form of a parenthesized prefix list notation and the semantic term is defined in its def link. The semantics of E and F will be recursively obtained from the corresponding formal argument (lambda) part during test generation.Algorithm 1Semantic tree evaluation.1: Input: a bound semantic node, sNode2: Output: a semantic value3: functionEVALUATE(sNode)4:λNode←sNode.def▹get the λ-node5:if (λNode.funis not null) then▹the node not evaluated yet6:for each node p inλNode.lambdado7:p.item←evaluate (p)▹evaluate parameters recursively8:end for9:for each tagging node q inλNode.taggingdo10:p.def←new SemNode(evalFun (q.def), null, null) ▹ Algorighm 211:end for12:λNode.fun←null▹indicate: the node already evaluated13:end if14:return getTaggingValue(0);▹return$[0]as a semantic value15: end functionEvaluating the semantic function.1: Input: a semantic term node, fNode2: Output: a semantic value3: functionEVALFUN(fNode)4:if (fNode.item is not null) then5:if (fNode.def is null) then6:returnfNode.item▹constant7:else8:returnevaluate (fNode.def)▹variable9:end if10:else▹a fully parenthesized semantic term11:functor←fNode.def12:i←013:aNode←functor14:whileaNode.next is not nulldo15:aNode←aNode.next16:args[i]←evalFun (aNode)17:i←i+118:end while19:returnapply (functor, args)▹call semantic operations20:end if21: end functionTAO generates test data as well as its associated semantic tree simultaneously. A derivation tree for generating a test data is entangled with a semantic tree for generating a corresponding oracle by means of binding a derivation variable with a semantic node and a tagging mechanism. Once a semantic tree is constructed, it can be evaluated in a bottom-up way to obtain its expected result, serving as an oracle. A pseudo code is given in Algorithm 1 for evaluating a semantic root node. If its λ-node has not been evaluated (line 5), the procedure first evaluates each node recursively in its formal argument part (lines 6–8), then evaluates each tagging variable by evaluating attached semantic terms (lines 9–11), where the function evalFun is defined in Algorithm 2. The procedure defined in Algorithm 2 is pretty straightforward, where the sub-function apply(functor, args) will invoke the pre-defined semantic operation functor in the Java class Domain.java.Oracles are critical on software testing to determine whether an SUT, given a test data, runs correctly or not. There are two typical roles that semantics-based oracles can play in automated software testing.Bridge from test generation to failure cause isolation: One nice feature of TAO is that when a test case is generated, it comes with a derivation tree containing structural patterns of the test case. These structural patterns give clues to users on what have been tested; and more importantly, when a failure is found, users may be able to isolate the failure causes based on its related structural patterns. For those applications with complex data inputs, programmers often intuitively link fault causes to input patterns which are not correctly processed, and use those fault-inducing patterns as a guide to pinpoint the locations of the faults. To locate precise fault-inducing patterns from structural inputs, users may apply hierarchical delta debugging [48].Embedding expected behaviors into a test script: TAO provides an easy tagging mechanism for a user to embed expected behaviors into a generated test script as runtime assertions. While specifying a CFG and its associated semantic functions, users may introduce tagging variables to record semantic values, and then pass the values to generated test scripts via embedding the tagging variables into CFG rules. Intermediate semantic values can also be recorded and embedded into test scripts, if necessary, since the derivation procedure in test generation is performed recursively and a corresponding semantic tree is evaluated in a bottom-up way.

@&#CONCLUSIONS@&#
This paper presented an application of denotational semantics on specifying and generating test cases and oracles in software testing. To support the denotational semantics methodology, TAO allows users to specify a CFG and its associated semantic valuation functions in a Lisp-like notation, and further provides a generic interface for users to define a semantic domain as a Java class, which can be integrated into TAO. Two practical case studies were given to illustrate how automated test and oracle generation can be effectively applied in different testing scenarios. The first scenario, testing Java programs on arithmetic calculation, shows that automated oracle generation plays critical roles in locating testing failure and fault-inducing patterns; the second scenario on Selenium-based web testing shows TAO is able to generate a JUnit test suite for automated web testing, by incorporating TAO-generated web operations, standard JUnit test header and footer, and web runtime behavior checking together. Based on the case studies, not only can the approach be applied on those SUTs which require structured input data, but it can also be adopted effectively on generating executable testing scripts or methods that can run along with SUTs.