@&#MAIN-TITLE@&#
Multilingual Spoken Language Understanding using graphs and multiple translations

@&#HIGHLIGHTS@&#
Test-on-source multilingual speech understanding.Construction of graphs of words from multiple translations.Semantic decoding of graphs of words using statistical models.Unsupervised portability for Spoken Language Understanding.

@&#KEYPHRASES@&#
Multilingual Language Understanding,Graph of words,Graph of concepts,Statistical semantic models,

@&#ABSTRACT@&#
In this paper, we present an approach to multilingual Spoken Language Understanding based on a process of generalization of multiple translations, followed by a specific methodology to perform a semantic parsing of these combined translations. A statistical semantic model, which is learned from a segmented and labeled corpus, is used to represent the semantics of the task in a language. Our goal is to allow the users to interact with the system using other languages different from the one used to train the semantic models, avoiding the cost of segmenting and labeling a training corpus for each language. In order to reduce the effect of translation errors and to increase the coverage, we propose an algorithm to generate graphs of words from different translations. We also propose an algorithm to parse graphs of words with the statistical semantic model. The experimental results confirm the good behavior of this approach using French and English as input languages in a spoken language understanding task that was developed for Spanish.

@&#INTRODUCTION@&#
Spoken Language Understanding (SLU) is an important challenge in human-machine interaction systems (Hahn et al., 2010; Raymond and Riccardi, 2007; Tür and Mori, 2011). In particular, SLU is a key component of Spoken Dialog Systems. Although many of the SLU systems are rule-based, there has been a growing interest in statistical modelization, which has provided good results (Maynard and Lefèvre, 2001; Segarra et al., 2002; He and Young, 2006; Lefèvre, 2007; De Mori et al., 2008). Statistical models have the advantages that they can be automatically learned from training samples and can accurately modelize the variability of semantics in spontaneous speech. Unfortunately, however, it is necessary to have a segmented and labeled training corpus that in most cases must be manually generated. This is a very time-consuming task which makes the adaptation of SLU systems to different tasks or languages difficult and expensive. In order to address this problem, many efforts have been made to develop semi-supervised and unsupervised learning techniques for semantic modelization (Tür et al., 2005; Ortega et al., 2010). These techniques can help to learn models from unlabeled corpora, in some cases taking advantage of the large amount of data that can be extracted from the web and other linguistic resources (Tür et al., 2011; Heck and Hakkani-Tür, 2012).When the problem is to adapt a SLU system that was developed for one language to another language, it would be desirable to take advantage of the effort made for the original language and not have to replicate the work for the other language. This issue has also been addressed in other areas of Natural Language Processing such as Part-Of-Speech (POS) tagging (Täckströ et al., 2013). In this work, a projection of POS annotation from English to other resource-poor languages is done.The multilingual approaches to SLU can be grouped in two classes, so-called test-on-source and train-on-target. In the test-on-source approach, there is a SLU system developed for a source language and the test are utterances in another language. The process consists of translating the test sentence into a sentence in the source language and performing the SLU of this translated sentence by using the SLU system in the source language. In the train-on-target approach, a new SLU model is trained in the target language, which is the language in which the test utterances are pronounced. To do this, it is necessary to translate the training corpus from the original language to this new language and to learn the corresponding SLU models. It must be noted that the translation of the training corpus not only consists of the translation of the sentences but also in the segmentation and semantic labeling of the training sentences into this new language. Once we have a model in this target language, the understanding process can be solved as in the monolingual SLU because the input utterance and the models are in the same language. Some works that focus on the adaptation of SLU systems to other languages have been presented in the last few years (Servan et al., 2010; Lefèvre et al., 2010; Jabaian et al., 2013; Calvo et al., 2012; García et al., 2012). The work presented in this paper addresses the problem of developing a multilingual SLU system that avoids the effort of manually relabeling the corpus in other languages. In a previous work, we studied the possibility of translating the training corpus to learn models in the target language (García et al., 2012), which is a train-on-target strategy.In this work, we propose an approach to multilingual Spoken Language Understanding where there is a SLU system in a source language and the user turns are translated from the target language into this source language, which is a test-on-source strategy. An essential aspect to ensure the viability of systems of this kind is the performance of the translation process. If we use Statistical Machine Translation (SMT) systems, such as MOSES (Koehn et al., 2007), it is necessary to have a parallel corpus in both languages that must be specifically designed for the domain, and this corpus is not always easy to obtain. On the other hand, we could use general-purpose translators that can be found on the web. The problem is that these translators often generate many errors; however, by using different translators and combining these translations, we may be able to correct the errors as well as improve the coverage. This is why we have focused our work on obtaining good mechanisms to combine different translations and on determining how to process them in the semantic module of a multilingual Spoken Dialog System. The SLU system presented here is based on a decoupled architecture in which there is a first phase consisting of the translation process and a second phase that corresponds to the semantic decoding process. In order to be able to recover errors generated in the translation phase, multiple hypotheses are conveyed to the second phase by means of a graph.We have developed an algorithm to obtain a graph of translations from the sentences generated by the translation process in the first phase. This graph represents a finite language that is a generalization of the translated sentences. In other words, the language represented by the graph not only contains all the sentences generated by the translation process, but it also contains other additional sentences. For the second phase, the semantic decoding, we have developed a graph-parsing algorithm that supplies the best path in the graph of translations according to the stochastic semantic model.In summary, our work proposes a test-on-source strategy to adapt SLU systems developed for one language to another language with the following main contributions:•The use of two alternative translation processes to obtain different translations of the user utterance: we propose the use of general-purpose web translators and also the use of a SMT system (MOSES) estimated from a parallel corpus.The construction of a graph of words from these different translations using a proposed graph-construction algorithm.The application of a graph-parsing algorithm that supplies the best path in the graph of words according to the understanding model.We have applied this approach to the SLU module of a Spoken Dialog System for the DIHANA task (Benedí et al., 2006), which consists of an information system about train timetables and fares in Spanish. To evaluate the multilingual approach, we have acquired a French and English corpus for testing, which consists of written and spoken sentences.

@&#CONCLUSIONS@&#
In this work, we propose a multilingual stochastic SLU system that takes advantage of multiple translators. We have designed an architecture where the communication between different modules is done by means of graphs. This way, the intermediate modules have the capability of generalizing from different hypotheses, which makes it possible to recover errors generated in previous phases. To do this, a specific semantic-parsing algorithm has been developed. We have proposed two test-on-source approaches for language portability. Both methods differ in the way that the Speech Translation process is performed. The first one is based on the combination of outputs from a set of general-purpose web translators; in the second one, a Statistical Machine Translation system is trained using an automatically collected task-dependent parallel corpus. We have also studied the complementarity of these two proposals by combining the output of all the general-purpose web translators and the output of the Statistical Machine Translation system.In all cases the manual effort to adapt the system to the new languages is avoided, which was one of the objectives of the work. Consequently, an advantage of this methodology is that it can be easily ported to many languages.The results show that the performance of the systems is good enough, taking into account that a translation process (usually a source of errors) is embedded between the input sentence and the understanding module. The results also show that the generalization inferred from the multiple translations and the inference algorithm to combine them permits some errors generated in previous phases to be recovered. This is clear in the first group of experiments, where the use of a combination of translations was better than the use of each translator separately, which only considered one hypothesis. On the other hand, although the BLEU and WER measured after the translation and semantic decoding processes indicated a low performance in terms of translation, the CER and FSER were satisfactory showing that many errors in words have no influence on the final semantic decoding.