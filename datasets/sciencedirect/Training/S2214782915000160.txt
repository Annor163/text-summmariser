@&#MAIN-TITLE@&#
Detecting suicidality on Twitter

@&#HIGHLIGHTS@&#
This study determined the level of concern for suicide-related Twitter posts using human coders and a computer classifier.14% of suicide-related tweets were deemed ‘strongly concerning’ and believed to warrant further investigation.The automated computer classifier achieved the same accuracy as the human coders.However, it remains unclear whether the ‘strongly concerning’ tweets were genuine statements of suicidality.

@&#KEYPHRASES@&#
Twitter,Suicide,Social media,Machine learning,Prevention,Big data,Online,

@&#ABSTRACT@&#
Twitter is increasingly investigated as a means of detecting mental health status, including depression and suicidality, in the population. However, validated and reliable methods are not yet fully established. This study aimed to examine whether the level of concern for a suicide-related post on Twitter could be determined based solely on the content of the post, as judged by human coders and then replicated by machine learning. From 18th February 2014 to 23rd April 2014, Twitter was monitored for a series of suicide-related phrases and terms using the public Application Program Interface (API). Matching tweets were stored in a data annotation tool developed by the Commonwealth Scientific and Industrial Research Organisation (CSIRO). During this time, 14,701 suicide-related tweets were collected: 14% were randomly (n=2000) selected and divided into two equal sets (Set A and B) for coding by human researchers. Overall, 14% of suicide-related tweets were classified as ‘strongly concerning’, with the majority coded as ‘possibly concerning’ (56%) and the remainder (29%) considered ‘safe to ignore’. The overall agreement rate among the human coders was 76% (average κ=0.55). Machine learning processes were subsequently applied to assess whether a ‘strongly concerning’ tweet could be identified automatically. The computer classifier correctly identified 80% of ‘strongly concerning’ tweets and showed increasing gains in accuracy; however, future improvements are necessary as a plateau was not reached as the amount of data increased. The current study demonstrated that it is possible to distinguish the level of concern among suicide-related tweets, using both human coders and an automatic machine classifier. Importantly, the machine classifier replicated the accuracy of the human coders. The findings confirmed that Twitter is used by individuals to express suicidality and that such posts evoked a level of concern that warranted further investigation. However, the predictive power for actual suicidal behaviour is not yet known and the findings do not directly identify targets for intervention.

@&#INTRODUCTION@&#
The World Health Organization recently reported that on average, a suicide occurs every 40s (World Health Organization, 2014). Worldwide, an estimated 804,000 suicide deaths occurred in 2012, representing an annual global age-standardised suicide rate of 11.4 per 100,000 population, 15.0 for males and 8.0 for females. Furthermore, there are up to 20 times as many adults who attempt suicide (World Health Organization, 2014). Suicide has a devastating impact on families (Cerel et al., 2008) and communities (Levine, 2008), and many suicide deaths are preventable (Bailey et al., 2011). Understanding the ways in which individuals communicate their suicidality is key to preventing such deaths. Suicidality is defined as any suicide-related behaviour, thoughts or intent, including completing or attempting suicide, suicidal ideation or communications (Goldsmith et al., 2002). Suicidal ideation is defined as thoughts about killing oneself, while suicidal behaviours involve acts of self-harm with the intention of causing death (Goldsmith et al., 2002). While not all individuals experiencing suicidal ideation will plan or make an attempt on their life, such ideation places individuals at increased risk of death by suicide (McAuliffe, 2002). In face-to-face settings, suicidality is usually uncovered by an outright disclosure of intent, or by asking an individual about their thoughts and actions. Some individuals have communicated their suicidal thoughts and plans to friends and family prior to suicide (Wasserman et al., 2008; Wolk-Wasserman, 1986); however, it is accepted that many do not disclose their intent. Recently, individuals have broadcast their suicidality on social media sites such as Twitter (Jashinsky et al., 2013), indicating that this social media site may have potential for use as a suicide prevention tool (Luxton et al., 2012).Twitter is a free broadcast social media site that enables registered users to communicate with others in real-time using 140 character statements. Users create a network by following other accounts; although, the large majority of Twitter accounts are public which allows anyone to view their content. Twitter content can be posted via a web interface, SMS or a mobile device. It is available in almost all countries except China, Iran and North Korea, and has no minimum age requirement. Approximately 23% of online adults use Twitter and over 500 million tweets are sent per day (Duggan et al., 2015). Twitter has recognised that individuals express suicidality in their broadcasts and have created internal mechanisms that allow it to be reported (Twitter Inc, 2014). If deemed serious, Twitter can provide the account holder with crisis support services. This type of risk detection is not automatic, does not occur in real-time, and relies solely on the discretion of networked users, of whom many have difficulty determining genuine risk (Wolk-Wasserman, 1986). Similarly, clinicians have reported monitoring patients' mental health via social media and they too are uncertain about the sincerity of posts, their duty of care and the ethics of intervention (Lehavot et al., 2012). Given the large volume of Twitter data, it is not yet feasible or ethical to directly contact and survey every Twitter user who may be at risk. The parameters of this risk are yet to be determined. Previous studies have collected and classified suicide-related tweets (Jashinsky et al., 2013); however, data sets remain small and modelling for automatic detection is in its infancy. Although Twitter may provide an unprecedented opportunity to identify those at risk of suicide (Jashinsky et al., 2013) and a mechanism to intervene at both the individual and community level, valid, reliable and acceptable methods of online detection have not yet been fully established (Christensen et al., 2014). Best practice for suicide prevention using social media remains unclear.This study aimed to establish the feasibility of consistently detecting the level of concern for individuals' Twitter posts, colloquially referred to as ‘tweets’, which made direct or indirect textual or audio-visual references to suicidality. Using a set of instructions and categories, human coders aimed to do this using only the content of the tweet itself. Following this process, this study aimed to design and implement an automated computer classifier that could replicate the accuracy of the human coders. The feasibility of this automated prediction was to be examined using recall and precision metrics.

@&#CONCLUSIONS@&#
