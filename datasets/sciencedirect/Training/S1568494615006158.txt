@&#MAIN-TITLE@&#
An efficient memory-based electromagnetism-like mechanism for the redundancy allocation problem

@&#HIGHLIGHTS@&#
An efficient MBEM is proposed to solve the redundancy allocation problem.MBEM employs a memory matrix in local search to save the features of good solutions.Various test problems and benchmarks are used to evaluate the performance of MBEM.Experimental results show that optimal solutions of all benchmark instances are obtained.The computer execution times of the algorithm on all large-scale instances are reasonable.

@&#KEYPHRASES@&#
Redundancy allocation problem,Electromagnetism-like mechanism,Local search,Memory-based algorithms,

@&#ABSTRACT@&#
Meta-heuristic algorithms have been successfully applied to solve the redundancy allocation problem in recent years. Among these algorithms, the electromagnetism-like mechanism (EM) is a powerful population-based algorithm designed for continuous decision spaces. This paper presents an efficient memory-based electromagnetism-like mechanism called MBEM to solve the redundancy allocation problem. The proposed algorithm employs a memory matrix in local search to save the features of good solutions and feed it back to the algorithm. This would make the search process more efficient. To verify the good performance of MBEM, various test problems, especially the 33 well-known benchmark instances in the literature, are examined. The experimental results show that not only optimal solutions of all benchmark instances are obtained within a reasonable computer execution time, but also MBEM outperforms EM in terms of the quality of the solutions obtained, even for large-size problems.

@&#INTRODUCTION@&#
Optimization of system reliability is a widely surveyed subject in the field of reliability, where various types of models have been introduced so far. There are two general strategies to maximize system reliability: (1) increasing the reliability of system components and (2) finding the optimal number of redundant components used in the system. The latter that introduces the so-called redundancy allocation problem (RAP) involves a combinatorial optimization problem, in which the aim is to find optimal number of proper components [1–3]. The models proposed for RAP are applicable to design highly reliable systems that are assembled and manufactured using off-the-shelf components. Some real-world applications include transportation system design [3], telecommunication design [4], and electrical power system design [5].Depending on system configuration, the structure of a system in the literature of RAP is categorized as series, parallel, series–parallel [6], k-out-of-n[7], and hierarchical series–parallel or complex. Among these, the series–parallel is a common structure that is used in many designs due to its wide applications and in this research; the RAP is addressed for this system structure. A series–parallel system includes a total of s independent subsystems arranged in series, in which the ith subsystem has up to nmax functionally equivalent components arranged in parallel. Each component potentially differs in reliability, weight, cost, and other features. A subsystem can work efficiently if at least one of its components is operational. Besides, the number of components in the ith subsystem, ni, can be selected from Tiavailable component types where multiple copies of each type can be chosen. The schematic view of a typical series–parallel system is depicted in Fig. 1.Reliability of a series–parallel system can be improved in four ways by: (1) using components that are more reliable, (2) increasing redundant components in parallel, (3) simultaneously utilizing the previous two, and (4) enabling repeatedly the allocation of the entire system framework [8]. However, there are two types of limitations involved: (1) resources like cost, component volume, and techniques are usually confined and (2) system constraints such as weight, capacity, and other specifications are fixed and cannot be changed in short notice [9]. While it is very difficult to work out an optimal solution under multiple constraints, several optimization algorithms have been proposed in the past decades to solve the series–parallel redundancy allocation problem. Fyffe et al. [10] proposed a mathematical model for RAP without component mixing under cost and weight constraints and employed a dynamic programming approach to solve it.Chern [11] proved that a RAP in series systems with linear resource constraints belongs to the class of Non-deterministic Polynomial-time hard (NP-hard) problems. Hence, researchers started to focus on developing meta-heuristics that can obtain near-optimum solutions of acceptable quality in reasonable computational times. Coit and Smith [12] suggested a genetic algorithm (GA) to analyze series–parallel systems and to determine the optimal design configuration when there are multiple component choices available for each of several k-out-of-n subsystems. Kulturel-Konak et al. [13] developed a Tabu search (TS) meta-heuristic to provide solutions to the system-reliability-optimization problem of redundancy allocation. Besides, an ant-colony optimization (ACO) algorithm for the RAP devised and tested on a well-known suite of problems from the literature in [14]. You and Chen [9] developed an efficient heuristic algorithm with greedy method (GM) and GA for series-parallel redundant reliability problems with separable constraints. They tested various well-known redundant allocation problems using their proposed algorithm and other competing conventional algorithms. Chena and You [15] proposed an immune algorithms-based (IA) approach for RAP with multiple component choices. They showed that the performance of IA was sensitive to value-combinations of the parameters, whose best values were case-dependent. Liang and Chen [16] presented a variable neighborhood search (VNS) algorithm to solve RAP with multiple component choices. The VNS algorithm of their research that included a newly designed neighborhood called shaking operation along with an adaptive penalty function was tested on a set of well-known benchmark problems from the literature. They showed that the shaking operation and the adaptive penalty function helped improve the performance of the algorithm.Onishi et al. [17] developed an exact solution method, based on the improved surrogate constraint (ISC) [18], and used it to solve benchmark problems from the literature. They showed the ISC-based method to be effective in terms of computational speed, as all computational times were less than one second. Nahas et al. [19] hybridized an ACO with a degraded ceiling local search technique to develop efficient solutions to the RAP, called ACO/DC. Tavakkoli-Moghaddam et al. [20] utilized a GA to solve RAP of a series–parallel system when either active or cold standby redundancy could be selected for individual subsystems. Beji et al. [21] developed a hybrid particle swarm optimization (PSO) algorithm to design an optimal reliability series–parallel system where the number of redundancy component and component reliability in each subsystem were to be decided simultaneously. Yeh and Hsieh [22] and Hsieh and Yeh [23] showed that the solution of RAP in reliability of series–parallel systems found by artificial bee colony (ABC) was better than some other meta-heuristics. Wu et al. [24] developed an improved particle swarm optimization algorithm for reliability problems. An annealing-based PSO, called APSO was proposed by Safaei et al. [25] to solve RAP with multiple component choices. They employed the metropolis-hastings, the main strategy behind the simulated annealing (SA), as a local search engine to improve the best position among all particles. Sadjadi and Soltani [26] developed a honey bee mating optimization (HMBO) algorithm for RAP with several constraints and different alternatives for components. Soltani et al. [27] adapted Sadjadi and Soltani [26] heuristic in order to enable it to enhance the reliability of the serial–parallel systems with component mixing. Chambari et al. [28] proposed a simulated annealing algorithm (SA) for the redundancy allocation problem with a choice of redundancy strategies, consisting of active and cold-standby components.It is usually difficult to judge which meta-heuristic performs the best among all for a given design problem. These algorithms perform variously in different design problems or even in a given problem with different parameters [29]. However, on the one hand, there are opportunities for improved effectiveness and efficiency of reported GA, ACO, TS, and IA for example through combining these algorithms with other meta-heuristic algorithms. On the other hand, some meta-heuristic algorithms such as ABC, HMBO, VNS, and VND may offer excellent solutions for reliability optimization problems. Recently, Soltani [30] offered a comprehensive survey and classification of reliability optimization models and methods.The electromagnetism-like mechanism (EM) algorithm is known as a new population-based meta-heuristic to tackle complex optimization problems [31,32]. It has been used in different cases such as capacitated vehicle routing problems [33], nonlinearly constrained global optimization [34], scheduled trucks in cross-docking systems [35], PID controller optimization [36], periodic job-shop scheduling problem [37], and layout design of reconfigurable manufacturing system [38]. EM imitates the attraction–repulsion of the electromagnetic theory that is based on Coulomb's law for obtaining the optimal solution. One of the advantages of this method is its small number of adjusting parameters. EM algorithm shows significant performance compared with other meta-heuristics in some NP-hard problems. However, it is still in its infancy and intensive studies are needed to improve its performance.To enhance the quality of solution in EM, several approaches have been proposed in literature. Xing et al. [39] proposed a revised electromagnetism-like mechanism for layout design of reconfigurable manufacturing system. They adopted the VNS strategy in the local search procedure of EM. Ali and Golalikhani [34] presented an electromagnetism-like method for a nonlinear constrained global optimization problem, in which a charge calculation of a point based on both the function value and the total constraint violations was adopted. Therefore, the calculation of the total force vector is different from the original EM method. In addition, Yurtkuran and Emel [33] developed a new hybrid electromagnetism-like algorithm for a capacitated vehicle routing problem, in which the iterated swap procedure (ISP) was applied as a new fast technique instead of the local search of ordinary EM.Although EM and its variations have been utilized to solve various optimization problems so far, to the best of the authors’ knowledge it has not been utilized to solve RAP of series–parallel systems yet. The algorithms available in the literature include some local search-based meta-heuristics [16] and one way of improving the performance of meta-heuristics as a hybrid approach using a local search procedure as well [19,21,25]. In addition to a local search that may improve the performance of EM, it will be modified in this research to suit RAP of series–parallel systems (instead of its original intends to solve continuous optimization problems). More specifically, this paper intends to develop a learning method for EM and proposes a memory-based electromagnetism-like mechanism (MBEM) for RAP. To do this, a memory matrix is used in the local search procedure to separate positive variations from negative variations, in a hope to generate better results. Using the available benchmarks in the literature, we will show that using a memory matrix in the local search procedure will significantly improve both the efficiency and the robustness of EM.The remainder of the paper is arranged as follows: Section 2 describes the problem in details. Section 3 presents the proposed memory-based electromagnetism-like mechanism (MBEM). The computational and comparison results are presented in Section 4 and finally, the conclusion comes in Section 5.In this section, the problem along with its assumptions is first described. Then, nomenclature used to model the problem is stated. Finally, the mathematical formulation of the problem is given.Consider a series–parallel system with s subsystems in series, each having ni; i=1, 2, …, s components in parallel. The goal is to design a system such that the system reliability is maximized within the system-level constraints on cost and weight. In addition, the following assumptions are made:•The states of a component and its subsystem are one of the True or False states.Failed components do not lead into system damage or failure and are not repaired either.The supply of components is unlimited.The component reliabilities are assumed known and deterministic.The state of components is assumed independent of each other.Active redundancy strategies are considered.The two sets of notation, one to model the problem and the other to code the model are provided in this section.The notation to model the RAP at hand are shown in Table 1.The notation to code the model using the proposed memory-based electromagnetism-like mechanism are given in Table 2.The RAP can be formulated to maximize system reliability given restrictions on system cost and system weight. The mathematical model of the general redundancy allocation problem is:(1)MaxR=∏i=1sRi(yi|ki)(2)∑i=1sCi(yi)≤C(3)∑i=1sWi(yi)≤W(4)yijintegerfori=1,2,…,sandj=1,2,…,TiThe objective function in Eq. (1) aims to determine the redundancy strategy, component type, and the quantity of components in each subsystem such that the system reliability is maximized. The constraints given in (2) and (3) are for the available budget and the maximum system weight, respectively. Moreover, if a pre-selected maximum number of components are considered in parallel for each subsystem, constraint (5) is added to the previous ones:(5)ki≤∑j=1Tiyij≤nmax;∀i=1,2,…,sEM is a population based meta-heuristic introduced by Birbil and Fang [31]. EM imitates attraction and repulsion of the electromagnetic theory to obtain optimal solution. The four procedures used in this algorithm are: (1) initialization, (2) neighborhood search to exploit local minima, (3) total force calculation exerted on each particle, and (4) movement along the direction of the force. The pseudo-code of EM is shown as follows:Procedures1. Initialize2: While (the stop criterion is not met) do3. Local search4. Calculate total force5. Move particle in the direction of the force6. End whileThe original EM that was designed to find optimum solutions of continuous optimization problems cannot be applied for interrupted optimization problems directly. In order to suit it for the RAP problem at hand, a memory matrix is added to the local search procedure to increase its efficiency. However, before introducing this matrix in Section 3.3, the particle representation and the initialization procedure are first explained in the following two subsections.A particle is represented by a s×z matrix, where s is the number of subsystems and z is the maximum number of component type in all subsystems. A scheme of this representation is illustrated in Fig. 2.Great care needs to be taken in order to initialize the algorithm to ensure convergence to desirable and better objective functions in a reasonable amount of time. In this procedure, popsize particles are randomly generated in the feasible region, where each attribute of a particle is assumed to be uniformly distributed between the corresponding upper and lower bound. Then, the objective function value for each particle is calculated and a particle with the best value is saved. The pseudo code of the initialization procedure is shown as follows:Procedure 1: Initialization1. fori=1 to popsizedo2.fork=1 to gdo3.xki=createdrandomnumber4.end for5. Calculate f(xi)6.end for7. xbest=argmin{f(xi), ∀i}The use of local search is one of the methods that can improve the evolution speed of a meta-heuristic. There are some methods available in the literature that applied memory on the local search [39–41]. The idea behind these methods is to keep positive and/or negative characteristics of previous solutions as information and applying them for improvement of the quality of next solutions. In this study, a memory matrix is used to keep good features of previous solutions. The pseudo code of the proposed local search procedure is shown as follows. The details involved in the pseudo code are explained in the following subsections.Procedure 2: Local search (particle, δ, ROM)1. fori=1 to popsizedo2. counter=13.while counter≤LSITERdo4. set the ith particle as a new particle5.select number of D separate subsystems randomly from new particle, D=Max (round (s×δ), 1)1.forl=1 to Ddo2.if rand≤ROM3.change the lth selected subsystem from new particle according to the memory matrix4.if all the elements of the lth selected subsystem in memory matrix are zero5.change the lth selected subsystem from new particle according to neighborhood structures6.end if7else8.change the lth selected subsystem from new particle according to neighborhood structures9.end if10.end for11. evaluate new particle12.if the new particle is better than the ith particle13.set new particle as ith particle14.update memory matrix15.counter=LSITER−116.end if17.counter= counter +118.end while19. end forIn order to generate neighbor solutions for each particle, first select a number of subsystems, D, obtained by(6)D=Max(round(s×δ),1)where δ is a parameter. Then, a set E with the size 1×D from the selected subsystems (SSl) is formed by(7)E={SSl};l=1,2,…,DThe possible combination matrix (PC) is considered to create neighborhood solutions based on the memory. A sample structure for this matrix is presented in Fig. 3. To construct this matrix, the quantity of component j used in subsystem i, i.e. yij, is assumed to take values between a lower and an upper bound (i.e., lij≤yij≤uij) with lij=0 and uij=mmax assigned by user. The number of rows of the PC matrix is the maximum number of component type in all subsystems (z) and its columns contain all existing component-type combinations of each subsystem defined by Nsolobtained by(8)Nsol=(mmax+1)zFor instance, the PC matrix when s=3, z=2, and mmax=2 is shown in Fig. 4, where based on Eq. (8), Nsol=9.In the proposed MBEM algorithm, the positive and negative features are separated using a memory matrix. The memory matrix is a s×Nsolmatrix, with the rows and columns corresponding to the number of subsystems and Nsol, respectively. The memory matrix is initially filled with zeros. During the search process, the information mechanism recognizes which component assignment can improve solutions. This information is stored in the memory matrix by setting its corresponding bits to 1. The memory matrix feeds the information back to EM and guides it to search in a space that contains better solutions. During the local search, components are first assigned to various subsystems and then the results of these allocations are evaluated using the fitness function, where new information on the component allocation is received. The memory matrix is updated each time a new and improved solution is found. The transaction between EM and the memory matrix continues until the termination criterion is satisfied (i.e. a predetermined maximum number of iterations is reached). Fig. 5depicts a schematic of the memory matrix.The memory matrix is updated by the best particle so far found through the local search procedure. In this case, a logic called updating replaces the zeros in the cells of the memory matrix by one. This logic involves two steps. In the first step, subsystems that have been changed in the new and improved particle through the E set are found. In the second, a combination of the subsystems in E is found and its corresponding bits are replaced by 1. Fig. 6depicts the updating memory in the instance shown in Fig. 4 with the assumption that the new particle is a better one. In Fig. 6, subsystems 1 and 3 are first selected for change based on the updating logic, then, the combinations 3 and 5 are considered for subsystems 1 and 3, respectively.During the search procedure, the memory matrix is employed under a variable rate called rate of memory (ROM). To balance the trade-off between the exploration and exploitation, a small initial ROM favors exploration in the initial steps of the search. As the iteration number increases, bigger ROM facilitates exploitation. Therefore, a linear dynamic tuning strategy is considered to control ROM using the following equation:(9)ROM=(iteration−1)MAXITERROMfinal+(MAXITER−iteration)MAXITERROMinitialwhere ROMinitialand ROMfinalare the initial and the final rates of memory, respectively. Fig. 7shows the dynamic change diagram of ROM in different iterations of the proposed algorithm.There are two types of policy to generate a new neighbor solution in MBEM: (1) generating neighbors using the memory matrix; and (2) generating neighbors with neighborhood structures. In order to select the policy, a random number b is first generated based on the uniform (0, 1) distribution. Then, if b is less than the ROM, the memory matrix is used. Otherwise, a neighborhood structure is utilized. These two policies are described in the following two subsections.The steps involved to generate neighbor solutions for each selected subsystem in this policy are:Step 1: Select one of the combinations from the ith row of the memory matrix marked by 1.Step 2: Extract this combination from the PC matrix.Step 3: Change the ith row of the particle.Note that, if all the elements in the ith row of the memory matrix are zeros, then the second policy is applied. As an example, consider the example given in Sections 3.3.2–3.3.4. In this example, subsystems 1 and 2 are first selected. Then, subsystem 1 can choose one of the combinations 3, 7, or 8 randomly (e.g. 7) and subsystem 2 can choose the combination 2. Then the new particle is generated as shown in Fig. 8.Neighborhood structures describe how a new neighbor solution is generated using previous solutions. In this paper, three neighborhood structures called NS1, NS2, and NS3 are selected randomly for the local search. The details on how these structure works come next.•Neighborhood structure NS1According to NS1, the positions of two randomly selected bits are swapped as shown in Fig. 9.Neighborhood structure NS2In NS2, two bits are selected randomly and their values are regenerated randomly, as shown in Fig. 10.Neighborhood structure NS3The steps for generating neighbor solutions by this structure are as follows:Step 1: Select two bits using the maximum and the minimum value.Step 2: Replace the maximum and the minimum value by zero and a random number greater than zero, respectively.This neighborhood structure is shown in Fig. 11.The third procedure in MBEM is to calculate the total exerted force on each particle. According to the electromagnetism theory, the electrostatic force between two point charges is directly proportional to the magnitudes of each charge and inversely proportional to the square of the distance between the charges. The charge of each particle i, qi, determines its power of attraction or repulsion. This charge can be obtained by Eq. (10).(10)qi=exp−nf(xi)−f(xbest)∑r=1popsizef(xr)−f(xbest),i=1,2,…,popsizewhere f(xi), f(xr), and f(xbest) are the objective value of ith particle, the objective value of rth particle and the best solution of the population respectively. Moreover, n is used to decrease the computational effort by reducing the charge values. Based on Eq. (10), we note that the points that have better objective function values possess higher charges. Since the number of population points in higher dimensions tends to get large, the dimension multiplies the exponent in Eq. (10).The quality of the solution or the charge of each particle shows the magnitude of an attraction or repulsion effects in the population. After comparing the objective function of the particles, the direction of a specific force between two particles is determined. At the end, the total force exerted on point i is calculated using Eq. (11). The total force calculation process is shown as follows:Procedure 3: Total force calculation1: fori=1 to popsizedo2:calculate (qi)3:Fi=04: end for5: fori=1 to popsizedo6:forr=1 to popsizedo7:iff(xr)<f(xi)then8:Fi=Fi+(xr−xi)qiqr||xr−xi||{Attraction}9:else10:Fi=Fi−(xr−xi)qiqr||xr−xi||{Repulsion}11:end if12:end for13: end for(11)Fi=∑r≠ipopsize(xr−xi)qiqr||xr−xi||2iff(xr)<f(xi)(xi−xr)qiqr||xr−xi||2iff(xr)≥f(xi)An example of the total force vector Fiexerted on candidate solutions is shown in Fig. 12. Assume that there are three particles. The force exerted on x3 by x1 is called F13. If the objective function of x3 is more desirable than x1, then, x3 will repulse x1. The force exerted on x3 by x2 is called F23. If the objective function of x3 is more undesirable than x2, then, x3 will attract x2. Consequently, F is the eventual force exerted on x3 by x1 and x2.After calculating the total force exerted on a point, the final procedure involves moving along the direction of the force. Particle i in the force direction moves by a random length step given in Eq. (12), in which λ is the random length step generated via the uniform distribution between 0 and 1. Besides, to preserve feasibility, the force exerted on each particle is normalized.(12)xi=xi+λFiFiRNG;i=1,2,…,popsizeIn Eq. (12), RNG is a vector whose components denote the allowed range of the movement toward the lower or upper bound for the corresponding dimension. The pseudo code of the moving procedure is shown as follows:Procedure 4: Movement by total forces1: fori=1 to popsizedo2:ifi≠bestthen3:λ=U(0, 1)4:Fi=Fi||Fi||5:fork=1 to ndo6:ifFki>0 then7:xki=xki+Fki(uk−xki)8:else9:xki=xki+Fki(xki−lk)10:end if11:end for12:end if13: end forThe proposed MBEM algorithm repeats iteratively until a termination criterion is met. In this paper, the algorithm is stopped when a maximum number of iterations sis obtained. Besides, the flowchart of the proposed MBEM algorithm is given in Fig. 13.

@&#CONCLUSIONS@&#
