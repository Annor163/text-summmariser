@&#MAIN-TITLE@&#
GPU accelerated dynamic functional connectivity analysis for functional MRI data

@&#HIGHLIGHTS@&#
First dynamic functional connectivity (DFC) analysis study using GPU and OpenMP.We proposed two parallel algorithms for DFC analysis.CUDA- and OpenMP-based algorithms are implemented and tested FRMI datasets.In CUDA, thread- and block-based approaches were analyzed, discussed, and compared.A CUDA-based design reached up to 157× speedup.

@&#KEYPHRASES@&#
GPU computing,CUDA,OpenMP,Dynamic functional connectivity,Functional magnetic resonance imaging,fMRI,

@&#ABSTRACT@&#
Recent advances in multi-core processors and graphics card based computational technologies have paved the way for an improved and dynamic utilization of parallel computing techniques. Numerous applications have been implemented for the acceleration of computationally-intensive problems in various computational science fields including bioinformatics, in which big data problems are prevalent. In neuroimaging, dynamic functional connectivity (DFC) analysis is a computationally demanding method used to investigate dynamic functional interactions among different brain regions or networks identified with functional magnetic resonance imaging (fMRI) data. In this study, we implemented and analyzed a parallel DFC algorithm based on thread-based and block-based approaches. The thread-based approach was designed to parallelize DFC computations and was implemented in both Open Multi-Processing (OpenMP) and Compute Unified Device Architecture (CUDA) programming platforms. Another approach developed in this study to better utilize CUDA architecture is the block-based approach, where parallelization involves smaller parts of fMRI time-courses obtained by sliding-windows. Experimental results showed that the proposed parallel design solutions enabled by the GPUs significantly reduce the computation time for DFC analysis. Multicore implementation using OpenMP on 8-core processor provides up to 7.7× speed-up. GPU implementation using CUDA yielded substantial accelerations ranging from 18.5× to 157× speed-up once thread-based and block-based approaches were combined in the analysis. Proposed parallel programming solutions showed that multi-core processor and CUDA-supported GPU implementations accelerated the DFC analyses significantly. Developed algorithms make the DFC analyses more practical for multi-subject studies with more dynamic analyses.

@&#INTRODUCTION@&#
Computational power of multicore processors and Graphical Processing Unit (GPU) supported devices, which are now widely available in commonly-used computers, provide a practical way to implement computationally intensive algorithms in parallel. Open Multi Processing (OpenMP) application programming interface provides an efficient abstraction for implementing parallel algorithms for multicore processors [1,2]. Software developers utilized advantages of OpenMP to speed up their applications using regular multicore CPUs. In addition to multicore processors, most of the modern graphics cards that have GPUs deliver computing hubs for the acceleration of parallelizable algorithms that demand high computational power. Numerous improvement attempts greatly increased the flexibility of the hardware and allowed the GPU vendors to better scale horizontally. Over time, uneven work distribution in this aspect of the architecture has been refined further. Specialized processor types, each with its own special instructions, have been unified into one less specialized processor type that is able to handle more general tasks. Unified processors have become more complex as well as more flexible.Currently, large number of lightweight threads in a GPU enables properly designed parallel algorithms to be executed relatively faster than sequential implementation. Compute Unified Device Architecture (CUDA) provides an exceptional foundation for programmers to utilize NVidia(R) GPUs efficiently [3–5]. Since their debut, OpenMP and CUDA-based parallel applications attracted researchers to use these tools in scientific and engineering applications including bioinformatics. Utilizing parallel computing methods to accelerate computational power also have gained importance. For example, various image processing and signal processing applications, heuristic optimization methods such as genetic algorithms, simulated annealing and particle swarm, and solutions of differential equations are just a few examples that have been implemented successfully using CUDA. Parallel computing approaches are also of high interest in bioinformatics to accelerate time-consuming computations [6–10].Dynamic functional connectivity (DFC) analysis is one of the computationally-intensive methods in neuroscience for investigating dynamic interactions among different brain networks (also applied to other organs such as the spinal cord [11]) from functional magnetic resonance imaging (fMRI) data, using dynamic sliding-window temporal correlation analysis [12–17]. DFC-based analyses identify pairs of brain areas that are activated or deactivated in tandem over the duration of fMRI experiments. However, fMRI data from multiple subjects examining interacting brain networks with DFC can be very large, such as 234×435=101,790 for 234 scans and 30 combinations per scans in human brains [13,15,18] as well as small animals’ brains (e.g., rodents [19]). Hence, DFC analysis can be computationally intensive depending on the imaging data size, resolution, and analysis parameters such as sliding-window width and window step size.The need for a more rapid computational approach for the DFC analysis warranted parallelization of the DFC algorithm and utilization of GPUs. GPUs are now more common and inexpensive; hence, the utilization of the parallel computations on GPUs would make the DFC analyses feasible for many researchers. Moreover, using the parallelization with GPUs, dynamic brain interactions can be accessed near-real-time or real-time during fMRI experiments using the DFC analysis. Another important application of the parallelization can be to the recently developed real-time neurofeedback fMRI experiments. It has been recently shown that the interactions occurring among different brain regions can be possibly exploited as neurofeedback, which can be used to potentially learn voluntary self-regulation at individual brain levels [20–27] using dynamic fMRI activation analysis in real-time. These novel approaches may lead to improved and more distinct sensory perceptions [28,29], faster motor response [30], and therapeutic effects in chronic patients [24], Parkinson's disease [23], tinnitus [31] and depression [32]. Voluntary regulation of functional interactions between different brain regions [21] has also been proposed; however, it was based on static functional connectivity. Some recent work utilized GPUs for fMRI data analysis [6,33], and more recently for functional connectivity analysis [34], but none applied it to DFC analysis of fMRI data.Enabling near real-time analyses of the brain's dynamic functional connectivity was the primary motivation for the utilization of parallel computing capabilities of OpenMP-supported multi-core CPUs and CUDA-supported GPUs to speed up the DFC analysis on a multi-subject fMRI dataset in this paper. In this work, 234 fMRI scans sessions from 83 de-identified subjects were used, since each subject had 2 or 3 separate fMRI scan sessions. We will refer to an fMRI scan session as “fMRI scan”, or simply “scan”, throughout this text, as it is common in the literature [35]. An identical set of 30 brain networks and their corresponding signature fMRI time-series data, which we refer to as “time-courses” throughout the text, were extracted for each subject. These networks and their time-courses were refined by a spatial group independent component analysis (ICA), which we simply refer to as “ICA” throughout this text. ICA is a data-driven blind source-separation technique which provides independently “behaving” brain networks common to all the subjects within a group of subjects [36–39].While a parallel implementation of DFC analysis based on OpenMP provides a practical way to reduce the computation time on multicore computers, CUDA-enabled GPU cards open door to further accelerations for the intensive computations. For this very reason, we developed parallel DFC algorithms based on the proposed thread-based and block-based approaches. Thread-based approach focuses on a single time-course as unit size of data and implemented in both OpenMP and CUDA programming environments. The block-based computing method is specific to GPU hardware and is proposed to better utilize GPU architecture under certain analysis parameters. The experimental results were obtained using a multicore host having AMD (R) FX 8320 processor and NVidia(R) GeForce GTX 660 GPU devices, which are widely available in the current market.The article is organized as follows. In the following Section 2, the details of the DFC algorithm, the computing application interfaces, algorithmic elements of OpenMP and CUDA, the implementation and proposed thread- and block-based approaches are explained. In Section 3, the details of the hardware we use and experimental results are provided. The outcomes of our designs are also discussed in Section 3. The last section, Section 4, finalizes the work with summary and future studies.

@&#CONCLUSIONS@&#
Computational demands of the DFC analyses on fMRI data from multi-subject experiments are significantly high. Based on our implementations of the presented DFC algorithm, current multicore processor and GPU technologies were shown to accelerate the computationally-intensive DFC algorithm. The GPU's architecture, which exploits the parallelism in the proposed implementation of the DFC algorithm, made the DFC analysis more practical as it enabled real-time or near real-time implementations. Our results showed that OpenMP and CUDA implementations significantly reduced the DFC computation time, and the utilization of parallel computing capabilities of GPU devices is very useful for the purpose of reducing computation time in the DFC analysis of fMRI data. The results also indicated that the increase in the intensity of the computations significantly boosted the speed-up/efficiency of the GPU device over the CPU, which amplifies the benefit of using GPUs for large scale multi-subject and multi-center fMRI studies. The achieved speed-ups in our study were obtained with NVidia(R) GeForce GTX 660, which is a widely available medium-end GPU device. Further performance improvements can be obtained using high-end NVidia(R) GPU devices.For future studies, we plan to utilize GPU clusters to reduce the execution time below one second for larger sizes of analyses, which can make real-time DFC analysis feasible, allowing neurofeedback based on DFC analysis of fMRI data. Our future work will involve seeking algorithmic improvements for reducing the execution time such as using a pseudo-correlation [43] method instead of using regular correlation function. Furthermore, the computation time of the correlation function can be improved in the GPU's local memory in both the thread- and block-based approaches that we utilize. It will also be important to investigate the effect of reducing data precision in order to speed-up data transfer procedures from host to GPU, which are the bottleneck for the whole computation. Lastly, a scalability as well as energy efficiency analysis should be investigated using a big data perspective comparing GPU and Hadoop [44] platforms.The authors declare that they have no competing interests.Dr. Sakoglu and Dr. Mete supervised the project. Mr. Esquivel conducted preprocessing and analysis of the fMRI dataset. Dr. Akgün implemented OpenMP and CUDA functions. Mr. Esquivel contributed initial setting of the implementations. Dr. Adinoff provided the MRI dataset and motivated the study. Comparison and testing were done by Dr. Akgün. All authors wrote, revised, and approved the manuscript.