@&#MAIN-TITLE@&#
A comparison of 3D shape retrieval methods based on a large-scale benchmark supporting multimodal queries

@&#HIGHLIGHTS@&#
Build a large-scale 3D shape retrieval benchmark that supports multi-modal queries.Evaluate the 26 3D shape retrieval methods using 3 types of metrics.Solicit and identify state-of-the-art methods and promising related techniques.Perform detailed analysis on diverse methods w.r.t accuracy and efficiency.Make benchmark and evaluation tools freely available to the community.

@&#KEYPHRASES@&#
3D shape retrieval,Large-scale benchmark,Multimodal queries,Unified,Performance evaluation,Query-by-Model,Query-by-Sketch,SHREC,

@&#ABSTRACT@&#
Large-scale 3D shape retrieval has become an important research direction in content-based 3D shape retrieval. To promote this research area, two Shape Retrieval Contest (SHREC) tracks on large scale comprehensive and sketch-based 3D model retrieval have been organized by us in 2014. Both tracks were based on a unified large-scale benchmark that supports multimodal queries (3D models and sketches). This benchmark contains 13680 sketches and 8987 3D models, divided into 171 distinct classes. It was compiled to be a superset of existing benchmarks and presents a new challenge to retrieval methods as it comprises generic models as well as domain-specific model types. Twelve and six distinct 3D shape retrieval methods have competed with each other in these two contests, respectively. To measure and compare the performance of the participating and other promising Query-by-Model or Query-by-Sketch 3D shape retrieval methods and to solicit state-of-the-art approaches, we perform a more comprehensive comparison of twenty-six (eighteen originally participating algorithms and eight additional state-of-the-art or new) retrieval methods by evaluating them on the common benchmark. The benchmark, results, and evaluation tools are publicly available at our websites (http://www.itl.nist.gov/iad/vug/sharp/contest/2014/Generic3D/, 2014, http://www.itl.nist.gov/iad/vug/sharp/contest/2014/SBR/, 2014).

@&#INTRODUCTION@&#
With the increasing number of 3D models created every day and stored in databases, the development of effective and scalable 3D search algorithms has become an important research area. Generally speaking, their objective is to retrieve 3D models similar to a 2D/3D sketch/image or a complete 3D model query from a large collection of 3D shapes. In this paper, we present a new large-scale benchmark that includes a large number of diverse types of sketches and models. Owing to the integration of the most important existing benchmarks to date, the newly created benchmark is the most extensive to date in terms of the number of semantic query categories covered as well as the variations of model types. In particular, it combines generic and domain-dependent model types and therefore rates the retrieval performance with respect to cross-domain retrieval tasks. The benchmark supports both sketch and 3D model queries, thus providing a unified platform to test diverse 3D model retrieval algorithms belonging to either Query-by-Model or Query-by-Sketch 3D retrieval techniques.Query-by-Model 3D retrieval is one of the most commonly seen and most widely studied 3D model retrieval techniques. Many dedicated algorithms and several benchmarks have been developed for this type of 3D retrieval. However, it requires users to provide a 3D model as a query.Query-by-Sketch (sketch-based) 3D retrieval is to retrieve a list of 3D models that closely match a provided input sketch. Compared to Query-by-Model, it is more intuitive and easier to use because users do not need to provide 3D models. However, it is also more challenging because of the semantic and representational gap between the 2D query sketches and the 3D models, and because user sketches may vary widely in sketching style and level of detail, as well. It has many applications, including sketch-based modeling and recognition, and sketch-based 3D animation [3].Two previous Shape Retrieval Contest (SHREC) tracks, SHREC’12 [4] and SHREC’13 [5], have been successfully organized on the topic of sketch-based 3D model retrieval. They invigorated this research area by providing a small-scale and a large-scale sketch -based retrieval benchmark, respectively, and attracted state-of-the-art algorithms to compete with each other. Yet, even the large-scale SHREC’13 Sketch Track Benchmark (SHREC13STB) [5] based on Eitz et al. [6] and the Princeton Shape Benchmark (PSB) [7] contains only 90 classes of 7200 sketches and 1258 models. Compared with the complete dataset of 250 user sketch classes compiled by Eitz et al. [6], there is still substantial room to make the benchmark more comprehensive in terms of completeness of object classes existing in the real world. Thus, we felt it is necessary to build an even larger sketch-based 3D retrieval benchmark with more sketches and more models to help better evaluate the scalability of existing and newly developed sketch-based 3D model retrieval algorithms. Considering this, we created a new large-scale benchmark (LSB) comprising 13680 sketches and 8987 available 3D models from 171 classes that can be and also have been used to evaluate both Query-by-Sketch and Query-by-Model 3D retrieval algorithms. Fig. 1shows several example sketches and their relevant 3D models.Based on this new benchmark, we organized a SHREC 2014 track [8] on large scale sketch-based 3D model retrieval to further foster this challenging research area by soliciting retrieval results from current state-of-the-art retrieval methods for comparison, especially in terms of scalability to a large-scale scenario. Moreover, by utilizing only the 3D target dataset of the benchmark, we organized another SHREC’14 track [9] on the topic of large scale comprehensive 3D shape retrieval to perform a comparison, especially for practical retrieval performance, of top 3D model retrieval methods. Thus, the two contest tracks have demonstrated the unification and large-scale properties of our benchmark in evaluating both Query-by-Model and Query-by-Sketch 3D retrieval techniques.In the rest of the paper, we first review the related work (w.r.t. techniques and benchmarks) in Section 2. In Section 3, we introduce the motivation, building process, contents, and evaluation metrics (containing both general and weighted variations) of the benchmark. Section 4 gives a brief introduction of the contributors of the paper. A short and concise description of each contributed method is presented in Section 5. Section 6 describes the evaluation results of the 22 Query-by-Model and 6 Query-by-Sketch 3D retrieval algorithms on the unified benchmark. Section 7 concludes the paper and lists several future research directions.

@&#CONCLUSIONS@&#
This paper describes the building process of LSB, a large-scale 3D model retrieval benchmark supporting both 3D model and 2D sketch queries. Compared to other multimodal query-supported 3D retrieval benchmarks, its 13680 sketches and 8987 models of 171 classes make it the currently largest scale benchmark in terms of the number of models and sketches as well as the most comprehensive benchmark in terms of the number of object classes and variations within a class. Compared to previous sketch-based 3D retrieval benchmarks, it is not only the largest and most comprehensive but also the only currently available comprehensive 3D model benchmark. Even compared to prior generic benchmarks, it is still among the largest and most comprehensive in terms of the number of categories. In addition to the LSB benchmark, we also developed two versions of commonly used performance metrics, proportionally-weighted and reciprocally-weighted, by incorporating the model variations in each class based on the number of available models it contains. We regard the reciprocally-weighted version as more accurate than its original form in terms of reflecting the real performance of a 3D shape retrieval algorithm either using model or sketch queries. We also hope that the large-scale sketch retrieval benchmark will prove useful for other researchers in our community.Based on the 3D model dataset of the LSB benchmark, we organized the SHREC’14 large scale comprehensive 3D model retrieval track. In this paper, a comprehensive evaluation of twenty (twelve track participating and eight state-of-the-art or new) Query-by-Model retrieval algorithms has been conducted based on both non-weighted and weighted performance metrics. A comparison of approximate runtime information was also performed to provide a reference on the efficiency of the evaluated methods, which also serves as evaluation of the scalability of each method w.r.t large-scale retrieval scenarios or real applications. According to the evaluation results, among the submitted algorithms, hybrid methods, manifold ranking learning methods, and Bag-of-Words approaches are more popular and promising in the scenario of Query-by-Model retrieval, which partially illustrates a current research trend in the field of comprehensive 3D model retrieval.Based on the complete LSB benchmark, we organized another SHREC’14 track on large scale sketch-based 3D retrieval. The second track is meant to foster this challenging and interesting research direction, encouraged by the success of the SHREC’12 and SHREC’13 sketch-based 3D shape retrieval tracks. Though the latest benchmark is by far the most challenging so far, we still attracted four groups who have successfully participated in the track and contributed twelve runs of six methods, which have been comparatively evaluated in this paper as well. We have noticed that the obtained retrieval performance is far from satisfactory, and the performance of existing sketch-based retrieval methods apparently drops when scaled to a significantly larger collection. Local feature and manifold ranking based approaches also dominate the evaluated methods and often achieve superior retrieval accuracy, but their performance leaves room for further improvements.