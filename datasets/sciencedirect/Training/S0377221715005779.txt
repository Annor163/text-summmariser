@&#MAIN-TITLE@&#
A multi-layer line search method to improve the initialization of optimization algorithms

@&#HIGHLIGHTS@&#
We describe a metaheuristic method to improve optimization algorithms.We apply our approach to five particular optimization methods.We check the performances of the resulting algorithms on various benchmark cases.We compare our results with other metaheuristic algorithms.Our algorithms exhibit good performances.

@&#KEYPHRASES@&#
Metaheuristics,Global optimization,Multi-layer line search algorithms,Evolutionary algorithms,Gradient methods,

@&#ABSTRACT@&#
We introduce a novel metaheuristic methodology to improve the initialization of a given deterministic or stochastic optimization algorithm. Our objective is to improve the performance of the considered algorithm, called core optimization algorithm, by reducing its number of cost function evaluations, by increasing its success rate and by boosting the precision of its results. In our approach, the core optimization is considered as a sub-optimization problem for a multi-layer line search method. The approach is presented and implemented for various particular core optimization algorithms: Steepest Descent, Heavy-Ball, Genetic Algorithm, Differential Evolution and Controlled Random Search. We validate our methodology by considering a set of low and high dimensional benchmark problems (i.e., problems of dimension between 2 and 1000). The results are compared to those obtained with the core optimization algorithms alone and with two additional global optimization methods (Direct Tabu Search and Continuous Greedy Randomized Adaptive Search). These latter also aim at improving the initial condition for the core algorithms. The numerical results seem to indicate that our approach improves the performances of the core optimization algorithms and allows to generate algorithms more efficient than the other optimization methods studied here. A Matlab optimization package called “Global Optimization Platform” (GOP), implementing the algorithms presented here, has been developed and can be downloaded at: http://www.mat.ucm.es/momat/software.htm

@&#INTRODUCTION@&#
We consider a general optimization problem of the form:(1)minx∈Ωh0(x)whereh0:Ω→Ris the cost function, x is the optimization parameter andΩ⊂RN,withN∈N,is the admissible space.When solving (1) by an iterative procedure the choice of the initial condition is essential. For instance, this is the case with the gradient methods such as the Steepest Descent algorithm (SD) (Luenberger & Ye, 2008), the Newton algorithm (Polyak, 2007) or with the Heavy-Ball algorithm (HB) (Attouch, Goudou, & Redont, 2000). When h0 has several local minima these algorithms converge to one of those depending on their initialization. However, these algorithms can still find the global optimum if the initial condition belongs to the attraction basin of the infimum. Another example where the initialization is of prime importance is with Genetics Algorithms (GA) (Goldberg, 1989; Gonalves, de Magalhes Mendes, & Resende, 2005) where a lack of diversity in the individuals of the initial population can result to a premature convergence to a local minimum of h0 (Rocha, Neves, & Ali, 1999).Thus, developing methods that intend to generate suitable initial conditions is interesting in order to improve the efficiency of existing optimization methods. For a given convergence accuracy, a better initialization may lead to a reduction in the number of functional evaluations, which is particularly important when working with expensive functional evaluations as in industrial design problems (Carrasco, Ivorra, & Ramos, 2012, 2015; Gomez, Ivorra, & Ramos, 2011; Ivorra, Hertzog, Mohammadi, & Santiago, 2006; Ivorra, Mohammadi, & Ramos, 2009, 2014; Ivorra, Redondo, Santiago, Ortigosa, & Ramos, 2013; Muyl, Dumas, & Herbert, 2004).The idea of improving optimization algorithms by choosing a suitable initialization is widely present in the literature. For instance, the Direct Tabu Search algorithm (DTS) (Hedar & Fukushima, 2006; Lamghari & Dimitrakopoulos, 2012) and the Tunneling algorithm (Gomez & Levy, 1982; Levy & Gomez., 1985), are based on a modification of the functional by the addition of penalty terms to avoid the algorithm to revisit previously explored regions. Other techniques, like the Greedy Randomized Adaptive Search Procedure (GRASP) (Hirsch, Pardalos, & Resende, 2010; Mart, Campos, Resende, & Duarte, 2015) or the Universal Evolutionary Global Optimizer (Redondo, Fernández, García, & Ortigosa, 2009) are based on the construction of a greedy solution combined with a local search step.Another technique consists in coupling line search methods (Luenberger & Ye, 2008; Vieira & Lisboa, 2014) with another optimization algorithm. For instance, in Gardeux, Chelouah, Siarry, and Glover (2011) the authors propose an optimization method, called EM323, well suited for the solution of high-dimensional continuous non-linear optimization problems. The algorithm EM323 consists in combining the Enhanced Unidirectional Search method (Gardeux, Chelouah, Siarry, & Glover, 2009) with the 3-2-3 line search procedure (Glover, 2010). Another example can be found in Grosan, Abraham, de Mello, and Yang (2007), in the context of Multi-Objective optimization problems. The authors develop a method combining several line search algorithms: one for determining a first point in the Pareto front and another one for exploring the front.In this work, we propose a novel metaheuristic technique also based on line search methods to dynamically improve the initialization of a given optimization method. The paper is organized as follows. In Section 2 we reformulate problem (1) as a sub-optimization problem where the initial condition of the considered optimization algorithm is the optimization parameter. This new problem is solved by considering an original multi-layer semi-deterministic line search algorithm. In Section 3, we focus on the implementation of our approach by considering two families of optimization algorithms: descent methods (in particular, SD and HB) and Evolutionary Algorithms (in particular, GAs, Controlled Random Search algorithms (CRS) (Price, 1983) and Differential Evolution algorithms (DE) (Price, Storn, & Lampinen, 2005)). In Section 4, we validate our approach by considering various test cases in both low (Floudas & Pardalos, 1999) and high (Li, Engelbrecht, & Epitropakis, 2013) dimensions. The results are then compared with those given by the following optimization algorithms: SD, HB, DTS, Continuous GRASP (CGR), CRS, DE and GA.We consider an optimization algorithm A0: V → Ω, called core optimization algorithm (COA), to solve problem (1). Here, V is the space where we can choose the initial condition for A0 (various examples are given in Section 3, for simplicity we can considerV=Ω). The other optimization parameters of A0 (such as the stopping criterion, the number of iterations, etc.) are fixed by the user. We omit them in the presentation in order to simplify the notations.We assume the existence of v ∈ V such that, for a given precisionϵ≥0,h0(A0(v))−minx∈Ωh0(x)<ϵ. Thus, solving problem (1) with algorithm COA means:(2)Findv∈VsuchthatA0(v)∈argminx∈Ωh0(x).In order to solve problem (2), we propose to use a multi-layer semi-deterministic algorithm (called in the sequel the Multi-Layer Algorithm and denoted by MLA) based on line search methods (see, for instance, Luenberger & Ye, 2008; Mohammadi & Saïac, 2003; Vieira & Lisboa, 2014).More precisely, we introduceh1:V→Ras:(3)h1(v)=h0(A0(v)).Thus, problem (2) can be rewritten as(4)Findv∈Vsuchthatv∈argminw∈Vh1(w).A geometrical representation of h1(.) in one dimension is shown in Fig. 1for a situation where the COA is the SD applied with 10,000 iterations,Ω=V=[−10,6]andh0(x)=12cos(2x)+sin(13x)+1.57. We see that h1(.) is discontinuous with plateaus. Indeed, the same solution is reached by the algorithm starting from any of the points of the same attraction basin. Furthermore, h1(.) is discontinuous where the functional reaches a local maximum. One way to minimize such kind of functionals in the one dimensional case is to consider line search optimization methods (such as the secant or the dichotomy methods, see Mohammadi & Saïac, 2003).Thus, in order to solve problem (4), we introduce the algorithm A1: V → V which, for any v1 ∈ V, returns A1(v1) ∈ V after the following steps:Step 1-Choose v2 randomly in V.Findv∈argminw∈O(v1,v2)h1(w),whereO(v1,v2)={v1+t(v2−v1),t∈R}∩V,using a line search method.Return v.The user may choose of the line search minimization algorithm in A1.This construction can be pursued looking for an optimal initialization for A1. This can be done adding an external layer to algorithm A1 and introducingh2:V→Rdefined by(5)h2(v)=h1(A1(v))and considering the following problem:(6)Findv∈Vsuchthatv∈argminw∈Vh2(w).To solve problem (6), we use the two-layers algorithm A2: V → V that, for each v1 ∈ V, returns A2(v1) ∈ V given byStep 1-Choose v2 randomly in V.Findv∈argminw∈O(v1,v2)h2(w)using a line search method.Return v.As previously, the user may choose the line search minimization algorithm in A2. Due to the fact that the line search directionO(v1,v2)in A1 is constructed randomly, the algorithm A2 performs a multi-directional search of the solution of problem (2).This construction can be pursued recursively defining(7)hi(v)=hi−1(Ai−1(v)),fori∈N,and considering the problem(8)Findv∈Vsuchthatv∈argminw∈Vhi(w).Problem (8) is solved by using the i-layers algorithm Ai: V → V that, for each v1 ∈ V, returns Ai(v1) given byStep 1-Choose v2 randomly in V.Findv∈argminw∈O(v1,v2)hi(w)using a line search method.Return v.In practice, as specified in Section 4, we run Aiwith a suitable stopping criterion and with v1 ∈ V arbitrary (or v1 ∈ V a good initial guess, if available).The choice of the random technique used to generate v2 in Step 1 of Aiis important and depends on h0. For instance, if we know that h0 has several local minima in Ω with a small attraction basins, it seems appropriate to generate v2 in a small neighborhood of v1.Also, the line search minimization algorithm used in Step 2 of Aidepends on the properties of h0, as discussed in Section 3.In this Section, we present various MLA implementations, considering different COAs, in the particular case where h0 is a non-negative function (or, equivalently, greater than a known real number). This specific situation often occurs in industrial problems (see, for instance, Ivorra et al., 2006; Ivorra et al., 2009, 2014; Ivorra, Ramos, & Mohammadi, 2007).In particular, we consider two classes of implementations of the MLA associated with two kinds of COAs: gradient and evolutionary algorithms.We consider a core algorithm A0 that comes from the discretization of the following initial value problem (Attouch et al., 2000):(9){ηd2xdt2(t)+M(x(t),t)dxdt(t)=−d(x(t)),t≥0x(0)=x0,dxdt(0)=xt,0,where t is a fictitious time,η∈R,M:Ω×R→MN×N(with MN × Ndenoting the set of matrix N × N) andd:Ω→RNis a function giving a descent direction. For instance:•Assumingh0∈C1(Ω,R),whenη=0,d=∇h0andM(x,t)=Id (the identity operator) for all(x,t)∈Ω×R,we recover, considering a suitable discretization, the SD method (Luenberger & Ye, 2008).Assumingh0∈C2(Ω,R),whend=∇h0andM(x,t)=Id for all(x,t)∈Ω×R,we recover, considering an adequate discretization, the HB method (Attouch et al., 2000). This algorithm presents an exploratory character in the optimization process, in comparison to the caseη=0,allowing to escape from attraction basins.According to the previous notation, we denote by A0(x0, xt, 0) the solution returned by the COA starting from x0 ∈ Ω with an initial “velocity”xt,0∈RNand the set of remaining algorithm parameters fixed by the user.We consider two possible choices for the initial condition of the COA (either x0 or xt, 0) leading to two different formulations of problem (2). In the following, we propose the corresponding MLAs for solving each case.We consider the following formulation of problem (2):(10)Findx0∈V=ΩsuchthatA0(x0,xt,0)∈argminw∈Ωh0(w),wherext,0∈RNis fixed. We note that any x0 ∈ argminx ∈ Ωh0(x) is a solution of (10).To solve problem (10), we consider a particular implementation of the algorithms Ai,i∈N,introduced previously. Fori∈N,Ai(v1) is applied with a secant method in order to perform the line search as following:Step 1-Choose v2 ∈ Ω randomly.For l from 1 toti∈N:Step 2.1-Ifhi(vl)=hi(vl+1)go to Step 3Setvl+2=projΩ(vl+1−hi(vl+1)vl+1−vlhi(vl+1)−hi(vl)),where projΩ:RN→Ωis a projection algorithm over Ω defined by the user.Return the output:argmin{hi(vm),m=1,…,ti}.In the previous algorithm, the values i and tidepend on the desired computational complexity. In Section 4, we check the efficiency of those algorithms for various set of values.A geometrical representation of one execution of algorithm A1 in one dimension is shown in Fig. 1.From a theoretical point of view, as the secant method is adapted to find the zeros of a function (Mohammadi & Saïac, 2003), those algorithms perform better if the minimum value of h0, denoted byh0*∈R,is known (for instance, in some inverse problems, see Ivorra, Mohammadi, & Ramos, 2014). Indeed, we can assume thath0*=0(we minimizeh0−h0*instead of h0) and thus Aiintends to find the zero of hi(see Ivorra, 2006 for more details). However, in practice (see experiments presented in Section 4), if the only information available is that h0 is greater than a known real numberhl∈R,we considerh0−hlinstead of h0 and this algorithm still gives good numerical results. This efficiency can be in part explained by the structure of the secant iteration that gives a quick information about the behavior of h0. If there is a significant evolution of the cost function value betweenvl+1and vl, the secant iteration generatesvl+2close tovl+1(because the slope of the straight line passing through the points (vl+1,h0(vl+1)) and (vl+2,h0(vl+2)) is steep) performing a refined search aroundvl+1. Otherwise, the secant method generatesvl+2far fromvl+1allowing to explore a new region.Remark 1Although this case is not considered in this paper, if no information about a lower bound value of h0 is available we could consider other MLA implementations. For instance, we can replace the secant method used in Step 2.2 by the SD iteration starting fromvl+1and using−vl+1−vlhi(vl+1)−hi(vl)as the descent direction. This new step reads:Step 2.2-Setvl+2=projΩ(vl+1−ρvl+1−vlhi(vl+1)−hi(vl)),where projΩ:RN→Ω,is a projection algorithm over Ω defined by the user andρ∈Ris obtained by solving numerically minρ∈R+h0(projΩ(vl+1−ρvl+1−vlhi(vl+1)−hi(vl)))by using a dichotomy method.We consider the following formulation of problem (2):(11)Findxt,0∈V=RNsuchthatA0(x0,xt,0)∈argminw∈Ωh0(w),where x0 ∈ Ω is fixed. In this case, under convenient hypotheses, we can prove the existence ofxt,0∈RNsuch that the solution of problem (11) can be approximated numerically, as stated in the following theorem:Theorem 1Leth0∈C2(IRN,R)having a minimum atxm∈RN. We assume that its gradient, denoted by ∇h0(.), is Lipschitz continuous. Thus, for every(x0,ϵ)∈RN×R+,there exists(σ,τb)∈RN×R+such that the solution of the following dynamical system(12){ηd2xdt2(t)+dxdt(t)=−∇h0(x(t)),t≥0,x(0)=x0,dxdt(0)=σ,withη∈R,passes at time τb into the ball of center xm and radiusϵ,denoted byBϵ(xm).We assume x0 ≠ xm(asx0=xmis a trivial case). Let δ ≥ 0, we consider the initial value problem(13){ηd2yδdt2(t)+δdyδdt(t)(t)=−δ2∇h0(yδ(t)),t≥0,yδ(0)=x0,dyδdt(t)(0)=ϱ(xm−x0),withϱ∈R+∖{0}. Let us show that yδpasses at some time into the ballBϵ(xm):•Ifδ=0,we obtain the following system(14){ηd2y0dt2(t)=0,t≥0,y0(0)=x0,dy0dt(0)=ϱ(xm−x0).System (14) describes a straight line of origin x0 and passing at some timeτϱ∈R+by the point xm(i.e.,y0(τϱ)=xm).If δ ≠ 0, System (13) can be rewritten as(15)dwdt(t)=(dyδdt(t)−δdyδdt(t)−δ2∇h0(yδ(t)))=f(t,w(t),δ),withw(t)=(yδ(t),ηdyδdt(t))and f continuous in t and in δ and Lipschitz continuous in w(t) (Attouch et al., 2000). Then, applying the Cauchy–Lipschitz theorem (see, for instance, Verhulst, 1996) and the Continuity Theorem 3.4 found in Hale (2009), we obtain thatlimδ→0|yδ(τϱ)−y0(τϱ)|=0.Thus, for everyϵ∈R+∖{0},there existsδϵ∈R+such that for everyδ≤δϵ(16)|yδ(τϱ)−xm|<ϵ.Letϵ∈R+∖{0}. We consider the change of variable given bys=δϵtandx(s)=yδϵ(sδϵ). Then, System (13) becomes(17){ηd2xds2(s)+dxds(s)=−∇h0(x(s)),s≥0,x(0)=x0,dxds(0)=ϱδϵ(xm−x0).Letτb=δϵτϱ. Under this assumption,x(τb)=yδϵ(τϱ). Thus, due to (16),|x(τb)−xm|<ϵ. We have foundσ=ϱδϵ(xm−x0)∈RNandτb∈R+such that the solution of System (12) passes at time τbinto the ballBϵ(xm).□In order to determine a solution of problem (11), we can consider, for example, the same implementation of algorithms Ai, withi∈N,as the one introduced in Section 3.1.1.Evolutionary Algorithms (EA) are population-based metaheuristic optimization algorithms which try to solve problems similar to (2) (Ashlock, 2010). From a general point of view, they start from a finite set of points in the search space Ω, called initial population, and intend to improve the value of the considered cost function by applying processes based on an analogy with the Darwinian evolution of species. For instance, we can cite some classical EAs (considered in the experiments presented in Section 4): the Genetic (Goldberg, 1989), the Controlled Random Search (Price, 1983) and the Differential Evolution (Price et al., 2005) algorithms. The EAs have many advantages, as for example: they generally do not require sensitivity computation, they can solve complex optimization problems (e.g., with high dimensional search space or function with various with local minima), and they are intrinsically parallel. However, they also have some important drawbacks as: slower convergence and lower accuracy than other methods (such as gradient algorithms (Ashlock, 2010)).We denote byX0={xj0∈Ω,j=1,…,Np},withNp∈N,the set corresponding to the initial population of the considered EA. All other parameters of the EA are fixed by the user. In this case, problem (2) can be rewritten as:(18)FindX0∈V=ΩNpsuchthatA0(X0)∈argminw∈Ωh0(w).In the following, we propose a version of the MLA used to solve problem (18). This MLA is illustrated by considering a particular Genetic Algorithm (GA), validated previously in Ivorra (2006),Ivorra et al. (2006),Ivorra et al. (2014), as the COA. We note that the proposed algorithm can be easily extended to any other EA, as illustrated in Section 4 with the use of a Controlled Random Search algorithm (CRS) and a Differential Evolution algorithm (DE) as COAs.As it is out of the scope in this paper, we do not describe the considered CRS and DE implementations, which are deeply detailed in Hendrix, Ortigosa, and Garca (2001) and Storn and Price (1997), respectively, but we give in Section 3.2.2 the implementation that we use for the GA.We first describe the GA considered here:•Step 1-Inputs: User must define the parametersNp∈N,Ng∈N,pm∈ [0, 1], pc∈ [0, 1],ϵ∈Rand the initial populationX0∈ΩNp. The meaning of those parameters is clarified later in the following steps.Step 2-Generating new populations: Starting from X0, we recursively create Ngnew populations by applying four stochastic processes: ‘selection’, ‘crossover’, ‘mutation’ and ‘elitism’, which are described in Steps 3.1, 3.2, 3.3 and 3.4, respectively.More precisely, letXi={xji∈Ω,j=1,…,Np},withi=1,…,Ng−1,denotes the population at iteration i. Then, using the (Np, N)-real valued matrixXi=[x1i⋮xNpi]=[x1i(1)…x1i(N)⋮⋱⋮xNpi(1)…xNpi(N)],withxji=(xji(1),…,xji(N))∈Ω,Xi+1is obtained by considering:Xi+1=(IN−Ei)(CiSiXi+Mi)+EiXi,where matricesSi,Ci,Mi,Eiand INare described below.–Step 2.1-Selection: We randomly select Npindividuals from Xiwith eventual repetitions. Each individualxji∈Xi,withj=1,…,Np,has a probability to be selected in this process which is given byJ−1(xji)/∑k=1NpJ−1(xki). This step can be summarized asXi+1,1=SiXi,whereSiis a (Np, Np)-matrix withSj,ki=1if the kth individual of Xiis the jth selected individual andSj,ki=0otherwise.Step 2.2-Crossover: For each pair of consecutive individuals (rows)2j−1and 2j inXi+1,1,with 1 ≤ j ≤ floor(Np/2) (where floor(X) is the nearest integer lower or equal than X), we determine, with a probability pc, if those rows exchange data or if they are directly copied into an intermediate population denoted byXi+1,2. Mathematically, this step can be written asXi+1,2=CiXi+1,1,whereCiis a real-valued (Np, Np)-matrix. The coefficients of the(2j−1)-th and 2jth rows ofCi,with 1 ≤ j ≤ floor(Np/2), are given byC2j−1,2j−1i=λ1,C2j−1,2ji=1−λ1,C2j,2ji=λ2,C2j,2j−1i=1−λ2whereλ1=λ2=1,with a probability1−pc,or λ1 and λ2 are randomly chosen in ]0, 1[, considering a uniform distribution, in other case. Other coefficients ofCiare set to 0. If Npis odd then we also setCNp,Npi=1and then the Np-th row ofXi+1,1is directly copied inXi+1,2.Step 2.3-Mutation: We decide, with a probability pm, if each row ofXi+1,2is randomly perturbed or not. This step is defined byXi+1,3=Xi+1,2+Mi,whereMiis a real-valued (Np, N)-matrix where the jth row,j=1,…,Np,is equal to 0, with a probability 1-pm, or a random vectormj∈RN,generated considering a uniform distribution in the subset of IRNsuch thatxji+1,2+mj∈Ω,otherwise.Step 2.4-Elitism: Letxbi,whereb∈1,…,Np,be the individual in Xiwith the lowest value of h0 (or, if there exists various, one of those individuals selected randomly with a uniform distribution). Ifxbihas a lower h0 value than all the individuals inXi+1,3,it is directly copied at the bth row ofXi+1. This step can be formalized asXi+1=(IN−Ei)(Xi+1,3)+EiXi,where INis the identity matrix of size N andEiis a real-valued (Np, Np)-matrix such thatEi(b,b)=1ifxbihas a lower h0 value than all the individuals inXi+1,3and 0 otherwise,Ei=0elsewhere.Step 3-Output: After Ngiterations or if the stopping criterion associated toϵ∈Ris satisfied for at least one individual inXi+1,the GA stops and returns an output solution denoted byA0(X0)=argmin{h0(xji)/xjiisthej-throwofXi,i=1,…,Ng,j=1,…,Np}.As a fine convergence is generally difficult to achieve with GAs, it is recommended when it is possible, to complete the GA iterations with a descent method (Muyl et al., 2004).The solution of problem (18) may be determined, for instance, by using the algorithms Ai(withi=1,2,…) presented in Section 3.1.1. However, previous studies (see Ivorra, 2006; Ivorra et al., 2006) show that the following variation of Ai(withi=0,1,2,3,…), denoted by Bi, is better suited to the GA case. LetX10={x1,j0∈Ω,j=1,…,Np}and B0(X0)=A0(X0), then, for i > 0,Bi(X10)reads:Step 1-For l from 1 toti∈N:Step 1.1-Setol=Bi−1(Xl0).We constructXl+10={xl+1,j0∈Ω,j=1,…,Np}as following:∀j∈{1,…,Np},ifh0(ol)=h0(xl,j0)setxl+1,j0=xl,j0else setxl+1,j0=projΩ(xl,j0−h0(ol)ol−xl,j0h0(ol)−h0(xl,j0))where projΩ:RN→Ωis a projection operator over Ω defined by the user.Return the output: argmin{hi(om),m=1,…,ti}As previously, the values of i and tidepend on the desired computational complexity.This version of the algorithm intends to improve, individual by individual, the initial population ofBi−1. More precisely, for each individual in the initial population:•If there is a significant evolution of the cost function between this individual and the best element found byBi−1,the secant method used in Step 1.2 generates, in the optimized initial populationXl+10,a new individual close to olthat performs a refined search near the actual solution.Otherwise, the secant method creates a new individual inXl+10far from ol, to expand the exploration of the admissible space.Numerical experiments in Section 4 seem to indicate that considering algorithms Bi, with i > 0, reduces the computational complexity of GAs. In particular, this allows to reduce both parameters Npand Ngin GAs. We will also analyze the application of algorithms Biwith CRS and DE as the COA.In order to check the efficiency of the MLAs presented in Section 3, we consider two sets of benchmark problems. The first set, described in Section 4.1, consists in low dimensional (i.e., dimension lower than 10) problems (Floudas & Pardalos, 1999). The second set, detailed in Section 4.2, focuses on high dimensional problems (with dimension from 50 to 1000) (Li et al., 2013). Our objective is to see how MLAs improve the efficiency of several COAs and to compare them with other metaheuristic methods.We consider the following set of box-constrained benchmark optimization problems: Branin (denoted by Bra), Eason (Eas), Goldstein–Price (G–P), Shubert (Shu), Hartmann with 3 (Hm3) and 6 (Hm6) variables, Rosenbrock with 2 (Rb2), 5 (Rb5) and 10 (Rb10) variables, Shekel with 4 variables andm=5(Sk5), 7 (Sk7)and 10 (Sk10), and Zakharov with 5 (Za5) and 10 (Za10) variables. A complete description of those problems with the considered values of the box restrictions can be found in Floudas and Pardalos (1999). These problems well feature the difficulties of optimization problems and are frequently used to validate optimization algorithms (Hedar & Fukushima, 2006; Hirsch et al., 2010).To solve numerically the problems introduced in Section 4.1.1, we consider the following MLAs:•When the SD is the COA, we use the MLA implementation presented in Section 3.1.1. We apply this method with different number of layers i:i=1(the algorithm is then denoted by SMA1, as SD Multi-Layer Algorithm 1-Layer),i=2(SMA2) andi=3(SMA3). We sett0=10andt1=1000for SMA1;t0=t1=10andt2=1000for SMA2; andt0=t1=t2=10andt3=1000for SMA3. The descent step size ρ is determined using 10 iterations of a dichotomy method starting fromρ0=1(Mohammadi & Saïac, 2003). Those parameters have been determined in Debiane et al. (2006), Ivorra (2006), Ivorra et al. (2006).When the HB is used as the COA, we use the two-layers algorithm A2, described in Sections 3.1.1 and 3.1.2, withη=0.1,t0=t1=10andt2=1000. The velocity xt, 0 is the initial condition to be optimized. x0 is chosen randomly in Ω. This algorithm is denoted by HMA (HB Multi-Layer Algorithm). Those specific parameters have been proposed in Ivorra (2006).With GA as the COA, we use the algorithm B2 introduced in Section 3.2 witht1=10andt2=1000. This algorithm is denoted by GMA (Genetic Multi-Layer Algorithm). The GA parameters are set to:Np=10,Ng=10,pc=0.55,pm=0.5. Those parameters have been considered in Gomez et al. (2011), Ivorra (2006), Ivorra et al. (2013).When the DE described in Storn and Price (1997) is considered as the COA, we use the algorithm B2 introduced in Section 3.2 witht1=10andt2=1000. This algorithm is denoted by DMA (DE Multi-Layer Algorithm). The DE parameters used here are the following: the population size is set to 10, the crossover operator is rand/1/exp, the crossover constant is 0.95, the mutation parameter is 0.9 and the maximum number of iterations is 100. Those parameters have been determined experimentally. The Matlab implementation of the DE can be found here: http://www1.icsi.berkeley.edu/~storn/code.htmlWhen the CRS detailed in Hendrix et al. (2001) is considered as the COA, we use the algorithm B2 introduced in Section 3.2 witht1=10andt2=1000. This algorithm is denoted by CMA (CRS Multi-Layer Algorithm). The CRS parameters used here are the following: the population size is set to 60, the number of trial points is set to the size of the problem, the maximum number of iterations is set to 300 and the rate of success test is 0.55. These parameters have been determined experimentally.Furthermore, at the end of the GMA, CMA and DMA, 10 iterations of the SD used in SMA1 are performed to improve the accuracy of the results.Also, the performances of MLAs are compared with those of other metaheuristic methods available in the literature. We consider algorithms CGR and DTS whose implementation, parameters and results are presented in Hedar and Fukushima (2006) and Hirsch et al. (2010), respectively. We point out that there are other versions of Tabu Search and GRASP that may be superior for the problems tested (for example, particular choices of frequency-based memory have been found to significantly improve Tabu Search in various applications, see Bozkaya, Erkut, and Laporte, 2003 and Glover, 1997, and the hybridization of GRASP with Path Relinking has been found to significantly improve GRASP, see Piana, Plana, Campos, and Martí, 2004 and Resende, Ribeiro, Glover, and Mart, 2010). Furthermore, to see if applying the MLAs allows to improve the performances of the different COAs, we also solve the considered benchmark problems by considering the COAs alone with the following parameters:•The SD and the HB are run starting from a random point in Ω, with the same parameters as in SMA1 and HMA exceptt0=3000.The GA is run with the same stochastic processes as GMA but withNg=1000,Np=180,pc=0.45andpm=0.15. The stopping criterion considered here is explained below. These parameters have been identified in previous works (Ivorra et al., 2006; Ivorra et al., 2014).The DE is run with the crossover operator set to rand/1/exp, the crossover constant set to 0.9, the mutation parameters set to 0.5, the population size set to 5 times the dimension of the benchmark problem and the maximum number of iterations set to 5000. These parameters were suggested in the literature for low dimensional problems (Storn & Price, 1997).The CRS is applied with a population size of 200, the number of trial points set to the size of the problem, the maximum number of iterations set to 3000 and the rate of success test set to 0.55. These choices have been suggested in Hendrix et al. (2001).Again, at the end of the GA, CRS and DR, 10 iterations of the SD used in SMA1 are carried out.Following Hirsch et al. (2010), as the global minimum denoted byh0*,of the different benchmark problems is known, the stopping criterion is defined as(19)|h0*−h0˜|≤ϵ1|h0*|+ϵ2,whereh0˜is the current solution of the algorithm,ϵ1=10−4andϵ2=10−6. The DE, DMA, CRS , CMA, GA and GMA are run withϵ1=10−2andϵ2=10−3and the SD performed at the end of those algorithms is executed withϵ1=10−4andϵ2=10−6.In addition to this stopping criterion we have limited the maximum number of functional evaluations to 50,000 for each run (which can be considered as a high number, see Gomez et al., 2011; Ivorra et al., 2014; Ivorra et al., 2013; Muyl et al., 2004). If at the end of the algorithm, (19) is not satisfied, we consider that the algorithm has failed to solve numerically the considered problem.As specified in Section 3, we recall that the MLAs presented previously are adapted to non-negative functions (or with a known lower bound value). So, the benchmark functions h0 with negative values have been modified adding a real numberCh0large enough to obtain a non-negative function. Here, in order to obtain a stopping criterion (19) comparable to the one used in Hedar and Fukushima (2006); Hirsch et al. (2010), we have consideredCh0=2|h0*|.Due to the stochastic aspect of the algorithms, each benchmark problem has been solved 100 times with each of the optimization algorithm. We define the success rate of an optimization algorithm by the percentage of runs satisfying the stopping criterion (19).In order to check the improvement of the MLA with respect to the COA alone, we have also computed the following improvement threshold (in %), denoted by Imp and given by:(20)Imp(AaMLA)=100×Tev(AaCOA)-Tev(AaMLA)Tev(AaCOA),where Tev(A) is the total number of evaluations required by the algorithm A to solve all the benchmark problems (including runs that have failed to satisfy the stopping criterion (19)) and COA is the core optimization algorithm of MLA. Imp represents the computational effort reduction obtained when using the MLA instead of the COA.All experiments have been performed on a Pentium I7 Quad-Core with 3.6 Ghz and 32Gb of RAM and the algorithms have been implemented in a Matlab 2014 script.Remark 3The MLAs performs better if the minimum valueh0*=0(see Section 3.1.1). So, whenh0*is known (e.g., as said previously, in some inverse problems (Ivorra et al., 2014)), we can minimizeh0−h0*instead of h0 (Ivorra, 2006; Ivorra et al., 2014). However, in industrial applications, this information is generally not available (Carrasco, Ivorra, & Ramos, 2015; Debiane et al., 2006; Gomez et al., 2011; Ivorra et al., 2009; Ivorra et al., 2007; Muyl et al., 2004). Thus, we have decided not to use it. Furthermore, we deduce from the results presented in Section 4.1.3 that this hypothesis is not mandatory as our methodology is efficient also in cases whenh0*is unknown.The multi-layers linear search method was also applied alone to solve the considered benchmark problems. To do so, we consideredA0(x0)=x0,and the 3-layers structure A3 witht0=t1=t2=10andt3=10,000. However, this algorithm exhibited a success rate of 0% in all benchmark problems. Thus, the precision of this algorithm seems to be extremely low and the obtained results are not reported in the next Section 4.1.3. This indicates that the use of a COA is necessary to generate an efficient MLA.

@&#CONCLUSIONS@&#
A new multi-layer line search method, denoted by MLA, has been developed. This metaheuristic algorithm solves a sub-optimization problem in order to improve the initialization of existing optimization procedures considered as core optimization algorithm (COA). A particular implementation of the approach, well suited for minimizing non-negative functions, has been presented and coupled with various COAs: Steepest Descent, Heavy-Ball, Genetic, Differential Evolution and Controlled Random Search algorithms. The MLAs have been validated on various benchmark problems from low (with dimension less than 10) to high (with dimension up to 1000) dimensional cases. The numerical results seem to indicate that our methodology improves the performances of the COAs. The general conclusion is that MLAs with COAs given by gradient descent algorithms (SMA2 and SMA3) and evolutionary algorithms (GMA, CMA and DMA) should be preferred. These latter are good alternatives to other metaheuristic algorithms such as DTS, DE, CRS and CGR.Our current effort is on parallel MLAs (Gomez et al., 2011).A Matlab version of some of the algorithms presented in this paper has been implemented in the free optimization package “Global Optimization Platform”, which can be downloaded at http://www.mat.ucm.es/momat/software.htm