@&#MAIN-TITLE@&#
Static search games played over graphs and general metric spaces

@&#HIGHLIGHTS@&#
A general game is defined to model search in regions with spatial structure.Propositions relating to strategic dominance in the game are presented and proved.Several methods are presented to simplify such games played on graphs.Analytic solutions of the game are presented for a particular family of graphs.

@&#KEYPHRASES@&#
Game theory,Search games,Networks,Graph theory,Metric spaces,

@&#ABSTRACT@&#
We define a general game which forms a basis for modelling situations of static search and concealment over regions with spatial structure. The game involves two players, the searching player and the concealing player, and is played over a metric space. Each player simultaneously chooses to deploy at a point in the space; the searching player receiving a payoff of 1 if his opponent lies within a predetermined radius r of his position, the concealing player receiving a payoff of 1 otherwise. The concepts of dominance and equivalence of strategies are examined in the context of this game, before focusing on the more specific case of the game played over a graph. Methods are presented to simplify the analysis of such games, both by means of the iterated elimination of dominated strategies and through consideration of automorphisms of the graph. Lower and upper bounds on the value of the game are presented and optimal mixed strategies are calculated for games played over a particular family of graphs.

@&#INTRODUCTION@&#
In this paper, we define a general search and concealment game that takes full account of the spatial structure of the set over which it is played. The game is static in the sense that players do not move, but deploy simultaneously at particular spatial points and receive payoffs based on their relative positions. In this way, the static spatial search game (SSSG) provides a theoretical foundation for the study of the relative strategic value of different positions in a geography. Using the theory of metric spaces, we model situations in which the searching player may simultaneously search multiple locations based on concepts of distance or adjacency relative to the point at which they are deployed.While the SSSG does build upon previous work, particularly that of Ruckle (1983) and White (1994), its simplicity and generality together with its explicit consideration of spatial structure set it apart from much of the literature (see Section 3 for a detailed review of related work) and lend it the versatility to describe games over a huge variety of different spaces. The primary contributions of this article are therefore to both propose a highly general model of spatial search and concealment situations, which unites several other games presented in the literature (see Section 4.2), and to present new propositions and approaches for the strategic analysis of such scenarios.While this paper is theoretical in nature, the SSSG provides a framework for the analysis of a diverse range of operational research questions. Aside from explicit search and concealment scenarios, the game may be used to model situations in which some structure or region must be protected against ‘attacks’ that could arise at any spatial point; for example, the deployment of security personnel to protect cities against terrorist attacks or outbreaks of rioting, security software scanning computer networks to eliminate threats, the defence of shipping lanes against piracy, the protection of a rail network against cable theft or the deployment of stewards at public events to respond to emergency situations.We provide a brief overview of all necessary game theoretic concepts in Section 2 and a review of the literature on games of search and security in Section 3, before formally defining the SSSG, examining its relationship to other games in the literature and presenting some initial propositions in Section 4. In Section 5, we examine the SSSG on a graph and identify upper and lower bounds on the value of such games before presenting an algorithm in Section 6 which simplifies graph games by means of the iterated elimination of dominated strategies, focusing particularly on the application of the algorithm to games played on trees. Section 7 contains further results, including a way to simplify graph games through consideration of graph automorphisms and an examination of a particular type of strategy for such games, which we describe as an “equal oddments strategy”. In Section 8, we use the concept of an equal oddments strategy to find analytic solutions for a particular family of graph games, while Section 9 forms a conclusion to the paper, containing a summary of our key results and suggestions of potential avenues for further research. Two proofs, which were too complicated to include in the main text, are presented as appendices.The definitions and notation relating to game theory used in this section are adapted from Blackwell and Girshick (1954) and Morris (1994).When discussing two-player games, we assume the following definition:Definition 2.1Two-player games in normal formA game in normal form between Players A and B, consists of:•strategy setsΣA,ΣBpayoff functionspA,pB, with:pA:ΣA×ΣB→RpB:ΣA×ΣB→RThe game is played by Players A and B simultaneously choosing strategies (described as pure strategies in cases where there may be any ambiguity) from their respective strategy setsx∈ΣA,y∈ΣBand receiving payoffspA(x,y),pB(x,y). The objective of each player is to maximise their payoff.In certain circumstances, we may allow players to adopt mixed strategies, whereby they choose their pure strategy according to a specified probability distribution. IfΣAandΣBare finite, with:ΣA={x1,…,xκA}ΣB={y1,…,yκB}for some positive integersκA,κB, then the mixed strategiesσA,σBcan simultaneously be regarded as vectors:σA=(σA[x1],…,σA[xκA])∈[0,1]κAσB=(σB[y1],…,σB[yκB])∈[0,1]κBand as functions, which allocate probabilities to pure strategies:σA:ΣA→[0,1]x↦σA[x]σB:ΣB→[0,1]y↦σB[y]∑x∈ΣAσA[x]=∑y∈ΣBσB[y]=1The following definitions relate to the maximum expected payoff that players can guarantee themselves through careful choice of their mixed strategies:Definition 2.2Values of the gameGiven a two-player game, the values of the gameuA,uBto Players A and B respectively, are defined as:•uA=maxτAminτBE[pA(τA,τB)]uB=maxτBminτAE[pB(τA,τB)]Optimal mixed strategiesGiven a two-player constant-sum game, where the payoffs sum toc∈R, mixed strategiesσA,σBfor Players A and B are described as optimal if and only if:•minτBE[pA(σA,τB)]=uAminτAE[pB(τA,σB)]=uBFor a constant-sum game, where the payoffs sum toc∈R, we have:(1)uA+uB=cAlso, provided thatΣAandΣBare finite, optimal mixed strategies are guaranteed to exist for both players.Both of these facts are consequences of the Minimax Theorem (see Morris, 1994, p. 102).Given a constant-sum two-player game with finite strategy sets, a solution of the game comprises optimal mixed strategiesΣA,ΣBand valuesuA,uBfor each Player.The following definition allows for a crude comparison of the efficacy of different strategies.Definition 2.4Strategic dominance and equivalenceConsider a two-player game with strategy setsΣA,ΣBand payoff functionspA,pB. Given particular pure strategiesx1,x2∈ΣAfor Player A, we have:•x2very weakly dominatesx1if and only if:pA(x2,y)⩾pA(x1,y),∀y∈ΣBx2weakly dominatesx1if and only if:pA(x2,y)⩾pA(x1,y),∀y∈ΣBand∃y∗∈ΣBsuch that:pA(x2,y∗)>pA(x1,y∗)x2strictly dominatesx1if and only if:pA(x2,y)>pA(x1,y),∀y∈ΣBx2is equivalent tox1if and only if:pA(x2,y)=pA(x1,y),∀y∈ΣBSince the designation of the players as A and B is arbitrary, obtaining corresponding definitions of strategic dominance and equivalence for Player B is simply a matter of relabelling.Note that weak dominance, strict dominance and equivalence are all special cases of very weak dominance. Also, strict dominance is a special case of weak dominance.In this paper, weak dominance is of most relevance. Therefore, for reasons of clarity, the terms “dominance” and “dominated strategies” will be used to refer to weak dominance unless otherwise stated.Since a player aims to maximise his or her payoff, we would intuitively expect that they should not play any dominated strategies.For a general definition of dominance in game theory, see Leyton-Brown and Shoham (2008, pp. 20–23), from which the above definition was adapted.Games of search and concealment, in which one player attempts to hide themselves or to conceal some substance in a specified space while another player attempts to locate or capture the player or substance, have been widely studied.One of the simplest search games is the well-known high-low number guessing game in which one player chooses an integer in a given range, while the other player makes a sequence of guesses to identify it, each time being informed whether the guess was too high or too low (Gal, 1974). Continuous versions of the game have also been studied (Gal, 1978; Baston et al., 1985; Alpern, 1985a).Another simple search game involves one player attempting to locate an object that the opposing player has hidden at a location chosen from a finite or countably infinite set with no spatial structure (except a possible ordering). Variants of these games include examples where the searching player has some chance of overlooking the object despite searching the correct location (Neuts, 1963; Subelman, 1981) or where the searcher must also avoid the location of a second hidden object (Ruckle, 1990).A more complicated class of search games is that in which the searching player is mobile and their target is immobile, with payoffs to each player typically (though not universally) being dependent on the amount of time that elapses before the target is located. Such games have been examined over many different types of graph (Anderson et al., 1990; Alpern, 2008, 2010; Buyang, 1995; Reijnierse & Potters, 1993; Kikuta et al., 1994; Kikuta, 2004; Pavlović, 1995), though in general the space may be a continuous region (Gal, 1979). While the starting position of the searching player is often fixed, games in which the searching player can choose their position have also been studied (Alpern, Baston, & Gal, 2008a; Dagan et al., 2008), as have games with multiple searchers (Alpern & Howard, 2000; Peshkin, 1994).Accumulation games are an extension of this concept in which there may be many hidden objects (Kikuta et al., 1997) or in which hidden objects are replaced with some continuous material that the hiding player can distribute across a set of discrete locations (Kikuta et al., 2002; Zoroa, Fernández-Sáez, & Zoroa, 2004) or across a continuous space (Ruckle et al., 2000). The payoffs in these games are typically dependent on the number of objects or the quantity of material that the searching player is able to locate.Adding a further layer of complication, there is the class of search game in which both the searching player and the hiding player are mobile, including so-called “princess and monster” games. Again, the payoffs in such games are typically dependent on the amount of time that elapses before the hiding player is captured and players are typically ‘invisible’ to each other, only becoming aware of the location of their opponent at the moment of capture.Such games have been considered over continuous one-dimensional spaces such as the circle (Alpern, 1974) and the unit interval (Alpern, Fokkink, Lindelauf, & Olsder, 2008b), over continuous graphs or networks (Alpern et al., 1986; Anderson et al., 1992; Alpern, 1985b) and over continuous two-dimensional spaces (Foreman, 1977; Garnaev, 1991; Chkhartishvili et al., 1995). In the latter case, it is necessary to introduce the concept of a detection radius, with a capture occurring if the distance between the players drops below this value. In some cases, the probability of capture is allowed to vary based on the distance between the players (Garnaev, 1992).Analyses of search games over discrete spaces in which both searcher and hider are mobile have tended to consider spatial structure in only a very limited way. While this structure may determine the freedom of movement of the players, very little work has been done to introduce an analogous concept to the detection radius to such games. Generally, players move sequentially and may only move to locations that are sufficiently close to their current position (e.g. Eagle et al., 1991), though variants have been considered in which either the searching player (Zoroa, Fernández-Sáez, & Zoroa, 2012) or the hiding player (Thomas et al., 1991) has the freedom to move to any location regardless of adjacency or distance.Further variations on the search game with mobile searcher and hider include games in which the searching player follows a pre-determined path and must decide how thoroughly to search each location visited (Hohzaki et al., 2000), games in which the searching player must intercept an opponent attempting to move from a given start point to a given end point (Alpern, 1992) and games with a variegated environment and the possibility that the hiding player will be betrayed by ‘citizens’ of the space (Owen et al., 2008). Such games have also been used to model predator–prey interactions (Alpern, Fokkink, Timmer, & Casas, 2011a).Allocation games are a related concept, in which the searching player does not move around the space individually, but rather distributes ‘search resources’ to locate the mobile hiding player. Such games may include false information (Hohzaki, 2007) and may incorporate spatial structure by allowing the influence of resources to spread across space (“reachability”), an area which has seen “little research” (Hohzaki, 2008).Variations on this idea include situations in which searching resources are deployed sequentially (Dendris, Kirousis, & Thilikos, 1997) or in which both players distribute resources to respectively locate or protect a hidden object (Baston et al., 2000). Cooperative allocation games, in which multiple players combine their searching resources to locate a moving target, have also been considered (Hohzaki, 2009).Rendez-vous games are a parallel concept to games with mobile searching and hiding players, the difference being that these games are cooperative, with both players wishing to locate the other as soon as possible (see Alpern, 2002, for an overview). Typically, in a rendez-vous game, the structure of the space is known to all, with consideration given to the amount of information available to players regarding their relative positions, and their ability to distinguish between symmetries of the space (whether they have a common understanding of “North”, for example).Rendez-vous games have been studied over various continuous one-dimensional spaces, such as the line (Alpern et al., 1995; Lim et al., 1996; Alpern et al., 2000) and the circle (Alpern, 2000), over continuous two-dimensional spaces, such as the plane (Kikuta et al., 2010) or a general compact metric space (Alpern, 1995) and over discrete spaces, such as lattices (Alpern et al., 2005; Ruckle, 2007) and other graphs (Alpern, Baston, & Essegaier, 1999). Costs may also be introduced for movement and examination of particular locations (Kikuta et al., 2007).Work has also been done on ‘hybrid’ games of search and rendez-vous, where, for example, two agents attempt to meet without being located by a third (Alpern et al., 1998) or where the seaching player does not know whether the other player is attempting to rendez-vous or to evade capture (Alpern et al., 2002).Security games are used to model situations in which some public resource (e.g. airports, transport infrastructure, power facilities) must be protected from attack with limited defensive resources. A good introduction to the topic is provided by Tambe (2012).Such situations tend to be modelled as Stackelberg games, where it is assumed that the defensive player first commits to some strategy to protect the vulnerable sites and that this strategy is observed by the attacking player, who then chooses an optimal response (Tambe, 2012, pp. 4–8). Stackelberg-type security games related to the mobile-searcher-immobile-hider games of Section 3.2 have also been proposed to examine optimal patrolling strategies (Alpern, Morton, & Papadaki, 2011b; Basilico, Gatti, & Amigoni, 2012).A related concept is that of the much studied Colonel Blotto game, in which two players must simultaneously distribute a fixed quantity of discrete or continuous resources across a number of sites, each site being ‘won’ by the player who distributed the greater quantity of resources to it, with payoffs determined by the number of sites that each player wins (see Roberson, 2006). The many extensions of the Blotto game have included asymmetric versions (Tofias, Merolla, & Munger, 2007; Hortala-Vallve & Llorente-Saguer, 2012), examples in which resources are allocated to battlefields sequentially rather than simultaneously (Powell, 2009) and examples in which defensive resources are heterogenous (Cohen, 1966).Though the deployment sites in such models are often assumed to be wholly separate, with events at one location having no effect on events at other locations, certain security games and Blotto games with strategically interdependent sites have been considered. For example, Shubik and Weber (1981) introduce the concept of a “characteristic function” for such games, which allocates values to subsets of the sites, thus allowing interdependencies between them to be captured. Other approaches to modelling such interdependence include an extension of the Colonel Blotto game in which a successful attack on a “radar site” ensures the success of attacks on other sites (Grometstein & Shoham, 1989), while Hausken (2010, 2011) discusses a classification of the underlying infrastructures of security games based on the interdependence of their sites (e.g. series, parallel, complex, …) and Powell (2007) analyses the relative value of defending borders over protecting strategic targets directly.Though analyses of interdependence in security games and Blotto games may be quite general (that of Shubik & Weber, 1981, for example), interdependence that arises explicitly from the spatial structure of the deployment sites has not been considered in a general setting.One of the most general and theoretical analyses of search and concealment type situations is Geometric games and their applications (Ruckle, 1983). In this book, the author defines a geometric game as a two-player zero-sum game (with players called “RED” and “BLUE”) played over a given set S, where the strategy sets for each playerΣRED,ΣBLUEare subsets of the power setP(S)(the set of all subsets of S). Pure strategies for each player are therefore subsetsR,B⊆S. The payoff to each player is a function of R and B, typically depending directly on the intersectionR∩B.This concept of a geometric game allows Ruckle to model a wide variety of situations of search, ambush and pursuit, as well as a range of abstract games, taking full consideration of the structure of the space S over which the games are played.Most published work based on Ruckle’s ideas (e.g. Baston, Bostock, & Ferguson, 1989; Zoroa et al., 1993; Zoroa, Fernández-Sáez, & Zoroa, 1999; Zoroa, Zoroa, & Fernández-Sáez, 1999, 2001, 2003; Alpern, Baston, & Gal, 2009, 2010) has focused on specific examples of geometric games, rather than on general results.Much of the literature on search games and related concepts has focussed on analysing specific games, rather than attempting to present general frameworks for such situations and identifying more broadly applicable results. While spatial structure may be considered for games in which players are mobile, the geography of the space over which games are played is often given little or limited consideration, particularly in the literature on security games. The concept of “reachability”, as described by Hohzaki (2008), in which a searcher or searching resource deployed at a point has influence over a neighbourhood of that point, has received very little attention. Games which concentrate purely on the strategic value of a player’s chosen position in a space, rather than on strategies for moving through the space for the purposes of search or rendez-vous, have also seen little research, at least since the work of Ruckle (1983).The definitions and notation relating to metric spaces used in this section are from Sutherland (1975, pp. 19–44).The static spatial search game (SSSG) is a two-player game played over a metric spaceM=(Ω,d), where Ω is a set of points x andd:Ω×Ω→[0,∞)is the metric or distance, which has the standard properties:(M1)d(x,y)⩾0;d(x,y)=0⇔x=y(M2)d(x,y)=d(y,x),∀x,y∈Ω(M3)d(x,y)+d(y,z)⩾d(x,z),∀x,y,z∈ΩThe metric d reflects the spatial structure of Ω. InRn,dmay be the Euclidean distance, while in a graph d may be the length of the shortest path connecting two points. However, depending on the interpretation of the game, d could also represent an abstract distance, indicating dissimilarity, difficulty of communication or perceived costs.In specific cases, it may be sensible to relax some of these conditions. For example, in a graph that is not connected, we could allow infinite distances between vertices that are not connected by a path (an extended metric). Alternatively, to represent a directed graph, we may wish to ignore the symmetry condition (M2) (a quasi-metric; see Steen & Seebach (1970)). However, for the sake of simplicity, we do not consider such cases at this time.We define a non-negative real number r called the detection radius and use the notationBr[x]to designate the closed ball centred on x:Br[x]=y∈Ω:d(x,y)⩽rThe strategies for Player A (the searching player) and Player B (the concealing player) are specific points of Ω at which they may choose to deploy. In a single play of the game, each player simultaneously picks a pointxA,xBfrom their own strategy set,ΣA,ΣB⊆Ω.For the sake of clarity, we use masculine pronouns to refer to Player A and feminine pronouns to refer to Player B throughout this paper.We define the payoff functions for Player A and Player B respectively as:pA(xA,xB)=1,xB∈Br[xA]0,otherwisepB(xA,xB)=1-pA(xA,xB)This is a constant-sum game and can be analysed accordingly.In interpreting the game, we imagine that Player B chooses to hide somewhere in Ω, while Player A attempts to locate his opponent. To do this, Player A selects a point of Ω and searches a neighbourhood of this point. If Player B’s hiding place falls within the detection radius of Player A’s chosen point, the attempt to hide is unsuccessful and Player B is located. Otherwise, Player B remains undetected.The game is illustrated in Fig. 1.The SSSG is not strictly a geometric game by Ruckle’s definition (1983, p. 2), since it is not zero-sum. However, it could be transformed into a zero-sum game without altering the subsequent analysis, simply by subtracting12from all payoffs. The decision that all payoffs should be 0 or 1 has been taken to ensure the clarity of the payoff matrices considered later in this paper.Given this proviso, certain of Ruckle (1983)’s geometric games can be formulated as particular cases of the SSSG. For example, if transformed to a zero-sum game as described, game AAGV (Ruckle, 1983, p. 86; adapted from Arnold (1962)) is an example of the SSSG, withΩ=[0,1]⊂R,ΣA=ΣB=Ωandd(x,y)=|x-y|.Similarly, White (1994)’s Games of strategy on trees are examples of the SSSG, where Ω is the set of vertices of a tree,ΣA=ΣB=Ω,r=1and d is the length of the shortest path between two vertices.A game that demonstrates the potential complexity that can arise from apparently simple cases of the SSSG is the “Cookie-Cutter” game (or the “Hiding in a Disc” game), in which Player A chooses a point in a disc of unit radius and Player B simultaneously places a circular ‘cookie-cutter’ centred at any point of the disc, winning the game if Player A’s point lies within the ‘cookie-cutter’. Given appropriate payoffs, this game is an example of the SSSG, where Ω is the closed unit disc,ΣA=ΣB=Ωandd(x,y)=|x-y|.The particular case of this game withr=1/2was originally proposed by Gale et al. (1974), for which optimal mixed strategies were presented by Evans (1975). The game was extended to allr>0by Bordelon (1975), who proposed optimal mixed strategies for allr>1/2, but these results were disputed by Ruckle (1983, p. 108). Ruckle’s disproof was disputed in turn by Danskin (1990), who showed that Bordelon (1975)’s results were correct for some values ofr>1/2, though false in general. Despite the apparent simplicity of the problem, Danskin (1990) was only able to find optimal mixed strategies for a small range of values of r aroundr=1/2and for allr⩾2/2, thus illustrating the hidden complexity of many games of this form.A particularly simple example of a game that can be represented as an SSSG is “Matching Pennies” (see Blackwell & Girshick, 1954, p. 13), in which Players A and B simultaneously call “Heads” or “Tails”, with Player A receiving a payoff of 1 if the calls are the same and −1 otherwise, and Player B receiving a payoff of −1 if the calls are the same and 1 otherwise. TakingΣA=ΣB=Ω={“Heads”,“Tails”},r=0, with d as any valid metric, this is an SSSG, again with the proviso that the payoffs must be transformed appropriately.A more complicated example of a game that can be represented as an SSSG is the graph security game of Mavronicolas, Papadopoulou, Philippou, and Spirakis (2008) if the number of attackers is restricted to one. This game is played over an undirected graphG=(V(G),E(G))with one defender and (in general) multiple attackers. Simultaneously, the defender chooses an edge and the attackers each choose a vertex. The defender receives a payoff equal to the number of attackers who choose vertices incident to his chosen edge. Each attacker receives a payoff equal to 0 if their chosen vertex is incident to the defender’s edge and 1 otherwise.Consider the graphG′obtained by inserting a new vertex at the midpoint of each of the edges of G. Let the set of new vertices created in this way be denotedV(G′)∗while the complete vertex setV(G′)includes both the new vertices and the original vertices. With the defender as Player A, a single attacker as PlayerB,Ω=V(G′),ΣA=V(G′)∗,ΣB=V(G),r=1and with d as the length of the shortest path between two vertices inG′, this game is also an example of the SSSG.The SSSG provides a framework that unites all of these games and allows for a general consideration of the relative strategic values of the different points of a space. It implicitly encompasses the concepts of reachability, interdependence based on spatial structure and the detection radius, as discussed in Section 3.Consider an example of the SSSG in which the strategy setsΣA,ΣBare finite. One of the simplest possible mixed strategies available to each player in such a case is the mixed strategy that allocates equal probabilities to all points in a player’s strategy set. We denote these mixed strategies byρAandρBfor Players A and B respectively.The following proposition establishes a sufficient condition forρA,ρBto be optimal mixed strategies:Proposition 4.1Consider the SSSG played over a metric space Ω, with finite strategy setsΣA,ΣBand distance d. If there exists a positive integer ζ such that:(2)|Br[xA]∩ΣB|=ζ,∀xA∈ΣA|Br[xB]∩ΣA|=ζ,∀xB∈ΣBthenρAandρBare optimal mixed strategies for Players A and B respectively andζ|ΣA|-1=ζ|ΣB|-1=uis the value of the game to Player A.Suppose that Player A employs the mixed strategyρAwhich allocates a uniform probability of|ΣA|-1to all pointsxA∈ΣA. In a particular play of the game, suppose that Player B deploys at pointxB∈ΣB.In this situation, since|Br[xB]∩ΣA|=ζ, the expected payoff to Player A isζ|ΣA|-1, the probability that Player A’s pointxAlies inBr[xB]. Therefore, for any mixed strategyσBfor Player B:E[pA(ρA,σB)]=ζ|ΣA|-1and thus:(3)u=maxσAminσBEpA(σA,σB)⩾ζ|ΣA|-1Now suppose that Player B employs the mixed strategyρBwhich allocates a uniform probability of|ΣB|-1to all pointsxB∈ΣB. In a particular play of the game, suppose that Player A deploys at pointxA∈ΣA.In this situation, since|Br[xA]∩ΣB|=ζ, the expected payoff to Player A isζ|ΣB|-1, the probability that Player B’s pointxBlies inBr[xA]. Therefore, for any mixed strategyσAfor Player A:E[pA(σA,ρB)]=ζ|ΣB|-1and thus:(4)u=maxσAminσBEpA(σA,σB)⩽ζ|ΣB|-1Now, (2) together with the symmetric property of the distance (M2) imply thatζ|ΣA|=ζ|ΣB|and thus that|ΣA|=|ΣB|. By (3) and (4), we therefore have:|ΣA|-1⩽u⩽|ΣB|-1⇒u=|ΣA|-1=|ΣB|-1andρA,ρBare optimal mixed strategies, by Definition 2.3.□We can now examine strategic dominance and equivalence (see Definition 2.4) in the context of the SSSG using the notation established in Section 4.Proposition 4.2Consider the SSSG played over a metric space Ω, with strategy setsΣA,ΣBand distance d. For strategiesx1,x2∈ΣA,x1≠x2, for Player A:•x2very weakly dominatesx1if and only if:(Br[x1]∩ΣB)⊆(Br[x2]∩ΣB)x2weakly dominatesx1if and only if:(Br[x1]∩ΣB)⊂(Br[x2]∩ΣB)x2strictly dominatesx1if and only if:(Br[x1]∩ΣB)=∅(Br[x2]∩ΣB)=ΣBx2isequivalenttox1if and only if:(Br[x1]∩ΣB)=(Br[x2]∩ΣB)This proposition states that for Player A:•x2very weakly dominatesx1if and only if, when deployed atx2, Player A can search every potential location of Player B that could be searched fromx1.This dominance is weak if there exist potential locations of Player B that can be searched fromx2but that cannot be searched fromx1(inclusion is strict).Strict dominance only occurs in the trivial case in which no potential locations of Player B can be searched fromx1while every potential location of Player B can be searched fromx2.x2andx1are equivalent if and only if precisely the same set of potential locations of Player B can be searched from both points.We consider each of the four parts of Definition 2.4 and show that, in the context of the SSSG, they are equivalent to the corresponding statements of Proposition 4.2. Recall thatpAtakes values in{0,1}.•Very weak dominancepA(x2,y)⩾pA(x1,y),∀y∈ΣB(∗)⇔[pA(x1,y)=1⇒pA(x2,y)=1],∀y∈ΣB⇔[y∈Br[x1]⇒y∈Br[x2]],∀y∈ΣB⇔(Br[x1]∩ΣB)⊆(Br[x2]∩ΣB)(∗∗)Weak dominanceSince(∗)⇔(∗∗), it suffices to observe that, if(∗∗)is assumed to be true:∃y∗∈ΣB:pA(x2,y∗)>pA(x1,y∗)⇔∃y∗∈ΣB:y∗∈Br[x2]andy∗∉Br[x1]⇔(Br[x1]∩ΣB)⊂(Br[x2]∩ΣB)[by(∗∗)]Strict dominancepA(x2,y)>pA(x1,y),∀y∈ΣB⇔y∈Br[x2]andy∉Br[x1],∀y∈ΣB⇔(Br[x1]∩ΣB)=∅,(Br[x2]∩ΣB)=ΣBEquivalencepA(x2,y)=pA(x1,y),∀y∈ΣB⇔[y∈Br[x2]⇔y∈Br[x1]],∀y∈ΣB⇔(Br[x2]∩ΣB)=(Br[x1]∩ΣB)□We now consider dominance and equivalence for Player B:Proposition 4.3Consider the SSSG played over a metric space Ω, with strategy setsΣA,ΣBand distance d. For strategiesx1,x2∈ΣB,x1≠x2, for Player B:•x2very weakly dominatesx1if and only if:[x2∈Br[y]⇒x1∈Br[y]],∀y∈ΣAx2weakly dominatesx1if and only if:[x2∈Br[y]⇒x1∈Br[y]],∀y∈ΣAand∃y∗∈ΣAsuch that:x1∈Br[y∗]andx2∉Br[y∗]x2strictly dominatesx1if and only if:x1∈Br[y]andx2∉Br[y],∀y∈ΣAx2isequivalenttox1if and only if:[x2∈Br[y]⇔x1∈Br[y]],∀y∈ΣAThis proposition states that for Player B:•x2very weakly dominatesx1if and only if, wherever Player A deploys, if he can searchx2then he can also searchx1.This dominance is weak if there exists a position for Player A from which he can searchx1but cannot searchx2.Strict dominance only occurs in the trivial case in which, wherever Player A deploys, he can searchx1but cannot searchx2.x2andx1are equivalent if and only if, wherever Player A deploys, he can searchx2if and only if he can searchx1.We consider each of the four parts of Definition 2.4 and show that, in the context of the SSSG, they are equivalent to the corresponding statements of Proposition 4.3. Recall thatpBalso takes values in{0,1}.•Very weak dominancepB(y,x2)⩾pB(y,x1),∀y∈ΣA(∗)⇔[pB(y,x1)=1⇒pB(y,x2)=1],∀y∈ΣA⇔[x1∉Br[y]⇒x2∉Br[y]],∀y∈ΣA⇔[x2∈Br[y]⇒x1∈Br[y]],∀y∈ΣA(∗∗)Weak dominanceSince(∗)⇔(∗∗), it suffices to observe that:∃y∗∈ΣA:pB(y∗,x2)>pB(y∗,x1)⇔∃y∗∈ΣA:x1∈Br[y∗]andx2∉Br[y∗]Strict dominancepB(y,x2)>pB(y,x1),∀y∈ΣA⇔x1∈Br[y]andx2∉Br[y],∀y∈ΣAEquivalencepB(y,x2)=pB(y,x1),∀y∈ΣA⇔[x2∈Br[y]⇔x1∈Br[y]],∀y∈ΣA□The necessary and sufficient conditions for dominance and equivalence for Player B established in Proposition 4.3 can be shown to be equivalent to a simpler set of conditions, clearly analogous to those relating to dominance and equivalence for Player A seen in Proposition 4.2:Proposition 4.4Consider the SSSG played over a metric space Ω, with strategy setsΣA,ΣBand distance d. For strategiesx1,x2∈ΣB,x1≠x2, for Player B:•x2very weakly dominatesx1if and only if:(Br[x2]∩ΣA)⊆(Br[x1]∩ΣA)x2weakly dominatesx1if and only if:(Br[x2]∩ΣA)⊂(Br[x1]∩ΣA)x2strictly dominatesx1if and only if:(Br[x1]∩ΣA)=ΣA(Br[x2]∩ΣA)=∅x2isequivalenttox1if and only if:(Br[x2]∩ΣA)=(Br[x1]∩ΣA)We consider each of the four statements of Proposition 4.3 (which has already been proven) and show that they are equivalent to the corresponding statements of Proposition 4.4.•Very weak dominance[x2∈Br[y]⇒x1∈Br[y]],∀y∈ΣA(∗)⇔[y∈Br[x2]⇒y∈Br[x1]],∀y∈ΣA[by(M2)]⇔(Br[x2]∩ΣA)⊆(Br[x1]∩ΣA)(∗∗)Weak dominanceSince(∗)⇔(∗∗), it suffices to observe that, if(∗∗)is assumed to be true:∃z∈ΣA:x1∈Br[z]andx2∉Br[z]⇔∃z∈ΣA:z∈Br[x1]andz∉Br[x2][by(M2)]⇔(Br[x2]∩ΣA)⊂(Br[x1]∩ΣA)[by(∗∗)]Strict dominancex1∈Br[y]andx2∉Br[y],∀y∈ΣA⇔y∈Br[x1]andy∉Br[x2],∀y∈ΣA[by(M2)]⇔(Br[x1]∩ΣA)=ΣA,(Br[x2]∩ΣA)=∅Equivalence[x2∈Br[y]⇔x1∈Br[y]],∀y∈ΣA⇔[y∈Br[x2]⇔y∈Br[x1]],∀y∈ΣA[by(M2)]⇔(Br[x2]∩ΣA)=(Br[x1]∩ΣA)□While Proposition 4.4 is apparently simpler than Proposition 4.3, note that every part of its proof depends on the symmetric property of the distance (M2). If this condition were to be relaxed, as discussed in Section 4.1, Proposition 4.4 would not be valid and dominance and equivalence for Player B would have to be analysed on the basis of Proposition 4.3.Definition 4.1Pairwise EquivalenceConsider the SSSG played over a metric space Ω, with strategy setsΣA,ΣBand distance d. For Player A or Player B, a subset of their strategy setΣˆ⊆ΣAorΣˆ⊆ΣBexhibits pairwise equivalence if and only if x is equivalent toy,∀x,y∈Σˆ.We conclude that a subsetΣˆ⊆ΣAorΣˆ⊆ΣBexhibiting pairwise equivalence can be reduced to any singleton{xˆ}⊆Σˆwithout altering the analysis of the game. Since all points inΣˆare equivalent, a player would neither gain nor lose by playing another point in the set overxˆ.The following proposition states that ifx2very weakly dominatesx1for Player A (andx1is adjacent to at least one potential location for Player B), then the distance between the two points must be no greater than2r.Proposition 4.5For the SSSG played over a metric space Ω, with strategy setsΣA,ΣBand distance d, ifx2very weakly dominatesx1for Player A andBr[x1]∩ΣB≠∅, thenx2∈B2r[x1]∩ΣA.Ifx2very weakly dominatesx1for Player A andBr[x1]∩ΣB≠∅, then:∅≠(Br[x1]∩ΣB)⊆(Br[x2]∩ΣB)[by4.2]⇒∃y∈Br[x1]∩Br[x2]⇒d(x1,y)⩽randd(x2,y)⩽r⇒d(x1,x2)⩽2r[by(M2),(M3)]⇒x2∈B2r[x1]∩ΣA□The condition thatBr[x1]∩ΣB≠∅simply removes trivial strategies that are very weakly dominated by every other strategy.An analogous result holds for Player B. The proof is similar to that of 4.5 and is therefore omitted:Proposition 4.6For the SSSG played over a metric space Ω, with strategy setsΣA,ΣBand distance d, ifx2very weakly dominatesx1for Player B andBr[x2]∩ΣA≠∅, thenx2∈B2r[x1]∩ΣB.In this case, the condition thatBr[x2]∩ΣA≠∅removes strategies that very weakly dominate every other strategy.Note that both of these propositions depend on the symmetric property of the distance (M2) and the triangle inequality (M3).The concepts of dominance and equivalence provide us with a method for reducing the SSSG through an iterative process of removing dominated strategies fromΣAandΣB, reducing pairwise equivalent subsets to singletons and reassessing dominance in the new strategy sets. This is known as the iterated elimination of dominated strategies (IEDS) (see, for example, Berwanger, 2007; Börgers, 1992; Dufwenberg et al., 2002). Given any game, the aim of IEDS is to identify a simplified game, whose solutions are also solutions of the complete game. These solutions can then be identified using standard techniques (see, for example, Morris (1994, pp. 99–114)). The application of this method to games played over graphs is discussed in Section 6.It should be noted that because we are considering weak rather than strict dominance, IEDS may not be suitable for identifying all the solutions of a particular game. The results of this form of IEDS are dependent on the order in which dominated strategies are removed (Leyton-Brown & Shoham, 2008, pp. 20–23) and some solutions may be lost. It is also necessary to observe that, while IEDS has been shown to be valid for games with finitely many possible strategies, for games with infinitely many possible strategies the process may fail (Berwanger, 2007). Indeed, such infinite games may not have solutions (Ruckle, 1983, p. 10).However, though IEDS is not guaranteed to produce optimal mixed strategies for the SSSG in such cases, given a pair of mixed strategiesσA,σBobtained by this method, it is straightforward to check whether or not they are optimal by verifying that, for someu∈[0,1], we have:(5)infx∈ΣBE[pA(σA,x)]=uinfy∈ΣAE[pB(y,σB)]=1-uwhere u is the value of the game to Player A.This method is described by Blackwell and Girshick (1954, p. 60) and used extensively by Ruckle (1983) to verify proposed optimal mixed strategies for geometric games.The definitions and notation relating to graph theory used in this section are adapted from Bondy and Murty (1976).Consider a simple undirected graph G, characterised by the symmetric adjacency matrixM=(aij), with a set of κ vertices:V(G)={v1,…,vκ}and a set of edges:E(G)={{vi,vj}:vi,vj∈V(G)andaij=1}We suppose that G is connected, to ensure that the metric space axioms are fulfilled, but this assumption could be relaxed if we allowed for infinite distances between vertices. We also suppose that all edges of G have unit weight.The graph gameG=(G,ΣA,ΣB,r)over a finite graph G is defined to be an example of the SSSG, withΩ=V(G),∅≠ΣA,ΣB⊆V(G),ra positive real number, and the distance functiondG(v,w)forv,w∈V(G),v≠w, defined to be the length of the shortest path from v to w in G. We also definedG(v,v)=0,∀v∈V(G). The assumption that G is undirected ensures that the symmetry conditiondG(v,w)=dG(w,v)holds∀v,w∈V(G).Settingr=1, we have thatBr[v], the zone that can be searched by Player A when deployed at v, is the closed neighbourhoodN[v]of v, the set of all vertices adjacent to v united with{v}itself.The game proceeds by Player A choosing a vertexvA∈ΣAand Player B simultaneously choosing a vertexvB∈ΣB. The payoff functions are:pA(vA,vB)=1,ifvAandvBareequaloradjacent;0,otherwise.pB(vA,vB)=1-pA(vA,vB)In this game, the pure strategies for each player are particular vertices. In the following analysis, we use the words “strategy” and “vertex” interchangeably, depending on the context.The graph game is illustrated in Fig. 2.The restriction tor=1is not a significant constraint, since any graph game can be reduced to this case by means of a minor alteration.For situations withr≠1, we can define:G′=(V(G),E(G′))such that:E(G′)={{vi,vj}:vi,vj∈V(G)and1⩽dG(vi,vj)⩽r}and apply our analysis toG′withr=1.Equivalently, ifr∈N, we can replace the adjacency matrixM=(aij)of G withM′=(aij′), where:aij′=0,ifbij=0ori=j1,otherwise.with(bij)=∑q=1rMq, the matrix which shows the number of paths in G of length no greater than r connectingvitovj.It therefore suffices to exclusively study graph gamesGwithr=1, since these methods for redefining G ensure that such analysis will be applicable to games for anyr∈N.Analysis of the graph game requires the statement of some preliminary results and definitions. For these results, we use the following notation:•NA[v]=N[v]∩ΣASet of all potential positions for Player A inN[v].NB[v]=N[v]∩ΣBSet of all potential positions for Player B inN[v].α[v]=|NA[v]|Number of potential positions for Player A inN[v].β[v]=|NB[v]|Number of potential positions for Player B inN[v].Δ(G)=maxw∈V(G)[deg(w)]Maximum degree of the vertices of G.δ(G)=minw∈V(G)[deg(w)]Minimum degree of the vertices of G.The following proposition states that if Player A can search a globally maximal number of potential positions for Player B from a vertex v, then v is not dominated by any other vertex and is only equivalent to those vertices which have the same closed neighbourhood as v. In a graph in which all vertices have a distinct closed neighbourhood, such as a rectangular grid graph, such a vertex v cannot be very weakly dominated by any other vertex.Proposition 5.1For the graph gameG=(G,ΣA,ΣB,r), withr=1, consider a vertexv∈ΣAand the subsetΣA(v)={z∈ΣA:N[z]=N[v]}. We have that if:(6)β[v]=Δ(G)+1then:(i)ΣA(v)exhibits pairwise equivalence for Player A;(ii)v is not very weakly dominated for Player A by any strategy inΣA⧹ΣA(v).To prove (i), observe that∀w1,w2∈ΣA(v),N[w1]=N[w2]. Hence,NB[w1]=NB[w2]and thereforew1is equivalent tow2for Player A, soΣA(v)exhibits pairwise equivalence for Player A.To prove (ii), suppose for a contradiction that v satisfies (6) and is very weakly dominated byvˆ∈ΣA⧹ΣA(v).Observe also that:(7)Ifβ[w]=Δ(G)+1,forsomew∈V(G),thenNB[w]=N[w].and note thatΔ(G)+1is an upper bound forβ[w].Now, we have that:NB[v]⊆NB[vˆ][byveryweakdominance]⇒Δ(G)+1⩽β[vˆ]⩽|N[vˆ]|[by(6)]⇒Δ(G)+1⩽β[vˆ]⩽Δ(G)+1⇒Δ(G)+1=β[v]=β[vˆ]⇒NB[v]=NB[vˆ][sinceNB[v]⊆NB[vˆ]]⇒N[v]=N[vˆ][by(7)]⇒vˆ∈ΣA(v)This is a contradiction, since we supposed thatvˆ∈ΣA⧹ΣA(v). □The next proposition is a stronger result. It states that, for Player A, given a vertex v that is known not to be very weakly dominated by any vertices outside of a certain subset S, if Player A can search strictly more potential hiding places for Player B when deployed at v than could be searched from any other vertex in S, then v is not very weakly dominated by any other vertex.Proposition 5.2For the graph gameG=(G,ΣA,ΣB,r), withr=1, consider a vertexv∈ΣA. LetS⊆ΣAbe such thatv∈Sand such thatΣA⧹Scontains no vertices that very weakly dominate v for Player A. We have that if:(8)β[v]>maxw∈S⧹{v}(β[w])then v is not very weakly dominated for Player A by any other strategy inΣA.For a contradiction, suppose that v satisfies (8) and is very weakly dominated byvˆ∈ΣAfor Player A. We must have thatvˆ∈S, since vertices outside S cannot very weakly dominate v.From the very weak dominance, we have:NB[v]⊆NB[vˆ]⇒maxw∈S⧹{v}(β[w])<β[v]⩽β[vˆ][by(8)]This is a contradiction, sincevˆ∈S⧹{v}. □The following proposition is a restatement of Proposition 4.5, reformulated in the context of the graph game. It states that any vertex that very weakly dominates v for Player A can be no more than 2 steps away from v on the graph. Its proof is identical to that of Proposition 4.5 and is thus omitted.Proposition 5.3For the graph gameG=(G,ΣA,ΣB,r), withr=1, if w very weakly dominates v for Player A andNB[v]≠∅, then:w∈B2[v]∩ΣAFor the graph gameG=(G,ΣA,ΣB,r), withr=1, consider a vertexv∈ΣA. We have that if:β[v]>maxw∈S′(β[w])where:S′=B2[v]∩ΣA⧹{v}then v is not very weakly dominated for Player A by any other strategy.This follows directly from Propositions 5.2 and 5.3, where the set S from Proposition 5.3 is defined as:S=B2[v]∩ΣA□The corollary states that any vertex from which Player A can search strictly more potential hiding places for Player B than could be searched from any other valid vertex lying no more than two steps away, cannot be very weakly dominated by any other vertex. These results allow us to considerably narrow down our search for dominated and equivalent vertices.Analogous results to Propositions 5.2 and 5.3 and Corollary 1 hold for very weak dominance for Player B. The proofs of these results are similar to those presented above and are thus omitted.Proposition 5.4For the graph gameG=(G,ΣA,ΣB,r), withr=1, consider a vertexv∈ΣB. LetS⊆ΣBbe such thatv∈Sand such thatΣB⧹Scontains no vertices that very weakly dominate v for Player B. We have that if:α[v]<minw∈S⧹{v}(α[w])then v is not very weakly dominated for Player B by any other strategy inΣB.For the graph gameG=(G,ΣA,ΣB,r), withr=1, if w very weakly dominates v for Player B andNA[w]≠∅, then:w∈B2[v]∩ΣBFor the graph gameG=(G,ΣA,ΣB,r), withr=1, consider a vertexv∈ΣB,α[v]≠0. We have that if:α[v]<minw∈S′(α[w])where:S′=B2[v]∩ΣB⧹{v}then v is not very weakly dominated for Player B by any other strategy.A first step in the analysis of a particular graph game is to determine lower and upper bounds on the values of the game (see Definition 2.2).Recall that for a two-player constant-sum game, it makes sense to restrict discussion to the value to Player A, since this also determines the value to Player B through the condition that the sum of the two values is a fixed constant (see (1)).Proposition 5.6For the graph gameG=(G,ΣA,ΣB,r), withr=1, let u represent the value to Player A. u is bounded as follows:minv∈ΣBα[v]|ΣA|⩽u⩽maxv∈ΣAβ[v]|ΣB|Note that in the case whereΣA=ΣB=V(G), these inequalities become:(9)δ(G)+1|V(G)|⩽u⩽Δ(G)+1|V(G)|The proposition derives from a consideration ofρAandρB, defined in Section 4.3 as the mixed strategies that allocate equal probabilities to all vertices in a player’s strategy set. If Player A employs mixed strategyρA, then Player B can do no better than to deploy at the vertex whose closed neighbourhood contains the fewest possible vertices inΣA. The value of the game to Player A cannot therefore be less than the sum of the probabilities thatρAassigns to these vertices. This reasoning produces the left hand inequality. The right hand inequality follows in a similar fashion from an analysis ofρBas a strategy for Player B. A formal proof follows:ProofSuppose that Player A employs the mixed strategyρAwhich allocates a uniform probability of|ΣA|-1to all verticesw∈ΣA. In a particular play of the game, suppose that Player B deploys at vertexv∈ΣB.In this situation, the expected payoff to Player A isα[v]|ΣA|-1. Therefore, for any mixed strategyσBfor Player B:E[pA(ρA,σB)]⩾minv∈ΣBα[v]|ΣA|and thus:u=maxσAminσBEpA(σA,σB)⩾minv∈ΣBα[v]|ΣA|The proof of the right hand inequality is similar. □The following corollary is a consequence of (9):Corollary 3Consider the graph game:G=(G,ΣA,ΣB,r)whereG=(V(G),E(G))is a regular graph of degreeD,ΣA=ΣB=V(G),r=1and let u be the value ofGto Player A. Then:•u=(D+1)/|V(G)|The strategyρthat allocates a uniform probability of|V(G)|-1to all vertices, is an optimal mixed strategy for both players.u can also be bounded in a different way:Proposition 5.7For the graph gameG=(G,ΣA,ΣB,r)withr=1, let u represent the value to Player A and:W=W′⊆ΣA:⋃w∈W′N[w]⊇ΣBZ=Z′⊆ΣB:dG(z1,z2)>2,∀z1,z2∈Z′Then u is bounded as follows:minW′∈W|W′|-1⩽u⩽maxZ′∈Z|Z′|-1The left hand inequality is derived from consideration of the mixed strategyτAfor Player A that allocates uniform probabilities to a minimal subset of vertices whose closed neighbourhoods coverΣB.The right hand inequality is derived from consideration of the mixed strategyτBfor Player B that allocates uniform probabilities to a maximal subset of vertices with the property that no two vertices are connected by a path of length less than 3.ProofFirst consider the left hand inequality.Consider a subset of verticesW′∈Wof minimum cardinality. Suppose that Player A employs the mixed strategyτAthat allocates uniform probability|W′|-1to verticesw∈W′and zero probability to all other vertices.In a particular play of the game, suppose that Player B deploys at vertexv∈ΣB. SinceW′∈W, we have:⋃w∈W′N[w]⊇ΣBTherefore∃w′∈W′such thatv∈N[w′]. SinceτAallocates a probability of|W′|-1tow′, the expected payoff to Player A is greater than or equal to|W′|-1. Therefore, for any mixed strategyσBfor Player B:E[pA(τA,σB)]⩾minW′∈W|W′|-1and thus:u=maxσAminσBEpA(σA,σB)⩾minW′∈W|W′|-1Now consider the right hand inequality.Consider a subset of verticesZ′∈Zof maximum cardinality. Suppose that Player B employs the mixed strategyτBthat allocates uniform probability|Z′|-1to verticesv∈Z′and zero probability to all other vertices.In a particular play of the game, suppose that Player A deploys at vertexw∈ΣA. SincedG(z1,z2)>2,∀z1,z2∈Z′, we clearly have that:|N[w]∩Z′|⩽1So, in this situation, the expected payoff to Player A is less than or equal to|Z′|-1. Therefore, for any mixed strategyσBfor Player A:E[pA(σA,τB)]⩽maxZ′∈Z|Z′|-1and thus:u=maxσAminσBEpA(σA,σB)⩽maxZ′∈Z|Z′|-1□Following these results, we label the bounds on u as follows:•LB1=minv∈ΣBα[v]|ΣA|LB2=minW′∈W|W′|-1UB1=maxv∈ΣAβ[v]|ΣB|UB2=maxZ′∈Z|Z′|-1For a particular graph game, each of these bounds may or may not be attained. For example, consider the four graphs shown in Fig. 3. In each case, consider the graph gameG=(G,ΣA,ΣB,r)withΣA=ΣB=V(G)andr=1. For such small graphs, optimal mixed strategies are easy to calculate (for example, using the method described by Morris (1994, pp. 99–114)). Table 1summarises the optimal mixed strategies, the true values of u (the value ofGto Player A) and the values of the bounds for each of the four games.It should be noted that whileLB1andUB1will generally be easy to calculate,LB2andUB2may not be, since the minimal and maximal cardinalities ofW′∈WandZ′∈Zrespectively may be difficult to determine.The results of Section 4.4 and Section 5.3 allow for the creation of an IEDS algorithm (see Section 4.5) for the graph gameG=(G,ΣA,ΣB,r). Since the game has finitely many strategies, this approach is always a valid method for finding a solution of the game (though it may not identify all optimal mixed strategies), as discussed in Section 4.5.The algorithm identifies vertices that may be very weakly dominated for Player A or Player B and checks for dominance and equivalence over a small subset of their surrounding vertices. Very weakly dominated vertices are eliminated and the strategy sets for the players are iteratively reduced, forming sequences(ΣA,K)K∈Nand(ΣB,K)K∈Nof subsets ofΣAandΣBrespectively, until there is no dominance or equivalence in the remaining vertices. The aim is to simplify the game as far as possible, such that optimal mixed strategies can be more easily identified.The explicit identification of vertices that cannot be dominated and the subsequent restriction of the set of vertices that should be examined when searching for dominance of a given vertex are intended to facilitate the creation of an efficient computer programme to apply IEDS in the graph game. An application of the algorithm in a very simple case is presented in Section 6.11.For the purpose of iteration, our existing notation is extended as follows:NA,K[v]=N[v]∩ΣA,KNB,K[v]=N[v]∩ΣB,KαK[v]=|NA,K[v]|βK[v]=|NB,K[v]|Ifr≠1, we transform G toG′using the method outlined in Section 5.2.We then set the iteration variableK=0and define:ΣA,0=ΣAΣB,0=ΣBBy Propositions 5.1 and 5.3 and Corollary 1, in a graph in which all vertices have a distinct closed neighbourhood, a vertex v for which:βK[v]=Δ(G)+1orNB,K[v]≠∅andB2[v]∩ΣA,K={v}orβK[v]>maxw∈S′(v)(βK[w])where:S′(v)=B2[v]∩ΣA,K⧹{v}cannot be very weakly dominated for Player A by any other vertex. We need not therefore consider such vertices when looking for dominated or equivalent strategies.Formally, we define a reduced set of strategies for Player A:ΣA,K-=ΣA,K⧹CA,K(0)∪CA,K(1)∪CA,K(2)with:CA,K(0)=v∈ΣA,K:βK[v]=Δ(G)+1CA,K(1)=v∈ΣA,K:NB,K[v]≠∅;B2[v]∩ΣA,K={v}CA,K(2)=v∈ΣA,K:βK[v]>maxw∈S′(v)(βK[w])For a graph in which two vertices may have the same closed neighbourhood, Proposition 5.1 is not used, and we instead define:ΣA,K-=ΣA,K⧹CA,K(1)∪CA,K(2)Now we must look for very weakly dominated vertices for Player A inΣA,K-.Verticesv∈ΣA,Kfor whichNB,K[v]=∅are dominated automatically by any vertexw∈ΣA,Kfor whichNB,K[w]≠∅, while Proposition 5.3 states that for eachv∈ΣA,K-withNB,K[v]≠∅we need only look for vertices that very weakly dominate v inB2[v]∩ΣA,K.Vertices are checked sequentially according to some pre-determined ordering and very weakly dominated vertices are removed and are not considered when searching for dominance and equivalence of any remaining vertices. Sequential checking and the immediate removal of identified vertices ensure that pairwise equivalent subsets are not eliminated fromΣA,Kin their entirety, but rather reduced to singletons as required.Let the set of very weakly dominated vertices identified in this way be denoted asΨA,K.Formally, we define a new strategy set for Player A:ΣA,K+1=ΣA,K⧹ΨA,KNote that in the trivial case whereNB,K[v]=∅,∀v∈ΣA,K, all vertices under consideration are equivalent for Player A, so we choose any vertexv¯∈ΣA,K, defineΣA,K+1={v¯},ΨA,K=ΣA,K⧹{v¯}and continue to Step Four. This ensures thatΣA,K+1is not empty.In a similar fashion to Step Two, we use Proposition 5.5 and Corollary 2 to define a reduced set of strategies for Player B, removing those strategies that cannot be very weakly dominated:ΣB,K-=ΣB,K⧹CB,K(1)∪CB,K(2)with:CB,K(1)=v∈ΣB,K:NA,K+1[v]≠∅;B2[v]∩ΣB,K={v}CB,K(2)=v∈ΣB,K:αK+1[v]<minw∈S″(v)αK+1[w]where:S″(v)=B2[v]∩ΣB,K⧹{v}However, in the trivial case where∃v∗∈ΣB,KwithNA,K+1[v∗]=∅, observe thatv∗(which need not be unique) very weakly dominates every other vertex for Player B, so we defineΣB,K-=ΣB,Kand continue to Step Five.Note the use ofNA,K+1[v]andαK+1[v]rather thanNA,K[v]andαK[v]at this step.Now we must look for very weakly dominated vertices for Player B inΣB,K-.If∃v∗∈ΣB,K-withNA,K+1[v∗]=∅thenv∗very weakly dominates every other vertex for Player B, as discussed, so we defineΣB,K+1={v∗},ΨB,K=ΣB,K⧹{v∗}and continue to Step Six.Otherwise, Proposition 5.5 states that for eachv∈ΣB,K-we need only look for vertices that very weakly dominate v inB2[v]∩ΣB,K.Vertices are checked sequentially and very weakly dominated vertices are removed and are not considered when searching for dominance and equivalence of any remaining vertices.Let the set of very weakly dominated vertices identified in this way be denoted asΨB,K.Formally, we define a new strategy set for Player B:ΣB,K+1=ΣB,K⧹ΨB,KIf no very weakly dominated vertices were identified at Steps Three and Five (ΨA,K=ΨB,K=∅), then no further pure strategy dominance or equivalence exists. In this case, proceed to Step Seven. Otherwise, increase the iteration variable K by one and return to Step Two.Construct the payoff matrix for the simplified game defined by the strategy setsΣA,K,ΣB,K. If optimal mixed strategies for this game can be found (for example, using the method described by Morris (1994), pp. 99–114), they are optimal mixed strategies for the complete graph game (see Morris, 1994, pp. 48–49; Berwanger, 2007, p. 2).Note that this algorithm must terminate for someK∈N. The condition for continued iteration (Step Six) is only fulfilled if new pure strategy dominance or equivalence is identified and this necessarily results in the elimination of strategies from one player’s strategy set. Also, graph games have been defined on graphs with a finite set of κ vertices, which implies thatΣA,0andΣB,0are finite sets. Therefore the integer sequence:(10)|ΣA,K|+|ΣB,K|K∈Nis strictly decreasing and positive, and so must terminate for someK=K′∈N.Though a thorough investigation of the computational complexity of the algorithm is beyond the scope of this paper (and would depend to some extent on its precise implementation), a crude measure of the algorithm’s efficiency can be determined by considering the number of pairs of vertices that must be tested for very weak dominance before the algorithm terminates. Given a graph gameG=(G,ΣA,ΣB,r)with|V(G)|=κ, an (extremely conservative) upper bound for this number can be determined as follows.At each of Steps Three and Five, a particular vertex can be tested against no more thanκ-1other vertices. Therefore, the number of vertex pairs tested for very weak dominance at a single iteration certainly does not exceed2κ2. Also, since (10) is a strictly decreasing positive sequence and|ΣA,0|,|ΣB,0|⩽κ, the number of iterations clearly cannot exceed2κ. Therefore, for any graph game, the total number of vertex pairs that must be tested for very weak dominance before the algorithm terminates will not exceed a cubic function of the number of vertices κ.Alternatively, since the algorithm only tests vertex pairs for very weak dominance if the distance between them is less than 3, at each of Steps Three and Five, a particular vertex will be tested against no more thanΔ(G′)2other vertices (whereΔ(G′)is the maximum degree of the vertices of the graph after the completion of Step One). Therefore, the number of vertex pairs tested in a single iteration certainly does not exceed2Δ(G′)2κ. Again using the fact that the number of iterations cannot exceed2κ, we may conclude that, for any graph game, the total number of vertex pairs tested before termination will not exceed a quadratic function ofΔ(G′)κ.Which of these bounds is more useful will depend on the structure of the graphs under consideration.In this section and the next, we demonstrate that the algorithm of Section 6.1 offers a distinct advantage over the method proposed by White (1994) for solving games played on trees (withr=1). Proposition 6.2 establishes that the algorithm always succeeds in reducing games of this type to cases that are trivially simple to solve, while Section 6.11 presents a simple example which shows that the algorithm can also be applied to games on graphs that are not trees. Also note that White (1994) exclusively considers situations whereΣA=ΣB=V(G), while the algorithm presented here is not restricted to such cases.Recall that a tree is a graph in which there is a unique path between any pair of vertices. In particular, if G is a tree, we may designate a vertext∈V(G)as the “root” of G, such that any vertexv≠thas precisely one neighbourvp(the “parent” of v) for which:dG(t,vp)=dG(t,v)-1For any other neighbourvcof v (a “child” of v) we have:dG(t,vc)=dG(t,v)+1As in Section 4.3, letρAandρBrepresent the mixed strategies for each player that allocate equal probabilities to all vertices in their strategy set. The following proposition is a restatement of Proposition 4.1 in the context of graph games, withζ=1.Proposition 6.1Consider the graph game:G=(G,ΣA,ΣB,r)withr=1. If we have:α[v]=1,∀v∈ΣBβ[w]=1,∀w∈ΣAthenρAandρBare optimal mixed strategies for Players A and B respectively and|ΣA|-1=|ΣB|-1=uis the value of the game to Player A.The following proposition states that, for graph games on trees withr=1, either the value of the game to Player A is zero and analysis of the game is trivial or the algorithm of Section 6.1 reduces the game to the form given in Proposition 6.1, for whichρAandρBhave been shown to be optimal mixed strategies.Proposition 6.2Consider the graph game:G=(G,ΣA,ΣB,r)where G is a tree andr=1. When applied toG, the algorithm of Section6.1terminates for someK=K′∈N, such that:•Either:ΣA,K′={w},βK′[w]=0ΣB,K′={v},αK′[v]=0and u, the value of the game to Player A, is 0;Or:αK′[v]=1,∀v∈ΣB,K′βK′[w]=1,∀w∈ΣA,K′and thus, byProposition 6.1, the mixed strategiesρA,K′andρB,K′, which allocate equal probabilities to all vertices in the players’ respective strategy setsΣA,K′andΣB,K′, are optimal mixed strategies and the value of the game to Player A is:u=|ΣA,K′|-1=|ΣB,K′|-1A proof of the proposition is presented in Appendix B.A computer programme was written in Python (Python Software Foundation, 2012) using NumPy (Numpy Developers, 2012) to implement the algorithm of Section 6.1.The single example presented here is clearly very simple and is included purely to demonstrate that the algorithm can be applied to games on graphs other than trees, though the extent to which it is able to simplify such game varies greatly. Note particularly that this example hasr≠1andΣA≠ΣB.Consider the graph gameG∗=(G∗,ΣA,ΣB,r), wherer=2andG∗is the graph over 14 verticesv0tov13defined by the adjacency matrix:M=0000000001000000100100000100010100100000010010000010000000000100000110010010100000100010010000100000000000011110000100000101101000000110000100000011000110010010011010000000110110100000100000010000with:ΣA=V(G∗)ΣB={v1,v2,v5,v6,v8,v10,v11,v12,v13}The graph is shown in Fig. 4.The algorithm reduces the game to the following case:•Remaining strategies for PlayerA:v1,v7,v8,v13Remaining strategies for PlayerB:v0,v2,v6,v12Payoff matrix (for Player A):Calculating the optimal mixed strategies from this matrix is simple, for example, using the method described by Morris (1994, pp. 99–114). Alternatively, observe that we may apply Proposition 4.1 to this reduced game, settingζ=3.An optimal mixed strategy for Player A is to play verticesv1,v7,v8,v13, each with probability 0.25; an optimal mixed strategy for Player B is to play verticesv0,v2,v6,v12, each with probability 0.25. The value of the game to Player A is 0.75.The definitions and notation relating to group theory used in this section are from Neumann, Stoy, and Thompson (1994).An automorphism of a graphG=(V(G),E(G))is a mapping of the graph to itself, which preserves adjacencies. The following definition is adapted from Bondy and Murty (1976, pp. 5–7):Definition 7.1Consider a simple undirected graphG=(V(G),E(G)).•An automorphismϕ of G is a permutation of the vertices:ϕ:V(G)→V(G)v↦ϕ(v)such that:{v,w}∈E(G)⇔{ϕ(v),ϕ(w)}∈E(G)The automorphism groupΓ(G)is the permutation group formed by the set of all automorphisms of G, with the operation of composition.The orbitOH[v]of a vertexv∈V(G)under a subgroupH⩽Γ(G)is the set:OH[v]={w∈V(G):∃ϕ∈Hwithϕ(v)=w}The orbits of the vertices of G under H form a partition ofV(G).Note that this definition is valid for simple graphs. For more general graphs, which may include directed edges, loops, or multiple edges connecting the same vertices, a permutation of the edges also needs to be specified.We extend the concept of a graph automorphism to that of a graph game automorphism, an automorphism of the graph that also preserves the strategic status of the vertices:Definition 7.2Consider a graph game:G=(G,ΣA,ΣB,r)withr=1. A graph game automorphismϕ ofGis an automorphism of G, such that:•v∈ΣA⇔ϕ(v)∈ΣA,∀v∈V(G)v∈ΣB⇔ϕ(v)∈ΣB,∀v∈V(G)We can also define automorphism groups and vertex orbits in terms of graph game automorphisms:Proposition 7.1Consider a graph game:G=(G,ΣA,ΣB,r)withr=1.•The set of all graph game automorphisms ofG, with the operation of composition, forms a subgroupΓ(G)(thegraph game automorphism group) ofΓ(G).The orbits of the vertices of G under any subgroupH⩽Γ(G)form a partition ofV(G).ForΓ(G)to be a subgroup ofΓ(G), we require thatΓ(G)is closed under composition, contains the identity and contains an inverse for every element. Since the only restriction onΓ(G)is thatΣA,ΣBare invariant under its elements, these conditions are clearly satisfied. The second part of the proposition is true of any permutation group.The following proposition describes a relationship between certain optimal mixed strategies ofGand the graph game automorphism groupΓ(G).Proposition 7.2Consider a graph game:G=(G,ΣA,ΣB,r)withV(G)={v1,…,vκ}andr=1. LetO[v]denote the orbit of v under some subset H of the graph game automorphism groupΓ(G).There exists a pair of optimal mixed strategies:σA=(σA[v1],…,σA[vκ])σB=(σB[v1],…,σB[vκ])whereσAandσBrespectively allocate probabilitiesσA[vi]andσB[vi]to vertexvi, such that∀i,j∈{1,…,κ}:(11)O[vi]=O[vj]⇒σA[vi]=σA[vj]σB[vi]=σB[vj].Note that in particular the proposition is true forH=Γ(G). A proof of the proposition is presented in Appendix B.Proposition 7.2 implies that, when looking for optimal mixed strategies for a graph gameG, it suffices to consider those strategies that allocate equal probability to all vertices lying in the same orbit under graph game automorphisms. For graphs with high numbers of symmetries, this can significantly simplify the analysis of the game.Furthermore, the fact that the proposition is valid for any subgroupH⩽Γ(G)ensures that even if not all graph game automorphisms ofGare known, to find a pair of optimal mixed strategies, it is sufficient to restrict consideration to those strategies that allocate equal probability to all vertices lying in the same orbit under the subgroup generated by those graph game automorphisms that can be identified.Note that, though stated and proved in a different setting, this proposition is strongly related to Theorem 2.1 of Zoroa et al. (1993, pp. 526–528), which relates to games played over sets that admit certain transformations. However, Zoroa et al. require that the transformations considered be commutative, which is not necessarily true of the automorphisms of a graph.Consider the graph gameG=(G5,5,ΣA,ΣB,r), whereG5,5is the the5×5rectangular grid graph depicted in Fig. 5,ΣA=ΣB=V(G5,5)andr=1. Each player has 25 possible pure strategies:V(G5,5)={v1,…,v25}.Note that since both Players may deploy at any vertex,Γ(G)=Γ(G5,5), so we consider all automorphisms ofG5,5. These automorphisms are rotations through multiples ofπ/2, reflection about a vertical axis and compositions of these transformations. The vertices can be partitioned into six orbits, which we denote asO(i),i∈{1,…,6}. The vertices belonging to each orbit are indicated in Fig. 5.By Proposition 7.2, there exist optimal mixed strategiesσA,σBfor Players A and B, which allocate the same probability to all vertices lying in the same orbit. LetωA(i)andωB(i)be the respective probabilities thatσAandσBallocate to individual vertices in orbitO(i), and define:(12)Ai=|O(i)|ωA(i),Bi=|O(i)|ωB(i),∀i∈{1,…,6}Observe that:∑i=16Ai=∑i=16Bi=1AiandBirepresent the total probability thatσAandσBrespectively allocate to all vertices in orbitO(i).Letσ(1),…,σ(6)be the mixed strategies (for either player), which allocate uniform probability to all vertices in the corresponding orbit and zero probability to other vertices:σ(i)=(σ(i)[v1],…,σ(i)[v25])with:σ(i)[vj]=|O(i)|-1,vj∈O(i)0,otherwise.We see thatσAandσBare linear combinations of theσ(i), weighted by the orbit probabilitiesAiandBi:σA=∑i=16Aiσ(i),σB=∑i=16Biσ(i)This observation allows us to take a different perspective on the problem. Suppose that we treat theσ(i)as if they were pure strategies. The following strategies would be optimal strategies of such a game:τA=(τA[σ(1)],…,τA[σ(6)])τB=(τB[σ(1)],…,τB[σ(6)])with:τA[σ(i)]=Ai,∀i∈{1,…,6}τB[σ(i)]=Bi,∀i∈{1,…,6}To find these optimal mixed strategies, we analyse the matrix of expected payoffs to Player A for each of these six strategies against one another:PlayerBσ(1)σ(2)σ(3)σ(4)σ(5)σ(6)PlayerAσ(1)σ(2)σ(3)σ(4)σ(5)σ(6)1/41/400001/41/81/41/40001/41/401/4001/401/41/20001/41/21/41000011The optimal mixed strategiesτAandτBcan be computed from this payoff matrix using standard methods (see, for example, Morris (1994, pp. 99–114)), giving:A1,…,A6=69-1(16,28,10,4,6,5)B1,…,B6=69-1(16,28,10,4,6,5)Using (12) we then find:ωA(1),…,ωA(6)=138-1(8,7,5,2,3,10)ωB(1),…,ωB(6)=138-1(8,7,5,2,3,10)This fully determines the optimal mixed strategiesσAandσBforG. These optimal mixed strategies are illustrated in Fig. 6.Note that by identifying the six orbits ofV(G)under graph game automorphisms ofG, rather than solving a game with a25×25payoff matrix, we needed only to solve a game with a6×6payoff matrix. A similar method could be applied to any graph gameG=(G,ΣA,ΣB,r)withr=1, for which non-trivial graph game automorphisms can be found.The example of the graph gameGplayed over the5×5rectangular gridG5,5exhibits two curious and related properties.Firstly, and most obviously, the optimal mixed strategies that were calculated for each player are identicalσA=σB=σ. This means that the optimal mixed strategy for Player A allocates identical probabilities to the vertices ofG5,5as does the optimal mixed strategy for Player B (though these optimal mixed strategies need not be unique). Given the interpretation of the game, this is a surprising result. Player B is attempting to hide from Player A, so we might have expected that her best mixed strategy would involve avoiding vertices at which Player A was more likely to deploy.Note that the method of Section 7.1 does not produce identical optimal mixed strategies for all graphs, nor for all grid graphs. For example, when applied to the6×6grid graphG6,6, the method produces distinct optimal mixed strategiesσA,σB(see Fig. 7) that appear to be more consistent with our intuition, in that vertices to whichσAallocates fairly high probability seem to be allocated fairly low probability byσBand vice versa.Secondly, in Fig. 6, observe that for all verticesv∈V(G5,5), the sum of the probability oddments allocated byσto the vertices in the closed neighbourhoodN[v]is equal to 22. Formally, we make the following definition:Definition 7.3Given a graph gameG=(G,ΣA,ΣB,r), withr=1andΣA=ΣB=V(G)={v1,…,vκ}, an equal oddments strategyσis a vector:σ=(σ[v1],…,σ[vκ])with:0⩽σ[vi]⩽1,∀i∈{1,…,κ}∑i=1κσ[vi]=1such that:∑w∈N[vj]σ[w]=u,∀j∈{1,…,κ}For someu∈R. We call u the neighbourhood sum ofσ.The following proposition links those situations in which Players A and B have identical optimal mixed strategies with the existence of equal oddments strategies.Proposition 7.3Given a graph gameG=(G,ΣA,ΣB,r), withr=1andΣA=ΣB=V(G), then the following statements are equivalent:•σis an equal oddments strategy ofGwith neighbourhood sumu∈R.σis an optimal mixed strategy ofGfor both players andu∈Ris the value of the game to Player A.Suppose thatσis an equal oddments strategy ofGwith neighbourhood sumu∈R. Observe that for all pure strategiesv∈V(G)for either player, we have:E[pA(v,σ)]=uE[pB(σ,v)]=1-uTherefore, by (5),σis an optimal mixed strategy ofGfor both players and u is the value of the game to Player A.To prove the opposite implication, suppose thatσis an optimal mixed strategy ofGfor both players and that u is the value of the game to Player A. Let:V(G)={v1,…,vκ}σ=(σ[v1],…,σ[vκ])Also let:m-=minv∈V(G)∑w∈N[v]σ[w]m+=maxv∈V(G)∑w∈N[v]σ[w]and letv-,v+be vertices for which this minimum and maximum are respectively attained.Assume (to derive a contradiction) thatσis not an equal oddments strategy. Then:(13)m-<m+Therefore:m+=E[pA(v+,σ)]⩾E[pA(σ,σ)]=u1-m-=E[pB(σ,v-)]⩾E[pB(σ,σ)]=1-uSinceσis an optimal mixed strategy, the above inequalities must be equalities. Specifically:m-=m+=uThis contradicts (13). Thereforeσis an equal oddments strategy. □Proposition 7.3 means that, given a graph gameG=(G,ΣA,ΣB,r), withr=1andΣA=ΣB=V(G), if we can find a distribution of positive real numbers across the vertices such that the sum of these numbers in any closed neighbourhood is equal to a constant, and we scale these numbers to produce a valid probability distribution across the vertices, this distribution defines a mixed strategy that is optimal for both players. This offers an alternative approach to proving Corollary 3 on optimal mixed strategies for games played over regular graphs, since the mixed strategyρ, as defined in the corollary, is clearly an equal oddments strategy.The concepts discussed in Section 7 suggest a potential approach for finding general expressions for the optimal mixed strategies of games played over certain families of graphs. To demonstrate this approach, we consider games played over a specific family of graphs, which we describe as poly-level graphs. The vertices in such graphs are arranged in levels and each vertex exhibits a local structural similarity in the way that it is connected to other vertices in its own level and to those in the levels above and below.Definition 8.1Poly-level graphA graphG=(V(G),E(G))is called a poly-level graph if and only if the vertices can be partitioned into h subsetsL1,L2,…,Lh⊆V(G)called levels, with|Li|=ci, such that each vertex inLiis adjacent to precisely:•j other vertices inLi(the intradegree);k vertices inLi+1(the superdegree), fori≠h;l vertices inLi-1(the subdegree), fori≠1;0 vertices in any other level.Fig. 8provides a visual representation of a general poly-level graph, while Figs. 9–13show specific examples of such graphs. In each example, vertices inL1are coloured black, with higher levels being indicated by progressively lighter shades.The appearance of a poly-level graph may be highly symmetric (Figs. 9 and 10) or quite irregular (Fig. 11). Also, two poly-level graphs with the same parameters may be topologically quite different (Fig. 12), while the parameters used to describe a particular poly-level graph are generally not unique (Fig. 13).Note that it suffices to specify the number of verticesc1inL1to determine the number of verticesciin any levelLi, as established in the following simple proposition:Proposition 8.1Given a poly-level graph G, with levelsL1,…,Lh, superdegree k, subdegree l and|Li|=ci, we have:ci=(kl-1)i-1c1,∀i∈{1,…,h}The number of edges linking vertices inLito vertices inLi+1can be expressed in two forms, which must be equal:lci=kci-1,∀i∈{2,3,…,h}Thus, theciform a geometric progression with common ratiokl-1and the proposition follows immediately. □The following proposition establishes two intuitively obvious constraints on the parameters of a poly-level graph.Proposition 8.2Given a poly-level graph G, with levelsL1,…,Lh, intradegree j, superdegree k, subdegree l and|Li|=ci, we have that∀i∈{1,…,h}:(a)(kl-1)i-1c1∈Z(b)(kl-1)i-1c1⩾j+1These constraints arise immediately from the fact that the number of verticesciin any levelLi(replaced in Proposition 8.2 by the expression from Proposition 8.1) must (a) be an integer and (b) exceed the intradegree j.Given a poly-level graph G, from Section 7.3, we know that if there exists a probability distribution across the vertices of the graph such that the sum of the probabilities in any closed neighbourhood is equal to some constantu∈(0,1], then this probability distribution defines an optimal mixed strategy for both players for the gameG=(G,ΣA,ΣB,r), withr=1,ΣA=ΣB=V(G), and the value of the game to Player A is u.Suppose that such a distribution exists, and suppose that this distribution allocates an equal probabilityωito each vertex in levelLi. Through consideration of the structure of the graph, we can write the following equations, which must hold for alli∈{2,3,…,h-1}:(14)(j+1)ω1+kω2=ulωh-1+(j+1)ωh=ulωi-1+(j+1)ωi+kωi+1=uWe also have the following constraints, to ensure that theωidefine a valid probability distribution:(15)∑i=1hωici=1(16)ωi⩾0,∀i∈{1,2,…,h}Note that it is not necessary to explicitly include the constraintωi⩽1, since this is implied by (15) and (16).We now perform the change of variables:(17)wi=u-1(j+k+l+1)ωi,∀i∈{1,…,h}and introduce additional unknownswi,∀i∈Z.The question of finding a functionωiof i that satisfies (14)–(16) can be reformulated as follows:•Given a non-negative integer j and positive integersh,k,l,c1satisfying the conditions of Proposition 8.2, find a functionwiof i, such that,∀i∈Z:(18)lwi-1+(j+1)wi+kwi+1=j+k+l+1Subject to the boundary conditions:(19)w0=wh+1=0With the constraint:(20)wi⩾0,∀i∈{1,2,…,h}To find a solution to the problem, let:wi=wiGS+wiPSwherewiPSis any particular solution of (18), andwiGSis the most general solution of the homogeneous difference equation:(23)lwi-1+(j+1)wi+kwi+1=0,∀i∈ZAn obvious candidate for the particular solution is:wiPS=1ForwiGS, there are three cases to consider:Look for a solution of the form:wiGS=A+λ+i+A-λ-iwhereA+,A-are arbitrary constants andλ+,λ-are unknown constants to be determined. Substituting into (23), we find:λ±=-(j+1)±(j+1)2-4kl2kSo:wi=A+λ+i+A-λ-i+1Applying the boundary conditions gives:A++A-=-1A+λ+h+1+A-λ-h+1=-1which can be solved to give:A+=1-λ-h+1λ-h+1-λ+h+1A-=1-λ+h+1λ+h+1-λ-h+1Note that in this case,λ+≠λ-, and thereforeA+andA-both exist.Look for a solution of the form:wiGS=(A+iB)λiwhereA,Bare arbitrary constants andλis an unknown constant to be determined. Substituting into (23), we find:λ=-j+12kSo:wi=(A+iB)λi+1Applying the boundary conditions gives:A=-1B=1-λ-[h+1]h+1Again, A and B exist for all values of the parameters.Look for a solution of the form:wiGS=λi[Pcos(θi)+Qsin(θi)]whereP,Qare arbitrary constants andλ,θare unknown constants to be determined. Substituting into (23), we find:(24)λ=l/k(25)θ=arg-(j+1)+i4kl-(j+1)2So:wi=λi[Pcos(θi)+Qsin(θi)]+1Provided thatθ[h+1]is not an integer multiple ofπ, applying the boundary conditions gives:P=-1Q=cos(θ[h+1])-λ-[h+1]sin(θ[h+1])Ifθ[h+1]is an integer multiple ofπthen no values of P and Q can be found to satisfy the boundary conditions (19) and no solutionwiexists, except in the particular case whereθ[h+1]is an even multiple ofπandk=l. In the latter instance, the boundary conditions are satisfied for all values of Q, withP=-1, identifying an infinite family of possible solutions.

@&#CONCLUSIONS@&#
