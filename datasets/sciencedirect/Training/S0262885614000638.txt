@&#MAIN-TITLE@&#
Unsupervised flow-based motion analysis for an autonomous moving system

@&#HIGHLIGHTS@&#
This paper focuses on segmenting the motion from dense optical flow fields.Two unsupervised clustering methods are presented and a model selection is proposed.A comparison between the proposed techniques with the K-means and EM is made.Experiments are conducted in a surveillance scenario with an autonomous mobile.The proposed techniques are superior in terms of robustness and computational demands

@&#KEYPHRASES@&#
Motion segmentation,Optical flow,Moving observer,Active surveillance,Mobile robot,

@&#ABSTRACT@&#
Graphical abstract

@&#INTRODUCTION@&#
For the generalization of robotic applications it is crucial to overcome certain problems related to the perception and interpretation of the dynamic scene, for instance, the extraction of high level information in order to increase the robots' ability to perform suitable motion detection [4,11], tracking [17], object recognition [30,24] and navigation [6,7]. It is also imperative to increase their ability to interact with the environment and, thus, the robot must be able to detect and analyze their surrounding scene.In the scientific community, motion perception is one of the most relevant areas under discussion, and there are several models to perform motion analysis in a variety of environments. However, most of the methods cannot achieve the real-time constraints imposed by mobile robots without specialized computers. In some cases, these computer devices cannot be used due to the small size of the vehicles or they cause a higher consumption of energy which reduces the autonomy of such robots. Nowadays, there are pixel-wise techniques that have good results [5]; however, the segmentation of motion commonly takes more than a pair of seconds. Techniques for robotic applications are computationally more efficient although, this improvement is usually done at the expense of using lower resolution of images and feature-based approaches. The computational resources and the processing-time are some of the most critical aspects for vision-based techniques applied to robotics. Usually, these applications tolerate some loss of accuracy in the algorithms to ensure a fast response [15].The work presented by this research studies the real-time motion analysis using dense optical flow fields and for a practical use in a mobile robot. Motion segmentation is the process of dividing an image into different regions in a way that each region presents homogeneous motion characteristics. The goal is to segment different objects according to their motion coherence. In particular, the current research describes a real application that is installed in a corridor with large homogeneous regions that does not have a significant amount of structural clues for feature-based techniques. Optical flow techniques provide relevant motion information about the environment around the robot [15]. Moreover, dense optical flow fields provide a good representation of the visual and apparent motion for robotic applications [27,25]; however, the analysis of these fields is a complex and challenging process that requires for sophisticated techniques.In this article, the estimation of dense flow fields is conducted by the optical flow technique of [29] that was especially designed for small robotic applications equipped with generic computers. This technique identifies motion properties which are considered as high level information about the sequence and originates flow fields in a short period of time. The research proposes two unsupervised clustering techniques for segmenting dense flow fields: the Hybrid Hierarchical Optical Flow Segmentation (HHOFS) and the Hybrid Density-Based Optical Flow Segmentation (HDBOFS). These two techniques were designed for robotic applications with a vision system and limited computer resources. Two major and distinct phases form both methods, namely, refining and collecting. The refining stage decomposes the flow field in a set of distinctive clusters that represent image regions with different motion models and the collecting stage merges the set of clusters that were obtained in the previous phase (using a hierarchical scheme or a density-based scheme). This architecture reduces the computational requirements of the proposed methods (HHOFS and HDBOFS). An extensive and interesting comparison between parametric (K-means and EM) and the proposed non-parametric techniques (no assumptions about the distribution of the data) is presented.In addition, this article proposes a model selection method, called Fusing Distributed Bayesian Hypothesis (FDBH), which combines a histogram-based approach with cost functions (that balance fitness and model complexity). The estimation of the number of clusters is incorporated in all methods.Experimental considerations prove that modeling a clustering technique in a structure formed by two consecutive stages is computationally rewarding. The computational demands of the HHOFS and the HDBOFS are substantially lower than that of the EM and K-means that are conducted at flow level. The behavior of the proposed techniques can be adjusted to specific characteristics of the application. For instance, motion segmentation in surveillance operations can be appropriately performed without processing at pixel level. Therefore, the proposed techniques are completely capable of perceiving and understanding external motions in real-time and using low computational resources. However, the results have a blocky aspect which is usually tolerable by robotic moving systems.Therefore, the contributions of this paper include:1.Novel motion analysis methods with a reduced computational complexity: the HHOFS and the HDBOFS. The proposed architecture guides the motion analysis in both methods, enabling a reliable segmentation process while preserving the computational time requirements;An efficient method to decompose the optical flow field into exclusive regions based on similarity properties of motion;A model selection method to enhance the performance of the clustering techniques, the FDBH method. The Bayesian formulation combines a histogram-based analysis of the flow field in the polar space with the decay-ratio of a model selection criterion;A comparative study of several unsupervised motion segmentation techniques (pixel-wise and block-wise) is provided;An extensive qualitative and quantitative evaluation under realistic working conditions (with moving observers);The article is organized as follows. Section 2 presents a brief review of motion segmentation methods that are commonly used in robotic systems to perceive motion. Section 3 shows the concept of the robotic application, named EEyeRobot. Section 4 presents the two unsupervised clustering techniques that are proposed and used in this research. Both non-parametric techniques are described with detail in Sections 4.1 and 4.2. Afterwards, a model selection method is proposed in Section 4.3. Experimental results are presented in Section 5. These results include the comparisons of the proposed techniques with the EM and the K-means. The experiments were conducted using the EEyeRobot in a real surveillance scenario. The results demonstrate that the HHOFS and the HDBOFS methods perform satisfactorily better, and can be used as a tool for motion analysis in applications with limited resources. Finally, Section 6 presents the most important conclusions of this research.

@&#CONCLUSIONS@&#
