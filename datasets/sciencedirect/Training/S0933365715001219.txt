@&#MAIN-TITLE@&#
Sparse deconvolution of higher order tensor for fiber orientation distribution estimation

@&#HIGHLIGHTS@&#
We model a regularization of HOT with an l1 penalization not on coefficient vector but directly on the FOD.A weighted regularization scheme is developed to iteratively solve the problem.Our method allows HOTs to obtain increasingly clean and sharp FOD with very higher order tensors.The method appears to be less spurious peaks and more coherence across neighboring FODs.

@&#KEYPHRASES@&#
Diffusion magnetic resonance imaging,Fiber orientation distribution,Higher order tensor,Spherical deconvolution,Sparse approximation,

@&#ABSTRACT@&#
PurposeHigher order tensor (HOT) imaging approaches based on the spherical deconvolution framework have attracted much interest for their effectiveness in estimating fiber orientation distribution (FOD). However, sparse regularization techniques are still needed to obtain stable FOD in solving the deconvolution problem, particularly in very high orders. Our goal is to adequately characterize the actual sparsity lying in the FOD domain to develop accurate estimation approach for fiber orientation in HOT framework.Materials and methodsWe propose a sparse HOT regularization model by enforcing the sparse constraint directly on the representation of FOD instead of imposing it on coefficients of basis function. Then, we incorporate both the stabilizing effect of the l2 penalty and the sparsity encouraging effect of the l1 penalty in the sparse model to adequately characterize the actual sparsity lying in the FOD domain. Furthermore, a weighted regularization scheme is developed to iteratively solve the deconvolution problem. The deconvolution technique is compared against existing methods using l2 or l1 regularizer and tested on synthetic data and real human brain.ResultsExperiments were conducted on synthetic data and real human brain data. The synthetic experimental results indicate that crossing fibers are more easily detected and the angular resolution limit is improved by our method by approximately 20°–30° compared to existing HOT method. The detection accuracy is considerably improved compared with that of spherical deconvolution approaches using the l2 regularizer and the reweighted l1 scheme.ConclusionsResults of testing the deconvolution technique demonstrate that it allows HOTs to obtain increasingly clean and sharp FOD, which in turn significantly increases the angular resolution of current HOT methods. With sparsity on FOD domain, this method efficiently improves the ability of HOT in resolving crossing fibers.

@&#INTRODUCTION@&#
Diffusion weighted magnetic resonance imaging (DW-MRI) is a non-invasive imaging technique capable of revealing microstructural information of human brain. Diffusion tensor imaging (DTI) is commonly used to approximate the diffusivity function from a given set of acquired DW-MRI images [1]. However, voxels are often contaminated with significant partial volume effects at current spatial resolutions, and the diffusion tensor model fails to accurately represent the nerve bundle geometry in voxels containing multiple fiber populations.The need of developing accurate estimation approaches for fiber orientation to resolve neural architecture in regions with complex fiber patterns necessitates the inventing or using novel methods of high angular resolution diffusion imaging (HARDI). One group of methods, collectively known as q-space techniques, identifies multiple fiber components by calculating the probability distribution function (PDF) of the diffusion process based on the Fourier transform relationship between the PDF of the diffusion displacement and the diffusion weighted signal attenuation in q-space. These methods include Q-ball imaging [2], diffusion spectrum imaging [3,4], and diffusion orientation transform [5]. Model-based methods rely on a more complex model to characterize the diffusion-weighted signal attenuation; such methods include the multi-tensor model [6], directional functions [7], spherical harmonics deconvolution [8–12], and high order tensor (HOT) [13–17]. Among these techniques, HOTs, which generalizes the 2nd order tensors, were introduced [13] to represent the non-Gaussian diffusion process owing to its simple polynomial form and its ability to model multi-lobed spherical functions. However, choosing a low-order basis implies an increased smoothing and therefore a loss of sharp directional information, whereas a high-order basis entails many more coefficients to represent the orientation distribution function (ODF). These coefficients, particularly those for the 8th, 10th or higher orders, are difficult to identify in diffusion estimation processing. Thus, the estimation of these coefficients suffers heavily from noise.A common approach to robustly obtain the fiber orientation distribution (FOD) is to guarantee the non-negative property of HOT functions. Barmpoutis et al. [18] presented a novel technique that represents a 4th-order tensor using a homogeneous polynomial of degree 4 in three variables. The theories guaranteed the symmetric positive definite property. In succeeding works, they extended their method to represent a tensor of any order using homogeneous polynomial parameterizations that covers the full space of positive definite tensors of any order [16,19]; they summarized their work as a complete mathematical study [14]. Qi et al. [20,21] proposed a positive semi-definite diffusion tensor model that is a convex optimization problem with a convex quadratic objective function constrained by the non-negative requirement on the smallest Z-eigenvalue of the diffusivity function. Their research improved the stabilities, but their results are still prone to poor angular resolution.Jiao et al. [15] recently expressed the spherical deconvolution of HOT-ODF as a linear programming problem and then extracted the fiber orientation using the rank-k tensor decomposition method. Weldeselassie et al. [16] used a spherical deconvolution framework in estimating the positive-definite Cartesian tensor ODF, which can be achieved by minimizing an objective function subject to nonnegative constraints. Such minimization is in turn achieved by solving a linear programming problem using the nonnegative least squares algorithm. These spherical deconvolution approaches represent a huge advance in obtaining increasingly sharp fiber orientation. However, the former method is known to suffer heavily from intrinsic instabilities in solving the non-negative linear programming problem. The latter method approximates the HOTs using the sum of squares of lower order tensors. The accuracy of the approximation also depends on how well the set of vectors is sampled in the space of a unit sphere.Recent research on HOT is generally based on the assumption that FOD is a non-negative function. Incorporating prior knowledge on FOD via sparse representation provides an effective approach to reconstruct sparse fiber signals. Landman et al. [22] and Pu et al. [23] imposed the l1-norm penalty on the coefficients of spherical harmonics basis. Daducci et al. [12] introduced l0-norm penalty and then performed approximations through a reweighing l1-norm scheme. These approaches assume that the sparsity of the coefficients implies the FOD sparsity. Hence, they usually directly enforce the FOD sparsity on the domain of coefficients. The FOD values are usually computed from a set of basis functions or polynomials with the coefficients. The sparsity of the coefficients means that only a few basis functions or polynomials are included to form the FOD, whereas the sparsity of the FOD suggests that only a small number of the FOD values are non-zero.In this work, we first define a new sparse HOT imaging model, in which the sparse constraint is directly imposed on the FOD domain using the l0-norm penalty. The l0-norm sparsity of FOD is then approximated by combining the sparsity encouraging effect of l1-norm and the stabilizing effect of l2-norm. In addition, a weighted regularization scheme is proposed to iteratively solve the minimization problem. We evaluate the effectiveness of our proposal for improving FOD reconstructions by comparing it with existing state-of-the-art HOT-ODF and spherical harmonics methods. We report results on both synthetic and real data. This paper is organized as follows: Section 2 develops the sparse HOT imaging model that performs convolution between the HOT-ODF and DW-MRI signals and proposes the iterative deconvolution algorithm. Section 3 presents the evaluation of the performance of the algorithm on synthetic data and real-world DW-MRI data. Section 4 concludes the paper.The image contrast in diffusion weighted imaging is related to the diffusion of water molecules, whose measurements can be rendered sensitive to water diffusion along distinct spatial direction g in the sphere, such that the diffusion signal attenuation S(g)/S0 is measured with diffusion weighted b-values b for each direction. We express the diffusion signal attenuation profile as the convolution of a signal fiber response function using HOT-ODF(1)S(g)/S0=R(v,g)⊗D(v)=∫S2R(v,g)D(v)dvwhere g=(g1, g2, g3)Tis the magnetic field gradient direction, andvis the unit vector on sphere S2. S(g) represents the DW-MRI signal acquired with b-value b in direction g∈S2, while S0 is the signal acquired without diffusion weighting.R(v,g)is an axially symmetric response function representing diffusion signal attenuation measured from a single coherently oriented fiber population[24], written as(2)R(v,g)=exp−μb(gTv)2whereμ=(λmax−λ¯)denotes anisotropy interaction to signal attenuation which can be estimated from the signal attenuation in areas of a single z-aligned rotationally symmetric fiber population with the eigenvalues[λmax,λ¯,λ¯]. The HOT-ODF functionD(v)is approximated using a Cartesian tensor [16]. For the lth order tensor, it reads(3)D(v)=∑r=0l∑s=0l−rdrsv1rv2sv3l−r−swherev=(v1,v2,v3)Tis the 3-dimensional unit vector, and drsare the tensor coefficients. For convenience, Eq. (3) can also be expressed as(4)D(v,x)=∑j=1mxjfj(v)where xjare the coefficients related to the tensor coefficients drs, andfj(v)=v1rv2sv3l−r−sare the jth tensor monomials withj=r(l−r−32)+s+1. The number of terms in the summation in Eq. (4) is bounded by the number of unique monomials, that is, m≤(l+1)(l+2)/2.Given a data set of DW-MRI signal attenuations S(gi)/S0 associated with magnetic gradient orientations giand diffusion weighted b-values b, the coefficients of an lth order tensor can be estimated by minimizing the following energy function with respect to the unknown polynomial coefficients(5)E=∑i=1nS(gi)/S0−∫S2R(v,gi)D(v,x)dv2=∑i=1nS(gi)/S0−∑j=1mxj∫S2e−μb(giTv)2fj(v)dv2Estimating the HOT coefficients in (5) constitutes a discrete inverse problem of the form(6)y=Ax+ξwhere A is an n×m matrix withAij=∫s2e−μb(giTv)2fj(v)dv, x is an m-dimensional vector that contains the unknown coefficients xj, y is an n-dimensional vector with yi=S(gi)/S0, and ξ represents the noise and measurement errors, represented as Rician noise in this work. The scale of the problem is related to the tensor order l and the magnetic field gradient direction number n. HOT helps improve the angular resolution of crossing fibers. However, it becomes a large-scale inverse problem as the tensor order and gradient direction number increase. The diffusion signal y is also contaminated by noise and measurement errors in practice. Hence, the system of linear (6) is typically very ill conditioned, and directly applying the least squares method [25] results in a solution dominated by noise that bears little resemblance to the true distribution of the fiber orientation. As a result, the angular resolution cannot be further increased when the tensor order is greater than four. Regularization is necessary to stabilize the problem and to define a unique solution.A common regularization approach is the penalized least squares. The Tikhonov regularization scheme with spherical harmonic functions, which is the non-negativity constrained spherical deconvolution (super-CSD) proposed by [8], involves minimizing the weighted sum of two terms(7)minxAx−y22+φ2Lx22where φ is the regularization parameter, and L is the constraint matrix that contains prior information on the smoothness of the exact solution. However, Tikhonov regularization results in a reduced overall mean square error through a bias-variance tradeoff. A problem of the Tikhonov regularization approach is that every element of x in the estimated solution is generally non-zero and non-negative, while the true solution involves only a subset of non-zero elements. Consequently, the solution of (7) is generally non-sparse.Sparse approximation methods are widely applied in the context of linear inverse problems of the form (6)[26,27]. The goal is to find a solution that accounts for the observed data using only a small subset of the elements of x. The true distribution of the fiber orientation can be considered sparse with the assumption that only a small number of the elements of x are non-zero. They produce a maximally sparse representation of an observed signal y by minimizing the l0 problem(8)minxx0s.t.Ax−y2≤ξwhere.0is the number of non-zero elements. Considering that only several fiber populations exist inside a voxel, they then assume the existence of less than k fiber bundles inside a voxel. The elements of (8) can be combined in seeking the minimal error possible at a given level of sparsity kminxAx−y2s.t.x0≤kThe essence of minimizing the l0 problem is an NP-hard problem.11NP-hard (Non-deterministic Polynomial-time hard), in computational complexity theory, is a class of problems that are, informally, at least as hard as the hardest problems in NP.It is usually relaxed as an l1 problem. Daducci et al. [12] usesωx1to approximatex0, which leads to the l1 problemminxAx−y2s.t.ωx1≤kwhereωx1defines a group of convex constraints by weighing the prior information. The sparse elements of x tend to zero with the iterative updating of ω. Here, the updating strategy of weight ω(t+1)=(1/xit). It can also be rewritten using parameter λ≥0 to balance the twin objectives of minimizing both error and sparsity(9)minxAx−y22+λωx1In problems (8) and (9), the sparsity constraint of FOD is imposed on the coefficient x. Our goal in this work is to adequately characterize the actual sparsity lying in the FOD domain.Our FOD sparsity is based on the assumption that only a small number of the FOD values are non-zero. Therefore, unlike (8), the new sparse representation of FOD is provided by minimizing the l0 problem(10)minxD(v,x)0s.t.Ax−y2≤ξwhereD(v,x)=xFwith x=[x1, x2, …, xm]TandF=[f1(v),f2(v),…,fm(v)]is the FOD values computed from the HOT-ODF in Eq. (4). It can also be relaxed as an l1 problem as in (10)(11)minxAx−y22+λωD(v,x)1The sparse elements ofD(v,x)tend to zero with the iterative updating of ω. The updating strategy of weight ω is defined here as(12)ωi(t+1)=▽(Di(v,x)(t),β)Di(v,x)(t)+δwhere∇(Di,β)=0|Di|≤β1|Di|>β, β is a given vector with positive elements with the same size of Di; δ is a positive constant to prevent the denominator of the weight is zero in iteration, therefore it is set to a very small number (δ=10−3 in this work). The functions of (9) and (11) are typical lasso-type optimization problems, which have been proven to be convex, albeit not strictly so; thus the solutions are not unique. One possible means of coping with the previous problems is to consider the elastic net model(13)minxAx−y22+λ(αωD(v,x)1+(1−α)ψD(v,x)22)where parameter λ balances the sparsity constraint term and the noise term. We assume that λ is a Gauss distribution of normalized D,λ=c1e−Dˆ, whereDˆ=x−minDmax(D)−min(D)is the minimum normalized D. Note that max(D)−min(D) is usually constant in the unit space, so we simply set λ=e−[D−min(D)]. Parameter α∈[0, 1] controls the amount of sparsity and smoothness (α=0 gives the group-lasso fit for smoothness, α=1 gives the lasso fit to encourage sparsity). In this work, we expect strong overall sparsity and also would like to encourage grouping and use α=0.5 with reasonable success. Parameter ψ is the constraint vector with elements(14)ψi=0|Di|>τ1|Di|≤τwhere τ is a user-specified threshold controlling the amplitude below which the corresponding fiber orientation density is assumed to zero. A simple iterative algorithm can be obtained using convex analysis tools. The main steps of our algorithm are shown as Algorithm 1. In the algorithm, parameter ɛ should be chosen as a small number such that the algorithm converges to a local minimum of Eq. (13). Here we set as ɛ=10−3.Algorithm 1Sparse deconvolution with HOT.Input:Diffusion MRI attenuation signal y∈Rn.Output:x∈Rm1:Set order l tensor coefficients:λ, A∈Rn×m2:Solve the problem:x(0)←argminAx−y223:Compute the weights ω, ψ with (12) and (14), t←14:Repeat: Solve the problem:x(t)←argminAx−y22+λ(αωD(v,x)1+(1−α)ψD(v,x)22)Update the weights ω, ψ with (12) and (14), t←t+1Until: Stopping criterionx(t)−x(t−1)2<ɛis satisfied5:x←x(t), end;6:returnx.

@&#CONCLUSIONS@&#
