@&#MAIN-TITLE@&#
Knapsack problems with sigmoid utilities: Approximation algorithms via hybrid optimization

@&#HIGHLIGHTS@&#
Root cause analysis of hardness of problems with sigmoid utility.Design of hybrid algorithms merging continuous and discrete optimization.Constant factor algorithm for knapsack problem with sigmoid utility.Constant factor algorithm for generalized assignment problem with sigmoid utility.Approximation algorithm for bin-packing problem with sigmoid utility.

@&#KEYPHRASES@&#
Sigmoid utility/S-curve,Knapsack problem,Generalized assignment problem,Bin-packing problem,Multi-choice knapsack problem,Human attention allocation,

@&#ABSTRACT@&#
We study a class of non-convex optimization problems involving sigmoid functions. We show that sigmoid functions impart a combinatorial element to the optimization variables and make the global optimization computationally hard. We formulate versions of the knapsack problem, the generalized assignment problem and the bin-packing problem with sigmoid utilities. We merge approximation algorithms from discrete optimization with algorithms from continuous optimization to develop approximation algorithms for these NP-hard problems with sigmoid utilities.

@&#INTRODUCTION@&#
With the inception of the National Robotic Initiative (Guizzo, 2011), the research in the field of human–robot interaction has burgeoned. Design of robotic partners that help human operators better interact with the automaton has received significant emphasis. In complex and information rich operations, one of the key roles for these robotic partners is to help human operators efficiently focus their attention. For instance, consider a surveillance operation that requires human operators to monitor the evidence collected by autonomous agents (Bulkeley, 2009; Drew, 2010). The excessive amount of information available in such systems often results in poor decisions by human operators (Shanker & Richtel, 2011). In this setting, the robotic partner may suggest to operators the optimal duration (attention) to be allocated to each piece of evidence. To this end, the robotic partner requires efficient attention allocation algorithms for human operators.In this paper we study certain non-convex resource allocation problems with sigmoid utilities. Examples of sigmoid utility functions include the correctness of human decisions as a function of the decision time (Bogacz, Brown, Moehlis, Holmes, & Cohen, 2006; Pew, 1969; Wickens & Hollands, 2000), the effectiveness of human–machine communication as a function of the communication rate (Wickens & Hollands, 2000), human performance in multiple target search as a function of the search time (Hong & Drury, 2002), advertising response as a function of the investment (Vakratsas, Feinberg, Bass, & Kalyanaram, 2004), and the expected profit in bidding as a function of the bidding amount (Rothkopf, 1977). We present versions of the knapsack problem (KP), the bin-packing problem (BPP), and the generalized assignment problem (GAP) in which each item has a sigmoid utility. If the utilities are step functions, then these problems reduce to the standard knapsack problem, the bin-packing problem, and the generalized assignment problem (Korte & Vygen, 2007; Martello & Toth, 1990), respectively. Similarly, if the utilities are concave functions, then these problems reduce to standard convex resource allocation problems (Ibaraki & Katoh, 1988). We will show that with sigmoid utilities optimization problems become a hybrid of discrete and continuous optimization problems.KPs (Kellerer, Pferschy, & Pisinger, 2004; Korte & Vygen, 2007; Martello & Toth, 1990) have been extensively studied. Considerable emphasis has been on the discrete KP (Korte & Vygen, 2007) and KPs with concave utilities (Bretthauer & Shetty, 2002). Non-convex KPs also have received a significant attention. Kameshwaran and Narahari (2009) study KPs with piecewise linear utilities. Moré and Vavasis (1990) and Burke, Geunes, Romeijn, and Vakharia (2008) study KPs with convex utilities. In an early work, Ginsberg (1974) studies a KP in which items have identical sigmoid utilities. Freeland and Weinberg (1980) discuss the implications of sigmoid functions on decision models. They present an approximation algorithm for the KP with sigmoid utilities that replaces the sigmoid functions with their concave envelopes and solves the resulting convex problem. In a recent work, Ağrali and Geunes (2009) consider the KP with sigmoid utilities and show that this problem is NP-hard. They relax the problem by constructing concave envelopes of the sigmoid functions and then determine the global optimal solution using branch and bound techniques. They also develop a fully polynomial-time approximation scheme (FPTAS) for the case in which decision variables are discrete.Attention allocation for human operators has been a topic of increased research recently. In particular, the sigmoid performance functions of the human operator serving a queue of decision-making tasks have been utilized to develop optimal attention allocation policies for the operator in Srivastava, Carli, Bullo, and Langbort (2011) and Srivastava, Carli, Langbort, and Bullo (in press). Bertuccelli, Beckers, and Cummings (2010) study an optimal scheduling problem in human supervisory control. They determine a sequence in which the tasks should be serviced so that the accumulated reward is maximized.We study optimization problems with sigmoid utilities. In the context of resource allocation problems, we show that a sigmoid utility renders a combinatorial element to the problem, and the amount of resource allocated to the associated item under an optimal policy is either zero or more than a critical value. Thus, optimization variables have both continuous and discrete features. We exploit this interpretation of optimization variables and merge algorithms from continuous and discrete optimization to develop efficient hybrid algorithms.We study versions of the KP, the GAP and the BPP in which utilities are sigmoid functions of the resource allocated. In particular, we study the following problems:First, given a set of items, a single knapsack with a fixed amount of the resource, and the sigmoid utility of each item, determine the optimal resource allocation to each item.Second, given a set of items, multiple knapsacks, each with a fixed amount of resource, and the sigmoid utility of each item-knapsack pair, determine the optimal assignments of items to knapsacks and the associated optimal resource allocation to each item.Third, consider a set of items with their sigmoid utilities, and an unlimited number of bins with a fixed amount of the resource available at each bin. Determine the minimum number of bins, and a mapping of each item to some bin such that an optimal allocation in the first problem is non-zero for each item in every bin.These problems model situations in which human operators are looking at the feeds from a camera network and are deciding whether some malicious activity is present. The first problem determines the optimal duration operators should allocate to each feed such that their overall performance are optimal. The second problem determines the optimal feed assignments to identical and independently working operators as well as the optimal duration allocation for each operator. Assuming that the operators work in an optimal fashion, the third problem determines the minimum number of operators required and feed-assignments to operators such that each operator allocates a non-zero duration to each feed.For clarity of presentation, discussions herein address these problems in the context of human decision-making. Following up on the examples of sigmoid performance functions mentioned earlier, the solutions to these problems can also be used to determine optimal human–machine communication policies, search strategies, advertisement duration allocation, and bidding strategies.The major contributions of this work are fourfold. First, we investigate the root-cause of combinatorial effects in optimization problems with sigmoid utilities. We show that for a sigmoid function subject to a linear penalty, the optimal allocation jumps down to zero with increasing penalty rate. This jump in the optimal allocation imparts combinatorial effects to optimization problems involving multiple sigmoid functions.Second, we study the KP with sigmoid utilities and determine a constant factor approximation algorithm for it. Our approach relies on the above combinatorial interpretation of the sigmoid functions and utilizes a combination of approximation algorithms for the binary KP and algorithms for continuous univariate optimization.Third, we study the GAP with sigmoid utilities. We first show that the GAP with sigmoid utilities is NP-hard. We then use a KP-based algorithm for the binary GAP to develop an equivalent algorithm for the GAP with sigmoid utilities.Fourth and finally, we study the BPP with sigmoid utilities. We first show that the BPP with sigmoid utilities is NP-hard. We then utilize the solution of the KP with sigmoid utilities to develop a next-fit-type algorithm for the BPP with sigmoid utilities.The remainder of the paper is organized in the following way. We highlight the root cause of combinatorial effects in optimization problems with sigmoid utilities in Section 2. We study the knapsack problem with sigmoid utilities, the generalized assignment problem with sigmoid utilities, and the bin-packing problem with sigmoid utilities in Sections 3–5, respectively. Our conclusions are presented in Section 6.In this section we formally define sigmoid functions, explore their connections with human decision-making, and study the maximization of a sigmoid function with a linear penalty.A Lipschitz-continuous functionf:R⩾0→R⩾0defined byf(t)=fcvx(t)1(t<tinf)+fcnv(t)1(t⩾tinf),wherefcvxandfcnvare monotonically non-decreasing convex and concave functions, respectively,1(·)is the indicator function, andtinfis the inflection point. The sub-derivative of a sigmoid function is unimodal and achieves its maximum attinf. Moreover,limt→+∞∂f(t)=0, where∂frepresents the sub-derivative of the function f. A typical graph of a smooth sigmoid function and its derivative is shown in Fig. 1.Remark 1Non-smooth sigmoid functionsFor ease of presentation, we focus on smooth sigmoid functions in this paper. Our analysis extends immediately to non-smooth functions by using the sub-derivative instead of the derivative. □In several interesting budget allocation problems, e.g., (Rao & Rao, 1983), the sigmoid utilities are not non-decreasing functions. The algorithms proposed in this paper involve certain performance improvement heuristics that exploit the monotonicity of the utility function and hence, do not apply to problems with such sigmoid utilities. However, the proposed algorithms without the performance improvement heuristics apply to such problems, and the obtained solution is within a constant factor of the optimal.□As discussed in the introduction, sigmoid functions model the utility in several contexts. Herein, we focus on one particular context, namely, human decision-making, and detail the significance of sigmoid functions. Consider a scenario in which a human subject is exposed to a noisy stimuli for a given amount of time. Then the human subject makes a decision on the presence or absence of a signal in the stimuli. In this scenario, the probability of the human decision being correct as a function of the allocated time is modeled well by a sigmoid function. We now briefly describe some models from the human-factors and the cognitive psychology literature that suggest that a sigmoid function is an appropriate measure of the correctness of the human decision:Pew’s model:For a two-alternative forced choice task, the probability of the correct decisionD1given that the hypothesisH1is true and t units of time have been spent to make the decision is:P(D1∣H1,t)=p01+e-(at-b),wherep0∈[0,1],a,b∈Rare some parameters specific to the human operator (Pew, 1969). Thus, according to Pew’s model, the probability of the correct decision is a sigmoid function of the time spent to make the decision.For a two alternative forced choice task, conditioned on the hypothesisH1, the evolution of the evidence for decision making is modeled as a drift–diffusion process (Bogacz et al., 2006). That is, for a given drift rateβ∈R>0, and a diffusion rateσ∈R>0, the evidenceΛat time t is normally distributed with meanβtand varianceσ2t. The decision is made in favor ofH1if the evidence is greater than a decision thresholdη∈R>0. Therefore, the conditional probability of the correct decisionD1given that the hypothesisH1is true and t units of time have been spent to make the decision is:P(D1∣H1,t)=12πσ2t∫η+∞e-(Λ-βt)22σ2tdΛ,which is a sigmoid function of the time spent to make the decision.Reaction times of a human operator in several missions have been studied (Southern, 2010) and are shown to follow a log-normal distribution. In this context, a relevant performance function is the probability that the operator reacts within a given time. This corresponds to the cumulative distribution function of the log-normal distribution, which is a sigmoid function of the given time.In order to gain insight into the behavior of sigmoid functions, we start with a simple problem with a very interesting result. We study the maximization of a sigmoid function subject to a linear penalty. In particular, given a sigmoid function f and a penalty ratec∈R>0, we study the following problem:(1)maximizet≥0f(t)-ct.The derivative of a sigmoid function is not a one-to-one mapping and hence, it is not invertible. We define the pseudo-inverse of the derivative of a sigmoid function f with inflection pointtinf,f†:R>0→R⩾0by(2)f†(y)=max{t∈R⩾0∣f′(t)=y},ify∈(0,f′(tinf)],0,otherwise.Lemma 1A sigmoid function with a linear penaltyFor the optimization problem(1), the optimal allocationt∗ist∗≔argmax{f(β)-cβ∣β∈{0,f†(c)}}.The global maximum lies at the point where the first derivative is zero or at the boundary. The first derivative of the objective function isf′(t)-c. Iff′(tinf)<c, then the objective function is a decreasing function of time, and the maximum is achieved att∗=0. Otherwise, a critical point is obtained by setting the first derivative to zero. We note thatf′(t)=chas at most two roots. If there are two roots, then only the larger root lies in the region where the objective function is concave and hence corresponds to a maximum. Otherwise, the only root lies in the region where the objective function is concave and hence corresponds to a local maximum. The global maximum is determined by comparing the local maximum with the value of the objective function at the boundaryt=0. □The optimal solution to problem (1) for different values of penalty rate c is shown in Fig. 2. The optimal allocation jumps down to zero at a critical penalty rate. This jump in the optimal allocation gives rise to combinatorial effects in problems involving multiple sigmoid functions.Definition 1Critical penalty rateFor the optimization problem (1), the maximum penalty rate that yields a non-zero solution is referred to as the critical penalty rate. Formally, for a given sigmoid function f and a penalty ratec∈R>0, let the solution of the problem (1) betf,c∗. Then, the critical penalty rateψfis defined byψf=max{c∈R>0∣tf,c∗∈R>0}.In this section, we consider the KP with sigmoid utilities. We first define the problem and then develop an approximation algorithm for it.Consider a single knapsack and N items. Let the utility of itemℓ∈{1,…,N}be a sigmoid functionfℓ:R⩾0→R⩾0. Given the total available resourceT∈R>0, the objective of the KP with sigmoid utilities is to determine the resource allocation to each item such that the total utility of the knapsack is maximized. Formally, the KP with sigmoid utilities is posed as:(3)maximizet⪰0∑ℓ=1Nfℓ(tℓ)subject to∑ℓ=1Ntℓ⩽T.In (3), without loss of generality, we assume that the decision variables in the resource constraint and the sigmoid utilities in the objective function are unweighted. Indeed, if the weights on the decision variables in the resource constraint are non-unity, then the weighted decision variable can be interpreted as a new scaled decision variable; while a weighted sigmoid utility is again a sigmoid utility.The KP with sigmoid utilities models the situation in which a human operator has to perform N decision-making tasks within time T. If the performance of the human operator on taskℓis given by the sigmoid functionfℓ, then the optimal duration allocation to each task is determined by the solution of problem (3). We now state the following proposition from Ağrali and Geunes (2009):Proposition 2Hardness of the KP with sigmoid utilitiesThe KP with sigmoid utilities is NP-hard, unless P=NP.We now present a simple example to illustrate that a naive concave relaxation of the KP with sigmoid utilities (3) may lead to an arbitrarily bad performance.Example 1Performance of a naive concave relaxationConsider an instance of the KP with sigmoid utilities in which each sigmoid utility is identical and is defined byf(t)=1/(1+exp(-t+5)). Let the total available resource beT=8units and the number of items beN=10. The optimal solution obtained using the procedure outlined later in the paper is to allocate the entire resource to a single item and accordingly, allocate zero resource to every other item. The value of the objective function under such an optimal policy is 0.9526.We now consider the solution to this problem obtained by a popular concave relaxation scheme. In particular, we consider the solution obtained by replacing each sigmoid function with its concave envelope (see Fig. 3). An optimal solution to the resulting relaxed maximization problem istℓ=T/N, for eachℓ∈{1,…,N}. The value of the objective function under this solution is 0.1477. Thus, the concave envelope-based policy performs badly compared to an optimal policy. In fact, the performance of the concave envelope-based policy can be made arbitrarily bad by increasing the number of items.□Example 1 highlights that a naive concave envelope based approach may yield an arbitrarily bad performance. While such a performance can be improved using existing branch-and-bound methods (Ağrali & Geunes, 2009), but in general, branch-and-bound methods may have an exponential run time. In the following, we develop an approximation algorithm for the KP with sigmoid utilities that is within a constant factor of the optimal and has a polynomial run time.We define the LagrangianL:R>0N×R⩾0×R≥0N→Rfor the knapsack problem with sigmoid utilities (3) byL(t,α,μ)=∑ℓ=1Nfℓ(tℓ)+α(T-∑ℓ=1Ntℓ)+μTt,whereα∈R⩾0andμ∈R≥0Nare Lagrange multipliers associated with the resource constraint and non-negativity constraints, respectively. Lettℓinfbe the inflection point of the sigmoid functionfℓandfℓ†be the pseudo-inverse of its derivative as defined in Eq. (2). We define the maximum value of the derivative of the sigmoid functionfℓbyαℓ=fℓ′(tℓinf). We also defineαmax=max{αℓ∣ℓ∈{1,…,N}}. We will later show thatαmaxis the maximum possible value of an optimal Lagrange multiplier associated with the resource constraint.We define the set of inconsistent sigmoid functions byI={ℓ∈{1,…,N}∣tℓinf>T}, i.e., the set of sigmoid functions for which any feasible allocation is in the convex part of the sigmoid function. Similarly and accordingly, we define the set of consistent sigmoid functions as{1,…,N}⧹I. We will show that for an inconsistent sigmoid function, the optimal allocation is either zero or T. We denote the j-th element of the standard basis ofRNbyej.Since constraints in (3) are linear, the solution to (3) is regular, and hence the Karush–Kuhn–Tucker (KKT) conditions for optimality hold (Rockafellar, 1993). We will show that for a fixed value of the Lagrange multiplierαand consistent sigmoid functions, the KKT conditions reduce the optimization problem (3) to theα-parametrized KP defined by:(4)maximize∑ℓ=1Nxℓfℓ(fℓ†(α))subject to∑ℓ=1Nxℓfℓ†(α)⩽Txℓ∈{0,1},∀ℓ∈{1,…,N}.DefineF:(0,αmax]→R⩾0as the optimal value of the objective function in theα-parametrized KP (4).For a fixed value ofα, (4) is a binary KP which is NP-hard. We now relax (4) to the followingα-parametrized fractional KP:(5)maximize∑ℓ=1Nxℓfℓ(fℓ†(α))subject to∑ℓ=1Nxℓfℓ†(α)⩽Txℓ∈[0,1],∀ℓ∈{1,…,N}.DefineFLP:(0,αmax]→R⩾0as the optimal value of the objective function in theα-parametrized fractional KP (5). For a givenα, the solution to problem (5) is obtained in the following way:(i)sort tasks such thatf1(f1†(α))f1†(α)⩾f2(f2†(α))f2†(α)⩾⋯⩾fN(fN†(α))fN†(α);findk≔min{j∈{1,…,N}∣∑i=1jfi†(α)⩾T};the solution isx1LP=x2LP=⋯=xk-1LP=1,xkLP=(T-∑i=1k-1fi†(α))/fk†(α), andxk+1LP=xk+2LP=⋯=xNLP=0.A 2-factor solution to the binary KP (4) is obtained by performing the first two steps in the above procedure, and then picking the better of the two sets{1,…,k-1}and{k}(see Kellerer et al., 2004; Korte & Vygen, 2007 for details). LetFapprox(0,αmax]→R⩾0be the value of the objective function in theα-parametrized knapsack problem under such a 2-factor solution.If the optimal Lagrange multiplierαis known, then the aforementioned procedure can be used to determine a solution to (3) that is within a constant factor of the optimal. We now focus on the search for an efficient Lagrange multiplierα. We will show that an efficient solution can be computed by picking the maximizer ofFLPas the Lagrange multiplier. The maximizer of a continuous univariate function can be efficiently searched, but unfortunately,FLPmay admit several points of discontinuity. If the set of points of discontinuity is known, then the maximizer over each continuous piece can be searched efficiently. Therefore, we now determine the set of points of discontinuity of the functionFLP.Lemma 3Discontinuity ofFLPThe maximal set of points of discontinuity of the functionFLPis{α1,…,αN}.For eachα∈[0,αmax], theα-parametrized fractional KP is a linear program, and the solution lies at one of the vertex of the feasible simplex. Note that iffℓ†(α)is a continuous function for eachℓ∈{1,…,N}, then the vertices of the feasible simplex are continuous functions ofα. Further, the objective function is also continuous iffℓ†(α)is a continuous function for eachℓ∈{1,…,N}. Therefore,FLPmay be discontinuous only iffℓ†(α)is discontinuous for someℓ, i.e., only ifα∈{α1,…,αN}.□In summary, we will show that if each sigmoid function is consistent, then the allocation to each sigmoid function can be written in terms of the Lagrange multiplierα, and the KP with sigmoid utilities (3) reduces to theα-parametrized KP (4). Further, an efficient Lagrange multiplierαLP∗can be searched in the interval(0,αmax], and theαLP∗-parametrized KP can be solved using standard approximation algorithms to determine a solution within a constant factor of the optimal. The search of an efficient Lagrange multiplier is a univariate continuous optimization problem and a typical optimization algorithm will converge only asymptotically, but it will converge to an arbitrarily small neighborhood of the efficient Lagrange multiplier in a finite number of iterations. Thus, a factor of optimality within an∊neighborhood of the desired factor of optimality, for any∊>0, can be achieved in a finite number of iterations.In Algorithm 1, we utilize these ideas to obtain a solution within(2+∊)-factor of the optimal solution for the KP with sigmoid utilities. The algorithm comprises four critical steps: (i) it searches for the Lagrange multiplierαLP∗that maximizesFLP; (ii) it determines a constant-factor solution to theαLP∗-parametrized KP; (iii) it then comparesFapprox(αLP∗)with the values of the objective function corresponding to the allocations of the formTej,j∈{1,…,N}, and picks the best among these policies; and (iv) it involves a performance-improvement heuristic in which the unemployed resource is allocated to the most beneficial item.Note that step (iii) takes care of inconsistent sigmoid utilities. In particular, we will show that the allocation to an item with an inconsistent sigmoid utility is either zero or T, and thus, if a non-zero resource is allocated to an item with an inconsistent sigmoid utility, then every other item is allocated zero resource.We now establish the performance of Algorithm 1. We define an∊-approximate maximizer of a function as a point in the domain of the function at which the function attains a value within∊of its maximum value. We now analyze Algorithm 1. We note that if the sigmoid utilities are non-smooth, then the standard KKT conditions in the following analysis are replaced with the KKT conditions for non-smooth optimization problems (Hiriart-Urruty, 1978).Algorithm 1KP with Sigmoid Utilities: Approximation AlgorithmThe following statements hold for the KP with sigmoid utilities(3)and the solution obtained via Algorithm1:(i)the solution is within a factor of optimality(2+∊), for any∊>0;if an∊-approximate maximizer over each continuous piece ofFLPcan be searched using a constant number of function evaluations, then Algorithm1runs inO(N2)time.See Appendix. □If the sigmoid utilities in the KP with sigmoid utilities(3)are identical and equal to f, then an optimal solutiont∗is an N-tuple withm∗entries equal toT/m∗and all other entries zero, where(6)m∗=argmaxm∈{1,…,N}mf(T/m).It follows from Algorithm 1 that for identical sigmoid utilities the optimal non-zero resource allocated is the same for each item. The number of items with the optimal non-zero resource is determined by Eq. (6), and the statement follows. □The approximate solution to the KP with sigmoid utilities in Algorithm 1 involves the search forαLP∗, the maximizer of functionFLP. It follows from Lemma 3 that this search corresponds to the global maximization of N univariate continuous functions. The global maximum over each continuous piece can be determined using the P-algorithm (Calvin, 1999; Kushner, 1964). If stronger properties ofFLPcan be established for a given instance of the KP with sigmoid utilities, then better algorithms can be utilized, e.g., (i) if each continuous piece ofFLPis differentiable, then the modified P-algorithm (Calvin & Žilinskas, 1999) can be used for global optimization; (ii) if each continuous piece ofFLPis Lipschitz, then one of the algorithms in Hansen, Jaumard, and Lu (1992) can be used for global optimization.□Given sigmoid functionsfℓ(t)=wℓ/(1+exp(-aℓt+bℓ)),ℓ∈{1,…,10}with parameters and associated weightsa=(a1,…,a10)=(1,2,1,3,2,4,1,5,3,6),b=(b1,…,b10)=(5,10,3,9,8,16,6,30,6,12),andw=(w1,…,w10)=(2,5,7,4,9,3,5,10,13,6).Let the total available resource beT=15units. The optimal solution and the approximate solution without the heuristic in step 6 of Algorithm 1 are shown in Fig. 4. The approximate solution with the heuristic in step 6 of Algorithm 1 is the same as the optimal solution. The value functionsF,Fapprox, andFLPare shown in Fig. 5. □Consider m disjoint classes{N1,…,Nm}of items and a single knapsack. The multiple-choice KP is to select one item each from every class such that the total utility of the selected items is maximized for a given total available resource. Let the total available resource beT∈R>0, and let the utility of allocating a resourcet∈R⩾0to item i in classNjbe a sigmoid functionfij:R⩾0→R⩾0. The multiple-choice KP with sigmoid utilities is posed as:(7)maximize∑i=1m∑j∈Nifij(tij)xijsubject to∑i=1m∑j∈Nitijxij⩽T∑j∈Nixij=1,i∈{1,…,m}xij∈{0,1},i∈{1,…,m},j∈Ni.Given a set of classes of tasks, the multiple-choice KP with sigmoid utilities models a situation where a human operator has to process one task each from every class within time T. The performance of the operator on task i from classNjis given by the sigmoid functionfij. Different tasks in a given class may be, e.g., observations collected from different sensors in a given region. The methodology developed in this section extends to the multiple-choice KP with sigmoid utilities (7). In particular, problem (7) can be reduced to anα-parameterized multiple-choice knapsack problem, and the LP relaxation based 2-factor approximation algorithm for the binary multiple choice knapsack problem (Kellerer et al., 2004) can be utilized to determine a 2-factor algorithm for problem (7). □The KP with sigmoid utilities (3) also models the resource allocation problem in queues with sigmoid server performance functions. In particular, consider a single server queue with a general arrival process and a deterministic service process. Let the tasks arrive according to some process with a mean arrival rateλ. Let the tasks be indexed by the set{1,…,N}, and let each arriving task be sampled from a stationary probability vector{p1,…,pN}, i.e., at any time the next task arriving to the queue is indexedℓwith probabilitypℓ. Let the performance of the server on a task with indexℓbe a sigmoid functionfℓof the service time. A stationary policy for such a queue always allocates a fixed durationtℓ∈R⩾0to a task with indexℓ. An optimal stationary policy is a stationary policy that maximizes the expected performance of the server while keeping the queue stable. The stability constraint on the queue implies that the average allocation to each task should be smaller than1/λ. Accordingly, the optimal stationary policy is determined by:maximizet⪰0∑ℓ=1Npℓfℓ(tℓ)subject to∑ℓ=1Npℓtℓ⩽1λ,which is a KP with sigmoid utilities. □In this section, we consider the GAP with sigmoid utilities. We first define the problem and then develop an approximation algorithm for it.Consider M bins (knapsacks) and N items. LetTjbe the total available resource at binj∈{1,…,M}. Let the utility of itemi∈{1,…,N}when assigned to bin j be a sigmoid functionfij:R≥0→R⩾0of the allocated resourcetij. The GAP with sigmoid utilities determines the optimal assignment of the items to the bins such that the total utility of the bins is maximized. Note that unlike the assignment problem, the generalized assignment problem does not require every item to be allocated to some bin. Formally, the GAP with sigmoid utilities is posed as:(8)maximize∑j=1M∑i=1Nfij(tij)xijsubject to∑i=1Ntijxij⩽Tj,j∈{1,…,M}∑j=1Mxij⩽1,i∈{1,…,N}xij∈{0,1},i∈{1,…,N},j∈{1,…,M}.The GAP with sigmoid utilities models a situation where M human operators have to independently serve N tasks. The performance of operator j on task i is given by the sigmoid functionfij, and she works for a total durationTj. The solution to the GAP determines optimal assignments of the tasks to the operators and the associated optimal duration allocations. We now state the following result about the hardness of the GAP with sigmoid utilities:Proposition 6Hardness of GAP with sigmoid utilitiesThe GAP with sigmoid utilities is NP-hard, unless P=NP.The statement follows from the fact that the KP with sigmoid utilities is a special case of the GAP with sigmoid utilities, and is NP-hard according to Proposition 2.□We now propose an approximation algorithm for the GAP with sigmoid utilities. This algorithm is an adaptation of the 3-factor algorithm (Cohen, Katzir, & Raz, 2006) for the binary GAP and is presented in Algorithm 2. We first introduce some notation. Let F be the matrix of sigmoid functionsfij,i∈{1,…,N},j∈{1,…,M}. LetF∗ℓdenote theℓth column of the matrix F. For a given matrix E, let us denoteE∗k:m,k⩽mas the sub-matrix of E comprising of all the columns ranging from the kth column to the mth column. For a given set of allocationstij,i∈{1,…,N},j∈{1,…,M}and a setA¯⊆{1,…,N},tA¯jrepresents the vector with entriestij,i∈A¯. Similarly, for a given setIunproc⊆{1,…,N},FIunprocjrepresents the vector with entriesFij,i∈Iunproc. LetKP(·,·)be the function which takes a set of sigmoid utilities and the total available resource as inputs and yields allocations according to Algorithm 1.Algorithm 2 calls a recursive functionGAP(·,·)with the input(1,F)to compute an approximate solution to the GAP with sigmoid utilities. The output of Algorithm 2 comprises a set A describing assignments of the items to the bins and a matrixtdescribing the associated duration allocations.The functionGAP(·,·)takes an indexℓ∈{1,…,M}and the matrix of sigmoid utilitiesfijℓ,i∈{1,…,N},j∈{ℓ,…,M}as the input and yields assignments of the items to the bin set{ℓ,…,M}and the associated duration allocations. The functionGAP(ℓ,F(ℓ))first determines a temporary set of assignments and the associated duration allocations for theℓth bin using Algorithm 1 with the sigmoid utilities in the first column ofF(ℓ)and the total available resource at theℓth bin.The function GAP then decomposes the matrixF(ℓ)into two matricesE1andE2such thatF(ℓ)=E1+E2. The matrixE1is constructed by (i) picking its first column as the first column ofF(ℓ), (ii) picking the remaining entries of the rows associated with the items temporarily assigned to theℓth bin as the value of the sigmoid function in the first column computed at the associated temporary allocation, and (iii) picking all other entries as zero. The matrixE2is chosen asE2=F(ℓ)-E1. The key idea behind this decomposition is that the matrixE2has all the entries in the first column equal to zero, and thus, effectively contains onlyM-ℓcolumns of sigmoid utilities.The function GAP then removes the first column ofE2, assigns the resulting matrix toF(ℓ+1), and calls itself with the input(ℓ+1,F(ℓ+1)). The recursion stops atℓ+1=M, in which caseF(ℓ+1)is a column vector, and the assignments with the associated allocations are obtained using Algorithm 1.Algorithm 2 also involves a performance-improving heuristic. According to this heuristic, if the total available resource at a bin is not completely utilized and there are tasks that are not assigned to any bin, then a KP with sigmoid utilities is solved using the remaining amount of the resource and unassigned tasks. Likewise, if the total available resource at a bin is not completely utilized and each task has been assigned to some bin, then the remaining resource is allocated to the most beneficial task in that bin.Algorithm 2GAP with Sigmoid Utilities: 3-factor ApproximationWe now establish performance bounds for the proposed algorithm:Theorem 7GAP with sigmoid utilitiesThe following statements hold for the GAP with sigmoid utilities(8)and the solution obtained via Algorithm2:(i)The solution is within a factor(3+∊)of the optimal, for any∊>0.Algorithm2runs inO(N2M)time, provided the solution to the KP with sigmoid utilities can be computed inO(N2)time.The proof is an adaptation of the inductive argument used in Cohen et al. (2006) to establish the performance of a similar algorithm for the binary GAP. We note that for a single bin, the GAP reduces to the knapsack problem and Algorithm 1 provides a solution within(2+∊)-factor of the optimal. Consequently, Algorithm 2 provides a solution within(2+∊)-factor of the optimal, and hence, within(3+∊)-factor of the optimal.Assume by the induction hypothesis that Algorithm 2 provides a solution within(3+∊)-factor of the optimal for L bins. We now consider the case with(L+1)bins. The performance matrix F has two components, namely,E1andE2. We note that first column ofE2has each entry equal to zero, and thus,E2corresponds to a GAP with L bins. By the induction hypothesis, Algorithm 2 provides a solution within(3+∊)-factor of the optimal with respect to performance matrixE2. We further note that the first column ofE1is identical to the first column of F and Algorithm 1 provides a solution within(2+∊)-factor of the optimal with respect to this column (bin). Moreover, the best possible allocation with respect to other entries can contribute to the objective function an amount at most equal to∑i=1Nfi1(ti1∗). Consequently, the solution obtained from Algorithm 2 is within(3+∊)-factor of the optimal with respect to performance matrixE1. Since the solution is within(3+∊)-factor of the optimal with respect to bothE1andE2, it follows that the solution is within(3+∊)-factor of the optimal with respect toE1+E2(see Theorem 2.1 in Cohen et al. (2006)). The performance improvement heuristic further improves the value of the objective function and improves the factor of optimality. Consequently, the established factor of optimality still holds. This establishes the first statement.The second statement follows immediately from the observation that Algorithm 2 solves2Minstances of knapsack problem with sigmoid utilities using Algorithm 1.□Consider the GAP withM=4bins andN=10items. Let the sigmoid utility associated with bin i and item j befij(t)=1/(1+exp(-t+bij)), where the matrix of parametersbijisb=17238751367988617454610123197959248125868.Let the vector of the total resource available at each bin beT=[5101520]. The resource allocations to different items obtained using Algorithm 2 are shown in Fig. 6. The assignment sets of items to bins areA1={8},A2={10},A3={1,3,4,5}, andA4={2,6,7,9}. □In this section, we consider the BPP with sigmoid utilities. We first define the problem and then develop an approximation algorithm for it.Consider a set of N items with sigmoid utilitiesfℓ,ℓ∈{1,…,N}, and an unlimited number of bins, each with a resourceT∈R>0. The BPP with sigmoid utilities determines the minimum number of binsK∈Nand assignments of items to binsϒ:{1,…,N}→{1,…,K}such that the KP with sigmoid utilities associated with each bin and items assigned to it allocates a non-zero resource to each item in the bin. Formally, letAibe the set of items assigned to bini∈{1,…,K}, that is,Ai={j∈{1,…,N}∣ϒ(j)=i}. Then, the BPP with sigmoid utilities finds the minimum K and setsAi,i∈{1,…,K}such that the optimal solution to the following KP with sigmoid utilities, for eachi∈{1,…,K}, allocates a non-zero resource to each itemℓ∈Ai:(9)maximize∑ℓ∈Aifℓ(tℓ)subject to∑ℓ∈Aitℓ⩽T.The BPP with sigmoid utilities determines the minimum number of identical operators, each working for a total duration T, required to optimally serve each of the N tasks characterized by sigmoid functionsfℓ,ℓ∈{1,…,N}.We will establish that the standard BPP is a special case of the BPP with sigmoid utilities, and consequently, the BPP with sigmoid utilities is NP-hard. To this end, we need to determine an amount of the resource T such that each item in a given setAiis allocated a non-zero resource by the solution to (9) obtained using Algorithm 1. We denote the critical penalty rate for the sigmoid functionfℓbyψℓ,ℓ∈{1,…,N}, and letψmin=min{ψℓ∣ℓ∈{1,…,N}}.Lemma 8Non-zero allocationsA solution to the optimization problem(9)allocates a non-zero resource to each sigmoid functionfℓ,ℓ∈Ai,i∈{1,…,K}, ifT⩾∑ℓ∈Aifℓ†(ψmin).It suffices to prove that ifT=∑ℓ∈Aifℓ†(ψmin), thenψminis the optimal Lagrange multiplierαLP∗in Algorithm 1. Note that if a non-zero resource is allocated to each task, then the solution obtained from Algorithm 1 is the optimal solution to (3). Since,tℓ∗=fℓ†(ψmin),ℓ∈Aiare feasible non-zero allocations,ψminis a Lagrange multiplier. We now prove thatψminis the optimal Lagrange multiplier. LetAi={1,…,ai}. By contradiction, assume thatt∗is not the globally optimal allocation. Without loss of generality, we assume that the global optimal policy allocates zero resource to sigmoid functionfai, and lett¯be the globally optimal allocation. We observe that(10)∑ℓ=1ai-1fℓ(t¯ℓ)+fai(0)⩽∑ℓ=1ai-1fℓ(t¯ℓ)+fai(tai∗)-ψmintai∗(11)⩽∑ℓ=1aifℓ(tℓ∗)+∑ℓ=1ai-1fℓ′(tℓ∗)(t¯ℓ-tℓ∗)-ψmintai∗=∑ℓ=1aifℓ(tℓ∗)+∑ℓ=1aiψmin(t¯ℓ-tℓ∗)=∑ℓ=1aifℓ(tℓ∗)where inequalities (10) and (11) follow from the definition of the critical penalty rate and the concavity to the sigmoid function attℓ∗, respectively. This contradicts our assumption. Hence,t∗is the global optimal allocation and this completes the proof. □We now state the following result about the hardness of the BPP with sigmoid utilities:Proposition 9Hardness of the BPP with sigmoid utilitiesThe BPP with sigmoid utilities is NP-hard, unless P=NP.Consider an instance of the standard BPP with items of sizeai⩽T,i∈{1,…,N}and bins of size T. It is well known (Korte & Vygen, 2007) that the BPP is NP-hard. Without loss of generality, we can pick N sigmoid functionsfi,i∈{1,…,N}such thatfi†(ψmin)=ai, for eachi∈{1,…,N}and someψmin∈R>0. It follows from Lemma 8 that such an instance of the BPP with sigmoid utilities is in a one-to-one correspondence with the aforementioned standard BPP. This establishes the statement.□We now develop an approximation algorithm for the BPP with sigmoid utilities. The proposed algorithm is similar to the standard next-fit algorithm (Korte & Vygen, 2007) for the binary BPP. The algorithm iteratively performs three critical steps: (i) it adds an item to the current bin; (ii) if after the addition of the item, the optimal policy for the associated KP with sigmoid utilities allocates a non-zero resource to each item in the bin, then it assigns the item to the current bin; (iii) otherwise, it opens a new bin and allocates the item to the new bin. This approximation algorithm is presented in Algorithm 3. We now present a formal analysis of this algorithm. We introduce following notations. LetK∗be the number of bins used by the optimal solution to the bin-packing problem with sigmoid utilities, and letKnext-fitbe the number of bins used by the solution obtained through Algorithm 3.Algorithm 3BPP with Sigmoid Utilities: Approx. AlgorithmThe following statements hold for the BPP with sigmoid utilities(9), and its solution obtained via Algorithm3:(i)The optimal solution satisfies the following boundsKnext-fit⩾K∗⩾1T∑ℓ=1Nmin{T,tℓinf}.The solution obtained through Algorithm3satisfiesKnext-fit⩽1T2∑ℓ=1Nmin{T,fℓ†(ψmin)}-1.Algorithm3provides a solution to the BPP with sigmoid utilities within a factor of optimalitymax{2min{T,fℓ†(ψmin)}∣ℓ∈{1,…,N}}max{min{T,tℓinf}∣ℓ∈{1,…,N}};Algorithm3runs inO(N3)time, provided the solution to the KP with sigmoid utilities can be computed inO(N2)time.It follows from Algorithm 1 that iftℓinf<T, then the optimal non-zero allocation to the sigmoid functionfℓis greater thantℓinf. Otherwise, the optimal non-zero allocation is equal to T. Therefore, if each sigmoid function gets a non-zero allocation under the optimal policy, then at least∑ℓ=1Nmin{T,tℓinf}resource is required, and the lower bound on the optimalK∗follows.It follows from Lemma 8 that iftℓ=fℓ†(ψmin)amount of the resource is available for taskℓ, then a non-zero resource is allocated to it. Therefore, the solution of the bin-packing problem with bin size T and items of size{min{T,fℓ†(ψmin)}∣ℓ∈{1,…,N}}provides an upper bound to the solution of the BPP with sigmoid utilities. The upper bound to the solution of this bin-packing problem obtained through the standard next-fit algorithm is(2∑ℓ=1Nmin{T,fℓ†(ψmin)}-1)/T, and this completes the proof of the second statement.The third statement follows immediately from the first two statements, and the last statement follows immediately from the fact that Algorithm 1 is utilized at each iteration of Algorithm 3.□For the same set of sigmoid functions as in Example 2 andT=20units, the solution to the BPP with sigmoid utilities obtained through Algorithm 3 requiresKnext-fit=3bins, and the associated allocations to each task in these bins are shown in Fig. 7.□We studied non-convex optimization problems involving sigmoid functions. We considered the maximization of a sigmoid function subject to a linear penalty and showed that the optimal allocation jumps down to zero at a critical penalty rate. This jump in the allocation imparts combinatorial effects to the constrained optimization problems involving sigmoid functions. We studied three such problems, namely, the KP with sigmoid utilities, the GAP with sigmoid utilities, and the BPP with sigmoid utilities. We merged approximation algorithms from discrete optimization with algorithms from continuous optimization to develop hybrid approximation algorithms for these problems.There are many possible extensions of this work. A similar strategy for approximate optimization could be adopted for other problems involving sigmoid functions, e.g., the network utility maximization problem, where the utility of each source is a sigmoid function. Other extensions include problems involving general non-convex functions and optimization in general queues with sigmoid characteristics.We apply the Karush–Kuhn–Tucker necessary conditions (Luenberger, 1984) for an optimal solution:Linear dependence of gradients(A.1)∂L∂tℓ∗(t∗,α∗,μ∗)=fℓ′(tℓ∗)-α∗+μℓ∗=0,for eachℓ∈{1,…,N}.Feasibility of the solution(A.2)T-1NTt∗⩾0andt∗⪰0.Complementarity conditions(A.3)α∗(T-1NTt∗)=0.(A.4)μℓ∗tℓ∗=0,for eachℓ∈{1,…,N}.Non-negativity of the multipliers(A.5)α∗⩾0,μ∗⪰0.Sincefℓis a non-decreasing function, for eachℓ∈{1,…,N}, the resource constraint should be active, and thus, from complementarity condition (A.3)α∗>0. Further, from Eq. (A.4), iftℓ∗≠0, thenμℓ∗=0. Therefore, if a non-zero resource is allocated to the sigmoid functionfη,η∈{1,…,N}, then it follows from Eq. (A.1)(A.6)fη′(tη∗)=α∗.Assuming that eachfℓis consistent, i.e.,tℓinf⩽T, for eachℓ∈{1,…,N}, the second order condition (Luenberger, 1984) yields that a local maxima exists att∗only if(A.7)fη″(tη∗)⩽0⇔tη∗⩾tηinf.The Eqs. (A.6) and (A.7) yield that the optimal non-zero allocation to the sigmoid functionfηis(A.8)tη∗=fη†(α∗).Given the optimal Lagrange multiplierα∗, the optimal non-zero allocation to the sigmoid functionfηis given by Eq. (A.8). Further, the optimal set of sigmoid functions with non-zero allocations is the solution to theα∗-parametrized KP (4). We now show thatα∗is the maximizer of F. Since, at least one task is processed,fℓ′(tℓ∗)=α, for someℓ∈{1,…,N}. Thus,α∈[0,αmax]. By contradiction assume thatα¯is the maximizer of F, andF(α¯)>F(α∗). This means that the allocation corresponding toα¯yields higher reward than the allocation corresponding toα∗. This contradicts Eq. (A.8).Iftℓinf>T, for someℓ∈{1,…,N}, then Eq. (A.7) does not hold for anytℓ∈[0,T]. Since,fℓis convex in the interval[0,T], the optimal allocation is at the boundary, i.e.,tℓ∈{0,T}. Therefore, as exemplified in Fig. 8, the optimal allocation is eitherTeℓor lies at the projection of the simplex on the hyperplanetℓ=0. The projection of the simplex on the hyperplanetℓ=0is again a simplex and the argument holds recursively.To establish the first statement we note thatαLP∗is the maximizer ofFLP, and theα-parametrized fractional KP is a relaxation of theα-parametrized KP, hence(A.9)FLP(αLP∗)⩾FLP(α∗)⩾F(α∗).We further note thatα∗is the maximizer of F andFapproxis a suboptimal value of the objective function, hence(A.10)F(α∗)⩾F(αLP∗)⩾Fapprox(αLP∗)⩾12FLP(αLP∗),where the last inequality follows from the construction ofFapprox(see 2-factor policy for the binary knapsack problem in Korte & Vygen (2007)). The value of the objective function att†in Algorithm 1 is equal toFapprox(αLP∗). The allocationt†may not saturate the entire resource T. Since, the sigmoid functions are non-decreasing with the allocated resource, entire resource must be utilized, and it is heuristically done in step 6 of Algorithm 1. This improves the value of the objective function and the factor of optimality remains at most 2. Finally, since a numerical method will only compute an∊-approximate maximizer ofFLPin finite time, the factor of optimality increases to(2+∊).To establish the last statement, we note that each evaluation ofFLPrequires the solution of theα-parametrized fractional KP and hasO(N)computational complexity. According to Lemma 3, the maximum number of points of discontinuity ofFLPisN+1. Therefore, if∊-approximate maximizer over each continuous piece ofFLPcan be searched using a constant number of function evaluations, thenO(N)computations are needed over each continuous piece ofFLP. Consequently, the Algorithm 1 runs inO(N2)time.□

@&#CONCLUSIONS@&#
