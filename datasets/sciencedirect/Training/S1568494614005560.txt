@&#MAIN-TITLE@&#
An iterated tabu search heuristic for the Single Source Capacitated Facility Location Problem

@&#HIGHLIGHTS@&#
Studies the Single Source Capacitated Facility Location Problem.Develops an iterated tabu search heuristic.Computational results show that this simple heuristic produces high-quality solutions.

@&#KEYPHRASES@&#
Facility location,Heuristic,Tabu search,

@&#ABSTRACT@&#
This paper discusses the Single Source Capacitated Facility Location Problem (SSCFLP) where the problem consists in determining a subset of capacitated facilities to be opened in order to satisfy the customers’ demands such that total costs are minimized. The paper presents an iterated tabu search heuristic to solve the SSCFLP. The iterated tabu search heuristic combines tabu search with perturbation operators to avoid getting stuck in local optima. Experimental results show that this simple heuristic is capable of generating high quality solutions using small computing times. Moreover, it is also competitive with other metaheuristic approaches for solving the SSCFLP.

@&#INTRODUCTION@&#
One of the most critical decisions in logistics is to decide where to locate the facilities (e.g., warehouses, plants, factories, retailers). This is a decision problem at the strategic level where the implemented decisions remain unchanged for a long period of time. The decisions lead to long-term investments as companies typically invest several millions or even billions of US dollars in building facilities in different regions or countries [1]. The problem of determining new locations for a set of facilities subject to cost minimization is called the Facility Location Problem (FLP) [2–4]. A variant of the FLP is the Capacitated Facility Location Problem (CFLP), where the problem includes capacities for the facilities.There are two levels of decisions involved with the CFLP, namely determining which facilities to open and allocating customers to the opened facilities without violating the capacity constraints. The objective is to minimize the costs of opening the facilities (i.e., fixed costs) and the costs of supplying the customers with goods (i.e., variable costs). There are two versions of the CFLP – multiple sourcing and single sourcing. The more popular one among researchers is the multiple sourcing version. When a customer can be supplied by more than one facility (i.e., multiple sourcing), the sub-problem of the CFLP (i.e., the customer allocation problem) becomes a transportation problem and can be solved efficiently by the transportation simplex algorithm. But if we restrict the possibility of multiple sourcing the customer allocation problem becomes a generalized assignment problem which is anNP-hard problem. Hence, the CFLP with single sourcing is a more difficult problem to solve than the CFLP with multiple sourcing. In this paper, the focus is on the Single Source Capacitated Facility Location Problem (SSCFLP). Despite itsNP-hardness, the SSCFLP serves also as the basis for other more complex problems, e.g., the location-routing problem [5] and the bi-objective SSCFLP [6].Different methods for solving the SSCFLP have been proposed in the literature. These include exact methods, lagrangian relaxations, and heuristics. One of the first exact methods proposed to solve the SSCFLP was developed by Neebe and Rao [7]. They formulated the problem as a set partitioning problem and solved it by a column-generating branch-and-bound procedure. As Lagrangian heuristics have shown to be very successful for solving Facility Location Problems, Holmberg et al. [8] combined a Lagrangian heuristic with a repeated matching heuristic [9] in a branch-and-bound procedure to speed up the bounding process. Few years later, Díaz and Fernández [10] developed an effective branch-and-price algorithm to solve the SSCFLP. The most recent exact method is the cut-and-solve approach proposed by Yang et al. [11]. Their method relies on the lifted cover inequalities and Fenchel cutting planes to strengthen the lower bound of the problem. Lagrangian relaxation-based techniques are very effective in solving the SSCFLP [12]. These techniques usually differ in (i) which constraints are relaxed (i.e., capacity or assignment constraints); and (ii) how a feasible solution can be constructed from the solution of the relaxed problem. In Klincewicz and Luss [13], the capacity constraints are relaxed and the relaxed sub-problem is solved by the dual-ascent algorithm. The Add heuristic is used to generate an initial feasible solution, and a final adjustment heuristic is used to improve the solution by the relaxations. Hindi and Pienkosz [14] developed a heuristic which combined Lagrangian relaxation (the assignment constraints are relaxed) with restricted neighborhood search. Cortinhal and Captivo [15] also relaxed the assignment constraints. Their Lagrangian heuristic consists of two phases. The first phase finds solutions that satisfy the assignment constraints (but not necessarily the capacity constraints), and these solutions are further improved in the second phase using local search and tabu search.Delmaire et al. [16] proposed different heuristics based on evolutionary algorithms, GRASP, and tabu search approaches. Tabu search is embedded in a multi-start heuristic where a number of different initial solutions are generated and the initial solutions are improved using tabu search. Only neighborhoods which do not modify the set of the opened facilities are explored. Diversification is ensured by selecting less-frequently made moves. In their follow-up paper, Delmaire et al. [17] proposed some improving algorithms that are based on their previous work; a reactive GRASP heuristic and some hybrid heuristics. These hybrid heuristics use reactive GRASP to construct a number of different initial solutions and the solutions are improved by tabu search (similar to the one in Ref. [16]) and a local search procedure (which is a variable neighborhood descent procedure). These heuristics outperformed previous results using small computation times. Ahuja et al. [18] proposed a very large-scale neighborhood search algorithm where the neighborhood structures are induced by customer multi-exchanges and by facility moves. Good results are obtained with their method. A scatter search heuristic for solving the SSCFLP was proposed by Contreras and Díaz [19]. Their method generated good solutions using a reasonable computing time. Chen and Ting [20] proposed a hybrid of Lagrangian heuristic and ant colony system for solving the SSCFLP. Near-optimal solutions were created with this hybrid.In this paper, a different strategy is utilized to design the tabu search heuristic. The tabu search procedure employs two simple neighborhood structures which re-allocate customers between opened and closed facilities. The re-allocation may lead to infeasible solutions, which are penalized in the evaluating function. The best solution from tabu search is then perturbed by one of the randomly chosen neighborhood operators. The iterative procedure that combines tabu search and perturbation is named iterated tabu search. One of the strengths of the proposed heuristic is its simplicity: the algorithm is based on a simple search paradigm and relies on easily reproducible mechanisms for constructing a solution, moving from one solution to another, deciding whether a solution should be accepted or not, and terminating the algorithm. In addition, this heuristic allows the search to be conducted in infeasible regions of the search space. With the possibility of infeasible intermediate solutions, it is possible to obtain good solutions that may never be encountered if only feasible solutions were allowed. This heuristic is also capable of identifying high quality solutions for two sets of benchmark instances using small computing times.The rest of the paper is organized as follows. A mathematical formulation of the SSCFLP is given in Section 2, while the iterated tabu search heuristic is described in Section 3. Computational experiments are provided in Section 4. Finally, a conclusion is drawn in Section 5.Let there be a setI={1,…,m}of potential locations, and a setJ={1,…,n}of customers. Each customer j is associated with a demand, dj, that must be satisfied by a single facility. A fixed cost, fi, is incurred for opening a facility at location i. Also, let bidenote the capacity of the facility located at site i. Moreover, let cijbe the cost of supplying the demand of customer j from a facility at site i. The overall problem consists of opening a number of facilities such that the customers’ demands are satisfied by these facilities at minimum cost.For each locationi∈I, we define the decision variable yiasyi=1,if facility at locationiisopened;0,otherwise.For each locationi∈Iand customerj∈J, we define the decision variable xijasxij=1,if customerjis assigned to a facility at locationi;0,otherwise.The Single Source Capacitated Facility Location Problem can be stated mathematically as:(1)min∑i∈I∑j∈Jcijxij+∑i∈Ifiyi(2)s.t.∑i∈Ixij=1∀j∈J(3)∑j∈Jdjxij≤biyi∀i∈I(4)yi∈{0,1}∀i∈I(5)xij∈{0,1}∀i∈I,j∈JConstraint (2) ensures that every customer is served by exactly one facility, while constraint (3) ensures that the total demand of customers served by a facility does not exceed its capacity. Eqs. (4) and (5) are the integrality constraints. The objective (1) is to minimize the fixed costs and the costs of supplying the goods to the customers.This section describes the Iterated Tabu Search (ITS) heuristic developed for the SSCFLP. ITS can be seen as a special case of Iterated Local Search (ILS) [21], in which the local search phase is replaced by a tabu search phase. At each iteration of the ITS heuristic, solutionsˆis perturbed resulting in solution s′, which is then improved by tabu search to obtain solutions¯. If solutions¯satisfies an acceptance criterion, the search continues with solutions¯, otherwise the search proceeds with solutionsˆ. The overall structure of the Iterated Tabu Search heuristic is depicted in Algorithm 1, whereg(s¯)is a function for evaluating solutions¯, s* is the best known feasible solution encountered and g* is the value of s*.Algorithm 1Iterated Tabu Search1: s0= InitialSolution()2:sˆ=TabuSearch(s0)3: ifsˆis feasible, sets*=sˆand g*=g(s*); otherwise, set s*=∅ and g*=∞.4: forv=1,…,κdo5:   s′= Perturbation(sˆ)6:s¯=TabuSearch(s′)7:   ifs¯is feasible andg(s¯)<g*then8: Sets*=s¯,g*=g(s¯)and σ=0.9:   end if10:   Ifs¯is feasible ands¯satisfies the acceptance criterion, setsˆ=s¯.11: end for12: returns*The procedure for finding an initial solution is a two-stage approach. In the first stage, a subset ofIneeds to be opened. The allocation of customers to the opened facilities is determined in the second stage. In order to determine which facility to open, the facilities are first sorted in an ascending order based on the ratio fi/bi. Starting with the facility with lowest fi/biwe open as many facilities as necessary in order to satisfy total demand (i.e.,∑j∈Jdj≤∑i∈Ibiyi). A customer is assigned to its nearest opened facility. This allocation might lead to some facilities violating the capacity constraints and/or some facilities with no customers assigned. An infeasible initial solution will not cause any problems, as the tabu search heuristic is designed to deal with infeasibility (see Section 3.2.1).Tabu search [22] is an iterative process where at each iteration, the algorithm moves from solution s′ to the best solution found in its neighborhood. In order to prevent the search from visiting previously visited solutions and to avoid getting stuck in a local optimum, recently made moves are declared tabu for a given number of iterations. The tabu status of a certain move might be overridden when some aspiration criterion is satisfied.The algorithm allows solutions to be infeasible during the neighborhood search. A solution is infeasible if it violates the capacity constraints of the facilities. The total violation of capacity constraints in solution s′ is computed asq(s′)=∑i∈Imax{0,∑j∈Jdjxij−biyi}. Each solution s′ is evaluated by an objective g(s′)=z(s′)+αq(s′). The cost function z(s′) is equal to∑i∈Ifiyi+∑i∈I∑j∈Jcijxijof solution s′, while the coefficient α is a self-adjusting positive parameter that is modified at every iteration. Parameter α is divided by 1+ϵ if there is no violation of capacity constraints, otherwise it is multiplied by 1+ϵ, where ϵ is a positive parameter.The neighborhoodN1(s)for solution s consists of all solutions that can be transformed from s by relocating customer j from its current facility k to facility l, where k≠l. Facility l might be opened or closed. If l is closed, it becomes opened after j has been assigned to l. In the case where k has only one customer assigned to it, it becomes closed after j is assigned to l. This move is labeled (j, k, l). The transition of j from k to l is forbidden if TABU(j, l)≥ρ, where TABU(j, l) is the last iteration number in which this forbidden transition is still active and ρ is the current iteration number.The neighborhoodN2(s)for solution s is obtained by exchanging customer j1 from facility k with customer j2 of facility l, with k≠l. Such a move is denoted by (j1, j2, k, l). The exchange of j1 from k with j2 from l is forbidden if TABU(j1, l)≥ρ and TABU(j2, k)≥ρ.Once a move has been recorded tabu, it is declared tabu for θ=7+m(a/u) iterations. The parameter a is the number of times the move from solution s to solutions¯has been made, and u is the maximum value of a, for all moves made. This way of setting the value of the tabu tenure is the same as in Cortinhal and Captivo [15]. The purpose of recording the moves tabu is to prevent the search from visiting previously visited-solutions. However, this rule is not strict as it can be overridden when some aspiration criterion is satisfied. Two aspiration criteria are used; one isg1*, the value of the best known feasible solutions˘*, and the other isg2*, the value of the best (feasible or infeasible) solutions˜*. Boths˘*ands˜*refer to solutions encountered in the current tabu search.In order to accelerate the neighborhood search, only a fraction, β, of the neighbor solutions inN1(s)andN2(s)is evaluated. This is implemented as follows: Every solutions¯∈N1(s)∪N2(s)is randomly assigned a probabilityps¯, ands¯is only evaluated ifps¯≤β. The resulting neighborhoods are denotedN1β(s)andN2β(s), respectively. This also acts as a diversification mechanism in which less explored regions of the solution space might be sampled.An algorithmic description of the tabu search heuristic is shown in Algorithm 2.Algorithm 2Tabu searchRequire: Initial solution s01: Sets˜*=s0andg2*=g(s0). If s0 is feasible, sets˘*=s0andg1*=g(s0); otherwise, sets˘*=∅andg1*=∞.2: Set TABU(j, l)=−1 ∀ customers j and locations l.3: Set α=1.4: Set s=s0.5: forρ=1, …, γdo6:   Select solutions¯∈N1β(s)∪N2β(s)that minimizesg(s¯)and is non-tabu or satisfies the aspiration criterion (i.e.,g(s¯)<g1*if feasible org(s¯)<g2*if infeasible).7:   Ifs¯is infeasible and∃sˆ∈N1β(s)∪N2β(s)which is feasible andg(sˆ)<g1*, sets˘*=sˆandg1*=g(sˆ).8:   Ifg(s¯)<g2*, sets˜*=s¯andg2*=g(s¯).9:   Ifs¯is feasible andg(s¯)<g1*, sets˘*=s¯andg1*=g(s¯).10:   Set the move froms¯to s tabu for θ iterations (i.e., TABU(j, k)=ρ+θ if (j, k, l) or TABU(j1, k)=ρ+θ and TABU(j2, l)=ρ+θ if (j1, j2, k, l)).11:   Computeq(s¯)and update α.12:   Sets=s¯.13: end for14: Ifs˘*≠∅, returns˘*; otherwise, returns˜*.Random perturbation mechanisms are applied to a solution to achieve search diversification. At iterationvof the ITS heuristic, one of the following perturbation mechanisms is applied to solutionsˆ:1.Close a facility A facility k with one customer (denoted as j) assigned to it is randomly chosen and closed down. The customer will then be re-assigned to the cheapest opened facility l. LetIo={i∈I:yi=1}, then facility l is determined asargmini∈I0∖{k}cij. Facility k cannot be opened again in the next run of tabu search.Open a facility Randomly choose a closed facility l and open it. Facility l cannot be closed down in the next run of tabu search.Close one facility and open one facility Randomly choose an opened facility k and a closed facility l, and exchange their statuses (i.e., close down facility k and open facility l). The exchange should not violate the total capacity constraint. Customers of facility k will then be re-assigned to facility l. Facility k cannot be opened again during the tabu search and facility l cannot be closed in the next run of tabu search.Re-assign customers 1 Randomly re-assign all customers to the opened facilities. Note that the set of opened facilities does not change with this perturbation operator.Re-assign customers 2 Let there be a setO2consisting of⌈Io/2⌉randomly chosen opened facilities, and let setO1denote the remaining opened facilities (i.e.,O1=Io∖O2). Close the facilities inO2and re-assign the customers inP={j∈J:xij=1∧i∈O2}. Customerj∈Pis re-assigned to facilityl∈O1that has enough spare capacity to cover the demand dj, otherwise j is re-assigned to facilityk=arg mini∈I∖O1fiand yk=1.Close a facility and open two facilities Letτ=∑j∈Jdj,ϕ=∑i∈IbiyiandIc=I∖Io.Ifmin{−fh+fr+fw:ϕ−bh+br+bw−τ≥0,h∈Io,r∈Ic,w∈Ic}<0,then facility k is closed down and facilities l1 and l2 are opened. The combination of opening and closing the facilities is determined as follows.(k,l1,l2)=arg minh∈Io,r∈Ic,w∈Ic{−fh+fr+fw:ϕ−bh+br+bw−τ≥0}.Customers originally assigned to facility k will then be re-assigned to whichever facility (l1 or l2) is cheapest. Facility k cannot be opened, while facilities l1 and l2 cannot be closed in the next run of tabu search.Open a facility and close two facilitiesIfmin{fh−fr−fw:ϕ−br−bw+bh−τ≥0,h∈Ic,r∈Io,w∈Io}<0,then facility k is opened and facilities l1 and l2 are closed down. The combination of opening and closing the facilities is determined as follows.(k,l1,l2)=arg minh∈Ic,r∈Io,w∈Io{fh−fr−fw:ϕ−br−bw+bh−τ≥0}.Customers originally assigned to facilities l1 and l2 will then be re-assigned to facility k. Facilities l1 and l2 cannot be opened, while facility k cannot be closed in the next run of tabu search.Usually, perturbation is done by randomly applying one of the first five perturbation operators to a solution. However, these operators might not always achieve the right diversification effect. Hence, every η consecutive iterations without improvement to the best known solution s*, some stronger perturbation operators (i.e., operators 6 and 7) are used to perturb a solution.It is vital that the perturbation applied does not get revoked in the next run of the tabu search procedure. Hence, tabu search will not consider any neighbor solutions obtained by reversing the move applied by the perturbation operator (except for operators 4 and 5) at iterationvof the ITS heuristic.A solutions¯in the ITS algorithm is accepted ifs¯is feasible andg(s¯)<g*(1+δ)where δ≥0. This acceptance criterion differs from standard acceptance criteria associated with ILS, where the comparison is between the current solutionsˆand its local optimums¯. The implemented acceptance criterion is inspired from the Record-to-Record travel algorithm [23], where solutions¯is accepted ifg(s¯)is not much worse than g*.The ITS heuristic was coded in C++ and all computational experiments were carried out on a Dell notebook with an Intel Core i5-2520M CPU @ 2.5GHz. Two sets of benchmark instances were used to test the described iterated tabu search heuristic. The first set includes the 57 instances available from http://www-eio.upc.edu/∼elena/sscplp/. The number of customers in these instances range from 20 to 90, while the number of potential locations range from 10 to 30. The second set of instances contains 71 instances and is available for download from https://db.tt/PAwTKatL. The number of customers in these instances range from 50 to 200 customers, and the number of potential locations range from 10 to 30. The fundamental difference between the two sets of instances is the relationship between the fixed costs (fi) and the assignment costs (cij). In the first set, fixed costs dominate the assignment costs resulting in solutions with a small set of opening facilities and not much slack for the capacity constraints. The situation in the second set is completely different as the assignment costs dominate the fixed costs thus may lead to a larger set of opening facilities and much more slack for the capacity constraints.To tune the six parameters ϵ, η, δ, γ, κ and β, a two-stage approach is employed. First, the parameters ϵ, η and δ are jointly tested, and the values of the other parameters are fixed (i.e., γ=100, κ=50 and β=1). Second, the remaining parameters γ, κ and β are jointly tested, and the values of the other parameters are fixed from the first-stage tuning process. Table 1shows the results of the first-stage experiments of the first set of benchmark instances when ϵ∈{0.1, 0.2, 0.3}, η∈{10, 20} and δ∈{0.01, 0.02, 0.03, 0.04, 0.05}. Every instance was run 20 times for each combination of the three parameters. The column Best shows the average deviations of best solutions from the optimal solutions, while the column Avg lists the average deviations of average solutions from optimal solutions. The table shows that when setting η=10 the results are in general much better than when setting η=20. This parameter denotes how often operators 6 and 7 are applied in the ITS heuristic. The usefulness of these operators is shown in Table 3. The average gaps do not vary much when η=10 which may indicate that the heuristic may not be very sensitive to the tested values. However, it can be observed that setting ϵ=0.1, η=10 and δ=0.01 yields the best results. Hence, these parameters are fixed with the chosen values for the second-stage tuning process.In the second-stage tuning process, parameters γ, κ and β are jointly tested. If γ, the number of TS iterations, is set with a too low value, then tabu search might not be capable of reaching promising regions of the solution space. This is partly due to the infeasibility of the solution caused by the perturbation operator in which feasibility might not be achieved if too few iterations of tabu search are run. If feasibility is achieved, then tabu search needs some time in order to reach good local minima. The parameter κ denotes the number of ITS iterations. Obviously, the larger the value of this parameter, the better the resulting solution quality of the heuristic. As a consequence, the computing time will soar. Hence, it is important to find a balance between solution quality and computing time when determining values for these parameters. The last parameter to impact both the solution quality and computing time is β, the sampling parameter. It might seem obvious that the larger the value of β, the better the resulting solution quality. However, computational experiments show that better solution quality is achieved for β=0.75 than for β=1. This is due to the stochastic nature of the neighborhood sampling (where β acts as a diversification mechanism) and the perturbation mechanism.Table 2shows the results of the computational experiments of the first set of benchmark instances when γ∈{50, 100}, κ∈{50, 100, 200} and β∈{0.25, 0.5, 0.75, 1}. The column CPU denotes the average computing time (in seconds). As can be seen from the table better solution quality is achieved with β=0.75 than with β=1, which indicates that proper randomness is beneficial for diversification purposes when searching the neighborhood for good solutions. Table 2 also confirms that setting γ with a low value and κ with a large value does not necessarily outperform the cases where γ is set with larger values and κ with smaller values. For example, setting κ=200 and γ=50 does not provide better solution quality than for the heuristic using the combinations (100,100) and (50,100). Employing combinations (200,50) and (100,100) are approximately equivalent in terms of computational effort. In contrast, setting κ=50 and γ=100 results in a faster heuristic than setting κ=200 and γ=50 but the former setting still resulted in better solutions. The table also shows that the best results are obtained by setting κ equal to 100, γ equal to 100 and β equal to 0.75. Hence, the computational results provided in the remainder of this paper are obtained using those values.Table 3 shows the statistics on the different operators. The second column lists the average solution degradation of the solutions found from running the heuristic excluding the operator (listed at the same row) for all instances of the first set of benchmark instances. Every instance was run 20 times. This table shows that operator 7 (i.e., open one facility, close two facilities) is the most useful one. One reason for the usefulness could be that a “better” set of opened facilities is created when this operator is applied. As mentioned earlier, fixed costs dominate the assignment costs in which solutions with a small set of opening facilities are preferred. This is achieved by operator 7. Operator 4 (i.e., re-assign customers 1) is the least useful operator among the seven operators. The reason for this could be that this operator does not lead to a different set of opened facilities, but it is still useful for diversification purposes. Perturbation is very useful for the iterated tabu search heuristic. When every operator is excluded from the heuristic, the average deviation degrades with 1.781%. As the tabu search procedure is not complex, the ITS relies on the different perturbation operators for diversification.The results of the first set of benchmark instances are depicted in seven tables (Tables A.1–A.7). In these tables, the first column indicates the problem, while the second and third columns denote the size of the instance. The column Optimal lists the optimal solution to each of the problems. The optimal solutions are obtained from Díaz and Fernández [10]. The fifth column lists the best solution (out of 20 runs) obtained by the ITS heuristic, and the sixth column is the deviation of the best solution from the optimal solution. The Average column is the average solution of 20 runs, while the following column is the average deviation of the average solution from the optimal solution. The last column is the average CPU time (in seconds). The results are obtained by setting ϵ=0.1, η=10, δ=0.01, β=0.75, κ=100 and γ=100 as good results were achieved using reasonable computing time. For class C1 and class C2, the ITS heuristic obtained 17 optimal solutions out of 17 benchmark instances. For the rest of the classes, the average deviations are less than 0.1.Table 4provides a comparison of the published metaheuristics applied on the 57 benchmark instances. GRASP is a multistart procedure and RGRASP is a reactive GRASP. TS1 and TS2 are tabu search procedures, while HB1 and HB2 are hybrid heuristics. Descriptions of these methods can be found in Delmaire et al. [16] and Delmaire et al. [17]. SS denotes the Scatter Search heuristic described in Contreras and Díaz [19]. The last column lists the results of the ITS method. Table 4 lists the average gaps of best solutions from optimal solutions and average running times (in seconds) for every problem class as well as for all 57 instances. This table also gives the number of optimal solutions found by the different heuristics (i.e., N_opt). ITS generates overall better solutions than any of the heuristics, but HB1 and HB2 managed to identify 6 and 5 more optimal solutions than the ITS heuristic. The ITS heuristic finds the optimal solution to 70% of the first set of problem instances. Optimal solutions to these problem instances are difficult to find, especially for the smaller-sized instances. The hardness of these problem instances is also indicated by Delmaire et al. [17, p. 220] and Contreras and Díaz [19, p. 81]. Comparing running times of the different metaheuristics is not an easy task due to the different computers, operating systems, compilers, data structures, and computer languages used. It might seem that the ITS heuristic is a little slower compared to the other methods. However, the reported computing times seem reasonable and acceptable for this type of problem.Results for the second set of problem instances are listed in four tables (Tables A.8–A.11) and are obtained with the same set of parameter settings as described earlier. These tables have the same format as Tables A.1–A.7. The optimal solutions are obtained from Holmberg et al. [8] and Ahuja et al. [18]. For classes C8 and C9, the ITS heuristic obtained 40 optimal solutions out of 40 benchmark instances. For the remaining two classes, the average deviations are 0.03 and 0.075, respectively.Table 5provides a comparison of different heuristics applied on the second set of benchmark instances. RM is a repeated matching heuristic [9], VLSN denotes the very large-scale neighborhood search heuristic [18], SS is the scatter search heuristic [19], ALH is the hybrid heuristic of ant colony and lagrangian relaxation [20], and lastly ITS is our ITS heuristic. The table lists the average deviations of best solutions from optimal solutions for every problem class as well as for the 71 instances. Time denotes the average computing times (in seconds) for the 71 benchmark instances and not for each individual class. The ITS heuristic performs quite well for this set of instances, but it is slower than all the methods listed in Table 5. However, the ITS heuristic has found the optimal solution to 61 instances out of 71 instances using reasonable computing time.As can be seen from Tables 4 and 5, the ITS heuristic's performance on the two sets of benchmark instances is quite good, especially on the first set where the ITS heuristic outperforms HB1 and HB2. To the best of our knowledge, Contreras and Díaz [19] is the only published paper which also considered the same two sets of benchmark instances. In that paper, the scatter search heuristic did extremely well on the second set of instances, while its performance on the first set of instances is only moderate.

@&#CONCLUSIONS@&#
