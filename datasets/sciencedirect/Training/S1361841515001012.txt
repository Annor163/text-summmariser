@&#MAIN-TITLE@&#
Feature-based fuzzy connectedness segmentation of ultrasound images with an object completion step

@&#HIGHLIGHTS@&#
HighligtsNovel US segmentation approach based on the fuzzy connectedness framework.Use of local phase and feature asymmetry to define affinity function.Shape-based object completion step to detect and complete one or more gaps.Novel regional entropy-based quantitative image quality assessment approach.Method performs well across a variety of image qualities from clinical practice.

@&#KEYPHRASES@&#
Image segmentation,Ultrasound,Shape completion,Fetal imaging,Image quality,

@&#ABSTRACT@&#
Medical ultrasound (US) image segmentation and quantification can be challenging due to signal dropouts, missing boundaries, and presence of speckle, which gives images of similar objects quite different appearance. Typically, purely intensity-based methods do not lead to a good segmentation of the structures of interest. Prior work has shown that local phase and feature asymmetry, derived from the monogenic signal, extract structural information from US images. This paper proposes a new US segmentation approach based on the fuzzy connectedness framework. The approach uses local phase and feature asymmetry to define a novel affinity function, which drives the segmentation algorithm, incorporates a shape-based object completion step, and regularises the result by mean curvature flow. To appreciate the accuracy and robustness of the methodology across clinical data of varying appearance and quality, a novel entropy-based quantitative image quality assessment of the different regions of interest is introduced. The new method is applied to 81 US images of the fetal arm acquired at multiple gestational ages, as a means to define a new automated image-based biomarker of fetal nutrition. Quantitative and qualitative evaluation shows that the segmentation method is comparable to manual delineations and robust across image qualities that are typical of clinical practice.

@&#INTRODUCTION@&#
Organ and tissue delineation is essential for underpinning image-based measurements of organ dimensions or tissue region properties. However, manual delineation is a tedious, subjective, time-consuming, and error prone task highly related to the image characteristics and the expertise of the observer. Development of automatic methods for quantitative analysis is especially challenging in ultrasound (US) images, where objects can show strong inhomogeneities and boundaries, can appear fuzzy or are not visible, and in the case of fetal analysis (which motivated this work) further issues are the change in appearance across gestational age and the challenge of fetal movement artefacts. Typically, purely intensity-based methods do not lead to good segmentation results. Several approaches are available at present for segmenting B-mode US images (Noble and Boukerroui, 2006). Among these, the use of local phase, derived from the monogenic signal (Felsberg and Sommer, 2001), has proven useful for a variety of image analysis tasks including segmentation (Belaid et al., 2011; Hacihaliloglu et al., 2008), registration (Mellor and Brady, 2005), image enhancement (Boukerroui et al., 2001), tissue characterization (Szilágyi et al., 2009), and feature detection (Bridge and Noble, 2015; Mulet-Parada and Noble, 2000; Rahmatullah et al., 2012), since local-phase methods extract structural image information while being invariant to contrast.Among the many image segmentation methods that are currently available, the fuzzy connectedness (FC) framework can potentially deal with the fuzziness inherently present in US images and is defined by a discrete mathematical formulation, which makes it easy to implement. Fuzzy connectedness (Udupa and Saha, 2003; Udupa and Samarasekera, 1996) is a region-based approach. The main idea consists of defining the strength of local “hanging togetherness” of pixels within an image taking into account their spatial relationship and their intensity similarities within the object of interest. Some variants such as Iterative Relative Fuzzy Connectedness have been shown to be equivalent to other segmentation methods such as graph cuts (Ciesielski et al., 2012) and the Absolute Fuzzy Connectedness with gradient based affinity to level-sets (Ciesielski and Udupa, 2012). This approach has proven to be effective in terms of precision, accuracy, and efficiency (Udupa et al., 2006) in segmenting tissues in the presence of intensity gradation in MR and CT images over numerous applications (e.g. Multiple Sclerosis, Udupa et al., 2001, artery-vein separation, Lei et al., 2001, brain tumour segmentation, Moonis et al., 2002, etc.). To our knowledge this article is the first to consider design of a solution specially formulated for US images.The particular segmentation challenge considered in this paper is 2D fetal US image segmentation. Previous automatic methods developed for this task have focused on extracting standard biometry (size) parameters over a narrow gestational age range. Examples include methods developed for the fetal head (Chalana et al., 1996; Hanna and Youssef, 1997; Lu and Tan, 2000; Lu et al., 2005; Pathak et al., 1997a; 1997b), the fetal femur (Rahmatullah and Besar, 2009; Shrimali et al., 2009; Thomas et al., 1991a; 1991b), and the fetal abdomen (Chalana et al., 1996; Ciurte et al., 2012; Nithya and Madheswaran, 2009; Yu et al., 2008b) by using active contour models, morphological operators, machine learning, deformable models, or Hough transform approaches. Further, there are a limited number of papers in the literature that have proposed to estimate multiple standard fetal biometric measurements using a general method (Carneiro et al., 2008c; Yu et al., 2008a). The latter work, was subsequently translated into a commercial tool, called Auto OB (Carneiro et al., 2008b). Finally, state-of-the-art segmentation methods for automatic biometry of the fetal head and femur were recently compared on ultrasound data acquired across gestational age in a recent medical image analysis challenge (Rueda et al., 2014).In 3D ultrasound, Yaqub et al. (2014a) has considered segmentation of 3D femur bone volumes using Random Forests, Cuingnet et al. (2013) has considered automatic detection and alignment of the fetal head from 3D US volumes, and automatic standard plane localization from 3D ultrasound volumes has been considered for the fetal abdomen (Ni et al., 2014) and 3D fetal neurosonography (Carneiro et al., 2008a; Yaqub et al., 2014b). Other fetal organs that have been investigated from a quantitative biomedical image analysis perspective are the fetal lungs (Prakash et al., 2002), heart (Deng et al., 2012; Dindoyal et al., 2005; Veronese et al., 2012), fetal face (Feng et al., 2009), and the fetal brain (Namburete and Noble, 2013; Namburete et al., 2012; 2015; Gutiérrez Becker et al., 2010; Yaqub et al., 2013).Most previous studies were designed to work over a particular gestational age range (particularly 18–22 weeks which corresponds to the interval of the abnormality screening scan). This avoids the main challenges (articulated later in the paper) of developing segmentation solutions applicable across gestation. To our knowledge, the only previous work to propose estimation of a fetal ultrasound biomarker across a large gestational age range is the framework (Namburete et al., 2015; 2014) that accurately predicts the gestational age of the fetus based on analysis of brain structures using a regression forest model.None of the previous works have attempted to relate the quality of the images to the quality of segmentation results which is an original contribution of this paper, and most prior work only uses a small number of images to develop and validate a method.As with the work of Namburete et al. (2014) and Namburete et al. (2015) the development of this method was motivated by the clinical need for cost-effective and simple image-based biomarker tools for supporting pregnancy care in the developing world. Ultrasound-based tools are natural to consider for this purpose. Specifically, fetal adipose tissue in the limbs has been shown to be representative of fetal nutritional state (Larciprete et al., 2003), and its quantification has been hypothesised to be a good indicator of fetal growth (Bernstein et al., 1997). Motivated by this, recent clinical studies by our group (Knight et al., 2012a; 2012b) have shown that estimation of adipose tissue from US images of fetal limbs (fat and fat-free regions), via manual delineation, can characterise differences between healthy fetuses and neonates and relates to fetal nutrition. The method proposed in the paper was designed to automate estimation of this image-based biomarker. We are not aware of any previous work on automatic segmentation of arm adipose tissue on fetal US images.The contributions of this article are three fold. First, we consider how to extend the Absolute Fuzzy Connectedness (AFC) approach to US images by defining a new affinity function. This is done by incorporating information extracted from local phase features instead of image intensities into the AFC framework affinity function. The resulting local phase-based FC framework becomes invariant to contrast and thus is well-suited for US image segmentation. Second, we present a new shape-based method for object completion of one or more ‘gaps’, to deal with missing information resulting from regions without an ultrasonic signal response (for example due to ultrasonic shadows). The result of object completion is then regularised by mean curvature flow. Thirdly, we introduce an approach to quantify the image quality (which can vary considerably between US image acquisitions) of an ultrasound image segmentation validation dataset to appreciate the accuracy and robustness of the developed analysis methodology across clinical data of varying appearance and representative of potential real world applications. The latter is especially important for US image analysis methods, where results are normally linked to the quality of the images and general practice (with few exceptions) is to report findings on good acoustic window data.Preliminary versions of parts of this article appeared in Rueda et al. (2011); 2012b). The present paper presents a more general formulation of the complete analysis method, an in-depth evaluation on clinical data, and the new method for quantitative US image quality assessment is introduced for the first time.The outline of the remainder of the paper is as follows. In Section 2, the overall segmentation framework is introduced and explained in detail. Qualitative and quantitative evaluations, including the proposed method of quantitative image quality assessment, are presented in Section 3. A discussion and conclusions are given in Section 4.The overall segmentation framework is composed of several steps summarised in Fig. 1. Each step is explained in the following subsections.LetfA(t)be the complex analytic signal derived from f(t) and its Hilbert transformfH(t)asfA(t)=f(t)−ifH(t). This representation allows the extraction of the local amplitude (energy) A(t) and local phase φ(t) of f(t) defined asA(t)=∥fA(t)∥=f2(t)+fH2(t),andφ(t)=arctan(fH(t)/f(t)),respectively.The monogenic signal (Felsberg and Sommer, 2001) IM(x, y) of an image I(x, y) generalises the analytic signal to 2D (and higher dimensions) using the Riesz transform instead of the Hilbert transform. From the monogenic signal, the local phase, local energy, and local orientation can be estimated.In the spatial domain, the convolution kernels of the Riesz transform are defined as(1)h1(x,y)=x2π(x2+y2)32andh2(x,y)=y2π(x2+y2)32,which in the frequency domain are expressed as(2)H1(u,v)=uu2+v2andH2(u,v)=vu2+v2,respectively. The quadrature pair (H1, H2) define the Riesz transform.The implementation requires a pair of bandpass quadrature filters to extract the local properties of an image (amplitude, phase, and orientation). The imageI(x),wherex=(x,y),is first convolved with a bandpass filterb(x),to giveIb(x)=b(x)⊗I(x),where ⊗ denotes the convolution operation. The bandpass filter chosen was a Gaussian derivative filter (Boukerroui et al., 2004) defined in the frequency domain as(3)B(u)=|u|exp(−u2σ2),whereu=(u,v)and σ is the selected scale of the filter.This filter was empirically chosen, giving better visual maps than other candidate bandpass filters. This is not a critical part of the methodology and other filters, such as Cauchy (Boukerroui et al., 2004), may be better suited for other applications. An example of a Gaussian derivative bandpass filter and the resulting bandpass quadrature pair of odd filters is shown in Fig. 2.The monogenic signalIM(x)ofI(x)is then expressed as(4)IM(x)=(Ib(x),h1(x)⊗Ib(x),h2(x)⊗Ib(x)).The local amplitude (energy)A(x),local phaseφ(x),and local orientationθ(x)ofI(x)are derived fromIM(x)and defined as(5)A(x)=Ib(x)2+(h1(x)⊗Ib(x))2+(h2(x)⊗Ib(x))2,(6)φ(x)=arctan(Ib(x)(h1(x)⊗Ib(x))2+(h2(x)⊗Ib(x))2),(7)andθ(x)=arctan(h2(x)⊗Ib(x)h1(x)⊗Ib(x)),respectively. The structural information is invariant to contrast and contained in the local phase, whereas the local amplitude represents the energy, which is dependent on intensity values. An example of local phase image can be seen in Fig. 15(a) for the image in Fig. 11(b).Computing the local phase at different scales, allows one to detect step edge features as points where there is local phase congruency (Kovesi, 1999). In other words, a positive step edge will have a local phase value of 0° and a negative step edge will have a value of 180°. To detect step edge features, we use the feature asymmetry FA measure, calculated over a number of scales, and defined as(8)FA(x)=1N∑s⌊|daodd(x)s|−|even(x)s|−Ts⌋even(x)s2+daodd(x)s2+ɛ,whereeven(x)=Ib(x),daodd(x)=(h1(x)⊗Ib(x),h2(x)⊗Ib(x)),⌊.⌋ sets to zero the negative values, s represents the scale, N is the total number of scales, ε is a constant that avoids the division by zero (typicallyɛ=0.01), and Tsis an orientation independent threshold that controls the spurious responses to noise at scale s (Kovesi, 1999; Mulet-Parada and Noble, 2000). Tscan be estimated from statistical properties of the energy response (Kovesi, 1999) or by approximating the statistical mode (Mulet-Parada and Noble, 2000).The FA image consists of thick detected edges with values close to 1 and with homogeneous regions close to 0 values. An example of a feature asymmetry image can be seen in Fig. 15(b) for the image in Fig. 11(b). However, a good localization of the edges of the object of interest is essential in this framework. Therefore, we need a technique to thin the feature asymmetry edge features while retaining most of the information present in the FA image. A non-maximal suppression technique (such as Sonka et al., 2008) could be used for this, but it will be unable to retain information in directions other than the local orientation direction at each edge pixel. Therefore, a modified non-maximal suppression technique was developed. First, for each pixel in the FA image, non-maximal suppression is performed in all possible directions. Then, at each pixel, the maximum value among all directions is retained. This strategy captures the relevant edge information with good localization while retaining the same intensity present in the FA image, thus obtaining the edge map E that will be used in this work. An example can be seen in Fig. 15(c) for the feature asymmetry image in Fig. 15(b).Although several variations of the fuzzy connectedness method exist (e.g. Iterative Relative Fuzzy Connectedness - IRFC, Relative Fuzzy Connectedness - RFC), in this paper we have chosen to employ one of the original formulations of FC, namely Absolute Fuzzy Connectedness (AFC), to study how it would perform using the affinities specially formulated for US imagery.The Absolute Fuzzy Connectedness strategy (Udupa and Saha, 2003; Udupa and Samarasekera, 1996) is based on a global fuzzy relation that assigns a strength of connectedness to every pair of pixels in an image to define objects via dynamic programming. The key step of this region-based approach relies on the definition of a local fuzzy relation μκ, called affinity, which defines the local “hanging togetherness” between any two adjacent pixels. If two pixels c and d are adjacent, the affinity depends on how homogeneous the region is and on how close the intensity values at c and d are from the expected intensity value of the object of interest. The affinity is equal to 0 for non-adjacent pixels.The affinity values are used to define a global relation, called Fuzzy Connectedness, where the strength of connectedness between any two pixels is calculated as the largest of the strengths of all paths between c and d on the discrete image grid. Each path corresponds to a sequence of adjacent pixels starting from c and finishing in d and has a corresponding strength value, which is the smallest affinity of any pair of consecutive pixels along the path (weakest link). The Absolute Fuzzy Connectedness is represented as a connectivity map, where the object of interest is obtained by thresholding the image at TFC. The detailed mathematical description of the method can be found in (Udupa and Saha, 2003; Udupa and Samarasekera, 1996).The initialisation of the general method is based on manually placing one or several seeds within the object of interest. A minimal training stage is required once to define the typical mean and standard deviation of the intensity values of the object of interest.The AFC framework was adapted to US segmentation by defining a new affinity function that uses structural and edge feature information instead of intensities and intensity gradients. The affinity function was designed as follows. Assume that every fuzzy subsetAin a set is characterised by its membership functionμAwith values in [0, 1]. Given an image, the affinity is composed of three factors: an adjacency component μα, an object feature-based component μϕ, and a homogeneity-based component μψ. The adjacency component μαis a non-increasing function of the distance in pixels (i.e. integers)∥c−d∥defined as(9)μα(c,d)={1,ifc=dor∥c−d∥=1,0,otherwise.In the original framework by Udupa and Samarasekera (1996), the object feature-based componentμϕ1was defined based on the intensities of the image, whereas the homogeneity-based componentμψ1was a measure of intensity gradient. The proposed method incorporates the local phase information into the object-feature based component, extracting structural information and making the image invariant to contrast. The edge map E, derived from the feature asymmetry image, directly gives a measure of homogeneity, since smooth regions have small values and regions near boundaries have large values (cf. Section 2.2). Therefore, it is natural to consider it in the definition of the homogeneity-based component. Let φ(c) be the local phase at pixel c and E(c, d) the thinned pixel edge derived from feature asymmetry between pixels c and d. The homogeneity-based componentμψ2will have a high affinity in homogeneous regions and small affinity at the edges. Since E is close to 0 in homogeneous regions and close to 1 at edge features, we can express the homogeneity component as(10)μψ2(c,d)=1−E(c,d)=g3(E(c,d)),where g3 is a function of E(c, d). The object feature-based componentμϕ2takes into account characteristic features of the object of interest. In this paper, a recent formulation (Ciesielski and Udupa, 2010) was applied directly to the local phase image instead of intensities, as follows:(11)μϕ2(c,d)=e−max{∥φ(c)−mo∥,∥φ(d)−mo∥}2/2σo2=g4(φ(c),φ(d)),where moand σoare the mean and standard deviation of the intensity values of the object of interest, previously calculated in a training stage, and g4 is a function of φ(c) and φ(d).There exist several ways of combining the affinity components to form the fuzzy affinity μκ(Ciesielski and Udupa, 2010). One general form commonly used is(12)μκ(c,d)=μα(c,d)[ω1g1(I(c),I(d))+ω2g2(I(c),I(d))],where I(c) and I(d) correspond to the intensities at pixels c and d, respectively (Udupa and Samarasekera, 1996),g1(I(c),I(d))=μψ1(c,d),andg2(I(c),I(d))=μϕ1(c,d). The equivalent affinity functionμκ*for the proposed approach is expressed as(13)μκ*(c,d)=μα(c,d)[ω1g3(E(c,d))+ω2g4(φ(c),φ(d))],whereω1+ω2=1,and with g3 and g4 as defined in (10) and (11), respectively.The segmentation resulting from the feature-based FC only incorporates regions of the object of interest present in the image. However, it is unable to delineate object boundaries in shadowed areas (e.g. shadow under the humerus bone in Fig. 11(b)), as there is no ultrasonic signal response from these regions. Furthermore, in some cases, the object of interest can be formed by several connected pieces with missing information between them that we would like to retrieve. To overcome this, a new object completion technique has been developed. This first detects the region of the object of interest with missing information, and then fills the gap(s) in by using local shape constraints (Rueda et al., 2008). In the preliminary version of the method (Rueda et al., 2012b), only one gap was corrected. In this paper we have generalised the approach to the detection and completion of any number of gaps appearing in the object of interest after segmentation. The object completion step is described in the next subsection.At each point p on a boundary, a local curvature scale segment (Rueda et al., 2008), called c-scale segment C(p), is defined as the set of connected points at a distance smaller than a threshold t from the line connecting the two end points of the set (red dashed curve in Fig. 3). Each C(p) is obtained after symmetrically and progressively examining the adjacent boundary elements to p until the distance is no greater than a threshold t.A c-scale value Ch(p) (green dashed line in Fig. 3) can then be obtained as the chord length corresponding to C(p), which is the length of the straight-line segment between the end points in C(p). Large Ch(p) values indicate small curvature at p, whereas small values denote high curvature (Rueda et al., 2008). Values of c-scale are very useful in estimating actual segments and their curvature by considering the local morphometric scale of the object, and are independent of digital effects and noise. The c-scale method has proven to be robust in obtaining a complete description of shape directly applied to digital boundaries. More details can be found in Rueda et al. (2008).An extension of this implementation was developed to obtain the normalnpat each point p in the boundary as the line perpendicular to Ch(p) passing through p (Fig. 3). The direction of the normals is always selected pointing to the inside of the object. Only the normal information is needed for the object completion step, which is described in the following.The object completion is performed in three steps: convex hull boundary extraction, gap detection, and gap completion.First, the convex hull of the segmentation result is computed and its boundary extracted (Fig. 4). If the segmented object is composed by several connected components, the convex hull contains all of them, as shown in Fig. 4(b). In the following, the completion strategy is illustrated on an example with three gaps to describe a general case. In our application, all the objects will have at least one gap to complete.For each boundary element in the convex hull boundary, the c-scale shape descriptor (Rueda et al., 2008) is used to define the tangent (chord) at each point in the curve. From the tangents, the normals to the convex hull boundary are calculated at each boundary point in the direction pointing towards the inside of the object (Fig. 5(a)). Then, the binary intersection between each normal and the segmented object (resulting from the feature-based fuzzy connectedness step) is retrieved and the connected object closest to the convex hull boundary element is retained. The width (thickness) is then calculated (Fig. 5(b)) by measuring the length of the connected object previously extracted for each boundary element of the convex hull. The gap(s) is(are) detected by finding the region(s) with zero width, as represented in Fig. 6.The last step consists of filling in the gap(s) in the segmented object. Two normals on each side of each detected gap are then identified at a fixed distance D (Fig. 7(a)). A polygon is constructed by connecting the two detected normals on each side of the hole at the level of the convex hull boundary from one side, and the segmented object boundary from the other side (Fig. 7(b)). The corrected object is obtained from the binary union between the polygon and the segmented object. Note that a different completion strategy could have been used instead of a polygon. For example, curvature information could be used to complete the gaps after detection using curves. However, in this case, we tried to follow the same strategy clinicians were using to complete the shapes in our particular application. Algorithm 1summarises the object completion step.The resulting object boundary is finally smoothed using a mean curvature flow (MCF)11http://www.cs.ubc.ca/~mitchell/ToolboxLS/regularisation strategy (Sethian, 1999). The method is based on the evolution of the curve using implicit functions. The points in the contour are moved in the normal direction with a speed proportional to the curvature at each point. A Matlab toolbox (Mitchell, 2008) was used for this purpose.

@&#CONCLUSIONS@&#
This paper has presented three main technical contributions: a feature-based segmentation strategy adapted to US images, a gap completion method, and a novel quantitative image quality assessment approach to assess segmentation performance.The complete US image segmentation framework introduced in this paper is based on a feature-based fuzzy connectedness segmentation method and requires manual placement of the seeds, after which the remaining steps are performed automatically. The selection of the threshold was fixed for this application, in future might be automated by, for instance, the method of Miranda et al. (2008). The proposed approach uses structural and edge information based on local phase, instead of intensities and intensity gradients, to drive the segmentation. The resulting segmentation is then completed by filling one or more gaps caused by shadows or artefacts in the segmented object of interest using a shape descriptor. A final regularisation based on mean curvature flow is performed to smooth the final contours.Although more conceptually advanced fuzzy connectedness methods exist, such as RFC and IRFC, it remains to be seen how these would perform in US images. This paper reports results on AFC applied to US images, which is the most basic form of FC with affinities specially formulated for US image segmentation. Once this basic investigation is reported and the behaviour of AFC understood in its most fundamental form, we can then take on investigations to study how more advanced forms of FC with the same forms of affinities on a multi-object setting would perform.We argued that all segmentation methods should report their results in conjunction with a quantitative image quality analysis to show that the dataset used is representative of a clinical application, and not selected to best suit a particular methodology. A novel quantitative image quality assessment protocol based on entropy was presented and applied to different image partitions to derive interface scores to show the variability of qualities existing in the dataset, representative of a real clinical application. This technique could readily be adapted to suit images from different clinical applications.A qualitative and quantitative evaluation was performed on 81 cross-sectional images of the fetal arm across gestation, by using region and distance-based metrics. The results showed a similar performance to manual segmentations. Furthermore, the quantitative image quality assessment method showed that the performance of the method was robust across a variety of image qualities representative of a real clinical environment.The proposed method has undergone clinical assessment on pilot data (Knight et al., 2012a; 2012b; Rueda et al., 2012a) and is now part of a large clinical study aimed at establishing normative nutritional growth charts of healthy fetuses across gestation (Knight et al., 2014). The presented framework estimates three main clinical measurements from US images: the amount of fetal arm adipose tissue, the fat-free (lean and bone) areas (useful for body composition assessment), and the adipose tissue percentages for each cross-section (normalised measurements with respect to arm size) across gestational ages. In this study, we have analysed cross-sectional data, but the method is also suitable to study longitudinal data, towards achieving a personalised nutritional monitoring of the fetus.The 2D feature-based FC implementation could readily be extended to 3D, as local phase and fuzzy connectedness can be easily extended to 3D. Finally, the proposed framework is motivated by, but not limited to this particular application or imaging modality and could equally be applied to other soft tissue segmentation problems, such as myocardium segmentation (Dietenbeck et al., 2012; Zhu et al., 2010), including contrast-enhanced US (CEUS) images, or intravascular US (IVUS) (Ciompi et al., 2012; Moraes and Furuie, 2011; Zhu et al., 2011).