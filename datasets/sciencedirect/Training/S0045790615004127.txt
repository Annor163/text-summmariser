@&#MAIN-TITLE@&#
Analysis and evaluation of MapReduce solutions on an HPC cluster

@&#HIGHLIGHTS@&#
Analysis and evaluation of several HPC-oriented MapReduce frameworks on a cluster.Proposal of a taxonomy to classify these frameworks according to their characteristics.Experimental configuration using several workloads, cluster sizes, networks and disk technologies.Evaluation in terms of performance and energy efficiency.Results useful to select a suitable MapReduce framework and to identify desirable characteristics for future ones.

@&#KEYPHRASES@&#
MapReduce,High Performance Computing (HPC),Big Data,Energy efficiency,InfiniBand,Solid State Drive (SSD),

@&#ABSTRACT@&#
The ever growing needs of Big Data applications are demanding challenging capabilities which cannot be handled easily by traditional systems, and thus more and more organizations are adopting High Performance Computing (HPC) to improve scalability and efficiency. Moreover, Big Data frameworks like Hadoop need to be adapted to leverage the available resources in HPC environments. This situation has caused the emergence of several HPC-oriented MapReduce frameworks, which benefit from different technologies traditionally oriented to supercomputing, such as high-performance interconnects or the message-passing interface. This work aims to establish a taxonomy of these frameworks together with a thorough evaluation, which has been carried out in terms of performance and energy efficiency metrics. Furthermore, the adaptability to emerging disks technologies, such as solid state drives, has been assessed. The results have shown that new frameworks like DataMPI can outperform Hadoop, although using IP over InfiniBand also provides significant benefits without code modifications.

@&#INTRODUCTION@&#
In the past several years, organizations have been adopting the Big Data paradigm to obtain valuable information from large volumes of data. The required capabilities to do so is increasing over and over, since the amount of data managed by organizations grows every year. This situation demands more efficient, scalable and capable systems, while maintaining some of the axioms that unify the way that data are managed and processed in most environments.In order to overcome the limitations of current systems, some organizations have put an eye on High Performance Computing (HPC), which could provide with the technology to achieve Big Data goals. At the same time, HPC environments could benefit from Big Data programming models, such as MapReduce [1]. MapReduce is a programming model and an associated implementation for generating and processing large data sets, which is widely used to solve many analytic problems in several application fields, from biology to finances. The Apache Hadoop project [2] has gained significant attention in the last years as a popular open-source Java-based implementation of the MapReduce paradigm derived from the Google’s proprietary implementation.The use of Hadoop in HPC systems is expected to increase its performance, which is mainly limited by disk and network bandwidths. In this respect, network bandwidth can be improved by using high-performance interconnects (e.g. InfiniBand [3]), which are usually available in HPC environments. Hadoop relies on the ubiquitous TCP/IP protocol to implement its communications support through Java sockets,and thus it is not able to leverage high-performance interconnects in an optimal way. This issue has caused the appearance of many HPC-oriented MapReduce frameworks like Mellanox UDA [4], RDMA-Hadoop [5], DataMPI [6] and others. These solutions attempt to overcome the limitations of standard Hadoop in HPC environments.This paper presents an in-depth analysis and evaluation of representative HPC-oriented MapReduce solutions, indicating their similarities and differences. The proposed taxonomy is intended to be used to determine the suitability of each solution in specific use cases. The evaluation of these frameworks has been performed using several representative benchmarks. Furthermore, the trend to increase the number of cores in current systems has turned their power consumption into one of the most relevant issues. Therefore, the evaluation of the frameworks has been assessed not only in terms of performance but also taking into account their energy efficiency. The obtained results can be useful to identify the strengths and weaknesses of each solution in order to get valuable characteristics for future implementations.The rest of this paper is organized as follows: Section 2 presents background information and related work. Section 3 describes the experiments performed with the different frameworks and analyzes the results in detail. Finally, Section 4 extracts the main conclusions of the paper and proposes ongoing work.This section addresses the MapReduce model and its de-facto standard implementation, Hadoop. It also includes some details about InfiniBand, which has become the most widely adopted interconnect in the TOP500 list [7]. Next, it classifies the different HPC-oriented MapReduce solutions. Finally, related evaluation works are discussed.The MapReduce paradigm performs the data processing in two main phases: Map and Reduce, which name the model. In the Map phase, the cluster nodes read the data from their own local filesystem and extract the significant features of each data element. Every feature is represented by a 〈key, value〉 pair in which every value of the significant feature is associated with a key. The key is used to index the value and add it to a group. Elements with the same key belong to the same group. The Reduce phase receives the 〈key, value〉 pairs after being grouped and sorted. Every value is operated with the rest of the elements of its group, leading to a final result. This result is also represented by a 〈key, value〉 pair, and it can be seen as the valuable information of the group identified by the key.Currently, the most popular MapReduce implementation is Apache Hadoop [2], which is widely used by large corporations like Yahoo!, Facebook, Twitter and many others. Hadoop is an open-source Java-based framework which enables to store and process Big Data workloads. It mainly consists of two components: (1) the Hadoop Distributed File System (HDFS), which distributes the storage of data among the nodes of a cluster; and (2) the Hadoop MapReduce engine, which allocates data processing to the node where it resides.Fig. 1shows an overview of the overall MapReduce process performed by Hadoop. At the beginning of the process, the input data set is divided into splits and processed by the map tasks. Each time a map task finishes, the map output is partitioned into different fragments (p-x-x in the figure) which are sent to their corresponding reducers and merged to form the reduce input. Each reduce task processes its input to generate the final results and write them to HDFS.The first version of Hadoop (Hadoop 1) suffered from certain problems, like lack of scalability in some components, which caused the appearance of Yet Another Resource Negotiator (YARN) [8] in Hadoop 2. In YARN, the resource management has been decoupled from the MapReduce engine. Due to this division, several kinds of applications other than MapReduce ones can run over the Hadoop cluster, such as Message-Passing Interface (MPI) [9] codes. Moreover, most of the previous Hadoop applications can run on YARN with no changes.InfiniBand [3] is a networking technology which is widely used by scientific computing centers world-wide. In fact, 51.8% of the supercomputers in the June 2015 TOP500 list [7] use this technology, being the most used interconnect family. Its popularity is caused by the high-performance features that InfiniBand provides, such as Remote Direct Memory Access (RDMA). RDMA allows to directly access the memory of the remote nodes without involving CPU usage at the remote side. This feature enables to implement high-performance communication protocols using zero-copy and kernel-bypass mechanisms. The InfiniBand specification declares the different tasks of software and hardware elements. To interact between them, the network elements make use of the Verbs layer, a low-level interface for RDMA communication. This communication is performed completely in user space, avoiding the use of kernel space to buffer the data as it occurs with the TCP/IP protocol. The reference implementation of the Verbs layer is provided by the OpenFabrics Alliance (OFA) [10].InfiniBand can also be used as an IP network. The IP layer exposes the InfiniBand device to the system as an available Ethernet card, which is commonly known as IP over InfiniBand (IPoIB) [11]. The communication with IPoIB is not kernel-bypassed, so the data must be buffered at the kernel space before sending it through the network, preventing the implementation of zero-copy protocols.The taxonomy proposed in this paper classifies the HPC-oriented MapReduce solutions by the way each one addresses the problem of leveraging high-performance interconnects. The degree of modification of Hadoop can be useful to identify the expected performance improvement of a certain solution, as a deeper modification would potentially involve a better adaptation to HPC systems. The main drawback of replacing Hadoop with a new framework is that applications may need to be rewritten.Some solutions are transparent or semi-transparent to the user, and do not require an overall modification of the Hadoop core implementation. Other proposals modify specific parts of Hadoop which are responsible for performing the communication phase. Finally, there are some new frameworks that implement the MapReduce model from scratch using a different design and/or approach. More details of this taxonomy are given next.The solutions which do not require changes in the Hadoop implementation (or these changes are minimal) are Hadoop with IPoIB and Mellanox UDA. Generally, only changes in the Hadoop configuration are needed.To enable the utilization of IPoIB it is only necessary to change the Hadoop network configuration, so that the IPoIB interface is used instead of the Ethernet one. Once the configuration is modified, Hadoop will use the new IP addresses without changing its behavior regarding the interconnection network. Therefore, this solution is the one which minimizes the changes required to use InfiniBand, and it can be applied to any version of Hadoop.Mellanox UDA [4] is basically a plug-in intended for improving the communications between mappers and reducers. It has been developed by the Parallel Architecture and System Laboratory of the Auburn University together with Mellanox. Currently, it supports both Hadoop 1 and 2 versions.UDA combines an RDMA-based communication protocol along with an efficient merge-sort algorithm, which is based on the network levitated merge algorithm [12]. This algorithm modifies the original overlapping of Hadoop phases, involving a single disk access to write the reduce input data. Additionally, it directly implements its RDMA protocol on top of the Verbs layer to natively support InfiniBand.Currently, the most popular solutions that modify some of the subsystems of Hadoop to take advantage of high-performance interconnects are RDMA-Hadoop and HOMR, described next.RDMA-Hadoop adapts Hadoop communications to take advantage of RDMA features. This framework has been extended to the High Performance Big Data (HiBD) project [5], which encloses RDMA-based implementations of Hadoop 1, Hadoop 2 (YARN) and Memcached [13], as well as a set of benchmarks for evaluating Big Data middleware.Previous works have revealed the benefits of using high-performance interconnects to increase the performance of HDFS [14]. This has led developers to adapt different components of Hadoop to use RDMA communications: HDFS [15], MapReduce [16] and Hadoop RPC [17]. The specific solution for MapReduce (i.e. RDMA-Hadoop) redesigns the communications between mappers and reducers to take full advantage of the RDMA interconnect. It also improves the transmission of the map output by introducing a pipeline between mappers and reducers, while also performing data prefetching and caching mechanisms. As in the case of Mellanox UDA, RDMA-Hadoop modifies the overlapping of Hadoop phases for faster data processing.HOMR [18] is a hybrid approach to exploit maximum overlapping in MapReduce over high-performance interconnects. Using both standard Hadoop and RDMA-Hadoop implementations, it can communicate by using sockets and RDMA. The main aim of HOMR is to obtain the maximum overlapping among the different MapReduce phases by leveraging the behavior characteristics of both frameworks, adjusting the used implementation to a specific moment of the MapReduce process. This mechanism improves the use of the interconnection network along the whole process and reduces disk accesses in the reduce phase. In order to enhance the transmission between mappers and reducers, HOMR also determines which map outputs should be sent sooner than others. HOMR is a relatively recent project that is not publicly available yet, and thus its evaluation has not been included in this work.Currently, the most representative framework developed from scratch is DataMPI, described next.The feasibility of using the MPI model for MapReduce-based computing has been studied since 2009 [19], which has led to several projects such as DataMPI [6,20], BDMPI [21] and MR-MPI [22]. However, DataMPI has moved forward by providing simple implementation examples and a full benchmarking suite, BigDataBench [23], which also includes benchmarks for Hadoop, Spark [24] and MPI [25].DataMPI implements the MPI-D specification [26], a proposed extension of the MPI standard which uses the 〈key, value〉 semantics taken from the MapReduce model. Based on Hadoop, the data processing architecture of DataMPI includes additional features like reduce-side data locality, improved shuffle pipeline and optimized buffer management. It considers four processing modes: Common, MapReduce, Streaming and Iteration. The proposal of DataMPI aims to cover a wide range of applications which use different communication models by unifying them in a single architecture. The current version implements the functionalities and features of the Common mode, which is intended to support Single Program Multiple Data (SPMD) applications. Although the rest of the processing modes are yet to be implemented, some representative MapReduce workloads are already available, such as Wordcount, Sort, TeraSort and Grep.One of the key factors in the MapReduce model is the overlapping of the different phases involved in the overall data processing. Each solution schedules these phases in a specific way to obtain a certain benefit, such as the reduction in disk accesses by using a network levitated merge (Mellanox UDA) or an in-memory merge algorithm (RDMA-Hadoop), maximum overlapping of the phases (HOMR), and an increase in data locality during the reduce phase (DataMPI). Fig. 2shows at a glance how each of these frameworks addresses this issue.

@&#CONCLUSIONS@&#
The use of high-performance interconnects for Big Data computing can improve significantly the performance of applications. In particular, popular MapReduce frameworks like Apache Hadoop can greatly benefit from using InfiniBand, which allows to achieve higher scalability in order to address challenging real-world workloads. This work has analyzed in detail several HPC-oriented MapReduce frameworks that provide different approaches to the same issues. Future implementations need to take into account the behavior of the existing solutions, taking advantage of those specific characteristics that provided the best performance. Moreover, the most appropriate framework may vary from problem to problem. The main conclusion that can be drawn from the analysis of the results is that DataMPI obtains the best performance and energy efficiency on average, although existing Hadoop applications can also be transparently boosted by using IPoIB without source code modifications.Mellanox UDA has definitely contributed with important ideas to optimize the MapReduce process, such as the network levitated merge algorithm. However, its overall performance is highly dependent on the underlying disk technology. Hence, the utilization of magnetic disks can cause congestions in the shuffle/merge phases, delaying the whole process. This issue is solved by using SSD disks, but there is still the constraint to adapt this solution to overcome this limitation. Moreover, Mellanox UDA does not improve the performance of application benchmarks. Regarding RDMA-Hadoop, it constitutes a strong attempt to adapt Hadoop to high-performance interconnects. In fact, it achieves good performance when using magnetic disks, but it has shown severe memory problems when managing large data sets or iterative workloads, hindering its adoption in real environments. Moreover, RDMA-Hadoop does not improve the results of standard Hadoop when using a high number of nodes. The approach proposed by DataMPI is totally different from the other solutions, as it tries to cover a wider range of applications (e.g. MapReduce, Iterative, Stream). Its performance results are better than those of Hadoop in HPC systems, even though applications must be rewritten for using it.Table 7 presents an overall review of the evaluated MapReduce solutions in terms of performance, energy efficiency, scalability and stability. It also shows how easy it is to configure each framework, the quality of the available documentation and how easy the user can retrieve information about its specific behavior. Note that this table assesses these features for the particular versions evaluated in this paper (see Table 4), using the specific infrastructure and configuration shown in Tables 5 and 6, respectively. Therefore, these values are subject to change as the projects keep on evolving.Future work includes further evaluations using larger cluster sizes and analyzing the impact of storage systems in frameworks developed from scratch like DataMPI. The evaluation of additional MapReduce frameworks and high-performance interconnects (e.g. RoCE) would also be of great interest.