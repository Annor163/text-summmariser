@&#MAIN-TITLE@&#
A probabilistic approach for designing nonlinear optimal robust tracking controllers for unmanned aerial vehicles

@&#HIGHLIGHTS@&#
The subjects covered in the article, such as evolutionary computing, unmanned aerial vehicles, and their control forms attract a lot of interest nowadays.A extensive literature review presents several advantages for the proposed approach.The controller performance is notable even considering significant robustness requirements.Difficult topics, such as optimality, robustness, stability, nonlinearity, and correctness are addressed with relative simplicity.

@&#KEYPHRASES@&#
Bio-inspired optimization,Automatic control,Simulation,Unmanned aerial vehicles,

@&#ABSTRACT@&#
In this study, we propose a probabilistic approach for designing nonlinear optimal robust tracking controllers for unmanned aerial vehicles. The controller design is formulated in terms of a multi-objective optimization problem that is solved by using a bio-inspired optimization algorithm, offering high likelihood of finding an optimal or near-optimal global solution. The process of tuning the controller minimizes differences between system outputs and optimal specifications given in terms of rising time, overshoot and steady-state error, and the controller succeed in fitting the performance requirements even considering parametric uncertainties and the nonlinearities of the aircraft. The stability of the controller is proved for the nominal case and its robustness is carefully verified by means of Monte Carlo simulations.

@&#INTRODUCTION@&#
Unmanned aerial vehicles and their control forms are an actual and important research subject. This technology can be used to solve many social problems, and this explains the great interest that the area has received from different research groups and organizations throughout the world. Examples of research related to unmanned aerial vehicles are path planning [27,52], squadrons formation reconfiguration [16], wireless networks [28], autopilot design [5], multiple unmanned aircraft coordination [30], formation [22], task assignment [35], trajectories generation [34], patrolling or surveillance [2], searching [11], tracking [48], flight control [24] and source seeking [53].Despite using unmanned aerial vehicles, the aircraft has to be capable of following references, which are commands that determine the motion of the aircraft. These references can be created by defining trajectories [20] that an unmanned aerial vehicle has to follow. When trajectories are defined, performance requirements can be established by directly considering these trajectories. For instance, an aircraft controller can be designed so that the aircraft is able to follow a trajectory with optimal values for rising time, overshoot and steady-state error for its controlled variables.In this work, we are interested in developing an unmanned aerial vehicle that is capable of following a set of trajectories such as those illustrated in Fig. 1. These trajectories exhibit interesting properties. For instance, the trajectories shown in Fig. 1a and b focus on testing latitudinal and longitudinal movements, while angle of heading is considerably modified in both cases. The trajectory shown in Fig. 1c illustrates a movement that emphasizes variations for height and angle of attack, while control of velocity is prioritized in Fig. 1d. As a consequence, all state variables of the dynamic model are substantially stressed in one way or another. Besides, optimal values for rising time, overshoot and steady-state error are desired features of response for the cases considered. There is a challenging problem to determine optimal values for these metrics by taking into account all trajectories, considering nonlinearities of the aircraft dynamic model, stability assurance, and parametric uncertainties of the plant. For example, the task of analytically designing a controller by taking into account all worst-case parametric uncertainties of the aircraft dynamic model becomes very hard, since the problem is NP-hard [49].The problem considered in this study can be posed as follows: Design a tracking controller for unmanned aerial vehicles by taking into account the set of trajectories shown in Fig. 1. The performance of the controller for each aircraft controlled variable must be global near-optimal in terms of a weighted average among rising time, overshoot and steady-state error for all trajectories illustrated in Fig. 1, and it must be capable of dealing with nonlinearities of the aircraft dynamic model even considering parametric uncertainties of the plant. The stability must be proved, and the robustness has to be carefully analyzed.Aircraft dynamics are typically nonlinear, and there are many ways of designing tracking controllers for nonlinear systems. Linearization is one of the possible alternatives. The linearized controller is designed for several points of operation, and a gain schedule is used to complete interpolation between each pair of these points. Although this technique has been broadly used, it exhibits some problems. For instance, it requires a lot of work because several designs must be completed for each point of operation [49], while scheduling the gains from point to point during regime operation is a difficult task [17]. The stability cannot be formally proved when considering this approach [40]. On the other hand, the proposed approach considerably simplifies the design because it is based on dynamic inversion, which acts as a universal gain scheduler [39], whose nonlinearities are canceled without approximations, thereby enabling its proof of stability by using linear control theory.Several approaches have also been proposed for dealing with robust path tracking controllers for nonlinear systems. Common approaches along this line of research are backstepping [31], adaptive control [47], model predictive control [37], H-2/H-∞ control [32], Lyapunov's direct method [18], sliding mode control [50], and linear quadratic Gaussian control [41].With regard to the backstepping approach, it is used in [31] for designing a tracking controller for underactuated unmanned surface vessels. Although good dynamic performance and robustness can be achieved by using this approach, it has some drawbacks. For instance, repeated differentiations and recursive design [7] can significantly increase the complexity of the approach and make it difficult to apply to multiple state control systems [13]. Otherwise, the proposed probabilistic approach does not present such complexity because the gains of the controller are determined by using an optimization algorithm capable of solving non-convex and multi-objective optimization problems, whose fact significantly simplifies the design.In [47], adaptive control is used for tracking nonholonomic mechanical systems. By using this approach, it is possible to asymptotically track the desired trajectory and the tracking error can be bounded within a controllable bound. However, this approach is criticized because the robustness of its transient response cannot be ensured [12], and it is quite sensitive to changeable uncertainties of the system [29]. Besides, adaptive control requires quite comprehensive theoretical background [8]. These are some reasons why adaptive control has still been subject of research. On the other hand, the proof of stability of the proposed approach is made by using linear control theory, which is simple and well-known. Besides, the design is formulated in terms of a multi-objective optimization problem, and this helps to reduce the conservatism by using a bio-inspired optimization algorithm that has very high likelihood of finding global optimal or near-optimal results for problems that can even be non-convex.Model predictive control is another relevant control design. An example can be found in [37], where this approach is used to control an autonomous ground vehicle that has to track trajectories. Considering advantages [37], model predictive control is capable of dealing with performance criteria, and it is able to generate trajectories that are optimal according to these criteria. Besides, constraints can be explicitly considered and tuning of the parameters can be intuitively performed. However, model predictive control depends on the precise knowledge of the system parameters [36], and it may require significant computational effort to be implemented [36], whose fact may be prohibitive for systems that require fast sampling rates [1]. As a consequence, model predictive control can require some special treatment in order to avoid these problems. Otherwise, the proposed approach is not so dependent on the precise knowledge of the system parameters because the designing is performed by taking into account a significant number of parametric uncertainties of the plant. Besides, the gains of the controller do not change during operation, thereby reducing the required computational effort, and making the proposed approach interesting for real-time implementations.In [32], robust H-2/H-∞ control is used to design an unmanned helicopter controller for tracking trajectories. As some benefits [32], robust H-2/H-∞ approach can run very fast in modern embedded systems, and its stability and performance criteria can be ensured even considering disturbances. Nevertheless, H-∞ approaches have been criticized for some reasons. Although weighting functions are crucial in order that H-∞ controllers reach some of their control objectives, there is no direct way of choosing weighting functions and some trial and error iterations may be necessary to determine them [51]. In addition to this fact, the order of H-∞ controllers is usually high [33]. This helps to explain why robust H-2/H-∞ control has still been subject of research. In contrast, the proposed approach does not present any of these problems. Although the optimization algorithm used in this study can require little adjustments while tuning the controller, it does not need trial and error iterations, and all analytical expressions can be directly determined since dynamic inversion is applicable. Besides, dynamic inversion does not result in high order controllers.Another approach to solve the problem is the Lyapunov's method, as in [18], where a micro aerial vehicle is capable of tracking roads by using a control switching mechanism. Lyapunov's approach play an important role in nonlinear systems control theory because it is able to readily ensure the closed-loop system stability [10], without solving ordinary differential equations [23], thereby reducing its dependence on the problem. Although this fact makes Lyapunov's approach applicable to the solution of a wide range of linear and nonlinear problems, one of its main drawbacks is the practical difficulty in finding a Lyapunov's function [43]. In contrast, the proposed approach is straightforward since dynamic inversion is applicable.As examples of sliding mode control, unmanned aerial vehicles track trajectories in [50] by using this approach, which has important advantages, such as stability, invariance, robustness, and good precision [42]. However, the main drawback of sliding mode control is the chattering phenomenon [3], which is common and difficult to avoid or attenuate [45]. Chattering is inevitable in sliding mode control when control is discontinuous [9], and special treatment should be given to reduce or to avoid it [45]. However, as control is continuous in the proposed approach, chattering is very rare or does not occur when this approach is used.According to linear quadratic Gaussian (LQG) control, matrices R and G must typically be determined before optimizing the control so that a given performance criterion is indirectly specified by them. As advantages, linear quadratic approaches result in constant gains, which exhibit some robustness against model uncertainties [6,41]. However, a usual drawback of LQG approaches is the fact that it is not quite intuitive to specify performance by means of matrices R, and G. Otherwise, performance metrics considered in this study are relatively intuitive because they are specified in terms of the desired output of the system.A probabilistic robust method is used by Wang and Stengel [49] for designing an aircraft controller whose model is quite nonlinear and considerably different from the one considered here. As the proposed approach, the method of Wang and Stengel [49] is based on dynamic inversion and probabilistic analysis. Although dynamic inversion is quite dependent on the precise knowledge of the model [19], and cannot deal with parametric uncertainties of the plant by itself [38], Wang and Stengel [49] mitigated these drawbacks by considering probabilistic analysis during the design phase, thereby enlarging the range of applications where dynamic inversion can be applied. Despite the similarity with the work of Wang and Stengel [49], the approach proposed in this study has significant differences, such as: (a) instead of minimizing the likelihood of having unacceptable stability or performance when considering parametric uncertainties of possibly manned aerial vehicles [49], the proposed approach focus on minimizing the norm between optimal specifications and desired outputs for controlled variables of unmanned aerial vehicles by taking into account parametric uncertainties of the plant, (b) instead of using genetic algorithms [49], the proposed approach uses a hybrid partitioned-population optimization algorithm (HPPOA) [21], which has very high likelihood of finding optimal or near-optimal global solutions for functions with noisy parameters, and (c) instead of using the multi-objective optimization approach called scalarization, which defines a weighted average among several optimization criteria, the proposed approach optimizes in a multi-objective multi-level fashion, which can better deal with solution candidates that have different components but are equal in module [15].The main contributions of this work are as follows:•A probabilistic approach for designing nonlinear optimal robust path tracking controllers for unmanned aerial vehicles, which does not present any of the problems previously described above, such as chattering, gain scheduling, trial and error iterations, conservatism, and real-time limitations. Besides, the optimization process exhibits very high likelihood of finding optimal or near-optimal global solutions and can better deal with multi-objective solution candidates that have different components but are equal in module.A nonlinear near-optimal robust path tracking controller for unmanned aerial vehicles, resulted from the proposed approach. It is capable of dealing with the tracking problem, where the process of tuning the controller minimizes differences between system outputs and optimal specifications given in terms of rising time, overshoot and steady-state error, by considering all trajectories shown in Fig. 1, and by taking into account parametric uncertainties of the plant. The stability is proved for the nominal case and the robustness is carefully verified by means of Monte Carlo simulations.This paper is organized as follows: Section 2 focuses on the idea of the probabilistic approach, where the fundamentals of the proposed approach are explained. Section 3 presents a proof of stability, where the stability of the controller is proved for the nominal case. Section 4 covers simulation results, where optimal specifications and near-optimal robust results are graphically compared. Section 5 covers robustness analysis, where robustness against parametric uncertainties of the plant is verified by means of Monte Carlo simulations, and main results and conclusions are included in Section 6.As shown in Fig. 2, the proposed approach comprises three important fundamentals: dynamic inversion, robust performance metrics, and optimization with noisy parameters. In this work, the HPPOA algorithm is used for optimization because it has been considered competitive in the task of finding optimal or near-optimal global solutions for non-convex functions with noisy parameters [21].Before describing how to design a tracking controller for unmanned aerial vehicles, Section 2.1 exemplifies the use of the proposed approach by using a simple example.Fig. 3displays a simple example of a nonlinear control system described in (1), where a pendulum turns around an horizontal axis when a torque T(t) is applied. The output variable is the angle θ(t), and the input variable is the torque T(t).(1)θ¨=1M·L2·(T−M·g·L·cos(θ)−b·θ˙)Dynamic inversion consists of designing control signals that vary at the same rate as their respective state derivatives. This objective is accomplished by applying (2) to (1), where θc,θ˙candθ¨care used as a synthetic inputs.(2)Tc=(θ¨c+PDθ˙)·M·L2+M·L·g·cos(θ)+b·(θ˙c+PDθ)As a result of applying (2) to (1), the feedback dynamic system becomes(3)θ˙=θ˙c+PDθ(4)θ¨=θ¨c+PDθ˙Besides, letX=[x1x2]T=[θθ˙]Tbe the state vector and E=Xc−X be the error vector. Then, (3) and (4) can be written asE˙+Kp·E+Kd·E˙=0, which is the error equation of the feedback dynamic system. Due to the fact that the error equation is linear, Laplace transform can be applied in order to prove that the error goes to zero for some given values of Kpand Kd.With regard to the robust performance metrics, there are two parts: The first one objects to defining a theoretical second order system S that produces desired values for θ(t),θ˙(t), andθ¨(t), which can be determined according to some optimization criterion. In the second part, given a plant H and a controller C, a functional F is defined as a norm between the output of the theoretical system S and the output of the system [H, C]. As a consequence, instead of defining an integral of a binary function, as discussed in [49], the metric P is defined as(5)P(d)=J(d)=∫QF[S,H(q),C(d)]pr(q)dqwhere d is a vector with controller gains candidates, q is a vector of varying plant parameters in space Q with distribution pr(q). Besides, the value of P in (5) is estimated by Monte Carlo simulations with pr(q) resulting in random samples of values for q. The estimation of P based on N samples is(6)Pˆ(d)=1N·∑k=1NF[S,H(qk),C(d)]According to the optimization with noisy parameters, the HPPOA algorithm is used as an optimization algorithm capable of minimizing (6), which is a functional with noisy parameters. In summary, the process of optimizing (6) determines the gains of the controller that make the error go to zero.Simulation results are shown in Fig. 4. Simulations were carried out by considering ±30% of parametric uncertainty for all plant parameters shown in Fig. 3. The HPPOA algorithm carried out 45 generations by using a population of 60 chromosomes and 20 Monte Carlo evaluations.In this subsection, for simplicity reasons the theoretical second order system S was not optimized and the design was not formulated in terms of a multi-objective optimization problem. Now, a more detailed description about the proposed approach is presented in Sections 2.2–2.4.The process of designing the controller begins by determining dynamic inversion and proportional-derivative (PD) layers, since DI is usually not applied alone. In this work, DI layers are used to cancel the nonlinearities of the plant and PD layers are used to ensure the controller stability.Besides, the PD controller does not require an integral parameter because the aircraft dynamic model already provides an integrator for the feedback dynamic system. This has to do with the fact that position is the integral of velocity, and this relation exists in the aircraft dynamic model. As a consequence, the steady-state error is eliminated without using a PID controller. Additionally, the derivative parameter used in the PD controller helps to increase the gain margin and the phase margin, thereby contributing to enlarge the stability of the feedback dynamic system. This benefit would not be achieved if a simple proportional controller were used.The following dynamic model is considered in the design, refer to Anderson and Robbins [4] for details,(7)dVdt=g·T−DW−sin(γ)(8)dγdt=gV·[n·cos(μ)−cos(γ)](9)dχdt=g·n·sin(μ)V·cos(γ)(10)dxdt=V·cos(γ)·cos(χ)(11)dydt=V·cos(γ)·sin(χ)(12)dhdt=V·sin(γ)where the variables are: airspeed (V), flight path angle (γ), flight path heading (χ), and the position variables (x, y, h). The other parameters are: weight (W), gravitational constant (g), drag force (D), bank angle (μ), load factor (n) and thrust (T). The drag force is given by(13)D=0.5·ρ·V2·S·CDo+2·k·n2·W2ρ·V2·Swhere ρ is the air density, S is the reference area, CDois the parasite drag coefficient, and k is the induced drag coefficient.Synthetic inputs Vc, γc, χc, xc, yc, and hcare calculated so that control signals vary at the same rate that of their respective state derivatives. This objective is reached by interspersing DI and PD layers, as shown in Fig. 5. From left to right in Fig. 5, PD controllers are determined for states x, y and h. Afterwards, a DI layer is used to calculate synthetic inputs Vc, γcand χc: See Fig. 5. A second sequence of PD and DI layers are used to determine synthetic inputs Tc, ncand μc, as follows(14)Tc=W·V˙c+PDVg+sin(γ)+D(15)nc=V2·(χ˙c+PDχ)2·cos(γ)2g2+V2·(γ˙c+PDγ)2g2+cos(γ)2+2·V·(γ˙c+PDγ)·cos(γ)g(16)μc=tan−1V·(χ˙c+PDχ)·cos(γ)V·(γ˙c+PDγ)+g·cos(γ)There are six PD controllers in Fig. 5, and two gains must be determined for each of them. A vector with all gains for all PD controllers is defined in the form(17)d=[PDxTPDyTPDhTPDvTPDγTPDχT]TPDx=[kpxkdx]TPDy=[kpykdy]TPDy=[kphkdh]TPDv=[kpvkdv]TPDγ=[kpγkdγ]TPDχ=[kpχkdχ]TThe process of determining these gains makes use of robust performance measures.The robust performance indexes (metrics) are divided into two parts: The first one aims at finding a theoretical second order system, defined in terms of ξ and ωn, that make optimal the weighted average among rising time, overshoot and steady-state error. A desired output for a theoretical system S is built by means of this theoretical second order system, that is represented as(18)x˙1=x2(19)x˙2=−2·ξ·ωn·x2−ωn2·x1+ωn2·yrefThe optimal values for ξ and ωnare determined by using the hybrid partitioned-population optimization algorithm, that minimizes the functional(20)J1[ξ,ωn]=c1·tR[ξ,ωn]+c2·os[ξ,ωn]+c3·ss[ξ,ωn]where tR, os, and ss are the rising time, overshoot and steady-state error, respectively, and c1, c2, and c3 are some constants. In the second part, the stochastic objective function chosen to guide the design is defined in a multi-objective multi-level fashion as(21)J2(d)=P1(d)=∫Q1F[S1,H(q),C(d)]pr(q)dq,PDv,PDh,PDγ,PDx,PDχ∈argminJ2(22)J3(d)=P2(d)=∫Q2F[S2,H(q),C(d)]pr(q)dq,PDv,PDh,PDγ∈argminJ4(23)J4(d)=P3(d)=∫Q3F[S3,H(q),C(d)]pr(q)dq,PDv∈argminJ5(24)J5(d)=P4(d)=∫Q4F[S4,H(q),C(d)]pr(q)dqwhere (21)–(24) deal with each trajectory shown in Fig. 1.The above expressions define a way of minimizing the norm between controlled variable outputs for unmanned aerial vehicles and optimal specifications by considering parametric uncertainties of the plant, and Section 2.4 describes how HPPOA algorithm is built to solve this multi-objective optimization problem.The HPPOA optimization algorithm is based on population partitioning, as shown in Fig. 6. Each element of the population represents a controller gains vector candidate d. The elements of the population are sorted, and simultaneous perturbation approach, particle swarm optimization and genetic algorithms are applied to the first, second and third parts of the population. From the view point of particle swarm optimization, each element of the population is called particle, but from the view point of genetic algorithm, each one is called chromosome. As a consequence, particles and chromosomes represent the same component in HPPOA algorithm.Created by Kennedy et al. [26], the basic version of particle swarm optimization consists of a swarm whose elements are particles. The particles are updated by (25)–(26) until some stopping condition has been reached. In (25)–(26), r1 and r2 are random vectors whose elements are between zero and one, c1 and c2 are constant values, a is the best position for particle x and g is the position of the particle with best global localization in the swarm.(25)v←v+c1·r1·(a−x)+c2·r2·(g−x)(26)x←x+vEven though the basic version of particle swarm optimization can be used to minimize complex functions, such as Scaffer's F6 function [26], the basic version of particle swarm optimization can be improved. Instead of using the constriction factor [14] or the inertia weight [44], in this work (25) is rewritten as(27)v←v+k·{r3·(a−x)+r4·(g−x)}where r3 and r4 are random vectors whose elements are between 0.5 and 1.5 and k is a positive constant lower than 1.0. Besides, velocity of each particle is saturated when its new value increases too fast or too slow. This scheme was empirically determined while tuning the robust controller shown in Fig. 5 due to its capacity to produce good results for functions with noisy parameters.With regard to genetic algorithms, Holland [25] described several basic concepts, such as mutation, crossover and selection. Here, mutation is implemented by applying a stochastic perturbation of ±50% in every gene of chromosome while crossover is implemented by choosing a random position i that splits two stochastically chose chromosomes, whose parts separated by i are exchanged between them resulting in two new chromosomes.According to simultaneous perturbation, it is similar to the definition found in [46]. The basic idea is summarized in (28) and (29), wherex∈ℝm,g∈ℝm, aiis a real constant that is positive if the gradient Δgiis positive, and negative otherwise, and Δg is an estimation of the gradient of f(x). Although a is a positive real constant in [46], in this study it is assumed to be a random vector.(28)x←x−a·Δg(29)Δgi←f(xi+ci)−f(xi)ciIn short, simultaneous perturbations and genetic algorithms are good local and global explorers, respectively, and particle swarm optimization acts on accelerating the convergence. The particles are randomly restarted after a fixed number of iterations and whenever their fitness value is greater than a constant upper bound, whose fact increases the likelihood of finding a global optimum. As a result, HPPOA algorithm was capable of finding the following gains vector d, which is a near-optimal global solution.d=[PDxTPDyTPDhTPDvTPDγTPDχT]TPDx=[4.68×10−11.20×10−1]TPDy=[4.80×10−10.0×100]TPDh=[4.68×10−11.04×10−3]TPDv=[2.99×10−79.30×10−2]TPDγ=[1.79×1002.84×10−4]TPDχ=[1.83×1001.83×10−3]TThe proof of stability and simulations were performed by taking into account these values for the nominal case.The proof of stability is carried out in two steps. Firstly, Lemma 1 focuses on the internal dynamics of the feedback dynamic system shown in Fig. 5. Afterwards, Lemma 1 is used in Theorem 1, where the stability of the feedback dynamic system is proved for the nominal case.Lemma 1LetX∈ℝn,E∈ℝn,Kp∈ℝn,n, andKd∈ℝn,nbe respectively the state vector, the error vector, the proportional gains matrix, and the derivative gains matrix for the feedback dynamic system shown in Fig.5, whereKpandKdare diagonal matrices with gains in the diagonal. Then, the dynamics of the feedback dynamic system without saturation is given by(30)X˙=X˙c+Kp·E+Kd·E˙ProofThe proof is made by introducing the synthetic variables into the dynamic model, whose use results in the cancellation of nonlinearities. Applying (14) to (7),dVdt=g·W·V˙c+PDVg+sin(γ)+D−DW−sin(γ)=g·W·V˙c+PDVg+sin(γ)W−sin(γ)=g·V˙c+PDVg+sin(γ)−sin(γ)=V˙c+PDV=V˙c+kpv·eV+kdv·e˙V(31)dVdt=V˙c+kpv·eV+kdv·e˙VApplying (15) and (16) to (8),dγdt=gV·V2·(χ˙c+PDχ)2·cos(γ)2g2+V2·(γ˙c+PDγ)2g2+cos(γ)2+2·V·(γ˙c+PDγ)·cos(γ)g·⋯⋯·costan−1V·(χ˙c+PDχ)·cos(γ)V·(γ˙c+PDγ)+g·cos(γ)−cos(γ)=gV·V2·(χ˙c+PDχ)2·cos(γ)2+V2·(γ˙c+PDγ)2+g2·cos(γ)2+g·2·V·(γ˙c+PDγ)·cos(γ)g2·⋯⋯·V·(γ˙c+PDγ)+g·cos(γ)V2·(γ˙c+PDγ)2+g2·cos(γ)2+2·V·(γ˙c+PDγ)·g·cos(γ)+V2·(χ˙c+PDχ)2·cos(γ)2−⋯⋯−cos(γ)=gV·V·(γ˙c+PDγ)+g·cos(γ)g−cos(γ)=γ˙c+PDγ=γ˙c+kpγ·eγ+kdγ·e˙γ(32)dγdt=γ˙c+kpγ·eγ+kdγ·e˙γAgain making use of (15) and (16) in (9) one has,dχdt=V2·(χ˙c+PDχ)2·cos(γ)2+V2·(γ˙c+PDγ)2+g2·cos(γ)2+g·2·V·(γ˙c+PDγ)·cos(γ)g2·⋯⋯·gV·cos(γ)·sintan−1V·(χ˙c+PDχ)·cos(γ)V·(γ˙c+PDγ)+g·cos(γ)=V2·(χ˙c+PDχ)2·cos(γ)2+V2·(γ˙c+PDγ)2+g2·cos(γ)2+g·2·V·(γ˙c+PDγ)·cos(γ)g2·⋯⋯·gV·cos(γ)·V·(χ˙c+PDχ)·cos(γ)V2·(γ˙c+PDγ)2+g2·cos(γ)2+2·V·(γ˙c+PDγ)·g·cos(γ)+V2·(χ˙c++PDχ)2·cos(γ)2=g·V·(χ˙c+PDχ)·cos(γ)g·V·cos(γ)=χ˙c+PDχ=χ˙c+kpχ·eχ+kdχ·e˙χ(33)dχdt=χ˙c+kpχ·eχ+kdχ·e˙χAs shown in Fig. 5,Vc=(x˙c+PDx)2+(y˙c+PDy)2+(h˙c+PDh)2. Applying Vcto (10),dxdt=(h˙c+PDh)2+(y˙c+PDy)2+(x˙c+PDx)2·(x˙c+PDx)2+(y˙c+PDy)2(x˙c+PDx)2+(y˙c+PDy)2+(h˙c+PDh)2·⋯⋯·x˙c+PDx(x˙c+PDx)2+(y˙c+PDy)2=x˙c+PDx=x˙c+kpx·ex+kdx·e˙x(34)dxdt=x˙c+kpx·ex+kdx·e˙xApplying Vcto (11) we obtain the following expressiondydt=(h˙c+PDh)2+(y˙c+PDy)2+(x˙c+PDx)2·(x˙c+PDx)2+(y˙c+PDy)2(x˙c+PDx)2+(y˙c+PDy)2+(h˙c+PDh)2·⋯⋯·y˙c+PDy(x˙c+PDx)2+(y˙c+PDy)2=y˙c+PDy=y˙c+kpy·ey+kdy·e˙y(35)dydt=y˙c+kpy·ey+kdy·e˙yWith regard to (12) when Vcis applied, one hasdhdt=(h˙c+PDh)2+(y˙c+PDy)2+(x˙c+PDx)2·h˙c+PDh(x˙c+PDx)2+(y˙c+PDy)2+(h˙c+PDh)2(36)dhdt=h˙c+kph·eh+kdh·e˙h(31)–(36) are written in a matrix form,(37)V˙γ˙χ˙x˙y˙h˙=V˙cγ˙cχ˙cx˙cy˙ch˙c+kpv000000kpγ000000kpχ000000kpx000000kpy000000kph·eVeγeχexeyeh+kdv000000kdγ000000kdχ000000kdx000000kdy000000kdh·e˙Ve˙γe˙χe˙xe˙ye˙hthat is the expanded matrix form of (30), which proves Lemma 1. □A direct consequence of Lemma 1 is the proof of correction for the feedback linearization process, since is linear the equation that represents the internal dynamics of the feedback dynamic system without saturation.The process of tuning the controller is carried out without saturating control signals and none of them remains saturated during steady state operation. Besides, the system remains stable with and without saturing control signals, and saturation is only and really necessary for improving transition behavior for velocity commands.Theorem 1LetI∈ℝn,n,X∈ℝn,E∈ℝn,Kp∈ℝn,n, andKd∈ℝn,nbe respectively the identity matrix, the state vector, the error vector, the proportional gains matrix, and the derivative gains matrix for the feedback dynamic system shown in Fig.5, whereKpandKdare diagonal matrices. LetKp>0be true. Then, the dynamic system is asymptotically stable ifKd>−I.ProofAccording to Lemma 1, since the internal dynamics is linear, Laplace transform can be applied, and the error can be calculated as a function of time,X˙=X˙c+Kp·E+Kd·E˙(38)X˙c−X˙+Kp·E+Kd·E˙=E˙+Kp·E+Kd·E˙=Kp·E+(I+Kd)·E˙=0LKp·E+(I+Kd)·E˙=L0=Kp·E(s)+(I+Kd)·s·E(s)−E(0)=Kp·E(s)+(I+Kd)·s·E(s)−(I+Kd)·E(0)=(Kp+(I+Kd)·s)·E(s)−(I+Kd)·E(0)=0(39)E(s)=Kp+(I+Kd)·s−1·(I+Kd)·E(0)=I+Kd·I+Kd−1·Kp+s−1·(I+Kd)·E(0)L−1{E(s)}=L−1I+Kd·I+Kd−1·Kp+s−1·(I+Kd)·E(0)=L−1I+Kd−1·Kp+s−1·I+Kd−1·(I+Kd)·E(0)=E(t)=E(0)·e−t·I+Kd−1·Kp(40)E(t)=E(0)·e−t·I+Kd−1·KpI+Kd−1·Kp>0⇒limt→∞E(t)=0which clearly proves the theorem since diagonal matrices are always invertible. □Since all kpgains found by HPPOA algorithm are greater than zero and all kdgains are greater than −1.0, then the system is stable. However, due to practical limitations, kpand kdgains cannot indefinitely increase. For instance, aggressive PD controllers can amplify noise, which can affect the control. This is the reason why simulations and numerical verification of robustness are also important.Simulations were ran by using the Runge–Kutta 4 algorithm and the C++ programming language. Gnuplot is used for graphics.In this work, maximum and minimum allowed values for velocity are equal to 289.56m/s and 57.91m/s, respectively, and all step commands for distance in Fig. 1 for maximum and minimum velocities are equal to 30.48m and 6.10m, respectively, since the relation between maximum and minimum velocities has to be equal the relation between maximum and minimum step commands for distance. For both cases, the maximum value is 5 times the minimum value.Results shown in Figs. 7, 8 and 9were obtained by considering maximum velocity, where longitudinal, latitudinal and vertical distance errors were 99.24%, 99.86%, and 99.82% lower than its initial values within 10.0s, and velocity error was 99.60% lower than its initial value within 10.0s. Results for minimum velocity, although not shown, were reached with behavior almost identical to the one achieved for maximum velocity. For instance, lateral and vertical errors decrease at exactly the same rate for minimum velocity cases, which is also an evidence that the dynamic inversion is correct. Furthermore, noise does not considerably affect the simulation results.The HPPOA algorithm was carried out for 80 genetic generations by using a population with 60 chromosomes and 20 Monte Carlo evaluations. The reduced number of genetic generations has to do with the fact that particle swarm optimization accelerates the convergence of the genetic algorithm. In addition, the number of chromosomes is chosen so that particle swarm optimization runs with 20 particles, since a swarm greater than 20 individuals does not considerably improve the result but affect the performance.Although a few number of genetic generations is spent by the HPPOA algorithm, the process of finding the controller gains can be intensive in terms of computational processing due to the Monte Carlo evaluations and the considerable number of time steps involved, since the trajectory is in the order of kilometers, and the value of each time step is 0.0625s. Otherwise, HPPOA algorithm has polynomial time complexity [21], which implies that the processing time is not explosive in terms of its variables, such as the number of restartings, the number of genetic generations, and the number of chromosomes. Besides, the processing time can become less intensive by reducing the value of these variables, but with the cost of reducing the likelihood of finding a global optimal result. On the other hand, the numerical verification of robustness has considerably lower time complexity than HPPOA algorithm, whose fact enables a greater number of testes, as described in Section 5.The results can be considered to be quite close to the optimal specifications. Simulation results were only reached after solving the multi-objective optimization problem in a multi-level fashion, instead of applying the scalarization approach. This is explained by the fact that the scalarization approach is a weighted average among several variables, and it cannot determine the minimum among several multi-objective solution candidates that are equal in module but are different in terms of its components, whose fact can significantly difficult the optimization process or make even impossible find the lowest value among several local minima.In this work, robustness verification consists of determining the maximal reduction in the aircraft performance during 105 Monte Carlo evaluations made for each maneuver shown in Fig. 1 by considering ±30% of parametric uncertainties of all aircraft parameters.The largest numerical final values for longitudinal, latitudinal and vertical errors were equal to 4.54×10−5m, 1.92×10−7m, and 8.51×10−7m, respectively. The greatest numerical final value for velocity error was equal to 22.70m/s, which was 2.39% lower than the desired value. Therefore, the controller remains stable even considering the significant number of 105 combinations of parametric uncertainties for the aircraft dynamic model.Besides, the greatest values for longitudinal, latitudinal, vertical and velocity errors were 99.24%, 99.86%, 99.80%, and 97.61%, respectively lower than its initial values within 10.0s. These values are quite similar to the ones found for the nominal case shown in Section 4. This means that the performance of the proposed controller is considerably robust against parametric uncertainties of the aircraft dynamic model.With regard to the efficiency, robustness verification depends on the number of time steps and the number of iterations, while the process of tuning the controller also depends on the size of chromosomes population, the number of restartings, the number of parametric uncertainties of the plant, and the cost of sorting the chromosomes population. As a consequence, the time complexity for the process of tuning the controller is greater than the one for the process of verifying the robustness. On the other hand, due to reliability reasons, a large number of iterations is interesting for robustness verification, but it is not so necessary to tune the controller. For this reason, instead of considering a large number of iterations for the process of tuning the controller, in this study the number of iterations is kept low for the process of tuning the controller, but is considerably higher for robustness verification. In summary, this fact helps to improve the efficiency of the proposed methodology without affecting the reliability of the robustness.

@&#CONCLUSIONS@&#
The proposed approach can be used to effectively design a near-optimal nonlinear controller robust against parametric uncertainties of the plant, where the proof of stability is compatible with the simulation results, and the process of tuning the controller minimizes differences between system outputs and optimal specifications given in terms of rising time, overshoot and steady-state error.Besides, the proposed probabilistic approach has some important features. First, chattering does not happen or happen very rarely, since control is essentially continuous. Second, gain scheduling is not necessary, because dynamic inversion acts as a universal gain scheduler, which significantly simplifies the design and consequently reduces the work load necessary to design it. Third, the design is made without trial-and-error procedures, since the controller is directly tuned by an optimization algorithm. Fourth, the proposed approach helps to reduce conservatism, since the design is formulated in terms of a multi-objective optimization problem whose algorithm used to solve it has very high likelihood of finding a global optimal or near-optimal solution, and dynamic inversion makes possible prove the stability by using linear control theory, which is considerably simple and well-known. Fifth, the proposed methodology is interesting for real-time applications, since the optimization process is made at design time, which results in constant gains that do not change during real-time operations. Seventh, since the performance is specified in terms of rising time, overshoot and steady-state error by directly taking into account trajectories that must be followed, the proposed approach can be considered relatively intuitive.However, dynamic inversion has been criticized due to its sensitivity to parametric uncertainties of the plant. Although this drawback is mitigated in [49], the scalarization approach used in [49] cannot determine the minimum among several multi-objective solution candidates that are equal in module but have different components [15]. This is the reason why in this study the optimization is performed in a multi-objective multi-level fashion. Besides, similar results were not achieved after using the scalarization approach. As a consequence, the proposed approach helps to enlarge the range of applications where dynamic inversion can be applied. In fact, the robustness of the controller against parametric uncertainties can be considered notable for an approach that is based on dynamic inversion, since the inability to support parametric uncertainties has been one of the main drawbacks of dynamic inversion, and even so the controller succeeded in bearing ±30% of parametric uncertainty for all aircraft parameters, and without considerably affecting its performance for the nominal case.With regard to the optimality of the result, even when it is not possible to assure that the result found by the proposed approach is a global optimum, the process of tuning the controller exhibits a very high likelihood of finding results quite close to the global optimal solution. This fact is confirmed by the simulation results and by previous studies about the bio-inspired optimization algorithm [21] used in this study.