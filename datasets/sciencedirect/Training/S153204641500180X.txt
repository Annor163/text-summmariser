@&#MAIN-TITLE@&#
Identifying adverse drug event information in clinical notes with distributional semantic representations of context

@&#HIGHLIGHTS@&#
A corpus of Swedish clinical notes was annotated for adverse drug event information.Detecting adverse drug events in clinical notes can support pharmacovigilance.Modeling context with distributional semantics yielded better predictive models.Distributed word representations allowed more context information to be incorporated.Inter-sentential relations between drugs and disorders/findings are hard to detect.

@&#KEYPHRASES@&#
Adverse drug events,Electronic health records,Corpus annotation,Machine learning,Distributional semantics,Relation extraction,

@&#ABSTRACT@&#
For the purpose of post-marketing drug safety surveillance, which has traditionally relied on the voluntary reporting of individual cases of adverse drug events (ADEs), other sources of information are now being explored, including electronic health records (EHRs), which give us access to enormous amounts of longitudinal observations of the treatment of patients and their drug use. Adverse drug events, which can be encoded in EHRs with certain diagnosis codes, are, however, heavily underreported. It is therefore important to develop capabilities to process, by means of computational methods, the more unstructured EHR data in the form of clinical notes, where clinicians may describe and reason around suspected ADEs. In this study, we report on the creation of an annotated corpus of Swedish health records for the purpose of learning to identify information pertaining to ADEs present in clinical notes. To this end, three key tasks are tackled: recognizing relevant named entities (disorders, symptoms, drugs), labeling attributes of the recognized entities (negation, speculation, temporality), and relationships between them (indication, adverse drug event). For each of the three tasks, leveraging models of distributional semantics – i.e., unsupervised methods that exploit co-occurrence information to model, typically in vector space, the meaning of words – and, in particular, combinations of such models, is shown to improve the predictive performance. The ability to make use of such unsupervised methods is critical when faced with large amounts of sparse and high-dimensional data, especially in domains where annotated resources are scarce.

@&#INTRODUCTION@&#
The digitization of healthcare data, as a result of the increasingly widespread adoption of electronic health records (EHRs), has rendered its analysis possible on a large and unprecedented scale. However, despite the widely acknowledged transformative potential of exploiting EHR data for secondary use in the endeavor of improving healthcare and supporting public health activities, it remains a largely underutilized resource [1], partly as a result both of technical challenges and possible application areas being underexplored. To ensure, then, that this valuable resource is more widely tapped and its potential fully realized, computational methods need to be developed for this particular domain.A nascent line of research concerns the application of machine learning algorithms to EHR data for the construction of predictive models that can be employed in a wide range of tasks. There are, however, many challenges involved in learning high-performing predictive models from EHR data, such as the high dimensionality caused by the large number of variables that can be used to describe a given set of observations, as well as the typically accompanying sparsity. There is also an inherent heterogeneity in EHR data, entailing that the various data types cannot be handled in an identical fashion. The majority of EHR data is, for instance, expressed in natural language, albeit in a form that is greatly specialized and domain-dependent: clinical text typically does not conform to standard grammar rules and is often littered with shorthand and misspellings [2,3], further exacerbating the aforementioned dimensionality and sparsity issues. There is perhaps, then, a particular need to adapt natural language processing (NLP) techniques to the genre of clinical text, lest the potentially valuable information contained therein should be ignored. It is moreover critical that research is conducted on languages other than English.One public health activity that may be supported through secondary use of EHR data is pharmacovigilance, i.e. post-marketing drug safety surveillance, as alternatives to spontaneous reporting systems for information on adverse drug events (ADEs) are currently being explored, not least in order to address the gross underreporting of ADEs that create obstacles in obtaining reliable incidence estimates. In comparison to spontaneous case reports, EHRs have several advantages, such as providing longitudinal observations of patient treatment, including drug prescriptions and administration. Unfortunately, ADEs are also heavily underreported in EHRs, where they can be encoded by a, albeit rather limited, set of diagnosis codes. It is therefore important to develop capabilities to process clinical notes, where clinicians may describe and reason around suspected ADEs.Extracting information pertaining to ADEs in clinical notes requires a number of key components: (1) named entity recognition, i.e. being able to detect mentions of, for instance, drugs, symptoms and disorders; (2) concept attribute labeling, e.g. being able to determine if named entity mentions are expressed with negation, speculation or a non-current temporality (past/future events); and (3) relation extraction, i.e. being able to detect and classify relations that may hold between pairs of named entity mentions. Machine learning can be leveraged to construct predictive models to perform such tasks automatically. Doing so, however, requires access to substantial amounts of labeled data, which is typically not readily available and, to create for every problem, domain and language, is prohibitively expensive, particularly when medical experts are required to provide the annotations.In this paper, we describe the creation of such an annotated resource – comprising clinical notes written by physicians in Swedish – that is then used to construct predictive models, which, in turn, are used to identify information pertaining to ADEs in clinical notes. To address the aforementioned challenges – high dimensionality and sparsity, on the one hand, and limited availability of annotated resources in the clinical domain, on the other – we investigate how models of distributional semantics can be leveraged to obtain enhanced predictive performance on the three identified tasks. Distributional semantics essentially allow word representations, typically in vector space, to be obtained in a wholly unsupervised manner. These can be used to generate (semantic) features that can subsequently be exploited by a learning algorithm when constructing predictive models. In a series of experiments, such representations of the data are shown to be more conducive to learning high-performing predictive models in comparison to the commonly employed bag-of-words (BOW) approach. The ability to exploit large amounts of unlabeled data is critical when faced with volumes of EHR data that are approaching “big data”.

@&#CONCLUSIONS@&#
We have reported on the creation of an annotated resource of Swedish clinical notes that can be used for learning key tasks that may ultimately help to enable secondary use of electronic health records for the purpose of supporting pharmacovigilance activities. To that end, relevant entity mentions, such as drugs and disorders, first need to be recognized in the oftentimes noisy clinical text. That is not enough, however, as the context in which the entities are mentioned is key: an entity’s negation, uncertainty and temporal status needs to be determined. Once that has been achieved, it is potentially very valuable to detect and classify relations that may hold between pairs of entities, primarily between drugs and symptoms. In this respect it is paramount to be able to distinguish between indications and adverse drug events. We tackled all three tasks within the supervised machine learning paradigm. To address some of the challenges of applying machine learning to electronic health records data, such as high dimensionality and sparsity, and to minimize the amount of labeled data that is needed, models of distributional semantics were leveraged to create dense word representations. These were, in turn, used to model context information, which for most tasks was shown to be important to increase the predictive performance; this scalable approach allows variable amounts of context information to be incorporated without increasing the dimensionality, which is a consequence of using bag-of-words representations. In most cases, employing distributional semantic features improved the predictive performance and, in certain cases, further improvements were obtained by utilizing multiple distributional semantic spaces.