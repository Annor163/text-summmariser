@&#MAIN-TITLE@&#
Mining approximate temporal functional dependencies with pure temporal grouping in clinical databases

@&#HIGHLIGHTS@&#
We focus on dependencies over facts (e.g. diagnosis vs therapy) stored in a database.Dependencies may generally hold: deviating facts set up an approximate dependency.We group data in sets, either by temporal granules or by fixed-length sliding windowsWithin every set, we look for temporal approximate dependencies.We mine psychiatry and pharmacovigilance data sets and derive new knowledge.

@&#KEYPHRASES@&#
Approximate temporal functional dependency,Temporal granule,Sliding window,Grouping,Psychiatric patients,Pharmacovigilance,

@&#ABSTRACT@&#
Graphical abstract

@&#INTRODUCTION@&#
Current clinical database systems enable us to store huger and huger quantities of data, and data mining techniques help in extracting relevant knowledge from these data. Analyzing temporal evolution of data, time series, changes of information over time, may lead to additional temporal knowledge. Temporal data mining is the research field in this direction, working on structured [1] and, occasionally, on semi-structured data [2].Knowledge on (clinical) databases may be expressed in two ways: on one hand, it can be represented through suitable constraints on data; on the other hand, it can be derived through the analysis of data by discovering patterns, regularities, and so on.According to the first point of view and considering data stored in a plain relational database, we may express constraints by identifying functional dependencies (FD). Let us consider, for example, a simple database table describing the reference areas for emergency admissions in a region. We typically specify that patients have a single reference hospital for emergencies, depending on their address (considering the neighborhood of the admitting reference hospital). We can thus specify a functional data dependency between the home address of the patient and the location of the hospital: all patients with the same address must refer to the same hospital. Leveraging the definition of functional dependencies as a way of expressing constraints on data, the research community focused also on extending FDs to deal with data temporalities [3–7]: as example, a temporal functional dependency (TFD) may be used to express the constraint that the reference hospital for emergencies depends on the patient home address, but this dependency may change according to the season of the year.On the other hand, a different approach has to be taken if we consider, for example, a database table collecting data on patients who were admitted for emergencies to hospitals. In this case, we cannot constrain patient addresses to hospitals in a strict way, but we could discover on the collected data that the dependency between patient addresses and hospitals hold on most tuples of the database, but not on all the tuples of that database. We call this an approximate functional dependency (AFD): patients with the same home address usually go to the same hospital (not always the reference one) when they are at home, but, as an example, some patients on holiday could have been admitted to an hospital which is not the closest one to their home address. The issue of discovering approximate functional dependencies from data has been largely studied in the literature [8–11].As final consideration, we may also experience that over some periods of the year we generally observe an approximate functional dependency, while in some other periods we observe a different approximate dependency: for example, it could occur that patients go to different hospitals for emergencies even according to some specific skills of hospitals in managing seasonal pathologies. In this case, it still holds that we can discover approximate dependencies between patient addresses and hospitals for emergencies, but only if we group data according to the season and the year of the emergency admission. We call this an approximate, temporal functional dependency (ATFD). At the best of our knowledge, studies on approximate temporal functional dependencies still lack.According to the depicted scenario, the aim of this paper is to propose a first step, focusing on a specific type of ATFD, of a general framework for temporal data mining of clinical data. In particular, we adopt a framework for temporal functional dependencies recently proposed by Combi et al. [7]: the framework subsumes all the previous proposals dealing with temporal functional dependencies for relational databases and introduces some new kinds of temporal functional dependencies. According to this framework, we then focus on the issue of mining (approximate) temporal functional dependencies based on a temporal grouping of tuples. We introduce the concept of approximate temporal functional dependency with temporal grouping, and discuss through some examples both the case when grouping is induced by granularities (i.e. time units) and the case when sliding windows are used. Then, we propose efficient algorithms for this kind of temporal data mining. Finally, we discuss the application of our algorithms to real world clinical data from the psychiatric and pharmacovigilance domains.Besides the technical performances, we discuss the clinical meaning and the most relevant mined temporal dependencies; in this regard, it is worth noting that the mined temporal functional dependencies are a relatively new kind of clinical knowledge on data, which deserves further efforts to become clearly interpretable by physicians in a daily clinical setting. Indeed, while association rules and temporal association rules have been considered in clinical domains for years and their role in the clinical decision-support process has been widely acknowledged [12,13], approximate temporal functional dependencies represent a new piece of knowledge that has to be properly integrated in clinical decision-support processes. As an example, temporal association rules may allow one to derive knowledge as “most patients presenting a symptom of chest pain overlapping nausea receive, within few days, a therapy with acetylsalicylic acid”. On the other side, approximate temporal functional dependencies provide knowledge at a higher abstraction level, as “in most cases, patients with the same symptoms are given the same drug (i.e. active principle), considering a time window of 10days”. Such kind of knowledge refers to a general relationship between some features of a patient, in this case symptoms and therapies: the relationship holds for any specific values of such features. Such a valuable kind of knowledge requires physicians to merge it with more specific knowledge, such as that one coming from temporal association rules, in the whole decision making process.The main novelty aspects of this paper can be summarized as in the following, even with a specific reference to the preliminary work in [14], where the main focus was on the proposal of ATFDs and on some preliminary experiments on a reduced set of psychiatry data with some first prototypal algorithms:•we discuss in detail the proposed approach for ATFDs and introduce completely new algorithms both for granularity-based temporal mining and for mining through sliding windows;we present and discuss two important clinical domains, i.e. psychiatry and pharmacovigilance, where temporal data mining is highly required. As the mined temporal dependencies are sometime completely new and unexpected even to expert physicians, we discuss here some possible interpretations of the discovered knowledge;the new experimental results, with a new and extended setting considering two different data sets from psychiatry and pharmacovigilance, consist of both a detailed performance analysis and an evaluation and discussion of the mined ATFDs from a clinical point of view.In the following, we describe the background and the related work (Section 2) and discuss the two clinical domains we considered for temporal data mining, namely psychiatry and pharmacovigilance (Section 3); we introduce the concept of approximate temporal functional dependency (ATFD), providing some examples on the application scenario (Section 4); then we describe how to mine minimal ATFDs (Section 5) and deploy the proposed techniques in clinical domains; we describe the experimental results obtained by considering data in the two mentioned domains (Section 6), and finally (Section 7) we draw some conclusions and sketch out some possible directions for future research.We recall here the definition of functional dependency (FD), and then introduce its extensions: approximate functional dependency (AFD) and temporal functional dependency (TFD). Such concepts will lead to the definition of approximate temporal functional dependency (ATFD) of Section 4, where ATFD inherits the properties both from AFD and from TFD.The concept of functional dependency (FD) comes from the database theory and is defined as follows [15]:Definition 2.1Functional dependencyLet r be a relationship over the relational schema R: letX,Y⊆Rbe attributes of R. We assert that r fulfills the functional dependencyX→Y(written asr⊨X→Y) if the following condition holds:∀t,t′∈r(t[X]=t′[X]⇒t[Y]=t′[Y])Informally, for all the couples of tuples t andt′showing the same value(s) on X, the corresponding value(s) on Y for those tuples are identical.Moving closer to the main kind of temporal features we shall consider here, several kinds of temporal functional dependencies (TFDs) have been proposed in the literature, usually as temporal extensions of the widely known (atemporal) functional dependencies [16]. As an example, we may consider that patients affected by a common pathology p1 may assume a common therapy t1 during some month M1, while in other month M2 the same patients affected by the same pathology p1 as above, do follow the another common therapy t2.Recently, Combi et al. proposed a framework for TFDs that subsumes and extends the considered previous proposals [7]. The proposed framework is based on a simple temporal relational data model based on the notion of temporal relation, i.e. a relation extended with a timestamping temporal attribute VT, representing the valid time temporal dimension, i.e. the time when the fact is true in the real world [17].Two temporal views have been introduced: they allow one to join tuples that represent relevant cases of (temporal) evolution. On the base of the introduced data model, and leveraging the introduced temporal views, TFDs may be expressed by the syntax[E-Exp(R),t-Group]X→YwhereE-Exp(R)is a relational expression on R, called evolution expression,t-Groupis a mappingN→2N, called temporal grouping, andX→Yis a functional dependency.As for the semantics, similar to the case of standard FDs, a TFD is a statement about admissible temporal relations on a temporal relation schema R with attributesU∪{VT}. A temporal relation r on the temporal relation schema R satisfies a TFD[E-Exp(R),t-Group]X→Yif it is not possible that the relation obtained from r by applying the expressionE-Exp(R)features two tuplest,t′such that (i)t[X]=t′[X], (ii)t[VT]andt′[VT](and the valid times of their evolutions, if present) belong to the same temporal group, according to the mappingt-Group, and (iii)t[Y]≠t′[Y]. In other words, FDX→Ymust be satisfied by each relation obtained from the evolution relation by selecting those tuples whose valid times belong to the same temporal group.Temporal grouping enables us to group tuples together over a set of temporal granules, based on one temporal dimension. We focus here on the VT temporal dimension.Four different classes of TFD have been identified in the following [7]:•Pure temporally groupingTFD:E-Exp(R)returns the original temporal relation r. Rules of this class force the FDX→Y, whereX,Y⊆U, to hold over all the maximal sets which include all the tuples whose VT belongs to the same temporal grouping.Pure temporally evolvingTFD:E-Exp(R)collects all the tuples modelling the evolution of an object. No temporal grouping exists, that is, the temporal grouping collects all the tuples of r in one unique set.Temporally mixedTFD: The expressionE-Exp(R)collects all the tuples modelling the evolution of the object. The temporal grouping is applied to the set of tuples generated byE-Exp(R).Temporally hybridTFDs: First, the evolution expressionE-Exp(R)selects those tuples of the given temporal relation that contribute to the modelling of the evolution of a real-world object (that is, it removes isolated tuples); then, temporal grouping is applied to the resulting set of tuples.In the remainder of the paper, we shall focus only on pure temporally grouping TFDs.The concept of approximate functional dependency (AFD) derives from the concept of plain FD. Given a relation r where a FD holds for most of the tuples in r, we may identify some tuples for which that FD does not hold. Consequently, we define some measurements over the error we make in considering the FD to hold on r. One measurement [8] is known as G1 and considers the number of violating couples of tuples. Another measurement [8], known as G2, considers the number of tuples which violate the functional dependency. The most common measurement [8], known as G3, considers the minimum number of tuples in r to be deleted for the FD to hold. Formally,G3(X→Y,r)=|r|−max{|s|∣s⊆r∧s⊨X→Y}The related scaled measurement g3 is defined asg3(X→Y,r)=G3(X→Y,r)/|r|We can now introduce here the definition of approximate functional dependency AFD as follows:Definition 2.2Approximate functional dependencyLet r be a relation over the relational schema R: letX,Y⊆Rbe attributes of R. Relation r fulfills an approximate functional dependencyX→εY(written asr⊨X→εY) ifg3(X→Y,r)≤ε, where ε is the maximum acceptable error defined by the user.Among the several AFDs that can be identified over a relation r, the minimal AFD is of particular interest, as many other AFDs can then be derived from the minimal one. We thus define the minimal AFD as follows:Definition 2.3Minimal AFDGiven an AFD over r, we defineX→εYto be minimal for r ifr⊨X→εYand∀X′⊂Xwe have thatr⊭X′→εY.In order to motivate and validate our approach, we consider two clinical domains: the first one refers to psychiatry, collecting data about contacts between patients and psychiatrists, psychologists, and social workers; the second one refers to pharmacovigilance, collecting data about drug administrations and adverse reactions.The first application domain (see Section 3.3 for further examples) refers to the Verona Psychiatric Case Register (PCR). The Verona Health District serves about 460,000 inhabitants. The National Health Service in trust with the University of Verona offers a public Community-based Psychiatric Service (CPS), providing psychiatric care to mentally ill as well as psychological care and responses to social needs. Data about patients are collected in the information system PCR, which has recorded information about patients׳ accesses to this service since 1979. At the first contact with the psychiatric service, socio-demographic information, past psychiatric history, and clinical data are routinely collected for patients aged 14 and over. Recorded contacts with psychiatrists, psychologists, social workers and psychiatric nurses including home visits, telephone calls, and day cares. Data on some 28,700 patients and more than 1,500,000 psychiatric contacts have been recorded. Besides patients׳ personal data (e.g., birth information, health insurance card number, gender, nationality, and previous contacts), patients׳ medical record, and contact information (contact duration, involved professionals, referrals, contact type, and conclusions), PCR also records education, employment, professional status, type of accommodation, and marital status of patients.PCR is used as a basis to evaluate the direct management costs for groups of patients, and to monitor the effects coming from changes in resources, organization, and needs. The clinical purposes include monitoring of patients to plan future contacts at regular time intervals, and providing clinicians with reports about admissions and contacts for every patient in a given time period.PCR stores several temporal data: a patient׳s contact is temporally qualified by its occurrence timestamp, while other personal information are qualified by their respective valid time. These temporal data can then be used by epidemiologists, e.g. to identify the number of contacts in different time periods with respect to different factors such as age, diagnosis.Pharmacovigilance (PhV) collects, analyzes, and prevents adverse reactions induced by drugs (ADR) [18]. In fact, also because of the limitations of pre-marketing trials (e.g. short duration of the study, highly selected test population), adverse reactions often go undetected, and become evident when the drug is put on the market, only [19]. Therefore a continuous monitoring of the effects is needed.The spontaneous reporting of ADRs identifies unexpected reactions and informs the regulating authority about them. This practice is valuable, provides early warnings, and requires limited economic and organizational resources [20]. It also has the advantage of covering every drug on the market and every category of patient.PhV considers possible relationships between one or more adverse reactions and one or more drugs, mainly focusing on unknown or completely undocumented relationships. Reports suggest a cause-effect link among ADRs and drugs: the link can be classified as “suspected” or “concomitant’. Reports are submitted by a physician, a chemists, or a private citizen.Each report includes patient׳s information (age, nationality, gender, weight, outcome of reactions, and so on), drug(s) involved in the suspected reaction(s) (identified by their Anatomical Therapeutic Chemical – ATC – classification, brand name, dosage), and the description of the occurred adverse reaction(s) encoded by means of the MedDRA classification [21]: MedDRA is a standard medical terminology used to classify adverse event information associated with the use of bio-pharmaceuticals and other medical products (e.g. medical devices and vaccines).Temporal data refer to entry date, drug name, exposure period, and adverse reaction. These temporal data are used to investigate any cause-effect relationship among drugs and reaction(s) in different time periods, or according to the time frame of the exposure.Throughout the paper we will refer to examples from the Verona Psychiatric Case Register (PCR). Table 1graphically depicts a simplified excerpt of database table Contact: VT (valid time, i.e., the date of the contact), ContactNumber (internal identifier of the contact), Patient (patient׳s name), Duration (of the contact), Area (location of the patient at contact time), and Professional (name of the operator responsible of the contact).We can start making some comments. Generally, one Patient refers to the same Professional: but this may not be always true. In the example of Table 1, we have Professional=“Mike” for all the tuples but Tuple#=2 and Tuple#=6. Thus, FDPatient→Professionaldoes not hold: that FD holds if we delete those two tuples out of the six tuples we have in Table 1. Consequently, according to the measurement of Definition 2.2,G3(Patient→Professional,Contact)=2.Moreover, AFDPatient→0.5Professionalholds becauseg3(Patient→Professional,Contact)≤0.5. Thus, accepting an error of 0.5 (50% of error), we can assert the AFDPatient→Professional. Instead, the AFDPatient→0.1Professionaldoes not hold, becauseg3(Patient→Professional,Contact)>0.1.Obviously, the plain FDX→Yequals the AFDX→0.0Y, whereg3(X→Y,r)=0.0.Besides plain AFDs, clinicians could be interested in discovering some temporal properties, relevant even from the clinical point of view. For example, according to the content of Table 1, it could be important to discover that some (approximate) dependencies hold month by month. The dependency from Patient to Duration holds month by month and it could be related to seasonal conditions influencing the overall state of the patient and requiring different durations of the contact. On the other hand, further dependencies could be observed when corresponding tuples are within a fixed time span. For example, an approximate dependency holds from Patient to Duration, considering a time span of three months (i.e., by deleting Tuple#=2 and Tuple#=6): such an approximate dependency could be related to the fact that the same patient usually has contacts of the same duration within some given time span, as the possible changes of a psychiatric state are slow with respect to the frequency of the contacts. As we shall see in the following sections, such dependencies require to group data in different ways, either according to non-overlapping time granules or according to (overlapping) time windows. We observe here that discovering this kind of temporal dependency over clinical data could help physicians to have a better and deeper understanding and management of some temporal behaviors of their patients.Moving from the definitions of FD, TFD, and AFD, we now introduce the concept of ATFD. In the following, we consider the basic temporal extension of the relational model proposed in [7]: we consider relations of a generic relational schema R with attributesU∪{VT}, where the set U is that of atemporal attributes, while VT represents the valid time. Moreover, according the taxonomy proposed in [7] and described in Section 2, we consider here pure temporal grouping TFDs of the form[r,t-Group]X→Y, wheret-Groupconsists only of granularity (Gran) or sliding window (SW) grouping:1.Grouping on granules (granularity grouping, or Gran grouping): A temporal granularity is a partition of a temporal domain in indivisible non-overlapping groups, i.e., granules, of time points: minutes, hours, days, months, years as well as working days are granularities[22].Two tuplest1,t2∈rbelong to the same temporal group Gran(i) ifft1[VT],t2[VT]∈Gran(i)where Gran(i) is the ith granule of granularity Gran.Grouping on sliding windows (SW): A sliding window11Actually a sliding window comes with three parameters, granularity, beginning timestamp, and size, as the number of time points inside the window.SW(i,k)includes all the time points in interval[i…i+k−1]. Thus, once we fix the length of the SW over relation r (i.e. k in the example), every SW over r will feature that length, and will - at most - include k elements (if relation r has tuples for all the time points of interval[i…i+k−1]).Two tuplest1,t2∈rbelong to the same sliding windowSW(i,k)ifft1[VT],t2[VT]∈[i…i+k−1].Before introducing ATFD, let us consider a new error measure, namely G4, we shall use for approximate temporal functional dependencies. G4 considers the minimum number of tuples in r which must be modified for the plain TFD to hold on all the tuples of r. In the following, if looking for an FD such asX→Y, we assume to modify only values for the Y attributes. The ε parameter is user-defined and it states the maximum error acceptable by that user:G4([r,t-Group]X→Y,r)=min{|s|∣s⊆r,((r−s)∪w)⊨[r,t-Group]X→Y}where the set w is the minimal one for which the following formula holds∀t∈s(∃t′∈w(t[U−Y]=t′[U−Y]∧t[VT]=t′[VT]))The related scaled measurement g4 is defined asg4(X→Y,r)=G4(X→Y,r)/|r|We anticipate here that, if we consider the Gran grouping, the two measurements g3 and g4 do not differ. However, as we shall describe in the following, g3 and g4 may differ when the SW grouping is considered.We define the ATFD with granularity grouping asDefinition 4.3ATFD with Gran groupingLet r be a relation over the relational schema R with attributesU∪{VT}: letX,Y⊆Ube attributes of R. Let Gran be the reference granularity. Relation r fulfills an approximate temporal functional dependency (written asr⊨[r,Gran]X→εY) iffg3([r,Gran]X→Y,r)≤ε.That is, the percentage of tuples in the entire relation r to be deleted for a ATFD to hold on all the tuples of r is less than ε; tuples of r are then grouped according to the granule of Gran their VT value belongs to, to evaluate the considered ATFD. We recall that the count of tuples in r to be deleted refers to the entire relation r, and not to the group – and one tuple may belong to one group only, if we use a Gran grouping.As an example, let us consider the fragment of the database table Contact, as depicted by Table 1, and Definition 4.3 based on the measurement G3.ATFD[Contact,Year(i)]Patient→0.4Durationholds, as tuples for which the rule does not hold, i.e. the tuples Tuple#=3 or Tuple#=6 in the specific example, and which need to be deleted for the rule to hold on all the tuples are less than the 40% in the entire table (Table 1).In fact, if we group the tuples according to granularity Year granularity, we can identify groupsYear(2007),Year(2008). For the first group (Year(2007)), two tuples (Tuple#=1 and Tuple#=2) out of three in the group confirm the FDPatient→Durationfor a Duration of 10. For the second group (Year(2008)), two tuples (Tuple#=4 and Tuple#=5) out of three in the group confirm the FDPatient→Durationfor a Duration of 35. As a consequence, the overall error is 2/6, or1/3, and it is smaller than 40%, and the required ATFD[Contact,Year(i)]Patient→0.40Durationholds on the fragment of Table 1.If we again consider the fragment of Table 1 and group tuples according to granularity Year, as we did before, we can check ATFD[Contact,Year(i)]Patient→0.1Area, accepting an error of 10%. While FDPatient→Areaholds on all the tuples of group ofYear(2007)(where Area=“North”), inside the group ofYear(2008)the FD (where Area=“South”) fails on one tuple (Tuple#=5) out of the three we have. The overall error is 1/6 or 16.66%, which is greater that the allowed 10%. Thus, ATFD[Contact,Year(i)]Patient→0.1Areawith an error of 0.1 does not hold on the fragment of Table 1.As for plain AFD, we can introduce the concept of minimality also for ATFD.Definition 4.4Minimal ATFD with Gran groupingAn ATFD[r,Gran]X→εYis said to be minimal for r iffr⊨[r,Gran]X→εYand∀X′⊂Xwe have thatr⊭[r,Gran]X′→εY.We define the ATFD with sliding window (SW) grouping as follows:Definition 4.5ATFD with SW groupingLet r be a relation over the relational schema R with attributesU∪{VT}: letX,Y⊆Ube attributes of R. Let{i…i+k−1}be a sliding window (SW) of length k. The relation r fulfills an approximate temporal functional dependency (written asr⊨[r,{i…i+k−1}]X→εY) iffg4([r,{i…i+k−1}]X→Y,r)≤ε.A similar definition can be derived from Definition 4.5 by replacing g4 with g3, as we shall discuss in Section 4.3.We consider as many SWs as possible, every SW sizing k elements: thus, the first considered sliding window isi…i+k−1, the second considered sliding window isi+1…i+k, the third considered sliding window isi+2…i+k+1, and so on. Every SW sets up a group (or chain) over which the ATFD is checked. The ATFD must hold, with an acceptable amount of error smaller than ε, over the entire database: we recall that, if we delete (as for measurement g3) or modify (as for the measurement g4) a tuple inside a SW, that tuple will remain deleted or modified in all the SWs (either preceding or following the current SW) which include that tuple.As an example, let us consider the fragment of the database table Contact, as depicted by Table 2, where the attribute VT refers to the valid time of the tuple at the day granularity. If we fix the length of the SW to 5, i.e. every sliding window includes a group (or chain) of five days, the first SW will formally include time points {2009-04-11, 2009-04-12, 2009-04-13, 2009-04-14, 2009-04-15}: since relation r in Table 2 has tuples for VT=2009-04-11 or VT=2009-04-14 or VT=2009-04-15, the first SW includes 3 tuples having VT values 2009-04-11, 2009-04-14, 2009-04-15. Thus, the following 6 SWs consider all the possible VT value groups {2009-04-11, 2009-04-14, 2009-04-15}, {2009-04-14, 2009-04-15}, {2009-04-15}, {2009-04-26, 2009-04-27, 2009-04-28}, {2009-04-27, 2009-04-28}, and {2009-04-28}.ATFD[Contact,{i…i+4}]Patient→0.4Durationholds. Indeed, tuples for which the dependency does not hold, i.e. Tuple# 3 and Tuple# 6 in the specific example, are those which need to be modified according to the measurement g4 of Definition 4.5. More precisely, the value of attribute Duration for Tuple# 3 has to be changed to 20; the value of attribute Duration for Tuple# 6 has to be changed to 40. Should we modify these two tuples, we shall obtain a plain TFD, holding on all the six SWs. The tuples we modified are less then the 40% of the entire fragment (Table 2), thus proving that the ATFD holds even with a threshold ε of 2/6 (i.e. 1/3), which is smaller than 0.4.If we again consider the fragment of Table 2 and group tuples according to the same six SWs as we did before, we can now check the ATFD[Contact,{i…i+4}]Patient→0.1Area, accepting an error of 10%. The TFD fails on one tuple (Tuple# 5, i.e. 1/6 of the entire relation), which needs to be modified according to measurement g4 of Definition 4.5: thus, the ATFD does not hold with a ε of 0.1.Analogous to Definition 4.4, we can introduce the concept of minimality also for ATFD with SW grouping.Definition 4.6Minimal ATFD with SW groupingGiven an ATFD over[r,{i…i+k−1}], we defineX→εYto be minimal for r iffr⊨[r,{i…i+k−1}]X→εYand ∀X′⊂Xwe have thatr⊭[r,{i…i+k−1}]X′→εY.When using a SW grouping, and only when using this grouping, measurements g3 and g4 (and the related G3 and G4) may differ: on the other side, when using granularity grouping, measurements g3 and g4 do not differ. In fact, in the SW grouping, according to the measurement g3 we delete one or more tuples: this may modify the temporal relationships among the tuples, the number of tuples inside every SW, and – occasionally – the total number of SWs to consider. Instead, according to the measurement g4, we modify one or more tuples, leaving unchanged the temporal relationships among tuples, the number of tuples inside every SW, and the total number of SWs to consider.As an example, let us consider the fragment of Contact in Table 3, assuming a length 2 for the SW (i.e.we consideri…i+1). We shall then have the following SWs, {2010-06-11, 2010-06-12}, {2010-06-12, 2010-06-13}, {2010-06-13, 2010-06-14}, {2010-06-14, 2010-06-15}, and {2010-06-15}, for a grand total of 5 SWs. We are interested in the ATFD[Contact,{i…i+1}]Patient→0.25Professional.For the measurement G3, the FDPatient→Professionalholds in the SWs {2010-06-11, 2010-06-12}, {2010-06-13, 2010-06-14}, {2010-06-14, 2010-06-15}, {2010-06-15}: the FD does not hold in the SW {2010-06-12, 2010-06-13}. Consequently, if we delete from Table 3Tuple# 3, the remaining SWs are {2010-06-11, 2010-06-12}, {2010-06-12}, {2010-06-14, 2010-06-15}, {2010-06-15}. The FD holds on all the SWs remaining after the deletion of Tuple# 3. Thus, the measurement G3 is 1, as we only deleted one tuple (Tuple# 3), obtaining the ATFD with an error of1/5(i.e. 20.00%), which is smaller than the maximum acceptable error of 0.25. The ATFD holds, and the measurement G3 returnsG3([Contact,{i…i+1}]Patient→Op,Contact)=1.For the measurement G4, if we update in Table 3Tuple# 1 and Tuple# 2, setting the value of the attribute Professional to “Romina”, the ATFD will hold in the SWs {2010-06-11, 2010-06-12}, {2010-06-12, 2010-06-13}, {2010-06-13, 2010-06-14}, {2010-06-14, 2010-06-15], and {2010-06-15}, that is in 5 out of the 5 SWs. Thus, the measurement G4 is 2, as we modified two tuples (Tuple# 1 and Tuple# 2) to obtain the ATFD. Changing one tuple only, whatever the tuple is, does not suffice to obtain the required TFD:G4([Contact,{i…i+1}]Patient→Op,Contact)=2We obtain the ATFD with an error of2/5(i.e. 40%), which is greater than the maximum acceptable error of 0.25: as a consequence, according to G4 the ATFD does not hold with the required threshold of 25%.We now consider how to mine minimal ATFDs both with granularity and sliding window groupings. While mining Gran grouping ATFDs can be mapped to mine corresponding suitable AFDs, mining SW grouping ATFDs requires ad hoc algorithms. The approach we propose here differs from the one in [14], where we performed both Gran and SW grouping ATFDs through an AFD analysis by the TANE[10] tool.Let us now consider how we can reduce the evaluation of minimal Granularity-based ATFDs to the evaluation of corresponding minimal AFDs: such approach allows us to use well-known algorithms for AFD and to characterize the complexity of mining minimal ATFD. In general, we proceed in three different steps: in the first one (PreAFD), the given relation is pre-processed to represent, by a suitable attribute, the granule/window each tuple belongs to. Next, we have an (atemporal) relation to consider for the usual AFD extraction (AFD phase). Finally, a suitable post-processing phase (PostAFD) is needed to properly identify and represent the mined ATFDs.As the temporal grouping of a granularity Gran is a bijective function, we may conclude that the set E of tuples not satisfying the considered granularity-based ATFD, may be partitioned in subsetsEG(i), whereEG(i)is the set of tuples of E having their valid time contained in the granule G(i). Thus, it holds|E|=G4([r,Gran]X→Y,r).Given an instance r with schemaR=U∪{VT}, a granularity Gran and a threshold ε, the preprocessing phase (see Algorithm 1 PreAFD-G(r,G)) builds up the relation preAFD with schemaR′=U∪{codGran}: the attribute VT is replaced by the attribute codGran. The tuples of preAFD have the same value for codGran if and only if they belong to the same temporal granule of the given granularity Gran. More formally, for each tuple t of r, we apply the functionf(Gran,t):r↦preAFD, wheref(t)[U]=t[U]andf(t)[codGran]=i, witht[VT]∈Gran(i). Algorithm 1 shows the pseudo-code of the preprocessing phase, having complexityO(|r|).Algorithm 1PreAFD-G(r,G).Input: r,GOutput: preAFD1preAFD←∅; /⁎ preAFDhas schemaU∪codGran⁎/2foralltheti∈rdo345|t′[U]←ti[U];t′[codGran]←f(G,ti);preAFD←preAFD∪t′6end forall7returnpreAFDOn the obtained relation preAFD, the next phase derives the minimal AFDs, according to the threshold ε. Let outAFD be the set of the found AFDs. As discussed in [10], the complexity of the corresponding algorithm isO(2|R|), since the number of attributes of preAFD is that of R.The error tuples of the ATFD[r,Gran]X→Yare, through the correspondence function f, the same as those of the AFDcodGran,X→Yon preAFD. As preAFD and r have the same cardinality (f is total and injective), we haveg4([r,Gran]X→Y,r)=g4(codGran,X→Y,preAFD). Indeed, for each Gran(i) for the setri={t[U]|t∈r∧t[VT]∈Gran(i)}we can computeG4(X→Y,ri)and, by definition,∑iG4(X→Y,ri)=G4([r,Gran]X→Y,r). According to the definition of f(t), we have that the setri′={t′[U]|t′∈preAFD∧t′[codGran]=i}=ri; thusG4(X→Y,ri′)=G4(X→Y,ri)and it holdsG4(codGran,X→Y,preAFD)=∑iG4(X→Y,ri′)=∑iG4(X→Y,ri)=G4([r,Gran]X→Y,r).As|r|=|preAFD|, we may conclude thatg4([r,G]X→Y,r)=g4(codGran,X→Y,preAFD).The last phase (post-processing) maps the derived AFDs into the minimal ATFDs holding in r. In Algorithm 2PostAFD-G maps the AFDs of the formcodGran,X→εYinto the ATFDs of the form[r,Gran]X→εY. The complexity of the algorithm isO(|outAFD|): as the number (|outAFD|) is of orderO(2|R|), Algorithm 2 has complexityO(2|R|).Algorithm 2PostAFD-G(outAFD).Input: outAFDOutput: postAFD1postAFD←∅;/⁎ postAFDis a set ofATFDs of the formcodGran,X→εY⁎/2forall thecodGran,X→εY∈outAFDdo3|postAFD=postAFD∪([r,Gran]X→εY)4end forall5returnpostAFDIt is straightforward to observe that these three phases allow us to derive all the minimal ATFDs with grouping based on granularity Gran, and holding in r with threshold ε.Finally, a strategy (see Algorithm 3) is needed to evaluate how to mine a relation r according to a set of temporal granularities. Let us focus on(GranSet,≺), a set of continuous and total granularities with a total order according to relation FinerThan[22]. Informally, relationFinerThan(Gran1,Gran2)holds if each granule of granularity Gran1 is contained in a granule of Gran2. IfFinerThan(Gran1,Gran2), then1.r⊨[r,Gran2]X→εY⇒r⊨[r,Gran1]X→εY.(Pruning condition)r⊭[r,Gran1]X→εY⇒r⊭[r,Gran2]X→εY.In Algorithm 3StrategyG(r,GranSet) starts to mine, according to order ≺, the ATFDs from the minimal (finest) granularity to the coarsest one in(GranSet,≺). In mining the ATFDs with coarser granularity, we shall find those ATFDs with antecedentX′⊇X, where X is the antecedent of a ATFD at a finer granularity. If there is no ATFD at granularity Grani, for the pruning condition no ATFD will be mined at any granularity Gran(j) such thatGran(i)≺Gran(j). In Algorithm 3StrategyG has complexityO(2|R|), since the three phases PreAFD-AFD-PostAFD are executed at most|GranSet|times.Algorithm 3StrategyG(r,GranSet,ε).Input:r,GranSet,εOutput:ATFDs1currGran←inf{Grani∈GranSet};2ATFDs←∅;3whilecurrGran≠∅do456789101112|ATFD←{[r,currGran]X→εYfoundinrexecutingPreAFD-G,AFD,andPostAFD-G};ifATFD=∅then|returnATFDselse|ATFDs←ATFDs∪ATFD;GranSet←GranSet-currGran;/⁎ATFDsis the set of all minimalATFDs⁎/;/⁎[r,Grani]X→εYvalid inrforgranularities∈GranSetcurrGran←inf{Grani∈GranSet}endif13end while14returnATFDsFor SW grouping, in [14] we adopted an approach in 4 phases: PreAFD-G, AFD, PostAFD-G, and StrategyG. We introduce here a novel approach for SW-based analysis, which does not need any PreAFD and PostAFD step. In the following we will focus on G3 and g3 error measures.We aim at verifying whether the ATFD[R,t-Group]X→εYholds over an instance r of a temporal relational schemaR(U,VT). First, we define the relationValueCount(r,v)={(y,vt,c)|c=|{t|t∈r∧t[VT]=vt∧t[X]=v∧t[Y]=y}|}, which, given the instance r of the schema R and a tuple v of values for attributes X, returns triples(y,vt,c). A triple(y,vt,c)belongs toValueCount(r,v)iff there exists exactlyc>0distinct tuplest∈rwheret[X]=v∧t[Y]=y∧t[VT]=vt.Given r as above, a setr′⊆ris minimal for[R,SlidingWindow(k)]X→Yiffr–r′fulfills[R,SlidingWindow(k)]X→Y, and for everyr″⊂r′we have thatr–r″does not satisfy[R,SlidingWindow(k)]X→Y.In order to identify the ATFD[R,SlidingWindow(k)]X→εYwe can restrict our analysis to the minimal setsr′: it can be easily observed that[R,SlidingWindow(k)]X→εYholds over a given instance r iff there exists a minimal setr′for[R,SlidingWindow(k)]X→εYwith|r′|≤ϵ·|r|. By restricting our analysis to minimal sets, only, we have to find one minimal set with minimum cardinality. This allows us to check immediately if an ATFD[R,SlidingWindow(k)]X→εYholds over a given instance of R. Let us consider now the following result over minimal sets:Lemma 5.1Given an instance r of a temporal relational schemaR(U,VT), for everyk∈N, for every minimal setr′⊆rfor[R,SlidingWindow(k)]X→Y, and for every value v, it holdsValueCount(r′,v)⊆ValueCount(r,v)VerifySW([R,SlidingWindow(k)]X→εY, r).Input:[R,SlidingWindow(k)]X→εY,rOutput: TRUE or FALSE1σ←0;2foreachv∈{x|∃t∈r(t[X]=x)}do3456|σ←σ+MinDelete(ValueCount(r,v),k);ifσ>ϵ·|r|then|returnFALSEendif7end foreach8return TRUE;/⁎ verify if[R,SlidingWindow(k)]X→εYholds overr ⁎/Lemma 5.1 provides us with the following property: the tuples of r which have the same attribute values for (X,VT) are either totally deleted or totally kept in a minimal setr′⊆rfor[R,SlidingWindow(k)]X→Y.By means of this property, a procedure that verifies[R,SlidingWindow(k)]X→εYover r is described in Algorithm 4. By definition, we have that r does not satisfy[R,SlidingWindow(k)]X→Yiff there exists at least one pair of tuplest,t′witht[X]=t′[X]∧t[Y]≠t′[Y]∧t′[VT]−t[VT]≤k.Thus, we can partition r intor=rv1,…,rvm, wherervi={t|t∈r∧t[X]=vi}(i.e.tuples having the tuple viof values for attributes X).For each i,1≤i≤m, we compute the minimal setrvi′for[R,SlidingWindow(k)]X→εYrestricted to the setrvi. It follows immediately that⋃1≤i≤mrvi′represents a minimal setr′for[R,SlidingWindow(k)]X→εYover the whole relation r.In the procedure, every setrviof the partition is represented by itsValueCount(r,vi)relation, which contains the minimum amount of information needed to determine the cardinality ofrvi′.The whole collection of relationsValueCount(r,vi), for1≤i≤m, can be computed inO(|r|·log(|r|)), by means of a simple counting aggregation function over r lexicographically ordered and grouped by attributesX,Y,VT.As shown in Algorithm 4, the auxiliary function MinDelete is applied to each relationValueCount(r,vi)and it returns the minimum amount of tuples that have to be removed fromrvito satisfy[R,SlidingWindow(k)]X→εYonrvi. Since|ValueCount(r,vi)|≤|rvi|, the overall worst-case complexity is reached when the partition is formed by one set only, namely r, i.e. all the tuples in r assume the same (tuple of) values for attributes X.WithO(f(n))being the worst case complexity of MinDelete, where n is the size of the input relation, the overall worst case complexity isO(|r|·log(|r|)+f(|r|))(as we shall see, k does not affect the complexity of MinDelete).We now have to identify an efficient algorithm to compute the function MinDelete, as described in Appendix A. First, Appendix A.1 describes a quadratic time algorithm version of MinDelete, that allows us to introduce the main ideas behind our solution, such as the representation of temporal relations by Directed Acyclic Graphs (DAGs): this naive algorithm shows that[R,SlidingWindow(k)]X→εYcan be computed in polynomial time for every instance r of R. Next, Appendix A.2 improves the asymptotic complexity of MinDelete, by providing anO(|r|·log|r|)version of its.We developed two running prototypes for off-line analysis: G-ATFDminer (Granularity Approximate Temporal Functional Dependency Miner) and SW-ATFDminer (Sliding Windows Approximate Temporal Functional Dependency Miner).G-ATFDminer is a Java based system aimed at extracting rules of approximate temporal functional dependency for granularity (Gran) grouping. We test G-ATFDminer on the psychiatric data set of Section 3.1, and on the phamarcovigilance data set of Section 3.2.We start by considering the scalability of the implemented software. The parameters of the algorithm are set as follows:ϵ=0.1; time granularity set to MONTH.The first analysis refers to tests with a fixed number of rows, but a varying number of attributes. G-ATFDminer was tested on a machine equipped with a 6 core AMD OpteronTM4284, and 8GB of RAM. We use the Ubuntu 12.04 64-bit (kernel 3.2.0-23-generic) operating system, Java version 1.7.0, and Postgresql 9.1 as DBMS.Table 4depicts the processing time in seconds over the psychiatric data set, consisting of 10,000 rows. Likewise, Table 5depicts the processing time in seconds, according to the number of attributes (the number of rows is kept fixed to 10,000) over the pharmacovigilance data set. Fig. 1depicts the processing time compared to the theoretical overall complexity of the algorithm.The second analysis refers to tests with a fixed number of attributes (5 in the example) over the psychiatric data set and over the pharmacovigilance data set, but with a varying number of rows. Table 6depicts the processing time in seconds for the psychiatric data set (5 attributes). Likewise, Table 7depicts the processing time in seconds for the pharmacovigilance data set (5 attributes): due to the smaller number of rows in this data set, experiments were performed up to212·100rows. Fig. 2compares the processing times with the theoretical overall complexity of the algorithm. The processing time is directly proportional (linearly) to the number of rows in input. The estimated complexity isn·log(n), but by using the pruning strategies, we tear down the processing time close to linear time.By running the G-ATFDminer, we identify some meaningful dependencies on the psychiatric data set we discuss here:•[MONTH]GAFScale→Area: this dependency points out that the state of the patient, expressed by means of the GAF scale, is directly connected to the geographical area the patient lives in. An urban environment, due to its chaotic nature, could negatively influence the state of the patient. Since the dependency refers to the month granularity, one may infer seasonal changes of state in patients, too;[MONTH]Patient→GAFScale: this dependency points out that patients are relatively stable: their state, expressed by the GAF Scale, does not change within a month;[MONTH]Patient→Operator1: this dependency links the patient to a particular operator (Operator1 is the first person that talks to the patient during a call or a visit). Patients are more used to talk to the same operator, instead of talking to different ones (strangers);[MONTH]Area→NumberofPsychiatrists: this dependency links the geographical area to the number of psychiatrists deployed during one month: shifts or teams of psychiatrists last for at least one month.The most relevant dependency we obtained by running the G-ATFDminer on the pharmacovigilance data set is[MONTH](Severity,Duration,Gender,Drug)→Dosage. It points out that drug dosage during a therapy, characterized by drug name, patient gender, duration and the severity (expressed a boolean flag), is likely to be adjusted due to reports about occurrences of adverse reaction. This means that the occurrences of adverse reaction may be linked to the dosage of a drug during therapies.SW-ATFDminer (Sliding Window Approximate Temporal Functional Dependencies Miner) is a Java based software extracting rules of approximate temporal functional dependencies for sliding window (SW) grouping.We start by considering the scalability of the implemented software. The parameters of the algorithm are set as follows:ϵ=0.1; minimum window size is 1day; maximum window size is 100years. This means that the mining algorithm returns the maximum window size for ATFDs to hold within this specified interval.We now describe some of the mined functional dependencies over the two data sets of Section 3.The first analysis refers to tests with a fixed number of rows, but a different number of attributes. As in Section 6.1, we tested SW-ATFDminer on a machine equipped with a 6 core AMD OpteronTM4284, and 8GB of RAM. We use the Ubuntu 12.04 64-bit (kernel 3.2.0-23-generic) operating system, Java version 1.7.0, and Postgresql 9.1 as DBMS.Table 8depicts the processing time in seconds over the psychiatric data set, consisting of 10,000 rows. Likewise, Table 9depicts the processing time in seconds, according to the number of attributes (the number of rows is kept fixed to 10,000) over the pharmacovigilance data set: due to the smaller number of attributes in this data set, experiments were performed up to 16 attributes. Fig. 3depicts the processing time compared to the theoretical overall complexity of the algorithm.One may argue that the experimental results (the blue line in Fig. 3) show that by our approach, due to suitable pruning strategies, it is possible to mine using 25 attributes before having a decay in the performances. Theoretically, this performance decay should occur as the number of attributes exceeds 10, as depicted by the red line of Fig. 3.The second analysis refers to tests with a fixed number of attributes (5 in the example) over the psychiatric data set and over the pharmacovigilance data set, but with a varying number of rows. Table 10depicts the processing time in seconds for the psychiatric data set (5 attributes). Likewise, Table 11depicts the processing time in seconds for the pharmacovigilance data set (5 attributes): as before, due to the smaller number of rows in this data set, experiments were performed up to212·100rows. Fig. 4compares the processing times with the theoretical overall complexity of the algorithm. The processing time is directly proportional (linearly) to the number of rows in input. The estimated complexity isn·log(n), but by using the pruning strategies, we tear down the processing time close to linear time.The psychiatric data set consists of 26 attributes. Theoretically, a mining algorithm would need to validate 872,415,232 (i.e.26·225) functional dependencies: however, after running the pruning operation, only 125,919 have been tested by SW-ATFDminer to obtain 3042 valid rules. By testing only the0.014%(125,919/872,415,232=0.014%) of all the possible ATFDs (that is 1 functional dependency every 6945), SW-ATFDminer allows one to treat an otherwise intractable problem.By running the SW-ATFDminer, we identify some meaningful dependencies we discuss here:•[133days]HealthStructure→ContactType: Due to the large window of 133 days, this dependency points out that healthcare structures are specialized in providing particular contact types (that is either scheduled, urgent, or not classified). For example, urgent contacts are less likely to be registered in community-based structures vs. hospital-based structures.[112days]Patient→GAFScale: Even in this case the window size is very large (112 days). This dependency states that the patient׳s GAF score (Global Assessment of Functioning is a numeric scale used by mental health professionals to rate subjectively the psychopathology severity, the social and occupational functioning of patients) basically is assessed every 3months, when changes in the patient׳s mental condition are observed.[13days]FirstContact→ContactType: This dependency states that, in a window of 13 days, whenever a patient contacts the service for the first time (FirstContact=TRUE), the type of that contact is the same for all the patients. This occurs also when the contact is not the first one (FirstContact=FALSE). This could be of interest: in fact, both the antecedent and the consequent of the dependency may assume 2 or 3 values, so one could guess, for instance, that the first contact of a patient is usually urgent, and the other contacts are routine/scheduled ones. This could be considered as an indicator of a good quality of care, as after an urgent contact (usually in an emergency room), the next contact is scheduled with a short waiting list.[12days](GAFScale,Patient)→Duration: Over a window of 12days, this dependency links the patient and the current condition (measured by the GAF score) to the duration of the contact. It means that, if a patient is scored with a higher functioning (high GAF score), the duration of the outpatient contact is shorter, since the need for psychological, psycho-pharmacological and social support is reduced. If a patient has a lower GAF score, the duration of the outpatient contact is longer.[5days]Patient→Referral: This dependency states that, in a window of 5days, the referral of the service depends on the patient (typically, the referral is a family member, a neighbor, the police, or the physician). The small window size indicates that the referral of a contact is strictly linked to the condition of the patient at that particular stage of the disease.[5days](Duration,GAFScale)→Professional: This dependency links the duration of the contact and the GAF score of the patient to the professional involved in the contact. The duration of the contact is longer if the patient is talking to his/her usual professional, while if talking to an unusual professional, the contact is shorter.We selected 19 attributes from the pharmacovigilance (PhV) data set, and processed them by the SW-ATFDminer. Theoretically, a mining algorithm would need to validate 4,980,736 functional dependencies (i.e.19·218): however, after running the pruning operation, SW-ATFDminer tested only 49,904 of them.By running the SW-ATFDminer, we identify some meaningful dependencies we discuss here:•[30days](Drug,AdverseReaction)→Outcome: Due to the large size of the window, this dependency points out that – given an adverse drug reaction – the outcome does not change. This is of interest for the analyst (i.e.asserting that the suspected drug is indeed the one that caused the reaction). In this case, it is not completely understood by pharmacologists why this dependency does not hold even for bigger window sizes.[23days](Drug,AdverseReaction)→HealthcareRegion: This dependency links a drug and its adverse reaction to the geographical region where that event has been detected. This dependency is explained as follows. Many reports are related to specific active pharmacovigilance projects. For example, many reports from the Lombardy region come from a project focusing on the monitoring of emergency departments: many drug-reaction couples (e.g., bleeding and aspirin) occur several times in the considered data sets due to this project. Even in this case, the length of the sliding window needs further investigations. Moreover, it is of interest to analyze this kind of dependency only for those reports which are not related to specific pharmacovigilance projects.[11days](Drug,TreatmentDuration)→Outcome: This dependency states that the outcome of any adverse reaction induced by a drug can be linked to the drug itself and to the duration of the treatment. This dependency is similar to the first one. In this case, it is interesting to observe that, given a drug, both the induced adverse reaction and the duration of the treatment induce a dependency with respect to the outcome. This could confirm that the same drug may produce different outcomes, according to the time span of the treatment.[6days]AdverseReaction→Severity: This dependency links the reaction to its severity. It is acknowledged by pharmacologists that a reaction is usually severe/not severe regardless of the associated drug. This feature holds even in this case, where severity is associated with the overall report, possibly containing several reactions for the same drug.[5days](ATC,AdverseReaction)→DrugRole: The ATC (Anatomical Therapeutic Chemical) classification system is widely used to classify drugs. ATC classifies drugs into different groups, according to the organ or system on which they act, and/or their therapeutic and chemical characteristics. This dependency links the higher level of this classification (e.g. cardiovascular system, dermatology, central nervous system), and the observed adverse reaction to the drug role (e.g. suspected of being the cause of the reaction, or just contemporary). This dependency may be explained by the “notoriety” of a reaction with respect to a group of drugs. For example, a hypertensive drug is expected to possibly induce hypotension, an anti-arrhythmic one may cause bradycardia. The short width of the sliding window could be explained by the irregular flow of reports and by the fact that different types of reports come in different time periods. Even in this case, the found window size has to be studied and deeply considered by pharmacologists.

@&#CONCLUSIONS@&#
In this paper, we introduced and discussed approximate temporal functional dependencies, with their related algorithms and clinical data mining issues. More precisely, we discussed how to mine pure temporally grouping temporal functional dependencies. We considered both granularity-based and sliding window temporal groupings. We applied ATFD mining to two different clinical data sets, related to psychiatric patient management and to pharmacovigilance. ATFDs proved to be an interesting tool for mining clinical data and the derived dependencies have been discussed as for their clinical relevance.As a future work, we plan to extend mining techniques to other kinds of temporal functional dependencies, according to the framework proposed in [7]. Moreover, a tuning of these techniques for specific temporal clinical data will be considered. In particular ATFDs could be the result of specific tools within an integrated suite of (temporal) data mining tools for clinical data, comprising both temporal dependencies and temporal association rules.None declared.This appendix describes two implementations for the MinDelete function: Appendix A.1 describes a naive implementation, while Appendix A.2 describes a smarter implementation.Function MinDelete of Algorithm 5 receives as input a relationr¯with schemaR¯(Y,VT,C); this relation stores, for a given tuple of values for attributes X, the number C of tuples, which share the same value for the attribute Y at the same valid time VT in the original instance r.Algorithm 5MinDeleteNaive(r¯,k).Input:r¯,kOutput:DAG_Shortest_Path(V,E,W,S,f)1/ ⁎r¯is supposed to contain only tuples(y,vt,c)whereyis a value in the domain ofY, and bothvtandcare natural numbers ⁎ /2assign to y a value∈Dom(Y);3s←(y,mint∈rt[VT]−k−1,0);4e←(y,maxt∈rt[VT]+k+1,0);5V←r∪{s,e};6E←{(s,t)|t∈r}∪{(t,e)|t∈r}∪{(t,t′)|t,t′∈r∧t[VT]<t′[VT]∧(t′[VT]−t[VT]>k∨t[Y]=t′[Y])};7foreach(t,t′)∈Edo8|W(t,t′)←∑t″∈r∧t″≠t′∧t[VT]<t″[VT]≤t′[VT]t″[C]9end foreach10returnDAG_Shortest_Path(V,E,W,S,f)Given such relationr¯, the algorithm computes the minimum number of tuples t, witht[X]=x, to be deleted from r in order to have the TFD[R,SlidingWindow(k)]X→Yto hold over the remaining tuples of r that share the same tuple x of values fort[X]. That is, Algorithm 5 looks for a minimal setrx′⊆rxfor[R,SlidingWindow(k)]X→Y.The procedure builds a DAG with positive weights on the edges. The nodes of G represent tuples of the input relation, and have two auxiliary nodes s and e. The set E of edges and their respective weights W are defined as follows:•there is one edge from s to everyt∈r, and one edge from everyt∈rto e;one edge connects two tuplest,t′∈r, iff the two tuples with subsequent VTs (t[VT]<t′[VT]) do not create a conflict with respect to[R,SlidingWindow(k)]X→Y. This occurs when eithert[Y]=t′[Y]ort′[VT]−t[VT]>k;the weight of every edge(t,t′)is the number of tuples that must be deleted if all the tuples represented by t together with all the tuples represented byt′will be kept in the final solution and no other tuples are in between, with respect to their valid time. In particular, when considering tuples within the sliding window, we cannot have tuples betweent[VT]andt′[VT]with the same corresponding values for attributes X and different values for Y (i.e. violating the dependency).Every path from s to e in the DAG describes one possible “deletion-strategy”. Every edge indicates that the two tuples may coexist without violating the dependency. If an edgee=(t,t′)is chosen in the shortest path between s and e, it means that t andt′are kept in r, and thus all the tuples of the DAG in-between them are deleted. The number of such deleted tuples is represented by the weight of the edge e.As an example, let us consider in Fig. A1the edge between nodesti+1andti+6. Tuplesti+2,ti+3,…ti+5will be deleted. Every path from s to e guarantees that[R,SlidingWindow(k)]X→Yis satisfied by all the remaining tuples sharing the same tuple x of values for attributes X. Indeed, all the edges on a path guarantee that the two connected nodes represent tuples that can be in a relation satisfying the given temporal functional dependency. Moreover the sum of the weights on every path from s to e is exactly the number of the tuples to be deleted, if the corresponding strategy would be adopted. Finding the weighted shortest path from s to e in the DAG corresponds to identifying the minimum number of tuples to be deleted to make rxconsistent with[R,SlidingWindow(k)]X→Y, i.e. considering only those tuples with the given (tuple of) values for attributes X.The complexity of such a procedure isO(|r|2), and it is determined by the worst case complexity to compute the weights for the edges. Such a computation requires, in the worst case, a quadratic parse of the original relation r: this dominates the overall complexity for every single source shortest path procedure used to compute the output value. We shall see in the next section how such weights can be incrementally computed just in time, tearing down the complexity of the whole procedure by exploiting the particular structure of the generated DAG.The procedure MinDelete can be improved with respect to the asymptotic complexity analysis, obtaining the procedure described in Algorithm 6. The soundness and completeness of such a procedure is given by Lemma A.1, which can be proved by contradiction.Lemma A.1Given a shortest pathP=s,t1,…,tm,ein theDAGbuiltup according to Algorithm5, for every pair of consecutive nodesti,ti+1in P there does not exist a pathP′in theDAGwith|P′|>1andP′=ti,t1′,…,tm′′,ti+1.This result strongly depends on how the weights are computed in the DAG, and informally it enables us to disregard all the edges that can lead to a longer path when computing the shortest path through the function SHP. SHP computes the cost of the shortest path between two given nodes. For example, in the DAG of Fig. A1, the edge(ti,ti+7)can be deleted without affecting any value for every shortest path. Indeed, looking at the edge weights we observe thatW(ti,ti+7)=∑j=i+1i+6tj[C]>W(ti,ti+4)+W(ti+4,ti+7)=∑j=i+1i+3tj[C]+∑j=i+5i+6tj[C]Thus, every path featuring(ti,ti+7)is not the shortest one, since such an edge may be replaced by the edge pairs(ti,ti+4),(ti+4,ti+7), to obtain a path with a lower weight. Corollary 1 follows from this result.Corollary 1Given a shortest pathP=s,t1,…tmin theDAGfrom s to any nodetm∈V, then eithertm[VT]−tm−1[VT]>k, or for everyt′withtm−1[VT]<t′[VT]<tm[VT], we havet′[Y]≠tm[Y].This means that every nodetm∈Vhas either•a predecessor in its shortest path outside the sliding window or;an immediate predecessor among the tuples with the same value for attribute Y in the sliding window.We call such a tuple, if it exists, the minimal window predecessor of tm. Given a node t, we say thatt′, witht[VT]−t′[VT]>k, is its minimal-external predecessor if and only if for everyt″witht[VT]−t″[VT]>k, we haveSHP(s,t″)+W(t″,t)≥SHP(s,t′)+W(t′,t).Corollary 2 completes the needed properties for our procedure. It can be proved by contradiction by looking at the properties of the weights in the DAG.Corollary 2For every pair of tuplest,t′witht[VT]≤t′[VT], lett¯andt¯′be the minimal external predecessors of t andt′respectively: then, it holdst¯[VT]≤t¯′[VT].Suppose that we are looking for a given node t. Properties highlighted by the two corollaries 1 and 2 restrict the value ofSHP(s,t)tomin((SHP(s,t′)+W(t′,t)),(SHP(s,t″)+W(t″,t)). Thus,t′is the minimal-external predecessor of t, andt″is the minimal-window predecessor of t (if any).Algorithm 6MinDelete(r¯,k).Input:r¯,kOutput: Min1optimized version for MinDelete;/⁎r¯contains only tuples(y,vt,c,lc,pw,pwc,fw,shp)wherey, vtandcare defined as inAlgorithm5. Attributeslc, pw, pwc, fwandshpare natural numbers. ⁎/2fori=1to|r¯|do3456789|ifi=1∨ti−1[VT]<ti[VT]then|Count←0;j←i;whiletj[VT]=ti[VT]∧j≤|r|do|Count=Count+tj[C]endwhileendifti[LC]←Count10end for11;/⁎ Tis assumed to be a balanced binary search tree. Each node ofTis ordered on the fieldkeywhich assumes values in the domain ofyand contains attributesidxandbonuswhich are natural numbers. ⁎/12T←∅;Count←0;13fori=|r¯|downto1 do1415161718192021222324|ti[PW]←NIL;n←T.search(ti[Y]);ifn≠NILthen|iftn[idx][VT]−ti[VT]≤kthen|tn[idx][PW]←i;tn[idx][PWC]←Count−n[bonus]endifT.delete(ti[Y])endifn←NewNode();n[key]←ti[Y];n[idx]←i;n[bonus]←Count+ti[C];T.insert(n);ifi>1∨ti[VT]>ti−1[VT]then|Count←Count+ti[LC]endif25endfor26foreacht∈r¯do27|t[FW]=mintj∈r∧t[VT]≥tj[VT]∧t[VT]−tj[VT]≤kj28foreach29Ext←Win←0;30fori=1 to|r¯|do313233343536363738394041424344454647|OutValue←Ext+ti[LC]−ti[C];ifti[PW]≠NILthen|InValue←tt[PW][SHP]+ti[PWC];ti[SHP]←min(InValue,OutValue)else|ti[SHP]←OutValueendififi<|r|∧ti[VT]<ti+1[VT]then|Win←Win+ti[LC];Ext←Ext+ti[LC];ifti+1[FW]>ti[FW]then|forj=ti[FW]toti+1[FW]−1do|Ext←min(Ext,Win+tj[SHP]−tj[LC]);iftj[VT]<tj+1[VT]then|Win←Win−tj[LC]endifendforendifendif48end for49Min←t|r|[SHP];Count←0;50fori=|r¯|−1down to 1 do51525354|ifti+1[VT]>ti[VT]then|Count←Count+ti+1[LC]endifMin←min(Min,ti[SHP]+Count);55endfor56returnMinThe procedure described in Algorithm 6 makes use of these properties to tear down the complexity of procedure MinDelete toO(n·log(n)). The procedure requires that the tuples are ordered lexicographically onVT,Y(given an arbitrary order on Y) in the input relation r. In the following, we assume that retrieving a tuple tjgiven its index j has a computational costlog(|r¯|), by supposing that there is some sort of an indexing structure (e.g. a B-tree) built up on the indexes of the tuples, and that the computational cost of computing such a structure isO(|r¯|·log|r¯|).Moreover, the procedure assumes that in the input relation there are five additional auxiliary not-initialized attributes LC, PW, PWC, FW andSHP. These integer attributes have the following meaning:•LC means “level count”, and it represents the sum for the C attribute for all the tuples that share the same VT with the current one (including t itself). Formallyt[LC]=∑t′∈r,t[VT]=t′[VT]t[C]Such an attribute is introduced in order to improve the readability of the code: the attribute is computed at the very beginning of the procedure and for everyt∈r¯with a simple single scan ofr¯(lines from 2 to 10 in Algorithm 6).PW stands for “predecessor in window” and it is the index for whichtt[PW]is the minimal-window predecessor of t inr¯.Formally (recall that tuples in r are lexicographically ordered onVT,Y):t[PW]={maxi(ti∈r¯∧t[Y]=ti[Y]∧t[VT]−ti[VT]≤k)if∃t∈r¯(t[Y]=ti[Y]∧t[VT]−ti[VT]≤k)NILotherwisePWC represents the weight of the edge between a node t and its minimal window predecessor (if any):t[PWC]={W(tt[PW],t)ift[PW]≠NILNILotherwiseBoth PW and PWC are computed in the second for-loop of the algorithm (lines from 13 to 25 of Algorithm 6), but their computation is much more complex with respect to the one for LC values.In fact, a naive way to compute them may lead to a quadratic complexity, making all our efforts unfruitful. On the contrary, the values PW and PWC can be computed for all the tuplest∈r¯inO(|r¯|·log|r¯|)by using a balanced tree T, say a B-tree, as an auxiliary structure (any other data structure where the computational cost to search/insert/delete is logarithmic will perform the same way).A node n of such a tree consists of a key valuen[key], which represents a value in the domain of Y, given an arbitrary order of the values for Y.n[idx]represents the index of the last tuple with attribute Y equal to the key encountered in the current window.n[bonus]is a value to easily compute the value of PWC. During the procedure, for every noden∈Twe guarantee that for everyn′∈T, withn≠n′,n[key]≠n′[key]. This second for-loop that computes the values for attributes PW and PWC for all the tuplest∈r, works backward from the tuple with the maximum value for the attributesVT,Y. At every step, PW is assigned to be NIL for the current tuple ti, and the keyti[Y]is searched into T. If there exists a noden∈Twithn[key]=ti[Y]andtn[idx][VT]−ti[VT]≤k, then tiis the minimal-window predecessor oftn[idx], andtn[idx][PW]=i.The valuetn[idx][PWC]is computed as follows: at every step Count is increased by the valueti[LC]of the current tuple if it represents the first tuple of all the tuples with the same VT. When we insert a node n, we store inton[bonus]the current value of Count, which is the sum of all the C attributes for the tuples already encountered. The weighttn[idx][PWC]=W(ti,tn[idx])is simply computed asCount−n[bonus].At the end of the iteration, n is removed from the tree and a new node for the current tuple is inserted into T. For every iteration we have a constant number of retrieve/search/delete/insert operations, each one costingO(log|r¯|). The loop completes afterO(|r¯|·log|r¯|)operations.FW stands for “first in window”, and for a tuple t it represents the minimum index j such that a tuple tjexists for which0≤t[VT]−tj[VT]≤k.The third for-loop of the algorithm (lines from 26 to 28 of Algorithm 6) computes j for every tuplet∈r¯. Algorithm 6 performs|r¯|Min operations on the indexes, by using the valuet[VT]for the current tuple t. We recall that the index i of every tuple is given according to the lexicographical order onVT,Y. Then, for everyi≤jwe haveti[VT]≤tj[VT]. The complexity of the third loop isO(|r¯|·log|r|).The fourth for-loop of the algorithm (from line 30 to 48 of Algorithm 6) for every tuplet∈r¯computesSHP. At the end of the fourth loop, we require thatt[SHP]=SHP(s,t)for everyt∈r¯.We use two additional variables, namely Ext and Win, belonging to the set of natural numbers. Ext represents theSHPvalue for the minimal-external predecessor for the tuple t. Win represents the sum of all the attributes C for all the tuplest′of the current tuple t witht[VT]−t′[VT]≤k. For every tuple, the value of the attributeSHPis the minimum between the minimal-external predecessor and theSHPof the minimal-windows predecessor (if any) plus their respective weights. At the end of every iteration, we update – if needed – the value Ext (lines from 37 to 47). Then we collect all the tuples that are in the current window, and that will not be included into the next one. Such a set of tuples is non-empty iffti+1[FW]>ti[FW]where tiis the current tuple.According to the property expressed by Corollary 2, the set containing the candidates for minimal-external predecessor is restricted to the current tuple, and the tjones, withj=ti[FW],…,ti+1[FW]−1. Values fortj[SHP]=SHP(sj)are already defined, and the value forW(tj,ti+1)is computed by the most internal for-loop (lines from 40 to 45) by means of Win. A graphical representation of this for-loop is depicted in Fig. A2.HavingSHP(s,t)for everyt∈r¯, we still have to determine the cost of the shortest path of the entire graph, i.e.SHP(s,f). This is done by the fifth and last for-loop (lines from 50 to 55 of Algorithm 6). Basically, this loop moves backward from the tuplet∈r¯with maximum value for the attributes VT and Y, computing the distance between the current tuple and f: at the end, the minimum value is returned. The complexity of the fifth loop isO(|r¯|)and the overall complexity of the procedure MinDelete shown in Algorithm 6 isO(|r¯|·log|r¯|).In conclusion, the complexity of procedure VerifySW isO(|r¯|·log|r¯|): this complexity does not depend on the size of the sliding window k, which is provided as input. However, the sliding window size may assume any positive value: we are interested in finding all the independent ATFDs[R,SlidingWindow(k)]X→εYwith the maximum sliding window size, where only ϵ and r are provided by the user. Indeed, k is the maximum value, for which the approximate temporal dependency[R,SlidingWindow(k)]X→εYholds over r.At the beginning of this section we observed that, in the worst case, the number of couples (X,Y) to be tested is exponential [23]. The size k of the sliding window is provided as a parameter, which does not affect the complexity of the procedure. One may ask if testing all the possible sliding windows in the interval[0,maxt∈rt[VT]]is reasonable: in fact, testing all the possible sliding windows would increase the overall complexity, depending in this case on the valuemaxt∈rt[VT]. However, such a test is not necessary in this case.Lemma A.2Downward closure propertyFor every temporal relation R, for every couple of attributesX,Y, for every instance r of R, for every0≤ϵ≤1, and for every k, if[R,SlidingWindow(k)]X→εYholds over r, then for everyk′≤kwe have that[R,SlidingWindow(k)]X→εYholds over r.Lemma A.2 asserts that finding the maximum k, if it exists, for which[R,SlidingWindow(k)]X→εYholds over r, may suffice. Then, by having X, Y and ϵ fixed, we perform a dichotomic search by the procedure VerifySW, starting fromk=maxt∈rt[VT], till we either terminate unsuccessfully or find the maximum sliding window k for which[R,SlidingWindow(k)]X→εYholds over r. The complete procedure is given in Algorithm 7.VerifySW can be applied at mostlog(maxt∈rt[VT])times. Finally, letkmax=maxt∈rt[VT]be the maximum value for the attribute VT in the instance r; the encountered complexity in finding the maximum size k (if any) for which[R,SlidingWindow(k)]X→εYholds over r is|r|·log(|r|)·log(kmax), by assuming that the VT is non-negative, and kmaxis expressed in the lower time-granule of its temporal domain (e.g. if VT is a year–month–day date then kmaxis expressed in days).Algorithm 7MaxSlidingWindow(R,X,ϵ,Y,r).Input:R,X,ϵ,Y,rOutput: k1;/⁎ A procedure for the dichotomic search of the maximum sizek, if it exists, such that [R,SlidingWindow(k)]X→εYholds overr.⁎ /2kmax←maxt∈rt[VT]];kmin←0;3whilekmax≠kmindo456789101112131415|ifVerifySW([R,SlidingWindow(kmax)]X→εY,r)then|returnkmaxendififNOTVerifySW([R,SlidingWindow(kmin)]X→εY,r)then|returnNILendifk←⌈kmax+kmin2⌉;ifVerifySW([R,SlidingWindow(k)]X→εY,r)|kmin←kelse|kmax←kendif16end while17ifVerifySW([R,SlidingWindow(kmax)]X→εY,r)then18|returnkmax19else20|return NIL21end if