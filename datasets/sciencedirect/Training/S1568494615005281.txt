@&#MAIN-TITLE@&#
A semi-supervised system for weed mapping in sunflower crops using unmanned aerial vehicles and a crop row detection method

@&#HIGHLIGHTS@&#
The problem of constructing a weed mapping model via machine learning techniques is assessed.The combination of spectral properties with vegetation indexes and crop rows helps the prediction.A semi-supervised classifier has been proved to perform well for the classification problem assessed with very few information provided by the user.An extended experimental design for weed mapping could be performed considering other crops.

@&#KEYPHRASES@&#
Remote sensing,Unmanned aerial vehicles (UAV),Weed detection,Machine learning,Hough transform,Support vector machine,

@&#ABSTRACT@&#
This paper presents a system for weed mapping, using imagery provided by unmanned aerial vehicles (UAVs). Weed control in precision agriculture is based on the design of site-specific control treatments according to weed coverage. A key component is precise and timely weed maps, and one of the crucial steps is weed monitoring, by ground sampling or remote detection. Traditional remote platforms, such as piloted planes and satellites, are not suitable for early weed mapping, given their low spatial and temporal resolutions. Nonetheless, the ultra-high spatial resolution provided by UAVs can be an efficient alternative. The proposed method for weed mapping partitions the image and complements the spectral information with other sources of information. Apart from the well-known vegetation indexes, which are commonly used in precision agriculture, a method for crop row detection is proposed. Given that crops are always organised in rows, this kind of information simplifies the separation between weeds and crops. Finally, the system incorporates classification techniques for the characterisation of pixels as crop, soil and weed. Different machine learning paradigms are compared to identify the best performing strategies, including unsupervised, semi-supervised and supervised techniques. The experiments study the effect of the flight altitude and the sensor used. Our results show that an excellent performance is obtained using very few labelled data complemented with unlabelled data (semi-supervised approach), which motivates the use of weed maps to design site-specific weed control strategies just when farmers implement the early post-emergence weed control.

@&#INTRODUCTION@&#
Weeds are responsible for an approximate 35% reduction in potential global crop yields. Today, most farmers in the EU rely on synthetic herbicides as a useful tool for maintaining and ensuring the quality and quantity of crop production and allowing an efficacy of weed control of almost 75%. This involves both that actual yield losses due to weeds are around 9% being â‚¬3.334M the cost of herbicides used, i.e. 41.5% of the total pesticides sales. This means by a 20 fold increase of herbicides from 1964 to 2004 [5,28]. Herbicides are usually broadcast over entire fields even though there are weed-free areas because weeds are usually spatially distributed in patches [20]. There are evident economical and environmental risks derived from over application, and to overcome this situation, patch spraying has supported the feasibility of using site-specific weed management (SSWM) based on weed coverage [30]. The cost of these herbicides usually accounts for 40% of the cost of all of the chemicals applied to agricultural land in Europe [5] and this economic factor together with environmental concerns have led to the creation of the European legislation on the sustainable use of pesticides, which includes guidelines for the reduction of these chemicals according to the weed infestation map [4,2]. A key component of SSWM is precise and timely weed maps for an appropriate early post-emergence weed control, and one of the crucial steps for weed mapping is weed monitoring [37], either by ground sampling or by remote detection and identification of weeds [33,16]. The remote sensing of weed canopies can significantly improve reliability compared to ground visits only whether the spectral and spatial resolutions of remote sensing equipment is sufficient for the detection of differences in spectral reflectance [39,23,24,15]. However, in early growth stages, the spectral and appearance characteristics of the crop and weeds are similar, thus imposing an additional handicap for the detection. Previous works have mapped weed at late growth stage (e.g. flowering) using piloted aircrafts or QuickBird satellite imagery [9,10]. However, this technology can not be applied in early detection because of the scarce spatial resolution of the data captured with these kind of platforms (pixel size around 50cm and 2.6m for piloted aircrafts and QuickBird satellite, respectively). In recent years, a new aerial platform has joined to the traditional ones, the unmanned aerial vehicle (UAV) [26]. Several investigations have demonstrated the advantages of the UAVs in comparison with airborne or satellite missions [22,25,44,32] regarding a minor cost and a higher flexibility in flight scheduling. These advantages make UAVs a proper tool to perform multi-temporal studies for crop and weed monitoring at early crop and weed phenological stage [42,41], which is a classic limitation of the traditional remote-sensed platforms. Another primary advantage of the UAV platforms is that flight route can be programmed at low altitude (e.g., <120m), which allows the acquisition of highly overlapping ultra-high spatial resolution images (in the range of very few centimetres).The combination of machine learning and UAVs for precision agriculture, although showing good synergy in a few previous works [31,45,18], is still an emerging research area mostly undeveloped. Usually, the most popular choice for defining a weed mapping system based on UAV-imagery is undoubtedly the use of manually defined rule sets [32,34] (based on pixel dissimilarity, pixel location or vegetation indexes), which has indeed led to very promising results. However, remote sensing and more specifically precision agriculture could benefit to a great extent from the use of supervised learning methods. Until now these methods have been mostly used with on-ground images in proximal sensing presenting great potential [38,23,6], which has motivated further research in this line. Proximal sensing can be said to present some limitations that make its use difficult in practice [6]. Firstly, this analysis is usually performed in real-time, resulting then in other series of concerns (e.g. computational resource limitations). Another factor contributing to this is the vibration of the equipment and changes of luminosity, which could jeopardize the correct classification of the data if the system is not robust enough. Opposed to this, remote sensing analysis would have to be performed prior to the broadcasting, but it could be useful to estimate a priori the quantity of herbicide and to optimise the field path to follow, notwithstanding that the image analysis step would be in general more simple. It is now, when the existing issues of UAVs have been mastered, such as route planning and others, and the cost of such platforms is affordable, that this technology is ready to use. In this sense, machine learning and image segmentation are suitable technologies for this task, given the large amount of previous research and the applicability of these techniques. Because of this, studies combining these two areas are starting to emerge in remote sensing [31,45]. Until now, the works in the literature have studied the feasibility and limitations of such an approach, proposing new methods for weed or vegetation fraction mapping and testing them in a wide variety of situations. These methods have shown great promise in detecting weeds between crop rows [32,41,40], but the identification of weeds within crop rows still remained an open challenge. The main difference between the proposal and the rest of studies is the analysis and use of a wide variety of machine learning techniques and the combination of these with a flexible crop row detection algorithm, which results in a robust and accurate method able to distinguish both weeds outside and within crop rows. Up to our knowledge, this is the first occasion where the information concerning crop rows is used in conjunction with the spectral features as input characteristics for a classifier.In this paper, a new system is proposed for weed mapping in sunflower crops. The objective is to alleviate the problem of crop and weed spectral similarity, therefore allowing a proper identification of weeds in a crop (sunflower, in this case). This crop was selected because it is the most important annual oilseed crop in southern Europe and the Black Sea region, with over 5Mha grown annually [1], of which 0.8Mha are in Spain [3] and consequently weed control operations account for a significant proportion of production costs. Ideally, the process of weed mapping should be performed timely and accurately to directly provide the farmer with a treatment map for early post-emergence. However, the direct generation of this treatment map is tricky when no prior information is provided and when the lighting settings and spectral properties of the different fields to study differ. Nowadays, with the current technology, the output of the proposed algorithm could be used to provide different treatments: a binary apply/not apply herbicides to weed infested field section (if one kind of weeds is present, e.g. grass weeds) or the application of different herbicides (e.g. to control broadleaved, grass or resistant weeds). These treatment maps will be afterwards given to a specific software which will be part of a treatment equipment in order to properly apply the chemicals. Moreover, the detection of crops could also be useful for plant counting or to position the equipment according to crop rows.The system proposed in this work uses the imagery of the field provided by the UAV and relies on very little information provided by the user: a set of labelled patches for each class and the set of parameters for the different algorithms. The methodology is based on the following steps: partition of the experimental field into different subimages, computation of vegetation indexes and binarisation of these, detection of crop rows and, finally, training of a classification model for the data provided. The main novelty of the methodology is the detection of crop rows based on the Hough transform (HT) [12] using imagery from UAVs (note that the Hough transform has been widely used with on-ground studies [38], but not with remote sensing imagery, for which and under our knowledge has only been used once in vineyard crop detection [8]). The HT information proves to be a very good way to differentiate crop from weed pixels presenting similar spectral information.On the other hand, the proposal tries to minimise the amount of information provided by the user and, at the same time, to obtain the maximum benefit from it. Most traditional machine learning approaches learn a discriminant function from a set of labelled data. However, labelled examples are usually expensive and time-consuming to obtain, as opposed to unlabelled data. This issue is indeed of serious concern for applications which require that the processing is performed in a limited time, such as the problem considered in this paper. In this direction, the paper explores how to perform this study with a simple a priori analysis of the UAV-captured images and how to optimise all the parameters of the method automatically. The second novelty of this work is the comparison of three machine learning paradigms (unsupervised, semi-supervised and supervised learning) to study the influence of labelled and unlabelled examples in the quality of the classifiers obtained.The objectives of the proposed system can be summarised in the following two: (1) to study how to combine UAV imagery with a crop row detection method, in such a way that the performance can be improved; and (2) to analyse the potential of different machine learning methods in the development of an algorithm using the minimum information possible, in order to provide a mostly unsupervised analysis which could be used easily in other real field scenarios. Different sensors and flight altitudes are also compared to study the influence of both factors. As far as the authors of this paper are concerned, this is the first approach to weed mapping via UAV imagery which combines spectral information with the HT [12] and analyses the performance of a wide range of different machine learning methods.The paper is organised as follows: SectionÂ 2 shows a description of the data acquisition and the weed mapping system proposed in this work; SectionÂ 3 describes the experimental study and analyses the results obtained; and finally, SectionÂ 4 outlines some conclusions and future work.The information provided in this section include the data acquisition and processing steps. The proposed system is described, including the different vegetation indexes (VI), the crop row detection method based on the Hough transform (HT), the different machine learning techniques and how to optimise all the parameters automatically. Fig. 1shows a summary of the different steps of the image processing algorithm proposed in this paper. As can be observed, the user has to provide only the UAV imagery, label some of the pixels and set the values for some of the parameters. The next steps of the proposed system are the following: Image partition (partition of the whole crop field into tractable regions for the subsequent algorithms), computation of the corresponding vegetation index (depending on the channels and sensor used), binarisation of this vegetation index (as a previous step for crop row detection), use of the HT for crop row detection, and finally, optimisation of parameters and classification of the pixels in soil, crop and weeds.The UAV system was tested in a sunflower field situated at the private farm La Monclova, in La Luisiana (Seville, southern Spain, coordinates 37.527N, 5.302W, datum WGS84). The flights were authorised by a written agreement between the farm owners and our research group. The sunflower seeds were planted at the end of March 2014 at 6kghaâˆ’1 in rows 0.7m apart. The set of aerial images were collected on May 15th, just when post-emergence herbicide or other control techniques are recommended in this crop. Several visits were periodically made to the field from crop sowing to monitor crop growth and weed emergence and, finally, to select the best moment to take the set of remote images. The sunflower was at the stage of 4â€“6 leaves unfolded. The weed plants had a similar size or, in some cases, were smaller than the crop plants. An experimental plot of 100Ã—100m was delimited within the crop-field to perform the flights. A systematic on-ground sampling procedure was carried out the day of the UAV flights. The procedure consisted of placing 49 square white frames of 1Ã—1m distributed regularly throughout the studied surface. Every frame was georeferenced with a GPS and photographed in order to compare on-ground weed infestation (observed weed density) and outputs from image classification (estimated weed density). These numbered cards were also utilised as artificial terrestrial targets (ATTs) to perform the imagery orthorectification and mosaicking process. In the course of the UAV flights, a barium sulphate standard spectralon panel (Labsphere Inc., North Sutton, NH, USA) of 1Ã—1m was also placed in the middle of the field to calibrate the spectral data.A quadrocopter platform with vertical take-off and landing, model md4-1000 (microdrones GmbH, Siegen, Germany), was used to collect the set of aerial images over the above-mentioned experimental crop-field (for different altitudes). The coordinates of each corner of the experimental field were collected with GPS for preparing the flight route. Then, the flight route was programmed into the UAV software to allow the UAV to reach every programmed altitude and required degree of image overlapping for further mosaicking. The md4-1000 UAV can carry any sensor weighing less than 1.25kg mounted under its belly, being the maximum recommended payload is 0.80kg, although as higher payload higher limitations related to UAV battery can occur. The imagery was collected at three different altitudes: 30, 60 and 100m and with two different cameras mounted separately in the UAV: a six-band multispectral camera, model TetraCam mini-MCA-6 (TetraCam Inc., Chatsworth, CA, USA), and a still point-and-shoot camera, model Olympus PEN E-PM1 (Olympus Corporation, Tokyo, Japan). The TetraCam mini-MCA-6 is a lightweight (700g) multispectral sensor composed of six individual digital channels arranged in a 263 array. Each channel has a focal length of 9.6mm and a 1.3 megapixel (1280Ã—61, 024 pixels) CMOS sensor that stores the images on a compact flash card. The images can be acquired with 8-bit or 10-bit radiometric resolution. The camera has user configurable band pass filters (Andover Corporation, Salem, NH, USA) of 10-nm full-width at half-maximum and centre wavelengths at blue (B, 450nm), green (G, 530nm), red (R, 670 and 700nm), R edge (740nm) and near-infrared (NIR, 780nm). These bandwidth filters were selected across the visible and NIR regions with regard to well-known biophysical indices developed for vegetation monitoring [21]. Image triggering is activated by the UAV according to the programmed flight route. At the moment of each shot, the on-board computer system records a timestamp, the GPS location, the flight altitude, and vehicle principal axes (pitch, roll and heading). The Olympus camera acquires 12-megapixel images in true colour (R, G and B bands) with 8-bit radiometric resolution and is equipped with a 14â€“42mm zoom lens. A sequence of 60% end or longitudinal lap and 30% side or lateral lap imagery was collected to cover the whole experimental sunflower field corresponding to each flight mission cameras and altitudes (Fig. 2). Detailed information about the configuration of the UAV flights and specifications of the vehicle and sensors can be found in [42].As said, different overlapped images were collected for this study to cover the whole experimental field. This is due to UAV images flying at low altitudes (according to Spanish regulation maximum altitude is 120m for UAVs weighing less than 25kg) that can not cover the whole field, and this causes the need to take a sequence of multiple overlapped (end-lap or lateral-lap and side-lap or longitudinal-lap) images. As consequence, a large number of UAV images are acquired to cover the whole sunflower plot. A necessary step of the system developed is the combination of these individual images via a process of image orthorectification and mosaicking. The Agisoft Photoscan Professional Edition (Agisoft LLC, St. Petersburg, Russia) software was employed for this task. In the first step, the software asks for the geographical position and principal axes (roll, pitch and yaw) of the vehicle in each acquired image. Next, the software automatically aligns the photos. Finally, some ATT's coordinates are added to assign geographical coordinates to the image. Then, the software automatically performs the orthorectification and mosaicking of the imagery set into a single image of the whole experimental field. The resultant ortho-mosaic shows a high-quality landscape metric and accurate crop row matching between consecutive images, which guarantees good performance of the subsequent image classification (see Fig. 2). More details about mosaicking in [14].Once the sunflower crop rows have been correctly matched in the ortho-mosaicked image, given the size of this image and the computational load of both the crop row detection and classifiers, the mosaicked image is partitioned into multiple subimages of approximately 1000Ã—1000 pixels (starting from the upper-left corner and finishing in the bottom-right one). Each of them is separately processed, i.e. an independent classifier is trained and evaluated in every subimage. Note however, that the training labelled samples are always the same, and the only information that change are the unlabelled ones. This partition is also important to consider potential differences in the spectral information of the experimental field or lighting changes. Each subimage will therefore represent a part of the experimental field.The term VI refers to a mathematical expression that combines the surface reflectance at two or more wavelengths of an image in order to highlight a particular property of vegetation. In this work, two widely used indices for vegetation estimation will be compared in order to analyse their performance:â€¢Normalised difference vegetation index (NDVI) [13,41] will be used with the images obtained from the multispectral camera (in our case, for the TetraCam sensor) to consider the near infrared (NIR) wavelength. It can be computed as follows: D=(Nâˆ’R)/(N+R), where D is the output matrix associated to the NDVI index, R is the matrix for the red channel and N is the matrix for the NIR channel.Excess green index (ExG) [43,41] will be used with visible images (in our case, for the Olympus sensor), and it can be computed as follows:(1)E=2G*âˆ’R*âˆ’B*,where R*=R/(R+G+B), G*=G/(R+G+B), B*=B/(R+G+B), E is the ExG output matrix and G, R and B are the matrices associated to the green, red and blue spectral channels, respectively.One of the main hypotheses of this paper is that weed discrimination could be improved based on the relative location of weeds with respect to crop lines. Therefore, a procedure able to accurately detect crop rows is of vital relevance in this case.The Hough transform (HT) [12] is a widely used and powerful technique for detecting complex patterns of points in binary images (such as lines or parametric curves). This method relies on a parameterisation (which is defined beforehand) that characterises the patterns that the algorithm is aiming to find (e.g. the parameters for the case of a line are the corresponding slope and intercept). In this sense, every pair of points in the image define a line. Furthermore, these parameters can be represented in a two-dimensional space (the so-called parameter space), where a voting procedure can be conducted. Points belonging to a line in the image will have the same slope and intercept, so the voting is performed considering how many times each combination of parameters has been selected for a line joining two points. Thus, the HT technique converts a difficult global detection problem in the image space into a more easy to solve local peak detection problem in the parameter space. Finally, object candidates (crop rows) are obtained as local maxima via a gradient ascent algorithm or simply by thresholding the number of votes.The HT method is applied to the vegetation index considered (e.g., NDVI for TetraCam). As stated before, the HT method is used for binary images. Because of this, the use of a thresholding procedure is necessary in order to binarise the vegetation index. In this paper, the Otsu's method [29] is selected, given its demonstrated robustness and simplicity [41]. This clustering-based image thresholding method searches for the thresholds that minimise the intra-class variance. Three different levels are assumed for the different indexes (the lowest level for the bare soil, a medium level for the weeds and the highest level for the crops). Then, bare soil and weeds in the image are taken as 0's and crops are taken as 1's, in order to extract the crop rows via the HT method.The HT method is able to detect only the first and the last point of the crop row, but crop rows have a predefined width (which is associated to the crop and height). Consequently, those pixels adjacent to the lines detected by the HT method should also be considered part of the crop row. To do so, we develop a method for automatically optimising this parameter. The distance from each point to the nearest crop row is computed. Note that these are line segments, but not strict lines. In this sense, if we aim to find the distance from a point x to a segment s delimited by points y and z (i.e. parameterised as y+t(zâˆ’y)), we firstly have to find where its projection onto the line falls:(2)t=(xâˆ’y)Â·(zâˆ’y)|(xâˆ’y)|2.Depending on the value of t, the point will lie beyond y (t<0), beyond z (t>1) or its projection will fall on the segment (0â‰¤tâ‰¤1):(3)d(x,s)=d(x,y),t<0,d(x,xs),0â‰¤tâ‰¤1,d(x,z),t>1,where xsis the projection of x over s. A threshold is applied to these distances to decide the points of the buffer for the crop row. The selection of this threshold is explained in the next section.These crop rows have to be incorporated in the classification process. We propose a new data feature to do so (apart from the spectral information and VI). This feature is computed by multiplying the VI and this binary mask (the result being zero for points outside the buffer and the VI value for points within the buffer). Ideally, it will allow to distinguish between pixels which lie very far from the crop rows (bare soil or weed) and pixels which lie closer to these crop rows (crop). However, at the same it also contains information about the VI (e.g. in order to distinguish between the different pixels outside and within the buffer).The HT technique depends on several parameters. For example, during the search process the HT considers different angles for the segments to be found. A free range of values can be used, but this results in a very high computational load. Instead of this, we fix the range of possible angle values to [10, 40] (the images should be analysed to fix this range). Another parameter, the number of lines to be detected, is set to 200 (as this number has been proven to work well for all of the partitioned images).However, there are other two parameters which have to be manually assigned according to the user preferences and the specific image analysed:â€¢Minimum length per crop line segment: Minimum length of a line segment to be considered as a possible solution.Fill gap: scalar value that specifies the minimum distance allowed between two line segments (if the distance is less than the specified value, the two line segments are merged).Optimising these two parameters by a nested 5-fold cross-validation procedure will pose a hindrance for the algorithm because of the excessive computational load (note that there are other parameters related to the classifier). Because of this, we design a new evaluation metric capable of capturing the amount of pixels with a high value of VI that are covered by the detected crop rows. This allows to optimise these parameters in a unsupervised manner. We make use of the result of the previous Otsu's binarisation (for more information, see SectionÂ 2.4.1), which (ideally) segmented the image into soil, weed and crops by the use of two thresholds. We apply the last threshold in order to obtain an estimation of crop pixels. Then, we compute the distance from each pixel to the set of crop rows. The next step is the optimisation of the threshold for the distances to crop rows via the well-known Receiver Operation Curve. For this, we consider that the estimated crop pixels represent the positive class and the rest represent the negative class. This is, we aim to find the optimal threshold for the computed distances in such a way that crop pixels present a distance to crop rows lower than the optimal threshold. We select the one presenting the best trade-off in terms of sensitivity and specificity.Once this threshold is selected, we can compute the crop row buffer by setting to zero the pixels which belong to the negative class and to one to the pixels that belong to the positive one. Then, we propose to use an evaluation metric computed as the number of estimated crop pixels that are included in this buffer. This measure is thus to be maximised, as a higher value indicates that the selected parameters (i.e. approximate number of lines and minimum length per row) allow a better coverage of crop rows. The same parameters are chosen for the whole experimental field. Therefore, each 1000Ã—1000 subimage contributes a different error and the sum of all errors is used for controlling the parameters. The formulation of this performance metric, e, is as following:(4)e(Î¸)=âˆ‘i=1mâˆ‘j=1riâˆ‘z=1civjziÂ·bjzi,vjziâˆˆVi,bjziâˆˆBi,where Î¸ is the set of considered parameters, m is the number of subdivisions of the experimental field, riand ciare the number of rows and columns for image Ii, respectively, Viis the associated VI for Iiand Biis the binary buffer matrix that has been obtained by applying HT using parameters Î¸, computing the distances from each pixel to the segments and optimising the threshold.In this paper, the minimum length of the lines and the gap between crop lines are chosen by cross-validation from the following set: {10, 30, 50}, using the previously proposed measure e(Î¸) as the performance criterion.For this paper, different machine learning techniques are considered in order to solve the above-mentioned problem of weed mapping. In this case, unsupervised learning itself does not match the definition of the problem that is intended to solve, since the classes into which characterise the data are clear (crop, weed and bare soil). On the contrary, the task of labelling every pixel in the experimental field (or, at least, a vast majority of them) is a hard and tedious work, and almost intractable for timely practical applications. Because of this, we consider a slightly different approach by guiding the learning process using only a 10Ã—10-pixel window for each different group (i.e., crop, weed and soil). The idea is to check if it is feasible to capture the nature of the three classes using a very small region of pixels for each group. Semi-supervised learning will be also considered, where both labelled and unlabelled information is included in the learning process.Fig. 3shows the subimages selected for both TetraCam and Olympus sensors at 30m of altitude. It can be seen that the manual selection of these subimages would not require much effort and time for the user (as these images are of a size of 10Ã—10 pixels).Note that the use of this information is different depending on the paradigm considered. For the guided unsupervised technique it is only used for initialising the data centroids but the data over which the algorithm is trained corresponds to the image itself. For the semi-supervised, it is used for the training phase in conjunction with all of the unlabelled data. Finally, for the supervised classification paradigm, only these data are used for training the model, and the rest of the data (i.e. the image itself) is only considered for prediction.There is a wide range of algorithms that can be framed under the term clustering. However, the pioneer method (which is still widely used) can be said to be the k-means algorithm [19].The k-means technique revolves around the notion of data centroid, which is the most representative point of a cluster and is used to determine whether a pattern belongs to the cluster. More formally, each pattern belongs to the cluster associated to the closest centroid (measured by a predefined distance notion). Each centroid is assigned an initial value. Then, centroids are iteratively shifted by averaging the patterns associated to each cluster until convergence. Further information about this method can be found in [19].At the initial stage, the centroids can be assigned randomly or by setting them to training patterns (which should be related to the information that we are aiming to find). In this paper, we propose to fix the initial centroids using two approaches:â€¢k-Means: the former approach consists on deterministically computing the initial data centroids by averaging each of the labelled 10Ã—10 subimages.Repeated k-means (Rk-means): The other method chooses a random pixel of each 10Ã—10 subimage (to allow more degrees of freedom). This procedure is repeated 30 times (randomly selecting centroids and running k-means) and the final centroids are the ones which produce the best results (considering whether each pixel of the subimages is grouped in its predefined cluster).The main goal of semi-supervised classification [7] is to derive a decision boundary sufficiently smooth with respect to the data structure composed both by labelled and unlabelled data to improve the generalisation. Usually, for the design of this type of algorithms, the cluster assumption is used, i.e., the decision boundaries are optimised in such a way that they do not cross high density regions, but instead lie in low density regions (ensuring that nearby patterns and patterns on the same data structure are likely to have the same label).The main restriction to consider for this type of paradigm is the computational load. Unlike most unsupervised methods which are relatively simple, semi-supervised ones require a higher computational load, because both labelled and unlabelled patterns are used for the training process. Depending on the application, this could involve a very high number of patterns. Considering all of the above-mentioned, we have selected a semi-supervised linear SVM-based approximation to deal with large-scale datasets [36]. We considered a one-against-one approach with a voting scheme, as done for most binary SVM-based techniques [17].The motivation to use semi-supervised learning is to analyse whether the inclusion of unlabelled data helps to the construction of the decision model in the case where the amount of labelled data is very few compared to the unlabelled examples.Supervised learning concerns to the notion of designing a prediction model by using previously labelled samples.In our case, we will test their performance when very few labelled data is considered (300 pixels, 100 for each class). We test two well-known and widely used classification methods: k-nearest neighbours and SVM. Both linear and kernel versions of the SVM algorithm will be tested, in order to compare the results (between the two methods and to the semi-supervised linear version) and analyse the nonlinearity of the learning problem. The one against one technique is considered for all of the binary SVM-based methods [17].As stated before, one of the main aims of this paper is to produce a mostly unsupervised timely response for the problem of weed mapping in crop areas. The parameters associated to the classifiers are optimised using a stratified 5-fold procedure over the sets of labelled data (i.e. the predefined subimages of each image belonging to the crop, weed and soil classes). The evaluation metric considered is the well-known accuracy.The values explored during parameter tuning are now introduced. For the k-nn method the number of nearest neighbours is cross-validated among the following values: {1, 3, 5, 7}. For the LinSVM and SVM techniques the cost parameter is chosen from one of these values: {10âˆ’2, 10âˆ’1, 100, 101, 102} (and so is the kernel parameter associated to SVM). For the regularisation parameters of SS-SVM the following values are used: {10âˆ’4, 10âˆ’3, 10âˆ’2, 10âˆ’1, 100}.

@&#CONCLUSIONS@&#
This paper proposes a system for weed mapping in sunflower crops via unmanned aerial vehicles for designing site-specific weed control treatments in early post-emergence. For the three classes to discriminate (crop, soil and weed), two of them have very similar spectral properties, making the task very difficult. The system proposed makes use of the Hough transform (HT) for crop row detection to complement the spectral information and increase the accuracy obtained. Although the process should be ideally performed in an unsupervised manner, the application of this type of techniques would not be satisfactory in this case, given that the classes are a priori predefined. We explore several machine learning paradigms with different degrees of labelled data (unsupervised, semi-supervised and supervised) with the purpose of minimising the intervention of the user. The results show that semi-supervised methods generalise well even when only a very small subset of labelled training patterns is considered. Moreover, the results showed that all the parameters of the proposed model could be almost automatically optimised as proposed, with very few interactions by the user. Finally, this work also validated some of the main hypothesis in the literature concerning the flight height and the sensor to use.Several lines of future work should be highlighted. Firstly, the paradigm of object based image analysis could be explored for image segmentation, which has been seen to alleviate the salt-and-pepper effect produced by pixel-based classification. Although the classical HT is designed to identify lines in an image, this technique has been later extended for arbitrary shapes, such as circles or ellipses. This improved version of HT could be used in future work to allow more degrees of freedom in the crop row detection phase. Moreover, other crops apart from sunflower (which is a wide row crop, rows of 70cm apart) could be considered, such as wheat (which is a narrow row crop, rows of 17cm apart) in order to analyse the potential applicability of the proposal to other agronomical scenarios, as well as other flight settings (flight height, sensor used, etc.). Other point that could be studied in future work is the use of big data or large-scale techniques for the processing step in such a way that each model is not only trained in a subimage, but also complemented with information of the whole image. This could make the whole learning process more robust and less dependent on the data partition. One-class or binary classification approaches could also be of interest, trying to discriminate weed pixels from the rest (soil and crop) and alleviating the labelling procedure, which is usually the main bottleneck of such a system. Furthermore, a study on the approximate number of training patterns and the influence of this choice would be of vital importance as well (to evaluate the effort needed for labelling the training data). Finally, the potential applicability of a model trained in a given experimental field to a different experimental field could be analysed (considering the same crop). The use of previously trained models could highly reduce the required computational time and alleviate the process of weed mapping. However, the experimental fields could have very different characteristics. Because of this, it could be interesting to study the paradigm of incremental learning [35]. Under this setting, a trained model could be slightly modified in order to better fit new data, and this approach could ideally lead to good results at the expense of a low computational load.