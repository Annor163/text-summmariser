@&#MAIN-TITLE@&#
Two-stage stochastic linear programs with incomplete information on uncertainty

@&#HIGHLIGHTS@&#
The model only uses the first and second moments information of random variables.We show that the new model is indeed a second-order cone optimization problem.Preliminary numerical experiments indicate the computational advantage of this model.

@&#KEYPHRASES@&#
Stochastic programming,Linear decision rule,Second order cone optimization,

@&#ABSTRACT@&#
Two-stage stochastic linear programming is a classical model in operations research. The usual approach to this model requires detailed information on distribution of the random variables involved. In this paper, we only assume the availability of the first and second moments information of the random variables. By using duality of semi-infinite programming and adopting a linear decision rule, we show that a deterministic equivalence of the two-stage problem can be reformulated as a second-order cone optimization problem. Preliminary numerical experiments are presented to demonstrate the computational advantage of this approach.

@&#INTRODUCTION@&#
Many decision-making problems that involve uncertainty are modeled as stochastic programs. Traditionally, stochastic optimization models require detailed information on the probability distribution of the random variables. Under such assumptions, the decision makers seek to minimize the aggregated expected cost over the multi-stage planning period. In order to solve the stochastic optimization problems, one often resorts to Monte Carlo sampling approximation approaches, which can be very challenging in practice. See Birge (1997), Shapiro (2001), and Lin and Fukushima (2010) for details in this regard. In fact, such assumption may not be applicable at all in practice because the required probability information of the underlying uncertainties is almost never available in real world environments.Motivated by recent development in risk measure theory and robust optimization, the aim of this paper is to demonstrate that, for the traditional two-stage stochastic programming model with fixed recourse, one could consider a new risk measure other than the expected cost to avoid requiring detailed distribution information and the “curse of dimensionality”. We consider a worst case cost model which is formulated as a minimax stochastic optimization problem over a family of possible probability measures of the stochastic parameters. In the terminology of risk measure theory, this family of distributions essentially defines a so-called “risk envelope” and the worst case cost defined by this risk envelope is a coherent risk measure in the basic sense, see Föllmer and Schied (2002), Lüthi and Doege (2005), and Rockafellar (2007). Recent works of Bertsimas, Doan, Natarajan, and Teo (2010), Bertsimas and Brown (2009), Natarajan, Pachamanova, and Sim (2009) disclosed connections between risk measures and uncertainty sets in robust optimization. Hence the models in this paper, in a sense, could be considered as a robust stochastic programming model. To be self-contained, also for ease of understanding, our exposition does not require knowledge on risk measure theory or robust optimization. We deal with the stochastic optimization model from a practical point of view; namely, we seek to minimize the worst-case aggregated expected cost that depends on first and second moments information of the random variables. The idea bears certain similarity to the so-called “Distributionally Robust Stochastic Program (DRSP)”, which was introduced by Scarf (1958), and had been studied by Landau (1987), Dupacova (1987), Kall and Wallace (1994), Delage and Ye (2010) for example.Different from the traditional DRSP approach, we only make modest assumptions on the distributional information. Such assumptions involve means, variances (or second moments), and supports of the random variable, which can be estimated from the historical data of the uncertain parameters. We show that the resulting models are equivalent to second-order cone optimization problems (SOCPs). Consequently, it is computationally tractable and allows us to apply the state-of-the-art SOCP solvers in computation.In order to derive meaningful results, we need a linear decision rule (explained in Section 2.1). Although such assumption is subject to criticism, it is interesting to know that how much we could gain from these assumptions.The main technical tool used in our exploration is linear programming (LP) duality both in finite and infinite (probabilistic) spaces together with quadratic programming duality. For a good introduction to LP duality in infinite-dimensional spaces, we recommend the book of Anderson and Nash (1987). The book of Rockafellar (1970) contains duality theory for quadratic and convex programming.The rest of this paper is organized as follows. In Section 2, we establish the optimization model of the two-stage stochastic programming problem with incomplete information by using the linear decision rule and we investigate deterministic tractable approximation to this model. Section 3 contains numerical results with certain important observations. Section 4 concludes the paper.Notations. We denote a random variable,x̃, with the tilde sign. Matrices and vectors are represented as upper and lower case letters respectively. If x is a vector, we use the notation xito denote the ith component of the vector. For any two vectorsx,y∈Rl, the notation x⩽y means xi⩽yifor all i=1,…,l. A random vector is represented by its support Ω and a probability measurePon a σ-algebra Θ of events. We useEP(x̃)andEP(x̃2), respectively, to denote the first and second moments ofx̃underP.Consider the following classical two-stage stochastic programming problem with fixed recourse:(2.1)minx∈X{c′x+EP[Q(x,z̃)]}where the apostrophe (′) stands for the transpose andQ(x,z)=minyd′ys.t.A(z)x+Dy=b(z),y⩾0,wherex∈Rnis the vector of first-stage decision variables subject to a feasible regionX⊆Rnwhiled∈Rk,b(z)∈Rl,A(z)∈Rl×nare second-stage data,D∈Rl×krepresents the fixed recourse matrix. Herez̃is random vector with a supportΩ⊂RmwhileA(z̃)andb(z̃)are the associated uncertain data andPis the probability measure ofz̃. In addition,y∈Rkrepresents the decision variables of the second-stage (recourse) problem with respect to a realization z ofz̃.To deal with (2.1), we need to assumePis known and then apply Monte Carlo simulation or sample average approximation method to solve the corresponding problem. However, this assumption is rather strong since it is often impossible to know the exact distribution. Moreover, the number of scenarios can grow exponentially with respect to the dimension ofz̃(the so-called “curse of dimensionality”), which often makes Problem (2.1) computationally intractable. It is therefore reasonable to consider a stochastic programming model in whichz̃is structured and only certain partial information onz̃, such as the first and second moments, is known.We assume the uncertain datab(z̃)andA(z̃), together with the (recourse) vector y, in (2.1) are affinely dependent on the random vectorz̃, namely(2.2)y(z̃)=y0+∑j=1mz̃jyj,b(z̃)=b0+∑j=1mz̃jbj,andA(z̃)=A0+∑j=1mz̃jAj,wherebj∈Rl, andAj∈Rl×n,j=0,1,…,m, are deterministic values given in advance. Since each yjis a k-dimensional vector, we define the k×(m+1) matrix Y asY=[y0,y1,…,ym]=[y0,Y-0]∈Rk×Rk×m,and denote the qth row vector of Y−0 by yq, i.e.,yq=yq1,…,yqm′∈Rm.There is no further assumption onz̃at this moment except that we assume the support ofz̃is a finite box, i.e.,Ω={z∈Rm:-∞<-ℓ⩽z⩽h<+∞}.The above affine-dependence assumption, also called the linear decision rule (LDR), is often adopted in dealing with the uncertainties in robust optimization models. See, e.g., Ben-Tal and Nemirovski (2002). Chen, Sim, Sun, and Zhang (2008) used it in the context of robust stochastic programming. Chen, Sim, Sun, and Teo (2010) used it in dealing with joint chance constraints. Note also that the same name of linear decision rule has been adopted in production planning with a totally different concept, see, e.g., Vollmann, Berry, Whybark, and Jacobs (2005).It is easy to see that if Ω is full-dimensional (that is, − ℓ<h), then the following equivalence is valid.A(z)x+Dy(z)=b(z),∀z∈Ω⇔Ajx+Dyj=bj,j=0,1,…,m.Moreover, by strong duality of linear programming, we may obtain the following equivalence.y(z)⩾0,∀z∈Ω⇔∃sq,tq∈R+msuchthatyq0-ℓ′sq-h′tq⩾0andsq-tq⩽yq,∀q=1,…,k.Therefore, under the linear decision rule, we have(2.3)E[Q(x,z̃)]=EminY,s,td′y0+∑j=1md′yjz̃js.t.Ajx+Dyj=bj,j=0,1,…,m,yq0-ℓ′sq-h′tq⩾0,q=1,…,k,sq-tq⩽yq,q=1,…,k,sq,tq⩾0,q=1,…,k,where s=(s1,…,sk)′ and t=(t1,…,tk)′.Remark 1It can be seen the boundedness assumption on Ω is not essential. If some of the ℓjs or hjs are infinite, the linear structure of the objective function and the constraints of (2.3) will remain.It is often difficult to obtain or use exact distribution of the random vectorz̃due to•absence of statistical data,unreliable measure of data, andthe difficulty to describe multi-dimensional distribution (say, computing the probability of an event in high-dimension spaces);Using the duality theory of linear optimization in probability spaces (see Anderson & Nash (1987), see also Vandenberghe, Boyd, & Comanor (2007) for some examples), the dual of Problem (2.5) is(2.6)minv0,v,V,Y,s,tv0+μ′v+η′Vs.t.v0+∑j=1mvjzj+∑j=1mVjzj2⩾minY,s,td′y0+∑j=1md′yjzj,∀z∈Ω,Ajx+Dyj=bj,j=0,1,…,m,yq0-ℓ′sq-h′tq⩾0,q=1,…,k,sq-tq⩽yq,q=1,…,k,V,sq,tq⩾0,wherev0∈R,v=(v1,…,vm)′,V=(V1,…,Vm)′∈Rm,μ=(μ1,…,μm)′, and η=(η1,…,ηm)′. Under suitable conditions, strong duality holds. One of such conditions is the generalized Slater condition, which says that there exists a strictly feasible solution for all z∈Ω and the optimal value of the dual problem is finite. For ease of exposition, we simply assume strong duality holds between (2.5) and (2.6). On the other hand, according to (2.6), model (2.4) is actually a “min–min” problem. Therefore, the two-stage problem with incomplete information on uncertainty (2.4) can be written as(2.7)minx,Y,s,t,v0,v,Vc′x+v0+μ′v+η′V(2.8)s.t.v0+∑j=1mvjzj+∑j=1mVjzj2⩾minY,s,td′y0+∑j=1md′yjzj,∀z∈Ω,(2.9)Ajx+Dyj=bj,j=0,1,…,m,(2.10)yq0-ℓ′sq-h′tq⩾0,q=1,…,k,(2.11)sq-tq⩽yq,q=1,…,k,(2.12)V,sq,tq⩾0,q=1,…,k,x∈X.Lemma 2.1LetΠ≔{(Y,s,t):∃x∈Xsuchthatconstraints(2.9)–(2.11) and (2.12)aresatisfied.}Assume that one of the sets Ω and Π is compact. Then Problem(2.7)–(2.12)is equivalent to(2.13)minx,Y,s,t,v0,v,Vc′x+v0+μ′v+η′Vs.t.v0+∑j=1mvjzj+∑j=1mVjzj2⩾d′y0+∑j=1md′yjzj,∀z∈Ω,Ajx+Dyj=bj,j=0,1,…,m,yq0-ℓ′sq-h′tq⩾0,q=1,…,k,sq-tq⩽yq,q=1,…,k,V,sq,tq⩾0,q=1,…,k,x∈X.Constraint (2.8) can be written as follows.∀z∈Ω,∃(Y,s,t)∈Π:v0+∑j=1mvjzj+∑j=1mVjzj2-d′y0+∑j=1md′yjzj⩾0,or equivalentlyminz∈Ωmax(Y,s,t)∈Πv0+∑j=1mvjzj+∑j=1mVjzj2-d′y0+∑j=1md′yjzj⩾0.The above objective function is convex in z and concave in (Y,s,t) and both sets, Ω and Π, are closed and convex. By Sion’s minimax theorem (Sion, 1958), as long as Ω or Π is compact, we haveminz∈Ωmax(Y,s,t)∈Πv0+∑j=1mvjzj+∑j=1mVjzj2-d′y0+∑j=1md′yjzj=max(Y,s,t)∈Πminz∈Ωv0+∑j=1mvjzj+∑j=1mVjzj2-d′y0+∑j=1md′yjzj.The constraint (2.8) is therefore equivalent to∃(Y,s,t)∈Π,∀z∈Ω:v0+∑j=1mvjzj+∑j=1mVjzj2-d′y0+∑j=1md′yjzj⩾0,which proves the lemma.□We next show that the problem (2.13) can be formulated as a second-order cone program.Proposition 2.1The feasible set of Problem(2.13)is second-order cone (SOC) representable. Consequently, Problem(2.4)can be reformulated as an SOCP.The feasible set of (2.13) can be equivalently written as(2.14)v0-d′y0+∑j=1m(vj-d′yj)zj+∑j=1mVjzj2⩾0,∀z∈Ω,Ajx+Dyj=bj,j=0,1,…,m,yq0-ℓ′sq-h′tq⩾0,q=1,…,k,sq-tq⩽yq,q=1,…,k,V,sq,tq⩾0,q=1,…,k,x∈X.The first constraint in (2.14) is equivalent to the following(2.15)minzv0-d′y0+∑j=1m(vj-d′yj)zj+∑j=1mVjzj2:-ℓ⩽z⩽h⩾0.Fix Vj, vj, yj, the left hand side of (2.15) is a separable convex quadratic program in z over a box. By strong duality of convex quadratic programming and the separability of variables, we have that (2.15) is equivalent to(2.16)max∑j=1m-hjλj-ℓjνj+Vjzj2+(vj-d′yj+λj-νj)zj+v0-d′y0⩾0(2.17)s.t.λj,νj⩾0,j=1,…,m,2Vjzj+(vj-d′yj+λj-νj)=0,j=1,…,m,where λj, νj, j=1,…,m, are dual variables.If all Vj>0, we solve zjfrom (2.17) and substitute the solution into (2.16) to obtainmax∑j=1m-hjλj-ℓjνj-(vj-d′yj+λj-νj)2/(4Vj)+v0-d′y0⩾0s.t.λj,νj⩾0,j=1,…,m,which is equivalent to(2.18)∑j=1m[-hjλj-ℓjνj-uj]+v0-d′y0⩾0,(2.19)uj,λj,νj⩾0,j=1,…,m,(2.20)(vj-d′yj+λj-νj)2⩽4Vjuj,j=1,…,m,where uj, j=1,…,m, are auxiliary variables.If some Vj=0, it can be directly verified that conditions (2.18), (2.19) and (2.20) are also sufficient and necessary for the optimality of Problem (2.16) and (2.17). Thus, Problem (2.13) is equivalent to(2.21)minu,v0,v,V,x,Y,s,t,λ,νc′x+v0+μ′v+η′Vs.t.∑j=1m[-hjλj-ℓjνj-uj]+v0-d′y0⩾0,(vj-d′yj+λj-νj)2⩽4Vjuj,j=1,…,m,Ajx+Dyj=bj,j=0,1,…,m,yq0-ℓ′sq-h′tq⩾0,q=1,…,k,sq-tq⩽yq,q=1,…,k,V,λ,ν,u⩾0,sq,tq⩾0,q=1,…,k,x∈X.The problem (2.21) is an SOCP since we can reformulate (2.21) as follows.(2.22)minu,v0,v,V,x,Y,s,t,λ,νc′x+v0+μ′v+η′Vs.t.1′u+d′y0+h′λ+ℓ′ν-v0⩽0,vj-d′yj+λj-νjVj-uj⩽Vj+uj,j=1,…,m,Ajx+Dyj=bj,j=0,1,…,m,ℓ′sq+h′tq-eq′y0⩽0,q=1,…,k,sq-tq-Y-0′eq⩽0,q=1,…,k,V,u,λ,ν⩾0,sq,tq⩾0,q=1,…,k,x∈X,where1=(1,1,…,1)′∈Rm,eq=(0,…,0,1,0,…,0)′∈Rk,q=1,…,k.□In the above analysis, the support Ω ofz̃is assumed to be a finite box. In fact, Ω could be in a more general form like a bounded full-dimensional polytope which could be defined by a finitely many affine inequalities, i.e.,Ω={z∈Rm:Mz⩽g}.With a similar manner, we can derive an SOCP equivalence of the corresponding optimization model as well.To illustrate the proposed worst-case optimization approach, we have carried out numerical tests on the corresponding SOCP reformulation using a two-stage stochastic programming example and its variations. In this section, we report some preliminary numerical results. The tests are carried out by implementing codes in Matlab 7.8.0 and CPLEX 12.4 installed in a PC with Windows XP Operating System. We first use the Matlab built-in solver linprog to solve the stochastic example under the usual sampling reformulation, which we call “the classical formulation”. For the SOC problems, we run the CPLEX solver cplexqcp in the Matlab environment. It is known that cplexqcp is a well-developed solver for solving linear/quadratic programming problems.Example 11This is a slightly different version of Example 7.3 in the book of Bertsimas and Freund (2000).1A company manager is considering the amount of steel to purchase (at $58/1000lb) for producing wrenches and pliers in next month. The manufacturing process involves molding the tools on a molding machine and then assembling the tools on an assembly machine. Here is the technical data.WrenchPlierSteel (lbs. per unit)1.51Molding machine (hours per unit)11Assembly machine (hours per unit)0.30.5Contribution to earnings ($ per 1000 units)130100There are uncertainties that will influence his decision. 1. The total available assembly hours of next month could be 8000 or 10,000, with 50/50 chance. 2. The total available molding hours of next month could be either 21,000 or 25,000 at 50% possibility for each case. The manager would like to plan, in addition to the amount of steel to purchase, for the production of wrenches and pliers of next month so as to maximize the expected net revenue of this company.This example is a typical two-stage stochastic programming problem where the first-stage decision variable is the quantity, x, of the steel to purchase now (unit: 1000 (lbs)) while the second-stage decision variables are the production plan w, p, or wi, piunder scenario i=1, 2, 3, 4 (unit: 1000 (units)), i.e., quantities of wrench and plier to be produced next month. The objective is to minimize (maximize) the total expected cost (profit). In this situation, the four scenarios concerning random variables, molding hour and assembly hour, are as follows.ScenarioMolding hoursAssembly hoursProbability125,00080000.25221,00080000.25325,00010,0000.25421,00010,0000.25Then, we solve the problem in format (2.1) as below, where without loss of generality and for brevity, we omit the common scalar 10−3 of all items in the objective function.min58x-∑i=140.25(130wi+100pi)s.t.w1+p1⩽25,(Moldconstraintforscenario1)0.3w1+0.5p1⩽8,(Assemblyconstraintforscenario1)-x+1.5w1+p1⩽0,(Steelconstraintforscenario1)w2+p2⩽21,(Moldconstraintforscenario2)0.3w2+0.5p2⩽8,(Assemblyconstraintforscenario2)-x+1.5w2+p2⩽0,(Steelconstraintforscenario2)w3+p3⩽25,(Moldconstraintforscenario3)0.3w3+0.5p3⩽10,(Assemblyconstraintforscenario3)-x+1.5w3+p3⩽0,(Steelconstraintforscenario3)w1+p1⩽21,(Moldconstraintforscenario4)0.3w4+0.5p4⩽10,(Assemblyconstraintforscenario4)-x+1.5w4+p4⩽0,(Steelconstraintforscenario4)x,wi,pi⩾0,i=1,…,4.Solving the above linear programming problem, we derive the optimal solution of the fist-stage decision variable x=31,500 (lbs) with the corresponding expected profit of $961.89, and the production plans for wrench and plier under various scenarios are as follows.Scenariowi(unit)pi(unit)117,2225667221,0000313,00012,000421,0000In this subsection, we compare the solution obtained previously with our SOCP reformulation with linear decision rule. Here we choose X={x:x⩾0} and havec=58,d=-130-10000,y=wpτ1τ2,A=00-1,D=11100.30.5011.5100,b(z̃)=z̃1z̃2z̃3,ℓ=-21-81,h=25101,where τ1, τ2 are slack variables,z̃3≡0, andz̃1,z̃2are random variables withP(z̃1=21)=P(z̃1=25)=P(z̃2=8)=P(z̃2=10)=0.5,E(z̃1)=23,E(z̃2)=9,E(z̃3)=0,Ez̃32=0.We haveEz̃12=533,Ez̃22=82, andA0=A=00-1,A1=A2=A3=000,b0=000,b1=100,b2=010,b3=001.Note that here we introduce an additional random variablez̃3(≡0)defined on a symmetric support [−1,1], which is due to our theoretical assumption on the full dimensionality of Ω, i.e., −ℓ<h.Based on the previous discussion, we solve the corresponding SOCP:minx,v0,v,V,u,Y,s,t,λ,ν58x+v0+23v1+9v2+533V1+82V2s.t.∑i=13ui-130y10-100y20+25λ1+10λ2+λ3-21ν1-8ν2+ν3-v0⩽0,v1+130y11+100y21+λ1-ν1V1-u1⩽V1+u1,v2+130y12+100y22+λ2-ν2V2-u2⩽V2+u2,v3+130y13+100y23+λ3-ν3V3-u3⩽V3+u3,y10+y20+y30=0,0.3y10+0.5y20+y40=0,-x+1.5y10+y20=0,y11+y21+y3=1,0.3y11+0.5y21+y41=0,1.5y11+y21=0,y12+y22+y32=0,0.3y12+0.5y22+y42=1,1.5y12+y22=0,y13+y23+y33=0,.3y13+.5y23+y43=0,1.5y13+y23=1,-21s11-8s21+s31+25t11+10t21+t31-y10⩽0,-21s12-8s22+s32+25t12+10t22+t32-y20⩽0,-21s13-8s23+s33+25t13+10t23+t33-y30⩽0,-21s14-8s24+s34+25t14+10t24+t34-y40⩽0,s11-t11-y11⩽0,s21-t21-y12⩽0,s31-t31-y13⩽0,s12-t12-y21⩽0,s22-t22-y22⩽0,s32-t32-y23⩽0,s13-t13-y31⩽0,s23-t23-y32⩽0,s33-t33-y33⩽0,s14-t14-y41⩽0,s24-t24-y42⩽0,s34-t34-y43⩽0,x⩾0,V,u,λ,ν⩾0,sk,tk⩾0,k=1,2,3,4.We derive the numerical results as follows. x=30,500 (lbs) with the corresponding worst-case expected profit of $929.88, andy0=34.1667-20.7500-13.41670.1250,y1=-0.72221.08330.6389-0.3250,y2=0001,y3=2-200.4.Using the LDR and the solutions of y0, y1, y2, y3 above, we derive the production plan, w and p, of the second-stage problem as below.w=y10+∑i=13y1izi;p=y20+∑i=13y2izi,where zirepresents the realization ofz̃i.Remark 3Comparing numerical results obtained from the above two formulations, we can see that the solution (x∗=31,500) of the classical two-stage model with complete information is less conservative than that of (x∗=30,500) the model with incomplete information under LDR. It shows that, although the robust formulation of the problem is conceptually “more conservative” (in terms of minimizing the worst case cost rather than the expected cost), its solution may not be drastically different from the case where the full information on distribution of the random variable is available.It appears that the SOC problem would have more variables and constraints than the two-stage stochastic programming formulation using the sampling approach. We should admit that for the case of the sample size or number of random variables being very small, the scale of the classical formulation would be smaller than the proposed SOCP reformulation. The classical sampling program turns to be a small-size linear programming problem while the latter becomes to problem with linear objective and quadratic constraints. However, such small-size problems are not our motivation to introduce robust optimization approach in this study.To see the effect of scenario number and the dimension of random vectorz̃to computational efficiency, we consider a general case of Example 1. Letmˆdenote the number of random variables of the example and S number of possible values of each random variable (for simplicity, assume every random variable is discrete with the same S). Letnˆbe the number of decision variables for the second-stage problem. Following the format of two-stage stochastic programming stated in Section 2, it follows thatn=1,m=mˆ+1,k=mˆ+nˆ, andl=mˆ+1. The scales of the resulting problem associated with the classical formulation and SOCP reformulation are listed in Table 1. Here, we do not include the nonnegativity constraints in the table.Evidently, the scale of classical formulation increases exponentially while the size of SOC problems increases relatively much slowly (at most quadratically). In fact, the scale of the latter only depends on the structure of primary second-stage stochastic programming problem under consideration, such as the number of second-stage decision variables and the dimension of the random vectorz̃.In this subsection, for the two random variables of molding hourz̃1and assembling hourz̃2in Example 1 (unit: 1000 (hours)), we assume each random variable is of 1000 possible values. In computation, such 1000 possible values are chosen in the following way. For molding hour, we randomly choose 500 values from the interval [20.5, 21.5] and 500 values from [24.5, 25.5] such that the sample mean equals to 23. Similarly, we generate 1000 possible values for assembling hour from the intervals [7.5, 8.5] and [9.5,10.5] such thatE[z̃2]=9.Note that, in this case,nˆ=2,mˆ=2, and S=1000. According to Table 1, the classical approach results in a problem of about 2 million decision variables and 3 million constraints. In general, this large-size problem is impossible to solve on current computers. However, the SOCP reformulation is of 57 decision variables with 32 constraints only, which can be solved efficiently using available software packages such as CPLEX, MOSEK, and SeDuMi.For SOCP reformulation, using the randomly selected samples and with similar arguments as above, we derive the second moments of random variables as follows.Ez̃12=531,Ez̃22=81. As before, we setE[z̃3]=0andEz̃32=0. The vectors concerning lower and upper bounds ofz̃,-ℓand h, are given by −ℓ=(20.5,7.5,−1)′ and h=(25.5,10.5,1)′, respectively. The values of other parameters are same as stated in Section 3.1.2. We then derive the solutions as follows. x=29,750 (lbs) with the corresponding worst-case expected profit of $900.618, andy0=27.1556-10.9833-16.1722-2.6550,y1=-0.42220.63330.7889-0.1900,y2=0001,y3=2-200.4.In this subsection, we assume there are 10 procedures in producing wrenches and pliers of Example 1. For each procedure, the corresponding processing hour is assumed to be a random variable denoted byz̃i, each having 4 possible values, i=1,…,10. In this setting, we havenˆ=2,S=4,mˆ=10. According to the previous discussion, the classical formulation is of over 2 million decision variables with more than 11 million constraints. However, for the SOCP reformulation, it has only 465 decision variables with 288 constraints, which has been solved at a laptop computer in seconds.In this example, the price of steel, the contributions to earnings of wrench and plier, and the steel constraint remain the same as Example 1. In what follows, we set the four possible values (unit: 1000 (hours)) of processing hour of each procedure under consideration, each realization having the equal probability 25%.P(z1=21)=P(z1=21.5)=P(z1=22)=P(z1=22.5)=0.25,P(z2=20)=P(z2=20.5)=P(z2=20.8)=P(z2=21.7)=0.25,P(z3=18)=P(z3=18.5)=P(z3=19)=P(z3=20.2)=0.25,P(z4=17)=P(z4=17.4)=P(z4=18.2)=P(z4=18.9)=0.25,P(z5=15)=P(z5=15.5)=P(z5=16)=P(z5=16.5)=0.25,P(z6=12)=P(z6=12.5)=P(z6=13.5)=P(z6=14.5)=0.25,P(z7=11)=P(z7=11.5)=P(z7=11.7)=P(z7=12.3)=0.25,P(z8=9.5)=P(z8=10)=P(z8=10.5)=P(z8=11.4)=0.25,P(z9=8)=P(z9=8.5)=P(z9=8.9)=P(z9=9.2)=0.25,P(z10=7.5)=P(z10=7.8)=P(z10=8.6)=P(z10=8.95)=0.25.For procedure i, denote by βithe coefficient vector of the constraint for producing wrenches and pliers, i=1,…,10. Then, we have [w,p]βi⩽zifor each realization ziof random variablez̃i. Here, βis are chosen as follows.β1=11,β2=0.90.7,β3=0.80.7,β4=0.60.8,β5=0.40.9,β6=0.80.5,β7=0.50.3,β8=0.40.6,β9=0.20.9,β10=0.30.5.According to the above samples of random variables, we derive the lower and upper bounds of the underlying random vectorz̃=(z̃1,…,z̃10,z̃11)′wherez̃11≡0. That is, −ℓ=(21,20,18,17,15,12,11,9.5,8,7.5,−1)′ and h=(25.5,21.7,20.2,18.9,16.5,14.5,12.3,11.4,9.2,8.95,1)′.In the SOCP reformulation, the vectors of the first and second moments, i.e., μ and η, are estimated based on the above samples. We then have μ=(21.75,20.75,18.925,17.875,15.75,13.125,11.625,10.35,8.65,8.213,0)′ and η=(473.375,430.945,358.823,320.053,248.375,173.188,135.358,107.615,75.025,67.788,0)′.By calling CPLEX solver cplexqcp in Matlab, we derive the solutions as follows. x=21,903.2 (lbs) with the worst-case expected profit of $727.537, andy0=17.1417-3.8093-13.3324-12.7610-11.0468-7.2376-3.4283-11.8087-7.4281-4.57110-3.2379,y1=001000000000,y2=000100000000,y3=000010000000,y4=000001000000,y5=000000100000,y6=000000010000,y7=000000001000,y8=000000000100,y9=-0.86961.3043-0.4348-0.1304-0.2174-0.5217-0.82610.04350.0435-0.43480-0.3913,y10=000000000001,y11=0.7826-0.1739-0.6087-0.5826-0.5043-0.3304-0.1565-0.5391-0.3391-0.20870-0.1478.As we mentioned before, the production plan, w and p, of the second-stage problem can be generated based on the solutions of y0, y1,…,y11 and the realization z ofz̃as follows.w=y10+∑i=111y1izi,p=y20+∑i=111y2izi.

@&#CONCLUSIONS@&#
