@&#MAIN-TITLE@&#
BIG-OH: BInarization of gradient orientation histograms

@&#HIGHLIGHTS@&#
BIG-OH, binary quantization of gradient orientation based descriptors, is proposed.Quantized SIFT descriptors reduce memory by 88% compared to classical SIFT.BIG-OH has performance comparable to SIFT and GLOH.BIG-OH has better performance than BRISK, CARD, BRIEF, and other descriptors.BIG-OH is effective for large scale applications such as copy detection.

@&#KEYPHRASES@&#
Gradient orientation histograms,SIFT,Gradient based keypoint descriptors,Keypoint descriptor quantization,

@&#ABSTRACT@&#
Extracting local keypoints and keypoint descriptions from images is a primary step for many computer vision and image retrieval applications. In the literature, many researchers have proposed methods for representing local texture around keypoints with varying levels of robustness to photometric and geometric transformations. Gradient-based descriptors such as the Scale Invariant Feature Transform (SIFT) are among the most consistent and robust descriptors. The SIFT descriptor, a 128-element vector consisting of multiple gradient histograms computed from local image patches around a keypoint, is widely considered as the gold standard keypoint descriptor. However, SIFT descriptors require at least 128bytes of storage per descriptor. Since images are typically described by thousands of keypoints, it may require more space to store the SIFT descriptors for an image than the original image itself. This may be prohibitive in extremely large-scale applications and applications on memory-constrained devices such as tablets and smartphones. In this paper, with the goal of reducing the memory requirements of keypoint descriptors such as SIFT, without affecting their performance, we propose BIG-OH, a simple yet extremely effective method for binary quantization of any descriptor based on gradient orientation histograms. BIG-OH's memory requirements are very small—when it uses SIFT's default parameters for the construction of the gradient orientation histograms, it only requires 16bytes per descriptor. BIG-OH quantizes gradient orientation histograms by computing a bit vector representing the relative magnitudes of local gradients associated with neighboring orientation bins. In a series of experiments on keypoint matching with different types of keypoint detectors under various photometric and geometric transformations, we find that the quantized descriptor has performance comparable to or better than other descriptors, including BRISK, CARD, BRIEF, D-BRIEF, SQ, and PCA-SIFT. Our experiments also show that BIG-OH is extremely effective for image retrieval, with modestly better performance than SIFT. BIG-OH's drastic reduction in memory requirements, obtained while preserving or improving the image matching and image retrieval performance of SIFT, makes it an excellent descriptor for large image databases and applications running on memory-constrained devices.

@&#INTRODUCTION@&#
The problem of finding images that are partly or wholly similar to a query image in a large gallery has long been a central concern of image processing and computer vision researchers. Some of the important applications are image retrieval, video indexing, texture recognition, image classification, and object recognition. Many of the most successful approaches to these search problems first pinpoint repeatable keypoint locations, compute a descriptor vector measuring properties of the local image patch around each keypoint, then match keypoints using a similarity measure over pairs of keypoint descriptors. Some of the most successful algorithms for keypoint detection and description include SIFT [1], SURF [2], and ORB [3].The SIFT descriptor is considered by many to be the gold standard for keypoint descriptors. It is quite resistant to image transformations [4,5] and has been used in many applications including image classification [6], image/video copy detection [7], object recognition [1], and image stitching [8].There are two major problems with the use of keypoint descriptor matching for image search problems as we attempt to scale to today's extremely large problems such as video copy detection on the Internet. Both problems stem from the high dimensionality of typical keypoint descriptors such as SIFT. The first problem is storage. A single image might have thousands of keypoints, and storing the set of raw descriptors for a single image could require more storage than the image itself. This would make it difficult for, say, a movie studio to index the frames of its video collection for purposes of illegal copy detection. The second problem is the time required to evaluate the similarity of two descriptors. Similarity computation involving measures such as Euclidean distance isOn, where n is the dimensionality of the descriptor vector. Searching for an image similar to a query image among millions of images is extremely expensive in terms of time and/or money, so reducing the time required for the descriptor distance calculation could substantially decrease the cost of large-scale image search.There are several possible ways to increase descriptor matching speed. The first is to reduce the dimensionality of the descriptor using dimensionality reduction techniques such as principal components analysis (PCA). Ke and Sukthankar [9] propose and evaluate a PCA-based SIFT descriptor (PCA-SIFT). The method is fast for matching, due to the reduced dimensionality, and it is also effective for image retrieval. However, PCA does not necessarily provide a discriminative representation for recognition, since it is unsupervised and the basis vectors it produces are global [10]. A second possibility is to use “smart” lower-dimensional descriptors that throw away information unlikely to be useful for robust matching and preserve information that is invariant to image transformations. One example is the 64-element version of the SURF descriptor [2]. A third possibility is to use binary descriptors such as BRIEF [11], BRISK [12], ORB [3], and CARD [13]. Binary descriptors require very little storage, reducing the time required to move large numbers of descriptors through the storage hierarchy. Better storage throughput leads to accelerated matching and search operations. The main limitation of binary descriptors, however, is that they tend not to perform well under image deformations such as changes in viewpoint and scale. A fourth group of approaches, used by many applications, aims to find only approximate nearest neighbors of a query descriptor based on hash codes. Every descriptor is coded and quantized by a hash function that might be randomized or learned from data [14–17]. These methods also generate binary descriptors, but since discriminative projections are learned from data, they can greatly decrease memory and computational costs. A fifth group of approaches, used by many large applications, is based on techniques for vector quantization. A large number of feature vectors are collected, and then a clustering algorithm is applied to map each vector in the feature space to a discrete cluster. The most common approach based on quantization is the bag-of-visual-words (BoVW) model, in which an image is represented by a sparse frequency vector over a set of feature descriptor cluster IDs. The BoVW model is used in many image retrieval, copy detection, and image classification applications [18]. However, both hashing and vector quantization have limitations. For example, they are not intrinsically adaptive, their performance depends strongly on hashcode or codebook size, and the quantization process may in some cases discard information in the raw descriptors that may be useful for discrimination [19]. Another limitation is that the hashcode or codebook learned from one image set may not generalize well to a new image set.Recently, other approaches based on vector quantization have introduced simpler deterministic mappings not requiring training sets. One such alternative approach is scalar quantization [20], in which we specify a fixed equivalence relation over the feature space and code each equivalence class with a bit vector.In this paper, we propose BIG-OH, a new method based on the scalar quantization approach. BIG-OH quantizes high dimensional gradient-based descriptors such as SIFT to a short binary vector. BIG-OH is similar to but more compact and computationally faster than previously proposed scalar quantization methods [20]. We reduce the memory required from SIFT's 128bytes (512bytes if 32-bit floating point numbers are used) to only 16bytes. Since the mapping is fixed, the quantizer does not require off-line visual word learning, which eliminates training time and the issue of adaptiveness to new features.We find that the use of binary signatures accelerates the matching process, speeding up the naive implementation of the distance computation by a factor of 2.4. Since the descriptor space is so small, the matching process can be further accelerated by the use of a very small lookup table as described in Section 4.3.1, yielding a speedup of 10 over the naive Euclidean distance measure for the 128-byte SIFT descriptor.BIG-OH itself is extremely simple yet very effective for practically encountered image transformations. Although one might expect that the large speedups just described would come at the cost of reduced matching accuracy or reduced image retrieval performance, to the contrary, despite the use of radical binary quantization, we find the method to be quite resistant to image transformations such as blurring, illumination, and rotation.The proposed quantized descriptor, BIG-OH, is thus useful for reducing the storage and computational resources required for large scale image-to-image matching applications. We also anticipate its usefulness on mobile devices with limited storage and compute resources such as smartphones and tablets.To demonstrate the performance of the proposed method, we perform an extensive series of experiments. We find that BIG-OH is equally discriminative and robust compared to the state-of-the-art descriptors for feature matching under different photometric and geometric transformations, and we also find, surprisingly, that it modestly outperforms SIFT for image retrieval.In detail, we perform experiments to measure the following performance criteria:•Speedup of descriptor match scoring.Decrease in descriptor storage requirements.Matching results consistent with SIFT.Accurate matching in comparison to state-of-the art algorithms under image transformations such as rotation, viewpoint change, and scale change. This experiment is designed to evaluate the robustness of descriptors under different levels of challenging distortions.Accurate image retrieval under severe image transformations. This experiment is designed to evaluate the distinctiveness of the descriptors.The rest of the paper is organized as follows. In Section 2, we briefly survey related work and state-of-the-art descriptors. In Section 3, we explain the BIG-OH quantization method. In Section 4, we describe our experimental methods and results. Finally, we conclude in Section 5.

@&#CONCLUSIONS@&#
