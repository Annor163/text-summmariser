@&#MAIN-TITLE@&#
Dynamic time warping in phoneme modeling for fast pronunciation error detection

@&#HIGHLIGHTS@&#
A low-complexity phoneme modeling method based on Dynamic Time Warping is proposed.Four variants of fast mispronunciation detection method based on DTW are presented.The proposed method works on a small speech corpus with no additional linguistic data.The method proves to be faster and more efficient than methods of higher complexity.

@&#KEYPHRASES@&#
Pronunciation error detection,CAPT systems,DTW algorithm,Phoneme modeling,Word structure analysis,

@&#ABSTRACT@&#
The presented paper describes a novel approach to the detection of pronunciation errors. It makes use of the modeling of well-pronounced and mispronounced phonemes by means of the Dynamic Time Warping (DTW) algorithm. Four approaches that make use of the DTW phoneme modeling were developed to detect pronunciation errors: Variations of the Word Structure (VoWS), Normalized Phoneme Distances Thresholding (NPDT), Furthest Segment Search (FSS) and Normalized Furthest Segment Search (NFSS). The performance evaluation of each module was carried out using a speech database of correctly and incorrectly pronounced words in the Polish language, with up to 10 patterns of every trained word from a set of 12 words having different phonetic structures. The performance of DTW modeling was compared to Hidden Markov Models (HMM) that were used for the same four approaches (VoWS, NPDT, FSS, NFSS). The average error rate (AER) was the lowest for DTW with NPDT (AER=0.287) and scored better than HMM with FSS (AER=0.473), which was the best result for HMM. The DTW modeling was faster than HMM for all four approaches. This technique can be used for computer-assisted pronunciation training systems that can work with a relatively small training speech corpus (less than 20 patterns per word) to support speech therapy at home.

@&#INTRODUCTION@&#
The problem of automatic pronunciation error detection has been recently subjected to intensive research studies involving speech analysis. The need to design methods which are able to assess the phonetic correctness of spoken words came from an idea of creating a Computer-Assisted Pronunciation Training (CAPT) system [1–3] for people having articulation problems, mostly non–native speakers and people struggling with speech dysfunctions, e.g. lisp.Nowadays, computer systems are widely used both in education and speech therapy. The applications designed for logopeadic purposes may supplement the therapy at home, as they usually provide extensive exercise material with the multimedia stimulus. However, only CAPT systems have the possibility of indicating the patients׳ articulation errors. For this reason, for some people (especially children and people with additional mental retardation) the home-based speech rehabilitation will inevitably require the constant presence of a caregiver who will catch the errors early enough. Preparing a tool that will grant the patient more independence – for example an application capable of providing correction and approval – could improve the quality of life of people with speech disorders.Logopeadic CAPT system could work as follows. During a visit a speech therapist will show the patient which set of words they should practice. Then, at home, the program will ask the patient to repeat words from the previously selected list. The system will indicate mistakenly spoken word fragments and suggest which phonemes need training. As a result, the patient will be able to correct the spoken word. During a next visit the speech therapist will be able to assess whether the home work delivered the desired results. Then they may select a different set of words and, if needed, supplement the database with recordings of additional words and expressions. The computer system works as a therapy tool, and the therapist׳s knowledge is still inevitable, but the time between the visits can be used more efficiently.Advantages of CAPT for logopeadic purposes are undeniable. Speech improvement requires many repetitions. The possibility of working at home at the patient׳s own pace, independently of the presence of a therapist and the reduction of stress caused by practising in front of a group of other people are the main reasons for creating such systems [1]. Well-developed computer software, extended with a subsystem able to evaluate pronunciation, could be an extremely useful tool in speech therapy.Pronunciation error detection methods are being developed all over the world and cover mostly segmental errors, which are related to inappropriate realization of individual phonemes or diphones [4–7]. A vast majority of the conducted research concern the Asian tonal languages. Studies include Mandarin Chinese [4,2,3,8], Taiwanese [7,6] and others. There are slightly fewer works concerning European languages (e.g. [9]). At present, the only well-publicized undertaking associated with Polish in terms of pronunciation error detection is the EURONOUNCE project [1,10–12].Most of the conducted experiments are concentrated on a small number of selected systematic errors – the most common mispronunciations. Limitations imposed on the search range make the classification simpler and they increase the detection efficiency of these errors. In [4], the 8 most common pronunciation mistakes committed by the Japanese people speaking Chinese have been evaluated. Xu et al. [6] present an example of a base of error patterns (EP) where the models of the most problematic phonemes have been enriched with additional phonological information. Another example of the detection method using supplementary linguistic knowledge is the Phonological Modeling of Mispronunciation Gradations (PMMG) described in [13]. The phonological rules occurring in the mispronunciation of certain words have been modeled in advance and next used to assess the pronunciation quality. In most of the studies, supplementing the speech database with appropriate rules resulting from language characteristics proves to increase the detection efficiency of the systematic errors. Unfortunately, at the same time the detection of any errors from outside the set becomes impossible. Therefore, there is a need to develop more general methods as well.Predefined error detection requires the use of classifiers and pronunciation quality metrics different from robust search algorithms. Goodness of Pronunciation (GOP) [5,4,14,15] or Log-Posterior Probability (LPP) [6] are examples of methods that do not operate on a predefined set of errors; the probabilistic models are calculated for all different phonetic units that are possible to encounter. More complex solutions use the artificial neural networks, e.g. Deep Neural Network (DNN) for modeling [16,8,17] or Multilayer Perceptron (MLP) for deriving additional signal features [18].The LPP modification, Revised Log-Posterior Probability (RLPP) [6], is used for error detection within a previously created set. LPP calculates the probability of correctness of the segment in the context of all phoneme models in the database, while RLPP considers only phonemes identified as the most problematic. Other methods of detection of the systematic errors are Likelihood Ratio (LR) [4,19,20] or Weigelt׳s algorithm [5].CAPT approaches often involve the algorithms based on Hidden Markov Models (HMM) [4,21,19,13,8,22] or similar probabilistic models. HMM, widely used in automatic speech recognition systems, prove to be effective also in speech modeling units shorter than sentences or words. Most commonly used signal features are the Mel-Frequency Cepstral Coefficients (MFCC) [23,21,24,20,16,19,25,17]. Other popular parameters are MFCC׳s first and second-order time derivatives (Delta and Delta–Delta MFCC) [16,19,25] and Perceptual Analysis Prediction (PLP) [18]. However, many mispronunciation detection studies focus on testing and development of new feature types [22,18,26].Another issue worth discussing in the context of pronunciation error detection is the size of a phonetic segment which is chosen as an analysis unit. There can be found examples of studies that operate on individual phonemes [6], diphones [27], triphones [28–30] or even syllables [31]. Every segment of an analyzed word can be classified as correctly or incorrectly pronounced. It is worth noting that using shorter units may allow errors to be identified more precisely. In addition, the number of phonemes in a specific language is respectively smaller than the number of their combinations forming diphones, triphones or syllables. In the study presented in [32] 14917 different Polish triphones have been annotated based on the speech corpus, while there are only 39 phonemes in the Polish language. Therefore, in order to carry out the detection based on triphones in Polish, almost 15,000 models of correct triphones need to be generated. In this case the analytical complexity becomes significantly higher than that for individual phonemes.Pronunciation error detection is still a fairly new topic. Even in 2002, the concept of an effective CAPT system was questioned [33]. A few years later, reports began to confirm the effectiveness of the conducted works [34,20,35,36]. However, the results are still not in general use and the studies include only specific languages. Projects addressing pronunciation correction in Polish, especially for speech therapy patients, are very rare. All these factors encourage researchers to carry out studies on the pronunciation error detection methods for the Polish language.The main problem of the currently developed pronunciation error detection methods is that they require a large amount of speech data as a training set. The problem has been effected by using statistical tools, such as HMM, which cannot work properly on a small speech corpus. As a result, the existing methods can hardly be used in CAPT software for domestic use by a patient. Furnishing these systems with speech databases containing more than several patterns for every element of training material requires a lot of storage space and effort to organize speech data. Moreover, error detection based on a relatively small number of patterns would allow teachers or therapists to supplement the database with additional words or word constructions, according to their needs.The aim of this study is to develop a fast mispronunciation detection algorithm which will work with a relatively small training corpus. With these two assumptions at the forefront, we are going to focus the study on finding methods which are ready to be used in practice, particularly in CAPT systems dedicated to speech therapy patients.Our main contribution is (1) the extension of a novel approach to pronunciation error detection based on the Dynamic Time Warping (DTW) algorithm, the basic version of which was described in our previous work [37]; (2) comparative studies of the proposed modeling method and popular HMM involving the mispronunciation detection within a speech corpus reflecting the most popular articulation disorders in the Polish language. According to the authors׳ knowledge, DTW [38,39] has not been suggested for use in the mispronunciation detection so far. However, this type of modeling turns out to be faster and more efficient than very common HMM if used for a small training corpus. This paper presents several variants of the pronunciation error detection method using DTW together with the results of comparative tests which have been carried out. Specific improvements made in comparison to [37] include two additional classification variants, extended speech corpus corresponding to two most popular segmental speech disorders, the iterative DTW modelling procedure and the use of the Sakoe–Chiba Band to optimize the DTW modelling. All these changes have been introduced to improve the efficiency of the algorithm and to turn the experiments towards the speech therapy case study.The paper is organized as follows. Speech corpus, which has been specially recorded for this work, and the created pronunciation error detection methods are described in Section 2. Section 3 provides a presentation of the performance measures that have been used, designed experiments and the evaluation of the obtained results. The conclusions are discussed in Section 4.For the purpose of this study a speech corpus has been designed and recorded. Speech databases are usually very expensive, as time and effort necessary to develop them generate high costs. In addition, the specifics of our project require a speech corpus that contains recordings of mispronounced words. However, none of the Polish databases satisfies this condition. Therefore, the collection of the recordings was inevitable.One of the objectives of the presented work is to propose a method operating on the Polish language and articulation problems characteristic for its phonological system. It was taken into account during the dictionary designing stage and database recording. We decided to focus on segmental errors – problems at the level of the sound forms of individual phonemes.The recorded words come from a fixed set of 12 words of different phonetic structure (Table 1). The set was consulted with a speech therapist. The selected words contain the phone ‘r’ or Polish dental phones (ś, ź, ć, dź; s, z, c, dz; sz, ż, cz, dż) to reflect the most common segmental pronunciation problems of native and non-native speakers of the Polish language.The transcription of the dictionary is presented according to the extended SAMPA standard (Speech Assessment Methods Phonetic Alphabet) [40–42].Speech databases for testing the error detection should include the recordings of people actually committing errors, e.g. speech therapy patients. However, speech corpora constructed for the purpose of testing new methods of analysis often contain recordings of speakers with correct pronunciation who intentionally mispronounced words (e.g. substituted problematic phoneme with a different one) [4,43]. This is because the effort needed to collect the recordings of real patients is very big. They are almost always in minority as compared to the group with correct pronunciation. The time needed to gather such a group and to carry out the recordings is therefore longer, and compiling the speech database is more time-consuming. Databases of artificially mispronounced recordings can be treated as a good model, especially in cases where error detection is not limited to a predefined set. A detection method seeking general abnormalities in pronunciation should cope well with the errors which are either natural or artificially introduced.In the presented study similar assumptions were made. The data collected during the first phase contained the recordings of the full dictionary of 12 words pronounced correctly by 60 people. Next, 10 most precisely pronounced utterances of each word were drawn from that corpus to create the training set containing 120 recordings. An independent group of 30 speakers were asked to pronounce the same word set, saying the words improperly (introducing mispronunciations). 15 occurrences of each of the 12 words were randomly chosen from this data in order to create the test set. In total, there were 120 utterances in the training set and 180 utterances in the test set. The introduced mispronunciations were meant to reflect typical errors committed by speech therapy patients, e.g. [Z] replaced by [z] or [z′], [S] replaced by [s] or [s′], [r] replaced by [l] or [j]. However, different pronunciation errors were permitted as well in order to simulate a speech problems variation.The registration was conducted during several sessions in a room with low noise and reverberation. The material was recorded at the sampling rate of 44.1kHz and the resolution 16 bit.Each recording was divided into phoneme segments manually, using a specially created software. The recordings were organized in a database that was subsequently annotated with substitution, deletion and insertion errors, which was necessary for further evaluation of the proposed error detection method. At the same time silence removal at the beginning and at the end of the recordings was carried out. The example of the segmentation of a correctly spoken word is presented in Fig. 1.

@&#CONCLUSIONS@&#
