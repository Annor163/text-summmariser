@&#MAIN-TITLE@&#
Benchmarking human epithelial type 2 interphase cells classification methods on a very large dataset

@&#HIGHLIGHTS@&#
Benchmarking of 14 HEp-2 cell images classification methods on a very large dataset.Six HEp-2 staining patterns considered: four common patterns plus two challenging rare patterns.Best methods use features extracted from local statistics of an image.SVM is the most effective classifier for this problem.

@&#KEYPHRASES@&#
Large-scale benchmarking,Computer-aided diagnosis systems,Indirect immunofluorescence,Hep-2 cell classification,

@&#ABSTRACT@&#
ObjectiveThis paper presents benchmarking results of human epithelial type 2 (HEp-2) interphase cell image classification methods on a very large dataset. The indirect immunofluorescence method applied on HEp-2 cells has been the gold standard to identify connective tissue diseases such as systemic lupus erythematosus and Sjögren's syndrome. However, the method suffers from numerous issues such as being subjective, time consuming and labor intensive. This has been the main motivation for the development of various computer-aided diagnosis systems whose main task is to automatically classify a given cell image into one of the predefined classes.Methods and materialThe benchmarking was performed in the form of an international competition held in conjunction with the International Conference of Image Processing in 2013: fourteen teams, composed of practitioners and researchers in this area, took part in the initiative. The system developed by each team was trained and tested on a very large HEp-2 cell dataset comprising over 68,000 images of HEp-2 cell. The dataset contains cells with six different staining patterns and two levels of fluorescence intensity. For each method we provide a brief description highlighting the design choices and an in-depth analysis on the benchmarking results.ResultsThe staining pattern recognition accuracy attained by the methods varies between 47.91% and slightly above 83.65%. However, the difference between the top performing method and the seventh ranked method is only 5%. In the paper, we also study the performance achieved by fusing the best methods, finding that a recognition rate of 85.60% is reached when the top seven methods are employed.ConclusionsWe found that highest performance is obtained when using a strong classifier (typically a kernelised support vector machine) in conjunction with features extracted from local statistics. Furthermore, the misclassification profiles of the different methods highlight that some staining patterns are intrinsically more difficult to recognize. We also noted that performance is strongly affected by the fluorescence intensity level. Thus, low accuracy is to be expected when analyzing low contrasted images.

@&#INTRODUCTION@&#
Recently there has been a growing interest in introducing automated pattern classification systems for microscopy images [1–5]. The results from these systems may offer a more objective classification which would improve result consistency and resolve any discrepancies in the subjective analyses.The anti-nuclear antibodies (ANA) test is commonly used to diagnose connective tissue diseases (CTD) such as systemic lupus erythematosus (SLE) and Sjögren's Syndrome [6]. The gold standard for performing this test is the indirect immunofluorescence (IIF) protocol using human epithelial type 2 (HEp-2) cells [6,7] due to the expression of a wide range of antigens on HEp-2 cells. Nevertheless, the protocol is time and labor intensive [8,9]. In addition, there is high intra- and inter-laboratory variation of the test [8,10,11].One way to address these issues is by applying computer-aided diagnosis systems. These provide a more objective analysis which could be incorporated into the overall test results. In recent years, we have seen significantly growing interest in developing such systems [2,10–20]. Nevertheless, the use of private datasets with non-standard evaluation protocols makes it difficult to draw meaningful conclusions from the existing works. Therefore, it is critical to develop a standard evaluation platform in order to advance the domain [2]. One notable example is the first contest initiative held in conjunction with the International Conference on Pattern Recognition (ICPR) 2012, here denoted ICPR2012Contest [2], which is then followed by publications of a Pattern Recognition journal special issue on the same theme [21].Despite the merit of being the first initiative in this research area and the attention received from the scientific community, there were some shortcomings in the benchmarking platform introduced through the ICPR2012Contest. Among such issues, the most relevant were:•Small size of the dataset: the dataset provided in ICPR2012Contest has six classes: centromere, coarse speckled, cytoplasmic, fine speckled, homogeneous and nucleolar. It has a total of 1457 cell images extracted from 28 specimen images. It is assumed that each specimen image comes from a unique patient serum and a specimen image contains a distribution of HEp-2 cells. The specimen images are equally divided for training and testing. Although at first glance the number of cell images may appear significant, larger numbers of images are required to draw more meaningful conclusions [2]. In fact, the overall analysis is mainly affected by the number of specimen images, as the cell images from the same specimen are similar. More specifically, the classes in both training and test sets only have two or three specimen images, thus, the evaluation protocol is limited to the variation generated from two specimen images. This also renders a biased view during the cross validation training process which may have misled participants in designing their systems.Focusing only on common patterns: whilst in general there are four ANA patterns commonly found in day-to-day operation – homogeneous, speckled, centromere and nucleolar – correctness in identifying less common patterns is equally significant as they may have clinical significance. Unfortunately, the ICPR2012Contest dataset did not include these less common patterns.In the present work, we address the above two issues by constructing a very large dataset consisting of 68,429 cell images extracted from 419 patient sera. In particular, there are now six classes: homogeneous, speckled, centromere, nucleolar, nuclear membrane and Golgi. Nuclear membrane and Golgi patterns are less common than the other four patterns. This not only offers a more realistic evaluation protocol, but also, more flexibility for doing cross validation. These factors allow the present work to offer a more realistic benchmarking of systems in this domain.We note that, unlike ICPR2012Contest that considers the cytoplasmic pattern, we exclude the cytoplasmic pattern from our current benchmarking platform as it is not considered an ANA pattern [7]. In addition, our benchmarking platform also does not differentiate between the fine and coarse speckled classes for two reasons. Firstly, the speckled pattern subdivision is generally more complex than simply dividing it into fine and coarse speckled groups. In general, the subdivision is done by relating each individual sub-group with specific antibodies [7]. For instance, fine speckled could be further divided into several sub-groups with distinct characteristics such as fine speckled patterns caused by SSA(Ro)/SSB(La) and DFS-70 [22]. Secondly, given the above fact, a better analysis would be to consider the fine-grained classification scheme [23,24] on the sub-groups of the speckled patterns once a specimen is identified as speckled.Our benchmarking platform is not aimed to evaluate the performance of CAD systems in the fine-grained speckled classification problem. Thus, using only one speckled class gives us an advantage to avoid confusion in analyzing the evaluation results (e.g. whether the classification mistakes are due to the inability of a method in addressing the fine-grained speckled classification problem or the general ANA HEp-2 cell classification problem).Finally, it is worth to highlight that the benchmarking platform presented here refers to the classification of the HEp-2 cells in the interphase, as the ICPR2012Contest, and does not consider the issue of the recognition of the cells in the mitotic stage.The paper is organized as follows: Section 2 provides a brief description on methods to perform the ANA test; in Section 3, we describe our dataset that has been used for the benchmarking; in Section 4, we first define formally the pattern recognition task that was proposed to the participants in the initiative and then provide a short summary of each method. The results and analysis of the benchmarking work are presented in Section 5. Finally, we draw conclusions and delineate future work in Section 6.The ANA test is used for screening a wide range of CTDs [6,7]. Methods to detect ANA include indirect immunofluorescence using HEp-2 cells, enzyme immunosorbent assay (EIA)/enzyme-linked immunosorbent assay (ELISA), farr assay, multiplex immunoassay (MIA) and western blot [25].Amongst these methods, the IIF using HEp-2 cell method is considered the gold standard as the method has high sensitivity due to the expression of wide range of antigens on HEp-2 cells [6]. Generally, other techniques are used as secondary/confirmatory tests. For instance, EIA/ELISA are specifically designed to target single autoantigens (e.g. dsDNA and SSA-A/Ro). The Farr assay is a radio-labeled assay for quantifying anti-dsDNA [25]. In western blot, antigens are separated according to their molecular weight and then transferred onto strips or a membrane [25]. The strips are then incubated with the patient serum. Positive reactions are compared to a positive control strip. For MIA, serum is incubated with a suspension of multi-colored polystyrene micro-spheres coated with a range of antigens. The binding, determining the test result, is then quantified using a specific instrument platform.For the IIF method, the slides are examined under a fluorescent microscope by two scientists. The analysis starts by determining the specimen positivity from the observed fluorescent signal. The guidelines established by the Center of Disease Control and Prevention, Atlanta, Georgia (CDC) suggest the use of a scoring system ranging from 0 to 4+ wherein 0 represents negative (no fluorescent signal observed), and 4+ represents the strongest positive (very bright fluorescent signal observed) [26]. As this process is subjective, it is possible to reduce the scoring system into merely determining whether the fluorescence intensity level of the sample is positive, intermediate or negative [12]. Positive ANA patterns are then titred by serial dilution to obtained a more objective fluorescence intensity level [26]. Finally, the last step in the analysis is to determine the visual pattern appearing in the positive and intermediate specimens.Generally, scientists consider at least three visual cues when examining positive and intermediate specimens: (1) at least one or two mitotic cells can be found in the specimen [26]; (2) the visual features of the mitotic cells and (3) the visual features of the interphase cells.Unlike the interphase cells, the amount of cell chromatin in mitotic cells is doubled. The cells undergoing the mitosis stage may express different antigens or antigens in different concentrations to those in the interphase stage [27,28]. Thus, in some cases, scientists need to consider the mitotic cell visual cues before correctly identifying an ANA pattern. For instance, the mitotic spindle pattern, where the mitotic spindle is positively stained, can only be observed in mitotic cells.While it is important to study the automated mitotic pattern classification which is shown in a number of recent works [29,20], in this work, we primarily focus on the interphase cell classification problems. Addressing the interphase cell classification problems is one of the early steps to develop a CAD system for the ANA IIF HEp-2 test.The dataset was obtained between 2011 and 2013 at Sullivan Nicolaides Pathology laboratory, Australia.11We name this dataset as ICIP2013 dataset as the benchmarking campaign was held at the International Conference on Image Processing 2013 (ICIP2013).The dataset contains the following six classes [7] (see Fig. 1for examples):•homogeneous: a uniform diffuse fluorescence covering the entire nucleoplasm sometimes accentuated in the nuclear periphery;speckled: this pattern is generally divided into two groups22In this dataset, we consider these two sub-categories as one category, while in the ICPR2012Contest they were kept distinct.:–coarse speckled: densely distributed, variously sized speckles, generally associated with larger speckles, throughout the nucleoplasm of interphase cells; nucleoli are negative;fine speckled: fine speckled staining in a uniform distribution, sometimes very dense so that an almost homogeneous pattern is attained; nucleoli may be positive or negative;nucleolar: brightly clustered large granules corresponding to decoration of the fibrillar centers of the nucleoli as well as the coiled bodies;centromere: rather uniform discrete speckles located throughout the entire nucleus;Golgi: staining of a polar organelle adjacent to and partially surrounding the nucleus, composed of irregular large granules. Nuclei and nucleoli are negative. Diffuse staining of the cytoplasm of dividing cells sometimes with accentuation around chromosomal material;nuclear membrane: a smooth homogeneous ring-like fluorescence of the nuclear membrane in interphase cells.The dataset33The dataset is available to interested researchers and practitioners by issuing a request at http://mivia.unisa.it/datasets/icip2013-hep2-dataset/ (Accessed: May 15, 2015)utilizes 419 unique positive sera extracted from 419 different patients randomly selected which were prepared on 18-well slides of HEP-2000 IIF assay from Immuno Concepts N.A. Ltd. using a screening dilution 1:80. As per the manufacturer's description, the assay contains at least one or two mitotic cells. In our dataset, each image is guaranteed to have at least one or two mitotic cells. The specimens, one for each patient serum, were then automatically photographed using a monochrome high dynamic range cooled microscopy camera which was fitted on a microscope with a plan-Apochromat 20×/0.8 objective lens and an LED illumination source. Approximately 100–200 cell images were extracted from each patient serum. In total there were 68,429 cell images extracted. We divided these into 13,596 images for training and 54,833 for testing. The division was deliberately made so that the test set only contained cells from patients who were not included in the training set. Specifically, the training set contains the specimen images from 83 patients, while the images from remaining 336 patients were reserved for the test set. The adopted subdivision between train and test set is motivated by the fact that it represents a good trade-off between on one side the need of having a large train set (its size is one order of magnitude larger than the size of the whole ICPR2012Contest) and on the other side the opportunity of resembling the real world situation where the field validation of a designed method is done on a set of data that is unknown and much larger than the train set.The labeling process involved microscopic reading by two experienced scientists. A third opinion was sought to adjudicate any discrepancies. We used each specimen label as the truth label of cells extracted from it. Furthermore, the labels were investigated further using secondary tests such as extractable nuclear antigens (ENA), and anti-ds-DNA to confirm specificity of the ANA pattern.Figs. 2 and 3present the number of exemplars for each pattern class in both training and test sets. The more common patterns such as centromere, homogeneous, nucleolar and speckled have a similar number of exemplars. However, the less common patterns such as the nuclear membrane and Golgi have fewer exemplars. In particular, Golgi has significantly fewer exemplars than the other patterns. This depicts a more realistic condition where the system needs to perform reasonably well on both common patterns and significantly less common patterns.We note that the creation of this benchmarking platform is possible due to the recent advancements that sufficiently address several practical problems in the automated acquisition of HEp-2 images which allows us to capture high quality images of a patient specimen in approximately 20s [28]. In particular, the acquisition system uses two channels: (1) the fluorescein-isothiocyanate (FITC) channel that is normally used in ANA tests and (2) the 4′,6-diamidino-2-phenylindole (DAPI) channel that is used in the cell image segmentation. DAPI, which is a fluorescent stain that binds strongly to cell DNA [30], specifically delineates the HEp-2 cell nuclei (i.e.  the area of interest in the ANA test). Therefore, this may be used to perform high precision HEp-2 cell segmentation regardless of the patient pattern exhibited in the FITC channel [28,27] (refer to Fig. 4for some challenging examples where the HEp-2 cell boundary and shape are not clearly defined, but are still successfully segmented in high precision). This approach addresses issues such as misclassifications due to poor segmentation, stemming from imperfections in the manual segmentation process in the previous benchmarking set, ICPR2012Contest.We note that, whilst DAPI is widely known as carcinogen substance, in general, the health risk can be significantly reduced by utilizing automated slide preparation systems that handles the high concentrated DAPI solution. In addition, the DAPI concentration applied on each slide is considered low and will not impose immediate health risk.We now describe the methods which participated in the benchmarking activity held at ICIP 2013. For the sake of brevity, the description is intentionally short so as to focus on the most relevant aspects of each method. However, interested readers may find more details about each individual method in the ICIP 2013 competition report44The report is available at http://nerone.diem.unisa.it/contest-icip-2013/ICIP2013_report.pdf. (Accessed: May 15, 2015)where each participant provides an extended description of their method. In the following, each method is reported using the first three letters of the surname of its first author.Recall that the classification goal for each team was to develop a classifier φ that classifies a set of HEp-2 cell images. Each image is represented by the three-tuple (I, M, δ) [19]: (1) I represents the cell fluorescence image in FITC channel; (2) M is the cell mask which is automatically extracted from the DAPI channel; and (3) δ represents the cell positivity strength which has two values weak/borderline (intermediate) or strong (or simply positive). To avoid confusion, here we use the terms intermediate and weak positive interchangeably. In addition, we refer strong positive samples as simply positive samples.Let Y be a test image, ℓ be its true class label andG={(I,M,δ)1,…(I,M,δ)n}be a given gallery set. The classifier task was to predict the test label,ℓˆ. In other words,φ:Y×G↦ℓˆ, where ideallyℓˆ=ℓ.CHA – The rationale of the method is to selectively exploit texture information from different regions of an image. To this end each cell is divided into six partially overlapped regions which extend from the cell boundary to the inner circle area. In total 18 features are calculated from each region: region brightness, contrast and 16 one-dimensional bispectral invariants [31]. These are successively concatenated to form a vector of 108 features which are used to train a set of classifiers (each HEp-2 cell class has one corresponding classifier). For each pattern class, Adaboost [32] is used to generate a 10-stage binary classifier, combined with a hand-crafted decision tree. In particular, the authors evaluated the performance of each binary classifier and constructed a decision tree that placed them in the order of performance, highest first. If all of the binary classifiers reject a query image, it is then assigned to a default class.HAN – The proposed method uses the distribution of local pixel neighborhoods (denoted micro-texton) with Gaussian mixture model as its histogram encoding method. For the image representation, they compute and concatenate the gradient with respect to the model parameters. The final representation can be considered as a Fisher Vector. A random forest classifier is adopted as the classifier.LAR – In the preprocessing stage each image is augmented with its logarithmic representation [33]. Then, each representation is mapped linearly to [0,1] such that their minimum attains a value of zero and their maximum a value of one. The features are extracted from both representations of each image. For each cell, a feature vector is built consisting of the intensity information, morphological features extracted from the provided mask (including area, eccentricity, major and minor axis length, perimeter), and the “annulus” shape index histogram feature. The latter is the most significant descriptor and consists of weighted histograms of second order image features derived from the local Hessian eigenvalues [34] over a number K of band-shaped regions. Each region is defined by its distance to the center pixel of the image, while the weight for each pixel is assigned based on a Gaussian distribution centered on the radial band. Classification is performed through a multi-class support vector machine (SVM) with radial basis function (RBF) kernel using a one-vs-one scheme.LIU – The proposed method initially normalizes the brightness of the input image. Then, local patches of size 9×9 pixels are extracted on a dense sampling grid. In the training phase, these patches are projected through PCA and a codebook with N codewords is created, as described in [35]. This codebook is used to partition all of the local patches into N groups. Then, discriminative projections are obtained for each group by a partial least square analysis in order to re-project the image patches to low dimensional vectors. According to the bag-of-word (BoW) pipeline, the final image representation is obtained by concatenation of the histograms from different groups. A linear SVM is used for the classification stage.MAR – The proposed approach [36] builds upon the use of square subwindows randomly extracted from the original image with respect to the position, the rotation angle and the size. The subwindows are resized to 16×16 pixels and encoded in normalized red-green-blue (RGB) color space. A very large set of visual features is generated using randomized trees. In particular, an ensemble of 50 trees is built according to [37] and then is used to generate an image-level signature inspired by the bags of visual words [38] or textons [39]. Each terminal node of an individual tree is a real-valued feature corresponding to the number of subwindows that reach the terminal node, divided by the number of subwindows extracted in the image. Each cell image is represented by these sparse and high-dimensional signatures. Finally, a linear SVM, adopting a one vs one multi-class strategy, is used for the final class prediction.NAN – The method is based on the combination of three texture descriptors: the multiscale pyramid local binary pattern (PLBP) [40], which is based on the local binary pattern (LBP) operator applied to each of the l=(0, …, L) levels of the gaussian pyramid built from the original image; the Strandmark's morphological features (STR), which are a reduced version of the features in [41]; and the canonical Haralick features (HAR) defined in [42]. The classification is performed using a multiclass SVM with RBF kernel, according to the one-vs-all approach. The SVMs are trained for each of the three sets of features and the results are combined according to the sum rule.PAI – After a preprocessing phase that includes denoising (median filtering) and normalization (histogram equalization), the proposed approach relies on three different sets of features in addition to the information regarding the image intensity level: (1) region covariance of image statistics, the first and second order derivative in the vertical and horizontal directions, and the magnitude of the gradients; (2) co-occurrence among adjacent linear binary pattern (CoALBP) features, which is the extension of LBP [43]; and (3) STR features [41]. Finally, the classification is carried out using a multi-class boosting algorithm that can adaptively select the most discriminative feature in each boosting iteration and combine these into an effective classifier.POM – In the preprocessing stage the cell image is binarized and resized to a canonical size. The employed features are based on the complete linear binary pattern (CLBP) approach [44]. The CLBP approach is based on the assumption that the local appearance and textural structure can be defined by the histogram of the local sign, magnitude and central pixel defined on a dense grid. The CLBP histograms of the sign magnitude and central pixel combine structural and statistical information, and capture the distribution of the classified structures. Classification is performed using K nearest neighbor (K-NN).PON – The proposed method relies on the characterization of the morphological properties of the stained regions of the HEp-2 cells such as nucleoli, nucleous and chromosomes. The authors suggest two different preprocessing steps depending on the type of the descriptor: (1) the image is thresholded using Otsu binarization; and (2) the image is normalized in the range [0,255]. Twenty-one features belonging to the following logical groups are used which include number of stained regions (also called objects by the authors), object size, holes inside objects, holes intensity depth, foreground/background intensity properties, normalized image intensity properties, object localization and object shape. Final image classification is carried out through a kernel SVM and includes two independently trained classification models, one for the positive level of the image intensity and the other for the intermediate level.SAR – The method first applies histogram equalization on the foreground part of the image. After that, the image is resized to 100×100 pixels. The following features are then extracted: statistical features as average intensity, average contrast, smoothness, skewness, uniformity and entropy [45], invariant moments [45], Haralick features [42], and discrete wavelet frame texture descriptors [46] with three resolution levels. The classification is performed using the maximum probability normal classifier.SHE – As described in [47], each cell image is represented through the combination of two rotationally invariant descriptors based on scale invariant feature transform (SIFT) [48] and co-occurrence LBP [49]. In particular, for the SIFT approach, a large number of SIFT features are clustered to form a dictionary, which is then used for cell representation. For co-occurrence LBP, the uniform pattern LBP operator was applied to two neighboring points for feature extraction. Finally, the two features are fused and input to a multi-class SVM with linear kernel trained with one vs one strategy.STO – In the preprocessing stage, image denoising, normalization and enhancement are performed. For each type of adopted image descriptor a separate feature space with its proper metric is employed. More specifically, the LBP descriptor, the Haralick features, the color structure, the surface descriptor, and the radial cell structure descriptor are used with L1 metric. The author defines a specific distance function for the granulometry descriptor. The final classification is obtained via a custom combination of k−NN searches over the considered feature spaces.THE – The proposed method preprocesses the input image by denoising and normalization. Then, a set of binary images are constructed by thresholding the image using a set of 14 equally spaced threshold values in the range [0,1]. Connected component analysis is performed in each binary image, and the following set of morphological features is applied: number of detected objects, density in binary image and mean objects’ solidity. Objects of size less than 1% of the mean objects’ size detected in each binary image are considered as noise and ignored during the calculation of the above features. Finally, the complexity of the cell's contour is considered and modeled as the difference between the cell's contour and the perimeter of the equivalent circle. The resulting feature vector is normalized to zero mean and unit variance using the training set. The final classification is performed using the k−NN classification rule.THI – The proposed method is based on two different statistical descriptors. The first descriptor is the Fuzzy Size Zone Matrix, a fuzzy version of Gray Level Size Zone Matrix [50]. This matrix is obtained by estimation of a bivariate conditional probability density function of the image pixel values. Features are then derived from this matrix. More precisely, moments of order −2 and 2 are computed from the matrix. The second descriptor is the multi-resolution local binary patterns which is a rotation and gray level invariant descriptor. The feature vector is derived from the histogram of the codes. Classification is performed according to a one-vs-all scheme. In particular, for each class, two classifiers (one per descriptor) are built with Random Forests [51] and the probabilities provided by the model are averaged in order to provide a final probability that the cell under study belongs to the class. The cell is then labeled with the class corresponding to the highest probability.

@&#CONCLUSIONS@&#
