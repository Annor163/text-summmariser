@&#MAIN-TITLE@&#
Multiple learning particle swarm optimization with space transformation perturbation and its application in ethylene cracking furnace optimization

@&#HIGHLIGHTS@&#
A new variant of PSO, abbreviated as MLPSO-STP, is proposed.A novel learning strategy is used to enhance the global search ability.Space transformation perturbation is used to obtain better solutions.MLPSO-STP outperforms its peers in terms of searching accuracy and reliability.MLPSO-STP is used to optimize the operating conditions of ethylene cracking furnace.

@&#KEYPHRASES@&#
Particle swarm optimization,Learning strategy,Space transformation,Ethylene cracking furnace,

@&#ABSTRACT@&#
This paper proposes a new variant of particle swarm optimization (PSO), namely, multiple learning PSO with space transformation perturbation (MLPSO-STP), to improve the performance of PSO. The proposed MLPSO-STP uses a novel learning strategy and STP. The novel learning strategy allows each particle to learn from the average information on the personal historical best position (pbest) of all particles and from the information on multiple best positions that are randomly chosen from the top 100p% of pbest. This learning strategy enables the preservation of swarm diversity to prevent premature convergence. Meanwhile, STP increases the chance to find optimal solutions. The performance of MLPSO-STP is comprehensively evaluated in 21 unimodal and multimodal benchmark functions with or without rotation. Compared with eight popular PSO variants and seven state-of-the-art metaheuristic search algorithms, MLPSO-STP performs more competitively on the majority of the benchmark functions. Finally, MLPSO-STP shows satisfactory performance in optimizing the operating conditions of an ethylene cracking furnace to improve the yields of ethylene and propylene.

@&#INTRODUCTION@&#
Research on optimization has been highly active in various engineering and science problems, such as in structural design, scheduling, and economic dispatch. As the complexity of the problems increases, traditional optimization algorithms may no longer satisfy problem requirements and consequently entail new effective algorithms. Over the last decades, various meta-heuristic algorithms have been developed as feasible and effective methods for optimization problems. Based on the number of solutions generated in each iteration, meta-heuristic algorithms can be divided into two main categories: individual-based and population-based [1]. For individual-based algorithms, such as Tabu Search (TS) [2] and Simulated Annealing (SA) [3], they start and perform the search process by single solution, thus less computational cost is needed but suffer from premature convergence. In contrary, population-based algorithms can efficiently discourage premature convergence since multiple solutions are involved during the search process. However, the computational cost of population-based algorithms is higher than algorithms with single solution. Many of population-based algorithms, such as Genetic Algorithms (GA) [4], Ant Colony Optimization (ACO) [5], Particle Swarm Optimization (PSO) [6], Artificial Bee Colony (ABC) [7], Gravitational Search Algorithm (GSA) [8], Teaching-Learning-Based Optimization (TLBO) [9–11], and Fruit Fly Optimization (FFO) [12,13], have been successfully implemented in practical problems.The abovementioned algorithms can solve many challenging real-world problems. However, according to “No Free Lunch” theorem [14], as no single meta-heuristic algorithm is yet able to achieve optimal results for all optimization problems, researchers are currently investing significant efforts to further improve existing algorithms or develop new algorithms inspired by natural phenomena. Some of the recently developed algorithms include Grey Wolf Optimizer (GWO) [15], Ant Lion Optimizer (ALO) [16], Multi Verse Optimizer (MVO) [17], Black Hole (BH) [18], Dragonfly Algorithm (DA) [19], Social Spider Algorithm (SSA) [20], Search Group Algorithm (SGA) [21], Ions Motion Optimization Algorithm (IMO) [22], Charged System Search (CSS) [23], and Moth-Flame Optimization (MFO) [1].PSO marks one of the most popular classes of nature-inspired optimizers and has its root in artificial life and social psychology. PSO does not require any information on the gradient of the function to be optimized. It uses only primitive mathematical operators and is conceptually simple. As such, PSO has rapidly progressed in recent years and has been successfully applied in diverse areas of science and engineering, such as in artificial neural networks [24–26], power systems [27–29], electricity markets [30,31], and other fields [32–36]. Similar to other population-based optimization techniques, PSO algorithms are subjected to performance evaluation in terms of two critical criteria, namely, convergence speed and global search ability. Each particle in PSO updates its velocity and position by learning from the personal historical best position (pbest) of the particle and the best position (gbest) found by the entire swarm so far. Restricting the social learning aspect to only gbest causes the original PSO to converge rapidly. However, in multimodal problems, the current gbest located at a local optimum may trap the entire swarm and cause premature convergence. The performance of PSO is highly related to particle diversity, especially when attempting to avoid premature convergence and to escape from the local optimum. The performance of PSO has been improved using several PSO variants, including those that resulted from different modifications. These enhancements include tuning the control parameters to balance the local and global search abilities, designing different topologies to replace the traditional global topology, and hybridizing PSO with other search techniques. However, these variants usually preserve swarm diversity at the cost of slow convergence speed or complicated algorithmic structures. Thus, synthetically improving the performance of PSO remains a challenging task in PSO research.The current paper proposes a new PSO algorithm, namely, multiple learning PSO with space transformation perturbation (MLPSO-STP). This new PSO variant employs a novel learning strategy and STP to increase the global search accuracy and convergence speed of the algorithm. In specific, each particle in the new learning strategy learns from the average information on pbest of all particles and from the information on multiple best positions that are randomly chosen from the top 100p% of pbest. This learning strategy improves swarm diversity and prevents premature convergence. Moreover, STP increases the chance to find optimal solutions. The performance of MLPSO-STP on 21 well-known benchmark functions with various characteristic features is compared with those of eight PSO variants and seven state-of-the-art meta-heuristic search (MS) algorithms. The proposed algorithm performs better than the other tested algorithms in the majority of the test problems.The monomer ethylene is highly important in the petrochemical industry [37]. Ethylene cracking furnaces are essential process units in ethylene plants; among the equipment used in an ethylene plant, these units have the largest production capacity and the highest energy consumption. Therefore, improving the operating conditions of ethylene cracking furnaces benefits the industry. Aside from ethylene, propylene is also produced using an ethylene cracking furnace. The yields of ethylene and propylene are typical indices of the success of a country's petrochemical industry [38]. Hence, optimizing the operating conditions of a cracking furnace to maximize the yields of ethylene and propylene is highly important to the petrochemical industry. MLPSO-STP exhibits a satisfactory performance on this industrial application.The article is subsequently organized as follows. Section 2 presents several PSO-related studies. Section 3 briefly introduces the standard PSO algorithm. Section 4 describes our proposed approach. Section 5 provides the experimental settings and results. Section 6 presents the industrial application of the proposed algorithm. Finally, Section 7 concludes this work.

@&#CONCLUSIONS@&#
