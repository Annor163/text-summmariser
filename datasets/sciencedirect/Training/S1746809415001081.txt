@&#MAIN-TITLE@&#
A study on the representation of QRS complexes with the optimum number of Hermite functions

@&#HIGHLIGHTS@&#
Heartbeat representation with different numbers of Hermite functions was studied.Model selection techniques were used to find the optimal representation length.The impact of representation length on the computational resources was studied.Using this information a mixture of models clustering algorithm was developed.A misclassification rate of 0.96% over the MIT-BIH database was achieved.

@&#KEYPHRASES@&#
Heartbeat representation,Hermite functions,ECG,Clustering,

@&#ABSTRACT@&#
When choosing a representation for the classification of heartbeats a common solution is using the coefficients of a linear combination of basis functions, such as Hermite functions. Among the advantages of this representation is the possibility of using model selection criteria for choosing the optimal representation, a property that is missing in other heartbeat representation schemes. However, to date none of the authors who have used basis functions has studied what is the optimal model length (number of functions in the linear combination). This length is usually chosen using ad hoc techniques such as the visual inspection of the reconstruction obtained for a few beats. This has led to such different choices as representing the QRS of the beats by as few as 3 or as much as 20 Hermite functions. This paper studies what is the optimal number of Hermite functions to be used when representing the QRS. The Hermite characterization of the QRS complex was calculated using from 2 to 30 functions. To determine the optimal number of functions AIC and BIC were calculated for all the heartbeats in the MIT-BIH database, obtaining for each QRS the optimum model length. The features of the Hermite characterization have been studied using feature selection techniques. Data about the impact of the length of the representation chosen on the computational resources is also presented. Using this information, we have developed a clustering algorithm based on mixture models that has a misclassification rate of 0.96% and 0.36% over the MIT-BIH database and the AHA database, respectively.

@&#INTRODUCTION@&#
Cardiovascular diseases are the number one cause of death in the world [1]. An estimated 17 million people died from them in 2011 and 80% of the deaths took place in low- and middle-income countries; these countries’ population represent more than 75% of the world population. In this context the electrocardiogram (ECG) has become a valuable low-cost diagnostic tool. Due to the large amount of data generated by the ECG, visual inspection is a tedious and time-consuming task. This is especially true in long recordings such as 24-hour Holter that can contain up to 100,000 heartbeats. Hence the interest in providing computational tools that automate this analysis.ECG analysis often starts with the detection and representation of the beats [2]. The detection of the QRS complex, the most significant feature of the heartbeat, is a problem solved with an acceptable degree of satisfaction (around 99.7% correct detections on the reference databases). After detection, the next step is beat representation. The different solutions to represent heartbeats could be classified into three major schemes: using the digital signal [3]; using segmentation features such as heights and lengths of the waves that make up the beat [4]; and representing the beat as a linear combination of a set of basis functions [5]. The first approach can produce a high dimensional feature space and is highly sensitive to noise. The second has the advantage of using the same features that clinicians use to reason about beats, but achieving a robust beat segmentation is very hard, especially in ambulatory ECG. The third approach is very robust in the presence of noise and it can provide a compact representation of the beat using a small collection of features, typically the coefficients of the basis functions. The main disadvantage of this representation is that the features have no meaning for the cardiologist.The ECG representation through basis functions was first proposed in [5] where Laguerre functions were used. Later, the Karhunen-Loève expansion was applied [6]. More recently the orthogonal Hermite functions were proposed [7]. In all these cases, beats are represented by the coefficients that permit their reconstruction from the basis functions. Hermite functions are the most used basis of functions for representing the beat, and they are growing in popularity. A query in Google Scholar with the terms “Hermite representation electrocardiogram” returns about 2500 scientific papers, of which over 900 have been written since 2010. This growing popularity is due to the strong similarity between the shape of the Hermite functions and the QRS complex, and due to Hermite functions having a dilation parameter that enables an efficient representation of beats with large differences in QRS duration.When using this representation, or any other basis functions, a choice must be made about the number of functions to be used. In the literature we can find papers that use almost any number of Hermite functions ranging from 3 [8] up to 20 [9]. The authors usually provide little or no justification for the number of functions used in their work, besides a visual inspection of the reconstruction of some of the beats.This paper attempts to provide an answer to the question: What is the optimal number of Hermite functions to be used in QRS representation? To achieve this, model selection techniques were used to determine the optimum number of functions to be used in beat representation. AIC and BIC were calculated when representing the QRS using from 2 to 30 Hermite functions. Using this information, we have designed a clustering algorithm that has a misclassification rate of 0.96% over the MIT-BIH database and of 0.36% over the AHA database. Section 2 describes the databases used in our analysis, the preprocessing applied to the ECG signal, and how we have calculated the optimal number of Hermite functions using model selection techniques. It also presents the clustering algorithm that we have used. Section 3 describes the results obtained, and Section 4 discusses them. Finally some conclusions are given.Following the recommendations of the ANSI/AAMI EC57 [10] we will use in this paper the MIT-BIH Arrhythmia Database [11] and the AHA ECG Database. The MIT-BIH database contains 48 half-hour excerpts of two-channel ambulatory ECG recordings of 47 subjects. This database includes a wide range of arrhythmias and can be considered the gold standard in automatic arrhythmia classification [8,9,12–16]. The recordings were digitized at 360Hz. Each recording has two leads among the modified limb lead II (MLII) and the modified leads V1, V2, V3, V4 and V5. Two or more cardiologists annotated each recording identifying each beat of the database (approximately 110,000 annotations). The heartbeats were divided into normal beats (approximately 68%) and 16 different types of abnormal beats.The AHA ECG Database was developed by the American Heart Association (AHA) and consists of 155 two-channel ambulatory recordings. The recordings are digitized at 250Hz and they are 3h long but only the last 30min of each recording are annotated beat-by-beat. In this work we used the last 30min of the 155 recordings.Two different filters were used to remove noise from the recordings. For the baseline drift elimination the Daubechies extremal phase filters of width 4 were used. The wavelet transform was used to compute an approximation of the signal below 1Hz. For a signal sampled at 360Hz, we need to compute until level 8. Then we remove all the details from level 1 to level 8 (included). Finally the signal is reconstructed using the inverse discrete wavelet transform and subtracted from the original signal, thus removing the baseline drift [17,18]. The high frequencies were eliminated using a low-pass Butterworth filter with a cutoff frequency of 40Hz.The algorithm for obtaining the Hermite representation of a QRS complex used in this paper was originally proposed by Lagerholm et al. in [14] and since then it has been widely used in the literature [8,9,15,19,20]. There are approaches more efficient to calculate the Hermite representation of a discrete time series while maintaining most of the properties of the continuous Hermite functions [21]. However, in this work we shall use the Lagerholm et al. method for the sake of comparability with previous papers in the arrhythmia recognition literature which have used this algorithm. We reproduce it here for completeness.An excerpt of 200ms was extracted around each beat position annotated in the database. With this window size the complete QRS complex is extracted leaving out the P and T waves. The QRS alone is not enough to discriminate atrial premature, nodal premature, atrial escape and junctional escape beats since these beats share a common QRS morphology. Once the QRS has been taken into account, the T wave provides little additional information for arrhythmia detection. The P wave does provide relevant information to discriminate atrial premature, nodal premature, atrial escape and junctional escape beats. But the difficulty in identifying it with reliability, especially in ambulatory ECG, often leads to trying to obtain similar information using features derived from the distance between consecutive beats [12,14,22]. This is the approach followed in this paper.The Hermite basis functions always converge to zero in ±∞. To ensure the convergence to zero at the edges of the window, 100ms of zeros were added on each side of the 200ms window of the QRS complex. The resulting window of 400ms, x[l], is represented as:(1)x[l]=∑n=0N−1cn(σ)ϕn[l,σ)+e[l]l=−W·fs2,−W·fs2+1,…,W·fs2being N the number of Hermite functions used, W the window size in seconds and fsthe sampling frequency. ⌊⌋ Means that the real number between the brackets is rounded to the nearest integer smaller than the value. ϕn[l, σ) is the n-Hermite discrete function obtained by sampling at fsthe continuous function ϕn(t, σ), cnare the coefficients of the linear combination, e[l] is the error between x[l] and the Hermite representation, and σ is a dilation parameter that controls the width of the Hermite function enabling it to adjust to the width of the QRS. The Hermite functions ϕn[l, σ), 0≤n<N, are defined as:(2)ϕn[l,σ)=1σ2nn!πe−(l·Ts)2/2σ2Hn(l·Ts/σ)being Tsthe inverse of the sampling frequency. The Hermite polynomial Hn(x) can be obtained recursively:(3)Hn(x)=2xHn−1(x)−2(n−1)Hn−2(x),where H0(x)=1 and H1(x)=2x. For example H2(x)=4x2−2, H3(x)=8x3−12x, and so on.Each QRS complex is represented by the N coefficients of the linear combination of the Hermite functions using cn(σ), 0≤n<N, and by σ. Fig. 1illustrates that the higher the order of the Hermite functions used, the more accurate the approximation of the beat is. However, using many functions has the risk of modeling noise in the signal, and not the actual shape of the QRS complex.For a given value of σ, the Hermite functions form an orthonormal basis:(4)∫−∞∞ϕn(σ)ϕm(σ)=δmn.This permits an efficient calculation of cn(σ). Without an infinite window size, (4) does not hold. However if ϕn[l, σ) is close enough to zero on the edges and outside the window, (4) is still an acceptable approximation. For the edges of the window we shall use the (quite tolerant) criterion that ϕn[l, σ) is at most 1/10 of its maximum value within the window:(5)|ϕn[−l0,σ)|=|ϕn[l0,σ)|<110maxshitasenl∈[−l0,l0]|ϕn[l,σ)|,where −l0 and l0 are respectively the first and last samples of the window. We shall also define the value of ϕn[l, σ) outside the window as being smaller than in the edge(6)|ϕn[l,σ)|≤|ϕn[l0,σ)|∀|l|>l0.For a given window size and a fixed number of Hermite functions (5) and (6) impose an upper limit on the value of σ. For example, for N=3, 4 and 5, the maximum values of σ that fulfill (5) and (6) are 62, 55 and 51ms, respectively.For a given σ the coefficients cn(σ) are calculated by minimizing the summed square error:(7)∑le[l]2=∑lx[l]−∑n=0N−1cn(σ)ϕn[l,σ)2.We can approximate the minimum of the square error assuming:(8)cn(σ)=x→·ϕ→n(σ),where the vectors are defined asx→={x[l]}andϕ→n(σ)={ϕn[l,σ)}.An iterative stepwise increment of σ was done by recomputing (8) and (7) for each step and selecting the σ that minimizes the error. The search starts from 0 and increases to the maximum value of σ in steps offs1000. Average optimal values of σ for all values of N were roughly between 14 and 21ms.In the past we have studied QRS representation with Hermite functions by measuring the error between the original signal and the reconstruction [23]. But when using such a measure, adding more functions will always reduce the error, and there is no well-defined criterion about up to which point the improvement in accuracy of representation justifies a more complex representation. In this work we shall use model selection criteria to choose the optimum number of functions to be used in QRS representation.In the field of model selection we have two main approaches: Bayesian criteria and information theory criteria. Among the Bayesian criteria, the Schwarz's Bayesian inference criterion (BIC) [24] is the most widely used. The approaches based on information/coding theory are many, but the more popular is the Akaike information criterion (AIC) [25]. Both AIC and BIC have strengths and weaknesses. AIC tends to choose models that are more complex than needed, especially if the number of samples is high. However, the fact that it minimizes the mean-squared error makes it a good candidate for a regression problem. On the other hand BIC should, in theory, only be used to find the real model among a set of candidates containing the real model, a hypothesis that is not true in our case. BIC also tends to choose very simple models for a low number of samples. In this paper we shall apply both methods separately and we shall compare their results.BIC is based on the likelihood function. When adding additional parameters the likelihood always increases. However, this may result in overfitting. Thus, a penalty term based on the number of model parameters is added. In our case each new parameter is the coefficient associated with a new Hermite function. For example, if we are using functions up to ϕn[l, σ) we shall have n+1 parameters, the n coefficients cn(σ) of the linear combination, and σ. In our problem BIC is defined as:(9)BIC=−2·lnLˆ+k·ln(m),where m is the number of samples, k is the number of parameters (k=n+1 when n functions are used) andLˆis the maximized value of the likelihood.AIC is based on the Kullback–Leibler Distance and the information entropy. Using this criterion we can obtain an estimate of the relative distance between the fitted model and the unknown true mechanism that generated the observed data. Akaike defined “an information criterion” (AIC) as:(10)AIC=−2·lnLˆ+2·k.If the sample size (m) is not several orders of magnitude greater than the number of parameters (k), AIC may perform poorly and the probability of overfitting increases. Sugiura [26] proposed a second-order variant of AIC with an additional bias-correction term (AICc). If m is large enough then AICcconverges to AIC and they will select the same model. AICcis defined as:(11)AICc=AIC+2k(k+1)m−k−1.Given that in our problem the ratio m/k is not large, we shall use this AIC variant.Assuming that the errors are independent and distributed according to a normal, and that the variance is constant, BIC and AICccan be expressed as:(12)BIC=m·ln(σe2)+k·ln(m),(13)AICc=m·ln(σe2)+2·k+2k(k+1)m−k−1,whereσe2is the error variance. The unbiased estimatorσe2ˆwill be used to estimateσe2, which in our case is given by(14)σe2ˆ=1m−1∑l=1mx[l]−∑n=0N−1cn(σ)ϕn[l,σ)2=1m−1∑l=1me[l]2.The representation of each QRS of each lead is an independent model selection problem. For each QRS of each lead we calculated BIC and AICcwhen it is represented using from 2 to 30 Hermite functions and its optimum model length was stored.In this article we will represent each beat using up to 30 Hermite functions. If we add the dilation parameter (σ) and we take into account that we have two leads, this means using up to 62 features to represent each QRS. This feature space has a high dimensionality. It might make sense to try to select a subset of features that are most relevant for the morphological classification of the QRS.To this end we have employed several feature evaluation techniques that are capable of ranking the features according to the information they provide: Information Gain, Gain Ratio and Chi-square feature evaluation. Information Gain and Gain Ratio try to measure the information obtained when making a decision based on a given feature [27]. Gain Ratio is based on Information Gain, but it applies a correction to penalize decisions with a high branching factor. Chi-square feature evaluation ranks features by computing the value of the chi-squared statistic with respect to the class [28].To apply these techniques we used the entire MIT-BIH database. We considered that the beats were labeled with the beat type to which they belong according to the database annotations. Feature selection was performed for each record (patient) separately and over the set of all the beats from all recordings together, in order to compare the results from these two approaches.The feature selection results were not encouraging. The most relevant features selected by the three feature selection techniques varied considerably between patients, and the features selected for each patient varied considerably from those selected in the set made of all the beats of the database. Despite many attempts, we had to dismiss the possibility of gaining information about the relevance of the features that could be used for all patients. While our results suggest that it is possible to reduce the feature space for a particular patient, the features that are not relevant for a given patient may be relevant to other, and vice versa. Therefore, feature selection needs to be applied on a per patient basis. These results are similar to the conclusions reached in [29]. Given that our ultimate goal is building an automatic beat recognition algorithm, we cannot assume that we have a subset of labeled beats for each patient that may be used on a “per patient” feature selection step. Thus, we cannot relinquish any feature and we shall work with the full set of features.Using a high number of features (i.e., using a large number of Hermite functions) can lead to a more accurate representation of the beat according to AIC and BIC. But when the beat is going to be analyzed automatically, a high number of features means having a high dimensionality in the feature space. Machine learning algorithms’ performance usually is impacted negatively by this situation. Hence the interest in analyzing the performance of machine learning algorithms when different number of features are used to represent the beat.An advantage that clustering algorithms have over classifiers for beat recognition is that, due to inter-patient variability, it is hard to obtain an accurate classification without a patient specific adaptation of the classifier using a set of beats from the patient that have been labeled. We will measure the performance of a clustering algorithm on the features of the Hermite representation using feature vectors constructed from 2 up to 30 functions. This upper limit was selected because, as it will be shown in the results section, using 30 functions or less the vast majority of the beats of the database are represented optimally according to both AICcand BIC.We used an Expectation Maximization (EM) clustering algorithm. This algorithm follows an iterative approach which tries to find the parameters of the probability distribution that maximizes the likelihood for parameterized Gaussian mixture models [30]. Each iteration of the algorithm has two steps. The E-step estimates the probability of each element belonging to each cluster. The M-step recalculates the parameters of the probability distribution for the next step. After each iteration a convergence test that verifies if the difference with the previous iteration is smaller than a fixed parameter is performed. To improve the quality of the results and mitigate the dependence with initialization parameters, the Gaussian models were initialized using hierarchical clustering, which does not require an initialization phase.In our tests we fixed the number of clusters to 25 to obtain a direct comparison with the most referenced article on beat clustering using Hermite-based features [14]. There are some types of arrhythmia, such as atrial premature, nodal premature, atrial escape and junctional escape beats, where the morphology of the QRS is not sufficient to reliably discriminate them from normal beats. To identify these beats it is necessary to have information on the distance between the beat and the previous one, and the beat and the next one. Thus, to improve the clustering process in these cases the two following rhythm features were added to the feature vector:(15)R1[i]=R[i]−R[i−1],(16)R2[i]=u(α)·α,α=(R1[i+1]−R1[i])−(R1[i]−R1[i−1]),where R[i] is the time of occurrence of the ith beat given by the database annotation, and u(x) is the Heaviside step function. These features were also used in [14]. Therefore our clustering vector consists of the Hermite function coefficients for each lead, the sigma parameters and the rhythm features given by (15) and (16).

@&#CONCLUSIONS@&#
In this article we have used model selection criteria to study the optimal representation of the QRS complex using the Hermite basis function. Our results show that the vast majority of authors that have used this representation were using a number of features that represents optimally a very small percentage of the beats. According to our data, 25 Hermite functions are needed to represent optimally about 90% of the beats (see Fig. 2). This suggests that the results achieved by these authors may improve just by employing a higher number of Hermite functions due to using a more accurate beat representation. We have shown how the classification error in our algorithm has fallen from 3.40% to 1.04% just by increasing the number of Hermite functions from 4 to 28, without making any other changes to the algorithm. Although our study was limited to Hermite functions, the same technique presented in this paper could be used with other function basis used to represent beats, such as Laguerre functions [5] and the Karhunen–Loeve expansion [6].A caveat with what is stated in the previous paragraph is that using a beat representation with a relatively large number of features can be challenging for machine learning techniques. However, we have shown that this beat representation allowed us to build a clustering algorithm for the recognition of the beats’ morphology which has better overall accuracy (99.04%) and positive predictive power (96.62%) over the MIT-BIH database than any other previously published paper (see Table 5). In this article we have also reported our results over the AHA database achieving an overall accuracy of 99.54%.