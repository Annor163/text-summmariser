@&#MAIN-TITLE@&#
Transfer learning based clinical concept extraction on data from multiple sources

@&#HIGHLIGHTS@&#
Using data drawn from different distribution to train concept extraction model.An instance based transfer learning method TrAdaBoost is applied in our work.We combine TrAdaBoost with Bagging to prevent the negative transfer problem.Only a tiny amount of data in target domain is required to build a model.

@&#KEYPHRASES@&#
Clinical concept extraction,Transfer learning,TrAdaBoost,Bagging,Machine learning,

@&#ABSTRACT@&#
Machine learning methods usually assume that training data and test data are drawn from the same distribution. However, this assumption often cannot be satisfied in the task of clinical concept extraction. The main aim of this paper was to use training data from one institution to build a concept extraction model for data from another institution with a different distribution. An instance-based transfer learning method, TrAdaBoost, was applied in this work. To prevent the occurrence of a negative transfer phenomenon with TrAdaBoost, we integrated it with Bagging, which provides a “softer” weights update mechanism with only a tiny amount of training data from the target domain. Two data sets named BETH and PARTNERS from the 2010 i2b2/VA challenge as well as BETHBIO, a data set we constructed ourselves, were employed to show the effectiveness of our work’s transfer ability. Our method outperforms the baseline model by 2.3% and 4.4% when the baseline model is trained by training data that are combined from the source domain and the target domain in two experiments of BETH vs. PARTNERS and BETHBIO vs. PARTNERS, respectively. Additionally, confidence intervals for the performance metrics suggest that our method’s results have statistical significance. Moreover, we explore the applicability of our method for further experiments. With our method, only a tiny amount of labeled data from the target domain is required to build a concept extraction model that produces better performance.

@&#INTRODUCTION@&#
Clinical documents are valuable resources in which abundant personalized health information, such as symptoms, medicines and tests, is recorded by physicians in natural language. As a subtask of automatic acquisition of knowledge from these unstructured clinical texts, concept extraction aims to identify words and phrases that stand for clinical concepts from the narrative texts in clinical documents. This is the key component of text processing systems for understanding the content of clinical documents. Only when clinical concepts are correctly identified can other more complex tasks, such as concept relation extraction, assertion classification, co-reference, health information retrieval and health information recommendation, be performed effectively.In the biomedical literature domain, research similar to concept extraction has been conducted in named entity recognition tasks such as gene name recognition [1]. However, research on clinical concept extraction for clinical documents appears to be rather sparse. One important reason for the lag of clinical concept extraction is the lack of shared annotated clinical documents due to patient privacy and confidentiality requirements. Fortunately, efforts to construct de-identified clinical documents are finally allowing studies on clinical concept extraction. For example, the 2010 Informatics for Integrating Biology and the Bedside (i2b2)/Veteran’s Affairs (VA) challenge [2] provided a total of 394 training documents, 477 test documents, and 877 un-annotated documents for all three tasks. However, annotated clinical documents are always scarce and are created by a number of different institutions; the 2010 i2b2/VA challenge’s data consist of four sets from three institutions. Such small-scale data sets limit the performance of a statistical machine learning model. One solution to this problem is to increase the training data sets by gathering data from multiple sources. Nevertheless, different vocabularies and writing styles of multiple sources make the combined data sets heterogeneous, to which the statistical machine learning model is sensitive. Specifically, the marginal probability distributions of words in clinical texts from different institutions are not equal, which violates the traditional machine learning’s basic assumption: the training and test data should be under the same distribution. Therefore, a learner trained by one institution’s data may perform worse when it is applied to data from another institution. The normal way of tackling this problem is to annotate data from the new institution, but this is always expensive and time-consuming. Abandoning old data would also be a waste.The objective of this paper is to discuss approaches and strategies for clinical concept extraction from multiple sources. Using a training data set with a different distribution from one institution, we build a clinical concept extraction model for data from another institution. Transfer learning is a family of algorithms that can relax the traditional machine learning’s same-distribution assumption. It leverages and transfers knowledge from the source domain to the target domain, and in this way, helps improve the model when the target domain’s training data are insufficient. Specifically, we apply an instance-based transfer learning method – TrAdaBoost [3] – to the clinical concept extraction task. TrAdaBoost aims to re-weight the instances in the source domain in order to decrease the diversity between the data of the source domain and the target domain. It was originally created to solve binary classification problems, and we apply it to the sequence labeling problem with multiple labels. Additionally, to avoid the negative transfer problem caused by the over-discarded risk of TrAdaBoost, we integrate Bagging with TrAdaBoost to provide a “softer” weight update mechanism. Two data sets, BETH and PARTNERS, from the 2010 i2b2/VA challenge, as well as one data set we built by combining BETH and a biomedical literature data set (BIOLITERATURE), are used to verify the effectiveness of our method’s transfer ability. Experiments show that with only a small amount of annotated training data from the target domain, our framework outperforms the baseline method, which simply combines data from the source domain and data from the target domain as training data.

@&#CONCLUSIONS@&#
