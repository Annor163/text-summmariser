@&#MAIN-TITLE@&#
A survey of genetic algorithms for solving multi depot vehicle routing problem

@&#HIGHLIGHTS@&#
We reviewed the use of genetic algorithms on the MDVRP (multi depot vehicle routing problem).Survey was made on every operator and setting of genetic algorithm for this problem.We tested different genetic operators and compared the results.We compared the genetic algorithms to other metaheuristic algorithms on MDVRP based on the results on standard benchmarks.

@&#KEYPHRASES@&#
Genetic algorithms,Vehicle routing problem,Evolutionary algorithms,Transport optimization,

@&#ABSTRACT@&#
This article presents a survey of genetic algorithms that are designed for solving multi depot vehicle routing problem. In this context, most of the articles focus on different genetic approaches, methods and operators, commonly used in practical applications to solve this well-known and researched problem. Besides providing an up-to-date overview of the research in the field, the results of a thorough experiment are presented and discussed, which evaluated the efficiency of different existing genetic methods on standard benchmark problems in detail. In this manner, the insights into strengths and weaknesses of specific methods, operators and settings are presented, which should help researchers and practitioners to optimize their solutions in further studies done with the similar type of the problem in mind. Finally, genetic algorithm based solutions are compared with other existing approaches, both exact and heuristic, for solving this same problem.

@&#INTRODUCTION@&#
Vehicle routing problem (VRP from now on) is the classic problem initially described by Dantzig and Ramser in 1959 [1] and it derives from the traveling salesman problem or arc routing problem. Arc routing problem is basically a problem where we strive to find the optimal way to construct a route in such a way that the route is the shortest one possible. VRP extends this problem in a way that there is a set of customers or stops, and they have to be visited by a vehicle and this vehicle has to start and finish its trip at the home depot stop [2]. This is basically a reflection of real life distribution problems like delivering and picking up passengers, mail, packages and different kind of goods. Since its proposition by Dantzig, it has received much attention in the scientific community and a lot of exact and also heuristic methods have been proposed to solve it. Our research focuses on one of the most widely used variations of this problem – multi depot VRP (MDVRP). It extends the classical problem by introducing the capacity to the vehicles and demand to the customers and adding multiple depots. MDVRP is, as is VRP, a NP hard combinatorial optimization problem and therefore it is difficult to find its optimal solution [3]. While exact methods solve small problems quite efficiently [4], issues still exist for the larger problems or the special types of the VRP variants. On the other hand, meta-heuristic methods find solutions in less time and one such method is the genetic algorithm (GA) – an algorithm that mimics the natural process of evolution [5].There are several meta-heuristic approaches to solving VRP and its variant transportation problems. State of the art solutions include: particle swarm optimization approach [6,7], ant colony optimization [8,9], genetic approach [10], simulated annealing [11,12] and tabu search [13,14]. These approaches are useful in various types of transportation problems, similar to VRP, such as facility location problem, where the goal is to find the optimal location of central depot considering the locations of stops. The topic of facility location problem has already been thoroughly researched in survey papers [15–17]. In [18] and [19] authors compared the meta-heuristic approaches on this facility location problem and location planning respectively. Results from these papers show that the main advantage of GA in comparison to other meta-heuristic algorithms is the performance and final result on time constraints and limited computer power, while still resulting in competitive solutions. Although some other meta-heuristics are able to find better solutions than GA, GA can generally find adequate (good enough) solutions in a shorter time frame [18,19]. This is also the main reason that GAsare still used in solving the routing, locating and other NP hard problems.There have been a lot of the researches done about solving VRP with GAs, where researchers focused on the practical usage of the GAs on VRP in real world problems. A systematic research on how different aspects, operators, variants and settings of GAs influence the search process and thus the obtained solutions still does not exist. Goals of this paper are thus to explore the background of solving MDVRPs with GAs, to look into, evaluate and compare different approaches used, and to discuss how to build this kind of GAs to solve MDVRP efficiently.Although the MDVRP itself and the use of GAs to solve it have been known for many years, the number of GAs for solving MDVRP keeps growing (Fig. 1). Namely, literature reports good GA solutions to MDVRPs, not far from optimal, while keeping the computational resources, needed to find the solution, within very reasonable boundaries. In this context, we provide a detailed survey of GAs to solve MDVRP. Furthermore, we provide results of using different genetic operators and/or settings, most commonly used in literature, on a set of standard benchmark problems, together with detailed discussion.The remainder of the paper is organized as follows. We start with the overview of the VRP and its variations. We describe the most frequent variations and formulate the MDVRP, as it is the main focus of our research. We continue with the basics of the GA – we describe the whole process from the data preparation to the main evolutionary loop of the algorithm and end up with the insights into genetic operators. Then we follow up with the main topic of this paper – solving MDVRP with the GAs. It starts with the basic background overview of this approach. Then the most common method of representing this problem in genetic form is listed. Next we look into the genetic operators used for this specific problem – we describe crossover, mutation, selection and other operators used. For the second part of the paper we developed a working prototype of GA for solving MDVRP and test it intensively. At the beginning we start with the comparison of some of the most used operators and try to decide which of these are most suitable for this type of problem. At the end we compare GA based solutions with some other existing solutions, both exact and heuristic, on a set of standard benchmark problems.The VRP is a classic problem that represents the real life situations from distribution field. In theory it derives from two basic optimization problems: the traveling salesman problem (TSP) and arc routing problem. The TSP [20] is meant to solve the problem of the salesman who has to visit all the cities and at the same time keep the total route as short as possible – it is a minimization problem. Numbers of methods have been developed to solve it, some are exact methods and others tried to solve it with heuristics. These methods have largely been used to solve VRP, some with more success than others [4,21]. The VRP expands on the TSP with the addition of the bases, from which the traveling vehicles have to start and return to. Situations from the real life problems have led to the numerous variations of this simple concept. This simplest type of VRP problem with only one depot and no capacity limitation is sometimes called single depot vehicle routing problem (SDVRP) [22].Capacitated VRP (CVRP) adds the capacity to the vehicle traveling. Vehicle is traveling from customer to customer picking up the goods from them. Each one of the customers has a fixed volume of these goods. The problem here is how to construct the routes in such a way that the length of it is minimal and the volume constraint is never breached.Multi depot VRP (MDVRP) extends the basic problem in such a way, that there are multiple bases (depots) from where vehicles are starting (Fig. 2). Depending on the situation, vehicles are either obligated to return to the starting base (fixed) or they have no such limitation (non-fixed). Solving this problem sometimes involves grouping customers into clusters, where each one of the clusters is visited from a vehicle from the nearest base. Extended variation is when the locations of the bases are not fixed and the goal is to find the optimal locations for them in such a way that the cost of the traveling will be the smallest. The fixed MDVRP with capacities is the focus of our research.VRP with time windows (VRPTW) is another of the standard extension. In this variation the customers have given time window when they are available for pickup of the goods. Finding solution to this kind of problem involves batching together customers who are near each other and have similar working time so that they can be serviced by the same vehicle. Variation of this kind of problem also implements the soft time windows, where customer still operates outside of the time windows but visiting them in that time involves some form of penalty. This kind of the problem usually has a complex way of calculating the cost of the trips, where the creator has to decide what is more important – to service all of the customers within the given time windows or to find the shortest route despite breaking some of the time constraints.As in the real life situations so is in the theoretical research field – many of the variations of the VRP are combined together to imitate or to resemble practical problems. Most of the studies done with the MDVRP are actually done with the capacity in mind and are sometimes called appropriately multi depot capacitated vehicle routing problem (MDCVRP). Actually, using capacity with multiple depots is so common, that papers use capacity when they refer to the MDVRP. Another one of the common combinations is the mash up of the multi depot problem with the addition of the time windows in customers – named multi depot vehicle routing problem with time windows (MDVRPTW).The need for solving real life problems has led researchers to theoretically approach even more possible variations. Limited distance of the vehicles and time shifts of the drivers has brought the distance constraint VRPs (DVRP), where each route of the vehicle has to be shorter than the given maximal distance. Capacitated VRPs have been extended in such a way that the storage room of the each vehicle has compartments for different type of resources. This resembles the situation where vehicle is delivering the raw food to the markets and the fresh meat has to be separated from fresh vegetables and fruits. The need to transport resources from one place to another has given a birth to the unique situation named general pickup and delivery problem (GPDP) which was later extended to the vehicle routing problem with pick up and deliveries (VRPPD or VRPDP) where vehicles with starting bases transport resources between the customers while keeping the route distance at minimal. Also other types of VRP problems exist but are out of the scope of this paper. For more detailed information on VRP see book on this topic from Toth and Vigo [23].MDVRP can be formulated in a mathematical model as follows – based on [24]. Let G=(VC U VD, R) be a directed graph where VC is a set made of customers and VD is a set made of depots. It is assumed that coordinates of all customers and depots are known. VC={c1,c2,…,cn}, where n is the number of the customers, and VD={d1,d2,…,dm} where m is the number of the depots.The R set is a set of all of the routes between the depots and customers. Each route has its cost and it is also assumed that the cost of each route is known. As is standard with this problem type, the cost is represented in the length of the route. The alternative would be to represent driving time on the route. Riis a route for one vehicle: R={(ri, rj):ri, rj∈VC∪VD, i≠j}, where lijis the distance of the route (ri, rj).The classic problem definition is that lijis symmetric and therefore satisfies the triangle inequality: lij=ljifor each i,j. Riis the route of one vehicle, where it starts in depot, visits some customers and ends in the starting depot: Ri={d, c1, …, cl, d}, where d∈VD, diis the demand of the cicustomer, and mkis the capacity of the vehicle k.Limitations are as follows: sum of customer demands on one route must not exceed the capacity of vehicle servicing that route, each customer is serviced by vehicles exactly once, each vehicle has to start and end in the same depot, and no customer has greater demand than any vehicle capacity.Goal of the MDVRP problem is to minimize the sum of all routes: min(∑(i∈VC∪VD)∑(j∈VC∪VD))lij, and to minimize the number of vehicles needed [25].A GA is a class of adaptive stochastic optimization algorithms that use the principles of natural evolution to perform search and optimization. It is used as an optimization technique where we strive to calculate the optimal or rather near optimal solutions to search problems. GA is a subset of the evolutionary algorithms, where the natural process from biology field is mimicked. Basic natural process was originally described by Darwin [26] with three basic principles: reproduction, natural selection and the diversity of individuals. These basic principles are used in the GA itself as we will see later on. The processes of evolution and natural selection are computed on the population of candidate solutions (individuals). Each individual in the population represents the particular solution to our problem and this individual is represented with the set of properties which are written in the chromosome or the genotype of the individual, just like in the nature. Based on the genotype, each individual is evaluated with what is called a fitness function. This function calculates the score of our individual in solving the given search problem and based on the type of the problem this can either be the minimization problem, where lower scores are preferred or maximization problem, where higher scores are preferred. Fitness basically represents the strength of the individual and it plays a vital role in the selection process (survival of the fittest). As in nature, so in our GAs our population evolves over time. Evolution occurs with the formation of the new generation of the individuals with the mating process (reproduction). Mating partners are chosen using the selection operator, based on their fitness. Mutation (small random change) is also mimicked in the algorithm, but it serves a different purpose – it widens the search space. GA was developed by Holland in 1975 [27] to a degree as we know it know and it continued to evolve with De Jong [28] and Goldberg [29] who showed how it could be used to solve complex optimization problems. Other types of evolutionary algorithms are genetic programming and genetic evolution strategies, but are out of scope of this paper.GA is an iterative process and iterations are called generations [30]. The main process of GA is presented on Fig. 3. After the initialization of a starting population, the main evolutionary loop starts with the evaluation of each individual according to the fitness function. Based on the fitness scores individuals from the population are selected using one of the selection methods described later. Generally, the more fit is an individual, greater are its chances of being selected. Again, the nature is mimicked, when the selected individuals are paired to go through the process of mating (crossover) and one or more children are produced from each pair. Crossover process is implemented in such a way, that children must have characteristics from both parents. Usually this consists of copying part of the genotype from one parent and filling the missing genes from another parent. A lot of different techniques of crossover were proposed over time, but as we will see later, no general technique can work perfectly on all types of problems. Besides the crossover, some other operators have been proposed. Mutation is one of these operators and is almost always used. Each child has a chance to go through the process of mutation, where some part of its genotype is randomly changed. This is supposed to include some randomness into the process and to widen the search space. All new children represent the new generation and replace the old population. The whole process is then repeated until one of the stopping criteria is reached. Through the years of research, many other operators were introduced, such as elitism where the best individuals automatically advance to the new generation. Some of the operators are so customized, that they are used only in specific problems. This is also the case when using GAs to solve VRP, as we will see later on.MDVRP was fully described in the year 1972 by Liong [31] and extensive research on this type of VRP began shortly. Sumichrast and Markham [32] described a problem where raw materials were transported from multiple sources (depots) to a set of plants. In their research they used the saving method which itself was developed decades before in 1964 by Clarke and Wright [33]. Throughout the years of the research a lot of different methods have been used to solve it, to name a few – tabu search [34], multi-level composite heuristics [35], lower bound heuristics [36], clustering and sweep procedure [37,38], some branch and bound algorithms [39], genetic clustering [40] and exact method using heuristics with back hauling [41]. Because MDVRP is a NP hard problem [3], most of the methods used were heuristic methods and no exact algorithm for large scale problems have been developed yet [42]. Searching the optimal solution would be hugely time consuming and with various methods of heuristics we strive to find enough good solutions in polynomial time. Focus of our research is the GA, so we centered our attention to this field and thoroughly reviewed most influential researches done on this algorithm. Following are the basic concepts adopted in those researches and some of them were chosen for implementation in our prototype, as we will see later on.Let us start with the problem representation of our individual solutions. Almost always the genotype is represented with an array of stops. Multiple variations of this representation have been used. The literature review revealed that most used variation is the simplest one, where array is filled with index numbers of the stops – these stops are visited one after another [43–57] as is shown in Fig. 4. The weakness of this solution is that there is no indication which vehicle, from which stop, on which trip is supposed to visit the particular stop. This genotype must be complemented with a special algorithm which calculates this information. Another weakness, and debatable even worse one, is that the crossover process cannot efficiently copy characteristics without losing some data. Some minor changes to this representation can be made with fixed routes annotated in array by reserved character [58].Researchers tried to solve some of the issues with inserting the depot index in the genotype, to inform the algorithm which tour is visited from which depot [59,60] – see Fig. 5. Again, if this upgrade brings any resolution remains debatable. Routing algorithm decides which vehicle drives on the particular route. Another similar representation is when array is filled with the indexes of the tours – character on the spot x represents the customer with index x, and the value of the character is the index of the tour [61,62]. In this case, the stops are already clustered together and algorithm just computes the order of the visits and assigns them to vehicles.Salhi and Petch [63] used a more radical approach where they proposed the genotype as an array of angles, which divide the field from the chosen central point to clusters as it is shown in Fig. 6. Each cluster is a responsibility of a particular base. Routes are calculated later with the mathematical arc route solution. As before, the crossover merges two arrays together and again the problem with losing some characteristics can emerge.Finally there are some genotypes made for simplifying the process of crossover. In [61,62,74,75] authors suggest multiple arrays to represent one genotype where each array is representation of one route. Crossover in this instance involves just combining routes together. Problem in this case is that some customers can be visited multiple times or can be left out – some repair process or at least penalty to fitness must be implemented. See Fig. 7for this type of crossover.Let us continue with the overview of the creation of the initial population in other researches. Most used is the strategy where initial population is randomly generated without any constraints or heuristics [43–45,59,63,66–68]. In some cases where individuals do not always represent feasible solutions, some constraints can be applied, as in paper by Zhao et al. [70], and Ghoseiri and Ghannadpour [58] where only feasible solutions are accepted in the initial population.In the pursuit to find the optimal solution faster, some heuristics are used to generate initial individuals. One popular method is to generate individuals using push-forward insertion heuristics (PFIH), which is an efficient method to compute route by comparing the cost of inserting a new customer into the existing route against that of starting a new route with the help of nearest neighbor algorithm. Some experiments use this method exclusively [46,47,58,69,70] but Zhu combine it with the randomly generated individuals [71]. Similar is the approach used by Filipec et al. [72], where the closest neighbor is found for each stop before starting the creation of the first generation. Routes are constructed with the closest neighbors in mind and choose them when it is possible. Another method used by Mendoza et al. is stochastic based insertion heuristics [73]. With this approach algorithm starts building route by inserting not yet served customers in such a way, that the solution remains feasible and the cost (distance) remains optimal. Similar type of greedy algorithm is used in paper from Santos et al. [48] and again in [46] by Ombuki et al. where researchers mixed this type of greedy algorithm with some randomness, so that initial population consist of 90% randomly generated individuals and other 10% of population from greedy algorithm. Xing et al. tested another interesting approach in [49] where the authors randomly choose one rule based on which is the next stop chosen (algorithm is called Extended Random Path-Scanning). In the same research they also test the method Extended Random Ulusoy's Heuristic where one giant route is created based on their rules, and then they split the giant route on smaller ones by implementing the algorithm where they search the optimal splits.Frequently the researchers do not supply the size of the population in the papers, so often this attribute is left unknown and experiments cannot be replicated. In cases where authors do supply this information, we found no pattern and it seems that the population size was chosen based on the best performance for the particular implementation. No know general optimal size was ever supplied, which leads us to conclusion that the size does not play a vital role in the process or that researchers have to find optimal size for their implementation through the process of testing. The logical conclusion is that too small population would not cover all the searching space, but too large populations tend to bring the evolution process to a crawl speed. We found that size ranges from 50 individuals [71] to well above 1000 individuals [50].Fitness function represents the method for the evaluation of individuals. It can be very simple or very complex method which includes a lot of parameters. The simplest way to calculate the fitness is to sum the lengths of all routes [59,61,67,69]. This type of fitness function is used if all solutions are feasible and no other constraints are given (like the number of routes, maximal length of the route and similar). If function combines route length with other parameters, the fitness function is calculated either with weighted sum of all parameters or simply by adding or multiplying the length with the penalty constant. This type of penalty is implemented when routes are not feasible [43–45,49,74]. Based on the goal of the experiment, other parameters can also be used to calculate the fitness. In research by Zhu [71] and Kamkar et al. [53] the number of routes played the vital role, so the fitness function is calculated using weighted sum of the total route length and the total number of routes. Few researches [43,53,66,72] are trying to limit the number of routes from one depot, so every route beyond the first one is also penalized – they are trying to minimize the number of vehicles used. Zhang et al. [68] uses an advanced fitness function where beside the number of routes, it also prefers the routes with minimal wasted empty space. One research [63] tries to minimize the overtime of the drivers, so it penalizes the routes which are too long. Another approach to evaluate the multi objective VRPs is shown by Moura [55] which uses Pareto ranking system instead of the simple sum or multiplication.The nature of VRP is such that it is easier to minimize the fitness (minimization problem), just because almost always the length of the routes is used in the fitness and almost always the goal is to find the shortest routes possible. In some cases researchers prefer to maximize the solutions. Simplest way to change this is to inverse the route length (1/length) like it was done in [70] by Alvarenga et al. Another method is shown in paper by Zhao et al. [60] where authors used ranking system to evaluate the solutions. The worst solution got the minimal rank (rank 0.8 is used in the research), the best solution is ranked with the maximal rank (1.2 used in the research) and all other individuals were rank in between. As we will see in the next chapter, this method of evaluating is useful when using the roulette wheel to select the individuals, because better solutions are not disproportionally favored.Selection phase is the process where the individuals are selected based on their fitness to mate and produce new offspring. There is no special selection method for the VRP problem and all of the methods described below are used on all types of GA problems. Most used method is the tournament method, where the numbers of randomly picked individuals compete in the tournament. Winner of the tournament and thus the selected individual is always the fittest individual from the tournament. The number of individuals competing in a single tournament is chosen by the researchers, but basically we can group the experiments in two groups. One group of researchers uses tournament where more than two individuals compete [46–48,53,56,59,66,70] and other experiments are done with the binary tournament, where only two individuals compete [49,58,65,67,71,75,77]. The larger the tournament size, more likely it is that the best solutions are included in the tournament and win.Another method used is the roulette wheel method [45,51,64,69,75]. In this method we simulate the game of roulette and choose the individual by throwing a ball in the wheel. Each individual occupies a spot on the wheel and the size of its spot is determined by the fitness of the individual solution – more fit the individual, more space it occupies on the wheel, higher are the chances of ball falling to its space. This method has a problem especially in the later stages of the evolution, where best individuals have disproportional larger space on the wheel and it is not unusual that the fittest individual occupies the half of the wheel. To solve this problem, some researchers use some kind of normalization techniques. One of these techniques is to rank individuals [49,60], where rank is the spot that the individual occupies on the list sorted by fitness – the best individual has a rank 1, and the worst individual has a rank k, where k is the size of the population. In general, two ranking based selection methods are used: linear and logarithmic ranking selection.Crossover is the process that mimics mating between two individuals with the goal of producing children. As in nature, also here those children take characteristics from both parents; it is just a matter of a method how to combine these characteristics. Which type of crossover do we choose is heavily relied on a type of genotype representation we have. Because most used genetic representation is with the arrays of indexes, most of the crossover algorithms invented is specifically designed for array crossover. We also observed that some researches use crossover in such a way that from every process two children are born, but other prefer just one child per crossover. We found no logical explanation of which one should bring better performance or better overall result.Most simple way to combine two arrays is to simply choose a random point in arrays and take first part from the first parent and the second part from the second parent – named 1-point crossover. As is expected, the resulting solutions can be infeasible, so researchers in the experiment by Drummond et al. [76] made a constraint that only feasible solutions may enter the new generation. Tie breaker crossover or 2-point crossover (2PX) expands previous one in such a way, that two points are randomly chosen. The middle part is exchanged [52,54,62,63,74], but also here the problem is that solutions are often infeasible. To overcome this problem, researchers Choi and colleagues [61] randomly insert missing genes in the middle part. Another version of this is Partially matched crossover (PMX) [77] where the indexes in the middle part are exchanged and the missing stops replace their matching index in the second parent [46,47,53,57,61,62,67,69,71]. Stop indexes are exchanged based on the mapping set, which is constructed by comparing the exchanging parts of two parents. This rather popular crossover method is depicted in Fig. 10, where gray part of the chromosome is the exchangeable part from which the mapping set is constructed. Next version of 2PX is the ordered crossover (OX) where the middle part (from point x to point y) comes from one parent and the second parent is swept from y+1 point circularly onward to complete the child [71,75] (see Fig. 9). Linear ordered crossover (LOX) is the version of OX where the genotype to chosen point is copied from first parent and the other part is completed from sweep of the other parent [49] (see Fig. 8).All crossover methods described until now have a tragic flaw, which is that they do not take routes into account. Indexes in arrays are copied and replaced without any regards to routes. This means that some routes may be split in half and others may not even be copied. Sometime a random stop is inserted into a route and fills the vehicle before it finishes the planed route. This can dramatically affect all further stops and routes in such a way that new random routes emerge instead of keeping the good ones.Next crossover operation is named route exchange crossover (REX) [50,65,73] and deals with the previous problem in such a way that one parent is a recipient. A child inherits most of the traits (routes) from the recipient, but also gets a small portion of genetic material (sub-route) from another parent, which is called a donor. Sub-route is chosen in such a way that no conflict emerges. Very similar crossover is also route based crossover (RBX) [66,78] where there is larger amount of genetic material copied from the second parent, not just one sub-route. In Fig. 11we can see that the second parent donates most of the genotype information to the child and its genes are shown before repair algorithm is run. The final iteration of this crossover is the Best Cost Route crossover, where the greedy repair algorithm is implemented [46,55,59], which does not only repair solutions so that they are feasible, but implements the local search algorithm, to find the best possible feasible repaired chromosome. Similar is the Alvarenga crossover, used by Wing and colleagues [59], is where child receives half of the routes from one and the other half from the other parent, and it regards that all inserted routes must be feasible. Left out customers are inserted using PFIH algorithm mentioned earlier. One would think that these types of crossovers bring better results, because no randomness is present in the merging of genotypes, but these kinds of crossovers have their own flaws. First of all they can take up more resources (processing time). Another and even more tragic flaw is that they enforce only feasible solutions, which means that in the REX algorithm, the new route that is inserted from the second parent must be just a permutation of previously overwritten route. In the case of RBX, there are much smaller chances of just permuting the route, but it can happen that some stop may be left out, so some kind of repair algorithm must be implemented, but this brings back the randomness from the array based crossovers.Route based crossovers deal with the problem of inheriting the routes, but can be very demanding in the computing time and memory space. So researchers [79,80,84] applied the edge recombination crossover (ERX), which combines two chromosome in such a way, that some logic remains from the parent chromosomes (Fig. 12). In ERX, algorithm combines genes in such a sequence that the genes remain neighbors with genes as were in parent genotypes. As is shown in Fig. 12, the neighbors are saved to the edge table and child is constructed in such a way, that these neighbor relations remain the same. One variation of this is pheromone based crossover [60] where researchers considered not only neighbors, but also lengths and adjacency relations on global account to combine genes.Some other researcher experimented with more unusual crossover operators. Method named cycle crossover (CX) identifies a set of cycles between two individuals in their chromosomes, then it copies these cycles alternately to children [43,65]. In [69] and [81] the authors mimicked the creation of a child in some species that do not mate, so their crossover process uses only one parent to generate new children.Mutation is an operator that serves as the mean to widen the search space for a small degree. In nature the mutation has a small chance of happening and the same is in the GAs, where researchers define a mutation probability factor. This factor has to be small enough because mutation brings randomness to the genetic principle. It is one of the easiest operators to implement and thus we have quite a lot of different mutation methods. The basic principle is to change a genotype (preferable just one or two genes) in just a fraction, but enough that this could mean the change for the better solution.Simplest mutation in VRP is the basic random exchange of two adjacent stops in the route. Based on the representation of the solution, some experiments implemented this mutation so that only feasible solutions prevail [63,76], but others make no effort to keep the solution feasible [52,54,55,62,71,74] (either because all solutions are feasible or by implementing the penalty factor into a fitness function). See Fig. 13for simple exchange mutation. Some researches [64,66] implemented a mutation, where the exchange could only happen in the same route.Another simple method is the insertion mutation, which removes the customer from its place and inserts it in a random place on the route in another position [50,57,65,67] as is shown in Fig. 14. Another very popular mutation is the inversion method, which is shown in Fig. 15. Here a part of the chromosome is inversed [45,46,49,50,53,57,67,73,82] – this mutation effects the solution in much higher rate than the simplest exchange. Smaller type of inversion is the swap mutation, where only two consecutive customers change their spots [45,47,50,57,67]. See Fig. 16for swap mutation. Another mutation is the route insertion, where the part of the route (consecutive customers) is removed and then inserted in the random place [50,66], and [78]. And again, the exchange was also implemented on the sub-routes level [49,65,66,78], where few consecutive customers are exchanged in the same route. Experiments [59,65,70] implemented one of the very interesting mutations – route merge. This one tries to merge two routes in a random way and, if any customers remain unattended, they are inserted in the random position. In the research [63,65,66,70] they also experimented with the route split, where the random place on the sub-route is chosen and the route splits into two smaller routes on that position.Until now, the described mutation methods could make solutions better and they could also corrupt the solution – lower their fitness value. Next group of mutation methods searches exclusively for better solutions. Researchers Berger and Barkaoui in [64] used a genotype representation where infeasible solutions could occur and they penalized them in the fitness function, but they also implemented a mutation operator, which finds the illegal stop and find a legal place on the route for it. Mutation can only be made on selected individuals, as in the research by Zhang et al. [68] where the mutation was allowed only on unfeasible individuals. Haghighi et al. [54] also limited the mutation process, but only on the solutions with low fitness. Alvarenga et al. made an experiment [70] that exchanges two customers in such a way that only better solution is accepted. The route exchange was also done with the constraint of accepting only better solutions [49,65]. Well used mutation operator is also the 2-opt exchange, where the algorithm finds routes which have paths that cross each other and tries to reinsert the customer in such a way that route crossing does not occur [49,59,60], and [72]. Heuristic approach has been used in the local search mutation [69], where selected individual goes through the process of finding optimal order on its sub-route. Local search optimization mutation is presented in Fig. 17. More radical variation of this, called global search optimization mutation, is when the local search algorithm optimizes all of the routes.Besides the previously described operators of selection, crossover and mutation, sometimes the researchers implement some of the nonstandard operators with a goal of improving the final result or the speed of the algorithm. Some of them copied the natural process and other are not based on them but are truly artificial methods. Let us start with the very popular elitism operator [46,54,58,65,68,70,71,81,82]. Elitism is a process that ensures the survival of the best intermediate solutions, so they are not lost through the evolutionary processes. Researchers define the number (usually very small, equal or below 15%) of the best solutions that automatically advance to the next generation. These elite individuals still act in the process of selection for the crossover method. In contrary to elitism, one very similar method is to combine the offspring with the old generation in such a way that the new generation consists from the best of each set [66]. A variation of this method is when algorithm does not build a new population but constantly updates the old one. In the researches [43] and [45] they used this method, when each new child is compared to the worst of the generation and replaces it, if it is better, otherwise it is ignored.As we saw in the previous sections, some versions of GAs enforce the feasibility of the solutions, either by using such a representation, that all solutions are feasible or by employing the next operator – the repair operator. Repair algorithm runs after the crossover and the mutation operators and ensures that all individuals remain feasible. This is usually done with the greedy search algorithms [61,74] which exchange stops and reorder routes so that solutions are feasible. Besides repairing the solutions heuristics can be implemented to optimize the solutions, which is usually done with the local search [47,48,59,62,65,67,69,73,75] or with the PFIH algorithm (already described in the section about initial population) [59]. Heuristics can be used to cluster the stops in clusters which are then serviced each by their nearest depot [54].Another interesting approach is to divide the population into groups which cannot interact with each other during the whole process. First version is to make “islands” of the population and from time to time let them exchange some individuals (like migration) to diversify the population [51,78]. On all of the islands, the process of the evolution is the same. Second method of division is with the cellular GA which was used in the paper by Kamkar et al. [53]. Here, where the individuals may only interact (crossover) with their immediate neighbors. This slows down the process of getting the optimal solutions, but the chance of converging to the local optimum and not the global one, is much smaller. Interesting approach was used by Li and Liu [83] where they mimicked the antibodies found in the living organisms. This method prevents the mating of too similar individuals thus preventing the domination of one type of genotype in the generation.To fight the premature convergence to local optimum, researchers in the researchers Salhi and Petch [63] used the injection method, where every N generation, new random individuals are inserted into population. The usefulness of this method remains debatable, because new individual would likely have much lower fitness due to randomly generated genotypes. This means that these new individuals could likely be wholly ignored by the selection process. In the name of the same goal to prevent reaching local optimum, a constraint can be implied to forbid the clones in the population [49,74,75]. This process can run on multiple levels: during the crossover and mutation or after these two processes. This method has its flaw; it can occasionally lead to prematurely terminating evolution, because a unique individual cannot be found. This can happen in too small populations.The whole process of evolution has to end at some point and a few options are used in the literature. First option is to end the evolution process after the limited time running, just like it was done by Berger and Berkaoui [64] with the limit of 1800s of evolving. The second option is the limit of the generations. Researcher Zhu [57] limited its process to maximal 1000 generations, while Skok and colleagues [43] used up to 50,000 generations. The next option is to have a constant overview of the best individuals in each generation and stop the evolution after the best individual has not change for some time. In research by Zhu [71] the process of evolution is stopped if the best individual stays the same for 30% of the generation limit. This option is particularly useful in case that the process of evolving basically stagnates – local optimum is reached, and the improvement can only be seen with the randomness of mutation. Some experiments combine the described ending criteria as in the case of the research [71]. Researchers Skok et al. [43] stopped the evolution process when almost the whole population converged to one solution – when 95% of the population was the same.To thoroughly test, evaluate and compare the variety of genetic approaches for solving MDVRP, we have implemented a working GA with various methods of selection, crossover and mutation described in literature. For the genotype representation we chose the most common representation of VRP, which is in a form of array. In our experiment each customer is given its own unique id and the array consists from the ids of customers. Next we implemented the method of mapping the genotype into the real solution (phenotype). Here we took the serial approach, where we start with the vehicle from the first depot and visit following customers until that vehicle is full or it cannot take in the cargo from the next customer. That vehicle then returns to its home depot and the vehicle from the next depot starts with the following customer. This repeats circularly, so that same depot can send out multiple vehicles, until all the customers are served. This method has one advantage – all solutions are feasible and no repair algorithm is necessary. Because we have no infeasible solutions, our fitness function can be simply the total sum of all routes. Each individual's fitness is calculated after its creation and mutation methods. We limited the size of the population to 300 individuals.We have implemented three different selection methods. The first one is the tournament method, which can host any number of competitors. Tournament method first picks a number of individuals from the population at pure random and then compares their fitness levels. The winner of the tournament is the fittest one. The second method implemented is the roulette wheel method. We pictured the wheel with the array of integers, where the content of each cell is the id of the individual. The worst individual in the population writes its id in only one cell. All other solutions write their ids in the X number of cells, where X=fitnessx/fitnessworst. At the final step the algorithm randomly selects one cell with the id and the individual with that id is selected. The next selection method was ranking selection, which is basically the same as roulette wheel, just the number of cells that one individual writes its id in is based on the rank within the fitness sorted population and not on the fitness value of the individual. We tried two variations of this selection to find the best suiting for the problem: linear and logarithmic ranking. The first one is where the number of cells that one writes its id in grows linearly. The second variation gives more chance to above average solutions – number of cells grows logarithmically, so that the best solutions have almost the same and big chance of being picked for the mating while the worst solutions have only minimal chance.When parent individuals are selected, comes the process of mating. We implemented few methods of crossover and compared them. The first crossover method is the order crossover (OX), the second is the linear ordered crossover (LOX), then the cycle crossover (CX), then the popular partially matched crossover (PMX) and finally the edge crossover (ERX). First two crossovers – the LOX and OX were chosen because majority of the implementations use one of these two crossover methods – probably because of the ease of implementation. The PMX is also one of the popular methods, but we will see if it lives up to its popularity in comparison to other types. The CX and ERX are more advanced methods and are in the comparison to test if there is even a reason to implement these advanced methods. Especially ERX method is implemented in such a way that it uses heuristics more than any other method above. In our implementation, the crossover happens always – there is no chance that mating process could not happen and parents could directly advance the next generation.Next, the mutation process occurs. Similar to previous operators, we also implemented few different methods of mutation. We chose to test all of the most popular ones and see if the mutation technique brings any difference to the final result. In our experiment we limited the chance of mutation to 10%, which is the number often used in literature. Mutation methods tested were: inversion, swap, insertion, exchange and two heuristic methods – local search optimization of one of the routes and local search optimization of the whole solution (we named it global search optimization). As in crossover, we could expect that heuristic approaches would return the best results, but the doubt remains, because these methods tend to change an individual the most.Other parameters in experiment were as follows. All of the children become the new population, with the mix of the few elite individuals from the previous generation. We copied the 10% of the best individuals directly to the next generation. No other operator was implemented. We repeat the whole process for 2000 generations, without any other stopping criterion, like stopping when the best solution stagnates. The best individual after 2000 generations is considered the final solution, obtained by the algorithm.The purpose of the implementation of the GA with various genetic operators was to test and compare different methods from each of the genetic. In our experiment each algorithm setting was launched on five standard benchmark problems (from p01 being the smallest to p06 being the hardest problem) for 10 times in order to obtain trustworthy results. A single result of one run for a specific algorithm/setting represents the fitness value (the overall length of all the routes) of the final solution (the best individual in the last generation). Average results of all runs for each used method and/or algorithm setting are presented below.Because all five benchmark problems are quite different from each other (ranging from the smallest p01 up to a much bigger p06), the obtained results differ quite a lot between these problems. For this purpose, besides providing the absolute fitness values, also the ranks of the methods for a single benchmark problem are provided.In each category, the comparison of different methods has been made also by performing statistical tests. Because of the non-normal distribution of results, the (non-parametric) Friedman test was used for the comparison of several methods using Bonferroni correction and Nemenyi post hoc tests to determine whether the difference between them is statistically significant (at p<0.05) [84].First we tested the selection operators. As mentioned before, we implemented five different methods: tournament with two competitors (binary tournament), tournament with five competitors, roulette wheel, linear ranking and logarithmic ranking selection. The rest of the parameters were as follows: exchange mutation with 10% probability of happening and ordered crossover (OX) on the population size of 300 individuals for 2000 generations. The elite number of individuals which automatically advance to the next generation was set to the 10% of the population size.The results for each of five selection methods (averaged values of the final solutions from 10 independent runs) on five used benchmark problems are presented on Fig. 18. The logarithmic ranking selection scored worst on all five benchmark problems. The rest four selection methods achieved the same ranking order on all but the smallest benchmark problem: linear ranking selection scored the best, following by the binary tournament, tournament with five competitors and roulette wheel selection. In the case of the smallest benchmark problem (p01) all the results (with the exception of the worst logarithmic ranking) were practically the same. It must be noted though that the best three selection methods achieved quite similar results, while roulette wheel and logarithmic ranking selection achieved much worse and almost equal results. Averaged ranks of all the used selection methods are presented in Fig. 19.The statistical comparison of the results just confirmed that linear ranking selection and binary tournament achieved significantly better results than all the other methods, while the difference between them two is not statistically significant.From the computing performance point of view, the tournament with five competitors was extremely fast at getting to the best solution, but probably has a greater chance of getting settled at the local optimum. If the goal is to find the solution very quickly, tournament with multiple competitors should be used. Linear ranking method, on the other hand, had relatively slow convergence to the optimal solution, but the chance of premature convergence to local optimum instead of finding the global one is drastically lower in comparison to the tournament with 5 competitors.Next we tested the crossover methods. We have implemented five methods of crossover. They were chosen based on the popularity from the existing literature and based on the chosen (by far most common) genotype representation, because not all crossovers are compatible with the id array representation. The implemented crossover methods are: ordered crossover (OX), linear ordered crossover (LOX), partial mapping crossover (PMX), cyclic crossover (CX) and edge recombination crossover (ERX). The rest of the parameters were as follows: binary tournament selection and exchange mutation with 10% probability of happening for 2000 generations of 300 individuals. Like in the entire experiment, the chance of crossover was 100% and elite size was set to 10% of the whole population size.The results for each of five crossover methods (averaged values of the final solutions from 10 independent runs) on five used benchmark problems are presented on Fig. 20. In the case of crossover methods, the differences are not as obvious as in the case of selection. The method that differs the most from the others is the edge recombination crossover (ERX), which provided the best solutions for two smaller problems (p01 and p02) and the worst for the two biggest problems (p04 and p06). On the other hand, the ordered crossover (OX) can be regarded as the most successful method in this test, as it was ranked among top 3 methods in all five problems and winning in two of them (p03 and p04). The closest to OX and also very successful in this test was partial mapping crossover (PMX).On most benchmarks the OX and PMX crossovers performed well and were most of the times the best or very near to the best found solutions. The ERX, which scored the most uneven to others, puts genes near the previous neighbors and therefore keeping some logical order from parent solutions. It does not copy routes directly like other methods but it puts the genes in the familiar neighborhood. Results show that this works pretty well on smaller problems, where there are no problems in preserving some logical order from both parents. The cyclic crossover (CX) is the method which tries to keep previous routes the most of all of the tested methods, but it does not seem to bring a big success. LOX and OX methods copy a part of the route, keeping some logic from parents and just filling the gaps with some randomness. LOX method is basically just a sub process of OX, where the starting point is the first gene in the chromosome. This is also its weakness because the probability of some gene getting copied is much more uneven through the whole chromosome as in the OX.Averaged ranks of all the used crossover methods are presented in Fig. 21. Also here it can be seen that OX achieved the best average rank followed by the PMX. The CX achieved almost identical average rank as ERX, although its results in single benchmark problems were much more similar to other methods. The worst average rank achieved the linear ordered crossover (LOX). Although the only statistically significant difference was confirmed between LOX (as the worst method) and OX and PMX (as the two best methods), it can be concluded that simpler crossover methods, like OX or PMX, probably bring the best and most stable results. It should be also noted, however, that the size of the problem should be taken into consideration when choosing the appropriate crossover method, as it impacts the results of (at least some) crossover methods quite importantly.Let us continue with the comparison of the mutation methods. We tested and compared most commonly known and used mutation approaches – four general mutation methods: exchange (EX), insertion (INS), inversion (INV), and swap (SWP), two heuristic improvement mutation methods: global search (GS) and local search optimization (LS), and also the case when no mutation is used (NO). The parameters for these two tests were set as follows: binary tournament selection, ordered crossover (OX), population size of 300 individuals for 2000 generations, the mutation probability of 10% and the elite of 10% of the population size. As the two heuristic search optimization approaches (GS and LS) take a considerable amount of time for each generation, the total amount of time was limited to twice the time of the slowest general mutation method. In this manner, only between 100 and 200 generations were evolved in bigger benchmark problems for GS and LS approaches instead of 2000 for other methods. As the final solutions, the best obtained individuals up to this point were used. We believe this comparison is fair, as the intermediate improvement mechanisms such as GS and LS include some characteristics of exact methods and therefore should only compete with true genetic approaches within the same limited resources environment.The results for each of seven mutation methods (averaged values of the final solutions from 10 independent runs) on five used benchmark problems are presented on Fig. 22. Following the Pareto principle, it can be easily seen that SWP, GS, LS and no mutation are worse than the other three methods (EX, INS, and INV) as they scored worse in all five benchmark problems. From the best three mutation methods, EX can be considered the best, as it achieved the best result in four out of five benchmark problems and ranked third only in the case of the smallest problem (p02). Not far behind on the second spot lies INS that scored one best and four second best results.Averaged ranks of all the used mutation methods are presented in Fig. 23. The trendline of the ranks clearly shows that EX and INS could be considered the best mutation methods. Even more, the statistical comparison revealed that the two are significantly better than all of the other methods. Even though no statistically significant difference between EX and INS were established, the difference was so big (p=0.056), that EX can be declared the sole winner of this test.Obvious pattern can be seen in the charts above (Figs. 22 and 23). They show that the two heuristic operators are lacking behind, together with no mutation approach. We suspect that this is the consequence of changing the individuals too much and thus converging to the local instead to the global optimum. Heuristic operators optimize individuals, but apparently such improved individuals have too much advantage in the selection process. The results indicate that less invasive the operator of mutation is, the better are the results – the simplest exchange and insertion brought the best results. Very poor results of the approach without the mutation operator prove that the mutation does actually contribute importantly to the final results. The test without mutation preformed the worst of them all – probably because the mutation operator widens the search perimeter and the individuals are found that could not be found with only the crossover process. The best mutation method is clearly the exchange mutation, where two genes are exchanged. It is our belief that this is because it is the least invasive algorithm. Two stops change their position in linear order of the route and because of such a small change there is only a small possibility that other routes will get changed. Insertion, which is the second best algorithm according to the experiment, takes one stop and insert it in another place and possibly in another route and therefore some routes may change, because of the capacity constraints of the vehicles. All other methods cause bigger changes to an individual being mutated.In the next test we tried to find the optimal mutation probability. The theory suggests that if the probability is set too high, too much randomness is mixed into solutions, but if the chance of mutation is too low, some search space may be left undiscovered and the optimal solution may be missed. For the test we used the same parameters setting as in the previous comparison of different mutation methods, and the exchange mutation (EX) method was always used. Averaged ranks of the results obtained with different mutation probability settings are presented in Fig. 24. We may see that using no mutation scored by far the worst results, confirming the finding from the previous test. On the other hand, 25% and 30% of mutation probability showed the best results. These are the only two settings, which scored among top 6 (out of 11) in all five benchmark problems and among top 3 in the majority of problems (25% scored among top 3 in four cases and 30% in three cases).Also the statistical tests confirmed these findings. The approach with no mutation was significantly worse than all the other settings. The approaches with mutation probability of 25% and 30% on the other hand significantly differ from five other approaches each (0–15% and 50%). Although the difference between these two approaches and the rest (20%, 35–45%) is not statistically significant, we may conclude that they should be preferred in the majority of cases, which is also clearly indicated by the trendline analysis shown in Fig. 24. Based on these results we could not recommend the mutation probability higher than 35% or lower than 20%, as too much mutation could cause uncontrollable randomness and too less mutation insufficient search space.Finally we compared GAs to other known methods for solving MDVRP. For the comparison, the results obtained by different methods on a set of standard benchmark problems by Cordeau were used. The five most commonly used benchmark problems out of 23 existing in the whole set were used in our comparison. Methods from all fields of MDVRP optimization were chosen. First one is an exact algorithm that works very well on smaller problems [85]. The advantage of the exact method is that it always provides the optimal solution, but for the price of extreme computational complexity. In this comparison, the results of all of the other methods were compared with these optimal ones. Next, the standard tabu search algorithm CGL by Cordeau, who also developed the benchmark instances, was included [24]. One more classic tabu search algorithm is the classic FIND algorithm by Renaud and Laporte [24]. The upgraded tabu method named parallel iterated tabu search (ITS) from paper by Cordeau and Maischberger [86], which got impressive results on all tests, was also included. Next were two ant colony algorithms: ACO by Dorigo[87] and its variation ACO-WM which has a mutation operator just like in GA [88]. The best of the ant colony algorithms at the moment is PIACO algorithm by Yu et al. [89], so we included it into our comparison. Furthermore, a heuristic method which uses the Adaptive Large Neighborhood Search (ALNS) framework to solve routing problems from paper by Pisinger and Ropke [90] was included. First evolutionary method in the comparison was the genetic clustering (GC) method by Thangiah and Salhi [40]. Finally, two GA methods in the comparison were by Ombuki-Berman and Hanshar (GA1) [25], and Surekha and Sumathi (GA2) [91], which are considered as leading among GA methods for solving MDVRP. The results obtained by all these methods on five standard benchmark problems are presented in Table 1.As we can see from the results in Table 1, the GA methods did not provide the optimal solutions, but they find very good solutions very efficiently and as discussed earlier, finding adequate (good enough) solutions in a short time frame is the ultimate goal of GAs. Especially when the problem size is growing, GAs are getting better in comparison to other algorithms. When comparing the computing times of all of the methods, the exact methods expectedly trail way behind all heuristic methods. Because VRP is a NP hard problem, the computing resources and time exponentially grow with the exact algorithms as the problem gets larger, but only grow with the linear scale using the GAs.

@&#CONCLUSIONS@&#
