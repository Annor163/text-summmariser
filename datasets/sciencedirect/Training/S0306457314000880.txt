@&#MAIN-TITLE@&#
Sentiment, emotion, purpose, and style in electoral tweets

@&#HIGHLIGHTS@&#
We automatically compile a dataset of 2012 US presidential election tweets.We annotate the tweets for sentiment, emotion, style, and purpose.We show that the tweets convey negative emotions twice as often as positive.We describe two automatic systems that predict emotion and purpose in tweets.

@&#KEYPHRASES@&#
Sentiment analysis,Tweets,Elections,Emotions,Purpose,Crowdsourcing,

@&#ABSTRACT@&#
Social media is playing a growing role in elections world-wide. Thus, automatically analyzing electoral tweets has applications in understanding how public sentiment is shaped, tracking public sentiment and polarization with respect to candidates and issues, understanding the impact of tweets from various entities, etc. Here, for the first time, we automatically annotate a set of 2012 US presidential election tweets for a number of attributes pertaining to sentiment, emotion, purpose, and style by crowdsourcing. Overall, more than 100,000 crowdsourced responses were obtained for 13 questions on emotions, style, and purpose. Additionally, we show through an analysis of these annotations that purpose, even though correlated with emotions, is significantly different. Finally, we describe how we developed automatic classifiers, using features from state-of-the-art sentiment analysis systems, to predict emotion and purpose labels, respectively, in new unseen tweets. These experiments establish baseline results for automatic systems on this new data.

@&#INTRODUCTION@&#
Elections, the cornerstone of democratic process, occur across the globe and often involve tens of millions of potential voters. Social media platforms such as Twitter give new opportunities to the electorate, the politicians, news corporations, and other participants to make their voice directly accessible to a large audience. However, the number of posts pertaining to a single event or topic such as a national election can grow to the hundreds of millions. The large number of tweets negates the possibility of a single person reading all of them to gain an overall global perspective. Thus, automatically analyzing electoral tweets, and specifically, analyzing sentiment and emotions in electoral tweets, can be beneficial for a number of downstream applications:•Understanding the role of target entities: A number of entities tweet during elections, for example, the politicians, the voters, the disenfranchised, news corporations, non-governmental organizations, special interest groups, etc. Analyzing the extent to which tweets from various entities help shape public sentiment will improve our understanding of how social media is used during elections. It is also of interest to identify which portions of the voting electorate tweet about politics during elections. For example, some studies have shown that the more partisan electorate tend to tweet more, as do members from minority groups (Lassen & Brown, 2011).Determining how public sentiment is shaped: Some tweets (or some sets of tweets) have more impact in shaping public opinion than others. Determining characteristics of influential tweets is particularly useful.Nowcasting and forecasting: Tweet streams have been shown to help identify current public opinion towards the candidates in an election (nowcasting) (Conover, Goncalves, Ratkiewicz, Flammini, & Menczer, 2011; Golbeck & Hansen, 2011). Some research has also shown the predictive power of analyzing electoral tweets to determine the number of votes a candidate will get (forecasting) (Bermingham & Smeaton, 2011; Lampos, Preotiuc-Pietro, & Cohn, 2013; Tumasjan, Sprenger, Sandner, & Welpe, 2010a), however, other research expresses skepticism at the extent to which this is possible (Avello, 2012).Identifying key electoral issues: Electoral tweets can be analyzed to determine the extent to which voters are concerned about particular issues. For example, does the electorate value economic development much more than environment protection, and to what extent? Other related problems include identifying contentious issues (Maynard & Funk, 2011) and detecting voter polarization (Conover et al., 2011).Impact of fake tweets: Often during elections there is an increase of artificially generated tweets from twitterbots, botnets, and sock-puppets. Understanding the impact of these tweets on public sentiment and automatic methods to filter out such tweets are both important research problems.Contributions of this work: Traditional information retrieval systems usually identify facts such as what a person is doing, at what time, in what location, etc. In this paper we analyze electoral tweets for more subtly expressed information such as sentiment (positive or negative), the emotion (joy, sadness, anger, etc.), the purpose or intent behind the tweet (to point out a mistake, to support, to ridicule, etc.), and the style of the tweet (simple statement, sarcasm, hyperbole, etc.). To our knowledge, this is the first tweets dataset annotated for all of these phenomena. We also developed two automatic statistical systems that use the annotated data for training and predict emotion and purpose labels in new unseen tweets. These experiments establish baseline results for automatic systems on this new data.Data Annotation: We designed two detailed online questionnaires and annotated the tweets by crowdsourcing to Amazon’s Mechanical Turk.1https://www.mturk.com/mturk/welcome.1We obtained over 100,000 responses from about 3000 annotators. We present an extensive analysis of the annotations which lend support to interesting conclusions such as electoral tweets almost always express the emotion of the tweeter as opposed to somebody else’s, the predominant emotion in these tweets is disgust followed by trust, electoral tweets convey negative emotions twice as often as positive emotions, and that different intents of tweeting may be associated with the same emotion. All the data created as part of this project: about 100,000 responses to questions about emotions, purpose, and style in electoral tweets are made available:http://www.purl.org/net/PoliticalTweets2012.Automatic Classifiers: We developed a classifier for emotion detection that obtains an accuracy of 56.84%. We show how the stimulus identification task can be framed as a classification task that circumvents more complicated problems of detecting entity mentions and coreferences. On this stimulus classification task, our supervised classifier obtains an F-score of 58.30.We show that emotion detection alone can fail to distinguish between several different types of purpose. For example, the same emotion of disgust can be associated with many different kinds of purpose such as ‘to criticize’, ‘to vent’, and ‘to ridicule’. Thus, detecting purpose provides information that is not obtained simply by detecting sentiment or emotion. We developed a preliminary system that automatically classifies electoral tweets as per their purpose, using various features that have traditionally been used in tweet classification, such as word ngrams and elongated words, as well as features pertaining to eight basic emotions. We show that resources developed for emotion detection are also helpful for detecting purpose. We then add to this system features pertaining to hundreds of fine emotion categories. We show that these features lead to significant improvements in accuracy above and beyond those obtained by the competitive preliminary system. The system obtains an accuracy of 44.58% on a 11-class task and an accuracy of 73.91% on a 3-class task. The various emotion lexicons are made freely available.2http://www.purl.org/net/NRCEmotionLexicon.2The rest of the paper is organized as follows. In Section 2, we present related work. Section 3 presents the data annotation step and also a detailed analysis of the annotations obtained. In Section 4, we describe an automatic classifier for detecting emotions (Section 4.1), an experiment showing that emotion detection although related to purpose detection is in fact a different task (Section 4.2), and finally a classifier for detecting purpose (Section 4.3). Section 5 presents conclusions and directions for future work.

@&#CONCLUSIONS@&#
Given that social media is playing a growing role in elections world wide, automatically analyzing posts on platforms such as Twitter has a number of applications such as determining support for political parties or candidates, identifying stance of various groups on key electoral issues, determining amount of voter polarization, detecting impact of mass tweets from political parties and Twitter bots in shaping public sentiment, etc. A useful resource in developing such applications is a dataset labeled for various affectual phenomena. Here, for the first time, we collected and annotated a common dataset (2012 US presidential elections tweets) for a number of labels pertaining to sentiment, emotions, style, and purpose. We designed questionnaires specifically for annotation on a crowdsource platform. We analyzed the data to show that electoral tweets are rich in emotions and mostly convey the feelings of the tweeters themselves. The predominant emotion in these tweets is disgust followed by trust. Electoral tweets convey negative emotions twice as often as positive emotions.We also developed supervised automatic classifiers for detecting emotional state, emotion stimulus, and purpose (or intent) of the tweets. These classifiers used many of the annotations described above for training. The results establish baselines for automatic systems on this new data. We show that even though the purpose classifier benefits from emotion features, emotion detection alone can fail to distinguish between several different types of purpose. For example, the same emotion of disgust can be associated with many different kinds of purpose such as ‘to criticize’, ‘to vent’, and ‘to ridicule’. Thus, detecting purpose provides information that is not provided simply by detecting sentiment or emotion.All of the electoral tweets and associated annotations are made freely available.16http://www.purl.org/net/PoliticalTweets2012.16One of our future goals is to use the data to create an automatic system to detect exaggeration. In this paper, we relied only on the target tweet as context. However, it is possible to obtain even better results by modeling user behavior based on multiple past tweets. Another avenue for future research is to compare electoral tweets from different countries, for example, it will be interesting to determine if the distributions of tweets by purpose differ across developed and developing world. We are interested in using purpose-annotated tweets as input in a system that automatically summarizes political tweets. We are also interested in automatically identifying other semantic roles of emotions such as degree, reason, and empathy target (described in Table 1).The histograms of the annotations from Questionnaires 1 and 2 are shown in Tables 15 and 16. Note that since the tweets with gold questions were used for quality control by CrowdFlower, some tweets were annotated more than three times in Questionnaire 1 and more than 5 times in Questionnaire 2. Only tweets with at least three annotations for Questionnaire 2 and with sufficient agreement among the annotators for emotional state, emotional stimulus, and purpose were used as training and test instances in the automatic classification experiments.