@&#MAIN-TITLE@&#
E-quality control: A support vector machines approach

@&#HIGHLIGHTS@&#
This work uses innovative methods in e-quality with the application of SVM.Many potential benefits of e-quality control have been presented and instantiated.The classifier equations are built on the data obtained from the experiments.A detailed analysis is presented for six different case studies.The results indicate the robustness of proposed SVM classification.

@&#KEYPHRASES@&#
Support vector machines,Part classifications,Remote inspection,Networked robotic station,e-quality,

@&#ABSTRACT@&#
The automated part quality inspection poses many challenges to the engineers, especially when the part features to be inspected become complicated. A large quantity of part inspection at a faster rate should be relied upon computerized, automated inspection methods, which requires advanced quality control approaches. In this context, this work uses innovative methods in remote part tracking and quality control with the aid of the modern equipment and application of support vector machine (SVM) learning approach to predict the outcome of the quality control process. The classifier equations are built on the data obtained from the experiments and analyzed with different kernel functions. From the analysis, detailed outcome is presented for six different cases. The results indicate the robustness of support vector classification for the experimental data with two output classes.

@&#INTRODUCTION@&#
It is more likely that the rapid advancements in sensor, computer, communication, and information technologies are bringing about the fundamental changes in manufacturing settings. This includes fully-automated, 100% quality inspection that can process a large amount of measurement data [1–6]. Other production related activities and business functions will be also integrated into the company information management network, which guarantees the instant access to critical production data for enhanced decision making [7–9]. This new approach is referred to as e-quality control, and one of the enabling tools is the ability to predict the variations and performance losses during the various production stages. This means that the traditional quality control scheme, which relies on sampling techniques, would be replaced by the sensor-based, automatic, computerized inspection methods that provide the unprecedented level of data processing and handling. Since the production equipment is integrated into the network, the condition of the machines can be monitored, while the product quality from specific machines can be instantly identified. In order to test the new quality control approach, the authors have developed a networked quality control station. This includes two network-accessible assembly robots, two networked vision sensors, and other ancillary equipment which constitutes the cell. The overall setting of the system is presented inFig. 1.The vision sensors see the part and measure the dimensions. The captured image has 640×480 pixel size and the analysis results are produced by the computer algorithms. Part gauging is established by using a pattern matching technique. For each part, the vision sensor conducts the pre-defined quality control tasks, and sends the information to the awaiting robot. If the part passes the quality standard, it will be picked up by the robot and dropped into the bin. Otherwise, the bad parts will be carried away by the conveyor belt. The picture of entire setup is shown inFig. 2.In the context of e-quality control, the objective of this paper is to apply the machine learning approach in the form of support vector machines (SVMs) to predict the outcome of the part classification. Data obtained from the remote inspection experiments will be analyzed using SVM classifier equations to build a model, which can be used for predictions (i.e., good vs. bad quality). The motivation behind this work is to build robust classifiers, which can sort the incoming parts based on the vision-sensor generated dimensional data into the predefined groups in an automated way.

@&#CONCLUSIONS@&#
This section presents the important findings that can be drawn from the analyses. The purpose of this research was to develop a support vector classifier model based on the experimental data in order to facilitate the process of e-quality control. The study was conducted under the following assumptions. (1) The data used for analysis contained 138 different cases, which were obtained by running the experiment with different test samples. (2) The model selection for training parameter C was based on the v-fold cross validation approach. (3) The range of training parameter C values included 0.01 to 500, where much higher values in the order of four digits and five digits can also be used based on the characteristics of data. (4) The parameters of the kernel functions were assumed based on the trial and error, to obtain the best accuracy level. After analyzing the data obtained using SVM classifiers and testing the accuracy levels using different kernels, the following conclusions can be drawn. Since the SVMs produced good classification results for data with binary outcome, the results achieved for this data were significant. The highest testing rate of 93% was achieved, when using Linear, Polynomial and RBF kernels in different cases. Polynomial kernel of second degree and RBF kernel with gamma values had slightly higher training rate values. Among all cases, the RBF kernel with a gamma value of 2 is identified as the best performer, as it has the lowest number of support vectors used in the classification method. Heuristically, a less number of support vectors signifies the robustness of the classifier. However, this might not be true in all cases, since it also depends on the number of bounded support vectors, which are located between the margins. The value of the training parameter ‘C’ identified as 376 for the RBF kernel also satisfies the basic necessity for selecting the ideal training parameter. If ‘C’ is too small, the insufficient stress will be placed on fitting the training data. If it is too large, the algorithm leads to over fitting the data. As to the data size, even though the available data are not large, it is adequate for the research. It may have a better result (i.e., a better predict accuracy) with the larger data sets. Basically, there are also problems in dealing with the big data, such as over fitting and outliers. Moreover, the proposed model may be insensitive only given by certain data sets. In other words, different data sets may lead various “optimal” models. Consequently, it is suggested that pre-processing effort could focus on eliminating bias, particularly pre-existing pattern data prior the use of SVM classification. One of the future works could dedicate to develop a better model, which may be hybrid in nature through combining different approaches (i.e., SVM and non-SVM) and/or fusing different kernel functions under feasible conditions. Another future work might be to realize the equality in the dynamic environments. The new algorithm will be affected by the dynamic data, when setting the parameters automatically to optimize the models.