@&#MAIN-TITLE@&#
Generalizing the advancing front method to composite surfaces in the context of meshing constraints topology

@&#HIGHLIGHTS@&#
A new automatic mesh generation algorithm over composite geometry.An extension of the advancing front method.Applied in the context of meshing constraints topology (virtual topology).Allows the automatic simplification (defeaturing) of CAD models.

@&#KEYPHRASES@&#
Advancing front,Mesh generation,Mesh adaptation,Composite geometry,Virtual topology,Defeaturing,

@&#ABSTRACT@&#
Graphical abstract

@&#INTRODUCTION@&#
Progress towards a better integration between finite element analysis (FEA) and computer aided design (CAD) has greatly reduced the median time requirements to prepare FEA models  [1]. One of the key steps in the integration between CAD and FEA is automatic surface meshing, because, in most approaches, filling the FEA domain with volume elements (tetrahedrons or hexahedrons) is based on a previous discretization of the domain’s boundary and because the quality of this discretization has a major effect on the quality of the resulting three-dimensional (3D) mesh with volume elements and on the reliability of the FEA solution. Surface meshing  [2–10] has been investigated by many researchers for the last 20 years. It can basically be performed either on a collection of trimmed parametric patches (like when meshing the faces of a B-Rep model) or on a tessellated representation of geometry (an STL file for example), and it can either be directly generated on surfaces in three dimensions or indirectly generated in the parametric space and then mapped in three dimensions  [11]. However, the automatic generation of surface meshes from CAD models and consequently the way the integration between FEA and CAD still faces several problems, especially when these CAD models feature many small shape details, and when their boundary representation (B-Rep) contains a large number of faces, many of them being eventually much smaller than the desired FE size. Such configurations are likely to be at the origin of either poorly shaped elements and/or over-densified elements, not only increasing the analysis time, but also producing poor simulation results or meshes incompatible with solver requirements. Applying geometry simplification and virtual topology techniques to these configurations has proven to be a very interesting option.Efforts have been made, aimed at avoiding poorly shaped elements and over-densified mesh elements generated from raw CAD models  [12–16]. In these approaches, well-known mesh topological transformations perform mesh element removal (e.g. decimation of surface meshes) or collapsing faces of tetrahedrons to remove these tetrahedrons. These transformations can be applied on the mesh itself or on a discrete representation of geometry, as proposed in  [17]. One limitation of these operators lies in the fact that collapsing operations are not intrinsically suited for the removal of through holes, which means that these operators require complex extensions when applied to real-life industrial parts. Therefore, removing holes may require specific processing such as manually removing these details in the CAD model. Element distortion (poorly shaped elements) and over-densified mesh elements are also closely related to the input mesh sizing objectives. Setting up appropriate mesh sizing objectives  [18–20] can actually contribute to lowering the element distortion and to avoiding over-densified mesh elements.Other approaches consist of adapting CAD models directly. For example, feature recognition and extraction processes can be intended to simplify details like fillets and blends  [21,22], bosses, pockets  [23], and holes. Some of these approaches generate tree-structured simplified models, in which each simplification is identified as a feature. Lee et al.  [24] propose a feature removal technique which starts from a feature tree and provides the ability to suppress, and subsequently reinstate features, independently from the order in which they were suppressed, within defined limitations. Another alternative is applying geometry transformation with the use of CAD kernel operators aimed at locally modifying the topology and/or underlying geometry in the B-Rep model [22,23,25]. Overall, these approaches manage a restricted set of feature types, and interactions between features remains a major issue. Moreover, even recognized features are often difficult to suppress, which makes these approaches non-robust and very restrictive when used alone. Nevertheless, these approaches are efficient when used to remove holes and bosses prior to mesh simplification. A very good survey of simplification techniques can be found in  [26].However, feature suppression does not guarantee that the object’s boundary decomposition can be directly used for automatic mesh generation purposes. In this context, virtual topology techniques (also referred to as virtual geometry in some papers) can be applied afterwards with the objective of adapting the boundary decomposition to the requirements of automatic mesh generation. Virtual topology approaches proposed by Sheffer et al. [27,28], Inoue et al.  [29], Wei  [30], and Tautges  [31] are aimed at the edition of the B-Rep definition of a CAD model to produce a new topology, which is more suited to mesh generation constraints and which contributes to avoid poorly shaped and over-densified mesh elements. These approaches implement split and merge operators aimed at clustering adjacent faces into nearly planar regions in order to generate a new B-Rep topology, which is better suited to mesh generation, while preserving its geometry. However, face clustering algorithms show limitations in the context of FE model preparation: they do not support the definition of edges and vertices interior to faces, while these non-manifold surface configurations are required for various needs (modeling boundary conditions, taking into account specific features and sharp curves lying inside faces).Towards the objective of overcoming the limitations of virtual topology, we introduced meshing constraints topology (MCT) concepts  [32] in a previous work. One of the basic and most important features of MCT is that it enables non-manifold surface transformations: edge deletion, vertex deletion, edge splitting, edge to vertex collapsing, vertices merging. Starting from a given B-Rep model to be meshed, generating the MCT is based on a local analysis of B-Rep faces and edges with regard to mesh generation constraints (local face width, normal vector deviation across edges, etc.). An interesting feature of the MCT is that it enables the definition of interior edges and vertices on B-Rep faces when required. As described in more detail in the following sections, MCT models are basically defined using composite geometry. For instance, a composite face (referred to in our work as an MC face) is defined as a set of adjacent faces in the input B-Rep structure, each of which associated with an underlying surface and its parametric definition. Consequently, meshing models that have been processed with MCT concepts require the ability of automatically generating finite elements across composite geometry (typically composite edges and faces). At present, mesh generation techniques aimed at handling composite surfaces are based on the following two main approaches.The first approach is computing a global parameterization [33,34]: this basically consists of defining a bijective mapping between any point inside sets of surface patches and a global parametric domain. The bijective transformations proposed in [33,34]are both based on a cellular decomposition of each reference (non-composite) surface mapped into the global parametric space. Each cell is associated with a specific mapping to a reference surface image, and with a global parametric space image. Any point of a cell in the global parametric space is represented using its barycentric coordinates, and projected in the equivalent cell of the corresponding reference surface using the same barycentric coordinates. This new parameterization enables a natural and transparent use of parametric meshing schemes. Unfortunately, this type of approach is limited, for the following reasons.•It is restricted to open and non-periodic surfaces: this method can only be applied to open surfaces (homeomorphic to a disc), and not to periodic surfaces and closed surfaces homeomorphic to ann-torus.It is restricted to smooth and nearly planar domains: the parametric domain of distorted surfaces may cause high variations in the global parameterization metrics due to the surface embedding, and often results either in failures during mesh generation or highly distorted meshes  [33].Identifying the outer loops of composite faces is not automatic.The second approach consists of using direct 3D advancing front techniques on a tessellated (triangulated) model of composite surfaces  [10]. This type of approach also shows significant limitations, for the following reasons.•Deviation of the final triangulation from the input model depends on the tessellation’s accuracy.More sophisticated discrete representations such as subdivision surfaces and higher-order triangulations allow curved mesh generation but still generate approximation errors.In order to overcome these limitations, this paper introduces a new approach to automatic mesh generation over composite surfaces, which is based on an adaptation of the advancing front method (AFM) over curved surfaces  [5,8,10,35–38]. The AFM [5,7,8,10,35–41] is a very common automatic mesh generation technique, and the main features of its adaptation to the context of composite surfaces are as follows.•Elements need to be generated across multiple parametric surfaces: advancing front propagation thus needs to be adapted through the extension to composite surfaces of propagation direction, propagation length, and target point calculations,Every mesh entity is associated with its image in each component (reference entity) of the composite surface,Intersection tests between 3D segments are performed in the parametric domain of their images.•Section  2 presents the context of adapting CAD models for FEA and introduces meshing constraints topology (MCT), which is one of the key inputs of the mesh generation process presented in this paper.Section  3 briefly reviews the main steps involved in the advancing front method (AFM) applied to automatic mesh generation over parametric surfaces.Section  4 presents the extension (data-structures and algorithms) of the AFM, in the context of mesh generation over composite geometry, which is the core of this paper.Section  5 illustrates the potential and efficiency of the method proposed through the presentation of mesh quality improvements obtained on several practical examples.The general context of the present work is performing, as efficiently and quickly as possible, an FEA from the input of a detailed CAD model. This detailed CAD model is intended for product definition purposes and not for FEA purposes, which implies that modifications and simplifications are likely to be applied on this model before FEA. Also, prior to FEA itself, the analyst must specify mechanical hypotheses and boundary conditions on the CAD model (i.e. materials, loads, and restraints). The analyst also needs to specify an objective with regard to the desired analysis accuracy. In a priori adaptive meshing, based on his/her FEA skills and experience, the analyst specifies an FE size map that is adapted to both the geometry and the FEA objective. This size map can either be rough (to quickly obtain an approximate solution) or be featuring a certain degree of adaptive refinement (to obtain accurate results in zones of interest). This FE size map is a central issue in our automatic feature removal and topology adaptation processes because it represents the analyst’s intent with regard to the size of shape features that can be neglected for analysis purposes. This size map is likely to vary significantly throughout the analysis domain, depending on where the zones of interest are located, and it is consistent with the specification of a clear analysis objective. The automatic feature removal and topology adaptation processes are strongly driven by this FE size map.In the specific case where the input CAD model is part of a larger assembly, the size map has to respect a smooth transition at mating faces in contact with mating components, in order to limit the mesh element size gradient during the transition. In this case, the 3D domain in which the size map is defined should enclose the whole assembly, and the same size map should be used for the mesh generation of each component in order to generate conformal meshes at mating faces.Trying to generate a mesh with large elements on a CAD model featuring rather small entities, i.e. an over-detailed model, leads to non-convergence or to the generation of sliver (very flat) elements. Automatically meshing CAD models is typically performed through three steps, which are is closely related to the B-Rep structure’s hierarchy. First, the edges are discretized with sets of mesh segments, whose lengths are consistent with the FE size map. Then, a triangulation algorithm fills the interior of each B-Rep face with triangles; the triangulation is constrained by the prior discretization of the edge mesh and is also consistent with the FE size map required. Processing the entire B-Rep of a given part results in a closed triangulation of its boundary. The last step consists of using a tetrahedrization algorithm to fill the closed triangulation with tetrahedrons, consistently with the FE size map as for the discretization of edges and faces. Consequently, due to the fact that standard meshing procedures are constrained by the B-Rep topology (the mesh is constrained by all B-Rep edges) when trying to mesh an over-detailed CAD model, it results in the following mesh inconsistencies.•Mesh over-densities: e.g. small triangles are propagated from tiny segments generated on tiny edges of the B-Rep (see Fig. 1).Poorly shaped elements: e.g. sliver triangles are originated from small segments and narrow faces (see Fig. 1).We present a fully automated adaptation process, which is intended to improve the efficiency and speed of preparing CAD models for FEA. The automatic simplification criteria used are based on the imposed size map and the process takes place through the following three steps.•Step  1—Feature removal: CAD design features (holes, fillets, pockets, and protrusions) that are too small (with respect to the imposed size map) to affect analysis results in zones of interest are automatically identified as shape details (see Fig. 2(b)). Two types of operation are used to remove these details automatically.(a)Suppressing features directly in the CAD feature tree: this applies for details that have been designed as features, and for which suppression does not affect any other feature.Using delete-face type operators: this type of operator performs the elimination of selected faces and the reconstruction of a closed solid envelope by filling holes  [23,24].Step  2—MCT adaptation: the B-Rep topology obtained after feature removal usually requires additional preparation for mesh generation. Indeed, small edges and narrow faces must be transformed to avoid over-constraining mesh generation, as mentioned above. MCT operators and criteria based on adjacency hypergraphs  [32,42] have been designed for the automatic adaptation of B-Rep topology (see Fig. 2(c)).∘MCT criteria, based on the size map and taking into account zones where boundary conditions are applied, automatically identify which MCT operations are required from the following.–Removing irrelevant edges (located in narrow faces or planar surfaces) using edge deletion.Removing irrelevant vertices (located on small edges or smooth curves) using vertex deletion or edge contraction.Collapsing constricted sections of faces by merging vertices.MCT operators are then automatically applied by editing the MCT topology hypergraphs and their underlying geometry  [32]: edge and vertex deletion, edge splitting, edge to vertex collapsing.Step  3—Meshing the MCT model: a mesh is automatically generated from the MCT model (see Fig. 2(d)) using the AFM. The AFM is first initialized by discretizing MC edges (which are composite edges). Then the mesh is propagated inside MC faces (composite faces). The detailed description of this automatic mesh generation process is the core of this paper.As introduced in the previous paragraph, MCT adaptation basically consists in adapting the B-Rep topology to the requirements of mesh generation. Thus, MCT (see Ref. [32] for a detailed description) basically appears as an enhanced B-Rep structure, featuring MC entities, which are fundamentally composite entities. As for classical B-Rep structures, an MCT model includes a full description of the entities orientation and topological links, as shown in Fig. 3.In the MCT, topological links betweeni-manifold MC entities andj-manifold MC entities (i∈[1,2]andj<i) are represented by adjacency hypergraphs referenced as G.i.j.•G.2.1 is the face-edge adjacency hypergraph where:•each node represents an MC faceeach arc is an MC edge connecting a set of MC faces;G.2.0 is the face-vertex adjacency hypergraph where:•each node represents an MC faceeach arc is an MC vertex connecting a set of MC faces;G.1.0 is the edge-vertex adjacency hypergraph where:•each node represents an MC edgeeach arc is an MC vertex connecting a set of MC edges.DefinitionsThe reference model  is the B-Rep model obtained after performing the first step of the process presented above (after feature removal and prior to topology adaptation).Reference entities  (namely reference face, reference edge, reference vertex) are topological entities of the reference model. Their underlying geometry is represented through a single mathematical definition.•The surface underlying a reference face is a Riemannian surface, i.e. a plane, a sphere, a torus, a NURBS, etc.The curve underlying a reference edge is a Riemannian curve, i.e. a line, a circle, an ellipse, a NURBS, etc.The composite surface underlying an MC face is defined as the union of its reference faces.The composite curve underlying an MC edge is defined as the union of its reference edges.The point underlying an MC vertex is simply a point coinciding with an underlying reference vertex.Thus, unlike usual B-Rep curves and surfaces, composite curves and composite surfaces can feature tangency and curvature discontinuities. Fig. 4illustrates an MC edge composed of a set of two adjacent reference edges. It is worth noting that MC edges and MC vertices can be located on the interior of an MC face (see Fig. 5).This section briefly reviews the main steps involved in the AFM when applied to mesh generation over parametric surfaces (see Ref.  [5]). Section  4 will present the adaptation of this classical scheme in the context of mesh generation over composite surfaces.Meshing a B-Rep model with the classical AFM scheme is achieved through four main steps. These steps are closely related to the B-Rep structure. First, nodes are generated on the vertices of the B-Rep structure, which is followed by the discretization of B-Rep edges (second step). The third step consists of extracting, from the former results and for each B-Rep face, the discretization of its bounding loops. This initiates the application of the AFM to the triangulation of B-Rep faces, which finally leads to a closed triangulation of the CAD model’s boundary. The tetrahedrization scheme (fourth step) completes the process and, at the end, this closed triangulation is totally filled with tetrahedrons.When the B-Rep is triangulated, each B-Rep face is triangulated independently by propagating triangles from the discretization of its bounding loops. For a given face, the triangulation stops when the face is completely filled with triangles. For each face, this triangulation process starts with an initial front that is composed with segments issued from the discretization of the face’s bounding loops. Along the whole process, each front segment is oriented and defined by two nodes (PiandPi+1for theith segment). Starting from the initial front, a recursive process is applied for which, at each step, one triangle (two in some cases) is propagated from one (or two) of the current front segmentsPiPi+1(usually the smallest front segment), which is followed by updating the advancing front consistently with the generation of one (or two) new triangle(s). At each step, the local front configuration for candidate front segmentPiPi+1is analyzed with respect to six possible configurations (as illustrated in Fig. 6). Then, one of six operators is applied, consistently with the local configuration. The first five local configurations and associated operators only use existing nodes, while a new node is likely to be created when using the sixth operator. The first operator applies when the front is reduced to three segments (see configuration #1 in Fig. 6). In this case, a triangle is simply generated from these three segments. Similarly, when the front is reduced to a cavity bounded by four segments (see configuration #2 in Fig. 6), two triangles are generated by creating a diagonal segment. The alternative generating two triangles with the highest quality is chosen (out of two possible diagonals). For configurations #3 to #6, anglesα1andα2betweenPiPi+1and its previous (Pi−1Pi) and next (Pi+1Pi+2) front neighbors are considered. The criterion used is that a cavity in the front has to be filled with triangles if a segment features an angle that is smaller than 80°with one of its neighbors (see configurations #3 to #5 in Fig. 6). For configuration #3, the alternative (out of two possible diagonals) resulting in the highest triangle quality is also chosen.The last configuration corresponds to the case where a new node (referred to as a candidate node) needs to be considered, and eventually created, from candidate segmentPiPi+1. The optimal positionPoptfor this candidate node is defined as follows: starting fromPM, the middle ofPiPi+1,Poptis located so that segmentPMPoptis perpendicular toPiPi+1and the curvilinear distancedfromPMtoPoptisd=3/2⋅(wT⋅H(PM)+wS⋅‖PiPi+1‖),wherewTandwSare two weights, withwT+wS=1.H(P)represents the target size (the FE size map) at locationPM.Thus,dreflects a compromise made between element shape and element size requirements which can be contradictory (see Fig. 7).wTcontrols respecting the size map whilewScontrols generating elements with a good aspect ratio (the optimal aspect ratio being for an equilateral triangle whered=3/2⋅‖PiPi+1‖). Past experience has shown that(wT,wS)=(0.65,0.35)is a good practical compromise between these two requirements.In the case where an existing nodePFis close enough toPopt(see Fig. 8), then the triangle (PiPi+1PF) is generated instead of (PiPi+1Popt). When several existing nodes are found aroundPopt,PFis chosen as the closest point toPopt. The details about the way the vicinity betweenPFandPoptis computed can be found in  [43].Collision detection tests, before validating each triangle creation, are required to avoid overlapping triangles. The front is updated at each step, and the whole process stops when the front is empty.The main challenge in extending the AFM to MCT models is that the geometric definition of MCT components is composite (composite surfaces and composite curves). Consequently, it requires an extension of the AFM principles to composite geometry, which means being able to discretize composite curves and triangulating composite surfaces. The most challenging part of this adaptation is extending the AFM to triangulating composite surfaces. The main problems to overcome are related to the fact that each mesh segment and mesh triangle generated through the AFM progression on composite geometry is likely to lie on multiple B-Rep faces and consequently, it is likely to be associated with a composite definition across multiple parametric spaces. Collision tests between new front segments and existing mesh elements also require specific and significant adaptations of the AFM, since a given front segment is also likely to lie on multiple B-Rep faces.In this work, the basic principles applied for this extension are as follows.•The triangulation process is performed over composite surfaces using the same overall AFM scheme as in the case of non-composite surfaces  [5,8,10,35–38]. This scheme notably allows handling non-manifold boundaries, which is an important requirement because, as mentioned previously, MCT naturally generates such configurations.Triangles are directly generated over multiple parametric definitions of reference surfaces underlying composite surfaces. This allows avoiding the problems and limitations of using a global parameterization of composite surfaces.The extension of the AFM to the triangulation of composite surfaces raises the following major problems.•The association of mesh elements with multiple reference entities. Our extension aims at generating mesh elements over composite curves and surfaces. In this extension, most algorithms (front propagation, intersection tests, shortest path estimation, and tangent vector evaluation) require computing and handling images of mesh elements in the parametric domain (for faces and edges) of the underlying reference entities of the MCT. This information about images of mesh elements in the parametric domain of reference entities should be easily accessible from mesh data-structures.The creation of explicit B-Rep data-structure featuring explicit co-edges and loops. The front initialization, which is inherent to the AFM, relies on loops and co-edges of the B-Rep data-structure. Co-edges must be sorted in loops to avoid self-overlapping problems, which is required to enable the front’s propagation initialization (from loops).Front initialization. The front has to be initialized from the MCT, which is made of composite surfaces, curves, and vertices where adjacency links are described in the B-Rep data-structure. This initialization consists of two steps: composite curve discretization, and front ordering based on the orientation of co-edges and loops.Normal vector evaluation at the location of first-order discontinuities. The evaluation of normal and tangent vectors is mathematically undetermined on curves and surfaces at the location of first-order discontinuities (corners and sharp edges). Pseudo-normal vectors need to be defined and computed at these locations because the AFM requires such vectors to set the front propagation direction.Front propagation. Front propagation and element generation have to be processed on multiple bi-parametric surfaces (see Fig. 9).Shortest path estimation on composite surfaces. Sharp edges or small details can be located inside the composite surface, and this induces important tangency discontinuities across which triangles must be generated. These surface discontinuities make it impossible to approximate curvilinear distance with Euclidean distance (see Fig. 10(a)). As a result, neighboring mesh elements have to be searched by considering the curvilinear distance (in the context of multiple parametric surfaces as illustrated in Fig. 10(c)) between nodes instead of the Euclidean distance (see Fig. 10(b)). This curvilinear distance has to be estimated using a shortest path (over multiple parametric surfaces) search algorithm (see Section  4.5.2).The following sections of the paper present how these problems can be solved. We start with the presentation of mesh generation data-structures and algorithms supporting the extension of AFM concepts to the context of composite geometry.A crucial point when trying to generalize the AFM to composite surfaces, in the context of using MC topology, is the transformation of MCT adjacency hypergraphs into a coherent B-Rep data structure (referred to as a winged-edge structure). (See Fig. 11.)•Any MC edge has to be associated to two partner co-edgesC1andC2whose orientation should be opposite  [32].Any MC face is associated with loops which are composed of co-edges, and these loops underlie the front initialization in the AFM. These MC face loops must be built with the objective of avoiding front overlaps during the front propagation process.Methods for the creation of partner co-edges of MC edges and loops of MC faces are proposed in Sections  4.1.1 and 4.1.2.In the definition of a B-Rep structure, co-edges are addressing the orientation of loops surrounding B-Rep faces. Co-edges associated with a given loop of a given face are oriented so that, at a given location along the face’s boundary, the cross product of a co-edge tangent vector and the face normal vector is directed towards the interior of this face, which means towards the front propagation direction (see Fig. 12(a)). In MC topology, the interior domain of an MC face is defined explicitly by reference faces being grouped into a single composite surface. Therefore, the following hold.•The interior domain of an MC face equals the interior domain of its underlying reference faces.The orientation of co-edges defining the orientation of an MC face is the same as those of co-edges addressing the reference faces of this MC face (see Fig. 12(b) and Fig. 12(c)).LetEibe an MC edge andFjan MC face adjacent toEi,∀Eref∈Eiand∀Fref∈Fj:Orientation(Ei,Fj)=Orientation(Eref,Fref).The boundary of an MC face is defined as non-manifold when one MC vertex is connected to more than two MC edges, these MC edges being adjacent to this MC face. This configuration is not specific to MCT, as can be seen in classical B-Rep structures, as shown in Fig. 13.The AFM requires that the geodesic propagation of fronts, initiated on the loops of an MC face, over the underlying composite surface fills the interior domain completely, without front overlaps. Loops are sorted list of co-edges such as the(i+1)th co-edge starts at theith co-edge’s end. In order to avoid front overlaps caused by non-manifold configurations such as the one illustrated in see Fig. 13, the sequence of co-edges along a given loop of an MC face is chosen using considerations about the interior angle between two consecutive co-edges (between two alternatives, the one inducing the minimal interior angle is chosen).The theoretical definition of interior angles is geodesic: considering an arc of geodesic circle starting from theith co-edge and ending on thei+1th co-edge, the interior angle is defined as the curvilinear length of arcsdivided by its geodesic radiusr. Practically, interior angles are calculated from a tessellation of the MCT, where MC faces are approximated by sets of triangles and MC edges by sets of segments. The interior angle between two co-edgesC1andC2is computed by summing interior angles of triangles chained between these co-edges and adjacent to their common vertexv(see Fig. 14). This tessellation of the MCT is derived from a tessellation of the reference B-Rep topology, which is available in any CAD kernel. The tessellation of the MCT is updated after any MC operation during MCT adaptation: for instance, merging two composite surfaces or curves is followed by merging their discretizations, and splitting a composite curve is followed by inserting a node in its discretization. The tolerance of this tessellation is set to 1/50th of the minimum value in the FE size map. This ensures that the accuracy of geometry definition is much better than the accuracy of the expected FE mesh.ConventionN(P)represents the normal vector to a surface at locationP, wherePcan be an Euclidean point or a parametric coordinate.As introduced in the previous sections, the triangulation of MC faces is preceded by the discretization of MC edges. This discretization of MC edges in mesh segments sets up data required for initializing the advancing front when triangulating MC faces. This discretization of MC edges and consequently, this initialization of the advancing front respects the following properties.1.The front is composed of segments generated through MC edge discretization, and these segments are oriented with respect to the orientation of all co-edges surrounding the MC face. Thus, each front segment is oriented (the orientation of vectorPiPi+1) consistently with the advancing front direction, defined asVi=N(PM)∧PiPi+1(see Fig. 15(a) and (b)). As illustrated in Fig. 15(b),N(PM)is the normal vector at locationPM. A detailed definition of normal vectors is given at Section  4.3.Each front segmentPiPi+1only features two neighbors (the previous and next segments). Consequently, the advancing front is composed of one or more closed segment loops that are consistent with the loops of MC faces (see Fig. 15(c)).There is no intersection between two segment loops of the front.ConventionVariable t designates the curve parameter associated with a reference geometry (tis dependent on the curve’s intrinsic mathematical formulation), while variablet′designates the curve parameter associated with a composite geometry (t′equals the curvilinear length along the composite curve).The generation of the initial front segments is processed as follows. A set of nodes is first generated on MC vertices and then nodes are generated along MC edges. Given the parametric function of a composite curvePolyC(t′)and the size map functionH(x,y,z), the method presented in  [32] generates an optimal parametric coordinate for each nodePi:ti′withi=0,1,…,Nseg, andNsegbeing the number of segments of the MC edge discretization. When all node parametersti′are defined, the composite curve’s mapping function provides, for anyt′, the corresponding reference edgeEand the parametric coordinatet(along this specific reference edge), written as(E,t)=PolyCRef(t′).As shown in Fig. 16, each segment is associated with an image curve, which consists of a sequence of subsegments, each of which representing the image of the mesh segment along a reference edge and on its two adjacent faces.As mentioned previously, MCT transformations naturally generate non-manifold boundary topologies. Fig. 17illustrates two such specific non-manifold configurations, one corresponding to an MC edge or a group of MC edges that are isolated on an MC face, and the other corresponding to an MC vertex that is isolated on an MC face. In the first case, the initial front segments associated with isolated MC edges are doubled (with inverse orientations) so that a closed loop of front segments allows it to progress in both inverse directions (for example at locationPMin Fig. 17). In the case of an isolated MC vertex, an additional front segment is automatically generated from the isolated vertex and, like in the case of isolated MC edges, it is doubled so that the front is able to progress in both directions. This specific front segment is generated arbitrarily except that it should not cross any other front segment and not be located too close to an existing front node (see Fig. 18).A case involving an isolated MC vertex is presented in Fig. 18(a), and in Fig. 18(b) the arbitrary front segment mentioned above is generated in such a way that the front nodePcis too close to other front segments. As illustrated in Fig. 18(b), a search zone is used around the candidate front segmentMPc, and, if an existing front node is found in this zone, it is used instead ofPc. In this case (see Fig. 18(c)), the advancing front is updated as [Pi−1Pi], [PiM], [MPi], [PiPi+1], etc.As mentioned in the previous section, the evaluation of normal vectors is crucial to compute the advancing front propagation direction when triangulating MC faces.•The front configurations 1–5 are validated if the directions of the normal vectors of candidate triangles generated are consistent with that of normal vector at midpointPM(see Fig. 19(a)).The front configuration 6 intends to create the optimal pointPoptby advancing towards a direction based on the composite surface’s normal (see Fig. 19(b)).In the context of composite surfaces, some of the normal vectors have to be evaluated at locations where the geometry is non-differentiable (sharp edges and corners featuringC0continuity), as well as at locations where the domain is at leastC1continuous (in curved regions). Like in the case of smooth rendering methods, the weighted average of normal vectors at adjacent faces smoothes the surface at points located on sharp edges and vertices of a composite surface. In this work, the weights used for the computation of the weighted average of normal vectors at the location of a sharp vertex are normalized interior anglesβjof facesFjadjacent to pointPi(see Fig. 20(a)). Consequently, the equivalent normal vectorN(Pi)at locationPiis given byN(Pi)=∑j=1nβj⋅N(Fj,Pi)∑j=1nβj,whereN(Fj,Pi)is the normal vector to reference faceFjat locationPi.For the calculation of an equivalent normal vector along a sharp edge (see Fig. 20(b)), this expression simply becomesN(Pi)=N3+N42, whereN3andN4are the normal vectors to the two intersecting reference faces at locationPi.Conventionsσj(u,v)represents the parametric surface equation underlying reference faceFj.CuvFj(t)represents a 2D curve, defined in the parametric space of reference faceFj.The 3D equation ofCuvFj(t)is given byCFj(t)=σj(CuvFj(t)). By the way,CFj(t)lies on the surface defined byσj(u,v).The most important obstacle to adapting the AFM to composite surfaces is adapting the method in the case of front configuration #6 (as defined in Fig. 6). Indeed, given a candidate front segmentPiPi+1, the problem is finding the optimal location of candidate nodePoptfrom segmentPiPi+1to obtain a triangle respecting both size and shape quality requirements. In the classical implementation of the AFM, the optimal location is basically estimated with the use of a trajectory, defined in the parametric space of the surface, which starts from midpointPM, and which progresses towards the advancing front direction, until matching a target distanced. The adaptation of this trajectory in the context of composite surface meshing is performed using the 3D intersection curve between a plane (referred to in our work asΦ) and the composite surface. This trajectory is computed as follows.•MidpointPMlies on the curvilinear image of the candidate front segment and it is equidistant toPiandPi+1(using the Euclidean distance).PlaneΦis computed as the equidistant plane toPiandPi+1.The advancing front directionViisVi=N(PM)∧PiPi+1.Like in the classical implementation of the AFM (see Section  3), the target distancedis calculated as a compromise between shape and size requirements.d=3/2⋅(wT⋅H(PM)+wS⋅‖PiPi+1‖), wherewT∈[0;1]andwT+wS=1.Then, the 3D intersection curve is built as follows. MidpointPMis obtained by finding intersection points betweenΦand the segment’s curvilinear image (see Section  4.2). Then, the trajectoryC(t′), which is defined as the intersection curve betweenΦand the composite surfaceσ, is obtained by creating a sequence of curvesCFj(t)that are defined in the parametric space of reference faces, and that are coincident toΦwith a given toleranceδmax. The first curveCF0(t)starts fromPMand stops either if the target distancedis reached, or if the boundary of the current reference face. New curvesCFj(t)are appended to the trajectoryC(t′)until the target distancedis reached or the MC face boundary is met (see Figs. 21 and 22). Each curveCFj(t)along the intersection between reference facesFjandΦis computed in the parametric space associated to faceFjas a polyline (referred to asCuvFj(t)).The overall trajectoryC(t′)is created by concatenating the curvesCFj(t)until target lengthdis reached, which means that‖C(t′)‖=∑j=0n−1‖CFj(t)‖=d.Consequently, the curvilinear length ofCFj(t)is limited byLmaxFj, which is the difference between target lengthdand length of the curves precedingCFj(t):LmaxFj=d−∑k=0j−1‖CFk(t)‖. The starting point of the first curve, referred to asP0,0, is located at midpointPM. The path creation consists of a concatenation of parametric subsegmentsPj,mPj,m+1along the intersection betweenΦand the surface (see Fig. 23). The length of subsegments, referred to asds, is small enough to locally approximate the intersection curve by a straight line segment in the parametric space. In practice, we found thatds=d50is small enough to reach accuracyδmaxwithδmax≈d500.Each subsegmentPj,mPj,m+1is obtained as follows.•Compute (see Fig. 23) the 3D increment vectorΔ3Dj,m(lengthdsand collinear to the intersection betweenΦand the plane that is tangent toFjat locationPj,m).Calculate the parametric incrementΔuvj,mby projectingΔ3Dj,min the parametric space associated with faceFj(with accuracyδmax).Append a new pointPj,m+1to polylineCFj(t):Pj,m+1=Pj,m+Δuvj,m.Following this last process, the number of parametric points constituting polylineCFj(t)isLmaxFjds+1. It appears that fewer points are actually required to respectδmax, and, in order to reduce the number of polyline points, an additional procedure is applied during path creation, with the objective of keeping the minimum number of points that are necessary to respectδmax.In the classical AFM scheme, each candidate triangle creation is analyzed before being validated to avoid triangle overlaps. As mentioned above, the extension of this analysis in the case of composite surfaces requires dealing with the fact that each mesh segment and mesh triangle generated through the AFM progression on composite geometry is likely to lie on multiple B-Rep faces and is, by the way, likely to be associated with a composite definition across multiple parametric spaces. Consequently, collision tests between new front segments and existing mesh elements are much more difficult to perform than in standard AFM, and these tests require setting up specific procedures, as described in the following paragraphs.Detecting front collisions in the validation of triangle creation in the context of composite surfaces requires computing the curvilinear image of front segments on a composite surface. Constructing the curvilinear image of a segmentPiPi+1is achieved by one of the following schemes.•The first attempt (see Section  4.5.3) consists of projectingPiPi+1in the normal direction on the underlying composite surfaceσ. This method is likely to fail when the normal projection is composed of several disconnected components (see Fig. 24).If this first attempt fails, the shortest path betweenPiandPi+1is evaluated with a method that is detailed in Section  4.5.4.As introduced in the previous section, the normal projection method applies when the curvilinear image is composed of one single component, which is true in most front generation situations. The projection is calculated as a plane–surface intersection, which is similar to the intersection used for creating a trajectory that is perpendicular to the front (as detailed in Section  4.4.1). The intersecting planeΦNis computed as follows.•Calculate normal vectorNby averaging normal vectors atPiandPi+1(see Fig. 24).ΦNis defined as passing through toPiandPi+1and as collinear to vectorN.Then, the curvilinear image of front segmentPiPi+1is generated by computing a trajectory, referred to asC(t′), at the intersection betweenΦNand the composite surfaceσ. This trajectory (fromPitoPi+1) is obtained by creating a sequence of curvesCFj(t)that are defined in the parametric space of reference faces, and that are coincident toΦNwith a given toleranceδmax. The first curveCF1(t)starts fromPiand stops either ifPi+1is reached, or if the boundary of the current reference face is reached. New curvesCFj(t)are appended to continue the trajectoryC(t′)untilPi+1is reached (see Fig. 25). Thus, each curveCFj(t)is constrained byΦNandFj.Composite surfaces singularities such as sharp edges and thin walls require a specific shortest path evaluation in the following cases.•When the method presented in Section  4.5.3 is affected by surface singularities (see Fig. 26), the shortest path estimation provides a valid representation of the segment’s image.When validating element creation by searching neighboring elements, the shortest path evaluation is a good estimator of the curvilinear distance in zones featuring singularities (see Fig. 26).The shortest path between two pointsPBandPCis computed following these steps.Step 1: A set of passing pointsPk(see Fig. 26) is defined and it is composed of the following.∘PBandPC, the beginning and the end of the shortest path.Pke, defined as points lying on reference edges of the composite surface and located in the neighborhood of linear segmentPBPC, which means such asdist(PBPC,Pke)<‖PBPC‖,where dist(PBPC,Pke) is the distance between the linear segmentPBPCandPke.Pkv, defined as coincident points with reference vertices of reference faces and located in the neighborhood of linear segmentPBPC, which means such asdist(PBPC,Pkv)<‖PBPC‖.Step 2: The set of curvesCiconnecting two passing pointsPklocated on a reference face or edgeGof the composite surface.Step 3: The point-curve adjacency graph is constructed as follows.∘Each graph node represents a passing pointPk.Each graph arc represents a curveCiconnecting two passing points.Step 4: Dijkstra’s algorithm  [44] is used to compute the shortest path through curves (see Fig. 26).∘In Dijkstra’s algorithm, the lengths associated with graph arcs are evaluated by calculating the lengths of curvesCi.The length of the path is the sum of the curves’ length attached to arcs.As mentioned in the previous section, the validation of triangle creation mainly relies on detecting collisions between mesh segments (the sides of newly created triangles) and front segments. As illustrated in Fig. 27, the intersection between two segments is tested by evaluating the intersection of their curvilinear images in the parametric space of the associated reference faces.Once a triangle creation is validated, the advancing front needs to be updated. The adaptation of front update operations to composite surfaces is straightforward, because it is identical to the process used for standard AFM. Also, like in the classical implementation of the AFM, the front progression stops when the front is empty, which means that the whole composite surfaces being triangulated is completely filled with triangles. The application of this adapted version of the AFM to all MC faces in the MCT model leads to a closed and watertight set of triangles representing the triangulation of the MCT model’s boundary. Once this triangulation generated, a 3D solid mesh can be derived using any automatic tetrahedral mesh generation scheme.The algorithms described in this paper are validated by showing the improvement obtained, on mesh size and shape quality criteria, when using the MCT approach if compared to meshes that are directly generated from unprepared CAD models. An analysis of quality improvement shows that the mesh quality obtained, after applying the MCT preparation process followed by the automatic triangulation process as presented in this paper, is close to optimal. This clearly validates the approach by showing that, whatever the topology of the initial CAD model is, the whole process is successful in avoiding the generation of badly shaped elements or over-refined meshes.Fig. 28illustrates the triangle quality distributions obtained for the meshes presented in Figs. 29 and 31–33. Shape quality is evaluated using a classical criterion (the radius of the inscribed circle divided by the maximum edge length) and size quality is evaluated using the geodesic size criterion  [5], which quantifies the difference between the actual area of a triangle and its optimal area with regard to the imposed size map.Quarter of a piston:   Fig. 29 shows one quarter (due to symmetry) of a piston’s CAD model. The original CAD model features many narrow faces and small edges that are irrelevant for mesh generation. On this sample part, the MCT simplification process  [32] performed 60 edges deletions, 62 vertex deletions, and collapsed one edge to a vertex. Thus, the number of faces has been reduced from 71 to 21, the number of edges from 182 to 76, and the number of vertices from 113 to 63. The size and shape quality distributions are satisfying, as illustrated in Fig. 29. Fig. 29 also shows that the use of the method presented in this paper on this example completely eliminates poor quality triangles (for both shape and size).In Fig. 29, a constant FE size is imposed, while in Fig. 30the FE size required varies. In this last figure, element colors refer to the imposed element size (instead of element quality), as indicated in the color legend. This illustrates that the method proposed in this paper can handle both constant and varying FE size maps.Milling cutter: results presented in Fig. 31represent the initial CAD model aside an MCT model automatically generated using our adaptation process. The B-Rep entities representing the cutter size label and other irrelevant edges have been removed. Fig. 31 shows that the shape and size quality distributions are both significantly improved with the use of the approach presented in this paper. In this case, seven triangles with a shape quality inferior to 25% remain in the final triangulation. It is important to outline that, for the size map imposed, the badly shaped triangles remaining cannot be eliminated. This is due to the fact that the geometry itself still overconstrains mesh generation, even once the MCT preparation process is applied. In this case, the elimination of the few badly shaped triangles remaining could only be achieved using a local mesh refinement.Carter:   Fig. 32illustrates a more complex CAD model (a carter). The MCT simplification process performed 540 edge deletions, 497 vertex deletions, and collapsed 7 edges. In this case, the number of faces has been reduced from 520 to 71, the number of edges from 1256 to 301, and the number of vertices from 785 to 279.Tire: This last example is issued from a CAD model generated for simulating the heating process of a tire section (courtesy MichelinTM). The MCT simplification process performed 185 edge deletions, 283 vertex deletions, and collapsed 1 edge. The number of faces has been reduced from 183 to 11, the number of edges from 569 to 134, and the number of vertices from 388 to 136.One of the most interesting aspects of the work presented in this paper is that using composite parametric definitions avoids using a global parameterization of composite surfaces. This is an important improvement, because it overcomes the main limitations of approaches based on mapping composite surfaces into a single parametric domain.Thus, as illustrated in Fig. 34, the AFM adaptation presented in this paper is•not restricted to specific boundary topologies: closed composite surfaces that are homeomorphic to a sphere or to ann-torus can be meshed as well as open composite surfaces;not limited by stretched geometries and steep metrics variations: highly stretched surfaces, such as the one representing a glove inspired shape, are handled easily and efficiently, and it results in very good quality elements, even in high curvature zones. In fact, with the approach presented here, these high curvature zones are handled as easily as when using the AFM on single surfaces.

@&#CONCLUSIONS@&#
