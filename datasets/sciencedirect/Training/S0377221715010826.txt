@&#MAIN-TITLE@&#
Switching regression metamodels in stochastic simulation

@&#HIGHLIGHTS@&#
How to collect data for switching metamodels (SWM) where several identified regimes.Procedure using replications to estimate regime probabilities and variances of SWM.Generalize WLSQ to mixtures of regimes (MWLSQ) based on clusterwise regression.Asymptotic normality and consistency of the MLE is established for MLE metamodels.Compare the precision of MWLSQ and MLE metamodels with a 4 regime example.

@&#KEYPHRASES@&#
Simulation,Metamodel,Regression mixture,Maximum likelihood,

@&#ABSTRACT@&#
Simulation models are frequently analyzed through a linear regression model that relates the input/output data behavior. However, in several situations, it happens that different data subsets may resemble different models. The purpose of this paper is to present a procedure for constructing switching regression metamodels in stochastic simulation, and to exemplify the practical use of statistical techniques of switching regression in the analysis of simulation results. The metamodel estimation is made using a mixture weighted least squares and the maximum likelihood method. The consistency and the asymptotic normality of the maximum likelihood estimator are establish. The proposed methods are applied in the construction of a switching regression metamodel. This paper gives special emphasis on the usefulness of constructing switching metamodels in simulation analysis.

@&#INTRODUCTION@&#
Linear regression analysis plays an important role in many fields. A regression metamodel may be used for interpreting the input/output of a simulation model and, consequently, for analysing the real world data. A simulation metamodel, usually a simple mathematical function, is an approximation of the input/output function that is defined by the underlying simulation model (Kleijnen, 2008). Kleijnen (1975) proposed some statistical tools for making the regression metamodels commonly usable, and the most popular methods for constructing simulation metamodels are the polynomial regression ones; see also (Biles, 1974). The construction and use of metamodels continues today and comprises several types of metamodels like, for example, linear regression metamodels (Kleijnen, 1992), nonlinear regression metamodels (Santos & Nova, 2006; Santos & Santos, 2008), Kriging metamodels (Kleijnen, 2009) among others. A metamodel may be used with different purposes; for example, it may be used as a surrogate of a simulation model or as a building block inside a simulation model (Santos & Santos, 2009).However, in simulation practice sometimes we may obtain a poor fit when a single regression metamodel is used. It happens when simulation model behavior isn’t likely to follow one unique regime, and that different subsets of the input/output data may favor different submodels. A different approach may be using switching regression techniques for constructing metamodels in stochastic simulation. A switching regression model assumes that we have a random variable y such that E[y] is a linear function of explanatory variables withy∼N(xTθs,σs2)with probability λs,s=1,…,S. So, there are a set of S regression models characterized by the parameters(θ1,σ12),…,(θS,σS2),and for each observation pair (yi, xi) the indicator λsichooses one among several models to obtain yi; the unknown parametersθ1,σ12,…,θS,σS2are estimated from the data.Switching regression models are dated to at least (Quandt, 1958), and find applications in a wide variety of areas such as economics (Chen, 2007; McKenzie & Takaoka, 2008), finance (Fukuda, 2009), and marketing (DeSarbo & Cron, 1988). Goldfeld and Quandt (1973) introduced the Markov-switching models, in which a latent state variable (instead of a fixed probability) following a Markov-chain controls regime shifts, meanwhile (Quandt, 1972) studies a mixture of normal linear regression models where the choice between regimes is based on fixed probabilities. In the clusterwise linear regression context, Späth (1979) considers the regression problem where the error sums of squares is computed over all regimes (referred by clusters) is minimized using an exchange algorithm. Lau, Leung, and Tse (1999) propose a programming procedure to estimate clusterwise linear regression models based on combinatorial optimization problems; see also Carbonneau, Caporossi, and Hansen (2011). Quandt (1972) proposed the maximum likelihood method for estimating switching regressions, and Kiefer (1978) studied the problem of data covering two regression regimes and maximum likelihood methods for unknown parameters estimation. In the maximum likelihood context, DeSarbo and Cron (1988) generalize the Quandt (1972) and Hosmer (1974) stochastic switching regression models to more than two regimes. This article extend these developments to the construction of simulation switching regressions metamodels, where the unknown variances are estimated using the replications available from a simulation experiment and the switching probabilities may vary with the experimental points, and are also estimated from de data.This paper is organized as follows. A framework of the metamodel with relation to simulation metamodels and switching regression models is described in Section 2. In Section 3 the estimation procedure for constructing switching regression metamodels is presented. Section 4 describes an application example related to a simple manufacturing process. The conclusions are presented in Section 5.A simulation model viewed as a black-box may be represented trough a mathematical function g(., .) asy=g(d,r0)where, y is a vector of simulation outputs, d is the vector of input factors of the simulation model and r0 is a vector of pseudo-random seeds. Typically, one metamodel is constructed for each component of y, so we consider metamodels where y has one componenty=f(x;θ)+ϵwhereθis the unknown metamodel parameters, and x is a vector of metamodel inputs; for example, in the simulation of the M/M/1 system we may choosex1=d1/d2=λ/μ,where λ is the arrival rate and μ is the service rate. If f is a linear regression function, then a common set of regression parameters is enough for describing the input/output characteristics of the simulation program and, consequently, the simulation data may be described with only one regime. However, sometimes the input/output data exhibit some heterogeneity which produces the variation of the set of regression parameters over the data and, consequently, one regime may not be adequate for approximating the simulation input/output data. Switching regression metamodels (mixture of linear regressions) may help to overcome the lack-of-fit problem in these situations.An illustrative example, where the usual regression leads to misleading results, is given in Table 1and is depicted in Fig. 1. The adjusted metamodel based on all data points isy^=0x+7.270and we may observe that this line poorly approximates the data. If the observations are split into two subsets then the following metamodel, which allows a good fit, is obtainedy^={−1.06x+6.080,withprobabilityλ^1=2/3(subset1)0.53x+7.865,withprobabilityλ^2=1/3(subset2)Consider an experimental design consisting of n different design points,{xil:i=1,…,n;l=1,…,p},with p explanatory variables. For each design point i, r independent replications of the simulation model are carried out and the experiment yieldsΩij={z˜ijk:i=1,…,n,j=1,…,r,k=1,…,o},wherez˜is the relevant system response, with o observations per replication. For each experimental point i and replicate j the observations(z˜ij1,z˜ij2,…z˜ijo)are split into S regimes sequentially ordered:regime 1:Ω1ij={zi,j,1,zi,j,2,…,zi,j,t1ij}regime 2:Ω2ij={zi,j,t1ij+1,zi,j,t1ij+2,…,zi,j,t1ij+t2ij}regime 3:Ω3ij={zi,j,t1ij+t2ij+1,zi,j,t1ij+t2ij+2,…,zi,j,t1ij+t2ij+t3ij}⋮⋮regimeS:ΩSij={zi,j,t1ij+t2ij+⋯+tijS−1+1,zi,j,t1ij+t2ij+⋯+tijS−1+2,…,zi,j,t1ij+t2ij+…+tSij}whereΩij=⋃s=1SΩsijThe probability associated with each set Ωsijis estimated by(1)λ^si·=1r∑j=1rλ^sijwhereλ^sij=#Ωsij#Ωij=tsijowhere#Ωrepresents the number of elements belonging to the set Ω.Ifλ^si≈1for some i ands=1,…,S,then we may assume one regime only at experimental point i. Since λsmay depend on the experimental point, when predicting the response at x between xiandxi+1the corresponding probabilities may be computed using, for example, interpolation of first degree. For a single input:λ^s(x)=λ^si+x−xixi+1−xi(λ^s,i+1−λ^s,i)For each regimes=1,…,S,and replication j of each design point i a measure of interest ysijis determined from zi, j, k. For instance, the mean value for each regime isysij=1tsij∑k=k1ijk2ijzi,j,kwherek1ij=1+∑m=1s−1tmijandk2ij=∑m=1stmijFor each experimental point i the mean and variance values of the measure of interest each regime can now be computedy¯si·=1r∑j=1rysij(2)σ^si2=1r−1∑j=1r(ysij−y¯si·)2To represent the simulation model, the following mixture of linear regressions is assumed(3)y¯i.={θ10+∑l=1pθ1lxli+ϵ¯1i.,withprobabilityλ1i⋮θS0+∑l=1pθSlxli+ϵ¯Si.,withprobabilityλSiwhereϵ¯si.are iid as N(0,σsi2/r),i=1,…,n,represents the inaccuracy of the metamodel (σsi> 0),s=1,…,S. Assume that the mixing weights λsi, 0 < λsi< 1, and the regression parametersθ=(θ10,…,θ1d,…,θS0,…,θSd)are unknown, and∑s=1Sλsi=1i=1…nWe assume λsi≠ 0 and λsi≠ 1 because ifλsi=0orλsi=1,the parameters of some regime is not identified. If the regime’s probabilities are unknown, then they may be estimated by (1).Consequently,y¯has a finite mixture probability density functionf(y¯.)=∑s=1Sλs2πσs2/rexp[−12σs2/r(y¯.−θs0−∑l=1pθslxl)2]Späth (1979) first introduced the term clusterwise regression as a separation technique when clustering data. Instead of a separation criterion given a set of previously known mathematical functions, the approach proposed in this paper estimates the function parameters from observations already clustered into different groups. Whereas in the traditional regression model the approximating function is the same for all subsets of the sample, that is, it assumes only one regime (θsl=θl,for alls=1,…,Sandl=0,…,p), the clusterwise model assumes a mixture of linear regressions like in (3). Späth presents an exchange algorithm to minimize the global problem∑i=1n∑s=1S(y¯si.−θs0−∑l=1pθslxli)2In this sense, the clusterwise linear regression is a regression problem where the error sums of squares computed over all clusters is minimized. In order to assure the existence of a solution, it is required that the number of observations is significantly larger than the number of unknown parameters (o ≫ dS).In this paper, the following global estimated weighted error sum of squares used is∑i=1n∑s=1Sλ^siσ^si2/r(y¯si.−θs0−∑l=1pθslxli)2In mixture weighted least squares (MWLSQ), all regimes must be adjusted simultaneously, taking into account the relative estimated variancesσ^si2and the estimated regime probabilitiesλ^si,obtained from the previously clustered observations.Initial values are computed using estimated separated weighted least squares (WSLQ) method for each regime.∑i=1n1σ^si2/r(y¯si.−θs0−∑l=1pθslxli)2Then an unconstrained nonlinear minimization is performed, using the previously determined initial values. The use of an initial value near the solution improves the robustness of the nonlinear search.The log-likelihood function can be expressed aslnL(λ,θ,σ2)=∑i=1nln{∑s=1Sλsi2πσsi2/rexp[−12σsi2/r(y¯si.−θs0−∑l=1pθslxli)2]}whereλ=(λ11,…,λ1n,…,λS1,…,λSn),θ=(θ10,…,θ1p,…,θS0,…,θSp),andσ2=(σ112,…,σ1n2,…,σS12,…,σSn2).Using (1) and (2), the maximum likelihood approach consists on maximizing the log-likelihood function with respect toθ, that is, consists on solving the following system of equations:(4)∂lnL(λ^,θ,σ^2)∂θ=0or equivalently,∂lnL(λ^,θ,σ^2)∂θst=0,s=1,…,S,t=0,…,pwhere,∂lnL(λ^,θ,σ^2)∂θst=∑i=1n1Viλ^si2πσ^si2/rxti(y¯si.−θs0−∑l=1pθslxli)σ^si2/rexp[−12σ^si2/r(y¯si.−θs0−∑l=1pθslxli)2]withVi=∑s=1Sλ^si2πσ^si2/rexp[−12σ^si2/r(y¯si.−θs0−∑l=1pθslxli)2]In Proposition 1, the existence of a consistent root of the likelihood Eq. (4) is established; also, the asymptotic distribution of this consistent root is obtained (see the verification of these results in Appendix).Proposition 1Let the random variabley¯si.has probability density function(5)f(y¯i.;θ)=∑s=1Sλ^si2πσ^si2/rexp[−12σ^si2/r(y¯i.−θs0−∑l=1pθslxli)2]whereθ=(θ10,…,θ1p,…,θS0,…,θSp),withθsl∈R. Then for n sufficiently large there exists an unique consistent rootθ^of the likelihoodEq. (4), and the asymptotic distribution ofn(θ^−θ*)is multivariate normal with zero mean vector and variance-covariance matrix given byI(θ*)−1,whereθ*represents the true value of the parameterθand I(θ*) is the Fisher information matrix.The system of nonlinear Eq. (4) yields the maximum likelihood estimates (MLE). However, this system cannot be solved explicitly and, frequently, has non-unique solution. Consequently, numerical methods like, for example, Newton method or Neder–Mead may be used for obtaining maximum likelihood estimates. These methods may converge to a local solution instead of the global one, especially if the initial guess is not sufficiently near the exact solution. However, Proposition 1 assures the existence of a unique global solution but, if there is more than one solution, it does not provide any information about which solution is consistent. When conventional algorithms fail in detecting the global optimum, stochastic methods like e.g. Simulated Annealing might prove to be a good alternative. Although sometimes slower, they converge to the global optimum.Several systems exhibit switching output regimes. Some of these systems include a feedback component. The depicted application example is a system with feedback that exhibits output regimes in certain range of inputs. The example is a simplification of a manufacturing process where items must be reprocessed if the result does not meet specifications.The system used for depicting the construction of the proposed metamodels is a simple parts painting processing unit. The parts to be painted arrive at the unit according to a Poisson process. The mean time between arrivals is the decision variable x. The painting time is triangularly distributed between 2 and 10 minutes, with a mode of 5 minutes. However, 20 percent of the painting operations have to be repeated due to imperfections (see Fig. 2).The paint process is repeated up to 3 times for each part, if the previous painting operation did not meet specifications, resulting in 4 regimes. The time in system grows during the day, but the growth rate varies with the interarrival time. The purpose of the simulation experiment is to express the time in the system, z, as a function of the mean time between arrivals of parts. The metamodels were built in MATLAB 7.10 with some custom made routines. The observations zijkwere gathered from 6 independent replications of 9 equally spaced design points in the [6, 6.8] experimental region. From each replication of 51000 observations, the first 1000 observations were removed to mitigate initialization transient and provide a good separation between regimes.Every observation from each simulation run is grouped into one of four switching regimes. From each regime, a growth rate is determined by the slope of the line that is obtained by applying a least squares to the regime observations (see Fig. 3). The probability of each regime is computed from the relative number of observations of each regime. At each design point, a set of six replications are performed. The average values of six computed slopesy¯si.(see Table 2) are determined (measure of interest), as well as their variancesσsi=σ^si(see Table 3) and the average probability of each regimeλ¯si.=λ^si(see Table 4).The resulting metamodel relates the interarrival time with the growth rate (see Fig. 4). All four regimes must be adjusted simultaneously, taking into account the relative variancesσ^siand the regime probabilityλ^si. In the first approach, a mixture weighted least squares method is used to compute theθvalues of the metamodel. In a second approach, a maximum likelihood method is applied.The results of performing independent weighted least squares on each regime provide the initialθvalues for the mixture weighted least squares and maximum likelihood estimation (see Table 5). Theseθvalues are used as initial values for the minimization Neder–Mead simplex method (see Lagarias, Reeds, Wright, & Wright (1998)), implemented by fminsearch in Matlab, also depicted in Table 5.The adjusted values through mixture weighted least squares and maximum likelihood methods produce indistinguishable lines in Fig. 4. However, the SSE values, depicted in Table 6, provide an insight into the precision of the resulting metamodelsSSE=∑i=1n∑s=1Sλ^siσ^si2/r(y¯si·−fs(xi,θ^s))2whereθ^s=(θ^s0,…,θ^sp).If all regimes are adjusted simultaneously, a better adjustment is achieved. The maximum likelihood method provides a slightly better fit.

@&#CONCLUSIONS@&#
Metamodels provide a simple representation of the input/output relationship of a simulation model. When the output data exhibits independent groups of data, the metamodel should reproduce that grouping if a good representation of the original simulation model is to be achieved. In order to reproduce those groups, the metamodel must switch between different regimes. Each regime is modeled by a different mathematical function and switch mechanism is activated, usually a probability. The probability at each design point can estimated using the relative frequencies of the observations. As the regimes result from the same output sequence, and are therefore dependent, they must be adjusted simultaneously. A number of simulation replications should be performed, if the variances of output are to be estimated. The metamodel construction processes the proposed fitting with a set of functions, one for each regime. Although each of the functions is usually linear, the resulting mixture is nonlinear. An unconstrained minimization algorithm is employed to estimate the metamodel parameters for the set of functions. The initial values for the minimization are obtained from the independent estimation of each regime to improve the performance of the algorithm, and consequently the precision of the estimated parameters. The example presented displays four regimes that are fitted with first degree polynomial functions. The metamodels are compared using the sum of squared errors and show that a global estimation improves the quality of the fitted metamodel. The maximum likelihood method provides slightly better fitting results and the resulting estimators are consistent.The verification of Proposition 1 consists on applying the following Theorem stated by Chanda (1954) to switching regression.Theorem 1Let (u1, u2, …, un) a random sample such that ui are independent and identically distributed with probability density function f(u;θ), whereθis a vector of unknown parameters. If the following conditions hold1.For almost all u and for allθ∈Ω¯⊂Rk(A.1)∂lnf∂θr,∂2lnf∂θr∂θs,and∂3lnf∂θr∂θs∂θt,r,s,t=1,…,k.For almost all u and for allθ∈Ω¯⊂Rk(A.2)|∂f∂θr|<Fr(u),|∂2f∂θr∂θs|<Frs(u)C,and|∂3f∂θr∂θs∂θt|<Hrst(u),r,s,t=1,…,k.where H is such that∫−∞∞Hrst(u)f(u;θ)du≤M<∞and Fr(u) and Frs(u) are bounded forr,s,t=1,…,k.For allθ∈Ω¯⊂Rk,the following matrix is positive definite:(A.3)I(θ)=∫−∞∞(∂lnf(u;θ)∂θ)(∂lnf(u;θ)∂θ)Tf(u;θ)dxThen, there exists a unique consistent estimatorθ^which is the solution of the likelihood equations∂lnL∂θj=∂∂θj(∑i=1nlnf(ui;θ))=0,j=1,…,kMoreover,n(θ^−θ*)is asymptotic normally distributed with mean zero and variance-covariance matrixI(θ*)−1,whereθ*is the true value ofθand I(θ*) is the Fisher information matrix.Let the density probability function (5) written asf(y;θ)=∑i=1Sfswherefs=λ^s2πσ^s2/rexp[−12σ^s2/r(y−θs0−∑l=1pθslxl)2]Then it may observed that the following derivatives exist∂f∂θ=(∂f1∂θ10,…,∂f1∂θ1p,…,∂fS∂θS0,…,∂fS∂θSp)T∂2f∂θ∂θT=[∂2f1∂θ102…∂2f1∂θ10∂θ1p…0…0⋮⋮⋮⋮∂2f1∂θ1p∂θ10…∂2f1∂θ1p2…0…0⋮⋮⋮⋮0…0…∂2fS∂θS02…∂2fS∂θS0∂θSp⋮⋮⋮⋮0…0…∂2fS∂θSp∂θS0…∂2fS∂θSp2]Consideringw=(1,xT)T,then,w1=1,w2=x1,…,wp+1=xpthe following may be written.∂f∂θsi=∂fs∂θsi=fswi+1σ^s2/r(y−wTθs)∂2f∂θsi2=∂2fs∂θsi2=wi+12σ^s2/r[1σ^s2/r(y−wTθs)2−1]fs∂2f∂θsi∂θkj=∂2fs∂θsi∂θkj=0,k≠s∂3fs∂θsi∂θkj∂θlt=0,k≠sorl≠s∂2f∂θsi∂θsj=wi+1xj+1σ^s2/r[1σ^s2/r(y−wTθs)2−1]fs∂3f∂θsi∂θsj∂θsk=wi+1wj+1wk+1(σ^s2/r)2(y−wTθs)[1+1σ^s2/r(y−wTθs)2]fsConsequently, the following derivatives exits and the first condition (A.1) is verified:∂lnf∂θsi=∂fs∂θsi1f(A.4)∂2lnf∂θsi∂θkj=1f∂2fs∂θsi∂θkj−1f2∂fs∂θsi∂fk∂θkjIf k ≠ s then∂2fs∂θsi∂θkj=0and, as a result,∂2lnf∂θsi∂θkj=−1f2∂fs∂θsi∂fk∂θkjUsing Eq. (A.4) the following third degree derivative may be written∂3lnf∂θsi∂θkj∂θtm=2∂fs∂θsi∂fk∂θkj∂ft∂θtm1f3−∂2fs∂θsi∂θtm∂fk∂θkj1f2−∂fs∂θsi∂2fk∂θkj∂θtm1f2−∂ft∂θtm∂2fs∂θsi∂θkj1f2+∂3fs∂θsi∂θkj∂θtm1fIf k and t are both not equal to s then∂3lnf∂θsi∂θkj∂θtm=2∂fs∂θsi∂fk∂θkj∂ft∂θtm1f3The first and second derivatives off(y¯;θ)are continuous in bothy¯andθ. Consequently, they are bounded forθ∈Ω¯andy¯∈[a;b]⊂R. Ify¯is arbitrarily large, the derivatives remain bounded because the largest of these derivatives isO=(y¯4exp(−y¯2)). Also, the largest value of the third derivatives of ln f isO(y¯6). Moreover, all the moments of f exist and they are finite for allθ∈Ω¯,so we may choose a constant M such that the second condition (A.2) is satisfied.The third condition (A.3) is also satisfied because I(θ) is a variance-covariance matrix.