@&#MAIN-TITLE@&#
An evolutionary algorithm for multi-criteria inverse optimal value problems using a bilevel optimization model

@&#HIGHLIGHTS@&#
Present an uniform multi-objective bilevel programming model for both inverse optimal value problems and inverse optimization problems.For the weighted aggregation method, give a search method for finding Pareto-optimal solutions located in concave region on the Pareto front.Propose a new problem-specific encoding, which makes the search space become finite.

@&#KEYPHRASES@&#
Inverse optimal value problem,Bilevel program,Evolutionary algorithm,Solutions,

@&#ABSTRACT@&#
Given a linear program, a desired optimal objective value, and a set of feasible cost vectors, one needs to determine a cost vector of the linear program such that the corresponding optimal objective value is closest to the desired value. The problem is always known as a standard inverse optimal value problem. When multiple criteria are adopted to determine cost vectors, a multi-criteria inverse optimal value problem arises, which is more general than the standard case. This paper focuses on the algorithmic approach for this class of problems, and develops an evolutionary algorithm based on a dynamic weighted aggregation method. First, the original problem is converted into a bilevel program with multiple upper level objectives, in which the lower level problem is a linear program for each fixed cost vector. In addition, the potential bases of the lower level program are encoded as chromosomes, and the weighted sum of the upper level objectives is taken as a new optimization function, by which some potential nondominated solutions can be generated. In the design of the evolutionary algorithm some specified characteristics of the problem are well utilized, such as the optimality conditions. Some preliminary computational experiments are reported, which demonstrates that the proposed algorithm is efficient and robust.

@&#INTRODUCTION@&#
General optimization problems are to determine the values of variables such that the objectives can achieve the optima on the condition that all coefficients are given in objectives and constraints. Inverse optimization is to execute an ‘inverse’ procedure, that is to infer some parameters in objective function or in constraints such that the optimal solutions satisfy a pre-specified standard. A standard inverse optimization problem can be described as follows: given an optimization problemP:minx∈XcTxand a desired optimal solution x∈X, determine a cost vector c such that x is optimal to problem P. In addition, some additional conditions on c are often taken into account. For example, c should be as close to a pre-determined vector c′ as possible under some ℓp-norm, that is, the deviation ∥c−c′∥pshould be minimized. This problem was first introduced by Burton and Toint [1,2] in a shortest path problem, in which all weights on edges need to be determined such that some pre-specified edges can form the short-path. In this class of problems, the objective function is also decided by the selected measure norm. For instance, when the deviation is evaluated by ℓ2-norm, the objective function of inverse optimization can be transformed into a convex quadratic function [1]. If P is a linear program, and ℓ1 and ℓ∞ norms are adopted, linear programming can be utilized to deal with this class of problems [3,4]. For a comprehensive survey of the literature on inverse optimization, please refer to [5].If the problem is to find a vector c such that the objective value is equal or close to a pre-specified value, the problem is known as an inverse optimal value problem. Obviously, the inverse optimal value problem is a generalized version of the standard inverse optimization problem, because the objective values must be close to each other when two optimal solutions approach for any continuous functions. This kind of problems can be stated as follows: given an optimization problem P, a desired optimal objective value z*, and a set C of feasible cost vectors, determine a cost vector c*∈C such that the corresponding optimal objective value of P is closest to z*[6,7]. The inverse optimal value problem has received little attention in the literature. Berman [8] discussed a minimal location model, which is to determine edge lengths in a graph such that the induced minimal distance from a given vertex to all other vertices is within prescribed bounds, and shows the problem is NP-complete for general graphs.This paper is motivated by an application in telecommunication bandwidth pricing proposed by Paleologo and Takriti [9]. In this research, the problem the authors consider is to infer the correct prices on city-to-city links on its bandwidth network, such that the total price of the links on the cheapest path between arbitrary two cities should be close to the pre-specified one. The problem is modeled as a directed graph with m nodes and n arcs, in which the length associated to each arc is the unknown price. Mathematically, the problem is to determine the length cjof each arc j, j=1, …, n, so that the length of the shortest path between a node pair is equal to a given value. We denote by K the number of origin-destination pairs for which the desired shortest distance pkis known. The problem becomes that of finding a nonnegative c such that(1)minxkcTxk=pk,s.t.A¯xk=bk,xk≥0.k=1,…,KAlternatively, we may formulate the problem as a multi-criteria optimization problem(2)minc≥0(f1(c),…,fK(c))Here,fi(c)=|minxi∈XicTxi−pi|,Xi={xi|A¯xi=bi,xi≥0}, i=1, …, K, C is a feasible region and |.| denotes the absolute value. In fact, the bandwidth pricing problem is essentially a multi-criteria inverse optimal value problem [7,9].For the case in which K=1 is a trivial one, Ahmed and Guan [7] showed that the inverse optimal value problem is NP-hard in general, and for the case that the set of feasible cost vectors is polyhedral, the authors developed an algorithm for the problem based on solving linear and bilinear programming problems. Lv [6] proposed a bilevel programming model and applied the duality principle of linear program to transform the problem into a single level nonlinear program. Then, a penalty function method was used to solve the equivalent problem. Despite the fact that these procedures are efficient for the trivial case (single-objective inverse optimal value problem), they cannot be extended directly to multi-criteria cases. From the multi-objective point of view, Paleologo and Takriti [9] suggested a mixed-integer programming formulation by the weighted sum of the objectives for this bandwidth pricing problem. However, it can only give one optimal solution in each run of the algorithm and needs to solve a mixed-integer program which is computationally intractable.In fact, problem (2) is a special multi-criteria bilevel programming problem (MCBLPP). MCBLPP describes a hierarchical structure, the constraint region of the first level problem (leader's problem/upper level problem) is implicitly determined by the second level optimization problem (follower's problem/lower level problem), and the upper and/or lower levels have more than one objective. At present, some algorithmic approaches and theoretical results have been developed for this kind of the problems [10–13]. In optimization procedures involving multiple objectives, some population-based algorithms have been widely adopted since these algorithms can provide a Pareto optimal front for various preferences, such as evolutionary algorithm (EA) and it's variations. Deb [13] proposed an efficient EA for solving MCBLPPs, which almost puts no requirements on all functions involved, such as convex or differentiable. But for problem (2) in which the lower level is single objective and is also linear for any fixed cost vector c, these procedures are computation-expensive.The purpose of this paper is to discuss a special MCBLPP which is a generalized version of problem (2) and then provide an efficient approach for solving most of inverse optimization problems with multiple criteria. Based on the proposed MCBLPP model, we develop an efficient EA by taking advantage of a dynamic weighted aggregation method as well as the optimality conditions of the optimization problem. In our approach, the potential bases of the lower level program are encoded as chromosomes, and the weighted sum of the upper level objectives is taken as a new optimization function, by which some potential nondominated solutions can be generated. It is worth noting that the coding scheme makes the algorithm evidently different from other EAs, such as Deb's method using NSGA-II, mainly because the coding technique makes the search space become finite even for a continuous MCBLPP.This paper is organized as follows. Multi-criteria bilevel programming model is proposed and some basic notations are presented in Section 2, and Section 3 gives evolutionary operators and displays our algorithm. Some computational examples are given and solved in Section 4. We finally conclude our paper in Section 5.Problem (2) can be rewritten as(3)minc≥0(|cTx1−p1|,…,|cTxK−pK|)mincTx1s.t.A¯x1=b1,x1≥0;mincTx2s.t.A¯x2=b2,x2≥0;…mincTxKs.t.A¯xK=bK,xK≥0.Obviously, the problem is a multi-criteria bilevel programming problem with multiple lower level problems. Note that no common variables are shared between arbitrary two lower level problems, therefore it is equivalent to(4)minc≥0(|cTx1−p1|,…,|cTxK−pK|)min∑i=1KcTxis.t.A¯xi=bi,xi≥0,i=1,…,K.Further, setc1=(cT,0,…,0︸K)…cK=(0,…,0,cT︸K)andx¯=(x1T,…,xKT)T,C=c1+⋯+ckThen, (4) can be reformed as(5)minc≥0(|c1x¯−p1|,…,|cKx¯−pK|)minCx¯s.t.diag(A¯)x¯=b,x¯≥0Here,b=(b1T,…,bKT)T. In order to obtain an uniform representation, letw1=In0⋱0,…,wK=0⋱0InThen, we have ci=Cwi, i=1, …, K. We consider the nonlinear model as follows(6)minc≥0((Cw1x¯−p1)2,…,(Cwkx¯−pk)2)minCx¯s.t.diag(A¯)x¯=b,x¯≥0.Evidently, (6) and (5) have the same optimal solutions. For general inverse optimization problems, when P is linear and multiple criteria are taken simultaneously to measure the cost vector c, multi-criteria cases arise. As a result, we give an uniform model for this kind of MCBLPPs as follows(7)minx(F1(x,y),…,FK(x,y))s.t.G(x,y)≤0minyxTys.t.Ay=b,y≥0.Here, x, y∈Rn, and Fi(i=1, 2, …, K), G are nonlinear. In this problem(8)minx(F1(x,y),…,FK(x,y))s.t.G(x,y)≤0.and(9)minyxTys.t.Ay=b,y≥0.are called the upper level problem and the lower level problem, respectively. The variables of problem (7) are divided into the upper level variables x=(x1, …, xn)Tand the lower level variables y=(y1, …, yn)T. Similarly, F:Rn×Rn→RKis called the upper level objective function, and xTy is called the lower level objective function. G(x, y)≤0 and Ay=b(∈Rq), y≥0, are called the upper level and the lower level constraints, respectively.The decision-making process of (7) can be stated as follows: the upper level decision-maker first selects a strategy x to optimize his/her objective, then the lower level decision-maker observes the upper level's selection and finds a strategy y to optimize his/her own objective. If such pair (x, y) satisfies the upper level constraints, it is called feasible in a bilevel decision-making procedure [14]. The purpose of solving (7) is to find out a Pareto-optimal solution set from all feasible points.Over the past 20 years or so, the field of bilevel optimization has received a lot of attention in developing efficient algorithms and applying bilevel models and optimization approaches to deal with hard real-world problems [15–21]. For bilevel programming problems (BLPPs) with multiple objectives, there exist few papers for this class of problems [11,13,24,22,23].Deb and Sinha [13] suggested a hybrid evolutionary algorithm for solving bilevel problems with multiple objectives in both levels. In the proposed procedure, two interacting populations are kept and both upper and lower levels are searched by EAs. The proposed algorithmic method is utilized universally since it has no requirements on the functions involved, such as convexity and differentiability. But Deb’method is computation-expensive to solve (7) due to the special structure of the problem. When all objective functions are linear, and the constraints at both levels define a polyhedra, Calvete [23] proved that the set of efficient solutions is non-empty, and based on weighted sum techniques, presented some methods of computing efficient solutions. However, the method cannot be extended to nonlinear cases. Ye [11] presented some optimality conditions by replacing the lower level problem with its KKT conditions. Also, for the general multiobjective bilevel problem, some necessary optimality conditions are also derived by considering the combined problem [11]. However, most theoretical results cannot be applied directly to develop efficient algorithmic approaches in view of rigorous requirements on functions involved. In addition, for most of the existing evolutionary algorithms, the computational performance will get worse as both the scale of problem and search space become larger. In view of these facts, an efficient algorithm for problem (7) should be:•population-based, which can provide a Pareto front instead of a single solution in one run.problem-specific, which means some specific characteristics of the problem can be used in designing an algorithm.less dependent on the size of feasible region. Otherwise, it will be time-consuming for some real-world problems with a larger search space.In the design of our EA, the first item is satisfied automatically. Also, the proposed algorithm explores a discrete space instead of continuous space, which differs from classical EAs, and the optimality conditions are taken advantage of as well as the characteristics of functions. It means that the second and the third items are taken into account very well.Now we introduce some related definitions and notations as follows [15].(1)Constraint region: S={(x, y)|G(x, y)≤0, Ay=b, y≥0}.Feasible region of the lower level problem for x fixed: S′={y|Ay=b, y≥0}.Projection of S onto the upper level decision space: S(X)={x|∃y, (x, y)∈S}.Rational reaction set of the lower level for each x∈S(X):M(x)={y|y∈argmin{xTv,v∈S′}}.Inducible region: IR={(x, y)∈S|y∈M(x)}.In terms of aforementioned definitions, problem (7) can also be written as:min{(F1(x,y),…,FK(x,y))|(x,y)∈IR}In order to ensure that problem (7) is well posed, in the remainder, we always assume thatA1.S is nonempty and compact.For all decisions taken by the upper level, the lower level has some room to react, that is, S′≠ϕ.The lower level problem has unique optimal solution for each fixed x.The rank of matrix A is q.Also, in order to solve the upper level programming easily, we further assume the functions Fi(i=1, …, k), G are convex and differential with respect to x and y.Definition 1DominationFor∀(x,y),(x¯,y¯)∈IR, (x, y) is said to dominate(x¯,y¯), i.e.,(x,y)≻(x¯,y¯), if and only if,Fi(x,y)≤Fi(x¯,y¯),i=1,…,Kand ∃i0∈{1, …, k} such thatFi0(x,y)<Fi0(x¯,y¯).Definition 2Pareto-optimal solution(xˆ,yˆ)∈IRis a Pareto-optimal solution if and only if there exists no (x, y)∈IR such that(x,y)≻(xˆ,yˆ).Definition 3Pareto frontGiven a Pareto-optimal solution set, the set of the objective function values in the objective space is called a Pareto front.Recall that for any (x0, y0)∈IR, y0 must be optimal to the follower program when x is fixed to x0 and is a vertex of the feasible region consisting of Ay=b, y≥0. In addition, the feasible region has only finite vertices. We take advantage of the characteristics of linear programming to present an evolutionary algorithm for solving MCBLPP (7). At first, to search potential bases of the follower linear program. For each fixed base B, one can obtain a feasible basic solution y0 to the follower problem by taking all basic variables as B−1b and nonbasic variables as 0. Then, if y0≥0, given a weight vectorw0, we take the weighted sum of all objectives of (8) as a new objective function, and replace y with y0. As a result, a new nonlinear program is generated in which only x is involved. Finally, we optimize the generated nonlinear program for obtaining x0, then (x0, y0) is a potential Pareto optimal solution. The main idea of the paper is to search all these points as different weight combinations and bases are chosen and to find out Pareto-optimal solutions from them.Since EA is used to search all bases of the follower's program, we encode each basis of (9) as an individual of population. Let V={1, 2, …, n} be the set of all column indices of A. q elements are selected from V and denoted by l={i1, i2, …, iq}. Furthermore, if these columns are linearly independent, then l is taken as an individual. An initial population with the size of Npcan be generated by lexicographically selecting Npindividuals.But it is computation-expansive if the determinant method is used for each l to judge whether the selected columns are linearly independent. We present a simplified approach by the following example.(10)A=a11a12a13a14a21a22a23a24Here, q=2, n=4. For convenience, we denote by A{i, j} the matrices consisting of the ith and jth columns of A. Without loss of generality, set(11)A{1,2}=a11a12a21a22be nonsingular, then we get an individual l={1, 2}. Further, we let(12)A{1,2}−1A=10a¯13a¯1401a¯23a¯24Ifa¯23≠0, then A{1, 3} is nonsingular, that is, l′={1, 3} is also an individual, otherwise, l′ is ignored. The same procedure can be applied to judge whether l″={1, 4} is an individual.If A{1, 3} is nonsingular, based on A{1, 2}−1, we can utilize the pivoting algorithm to obtain A{1, 3}−1 as done in the simplex method.For any individual l, the basic matrix associated with l is denoted by B consisting of the first q columns of A. If(13)B−1b≥0we then provide a weight vector setΛl={λi|λi=(λi1,…,λiK),∑j=1Kλij=1,λij∈[0,1],i=1,…,s}. Here, s is a positive integer determined previously. In fact, one can easily generate the set according to the following procedure: First, we take K numbers at random from interval [0, 1] (there exists at least one positive number), and denote these numbers by γj, j=1, …, K. Then, takeλi=((γ1/∑v=1Kγv),…,(γK/∑v=1Kγv)),i=1,…,s. After Λlis determined, we solve a group of nonlinear programs as follows(14)minx∑j=1KλijFj(x,y)s.t.G(x,y)≤0,xN−xBB−1N≥0,i=1,…,s.Here, A=(B, N), xNis the objective coefficient vector associated with all nonbasic variables, whereas xBis associated with all basic variables, andy=(B−1b,0)Tis the optimal solution to the follower's program. In fact, inequality (13) and constraint xN−xBB−1N≥0 guarantee that B is feasible and optimal in the follower's problem for some values of x.Recall the previous assumptions, the programs involved in (14) are convex, there exist dozens of optimization approaches for the problems of this kind, such as cutting plane algorithms and active-set algorithms, thus they can easily be solved. Especially, when Fiand G are linear, the simplex method can be employed. If (14) has an optimal solution x for some i, then (x, y) is a potential Pareto solution. Note that (14) involves s mathematical programs, it means that an individual l can provide s potential Pareto solutions with different x′s, which differs from classical EAs.It should be noted that in (14) all s problems have the same constraints. If one of them is solved, then the obtained solution can be taken as a starting point for solving other problems, which can reduce the complexity of computation. Also, we haveTheorem 1The existence of solutions to(14)is indifferent to the given weight coefficients, i.e., if one of s problems has an optimal solution, then other optimization problems have the optimal solutions; otherwise, there exists no solution for all of s optimization problems.ProofSince S is compact, it follows that the feasible region of (14) is bounded. If one among s problems has an optimal solution, then it can be inferred that the feasible region of (14) is nonempty. Hence, all s problems have optimal solutions. If one among s problems has no solution, it means the shared feasible region is empty. This completes the proof.When an individual is evaluated, (13) is first checked. If the inequality holds, then (14) is solved. Furthermore, from Theorem 1, if (14) has one solution for some λi, then s potential Pareto optimal solutions can be obtained by solving s optimization problems in (14); otherwise, Fi(i=1, …, K) are taken as infinity.In addition, it should be noted that the weighted aggregation method has a drawback, i.e., it is difficult for the search algorithm to find out the points located in concave region on Pareto fronts whatever weight combinations are taken [25]. In order to overcome the shortcoming, we execute a procedure as follows: First, keep all processing points in the optimization of (14) as well as the optimal solutions for each individual, and denote the set of these points by ϒ. Since these points come from an individual, it follows that y associated with these points is unique, and (xi, y)∈IR, ∀xi∈ϒ. Then, randomly choose two points from ϒ and execute arithmetic crossover. The generated points are put into ϒ. The process is not stopped until pre-determined times r is achieved. After doing so, there arises a problem whether y is still optimal to the follower problem for these generated points. We haveTheorem 2If (xi, y)∈IR, i=1, 2, come from the same individual, andx¨=αx1+(1−α)x2,α∈[0,1], then(x¨,y)∈IR.ProofSince (xi, y)∈IR, i=1, 2, it follows that (13) holds. Also, (xi, y), i=1, 2, come from the same individual, it meansxNi−xBiB−1N≥0,i=1,2hold. Multiple the inequalities by α and (1−α), respectively, and add them. We get(αxN1+(1−α)xN2)−(αxB1+(1−α)xB2)B−1N≥0i.e.x¨Ni−x¨BiB−1N≥0Recall that G is convex, it follows that both the feasibility and the optimality are satisfied. This completes the proof.Finally, we retain s optimal solutions in ϒ, but delete some of the other points located in dense parts from the set using the clustering technique [26], and keep that the element number is κ(κ>s) (a pre-determined integer).All potential Pareto-optimal solutions generated by EA are evaluated by the dominating procedure and both the Pareto solutions and the front of (7) are finally determined.We choose two crossover parents l={l1, l2, …, lq} andl′={l1′,l2′,…,lq′}. First, a cross-position is determined at random in l′ as done in one-point crossover operator. Then the components at left-hand side of the cross position are, one by one, taken as entering elements for l and correspondingly, some components in l are removed as leaving elements, which almost follows the same procedure as in the simplex method except for the selection of entering-basis variables. Also, the procedure makes the total of elements in l keep unchanged. For any entering element which is also in l, the replacement is ignored. When all entering procedures are finished, a crossover offspring is generated. When a cross-position is given in l, some elements in l′ will be replaced and the other offspring can be generated.It should be noted that when the replacements are executed one by one, the inverse matrices associated with individuals can be obtained by the pivot algorithm. Also, based on the minimum-ratio principle in selecting leaving-basis variables, inequality (13) associated with the crossover offspring always holds.Letl¯={l1,l2,…,lq}be a selected mutation parent, andB˜=A{l1,l2,…,lq}. First, to choose randomly an integeri0∈V∖l¯andAi0is taken as an entering-basis column. The pivot operation is executed and a leaving-basis variable is determined. If the pivot operation cannot be executed, we choose anotherAi0until the operation can proceed. When the pivot process is finished, a new individual, as a mutation offspring, is obtained. As discussed in the crossover operation, (13) holds for each mutation offspring.In this section, based on a weighted aggregation technique, we present an evolutionary algorithm (EA/WA). In the proposed algorithm, the weight vector set is first given and then changed periodically.Step 0.Some parameters are given, i.e., population size Np, crossover probability pc, mutation probability pmand positive integers s, t, r, κ, NnonD. Let set Ω=ϕ.Npindividuals are generated, these individuals form an initial population denoted by pop(0). Let g=0;Generate a set Λ consisting of s weight vector;For each individual, solve (14) to obtain all points of ϒ. Compute Fi, i=1, …, K of each point in ϒ and put all obtained non-dominated solutions into Ω. If some points are dominated in Ω, then delete these dominated points; If the element number of Ω is larger than NnonD, then delete some points located in dense fractions on the Pareto front by using the clustering method until there are NnonDpoints in Ω [26].Crossover parents are chosen from pop(g), and the crossover is executed according to crossover probability pc. The crossover offspring set is denoted by Oc;Mutation is executed to each individual according to mutation probability pm, and mutation offspring set is represented as Om;If g≥t and g mod t=0, then update Λ; Otherwise, turn to the next step;Evaluate offspring generated by crossover and mutation operators and update the non-dominated set Ω. Randomly choose Npindividuals from pop(g)∪Oc∪Omas next population pop(g+1).If the termination criterion is satisfied, then output Ω; otherwise, let g=g+1, return to Step 4.The advantage of the algorithm is that the searching space is the set of potential bases and finite, which means that it is enough for the algorithm only to search all vertices of the follower's feasible region. Also, to solve (14) is a local searching process for x, hence, it is of much help for EA/WA to exploit the space S(X).In fact, it is not necessary for us to assume the leader's functions, F and G, are convex. If the nonlinear programming (14) can be solved, we can remove the assumption.In this section, two classes of problems are first given and then solved. One is an inverse optimization problem with two criteria, whereas the other is a set of inverse optimal value problems with two criteria at different scales. We perform simulations of EA/WA in Matlab 7.0 on a personal computer (Microsoft Windows XP SP2, Inter® Core™ 2, CPU2.99GHz, RAM 2.0G). In order to compare the computational results with the real optimal solutions of problems or with those provided by other algorithms, some measure methods must be adopted. In fact, to evaluate the quality of the existing algorithms, several quality measures have been used or proposed in the literature:I.Number of function evaluations or CPU time required [27,28]: it measures the time complexity of a multi-objective optimization algorithm;Number of solutions found [27,28]: it measures the number of solutions that can be found by a multi-objective optimization algorithm;Hypervolume indicator [29–31]: this metric calculates the volume (in the objective space) of the union of some hypercubes, in which each hypercube is constructed with a referent point (rp) and a solution as the diagonal corners of the hypercube. For minimized problems, the larger the indicator is, the better the obtained solutions are.C/IC-measure [30,31,25]: C(IC)-measure was proposed to compare the relative quality of two sets of solutions. It measures the percentage of solutions in one set such that these solutions are at least as good as (i.e., not dominated by) those in the other set. We can describe the IC-measure as follows: Let A be a set of nondominated solutions by Algorithm A and B be a set of nondominated solutions by Algorithm B. We denote the nondominated solution set of A∪B by D, then IC(A)=(|D∩A|)/(|D|) and IC(B)=(|D∩B|/|D|), here, |.| represents the element number of a set. If IC(A)>IC(B), it means that Algorithm A finds out more high-quality solutions than Algorithm B.U-measure [32]: U-measure is given to measure the uniformity of a given set of nondominated solutions over the Pareto front, which can be finished in the following three steps: (1) determine the domains of the Pareto front over which uniformity is measured, (2) determine the nearest neighbors of each solution in the objective space, and (3) compute the discrepancy among the distances between nearest neighbors. The U-measure is equal to this discrepancy where a smaller discrepancy indicates a better uniformity.In our computational experiment, we adopt CPU time, the hypervolume indicator, IC-measure and U-measure to evaluate the proposed algorithm and keep at most 100 Pareto-optimal solutions outputted when the computation is finished.First, we construct an inverse optimization problem (IOP) as follows: find cost vector c∈C={c|0≤ci≤10, i=1, 2} such that ∥c−(1/(10−i), 1)∥1(i=3, 7) are as small as possible and the linear program(15)maxy≥0cys.t.y2≤10,i10−iy1+y2≤10+i210−i,i=3,7,y1≤10,can achieve its optimal solution at point C(7.9, 7.9), refer to Fig. 1. In fact, these two reference points, (i/(10−i), 1), i=3, 7, are the gradients of the second group of constraint functions (straight lines cc1 and cc2 in Fig. 1). Also, the shaded part shows the desired region of objective vector c in the inverse optimization problem (IOP). As a result, it is easy for one to obtain the optimal solution set {(a, 1)∣a∈[3/7, 7/3]} to problem (IOP). These true optimal solutions and the corresponding Pareto front are shown in Fig. 2.In order to solve problem (IOP), we transform the problem into the following MCBLPP:(16)min0≤c≤10∥c−310−3,1∥1,∥c−710−7,1∥1s.t.37≤c1c2≤73,miny≥0−cys.t.y2≤10,i10−iy1+y2≤10+i210−i,i=3,7,y1≤10.where the leader's constraints guarantee that c can be taken in a reasonable bounded region and the optimal solution can be achieved at vertex C. Further, the problem is equivalent to(17)min0≤c≤10(u1+v1+u2+v2,u3+v3+u4+v4)s.t.37c2≤c1≤73c2,c1−310−3+u1−v1=0,c2−1+u2−v2=0,c1−710−7+u3−v3=0,c2−1+u4−v4=0,ui≥0,vi≥0,i=1,2,3,4miny≥0−cys.t.y2≤10,i10−iy1+y2≤10+i210−i,i=3,7,y1≤10.Problem (17) is a linear multi-objective bilevel program, then the resulting problems (14) are linear problems, and the simplex method is used to solve these problems. We take the parameters of EA/WA as follows:•Population size Np=5;Crossover probability pc=0.8;Mutation probability pc=0.01;Maximum number of generations MaxGen=50;Number of nondominated solutions NnonD=100;Number of weight vectors s=10, and r=10, κ=20;Number of interval generations t=5.We execute EA/WA 10 independent runs on problem (IOP), and record CPU time, the optimal solutions and objective values. All Pareto-optimal solutions found belong to the true Pareto-optimal set, it means that Pareto front can be fitted very well. From all 10 groups of results we randomly choose one and plot the Pareto front and Pareto solutions, which are shown in Fig. 2. For all 10 runs we calculate the mean CPU time is 0.9s and the mean of U-measure values is 0.08.For the case of inverse optimal value problem with multiple evaluation objectives, Paleologo proposed a real-world application [9], but no available data were provided. In order to test the performance of the proposed algorithm on this kind of problems, we construct the following type of test problems (IOVP) with 6 different scales from 5 to 30 dimensions (Dim) (these scales are shown in Table 1).(18)minx≥0((xTy−p1)2,(xTy−p2)2)s.t.A1x+B1y≤b1;miny≥0xTys.t.B2y=b2,which has the same type as problem (6) or (7), and x has the same dimensions as y. In these constructed problems, all elements in A1, Bi, bi, i=1, 2, are generated randomly in the interval [−50, 50], and the vector p=(p1, p2) is taken at random in [0, 50]. In order to guarantee that the constraint region is bounded, we restrict all variables in [0, 100]. The number of the follower's constraints is ⌈Dim*0.6⌉, whereas that of the leader's constraints is taken directly as Dim. For problems (14) generated in these test examples, the active-set method is used to solve these quadratic programs. In order to test the stability and performance of the proposed algorithm, we construct two computational examples (denoted by P1 and P2) for each scale by using the above procedure. As a result, there are total 12 examples.For nonlinear multi-objective bilevel programming problems, there are few efficient algorithms. Deb proposed NAGS-II for multi-objective optimization problems and extended the method to multi-objective bilevel program [13,24]. But for the case of problem (6) or (7) in which the follower has only one objective, the method presented in [13] is computationally expensive since it randomly searches the Pareto solutions of the lower level in feasible regions. We revise the method as follows: For each variable value taken by the upper level, the lower level is solved by using the simplex method, whereas the upper level variables are evolved via NSGA-II. The revised version is more efficient than the original one since the solutions of the lower level can be obtained very fast and accurately. In the remainder, for the purpose of simplicity, we also denote the revised NSGA-II by NSGA-II.In order to fairly compare EA/WA with NSGA-II, we set a maximum number of objective evaluations (Num-Obj-Eval) for each problem, refer to Table 1. We run EA/WA and NSGA-II on each problem until the Num-Obj-Eval is achieved, and record the CPU time, Pareto-optimal solutions and corresponding objective values (Pareto front). Furthermore, in order to test the stability of the algorithms, we execute EA/WA and NSGA-II algorithms 10 independent runs, and compute mean CPU time and success rate in 10 runs for each computational example. Also, To compare the quality of the solutions, we adopt the hypervolume indicator, IC-measure and U-measure.We modify Np=100 except for the case Dim=5, and keep other parameters unchanged. MaxGen is omitted since the algorithm stops when the maximum number of objective evaluations is achieved for these 12 computational examples.First, we define a term “success rate”: If an algorithm finds out at least 5 Pareto-optimal solutions in a run, then the algorithm executes a successful run. The success rate is the proportion of successful runs in all runs. For each class of problems with the same scale, we record the success rate in all 20 runs. In addition, the mean CPU time for each class of problems is also calculated. The success rate and the mean CPU time are shown in Table 2. From Table 2, one can see that the success rate of NSGA-II decreases as the dimension increases, whereas EA/WA keeps the success rate of 100% unchanged. Also, when the algorithms stop after the same objective evaluations, the less CPU time the algorithm occupies, the more efficient the algorithm is. EA/WA needs much less CPU time than NSGA-II.In fact, in our experiment on 12 examples, when NSGA-II fails, it can only provide a nondominated solution with an unsatisfactory objective value. We randomly show a failure case of NSGA-II on an example (Dim=30, P1), refer to Fig. 3. It should be noted that for the example, EA/WA obtains a better Pareto-optimal front.Considering that too large objective values and too few Pareto-optimal solutions will be caused when a run of NSGA-II fails, and the comparisons of quality and/or uniformity of the obtained solutions can be made at the same order of magnitude, we simply compare the results provided by successful runs. These comparisons are made by taking three indicators into account, that is the hypervolume indicator, IC-measure and U-measure. Table 3shows the comparison of the means of the hypervolume indicator values for each problem, in which the reference point is taken as follows: each component of this point is taken as the maximal one among the corresponding objective values of all solutions found by two algorithms. From the table, one can easily see that EA/WA found better solutions than NSGA-II with regard to the indicator. In fact, NSGA-II will provide worse indicator values if all results are considered including failure cases. Table 4shows the means of IC-measure and U-measure of Pareto-optimal fronts provided by EA/WA and NSGA-II respectively. The mean values of IC-measure corresponding to EA/WA are larger than or equal to those provided by NSGA-II. Meanwhile, the mean values of U-measure generated by EA/WA is less than those given by NSGA-II. It follows that EA/WA found more high-quality Pareto-optimal solutions than NSGA-II, and the Pareto fronts provided by EA/WA are more uniform than those given by NSGA-II for all 12 problems.In order to show the distribution of solutions obtained by two algorithms, we randomly select one from all successful runs on each problem P1 and plot the Pareto fronts (Fig. 4). In these scatter diagrams, we randomly choose a segment with different distributions, and magnify them for the purpose of comparison. From these magnified parts, one can see that the Pareto-optimal solutions found by EA/WA are located more uniformly in objective space than those by NSGA-II.In order to illustrate the search process of these two algorithms, we take the hypervolume indicator as a measure value, and demonstrate the change of the value as the number of generations increases. When calculating the hypervolume, we select a dominated point as reference point for each problem. If a worse point is found in evolving process, we take the volume of the corresponding hypercube as 0. When the same genetic parameter values are taken, such as population size, crossover and mutation probabilities, etc, the hypervolume indicator can be affected only by search spaces and search schemes involving individual-encoding. We execute EA/WA and NSGA-II 5 runs for each problem P1, and calculate mean hypervolume values at each generation, in which the maximum number of generations is taken as 100. These hypervolume values are plotted as the number of generations increases from 1 to 100, refer to Fig. 5. It can easily be seen that the performance of NSGA-II becomes increasingly worse as the dimension increases since the success rate is lower. A simple analysis can be made for the result: for a problem with dim=30, there are 18 lower level constraints. It follows that the search space of EA/WA is composed of at mostC3018points, whereas that of NSGA-II is [0, 100]30. The small and finite search space makes EA/WA more efficient than NSGA-II.When the variables are restricted into interval [0, 2], that is, the constraint region is reduced, the success rates of NSGA-II become 100% for all problems. It follows that one must have a priori knowledge of Pareto-optimal solutions when NSGA-II is applied to solve larger-scale problems, while EA/WA always shows better performance on all computational examples.

@&#CONCLUSIONS@&#
