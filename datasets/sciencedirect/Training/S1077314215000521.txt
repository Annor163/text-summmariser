@&#MAIN-TITLE@&#
Learning representative and discriminative image representation by deep appearance and spatial coding

@&#HIGHLIGHTS@&#
Propose a deep appearance and spatial coding model to learn image representation.Adopt stacked ISA network combined with sparse RBM to perform appearance coding.Adopt over-complete spatial max-pooling to incorporate various spatial information.Introduce a structured sparse Auto-encoder to carry out spatial coding.The experimental performances on five challenging benchmark datasets outperform baselines and related work.

@&#KEYPHRASES@&#
Image classification,Deep learning,Structured sparsity,

@&#ABSTRACT@&#
How to build a suitable image representation remains a critical problem in computer vision. Traditional Bag-of-Feature (BoF) based models build image representation by the pipeline of local feature extraction, feature coding and spatial pooling. However, three major shortcomings hinder the performance, i.e., the limitation of hand-designed features, the discrimination loss in local appearance coding and the lack of spatial information. To overcome the above limitations, in this paper, we propose a generalized BoF-based framework, which is hierarchically learned by exploring recently developed deep learning methods. First, with raw images as input, we densely extract local patches and learn local features by stacked Independent Subspace Analysis network. The learned features are then transformed to appearance codes by sparse Restricted Boltzmann Machines. Second, we perform spatial max-pooling on a set of over-complete spatial regions, which is generated by covering various spatial distributions, to incorporate more flexible spatial information. Third, a structured sparse Auto-encoder is proposed to explore the region representations into the image-level signature. To learn the proposed hierarchy, we layerwise pre-train the network in unsupervised manner, followed by supervised fine-tuning with image labels. Extensive experiments on different benchmarks, i.e., UIUC-Sports, Caltech-101, Caltech-256, Scene-15 and MIT Indoor-67, demonstrate the effectiveness of our proposed model.

@&#INTRODUCTION@&#
The task of recognizing semantic category of an image remains one of the most challenging problems in computer vision. How to build suitable image representations is the most critical. In previous decades, Bag-of-Feature (BoF) [8] based models have achieved impressive success for image representations. Usually, the models employ carefully hand-designed features, e.g. SIFT [38], HOG [9] and LBP [1], along with visual dictionary learning for local feature coding, and then obtain the image-level signatures by spatial concatenation of the local codes, and the powerful SVM are utilized to perform the classification task at last. However, three major problems hinder the performance of such a pipeline, i.e., the limitation of hand-designed descriptors, the information loss brought by feature coding and the lack of spatial information. How to alleviate the above problems in the BoF-based framework to enhance the representative and discriminative abilities of image features is a challenging but vital task, and also becomes our focus in this paper.There are several improvements proposed to address the above problems. Yang et al. [53] and Wang et al. [51] reduce the information loss by minimizing the reconstruction error along with effective priors such as sparse regularizer or locally-constrained linearity constraints. However, these methods are performed in a purely unsupervised way without any high-level guidance. Another inherent drawback is the lack of spatial information as the BoF-based representation describes an image as an orderless collection of local features. To incorporate the spatial information, one popular extension, i.e. Spatial Pyramid Matching (SPM) [29], is effective. It requires to partition each image into a fixed sequence of increasingly finer uniform grids (1×1,2×2,4×4) and then concatenates the BoF features in each grids forming an image representation. Obviously, this simple partition and concatenation scheme can not reflect various spatial distributions in different categories of images. It is demonstrated recently that deep feature learning models, inspired by the hierarchical nature of human vision cortex, are effective to learn high-level image features [20]. The deep architectures are also effective to reduce the information loss by integrating unsupervised pre-training and supervised fine-tuning [17], and may generalize to different situations.Motivated by the traditional image prior knowledge and recently developed deep feature learning, this paper proposes a novel deep appearance and spatial coding architecture. The whole network is built based on Restricted Boltzmann Machines (RBM) and Auto-encoder (AE), which take advantage of unsupervised learning and supervised learning to explore the latent generative and discriminative properties. As shown in Fig. 1, it is a hierarchical architecture consisting of three modules: appearance coding, over-complete spatial max-pooling and spatial coding. With an image as input, our model first extracts dense local patches to learn local features by the stacked Independent Subspace Analysis (SISA) network, which is demonstrated effective to learn robust features [30]. Then the learned features are encoded into high-dimensional appearance codes by a sparse RBM (SRBM) layer. To incorporate more flexible spatial layout information, we adopt the ideas of over-completeness and structured sparsity. A over-complete spatial partition set including various spatial distributions is created in a flexible scheme and then max-pooling is carried out within each region. The resulting region features are concatenated as input to the next spatial coding module. In the spatial coding, we hypothesize that only a few dimensions of the mid-level region representations are effective. That is, partial spatial partitions are suitable to describe images. A structured sparse Auto-encoder (SSAE) approach is adopted to sparsely select the useful dimensions of the concatenated features as the image-level signature. An additional AE layer is further added to improve the performance. To learn the proposed deep model, we apply layer-by-layer unsupervised training and then fine-tune the parameters with image labels to enhance the discrimination. Finally, the output image representations are employed to train a one-versus-others SVM classifier to perform classification. We evaluate our model on widely used image benchmarks (i.e. UIUC-sports, Caltech-101, Caltech-256, Scene-15 and MIT Indoor-67). The extensive experiments demonstrate the effectiveness of our method in comparison with baselines and related work.The rest of this paper is organized as follows. Section 2 reviews the related work of traditional image representation models and feature learning In Section 3, we elaborate our proposed model by introducing the three modules in details. The experimental evaluations and conclusions are given in Section 4 and Section 5 respectively.

@&#CONCLUSIONS@&#
