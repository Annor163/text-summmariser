@&#MAIN-TITLE@&#
Speech enhancement based on wavelet packet of an improved principal component analysis

@&#HIGHLIGHTS@&#
Integrating the principal component analysis in wavelet packet decomposition.Extended PCA technique for speech enhancement is considered.To obtain a sparse matrix to contain the enhanced speech.Experiments on NOIZEUS data corrupted by Gaussian and four non-stationary noises.Our approach shows superior outcomes in BSS EVAL toolbox, SegSNR, PESQ, and Cov.

@&#KEYPHRASES@&#
Speech enhancement,Wavelet packet analysis,Principal components analysis,Sparse matrix,

@&#ABSTRACT@&#
In this paper, we propose a single-channel speech enhancement method, based on the combination of the wavelet packet transform and an improved version of the principal component analysis (PCA). Our method integrates ability of PCA to de-correlate the coefficients by extracting a linear relationship with what of wavelet packet analysis to derive feature vectors used for speech enhancement. This allows us to operate with a convenient shrinkage function on these new coefficients, removing the noise without degrading the speech. Then, the enhanced speech obtained by the inverse wavelet packet transform is decomposed into three subspaces: low rank, sparse, and the remainder noise components. Finally, we calculate the components as a segregation problem. The performance evaluation shows that our method provides a higher noise reduction and a lower signal distortion even in highly noisy conditions without introducing artifacts.

@&#INTRODUCTION@&#
The goal of speech enhancement in a single-channel recording varies according to specific applications, such as to reduce listener fatigue, to improve the overall speech signal quality, to enhance intelligibility, and to increase the efficiency of the voice communication device (Loizou, 2007).In general, speech denoising algorithms can be categorized into four broad classes: spectral subtractive algorithms, statistical-model-based algorithms, wavelet transform, and subspace algorithms.Spectral subtraction (SS) (Boll, 1979) is one of the first algorithms applied to the problem of speech enhancement. It is simple to implement but it distorts the speech signal and introduces additional annoying noise known as “musical noise”. Many algorithms have been proposed to remove this phenomenon including perceptually motivated techniques by Petrovsky et al. (2004) and the aspects of the human auditory system (Lu and Loizou, 2008), but their optimality in a sense of linear estimation is not clear.Statistical model-based algorithms are one of the most commonly used classes of speech denoising methods. Recovery of the clean speech transform coefficients, or their magnitudes, is treated as a Bayesian estimation problem with known speech and noise statistics. Many estimators have been derived under different assumptions for the noise and speech distributions. The Wiener filter algorithms consist in estimating an optimal filter from the noisy speech spectrum by minimizing the Mean Square Error (MMSE) (Gui and Kwan, 2005). The MMSE estimator is used to evaluate the short-time spectral amplitude (STSA) based on a priori signal-to-noise ratio (SNR) estimation and Gaussian statistics. The prior SNR estimation was performed using “decision estimator” proposed by Ephraim and Malah (1984).Wavelet transforms (WT) have been applied to various speech applications. The basic principle of speech enhancement in wavelets analysis is based on the thresholding of the discrete wavelet coefficients (DWC) to segregate the components corresponding to the target speech from those of the noise. However, when we apply a fixed threshold for the DWC of speech, some unvoiced speech frames can be eliminated with the additional ranges noise thus degrading the intelligibility of the enhanced speech. To solve this problem, the thresholding must be modified over time. Therefore, diverse adaptive wavelet thresholding procedures are proposed as the universal threshold proposed by Donoho and Johnstone (1995), Stein's Unbiased Risk Estimate (SURE) strategy described in Hu and Loizou (2004), Bayes Shrink exploiting a Bayesian estimate is described in Leporini and Pesquet (2001). The main drawback of the WT is the restricted number of frequency bands. Also, the unvoiced frames of noisy speech have proven to be problematic in terms of the wavelet shrinking. Since the unvoiced parts of speech include many noise-like high frequency components, removing them in the wavelet domain can degrade the quality and intelligibility of the enhanced speech.The speech subspace algorithms consist in projecting the noisy speech segments onto orthogonal subspaces. The speech subspace is composed of high-energy vectors in the segment's principal component (PC) basis. The first algorithm was introduced by Dendrinos et al. (1991) who proposed to use the Singular Value Decomposition (SVD) technique to eliminate the noise subspace for speech denoising. Therefore, Ephraim et al. (1996) have used the fast Fourier transform (FFT) to approximate PC basis. These methods have removed the “musical noise” artifacts but the subspace approach improves perceived speech quality without increasing speech intelligibility. A well-known method proposed by Hu and Loizou (2003) is based on a joint digitalization of the noise and clean speech covariance matrices leading to the optimal estimators. Unfortunately, an efficient implementation of the subspace based approaches with an optimal choice of parameters is a challenging task and mainly in the case of colored and babble noise. To overcome the limitation, many approaches based on the speech segregation for enhancing the perceptual intelligibility of the speech degraded by additive background noise have been presented such as K-SVD by Sigg et al. (2010) and non-negative matrix factorization (NMF) by Mohammadiha et al. (2011), and Mysore and Smaragdis (2011). However, these methods always demand prior training for supervised segregation, empirical parameters, or particular features.So, a number of studies using principal component analysis (PCA) are proposed. The essential object is to obtain a set of orthogonal factors that describe the variance of the observations and track the new factors considered to determine the necessary features without prior training. Speech processing by PCA (Joliffe, 2002) is extensively applied as a classical multivariate speech processing tool. For speech segregation, a robust extension of classical PCA by generalizing an eigenvalue decomposition of a pair of covariance matrices is proposed by Benabderrahmane et al. (2010). It may be used in speech denoising by Shinde et al. (2012), speech identification by Abolhassani et al. (2007), and speech recognition by Takiguchi and Ariki (2007).In this paper, we propose a speech enhancement method based on the combination of the wavelet packet transform (WPT) and an improved version of the principal component analysis (IPCA). In fact, the orthogonal basis functions produced by the WPT, provide satisfactory results at low and high frequencies (Donoho et al., 1995; Ghanbari and Karami, 2006). Projection of a noisy speech onto these basis functions may be realized efficiently by passing the noisy speech through a tree-structured conjugate quadrature filter bank. In the proposed method, we apply the WPT, which allows to obtain appropriate time-frequency resolution, and to adaptively select relative frequency band based on the type of the speech to be estimated. To further improve denoising character of WPT, the paper describes a method, which combines the ability of the PCA tool to decorrelate the variables by extracting a linear relationship with that of wavelet packet analysis to enhance the speech signal. Our basic idea is to construct powerful filters by applying the PCA in the wavelet packet domain, thus getting a compaction of the speech energy into a few principal components (PC's), while the noise is spread over all the transformed coefficients. This allows us to operate with a convenient shrinkage function on these new coefficients, removing the noise without degrading the speech.Then, we apply our improved version of the PCA at the enhanced speech obtained by the inverse wavelet packet transform. Our extension of PCA technique exploits the benefit of sparse PCA in the context of classification. Based on the fact that the sparse PCA by Zou et al. (2006) is a regression type optimization to PCA with a quadratic penalty, our technique segregates the noisy speech using the sparse matrix, the remainder noise component, and low-rank decomposition technique. In this paper, we propose to optimize a sparse PCA which decomposes the noisy speech into three subspaces corresponding to the speech structure subspace, noise structure subspace, and the remainder noise subspace.The proposed method is tested on noisy speech under various types of noise conditions including white, babble, factory, car, and street noises. Objective and subjective results show that the system based on this approach has significant improvement over three recent methods.The rest of the paper is organized as follows. In Section 2, we give a brief description of the PCA technique and its application for speech enhancement. Next, in Section 3, we detail our approach. The experimental results of our method under a variety of real noisy environments are given in Section 4. Finally, we draw conclusions in Section 5.In this section, we first present fundamental relations and properties of PCA and then review PCA based speech enhancement.Suppose that the single-channel noisy speech signal observation vectorx(t)∈ℝLcan be constructed by the sum of the clean speech vector s(t) and the noise vector n(t):(1)x(t)=s(t)+n(t)We consider a set of L centered observations x(t)=[x1, x2, …, xL]T, and∑k=1Lxk=0.Then, we arrange the L-dimensional observation vector in a I×J normalized matrix of the observation XI×J(t), with L=I+J−1.The time-variable notation is considered implicit. In the remainder of the section, this notation will be left out.From the vector x, we compute the covariance matrix C. We use the PCA tool to diagonalize the matrix.(2)C=1L∑k=1LxkxkTThe covariance matrix C can be estimated as:(3)C=1I−1XXT∈ℝJ×JIt is about the best covariance matrix estimation having the lowest dimension.Letv1,v2,…,vIbe the eigenvectors corresponding to the eigenvalues α1, α2, …, αIof the matrix C.The matrix V is defined as:(4)V=[v1,v2,…,vI]∈ℝI×ITo compute the PCA, we must evaluate the magnitude of the eigenvalue problem(5)αV=CVThen, we can decompose the covariance matrix C into its eigenvalue decomposition (EVD) by Karhunen–Loève transform (KLT) as follows:(6)C=VχVTwhere χ is a diagonal matrix corresponding to the eigenvalues in a decreasing order represented as follows:(7)χ=diagα1,α2,…,αIWithα1≥α2≥⋯≥0The aim is to find some orthonormal matrix V in order to extract the feature of the clean speech only. The column of V is the PC's of X.According to Eqs. (3) and (6), we have:(8)VTχV=1I−1XXTFrom Eq. (8), we can observe thatχ=1I−1XVXVTis the diagonal covariance matrix.We can conclude that columns of V are the PCs of X and the eigenvectors of XXT.The goal of PCA technique is to determine the most significant basis to re-express a noisy speech set. This new basis will filter out the noise and reduce a multidimensional speech to lower dimensions by avoiding redundant data.Different approaches had been applied to choose the optimal number of PCs like imbedded error function (IEF) (Kaiser, 1960), minimum description length (MDL) (Rissanen, 1978), cumulative percent variance (CPV), average eigenvalue (AE), auto-correlation (AC) (Shrager and Hendler, 1982), parallel analysis (PA) (Zwick and Velicer, 1986), variance of the reconstruction error (VRE) (Qin and Dunia, 1998). The MDL criterion is based on the covariance matrix with solid statistical basis. While, the methods based on the correlation matrix consist in weighting all variables by a variance scaling.As the distribution of the noisy speech is highly non-Gaussian, Lev-Ari and Ephraim (2003), Wei and Hu (2003) and Li and Lei (2007) propose the use of the Kernel PCA (KPCA) to eliminate the non-stationary and colored noise. In KPCA, the nonlinear structure of the noisy speech is modified into a higher-dimensional space with LPCA by Schölkopf et al. (1998). Besides, we must select the adequate number of PCs to describe the model in an optimal manner.In order to improve the performance of the speech enhancement methods, the PCA has been incorporated with the human hearing properties (Jabloun and Champagne, 2003), the Hilbert–Huang transform (Khademul and Hirose, 2007), and also the transition from the classical PCA to self-adapting PCA/KLT technique (Rezayee and Gazor, 2001).Vetter et al. (1999) propose a subspace approach based on the KLT/PCA to give an optimum compression of information. The optimal subspace selection is provided by a MDL criterion. The idea is based on the fact that the covariance matrix of a noisy speech can be decomposed into two mutually orthogonal vector spaces: a noise subspace and a signal (+noise) subspace. Noise reduction is achieved by discarding the noise subspace completely, while modifying the noisy speech components in the signal (+noise) subspace.Lee et al. (2001) have applied the PCA in the spectrum domain to estimate the filter-bank coefficients for speech enhancement.Lima et al. (2004, 2005), have applied the KPCA only to the low-order MFCCs for speech enhancement and speech recognition.Takiguchi and Ariki (2007) have proposed to apply the KPCA to the mel-scale filter bank output because the KPCA will project the main speech element onto low-order features, while noise elements will be projected onto high-order ones.Haji-Abolhassani (2007) introduced an optimal subspace partitioning using the variance of the reconstruction error (VRE) criterion.Leitner et al. (2011) used an approach based on the complex coefficients of the FFT using KPCA.A recent study explores the sparse and the low-rank structures by Candès et al. (2011) to enhance the noisy speech. Candès et al. (2011) have developed meaningful decompositions named “Robust Principal Component Analysis” (Robust-PCA). The authors prove that the sparse and the low-rank components of a matrix can be exactly recovered, if it has a unique and precise decomposition. This unsupervised method gives a blind separation of the sparse speech and the low-rank noise.In this section, we show how the wavelet-packet transform (WPT) and an improved version of the principal component analysis (PCA) can be suitably combined to simultaneously minimize the speech distortion and maximize the noise reduction.The principal steps of our method called WP-IPCA (wavelet packet and improved version of the principal component analysis) are shown in Fig. 1.Wavelet transforms allow the decomposition of the signal into detail and approximation. The approximation is then decomposed into a second level of approximation and details and so on by a quadrature mirror filter (Donoho, 1995). Wavelet packet decomposition (WPD) is a further generalization of the wavelet decomposition (WD). In the WPD, the filtering procedure is iterated on both the high and low frequency components.In Fig. 2, we show the decomposition tree of the WP.Each node is defined by (E,n), where E is the decomposition level and n corresponds to a sub-band node index. The root of the tree corresponding to (E,n)=(0,0), makes the reference to the entire signal space. The right and left branches indicate high-pass and low-pass filtering followed by 2:1 down-sampling, respectively.The application of the WP for speech enhancement is a three step algorithm, applying wavelet decomposition, wavelet coefficient thresholding, and wavelet rebuild.The different steps of our method are described as follows:Step 1:Divide the noisy speech into F frames of N=512 samples with half-length overlap. We obtain a matrixX=x1,x2,…,xFwith dimension F×N. It is the results of the speech framing whose columns host the partially overlapping noisy speech segments.For each column in the noisy speech data matrix X, we select the wavelet packet (WP) function Ψi,j(t) and calculate the wavelet packet decomposition (WPD) coefficients matrixes{WE,0,WE,1,…,WE,2E−1}using Daubechies wavelet with level E.Apply the best WP basis coefficients to operate the WPD tree.Choice the coefficients as a column vector to get WPD coefficients matrixes with various tree nodes{YE,0,YE,1,…,YE,2E−1}, the column number is F and the row number of these matrix is N/2E.Apply the conventional PCA on the obtained coefficients matrixes to calculate PC's score matrixes{OE,0,OE,1,…,OE,2E−1}, load matrixes{LOE,0,LOE,1,…,LOE,2E−1}in order to reconstruct WP coefficients matrixes{Y′E,0,Y′E,1,…,Y′E,2E−1}, and combine the corresponding column vectors to obtain{W′E,0,W′E,1,…,W′E,2E−1}. To get the PC's, first, we compute the Eigen-decomposition of covariance matrices to find out the eigenvector and eigenvalues. Second, we arrange them in a decreasing order. Finally, we select the eigenvalues to determine the number of retained PC's using Kaiser's rule.As (Rissanen, 2000) showed that the thresholding technique proposed by Donoho and Johnstone (1995) leads to eliminate too many coefficients, we apply the MDL model selection criterion to choose the correct threshold values for denoising. For more detailed information of the MDL model, you can refer to Whitmal et al. (1996).Reconstruct by an overlap-adding the enhanced speech frames signal of the matrixB=x′1,x′2,…,x′Fusing WP rebuild (WPR) method.Use the obtained matrix B to reconstruct our final enhanced speech signalXe=xe′1,xe′2,…,xe′Fby our improved PCA (IPCA). This step will be detailed in the following sub-section.Our contribution consists essentially in the partition of the eigenspace of the obtained signal into 3 subspaces to guarantee the maximization of noise reduction and the minimization of the signal distortion.First, we calculate the FFT of the noisy speech signal and compute the spectrogram to obtain the matrix X′.The FFT of the result signal x′(t) is given by:(9)X′(i,n)=∑k=−∞+∞x′kwi−ke−j2πkn/Lfwhere i refers to the index of the time-frame, n is the index of the discrete frequency, w(i) is an analysis window function, and Lf is the length of the frequency analysis. In the spectral domain, we smooth the speech spectrum magnitudeX′(i,n)at each frame, and accumulate all frames of theX′(i,n)as column vectors to obtain the matrix representation X′.Second, we apply our improved principal component analysis (IPCA) technique to obtain three matrices S, Re and Lo from the matrix X′. Our partition to the sparse, remainder noise, and the low structure subspaces is based on the hypothesis that the noise spectrum always presents an iterative pattern with limited variation whereas the speech signal has more alteration and is relatively sparse within the noise.The new formulation of IPCA is described in the frequency domain by the following equation:(10)X′=S+Re+Lowhere X′ is the input coefficients matrix, S refers to sparse matrix, Re refers to the remainder matrix and Lo refers to the low-rank matrix.In this sub-section, we aim to recover the sparse matrix S, which represents the speech structure matrix, the low-rank matrix Lo, which represents the noise structure matrix, from the input matrix under the perturbation of the remainder matrix Re whose inputs have zero-mean Gaussian distributions. Then, the background noise is identified as the sum of the remainder and the low-rank components. Our method applies the remainder noise matrix to model the alteration of noise while the stable statistics of noise are described in the low-rank matrix. This new assumption should allow us to improve our method.Now, we try to solve the following well-behaved convex optimization problem using the algorithm proposed by (Zhou and Tao, 2011):(11)minX′−S−Lo*+αS1||||* makes reference to the nuclear norm of Lo, where ||Lo||* is determined as the sum of the singular values of Lo, which is representative for minimizing the rank of Lo.The sparsity of S is measured by the L1-norm ||||1, meaning the summation of absolute value of the matrix's elements.α=1/max(m1,m2)is a trade-off parameter between the sparsity of S, and the rank of Lo.Finally, we use a convex relaxation technique by applying the inexact Augmented Lagrange Multiplier (IALM) by Lin et al. (2009), to obtain the enhanced matrix:(12)X′=S+Re+LogS,Lo=Re=X′−S−LoThe function g describes the remainder matrix Re in terms of the sparse and low components.As a result, the IALM function is given by the following equation:(13)I(S,Lo,Re,β)=Lo*+αS1+〈X′,Re〉+β2X′−S−LoF2where I() is the IALM function, and β is a positive scalar.Then,S*,Lo*,Re*ofSi*,Loi*,Rei*is the best solution of our improved PCA and the convergence rate is at leastOβi−1. It is clear that the choice of βiis essential to obtain a minimum number of SVD. So, we solve the sub-problemSi+1*,Loi+1*,Rei+1*=argminLo,S,ReI(S,Lo,Re*,βi)inexactly by the IALM technique.The detailed procedure is presented in the algorithm below:Algorithm of the IALM model.Input: data matrix X′, and the parameter α.Initialization:Lo=0; S=0; Re=random; β>0; ω>1; i=0;while not converged doUpdate S:Si+1=argminS,ReI(S,Lo,Re*,βi)Update Lo:Loi+1=argminLo,ReI(Si,Lo,Rei,βi)Update Re:Rei+1=Rei+βiX′−Si+1−Loi+1βi+1=ωβii+1end whileOutput:Si;Loi;ReiWe introduce the remainder matrix in the subspaces to avoid fitting the background noise with simultaneous speech. Also, we would like to cover a wider range of variation as efficiently as possible. Finally, our method is extendable to a more complex model.The Fig. 3shows respectively the spectrograms of the original speech, the noisy speech, the enhanced speech signal using the wavelet packet and an improved version of the principal component analysis.In Fig. 3(c), we can observe that the sparse component accords with sparsity of the speech energy in the frequency domain, and the low-rank component is spanned by a few frequency basis segments.

@&#CONCLUSIONS@&#
