@&#MAIN-TITLE@&#
Background modeling using Object-based Selective Updating and Correntropy adaptation

@&#HIGHLIGHTS@&#
We propose a background modeling method to deal with non-stationary conditions.The object-based updating strategy allows to work with SFO and RFO.Non-Gaussian pixel dynamics are modeled using a Correntropy cost function.Analyzing the regions movement direction avoids tracking background objects.Object-based updating strategies improve the performance for indoor scenarios.

@&#KEYPHRASES@&#
Background modeling,Learning rate,Correntropy-based adaptation,Moving object detection,

@&#ABSTRACT@&#
Graphical abstract

@&#INTRODUCTION@&#
Development of computer vision techniques to support visual surveillance aims to facilitate analysis of video records, which due to their length are not suitable to be monitored by visual inspection. Particularly, some typical video-based surveillance applications include pedestrian and car traffic monitoring [1], unusual human activity detection [2], target counting [3], detection of abandoned objects [4], among others. Many applications are devoted to detect moving objects in the scene to support high-level stages in visual surveillance systems (object recognition and tracking). In practice, to efficiently detect moving objects (foreground) of video streams, background modeling is widely used, which contrasts every new input frame to identify as foreground those regions diverging the most from the static elements (background). Commonly, pixels related to foreground objects are assumed as having stochastic behaviors while the ones related to the background are expected as static [5]. Nonetheless, real-world scenarios tend to have time and spatial non-stationary fluctuations, where not all changing pixels must be associated with foreground entities nor static pixels must be associated with the background [6]. Therefore, the goal is to properly adapt the background model to video perturbations that may include pixel noise and illumination variations (local or global), visual artifacts having similar appearances with surrounding backgrounds (shadows, camouflage, bootstrapping, reflections), dynamic background scenarios, static foreground objects, removed foreground objects, among others [7].

@&#CONCLUSIONS@&#
A methodology for background and foreground discrimination in video surveillance scenarios is proposed. Our approach, called OSUC analyzes pixel spatio-temporal relations as an adaptive learning algorithm. OSUC infers the temporal statistical distribution of each pixel by using a Correntropy-based cost function, which is able to weight the relevance of each new input pixel to build a background model. Moreover, an automatic tuning algorithm is proposed in order to suitably set the Correntropy kernel bandwidth by evaluating the error distribution shape, achieving good performance under both Gaussian and non-Gaussian pixel distribution conditions. By including an object motion analysis stage, proposed OSUC is able to properly detect, model, and track foreground objects. Such information is weighted afterwards into the background model, avoiding false segmentations when working with the presence of moving and static foreground objects in the scene. Besides, OSUC object motion analysis stage is able to give extra information about the foreground object dynamics which could be further used to solve other video surveillance tasks.From the obtained results, we infer that proposed OSUC is able to handle well known issues from video surveillance systems. Furthermore, achieved performance is comparable with state of the art algorithms, obtaining even better results when the challenge of the segmentation relies on the complexity of the relations between foreground and background dynamics. Furthermore, it was shown with the experiments performed by OSUC-2 that even using a single Gaussian model, the Correntropy cost function is able to support the background modeling process just as good as the Z-GMM. The main OSUC free parameters are experimentally studied, to validate algorithm's performance and stability under different video conditions. Proposed approach, is a suitable alternative to support video surveillance tasks achieving good segmentation results, while having an affordable computational burden.As future work, it would be interesting to consider more robust approaches to model and track the detected foreground objects. In addition to F-measure in the experimental validation, the authors plan to employ more elaborate metrics (like D-Score or Structural Similarity [5]) that take into account more information about the segmented image structure. Finally, an OSUC extension should be developed to deal with moving cameras, and optimized implementation will be carried out in order to improve the OSUC scalability.