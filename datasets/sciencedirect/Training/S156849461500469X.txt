@&#MAIN-TITLE@&#
An uncertainty-managing batch relevance-based approach to network anomaly detection

@&#HIGHLIGHTS@&#
Adaptive, network anomaly detection strategy based on a batch relevance-based fuzzified learning algorithm.Couples the capability of inferring decisional structures from incomplete observations, with the flexibility of a fuzzy-based uncertainty management strategy.Infers the laws and rules governing normal or abnormal network traffic, in order to model its operating dynamics.Based on a rule-based detection strategy, is more effective against previously unknown phenomena and robust against obfuscation mechanisms.

@&#KEYPHRASES@&#
Network anomaly detection,Machine learning,Supervised classification,Fuzzy-based techniques,Inductive inference,

@&#ABSTRACT@&#
The main aim in network anomaly detection is effectively spotting hostile events within the traffic pattern associated to network operations, by distinguishing them from normal activities. This can be only accomplished by acquiring the a-priori knowledge about any kind of hostile behavior that can potentially affect the network (that is quite impossible for practical reasons) or, more easily, by building a model that is general enough to describe the normal network behavior and detect the violations from it. Earlier detection frameworks were only able to distinguish already known phenomena within traffic data by using pre-trained models based on matching specific events on pre-classified chains of traffic patterns. Alternatively, more recent statistics-based approaches were able to detect outliers respect to a statistic idealization of normal network behavior. Clearly, while the former approach is not able to detect previously unknown phenomena (zero-day attacks) the latter one has limited effectiveness since it cannot be aware of anomalous behaviors that do not generate significant changes in traffic volumes. Machine learning allows the development of adaptive, non-parametric detection strategies that are based on “understanding” the network dynamics by acquiring through a proper training phase a more precise knowledge about normal or anomalous phenomena in order to classify and handle in a more effective way any kind of behavior that can be observed on the network. Accordingly, we present a new anomaly detection strategy based on supervised machine learning, and more precisely on a batch relevance-based fuzzyfied learning algorithm, known as U-BRAIN, aiming at understanding through inductive inference the specific laws and rules governing normal or abnormal network traffic, in order to reliably model its operating dynamics. The inferred rules can be applied in real time on online network traffic. This proposal appears to be promising both in terms of identification accuracy and robustness/flexibility when coping with uncertainty in the detection/classification process, as verified through extensive evaluation experiments.

@&#INTRODUCTION@&#
Together with the astonishing deployment of network technologies and the consequent increment in traffic volumes, the importance of network misuse detection and prevention frameworks is proportionally growing in almost all the modern organizations, in order to protect the most strategic resources from both external and internal threats. In this scenario, the task of identifying and categorizing network anomalies essentially consists in determining all the circumstances in which the network traffic pattern deviates from its normal behavior, that in turn depends on multiple elements and considerations associated to the activities taking place every day on the network.However, the main difficulty related to a really effective detection is associated to the continuous evolution of anomalous phenomena, due to the emergence of new previously unknown attacks, so that achieving a precise, stable and exhaustive definition of anomalous behavior, encompassing all the possible hostile events that can occur on a real network, is practically impossible. Nevertheless, detection systems must not be limited by the a priori knowledge of a specific set of anomalous traffic templates or be conditioned by a large number of complex operating parameters (e.g., traffic statistic distributions and alarm thresholds), and hence have to be able to recognize and directly classify any previously unknown phenomenon that can be experienced on the network. As a consequence, the ultimate goal of modern anomaly detection systems is behaving in a adaptive way in order to flag in “real-time”, all the deviations from a model that is built dynamically and in an incremental way by capturing the concept of normality in network operations according to a learning-by-example strategy. These new systems, overcoming the known limitations of the more traditional ones based on pattern detection and statistical analysis, are empowered by flexible machine learning techniques.Accordingly, we propose a novel anomaly detection strategy, particularly suitable for IP networks, based on supervised machine learning, and more specifically on a batch relevance-based fuzzyfied learning algorithm known as U-BRAIN.This strategy aims at understanding the processes that originate the traffic data, by deriving the specific laws and rules governing it, in order to reliably model its underlying dynamics. This is accomplished by performing inductive inference (or better, generalization) on traffic observations, based on some empirical pre-classified “experiential” (training) data, representing incomplete information about the occurrence of specific phenomena that describe normal or anomalous network activities. In addition, the adopted learning scheme allows a certain degree of uncertainty in the whole detection process making the resulting framework more solid and flexible in managing the large variety and complexity of real traffic phenomena. Then the inferred rules can be applied in real time on online network traffic.We evaluated the effectiveness of the presented detection framework within a widely known test case scenario, in order to make the achieved results comparable with those of other proposal available in literature. These results demonstrated a quite satisfactory identification accuracy by placing our strategy among the most promising state-of-the-art proposals.Network anomaly detection has gained a great attention in security research with about 40 years of experiences available in literature. The first approach to automatic detection has been proposed in [1], followed by a large number of contributions exploring many other solutions and proposals [2–4].The earliest and more traditional detection approaches, mainly aiming at spotting intrusion activities, work by matching specific traffic patterns, gathered from the packets under observation, against a list of predefined signatures, each associated to a known attack or hostile/anomalous behavior. Some well-known examples are SNORT [5] and BRO [6]. While ensuring very good response times and a quite satisfactory degree of effectiveness in case of previously known menaces, these approaches are almost totally clueless in presence of new (zero-day) attacks, or when, due to minor modifications in its behavior, an already known attack does not closely match the associated signatures. In both the cases new up-to-date signatures must be generated and added to the list as soon as more detailed information about the hostile behavior become available. Unfortunately, this implies human intervention, and hence too much time to ensure real-time response.Other very common detection systems are based on a statistical idealization of the network behavior and process the traffic observations through statistical-analysis techniques by flagging the outliers as anomalous events. The most significant examples are NIDES (Next-Generation Intrusion Detection Expert System) [7], an hybrid system providing a statistical analysis engine, and SPADE (Statistical Packet Anomaly Detection Engine) [8] a statistical detection system based on determining anomaly scores, available as a plug-in for SNORT. However, while straightforward and robust in their formulation (they do not require prior knowledge of the security menaces nor need packet inspection), statistic detection approaches may result too simplistic in their basic assumptions and hence scarcely reliable in their results. In fact, being based only on the statistical properties of the involved traffic flows, these approaches are too sensitive to the normality assumption, and really effective only against specific phenomena that imply significant variations in the statistical properties of the network traffic (Volume-based Attacks). More precisely, such detection techniques have to be based on extremely accurate statistical distributions that describe the traffic under observation. Unfortunately, modeling real network traffic, typically characterized by an inhomogeneous usage pattern, by using only pure statistical methods, may result in a poor choice in terms of real effectiveness. Furthermore, these solutions cannot be aware of hostile activities that only affect the packet contents (such as stack smashing or other kind of malicious code exploiting system/services vulnerabilities) or explicitly conceived to be undistinguishable from regular user activities (e.g., low-rate DoS attacks).As an alternative that may reveal extremely effective in coping with the above challenges, machine learning provides fully automated detection capabilities, by allowing a system to learn by example what are the anomalous events occurring in the observed traffic. It also allows improving the detection performance over time with experience, as more and more examples (or training data), describing normal or anomalous behaviors, are provided in its knowledge base. In this way, the detection function, that is essentially a binary classifier working on the normal and anomalous traffic classes, is inferred from the aforementioned training data. Such data consist of a set of pre-classified traffic samples. In supervised learning, each sample is a pair consisting of an input object (typically a vector of traffic features) and a desired output value (the class value) also called the supervisory signal. The inferred classifier should assign the right output class value to any valid input sample. This implies that the learning paradigm should be reasonably capable to perform generalization from the knowledge contained in the training data to previously unseen situations.The use of machine learning in anomaly detection, with the development of generalization capabilities from past experiences for classifying future data as normal or anomalous has been exploited in many proposals [9], based on neural networks [10,11], SVMs [12] and data mining techniques [13,14]. These approaches can be further subdivided into generative or discriminative. A typical generative approach (e.g., [15]) constructs a model by starting only from normal training examples, and then evaluate several test instances in order to appreciate how well they fit such model. As an example, the ideas presented in [16] explore different machine learning techniques to construct detection models from past behavior. On the other hand, discriminative techniques (e.g., [12]), attempt to understand the difference between the normal and anomalous instance classes. A learning approach for reproducing packet level alerts for anomaly detection at the flow level has been presented in [17]. Several approaches rely on clustering techniques, such as ADWICE [18], performing unsupervised detection based on a fast incremental clustering technique. K-Means+ID3 [19], instead, is a supervised learning approach combining k-Means clustering and the ID3 decision trees in order to classify anomalous and normal network activities. Regarding the use of tree-based structures, the DGSOT+SVM [20] scheme is an iterative approach leveraging the dynamic generation of self-organizing hierarchical trees together with SVMs to be trained on the tree nodes, where support vectors are used as the basic knowledge to control the tree growth. Also non-linear analysis, combined with recurrence quantification techniques [21] has been used to construct a flexible detection approach based on understanding the most hidden traffic dynamics by simultaneously observing the traffic behavior on multiple time scales.Other approaches introduced the concept of uncertainty within the learning strategy. Notably, a detection solution based on weighted fuzzy matching over frequent episode rules is presented in [22]. In addition, the approach presented in [23] applied fuzzy logic-based rules to audit data in order to classify it as normal or anomalous.Starting from the above experience, our machine-learning based detection solution combines the strength of rule-based systems and the flexibility of fuzzy logic to reliably understand the fundamental properties of the network traffic in order to rapidly flag the occurrence of abnormal events.The basic idea is building a formal model that expresses the relations between all the fundamental variables involved in the traffic dynamics, and hence “understands” the notions of normal and anomalous behavior from the available experience by learning the characteristics of the corresponding traffic classes and expressing them into laws and rules that are general enough to determine if any unseen instance belongs to the one or the other class. Obviously, the overall detection quality strongly depends on the accuracy and generality of the above model and hence on the completeness of the training data on which its “knowledge” about normal and anomalous phenomena is built.Starting from the previous considerations, we modeled our anomaly detection strategy according to a supervised machine learning scheme, specifically conceived for learning disjunctive normal form (DNF) [24] Boolean formulas from partial truth tables, possibly with uncertain values or missing information bits. Such formulas, determined by using the U-BRAIN (Uncertainty-managing Batch Relevance-based Artificial Intelligence) algorithm [25], describe the correlation rules between attribute conditions and class labels, modeling the normal and anomalous traffic profiles through Boolean predicates on the observation attributes. Since the U-BRAIN algorithm works on Boolean data, the above attribute values have to be quantized, in order to represent them in rules by using binary strings.The aggregation of all the determined correlation rules defines the behavior of an inductively learned classifier that is able to analyze the deviation from normal traffic profiles and the proximity to the known anomalous ones, as determined from the historical observations available in the training set. Clearly, by relying on a supervised approach where both the phenomena of interest are known in the training set, such a classifier should be potentially able to achieve better detection performance respect to semi-supervised and unsupervised solutions, since more information is available in its training knowledge base. However, the unbalancing in the amount of training data representing the two classes, together with the presence of some uncertainty and noise in pre-classified samples, can significantly affect the final accuracy of the detection results. U-BRAIN faces uncertainty problems by improving the flexibility of rules through the introduction of fuzzy logic. This characteristic, allowing a certain degree of uncertainty at the binary classifier level, makes the resulting detection strategy significantly stronger both in terms of flexibility and ability to cope with the variety and complexity of network traffic phenomena. In this way the detection approach considers a wider range of implications when making its decisions, resulting in a more effective and powerful approach in presence of incomplete training data.A fundamental preliminary task in a supervised network anomaly detection system is the initial “knowledge construction” where the most significant network utilization patterns, describing the fundamental traffic dynamics, should be described in terms of specific features gathered from traffic observations. This is a very slow and complex activity that implies collecting and pre-classifying network traffic observations over a sufficiently long period of time, in order to build a quite complete training set, reliably describing the historical knowledge of the network behavior, or “baseline”. The training data will thus consist in a parametric network traffic model that can be viewed as an approximation of reality, where a limited set of parameters is available in form of the most discriminant traffic features that are able to describe the traffic behavior. Such traffic model can be realized by looking at different observation dimensions, such as inter-arrival times of packet transmission and reception events, together with information about packet sizes, flags, source and destination addresses, ports/services involved, by also attempting to use the memory of recent past to identify persistent events like end-to-end connections (traffic flows). These observations are represented as a time series, that is, a sequence of scalar samples measured at uniformly spaced time intervals. More formally, the training set T=(t1, t2, …tN) consists of N samples, each structured as an d-dimensional vector of traffic features si=(f1, f2, …fd). The training set is joined with a one-dimensional feature set C=(c1, c2, …cm) associated to the supervisory signal, where cirepresent the class (i.e., anomalous, not anomalous) to which each sample tibelongs. In this way, the knowledge base of the classifier is described by a set or rules that will be “inferred” from the aforementioned collection of pre-classified training samples, where p of them are associated to anomalous traffic observation and q to normal ones, with p≪q.U-BRAIN is a machine learning algorithm able to infer explicitly the laws that govern a process from examples. In its latest version, U-BRAIN can also act on incomplete data. Originally, the algorithm, named BRAIN [26], was conceived for recognizing the borders of coding regions in human DNA. The algorithm was based on the Michalski's STAR technique [27], on the candidate-elimination method introduced by Mitchell [28], and on the work of Haussler [29]. The BRAIN algorithm was later extended [25] to treat data with missing bits by using fuzzy sets. The resulting U-BRAIN algorithm keeps the computational complexity of the original one. The great versatility that characterizes it, makes U-BRAIN applicable in every industry and science field in which there are data to be analyzed, such as the financial world, the aviation industry as well as the biomedical scope. U-BRAIN models a process by a formula able to forecast the future process behavior. Specifically, the algorithm builds Boolean formulae F of n literals xi(i={1, …, n}) in DNF form, made up of disjunctions of conjunctive terms, starting from a set T of training data. The data (instances) in T are divided into two classes, named positive and negative, respectively modeled by the n-sized vectorsui→with i={1, …, p} andvj→with j={1, …, q}, representing the issues to be classified. Each element ui,korvj,kwith k={1, …, n} can assume values belonging to the set{0.1,12}respectively associated to positive, negative and uncertain values. The conjunctive terms of the formula are carried-out in an iterative way by two nested loops (see Algorithm 1 schema). The inner cycle refers to the selection of the literals of each formula term, while the outer one is devoted to the terms themselves. In order to build a formula consistent with the given data, U-BRAIN compares each given positive instance with each negative one and builds a family of fuzzy sets of conditions that must be satisfied by at least one of the positive instances and violated by all the negative ones formally defined as:(1)Si,j=xk|ui,k>vj,k∨ui,k=vj,k=12∪xk¯|ui,k<vj,k∨ui,k=vj,k=12In other words, the k-th literal belongs to the Si,jset if the elements in the position k, belonging to the i-th positive instance ui,kand to the j-th negative instancevj,k, are different or both equal to12.Starting from these sets Si,j, the algorithm determines for each literal xk, belonging to them, a set of coefficients Ri,j, Riand R, called relevances, forming a probability distribution:(2)Ri,j(xk)=μi,j(xk)#(Si,j)Ri(xk)=1q∑j=1qRi,j(xk)R(xk)=1p∑j=1oRi(xk)where μi,jis the membership function of the set Si,j(3)μi,j(xk)=1ifui,k=1andvj,k=012(p+q)ifui,k>vj,kandui,k=12orvj,k=1212(p+q+1)ifui,k=12andvj,k=120otherwiseμi,j(x¯k)=1ifui,k=0andvj,k=112(p+q)ifui,k<vj,kandui,k=12orvj,k=1212(p+q+1)ifui,k=12andvj,k=120otherwiseand where #(x) is the fuzzy cardinality of a subset s of a set S defined as #(x)=∑x∈Sμs(x). The membership function, defined in (3), is conceived in such a way that, in a comparison between two instances, the certain values have a much prominent role w.r.t. the missing ones while uncertain information may gain relevance only if the certain one is not sufficient (see [25]).This allows the selection of the literals based on a maximum probability greedy criterion (the literal having maximum relevance value is selected). The goal of such greedy selection is simultaneously covering the maximum number of positive instances with the minimum possible number of literals. Each time a literal is chosen, the condition sets Si,j, and the corresponding probability distribution, are updated by erasing the sets containing the literal itself. The inner cycle is then repeated and the term is completed when there are no more elements in the sets of conditions. Then the new term is added to the formula and, in the outer cycle, the positive instances satisfying the term are erased. Then, the inner cycle starts again on the remaining data. The algorithm ends when there are no more data to treat. The algorithm has two biases: the instance set must be self-consistent, that means that an instance cannot belong to both the classes, and no duplicated instances are allowed. In fact, it may happen that the initial set of training instances contains redundant information. This may be due to repeated instances present from the beginning of the process or resulting from a reduction step, whose task is limiting the presence of missing bits, by recovering them as possible. Such redundancy is automatically removed by keeping each instance just once and deleting all the repetitions, in order to avoid consistency violation that can halt the process.Algorithm 1The U-BRAIN schemaRequire:p>0.q>0.T={u1→,…,up→,v1→,…,vq→}1:F←∅   {Initialize F}2:while there are positive instancesui→∈Tdo3:Uncertainty Reduction4:Repetition Deletion5:m←∅   {Initialize term m}6:Build Si,jsets from T7:while there are elements in Si,jdo8:ComputeRi,jfor{xk,x¯k},k={1,…,n}9:ComputeRifor{xk,x¯k},k={1,…,n}10:ComputeRfor{xk,x¯k},k={1,…,n}11:Choose literal x withmaxrelevance R12:m←m∪{x}  {Update term m}13:Update Si,jsets14:end while15:F←F∪{m}  {Add term m to F}16:Updatepositiveinstancesui→∈T,i={1,…,p}17:Updatenegativeinstancesvj→∈T,j={1,…,q}18:Check consistency19:end while20:returnFThe overall algorithm's time complexity is O(n5) and its space complexity is O(n3) for large n (where n is the number of variables). So, processing large amounts of data with a single computer may be prohibitive in terms of both space and time needed. Of course, such a complexity is only referred to the training phase where the set of classification rules is initially built from the training data. Once these rules are available the detection activity is extremely simple and fast and hence can be performed in real-time by operating on-line on live network traffic, by potentially including the resulting classifier within a next-generation firewall or IDS system providing limited processing capabilities. The whole operating scenario is depicted in Fig. 1where all the off-line activities, associated to the U-BRAIN framework, are reported into a gray box, whereas the other ones can be managed on-line within the context of a real-time detection system.However, in order to keep the classifier up-to-date with the evolving network traffic dynamics, periodical re-training is necessary. Due to the above computing and space demands characterizing the training phase, such activity can be performed off-line and independently from the running classifier, by eventually distributing its load among multiple cooperating runtime machines that provide high performance High-Performance Computing (HPC) capabilities. Accordingly, the main goal of a recent work [30] has been the construction of a new version of the U-BRAIN algorithm relying on HPC capabilities, in order to overcome the limits related to its high computational complexity. The new version, using more clever mathematical and programming solutions, such as a Dynamic Programming and a new relevance representation, allows the algorithm implementation on parallel computing systems with reduced communication costs. To this aim an effective distributed computing and storage architecture has been specifically designed according to an high degree temporal and spatial locality principle [31]. The algorithm has been implemented by using a Single Program Multiple Data (SPMD) [32] technique together with a Message-Passing Programming paradigm. Overall, the results obtained on standard data sets show that the parallel version is up to 30 times faster than the serial one. Moreover, by increasing the problem size, with a constant number of processors, the average speed-up further increases. Recently, the U-BRAIN parallel version has been used in diagnosis of aerospace structures’ defects. In such a context, the algorithm demonstrated to be effective as a defect classifier in non destructive testing [33].

@&#CONCLUSIONS@&#
Identifying anomalous events is one of the best ways to discover a lot of existing malfunctions and handle most of the security and performance problems that may occur in modern networks. Hence, the availability of reliable detection devices and strategies becomes a fundamental prerequisite for next generation network-empowered infrastructures. We presented a new supervised machine learning approach to anomaly detection, whose goal is understanding the dynamics and behaviors characterizing network traffic in order to generate a set of rules and criteria that can be used to effectively discriminate anomalous events in the normal traffic flow. Such approach couples the capability of inferring rigid decisional structures, represented as Boolean formulas, from incomplete sample observations, with the flexibility introduced by a fuzzy-based uncertainty management strategy. This allows the detection engine to easily adapt to the very different kind of phenomena that can be experienced on a real network. The results of the experimental evaluation demonstrate the ability of successfully handling very different kind of events/phenomena within the context of a quite difficult selection of training and testing data, commonly used for assessing detection approaches.However, it must be considered that the detection capability is directly depending on accuracy of the self-learnt rules describing the traffic model, so that, if the training data are not enough complete and realistic, i.e., they do not reflect all the aspects characterizing the real network traffic, the risk of false positives and/or negatives increases. This introduces the need of an incremental knowledge construction ad refinement process, implemented within the context of a continuous supervised re-training mechanism, managed trough human-driven results validation. Furthermore, while rule construction is a computationally heavy task that has to be managed off-line, on a periodic basis, by relying on properly crafted parallel computing environments, the on-line detection activity, based on the above rules, is extremely simple and effective in term of performance and can be easily implemented in most of the next-generation security equipments available on modern networks.Finally, it should be considered that, by relying on a native rule-based detection strategy, where the inferred rules have the main goal of reliably describing the model (ideally dynamically kept up-to-date through periodic re-training) that represents network traffic, this approach is potentially more effective against previously unknown phenomena and robust against obfuscation mechanisms.