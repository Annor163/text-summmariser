@&#MAIN-TITLE@&#
Simplified supervised i-vector modeling with application to robust and efficient language identification and speaker verification

@&#HIGHLIGHTS@&#
Simplified and supervised I-vector modeling for robust and efficient language identification and speaker verificationI-vector baseline is extended to the proposed label-regularized supervised I-vector modeling for better robustnessI-vector baseline is extended to the proposed simplified I-vector modeling for better efficiencySimplified supervised I-vector modeling improves the performance and reduces the computational cost at the same time

@&#KEYPHRASES@&#
Language identification,Speaker verification,I-vector,Supervised i-vector,Simplified i-vector,Simplified supervised i-vector,

@&#ABSTRACT@&#
This paper presents a simplified and supervised i-vector modeling approach with applications to robust and efficient language identification and speaker verification. First, by concatenating the label vector and the linear regression matrix at the end of the mean supervector and the i-vector factor loading matrix, respectively, the traditional i-vectors are extended to label-regularized supervised i-vectors. These supervised i-vectors are optimized to not only reconstruct the mean supervectors well but also minimize the mean square error between the original and the reconstructed label vectors to make the supervised i-vectors become more discriminative in terms of the label information. Second, factor analysis (FA) is performed on the pre-normalized centered GMM first order statistics supervector to ensure each gaussian component's statistics sub-vector is treated equally in the FA, which reduces the computational cost by a factor of 25 in the simplified i-vector framework. Third, since the entire matrix inversion term in the simplified i-vector extraction only depends on one single variable (total frame number), we make a global table of the resulting matrices against the frame numbers’ log values. Using this lookup table, each utterance's simplified i-vector extraction is further sped up by a factor of 4 and suffers only a small quantization error. Finally, the simplified version of the supervised i-vector modeling is proposed to enhance both the robustness and efficiency. The proposed methods are evaluated on the DARPA RATS dev2 task, the NIST LRE 2007 general task and the NIST SRE 2010 female condition 5 task for noisy channel language identification, clean channel language identification and clean channel speaker verification, respectively. For language identification on the DARPA RATS, the simplified supervised i-vector modeling achieved 2%, 16%, and 7% relative equal error rate (EER) reduction on three different feature sets and sped up by a factor of more than 100 against the baseline i-vector method for the 120s task. Similar results were observed on the NIST LRE 2007 30s task with 7% relative average cost reduction. Results also show that the use of Gammatone frequency cepstral coefficients, Mel-frequency cepstral coefficients and spectro-temporal Gabor features in conjunction with shifted-delta-cepstral features improves the overall language identification performance significantly. For speaker verification, the proposed supervised i-vector approach outperforms the i-vector baseline by relatively 12% and 7% in terms of EER and norm old minDCF values, respectively.

@&#INTRODUCTION@&#
The goal of language identification (LID) is to automatically determine the language spoken in a given segment of speech. In real world applications e.g., security or defense, the speech signals could come from extremely noisy and distorted communication channels, such as short wave AM broadcasting. Thus robust LID on noisy and degraded data represents an important need.Several algorithmic and computational advances have enabled impressive LID performance in the state of the art. Approaches using phonotactic information, namely PRLM (phoneme recognizer followed by language models) and PPRLM (parallel PRLM), have been shown to be quite successful (Zissman, 1995; Yan and Barnard, 1995). In this phonotactic modeling framework, a set of tokenizers are used to transcribe the input speech into token strings or lattices which are later scored by n-gram language models (Gauvain et al., 2004) or mapped into a bag of trigrams feature vector for support vector machine (SVM) modeling (Li et al., 2007a). Although the traditional hidden Markov model (HMM) based phone recognizer (Rabiner, 1989) is widely used as tokenizer in the state-of-the-art systems, other types of tokenizations could also be applied here (Li et al., 2013), for example, Gaussian Mixture Model (GMM) tokenization (Torres-Carrasquillo et al., 2002b), universal phone recognition (UPR) (Li et al., 2007a), articulatory attribute-based approach (Siniscalchi et al., 2010), deep neural networks based phone recognizer (Hinton et al., 2012; Deng and Li, 2013), just to name a few. A recent literature review on LID is provided in Li et al. (2013).With the introduction of shifted-delta-cepstral (SDC) acoustic features (Torres-Carrasquillo et al., 2002a), promising results using GMM framework with factor analysis (Castaldo et al., 2007; Kenny et al., 2007a,b, 2008), supervector modeling (Campbell et al., 2006; Li et al., 2007b) and maximum mutual information (MMI) based discriminative training (Burget et al., 2006) have also been reported for LID. In this work, we focus on the acoustic level systems.Another critical speech processing application domain is speaker verification (SV); this domain also is challenged by significant variability in the speech signal. In particular, the use of joint factor analysis (JFA) (Kenny et al., 2007a,b, 2008) has also contributed to the state of the art performance in text independent speaker verification. It is a powerful technique for compensating the variability caused by different channels and sessions.Recently, total variability i-vector modeling has gained significant attention in both LID and SV domains due to its excellent performance, low complexity and small model size (Dehak et al., 2011a,b; Martinez et al., 2011). In this modeling, first, a single factor analysis is used as a front end to generate a low dimensional total variability space which jointly models language, speaker and channel variabilities all together (Dehak et al., 2011b). Then, within this i-vector space, variability compensation methods, such as Within-Class Covariance Normalization (WCCN) (Hatch et al., 2006), Linear Discriminative analysis (LDA) and Nuisance Attribute Projection (NAP) (Campbell et al., 2006), are performed to reduce the variability for subsequent modeling (e.g., using SVM, logistic regression (LR) (Martinez et al., 2011) and neural network (Matejka et al., 2012) for LID and probabilistic linear discriminant analysis (PLDA) (Matejka et al., 2011; Kenny, 2010) for SV, respectively).However, the i-vector training and extraction algorithms are computationally expensive, especially for large GMM model sizes and large training data sets (Aronowitz and Barkan, 2012; Glembek et al., 2011). Both Glembek et al. (2011) and Aronowitz and Barkan (2012) used a pre-calculated UBM weighting vector to approximate each utterance's 0th order GMM statistics vector to avoid the computationally-expensive GMM component wise matrix operations for the SV task. This approximation resulted in 10–25 times computational cost reduction at the expense of a significant performance degradation (about 17% EER) (Aronowitz and Barkan, 2012). By enforcing this approximation in both training and extraction stages, the performance degradation can be reduced notably (Glembek et al., 2011) on condition that there is no or very little mismatch between train/test data and UBM data. Therefore, we investigated an alternative robust and efficient solution for LID and SV tasks in this work.We perform factor analysis (FA) on the pre-normalized centered GMM first-order statistics supervector to ensure each gaussian component's statistics sub-vector is treated equally in the factor analysis which reduces the computational cost significantly (by a factor of 25). In this way, each utterance is represented with one single pre-normalized supervector as the feature vector plus one total frame number to control its importance against the prior. Each component's sub-vector of statistics is normalized by its own occupancy probability square root, thus mitigating the mismatch between the global pre-calculated average weighting vector (Glembek et al., 2011 adopted the UBM weights) and each utterance's own occupancy probability distribution vector. Furthermore, since there is only one global total frame number inside the matrix inversion, we propose to pre-construct a global lookup table of the resulting matrices against the frame numbers’ log values; the reason to choose the log domain is that the smaller the total frame number, the more important it is against the prior. By looking at the table, each utterance's i-vector extraction is further sped up by a factor of 4 with only a small table index quantization error. The larger the table, the smaller this quantization error.Moreover, as a single unsupervised method, i-vectors cover language, speaker, channel and other variabilities all together which necessarily requires variability compensation methods (both LDA and WCCN are linear) as the back end. This motivated us to investigate joint optimization to minimize the weighted summation of both the re-construction error and the linear classification error simultaneously. Compared to the sequential optimization used for traditional i-vectors, this proposed joint optimization can select the top eigen directions only related to the given labels. This can help reduce the non-relevant information in the i-vector space, such as noise and variabilities from undesired sources (e.g., non-language related factors for LID and session/channel/language related variabilities for SV).In this work, the traditional i-vectors are extended to label-regularized supervised i-vectors by concatenating the label vector and the linear regression matrix at the end of the mean supervector and the i-vector factor loading matrix, respectively. There are some obvious extensions of this supervised i-vector framework. We can let the appended label vector be the parameter vector that we want to perform regression with (e.g., ages Li et al., 2012; Bahari et al., 2012, paralinguistic measures Schuller et al., 2013) to make the proposed framework suitable for regression problems. The reason for using a linear classification/regression matrix W is that many back end classification modules in LID and SV are linear (linear kernel SVM, inner product, WCCN, LDA, etc.). Moreover, if the classification or regression relation is not linear, we can use non-linear mapping as a preprocessing step before generating the label vectors. The contribution weight of each supervector dimension and each target class in the objective function is automatically calculated by iterative EM training. The traditional i-vector system serves as our baseline.Finally, inspired by the success of robust features for noisy data based SV tasks (Shao and Wang, 2008; Lei et al., 2012), we also applied the auditory-inspired Gammatone frequency cepstral coefficients (GFCC) (Shao and Wang, 2008; Zhao and Wang, 2013) features and the spectro-temporal Gabor features (Kleinschmidt and Gelbart, 2002) for robust LID task on the noisy data as additional performance improvement steps. When fused with traditional MFCC and SDC feature based systems, the overall system performance was further enhanced.The remainder of the paper is organized as follows. The baseline and the proposed algorithms are explained in Sections 2 and 3, respectively. Complexity analysis is given in Section 3.3. Experimental results and discussions are presented in Section 4 while conclusions are provided in Section 5.In the total variability space, there is no distinction between the language effects, speaker effects and the channel effects. Rather than separately using the eigenvoice matrix V and the eigenchannel matrix U (Kenny et al., 2007b), the total variability space simultaneously captures the speaker and channel variabilities (Dehak et al., 2011a). Given a C component GMM UBM model λ with λc={pc,μc,Σc}, c=1, …, C and an utterance with a L frame feature sequence {y1,y2, …,yL}, the 0th and centered 1st order Baum-Welch statistics on the UBM are calculated as follows:(1)Nc=∑t=1LP(c|yt,λ)(2)Fc=∑t=1LP(c|yt,λ)(yt−μc)where c=1, …, C is the GMM component index and P(c|yt, λ) is the occupancy probability foryton λc. The corresponding centered mean supervectorF˜is generated by concatenating all theFc˜together:(3)Fc˜=∑t=1LP(c|yt,λ)(yt−μc)∑t=1LP(c|yt,λ).The centered GMM mean supervectorF˜can be projected on a low rank factor loading matrixTfollowing the standard factor analysis framework as shown in Fig. 1:(4)F˜→Tx,whereTis a rectangular total variability matrix of low rank andxis the so-called i-vector (Dehak et al., 2011a). Considering a C-component GMM and D dimensional acoustic features, the total variability matrixTis a CD×K matrix which can be estimated the same way as learning the eigenvoice matrixVin Kenny et al. (2005) except that here we consider that every utterance is produced by a new speaker or in a new language (Dehak et al., 2011a).Given the centered mean supervectorF˜and total variability matrixT, the i-vector is computed as follows (Dehak et al., 2011a):(5)x=(I+TtΣ−1NT)−1TtΣ−1NF˜whereNis a diagonal matrix of dimension CD×CD whose diagonal blocks are NcI, c=1, …, C andΣis a diagonal covariance matrix of dimension CD×CD estimated in the factor analysis training step. It models the residual variability not captured by the total variability matrixT(Dehak et al., 2011a). The mathematical interpretation under the standard factor analysis framework is provided in Section 3.1.In this total variability space, two channel compensation methods, namely Linear Discriminant Analysis (LDA) and Within Class Covariance Normalization (WCCN) (Hatch et al., 2006), are typically applied to reduce variability. LDA attempts to transform the axes to minimize the intra-class variance due to the variability effects and maximize the variance between classes while WCCN uses the inverse of the within-class covariance to normalize the cosine kernel. After LDA and WCCN steps, cosine distance is employed for i-vector modeling. The cosine kernel between two i-vectorsx1 andx2 is defined as follows:(6)k(x1,x2)=<x1,x2>∥x1∥2∥x2∥2Finally, PLDA or SVM is adopted as the classifier.The i-vector training and extraction can be re-interpreted as a classic factor analysis based generative modeling problem. We can assume that the mean supervector is generated by the hidden variable i-vector. For the jth utterance, the prior and the conditional distribution is defined as following multivariate Gaussian distributions:(7)P(xj)=N(0,I),P(Fj˜|xj)=N(Txj,Nj−1Σ)therefore, the posterior distribution of the hidden variable i-vectorxgiven the observedF˜is:(8)P(xj|Fj˜)=N((I+TtΣ−1NjT)−1TtΣ−1NjFj˜,(I+TtΣ−1NjT)−1).The mean of the posterior distribution (point estimate) is adopted as the estimation of i-vector.As shown in Fig. 2, the traditional i-vectors are extended to the label-regularized supervised i-vectors by concatenating the label vector and the linear regression matrix at the end of the mean supervector and the i-vector factor loading matrix, respectively. These supervised i-vectors are optimized not only to reconstruct the mean supervectors well but also to minimize the mean square error between the original and the reconstructed label vectors, and thus can make the supervised i-vectors become more discriminative in terms of the regularized label information.(9)P(xj)=N(0,I),PFj˜Lj|xj)=NTxjWxj,Nj−1Σ1nj−1Σ2In (7), (8), (9),xj,Nj,Fj˜andLjdenote the jth utterance's i-vector,Nvector, mean supervector and label vector, respectively.Σ1 andΣ2 denote the variance for CD dimensional mean supervector and M dimensional label vector, respectively.nj=∑c=1CNcjwhere Ncjdenotes the Ncfor the jth utterance. The reason for using a global scalar njis that each target class is treated equally in terms of frame length importance, the varianceΣ2 is adopted to capture the variance and accuracy for each particular class.We design two types of label vectors as follows (type 1 is mainly for identification purposes and type 2 is for verification tasks):(10)Supervisedtype1:Lij=1ifutterancejisfromclassi0otherwiseFor type 1 label vectors, we want the regression matrix W to correctly classify the class labels. We denote the dimensionality of label vector Ljas M. Suppose there are H target classes (H languages for LID or H speakers for SV), Ljis an H (M=H) dimensional binary vector with only one non-zero element with the value of 1 and W is a M×K linear regression matrix.(11)Supervisedtype2:Lj=x¯sj,W=I.Type 2 label vectors specify the sample mean vector of all the supervised i-vectors from the same class in the last iterationx¯sjand let the regression matrix be an identity matrix (similar to the one in WCCN). The reason is to reduce the within class covariance and help all the supervised i-vectors to move towards their class sample mean. Therefore, M=K in this case.The log likelihood of the total Γ utterances is:(12)∑j=1Γln(P(Fj˜,Lj,xj))=∑j=1ΓlnPFj˜Lj|xj+ln(P(xj))Combining (9) and (12) together and removing non-relevant items, we can get the objective function J for the Maximum Likelihood (ML) EM training:(13)J=∑j=1Γ(12xjtxj+12(Fj˜−Txj)tΣ1−1Nj(Fj˜−Txj)+12(Lj−Wxj)tΣ2−1nj(Lj−Wxj)−12ln(|Σ1−1|)−12ln(|Σ2−1|))It is worth noting that we simply setTandWto be uncorrelated in order to get (13). The reason to make this simplification is that in the factor analysis generative model, given the i-vectorx, the mean supervectorFand label vectorLare conditionally independent.For the E-step, we estimate E(xj) and E(xjxjt):(14)E(xj)=(I+TtΣ1−1NjT+WtΣ2−1njW)−1(TtΣ1−1NjFj˜+WtΣ2−1njLj),(15)E(xjxjt)=E(xj)E(xj)t+(I+TtΣ1−1NjT+WtΣ2−1njW)−1.Then, for the M-step, we need to minimize the following expected objective function:(16)E(J)=∑j=1Γ(12Tr[E(xjxjt)]+12Fj˜tΣ1−1NjFj˜+12Tr[TE(xjxjt)TtΣ1−1Nj]−Fj˜tΣ1−1NjTE(xj)+12LjtΣ2−1njLj+12Tr[WE(xjxjt)WtΣ2−1nj]−LjtΣ2−1njWE(xj)−12ln(|Σ1−1|)−12ln(|Σ2−1|))In deriving(16), we usedTr[TxjxjtTtΣ1−1Nj]=Tr[xjtTtΣ1−1NjTxj]. By setting the derivatives of E(J) towardsTandWto be 0, we can get:(17)∑j=1ΓNjTE(xjxjt)=∑j=1ΓNjFj˜E(xjt)(18)∑j=1ΓnjWE(xjxjt)=∑j=1ΓnjLjE(xjt)Since njis a scalar, the newWmatrix is updated as:(19)Type1:Wnew=[∑j=1ΓnjLjE(xjt)][∑j=1ΓnjE(xjxjt)]−1Since the regression matrixWin the type 2 setup is set to identity, we do not updateWfor type 2 setup. For theTmatrix, we followed the strategy used in Dehak et al. (2011a) to update component by component since Ncjis also a scalar.(20)Tcnew=[∑j=1ΓNcjFcj˜E(xjt)][∑j=1ΓNcjE(xjxjt)]−1In (20),Tcdenotes the [(c−1)D+1:cD] rows sub-matrix ofTandFcj˜is the [(c−1)D+1:cD] elements sub-vector ofFj˜. Similarly, by setting∂Ej∂(Σ1−1)and∂Ej∂(Σ2−1)to be 0, we can get:(21)Σ1=diag{∑j=1Γ(Nj(Fj˜−TnewE(xj))Fj˜t)}Γ(22)Type1:Σ2=diag{∑j=1Γ(nj(Lj−WnewE(xj))Ljt)}Γ(23)Type2:Σ2=diag{∑j=1Γ(nj(Lj−E(xj))t(Lj−E(xj)))}ΓThese 2 variance vectors describe the energy that cannot be represented by factor analysis and control the importance in the joint optimization objective function (13). Σ2 for the type 2 label vectors is just the diagonal elements of the within class covariance matrix in WCCN. After several iterations of EM training, the parameters are learned. For the subsequent supervised i-vector extraction, we letΣ2 to be infinity since we do not know the ground truth label information. This will make (14) converge back to (5). After the supervised i-vector extraction, the classification methods steps are the same as in the traditional i-vector modeling.There are some obvious extensions of this supervised i-vector framework. We can makeLas the parameter vector that we want to perform regression with and this can make the proposed framework suitable for regression problems. Moreover, if the classification or regression relation is not linear, we can use non-linear mapping as a preprocessing step before generatingL.I-vector training and extraction is computationally expensive. Consider the GMM size, feature dimension, factor loading matrix size to be C, D, and K, respectively. The complexity for generating a single i-vector is O(K3+K2C+KCD) (Glembek et al., 2011). As shown in Table 1(K=600, C=2048, D=56), the K2C term dominates the overall complexity. In this work, we make two approximations to reduce the complexity.The K3 term comes from the matrix inversion while the K2C term is fromTtΣ−1NjTin (5). When C is large, this K2C term's computational cost is huge. The fundamental reason is that each Gaussian component λchas different Ncfor each utterance j which means some sub-vectorsFcj˜have less variance than others inFj˜and need utterance specific intra mean supervector re-weighting in the objective function. We first decompose theNjvector intoNj=njmjwherenj=∑c=1CNcj, mcj=Ncj/njand∑c=1Cmcj=1.mjis the re-weighting vector and nj(total frame number) controls the confidence at the global level. Our motivation is to re-weight each utterance's mean supervector with its own (mj)1/2 before the factor analysis step which makes each dimension of the new supervectorFjˆbe treated equally in the approximated modeling (25).(24)Fcˆ=diag([∑t=1LP(c|yt,λ)∑c=1C∑t=1LP(c|yt,λ)]1/2)∑t=1LP(c|yt,λ)(yt−μc)∑t=1LP(c|yt,λ)=diag([Ncjnj]1/2)∑t=1LP(c|yt,λ)(yt−μc)∑t=1LP(c|yt,λ)Fjˆ=diag(mj1/2)Fj˜So the intra supervector imbalance is compensated by this pre-weighting, and each utterance is represented byFjˆas the general feature vector and njas the confidence value for the subsequent machine learning algorithms. We perform factor analysis in the following way by linearly projecting this new normalized supervectorFˆon a dictionaryTˆ:(25)Fˆ=Txˆ,P(xjˆ)=N(0,I),P(Fjˆ|xjˆ)=N(Tˆxjˆ,mjNj−1Σ)=N(Tˆxjˆ,mj(njmj)−1Σ)=N(Tˆxjˆ,nj−1Σ)Therefore, the posterior distribution of the i-vectorxˆgiven the observedFˆis:(26)P(xjˆ|Fjˆ)=N((I+TtˆΣ−1njTˆ)−1TtˆΣ−1njFjˆ),(I+TtˆΣ−1njTˆ)−1).From the above equation, we can find that the complexity is reduced to O(K3+KCD) since njis not dependent on any GMM component. By replacing the 1st GMM statistics supervectorFj˜with the pre-normalized supervectorFjˆand settingNjto a scalar nj, the i-vector training equations become the proposed simplified i-vector solution.Moreover, since the entire term(I+TtˆΣ−1njTˆ)−1TtˆΣ−1in (26) only depends on the scalar total frame number nj, we can create a global table of this quantity against the log value of nj. The reason to choose log domain is that the smaller the total frame number, the more important it is against the prior. If njis very large compared to the prior, then the two njget canceled. By enabling the table lookup, the complexity of each utterance's i-vector extraction is further reduced to O(KCD) with a small table index quantization error. The larger the table, the smaller this quantization error. Fig. 3shows the quantization distance curve. We can see that the quantization error is relatively small when njis small.In this work, we also derived the simplified supervised i-vector modeling's solution as follows:(27)E(xjˆ)=(I+TtˆΣ1−1njTˆ+WtΣ2−1njW)−1(TtˆΣ1−1njFjˆ+WtΣ2−1njLj),(28)E(xjˆxjˆt)=E(xjˆ)E(xjˆ)t+(I+TtˆΣ1−1njTˆ+WtΣ2−1njW)−1.(29)Wnew=[∑j=1ΓnjLjE(xjˆt)][∑j=1ΓnjE(xjˆxjˆt)]−1(30)Tˆnew=[∑j=1ΓnjFjˆE(xjˆt)][∑j=1ΓnjE(xjˆxjˆt)]−1(31)Σ1=diag{∑j=1Γ(nj(Fjˆ−TˆnewE(xjˆ))Fjˆt)}Γ(32)Σ2=diag{∑j=1Γ(nj(Lj−WnewE(xj))Ljt)}ΓSince the label vector dimensionality M<<CD, the complexity is almost the same as previously shown, O(CDK). It is worth noting that for best accuracy, we only perform approximation using the global table for training purposes. When in testing mode, (27) is still employed (withΣ2−1=0). All the experimental results based on simplified i-vector or simplified supervised i-vector in Section 4 are generated in this way.The complexity of the proposed methods for a single utterance is shown in Table 1. We use both LID and SV examples to demonstrate the efficiency of the proposed methods. We can see that the proposed simplified and simplified supervised i-vector systems achieve significant complexity cost reduction (by more than a factor of 100) which has a potentially large impact on mobile devices implementation.

@&#CONCLUSIONS@&#
This paper presented a robust and efficient approach using simplified and supervised i-vector modeling with applications to automatic language identification (LID) and speaker verification (SV). Several new algorithmic and computational modeling ideas are proposed. First, by concatenating the label vector and the linear regression matrix at the end of the mean supervector and the i-vector factor loading matrix, respectively, the traditional i-vectors are extended to the label-regularized supervised i-vectors. These supervised i-vectors are optimized not only to reconstruct the mean supervectors well but also to minimize the mean square error between the original and the reconstructed label vectors; this can thus make the supervised i-vectors become more discriminative in terms of the regularized label information. Second, factor analysis (FA) is performed on the pre-normalized GMM first order statistics supervector to ensure each gaussian component's statistics sub-vector is treated equally in the FA which reduces the computational cost by a factor of 25. Further computational improvement is obtained by pre-computing a global cache table of the resulting matrices against the total frame numbers’ log values. By using the lookup table, each utterance's i-vector extraction is further sped up by another factor of 4 with just a small table index quantization error. The larger the table, the smaller this quantization error. Third, simplified and supervised i-vector modeling can be used together as the simplified supervised i-vector which outperforms the i-vector baseline in terms of both robustness and efficiency. The solutions for training and extracting these simplified version i-vectors are provided for both the traditional unsupervised and the proposed supervised i-vectors. Finally, Gammatone frequency cepstral coefficients (GFCC) and Gabor features are adopted as yet additional (complementary) auditory-inspired and spectro-temporal features for LID. By fusing GFCC and Gabor features with the traditional MFCC and SDC features based systems, overall LID performance is improved significantly.