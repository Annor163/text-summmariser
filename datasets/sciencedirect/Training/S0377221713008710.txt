@&#MAIN-TITLE@&#
Integer programming models for the multidimensional assignment problem with star costs

@&#HIGHLIGHTS@&#
We introduce a continuous nonlinear program for solving the multidimensional star assignment problem (MSAP).We transform the initial formulation into a mixed integer linear optimization program.We propose valid inequalities to improve the lower bound of the proposed formulation.We reformulate the MSAP as a set partitioning problem, and solve it via branch and price.We test our approach by solving several MSAP instances of different sizes.

@&#KEYPHRASES@&#
Combinatorial optimization,Multidimensional assignment problem,Star covering,Multi-sensor multi-target tracking problem,Graph partitioning,Branch and price,

@&#ABSTRACT@&#
We consider a variant of the multidimensional assignment problem (MAP) with decomposable costs in which the resulting optimal assignment is described as a set of disjoint stars. This problem arises in the context of multi-sensor multi-target tracking problems, where a set of measurements, obtained from a collection of sensors, must be associated to a set of different targets. To solve this problem we study two different formulations. First, we introduce a continuous nonlinear program and its linearization, along with additional valid inequalities that improve the lower bounds. Second, we state the standard MAP formulation as a set partitioning problem, and solve it via branch and price. These approaches were put to test by solving instances ranging from tripartite to 20-partite graphs of 4 to 30 nodes per partition. Computational results show that our approaches are a viable option to solve this problem. A comparative study is presented.

@&#INTRODUCTION@&#
The multidimensional assignment problem (MAP), originally introduced by Pierskalla (1968), aims to minimize the overall cost of assignment when matching elements fromN={N1,…,Nn}(n>2) disjoint sets of equal size m. It comes as a natural generalization of the two-dimensional Assignment Problem (AP), known to be polynomially solvable (Edmonds & Karp, 1972; Kuhn, 1955). Among all the different generalizations of the MAP, the one considered in this paper is the axial MAP (hereafter referred to as MAP). In an axial MAP, each element of every set must be assigned to exactly one of m disjoint n-tuples, and each n-tuple must contain exactly one element of each set. Contrary to the AP, the MAP is known to be NP-hard (Karp, 2010) for all values ofn>2.The MAP is usually presented as the following integer (0–1) program(1)(MAP):min∑i1∈N1∑i2=N2,…,∑in∈Nnci1i2,…,inxi1i2,…,in(2)s.t.∑i2∈N2∑i3∈N3,…,∑in∈Nnxi1i2,…,in=1,i1∈N1(3)∑i1∈N1,…,∑is-1∈Ns-1∑is+1∈Ns+1,…,∑in∈Nnxi1i2,…,in=1,is∈Ns,s=2,,…,,n-1(4)∑i1∈N1∑i2∈N2,…,∑in-1∈Nn-1xi1i2,…,in=1,in∈Nn(5)xi1i2,…,in∈{0,1},is∈Ns,s=1,…,n,where for every n-tuple(i1,i2,…,in)∈N1×N2×⋯×Nn, variablexi1i2,…,intakes the value of one if elements of the given n-tuple belong to the same assignment, and zero otherwise. The total assignment cost (1) is computed as the cost of matching elements from different sets together. As an example, an assignment which selects elements(i1,i2,…,in)to be grouped together would have a cost ofci1i2,…,in.Depending on the definition of the assignment costs, there are several variations of the MAP that can be considered. These variations are mainly associated with cases where the assignment cost of each n-tuple can be decomposed as a function of all possible pairwise assignment costs between elements of different sets. That is,ci1i2,…,in=f(ci1i2,…,cinin-1), wheref:N1×N2∪⋯∪Nn-1×Nn→Randcisitis the cost of assigning together elementsis∈Nsandit∈Nt, fors≠t. In general, the main advantage of having decomposable cost functions is that there may be ways of tackling the problem without having to completely enumerate all of the different assignment costs, which can be exponentially many. Moreover, most of these MAP variations can be associated with a weighted n-partite graph, in which the elements are represented by the vertices of the graph, each of the edges describes the decision of assigning two elements within the same n-tuple, and the weights on the edges account for the corresponding assignment costs. We provide a detailed explanation of this representation in Section 2.Based on the applications and the context of the problem, there are different definitions of the MAP with decomposable costs that can be found in the literature (Aneja & Punnen, 1999; Bandelt, Crama, & Spieksma, 1994; Burkard, Rudolf, & Woeginger, 1996; Crama & Spieksma, 1992; Malhotra, Bhatia, & Puri, 1985; Kuroki & Matsui, 2009). In this paper we consider the case where each n-tuple of any feasible assignment is assumed to form a star (see, Bandelt et al., 1994). Nonetheless, since most of the extant literature concentrates on the case where the n-tuples form cliques, we also provide a brief description of the latter to emphasize the differences and enrich the discussion.For the case of the cliques, a feasible assignment includes all possible pairwise connections within the elements of each tuple and thus, the cost of tuple(i1,i2,…,in)∈N1×N2×⋯×Nnis defined as the sum of all pairwise assignment costs. That is,(6)ci1i2,…,in=∑s=1n∑t=s+1ncisitOn the other hand, for the case of the stars, one element of each tuple is assigned to be a center (or representative) and the other elements are considered to be the leafs (or legs) of the star. Note that, contrary to the case of the cliques, each tuple can generate many different star configurations, depending on which element is selected as the center. Assuming for example, that the center is elementis, the cost of the induced star is the sum of the pairwise costs betweenisand the other elements of the tuple. In view of these multiple possible configurations, the cost of tuple(i1,i2,…,in)∈N1×N2×⋯×Nnis defined as the minimum cost among the costs of all the possible star configurations of the tuple. That is,(7)ci1i2,…,in=minis∈{i1,i2,…,in}∑t∈{1,2,…,n}⧹{s}cisitWe name the aforementioned MAP version, the multidimensional star assignment problem (MSAP), because of the particular structure that each feasible assignment has. Despite the fact that this variant is often referred to as a particular case of the clique version (Bandelt et al., 1994), we consider that it is relevant to state it in a separate form. We base our argument on the fact that there exist applications for which the use of this variant could be of benefit. Moreover, there are formulations and techniques specifically tailored to solve the MSAP.Several methodologies have been proposed to solve different variants and generalizations of the MAP, including exact approaches, approximation algorithms, heuristics, and metaheuristics. In particular, given the inherent NP-hardness of the problem, heuristic approaches have gained practical interest over the years. These include greedy heuristics (Balas & Saltzman, 1991), generalized randomized adaptive search procedures (GRASP) (Murphey, Pardalos, & Pitsoulis, 1999; Robertson III, 2001), GRASP with path relinking (Aiex, Resende, Pardalos, & Toraldo, 2005), randomized algorithms (Oliveira & Pardalos, 2004), genetic algorithms (Gaofeng & Lim, 2003), memetic algorithms (Karapetyan & Gutin, 2011b), local search heuristics (Bandelt, Maas, & Spieksma, 2004; Karapetyan & Gutin, 2011a), simulated annealing (Clemons, Grundel, & Jeffcoat, 2004), decomposition schemes (Vogiatzis, Pasiliao, & Pardalos, 2013), Lagrangian based procedures (Balas & Saltzman, 1991; Frieze & Yadegar, 1981; Poore & Robertson, 1997), and branch-and-bound techniques (Larsen, 2012; Pasiliao, Pardalos, & Pitsoulis, 2005).From the perspective of approximation algorithms, there exist the works of Crama and Spieksma (1992) and Bandelt et al. (1994). Furthermore, contributions to the study of the polyhedral structure of the MAP formulation and other generalizations can be found in Appa, Magos, and Mourtos (2006), Balas and Saltzman (1989) and Magos and Mourtos (2009). Finally, studies related to the asymptotic behavior of the expected optimal value of the MAP, as well as tools to perform probabilistic analysis of MAP instances are given in Krokhmal, Grundel, and Pardalos (2007), Grundel, Oliveira, and Pardalos (2004) and Gutin and Karapetyan (2009).Among all the proposed techniques listed above, we next focus our attention on approaches that are either proposed to tackle the MSAP, or that are designed to solve generalizations of the MAP, and thus can also be used to solve this problem. To solve the MSAP, Crama and Spieksma (1992) introduced an approximation algorithm designed to solve the three-dimensional case (i.e.,n=3). The proposed algorithm consists of sequentially solving two linear assignment problems. First, the elements of setN1are assigned to the ones of setN2and then, the resulting pairs are assigned to the elements of setN3. The authors proved that if the pairwise assignment costs satisfy the triangle inequality, the proposed algorithm produces a12approximation. Moreover, noting that this algorithm can produce three different solutions by simply varying the assignment order of the sets (e.g., assigning first the elements ofN1to the ones of setN3and then, assigning the resulting pairs to the elements of setN2), Crama and Spieksma proved that selecting the best of the three solutions yields a13approximation.In a subsequent study, Bandelt et al. (1994) proposed two type of heuristics, namely the hub and the recursive heuristics. They can be viewed as generalizations of the approach proposed by Crama and Spieksma (1992), but designed to solve the general n-dimensional case. The authors also provide an upper bound on the ratio between the cost of the solutions produced by these heuristics and the cost of the optimal solution.As mentioned before, the MSAP is a particular case of the MAP and therefore, it can be solved using formulation (1)–(5). The polyhedral studies introduced by Balas and Saltzman (1989), for the three-dimensional case, and by Appa et al. (2006) and Magos and Mourtos (2009), for a more general version of the MAP, can be used to enhance (1)–(5) via the introduction of cutting planes. Using formulation (1)–(5) to solve the MSAP has one main drawback. It requires that all possible star costs be generated beforehand. This could be problematic because the total number of possible stars grows exponentially with the size of the problem (see Section 3). To circumvent this issue, it is possible to embed (1)–(5) within a branch-and-price scheme (see Section 3). Therefore, instead of enumerating all possible stars from the beginning, those are generated via column generation, in case they are considered suitable. The downside of this approach, though, is that mixing cutting planes and column generation is in general a difficult task (Barnhart, Johnson, Nemhauser, Savelsbergh, & Vance, 1998; Desaulniers, Desrosiers, & Spoorendonk, 2011; Lübbecke & Desrosiers, 2005).For additional information about the MAP and its variations, we refer the reader to the surveys provided by Burkard, Çela, Pardalos, and Pitsoulis (1998), Burkard and Çela (1999), Burkard (2002), Gilbert and Hofstra (1988), Pardalos and Pitsoulis (2000), Pentico (2007) and Spieksma (2000).This paper is inspired by the context of multi-sensor multi-target tracking problems, that involve the assignment of a series of sensor observations into a set of different targets. The relationship between these problems and the MAP, has been stated and studied by many authors including Bandelt et al. (2004), Chummun, Kirubarajan, Pattipati, and Bar-Shlom (2001), Deb, Pattipati, and Bar-Shalom (1993), Deb, Yeddanapudi, Pattipati, and Bar-Shalom (1997), Morefield (1977), Murphey et al. (1999), Poore (1994) and Pusztaszeri, Rensing, and Liebling (1996) among others.There are several contexts in which using star costs can prove beneficial when solving multi-sensor multi-target tracking problems. In particular, when the assignment costs have metric properties (i.e., nonnegativity, symmetry, and subadditivity), it is interesting to see that in some cases, considering all pairwise costs within the assignments (e.g., the clique case) is not necessary to obtain a valid solution. We provide two examples with costs that satisfy those properties and show that the star cost variation is a valuable tool to solve those problems. We would like to emphasize though, that the star costs are not always a better or worse option compared to other versions such as the clique costs. Instead, it can be seen as an alternative that also provides additional information, and that can contribute to a better analysis depending on the context.In the first example we aim to identify a set of land mines that are planted on a field. To find the location of the mines, a drone is sent to fly over the field emitting a signal. Once the signal reaches each of the mines, it bounces back and is analyzed by the sensors of the drone. After the drone has flown over the field a number of times and its sensors have collected the set of different signals (several of those associated with each of the mines), it is possible to calculate a set of estimated locations where the mines could be located. The idea behind solving a MAP is to associate the locations that are close to each other, which would help pinpoint the actual positions of the mines. In this context, the assignment costs represent the Euclidean distances between the estimated locations and, since the costs satisfy the triangle inequality, not all the costs need to be considered to obtain a valid association.Consider the simple case depicted in Fig. 1a, where the nodes represent three estimated locations that where assigned together. Here, the center of the star is clearly node 1. Notice that, the cost of the legs (i.e., edges(1,2)and(1,3)) already contains information about the cost of edge(2,3). In this example, since we expect that costc23satisfiesmax{c12,c13}⩽c23⩽c12+c13, some information aboutc23is already considered within the value ofc12+c13. In some situations, for instance in the presence of a faulty sensor, addingc23could contribute to obtain a wrong assignment, especially when this value is close to its upper bound.Moreover, the expected position of the mine is often considered to be a concurrency point associated with the positions that are in the same n-tuple, generally the centroid. On the other hand, if star costs are used, the region around the center of the stars can be seen as the zone where the mines are most likely to be located. Under the triangle inequality assumption, it is easy to prove that many of the triangle concurrency points (e.g., the centroid, the incenter, or the circumcenter) are always closer to the center of the star. For instance, observe the locations of the centroid (×1) and the incenter (×2) of Fig. 1b (this can also be generalized forn>3). This implies that, if the assignments (i.e., the n-tuples) produced by both the clique or the star versions are the same, then the conclusion regarding the positions of the mines would be very similar. Following this idea, lettingCMSAPandCMAPbe the optimal assignment costs of the MSAP and the clique MAP, respectively. It can be seen that, for the 3-dimensional case, the inequalityCMSAP⩽CMAP⩽2CMSAPholds. This is easily generalized for the n-dimensional case toCMSAP⩽CMAP⩽(n-1)CMSAP, which implies that, in case a solution for the clique version is required, the MSAP generates both upper and lower bounds on the optimal value.Fig. 2represents a case in which one of the observations of a given sensor (node (1,1)) is wrongly assigned to a position far away from the other observations. In this example, we assume that there are two mines in the field and six estimated positions calculated by three different sensors. First, in Fig. 1b, note that, if the representative locations of the mines are assumed to be the centroids of the cliques, those positions are strongly biased by the wrong observation and then, are positioned significantly farther away from any of the original observations. This particular issue is depicted in clique {(1,1),(1,2),(1,3)}. On the other hand, in Fig. 1c it can be seen that this effect is reduced when using a star assignment. We make the remark that similar examples can also can be constructed to point out negative effects of using the star costs. Therefore, in this context it is often considered solving the problem with both the star and the clique costs to have more information and obtain a better analysis.The second example is a case where the costs do not represent Euclidean distances and hence, the concept of the geometric center does not have a proper interpretation. Assume we have a group of antennas that are placed to intercept a collection of encrypted messages that we want to decode. Because of the interference and the noise of the environment, when the messages are received by the antennas they are somehow disrupted and thus not perfect for decoding. Each of the antennas can potentially receive a different version of each of the messages. The idea is to identify which of the received versions are the ones that most closely resemble the correct (transmitted) ones, so they can be sent for decoding. Here, since there is no way to compare the disrupted versions with the correct messages, the decision of which versions are finally sent to decode should be made by analyzing the dissimilarities between the received messages. In many contexts like this, the decoding process could be rather difficult. Hence, it is desired to select only one of the disrupted versions of each of the messages. Assuming that the messages are encrypted in some kind of alphabet (e.g., binary codes), using the centroid of the disrupted versions is not a valid approach here. In this framework, the use of the star costs could be of benefit, because the messages associated with the centers of the stars can be the ones selected for decoding (representative). For this problem, the costs can be assumed to be the number of different characters between the messages, the sum of how far apart in the alphabet the different characters of the messages are, or any desired correlation metric.The examples that we provided represent two cases of many others for which the MSAP arises. We would like to emphasize that the models introduced in this paper are intended to tackle more general instances of the MSAP and, therefore, can be used to solve not only these problems, but a multitude of others as well. The paper is outlined as follows. In Section 2, we formally state the MSAP and propose a continuous nonlinear formulation and its linearization. Further, we introduce five families of valid inequalities to strengthen the formulation. Then, in Section 3 we reformulate (1)–(5) as a set partitioning problem, and solve it via branch and price. In Section 4 we present the computational results over a series of instances ranging in size from tripartite to 20-partite graphs of 4 to 30 nodes per partition. We then proceed to compare the solutions from both approaches. Last, in Section 5 we summarize our findings, and offer insights for future research on this topic.Given a collectionN1,…,Nnof n disjoint node sets of equal size m and the corresponding collection of pairwise arc setsE12,…,En-1,n, whereEst=Ns×Ntfors<t, letG=(N,E)be a complete n-partite graph, whereN=⋃s=1nNsandE=⋃s<tEst. We refer to the ith node of setNswith the duple(i,s)and use the quadruple(i,s,j,t), to represent the edge between nodes(i,s)and(j,t). Also, letcijstbe a cost value associated with edge(i,s,j,t)that accounts for the cost of assigning nodes(i,s)and(j,t)to the same star. Let a valid star be defined as a subgraph ofGsuch that, (1) it contains exactly one node from each setN1,…,Nn; (2) one of the nodes (the center) is connected to all of the other nodes of the star (the leafs); and (3) there are no connections between any pair of leafs. Then, the MSAP aims for a set of m disjoint valid stars that cover all the nodes inG. An example of a valid star assignment of an instance, wheren=4andm=3is given in Fig. 3. The three valid stars are colored gray, black, and white. The MSAP is known to be NP-hard (Crama & Spieksma, 1992).Let variableszandxbe defined as follows:zis=1,ifnode(i,s)∈Nisastarcenter0,otherwise,andxijst=1,ifnodes(i,s)and(j,t)∈Nbelongtothesamestar0,otherwise.Observe thatxijst=xjitsfor all(i,s,j,t), andxijss=0, since(i,s,j,s)∉E. The initial formulation is presented in (8)–(15), where the objective function (8) aims to minimize the overall assignment cost. Constraints (9) ensure that, if node(i,s)is a center, it must be connected to(n-1)nodes. Conversely, if it is not a center, then it should be connected to one node. Constraints (10) and (11) guarantee that if node(i,s)is a center, it must be connected to exactly one node from each setNt, for allt≠s. Further, constraints (12) enforce that there are exactly m stars in the optimal solution. Nonlinear constraints (13) guarantee that each node(i,s)∈Nis either connected to a center, or is a center itself, and hence, it can only be connected to leafs. Last, (14) and (15) define the domain of variableszandx.(8)(INLP):min∑i=1m∑j=1m∑s=1n∑{t=1,…,n:s<t}cijstxijst(9)s.t.∑j=1m∑t=1nxijst=1+(n-2)zis,∀i=1,…,ms=1,…,n(10)∑j=1mxijst⩽1,∀i=1,…,ms,t=1,…,n(11)∑j=1mxijst⩾zis,∀i=1,…,ms,t=1,…,n(12)∑i=1m∑s=1nzis=m(13)zis+∑j=1m∑t=1nxijstzjt=1,∀i=1,…,ms=1,…,n(14)zis∈{0,1},∀i=1,…,ms=1,…,n(15)xijst∈{0,1},∀i=1,…,ms=1,…,n.Let RNLP be the continuous relaxation of formulation (8)–(15). That is, bothzandxare allowed to take fractional values between zero and one. We now proceed to prove that in any feasible solution of RNLP, allzvariables take integer values. For this proof, assume we have a feasible solution(z,x). We refer to node(i,s)as white ifzis=0, black ifzis=1, or gray ifzis∈(0,1).Lemma 1In any feasible solution of RNLP, a white node can only be connected to black nodes.See Appendix A. □In any feasible solution of RNLP, a black node can only be connected to white nodes.See Appendix A. □Based on Lemmata 1 and 2, we can deduce that, if there exist gray nodes, then they are only connected to other gray nodes.Lemma 3If there exist gray nodes in a feasible solution, then the number of those is a multiple of n.See Appendix A. □In any feasible solution of the RNLP, allzvariables are binary (i.e., there cannot exist gray nodes).See Appendix A. □Contrary to the case of thezvariables, it is easy to see that there can be feasible solutions where some of thexvariables are fractional. Consider the example presented in Fig. 4. It is easy to see that the fractional solution depicted in Fig. 4c, satisfies all constraints in (9)–(13). Moreover, such a solution is actually a convex combination of integral solutions displayed in Fig. 4a and b. Note that we are able to construct this combination because the star centers in both integral solutions Fig. 4a and b are the same. Because of the result presented in Theorem 1, a strictly convex combination between two integral solutions with different star centers would yield fractionalzvariables, and therefore an infeasible solution. We now formally prove that if there exists an optimal solution where thexare fractional, there is also an alternative integral solution.Theorem 2If RNLP is feasible, then there always exists an optimal solution of RNLP, where allxvariables take integer values.See Appendix A. □As a result from Theorems 1 and 2, constraints (14) and (15) can be relaxed in INLP, leaving the continuous nonlinear optimization problem RNLP, henceforth referred to only as NLP. To solve this formulation we can use any available optimizer that handles nonlinear programs. Although, in spite of having a continuous formulation, rather than an integer one, nonlinear constraints (13) still pose a difficult challenge because of their non-convex nature. As an alternative approach, instead of solving NLP, we propose using a standard linearization technique that involves introducing additional variables to replace the bilinear terms in constraints (13). Furthermore, from the results presented in Theorems 1 and 2, we derive additional valid inequalities that strengthen the proposed linear formulation. A description of the linearization and the valid inequalities follows.The bilinear terms of constraints (13) represent the greatest difficulty of the NLP formulation. Thus, we apply a standard linearization technique by replacing those terms with additional variables (w). Unfortunately, by relaxing the nonlinear constraints, we lose the integrality properties described in Theorems 1 and 2. Hence, the resulting formulation is a mixed integer linear program (MIP). On top of that, this reformulation comes with an overhead ofO(n2m2)variables and constraints. The proposed reformulation follows:(16)(MIP):min∑i=1m∑j=1m∑s=1n∑{t=1,…,n:s<t}cijstxijst(17)s.t.(9)–(12)(18)wijst⩽zjt,∀i,j=1,…,ms,t=1,…,n(19)wijst⩽xijst,∀i,j=1,…,ms,t=1,…,n(20)wijst⩾zjt+xijst-1,∀i,j=1,…,ms,t=1,…,n(21)zis+∑j=1m∑t=1nwijst=1,∀i=1,…,ms=1,…,n(22)wijst∈[0,1],∀i=1,…,ms=1,…,n(23)xijst∈[0,1],∀i=1,…,ms=1,…,n(24)zis∈{0,1},∀i=1,…,ms=1,…,n,where variablewijstrepresents the bilinear termxijstzjt, for all(i,s,j,t)∈E, and constraints 18, are the linearization inequalities. Note that, contrary to the case of thexvariables,wijst=xijstzjt≠xijstzis=wjits. Thus, both variableswijstandwjitsmust be included. Finally, using a similar argument as in Theorem 2, it is easy to see that in the above formulation we can relax the integrality constraints of variablesxandw.In this subsection, we introduce five families of valid inequalities that strengthen the MIP formulation. Since we no longer have the nonlinear set of constraints (13), it is possible (and likely) that the linear relaxation of this formulation produces fractional solutions (i.e., gray nodes). To cope with this issue, we can use the results from Lemmata 1 and 2 to define the following inequalities.Proposition 1For any edge(i,s,j,t)∈E, the inequalityxijst⩽2-zis-zjtis valid.From constraints (13), for nodes(i,s)and(j,t), we obtainzis+xijstzjt⩽1andzjt+xijstzis⩽1.Adding both inequalities yields(25)2⩾zis+zjt+xijst(zis+zjt).Furthermore, sincexijst∈[0,1]andzis∈[0,1], we have thatxijstzis⩾xijst+zis-1andxijstzjt⩾xijst+zjt-1.Adding up both inequalities, results in(26)xijstzis+zjt⩾2xijst+zis+zjt-2.Finally, from (25) and (26), we obtain(27)xijst⩽2-zis-zjt.□Inequality (27) comes from the fact that in any feasible solution of the MIP there are no connections between black nodes (star centers). Clearly, if both variableszisandzjttake the value of one, the corresponding variablexijstcannot be positive.Proposition 2For any edge(i,s,j,t)∈E, the inequalityxijst⩽zis+zjtis valid.From Lemma 1, the proposed inequality:(28)xijst⩽zis+zjtis trivially derived. □Similarly as before (cf. Proposition 1), in any feasible solution of the MIP there are no connections between white nodes (leafs). Thus, if both variableszisandzjtare zero, the corresponding variablexijstmust also be zero.There are two interesting features of inequalities (27) and (28). First, the size of both families isO(n2m2), which implies that both can be directly included in the MIP without the need of a separation algorithm. Second, as proved in Theorem 3, if constraints (27) and (28) are included in formulation (16)–(24), it is possible to relax constraints (21), and therefore remove the extrawvariables. The resulting formulation, referred to as MIPa, not only has less variables and constraints than MIP, but also produces a better dual bound.(29)(MIPa):min∑i=1m∑j=1m∑s=1n∑{t=1,…,n:s<t}cijstxijst(30)s.t.(9)–(12)(31)xijst⩽zis+zjt,∀i,j=1,…,ms,t=1,…,n(32)xijst⩽2-zis-zjt,∀i,j=1,…,ms,t=1,…,n(33)zis∈{0,1},∀i=1,…,ms=1,…,n(34)xijst∈{0,1},∀i=1,…,ms=1,…,n.Theorem 3MIPa is a valid formulation for the MSAP.Since MIPa includes constraints (9)–(12), it suffices to show that any optimal solution of this formulation satisfies that, (1) there are no gray nodes (i.e.,zis∈{0,1},∀(i,s)∈N) and (2) the only connections that can exist are between white and black nodes.Clearly, MIPa contains the integrality constraints for thezvariables. Thus, no gray nodes would exist. Furthermore, observe that constraints (31) guarantee that no connection exists between white nodes. Hence, white nodes can only be connected to black ones. Similarly, constraints (32) guarantee that no connection exists between two black nodes, hence black nodes can only be connected to white ones.□We now describe three additional families of valid inequalities.Proposition 3For any node(i,s)∈N, the inequality(35)zis+∑j=1m∑t=1nqijst⩾1,whereqijst∈{xijst,zjt}is valid.From nonlinear constraints (13), it is easy to see that any integral solution of MIPa satisfies the following equation:zis+∑j=1m∑t=1nmin{xijst,zjt}=1.Since by definition,qijst⩾min{xijst,zjt}, all integral feasible solutions satisfy the proposed inequality.□We refer to this family as the minimum sum inequalities. Note that, for each node(i,s), the number of inequalities of this family isO(2mn). Thus, we propose the separation procedure presented in Algorithm 1. Given a fractional solution(z¯,x¯), for each node(i,s), we search for the inequality that is violated the most. For this purpose, for each(j,t)such that(i,s,j,t)∈E, we select asqijstin (35) the variable associated with the minimum value betweenz¯jtandx¯ijst. We repeat this procedure for all(i,s)∈N, adding all violated inequalities.Algorithm 1minSumSeparation(G,i,s,z¯,x¯)1:sum=z¯is2:cut=zis3: for all(j,t)such that(i,s,j,t)∈Edo4:ifz¯jt<x¯ijstthen5:sum←sum+z¯jt6:cut←cut+zjt7:else8:sum←sum+x¯ijst9:cut←cut+xijst10:end if11: end for12: ifsum<1then13:returncut⩾114: else15:returnnull16: end ifFor the last two families of valid inequalities, consider the fractional solution depicted in Fig. 5. This is an optimal solution of the linear relaxation of MIPa. First, observe the 4-cycle formed by nodes(2,1),(1,3),(1,4),(2,2). Clearly, in a feasible integral solution the number of arcs within the cycle cannot be greater than two. We analyze this inequality in Proposition 4.Proposition 4For any 4-cycle involving nodes(i,s),(j,t),(k,u), and(l,v),xijst+xjktu+xkluv+xilsv⩽2is a valid inequality.Assume that there is an integral solution wherexijst+xjktu+xkluv+xilsv>2. Hence, there exist at least three arcs in the 4-cycle for which the respectivexvariables are one. In turn, this implies that at least two nodes have two connections each. From (9), it can be deduced that these two nodes need to be black (since they have more than one connection). Hence, all the possible node configurations can be summarized with the two cases, shown in Fig. 6. The cases that are not included in this figure correspond to mirrored versions of the ones that are presented.Case 1 can be dismissed because a white node is connected to two black nodes, contradicting (9). Similarly, case 2 cannot happen because it contradicts the fact that two black nodes can never be connected (see Proposition 2).□We refer to this family as the 4-cycle inequalities. Since the number of inequalities of this family isO(m4n4), we can find all violations by total enumeration.Finally, observe the triplet formed by nodes(1,3),(2,1), and(2,2)in Fig. 5. It is easy to see that all three nodes cannot be black and simultaneously have any connection between them. We analyze this inequality in Proposition 5.Proposition 5For any triplet of nodes(i,s),(j,t),(k,u), where node(i,s)is the center of the triplet,xijst+xiksu+zis+zjt+zku⩽3is a valid inequality.Since there cannot be any connection between two black nodes or two white nodes, it is easy to see that the only feasible options can be summarized by the ones depicted in Fig. 7. As before, we do not include mirrored configurations, or the cases where the inequality is trivially satisfied (e.g., the case where all the nodes are white and there are no connections between them). Note that in all this cases, if we sum up the correspondingzvariables of all three nodes, and thexof the arcs connecting the center with the leafs, the resulting summation is always less or equal than three.□We described the above inequality for the case where node(i,s)is the center of the triplet. Although, note that it is possible to obtain two alternative inequalities by choosing any of the other two nodes as the center. We refer to this family as the triplet inequalities and, since the total number of possible triplets isO(n3m3), we can find violations by total enumeration. Finally, note that this family of inequalities can be easily generalized for k-tuples, wherek>3. However, in practice they are less effective and harder to evaluate, as the total number of k-tuples ifO(nkmk).From formulation (1)–(5), it is easy to see that the MSAP is a particular case of the set partitioning problem, and thus can be formulated as such. The set up of this formulation is as follows. Let K be the set of all feasible stars that can be used to partitionG. For each stark∈K, letaiskbe a parameter that takes the value of one if star k covers node(i,s)and zero, otherwise. Letykbe a binary variable that takes the value of one if star k is selected and zero, otherwise. Further, letϕ(k)be a function that returns the center of star k, and finally, letckbe the cost of star k. That is, assuming thatϕ(k)=(i,s), the cost of star k is given by,(36)ck=∑j=1m∑{t=1,…,n:t≠s}cijstajtk.Then, the resulting set partitioning (SP) formulation can be defined as follows:(37)(SP):min∑k∈Kckyk(38)s.t.∑k∈Kaiskyk=1,∀i=1,…,ms=1,…,n(39)yk∈{0,1},∀k∈K.Note that constraint set (38) is created by aggregating all constraints in (1)–(5). Hence, both formulations are equivalent. The advantage of the SP over MIPa is the fact that the star configuration, required by any feasible solution of the MSAP, is implicitly guaranteed by the definition of set K. In other words, since all the elements in K are valid stars, the remaining decision is finding the right partition. However, the downside is that|K|grows exponentially as the size ofGincreases (see Proposition 6). For this reason, (37)–(39), has far more variables than can be reasonably handled and therefore solving it explicitly can be computationally impractical.Proposition 6The total number of feasible stars isnmn.To be a feasible star, its center must be connected to exactly one node from each of the othern-1sets. Since there are m nodes in each set, the total possible stars centered at any given node ismn-1. Furthermore, since the total number of nodes is nm and each of them can be the center of a star, the total number of stars isnmn.□To overcome this difficulty, we solve the problem via branch and price (Barnhart et al., 1998; Lübbecke & Desrosiers, 2005). That is, at each node of the branch-and-bound tree, we solve a linear relaxation of SP, defined over a manageable subset of starsK′⊂K. We refer to this formulation as the restricted master problem (RMP). If the current set of starsK′is not sufficient to declare optimality, we proceed to generate additional stars via column generation. Furthermore, if the optimal solution at the end of the column generation phase is not integral, we branch to reduce the solution space, eliminating undesired fractional solutions. The RMP is as follows:(40)(RMP):min∑k∈K′ckyk(41)s.t.∑k∈K′aiskyk=1,∀i=1,…,ms=1,…,n(42)0⩽yk⩽1,∀k∈K′,Before starting the column generation phase, we require to construct an initial set of starsK′for which RMP is feasible. There are different options for constructing this set. One can, for example, use a typical initialization method such as the two-phase or the penalization methods (see Bazaraa, Jarvis, & Sherali, 2009). Alternatively, we can initializeK′with any feasible solution produced heuristically. This is in general a preferred option because a good initial solution provides RMP with a high quality upper bound, which in turn may help prune some unnecessary branches in the branch-and-bound tree. To find the initial setK′, we propose a very simple greedy algorithm that generates iteratively a set of valid stars. For this purpose, we define a feasible star p to be a minimum cost star ofG, ifcp⩽ck, for allk∈K. Assume we begin the algorithm with an empty setK′. Then, we sequentially add toK′a minimum cost star of graphG⧹K′. We repeat this process until all the nodes are covered. A full description of this heuristic is presented in Algorithms 2–4.Algorithm 2minCenteredStar(G,m,n,i,s)1:S←{(i,s)}2:cost←03: for allt=1,…,n, wheret≠sdo4:l∈argminj=1,…,m{cijst}5:S←S∪{(l,t)}6:cost←cost+cilst7: end for8: return[S,cost]minStar(G,m,n)1:S∗←∅2:cost∗←∞3: for alls=1,…,ndo4:for alli=1,…,mdo5:[S,cost]←minCenteredStar(G,m,n,i,s)6:ifcost<cost∗then7:cost∗←cost8:S∗←S9:end if10:end for11: end for12: return[S∗,cost∗]findInitialSet(G)1:K′←∅2:G′←G3:cost∗=04:m′=m5: whileG′≠∅do6:[S,cost]=minStar(G′,m′,n)7:K′←S8:cost∗←cost∗+cost9:G′←G′⧹S10:m′=m′-111: end whileWe now prove that the proposed heuristic produces a feasible solution inO(m3n2). We first derive the complexity of identifying a minimum cost star of a given graphGand then, we prove the correctness and provide the overall complexity.Lemma 4Given a graphG, finding a minimum cost star takesO(m2n2).First, assume we know a priori the center of the minimum cost star. Let(i,s)be that node. Since the center must be connected to exactly one node from each setNt∈N⧹Ns, we obtain the minimum cost star by finding a node(j¯,t)such thatj¯∈argminj=1,…,m{cijst}, from each of the remainingn-1sets. Furthermore, each set has in total m nodes. Thus, finding the minimum cost star centered at(i,s)takesO(nm)(see Algorithm 2).Now, observe that since there are nm nodes inG, we can repeat the same process for each node, selecting the overall minimum cost star inO(m2n2)(see Algorithm 3).□Given a graphG, the proposed heuristic finds a feasible set K′ inO(m3n2).We initialize Algorithm 4 with a graphG′=G. First, note that at each iteration of the while loop (steps 5–11), we generate a valid star composed of exactly one node from each setN1,…,Nn. Since we remove fromG′the nodes of such star, we guarantee that those nodes are not covered by other stars in further iterations. Moreover, at each iteration, the number of nodes inG′decreases by n. In view ofG′having initially mn nodes, by iteration m all the nodes must be covered by one star. Finally, finding the minimum cost star takesO(m2n2). Thus, generatingK′takesO(m3n2). □Naturally, there are additional elements that can be used for improving the running time of Algorithm 4 and obtaining additional stars to add inK′. For example, after each run of Algorithm 2, we can temporarily store the minimum cost star centered at each node(i,s)∈G. Then, in further iterations we can warm start the algorithm initializing the search with those stars. Moreover, noting that each of these minimum cost stars is a member of K, we can include some of them in the initial setK′. However, since we would like to avoid having a large initial set of columns, or worse including poor candidates, in practice we impose a limit on the size of the initial setK′. Thus, besides adding the solution found by Algorithm 4, we keep an ordered set of the bestαmgenerated stars and include those inK′. We have tested different values forα, beingα={2,3,4}the ones that produced the best results. We only use this limit when generating the initial set of columns. Once in the column generation stage, we relax this limit.While solving RMP, it is possible (and in general common) that the initial set of starsK′does not include an optimal partition ofG. Moreover, it is also possible that we cannot even find an optimal solution of the linear relaxation, using the stars inK′. This is not a particular issue of the MSAP as it happens often with most problems that are solved using set partitioning formulations (Barnhart et al., 1998).To find the optimal solution of the linear relaxation, we use a column generation approach that introduces new stars toK′in case they are needed to declare optimality. Hence, at each iteration, we are required to find whether there exists a new stark∈K⧹K′, that improves the current solution. In other words, we aim to find a variableyk, fork∈K⧹K′, such that its reduced cost is negative, or, from the dual perspective, a variable such that its corresponding dual constraint is violated.Consider the dual of the RMP, defined as the relaxed dual problem RDP.(43)(RDP):max∑i=1m∑s=1nαis(44)s.t.∑i=1m∑s=1naiskαis⩽ck,∀k∈K′Notice that (44) includes only the constraints associated with the stars inK′. This implies that, if we find a stark∈K⧹K′, such that its corresponding constraint (44) is violated by the current solution, i.e., a star k for whichck-∑i=1m∑s=1naiskαis<0, we can include such star inK′. In consequence, the optimality conditions of the column generation stage can be defined as follows.(45)ck-∑j=1m∑t=1najtkαjt⩾0,∀k∈K⧹K′,or, alternatively, from (36),(46)∑j=1m∑{t=1,…,n:t≠s}cijstajtk-∑j=1m∑t=1najtkαjt=∑j=1m∑{t=1,…,n:t≠s}cijstajtk-αis-∑j=1m∑{t=1,…,n:t≠s}ajtkαjt=-αis+∑j=1m∑{t=1,…,n:t≠s}(cijst-αjt)ajtk⩾0,(i,s)=ϕ(k),∀k∈K⧹K′.To identify promising stars, we propose a similar approach to the one used to obtain the initial setK′. We first fix the center of the star at node(i,s)and then, search for stars that violate condition (46). We repeat the same process for each node(i,s)∈G. Thus, given a center node(i,s), the proposed pricing subproblem (P(i,s)) is as follows:(47)(P(i,s)):-αis+min∑j=1m∑{t=1,…,n:t≠s}(cijst-αjt)ajt(48)s.t.∑j=1majt=1,∀t=1,…,n,t≠s(49)ajt∈{0,1},∀j=1,…,m,t=1,…,n,t≠swhere the objective function (47) minimizes the reduced cost of the star, constraints (48) guarantee that the center node(i,s)is connected with a node in each layert≠s, and constraints (49) define the domain of the variables.Then, we solve a problemP(i,s)for each node(i,s)∈G, finding new candidate stars (possibly many) at each iteration. Note that, if for all nodes(i,s)∈G,-αis+min∑j=1m∑t=1,t≠sn(cijst-αjt)ajt⩾0, we have an optimal solution for the RMP.In principle, instead of solving a sequence of mnP(i,s)subproblems, we could adapt Algorithm 3 to obtain the same result inO(m2n2). This approach will indeed work for solving the root node of the branch-and-bound tree. However, if the solution of the linear relaxation is not integral, we must proceed with the branching stage to eliminate fractional solutions. Then, the branching decisions must be enforced in the subproblem in the form of constraints to prevent generating stars that violate them. Because of these additional constraints, we cannot solely apply Algorithm 3. On the other hand,P(i,s)can be easily updated to include the branching constraints. Nonetheless, solving sequentially mn of such integer programs, after including the branching constraints, could potentially hinder the column generation procedure. To circumvent this issue we will show that it is possible to reformulateP(i,s)as a shortest path problem with side constraints. Before describing the proposed reformulation, we first introduce the branching rule.One of the major difficulties that arise when solving a problem via branch and price is defining the branching rule. There are many reasons why standard branching (i.e., fixing a fractional variable to either zero or one) is undesirable in this context. First of all, when fixing a variable to one, the n nodes of the star corresponding to such a variable are covered. Since those nodes cannot be covered again, all the other stars in K containing at least one of those nodes are discarded (i.e., the corresponding variables are fixed to zero). Hence, the number of variables to be considered in that branch is significantly reduced. On the other hand, when a variable is fixed to zero, only one of exponentially many variables is fixed. This particular behavior results in a highly unbalanced, and thus inefficient, branching tree. Furthermore, when fixing a variable to zero, we must ensure that the pricing subproblem does not produce the same variable again. This is generally done by either finding the next best solution (possibly the nth best after n branches), or by including additional constraints in the subproblem. In both cases, solving the pricing problem becomes remarkably harder.An alternative option, that is widely used when solving set partitioning problems, is the so-called Ryan-Foster branching rule (Barnhart et al., 1998; Ryan & Foster, 1981). Consider a fractional solution of the RMP. From constraints (41), it is easy to see that if a solution is fractional, there exists a node that is partially covered by at least two stars. Letykandylbe two fractional variables (i.e.,yk,yl∈(0,1)) such that the corresponding stars share node(i,s). Clearly, since stars k and l are different, there exists a node(j,t)≠(i,s)that is either covered by k and not by l, or vice versa. Thus, we can generate a branch in which we force both nodes(i,s)and(j,t)to be covered by the same star, and a second one that ensures that the nodes are covered by different stars. It is easy to see that the current fractional solution is no longer valid, while any feasible integer solution belongs to one of the two branches.Once we generate the new branches, we need to enforce the respective branching decisions in the subsequent iterations. Instead of sequentially adding such constraints to the RMP, we can alternatively propagate them over setK′. For the branch that requires both nodes to be in different stars, we fix to 0 all the variables of the stars that cover both nodes simultaneously. Conversely, we fix to 0 all the variables of the stars that cover only one of these nodes, for the branch that requires both nodes to be together. Moreover, we must ensure that the pricing problem also satisfies the branching constraints. If we use formulationP(i,s)as the pricing problem, these constraints are easily enforced as follows. Assume that(i,s)and(j,t)are the nodes of the current branching decision. If the subproblem we are solving isP(i,s), we fixajtto be either one or zero for the cases where both nodes are required to be together or separated, respectively. ForP(j,t), the process is similar but fixingaisinstead. If we are solving the subproblem for other nodes different than(i,s)or(j,t), we introduce constraintsais=ajtorais+ajt⩽1in each of the branches, respectively.In general, the quality of any column generation approach relies on the ability to generate new candidate variables in an efficient way. This is because the subproblem, that either declares optimality or generates new variables, may be solved a considerable number of times before terminating. Despite the fact that solving the subproblem via integer programming is sufficient for tackling small instances, in practice, the use of specialized algorithms is proven to yield better results (Feillet, Dejax, Gendreau, & Gueguen, 2004). Furthermore, when possible, it is often desired to transform the subproblem into a shortest path problem because of the variety of different solution techniques that can be used to efficiently solve this kind of problems (Feillet et al., 2004; Irnich & Desaulniers, 2005; Valério de Carvalho, 1999).For this reason, as an alternative to solvingP(i,s)using integer programming techniques, we propose reformulating it as a shortest path problem over a directed acyclic networkH(i,s)=(N′,A). The set up for this network is as follows. First, we introduce two nodes(i,s‾)and(i,s̲)referred to as the source and sink nodes, respectively. There is a set of nodes,N‾, composed of one node associated with each setN1,…,Ns-1,Ns+1,…,Nn-1(i.e.,N‾={1,…,s-1,s+1,…,n-1}). The node set is defined asN′={(i,s‾),(i,s̲)}∪N‾∪N⧹Ns, and the arc setAis constructed as follows. First, ifs=1, then there is an arc between the source node(i,s‾)and node(j,2), for allj=1,…,m. Otherwise, ifs>1, there is an arc between the source node(i,s‾)and node(j,1), for allj=1,…,m. Second, there is an arc between nodes(j,t)and t, for allj=1,…,m, such thatt∈N‾. Third, there is an arc between nodes t and(j,t+1), such that1<t<s-1; an arc between nodess-1and(j,s+1); and an arc between nodes t and(j,t+1), such thats<t<n, for allj=1,…,m. Finally, ifs<n, there is an arc between node(j,n)and the sink node(i,s̲), for allj=1,…,m. Conversely, ifs=n, there is an arc between node(j,n-1)and the sink node(i,s̲), for allj=1,…,m.The cost of using the arc between nodes(i,s‾)and(j,t)is(cijst-αjt), forj=1,…,mandt={1,2}, depending on the value of s. Further, the cost between nodes(j,t)and t is zero, and the cost between nodes t and(j,u)is(cijsu-αju), for allj=1,…,mandu=s+1, ift=s-1, oru=t+1, otherwise. Finally, the cost of using the arc between nodes(j,t)and(i,s̲)is zero, forj=1,…,mandt={n-1,n}, also depending on the value of s. A graphical representation ofH(i,s)is presented in Fig. 8a.Note that the costs of the arcs do not depend on the nodes they emanate from. This is because such arcs represent the connection between(i,s)and the node at the head of the corresponding arc. Moreover, it is easy to see that each path from the source to the sink inH(i,s)can be associated with a star centered at(i,s). For instance, the path formed by the gray nodes in Fig. 8b can be associated with the valid star shown in Fig. 8c. Thus, if we subtractαisfrom the cost of the shortest path between the source and sink nodes inH(i,s), we obtain the minimum reduced cost of the variable associated with the star that corresponds to the shortest path.In the absence of branching constraints, sinceH(i,s)is acyclic and the number of arcs isO(mn), finding a shortest path can be done inO(mn)(Ahuja, Magnanti, & Orlin, 1993). Thus, similarly as in Algorithm 3, solving the problem for all the nodes takesO(m2n2). On the other hand, once the branching stage begins, finding the corresponding shortest path becomes a more difficult task. The advantage of the proposed representation is that we can include the additional branching constraints and solve the resulting shortest path with side constraints via Dynamic Programming (Irnich & Desaulniers, 2005). In Appendix B we provide a brief description of the algorithms that we used to calculate the candidate stars.After solving all theP(i,s)subproblems for all nodes(i,s)∈N, it is possible to obtain several candidate stars with the same set of nodes, but with different centers. For instance, for the network depicted in Fig. 8c, assume that after solvingP(2,3)we obtain the star described in the figure, and when solvingP(1,4)we obtain a star with the same set of nodes but centered at(1,4). Clearly, from the definition of the star costs presented in (7), among those stars, we should only consider the one with the minimum cost. Thus, while solving the subproblems, we create a hash map that, in case more than one star is generated with the same set of nodes, keeps only the one with the minimum cost.Finally, it is well known that the SP formulation is highly degenerate. Note for example that for the MSAP case, SP has in total mn constraints (without including the bounds on the variables), whereas any feasible integer solution would only have m nonzero variables. Primal degeneracy is well known to cause slow convergence (Lübbecke & Desrosiers, 2005). One of the principal causes of this behavior is the instability of the dual variables. Unfortunately, they do not smoothly converge to their respective optima, as they constantly oscillate without a regular pattern. Since the columns generated depend on the dual variable values, effects on the quality of solutions and on the running time pose an important issue that must be considered.Several methods have been proposed to overcome this issue (Agarwal, Mathur, & Salkin, 1989; Marsten, Hogan, & Blankenship, 1975; Rousseau, Gendreau, & Feillet, 2007). Besides applying such methods, it is also known that when using an interior point method to solve the RMP, the dual solutions that are produced are often more balanced (Bixby, Gregory, Lustig, Marsten, & Shanno, 1992), leading to a better performance. We are aware though, that stabilization strategies generally outperform this option. However, for the purpose of this paper, the combination of an interior point method and the fact that we often include several star candidates (possibly one for everyP(i,s)), proves to be sufficient.To analyze the performance of the different formulations, we created a test bed of 37 problem sets, ranging n from 3 to 20 and m from 4 to 30. We refer to each set as nDm. Moreover, every set is comprises 20 random instances generated using the method described in (Grundel & Pardalos, 2005), which was designed to produce difficult MAP instances. The full set of instances (37×20=740in total) can be found in http://www.caopt.com/instances/MAP.The computational experiments were performed on a server with two AMD Opteron 6128 Eight-Core CPUs and 12gigabytes of RAM, running Linux x86_64, CentOS 5.9. Formulations MIP and MIPa were implemented in C++ and solved using CPLEX 12.3, while the branch-and-price framework for the SP was coded in C and solved using SCIP (Berthold et al., 2012).In our experiments we compare the performance of formulationsSP,MIP, and MIPa without the minimum sum, 4-cycle, and triplet cuts, as well as the MIPa including the cuts at (1) the root node (MIPa-R), and (2) all nodes of the branch-and-bound tree (MIPa-A). For all the approaches, we imposed a time limit of 7200seconds.Table 1reports the average computational time for all the problem sets, where the fastest times are presented in bold. In parentheses we include (1) the average optimality gap of the instances that were not solved by the time limit and (2) the number of instances that were not solved to optimality, if any. The gap was calculated as (Primal bound-Dual bound)/Primal bound. Table 2compares the average number of nodes of the branch-and-bound tree, while also presenting the average number of inequalities that were produced for each of the three families of cuts. The average number of cuts generated at the root node is given in parentheses. For the sake of simplicity, these values were rounded up to the next integer.First of all, examining Table 1 we can easily observe that MIP is generally outperformed. This is reasonable, since the overhead of adding the linearization variables renders it very slow. We can also observe that SP is very fast in the instances where n is small. However, as it increases, SP becomes significantly slower than the MIPa, with and without the cuts. Furthermore, in the smaller instances, the cut families introduced are not as effective, which is to be expected. Hence, the solution times ofMIPa,MIPa-R, and MIPa-A are comparable. On the other hand, in larger instances, the effect of the cuts becomes visible, rendering MIPa-R a clear winner.Note that, because of the complexity of the separation algorithms, MIPa-R is faster than MIPa-A. Nonetheless, as it can be seen in Table 2, the branch-and-bound tree for MIPa-A is remarkably smaller than MIPa-R, which in turn is smaller than MIPa. Finally, we report the number of cutting planes introduced at each problem set. Observe that all families of inequalities are used, being the minimum sum cuts the ones that appear more often.Finally, Table 3reports additional statistics about the performance of formulation SP, including the average number of nodes of the branch-and-price tree, the number of times the subproblem (i.e., the star generation algorithm) was executed, the number of candidate stars produced, and the average total time spent solving the subproblem. For the sake of simplicity, with the exception of the execution times, the values were rounded up to the next integer.As can be seen in Table 3, the execution time of the subproblem is in average about70%of the total running time of the algorithm. This is expected because each of the subproblem calls corresponds to solving a total of mn shortest path problems with side constraints. For this reason, the time required to solve the RMP compared to the one needed to generate the new candidate stars is almost negligible. Moreover, this percentage is even higher (≈95%) for the instances that where not solved to optimality. This is not only because those are the problems with lager sizes, but also because the corresponding branch-and-bound trees have more nodes and therefore, more side constraints are introduced to the shortest path problems. It is also interesting to note that the average execution time of each of the individual mn subproblems is very short. For example, consider the execution time of the 20D5 instances. The average time that takes evaluating each of the shortest paths is6625.83/(6556×20×5)=0.01seconds.In this paper, we presented a reformulation of the MAP with decomposable costs, where each of the assignments is assumed to be a star. We proposed a continuous nonlinear formulation for the problem, and its linearization into a mixed integer program. In addition to that, we proposed a series of valid inequalities to strengthen the formulation. Last, we also implemented a branch-and-price framework to solve a set partitioning reformulation of the problem. All the approaches were compared, and the families of cuts introduced proved to be very efficient at tackling large-scale instances.Our work stemmed from the multi-sensor multi-target tracking problem, for which the MAP is widely used. We show that our approach is also a viable option for solving these problems. An advantage of this formulation is the fact that the center of every star plays the important role of a representative measurement. Further, the effect of noisy sensors is alleviated, compared to employing the MAP formulation.As far as future work is concerned, as seen in the computational results, the number of minimum sum cuts produced is very high, even though they are effective. A method to smartly choose the best of these cuts would result in a smaller model size, which could prove beneficial. Moreover, especially in large-scale instances, a decomposition scheme could be used in order to reduce the size of every subproblem, making it manageable in time. More specifically, Benders’ decomposition, along with graph partitioning schemes, might be of interest.Last, scientific interest has turned recently to the need for a decentralized algorithm for solving multi-sensor multi-target tracking problems. In this setting, every sensor decides on-the-fly which other sensors it is paired with. Such extensions would involve game theoretic approaches, as in (Marden & Shamma, 2007), or swarm optimization (Özbakir, Baykasogˇlu, & Tapkan, 2010). Another extension could focus on further investigating different potential MAP relaxations, such as the detection of disjoint trees, or quasicliques.

@&#CONCLUSIONS@&#
