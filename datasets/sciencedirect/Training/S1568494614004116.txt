@&#MAIN-TITLE@&#
Critical evaluation of non-linear filter configurations for the state estimation of Continuous Stirred Tank Reactor

@&#HIGHLIGHTS@&#
Developed discrete state space model of CSTR.Implemented three non-linear filters to estimate concentration and temperature.Performance of the three filters is analyzed under various operating conditions.

@&#KEYPHRASES@&#
EKF,UKF,Neural Observer,State estimation,Concentration,Temperature,

@&#ABSTRACT@&#
A systematic approach has been attempted to design a non-linear observer to estimate the states of a non-linear system. The neural network based state filtering algorithm proposed by A.G. Parlos et al. has been used to estimate the state variables, concentration and temperature in the Continuous Stirred Tank Reactor (CSTR) process. (CSTR) is a typical chemical reactor system with complex nonlinear dynamics characteristics. The variables which characterize the quality of the final product in CSTR are often difficult to measure in real-time and cannot be directly measured using the feedback configuration. In this work, the comparison of the performances of an extended Kalman filter (EKF), unscented Kalman filter (UKF) and neural network (NN) based state filter for CSTR that rely solely on concentration estimation of CSTR via measured reactor temperature has been done. The performances of these three filters are analyzed in simulation with Gaussian noise source under various operating conditions and model uncertainties.

@&#INTRODUCTION@&#
On line estimates of state variables have been considered necessary in diverse applications such as process and controller performance monitoring and state feedback control [13]. State observer can designed to generate an estimate of the state by making use of the relevant process inputs, outputs and mathematical model of the system. The well-known Kalman filter [1] solves the general state estimation problem in stochastic linear system. For linear systems, Kalman filter generate optimal estimates of state from observations. In addition, Kalman filter has become more useful even for very complicated real-time applications and has attracted the attention of chemical engineering community because of recursive nature of its computational scheme. However, for non-linear systems, extended Kalman filter is a natural extension of the linear theory to the non-linear domain through local linearization. There are several variants of the basic EKF, which have been evaluated by various researchers [2]. Many studies in observer design for nonlinear system are based on extended Kalman filter approach, which leads to complex nonlinear algorithm. In spite of good results, there is no a priori guarantee of the convergence and stability of the algorithms. Simon J. Julier proposed an unscented Kalman filter (UKF) [3] for the nonlinear dynamic system. Its use for the state estimation of Continuous Stirred Tank Reactor has been reported in some literatures [4,5,14]. Unlike EKF, it utilizes unscented transform which is a deterministic sampling approach to calculate the current mean and covariance of states and hence called derivative free filter [9,10]. However, the UKF algorithm is more computationally intensive [8] than EKF. A.G. Parlos has proposed a non-adaptive state filtering algorithm for the non-liner dynamic system using neural network. The algorithm presented by the A.G. Parlos et al. is based on the two-step prediction–update approach of the Kalman filter [3]. The use of neural network for state and parameter estimation of CSTR has been well studied [4,5,12]. Structure of the Neural Observer considered in this work differs from EKF in the sense that the function form of state update equation is allowed to be nonlinear and constructed as a neural network, whereas in EKF update state estimate is a linear combination of predicted state estimates and the weighted difference between the actual measurement and the measurement prediction. The main contributions of this work is to implement EKF, UKF and Neural Observer algorithms for the state estimation of Continuous Stirred Tank Reactor and comparative study of the performances under different conditions based on the performance index Mean Square Error (MSE).The first principle model of the continuous stirred tank system and the operating point data [5] (refer Table 1) as specified in the Pottman and Seborg paper have been used in the simulation studies [6]. Highly nonlinear CSTR process is very common in chemical and petrochemical plants. In the process considered for simulation study as shown in Fig. 1, an irreversible, exothermic reaction A→B occurs in constant volume reactor that is cooled by a single coolant stream.The CSTR system has two state variables, namely the temperature and the concentration of the reactor. The process is modeled by the following equations:(1)dCAdt=FV(CAf−CA)−k0CAexp−ERT(2)dTdt=FV(Tf−T)−−ΔHρCpk0exp−ERTCA+ρCpcρCpVqc1−exp−hAρCpqc(Tco−T)Figs. 3 and 4show the open loop responses of temperature and concentration of the CSTR for the coolant flow rate variation as shown in Fig. 2. So, it can be concluded that the dynamic behavior of the CSTR process is not the same at different operating points and the process is indeed non-linear.The well-known Kalman filter [1] solves the state estimation problem in a stochastic linear system. The extended Kalman filter (EKF) is probably the most widely used nonlinear filter. For nonlinear problems, the Kalman Filter is not strictly applicable since linearity plays an important role in its derivation and performance as an optimal filter. The EKF attempts to overcome this difficulty by using a linearized approximation where the linearization is performed about the current state estimate. The basic framework for the EKF involves the estimation of the state of a nonlinear dynamic system given by Eqs. (1) and (2).(3)x(k)=x(k−1)+∫tk−1tkF[x(τ),u(k)dτ]+w(k)(4)y(k)=H[x(k)]+v(k)In the above equations, x(k) represents the unobserved state of the system, u(k) is a known exogenous input and y(k) is the only observed signal. We have assumed w(k) and v(k) as zero mean Gaussian white noise sequences with covariance matrices Q and R respectively. The symbols F and H represent an n-dimensional function vector and are assumed known. EKF involves the recursive estimation of the mean and covariance of the state under maximum likelihood condition. The function F can be used to compute the predicted state from the previous estimate and similarly the function H can be used to compute the predicted measurement from the predicted state. However, F and H cannot be applied to the covariance directly. Instead a matrix of partial derivatives (Jacobian) is computed at each time step with current predicted state and evaluated. This process essentially linearizes the non-linear function around the current estimate. The predicted state estimates are obtained as(5)xˆ(k|k−1)=xˆ(k−1|k−1)+∫tk−1tkF[x(τ),u(k)dτ]The covariance matrix of estimation errors in the predicted estimates is obtained as(6)P(k|k−1)=ϕ(k)P(k−1|k−1)ϕ(k)T+Qwhere ϕ(k) is the Jacobian matrix of partial derivatives of F with respect toA¯(7)ϕ(k)=∂F∂x[xˆ(k−1|k−1),u(k−1)]Note that the EKF computes covariances using the linear propagation. The measurement prediction, computation of innovation and covariance matrix of innovation are as follows(8)yˆ(k|k−1)=H[xˆ(k|k−1)](9)γ(k|k−1)=y(k)−yˆ(k|k−1)(10)V(k)=C(k)P(k|k−1)C(k)T+Rwhere c(k) is the Jacobian matrix of partial derivatives of H with respect to x.(11)C(k)=dH∂x[xˆ(k−1),u(k−1)]The Kalman gain is computed using the following equation(12)K(k)=P(k|k−1)C(k)TV−1(k)The updated state estimates are obtained using the following equation(13)xˆ(k|k)=xˆ(k|k−1)+K(k)γ(K|k−1)The covariance matrix of estimation errors in the updated state estimates is obtained as(14)P(k|k)=[1−K(k)C(k)]P(k|k−1)The sigma points are not drawn at random, but they are deterministically chosen. As a result, high-order information about the distribution can be captured with a fixed and small number of points. UKF filter uses the unscented transform [3] to pick a minimal set of sample points (called sigma points) around the mean. These sigma points are then propagated through the nonlinear functions and the covariance of the estimate is then determined. The result is a filter which more accurately captures the true mean and covariance [7]. A set of 2L+1 sigma points, x(k|k,i) with the associated weights W(i) are chosen symmetrically about as given below(15)Xi=x¯(16)Xi=x¯+((L+λ)Px)iwhere i=1,…, L.(17)Xi=x¯+((L+λ)Px)where i=L+1,…, 2L.The weights for the state and covariance are as follows(18)W0(m)=λL+λ(19)W0(c)=λL+λ+(1−α2+β)(20)W0(c)=λL+λ+(1−α2+β)where i=1,…, 2L.x(L+λ)Pxiwhere λ=α2(L+K)−L is a scaling parameter. α determines the spread of the sigma points around mean and is usually set to a small positive value. K is a secondary scaling parameter which is usually set to 0 and β is used to incorporate prior knowledge of the distribution of A set of 2L+1 sigma points is derived from the augmented state and covariance where L is the dimension of the augmented state.The sigma points are propagated through the transition function f.(21)Xk−1|k−1i=f(Xk−1|k−1i)where i=0,…, 2L.The weighted sigma points are recombined to produce the predicted state and covariance.(22)xˆ(k|k−1)=∑i=02LW(m)iXk|k−1i(23)Pk|k−1=∑i=02LW(c)i[Xk|k−1i−xˆk|k−1][Xk|k−1i−xˆk|k−1]TThe weighted sigma points are recombined to produce the predicted measurement and predicted measurement covariance.(24)yˆk=∑i=02LW(m)iYki(25)Pykyk=∑i=02LW(c)i[Yki−yˆk][Yki−Yˆk]TThe state-measurement cross-variance matrix,(26)Pxkyk=∑i=02LW(c)i[Xk|k−1i−xˆk|k−1][Yki−Yˆk]TUKF Kalman filter gain is calculated from the above two covariance matrices as follows:(27)Kk=PxkykPykyk−1As like EKF, the update state is the predicted state plus the innovation weighted by the Kalman gain,(28)xˆk|k=xˆk|k−1+Kk(yk−yˆk)The updated covariance is the predicted covariance minus the predicted measurement covariance, weighted by the Kalman gain(29)Pk|k=Pk|k−1+KkPYkYkKkTIn neural network based state filtering, a general first principle model does the one step ahead state prediction and neural network filter which is a dynamic feed forward multilayer perceptron does the state update [3,11].As stated in Section 1, unlike EKF, the function form of state update equation in the Neural Observer is made nonlinear and performed by a neural network whose inputs are present and past values of measurements and innovations as well as predicted states.A feed forward network does not have a dynamic memory so the tapped delay line method is adapted to enable it to represent a dynamic system. This method thus turns a temporal modeling problem (learning the behavior of the system in time domain) into a spatial modeling problem (statically mapping the delayed inputs to the next output). The block diagram of the neural based state estimation scheme for CSTR process is shown in Fig. 5.To obtain a state estimate using a nonlinear system model of the form given by Eqs. (3) and (4), the following prediction update algorithm is proposed.The predicted state estimates are obtained as follows(30)Xˆ(k|k−1)=Xˆ(k−1|k−1)+∫tk−1tkF[X(τ),u(k−1)]dτThe predicted output estimates are obtained as follows(31)yˆ(k|k−1)=CXˆ(k|k−1)The updated state estimates(xˆ(k|k))are obtained using the non-linear update equation(32)Xˆ(k|k)=KNN(Xˆ(k|k−1),Y(k),ε(k))where(33)Y(k)=(y(k),y(k−1),…,y(k−ny+1))(34)ε(k)=(e(k),e(k−1),…,e(k−ny+1))(35)e(k)=y(k)−yˆ(k|k−1)In the above equations, Y(k) is a vector containing the present and past measurements and ɛ(k) is a vector containing the present and past innovations. KNNis the nonlinear function which is equivalent in functionality to the Kalman gain where nyand neare the number of past output and error terms used in the observer. The functionality of KNNis performed by a neural network having the structure of a feed forward multilayer perceptron.In all the simulation runs, the process is simulated using the non-linear first principle model and the true state variables are computed by solving the non-linear differential equations using differential equation solver in MATLAB. Fig. 6shows the block diagram of the proposed method for the CSTR process. It is assumed that feed temperature and concentration are constants, and coolant flow rate and feed flow rate are given as input parameters. The other parameters such as activation energy, heat of reaction, coolant temperature, etc., are taken as constants, because certain assumptions are considered like perfect mixing, constant volume, constant parameter values and constant physical properties. The tuning parameter values of EKF, UKF and Neural Observer are listed in Tables 2–4.Keeping in mind the realistic situation, the following simulation studies [7] have been carried out under the following conditions:•Normal operating conditionsModel parameter mismatchInitial state mismatchCase 1: Normal Operating ConditionsFigs. 7, 8 and 9show the EKF, UKF and Neural Observer estimated reactor concentration in CSTR for step changes in the coolant flow rate and random errors in the measurement.Figs. 10, 11 and 12show the EKF, UKF and Neural Observer estimated reactor temperature in CSTR for step changes in the coolant flow rate and random errors in the measurement.Case 2: Model parameter mismatchDue to inaccuracy in measurements and variation in operating conditions, parameters of process and model will not be identical. This may lead to poor estimation and hence poor control. Here, simulation studies are made considering both the above mentioned situations. Since the feed flow rate affects both temperature and concentration of the reactants simultaneously, it is chosen as the parameter of mismatch between the model and process. 30% model mismatch is considered and applied to EKF, UKF and Neural Observer. The response compared on the basis of MSE. Figs. 13, 14 and 15show the EKF, UKF and Neural Observer estimated reactor concentration and Figs. 16, 17 and 18show the reactor temperature in CSTR for 30% model mismatch.Case 3: Initial state mismatchSimulation studies are performed with different initial state values and it is observed that the performance of the filters is affected mainly due to the difference in initial values between the process and model. Accordingly, simulations are carried out for different initial settings. Moreover, the filter estimation is started at different instances after the process has been started. So the process is simulated with initial temperature mismatch and also initial concentration mismatch. Initial state mismatches are given at 600th sampling instant. Estimation is carried out at 600th sampling instant and plotted in Figs. 19–24.Mean Square Error (MSE), is used as performance indices to evaluate the performance of EKF, UKF and Neural Observer algorithms under different operating conditions. Tables 4–6show the comparative study (Figs. 23 and 24).From Table 4, it is clear that EKF algorithm shows better performance compared to UKF and Neural Observer under ideal conditions. For better dictating, a bar chart for comparative performance analysis of all nonlinear filter configurations under ideal conditions is presented as shown in Fig. 25.But when model mismatch is introduced EKF fails to estimate the true states. UKF and Neural Observer algorithm are able to track the true states even in the presence of higher percentage of model mismatch with reasonable error which is shown in Table 5. For better dictating, a bar chart for comparative performance analysis of all nonlinear filter configurations under model parameter mismatch is presented as shown in Fig. 26.Similarly for initial state mismatch condition UKF and Neural shows better response than EKF as shown in Table 6. Fig. 27shows a bar chart comparison for performance analysis of all nonlinear filter configurations under Initial condition mismatch.

@&#CONCLUSIONS@&#
