@&#MAIN-TITLE@&#
Integration of multi-feature fusion and dictionary learning for face recognition

@&#HIGHLIGHTS@&#
We propose two strategies for face recognition through multiple features.Our methods integrate multi-feature fusion and dictionary learning.The fusion process and dictionary learning are learned simultaneously.Extensive experiments validate the merits of our methods.

@&#KEYPHRASES@&#
Dictionary learning,Face recognition,Multiple features fusion,Tensor decomposition,Sparse coding,

@&#ABSTRACT@&#
Graphical abstract

@&#INTRODUCTION@&#
With the recent endeavor of computer vision researchers, lots of features have been designed to characterize various aspects of an object. Taking advantage of multiple features can provide more information for face recognition (FR), and the advantages of jointly analyzing multiple features are demonstrated in the literature [1–4]. Although it is widely believed that recognition performance can benefit from multiple features, in front of the developed multi-feature approaches, it remains an exploratory task to design a more effective and more efficient method to exploit multiple features.In recent years, several FR methods [5–7] have been developed based on the dictionary learning (DL) framework, and achieved very promising results. These DL-based FR methods are mainly developed in the following two tracks [8]:1.Directly making the dictionary discriminative, such as learning a class-specified sub-dictionary for each class;Making the sparse coefficients discriminative to propagate the discrimination power to the dictionary.Even though DL-based recognition methods achieve very promising and even state-of-the-art performances, they only work on a single feature type, e.g. the original grayscale facial image or facial outline image, rather than multiple informative features. In other words, they cannot exploit multiple features of one face image and their possible semantic relationships to enhance FR performance.Aware of the limitations of these DL-based methods that they cannot deal with multiple features, researchers have proposed several methods to tackle this problem [9–11]. Yuan and Yan propose a multi-task joint sparse representation based classification method (MTJSRC), which treats the recognition with multiple features as a multi-task problem, and each feature type is one task [9]. MTJSRC assumes that the coefficients share the same sparsity pattern among all the features. However, this assumption is too strict and is not held in practice. Therefore, Zhang et al. propose a joint dynamic sparse representation classification method (JDSRC) [10] to address this problem. They argue that the same sparsity pattern is shared among the coefficients at class-level, but not necessarily at atom-level. Yang et al. also address this problem by proposing a relaxed collaborative representation method (RCR), which assumes that the sparse codes among different features should be similar in appearance [11].All the above three methods elaborately use multiple features and try to exploit the sparse pattern between the coefficients of different features. Although they produce improved performance, there are still some intrinsic problems:1.Since the overall dictionary consists of all the features from all training images, when the training data increase in number, the dictionary will become too large that can lower the computational efficiency;Simply taking all features into computation will raise the computational burden and will induce redundant information that does not benefit or even can degrade FR performance;Although different features are connected through the coefficient constraints, these methods neglect the internal relationships among these features which may enhance the FR performance further;The dictionary constituted by all the training data has common components that are shared by different classes, and these components can be interchangeably used for reconstructing the query images, in which way the performance can be compromised.To address the above problems, we extend our previous work reported in [12,13] with the proposed two different strategies to integrate multi-feature fusion process11In this work of multiple features fusion, we only focus on the 2D face image databases instead of 2.5D or 3D images [14,15], as all the compared methods perform on the 2D image databases.and dictionary learning framework. The first one is a two-step model, which first learns a fusion matrix from the training data to fuse different features and then learns class-specific dictionaries. The fusion process exploits the high-level relationship among different features, and fuse these features into a more compact and more discriminative representation. Over the fused features of one specific class, the corresponding dictionary is learned. The second strategy is to learn the fusion matrix and class-specific dictionaries simultaneously. This strategy takes more time but produces better performance. Moreover, in this scheme, we explicitly separate the common components from different classes in the dictionary to make the learned dictionary more compact and more discriminative. As demonstrated by the experimental results, our two strategies both achieve better performances than other closely related methods.The rest of this paper is organized as follows. In Section 2, we briefly introduce the background and review several approaches that motivate ours. We elaborate the proposed two strategies in Section 3. Extensive experiments on three face recognition datasets are presented in Section 4. Finally, we conclude our paper in Section 5 with discussions.As we consider to generalize dictionary learning method to multiple features, we turn to the tensor algebra calculation framework. The notations and calculations are the following [16,17]. High-order tensors are denoted by boldface Euler script letters, e.g.X. Specially,Xnsymbolizes the matrix corresponding to the flattened tensorXalong the nth mode. Mathematically, tensor elementXi1,i2,…,iKof a Kth-order tensorX∈RI1×I2×…×IKmaps to the element (ik,j) of matrixXn, where:(1)j=1+∑k=1k≠nKik−1JkwithJk=∏m=1m≠nk−1ImImdenotes the m×m identity matrix with 1's along the diagonal positions and 0's elsewhere. Moreover, the nth element in a sequence is denoted by a superscript in parentheses, e.g. X(n) is the nth matrix in a sequence. X⊤ is the transpose of matrix X. We assume there are N observations, and each one has K features. Particularly,Xn=x1n…xkn…xKn∈Rp×Kconsists of all K features of the nth sample.22Without losing generality, in this paper, we assume that all the K features have the same length p.The k-mode product of a Kth-order tensorX∈RI1×…×Ik−1×Ik×Ik+1×…×IKby matrixU∈RJ×Ikis expressed asX×kU∈RI1×…×Ik−1×J×Ik+1×…×IK, which can be calculated as:(2)X×kUi1…ik−1jik+1…iK=∑ik=1Ikxi1i2…iKujik,where the element x and u inXand U are indexed by the corresponding subscripts.

@&#CONCLUSIONS@&#
