@&#MAIN-TITLE@&#
Near laser-scan quality 3-D face reconstruction from a low-quality depth stream

@&#HIGHLIGHTS@&#
We infer a very accurate 3-D face model for a freely moving user from a single depth camera.Using unwrapped cylindrical 2-D images enables us to use simple 2-D image processing algorithms to process the 3-D information.We use a combination of spatial smoothing and temporal integration for noise removal.A robust rejection method produces reliable results in the presence of facial expression changes and partial occlusions.Our system runs online and in real-time.

@&#KEYPHRASES@&#
Kinect,3D reconstruction,Face modeling,

@&#ABSTRACT@&#
We propose a method to produce near laser-scan quality 3-D face models of a freely moving user with a low-cost, low resolution range sensor in real-time. Our approach does not require any prior knowledge about the geometry of a face and can produce faithful geometric models of any star-shaped object. We use a cylindrical representation, which enables us to efficiently process the 3-D mesh by applying 2-D filters.We use the first frame as a reference and incrementally build the model by registering each subsequent cloud of 3-D points to the reference using the ICP (Iterative Closest Point) algorithm implemented on a GPU (Graphics Processing Unit). The registered point clouds are merged into a single image through a cylindrical representation. The noise from the sensor and from the pose estimation error is removed with a temporal integration and a spatial smoothing of the successively incremented model. To validate our approach, we quantitatively compare our model to laser scans, and show comparable accuracy.11This paper extends the method presented in [15].

@&#INTRODUCTION@&#
Accurate 3-D face modeling with affordable sensors offers many potential applications in biometrics, as in [20], or the gaming industries. Therefore, many researchers in computer vision and graphics have focused on this problem and proposed methods from structured lighting systems, multiple images, videos, and even a single image [1,42,22,36,2].Getting an accurate 3-D face model from low-quality 3-D cameras, such as the PrimeSense [31] camera, is a challenging problem. These cameras can provide both a standard RGB image and a depth image containing the 3-D information at 30 frames per second in VGA format. However, the quality of any single frame is not sufficient to generate reasonable 3-D models. The sensor computes a depth map based on the triangulation principle given correspondences between stored pattern and projected pattern. Hence, depth data near boundaries can be very noisy, as evaluated in [4,32]. A simple averaging in time is not sufficient.In this paper, we leverage the recent developments of inexpensive 3-D sensor technologies. We propose to generate 3-D models of a user's face from the depth video stream of a low-cost range sensor online and in real-time.In order to compensate for the noisy depth data, we propose to use several poses, accumulate and refine the information through time. Prior to any processing, we reduce the noise and blur the discontinuities of the raw input data by applying a bilateral filter [38]. Then, we automatically segment the head region.The first frame, containing a near frontal face is set as a reference, and is used to generate a 3-D point cloud. Given a new frame, we convert the depth map into a 3-D point cloud and register it with respect to the reference point cloud.To accumulate multiple views from a moving face, we propose to use unwrapped cylindrical 2-D images in canonical form, which is a well-known technique to represent a 3-D face [40,22]. This method enables us to perform 2-D image-based operations to filter out noisy input, instead of complex 3-D mesh processing. Also, a running mean is performed on every pixel for temporal integration and a bilateral filter [38] is used for spatial smoothing. Fig. 1shows the overview of our approach.Building a set of unwrapped cylindrical 2-D images enables us to add the information on previously occluded parts and refine the poor information on the edges. However, any error in the 3-D pose estimation would impact the model. To minimize the added noise and increase the robustness of our approach, we add a rejection process. We evaluate the quality of each new unwrapped cylindrical 2-D image and discard those which seem to be due to different facial expression or partial occlusions.The contributions of this paper are as follows.•We infer a very accurate 3-D face model for a freely moving user from a single depth camera. The reconstructed 3-D faces are compared to laser scan ground truth data and show comparable results.Using unwrapped cylindrical 2-D images enables us to use simple 2-D image processing algorithms to process the 3-D information, making the process computationally efficient.We use a combination of spatial smoothing and temporal integration for noise removal.A robust registration and a user-dependent rejection method produce reliable results in the presence of facial expression changes, partial occlusions and wide head pose angle changes.Our system runs online and in real-time.In the following sections, we first review the related work, then describe the details of the proposed approach, and discuss our results.

@&#CONCLUSIONS@&#
