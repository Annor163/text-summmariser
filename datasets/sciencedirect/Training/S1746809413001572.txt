@&#MAIN-TITLE@&#
An efficient voice pathology classification scheme based on applying multi-layer linear discriminant analysis to wavelet packet-based features

@&#HIGHLIGHTS@&#
Early voice pathology diagnosis is very worthwhile to prevent suffering from chronic voice diseases.This study introduces an efficient algorithm for classification of pathologic voices.The proposed algorithm benefits from the ability of energy or Shannon entropy features that are extracted from level eighth of wavelet packet tree.Significant classification results are achieved by applying multi-class linear discriminant analysis.

@&#KEYPHRASES@&#
Voice disorders classification,Discrete wavelet packet transform,Energy and entropy,Multi-class linear discriminant analysis,

@&#ABSTRACT@&#
In this work, we are interested in developing an efficient voice disorders classification system by using discrete wavelet packet transform (DWPT), multi-class linear discriminant analysis (MC-LDA), and multilayer neural network (ML-NN). The characteristics of normal and pathologic voices are well described with energy and Shannon entropy extracted from the coefficients in the output nodes of the best wavelet packet tree with eight decomposition level. The separately extracted wavelet packet-based features, energy and Shannon entropy, are optimized with the usage of multi-class linear discriminant analysis to reduced 2-dimensional feature vector. The experimental implementation uses 258 data samples including normal voices and speech signals impaired by three sorts of disorders: A–P squeezing, gastric reflux, and hyperfunction. The voice disorders classification results achieved on Kay Elemetrics databases, developed by Massachusetts Ear and Eye Infirmary (MEEI), show average classification accuracy of 96.67% and 97.33% for the structure composed of wavelet packet-based energy and entropy features, respectively. In these structures, feature vectors are optimized by multi-class linear discriminant analysis and, finally classified by multilayer neural network. The obtained results from confusion matrix and cross-validation tests prove that this novel voice pathology classification system is capable of significant classification improvement with low complexity. This research claims that the proposed voice pathology classification tool can be employed for application of early detection of laryngeal pathology and for assessment of vocal improvement following voice therapy in clinical setting.

@&#INTRODUCTION@&#
Voice health has been playing a significant role in promoting the quality of daily activities in many aspects. Therefore, considering precise and preventive health care programs is essential for taking care of voice health. In many cases, the origin of the voice disorders arises from unknown causes. Sometimes lasting cold or flu, a continuing virus or bacteria, and vocal abuse or misuse may result in chronic laryngitis and other types of voice diseases [1]. Automatic voice pathology assessment can be employed in the field of communication science and disorders as a complementary tool to screen individuals for early cases of laryngeal pathology [2,19]. This paper mainly focuses on introducing an automatic algorithm in classification of voices developed by impairments in the vocal folds.The human apparatus concerned with speech production is complex and involves many important organs. This mechanism involves three subsystems: air pressure system, vibratory system, and resonating system [1]. The vocal tract and the vocal cords are the most important components of speech system which their characteristics have the highest influences in the resulted voice [3]. Vibration of vocal folds is the result of providing and regulating air pressure by air pressure system – composed of diaphragm, chest muscles, ribs, abdominal muscles, and lungs – which is reflected in the concept of “pitch” [14]. Finally, a person's recognizable voice is produced by resonating system that involves throat, oral cavity, and nasal cavity [3]. The precise handling may be achieved by internal feedback in the brain. Actually, the central nervous system (CNS) coordinates voice production process through specific nerve connections and signals. The larynx muscles are stimulated by recurrent laryngeal nerve (RLN) and superior laryngeal nerve (SLN) [1]. The left and the right vocal folds, housed in the larynx, include tree distinct layer: mucosa, vocal ligament, and body. These soft and fragile structure of the vocal fold makes it very sensitive and vulnerable [3].The cycle of the vocal folds vibration creates a repeating undulation known as mucosal wave. The regularity of the mucosal wave is a sign of normal voice [1]. Also, the pliability of the mucosa depends on the integrity of the layer beneath it; superficial lamina propria. In normal voice, loudness which is the volume of sound resulted from the pressure of the air blown past the vocal folds, is in normal range. Pitch – the frequency of the mucosal wave – is an operative measure to evaluate laryngeal function which can be produced rapidly and precisely by who has a normal voice. Softness of voice is dependent on vocal fold closure and the integrity of the superficial lamina propria. Generally speaking, sign of “hoarseness”, “nasality”, “breathiness”, and “harshness” is sufficiently weak in normal voice.Abnormalities and impairments in the vibratory system are termed “voice disorders” which may cause breathiness, harshness, and hoarseness [3]. Stiffness in the vocal folds caused by swelling develops hoarseness and, also air leakage caused by partial nerve input loss increases breathiness. Position of the vocal folds is controlled by laryngeal muscles, arytenoid cartilages, RLN, SLN, and mass of vocal folds. A laryngeal pathology, such as A–P squeezing or gastric reflux, generally produces asymmetrical changes in the mass, elasticity and tension of the vocal folds, leading to deviant vibration [1]. In the case of A–P squeezing and hyperfunction, laryngeal muscle tension is damaged by voice abuse and misuse. Also, swelling and inflammation caused by gastric reflux and viral laryngitis affect the elasticity of vocal fold and, therefore it changes the normal status of air pressure passing form glottis and the resistance of vocal folds. Abnormality in the vocal folds can be detected in terms of harshness, breathiness, hoarseness, effortful phonation, vocal fatigue and vocal fry [1].In this work, the studied voice disorders for classification are impaired by three types of pathology: A–P squeezing, gastric reflux, and hyperfunction. The tense voice is often described as a voice produced with poor breath support, elevation of the hyoid bone and larynx, mandibular restriction, unnecessary tongue tension, and overall vocal tract constriction [3]. Part of such tract constriction was described by Colton and Casper [47] as anterior–posterior laryngeal squeezing (A–P squeezing) where the epiglottis and the arytenoids approach each other during phonation. A–P squeezing is demonstrated as a reduction in the supraglottic space as the arytenoid cartilages move anteriorly toward the petiole of the epiglottis, which results in varying degrees of visual obstruction of the adducted true vocal folds [3]. A–P squeezing is believed to be caused by excessive strain and tension in the laryngeal area. Sound of voice ranges from normal to extremely squeezed and tight sounding. The voice may sound rough if the squeezing causes irregular vibration of the vocal folds.Irritation and swelling in parts of the voice box due to backflow of stomach fluids into voice box area or laryngopharyngeal reflux usually result in gastric reflux [4]. Patients who suffer from gastric reflux generally complain of hoarseness, frequent throat cleaning, sensation of lump in the throat, and cough or sore throat. To diagnose, physicians determine the cause of reflux laryngitis -backflow of stomach fluids to the voice box or laryngopharyngeal reflux-using rigid or flexible laryngoscope.Hyperfunction involves increased laryngeal or supralaryngeal muscle tension, regardless of the presence of a vocal fold lesion. It is most often caused by abuse or misuse of the voice or constant throat clearing as a result of things such as gastro esophageal reflux. Resulted voice may leads to vocal fatigue, constant throat clearing, ulcer on vocal process, breathy voice, hoarseness, audible inhalation, and growth on vocal fold. An ear–nose–throat (ENT) specialist (otolaryngologist) or physician voice specialist (laryngologist) should be consulted in the case of voice disorders. Typically, laryngoscopy and stroboscopy are performed to provide elaborate information from larynx [2]. These technologies allow examiners to review the images of the larynx frame-by-frame, and to re-review images with members of the voice care team. However, these methods are expensive, invasive, and also bring discomfort.On the other hand, an automatic acoustic analysis for diagnosis of pathologic voices would greatly aid in clinical evaluation of laryngeal function and early detection/classification of pathologic voice. The advantage of acoustic analysis is its nonintrusive nature and its potential for providing quantitative data with reasonable expenditure of analysis time [2]. During the last decades, various approaches to efficient voice pathology assessment have been adopted. The most recent techniques in the area of pathologic voice detection/classification have been explored for some techniques to model accurately the variations of a group of features in normal and disordered subjects. Among various pathological voice detection algorithms, wavelets [5], fractals [6], neural maps and networks [7] has been mostly employed. In addition, many parameters have been suggested such as pitch, jitter, shimmer, amplitude perturbation quotient (APQ), pitch perturbation quotient (PPQ), harmonic to noise ratio (HNR), Glottal to Noise Excitation Ratio [8–18] and normalized first harmonic energy (NFHE) [19] to improve voice pathology detection system. These techniques necessitate an accurate estimation of the fundamental frequency, a fairly complex task in the presence of voice pathologies. In recent studies, several alternative approaches such as Mel-frequency cepstral coefficients (MFCC) and linear prediction cepstral coefficients (LPCC) have been proposed based on conceptual modeling for appropriate parameterization of speech signal to detect voice pathology. Godino-Llorente and Gomez-Vilda introduced voice disorders identification techniques based on MFCC speech parameterization fed to neural network [20] and Gaussian mixture model (GMM) [21]. In these works, the ability of F-ratio and Fisher's discriminant ratio was examined in reducing the dimension of MFCC-based features. In the best case, efficiency of 94.04% was reported for selected dataset. Different modifications for Mel-frequency cepstral coefficients (MFCC) and linear prediction cepstral coefficients (LPCC) have been suggested to improve voice disorders detection. For example, Costa et al. [22] proposed weighted cepstral coefficients in order to account for the sensitivity of the low-order cepstral coefficients to overall spectral slope and the sensitivity of the high-order cepstral coefficients to noise. Little et al. [23] studied two non-linear features of return period density entropy (RPDE) and fractal self-similarity based upon the biophysics of speech production for speech pathology detection. It proved that this proposed measures can be both simple and robust by achieving detection rate of 91.4% to discriminate normal and pathological voices.On the other hand, time-frequency transforms including wavelet and discrete wavelet packet transforms (DWPTs) are non-parametric estimation methods that have been recently proposed for speech parameterization to detect/classify voice disorders. DWPT is generally acknowledged to be useful for studying non-stationary phenomena and, in particular, have been shown or claimed to be of value in the detection and characterization of transient signals which is prevalent in pathologic voices. Local discriminant bases (LDB) algorithm and wavelet packet decomposition have been employed by Umapathy and Krishnan [24] to demonstrate the significance of identifying the signal subspace that contribute to the discriminatory characteristics of normal and pathological speech signals. In this research, a database of 212 speech signals (51 normal and 161 pathological) was used to evaluate the proposed system. Using the Daubechies wavelet with order 4 (db4) classification accuracy up to 96% for a two-class classification task (normal/pathological) and 74% for a four-class classification (male normal/female normal/male pathological/female pathological) were reported. Also, abnormal/pathological voice detection algorithm was developed by Schuck et al. [25]. This technique uses the characteristics of entropy and energy of wavelet packet decomposition, the best basis algorithm (BBA), and artificial neural networks (ANN) as a non-linear discriminator to classify dysphonic voices. The designed dysphonic voice classification system proposed a classification rate of 84.3%, with 4.6% of false negative and 10.9% false positives. Recently, a novel approach for detecting pathologic voice using wavelet packet transform was proposed by Arjmandi and Pooyan [26]. It presented an optimum voice pathology detection algorithm based on the energy and entropy features, obtained from the coefficients in the output nodes of the optimum wavelet packet tree. However, there are few studies that concentrated on classification of various types of voice disorders. Discrete wavelet transform and wavelet packet transform were examined especially to classify pathologic voices. As an example, Nayak et al. [27] proposed a classification method using wavelet coefficients, achieved by discrete wavelet transform, and artificial neural network to classify certain diseases: normal, paralysis, and hyperfunction. This research reported an inadequate efficiency in the range of 80–85% of accuracy. However, the approach did not consider feature dimension reduction methods which may result in better accuracy for classification. Recently, a classification algorithm using energy and Shannon entropy features at different spectral sub-bands, optimized by Davies–Bouldin (DB) criteria and genetic algorithm (GA), was proposed by KhadiviHeris et al. for the purpose of automatic screening of normal voices, unilateral vocal fold paralysis, vocal fold polyp, and vocal fold nodules [28]. In this work, the obtained feature vectors have been passed on to SVM and KNN classifiers. Reported results show that a feature vector of length 12 obtained by the optimization method of GA with the fitness function of SVM's recognition rate fed to SVM classifier achieves the highest classification accuracy of 91%. It has been already shown that the usage of DWPT in feature extraction stage [24–26,28,29] leads to gain significant results for automatic voice pathology detection/classification. Comparing these results with those of MFCC-based speech parameterization algorithms [20–22], is controversial.The main motivation for conducting this research was to introduce an efficient scheme for classifying normal voice and three specific pathologic voices: A–P squeezing, gastric reflux, and hyperfunction. To this end, this paper designs an investigation through the development of a non-parametric discrete wavelet packet feature extraction from voiced signal as an explicit modeling of pathologic and normal properties to screen patients with three specific pathologic voices; A–P squeezing, gastric reflux, hyperfunction. In many applications, time-frequency transforms are simply employed as qualitative and quantitative tool for signal representation. In the proposed algorithm, an energy-based or entropy-based feature parameterization scheme is applied in discrete wavelet packet domain. Unlike other techniques using time-frequency transforms for classification, the wavelet packet transform has the ability of automatic tuning of the features to a given signal. A precise investigation is designed to search the best decomposition level of wavelet packet to classify four classes of voice pathology. To improve classification accuracy, a feature optimization method is proposed which is an extension of linear discriminant analysis called multi-class linear discriminant analysis (MC-LDA). To study the proposed method precisely, the system performance is evaluated based on classification results obtained from scatter-plot, confusion matrix, and cross-validation.In continue, we first briefly introduce the studied dataset, the basic discrete wavelet packet transform, and extracted features from the output nodes of the best wavelet packet tree in the concept of energy and entropy in Section 2. Confusion matrix and cross-validation are discussed as evaluation tools in this section. The experimental results are discussed in Section 3. Next, Section 4 discusses obtained experimental results. Finally, the conclusion of this research is mentioned in Section 5.In this study, the examined voice samples were selected from the database of voice disorders [30], model 4337, version 1.03 (Kay Elemetrics Corporation, Lincoln Park, NJ), developed by the Massachusetts Eye and Ear Infirmary Voice and Speech Lab. Subjects were asked to sustain the vowel/a/(1s long) and voice recordings were made on a DAT (digital audio tape) recorder at a sampling frequency of 44.1kHz with 16-bit resolution. Selected voices belong to 53 normal people and 205 patients infected with A–P squeezing (72), gastric reflux (48), and hyperfunction (85). This database was selected so that the distribution of four classes is proportional to those of the original database. As a matter of fact, in selecting the data samples the distribution of data in the original database as a criterion of fair data selection are considered as well. The distribution of the selected data on four classes is detailed in Table 1. Also, an accurate procedure is followed to select the database regarding two concerns. At first, as it is evident from the database, there are many samples which have different labels (for instance a voiced signal “FMR17AN.NSP” labeled both A–P Squeezing and hyperfunction or “GXT10AN.NSP” labeled both gastric reflux and hyperfunction) which we removed these samples. Second, disorders which have the potency to classify were limited based on the limitation on number of their samples. After consulting with our physician, the database was designed so as considered in our research.Processing of non-stationary signals using conventional Fourier transform (FT) and short-time Fourier transform (STFT) are not efficient for detection and classification. Fourier-based methods are ideally suited to the extraction of narrow band signals whose durations exceed or are at least on the order of the Fourier analysis window length. That is, Fourier analysis, particularly the short-time Fourier transform (STFT), does an excellent job of focusing the information for sources of this type, thus, providing features (spectral amplitude) perfectly suited to detection and discrimination. For transient signals, the STFT with its non-varying window is not readily adaptable for capturing signal-specific characteristics. The STFT does allow for some temporal as well as frequency resolution, but it is not well suited for the analysis of many transient signals and, in particular, to the generation of features for detection and discrimination. An alternative means of analysis needs to be employed so that valuable time-frequency information is not lost. The discrete wavelet packet transform (DWPT) is one such time-frequency analysis tool. Actually, in opposition to the short time Fourier transform (STFT)-based time-frequency signal representation, discrete wavelet packet decomposition can lead to better representation of non-stationary parts of the speech signal. In the case of pathological voice, wavelet packet transform has a great ability to estimate the non-stationary, abrupt and discriminative events from speech signal. This paper presents a strong feature extraction algorithm using discrete wavelet packet transform (DWPT) to extract acoustic measures of vocal function from the speech signal in order to classify laryngeal pathologies.Wavelet transform has the advantage of using variable-sized time-windows for different frequency bands and, therefore has a merit of high frequency-resolution (and low time-resolution) in low bands and low frequency-resolution in high bands. Consequently, wavelet transform is a powerful tool for modeling non-stationary signals like abnormal speech that exhibit slow temporal variations in low frequency and abrupt temporal changes in high frequency. In fact, the DWPT is the only time-frequency transform with a potential for adaptability and representing localized discontinuities. Structure of the discrete wavelet packet decomposition is shown in Fig. 1.As Fig. 1 shows, discrete wavelet packet decomposition is a wavelet transform where the signal is passed through more filters than the discrete wavelet transform (DWT). The hierarchical wavelet-packet transform uses a family of wavelet functions and their associated scaling functions to decompose the original signal in subsequent sub-bands. The decomposition process is recursively applied to both low- and high-frequency bands to generate the next level of the hierarchy [31]. If an orthonormal wavelet basis is chosen, the estimated coefficients will be independent and may result in distinct groups of feature vectors [32,33]. Starting with a discrete input signal x[n], the first stage of the fast wavelet transform (FWT) algorithm [32] decomposes the signal into two sets of coefficients. There are the approximation coefficients cA1 and the detail coefficients cD1. However, in the DWPT, both the detail and approximation coefficients are decomposed. For N level of decomposition the DWPT produces 2Ndifferent sets of coefficients (nodes) as opposed to (3N+1) sets for the DWT. In a manner similar to wavelet systems, wavelet packets can be described by the collection of the following basic functions [32]:(1)W2N(2P−1x−l)=21−P∑mh(m−2l)2PWN(2Px−m)(2)W2N+1(2P−1x−l)=21−P∑mg(m−2l)2PWN(2Px−m)where P is the scale index, l the translation index, h the low-pass filter and g the high-pass filter as follow:(3)g(k)=(−1)kh(K−1−k)where K is the length of filter-banks. Therefore, due to the orthonormal property, the wavelet-packet coefficients at different scales and positions of a discrete signal can be computed efficiently as follows [32]:(4)CN,kP=2P∑−∞+∞f(m)⋅WN(2Pm−k)(5)C2N,lP−1=∑mh(m−2l)⋅CN,mP(6)C2N+1,lP−1=∑mg(m−2l)⋅CN,mPTherefore, if the wavelet analysis decomposes the approximation signals, the wavelet packets permit to decompose the details too. The nodes, which are not decomposed further, are called output nodes. In this study, the output nodes are employed to determine elements of feature vector using energy and entropy calculated from their coefficients.Energy is one of the most informative concepts in information theory that has the ability to exploit many meaningful features from a non-stationary signal. From the signal processing point of view, energy is often considered in the form of power spectral density (PSD) [34]. In comparison with Fourier-based signal representation, wavelet packet-based energy is more superior to Fourier-based energy (PSD), because it is capable of modeling localized information in both frequency and time domain. Therefore, for a group of wavelet-packet coefficients, energy yields elaborate features in its corresponding sub-band. This term is employed in this work as below:(7)EnergyN=1N2∑k=1NCN,kP2This measure is calculated from the sequences of output nodes of wavelet packet decomposition and is used to have an exact representation for irregularities in a specific type of pathologic voice as well as possible.Entropy is considered as a measure of uncertainty in a random sequence. Equivalently, Shannon entropy [35] is a measure of the average information content that has been hidden in a signal. The Shannon entropy is exploited to model the unpredictability and irregularities of a pathologic speech signal as well as possible within a certain wavelet packet decomposition sub-band. The Shannon entropy is measured as follow,(8)EntropyN=−∑k=1NCN,kP2logCN,kP2Any abnormality in the vocal folds result in uncertain series events with high random property, sudden variations, local discontinuities, quasi-noise components and distorted spectrum for analyzed speech signal. Shannon entropy has the ability to model these measures appropriately.Some major problems arise when the original feature distribution is so uncorrelated and complex. In the formulation of a decision rule, it is desirable to find a feature set which uniquely represents each class of signals in order to simplify decision rule. For example, for a multilayer neural network as used in this study for classification, a small feature set will lessen problems that the neural network learning algorithm have with local minima. Thus, the wavelet packet feature parameterization joint with multi-class linear discriminant analysis is considered with the above criteria. This paper focuses on linear discriminant analysis since it frequently achieves great performances in the tasks of voice disorders recognition [17,26], even though the assumptions of common covariance matrix among groups and normality are often violated [36]. In summary, as pointed out in [37], it is fair to say that there is probably no multi-class approach generally outperforms the others. For practical problems, the choice of approach will depend on constraints on hand such as required accuracy, the time available for development and training, and the nature of the classification problem. The simple, efficient, and accurate discriminant analysis provides a good choice for practical multi-class classification problems.Linear discriminant analysis (LDA) has been the workhorse of classification for many years, and will remain so. It is simple, well understood from a theoretical point of view, and reasonably effective on most problems. At first, linear discriminant analysis was introduced for two classes, and its idea was to transform the multivariate observations x to univariate observations y such that the y's derived from the two classes were separated as much as possible. Mathematically, a typical LDA implementation is carried out via scatter matrix analysis [38]. Suppose that we have a set of m p-dimensional samples x1, x2,…,xm, where xi=(xi1, xi2,…,xip), belonging to two different classes, namely c1and c2. For the two classes, scatter matrices are defined as a measure of the scatter in multivariate feature space x such as [38],(9)Si=∑x∈ci(x−x¯i)(x−x¯i)T,where(10)x¯i=1mi∑x∈cixand miis the number of samples in ci. Therefore, the total within-class scatter matrix is given by [38],(11)Σˆw=S1+S2=∑i∑x∈ci(x−x¯i)(x−x¯i)T.Also, the between-class scatter matrix is given by(12)Σˆb=(x¯1−x¯2)(x¯1−x¯2)TFisher's criterion suggested the linear transformation Φ to maximize the so-called Rayleigh coefficient, which is the ratio of the determinant of the between-class scatter matrix of the projected samples to the within-class scatter matrix of the projected samples [38].(13)J(Φ)=ΦTΣˆbΦΦTΣˆwΦ.IfΣˆwis non-singular, Eq. (13) can be solved as a conventional eigenvalue problem and Φ is given by the eigenvectors of matrixΣˆw−1Σˆb[38]. If the numbers of classes are more than two, as it is in this research, a natural extension of Fisher's linear discriminant exists using multiple discriminant analysis [39]. As in the case of two-class, the projection is from high dimensional space to a low dimensional space and the suggested transformation still maximizes the ratio of within-class scatter to the between-class scatter. But unlike the two-class case, the maximization should be done among several competing classes (four classes for this work). Suppose that now there are n classes. The within-class matrix is calculated similar to Eq. (11)[36]:(14)Σˆw=S1+S2+⋯+Sn=∑i=1n∑x∈ci(x−x¯i)(x−x¯i)T.The between-class scatter matrix slightly differs in computation and is given by [36](15)Σˆb=∑i=1nmi(x¯i−x¯)(x¯i−x¯)Twhere miis the number of training samples for each class,x¯iis the mean for each class andx¯is total mean vector given byx¯=1/m∑i=1nmix¯i. After obtainingΣˆbandΣˆw, the linear transformation we want should still maximize Eq. (13). It can be shown that the transformation Φ can be obtained by solving the generalized eigenvalue problem [38]:(16)ΣˆbΦ=λΣˆwΦIt is easy to prove that the upper bounds of the rank ofΣˆwandΣˆbare respectively m−n and n−1 [38]. Multiple discriminant analysis (MC-LDA) provides an elegant way for classification using discriminant features. Therefore, this research designed an optimization procedure by employing multi-class linear discriminant analysis (MC-LDA) to reduce original feature vector obtained from output nodes of wavelet packet tree, and also improve classification rate.Eventually, a multi-layer neural network (ML-NN) is selected as a pattern matching method for classification. The most advantage of the neural networks is its ability in automatic learning, what permits to solve some problems without need to write complex rules, while being tolerant to the errors [40]. A multilayer neural network is trained by using generalized back-propagation algorithm in order to classify four classes of disordered voice (Fig. 2) [41]. The neural network has 2Ninputs corresponding to number of sub-bands in the output nodes of the wavelet packet tree in level N before optimization by LDA or 2 inputs when the feature vector is optimized by LDA. Four neurons in output layer are assigned to classify three pathologic and one normal class. The first hidden layer comprises 20 neurons and second one includes 15 neurons. The optimum number of neurons in the first and second layer is determined experimentally which will be discussed in Section 2.5. Subsequently, the input is a feature vector extracted from the output nodes of wavelet packet decomposition in level N. The network weights are updated as(17)ΔWkj=12η(dk−zk)[1−zk2]yjforj=1,2,3,…;k=1,2,3,…Therefore, the (k×j) weights of output layer are updated. Then the input layer weights Vjiare updated as(18)ΔVji=14η[1−yj2]xi∑k=1k(dk−zk)[1−zk2]Wkjfori=1,2,3,…;j=1,2,3,…In this paper, we used a neural network with 2 hidden layers. Therefore, Eq. (18) was applied to update weights of the first and the second layer.To evaluate performance of the proposed system, a precise evaluation process was designed based on pursuing the variation in distribution of data (scatter-plot) in each step of processing, confusion matrix, and classification accuracy for non-optimized and optimized features in three consecutive levels of wavelet packet decomposition before level eight. At first, proficiency of the level of wavelet packet decomposition was scrutinized for reduced 2-dimentional new optimized feature vectors by illustrating their scatter-plot. Also, the scatter-plot provides a graphical display of the relationship between two features. It is useful in early stage of analysis, when exploring distribution of features, before actually applying classifier and calculating classification accuracy. It provides information about strength, shape (linear, curved, etc), direction, and presence of outliers between two features. Tracking the variation of decision boundaries through different proposed structures is considered as an evaluation tool. To achieve this aim, the performance of those structures is investigated based on assigned decision boundaries by applied multilayer neural network on optimized features.The concept of confusion matrix is well-known and has been widely exploited in related studies. A confusion matrix [43] contains information about actual and estimated classifications done by a classification system and its plot used to evaluate the performance of a classifier during supervised learning. Each column of the matrix represents the instances in a predicted class, while each row represents the instances in an actual class. Some measures have been defined on confusion matrix for different purposes. Accuracy of a classifier is a popular measure that can be easily calculated from its corresponding confusion matrix. Most advantage of confusion matrix is that it is able to monitor number of misclassification between classes, and therefore it is easy to see if the system is confusing two classes [43].Cross-validation is a statistical method of evaluating and comparing learning algorithms by dividing data into two segments: one used to learn or train a model and the other used to validate the model. In typical cross-validation, the training and validation sets must cross-over in successive rounds such that each data point has a chance of being validated against. The basic form of cross-validation is k-fold cross-validation. Other forms of cross-validation are special cases of k-fold cross-validation or involve repeated rounds of k-fold cross-validation. In k-fold cross validation, the dataset is randomly permutated and divided in k equally sized parts. The classifier is trained on k−1 parts and the remaining part is used for testing [42]. This is rotated over all parts. Finally, accuracy is estimated as the average accuracy rate on test samples. A commonly used method to obtain reliable performance estimation or comparison is to run k-fold cross-validation multiple times. The data is reshuffled and re-stratified before each round. The advantage of k-fold cross-validation is that all the examples in the dataset are eventually used for both training and testing.Structure of the proposed system is shown in Fig. 3. Based on this diagram, the overall algorithm is designed as follows:(1)The full DWPT of each signal was calculated,the energy and entropy features were created separately for each signal from the output nodes of its wavelet packet tree,obtained feature vectors were normalized by Z-Score normalization method,the dataset (feature set) is divided to train set and test set using k-fold cross-validation procedure,dimension of the energy or entropy feature vector from test set is optimized using resulted mapping from applying multi-class linear discriminant analysis on train set,a multilayer neural network with two hidden layer was trained to classify four studied classes,to insure for satisfactory between-class separation the test dataset is examined. Each of these stages is explained in more detail below.The purpose of feature extraction is to initially parameterize the speech signal in order to obtain the best representation of voiced sound for a certain class. Wavelet packet transform introduces a time-frequency analysis based on quantifying cross-correlation between a mother wavelet and analyzed signal that leads to comprehensive representation of signal on its wavelet coefficients [29]. Due to this, discrete wavelet packet (DWP) decomposition was utilized to exploit class dependent time-frequency characteristics in different sub-bands. The DWPT decomposed the input signal into 2Nsub-bands (decomposition level equaled to N) corresponding to 2Noutput nodes of wavelet packet tree [33]. The energy and entropy derived from the coefficients of the output nodes have been considered as proper features [29]. Therefore, there are 2Nelements for a feature vector extracted from a voiced sample from output nodes of wavelet packet tree. From the decomposition level point of view, the optimal wavelet packet decomposition is investigated to extract appropriate and distinguishing features.Some major issues must be considered before using the neural network models such as normalization methods for input vectors. Z-Score normalization method is applied to transform inputs into better form for the network use [44]. This routine produces data where each feature has a zero mean and a unit variance. Normalization technique is applied to all the feature vectors in the data set first; creating a new training set and then training is commenced. The advantage of this statistical normalization is that it reduces the effects of outliers in the data, enhances the reliabilityof the trained network, and also improves the classification accuracy [41].In this study, classification results for both energy and Shannon entropy are evaluated in a distinct and comparative way. After extracting the feature, we have a feature matrix along with corresponding labels. Our goal is to minimize the classification error using an appropriate feature vector. From the optimization point of view, an optimal feature vector was achieved by applying multi-class linear discriminant analysis to maximize the classification rate of the classifier. Therefore, we divided the dataset into train set and test set using k-fold cross-validation (k=10). Then, a mapping, based on multi-class linear discriminant analysis (MC-LDA), was calculated from train set and applied to the system (test set) to enable it to reduce feature dimension into 2-dimensional feature space and improve classification rate, simultaneously. Classification of dimension-reduced features was implemented using multilayer neural network (ML-NN) to discriminate four studied classes. Basically, a tree-layer ML-NN with a 2N-L1-L2-4 configuration is utilized for classification, where N is the level of wavelet packet decomposition and L1 and L2 indicates the number of neurons in the first and the second layers, respectively. Every neuron of the hidden layers is connected to the neurons of the input layer and those of the next hidden layer or output layer and there is not a connection between the cells of a same layer. After a number of trails, a best ML-NN model was achieved. Table 2shows some of the prominent classification results of ML-NN among different examined structures based on the number of layers, number of neurons at each layer, applied transfer function, and the training model. As given in Table 2, the best structure comprised of two hidden layers containing 15 and 20 neurons in the first and the second hidden layer with four output layers which results in minimum error rate. Each layer is interconnected each other with logarithmic, tangent hyperbolic and linear transfer functions, respectively. This ML-NN was trained using the Gradient descent with momentum backpropagation algorithm and the weights were adaptively updated during training period for each new incoming data sample (incremental training). As can be seen from Table 2, the system is robust after 3000 epochs however small changes may vary for new epochs. Also, the performance of each proposed classification algorithms were separately examined based on the results announced by confusion matrix and cross-validation (CV). Totally, CV is used to evaluate different structures as follow:-Non-optimized features (a feature vector with 2Nfeatures corresponding to level N of DWP decomposition)+ML-NN.Optimized features using MC-LDA (a feature vector with 2Nfeatures corresponding to level N of DWP decomposition reduced to 2 dimension feature vector using LDA)+ML-NN.Each algorithm was simulated using Matlab 7.6.0. (The Mathworks Web-Site [http://www.mathworks.com]).

@&#CONCLUSIONS@&#
