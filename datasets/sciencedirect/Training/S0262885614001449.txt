@&#MAIN-TITLE@&#
Representation of facial expression categories in continuous arousal–valence space: Feature and correlation

@&#HIGHLIGHTS@&#
Compared performance of texture (SIFT, Gabor, LBP), geometry and their fusionsInvestigated correlation of arousal and valence dimensions to six basic emotionsNovel insights into categorized emotion recognition using dimensional axes

@&#KEYPHRASES@&#
Facial expression recognition,Dimensional space,Continuous axis,Correlation,Categorized emotion,

@&#ABSTRACT@&#
Graphical abstract

@&#INTRODUCTION@&#
Facial expression is an important means of perceiving attitude, expressing opinion and conveying reactions during human-to-human interactions and is also an indicator of fatigue or boredom. Accordingly, automated facial expression recognition (FER) is useful in areas such as human–computer interaction, psychological monitoring, and driver condition assessment. For FER facial expressions must be represented in some feature spaces of numerical or symbolic values. Facial expressions can be represented in three ways: categorized emotions (e.g. happiness and surprise), facial action units defined in the facial action coding system (FACS), and continuous dimensional spaces (e.g. arousal and valence). A dimensional space representation can provide unique insights into the intensity of emotions and the relationship between different emotions, and thus contain more psychologically meaningful information. Correlations between dimensional values and emotion categories can guide the recognition of a categorized emotion using continuous dimensional axes and can be useful in applications such as video content indexing [1].Most of the current FER approaches use categorized emotions and facial action units. The use of dimensional representation is less common. Most FER algorithms in dimensional space quantize the dimensions into intervals such as high and low, and only few have used continuous values along the dimensional axes. There have been recent benchmarking studies, such as the 2012 and 2013 Audio/Visual Emotion Challenges (AVEC) [2,3]. Most of the approaches compared have used either texture or geometric features, not both. It is established that fusion leads to better performance for categorized emotions as it does with most classification problems. Whether a fusion of texture and geometry features can lead to better performance in the continuous arousal and valence dimensions has not been experimentally investigated. Further, nearly all the current knowledge of the correlation between continuous emotion dimensions and categorized emotions is directly adopted from psychological, cognitive, or neuroscience studies [4,5]. From these studies, it can be reasonably assumed that negative valence with negative arousal corresponds to sadness or boredom, but this is more of an abstract and relatively ambiguous correspondence and no explicit mapping between the two descriptions has been established [6]. No other work has been found that computes and estimates the correlations of arousal and valence dimensions to categorized emotions using publicly available databases. A key unanswered research question in this context is: Does arousal exhibit higher correlation with a categorized emotion (e.g. happiness) than valence? This paper will address such questions and issues.A framework is proposed to evaluate the performance of different texture features fused with geometric distance features for representing facial expressions in a continuous arousal–valence space. The texture features include discriminative subsets of three most widely used texture descriptors: local binary patterns — LBP, scale-invariant feature transform — SIFT and Gabor filter outputs that have shown state-of-the-art FER performance [7]. The geometric features are 43 distances between fiducial points defined based on facial animation parameters (FAPs). Each type of texture feature set is evaluated by itself and evaluated fused with geometric features. Arousal and valence are regressed from the features using support vector regression (SVR). The best-performing combination of LBP and FAP features is adopted for further investigations. The predicted arousal and valence values using this combination are then compared with the corresponding ground truths, considering aspects such as spatial distribution, shift, similarity, and correlation for each of the six basic categorized emotions. Two databases, NVIE and FEEDTUM, are used to estimate the correlations between emotion dimensions and categorized emotions. The results are benchmarked with previous findings in psychological studies.The rest of the paper is organized as follows. Section 2 reviews related work. Section 3 describes the evaluation framework. Section 4 presents experimental results. Conclusions are drawn in Section 5.

@&#CONCLUSIONS@&#
