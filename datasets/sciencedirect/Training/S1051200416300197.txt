@&#MAIN-TITLE@&#
High throughput resource shared 2D integer transform computation for H.264/MPEG-4 AVC

@&#HIGHLIGHTS@&#
Parallel processing of two independent blocks of4×4data.High circuit utilization ratio during 2D8×8and4×4integer transform computation.Data stream processing capability.High throughput.Small gate count.

@&#KEYPHRASES@&#
DCT,Dual clock architecture,H.264/MPEG-4 AVC,IDCT,Integer transform,Resource sharing,

@&#ABSTRACT@&#
Graphical abstract

@&#INTRODUCTION@&#
Integer transform based on forward and inverse Discrete Cosine Transform (DCT/IDCT) is employed in the H.264/MPEG-4 advanced video coding (AVC) standard, and it provides a balance between the compression ratio and video degradation due to compression [1,2]. The two-dimensional (2D)4×4integer transform allows for faster computation while the 2D8×8integer transform offers better compression for high-quality videos [3–5]. Row-column decomposition for DCT computations requires transpose memory, which leads to a larger implementation area and a low computational speed. Various architectures have been proposed to support independent implementation [6,7] as well as variable block size transformations [8,9]. Shared resource architectures and unified transform implementation have been proposed to optimize the area consumption and throughput [10,11], and architectures with a high throughput utilize intermediate memory and thereby require a larger implementation area and power consumption, which in turn limits their applicability in a low-power mobile environment. The matrix arithmetic operations that were described in [12] have been used to present shared resource architecture to achieve a high level of throughput with an optimized area requirement [13]. In [13] resource shared 2D4×4and 2D8×8integer transform computation were carried out by using a unified pipelined implementation. Although optimized, the structure can process only one block of4×4data during 2D4×4integer transform computation. During this time, approximately 25% of the circuit was used while the rest of the 75% processed non-useful data. In other words, during the 2D4×4integer transform computation, the shared resource architecture in [13] uses less than 50% of its resources, leading to undesirable power usage.In the proposed architecture, two4×4blocks can be processed in parallel to compute their respective 2D4×4integer transform by adding data re-arrangement and input/output ordering stages to the 2D8×8integer transform. It is shown that by using the hardware of 2D8×8integer transform, the 2D4×4integer transform of two independent blocks of size4×4can be computed. Hence, by sharing the computing resources between the 2D8×8integer transform computation and 2D4×4integer transform computation the implementation area can be optimized without sacrificing the throughput. To achieve resource sharing data rearrangement blocks are added to the existing 2D8×8integer transform computation design. The data re-arrangement and input/output ordering stages do not involve computation and can be merged with their preceding or succeeding stages. This allows the design to achieve a high throughput during the 2D8×8integer transform computation and parallel processing of two blocks during the 2D4×4integer transform computation. Parallel processing during 2D4×4integer transform computations allows for better resource utilization and optimized power consumption. Parallel processing also increases the overall throughput of the 2D4×4integer transform computation by 200%. In each stage, the simplified computation allows for the use of a high-frequency clock at each stage to help increase the overall throughput.The following sections explain the basic operations and structure of the 2D4×4and8×8integer transform used in H.264. Thereafter, the proposed algorithm and its implementation are presented. Next, a comparison is made with existing systems, and the conclusion is finally presented.For the H.264/MPEG-4 AVC FRExt, the 2-D forward integer transform is computed using an integer coefficient matrix,C[7]. Correspondingly, for an8×8matrixX8, the 2-D8×8forward transformY8is calculated as [7](1a)Y8=(CX8CT)⊙EgwhereEg= scaling matrixEgthat is absorbed in the quantization process, “⊙” = element by element multiplication ofEg,()Tis the matrix transpose operator.C=(1/8)⋅[88888888121063−36−10−1284−4−8−8−44810−3−12−66123−108−8−888−8−886−12310−10−312−64−88−4−48−843−610−1212−1063]Using matrix product and matrix transpose properties [12], the core equation in Eq. (1a) can be decomposed as(1b)Y8=(C(CX8)T)T⊙EgIn [9], the linear transformation (see appendix) is used to give the column-wise stacking vector ofX8andY8,Xvec8andYvec8the forward transform as(2)(C⊗C)⋅Xvec8=Yvec8The core forward and inverse transforms were further decomposed as(3)(C⊗C)⋅Xvec8=Pr‾︸StageS88⋅{{I4⊗[(H2⊕Q2)⊕Q3}︸StageS7,18⊕{I4⊗[(H2⊕Q2)⊕Q3}︸StageS7,28}︸StageS78⋅{[(H2⊕Q2)⊗I8]︸StageS6,18⊕(Q3⊗I8)︸StageS6,28}︸StageS68⋅{{I4⊗[(H2⊗I2)P4⊕Q1]}︸StageS5,18⊕{I4⊗[(H2⊗I2)P4⊕Q1]}︸StageS5,28}︸StageS58⋅{{[(H2⊗I2)P4]⊗I8}︸StageS4,18⊕(Q1⊗I8)︸StageS4,28}︸StageS48⋅(H2⊗I32)︸StageS38⋅(I8⊗H2⊗I4)︸StageS28⋅Pc‾︸StageS18⋅Xvec8whereXvec8is the column-wise stacking version ofX8, ⊗ denotes the Kronecker product [12] (see Appendix), ⊕ denotes the direct sum operation [12] (see Appendix),P‾r=Pr⊗PrandP‾c=Pc⊗Pc.Inis then×nidentity matrix, and the value of the other matrices is given below.Pr=[1000000000001000001000000000010001000000000000100001000000000001];Pc=[1000000001000000001000000001000000000001000000100000010000001000];P4=[1000010000010010];H2=[111−1];Q1=[3/211010−3/2−11−3/20101−13/2];Q3=[1001/4011/400−1/4101/400−1];Q2=[11/21/2−1];The fractional constants of each stage are shifted to the output, and the forward transform can be given as(4)(C⊗C)⋅Xvec8=1/64⋅Pr‾︸StageS88⋅{{I4⊗[2⋅(2⋅H2⊕Q2′)⊕Q3′}︸StageS7,18⊕{I4⊗[2⋅(2⋅H2⊕Q2′)⊕Q3′}︸StageS7,28}︸StageS78⋅{2⋅[(2⋅H2⊕Q2′)⊗I8]︸StageS6,1⊕(Q3′⊗I8)︸StageS6,28}︸StageS68⋅{{I4⊗[2⋅(H2⊗I2)P4⊕Q1′]}︸StageS5,18⊕{I4⊗[2⋅(H2⊗I2)P4⊕Q1′]}︸StageS5,28}︸StageS58⋅{2⋅{[(H2⊗I2)P4]⊗I8}︸StageS4,18⊕(Q1′⊗I8)︸StageS4,28}︸StageS48⋅(H2⊗I32)︸StageS38⋅(I8⊗H2⊗I4)︸StageS28⋅Pc‾︸StageS18⋅Xvec8where,Q1=1/2⋅Q1′,Q2=1/2⋅Q2′andQ3=1/4⋅Q3′, andQ1′=[322020−3−22−30202−23];Q2′=[211−2];Q3′=[400104100−140100−4];For H.264/MPEG-4 AVC, the forward4×4integer transform ofX4, is given asY4, [6](5a)Y4=(HX4HT)⊙Efwhere,(5b)H=[111121−1−21−1−111−22−1];Ef=[a2ab/2a2ab/2ab/2b2/4ab/2b2/4a2ab/2a2ab/2ab/2b2/4ab/2b2/4];a=1/2,b=(2/5)1/2.Using transpose property the core equation in Eq. (5a) can be decomposed as(6)Y4=(H(HX4)T)T⊙EfAs shown in [6], the core forward transform(HX4HT)is used as the forward integer transform, andEfis absorbed in the quantization process. For the column-wise stacking vector ofX4andY4,Xvec4andYvec4, the forward transform is given as(7)(H⊗H)⋅Xvec4=Yvec4As shown in [6], the core forward transform is further decomposed as(8)(H⊗H)⋅Xvec4=PˆR︸StageS74{[I2⊗(H2⊕V)︸StageS5b4](H2⊗I4)︸StageS5a4⊕P(2,4)︸StageS64⋅[(I2⊗V)︸StageS5d4(H2⊗I2)︸StageS5c4⊕(V⊗V)︸StageS5e4]P(4,2)︸StageS44}⋅(H2⊕I8)︸StageS34(I4⊗H2⊗I2)︸StageS24⋅PˆC︸StageS14⋅Xvec4where,PˆR=PR⊗PRandPˆC=PC⊗PC,In=n×nidentity matrix.(9)PR=[1000001001000001],PC=[1000010000010010];H2=[111−1];V⊗V=[42212−41−221−4−21−2−24];V=[211−2];The matrix decomposition shown in Eq. (1a) and (6) can be used to implement a row-column decomposed integer transform computation architecture [14,15]. The basic block diagram of such a system is as shown in Fig. 1.In this architecture, the input 2D matrix is first processed column wise. The output of select logic goes to the input of the core matrix multiplication circuitCØi. During this first stage of processingIselselect signal is set in mode to allowØito beXn,i. The output of the multiplication circuit is stored in the transpose memory,T1, to transpose the result of column processing using the output select signalOen. After all the columns have been processed the output of the transpose memory is feedback through the select logic. The transpose operation inT1allows for the row processing. During this second set of processingIselselect signal is set in the mode to allowØito beTn,i. After the second set of processing theOensignal saves the final result in transpose memoryT2.The advantage of such scheme is its simplicity. The timing of theIselandOenselect signal can be controlled such that the transpose memoryT1andT2can be merged. The merging of transpose memoryT1andT2helps to reduce the implementation hardware. The principle disadvantage of this scheme is that at any given time instance, during first and second stage of processing, only n element vector is processed. For the best case scenario, consider that core matrix multiplication takes only one clock for processing one set of input vector. Let us consider that maximum latency between transpose memory write and read is one clock. Hence, for 2D integer transform computation ofn×ninput matrix, first stage of calculation will require n clocks. Thereafter, 1 clock will be used by the transpose memoryT1. Similarly, second stage of processing will require n clock cycles. Therefore, even in best case scenario, total2n+1clock cycles will be required to processn×ninput samples. In actual implementation the core matrix multiplication requires more one than one clock for processing the n element vector. Hence, the final latency is much more than2n+1in a real design. The 2D integer transform designs based on row-column decomposition architecture must be optimized to meet desired real time latency constrains [14,15]. In terms of implementation, when the intermediate memory,T1, and the output memory,T2, are merged, the timing of memory read and write affects the maximum computational speed of the design. Hence the memory merging will also affect the maximum achievable throughput of the system. Many architectures have been proposed to achieve high throughput at the expense of increased hardware or allow multi-transform processing using a unified architecture [3–5,8,9].In [6,7] and [10], the matrix decomposition of core integer transform used in H.264 is presented. A simplified implementation of design proposed in [6,7] and [10] is shown in Fig. 2.In [6,7] and [10] it is shown that using matrix manipulation, the 2D integer computation can be broken down in to a sequence of data addition, subtraction and re-arrangement operation. It is shown thatn×ninput samples is converted to a vector withn2elements which are processed in parallel. The implementation based on [6,7] and [10] will not require transpose memory. Since all the input samples are processed in parallel the throughput of such system is high enough to achieve real time encoding performance. The design proposed in [6,7] and [10] deals with design of 2D4×4and8×8integer transform separately and hence, the implementation based on these designs will require separate processing units for 2D4×4and8×8integer transform computation. This will lead to higher area requirement for hardware implementation. On the other hand, while 2D4×4integer transform unit is being used 2D8×8integer transform unit will remain idle and vice-versa. Hence, if the unused block is not completely disconnected, there will be unnecessary power consumption due to inefficient hardware usage.The resource sharing architecture presented in [13] describes the method to use the 2D8×8integer transform architecture to compute the 2D4×4integer transform. The resource sharing version of the8×8integer transform can be given as(10)Yout8=(C⊗C)⋅Xin=1/64⋅Pr‾︸StageS88⋅{{I4⊗[2⋅(2⋅H2⊕Q2′)⊕Q3′}︸StageS7,18⊕{I4⊗[2⋅(2⋅H2⊕Q2′)⊕Q3′}︸StageS7,28}︸StageS78⋅{2⋅[(2⋅H2⊕Q2′)⊗I8]︸StageS6,18⊕(Q3′⊗I8)︸StageS6,28}︸StageS68⋅{{I4⊗[2⋅(H2⊗I2)P4⊕Q1′]}︸StageS5,18⊕{I4⊗[2⋅(H2⊗I2)P4⊕Q1′]}︸StageS5,28}︸StageS58⋅{2⋅{[(H2⊗I2)P4]⊗I8}︸StageS4,18⊕(Q1′⊗I8)︸StageS4,28}︸StageS48⋅R48(s)︸StageM2⋅(H2⊗I32)︸StageS38⋅(I8⊗H2⊗I4)︸StageS28⋅Pc‾︸StageS18⋅Ri(s)︸StageM1⋅XinSimilarly, the4×4integer transform is given as(11)Yout4=(H⊗H)⋅Xvec4=1/4⋅PˆR︸StageS74⋅[I8⊕P(2,4)]︸StageS64⋅{[I2⊗(4H2⊕V′)︸StageS5b4]⊕(I2⊗V′)︸StageS5d4⊕(V′⊗V′)︸StageS5e4}⋅VinV′=2⋅V;Vin=[VaVr];Va=[Rrvo⋅Or′8]/2;Or′8=[Ora8Orb8];Ora8=[Or8(1)Or8(2)…Or8(8)]T;Orb8=[Or8(17)Or8(18)…Or8(24)]T;Rrvo=Rvtvo(i,j);i=1,2,…12;j=1,2,…8,17,18,…24;Rvtvo=RvoT;Vr=[O44(13)⋯O44(16)]T(12)Ri(s)={Ris=1I64s=0R48(s)={R48s=1I64s=0(13)Xin={Xvec4s=1Xvec8s=0wheresis the select logic for4×4(s=1) and8×8(s=0) integer transform computations.(14)R48=[rij]where,rij={1i=is(k);j=js(k);0otherwiseis=[1,2,3,4,25,26,27,28,5,29,33,35,6,30,34,36];js=[1,2,5,6,9,10,13,14,33,34,37,38,41,42,45,46];k=1,2,…,16Ri=β⊗{I2⊗[α⊗(I2⊗α)]}β=[1000];α=[10000001]and,(15)Ro=[ΦfZ48,64];Φf=(Φ1⊗((I2⊗Φ1)⊗I2))Φ1=[10000010];Zp,qis all zero elements matrix of sizep×q.The basic implementation scheme based on the design proposed in [13] is shown in Fig. 3.In H.264, the transform size is based on the size of sub-blocks in the macro-blocks. Once when an8×8size sub-block is partitioned, 4 blocks of4×4size will be formed. Hence, whenever a block of4×4size is processed 3 other blocks of4×4size are waiting to be processed. Eqs. (10) and (11) show that the structure presented in [13] utilizes only a portion of the complete circuit when a single block of4×4data has been processed for the 2D4×4integer transform computation. Since, other blocks of4×4size are available, they can be processed in parallel. Hence, to increase the utilization factor, two independent blocks of4×4data can be processed for the 2D4×4integer transform computation, and this will also increase the throughput for the 2D4×4integer transform computation.As discussed in previous section, the implementation presented in [13] allows resource sharing in 2D4×4and8×8integer transform computation. The aim of this paper is to show that by using matrix decomposition and data rearrangement operations multiple blocks of4×4size can be processed in parallel using the 2D8×8integer transform computation circuit. A simplified block diagram of proposed implementation is shown in Fig. 4.The advantage of proposed implementation is that as compared to existing schemes, the proposed scheme will be able to achieve higher throughput without significant increase in hardware implementation area. In the existing designs only one block of size4×4is sent at the input for further processing. However, in the proposed design two blocks of size4×4will be processed in parallel. Hence, the difference in the existing and the proposed design will start from the way the input is applied to the system.In the existing implementation [13], the4×4integer transform of one set of 16 pixels can be computed from the8×8integer transform by zero-padding the input sample of 16 values to form a 64-element input vector. In most situations, multiple4×4blocks are processed during encoding and decoding. Hence, two blocks of dimension4×4can be considered to be available and are converted to 16-element vectors,XA,vec4andXB,vec4, for processing. The4×4integer transform ofXA,vec4andXB,vec4can be computed in parallel using a single butterfly structure of an8×8integer transform.The column-wise stacking vectorsXA,vec4,XB,vec4andXvec8consist of 16, 16 and 64 elements, respectively. To compute the4×4integer transform from the8×8integer transform, inputXA,vec4andXB,vec4are concatenated to form a column-wise stacking vector and are then zero padded to obtain 64 element vectors,X4e, as(16)X4e=[XA,vec4XB,vec40]64×1The output of sectionsS14,S24andS34, of the4×4integer transform,O34, are considered to obtain output of sectionsS18,S28andS38, of the8×8integer transform,O38, as,(17)OAB,34=ψAB,34⋅XAB,vec4(18)O38=ϕ38⋅Xvec8where,XAB,vec4=[XA,vec4XB,vec4]32×1,ψAB,34=(ψ34⊕ψ34),ψ34=(H2⊕I8)⋅(I4⊗H2⊗I2)⋅PˆCandϕ38=(H2⊕I32)⋅(I8⊗H2⊗I4)⋅Pc‾.Eqs. (17) and (18), show that apart from the size of the identity matrix, the other matrices and the operating sequence are identical.To obtain the zero padded version ofO34, the zero padded input,X4e, is pre-multiplied withRibefore applying it to stagesS18,S28andS38of the8×8integer transform. The output is again pre-multiplied with matrixRofor output reordering, and in this case, the output of stageS38of the8×8integer transform is given as(19)O34e=Ro⋅ϕ38⋅Ri⋅X4ewhere,Ri=(Ri,3⊗(Ri,2⊗(I2⊗(Ri,1⊗I2))));Ri,3=[10];Ri,2=[1000001000010100];Ri,1=[10000001]and,(20)Ro=(Ro,3⊗(Ro,2⊗(I2⊗(Ro,1⊗I2))))Ro,3=[10];Ro,2=[1000001001000001];Ro,1=[10000010]TheO34ethat is thus obtained is the zero padded version ofO34and is given by(21)O34e=[OAB,34Z32,1]Zp,qrepresents an all zero elements matrix of sizep×q.Hence, the zero padded version ofO34; the output from stagesS14,S24andS34of the4×4integer transform; can be obtained from stagesS18,S28andS38of the8×8integer transform.During the computation of the8×8integer transform, the output of stageS38is passed directly on to stageS48. However, stageS44of the4×4integer transform re-orders the input vector using a permutation matrixP(4,2). Hence, to compute the4×4integer transform by using the8×8integer transform, a conditional re-ordering matrix must be inserted between stagesS38andS48of the8×8integer transform.The output of stageS44of the4×4integer transform is given by(22)O44=P(4,2)⋅O34To compute the zero padded version ofO44, the output of stageS48,O34e, is reordered by pre-multiplying it with the reordering matrixR3as(23)O44e=R3O34e;whereR3=(P(4,2)⊕P(4,2)⊕Z32)withZnas an all zero elements matrix of sizen×n.While computing the4×4integer transform,O34ebecomes the zero padded version ofO34and is given by(24)O44e=[O44Z32,1].Consider that the input to stage 5 of 2D4×4integer transform based on Eq. (8) is given byvin,5(n), wheren=1to 16. Eq. (8) for 2D4×4integer transform shows that the processing in stage 5 is split into two sub-sections. Sub-sectionS5a4is for processing top 8 inputs to stage 5 i.e. for processing inputsvin,5(1)tovin,5(8). Similarly, sub-sectionS5b4is for processing bottom 8 inputs to stage 5 i.e. for processing inputsvin,5(9)tovin,5(16). The resource sharing architecture presented in [13] shows that while using the architecture of 2D8×8integer transform for the computation of 2D4×4integer transform, the computation in sub sectionS5b4is further split in to two sub-sections. One sub-section to process inputsvin,5(9)tovin,5(12)and another to process inputsvin,5(12)tovin,5(16). To simplify the computation and optimize resource sharing the 4 inputs from lower order input,vin,5(9)tovin,5(12), were combined with top 8 input samples,vin,5(1)tovin,5(8). This combined 12 input sample vector was processed separately from lower order inputs,vin,5(13)tovin,5(16). Through this segregation the computation is simplified as processing of inputvin,5(1)tovin,5(12)does not require multiplication with sub-matrix block(V⊗V)given in Eq. (9), while the processing of inputsvin,5(13)tovin,5(16)requires multiplication with sub-matrix block(V⊗V)given in Eq. (9).In the proposed design the input samples from two independent data blocks are processed in parallel during 2D4×4integer transform computation. Hence, the 12 sample input vector from both the independent data blocks must be considered. For any input vectorV12,1of size12×1, the output of stageS5a4of the4×4integer transform is given by(25a)O12,1U4=(H2⊗I4)V12,1UwhereV12,1U(j)=[V12,1(1)⋯V12,1(8)]T.Hence, for the input vectorsV12,1AandV12,1Bof size12×1, associated with the main input vectorXA,vec4andXB,vec4, the output of stageS5a4of the4×4integer transform is given by(25b)O12,1UA4=(H2⊗I4)V12,1UA(25c)O12,1UB4=(H2⊗I4)V12,1UBwhere,V12,1UA(j)=[V12,1A(1)⋯V12,1A(8)]T;V12,1UB(j)=[V12,1B(1)⋯V12,1B(8)]T.Similarly, the output of stageS5c4of the4×4integer transform is given by(26a)O12,1L4=(H2⊗I2)V12,1Lwhere,V12,1L(j)=[V12,1(9)⋯V12,1(12)]T.Therefore, for input vectorsV12,1AandV12,1Aof size12×1, associated with main input vectorXA,vec4andXB,vec4, the output of stageS5c4of4×4integer transform is given by(26b)O12,1LA4=(H2⊗I2)V12,1LA(26c)O12,1LB4=(H2⊗I2)V12,1LBwhere,V12,1LA(j)=[V12,1A(9)⋯V12,1A(12)]T;V12,1LB(j)=[V12,1B(9)⋯V12,1B(12)]T.The output of stagesS5a4andS5c4of the4×4integer transform can be obtained simultaneously as(27a)O12,1A4=[(H2⊗I4)⊕(H2⊗I2)]V12,1A(27b)O12,1B4=[(H2⊗I4)⊕(H2⊗I2)]V12,1B(28a)O12,1A4=[O12,1UA4O12,1LA4](28b)O12,1B4=[O12,1UB4O12,1LB4]The input vectorsV12,1AandV12,1Bcan be zero padded to obtain input vectorV32,1of size32×1as(29a)V32,1=[V12,1AZ4,1V12,1BZ4,1]The zero padded vector version ofV32,1with a size of64×1is obtained by output re-ordering the stage 4 output of the8×8integer transform.(29b)[V32,1V32,e]=RaO44ewhereV32,eis the zero padded version of output not included inV32,1.It can be shown that if the input vectorV32,1is rearranged, stageS4,1of the8×8integer transform can simultaneously perform the operations in stagesS5a4andS5c4of the4×4integer transform. To achieve this, the input is pre-multiplied with reordering matrixRb. The re-ordered inputV32,r, is given by(30a)V32,r=RbV32,1Eqs. (29b) and (30a) are combined to obtain the zero padded vector for the input of the stageS4,1of the8×8integer transform,V32,r, as(30b)[V32,rV32,e]=[RbV32,1IbV32,2]=(Rb⊕Ib)RaO44e=R4O44ewhere,R4=(Rb⊕Ib)Ra=(Rv⊕Z24,32)Rv=[G4,1,2Z8G4,3,2Z8Z8G2,1,4Z8G2,5,4Z8G2,2,4Z8G2,6,4G4,2,2Z8G4,4,2Z8Z8G4,2,2Z8G4,4,2];Gs,l,n=Wn⊗Is;Wn(i,j)={1i=l/n;j=mod(l/n)0otherwise;For the re-ordered input vectorV32,rthe output of stageS4,18of the8×8integer transform is given by(31)Or8=[2⋅{[(H2⊗I2)P4]⊗I8]V32,rEqs. (28) and (31) are compared to show thatOr8andO12,14are related by(32)Ou,44e=2⋅[O12,1A4Z4,1O12,1B4Z4,1]=RvoOr8;where,Rvo=[G4,1,2Z8G4,3,2Z8Z8G2,1,4Z8G2,5,4G4,2,2Z8G4,4,2Z8Z8G2,2,4Z8G2,6,4]Gs,l,n=Wn⊗Is;Wn(i,j)={1i=l/n;j=mod(l/n)0otherwise.The computations in stageS5e4of the4×4integer transform can be carried out by using the8×8integer transform. However, this will require significant data re-ordering and additional adders, thereby introducing a significant latency to the output and reducing the overall throughput. Hence, stageS5e4of the4×4integer transform has been separately implemented to reduce latency. The input for this section will consist of four input values from vectorO44e, which correspond to the last four inputs from vectorO44.The output of stageS38of the8×8integer transform provides the input to stagesS4,18andS4,28of the8×8integer transform. Eqs. (30), (31) and (32) are used to show that stageS4,18can simultaneously perform the operations from stagesS5a8andS5c8of the4×4integer transform. During this computation period, stageS4,28of the8×8integer transform remains idle. Eqs. (31) and (32) show thatS4,18can perform simultaneous calculations when the input has been arranged asVr. To constructVr, vectorV32,1is required, which in turn requires vectorV12,1. A zero padded version ofV32,1can be obtained fromO34eas(33)Ov8=[V32,rV32,e]=R4O44e;where,V32,e=[V4,1AV4,1BZ24,1];V4,1A(j)=[V12,1A(13)⋯V12,1A(16)]T;V4,1B(j)=[V12,1B(13)⋯V12,1B(16)]T;V32,randV32,eare the input vectors of stagesS4,18andS4,28of the8×8integer transform. Based on the previous discussion, stageS4,28of the8×8integer transform is known to remain idle, and the inputs,V4,1, corresponding to the last four outputs of stageS44of the4×4integer transform can be given to stageS5e4of the4×4integer transform, which has been implemented separately.Finally, Eqs. (19), (23), (30), (31) and (33) are used to give the combined input to stagesS4,18andS4,28of the8×8integer transform,V48as(34)V48=Ov8=[V32,rV32,e]=R4O44e=R4R3Roϕ38RiX4e;To obtain a smaller latency, all re-ordering matrices can be combined in one single re-ordering matrixR48given by(35)R48=R4R3RoEq. (35) is solved to give the reordering matrixR48as(36)R48=[rij]whererij={1i=is(k);j=js(k);0otherwiseis=[1,2,3,4,25,26,27,28,5,6,7,8,29,30,31,32,9,17,33,35,10,18,34,36,11,19,37,39,12,20,38,40];js=[1,2,5,6,9,10,13,14,17,18,21,22,25,26,29,30,33,34,37,38,41,42,45,46,49,50,53,54,57,58,61,62];k=1,2,…,32It should be noted that the original4×4and8×8integer transform do not contain the matrices introduced in Section 4. These matrices are part of the proposed work where matricesRiandR48are added to the existing8×8transform architecture to obtain a partial result for the4×4integer 2D DCT computation.As shown in Ref. [13], sectionsS5b4andS5d4of the4×4integer transform are independently implemented to achieve a high throughput. SectionsS64andS74of the4×4integer transform perform an input re-ordering without any computations, and thus, they are independently implemented using output buffers.From previous sections, re-ordering matricesRiandR48are inserted before stagesS18andS48, respectively, in the8×8integer transform to allow the computation of the4×4integer transform from the same circuit. These matrices are bypassed or treated as identity matrices during the8×8integer transform computation. Hence, for the actual implementation,RiandR48are changed toRi(s)andR48(s), respectively, and are defined as(37)Ri(s)={Ris=1I64s=0(38)R48(s)={R48s=1I64s=0where,sis the select logic for4×4(s=1) and8×8(s=0) integer transform computations.Finally, Eqs. (15), (19), (23), (32), (33), (34), (35), (37), and (38) are used to give the shared resource version of the8×8integer transform as(39)Yout8=(C⊗C)⋅Xin=1/64⋅Pr‾︸StageS88⋅{{I4⊗[2⋅(2⋅H2⊕Q2′)⊕Q3′}︸StageS7,18⊕{I4⊗[2⋅(2⋅H2⊕Q2′)⊕Q3′}︸StageS7,28}︸StageS78⋅{2⋅[(2⋅H2⊕Q2′)⊗I8]︸StageS6,18⊕(Q3′⊗I8)︸StageS6,28}︸StageS68⋅{{I4⊗[2⋅(H2⊗I2)P4⊕Q1′]}︸StageS5,18⊕{I4⊗[2⋅(H2⊗I2)P4⊕Q1′]}︸StageS5,28}︸StageS58⋅{2⋅{[(H2⊗I2)P4]⊗I8}︸StageS4,18⊕(Q1′⊗I8)︸StageS4,28}︸StageS48⋅R48(s)︸StageM2⋅(H2⊗I32)︸StageS38⋅(I8⊗H2⊗I4)︸StageS28⋅Pc‾︸StageS18⋅Ri(s)︸StageM1⋅Xin(40)Xin={X4es=1Xvec8s=0Similarly, the4×4integer transform is given as(41a)Yout,A4=(H⊗H)⋅Xvec,A4=1/4⋅PˆR︸StageS74⋅[I8⊕P(2,4)]︸StageS64⋅{[I2⊗(4H2⊕V′)︸StageS5b4]⊕(I2⊗V′)︸StageS5d4⊕(V′⊗V′)︸StageS5e4}⋅Vin,A(41b)Yout,B4=(H⊗H)⋅Xvec,B4=1/4⋅PˆR︸StageS74⋅[I8⊕P(2,4)]︸StageS64⋅{[I2⊗(4H2⊕V′)︸StageS5b4]⊕(I2⊗V′)︸StageS5d4⊕(V′⊗V′)︸StageS5e4}⋅Vin,BVin,A=[Vu,A(i)Vl,A(j)];Vin,B=[Vu,B(i)Vl,B(j)];Vu,A(i)=Ou,44e(i);Vu,B(i)=Ou,44e(16+i);i=(1..12);Vl,A(j)=V32,e(j);Vl,B(j)=V32,e(4+j);j=(1..4);V′=2⋅V;Vin=[VaVr];Va=[Rrvo⋅Or′8]/2;Or′8=[Ora8Orb8];Ora8=[Or8(1)Or8(2)…Or8(8)]T;Orb8=[Or8(17)Or8(18)…Or8(24)]T;Rrvo=Rvtvo(i,j);i=1,2,…12;j=1,2,…8,17,18,…24;Rvtvo=RvoT;Vr=[O44(13)⋯O44(16)]TIt should be noted that all matrices proposed in Sections 4 and 5 are absent from the previously existing literature [6,9,13]. These matrices have been proposed to allow partial results to be computed for4×42D DCT using the8×8integer transform.In previous implementations of shared resource architectures, the overall implementation was comprised of smaller independent units. In [13] it is shown that the basic building blocks comprised of vector addition and reordering operations were implemented. Thereafter, these building blocks were integrated in higher-level complex sub-blocks to perform the desired data manipulation at each stage. For example, multiplying a vector,v1, withH2requires addition and subtraction. Similarly, multiplication of a vector,v2, withQ2′requires a data shift, an addition and a subtraction operation. Therefore, if a vector,v3=[v1v2]T, is multiplied by the sub-block in stageS6,18to compute(2⋅[(2⋅H2⊕Q2′)])⋅v3, a total of two data shift, two addition and two subtraction operations are required.The data shift in the computation of(2⋅[(2⋅H2⊕Q2′)])⋅v3is the result of multiplication with a factor of 2. Hence, the shift operation can be hardwired to reduce the computation time. Similarly, addition and subtraction are performed on independent input and can hence be performed in parallel. Therefore, the computation of the 2D DCT integer transform given in Eqs. (39) and (40) has been split into stages such that the computation within each stage can be carried out independently. Clock based synchronization is used to show that the maximum latency between the input and output in each stage is not more than an addition or subtraction operation. In stages likeM1andM2, only the data rearrangement has been performed, and hence, the actual latency is less than an arithmetic operation.Based on Eq. (39) the block diagram for the computation of the 2D8×8integer transform is shown in Fig. 5a. Similarly, based on Eq. (41), the block diagram to compute the 2D4×4integer transform is shown in Fig. 5b.Fig. 5a and Fig. 5b show the architecture to compute the 2D8×8and4×4integer transform. In the actual implementation, stagesM1,S18,S28,S38andM2are shared. Fig. 6shows the implementation structure that integrates both 2D8×8and4×4integer transform. The sections that are common in the computation of 2D8×8and4×4integer transform can be seen to provide intermediate results to the sections that are exclusive to the 2D8×8and4×4integer transform computation. To reduce the power consumption, the clock input to the sections that are required exclusively for the 2D4×4integer transform computation can be disabled during the 2D8×8integer transform computation. Similarly, the clock input to the sections required exclusively for the 2D8×8integer transform computation can be disabled during the 2D4×4integer transform computation.In the proposed design, let the worst case latency in any stage beLw, the worst case setup time in any stage beSwand the worst case hold time in any stage beHw. Hence, with single clock structure the minimum clock period,Tc1(min⁡)must be greater than the worst case computational delay + setup time of the next stage+hold time for the next stage, i.e.Tc1(min⁡)>Lw+Sw+Hw. Using a 10% margin the minimum clock period for a single clock design,Tc1(min⁡)can be given asTc1(min⁡)=1.1(Lw+Sw+Hw). Hence, the maximum frequency of operation will beFc1(max⁡)=1/Tc1(min⁡). For a CMOS implementation the dynamic power consumption in each stage,Pds, is proportional to the switching frequency, i.e.,Pds∝Fc1(max⁡). Fig. 5a shows that there are 11 stages in the implementation of the 2D8×8integer transform and Fig. 5b shows that there are 10 stages in the implementation of the 2D4×4integer transform. Hence, for 2D8×8integer transform, if all the stages are triggered every clock cycle then the instantaneous dynamic power consumption,Pd8, is proportional to the product of number of stages and the switching frequency, i.e.,Pd8=11.Pds∝11.Fc1(max⁡). Similarly, for 2D4×4integer transform, if all the stages are triggered every clock cycle then the instantaneous dynamic power consumption,Pd4, is proportional to the product of number of stages and the switching frequency, i.e.,Pd4=10.Pds∝10.Fc1(max⁡). To maintain the power consumption within reasonable limits, the maximum switching frequency is reduced and the clock margin is set to be about 2 times the minimum clock period. Hence,Tc1(>Tc1(min⁡))=2(Lw+Sw+Hw),Fc1(max⁡)=1/Tc1(min⁡)=1/(2(Lw+Sw+Hw)),Pds∝Fc1(max⁡)=1/(2(Lw+Sw+Hw)),Pd8=11.Pds∝11.Fc1(max⁡)=11/(2(Lw+Sw+Hw)),Pd4=10.Pds∝10.Fc1(max⁡)=10/(2(Lw+Sw+Hw)). Fig. 7shows the triggering timing requirement for single clock design and dual anti phase clock design.In a dual anti-phase clock design with 50% duty cycle, the alternating stages can be triggered by anti-phase clocks as shown in Fig. 7. Consider that each stage is triggered at the rising edge of the input clock. Hence, when the rising edge of clock C_Fc2occurs, only half of the stages will be triggered. The remaining sections will be triggered at the rising edge of the anti-phase clock, C_Fc2_i. This will have two effect on the design.A.At any time only half of the stages will be triggered. Hence, for 2D8×8integer transform, the instantaneous dynamic power consumption,Pd8, will be proportional to the product of (number of stages)/2 and the switching frequency, i.e.,Pd8=6.Pds(≈5.5Pds)∝6.Fc1(max⁡). Similarly, for 2D4×4integer transform, the instantaneous dynamic power consumption,Pd4, is proportional to the product of (number of stages)/2 and the switching frequency, i.e.,Pd4=5.Pds∝5.Fc1(max⁡). Due to reduced power consumption, the maximum switching frequency is reduced but not significantly and the clock margin is set to be about 10% of the minimum clock period. Hence,Tc1(>Tc1(min⁡))=1.1(Lw+Sw+Hw),Fc1(max⁡)=1/Tc1(min⁡)=1/(1.1(Lw+Sw+Hw)),Pds∝Fc1(max⁡)=1/(1.1(Lw+Sw+Hw)),Pd8=6.Pds∝6.Fc1(max⁡)=6/(1.1(Lw+Sw+Hw)),Pd4=5.Pds∝5.Fc1(max⁡)=5/(1.1(Lw+Sw+Hw)). Hence, if power consumption of all the stages is considered together than the power consumption of the single clock design will be same as that of the dual anti-phase clock design. However, in this case, the operating frequency of the dual anti-phase clock design will be higher than that of the single clock design.As discussed earlier, if the clock frequency of the single clock design and the dual anti-phase clock design is kept same, the dynamic power consumption in the dual clock structure is significantly reduced as compared to the single clock design.Due to these reasons, dual anti-phase clock has been used in the implementation of the proposed design. Further reduction in latency can be achieved by merging different sections in to a single section.It should be noted that currently existing designs can also use dual clock system as long as the computations are done in mutually independent stages. The effect of using dual clock design on timing and power consumption in existing schemes requires a case-by-case analysis. Hence, such an analysis is considered outside the scope of this manuscript.StagesM1,S18,S28,S38andM2are shared in the computation of the 2D8×8integer transform as well as in the computation of the 2D4×4integer transform. Anti-phase clocks are alternately used to reduce the computation time. In other words, ifM1is clocked by a clockCk, the next stageS18will be clocked byCk‾(180 phase shiftedCk). As discussed earlier, the computation in each stage is independent, and therefore, a new data set can be given as the input in next clock edge once the data passes through one stage. This pipelined dual clocked architecture reduces the latency to half.Fig. 5a shows that there are 11 stages in the implementation of the 2D8×8integer transform. Hence, a total of 11 clock cycles will be required for the 2D8×8integer transform computation. With the use of a dual clock structure, the latency is reduced to 5.5 Clock cycles, and to further reduce the latency and increase the throughput, sections with data shift operations can be combined with their preceding or succeeding stages. For example, stagesS18andS28consist of simple input reordering and can be merged into one block, which will reduce the overall latency to 4.5 clock cycles.Fig. 5b shows that there are 10 stages in the implementation of the 2D4×4integer transform. Hence, a total of 10 clock cycles will be required for the 2D4×4integer transform computation. The dual clock structure reduces the latency to 5 Clock cycles, and similar to the 2D8×8integer transform computation structure, the sections with data shift operations can be combined with their preceding or succeeding stages. For example, the output stages of the4×4integer transformS64,S74and 1/4 can be merged into one block, and sub-blockKcan be implemented as combinational logic without clock input since it performs data selection only. This will reduce the overall latency to 3 clock cycles.Eqs. (39), (40) and (42) show that switching between the 2D8×8integer transform computation and 2D4×4integer transform computation is controlled by the select signal,s. Fig. 8shows the timing diagram for the 2D8×8integer transform computation (s=0). As shown in the timing diagram, the alternative stages are clocked by anti-phase clocks, and the output of each stage is available at the rising edge of the input clock. After the data has been passed to the succeeding stage, the data input to the current stage can be updated. Hence, new data input can be applied to the pipelined architecture at each rising edge, and thus the maximum input to output latency is 4.5 clocks due to the merging of stages and use of a dual clock architecture.Fig. 9shows the timing diagram to compute the 2D4×4integer transform (s=1). StagesM1,S18,S28,S38andM2are used in the computation for the 2D8×8as well as the 2D4×4integer transform. The alternating stages are clocked by anti-phase clocks. The maximum input to output latency is 3 clocks due to the merging of stages and use of a dual clock architecture.Let the total number of shift and add operations required in 2D4×4and8×8integer transform computation beΘ4andΘ8be respectively. As shown in previous sections, to achieve resource sharing in 2D4×4and8×8integer transform computation; using the scheme presented in [6,7] and [10]; additional stages have been introduced in the proposed design. However, it should be noted that the new sections introduced in proposed paper are data rearrangement blocks. There are no arithmetic or logical operation performed in these sections. Hence, it can be concluded thatΘ4andΘ8of the proposed design is same as that of 2D4×4and8×8integer transform presented in [6,7] and [10]. It has already been proved in [6,7] and [10] that the fast 2D4×4and8×8integer transform requires smaller number of shift and add operations as compared to the existing schemes.If the designs presented in [6,7] and [10] are implemented separately, as shown in Fig. 2, the total number of shift and add elements required for implementation will be approximately equal toΘ4+Θ8. For the resource shared implementation presented in [13] let the number of shift and add operations common in 2D4×4and8×8integer transform be given byΘ4+8. Hence, the number of shift and add operations required for implementation of design based on [13] will approximately be equal toΘ4+Θ8−Θ4+8. In the proposed implementation the newly added blocks does not require any shift and add operations. Hence, the number of shift and add operations in the proposed resource shared architecture is also approximately equal toΘ4+Θ8−Θ4+8. SinceΘ4+Θ8−Θ4+8<Θ4+Θ8the number of computational elements required for implementation of proposed scheme will be less than the total number of shift and add elements required for independent implementation of 2D4×4and8×8integer transform based on [6,7] and [10]. Hence, it can be concluded that the proposed scheme can achieve higher throughput by parallel processing of two independent blocks of4×4size with approximately same number of processing elements as [13] and less number of computation elements based on row-column decomposition methodology for 2D integer transform computation.To verify the proposed design, the VHDL code of the proposed design was synthesized using Artisan TSMC 0.18-μm Process Standard Cell and the Synopsys Design Compiler tool. Synopsys IC compiler tool has been used for placement and route (P&R). The proposed architecture has been implemented using 0.18 μm CMOS technology to develop an ASIC prototype for functionality and operating speed verification. The maximum achievable clock frequency for the proposed implementation is 1.316 GHz. For functional verification, an anti-phase clock of 1.25 GHz was used to verify the post synthesis simulation results. For design verification various alternatives are available. For example, the proposed design can be used in conjunction with the H.264/MPEG-4 AVC reference software [16] as a hardware accelerator. Another way is to apply pre-defined inputs to the proposed design and compare the output with the standard response. For this research work a simplified verification method way employed. Fig. 10shows the verification environment setup used in this research work. Random input sample patterns resembling pixel values were generated using software tools such as MATLAB. This set of input data pattern was applied to two different test objects. The first test object is standard 2D8×8and4×4integer transform given by Eqs. (1a) and (5a). The second test object is the ASIC based on proposed design. The standard 2D8×8and4×4integer transform runs at software level while FPGA based verification platform was used to connect MATLAB with ASIC based on proposed design. The outputs from the ASIC based on proposed design is compared with the standard 2D8×8and4×4integer transform for verification. The core transform used in H.264 reference software [16] and the proposed scheme is same. The difference in reference software and proposed scheme is the method with which the 2D integer transforms are computed. The software as well as proposed scheme uses integer computations. Hence, the results obtained from the proposed scheme and the software code shall be identical. During the implementation of proposed scheme the bit length of adders in various sections are chosen such that difference and hence, the mean square error (MSE) between the result from the software based integer transform and proposed design is zero.Real time processing of high resolution video, such as HD 1080p (1920×1080), requires high DCT computation throughput. In [17], H.264/MPEG-4 AVC reference software JM14.0 is used to present the throughput requirements for various video samples. The results in [17] show that with the increase in video frame size, the minimum throughput requirement increases from Mega-pixels per second to Giga-pixels per second. This minimum required throughput also affects the power consumption of the clocked circuits that are employed in high-throughput DCT computation designs.Table 1shows a comparison of existing implementations with the proposed implementation. The results of the implementation show that the proposed design can achieve twice the throughput for 2D4×4integer transform computation as compared to the shared resource architecture in [13]. The operating frequency of the proposed design is about six times higher (1.316 GHz) that of other unified architectures. The proposed architecture does not require transpose or intermediate memory and hence requires a fewer number of gates than the other unified architectures with a high throughput. When compared to the shared resource architecture in [13], the proposed design requires a higher number of gates for implementation due to parallel processing of two independent4×4blocks for 2D4×4integer transform computation. Hence, with less than a 12% increase in gate count, the throughput for 2D4×4integer transform computation increases by 100%. It should be noted that the new sections introduced in the proposed design are used for sample reordering. There are no arithmetic operations performed in these blocks. To achieve 2D4×4integer transform from 2D8×8integer transform, the design in [13] also uses data rearrangement sections which are combined with their preceding or succeeding stages to reduce latency. Hence, even though the data re-ordering sections in proposed design are different from those used in [13], the number of computations in the data path for 2D4×4and8×8integer transform is same in proposed design and the resource shared architecture of [13]. Since the data reordering computations are merged with preceding or succeeding stages, the latency in the data path 2D4×4and8×8integer transform is same in proposed design and the resource shared architecture of [13]. Hence, for the 2D8×8integer transform the proposed scheme can achieve same clock speed as the design presented in [13]. For the 2D4×4integer transform computation two blocks are processed in parallel and hence the total number pixels processed is doubled. Therefore, the throughput for the 2D4×4integer transform computation in the proposed design is doubled to that of the design presented in [13]. At each stage, the output is buffered at the rising edge of the corresponding input clock. Therefore, as shown in the timing diagram, each stage can start processing a new set of input data while the succeeding stage performs the intermediate computations for the previous set of input data. Therefore, the initial input to output latency is of 4.5 clocks for the 2D8×8integer transform computation. Similarly, the initial input to output latency is 3 clocks for 2D4×4integer transform computation. The pipelined structure allows continuous data stream processing.As shown in Table 1, the reduced computation time and small gate count allow the proposed design to achieve the highest throughput to area ratio, and the throughput of the proposed design is about 3 times that of existing architectures. Designs based on parallel computation architecture achieve high throughput at the expense of higher gate count [13–15]. Designs based on row-column decomposition have simple architecture. Hence, they can achieve high operating frequency and lower gate count at the expense of throughput [9–11,13]. In the proposed manuscript, matrix decomposition has been used to simplify parallel processing of inputs and intermediate results in each stage. Simplified computations helps to reduce the latency in various stages without significantly increasing the gate count. A lower gate count and higher throughput results in a throughput-to-area ratio of the proposed design that is about 4 times larger than any of the other architectures. In conclusion, the proposed design for the shared resource architecture for 2D8×8and4×4integer transform computation has following salient features:a)Parallel processing of two independent blocks of4×4data.High circuit utilization ratio during 2D8×8and4×4integer transform computation.Data stream processing capability.High operating frequency helps reduce latencyHigh throughput.Small gate count.

@&#CONCLUSIONS@&#
