@&#MAIN-TITLE@&#
Decision making with imprecise probabilities and utilities by means of statistical preference and stochastic dominance

@&#HIGHLIGHTS@&#
We extend binary relations to express preferences between sets of alternatives.The cases of stochastic dominance and statistical preference are considered.We use this to deal with imprecise information about utilities and probabilities.We make a connection with aggregation operators.The results are illustrated by means of an example.

@&#KEYPHRASES@&#
Preference learning,Binary relations,Stochastic dominance,Statistical preference,Random sets,Imprecise probabilities,

@&#ABSTRACT@&#
A problem of decision making under uncertainty in which the choice must be made between two sets of alternatives instead of two single ones is considered. A number of choice rules are proposed and their main properties are investigated, focusing particularly on the generalizations of stochastic dominance and statistical preference. The particular cases where imprecision is present in the utilities or in the beliefs associated to two alternatives are considered.

@&#INTRODUCTION@&#
In decision making under uncertainty, it is not uncommon to encounter situations with vague or conflicting information about the probabilities or the utilities associated to the different alternatives. We may think for instance of conflicts among the opinions of several experts, limits or errors in the observational process, or simply partial or total ignorance about the process underlying the alternatives. In any such case, the elicitation of a unique probability/utility model for each of the alternatives may be difficult and its use, questionable.One of the solutions that have been proposed for situations like this is to consider a robust approach, by means of a set of probabilities and utilities. The use of this approach to compare two alternatives is formally equivalent to the comparison of two sets of alternatives, those associated to each possible probability-utility pair. Hence, it becomes useful to consider comparison methods that allow us to deal with sets of alternatives instead of single ones. However, the way to compare of sets of alternatives is no longer immediate: we may compare all possibilities within each of the sets, or also select some particular elements of each set, to take into account phenomena of risk aversion, for instance. This gives rise to a number of possibilities. Moreover, even in the simpler case where we choose one alternative from each set, we must still decide which criterion we shall consider to determine the preferred one.There is quite an extensive literature on how to deal with imprecise beliefs and utilities when our choice is made by means of an expected utility model (Aumann, 1962; Nau, 2006; Ríos Insua, 1992; Seidenfeld, Schervish, & Kadane, 1995). However, the problem has almost remained unexplored for other choice functions. In this paper we focus mostly on two different optimality criteria that serve as an alternative to the expected utility model: stochastic dominance and statistical preference. The former is based on the comparison of the distribution functions associated to the alternatives, and has been applied in economics (Denuit, Dhaene, Goovaerts, & Kaas, 2005; Goovaerts, Kaas, Van Heerwaarden, & Bauwelinckx, 1990); the latter can be seen as a robust alternative to expected utility which is based on the median instead of the mean as a location parameter, and was introduced in De Schuymer, De Meyer, De Baets, and Jenei (2003), as an equivalent and graded version of the method presented in Boland, Hollander, Joag-Kev, and Kochar (1996); it is also a counterpart of the expected utility model when the rewards of the different alternatives are expressed in a qualitative scale (Dubois, Fargier, & Perny, 2003). We shall recall the basic aspects of these two criteria in Section 2.In Section 3, we define a number of choice models for sets of alternatives starting from some binary relation, based on earlier work on this problem carried out in Montes, Miranda, and Montes (2013), and apply them to the particular cases where this relation is the one associated to stochastic dominance or statistical preference. Then we consider two particular cases: first, in Section 4 we deal with the case where we have precise information about the beliefs but imprecise one about the utilities. We model this situation by means of multi-valued mappings, or random sets (Dempster, 1967) which, under the epistemic interpretation considered in Kruse and Meyer (1987), can be seen as collections of random variables imprecisely specified. We show that under some conditions the comparison can be simplified using the lower and upper probabilities induced by the random set. Secondly, we consider in Section 5 the case where we have precise utilities but imprecise beliefs, and show that there are two additional notions that may be more useful in such a scenario.The different conditions and their properties are illustrated by means of an example in Section 6. We conclude the paper by giving a number of additional remarks in Section 7.Let us review the basics about the two optimality criteria for decision making under uncertainty we shall consider in this paper. To clarify our set up, we consider a problem where we must choose between alternatives X, Y whose utilities depend on the values ω of the states of nature. We assume that we have probabilistic information about these states of nature, so that X, Y are defined as variables from a probability space(Ω,A,P)and taking values on an utility space Ω′. For the most part, we shall assume that Ω′ is a bounded subset of the reals; however, in the case of statistical preference we may have qualitative utilities, and then Ω′ may correspond to an ordered qualitative scale.The notion of stochastic dominance between random variables is based on the comparison of their corresponding distribution functions. Assume that our utility scale is Ω′=[0,1] (the results in this section generalize immediately to the case where Ω′ is any bounded interval of real numbers). Distribution functions are thus defined in the following way:Definition 1A cumulative distribution function on [0,1] is a function F: [0,1]→[0,1] satisfying the following properties:•x⩽y⇒F(x)⩽F(y) ∀x,y [Monotonicity].F(1)=1 [Normalization].F(x)=lim∊↓0F(x+∊) ∀x<1 [Right-continuity].Any F satisfying the properties of monotonicity and normalization is associated to a finite additive probability measure, and we shall call it a finitely additive distribution function.One of the most popular methods for the comparison of cumulative distribution functions is stochastic dominance (Levy, 1998):Definition 2Given two cumulative distribution functions F and G, we say that F stochastically dominates G, and denote it F⪰FSDG, if F(t)⩽G(t) for every t in [0,1], and given two random variables X, Y taking values on [0,1], we say that X stochastically dominates Y, and denote it X⪰FSDY when its associated distribution function FX stochastically dominates FY, whereFX(t)=P(X⩽t)andFY(t)=P(Y⩽t)∀t∈[0,1].In the literature, this notion is sometimes called first degree stochastic dominance, in order to distinguish it from a number of weaker conditions called second, third,… degree stochastic dominance (Levy, 1998). This is the reason of the notation ⪰FSD. Occasionally the notation ⪰stis also employed (see for instance Müller & Stoyan, 2002).This definition induces a partial order in the spaceFof cumulative distribution functions, from which we can derive the notions of strict stochastic dominance, indifference and incomparability:•We say that F stochastically dominates G strictly, and denote it by F≻FSDG, if F⪰FSDG but G⪰FSDF. This holds if and only if F⩽G and there is some t∈[0,1] such that F(t)<G(t).F and G are stochastically indifferent, and denote it by F≡FSDG, if F⪰FSDG and G⪰FSDF, or equivalently, if F=G.F and G are stochastically incomparable, and denote it by F≁FSDG, if F⪰FSDG and G⪰FSDF.Thus,(F,≻FSD,≡FSD,≁FSD)constitutes a preference structure (Roubens & Vincke, 1985).Stochastic dominance is commonly used in economics and finance (Denuit et al., 2005; Goovaerts et al., 1990 ) and can be given the following interpretation: F⪰FSDG means that the choice of F over G is rational, in the sense that we prefer the alternative with greater probability of providing a utility above a certain threshold t, and this for all possible t. The notion has also been used in other frameworks such as reliability theory, statistical physics, and epidemiology. We refer to Levy (1998), Müller and Stoyan (2002) for more information, and to Batur and Choobineh (2012), Dupacova and Kopa (2013) for recent works in the context of decision making. It is characterized by the following property:Theorem 1Levy, 1998Given two random variables X and Y it holds that: X⪰FSDY if and only if E(u(X))⩾E(u(Y)) for every non-decreasing u.The result is based on the equivalence between X⪰FSDY and the inequality E(I[t,∞)(X))⩾E(I[t,∞)(Y))∀t∈R, so if we denote byU∗the set of non-decreasing and bounded maps fromRtoR, we may also characterize stochastic dominance by:(1)X⪰FSDY⇔E(u(X))⩾E(u(Y))foreveryu∈U∗.We next introduce the notion of statistical preference. One of its advantages is that it is applicable to variables X, Y taking values on any ordered qualitative scale Ω′, which need not be numerical. It is based on the notion of probabilistic relation.Definition 3Bezdek, Spillman, and Spillman, 1978Given a set of alternativesD, a probabilistic relation is a mapQ:D×D→[0,1]satisfying Q(a,b)+Q(b,a)=1 for all a, b inD.Consider two variables X, Y from a probability space(Ω,A,P)to an ordered utility space Ω′ and define(2)Q(X,Y)=P(X>Y)+12P(X=Y);then it is easy to see that Q is a probabilistic relation. The value Q(X,Y) can be interpreted as a measure of the strength of our preference of X over Y. Statistical preference can then be introduced as a decision criterion based on this probabilistic relation:Definition 4De Schuymer, De Meyer, and De Baets, 2003; De Schuymer et al., 2003We say that the random variable X is:•statistically preferred to Y, and denote it by X⪰SPY, ifQ(X,Y)⩾12;strictly statistically preferred to Y(X≻SPY) ifQ(X,Y)>12;statistically indifferent to Y(X≡SPY) whenQ(X,Y)=12.Note that, ifDdenote a set of random variables defined on the probability space,(D,≻SP,≡SP)constitutes a preference structure without incomparable elements.Remark 1One context where statistical preference appears naturally is that of decision making with qualitative random variables. Dubois et al. show in Dubois et al. (2003) that given two variables X, Y: Ω→Ω′, where(Ω′,⪰Ω′)is an ordered qualitative scale, then, given a number of rationality axioms over our decision rule, the choice between X and Y must be made by means of the likely dominance rule, which says that X is preferred to Y if and only if[X⪰Ω′Y]≿[Y⪰Ω′X], where[X⪰Ω′Y]={ω∈Ω:X(ω)⪰Ω′Y(ω)}and[Y⪰Ω′X]={ω∈Ω:Y(ω)⪰Ω′X(ω)}and where≿is a binary relation on subsets of Ω. One of the most interesting cases is that where≿is determined by a probability measure P, soA≿B⇔P(A)⩾P(B); we obtain that X is preferred to Y if and only if P(X⩾Y)⩾P(Y⩾X), or, equivalently, if X⪰SPY. Hence, we can see statistical preference as a natural generalization of the expected utility model to the case of qualitative utilities.Statistical preference is also applicable when we are dealing with quantitative utilities and the utility scale Ω′ is a subset of the reals; in that case, statistical preference is related to a location parameter: the median. This is detailed in Montes, Martinetti, Díaz, and Montes (submitted for publication, Theorem 5).More generally, the idea of statistical preference is to consider X preferred to Y when it provides greater utility the majority of times. As such, it is close to the rule of majority in voting systems; taking into account Condorcet’s paradox (see Condorcet, 1989) it is not surprising then that the binary relation associated to statistical preference is not transitive: it is possible to find random variables X, Y and Z satisfying X>SPY,Y>SPZ and Z>SPX. Let us recall one example, that shall be used later on; another one can be found in Dubois et al. (2003, Example 3).Example 1De Schuymer et al., 2003Consider independent dice (here, we call dice a random variable with a discrete uniform distribution over a six-value space) defined by:X={1,3,4,15,16,17}.Y={2,10,11,12,13,14}.Z={5,6,7,8,9,18}.It holds thatQ(X,Y)=2036,Q(Y,Z)=2536, butQ(Z,X)=2136.The binary relation induced by statistical preference is reflexive, because we see immediately from Eq. (2) thatQ(X,X)=12, and therefore X≡SPX for every X. However, it is not antisymmetric, sinceX≡SPY⇔Q(X,Y)=12, and this does not imply that X=Y: to see an example, consider Ω={ω1,ω2}, withP({ωi})=12, and the variables X, Y given byω1ω2X20Y11Then,Q(X,Y)=12, and consequently X≡SPY even if the two random variables are different.With respect to the expected utility, statistical preference can be characterized in the following way (Couso & Sánchez, 2010). Given two real-valued random variables X, Y,(3)X⪰SPY⇔X-Y⪰SP0⇔E(u(X-Y))⩾0,where the utility functionu:R→Ris given by u=I(0,+∞)−I(−∞,0).To conclude this part, we discuss briefly imprecise probability models. This is the generic term used to refer to all mathematical models that serve as an alternative and a generalization to probability models in cases of imprecise knowledge. It includes possibility measures (Zadeh, 1978), Choquet capacities (Choquet, 1953–1954), belief functions (Shafer, 1976) or coherent lower previsions (Walley, 1991), among others.In this paper, we shall use imprecise probability models because we shall deal with a setXof alternatives, each with its corresponding probability distribution; we obtain thus a setPof probability measures. This set can be summarized by means of its lower and upper envelopes, which are given by:(4)P̲(A)≔infP∈PP(A),P‾(A)≔supP∈PP(A),and which are coherent lower and upper probabilities in the sense of Walley (1991). If instead we consider the lower and upper expectation operators, given byE̲P(f)≔infP∈PEP(f),E‾P(f)≔supP∈PEP(f), we obtain coherent lower and upper previsions. Conversely, if we specify a coherent lower probabilityP, we shall denote byM(P̲)≔{Pprobabilitymeasure:P(A)⩾P̲(A)∀A}its associated credal set.In a similar way, if we consider a setFof distribution functions, its associated lower and upper distribution functions are given by(5)F̲(x)≔infF∈FF(x),F‾(x)≔supF∈FF(x).ThenF̲,F‾are finitely additive distribution functions, and the set of distribution functions bounded between them is called a p-box (Ferson, Kreinovich, Ginzburg, Myers, & Sentz, 2003), and denoted(F̲,F‾). P-boxes shall be useful when dealing with imprecise stochastic dominance.In the following, we propose a number of comparison methods for pairs of sets of variables which are based on performing pairwise comparisons of elements within these sets. We shall first give our definitions for the case where the comparisons of the elements are made by means of a binary relation, and later apply them to the particular cases where this binary relation consists of stochastic dominance or statistical preference. Some of the ideas within this section are similar to those put forward in Montes et al. (2013) when extending stochastic dominance in order to deal with imprecise information.Definition 5Let ⪰ be a binary relation on the set of variables from a probability space(Ω,A,P)to an ordered utility scale Ω′. Given two sets of random variablesXandY, we say that:1.X⪰1Yif and only if for everyX∈X,Y∈Yit holds that X⪰Y.X⪰2Yif and only if there is someX∈Xsuch that X⪰Y for everyY∈Y.X⪰3Yif and only if for everyY∈Ythere is someX∈Xsuch that X⪰Y.X⪰4Yif and only if there areX∈X,Y∈Ysuch that X⪰Y.X⪰5Yif and only if there is someY∈Ysuch that X⪰Y for everyX∈X.X⪰6Yif and only if for everyX∈Xthere isY∈Ysuch that X⪰Y.The relationships between the definitions are summarized in the following proposition. Its proof is immediate and therefore omitted.Proposition 2The following implications hold:(a)⪰1⇒⪰2⇒⪰3⇒⪰4.⪰1⇒⪰5⇒⪰6⇒⪰4.The previous implications can also be seen easily in the particular case whereXandYare finite sets,X={X1,…,Xn}andY={Y1,…,Ym}. Denote by M the n×m matrix where Mi,j=1 if Xi⪰Yjand 0 otherwise. The above definitions are characterized in the following way:•X⪰1Y⇔M=1.X⪰2Y⇔∃i∈{1,…,n}s.t.Mi,·=1.X⪰3Y⇔∄j∈{1,…,m}s.t.M·,j=0.X⪰4Y⇔M≠0.X⪰5Y⇔∃j∈{1,…,m}s.t.M·,j=1.X⪰6Y⇔∄i∈{1,…,n}s.t.Mi,·=0.The ideas in the above definition are somewhat similar to those in the field of robust ordinal regression (Greco, Słowiński, Figueira, & Mousseau, 2010; Kadziński, Greco, & Słowiński, 2012a, Kadziński, Greco, & Słowiński, 2012b): in that case we consider a set of additive value functions compatible with our partial preferences, and the problem of considering a choice function that is robust with respect to this information is considered. In particular, in Kadziński et al., 2012a the best and the worst expected rewards for any alternative with respect to the set of value functions are considered. This could be embedded into our formulation above, provided that: (a) our binary relation is that associated to expected utility and (b) the set of alternatives corresponds to the conjunction of an alternative with a set of value functions. See also Section 5 later on.Observe that for any binary relation ⪰, its extensions ⪰2 and ⪰3 are quite similar: both compare the best alternatives within each setX,Y. The difference between them lies on whether there is a maximal element within each of these sets or not. A similar comment (this time in terms of the worst alternatives) can be made for ⪰5, ⪰6. Taking this into account, we can easily give a necessary and sufficient condition for the equivalences⪰2⇔⪰3and⪰5⇔⪰6.Proposition 3Let ⪰ be a binary relation on the set of random variables that is reflexive and transitive.(a)Given a setXof random variables,X⪰3Y⇒X⪰2Yfor any set of variablesYif and only ifXhas a maximum element under ⪰.Given a setYof random variables,X⪰6Y⇒X⪰5Yfor any set of variablesXif and only ifYhas a minimum element under ⪰.(a)Assume thatXhas a maximum element X such that X⪰X′ for everyX′∈X. IfX⪰3Y, then for everyY∈Ythere is someXY∈Xsuch that XY⪰Y. Since ⪰ is transitive and X⪰XY, we deduce that X⪰Y for everyY∈Y, and as a consequenceX⪰2Y.Conversely, ifXdoes not have a maximum element, we can takeY=Xand we would haveX≡3Ybecause ⪰ is reflexive; however,XandYare incomparable with respect to ⪰2 becauseXdoes not have a maximum element.Similarly, ifYhas a minimum element Y, it holds that Y′⪰Y for anyY′∈Y. IfX⪰6Y, then for everyX∈Xthere existsYX∈Ysuch that X⪰YX, and since ⪰ is transitive and YX⪰Y we obtain that X⪰Y for everyX∈X, whenceX⪰5Y.Conversely, ifYdoes not have a minimum element, we can takeX=Yand we would haveX≡6Ybecause ⪰ is reflexive; however,XandYare incomparable with respect to ⪰5 becauseYdoes not have a minimum element. □Under some conditions, we can also give a simpler characterization of the above conditions:Proposition 4Let ⪰ be a binary relation between random variables, and assume that it satisfies the Pareto Dominance condition:(6)X(ω)⩾Y(ω)∀ω⇒X⪰Y.Consider two sets of random variablesX,Y. If the random variablesminX,maxXbelong toXandminY,maxYbelong toY:(a)X⪰1Y⇔minX⪰maxY.X⪰2Y⇔X⪰3Y⇔maxX⪰maxY.X⪰4Y⇔maxX⪰minY.X⪰5Y⇔X⪰6Y⇔minX⪰minY.The result follows from Definition 5 and Proposition 3, taking into account that when bothX,Yinclude a maximum and a minimum random variable, Eq. (6) implies that for everyX∈X,Y∈Y,minX⪰Y⇒X⪰Y⇒maxX⪰YandX⪰maxY⇒X⪰Y⇒X⪰minY.□Next we investigate which of the properties of the binary relation ⪰ are also satisfied by its extensions ⪰1,…,⪰6. Obviously, when ⪰ is not reflexive (resp., antisymmetric, transitive), neither are its extensions ⪰i,i=1,…, 6. Conversely, we can establish the following:Proposition 5Let ⪰ be a binary relation on random variables, and let ⪰i,i=1,…, 6 denote its extensions to sets of random variables, given byDefinition 5.(a)If ⪰ is reflexive, so are ⪰3, ⪰4and ⪰6.If ⪰ is antisymmetric, so is ⪰1.If ⪰ is transitive, so are ⪰ifor i=1, 2, 3, 5, 6.First of all, if ⪰ is reflexive, X≡X for any random variable X, and applying Definition 5 we deduce thatX⪰iXfor any i=3, 4, 6 and any set of random variablesX.Secondly, assume that ⪰ is antisymmetric and that two sets of random variablesX,YsatisfyX⪰1YandY⪰1X. Then, X⪰Y and Y⪰X for everyX∈XandY∈Y, and by the antisymmetry property of ⪰, we deduce that X=Y for everyX∈X,Y∈Y. But this can only be ifX={Z}=Yfor some random variable Z. As a consequence, ⪰1 is antisymmetric.Finally, assume that ⪰ is transitive, and let us show that so are ⪰i for i=1, 2, 3, 5, 6. Consider three sets of random variablesX,Y,Z:1.IfX⪰1YandY⪰1Zthen X⪰Y and Y⪰Z for everyX∈X,Y∈Y,Z∈Z. Applying the transitivity of ⪰, we deduce that X⪰Z for everyX∈X,Z∈Z, and as a consequenceX⪰1Z.IfX⪰2YandY⪰2Z, there isX∈Xsuch that X⪰Y for everyY∈Yand there isY∗∈Ysuch that Y∗⪰Z for everyZ∈Z. In particular, X⪰Y∗⪰Z for everyZ∈Z, whence, by the transitivity of⪰,X⪰2Z.IfX⪰3YandY⪰3Z, for everyY∈Ythere is someXY∈Xsuch that XY⪰Y, and for everyZ∈Zthere isYZ∈Ysuch that YZ⪰Z. As a consequence, for everyZ∈Zit holds thatXYZ⪰Z, and thereforeX⪰3Z.The transitivity of ⪰5, ⪰6 is proved similarly to that of ⪰2, ⪰3, respectively. □In addition, it is easy to check that reflexivity, antisymmetry and transitivity do not hold for definitions different than the ones of statements (a), (b) and (c), respectively.Another interesting property in a binary relation is that it is complete, in the sense that given any two elements, either one is preferred to the other or they are indifferent, but they are never incomparable. From Proposition 2, it follows that the incomparable pairs with respect to an extension ⪰i are also incomparable with respect to the stronger extensions. The following result shows that if ⪰ is a complete relation, then its weakest extensions (namely, ⪰3, ⪰4 and ⪰6) also induce complete binary relations:Proposition 6Let ⪰ be a binary relation on random variables, and let ⪰i, i=1,…, 6 be its extensions to sets of random variables given byDefinition 5. If ⪰ is complete, then so are ⪰3, ⪰4and ⪰6.LetX,Ybe two sets of random variables, and assume thatX⪰3Y. Then there is someY∈Ysuch that X⪰Y for allX∈X. But since ⪰ is a complete relation, this means that Y⪰X for allX∈X. As a consequence,Y⪰2X, and applying Proposition 2 we deduce thatY⪰3X. Hence, the binary relation ⪰3 is complete.On the other hand, ifX⪰4Y, we deduce from Proposition 2 that alsoX⪰3Y, whence the above reasoning implies thatY⪰3Xand again from Proposition 2 we deduce thatY⪰4X.The proof that ⪰6 also induces a complete relation is analogous. □Although in this paper we shall focus on the particular application of Definition 5 to the relation ⪰ associated to stochastic dominance or statistical preference, there are other cases of interest. Perhaps the most important one is that where the comparison between pairs of random variables is made by means of their expected utility:X⪰Y⇔E(X)⩾E(Y);it is not difficult to see that Definition 5 gives rise to some well-known generalizations of expected utility that are formulated in terms of lower and upper expectations. Consider two setsX,Yand assume that the expectations of all their elements exist. Then with respect to definition ⪰1 it holds that:X⪰1Y⇔E̲(X)=infX∈XE(X)⩾supY∈YE(Y)=E‾(Y),which relates this notion to the concept of interval dominance in Zaffalon, Wesnes, and Petrini (2003).If we now consider definition ⪰3, it holds thatX⪰3Y⇒E‾(X)=supX∈XE(X)⩾supY∈YE(Y)=E‾(Y).Thus, definition ⪰3 is stronger than the maximax criterium (Satia & Lave, 1973), which is based on comparing the best possibilities in our sets of alternatives. Similarly, if we consider definition ⪰6 it holds that:X⪰6Y⇒E̲(X)=infX∈XE(X)⩾infY∈YE(Y)=E̲(Y).Thus, definition ⪰6 is stronger than the maximin criterium (Gilboa & Schmeidler, 1989), which compares the worst possibilities within the sets of alternatives.Finally, definition ⪰4 implies thatX⪰4Y⇒E‾(X)=supX∈XE(X)⩾infY∈YE(Y)=E̲(Y),so ifXis ⪰4-preferred toYthen it is also preferred with respect to the criterion of E-admissibility from Levi (1980). See Couso and Dubois, 2012; Troffaes, 2007 for related comments.In this subsection, we explore in some detail the case where the binary relation ⪰ is the one associated to the notion of stochastic dominance we have introduced in Definition 2, i.e., the relation ⪰ is defined by ⪰FSD. We shall assume that the utility space Ω′ is [0,1], although the results can be immediately extended to any bounded interval of real numbers.From Montes et al. (2013, Example 1), we can see that the converse implications in Proposition 2 do not hold in general. With respect to the other results, since the relation ⪰FSD is reflexive and transitive, we can apply Proposition 3 and characterize the equivalences between⪰FSD2and⪰FSD3, and also between⪰FSD5and⪰FSD6by means of the existence of a maximum and a minimum value in the setsX,Ywe want to compare. Moreover, we can deduce from Proposition 5 that⪰FSDiis reflexive for i=3, 4, 6 and transitive for i=1, 2, 3, 5, 6. On the other hand, since two different random variables may induce the same distribution function, ⪰FSD is not antisymmetric.Since ⪰FSD also complies with Pareto dominance (Eq. (6)), we deduce from Proposition 4 that when the setsX,Yto compare have both a maximum and a minimum element, we can easily characterize the conditions⪰FSDi, i=1,…, 6 by comparing these maximum and minimum elements only.Finally, note that ⪰FSD is not a complete relation, because there are distribution functions F,G such that F⪰FSDG and G⪰FSDF. As a consequence, Proposition 6 is not applicable in this context.The relations⪰FSDi,i=1,…,6, were already studied in Montes et al. (2013) as a generalization of stochastic dominance towards sets of alternatives. Since stochastic dominance compares the alternatives by means of their associated distribution functions, this extension to an imprecise context may be made in terms of the comparison of sets of distribution functions, which can be equivalently represented by means of their associated p-boxes. We have proved the following:Proposition 7[Montes et al. (2013, Proposition 3)] LetFXandFYbe two sets of cumulative distribution functions, and denote by(F̲X,F‾X)and(F̲Y,F‾Y)the p-boxes they induce by means of Eq.(5). Then the following statements hold:1.FX⪰FSD1FY⇔F‾X⪰FSDF̲Y.FX⪰FSD2FY⇒F̲X⪰FSDF̲Y.FX⪰FSD3FY⇒F̲X⪰FSDF̲Y.FX⪰FSD4FY⇒F̲X⪰FSDF‾Y.FX⪰FSD5FY⇒F‾X⪰FSDF‾Y.FX⪰FSD6FY⇒F‾X⪰FSDF‾Y.Note that the second part of this result can be seen now as a consequence of Propositions 3 and 4.Next, we provide an alternative characterization of imprecise stochastic dominance in terms of the equivalent formulation given in Theorem 1. Recall that given two random variables X and Y, it holds that X⪰FSDY if and only if E(u(X))⩾E(u(Y)) for every non-decreasing function u. When we compare sets of random variables, we must replace these expectations by lower and upper expectations. For any given set of distribution functionsFand any non-decreasing functionu:[0,1]→R, let us denoteE̲F(u)≔infF∈FEPF(u)andE‾F(u)≔supF∈FEPF(u). It is easy to establish the following result:Theorem 8Let us consider two sets of cumulative distribution functionsF1andF2, and letUbe the set of all non-decreasing functionsu:[0,1]→R. The following statements hold:1.F1⪰FSD1F2⇔E̲F1(u)⩾E‾F2(u)for everyu∈U.F1⪰FSD2F2⇒E‾F1(u)⩾E‾F2(u)for everyu∈U.F1⪰FSD3F2⇒E‾F1(u)⩾E‾F2(u)for everyu∈U.F1⪰FSD4F2⇒E‾F1(u)⩾E̲F2(u)for everyu∈U.F1⪰FSD5F2⇒E̲F1(u)⩾E̲F2(u)for everyu∈U.F1⪰FSD6F2⇒E̲F1(u)⩾E̲F2(u)for everyu∈U.Taking into account Eq. (1), the above implications hold in particular when we replace the setUby the subsetU∗of the non-decreasing and bounded mapsu:R→R. This will be useful when comparing random sets by means of stochastic dominance in Section 4.We consider next the case where the basic binary relation to generalize is that associated to statistical preference, as given in Definition 4. Hence, we shall assume in general that the utility space Ω′ is an ordered set, which need not be numerical.Let us denote by⪰SPi,i=1,…,6the conditions obtained by means of Definition 5. Note that ⪰SP is reflexive and complete, but it is neither antisymmetric not transitive. Hence, Proposition 3 does not apply in this case; indeed, we can use statistical preference to show that Proposition 3 cannot be extended to nontransitive relationships:Example 2Consider the random variables X, Y, Z from Example 1 such that X≻SPY≻SPZ≻SPX, and letX={X,Y},Y={X,Z}. Then since X⪰SPX and Y⪰SPZ, we deduce thatX⪰SP3Y; since X≻SPY and Z≻SPX, we see thatX⪰SP2Y; however,Xhas a maximum element, because X≻SPY.On the other hand, since statistical preference complies with Pareto dominance we deduce from Proposition 4 that the different conditions can be reduced to the comparison of the maximum and minimum elements ofX,Y, when these maximum and minimum elements exist. Finally, we deduce from Propositions 5 and 6 that conditions⪰SP3,⪰SP4,⪰SP6induce a reflexive and complete relationship.We can also use statistical preference to show that Proposition 6 cannot be extended to the relations ⪰1,⪰2 nor ⪰5: take the setsX=Y={X,Y,Z}, where the variables X, Y, Z satisfy X≻SPY≻SPZ≻SPX as in Example 1; then the setXhas neither a maximum nor a minimum element, whence it is incomparable with itself with respect to⪰SP2and⪰SP5. Applying Proposition 2, we deduce thatX,Yare also incomparable with respect to⪰SP1.We showed in Theorem 8 that the generalizations of stochastic dominance towards sets of variables are related to lower and upper expectations. Next, we establish a similar result for the generalizations of statistical preference. The result shall be established in terms of lower and upper medians, and for this we shall require that our utility space Ω′ is numerical. Let us consider two sets of alternativesX,Ywith values on Ω′, and let us introduce the following notation:Me(X-Y)={Me(X-Y):X∈X,Y∈Y}.Me̲(X-Y)=infMe(X-Y).Me‾(X-Y)=supMe(X-Y),where the median of a random variable with respect to a probability measure is given by MeP(X)≔{t: P(X⩽t)⩾ 0.5≤P(X≥t)}.Proposition 9LetX,Ybe two sets of random variables defined on a probability space(Ω,A,P)and taking values onR.1.Me̲(X-Y)>0⇒X⪰SP1Y⇒Me‾(X-Y)⩾0.∃X∈Xs.t.Me̲({X}-Y)>0⇒X⪰SP2Y⇒∃X∈Xs.t.Me‾({X}-Y)⩾0.Me‾(X-{Y})>0∀Y∈Y⇒X⪰SP3Y⇒Me‾(X-{Y})⩾0∀Y∈Y.Me‾(X-Y)>0⇒X⪰SP4Y⇒Me‾(X-Y)⩾0.∃Y∈Ys.t.Me̲(X-{Y})>0⇒X⪰SP5Y⇒∃Y∈Ys.t.Me‾(X-{Y})⩾0.Me‾({X}-Y)>0∀X∈X⇒X⪰SP6Y⇒Me‾({X}-Y)⩾0∀X∈X.From Montes et al. (submitted for publication, Theorem 5), given two random variables X, Y,Me‾(X-Y)>0⇒X⪰SPY⇒Me‾(X-Y)⩾0.The result follows from this equation together with Definition 5 and the above definitions of lower and upper median. □Taking into account the properties of the median, we conclude from this result that statistical preference may be seen as a more robust alternative to stochastic dominance or expected utility in the presence of outliers.Since the binary relation associated to statistical preference is complete, we deduce from Proposition 6 that so are the relations⪰SP3,⪰SP4,⪰SP6. Complete relations are interesting because they mean that we can always express a preference between two sets of alternativesX,Y. Another way of deriving a complete relation when we make multiple comparisons is to establish a degree of preference for every pairwise comparison, and to aggregate these degrees of preference into a joint one. This is possible to do by means of an aggregation operator.LetX={X1,…,Xn}andY={Y1,…,Ym}be two finite sets of random variables taking values on an ordered utility space Ω′, and let us compute the statistical preference Q(Xi,Yj) for every pair of variablesXi∈X,Yj∈Yby means of Eq. (2). The set of all these preferences is an instance of profile of preferences (García-Lapresta & Llamazares, 2001), and can be represented by means of the matrixQX,Y≔Q(X1,Y1)Q(X1,Y2)…Q(X1,Ym)⋮⋮⋮⋮Q(Xn,Y1)Q(Xn,Y2)…Q(Xn,Ym).Note that the profile of preferences ofYoverX,QY,X, corresponds to one minus the transposed matrix ofQX,Y, i.e.,1-QX,Yt. We shall show that conditions⪰SP1,…,⪰SP6can be expressed by means of an aggregation operator over the profile of preference:Definition 6Calvo, Kolesárová, Komorníková, and Mesiar, 2002; García-Lapresta and Llamazares, 2001An aggregation function is a mappingF:∪s∈N[0,1]s→[0,1]. It is called an aggregation operator when it satisfies the following conditions:•xi⩽yi∀i=1,…,s⇒F(x1,…, xs)⩽F(y1,…, ys).[Monotonicity]F(0,…, 0)=0 and F(1,…, 1)=1. [Boundary conditions]The matrixQX,Yrepresenting the profile of preferences betweenXandYcan be equivalently represented by means of a vector on [0,1]nmusing the lexicographic order:z→X,Y=(Q(X1,Y1),Q(X1,Y2),…,Q(X1,Ym),Q(X2,Y1),…,Q(Xn,Ym)).Taking this into account, given an aggregation functionF:∪s∈N[0,1]s→[0,1], we shall denote byF(QX,Y)the image it gives to the vectorz→X,Y.Definition 7Given two finite sets of random variablesX={X1,…,Xn}andY={Y1,…,Ym}and an aggregation function F, we say thatXis F-statistically preferred toY, and denote it byX⪰SPFY, if(7)F(QX,Y)≔F(z→X,Y)⩾12.We refer to Calvo et al. (2002) for a review of aggregation operators. Some important properties are the following:Definition 8Calvo et al., 2002An aggregation functionF:∪s∈N[0,1]s→[0,1]is called:•symmetric if it is invariant under permutations.monotone ifF(r1,…,rs)⩾Fr1′,…,rs′wheneverri⩾ri′for every i=1,…,s.idempotent if F(r,…,r)=r.We shall call an aggregation functionF:∪s∈N[0,1]s→[0,1]self-dual if F(r1,…,rs)=1−F(1−r1,…,1−rs) for every (r1,…,rs)∈[0,1]sand for everys∈N.All these properties are interesting when aggregating the profile of preferences into a joint one: symmetry implies that all the elements in the profile are given the same weight; idempotence means that if all the preference degrees equal r, the final preference degree should also equal r; monotonicity assures that if we increase all the values in the profile of preferences, the final value should also increase; and self-duality preserves the idea behind the notion of probabilistic relation in Definition 3, since for a self-dual aggregation functionF,FQX,Yt+F(QY,X)=1. If in addition F is symmetric, we obtain thatF(QX,Y)+F(QY,X)=1. This last property means that, when F is a self-dual and symmetric aggregation function, Eq. (7) is equivalent toF(QX,Y)⩾F(QY,X).The relations⪰SPi, for i=1,…, 6, can all expressed by means of an aggregation function, as we summarize in the following proposition. Its proof is immediate and therefore omitted.Proposition 10LetX={X1,…,Xn},Y={Y1,…,Ym}be two finite sets of random variables taking values on an ordered space Ω′. Then for anyi=1,…,6X⪰SPiYif and only if it is Fi-statistically preferred toY, where the aggregation functions Fiare given by:F1(QX,Y)≔mini,jQ(Xi,Yj).F2(QX,Y)≔maxi=1,…,nminj=1,…,mQ(Xi,Yj).F3(QX,Y)≔minj=1,…,mmaxi=1,…,nQ(Xi,Yj).F4(QX,Y)≔maxi,jQ(Xi,Yj).F5(QX,Y)≔maxj=1,…,mmini=1,…,nQ(Xi,Yj).F6(QX,Y)≔mini=1,…,nmaxj=1,…,mQ(Xi,Yj).It is not difficult to see that all the aggregation functions Fiabove are monotonic and comply with the boundary conditions Fi(0,…,0)=0 and Fi(1,…,1)=1; they are thus instances of aggregation operators. They are moreover idempotent. On the other hand, only F1 and F4 are symmetric, and none of them is self-dual.We can also use these aggregation operators to deduce the relationships between the different conditions established in Proposition 2 in the case of statistical preference: it suffices to take into account that F1⩽F2⩽F3⩽F4 and F1⩽F5⩽F6⩽F4.The above remarks suggest that other preference relationships may be defined by means of other aggregation operators F, and this would allow us to take all the elements of the profile of preferences into account, instead of focusing on the best or worst scenarios only. Next, we explore briefly one of these possibilities: the arithmetic mean Fmean, given byFmean:∪s∈N[0,1]s→[0,1](r1,…,rs)↪r1+⋯+rss.This is a symmetric, monotone, idempotent and self-dual aggregation operator. For clarity, whenXis Fmean-statistically preferred toYwe shall denote itX⪰SPmeanY. The connection between⪰SPmeanand⪰SPi,i=1,…,6is a consequence of the following result:Proposition 11Given two finite sets of random variablesX={X1,…,Xn}andY={Y1,…,Ym}and a monotone and idempotent aggregation function F,X⪰SP1Y⇒X⪰SPFY⇒X⪰SP4Y.On the one hand, assume thatX⪰SP1Y. Then,Q(X,Y)⩾12for everyX∈XandY∈Y. Since F is monotone and idempotent,F(QX,Y)⩾F12,…,12=12, and consequentlyX⪰SPFY.On the other hand, assume ex-absurdo thatF(QX,Y)⩾12and thatX⪰SP4Y, so thatQ(X,Y)<12for everyX∈XandY∈Y. ThenF(QX,Y)⩽maxi,jQ(Xi,Yj)<12, a contradiction. Hence,X⪰SP4Y. □In particular, we see that⪰SPmeanis an intermediate notion between⪰SP1and⪰SP4. To see that it is not related to⪰SPifor i=2, 3, 5, 6, consider the following example:Example 3Consider Ω={ω1,ω2} (P({ωi})=1/2), and the sets of random variablesX={X1,X2,X3}andY={Y}defined by:ω1ω2X102X200X322Y11Then,QX,Y≔1201andQY,X≔1210whence by Proposition 10X≻SPiY, for i=2, 3, andY≻SPiX, for i=5, 6. On the other hand,Q(X1,Y)+Q(X2,Y)+Q(X3,Y)3=12,and consequentlyX≡SPmeanY. Hence,X⪰SPmeanY⇏X⪰SPiYfor i=5, 6, andY⪰SPmeanX⇏Y⪰SPiXfor i=2, 3. By comparingZ1={X2,Y}andZ2={X3,Y}withX, we can see that the converse implications do not hold:Z1≡SP5,6X≻SPmeanZ1andZ2≻SPmeanX≡SP2,3Z2.In the next two sections, we shall show how the above results can be applied in two different scenarios of imprecision within a decision problem: the case where we have imprecise information about the utilities of the different alternatives, and that where we have imprecise beliefs about the states of nature.Let us start with the first case. Consider a decision problem where we must choose between two alternatives X and Y whose respective utilities depend on the values ω of the states of nature. Assume that we have precise information about the probabilities of these states of nature, so that X and Y can be seen as random variables defined on a probability space(Ω,A,P). If we have imprecise knowledge about the utilities X(ω) associated to the different states of nature, one possible model would be to associate to any ω∈Ω a set Γ(ω) which is sure to include the ‘true’ utility X(ω). By doing this, we obtain a multi-valued mappingΓ:Ω→P(Ω′), and all we know about X is that it is one of the measurable selections of Ω, i.e., that it belongs to the set(8)S(Γ)={U:Ω→Ω′r.v.:U(ω)∈Γ(ω)foreveryω∈Ω}.This interpretation of multi-valued mappings, as a model for the imprecise knowledge of a random variable is not new, and can be traced back to Kruse and Meyer (1987). This epistemic interpretation contrasts with the ontic interpretation which is sometimes given to random sets as naturally imprecise quantities (Dubois & Prade, 2012).In this paper, we shall consider only multi-valued mappings satisfying a certain measurability condition:Definition 9Let(Ω,A,P)be a probability space,(Ω′,A′)a measurable space andΓ:Ω→P(Ω′)a multi-valued mapping. It is called a random set whenΓ∗(A)≔{ω∈Ω:Γ(ω)∩A≠∅}∈A∀A∈A′.Our comparison of two alternatives with imprecise utilities results thus in the comparison of two random sets Γ1,Γ2, that we shall compare by means of their respective sets of measurable selections S(Γ1), S(Γ2) determined by Eq. (8). For simplicity, we shall use the notation Γ1⪰Γ2 instead of S(Γ1)⪰S(Γ2) when no confusion is possible.Let us begin by studying the comparison of random sets by means of stochastic dominance.Proposition 12Let(Ω,A,P)be a probability space,(Ω′,P(Ω′))a measurable space, with Ω′ a finite subset ofR, and Γ1, Γ2be two random sets. The following equivalences hold:(a)Γ1⪰FSD1Γ2⇔minΓ1⪰FSDmaxΓ2.Γ1⪰FSD2Γ2⇔Γ1⪰FSD3Γ2⇔maxΓ1⪰FSDmaxΓ2.Γ1⪰FSD4Γ2⇔maxΓ1⪰FSDminΓ2.Γ1⪰FSD5Γ2⇔Γ1⪰FSD6Γ2⇔minΓ1⪰FSDminΓ2.The result follows from Proposition 7, taking into account that given a random set Γ taking values on a finite space, the lower distribution function associated to its set S(Γ) of measurable selections is induced by maxΓ and its upper distribution function is induced by minΓ. □Moreover, we can characterize the conditions⪰FSDi,i=1,…,6even for random sets that take values on infinite spaces. To see how this comes out, we must recall first the notion of upper and lower probabilities induced by a random set:Definition 10Dempster, 1967Let(Ω,A,P)be a probability space,(Ω′,A)a measurable space andΓ:Ω→P(Ω′)a random set. Then its upper and lower probabilities are the functionsP∗,P∗:A→[0,1]given by P∗(A)=P({ω:Γ(ω)∩A≠∅}) and P∗(A)=P({ω: ∅≠Γ(ω)⊆A}) for everyA∈A.The upper and lower probabilities of a random set are in particular coherent lower and upper probabilities as introduced in Section 2.3, and constitute upper and lower bounds of the probabilities induced by the measurable selections:(9)P∗(A)⩽PX(A)⩽P∗(A)foreveryX∈S(Γ);therefore, their associated cumulative distributions provide lower and upper bounds of the lower and upper distribution functions associated to S(Γ). The inequalities in Eq. (9) may be strict Miranda, Couso, and Gil (2010, Example 1); however, under fairly general conditions(10)P∗(A)=maxP(Γ)(A)andP∗(A)=minP(Γ)(A)foreveryA∈A′,whereP(Γ)(A)≔{PX(A):X∈S(Γ)}. In particular, if Γ takes values on the measurable space ([0,1],β[0,1]), where β[0,1] denotes the Borel σ-field, Eq. (10) holds under any of the following conditions (Miranda et al., 2010):•if the class {Γ(ω): ω∈Ω} is countable;if Γ(ω) is closed for every ω∈Ω;if Γ(ω) is open for every ω∈Ω.Let(Ω,A,P)be a probability space. Consider the measurable space ([0,1],β[0,1]) and letΓ:Ω→P([0,1])be a random set. IfP∗(A)=maxP(Γ)(A)for allA∈A′, then for any bounded random variablef:[0,1]→R:(C)∫fdP∗=supX∈S(Γ)∫fdPX,(C)∫fdP∗=infX∈S(Γ)∫fdPX,and consequently:(C)∫fdP∗=sup(A)∫(f∘Γ)dP,(C)∫fdP∗=inf(A)∫(f∘Γ)dP,where(C)∫fdP∗denotes the Choquet integral of f with respect to P∗, and(A)∫(f∘Γ)dPdenotes the Aumann integral of f∘Γ with respect to P.These results allow us to characterize the imprecise stochastic dominance between random sets by means of the comparison of Choquet or Aumann integrals. Recall that we have denoted byU∗the set of non-decreasing and bounded random variablesu:[0,1]→R.Proposition 14Let(Ω,A,P)be a probability space. Consider the measurable space ([0,1],β[0,1]) and letΓ1,Γ2:Ω→P([0,1])be two random sets. IfP1∗(A)=maxP(Γ1)(A)andP2∗(A)=maxP(Γ2)(A)for all A∈β[0,1], the following equivalences hold:1.Γ1⪰FSD1Γ2⇔(C)∫udP1∗⩾(C)∫udP2∗for everyu∈U∗.Γ1⪰FSD2Γ2⇒(C)∫udP1∗⩾(C)∫udP2∗for everyu∈U∗.Γ1⪰FSD3Γ2⇒(C)∫udP1∗⩾(C)∫udP2∗for everyu∈U∗.Γ1⪰FSD4Γ2⇒(C)∫udP1∗⩾(C)∫udP2∗for everyu∈U∗.Γ1⪰FSD5Γ2⇒(C)∫udP1∗⩾(C)∫udP2∗for everyu∈U∗.Γ1⪰FSD6Γ2⇒(C)∫udP1∗⩾(C)∫udP2∗for everyu∈U∗.Consideru∈U∗. We deduce from Theorem 13 that, under the hypotheses of the proposition,(C)∫udPi∗=supX∈S(Γi)∫udPX=E‾S(Γi)(u)and(C)∫udPi∗=infX∈S(Γi)∫udPX=E̲S(Γi)(u)for i=1, 2. The result follows then applying Theorem 8. □Let us discuss next the comparison of random sets by means of statistical preference. When the utility space Ω′ is finite, we obtain a result akin to Proposition 12:Proposition 15Let(Ω,A,P)be a probability space,(Ω′,P(Ω′))a measurable space, with Ω′ finite, and Γ1, Γ2be two random sets. The following equivalences hold:(a)Γ1⪰SP1Γ2⇔minΓ1⪰SPmaxΓ2.Γ1⪰SP2Γ2⇔Γ1⪰SP3Γ2⇔maxΓ1⪰SPmaxΓ2.Γ1⪰SP4Γ2⇔maxΓ1⪰SPminΓ2.Γ1⪰SP5Γ2⇔Γ1⪰SP6Γ2⇔minΓ1⪰SPminΓ2.The result follows from Proposition 4, taking into account that statistical preference satisfies the monotonicity condition of Eq. (6) and that if Γ is a random set taking values on a finite space, then the mappings minΓ, maxΓ belong to S(Γ). □In particular, we deduce that we can focus on the minimum and maximum measurable selections in order to characterize these extensions of statistical preference:Corollary 16Let(Ω,A,P)be a probability space, Ω′ a finite space and letΓ1,Γ2:Ω→P(Ω′)be two random sets. Then for every i=1,…, 6:(11)Γ1⪰SPiΓ2⇔{minΓ1,maxΓ1}⪰SPi{minΓ2,maxΓ2}.These two results are interesting because random sets taking values on finite spaces are quite common in practice; they have been studied in detail in Dempster (1967) and Miranda, Couso, and Gil (2002), and one of their most interesting properties is that they constitute equivalent models to belief and plausibility functions (Nguyen, 2006).Note that the equivalence in Eq. (11) does not hold for the relation⪰SPmeandefined in Section 3.2:Example 4Consider the probability space(Ω,A,P)whereΩ={ω1,ω2},A=P(Ω)and P is the probability distribution given by P({ω1})=P({ω2})=0.5, and let Γ1 be the random set given by Γ1(ω1)={0,1}, Γ1(ω2)={0,2,3,4}, and let Γ2 be single-valued random set given by Γ2(ω1)={1}=Γ2(ω2). Then minΓ1 is the constant random variable on 0, while maxΓ1 is given by maxΓ1(ω1)=1, maxΓ1(ω2)=4. Hence, if we compare {minΓ1,maxΓ1} with Γ2 by means of⪰SPmeanwe obtainQ(minΓ1,Γ2)+Q(maxΓ1,Γ2)2=0+0.752=0.375and thusΓ2≻SPmean{minΓ1,maxΓ1}. On the other hand, the set of selections of Γ1 is given by (where a selection X is identified with the vector (X(ω1),X(ω2))): S(Γ1)={(0,0), (0,2), (0,3), (0,4), (1,0), (1,2), (1,3), (1,4)}, from which we deduce thatΓ1≻SPmeanΓ2.We next consider the case where we want to choose between two alternatives X, Y: Ω→Ω′, and there is some uncertainty about the probability distribution P of the different states of nature ω∈Ω, that we model by means of a setPof probability distributions on Ω. Then we may associate to X a setXof random variables, which correspond to the transformations of X under any of the probability distributions inP; and similarly for Y. We end up thus with two setsX,Yof random variables, and we should establish methods to determine which of these two sets is preferable.1One particular case where this situation may arise is in the context of missing data (Zaffalon & Miranda, 2009). We may divide the variables determining the states of nature in two groups: one for which we have precise information, that we model by means of a probability measure P′ over the different states, and another one about which are completely ignorant, knowing only the values they take, and nothing more. Then we may get to the classical scenario by fixing the value of the variables in this second group: for each of these values the alternatives may be seen as random variables, using the probability measure P′ to determine the probabilities of the different rewards. Hence, by doing this we would transform the two alternatives X and Y into two sets of alternativesX,Y, considering all the possible values of the variables in the second group.1In this situation, we may compare the setsX,Yby means of the generalizations of statistical preference or stochastic dominance we have discussed in Section 3; however, we argue that other notions may make more sense in this context. This is because conditions ⪰1,…,⪰6 are based on considering a particular pair (X1,Y1) inX×Yand on comparing X1 with Y1 by means of the binary relation ⪰. However, any X1 inXcorresponds to a particular choice of a probability measureP∈P, and similarly for anyY1∈Y; and if we use an epistemic interpretation of our uncertainty under which only oneP∈Pis the ‘true’ model, it makes no sense to compare X1 and Y1 based on a different distribution. This is particularly clear in case we want to apply statistical preference, which is based on comparing P(X>Y) with P(Y>X), where P is the initial probability measure.To make this clearer, in this section we may denote our sets of alternativesX≔{(X,P):P∈P}andY≔{(Y,P):P∈P}, meaning that our utilities are precise (and are determined by the variables X and Y, respectively), while our beliefs are imprecise and are modeled by the setP. To avoid confusions, we will now write X⪰PY to express that X is preferred to Y when we consider the probability measure P in the initial probability space. Then we can establish the following definitions2A similar idea can be found in Greco, Mousseau, and Słowiński (2008) in the context of robust ordinal regression; in that case, the set of additive value functions compatible with the available information is obtained and two binary relations between pairs of alternatives are defined, depending on whether an alternative is preferred to another one with respect to all or some of the value functions.2:Definition 11Let ⪰ be a binary relation on random variables. We say that:•Xis stronglyPpreferred toY, and denote itX⪰sPY, when X⪰PY for everyP∈P;Xis weaklyPpreferred, and denote itX⪰wPY, toYwhen X⪰PY for someP∈P.Obviously, the strong preference implies the weak one. To see that they are not equivalent, consider the following simple example:Example 5Let ⪰ be the binary relation associated to statistical preference and consider the variables X, Y in Example 1. If we consider the uniform distribution P1 in all the die outcomes, we obtainQ(X,Y)=2036, so thatX⪰SPP1Y; if we take instead the uniform distribution P2 on the first three outcomes, thenQ(X,Y)=29, and as a consequenceY⪰SPP2X. Hence, X is weakly {P1,P2} statistically preferred to Y, but not strongly so.With respect to the notions established in Section 3, it is not difficult to establish the following result. Its proof is immediate, and therefore omitted.Proposition 17LetX,Ybe the sets of alternatives considered above, and let ⪰ be a binary relation. ThenX⪰1Y⇒X⪰sPY⇒X⪰wPY⇒X⪰4Y.Let us show that the converse implications do not hold:Example 6ConsiderΩ={ω1,ω2,ω3},P≔{P:P(ω1)>P(ω2),P(ω2)∈[0,0.2]}and the alternatives X, Y given byω1ω2ω3X101Y011Then if we consider the sets of alternativesX={(X,P):P∈P}andY={(Y,P):P∈P}and we compare them by means of stochastic dominance, it is clear thatX≻sPY; however, it does not hold thatX⪰FSD1Y: if we consider P1≔(0.3,0.2,0.5) and P2≔(0.1,0,0.9), it holds that (Y,P2)≻FSD(X,P1).Moreover, in this example we also have thatXis strictly weaklyP-preferred toYwhileX≡FSD4Y.If the binary relation ⪰ we start with is complete, so is the weakP-preference. In that case, we obtain thatX≻wPYimplies thatX≻sPY, because ifX≻wPYwe must have that (X,P)≻(Y,P) for everyP∈P.Moreover, whenX≡wPY, we may have strict preference, indifference or incomparability with respect to strongP-preference.In what follows, we study in some detail the notions of weak and strong preference for particular choices of the binary relation ⪰. If ⪰ corresponds to expected utility, strong preference ofXoverYmeans that X is preferred to Y with respect to all the probability measures P inP, and is thus related to the idea of maximality (Walley, 1991); on the other hand, weak preference means that X is preferred to Y (i.e., it is the optimal alternative) with respect to some of the elements ofP; this idea is close to the criterion of E-admissibility (Levi, 1980). See also Remark 3 and (Couso & Dubois, 2012, Section 3.2).When ⪰ is the binary relation associated to stochastic dominance, we obtain the following:Proposition 18Consider a setPof probability measures on Ω, and let X, Y be two real-valued random variables on Ω. Let us defineFX≔FXP:P∈PandFY≔FYP:P∈P, and(F̲X,F‾X),(F̲Y,F‾Y)their associated p-boxes.1.F‾X⩽F̲Y⇒Xis stronglyP-preferred toYwith respect to stochastic dominance.Xis weaklyP-preferred toYwith respect to stochastic dominance⇒F̲X⩽F‾Y.The result follows from Propositions 7 and 17. □Finally, when ⪰ corresponds to statistical preference, we can apply Remark 4, because ⪰ is a complete relation. In addition, we can establish the following result:Proposition 19Consider a setPof probability measures, and letP̲,P‾denote its lower and upper envelopes, given by Eq.(4). Let X, Y be two real-valued random variables on Ω, and let u=I(0,+∞)−I(−∞,0).1.X is stronglyPstatistically preferred toY⇔P̲(u(X-Y))⩾0.X is weaklyPstatistically preferred toY⇒P‾(u(X-Y))⩾0. The converse holds ifP=M(P‾).The result follows simply by considering that if X, Y are random variables on a probability space(Ω,A,P), then, by Eq. (3)X⪰SPPYif and only if P(u(X−Y))⩾0, where we also use P to denote the expectation operator associated to the probability measure P.To see that the converse of the second statement holds whenP=M(P̲), note that the upper envelopeP‾ofPis a coherent lower prevision. From Walley (1991, Section 3.3.3), given the bounded random variable u(X−Y) there is someP∈M(P̲)such thatP(u(X-Y))=P‾(u(X-Y)). □In this section, we shall illustrate the previous results by means of an application to decision making. We shall consider two different scenarios: on the one hand, we shall compare two alternatives in a context of imprecise information about their utilities or probabilities, by means of the results in Sections 4 and 5; on the other hand, we shall consider the comparison of two sets of alternatives, by means of the techniques established in Section 3. Our running example throughout this section is based on Lui, Jin, Zhang, Su, and Wang (2011, Section 4).Let us consider a decision problem where we must choose between n alternatives a1,…, an, whose rewards depend on the values of the states of nature, θ1,…, θm, which hold with certain probabilities P(θ1),…,P(θm).Let us start by assuming that there is uncertainty about these probabilities, that we model by means of a set of probability measuresP. Then, we shall compare any two alternatives by means of the concepts of weak and strongP-preference we have considered in Section 5.Example 7A company must choose where to invest its money. The alternatives are: a1-a computer company; a2-a car company; a3-a fast food company. The rewards associated to the investment depend on an attribute c1: “economic evolution”, which may take the values θ1 – “very good”, θ2 – “good”, θ3 – “normal” or θ4 – “bad”. The probabilities of each of these states are expressed by means of an interval. The rewards associated to any combination (alternative, state) are expressed in a linguistic scale, with values S={s0,s1,s2,s3,s4,s5,s6} (very poor, poor, slightly poor, normal, slightly good, good, very good). The available information is summarized in the following table:θ1θ2θ3θ4[0.1,0.4][0.2,0.7][0.3,0.4][0.1,0.5]a1s4s3s3s2a2s5s4s4s2a3s2s3s5s4Hence, the setPof probability measures for our beliefs is given byP={(p1,p2,p3,p4):p1+p2+p3+p4=1,p1∈[0.1,0.4],p2∈[0.2,0.7],p3∈[0.3,0.4],p4∈[0.1,0.5]}.Since the rewards are expressed in a qualitative scale, we are going to compare the different alternatives by means of statistical preference. We obtain that:Q(a1,a2)=12p4∈[0.05,0.25].Q(a1,a3)=p1+12p2∈[0.2,0.5].Q(a2,a3)=p1+p2∈[0.3,0.6].We deduce that, using statistical preference as our basic binary relation:•a2≻sPa1anda2≻wPa1.a3≻sPa1anda3≡wPa1.a2≡wPa3and they are incomparable with respect to strongP-preference.Consequently, with respect to the strong preference, both the car company and the fast food companies are preferred to the computer company, and they are incomparable to each other. With respect to the weak preference, the car company is also preferred to the computer company, while the fast food company is indifferent to the car and the computer companies.Let us assume next that we have precise information about the probabilities of the different states of nature but that we have imprecise information about the utilities associated to the different rewards. Let us model this case by means of a random set, as we discussed in Section 4.Example 7 (cont)Assume that the probability of the different states of nature is given by:P(θ1)=0.2P(θ2)=0.25P(θ3)=0.3P(θ4)=0.25,but that we cannot determine precisely the consequences associated to each combination (alternative, state). We model the available information by means of a set of possible consequences, that we summarize in the following table:θ1θ2θ3θ40.20.250.30.25a1{s4,s5}{s3}{s2,s3}{s2}a2{s5}{s3,s4}{s3,s5}{s2,s4}a3{s2}{s3}{s3,s5}{s3,s4}Since again we have qualitative rewards, we shall use statistical preference to compare the different alternatives. Taking into account that the utility space is finite, we deduce from Proposition 15 that the comparison of the random sets associated to each of the alternatives reduces to the comparison of the greatest and smallest measurable selections. Moreover, since the utility space is finite,⪰SP2⇔⪰SP3and⪰SP5⇔⪰SP6.Let us compare alternatives a1, a2:Q(mina1,maxa2)=0.Q(mina1,mina2)=0.25.Q(maxa1,maxa2)=0.1.Q(maxa1,mina2)=0.5.Using Proposition 15, we conclude thata2≻SPia1for i=1, 2, 3, 5, 6 anda1≡SP4a2.With respect to alternatives a1 and a3, we obtain that:Q(mina1,maxa3)=0.325.Q(mina1,mina3)=0.325.Q(maxa1,maxa3)=0.325.Q(maxa1,mina3)=0.475.Using Proposition 15, we conclude thata3≻SPia1for i=4 and as a consequence also for i=1,2,3,5,6.Finally, if we compare alternatives a2 and a3, we obtain that:Q(mina2,maxa3)=0.325.Q(mina2,mina3)=0.475.Q(maxa2,maxa3)=0.725.Q(maxa2,mina3)=1.Using Proposition 15, we conclude thata2≻SPia3fori=2,3,a3≻SPia2fori=5,6,a2equivSP4a3and they are incomparable with respect to⪰SP1.The above relationships are summarized in the following table:SP1SP2SP3SP4SP5SP6(a1,a2)≺SP1≺SP2≺SP3≡SP4≺SP5≺SP6(a1,a3)≺SP1≺SP2≺SP3≺SP4≺SP5≺SP6(a2,a3)≁SP1≻SP2≻SP3≡SP4≺SP5≺SP6Hence, both the car and the fast food companies are preferred to the computer one. On the other hand, the preference between the car and fast food companies would depend on our attitude towards risk, which would determine if we focus on the best or the worst-case scenarios.Assume now that we have precise beliefs and utilities but the choice must be made between sets of alternatives instead of pairs. In that case, we shall apply the conditions and results from Section 3.Example 7 (cont)Assume now that we may invest our money in another company a4 in the telecommunications area, and that the choice must be made between two portfolios: one-that we shall denoteX-made by alternatives a1, a2, and another – denoted byY-made by a3, a4. Assume that the rewards associated to each alternative are given by the following table:θ1θ2θ3θ40.20.250.30.25a175605550a280655540a360555055a480554065where the utilities are now expressed in a [0,100] scale.If we compare these alternatives by means of stochastic dominance, we obtain that a1≻FSDa3, a2≻FSDa4 and any other pair (ai,aj) with i∈{1,2}, j∈{3,4} are incomparable with respect to stochastic dominance. Hence,X≻FSDiYfor i=3, 4, 6 and they are incomparable with respect to⪰FSDifor i=1, 2, 5.Note that this example is an instance where⪰FSD2is not equivalent to⪰FSD3and⪰FSD5is not equivalent to⪰FSD6, because there is neither a maximum nor a minimum in the sets of distribution functions associated toX,Y.On the other hand, if we compare the setsX,Yby means of statistical preference, we obtain the following profile of preferences:QX,Y≔0.750.550.750.65.From this we deduce thatX≻SP1Y, and as a consequenceX≻SPiYfor i=2,…, 6 and alsoX≻SPmeanY. Hence, from the point of view of statistical preference the first portfolio should be preferred to the second.

@&#CONCLUSIONS@&#
In this paper, we have presented a number of choice models for decision making under uncertainty when there is imprecision about the probabilities of the states of nature and the utilities of the different alternatives. By considering all the probability measures and utility functions compatible with the available information, any alternative becomes a set of alternatives, and therefore the choice functions between pairs of alternatives must be extended in order to be able to choose between sets of alternatives.We have proposed a number of choice models that accommodate different attitudes towards risk, by focusing on particular alternatives within each of the sets. These extensions can be applied to any choice function between pairs of alternatives. We have focused in particular on two such choice functions: stochastic dominance and statistical preference. The first one has been applied extensively on economics, while the second one is interesting when the utilities are expressed in a qualitative scale. Both of them serve as an alternative to the expected utility model, for which we have commented briefly on some of its possible generalizations to an imprecise context; they may also be regarded as more robust: in the case of stochastic dominance, it is invariant under increasing transformations of the utility function; on the other hand, statistical preference is related to the median, and is less affected by extreme rewards of the alternatives.We think that with these relationships we are now able to effectively choose between two alternatives in any of the possible scenarios of imprecision: in either the probabilities of the states of nature or the utilities of the different alternatives; for qualitative or quantitative utility scales; and for different attitudes towards risk, more or less conservative.From our results, there are a number of open problems which may be of interest: the comparison of more than two sets of alternatives, by means of transitive choice functions; the study of the stochastic dominance of the nth order; the modeling of imprecise beliefs and utilities by means of random sets with an imprecise probability model on the initial space; and a deeper study of the connection with the work on robust ordinal regression.