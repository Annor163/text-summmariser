@&#MAIN-TITLE@&#
Evaluation of speech-based HMI concepts for information exchange tasks: A driving simulator study

@&#HIGHLIGHTS@&#
We compare different speech-based in-car HMI concepts in a driving simulator study.The HMI concepts are evaluated in terms of usability and driver distraction.The comparison of speech dialog strategies revealed only differences in usability.The use of a GUI impaired the driving performance and raised gaze-based distraction.An avatar does not additionally raise driver distraction but is not accepted by users.

@&#KEYPHRASES@&#
Speech dialog system,Driving simulation study,Usability,Driver distraction,

@&#ABSTRACT@&#
Due to the mobile Internet revolution, people tend to browse the Web while driving their car which puts the driver's safety at risk. Therefore, an intuitive and non-distractive in-car speech interface to the Web needs to be developed. Before developing a new speech dialog system (SDS) in a new domain developers have to examine the user's preferred interaction style and its influence on driving safety.This paper reports a driving simulation study, which was conducted to compare different speech-based in-car human–machine interface concepts concerning usability and driver distraction. The applied SDS prototypes were developed to perform an online hotel booking by speech while driving. The speech dialog prototypes were based on different speech dialog strategies: a command-based and a conversational dialog. Different graphical user interface (GUI) concepts (one including a human-like avatar) were designed in order to support the respective dialog strategy the most and to evaluate the effect of the GUI on usability and driver distraction.The results show that only few differences concerning speech dialog quality were found when comparing the speech dialog strategies. The command-based dialog was slightly better accepted than the conversational dialog, which seems to be due to the high concept error rate of the conversational dialog. A SDS without GUI also seems to be feasible for the driving environment and was accepted by the users. The comparison of speech dialog strategies did not reveal differences in driver distraction. However, the use of a GUI impaired the driving performance and increased gaze-based distraction. The presence of an avatar was not appreciated by participants and did not affect the dialog performance. Concerning driver distraction, the virtual agent did neither negatively affect the driving performance nor increase visual distraction.The results implicate that in-car SDS developers should take both speaking styles into consideration when designing an SDS for information exchange tasks. Furthermore, developers have to consider reducing the content presented on the screen in order to reduce driver distraction. A human-like avatar was not appreciated by users while driving. Research should further investigate if other kinds of avatars might achieve different results.

@&#INTRODUCTION@&#
Thanks to the mobile Internet revolution people can access the Internet via their smartphone anywhere at anytime. Smartphones are considered as people's companion and support the user to make life easier in various daily situations. The pervasive use of smartphones also significantly impacts the automotive environment. In order to stay “always connected” people do not even refrain from using their smartphone's Internet functions manually while driving. However, the manual use of smartphone distracts from driving and endangers the driver's safety. According to the Governors Highway Safety Association 25% of U.S. car crashes are related to drivers using their cellphones while driving (Governors, 2011).In order to control the in-car infotainment system in a safe manner speech technology has been applied for in-vehicle use since many years. Previous research proves that controlling an in-car infotainment system by speech distracts less than manual control (Peissner et al., 2011; Barón and Green, 2006). By using speech instead of manually controlling the smartphone, drivers could keep their hands on the wheel and their eyes on the road. In order to increase driver safety it is essential to develop an intuitive and non-distractive in-car speech interface to the Web.Before developing a new speech dialog system (SDS) in a new domain developers have to examine how users would interact with such a system. An Internet user study by Hofmann et al. (2012) in which the subjects had to solve Internet tasks orally, revealed that concerning information exchange tasks (e.g. booking a hotel) conversational and command-based speaking styles were used with equal frequency of occurrence. Command-based utterances consist of short impersonal phrases whereas conversational utterances resemble human–human communication. Because of the equal distribution it is valuable to examine which speech dialog style and strategy is the most suitable for these tasks. In the driving scenario, the most user-friendly and the least distractive speech dialog needs to be found.When designing SDSs several dialog strategies have to be taken into consideration: system-directed, user-directed and a mixed-initiative dialogs (McTear, 2004). For applications in which multiple parameters have to be collected, such as information exchange tasks, López-Cózar Delgado and Araki (2005) suggest to use a mixed-initiative or a system-directed dialog strategy. Mixed-initiative dialogs are the basis for conversational speech dialogs and resemble human-human communication. As this dialog strategy allows users greater input variability, SDS developers attempt to model the automatic speech recognition (ASR) and natural language understanding (NLU) components to cope with conversational utterances. In contrast, system-directed dialogs are less flexible and limit the input possibilities to certain commands and other elliptical utterances, which is why they are also called command-based dialogs. At a first glance due to the flexibility conversational speech interfaces seem to provide greater usability and should be the mean of choice when it comes to the dialog strategy decision. However, Thomson and Wisowaty (1999) argue that conversational speech interfaces lead to user confusion, as users do not know how to talk to such a SDS. Often, users are unfamiliar with the system capabilities and do not exactly know what spoken format is expected by the speech recognizer. In addition, research found out that allowing users to speak freely, leads to inaccuracies in the ASR and NLU components (Aust et al., 1995), which might negatively affect the usability (Berg, 2013). In contrast, system-directed dialogs guide the user and limit the user input to certain commands, which reduces the risks of recognition errors. Sturm et al. (1999) investigate a mixed-initiative SDS for access to train timetable information, which allows users to take the initiative but also guides novice users if the dialog initiative is not taken. They made the experience that the mixed initiative capabilities were used only occasionally by the users. Due to the directive questions the system asks users did not spontaneously make use of the flexibility in the dialog and followed the system-directed questions. As both strategies obviously provide advantages and disadvantages research needs to focus on the direct comparison of these two speech dialog strategies.Studies on the direct comparison of dialog strategies have been conducted by Walker et al. (1997) and Devillers and Bonneau-Maynard (1998). Walker et al. compare a mixed-initiative dialog agent to a system-directed dialog agent. They conclude that the system-initiative dialog is better for inexperienced users. Mixed-initiative is preferred by users as they gain experience using the system successfully. As for the overall dialog quality the mixed-initiative dialog strategy did not surpass the system-directed strategy concerning the overall dialog performance across several tasks. Deviller et al. compare two SDSs allowing the user to retrieve touristic information. One dialog strategy guides the user via system suggestions, the other does not. The authors conclude that user guidance is suitable for novices and appreciated by all kinds of users.However, all the presented research work did not address a dual-task scenario such as accessing the Internet by speech while driving. When performing two tasks in parallel the user's behavior and preferences might be different. When users have to perform a task by speech while driving their car they might prefer a simple and clearly directed dialog with low mental demands, which would speak for a system-directed dialog strategy. Nevertheless, this dialog strategy requires many dialog steps and demands the user's attention for a long time. Using a mixed-initiative dialog, the user is able input multiple parameters at once and thereby, could shorten the speech dialog. However, this dialog strategy is more complex and mentally demands the user, which might have a negative effect on the primary task driving. Depending on the environmental context one or the other strategy might be preferred. Therefore, it is important to find out, which is the most appropriate strategy for information exchange task in the driving scenario.Until today only few research has examined different speech dialog strategies while driving. Research work by Mutschler et al. (2007) investigated speech dialog strategies as part of a multimodal research question. In the EU funding project TALK,22http://talk-project.eurice.eu.Mutschler et al. compared two multimodal systems, one based on a command-based speech dialog, the other based on a conversational speech dialog in a driving scenario. In the experiment, participants had to control the in-car mp3-player by speech or haptic input while driving. Each speech dialog strategy was supported by the same graphical user interface (GUI). The main research goal was to investigate multimodal interaction with the focus on modality selection. Although the conversational dialog was more efficient the command-based dialog was more appreciated by the participants. According to Mutschler et al. a high error rate of the conversational strategy was the reason for the higher acceptance of the command-based dialog. There were no significant differences in the driving performance revealed when using the different SDS. However, the comparison of speech dialog strategies is only achieved on the basis of the available speech turns and is rather a side product of this experiment and therefore, the results have to be handled with care. As the speech recognizer quality has improved enormously within the last five years, the influence of the weak speech recognition performance of Mutschler et al.'s conversational dialog may be less significant today. Furthermore, the use of the same GUI for different dialog strategies could have additionally influenced the result. The GUI should be adapted to the particular dialog strategy in order to benefit from the advantages of the respective strategy the most and to allow for a comparison of optimal systems.This paper reports experimental results from the development and the evaluation of various in-car SDS prototypes and presents follow-on work to the research reported in Hofmann et al. (2014). Besides the comparison of different speech-based human–machine interface (HMI) concepts the capabilities of today's speech recognition and understanding technology are of interest. Therefore, instead of evaluating the different concepts in a Wizard-of-Oz setup real system prototypes are used. The SDS prototypes are based on different speech dialog strategies, a command-based and a conversational dialog, which were evaluated on usability and driver distraction. The systems have been developed for German users and allow to perform a hotel booking by speech. Since it is common in today's in-car infotainment systems the developed SDS prototypes were supported by a GUI, which gives visual feedback to the user to support the speech interaction. In this research, different GUIs (one including a human-like avatar) were designed in order to support the respective dialog strategy the most and to evaluate the effect of the GUI on usability and driver distraction. Objective and subjective dialog measures are applied to assess the dialog quality and user acceptance. In order to assess the level of driver distraction, objective driving performance and subjective workload measures are applied. Additionally, visual demand is assessed by recording the participants’ glances on the screen using an eye tracker. The experiments have been conducted at DFKI, Saarbrücken using the OpenDS33http://www.opends.eu/.driving simulation. The research work is performed within the scope of the EU FP7 funding project GetHomeSafe.44http://www.gethomesafe-fp7.eu.The remainder of the paper is structured as follows: In Section 2, the developed SDS prototypes are described. In this section, first the different speech dialog strategies are described, followed by the description of the GUI concepts. Section 3 presents the experimental procedure. In Section 4 the results are presented and discussed and finally, conclusions are drawn.Booking a hotel requires to input several parameters, which makes it a good use case to highlight the strengths and weaknesses of the command and conversational dialog strategy. Another advantage of the hotel booking use case is that every user has a clear conception, of what is needed to book a hotel. This distinct mental model makes it easier for the user to understand the voice-control concept, simplifies explanations about the functionality of the system and thereby, reduces the risk of misunderstandings in the experiment. In order to access hotel data the online booking service HRS55http://www.hrs.com.has been used as data provider for the SDS. The selected use case covers many different subdialog types (parameter input, list presentation and browsing, etc.). Each SDS prototype concept offers the same functionality: First, the user has to input several search parameters to retrieve a list of hotels. The user can browse the list and ask for detailed information about a certain hotel. If the hotel matches his needs he is able to book the hotel. In addition, the user can change search parameters and thereby recover from errors if they occur.In the following, the developed speech dialog strategies and the different GUI concepts are described.SDS prototypes for German language have been developed including the following SDS features: In order to speak to the system the driver has to press a Push-To-Activate (PTA) button. Furthermore, the driver is able to interrupt the system while prompting the user (“barge-in”). Previous research work (Walker et al., 1997; Devillers and Bonneau-Maynard, 1998; Mutschler et al., 2007) has shown that a command-based dialog strategy based on a system-directed initiative and a conversational dialog strategy based on a mixed initiative should be investigated. When designing the different dialog strategies we particularly focused our attention on the dialog initiative, the possibility to enter multiple input parameters and the acoustic feedback.The dialog behavior of the command-based dialog strategy corresponds to the voice control which can be found in current state-of-the-art in-car SDS. By calling predefined explicit or implicit speech commands, the speech dialog is initiated. There are several synonyms available for each command. System feedback of what was understood is given via the system reaction (e.g. execution of what was demanded) or by spoken (implicit or explicit) feedback in the system's voice prompt. If more information is needed from the user, in order to fulfill the user's demands the system guides the user. This system-directed dialog strategy is adopted to the command-based dialog strategy of a hotel booking. The GUI supports the speech dialog by showing the “speakable” commands as widgets on the screen (see Section 2.2). A sample dialog is illustrated in the following:Driver:Book a hotel.System:Where would you like to book a hotel?Driver:In Stuttgart.System:When do you want to arrive in Stuttgart?Driver:Tomorrow.System:How long would you like to stay in Stuttgart?Driver:Until the day after tomorrow.After the first speech command the driver is guided by the system and executes the next steps which are suggested and displayed by the system. The dialog is mainly system-driven and the input possibilities are restricted to direct answers (no over-answering). Furthermore, the user is only able to set one input parameter within an utterance to keep the dialog simple and lower the mental demand. When the parameters have been input HRS is called to retrieve the list of hotels. The HRS service returns a result list of hotels, which the SDS presents itself one-by-one. For each hotel the most important facts are read out. The user can interrupt the process of reading out by speaking commands for e.g. selecting a presented hotel.A conversation between an agent and a client over the phone is taken as an example for the conversational dialog design. In the conversational dialog strategy, the dialog initiative switches during the speech interaction. The driver is able to speak whole sentences where multiple parameters can be set within one single utterance. Thereby, the dialog can run more natural, flexible and efficient. The driver is informed about what the system has understood by using explicit or implicit feedback and via the system reaction. If the driver has set multiple parameters in his utterance, the system does not repeat all parameters as the system response would be too long. Therefore, the system repeats only the contextually most important parameter. The GUI does not present the “speakable” utterances on the screen. In order to indicate the possible functions, icons are used (see Section 2.2). A sample dialog is illustrated below:Driver:I would like to book a hotel in Stuttgart.System:When do you arrive in Stuttgart?Driver:I arrive tomorrow and leave the day after tomorrow.The user starts the speech interaction by speaking to the system in whole sentences. He can already mention some input parameters when addressing the system for the first time. The system verifies which input parameter are missing in order to send a request to the HRS service. The system prompts the user and collects the missing information. Although the system asks for only one parameter, the user is able to give more or other information than requested. When the parameters have been input HRS is called to retrieve the list of hotels. Equivalent to the command-based dialog, the HRS service returns a result list of hotels, which the SDS presents itself one-by-one. Now, the user can continue the interaction by speaking freely and without having to speak certain commands.The original TRINDI ticklist from (Bohlin et al., 1999), which characterizes the dialog behavior of an SDS with the help of 12 Yes-No-questions, gives a good overview of the implemented dialog features. Both of the SDS prototypes have been developed and differentiated corresponding to this list. The filled out TRINDI ticklist for both dialog strategies is illustrated in Table 1.In this research work, the most important dialog features, which allow to distinguish both dialog strategies have been realized so far. Concerning the dialog design of the conversational dialog, we set a high value on the flexibility to input parameters by speech (e.g. Q2, Q3). In order to achieve a successful human-machine speech dialog an SDS has to be able to interpret utterances dependent on the dialog context (Q1). Dialog features which are no beneficial characteristic of one of the dialog strategies and which do not reveal differences in the evaluation are left out to lower the development effort (e.g. Q5, Q6). Impact of the environment on the speech interaction is not in focus of this research (Q8). The dialog flow of a hotel booking dialog is linear and does not allow for context-relevant branches whereby Q11 becomes superfluous.The speech dialog strategies have been implemented in the Daimler Speech Dialog Framework (SDF) which allows to quickly realize multimodal SDS prototypes.In the Daimler SDF the dialog is modeled as a hierarchy of sub-tasks including roles which can trigger a system reaction if the according user input is given (Ehrlich, 1999). The ASR and NLU module of the SDS prototypes were based on grammars. In order to cover the large variety of possible utterances of conversational speech a linguistic grammar approach (Hofmann et al., 2013) was applied. The grammar-based ASR engine is Nuance's VoCon® 32005 embedded speech recognizer. The embedded TTS engine integrated in the prototypes is Nuance's Vocalizer for Automotive.66http://www.nuance.com.In the next section, the different GUI concepts, which have been designed to support the speech dialog are described.As common in today's in-car infotainment systems a GUI gives visual feedback in order to support the speech dialog strategies the most. Different GUI concepts have been designed and customized corresponding to the dialog strategies only as much as necessary since an objective comparison is targeted. When designing the screens the international standardized AAM-Guidelines (Driver, 2002) were adhered to, which determine the minimum font sizes, the maximum numbers of widgets, etc. in order to minimize distraction.Several GUI concepts have been designed. One concept, which is especially adapted to the command-based dialog and one concept which is adapted to the conversational dialog. Furthermore, the conversational dialog is supported by a human-like avatar to raise the level of naturalness in the interaction. Finally, a concept which gives almost no visual feedback is designed in order to investigate the necessity of a GUI for a successful speech dialog and its influence on driver distraction. The different GUI concepts are described in the following with the aid of screenshots.In the command-based dialog strategy, as common in state-of-the art in-car SDS the “speakable” input is presented on the GUI supporting thus the speech dialog. The most relevant speech commands are displayed on the screen at all times, which may lead to a high visual distraction. In automotive terms, the command-based speech dialog strategy is also called “speak-what-you-see” strategy (Niemann, 2013).When the user has initiated the speech dialog the parameter input process begins and the screen illustrated in Fig. 1appears. Here, the first input parameter “destination” (“Ziel” in German) has to be set by the user after being requested by the system. Afterwards the user is guided step-by-step by the system. When the driver has given the requested information, a new widget appears on the screen and the system asks the driver for the corresponding input (see Fig. 2).When all the parameters are elicited by the system and the hotel service has returned the list of hotels, the possible commands for changing the input parameters (“Suche ändern”), presenting the result list (“Liste”) and starting a new search (“Neue Suche”) become visible in the sub-function line, which is located on the bottom of the screen (see Fig. 3). For instance, by calling the command “Liste” (or synonyms of the command) the list browsing sub-dialog is triggered and the hotel list is displayed (see Fig. 4). Further screens were designed for the remaining sub-dialogs.In the conversational dialog strategy, the driver can speak freely and does not have to call certain commands. There is no need to give the driver a visual feedback of the currently “speakable” input whereby the visual distraction may be lowered. For that reason, the content on the car's head unit screen does not have to indicate the possible options to proceed with the speech dialog. The sub-function line, which was used to indicate the available commands is replaced by only few symbols, which resemble the current GUI state.When the user asks to book a hotel the form filling screen illustrated in Fig. 5appears. This screen represents the main screen at the beginning of the parameter input dialog where the user is already able to input several parameters at once (see Fig. 6). The respective fields of the form are filled in the course of the parameter input as illustrated in Fig. 7.After having input all required (and optional) parameters the system calls the HRS service and retrieves a list of hotels (see Fig. 8). The symbols on the bottom of the screen resemble the GUI states for parameter input/changes and the result list. Depending on the current GUI state the respective symbol is highlighted. Visual feedback is given by updating the fields of the form. For the remaining sub-dialogs further screens were designed.The goal of using a human-like avatar is to raise the naturalness of the human-machine interaction. By expressing gestures and mimics, the avatar contributes to a more human-like interaction. When seeing a human character on the screen, the driver might tend to speak more naturally, as if he would talk to a human being. Previous research by Nicolescu (2009) investigated different in-car user interface concepts for virtual instruction manuals, one including an avatar. The results showed that the avatar-based UI concept was appreciated by the participants of the user study. Therefore, in our research the presence of an avatar might also have a positive effect on the user acceptance. However, the user might be more distracted by a human character on the screen. So far, those positive and negative effects of an SDS with avatar while driving have not been examined.The avatar is only used in combination with the conversational dialog strategy. Therefore, the GUI concept with avatar is based on the conversational dialog GUI. A virtual character designed and developed by Charamel77http://www.charamel.de.is integrated. The avatar overlays the background illustrated in Figs. 5 and 8 but does not cover the widgets, which are currently important for the speech dialog (see Figs. 9 and 10).The human agent is already visible at the very beginning of the speech dialog. The avatar makes certain gestures to give the SDS some human character. For example, when the system asks for inputting the arrival date, the avatar points toward the arrival date widget on the screen. When the user browses the hotel result list, the avatar makes a swipe gesture to support the scrolling in the list as illustrated in Figs. 9 and 10.Another goal of this research was to investigate the need for a visual feedback during the speech interaction. Can a speech dialog without a GUI still be performed effectively and efficient and will users accept such a kind of speech interaction? How strong are the influences of the GUI on driver distraction? In order to answer these questions the two speech dialog strategies are also evaluated “without GUI”. In this case, “without GUI” means that no content information is displayed on the screen. However, the visual feedback, which indicates if the user is allowed to talk is still presented in the top bar of the screen (see Fig. 11).The different GUI concepts have been specified using the Daimler SDF. The GUI of the Daimler SDF is implemented as finite state machine, which can present different background images, image-based widgets or text fields. In order to present the avatar on the screen the avatar engine had to be integrated in the Daimler SDF and the lip movements had to be synchronized with the TTS engine.In this section, the developed speech dialog strategies and GUI concepts have been described. These concepts have been implemented as SDS prototypes and evaluated in a driving simulator study. The driving simulation study setup is described in the following.In this section, the method of the driving simulator experiment is described in detail. First, the target group and the experimental design is described, followed by the description of the used materials and the experimental procedure. Finally, the dependent variables and the derived hypotheses are presented.A study conducted by BITKOM (2011) revealed that especially young German adults (18–35 years) are quite interested in Internet access in the car. The elders’ interest in a connected car is much lower. Therefore, corresponding to the BITKOM study, this driving simulation study was targeted at young German adults at the age of 18–35.In total, 25 German participants (mainly students) participated in the experiment. All participants possessed a valid driver's license. The participants comprised 11 male and 14 female subjects and the average age was 26.0 years (SD=6.0). 52% of the participants were driving their car at least once a week. 68% had little to no experience with speech-controlled devices.

@&#CONCLUSIONS@&#
This paper reports a driving simulation study in which different in-car speech-based HMI concepts for performing information exchange tasks were compared. The paper describes the different concepts, which have been designed for a hotel booking by speech, the driving simulation study, and the results of the experiment.The described HMI concepts are based on different dialog strategies which include speech as main input and output modality. The speech dialog is supported by a GUI which is adapted to the respective speech dialog strategy. The first HMI concept is based on a command-based dialog strategy where the driver is able to start the speech dialog by single commands and is led step-by-step by the system afterwards. The available commands are displayed on the GUI screen. The second dialog strategy, the conversational dialog, allows the driver speaking entire sentences as if he would talk to a human being. Thereby, multiple parameters can be input at once and the dialog initiative may switch frequently. Two different GUI design concepts were targeted to support the conversational dialog. The first concept does not display the commands anymore but uses icons to suggest possible functions of the system to the driver. Based on the first conversational GUI concept, the second concept contributes to a more conversational interaction by displaying additionally a human-like character on the screen. In order to investigate the need for a visual feedback during the speech interaction the two speech dialog strategies were also evaluated without a GUI.The different speech-based HMI concepts were evaluated in a driving simulator study concerning usability and driver distraction. The results show that only few differences concerning speech dialog quality were found when comparing the speech dialog strategies. The command-based dialog was slightly better accepted than the conversational dialog, which seems to be due to the high CER of the conversational dialog. SDSs without GUI also seem to be feasible for the driving environment and are accepted by the users. The comparison of speech dialog strategies did not reveal differences in driver distraction. However, the use of a GUI impaired the driving performance and increased gaze-based distraction. The presence of an avatar was not appreciated by participants and did not affect the dialog performance. Concerning driver distraction, the virtual agent did not negatively affect the driving performance or increase visual distraction.The current results implicate that in-car SDS developers should take both speaking styles into consideration when designing an SDS for information exchange tasks. Furthermore, developers have to consider reducing the content presented on the screen in order to reduce driver distraction.In the future, we will develop a hybrid SDS concept and compare its performance with the SDS prototypes described in this paper. As the results of this research work only allow to make implications for speech dialogs within one application further investigations are needed to examine the most appropriate speech dialog strategy for speech dialogs across applications. Therefore, further experiments on the comparison of speech dialog strategies in the driving environment for cross-application tasks or task switches will be conducted.