@&#MAIN-TITLE@&#
A simulation based approximate dynamic programming approach to multi-class, multi-resource surgical scheduling

@&#HIGHLIGHTS@&#
We model surgical scheduling with multiple patient classes and multiple resources consumed.We develop a version of the least squares approximate policy iteration algorithm.We capture the stochastic nature of both OR time and post-surgery recovery time.We demonstrate the value of our policy over the current policy at a local hospital.

@&#KEYPHRASES@&#
Health care,Dynamic programming,Markov decision processes,Surgical scheduling,Simulation,

@&#ABSTRACT@&#
This paper presents a model and solution methodology for scheduling patients in a multi-class, multi-resource surgical system. Specifically, given a master schedule that provides a cyclic breakdown of total OR availability into specific daily allocations to each surgical specialty, the model provides a scheduling policy for all surgeries that minimizes a combination of the lead time between patient request and surgery date, overtime in the operating room and congestion in the wards. To the best of our knowledge, this paper is the first to determine a surgical schedule based on making efficient use of both the operating rooms and the recovery beds. Such a problem can be formulated as Markov Decision Process model but the size of any realistic problem makes traditional solution methods intractable. We develop a version of the Least Squares Approximate Policy Iteration algorithm and test our model on data from a local hospital to demonstrate the success of the resulting policy.

@&#INTRODUCTION@&#
It is a testament to the affluence of the developed world that we are able to expend so much of our resources on maintaining and improving our health systems. Nonetheless, these systems face increasing and severe strain as advancements in technology combined with an aging population places demands on our health systems that even the most affluent of countries is finding hard to satisfy. These increases in demand have forced hospitals in particular to look more closely at how they manage the resources available to them. Within that pool of resources, there is plenty of evidence that the surgical department, for most hospitals, is the largest cost and revenue department as well as being one of the most resource-intensive (Macario, Vitez, Dunn, and McDonald, 1995). Managing a surgical department efficiently involves determining the appropriate capacity and the optimal scheduling policy in order to satisfy incoming demand. This however is an extremely challenging endeavor for at least two reasons. First, appropriately scheduling patients to surgery appointments involves the consideration of at least three different objectives – meeting priority-specific wait time targets, ensuring that operating room (OR) time is used efficiently with neither too much overtime nor too much idle time and finally, ensuring that recovery bed capacity is sufficient but not excessive. Secondly, resource consumption – both in terms of OR time and recovery time – is highly stochastic further compromising the manager’s ability to make the best use of the available resources.As a result both researchers and managers have tended to work with a simplified version of the surgical scheduling problem. Most hospitals begin by classifying patients into priority categories within their surgical type. Each priority class has a pre-determined wait time target that, in theory, ought not to be exceeded. Patients are then scheduled to appointments in such a way that the targets are met while ensuring that the expected amount of surgical time scheduled into an OR (including necessary time between surgeries) does not exceed the available capacity. While reasonable, such practice is hardly sufficient as it ignores the variability in surgical times as well as the potential impact the schedule will undoubtedly have on post-surgery bed utilization. Evidence of this impact is most easily demonstrated by the fact that one of the primary reasons for surgical cancelations is the absence of an available recovery bed – a direct result of a scheduling policy that does not account for post-surgery recovery time.It is perhaps not surprising that hospitals function based on such a simplified version of the surgical scheduling problem since, even in the research literature, intelligently scheduling multiple classes of clients with varying degrees of urgency, each with a time-window of an acceptable delay, to only a single resource is generally considered to be a challenging managerial problem (Erdelyi and Topaloglu, 2009; Patrick, Puterman, and Queyranne, 2008; Saure, Patrick, and Puterman, 2015; Saure, Patrick, Tyldesley, and Puterman, 2012). Adding sequential resources that are all consumed in a stochastic fashion significantly compounds the complexity of the problem. To our knowledge, this paper represents the first attempt to build a surgical scheduling policy that seeks to take into account the three-pronged nature of the surgical scheduling challenge – maximizing the efficient use of the available capacity in the ORs and in the wards while also seeking to meet the priority-specific wait time targets of each patient. In addition, our methodology does not rely solely on expectations but rather incorporates the stochastic nature of both the surgery and recovery times.The complexity of the surgical scheduling problem has often led researchers to concentrate on one part of the overall process at a time. Indeed, surgical scheduling lends itself well to such segmentation as there are a number of decisions, separated in time, that together determine the surgical schedule. Usually once a year the total operating room (OR) capacity is determined and allocated between the various surgical specialties performed at the hospital. As an example of research in this stream, Lovejoy and Li (2002) provide a model that determines OR capacity while trading-off three performance criteria – patient waiting time to receive a surgery, scheduled procedure start-time reliability and hospital profits. They provide a method for determining the efficient frontier in the three performance dimensions.Second, that capacity allocation is converted into a cyclic master or block schedule (usually a week or a month long) that allocates specific blocks of OR time to each surgical specialty in accordance with the allocation decisions in the first step. As an example, Santibanez, Begen, and Atkins (2007) derive a master schedule based on an integer programming model that seeks to maximize OR utilization conditional on post-surgical resource constraints. Their model bases decisions on the average surgical times for each specialty and the average length of stay post surgery. They demonstrate the importance of choosing the master schedule intelligently in order to avoid weekly fluctuations in hospital occupancy levels. In a similar vein, Chow, Puterman, Salehirad, Huang, and Atkins (2011) use a combination of simulation and a mixed integer programming model to develop a block schedule that minimizes peak occupancy levels in the wards. Their model goes further than most master schedules by defining patient types within each surgical specialty and scheduling at the level of these types rather than the specialty. Thus, they combine step two of the surgical process with step three – the scheduling of patients within each block in order to determine the number of surgeries to perform in a given day. In a high level analysis of step 3, Gerchak, Gupta, and Henig (1996) provide a model that seeks to determine the number of elective surgeries to perform today as a function of the elective wait list and the number of expected emergency surgeries. They demonstrate that the optimal decision rule is not necessarily of a threshold type. However, they do not differentiate between surgical types and do not provide a booking policy for elective surgery. In another study, Gocgun and Ghate (2012) define a set of MDP models that can be used to represent advanced multi-resource scheduling problems (such as scheduling patients to a block) and develop a Lagrangian based approximate dynamic programming method for solving these MDPs. One of their MDP models closely resembles the setting discussed in this paper as it is also an application of advanced scheduling with multiple resources. However, there are a few notable differences. First, though multiple resources are consumed in their model they are done so in a deterministic fashion and all at once. In our setting, resource consumption is assumed to be stochastic and the consumption of bed resources, in particular, covers multiple decision epochs. Finally, in Gocgun and Ghate, they consider delay costs (not meeting a wait time target) and rejection costs (demand that is not accepted). This differs substantially from the cost structure considered in this paper and described below.The final stage is termed the appointment scheduling problem and involves assigning specific start times to each surgery booked into each block. Denton et al. provide a stochastic linear programming approach that assigns specific start times to a set of n patients in order to minimize a combination of patient wait time, physician idle time and overtime (Denton, Viapiano, and Vogl, 2007). They explore heuristic policies associated with the advanced scheduling problem including the dome-shaped policy that clusters patients closer together at the beginning and the end of the day and the “least variable to most variable” rule that orders patients according to the variability of surgical times. In a similar vein, Begen and Queyranne (2011) provide an integer programming approach to the appointment scheduling problem. Initially they assume that the distribution of processing times are integer and follow a known discrete probability distribution. They demonstrate that an optimal solution can be found in polynomial time. They then relax the assumption of a known discrete probability distribution and determine the necessary sample size of surgical times to obtain provably near-optimal solutions with high probability. While they provide an analytical model that can be solved for specific instances, they do not provide any generalizable policy insights.Schutz and Kolisch (Schutz and Kolisch, 2012) provide one of the few papers that combines the last two stages of the scheduling process. They use a continuous time MDP model to derive a policy for accepting/rejecting demand for a single day of service where there are multiple patient classes. They first solve a simplified model with deterministic service times and demonstrate that their policy (derived through a simulation based approximate dynamic programming methodology) does reasonably well in comparison with the optimal solution. They then complicate the model by incorporating stochastic service times and patient no-shows. They use a heuristic rule from the literature to provide an appointment policy in order to estimate the overtime costs. Their model differs from ours in that they consider a single day in isolation and one resource.This paper focuses on a model that addresses step 3 of the surgical scheduling process but using a methodology that is sufficiently robust to potentially allow the model to expand to include steps 2 and 4 as well. Specifically, given a master schedule that provides a cyclic breakdown of total OR availability into daily allocations to each surgical specialty, we look to provide a scheduling policy for all surgeries that minimizes a combination of the lead time between patient request and surgery date, overtime in the ORs and congestion in the wards. In the form presented here, our model assumes an available master block schedule but future work will expand it to incorporate the creation of the block schedule itself. In Section 2, we present an MDP model for the surgical scheduling process followed, in Section 3, by a description of the approximate dynamic programming (ADP) approach to solving the model made necessary due to the size of the state space in the MDP. We utilize the simulation based approach to Policy Iteration briefly outlined in Bertsekas (2007) but coded and adapted to our specific setting. In Section 5, we present the results from testing our policy in a simulation and in Section 6, we provide our policy insights and conclusions.This section presents a Markov Decision Process model for scheduling patients into a pre-determined master schedule in such a way as to minimize a combination of patient lead time, OR overtime, and over-occupancy in the wards. The size of the state space prohibits solving the MDP by standard methods and thus Section 3 presents a simulation-based approximate dynamic programming approach to solving the MDP. Below we provide the five elements of an MDP as well as the resulting optimality equations.We assume that booking decisions are made once a day. The scheduler bases those decisions on the current schedule, the current census in the hospital and the number of patients waiting to be booked. Those patients already booked are categorized according to surgical type. The state of the system is represented by a vector,s→={t,w→,x→,y→},that captures the current day in the master schedule, the booking slate, the hospital census and waiting demand. The scalar t represents the current day in the master schedule. The vectorw→={win}(i,n)∈I×Nrepresents the number of patients of class i with surgery in n days. I represents the number of patient types and N represents the maximum number of days in advance a patient can be booked. The I patient types are divided between the J surgical specialties upon which the master schedule is built. The vectorx→={xin}(i,n)∈I×Mrepresents the number of patients of class i who are in their nth day of post-operative recovery. We assume that there exists a day M such that the probability of discharge after k days is the same for all k ≥ M and let xiMrepresent the number of patients who have remained in the hospital at least M days. It would be possible to expand the model to include multiple downstream bed classes (i.e. ICU, PACU and ward) but this initial model assumes a single bed class in order to reduce the size of the state space. Finally, the vector,y→={yi}i∈Irepresents waiting demand.The scheduler must choose how far in advance to book each waiting patient or whether to simply delay that decision. The vectorb→={bin}(i,n)∈I×Nrepresents the number of class i patients to book n days in advance. The cancelation of surgeries is assumed not to be an option as the collaborating hospital wished to determine a policy and the appropriate capacity in order to avoid such measures. Available OR capacity for surgical specialty j on day n of the master schedule is represented byz→={zjn}(j,n)∈J×N.Actions are constrained by a number of factors. First, there is a capacity constraint:(1)∑i∈I(j)l(i)(bin+win)≤zj,t*∀j∈[J]where t* is equal to t + n if t + n is less than N; otherwise t* equals t + n − N. The value of l(i) is based on the historical length of surgery for each patient type. Depending on the preference of the user, it could represent the average or some percentile of the distribution of the length of surgery. Thus some form of constraint is placed on the expected length of surgery booked into each block though of course the stochastic nature of surgical times means that the actual total service time may still exceed the available capacity. This was deemed necessary as no hospital is going to be content with a policy that allows for an unlimited amount of overtime in the operating rooms.Second, for each patient class there may be inadmissible days (e.g. emergency patients are not booked in advance and elective patients may require a certain number of days between request and procedure date for the pre-operative work). Thus,(2)bin=0∀(i,n)∈[I]×E(i)where E(i) is the set of inadmissible booking dates for patients of class i. Third, bookings need to be less than waiting demand(3)∑n∈[N]0bin≤yi∀i∈[I].Finally, all bookings are required to be integer and positive(4)bin∈Z+∀(i,n)∈[I]×[N]0The stochastic elements of the process are new arrivals and discharges (either from the schedule or from the hospital). The schedule is modeled as a rolling horizon of length N. We present the transition of each part of the state vector separately, beginning with the transition of the current day in the master schedule:(5)t→{t+1,ift≠N;1,ift=N.The current booking schedule transitions according to:(6)w→={wi0,…,wiN}→{wi1−Di1bs+bi1,…,wiN−DiNbs+biN,0}i∈[I]whereDinbsis a random variable representing discharges from the booking schedule for patients from class i who are n days away from surgery. Discharges are the result of patients who, for one reason or another (e.g. additional complications leading to emergency surgery or death), no longer require surgery. Since no one is booked more than N days in advance, the Nth day is always empty at the beginning of a decision epoch. The hospital census transitions according to:(7)x→={xi1,…,xiM(i)}i∈[I]→{wi0+bi0−Di0h,xi1−Di1h,…,xi,M(i)−2−Di,M(i)−2h,∑j=M(i)−1M(i)xij−Dijh}i∈[I]whereDinhis a random variable representing patients from class i who are discharged after n days in the hospital. The new set of patients who are on their first day of recovery are composed of those patients who had surgery on the previous day and who required at 1 day of recovery in hospital,wi0+bi0−Di0h. Recall that xiMrepresents demand that has waited at least M days for service. The waiting demand transitions according to:(8)y→={y1,…,yI}→{yi−∑n∈Nbin−Diwl+Yi}i∈[I]whereDiwlis a random variable representing discharges from the wait list for patients of class i and Yirepresents newly arrived demand.The transition probabilities are thus based on four distributions – the distribution of new arrivals, the distribution of patients reneging from the wait list, the distribution of cancelations of already booked surgeries and the distribution of discharges from the hospital post-surgery. The distribution of new surgical demand is assumed to follow a Poisson distribution while the three discharge distributions can all be modeled using binomial distributions. For instance, the distribution ofDijhwould follow a binomial distribution with the probability of “success” being the probability that a patient of type i has remained j days in the hospital is discharged on day j and the number of trials being equal to the number of such patients currently in the hospital.Each action comes with a potential cost – a cost for delayed booking, a cost for patients booked past the medically recommended wait time target and a cost for exceeding available capacity resulting in overtime or over-occupancy in the wards. We write the costs as:(9)c(s→,a→)=∑i∈[I]fDELAY(i)(yi−∑n∈[N]0bin)+∑(i,n)∈[I]×[N]fLATE(i,n)bin+fOR(w→0+b→0)+fBED[∑(i,n)∈[I]×[M(i)]xin−CB]+where CBrepresents the capacity of the ward.The first term captures the cost of delaying the booking decision, the second the cost of booking a patient late, the third the cost of overtime in the OR and the fourth the cost of exceeding the bed capacity. All costs are easily determined based on the state space, except for the cost associated with overtime in the OR. A full description of how overtime costs are calculated is left till after the description of the methodological approach of this paper in the next section.It is intuitively obvious that fDELAY(i) should be higher for a higher priority patient. However the actual values are fairly subjective as it is difficult to quantify the impact of a delay on a patient’s health. For the fLATE(i, n) we have adopted the same form as in Patrick et al. (2008):fLATE(i,n)={∑k=1n−T(i)γk−1fDELAY(i),foralln>T(i);0,otherwise.where T(i) is the wait time target for a patient of class i. This insures that delaying the booking for n days and then booking within the target results in the same cost as booking a patient n days past the target initially. In contrast to the subjective nature of the delay costs, the costs associated with the utilization of overtime in the operating rooms and the cost associated with exceeding the bed capacity can be easily quantified. Results from Patrick et al. (2008) suggest that the scheduling policy is not likely to be highly sensitive to the actual value of the delay costs as even small values for this cost tend to lead to policies that do not book late.The above describes the elements of a classic MDP model. In the next section, we introduce the version of simulation based approximate dynamic programming used to solve this otherwise intractable MDP.An MDP model can be characterized by a tuple (S, U, P, C) where S is the state space, U is the action space, P is the stochastic dynamics of the model such that Pij(u) gives the transition probability from state i to state j under action u, and C(i, u) gives the immediate cost of taking action u in state i. Future costs are discounted by a scalar discount factor γ. A stationary policy of the MDP is a mapping from states to actions and is denoted by μ: S → U. Given an MDP with these specifications, the goal is to minimize the total discounted cost over the infinite horizon, represented by the value function Jμ: S → ℜ, over the set of admissible policies Π:(10)Minμ∈ΠJμ(i0)=Minμ∈ΠE[∑t=0∞γtC(it,μ(ik))|μ]Here, i0 ∈ S is an initial state and the expectation is over all possible future states {i1, i2, …} given a fixed policy μ ∈ Π. In solving the MDP, the primary interest is the policy μ* which satisfies the minimum in Eq. (10) simultaneously for all states i0 ∈ S . It can be shown that the optimal value function J* associated with μ*, satisfies the Bellman optimality equation (Bellman, 1957):(11)J*(i)=minu∈U(C(i,u)+γ∑j∈SPij(u)J*(j))∀i∈SAs a result, once the optimal value function J* is known, the optimal policy μ* can be found by solving:(12)μ*(i)=argminu∈A(C(i,u)+γ∑j∈SPij(u)J*(j))∀i∈SUnfortunately, to determine optimal policies for realistically systems, the MDP model becomes challenging. For real problems with large state spaces, it is not possible to apply traditional dynamic programming methods directly because of the long computation time and memory requirements. This is referred to as the curse of dimensionality(Powell, 2007). The question of how to address these challenges has been the subject of a great deal of research, leading to the development of the field of Approximate Dynamic Programming (ADP) that provides methodologies for solving previously intractable, large-scale MDP models (Bertsekas and Tsitsiklis, 1996; Sutton and Barto, 1998).In a vast range of practical applications, finding the one-step transition probability matrix required to compute the expectation in Eq. (11) is computationally intractable. In order to help address this problem, many researchers have differentiated between the pre-decision and post-decision state variables. The pre-decision state variable, represented by i, refers to the information required to make a decision u, while the post-decision state variable, i′, refers to the state of the system immediately after a decision u is made. With the help of the post-decision concept, the original transition function can be divided into two steps, given by i′ = fu(i, u) representing the pure effect of a decision u and i = fw(i′, w) representing the effect of the exogenous information w. Exogenous information refers to a set of random variables representing the information that arrives after making decision u and that changes the state of the system prior to the next decision epoch.In our surgical scheduling model the exogenous information consists of the arrival of new demand and discharges from either the booking schedule or the ward that occur between the end of the current day t and the start of a new day t + 1. Hence, having made booking decision bin, the post-decision state would be:(13)w→u={wi1+bi1,…,wi,N+bi,N}i∈[I](14)y→u={yi−∑n∈Nbin}i∈[I]Note that the state components, t andx→,are not directly affected by the action and are thus unchanged from pre- to post-decision state. The transition from post-decision to pre-decision occurs after the arrival of new stochastic information according to:(15)t→t+1(16)w→={wi1u−Di1bs,…,wi,Nu−Di,Nbs,0}i∈[I](17)x→={wi0u+Di0h,xi1−Di1h,…,xi,M(i)−1−Di,M(i)−1h+xi,M(i)−Di,M(i)h}i∈[I](18)y→={y1,…,yI}→{yiu−Diwl+Yi}i∈[I]In this way we are able to derive deterministic optimality equations around the post decision state variable given by:(19)J(i)=minu∈U(C(i,u)+γJ(i′))This is the primary advantage of the post-decision framework along with a reduction in the size of the state space.While the post-decision state helps overcome the curse of dimensionality surrounding the computation of the expectation, there is often an additional tractability challenge due to the size of even the post-decision state space. One means of overcoming this challenge is the use of a function approximation architecture to represent the value function at the cost of losing some precision. The fundamental idea is to assume that the value function has a functional form that can be characterized by a set of parameters similar to that of statistical regression. Thus, instead of computing the value function for every state i ∈ S, ADP methods use a parameterized class of functionsJ˜(.,r)to approximate Jμand the optimal value function J*. In particular for state i, we approximate Jμ(i) and the optimal value function J*(i) by a suitable approximation architectureJ˜(i,r)and then compute a vector of tunable parametersr→to fit the optimal value function so thatJ˜(i,r)≈J*. Thus instead of presenting a look-up table that provides the optimal action for each given state (an impossible task if the state space is large), ADP seeks to provide the optimal parameter valuesr→in order to get the best approximation possible.In general choosing the appropriate approximation architecture is largely dependent on the nature of the problem. In this paper we consider a parameterized class of functions of the formJ˜(i,r)=∑p=1Prpφp(i),wherer→=(r1,…,rp)is the vector of tunable parameters andφ→(i)=(φ1(i),…,φp(i))is the vector of fixed basis functions for state i, also known as the feature vector of state i(Bertsekas and Tsitsiklis, 1996). A reasonable starting point in our model based on the above linear architecture is the following affine approximation:(20)∑p=1Prpφp=r0+∑i∈Iriwwi+∑i∈IriyyiWe choose the basis functions to be the exact value of the number of patients already booked from class i, wi, and the number of patients waiting to be booked from each class yi. This simple approximation has the advantage of being easily interpreted.riwrepresents the marginal cost of occupied OR time by patients from class i, and riyrepresents the marginal cost of having one more patient of class i waiting to be booked. Once the approximation architecture is known, we can replace the original value function with the approximationJ¯(i′)and solve:(21)J(i)=minu∈U(C(i,u)+γJ¯(i′))in order to derive the optimal action in any given state.This subsection describes the simulation-based approximate policy iteration algorithm developed to tune the approximation parameters in this paper. Simulation based approximate policy iteration is an iterative method where each iteration consists of two steps. In the first step the cost of the system is collected by simulating the trajectory of a stationary policy μ, derived from the current value function approximation, over a set period of time. In particular, for each q ∈ Q, where Q represents the number of initial states to be sampled, an initial post-decision state i′ is randomly generated and an estimate of the discounted cost incurred from starting in state i′ is determined through the simulated trajectory. In the second step the parameters in the approximation are tuned by solving the least-squares problem for the set of Q post-decision states and cost estimates. The regression model fits the value function approximation J(i′n(q), r) to the collected cost estimatesCn(q). This results in a new set of parameters characterizing the value function approximation that is used in the next replication of the above steps. This iterative process is repeated until the tunable parameters stabilize. The idea is closely related to classical policy iteration where the first step resembles the policy evaluation and the second step accounts for policy improvement. We start with an arbitrary parameter vectorr→1and generate a sequencer→tof tunable parameter values using the following algorithm:•Step 0.-Initialize the iteration counter n to 1.Initialize tunable parameter vectorr→1arbitrarily.Step 1. (Policy evaluation through simulation)-Step 1a. Set replication counter q = 1.Step 1b. Initialization*Generate post-decision state i′n(q)Find the next pre-decision state associated with i′n(q)Step 1c. Do for t = 1, …, T:*Generate an optimal control utby letting:(22)ut=argMinu∈U{c(it,u)+γJ˜(fu(it,u),rt)}Compute cost associated with action uttaken in current pre-decision state Ct(it, ut)Obtain the next post-decision state using control ut:(23)it′=fu(it,ut)Run simulator to obtain the next pre-decision state using current post decision(24)it+1=fw(i′t,wt)Step 1d. Compute discounted cost incurred by starting from state i′n(q):(25)Cn(q)=∑t=1Tγ(t−1)CtStep 1e. If q ≤ Q, increment q and go to Step 1a.Step 2. (Policy improvement)-Step 2a. (Projection) Compute the tunable parameters at the next iteration by solving the following lest square regression model:(26)r→*=argMinr→{∑q=1Q[Cn(q)−J(i′n(q),r)]2}Step 2b. Update the value of the approximation parameters using step size αn:(27)r→n=(1−αn)r→n−1+αnr→*Step 3. If n < N, increment n and go to Step 1.The computation of the cost of overtime deserves specific mention. In step 1c, the optimal control is chosen based on the expected overtime as the scheduling decision has to be made before the actual surgery times are known. This is approximated by taking the sum of the expected length of surgery for each of the surgeries booked into the block, subtracting the available capacity and taking the positive part. Appropriate turn-around times (the necessary down time between one surgery and the next) are included in this computation. However, in the computation of the actual costs associated with taking a given action, Ct(it, ut), the portion of the costs attributable to overtime is calculated based on simulated surgical times. Thus, the parameters of the approximation architecture are updated based on actual surgical times rather than the expectations. Therefore, the approximated cost-to-go function ought to incorporate the impact of the variance in surgical times that is being ignored when taking the expectation.The method of generating the initial post-decision states at the start of each replication is a crucial part of the algorithm. One intelligent approach is to simulate a policy, known to be a reasonably good policy for the problem in question, for several days (warm-up period) starting from a random initial state and utilize the post-decision state visited by the end of the warm-up period as the initial state. However, there is no such known policy in our problem so for the purpose of generating initial post decision states in each run, we use a distribution that heavily weights realistic states. Thus, for instance, states with booking schedules that are close to empty or are entirely full are avoided. This ensures that the parameters in the approximation are being tuned based on states that are likely to be visited. In particular, the underlying distribution chooses from a set of states where days in the booking slate are one half to nine-tenths full with a higher likelihood of being closer to nine-tenths full the closer to the day of surgery. For the number of patients on the waiting list we used the distribution of arrivals to generate states.The discount factor γ plays an important computational role here in reducing error. In particular, the linear value function approximation includes some error and the discount factor is used to place more emphasis on the present cost rather than future costs. We chose 0.99 as a discount factor in our algorithm.Coding of the algorithm was done in C++ and all computations were performed on an Intel(R) Core(TM) 2 CPU with 1.6 gigahertz. We use IBM ILOG CPLEX (CPLEX, 2011) to solve the linear optimization problem in step 1c of the algorithm. In order to generate the necessary random numbers from a specific distribution especially in finding the next pre-decision function, the GNU Scientific Library (GSL) was used (GNU (2011)). The GNU Scientific Library (GSL) is a numerical library for C and C++ programmers. LAPACK linear algebra package in the Netlib repository was employed to solve the least squares regression problem in Step 2; see Netlib (2012). Once there is a good value function approximation available, it takes less than 3 seconds to solve the least squares regression problem using LAPACK to obtain the new approximation parameters.The replication parameter Q has been set to 50 and the simulation horizon to T = 100 within each replication. The algorithm has been run for 1000 iterations. The CPU time for each iteration of the ADP algorithm was almost 21 minutes including solving the linear optimization problem 5000 times and the enumeration over possible post-decision states.Data was provided by a local hospital and represented one year’s worth of surgeries. From this data set, we were able to determine the distribution of recovery time, length of surgery and the arrival rates for each surgical type and specialty. One of the challenges in populating the proposed ADP model with the required parameters is the high number of patient categories as there are 900 different surgical procedure types identified in our data set spread over 9 different surgical specialties. Modeling this many patient classes is impossible and also unnecessary. Therefore we used the K-means clustering technique to classify patients into a manageable number of classes. This methodology is described in the subsequent sub-section.Since we are interested in managing resources efficiently, it makes sense to classify patients based on resource consumption. Therefore within each surgical specialty, surgery length and post-operative length of stay (LOS) are used as the clustering attributes. The intended result is to classify patients so that there is no class involving multiple surgical specialties and the distributions of surgical time and LOS are reasonably tight within each class. IBM SPSS Modeler and Rapid Miner software were used for the purpose of executing the clustering. Fig. 1illustrates the 3D scatter plot representing the final clusters for the thoracic surgical service. The X axis represents the length of surgery attribute, the Y axis represents the LOS attribute and the Z axis represents clusters. The 3D scatter plot shows dependencies between the three dimensions.Once the classes are determined, it is possible to determine how these classes should be scheduled based on the distribution of their resource consumption and the associated wait time targets. The best fit distribution has been determined using the Anderson Darling and Kolmogorov Smirnov goodness of fit tests. The distribution of demand for most of the classes follows a Poisson distribution and for the remaining groups is very close to Poisson.The distribution of procedure length in class one and two for each specialty follows a Lognormal distribution. Lognormal distributions have been shown in the literature to be the most common distribution for the best estimation of the length of surgery. For example, Strum, May, and Vargas (2000) illustrated that the log-normal model is superior to the normal model for large sets of surgery times. A log-normal distribution has positive support and positive skew both of which are appropriate characteristics of surgery times in that a few cases may take much longer than the average. Due to the longer procedure length of the higher classes, the resulting distribution is slightly skewed to the left which makes it closer to the Weibull distribution.In addition, the probability of a patient of class i being discharged after n days was also determined from the data. The values of M(i) in the MDP model are based on that point in the probability density function where the probability begins to stabilize. For instance Fig. 2shows the distribution of length of stay for the second class of the neurology surgical service. It clearly shows that it stabilizes to a constant value after 30 days.

@&#CONCLUSIONS@&#
