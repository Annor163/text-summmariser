@&#MAIN-TITLE@&#
Automatic sleep staging by simultaneous analysis of ECG and respiratory signals in long epochs

@&#HIGHLIGHTS@&#
We evaluated the potential utility of combining ECG and respiratory signals in sleep staging.These signals are easily recorded and can be useful in home sleep monitoring systems.The SVM-RFE and SVM were used for the ranking and classification of extracted features, respectively.The extracted features from thoracic respiratory signals have higher ranking than ECG-derived respiratory features.The best result was obtained by using HRV and thoracic respiratory signals.

@&#KEYPHRASES@&#
Heart Rate Variability (HRV),ECG-Derived Respiration (EDR),Empirical Mode Decomposition (EMD),Discrete Wavelet Transform (DWT),Detrended Fluctuation Analysis (DFA),Support Vector Machine-Recursive Feature Elimination (SVM-RFE),

@&#ABSTRACT@&#
EEG, EMG, and EOG are very informative signals recorded in polysomnography (PSG) and used for sleep staging. Their reliable acquisition at home, however, is difficult. In comparison, ECG and thoracic respiratory (R) signals are easier to record and can be useful in home sleep monitoring systems. The simultaneous utilization of Heart Rate Variability (HRV) and respiratory (R) signals seems a plausible scenario as both heart rate (HR) and respiration rate (RR) vary during different sleep states. Therefore, we explored the combined discriminative capacity (accuracy, sensitivity, and specificity) of ECG/R signals in automatic sleep staging. As baseline, we classified the wakefulness, Stage 2, SWS (slow wave sleep) and REM sleep by using a Support Vector Machine (SVM) fed with a set of features extracted from: (a) HRV (34-features), (b) HRV/ECG-Derived Respiration (45-features), and (c) combined HRV/R (45-features) signals. Approach (a) produced reasonable discriminative capacity, while approach (b) significantly improved the classification; however, the best outcomes were achieved by using approach (c). Then, we enhanced the SVM classifier with the Recursive Feature Elimination (RFE) method. The classification results were improved with 35 out of the 45 HRV/RS-EDR features. In comparison, best results were obtained by combining 27 out of the 45 features derived from HRV/R signals, in which the optimal feature set selected by the SVM-RFE method, included a combination of time domain, time-frequency, and fractal features, as well as entropies. Overall, these improvements revealed that it is possible to simplify home monitoring of sleep disorders and achieve high discriminative capacity (accuracy=89.32%, specificity=92.88%, and sensitivity=78.64%) in automatic sleep staging by the exclusive recording of cardiorespiratory signals.

@&#INTRODUCTION@&#
Generally, there are three different states of existence: wakefulness, rapid eye movement (REM) sleep and non-rapid eye movement (NREM) sleep. According to the latest standard of the American Academy of Sleep Medicine (AASM), NREM sleep states are divided into three stages (stages 3 and 4 in the Rechtschaffen and Kales [1] standard are scored as SWS, in the AASM standard) [2]. EEG (Electroencephalogram), EMG (Electromyogram) and EOG (Electro-oculogram) signals are among the most important polysomnography (PSG) signals used for sleep staging. High performance can be reached with such recordings but the reliable acquisition of these signals is not easily possible in the home environment. Instead, ECG (Electrocardiogram) and respiration signals, which are much easier to record, can be useful in home sleep monitoring systems.It has been shown that autonomic nervous system (ANS) activity differs during wakeful and sleep states. During NREM sleep, sympathetic input is reduced and parasympathetic activity predominates, resulting in relative stability in the ANS function. REM sleep, in contrast, is characterized by a highly variable sympathetic activation (which can be comparable to or higher than wakefulness levels) punctuated by a phasic parasympathetic discharge, which results in fluctuating cardiovascular and respiratory behaviors. Accelerations and pauses in heart rate and irregular ventilation are therefore characteristic of REM sleep [3]. In addition, by directly recording sympathetic nerve activity for several hours, investigators have provided solid evidence that sympathetic activity is reduced by more than half from wakefulness to SWS stage but increased to levels above waking values during REM sleep [4].Throughout NREM sleep, respiration is controlled entirely automatically, functioning primarily to maintain the level of carbon dioxide in the blood at a slightly higher level than the awake stage and, to a lesser extent, maintain oxygen in the blood at a slightly lower level. There is about a 15% decrease in air volume entering and leaving the lungs per minute during NREM sleep. Overall, respiration, especially during SWS stage, is regular and slightly deeper. The control of respiration during REM sleep is another story. The respiration rate and depth are very irregular and a rapid and shallow pattern tends to prevail. The average air intake and the level of oxygen in the blood can be about the same or less than that of NREM sleep. There may even be pauses in respiration during REM sleep [5].The sleep literature shows that the identification of sleep stages from the ECG is the most recent endeavor in the field and numerous papers have shown that sleep staging depends on ECG-related parameters. For example, Vigo et al. showed the importance of feature extraction from 5-min epochs of HRV (Heart Rate Variability) signals in sleep staging [6]. In addition, it has been shown that the ratio of the power in the LF (low frequency) and HF (high frequency) bands of the heart rate is a valuable feature in sleep staging [7]. Moreover, Penzel et al., by using Detrended Fluctuation Analysis (DFA), showed that the dynamics of HRV signals are different in the wakeful state and sleep stages [8]. They also used spectral analysis and DFA in order to extract information from HRV signals separately for automatic sleep staging and showed that DFA is a better approach than spectral analysis [9]. The importance of R signals has also been probed in some studies. Carskadon et al., for instance, evaluated the use of R signal variability in wakeful and sleep stages in children [10]. They observed that the respiration rate and its regularity decreased from wakefulness to NREM sleep. Miyata et al. showed that R signals were generated from a nonlinear underlying system [11]. Another study evaluated the importance of using approximate entropy of R signals in wakeful and sleep stages [12]. Generally speaking, having nonlinear characteristics does not necessarily mean that the signal has fractal characteristics, however some studies have shown that R signals could exhibit fractal behavior [13–15]. Ordinarily, cardiac and respiratory rhythms can synchronize in different ratios. For some synchronization ratios, a pronounced sleep-stage dependency has been observed with the low degree of synchronization during REM and Wake, higher during LS??, and most pronounced during deep sleep [16,17]. Recent findings in this area have motivated some scholars to classify sleep stages automatically based on HRV [18–20], and by the combination of ECG and respiratory signals [21–23].The objective of this paper is to report our ongoing research efforts on ECG-based automatic sleep staging. Here we evaluate the potential utility of combining ECG and R signals in automatic sleep staging. First, ECG-Derived Respiration (EDR) signals based on the R and S waves of the QRS complex, called the RS-EDR signal, as well as HRV signals, were derived from raw ECG data. Then, we extracted features from RS-EDR, raw R and HRV signals. Following this step, the variability of some of these features in different sleep and wakeful stages was compared. Finally, we performed automatic sleep staging by using HRV signal features alone, in combination with RS-EDR signal features, and then by combining R signal features with HRV signal features. A Support Vector Machine (SVM) classifier was implemented for classification and then a wrapper feature selection method, named SVM Recursive Feature Elimination (SVM-RFE), was used for feature optimization, before classification.Fig. 1shows the block diagram for the automatic sleep staging algorithm used in our research. It comprises of four steps: (1) preprocessing, (2) feature extraction, (3) SVM-RFE-based feature reduction, and (4) SVM-based automatic sleep classification. Below, each block is described in more detail.The Sleep Heart Health Study (SHHS) database was used to provide the sleep data for this investigation [24]. These recordings were selected by considering a Respiratory Disturbance Index 3 Percent (RDI3P11RDI3P was defined as the number of apneas and hypopneas per hour of sleep at 3% oxygen desaturation.) <5 to have near-normal characteristics. Subjects did not use beta-blockers, alpha-blockers or inhibitors. ECG signals from 30 overnight (nocturnal) polysomnographic recordings sampled at 250Hz (Fs=sampling rate) and thoracic excursion data recorded by inductive plethysmography bands and sampled at 10Hz were used as reference R signals. Sleep architecture for these data was determined in each subject according to Rechtschaffen and Kales (R&K) criteria in 0.5-min epochs [1]. For each recording, continuous segments of ECG signals in each sleep cycle were separated first and then, 5-min segments of different sleep stages were selected manually. In this study, a small part of wake stage, which happens during sleep times (or relaxed wakefulness) was considered. There were no continuous 5-min epochs available for Stage 1 in the database that we used. Since, the study was carried out based on using 5-min segments of cardiorespiratory signals; we did not consider Sleep Stage 1 for further analysis. In addition, we did not use some of the 5-min epochs for which the R-detection algorithm was not effective. The remaining 5-min epochs were selected randomly so that the number of feature vectors in the 4 classes would not be too different. Table 1shows the number of 5-min segments of wakeful and different sleep stages for all recordings.Moreover, atrial fibrillation frequently happens in patients with sleep apnea [25–30]. As in our study, the recordings were selected by considering a Respiratory Disturbance Index 3 Percent (RDI3P11) <5 to have near-normal characteristics, we assumed there were no atrial fibrillations in our database.Continuous 5-min segments of ECG signals were filtered by using an FIR band pass filter with low and high cut-off frequencies of 8 and 20Hz, respectively [31]. In order to extract HRV signals, QRS complexes were detected first by using an Enhanced Hilbert Transform (EHT) algorithm [32] and then were quality-assured manually for missing beats correction. RRI (ECG R–R interval) time series were constructed from QRS complexes by using a cubic spline interpolation method with a 2.4Hz sampling rate. As non-stationary characteristics in the form of linear trends or more complex trends disturb HRV signal analysis and cause unwanted effects on the extracted features from these signals, existing trends were removed from interpolated RRI time series [33].During breathing when the lungs fill with and empty of air, the ECG signal recorded from the surface of body is affected by the motion of electrodes with respect to the position of the heart and the variations in thoracic impedance. These effects often appear as ECG amplitude modulation, which is indicative of the R signal. The research literature abounds with efforts for extraction of the R signal from the ECG signal [34–39]. RSampl is a method of EDR extraction, which is presented by Mason et al. [35]. In this method, the amplitude difference between the R wave and the S wave is calculated.(1)ampl(i)=rampl(i)−sampl(i)In the above equation, rampl and sampl are R wave and S wave amplitudes, respectively. The sampl is the minimum amplitude of ECG signals in the 0.1s window immediately following the R wave. The RSampl EDR (RS-EDR) method has been used in other research efforts for detection of sleep disorder breathing (SDB), as it is not sensitive to ECG baseline wander [37].In our investigation here, the EDR signal was extracted by using the RSampl or RS-EDR method from ECG signals. The QRS complexes were detected first from 5-min segments of ECG signals in different sleep stages and wakefulness (as described in Section 2.2) by using an Enhanced Hilbert Transform (EHT) algorithm [32]. Then, each sample point of the RS-EDR signal was obtained by calculating the amplitude difference between the R and S waves (as explained above) and then saved as a vector. The RS-EDR signal is an unevenly sampled sequence, with samples corresponding to the QRS detection times. To generate a smooth EDR waveform, a 2-point moving average was applied to the extracted vector and the RS-EDR time series were interpolated using cubic splines to derive a signal uniformly sampled at 10Hz. The resulting signal was then filtered within respiration rates of 5 and 25 cycles per minute using a Chebyshev Type I band pass filter. Fig. 2shows the results of extraction of the R signal from a 5-min ECG signal by using the RS-EDR method (after IIR filtering).The peaks and valleys in R signals indicate the beginning of an expiration and an inspiration, respectively. However, the detection of peaks and valleys also includes the detection of local optima (upper trace of Fig. 3). To remove false inspirations and expirations from local optima and to separate global optima, the preprocessing was performed as follows (lower trace of Fig. 3) [36–38]:Duration: To be accepted as a correct respiratory cycle, the minimum duration of the cycle was set at 1500ms. Shorter respiratory cycles were eliminated by the removal of a peak and a valley in such a way that the amplitude difference between the remaining successive peaks and valleys was maximal. It should be noted that the duration of respiratory cycles was defined from valley to valley.Amplitude: To satisfy the detection criterion, the amplitude difference between a peak and a valley was supposed to be at least 15% of the previous and the following amplitude difference. Otherwise, the removal of a peak and a valley was performed in order to ensure that a maximal amplitude difference between the 2 optima was obtained.Correa et al. compared directly recorded R signals (chest, abdomen and oronasal airflow) and EDR signals by measuring the mutual correlation coefficient and the spectral coherence. They observed that the EDR signal had the highest correlation with the chest (thoracic) R signal. They also showed that raw R signals did not have perfect correlation with themselves [39]. Considering these findings, we used the thoracic R signal recorded by inductive plethysmography bands and sampled at 10Hz.First, thoracic R signals were filtered by a 10th order Butterworth low pass filter with a 0.8Hz cut-off frequency in order to remove high frequency noise and variations above the respiratory frequency. Then, a 6-point moving average filtering method was used to smooth out the thoracic R signal and remove additional peaks. Finally, since the signal was not calibrated in terms of absolute tidal volume, we normalized it for each subject and considered only relative differences. The thoracic R signal was normalized by first detecting the turning points and then calculating the difference between sequential peaks and troughs. The median peak-to-trough amplitude over the entire record was then determined and the signal was normalized by dividing into this value, so that the median peak-to-trough amplitude was unity [22]. The median was more robust to outliers and did not move (change) unless more than half of the signal contained noise, which in the plethysmogram can be extreme and create very large peak-to-trough values and can skew the mean.Overall, features were extracted from 5-min segments of thoracic R signals in Stage 2, SWS, REM sleep and wakeful stages. First, peaks and valleys of thoracic R signals were detected. Then, the missing detections were corrected by the procedure explained in Section 2.4.1. Finally, the tidal volume (TV) and the respiration rate (RR) were calculated as the amplitude difference between a successive peak and valley, and the number of breaths per minute, respectively. In this study, the mean, the standard deviation and the coefficient of variation (standard deviation 100/mean) of the TV and RR were computed as features.Other features, such as Approximate Entropy (ApEn), Sample Entropy (SampEn), and Shannon Entropy (ShanEn) were extracted from thoracic R signals. Entropy is one of the most important parameters in biological signal processing, which extracts the information generation rate in these systems. For an N-point segment of a time series, with an embedding dimension m and a similarity parameter r, ApEn is given by the following [40]:(2)ApEn(m,r,N)=φm(r)−φm+1(r)φm(r)=[N−(m−1)τ]−1∑i=1N−(m−1)τlnCim(r)where(3)Cim(r)=BiN−(m−1)τ(4)Bi=number ofjsuch thatd|Xi,Xj|≤rIn the above equation (Xi, Xj) are m-dimensional pattern vectors, whose components are time delayed versions of the elements in the original time series with delay τ, a multiple of the sampling time, as follows:Xi=(xi,xi+τ,xi+2τ,…,xi+(m−1)τ)Xi∈RmXj=(xj,xj+τ,xj+2τ,…,xj+(m−1)τ)Xj∈RmAnd d|Xi, Xj| is a measure of the distance between Xiand Xj. For large values of N the ApEn is given by:(5)ApEn(m,r,N)=[N−mτ]−1∑i=1N−mτ−lnAiBiwhere Aiis the number of Xiwithin tolerance r of Xjfor the (m+1) – dimensional pattern vector and Biis the number of Xiwith tolerance r of Xjin the m-dimensional pattern vector.SampEn is another measure of complexity [40], which is very similar to ApEn. The main difference between these two measures is how self-counting is handled in their computation. In calculation of the ApEn, self-counting is included at each iteration to prevent computing the natural logarithm of zero. However, in SampEn calculation, the natural logarithm is computed once and self-counting is excluded by requiring that i≠j in Eq. (5). SampEn is computed by modifying the ApEn formula given in Eq. (5) to:(6)SampEn(m,r,N)=−lnAB=−lnΣi=1N−mτAiΣi=1N−mτBiThe calculation of ApEn and SampEn requires a priori specification of some unknown parameters: m, the embedding dimension (ED) – r, a tolerance value and τ, time delay. In our study, we considered m=2, r=0.2 times the standard deviation of the data and τ=11 [12]. Time delay was determined as the lag at the point at which the autocorrelation function of the respiratory signal was near zero for the first time.Finally, the peak frequency of thoracic R signals and the power value in peak frequency were extracted. The Power Spectral Densities (PSDs) of 5-min segments of R signals were estimated by using the nonparametric method and 1024-point FFT (Fast Fourier Transform). Totally, 11 features were extracted from the 5-min segments of thoracic R signals.The procedure for the feature extraction from RS-EDR signals was the same as that for thoracic R signals.Generally, a 4-feature set was extracted from the HRV signals in 5-min segments as follows: (1) the time domain features included: the median, Inter-Quartile Range (IQR), Mean Absolute Difference (MAD), mean, standard deviation and range; (2) the nonlinear dynamic features included: Detrended Fluctuation Analysis (DFA)-based features (α1 and α2, the details of which were presented in [41]) and entropy measures (Shannon entropy, ApEn and SampEn); (3) the feature extraction by DWT, which included: the normalized values of energy in VLF (very low frequency), LF and HF bands (Wave 1:3) – the ratio of energies in LF/HF (Wave 4) – Shannon entropy in VLF, LF and HF bands (Wave 5:7) – the ratio of entropies in LF/HF(Wave 8); (4) feature extraction by the Empirical Mode Decomposition (EMD) method consisted of normalized values of energy in VLF, LF and HF bands computed by the Hilbert energy spectrum (EMD 1:3) – the ratio of energies in LF/HF (EMD 4) – harmonic parameters such as the central frequency, the deviation of central frequency and the energy in central frequency were extracted from the Hilbert amplitude spectrum (EMD 5–7) – ApEn (EMD 8:11) and SampEn (EMD 12:15) were calculated from the 4 most significant IMFs of the 5-min segments. To calculate ApEn and SampEn from HRV signals, the following values were selected: m=2, r=0.2 times the standard deviation of the data, and τ=1 [42]. Time-frequency methods are suitable for the extraction of cyclical variations. Detrended Fluctuation Analysis is mainly employed to analyze the scaling behavior and detect long-range correlations and irregularities of signals are measured by the calculation of entropy. As a result, it can be safely claimed that these methods are complementary techniques for HRV signal analysis.SVMs are designed for binary-classification problems, assuming the data are linearly separable. Given the training data (xi, yi), i=1,…,l, xi∈Rn, yi∈{+1, −1}, where Rnis the input space, xiis the sample vector and yiis the class label of xi, the separating hyperplane (ω, b) is a linear discriminating function that solves the optimization problem given as:(7)minω,b〈ω,ω〉Subject to yi(〈ω, xi〉+b)≥1, i=1, 2, …, lwhere 〈.,.〉 indicates the inner product operation. The minimal distance between the samples and the separating hyperplane, i.e. the margin, is 1/||ω||.In order to relax the margin constraints for the non-linearly separable data, the slack variables are introduced into the optimization problem:(8)minξ,ω,b〈ω,ω〉+C∑i=1lξisubject to yi(〈ω, xi〉+b)≥1−ξi, i=1, 2, …, l, ξi≥0This leads to a soft margin SVM that is generally discussed and applied. The resulting classifier is called the 1-norm soft margin SVM, and C is the penalty parameter of error. The decision function of the classifier is:(9)sign(Σxi:SVyiαi〈xi,x〉+b)In practice, since real data are often not linearly separable in the input space, the data can be mapped onto a high dimensional feature space, in which they are sparse and possibly more separable. When using a function φ: X→F to map the data onto a high dimensional feature space, the decision function of the classifier becomes:(10)sign(Σxi:SVyiαi〈φ(xi),φ(x)〉+b)The mapping is often not explicitly given. Instead, a kernel function (K(x1, x2)=〈φ(x1), φ(x2)〉) is incorporated to simplify the computation of the inner product value of the transformed data in the feature space and the decision function becomes:(11)sign(Σxi:SVyiαiK(xi,x)+b)When the data are linearly inseparable, a non-linear kernel that maps the data onto the feature space non-linearly can handle the data better than the linear kernels. Gaspar et al. showed that the most common kernels in the literature: linear, polynomial and radial basis function (RBF), yield the best improvements [43]. The RBF kernel (k(x,y)=e−γ||x−y||d) is a reasonable first choice of kernel function [44]. When using the RBF kernel, the parameters d, γ should be set properly. Generally d is set to be 2. Thus the kernel value is related to the Euclidean distance between the two samples, and γ is related to the kernel width. To apply SVM to multi-class classification problems, the problem can be divided into sub-problems, which are binary classification problems. The often suggested implementations for SVM multi-class classification are the one-against-rest and the one-against-one method. Lin et al. [45] showed that the one-against-one method performs the best and can be trained faster than the SVM models in the one-against-rest method.In our study, the SVM separating hyperplane was calculated by solving the quadratic optimization problem. The RBF kernel and the one-against-one method were used for SVM multi-class classification. The dataset was divided into the training (80%) and the test set (20%). Then, the 10-fold cross-validation was used to find optimal parameters (C, γ). In the 10-fold cross-validation, first the training set was divided into 10 subsets of equal size. Sequentially one subset of 10 training subsets was tested using the classifier trained on the remaining 9 subsets. Thus, each instance of the whole training set was predicted once so the cross-validation accuracy was the percentage of data, which were correctly classified. The cross-validation procedure can prevent the over-fitting problem. A “grid-search” on C and γ (C=2−5 2−3,…,215, γ=2−15; 2−13,…,23) was used to find optimal pairings [44]. Various pairs of (C, γ) values were tried and the one with the best cross-validation accuracy was picked. Finally, the SVM was trained by optimal parameters using all the training data (80% feature vectors) and was then tested on the test data (20% feature vectors).Feature reduction has an important role in classification. It reduces computational load and yields good performance for the classifier. Generally, there are three feature selection methods: embedded, filter and wrapper. In embedded-based methods, feature selection is a part of the classifier training process and these methods exploit the knowledge of the specific structure of the learning algorithm. In filter-based methods, a subset of features is selected based on evaluation criterion which is independent of the learning algorithm, and in the wrapper methods, feature selection is based on performance of the classifier [46]. Here, we used the SVM Recursive Feature Elimination (RFE) method, which is a wrapper-based method. The SVM-RFE was developed by Guyon et al., and has been used in gene selection for cancer classification [47]. The description of this method is given below.In the SVM-RFE method, the effect of removing a feature on an objective function is used as a ranking criterion. Guyon, et al. used the weight magnitude of support vectors as ranking criterion [47]. Adnane et al. used the ranking criterion Total Error Rate (TER) [19]. Here, we use the ranking criterion Correct Classification Ratio (CCR). The steps of the SVM-RFE feature selection algorithm are as follows:(a)Remove one feature out of the number of features (NF) with an initial value of NF=45 and compute the ranking criterion (calculated on test data). This operation is repeated for every feature removed.Compare the ranking criterion values obtained for each subset of (NF−1) features and sort out the feature with the highest ranking criterion, which is removed completely. A new subset of (NF−1) features is then treated in step (a). In the case of CCR used as ranking criterion (as we have done here), the subset of (NF−1) features with the higher CCR contains the best features, and the feature that was removed in step (a) from the set (or subset) of NF features is considered as the worst one.

@&#CONCLUSIONS@&#
