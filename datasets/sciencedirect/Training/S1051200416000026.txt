@&#MAIN-TITLE@&#
Audio steganalysis based on reversed psychoacoustic model of human hearing

@&#HIGHLIGHTS@&#
Based on a model with maximum deviation from human auditory system, a new steganalysis method is proposed.The method is tested on wide range of data hiding algorithms and in both targeted and universal scenarios.The proposed method improves detection rate of targeted and universal scenarios by 17.3% and 20.8%.

@&#KEYPHRASES@&#
Audio steganalysis,Universal steganalysis,Audio steganography,Mel frequency cepstrum coefficients,Human auditory system,

@&#ABSTRACT@&#
During the last decade, audio information hiding has attracted lots of attention due to its ability to provide a covert communication channel. On the other hand, various audio steganalysis schemes have been developed to detect the presence of any secret messages. Basically, audio steganography methods attempt to hide their messages in areas of time or frequency domains where human auditory system (HAS) does not perceive. Considering this fact, we propose a reliable audio steganalysis system based on the reversed Mel-frequency cepstral coefficients (R-MFCC) which aims to provide a model with maximum deviation from HAS model. Genetic algorithm is deployed to optimize dimension of the R-MFCC-based features. This will both speed up feature extraction and reduce the complexity of classification. The final decision is made by a trained support vector machine (SVM) to detect suspicious audio files. The proposed method achieves detection rates of 97.8% and 94.4% in the targeted (Steghide@1.563%) and universal scenarios. These results are respectively 17.3% and 20.8% higher than previous D2-MFCC based method.

@&#INTRODUCTION@&#
Subliminal channels are types of covert channels which are used for stealth communication over innocuous-looking insecure channels. This concept was first introduced by Simmons as the prisoner's problem [37]. Two accomplices have been arrested and are kept in separate cells. They want to cook up an escape plan but they can only communicate through a vigilant warden who will deliver only innocuous messages. Steganography is among the ways to implement such subliminal channel. Steganography consists of an embedding algorithm (Aem) that hides a message (m∈M) into an innocent-looking signal called cover (c∈C) and results in a stego signal (s∈S). On the receiver side, another algorithm (Aex) is used to extract hidden message from the stego signal. A steganography system is called secure if the spaces of cover and stego coincide with each other:(1)C=SOn the other hand, steganalysis is the countermeasure of warden to detect presence of any subliminal channel. If cover signals are empirical [4] then for practical steganography systems, assumption of (1) does not hold and there would be a deviation betweenCandS. This discrepancy can be exploited to discriminate between cover and stego signals. IfAemand statistical model ofCare known a-priori, optimum detector can be designed using statistical decision theory, otherwise a set of suitable feature and machine learning techniques should be employed [21].Considering different types of cover media, steganographic systems can be divided into five major categories including image, audio, video, text, and network. Reviewing literature shows that on the contrary to the image, audio steganographic systems have found less attention so far. It is noteworthy that, steganography and steganalysis like many new trends in cryptology such as multimedia encryption systems [18], multimedia secret sharing, and water marking rely heavily on signal processing techniques.Regarding the functionality of steganalysis systems, they are either universal or targeted. In the former one, the detector does not have any prior knowledge aboutAem, while in the latter one the system is designed specifically for detecting signatures of a particular method. Over the past decade, different audio steganalysis systems have been proposed. Based on the nature of their features, they can be divided into two distinct types:1.Methods that extract their features by comparing the input signal with a reference signalMethods based on extracting features directly from the signalSteganalysis by comparing signal with a reference:Extracting a proper reference signal is the main issue in this category. There are different methods to generate the reference signal for this paradigm. One possible solution is applying denoising method to the input signal in order to provide an estimation of the cover signal. The first method in this area was proposed in [28]. They also used audio quality metrics (AQMs) to quantify the deviation between input signal and generated reference signal [29]. In [14], they argued that AQMs have been designed specifically to detect modifications of pure audio contents. They proposed Hausdorff distance for a better representation of dissimilarity between reference and input signal. Johnson et al. proposed another method for creating reference signal. They used a set of bases functions that were localized in both time and frequency domains to capture regularities of audio signals. These bases aimed to estimate a reference for every input signal. The deviation between reference and input signals was modeled by different moments [20]. In another work, a reference signal independent of input signal was applied [1]. Avcıbas showed that if reference is generated from input signal, then the extracted features depend on both message and content of the cover signal. This dependency on the cover signal may diminish generalization property of the system. They used a constant pair of cover-stego signal for referencing. They showed that this technique improves steganalysis results.Steganalysis by direct inspection of input signal:In this scenario, the features are extracted directly from input signals. First, steganalysis was integrated into an intrusion detection system. This work used ratio of ones and zeros in the LSBs to detect steghide [9]. Ru et al. used wavelet and linear prediction techniques to extract correlation between samples of input signals [34]. They employed different statistical moments calculated from the residual signal of every sub-band of wavelet tree for steganalysis. MFCC as one of the most well-known features were examined to improve steganalysis results in [24]. This work also demonstrated that removing speech relevant components of speech signal is beneficial for improving steganalysis. In [13], the first three moments of time and frequency histograms of input signal and its wavelet sub-bands were exploited for proposing a proper steganalysis scheme. Principle component analysis (PCA) was applied to reduce the features' dimension. In [23], it was argued that due to the existence of chaotic phenomena in speech signals, chaotic-based features may be employed to boost detection of audio steganalysis algorithms. It was shown that steganography noise increases chaoticity and dimension of phase space in the stego signals. Then, values of false neighbor fraction and Lyapunov spectrum were used to quantify chaotic characteristics of the analyzed signals. Markov transition probabilities were proposed in [25]. They introduced a metric for measuring complexity of different cover signals and showed that performance of their method maintained good even for complex signals. Liu et al. showed that second order derivative magnifies the differences between spectrum of cover and stego signals [26]. A steganalysis system based on auto regressive time delay neural network was proposed in [31]. A combination of different invariant moments and features was used by Bhattacharyya to model deviation between cover and stego signals [2].Investigating previous audio steganalysis methods shows that:1.As the most basic requirement, the effects of steganography should not be detectable by human perception systems. Therefore, processing a cover and its stego version with a “perfect” model of human perception system virtually should produce the same results, and they should be indistinguishable. For example in [24,26] Mel frequency cepstral coefficients (MFCC) have been used for feature extraction. MFCC is a model that mimics frequency resolution of HAS. Other characteristics of HAS that have been used in steganalysis literature include loudness, pre-masking and post-masking [1,28,29]. For instance, loudness belongs to the category of intensity sensations and it is primarily a psychological characteristic. It is known that HAS has the lowest sensitivity in the high frequencies; therefore, incorporating loudness in the feature extraction wipes out faint noises in the high frequency portions of the signal, a region that is very valuable for steganalysis. These ideas are discussed more thoroughly in the section 2 of this paper.Most of the previous works have investigated only LSB steganography and its different implementations. Furthermore, to address steganography systems that resist active warden, these works have used watermarking methods [1,23,29]. We believe that reliable results for active warden are achieved if robust steganography methods are investigated. The rationale behind this claim is that undetectability is not a prerequisite for watermarking systems. Therefore, reliable detection of watermarking methods does not necessarily lead to a reliable detection of robust steganography methods.Although most of previous works have claimed a universal steganalysis system but all of them (except for [29], to the best of our knowledge) have only reported results of targeted simulations.Continuing on our seminal work [16], this paper aims to address these problems. Specifically the following contributions are made:–A new model with the maximum deviation from HAS is proposed. Then, this model is exploited for extracting a new set of features. Finally, genetic algorithm (GA) is invoked for a near optimum feature selection.The reliability of the proposed steganalysis system is tested on a wide range of steganography methods including LSB, DWT, and DCT domain methods. Also, for the sake of completeness and better comparison with previous works, two watermarking methods are also considered.Both targeted and universal steganalysis scenarios are pursued.The rest of this paper is organized as follows. Section 2 includes some preliminaries on the HAS and its relations with steganographic concepts. Section 3 elaborates on the proposed method. Experimental results are presented in section 4. Discussion follows in section 5 and finally conclusions are made in section 6.Basilar membrane within cochlea of the inner ear is the base for sensory cells of hearing. Previous studies have shown that cochlea operate as a kind of mechanical frequency analyzer [35]. Further studies have discovered that the produced effects in the inner ear are not linear or logarithmic over the whole length of the basilar. In contrast, other scales such as pitch ratio and critical-band can be plotted on linear scales along the basilar membrane. Therefore, in characterizing HAS either the critical-band scale or the pitch ratio scale are more useful than the frequency scale [12].Pitch ratio and Mel Scale:To measure pitch of a pure tone, one possible procedure is to present human subjects with a pure tone of frequencyf1and ask them to adjust a second frequencyf2such thatf2produces half pitch of the first tone. Subjective measurements have shown that at low frequencies, halving of the pitch sensation corresponds to the ratio off1/f2=2while in the frequencies above 1 KHz, this ratio is larger than 2 [12]. According to these observations, for each tone with an actual frequency measured in hertz, a subjective pitch is calculated on a scale called ‘Mel’. Equation (2) shows the mathematical formula for converting a given frequency (f) in hertz to its corresponding Mel value.(2)Mel=1127×ln⁡(1+f700)Mel-frequency cepstral coefficients:Cepstrum is the anagram of the word spectrum which reflects information about the rate of power changes in different spectrum bands. Later, this metric was tweaked to mimic characteristics of HAS. These new coefficients are commonly known as MFCC and have found numerous applications such as speaker identification [33] and speech recognition [30].Assume that F denotes fast Fourier transform, MFCCs are calculated as:(3)Sk=∑F(x(t)).Wk;Cm=F(log⁡(Sk))Where M is the number of filters in the Mel bank, andWkis the triangular weighting function corresponding to the k-th filter. These filters are constructed as follows:–In the target scale (R-Mel or Mel), linearly divide the whole spectrum intoM+1parts.Convert stop and start points of all parts to hertz. This will lead toM+2distinct points.Wkis a triangle such that it starts from i-th point, reaches its peak ati+1th point and returns to zero at thei+2th point. Sometimes these triangles are normalized such that they have areas equal to one.Steganography and Human Auditory SystemReviewing the steganography literature shows that many works have used peak signal to noise ratio (PSNR) or signal to noise ratio (SNR) to imply security of their methods. Furthermore, Zamani et al. investigated the correlation between PSNR and the capacity of audio steganography [41]. They showed that PSNR decreases with increasing the capacity. Logically, increasing the capacity of a certain method enhances its probability of detection. Therefore, it can be inferred that lower values of PSNR lead to higher probability of detection. Based on this assumption, effect of a typical audio steganography system is investigated. Let us model the effect of steganography as an additive noise:(4)s(t)=c(t)+n(t)We take discrete time Fourier transforms from both sides:(5)S(ejw)=C(ejw)+N(ejw)Then, the whole spectrum of the signal is divided into L equally spaced sub bands:(6)(i−1)×πL≤Bi≤i×πL,1≤i≤LWe define sub-band SNR of signal as:(7)SNRi=10log10⁡(∫Bi|C(ejw)|2∫Bi|N(ejw)|2),1≤i≤LIn order to investigate the effect of steganography on different sub bands, a total number of 4169 audio files were embedded with different data hiding methods. The methods included Hide4Pgp [32], Steghide [19], spread spectrum in the frequency domain [27], error-free wavelet method [36], and two watermarking methods of spread spectrum [22], and the DCT-based robust watermarking method (COX) [7]. After dividing the whole spectrum of cover and noise signals into 29 sub-bands, values ofSNRiwere calculated for all files. Fig. 2shows average values ofSNRiover all the files. (Notations are in accordance with those of Table 1.)The main purpose of steganographic communication is to hide the mere existence of a secret message. Therefore, the most primary requirement of a steganographic system is to remain undetectable. Thus, in its most rudimentary form, it is crucial that the human perception system (ears in the case of audio steganography and eyes in the case of image) should not be able to distinguish between the stego and cover signals. In other words, effects of steganography should not be detectable by human perception systems. According to this fact, a true model of human perception system should be indifferent to steganography. Thus, it is very likely that employing features based on human perception systems leads to discarding vital information.Investigating different audio covers shows that as frequency increases, their power spectrums decrease so they can be considered as band-limited signals. On the other hand, investigating noise of steganography indicates that it is a broadband signal. Consequently, it is expected that the value ofSNRidecreases with increasing of the frequency. Fig. 2 supports this claim.Comparing results of Fig. 2 and characteristics of HAS reveals interesting facts. According to Fig. 1, Mel scale has its highest resolution in the lower frequencies and its lowest resolution in the higher frequencies. On the other hand, according to Fig. 2, high frequency portions of the signal tend to reveal the effects of steganography more clearly. Therefore, features based on HAS are not very suitable. It is noteworthy that steganalysis methods [1,28,29] that have incorporated other psychoacoustic characteristics of HAS (such as loudness and masking [12]) in their feature extraction routine, have produced inferior results to MFCC-based systems. We believe these inferior results are due to extracting features from a more accurate model of HAS.Reversed Mel Scale:Based on our previous discussions, we propose an artificial auditory model that has maximum deviation from HAS. Specifically, our suggested model employs a new scale called reversed-Mel scale (R-Mel) that has reversed frequency resolution of HAS. The new scale has its highest resolution in high frequencies and its lowest resolution in low frequencies. IfFSdenotes sampling frequency of the signal, we define the R-Mel value of a given frequency f in hertz as:(8)RMel=1127×ln⁡(1+0.5×Fs−f700)Based on this new scale, a new set of triangular weighting functions is constructed. These new filters are used in equation (3) to produce reversed-Mel frequency cepstral coefficients (R-MFCC). Fig. 1 compares filter banks constructed based on Mel with R-Mel scale. Investigating filers constructed on the Mel scale shows that these filters are more concentrated in the lower frequencies. In other words because triangles in the low frequencies have smaller width, more coefficients will be extracted from low frequencies. Therefore, we say Mel scale has higher frequency resolution in the lower frequencies. On the other hand, filters constructed on the R-Mel scale have exactly the opposite characteristics. That is, the filters have finer resolutions in the higher frequencies and coarser resolutions in the lower frequencies.Our proposed method is based on taking advantages of R-MFCC coefficients discussed in the previous section. We believe that these features provide suitable discrimination between cover and stego audio files.Analysis of the Proposed Features:According to equations (3) and (4), the discriminating factor between the cover and stego is:(9)D=F(log⁡(∑F(c+n).Wk))−F(log⁡(∑F(c).Wk))Using some basic manipulation, (9) reduces to:(10)D=F(log⁡(∑F(c+n).Wk∑F(c).Wk))(11)D=F(log⁡(1+∑F(n).Wk∑F(c).Wk))Now let us investigate equation (11) for both MFCC and R-MFCC cases. According to the discussion of section 2, the most discriminative features would be extracted from high frequency regions; thus, the last weighting function of Mel and R-Mel banks are considered. AssumingFS=44100, andM=29, theW29of MFCC and R-MFCC have non-zero values in the regions of [17 340, 22 050] Hz and [21 869, 22 050] Hz, respectively. Apparently,W29in the MFCC has larger number of non-zero components; therefore, denominator of equation (11) for MFCC feature is larger than the R-MFCC case.(12)∑F(c).W29-MFCC>∑F(c).W29R-MFCCFurthermore, frequency components of noise are much smaller than their cover counterparts; thus, the numerator cannot compensate for this increase in the value of denominator. In other words, in the high frequency regions, the discriminating factors of (11) are larger in R-MFCC case than their MFCC counterparts.(13)D29-RMFCC>D29-MFCCFeature Extraction:After normalizing data to[−1,1], it was segmented into frames of 1024 samples with overlap of 512. Then, R-MFCCs were calculated for each frame. In this paper, 29 different filters were used. Features were calculated as the values of mean, standard deviation, skewness, and kurtosis of each R-MFCC coefficient over all the frames. Previous works have shown that employing second order derivative of the signal leads to better discriminating features [25,26]. Based on this idea, the same procedure was applied on the second order derivative of the input signal. This second set of features is denoted by D2-R-Mel. Fig. 3illustrates the feature extraction procedure.Preprocessing:Investigating the extracted features shows that:1.The values of extracted features from some observations in the same class are significantly different from each other.Different features tend to have different dynamic ranges.Observations with significantly different feature values are called outliers. Outliers are either results of noisy measurements or distribution with long tails [39]. Removing the noise and outliers during training allows the learning algorithm to find more accurate classification boundaries [38]. Therefore, in the training phase, outliers were removed using the distance-based method implemented in [11]. In this method, distances between all observations from the same class were calculated. If the distance between an observation and more than 10% of other observations was larger than a threshold, it was considered as an outlier. Also, the threshold was defined as the mean of distances plus three times their standard deviation.Another problem in classification stems from features with high values. Such features may influence cost function of the classifier more, regardless of their effectiveness in discrimination. Features were normalized to alleviate this problem. To this end, mean and variance of features over train set were calculated, and then features were normalized according to equation (14):(14)xˆik=xik−mkσkFurthermore, the values ofmkandσkwere retained for applying normalization to test samples.Dataset:Our cover signals consisted of 4169 mono uncompressed audio wave files with frequency of 44 100 Hz and 16 bits resolution. The duration of each excerpt was 10 seconds and they covered wide range of music genres and languages [16]. All covers were embedded with random messages; furthermore, the message was changed for each cover. Different steganography and watermarking algorithms were used to hide message. The steganography algorithms in this study were Hide4Pgp, Steghide, spread spectrum in the frequency domain, error-free wavelet method, and watermarking methods are spread spectrum, and the DCT-based robust watermarking method (COX).Embedding Strength:Expressing embedding strength of steganographic methods can be accomplished through two different metrics of capacity ratio and bit-per-bit percent (BPB). Capacity ratio is the ratio of embedding rate to the maximum capacity of a particular method. Also, BPB is the ratio of message size to the size of cover. Although previous audio steganalysis studies have used capacity ratio for expressing embedding strength, BPB is much more suitable. First, steganography tries to implement a subliminal channel which its efficiency is equal to the ratio of message size to the cover size. Therefore, BPB quantifies objective of steganography more closely. Furthermore, BPB is a universal metric and can be used across different steganography methods and different bit resolutions of cover signals. Thus, BPB provides a meaningful way of comparing different steganography methods. Table 1 presents details of the employed database.Feature Selection:In classification tasks, there are usually some irrelevant or redundant features. In fact, there is no useful information with irrelevant features and also redundant features do not provide further information than the currently selected features. Such features increase complexity of feature extraction (as the most time-consuming part of the system) while they provide no useful information. Furthermore, high dimensional space increases the computational complexity of the classifier and it may also diminish its generalization property [40]. Due to its good performance [17], GA was invoked to choose a near-optimum subset of features. We used accuracy of the classifier as the fitness function, population size of 200 individuals, tournament selection [3], and two-point crossover [15]. For selecting k out of n features, genes were encoded as a decimal array of length k. Initially, this array was filled with k random draws from set of[1,n]without replacement. To further improve the performance of GA, selection operation was followed by elitism [8] which was implemented as directly selecting 1% of the mating population from the best chromosomes. Finally, mutation with rate of 1% was implemented as replacing one of already selected features with one of the remaining ones.Classifier:The process of distinguishing cover from stego samples needs a classifier to define a suitable decision boundary. This work employs support vector machine (SVM) for its superb performance [17]. SVM is basically based on Vapnik's statistical learning theory in which a maximum-margin hyper plane is created to distinguish the training vectors from different classes [6]. Furthermore, if features are not linearly separable, it is possible to map the original problem into a much higher-dimensional space and achieve better classification result. This task is accomplished by applying a suitable kernel function. In this work, SVM is applied by using the non-commercial package LIBSVM [5] with radial basis function (RBF).

@&#CONCLUSIONS@&#
