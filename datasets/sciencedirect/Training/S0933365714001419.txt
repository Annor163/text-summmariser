@&#MAIN-TITLE@&#
Improving the Mann–Whitney statistical test for feature selection: An approach in breast cancer diagnosis on mammography

@&#HIGHLIGHTS@&#
An innovative feature selection method (named uFilter) is proposed.A set of image-based features, from mammography lesions, were explored and successfully ranked.Classification's performance of four different machine learning algorithms increased in almost all scenarios when using the uFilter method.The uFilter method statistically improved the breast cancer classification in mammography.The efficiency of the uFilter method was confirmed by the Wilcoxon statistical test.

@&#KEYPHRASES@&#
Feature selection methods,Mann–Whitney U-test,uFilter method,Machine learning algorithms,Redundancy analysis,Breast cancer CADx,

@&#ABSTRACT@&#
ObjectiveThis work addresses the theoretical description and experimental evaluation of a new feature selection method (named uFilter). The uFilter improves the Mann–Whitney U-test for reducing dimensionality and ranking features in binary classification problems. Also, it presented a practical uFilter application on breast cancer computer-aided diagnosis (CADx).Materials and methodsA total of 720 datasets (ranked subsets of features) were formed by the application of the chi-square (CHI2) discretization, information-gain (IG), one-rule (1Rule), Relief, uFilter and its theoretical basis method (named U-test). Each produced dataset was used for training feed-forward backpropagation neural network, support vector machine, linear discriminant analysis and naive Bayes machine learning algorithms to produce classification scores for further statistical comparisons.ResultsA head-to-head comparison based on the mean of area under receiver operating characteristics curve scores against the U-test method showed that the uFilter method significantly outperformed the U-test method for almost all classification schemes (p<0.05); it was superior in 50%; tied in a 37.5% and lost in a 12.5% of the 24 comparative scenarios. Also, the performance of the uFilter method, when compared with CHI2 discretization, IG, 1Rule and Relief methods, was superior or at least statistically similar on the explored datasets while requiring less number of features.ConclusionsThe experimental results indicated that uFilter method statistically outperformed the U-test method and it demonstrated similar, but not superior, performance than traditional feature selection methods (CHI2 discretization, IG, 1Rule and Relief). The uFilter method revealed competitive and appealing cost-effectiveness results on selecting relevant features, as a support tool for breast cancer CADx methods especially in unbalanced datasets contexts. Finally, the redundancy analysis as a complementary step to the uFilter method provided us an effective way for finding optimal subsets of features without decreasing the classification performances.

@&#INTRODUCTION@&#
Devijver and Kittler define Feature Selection as the problem of “extracting from the raw data the information which is most relevant for classification purposes, in the sense of minimizing the within-class pattern variability while enhancing the between-class pattern variability” [1]. Guyon and Elisseeff consider that “feature selection addresses the problem of finding the most compact and informative set of features, to improve the efficiency or data storage and processing” [2].During the last decade parallel efforts from researchers in statistics, machine learning, and knowledge discovery have been focused on the problem of feature selection and its influence in machine learning classifiers. The recent advances made in both sensing technologies and machine learning techniques make it possible to design recognition systems, which are capable of performing tasks that could not be performed in the past [2]. Feature selection lies at the center of these advances with applications in the pharmaceutical industry [3,4], oil industry [5,6], speech recognition [7,8], pattern recognition [9,10], biotechnology [11,12] and many other emerging fields with significant impact in health systems for cancer detection [13–17].In contrast to other dimensionality reduction techniques like those based on projection (e.g. principal component analysis) or compression (e.g. using information theory), feature selection techniques do not alter the original representation of the variables, but merely select a subset of them. Thus, they preserve the original semantics of the variables, hence, offering the advantage of interpretation by a domain expert [18].There are many potential benefits of feature selection: facilitating data visualization and data understanding, reducing the measurement and storage requirements, reducing training and utilization times, defining the curse of dimensionality to improve the predictions performance [9]. The objectives are related: to avoid overfitting and improve model performance; to provide faster and more cost-effective models, and to gain a deeper insight into the underlying processes that generated the data [18]. Although these benefits, the problem of finding or ranking relevant features is still a challenging task.Regarding their classification, feature selection techniques can be structured into three paradigms, depending on how they combine the feature selection search with the construction of the classification model: wrappers, embedded and filters methods (univariate and multivariate). Wrappers utilize machine learning classifiers as a black box to score subsets of features according to their predictive power. Embedded methods perform feature selection in the process of training and are usually specific to given machine learning classifiers. Filters methods (considered the earliest approaches) use heuristics based on general characteristics of the data rather than machine learning classifiers to evaluate the merit of features [2,9]. Therefore, filter methods in general present lower algorithm complexity and are much faster than wrapper or embedded methods [2,9].Univariate filter methods, such as chi-square (CHI2) discretization [19], t-test [20], information gain (IG) [21] and gain ratio [22], present two main disadvantages: (1) ignoring the dependencies among features and (2) assuming a given distribution (Gaussian in most cases) from which the samples (observations) have been collected. In addition, to assume a Gaussian distribution includes the difficulties to validate distributional assumptions because of small sample sizes. On the other hand, multivariate filters methods such as: correlation based-feature selection [20,23], Markov blanket filter [24], fast correlation based-feature selection [10], ReliefF [25,26] overcome the problem of ignoring feature dependencies introducing redundancy analysis (models feature dependencies) at some degree, but the improvements are not always significant: domains with large numbers of input variables suffer from the curse of dimensionality and multivariate methods may overfit the data. Also, they are slower and less scalable than univariate methods [2,9].To overcome these inconveniences we developed the uFilter method. uFilter is an innovative feature selection method for ranking relevant features that assess the relevance of features by computing the separability between class-data distribution of each feature. We address a theoretical description and experimental evaluation of the uFilter method, and it is described a formal framework for understanding the proposed algorithm, which is supported on the statistical model/theory of the non-parametric Mann–Whitney U-test [27]. A software prototype implementation of the uFilter method using these theoretical intuitions is also presented. The uFilter is an univariate filter method that solves some difficulties remaining on previous methods, such as: (1) it is effective in ranking relevant features independently of the samples sizes (tolerant to unbalanced training data); (2) it does not need any type of data normalization; and (3) the most important, it presents a low risk of data overfitting and does not incur the high computational cost of conducting a search through the space of feature subsets as in the wrapper or embedded methods.The remainder of the paper is organized as follows: Section 2 describes in detail the developed uFilter method as well as the experimental methodology for its evaluation in breast cancer databases; Section 3 presents and discusses the experimental results obtained both from the head-to-head statistical comparison between the proposed method and the theoretical basis (named U-test) method and from the global comparison with other well-known feature selection methods. Finally, in Section 4 we outline the principal achievements of the work.This work considered two public databases: the Breast Cancer Digital Repository (BCDR) and the Digital Database for Screening Mammography (DDSM). The BCDR is the first wide-ranging annotated Portuguese breast cancer repository, with anonymous cases from medical historical archives supplied by Faculty of Medicine – Centro Hospitalar de São João at University of Porto, Portugal [28,29]. For convenience, the DDSM images used in this study were obtained from the Image Retrieval in Medical Applications (IRMA) project (courtesy of TM Deserno, Dept. of Medical Informatics, RWTH Aachen, Germany) where the original LJPEG images of DDSM were converted to 16 bits portable network graphics format [30,31].BCDR is composed of 1734 patient cases with mammography and ultrasound images, clinical history, lesion segmentation and selected pre-computed image-based descriptors; each case may have one or more segmented (outlined) region of interest (ROI) associated to a pathological lesion, typically in mediolateral oblique (MLO) and craniocaudal (CC) images of the same breast [28,29]. We used the dataset BCDR-F01 available online at the BCDR website (http://bcdr.inegi.up.pt), which is composed by 190 patient cases, biopsy proven.DDSM database is composed by 2620 patient cases divided into three categories: normal cases (12 volumes), cancer cases (15 volumes) and benign cases (14 volumes); each case may have one or more associated pathological lesion segmentations, usually in MLO and CC image views of the same breast [30,31]. Due to the wide range of information, we considered a dataset formed with 582 patient cases representing two volumes of cancer and benign cases (random selected).Each instance of the datasets (above mentioned) is composed by a set of 23 image-based descriptors extracted both for the BCDR and DDSM databases. This rather extensive feature list builds upon the radiologists experience and previously reported feature lists embedded in breast cancer computer-aided diagnosis (CADx) systems. Selected descriptors included intensity statistics, shape and texture features computed from segmented pathological lesions in both MLO and CC mammography views. The intensity statistics and shape descriptors were selected according to the radiologists experience (similar to the clinician procedure) and the American College of Radiology (BIRADS-Mammography atlas) [32], which described in detail how to detect/classify pathological lesions. Additionally, texture descriptors were the Halarick's descriptors extracted from the gray-level co-occurrence matrices [33]. An overview of the mathematical formulation is presented below:•Skewness:f1=(1/n)∑i=1n(xi−x¯)3(1/n)∑i=1n(xi−x¯)23with xibeing the ith-value andx¯the sample mean.Kurtosis:f2=(1/n)∑i=1n(xi−x¯)4((1/n)∑i=1n(xi−x¯)2)2−3with xibeing the ith-value andx¯the sample mean.Circularity:f3=4πareaperimeter2Perimeter:f4=length(E)with E⊂O being the edge pixels.Elongation:f5=mMwith m being the minor axis and M the major axis of the ellipse that has the same normalized second central moments as the region surrounded by the contour.Standard deviation:f6=1n−1∑i=1n(xi−x¯)2with xibeing the gray level intensity of the ith pixel andx¯the mean of intensity.Roughness:f7=(perimenter)24π*areaMinimum (f8) and maximum (f9): the minimum and maximum intensity value in the region surrounded by the contour.Shape:f10=perimeter*elongation8*areaX centroid:f11=min(x)+max(x)2with x being the set of X coordinates of the object's contour.Entropy:f12=−∑i=1L∑j=1Lp(i,j)log(p(i,j))with p(i,j) being the probability of pixels with gray-level i occur together to pixels with gray-level j.X center mass (f13) and Y center mass (f14): normalized X and Y coordinates of the center of mass of OAngular second moment:f15=∑i=1L∑j=1Lp(i,j)2with L being the number of gray-levels, and p being the gray-level co-occurrence matrix and, thus, p(i,j) is the probability of pixels with gray-level i occur together to pixels with gray-level j.Median:f16=MED=n+12,iflength(X)isoddMED=Xn2+Xn2+12,iflength(X)isevenwith X being the set of intensities.Contrast:f17=∑i∑j(i−j)2p(i,j)with p(i,j) being the probability of pixels with gray-level i occur together to pixels with gray-level j.Correlation:f18=∑i∑j(ij)p(i,j)−μxμyσxσywith μx, μy, σxand σybeing the means and standard deviations of the marginal distribution associated with p(i,j).Mean:f19=1n∑i=1nxiwith n being the number of pixels inside the region delimited by the contour and xibeing the gray level intensity of the ith pixel inside the contour.Inverse difference moment:f20=∑i∑j11+(i−j)2p(i,j)with p(i,j) being the probability of pixels with gray-level i occur together to pixels with gray-level j.Area:f21=|O|with O being the set of pixels that belong to the segmented lesion.Y centroid:f22=min(Y)+max(Y)2with Y being the set of Y coordinates of the object's contour.Statistical mode (f23): most frequent intensity value in a segmented ROI (lesion).Taking as start point the two initially formed datasets from BCDR and DDSM, we created six new datasets (three from BCDR and three from DDSM respectively) representing three different configurations: (1) two balanced datasets (same quantity of benign and malignant instances), (2) two unbalanced datasets containing more benign than malignant instances and (3) two unbalanced datasets holding more malignant than benign instances. From the BCDR, we created the BCDR1 dataset comprising 362 features vectors, and the BCDR2 and BCDR3 datasets including a total of 281 features vectors (each one). Besides, from the DDSM database, we formed the DDSM1 dataset holding 582 features vectors, and the DDSM2 and DDSM3 datasets involving a total of 491 features vectors respectively. Fig. 1shows a detail description of created datasets.Many types of extracted features (e.g. intensity statistics, shape and texture) from mammograms have been used to form subsets of features with significant information about different lesions [13,15,17,34]. However, selecting the most appropriate subset of features is still a very difficult task; usually a satisfactory instead of the optimal feature subset is searched.Dash and Liu in Ref. [35] stated that an optimal subset is always relative to a certain evaluation function. It is mean that an optimal subset chosen using one evaluation function may not be the same as that which uses another evaluation function. An example of this is the work of Ghazavi and Liao [14], which used different evaluation functions for feature selection purposes, including three modalities of mutual correlation, two variants of Welch t-statistic, two variants of Fisher correlation, the independently consistent expression discriminator, and two distance scores. These functions were evaluated on two binary class medical datasets available at UCI repository: the Wisconsin breast cancer and Pima Indians diabetes, and on a particular industrial dataset: the welding Flaw. The reported results highlighted the mutual correlation method as the best feature selector for the Wisconsin breast cancer and welding flaw datasets respectively. Meanwhile, the best result in the Pima Indians diabetes dataset was achieved by either one of the four statistical criteria.Usually, an evaluation function tries to measure the discriminating ability of a feature or a subset to distinguish the different class’ labels. Thus, the use of different evaluation function provides important information about the nature of each feature (respect to the class) in the features space. We selected different methods with different evaluation function, all of them derived from the filter paradigm (independent of classifiers):•CHI2 discretization: this method consists on a justified heuristic for supervised discretization [19]. Numerical features are initially sorted by placing each observed value into its own interval. Then the chi-square statistic is used to determine whether the relative frequencies of the classes in adjacent intervals are similar enough to justify merging. The extent of the merging process is controlled by an automatically set chi-square threshold. The threshold is determined through attempting to maintain the fidelity of the original data.IG method: the IG measurement normalized with the symmetrical uncertainty coefficient [21] is a symmetrical measure in which the amount of information gained about Y after observing X is equal to the amount of information gained about X after observing Y (a measure of feature−feature intercorrelation). This model is used to estimate the value of an attribute Y for a novel sample (drawn from the same distribution as the training data) and compensates for information gain bias toward attributes with more values.1Rule: this method estimates the predictive accuracy of individual features building rules based on a single feature (can be thought of as single level decision trees) [36]. As it is used training and test datasets, it is possible to calculate a classification accuracy for each rule and hence each feature. Then, from the classification scores, a ranked list of features is obtained. Experiments with choosing a selected number of the highest ranked features and using them with common machine learning algorithms showed that, on average, the top three or more features are as accurate as using the original set. This approach is unusual due to the fact that no search is conducted.Relief: this method uses instance based learning to assign a relevance weight to each feature [25]. Each feature weight reflects its ability to distinguish among the class values. The feature weight is updated according to how well its values distinguish the sampled instance from its nearest hit (instance of the same class) and nearest miss (instance of opposite class). The feature will receive a high weight if it differentiates between instances from different classes and has the same value for instances of the same class. For nominal features it is defined as either 1 (the values are different) or 0 (the values are the same), while for numeric features the difference is the actual difference normalized to the interval [0.1].The discrimination of two different samples is a supervised learning problem, which is defined as the prediction of the value of a function for any valid input after training a learner using examples of input and target output pairs [27]. For the problem at hand, the function has only two discrete values: benign or malignant. Hence the problem of discriminating benign and malignant lesions can be modeled as a two-class classification problem.Among a wide variety of machine learning classifiers that have been applied in mammography-based CADx systems to solve the problem of breast cancer classification; artificial neural networks (ANN) [37–43], support vector machines (SVM) [40,44–46] and linear discriminant analysis (LDA) [16,41,42,47–50] seem to be the most commonly used type of classifiers. Other less used with high performance in breast cancer classification are the Naive Bayes (NB) classifier [37,51–53] and the fuzzy modeling methods [54–57]. However, the latter is very expensive in terms of CPU time consuming, because they are mainly based on rules. An example is the work of Ghazavi and Liao [14] where three fuzzy modeling methods for breast cancer classification were used, achieving a satisfactory AUC value (0.9587) when using the fuzzy k-nearest neighbor algorithm in the Wisconsin breast cancer dataset, but the CPU time consumed was high.We used the ANN, SVM, LDA and NB classifiers implemented and available on the Weka version 3.6 [58]. For all classifiers with the exception of the NB (which is parameterless), a 10-fold cross validation method [59] was applied on the training set for optimizing classifiers’ parameters. A brief description and configuration of employed machine learning classifiers is given here:•The feed forward back-propagation (FFBP) neural network is a particular model of ANN, which provides a nonlinear mapping between its input and output according to the back-propagation error learning algorithm [60]. We used this classifier with the following parameters: neurons on hidden layers were determined according to the equation (attributes+number of classes)/2; one output layer associated with the binary classification (benign or malignant); the sigmoid function was used as transfer function on all layers and the number of iterations (epochs) were optimized in the range of 100–1000 epochs (with an interval increment of 100 units).SVMs are based on the definition of an optimal hyperplane, which linearly separates the training data. In comparison with other classification methods, a SVM aims to minimize the empirical risk and maximize the distances (geometric margin) of the data points from the corresponding linear decision boundary [60]. The SVM classifier was used with the following settings: the regularization parameter C (cost) was optimized in the range of 10−3–103 and the kernel type was based on a linear function, which provided better results respect to others kernel such as: radial basis, polynomial and sigmoid function (from our experimental experience).LDA is a traditional method for classification [61]. The basic idea is to try to find an optimal projection (decision boundaries optimized by the error criterion), which can maximize the distances between samples from different classes and minimize the distances between samples from the same class. We used LDA for binary classification, thus, observations were classified by the following linear function:gi(x)=WiT*x−ci,1≤i≤2whereWiTis the transpose of a coefficient vector, x is a feature vector and ciis a constant as the threshold. The values ofWiTand ciare determined through the analysis of a training set. Once these values are determined, they can be used to classify the new observations (smallest gi(x) is preferred).The NB classifier is based on probabilistic models with strong (Naive) independence assumptions, which assumes a class variable depending on the set of input features [62]. This classifier can be trained based on the relative frequencies shown in the training set to get an estimation of the class priors and feature probability distributions. For a test sample, the decision rule will be picking the most probable hypothesis, which is known as the maximum a posteriori decision rule.We considered developing the new uFilter feature selection method based on the Mann–Whitney U-test [27], in a first approach, to be applied in binary classification problems. The uFilter algorithm is framed in the univariate filter paradigm since it requires only the computation of n scores and sorting them. Therefore, its time execution (faster) and complexity (lower) are beneficial when is compared to wrapper or embedded methods.The Mann–Whitney U-test is a non-parametric method used to test whether two independent samples of observations are drawn from the same or identical distributions. U-test is based on the idea that the particular pattern exhibited when m number of X random variables and n number of Y random variables are arranged together in increasing order of magnitude provides information about the relationship between their parent populations [27]. The Mann–Whitney test criterion is based on the magnitude of the Y's in relation to the X's (e.g. the position of Y's in the combined ordered sequence). A sample pattern of arrangement where most of the Y's are greater than most of the X's or vice versa would be evidence against random mixing. This would tend to discredit the null hypothesis of identical distribution [63]. An advantage of using this test is that the two samples under consideration may not necessarily have the same number of observations. However, samples with at least 25 instances would be more desirable for statistical analysis, since data distribution follows the normal distribution.For better understanding the theoretical description, we considered a binary class problem (benign and malignant classes) with more than 25 instances per class, thus:Let F={f1, f2, …, ft} a set of features with size t, and let fi={Ic,1, Ic,2, …, Ic,n} an ordered set of instances (in ascending way) with size n belonging to the ith-feature under analysis, where Ic,jrepresents the value of the feature fifor an individual instance j, and c denotes the class value: Benign (B) and Malignant (M). Then, the uFilter performs a tie analysis in the fisequence according to the rule: if there are tie elements, their positions are updated by the resultant value of averaging the positions of tied elements; the output sequence is saved inf′i. Consequently, summation of benign (SB) and malignant (SM) instance positions in thef′isequence was defined by:(1)SB=∑j=1nBf′j(2)SM=∑j=1nMf′jwhere nBand nMare the totals of benign and malignant instances respectively. Thus, u-values (according to the Mann–Whitney U-test [27]) for each sample are computed as:(3)uB=nBnM+nB(nB+1)2−SB(4)uM=nBnM+nM(nM+1)2−SMAs the sample size exceeds 25 instances per class, the original Mann–Whitney U-test [27] selected the minimum between both computed u-values (from Eqs. (3) to (4)) for the calculation of the Z-indicator (see Eqs. (5) or (6)). In this case, only one Z-indicator will be analyzed to accept or reject the null hypothesis at a given level of significance (α=0.05).In contrast with the original U-test, the proposed uFilter method computes both Z-indicators (one by each class) in the following way:(5)ZB=uB−u¯σu(6)ZM=uM−u¯σuwhereu¯is the mean of the sample and the standard deviation is defined as:σu=nBnMn(n−1)n3−n12−∑i=1kli3−li12where k denotes the total of range having tied elements in fisequence and limeans the quantity of elements within each kth-range. Finally, the score/weight of the feature fiis calculated as the absolute value of the numerical difference between Z scores (see Eq. (7)).(7)wi=|ZB−ZM|The uFilter algorithm is applied to the whole feature space and the output of the algorithm is the ranking of features established by sorting in descendant way the random sequence of weights(w). In this approach, higher values in Eq. (7) are preferred, because it means the feature has better separability of class-data distributions and therefore higher discrimination power. Otherwise, the class-data distributions is overlapping and finding the decision boundary for future classifications becomes more difficult. Algorithm 1 summarizes the uFilter steps.This section outlines the experimental evaluation of the proposed uFilter method when compared to four well known (classical) feature selection methods on breast cancer diagnosis. Since this research is a multistep modeling procedure, the application of the k-fold cross validation method [59] to the entire sequence of modeling steps guarantees reliable results [64].In particular, we applied ten times the 10-fold cross validation method before to establish a ranking of features (to avoid giving an unfair advantage to predictors) and classification steps respectively (to prevent overfitting of classifiers to the training set [59]) (see Fig. 2). Thus, no samples appear simultaneously in training and test (disjoint test partitions). In this way, individual classifiers will be trained on different training sets, leading to different representations of the input space. Testing on these different input space representations leads to diversity in the resultant classifications for individual samples.The overall procedure for the uFilter evaluation involves five main steps:•Applying the classical Mann–Whitney U-test (U-test), the new proposed uFilter method and four well known feature selection methods: CHI2 discretization [19], IG [21], 1Rule [36] and Relief [25] to the six previously formed breast cancer datasets (see Fig. 2 step 2);Creating several ranked subset of features using increasing quantities of features. The top N features of each ranking (resultant from the previous step) were used for feeding different classifiers, with N varying from 5 to the total number of features of the dataset, with increments of 5 (see Fig. 2 step 3).Classifying the generated ranked subset of features using FFBP neural network [60], SVM [60], LDA [61] and NB [62] classifiers for a comparative analysis of AUC scores. All comparisons were using the Wilcoxon statistical test [65,66] to assess the meaningfulness of differences between classification schemes (see Fig. 2 step 3);Selecting the best classification scheme on datasets (BCDR1, BCDR2, BCDR3, DDSM1, DDSM2 and DDSM3), and thus the best subset of features.In the last step of the experiment, we determined the feature relevance analysis using a two-step procedure involving (1) selecting the best subset of features for each dataset, and (2) performing a redundancy analysis based on the Pearson correlation [67], to determine and eliminate redundant features from relevant ones, and thus to produce the final subset of features.In contrast to the work of Ghazavi and Liao [14], we decided to employ the correlation analysis as a complementary step to the uFilter procedure, instead to an evaluation function for features selection, because in real domains many features have high correlations and thus many are (weakly) relevant and should not be removed [68]. Also, some variables may have a low rank because they are redundant and yet be highly relevant [9].

@&#CONCLUSIONS@&#
The new developed uFilter method performed better than the Mann–Whitney U-test (U-test) when applied to reduce and ranking features in binary classification problems. uFilter was validated using several machine learning algorithms such as FFBP neural network, SVM, LDA and NB classifiers over six different (balanced and unbalanced) datasets representative of two different breast cancer repositories. A head-to-head comparison proved that the uFilter method significantly outperformed the U-test method for almost all of the classification schemes. It was superior in 50%; tied in a 37.5% and lost in a 12.5% of the 24 comparative scenarios. Moreover, a global comparison against other four well known feature selection methods (CHI2 discretization, IG, 1Rule and Relief) demonstrated that uFilter statistically outperformed the remaining methods on several datasets (BCDR1, DDSM1 and BCDR3), and it was statistically similar on the BCDR2, DDSM2 and DDSM3 datasets while requiring less number of features. The uFilter method revealed competitive and appealing cost-effectiveness results on selecting relevant features, as a support tool for breast cancer CADx methods especially in unbalanced datasets contexts. Finally, the redundancy analysis as a complementary step to the uFilter method provided us an effective way for finding optimal subsets of features without decreasing the classification performances.Future work will be aimed to: (1) increasing the number of features in benchmarking breast cancer datasets; (2) exploring the performance of uFilter in other knowledge domains and (3) extending uFilter allowing it to be used on multiclass classification problems.The authors declare that they do not have any conflict of interest.