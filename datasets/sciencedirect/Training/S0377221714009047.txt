@&#MAIN-TITLE@&#
A continuous buffer allocation model using stochastic processes

@&#HIGHLIGHTS@&#
Rigorous derivation of a continuous model for the buffer allocation problem based on a discrete time recursion.An adjoint approach is used to efficiently compute sensitivity/gradient information for the presented model.Moderate increase of the computing times for optimization tasks with respect to the number of pieces and processors.

@&#KEYPHRASES@&#
Production systems,Buffer allocation,Sampling,Nonlinear optimization,,

@&#ABSTRACT@&#
The buffer allocation problem consists of a dynamical description of the underlying production process combined with stochastic processing times. The aim is to find optimal buffer sizes averaged over several samples. Starting from a time-discrete recursion we derive a time-continuous model supplemented with a stochastic process. The new model is used for simulation and optimization purposes as well. Numerical experiments show the efficiency of our approach compared to other optimization techniques.

@&#INTRODUCTION@&#
Production systems are organized in a way that the best possible output is reached and storage costs are minimized. However, this objective is usually influenced by external factors such as fluctuating demands, supply bottlenecks or individual product specifications. In most instances, the overall goal is to minimize the total buffer load, where the production dynamics is induced by processing order inequalities and restrictions on the system capacities. Typical applications we think of include the motor vehicle industry in the case of automotive parts as well as other kinds of processing industries.Mathematical models provide a powerful tool to study and analyze production systems. Especially in the case of the buffer allocation problem, see Alfieri and Matta (2012),Burman (1995),Dallery and Gershwin (1992),Demir, Tunali, and Eliiyi (2014),Dolgui, Eremeev, Kovalyov, and Sigaev (2013),Gershwin (1987),Gershwin and Schor (2000),Gershwin and Tan (2009); 2010), Gürkan (2000),Helber, Schimmelpfeng, Stolletz, and Lagershausen (2011),Matta (2008), and Tan and Yeralan (1997) for an overview. One can basically distinguish between discrete and continuous models. Discrete models are characterized by discrete time periods and work pieces while continuous models instead rely on continuous time and approximate quantities, see e.g. Armbruster, Degond, and Ringhofer (2006),Degond and Ringhofer (2007),Göttlich, Herty, and Klar (2006),Göttlich, Herty, and Ringhofer (2010). In this paper, we focus on a model connecting these two perspectives from a numerical point of view.In Section 2, a discrete time recursion formula is introduced which can be used for the tracking of individual work pieces through a production system, also called discrete event simulation (DES). The work pieces have particular processing times which are randomly distributed. Evaluation measures help to determine buffer loads and the current work in progress (WIP). The goal is to minimize the total buffer size in the production system. The resulting optimization problem can be exactly reformulated as a mixed integer linear program (MIP), and as illustrated in Matta (2008),Stolletz and Weiss (2013), and Weiss and Stolletz (2013), there is a strong need for adapted solution methods to tackle the underlying MIP—even for smaller test cases. Optimization techniques such as Benders decomposition must be applied to solve the models within an acceptable time frame. In further literature, the classical buffer allocation problem (cf. Demir et al., 2014 and the references therein) is based on a similar idea leading to a NP-hard combinatorial optimization problem. Without additional heuristics there is nearly no chance to deal with large-scale problems.Another modeling approach, also implying a different optimization as indicated in Fig. 1, will be our major concern. It is well known that discrete event models provide the most accurate description of the underlying dynamics for simulation purposes. However, it is a microscopic model, meaning that the computation times highly depend on the number of work pieces to be considered. An optimization problem based on such a model at first leads to simulation-based optimization procedures only and is usually extremely costly, see Göttlich et al. (2006). In order to derive a suitable optimization framework, one can introduce an associated mixed integer linear program. Although this program is still dependent on individual parts, the optimization can be done in a well-defined way using common Branch and Bound algorithms. At best, global optimality can be reached.Within this article we are interested in models on a macroscopic scale, or more precisely, we rigorously derive a continuous model which avoids the dependence on single parts and discrete options for the buffer capacities. The benefit of such a continuous model is that it can be used for fast simulation and also optimization. For the optimization we apply nonlinear methods leading to qualitatively very good results close to the mixed integer solution.The paper is organized as follows: First, based on the discrete time recursion described in Section 2, we formally derive a time-continuous model in Section 4 and also describe its numerical treatment (Section 5.1). Then, using nonlinear optimization techniques as in Göttlich, Kolb, and Kühn (2014),Kirchner, Herty, Göttlich, and Klar (2006),Kolb (2011), and Kolb and Lang (2012), we are able to solve the reformulated problem by a gradient method (cf. Section 5.2). The quality of the results is very promising as pointed out in Section 6.In this section, we start with the description of a time discrete model called discrete event simulation that is suitable for evaluating queuing systems. Similar approaches can be found in Armbruster et al. (2006),Stolletz and Weiss (2013), and Weiss and Stolletz (2013).We consider a queuing network with K consecutive processors, each of them with a queue of size Cm(m ∈ {1, … , K}) in front, see Fig. 2. The times Tm, nneeded by processor m to process piece n (n ∈ {1, … , N}) follow a processor dependent random distribution and will be sampled accordingly. Note that for the evaluation and the comparison of all presented models (Sections 2–4), we always consider several samples of processing times Tm, nin the numerical results in Section 6, but the same samples will be used for all models. Transport times between different processors are neglected and so the work pieces are directly fed into the next production unit.The main ingredient of a time recursion is the modeling of effects such as free flow, starving and blocking. Let τm, nbe the arrival time of piece n at the queue of processor m. Assuming all pieces are processed as fast as possible, the arrival times of the considered production line read(1)τm,n=max{max{τm,n−1,τm−1,n}+Tm−1,n,τm+1,n−(Cm+1)}.The first term,max{τm,n−1,τm−1,n}+Tm−1,n,results from the fact that piece n cannot be started being processed at processor m − 1 before the preceding piece n − 1 has left processor m − 1 and therewith arrived at (the queue) of processor m at time τm, n − 1 (free flow) and not earlier than the arrival time τm − 1, nof piece n at processor m − 1 (starving). The second term in (1) ensures that if there is enough space in the queue in front of processor m (at least piece n − (Cm+ 1) has been processed, yielding a free slot), the piece n can be processed directly, otherwise it will be stopped (blocking). For given initial conditions τ1, n(arrival times at the first processor), processing times Tm, nand queue sizes Cm, a simulation/evaluation of the arrival times τm, n(m ∈ {2, … , K + 1}, n ∈ {1, … N}) can be done based on (1) (with τm, n= −∞ if n ≤ 0 or m > K + 1). Here, we typically assume τ1, n= 0 and C1 = CK + 1 = ∞. Note that we also consider τK + 1, n, as the time when piece n leaves the last processor.In a next step, cf. Armbruster et al. (2006) and Göttlich et al. (2006), evaluation measures are needed to identify the quantities flux and WIP. Mathematically, we introduce the concept of curves of cumulative counts using the Heaviside function H( · ). Then, withH(x)={1x≥00x<0we denote byUm(t)=∑n=1NH(t−τm,n)the number of pieces having arrived at (the queue of) processor m until time t. Further, we define the fluxFm(t)=ddtUm(t)=∑n=1Nδ(t−τm,n),where δ is the Dirac delta function (derivative of the Heaviside function in a distributional sense), and the WIPWm(t)=Um(t)−Um+1(t)+Wm,0with initial conditions Wm, 0. Obviously,(2)ddtWm(t)=Fm(t)−Fm+1(t)holds. Due to the limited queue size Cmin front of processor m, the following constraint must be satisfied for the WIP:(3)0≤Wm(t)≤Cm+1.The WIP is limited by Cm+ 1 because Cmpieces may be waiting in the queue and one can be currently processed.The discrete model described in Section 2 can be modeled within a linear MIP (cf. Matta, 2008; Weiss and Stolletz, 2013). Transferred to our notation (regarding names of the variables and also indexing), the relevant constraints within the MIP formulation are(4)τ1,n=0n∈{1,…,N},(5)τm,n≥τm,n−1+Tm−1,nm∈{2,…,K+1},n∈{1,…,N},(6)τm,n≥τm−1,n+Tm−1,nm∈{2,…,K+1},n∈{1,…,N},(7)τm,n≥τm+1,n−(b+1)−M(1−ym,b)m∈{2,…,K},n∈{1,…,N},b∈{0,…,B},(8)ym,b∈{0,1},∑b=0Bym,b=1,Cm=∑b=0Bbym,bm∈{2,…,K}.Eq. (4) states the initial conditions (all pieces are directly available at the first processor). The inequalities (5)–(7) refer to the three different cases in (1), where M is a sufficiently large Big-M term and B defines the maximum queue size. Note that for a given objective function (like maximization of the throughput under further constraints), at least one of these inequalities is typically fulfilled with equality in the optimal solution (for each pair of m and n), which means that the corresponding piece n is processed as fast as possible at the corresponding machine m. Finally, Eq. (8) defines the queue sizes Cmbased on the binary auxiliary variables ym, b, which are necessary to formulate (7). In particular, for each machine m exactly one ym, bequals 1 and implies Cm= b.A complete MIP formulation for the buffer allocation problem, here for minimizing the accumulated buffer size, would then readmin∑m=2KCms.t.(4),(5),(6),(7),(8),furtherconstraintswhere further constraints could be to maintain a given minimum mean throughput as below (cf. (22)).As one may imagine, the introduction of the binary auxiliary variables ym, bto formulate the dependence on the queue size in (7) within an MIP framework constitutes the main part of the complexity of optimization tasks based on this model. One may expect rapidly increasing running times for increasing problem sizes (in particular when K increases) as observed in Weiss and Stolletz (2013). To avoid this effect, we consider a continuous model in the following section, which will allow for an easier dealing of the queue sizes and result in moderately increasing running times within a gradient-based optimization framework.DES models as introduced in Section 2 have the advantage of being the most accurate models to describe the dynamics inside a system. However, as already noted in the last section, the computational costs within optimization frameworks may rapidly increase for such models. Therefore we intend to proceed with a different approach and use the DES model to rigorously derive a continuous model with real-valued fluxes and WIP, which approximate the DES model in a weak sense. Within this model the queue sizes Cmmay be chosen non-integer and the presented model will allow for gradient-based optimization techniques.In the continuous model, we denote by fm(t) the flux arriving at processor m at time t and by wm(t) ∈ [0, Cm+ 1] the work in progress at processor m. According to (2) we haveddtwm(t)=fm(t)−fm+1(t).The main idea in the following is to approximate Fm(t) by fm(t) in an integral/weak sense. Thus, for consistency reasons, we claim∫τm,nτm,n+1fm(t)dt=1,i.e. exactly one work piece is processed between the arrival times of two consecutive work pieces at the following processor. If there is no starving or blocking, and therefore τm, n + 1 − τm, n= Tm − 1, n + 1, a natural choice would be a uniform fluxfm(t)=1Tm−1,n+1for t ∈ (τm, n, τm, n + 1). In the general case, we will use 1/Tm − 1, n + 1 as the maximum possible processing rate of processor m − 1 at all times t ∈ (τm, n, τm, n + 1). To stay consistent with the discrete model, in particular we want to somehow preserve the processing order of all pieces, we consider the following concept: For each processor m − 1, we introduce a virtual timet˜m−1=pm−1(t),which measures how long processor m − 1 had to run at the currently maximum possible processing rate to achieve the past throughput until time t. In particular, we claimpm−1(τm,n)=∑k=1nTm−1,kandt˜m−1=pm−1(t)∈(∑k=1n−1Tm−1,k,∑k=1nTm−1,k)⇔t∈(τm,n−1,τm,n).Depending on this virtual time, we define the (maximum) processing rates (see Fig. 3for an example)(9)μm−1(t˜m−1)=1Tm−1,n∀t˜m−1∈(∑k=1n−1Tm−1,k,∑k=1nTm−1,k).Then, the definition of the virtual timet˜m−1yields/is given by(10)∫pm−1(t)pm−1(t+Δt)μm−1(t˜m−1)dt˜m−1=∫tt+Δtfm(s)dsfor arbitrary Δt.Since we claimed fm(t) ≤ μm − 1(pm − 1(t)) above, one may show from (10) thatpm−1(t+Δt)−pm−1(t)≤(t+Δt)−t=Δtand we therewith get the following upper bound for the flux fm(t):(11)∫tt+Δtfm(s)ds=(10)∫pm−1(t)pm−1(t+Δt)μm−1(t˜m−1)dt˜m−1≤∫pm−1(t)pm−1(t)+Δtμm−1(t˜m−1)dt˜m−1.For later use, we define(12)μm−1,max(t,Δt)=1Δt∫pm−1(t)pm−1(t)+Δtμm−1(t˜m−1)dt˜m−1.Next, we consider the influence of constraint (3) on our model. The upper bound in (3) at time t + Δt yieldsWm(t+Δt)=Wm(t)+∫tt+ΔtddsWm(s)ds=Wm(t)+∫tt+Δt(Fm(s)−Fm+1(s))ds≤Cm+1.Dividing by Δt and rearranging terms gives(13)1Δt∫tt+ΔtFm(s)ds≤Cm+1−Wm(t)Δt+1Δt∫tt+ΔtFm+1(s)ds.Analogously, we consider the lower bound in (3) at time t + Δt for m − 1:0≤Wm−1(t+Δt)=Wm−1(t)+∫tt+ΔtddsWm−1(s)ds=Wm−1(t)+∫tt+Δt(Fm−1(s)−Fm(s))ds.Dividing by Δt and rearranging terms yields(14)1Δt∫tt+ΔtFm(s)ds≤Wm−1(t)Δt+1Δt∫tt+ΔtFm−1(s)ds.Replacing the variables F, W of the discrete model by f, w and definingγm(t,Δt)=1Δt∫tt+Δtfm(s)ds,inequalities (13) and (14) readγm(t,Δt)≤min{wm−1(t)Δt+γm−1(t,Δt),Cm+1−wm(t)Δt+γm+1(t,Δt)}.Considering the maximum processing rate μm − 1, max (t, Δt) at the preceding processor, we finally have (with (11))(15)γm(t,Δt)=min{μm−1,max(t,Δt),wm−1(t)Δt+γm−1(t,Δt),Cm+1−wm(t)Δt+γm+1(t,Δt)}when assuming that all pieces are processed as fast as possible (and the presented constraints are fulfilled).Accordingly, we get the following update formula for the continuous WIP:(16)wm(t+Δt)=wm(t)+∫tt+Δtddswm(s)ds=wm(t)+∫tt+Δt(fm(s)−fm+1(s))ds=wm(t)+Δt(γm(t,Δt)−γm+1(t,Δt)).Remark 1For comparison of the discrete model (1) with the time-continuous one (15), we rearrange the first term in (1):(17)τm,n=max{τm,n−1+Tm−1,n,τm−1,n+Tm−1,n,τm+1,n−(Cm+1)}.In (15) and in (17), the first term corresponds to the case where there is no starving or blocking: Processor m − 1 works with the currently maximum processing rate in the continuous model, and piece n is directly processed after piece n − 1 and delivered to the next processor in the discrete model. Due to the second term in (15) and in (17), starving may occur, and the third term is responsible for blocking.In this section, we describe the later applied numerical schemes for simulation and optimization purposes based on the continuous model presented in Section 4. Especially for optimization purposes we will not directly use (15) for the computation of the flux values γm, because this leads to an implicit system of equations. Instead of that, we will leave out the γ terms within the minima on the right-hand side. This way, we end up with a computationally inexpensive explicit scheme approximating the solution of (15). Having in mind the discrete model, this modification has another motivation: Due to the γ terms on the right-hand side of (15), flux through a processor may be instantaneously processed by subsequent processors, while in the discrete model, each piece is sequentially processed at all processors, with a minimum delay of the single processing times. By omitting the γ terms in the numerical scheme, we artificially add some kind of delay in the processing, namely the applied step size Δt. Later in the numerical results (in Section 6.1), we will also compare the solutions of the continuous model with and without the γ terms on the right-hand side of (15) and refer to them as continuous model with/without instantaneous processing.We seek for an (approximate) solution to the continuous model described in Section 4, that is, we are interested in the state of the queuing network at certain points in time for a given initial state and processing times Tm, n. Within the continuous model, the state at some time t is described by the current work in progress wm(t) (for m ∈ {2, … , K}) and the virtual timest˜m=pm(t)(for m ∈ {1, … , K}). We consider the discrete times tk= kΔt and accordingly the stateswmk≈wm(tk),t˜mk≈pm(tk),where we assume the initial conditionswm0andt˜m0to be given. Starting from this initial state, the aim of the numerical scheme is to (iteratively) compute the following stateswmkandt˜mkfor all k ∈ {1, … , Nt}. The basic steps of this procedure are given in Algorithm 1.In each iteration of the main loop of Algorithm 1, we first compute the average flux valuesγmk−0.5for the currently next interval [tk − 1, tk]. Based on these flux values and the old stateswmk−1,t˜mk−1at time tk − 1, the new stateswmkandt˜mkat time tkare computed in the second step. In principal, depending on the applied discretization of the model equations presented in Section 4, both steps may involve the solution of a system of nonlinear equations, which we typically solve via Newton’s method within our software. Here, one might also directly use (15) for a fixed point iteration, which has also been done for the numerical results in Section 6.1. But as we will see below, a purely explicit scheme approximating the solution of (15) is possible. In the following, we explain the details of both steps in the main loop of Algorithm 1.Computation of the average flux values: For given processing times Tm, n, we directly haveμm(t˜m)via (9). Thus, we may compute the maximum (average) flux within the interval [tk − 1, tk] according to (12),(18)μm,maxk−0.5=1Δt∫t˜mk−1t˜mk−1+Δtμm(s)ds∀m∈{1,…,K},where Δt = tk− tk − 1. Sincet˜mk−1is known (from the initial conditions or the previous iteration) and the functions μmgiven by (9) are piecewise constant, these integrals can be exactly evaluated.Next, we compute the desired average flux values(19)γ2k−0.5=min{μ1,maxk−0.5,C2+1−w2k−1Δt},γmk−0.5=min{μm−1,maxk−0.5,wm−1k−1Δt,Cm+1−wmk−1Δt}∀m∈{3,⋯,K},γK+1k−0.5=min{μK,maxk−0.5,wKk−1Δt}.Here, we assumed that there is no starving at the first processor (τ1, n= 0 and C1 = ∞) and CK + 1 = ∞. Comparing with (15) and as already noted above, we skipped the γ terms within the minima on the right-hand side. The main reason for this modification is that we end up with a computationally inexpensive explicit scheme this way, which approximates the solution of (15). Moreover, we avoid singular Jacobian matrices, which may occur when solving (a smoothed version of) the original formulation with Newton’s method. A comparison of using the continuous model with or without the γ terms on the right-hand side of (15), corresponding to instantaneous processing, is done in the numerical results in Section 6.1.Computation of the new states: Having computed the average flux values within the time interval [tk − 1, tk], the change of the work in progress reads (according to (16))(20)wmk=wmk−1+Δt(γmk−0.5−γm+1k−0.5)∀m∈{2,…,K}.Additionally, we have to compute the new virtual timest˜mk. From (10) we get(21)∫t˜m−1k−1t˜m−1kμm−1(s)ds=Δtγmk−0.5.Again, since the functions μm − 1 are piecewise constant, Eq. (21) can be exactly solved fort˜m−1k(for m ∈ {2, … , K + 1}). This completes the description of the applied numerical scheme to solve simulation tasks based on the continuous model.As already announced in the Introduction, we will now formulate the buffer allocation problem based on the presented continuous model (in Section 5.2.1). Since we want to apply gradient-based optimization techniques to solve the resulting problem, Appendix A is concerned with the (efficient) computation of the necessary gradient information by an adjoint approach.The optimization task we are interested in is the minimization of the buffer sizes,min∑m=2KCm,while maintaining a given minimum mean throughputF˜of the queuing network. In the discrete model, or accordingly in the MIP approach of Section 3, this constraint reads(22)N−N0τK+1,N−τK+1,N0≥F˜with N0 > 0 pieces as warm-up phase for the entire system. To check (22) for a choice ofCm∈N,we simply have to evaluate the arrival times τm, naccording to (1).In the continuous model, we may chooseCm∈R≥0and evaluate the discretized model equations introduced in Section 5.1. Here, we claim as constraint for the mean throughput(23)1tNt−tw∫twtNtfK+1(t)dt≥F˜with tw> t0 as a warm-up time. To evaluate (23), fK + 1(t) is approximated byγK+1k−0.5for t ∈ (tk − 1, tk).The entire optimization task for the continuous model reads(24)min∑m=2KCms.t.Cm∈R≥0modelequations:(18),(19),(20),(21)meanthroughput:(23)and we would like to apply gradient-based optimization techniques for the solution of (24). For this, some terms in the discretized model equations (18)–(21) have to be smoothened (in particular the minimum functions in (19)). Then, a quite efficient way to compute the necessary gradient information for the solution of (24) is to apply an adjoint approach, which will be in Appendix A.

@&#CONCLUSIONS@&#
