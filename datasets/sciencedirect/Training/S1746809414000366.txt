@&#MAIN-TITLE@&#
Energy efficient telemonitoring of physiological signals via compressed sensing: A fast algorithm and power consumption evaluation

@&#HIGHLIGHTS@&#
We developed a fast compressed sensing (CS) algorithm based on the block sparse Bayesian learning (BSBL) framework.We systematically evaluated the distortions of CS-based data compression on two real-life applications, e.g., fetal ECG (FECG) telemonitoring and EEG telemonitoring for the epileptic patients.Using an FPGA platform, we showed that the CS-based compression method, compared to a low-power wavelet-based compression method, can largely reduce power consumption and save other computing resources.

@&#KEYPHRASES@&#
Low-power data compression,Compressed sensing (CS),Block sparse Bayesian learning (BSBL),Electrocardiography (ECG),Electroencephalography (EEG),Field programmable gate array (FPGA),

@&#ABSTRACT@&#
Wireless telemonitoring of physiological signals is an important topic in eHealth. In order to reduce on-chip energy consumption and extend sensor life, recorded signals are usually compressed before transmission. In this paper, we adopt compressed sensing (CS) as a low-power compression framework, and propose a fast block sparse Bayesian learning (BSBL) algorithm to reconstruct original signals. Experiments on real-world fetal ECG signals and epilepsy EEG signals showed that the proposed algorithm has good balance between speed and data reconstruction fidelity when compared to state-of-the-art CS algorithms. Further, we implemented the CS-based compression procedure and a low-power compression procedure based on a wavelet transform in field programmable gate array (FPGA), showing that the CS-based compression can largely save energy and other on-chip computing resources.

@&#INTRODUCTION@&#
Monitoring physiological signals via wireless sensor networks is an important topic in wireless healthcare. One major challenge of wireless telemonitoring is the conflict between huge amount of data collected and limited battery life of portable devices [1–3]. Data need to be compressed [4,3] before transmission. Most physiological signals are redundant, which means that they can be effectively compressed [3] using transform encoders such as discrete wavelet transform (DWT) based methods [5]. However, these methods consist of sophisticated matrix–vector multiplication, sorting and arithmetic encoding which subsequently drain the battery.Compressed sensing (CS), [6], can recover a signal with less measurements given that the signal is sparse or can be sparse represented in some transformed domains. CS-based wireless telemonitoring technology [7–12] can thus be viewed as a lossy compression method. The block diagram of a typical CS-based wireless telemonitoring is shown in Fig. 1. Physiological signals are firstly digitalized (Nyquist sampling) via an analog to digital converter (ADC). Those digitalized samples are compressed by a simple matrix–vector multiplication and the results are transmitted via wireless networks. At the data central, a CS algorithm is used to recover original signals from the compressed measurements.The basic goal of CS aims to solve the following underdetermined problem:(1)min‖x‖1s.t.y=Φx,where x is the samples,Φis the sensing matrix whose row number is smaller than column number, and y is the compressed measurements. ||x||1 is the ℓ1 norm penalty of x, which prompts its sparsity.In practice, physiological signals are not sparse in the time domain, therefore one often resorts to a transformed domain such that x can be expressed as x=Dθwhere D is a dictionary matrix such that the representation coefficientsθare much sparser than x. The problem in (1) then becomes(2)min‖θ‖1s.t.y=(ΦD)θ,The signal can be reconstructed afterwards usingxˆ=Dθˆwith the recovered coefficientsθˆ. Most CS-based telemonitoring systems [8,9] are build upon this model.Recent advance in CS algorithms is to incorporate physical information [13–15] into the optimization procedure with the goal to achieve better reconstruction performance. One structure widely used is the block/group sparse structure [13,16–18], which refers to the case when nonzero entries of a signal cluster around some locations. Moreover, noticing intra-block correlation widely exists in real-world signals, Zhang and Rao [13,19] proposed the block sparse Bayesian learning (BSBL) framework. It showed superior ability to recover block sparse signals or even non-sparse raw physiological signals such as fetal ECG [11] and EEG signals [10].BSBL algorithms [13] showed impressive recovery performance on physiological signals such as ECG and EEG. However, these algorithms derived so far are not fast and may limit their applications. The first contribution of our work is a fast implementation11The preliminary work of the developed algorithm is available in http://arxiv.org/abs/1211.4909.of the BSBL framework using the fast marginalized (FM) likelihood maximization method [20]. Experiments conducted on real-life physiological signals showed that the proposed algorithm had similar recovery quality as BSBL algorithms, but was much faster.Power consumption is a major concern in wireless telemonitoring systems. Traditionally, the power consumption was evaluated on a low-power microcontroller (MCU) [8]. However, MCU does not support fully parallel implementation and the power estimate is affected by the coding style. In this work, we analyzed the power consumption on field programmable gate array (FPGA). In FPGA, we can implement the compressor in parallel and control the overall activities. Only the logic cells related to the compression core are implemented and the rest are holding reset. Therefore the power estimate is more accurate. In the experiment, the CS-based compressor was compared to a low-power DWT-based compressor in terms of compression latency, the number of utilized on-chip resources and power consumption. We proved that the CS-based architecture was more suitable for low-power physiological telemonitoring applications.The rest of the paper is organized as follows. Section 2 presents the fast marginalized implementation of the BSBL algorithm and Section 3 provides the simulation setup and evaluation metrics. In Section 4 and Section 5, we conduct experiments on fetal ECG (FECG) and EEG signals. The extracted FECGs and the epileptic seizure classification results are used to evaluate the performance of CS. FPGA implementations and power consumption of the CS-based and the DWT-based compression methods are given in Section 6. Conclusion is drawn in the last section.Throughout the paper, Bold letters are reserved for vectors x and matrices X. Tr(·) computes the trace of a matrix and diag(A) extracts the diagonal vector of the matrix A. (·)Tis the transpose operator.N(x;μ,Σ)denotes a multivariate Gaussian distribution with meanμand varianceΣ.A block sparse signal x has the following structure:(3)x=[x1,…,xd1︸x1T,…,x1,…,xdg︸xgT]T,which means x has g blocks, and only a few blocks are nonzero. Here diis the block size for the ith block. The BSBL algorithms [13] exploit the block structure and the intra-block correlation by modeling the signal block xiusing the parameterized Gaussian distribution:(4)p(xi;γi,Bi)=N(xi;0,γiBi).with unknown deterministic parameters γiand Bi. γiis a nonnegative parameter controlling the block-sparsity of x and Biis a positive definite matrix modeling the covariance structure of xi. We assume that the blocks are mutually independent. Henceforth,(5)p(x;{γi,Bi}i)=N(x;0,Γ),whereΓdenotes a block diagonal matrix with the ith principal block given by γiBi.The measurement noise is assumed to be independent and Gaussian with zero mean and unknown variance β−1. Thus the measurement model is(6)p(y|x;β)=N(y;Φx,β−1I).Given the signal model (5) and the measurement model (6), the posteriorp(x|y;{γi,Bi}i,β)and the likelihoodp(y|{γi,Bi}i,β)can be derived as follows:(7)p(x|y;{γi,Bi}i,β)=N(x;μ,Σ),(8)p(y|{γi,Bi}i,β)=N(y;0,C)whereΣ≜(Γ−1+ΦTβΦ)−1,μ≜ΣΦTβy and C≜β−1I+ΦΓΦT. To estimate the parameters{γi,Bi}iand β, the following cost function is used, which is derived according to the Type II maximum likelihood [13]:(9)L({γi,Bi}i,β)=−2logp(y|{γi,Bi}i,β)(10)∝log|C|+yTC−1y,Once all the parameters are estimated, the MAP estimate of the signal x can be directly obtained from the mean of the posterior, i.e., x=μ.There are several methods to minimize the cost function as shown in [13]. In the following we consider to use the fast marginalized (FM) likelihood maximization method [20].The cost function (10) can be optimized in a block way. We denote byΦithe ith block basis inΦwith the column indexes corresponding to the ith block of the signal x. Then C can be rewritten as:(11)C=β−1I+∑m≠iΦmγmBmΦmT+ΦiγiBiΦiT,(12)=C−i+ΦiγiBiΦiT,whereC−i≜β−1I+∑m≠iΦmγmBmΦmT.Using the Woodbury identity,|C|=|γiBi||C−i||Ai−1+si|,C−1=C−i−1−C−i−1Φi(Ai−1+si)−1ΦiTC−i−1, where Ai≜γiBi,si≜ΦiTC−i−1Φiandqi≜ΦiTC−i−1y, Eq. (10) can be rewritten as:(13)L=log|C−i|+yTC−i−1y+log|Idi+Aisi|−qiT(Ai−1+si)−1qi,(14)=L(−i)+L(i),whereL(−i)≜log|C−i|+yTC−i−1y, and(15)L(i)≜log|Idi+Aisi|−qiT(Ai−1+si)−1qi,which only depends on Ai.Setting∂L(i)/∂Ai=0, we have the updating rule(16)Ai=si−1(qiqiT−si)si−1.In our model we further parameterize Aias Ai=γiBiin order to impose some constraint (i.e. regularization) on the covariance structure (see the next subsection). However, there is ambiguity between γiand Bi. To solve this, we define γias the norm of Ai, namely,(17)γi=‖Ai‖F,and define Bias a matrix of unit norm which models the covariance structure of the ith block Ai, namely,(18)Bi=Aiγi.One can see this parameterization is a natural extension of the basic SBL model proposed by Tipping [21].As noted in [13], regularization to Biis required due to limited data. A good regularization can largely reduce the probability of local convergence. Although theories on regularization strategies are lacking, some empirical methods [19,13] were presented.In this paper we focus on the following two correlation models. One is the simple (SIM) model:(19)Bi=I(∀i).When the developed algorithm uses this regularization, we denote it by BSBL-FM(0). This model assumes that entries in each block are not correlated.Another is to model the entries in each block as an autoregressive (AR) process [19,13] of order 1 with the coefficient ri. The correlation level of the intra-block correlation is reflected by the value of riwhich can be empirically calculated [13] from the estimated Biin (18). In many real-world applications, the intra-block correlation in each block of a signal tends to be positive and high together. Thus, we further constrain that all the intra-block correlation values of blocks have the same AR coefficient r[13],(20)r=1g∑i=1gri.Then Biis reconstructed as a symmetric Toeplitz matrix with the first row given by [1, r, …, rdi−1]. Our algorithm using this regularization is denoted by BSBL-FM(1).The parameter β−1 is the noise variance in our model. It can be estimated by solving∂L/∂βfrom (10),(21)β=MTr[ΣΦTΦ]+‖y−Φμ‖22.However, the resulting updating rule is generally not robust and thus requires some regularization [13,19]. Alternatively, one can treat it as a regularizer and assign suitable values to it via cross-validation. In our experiments we set β−1=10−6 in noiseless simulations andβ−1=0.01‖y‖22in noisy scenarios, which showed good performance.The fast marginalized block SBL algorithm (BSBL-FM) is given in Fig. 2. Within each iteration, it only updates the block signal that attributes to the deepest descent ofL(i). The detailed procedures on re-calculation ofμ,Σ, {si}, {qi} are similar to [20]. The algorithm terminates when the maximum change of the cost function is smaller than a threshold η. In our experiments, we set η=1e−5.In our experiments, physiological signals were divided into packets. Each packet consisted of digitalized samples collected within a time window tp, where tp=Nts, N was the number of samples within a packet and tswas the sampling interval. The packet was compressed by multiplying a sparse binary matrixΦof size M×N with k non-zero entries of each column. Note that the sparse binary sensing matrix [8,10,11] has been widely used in CS-based telemonitoring for its efficiency in storage and matrix–vector multiplication. The compression ratio (CR) was defined as(22)CR=N−MN.We compared the proposed algorithm with state-of-the-art CS algorithms. The algorithms and their features are listed in Table 1. Throughout the experiments, the number of samples within a packet was fixed to N=512. Default parameters for BP were used. For Group BP, we tuned the parameters ‘optTol’ to 10−5 and ‘iterations’ to 200 for optimum performance. β−1=10−6 was selected for BSBL based algorithms. The same block partition (block size equals to 32) was used for all block based recovery algorithms.Throughout the experiments, we used two performance indexes. One was the percentage root-mean squared distortion (PRD), defined as(23)PRD=‖x−xˆ‖2‖x‖2·100,wherexˆwas the reconstructed signal of the true signal x. The lower the PRD, the better the recovery performance. Another was the CPU time, which was calculated on a computer with 2.9GHz CPU and 16G RAM.Two experiments were carried out. One was fetal ECG (FECG) telemonitoring. Similar as in [10,11], we compared the independent component analysis (ICA) decomposition [23] of original FECG recordings to the ICA decomposition of recovered FECG recordings. Another experiment was EEG telemonitoring for epileptic patients. We evaluated the distortion of CS by comparing the seizure classification results. The metric, called Area Under the receiver operation Curve (AUC) [4], was calculated to evaluate the classification performance. AUC denotes the area below the plot of sensitivity (true positive rate) versus specificity (true negative rate).The FECG dataset used in the experiment was the same as in Section III.B of [11].22Available on-line: https://sites.google.com/site/researchbyzhang/bsbl.The FECG dataset consisted of eight abdominal (channels) recordings sampled at 250Hz and each recording contained 10,240 data points.An example on a raw FECG packet reconstructed by different CS algorithms is shown in Fig. 3. In this example, a FECG packet of N=512 samples was compressed with CR=0.60. The recovered signals as well as the distortions using different CS algorithms are shown in Fig. 3.In the following we analyzed various factors that affected the distortion of CS, including the choice of the dictionary matrix D and the compression ratio CR. The ICA decompositions on the recovered recordings were used to verify the design results.The dictionary matrix D was used to sparsely represent the physiological signal x in a transformed domain. In this experiment, we considered six orthogonal dictionary matrices. One was the discrete cosine transform (DCT) matrix, which has been widely used in biological signal processing [10,11]. The next five were wavelet transform matrices,33The wavelet transform matrix D was generated using the wavemat function of the wavelab toolbox, available at http://www-stat.stanford.edu/~wavelab/.namely, the Haar wavelet, the Symmlet wavelet (the number of vanishing moments was set to 6), the Daubenchies wavelet (the number of vanishing moments was set to 8), the Coiflet wavelet and the Beyklin wavelet. In this experiment, N=512, k=2 and CR=0.60. The results are shown in Fig. 4.From Fig. 4 we found that the algorithms derived from the BSBL framework had better performance than the other recovery algorithms. The best performance of the BSBL family was obtained when D was the DCT matrix.The data distortion from CS is also affected by the compression ratio, CR. As more measurements are obtained, a CS algorithm's recovery performance can be further improved. In this experiment we studied the recovery performance of all compared algorithms in terms of CR. The dictionary matrix D was a DCT matrix, N=512, and k=2. The results are shown in Fig. 5 and 6.From Fig. 5 we found that the proposed algorithm showed similar performance as BSBL-BO, and all BSBL algorithms significantly outperformed other algorithms.From Fig. 6, we may conclude that our fast implementation was in average ∼7 times faster than BSBL-BO. We also noted that, in the DCT transformed domain, the coefficientsθwere almost not correlated. Therefore, the algorithms BSBL-FM(0) and BSBL-FM(1) yielded similar performances. However, by regularizing Bi=I, BSBL-FM(0) reduced computational load compared to BSBL-FM(1).As illustrated in Fig. 3, the desired FECG was buried in baseline noise and maternal ECG. Thus, we used ICA to extract the clean FECG from the raw FECG recordings recovered by different CS algorithms. In this experiment, CR=0.60, k=2, N=512 and D was a DCT dictionary matrix. The extracted FECGs of different CS algorithms are shown in Fig. 7and the average PRDs and the CPU time of these algorithms are shown in Table 2. We can see that although BSBL-FM(0) had slightly poorer recovery performance than BSBL-BO, it was much faster. Furthermore, as shown in Fig. 7, the extracted clean FECG using ICA from the recovered recordings by BSBL-FM(0) was almost the same as the extracted one from the original recordings.Epilepsy is a common chronic neurological disorder. About one out of every three patients with epilepsy continue to experience frequent seizures [24]. Using EEG signals as the proxy to identify and detect epilepsy seizures has been widely studied [25,26,24,27]. A low-energy designed telemonitoring framework is valuable for such application as it can provide all-day long continuous monitoring, which makes epilepsy more likely to be detected and suitably treated.The EEG dataset used in this experiment was the same as [28,24]. It consisted of EEG recordings with intractable seizures from 22 subjects. For each subject, there were hours of recordings with clinician annotated seizure segments. Such annotations were used to evaluate the epileptic classification results. The EEG dataset was sampled at 256Hz with 16-bit resolution. Our objective here is to evaluate the distortion of lossy compression via CS.In the experiment, EEG signals were divided into packets. Each packet was 2s long which contained N=512 samples. The ith packet was denoted as{xi1,…,xiC}, where C was the number of electrodes andxijwas the ith packet from electrode j. A binary sensing matrixΦwith two entries of 1s in each column (k=2) was generated. Each packet in {xi} was compressed using this sensing matrix, resulting in the compressed measurements {yi}.We used machine learning techniques to automatically detect the epileptic seizure packets. The diagram of the epileptic seizure classifier is shown in Fig. 8. The features used in this paper were non-linear features [26,25], namely approximate entropy [29], sample entropy [30], hurst exponential [31], and scale exponential [32]. These features were fed into a random forest (RF) [33] classifier to classify the epileptic seizure segments.The distortion introduced by CS varies with different CS solvers and different CR values. In this experiment, we varied CR from 0.5 to 0.9 and calculated the average PRD of each algorithm. The result is shown in Fig. 9. Again we saw that BSBL-FM(0) had similar recovery performance as BSBL-BO but was much faster.The AUC of the epileptic seizure classifier on the recovered signals was also calculated. The classifier was trained on 80% of the recovered dataset and tested on the rest dataset. Fig. 10shows the calculated AUCs when the classifier performed on the recovered signals by all algorithms at different CR values. The result showed that BSBL-FM(0) had similar recovery quality as BSBL-BO. All the BSBL based algorithms had comparable AUC metrics to the ‘non-compressed’ with CR ranging from 0.50 to 0.90.

@&#CONCLUSIONS@&#
