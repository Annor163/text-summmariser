@&#MAIN-TITLE@&#
A moving target DDoS defense mechanism

@&#HIGHLIGHTS@&#
We design a moving target mechanism to defend against Internet service DDoS attacks.We propose a shuffling model to segregate innocent clients from malicious insiders.A greedy algorithm is designed to accelerate the segregation of insiders.Greedy algorithm enables defenders to plan defense resource to meet QoS goals.

@&#KEYPHRASES@&#
DDoS,Moving target defense,Secret proxy,Insider,Shuffling,

@&#ABSTRACT@&#
In this paper, we introduce a moving target defense mechanism that defends authenticated clients against Internet service DDoS attacks. Our mechanism employs a group of dynamic, hidden proxies to relay traffic between authenticated clients and servers. By continuously replacing attacked proxies with backup proxies and reassigning (shuffling) the attacked clients onto the new proxies, innocent clients are segregated from malicious insiders through a series of shuffles. To accelerate the process of insider segregation, we designed an efficient greedy algorithm which is proven to have near optimal empirical performance. In addition, the insider quarantine capability of this greedy algorithm is studied and quantified to enable defenders to estimate the resource required to defend against DDoS attacks and meet defined QoS levels under various attack scenarios. Simulations were then performed which confirmed the theoretical results and showed that our mechanism is effective in mitigating the effects of a DDoS attack. The simulations also demonstrated that the overhead introduced by the shuffling procedure is low.

@&#INTRODUCTION@&#
Distributed denial-of-service (DDoS) attacks are a rapidly growing problem which poses an immense threat to the Internet. Arbor Networks reported a significant increase in the prevalence of large-scale distributed denial-of-service (DDoS) attacks in recent years [1]. In 2010, the largest reported bandwidth achieved by a flood-based DDoS attack reached 100Gbps. Even as the bandwidth of attacks has increased, the cost of performing a DDoS attack has turned out to be surprisingly low. A Trend Micro white paper [2] reported that the price for a 1-week DDoS attack could be as low as $150 on the Russian underground market.A number of mechanisms have been proposed in the past to prevent or mitigate the impact of DDoS attacks. Filtering-based approaches [3–5] use ubiquitously deployed filters that block unwanted traffic sent to the protected nodes. Capability-based defense mechanisms [6–9] endeavor to constrain resource usage by senders to beneath a threshold defined by the defended system. Secure overlay solutions [10–15] interpose a network of proxy nodes that redirect packets between clients and the protected nodes and are designed to absorb and filter out attack traffic. All these mechanisms are effective to varying degrees; but these static defense mechanisms either rely on the global deployment of additional functionalities on Internet routers or require large, robust, virtual networks designed to withstand the ever-larger attacks. Due to the large investment required and the vulnerability to sophisticated attacks such as sweeping [11] and adaptive flooding attacks [12], the development of novel, effective, efficient, and low cost defense mechanisms continues to be a high priority, but elusive goal.Motivated by the aforementioned elusive goal, we propose MOTAG[16], a MOving Target defense mechanism AGainst Internet DDoS attacks. This dynamic DDoS defense mechanism implements a scheme of moving proxy nodes to protect centralized online services. In particular, MOTAG offers DDoS resilience for authenticated clients of security sensitive services such as online banking and e-commerce. MOTAG employs a layer of secret moving proxy nodes to relay communications between clients and the protected application servers.The proxy nodes in MOTAG have two important characteristics. First, the proxy nodes are “secret” in that their IP addresses are concealed from the general public and are exclusively known only to legitimate clients and only after successful authentication. In order to avoid unnecessary information leakage, each authenticated client is provided with the IP address of only a single proxy node at any given time. Existing Proof-of-Work (PoW) schemes [17–20] are employed to protect the client authentication channel. Second, the proxy nodes are “moving”. As soon as an active proxy node is attacked, it is replaced by a set of alternate proxy nodes instantiated at a different IP address; and the clients associated with the attacked proxy node are migrated to alternative proxy node(s). We show that this migration to “secret” proxy nodes not only enables the MOTAG mechanism to mitigate brute-force DDoS attacks, but also provides a means to discover and isolate malicious insiders designed to divulge the location of the secret proxy nodes to external attackers. The malicious insiders are isolated via a shuffling process that reassigns and migrates clients through sequential sets of instantiated of proxy nodes. This paper presents the algorithms developed to (1) accurately estimate the number of insiders and (2) to dynamically determine client-to-proxy assignment that will “save” the largest number of legitimate clients after each shuffle.Unlike previously proposed DDoS defense mechanisms, MOTAG does not rely on global adoption on Internet routers or collaboration across different ISPs to function. Also MOTAG neither depends on resource-abundant overlay networks to out-muscle high bandwidth attacks nor uses filters to provide fault tolerance. Instead, we take advantage of our proxy nodes’ secrecy and mobility to fend off powerful DDoS attacks including sweeping and adaptive flooding attacks. Employing the MOTAG DDoS defense mechanism requires lower deployment costs while offering substantial defensive agility which results in effective and cost-efficient DDoS protection.This paper is an extension of the work we presented in [16]. The main contributions of this paper are:•A discussion of the reduction of the computational complexity of greedy algorithm fromO(N·Ni)toO(1)where N is the number of total clients andNiis the number of insiders.A theoretical and empirical analysis of the insider quarantine capability of the greedy algorithm.A discussion of a special DDoS attack case for which a simple and elegant shuffling mechanism is designed to segregate innocent clients from insiders.Instead of targeting open and general-purpose web services, we focused on protecting security sensitive online services against network flooding attacks. We assume that legitimate clients of the protected services are pre-authorized and their identities can be authenticated before they are served. We assume the availability of a cloud environment with sufficient computing power and bandwidth to instantiate numerous backup proxy nodes. Since only a small group of proxy nodes are active at any time, a cloud environment in which customers are charged only for running instances would be ideal to avoid extensive operational costs. We further assume that although powerful attackers with a high aggregate bandwidth are capable of simultaneously overwhelming many stand-alone machines on the Internet, attackers cannot saturate the well-provisioned Internet backbone links of ISPs, data centers, and cloud service providers.We also assume that attackers, in case of uncertainty, can first perform reconnaissance attacks (e.g., IP and port scanning) to pinpoint targets for the subsequent flooding attacks. With knowledge of the MOTAG mechanism, attackers could attempt to flood the authentication channel through which the legitimate clients are admitted. Successful attacks against the authentication server are considered unlikely because it employs proof-of-work (PoW) schemes to prevent both computational and network flooding attack. MOTAG takes advantage of PoW schemes that are designed to prevent computational attacks. In a cloud environment, the ability of lightweight PoW schemes to quickly reject non-authentication requests makes it resistant to flooding attacks. Since it is significantly harder for attackers to pass strong authentication by brute force and reach the proxy nodes as legitimate clients, some attackers will attempt to uncover the network locations of proxy nodes and may plant ”insiders” by compromising legitimate clients or eavesdropping on legitimate clients’ network connections. However, the number of such insiders in a protected system is assumed to be limited.The proposed MOTAG mechanism employs a group of dynamic proxy nodes that relay traffic between servers and authenticated clients and that provide a moving target defense mechanism that mitigates Internet service DDoS attacks. The IP address of the proxy nodes are hidden from clients (and potential attackers), and each client can only see the IP address of the proxy node to which he is randomly assigned. Therefore, insiders will only be able to attack the proxy node(s) to which they are assigned, and the innocent clients who are impacted by the attack will be only those who share the proxy node(s) with the insiders. In order to separate affected innocent clients from insiders, MOTAG instantiates proxy nodes and performs client-to-proxy reassignment under the guidance of the shuffling algorithm discussed in Sections 4 and 5. In the following sections, we first give an overview of MOTAG, and then introduce the main components in greater detail.Fig. 1shows the overall architecture of MOTAG which consists of four inter-connected components: the authentication server, the proxy nodes, the filter ring, and the application server. The application server provides the online services (e.g., banking or e-commerce services) that we want to protect and make accessible to authenticated clients. The IP address of the application server is concealed from all clients and all traffic is relayed to the application server via the proxy nodes. The filter ring, similar to what was described in [12], is comprised of a number of high speed routers placed around the application server which allows inbound traffic only from valid proxy nodes. The proxy nodes are a group of dynamic and distributed cloud instantiations that relay communications between clients and the application server. The authentication server is responsible for authenticating clients, assigning legitimate ones to individual proxy nodes, and coordinating the shuffling of clients.MOTAG allows a client to access the application server via a proxy node only if the client can be successfully authenticated. One simple solution is to associate the application domain name with the IP address of the authentication server during DNS registration. Each successfully authenticated client is then randomly assigned to one of the active proxy nodes whose identities are not publicly known. The authentication server will inform each client of the IP address of a designated proxy node, and simultaneously notify the proxy node of the forthcoming connection from the client. This communication between the authentication server and the proxy nodes is via a dedicated signaling channel. Through this signaling channel, proxy nodes report to the authentication server if they are under attack. The authentication server also uses this channel to inform proxy nodes of client assignments and to support coordination of their actions against DDoS attacks.The authentication server also assigns a capability token for each client-to-proxy session. This token is used to limit a client’s throughput by specifying the number of packets (or, the number of bytes) allowed for the session in the next time window (t seconds). In order to validate a client connection, a proxy node should receive two identical copies of a capability token; one from the authentication server as notification of a new authenticated client assignment, and one from the client as a proof of identity. Every proxy node maintains a per session counter and regulates traffic according to individual capability. Such capability-based policing is key to detecting external, brute-force flooding attacks in that it allows proxy nodes to distinguish between authorized packets and illegal ones. Furthermore, the use of a capability token helps frustrate an internal attempt to abuse the assigned capability.For communications between proxy nodes and the application server, a lightweight authenticator as described in Mayday [12] can be employed for proxy identity validation. The filter ring routers can perform fast look-ups to verify such lightweight authenticators in proxy-to-application packets. These authenticators can be dynamically altered, and active proxy nodes will receive timely updates via the signaling channel. To prevent the authentication server from being flooded by botnets, we employ proof-of-work (PoW) schemes [17–20] to ensure its accessibility for legitimate clients.Overall, the procedure that a client needs to go through in order to get access to the application server is: First, the client resolves the domain name of the target web service via a DNS and is redirected to the authentication sever (step 1). Upon authentication, the authentication server assigns the client randomly to a proxy node. Both the client and proxy will receive a capability token (step 2) that serves to notify each of the client-to-proxy node assignment (including IP addresses) and provides a means of validating the client to the proxy node. The client can then communicate with application server via the proxy node (step 3). The specifics of the implementation of the proxy nodes and authentication server are discussed below.MOTAG is designed to take advantage of the unique capabilities of a cloud environment. The MOTAG builds an intermediate layer consisting of a pool of geographically distributed proxy nodes designed to diffuse attackers’ traffic and insulate the application server. When not under DDoS attack, only a small subset of the available proxy nodes are active. These active proxy nodes provide sufficient capability to relay normal traffic to the application server. When under DDoS attack, dynamically instantiated proxy nodes are substituted for the attacked proxy nodes in real time, confusing attackers with “moving” target proxy nodes. The “moving” proxy nodes are resilient to scanning attacks because they only respond to IP addresses of the authenticated clients.When under attack, a proxy node informs the authentication server, and the authentication server coordinates the instantiation of new proxy node(s) at different network locations. Clients (both innocent and insiders) on the attacked proxy node(s) are migrated to the newly instantiated proxy nodes, and the proxy node(s) under attack are shut down. Proxy instantiation and client migration is a fast, lightweight operation because all session information is centrally stored at the application server; and all proxy nodes run the same, simple traffic redirection logic and maintain no client state. The clients connected to the under attack proxy node(s) are re-assigned across the entire set of active proxy nodes. The new client-to-proxy node assignments can be pushed to the affected clients by the authentication server, or the clients can be made to re-authenticated for security assurance. The overall process of proxy replacement and client re-assignment is called client-to-proxy shuffling, and details of the shuffling algorithm are presented in Section 4. No shuffling is performed if there is no attack, and only a small set of proxy nodes with constant IP addresses are required to serve all legitimate clients.MOTAG is different from existing overlay network solutions [10–12,15], which rely on a fairly static, high-capacity, network composition of overlay nodes to tolerate and filter out the attack traffic. Building and maintaining such an overlay entails extensive and continuous investment to acquire more nodes and bandwidth. As currently implemented, existing overlay networks may be subject to sever service disruptions due to sweeping [11] and adaptive [12] flooding attacks. In contrast, MOTAG proxy nodes are dynamic and their IP addresses are kept confidential. The combination of these two factors serves to enhance the agility of the MOTAG defense mechanism against massive, sophisticated attacks while reducing dependence on the capacity of individual proxy resources.An authentication server with assured accessibility is essential to our moving target defense. It acts as the initial checkpoint to separate legitimate clients from external attackers. MOTAG uses established authentication procedures as a mechanism to bind a client to a specific network flow. Only with such a unique binding is the authentication server able to keep track of the proxy to which each client is assigned throughout the shuffling process. Since each client has to pass authentication before being assigned to a proxy node, the IP addresses of authenticated clients are recorded and sent to proxy nodes and used by the proxy nodes to enforce IP-based filtering. The authentication server is also responsible for coordinating subsequent client-to-proxy assignments during shuffling. MOTAG is agnostic to the specific authentication mechanism employed.The authentication server is the only part of the MOTAG architecture that can be publicly addressed. Therefore, only it can be a target of non-insider assisted, distributed flooding attacks. To mitigate this type of attack, the authentication server takes advantage of existing proof-of-work (PoW) schemes [17–20], which force clients to solve cryptographic puzzles before allowing them to consume resources on the application server. Using the PoW schemes, the authentication server can realize per-computation fairness regarding bandwidth usage among all clients [20], prevent connection depletion attacks [19], and mitigate DDoS attacks on application-level authentication protocols [17,18]. Although mandating the extra computational tasks involved with PoW schemes can help reduce attackers’ throughput, it also imposes considerable burden on legitimate clients. Therefore, PoW approaches are suitable for client authentication mechanisms that require authentication packets to be sent infrequently and which are delay-tolerant. However, PoW schemes are not preferred for securing application data communication due to their high overhead.While using hidden proxy nodes and enforcing client authentication can effectively prevent external attackers from reaching MOTAG’s packet delivery system, implementing a shuffling process that employs mobile proxies and intelligent shuffling of client-to-proxy assignments enables MOTAG to also mitigate insider attacks designed to expose the hidden proxy nodes to flooding attacks.Under our assumptions, the use of effective authentication prevents DDoS attacks from external attackers. Therefore MOTAG is designed to combat attacks from authenticated users (insiders). Attackers can gain access to the application server and implant malicious insiders in the targeted system via social engineering, compromising legitimate clients, stealing clients’ identities for authentication, and eavesdropping on clients’ network connections. Insider attacks within a protected system are the results of targeted attacks with relatively high technical sophistication. Thus, the number of functioning insiders is expected to be small (maybe hundreds) compared to a typical external-only DDoS attack. Nevertheless, the damage they can cause is still significant. Once insiders uncover the IP addresses of some proxy nodes, they will notify external attackers who will carry out DDoS attacks against these exposed proxies. MOTAG is designed to combat such insider-assisted DDoS attacks, or simply insider attacks. Although insider-assisted attacks cannot be fully prevented, MOTAG aims to minimize their impact on innocent clients. In this portion of the paper, we discuss a client-to-proxy shuffling mechanism designed to quarantine insider attacks over time and ensure service accessibility for as many innocent clients as possible.In MOTAG, cloud computing capacity and bandwidth is reserved to meet the needs of the proxy nodes used in normal operations as well as providing sufficient capacity to instantiate a large number of additional proxy nodes. In the event of a DDoS attack, a small number of additional proxy nodes are instantiated. The total set of instantiated proxy nodes can be logically classified into two groups: namely serving proxy nodes and shuffling proxy nodes. The relatively static serving proxy nodes provide more reliable connection services for known innocent clients, while shuffling proxy nodes are responsible for the dynamic shuffling operations and are designed to provide intermittent connections to suspicious clients. During the course of an attack, sets of shuffling proxy nodes will be replaced and the associated clients reassigned to new shuffling proxy nodes. This shuffling of clients provides a continually moving target for insider-assisted attacks and allows MOTAG to isolate malicious insiders.Prior to an attack, all the active proxy nodes are unmarked, and clients are randomly assigned to proxy nodes by the authentication server. Each client is assigned to only one proxy node. Proxy nodes that are subsequently attacked will be marked as shuffling proxy nodes while the unattacked proxy nodes remain unmarked and are still considered serving proxy nodes. Once a proxy node or nodes comes under attack, the authentication server employs the greedy algorithm described in Section 5.1 to repeatedly shuffle the client-to-proxy assignments within the shuffling proxy group to distinguish between, and eventually segregate, insiders and innocent clients.After each shuffle, some shuffling proxy nodes will still be under attack, and some will not. The shuffling proxy nodes that are no longer under attack are unmarked and become serving proxy nodes and the associated clients are marked as trusted and considered as saved from the on-going attack (i.e. no longer affected by the attack). Clients connected to the attacked proxy nodes are considered untrusted since we cannot determine which clients are insiders. To save the innocent clients from among the untrusted group, the authentication server randomly re-distributes all the untrusted clients across the shuffling proxy nodes. Given an estimated number of suspicious clients and the available proxy nodes, new proxy nodes can be instantiated as shuffling proxy nodes to accelerate shuffling operations. As will be shown later, the more nodes used as shuffling proxies, the faster insiders will be quarantined and innocent clients saved. By repeating the client-to-proxy shuffling for multiple rounds and keeping record of the suspicious proxies/clients, most of the innocent clients can be gradually identified. Based on the estimated number of insiders and given a desired percentage of clients to be saved, the greedy algorithm initiates a limited number of shuffling rounds after which the (expected) percentage of innocent clients will be saved, the remaining clients will be quarantined, and the attack damage will be minimized.In order to reduce overhead, the shuffling process is stateless, meaning each shuffle is considered independent. The tags (trusted/untrusted) that are placed on clients are reset after each shuffle. These tags do not necessarily reflect the true identity of the clients, but instead characterize the proxy node to which they are assigned. Also, the roles of proxy nodes (shuffling/serving) are interchangeable across shuffles, depending on the behavior of attackers, i.e previously unmarked proxy nodes can become shuffling proxy nodes if attacked during the shuffling process. The goal of shuffling operations is to separate innocent but attacked/suspected clients from true insiders. Because of the iterative nature of the sequential shuffles and since the characteristics of the individual clients are not used to determine the maliciousness of the client, insider attempts to mimic innocent clients will not affect MOTAG’s ability to detect and isolate attackers.Fig. 2illustrates how client-to-proxy shuffling works. Initially, seven clients (including insiders, denoted byC1,…,C7) are randomly assigned to three proxy nodes (denoted byK1,K2, andK3), as suggested by the dotted lines: ClientC1,C2, andC3are assigned to proxy nodeK1, clientsC4andC5are assigned to proxy nodeK2, and clientsC6andC7are assigned to proxy nodeK3. In this example, clientsC3andC5are insiders; they will divulge the location of the proxies in which they reside and bring an attack to proxy nodesK1andK2. In this case proxy nodesK1andK2are marked as shuffling proxy nodes, and since the identity of specific clients cannot be determined, clientsC1-5are equally suspicious. As a result, the MOTAG reacts by replacing shuffling proxy nodesK1andK2with new shuffling proxy nodesK4andK5. Clients and insiders previously assigned toK1andK2are re-assigned toK4andK5. One possible reassignment scheme assignsC1,C3, andC5toK4, while assigningC2andC4toK5, as indicated by the solid lines. In this case,K5was not under attack and the clients onK5are saved. Conversely,K4is still be under attack and the clients on it are suspect. The assignment of clientsC6,C7andK3remain unchanged because they are not affected by the attack. As a result of this shuffle, onlyK4remains marked as a shuffling proxy node, and it’s associated clients marked as suspect. OnlyK4will be involved in the next round of shuffling. Whereas proxy nodesK3andK5are unmarked as serving proxy nodes and will not be involved in the next round of shuffling.To mitigate insider attacks as quickly as possible, and also to adapt to system dynamics such as client mobility, we need a shuffling algorithm that can identify and separate as many innocent clients as possible per shuffle. To that end, we first analyzed the effect of different client-to-proxy assignment schemes on the desired number of innocent clients saved. The main notations used in this model are summarized in Table 1.Specifically, among a total number of N clients to be shuffled, the number of insiders isNi, and the number of innocent clients isNc; so we haveNi+Nc=N.1We provide a method to estimate the number of insiders in Section 5.4.1After one round of shuffling,Ncainnocent clients are still being attacked, andNcuof them are not (Nca+Ncu=Nc). Our goal is to mathematically compute the expected value ofNcu(denoted asE(Ncu)) under different circumstances and find a method that maximize it given K available shuffling proxies. We useAjto represent the number of clients appointed to proxy j. Given thatE(Ncu)=∑j=1KpjAj, wherepjis the probability that proxy j is not under attack, an arbitrary proxy j, it is not under attack only when none of the insiders are connecting to it. Hence,pjis also the probability that all insiders are assigned to proxy nodes other than j. According to simple combinatorics,pj=N-AjNiNNi, whereNNiis the total number of ways to distribute theNiinsiders in the population N, andN-AjNiis the number of combinations in which all insiders are in theN-Ajclients not connecting to proxy j. Therefore, the expected value ofNcucan be calculated by Eq. (4.1).(4.1)E(Ncu)=∑j=1KpjAj=∑j=1KN-AjNiAjNNiFrom the above we also haveE(Nca)=Nc-E(Ncu).Given the total number of clients N, the number of insidersNi, the number of shuffling proxies K, and the client-to-proxy assignment vectorA, we want to maximizeE(Ncu). As a result of analyzing Eq. (4.1), increasing the number of shuffling proxy nodes also increases the number of clients that are expected to be saved in each shuffle. In the extreme case whereK⩾N, each client can be allocated to an exclusive proxy node (Aj=1,∀j∈(1,K)).E(Ncu)=Ncimplies that, in this case, no innocent client will be attacked. This is the ideal scenario where all insiders are quarantined within their own proxy nodes in a single round of shuffling. However, due to resource constraints, it will typically not be cost-effective to provide a dedicated proxy node for each client. In most cases, the client population would greatly outnumber the shuffling proxies (K≪N). Consequently, the method of distributing clients across proxy nodes becomes vitally important to the number of clients saved.Assuming we have a constant number of K shuffling proxy nodes, we are facing an optimization/maximization problem with Eq. (4.1) as the objective function. The variables are summarized into the vectorAof natural numbers that defines the client-to-proxy assignment scheme, with the constraint being(4.2)∑j=1KAj=N,whereA∈NKAlthough recursive algorithms such as dynamic programming can be employed to compute the optimal solution, we adopt a greedy approach described in Section 5.1 to produce a quick and near-optimal solution. Our simulations of various configurations showed that the results produced by the greedy algorithm approached very closely the theoretical upper bound ofE(Ncu).Before presenting the greedy algorithm solution to the client-to-proxy shuffling optimization problem in Section 5.1, we will first introduce a simple, elegant, and straightforward optimal solution to a special case of the general problem. We note that when the number of insiders (Ni) is less than or equal to the number of proxies (K), then evenly distributing all clients among all shuffling proxies will be optimal in saving maximum number of clients.Theorem 1Evenly distributing clients to all shuffling proxies maximizesE(Ncu)whenNi⩽Kand client-to-proxy distribution is uniform.We prove Theorem 1 using the exchange argument. For simplicity without loss of generality, we consider an arbitrary pair of proxy nodes among all shuffling proxy nodes. Assuming these two proxy nodes are the ith and jth proxy nodes, and there areAiandAjclients on them respectively, whereAi+Aj=T. Given that client-to-proxy distribution is uniform andNi⩽K(K=2), it is expected that there are 1 or 2 insiders here, i.e.Ni=1or 2. Using Eq. (4.1), whenNi=1, we haveE(Ncu)=T-Ai1·AiT1+T-Aj1·AjT1=2·Ai·AjTWhenNi=2, we haveE(Ncu)=T-Ai2·AiT2+T-Aj2·AjT2=Ai·Aj·(T-2)T·(T-1)In both cases,Ai=AjmaximizesE(Ncu). Since this pair of shuffling proxy nodes is randomly chosen, we can iteratively apply the exchange argument to any pair of shuffling proxy nodes, and eventually every proxy node will have the same number of clients. From this we can conclude thatE(Ncu)is maximized when all proxy nodes are assigned an equal number of clients.□As a result, in the special case where the number of insiders is less than or equal to the number of shuffling proxies, we can obtain an optimal client-to-proxy assignment inO(1)by randomly assigningNi/Kclients to each of the shuffling proxy nodes. Next we will discuss the general case solved by a greedy algorithm.In this section, we present a greedy algorithm for guiding client-to-proxy shuffling. First, we show a naive version of the greedy algorithm which applies an enumeration approach in finding the local optimal. Then by applying approximation techniques, we improve the greedy algorithm and dramatically reduce its computational complexity. Next, we theoretically investigate the insider quarantine capability of the greedy algorithm under various attack scenarios. Finally, to support the greedy algorithm, we present maximum-likelihood estimation (MLE) approach for estimating the number of insiders.As determined from the previous discussion, evenly distributing all clients to all proxy nodes is optimal for saving clients when the number of insiders is less than or equal to the number of clients. However, in reality, the number of insiders can be far greater than the number of proxy nodes. In this more likely case, evenly distributing clients may result in all proxy nodes being under attack and thus shuffling may be unable to save clients efficiently. Therefore, the strategy of evenly distributing clients among proxy nodes may not be applicable to the case when the number of insider is far more than the proxy number. This motivated us to design a shuffling algorithm that can be applicable to general case.Intuitively, assigning fewer clients to a given proxy node should reduce the probability of introducing insiders to this proxy. However, if the proxy node is not under attack, assigning fewer clients to it also results in fewer clients being saved. Therefore, an efficient shuffling algorithm was needed to determine how many clients to assign to each proxy node in order to maximize the expected number of clients saved among all proxy nodes.Based on this intuition, the greedy algorithm decides how many clients to assign to a given proxy node, one proxy node at a time, based on the goal of maximizing the overall expected number of clients to be saved in a given shuffle. For an arbitrary proxy j, the number of clients assigned to it and the number of innocent clients that are expectedly to be saved are denoted asAjandE(Aj), respectively. The greedy algorithm computesE(Aj)as follows.(5.1)E(Aj)=N-NjAjNAj·AjThe detailed procedure of greedy algorithm used in computing the client-to-proxy assignment is shown in Algorithm 1. The main function is called GreedyAssign. Since in Eq. (4.1)E(Ncu)is the sum of expected number of clients saved for each proxy node (i.e.pj·Aj) for all the active shuffling proxy nodes, an optimality analysis was first performed for an individual shuffling proxy node. For an arbitrary proxy nodej,Ajcan be any value within[0,N-1].Ajcannot be N; otherwise, all clients would be under attack if there is a single insider present.Since the value ofNiwill affect the optimal choice ofAj, for a particularNi, all possible values ofAjwill be enumerated and the parameterωthat maximizedpj·Ajwill then be selected. This subroutine is described in procedure MaxProxy of Algorithm 1. Under our greedy approach, we assignωclients to as many proxy nodes as possible.Function GreedyAssign is called recursively to assign the remaining clients to the rest of the proxy nodes. The computation will terminate when any one of three conditions is met: first, when there are more proxy nodes left than clients, i.e. when each client will be assigned to an exclusive proxy node; second, when there is only one proxy node left, i.e. all remaining clients will be appointed to a single proxy node; and, third, when the expected number of remaining insiders is rounded to 0, i.e. there are no insiders, and all remaining clients will be evenly distributed for load balancing. The overall computational complexity of the greedy algorithm isO(N·Ni). To further reduce the computational overhead throughout the shuffling procedures, the client-to-proxy assignment vectors for differentN,K,Nicombinations can be pre-computed and stored in lookup tables for runtime reference.Algorithm 1. Greedy algorithm for computing client-to-proxy assignmentfunctionGreedyAssignClient,Insider,ProxifClient⩽ProxthenAssign1exclusive proxy to each clientelse ifProx=1thenAssign all clients to the proxyelse ifInsider=0thenEvenly distributeClientoverProxelseω=MaxProxy(Client,0,Client-1,Insider)ProxToFill=⌊Client/ω⌋ifProxToFill⩾ProxthenProxToFill=Prox-1end ifRemC=Client-ProxToFill·ωRemP=Prox-ProxToFillRemA=RoundInsider·RemCClientFillProxToFillproxy nodes withωclients eachFill the rest proxy nodes according toGreedyAssign(RemC,RemA,RemP)end ifend functionprocedure MaxProxy(Client,Lbnd,Ubnd,Insider)Max=0,MaxAssign=0fori=Lbnd→UbnddoSave=Client-iInsider·i/ClientInsiderifSave>MaxthenMax=Save,MaxAssign=iend ifend forreturnMaxAssignprocedureTo evaluate the optimality of the greedy algorithm, the results of experimental implementations were compared with the theoretical upper bound ofE(Ncu). Since Eq. (4.1) is a summation ofpj·Ajfor each individual shuffling proxy j, the maximal value of (4.1) cannot be greater than the sum of the max of eachpj·Ajwhen relaxing Constraint (4.2), i.e.Max(E(Ncu))⩽K·Max(pj·Aj). Here,Max(pj·Aj)can be obtained by running subroutine MaxProxy (N,0,N-1,Ni). The comparison between the greedy algorithm and the theoretical upper bound is done via simulations under various configurations on MATLAB. The results are presented in Section 6.As discussed above, the greedy algorithm aims to maximize the overall number of innocent clients expected to be saved by summing up the expected number of clients saved in each single proxy. The subroutine MaxProxy of Algorithm 1 finds the value ofAithat maximizesE(Ai)in Eq. (5.1) by enumerating all possible choices. For the purpose of the discussion, we name this approach the enumeration approach. The enumeration approach can find the optimal value ofAiinO(N·Ni)time complexity, where N denotes the total number of all clients andNidenotes the number of insiders among the clients. Therefore, as N andNigets larger, the running time of the subroutine MaxProxy will become notably longer.To improve the efficiency of the greedy algorithm, we designed an approximation approach that can find a near-optimal value ofAiinO(1)time complexity. This is done by solving Eq. (5.1) using Stirling’s Approximationn!≈nen2πn, and a series of other approximations assumingNi≪N, as follows.E(Ai)=(N-Ni)!(N-Ai)!(N-Ni-Ai)!N!·Ai≈(N-Ni)N-Ni(N-Ai)N-Ai(N-Ni)(N-Ai)(N-Ni-Ai)N-Ni-AiNN(N-Ni-Ai)N·Ai≈(N-Ni)N-Ni(N-Ai)N-Ai(N-Ni-Ai)N-Ni-AiNN·Ai≈N-NiNAi·AiLetAi=N·xNi, we have(5.2)E(Ai)=1-NiNN·xNi·N·xNi=e-xN·xNiAfter applying approximationlimn→∞1-1/nn≈e-1on the derivation of Eq. (5.2), we get(5.3)∂E(Ai)∂x=e-x·NNi·(1-x)From Eq. (5.3), the derivation ofE(Ai)equals 0 if and only ifx=1. In other words,x=1maximizesE(Ai). As a result, assigningAi=NNiclients to proxy i will optimize the expected number of benign clients that can be saved, which is(5.4)EAi=NNi=NNi·eWith the analysis above, we can improve the greedy algorithm by using an approximation approach for the subroutine MaxProxy. Unlike the enumeration approach which enumerates all the possible values ofAito find an optimal value that could maximize Eq. (5.1), the approximation approach computes the value ofAionly based on the total client number and number of insiders, i.e.Ai=NNi. The enumeration approach has computational complexityO(N·Ni)while approximation approach has computational complexityO(1).To evaluate the accuracy and the optimality of the approximation approach, we compared it to the enumeration approach using a series of simulations in MATLAB. Fig. 3shows the number of clients that should be assigned to a given proxy node in order to save the expected maximum number of innocent clients from one proxy node under varying conditions for both the enumeration and the approximation approach. Since the enumeration approach enumerates and compares all possible choices, we know that its results are optimal. In Fig. 3, the results produced by the approximation approach overlap with those given by the enumeration approach in almost all cases indicating that the approximation approach is nearly optimal.For ease of presentation, we term the algorithm which adopts the enumeration approach to implement MaxProxy subroutine as greedy algorithm, and name the variant which replaces the enumeration approach with approximation approach as the improved greedy algorithm. Taking the analysis one step further, we implemented both the greedy algorithm and the improved greedy algorithm in MATLAB and ran simulations with varying numbers of insiders and clients. In Fig. 4, the y-axis represents the deviation between the improved greedy algorithm and the greedy algorithm in the percentage of clients saved. The y-axis values were computed usingy=s2-s1s1, wheres1ands2were the percentage of clients saved under greedy and improved greedy algorithm respectively. From Fig. 4, we can see that the deviation was consistently less than1%, and from this we can conclude that the improved greedy algorithm has performance very close to the greedy algorithm.Since the improved greedy algorithm has a lower time complexity in deciding client-to-proxy assignment (i.e.O(1)), is likely to be computationally faster, and generates near-optimal results, we believe the improved greedy approach is preferable for practical usage.Since we are able to demonstrate that the greedy algorithm provides a near-optimal method for assigning clients to proxy nodes in order to save the maximum number of clients, we next approached the problem of estimating the insider quarantine capability of the greedy algorithm. This issue is considered very important since knowing the insider quarantine capability of the greedy algorithm would aid in estimating the number of proxy nodes to instantiate as shuffling proxy nodes in order to meet quality of service (QoS) goals. Here, QoS refers to the specific percentage of clients saved.The insider quarantine capability is defined as the percentage of clients can be quarantined (saved) from insiders given N clients (among whichNiare insiders), K proxy nodes and j rounds of shuffling. As is discussed in Section 5.2, the enumeration and the approximation approaches can both be used in the subroutine MaxProxy of greedy algorithm to achieve near-optimal assignment of clients to each shuffling proxy node. Since the approximation approach has performance close to that of the enumeration approach and is likely to perform faster, we used the approximation approach based greedy algorithm in analyzing the insider quarantine capability.Eq. (5.4) shows the number of clients that can be saved in one proxy node when there are N client andNiinsiders. From this equation it is evident that the number of clients saved is dependent on the number of shuffling proxy nodes used. Recall that the greedy algorithm tries to assignN/Niclients to as many proxy nodes as possible, and put the rest of clients in the last proxy. Typically, the number of insiders is much larger than the number of shuffling proxy nodes, i.e.Ni≫K, the last proxy is likely to be assigned far more clients than the other proxy nodes. Therefore, the last proxy is likely to have the highest probability of being attacked. For ease of analysis, we assume it will always be attacked. Thus the maximum expected number of clients saved will be the summation of the expected number of clients saved in the firstK-1proxy nodes, i.e.(K-1)·NNi·e. Let y be the percentage of clients saved among all N clients in one round of shuffle, then we have:(5.5)y=K-1Ni·eAs the number of insiders (Ni) will almost be the same each round and the number of shuffling proxy nodes (K) is a constant, we can regard y as the same number in each round of shuffling. If we defineE(Uj)as the percentage of clients not saved andE(Sj)as the percentage of clients saved after j rounds of shuffle, then we haveE(Uj)=(1-y)j. Therefore, the percentage of clients saved in the first j rounds of shuffle is:(5.6)E(Sj)=1-E(Uj)=1-1-K-1Ni·ejThis result indicates that the percentage of clients saved with j rounds of shuffle only depends on the number of insiders,Ni, and the number of proxy nodes, K. The total number of clients,N, will not affect the percentage of clients saved.In order to confirm the correctness of the achieved theoretical results, simulations were conducted using constant values for the number of shuffling proxy nodes and insiders (100 and 500 respectively), using10K,50K,100Kinnocent clients and varying the number of rounds of shuffling. In Fig. 5, the y-axis represents the accumulated percentage of clients saved for each value of the number of innocent clients. In all cases the experimental results very nearly overlap with the theoretical results. The small differences can probably be attributed to the use of the approximation approach in the greedy algorithm.In our earlier discussion, we assume the number of insiders (Ni) is fixed and given; however, in practice, we have no such prior knowledge. Since the value ofNihas direct influence on the client-to-proxy assignment, accurate estimation is important to the efficiency of the shuffling mechanism. We investigated the use of a maximum-likelihood estimation (MLE) as a source of an estimate of the number insiders.In order to use the MLE, it was necessary to establish a connection between the number of insidersNiand the number of proxy nodes that are not under attack (denoted as X). In a particular attack whereX=m, we can calculate the probabilitiesPr(X=m)with regard to differentNivalues, and use theNivalue that maximizes the probability as the estimated number of insiders. According to the inclusion–exclusion principle under balls-and-urns model [21], we can compose Eq. (5.7) to calculatePr(X=m), wherePr(X⩾M)stands for the probability that at least M (M=m,m+1,…,K) proxy nodes are not attacked, K is the total number of all shuffling proxy nodes.(5.7)Pr(X=m)=Pr(X⩾m)-m+1mPr(X⩾(m+1))+m+2mPr(X⩾(m+2))-…+(-1)K-mKmPr(X⩾K)In particular, these M not-under-attack proxy nodes constitute the setU={u1,u2,…,uM}, whereujis the real ID of the jth available proxy node. SetUcan be any M sized subset of the K shuffling proxy nodes.The derivation ofPr(X⩾M)is similar to the derivation of Eq. (4.1). If a particular setUof proxy nodes are not attacked, the insiders must be among the clients assigned to the remaining proxy nodes (the complement ofU). Thus, we have Eq. (5.8), in which∑U(M)denotes the summation over all possible combinations ofU(all M sized subsets of the K shuffling proxy nodes), andN-∑j=1MAujgives the number of clients connecting to the proxy nodes not inU.ujis an arbitrary proxy node in the set, andAujdenotes the number of clients assigned to that node.(5.8)Pr(X⩾M)=∑U(M)N-∑j=1MAujNiNNiUnder a certain client-to-proxy assignment schemeA, we can now derivePr(X=m)withNiby combining Eq. (5.7) and (5.8).To evaluate the insider estimation algorithm, simulations were run in MATLAB varying the number of insiders. Based on the number of attacked proxy nodes, the algorithm uses the MLE to estimate the real number of insiders. The estimate of the number of insiders that maximizes the result of Eq. (5.7) is used as the overall estimate. These estimations are plotted against the actual numbers of insiders in Fig. 6. For each data point, we ran the simulation 30 times to compute the mean and 99% confidence intervals. The overlapping plots and the small error bound (relative to the number of insiders) indicate that the MLE estimate of the number of insiders is quite accurate.In the previous discussions, we generated a theoretical basis for MOTAG and demonstrated via simulations, that our assumptions do not significantly degrade its expected performance. In this section, we assess the overall effectiveness of the MOTAG in mitigating the effects of a DDoS attack and evaluate the overhead introduced by the shuffling mechanism.In evaluating the effectiveness of MOTAG, we (1) compared the performance of an implementation of MOTAG using the greedy algorithm to the theoretical upper bound discussed in the previous sections, and (2) demonstrated that the greedy algorithm can segregate innocent clients from insiders in only a few shuffles.In the simulations, we implemented the algorithms of MOTAG on MATLAB and simulated various combinations of the number of clients, the number of insiders, the number of shuffling proxy nodes. Although MOTAG does not require any of these factors to remain constant from shuffle to shuffle, for ease of comparison, all these factor were held constant during each simulation run (series of shuffles). In each simulation, the clients designated as insiders were randomly selected from the pool of clients using Mersenne twister [22] as our random number generator. The insiders were assumed to always generate attacks on the proxy nodes to which they were connected, and the attackers were assumed to have sufficient bandwidth to overwhelm an attacked proxy node. In practice, this means that a single insider assigned to a proxy node will ensure that node is attacked. However, as discussed earlier, due to the strong authentication enforced by the authentication server, we assumed only a limited number of insiders (hundreds) will be able to initiate attacks. In these simulations, MOTAG used the MLE method from Section 5.4 to estimate the number of insiders and uses the greedy algorithm from Section 5.1 to determine the client-to-proxy assignments for the each shuffle.Fig. 7shows the number of shuffles needed to save 80% and 95% of the innocent clients using the greedy algorithm (solid lines) and the theoretical upper bound from Section 5.1 (dotted lines). As was expected, saving a specific percentage of the innocent clients requires more shuffles as the number of insiders increases and fewer shuffles as the number of shuffling proxy nodes increases. In Fig. 7(a) and (b) the total number of clients (10k for Fig. 7(a) and 100k for Fig. 7(b)) and the number of shuffling proxy nodes (100) are held constant while the number of insiders varies from 10 to 500. In Fig. 7(c) and (d) the total number of clients are the same as in the previous two figures, but the number of insiders is held constant at 100 and the number of shuffling proxy nodes varies between 40 and 500. Each simulation was run 30 times to generate average data points and 99% confidence intervals.Overall, the results of the simulations presented above indicate that the performance of MOTAG is close to the theoretical optimum. This suggests that the reassignment of clients to shuffling proxy nodes is also nearly optimal. Specific conclusions can be drawn from the individual figures. Fig. 7(a) and (b) show that the number of shuffles needed to save the same percentage of innocent clients grows approximately linearly with the increase in the number of insiders. Similarly, Fig. 7(c) and (d) indicate that the number of shuffles required to save a given percentage of innocent clients increases when fewer proxy nodes are used in each shuffle. The number of shuffles rises slowly while the number of proxy nodes outnumbers the insiders, but that number begins to rise ever more steeply when the number of proxy nodes falls below the number of insiders (100). Moreover, the narrow confidence intervals of all the data points indicate that the performance of the MOTAG shuffling algorithm is reliable and predictable.Fig. 8shows the relationship between the number of insiders and the number of shuffling proxy nodes for 5, 10, and 15 shuffles with the number of clients held constant at 10k (solid lines) and 100k (dotted lines). For both cases, when 80% and 95% of the innocent clients are saved, there seems to be a nearly linear relationship between the number of required shuffling proxy nodes and the number of insiders. Also, the 10-fold increase, from 10K to 100K, in the number of clients does not require a similar 10-fold increase in the number of shuffling proxy nodes. This seems to indicate that the greedy shuffling algorithm is robust with respect to the number of innocent clients. Overall, the simulation results show that MOTAG is effective in mitigating the effect of DDoS attack initiated by hundreds of insiders within a few shuffling.The experimental results presented above indicate that using MOTAG would be effective in defense, but implementing MOTAG would also increase the overhead in the communications between clients and the application server due to the proxy-based communication relay and the client-to-proxy shuffling.First, to assess the overhead introduced by proxy-based traffic relays, 10 geographically distinct U.S. nodes were selected from PlanetLab to form 5 end-to-end flows. Also, 24 other nodes that spread across the country were selected to serve as proxy nodes. The latency and throughput for both direct and relayed communications were measured for each of the 5 flows, and the results are shown in Tables 2 and 3, respectively. SSH tunneling through individual proxy nodes was employed to redirect traffic between end nodes. Mean round trip times (RTT) were obtained by bouncing short TCP messages back and forth between the end nodes of each flow 100 times. Throughput data was the average of 10 Iperf [23] sessions. From the tables, the impact of introducing proxy nodes on latency (usually less than 30%) is much less significant than its influence on throughput. The drop in throughput is not only due to traffic redirection in the proxy nodes, but is also a result of message encryption and decryption by SSH agents. Since MOTAG does not specify communication protocols, various cryptographic strategies, including no encryption, can be listed as options when implementing MOTAG based systems. Users can make informed decisions based on the nature of the protected application.The overall agility, and therefore the usability, of MOTAG is dependent on the time needed to shuffle clients among different proxy nodes. Rapid shuffles will make it harder for attackers to “follow” the moving target (proxy) nodes as well as reducing the time needed to quarantine insiders. Likewise, reducing the time for individual shuffles will save clients more rapidly and improve the overall QoS by reducing the severity of service disruptions. Therefore, to quantify the impact of our mechanism on the end users, the time needed for a client to switch from one proxy node to another was determined. To that end, 5 geographically dispersed nodes were chosen from PlanetLab to be the destination servers. Another node was randomly selected to play the role of the authentication server. Finally, 8 PlanetLab nodes were selected as proxy nodes. The time between when the redirection message was sent by the authentication server to the client and when the client connected to the destination server via the new proxy node was recorded as the time to migrate clients between proxy nodes. Concurrent with client migration, the authentication server sends a session ticket to both the client and the new proxy node, the client is authenticated by the proxy node when this ticket is validated. Only upon authentication will the new proxy node begin relaying packets for the client. Table 4presents the average, maximum, and minimum proxy switching times for each destination node. The numbers are fairly small yet consistent; the less than one second proxy switching time should not cause significant service disruption for most non-realtime applications.

@&#CONCLUSIONS@&#
