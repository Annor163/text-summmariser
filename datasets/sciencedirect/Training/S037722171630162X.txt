@&#MAIN-TITLE@&#
An auto-realignment method in quasi-Monte Carlo for pricing financial derivatives with jump structures

@&#HIGHLIGHTS@&#
The idea of machine learning is introduced to the QMC area.A new path generation method called the auto-realignment method is proposed.The k-means clustering algorithm is used to select representative normal vectors.Experiments demonstrate the efficiency and robustness of the proposed method.

@&#KEYPHRASES@&#
Pricing,QMC,OT method,QR decomposition,Auto-realignment method,

@&#ABSTRACT@&#
Discontinuities are common in the pricing of financial derivatives and have a tremendous impact on the accuracy of quasi-Monte Carlo (QMC) method. While if the discontinuities are parallel to the axes, good efficiency of the QMC method can still be expected. By realigning the discontinuities to be axes-parallel, [Wang & Tan, 2013] succeeded in recovering the high efficiency of the QMC method for a special class of functions. Motivated by this work, we propose an auto-realignment method to deal with more general discontinuous functions. The k-means clustering algorithm, a classical algorithm of machine learning, is used to select the most representative normal vectors of the discontinuity surface. By applying this new method, the discontinuities of the resulting function are realigned to be friendly for the QMC method. Numerical experiments demonstrate that the proposed method significantly improves the performance of the QMC method.

@&#INTRODUCTION@&#
Monte Carlo (MC) method and quasi-Monte Carlo (QMC) method have been successfully used to a wide range of finance problems, such as the pricing and hedging of complex financial derivatives (see Glasserman, 2004; Jin, Li, Tan, & Wu, 2013). By suitable transformations, these problems can often be represented as the integral of a real-valued function H over the d-dimensional unit cubeI(H)=∫[0,1]dH(u)du. The QMC method approximates the integral byQN(H)=1N∑i=1NH(ui),where the quadrature pointsu1,⋯,uNare deterministically chosen low discrepancy points from [0, 1]dinstead of random ones in MC sampling. The low discrepancy points are relatively uniform so that it is common for QMC to produce much more accurate answers than MC does. The justification is through the well-known Koksma–Hlawka inequality, which claims that the QMC integration error is ofO(N−1(logN)d)for functions with finite variation in the sense of Hardy and Krause (see Niederreiter, 1992).The advantage of the QMC method for high-dimensional finance problems was shown in many empirical studies (see Joy, Boyle, & Tan, 1996; Paskov & Traub, 1995). The concept of effective dimension offers a possible explanation for the success of QMC method for high-dimensional problems (see Wang & Fang, 2003). It is widely believed that functions of small effective dimension are easier to integrate by the QMC method. To this end, some path generation methods (PGMs) are proposed to reduce the effective dimension, such as the Brownian bridge (BB) (Caflisch, Morokoff, & Owen, 1997; Moskowitz & Caflisch, 1996), the principal component analysis (PCA) (Acworth, Broadie, & Glasserman, 1998) and the linear transformation (LT) method (Imai & Tan, 2006). However, they do not consider the discontinuities of underlying functions.In practice, a broad class of finance problems involves discontinuities. If the boundaries of discontinuity are not parallel to the axes, these discontinuities may be detrimental to the QMC method. The efficiency of the QMC method could be recovered if the discontinuities are realigned to be axes-parallel. Wang and Tan (2013) proposed the orthogonal transformation (OT) method for a particular class of discontinuous functions and suggested to realign discontinuities onto axes-parallel hyperplanes. Subsequently, He and Wang (2014) developed a PGM called the QR11The term “QR” is from the QR decomposition in linear algebra (see Golub & van Loan, 2013).method to deal with multiple discontinuity structures. The QR method makes the surfaces of discontinuities parallel to as many axes as possible. Both the OT and QR methods improve the efficiency of the QMC method significantly for many problems with discontinuous functions arising from finance. Wang (2016) proposed a procedure to handle high dimensionality and discontinuities concurrently. But for payoffs involving complex discontinuity structures, the OT and QR methods cannot be applied directly.In this paper, we propose a new PGM called the auto-realignment method to deal with payoffs with complex jump structures. Our approach obtains the information of the discontinuity surface from a set of low discrepancy points. We use the k-means clustering algorithm to automatically select several representative hyperplanes to approximate the discontinuity surface. These hyperplanes are characterized by their corresponding normal vectors. The basic idea of the auto-realignment method is intuitive: The more points distribute around the discontinuity surface with a certain normal vector, the more important is this normal vector. We could apply the QR method to realign these hyperplanes such that they are parallel to as many axes as possible. The new method can make the discontinuities of the payoffs more QMC-friendly. The auto-realignment method merits several advantages: It selects representative normal vectors and quantifies the importance of chosen vectors automatically without tedious recognition. Moreover, the performance of the auto-realignment method is more effective and robust than other PGMs, as confirmed by the numerical experiments.The rest of the paper is organized as follows. The OT method is reviewed in Section 2. The proposed auto-realignment method is formally presented in Section 3. Section 4 performs some numerical experiments for pricing exotic options. Section 5 concludes this paper.Suppose that S(t) is the price of the underlying asset at time t. We assume that under the risk-neutral measure the underlying asset follows a geometric Brownian motion (BM):(1)dS(t)=rS(t)dt+σS(t)dB(t),where r represents the risk-free interest rate, σ represents the volatility, and B(t) is the standard BM. The explicit solution of (1) isS(t)=S(0)exp{(r−σ2/2)t+σB(t)}.Let K and T denote the strike price and the maturity of the option, respectively. LetS:=(S(t1),S(t2),⋯,S(td))Trepresent the d-dimensional vector of asset prices, wheretj=jΔt,Δt=T/d,andS(tj)=S(0)exp{(r−σ2/2)tj+σB(tj)},j=1,⋯,d.Letx=(x1,⋯,xd)T:=(B(t1),⋯,B(td))T,thenx∼ N(0, C), whereCis the covariance matrix with entriesCij=Δtmin(i,j),i,j=1,⋯,d. Suppose that the discounted payoff function of a path-dependent option is given by H(x). The price of the option can be expressed asE[H(x)],whereE[·]is the expectation under the risk-neutral measure.LetAbe any decomposition ofCsuch thatAAT=Candzbe a d-dimensional vector of independent standard normal random variables, i.e.,z∼ N(0, Id), then we haveAz∼ N(0, C). The matrixAis called the generating matrix ofx∼ N(0, C). From the view of expectation, the price can be written as(2)V(H):=E[H(Az)]=E[H(AΦ−1(u))],whereuis uniformly distributed on [0, 1]dand Φ is the cumulative distribution function of standard normal. It can be approximated by(3)QN(H,P,A)=1N∑i=1NH(AΦ−1(ui)),whereP={ui,i=1,⋯,N}is a set of low discrepancy points in [0, 1]d. It should be stressed that the choice of the generating matrixAis not unique. The accuracy of the approximationQN(H,P,A)may depend heavily on the choice ofA. The generating matrix of the standard (STD) construction of the BM is given byASTD:=Δt[10⋯011⋯0⋮⋮⋱⋮11⋯1],which is actually the Cholesky decomposition of the covariance matrixC. Since the STD, BB and PCA constructions for the BM do not take the payoff functions into account, they may have bad performance for payoff functions with jump structures. In the next subsection, we review the OT method that deals with simple discontinuities.The discontinuities which are axes-parallel are considered as QMC-friendly since high efficiency can still be expected in QMC. Wang and Tan (2013) proposed the OT method that transforms the discontinuities to be QMC-friendly. The OT method targets the following special class of discontinuous functions(4)H(x)=1{h(qTx)>0}(x),whereq=(q1,⋯,qd)Tis a nonzero vector of constants and h( · ) is a strictly increasing function defined onR.LetA0 be an arbitrary initial generating matrix satisfyingA0A0T=CandpT:=(p1,⋯,pd)=qTA0. The payoff function (4) is equivalent to(5)H(z)=1{h(qTA0z)>0}(z)=1{h(pTz)>0}(z)=1{pTz>h−1(0)}(z),wherez=(z1,⋯,zd)T∼N(0,Id). By using the inverse transformationz=Φ−1(u),the inequality in (5) can be written asp1Φ−1(u1)+p2Φ−1(u2)+⋯+pdΦ−1(ud)>h−1(0).Obviously, the discontinuity boundary may not be parallel to any coordinate axis.The OT method offers a precise specification of an orthogonal matrixUby setting the first column ofUasU·1=1DA0Tq,whereD=qTCqand the remaining columns ofUare arbitrary as long as they satisfy the orthogonality conditions. The OT method takes the generating matrix asAOT=A0U. By the transformationx=AOTz,the expectationE[H(x)]can be represented asE[1{h(qTA0Uz)>0}(z)]=E[1{h(Dz1)>0}(z)].The indicator function (4) is transformed to(6)1{h(Dz1)>0}(z)=1{z1>1Dh−1(0)}(z).By the transformationz=Φ−1(u),the inequality in (6) can be further written asu1>Φ(D−1h−1(0)).Note that the discontinuity occurs atu1=Φ(D−1h−1(0)). Hence the discontinuity surface of the payoff function is realigned to be QMC-friendly.The OT method mainly focuses on indicator functions with respect to one linear structureqTx. But for payoffs involving complex discontinuities, it is difficult to figure out the right generating matrixAsuch that the discontinuities are realigned to be QMC-friendly.Since the nature of discontinuities of the underlying functions has a tremendous impact on the accuracy of the QMC method, the success of the OT method motivates us to develop a general PGM for payoff functions involving complex discontinuity structures.Suppose thatA0 is an initial generating matrix satisfyingA0A0T=C,thenAAT=Cif and only ifAcan be expressed asA=A0Ufor some orthogonal matrixU. Assume that the payoff function is written as(7)h(z)=H(A0z)=h0(z)1{f(z)>0}(z),z∼N(0,Id),where h0 and f are almost everywhere differentiable inRd. Note that f(z) > 0 is the condition of exercising and h0(z) is the payoff amount when the security is exercised. The discontinuity surface of h(z) is(8)Σ:={z|f(z)=0}.Letɛ1,⋯,ɛrbe r arbitrary fixed points on the discontinuity surface Σ and letH1,⋯,Hrbe the corresponding local discontinuity hyperplane in the neighborhood ofɛ1,⋯,ɛr,defined by(9)Hi:={z|∇f(ɛi)T(z−ɛi)=0},i=1,⋯,r,where ∇f(εi) is the gradient vector of f(z) evaluated atεi. The normal vector of the local discontinuity hyperplane Hiis(10)li:=∇f(ɛi)∥∇f(ɛi)∥,i=1,⋯,r.For an orthogonal matrixUsatisfyingUUT=I,letz˜=UTz. Thenz=Uz˜and the payoff function in (7) can be written ash(z)=h(Uz˜)=h0(Uz˜)1{f(Uz˜)>0}(z˜).Leth˜(z˜)=h(Uz˜)andf˜(z˜)=f(Uz˜). We haveE[h(z)]=E[h˜(z˜)]. The discontinuity surface ofh˜(z˜)isΣ˜={z˜|f˜(z˜)=0}. Note that there exists a one-to-one correspondence between Σ andΣ˜under the mapping ϕ:ϕ:z↦z˜=UTz.The pointsɛ1,⋯,ɛrcorrespond to the pointsɛ˜1,⋯,ɛ˜ron the new discontinuity surface. DenoteH˜1,⋯,H˜ras the new local discontinuity hyperplanes in the neighborhoods ofɛ˜1,⋯,ɛ˜r,defined by(11)H˜i:={z˜|∇f˜(ɛ˜i)T(z˜−ɛ˜i)=0},i=1,⋯,r.The normal vectors of the new local discontinuity hyperplaneH˜1,⋯,H˜rcan be denoted asl˜1,⋯,l˜r,wherel˜i:=∇f˜(ɛ˜i)∥∇f˜(ɛ˜i)∥,i=1,⋯,r.Theorem 1Let h(z) be the payoff function given in(7)and Σ be the discontinuity surface given in(8). Letɛ1,⋯,ɛrbe r arbitrary fixed points on the discontinuity surface Σ. The normal vectorsl1,⋯,lron these points of the discontinuity surface are given by(10). LetL=(l1,⋯,lr)∈Rd×rand assume thatRank(L)=r<d. LetQbe the resulting orthogonal matrix from the QR decompositionL=QR,whereR∈Rd×ris an upper triangular matrix. Then by settingU=Q,the new local discontinuity hyperplaneH˜igiven in(11)is aligned parallel to the latterd−iaxes.Note thatf˜(z˜)=f(Uz˜). By the chain rule of differentiation, we have∂f˜∂z˜i|z˜=ɛ˜1=∇f(ɛ1)TU·i,i=1,⋯,d,whereU· iis the ith column of orthogonal matrixU. Note thatUUT=IandR∈Rd×ris an upper triangular matrix. The normal vectorl˜1of the local discontinuity hyperplaneH˜1isl˜1=c1′UT∇f(ɛ1)=c1UTl1=c1UTUR·1=c1(R11,0,⋯,0)T,whereR· iis the ith column of the matrixRandc1′,c1are appropriate coefficients such that∥l˜1∥=1. This implies thatH˜1is parallel tod−1axes. Next we consider the normal vectorl˜2of the new local discontinuity hyperplaneH˜2. Similarly, we havel˜2=c2′UT∇f(ɛ2)=c2UTl2=c2UTUR·2=c2(R12,R22,0,⋯,0)T,wherec2′andc2are appropriate coefficients such that∥l˜2∥=1. This implies thatH˜2is parallel to the laterd−2axes. The following steps are similar to the previous deduction.□How to find the representative normal vectors on the discontinuity surface? Our strategy is to obtain a whole picture of normal vectors on the discontinuity surface from a number of sample points. Then we use k-means clustering algorithm to automatically select several most representative normal vectors on the discontinuity surface. The details are stated as Steps (1)–(3) below.Step (1)Sample n pointsɛ1,⋯,ɛnaround the discontinuity surface Σ and calculate their corresponding normal vectorsv1,⋯,vnof the discontinuity surface.Theoretically it is difficult to choose the required points exactly on Σ. Thus an area with positive probability {z: |f(z)| < η} is used as a substitute of the discontinuity surface, where η is a small number. Generateɛ1,⋯,ɛNfrom low discrepancy pointsu1,⋯,uN∈[0,1]dby the transformationɛ=Φ−1(u). These pointsɛ1,⋯,ɛN∈Rdare considered around the discontinuity surface when the condition |f(εi)| < η holds. In our experiment,N=214and η is the 1st percentile of N observations|f(ɛ1)|,⋯,|f(ɛN)|. For simplicity, we assume that the first n pointsɛ1,⋯,ɛnare selected according to the condition |f(εi)| < η. Thus we are able to obtain a group of normal vectorsv1,⋯,vnof the discontinuity surface on these selected points.Step (2)Apply the k-means clustering algorithm proposed byHartigan and Wong (1979)to partitionv1,⋯,vninto r clustersC1,⋯,Cr. Choosel1,⋯,lras the centroids of each cluster such that the within-cluster sum of distance to centroids is minimized. Choosing the number of clusters r is a practical issue; see Remark1for details.The clustering algorithm is run by a cyclic process. LetC:={v1,⋯,vn}and denotel1(i),⋯,lr(i)as the ith step centroids andC1(i),⋯,Cr(i)as the ith step clusters.Firstly, we select r vectorsl1(1),⋯,lr(1)randomly fromCas the 1st step centroids. ThenCcan be partitioned into r clustersC1(1),⋯,Cr(1)according to the following criterion,(12)Ci(1):={v∈C:ρ(v,li(1))≤ρ(v,lj(1)),∀1≤j≤r},whereρ(x,y)=1−cos〈x,y〉denotes the distance between vectorsxandy. The distance ρ(x, y) measures the divergence to which extent the vectorxis from the vectory. AfterCbeing partitioned into 1st step clustersC1(1),⋯,Cr(1),the centroid of the ith cluster is then updated by(13)li(2)=c∑v∈Ci(1)v,where c is the normalization factor such that∥li(2)∥=1. Steps (12) and (13) can be described as the assignment step and the update step, respectively. Given the centroidsl1(2),⋯,lr(2),the group of normal vectorsv1,⋯,vncan be reassigned based on the reassignment step to produce the new clustersC1(2),⋯,Cr(2). The algorithm proceeds by alternating between the assignment step and the update step until vectors in each cluster no longer change. In the end, we get the convergence clustersC1,⋯,Crwith centroidsl1,⋯,lr.Step (3)Arrange the chosen vectorsl1,⋯,lrin a decreasing orderl1*,⋯,lr*according to their importance. The weight matrix is chosen asL=(l1*,⋯,lr*)∈Rd×r.It is natural to quantify the importance of certain normal vectorliby the number of vectors clustered in the setCi. The more vectors amass inCi,the more frequently random points distribute around the discontinuity surface with the normal vectorli, which implies that this structure is more important. Namely, the normal vectorl1*is the centroid of the cluster which contains the most vectors, andlr*is the centroid of the cluster which contains the least vectors. That is why we choose the weight matrix asL=(l1*,⋯,lr*),whose columns are the representative normal vectors of the discontinuity.After obtaining the weight matrixL, as suggested by Theorem 1, we perform a QR decomposition ofLsuch thatL=QR,whereQis an orthogonal matrix andRis an upper triangular matrix. We find the orthogonal matrixUof the auto-realignment method by settingU=Q. The resulting generating matrix is given byAAUTO=A0U,whereA0 is the initial generating matrix given in (7).We start with this section by verifying that the orthogonal matrixUindeed makes the discontinuities of the payoff function (7) more QMC-friendly. Recall that the new discontinuity surface of the payoff function is given asΣ˜={z˜|f(Uz˜)=0}.It is enough to verify that the normal vector on the surfaceΣ˜is nearly parallel to many axes.Note that the discontinuity surface Σ is well approximated by hyperplanes with normal vectorsl1*,⋯,lr*in Step (2). For any pointz˜=(z˜1,⋯,z˜d)on the discontinuity surfaceΣ˜,f˜(z˜)=0is equivalent tof(z)=0. Without loss of generality, assume that the normal vector onzof the discontinuity surface belongs to the cluster with the centroidl1*. We could reasonably assume that the normal vector of the local discontinuity hyperplane onzcan be approximated byl1*. Thus the new local discontinuity hyperplane onz˜is nearly realigned parallel to the latterd−1axes according to Theorem 1. Note that the new local discontinuity hyperplane onz˜is given by(14)H˜={z|∥∇f˜(z˜)∥(z1−z˜1)=0}.By the transformationz=Φ−1(u),the local hyperplane (14) can be further transformed intoH˜={u|u1=Φ(z˜1)}. Thus the discontinuity surface Σ of the payoff function is transformed into a new discontinuity surfaceΣ˜,which is more QMC-friendly.Remark 1In order to apply the auto-realignment method, we need to specify the number of clusters r. Here we suggest practical criteria for choosing r. Let AQR(r),r∈N,denote the auto-realignment method which chooses r clusters. Since it is inefficient to choose nearly parallel normal vectors for the weight matrixL, we need to set a tolerance level ϵ to keep chosen normal vectors distinct from each other. Denote AQR* as the auto-realignment method choosing r* hyperplanes to approximate the discontinuity surface, i.e., AQR* ≔ AQR(r*), in whichr*=max{r∈N:ρ(li*,lj*)⩾ϵ,∀1⩽i<j≤r}.We chooseϵ=0.001in our experiments.In our experiments, we use the d-dimensional Sobol’ point set as the inputP={ui,i=1,⋯,N}for QMC. In practice, it is very hard to quantify the error of deterministic QMC quadratures. We thus use randomized QMC (RQMC) instead; see L’Ecuyer and Lemieux (2002) for a comprehensive overview of RQMC. Specifically, we obtain M independent randomized versions ofPby Owen’s scrambling method (see Owen, 1995), i.e.,Pj={ui(j),i=1,⋯,N}forj=1,⋯,M. Correspondingly, an estimate of the option price for the jth independent batch is given byQN(H,Pj,A). Note that the randomized QMC points preserve the good quality of low-discrepancy points. Moreover, each elementui(j)ofPjhas the uniform distribution in [0, 1]d, implying thatQN(H,Pj,A)is unbiased. The final estimate is the average of the M independent estimates, i.e.,Q¯N,M(H,A)=1M∑j=1MQN(H,Pj,A). The corresponding sample variance, which is an unbiased estimate of the variance ofQ¯N,M(H,A),is given by(15)σ^QMC2:=1M(M−1)∑j=1M(QN(H,Pj,A)−Q¯N,M(H,A))2.To demonstrate the efficiency of the auto-realignment method, variance reduction factors (VRFs) of using various PGMs in QMC with respect to the crude MC method are assessed and compared. The VRF measures the efficiency gain of QMC estimators as in many related literatures (see Dingeç & Hörmann, 2012). The VRF is defined byVRF:=σ^MC2σ^QMC2,whereσ^MC2denotes the sample variance of the crude MC andσ^QMC2denotes the sample variance (15) for QMC combined with certain PGM. Obviously, large VRF guarantees good performance of the PGM used in QMC. All the VRFs in our examples are based on 500 independent batches of simulation and each batch contains 214 samples, i.e.,M=500andN=214. All experiments are conducted using MATLAB running on a PC with 3.6 GHz Intel Core i7-4790 CPU and 16GB RAM.We compare six QMC-based schemes with the crude MC method (using the STD construction for generating the BM). The six QMC-based schemes are divided into two groups. The first group consists of Schemes 1–2 which use STD and PCA constructions to generate the BM. The second group consists of Schemes 3–6, which are problem-dependent PGMs.(1)Standard QMC — STD,Principal Components Analysis — PCA,Orthogonal Transformation — OT,The crude QR method — CQR,The auto-realignment method with one cluster — AQR(1),The auto-realignment method with r* clusters — AQR*.All the PGMs of the second group take theASTD as the initial generating matrix. The CQR method using normalized gradient vectors calculated on the following special points,ɛi=(1,⋯,1︸i−1,0,⋯,0︸d−i+1),i=1,⋯,d.Then normalized gradient vectorslican be calculated on these points. Let the weight matrixL=(l1,l2,⋯,ld)∈Rd×dand take a QR decomposition ofLsuch thatL=QR. We specify the orthogonal matrixUof the CQR method by settingU=Q. This PGM is proposed for the comparison with the AQR* method to emphasize the importance of finding representative normal vectors as columns of the weight matrix.We first consider digital options on a single asset. The discounted payoff of a digital Asian option is given by(16)H(x)=e−rT1{SA−K>0}(x),whereSA=1d∑j=1dS(tj). Under the STD construction, the payoff function can be expressed in terms ofzh(z):=H(ASTDz)=e−rT1{f(z)>0}(z),whereΣ={z|f(z)=0}is the original discontinuity surface. Under the risk-neutral valuation principle, the price of the digital Asian option is given byE[h(z)].In Table 1, we present the VRFs of various QMC-based PGMs with respect to the crude MC. In the simulation, the parameters are chosen asS(0)=100,σ=0.2,r=0.1,T=1,d ∈ {32, 64, 128} and K ∈ {90, 100, 110, 120}. We have the following observations.•The VRFs of QMC-based estimates are affected significantly by PGMs. The proposed AQR* method is the most superior in terms of VRFs, irrespective of the nominal dimension and the strike price. The VRFs of using the AQR* method in QMC can be at least double than those of using the other PGMs.The VRFs of the QMC-based STD method are much lower than those of using the other QMC-based PGMs. The VRFs of the PCA method seem to be invariant to the nominal dimension. The PCA method only provides moderate advantage over the STD method since it does not tackle the discontinuity structure of the integrand. This implies that the jump structures of the integrand have a great impact on the performance of QMC methods.The OT method works the best when the strike priceK=100,and its performance gets worse when the digital Asian option is deep out-the-money or deep in-the-money. The reason is that the weight matrix chosen by the OT method is independent of the strike price K. So when the strike price K is much larger or smaller than 100, the linear structure used by the OT method does not approximate the discontinuity structure well. The performance of the AQR(1) method and the OT method are nearly the same when the strike price K is around 100, while the AQR(1) method exhibits obvious advantage over the OT method when the strike priceK=120. This implies that the typical normal vectorl1*chosen by the auto-realignment method approximates the discontinuity surface better than the OT method when the digital Asian option is deep out-the-money or deep in-the-money.The efficiency gain of the AQR* method is significantly larger than the AQR(1) method, which implies that the discontinuities of the payoff function cannot be approximated by just one structure. Thus the AQR* method which chooses r* most representative normal vectorsl1*,⋯,lr**is much better than just applying single structure.The comparison of results of the CQR method and the AQR* method confirms that the procedure of finding several representative normal vectors of the discontinuity surface is indispensable. If we use the normalized gradient vectors calculated on d arbitrarily chosen points to approximate the discontinuity surface, the performance of the CQR method is not very well compared with the AQR* method and even worse than AQR(1) in some cases.Next we turn to the convergence graphs in Fig. 1for the digital Asian option. The parameters are given as d ∈ {64, 128} andK=100. In these graphs, the horizontal axis gives the number of low discrepancy points N (which ranges from 20 to 220) plotted on a log scale. The vertical axis gives the mean squared error (MSE) obtained from 500 independent simulations also plotted on a log scale. The RQMC method yields an unbiased estimator. Thus we use the sample variance as the estimate of the MSE. Fig. 1 shows that the AQR* method has the least MSE and exhibits the fastest convergence rate among other PGMs. Thus the superiority of the AQR* method over the other PGMs is confirmed.Consider the following digital Asian barrier option with a payoff as(17)H(x)=e−rT1{SA−K>0}(x)1{SA−B<0}(x),where B > K is the barrier. Under STD construction, the payoff function can be expressed in terms ofz. Letg(x)=min(SA−K,B−SA)and f(z) ≔ g(ASTDz). Note that f(z) is a continuous and almost everywhere differentiable function. The payoff function can be expressed ash(z):=e−rT1{f(z)>0}(z).In Table 2, we present the VRFs of various QMC-based PGMs with respect to the crude MC. We choose the parameters asS(0)=100,σ=0.2,r=0.1,T=1,K=100,B ∈ {120, 130, 140}, d ∈ {32, 64, 128}. We draw the following remarks based on the simulation results.•The AQR* method is the most superior in terms of VRFs, irrespective of the nominal dimension and the barrier.The OT method and the crude QR method are affected by the nominal dimension of the problem. These two methods perform better in low-dimensional cases than in high-dimensional cases. When the strike price K and the barrier B are closer, the efficiency of these two methods gets worse. The performance of the AQR(1) method and the OT method are nearly the same in this case.The efficiency gain of the AQR* method is significantly larger than the AQR(1) method. This confirms that the AQR* method which chooses r* representative normal vectors is much better than the AQR(1) method which chooses only one structure.The convergence graphs of MSE for the digital Asian barrier option is presented in Fig. 2. The parameters are given as d ∈ {64, 128} andB=130. The results are also very encouraging. The AQR* method has the least MSE and exhibits the fastest convergence rate among various PGMs. The comparison confirms the superiority of the AQR* method over other PGMs.In this subsection we consider the case of digital option based on multiple underlying assets. We assume that the risky assets follow the multi-dimensional geometric BM. Under the risk-neutral measure, their dynamics are given by the stochastic differential equationsdSi(t)=rSi(t)dt+σiSi(t)dBi(t),i=1,⋯,d,where Si(t) denotes the ith asset price at time t, r is the interest rate, σiis the volatility for the ith asset, andB(t)=(B1(t),⋯,Bd(t))Tis a d-dimensional BM, where each Bi(t) is a standard one-dimensional BM and the instantaneous correlation of Bi(t) and Bj(t) is Cij,Cov(Bj(t),Bj(t))=Cijt,where the matrixC=(Cij)d×dis positive definite.Suppose that the d-dimensional vectorS:=(S1(T),S2(T),⋯,Sd(T))Trepresents the price of underlying assets at time T and the jth asset price at time T is given bySj(T)=Sj(0)exp{(r−σj2/2)T+σjBj(T)},j=1,⋯,d.For simplicity we assume the initial valueSi(0)=S(0)and the volatilityσi=σfori=1,⋯,d. Letx=(x1,⋯,xd)T:=(B1(T),⋯,Bd(T))T,thenx∼ N(0, C). Consider a digital Asian option based on the weighted arithmetic average of the multi-asset prices. The discounted payoff function is given as following,(18)H(x)=e−rT1{SA(β)−K>0}(x),whereSA(β)=∑j=1dβjSj(T)andβ=(β1,⋯,βd)Tis a vector satisfying∑j=1dβj=1. By taking Cholesky decomposition of the covariance matrixC, we get the STD generating matrixASTD of the BM. Soxcan be represented asx=ASTDz,z∼N(0,Id). Let h(z) ≔ H(ASTDz) expressed in terms ofz, i.e.,h(z):=e−rT1{f(z)>0}(z),whereΣ={z|f(z)=0}is the discontinuity surface.In Table 3, we present the VRFs of various QMC-based PGMs with respect to the crude MC. We set the parameters asS(0)=100,σ=0.2,r=0.1,T=1,d ∈ {50, 100}, and K ∈ {90, 100, 110, 120}. In our experiments, we study two kinds of covariance matricesC, whereC1=(Cij)d×din whichCij=T(d−|i−j|)/dandC2=(Cij)d×din whichCij=Tλ|i−j|withλ=0.98. The weight vectorβis chosen from one of the following,β1=(1/d,⋯,1/d)Tandβ2=c(|cos(2π/d)|,⋯,|cos(2dπ/d)|)T,where c is a positive number such that∑j=1dβj=1. We have the following observations.•The AQR* method in QMC performs consistently better than STD, PCA, OT, CQR and AQR(1), regardless of the nominal dimension, the strike price, the choice of covariance matrixCand the vectorβ.The VRFs of the PCA method and the crude QR method seem to perform well when the weight vectorβ=β1. But for the weight vectorβ=β2,the efficiency of the PCA method and the CQR method decreases. This implies that the PCA method and the CQR method may not be a stable good PGM. The CQR which chooses d arbitrary structures may be inappropriate.The performance of the AQR(1) method and the OT method are nearly the same observed from Table 3. The comparison of the AQR* method and the OT method implies that it is insufficient to use only one normal vector to handle the discontinuities. The normal vectors on the discontinuity surface of the payoff function may be distributed more dispersedly than in the single asset case, which may be the reason of the inefficiency of the OT method and the AQR(1) method. Thus choosing enough representative normal vectors on the discontinuity surface is indispensable when we tackle the complex discontinuity structures.Fig. 3presents the convergence graphs of digital multi-asset option for d ∈ {50, 100}. We chooseK=100,C=C1andβ=β2. Obviously, the AQR* method has the least MSE and exhibits the fastest convergence rate among all PGMs. The comparison once more confirms the superiority of the AQR* method over the other PGMs.

@&#CONCLUSIONS@&#
Many financial derivatives involve jump structures in their payoff functions. These structures may deteriorate the efficiency of the QMC method significantly. Although the OT method can recover the superiority of the QMC method for problems involving simple discontinuity structures, but for those payoffs involving complex discontinuities, they cannot be applied directly.The contribution of this paper is twofold. Firstly, we use the machine learning technique to learn the information of the complex discontinuities more thoroughly in an automatic way. Learning the nature of the discontinuities completely is the key step to design a problem-dependent PGM. The second contribution of this paper is to propose a new PGM called the auto-realignment method to handle complex discontinuities. The proposed method finds several representative normal vectors of the discontinuity surface by using the k-means clustering algorithm. After finding the appropriate weight matrix, we use the QR method to realign the discontinuity surface such that it is parallel to as many coordinate axes as possible. Thus the discontinuity structure of the transformed function will be much more QMC-friendly. As illustrated in the experiments, the proposed PGM is effective and robust.The idea of machine learning plays an important role in designing the new PGM. We expect to find a better PGM via more efficient and accurate machine learning techniques. As future research, it is worth developing similar methods for pricing options and estimating Greeks under Lévy processes.