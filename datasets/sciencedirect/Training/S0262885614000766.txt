@&#MAIN-TITLE@&#
Robust visual tracking via augmented kernel SVM

@&#HIGHLIGHTS@&#
Augmented Kernel Matrix (AKM) is applied to combine complementary features.AKM clustering is utilized to group the tracking results into a few aspects.Representative patches are selected to learn the appearance model.Adding representative patches our tracker more robust to abrupt appearance changes.

@&#KEYPHRASES@&#
Feature representation,Appearance model,Augmented Kernel Matrix (AKM),

@&#ABSTRACT@&#
Most current tracking approaches utilize only one type of feature to represent the target and learn the appearance model of the target just by using the current frame or a few recent ones. The limited representation of one single type of feature might not represent the target well. What's more, the appearance model learning from the current frame or a few recent ones is intolerant of abrupt appearance changes in short time intervals. These two factors might cause the track's failure. To overcome these two limitations, in this paper, we apply the Augmented Kernel Matrix (AKM) classification to combine two complementary features, pixel intensity and LBP (Local Binary Pattern) features, to enrich the target's representation. Meanwhile, we employ the AKM clustering to group the tracking results into a few aspects. And then, the representative patches are selected and added into the training set to learn the appearance model. This makes the appearance model cover more aspects of the target appearance and more robust to abrupt appearance changes. Experiments compared with several state-of-the-art methods on challenging sequences demonstrate the effectiveness and robustness of the proposed algorithm.

@&#INTRODUCTION@&#
Object tracking is an important problem in computer vision and has many practical applications, especially for vehicle navigation, augmented reality (AR) and human computer interface (HCI). Although many tracking algorithms have been proposed [1–8], it is still a great challenging task to design a robust tracker which can cope with different kinds of objects under various situations. A very common difficulty is to deal with the visual appearance changes of the target over time due to pose changes, sudden illumination changes, partial occlusion and background clutter.To deal with the changes of the object appearance, a common strategy is to adopt an adaptive appearance model [2,3,5], which updates during the tracking process with the appearance changes of the target. To construct the adaptive model, it often uses the current or the latest few frames and represents the target by one type of the feature. Comaniciu [1] only used the current frame and represented the target as the weighted feature histogram to construct the appearance model. Ross et al. [3] employed the incremental learning scheme to learn a low-dimensional subspace representation, which was based on the pixel intensity. Babenko et al. [5] represented the target by using the generalized Haar-like features [9] and applied Multiple Instance Learning (MIL) [10] to select many discriminative weak classifiers from a feature pool. The weak classifiers were updated online by means of a forgetting factor and this implicitly meant that the appearance model was built only on the latest few frames. Kwon and Lee [4] utilized the first initial and latest four frames and sparse principal component analysis (SPCA) to select a set of complementary feature templates to model the target. Bai and Tang [7] proposed the online Laplacian ranking support vector tracker (LRSVT) to incorporate the initial and the latest frames and the weakly labeled information in the next frame to model the appearance. In the LRSVT system, the target was represented by using Haar-like features.Many of the aforementioned approaches could not deal with all various appearance changes simultaneously either due to the limited representation of one single type of feature or the only usage of the recent target samples [11]. To cope with the representation limitation, one strategy was that we could design a strong feature which was robust to any change. However, it was not an easy task [12,13], especially for the model-free tracking problem in which no prior knowledge about the target is known except for the object location at the beginning of tracking. Another strategy was that we could propose an efficient scheme that combined different complementary features (e.g. image features based on pixel intensity, edge and texture information) [12,13]. One type of feature captured one channel of information of the target and compensated for others' representation limitation.To make the tracker be intolerant of abrupt appearance changes in short time intervals, we could add the tracking result into the training set [11]. Nevertheless, if we brutally added all the tracking results, it would need much time to learn the appearance model and even degrade the tracker's performance. Instead, we could mine a few representative examples from the tracking results to add into the training set.In this paper, we applied the Augmented Kernel Matrix (AKM) classification [14–16] to combine two complementary features, the pixel intensity and LBP [17] features to model the target's appearance. The AKM classification assigns different weights to the information channel per example rather than per kernel. As a result, this could make the AKM learn a much more representative appearance model to cover the target appearance changes. Meanwhile, to make usage of the tracking result, we proposed the AKM clustering algorithm to group the tracking result into a few aspects and selected a few examples from each aspect. The AKM clustering has two advantages as follows. Firstly, it could decide the number of the cluster automatically, which was very important to the tracking problem. We could not give a predefined number of clusters due to the arbitrary appearance changes during the tracking process. Secondly, it could also handle outliers by employing a soft margin constant. Therefore, it might discard a few inaccurate tracking results which were unavoidable in the tracking process. And this contributed to our system to be more robust to abrupt appearance changes in short time intervals.The rest of this paper is organized as follows. In Section 2, we briefly overview the related work. The novel tracking algorithm, the Augmented Kernel Matrix tracker and the implementation details are given in Section 3. Experimental results and comparison with other state-of-the-art methods are presented in Section 4. Section 5 summarizes our work.

@&#CONCLUSIONS@&#
