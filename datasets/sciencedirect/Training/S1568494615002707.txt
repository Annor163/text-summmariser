@&#MAIN-TITLE@&#
Seeding the initial population of multi-objective evolutionary algorithms: A computational study

@&#HIGHLIGHTS@&#
We study the benefits of seeding for multi-objective optimization algorithms.We investigate two approaches for five state-of-the-art algorithms on 48 functions.Different optimization algorithms benefit very differently from seeding.AGE and SMS-EMOA typically achieve the best approximation of the true Pareto front.

@&#KEYPHRASES@&#
Multi-objective optimization,Approximation,Comparative study,Limited evaluations,

@&#ABSTRACT@&#
Most experimental studies initialize the population of evolutionary algorithms with random genotypes. In practice, however, optimizers are typically seeded with good candidate solutions either previously known or created according to some problem-specific method. This seeding has been studied extensively for single-objective problems. For multi-objective problems, however, very little literature is available on the approaches to seeding and their individual benefits and disadvantages. In this article, we are trying to narrow this gap via a comprehensive computational study on common real-valued test functions. We investigate the effect of two seeding techniques for five algorithms on 48 optimization problems with 2, 3, 4, 6, and 8 objectives. We observe that some functions (e.g., DTLZ4 and the LZ family) benefit significantly from seeding, while others (e.g., WFG) profit less. The advantage of seeding also depends on the examined algorithm.

@&#INTRODUCTION@&#
In many real-world applications trade-offs between conflicting objectives play a crucial role. As an example, consider engineering a bridge, where one objective might be costs to build and another durability of the bridge. For such problems, we need specialized optimizers that determine the Pareto front of mutually non-dominated solutions. There are several established multi-objective evolutionary algorithms (MOEA) and many comparisons on various test functions. However, most of them start with random initial solutions.If prior knowledge exists or can be generated at a low computational cost, good initial estimates may generate better solutions with faster convergence. These good initial estimates are often referred to as seeds, and the method of using good initial estimates is referred to as seeding. These botanical terms are used to express the possibility that good solutions for the environment can develop from these starting points. In practice, a good initial seeding can make problem solving approaches competitive that would otherwise be inferior.For single-objective evolutionary algorithms, methods such as seeding have been studied for about two decades; see, e.g., [17,20,23,26,30,41] for studies and examples (see [27] for a recent categorization). For example, the effects of seeding for the Traveling Salesman Problem (TSP) and the job-shop scheduling problem (JSSP) were investigated in [32]. The algorithms were seeded with known good solutions in the initial population, and it was found that the results were significantly improved on the TSP but not on the JSSP. To investigate the influence of seeding on the optimization, a varying percentage of seeding was used, ranging from 25 to 75%. Interestingly, it was also pointed out that a 100% seed is not necessarily very successful on either problems [28]. This is one of the very few reports that shows seeding can in some cases be beneficial to an optimization process, but not necessarily always is. In [21] a seeding technique for dynamic environments was investigated. There, the population was seeded when a change in the objective landscape arrived, aiming at a faster convergence to the new global optimum. Again, some of the investigated seeding approaches were more successful than others.One of the very few studies that can be found on seeding techniques for MOEAs is the one performed by Hernandez-Diaz et al. [22]. There, seeds were created using gradient-based information. These were then fed into the algorithm called Non-Dominated Sorting Genetic Algorithm II (NSGA-II, [10]) and the quality was assessed on the benchmark family ZDT ([44], named after the authors Zitzler, Deb, and Thiele). The results indicate that the proposed approach can produce a significant reduction in the computational cost of the approach.In general, seeding is not well documented for multi-objective problems, even for real-world problems. If seeding is done, then typically the approach is outlined and used with the comment that it worked in “preliminary experiments”—the reader is left in the dark on the design process behind the used seeding approach. This is quite striking as one expects that humans can construct a few solutions by hand, even if they do not represent the ranges of the objectives well. The least that one should be able to do is to reuse existing designs, and to modify these iteratively towards extremes. Nevertheless, even this manual seeding is rarely reported.In this paper, we are going to investigate the effects of two structurally different seeding techniques for five algorithms on 48 multi-objective optimization (MOO) problems.As seeding we use the weighted-sum method, where the trade-off preferences are specified by non-negative weights for each objective. Solutions to these weighted-sums of objectives can be found with an arbitrary classical single-objective evolutionary algorithm. In our experiments we use the algorithm Covariance Matrix Adaptation Evolution Strategy (CMA-ES, [18]). Details of the two studied weighting schemes are presented in Section 2.1.There are different ways to measure the quality of the solutions. A recently very popular measure is the hypervolume indicator, which measures the volume of the objective space dominated by the set of solutions relative to a reference point [43]. Its disadvantage is its high computational complexity [4,3] and the arbitrary choice of the reference point. We instead consider the mathematically well founded approximation constant. In fact, it is known that the worst-case approximation obtained by optimal hypervolume distributions is asymptotically equivalent to the best worst-case additive approximation constant achievable by all sets of the same size [6]. For a rigorous definition, see Section 2. This notion of multi-objective approximation was introduced by several authors [19,15,31,35,36] in the 80s and its theoretical properties have been extensively studied [9,12,33,34,37].We use the jMetal framework [13] and its implementation of NSGA-II [10], Strength Pareto Evolutionary Algorithm (SPEA2, [45]), S-Metric Selection Evolutionary Multi-Objective Algorithm (SMS-EMOA, [14]), and Indicator Based Evolutionary Algorithm (IBEA, [42]). Additionally to these more classical MOEAs, we also study Approximation Guided Evolution (AGE, [7]), which aims at directly minimizing the approximation constant and has shown to perform very well for larger dimensions [38–40]. For each of these algorithms we compare their regular behavior after a certain number of iterations with their performance when initialized with a certain seeding.We compare the aforementioned algorithms on four common families of benchmark functions. These are DTLZ ([11], named after the authors Deb, Thiele, Laumanns and Zitzler), LZ09 ([29], named after the authors Li and Zhang), WFG ([24], named after the authors’ research group Walking Fish Group) and ZDT [44]. While the last three families only contain two- and three-dimensional problems, DTLZ can be scaled to an arbitrary number of dimensions.We consider minimization problems with d objective functions, where d≥2 holds. Each objective functionfi:S↦ℝ, 1≤i≤d, maps from the considered search space S into the real values. In order to simplify the presentation we only work with the dominance relation on the objective space and mention that this relation transfers to the corresponding elements of S.For two points x=(x1, …, xd) and y=(y1, …, yd), withx,y∈ℝdwe define the following dominance relation:x⪯y:⇔xi≤yiforall1≤i≤d,x≺y:⇔x⪯yandx≠y.We assess the seeding schemes and algorithms by their achieved additive approximation of the (known) Pareto front. We use the following definition.Definition 1For finite setsS,T⊂ℝd, the additive approximation of T with respect to S is defined asα(S,T):=maxs∈Smint∈Tmax1≤i≤d(si−ti).We measure the approximation constant with respect to the known Pareto front of the test functions. The better an algorithm approximates a Pareto front, the smaller the additive approximation value is. Perfect approximation is achieved if the additive approximation constant becomes 0. However, the approximation constant achievable for a (finite) population with respect to a continuous Pareto front (consisting of an infinite number of points) is always strictly larger than 0. It depends on the fitness function what is the smallest possible approximation constant achievable with a population of bounded size.For the task of computing the seeds, we employ an evolutionary strategy (ES), because it “self-adapts” the extent to which it perturbs decision variables when generating new solutions based on previous ones. CMA-ES [18] self-adapts the covariance matrix of a multivariate normal distribution. This normal distribution is then used to sample from the multidimensional search space where each variate is a search variable. The co-variance matrix allows the algorithm to respect the correlations between the variables making it a powerful evolutionary search algorithm.To compute a seed, a (2,4)-CMA-ES minimizes∑i=1daifi(x), where the fi(x) are the objective values of the solution x. In preliminary testing, we noticed that larger population values for CMA-ES tended to result in seeds with better objective values. This came at the cost of significantly increased evaluation budgets, as the learning of the correlations takes longer. Our choice does not necessarily represent the optimal choice across all 48 benchmark functions, however, it is our take on striking a balance between (1) investing evaluations in the seeding and (2) investing evaluations in the regular multi-objective optimization. Note that large computational budgets for the seeding have the potential to put the unseeded approaches at a disadvantage, if the final performance assessment is not done carefully.The number of seeds, the coefficients used, and the budget of evaluations is determined by the seeding approaches, which we will describe in the following.CCornersAndCentre: A total of 10,000 evaluations is equally distributed over the generation of d+1 seeds. The rest of the population is generated randomly. For the i-th seed, 1≤i≤d, the coefficients aj(1≤j≤d) are set in the following way:ai=10ifi=j,1otherwise.Thus, we prevent the seeding mechanism from treating the optimization problem in a purely single-objective way by entirely neglecting any trade-off relationships between the objectives.11If the ranges of the objective values differ significantly, then the coefficients should be adjusted accordingly.Lastly, the (d+1)-th weight vector uses equal weights of 1 per objective. This way, we aim at getting a seed that is relatively central with respect to the others.LLinearCombinations: Here a total of 100 seeds is generated, where each seed is the result of running CMA-ES for 1000 evaluations. The coefficients of the linear combinations are integer values and we construct them in the following way. First, we consider all “permutations” of coefficients with ai=1 for one coefficient and aj≠i=0 for all others. Then, we consider all permutations where two coefficients have the value 1, then those where three coefficients have the value 1, and so on. When all such permutations that are based on {0, 1} are considered, we consider all permutations based on {0, 1, 2}, then based on {0, 1, 3}, then based on {0, 2, 3}, and so on.Consequently, we achieve a better distribution of points in the objective space. This comes, however, at the increased initial computational cost. Furthermore, the budget per seed is lower than in the CornersAndCentre approach, which typically results in less optimized seeds.NoSeed: All solutions of the initial population are generated randomly. This is the approach that is typically used for the generation of the initial population.In the classification of population initialization techniques for evolutionary algorithms by Kazimipour et al. [27], our approaches CornersAndCentre and LinearCombinations fall into the following categories:•Randomness: stochastic, as they rely on the stochastic hill-climber CMA-ES,Compositionality: composite multi-step, as the initial population is generated by several individual methods,Generality: generic, as the coefficients can easily be adjusted for other problems.In the following, we outline the five optimization algorithms for which we will later-on investigate the benefits of seeding the initial populations.Many approaches try to produce good approximations of the true Pareto front by incorporating different preferences. For example, the environmental selection in NSGA-II [10] first ranks the individuals using non-dominated sorting. Then, in order to distinguish individuals with the same rank, the crowding distance metric is used, which prefers individuals from less crowded sections of the objective space. The metric value for each solution is computed by adding the edge lengths of the cuboids in which the solutions reside, bounded by the nearest neighbors.SPEA2 [45] works similarly. The raw fitness of the individuals according to Pareto dominance relations between them is calculated, and then a density measure to break the ties is used. The individuals that reside close together in the objective space are less likely to enter the archive of best solutions.In contrast to these two algorithms, IBEA [42] is a general framework, which uses no explicit diversity preserving mechanism. The fitness of individuals is determined solely based on the value of a predefined indicator. Typically, implementations of IBEA come with the epsilon indicator or the hypervolume indicator, where the latter measures the volume of the dominated portion of the objective space.SMS-EMOA [14] is a frequently used IBEA, which uses the hypervolume indicator directly in the search process. It is a steady-state algorithm that uses non-dominated sorting as a ranking criterion, and the hypervolume as the selection criterion to discard the individual that contributes the least hypervolume to the worst-ranked front. While SMS-EMOA often outperforms its competition, its runtime unfortunately increases exponentially with the number of objectives. Nevertheless, with the use of fast approximation algorithms (e.g., [2,5,25]), this algorithm can be applied to solve problems with many objectives as well.Recently, approximation-guided evolution (AGE) [7] has been introduced, which allows to incorporate a formal notion (such as Definition 1) of approximation into a multi-objective algorithm. This approach is motivated by studies in theoretical computer science studying multiplicative and additive approximations for given multi-objective optimization problems [8,9,12,37]. As the algorithm cannot have complete knowledge about the true Pareto front, it uses the best knowledge obtained so far during the optimization process. It stores an archive A consisting of the non-dominated objectives vectors found so far. Its aim is to minimize the additive approximation α(A, P) of the population P with respect to the archive A. The experimental results presented in [7] show that given a fixed time budget it outperforms current state-of-the-art algorithms in terms of the desired additive approximation, as well as the covered hypervolume on standard benchmark functions.We use the jMetal framework [13], and our code for the seeding as well as all used seeds are available online.22http://cs.adelaide.edu.au/~markus/publications.html.As test problems we used the benchmark families DTLZ [11], ZDT [44], LZ09 [29], and WFG [24], We used the functions DTLZ 1-4, each with 30 function variables and with d∈{2, 4, 6, 8} objective values/dimensions.In order to investigate the benefits of seeding even in the long run, we limit the calculations of the algorithms to a maximum of 106 fitness evaluations and a maximum computation time of four hours per run. Note that the time restriction had to be used as the runtime of some algorithms increases exponentially with respect to the size of the objective space.AGE uses random parent selection; in all other algorithms parents are selected via a binary tournament. As variation operators, the polynomial mutation and the simulated binary crossover [1] were applied, which are both used widely in MOEAs [10,16,45]. The distribution parameters associated with the operators were ηm=20.0 and ηc=20.0. The crossover operator is biased towards the creation of offspring that are close to the parents, and was applied with pc=0.9. The mutation operator has a specialized explorative effect for MOO problems, and was applied with pm=1/(number of decision variables). Population size was set to μ=100 and λ=100. Each setup was repeated 100 times. Note that these parameter settings are the default settings in the jMetal framework, and they can often be found in the literature, which makes a cross-comparison easier. To the best of our knowledge, this parameter setting does not favor any particular algorithm or put one at a disadvantage, even though individual algorithms can have differing optimal settings for individual problems.In a real-world scenario, if an algorithm is run several times (e.g. because of restarts), the seeding might be only calculated once. In this case, it might make sense to compare the unseeded and seeded variant of an algorithm with the same number of fitness evaluations. However, we observed the expected outcome that in this case seeding is almost always beneficial. We therefore consider a more difficult scenario where the optimization is only run once and the number of fitness function evaluations used for the seeding is deduced from the number of fitness evaluations available for the MOEA.As pointed out earlier, we assess the seeding schemes and algorithms using the additive approximation of the Pareto front. However, as it is difficult to compute the exact achieved approximation constant of a known Pareto front, we approximate it. For the quality assessment on the LZ, WFG and ZDT functions, we compute the achieved additive approximations with respect to the Pareto fronts given in the jMetal package. For the DTLZ functions, we draw one million points of the front uniformly at random, and then compute the additive approximation achieved for this set.We also measure the hypervolume for all experiments. As the behaviors of the five algorithms differ significantly, there is no single reference point that allows for a meaningful comparison of all functions. However, we observe the same qualitative comparison with the hypervolume as we do with the additive approximation. Therefore, we omit all hypervolume values in this paper, because the additive approximation constant gives a much better way to compare the results for these benchmark functions, where the Pareto fronts are known in advance.In addition to calculating the average ratio of the achieved approximation constant with and without seeding, we also perform a non-parametric test on the significance of the observed behavior. For this, we compare the final approximation of the 100 runs without seeding and the 100 runs with seeding using the Wilcoxon–Mann–Whitney two-sample rank-sum test at the 95% confidence level.

@&#CONCLUSIONS@&#
Seeding can result in a significant reduction of the computational cost and the number of fitness function evaluations needed. We observe that there is an advantage on many common real-valued fitness functions even if computing an initial seeding reduces the number of fitness function evaluations available for the MOEA. For some functions we observe a dramatic improvement in quality and needed runtime (e.g., DTLZ4 and the LZ09 family).For practitioners, our results show that it can be worthwhile to apply some form of seeding (especially when evaluations are expensive), but also to investigate different MOEAs as well, as they have proven to benefit differently from seeding. While we observed that seeding can be very beneficial, our experiments could not reveal why this is the case for a particular combination of seeding, algorithm, and function landscape. To answer this, many parts have to be studied: the mappings that the benchmark functions create from the search spaces into the objective spaces, the connectedness between different local Pareto fronts, the adequacy of using CMA-ES in the seeding procedure, and much more. As a next step towards this goal, we propose to investigate seeding for combinatorial optimization problems.