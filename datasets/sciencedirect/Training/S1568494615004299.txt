@&#MAIN-TITLE@&#
Particle Swarm Optimization inspired by starling flock behavior

@&#HIGHLIGHTS@&#
New Particle Swarm Optimization algorithm based on the collective response of starlings flock behavior called “Starling PSO.”Starling PSO introduces a new method to adjust the position and velocity of particles which will generate new feasible solutions to increase the diversity in the solution space.Starling PSO improves the performance of the original PSO and yields the optimal solution in many numerical benchmarking experiments.Starling PSO gives the best results in almost all clustering experiments.

@&#KEYPHRASES@&#
Particle Swarm Optimization,Swarm intelligence,Optimization,Collective behavior,Data clustering,

@&#ABSTRACT@&#
Swarm intelligence is a meta-heuristic algorithm which is widely used nowadays for efficient solution of optimization problems. Particle Swarm Optimization (PSO) is one of the most popular types of swarm intelligence algorithm. This paper proposes a new Particle Swarm Optimization algorithm called Starling PSO based on the collective response of starlings. Although PSO performs well in many problems, algorithms in this category lack mechanisms which add diversity to exploration in the search process. Our proposed algorithm introduces a new mechanism into PSO to add diversity, a mechanism which is inspired by the collective response behavior of starlings. This mechanism consists of three major steps: initialization, which prepares alternative populations for the next steps; identifying seven nearest neighbors; and orientation change which adjusts velocity and position of particles based on those neighbors and selects the best alternative. Because of this collective response mechanism, the Starling PSO explores a wider area of the search space and thus avoids suboptimal solutions. We tested the algorithm with commonly used numerical benchmarking functions as well as applying it to a real world application involving data clustering. In these evaluations, we compared Starling PSO with a variety of state of the art algorithms. The results show that Starling PSO improves the performance of the original PSO and yields the optimal solution in many numerical benchmarking experiments. It also gives the best results in almost all clustering experiments.

@&#INTRODUCTION@&#
Swarm intelligence is a meta-heuristic algorithm which is widely used nowadays. The main characteristic of swarm intelligence is that high quality problem solutions emerge from the collaborative behavior of individuals within a swarm. In general, the meta-heuristic framework starts with an initial solution called the current solution and a set of neighborhood solutions, which are the candidate solutions. Each candidate solution in the neighborhood set is selected and evaluated. This evaluation involves calculating or estimating the performance of the candidate solution(s) and comparing them with the performance of the current solution and sometimes with each other. Based on this evaluation, if a candidate solution is better than the current solution, it will be accepted. If the current solution is better than the candidate solution, the candidate solution will be rejected. Each member of the swarm discovers and/or evaluates some candidates. The above process is repeated until the optimal solution is found [1].To effectively discover optimal solutions, a meta-heuristic requires two mechanisms, exploration and exploitation. Exploration mechanisms help the algorithm discover candidate solutions from the whole search space rather than just specific regions. Exploitation focuses on retrieving the best solution from a specific area of the search space. In other words, exploration mechanisms identify possible alternative areas into the search space. Exploitation mechanisms prune to find the optimal solution in the explored area. If the best solution identified by the exploitation is unacceptable, the exploration mechanism finds another area in the search space to examine. An algorithm which provides good performance in both exploration and exploitation is more likely to reach the optimal solution in every kind of problem.Popular swarm intelligence algorithms include Ant Colony Optimization (ACO) [2], Particle Swarm Optimization (PSO) [3] and Artificial Bee Colony algorithm (ABC) [4].Ant Colony Optimization finds the optimal solution by exploring the candidate paths that ants travel from their nest to food sources. Each path represents a candidate solution. At the beginning, the chance that an ant will select any candidate path is equal for all paths. The ant colony exploits to find the solution by adding pheromone traces to the better candidate paths. The more pheromone deposited on a path, the higher the probability that other ants will select that path. After some iterations of route selection, the paths of all ants converge to the optimal candidate. ACO was originally proposed to solve combinatorial problems such as the traveling salesman problem.Artificial Bee Colony (ABC) algorithm finds the optimal solution by sending employed bees to find food sources, which represent candidate solutions. The employed bees come back to report the nectar amount in the food sources they found to the onlooker bees in their hive. The higher the nectar mount, the higher the probability that the onlooker bees will prefer that food source. The onlooker bees investigate the selected food source as well as food sources in its neighborhood. Some poor food sources might be abandoned after some time. ABC also improves the exploration ability of the optimization algorithm by using scout bees. Scout bees introduce a mutation process to the algorithm by searching for new candidate food sources in previously unexplored areas of the search space.Particle Swarm Optimization adds steps to update the current best solution into the meta-heuristic to increase the exploration ability in order to solve numerical problems. Instead of using individual ants to find the solution, Particle Swarm Optimization uses particles in the swarm moving around the solution space to find the global best position (or solution). The position of a particle represents an alternative solution in a multidimensional solution space. Each particle is assigned a velocity, which changes over time and which is used to update the particle's position over iterations until the optimal solution is found. However, because the exploration capability of this algorithm is limited, it sometimes fails to find the global best solution.Particle Swarm Optimization provides good exploitation performance. However, PSO is inferior in exploration and thus tends to converge prematurely to a local optimum, without considering more promising areas of the search space. Many researchers have introduced methods to improve the exploration mechanisms of PSO. Their work can be categorized into two groups: work that modifies the value of parameters in the PSO updating equation and work that introduces additional techniques to the original PSO process.Van den Bergh and Engelbrecht [5] proposed an algorithm called Guaranteed Convergence PSO (GCPSO). In their algorithm, the global best solution is updated using a new equation to propose an alternative solution to the global best. The new algorithm tends to improve the performance of exploitation. However, the performance in exploration does not improve. Multi-Start PSO (MPSO) [6] is an enhancement of GCPSO. The process of MPSO is the same as GCPSO but the swarm is re-initialized if the solution converges to a local optimum. This modification improves the performance in exploration compared to GCPSO while maintaining the good performance in exploitation. However, performance of MPSO decreases when the dimensionality of the problem increases [7].Some research has focused on improving exploration performance in PSO by adding communication among particles instead of communication regarding only global best solution. He [8] proposed PSO with Passive Congregation (PSOPC). The algorithm tries to introduce communication among individuals to avoid local optima. Velocity updating in PSOPC is based not only on personal best and global best but also on a randomly chosen particle position. Mendes [9] proposed Full Informed PSO (FIPSO). Each particle in FIPSO communicates not just with the particle whose position represents the global best but with all of its neighboring particles. The aforementioned methods can prevent PSO from converging prematurely but the exploitation performance sometimes decreases.To improve the exploration performance while maintaining the exploitation performance of PSO, the concept of multi-swarm has been adoptedby many researchers. In species-based PSO (SPSO) [10] the population is separated into sub-swarms by similarity. The process of standard PSO is applied to each sub-swarm separately. Cooperative PSO (CPSO) [11] uses the multi-swarm concept in another manner. In CPSO, the solution vector is separated into sub-vectors. Each sub-swarm is responsible for finding the solution for each sub-vector. The solutions from each sub-swarm are then combined at the end.The previously mentioned algorithms divide the population into sub-swarms but each sub-swarm works separately. There is no interaction between sub-swarms. To add the information sharing into the multi-swarm concept, Jie [12] developed a Knowledge-based Cooperative PSO (KCPSO). The information of the whole swarm and each sub-swarm is used to adapt the process by following a set of rules. Jiang [13] proposed Master-Slave Swarms Shuffling Evolution based on PSO (MSSE–PSO). The particles in MSSE–PSO are ranked by fitness of their current solution and are divided into sub-swarms. The sub-swarm with the best fitness is called the master swarm and the others are called slave swarms. A particle in master swarm takes information from the best position in the slave swarms to update its position.Dividing the population into sub-swarms can add diversity to the population and thus improve the exploration performance. However, to maintain the exploitation performance in each sub-swarm, the algorithm needs a larger population size which increases the execution time of the algorithm.Many recent studies focus on developing a new particle update equation. Xi [14] proposed Weighted Quantum-behaved PSO (WQPSO). The local attractor, which is the combination of a particle's own personal best, and global best, plus the mean of personal bests are used to update the particle's position. Each personal best is weighted according to the rank of its fitness compared to the other personal bests. Chuang [15] proposed Chaotic Catfish PSO (C-Catfish PSO). To accelerate the convergence, a logistic map is used instead of random numbers in the updating equation. C-Catfish also avoids local optima by randomly creating new particles to replace the worst 10% of the particle population. C-Catfish PSO performs best among the PSO-type algorithm on some specific benchmark functions.Our research proposes a new variation of PSO. The objective is to increase PSO's capability in exploration without decreasing the capability in exploitation. We introduce Starling Particle Swarm Optimization (Starling PSO) which is a collective response process. The concept of applying collective behavior of starlings to PSO has been previously proposed in [16]. In their proposed method, the original velocity updating equation is replaced by new equation which mimics the collective behavior of starlings. In their experiments, the proposed algorithm performed better than the original PSO on unimodal benchmark functions. However, for multimodal benchmark functions, original PSO still performed better. As we have mentioned before, PSO is inferior in exploration in handling complex problems such as multimodal functions. In our work, we maintain the original velocity updating equation of PSO most of the time, except when stagnation occurs. In other words, when the global best stagnates in a local optimum, the position and velocity of particles are adjusted by using a mechanism similar to the collective behavior of starlings.Particle Swarm Optimization (PSO) [3][17] searches for a solution which is a multi-dimensional vector of real values. Each solution is modeled by the position of a particle in a multidimensional solution space. Each particle has its own velocity which it uses to update its position over iterations. Along the way, each particle remembers its personal best which is the best solution (i.e. location) which that particle has found so far. Among the local best solutions from all particles, the one with the highest fitness is remembered as the global best. The particles in the swarm move around the solution space by updating their positions and velocities. After each update, the particles in the swarm will find their local bests and a new global best. This process will be repeated until some stopping condition is satisfied.In each iteration, a particle's velocity is updated using equation (1).(1)v⇀kt+1=ωv⇀kt+c1r1(p⇀kt−x⇀kt)+c2r2(p⇀gt−x⇀kt)where ω is inertia weight factor, c1, and c2 are the constant factors, and r1 and r2 are random real numbers between 0 and 1. The value of inertia weight affects the overall characteristics of the swarm. Higher values of inertia weight make the swarm better in exploration but slow in convergence. Lower values make the swarm converge faster but also increase the chance of premature convergence. For particle k after t iterations,v⇀ktis its current velocity.x⇀ktis its current position.pktis its personal best.pgtis the global best after t iterations. After updating the velocity, the particle's position is updated using equation (2).(2)x⇀kt+1=x⇀kt+v⇀kt+1The updating iterations continue until the termination criterion is met. The global best from the last iteration is used as the solution. Pseudo code of PSO is shown in Algorithm 1.Algorithm 1: PSO Pseudo code1Generate initial population2for k=1 to population size3particle[k].best=particle[k].position4particle[k].bestfitness=particle[k].fitness5end for6gbest=particle.best with highest fitness7for t=1 to MAX_ITERATION8for k=1 to population size9v⇀kt+1=ωv⇀kt+c1r1(p⇀kt−x⇀kt)+c2r2(p⇀gt−x⇀kt)10x⇀kt+1=x⇀kt+v⇀kt+111if particle[k].fitness>particle[k].bestfitness12particle[k].best=particle[k].position13particle[k].bestfitness=particle[k].fitness14end if15end for16gbest=particle.best with highest fitness17end for18return gbestStarling birds gather in flocks as an astonishing cloud. The mass of birds moves synchronously and swiftly to evade predators that fly near the edge of the flock. The flock strives to defend itself by increasing the distance between its members and the predator. The approach of a predator causes the starling flock to alter its flight orientation (Fig. 1). The change in orientation starts from one starling and ripples quickly through the flock. The group behavior can spontaneously arise from many individuals at once.In the starling flock, each starling's direction of movement depends not only on self-information but also on information from other starlings nearby. A starling in the flock communicates with its neighbors and then adjusts its direction according to the direction of its neighbors. This produces the collective behavior in the flock [18,19]. Since each starling communicates with the other starlings nearby, the information from that starling can spread to every starling in the flock after some time, without direct interaction. This behavior is called collective response. The collective response of starlings increases the chance of avoiding the predator. In fact, starlings always communicate within the flock even when a predator is not present nearby. Their communication gives them more time to eat and provides more effective vigilance [20].Members of large flocks consistently coordinate their movements with their seven nearest neighbors. Communication starts from one starling to its seven neighbors, each of which affects seven more neighbors, and so on (Fig. 2). An analysis of robustness to uncertainty of consensus in empirical data from multiple starling flocks show that the flock interaction networks with six or seven neighbors optimize the trade-off between group cohesion and individual effort [21]. Therefore, communication with only the seven birds nearby is sufficient to influence the behavior of the whole flock. The behavioral correlation of starlings exhibits the scale free property, that is, the property that the behavior of a small flock is the same as a large flock. The pattern of collective behavior is the same regardless of the size of the flock [22].PSO mimics the bird flock behavior in finding food to create an optimization algorithm. The search mechanism of PSO is guided by the local best and global best value to move the particles toward the target position. This movement does not consider the obstructions that may appear in search space into account. Therefore, one of the drawbacks of the PSO algorithm is the lack of a mechanism which adds diversity to exploration in the search process. This makes PSO prone to stagnation at local optima rather than finding new, better solutions. Starling PSO addresses this weakness of PSO. Inspired by the behavior of starlings, the algorithm introduces a collective response to change the flock orientation when the environmental conditions are not favorable. The particles’ position and velocity are adjusted if the search process fails to improve the solution quality after a certain number of iterations.During the PSO process, the collective response of particle reorientation occurs when the global best fitness is stagnant for some number of iterations. To explore a broader range of solutions, we apply Eq. (3) to every particle. For the particle k,xˆkis its new position after collective response of particle reorientation. The new position is calculated from the positions of its seven nearest neighbor particles, selected based on Euclidean distance from particle k. The random number rxis a real number between −1 and 1. The set Nkcontains indexes of the seven nearest neighbors of particle k.(3)xˆk=x⇀k+rx17∑n∈Nkx⇀nThis equation will be applied to update the position of each particle, using the indices of that particle's neighbors. To increase the chance of getting a better position adjustment, we generate MAX_NUM sets of alternative orientation directions from the original positions. MAX_NUM, which is chosen by the experimenter, is used to control the number of generated alternatives. Within each set of alternatives, the new position of each particle calculated from (3) is set to be that particle's personal best. Among these personal bests, the alternative which yields the best global fitness will be selected as a new set of particle positions.In addition to changing particles’ positions, we also adjust particle velocities using Eq. (4). We simulate the collective behavior of starlings’ velocity adjustment in the same manner as position adjustment. For the particle k,vˆkis its new velocity after collective response. The velocities of seven nearby neighbor particles are used to adjust the velocity of a particle. The random number rv is a real number between 0 and 1. We identify the neighbor particles by Euclidean distance and collect their indexes in a set, Nk,(4)vˆk=v⇀k+rv17∑n∈Nkv⇀nEqs. (3) and (4) describe the characteristics of collective response in the orientation change of the starling flocks. The collective response of a bird's seven closest neighbors is shown in17∑n∈Nkx⇀nof Eq. (3) and17∑n∈Nkv⇀nof Eq. (4). After the change the new personal best and global best solutions are selected from these new positions and velocities. The algorithm of the collective response to the positions and velocities change can be described as shown in Algorithm 2.Algorithm 2: Collective response to orientation change1for k=1 to number of particles2find the closest seven neighbors of k using Euclidean distance and keep the index3of neighbor (n) in the set Nk4xˆk=x⇀k+rand−1,117∑n∈Nkx⇀n5vˆk=v⇀k+rand0,117∑n∈Nkv⇀n6pbest=current position of each particle7end for8gbest=best{pbest}9Therefore, the new Particle Swarm Optimization algorithm called Starling PSO can be described as shown in Algorithm 3.Algorithm 3: Starling Particle Swarm Optimization1##### Initialize population and parameters ####2Generate initial population3for k=1 to population size4particle[k].best=particle[k].position5particle[k].bestfitness=particle[k].fitness6end for7gbest=particle.best with highest fitness8best-so-far=gbest9stagnant_count=010for t=1 to MAX_ITERATION11##### Update particles’ positions and velocities as in standard PSO ####12for k=1 to population size13v⇀kt+1=ωv⇀kt+c1r1p⇀kt−x⇀kt+c2r2p⇀gt−x⇀kt14x⇀kt+1=x⇀kt+v⇀kt+115if particle[k].fitness>particle[k].bestfitness16particle[k].best=particle[k].position17particle[k].bestfitness=particle[k].fitness18end if19end for20gbest=particle.best with the highest fitness21if gbest's fitness>best-so-far's fitness22best-so-far=gbest23end if24##### Check if stagnation has occurred ####25if gbest's fitness<=previous gbest's fitness26stagnant_count=stagnant_count +127else28stagnant_count=029end if30previous gbest's fitness=gbest's fitness31##### Collective response to orientationchange to avoid stagnation ####32if stagnant_count> STAGNANT_LIMIT33# Creating MAX_NUM copies of current population34for m=1 to MAX_NUM35response[m]=copy(population)36# Adjust position and velocity of response[m] by Algorithm 237Collective response on response[m]38end for39population=response[m] with highest gbest's fitness40gbest=gbest[m]41stagnant_count=042end if43end for44return best-so-farThe process of Starling PSO as described in Algorithm 3 above begins with parameter initialization. All particles take their initial position as their personal best and the particle whose position has the best fitness among all particles is used as global best. In the initial stage, the stagnant count is set to 0 (line 9). After that, all the particle velocities and positions are updated by Eqs. (1) and (2) respectively. Their positions are evaluated by the objective function to calculate the new fitness value. If a particle's new fitness value is better than its current personal best fitness value, the new position is used as the new personal best. Then, after all particle velocities and positions are updated, the personal best with the best fitness value is used as new global best. The above process iterates to find a better global best.If the global best does not improve from the previous iteration, the stagnant counter is increased by 1 (line 25–29). If the value of stagnant counter reaches STAGNANT_LIMIT (line 32), the collective response to orientation change occurs. MAX_NUM copies of the last particle population are created as alternative candidate populations (lines 34–35). For each alternative candidate population, the position and velocity of orientation change is created using Eqs. (3) and (4) respectively (line 37). The new global best of each alternative population is selected from these new personal best values. Among these alternative populations, the one which contains the global best with the highest fitness is selected to be the population for the next iteration (line 39). After that, the process goes back to the velocity and position updating using equation (1) and (2) again.This process continues until the max number of iterations (MAX_ITERATION) is reached. The best-so-far global best kept during the process is returned as the system solution.Starling PSO uses the velocity and position updating of the original PSO. The search direction is also guided by personal best and global best. The collective response process added in Starling PSO adjusts the velocity and position of particles by using the velocity and position of nearby particles. From the mechanism mentioned above, we considered that Starling PSO can be employed as a search algorithm which its searching directions are influenced by the position and velocity of the neighbor particles.The overall process of Starling PSO is summarized in Fig. 3. The main process which consists of velocity updating and position updating is the same as original PSO. The additional process called collective response to orientation change occurs when the swarm is in a state of stagnation. When the swarm is stagnant, the current population is sent into the collective response process to create orientation change. In the initialization process of collective response, the current global best is compared to best-so-far global best and replaces it if the current global best is better. The current population is copied to generate MAX_NUM alternatives. Thus, the initialization process provides the MAX_NUM copies of current population to be alternatives in orientation changing. Next, the neighbors of each particle are identified according to Euclidean distance. The seven nearest particles are identified as the neighbors. This step provides a set of neighbors for every particle. Then, in the orientation changing process, the position and velocity of every particle in every copy are adjusted, based on the average of velocity and position of the respective neighbors identified in the previous step. After all adjustments have been done, MAX_NUM different alternative populations with new positions and velocities are available. The global best of each alternative is selected from the new position after adjustment. The alternative which provides the best global best is selected as the best alternative. Personal best of each particle is changed into the current position after orientation changing and global best is selected among these personal best. The best alternative population is then sent to the velocity updating process of PSO to be used as the new current population.Fig. 4shows the convergence graph of the Starling PSO which we tested with the Sphere function. When the algorithm gets stuck in a local optimum, the collective response algorithm activates the orientation changing to find other areas for exploration to escape the local optimum. The graph then converges to another minimum point. The process goes on repeatedly until no better solution is found. This figure also compares typical convergence graphs of Starling PSO and original PSO. It can be seen that after some stagnant iterations the Starling PSO algorithm changes the position and velocity so that the algorithm explores the new area of the search space and avoids the suboptimal solutions. Original PSO has more of a tendency to converge prematurely and return a poorer final solution.

@&#CONCLUSIONS@&#
