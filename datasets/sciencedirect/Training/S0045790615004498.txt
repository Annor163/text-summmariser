@&#MAIN-TITLE@&#
Characterization and modeling of multicast communication in cache-coherent manycore processors

@&#HIGHLIGHTS@&#
Multicast traffic is characterized and modeled with an emphasis on scalability.Intensity, concentration and burstiness increase with the system size.Growing correlation suggests the use of prediction to optimize NoC designs.Simple multicast source predictors achieve modest but promising accuracies.

@&#KEYPHRASES@&#
Manycore processors,Multicast,Broadcast,On-chip traffic analysis,Network-on-chip,Scalability,

@&#ABSTRACT@&#
The scalability of Network-on-Chip (NoC) designs has become a rising concern as we enter the manycore era. Multicast support represents a particular yet relevant case within this context, mainly due to the poor performance of NoCs in the presence of this type of traffic. Multicast techniques are typically evaluated using synthetic traffic or within a full system, which is either simplistic or costly, given the lack of realistic traffic models that distinguish between unicast and multicast flows. To bridge this gap, this paper presents a trace-based multicast traffic characterization, which explores the scaling trends of aspects such as the multicast intensity or the spatiotemporal injection distribution for different coherence schemes. This analysis is the basis upon which the concept of multicast source prediction is proposed, and upon which a multicast traffic model is built. Both aspects pave the way for the development and accurate evaluation of advanced NoCs in the context of manycore computing.

@&#INTRODUCTION@&#
In the ever-changing world of microprocessor design, multicore architectures are currently the dominant trend for both conventional and high-performance computing. Chip Multiprocessors (CMPs) resulting from the interconnection of several processing cores were conceived to overcome the complexity and power scalability hurdles of processors with a single CPU; however, the scalability concerns have now migrated to facets such as memory management, programmability or the limits of parallelism as the core count increases.Inherent parallelism limits aside, these scalability concerns are generally dependent on the architecture or programming model of choice. A long-running debate has brought up strong arguments for the adoption of two widely-known models in manycore CMPs: shared memory and message passing. Shared memory provides remarkable programmability and compatibility with legacy code. However, its scalability is arguably limited by performance and architectural complexity issues related to data consistency. On the contrary, message passing offers unique validation and hand-tuned performance benefits, which come at the cost of placing an increasingly heavy burden upon the programmer. The differences between these two extremes contrast with one common point: most of the scalability issues are tightly coupled to on-chip communication limitations. Due to this, the research focus in multiprocessors has gradually shifted from how cores compute to how cores communicate.The limited scalability of conventional Networks-on-Chip (NoCs) in the presence of global and multicast traffic represents an important constraint to multiprocessor architects and programmers. In shared-memory multiprocessors, cache coherence is the main source of on-chip communication and is generally maintained through directory-based protocols that limit the use of multicast to the invalidation of cache blocks on a shared write. This reduces the injection of multicast traffic, yet at the cost of non-scalable area and energy overheads required to track the sharers of the data. In message passing systems, where communication is explicitly set by the programmer, the use of collective communication routines such as MPI_Bcast or MPI_Allgather is often avoided. This, however, may lower the maximum achievable performance and increase the complexity of parallel programming over message passing even further. Also, the lack of proper multicast support hampers the development of novel programming models and manycore systems that may be multicast-intensive [1].Given that multicast and broadcast may become a critical factor guiding the design of future manycore CMPs, there is a need to understand how the characteristics of such traffic will scale with the number of cores. Providing accurate multicast traffic characterization in different scenarios would be useful for the early-stage design and evaluation of NoCs in general and multicast mechanisms in particular. However, to the best of the authors’ knowledge, no tools are available for the analysis and modeling of multicast traffic. Different works have characterized or modeled inter-processor communication in moderately-sized shared memory processors (see [2] and references therein), as well as in message passing clusters or supercomputers [3–5]. However, none of them has analyzed how collective communication scales for a wide set of representative applications and architectures at the CMP scale. Also, existing traffic models do not differentiate between unicast and multicast flows and only offer data for a given system size.In this paper, we aim to address these issues in one of the contending programming models (shared memory) by performing a scalability-oriented multicast traffic characterization. Our contribution and methodology is summarized in Fig. 1. We first analyze traces of widely known SPLASH-2 and PARSEC benchmark applications running over a set of existing cache coherence alternatives and for different processor sizes. Since scarce data is available beyond 64 cores, we additionally perform an exploratory extension of the study up to 512 cores whenever possible. Although most of these applications were not build to scale to thousands of processors [6,7], the analysis of its multicast traffic patterns may be still useful to extrapolate the behavior of future scalable shared-memory applications. We later employ the results of the characterization process to (1) propose and evaluate the potential of multicast source prediction, and (2) create a synthetic traffic generator that faithfully models multicast communication and that can be used to generate realistic mixed traffic profiles. With this, we aim to trigger further research in the area of multicast support for manycore systems.The paper is a direct extension of previous work by the authors [2]. The original contribution is augmented as follows:•The analysis now includes results regarding Token Coherence [9], as well as directory-based coherence with imprecise tracking up to 512-core CMPs.The concept of multicast source prediction is presented and evaluated, placing emphasis on its potential applicability at the NoC design level.The characterization results are used to implement a multicast traffic model and propose an appropriate synthetic traffic generator.The remainder of this paper is as follows. In Section 2, we provide background on cache coherence and on-chip networking which may further motivate this work and be useful to understand its results. Within the same section, we present related work in NoC traffic analysis and modeling. Section 3 details the characterization methodology used to obtain multicast communication traces and to analyze them. The results of the multicast traffic characterization are presented in Section 4, which are later used in Section 6 to create and validate a multicast traffic model. Section 7 concludes the paper.This section seeks to further motivate this work by explaining why it is necessary to analyze unicast and multicast traffic separately (Section 2.1); by providing background on the relation between cache coherence and the characteristics of the multicast traffic, in an attempt to both explain the importance of multicast in shared-memory manycore chips and justify the choice of protocols for analysis (Section 2.2); and by detailing in which aspects this paper differs from related work in multicast traffic analysis and modeling (Section 2.3).The nature of on-chip interconnects has changed with the number of processors. Buses are feasible for a few cores and, therefore, all communications are inherently multicast (broadcast, in fact). As more cores are integrated within a single chip, though, the interconnect design shifts to the NoC paradigm which is point-to-point in nature. Due to this, NoCs require that multicast packets be replicated and delivered to each of the intended destinations. When dense multicasts and broadcasts go through this process, the performance of the network may suffer a severe drop due to both the delay incurred by the packet replication and the contention associated to these additional messages. The performance loss is generally proportional to the multicast intensity and to the number of destinations per message for a fixed network size.The way packets are treated in conventional NoC has been subject of different studies. The most simple approach is to generate and inject one unicast message per destination. This process is performed at the source network interface (NIF) and, besides being highly power-inefficient, implies a potentially large serialization delay and increases contention around the transmitting node. To alleviate these effects, two in-network multicast support techniques have been explored. On the one hand, path-based multicast[10] relies on the transmission of a number of messages which travel around distinct regions of the chip and are replicated and delivered at the NIF of each of the destinations. On the other hand, tree-based multicast[11] requires the injection of a single message, which is replicated at the intermediate routers following a virtual tree until it reaches the intended destinations. In general, path-based methods are more contention-aware, whereas tree-based methods incur into lower latency.Another way to reduce the impact of multicast communications is to improve the connectivity of the network or by using globally shared media. This can be done with traditional RC wires and buses [13] or with emerging interconnect technologies such as 3D stacking [10], nanophotonics [14] or wireless RF [1].Regardless of the approach taken, multicast support proposals been tested either using synthetic traffic or within full-system simulations, generally assuming a fixed network size. Consequently, their impact upon the network performance is imprecise and their scalability remains largely unknown. In this paper, we aim to set the foundations of effective NoC testing for different network sizes and for a set of representative and realistic cases.The modest performance of conventional NoCs in the presence of dense multicast and broadcast communication has guided the design of shared memory multiprocessors through the years, encouraging the adoption of memory architectures and cache coherence protocols that avoid such type of traffic. As a result, traditional snoopy coherence schemes gave way to directory-based coherence. The former requires an ordered broadcast mechanism; whereas the latter relies in an entity (the directory), which serves as an ordering point and coordinates, through point-to-point messages, the memory transactions among the involved processors. As shown in Fig. 2, these represent the two extremes of cache coherence which trade off architectural cost against interconnect cost.In directory-based coherence, the use of multicast is generally limited to the invalidation of cache blocks on a shared write. To send invalidation messages only to the sharers of that block, the directory needs to provide precise sharer tracking. This implies having one bit per core per each cache block to store that information. Obviously, this scheme does not scale well as storage requirements skyrocket for hundreds of cores. To relax these constraints, one can limit the number of tracked sharers and send broadcasts to invalidate heavily shared blocks. An extreme case of imprecise tracking could be the protocol implemented by AMD HyperTransport [16], which is stateless and directly broadcasts all requests. However, broadcast delivery does not need to be ordered as in snoopy protocols, and responses are still unicast. Other alternatives such as Token Coherence [9] or Destination Set Prediction [15] propose advance techniques to further limit their architectural or communication costs.As mentioned above, the adoption of multicast-demanding methods is hampered by the performance of NoCs and their lack of ordering. Performance penalties are significant already at 64 cores and are expected to dramatically increase with the core count [11], progressively cornering the coherence solution space far from the ideal area. This further motivates the pursue of improved multicast and broadcast support in NoCs, indirectly highlighting the importance of this work as a vehicle for the evaluation of future interconnect fabrics in realistic conditions.The driving motivation behind traffic characterization is the need for a cost-effective (more than using real traces) but accurate (more than using synthetic traffic) way to evaluate networks. In NoCs, traffic characterization can be performed by analyzing communication traces obtained from full-system simulations. Multiprocessor benchmarks such as SPLASH-2 [6] and PARSEC [7] are commonly used to serve this purpose in shared memory architectures. Other benchmark suites such as NAS could be employed in message passing systems more oriented to supercomputing [3].Traffic characterization: Shared memory – On-chip traffic generated by shared-memory architectures has been analyzed in a wide variety of settings. Our previous work in [2] contains a comprehensive view of such characterization efforts, including the seminal papers that explore the SPLASH-2 and PARSEC benchmarks [6–8]. Their main downturn, though, is that those works do not distinguish between unicast and multicast in most cases. In fact, the few existing explicit multicast analyses are thus far limited to very specific use cases. Here, instead, we perform a complete characterization of multicast traffic for different representative cases using a unified approach and, for the first time, up to 512 cores to inspect their scalability.Traffic characterization: Message passing – In message passing, simpler steps can be taken to analyze traffic due to the explicit nature of communication. One can obtain a traffic characterization by looking into the types of communication routines used within a given program and projecting them into a given target system. The communication routines can be point-to-point (e.g. MPI_Send) or collective (e.g. MPI_Allgather), which may directly involve multicast and broadcast patterns. By breaking down these operations into messages and aggregating all contributions, metrics such as the multicast intensity or the number of destinations per message could be obtained. In the literature, several works have analyzed the communication primitives of different parallel algorithms. In [4], collective communication patterns and their impact on scalability are analyzed. The communication characteristics of NAS benchmarks and other scientific applications have been also extensively evaluated in [3,5] including information on collective routines.Traffic modeling – As mentioned above, traffic analysis also enables the faithful yet simple modeling of traffic for NoC evaluation. First proposals in this regard consider that three dimensions are enough to model the injection of traffic in NoCs of different benchmarks and architectures [17]: the degree of temporal burstiness resulting from the widely proven self-similarity of NoC traffic, the degree of concentration in the spatial injection distribution, and the hop distribution that models the probability of a packet going through a given number of hops as a function of the NoC topology or how a given application is mapped onto the processor.When modeling traffic using such methods, no distinction is made between unicast and multicast flows, and a unified model is used. This may be acceptable from a behavioral perspective only if the NoC treats each multicast as a set of independent unicast packets. In contrast, both types of traffic may have to be modeled separately and then interleaved in path-based or tree-based multicast schemes, since the network behavior changes with the type of packet. Such heterogeneous approach has been adopted in works like [10], which evaluates a path-based multicast routing method using mixed traffic profiles. Our work builds upon this premise, sustaining that the same model should not be used for both profiles as they may have fundamentally different sources and, therefore, different characteristics. Actually, we aim to improve the quality of existing models by focusing on the less-explored area of multicast characterization.An alternative traffic modeling methodology based upon full-system simulations is presented in [18]. Instead of relying blindly on the temporal and spatial information given by the traces, their approach uses additional information on the type of communication (e.g. purpose) to establish dependencies between messages and to determine its typology. Therefore, this method contemplates the possibility of distinguishing between multicast and the rest of traffic.

@&#CONCLUSIONS@&#
We have analyzed the scaling trends of multicast communication in cache-coherent processors by performing a trace-based characterization of a wide set of architectures, applications and system sizes. The results point towards a sustained increase of the multicast intensity, as well as of its spatial imbalance and temporal burstiness, confirming the need for proper multicast support in manycore scenarios. To assist the evaluation of future NoCs, we proposed a simple yet accurate multicast traffic model; whereas to optimize their design, we demonstrated a consistent growth in terms of spatiotemporal correlation of multicast traffic. This trend implies an increase of the chances of correctly predicting the source of multicast transfers, as shown here both using a predictability metric and evaluating the performance of two simple predictors.