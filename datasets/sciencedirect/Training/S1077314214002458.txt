@&#MAIN-TITLE@&#
Features for stochastic approximation based foreground detection

@&#HIGHLIGHTS@&#
Features for foreground detection algorithms are evaluated.The foreground is modeled with a full covariance Gaussian.The background is modeled with a uniform distribution.The model accommodates for any number of pixel features.Extensive comparisons are carried out with well known competing approaches.

@&#KEYPHRASES@&#
Background modeling,Foreground detection,Probabilistic mixture model,Background features,Pareto front,

@&#ABSTRACT@&#
Foreground detection algorithms have sometimes relied on rather ad hoc procedures, even when probabilistic mixture models are defined. Moreover, the fact that the input features have different variances and that they are not independent from each other is often neglected, which hampers performance. Here we aim to obtain a background model which is not tied to any particular choice of features, and that accounts for the variability and the dependences among features. It is based on the stochastic approximation framework. A possible set of features is presented, and their suitability for this problem is assessed. Finally, the proposed procedure is compared with several state-of-the-art alternatives, with satisfactory results.

@&#INTRODUCTION@&#
The proliferation of video vigilance systems has given rise to an ever increasing need of preprocessing, analyzing, indexing and searching over huge quantities of video data. These tasks cannot be efficiently carried out by humans, since the volume of data to be processed is too large for their capabilities. Hence, activity analysis intelligent systems are an emergent research field with multiple applications, both in the private and public sectors [36].Under a modular view of computer vision systems, the separation of moving objects from the background is one of the earliest stages. This is an essential part of any surveillance system, since its performance deeply influences the higher level stages which carry out the object detection. Consequently, much effort has been devoted to this complex problem, which includes challenges such as dynamic backgrounds, shadows, objects which integrate into the background, sudden illumination changes, color similarity (camouflage) and many others [4].Most approaches are based on building a model of the background which is based on some statistics obtained from the previous video frames. We might classify most of them into four classes: median based, kernel density estimation based, subspace based, and probabilistic mixture based [15]. The first class computes the median of the pixel values over the last frames in order to obtain a robust estimation of the background image. These approaches exhibit a good resilience against noise and artifacts [8], but they are also computationally expensive if the frame window is large, a problem which can be alleviated by fast methods to approximate the median [29,33]. The second kind of approaches estimates the probability density function (pdf) of the pixel values, but it does not assume any particular probability distribution for them, i.e. non parametric methods are used. Gaussian kernels are commonly chosen for this purpose [9,14]; the fundamental parameters to be tuned in this case are the number of kernels and their bandwidth. There is also a need to reduce the inherent computational load of kernel density estimation, which can be done by dropping irrelevant features. Subspace based methods try to find a subspace of the space of all possible images where the background of the scene lies, so that departures from that subspace can be detected as foreground objects [31,46,44,42]. Finally, the fourth group of methods assumes that the pixel values follow certain probability distribution, usually a mixture of Gaussians, and then it tries to estimate its parameters; this means that they are parametric methods. They tend to have less memory and time requirements than non parametric ones, since the number of parameters is relatively small. This is one of the causes of their popularity [45,40,51,17], along with the possibility to introduce specific mechanisms to tackle the above mentioned challenges [4].Even though there is a large number of background subtraction algorithms based on probabilistic mixtures, a majority of them stick to a set of simplifications which can reduce their performance. On one hand, most proposals use the RGB pixel values as inputs [34]. On the other hand, some well established and frequently used background modeling algorithms use the same variance for all the input variables [17,41,51], although there is no fundamental reason not to use the full covariance matrix. In other words, the use of full covariances is an option which exists in theory but is very rarely implemented in practice. A spherical covariance matrix might not be the optimal choice because the variance of the input variables can be different, which means that those models do not adapt to the specific dispersion of each variable. For example, the variabilities of median filtered features are expected to be much lower than those of non median filtered features. Also, features based on edge information (high pass filters) tend to vary more than features based on low pass filters. Moreover, the above mentioned models do not consider the covariances among the variables, so they treat them as if they were independent, which is not the case. For example, the red, green and blue color components of a pixel will typically grow or diminish together as the lighting increases or decreases, respectively. This means that RGB color components are strongly correlated. Another example is edge features in the horizontal and vertical directions, since textured objects will have high values of the features in both directions, while homogeneous objects will have low values of the features in both directions.Our aim here is to develop a method which overcomes the limitations we have just outlined, along with a set of relevant features that yields adequate results. Our proposal defines a probabilistic model which handles any number of pixel features. It also accounts for the correlations among the features, so that a more realistic model is obtained.The structure of this paper is as follows. First of all, a review of previous work about probabilistic background models and feature selection is done in Section 2. Then the proposed probabilistic mixture model and the corresponding learning algorithm are considered in Section 3. The set of pixel features that we have chosen are defined and studied in Section 4. Section 5 is devoted to the experimental results, with comparisons with state-of-the-art approaches. Finally, Sections 6 and 7 deal with the discussion of the most relevant characteristics of our proposal and the conclusions, respectively.

@&#CONCLUSIONS@&#
A new model for the detection of foreground objects has been proposed. It is able to manage any number and kind of pixel features. We have also proposed a set of relevant features according to several properties. It has been found that normalized and median filtered pixel values outperform the standard RGB color channels. On the other hand, some features which have been reported to work well with kernel density estimation approaches are not suited for our method. The performance of our approach has been compared with state-of-the-art alternatives over a set of benchmark videos, with favorable results. We foresee that these alternative methods could be enhanced by modifying them to accept any number and kind of pixel features.