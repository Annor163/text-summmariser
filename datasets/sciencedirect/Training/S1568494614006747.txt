@&#MAIN-TITLE@&#
An improved scatter search algorithm for the single machine total weighted tardiness scheduling problem with sequence-dependent setup times

@&#HIGHLIGHTS@&#
Different heuristics are adopted to generate the diversified population.A variable neighborhood search is embedded into the algorithm to improve the trial solutions and the combined solutions.The number of edges by which the two solutions differ from each other is counted to measure the diversification value.The length of reference set of scatter search could be adjusted adaptively to balance the computing time and solving ability.A discrete differential evolution operator is proposed as combination strategy.

@&#KEYPHRASES@&#
Improved scatter search,Variable neighborhood search,Variable-length reference set,Discrete differential evolution,Total weighted tardiness scheduling,

@&#ABSTRACT@&#
In this paper, a scatter search algorithm with improved component modules is proposed to solve the single machine total weighted tardiness problem with sequence-dependent setup times. For diversification generation module, both random strategy based heuristics and construction heuristic are adopted to generate the diversified population. For improvement module, variable neighborhood search based local searches are embedded into the algorithm to improve the trial solutions and the combined solutions. For reference set update module, the number of edges by which the two solutions differ from each other is counted to measure the diversification value between two solutions. We also propose a new strategy in which the length of the reference set could be adjusted adaptively to balance the computing time and solving ability. In addition, a discrete differential evolution operator is proposed with another two operators constitute the combination module to generate the new trial solutions with the solutions in the subsets. The proposed algorithm is tested on the 120 benchmark instances from the literature. Computational results indicate that the average relative percentage deviations of the improved algorithm from the ACO_AP, DPSO, DDE and GVNS are −5.16%, −3.33%, −1.81% and −0.08%, respectively. Comparing with the state-of-the-art and exact algorithms, the proposed algorithm can obtain 78 optimal solutions out of 120 instances within a reasonable computational time.

@&#INTRODUCTION@&#
One of the most thoroughly studied scheduling problems is the single machine total weighted tardiness problem with sequence-dependent setup times (STWTSDS) [1]. Formally, this problem is generally expressed as1/sij/∑wjTjand can be stated as follows. A set of n jobs are available at time zero and have to be scheduled without preemption on a single machine that can handle at most one job at a time. Each job j (j=1, 2,…,n) has a processing time pj, a due date dj, a weight wjand a setup time sijwhich takes place when job j immediately follows job i in the processing sequence. If job j is processed first, it is assumed that it requires a setup time s0j. The tardiness of job j is defined as Tj=max{0, Cj−dj}, where Cjis the completion time of job j. The objective of this problem is to find a sequence of jobs that minimizes the total weighted tardiness, i.e.,∑wjTj. Both the features of the weighted tardiness and the sequence-dependent setup times are encountered in a number of real-world applications. In many manufacturing industries, such as iron and steel industry, chemical industry, the mode of their production is make-to-order, so an important objective function is to minimize the total tardiness as it can be used to differentiate between customers. The setup time between two consecutive jobs on the same machine is a function of the size, physical or chemical characteristics of the jobs.Comparing the STWTSDS with the well-known TSP problem, it can be concluded that they are both permutation problem with the distances (setup times for STWTSDS) between two elements and their purposes are both to find a tour with specific objective functions. According the triplet-field notation in scheduling theory, TSP could be described as 1/sij/Cmax. Therefore, STWTSDS is also similar with TSP from the perspective of their models in addition to the different objective function. Based on this consideration, the successful methods of TSP may be also effective for STWTSDS.The STWTSDS problem has been proved to be strongly NP-hard [2]. Actually,1//∑wjTj, the generic version of this problem has already been proven to be strongly NP-hard by Lawler [3]. The feature of sequence-dependent setup times greatly increases the difficulty of solving the problem. So there is a need to develop heuristic algorithms for obtaining near-optimal solutions within a reasonable computation time. The best known construction heuristic for this problem is the Apparent Tardiness Cost with Setups (ATCS) rule proposed by Lee et al. [4]. The ATCS rule combines the weighted shortest processing time (WSPT) rule, the minimum slack (MS) rule and the shortest setup time (SST) rule in a single ranking index. The ATCS rule is implemented by assigning jobs in non-increasing order of parameter Ij(t, l) that is given by (1)(1)Ij(t,l)=wjpjexp−max(dj−pj−t,0)k1p¯exp−sljk2s¯where t denotes the current time and l is the index of the job just completed,p¯is the average processing time,s¯is the average setup time, k1 and k2 are the look-ahead parameters fixed as originally suggested in Lee et al. [4].In the literature, several meta-heuristics have also been proposed for the STWTSDS problem. Cicirello and Smith [5] generated 120 benchmark instances and applied five stochastic sampling approaches: Limited Discrepancy Search (LDS), Heuristic-Biased Stochastic Sampling (HBSS), Value Biased Stochastic Sampling (VBSS), Value Biased Stochastic Sampling seeded Hill-Climber (VBSS-HS) and Simulated Annealing. These instances were next improved by the following meta-heuristics algorithms. Lin and Ying [6] proposed a simulated annealing (SA) method with swap and insertion search, a generic algorithm (GA) with mutation operator performed by a greedy local search and a tabu search (TS) with a swap and an insertion tabu list. Liao and Juan [7] presented an ant colony optimization (ACO) algorithm for this problem. They introduced a new parameter for the initial pheromone trail and adjusted the timing of applying local search. Another ACO with a new global pheromone update mechanism and a new type of asymptotic pheromone trails is described by Anghinolfi and Paolucci [8] and compared with Liao and Juan [7]. Anghinolfi and Paolucci [9] proposed a new discrete particle swarm optimization (DPSO) approach and used a discrete model both for particle position and velocity and a coherent sequence metric that is different from previous DPSO. A discrete differential evolution (DDE) algorithm is presented by Tasgetiren et al. [10], speed-up methods are proposed to facilitate the greedy job insertions in their algorithm. Kirlik and Oguz [11] formulated this problem to a mathematical model and proposed a general variable neighborhood search (GVNS) heuristic to solve it. Chao and Liao [12] presented a discrete electromagnetism-like mechanism (DEM) algorithm for this problem with an attraction–repulsion mechanism involving crossover and mutation operators. A greedy randomized adaptive search procedure (GRASP) combined with path relinking (PR) is proposed by Luo and Hu [13] for this problem. Subramanian et al. [14] studied this problem and developed an iterated local search (ILS) and variable neighborhood descent with random neighborhood ordering meta-heuristic and compare its performance with the state-of-the-art meta-heuristic algorithms. Another ILS including a new neighborhood structure called BlockMove and a fast incremental evaluation technique is proposed by Xu et al. [15] to solve this problem. Deng and Gu [16] presented an enhanced iterated greedy (EIG) algorithm with elimination rules and a perturbation operator for this problem. Xu et al. [17] presented a systematic comparison of hybrid evolutionary algorithms (HEAs), which independently use six combinations of three crossover operators and two population updating strategies, for solving this problem and the unweighted 64 public benchmark instances. Additionally, Liao et al. [18] improve the time complexities of searching the interchange, insertion and twist neighborhoods for this problem which could be used to speed-up other algorithms.Tanaka and Araki [19] proposed an exact algorithm for the STWTSDS problem. The algorithm is based on the SSDP (Successive Sublimation Dynamic Programming) [20,21]. The proposed algorithm is applied to Cicirello's benchmark instances and all of them are optimally solved. However, it still takes a long computation time even with 20GB memory size (for the two hardest instance, 2 weeks and 1 month were taken, respectively). Therefore, for the practical problems or larger size problems than Cicirello's benchmark instances, the computation time of Tanaka and Araki's exact algorithm may increase exponentially. The motivation for our work is the implementation of a new meta-heuristic algorithm with the aim of generating solutions which are closer to the optimal ones for the STWTSDS problem within a reasonable time.Scatter search (SS) was first introduced in Glover [22] as a meta-heuristic for integer programming. SS is an evolutionary method which operates on a reference set of solutions by intelligently combining these solutions to yield better solutions. The purpose of these combination mechanisms is to incorporate both diversity and quality. Then the combined new solutions must undergo the improvement module which results in the reference set update. The algorithm continues until the stopping criteria are satisfied. Possible stopping criteria include the maximum number of iterations or the elapsed time. The algorithm may also terminate when the objective function reaches a predetermined value. SS is very flexible and has successful applications in several application areas, since each of its elements can be implemented in a variety of ways and degrees of sophistication. Laguna [23] summarized the basic SS framework as five component modules: diversification generation module, improvement module, reference set update module, subset generation module and combination module. The outline of our improved SS algorithm is shown in Fig. 1. The symbol gbest is used to describe the best solution found so far. A boolean variable NewElements is defined to distinguish whether the reference set is updated. For an overview of the features of SS, we refer to Glover and Laguna [24] and Martí et al. [25].SS has also provided very promising results for scheduling problems. Jain and Meeran [26] applied a SS and path relinking method to general flow-shop problem. The SS and path relinking strategies were embedded within a core and shell framework that is able to provide substantially better results than a tabu search approach. Nowicki and Smutnicki [27] proposed a modified SS algorithm for the flow-shop problem with makespan criterion. Good properties were scalable and had been confirmed by a large number of tests on common benchmarks. Manikas and Chang [28] used SS algorithm to solve the job shop scheduling problem with sequence-dependent setup times. The experiments showed that SS produces excellent results comparing with solutions obtained by common heuristics, a tabu search, a simulated annealing and a genetic algorithm. Sels et al. [29] proposed hybrid single and dual population based procedure to solve the well-known job shop scheduling problem. Various algorithmic parameters from literature were embedded in the procedures. Computational experiments verified the benefit of the diversity on the effectiveness of the meta-heuristic search process.In this paper, an improved SS algorithm is proposed for solving the STWTSDS problem and compared with the best known solutions. In the proposed SS, both random strategy based heuristics and construction heuristic are adopted to create a set of population solutions that balances diversification and quality. Campos et al. [30] conducted an experimental study to determine the effectiveness of 10 different diversification generation methods. Two variable neighborhood search based local searches are embedded into the proposed SS algorithm as the improvement method. As in Hvattum et al. [31], a SS algorithm with eight different improvement methods is considered to the unconstrained global optimization problem, they proposed a procedure to determine the values of the key search parameters and studied whether improvement methods of different quality have a direct effect on the performance of the SS procedure. The number of edges by which the two solutions differ from each other is counted when measuring the diversification value, and other diversity measure methods will be discussed in Section 2.3. A novel strategy that the length of the reference set could be adjusted adaptively to balance the computing time and the solving ability is proposed in this work. Three combination operators are used to generate new solutions. Most of the above strategies are suitable for the scheduling problems with appropriate modifications, such as the diversification generation, improvement and combination should be designed according the features of the problem.The remainder of the paper is organized as follows. Section 2 describes detailed steps of the proposed improvement strategies. Firstly, the main framework of the procedures is introduced based on the meta-heuristic procedures available in literature, and then we present some improvement strategies such as variable neighborhood search, variable-length reference set and the DDE based operators. Section 3 presents the computational experiments and compares them to both state-of-the-art and optimal results from literature. The efficiency of the algorithm is discussed in the following. Section 4 gives some conclusions.The historical application of SS shows its effectiveness. However, for a complex scheduling problem, improvement strategies combined with the characteristics of the problem are needed. For the five component modules of basic SS, the diversification generation, the improvement and the combination modules are problem dependent and are designed specifically for the problem being solved. It would be more effective to base the design on the specific characteristics of the problem setting. In this paper, both random strategy based heuristics and construction heuristic are used to generate the diversified population. Variable neighborhood search based local searches are adopted to improve the trial solutions and the combined solutions. For the combination module, a DDE based operator is proposed in addition to another two operators to generate the new trial solutions with the solutions in the subsets. The other two component modules, the reference set update and the subset generation modules, are mainly context independent. However, the diversity measure could be defined according to the problem while creating or updating the reference set. In this paper, the total number of different edges between two solutions is calculated to measure the diversification value between two solutions. We also propose a new strategy that the length of the reference set could be adjusted adaptively to balance the computing time and the solving ability.Although evolutionary algorithms could obtain excellent solutions for combinatorial optimization problems, they usually require a long computation time. One reason for this is the nature of the population-based search. Evaluating and improving solutions both for population and offspring are time consuming. To speed up the proposed algorithm, the following improvement strategies are implemented. Firstly, two similar local searches with different complexity are respectively used for preferable solutions and other solutions. Secondly, a beforehand evaluation is proposed for the neighborhoods of local search. For the subset generation module, two of the three types of subsets are adopted to generate new solutions. The improved SS is described in the following discussion.The diversification generation module is used to generate a collection of diverse trial solutions, using arbitrary trial solutions as an input. In order to construct a diversified population of solutions, a large set of solution elements need to be generated to ensure that a diverse region of the solution space will be covered. Therefore, two types of heuristic strategies are used to construct a subset P consisting of p initial solutions.It has been observed by many researchers that introducing high-quality solutions in the population could help a meta-heuristic to find good solutions more quickly. For example, in Holland's original generic algorithm, better individuals have more opportunities to produce offspring. And it had been pointed out that “High-quality solutions obtained from another heuristic technique can help a genetic algorithm to find better solutions more quickly than it can from a random start” [32]. Campos et al. [30] conducted an experimental study on SS algorithm and concluded that the population considering both diverse and quality is better than the outcome of a purely random process. For this problem, Anghinolfi and Paolucci [8,9] both use different constructive heuristics to generate the initial population. These high-quality solutions could be obtained from heuristic techniques that introduce problem-specific information in the diversification generation module. Therefore, the first class of heuristic is constructed by taking advantage of the ACTS construction heuristic which generates one trial solution.The other trial solutions are generated by two heuristics based on random strategy. For Cicirello’ benchmark instances, the weight of some jobs is zero. Since this problem is to minimize the total weighted tardiness, so the jobs whose weight is zero should be the last in the optimal sequence and their relative position is arbitrary. Based on the above characteristics, we define the number of jobs whose weight is larger than zero is no_num. Then the jobs are assigned into two sets (I and II): the jobs in set I whose weight is larger than zero while the jobs in set II whose weight is equal to zero. Therefore, the size of set I is equal to no_num and the size of set II is equal to (n-no_num). Then two heuristics are proposed as follows.Heuristic 1. This method randomly selects a job from set I for the first position, and then the job with the smallest setup times for the second position is chosen from the remaining jobs in set I. This process is repeated until set I is empty. Then the jobs in set II are put on the remaining positions in accordance with any order. The difference between this method and the shortest setup time (SST) rule is that the SST rule generates only one solution while this method could generate multiple solutions because the first position is not fixed.Heuristic 2. This method randomly selects jobs from set I for the first no_num positions while the remaining elements are selected from set II arbitrarily. It is also usually considered that multiple population generating methods could promote the diversity. Therefore, ATCS heuristic and these two heuristics are used to guarantee the diversity of the initial solutions.In SS, an improvement module is introduced to transform a trial solution into one or more enhanced trial solutions. Thus, a local search procedure is usually applied over each solution of the population and the combined new solution in SS procedure. As described in Section 1, there are similarities between STWTSDS and TSP. Therefore, the 3-opt move [33] is introduced to the local search module. Liu [34] developed a hybrid SS for the probabilistic traveling salesman problem, the insert, 2-opt and 3-opt moves are tested by numerical experiments. In our work, a local search which is based on a variant of the variable neighborhood search [35] has been adopted. The classical insert, edge-insert and swap neighborhood which are widely used in [11–16] for STWTSDS are also adopted in our local search module. As described in Kirlik and Oguz [11], the order of the neighborhood structures used in the search process and the search strategy employed in changing neighborhood will affect the efficiency of the VNS algorithm. While establishing the best order of the neighborhood structures we performed preliminary computational experiments and also refer to Kirlik and Oguz's experience. In order to improve the efficiency of the calculation, two local search algorithms named LS1 and LS2 are adopted for the STWTSDS problem. The structure of LS1 and LS2 is reported in Figs. 2 and 3. Obviously, there is a problem that we have to decide which local search to use for a trial solution. This problem will be studied via computational experiments in Section 3.1. In addition, only the combined new solutions are improved by the local searches in our algorithm to save the computation time and keep the diversity of the population.As can be seen from Fig. 2, the local search LS1 performs a random neighborhood exploration allowing an alternation of random edge-insert move, 3-opt move and random insert move. The algorithm executes an exploration first using a series of random edge-insert move until no improvement is found, and then trying a series of 3-opt move until no improvement is found, and then followed the random insert move: when the random insert move is not able to find a better solution, then a new series of random edge-insert move is started and the exploration counter is incremented until the n*(n−1) explorations have been completed. While as expressed in Fig. 3, the local search LS2 performs a random exploration allowing an alternation of random swap move, random edge-insert move and random insert move in accordance with the principles of the above. Step 6 for each local search, which is called shaking, randomly chooses an insert or swap neighborhood of the incumbent solution x1. The shaking strategy is described in Fig. 4.Considering a solution described by a permutation (1,…,i−1, i, i+1,…,j−1, j, j+1,…,n) with n elements, the insert, edge-insert and swap neighborhood could be illustrated as below.•Insert. Remove a job i from its original position and insert it before element j. Thus, (1,…,i−1, i+1,…,j−1, i, j, j+1,…,n) is a neighbor.Edge-insert. Remove two jobs i and i+1 from their original positions and insert them before element j. Thus, (1,…,i−1, i+2,…,j−1, i, i+1, j,…,n) is a neighbor.Swap. Swap two jobs i and j that are not be adjacent. Thus, (1,…,i−1, j, i+1,…,j−1, i, j+1,…,n) is a neighbor.The 3-opt move replaces two or three edges in the current tour by two or three others. Suppose the original tour is (1,…,h, h+1,…,i, i+1,…,j, j+1,…,n), two or three of the distinct edges (h, h+1), (i, i+1), and (j, j+1) of the current tour are to be replaced. If all three edges are to be replaced and they are non-adjacent, then (1,…,h, j,…,i+1, h+1,…,i, j+1,…,n), (1,…,h, i+1,…,j, h+1,…,i, j+1,…,n), (1,…,h, i,…,h+1, j,…,i+1, j+1,…,n) and (1,…,h, i+1,…,j, i,…,h+1, j+1,…,n) are four neighbors. Selecting the shortest tour from the four reconnect tours and comparing with the original tour, if it is shorter than the original tour, then the original tour is replaced by it.For the insert, edge-insert and swap moves, the elements i and j are chosen randomly, so the result of above neighborhood may be very poor. To improve this deficiency, we introduce a parameter avg_setup which is calculated by the average setup time (for this instance) multiplied by a coefficient rand_setup. The rand_setup is a random number derived between 0.2 and 0.3. The avg_setup is used to determine whether the current move is promising by the following steps. Firstly, the setup times of the potential move are calculated. Then if one of these setup times is larger than the avg_setup, the elements i and j are re-selected. This step would be repeated at most ten times, after that, the move must be executed even if the neighborhood of the new i and j is still not satisfied.As in all evolutionary method, a set of solutions (population of individuals) containing high evaluation are used to generate new solutions to replace less promising solutions at each iteration of the implementation process. The SS method builds a reference set (Refset for short) of solutions to maintain a good balance between intensification and diversification of the solution process. A straightforward way to create a Refset consists of selecting the two subsets, Refset1 and Refset2 of size b1 and b2, respectively. That is |Refset|=b=b1+b2. The set of high quality solutions Refset1 is built to include b1 best solutions (in terms of the objective function value) in the population. Then we generate the Refset2 of b2 diverse solutions by selecting the solution that differs by the greatest amount from the current reference set.In [36], Laguna concluded the measure for choosing the diverse solutions. For instance, the Euclidean distance is typically used for problems whose solution representation is given by continuous variables, and the Hamming distance is commonly used for binary vectors and permutation vectors. In this paper, as a diversity measure we define div(s1, s2) to be the diversification value between two solutions s1 and s2 and calculate the value of div(s1, s2) as the number of edges by which the two solutions differ from each other. So the div(s1, s2) for two solutions lies between 0 and n, the larger the value, the more diverse the two solutions. For example, there are three solutions s1=(1, 2, 3, 4, 5, 6), s2=(1, 4, 3, 2, 5, 6), and s3=(4, 1, 3, 2, 5, 6), then div(s1, s2)=4 because the edges (1, 2), (2, 3), (3, 4), (4, 5) in s1 are different from edges (1, 4), (2, 5), (3, 2), (4, 3) in s2. Similarly, div(s1, s3)=4 and div(s2, s3)=2. Based on the above diversity measure formula, the candidate solutions are included in Refset according to the Maxmin criterion that maximizes the minimum distance of each candidate solution to all the solutions currently in the reference set.In classic SS, the two subsets Refset1 and Refset2 have the same length and the length remains the same during the solution process. This approach is conductive to the implementation and management of the program. However, the choice of the length is mainly based on experience and lack of theoretical basis. The longer the reference set, the greater the search space, but the computing time is also long. In some experiments, it is found that the obtained solutions by a small reference set and a large reference set are very close at the beginning of the algorithm, but with the implementation of the algorithm, a large reference set has a high probability to find better solutions. Based on the above considerations, we propose a new strategy that the length of the reference set could be adjusted adaptively according to the needs of the solution process. Specifically, a smaller reference set is chosen in the beginning of the algorithm, but while the best solution cannot be updated continuously, the length of the reference set is increased to find better solutions. For example, suppose we set the length of reference set |Refset|=b1+b2 at the beginning and define nIter to be the iterations that the current best solution has not been improved, then the adjustment process of the length of the reference set is reported in Fig. 5.The subset generation module consists of generating the subsets that will be used for creating new solutions with the solution combination module. The most common subset generation consists of creating a list of all pairs (i.e., all 2-element subsets) of reference solutions for which at least one of the solutions is new. A reference solution is new means that it has not been used by the combination module. In order to choose the two reference solutions, three types of subsets are organized to consist of:(1)subsets containing only solutions in Refset1,subsets containing only solutions in Refset2,subsets that mix solutions in Refset1 and Refset2.The subsets of type 1 are conceived to intensify the search in regions of high-quality solutions while subsets of type 2 are created to diversify the search. Finally, subsets of type 3 integrate both high-quality and diverse solutions to exploit solutions across these two types of regions. The preliminary experiments shows that the subset of type 2 has a small probability of getting new better solutions, this may because our diversification generation module consists of both construction and random heuristics. Therefore, only the subsets of type 1 and type 3 are adopt for this problem.This module generates one or more new trial solutions for the subsets generated in the previous step. The module is typically problem-specific since it is directly related to the solution representation. Campos et al. [37] proposed a set of ten combination operators for the permutation problem. In their implementation, the operator is probabilistically selected according to its performance in previous iterations. In this paper, we adopt directly the third operator from the Campos’ ten and a similar crossover operator. These two operators make use of linear combinations of parents to generate offspring solutions which would make the probability of repeating solutions increase as the search progresses. To increase the diversity of combined solutions, a new combination operator which is based the differential evolution (DE) methodology is proposed. These operators generate one new trial solution from the combination of two reference solutions.Combination Operator 1. This is the third operator in Campos’ which is an implementation of what is known in the GA literature as the partially matched crossover. The operator randomly selects two crossover points and copies the partial permutation between them from one reference solution into the new trial solution. The remaining elements are copied from the other reference solution preserving their relative ordering.Combination Operator 2. This operator randomly selects a position k to be the crossing point from the range [1, n]. The first k elements are copied from one reference solution. For each remaining element i (i=k+1,…,n) the operator copies from the other reference solution preserving their relative ordering.Combination Operator 3. DE is a population-based stochastic search technique introduced by Storn and Price [38] for continuous optimization problems. Different variants of DE have been developed successfully for benchmark and practical optimization problems [39,40]. It performs searching using floating point representations opposing the binary wording, commonly used by other evolutionary algorithm schemes. So the classic DE cannot be used to generate discrete values since its individuals are floating point numbers. Tasgetiren et al. [41,42] and Pan et al. [43] proposed a simple and novel DDE algorithm whose solutions are based on discrete job permutations, however, the mutated individual was generated from only one individual in their DDE. Hou et al. [44] proposed a DDE algorithm for stochastic VRPSPD, their mutation operator is based on binary values and seems not to be used directly for scheduling or permutation problems. In this section, we will present a DDE based combination operator for our improved SS algorithm.In this DDE operator, the individual is represented by a permutation of jobs x={x1, x2,…,xn}. According to the classic DE, a mutant individual is generated by adding the weighted difference between two target individuals randomly selected from previous population to another individual, so the mutation operator can be presented as Eq. (2):(2)Vi+1=xi⊕F⊗(xr1−xr2)where xi, xr1 and xr2 are three different individual and F is a mutant scale factor. This formula consists of three operators. The first operator is Δ1=xr1−xr2 which represents the difference (“subtraction”) between two individuals xr1 and xr2 where Δ1 is the new individual. The difference of xr1 and xr2 is calculated as shown in Fig. 6. For example, assuming that there are two individuals xr1={2, 1, 5, 4, 3} and xr2={3, 4, 1, 5, 2}, then the difference of these two individuals is calculated as follows. Firstly, for job 1, we scan xr2 and find that the position number of job 1 is 3, next we find the job in the third position of xr1 is job 5, and then job 5 is added to the first position in Δ1. Secondly, for job 2, we scan xr2 and find that the position number of job 2 is 5, next we find the job in the fifth position of xr1 is job 3, and then the job 3 is added to the second position in Δ1. Similarly, we can get the other three positions of Δ1 and the final result is Δ1={5, 3, 2, 1, 4}. This procedure could be illustrated in Fig. 7.The second operator is Δ2=F⊗Δ1 where the mutant scale factor F could be generated randomly in [0, 0.25] range, then (100×F) % of the elements in Δ1 will be changed. The third operator is Vi+1=xi⊕Δ2 which represents the “summation” between two individuals named xiand Δ2. The “summation” of xiand Δ2 is calculated as shown in Figs. 8 and 9. For example, assuming that there are two individuals xi={2, 1, 5, 4, 3} and Δ2={3, 4, 1, 5, 2}, then the “summation” of these two individuals is calculated as follows. Firstly, we find the job number in the first position in Δ2 is 3, next we find the job number in the third position in xiis 5, and then job 5 is added to the first position in Vi+1. Secondly, we find the job number in the second position in Δ2 is 4, next we could find the job number in the fourth position in xiis 4, and then job 4 is added to the second position in Vi+1. Similarly, we could get the other three positions of Vi+1 and the final result is Vi+1={5, 4, 2, 3, 1}. Therefore, a new individual is generated using this DDE method from three different individuals.The above three combination operators are probabilistically selected according to their performance in previous iterations that is the same way with Campos et al. [37]. In our implementation, solutions in the Refset are ordered according to their objective function value. When a solution obtained with combination operator i qualifies to be the jth member of the current Refset, we add b−j+1 to score(i). Therefore, combination modules that generate good solutions accumulate higher scores and increase proportionally their probability of being selected. To avoid initial biases, selections are made completely at random before the first InitIter combination, and after this, the combination modules are selected according their scores.In most SS implementations, the diversification generation module is applied first followed by the improvement module. If the application of the improvement module results in the shrinking of the population (due to more than one solution converging to the same local optimum) then the diversification module is applied again until the total number of improved solutions reaches the desired target. Based on the improved solutions, the reference update module is applied to construct the reference set. Then SS continues in a loop that consists of applying the solution combination module followed by the improvement module and the reference update module. This loop terminates when the reference set does not change and all the subsets have already been subjected to the solution combination module. At this point, the diversification generation module is used to construct a new Refset2 and the search continues. The whole SS is terminated when the predefined maximum computational time is reached or the best solution cannot be improved after a predefined number of iterations.The improved SS algorithm was coded in C++ and run on a Core 2 with 2.83GHz CPU and 3.25GB memory using Windows XP operating system (32-bit). The algorithm was tested on the benchmark instances provided by Cicirello and Smith [5]. Three parameters characterize each problem instance: the due-date tightness factor τ, the due-date range factor δ and the setup time severity factor η. The benchmark set is established by the following parameter values: τ={0.3, 0.6, 0.9}, δ={0.25, 0.75} and η={0.25, 0.75}. Each of the 12 combinations of parameters leads to 10 problem instances with 60 jobs. These 12 problem sets cover a wide range of spectrum from loosely to tightly constrained problem instance. The benchmark instances can be obtained at http://loki.stockton.edu/~cicirelv/benchmarks.html.The performance of an algorithm has a great relationship with the parameters. To determine the relatively best parameters, considering both our previous experience and the preliminary testes of this problem, the parameters of the improved SS are set as follows: maximum number of the iteration=500, population size p=100, initial Refset1 size b1=5 and initial Refset2 size b2=5. For the adjustment process of the length of the reference set, max_nIter=5, Δb1=Δb2=3 while b1=b2=5, Δb1=Δb2=2 while b1=b2=8, Δb1=Δb2=5 while b1=b2=10, Δb1=5 and Δb2=0 while b1=b2=15.As described in Section 2, two local searches are used to improve the trail solutions. According to the maximum number of the exploration of the VNS and the complexity of the 3-opt move, it is easy to see that the required computational time of LS1 is larger than the time of LS2. In order to determine the scope of these local searches, we consider both the previous experience and some inexpensive pilot runs. Then the application of the local searches for this problem is as follows:Because different heuristics are used in the diversification generation module, the solutions in the initial population do not need to be improved. For the combined solutions, we defined a reference value TB which is 1.1 times the value of the best known solution. If the current solution is less than TB, then LS1 is used for all of the combined solutions. And if the current solution is larger than TB, then LS1 is used for the best combined solution while other combined solution is improved by LS1 or LS2 randomly.In the previous literature, overall aggregated best known solutions composed of the solutions generated by the SA, GA, TS algorithms by Lin and Ying [6] and the ACO algorithm by Liao and Juan [7] are denoted as Obk using as the comparison results. This set of solutions provides three best known solutions for the instances nos. 6, 69 and 116, which were given in Liao and Juan [7]. Tanaka and Araki [19] had found that these three solutions turn out to be incorrect due to corrupted instance data. And for other instances, it seems that the Obk is dominated in term of solution quality by the following algorithms. Therefore, we do not include the Obk and employ the following five sets of the best known solutions:(1)ACO_AP: solutions of the ACO algorithms by Anghinolfi and Paolucci [8].DPSO: solutions of the DPSO algorithm by Anghinolfi and Paolucci [9].DDE: solutions of the DDE algorithm by Tasgetiren et al. [10].GVNS: solutions of the GVNS algorithm by Kirlik and Oguz [11].OPT: optimal solutions of the exact algorithm by Tanaka and Araki [19].Our improved SS algorithm was run independently 20 times for each instance within a time limit of 300s. The average computational time is 186s. Table 1shows the comparison between the solutions from our improved SS algorithm, denoted by I-SS, the ACO_AP, the DPSO, the DDE, the GVNS and the OPT. Note that bold numbers in Table 1 show the optimal solutions. As a summary of Table 1, while comparing with other meta-heuristic algorithms, 20 (16.67%) out of 120 instances are improved, 76 (63.33%) out of 120 are equal, and 24 (20%) out of 120 are inferior to the overall aggregated best known solutions composed of ACO_AP, DPSO, DDE and GVNS algorithms. While comparing with the exact algorithm, ACO_AP, DPSO, DDE, GVNS and our I-SS get 36, 54, 68, 76 and 78 optimal solutions, respectively. The optimal solutions obtained by the above meta-heuristic algorithms are also described in Table 2.The relative percentage deviations are also provided to see the difference between our algorithm and the solutions in the literature. These deviations are computed as follows: ΔACO_AP=(fI-SS−fACO_AP)/fACO_AP×100%, ΔDPSO=(fI-SS−fDPSO)/fDPSO×100%, ΔDDE=(fI-SS−fDDE)/fDDE×100%, ΔGVNS=(fI-SS- fGVNS)/fGVNS×100%, ΔOPT=(fI-SS−fOPT)/fOPT×100%, where fI-SS, fOPT, fACO_AP, fDPSO, fDDEand fGVNSare the objective function values generated by these algorithms. Furthermore, Table 1 indicates that the average deviations with respect to ACO_AP, DPSO, DDE, GVNS and OPT are −5.16%, −3.33%, −1.81% −0.08% and 1.94%, respectively.Table 3shows the summary of our I-SS algorithm comparing with the existing algorithms. The table exhibits the number of improved, equally solved and unimproved solutions of the I-SS with respect to each of the algorithms from the literature. To see how I-SS algorithm performed across a wide variety of due-date tightness, due-date range and setup time severity parameters, we summarize our results in Table 4. The table summarizes the average relative percent deviations for each 12 combination according to the characteristics of the parameters as follows. For the due-date tightness factor τ, if τ value is large, then the due-dates are tighter compared to the case that τ values are small. The due-date range factor δ provides an empirical measurement about the spread of the due-dates, a small value of δ indicates a clustered set of due-dates. A larger value of the setup time severity factor η designates more significant setup value with respect to the processing time.From the computational results presented in Tables 1–3, the following observations can be made about our algorithm. It should be noted that these observations are very similar with Kirlik and Oguz's [11].(1)I-SS is better in terms of improving most of the existing result when η value is high given that τ and δ values are constant. This demonstrates the success of I-SS in solving problems having significant setup times concerning the processing times.I-SS improves more of the existing solutions when δ value is small given that τ and η values are constant. This shows the success of I-SS for those instances where the due-dates are not scattered.The highest improvement obtained by the I-SS comparing with ACO_AP, DPSO and DDE is for the second class of instances where τ=0.3, δ=0.25 and η=0.75, but it is inferior to the most successful algorithm in the literature (GVNS). While the relatively large improvements over the GVNS are 10.00% and 0.76% respectively for the fourth and the first classes of instances.Multiple populations and random strategies are adopted to promote the diversity of I-SS, but the effectiveness of these modules could be studied deeply in the future. I-SS is a bit time consuming which may be caused by the VNS based local search algorithm. This due to the trade-off of the efficiency and effectiveness.Fig. 10shows the box-plots of the objective functions given by I-SS for some instances (nos. 1, 10, 11, 20, 41, 50, 51, 60, 61, 70, 71, 80, 81, 90, 91, 100, 101, 110, 111, and 120). The instances nos. 21–40 are not considered in this experiment because most results of them are zero. Each box shows the lower quartile, the median, and the upper quartile values. The whiskers are lines extending from each end of the box to show the extent of the remaining data. The box-plots describe the distribution of the data and the consistency of the proposed algorithm.To test the performance of the multi-heuristics based diversification generation module, a computational experiment (denoted by EX1) which only uses the Heuristic 2 to generate the initial population is carried on the 120 instances. To test the performance of the adaptive adjustment of the length of the reference set, another experiment (denoted by EX2) is carried out on the 120 instances without employing the reference set's adaptive adjustment strategy. The configuration of the EX1 and EX2 is the same with the improved SS. The EX1, EX2 and the improved SS is employed on each instance 10 times and the average objective function of them is denoted by fAVG_EX1, fAVG_EX2 and fAVG_ISS, then the relative percentage deviations between them are computed as follows: Δ1=(fAVG_ISS−fAVG_EX1)/fAVG_EX1×100%, Δ2=(fAVG_ISS−fAVG_EX2)/fAVG_EX2×100%. The computational results are summarized in Table 5.As seen in Table 5, while comparing with the improved SS, 66 out of 120 instances are inferior and 19 out of 120 instances are equal by the EX1, 87 out of 120 instances are inferior and 18 out of 120 instances are equal by the EX2. The results show that these two strategies both could improve the proposed algorithm and the reference set's adaptive adjustment strategy is more effective.

@&#CONCLUSIONS@&#
In this paper, an improved SS algorithm is proposed to solve the strongly NP-hard single machine weighted tardiness scheduling problem with sequence dependent setup times. The algorithm includes both random strategy based heuristics and construction heuristic to generate the initial population, a variable neighborhood search as local search to improve the population and the combined solutions, and three combination operators containing a DDE operator to combine the solutions in the subsets. A variable-length reference set strategy is also proposed to improve the solving ability of SS. This algorithm is competitive with the existing best-performing meta-heuristics including ACO, DPSO, DDE and GVNS. The analysis of the outcomes showed that the competitiveness of the improved SS algorithm, which was able to improve 20 out of 120 overall aggregated best known meta-heuristics solutions so far in the literature and 76 instances were solved equally. While comparing with the exact algorithm, the proposed algorithm gets 78 optimal solutions out of 120 instances.