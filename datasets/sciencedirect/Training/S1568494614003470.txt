@&#MAIN-TITLE@&#
Convergence analysis and performance of an improved gravitational search algorithm

@&#HIGHLIGHTS@&#
IGSA that employs personal best memory and chaotic perturbation is proposed.Stability condition of the IGSA is analyzed based on linear system theory.Global convergence of the IGSA is presented using stochastic process method.Sensitivity analysis of parameters for IGSA is discussed on test functions.Comparative experiments are performed to evaluate performance of the IGSA.Results show IGSA outperforms other heuristic algorithms and GSA variants.

@&#KEYPHRASES@&#
Gravitational search algorithm,Memory strategy,Chaotic perturbation operator,Convergence analysis,Parameter sensitivity,Performance evaluation,

@&#ABSTRACT@&#
Gravitational search algorithm (GSA) has been shown to yield good performance for solving various optimization problems. However, it tends to suffer from premature convergence and loses the abilities of exploration and exploitation when solving complex problems. This paper presents an improved gravitational search algorithm (IGSA) that first employs chaotic perturbation operator and then considers memory strategy to overcome the aforementioned problems. The chaotic operator can enhance its global convergence to escape from local optima, and the memory strategy provides a faster convergence and shares individual's best fitness history to improve the exploitation ability. After that, convergence analysis of the proposed IGSA is presented based on discrete-time linear system theory and results show that IGSA is not only guaranteed to converge under the conditions, but can converge to the global optima with the probability 1. Finally, choice of reasonable parameters for IGSA is discussed on four typical benchmark test functions based on sensitivity analysis. Moreover, IGSA is tested against a suite of benchmark functions with excellent results and is compared to GA, PSO, HS, WDO, CFO, APO and other well-known GSA variants presented in the literatures. The results obtained show that IGSA converges faster than GSA and other heuristic algorithms investigated in this paper with higher global optimization performance.

@&#INTRODUCTION@&#
As many real-world optimization problems become increasingly complex, better optimization algorithms are always needed. The traditional optimization algorithms, such as the gradient descent method and the simplex method, do not provide a suitable solution because these approaches require objective function's gradient information, and may easily get trapped in a local optimum of highly multimodal or “deceptive” functions. Hence, in recent decades, a set of more adaptable and flexible heuristic optimization algorithms have been developed to solve problems with high dimensions, especially with incomplete or imperfect information or limited computation capacity. An important branch of these algorithms that simulates the inspiration of natural phenomena, especially biological systems or physical processes, is known as nature-inspired search algorithms.Genetic Algorithm (GA) [1], Differential Evolution (DE) [2], Estimation of Distribution Algorithm (EDA) [3], Ant Colony Optimization (ACO) [4], Particle Swarm Optimization (PSO) [5], Artificial Bee Colony (ABC) [6], Glowworm Swarm Optimization (GSO) [7], Seeker Optimization Algorithm (SOA) [8], Artificial Immune System (AIS) [9] and Bacterial Foraging Optimization Algorithm (BFOA) [10] are in the class of nature-inspired or biological-based stochastic optimization algorithms.In addition, another category of nature-inspired heuristic optimization algorithms usually inspired by physical processes have been proposed in some literatures to show satisfactory capabilities to handle high dimension optimization problems. Among them, Simulated Annealing (SA) [11], Electromagnetism-like Algorithm (EM) [12], Central Force Optimization (CFO) [13–17], Harmony Search Algorithm (HS) [18,19], Wind Driven Optimization (WDO) [20,21], Artificial Physics Optimization (APO) [22,23], Space Gravitational Optimization (SGO) [24] and Integrated Radiation Optimization (IRO) [25] belong to physics-inspired heuristic search algorithms. These algorithms mimic physical behavior and physical principles.The above-mentioned algorithms have shown good performance in a wide range of optimization problems, such as function optimization [6–8,10,12,13,28], data clustering [5,39,43,56], image processing [31,41], economic dispatch [9,32–34,44] and neural networks training [42]. However, many of them may suffer from premature convergence or result in their missing global optimum. For instance, PSO can sometimes find local optima or exhibit slow convergence speed in the later stage; CFO and WDO take long running times to obtain the solution. Moreover, a majority of these algorithms require several parameters to tune, and some of the parameter settings can be challenging for optimization problems. Moreover, there is no specific algorithm to be capable of obtaining adequately high performance for all the optimization problems in comparison with other alternatives [26]. In other words, some algorithms give a better solution for some particular problems than others. Hence, searching for new effective heuristic algorithms for optimization areas remains an open issue [27].More recently, inspired by the law of gravity and mass interactions, a newest physics-based heuristic stochastic optimization algorithm, namely gravitational search algorithm (GSA), has been firstly introduced by Rashedi et al. [28]. GSA is characterized as a simple concept that is easy to implement with higher computational efficiency and small numbers of parameters to adjust. Since its introduction, it has been analyzed over time by researchers and this algorithm has shown good performance and is suitable for solving complex problems in both scientific research world and industrial application fields [29–39]. However, the common drawbacks of some heuristic stochastic optimization algorithms are not free from false and/or premature convergence in optimization process, especially over multimodal fitness landscapes and higher dimensional problems. GSA is no exception. In GSA, gravity is a force that pulls all objects together. As this force absorbs every other particle, there will not be any recovery for the algorithm if premature convergence happens. In other words, after going into converged premature stage, the algorithm loses the ability of exploration and then becomes inactive. To overcome the disadvantage, several improvements in GSA have been proposed to further enhance its optimization performance. Li et al. [40] proposed a hybrid heuristic algorithm integrating differential evolution into gravitational search algorithm (DE-GSA) for unconstrained optimization. A novel hybrid algorithm, genetic algorithm-based gravitational search algorithm (GA-GSA) using multilevel thresholding was introduced for image segmentation [41]. Also, a hybrid particle swarm optimization and gravitational search algorithm (PSOGSA) for training feedforward neural networks was proposed by Mirjalili et al. [42]. Although these hybrid algorithms can provide satisfactory results, they may increase the computational complexity of the algorithms in a way. Hence, there will be a good alternative if simple operators are directly merged with GSA to improve its performance. A modified gravitational search algorithm (MGSA) was proposed for digital secure communication by introducing logistic chaotic operator to overcome premature convergence [43]. Chatterjee et al. [44] proposed a novel GSA with wavelet mutation concept (GSAWM) for the solution of economic load dispatch problems.Although GSA and its various variants have been proven successful against other well-known algorithms, there is room for improvement, particularly by taking more efficient search strategies in a given time budget. In order to further achieve more rapid convergence ability, lower computational complexity and better convergence accuracy, an improved variant of gravitational search algorithm (IGSA) is proposed in this paper. It is achieved by first adding iterative chaotic perturbation operator and then considering memory strategy. The twofold modification tries to balance between the explorative and exploitative tendencies of the swarm with the objective of achieving better search performance. The work is done as follows. First, since the original GSA is a memory-less algorithm and ignores each individual's fitness history in the process of iterations. According to PSO's sharing information strategy, each particle's best fitness stored by PSO is introduced to help advance the search into the regions that otherwise might not be exploited. Consequently, memory strategy including each individual's best fitness history from PSO is proposed to enhance the exploitation ability (also termed intensification) of GSA. Second, new iterative chaotic perturbation operator in nonlinear system to overcome premature convergence is added to GSA to increase its flexibility and exploration ability (also termed diversification) for solving more complicated problems. The two modifications can help GSA to explore all the promising regions and work more efficiently. Third, to the best of our knowledge, there has not been an intact mathematical analysis on GSA or IGSA. And inspired by the linear difference equation based convergence analysis [23,45–47], this paper also proposes a new linear, time-invariant system theory based convergence analysis of IGSA for further insight into the proposed algorithm. Finally, the proposed algorithm is applied to the well-known test functions and compared with several state-of-the-art heuristic algorithms.This paper is organized as follows. The next section provides a brief comparison of physics-inspired heuristic algorithms. In the third section, we introduce the framework of the original GSA. Fourth section describes an improved gravitational search algorithm and its improvements. Fifth section presents the convergence analysis of IGSA. The comparative study of IGSA with other GSAs and representative heuristic stochastic algorithms against several recognized test functions is presented in the sixth section. Finally, the last section presents conclusions and suggestions for the relevant future work.As pointed out above, nature-inspired heuristic algorithms mimic physical, collective and biological phenomenon and seek good results in specific optimization problems at a reasonable computational load through defined iteration equations and specified operators. Some of these famous physics-inspired heuristic algorithms are SA [11], EM [12], CFO [13–17,46], APO [22,23] and GSA [28–44]. Among them, different points of views based on the selected characteristics have been considered to describe these physic-based algorithms as below. First, CFO is inherently a deterministic heuristic search algorithm and does not use any random parameter in its formulation, whereas others are provided with stochastic behavior based on the metaphor of physical processes. Furthermore, CFO is reasonably complex and typically requires higher computational time for convergence when compared with other algorithms. Second, these algorithms originate from different development backgrounds and movement mechanisms. For instance, SA performs optimization by analogizing the statistical mechanics of systems in thermal equilibrium. Its search process starts from a single point and continues in a sequential manner, while other approaches do search in a parallel fashion with multiple initial points, e.g. PSO of swarm-based algorithms uses a collection of particles similar to a natural flock of birds; CFO is based on a swarm of scattered probes that are both repelled and attracted by other probes based on their gravity force throughout the search space. These probes are EM is inspired by Coulomb's force law from electromagnetic theory by viewing each particle as an electrical charge, while CFO, APO and GSA are based on Newtonian's gravity force law for mutual object masses. Each particle possesses “charge” and position in EM, while each probe has a “mass” and position for APO and GSA. The electromagnetic force is proportional to the product of the charges and inversely proportional to the square of the separation distance for EM, while the force of gravity is proportional to the product of the masses with the same distance dependence for CFO, APO and GSA.However, seen from another point of view, although the gravity force laws are very similar for CFO, APO and GSA, and gravity acts between separated particles without any intermediary and delay, these algorithms differentiates themselves as they have various evolution formulae and different mass definitions. First, CFO is a deterministic multi-dimensional search algorithm. Its initial probe positions are computed in a deterministic manner with a uniform distribution of probes on each coordinate axis, while the initial distribution of swarm particle positions is random in APO and GSA. Second, each agent in the population possesses some physical quantities with a position, mass, velocity and momentum for APO and GSA, while CFO possesses no velocity. Finally, the force effect laws of APO and GSA are different [23,28]. APO applies the attractive–repulsive force law to its individual. Fig. 1can be used to explain how APO works. Suppose that the algorithm has three particles i, j and l in a two-dimensional decision space, and corresponding masses are set to mi, mjand ml(ml>mi>mj). Under APO's novel attractive–repulsive force law, particle i is attracted by particle l and repelled by particle j, in other words, an attractive force Filand a repulsive force Fijare exerted on particle i. As a result, the total force Fiexerted on particle i is calculated by vectorially adding the force Filand Fij. Then, particle i moves through the decision space under the action of this total force Fiwhich determines its velocity, in turn, is used to update particle i's position step-by-step throughout the optimization process. On the other hand, however, GSA considers only its attractive gravity force among all other particles of the decision space where the effect of bigger and the closer particle is higher. GSA adopts the attractive force law between its individual. GSA's working principle is illustrated in Fig. 2. In this figure, the parameter's implication is the same as those of Fig. 1. Under GSA's attractive force law, Fijis the force that acting on mifrom mjand Filis the force that acting on mifrom ml. Then, Fiis the overall force that exerts on miand causes the velocity and acceleration vector. The detailed descriptions of these algorithms can be referred to the corresponding publications [11–16,23,28] and they serve as examples of the efficacy of searching the decision space by analogizing a law of physics.Here, a simple comparison of several physics-inspired heuristic algorithms is made to help us understand their differences and select a suitable method when applying to seek the optimal solution. Motivated by the aforementioned research, the motivation of this study is to propose a new optimization algorithm, an improved GSA (IGSA), in which the novel chaos operator and memory strategy are applied to achieve better performance over solving complex optimization problems. In the following, an overview of original GSA is given to provide an introduction and followed by the proposed IGSA approach and its convergence analysis.Gravitational search algorithm is a newly developed population-based stochastic optimization method based on the metaphor of gravity and mass interactions. This approach provides an iterative method that mimics mass interactions and moves through a multi-dimensional search space under the influence of gravitation in physics. In this algorithm, particles are taken into consideration as objects and their performances are measured by their masses. Every particle represents a candidate solution to the search problem. All the particles attract each other by the gravity force, and this force causes a global movement of all objects toward the objects with heavier masses. Hence, masses mutually cooperate using a direct form of communication by gravitational force. Since the heavier masses have higher fitness values, they describe good optimal solutions to the problem and move slower than lighter ones representing worse solutions. Then, it is guaranteed that the algorithm obtains global solution and convergent performance.Each particle in GSA is specified by four parameters [28]: position of the mass of a particle at specified dimensions representing a solution of the problem, inertial mass representing a particle resistance to changing its state of motion, active gravitational mass standing for the strength of the gravitational field due to a particular particle, and passive gravitational mass reflecting the strength of a particle's interaction with the gravitational field. Both the gravitational mass and the inertial mass are determined by fitness evolution of the problem. The algorithm is navigated by properly adjusting the gravitational and inertial masses. By lapse of time, the masses will be attracted by the heaviest mass which represents an optimal solution in the search space.The GSA comprises three main procedures: (a) Initialization, (b) Force Calculation, (c) Motion. The steps of GSA are depicted in Table 1. To describe the GSA, let us consider a system with N objects (masses). The position of the ith object Xi, which is a candidate solution, is defined by:(1)Xi=(xi1,…,xid,…,xiD)fori=1,2,…,Nwherexidrepresents the positions of the ith agent in the dth dimension, D is the dimension of the search space, N denotes the total number of particles.In the initialization step, a population of particles is randomly generated in the D-dimensional decision space. The particles’ velocities are initialized to zero, although non-zero values could be used if desired. The fitness evaluation (value of the objective function) for each particle is calculated using the objective functionfit(Xi). The position vector of the particle with the greatest fitness at step t is denoted Xbest.In the Force Calculation, the total force exerted on each particle is calculated based on the “masses” and distances between particles. The GSA force law is an extension of the physics force law, which firstly requires a definition of “mass” in GSA. Mass is a user-defined function of an objective function to be optimized, here it ismi=g(f(Xi)), where mi∈(0,1] andg(⋅)≥0is bounded and monotonically decreasing. Obviously, there are many functions meeting the requirements and no doubt some will be better than others for specific optimization problems or classes of problems. The basic requirement is that the mass of the best particle has the largest (normalized) value, that is, mbest=1, while all other particles with worse fitness have smaller values. The choice of mass function, however, depends on whether maximization or minimization is the goal. Thus, an additional requirement is that the mass function should be monotonically increasing or decreasing for maximization or minimization, respectively, thereby guaranteeing greater mass, and hence greater attractive force for the better fitness value. Thus, after evaluating the current population fitness, the gravitational mass and inertia mass [28] for each particle are calculated as follows:(2)Mai=Mpi=Mii=Mi,(3)mi(t)=fiti(t)−worst(t)best(t)−worst(t),i=1,2,…,N(4)Mi(t)=mi(t)∑j=1Nmj(t),whereMaiis the active gravitational mass of the particle i, Mpiis the passive gravitational mass of the particle i, Miiis the inertia mass of the particle i.fiti(t)represents the fitness value of the ith particle at time t. A larger mass indicates a more efficient object. This means that more efficient objects possess greater attractions and move more slowly. Also, best(t) and worst(t) respectively specify the best and the worst particle with regard to their fitness value. Without loss of generality, considering a minimization problem:(5)best(t)=minj∈{1,…,N}fitj(t),(6)worst(t)=maxj∈{1,…,N}fitj(t).Having developed an appropriate definition of mass, the next step is to compute the forces exerted on each particle by all other particles, component by component, we define the force acting on mass ‘i’ from ‘j’ as following:(7)Fijd(t)=G(t)Mpi(t)×Maj(t)Rij(t)+ε(xjd(t)−xid(t)),whereMaj(t)is the active gravitational mass related to particle j,Mpi(t)is the passive gravitational mass related to particle i.ɛ is a small value. The gravitational constant G(t) is calculated by Eq. (8), where G0 is set to 100 and α is set to 20 [28], and tmax is the total number of iterations:(8)G(t)=G0exp−αttmax.Rij(t)is the Euclidean distance between i and j particles, which is defined as follows:(9)Rij(t)=Xi(t),Xj(t)2.After that, the total force acting on the ith particle in a dimensiond(Fid(t))is calculated as follows:(10)Fid(t)=∑j∈kbest,j≠iNrandjFijd(t),where randjis a random number in the interval [0,1], kbest is the set of first K particles with the best fitness value and biggest mass, which is a function of time with the initial value K0 at the beginning and decreasing with time. Here K0 is set to N (total number of particles) and is linearly decreased to 1. In such a way, at the beginning, all particles apply the force, and as time passes, kbest is decreased linearly and at the end there will be just one particle applying force to the others. To avoid trapping in a local optimum the algorithm must use the exploration at the beginning, and by lapse of iterations, exploration must fade out and exploitation must fade in. Thus, only the kbest particles will attract the others, which enhance GSA's computational efficiency by regulating the exploration and exploitation of GSA.The third and final step is Motion, which refers to the movement of particles through the decision space using the previously computed total force to calculate a “velocity”, (vid(t)) which then is used to update the particles’ positions (xid(t)). The velocity and coordinates of particle i at time t+1 of the next iteration are updated using Eqs. (11) and (12), respectively:(11)vid(t+1)=randi×vid(t)+aid(t),(12)xid(t+1)=xid(t)+vid(t+1),where randiis a random number in the interval [0,1]. This number enables the algorithm to have a randomized characteristic to the search, which may further advance the global convergence ability of the algorithm. Each particle's movement is restricted to the domain of feasible solutionsxid∈xdmin,xdmax, and the velocities are similarly constrainedvid∈vdmin,vdmax. The acceleration of particle i in direction d at iteration t is denoted asaid(t)and given as follows:(13)aid(t)=Fid(t)Mii(t).whereMii(t)=Mi(t)is the inertial mass of ith particle.GSA's effectiveness has been testified against other well-known methods, but there is room for improvement. In this section, memory strategy and iterative chaotic perturbation operator are performed to avoid premature convergence and improve the search speed compared to GSA. The steps of an improved gravitational search algorithm (IGSA) are depicted in Table 2.It is well known that the velocity updating in the PSO algorithm depends on its own best fitness history and the best fitness experience of the swarm found so far. Thus, information sharing on each particle's best position can help advance the search into areas that otherwise might not be explored, while the original GSA reserves only the global best position located by the entire population and ignores each particle's best fitness history, even though this information may be very beneficial in promoting the search. GSA, therefore, is modified to include the personal best fitness history found so far by an individual particle. IGSA consequently extends GSA to include its own fitness history in the following way.Pi=(pi1,pi2,…,piD)is defined as the position vector of the best fitness found by particle i over all iterations at the current iteration, t. At each successive iteration, the fitness history is updated as follows:(14)pid(t+1)=pid(t),iff(Xi(t+1))>f(Pi(t)),xid(t+1).iff(Xi(t+1))≤f(Pi(t)).The best fitness over all particles is denoted as Pbest=Xbest. The GSA mass function in Eq. (3) is modified to include the fitness history as follows:(15)mi(t)=fitpi(t)−worst(t)best(t)−worst(t),(16)Mi(t)=mi(t)∑j=1Nmj(t).The analogs of Eqs. (7) and (10) for calculating the component-wise force are exerted on each particle by all others and the updated velocity components and particle positions are altered as follows:(17)Fid(t)=∑j=1,j≠iNrandjFijd(t)=∑j=1,j≠iNrandjG(t)Mpi(t)×Maj(t)Rij(t)+ε(pjd(t)−xid(t)),(18)vid(t+1)=wvid(t)+aid(t),(19)xid(t+1)=xid(t)+vid(t+1),where w∈[0,1) is a user-specified inertia weight that determines how easily the previous velocity can be changed, and note that larger values of w corresponds to greater velocity changed.A new chaotic operator modification should be inserted into GSA in order to overcome premature convergence. Chaos is a kind of nonlinear dynamic that can be used for global optimization due to its ergodicity and random nature [48]. GSA approach can be more capable of escaping from local convergence than random search. To prevent divergence in solutions and inordinate increase in the complexity of the algorithm, the solutions that satisfying a certain condition (Eq. (20)) should be exerted on iterative chaotic perturbation operator. If the ratio of the distance between mass i and its nearest neighboring mass (solution) to its distance from the star (the best solution) is checked and smaller than a specific threshold pc, the iterative chaotic perturbation will only take place on mass i. Obviously, this condition is checked for all solutions except for the best solution.(20)Ri,jRi,best<pc,where Ri,jand Ri,bestare Euclidean distances between masses i and j and between mass i and the best solution, respectively. Note that mass j is the nearest neighbor of mass i in the decision space. The operator threshold pcshould be a variable with regard to number of iterations or number of fitness evaluations in order to make the chaotic operator more meaningful, as shown in Eq. (21). In other words, when the distances between the masses are larger at the beginning, threshold pchas to be large to provide more exploration, and the masses will get closer to each other as time passes, then parameter pchas to become smaller. In this work, according to the results of experiments on sensitivity analysis of parameters in subsection “Sensitivity analysis of parameters of IGSA”, β is set to 5.(21)pc=β⋅1−ttmax.Among the particles, a selected particle will undergo iterative chaotic perturbation operator as given in Eq. (22).(22)Xi(new)=Xi(old)*L,L=Ri,j⋅Zk,Ri,best≥1,1+ρ⋅Zk.otherwise.in which L is a zoom factor to control the algorithm lying on exploring or exploiting stage. WhenRi,best≥1,Ri,j⋅Zkcan be a smaller or larger value than 1, and by multiplying it to Xi(old), then Xi(old) changes randomly and becomes larger or smaller than what this was previously. As a result, this may place Xi(new) in a position far from Xi(old). Therefore, the algorithm is able to explore the search place thoroughly. On the other hand, whenRi,best<1(i.e., mass i is close to the best mass and, in this case, the algorithm should exploit around the best solution), L is set to a region with radius ρ to provide exploitation around Xi(old). Then by multiplying L to Xi(old), the algorithm finds new solutions near to the old ones. In the circumstance, the algorithm is exploiting. It is clear from Eq. (22) that whenRi,best≥1, the iterative chaotic perturbation operator makes the algorithm in the exploring stage, and whenRi,best<1, the masses are converging and getting close to the best solution, so it is the time to exploit.Besides,ρ=10−16is a small constant.Zk=ηsin(γ1/Zk−1)exp(−γ2Zk−12)[49,50] represents an iterative chaotic map function with infinite collapses in the interval [–1,1],ηis a damping factor(0≤η<1),γ1andγ2are two positive constants. In this work, the parameters are specified by η=0.95, γ1=8, γ2=3. Fig. 3shows the chaotic graphs of the map with the specified parameters and k=500.As a novel algorithm, IGSA, its theoretical foundation can help us understand the algorithm dynamic characteristics and make a further improvement. Whether IGSA is convergent? Can IGSA converge to local optima or global optimum? As far as we know, the swarm dynamics of GSA has been almost not mathematical analyzed so far. Hence, a detailed proof of IGSA convergence is developed here. It includes two cases. In the first case, the stability conditions of particle's trajectory in IGSA are analyzed. It reveals the specific conditions under which IGSA is guaranteed to converge to a point in the decision space, and it depends on including the best fitness history as a key part in the algorithm. Another case is the analysis on its global convergence based on stochastic process theory. This proof also encourages further work of analyzing. That is to say, IGSA converges to a global optimum with the probability 1.We first try to develop a proof of stability convergence conditions in IGSA based on an analysis drawn from the theory of linear, time-invariant systems.The velocity update Eq. (18) is rewritten as follows:(23)vid(t+1)=wvid(t)+aid(t)=wvid(t)+∑j=1,j≠iNrandjFijd(t)Mii(t).For analysis purpose, several assumptions are made to facilitate the convergence analysis by reducing the D-dimensional problem to a simplified one-dimensional one-particle algorithm. Also, consider the situation that Pbestkeeps constant during a period of time (of course, in operation Pbestis updated as IGSA progresses), then all particles evolve independently. Thus, only particle i needs to be studied. Without loss of generality, particle i is chosen arbitrarily. At the same time, it is evident from Eqs. (18), (19) and (23) that each dimension is updated independently from the others. As a result, the algorithm analysis description can be reduced to a one-dimensional case. Thus, by omitting the coordinate (dimension) index d in Eqs. (23) and (19), the following update equations become:(24)Vi(t+1)=wVi(t)+∑j=1,j≠iNrandjFij(t)Mi(t),(25)Xi(t+1)=Xi(t)+Vi(t+1).It should be noticed that the above simplification is only for analysis purpose, and the analytical results can apply to the total mass swarm. All analyses in this paper are based on the simplified one-dimensional one-particle system, and the extension to the real D-dimensional N-particle system can be easily obtained.Definition 1Bi={j|f(Pj)<f(Xi),∀j∈S}is a set of particles which better fitness than particle i.Wi={j|f(Pj)≥f(Xi),∀j∈Sandj≠i}is a set of particles which worse fitness than particle i. where, S is the swarm all of particles. Then, for the single-particle one-dimensional IGSA with the constant Pj, the velocity update Eq. (24) can be simplified as:In order to make the procedure of proof process clear, some symbols should be first introduced. Let(27)FBi=∑j∈BirandjG(t)MjRij+ε,(28)FWi=∑j∈WirandjG(t)MjRij+ε,(29)FBWi=FBi+FWi,(30)Fi=∑j∈BirandjG(t)MjPjRij+ε+∑j∈WirandjG(t)MjPjRij+ε.After that, Eq. (26) can be written:(31)Vi(t+1)=wVi(t)−FBWiXi(t)+Fi.By substituting Eq. (31) into Eq. (25), the following non-homogeneous recurrence relation is obtained:(32)Xi(t+1)−(1+w−FBWi)Xi(t)+wXi(t−1)=Fi.Obviously, Eq. (32) is a second order difference equation with Fican be considered as the external input, which does not affect stability.In order to testify the convergence of IGSA, we first introduce the methodology of stochastic sequences convergence. For a deterministic discrete-time sequence {X(t)}, t=0, 1,…, the scalars or vectors X(t) converges to the limit point X*if and only if the limit exits:(33)limt→∞X(t)=X*.However, IGSA is inherently stochastic process. Each particle's position vector includes random component, so the deterministic definition of convergence above should be expanded to use this method. There are several ways to define convergence for stochastic sequences. The notion of mean convergence is adopted in the current paper. Consequently, convergence is defined as follows: {Xi(t)} converges to X*(i.e.∀i∈{1,2,…,N}if and only iflimt→∞E[X(t)]=X*), that is, X*is the limit of the expected value of {Xi(t)}, where E refers to the mathematical expectation operator, N is the population size (number of particles), Xi(t) is the position of particle i at time t, and E[Xi(t)] is the expected value of Xi(t). In term of this definition, IGSA is said to “converge” to a solution at the point X* in the decision space.As a result, for the stochastic variable, applying the above-mentioned convergence definition, particle position's expectation will be calculated, which are deterministic processes rather than stochastic processes, thus the corresponding guaranteed convergence properties can be directly analyzed. Hence, the mathematical expectation operator to Eq. (32) yields(34)E[Xi(t+1)]−(1+w−θi)E[Xi(t)]+wE[Xi(t−1)]=ϕi.where(35)θi=E(FBWi)=1/2G∑j∈BiMj+∑j∈WiMjRij+ε,(36)ϕi=E(Fi)=1/2G∑j∈BiMjPj+∑j∈WiMjPjRij+ε,(37)G=E[G(t)]=EG0exp−αttmax=G0tmax2α2.By observation, the eigenvalue (characteristics) equation for the second order linear system given by Eq. (34) is(38)λ2−(1+w−θi)λ+w=0Based on the theory of stability for discrete dynamics system [51], IGSA convergence is equivalent to the stability of the dynamical system (32). The system represented by Eq. (34) is stable when its eigenvalues lie inside the unit circle in the complex plane. Then, the following result is obtained.Theorem 1Given w≥0 and G>0, if and only if 0≤w<1 and 0<θi<2(1+w), then {E[Xi(t)]} is guaranteed to converge to Xbestwhich is the particle position with the greatest fitness.The convergence condition of {E[Xi(t)]} is that the absolute values (complex moduli) of both eigenvaluesλ1,λ2are less than 1. That is,Due to the different value of the discriminant(1+w−θi)2−4wfor Eq. (39), three cases are discussed as follows:(i)The discriminant is zero, i.e.(1+w−θi)2=4w.The eigenvalues are real and equal to each other,λ1=λ2=(1+w−θi)/2.Condition (i) is equivalent toθi=1+w±2w, that is,λ1=λ2=±wandλ1=λ2=w. Hence,λ1=λ2<1is assured as long as0≤w<1.The discriminant is positive, i.e.(1+w−θi)2>4w.In this case, both the eigenvalues are real and unequal, that is,(40)λ1=1+w−θi2+(1+w−θi)2−4w2and(41)λ1=1+w−θi2−(1+w−θi)2−4w2Condition (ii) is equivalent toθi>1+w+2worθi<1+w−2w.Ifθi<1+w−2w,thenmaxλ1,λ2<1is assured whenλ1<1,thus resulting inw<1and0<θi<1+w−2w.Ifθi>1+w+2w,thenmaxλ1,λ2<1is assured whenλ2>−1,thus leading tow<1and1+w+2w<θi<2+2w.Combining the cases results in w<1 and1+w+2w<θi<2+2wfor stability.The discriminant is negative, i.e.(1+w−θi)2<4w.Similarly, the two eigenvalues are complex conjugates with equivalent modulus:(42)λ1=1+w−θi2+(1+w−θi)2−4w2iand(43)λ1=1+w−θi2−(1+w−θi)2−4w2iMoreover,λ1=λ2=1+w−θi22+(1+w−θi)2−4w4=2(1+w−θi)2−4w2.The stability conditionλ1<1andλ2<1therefore is satisfied when2(1+w−θi)2−4w2<1,thus resulting inθi>1+w−21+w.After that, because condition (iii) is equivalent to1+w−2w<θi<1+w+2w, the stability convergence condition becomes1+w−2w<θi<1+w+2wfor the case (iii).In conclusion, stable system is guaranteed when the stability conditions imposed by cases (i)–(iii) are simultaneously met, that is, in the intersection of the three regions of thew−θiplane. Then, the sequence {E[Xi(t)]} will follow a convergent trajectory under the following conditions:(44)0≤w<1and0<θi<2(1+w).Eq. (44) reveals the relationship between running parameters {w, Mj, G} that ensures convergence.When {E[Xi(t)]} is convergent, the corresponding convergent position vector X*can be computed fromX*−(1+w−θi)X*+wX*=ϕi. Then we get the result(45)θiX*=ϕi.Substituting Eqs. (35) and (36) into (45), we yield(46)12G∑j∈BiMj+∑j∈WiMjX*Rij+ε=12G∑j∈BiMjPj+∑j∈WiMjPjRij+ε,which may be written as(47)12G∑j∈BiMj+∑j∈WiMjX*Rij+ε=12G∑j∈BiMjPj+∑j∈WiMjPjRij+ε⇒∑j∈Bij≠bestMj+∑j∈WiMjX*+MbestX*=∑j∈Bij≠bestMjPj+∑j∈WiMjPj+MbestPbest⇒∑j∈Bij≠bestMjX*−∑j∈Bij≠bestMjPj+∑j∈WiMjX*−∑j∈WiMjPj+Mbest(X*−Pbest)=0.By observation, Eq. (47) is ensured if and only ifX*=Pj=Pbest. Then,E[Xi(t)]=X*=Pbest. This completes the proof of Theorem 1.□Now, we analyze a particle movement trajectory based on the above convergence condition in running process. Substituting Eq. (35) into Eq. (44) yields(48)0≤w<1and0<G∑j∈BiMj+∑j∈WiMjRij+ε<4(1+w).It is obvious from this expression that particle trajectories in evolutionary process are convergent if G satisfies0<G<41+wRij+ε/∑j∈BiMj+∑j∈WiMj, i.e. a smaller value of G will guarantee convergence, while a larger value of G, i.e.G≥4(1+w)(Rij+ε)/∑j∈BiMj+∑j∈WiMj, the trajectories will result in instability. As a matter of fact, sinceRijemerges larger distance, while∑j∈BiMj+∑j∈WiMjemerges smaller mass in the early stage of the algorithm,G(t)may be not meet the convergent condition. Thus, the algorithm shows more capability of exploration in a way to avoid trapping in a local optimum at beginning. By lapse of iterations, due to the fact that particles with memory strategy and information-transferring mechanisms tend to move toward the best particle in the IGSA,Rijtends to reduce while∑j∈BiMj+∑j∈WiMjtends to increase.G(t)tends to a small value, even zero and is guaranteed to satisfy the convergent condition by using Eq. (8). Thus, the dynamic system of IGSA tends to a stable stage and the algorithm presents much more ability of exploitation to contribute to obtaining the optimal solutions. It is consistent with the idea that gravitational constantG(t)adjusts the accuracy of the search proposed in [28].The stochastic nature of IGSA makes it more difficult to prove (or disprove) properties like global convergence. Solis and Wets have studied the general sufficient conditions for the convergence of different type stochastic search algorithms, providing relevant criteria under which algorithms can be considered to be global search algorithms [52,53]. For convenience, some mathematical preliminaries have been reproduced below.Assumption 1Given a continuous function on the feasible region S, f:Rn→RandS⊆Rn. The objective is to find a pointx∈Swhich minimizes f on S, where S is bounded closed region.Suppose that ξnis a stochastic sequence in a probability space, if there exists random variable ξ for∀ε>0, such thatlimn→∞Pξn−ξ<ε=1, then stochastic sequence {ξn} converges to ξ with a certain probability.For the aboveξnandξ, if there existsP{limn→∞ξn=ξ}=1orP⋂n=1∞⋃k≥n|ξn−ξ|≥ε=0, then stochastic sequence{ξn}converges toξwith the probability 1 (w. p. 1).Borel–Cantelli Lemmas[52]: Suppose thatAk:k≥1is a sequence of events in a probability space. Letpk=P{Ak}. If∑k=1∞pk<∞holds, thenP⋂n=1∞⋃k≥nAk=0, i.e. among the events {Ak} infinitely many takes place, w. p. 1. Similarly, suppose that{Ak:k≥1}is a sequence of independent events in a probability space. If∑k=1∞pk=∞holds, thenP⋂n=1∞⋃k≥nAk=1, i.e. among the events {Ak} only a finite number takes place, w. p. 1.Suppose thatΔxid=vid(t+1)=xid(t+1)−xid(t),thenΔxid∼N(μi,σi2).Substituting Eq. (23) intoΔxid=vid(t+1)=xid(t+1)−xid(t),we obtainLetwvid=μi,∑j=1,j≠iNFijd/Mii=σiandrandj=λ:(50)Δxid=μi+λσi,whereμi,σiare constant, whereasλ∼N(0,1), thusΔxid∼N(μi,σi2)is testified andΔxidare mutually independent variables.□According to Assumption 1, we haveI=x|argminx∈Sf(x)≠∅. For any givenε>0, let us defineD0={x∈S|f(x)−f*<ε};D1=S\D0,wheref*=min{f(x):x∈S}, and then the position vector X(k) generated by IGSA in S at step k should be classified two states:(i)At least a particle belong to D0, there is the noted state I0;All the particles belong to D1, there is the noted state I1.Suppose that Assumption 1 holds, and ifqij(i,j=0,1)is the state transition probability of going from the stateIiin X(k) toIjinX(k+1), then two cases are obtained:For any state I0in a set of points X(k),q00=1;For any stateI1in a set of points X(k),q11≤bwhen there exists a constantb∈(0,1).That (i) holds in terms of steps of IGSA is obviously. The following main content is the proof of (ii).According to a continuous function f(x) in the feasible region S, there is a particle x0 which minimizes f on S. Therefore, there existsr>0, we certainly havef(x)−f(x0)<ε/2whenx−x0≤r. DefineSx0,r=x∈S|x−x0≤r. It is easy to see thatSx0,r⊂D0. Also, let us define the set A which includes N particles of a swarm andA⊂S. For anyi∈A, then we have(51)P{(xi+Δx)∈Sx0,r}=∏d=1DPxid+Δxid−x0d≤r=∏d=1DPx0d−xid−r≤Δxid≤x0d−xid+r,wherex0d,xidrepresent the kth component of the particlesx0,xi, respectively. Based on Lemma 2, we have(52)P{(xi+Δx)∈Sx0,r}=∏d=1D∫x0d−xid−rx0d−xid+r12πσie(y−μi)22σi2dy.DefineP1(xi)=P{(xi+Δx)∈Sx0,r}for anyi∈N. Hence, Eq. (52) implies0<P1(xi)<1. According to the fittest particle found so far by the entire swarm in IGSA, we have(53)Pi=Pi,iff(xi+Δx)>f(Pi),xi+Δxiff(xi+Δx)≤f(Pi).Thus, it is clear that0<P1(Pi)<1. If there existsl∈Ain finite set A, then(54)P1(Pl)=mini∈A(P1(Pi))By Eq. (54) andSx0,r⊂D0, it can be concluded thatq10≥P1(Pi)≥P1(Pl), whileq10+q11=1, hence, for a given b, we therefore have thatq11=1−q10≤1−P1(Pl)=b. This completes the proof of Lemma 3.□Theorem 2Let {Pg} be a sequence of solutions generated by the IGSA algorithm, in which{Pg(k)}∈Pgdenotes the optimal solution in the swarm at time k, that is,Pg(k)=argmin1≤i≤Nf(Pi(k)). If Assumption 1 is satisfied, we have thatP{limx→∞f(Pg(k))=f*}=1, in other words, {Pg} converges to the global solution to Assumption 1 with the probability 1.For any givenε>0, let us definePk=P{|f(Pg(k))−f*|≥ε}, wheref*=min{f(x):x∈S}. Accordingly,By Lemma 3, we can deduce thatPk¯=q11k≤bk, such that∑k=1∞Pk¯≤∑k=1∞bk=b/(1-b)<∞. Also,P⋂n=1∞⋃k≥n|f(Pg(k))−f*|≥ε=0is obtained through Lemma 1 (i.e. Borel–Cantelli Lemmas). As a result, we can conclude thatf(Pg(k))converges tof*with the probability 1 using Definition 4, i.e., it converges to the global solution with the probability 1. This completes the proof of Teorem 2□.It has been theoretically proven that the IGSA is global convergent in the section “Convergence analysis of IGSA”, which, however, is not sufficient to draw a conclusion that the IGSA is effective in real-world applications. Hence, the experiments to objectively evaluate the performance of the proposed IGSA using a large test set of optimization functions were performed. These test functions are presented in the subsection “Benchmark test functions”. The subsection “Experimental design” proposes experimental scheme including parameters settings for related algorithms. The sensitivity analysis of parameters of IGSA is discussed in third subsection. In the subsection “Comparative study”, some empirical studies on 16 popular benchmark functions were performed in order to make an extensive performance investigation and comparison between GA, PSO, HS, WDO, CFO, APO and other variants of the GSA algorithm presented in the corresponding publications.All of the test functions with different complexities of the fitness landscape are listed in the Appendix A. These functions were considered in the study [53,54] as well. According to their properties, they are divided into three classes: unimodal test functions (f1–f7) (they have a single local optimum that is a global optimum), multimodal test functions with many local optima (f8–f13), and multimodal test functions with two dimensions (f14–f16). All the functions used in this paper are minimization problems. More detailed description of these benchmark functions can be found in [55]. Since they have different properties (e.g. they are unimodal or multimodal, or have dependent or independent variables), we select these functions as each of them represents a candidate for a different class of real-world problems. A better optimization algorithm maintains balance between exploration and exploitation, and mitigating premature convergence to deal with problems of different types.

@&#CONCLUSIONS@&#
This paper proposes an improved GSA by using memory strategy with each personal best fitness history found so far to accelerate convergence speed and chaotic perturbation operator to enhance global convergence performance. We first investigate IGSA's convergence conditions by applying the discrete time-invariant linear system theory, and then provide a proof of global convergence based on the sufficient conditions on convergence of stochastic search algorithms. The analysis confirms that IGSA not only can converge in an expected value sense, but can guarantee global convergence with the probability 1. Next, the sensitivity analysis of parameters of IGSA with respect to parameters β and w is performed, and reasonable parameter values are obtained. Finally, the comparative experiments are performed on a set of benchmark functions to evaluate the performance of the proposed IGSA compared to other heuristic optimization algorithms and peer GSA algorithms. The results show that IGSA is comparable with or even better than other optimization methods given in this paper in finding the optimal solutions, and also show that IGSA achieved remarkable improvement over the original GSA algorithm.One possible direction for future study is to apply IGSA to constrained optimization and multi-objective optimization problems. Besides, effective memory strategy, other chaotic operator, different mass function, and different law of motion, etc., may implicate other improved GSA approaches. How to develop some other operators to propose or improve physics-inspired optimization algorithms is a significant and novel research work. Moreover, it is necessary to understand the underlying theoretical foundations of these GSAs by further studying their mathematical models and obtain theoretical analysis, so as to reveal the nature of how GSAs function.