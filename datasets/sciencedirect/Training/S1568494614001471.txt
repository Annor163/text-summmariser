@&#MAIN-TITLE@&#
Double recurrent interaction V1–V2–V4 based neural architecture for color natural scene boundary detection and surface perception

@&#HIGHLIGHTS@&#
Bio-inspired neural architecture for natural scene boundary detection.Double feedback among V1, V2 and V4 cortical areas and chromatic diffusion.Results quantified using F-measure from the Berkeley segmentation benchmark.Parallel implementations on GPU: CUDA(R) and Matlab(R).Neural architecture performance and results compatible with real applications.

@&#KEYPHRASES@&#
Boundary detection,Neural networks,Color image processing,Bio-inspired models,GPU,CUDA,

@&#ABSTRACT@&#
In this paper, a new neural model for bio-inspired processing of color images, called dPREEN (double recurrent Perceptual boundaRy dEtection Neural) model, is presented. The dPREEN model includes a double feedback among V1, V2 and V4 cortical areas, simple and double color opponent processes, orientation filtering using Gabor kernels, surround suppression in complex cells, top-down and bottom-up information fusion and chromatic diffusion, to generate contours of perceptual significance in color natural scenes. The outputs of the model are a boundary map of the scene and surface perception images. This paper incorporates a comparative analysis of the proposed model against two other contour extraction methods in the Berkeley Segmentation Dataset and Benchmark. The analysis shows favorable results to the dPREEN model. Additionally, this paper describes two parallel implementations of the model for its execution on Graphics Processing Units.

@&#INTRODUCTION@&#
Understanding a visual scene requires the ability to recognize objects and their location in the image. Two fundamental steps for object recognition are image boundary detection and segmentation process. Object recognition is simplified if the extracted contours have perceptual significance, since they correspond to object's boundaries with human meaning. The perceptual significant boundary extraction has become one of the most active research areas in neuroscience. The ways of accomplishing this objective can be divided into two groups: (1) not biologically motivated methods: graph-based methods [1], probabilistic multi-scale models [2], watersheed-based [3], tensor voting-based [4], reversible jump Markov chain Monte Carlo [5], deformable contour methods [6]; and (2) bio-inspired models: biologically motivated neural models with a behavior similar to the human visual system [7–26]. The work presented in this paper is included within this second research line.In [27] we proposed a bio-inspired architecture for color-texture identification corresponding to the color extension of the BCS/FCS system [11,23]. We presented a Color BCS system for processing signals from three channels, two opponent chromatic channels and a luminance one, combined with a two-channel FCS system used for diffusing the processed chromatic channels. On the basis of this work, we later proposed a color neural model for natural boundary detection, called PREEN (Perceptual boundaRy dEtection Neural) model [28]. The PREEN model incorporated processes related to V1–V2 recurrence and surround-suppression, competitive and cooperative filtering. These published works were underpinned by comparisons with other relevant methods, always achieving better results in the comparison tests performed.In the present paper, we build on top of our previous work, PREEN [28], to propose a new model called dPREEN – double recurrent PREEN architecture – by including:•A double feedback (a new V4 TD-BU interaction).Six opponent channels, four chromatic and two achromatic, emerged from the opponent transformations of the RGB color image. R+G−, G+R−, B+Y−, Y+B− and achromatic channels ON and OFF. Unlike previous PREEN model, opponencies G+R−, B+Y− and OFF are calculated following an opponency competitive equation.A double opponency as diffusion process input, versus the simple opponency employed in the previous model. Double opponency is more appropriate for performing diffusion processes since the second opponency highly homogenizes the inside of the scene regions.Four diffusion stages. These stages are required for V4 feedback, since it is fed with the diffusion contours from the four chromatic channels. These signals determine the boundaries of the enhanced regions (surface perception) and they are fused with the output of the simple cells stage in order to improve the bottom-up contours.A competition among orientations to obtain higher precisions in contour orientation, this allows to extract the most significant perceptual natural scene boundaries. The previous model did not consider the inhibition among orientations. This effect will be analyzed down below in this paper.Two parallel implementations of dPREEN using GPU technology. The first implementation is based on MathWorks Matlab®, while the second is based on Nvidia CUDA® language.The test simulations included in this work use the Berkeley Segmentation Dataset and Benchmark (http://www.eecs.berkeley.edu/Research/Projects/CS/vision/bsds/). Both BSDS300 and BSDS500 image databases have been used. These databases are aimed to provide an empirical basis for research on image segmentation and boundary detection. The BSDS300 database was the former database in the Berkeley benchmark [29]. This dataset contains 12,000 manual segmentations performed by 30 humans over 300 color and grayscale images of size 481×321 pixels. The database is divided into two image groups: 200 train images and 100 test images. The BSDS500 database is an extended version of the BSDS300, and it includes 200 new images. The original 300 images are used for training and the new 200 images are used for testing.The obtained results have been quantified with the boundary-based measure, F-value, which computes the precision and recall from the contours extracted and compares them to the human segmented images, which are taken as the ground truth.The F-value, commonly utilized in comparative analysis [2,4,5,9,29,34], is the harmonic mean of precision (the fraction of true positives) and recall (the fraction of ground-truth boundary pixels detected), at the optimal detector threshold. Depending on the relative cost between these measures, the F-value is expressed according to Eq. (1)[34], where P stands for precision, R for recall and α is the relative cost. For the tests performed using dPREEN we chose a relative cost α=0.5, which is a common value along the benchmarks and boundary detection studies [2,4,29,34](1)F=PRαR+(1−α)PThe main contributions presented in this paper are: the use of color features in the neural perceptual dynamics from the extraction of natural boundaries (color opponent channels, double opponencies, chromatic diffusion, chromatic contours fusion, etc.), the incorporation of evidenced recurrences in the early vision (V1–V2–V4) and related surround suppression processes observed in the 80% of the orientation selective cells, and the proposal of a new model of the competitive and cooperative processes in the color boundary detection process and the parallel implementations of dPREEN using GPU technology. The output of dPREEN architecture corresponds to the scene boundary map and the surface perception images.

@&#CONCLUSIONS@&#
This work presents a new model for extracting contours with perceptual significance and surface perception from color natural images. The proposed architecture is called dPREEN and it has been developed on the basis of previous works [28] and is inspired on the color opponent processes and the evidenced feedbacks located in V1, V2, and V4 visual areas of the Human Visual System. The dPREEN model also includes orientation filtering, surround suppression, competition among orientations and positions, and cooperation through bipole profile fields. In comparison with a previous work which only included one feedback [28] (F-value=0.61), the present paper shows than double feedback offers better contour detection (F-value=0.65 and 0.66) and, hence, it can be derived that diffusion contours heighten good contours and reduce weak contours and noise.The proposed architecture has been compared against two contour detectors, Felzenszwalb and McAllester's min-cover method [45] and Martin et al.’s Pb algorithm [46]. In order to perform the comparisons, the 100 test images from the Berkeley image dataset were used. Achieved results show better extraction capabilities of dPREEN versus these two other methods. The biologically inspired dPREEN model generates accurate contours closer to those extracted by humans, enhancing contour extraction with high perceptual significance and weakening remainder contours.In contrast to the rest of proposals in the best positions of the Berkeley benchmark ranking, dPREEN is a bio-inspired color image segmentation model reproducing the behavior of the human visual system up to the V4 area. Our model offers not only boundary information in all the orientations and scales, but also surface perception, which provides region pseudo-segmentation in an inherent way to the architecture.An important advantage of the dPREEN model is that it can be implemented over parallel hardware to exploit its inherent data-parallel processing. In this paper, we described two different approaches for the execution of dPREEN over GPUs. These massively parallel processors proved to deliver very good performance executing our architecture. In the fastest CUDA implementation, we managed to process images of size 481×321 px of the Berkeley dataset in just 1.28seconds. Using this kind of hardware, the proposed bio-inspired neural model delivers results in a processing time compatible with real applications.The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.