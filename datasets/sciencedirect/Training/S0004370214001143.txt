@&#MAIN-TITLE@&#
Eliciting good teaching from humans for machine learners

@&#HIGHLIGHTS@&#
We aim to improve Interactive Machine Learning by influencing the human teacher.We propose Teaching Guidance: instructions for teachers, to improve their input.Teaching Guidance is derived from optimal or heuristic teaching algorithms.We performed experiments to compare human teaching with and without teaching guidance.We found that Teaching Guidance substantially improves the data provided by teachers.

@&#KEYPHRASES@&#
Algorithmic teaching,Interactive machine learning,

@&#ABSTRACT@&#
We propose using computational teaching algorithms to improve human teaching for machine learners. We investigate example sequences produced naturally by human teachers and find that humans often do not spontaneously generate optimal teaching sequences for arbitrary machine learners. To elicit better teaching, we propose giving humans teaching guidance, which are instructions on how to teach, derived from computational teaching algorithms or heuristics. We present experimental results demonstrating that teaching guidance substantially improves human teaching in three different problem domains. This provides promising evidence that human intelligence and flexibility can be leveraged to achieve better sample efficiency when input data to a learning system comes from a human teacher.

@&#INTRODUCTION@&#
We are interested in the interactive Machine Learning (ML) scenario of a human training an agent to perform a classification task by showing examples. A diverse set of ML applications take input data directly from a human who is not a ML expert (e.g. document classification, user preference modeling, robot programming by demonstration). In these applications it is essential that ML algorithms require a minimal amount of data, as providing it can be a cumbersome process for the human. To this end, ML research has produced a range of methods that adapt conventional learners to improve their sample efficiency in learning (e.g. Active Learning or Semi-supervised Learning). The main idea that we explore in this article is to improve the teacher, rather than the learner, in trying to achieve this objective.A helpful teacher can significantly improve the learning rate of a ML algorithm, as shown in the field of Algorithmic Teaching [3,29,15]. This field studies the teaching problem, that is, producing a set of labeled examples based on a known target concept. The goal is to find efficient algorithms that can teach with as few examples as possible. Oftentimes this is much smaller than the number of randomly, or even actively, chosen examples needed to learn a concept [2,15]. In other cases, a concept that is not PAC learnable under arbitrary distributions, may become learnable with a helpful teacher [10].To illustrate the potential of good teaching, consider a canonical example from Dasgupta [9] (illustrated in Fig. 1). The learning problem is to find a threshold that separates two classes in 1-D space, from observed examples. A simple consistent learner achieves this by placing the threshold between the rightmost negative example and the leftmost positive example. In this setting an active learner11Active Learning is a paradigm in which the learner chooses the instance that will be labeled by the teacher. Label requests made by the learner are called queries.achieves logarithmic advantage over random sampling, by always querying the unlabeled sample closest to the estimated boundary. However, a good teacher could directly provide the two examples closest to the true decision boundary, to achieve the smallest possible error rate.Given the significant potential of good teaching we pose two questions:•How well do humans naturally teach machine learners?Can we influence humans to teach more optimally?In particular we are interested in non-expert humans who might not fully understand the inner workings of the learner they are teaching. Human teaching is largely optimized for human learning, and therefore is not expected to be naturally optimal for arbitrary machine learners. However, we believe that human teachers have the capacity to adapt for the needs of a specific learner. We propose to achieve this with teaching guidance.Teaching guidance is intended to directly guide the teacher through instructions on how to teach. We propose grounding such instructions in computational solutions to the teaching problem at hand. In this article, we present a series of experiments that explore the use of computational solutions to different teaching problems, for guiding human teachers. Our experiments demonstrate that humans are not spontaneously as good as computational teachers that are tailored for the specific learner, and that teaching guidance improves their example sequences across all of our problem domains.Teaching guidance is a set of instructions given to human teachers, with the goal of influencing their choice of examples towards those that are most informative for a particular learner. Teaching guidance is specific to a learner; however, it is independent of the particular concept that is being taught to the learner. The objective of teaching guidance is to improve upon natural teaching by human teachers.The approach proposed in this article is to construct teaching instructions based on computational solutions to the teaching problem at hand. These solutions can be in the form of either an algorithm or a heuristic. Algorithms can have guaranteed optimality bounds; however, they are often not as amenable to be used as teaching guidance. Although heuristics may not guarantee optimality, they are often easier to understand and use for everyday people. In the rest of this section we describe these two types of computational solutions to the teaching problem and discuss how they can be translated into teaching guidance.The first type of teaching guidance involves explaining an optimal teaching algorithm to a human teacher. A teaching algorithm produces a sequence of labeled examplesτcconsistent with a known target concept c from the concept classC. Formally, a concept is a function that assigns a label to all points in the state space, i.e. a separation of the state space. A concept class is a set of concepts, often with a compact representation.The objective of the teacher is to allow the learner to uniquely identify the correct target concept. A concept is uniquely identified when it is the only concept inCthat is consistent with a provided data set. The optimal teaching problem is to achieve unique identification with as few examples as possible. We refer to a shortest sequence of examples that uniquely identifies a target concept as an optimal teaching sequence for that concept. Note that more than one such sequences might exist. We denote the length of an optimal teaching sequence as|τc⁎|=minτ∈Tc⁡|τ|whereTcis the set of example sequences that uniquely identify c. An algorithm that produces a teaching sequence of length|τc⁎|for every conceptc∈Cis referred to as an optimal teaching algorithm for the concept classC.Characterizing the teachability of concepts is a central problem in Algorithmic Teaching, and many teachability metrics have been proposed. The most popular metric is the Teaching Dimension[15], which quantifies teachability of a concept class by the number of examples required to optimally teach the hardest-to-teach concept in the class:TD(C)=maxc∈C⁡(|τc⁎|)The teaching dimension of a particular concept c with respect to the concept classCisTD(c,C)=|τc⁎|.Finding an optimal teaching sequence for an arbitrary concept is NP-hard, by reduction to the minimum set cover problem [15]. However, polynomial time algorithms have been proposed for certain concept classes such as conjunctions, monotone decision lists, orthogonal rectangles and monotone K-term DNFs, among others. These algorithms cleverly exploit the compact (polynomial-size) representation of concepts and instances, to avoid enumerating all possible example sequences.For a large set of practical learning problems, there is no known optimal teaching algorithm. For these problems one can devise approximately optimal algorithms, which are sub-optimal algorithms whose solutions differ from optimal ones within provable bounds. One of the well-known approximate algorithms for the set cover problem is one that greedily selects the set with highest cover at every step. For a teaching algorithm, this can be interpreted as greedily choosing an example that reduces the version space the most, i.e. that rules out the most concepts. In problems where the version space cannot be enumerated, a greedy teaching algorithm could select the example that increases the learner's performance (e.g. accuracy) the most.Although both optimal and approximately-optimal teaching algorithms could potentially serve as teaching guidance, generally, approximately-optimal algorithms are not feasible. The greedy algorithm described above requires the ability to simulate and evaluate the learner, as well as, the ability to sort all possible examples in terms of how much they would improve the learner when presented. As will be discussed in Section 2.2, heuristic algorithms are more suitable for teaching guidance in problems where no optimal teaching algorithms are known.The operation of an optimal teaching algorithm is often intuitive to an educated viewer; however, getting everyday people to use the algorithm when they are providing examples to a machine can still be challenging. In the following, we present the optimal teaching algorithm for conjunctions and discuss how it can be used as teaching guidance.A conjunction is a list of feature values that must all be true, for a sample to be labeled as positive. Features in the conjunction are referred to as relevant, while all the other dimensions of the sample space are irrelevant features. We focus on the general set of conjunctions with binary features, which can have either a feature or its negation in the conjunction (rather than monotone conjunctions which do not allow negations).Consider the concept classCnof conjunctions over n binary variables. The teaching dimension of a conceptcrwith respect to this concept class isTD(cr,Cn)=min⁡(n+1,r+2), where r is the number of relevant variables forcr[15]. The algorithm that produces an optimal teaching sequence of this size is outlined in Algorithm 1. The first two positives examples chosen by the first two steps of the algorithm prove to the learner that all changed features are irrelevant.22Note that ifr=nthen all features are relevant and there is only one positive example, thus|τcr⁎|=n+1.The negative examples chosen by the loop in the algorithm show the learner that the feature changed in each iteration is relevant, since the negative example differs from a known positive example by only one feature.In our experiments, the teaching guidance provided to humans for teaching a conjunction is a step-by-step strategy based on this algorithm. Some terms such as positive/negative example or relevant/irrelevant features need to be replaced or explained in such guidance. A domain specific example of guidance for teaching conjunctions will be seen in Experiment 1 (Section 3.3).The second type of teaching guidance involves explaining a teaching heuristic to a human teacher. Many practical learning problems do not have known efficient optimal teaching algorithms, and the approximately optimal alternatives are intractable for human teachers. For these problems we propose using teaching heuristics that approximate the informativeness of an example for the learner. These heuristics aim to capture the intuition of an optimal teacher. A computational teacher can use this heuristic to rank all possible examples and greedily present the best example at each step. Although there are no optimality guarantees for these teachers, we expect they would be better than a random teacher. We also expect that, when the heuristic is described to human teachers as a way for selecting examples, it will lead to better teaching examples than those humans give naturally.One of the main assumptions for computational heuristic teachers is that the set of all possible examples,Sc, is finite. The teaching heuristic is therefore a means of ordering or ranking these examples in terms of their informativeness. We first consider teaching heuristics that can be used as teaching guidance in such problems where the teacher selects examples from a finite set. Later, we extend the idea of heuristic teaching guidance to problems that involve generating samples, rather than selecting them from a pool.Teaching by selecting examples involves ranking examples in terms of their informativeness for the learner. For instance, in the illustrative problem of teaching a threshold in 1-D (Fig. 1), a useful heuristic would be the distance to the nearest example from the opposite class. This heuristic indeed identifies the two examples closest to the threshold as most informative.MacGregor [27] proposed two teaching heuristics. The fast-match heuristic evaluates each example in terms of the degree that it improves the goodness-of-fit between current and true models.33Note that this is equivalent to the approximately optimal greedy algorithm discussed in Section 2.1, and it is intractable for human teachers.MacGregor observed that this heuristic favors examples that are similar to both categories, while placing prototypical, pure-case examples lower in the ranking. Based on this observation he proposed the close-all heuristic, which ranks examples based on their distance to the decision boundary, as in our illustrative example above. While the fast-match heuristic is impractical as teaching guidance, the close-all heuristic gives an intuitive description of useful examples for a binary discriminative learner. Thus our experiments involving heuristic teaching guidance use this heuristic, referred to as the borderline heuristic.As an example, we consider a simple binary Nearest Neighbor (NN) classifier. A NN classifier stores all labeled examplesSτ={(xi,yi)}i=1|τ|provided by the teacher. It assigns a label to a new sample x from the state spaceXas the label of the most similar example inSτ, using a similarity function d overX, i.e. the label of x is predicted asyj, wherej=argmini=1..|τ|d(xi,x). The borderline heuristic is appropriate for this learner, since the ideal operation of a binary NN classifier requires that for every unlabeled sample, the nearest labeled example is in the same class.In this problem setting, we define the borderline heuristic ash(xi,yi)=minj=1..|Sc|⁡d(xi,xj)I(yi,yj)whereI(yi,yj)is 1 ifyi≠yj, and infinity otherwise. A computational teacher for this problem can rank examples(xi,yi)∈Scbased onh(xi,yi), and present them to the learner in increasing order. Pseudo-code for this algorithm is given in Algorithm 2.Describing this heuristic to human teachers requires giving them an understanding of borderline examples. A domain specific example of such heuristic teaching guidance is given in Experiment 3 (Section 3.5) for the problem of teaching a binary NN classifier. We note that the optimal teaching algorithm for conjunctions explained earlier in Section 2.1.1 is also consistent with the borderline heuristic, since it provides the negative examples that are closest to being positive (i.e. different by a single property). Therefore we hypothesize that the same heuristic teaching guidance will be effective for teaching conjunctions. In Experiment 2 (Section 3.4), we provide the heuristic version of the algorithmic teaching guidance considered in Experiment 1 (Section 3.3), for the problem of teaching conjunctions.For some problems there is no existing set of examples (Sc) from which the teacher can choose examples. Instead, the teacher needs to generate examples to be provided to the learner. For instance, a gesture recognition system can be trained by demonstrating gestures and labeling them. Ideally, a computational teacher in this setting can directly generate examples subject to a teaching heuristic. This requires the teacher to have an explicit model of the target concept. For example, given a target linear classifier, the teacher can directly generate examples that are close to the decision boundary.Alternatively, the teaching problem can be converted to the setting where the teacher selects examples from a finite set (Section 2.2.1) by first generating an example setScand then using a teaching heuristic to select examples, as discussed previously. This approach requires a computational teacher to have the ability to generateScby drawing samplesxifromXand assigning their correct labelsyi.We note that the intuition behind a teaching heuristic remains the same in both settings. A heuristic that describes properties of informative examples can be used both for choosing examples from a set and for generating new examples from scratch. Therefore in our experiments we reuse the teaching guidance based on the borderline heuristic, in a problem that involves generating examples to teach a binary NN classifier. The domain specific example of this type of teaching guidance is given in Experiment 4 (Section 3.6).

@&#CONCLUSIONS@&#
Our paper demonstrates that humans do not naturally provide the best possible examples when they teach an arbitrary machine learner. We proposed teaching guidance as a mechanism to influence human teaching towards being more useful for the learner. We discussed how the nature of such guidance changes based on the problem type, and demonstrated its utility in three different domains. Across all of our experiments, teaching guidance helped people achieve better teaching performance.