@&#MAIN-TITLE@&#
Disassociation for electronic health record privacy

@&#HIGHLIGHTS@&#
Diagnosis codes in Electronic Health Records (EHR) may re-identify patients.Existing works are limited in their privacy and utility specification model.Disassociation can preserve privacy by carefully partitioning records.We propose a novel algorithm for guaranteeing data utility and privacy.Experiments demonstrate the effectiveness of our algorithm.

@&#KEYPHRASES@&#
Privacy,Electronic health records,Disassociation,Diagnosis codes,

@&#ABSTRACT@&#
The dissemination of Electronic Health Record (EHR) data, beyond the originating healthcare institutions, can enable large-scale, low-cost medical studies that have the potential to improve public health. Thus, funding bodies, such as the National Institutes of Health (NIH) in the U.S., encourage or require the dissemination of EHR data, and a growing number of innovative medical investigations are being performed using such data. However, simply disseminating EHR data, after removing identifying information, may risk privacy, as patients can still be linked with their record, based on diagnosis codes. This paper proposes the first approach that prevents this type of data linkage using disassociation, an operation that transforms records by splitting them into carefully selected subsets. Our approach preserves privacy with significantly lower data utility loss than existing methods and does not require data owners to specify diagnosis codes that may lead to identity disclosure, as these methods do. Consequently, it can be employed when data need to be shared broadly and be used in studies, beyond the intended ones. Through extensive experiments using EHR data, we demonstrate that our method can construct data that are highly useful for supporting various types of clinical case count studies and general medical analysis tasks.

@&#INTRODUCTION@&#
Healthcare data are increasingly collected in various forms, including Electronic Health Records (EHR), medical imaging databases, disease registries, and clinical trials. Disseminating these data has the potential of offering better healthcare quality at lower costs, while improving public health. For instance, large amounts of healthcare data are becoming publicly accessible at no cost, through open data platforms [4], in an attempt to promote accountability, entrepreneurship, and economic growth ($100 billion are estimated to be generated annually across the US health-care system [11]). At the same time, sharing EHR data can greatly reduce research costs (e.g., there is no need for recruiting patients) and allow large-scale, complex medical studies. Thus, the National Institutes of Health (NIH) calls for increasing the reuse of EHR data [7], and several medical analytic tasks, ranging from building predictive data mining models [8] to genomic studies [14], are being performed using such data.Sharing EHR data is highly beneficial but must be performed in a way that preserves patient and institutional privacy. In fact, there are several data sharing policies and regulations that govern the sharing of patient-specific data, such as the HIPAA privacy rule [47], in the U.S., the Anonymization Code [6], in the U.K., and the Data Protection Directive [3], in the European Union. In addition, funding bodies emphasize the need for privacy-preserving healthcare data sharing. For instance, the NIH requires data involved in all NIH-funded Genome-Wide Association Studies (GWAS) to be deposited into a biorepository, for broad dissemination [44], while safeguarding privacy [1]. Alarmingly, however, a large number of privacy breaches, related to healthcare data, still occur. For example, 627 privacy breaches, which affect more than 500 and up to 4.9M individuals each, are reported from 2010 to July 2013 by the U.S. Department of Health & Human Services [15].One of the main privacy threats when sharing EHR data is identity disclosure (also referred to as re-identification), which involves the association of an identified patient with their record in the published data. Identity disclosure may occur even when data are de-identified (i.e., they are devoid of identifying information). This is because publicly available datasets, such as voter registration lists, contain identifying information and can be linked to published datasets, based on potentially identifying information, such as demographics [52], diagnosis codes [34], and lab results [9]. The focus of our work is on diagnosis codes, because: (i) they pose a high level of re-identification risk [34], and (ii) ensuring that diagnosis codes are shared in a privacy-preserving way, is challenging, due to their characteristics [55,25,28]. For example, more than 96% of 2700 patient records that are involved in an NIH-funded GWAS were shown to be uniquely re-identifiable, based on diagnosis codes, and, applying popular privacy-preserving methods, distorts the published data to the point that they lose their clinical utility [34].To perform identity disclosure, an attacker must possess three types of knowledge: (i) a patientâ€™s identity, (ii) a set of diagnosis codes, and (iii) whether a patient is included in the published dataset (research sample) [36]. Knowledge of the first two types can come in the form of background knowledge [36] or may be solicited by exploiting external data sources.1These include publicly available voter lists combined with hospital discharge summaries [50], or the identified EHR system available to the primary care environment [34].1At the same time, knowledge of the third type is obtainable through interaction with data subjects [19], or it can be inferred by applying the procedure used to create the research sample from a larger patient population, which is often described in the literature [36]. To see how identity disclosure may occur, consider the de-identified data in Fig. 1. In these data, each record corresponds to a distinct patient and contains the set of diagnosis codes that this patient is associated with. The description of the diagnosis codes in Fig. 1 is shown in Fig. 2. An attacker, who knows that a patient is diagnosed with Bipolar I disorder, single manic episode, mild (denoted with the code 296.01) and Closed dislocation of finger, unspecified part (denoted with 834.0), can associate an identified patient with the first record, denoted withr1, in the data of Fig. 1, as the set of codes{296.01,834.0}appears in no other record. Note that the attacker cannot perform this association, based on knowledge of either 296.01 or 834.0, but can associate the identified patient withr1, if they know any other code or codes, in addition to the set of codes{296.01,834.0}. Notice also that, in this work, we consider ICD-9 codes,2http://www.cdc.gov/nchs/data/icd9/icdguide10.pdf.2following [36,35]. However, our approach can be applied to other standardized codes, such as Common Procedure Terminology (CPT) codes.

@&#CONCLUSIONS@&#
Ensuring that diagnosis codes cannot be used in identity disclosure attacks is necessary but challenging, particularly when data need to be shared broadly and to support a range of medical analytic tasks that may not be determined prior to data dissemination. To this end, we proposed a novel, disassociation-based approach that enforceskm-anonymity with low information loss. Our approach does not require data owners to specify diagnosis codes, as existing methods do, and takes into account analytic tasks that published data are intended for. Extensive experiments using EHR data show that our approach can produce data that permit various types of clinical case count studies and general medical analysis tasks to be performed accurately.