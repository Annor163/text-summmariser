@&#MAIN-TITLE@&#
State estimation of nonlinear dynamic systems using weighted variance-based adaptive particle swarm optimization

@&#HIGHLIGHTS@&#
A new heuristic filter of adaptive particle swarm optimization (APSO) is developed.The swarm size is adaptively tuned based on the weighted variance of the particles.The proposed APSO is compared with a variety of heuristic optimization algorithms.Performance of the proposed filter is compared with variety of existing filters.APSO is applicable for state estimation of every nonlinear/non-Gaussian system.

@&#KEYPHRASES@&#
Heuristic filter,Adaptive population size,Particle swarm optimization,Differential evolution,

@&#ABSTRACT@&#
New heuristic filters are proposed for state estimation of nonlinear dynamic systems based on particle swarm optimization (PSO) and differential evolution (DE). The methodology converts state estimation problem into dynamic optimization to find the best estimate recursively. In the proposed strategy the particle number is adaptively set based on the weighted variance of the particles. To have a filter with minimal parameter settings, PSO with exponential distribution (PSO-E) is selected in conjunction with jDE to self-adapt the other control parameters. The performance of the proposed adaptive evolutionary algorithms i.e. adaptive PSO-E, adaptive DE and adaptive jDE is studied through a comparative study on a suite of well-known uni- and multi-modal benchmark functions. The results indicate an improved performance of the adaptive algorithms relative to original simple versions. Further, the performance of the proposed heuristic filters generally called adaptive particle swarm filters (APSF) or adaptive differential evolution filters (ADEF) are evaluated using different linear (nonlinear)/Gaussian (non-Gaussian) test systems. Comparison of the results to those of the extended Kalman filter, unscented Kalman filter, and particle filter indicate that the adopted strategy fulfills the essential requirements of accuracy for nonlinear state estimation.

@&#INTRODUCTION@&#
Successful control of many closed loop dynamic systems relies on exact and complete knowledge of the system states. Lack of proper information in the feedback signals results in ineffective control law. Unfortunately, for many physical systems not all states are measurable due to restrictions on the utilized sensors such as cost and/or weight. Therefore, state estimation or in other words filtering out the bad information from the available noise-corrupted measurements is an essential task for all controlled dynamic systems. On-line state estimation enhances system security, data accuracy and reduces the cost of the measurement package due to requiring less measurement sensors.State estimation problem has been in the center of attention for many years. Dynamic system state estimation has been usually formulated as a weighted least squares problem. This widespread method is considered as a batch estimator that uses the complete history of measurements to estimate the unknown states. In comparison to the batch strategies, recursive filters receive and process measurements sequentially and as such are regarded more important and useful. Every progressive step of a recursive filter consists of two stages: prediction and data assimilation. Prediction propagates the system states from a time step to the next one ahead, while data assimilation is employed to refine the predicted states utilizing the new measurements. Fortunately, there exist various schemes in the literature for state estimation of nonlinear dynamic systems. Although, Extended Kalman filter (EKF) [1] is the simplest and the most utilized nonlinear filter applied to different systems, it suffers from two important drawbacks. First, it is prone to divergence as it is based on linearization of nonlinear dynamics and measurement functions. Second, it is only suitable for systems with Gaussian noise models. Other nonlinear filters have been presented to remedy these weaknesses. Unscented Kalman filter (UKF) [2], the next well-known nonlinear filter, originates from the idea that approximating a Gaussian distribution is easier than approximating an arbitrary nonlinear function. In this regard, UKF removes the need for linearization, while the assumption of Gaussian distribution is still kept. Particle filter (PF) family [3] is suggested to complement UKF and to cope with its shortcomings. In contrast to the EKF, as an analytical approach for state estimation, UKF and PF are both sampling approaches to this aim. However, there exists a fundamental difference between the two latter. UKF is based on a deterministic sampling methodology, while samples are stochastically generated in the PF. Therefore, PF can be considered as a member of the newly defined class of heuristic filters.In the simplest form of the PF, the particles are initially propagated through the dynamic model and are next weighted according to the likelihood function that determines how closely the particles match the measurements. Subsequently, at the re-sampling step, those that best match the measurements are multiplied and the rest are discarded. Although due to novelty of the PF, its members have received considerable attention in lots of different scientific fields, there are still some outstanding difficulties with this method such as sample impoverishment due to lack of population diversity.As a characteristic of any sample based method, PF estimation performance depends on the number of utilized particles as well. Increasing the number of particles increases the estimation accuracy to some extent, but at the same time results in a dramatic increase in run time, which is not desirable especially for on-line applications. A more detailed review of literature reveals that heuristic optimization methods such as particle swarm optimization (PSO), genetic algorithm (GA), ant colony optimization (ACO), etc. have been used to enhance the performance of the PF. Zhong et al. [4] and Hao et al. [5] have tried using ACO to optimize the re-sampling step in order to avoid the sample impoverishment problem. In [5], the optimization allows the particles to move closer to their local highest posterior density function, thus producing a better estimation results. Zhang et al. [6] have combined PSO with PF before re-sampling stage in order to increase diversity of the particles. In [6], particles’ weights in PF are considered as the fitness values in PSO, and the particles set which is formed after re-sampling step is operated by PSO. This process caused the particles to move to a point with a higher fitness value. Yu et al. [7] have incorporated ACO into PF in order to optimize the sampling process. Unlike the standard PF, re-sampling is not required in their scheme.As it already mentioned, state estimation can be thought as a stochastic dynamic optimization problem as well. In this context, various kinds of powerful heuristic optimization methods can be utilized to estimate the states of nonlinear dynamic systems.Parpinelli et al. [8] has compared three swarm intelligence algorithms of bacterial foraging optimization (BFO), PSO and artificial bee colony (ABC) for the optimization of hard engineering problems. It is shown that PSO results in the best balance between quality of solution and number of function evaluations.According to [9], an appropriate initial population size plays a key role in the effectiveness and efficiency in the performance of the evolutionary algorithms such as PSO, differential evolution (DE), etc. Therefore, a new method is presented in the current study that allows setting the number of needed particles to search the state space adaptively. In this paper, the sample size is determined based on the weighted variance of the participating particles.Leong and Yen [10] have presented a method to tune the swarm size based on the rank and density of the population. The presented algorithm has many parameters to set in advance that makes its utilization complicated. Sun et al. [11] have also proposed a scheme to improve the performance of PSO based on time-variant particle population function, which makes the population decrease gradually in order to reduce the computational cost, and produce random particles at periodical phases to avoid trapping in the local optima.Coelho and de Oliveira [12] have introduced two usual ideas of population resizing in GA to the PSO. The first idea controls the birth and death of the particles at every generation; while the second one increases the swarm size at initial iterations to enhance the exploration and decreases it subsequently to improve the exploitation capability. Applying these ideas to some benchmark functions has shown the superiority of the first idea. Lei [13] has presented two dynamic population size improvements for the standard PSO as well. The first method starts with a small number of particles and increases the number of particles iteratively, while the second algorithm starts with a large number of particles and decreases the swarm size gradually. Both methods result in reducing computational time, but the second method is more successful in converging to the global optimum. Sample size is adaptively determined in [14] based on a complicated combination of the density and the average Hamming distance of particles.In following, application of heuristic optimization methods for state estimation will be reviewed briefly. Nobahari et al. [15], Heris and Khaloozadeh [16] and Naka et al. [17] have proposed state estimators based on the traditional ACO algorithm and in a framework similar to the PF. Xu et al. [18] have used PSO to search the optimal or near optimal parameters that produce desirable steady state filters such as α–β filter and α–β–γ filter. Jeong and Park [19] have used a hybrid PSO (HPSO) for a cluster of PC systems to minimize the difference between measured and calculated state variables in order to estimate the system states. Zhang et al. [20] have proposed utilizing the Gaussian PSO to approximate the optimal solution of the target-tracking problem, and utilized a re-diversification scheme to enhance the diversity of the particle set.In addition to the PSO, the differential evolution (DE) has also recently received increased interest from evolutionary computation community. Both techniques have shown a great promise in various fields of real world applications such as air traffic control, composite structures [21], target tracking [20], parameter estimation [22], neural networks training [23], etc. Some researchers tried to integrate the advantages of both algorithms to improve the efficiency of them. Wan et al. [24] have designed a mutation operator based on the DE and employed it to update the personal and the global best positions in Gaussian PSO. Ali et al. [25] have presented a good review of hybridization of PSO and DE, and proposed a new hybrid version of DE and PSO. Nevertheless, comparison of these two methods indicates that DE generally outperforms the PSO [26,27].Success of DE strongly depends on the proper selection of its parameters including amplification factor (F), crossover rate (CR), population size (N) and the mutation strategy. While the original DE keeps the three control parameters of F, CR, and N fixed during the optimization process, ample work is done to adapt/self-adapt the control parameters [28–30]. The effect of population size on the solution quality and the needed computational burden for DE technique is investigated in [31]. It is demonstrated that control parameters are problem dependent and the sample size is a key factor in the algorithm performance in addition to the F and CR. Reviewing the literature shows that like PSO, there are not much instances available to adapt the sample size in DE. Yang et al. [32] have proposed the population adaptation as a remedy for enhancing the DE performance especially in stagnation conditions or low diversity situations. The sum Euclidean distances between individuals of the population is considered as the diversity measure, and when it does not change in some successive generations, the population should be regenerated to increase the diversity. Sarker et al. [33] has tried to detect the best combination of control parameters during the evolutionary process for the optimization problem. It is demonstrated that the most successful combination depends on the problem. It has been highlighted that an appropriate population size is critical to both run-time efficiency and optimization effectiveness [34]. The population resizing in [35] is according to the instantaneous solution searching status. If the best fitness of the population at every generation improves or does not change, the exploration ability needs to strengthen. Otherwise, it should decrease. Slowik and Bialko [23] followed a similar scheme to change the sample size dynamically. Teo [34] discriminated between the parameter adaptation and self-adaptation, and attempted to self-adapt the population size parameter in addition to crossover and mutation rates. Brest et al. [36,37] proposed an algorithm to decrease the population size during the evolutionary process accompanied with self-adapting the parameters F and CR from jDE algorithm. The population size is not allowed to increase in their algorithm at all. Subsequently, Zamuda et al. [38] added the idea of multiple mutation to the previous research to improve the DE performance for real parameter optimization. Zhu et al. [39] have changed the sample size through some steps according to the solution-searching status. When the individuals are trapped into a local optimum, the number of particles increases, and when the better solutions can be found, extra particles are removed.This paper is organized as follows. The state estimation problem is introduced in Section 2. The evolutionary algorithms of PSO and DE are described in Section 3. The main idea of dynamic population size evolutionary algorithms as well as the pertinent heuristic filters are elaborated in Section 4. Section 5 provides the results of the numerical simulation of the proposed optimization and estimation algorithms for well-known benchmark problems in related fields. Finally, Section 6 concludes the article and introduces some recommendations for future work.The problem of nonlinear/non-Gaussian state estimation is to estimate the state vector of a nonlinear dynamic system sequentially using a sequence of noise-polluted measurements. In order to analyze and make inferences about the dynamic system, at least two models are required. First, the system or dynamic model that describes the evolution of the state with time. Second, the measurement model that relates noisy measurements to the state. If either the system or the measurement model is nonlinear, the posterior probability density function will be non-Gaussian. In this paper, the target state evolves according to the following discrete-time stochastic model:(1)xk=fk−1(xk−1,wk−1)where fk–1 is a known, possibly nonlinear function of the state xk–1, wk–1 is the process noise sequence, and index k is the time step. Process noise represents every mis-modeling effect or unforeseen disturbance in the dynamic model. The measurements are related to the state vector via the measurement equation as below,(2)zk=hk(xk,vk)where hkis a known, possibly nonlinear function of the states xkand vkis the measurement noise sequence. The noise sequences wk−1 and vkare usually assumed to be white, with known probability density functions (pdfs) and mutually independent. The initial target state is assumed to have also a known pdf p(x0) and to be independent of the aforementioned noise sequences [40].Therefore, the objective of nonlinear filtering is to estimate xksequentially from the available measurement zk. It is notable that the time step k is different from iteration/generation number in the optimization algorithm. Indeed, at every time step k the available measurement zkassists the optimization algorithm to provide the estimation xkdenoted byxˆk.The PSO is a population-based optimization method initially proposed by Eberhart and Kennedy in 1995 [41]. The population is referred to as a swarm and denotes to the number of particles in the PSO algorithm. Each particle represents an n-dimensional potential solution (xi) to the optimization task and so stands as a candidate solution. During the optimization process, each particle moves to a new position according to a new velocity that includes its previous velocity (Vi) and a moving vector according to the past best solution (xbesti) and global best (gbest) solution. The best solution is then kept; and so each particle accelerates in the directions of not only the local solution but also the global best position. If a particle discovers a new probable solution, other particles will move closer to it in order to explore the region. Each particle i in the swarm is updated at every iteration j according to the aforementioned attributes as follows:(3)Vi,dj+1=wjVi,dj+c1r1j[xbesti,dj−xi,dj]+c2r2j[gbestdj−xi,dj]For all d∈1, .., n. Where n is the problem dimension, Vi,dis the velocity at the dth dimension of the ith particle, c1 and c2 denote the acceleration coefficients, r1 and r2 are elements from two uniform random sequences in the range (0,1), and w is the inertia weight that balances the global and local search abilities. Some researches such as [21,42] have proposed a variation scheme for acceleration coefficients and/or inertia weight to improve the PSO performance. A simple and successful method is suggested by Shi et al. [42] that decreases w linearly from predefined wmax to wmin with iteration as below(4)wj=wmax−wmax−wminitermaxjwhere itermax is the maximum iteration number. The new position of every particle is then calculated as follows [41]:(5)xij+1=xij+Vij+1Most PSO algorithms use uniform probability distribution to generate random numbers. However, influence of different probability distributions, especially Gaussian and Cauchy probability distributions, on PSO performance have been studied, in order to improve the performance of the standard PSO. Investigation of different combinations of Gaussian and Cauchy distribution functions in [43] shows that the combination of Gaussian distribution in the cognitive part and the Cauchy distribution in the social part yields a better performance than other combinations and even the standard GA. Kennedy [44] developed an almost parameter-free PSO, named Bare Bones PSO (BBPSO), which consists of sampling new particle positions selected from a Gaussian distribution with the mean given by the average of the global and local best positions and the standard deviation given by the absolute difference between the global best and the personal best positions. Krohling [45] developed another parameter-free PSO algorithm based on the Gaussian distribution named GPSO to improve the convergence ability of the PSO without the necessity of tuning the PSO parameters. Subsequently, Krohling and Coelho [46] presented a new version of parameter-free PSO using the exponential probability distribution (PSO-E) aiming at improvement in performance.One disadvantage of popular search algorithm of PSO is that it can be easily trapped into some local optimal solutions due to lack of population diversity and premature convergence. Dong and Cooper [47] utilized crossover and mutation operations to cope with such anomalies in complex multimodal optimizations when the diversity of particles is less than a predefined threshold. It is notable that they adopted the average distance around the swarm center as the diversity measure. Thangaraj et al. [48] also aiding similar diversity criterion, utilized a beta probability distribution for the mutation. Andrews [49] reviewed some mutation strategies and showed that designing mutation operators depends on the nature of the optimization problem.Differential evolution (DE) is introduced by Storn and Price in 1995 [50] as a simple yet powerful method for global optimization. The working procedure of this algorithm consists of three main steps: mutation, crossover, and selection. After setting the algorithm parameters, the initial population is randomly generated and evaluated using the provided fitness function. Next, the following process is executed as long as the stopping criterion is not fulfilled; for every particle (xi) in the population, a mutant vector (vi) is generated using the weighted difference of the parent solution. Then, a trial vector (offspring ui) is created in the crossover step using the crossover rate probability. Afterwards, a greedy selection scheme is performed to select the individual with the best fitness value in the child–parent competition. When ui,dexceeds the search range after the mutation, ui,dis mapped to be legal as follows [32](6)ui,d=(Fb−a+ui,d)/Fifui,d<a(Fa−b+ui,d)/Fifui,d>bwhere a and b are the lower and the upper bounds of the search space, respectively.Success of DE strongly depends on the proper selection of parameters including amplification factor (F), crossover rate (CR), population size (N) and the mutation strategy. Various mutation strategies have been proposed in order to enhance the performance of the DE [51]. Some researchers have tried to adapt/self-adapt the control parameters [28–30]. jDE [28] is one of the most famous ones which adapts the F and CR for each particle.The population size is one of the key factors that affects the search performance of the population-based algorithms in seeking the optimal solution. A larger population size can guarantee a higher chance of reaching the optimal solution, while a limited sample size results in being trapped in local optima. However, it is obvious that a bigger sample size increases the computational time as well. Therefore, it seems appropriate to let the algorithm decide about the required number of particles need to participate in the optimization process. This way the algorithm itself can remove or add some particles to the current population to increase the search performance. As mentioned before in the introduction section, rank, density and the average distance have been the main quantities for changing the sample size dynamically in the PSO, and the average distance has been the only significant parameter for calculating the diversity of individuals and the main criterion for the population size adaptation in DE. In this paper, the weighted variance is proposed as the key variable to adapt the swarm/population size. The weighted variance is defined as below,(7)σω2=trace∑i=1Nωi(xi−xmin)(xi−xmin)T∑i=1Nωiwhere(8)ωi=1−riN2and riis the rank of ith particle in the population sorted in an ascending order, N is the number of particles at current generation. xmin is the position of the global best particle (PSO) or the best individual in the generation (DE), and trace indicates the matrix trace. It is clear that calculating particles weights (ωi) needs evaluation of the cost function (f). σωcan be counted as a diversity measure of good particles, since it considers the fitness level of particles as well as the simple diversity of population. A large value of σωindicates poor diversity of good particles. Thus, exploration ability of the population needs to be strengthened. Inversely the exploitation should increase in the case of small values of σω.σωis not calculated at every iteration/generation. The predefined maximum number of iterations/generations is proposed to be divided into R periods with the equal length T, so that the maximum generation number will be itermax=R×T, R is an integer number. Similar time division has been also proposed by [14] for swarm size adaptation scheme, but there is a fundamental difference between the present research and [14]. Chen et al. [14] have proved that mean population distance is not a suitable measure for the swarm diversity at first, and thus proposed a complicated combination of average hamming distance and population density named entropy to change the swarm size. In contrast, a simple and different quantity, namely the weighted variance, is proposed in the current study to adapt the population size. In addition, [14] forces the algorithm to start with the maximum number of particles, while the present algorithm commences with a rational population size initially. This initial size is usually chosen between [Nmin, Nmax]=[n+1, 10n]. The boundary values are inspired from the unscented Kalman filtering method [2,52]. Moreover, the proposed algorithm needs fewer parameters for execution in comparison to [14], which makes it more desirable.At the end of every period, σωis calculated and if diversity of good particles has increased relative to the previous period, there is an essential need to strengthen global search. Thus, the number of particles will increase. In this case, the following relation is suggested here to adjust the population size for the future cycle:(9)Np+1=σωpσωp−'12/3Npwhere subscript “p” denotes pth period and p=2,…,R.Xalso returns the nearest smaller integer part of real value X. It is emphasized again that this relation is an empirical relation obtained from investigation of various mathematical functions not an optimal choice. It can be simply substituted by a fixed percentage of the maximum allowed population size (Nmax) or a fraction of the swarm size at the last period. New particles are added stochastically with the standard deviation of σωto the population.On the other hand, if σωdecreases at the end of two sequential periods, the number of particles is more than sufficient. As extra particles do not increase the accuracy of process; and slow its time performance, so some percentage of particles will be discarded. It is obvious that the worst particles are omitted. Similar to enlarging population scheme, an empirical relation is suggested here to determine the swarm size in the next period as below,(10)Np+1=σωpσωp−'11/3NpIt is worth mentioning that sample size is never allowed to be less than a lower limit of Nmin.Since shrinking of good particles may be due to being trapped into a local optimum, simple variance of particles is checked at first (σx). If σxis less than a predefined threshold, a jump in the swarm occurs to escape from the local minimum. σxis calculated as below,(11)σx2=trace∑i=1N(xi−xavg)(xi−xavg)TWhere xavg is the center of population. It is notable that the threshold variance is considered here as a fixed ratio (η) of the search space bounds:(12)σthr=η(b−a)Inspiring the roughening step in PF [53], the jump/mutation strategy to perturb the individuals is suggested as follows:(13)xi,dj=xi,dj+Δxdj(d=1,...,n)Δxdj∼N(0,KMdjN−1/n)Δxdjis a zero-mean random variable (usually Gaussian). K is a scalar tuning parameter,Mdjcontains the maximum difference between the particle elements in dimension d;(14)Mdj=maxi,mxi,dj−xm,djwhere i and m are particle numbers. K is a tuning parameter that specifies the amount of jitter that is added to each particle at iteration j.If σωchanges insignificantly at the end of two sequential periods, there is no need to change the sample size.Alfi [22] has proposed mean square error of system state as the cost function of the optimization problem to estimate system parameters. However, in the current study, the cost function is proposed based on maximization of particles likelihood or equivalently minimization of measurement residuals. After trying out several options for the cost function, the following form is selected as the best candidate. The proposed form gives the cost function for particle i at iteration j and time step k as below,(15)fij(k)=zk−hk(xˆij(k))2=zk−hk(xˆij(k))Tzk−hk(xˆij(k))As reflected in the proposed cost function, an adaptive evolutionary algorithm provides an estimation of system states as soon as the measurement vector becomes available. At every measurement time step, the best particle in the population (global best in PSO) is considered as the estimation of state vector. Since particles naturally move toward minimization of the residuals, there is no need to do any re-sampling to avoid degeneracy, as is usually the problem faced by PF or hybrid algorithms of PF/PSO, PF/ACO, etc. This latter part is another important distinguishable factor of this work as compared with other available researches such as [15–17].Tables 1 and 2show the corresponding pseudo code for the proposed dynamic population size PSO- and adaptive DE-based filters, respectively. In these tables, ɛ is a small number like 0.05 in order to relax the limitation of no exact change of weighted variance in the third option of the proposed adaptive sample size scheme.To evaluate the performance of the proposed idea, adaptive evolutionary algorithms are applied to a suite of well-known benchmark functions given in Table 3previously introduced by [44,46]. The suite contains a diverse set of problems including unimodal (f1) as well as shifted (f3)/rotated (f5) multimodal functions with a few/many local minima in the search space (f2,f4,f6,f7).The aim of this section is detecting the most accurate parameter-free PSO algorithm. To this aim, bare bones PSO (BBPSO), Gaussian PSO (GPSO), and PSO with exponential distribution (PSO-E) are selected and compared with standard PSO (SPSO) and decreasing inertial weight PSO (DPSO).For the standard PSO, the parameters are set as c1=c2=2 and w=0.7. For the DPSO, maximum and minimum inertial weights are assumed 0.9 and 0.4, respectively. The other algorithms are encoded as suggested by pertinent references [44–46]. The whole algorithms are investigated for two dimensions of n=10 and n=30, and the population size is set to 30 and 100, respectively. Each experiment is run 30 times and terminated when the maximum number of iterations (itermax=1000) has been reached.The obtained results including the best, the worst, mean and the standard deviation (std.) of different optimization algorithms averaged over 30 independent runs, are relatively similar for both dimensions of n=10 and n=30, so just for brevity the results of n=10 are presented in Figs. 1 and 2and summarized in Table 4. This table shows that three algorithms of SPSO, DPSO and PSO-E are more accurate. Since one of the initial aims is utilizing an almost parameter-free algorithm, the PSO-E is selected as the base optimization method in this study.The proposed dynamic swarm size idea is performed on the PSO-E algorithm called APSO-E hereafter, and then the jump steps at needed times are added in order to prevent premature convergence and named JAPSO-E.Fig. 3shows the effect of R on APSO-E performance. This experiment is performed for three values of R=5, 10, and 20. It is seen that R=20 results in more accurate optimization. Fig. 4also depicts the effect of η on the adaptive optimization algorithm. It is shown that smaller values of η is more suitable for multimodal functions with huge number of local minima like f4 and f8, while an average value of 0.01 is suitable for the others. It is worth mentioning that in the current study Nmax=10n is considered and inspiring simplex UKF Nmin=n+1 is assumed, and the constant K in jump steps is considered equal to 0.1.Table 5summarizes the obtained results of APSO-E and JAPSO-E for the 10-dimensional benchmark functions and compares them with those of PSO-E, DE, artificial bee colony (ABC) [54], and ant colony optimization for continuous domains (ACOR) [55]. The parameters of these optimization algorithms are tuned according to the pertinent recommendations made in [28,54,55], respectively. The main emphasize in the comparison is on the mean fitness function. It is seen that ACORsignificantly outperforms the other three algorithms in optimizing unimodal function of f1, while except the ABC for f3 the APSO and especially JAPSO-E are superior for multimodal optimization problems.Figs. 5 and 6depict the mean fitness functions of f1 through f7 for n=30. These figures clearly show that although the idea of dynamic population size and jump steps have improved the performance of PSO-E, DE outperforms PSO-E, improved versions of PSO, ABC and ACOR for high dimensional optimization problems. Therefore, the idea of dynamic population size utilizing the weighted variance of population is applied to the DE algorithm, and a new adaptive DE (ADE) is developed especially for high dimensions.There are different options to select for the mutation strategy in DE, but the classic DE/rand/1/bin algorithm is employed here. As recommended by [28,50], F=0.5 and CR=0.9 are set in this study. Most of the adaptive/self-adaptive algorithms such as jDE have been also developed based on the classic DE/rand/1/bin. The dynamic population size-based DE known as ADE in this study has utilized the idea of self-adapting F and CR for each particle in jDE and developed the new algorithm of adaptive jDE (AjDE). Table 6compares the performance of 10-dimensional DE, ADE, jDE, and AjDE. This table generally shows the superiority of the adaptive versions to the simple ones for multimodal functions, but there is no dramatically better choice between adaptive versions for the whole benchmark functions. Fig. 7also shows the mean function evaluations (FEs) for three algorithms of DE, ADE, and AjDE. These algorithms have similar number of FEs except for f5 that the FEs of AjDE is about twice of the other algorithms’. Figs. 8 and 9depict the mean fitness function values for the 30-dimesional benchmark functions, and Fig. 10illustrates the mean function evaluations in the case of n=30. Unlike 10-dimensional study, this figure clearly shows that except for f5, AjDE has fewer FEs than ADE and DE.Comparison of three new adaptive algorithms i.e. APSO-E, ADE, and AjDE is summarized for n=10 in Table 7. Figs. 11 and 12show the mean population size utilized for these algorithms. ADE is the best optimization algorithm for f1 and f7, while the APSO-E is the most accurate option in the cases of f2, f4, and f5. AjDE has better result for f3, and results in similar performance with ADE in optimization of f6 The only important observation about the average sample sizes is that ADE needs much less population for shifted rotated Ackley function (f5).Figs. 13 and 14show the mean fitness functions for n=30 and Figs. 15 and 16depict the mean population size of adaptive algorithms. As expected, these Figures verify that ADE and AjDE are more accurate optimization strategies for high dimensional problems. It is also shown that APSO-E needs more swarm size for the whole functions in the case of high dimensional optimization problems.Previous subsections proved the general superiority of APSO-E, ADE and AjDE over the simple pertinent versions. In this section, the mentioned adaptive evolutionary algorithms are utilized for nonlinear/non-Gaussian state estimation problem. These heuristic filters are applied to four well-known test systems consist of different combinations of Gaussian (non-Gaussian)/linear (non-linear) systems described in Table 8taken from [4,6,53]. It is worth mentioning that the measurement function is non-stationary for the second one, while it is stationary for the others.The effectiveness of the proposed adaptive evolutionary algorithms is evaluated against the test systems and their results are compared with those of EKF, UKF, and PF in the terms of root mean square error (RMSE). The RMSE analysis is defined as follows:(16)RMSE=∑k=1NV(Mitrue−Miest)2NV1/2where, NV, number of values;Mitrue, true value of measurement k,Miest, estimated value of measurement k.Note that the RMSE provides an average error for all estimated values. It is obvious that the smallest RMSE refers to the best and most accurate estimation scheme. Table 9summarizes the obtained results for the test systems averaged over 15 independent runs.As shown in this table and depicted in box plots of Figs. 17–24, the mean RMSE of APSO-E is much smaller than EKF, UKF, PF, ADE and AjDE for estimation test functions except the third one that is a linear/Gaussian system. Since the Kalman filter (KF) is an optimal minimum variance estimator for linear and Gaussian systems, the obtained results for KF in this outperforms the others. Nevertheless, the results of APSO-E is not far less accurate than those of the Kalman filter.It is notable that unlike the Kalman filter family, adaptive evolutionary-based filters are independent of noise distributions. They have resulted in more accurate nonlinear state estimation as compared with the standard PF and the Kalman filter family.

@&#CONCLUSIONS@&#
This paper has proposed novel adaptive heuristic filters to solve the state estimation problem for nonlinear/non-Gaussian dynamic systems. Conversion of state estimation in to a stochastic nonlinear optimization problem is the core idea behind the development of the new filters. Population size plays a key role in the performance evaluation of most available population-based optimization methods such as particle swarm optimization (PSO), differential evolution (DE) algorithms as well as the sample based particle filter (PF). In this respect, the current work has proposed a new method to determine the required population size adaptively, at every time step. Variation of the weighted-variance of particles is the cornerstone of this new approach. The proposed evolutionary algorithms are initially evaluated against a suit of well-known benchmark functions, and their effectiveness in improving the simple evolutionary algorithms is proven. Subsequently, the associated heuristic filters are developed and applied to a set of test systems including linear (nonlinear)/Gaussian (non-Gaussian) systems and the results are compared with those of the extended Kalman filter (EKF), unscented Kalman filter (UKF) and PF in terms of the root mean square error (RMSE) criterion. It is demonstrated that the proposed heuristic filters excel from these well-known methods in the terms of estimation accuracy. Future research involves application of multiple mutation concept to the proposed ADE based filter for further performance enhancement.