@&#MAIN-TITLE@&#
Evaluation of detection and discrimination ability of peripheral vision on notification information based on large displays

@&#HIGHLIGHTS@&#
We propose an array of glyphs as a notification system using peripheral vision.The system behaviors were controlled by size, rhythm, frequency, and phase shift.The size of the glyph arrays affects detectability more than location or shape.Phase shift is better than frequency as a coding dimension for discriminability.The results are worst-case lower bounds for real applications.

@&#KEYPHRASES@&#
Notification information,Detection,Discrimination,Large display,Peripheral vision,

@&#ABSTRACT@&#
Large displays enable users to perform several tasks simultaneously. Under such circumstances, notification information provided through the concept of ambient displays plays a vital role in assisting users to switch among tasks. This paper presents the experimental results of a notification system design in the peripheral region of large displays. The aim is to provide guidance for notification information design by investigating detection and discrimination performance of human observers when visual notification information is presented away from the foveal region and viewed using peripheral vision. The proposed notification system was designed using an array of glyphs. Each glyph is a small gray square with a fixed size of 60×60 pixels. By changing the gray levels of adjacent glyphs dynamically, a glyph array presents a particular dynamic pattern. The experiments involved testing factors that comprised the visual angle, size and shape of glyph arrays, frequency of temporal modulation, phase shift of each pattern, and number of stimuli. The results show that glyph arrays are detected accurately if they are larger, even at wide viewing angles, and that the number of glyphs in a glyph array affects the performance more than the shapes of glyph arrays do. Furthermore, the discrimination performance is higher when both the frequency and phase are manipulated simultaneously (multidimensional design), compared with the case when each of these dimensions is varied separately (single-dimensional design). When the number of stimuli is set at 8, for example, users can maintain an accuracy rate of 70% for the multidimensional design, whereas the accuracy rate is only approximately 60% for the single-dimensional design.

@&#INTRODUCTION@&#
Large high-resolution displays are leading the growth in the global display market. NPD Display Search indicated that in January 2005, the average desktop monitor size for personal workstations was 16.4″ and by 2013, the corresponding average measurement was 20.9″. For the professional graphics market, the largest market share by size in 2013 was 27″ displays, and curved displays with a size of up to 40″ are currently available. A larger display provides more space to present information, thereby supporting various tasks for users simultaneously and in a more detailed view than on a smartphone or tablet [1].In addition to the trend of increased display size, many people currently enjoy maintaining awareness of information such as news, the weather, entertainment, and other personally relevant information when interacting with a computer [2,3] or a smart device [4,5]. Such information is typically provided by a notification system that transmits current and timely information efficiently and effectively without causing unwanted distraction to a user’s ongoing tasks [6]. A notification system can be used for several purposes including (1) receiving news [7], (2) interacting with social groups [8,9], and (3) delivering information through notifications such as time-sensitive data [10]. According to the priority of the information being conveyed, the display of notification systems can be divided into two categories: ambient and alert. An ambient display shows low-priority information and requires divided human attention, whereas an alert display shows prioritized information demanding focused attention [10].Notification information can be transmitted differently through human modalities such as visual, auditory, tactile, olfactory, and multimodal [11–14]. Arroyo et al. [15] compared five notification modalities—heat, smell, sound, vibration, and light—from the aspect of disruption. The results indicated no considerable differences among the five transmission methods regarding disruption. Warnock et al. [14] compared eight delivery methods categorized into four groups: visual, auditory, tactile, and olfactory. The visual group comprised text, pictograms, and abstract visual stimuli; the auditory group comprised voice, earcons, and auditory icons; the tactile group comprised tactons; and the olfactory group comprised aromacons regarding disruptiveness and effectiveness. The results indicated that the users demonstrated considerably higher accurate responses to the notification via visual and audio transmissions than they did via tactile and olfactory transmissions. Regarding the response time, the users had the shortest response time to the visual cues and the longest response time to the olfactory cue. From the aspect of disruption, tactile and olfactory transmissions introduced more disruption to the users than visual and auditory cues did.These studies have suggested that, compared with other human modalities, visual and auditory cues provide optimal transmission to users regarding disruption, response time, and accuracy. However, auditory cues are designed to prompt immediate action, whereas visual cues are not designed for vigilant types of tasks [16]. This suggests that auditory cues are more suitable for alert displays and visual cues are more suitable for ambient displays.Because this study focused on nonemergent information types, the information transmission was designed on the basis of visual cues. Different forms of visual cues, such as text, patterns, pictograms, shapes, and colors, can be used for transmitting information. The transmission method can be either static or dynamic and the presentation of the transmitted information can be abstract or concrete.Numerous peripheral awareness systems have been created to support abstract presentation [17–20]. Tarasewich et al. [11] combined color and position on three LEDs and conveyed 27 messages with high recognition accuracy for users. One of the peripheral awareness systems, ambient media, comprised physical devices, such as money color [21], breakaway [22], and daylight displays [23], that were placed in a person’s environment. Hung and Ostovari [24] designed an assistive interface in which hints (e.g., changing the color of a cursor) are provided to attract a user’s attention to a notification that is initially displayed in the peripheral region outside the user’s field of view.An example of concrete presentation involves text information. Plaue and Stasko [2] compared different peripheral display configurations for text information. McCrickard et al. [25] compared three animation notification systems (i.e., blast, fade, and ticker) with no animation regarding the correct rate, hit rate, and false alarm rate. The results showed that the blast and fade animations resulted in considerably faster monitoring times than the ticker did. The hit rate for the ticker was higher than that for the fade and blast.When interacting with large displays, users generally separate the focal region from the peripheral region depending on the priorities of tasks, and they can take advantage of peripheral vision to monitor applications of lower relevance by placing them in the peripheral areas of the display [26]. Therefore, demand is increasing for using peripheral displays in maintaining awareness [3,7,27], in which users tend to glance at or use peripheral vision to view low-priority information.Anderson et al. [28] measured spatial contrast sensitivity functions at retinal locations from 0° to 55° along the nasotemporal meridian for a single eye and found that contrast sensitivity functions for peripheral vision are shaped similarly to those observed foveally, but are shifted to lower spatial frequencies. In particular, there is a clear nasotemporal asymmetry in contrast sensitivity in the far peripheral visual field. Stimuli imaged on the nasal retina are detected with higher sensitivity than those imaged on the temporal retina.Legge et al. [29] linked the spatial and temporal properties of letter recognition to reading speed for text viewed using central or peripheral vision. They found that the size of the visual span decreased from at least 10 letters in central vision to 1.7 letters at 15° eccentricity, concluding that the retinal position, exposure time, and relative position within a character string are key factors that limit letter-recognition accuracy. Chung et al. [30] compared the effects of central and peripheral vision on the spatial-frequency characteristics of letter identification, determining that the spatial frequency tuning and scaling properties for letter identification were similar between the fovea and periphery.In addition to letter-like stimuli, human peripheral vision in texture segregation and contour integration also has crucial implications in pattern and object recognition. Joffe and Scialfa [31] investigated texture segmentation as a function of eccentricity and concluded that optimal texture segregation does not peak in foveal vision but does so in the near periphery. Experimental evidence suggests that contour integration is mainly present in foveal vision [32,33]. However, recently Kuai and Yu [34] demonstrated that for contour stimuli such as circles and ellipses, which bear favorable Gestalt properties, contour integration for shape detection and discrimination was nearly constant from the fovea to up to 35° of visual periphery.The cones and rods in the human retina provide different ocular capabilities. The cones are efficient for visual acuity, visual resolution, and color recognition, and the rods are effective for motion detection. The cell density is a function of the retinal angle; where away from fovea, the retina is composed primarily of rod receptors with extremely few cones [35]. Although this may imply that human peripheral vision is sensitive to motion and is relatively ineffective for color discrimination, it is now well known that peripheral color vision is similar to foveal vision if the target is sufficiently large. Gordon and Abramov [36] measured the spectral hue and saturation functions of the nasal retina both at and 45° from the fovea. Using large and small targets in the fovea (1.5° and 5′) and periphery (6.5° and 1.5°), they found that the quality of color vision in the periphery depends crucially on stimulus size. A sufficiently large stimulus enables detecting a complete range of well-saturated hues.Notification information is widely presented using animation [2,25] because dynamic presentations obviously attract more attention than static presentations do; the efficiency of such presentations is generally evaluated according to glanceability [37] instead of studying peripheral vision directly. Research on the perception and recognition ability of peripheral vision has largely focused on static information (e.g., a fixed color or word); only a few studies have focused on the effects of dynamic information. Bartram et al. [38] reported that motion cues draw more attention than do static representations, and some motion types (e.g., traveling motions) are more distracting and irritating than other types (e.g., anchored motions). They suggested that traveling motion requires more attention because in addition to detection, a cognitive act of tracking is involved. Park and Nam [39] used card sorting skills to extract four dynamic design elements: tempo, direction, rhythm, and volume. They suggested that in the case of presenting information, complex information tends to require more design elements or coding dimensions compared with simple information. Yamada et al. [40] developed an information notification method called peripheral cognition technology. They applied the phenomenon of visual field narrowing (VFN), in which the human visual field narrows considerably during a difficult task, to design a peripheral agent. When a new message arrives, this agent appears in a peripheral visual area outside the visual scope of the primary task. Because of VFN, users may not notice the onset of this agent when they are focused on the main task. The information notification is perceived only when the attention to the main task is lowered somewhat and the phenomenon of VFN disappears, thus enabling the attention to be switched to other regions of the display.The objective of this study was to design a novel notification system for presenting nonemergent information by using the peripheral areas of a large display while minimizing the distraction and mental workload on users. In other words, by applying the concept of calm technology, users can perceive information presented on a certain part of a display by using peripheral attention to focus on it as desired [41].To prevent unexpected interruptions, current notification systems generally present notification information along the border of a display. Users generally glance briefly at the information or capture it by using their peripheral vision. However, when the display size increases, more space is potentially available to present information. This raises several questions. According to the concept of calm technology, can human eyes capture notification information by using peripheral vision when the information is presented away from the foveal region? If so, then what types of peripheral display designs can facilitate human detection and discrimination?This study performed two experiments to answer these questions. In the first experiment, detectability was measured to verify the design of the proposed notification system and to determine the parameters for the design. In the second experiment, discriminability was measured to determine the performance of the proposed design.The proposed notification system was designed using an array of glyphs. Each glyph is a small gray square with a fixed size of 60×60 pixels. The behaviors of the notification system were controlled by applying four parameters.The size of the notification system is determined according to the number of columns and rows of the array of glyphs. Four sizes in width (1, 2, 4, and 8 columns) and four sizes in length (2, 4, 8, and 16 rows) produce 16 (4×4) shapes in the proposed notification system.In the proposed design, the luminance of each glyph changes dynamically with time to attract attention. However, to prevent abrupt interruptions during the onset of information notification, the dynamic change in the luminance of a glyph is controlled by a sine wave function. A sine wave function along time is mapped to an RGB value from (0,0,0) to (255,255,255) to create a smooth gray-level transition for each glyph (Fig. 1).The tempo of the changing gray level is determined by the frequency (f) of the sine wave function. Fig. 1 illustrates an example of a sine wave function at a frequency of 1Hz.Although the luminance of each glyph changes according to the rhythm and tempo, when there is no difference between adjacent glyphs, the notification system displays a large gray rectangle with changing shades because all glyphs follow the same rhythm and tempo in the proposed design. To capture a user’s attention through only his or her peripheral vision, the dynamic interactions between adjacent glyphs should create an overall pattern that can elicit awareness. The phase-shift parameter is introduced to provide this function.The phase shift in our case is defined as the difference (expressed in degrees) between two adjacent glyphs following the same rhythm and tempo and referenced to the same time point. Givenxij(t), which represents the corresponding sinusoidal function for the glyph at the ith row and jth column of the notification system at timet, a single parameter (∅) can be used to control all vertically and horizontally adjacent glyphs, as shown in Eq. (1), and to generate an overall dynamic pattern.(1)xij(t)=sin2πft+(i+j-2)∅π180where i is the length (number of rows), j represents the width (number of columns),fis the tempo (frequency), and∅is the phase shift.Fig. 2depicts a notification system of size 2 glyphs×2 glyphs with∅=36°of change along the time axis.This experiment was conducted to determine whether peripheral vision can be used to detect dynamic patterns generated by glyph arrays presented away from the central focal area of a display. The just-noticeable difference (JND) of the phase shift (∅) was measured as a dependent variable to evaluate the design.This study recruited 10 paid participants, five females and five males, from the College of Engineering at Feng Chia University. Informed consent was obtained from all the participants prior to participation. All collected data during the experiments were depersonalized before statistical analyses were performed. The participants had at least 3years of experience using computers. The average age of the participants was 20years, with a standard deviation of 1.1years. All the participants had normal or corrected-to-normal eyesight.The viewing angles for presenting the notification information (i.e., glyph array) were tested at two levels: 25° and 45° shifts from the center of the display along the nasotemporal meridian. In Bi and Balakrishnan [42], participants interacted with a tiled display at distances of 2–2.5m; the width and height of the tiled display were 4.9 and 1.8m, respectively. They concluded that 81% of mouse events occurred within a central square area ranging from 1.4 to 3.5m wide and less than 1.2m high. They determined that in this central square area, primary tasks were performed within a width of 2.1m (3.5–1.4m=2.1m) and secondary tasks were performed outside this area. When this area is used as a baseline, the viewing angle from 2.25m (the average distance from a participant to the display) in front of the center of the tiled display to the border between the primary and secondary areas can be calculated at approximately 25°(tan−1(2.1/2)/2.25=24.99°), and the viewing angle from the same location to the border of the tiled display is nearly 47°(tan−1(4.9/2)/2.25=47.44°). Thus, in the current study, these viewing angles were used as a reference, and the presentation of the notification information was tested at both 25° and 45°.Three 23″ displays with 1920×1080 resolution and a 42-cd/m2 mean luminance (RGB=128) were placed side by side as the tiled display for this experiment. The width and height of each 23″ display were 51 and 29cm, respectively. Therefore, the total width and height of the tiled display were 153 and 29cm, respectively, and the total resolution was 5760×1080. The distance between the participants and the display was set at 70cm, and the environment luminance was controlled as 320±30lux. The tiled display was arranged in the layout shown in Fig. 3. The three 23″ displays were placed side by side on a surface, as shown in Fig.3(a); when measured at 25° in periphery, the angle between the line of sight and the front panel was 65°, and the distance was approximately 78cm. When measured at 45° in periphery, the angle between the middle display and the remaining two displays was 160° so that both the viewing distance and angle between the line of sight and the front panel were the same as those measured at 25°. With such a layout, glyph arrays of the same size at either 25° or 45° would generate the same visual angle and luminance level for a participant.Four factors were used as independent variables in this experiment and are outlined as follows:Length: the length of the glyph array at four levels; that is, 2, 4, 8, and 16 glyphs, respectively corresponding to 3.2, 6.4, 12.8, and 25.6cm on the display.Width: the width of the glyph array at four levels; that is, 1, 2, 4, and 8 glyphs, respectively corresponding to 1.6, 3.2, 6.4, and 12.8cm on the display.Frequency: the rhythm of a glyph at three levels; that is, 0.25, 0.5, and 1Hz.Viewing angle: the position of the glyph array centered at 25° and 45° from the center of the display along the nasotemporal meridian. The glyph arrays of the same width presented on the display at two viewing angles subtend the same visual angles, as shown in Fig. 3. Given a participant sitting at 70cm in front of the display, when viewed at either 25° or 45°, the visual angles corresponding to 1, 2, 4, and 8 glyphs in width are 1.0°, 2.0°, 4.0°, and 8.0° respectively. The dotted lines in Fig.3(a) and (b) represent the visual angle of the largest glyph arrays (i.e., 8.0°) and the corresponding locations on the two display layouts for two viewing angles.All the four factors were treated as within-subject factors and repeated twice for measuring the phase-shift JND. The frequency and viewing angle are block factors, and each participant interacted with six blocks (3×2) in random order. Under each block, the 16 (4×4) combinations of glyph arrays were presented to the participants in random order. There were 192 trials (4×4×3×2×2). A testing platform developed by Microsoft Visual Basic 6.0 was used to control the experiment.In each trial, the participants were presented with a glyph array of predefined size with a 0° phase shift at the beginning. For example, one trial may have involved a glyph array of size 16×2 (960×120 pixels) changing at 1Hz and viewed from 25°. At the beginning with a 0° phase shift, this glyph array is simply a large gray rectangle with changing shades following a sine wave function at 1Hz. The experiment administrator subsequently pressed the Up key to increase the phase shift by one unit. When the administrator released the Up key, the top-left glyph of the glyph array was maintained at the same gray level, and the gray levels of the remaining glyphs changed according to Eq. (1) and their corresponding positions in the glyph array. The participants were requested to answer the question “Is this pattern different from the previous one?” If a participant answered “No,” the administrator continued to increase the phase shift until the participant detected a difference. The JND was recorded in a database as a dependent variable for analysis. The participants were allowed breaks between trials to prevent fatigue.Throughout the experiment, to ensure that the participants used only peripheral vision to detect the glyph array, we explicitly instructed them to focus on the center of the tiled display where a pseudo primary task was provided (staring at a fixed dot on the display), and an eye tracker was used to monitor their eye movements. The image captured by the eye tracker was projected to another display in real time and was monitored by an experiment administrator. If it was determined that a participant did not fixate on the center of the display during the experiment, the results from the affected trials were deleted from the collected data set and the participant had to undergo the deleted trials again at the end of each block.

@&#CONCLUSIONS@&#
