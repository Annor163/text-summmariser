@&#MAIN-TITLE@&#
Three-way recommender systems based on random forests

@&#HIGHLIGHTS@&#
We propose a framework integrating three-way decision and random forests.We introduce a new recommender action to consult the user for the choice.We build a random forest to predict the probability that a user likes an item.The three-way thresholds are optimal for both the training set and the testing set.

@&#KEYPHRASES@&#
Cost sensitivity,Random forests,Recommender systems,Three-way decision,

@&#ABSTRACT@&#
Recommender systems attempt to guide users in decisions related to choosing items based on inferences about their personal opinions. Most existing systems implicitly assume the underlying classification is binary, that is, a candidate item is either recommended or not. Here we propose an alternate framework that integrates three-way decision and random forests to build recommender systems. First, we consider both misclassification cost and teacher cost. The former is paid for wrong recommender behaviors, while the latter is paid to actively consult the user for his or her preferences. With these costs, a three-way decision model is built, and rational settings for positive and negative threshold values α* and β* are computed. We next construct a random forest to compute the probability P that a user will like an item. Finally,α*,0.35em0exβ*, and P are used to determine the recommender’s behavior. The performance of the recommender is evaluated on the basis of an average cost. Experimental results on the well-known MovieLens data set show that the (α*, β*)-pair determined by three-way decision is optimal not only on the training set, but also on the testing set.

@&#INTRODUCTION@&#
Recommender systems (RSs) have been extensively studied to present items such as movies [20,21,40], music [15] to consumers. There are two main approaches to implementing RSs, memory based and model based [8]. Memory-based methods [13,51] employ the entire user-item database to generate a prediction. Model-based methods [22,41,71,72] use demographic and content information to create a model that generates recommendations. Demographic RSs [14,48] generate recommendations based on compiled user demographic profiles, whereas content-based systems [5,25,35,49] treat recommending as a user-specific classification problem and learn a classifier for the user’s likes or dislikes based on product features. Most existing RSs implicitly assume that the underlying task is one of binary classification, and so consider only two actions (recommend or not) for candidate items.In this paper, we propose a framework that integrates three-way decision and random forests to build recommender systems. Three-way decision is introduced to modify the recommender’s user output [4], that is, for a given item, to recommend, not recommend, or consult the user actively for his or her preferences. A misclassification cost is incurred for wrong recommender behaviors, including recommending movies to users who dislike them or not recommending movies to users who would like them. Teacher cost is incurred for the consultation, e.g., distributing coupons to users. Because two types of costs are considered, this approach essentially involves cost-sensitive learning [17,36,37,39,78]. There are various types of costs that can be considered [57,73]. In existing work, misclassification cost is the most widely addressed because classification is a major task of data mining (see, e.g., [28,60,77]). Test cost is often considered because data are not free (see, e.g., [58,61,69]). Delay cost is a major issue in the context of decision-theoretic rough sets [30,32,65,75]. Teacher cost is an essential consideration in active learning [6,43,54,55]. It is similar to test cost in that both “buy” data from the user. The major difference between the two lies in that test cost is incurred to obtain attribute values for data, whereas teacher cost is accrues to obtaining actual user decisions.Three-way decision [33,34,67] is a methodological extension of decision-theoretic rough sets [31,59,62,64] that deals with situations where there are three possible decisions, namely, accept, reject, and wait and see [63,73,76]. It has been widely applied to situations such as filtering of spam email [76], determining biological matrices [18] and medical decision making [42]. The starting point is often a cost matrix with misclassification and delay costs. In this work, we consider teacher cost instead of delay cost. The purpose is also to compute two thresholds α* and β*: if the probability that a user will like a movie is greater than α*, the movie is recommended., and if it is less than β*, the movie is not recommended. Otherwise, we solicit his or her inclination, at the price of paying teacher cost.To determine the recommender’s behavior, we need to formulate the probability of the user’s liking a movie. Decision-tree classification algorithms [50] are a natural approach. A decision tree describes graphically the decisions to be made, the events that may occur, and the outcomes associated with combinations of decisions and events [11]. However, a single decision tree can only take advantage of limited information of users and items, and hence no suggestion is generated for many new users and new items. To overcome this limitation, we employ a random forest instead for this purpose. A random forest is a collection of decision trees [10], and different trees in the forest may include different information, therefore the missing of prediction seldom happens.Our approach is depicted in Fig. 1. It is divided into three parts: (1) An optimal threshold pair (α*, β*) is computed based on the cost matrix, where α* determines the probability necessary to recommend an item and β* determines that necessary to not recommend an item. (2) The user, item, and rating information are merged to construct an aggregate decision table in which the rating information serves as the decision attribute. A random forest is then built from the aggregate training set, where each leaf is assigned a distribution of discrete ratings. The probability of each testing object is computed from the random forest. (3) Finally the RS selects an action based onP,0.35em0exα*, and β*.Experiments on the well-known MovieLens data set (http://www.movielens.org/) show that (1) the threshold pair (α*, β*) determined with three-way decision is optimal not only on the training set, but also on the testing set and (2) our three-way RS outperforms the Pawlak, variable-precision, and probabilistic two-way models in terms of average cost.The rest of the paper is organized as follows: Section 2 describes the three-way recommender problem and presents some background, including the rating system and cost-sensitive learning. An aggregate decision system is then built to mine the behavior of users on items. Section 3 discusses how to apply four rough-set models to our RSs. Section 4 constructs a random forest to predict the probability P and compute the average cost according to the three-way decision model. Section 5 presents experimental results from the MovieLens data set with the four rough-set models. How to set the threshold pair (α, β) is discussed in detail. Concluding remarks are presented in Section 6.Most existing RSs take a rating system as input, and the recommender’s accuracy is regarded as a kind of evaluation metric. Our three-way RS considers misclassification and teacher costs, and through cost-sensitive learning, we build proper classifiers to find a minimum average cost. For this purpose, the rating system is transformed into a decision system.We first revisit the definitions of information and rating systems [1,71].Definition 1An information system is a 2-tuple [71](1)S=(U,A),whereU={x1,x2,⋯,xn}is the set of all objects,A={a1,a2,⋯,am}is the set of all attributes, and aj(xi) is the value of xiwith respect to attribute ajfor i ∈ [1, n] and j ∈ [1, m].Fig. 2(a) shows an information system where U={u1, u2, u3, u4, u5} and A={Age, Gender, Occupation}. UID is the user identification, which is usually not viewed as an attribute. Another example of an information system is given by Fig. 2(b).LetU={u1,u2,⋯,un}be the set of users of a RS andV={m1,m2,⋯,ml}be the set of all possible items that can be recommended to users. Then the rating function is defined as(2)R:U×V→VR,where VRis the rating domain employed by the users to evaluate items.In this study, we consider a situation in whichVR={0,Y,N}.YandNrespectively indicate the user liked or disliked a movie, while00.35em0.8exindicates that the user did not rate it. A rating function is often stored in the database as a table with two foreign keys for space savings. For the sake of illustration, here we represent it as ann×lrating matrix.With Definitions 1 and 3, the rating system is defined as follows:Definition 4A rating system is a 5-tuple [71](3)RT=(U,A,V,B,R),where (U, A) and (V, B) are two information systems andR:U×V→VRis a rating function.Fig. 2 depicts a rating system in which Fig. 2(a) is the user table for (U, A), Fig. 2(b) is the item table for (V, B), and Fig. 2(c) is the rating table. User u1 likes movie m1 and dislikes movie m2, while u1 never rated m3.Most research in cost-sensitive learning [27,77] is an extension of machine learning approaches through the consideration of traditional misclassification cost. Hunt et al. [26] initially proposed two types of costs, (1) misclassification cost and (2) test cost. Yao [67] considered misclassification cost and delay cost. Turney [56] proposed a taxonomy of costs, including test cost, misclassification cost, delay cost, teacher cost, etc.Test cost refers to the measurement cost of determining the value of an attribute for a given object. Min et al.introduced test costs for attribute reduction [36] and built a hierarchical model for test-cost-sensitive decision systems by considering common test costs and sequential issues [38]. Zhao et al. [74] considered this attribute reduction problem for numeric data with measurement errors.Misclassification cost is that incurred as a result of classification errors. AdaCost [16] uses the cost of misclassifications to update it training distribution on successive boosting rounds. An optimal Bayes classification rule that minimizes the expected misclassification cost has been constructed for various misclassification cost functions [9]. Pazzani et al. [47] introduced a reduced cost ordering algorithm to minimize classification costs. In real applications, how to evaluate misclassification cost is a very difficult problem. In some cases, relative values are assigned to represent misclassification cost [73].Delay cost is incurred as a result of deferred decision making. Rough-set approximation or classification employs three pairwise disjoint regions that are defined by logical constructions, namely, positive, negative, and boundary regions [68]. Herbert and Yao [23,24] referred to the first two regions as representing immediate decisions and the third as containing delayed decisions.Teacher cost comes from buying decision data from the user. Recommender action on the basis of paying teacher cost forms an active learning scenario. Active learning guides the acquisition of new knowledge suitable to updating recently rated or browsed information [29,53,55]. Turney [57] used inductive concept learning to create a taxonomy of the different cost types and discussed the expected cost of classifying a new object by itself versus the cost of asking a teacher to perform this task. Both teacher cost and test cost are forms of paying for data. The difference lies in that a teacher cost is paid to obtain a decision or result, while a test cost is paid to obtain an attribute value.We next build an aggregate decision system to mine the behavior of users respect to individual items. A similar conversion has been discussed in [71]. We propose the concept of an aggregate decision system (ADS) as follows:Definition 6An ADS induced by a rating systemRT=(U,A,V,B,R)is(4)DS(RT)=(G,C,d,{Ea|a∈C∪{d},{Ia|a∈C∪{d}),whereG={(ui,mj)∈U×V|R(ui,mj)0.25em0ex≠0.25em0ex0},C=A∪B, and∀gi,j=(ui,mj)∈G,d(gi,j)=R(ui,mj).Because there may exist many identical objects in U and V, there are also many identical objects in G. We can merge these to save space and facilitate further analysis. Formally, an equivalence relation on G for the conditional attributes C can be defined as(5)IND(G,C)={(x,y)∈G2|∀a∈C,Ia(x)=Ia(y)}.The equivalence class of x ∈ G on C is(6)[x]=[x]G,C={y∈G|(x,y)∈IND(G,C)}.The partitioning of G induced by C is denoted(7)G/C={mg1,mg2,⋯,mge},where ∀mg ∈ G/C is an equivalence class,∪mg∈G/C=G, and∀(mgi,mgj)∈G/C,mgi∩mgj=⌀.Example 7Fig. 3(a) depicts an ADS with G={g1,1,g1,2,⋯,g5,4,g5,5},C={Age, Gender, Occupation, Year, Comedy, Action, Drama}, and d={R}.The equivalence class of g1, 1 is[g1,1]={g1,1,g1,2,g4,1,g4,2,g5,1,g5,2}.To test the performance of an RS, we need to divide DS(RT) into a training set and a testing set. This is done by randomly choosing a portion of DS(RT) as the training set and the remainder as the testing set. Formally, let Grand Gtbe the training set and the testing set respectively; we requireGr∩Gt=⌀andGr∪Gt=G.To facilitate the learning process, we merge the training set according to Eqs. (5)–(7). An example of a merged training set is shown in Fig. 3(b). Here the first object corresponds to3+1=4objects from the original set. Objects in the same equivalence class may have different decisions. Therefore, we use L instead of R to indicate the decision. HereL(mg1)=(3Y,1N), indicating that there are three objects for decisionYand one for decisionN.For a merged object mg, the probability P that a user with the given demographic information will like a movie with the specified item information is denoted by P(mg), which can easily be computed from L(mg). For example,L(mg1)=(3Y,1N), and thereforeP(mg1)=3/(3+1)=0.75. Formally,(8)P(mg)=|{y∈mg|R(y)=Y}|/|mg|.In this section, we discuss how to apply four rough-set models to our RSs. The models determine the action of the recommender according to the threshold pair (α, β) and the probability P that a user will like a movie.The Pawlak rough-set model [44] approximates a set by a pair of lower and upper approximations. The model has been used widely in instances such as attribute reduction [69], attribute–value reduction [45] and rule synthesis [7].We apply the Pawlak model to the RS. For a set X⊆G, we construct the lower and upper approximations according to Eqs. (5) and (6):(9)apr̲(X)={x∈G|[x]⊆X},apr¯(X)={x∈G|[x]∩X0.25em0ex≠0.25em0ex⌀}.The nonempty set G is divided into three disjoint regions: (1) the lower approximation defines the positive region POS(X), (2) the difference between the upper and lower approximations defines the boundary region BND(X), and (3) the complement of the upper approximation defines the negative region NEG(X). According to the lower and upper approximations, the positive, negative, and boundary regions of X are defined as [46](10)POS(X)=apr̲(X),NEG(X)=apr¯(X),BND(X)=apr¯(X)−apr̲(X).Furthermore, Pawlak and Skowron [45] suggested a rough membership function to redefine the two approximations, defined by(11)P(X|[x])=|X∩[x]|/|[x]|,where | · | indicates the cardinal number of objects in a set and P(X|[x]) is the conditional probability of the classification.From the rough membership function, Pawlak approximations can be equivalently defined as follows:(12)apr̲(X)={x∈G|P(X|[x])=1},apr¯(X)={x∈G|P(X|[x])>0}.Based on Eq. (12), the Pawlak positive, negative, and boundary regions are(13)POS(X)={x∈G|P(X|[x])=1},NEG(X)={x∈G|P(X|[x])=0},BND(X)={x∈G|0<P(X|[x])<1}.In Fig. 4(a), Pawlak’s classical model takes no action in the boundary region. In this study, we consult the user actively to obtain his or her preference. For the Pawlak rough-set model as applied to our RS, the three regions’ actions are shown in Table 1.The variable-precision rough-set (VPRS) model [3,19,31,79] extends Pawlak rough sets to incorporate probabilistic information, substituting α for 1 and β for 0 in Eq. (12). The condition is 0 ≤ β < α ≤ 1. The lower and upper approximations in VPRS are, respectively(14)apr̲(X)={x∈G|P(X|[x])≥α},apr¯(X)={x∈G|P(X|[x]<β}.Similarly, the positive, boundary, and negative regions with probabilistic variable precision can be defined as follows (see also Fig. 4(b)):(15)POS(X)={x∈G|P(X|[x])≥α},NEG(X)={x∈G|P(X|[x])≤β},BND(X)={x∈G|β<P(X|[x])<α}.If we setα+β=1and α > 0.5, this becomes symmetric VPRS. Withα+β0.25em0ex≠0.25em0ex1, it is asymmetric VPRS.The probabilistic two-way decision model [2] is based on inclusion of each equivalence class in either the positive or the negative region, as shown in Fig. 4(c). This model allows one to make useful decisions for all objects, i.e., all the objects are in a decision region.If we setγ=α=β, Eq. (15) can be rewritten as(16)POS(X)={x∈G|P(X|[x])≥γ},NEG(X)={x∈G|P(X|[x])<γ}.This is a special case of the VPRS model withα=β. Ifγ=0, we simply recommend every movie. Ifγ=1, we only recommend those movies with full probabilityP(X|[x])=1.We apply the existing three-way decision model [66,67,70,76] to build our RSs. Our approach includes three parts: (1) two preferences and three actions are defined for our RSs; (2) a cost matrix is constructed according to the misclassification and teacher costs; (3) the threshold pair (α*, β*) is computed based on the cost matrix. The three-way decision model is illustrated in Fig. 4(d).With respect to a type of movie to be approximated, let X be a collection of movies liked by users andX˜=V−Xbe a collection of movies disliked by users. The recommended movies can be divided into the standard three regions, namely, positive (POS), boundary (BND), and negative (NEG).The three recommender actions are given byR={rP,rB,rN}based on the three regions: rPdenotes “recommend” if a movie is classified into POS, rBdenotes “not recommend” if a movie is classified into BND, and rNdenotes “pay teacher cost” if a movie is classified into NEG.The cost matrix for the actions in the different states is given by a3×2matrix, shown in Table 2. If the movie belongs to X, thenλPP,0.35em0exλBP, and λNP denote the costs incurred for taking actionsrP,0.35em0exrB, and rN, respectively. If the movie belongs toX˜, thenλPN,0.35em0exλBN, and λNN are the costs incurred for taking these actions.The expected costs associated with the different actions for a movie can be expressed as(17)TP=λPPP(X|[x])+λPNP(X˜|[x]),TB=λBPP(X|[x])+λBNP(X˜|[x]),TN=λNPP(X|[x])+λNNP(X˜|[x]).The Bayesian decision procedure leads to the following minimum-risk decision rules:(P)If TP≤ TBand TP≤ TN, then decide x ∈ POS;If TB≤ TPand TB≤ TN, decide x ∈ BND;If TN≤ TPand TN≤ TB, decide x ∈ NEG.To simplify the rules, some constraints should be added so that each movie is put into only one region. The first condition is(18)P(X|[x])+P(X˜|[x])=1.The cost of classifying a movie x in X into the positive region POS is no more than the cost of classifying x into the boundary region BND. Both costs are strictly less than the cost of classifying x into the negative region NEG. The reverse cost order is used for classifying a movie not in X. The second condition is(19)λPP≤λBP<λNP,λNN≤λBN<λPN.We consider a special kind of cost function. The third condition is(20)λNP−λBPλBN−λNN>λBN−λNNλPN−λBN.The final condition is(21)0≤β*<α*≤1.With these four conditions, we have the simplified decision rules as follows:(P1)If P(X|[x]) ≥ α*, decide x ∈ POS;If β* < P(X|[x]) < α*, decide x ∈ BND;If P(X|[x]) ≤ β*, decide x ∈ NEG.Here α* and β* are computed as follows:(22)α*=λPN−λBN(λPN−λBN)+(λBP−λPP),β*=λBN−λNN(λBN−λNN)+(λNP−λBP).Our RS takes different recommender actions with respect to objects with the same P when we use different probabilistic rough set models. We use the aggregate decision system depicted in Fig. 3 to illustrate this situation.Grand Gtare the training and the testing set, respectively. For any x ∈ Grin Fig. 3(b) and any y ∈ Gtin Fig. 3(c), there are three steps to determine the recommender action. First, the probability P(y) is predicted. Before using the random-forest model for prediction, we match the conditional attributes between x and y. If the conditional attributes are the same, L(y) is assigned as the class attribute of x. Second, the probability P(y) is computed according to L(y) and Eq. (8). The probabilities are 0.75, 0.5, 0.75, and 1 for the four test objects illustrated in Fig. 3(c), respectively. Third, our RS makes different decisions, shown in Table 3, based on P(y) and different probabilistic rough set models.LetMT1={v∈V|Drama(v)=1}. That is, MT1 is the type for dramatic movies. Similarly, letMT2={v∈V|Comedy(v)=1}andMT3={v∈V|(Drama(v)=1)∧(Action(v)=1)∧(Comedy(v)=1)}. LetUG1={u∈U|(Age(u)=25)∧(Gender(u)=F)∧(Occupation(u)=technician)}. That is, UG1 is the group of “(Age(u)=25)∧(Gender(u)=F)∧(Occupation(u)=technician)” users. We take the following actions based on the different models:1.With the Pawlak model, our RS pays teacher cost to UG1 for watching MT1 and MT2 but recommends MT3 to UG1.With the VPRS model, we assume thatα=0.8andβ=0.6. Our RS pays teacher cost to UG1 for watching MT1, does not recommend MT2, and recommends MT3 to UG1.With the probabilistic two-way decision model, we assume thatγ=0.6. Our RS recommends MT1 and MT3 to UG1, and does not recommend MT2.With the three-way decision model, the optimal thresholds areα*=0.6andβ*=0.5. Our RS recommends MT1 and MT3 to UG1 but pays teacher cost to UG1 for watching MT2.LetUG2={u∈U|(Age(u)=25)∧(Gender(u)=F)∧(Occupation(u)=writer)}. That is, UG2 is the group of “(Age(u)=25)∧(Gender(u)=F)∧(Occupation(u)=writer)” users. For any ug2 ∈ UG2, if ug2 consults our RS, there is no matching object in Fig. 3(b) on the basis of matching conditional attributes. We can build a random forest to deal with this situation, as discussed in the next section.In the training set, P can be computed directly. However, in the testing set it should be predicted. In this section, we construct a random forest to predict P and compute the average cost according to the three-way decision model.In this subsection, the prediction of P based on a random forest is described in detail. First, random decision trees are built based on the aggregate training set. These trees are combined together to form a random forest. Second, each random decision tree produces a predictive probability for each testing object. By averaging these predicted probabilities, we obtain the P of participation in the three-way decision.Decision-tree learners build a tree by recursively partitioning training data. In the process of building a random decision tree, demographic and content information serve as conditional attributes and probability information serves as the decision attribute. For example, in Fig. 3(b) the conditional attributes are {Age, Gender, Occupation, Year, Comedy, Action, Drama} and the decision attribute is {L}. The probability P is easily computed according to L and Eq. (8). Each root-to-leaf path of the tree represents a rule for the probability that one group of users watches one type of movie. The process of building an unpruned random decision tree is described in Algorithm 1.Algorithm 1Build an unpruned random decision treeInput: training set(Gr), condition attributes(C), probability(P)Output: An unpruned decision treeMethod: buildUnprunedRandomTree1: if (C=∅0.35em0exaor0.35em0exGr=∅) then2:return NULL;3: end if4:Pg=P(Gr);5: currentNode=new buildUnprunedRandomTree(Gr,C,Pg);6: found=lseafalse;7: for (a∈Cis randomly selected) do8:C=C−{a};9:if (informationGain(a)>0) then10: found=ueatrue;11: break;12:end if13: end for14: if (tanotfound) then15: currentNode.children=NULL;16:return currentNode;17: end if18: currentNode.splittingAttribute=a;19:|va|=the number of attribute values of a;20: currentNode.children=new buildUnprunedRandomTree[|va|];21: for (i=1 to|va|) do22:Gri={x∈Gr|a(x)=i};23:Pg=P(Gri);24: currentNode.children[i]=buildUnprunedRandomTree(Gri,C,Pg);25: end for26: return currentNode;There are four steps to build the random decision tree:Step 1.The probability Pgof the training set Gris computed based on Eq. (8) (line 4).The current node is built based on the training set Gr, conditional attributes C, and probability Pg(line 5).An attribute a is randomly selected from the conditional ones and acts as the splitting attribute if its information gain is greater than 0 (lines 6–13).The original set is be split into many subsets based on the values of the splitting attribute. The subsets are be split recursively to construct subtrees. The probability Pgcorresponding to subsetGriis computed according to Eq. (8). Each leaf is assigned the probability that one group of users likes one type of movie (lines 18–25).A random decision tree only takes advantage of the limited information on users and items. Therefore, for many users and items a classical random decision tree may produce no prediction at all. In contrast, there is a probability P for each node in our tree. For many users and items, it may travel from the root to a branching node instead of a leaf node. In this way, the prediction is still rather imprecise. For example, the tree of Fig. 5(b) has no(Age=A18)user information, so an imprecise prediction is produced. But the two trees of Fig. 5 can avoid this situation.There are three steps to building the random forest: (1) aggregate training and testing sets are generated according to the different random-forest models; (2) condition attributes are randomized based on random seeds; (3) N random decision trees are built based on Algorithm 1. N, designated by the operator, is the size of the forest.The random forest is used to predict P for test objects. Each tree uses a different random seed, so they may produce different results for the same test object. Consequently, all trees contribute to the final prediction. The process of predicting P based on random decision tree is described in Algorithm 2.Algorithm 2Predict based on random decision treeInput: current node(currentNode), testing object(y)Output: PRMethod: predictBasedOnRandomTree1: a=currentNode.splittingAttribute;2: i=i=a(y);3: if (currentNode.children=NULL) then4:return currentNode.P;5: else if (currentNode.children[i]=NULL) then6:return currentNode.P;7: else8:returnpredictBasedOnRandomTree(currentNode.children[i], y);9: end ifWe obtain the value of the splitting attribute a for test object y (lines 1–2).If the current node has no children, the predictive value is the probability P of the current node (lines 3–4).If the ith children of the current node are empty, the predictive value is the probability P of the current node (lines 5–6).We obtain the predictive probability by recursively traversing the tree (line 8).Finally, the average probability is equal to total probabilities divided by the size of the random forest:(23)P=1N∑i=1NPRi,where N is the size of the random forest.In this subsection, we discuss the computation of the average cost of the training and testing sets. Throughout the study, the average-cost difference between training and testing sets is used to evaluate our RS.Grand Gtare the training and testing sets, as shown in Fig. 3(b) and (c), respectively. Based on the three-way decision model, there are five steps to compute the average costs of Grand Gt.First, for anyx∈Gr,0.35em0exP(x)can be computed directly based on the aggregate decision table. However, for anyy∈Gt,0.35em0exP(y)should be predicted based on the random forest. Second, we decide that each object should belong to the positive, negative, or boundary region based on three-way decision. Third, we count the classification numbers of the different regions listed in Table 4. Fourth, the total cost of all regions is computed according to the cost matrix and the classification number of the respective region:(24)Tc=λPPNPP+λPNNPN+λNPNNP+λNNNNN+λBPNBP+λBNNBN.Finally, the average cost is equal to the total cost divided by the number of training or testing objects. The average-cost computation for a training or testing set is described in Algorithm 3.Algorithm 3Average-cost computationInput: aggregated set (E)Output: average cost (Ac)Method: costComputation1: for (y∈E) do2:if (E is training set) then3:P(y)is computed directly based on Eq. (8);4:else5:P(y)is predicted based on Algorithm 2;6:end if7:R(y)is the original rating of y;8:if (P(y)>α*) then9:if (R(y)=Y) then10:NPP++;// classification number of positive–positive region11:else12:NPN++;// classification number of positive–negative region13:end if14:else if (P(y)<β*) then15:if (R(y)=Y) then16:NNP++;// classification number of negative–positive region17:else18:NNN++;// classification number of negative–negative region19:end if20:else21:if (R(y)=Y) then22:NBP++;// classification number of boundary–positive region23:else24:NBN++;// classification number of boundary–negative region25:end if26:end if27: end for28:Tcis computed based on Eq. (24);29: returnAc=Tc/|E|;Each object is classified into different regions based on P, α*, β* and user’s preference. This step corresponds to lines 8–26 of the algorithm.The total cost is computed based on three-way decision. This step corresponds to line 27 of the algorithm.The average cost is equal to the total cost divided by the number of aggregated objects. This step corresponds to line 29 of the algorithm.In this subsection, we explain the cost computation for a training or testing object through a working example. First, we calculate the three-way threshold pair (α*, β*) based on the cost matrix. Second, we compute the probability P(x) directly based on the training set or predict the probability P(y) based on the random forest. Third, we count the classification number based on the original rating, P and the pair (α*, β*). Finally, the expected cost is computed based on the classified counts and the cost matrix.Based on the cost matrix of Fig. 1 and the three-way decision model, we calculate α* and β* as0×α*+40(1−α*)=20α*+20(1−α*),50β*+0×(1−β*)=20β*+20(1−β*),which implies thatα*=0.6andβ*=0.5.In the training set, P(x) can be computed directly. For example, we computeP(mg1)=1/(1+3)=0.75in Fig. 3(b). Based on the original rating in Fig. 3(a), we find thatNPP=3andNPN=1. Based on the cost matrix of Fig. 1, the expected cost is then computed ascost=λPPNPP+λPNNPN=0×4+50×1=50.In the testing set, P(y) should be predicted based on the random forest. Given the training set of Fig. 3(b), we construct two random trees as shown in Fig. 5.In Section 3.5, ug2 consults our RS. For any ug2 ∈ UG2, there are three steps for our RS to decide whether or not recommend mt2 to ug2. First, aggregated conditional attributes are constructed based on demographic and content information. Second, the user–movie combination (A25, F, writer, 90s, 1, 0, 0) does not match any object in the training set; therefore, we cannot arrive at the probability directly from the training set. P(y) should be predicted based on the random forest. Following the tree of Fig. 5(a), the probability is 0.5. Following the tree of Fig. 5(b), the probability is 0. Hence P(y)=12(0.5+0)=0.25. Third, our RS makes one decision for mt2 to ug2 based on the three-way decision model. Because 0.25 < β*, our RS does not recommend mt2 to ug2. Assume that the original rating of the object isY, so we haveNNP=1. Based on the cost matrix of Fig. 1, the expected cost of this decision is computed ascost=λNPNNP=40×1=40.

@&#CONCLUSIONS@&#
We have proposed a framework integrating three-way decision and random forests to build recommender systems. In addition to recommending or not recommending a movie to a user, the third option of paying a teacher cost is considered for undecided cases. According to our experiments on Movielens data set, the threshold pair (α*, β*) determined with three-way decision is optimal not only on the training set, but also on testing set. Compared with the Pawlak, variable-precision, and probabilistic two-way rough set models, the three-way decision model has lowest average cost. In the future, we will apply memory-based approaches to this problem.