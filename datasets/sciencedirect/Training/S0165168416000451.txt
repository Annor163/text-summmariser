@&#MAIN-TITLE@&#
Extraction of instantaneous frequencies from ridges in time–frequency representations of signals

@&#HIGHLIGHTS@&#
Identifying and following instantaneous (ridge) frequencies in complex signals.Adaptive, universal, extraction of ridge frequencies from time–frequency representations.Comparison of the performance of different approaches for ridge curve extraction.Relative performance of the synchrosqueezed transforms in terms of curve extraction.Freely available codes implementing the new method.

@&#KEYPHRASES@&#
Ridge analysis,Wavelet ridges,Time–frequency representations,Wavelet transform,Windowed Fourier transform,Instantaneous frequency,Synchrosqueezing,

@&#ABSTRACT@&#
In signal processing applications, it is often necessary to extract oscillatory components and their properties from time–frequency representations, e.g. the windowed Fourier transform or wavelet transform. The first step in this procedure is to find an appropriate ridge curve: a sequence of amplitude peak positions (ridge points), corresponding to the component of interest and providing a measure of its instantaneous frequency. This is not a trivial issue, and the optimal method for extraction is still not settled or agreed. We discuss and develop procedures that can be used for this task and compare their performance on both simulated and real data. In particular, we propose a method which, in contrast to many other approaches, is highly adaptive so that it does not need any parameter adjustment for the signal to be analyzed. Being based on dynamic path optimization and fixed point iteration, the method is very fast, and its superior accuracy is also demonstrated. In addition, we investigate the advantages and drawbacks that synchrosqueezing offers in relation to curve extraction. The codes used in this work are freely available for download.

@&#INTRODUCTION@&#
A recurring problem in many areas of science is that of identifying curvilinear structures in noisy data and, in many cases, following them as the system evolves in time. The object of study may be spatial, as in automated screening for diabetic retinopathy [1] and in astronomy [2], or it may be a wavelet transform as in the identification of substances through terahertz tomography measurements [3], or it can be a prehistory probability density whose ridge represents the most probable fluctuational path for a nonlinear system undergoing a large fluctuation [4]. It has recently been shown that time-dependent dynamics can be of particular importance, and effective methods have been devised for characterizing the time-dependent amplitudes and phases [5,6]. In these and enumerable other cases the basic problem is that of putting a best-fit curve through a set of points, typically tracing a sequence of extrema, in a digital object. Difficulties to be overcome, in addition to the noise, may include possible crossings, self-crossings or closure of the extracted curves. The approaches that have been proposed include, for example, a variety of ridge-based methods based on locally defined principal curves [7–11] and a method based on an adaptive short-time Fourier transform [12]. In what follows we will focus on the problem as it arises in the analysis of recorded signals.Separation of the amplitude and frequency-modulated components (AM/FM components) in a given signal, and estimation of their instantaneous characteristics, is a classical problem of signal analysis. It can be approached by projecting the signal onto the time–frequency plane, on which the changes of its spectral content can be followed in time. Such projections are called time–frequency representations (TFRs), typical examples being the windowed Fourier transform (WFT) and the wavelet transform (WT). If the construction of the TFR is well-matched to the signal׳s structure, then each AM/FM component will appear as a “curve” in the time–frequency plane, formed by a unique sequence of TFR amplitude peaks – ridge points. Based on the properties of these curves, one can estimate the time-varying characteristics of the corresponding components (such as amplitude, phase and instantaneous frequency), an idea that was first expressed in [13]. In other words, to separate a signal into its AM/FM components one can: (a) trace the ridge curves corresponding to the individual components in the signal׳s TFR; (b) feed these curves into a chosen reconstruction method in order to recover the components and their characteristics (see [14] for a detailed study of the different reconstruction methods together with evaluations of their performance).However, the first step of such an approach, namely finding the TFR peak sequences associated with the individual signal components, is not a trivial issue. In real cases there are often many peaks in the TFR amplitude at each time, and their number often varies. In such circumstances it can be unclear which peak corresponds to which component, and which are just noise-induced artifacts.In the present paper, we concentrate solely on the problem of ridge curve identification, which is of great importance in time–frequency signal processing. Ridge analysis is widely used, e.g. machine fault diagnosis [15], fringe pattern analysis [16], studies of cardiovascular dynamics [17] and system classification [18,19]. Although curve extraction has been addressed explicitly in the past [17,20–23], there seems to be no agreement as to the optimal procedure to be used for this task. Here we discuss and generalize some existing algorithms, present new ones, and compare their performance. We end up with a method that is accurate and of almost universal applicability, so that it works well for a large class of signals and, in most cases, does not require adjustment by the user; this is the main contribution of the work. The effects of synchrosqueezing [23–26] on curve extraction are also studied.The plan of the work is as follows. After reviewing the background and notation in Section 2, we discuss different schemes for curve extraction in Section 3. In Section 4 we compare the performance of these schemes, while the advantages and drawbacks of synchrosqueezing in relation to curve extraction are studied in Section 5, and the limitations of the proposed methods are discussed in Section 6. We draw conclusions and summarize the work in Section 7. A dynamic programming algorithm for fast optimization of a path functional of particular form over all possible peak sequences is discussed in the Appendix.In what follows, we denote byf^(ξ)andf+(t), respectively, the Fourier transform of the function f(t) and its positive frequency part:(2.1)f^(ξ)=∫−∞∞f(t)e−iξtdt⇔f(t)=12π∫−∞∞f^(ξ)eiξtdξ,f+(t)≡12π∫0∞f^(ξ)eiξtdξ.Next, by an AM/FM component (or simply component) we will mean a signal of the form:(2.2)x(t)=A(t)cosϕ(t)(∀t:A(t)>0,ϕ′(t)>0),which is additionally required to satisfyA(t)eiϕ(t)≈2[A(t)eiϕ(t)]+, so that A(t) andϕ(t)are determined uniquely and, in the case of a single component, can be found using the analytic signal approach; more detailed discussions of issues related to the definition and estimation of the amplitude A(t), phaseϕ(t)and instantaneous frequencyν(t)≡ϕ′(t)of the component can be found in [14,27–30].In real cases, a signal usually contains many components xi(t) of the form (2.2), as well as some noiseζ(t)(that can be of any form, and is not necessarily white and Gaussian [30]):(2.3)s(t)=∑ixi(t)+ζ(t).The goal of ridge analysis is to extract these components, either all or only those of interest, from the signal׳s TFR.The two main linear TFRs suitable for components extraction and reconstruction are the windowed Fourier transform (WFT)Gs(ω,t)and the wavelet transform (WT)Ws(ω,t). Given a signal s(t), they can be constructed as(2.4)Gs(ω,t)≡∫−∞∞s+(u)g(u−t)e−iω(u−t)du=12π∫0∞eiξts^(ξ)g^(ω−ξ)dξ,Ws(ω,t)≡∫−∞∞s+(u)ψ⁎(ω(u−t)ωψ)ωduωψ=12π∫0∞eiξts^(ξ)ψ^⁎(ωψξ/ω)dξ,wheres+(t)is the positive frequency part of the signal (as defined in (2.1)), g(t) andψ(t)are respectively the window and wavelet functions chosen, andωψ≡argmax|ψ^(ξ)|denotes the wavelet peak frequency (for the WFT we assumeargmax|g^(ξ)|=0). Note that the WT is commonly defined through the scalesa=ωψ/ω, but that in (2.4) we have already transformed to frequencies.The main difference between the two TFRs mentioned is that the WFT distinguishes the components on the basis of their frequency differences (linear frequency resolution), while the WT does so on the basis of ratios between their frequencies (logarithmic frequency resolution). In effect, while the time-resolution of the WFT is fixed, for the WT it is linearly proportional to frequency, so that the time-modulation of the higher frequency components is represented better than that for the components at lower frequencies.In numerical simulations we use a Gaussian window for the WFT and a lognormal wavelet [14] for the WT:(2.5)g^(ξ)=e−(f0ξ)2/2⇔g(t)=12πf0e−(f0−1t)2/2,ψ^(ξ)=e−(2πf0logξ))2/2,ωψ=1,where f0 is the resolution parameter determining the tradeoff between the time and frequency resolution of the resultant transform (we usef0=1by default). While the methods developed below are generally applicable for any window/wavelet, the forms (2.5) seem to be the best choice [14], at least for the extraction and reconstruction of components.As illustrated in Fig. 1, the components present in the signal appear in its TFR as “curves” (which will be referred to as ridge curves), i.e. time sequences of close peaks. Generally, the component׳s ridge curve can be defined as the sequence of TFR amplitude peaks into which most of the energy of that component is mapped at each time (for further discussion see e.g. [13,21,24,31]). In the case when the signal consists of only one component, and there is no noise, and the TFR resolution is sufficient to represent all of the related time and frequency variability, there will only be one ridge curve: it can be found as a simpleargmaxof the TFR amplitude at each time; but in real cases there are usually many peaks, noise, and other complications.The problem of curve extraction therefore lies in selecting from among all possible trajectories the sequence of peaks that corresponds to a single component; the positions of these peaks then form a specific frequency profile, which will be denoted asωp(t). Having found the ridge curve, the parameters of the corresponding component can be estimated in a number of ways [14,24,31]. In the present work, however, we concentrate on curve extraction only and, except where it is unavoidable, do not consider the reconstruction issues; for a detailed study of the latter, see [14]. Note that, in practice, it is convenient to find the ridge curve associated with the dominant component present, which can then be reconstructed and subtracted from the signal; the procedure can then be repeated to extract any other possible ridge curves.In what follows, we denote the ridge frequencies, i.e. positions of the peaks at each time, asνm(t), the corresponding TFR amplitudes as Qm(t), and their numbers as Np(t):(2.6)νm(t):{[∂ω|Hs(ω,t)|]ω=νm(t)=0,[∂ω2|Hs(ω,t)|]ω=νm(t)<0,Qm(t)≡|Hs(νm(t),t)|,m=1,…,Np(t),whereHs(ω,t)is the chosen TFR of a given signal (WFTGs(ω,t)or WTWs(ω,t)). The ridge curve can then be parametrized asωp(t)=νmc(t)(t), where mc(t) is the sequence of peak indices at each time t, which we need to find. Note that the number of peaks Np(t) can vary in time and in practice is often greater than the number of components present in the signal, with the additional peaks being attributable e.g. to noise.For simplicity, we have treated ω and t as continuous variables. In practice, however, both time and frequency are discretized, and so also are many other related quantities (e.g. the ridge curveωp(t)becomes a discrete set of points). In what follows we therefore assume that the signal is sampled attn=(n−1)Δtforn=1,…,N, so that N is the signal׳s length in samples, while the TFRs (2.4) are calculated for the frequenciesωk=ωmin+(k−1)Δω(WFT) orωk=2k−1nvωmin(WT), wherek=1,…,Nf. The discretization parametersΔωand nvare generally selected by the user, but one can use e.g. the criteria suggested in [14] to make an appropriate choice.The most straightforward way to extract the ridge curve is first to choose some starting pointωp(t0), and then to follow from it forwards and backwards in time, selecting next ridges as those maximizing some suitably chosen functional of the corresponding peak amplitudes and the previously selected ridges. This approach, which we will call one-step optimization, can be formulated mathematically as(3.1)forn=n0+1,…,Ndo:mc(tn)=argmaxm{F[tn,Qm(tn),νm(tn),ωp(tn−1),ωp(tn−2),…,ωp(tn0)]}ωp(tn)=νmc(tn)(tn),and similarly backwards in time, forn=n0−1,n0−2,…,1. In (3.1), n0 denotes the discrete index of the starting time t0 (for whichωp(tn0)is known), andF[⋯]is the chosen functional of the current discrete time tn, the peak positionsνm(tn)and amplitudesQm(tn)at this time, and all previously selected ridge points{ωp(tn0≤t≤tn−1)}. For scheme (3.1) to be O(N), the functionalF[⋯]should either depend on the finite number of previously selected ridges, or on the set of parameters which can be updated in O(1)steps whenever a new point becomes available (e.g. the moments ofωp(t)).To implement (3.1), one needs to choose the starting time index n0 and the corresponding ridgeωp(tn0). It seems natural to select this starting point (among all times and ridges) as being that for which the functional in (3.1) is likely to attain its maximum:(3.2)ωp(tn0)=νm0(tn0),{m0,n0}=argmax{m,n}{F0[tn,Qm(tn),νm(tn)]},whereF0[⋯]denotes a “zero-step” version of the original functional, obtained from the latter by taking its maximum among all the other parameters. For example, if one hasF[⋯]=f(Qm(tn),νm(tn))+g(νm(tn)−ωp(tn−1)),thenF0[⋯]=f(Qm(tn),νm(tn))+maxΔξg(Δξ); if additionallyf(Qm(tn),νm(tn))does not depend onνm(tn)and is proportional toQm(tn), then (3.2) will correspond to the highest TFR amplitude peak over all time. The criterion (3.2) works well in most cases, although it could still provide a “bad” starting point when sharp time events are present or the noise is too strong.A serious drawback of the outlined one-step approach (3.1) is that even a single wrongly selected point might completely change all the following curve being extracted. Consequently, it is more accurate to optimize the functional not over each consecutive point, as in (3.1), but over the whole profileωp(t), selecting the ridge curve as being that which maximizes the full integral ofF[⋯]over time:(3.3){ωp(t1),…,ωp(tN)}={νmc(t1)(t1),…,νmc(tN)(tN)},{mc(t1),…,mc(tN)}=argmax{m1,m2,…,mN}∑n=1NF[tn,Qmn(tn),νmn(tn),{νm1(t1),…,νmN(tN)}].This approach, where the optimization is performed over all possible sequences of peak numbers{m1,m2,…,mN}, will be referred to as the path optimization. In general, it is computationally very expensive. However, if the functional depends on only a finite number of previous points{ωp(tn−i),…,ωp(tn−1)}, rather than on the full history, then the optimal path in terms of (3.3) can be selected in O(N)computations using a dynamic programming algorithm (see Appendix). Note that, in this way, the widely used method of Carmona et al. [20] can also be performed in O(N)steps instead of the computationally expensive simulated annealing used previously.It will be demonstrated in Section 4 (Figs. 3 and 4) that path optimization (3.3) usually gives much better results than the one-step optimization (3.1), and should therefore always be preferred to the latter. Furthermore, it has no problem associated with the selection of the starting point (3.2), as all the trajectories are explored.What remains is to select an appropriate functional in (3.3). We consider below some curve-extraction schemes defined by particular classes ofF[⋯]. We first develop these schemes for the WFT, and then discuss how they can be adjusted for the WT. In all cases, we perform path optimization using the algorithm discussed in the Appendix. Taking into account its complexity, and the fact that one needs to locate all peaks (2.6) in the TFR prior to applying any extraction procedure, the computational costs of the methods discussed below areO(NfN)+O(Mp2N)(scheme I) andO(NfN)+O(Mp2NlogN)(scheme II), withlogNcorresponding to the number of iterations as discussed below; NfandMp≡maxtNp(t)are respectively the number of frequencies ωkfor which the TFR is calculated, and the maximum number of TFR amplitude peaks present at any one time. Both Nfand Mpare independent of N.Remark 3.1Because in practice the frequency scale for the WFT/WT is discretized, the ridge frequenciesνm(t)also take discrete values at each time. As a result, e.g. the differences between consecutive ridgesΔωp(tn)≡ωp(tn)−ωp(tn−1)cannot reliably be calculated, being “quantized” in steps determined by the widths of the frequency bins, so that in typical cases it will be zero for most of the time and have relatively high values otherwise. To avoid consequential problems, and to improve the quality of the ridge frequency estimates, we find peak positionsνm(t)more precisely by using parabolic interpolation based on the TFR amplitudes at the peak and the two adjacent bins: see e.g. the discussion of ridge reconstruction in [14]. Because the TFR amplitudes take continuous values, the estimates ofνm(t)(and therefore those ofΔωp(t)) also become continuous. One then does not need to worry about the related discretization effects, which could otherwise influence significantly the performance of methods that are based on the differences between ridge frequencies.A widespread approach is to penalize the frequency difference between the consecutive ridge points, so that(3.4)F[⋯]=logQm(tn)+w(νm(tn)−ωp(tn−1),α),wherew(Δξ,α)is some weighting function, aimed at suppressing frequency jumps, and α is its set of adjustable parameters. Note that in (3.4) one can choose another function ofQm(tn)instead of the logarithm, e.g.|Qm(tn)|2; however, the logarithm seems to be the most appropriate choice because the path functional (3.3) then depends on the product of all the amplitudes and thus can be significantly influenced even by a single “wrong” point, making selection of the latter less probable.The class of functionals (3.4) is a popular choice. The approach of [22] corresponds tow(Δξ,α)=0forΔξ∈[−1/α,1/α]and=−∞otherwise, while the procedure used in [23,30] utilizes the quadratic weightsw(Δξ,α)=αΔξ2(though in these methods the optimization is carried out over all frequency bins ωkat each time rather than using only the peaksνm(t), as we do here). The algorithm of [17] also represents a variant of (3.4). Finally, the approach of Carmona et. al. [20] can be viewed as a modified version of (3.4) with additional penalization of the second order frequency differences.The main disadvantage of the approaches mentioned is that they require fine tuning of each method׳s parameters to obtain an accurate result, with different choices being needed for different signals and different characteristics of the TFR in use. To make the parametrization more universal, the weighting function should utilize the resolution properties of the WFT, which are determined by the window function g(t). Thus, for a given window there exists a minimum frequency (resp. time) difference Δξg (resp. Δτg) for which two frequency events, e.g. tones (resp. time events, e.g. delta-peaks) can be resolved in the WFT. In other words, the larger Δτg is (the smaller f0 is in (2.5)), the less time-variability is allowed for the components, so that one expects smaller frequency jumps.We therefore penalize the ratio of the observed time-derivative of the ridge frequency difference to its characteristic value, which can naturally be taken asΔξg/Δτg. This leads to the choice(3.5)w(Δξ,α)=αw˜(fs|Δξ|Δξg/Δτg)=−αfs|Δξ|Δξg/Δτg,where fsis the signal sampling frequency, while Δξg and Δτg are chosen resolution measures. We use those introduced in [14], taking Δξg and Δτg as being the widths of the regions in time and frequency encompassing 50% of the window function:(3.6)Δξg=ξg(2)(0.5)−ξg(1)(0.5),Δτg=τg(2)(0.5)−τg(1)(0.5);ξg(1,2)(ϵ):|Rg(ξ≤ξg(1))|<ϵ/2,|1−Rg(ξ≥ξg(2))|<ϵ/2;τg(1,2)(ϵ):|Pg(τ≤τg(1))|<ϵ/2,|1−Pg(τ≥τg(2))|<ϵ/2;Rg(ω)≡∫−∞ωg^(ξ)dξ∫−∞∞g^(ξ)dξ,Pg(τ)≡∫−∞τg(t)dt∫−∞∞g(t)dt.For a Gaussian window (2.5) one obtainsΔξg/Δτg=1/f02, and this result remains the same even if using as Δξg and Δτg the conventional standard deviations of|g^(ξ)|2and|g(t)|2, respectively.With the choice (3.5), the parameter α is expected to be nearly universal, so that the same value should work well for different window functions. Note that, although in (3.5) we usew˜(r)=−|r|, other functions can be utilized instead. However, for any reasonable choice, the method remains qualitatively the same, i.e. one expects it to suffer from the same drawbacks and to have similar issues.It is important to note that scheme I corresponds to the simple cases of “global maximum” and “nearest neighbor” curve extraction forα=0andα→∞, respectively:•Global maximum(α=0). In this case the functional (3.4) reduces toF[⋯]=logQm(tn), so that the maximum peak will be selected at each time, taking no account of the previous ridge points.Nearest neighbor(α→∞). This case differs for one-step optimization (3.1) and path optimization (3.3). The former approach corresponds to selecting at each new step the peak which is nearest to the previous one, taking no account of its amplitude. The latter approach will give simply the least frequency-varying curve.In the previous scheme, an adjustable parameter α determines the suppression of the frequency variations. Although some choices (e.g.α=1) appear to be almost universal, they still remain highly non-adaptive, so that a particular parameter value might be suitable for one type of the signal, and a different value for another type. For example, in the case of chirps~cos(at+bt2)it is clear that one should penalize not simply the frequency derivative|Δωp(t)/Δt|, but its difference from the true value(2b), i.e.|Δωp(t)/Δt−2b|.To make the scheme adaptive, the parameters of the functional should be matched to the properties of the component being extracted, such as the typical variations of its instantaneous frequency. The latter can be characterized by the averages and standard deviations of the ridge frequenciesωp(t)and their differencesΔωp(tn)≡ωp(tn)−ωp(tn−1); or, which appears to be more stable in practice, by the corresponding mediansm[⋯]and interquartile rangesIQR[⋯], defined for an arbitrary function f(t) as(3.7)m[f(t)]≡perc0.5[f(t)],IQR[f(t)]≡perc0.75[f(t)]−perc0.25[f(t)],wherepercp[f(t)]denotes thepthquantile of f(t).An adaptive functional can then be constructed by suppressing not the absolute frequency jumps, as before, but the relative deviations of the component׳s ridge frequency and its derivative from their typical values:(3.8)F[⋯]=logQm(tn)+w2(νm(tn),m[ωp],IQR[ωp],β)+w1(νm(tn)−ωp(tn−1),m[Δωp],IQR[Δωp],α).where α and β denote sets of adjustable parameters controlling suppression of atypical variations of the ridge frequency׳s derivative and value, respectively. Similar to (3.5), we choose the first order penalization functions:(3.9)w1(Δξ,m[Δωp],IQR[Δωp],α)=−α|Δξ−m[Δωp]IQR[Δωp]|,w2(ξ,m[ωp],IQR[ωp],β)=−β|ξ−m[ωp]IQR[ωp]|.By maximizing the path integral (3.3) based on the functional (3.8), one is in fact trying to extract the curve which is most consistent with itself. Thus, the strength of the respective frequency variations becomes unimportant, and it is only their agreement and similarity at different times that matters.Even the most adaptive method can be parametrized to tackle special cases, and in (3.8) we have introduced the adjustable parameters α and β controlling the strengths of suppression of the corresponding relative deviations. However, although there are now two parameters, they are in fact more universal than the single parameter of scheme I, and the particular choice ofα,βfor scheme II is expected to work well for a larger class of signals than the particular choice of α in the scheme I, as will be seen below. This is because in (3.8) we take explicitly into account the actual properties of the component being extracted, penalizing deviations from its typical behavior rather than simply the frequency jumps. Additionally, by suppressing the relative deviations of the component׳s frequency from its mean, scheme II stabilizes the curve in its characteristic frequency range (thus decreasing the possibility that it will “escape” and switch to another component), while there is no such mechanism in scheme I.The functional (3.8) depends, however, on the whole time-evolution ofωp(t), so that the path optimization (3.3) cannot be performed in O(N)steps, as before (see Appendix); nor is it evident how to update the functional at each step if using the one-step optimization (3.1). Nevertheless, one can approach the approximately optimal curveωp(t)by use of a kind of fixed-point iteration [32]. Starting with some initial guessωp(0)(t), one calculates the corresponding medians and ranges, fixes them in (3.8) (so that the functional now depends on only two consecutive ridges rather than on the full history, meaning that the algorithm discussed in Appendix becomes applicable), and extracts the newer profileωp(1)(t)in the usual way. The (fixed) medians and ranges are then updated to those of theωp(1)(t)and, based on these newer estimates, the next approximationωp(2)(t)is found in the same manner. The procedure is repeated until the curves obtained in two consecutive iterations coincide perfectly (ωp(n)(t)=ωp(n−1)(t)for all t). For the first iteration, we use a simple global maximum curveωp(0)(t)=argmaxω|Gs(ω,t)|.The convergence of the fixed-point algorithm outlined above is in general hard to prove. In practice, however, the procedure converges not only exactly (so that the next iterations produce absolutely identical curves), but also rapidly. To show this, we have analyzed the performance of the method for white noise signals with different sampling frequencies and time lengths, thus trying to model the worst case (as the method will obviously converge faster if the signal contains some pronounced components). The results are presented in the Supplementary material, Fig. 1. The number of iterations needed is always relatively small, being proportional tologN; it is determined primarily by the signal׳s time length, while the sampling frequency only has a very minor effect. Note also that one can set some maximum number of allowed iterations if desired, though in our simulations the procedure always converged exactly and rapidly.Due to the logarithmic frequency resolution of the WT, one should consider not the frequencies but their logarithms, which is the only significant difference from the WFT case. In the case of the WT one uses the same schemes and functionals, but now everything is taken on a logarithmic frequency scale (ωp(tn)→logωp(tn),Δωp(tn)≡ωp(tn)−ωp(tn−1)→Δlogωp(tn)≡logωp(tn)−logωp(tn−1), and similarly for all the other frequency variables). We now summarize briefly the required adjustments.Scheme I: Instead ofw(νm(tn)−ωp(tn−1),α), in (3.4) one usesw(logνm(tn)−logωp(tn−1),α). The form of the penalization function (3.5) remains qualitatively the same:(3.10)w(Δlogξ,α)=αw˜(fs|Δlogξ|Δlogξψ/Δτψ)=−αfs|Δlogξ|Δlogξψ/Δτψ,but one now uses the wavelet׳s characteristic log-frequency and time differencesΔlogξψandΔτψ, respectively. The estimates given in [14] are calculated as(3.11)Δlogξψ=logξψ(2)(0.5)ξψ(1)(0.5),Δτψ=τψ(2)(0.5)−τψ(1)(0.5);ξψ(1,2)(ϵ):|Rψ(ξ≤ξψ(1))|<ϵ/2,|1−Rψ(ξ≥ξψ(2))|<ϵ/2;τψ(1,2)(ϵ):|Pψ(τ≤τψ(1))|<ϵ/2,|1−Pψ(τ≥τψ(2))|<ϵ/2;Rψ(ω)≡∫0ωψ^⁎(ξ)dξ/ξ∫0∞ψ^⁎(ξ)dξ/ξ,Pψ(τ)≡∫−∞τψ⁎(t)eiωψtdt∫−∞∞ψ⁎(t)eiωψtdt.Scheme II: In (3.8) thew1(⋯)andw2(⋯)are changed tow1(logνm(tn)−logωp(tn−1),m[Δlogωp],IQR[Δlogωp])andw2(logνm(tn),m[logωp],IQR[logωp]),respectively, with their basic forms (3.9) remaining the same.As discussed above, the general form of scheme I is motivated by many previously proposed algorithms for curve extraction [17,20,22,23,30], most of which can be considered as its specific variants and which should therefore have qualitatively similar properties and issues. Scheme II, on the other hand, provides the main novelty of the present work. We now compare the performance of both schemes for various parameter choices and signals.We test the relative performances of the different methods on two signals. The first signal is an AM/FM component with simple sinusoidal amplitude modulation and two-sinusoidal frequency modulation, plus a weaker component:(4.1)s1(t)=(1+13cos2πt9)cos(2πt+6sin2πt30+cos2πt12)+0.8cos(2π×1.75t+0.5sin2πt5).Note that, although an AM/FM component around 1Hz is dominant in terms of both maximum amplitude and mean squared amplitude, there are certain times at which the amplitude of the other component (at around 1.75Hz) becomes higher, thereby introducing additional complications for curve extraction. The second test signal is taken from real life, representing the central 200s part of a 30min electrocardiogram (ECG) signal recorded from a 30-year-old male subject [17]. The WFTs for both signals are shown above in Fig. 1.The main complications that arise in curve extraction relate to the appearance of other WFT amplitude peaks nearωp(t), which can be due either to noise or to other components. We model these complications by corrupting the signal with colored noiseη(t)of unit deviation and a particular Fourier amplitude (while the phases of its Fourier coefficients are random):(4.2)s(t)=s(t)+ση(t),|η^(ξ)|~14π2+ξ2.Being asymmetric, the noise amplitude at frequency 0.5Hz is around 2.5 times higher than at 1.5Hz, corrupting the dominant components (which have a mean frequency around 1Hz in both test signals) unequally in frequency on the two sides. This gives an opportunity to study reliably the relative performance of the different methods, as colored noise can additionally model the effect of other components that are asymmetrically distributed in frequency around the component of interest. The WFTs of the two test signals corrupted with noise are presented in Fig. 2.It is well known that, even in the absence of noise, the ridge points are not located exactly at the true instantaneous frequenciesν(t)≡ϕ′(t)[14,31]. If we compare theωp(t)obtained with the true frequency profile then, even in the case when the curve extraction works perfectly (e.g. when there is a single peak at each time, and hence only one possible ridge curve) there will be some discrepancy between the two. At the same time, what we want to test is how well the methods presented can identify the peak sequence corresponding to the component of interest, and not how well one can then reconstruct the component׳s parameters from this sequence. Therefore, to assess the performance of the curve identification method, rather than the performance of the TFR itself or the accuracy with which frequencies are estimated from ridges, we compare the extractedωp(t)with the “ideal” ridge curveω˜p(t)obtained in the noise-free case. The corresponding error ϵfcan then be defined as(4.3)ϵf2≡〈[ωp(t)−ω˜p(t)]2〉〈[ω˜p−〈ω˜p〉]2〉,where〈⋯〉denotes the time-average. An additional complication is that, because noise changes the ridge profile as it appears in the WFT, there always exists some deviation between the extracted profiles with and without noise, which is unrelated to the performance of the extraction method. Consequently, the ϵf(4.3) contains both an irreducible, inherent, error related to the effect of noise on the TFR, and the error of the curve extraction method. Therefore, we only compare the performance of different methods, without aiming to find the profile as it would be without noise (which is generally impossible).In the simulations, both test signals are sampled at 20Hz. We will test curve extraction only for the WFT, but the results remain qualitatively the same for the WT as well. To eliminate boundary distortions in the TFR, we simulate the first test signal (4.1) for 1000s, calculate the corresponding WFT and then use only its central 200s part; the same procedure is applied for the ECG signal. Also, since there are two strong components in the first signal, we find two ridge curves for it and choose that lying closer in frequency to the dominant component (around 1Hz). We use a Gaussian window (2.5) withf0=1and calculate the WFTs at frequenciesωk/2π=0.25+(k−1)Δω/2π∈[0.25,2.25](this range of frequencies is chosen based on a priori knowledge that all components of interest are contained in it) withΔω=Δξg/25≈2π×0.008. For both signals, we use 40 noise realizations, which are the same for each method, parameters and noise intensities σ being tested.

@&#CONCLUSIONS@&#
We have developed and compared techniques that can be used for ridge curve extraction from the WFT/WT, and discussed a number of related issues. Among the proposed approaches, scheme II(α,β) withα=βwas shown to produce the best results. Its parameters β and α control the strengths of suppression of the relative deviations of ridge frequency and its time-derivative from the corresponding median values, respectively. Although these parameters can be adjusted to better match any specific problem, due to high adaptivity of the approach the default choiceα=β=1works well in the majority of cases (within the limitations discussed in the previous section). Scheme II(1,1) appears to be of almost universal utility, being a type of “just apply” method that does not require any tuning by the user. The corresponding MatLab codes, as well as other useful time–frequency analysis tools, are freely available in [36].We have also tested the effects of synchrosqueezing [23–26] in relation to curve extraction, and found that its drawbacks heavily outweigh its advantages. Although scheme II(1,1) still remains the best and works reasonably well if applied to the synchrosqueezed transforms, in general the structure of the SWFT/SWT seems to be less suitable for curve extraction compared to that of the WFT/WT, at least for the methods considered.