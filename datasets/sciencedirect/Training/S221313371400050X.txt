@&#MAIN-TITLE@&#
Multiscale Distilled Sensing: Astronomical source detection in long wavelength images

@&#HIGHLIGHTS@&#
A new approach to detect sources in long wavelength images is presented.It is based on a multiscale decomposition and a method called Distilled Sensing.The method is tested against real infrared and radio images.The performance of the method is compared to reference state-of-the-art algorithms.

@&#KEYPHRASES@&#
Methods: data analysis,Techniques: image processing,

@&#ABSTRACT@&#
The increasing number of astronomical surveys in mid- and far-infrared, as well as in submillimetre and radio wavelengths, brings more difficulties to the already challenging task of detecting sources in an automatic way. These specific images are characterized by a more complex background than in shorter wavelengths, with a higher level of noise, more noticeable flux variations and both unresolved and extended sources with a higher dynamic range. In order to improve the source detection efficiency in long wavelength images, in this paper we present a new approach based on the combined use of a multiscale decomposition and a recently developed method called Distilled Sensing. Its application minimizes the impact of the contaminants from the background, unveiling and highlighting the sources at the same time. The experimental results achieved using infrared and radio images illustrate the good performance of the approach, identifying greater percentages of true sources than using both the widely used SExtractor algorithm and the Distilled Sensing method alone.

@&#INTRODUCTION@&#
Many source detection methods based on different techniques have been developed over the last years (see, e.g., Masias et al., 2012 for a review). They typically deal with detection in astronomical images by means of thresholding techniques based on local noise estimation to unveil the sources. However other different innovative approaches have recently arisen as well. Of special interest is the method called Distilled Sensing (DS) proposed by  Haupt et al. (2009) to detect sparse signal in noisy observations. It deals with the detection problem from a different point of view. The strength of DS lies in the idea that it is easier to identify where the signal is absent than where it is present. In other words, it consists of discarding those regions where the signal (sources in the case of astronomical images) is unlikely to be present, and focuses the detection on the remaining regions. This method has proven to work satisfactorily with optical astronomical images (Masias et al., 2013). However, like many other methods, its performance decreases when images have a complex background with a high level of noise and marked intensity variations. This is the case with images acquired at long wavelengths such as radio and infrared, where an additional image transformation step may be needed to attenuate these harmful effects. Although it presents good percentages of reliability in all bands, its completeness decreases with these types of images.Aiming to improve the source detection in long wavelength images, especially in terms of completeness, in this paper we propose a method based on the combined use of DS with multiscale techniques that are widely applied to astronomical imaging for noise filtering and source highlighting purposes.Distilled Sensing (DS) is an adaptive sampling method for the detection and estimation of sparse signal (Haupt et al., 2009). These kinds of methods are also known as compressed/sparse signal/sensing and basically recover (i.e. estimate or detect) signal in sparse observations. DS is based on the main principle that in a noisy observation, it is far simpler to identify larger sets of non-signal than smaller sets of signal. It can be seen as an image transformation step where, through different iterations, the data is refined. More resources are iteratively focused on those regions that are more likely to be signal while at the same time ignoring those regions unlikely to be of interest. In this way, the increasing level of certainty of where the sources are located increases along iterations. In the astronomical image domain, this procedure is equivalent to discarding background/noise regions and only taking the sources into account. Notice that DS assumes that the noise is normally distributed.Fig. 1illustrates a simple example of how DS works. A certain amount of energy sensing (a predefined value) is distributed into the iteration steps, and at the same time, this part of the energy is equally distributed into the different interest regions in the image, being all the pixels in the first iteration. A larger value of energy sensing is devoted to the first iterations and decreases exponentially in the later iterations when there are fewer remaining interest regions, finally using the remaining resources in the last iteration. The following formula is a formal representation of this energy sensing allocation among the iterations:(1)Rk={ϵk−1R1k=2,…,m−1R1k=1,m,whereRkis the energy sensing allocated to the iterationk,ϵis an arbitrary parameter to model the relationship between the energy allocated to an iteration and that of the previous iteration (with 0<ϵ<1), andmthe total number of iterations fixed to:(2)m=max{log2logn,0}+2,wherenis the total number of components of the observation (pixels in our case).As can be seen, the energy of the initial and final iterations is the same because, according to  Haupt et al. (2009), that benefits the control of the false positives in the first iteration and the false negatives in the last one.  Haupt et al. (2009) also suggested that∑k=1mRk≤n. The data is iteratively refined using a function where some uncertainty, a random value drawn from a normal distribution, is added to each interest pixel, and the resulting sum is divided into the square root of the energy sensing value corresponding to the pixel (Haupt et al., 2009). The formal representation of this refinement or distillation in an iteration follows:(3)Yk(i,j)={(I(i,j)+Z)Rk|Sk|I(i,j)∈Sk0I(i,j)∉Sk,whereYkis the refined image in iterationk,I(i,j)is the intensity of the pixel in rowiand columnj,Z∼N(0,1), andSkis the set of pixels of interest of iterationk(|Sk|being the number of pixels of interest). This equation leads to negative values considered as noise, so they are discarded. Afterwards, the interest regions are limited to those with positive values, and the entire process is repeated. Notice that, at each iteration, what is refined are the intensities of the pixels in the original image. As a result of this process, most of the background pixels are discarded. The authors stated that in each distillation iteration, most of the pixels corresponding to signal were retained, whereas approximately half of the background/noise pixels were ruled out. Finally, the source locations are specified by using a data-based thresholding. In  Haupt et al. (2009), the authors used a threshold that guarantees a detection reliability of 95%, meaning that at least 95% of the detections performed by the method were true sources.In order to turn DS into a more robust method able to deal with images with more complex backgrounds, we decided to apply it after a multiscale transform of the original data. Multiscale techniques decompose images into components at different scales or frequencies, and depending on the type of source, they become highlighted in the low or high scales. Furthermore, overlapped sources usually appear individually in some of these scales. Thus, every single scale can be treated as an image where the sources have to be detected. These types of techniques are widely used in astronomical images since, apart from highlighting sources, they are good at filtering noise, removing background, attenuating the background variability and deblending sources (Masias et al., 2012). Therefore, by using a multiscale transform the background will have a lesser impact and the detection results should improve. Fig. 2depicts an example of an image decomposed in several wavelet scales.Different multiscale decompositions have been used in the literature, the wavelet transform (WT) and its variations being the most used by far due to their performance (Damiani et al., 1997; Starck et al., 1999; Freeman et al., 2002; Vielva et al., 2003; González-Nuevo et al., 2006). In this work, we have selected two types of WT that are most commonly used:•The stationary wavelet transform (SWT), more commonly known as the ‘à trous’ algorithm, which is an extension of the discrete WT designed to overcome the lack of shift invariance (Starck and Murtagh, 2006). Each scale is defined as the difference between the previous scale and the previous scale convolved with a specific discrete filter. We have used a spline of degree 3 as a filter, as suggested in  Starck and Murtagh (2006).The Mexican hat wavelet transform (MHWT), a special case of the family of continuous wavelets consisting of applying a Laplacian operator to a Gaussian function (Starck and Murtagh, 2006).When these transformations have been done, we then apply the DS algorithm to provide the source detections. We decided to analyse the first three scales in the SWT since most of the sources to be found were point-like and, as stated in  Masias et al. (2012), the most suitable scales in which to find these types of sources are those with higher spatial frequencies (the first ones). On the other hand, we only used the first scale of the MHWT since further scales of this transform are not commonly used in the literature. Afterwards, we applied the DS method to each of the four resulting scales: the three scales in the SWT and the first scale in the MHWT. We call this procedure Multiscale Distilled Sensing (MDS). The seminal work of this proposal was presented in the 23rd Annual Astronomical Data Analysis Software and Systems (ADASS) Conference (Masias et al., 2014).MDS is based on the following steps:1.A wavelet transform is applied to the raw image and a significant scale is selected.A certain value, energy sensing, is distributed into a certain number of iterations.In the wavelet scale, the proportional energy sensing is distributed in the regions of interest (the whole image in the first iteration).Pixels in the region of interest are refined:4.1Some uncertainty is added to each interest pixel intensity.The resulting sum is divided into the square root of the energy sensing value corresponding to the pixel.Pixels with negative values are excluded from the regions of interest.Steps 3–5 are repeated until the specified number of iterations is reached.Finally, connected zones and their centroids are computed to produce the source position catalogue.The final step is based on a thresholding. This process results in various regions consisting of adjacent pixels with intensities above a predefined level. Therefore, this cut-off value must be experimentally tuned to achieve the best possible results.

@&#CONCLUSIONS@&#
Aiming to deal with automatic source detection in long wavelength images such as infrared and radio, we have proposed a new approach based on multiscale decomposition and Distilled Sensing (DS). In these images characterized by complex backgrounds, Multiscale Distilled Sensing (MDS) has provided satisfactory results since the number of true sources detected for a given false alarm rate has been substantially better than using DS directly. The number of fainter sources identified has dramatically increased in some scales. Specifically, the results have been particularly good in the first two scales of the SWT. Furthermore, the quantitative comparison of the new approach with the original DS and the commonly used SExtractor software has demonstrated the validity of the combined use of DS and wavelets, results obtained with MDS being better in most cases analysed.A key parameter in both DS and MDS is the detection threshold. It is a data-based value that we have experimentally fixed for each image in each of the scales used. Table A.3summarizes the thresholds that provided the best results for reliability levels of 90% and 95%. Notice that, since they depend on the transformed data, they are quite different.Moreover, the parameterϵcorresponding to the relationship between the energy sensing allocation between two successive iterations was fixed to 0.75, since the authors of DS mentioned that this value provides good performance in data with different levels of noise. This value implies that the resources devoted to an iteration are 0.75 times fewer than in the previous iteration. The sum ofRkwas fixed ton(the number of pixels in the image), and distributed into the different iterations according to  Eqs. (1) and (2).