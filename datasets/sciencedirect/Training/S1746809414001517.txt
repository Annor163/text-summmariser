@&#MAIN-TITLE@&#
Classifying infant cry patterns by the Genetic Selection of a Fuzzy Model

@&#HIGHLIGHTS@&#
We propose an automatic classification model for infant crying for early disease detection.Feature extraction and an automated model selection processes are described.We apply the Genetic Selection of a Fuzzy Model algorithm to generate a classifier.Our approach improves the predictive performance on the identification of the cause of crying.

@&#KEYPHRASES@&#
Feature extraction,Pattern recognition,Infant cry classification,Fuzzy model,Model selection,Genetic algorithms,

@&#ABSTRACT@&#
Infant crying analysis is an important tool for identifying different pathologies at a very early stage of the life of a baby. Being able to perform this task with high accuracy is therefore important and required as a medical support system to assess a baby's health. In this research we propose an automatic classification model for infant crying for early disease detection. Our model mainly consists of two phases: (a) an acoustic features acquisition from the Mel Frequency Cepstral Coefficient and the Linear Predictive Coding from signal processing and (b) the selection/creation of an optimized fuzzy model through the Genetic Selection of a Fuzzy Model (GSFM) algorithm. GSFM searches for the best model by choosing a combination of a feature selection method, a type of fuzzy processing, a learning algorithm together with its associated parameters that best fit the input data. Our approach improves the predictive accuracy on the identification of the cause of crying and clearly helps to differentiate between normal and pathological cry. Experimental results show a significant accuracy improvement when using our optimized genetic selection method for most of the cases.

@&#INTRODUCTION@&#
Infant crying is at birth the only communication means of babies, which, while very restricted, takes the roll of adults’ speech. Through crying, the baby shows his/her physical and psychological state. Several studies have been performed in order to distinguish between different kinds of cries. The crying wave carries useful information, as to detect possible physical pathologies from very early stages of life. Those studies bring the opportunity of helping babies by understanding their needs or by detecting specific diseases, in which case the appropriate treatment can be provided and future complications prevented. For example, world-wide statistics indicate that from one thousand new born, 1 or 2 present deep hearing loss or severe hearing loss. Nevertheless not all of them receive diagnosis and timely treatment. This fact generates a very serious problem, because the beginning of an opportune treatment is delayed. The earlier the deafness diagnosis the better guaranteed the possibilities of rehabilitation and acquisition of language. In cases like those the application of non-invasive tools, like infant cry analysis, to produce early diagnosis could help to provide the needed treatment.The first works with infant cry were initiated by Wasz–Hockert since the beginnings of the 60s [56]. In 1964 the research group of Wasz–Hockert showed that the four basic types of cry can be identified by listening: pain, hunger, pleasure and birth [56]. In a recent study Sheinkopf et al. examined differences in acoustic characteristics of infant cries in a sample of babies at risk for autism and a low-risk comparison group [49]. Besides, many other studies related to this line of research and to that of automatizing the recognition of cries have been reported.Sergio D. Cano carried out and directed several works devoted to the extraction and automatic classification of acoustic characteristics of infant cry. In one of those studies, in 1999 Cano presented a work in which he demonstrates the utility of Kohonen's Self-Organizing Maps in the classification of Infant Cry Units [14]. In [12] a radial basis function (RBF) network is implemented for infant cry classification in order to find out relevant aspects concerned with the presence of Central Nervous System (CNS) diseases. First, an intelligent searching algorithm combined with a fast non-linear classification procedure is implemented, establishing the cry parameters which better match the physiological status previously defined for the six control groups used as input data. Finally the optimal acoustic parameter set is chosen in order to implement a new non-linear classifier built on a RBF network, an ANN-based procedure which classifies the cry units into two categories, normal or abnormal class, as the ones shown in Figs. 1 and 2.In 2004 a study is published in [55] which deals with classical and new methods of acoustic analysis of the infant cry, where the final goal is to detect hearing disorders according to the crying at the earliest possible moment. Manfredi et al. [38] developed, a new robust adaptive tool for new born infant cry analysis which is characterized by a high tracking capability, well suited for the signals under study. The tool performs F0 noise and resonance frequencies tracking, on signal frames of varying length. Moreover, voiced/unvoiced separation is implemented, allowing disregarding unvoiced parts of the signal where misleading results could be obtained. In a further study Manfredi et al. [37] presented a user-friendly software tool to deal with newborn infant cry signals, which allows robust tracking of main acoustic parameters on very short and time-varying signal frames.In [31], LaGasse et al. state that the typical infant cry analysis protocol involves 30s of crying from a single application of the stimulus. The recorded cry is submitted to an automated computer analysis system that digitizes the cry and either presents a digital spectrogram of the cry or calculates measures of cry characteristics. Another study presented by Branco et al. [11] is focused in the extraction of the characteristics of pain vocal emission of newborns during venepuncture through acoustic analysis and relate them to the Neonatal Infant Pain Scale (NIPS) and some other variables of the newborns.The infant cry automatic classification process is, in general, a pattern recognition problem, similar to Automatic Speech Recognition (ASR). The goal is to take the wave from the infant's cry as the input pattern, and at the end obtain the kind of cry or pathology detected on the baby [24,43]. Generally, the process of Automatic Cry Recognition is performed in two steps, see Fig. 3.The first step is known as signal processing, or feature extraction, whereas the second is known as pattern classification. In the acoustical analysis phase, the cry signal is first normalized and cleaned, and then it is analyzed to extract the most important characteristics in function of time. The cleaning of the signal is applied in order to eliminate irrelevant and undesirable information, like background noise, channel distortion, and particular characteristics of the signal. Some of the more used techniques for the processing of the signals are those to extract: linear prediction coefficients, cepstral coefficients, pitch, intensity, spectral analysis, and Mel's filter bank. The set of obtained characteristics is represented by a vector, which, for the process purposes, represents a pattern. The set of all vectors is then used to train the classifier, which is later on evaluated on data that was not used for training the model. For the evaluation process, a set of unknown feature vectors is compared with the knowledge that the computer has to measure the classification output efficiency. When using supervised learning methods for classification, as in our case, the knowledge is utilized to measure the error between the actual and the desired output during training. This knowledge is represented by the labels attached to each sample training vector.For our purposes, the study of the infant crying is performed through an automatic infant cry recognition process. In this work, besides applying some of the above mentioned acoustic extraction techniques, and forming the set of pattern vectors, we propose the use of a Genetic Selection method to generate a customized fuzzy model (GSFM) for the classification of infant cry. GSFM selects: the best combination of feature selection methods, the more adequate type of fuzzy processing, an appropriate learning algorithm, and its associated parameters that best fit the data. The viability of the proposed technique in the infant cry classification task is supported by the results obtained through experiments. In this paper we show the implementation stage as well as experiments and some results, in which up to 99.42% in recognition accuracy was obtained. According to our findings such accuracy rate can be obtained due to the right selection of a model totally adapted to the set of samples available for each experiment. Although the results were obtained for identifying cause of crying and differentiate between normal and pathological cry, it is our hypothesis that having available the right sample data base for training, our proposed method will perform well in the early identification of other infant disorders as those belonging to the Autism Spectrum Disorders.The remaining contents of our paper are organized as follows. In Section2 the acoustic feature extraction methods used are described, namely Mel Frequency, Cepstral Coefficients and Linear Predictive Coding. Section3 briefly describes the most used pattern recognition techniques and outlines some of the previous works conducting to the present model selection algorithms. It also explains the classification approach taken with particular detail on the presented Genetic Selection of a Fuzzy Model. The experiments designed and results obtained on each of them are detailed in Section4, where comparisons with similar methods are also provided. Finally, to round up the advantages of the proposed method, Section5 provides conclusions and outlines potential directions for future work.The acoustic analysis implies the application and selection of filter techniques, feature extraction, signal segmentation, and normalization. With the application of these techniques we try to describe the signal in terms of its fundamental components. One cry signal is complex and codifies more information than the one needed to be analyzed and processed in real time applications. For this reason, in our cry recognition system we use a feature extraction function as a first plane processor. As illustrated in Fig. 4, the input is a cry signal, and its output is a vector of features that characterizes key elements of the cry's sound wave.The acoustic features are extracted as follows (see Fig. 4): the original infant cry recordings are divided into 1-s segments, for each segment we extract 16 coefficients to every 50ms window, generating a total of 304 features from each 1-s sample. One should note that we do not use any noise-removal algorithms prior to the initial segmentation; since infant cry is very different from voice samples, it is normally mistaken as noise and most algorithms degrade the signal to an extent that the information contained in the sound wave is eliminated.In our study, we have been experimenting with diverse types of acoustic features, emphasizing, by their utility, Mel Frequency Cepstral Coefficients (MFCC) and Linear Predictive Coding (LPC) [32].In the literature, one can find a plethora of methods and techniques used for Automatic Speech Recognition (ASR) applications. Many of these works employ Mel Frequency Cepstral Coefficients (MFCC) to process the recorded sound waves [1,20,24,30,35,40,43,54]. In point of fact, since the mid-eighties MFCC has been the most widely used feature extraction method in the field of ASR [19]. The MFCC use a spectrum represented by a Mel filter bank (refer to Fig. 5) which has a frequency resolution similar to that of a human auditory system, and the hair-cell distribution inside, which has high resolution at low frequencies; the Mel Frequency scale corresponds to a linear scale below 1kHz, and a logarithmic scale above 1kHz (see Eq. (1)), making them useful for speech synthesis, recognition, and a better representation of sound [22].(1)FMel=100log(2)×1+FHz1000where FMelis the resulting frequency on the mel-scale measured in mels, and FHzis the normal frequency measured in Hertz (Hz). Commonly, the speech is divided into overlapping frames of 25 or 30ms, with 10ms overlap for the consecutive frames. Each one of these frames is processed by a Hamming window, to avoid distortion, and then a Fast Fourier Transform (FFT) is applied to each windowed excerpt. Next, the powers obtained in the last step are mapped onto the Mel filter bank by using triangular overlapping windows (see Fig. 5). A log energy output of each of the Mel frequencies is evaluated by applying the N-point discrete Fourier Transform of the discrete input signal x(n):(2)X(k)=∑n=0N−1x(n)exp−jπ2nkNNext, an equal area filter-bank Hi(k) is employed in the computation of the low-energy output:(3)Xi=log10∑k=0N−1∣X(k)∣×Hi(k)where i=1, 2, …, M and M is the number of filters in the filter-bank. Finally the discrete cosine transform of the list of Mel log powers is used as a signal (refer to Eq. (4)). This last step results in the MFCC features, which are the amplitudes of the resulting spectrum.(4)Cj=∑i=1MXicosj×i−12×πMwhere j=0, 1, …, J−1, and J is the number of MFCC that are needed. This technique is applied to the infant cry to generate the patterns that will help us recognize the type of pathology or message that the infant is trying to express. It is important to highlight that the frames used to divide the speech are different to the frames used for infant cry. Since there is no articulation of phonemes in the sound a child produces, we have more flexibility in the choice of time frames used to divide the sound waves. Moreover, it is expected that after processing the infant cry, each resulting vector represents a pattern which contains distinguishing MFCC features, as shown in Fig. 6[43].Similar to MFCC, Linear Predictive Coding (LPC) is another method widely used in the literature of ASR [15,18,28,29,39,42,58]. Numerous researchers select LPC as their feature extraction method because it is one of the most powerful speech analysis techniques, and one of the most advantageous methods applied to encode good quality speech at low bit rates, while providing at the same time accurate estimates of the speech signal. LPC was proposed for the first time as a method for encoding human speech by the United States Department of Defense in the federal standard 1015, published in 1984. The proposed algorithm enabled the user to encode understandable speech, with a very unnatural and synthetic quality, and with a file size 20 times smaller than a MP3 file [58]. In digital signal processing, LPC can be viewed as a subset of filter theory [32].In principle, LPC tries to imitate the resonant structure of the human vocal tract when a sound is produced [19]. In a nutshell, LPC starts with the assumption that a signal is produced by a buzzer at the end of a tube (vocal tract), with occasional hissing and popping sounds (sibilants and plosive sounds); this is a crude but a very close description of speech production. To extract the features from the sound previously produced, the input signal is divided into segments; again a Hamming window is used. Next, the LPC analysis is carried out by estimating the autocorrelation coefficients, as shown in the following expression [19,58]:(5)sˆ(n)=∑k=1paks(n−k)wheresˆ(n)is the predicted signal value, s(n−k) is the previous observed values, akis the predictor coefficients, and p is the linear predictor order, or a linear combination of p past samples. Finally, the autocorrelation between the frames is evaluated, and the LPC analysis is performed on the resulting autocorrelation coefficients. When processing speech, usually the segments have a similar size as in the previous method in order to detect the production of phonemes. But with infant cry, we again have more flexibility when setting the amount of time used to divide the cry. At the end, we use LPC to extract features and help represent the crying signals.All the infant cry recordings are processed with the freeware program Praat v4.0.8 [10]. A major advantage of this publicly available software is that it has a scripting language, which allows the user to prepare scripts for the automatic processing of the recordings. In this study we used three scripts to perform the needed tasks: (1) a script to automatically divide each file into a desired length (in seconds) and save each segment into a raw wave file; (2) another script to open each wav segment, extract the required coefficients (e.g., MFCC or LPC) into a short text file and save each text file; and (3) since each text file comes with a header, which is not needed for the training process, we used one final script to remove the header from each text file.Once all the text files are cleaned, we can use them for training or testing the models. The time to process a set of recordings heavily relies on the number and length of the sound files available to process. Nevertheless, while this part of the process is necessary for the whole processing of the infant cry recordings during the training and testing phases of the model, it is not necessary to repeat the same steps when the model is potentially used as a diagnostic tool. In a hypothetical real-world environment, the users will have access to the trained model, and a tool which receives a sound file (pre-recorded or acquired in-site) and returns a quick diagnostic, since the segmentation, processing, and testing of one single wave file is performed virtually in real-time.Several pattern recognition techniques have been used for the classification of infant cry. Among these techniques, artificial neural networks have been one of the most widely used [13,26,41,45]. With the same purpose, the use of support vector machines (SVMs) [7,48], hidden Markov models [33,34], as well as several hybrid approaches that combine fuzzy logic with neural networks [44,50–52], fuzzy logic with support vector machines [6] or evolutionary strategies with neural networks [23] have also been explored. Table 1summarizes the characteristics of previous studies around the infant cry recognition.Most of the previous works have reported favorable results in infant cry recognition. However, many efforts had to be devoted to the manual design of the classifiers with the intend to determine the set of adequate parameters for each technique to get the right classification of infant cry. In order to avoid useless hard work and many drawbacks, alternative approaches that combine genetic algorithms with fuzzy logic and neural networks have been proposed [5,46]. Nonetheless, most of the works only determine the parameters for a specific learning algorithm.Choosing an algorithm to classify instances from a specific domain with high accuracy is not an easy task, the task is even harder if we want to obtain the best possible result with the available resources. There are some domains for which obtaining the best possible accuracy might not be relevant but there are others in which this is a critical issue; this is the case of some medical systems.Finding the “best” classification method for a particular data set is the goal of a model selection algorithm. In order to effectively perform this task, the search space for a model considers different variables such as: selecting preprocessing method, features and instances that lead to better performance, as well as the classification method to use, together with its parameters.Previous work in this area has been done as in the case of Ayat et al. [2], in which the authors optimize the kernel parameters of a support vector machine (SVM) while reducing the number of support vectors in order to decrease the generalization error. Bao et al. [4] use a particle swarm optimization algorithm to optimize the parameters of an SVM too. Chapelle et al. [16] choose the parameters of an SVM by minimizing estimates of their generalization error using a gradient descent algorithm over the set of parameters.For the selection of models there are also multi-objective optimization approaches. In [3], the authors use Artificial Immune Systems (AIS) to optimize the parameters of the SVM using a multi-objective strategy (optimizing the kernel and penalizing the parameters of the SVM). Chatelain et al. [17] created a multi-objective and multi-model selection approach for model selection when the misclassification costs are unknown or might change over time. Suttorp and Igel [53] explore different multi-objective evolutionary approaches for SVM model selection. Li et al. [36] proposed a multi-objective uniform design search method for SVM model selection in order to reduce the computational cost of the model selection task while improving the classification ability. This model was applied to the face recognition problem.There are some other methods that try to reduce the intensive computation time consumed by model selection algorithms. This is the case of Gorissen et al. [25] that uses a surrogate environment with adaptive sampling guided through evolution.In this work we propose to explore the use of the Genetic Selection of a Fuzzy Model (GSFM) approach for infant cry classification. GSFM was recently proposed and it was applied to acute leukemia subtypes classification [47]. A genetic algorithm is used in GSFM for selecting the right combination of a feature selection method, the type of fuzzy processing, a learning algorithm, and their associated parameters that better fit to a data set. The goal of GSFM is to choose a combination of methods that minimizes the average error rate of the classes for a given data set. The rest of this section describes classification approach and in Section4 we show experimental results on the application of GSFM to the infant-cry data set.Genetic algorithms, proposed by Holland [27] in the 70s, are heuristic search techniques, which are inspired in Darwin's theory of evolution to solve problems using computational models. The genetic algorithms are based on the idea of survival of the fittest and reproduction strategies where stronger individuals have higher chances to create offsprings, and consequently are considered in the evolution process. Generally, genetic algorithms have five basic components: an encoding scheme, in a form of chromosomes or individuals, that represents the potential solutions to the problem, a form to create potential initial solutions, a fitness function to measure how close a chromosome is to the desired solution, selection operations and reproduction operators [21].In this work we use a hybrid algorithm called Genetic Selection of a Fuzzy Model (GSFM) to perform infant cry classification. The goal of GSFM is to find an effective classification model to be used for infant cry classification. We use GSFM to find a classification model for each of the considered data sets (see Section4.1). The obtained model was trained with a training data set, and this model was used to predict the testing set. In the following we detail the GSFM technique.The process of the construction of a fuzzy model is shown in Fig. 7. A labeled data set is the input. Given that each sample is described by a set of N features, and that N is usually large, the first step is to reduce the dimensionality of the data set. This task is done by applying a feature selection method. Then, the subset of selected features is converted into fuzzy values, which is the fuzzification step. Next, the parameters of fuzzy membership are fitted to reduce the overlapping degree. Finally, with the fuzzy features a fuzzy classifier is built. Given a pool of feature selection methods, fuzzy processing and learning algorithms, GSFM selects the combination of them that minimizes the error.GSFM has the advantage of considering different methods, Table 2describes each of the methods considered by GSFM and the corresponding hyper-parameters. We considered four feature selection methods (reliefF, χ2, information gain (InfoGain), and one based on correlation), the fuzzy pre-processing, which consists on choosing the number of linguistic properties (NLP), and the type of membership function (TMF), and four fuzzy classifiers (a fuzzy decision tree (FDT), A fuzzy decision forest (FDF), the fuzzy K nearest neighbors (FKNN), and the fuzzy relational neural network (FRNN)). Therefore, GSFM explores the models space and it picks up the best one according to a given criterion. It is worthnoting that each model is composed by a combination of a feature selection step, a pre-processing step and the learning algorithm together with its hyper-parameters. This results in a vast model space, which could be computationally intractable. Stochastic search techniques are well-suited to deal with these cases. In particular, GSFM uses a genetic algorithm to this aim.In GSFM, each model (a combination of feature selection method, pre-processing method and learning algorithm together with its hyper-parameters) is represented by a chromosome. This chromosome, also known as individual, is a 15-dimensional binary vector, as follows:(6)x(i)=[fs1,fs2,hp1fs,…,hp4fs,hp1fp,…,hp4fp,fc1,fc2,hp1Fc,…,hp3fc]where fs1, fs2 are two bits that control the feature selection method to be used;hp1fs,…,hp4fsare the hyper-parameters for the selected feature selection method;hp1fp,…,hp4fpare the fuzzy pre-processing's hyper-parameters, andfc1,fc2,hp1Fc,…,hp3fcare the learning algorithm and its hyper-parameters.The goal of genetic operations is to create new individuals from existing ones. The selection operation, which is one of the genetic operations, selects the parents to be crossed, giving preference to the fittest individuals. However, individuals who represent a type of learning algorithm may be less selected, due to its low fitness value, than others causing the number of these individuals to become smaller and disappear in future generations.When the size of the population of individuals that represent a type of learning algorithm is lower than a threshold α, the surviving individuals for this type are copied, mutated and subsequently added to the population. This step is performed in order to avoid the extinction of these individuals, as well as to maintain the diversity of the different models. In order to ensure that the population size remains constant, the individuals (i.e., classification models) with a bad performance are removed, starting with the one with the worst performance, following by the second one and so on until the number of individuals is equal to the population size.In each generation in the genetic algorithm, a population of individuals is evaluated with the fitness function, and the fitness value is used to choose the individuals for reproduction, and this process is repeated until a number of generations is reached. In GSFM, individuals are classification models, hence we need a way to evaluate the goodness (fitness) of a classification model, in this case we considered the balanced error rate (BER). The BER is the average of the errors incurred by a classifier on each class i and it is computed as follows:(7)BER=1j∑i=1jeiwhere j is the number of classes in the data set and eiis the error rate of the classification model in the ith class, that is, the fraction of instances of class i that were misclassified by the model. Since all we have for estimating the performance of models is training data, we may compute the performance of models in these data. However, as the models were trained using such data, estimating the BER on training data directly would lead to optimistic estimates. Instead we adopted a 2-fold cross validation procedure over the training set to estimate it. In this way, training data is split into two disjoint subsets, one is used for training the model and in the other we assess the model's performance, next we interchange the subsets and repeat the process. The fitness of the model is the average BER over the two subsets. In this manner, the performance of the model is estimated on data that was not used to train the model.The BER is in the range [0, 1], where a value of 0 indicates that a classification model correctly predicts all samples, whereas a value of 1 indicates that a classifier has incorrectly predicted all of the samples. Hence, the goal of GSFM is to minimize the BER.

@&#CONCLUSIONS@&#
