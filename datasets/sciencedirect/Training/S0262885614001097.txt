@&#MAIN-TITLE@&#
A spectral independent approach for physiological and geometric based face recognition in the visible, middle-wave and long-wave infrared bands

@&#HIGHLIGHTS@&#
Propose new automated tri-spectral (visible, MWIR and LWIR) FR approachDesign experiments to quantitatively measure benefits of global vs. local matchersEvaluation of global vs. local based matchers when fused at the score levelAchieve rank-1 identification rate of at least 99.43% per spectrum of operation

@&#KEYPHRASES@&#
Face recognition,Visible,Middle-wave infrared,Long-wave infrared,Fiducial point extraction and matching,

@&#ABSTRACT@&#
Graphical abstract

@&#INTRODUCTION@&#


@&#CONCLUSIONS@&#
In this paper, we investigated the use of extracted face based features composed of veins, edges, wrinkles, and perimeter lines, using two different matchers for face recognition. The experiments were carried out across the visible band and passive (MWIR and LWIR) bands for canonized faces. For the global matcher, the best performance was achieved in the MWIR spectrum with 99.47% rank-1 accuracy. For the local matcher, the best performance was achieved in the visible spectrum with 98.95% rank-1 accuracy. The number of subjects our system incorrectly identifies can be decreased, and overall performance increased with the addition of samples to the image gallery. Although the global matcher is computationally efficient, the local matcher outperforms the global matcher across the visible and MWIR spectrums. When matchers are fused, rank-1 accuracy of at least 99.43% is achieved across all spectrums.A subset of each dataset was used for experimenting on different methods for feature point detection, along with matching individual parts of the face, such as the eye, nose, and chin regions. A very interesting result from our study was in the case where our proposed methodology was applied to the disjointed face sub-region (i.e. the region of the face excluding the eyes, nose, and chin regions) in the MWIR spectrum. In this case we achieved at least a 93% rank-1 accuracy using the global matcher and 99% rank-1 accuracy using the local matcher. Another interesting result in the MWIR spectrum was that the mouth region could be matched using our global matcher with 94% confidence. These partial face matching results suggest that the features extracted around the cheek, forehead and chin regions are unique per individual, particularly in the MWIR spectrum. It appears that our global matcher outperforms our local matcher in matching sub-facial regions for each spectrum except the MWIR spectrum. Fusing matchers for sub-facial regions does not always increase the recognition performance, but performance is always increased for holistic face matching when matchers are fused. For each subset of our databases, it took less time to match subjects using the global matcher in comparison to the local matcher. Through our experiments and baseline comparison, we can conclude that the FR in LWIR spectrum doesn't perform as well as FR in the visible spectrum. However, a reason for the decrease in performance may be due to the lower resolution images in our LWIR dataset.Skin segmentation remains a difficult task, particularly in the visible spectrum due to variations in illumination, therefore requiring a number of different thresholds for the task. However, because the visible spectrum is a traditional research area in biometrics, pre-processing tasks such as eye detection hold an advantage in the visible spectrum. Eye detection in the passive infrared band is an area that still needs some attention. Per our robustness experiments, photometric normalization techniques such as CLAHE appear to offer little to no advantage for our local matcher, however CLAHE may be advantageous for our global matcher. Due to the use of physiological and geometric features for our matchers, eye detection accuracy is a crucial to the sensitivity of our automated system. An advantage to our proposed approach is that it is fully automated and does not require a design and the usage of a training set. This saves a lot of computational time and effort in processing. Another observation is that our pre-processing step reduces image storage size for a given subject from as large as 3MB after video extraction, down to 1kB, which is beneficial when storing a large number of subjects. Despite the fact that we only dealt with frontal face images, the design of our pre-processing step turned to be very important in achieving high recognition rates. Furthermore, although users could be identified using parts of the face instead of the whole face, face sub-regions should be used in conjunction with other biometric approaches to boost performance. This needs further investigation, and if such an observation holds in large datasets, it can assist current FR systems in cases of facial occlusion or disguise. Following that, the application of our proposed methodology to datasets consisting of subjects with facial occlusion or disguise intending to counterfeit a biometric system would provide further insights in this research field. Also, to further validate the efficiency of our proposed FR approach and matchers, other datasets such as that of the University of Notre Dame [23,27] should also be considered. Our results suggest that our algorithm is robust to minor pose and expression variations, assuming that the face is normalized accurately and similar poses are matched to one another. In the context of a biometric system, we need to be able to estimate a pose angle for the subject's face in order to constrain matches to similar poses. A quick solution that alleviates this challenge is the use of different poses as samples for each respective subject in both gallery and probe. Nevertheless, this would result in an increase of the computational complexity of our proposed system that could be avoided with prior knowledge of the pose angle. The problem of automated pose estimation and side-profile FR across the visible, MWIR and LWIR spectrums will be part of our future work. Finally, another area that merits further investigation is the use of object-oriented code and parallel computing to speed up local fiducial point extraction and matching.