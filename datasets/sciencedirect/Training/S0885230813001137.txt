@&#MAIN-TITLE@&#
The glottaltopogram: A method of analyzing high-speed images of the vocal folds

@&#HIGHLIGHTS@&#
We propose a method to visualize laryngeal high-speed video in an intuitive way.This method reveals the overall synchronization of the glottal vibratory patterns.This method visualizes pathological and normal glottal vibratory patterns.

@&#KEYPHRASES@&#
High-speed videoendoscopy,Vocal fold vibration,Principal component analysis,

@&#ABSTRACT@&#
Laryngeal high-speed videoendoscopy is a state-of-the-art technique to examine physiological vibrational patterns of the vocal folds. With sampling rates of thousands of frames per second, high-speed videoendoscopy produces a large amount of data that is difficult to analyze subjectively. In order to visualize high-speed video in a straightforward and intuitive way, many methods have been proposed to condense the three-dimensional data into a few static images that preserve characteristics of the underlying vocal fold vibratory patterns. In this paper, we propose the “glottaltopogram,” which is based on principal component analysis of changes over time in the brightness of each pixel in consecutive video images. This method reveals the overall synchronization of the vibrational patterns of the vocal folds over the entire laryngeal area. Experimental results showed that this method is effective in visualizing pathological and normal vocal fold vibratory patterns.

@&#INTRODUCTION@&#
Clinicians and speech scientists have developed a number of techniques to observe vocal fold vibrations, including electroglottography (Baken, 1992), photoglottography (Sonesson, 1959), stroboscopy (Kitzing, 1985), and videokymography (Švec and Schutte, 1996). Recently, high-speed video (HSV) of the larynx has emerged as the state of the art in laryngeal imaging, due to increased recording frame rates, improved image resolution, and the decreasing cost of high-speed recording devices.The study of HSV remains limited, however, by the large amount of 3-dimensional data produced (Fig. 1), so that images are inherently difficult to interpret visually and usually require subjective assessment. Because humans are better at discriminating characteristics of static than of dynamic images (which impose a memory load), many methods have been proposed to reduce the dimensionality of spatial–temporal HSV data and condense the time-varying video into a few static images that preserve the most important characteristics of the vibratory patterns. In this study, we propose a new computationally-efficient method—the glottaltopogram—to compactly summarize the overall spatial synchronization pattern of vocal fold vibration for the entire glottal area, in a manner that can be intuitively interpreted. Such a method may produce plots that are spatially similar to the original images, and which can be easily interpreted by physicians and clinicians during diagnosis.Many previously described methods for analyzing HSV data depend on glottal area segmentation (Lohscheller et al., 2008; Karakozoglou et al., 2012; Döllinger et al., 2011; Yan et al., 2005). Automatic segmentation of the glottal area from HSV is in itself a challenging task, and a number of methods have been proposed. The most straightforward is thresholding, in which pixels with brightness lower than a certain threshold are treated as part of the glottis (e.g., Mehta et al., 2010, 2011). The threshold is typically specified based on a histogram of the image, where several peaks are assumed to exist due to clustering of glottal and non-glottal regions. However, this method is unsatisfactory when contrast is low, because segmentation performance is sensitive to threshold selection. In addition, this method is not fully automatic because it typically requires manual adjustment of thresholds over time. Other approaches to glottal area segmentation apply seeded region-growing algorithms. After manually selecting seeds from the image, neighboring pixels are examined to decide whether they should be added to the region, subject to criteria that vary from implementation to implementation (Adams and Bischof, 1994; Yan et al., 2006; Lohscheller et al., 2007). This method typically requires clear glottal edges to produce a correct result.The segmented glottal area can subsequently be analyzed to reveal spatial and/or temporal variations in glottal vibratory patterns. For example, in phonovibrography (PVG; Lohscheller et al., 2008), the segmented glottal area is transformed into a geometric pattern representing the distance from the glottal edges to the glottal center line axis. In terms of the representation in Fig. 1, PVG condenses the x and y axes into one axis by mapping along the glottal edge trajectory, so that temporal resolution is perfectly maintained but spatial resolution is limited to the glottal edge trajectory. This method is sensitive to detection of the glottal center line axis, which strongly depends on the geometry of the detected glottal area (Karakozoglou et al., 2012) and can be difficult to identify accurately in the presence of a posterior glottal chink (glottal gap). A visual representation termed the “glottovibrogram” extends the PVG method (Karakozoglou et al., 2012; Döllinger et al., 2011). Glottovibrograms measure the distance between vocal fold contours instead of the distance to the glottal center-line axis, but visualization and interpretation of alterations in subsequent cycles remain unintuitive. Recently, Unger et al. (2013) proposed a PVG-wavegram to reveal inter-cycle characteristics of vocal fold vibrations across long sequences, where individual cycles of a PVG are segmented, normalized for cycle duration, and concatenated over time. Yan et al. (2005) applied a Hilbert transform to glottal area waveforms to analyze perturbation and periodicity. However, analyses of the glottal area waveforms do not preserve spatial information about vocal fold vibration, limiting applicability for interpreting spatial vibratory features such as asymmetry.Despite these efforts, segmentation of the glottal area remains a non-trivial task. Results depend on the quality of the HSV data, including image contrast and the clarity of the glottal edge. Manual interactions are typically needed, such as initial seed assignment or threshold selection, and the segmented glottal area sequence requires inspection. In addition, segmentation of the glottal area typically requires processing the HSV data on a frame-by-frame basis, and the long computational time required for image processing limits the applicability of glottal-area based approaches under clinical conditions, where prompt results are preferred.Other HSV analysis tools do not rely on glottal area segmentation. The most common of these, kymography (Tigges et al., 1999; Larsson et al., 2000), reduces data dimensionality by selecting pixels with a given value on the y axis (anterior–posterior dimension; Fig. 1)—or several values in multiplane kymography—usually chosen near the glottal midpoint. By limiting resolution along the y axis, kymography essentially collapses image analysis along the anterior–posterior dimension, so that temporal resolution is lossless but spatial resolution is limited to at most a few points. In a second method, temporal oscillation patterns across the entire laryngeal area are visualized by applying a Fourier transform to the light intensity time sequences from sequential high-speed images (Granqvist and Lindestad, 2001). The resulting signal contains amplitude and phase information as a function of frequency, and is displayed as color saturation on top of a single image selected from the original sequence, to characterize vibrational characteristics of the entire laryngeal area. On the basis of this work, Sakakibara et al. (2010) proposed a third method they called “laryngotopography” to visualize spatial characteristics of the Fourier spectra of the pixel-wise brightness curves (e.g., the frequency component that has the maximum amplitude in the Fourier spectra), which they claimed was effective in visualizing various vibrational modes of the vocal folds of patients with paralysis and cysts. Laryngotopography compresses the time axis by mapping the pixel-wise brightness scale time course into several transformed coefficients, where temporal information is condensed but spatial resolution is fully preserved. In other words, while kymography has limited spatial resolution, laryngotopography maintains the spatial characteristics of the entire image but focuses only on a single frequency component of the spectrum of the vibrational pattern.In this paper, we propose the “glottaltopogram” to visualize HSV data. In this method, principal component analysis (PCA) is applied to light intensity time sequences from consecutive high-speed images and PCA coefficients are visualized. The proposed method reveals the overall spatial synchronization pattern of the vocal fold vibrations for the entire laryngeal area, rather than focusing on a specific location or frequency. Full spatial resolution is maintained, although the time axis is not preserved. Further, the proposed method does not rely on segmentation of the glottal area, and is robust to perturbations of video quality that might result in artifacts during glottal area detection. With minimal user interaction and fast processing time, glottaltopography provides an automatic way of finding the region of interest from the entire image and is suitable for clinical application. Comparisons between analyses of pathological and normal data, described in the next sections of this paper, show that the proposed method is effective in visualizing a wide variety of vocal fold vibrational patterns. Additional comparisons between glottaltopograms and kymograms show the manner in which these two analysis techniques (one that compresses the time axis, and one that compresses area) can complement each other in understanding glottal vibration.High-speed images were recorded at 4000frames/s using a 70° rigid laryngoscope (KayPentax, Lincoln Park, New Jersey) with a 300W Xenon light source (KayPentax, Lincoln Park, New Jersey) and a Color High-Speed Video System, Model 9710 (KayPentax, Lincoln Park, New Jersey). The image resolution was 512 pixels×256 pixels and the color mode was 8bit RGB. Audio signals were synchronously recorded with a Brüel & Kjær microphone (1.27cm diameter; type 4193-L-004) and directly digitized at a sampling rate of 40kHz, with a conditioning amplifier (NEXUS 2690, Brüel & Kjær, Denmark). Four subjects (3 males, denoted by M1–M3, and 1 female, denoted by F1) without voice disorders were recorded saying the vowel /i/ with breathy, modal, and pressed voice qualities (although for the male speakers only the modal voice samples were examined in this paper). Similar to Chen et al. (2013), normal subjects were phonetically knowledgeable and voice quality was demonstrated by a phonetician prior to each recording. Four additional male subjects with voice disorders (denoted by PM1–PM4) were also recorded while saying /i/ using their habitual pitch and loudness. All subjects were asked to sustain the phonation for at least one second during rigid endoscopy.High-speed images were first converted from RGB to brightness scale. Due to illumination conditions, brightness of some glare spots needed to be adjusted before subsequent pixel brightness scale analysis (Fig. 2), because their brightness did not reflect actual vocal fold movement. Histogram equalization was performed manually (through an interactive graphical user interface) to enhance edge contrast of the vocal folds and remove the glare spots as much as possible. Compared to the original image in panel (a), the glare spots in the posterior glottis have been removed after the brightness adjustment in panel (b). Note that although the overall brightness increased after the adjustment, the contrast between glottal and non-glottal areas in the image was enhanced. The brightness of vocal folds approaches its maximum value and the brightness of the glottal open area approaches 0 (a non-linear transformation from physical position to light intensity), so that brightness curves better represent movements of the vocal folds.One PCA was performed for each HSV recording. A rectangular window was manually selected to isolate the image region containing the vocal folds (Fig. 3). To ensure the representativeness of each function, the brightness scale time course was extracted across 300 consecutive frames (roughly 8–15 glottal cycles depending on the speaker's fundamental frequency) for each pixel inside the rectangular window. The number of pixels included in each analysis differed across recordings, ranging roughly from 5000 to 10,000, depending on the distance of the laryngoscope from the glottis.The amplitude values for the brightness scale time course for each pixel served as input to the PCA, which was implemented using the Matlab Toolbox for Dimensionality Reduction (van der Maaten, 2011). Specifically, for a given HSV, ifgi,jtis a 1-by-N vector and contains the glottal vibration information at pixel location (i, j), then:(1)g(i,j)(t)=[bi,j(1),bi,j(2),…,bi,j(N)]denotes the brightness time sequence (from frame 1 to frame N) at pixel location (i, j), where1≤i≤W,1≤j≤H,W is the image width, H is the image height, N is the total number of image frames, t is the frame index, andb(i,j)(k)denotes the brightness value of pixel (i, j) at frame index k. Examples ofg(i,j)(t)are shown in the panels surrounding the central image in Fig. 3.After performing a mean subtraction (for each frame) to ensure each frame has a zero mean for the brightness scale, a PCA was conducted. PCA models the brightness time sequence g(t), treating each spatial pixel as a “repetition” of the experiment and each frame as a “feature”. The matrix G in Eq. (2) was thus built and used as the input to PCA. This W×H-by-N matrix G was constructed by concatenating all the brightness scale time sequences across all pixels in the video:(2)GW×H,Ng(1,1)(t)g(1,2)(t)⋮g(1,H)(t)g(2,1)(t)g(2,2)(t)⋮g(2,H)(t)⋮g(W,H)(t)This matrix G losslessly contains all the glottal vibration information from the video under study. Each brightness time sequenceg(i,j)(t)can be decomposed as:(3)g(i,j)(t)=αi,j⋅PC1(t)+βi,j⋅PC2(t)+ei,j(t)wherePC1(t)andPC2(t)are the first two principal components (orthogonal bases),αi,jandβi,jare projections on the principal components, andei,j(t)is the error term. Unlike conventional PCAs which are applied to model multiple images in other studies (e.g., face recognition), the PCA used in this study was applied to model the brightness time sequence, treating a spatial pixel's sequence as a “repetition”. One PCA was conducted to model the brightness scale time sequences from all spatial points within a single recording. Thus, the basis of the PCA (principal component) was the same for all spatial points within that recording. That is, a single matrix G was derived for each individual video, so thatPC1andPC2did not depend on pixel locations (i, j).For each brightness scale time sequencegi,jt, the first two PCA coefficientsα(i,j)andβ(i,j)(projections on the first two principal components, PC1 and PC2) were calculated. The coefficients were normalized to an 8bit (0–255) scale and visualized at the original pixel location (i, j) in terms of color saturation to facilitate interpretation. The brightness scale curve was then reconstructed using the first two coefficients and principal components. Mean square reconstruction errors (mean square ofe(i,j)(t)) were calculated and visualized in the same way. In the final stage, the percentage of variance explained by the first two principal components (eigenvalues, or energy, corresponding to the orthogonal bases) was calculated, which partially reflects the energy compactness of PCA (synchronization of the glottal vibration).By performing PCA, the glottal vibratory pattern represented by the brightness scale time courses is presumably “mapped” to a two-dimensional space captured by PC1 and PC2, given that PC1 and PC2 can account for the majority of the variance in the time-varying data. That is, glottaltopography compresses the time axis by mapping the pixel-wise brightness scale time course into the PCA coefficients, where temporal information is condensed into a single static image but spatial resolution is fully preserved. Pixels with similar brightness scale time courses should have similar PCA coefficients, which are represented in the glottaltopogram as similar colors. Recall that the PCA for each HSV recording was based on brightness scale time sequences from all spatial points within this video, which ensures homogeneity across the spatial points within one HSV recording. Thus, if the left and right vocal folds are vibrating symmetrically, the pixels on the two folds should also exhibit similar brightness scale time sequences. This similarity should be captured by the first two PCA coefficients and the derived images should exhibit symmetric color patterns. If the left and right vocal folds are vibrating asymmetrically, as might occur in a vocal fold paralysis, this asymmetry should result in a glottaltopogram with asymmetric color patterns. Similarly, a glottal region with highly aperiodic vibrations will appear with a distinct color pattern with respect to the remaining steady-vibrating region. When vibration of the two vocal folds is synchronized, the variance accounted for by the principal components should be higher (more compact energy concentration) than when vibrations are unsynchronized, because synchronization results in similar pixel-wise brightness scale time sequences. Similarly, the pixel-wise mean square reconstruction error should be generally low and (roughly) evenly distributed across pixels when glottal vibration is synchronized, while higher reconstruction errors should be observed in laryngeal regions exhibiting unsynchronized glottal vibrations.

@&#CONCLUSIONS@&#
Data reduction methods like glottaltopography all reduce HSV data from 3 dimensions to 2, which inevitably leads to loss of information, either temporal or spatial. In this sense, glottaltopography, kymography, and laryngotopography visualize different aspects of HSV data, by maintaining information from different dimensions, but no one method “outperforms” the others. However, the results presented here show how methods can be combined to analyze and interpret HSV data while overcoming the limitations inherent in each individual visualization approach.Two attributes of glottaltopography make it a particularly useful addition to the set of methods available for working with HSV data. First, glottaltopography is robust (especially when compared to methods like PVG requiring glottal area segmentation) when used with HSV data with variations in contrast levels, random noise during recordings, and multiple glottal gaps, where detection of the glottal edges is inherently difficult. Because some subjects have difficulty tolerating a rigid endoscope, it can be impractical to create multiple high-speed recordings of the same subject in clinical application, and the ability to adjust focus and illumination levels during recording may be limited by the need to complete an exam quickly. As a result, recorded HSV data are often suboptimal in quality (Lohscheller et al., 2007), so that robustness is an important advantage of the method described here.Secondly, the computational complexity of the glottaltopogram is much lower than that of methods based on glottal area segmentation (e.g., PVG), where the detection of glottal area has to be implemented for each image on a frame-by-frame basis. A glottaltopogram can be generated from 300 video frames in under 5s, while calculating a PVG typically takes a few minutes and involves visual inspection of (at least a few) key frames to ensure the accuracy of glottal area detection.The first PCA coefficient describes the projection on the dimension that represents the maximum variance in the underlying HSV data. In the present data, this first coefficient always roughly represents the mean of the pixel's brightness scale time sequence, which predominantly depends on the average shape of the glottal area. The second PCA coefficient shows more variability in vibrational pattern across pixel locations, and thus differed more from speaker to speaker. For both synchronized and unsynchronized vocal fold vibrations, the first two PCA coefficients accounted for an average of almost 88% of the variance, largely due to the prevalent quasi-periodic shapes of the brightness scale time sequences among pixels that resulted from quasi-periodic vocal fold vibrations (Table 1). This also indicates that the mapping into PCA coefficients substantially maintains the characteristics of vocal fold vibration, as represented by brightness scale time sequences.It is often claimed that healthy voices are characterized by symmetric, periodic vocal fold vibrations (Hertegård et al., 2003; Döllinger et al., 2003), and previous studies have sometimes found links between the presence of asymmetric vocal fold vibration and degradations in perceived voice quality in patients with voice disorders (Niimi and Miyaji, 2000; Verdonck-de Leeuw et al., 2001). The present data are not entirely consistent with this scenario. Although the manner in which vibratory asymmetries or phase lags affect perceived voice quality is far from well understood, virtually all of the glottaltopograms of phonation from normal speakers revealed at least minor asymmetries (and in some cases very large asymmetries) in vibratory patterns. We note that a recent study based on physical vocal fold models showed that left-right asymmetry in vocal fold vibration does not produce a perceivable perceptual effect unless the asymmetry is so large that it causes a change in vibratory mode (Zhang et al., 2013). The potential applicability of detecting unsynchronized vocal folds vibration via glottaltopography in clinical settings may provide the data needed to explicate which asymmetries are clinically significant, and which have little or no impact on voice quality. In this way, this method constitutes a promising aid in studying the perceptual consequences of irregular vocal fold vibrations among normal subjects and patients.