@&#MAIN-TITLE@&#
Self-adjusting focus of attention in combination with a genetic fuzzy system for improving a laser environment control device system

@&#HIGHLIGHTS@&#
New interaction system in real environments by means of a laser pointer.New approach using a self-adjusting focus of attention that increases the results.The paper can detect the laser spot in a real environment.The system uses: genetic fuzzy systems and genetic programming to self-adjust the FOA.

@&#KEYPHRASES@&#
Self-adjusting,Focus of attention,Laser pointer,Environment control systems,Genetic fuzzy systems,

@&#ABSTRACT@&#
This paper presents a new algorithm capable of improving the accuracy level of a laser pointer detector used within an interactive control device system. A genetic programming based approach has been employed to develop a focus of attention algorithm, which works cooperatively with a genetic fuzzy system. The idea is to improve the detection of laser-spots depicted on images captured by video cameras working on home environments. The new and more accurate detection system, in combination with an environment control system, allows to send correct orders to home devices. The algorithm is capable of eradicating false offs, thus preventing devices to autonomously activate/deactivate appliances when orders have not been really signalled by users. Moreover, by adding self-adjusting capabilities with a genetic fuzzy system the computer vision algorithm focuses its attention on a narrower area of the image. Extensive experimental results show that the combination of the focus of attention technique with dynamic thresholding and genetic fuzzy systems improves significantly the accuracy of the laser-spot detection system while maintaining extremely low false off rates in comparison with previous approaches.Human beings feature both the desire and need to control the environment, probably as a result of attempting to improve their quality of life. For example, in prehistory when fire taming could mean a difference between life and death; later on history while managing and manipulating natural resources as in agriculture; and more recently with the arrival of the technological society where a plethora of electronic devices are nowadays part of our life.Today, every conventional-home features tens of electronic devices that should be manipulated with ease. Technology should be helpful in providing smooth interaction with home appliances with the aim of transforming it into the new smart-home concept.Nowadays, smart homes are particularly helpful for elderly or handicapped people [1,2], who will benefit from a proper application of technology. As a result, an easy-to-use interactive system, capable of controlling different home devices, is required.An interactive system can be defined as: a set of interrelated objects neatly exercising an interplay between them. This concept can be applied to smart homes [3,4] thus providing environment control systems. We can find in the state of the art several approaches available in environment control systems. But we want to develop simpler interaction systems, by using a laser pointer as a basic interaction device.The distinctiveness of our approach is the application of computer vision and computational intelligence techniques with the aim that the system should be capable of detecting laser spots and converting the signals into suitable domotic control orders. This paper continues the improving of our previous approach built on the latest results presented in [5] where different algorithms were tested to correctly detect a laser spot.On the one hand, our earlier attempts presented in [6–8] applied several classical computer vision techniques, such us dynamic thresholding (DT) and template matching (TM), which were integrated into a decision making algorithm. On the other hand, we also analyzed the replacement of DT by a new soft computing based decision making system in [5,9–12] as well as genetic fuzzy systems (GFSs) [13–15], which in combination with TM allowed us to provide good accuracy for the problem of laser-spot detection.Both approaches, using classical techniques and soft computing based ones, feature the same problem: TM always incur on a number of errors that are fed into the system, then making the system incapable of avoiding such errors. As a result, a number of false negatives and false positives (also called false offs) appears in the decision process. Yet, the decision making system requires such previous process that provides the values for the classification: images with or without a laser spot.This paper presents an approach to improve the accuracy of the whole system: Instead of trying to improve the decision making algorithm, we focus on the previous techniques in charge of extracting and providing the main features required for the final decision. The main contribution of this paper is thus the application of a new genetic programming based technique, called the focus of attention (FOA) algorithm, capable of regulating the algorithm according to environmental light conditions with, the aim of providing better extracted features and smaller image areas. We compare the approach with previous methods and provide results that show noteworthy scores in the false offs that are maintained at an extremely low level while the new method also increases the laser-spot detection accuracy.The rest of the paper is organized as follows: The state of the art is presented in Section 2. The classical algorithms are described in Sections 3, and Section 4 describes the whole laser pointer based environment control system. The new FOA-based approach is introduced in Section 5. The results are provided in Section 6. Finally, the conclusions are drawn in Section 7.In the literature, different environment control systems have already been described; see [4,6,16–22]. Note that, a large set of previous works, where different techniques are used, are based on laser pointers; see Table 1. In those works, the goal is to interact with a projection screen by means of the laser pointer. In our previous works, we attempt to extend similar capabilities in such a way of enhancing the interaction with devices considering a real-home environment. The idea allows users to send orders by projecting laser spots onto home devices in combination with domotic control systems [6,7,9–12,23].Table 1 includes a summary of the previous works employing laser pointer as a pointing device. The aims of these works are to be able to control different objects (i) presented on a large display, (ii) within an environment where a robot has to pick them up or (iii) with the aim of detecting imperfections in buildings. Different techniques have been used for solving the problem of detecting the laser spot, such as threshold value, pattern recognition, colour analysis, etc. Kirstein and Müller used an algorithm divided in three phases for detecting the laser spot. The phases were, motion detection, pattern recognition and histograms comparison [24], with these techniques, the laser spot was detected only on 50% of the frames.Another standard technique used in previous works is thresholding. This technique consists of calculating a value, using all the information that is possible to detect from the laser spot in an image. The process to calculate such value is common in the works presented in Table 1. Note that it is necessary to analyze the brightness of the image to correctly calculate the threshold value of the laser spot. These works are characterized by the difficulty for detecting the laser spot in environments where the light conditions are not favorable.Other classical vision techniques incorporate a well-known algorithm called template matching, see [6,7,12,24–26]. In our problem a laser spot has a peculiar characteristic: it is similar to a circle. If the laser pointer is aimed directly towards a surface, a red or green circle is drawn. For this reason, authors applied different techniques to find a circle in the image. The technique consists of calculating the position of the laser spot by means of a convolutional process that searches around the whole image. Thus, the image section with the highest convolutional value is designated as the location of the laser spot.A different technique that is also applied to detect the laser spot is employed in [27–31]. The algorithm uses different colour bands: red, green and blue (RGB) and Hue, Saturation and Intensity (HSI) to provide with a richer information that is useful for detecting the laser spot on an image. Thus, a video-camera takes a colour image in the RGB space system and the algorithm changes it to the HSI system. As a result, the laser spot is detected, by means of segmented functions or threshold values according to the applied colour system.The main drawback in these previous works is that light conditions, orientations and textures, need to be controlled and fixed. For example, the laser spot cannot be detected correctly if there is a high brightness on a screen projection. Moreover, since previous approaches typically present many false offs, the proposed techniques require whole new processes. Table 1 presents a summary of the above described works together with others that use cameras or display filters, video analysis, camera networks, and hardware-based approaches.We can observe that light conditions and textures are the main problem for detecting correctly the laser spot. Also, we could say that for most of the cases the algorithms work in controlled light-environment conditions. As a result, it is easier to locate the laser spot in comparison with a real home environment, where brightness of light conditions are almost impossible to control, leading the algorithms’ attempt to solve uncontrollable situations.We describe here some of the classic computer vision techniques we have employed as our base case for comparison. As described above these techniques have been frequently employed before, (see Table 1), and allows us to compare their behaviours. Moreover, we already considered such techniques in some of our previous works [5–12].Dynamic thresholding was the first algorithm that we applied for image feature extraction and it was also considered as the basic routine for the decision making system. Such algorithm applies a threshold value to extract candidate pixels for laser-spot detection. Fig. 1shows two images with a laser spot for different lightning conditions. We observe that the laser spot has different sizes depending on: the light conditions and distance to the wall; hence, the two affect how the spot is projected into the camera. Moreover, laser-spot pixels also feature different energy values; hence, it was necessary to establish a dynamic threshold value that adapt according to light conditions.In a first step, the algorithm tries to calculate the threshold value; then, pixels under this value are eliminated at the time of searching for the laser spot. Interested readers can check the whole process in [6–8].Despite carefully analysing this classic technique, that we improved with the dynamic thresholding technique, the results obtained were still unsatisfactory. Hence, we decide to add a second technique, known as template matching (TM), that was also tested by some authors, with the idea of combining it with the previous approach to help the process of feature selection. TM requires a template to be searched within the studied image. In our case, several templates of laser spots, projected in a standard surface at different distances, were computed and saved as a database for further processing. Fig. 2shows examples of a laser template image. The process to obtain the laser template is explained in detail in [6].Once several laser templates have been obtained, the algorithm uses the templates to search for the most similar image section. Note that this algorithm works with the complete image sent by the video camera as in the DT algorithm. The algorithm uses the convolution technique known as zero mean normalize cross correlation (ZMNCC) [51,52]. In this way, the algorithm compares the selected laser template with the image section that was sent by the video-camera. As a result, a correlation value between both images is obtained, and if this value is greater than a threshold, indicated by the user, the image section is saved in a vector of correlation images. Then, when the process is finished the vector is sorted according to the correlation value. As a rule of thumb, the image with the highest value is considered as the selected laser spot image. The complete process is explained in [6–8].We have thus considered the combination of these two classic techniques, already employed by other authors (although separately), as our basic test for comparing the new algorithms introduced in the following sections. The results obtained will be shown to asses the advantages of the new methods.In order to provide with a home environment laser-pointer interactive system, we need a number of modules that cooperate to achieve the desired functionality. Although the main goal of this paper is to improve the laser-spot detection system, we provide here a summary of the whole system including their components and relationships. In particular, the system includes a tool that helps the system to adapt to new environments by providing the location of controllable devices. We consider that the domotic system should be already available in order to send/receive orders to/from the devices. The new system will work in collaboration with it, by providing a new and easier way to use the interactive system.When the users want to use a home appliance, they select the device by aiming it with a laser pointer. Several low-cost video-cameras are located on different home rooms, taking images with a pre-specified frequency (several times per second) and sending the images to be analyzed by the algorithms in charge of the laser spot detection. Once the laser spot is detected a control order is sent to the domotic control system to switch on-off the home device selected by the user. Thus, the whole system is divided into three different sections: control section, image analysis section, and domotic control section; see Fig. 3.•Section 1: setup module: Control tool in charge of initializing the system. It allows users to mark the areas where devices are located, so that they can be controlled by the domotic system. By means of this tool, the user can define the areas of interest where the laser spot will be searched for. These areas are called active zones.Section 2: image processing module: A number of algorithms are used for analyzing the images sent by the video-camera while searching the laser spot in an active zone.Section 3: domotic interactive module: By means of a domotic system, control orders can be sent to the different home appliances [53]. The order will correspond to the device located in the active zone where the laser spot is detected.The system needs to know where the home appliances are located and how they will be controlled. The user is in charge of specifying the areas of interest with a special software tool that shows the images taken from all cameras, so that the user can select the areas where specific home devices are located. With this information, the system generates a number of active zones. The system also allows to select – among those provided by the domotic control system – the order to be sent to each of the devices. The system is thus capable of sending an order when the laser spot is detected within an active zone.This is the more relevant module: it includes the required algorithm for an accurate detection of laser spots. The whole system functionality strongly depends on the accuracy attained by this module. We summarize here the main approaches that have already been applied:1Algorithms embodying classical computer vision techniques for feature extraction [6,8]:•Dynamic Thresholding (DT).Template Matching (TM).Algorithms using classical techniques for decision making [7]:•Template Matching+Dynamic Thresholding (TM+DT).Algorithms using GFS techniques for decision making [9–12]:•Template Matching+Fuzzy Rule-Based System (FRBS) designed from expert's experience and automatic evolutionary tuning (TM+FRBStuned−GA).Template Matching+Evolutionary Learning Fuzzy Rule-Based System (TM+FRBSlearning−GA).Although the results of previous approaches were encouraging, the best one presents a drawback despite significantly improving the original results. The TM algorithm was used in all experiments and note that it introduces a number of errors that cannot be avoided by subsequent computations. The main goal in the current work is to supplement the TM step that is applied during the task of feature extraction by considering a novel FOA methodology in such a way that the detection process could improve the whole algorithmic process.As we will introduce in Section 5, given the good results already obtained in the preliminary application of FOA, the idea now is to combine the novel algorithm with the best approaches that were already developed in our previous work:1New algorithms using classical techniques for decision making:•Focus of Attention+Template Matching+Dynamic Thresholding (FOA+TM+DT) (preliminary results and details can be seen in [5]).New algorithms using genetic fuzzy system techniques for decision making:•Focus of Attention+Template Matching+Fuzzy Rule-Based System (FRBS) design from expert's experience and automatic evolutionary tuning (FOA+TM+FRBStuned−GA).Focus of Attention+Template Matching+Evolutionary Learning Fuzzy Rule-Based System (FOA+TM+FRBSlearning−GA)Once the laser spot is located on a home device using the image analysis algorithm, an order must be sent to control the selected device. In our tests, the system uses a domotic control system based on KNX/EIB technology [53] to send basic orders to control the different devices although other standard protocols for domotic control could also be employed. The orders sent by the system allows to switch on/off the selected device. It is out-of-scope the analysis of video sequences to send more elaborated orders; although the improvement on the detection step described in this paper could help to face that problem.Although other approaches were followed to improve the results achieved by the described techniques; see [6–12], TM was always the base for the feature extraction process. It was noteworthy that every time that a new method was proposed an improvement was attained; nevertheless, we remark that TM was the main source of false negatives that persistently deteriorated the results. Hence, this algorithm tends to find, under certain conditions, images sections that do not correspond with the laser spot. Despite careful application of the proposed approach in combination with more advanced techniques, we were unable of improving the accuracy. Moreover, given that the source of errors was still part of all approaches, we noticed the need of looking for alternatives.This paper considers the possibility of improving the results obtained by TM+DT, as well as the two TM+FRBS systems by suppressing the TM step or by complementing it with an extra technique that could help TM to work more accurately. Thus, we introduce a genetic programming based focus of attention (FOA) system which tries to reduce the section of the image where TM has to look for the laser spot. As we will see, FOA is capable of self-adjusting the area of the image where the laser spot must be located, thus reducing the search space for TM, as well as diminishing its failure probabilities. In the next sections we describe the FOA, which is the technique that is used to improve the whole laser spot detection system in combination with the systems where FOA is integrated such as: FOA+TM+DT, FOA+TM+FRBStuned−GA, and FOA+TM+FRBSlearning−GA.It is well-known that a human is unable to create a complete mental representation of everything in its visual field; hence, in order to process the visual information, a person must focus, for each time, on an unique region of the environment. The idea behind focus of attention is to find the part of the scene that contains prominent information for solving a given task. In this way, a basic phenomenon that defines the visual attention paradigm is selectivity, which is understood as the ability to filter unwanted information [54]. Then, the concept of visual attention is defined as a process that establishes a relationship between the different properties or features of the scene, which are perceived through the visual system, with the aim of selecting the most suitable aspect for the task at hand [55]. Therefore, the FOA algorithm is an abstraction of the natural visual attention process, which can be applied to find the location of the laser spot in the image and as a result it reduces the detection of false positives during the TM stage.The FOA algorithm is based in the feature-integration theory [56], which is divided in two main stages: feature extraction and feature integration. Next, the computational implementation of the FOA is explained giving special emphasis to the computational aspects that make the self-adjusting process possible.In this stage the scene is perceived through a camera. Then, the extraction of the visual features is performed through, what is called, evolved visual operators (EVOs). In this way, there are three different EVOs, each one is specialized in the detection of a single feature: orientation (EVOO), colour (EVOC) and shape (EVOS). There is a fourth visual operator that is not evolved but is used to represent the intensity feature dimension. These operators can be applied on the image in a parallel manner resulting in a visual map (VM) per feature dimension; see Fig. 4. In summary, we propose to use a multiple GP-based algorithm to obtain these artificial visual operators. The EVOs that are applied within the FOA are generated by artificial evolution based on the functions and terminals listed in Table 2.Once the VMs are obtained, the conspicuity maps (CMs) are computed in the next step following Walther and Koch's model [57]. The CMs are obtained through a center-surround function that is applied in order to simulate the center-surround process of the natural visual system. Finally, the CMs are combined to obtain a single saliency map as explained in the next section.The following step in the FOA algorithm is the fusion of the CMs into a single map of salient information with the aim of determining the location, in the visual field, where the attention should be directed at a given time. The saliency map (SM) defines the position of the most prominent regions in the image; given the characteristics of intensity, orientation, colour and shape. In other words, the objective of this stage is to decide where attention should be directed within the image.In this work, the task of the FOA algorithm is to find the laser spot. Hence, the criterion defined below is in accordance with this task in order to guide the process towards the best combination of several extracted features that are integrated into a single saliency map. Therefore, we decided to evolve the integration of the CMs through a function that we called Evolved Feature Integration (EFI); see Fig. 4. Thus, the self-adjusting process considers different combinations of CMs to achieve the desired goal. The evolutionary method uses the set of functions and terminals listed in Table 2, to create a fusion operator that highlights the features of the laser spot. More details about the methodology can be found in [58].Afterwards, the integration of features is performed and an optimized saliency map (OSM) is obtained by indicating the location of the most prominent region in the original image. This is known as the proto-object Pt, measured at time t.In this subsection, the central aspects for the evolution of the FOA are described in order to explain the self-adjusting process that was applied for the location of the laser spot in the image. Thus, the explanation is divided in two main steps, first we start by outlining the training process, then we continue by providing the definition of the fitness function.The first stage of the evolutionary algorithm refers to the training process. In this process, the self-adjusting FOA learns to focus into a prominent region of the image, with the aim of characterizing the laser spot using an image database as reference. The FOA algorithm needs a flexible computational structure to encourage the self-adjustment of the general algorithm, depicted in Fig. 4, through a simple yet robust code. Thus, the FOA algorithm is encoded through a syntactic tree array as genotype, which is constructed as follows: the first-tree encodes the orientation operator EVOO, the second-tree EVOOencodes a colour function working over the image, the third-tree models the shape on the image region EVOS, and finally the fourth-tree encodes the integration of the extracted features with the aim of obtaining the saliency map using the operator EFI; see Fig. 5. In this way, each EVO focuses on a particular image feature such as: colour, orientation and shape; while the fourth one is applied to integrate the information from the previously computed feature dimensions. Hence, the four trees have their own independent set of functions and terminals and as result, it turns into a more complex programming environment with respect to classical GP. In this way, the functions and terminals sets are listed in Table 2.In this manner, each tree is initialized with a ramped half-and-half technique with a maximum depth of 9 levels. In this way, each element of the chromosome, that we call gene, is represented by a tree. Given the complexity of the genotype structure there are two kinds of crossover operators and two mutation operators, which are used to diversify the programming of the chromosomes as a way of creating new visual attention programs. In our system, the low level of variation mechanisms, the crossover and mutation, works just like in classical GP. However, the whole structure of the chromosome should be understood as a complex array of trees embedded within a software template that defines the FOA. As a result, there are also high level of variation mechanisms, where the encoding is combined at chromosome level, instead of tree level. Fig. 6depicts the proposed evolutionary system, which is used as a self-adjusting process of the FOA algorithm.After initialization, the self-adjusting FOA relies on a well-posed fitness function in order to achieve the task at hand. In this manner, we propose the F-measure as score to tests the accuracy between the region selected by the FOA and the location of the laser spot within the image region. The F-measure considers both precision ρ and recall ϑ to determine the number of pixels that conform the intersection between the proto-object Ptand the region where the laser spot is located. In this way, ρ is the number of pixels that match the two regions divided by the number of proto-object pixels, while ϑ is the number of pixels that correspond also to the intersection of the two regions divided by the number of pixels highlighted by the laser-spot region; see Fig. 7. Then, the F-measure is defined as follows:(1)Fmeasure=2×ρ×ϑρ+ϑAs described above, we proposed a combination of classical computer visions techniques such as DT and TM [7], which unfortunately provided a significant number of errors, including the false offs. A false off is the situation when the system switches on/off a home appliance because it has detected a laser spot but without having been projected on the device.In this work, the FOA algorithm focuses on narrow areas of the images, where the laser spot is to be located, instead of trying to find it in the complete image. Then, TM is applied and the candidate image section with the highest correlation is obtained. In the next step, the dynamic threshold value is calculated by means of the DT process. A pixel is considered as a laser-spot image if it surpass the dynamic threshold value. Otherwise, the candidate image section is rejected.As a first example, we tested FOA in combination with TM+DT, our literature review base case, see Fig. 8. This preliminary test showed the capability of FOA for improving other previously developed algorithms, by increasing the accuracy from 83.43 to 86.77%; see [5]. These preliminary results encouraged us to test FOA with other more robust algorithms for laser-spot detection.Note that in previous works we have replaced the decision step DT with a more advanced technique such as FRBS [9–12]. In this work, we decide to test such proposal in combination with FOA; see Fig. 9.The idea now is to add FOA as a helpful tool to improve the good results obtained with FRBS. A hybrid approach embodying FOA, TM and FRBS, is employed in this paper to determine whether an image section provided by FOA, and analyzed by TM, should be counted as containing a laser spot. The FRBS works with a number of labels [59–61] in a similar way as how human language establishes non-numerical conditions, thus simplifying the generation of decision rules [62] that are used to provide a positive or negative response for each of the analyzed image sections. In our work, a set of interesting system variables determined by an expert were considered as in [7].Once it is defined the input variables and their domains, the expert also built useful fuzzy rules and manually adjusted the membership function (MF) definitions for the detection task. The process to determine these variables, as well as FRBS can be found in [7].In summary, the complete recognition task is therefore comprised of three main parts (algorithms). The first algorithm, FOA, extracts an image section from the test image in order to decide if it came with or without laser-spot information. The second algorithm, TM, analyzes the image extracted by FOA using a template image. This process obtains the image section with the highest correlation value. The image section is then analyzed with the proposed FRBS that returns a value, which is useful for determining the presence of the laser spot on the image.The expert is a key component in the previous approach, given the need to properly design the set of rules employed by the FOA+TM+FRBS_expert algorithm. In our work, we were interested in studying if the relationship between the features extracted could be further improved.Several methods in the literature allow to refine a FRBS. For example, the Genetic tuning of the membership functions (MFs) [63–66] apply a genetic algorithm (GA) [67,68] to adjust the MFs of a previously designed FRBS. This kind of hybridization approach between fuzzy logic [59–61] and GAs is known as genetic fuzzy system (GFS) [13–15].Tuning a FRBS aims at obtaining a better data base (DB) definition. The improvement includes a new definition of the MFs, or the inference engine parameters once derived the rules base (RB) [13–15]. Nowadays, due to the wide use of triangular-shaped MFs, the tuning methods [13,63] refine three definition parameters that identify these kinds of MFs; see Fig. 10. Also, a graphical representation of the GA based tuning process is shown in Fig. 11.The FRBStuned−GAgenerates for each input, sample to be classified, an output value in the interval [0, 1]. If this value is higher than a threshold value (L), the sample will be classified as a laser-spot image; otherwise, it will be classified as an image without a laser spot. In our work, the threshold value L is tuned together with the MFs. Thus, three possible situations arise:•False negative (FN), If the example is classified as an image without a laser-spot while being a laser-spot image.False positive (FP), If the example is classified as a laser-spot image while being an image without a laser-spot.Hit, If the example is correctly classified.The objective of this algorithm is to minimize the number of FNs and FPs obtained by the FRBS. To evaluate a given chromosome Cjwe employ the following fitness function:(2)Fitness(Cj)=|FN||D|+X·|FP||D|where |FN| is the number of FNs, |FP| is the number of FPs and |D| is the dataset size. Note that the number of FPs is penalized by a factor X in order to eliminate the wrong orders/commands that are sent to the domotic system.Once the FRBSexpertis tuned, it is hybridized with FOA and TM, resulting in a system that is called FOA+TM+FRBStuned−GA.In our work a real coding scheme is considered where each chromosome is a vector of real numbers of size 3·F+1, F being the number of MFs in the given DB, whose three parameters identify the MFs and threshold value. Hence, a chromosome Cjhas the following form, with mithe number of MFs, for each of the n variables in the DB.Cj=Cj1Cj2⋯CjnLj,Cji=(aj1i,bj1i,cj1i,…,ajmii,bjmii,cjmii),i=1,⋯,nThe initial gene pool is created from the initial DB definition. This initial DB, with L=0.5 as threshold value, is encoded directly into a chromosome denoted as C1. The remaining individuals are generated randomly with the variation intervals associated with each MF and its corresponding threshold value. For each MFf=(af, bf, cf) where f=(1, …, F), the variation intervals are calculated in the following way; see Fig. 12.(3)[Iafl,Iafr]=af−bf−af2,af+bf−af2[Ibfl,Ibfr]=bf−bf−af2,bf+cf−bf2[Icfl,Icfr]=cf−cf−bf2,cf+cf−bf2The interval for the threshold value L is in [0, 1]. Therefore, we create a population of chromosomes containing C1 as its first individual and the remaining are initiated randomly, with each gene in its corresponding variation interval.IfCv=(av11,…,evk,…,Lv)andCw=(aw11,…,ewk,…,Lw)are to be crossed, the following four offspring are generated(4)C1=dCw+(1−d)CvC2=dCv+(1−d)CwC3withe3k=min{evk,ewk}C4withe4k=max{evk,ewk}This operator uses a parameter d=0.35, which is either a constant or a variable whose value depends on the age of the population. The resulting descendants are designated as the two best from the four offspring.IfCj=(aj11,…,ejk,…,Lj)is a chromosome and the element ejkwas selected for mutation, the domain of ejkis[ejkl,ejkr]) and the result is a vectorCj′=(aj11,…,ejk′,…,Lj)with(5)ejk′=ejk+(ejkr−ejk)·rwhere r is a random number within the interval [−1.0, 1.0].Finally, we decided to adjust not only the MFs but also to automatically design the set of rules. The aim was to corroborate if the FRBS, generated by experts and tuned by a GA, could be further improved. Therefore, in this new approach we have combined FOA+TM with a FRBS generated process in charge of learning the complete knowledge base (KB). The idea behind is to simultaneously design both, MFs and rules; thus, considering the interaction between the two parts and therefore trying to obtain a more accurate model. Unfortunately, this proposal has to deal with a huge search space [11,12].In [69], a new model for tuning FRBSs was proposed considering the linguistic 2-tuples representation scheme introduced in [70,71], which allows the lateral displacement of the support label while maintaining the interpretability associated to the linguistic FRBS label. This proposal also introduces a new model for rule representation based on symbolic translation: a number within the interval [-0.5, 0.5), expressing the domain of a label, is moved between its two lateral labels. Formally, we have the pair,(si,αi),si∈S,αi∈[0.5,−0.5)Fig. 13shows the lateral displacement of the label M. The new label “y2” is located between B and M.This method consists of learning the KB via genetic derivation of the DB. The process obtains the DB and the RB separately based on the embedded learning of the DB [72–75]; see Fig. 14. This new approach allows us to learn the most adequate context for each fuzzy partition. Hence, the process obtains a set of MFs for each variable, which are optimized during the complete learning process. Also, a specific RB is derived through the well-known technique of Wang and Mendel [76]. The whole definition of the KB is obtained by means of the cooperative action of both processes.The FRBSlearning−GAgenerates an output value in the interval [0, 1]. Thus, the system uses a fixed threshold value of 0.5: if the output value is greater the image section is considered as the laser spot. In both approaches, FRBStuned−GAand FRBSlearning−GA, we employed the same fitness function; see Eqs. (7) and (8). Interested readers can study the complete description of both approaches in [9,10].

@&#INTRODUCTION@&#


@&#CONCLUSIONS@&#
This paper shows the interest of a self-adjusting the GP-based focus of attention technique when working in collaboration with classical computer vision techniques and genetic fuzzy systems for a specific problem: the accurate detection of laser spots. The main goal is to offer a reliable user interface with standard domotic systems based on laser pointers and video cameras, which are capable of detecting user actions and sending the appropriate orders to devices.Previous works showed us that classical computer vision techniques in combination with other decision making systems present an specific problem: TM inserts errors at the moment of selecting the candidates for laser spots within the images.In this paper, a new approach was proposed based on the incorporation of a GP-based algorithm capable of properly focusing the attention into small image regions projected in photographs from the environment. Once the area is selected, it is analyzed by means of template matching as the suitable way of searching the laser spot. The GP-based FOA algorithm is first self-adjusted on a set of training images; then, the discovered program is applied in collaboration with TM+DT, TM+FRBStuned−GAand TM+FRBSlearning−GAon real-home environments.In our work, we have shown how a proper combination of the FOA algorithm with different GFS allows us to improve significantly the accuracy of the detection system. When FOA is interpreted with FRBSlearning−GAthe system improves a 4.87% in general, 11.67% for images with the laser spot, and it decreases 1.67% in images without a laser spot. On the other hand, when FOA is combined with the TM+FRBStuned−GAa general improvement of 9.36% is reached: 11.86% in images with a laser spot and 6.75% for images without laser spots.Summarizing, the results presented in this paper show the advantages of this new approach. The general accuracy level is increased since: (1) it maintains the extremely low level of false negatives already provided by previous approaches, and (2) it increases the detection level of laser spots by reaching a general accuracy of 92.5%.