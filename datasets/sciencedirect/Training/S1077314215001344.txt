@&#MAIN-TITLE@&#
Landmark localization on 3D/4D range data using a shape index-based statistical shape model with global and local constraints

@&#HIGHLIGHTS@&#
We propose a method for landmark localization on 3D and 4D range data.A new Shape Index-Based Statistical Shape Model is proposed.Five Benchmark 3D/4D face databases are tested on.The accuracy of the landmarks is compared to ground truth data, and state-of-the-art methods.The efficacy of the landmarks is validated through expression analysis and pose estimation.

@&#KEYPHRASES@&#
3D range data,4D range data,Landmark localization,Statistical shape models,Face and expression analysis,Deformable models,

@&#ABSTRACT@&#
In this paper we propose a novel method for detecting and tracking facial landmark features on 3D static and 3D dynamic (a.k.a. 4D) range data. Our proposed method involves fitting a shape index-based statistical shape model (SI-SSM) with both global and local constraints to the input range data. Our proposed model makes use of the global shape of the facial data as well as local patches, consisting of shape index values, around landmark features. The shape index is used due to its invariance to both lighting and pose changes. The fitting is performed by finding the correlation between the shape model and the input range data. The performance of our proposed method is evaluated in terms of various geometric data qualities, including data with noise, incompletion, occlusion, rotation, and various facial motions. The accuracy of detected features is compared to the ground truth data as well as to start of the art results. We test our method on five publicly available 3D/4D databases: BU-3DFE, BU-4DFE, BP4D-Spontaneous, FRGC 2.0, and Eurecom Kinect Face Dataset. The efficacy of the detected landmarks is validated through applications for geometric based facial expression classification for both posed and spontaneous expressions, and head pose estimation. The merit of our method is manifested as compared to the state of the art feature tracking methods.

@&#INTRODUCTION@&#
Applications such as face recognition, expression analysis, human-computer interaction, and face video segmentation are increasingly being developed based on 3D, and 4D (3D+time) range data [34,36,38,41–44], given the rapid technological advancement of 3D imaging systems [16,37,40,46]. Landmark localization on 3D/4D range data is the first step toward geometric based vision research for object modeling, recognition, visualization, and scene understanding [35,39,47–49]. Landmark localization is a crucial task when dealing with 3D and 4D data. For example it allows for simultaneous location of multiple objects in a scene.While 2D based tracking methods have been successfully developed, such as Active Shape Models [7], Active Appearance Models [18], using a consensus of exemplars [2], Constrained Local Models (CLM) [9], regularized landmark mean-shift [24], generative shape regularization model [13], explicit shape regression [6], supervised descent method for face alignment [28], and shape-constrained linear predictors [45], there is a need for novel and robust algorithms to handle 3D/4D range data. Morphable Model [4,53] is one of the successful algorithms for handling 3D range data.There has been recent work to address the problem of detecting feature landmarks on range data. Zhao et al. [32] had success with detecting 3D landmarks using a statistical facial feature model; however there is an upper bound on the number of landmarks. Fanelli et al. [11] used an active appearance model that is based on random forests; however this method used depth and intensity data rather than the 3D/4D range data. Sun et al. [25] used a so-called vertex flow approach, which used an active appearance model (AAM) to track features of 3D range models. However, the tracking of facial features was not truly in the 3D space, rather it was tracked in the 2D space and the 3D features themselves were obtained by mapping the 2D features to the corresponding parts of the 3D models, tending to cause inaccurate projections. Nair et al. [20] fit a 3D active shape model to facial data using candidate landmarks to deform the model, however the resulting error rate for fitting is relatively large, and problems occur when holes exist around the nose. Zhou et al. [33] created a 3D active shape model which was trained using a 3DMM, although the fitting for this method was done in 2D. Perakis et al. [21] used a 3D active shape model which was fit from previously determined candidate landmarks. A draw-back to this method is the need for preprocessing. Guan et al. [14] performed landmark localization on facial data by utilizing a Bezier surface. This method was tested on a small dataset consisting of 100 3D models. Jeni et al. [15] used a 3D constrained local model method (estimated from 2D shape) to track landmarks for action unit intensity estimation. Baltrisaitis [1] used a 3D CLM (a.k.a. CLM-Z) trained with depth data rather than 3D/4D range data for rigid and non-rigid feature tracking. A statistical model (blend-shape) was utilized by Weise et al. [27] to track facial data and animate a virtual avatar; however, this has the limitation that the blend-shape may not have a unique set of needed weights for an expression. Chen et al. [39,47] applied a coarse-to-fine approach via curvature and active normal model for landmarking. Bonde et al. compute the shape-index of discrete points, on 2.5D data, to recognize objects [50]. Chen et al. compute the shape-index along with histograms to recognize 3D data [51]. Wang et al. use shape-index and geodesic distances to find correspondences between 3D objects [52]. Recently, we have developed a so-called 3D temporal deformable shape model (TDSM) for feature tracking through 3D range sequences [5]. However, such a multi-frame based shape model may not work well for different expressions within a very short duration when dramatic motions or sudden expression changes occur in the 3D videos, thus the performance on 3D geometric tracking still needs to be improved. Motivated by the previous work [5], we continue to address the issue of feature detection and tracking on 3D/4D range data with a more reliable way.In this paper, we study the challenges of detecting and tracking landmarks by proposing to construct a shape index-based statistical shape model (SI-SSM) with both global and local constraints. The SI-SSM is constructed from both the global shape of 3D feature landmarks and local features from patches around each landmark. In order to construct the patches we find 3D features from the (u, v) coordinates around each landmark. From these new features we construct a n × n patch, where each vertex is represented by a unique shape index value. Using both the global shape and the local features around each landmark enables us to reliably detect and track features on the range mesh data. The feature detection and tracking are based on finding the correlation between the local shape index patches on the input range data and the trained SI-SSM model (as illustrated in Fig. 3).The main contribution of this paper is the construction of a statistical model that makes use of both the global shape of 3D face surface, as well as the local shape around individual features by way of shape index representation. This model can be used to detect and track features on range data. By using the shape index representation we are able to make the local fitting invariant to both lighting and pose changes. We are able to model and fit data that includes various emotions, rotations, occlusions, and missing data by training on each of these data types. Following is the summary of the main contribution of this work:(1)We proposed and developed a novel approach for 3D/4D facial feature detection and tracking. This approach has extended the global statistical shape model to an integrated global and local shape model to improve the tracking performance with respect to various imaging data conditions. In particular, we have presented a shape-index based local shape model and combined this model with the global shape model as a new statistical shape descriptor (so-called shape-index based statistical shape model (SI-SSM)).We have tested the new SI-SSM model on five public 3D/4D face databases (i.e., BU-3DFE [29], BU-4DFE [30], BP4D-Spontaenous [31], FRGC 2.0 [22], and Eurecom Kinect Face Database [19]) which cover a variety of data types, including static vs. dynamic, posed vs. spontaneous, high-resolution vs low-resolution, etc.We show the merit of the new SI-SSM based detection and tracking through performance evaluations with respect to various authentic facial behaviors, dramatic head rotations, data conditions with noise, occlusion, and incompleteness, as well as comparison with four state of the art approaches.We have validated the usability of our new approach through its application to facial expression recognition and head pose estimation. Especially, we applied a spatial–temporal HHM model to classify six posed expressions on 4DFE and eight spontaneous expressions on BP4D-Spontaneous database successfully.The paper is organized as follows: Section 2 presents the new statistical model and its construction. Section 3 describes the feature detection and tracking algorithm in detail. The experiments and evaluations are reported in Section 4, followed by application study for 3D/4D face analysis. Finally, the conclusion and future work are discussed in Section 6.Our proposed method models both the global shape of 3D facial landmarks, as well as the local curvatures from patches around the landmarks. In order to construct the SI-SSM, we annotate the training data with L landmarks. From these annotated landmarks we are able to model both the global and local shapes of a face. An example of an annotated mesh can be seen in Fig. 1, where L = 83. The resulting global shape, local curvature patches, and the final construction of the SI-SSM are detailed in the following sub-sections.To model the global face shape, we first create a n × n patch around each of the L annotated landmarks for each training mesh. To construct these patches we use the corresponding (u, v) coordinates for each of the training data. An example of a 3D mesh with patches can be seen in Fig. 1.Given a set of M training data, each with L patches, a parameterized model, SG, is constructed. This parameterized model contains the global shape of all of the training data, whereSG=(x1,y1,z1,…,xN,yN,zN), where N =L × n × n. The first step to create this model is aligning the N landmarks, on each of the M training data, by using a modified version of Procrustes analysis [7]. PCA is then applied to learn the modes of variation from the training data. For our experiments we keep approximately 95% of the variance. We can then approximate any shape by(1)SG=s¯+Vwwheres¯is the mean shape, V is the eigenvectors of the covariance matrix C, which describes the modes of variation learned from the training data, and w is a weight vector used to generate new shapes (referred to as an instance of the SI-SSM) by varying its parameters within certain limits. We impose these limits to ensure only valid shapes are constructed. For our model we constrain those valid shapes to be within two standard deviations from the mean (which is the allowable shape domain)(2)−2λi≤wi≤2λiwhereλiis the ith eigenvalue of C. We have empirically found, from the training data, ± 2 standard deviations from the mean to be a suitable constraint for our model as this range gives us a good balance between speed and accuracy of model fit. A smaller constraint would shrink the search space and possibly miss the best fit to the input model. A larger domain would create an unnecessarily large search space that would have instances of the model that do not look like a face.To model the local face shape we apply the shape index values to represent the local patches. To do so, we calculate the shape index values for each of the L patches in the global face shape. Calculating the shape index gives us a quantitative measure of the shape of each patch around the L annotated landmarks. Shape index is defined as follows:(3)SI=2π*arctan(k2+k1k2−k1)where k1 and k2 are the min and max principal curvatures of the surface, with k2 ≥ k1. All shapes can be mapped to the range [−1.0, 1.0], where each unique shape corresponds to a specific shape index value. A cubic polynomial fitting approach is used to compute the eigen-values of the Weingarten Matrix [10] giving us k1 and k2. We normalize the shape index scale to [0, 1] and encode them as a continuous range of grey-level values between 1 and 255. To give us an efficient description of the data, we transform the shape index scale to a set of nine quantization values from concave to convex. Fig. 2shows example range meshes with the shape index values normalized to [1, 255] for illustration.Given the set of M training data with L patches where each contains the calculated shape index values, we construct a second parameterized modelSL=(SI1,…,SIN). PCA is then applied to this local shape vector in the same manner as the global shape vector does. We construct a new vector, VSI, which yields of the modes of variation along the principal axes for the local shape index values. Similar to the global shape, we can approximate any local patch shape using the vector, VSI, and a weight vector wSIby(4)SL=si¯+VSIwSITo take both global and local shape constraints, we integrate the two features into a combined feature model. To do so, we concatenate both the global and local shape feature vectors into one feature vectorSGL, whereSGL=(x1,y1,z1,…,xN,yN,zN,SI1,…,SIN). Using the combined feature vector allows us to move the local patches, on the face data, to a more representative surface on the model while maintaining the constraint that we approximate a valid face shape in the allowable shape domain. Other methods that use statistical models such as [8,9,25] have been successful in using statistical models to create a combined feature vector that incorporates both the shape and “appearance” of the face. The “appearance” portion (e.g. textures) of the model helps to guide the model and fit to new data, however, these approaches suffer from the problem of global lighting variation, as well as skin tone of the modeled face. The grey-level appearance information in these models must be normalized in order to handle this lighting variation. Our SI-SSM uses shape index values to model our local features, which guide our model and fit to new range data. Shape index values are invariant to global lighting variation and skin tone. As described in the previous section, shape index is a quantitative measure of shape, so using these features our model does not encounter the same issues that similar “appearance” based solutions do.Given an SI-SSM we are able to detect and track landmarks on 3D/4D sequences of range data. In order to perform the detection and tracking, we must first calculate the shape index values for the vertices of the input range mesh. This is done in the same manner as described in Section 2.2. Once we have these values calculated we can then apply the SI-SSM fitting algorithm to the input range mesh data.First, an initialization phase is performed to give us a sufficient starting point to perform a local patch-based correlation search. During the initialization phase, to fit our model to the range data we learn the weight parameters w of the global shape by uniformly varying the weight vector to generate new instances of the SI-SSM. By performing this learning offline, for the initialization, we are able to have precise control over which shapes are constructed, ensuring that the new shapes constructed are valid (within the allowable shape domain). Iterative closest point (ICP) [3] is used to minimize the distance between each SI-SSM instance and the input range data. The patches from the instance of the SI-SSM with the lowest ICP matching score are used as the initialized starting landmarks for the SI-SSM. Given this global fit, we then calculate the local patch–based correlation score with the SI-SSM and the input range mesh. This correlation score is computed using a cross correlation template matching scheme [17]. The correlation score, CSp, is computed for each patch as(5)CSp=∑i′,j′(P(i′j′)·R(i+i′,j+j′))∑i′j′P(i′j′)2·∑i′j′′R(i+i′,j+j′)2where P(i'j') is the computed shape index value at index (i, j) of the SI-SSM patch, andR(i+i′,j+j′)is the summation between the shape index value at index (i, j) of the SI-SSM patch and the corresponding shape index value on the range mesh. The final correlation score, CS, is computed as(6)CS=∑(p=1)LCSpThis initialcorrelation score allows us to have a base line comparison for the local patch-based correlation search, as well as define tighter convergence criteria.Once we have the initialized patches and initial correlation score we then perform a local search around each of the patches of the SI-SSM. For each patch in our model we construct a new patch of the same size around each of the n × n points of the original patch. For example, when n = 3, we construct a patch centered on each point of the original 3 3 patch, resulting in nine new patches (as illustrated in Fig. 3). The shape index values for each of these patches correspond to the shape index values of the vertices of the new patches. Using Eq. (5) we compute a new CSpfor each of the new patches we created. The patch that gives us the highest correlation score is marked as the new patch of the SI-SSM. It is important to make sure that when all of the patches have been moved the new global shape of the face is with the allowable shape domain of−+2standard deviations from the mean. From Eq. (4), we can derive the corresponding wSIvector of the newly transformed SI-SSM by the following:(7)wSI=VSIT(SL−si¯)This new weight vector is constrained to be within the allowable shape domain, and we approximate a new shape by again utilizing Eq. (4) with this weight vector.Once we have the new approximated global shape of the face, iterative closest point is then used to again minimize the distance between the new SI-SSM instance and the range mesh. This process continues until convergence is reached. Convergence is defined by two main criteria:(1)The computed correlation score, CS, for the transformed SI-SSM is higher than the computed score in the previous iteration (for the first iteration we make use of the correlation score computed in the initialization phase).The computed correlation score, CS, exhibits little to no change from the CS computed in the previous iteration.If the first convergence criterion is satisfied after the first iteration after initialization, the transformed patches are discarded and the previously computed global patch shape is used. Due to this, we need to compute the initialization correlation score as it is possible in our initialization phase that our SI-SSM will find the best fit to the range mesh, and additional transformation(s) of the model are not required. Once we have the detected features for the current 4D mesh in the sequence, we then use ICP to move the landmarks to the next mesh in the sequence and continue the tracking of the sequence. The fitting process is then repeated with the previously detected landmarks used as the initial model fit. We are able to fit approximately three models per second with sufficient accuracy on an average PC configuration.Table 1 outlines the algorithm, Fig. 3 shows an example illustration outlining the fitting process, and Fig. 4 shows several sample 4D range models with detected patches using the SI-SSM algorithm.Five public face databases have been used for our study including three static and two dynamic databases (as shown in Table 2, and Figs. 5 and 6 for examples).(1)BU-3DFE [29] consists of 100 subjects each displaying one neutral expression and four intensity levels of six deliberate expressions.Eurecom Kinect Face Database [19] consists of 52 subjects, displaying nine deliberate expressions, obtained through the Microsoft Kinect [16].FRGC 2.0 [22] consists of 466 subjects displaying two different deliberate expressions.BU-4DFE [30] consists of 101 subjects with sequences of six different deliberate expressions.BP4D-Spontaneous database [31] consists of 41 subjects, each consisting of eight different spontaneous expression sequences (e.g., joy, embarrassment, surprise, disgust, fear, sadness, pain, and anger). The expressions were elicited through activities including film watching, interviews, and experiencing cold pressor test, etc. The database includes the 3D dynamic model sequences, texture videos, and annotated action units (AU). Table 2 lists more details pertaining to each database.To evaluate the accuracy of detecting and tracking landmarks using our SI-SSM method, we calculate the mean squared error between the ground truth and our detected/tracked landmarks (centroids of patches). We do this by calculating the one-point spacing between each landmark. The one-point spacing is defined as the closest pair of points on the 3D scans (0.5 mm on the geometric surface). We treat the unit error as equal to 1 point spacing, so we can compute the average of the point distances between the sets. Table 3detailsthe error rates, mean squared error (MSE), for all five tested databases.Note that the ground truth feature points that have been used for comparison in each database are obtained as follows:(1)For 3DFE and 4DFE databases, we used the associated feature points (N = 83) (released from the databases) as ground truth;For FRGC 2.0 and Eurecom databases, the ground truth feature points (N = 83) were obtained through our manual annotation;For BP4D-Spontaneous database, the ground truth feature points (N = 83) were obtained by a semi-automatic method: First, we utilized the Kinect face tracking API [16] and modified it for 3D range data tracking. To modify the Kinect face tracking algorithm a multi-rendering is done to render the 3D range data in a suitable depth and RGB format. Second, the 2D coordinates are converted into model space to acquire the 3D landmarks. Finally, we manually correct the feature points that were erroneously detected or mapped.As can be seen from Table 3 our proposed algorithm performs well on the 4DFE and BP4D databases. The relatively higher error rate on the 3DFE can be attributed to the low resolution of this database. Also, the relatively higher error rates on the FRGC and Eurecom databases can be attributed to the greater level of noise and holes in these datasets.

@&#CONCLUSIONS@&#
