@&#MAIN-TITLE@&#
A model for heuristic coordination of real life distribution inventory systems with lumpy demand

@&#HIGHLIGHTS@&#
The motivation for this work stems from close cooperation with industry.Distribution systems with fill-rate constraints and lumpy demand are considered.A method based on decomposing the problem to single-echelon problems is developed.The policies are close to optimal and the heuristics can be directly implemented.A numerical study based on real data show improvements compared to current methods.

@&#KEYPHRASES@&#
Inventory/production,Multi-echelon,Policies,Continuous review,Stochastic,Poisson demand,

@&#ABSTRACT@&#
This paper presents an approximation model for optimizing reorder points in one-warehouse N-retailer inventory systems subject to highly variable lumpy demand. The motivation for this work stems from close cooperation with a supply chain management software company, Syncron International, and one of their customers, a global spare parts provider. The model heuristically coordinates the inventory system using a near optimal induced backorder cost at the central warehouse. This induced backorder cost captures the impact that a reorder point decision at the warehouse has on the retailers’ costs, and decomposes the multi-echelon problem into solving N+1 single-echelon problems. The decomposition framework renders a flexible model that is computationally and conceptually simple enough to be implemented in practice.A numerical study, including real data from the case company, shows that the new model performs very well in comparison to existing methods in the literature, and offers significant improvements to the case company. With regards to the latter, the new model in general obtains realized service levels much closer to target while reducing total inventory.

@&#INTRODUCTION@&#
Inventory control of one-warehouse N-retailer systems is an issue that has attracted significant research interest for quite some time. The multi-echelon inventory literature contains a large number of models and approaches for analyzing different aspects of this problem, see for example Axsäter (2003a) for an overview. Still there are few reported applications of these theories to real systems. One reason for this may be that most of the models in the literature are difficult to directly apply because of restrictive model assumptions and/or conceptual and computational complexities. The research reported in this paper is an attempt to remedy this by presenting a simple and flexible approximation model for optimizing reorder points in systems subject to highly variable lumpy customer demand.The work is motivated by close collaboration with a supply chain management software company, Syncron International, and one of their customers, a global spare parts provider. Important requirements posed on the model are that it should: (i) handle reorder point policies with batch ordering, backordering, and partial order deliveries, (ii) jointly optimize and coordinate the reorder points in the system to meet target service levels for the end customers while minimizing the inventory costs, (iii) be applicable to realistic demand distributions, particularly where customer orders vary considerably in size, (iv) be able to deal with transaction data, i.e., continuous review information, (v) be computationally feasible for large systems in practice, and (vi) be conceptually simple enough to be understood by the end users.Based on these requirements our model is characterized by continuous review installation stock (R,nQ)-policies at all locations, First-Come–First-Served allocation, complete backordering, and compound Poisson demand with general compounding distributions. Applying the (R,nQ)-policy, means that an order of nQ units is generated as soon as the inventory position (=stock on hand+outstanding orders–backorders) reaches or drops below the reorder point R, where n is the smallest integer such that the inventory position just after ordering is above R.The approximation model we present heuristically coordinates the reorder point decisions by decomposing the multi-echelon system into solving N+1 single-echelon models. The decomposition is achieved by introducing a near optimal induced backorder cost at central warehouse that captures the impact that its reorder point decision has on the retailers. The induced backorder cost is obtained from applying the results in Berling and Marklund (2006). The decomposition framework makes it possible to obtain a very flexible model that is able to meet the requirements listed above. It also allows for optimization of reorder points either with the objective to minimize expected inventory holding costs while meeting specified target fillrates, or the objective to minimize total expected holding and backorder costs for specified backorder cost rates.A numerical study, including real data from our case company, shows that the new model performs very well. It renders total cost solutions that are on average within 1% of the exact method in Axsäter (2000). It is superior to the approximation method in Berling and Marklund (2012) in meeting target fillrates (and thereby also to the other approximation methods from the literature that they investigated), and it offers significant improvements to the case company. In our simulation study based on real data, the fillrate on average increases from 12% below target with the current method, to 0.6% above target with our approximation model, while at the same time reducing the average holding costs by 11.8%.Looking at the literature, there is a close relationship between our work and that of Andersson et al. (1998), Andersson and Marklund (2000), and Berling and Marklund (2006), all dealing with approximation models for minimization of expected holding and backorder costs in the type of system we consider. Assuming identical retailers and normally distributed demand, Andersson et al. (1998) first introduced the idea of decomposing the complex multi-echelon system into N+1 single echelon systems by use of an induced backorder cost, β, at the central warehouse. Their approach is based on replacing the stochastic retailer lead-times with their correct averages, and applying an iterative procedure (repeatedly solving the N+1single-echelon problems, and updating the reorder points, β, and the retailer lead-times) to find an optimal solution to the resulting approximation model. The obtained solution is proven to represent a lower bound to the cost minimizing solution. Andersson and Marklund (2000) generalize the method to non-identical retailers, under the assumptions of complete deliveries and normal demand. Later, Berling and Marklund (2006) investigate how the induced penalty cost depend on the system parameters and provide closed form estimates for near optimal induced backorder costs as functions of the system parameters. A numerical study illustrates that the estimated induced penalty costs are near optimal not only for the normal demand models from which they are derived, but also in the exact compound Poisson model presented in Axsäter (2000). The study also shows that the new method for estimating the induced backorder costs outperforms the alternative method proposed in Axsäter (2005), which is based on disregarding the warehouse stockout delay. These results have been an important source of inspiration for the present research. Important features that distinguish our present model from the previous is that it deals with compound Poisson demand, partial deliveries, and optimization of reorder points to meet target service levels. Last but not least, it represents a complete approximation model that is computationally feasible to implement in practice.A closely related paper is Berling and Marklund (2012), which analyzes a similar approximation model. The main difference is that customer demand in their model is assumed to be normally distributed. An important model feature is compensation for the fact that arriving customers actually demands an integer number of units, which implies a possible undershoot of the retailers’ reorder points before ordering (i.e., the inventory position may drop below the reorder point). Under the regular normal demand assumption this undershoot is disregarded, which turns out to be a major problem in the quest for reorder points that achieve target fillrates. The presented Normal demand model with undershoot compensation is computationally simple and a numerical study shows that it performs quite well. However, the same study also show that there is room for improvement for products with intermittent and highly variable (i.e., lumpy) demand. Our present model is designed to better deal with these cases, and improve the accuracy in achieving the target fillrates. This is also shown to be the case in the numerical study. We will refer to the best model alternative in Berling and Marklund (2012), in terms of fillrate attainment at low inventory holding costs, as BMN.Our work is also related to the literature on exact analysis of continuous review one-warehouse multiple-retailer systems. Forsberg (1997) and Axsäter (1993, 1998) provide exact analysis of the same system we consider with installation-stock (R,Q) policies at all inventory locations, but for the more restrictive case of Poisson demand. Chen and Zheng (1997) also considers Poisson demand but for systems where all stock points use echelon-stock (R,Q) policies. Axsäter (1997) considers the same type of system and provides exact analysis valid also for compound Poisson demand. Axsäter (2000) is closely related to our present work as it presents a method for exact cost evaluation of precisely the same system that we study with installation-stock (R,Q) policies, and compound Poisson demand. The method is recursive and quite fast for small problems (i.e., low demand and few retailers) but it becomes computationally intractable for larger systems. It is also conceptually challenging to grasp. It is therefore not feasible to directly implement in practice, except for very small systems. The numerical study shows that our approximation model renders near optimal reorder points, which on average renders total expected costs within 1% of the minimum cost of the exact solution. Computationally and conceptually our approximation model is much simpler.More remotely related to our work, but belonging to the same research stream of exact analysis of one-warehouse multiple retailer systems, are a number of papers focusing on more complicated warehouse ordering policies. Marklund (2002) analyzes a system with non-identical retailers, Poisson demand, (R,Q)-policies at the retailers and a service-level policy at the central warehouse. For the more restrictive case of identical retailers, Moinzadeh (2002) investigates a generalized installation-stock (R,Q) policy at the warehouse. Recently, Axsäter and Marklund (2008) derive a warehouse policy that is optimal in the class of “position based” policies, and relax the FCFS assumption used in all the exact methods mentioned above. The class of “position based” policies encompasses all the policies previously analyzed exactly.There is of course a relationship between our work and other approximation models for continuous review one-warehouse multiple-retailer systems, particularly with non-identical retailers and batch ordering. In addition to Andersson and Marklund (2000), and Berling and Marklund (2012) mentioned above, there is a clear connection to Axsäter (2003b). The model presented in this paper deals with the same system as we do, but under the assumption of normally distributed demand. The numerical study in Berling and Marklund (2012) shows that their proposed model (BMN) is better at achieving target fillrates than the one in Axsäter (2003b). We therefore benchmark against BMN in our numerical study. In a recent paper, Gallego et al. (2007) analyze bounds, heuristics and approximations of one-warehouse continuous review multiple-retailer systems under the assumptions of Poisson demand and base-stock policies at all locations. Earlier papers that deserve mentioning, even though they are based on more restrictive assumptions, include Deuermeyer and Schwarz (1981), Moinzadeh and Lee (1986), Lee and Moinzadeh (1987a,b), and Svoronos and Zipkin (1988). The first and last of these papers also use decomposition, albeit technically quite different from ours. Schneider et al. (1995) also use a decomposition idea, which in spirit is similar to ours, for analyzing a periodic review system with continuous demand, and (s,S) policies at all installations. Examples of other more remotely related literature on periodic review models include: Federgruen and Zipkin (1984a,b,c), Jackson and Muckstadt (1989), van der Heijden et al. (1997), Cachon (1999), Cachon and Fisher (2000), Axsäter et al. (2002), Dogru (2006), Marklund and Rosling (2012), and references therein.The remainder of this paper is organized as follows. Section 2 provides a thorough model formulation and presents the details of our approximation model. Section 3 contains the numerical study and analyzes the model performance, and Section 4 concludes.As indicated above, the generic inventory system we consider consists of one central warehouse (CW), and N non-identical retailers distributing a single product. The central warehouse replenishes its stock from an outside supplier/manufacturer with constant lead-time (L0). The transportation time from the central warehouse to each retailer i (li) is also constant, but the lead-time (Li) may be stochastic due to shortages at the central warehouse. Complete backordering is assumed at all stock-points, and demand is served according to a First-Come–First-Served (FCFS) principle. All locations replenish their inventory using continuous review (Ri,nQi)-policies. Motivated by the lumpy demand pattern (intermittent with large variations in order sizes) at the case company, the customer demand at each retailer is modeled as independent compound Poisson processes. This means that customers arrive according to a Poisson process, and each customer orders a stochastic amount of units (>0), independent of previous and subsequent orders. The order sizes at each retailer follow specified compounding distributions. We pose no restrictions on these distributions except that they should be discrete. There are holding costs per unit and time unit at all locations. In terms of service requirements, the retailers are either subject to service level constraints in the form of specified target fillrates, or they experience backorder costs per unit and time unit. We refer to the former as the service level model and the latter as the backorder cost model.In the forthcoming analysis, the batch quantities are given and we focus on optimizing the reorder points. We assume that the initial inventory position, the reorder point, and the batch size at the warehouse are integer multiples of a common subbatch, Q. This subbatch represents the largest common divisor of all batch quantities in the system (can be equal to one). Motivated by the practical application, we focus on the service level model, where the objective is to minimize the expected holding costs while meeting the specified target service levels at the retailers. However, as indicated above, we also consider the backorder cost model where the objective is to minimize the expected holding and backorder costs in the system. For this alternative, backorder costs per unit and time unit are added to the retailers’ cost functions. A mathematical description of the service level model is provided in (1) and (2) using the following notation:qibatch quantity at retailer i, expressed in units of QQibatch quantity at retailer i, expressed in number of units (Qi=qiQ)Q0warehouse batch quantity, expressed in units of Qh0holding cost per unit and time unit at the warehousehiholding cost per unit and time unit at retailer ipishortage cost per unit and time unit at retailer iRireorder point for retailer iR0reorder point at the central warehouse in units of QCiexpected inventory holding costs per time unit at retailer i (for the backorder cost model the expected backorder costs are also included)C0expected inventory holding costs per time unit at the central warehouseTCexpected total system cost per time unitγiexpected fillrate at retailer iFRitarget fillrate at retailer i(1)MinTC(R0,R)=C0(R0)+∑i=1NCi(Ri,Li(R0))(2)S.t.γi(Ri,Li(R0))⩾FRi∀i=1,2,…NIn the backorder cost model, the constraints in (2) disappear and the retailer cost functions, Ci(i=1,2,…,N), are modified to include the expected backorder costs.Although the model assumes that all customer demands occur at the retailers, it is possible to deal with direct customer demand at the central warehouse by letting this demand be handled by a virtual retailer with transportation time zero. This approach has been analyzed, for example, in Axsäter et al. (2007) with good results.For small problem instances (of the backorder cost model) the described inventory system may be analyzed exactly using the method presented in Axsäter (2000). However, for the real life applications we have studied, the exact analysis is not computationally feasible. Thus, for practical implementation there is need for a computationally fast and accurate approximation method with focus on meeting fillrate targets.The method we propose in this paper is based on decomposing the complex multi-echelon system into N+1 single echelon systems using an induced backorder cost, β, at the central warehouse. This induced backorder cost should capture the costs afflicted to the system by delivery delays at the central warehouse. It is based on the marginal increase in expected cost at the retailers with respect to their replenishment lead-times. This means that expressions (1) and (2) are replaced by (3)–(5), where (3) is referred to as the warehouse problem and (4) and (5) define the N retailer problems. In (3), B0(R0) denotes the number of backordered subbatches of size Q at the warehouse for a given R0. Note that in steady state, the backorders at the central warehouse, B0(R0), only depend on R0 and not on the retailers’ reorder points (R1,R2,…,RN). The reason is that the steady state demand process seen by the warehouse is unaffected by the retailers’ reorder points.(3)MinR0C∼0(R0)=MinR0{C0(R0)+βQE[B0(R0)]}(4)Fori=1,2,…,NMinRiCi(Ri,Li(R0))(5)S.t.γi(Ri,Li(R0))⩾FRiThe advantage of the decomposed model is that the warehouse problem (3) can be solved first independently of the retailer problems, rendering a near optimal reorder pointR0∗. Then the retailer lead-times,LiR0∗, and lead-time demandDiLiR0∗can be determined. Finally, the N retailer problems can be solved in parallel rendering near optimal reorder pointsRi∗,i=1,2,…N.Heuristic coordination and computational efficiency are achieved by approximations of (i) the induced backorder cost, β, (ii) the subbatch demand at the central warehouse, and (iii) the retailer lead-times and lead-time demand. The following notation is used to describe the model.L¯iexpected replenishment lead-time for retailer iDi(t)customer demand at retailer i during time t (stochastic variable)λicustomer arrival rate at retailer ifi(j)probability that a customer at retailer i demands j unitsfik(j)probability that k customers at retailer i demands a total of j unitsmiexpected number of units demanded by a single customer at retailer iνivariance of the number of units demanded by a single customer at retailer iδi(n)probability that at most n batches of Qiunits (or qisubbatches) are triggered at retailer i during a time interval of length L0μiexpected demand (in number of units) per time unit at retailer iσistandard deviation of the demand per time unit at retailer i (in number of units)μ0expected lead-time demand (during L0) in units of Q at the central warehouseσ0standard deviation of the lead-time demand in units of Q at the central warehouseD0(t)subbatch demand (in units of Q) at the warehouse during t time unitsIPilocal inventory position at location i (=stock on hand+outstanding orders-backorders) in steady stateILiinventory level (=stock on hand–backorders) at location i in steady state(x)+max(0,x),(x)− is defined analogously as max(0,−x)Conceptually the proposed approximation model can be divided into the following five steps, which are further explained in Sections 2.1–2.5.Step 1: Estimate a near optimal induced backorder cost at the central warehouse, β.Step 2: Determine the lead-time demand at the central warehouse, D0(L0), in units of Q.Step 3: Determine a near optimal reorder point at the central warehouse,R0∗.Step 4: Estimate the lead-time demand at each retailer i, Di(Li).Step 5: Determine a near optimal reorder point at each retaileri,Ri∗.To estimate a near optimal induced backorder cost at the central warehouse, β, we use the approach presented in Berling and Marklund (2006). The first step in this method is to normalize the system with respect to li, μiand hi. More precisely, a time unit is defined so that li=1, a unit of demand is defined so that μi=100, and a monetary unit is defined so that hi=1. Table 1 in Berling and Marklund (2006), restated as Table A4 in the Appendix, shows how to move between the original and normalized system. The parameters in the latter are indicated with subscript n. Using the transformation we can estimate an induced backorder cost related to retailer i in the normalized system, βi,n, and then easily obtain the corresponding value in the original system as βi=hiβi,n. A closed form estimate of βican then be computed using the following equation:(6)βi=hig(Qi,n,pi,n)σi,nk(Qi,n,pi,n)Fori=1,2,…,NThe functions g(Qi,n,pi,n) and k(Qi,n,pi,n) can be determined from Berling and Marklund (2006) either by use of Table B1 and Table B2, or through Eqs. (13) and (14) found in their paper. For convenience these two equations are restated as (A10) and (A11) in Appendix A. In the present model, βiis determined by interpolation in the tables whenever the parameters are within the tabulated ranges, the equations are applied otherwise.Finally, β is estimated from (7) as a simple weighted average with respect to the expected demand per time unit. (Note thatμ0Q/L0=∑i=1Nμi.)(7)β=∑i=1NμiL0μ0Qβi.Clearly there are many other plausible weighting schemes. Berling and Marklund (2006), investigates some obvious alternatives that require more computational work, but they could not assert that these alternatives performed significantly better than (7). Thus in the name of simplicity we use (7), which also appears in Axsäter (2005).It should be noted that expression (6) for βineeds the normalized backorder cost for retailer i, pi,n, as input. This is not an issue for the backorder cost model since the backorder cost rates, pi(for i=1,2,…,N), are given. But for the service level model, values for pi(i=1,2,…,N) that correspond to the specified target fillrates need to be estimated. We use a simple approach and set pi/(hi+pi)=FRior equivalently pi=FRihi/(1−FRi). In case of normally distributed demand this corresponds to the optimal pi(which will produce the specified target fillrate if the total costs are minimized), see, for example, Axsäter (2006). For compound Poisson demand, setting pi=FRihi/(1−FRi) tends to underestimate pi. If piis underestimated, this means that also βiand β tend to be underestimated. Fortunately, Berling and Marklund (2006) and Axsäter (2005) emphasize that it is better to underestimate than to overestimate the induced backorder cost. Our numerical study supports this assertion, as the approximation model performs well.In order to solve the warehouse problem (3) we need the distribution of the lead-time demand at the central warehouse, D0(L0), expressed in units of Q. As demand is compound Poisson, the probability distribution of the customer demand at retailer i during time t can be determined as(8)P(Di(t)=j)=∑k=0∞(λit)kk!e-λitfik(j),wherefik(j)can be obtained recursively (see Axsäter, 2006, p. 79) asfik(j)=∑d=k-1j-1fik-1(d)fi(j-d).For the specified retailer model it is well known (see for example Axsäter, 2006, p. 88) that the inventory position at retailer i, IPi, is uniformly distributed over [Ri+1,Ri+Qi] as long as all demands are not multiples of some integer larger than one (if such a multiplicity should exist it is possible to rescale the unit size for this particular retailer). Thus, if we consider the retailer at an arbitrary time and let x=IPi−Ri, it follows that x is uniformly distributed on [1,Qi]. Moreover, if we consider the demand over the next L0 time units, Di(L0), this demand will trigger n retailer orders of Qiunits (or equivalently qisubbatches of size Q) where n=0 if Di(L0)<x, n=1 if x⩽Di(L0)<x+Qi−1 etc. From this observation, expression (9) for δi(n), the probability of at most n orders from retailer i during L0 time units, follows directly.(9)δi(n)=1Qi∑x=1QiP(Di(L0)⩽nQi+x-1)forn=0,1,2,…DefiningD0i(L0)as the subbatch demand from retailer i during L0 time units, with probability mass function (pmf)g0i(u), we have:(10)g0i(u)=PD0i(L0)=u=δi(0)ifu=0δi(n)-δi(n-1)ifu=nqi,n=1,2,…0otherwiseUsing (10), it is straightforward to obtain the exact pmf of D0(L0), denoted g0(u) through N−1 successive convolutions of the distributions forD0i(L0),i=1,2,…N. However, for the real data we have worked with, this exact approach is too time consuming. The computational complexity is typically caused by large Qivalues and small Q. Instead we compute the correct mean (μ0) and varianceσ02of the lead-time demand D0(L0), and fit a standard distribution to these two moments. The mean, μ0, can be obtained directly as the average total systems’ demand expressed in units of Q, i.e.,μ0=μ01+μ02+…+μ0Nwhereμ0i=(μiL0)/Q. To determineσ02we compute the variance of the subbatch demand emanating from retaileri,σ0i2, using (10) and then add them up, i.e.,σ02=σ012+σ022+⋯+σ0N2whereσ0i2=∑u=0∞μ0i-u2g0i(u)The distributions (with mean μ0 and standard deviation σ0) that are used for approximating g0(u) in our model are: (i) a negative binomial distribution (or equivalently compound Poisson with logarithmic compounding distribution) whenσ02/μ0>1(a necessary requirement for this distribution to exist), (ii) a discrete normal distribution when σ0/μ0< 0.25 and (iii) a discrete gamma distribution in all other cases. The reason for combining these three distributions in our model is to maintain computational efficiency and accuracy for all variance to mean ratios. The limitation of the normal distribution is that the accuracy suffers when the probability of negative demand increases. For the discrete gamma distribution there may be numerical problems when the variance to mean ratio is very high or very low.To avoid any ambiguities regarding the distributions we use, some definitions are called for. The negative binomial distribution is based on two parameters, p and r, where 0<p<1 and r can be any positive real number. Following, Axsäter (2006, pp. 80–82), the mean of this distribution is rp/(1−p) and the variance is rp/(1−p)2, which means that it is straightforward fitting it to μ0 andσ02for the warehouse lead-time demand; p=1−μ0/(σ0)2 and r= (μ0)2/((σ0)2−μ0). The corresponding pmf that approximates the warehouse lead-time demand distribution in units of Q as negative binomial is thenP(D0(L0)=u)=g0(u)≅(1-p)rforu=0r(r+1)…(r+u-1)u!(1-p)rpuforu=1,2,…The gamma distribution is defined by the parameters α>0 and θ>0, see for example Law and Kelton (2000). The mean is αθ and the variance is αθ2, thus fitting it to μ0 andσ02is easy; α= (μ0/σ0)2 and θ= (σ0)2/μ0. Defining F(x) as the cumulative distribution function (cdf) of the associated gamma distribution, we construct a discrete pmf to approximate g0(u) using (11). It is noteworthy that the mean and variance of the constructed pmf may deviate slightly from μ0 andσ02. Also, F(x) only exists in closed form when α is a positive integer.(11)P(D0(L0)=u)=g0(u)≅F(0.5)foru=0F(u+0.5)-F(u-0.5)foru=1,2,…Analogously, we use the normal distribution to construct a pmf to approximate g0(u) when μ0 is large compared to σ0 and the probability for negative demand is small. If F(x) represents the cdf of a normal distribution with mean μ0 and varianceσ02, (11) defines the approximated pmf. (Note, if Φ(.) denotes the cdf for the standardized normal distribution with mean 0 and variance 1, F(x)=Φ((x−μ0)/σ0).) As for the gamma approximation, the mean and variance of the constructed distribution may deviate slightly from μ0 andσ02. The normal distribution approximation is computationally much faster to use than the gamma distribution.The objective is to find a near optimal reorder point to the original system by solving the warehouse problem defined in (3).MinR0C∼0(R0)=MinR0{C0(R0)+βQE[B0(R0)]}where(12)C0(R0)=h0QQ0∑y=R0+1R0+Q0ED0(L0)[(y-D0(L0))+]=h0QQ0∑y=R0+1R0+Q0∑u=0y(y-u)g0(u)(13)E[B0(R0)]=1Q0∑y=R0+1R0+Q0ED0(L0)[(D0(L0)-y)+]=1Q0∑y=R0+1R0+Q0∑u=y∞(u-y)g0(u)Simplifying the cost expressionC∼0(R0)we get(14)C∼0(R0)=(h0+β)QQ0∑y=R0+1R0+Q0∑u=0y(y-u)g0(u)-βQR0+Q0+12-μ0.It is easy to show that, asβ>0,C∼0(R0)-C∼0(R0-1)is increasing in R0, which implies thatC∼0(R0)is convex. An optimalR0∗that solves the warehouse problem and satisfies the optimality condition (15) can therefore be found through a simple search.(15)R0∗=maxR0:C∼0(R0)-C∼0(R0-1)⩽0The replenishment lead-time to retaileri,LiR0∗, and the associated lead time demandDiLiR0∗are functions ofR0∗. Focusing on the lead-time, it consists of two components, the transportation time, li, and the waiting time because of stockouts at the central warehouseWiR0∗. The correct distribution ofWiR0∗is difficult to obtain for a general demand distribution. Andersson and Marklund (2000) provide a method that is exact under the assumption of Poisson demand, and Axsäter (2000) provides a more general method that are exact for compound Poisson demand. However, none of these methods is computationally feasible for the real cases that we study. We therefore focus on approximatingWiR0∗, and the associated lead-time demandDiLiR0∗. Our main approach referred to as M1 is to disregard the variability ofWiR0∗and focus on estimating its mean. However, we also investigate an alternative method, referred to as M2, where also the variance ofWiR0∗is estimated and incorporated into an approximation of the lead-time demand distribution. M1 is conceptually and computationally much simpler than M2.Method M1whereLiR0∗is approximated by its meanL¯iR0∗is based on Andersson et al. (1998) and Andersson and Marklund (2000) where this approach is shown to work well under different model assumptions. The same idea is also the basis for the well known METRIC model by Sherbrooke (1968), and it has since then been applied in many different situations. Note that for a constant lead-timeLiR0∗=L¯iR0∗the pmf of the lead-time demandPDiL¯iR0∗=jcan be obtained directly from (8) witht=L¯iR0∗.If all retailers are identical a direct application of Little’s law, see (16), renders the correct mean ofLiR0∗. (Recall that μ0 denotes the mean subbatch demand during L0.)(16)L¯iR0∗=li+L0μ0EB0R0∗In case of non-identical retailers, (16), does not represent the correct mean, but it can still serve as an approximation. We use this estimate in our model when partial deliveries are assumed, (i.e., if the central warehouse does not have enough stock on hand to satisfy a complete retailer order, it ships what it has and backorders the rest). If only complete deliveries are allowed, (i.e., the warehouse always waits until a complete order can be shipped) we propose to estimateL¯iR0∗using the simple approximation presented in Andersson and Marklund (2000) (their Eq. (30)). However, we refrain from providing numerical evidence as to the quality of this approximation in this paper. Our focus is solely on partial deliveries as this is what our case company uses.Method M2estimates the mean ofLiR0∗in the same way as in M1 using (16). The variance ofWiR0∗, (and consequently ofLiR0∗), is estimated by adopting the method in Axsäter (2003b) for normal demand to our demand assumptions. This method assumes that the variance, denoted (σW)2, is the same for all retailers. Details of this approximation method are provided in Appendix A. Given the mean and variance of the lead-time to retailer i, and (σW)2, respectively, we can obtain the associated mean and variance of the lead-time demand, μi(Li) and σi(Li)2 exactly as:(17)μi(Li)=E[Di(Li)]=μiL¯i(18)σi(Li)2=Var[Di(Li)]=σi2L¯i+μi2σW2For a derivation of (18) we refer to Axsäter (2006, pp. 121–122). As a final step we use μi(Li) and σi(Li) to fit a new compound Poisson process to describe the demand during the lead-time. In our numerical study we do this by retaining the same type of compounding distribution that was used to describe the demand in the first place. Thus if the demand originally was assumed to follow a compound Poisson process with a logarithmic compounding distribution, which means that the demand over a specified time period is negative binomial, we use μi(Li) and σi(Li) to fit a new negative binomial distribution to approximate the lead-time distributionDiLiR0∗. Analogously, if the compounding distribution is delayed geometric (or any other standard distribution), the only difference is that finding the lead-time distributions can be more or less time consuming as it involves convolutions of probability distributions. Clearly, one can think of many alternative approaches to estimate the lead-time demand distributions givenL¯iand (σW)2, but we find our approach to be straightforward, and a computationally simple adoption of the approach suggested in Axsäter (2003b). Investigating other approximations is an interesting topic for future research.When comparing M1 to M2, note that the mean lead-time is the same, but the variance is greater in M2, thus M2 represents a system with more uncertain leadtimes. This suggests that using M2 instead of M1 in our approximation model should render a solution with larger reorder points at the retailers and more system inventory. This can also be seen in our numerical results. However, a clean mathematical analysis of this relationship is difficult as M2 involves the fitting and use of a different compound Poisson process than M1. Moreover, because of the many layers of approximations used in our model there is little hope to assert analytically whether M1 or M2 will produce the best solutions. Therefore, we have opted to investigate this numerically.Given the estimated lead-time demandDiLiR0∗, from here on denoted Di(Li), each retailer i can be analyzed as a single-echelon inventory model with compound Poisson demand, controlled by a continuous review (Ri,nQi) policy. Following, for example, the analysis in Axsäter (2006), the steady state probability distribution of the inventory level at retailer i, given a reorder point Ri, is obtained from (19).(19)P(ILi=j|Ri)=1Qi∑k=max(Ri+1,j)Ri+QiP(Di(Li)=k-j)forj⩽Ri+Qi0otherwiseNote that P(ILi=j∣Ri=y)=P(ILi=j−y∣Ri=0), which means that this probability distribution only needs to be computed once as we search for the optimal reorder point,Ri∗.In the service level model (see (4) and (5)),Ri∗is the smallest Rithat satisfies the fillrate constraint (5) for the given lead-time demand Di(Li).(20)Ri∗=minRi:γi(Ri,Li)⩾FRiThe fillrate, γi(Ri,Li), can be obtained from (21). Note that γi(Ri,Li) is increasing in Rifor fixed Li.(21)γi(Ri,Li)=∑d=1∞∑j=1∞min(j,d)fi(d)P(ILi=j|Ri)∑d=1∞dfi(d)In the backorder cost model the objective is to minimize Ci(Ri,Li), the expected holding and backorder cost per time unit at retailer i. As Liis fixed while optimizing Ri, we simplify the notation by excluding Li.(22)Ci(Ri)=hiE[(ILi)+]+piE[(ILi)-]=-piE[ILi]+(hi+pi)E[(ILi)+]=-piRi+Qi+12-μiLi+(hi+pi)∑j=1Ri+QijP(ILi=j|Ri)Following Axsäter (2006), and defining P(ILi>0∣Ri) as the ready rate for retailer i when using the reorder point Riwe get(23)ΔCi(Ri)=Ci(Ri+1)-Ci(Ri)=-pi+(hi+pi)P(ILi>0|Ri+1)Because the ready rate is increasing in Ri, ΔCi(Ri) is increasing in Ri. Thus Ci(Ri) is convex in Ri, and (24) represent necessary and sufficient optimality condition with respect to Ri.(24)PILi>0Ri∗⩽pipi+hi<PILi>0|Ri∗+1Moreover, as P(ILi>0∣Ri)=0 for Ri⩽−Qiit follows from (23) thatRi∗⩾-Qi. Hence, we can initiate a search forRi∗at Ri=−Qi, and then increase Riincrementally by one unit at a time until (24) is satisfied andRi∗is found.The objective with this numerical study is to investigate the performance of the proposed approximation model for a wide range of scenarios characterized by lumpy, highly variable, demand. The study is based on four different test series and a total of 456 examples. Test series 1 investigates the performance relative to the exact solution of the backorder cost model. The optimal reorder points are then obtained exactly using the method in Axsäter (2000). Test series 1 consists of 48 problems evaluated with 3 different methods rendering a total of 144 examples.Test series 2 and 3 are focused on investigating the performance of the service level model, i.e., its ability to achieve the target service levels while minimizing the expected inventory holding costs. Due to the lack of a clearly defined exact method in the literature, we compare with the best Normal demand heuristic for the service level model suggested in Berling and Marklund (2012), referred to as BMN. This is the best among the methods investigated in this paper, including Axsäter (2003b). Test series 2 consists of 32 problems with identical retailers evaluated with three different methods resulting in 96 examples. Similarly Test series 3 also consist of 32 problems and 96 examples but in this case for non-identical retailers.For test series 1, 2, and 3, the parameters (order quantities, demand and cost rates) are chosen to reflect realistic situations with low and lumpy demand when a time unit corresponds to a month or a year.Finally, Test series 4, which encompass 105 examples, illustrates the performance of the service level model when applied to real data obtained from our case company for 35 representative articles. This study illustrates the improvements achieved by using the proposed service level model instead of the current method, CM, used by the company. CM is obtained from the Syncron Software and represents an uncoordinated approach as the reorder point at the central warehouse is optimized under set fillrate constraints. We also evaluate the performance against BMN.In all examples, the analytical models are used for determining the reorder points for the system. The performance measures for these different solutions in terms of total expected costs, fillrates, and average inventory levels are then obtained via discrete event simulation using the software package Extend from Imagine That Inc. An exception is the exact optimal solutions in Test series 1, where the total expected costs are computed analytically.Test series 1 is an expansion of the 16 test problems used in Axsäter (2005). It consists of 48 problems with non-identical retailers, 24 with 3 retailers and 24 with 6 retailers. The parameter settings for each of the 48 problems are specified in Table A1 in Appendix A. This table also contains the optimal reorder points and the exact total cost, together with the reorder points of our backorder cost model under lead time approximation M1 and M2, respectively. Using M1 our approximation model finds the optimal reorder points in 10 of the 48 problems. Using M2 the optimal policy is found in 9 problems. It is not surprising that the approximation model often do not find the optimal policy. The interesting question is how far from the optimal cost these solutions are. To investigate this we determine the expected inventory holding and backorder costs of the policies determined under M1 (TCM1) and M2 (TCM2) using simulation, and compare these costs to the exact optimal costTCoptE. We define the relative cost increase of the heuristics asΔTCM1=TCM1-TCoptE/TCoptE, andΔTCM2=TCM2-TCoptE/TCoptE. Table 1provides summary statistics for different subsets of Test series 1. Fig. A1 in Appendix A depicts ΔTCM1 and ΔTCM2 for each individual problem.From Table 1 we can see that on average both M1 and M2 perform quite well, staying within 1% of the optimal cost (ΔTCM1=0.91% and ΔTCM2=0.47%). Table 1 and Fig. A1 also indicates that M2 typically performs slightly better than M1. The main advantage being that the worst case performance is better. This can be seen both in Fig. A1, and from the maximum cost increase in Table 1 which is 5.36% for M1 and 2.86 % for M2. From Table 1 we can also see that both M1 and M2 tend to perform better when (i) N is large, (ii)σi2is large relative to μi(large coefficient of variation), and (iii) Q0 is small. These observations are encouraging as the model is designed to deal with items subject to infrequent but highly variable (lumpy) demand in large scale systems. As these items typically are characterized by a low average demand, an appropriate Q0 should also in most cases be relatively small.Explaining the observed behavior is not trivial because of the approximations used. However, the improved performance for large N may be explained by a smaller relative impact of each retailer on the delays at the central warehouse, which suggests that assuming that the delay to each retailer is the same is more appropriate. Similarly, a plausible explanation for the positive effect of more variable demand (larger coefficient of variation) is that with more inventory in the system, the total cost is, relatively speaking, less affected by deviations from the correct lead-times. Turning to the impact of Q0, we note that a large Q0 suggests a small R0, which means that the delays for retailer orders at the central warehouse tend to be either zero (when there is available stock at the central warehouse), or quite long (when items are not available). In these situations intuition tells us that it is less appropriate to replace the stochastic lead-time by its mean, as in M1, but also less appropriate to assume the delay is normally distributed, as in M2. A long L0 means that the delays are longer when they do occur. This is negative for the performance of M1 where the lead-time variability is ignored, but apparently it may be positive for M2, which, according to our tests, has a tendency to overestimate the lead-time variability.Test series 2considers a system with 6 identical retailers. Parameter settings for each of the 32 problems are available in Table A2 in Appendix A. This table also contains the policies obtained for M1, M2 and BMN as well as the fillrates computed for M1 and M2. The actual retailer fillrates, and the associated average system inventories, obtained from simulating the respective policies, are depicted in Fig. 1. Summary statistics for subsets of Test series 2 are provided in Table 2. TISIM denotes the total average inventory for the system obtained from simulation (as h0=hi=1 for all i, this also equals the expected holding cost per time unit).γiSIM(i=0,1,…,N)denotes the actual fillrate at location i(i=0 corresponds to the central warehouse) obtained by simulation of a given policy. We also defineγSIM=γ1SIM+⋯+γNSIM/N,Δγ=(γSIM-γ1), and ΔFR=(γSIM−FR1), noting that γ1=γi, FR1=FRifor all i. Δγ measures the model’s ability to estimate the actual fillrate. ΔFR indicates how well the actual fillrate for the obtained policy achieves the target. Because of the discrete compound Poisson demand and discrete reorder points there is generally a gap between γiand FRi, as can be seen in Fig. 1. With regards to the simulation results, the maximum standard deviation across allγiSIMis 0.4% for M1 (problems 5–8) and 0.5% for M2 (problems 5–6). The average of the maximum standard deviation forγiSIM(i=1,2,…,N)in each problem is 0.2% for both M1 and M2.From Table 2 we can see that the average performances of both M1 and M2 are quite good in terms of generating solutions that achieve the target fillrates (Total ΔFR=0.1% for M1 and 1.7% for M2). On average M1 outperforms M2 as it achieves the targets with lower inventory. From Fig. 1 and Table 2 we see that this holds for all problems 1–16 where μi=1. However, for problems 17–32 with μi=8, the M1 policies render solutions just below the target fillrates. As shown in Fig. 1, the M2 policies, on the other hand, always render fillrates above the targets, but often quite a bit above with high inventories as consequence, see Table 2.It appears that M1, typically, is better at producing solutions with fillrates that are close to the targets, while M2 produces solutions that are above the targets. An explanation for the former is that M1 underestimates (disregards) the lead-time demand variability. M2 on the other hand, incorporates the lead-time variability by adjusting the customer arrival rate and compounding distribution, and this tends to overestimate the need for safety stock. Table 2 and Fig. 1 show that both M1 and M2 perform considerably better than BMN, which only meets the target in two problems, and with a worse average performance as a result (ΔFR=−1.9%).Focusing on Δγ and ΔFR, Table 2 indicates that the performance of M1 and M2 is better for: (i) small μi, (ii) large coefficients of variationσi2/μi, (iii) small Q0 and Qi. This is consistent with the results for the backorder cost model in Test series 1. It is again reassuring that the model works best for the scenarios it is designed for, low but highly variable/lumpy demand tend to drive small order quantities. Another observation to be made from Table 2 is that the performance of both M1 and M2 (with regards to Δγ and ΔFR) appear to be better when the fillrate at the central warehouseγ0SIMis high. This is intuitive as correctly estimating the delays at the warehouse is less important when they constitute a smaller part of the total lead-time.Test series 3considers a system with N=6 non-identical retailers divided in two groups, G1 with retailers 1, 3 and 5, and G2 with retailers 2, 4 and 6. The retailers are identical within each group but different between groups. The detailed parameters for each of the 32 problems are available in Table A3 in Appendix A. Table A3 also specifies the reorder points obtained using M1, M2 and BMN. The results in terms of fillrates and average system inventory are reported in Table 3(averages) and Fig. 2(for each individual problem). In all problems h0=hi=1 for all i, so the average system inventory equals the average holding costs per time unit. We use the notation:γG1SIM=γ1SIM+γ3SIM+γ5SIM/3,γG2SIM=γ2SIM+γ4SIM+γ6SIM/3,ΔγG1=γG1SIM-γ1,ΔγG2=γG2SIM-γ2,ΔFRG1=γG1SIM-FR1andΔFRG2=γG2SIM-FR2. With regards to uncertainty in the simulation results, the maximum standard deviation forγiSIMin G1 (i=1,3,5) is 0.4% for M1, and 0.6% for M2. The corresponding maximum standard deviation forγiSIMin group 2 (i=2,4,6) is 0.2% for M1, and 0.3% for M2.Overall, the results for Test series 3 are similar to the results obtained from Test series 2. Table 3 together with Fig. 2 show that both M1 and M2 perform well in terms of meeting the target fillrates, both on average and in each individual problem. M1 is slightly better as it achieves the targets with less inventory. M2 has a tendency to overshoot the target fillrate with increased inventory as a consequence. The model’s precision in estimating fillrates as measured by ΔγG1 and ΔγG2 is quite good particularly for M1. In terms of ability to reach target fillrates, both M1 and M2 perform considerably better than BMN, which on average does not achieve the targets (ΔFRG1=−2.5%, ΔFRG1=−1.0%). See also Fig. 2.A closer look at the results in Table 3 and Fig. 2 reveals a tendency for both M1 and M2 to perform better when the coefficient of variation is high, and when the target fillrate is high. This is consistent with Test series 1 and 2 and can be explained in the same way.Comparing the results for the retailers in G1 with μ1=1, and G2 with μ2=4, we can see from Fig. 2 that M2 tends to perform worse (overshooting the target and the computed fillrates more) when the average demand is higher. For M1 the difference is much smaller, but reversed. The risk of not meeting the computed fillrate γi(and thereby the target) tends to increase with high average demand. Also this behaviour is consistent with the results for Test series 2.It is noteworthy that M1 performs better than M2 in test series 2 and 3 for service level model, while M2 is better than M1 in Test series 1 for the backorder cost model. This may seem contradictory but can be explained by the fact that M2 renders more retailer inventory than M1, which tends to underestimate the true lead-time demand. In the backorder cost model with hi≪pi(as in Test series 1), it impacts the total cost much less to overestimate than to underestimate the need for stock. In the service level model it tends to be the other way around. Overestimating the need for stock leads to higher fillrates and more inventory. Slightly underestimating the need for stock means less inventory (and oftenγiSim<γi), but the target may still be met as γi⩾FRi. This can be seen in Tables 2 and 3, and in Figs. 1 and 2.To investigate the performance of our model in a realistic setting, we evaluate it using real data from the case company. More precisely, Test series 4 encompass 35 items (all spare parts) that constitute a representative sample for the range of products that the company considers as lumpy demand items (intermittent with large variation in demand size). For simplicity we measure this by the coefficient of variationσi2/μi.We focus on the service level model with lead-time estimation M1. M2 is not considered for two reasons. First of all, the service level model under M1 is simpler and according to Test series 2 and 3 also more accurate in general. Secondly, it is ambiguous how to combine M2, (which involves modification of the original compound Poisson demand process) with the empirical compounding distributions we use for accurately modeling the real data. The model’s performance is measured by its ability to meet target fillrates at reduced inventory levels relative to the current method used by the case company (CM). We also compare with BMN. We focus on inventory levels as the case company presumes each item has the same holding cost rate at all locations. For each item, we have had access to data regarding: (i) number of retailers selling it (2⩽N⩽9), (ii) order quantities (1⩽{Q0 and Qi}⩽3278), (iii) transportation lead-times (5⩽{L0 and li}⩽31), (iv) customer demand at each retailer (mean and variance of demand per month, and size of each customer order), (v) target service level at each retailer (0⩽FRi⩽99.5%), and (vi) current reorder points (R0 and Ri).Based on the provided data, we model the item demand at each retailer as a compound Poisson process with an empirical compounding distribution. The reason for choosing an empirical distribution (estimated from data using relative frequencies) is that we found no standard distribution with a good fit. Fig. A2 in Appendix A illustrates the empirical compounding distribution for one of the items in Test series 4.As an indication of the highly variable and heterogeneous demand structure across the items, we consider the coefficient of variationσi2/μi,CV, for the demand at each retailer. For the items in Test series 4, MaxCV=309 and MinCV=1. A further illustration is found in Fig. A3 in Appendix A.Table 4provides summary statistics regarding achievement of target fillrates and average inventories for the different methods. For each item we define:ΔFRi=γiSim-FRias the deviation from the target fillrate at retailer i,ΔFR=∑i=1NΔFRi/Nas the average deviation from target fillrates across all retailers, and σ(ΔFRi) as the standard deviation of the deviations from target fillrates (across the retailers for a given item). We also define: ΔTIX=(TICM−TIX)/TICMas the relative decrease in average inventories for a given item when using method X to compute the reorder points instead of CM (X=M1 or BMN). Analogously ΔIWXis the relative decrease of inventories at the central warehouse. The summary statistics in Table 4 are complemented by Fig. 3which shows the average deviation from target fillrates (ΔFR) for each item when using M1, BMN, and CM, respectively. Similarly, Fig. 4shows the relative decrease in average system inventories of using our service level model under M1, or BMN, instead of CM.From Table 4 we can see that on average both M1 and BMN performs well in the sense that they achieve the target fillrates (Average ΔFRM1=0.6% and ΔFRBMN=2.3%). At the same time they manage to reduce the average inventory compared to the current solution CM (ΔTIM1=11.9%,ΔTIBMN=8.7%). In addition CM does a poor job in reaching the target fillrates (ΔFRCM=−12.2%). Hence, both M1 and BMN offer large potentials to drastically increase service and to reduce inventories. We can also see that M1 outperforms BMN in the sense that on average it achieves the target fillrates with less inventory. Structurally, the difference between CM and the coordinated solutions offered by M1 and BMN is that the latter two drastically reduces inventory at the central warehouse (ΔIWM1=71.5% and ΔIWBMN=71.8%) and moves some, but not all, of this inventory to the retailers.Fig. 3, shows that the fillrate performance for each item in Test series 4 is consistent with the average performance seen from Table 4; M1 is with few exceptions closer to the fillrate target (i.e., ΔFRM1 is closer to zero) than BMN. CM on the other hand rarely achieves the target and typically is far from reaching it. This is also reflected in the maximum and minimum deviations for the methods, where we can see across Test series 4 that −3.8%⩽ΔFRM1⩽5.6%, −4.2%⩽ΔFRBMN⩽14.8%, and −46.2%⩽ΔFRCM⩽2.6%. An additional strength with M1 over BMN and CM is that σ(ΔFRi) is smaller (see Table 4). This indicates that the variability of the deviations from target at each individual retailer (ΔFRi) is smaller.Looking at Fig. 4, it may seem discouraging for the performance of M1 (and BMN) that for several of the investigated items the new coordinated solution leads to an increase in total inventory for the system. However, in these cases the current method is very far from meeting the target fillrates, while M1 (and BMN) renders a solution that is on par with the targets. It is easy to see this by comparing the graphs in Figs. 3 and 4.Partitioning the items with regards to their average coefficient of variation,CV¯, Table 4 and Fig. 3 show that M1 (and BMN) is good at achieving the fillrate targets forCV¯⩾26(item #1–10) andCV¯<10(item #26–35), but for10⩽CV¯<26(item #11–25) there are several instances where ΔFR is slightly below zero (average ΔFRM1 for this subset is −0.2%). The explanation for this has less to do with the coefficient of variation (we know from Tests series 2 and 3 that M1 tends to perform better when the CV increases) and more with the fact that R0 for many items in this subset becomes strongly negative. This can be seen in Table 4 where average R0=−261 for10⩽CV¯<26, while it is −67 and −68 for the other subsets of items. The main reason for these negative reorder points is that the order quantities Q0, given by our case company, are quite large for many items. A large Q0 and strongly negative R0 mean that the delays at the central warehouse are either zero, or quite long (>L0), which makes the assumption about a constant lead time less appropriate. As a simple sensitivity analysis we have decreased Q0 for the items with10⩽CV¯<26 until our model renders a positive R0. When evaluating these solutions with simulation, the average ΔFRM1 increases to 1.8% (minΔFRM1=0.1%, maxΔFRM1=4.5%). Of course, it is a weakness of our model that its performance is negatively affected by strongly negative R0. However, arguably this is of less consequence for the practical use of the model. When discussing these matters with the case company and other practitioners, they stress that implementing a strongly negative R0 in practice, is not of interest. Waiting to place a replenishment order long after the inventory is depleted (and several backorder have accumulated) is not acceptable, particularly for spare parts with high demands on availability. An interesting application of our model is therefore as a tool for identifying when smaller order quantities are necessary in order to obtain a coordinated multi-echelon system with non-negative R0. A more elaborate extension of our model, for future research, is to optimize both Q0 and R0 under the constraint that R0⩾ 0. This requires accurate data regarding order set up costs and potential restrictions on feasible Q0 values. In considering such a model it should also be noted that the retailer reorder points (Qi) also influence the choice of R0.In this paper we have presented an approximation model for optimizing the reorder points in one-warehouse N-retailer systems with continuous review (R,nQ) policies, subject to highly variable compound Poisson demand. An important feature of the model is that it decomposes the complex multi-echelon problem into solving N+1 single echelon problems by introducing a near optimal induced backorder cost at the central warehouse. The complete heuristic also involves approximations of the distribution of retailer demand at the central warehouse, and the lead-time demand at all the retailers. For the latter we consider two different approaches M1 and M2. From a modeling perspective the main contribution of our work is that the resulting approximation model is accurate, computationally feasible, and conceptually simple enough to be implemented in practice. The general ideas we base the model on are not new, but previous literature have not combined these ideas to a complete approximation model.Another contribution of our work is that the model’s performance is investigated in an extensive numerical study which includes real data from our case company. This study shows that both versions of the model, M1 and M2, perform well. M1 is preferable when the objective is to achieve target fillrates while minimizing the holding costs. M2 tends to perform better when the objective is to minimize the expected holding and backorder costs.An important aspect of our model is that it is easy to combine with the Normal demand model in Berling and Marklund (2012). This model is computationally simpler and suitable for items with higher demand which cannot be solved with the present compound Poisson model. From the real cases we have studied, it is not uncommon that for the same item, the demand at some retailers are high and relatively smooth, whereas it is low and lumpy for others. The combined approximation model can easily deal with these types of heterogeneous demand structures. This is an important feature for the model’s applicability in practice, and one of the reasons why Syncron International is in the process of implementing it into its software.

@&#CONCLUSIONS@&#
