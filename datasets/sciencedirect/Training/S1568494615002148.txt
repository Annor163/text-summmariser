@&#MAIN-TITLE@&#
A novel hybrid adaptive collaborative approach based on particle swarm optimization and local search for dynamic optimization problems

@&#HIGHLIGHTS@&#
We propose a hybrid collaborative model based on fuzzy social-only particle swarm optimization and local search methods for dynamic optimization problems.We examine the performance of the proposed model on moving peaks benchmark (MPB) which is one of the most widely used benchmarks in the literature.We further extend the basic algorithm using novel resource management schemes, i.e. competition and hibernation, to improve the performance of the basic model.We investigate the influence of different components and parameters on the performance of the proposed algorithms.We propose the performance comparison between the proposed method and several well-known and recently proposed models.

@&#KEYPHRASES@&#
Dynamic optimization problems,Moving peaks benchmark,DOPs,MPB,Particle swarm optimizer,Naive direct search,

@&#ABSTRACT@&#
This paper proposes a novel hybrid approach based on particle swarm optimization and local search, named PSOLS, for dynamic optimization problems. In the proposed approach, a swarm of particles with fuzzy social-only model is frequently applied to estimate the location of the peaks in the problem landscape. Upon convergence of the swarm to previously undetected positions in the search space, a local search agent (LSA) is created to exploit the respective region. Moreover, a density control mechanism is introduced to prevent too many LSAs crowding in the search space. Three adaptations to the basic approach are then proposed to manage the function evaluations in the way that are mostly allocated to the most promising areas of the search space. The first adapted algorithm, called HPSOLS, is aimed at improving PSOLS by stopping the local search in LSAs that are not contributing much to the search process. The second adapted, algorithm called CPSOLS, is a competitive algorithm which allocates extra function evaluations to the best performing LSA. The third adapted algorithm, called CHPSOLS, combines the fundamental ideas of HPSOLS and CPSOLS in a single algorithm. An extensive set of experiments is conducted on a variety of dynamic environments, generated by the moving peaks benchmark, to evaluate the performance of the proposed approach. Results are also compared with those of other state-of-the-art algorithms from the literature. The experimental results indicate the superiority of the proposed approach.

@&#INTRODUCTION@&#
Optimization in dynamic environments has emerged as an important field of research during the last two decades, since many real-world optimization problems tend to change over time. The representative examples of real-world dynamic optimization problems (DOPs) are portfolio decisions optimization in changing stock market conditions, shortest path routing problem in changing network environments, and vehicle routing with online arrival of customer's requests. In these problems, the task of optimization is not confined to finding the optimum solution(s) in the problem space but to continuously and accurately adapt to the new conditions during the course of optimization.Each dynamic optimization problem P can be defined by a quintuple {Ω, x, ϕ, f, t} where Ω denotes the search space, x is a feasible solution in Ω, ϕ represents the system control parameters which determines the distribution of the solutions in the fitness landscape, f is the static objective function and t is the time. P is then can be modeled as follows [1]:(1)P=∑t=0endft(x,ϕ)As can be seen in the above equation, dynamic optimization problem P is composed of a sequence of static instances. Hence, the goal of the optimization in such problems is no longer just locating the optimal solution(s), but rather tracking the shifting optima over the time.The dynamism of the problem can then be obtained by tuning the system control parameters as follows:(2)ϕt+1=ϕt⊕ΔϕwhereΔϕis the deviation of the control parameters from their current values and ⊕ represents the way the parameters are changed. The next state of the environment then can be defined using current state of the environment as follows:(3)ft+1(x,ϕ)=ft(x,ϕt⊕Δϕ)Different change types can be defined, using Δϕ and ⊕. Li et al. [1] proposed a framework of the eight change types including small step change, large step change, random change, chaotic change, recurrent change, recurrent change with noise, and dimensional change. For additional information, interested readers are referred to [1].The adaptive nature of evolutionary algorithms and swarm intelligence methods make them suitable candidates for dealing with DOPs. However, the dynamic behavior of DOPs poses additional challenges to the evolutionary algorithms and swarm intelligence techniques. The main challenge of the mentioned techniques in dynamic environments is diversity loss which arises due to the tendency of the population to converge to a single optimum. Consequently, when a change occurs in environment, the number of function evaluations required for a partially converged population to re-diversify and re-converge to the shifted optimum is quite deleterious to the performance [2]. Particle swarm optimization (PSO) is one of the swarm intelligence algorithms that should undergo a certain adjustment to work well in dynamic environments.In this paper, a novel PSO-based approach which combines a fuzzy social-only model PSO and local search is suggested to address DOPs. The basic algorithm is then further extended based on three resource management schemes. Experimental studies are carried out on the sensitivity analysis of the several components and parameters of the proposed method. The performance of the proposed approach is also compared with several state-of-the-art algorithms on moving peaks benchmark (MPB) problem.The rest of this paper is structured as follows: Section 2 gives an overview to the basic PSO algorithm and its variants for dynamic environments. In Section 3, we explain our proposed approach in detail. Experimental study regarding the parameters sensitivity analysis, impact of using different local search methods, effect of applying different resource management schemes, and comparison with other state-of-the-art methods is presented in Section 4. Finally, conclusions and future works are given in Section 5.PSO is a versatile population-based stochastic optimization method which was first proposed by Kennedy and Eberhart [3] in 1995. PSO begins with a population of randomly generated particles in a D-dimensional search space. Each particle i of the swarm has three features:x→ithat shows the current position of the particle i in the search space,v→iwhich is the velocity of the particle i andp→iwhich denotes the best position found so far by the particle i. Each particle i updates its position in the search space, at every time step t, according to the following equations:(4)v→i(t+1)=wv→i(t)+c1r1[p→i(t)−x→i(t)]+c2r2[p→g(t)−x→i(t)](5)x→i(t+1)=x→i(t)+v→i(t+1)where w is the inertia weight parameter which determines the portion of velocity preserved during the last time step of the algorithm. c1 and c2 denote the cognitive and social learning factors that are used to adjust the degree of the movement of particles toward their personal best position and global best position of the swarm, respectively. r1 and r2 are two independent random variables drawn with uniform probability from [0,1]. Finally,p→gis the globally best position found so far by the swarm. The pseudo-code of the PSO is shown in Algorithm 1.PSO has been successfully applied in many optimization problems including numerical optimization [4,5], image processing [6], training feedforward neural networks in dynamic environments [7], density estimation [8], multi-objective optimization [9,10], data clustering [11], etc. However, as we mentioned in Section 1, PSO suffers from diversity loss when dealing with DOPs. Many attempts have been made by the researchers to deal with this issue. In the rest of this section, we will examine the current studies and advances in the literature in five major groups.A very basic strategy to cope with diversity loss problem is to inject a certain level of diversity to the swarm whenever a change occurs in the environment. An example of this approach is the re-randomization PSO (RPSO) proposed by Hu and Eberhart [12]. In RPSO, upon detecting a change in the environment, the entire or a part of the swarm is randomly relocated in the search space. Their results suggest that the re-randomization of a small portion of the swarm (i.e. 10% in their study) can improve the ability of the canonical PSO in tracking the shifting optimum, when the step size of the environmental change is small. It should be noted that specifying the proper rate of randomization is a challenging task. One the one hand, too much randomization will result in losing too much information and resemble solving the problem from scratch. One the other hand, too little randomization might be unable to introduce enough diversity to the swarm, which is necessary for tracking the optimum.A group of studies have tried to preserve a sustainable level of diversity during the entire run by avoiding individuals from converging to a single optimum.Applying a mutual repulsion between particles, swarms or captured optimums can maintain a suitable level of diversity during the search process. The atomic model [13,14] used in mCPSO is an example of utilizing repulsion for dynamic environments. In mCPSO, each swarm contains a number of charged classical particles. Charged classical particles in each swarm repel each other to provide a sustainable diversity among the individuals.Some researchers have modified the topology of information sharing among the particles of the swarm in order to improve the performance of PSO in dealing with dynamic situations. This can temporarily reduce the tendency of particles to move toward the best found positions, thereby enhancing the diversity among the swarm. For example, Janson and Middendorf [15] studied a hierarchical PSO (H-PSO) for noisy and dynamic environments. H-PSO uses a tree-like structure to establish a hierarchy between particles. They also proposed a partitioned hierarchical PSO (PH-PSO) where the tree is temporarily partitioned into sub-swarms after an environmental change is detected. Both approaches reported a significant improvement over standard PSO on different dynamic and noisy functions.Beside the above strategies, some researchers have considered other types of techniques to maintain diversity throughout the run. Li and Yang [16], for example, incorporated a random immigrants scheme into PSO where a temporal population is randomly generated if the population diversity drops below a constant threshold.Many studies have proved that making use of a memory scheme to restore useful information about previously found positions in the search space can be beneficial for various DOPs. For example, Wang et al. [17] proposed a memory-based PSO for dynamic environments. In this method, the entire population is divided into three parts: (1) “explore”-population which is responsible for collecting information about the good solutions, (2) “memory”-population for storing and retrieving information about promising areas of the search space, and (3) “exploit”-population that is used to refine the solutions around the areas provided by memory. They have introduced two new operators called memory-based resetting and memory-based immigrants to transfer information from memory to “exploit”-population. Their experimental results confirm that the memory scheme can enhance the performance of PSO in dynamic environments.The most widely used technique to cope with diversity loss problem is to make use of multiple swarms or to divide the particles of the main swarm into several sub-swarms, and assign them to different areas of the search space. In the rest of this sub-section, we examine two major types of multi-swarm PSOs for DOPs.Various methods exist in the literature that have used a fixed number of swarms to capture several promising areas of the search space in parallel. The pioneer work in this context was done by Blackwell and Branke [18]. They introduced a multi-swarm algorithm based on the atomic metaphor, namely mQSO. The mQSO starts with a predefined number of swarms, typically equal to the number of peaks in the landscape, exploring in the search space to locate the optima. In mQSO, each swarm is composed of a number of neutral particles and a number of quantum particles. Neutral particles update their velocity and position according to the principles of pure PSO. On the other hand, quantum particles do not move according to the PSO dynamics but change their positions around the center of the best particle of the swarm according to a random uniform distribution with radius rcloud. Consequently, they never converge, but provide the swarm with a sustainable level of diversity needed for tracking the shifting optimum. They also introduced two operators to establish two forms of interactions between swarms. First operator named exclusion, which prevents populations from settling on the same peak by reinitializing the worst performing swarm in the search space. Second operator is referred to as anti-convergence which is triggered whenever all swarms converge, and removes the worst swarm from its peak and reinitializes it in the search space. These two operators have initiated two implications for other researchers as: (a) search of two populations in the same area is not efficient and (b) it is necessary for different methods to be able to detect new emerging peaks, specifically in the environments with an unknown number of peaks.The critical drawback of the multi-swarm algorithm proposed in [18] is that the number of swarms should be defined before the optimization process, whereas in real-world problems the information about the environment may not be in hand. The very first attempt to adapt the number of swarms in dynamic environments was made by Blackwell [2]. He introduced self-adaptive version of mQSO, which dynamically adjusts the number of swarms either by spawning new swarms into the search space, or by destroying redundant swarms [2]. In this algorithm, swarms are categorized into two groups: free swarms, whose expansion, i.e. the maximum distance between any two particles in the swarm in all dimensions, are larger than radius rconv, and converged swarms. Once the expansion of a free swarm, becomes smaller than a radius rconv, it is converted to the converged swarm. In AmQSO, when the number of free swarms (Mfree) is dropped to zero, a free swarm is initialized in the search space for capturing undetected peaks. On the other hand, free swarms are removed from the search space if Mfreeis higher than a threshold nexcess.Dividing the main population of the algorithm into several clusters, i.e. sub-populations, via clustering methods and assigning each of them to different promising regions of the search space is a relatively new multi-population scheme for DOPs which has shown promising results [19]. For example, Parrott and Li [20] proposed a Speciation-based Particle Swarm Optimization (SPSO) for tracking multiple optima in dynamic environments, which dynamically distributes particles of the main swarm over a variable number of so-called species.Yang and Li [21] employed a single linkage hierarchical clustering method to create an adaptive number of sub-swarms, and assign them to different promising sub-regions of the search space. Each created sub-swarm then uses the PSO with a modified gbest model to exploit the respective region. In order to avoid different clusters from crowding, they have applied a redundancy control check. In this regard, when two sub-swarms are located on a single peak, first they are merged together and then the worst performing individuals of the sub-swarm are removed until its size is equal to a predefined threshold. In another work [16], they have further extended the fundamental idea of CPSO and introduced a framework for multi-population methods in undetectable environments, where the detection of environmental changes is very difficult or impossible.Nickabadi et al. [22] proposed a competitive clustering particle swarm optimizer (CCPSO) for DOPs. They employed a multi-stage clustering procedure to split the particles of the main swarm over a varying number of sub-swarms based on the particles positions as well as their objective function values. In addition to the sub-swarms, there is also a group of free particles that explore the environment to locate new emerging optima or exploit the current optima which are not followed by any sub-swarm, and are updated using a cognitive-only movement model. Moreover, each sub-swarm adjusts its inertia weight according to the success percentage of the sub-swarm [23].Another approach for dealing with diversity loss problem is to divide the search space into several partitions and keep the number of individuals in each partition less than a predefined threshold. Hashemi and Meybodi [24] incorporated PSO and Cellular Automata (CA) into an algorithm referred to as cellular PSO. In cellular PSO, the search space is partitioned into some equally sized cells using CA. Then, particles of the swarm are allocated to different cells according to their positions in the search space. At any time, particles residing in each cell use their personal best experience and the best solution found in their neighborhood cells for searching an optimum. Moreover, whenever the number of particles within each cell exceeds a predefined threshold, randomly selected particles from the saturated cells are transferred to random cells within the search space. In addition, each cell has a memory that is used to keep track of the best position found within the boundary of the cell and the best position among its neighbors. In another work [25], they changed the role of some particles in each cell, from standard particles to quantum particles for a few iterations upon the detection of a change in the environment.With the aim to improve the performance of cellular PSO, Sharifi et al. [26] proposed a two phased collaborative algorithm, named two phased cellular PSO (TP-CPSO). In TP-CPSO, each cell can function in two different phases: exploration phase, in which the search is performed by a modified PSO algorithm until a convergence to local optima is detected, and exploitation phase, in which the search process is conducted by a directed local search with a high capability of exploitation. Initially, all cells are in exploration phase, but upon converging to local optima they go to exploitation phase. Moreover, they eliminated the need for defining a limit for each cell.The major strategy in this approach is to divide the search space into different sub-regions, using a parent swarm, and carefully exploit each sub-region with a distinct child swarm. Several studies exist in the literature that have followed this approach. For example, Kamosi et al. [27] introduced a multi-swarm algorithm for dynamic environments, which consists of a parent swarm to explore the search space and a varying number of child swarms to exploit promising areas found by the parent swarm. In this method, called mPSO, the optimization process starts with a parent swarm exploring the entire search space for locating promising areas of the search space. Whenever the fitness value of the best particle in the parent swarm improves, a child swarm will be created as follows: (a) a number of particles located within the radius r from the best particle of the parent swarm are separated from the parent swarm and form a new child swarm and (b) a number of particles are randomly initialized in a hyper-sphere with radius r/3 centered at the best particle of the child swarm. Afterwards, a number of randomly initialized particles are added to the parent swarm in order to compensate for the migration of particles from parent swarm to the child swarm. After creating child swarms, each of them exploits their respective sub-regions in the search space. Upon detecting a collision between two child swarms, the worse child swarm is removed. In case that a particle of the parent swarm finds a better position in the search territory of a child swarm, it replaces the local best particle of the respective child swarm. Afterwards, the particle of the parent swarm is reinitialized in the search space. In another work, inspired by hibernation phenomenon in animals, they extended mPSO and proposed a hibernating multi-swarm algorithm (HmSO) [28]. In HmSO, unproductive search in child swarms is stopped by “sleeping” converged child swarms. This hibernation mechanism makes more function evaluations available for the parent swarm to explore the search space, and for the other child swarms to exploit their respective areas in the landscape.Recently, Yazdani et al. [29] employed several mechanisms in a multi-swarm algorithm to conquer the existing challenges in dynamic environments. In their proposed method, named FTMPSO, a randomly initialized finder swarm exploring the entire search space for locating the position of the peaks. Upon convergence of the finder swarm, a tracker swarm will be activated by transferring the fittest particles from the finder swarm into the newly created tracker swarm. The finder swarm is then reinitialized into the search space to capture other uncovered peaks. Afterwards, the activated tracker swarm is responsible for finding the top of the peak using a local search along with following the respective peak upon detecting a change in the environment. In order to avoid tracker swarms exploiting the same peak, exclusion is applied between every pair of tracker swarms. Besides, if the finder swarm converges to a populated peak, it is reinitialized into the search space without generating any tracker swarm.Our proposed approach is relatively similar to the methods of this group in the sense that it uses a main swarm to explore the search space. However, instead of using child swarms for exploiting promising areas of the search space, in this work we apply local search agents. Moreover, we use various schemes to effectively allocate the function evaluations to the most promising areas of the search space.In this approach, knowledge on the search process from different particles is included to improve the efficiency and effectiveness of the search process. Moreover, in this approach, different schemes and operators are further devised to promote the ability of the particles to deal with the environmental dynamism. For example, inspired by composite particles in physic, Liu et al. [30] introduced a new variant of PSO, called PSO with composite particles (PSO-CP) for DOPs. PSO-CP contains four major components: (1) composite particles which are formed by iteratively grouping the worst particles with two of their nearest particles, (2) scattering operator which aims at enhancing the local diversity within composite particles, (3) velocity-anisotropic reflection scheme that can improve the ability of particles for tracking the promising peaks in a new environment, and (4) integral movement strategy which is favorable for detecting new peaks in the search space by promoting the swarm diversity. Inspired by microbial life, Karimi et al. [31] proposed the dynamic hybrid PSO (DHPSO) where a new birth and death mechanism has incorporated into the PSO to dynamically adjust the swarm size during the search process. In DHPSO, each three neighborhood particles can produce a new infant, based on the quadratic interpolation distribution, with a certain probability. Moreover, they have used an aging scheme to remove the old particles.Some researchers have tried to combine desirable features of PSO with other optimization algorithms for DOPs. For example, Lung and Dumitrescu [32] introduced a hybrid collaborative approach for dynamic environments called collaborative evolutionary swarm optimization (CESO). CESO has two equal-size populations: a main population to maintain a set of local and global optima during the search process using crowding-based differential evolution (CDE), and a PSO population acting as a local search operator around solutions provided by the first population. During the search process, information is transmitted between both populations via collaboration mechanisms. In another work [33], a third population is incorporated to CESO which acts as a memory to recall some promising information from past generations of the algorithm. Inspired by CESO, Kordestani et al. [34] proposed a bi-population hybrid algorithm. First population, called QUEST, is evolved by CDE principles to locate the promising regions of the search space. Second population, called TARGET, uses PSO to exploit useful information in the vicinity of the best position found by the QUEST. When the search process of the TARGET population around the best found position of the QUEST becomes unproductive, TARGET population is stopped and all genomes of the QUEST population are allowed to perform extra operation using hill-climbing local search. They also applied several mechanisms to conquer the existing challenges in the dynamic environments. In this work, the authors have tried to spend more function evaluations around best found position in the search space. Here, our adaptations are also following the idea of spending more function evaluations around the best found position in the search space.In this section, first we describe the outline of the basic approach in detail. Three adaptations to the basic approach are then proposed to further enhance the performance of the basic algorithm by managing the function evaluations.PSOLS stars with a randomly initialized swarm exploring the entire search space to locate promising areas using a social-only movement model. Upon detecting such areas, a local search agent is created and placed on the best position found by the swarm. The swarm is then reinitialized into the search space to explore for locating other desirable regions. After creating LSAs, each of them is responsible for exploiting its respective region and tracking the respective peak after the change. Once an environmental change is detected, the fitness of all LSAs are re-evaluated and their step size is adjusted to the initial value. Moreover, the swarm is reinitialized. The structure of PSOLS is given in Algorithm 2. In the rest of this sub-section, the major steps of PSOledLS are described in detail.The initial swarm of particles is simply randomized into the boundary of the search space according to a uniform distribution as follows:(6)xij=Lj+rand[0,1]×(Uj−Lj)wherei∈[1,2,…,swarm_size]is the index of ith particle of the swarm,j∈[1,2,…,D]represents jth dimension of the search space, rand [0,1] is a uniformly distributed random number in the range of [0,1]. Finally, Ljand Ujare the lower and upper bounds of the search space corresponding to jth dimension.Moreover, the initial velocity of each particle is defined according to the following equation:(7)vij=(1−2×rand[0,1])×(vmax)where vijis the velocity of ith particle in jth dimension of the search space, rand [0,1] is again a random uniform number in [0,1], and vmaxis the maximum velocity.Several methods have been suggested for change detection. In this work, the best particle of the swarm is used as the “sentry” particle to detect the changes of the environment. In fact, the fitness value of the best particle is re-evaluated in each iteration. If the fitness of the best particle differs from its previous value, we can conclude that a change has occurred in the environment.Once an environmental change is detected, all LSAs are re-evaluated and the swarm is randomly initialized in the search space. Moreover, the step size for LSAs is adjusted to its initial vale.The particle swarm optimization used in this study is responsible for accomplishing a three-fold task: (a) exploring and detecting new promising areas of the search space, (b) placing a new LSA after converging to a previously undetected region, (c) controlling the density of the LSAs in different areas. In the following, the major components for accomplishing the mentioned tasks are described in detail.Wang et al. [35] introduced a fuzzy cognition local search (FCLS) operator based on the cognition-only model of PSO to generate the velocity vector of the particles. Their experimental results show that FCLS can improve the performance of PSO in DOPs. Inspired by this work, in order to enhance the exploration ability of the swarm and avoiding the stagnation problem, a fuzzy social-only model is presented in this paper which is described as follows:(8)g→′i(t)=N(g→(t),σi)(9)v→i(t+1)=wv→i(t)+c2r2(g→′i(t)−x→i(t))whereg→′i(t)is the fuzzy position of gbest for ith particle at time t, which is characterized by a normal distribution vectorN(g→i(t),σi). σiis a parameter which controls the distribution range of vector N based on the normalized distance of the ith particle to the best particle which is defined as follows:(10)σi=1−d(x→i,g→)∑popsizej=1d(x→j,g→)whered(x→i,g→)denotes the Euclidean distance between particle i and the best particle of the swarm, and∑j=1popsized(x→j,g→)is the total distance of all particles to the best particle of the swarm. The Euclidean distance between any two particles i and j in the D-dimensional search space is defined as follows:(11)d(i,j)=∑d=1D(xid−xjd)2In this model, the nearer the LSA to the gbest, the larger the distribution range of vector N, and vice versa.Various diversity measures exist in the literature for detecting the convergence of the swarm. For example, Blackwell [2] defined the swarm diameter as a criterion to determine the convergence of the swarm. The swarm diameter |S| is defined as the largest distance, along any dimension, between any two particles of the swarm. If the swarm diameter is less than a threshold parameter, one can conclude that the swarm has converged. In the present study, we use the distance between any particle andp→gof the swarm to examine the convergence. The swarm has converged if the distance between every particle andp→gis less than a threshold Rmin. The checking mechanism for convergence of the swarm is as shown in Algorithm 3.Several studies have confirmed that crowding of individuals in the same sub-area of the search space is not effective. In order to prevent LSAs from crowding in the search space and hence saving computing resources, a diversity control mechanism is introduced. In this regard, when the swarm converges to a position that has been already captured by a number of LSAs, it keeps the fittest LSA and removes the others from the search space. Algorithm 4 shows the density control mechanism in PSOLS.After locating a peak by the swarm, a local search agent is created by transferring the information of the best particle of the swarm to the LSA. The newly created LSA is then responsible for finding the top of the peak using a local search, and following the respective peak upon detecting a change in the environment. Any local search method can be used in this stage. In this study we apply different local search methods and investigate the effect of them on the performance of the proposed approach. These local search methods include a simple Random Walk (RW), Evolution Strategy (ES) [36], and Naive Directed Search (NDS) [26]. For detailed descriptions about RW, ES and NDS, interested readers are referred to the respective papers.Several variations of PSOLS can be obtained by using different local search methods. In these variations when we refer to PSO-NDS, for example, we mean that we use NDS in the local search stage. For the sake of completeness and because of the critical role that NDS plays in our approach, here we give the pseudo-code for NDS in Algorithm 5.A dynamic optimization problem can contain several peaks or local optima. However, as the heights of the peaks are different, they do not have the same importance from the optimality point of view. In PSOLS, all available resources, i.e. function evaluations, are equally distributed between LSAs. It means that, LSAs consume an equal portion of the function evaluations regardless to the height of the peaks where they stand on.As the first attempt to improve the performance of the proposed PSOLS, we try to allocate more function evaluations to the best performing LSA. The primary goal of the new adaptation is to let the best performing LSA perform extra local searches.The advantage of this adaptation is that better performing LSAs will receive more function evaluations that would otherwise have been spent on exploiting the maximum of the sub-optimal peaks. In short, competitive PSOLS operates as follows:(i)At the commencement of the run, allow the PSOLS to run in its standard manner.Let the best LSA, i.e. the LSA with the highest fitness value, perform an extra local search and return to step (i).The extra local search operation in the best LSA can be performed using any local search method and it should not be necessarily same as the local search in other LSAs. In this regard, various combinations of different local search methods are possible. Here, for example, CPSO(ES-NDS) means that the type of the local search in all LSAs is ES, and the extra local search on the best LSA is performed using NDS.The motivation behind this adaptation is to avoid allocating function evaluations to the LSAs that are not contributing much to the search process, hence allocating more fitness evaluations to the most successful LSAs. Therefore, HPSOLS differs from PSOLS in that local search operations are temporarily stopped in LSAs with step size less than Smin. The working procedure of HPSOLS can be summarized as follows:(i)At the commencement of the run, allow the PSOLS to run in its standard manner.If the step size of a LSA is less than the threshold Smin, then make it inactive.If no environmental change has been detected, return to step (i).Upon detecting a change in the environment, go to step (v).Activate all frozen LSAs, return to step (i).It is worth noticing that the hibernation mechanism has been previously introduced by Kamosi et al. [28] at the swarm degree. Similar strategies were also used by the other authors for controlling the number of active swarms during the run [29,37]. The major difference between the proposed mechanism in this work and those introduced in mentioned papers is that in this work we apply the hibernation at individual degree, which is one of the contributions of this paper.The basis for the new adaptation is to combine desirable features of both HPSOLS and CPSOLS together. Since HPSOLS and CPSOLS are independent adaptations, we can use both of them simultaneously. The CHPSOLS can be shortly described as follows:(i)At the commencement of the run, allow the PSOLS to run in its standard manner.If the step size of a LSA is less than the threshold Smin, then make it inactive.Upon detecting a change in the environment, go to step (iv).Activate all frozen LSAs, return to step (v).Let the best LSA to perform an extra local search and return to step (i).In this section, three groups of experiments are carried out in order to evaluate the performance of our proposed PSOLS. In the first group of experiments, we investigate the influence of different components and parameters of PSOLS on the performance. The second group of experiments is devoted to an in depth comparison of PSOLS with some PSO-based algorithms in numerous dynamic scenarios modeled by MPB. Finally, in the third group of experiments, we examine the performance of our proposed PSOLS in comparison with several recent and well-known methods in the literature on some of the most commonly used configurations of MPB.One of the most widely used synthetic dynamic optimization test suites in the literature is the moving peaks benchmark (MPB) proposed by Branke [38], which is highly regarded due to its configurability. MPB is a real-valued dynamic environment with a D-dimensional landscape consisting of m peaks, where the height, the width and the position of each peak are changed slightly every time a change occurs in the environment [39]. Different landscapes can be defined by specifying the shape of the peaks. A typical peak shape is conical which is defined as follows:(12)f(x→,t)=maxi=1,…,mHt(i)−Wt(i)∑j=1D(xt(j)−Xt(i,j))2where Ht(i) and Wt(i) are the height and the width of peak i at time t, respectively. The coordinates of each dimensionj∈1,Drelated to the location of peak i at time t, are expressed by Xt(i, j), and D is the problem dimensionality. A typical change of a single peak can be modeled as follows:(13)Ht+1(i)=Ht(i)+heightseverity⋅σh(14)Wt+1(i)=Wt(i)+widthseverity⋅σw(15)X→t+1(i)=X→t(i)+v→t+1(i)(16)v→t+1(i)=s|r→+v→t(i)|((1−λ)r→+λv→t(i))where σhand σware two random Gaussian numbers with zero mean and standard deviation one. Moreover, the shift vectorv→t+1(i)is a combination of a random vectorr→, which is created by drawing random numbers in [−0.5, 0.5] for each dimension, and the current shift vectorv→t(i), and normalized to the length s. Parameterλ∈0.0,1.0specifies the correlation of each peak's changes to the previous one. This parameter determines the trajectory of changes, where λ=0 means that the peaks are shifted in completely random directions and λ=1 means that the peaks always follow the same direction, until they hit the boundaries where they bounce off.Different instances of the MPB can be obtained by changing the environmental parameters. Three sets of configurations have been introduced to provide a unified test bed for the researchers to investigate the performance of their approaches in the same condition. Among them, the second configuration (Scenario 2) is the most widely used configuration, which was also used as the base configuration for the experiments conducted in this paper.For the purpose of measuring the efficiency of the optimization algorithms on DOPs, we use offline error which is the most well-known metric for dynamic environments. There are two measures in the literature which have been termed as “offline error”. The first one is the performance measure suggested by Branke and Schmeck [40] which is defined as the average of the smallest error found since the last change in the environment over the entire run as follows:(17)EO=1T∑t=1Tet*where T is the maximum number of function evaluations so far andet*is the minimum error gained by the optimization algorithm since the last change at the tth fitness evaluation.The other measure, which was first proposed in [41] as accuracy and later named as best error before change by Nguyen et al. [42], is calculated as the average of the minimum fitness error achieved by the algorithm at the end of each period right before the moment of change, as follows [21]:(18)EB=1K∑k=1K(hk−fk)where fkis the best solution obtained by the algorithm just before the Kth change occurs, hkis the optimum value of the Kth environment and K is the total number of environments. In this study, we use both measures to evaluate the performance of the proposed approach. For more detail on the difference between these two measures, interested readers are referred to [43].For PSOLS, a swarm with three particles is applied. The learning factors c2 is set to 1.496180 and inertia weight w is set to 0.729844. The convergence radius Rminand radius ξ are set to 10 and 20, respectively. For NDS local search, the initial step size δinit, discount factor b, and minimum step size Sminare set to 0.5, 0.2, and 0.01. When using ES and RW, the initial step size σinitis 0.2. For ES, (1+1)ES with 1/5 success rule is applied.Unless stated otherwise, the default value for the parameters of the proposed approach are according to Table 2. For each experiment of the proposed algorithm on a specific DOP, at least 500 independent runs were executed with different random seeds. For each run of the algorithm, 100 environmental changes were considered as the termination condition, which results in f×100 function evaluations. The experimental results are reported in terms of average offline error (best error before change) and standard error, which is calculated as standard deviation divided by the squared root of the number of runs. Moreover, in all experiments of this paper the results of the best performing algorithm, which are significantly superior to the others with a t-test at 5% significant level, are printed in boldface. In order to counteract the effect of type I error, Holm–Bonferroni correction [44] has been applied to control the family-wise error rate. In situations where the outcomes of the t-test reveal that the results of the best performing algorithms are not statically significant, all of them are printed in boldface.In this sub-section, effects of key parameters (i.e. swarm size, Rmin) and components (i.e. local search operation, function evaluation management scheme) on the performance of PSOLS were analyzed on different DOPs.In this set of experiments, we examine the effect of the swarm size on the performance of PSOLS in different dynamic environments. Various experiments were carried out with value of the swarm size chosen from [3,14]. The environmental parameters were the combination of change frequency f∈{500, 1000, 2500, 5000} and the number of peaks m∈{1, 3, 5, 10, 20, 100}.Fig. 1draws the average offline error of PSOLS with varying swarm size across different dynamic environments. From Fig. 1, it can be seen that the swarm size 3 produces a better result in most of the tested DOPs. It can be also seen that the performance of PSOLS is degraded as the swarm size increases. The reason mainly lies in the fact that the swarm is responsible for creating LSAs in promising areas of the search space. The bigger the population size of the swarm, the more function evaluations is consumed by the swarm for converging to an area. This makes less function evaluations available for LSAs to exploit the peaks.Our experiments revealed that, the standard PSO with only three particles fails to achieve a good performance due to the stagnation. However, the proposed fuzzy social-only model can improve the exploration ability of PSO by its random behavior.The aim of this experiment is to investigate the effect of Rminon the performance of PSOLS. As we mentioned in Section 3, Rminis a threshold parameter which is used to determine the convergence of the swarm. Therefore, it is expected that this parameter has a significant impact on the performance of PSOLS.From Table 3, it can be seen that PSOLS with Rmin=10.0 gives better results. On the one hand, a large value of Rmincauses that the swarm creates LSAs in areas far away from the peaks. On the other hand, a very small value of Rmincauses that the swarm consumes a large number of fitness evaluations to converge. In addition, a small value of Rmincan cause the swarm to frequently converge to a limited area of the search space. Table 3 also indicates that the extreme values for this parameter, i.e. 0.01, 0.1 and 100, gives the worst results.This set of experiments aims to investigate the effect of local search method being used by each LSA on the performance of PSOLS in DOPs with different complexities. The environmental conditions were different combinations of dimension d∈{5, 10, 100}, number of peak m∈{1, 10, 100}, and severity s∈{0.0, 1.0, 2.0, 3.0, 4.0, 5.0}. The results are given in Table 4. From Table 4, it is observed that NDS is the most favorable local search method in the majority of the tested DOPs.This experiment has been specifically designed to verify the effectiveness of hybridizing PSO with local search agents. In this experiment, the performance of the proposed method is compared with two different methods: (1) re-randomization PSO, i.e. RPSO and (2) a group of independent local search agents (GILSAs). For RPSO, a population size of 30 particles was used. Furthermore, the velocity of particles was clamped within the range [−20, 20] and the rate of re-randomization was set to 50%. For GILSAs, a number of LSAs equal to the number of peaks in the landscape are randomly initialized into the search space. Each LSA then starts to explore the search space using NDS. To prevent LSAs from searching in the same area, the exclusion operator with radius 20 is also applied.The results of experiment conducted to investigate the effectiveness of hybridizing PSO with local search agents are listed in Table 5.As shown in Table 5, all the results of the proposed hybrid method are much better than the results of RPSO and GILSAs. The comparison results clearly confirm the advantages of collaboration between the swarm and LSAs in PSOLS.The most important component of the proposed adapted algorithms is the resource management scheme that increases the efficiency of the PSOLS. Therefore, experiments were carried out to validate the benefits of the proposed adaptations. The main goal of this set of experiments is to specifically emphasize on the importance of the managing function evaluations for DOPs. Furthermore, we are interested in investigating the effect of combining different resource management schemes. The performance of different algorithms was evaluated on various DOPs with f∈{500, 2500, 5000}, d∈{5, 10}, and m∈{1, 10, 100}. Experimental results are provided in Table 6. Table 6 indicates that managing function evaluations is a major concern that can contribute much to the performance of PSOLS on dynamic environments.Several conclusions can be drawn from Table 6. Here we highlight a number of important conclusions as follows:(1)It is clearly observed that the resource management schemes have a significant influence on the performance of the proposed approach.The performance of CPSOLS(NDS-NDS) is worse than PSO-NDS. The reason is that NDS is a very expensive local search that consumes many function evaluations.Combining different local search methods in CPSOLS is preferable. Different local search methods have different characteristics. ES local search can improve the position of the LSAs with consuming fewer resources. Afterwards, NDS can exploit around the best found area more elaborately.The proposed hibernation mechanism can improve the performance of the proposed algorithm by stopping the local search in LSAs that are not beneficial for the search process.In this sub-section, various experiments were carried out to compare the performance of the proposed method with several PSO-based algorithms, on different DOPs generated by MPB. The involved algorithms include mQSO [18], AmQSO [45], CellularPSO [24], mPSO [27], HmSO [28], APSO [46], CPSO [21] and CPSOR11Source code for CPSO and CPSOR is publicly available at: http://cs.cug.edu.cn/teacherweb/lichanghe/pages/EAlib.html.[16], TP-CPSO [26], and FTMPSO [29]. Among the peer algorithms, the mQSO and AmQSO were implemented for this study as described in the corresponding papers. For CPSO and CPSOR on each DOP, the best configuration of the algorithms which enables them to achieve their best performance is adopted. The results of TP-CPSO were also updated for the purposes of this paper. For mQSO and AmQSO, the parameter settings that were suggested in the original paper were also applied here.The experiment aims to investigate the performance comparison between CHPSO(ES-NDS) and 10 PSO-based algorithms on DOPs with different number of peaks m∈{1, 5, 10, 20, 30, 40, 50, 100, 200} and change frequencies f∈{500, 1000, 2500, 5000, 10,000}. The other environmental parameters are set according to the MPB settings shown in Table 1. The various combinations of (f, m) resulted in 45 different DOPs being modeled by the MPB. The numerical results of different PSO-based algorithms are reported in Tables 7 and 8.From Tables 5 and 6, it can be clearly observed that our proposed method is superior to the other contestant algorithms on most of the tested DOPs. The results confirmed that our approach can successfully combine the explorative ability of the population-based method and exploitative capability of the local search in a single method.In this experiment, the effect of change severity on the performance of different algorithms is examined.As shown in Table 9, the performance of CHPSO(ES-NDS) is superior to the other methods in five out of six DOPs. In a DOP with s=5, the offline error achieved by FTMPSO is slightly lower than that achieved by CHPSO(ES-NDS). The reason is in the fact that FTMPSO utilizes the information about the shift severity, i.e. s, to respond to environmental changes, whereas this information may not be available in real-world situations.As can be seen in Table 10, the best error before change in CHPSO(ES-NDS) is less affected by the change severity of the environment.Many real-world problems consist of optimizing a large number of components. In this experiment, the performance of the eight PSO algorithms is investigated on the MPB with different dimensionalities d∈{5, 10, 20, 50} and other dynamic and complexity parameters are set according to Table 1.Regarding the results in Table 11, CHPSO(ES-NDS) can significantly outperform the other PSO variants. Results also indicate that our method is less affected by the number of dimensions.Comparing the results of CHPSO(ES-NDS) with CPSO and CPSOR in Table 12, the best error before change achieved by CHPSO(ES-NDS) is much less than that achieved by CPSO in all tested environments. Although on DOPs with d=5, and d=10 the results of CHPSO(ES-NDS) is slightly worse than those obtained by CPSOR, on DOPs with a large number of dimensions they are much better than the results of CPSOR. It should be noted that CPSO and CPSOR were reconfigured for each DOP separately, but the same settings were used for CHPSO(ES-NDS) in all experiments.This experiment aims to provide a visual view of the convergence behavior of CHPSO(ES-NDS). Fig. 2illustrates a graphical representation of the convergence of different PSO-based algorithms in a DOP with 50 peaks and change frequency 5000.Regarding Fig. 2, the first thing that stands out is that AmQSO and CellularPSO have the poorest performance during the whole search process. From the curves it is noticeable that the small population of CHPSO(ES-NDS) can be favorable to its current error at the very early stages of the optimization. Later, from evaluation 2400 to 30,000, TCPSO can perform slightly better than CHPSO(ES-NDS). The reason is that TCPSO can locate the peaks of the landscape faster. However, once the peaks are discovered, the powerful exploitation ability of the CHPSO(ES-NDS) can be very desirable in both refining the solutions and following the trajectories of the peaks after the change.In this sub-section, we study the performance of the proposed method in comparison with several recently proposed algorithms taken from the literature. The involved algorithms include:–The differential evolution with dynamic population adjustment for unknown environments (DynPopDE) [47].The competing differential evolution (CDE) [48].A modified multi-population artificial fish swarm algorithm (DMAFSA) [49].A bi-population hybrid approach (CDEPSO) [34].A memetic particle swarm optimizer (MPSO) [50].A competitive clustering particle swarm optimizer (CCPSO) [22].Two multi-population evolutionary algorithms with clustering scheme (CGAR and CDER) [16].The finder-tracker multi-swarm PSO (FTMPSO) [29].The speciation based firefly algorithm (SFA) [51].An improved artificial fish swarm algorithm (mNAFSA) [52].A multi-population electromagnetic algorithm (EM-POP) [53].The results of the peer algorithms shown in Tables 13 and 14are borrowed from their original reference. For each algorithm on a specific environment, the standard deviation, or confidence interval, has been converted to the standard error.From Table 13, it can be realized that the proposed CHPSO(ES-NDS) is considerably better than the other peer algorithms in most of the tested DOPs in terms of offline error.Considering Table 14, when the environment is unimodal, the best error before change for CHPSO(ES-NDS) is outstandingly better than the other contestants. For m=5, 10, 20, and 30, the reported results by FTMPSO is slightly better than those of CHPSO(ES-NDS). However, as the number of the peaks in the landscape is increased, CHPSO(ES-NDS) can reach lower error than FTMPSO. From Table 14, in DOPs with many optima, i.e. m=100 and 200, CHPSO(ES-NDS) is significantly superior to FTMPSO.From the comparison results of CHPSO(ES-NDS) with the other contestant methods on the MPB problem with various configurations, we can reach to the conclusion that the CHPSO(ES-NDS) algorithm is a highly effective method for optimization in dynamic environments.There are several key features that contribute to the high performance of CPSOLS(ES-NDS) on the dynamic test environments which can be summarized as follows:(1)Small population size. Many multi-population algorithms, e.g. mQSO [18], CellularPSO [24], CPSO [21], etc. are started from a big initial population. Therefore, these methods use too many function evaluations to detect the potential peaks. In contrast, CPSOLS(ES-NDS) starts with just three particles and dynamically adds and removes LSAs as required. This feature is beneficial specifically for fast changing dynamic optimization problems.Fuzzy social-only PSO model. The proposed fuzzy social-only PSO model improves the exploration ability of the PSO. More importantly, it enables PSO to operate with fewer number of particles, i.e. three particles in CPSOLS(ES-NDS).Density control mechanism. The density control mechanism provides the opportunity to avoid too many LSAs exploiting the same sub-area of the search space and hence save fitness evaluations.Hibernation mechanism. The hibernation mechanism used in LSAs prevents wasting precious fitness evaluations on unproductive LSAs. Therefore, more evaluations are saved and then allocated for searching other areas of the search space.Strong local search ability. The local search component of CPSOLS(ES-NDS) is a key factor in exploiting the promising sub-regions of the search and tracking the movement of peaks in the next environment.Competition mechanism. By choosing the best LSA to perform extra local search operation, the error value is reduced if the best LSA is on the highest peak. Using this mechanism, the best performing LSAs receive more fitness evaluations which is favorable to the performance of the CPSOLS(ES-NDS).A new hybrid model has been presented in this paper, called PSOLS, for dealing with DOPs. The main motivation behind the present study is to combine the desirable explorative features of PSO with exploitative features of local search methods. The basic algorithm has then further extended based on the following adaptations.–The first adapted algorithm aims at allocating more function evaluations to the best performing local search agents in the search space. In this regard, the best performing LSA receives an extra round of local search at each iteration. This way, we expect that more function evaluations to be spent on most promising areas of the search space.Saving computational resources, i.e. function evaluations, and allocating them to the successful individuals of the algorithm can improve the performance of the search process. Therefore, the main goal of the second adaptation is to stop the search process in LSAs that consume resources without contributing much to the optimization.In the third adaptation, a combination of both mentioned adaptations are presented.In order to validate the effectiveness of the proposed methods, a wide range of experiments were carried out to compare the proposed approach with various state-of-the-art algorithms on MPB. The experimental results confirm that the proposed hybrid approach is a very suitable tool for optimization in dynamic environments.Several research directions can be pursued as future works. First, the values of the parameters of PSOLS were adjusted based on some preliminary experiments. Therefore, a comprehensive sensitivity analysis on the effect of parameters could be a direction for future research. Second, since change detection will not work in many real-world dynamic optimization problems, e.g. noisy dynamic environments, it is interesting to propose a new method without change detection. Third, it is also very valuable to apply the proposed approach to several real-world problems.At the end, the authors would like to share the source code of PSOLS and will make it publicly available at http://ceit.aut.ac.ir/∼meybodi/.

@&#CONCLUSIONS@&#
