@&#MAIN-TITLE@&#
A new decomposition based evolutionary algorithm with uniform designs for many-objective optimization

@&#HIGHLIGHTS@&#
Any numbers of weight vectors with good diversity can be generated by a uniform design method.A sub-population strategy is used to enhance the local search ability of the algorithm.An update strategy based on decomposition is proposed to maintain the diversity.

@&#KEYPHRASES@&#
Multi-objective optimization,Decomposition,Uniform design,Weight vector,Many-objective optimization problems,

@&#ABSTRACT@&#
For many-objective optimization problems, how to get a set of solutions with good convergence and diversity is a difficult and challenging work. In this paper, a new decomposition based evolutionary algorithm with uniform designs is proposed to achieve the goal. The proposed algorithm adopts the uniform design method to set the weight vectors which are uniformly distributed over the design space, and the size of the weight vectors neither increases nonlinearly with the number of objectives nor considers a formulaic setting. A crossover operator based on the uniform design method is constructed to enhance the search capacity of the proposed algorithm. Moreover, in order to improve the convergence performance of the algorithm, a sub-population strategy is used to optimize each sub-problem. Comparing with some efficient state-of-the-art algorithms, e.g., NSGAII-CE, MOEA/D and HypE, on six benchmark functions, the proposed algorithm is able to find a set of solutions with better diversity and convergence.

@&#INTRODUCTION@&#
Multi-objective evolutionary algorithms (MOEAs) are a kind of effective method for solving multi-objective problems because they can handle a set of solutions in parallel. In the last twenty years, there are many well-known MOEAs [1–5] that are proposed, most of these MOEAs are based on Pareto dominance. Such Pareto dominance-based algorithms usually deal well with two or three objectives problems but their searching and selecting ability are often severely degraded with the increased number of objectives [6,50,51]. This is explained by the fact that, as the number of objectives increases, the proportion of non-dominated elements in the population grows, being increasingly difficult to discriminate among solutions using only the dominance relation [51]; if the number of solutions is constant, the size of non-dominance area of solutions will increase with the increase of the number of objectives, these will make the Pareto dominance-based fitness evaluation generate very weak selection pressure toward the Pareto front (PF). Therefore, how to enhance the selection pressure toward the PF and maintain the diversity of obtained solutions are critical for the many-objective optimization algorithms.Currently, the methods for dealing with many-objective problems can be divided into three categories. The first category uses an indicator function, such as the hypervolume [7–9], as the fitness function. This kind of algorithm is also referred to as IBEAs (indicator-based evolutionary algorithms), and their high search ability has been shown in the literature [10]. Recently, Bader and Zitzler [11] proposed a fast hypervolume-based many-objective optimization algorithm (HypE) which uses Monte Carlo simulation to quickly approximate the exact hypervolume values. However, one of their main drawbacks is the computation time for the hypervolume calculation which exponentially increases with the number of objectives [43], and even if the hypervolume values are calculated by Monte Carlo approximations, its running time is more than 10h after 50,000 objective function evaluations for seven-objective problems [44]. This limits the application of hypervolume indicator-based evolutionary algorithms to many-objective optimization problems.The second category takes advantages of solution ranking methods. Specifically, solution ranking methods are used to discriminate among solutions in order to enhance the selection pressure toward the PF, which makes sure the solutions are able to converge to the PF. At present, numerous approaches have been proposed to rank solutions for many-objective problems. Bentley and Wakefield [12] proposed ranking composition methods which extract the separated fitness of every solution into a list of fitness values for each objective. Kokolo and Hajime [13] proposed a relaxed form of dominance (RFD) to deal with what they called dominant resistant solutions, i.e., solutions that are extremely inferior to others in at least one objective. Farina and Amato [14] proposed a dominance relation which takes into consideration the number of objectives where a solution is better, equal and worse than another solution. Sato et al. [15] proposed a method to strength or weaken the selection process by expanding or contracting the solutions’ dominance area (CE).The third category utilizes the scalarizing functions to deal with the many-objective problems. According to the literatures [16–18], scalarizing function-based algorithms could deal better with many-objective problems than Pareto dominance-based algorithms. The main advantage of scalarizing function-based algorithms is that their fitness evaluation can be easily calculated. The representative MOEA in this category is MOEA/D [19] (multi-objective evolutionary algorithm based on decomposition), which makes use of traditional aggregation methods to convert a MOP into a number of single objective optimization sub-problems, and simultaneously optimizes each sub-problem in one single run. Each sub-problem is optimized by using information from its several neighboring sub-problems, which makes MOEA/D have a good performance. MOEA/D works well on a wide range of multi-objective problems with many objectives, discrete decision variables and complicated Pareto sets [20–22]. In MOEA/D, weight vectors play a very important role, they directly determine the distribution of obtained solutions and affect the convergence of obtained solutions. In MOEA/D [19], the uniformity of the used weighted vectors determines the uniformity of the obtained non-dominated optimal solutions; however, the used weighted vectors in MOEA/D are not very uniform and the size N of these weighted vectors should satisfy the restrictionN=CH+m−1m(where m is the number of objectives and H is an integer). Thus N cannot be freely assigned and it will increase nonlinearly with the increase of m, which restricts the application of MOEA/D to a certain extent in many-objective optimization problems. Therefore, for many-objective problems, how to set weight vectors is a very difficult but critical task, and it is necessary to consider an efficient and simple method to product the weight vectors [19,23]. Hughes [24] also considers a similar idea to set the weight vectors.Uniform design (UD) which is proposed by Fang and Wang [25] represents a combination of number theory and numerical analysis. The UD method has been successfully implemented in science, engineering and industries [26–31]. The literature [32] has shown that the uniform design performs better at estimating nonlinear problems than other designs. The foremost goal of the UD method is to find a set of points that are uniformly distributed over the design space, and the set has a small discrepancy. The UD method has been used in MOEAs to generate the weight vectors, for example, Leung and Wang [28] use the UD method to generate multiple weight vectors which are uniformly scattered points on a unit hypercube and each point on the unit hypercube yields a weight vector; the literature [22] uses the UD method to yield weight vectors and design a uniform design multi-objective evolutionary algorithm based on decomposition for many-objective optimization problems, but the algorithm only tests five-objective problems.Because the computation time for the discrepancy of a set of weight vectors exponentially increases with the number of objectives and the weight vectors, which restricts the application of the UD to many-objective optimization problems. In this paper, we use the inverted generational distance (IGD) [33] to approximate the discrepancy, then we use the UD method to generate a set of points which are uniformly distributed on a unit sphere, and the points are the weight vectors. In addition, a sub-population strategy is used to enhance the local search ability of the proposed algorithm. We make each sub-problem have a sub-population, and each sub-problem uses the information provided by its corresponding sub-population to improve the convergence performance. Then, a selection strategy based on decomposition and the sub-population strategy is designed to help crossover operators carry out the global search and local search. Moreover, a crossover operator based on the UD method is constructed to improve the search capacity. Based on all these, a new decomposition based evolutionary algorithm with uniform design, UDEA/D, is designed for many-objective optimization problems. The experiments demonstrate that UDEA/D can significantly outperform MOEA/D, NSGAII-CE (NSGAII based on contracting or expanding the solutions’ dominance area) and HypE on a set of test instances.The rest of this paper is organized as follows: Section 2 introduces the main concepts of the multi-objective optimization; Section 3 describes two related uniform design methods; Section 4 presents a crossover operator based on a uniform design method; Section 5 presents a new many-objective evolutionary algorithm; while Section 6 shows the experiment results of the proposed algorithm and the related analysis; finally, Section 7 draws the conclusions and proposes the future work.A multi-objective optimization problem can be formulated as follows [34]:(1)minF(x)=(f1(x),f2(x),…,fm(x))s.t.gi(x)≤0,i=1,2,…,e1hj(x)−0,j=1,2,…,e2where x=(x1, …, xn)∈X⊂Rnis called decision variable and X is n-dimensional decision space. fi(x)(i=1, …, m) is the ith objective to be minimized, gi(x)(i=1, 2, …, e1) defines ith inequality constraint and hj(x)(j=1, 2, …, e2) defines jth equality constraint. Furthermore, all the constraints determine the set of feasible solutions which are denoted by Ω. To be specific, we try to find a feasible solution x∈Ω minimizing each objective function fi(x)(i=1, …, m) in F. In the following, four important definitions [35] for multi-objective problems are given.Definition 1Pareto dominancePareto dominance between solutions x,z∈Ω is defined as follow. If(2)∀i∈{1,2,…,m}fi(x)≤fi(x)∧∃i∈{1,2,…,m}fi(x)<fi(z)are satisfied, x dominates (Pareto dominate) z (denoted x≻z).A solution vector x is said to be Pareto optimal with respect to Ω, if ∄z∈Ω:z≻x.The set of Pareto optimal solutions (PS) is defined as:(3)PS={x∈Ω|∄z∈Ω:z≻x}The Pareto optimal front (PF) is defined as:(4)PF={F(x)|x∈PS}In this section, two uniform design methods are briefly introduced. The main goal of a uniform design is to sample a small set of points from a given closed and bounded set G⊂RMsuch that the sampled points are uniformly scattered on G. In the following, we consider only two specific cases of G and describe the main features of uniform design. For more details, we refer to [25].We first explain the meaning of uniformly scattered points on the set G, which will be done with G being an m-dimensional unit hypercube,(5)C={(θ1,θ2,…,θM)|0≤θi≤1,i=1,…,M}For any given point r=(r1, r2, …, rM)∈C, a hyper-rectangle between 0 and r that is denoted by C(r) is defined by:(6)C(r)={(θ1,θ2,…,θM)|0≤θi≤ri,i=1,…,M}For a given set of q points in C, suppose that q(r) of these points fall in the hyper-rectangle C(r). Then the fraction of the points falling in the hyper-rectangle C(r) is given by q(r)/q. Since the volume of the unit hypercube is 1, hence, the fraction of volume of this hyper-rectangle is given by r1, r2, …, rM. The uniform design on C is then defined as determining q points in C such that the following discrepancy is minimized:(7)supr∈cq(r)q−r1,r2,…,rMLet l=(l1, …, lM) and u=(u1, …, uM) be two points of RM, where li≤ui, i=1, …, M.Denote(8)[l,u]={(θ1,θ2,…,θM)|li≤θi≤ui,i=1,…,M}Finding a set of exactly uniformly scattered points on [l,u] and C is, in general, very difficult, but there are some efficient methods to look for a set of well approximately uniformly scattered points on [l,u] and C. One of the simple and efficient methods is the Good-Lattice-Point method (GLP) [25], which generates a set of q uniformly scattered points on C, denoted by C(q,M), and a set of q uniformly scattered points on [l,u], denoted by O(q,M), respectively, as follows:For given q and M, a positive integer μ determines a q×M integer matrix that is called uniform array and can be generated by:(9)G(q,M,μ)=[Gij]q×MwhereGij=mod(iμj−1,q)+1,i=1∼q,j=1∼M).where mod(iμj−1, q) is the remainder of iμj−1/q. In general, μ∈{1, …, q−1}, this is because C(q,m,μ)=C(q,m,μ+hq) (for each i=1∼q and j=1∼M, mod(iμj−1, q)=mod(i(μ+hq)j−1, q), where h is an integer and μ+hq is a positive integer). Thus, there are q−1 different integer matrices to be generated by all these μ. So, for given q and M, they can determine a number δ (Table 1lists the values of δ for different values of q and M) which determines an integer matrix with the smallest discrepancy among these q−1 different integer matrices, and the integer matrix with the smallest discrepancy is denoted as C(q,M). In practice, the greatest common divisor of μ and q should be 1 to reduce the amount of calculation, which is because the integer matrix with the smallest discrepancy must be determined by these μ[25].Each row of matrix C(q,M,μ) defines a pointCi=(Ci1,Ci2,…,CiM)of C(q,M,μ) and a pointOi=(Oi1,Oi2,…,IiM)of O(q,M,μ) by(10)Cij=2Gij−12q,Oij=lj+cij(uj−lj),i=1–q,j=1–MC(q,M,μ) and O(q,M,μ) are given by(11)C(q,M,μ)={Ci|i=1–q}andO(q,M,μ)={Oi|i=1–q}when μ=δ, C(q,M)=C(q,M,μ) and O(q,M)=O(q,M,μ). For example, when q=11 and M=11, it can be seen from Table 1 that δ=11. Thus,G(q,M)=234567891011184117310629516115104938271TandC(q,M)={(0.13640.68180.500)(0.22730.31820.9545)(0.31820.95450.4091)(0.40910.59090.8636)(0.50000.22730.3182)(0.59090.86360.7727)(0.68180.50000.2273)(0.77270.13640.6818)(0.86360.77270.1364)(0.95450.40910.5905)(0.04550.04550.0455)}Let(12)U(m)={(f1,…,fm)|f12+⋯+fm2=1,fi≥0,i=1–m}denote the nonnegative hyper-quadrant of the unit sphere in the objective space. The main idea of uniform design on U(m) is mapping q points approximately uniformly distributed on a (m−1)-dimensional unit hyper-rectangle C to q points approximately uniformly distributed on U(m), or mapping q points approximately uniformly distributed on a subset of C to q points uniformly distributed on a subset of U(m). A set of q points uniformly distributed on U(m), denoted by D(q,m,μ), can be generated according to the following steps:A set of q uniformly distributed points on C=[0, 1]m−1 or on a subset of C is denoted by this set of pointsC(q,m−1,μ)={Ci=(Ci1,Ci2,…,Cim−1),i=1–q}. Each row of matrix C(q,m−1,μ) defines a pointDi=(di1,di2,…,dim)of D(q,m,μ) by:(13)sin(0.5Ci1π),ifj=m∏s=1m−1cos(0.5Cisπ),ifj=1sin(0.5Cim−j+1π)∏s=1m−jcos(0.5Cisπ),if2≤j≤m−1ThenD(q,m,μ)={Di=(di1,di2,…,dim),i=1–q}is a set of q points uniformly distributed on U(m).Since the computation time for measuring the discrepancy of a set of weight vectors (Eq. (7)) exponentially increases with the number of objectives, the optimal value δ is difficult to determine a large number of objectives (e.g., m≥20). In order to overcome this drawback, in this paper, on the basis of finding a set of weight vectors uniformly distributed on a nonnegative hyper-quadrant of a unit sphere, we propose to determine the optimal value of δ by the discrepancies of D(q,m,μ) instead of C(q,m,μ) and use the inverted generational distance (IGD) [33] to approximate the discrepancy of D(q,m,μ). The main reasons are that: (1) a goal of this paper is to obtain a set of weight vectors with good diversity, IGD can measure the diversity of a set; (2) the computational complexity of IGD(P*,P) is O(|P*|×|P|×m), which does not exponentially increase with the number of objectives (where, |P*|, |P|, m are the number of set P*, set P and objectives, respectively). So, the discrepancy of D(q,m,μ) can be replaced by the inverted generational distance (IGD) of D(q,m,μ). Let P* be a set of uniformly distributed points on U(M), the inverted generational distance from P* to D(q,m,μ) is defined as:(14)IGQ(P*,D(q,m,μ))=∑v∈P*d(v,D(q,m,μ))|P*|whered(v,D(q,m,μ))is the minimum Euclidean distance between v and the points in D(q,m,μ). If |P*| is large enough to represent the U(m) very well, IGD(P*,P)D(q,m,μ) could measure both the diversity and convergence of D(q,m,μ) in a sense. Because the points of D(q,m) are on the U(m), so the smaller the value of IGD(P*D(q,m,μ)) is, the better the diversity of D(q,m,μ) will be. Thus, the IGD can simply measure well the diversity of D(q,m,μ) such that the optimal value of δ can be readily determined here.Note that the optimal value of δ can be easily determined in the UD method such that a set of uniformly distributed weight vectors can be easily generated. Moreover, the number of weight vectors only needs to be larger than the number of objectives. In general, the number of the weight vectors is larger than the number of objectives. Hence, the UD method can easily generate a set of uniformly distributed weight vectors and its size can get any number which is greater than the number of objectives.In this section, we use the uniform design method in Section 3.1 to construct a crossover operator. The operator generates the offspring made by two parents and uniformly scattered in a region, and thus can effectively exploit the search space. The main idea is that, for two parents y=(y1, …, yn) and x=(x1, …, xn), we define two vectors,(15)l=(l1,…,ln)andu=(u1,…,un)where li=min{l1, …, ln}and ui=max{u1, …, un} for i=1∼n. These two vectors define a hyper-rectangle,(16)[l,u]={(z1,z2,…,zn)|li≤zi≤ui,i=1,…,n}Choose a proper integer q1. The uniform design in Section 3.1 is then used to generate q=q1 points uniformly distributed on [l,u], and these q1 points can be regarded as the offspring of two parents y and x.Note that the parameters M and q in the UD in Section 3.1 should satisfy M≤q−1 [25]. Thus, given M and q=q1, the set of q1 offspring, denoted by(17)O(q,n)={Oi=(oi1,oi2,…,oin)|i=1–q}O(q,n) can be generated according to two cases: M≤q−1 and M>q1−1. The detail is given by the following Algorithm 1.Algorithm 1Crossover operatorStep 1.For two parents y and x, define two vectors l and u by the formula (15) and a hyper-rectangle [l,u] by the formula (16). Choose a proper prime number q1.If n≤q1−1, take M=n in the formulas (9) and (11). Then the ith offspringOi=(oi1,oi2,…,oin)can be generated by the formulas (9) and (11) with M=n for i=1∼q1.If n<q1−1, take M=q1−1 and randomly divide l and u into M blocks of sub-vectors, respectively, in the following way:(18)l=(A1,A2,…,Aq1−1)andu=(B1,B1,…,Bq1−1)where Ajand Bjare sub-vectors of l and u in the same dimension. Then the ith offspringOi=(oi1,oi2,…,oiq1−1)can be generated by(19)Oij=Aj2Gij−12q1(Bj−Aj),i=1–q1,j=1–q1−1whereG(q1,q1−1)=[Gij]q1×q1−1is defined by (9) with M=q1−1.In this paper, we use the idea of MOEA/D to decompose a multi-objective optimization problem (MOP) into a number of scalar optimization sub-problems and optimize them simultaneously. In this work, the objective of each sub-problem is just an aggregation function of all the objectives in the MOP. The uniformity of the aggregation coefficient vectors determines the uniformity of the obtained non-dominated optimal solutions in a sense of MOEA/D. We use the framework of MOEA/D and try to use the UD method in Section 3.2 to set the weighted vectors. The UD method can generate a set of uniformly distributed weight vectors with the minimum IGD value, and the number of the weight vectors which is the population size of the algorithm will only need to be larger than the number of the objectives. Thus, the UD method is appropriate for many-objective problems to generate the weight vectors.The aggregation function also plays an important role in MOEA/D. There are several approaches used to convert a MOP into a number of scalar optimization problems [36]. In this work, Tchebycheff approach and its variant are mainly used. Let λ1, …, λNbe a set of uniformly distributed weight vectors (N is the number of population) and Z* be the reference point, i.e.,Z*=(Z1*,…,Zm*),Zi*=min{fi(x)|x∈Ω}for each i=1, …, m. In Tchebycheff approach, the ith scalar optimization problem is in the form(20)minimizex∈ngte(x|λi,Z*)=max1≤j≤m{λji|fj(x)−Zj*|}whereλi=(λ1i,…λmi). The variant of Tchebycheff approach is in the form:(21)minimizex∈ngTE(x|λi,Z*)=max1≤j≤m|fj(x)−Zj*|λjiIf the optimal solutionxi*of (21) is the Pareto optimal solution of (1), then(f1(xi*)−Z1*):⋯:(fm(xi*)−Zm*)=λ1i:⋯:λmi. We use (21) as the aggregation function to convert a MOP into a number of scalar optimization problems.The selection strategy has a great impact on the performance of local search and global search, thus an appropriate selection strategy can improve the performance of an algorithm. In this work, a selection strategy based on the decomposition and sub-population strategy is designed to achieve the goal. Firstly, compute the Euclidean distance between any two weight vectors and then work out the T closet weight vectors to each weight vector [27]. For each i=1, …, N, set B(i)={K*i1, …, K*iT} where λi1, …, λiTare the T closet weight vectors to λiand K is each sub-population size. Then set(22)S={(i−1)*K+1,⋯,i*K},ifrand1<p1B(i)ifrand2<1K*1,…,K*Notherwise,otherwisewhere rand1 and rand2 are two random numbers and their scope is [0,1], p1 and J are two parameters. l is set to 0.9 as the same in [21]. For the weight vector λi, the aggregation function value of xK*iis the smallest among x(i−1)*K+1, …, xK*i. When S is set, randomly select two indexes r2 and r3 from S, and generate some solutions from xr2 and xK*iby the crossover operator of Section 4 or then generate a solution from xK*i, xr2 and xr3 by the following formula:(23)xjnew=xjK*i+L(xjr2−xjr3),ifrand(0,1)<CRxjK*iotherwisewhere L∈[0,2] is a scale factor which controls the length of the exploration vector (xr2−xr3); CR is a constant value namely crossover rate; j=1, …, n andxjr2indicates the jth component of xr2.If S is set toB(i)ifrand2<J{K*1,…,K*N},otherwise, which helps crossover operators to carry out the global search, if S is set to {(i−1)*K+1, …, i*K}, which helps crossover operators to carry out the local search.Based on all the above, a new uniform evolutionary algorithm based on decomposition and sub-population (UDEA/D) is proposed and the steps of algorithm UDEA/D are as follows:Algorithm 2BeginEF→0//EF: number of function evaluationsInitialize POP//POP: population with N×K solutions (where N: the number of weight vectors (the sub-problems); K: the size of the sub-population.)Evaluate F(POP)//F(POP): fitness functionEF→EF+N*KInitialize Z=(Z1, …, Zm)//Z: reference pointSet B(i)={i1, …, iT}, i=1, …, N//λi1, …, λiTare the T closest weight vectors to λi, and T is the number of weight vectors in the neighborhood of each weight vector.Evaluate gTE(xi−1*K+1|λi, Z), i=1, …, N; j=1, …, K//gTE(xi−1*K+1|λi, Z): aggregation function, and sort gTE(xi−1*K+1|λi, Z), …, gTE(xi−1*K+1|λi, Z), then let gTE(x(i−1)*K+1|λi, Z)≥…≥gTE(xi−K|λi, Z).WhileEF<maxEFdofori=l, …, N doif random(0,1)<p2if random(0,1)<p1Select 2 indexes r2 and r3 from {(i−1)*K+1, …, i*K}elseif random(0,1)<JSelect 2 indexes r2 and r3 from B(i)elseSelect 2 indexes r2 and r3 from {K*1, …, K*N}end ifend ifGenerate a new solution y from xK*i, xr2 and xr3 by using the crossover operator Eq. (23), and apply a mutation operator on y to produce y′. Let EF=EF+1.Update of Z: For s=1, …, m, if Zs<fs(y′), then set Zs<fs(y′).fork=1, …, TifgTE(y′|λB(k), Z)<gTE(xB(k)*K|λk, Z), thenRandomly select a indexes h from {(B(k)−1)*K+1, …, (B(k))*K−1}, let xh=xB(k)*K, F(xh)=F(xB(k)*K), xB(k)*K=y′ and F(xB(k)*K)=F(y′).End ifend forelseSelect 1 index r2 from {K*1, …, K*N}Generate a set of new solutiony1,…,yq2from xK*iand xr2 by using the crossover operator Algorithm 1. Let EF=EF+q2forj=1, …, q2Apply a mutation operator on yjto producey′j.Update of Z: For s=1, …, m, ifZs<fs(y′j), then setZs<fs(y′j).fork=1, …, TifgTE(y′j|λB(k),Z)<gTE(xB(k)*K|λk,Z), thenRandomly select a indexes h from {(B(k)−1)*K+1, …, (B(k))*K−1, let xh=xB(k)*K, F(xh)=F(xB(k)*K),xB(k)*K=y′jandF(xB(k)*K)=F(y′j).end ifend forend forend ifend forend whileendIn this section, UDEA/D will be compared with three well known algorithms: multi-objective evolutionary algorithm based on decomposition (MOEA/D [21]), non-dominated sorting genetic algorithm II based on contracting or expanding the solutions’ dominance area (NSGAII-CE [15]) and fast hypervolume-based many-objective optimization algorithm (HypE) through experiments. The experiments are conducted on six widely used and challenging enough many-objective benchmark problems.Among six benchmark problems, four scalable test problems DTLZ1, DTLZ2, DTLZ3 and DTLZ4 are of the DTLZ family [38] which is a set of test problems often used in the analysis of MOEAs. They are selected for this study because they have the following important advantages: (1) they are easy to construct; (2) convergence and diversity are difficult to be controlled; (3) they can be easy scaled to any number of decision variables and objectives; (4) the global PF is known analytically and they have many local PFs. DTLZ1 has (11n−m+1−1) local PFs and DTLZ3 has (3n−m+1−1) local PFs [38]. The DTLZ1 and DTLZ3 problems can be used to investigate the global search ability of the algorithms and the ability to solve large numbers of objectives problems. All local PFs are parallel to the global PF. F1 and F2 with variable complicated PS shapes are used by Tan [22]. This class of functions with complicated PS shapes is proposed by Zhang [21] and is used as the test instances of the unconstrained MOEA competition in CEC 2009 [39]. It has been shown that these complicated PS shapes, as well as the geometrical shapes of the PF, can cause difficulty for MOEAs [40]. The F1 and F2 problems are used in order to investigate the ability of UDEA/D to search the decision space.The experiments are carried out on a personal computer (Intel Xeon CPU 2.53GHz, 3.98G RAM). The solutions are all coded as real vectors. Polynomial mutation [41] operators and differential evolution (DE) [37] are applied directly to real vectors in four algorithms, i.e. UDEA/D, MOEA/D, NSGAII-CE and HypE. The parameter configuration in this paper is as follows:(1)Control parameters in reproduction operators:(a)Crossover rate CR is 0.5 and scaling factor is 0.5 in the DE operator.Distribution index is 20 and mutation probability is 0.1 in Polynomial mutation operator.Let the number of points be q=5 in the UD method in Section 4.The parameter of CE [15] is set to 0.25.Two probabilities of UDEA/D are set to p1=0.8 and p2=0.9, respectively.Population size is set to 200 for all test problems and algorithms, 200 weight vectors are generated by the UD method in Section 3.2 for MOEA/D and UDEA/D. Number of the weight vectors in the neighborhood in MOEA/D and UDEA/D is 20 for all test problems.Each algorithm is run 20 times independently for each test instance. The maximal number of function evaluations is set to 400,000 for all test problems.In this paper, the following two performance metrics are used to compare the performance of the different algorithm quantitatively: generational distance (GD) [33], and inverted generational distance (IGD) [33]. GD measures how far the known Pareto front is away from the true Pareto front. If GD is equal to 0, all points of the known PF belong to the true PF. GD allows us to observe whether the algorithm can converge to some region in the true PF. IGD measures how far the true PF is away from the known PF. If IGD is equal to 0, the known PF contains every point of the true PF. IGD shows whether points of the known PF are evenly distributed throughout the true PF. Here, GD and IGD indicators are used simultaneously to observe whether the solutions are distributed over the entire PF. For IGD indicators, a large number of Pareto optimal solutions with well uniformity are needed in the reference set to obtain more reliable results [52,53]. Thus, in our experiments, the uniform design method is used to generate 100,000 uniformly distributed optimal solutions which are composed of the true PF for all problems. Wilcoxon Rank-Sum test [42] is used in the sense of statistics to compare the mean IGD and GD of the compared algorithms. It tests whether the performance of UDEA/D on each test problem is better (“+”), same (“=”), or worse (“−”) than/as that of the compared algorithms at a significance level of 0.05 by a two-tailed test.In this section, some simulation results are presented in Tables 2 and 3on six test problems with 5–25 objectives respectively, and the comparisons are made which demonstrate the performance of UDEA/D. The comparisons mainly focus on two aspects: (1) the convergence of the obtained solutions to the true Pareto optimal front; (2) the diversity of the non-dominated solutions. Although these comparisons are not exhaustive, they provide a good basis to assess the performance of UDEA/D. In addition, in this section, the aggregation function of UDEA/D is formula (21), while the aggregation function of MOEA/D is formula (20).Tables 2 and 3 show the mean and standard deviation values of the IGD metric and GD metric obtained by these four algorithms on test problems with 5–25 objectives respectively, and Wilcoxon test for pair wise comparisons of algorithms on each test instance is also shown in Tables 2 and 3. DTLZ1-k represents that the number of objectives adopted in DTLZ1 is k.It can be seen from Table 2 that, for the IGD metric, only MOEA/D has the same performance as UDEA/D on problem DTLZ2-20, and UDEA/D outperforms MOEA/D on other test problems and outperforms NSGAII-CE and HypE on all these test problems. From Table 2, we also can see that the mean values of IGD obtained by MOEA/D are much smaller than those obtained by NSGAII-CE and HypE for all these test problems, which indicates that for these test problems, the performance of MOEA/D is better than NSGAII-CE and HypE. However, the mean values of IGD obtained by UDEA/D are much smaller than those obtained by MOEA/D, especially, e.g., for each problem, the mean value of IGD obtained by UDEA/D is smaller at least 15% than that obtained by MOEA/D. These indicate that for these test problems, the solutions obtained by UDEA/D have better coverage than those obtained by other three algorithms and have good convergence. These also imply that decomposition-based evolutionary algorithms are better at maintaining the diversity than indicator-based evolutionary algorithms and sorting-based evolutionary algorithms.We can see from Table 3 that, for the GD metric, UDEA/D outperforms NSGAII-CE on nine problems, outperforms HypE on twenty-one problems, performs worse than NSGAII-CE on fifteen problems and HypE on six problems (a total of thirty problems). UDEA/D outperforms MOEA/D on twenty-six problems. These results indicate that UDEA/D can obtain better convergence than MOEA/D and HypE on most problems. From the table, we can also see that the mean values of GD obtained by UDEA/D are smaller than those obtained by MOEA/D on all these problems except problems F2-20 and F2-25, which indicate that UDEA/D has better convergence performance than MOEA/D on most problems. For NSGAII-CE and HypE, although the mean values of GD obtained by them are much smaller than those obtained by UDEA/D on some problems, the mean values of GD obtained by them are much larger than those obtained by UDEA/D, which show that solutions obtained by them may concentrate in some regions of the PF.Veček [45] proposed a chess rating system for evolutionary algorithms to compare and rank evolutionary algorithms. According to the thought of the ranking system, the Holm test [46] is used to implement the post hoc analysis for comparing and ranking these four evolutionary algorithms (i.e., UDEA/D, MOEA/D, NSGAII-CE and HypE). The standard error SE for the post hoc analysis with Holm test using the control algorithm isSE=(k+1)k/(6NM)4*5/(6*30)=1/3, where k and NM are the number or algorithms and test problems, respectively. Table 4shows the corresponding statistics and p values for the other three algorithms (i.e., MOEA/D, NSGAII-CE and HypE). Hypotheses from i=1–3 are rejected, which indicate that UDEA/D significantly outperforms MOEA/D, NSGAII-CE and HypE.In summary, the comparisons of the simulation results of these four algorithms show that UDEA/D is able to obtain much better spread, distributed and convergent PFs.HMOEA [47] is a novel hybrid multi-objective evolutionary algorithm which incorporates the concepts of personal best and global best in particle swarm optimization and multiple crossover operators to update the population. In order to compare UDEA/D with HMOEA, we used eight 3-objective problems (i.e., DTLZ1-DTLZ7 [38] and LZ09_F6 [21] which are tested in the literature [47]) as the test problems. To make a fair comparison and use the results of HMOEA [47] directly, the set of weight vectors size of UDEA/D is set to 100, the size sub-population is set to 5, and the maximal number of function evaluations is set to 25, 000 for these ten test problems, moreover, two performance metrics are used to compare the performance of the different algorithm quantitatively: generational distance (GD) [33] and spread (SP) [48].The mean and standard deviation values of GD and SP obtained by UDEA/D and HMOEA are shown in Table 5. Table 5 shows that the mean values of SP obtained by UDEA/D are smaller than those obtained by HMOEA on these eight problems except for DTLZ7, which indicates that for problems DTLZ1-DTLZ6 and LZ09_F6, the solutions obtained by UDEA/D have better coverage than those obtained by HMOEA; for problems DTLZ2 and DTLZ4-DTLZ7, the mean values of GD obtained by UDEA/D are larger than those obtained by HMOEA, which illustrates that the solutions obtained by HMOEA have a better convergence than those obtained by UDEA/D on these five problems; however, for problems DTLZ1, DTLZ3 and LZ09_F6, the mean values of GD obtained by UDEA/D are smaller than those obtained by HMOEA. In summary, HMOEA is better at improving the convergence than UMOEA/D; however, UDEA/D is better at maintaining the diversity than HMOEA.In this subsection, the contribution of the uniform crossover operator to the performance of UDEA/D is analyzed through experiments. The UDEA/D without the uniform crossover operator is denoted as UEA/D. All the other parameters remain the same as in Section 6.4. Table 6presents the mean and standard deviation values of the IGD metric and GD metric obtained by UDEA/D and UEA/D. It can be seen from Table 7that, for each problem, the difference of the mean values of IGD obtained by UDEA/D and UEA/D is very small, which indicates that the two algorithms have the same ability to maintain the diversity. However, mean values of GD obtained by UDEA/D are smaller than those obtained by UEA/D, which indicates that the uniform crossover operator can improve the convergence performance of UDEA/D.In this subsection, the effect of the sub-population strategy to the performance of UDEA/D is analyzed. In this subsection, the MOEA/D with aggregation function (21) is the UDEA/D without the uniform crossover and sub-population strategy. Table 7 presents the mean and standard deviation of the IGD metric and GD metric obtained by MOEA/D and UEA/D. From Table 7, we can see that the mean values of IGD obtained by UEA/D are much smaller than those obtained by MOEA/D for all test problems, especially, e.g., for each problem, the mean value of IGD obtained by UEA/D is smaller at least 50% than that obtained by MOEA/D. These indicate that for these test problems, the solutions obtained by UEA/D have better coverage than those obtained by MOEA/D. For GD metric, we can also see that the median values of GD obtained by UEA/D are smaller than those obtained by MOEA/D for all problems except F1-25, F2-20 and F2-25, especially, e.g., for each problem of DTLZ1-4 except DTLZ1-5 and DTLZ3-5, the mean value of IGD obtained by UEA/D is smaller at least 60% than that obtained by MOEA/D. These indicate that the sub-population strategy can improve the convergence performance of UEA/D. Even for problems F1-25, F2-20 and F2-25, the mean value of IGD obtained by UEA/D is smaller at least 70% than that obtained by MOEA/D, which implies that most solutions obtained by UEA/D converge to the true PF. Thus, the sub-population strategy can improve the convergence performance of UEA/D and makes a substantial contribution on the performance of UDEA/D.To study the sensitivity of the parameter in the proposed algorithm UDEA/D, we have to test different settings of the parameter in the implementation of UDEA/D on problems DTLZ1-DTLZ3 with 10-objecective, where the parameter value in DE operator was given in MOEA/D, we adopt these values. T is a major control parameter in UDEA/D. In order to study the sensitivity of T to the performance of UDEA/D, we use different values of T from 4 to 94 in the experiments of UDEA/D for 10-objective DTLZ1, DTLZ2 and DTLZ3. All the other parameters remain the same as in Section 6.2 except the setting of T. Fig. 1shows the variations of the values of IGD with different values of T on DTLZ1-10, DTLZ2-10 and DTLZ3-10. It can be seen from Fig. 1 that, for different values of T, the values of IGD only have a little bit variation on these three problems. This suggests that the proposed algorithm UDEA/D is not sensitive to the parameter. In addition, the computational complexity of MOEA/D will be increased with the T[19], thus the values of T should not be too large to reduce the computational complexity.The probability of p1 and p2 is two important control parameters in UDEA/D. They control the crossover strategy and way of crossover operator. To investigate the impact of them on the performance of UDEA/D, we have tested different settings of p1 and p2 on DTLZ1-10. All the other parameters are the same as in Section 6.2. Fig. 2shows the variations of the values of IGD with different values of p1 and p2 on DTLZ1-10. From Fig. 2, we can see that, when the value of p2 is smaller than 0.2, the performances of UDEA/D are relatively poor; however, when the value of p2 is larger than 0.4, the performances of UDEA/D are relatively good and different values of p1 have little impact on the performance of UDEA/D. In Section 6.7, we obtain that the sub-population strategy can improve the convergence performance of UDEA/D, so the value of p2 should not be very close to 1. Thus, we can obtain from Fig. 2 that, when the values of p2 are between 0.4 and 0.9, the performances of UDEA/D are relatively good and different values of p1 have little influence on the performance of UDEA/D.Through the above numerical experiment results, we can get that the performance of UDEA/D is better than NSGAII-CE, MOEA/D and HypE on most problems, which indicates that UDEA/D has good ability of exploration and exploitation. The main reasons of UDEA/D with good performance are that, (1) the update strategy can maintain the diversity of population and decrease the diversity of each sub-population, which helps to balance between exploration and exploitation [49]; (2) the crossover operators (i.e., Eq. (23) and Algorithm 1) have the ability of exploration and exploitation; (3) the selection strategy based on the decomposition and sub-population strategy helps the crossover operators to make the exploration and exploitation (If S is set toB(i)ifrand2<J{K*1,…,K*N},otherwise, the crossovers help to make the exploration. If S is set to {(i−1)*K+1, …, i*K}, the crossovers help to make the exploitation.).

@&#CONCLUSIONS@&#
