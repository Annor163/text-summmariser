@&#MAIN-TITLE@&#
Delineation and diagnosis of brain tumors from post contrast T1-weighted MR images using rough granular computing and random forest

@&#HIGHLIGHTS@&#
A new approach of tumor area delineation from T1C brain MR image.A complete framework of detection and characterization of brain tumors.The diagnosis can be performed from single slice of T1C MRI.

@&#KEYPHRASES@&#
MRI,Brain tumor,Rough entropy,Feature extraction,Tumor characterization,

@&#ABSTRACT@&#
This paper presents a new approach of delineation and characterization of four different types of brain tumors viz. Glioblastoma multiforme (GBM), metastasis (MET), meningioma (MG) and granuloma (GN) from magnetic resonance imaging (MRI) slices of post contrast T1-weighted (T1C) sequence to improve the computer assistive diagnostic accuracy. An integrated framework of identification and extraction of tumor region, quantification of histogram, shape and textural features followed through pattern classification by machine learning algorithm has been proposed. Rough entropy based thresholding in granular computing paradigm has been adopted for delineation of tumor area. After accomplishing quantitative validation and comparison with existing methods, experimental results prove the efficiency and applicability of proposed segmentation approach. In the next stage, the extracted lesions have been quantified with 86 features to develop the training dataset. Random forest (RF), an ensemble learning scheme has been implemented, which learns the training data for accurate prediction of the class label of a given input. The performance of RF has been evaluated by statistical measures from 3 fold cross-validation and compared with five different classifiers. The same experiment has been repeated over the reduced set of features generated by correlation based feature selection strategy. Experimental results show the superiority of RF (Sensitivity achieved in %: GBM-96.7, MET-96.2, MG-98.1 and GN-97.7) with the complete set of features. The comparison of proposed methodology with the existing works signifies its applicability and effectiveness. Additionally a 10 fold cross-validation has been accomplished to justify the statistical significance of the classification accuracy achieved from proposed methodology.

@&#INTRODUCTION@&#
At present scenario, the prevalence of brain cancer is increasing rapidly. It develops from brain tumor, which is a solid mass originated by the uncontrolled cell divisions in human brain leading to the abnormal growth of the cells [1]. The early diagnosis of tumor can help in better prognosis. MRI is widely appreciated popular imaging modality for initial diagnosis of brain tumor because of its noninvasive characteristics, radiation free environment and potentiality in providing image of internal body part with impressive soft tissue contrast. MRI follows different protocols viz. T1-weighted (T1), T2-weighted (T2) etc. for imaging. Interestingly, every MRI protocol or sequence provides different characteristics of tumor region. As a consequence, the intensity profile of the tumor tissues changes between sequences. Therefore, the diagnosis through interpreting the multispectral magnetic resonance (MR) images by observing and analysing the visual imaging features becomes a challenging task for radiologists. In fact the typical shape and orientation of tumors, sometimes heterogeneous intensity profile and overlapping intensity in the spatial imaging plane make the diagnosis difficult and confusing to the radiologists. As a result differential diagnosis happens. In the context of brain tumor diagnosis, it is a challenging task of distinguishing one type of tumor from other kinds having lookalike features (for example, GBM is the differential diagnosis of MET). In a regular practice, the manual segmentation of tumor for better interpretation is itself a time consuming procedure; which involves intra-observer variability. On the other hand, the brain biopsy (guided stereotactic surgery) is a surgical procedure of confirmatory diagnosis. But stereotactic biopsy is very risky and invasive surgery. Considering Indian socio-economic status, it is costly too. Under such circumstances, the development of a robust computer vision technique for exact detection of tumor region and the identification of its type from MR image computation can certainly improve the diagnostic process through helping in fast diagnosis, therapeutic and surgical interventions.GBM and MET both are malignant brain tumors. GBM is a primary tumor as it originates from the glial cells of brain and MET is developed due to the migration of the cancer cells from other organ and thus it is a secondary [1]. MG is an extraaxial benign tumor and common in middle aged women. Generally it appears large and compresses and causes damage to brain tissues. Hence it becomes fatal [1]. In this study, the GN lesions represent the small region of inflammation in brain due to the tuberculosis and neurocysticercosis. The tumor and its vascular region develop blood brain barrier, which is eventually the inherent characteristics of tumor. When nonionic gadolinium radiopaque (paramagnetic substance) is injected during T1C MR sequence, the barrier breaks down. In effect, we observe the enhanced visualization of abnormal vascularity in tumor which is referred as the enhancing lesion or active region. The enhancement of vascular region (enhancing lesion) is a common characteristic of all four tumors and it helps in understanding the boundary of tumor. Thus, this imaging sequence is a routinely followed scanning procedure in tumor diagnosis. During the course of T1C, the peripheral enhancement of GBM, MET and GN can be observed and hence they are named as ring enhancing lesions. Owing to this fact, the detection of the enhancing lesion and its contour signifies the boundary of core tumor region. The most threatening characteristic of brain tumor is its mass effect and because this infiltrates brain tissues. As a result, it holds a typical orientation in image. Sometimes in T1C images, the ambiguity exists in the boundary of tumor region. Under such conditions, the radio-diagnostic decision making for tumor evaluation seeks more attention toward minimization of ambiguity. In view of this, we propose a new framework through integrating pattern identification with automated classification of brain tumors by machine learning technique for its computer assistive diagnosis from T1C MR sequence with improved accuracy.In this section, we discuss the prior arts of tumor detection and characterization from MR images. Knowledge based fuzzy clustering [2,3] and fuzzy clustering [4] are popular techniques for identifying the exact location of abnormal mass from brain MRI and it has been used in various types of tumor segmentation. Warfield et al. developed an adaptive template moderated algorithm consisting of iterated sequence of spatially varying classification and nonlinear registration through embedding k-nearest neighbor (kNN) classifier for automatic segmentation of normal and abnormal anatomy of human brain from MR images [5]. Later, Kaus et al. [6] applied the same algorithm [5] for segmentation of low grade glioma (LGG) and MG and also validated the performance against the manually segmented results. Deformable models like level set, active contour etc. are also popular in tumor segmentation. For example, Ho et al. used intensity based fuzzy segmentation for initial classification of voxels in tumor and background region. According to this, tumor probability map was generated, which drove the automatic initialization of level set curve that generated the three-dimensional segmented region of GBM [7]. Prastawa et al. introduced the expectation maximization (EM) technique on atlas data for GBM segmentation and they reported 49–71% accuracy level over 5 cases [8]. In the next year, the same group proposed a knowledge based framework based on outlier detection for segmenting GBM [9]. In this approach, they considered only T2 MRI for simultaneous segmentation of both tumor and edema. They also discussed the contribution of edema in diagnosis and treatment. Zhang et al. [10] designed one class support vector machine (SVM) for classifying tumors. They also proved the superiority of their unsupervised approach over the supervised two-class SVM. Xie et al. proposed a hybrid level set method by combining region information as a propagation force and boundary information as a stopping function for semi-automated segmentation of brain tumor and edema [11]. In the same year, Lee et al. employed discriminative random fields classifier for detecting GBM and astrocytoma (AST) [12]. Corso et al. developed a novel methodology of segregating GBM from MR images by bridging the gap between affinity based and model based segmentation [13]. Wang et al. designed an integrated framework for segmentation of tumors from T1 MRI. Brain map was generated by Gaussian Bayesian classifier based on normalized Gaussian mixture model. Then 3D fluid vector flow was employed to extract the final contour [14]. Hsieh et al. [15] also developed a hybrid model through integrating fuzzy C-means with region growing for automatic segmentation of MG from non-enhancing lesions appeared in T1 and T2 MRIs. Sachdeva et al. introduced content based active contour model by integrating intensity and texture information for detecting various homogeneous brain tumors. In addition, texture space was generated with gray level co-occurrence matrix [16]. Rajendran and Dhanasekaran proposed possibilistic fuzzy C-means with modified distance metric for initial segmentation of tumor and later on parametric active contour model was implemented to obtain the final contour of tumor from T1C and fluid attenuation inversion recovery (FLAIR) images [17]. Gooya et al. developed a new technique based on EM for simultaneous segmentation and registration of glioma [18]. Georgiadis et al. modified the existing probabilistic neural network (PNN) classifier by introducing a nonlinear least squares features transformation (LSFT) for characterization of brain tumors from T1C MRI with improved performance as compared to PNN alone [19]. In the next year, the same group used LSFT-PNN for two stage classifications of brain tumors from T1C MR images; in the first step primary tumors were differentiated from MET and glioma was characterized from MG in the second step [20]. Five different categories viz., MET, MG, grade II glioma, grade III glioma and GBM were distinguished from MR image database of 102 tumors by three different classifiers viz. kNN, linear discriminant analysis (LDA), and nonlinear SVM [21]. They reached satisfactory classification accuracy for MET and grade II glioma, whereas in case of grade III and GBM accuracy was very poor. Kumar et al. proposed Principal component analysis (PCA) and Artificial neural network (ANN) based classification framework for discriminating various brain tumors and normal region from T1C MR images [22]. Sachdeva et al. introduced a new brain tumor characterization methodology consisting of genetic algorithm (GA) and SVM from T1C MR images [23]. After accomplishing an extensive literature review, it has been observed that no such MR image computing technique has been yet proposed for characterization of GN from brain tumors (viz. GBM, MET and MG). Sometimes the appearance of GN is lookalike to the ring enhancing MET lesion in T1C image and hence it is a challenging task to be solved in computational domain. Therefore, our study has taken up the problem of automated characterization of those brain tumors from MR images with augmented classification accuracy.The aim of this work is to develop a new computer aided decision support system for brain tumor diagnosis from MR image analysis. In this regard, the accurate detection and automated characterization of tumor can be performed with improved accuracy from the single slice of T1C MR sequence. The slice selection depends on radiologist's interpretation. Fig. 1represents the block diagram of proposed work. In this study the selected slices are processed to detect and extract the exact area of lesion by rough entropy based thresholding followed by morphological post processing. In the next stage histogram, shape and textural features are quantified from the tumor area and used as an input to the trained pattern classification module of RF for prediction of the desired tumor class. The performance evaluation of proposed approach and its comparison with different classifiers has been accomplished.The rest of the paper is organized as follows; Section 2 describes the proposed methodology through demonstrating segmentation, feature quantification and tumor classification steps. The details of brain tumor database, experimental outcomes with comparative analysis at segmentation and pattern classification steps and the impact of feature selection on tumor classification are presented in Section 3. Finally we have concluded the work in Section 4.The basic concept of rough set and roughness measure is described before demonstrating the binary classification or segmentation of MR images for tumor detection using this theory.According to the theory of rough set, any crisp set can be represented with its inner (lower) and outer (upper) approximations in the approximation space [24]. Let consider U is a universe of discourse and R be an equivalence relation on U. As a result of which U can be decomposed into number of disjoint classes. Now the quotient set of U can be denoted by U/R(U/R=S1, S2, …, Sn;Sirepresents the equivalence class of R). Theoretically, it is difficult to precisely represent S in the approximation space 〈U, R〉 for a given arbitrary set S∈2U. Under such case, with the help of rough set, S can be characterized by the pair of approximation spaces.The lower approximation(R_S)of S is defined as:(1)R_S=⋃Si⊆SSiThe above equation signifies that lower approximation is represented by the union of all the equivalence classes (Si, i=1, 2, ..., n) of R and each of which is a subset of S. For any object, it represents the positive region. That means the lower approximation of an object absolutely belongs to the inside region of the object.The upper approximation(R¯S)of S can be expressed as:(2)R¯S=⋃Si∩S≠∅SiIt is the union of all possible members of the set S which possess the non-empty intersection with them. According to the rule, if any element is a part of lower approximation of the object, it will also belong to the upper approximation of the same. Therefore, it contains both the positive and boundary region. The ambiguity exists in the boundary region and by definition it can be computed by subtracting lower from upper approximation as expressed below.(3)Boundary=R¯S−R_SThe interval between two spaces i.e.[R_S,R¯S]is the rough representation of S in the approximation space. When the image is represented in the rough domain, the classification accuracy of pixels into two approximation spaces can be obtained from the ratio of the cardinalities of lower and upper approximations. The mathematical expression for evaluating roughness of a set S can be defined as(4)RS=1−(|R_S|/|R¯S|)The value of roughness (RS) is ranging from 0 to 1. It becomes zero for a crisp set and for its nonzero value the set acts as a rough set [25]. In the proposed methodology, the rough entropy based thresholding has been implemented in the granular computing paradigm. The granules are the non-overlapping windows. The information contents from the granules have been taken into account in order to find the logical rule of accurate binary classification (tumor vs. background) through overcoming the barrier of gray level ambiguities.The limited discernibility of the tumor region or the vagueness of the tumor boundary in the gray scale MR images causes uncertainty leading to a poor interpretation of the image. Rough set has been employed to handle the uncertainty by representing tumor and background (non-brain and normal brain tissues) regions with lower and upper approximations [25]. Here, rough set works in granular computing paradigm. In granular computation, the whole image is decomposed into number of small windows having equal dimension. Now the image is computed by analysing each granule [25]. According to this, the uncertainty has been quantified by measuring the rough entropy from the tumor and background roughness of the granule (contains image pixels) [25]. Then the computed entropies from all granules should be maximized for the minimization of uncertainty in order to determine the optimal threshold value.In view of this, a gray level threshold will be derived from the rough entropy for the detection of tumor region [25]. A gray scale MR image is assumed to be a universe of discourse containing the set of pixels, which can be divided into number of granules (G) of equal dimension (p×q). In this respect, Ip×qhaving pq number of pixels in each granule, represent the induced equivalence classes. Now for a binary classification problem, the representation of tumor and background region in the rough domain with respect to a certain threshold (Th) is explained below.From the definition of rough set the lower approximation of the tumor region(Tu_Th):Tu_Th={⋃iGi|gj>Th,∀j=1,2,…,pq,gjbelongstoGi}The upper approximation of tumor region(Tu¯Th):Tu¯Th={⋃iGi,∃j,j=1,2,…,pq,subjecttogj>Th,wheregjisapixelinGi}The lower approximation of background region(Bg_Th):Bg_Th={⋃iGi|gj≤Th,∀j=1,2,…,pq,gjbelongstoGi}The upper approximation of the background region(Bg¯Th):Bg¯Th={⋃iGi,∃j,j=1,2,…,pq,subjecttogj≤Th,wheregjisapixelinGi}The algorithm for classification of image pixels in lower and upper approximations of tumor and background regions in order to determine the optimal rough entropy based threshold is illustrated below.Maximum gray level value of the image=Imax; Minimum gray level value of the image=IminMaximum pixel gray level in the granule=Gmax; Minimum pixel gray level in the granule=GminStep 1:for Th=Imin to ImaxforGmax≤gj≤ThTumor_lower_cnt(Th)=Tumor_lower_cnt(Th)+1forGmin≤gj≤ThTumor_upper_cnt(Th)=Tumor_upper_cnt(Th)+1forImin≤gj≤GminBackground_lower_cnt(Th)=Background_lower_cnt(Th)+1forImin≤gj≤GmaxBackground_upper_cnt(Th)=Background_upper_cnt(Th)+1end forStep 2: The roughness of both tumor and background regions for any granule at each threshold (Th) can be computed as (threshold varies from minimum to maximum gray level of an image)(5)TumorroughnessTh=1−Tumorlowerapproximation(Th)Tumorupperapproximation(Th)=1−Tumor_lower_cnt(Th)Tumor_upper_cnt(Th)and(6)BackgroundroughnessTh=1−Backgroundlowerapproximation(Th)Backgroundupperapproximation(Th)=1−Background_lower_cnt(Th)Background_upper_cnt(Th)Step 3: Rough entropy with respect to a threshold (RETh) is obtained from Shannon entropy(7)RETh=−e2[TumorroughnessTh×loge(TumorroughnessTh)+BackgroundroughnessTh×loge(BackgroundroughnessTh)]Step 4: Compute the maximum rough entropy for a particular granule(8)REmaxTh=maxImin≤Th≤Imax(RETh)Step 5: Repeat Step 1 to Step 4 to obtain REmaxThfor every granule. Now the maximization of the computed maximum rough entropies of the granules is performed as(9)Max_Rough_Entropy=maxi(REmaxTh(i))Hence, the optimal threshold (ThSeg) for segmenting tumor area from background region is (total number of gray levels=2l; l is 16 for 16 bit image) defined as(10)ThSeg=(2l−1)×Max_Rough_EntropyStep 6: Threshold the image in such a way that the gray levels 0, 1, 2, …, ThSegcome under the background region and ThSeg+1, ThSeg+2, …, L−1 segment to tumor region.During the implementation phase of the algorithm, Gmax and Gmin can be computed once for each granule. In the meantime, the image pixels are scanned once for the computation of rough entropy for the given values of Imax and Imin. This makes the complexity of the algorithm similar to the computation of image histogram [25].This section describes various types of descriptors viz. histogram, shape and texture based features which are quantified from the detected lesion area. In this study, four histogram based features, 19 shape descriptors and 63 textural features (all total 86 features) have been quantified to develop the feature vector(F_)which can be expressed as(11)F_=F1,F2,F3,F4,…,F83,F84,F85,F86The first order statistical features are derived from the image histogram. All total four histogram based features viz. mean, standard deviation, skewness and kurtosis are extracted; in which each of them represents mean, variations with respect to mean, degree of asymmetry and sharpness of the histogram respectively [26].These descriptors represent the shape information of the tumor region whose contour plays the key role in analysis. The detected gray scale tumor region is converted to binary for quantification of the following descriptors. The basic descriptors [26,40] are summarized in Table 1and other two are explained below.It represents the two-dimensional closed shape of the tumor region [26]. Theoretically, each boundary or edge point (pixels (xi, yi)) can be represented by the complex coordinate pair as shown below(12)z(k)=x+ijyiwherek=0,1,2,…The x-axis and y-axis indicate the real and imaginary axis of the complex numbers respectively. The complex coefficients of the discrete Fourier transformation of z(k) are regarded as the Fourier descriptors (four features) representing the shape of tumor boundary as expressed below.(13)A(u)=∑k=0K−1z(k)exp−j2πukKHu (1962) proposed two dimensional invariant moments as the shape descriptors for recognizing the visual pattern [27]. His seven moments were derived from the normalized central moments in which the central moment is represented in the form of Riemann integral and all the moments are rotational, translational, scaling and mirroring invariant. The discrete central moment (μpq)of order p+q for an image I(i,j) having dimension M×N can be defined as(14)μpq=∑i=1M∑j=1N(i−i′)p(j−j′)qI(i,j)wherep=0,1,2,…andq=0,1,2,…where, (i′, j′) indicates the centroid. The first feature of Hu's moment is equivalent to the moment of inertia with respect to the centroid of the image and the seventh one represents skewness invariant.Texture represents the roughness pattern of an object in an image. Hence, this kind of features are widely used as distinguished descriptors in the field of pattern identification. In this study, the following textural features have been quantified during the course of pattern classification.According to the principle, any surface in the Euclidean n-space can be regarded as self-similar only when the surface can be represented as the union of the scaled version of (by r factor) Nrnumber of its distinct non-overlapping copies [28,29]. It is defined as(15)FDim=logNrlog(1/r)wherer=sR;R=max(M,N)In the above equation, s, M and N denote the scaling parameter, number of rows and columns respectively. In this study, the differential box counting has been accomplished by employing sequential algorithm. The extracted tumor lesion is considered as an input to the algorithm and the grid size is kept as the power of 2. The dimension of each box is 2×2 during the computation of this single feature.GLDS emphasizes the absolute gray level differences between the two occurring pixels which are separated through a displacement vector δ(Δi, Δj) to compute the texture coarseness of tumor region [30]. Let I(i, j) is an image and for a given displacement δ(16)Iδ(i,j)=|I(i,j)−I(i+Δi,j+Δj)|and the probability density function p(x|δ) can be expressed as(17)p(x|δ)=prob(Iδ(i,j)=x)In this study, four different forms of pixel displacements viz. δ=(0, d), (−d, d), (d, 0), (−d, −d) have been employed to compute the four different density functions and for each of them three textural features (viz. contrast, angular second moment, and mean) can be obtained. In this study, the inter pixel spacing d is one. Finally, the mean values of the three textural descriptors among all displacements have been considered as features in the present study.The concept of Gabor filtering is the modulations of an oriented sinusoid by a Gaussian envelop [31,33]. A two dimensional Gabor filter is defined as(18)g(x,y,f)=12πσxσyexp−12x2σx2+y2σy2exp(−j2πfx)where, f, σx and σy denote the modulation frequency and the standard deviations of the envelop in both directions x and y respectively. The first term represents Gaussian envelop and second is the sinusoid. The children Gabor filters (gmn(x, y)) or the filter bank can be achieved after performing the rotation and scaling operations on the mother filter, which can be defined as(19)gmn(x,y)=g(x′,y′,fm);x′=xcosθn+ysinθnandy′=ycosθn−xsinθnwhere, m and n indicate the scale and orientation parameter respectively. In tumor region quantification, 24 texture channels have been generated by employing m=4(0, 1, 2, 3) with the corresponding frequenciesfm=24,28,216,232and n=6(0, 1, 2, 3, 4, 5) with the corresponding angles of rotations θn=0°, 30°, 60°, 90°, 120° and 150°. The response of the Gabor filter (Gmn(x, y)) can be obtained by convolving the image I having dimension M×N with a two dimensional Gabor filter as expressed below(20)Gmn(x,y)=I(x,y)∗gmn(x,y)=∑i=1M∑j=1NI(x−i,y−j)gmn(i,j)In this study, 48 Gabor texture features are quantified through computing the mean and standard deviation of each filtered image.Wavelet transform performs multiresolutional decomposition of the multidimensional signal into approximation and detailed coefficients. Approximation coefficient represents coarse information, while the detailed coefficients are responsible for fine details (viz. edge, line, contour etc.) of an image. An orthogonal wavelet, Daubechies ‘db1’ has been employed for decomposition of the tumor region at fourth level. The Frobenious norm of each coefficient has been computed as textural feature [32,33]. Let Clrepresents any one of the approximation or detailed coefficients (horizontal, vertical and diagonal). Their corresponding norm of N∈CM×Ncan be expressed as(21)||N||F2=∑i,j|Cij|2=∑i||Ni∗||22=∑j||Nj∗||22=trace(N*N)The energy of each subband, which contains the amount of information present in the respective subband has also been considered as texture feature and can be expressed as(22)El=(∑i∑jCl/∑l∑i∑jCl)×100Altogether 9 wavelet based textural features have been quantified; first four features are the norm of the approximation, horizontal, vertical and diagonal coefficients respectively, whereas the fifth one represents the energy of approximation subband and last four are the sum of the energies of detailed coefficients at each level of decomposition.According to Ojala et al. (2002), LBP describes the spatial structure of circularly symmetric neighborhood centered at a pixel of an image [34]. Each pixel can be defined by a LBP code which is generated by summing the product of binomial factor 2i(for 3×3 neighborhood 0≤i≤7) and the outcome of thresholding of corresponding neighboring pixels with respect to the center one. Once the LBP coded image is generated, its histogram can be considered as the texture representation of the image. But this kind of hard thresholding is sensitive to noise and may not efficient where uncertainty exists. In view of this, Iakovidis et al. [35] proposed fuzzy LBP to enhance the performance of existing one. Let Icand Inare the center and neighboring peripheral pixels respectively and the degree of fuzziness is Tf. The membership (μ0(i)) function can be defined as(23)μ0(i)=0forIn≥Ic+Tf(Tf−In+Ic)/2TfforIc−Tf<In<Ic+Tfandμ1(i)=1−μ0(i)1forIn≤Ic−TfNow the contribution LBP, CLBPfor 3×3 neighborhood defining a single bin in fLBP histogram can be expressed as(24)CLBP=∏i=07μdi(i)where diis the threshold operator (like a unit step function) and hence every pixel can be recognized by multiple LBP codes. In this study, a 3×3 neighborhood with 5 as the degree of fuzziness has been employed to obtain the fLBP histogram from which the mean and standard deviation as the two textural features of tumor region have been computed.This learning scheme was developed by Breiman [36] to establish an ensemble classifier containing a set of decision tree classifiers can be expressed asC(X_,Θn)for n=1, 2, …, whereΘnare the independent random vectors of predictor variables having identical distribution with previous vectors andX_denotes input vector for which every tree would cast unit vote to the eligible brain tumor class. RF has ability to handle large set of predictor variables and it does not require any selection strategy as it itself can estimate the importance of features. In addition, this algorithm can run on large dataset and also well capable of estimating missing data. Apart from that, it is computationally faster, robust to noise and outliers as compared to conventional bagging. This learning scheme starts by building trees through employing bootstrap aggregating and random selection of predictor variables. RF comprises of ensemble of decision trees for classification, which are raised over the bootstrap data of training set. Accordingly, the candidate set of predictor variables are randomly identified from the actual feature set at every split and each tree grows till it gets low bias [37]. Finally the prediction will be taken on the basis of majority voting of the set of n trees. The work flow of RF is explained below.Model input:Training dataset:STrain={(d¯1,l1),(d¯2,l2),…,(d¯m,lm)};(d¯i,li)→(featurevector,classlabel)ofithdatasampleNumber of trees: NTreeNumber of predictor variables selected for splitting: nvarTrain model:for i=1:NTreedo• perform bootstrap aggregating to create subset, Dbof independent random vectors from training dataset• perform random selection of nvar variables in order to select the best split at every node of tree• unpruned tree constructionend forPattern prediction:Majority voting of NTreetrees as a criterion to predict the class as expressed below:(25)favg(D)=(p1(D),p2(D),…,pi(D))=1NTree∑i=1NTreefi(D)(26)fRF(D)=argmaxi{p1(D),p2(D),…,pi(D)}The MRI scans were performed by 1.5T MRI machine (GE Signa 1.5T SYS#GEMSOW) at EKO CT & MRI Scan Centre, Medical College and Hospitals Campus, Kolkata, India. The institutional ethical clearance was obtained for conducting this study. The post contrast (gadolinium injected) T1C images were acquired with 5mm slice thickness, 90° flip angle, 512×512 spatial resolution and 240×180mm2 field of view. In general, 10ml nonionic paramagnetic substance (gadolinium-dimeglumine) was injected for efficient disruption of blood–brain barrier in T1C sequence. The acquired images were collected from MRI workstation in Digital Imaging and Communications in Medicine (DICOM) format for processing. The MR image database consists of 10, 13, 18 and 28 cases of GBM, MET, MG and GN (25 tuberculoma and 3 neurocysticercosis) respectively. The task of manual characterization or grading of the tumors was accomplished by the radiologists. They followed different protocols such as patients’ clinical history, stereotactic or neuronavigational biopsy, knowledge and experience in interpreting disease category from visual imaging features and sometimes the imaging features of CT to grade the tumor types in the developed database. The slice selection at different planes viz. axial, coronal and sagittal of T1C MR sequence was performed by expert radiologists, which have been included in this study.The MR slices of all four classes of brain tumors are taken into account for processing. The data labeling (tumor grading) and the slice selection have been performed by radiologists. The labeled data will be processed through the different blocks of proposed methodology. At the beginning stage, the image is represented in the rough domain to minimize the gray level ambiguities exist in the boundary of lesion in the purpose of detecting the tumor area. Although the segmentation process is not fully an automated technique, but the obtained accuracy is satisfactory. According to the tissue characteristics of tumors, it is well known that GBM, MET and GN is ring enhancing lesion (hyperintense) which makes the peripheral ring enhancement during the contrast injected MR sequence. In continuation, MG (highly vascular) has very strong potential of enhancement (∼95%) throughout the tumor region in T1C protocol [1]. Therefore, the thresholding technique may be an appropriate selection for delineation of the exact contour of tumor region. In the rough entropy based thresholding over granular computing paradigm, rough entropy for every threshold which varies from lowest to highest intensity of pixel is computed. The maximum rough entropy from each granule is selected for next step of computation. The highest entropy from the array of maximum entropies of granules can be considered for multiplication with the maximum gray level of the image in order to obtain the desired threshold for binary classification (tumor vs background). As per the rule, for every threshold, the lower and upper approximations of tumor region changes; where as in case of background, both the approximations remain unaltered. According to this methodology, the granule size is arbitrarily selected to perform the segmentation task. Experimentally it has been observed that, the dimension of granule varies in between 3×3 to 7×7 for highly enhancing lesions and 9×9 to 15×15 in poorly enhancing lesions. The results of the every steps of RGC based segmentation to detect the tumor region are represented in Fig. 2. Fig. 3shows the detected tumor regions by RGC based technique with respect to the expert generated ground truth images. The presences of artifacts are observed in the output of RGC thresholding (Fig. 2(b)). The isointense areas (gray level equals to the intensity of ring enhancing lesion) in brain tissue and fat tissue of skull appear as artifacts. The morphological binary operators have been employed to remove them in order to extract the lesion for next level processing. In the beginning, the area operator does the task of removing small objects and its selection depends on tumor type. The holes inside the detected objects are filled by morphological filling operator. The roundness of each detected object has been computed from its area and perimeter by assuming that tumor region holds higher degree of roundness than others. By using this strategy, the detected lesion can be extracted. The performance of RGC with binary morphological operators has been validated with respect to the ground truth images (tumor regions are manually segmented by expert radiologist). To accomplish this task, three accuracy measures viz. jaccard score (JS) [38], percent matching (PM) and correspondence ratio (CR) [11] evaluate the performance of the proposed segmentation technique as presented in Table 2.Table 3in the manuscript represents the summary of the comparative analysis of proposed approach with the existing methodologies for brain tumor segmentation. Jaccard score as a measure of segmentation accuracy has been considered in the analysis. Most of the existing works as mentioned in the table focused on the segmentation of tumor from MR volumes. In fact, the different researchers explored various MRI sequences for delineating tumor region. For example, Liu et al. [4] used multimodal MRI viz. pre and post contrast T1 and FLAIR images for developing information base to segment brain tumor. Similarly, Kaus et al. [6] worked with contrast enhanced SPGR MRI sequence for automated segmentation. Being a gradient echo sequence, SPGR provides impressive soft tissue contrast in comparison with spin echo sequence. In this context, our approach focuses on computing the two dimensional slices of T1C spin echo sequence (routinely done for tumor diagnosis) whose imaging principle is different from SPGR. In addition, all the reported literatures in Table 3 performed the assessment of their respective methodologies on their own brain tumor image database. Therefore, after analysing Table 3, the performance difference with the proposed RGC based technique has been noticed in some cases. On the other hand most of them worked on GBM only, but the proposed segmentation technique has tested its performance over the real database of four different types of tumors. In comparison, it has shown satisfactory performance toward routine protocol. In order to highlight all these issues and to show the applicability and effectiveness of the proposed technique the literature based comparative analysis has been studied.In this stage, three types of attributes viz. histogram, shape and texture are quantified from the extracted lesion to create a feature vector of 86 elements which will undergo the pattern classification step. The textural features also include multiresolutional filter banks to emphasize the coarse information of tumor area. Fig. 4represents the visual appearances of the extracted lesions of GBM, MET, MG and GN from which the feature quantification would be performed. On a different note, the dimension of all images in this figure have been kept equal for better visualization which does not mean that all four types of tumors are equal in size. During observation, it is well understood that heterogeneous tissue characteristics induce texture information. In continuation, the shape information of the tumor region may also be the key distinguishing features in pattern classification. There are many shape descriptors as explained in previous section emphasizes the various morphological information of tumor. Additionally, the image histogram summarizes the overall information contained in the image. In this respect, total 86 features have been quantified from 90, 79, 103 and 88 (all total 360) images of extracted lesions of GBM, MET, MG and GN respectively. This 360×86 dimensional data are trained by random forest to develop training module which can be used for testing the class pattern of a given input feature vector. The kernel density of a particular feature (random variable) for all four classes is the estimation of probability density function for each class individually. It helps in analyzing the distribution of same feature in all classes. That means the quality of feature can be realized. The overlapping in the density functions indicates the misclassification during the inference of input data. The kernel density estimations of four different features are presented in Fig. 5.The quantified feature set has been undergone through a learning scheme of RF ensemble classifier to develop a training model for predicting the class pattern of given input data. RF has been chosen for its efficient performance, capability of dealing large dataset and fast computation capability. In this study, 100 trees have been used to develop this ensemble classifier where each tree can be constructed with seven randomly selected features from the whole feature set. This work takes the advantage of RF that it can evaluate the potential features and hence the proposed methodology deals with 86 features where feature selection has not been done externally. After establishing the architecture of RF with 100 trees, each tree can be constructed with the subset of randomly selected data samples from original training set. These are called bootstrap samples. According to the theory, around one-third of the training samples must not be the part of bootstrap samples in the construction of nth tree. These samples are referred as out-of-bag samples which can be used as the test examples to the classifier. The out-of-bag error, whose value is found 0.044 in this study, is the average classification error of out-of-bag classifier. It has been observed from the plot of out-of-bag classification error vs number of grown trees in Fig. 6(a) that error decreases as the number of trees increases. On the other hand, during the evaluation of feature importance, the prediction accuracy over the out-of-bag samples of training data has been recorded at each tree. Now the permutation of predictor variables happens to compute the prediction accuracy again. Finally the score of the importance of predictor variable is derived from averaging the difference of two accuracies over all the trees. Standard error can be employed for further normalization if the accuracies are independent of trees. The out-of-bag feature importance is presented in Fig. 6(b).This study performs 3 fold cross-validation to evaluate the classification accuracy of different classifiers. In this respect, the whole training dataset can be divided into two proportions, where 66% of samples are considered for training and 33% for testing. According to this, 240 sample data are trained and 120 data are tested in this study. The performance of RF is compared with various classifiers viz. classification and regression tree (CART) [39], multilayer perceptron (MLP) [40], radial basis function neural network (RBF) [40,41], Logistics Regression (LR) [40,42] and C4.5 algorithm [43] by employing different statistical measures [44] viz. precision, recall or sensitivity, F-measure and accuracy. This comparative analysis is represented in Table 4. It has been observed from the table that CART provides 100% of precision, recall (sensitivity) and F-measure for classification of granuloma, but its performance is poor with respect to RF for other three classes. Hence the overall accuracy (ratio of correctly classified data to the total number of data) of CART is less than RF. MLP also provides good prediction accuracy. On the basis of consistent efficient performance in brain tumor classification into all four classes and also for having the highest classification accuracy, RF outperforms the other classifiers as listed in Table 4. From the overall discussion, we can conclude that the proposed methodology is an efficient technique for automated characterization of brain tumors from T1C MR images.The experiment of feature set selection has been performed to observe the accuracy level in pattern classification with reduced set of features. Hall and Smith [45] developed a heuristic process of potential feature set selection based on the correlations of features. This main advantage of this method is that it considers the importance of each individual descriptor. In this selection strategy, the redundant descriptors which are having higher correlation with other attributes can be discriminated. At the beginning of the algorithm, the discretization of training data should be accomplished by following the proposed frame work of Fayyad and Irani [46]. In the next stage, the class–feature and feature–feature correlations can be computed through evaluating the symmetrical uncertainty (SU) which is derived from the information gain and individual entropy H(F) as expressed below(27)SU=2×InformationGainH(F1)+H(F2)=2(H(F1)+H(F2)−H(F1,F2))H(F1)+H(F2)The merit of the feature subset (MS) consisting of n number of descriptors can be computed from(28)MS=nρCFn+n(n−1)ρFFwhere, ρCFand ρFFdenote mean of the class–feature and feature–feature correlation respectively. The selection strategy initiates at the point where the feature set is empty. The space of the descriptor subsets are searched by using greedy ‘hill climbing augmented with a backtracking facility’ to find the feature subset with highest merit. As a result of which the feature dimensionality is reduced. The algorithm stops when the five consecutive non-improving fully expanded subsets can be obtained. The reduced potential feature subset can be processed for training by the machine learning algorithm. On the other hand, the testing of pattern classification technique has been conducted over the reduced set of descriptors. In this study, 1401 number of subsets has been evaluated and the merit of the best subset is found to be 0.822. As a result, CFS reduces the feature dimension from 86 to 15. All the selected potential features are listed in Table 5. The reduced features set has been trained by RF with 100 trees and four random features have been considered for the construction of each tree. The obtained out-of-bag classification error is 0.0278. The different statistical measures used in earlier analysis have been employed to evaluate the performance of RF and other classifiers. The comparative analysis of RF with CART, MLP, RBF, LR, and C4.5 classifiers in terms of different statistical measures are reported in Table 6.In this experiment, the feature dimension has been reduced to 15 and the reduced features set has been trained by different classifiers. The 3 fold cross-validation has been performed to evaluate their classification accuracy as reported in Table 6. It can be observed from the table that RF consistently provides higher classification accuracy as compared to others. In continuation, CART also retains its comprehensive accuracy in classifying GN, but again the overall accuracy is inferior to RF. The most interesting finding is that the performance of LR has been significantly improved with the reduced set of features and this makes it second best classifier, whereas the accuracy level of other classifiers have been reduced as compared to their performance over the whole feature set. Therefore, giving importance to the consistent performance with higher classification accuracy leading to the improved brain tumor diagnosis, we conclude that the proposed methodology incorporating with 86 features trained by RF machine learning algorithm to predict the accurate class pattern of unknown data is an efficient brain tumor screening tool. To justify the above statement, the 10 fold cross-validation has been accomplished to test the performance of proposed methodology. Under such evaluation, the whole dataset (360×86) have been divided into 10 partitions and each of them contains 324 train data and 36 test data. Table 7represents the overall accuracy of test set of each partition. To find out the statistical significance of the test outcomes, the confidence interval (CI) of the mean classification accuracy of 10 test sets has been computed. The statistical test shows that the corresponding 95% CI is ±1.86. So it can be inferred that the classification accuracy of the proposed methodology for brain tumor characterization from the T1C MR image falls within the range of 93.97–97.69 with 95% of confidence.Table 8represents a comparative performance analysis of proposed methodology with the existing works on brain tumor characterization from MR images in terms of the reported classification accuracy (per class accuracy). In continuation, the characterization of Glioma, MET and MG has been found common in the enlisted existing works (except Zacharaki et al. [21]) in the table. Although apart from the common group, some of the previous works also considered other tumor types viz. Medulloblastoma (MED), low grade and grade three gliomas etc. In view of this, the present work has considered the cases of GN for automated characterization from MR images. Till now no computational attempt has been made to characterize GN from other brain tumors through MR image computing to the best of our knowledge. All the reported literatures in Table 8 tested the performance of their respective methodologies on their own image database. Table 8 has been made completely on the basis of the information (viz. data, classification accuracy etc.) provided in the respective literature as mentioned in the said table [23]. Hence the comparison has not been done in terms of computation time.During the analysis of Table 8, it has been observed that in most of the cases the proposed methodology performs better than the existing techniques (e.g. proposed methodology provides higher accuracy for GBM and MG characterization than Kumar et al. [22] and Sachdeva et al. [23]). In overall analysis, the accuracy level of the proposed technique is highly comparable with the existing methods. After understanding the comprehensive analysis of this table, we can conclude the effectiveness and applicability of the proposed methodology in the field of computer assistive brain tumor characterization from T1C MR images.

@&#CONCLUSIONS@&#
