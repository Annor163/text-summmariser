@&#MAIN-TITLE@&#
A new particle swarm optimization algorithm with adaptive inertia weight based on Bayesian techniques

@&#HIGHLIGHTS@&#
Why BPSO can achieve the excellent balance between exploration and exploitation in optimization processing is explained.To overcome the defect of ordinary PSO, a new algorithm with adaptive inertia weight based on Bayesian techniques is proposed.Analysis of parameters s and ω in the BPSO.

@&#KEYPHRASES@&#
Particle swarm optimization,Monte Carlo,Gaussian distribution,Bayesian techniques,

@&#ABSTRACT@&#
Particle swarm optimization is a stochastic population-based algorithm based on social interaction of bird flocking or fish schooling. In this paper, a new adaptive inertia weight adjusting approach is proposed based on Bayesian techniques in PSO, which is used to set up a sound tradeoff between the exploration and exploitation characteristics. It applies the Bayesian techniques to enhance the PSO's searching ability in the exploitation of past particle positions and uses the cauchy mutation for exploring the better solution. A suite of benchmark functions are employed to test the performance of the proposed method. The results demonstrate that the new method exhibits higher accuracy and faster convergence rate than other inertia weight adjusting methods in multimodal and unimodal functions. Furthermore, to show the generalization ability of BPSO method, it is compared with other types of improved PSO algorithms, which also performs well.

@&#INTRODUCTION@&#
Particle swarm optimization (PSO) was firstly introduced by Kennedy and Eberhart in 1995 [1]. It belongs to evolutionary algorithm (EA), however differs from other evolutionary algorithms, which is inspired by the emergent motion of a flock of birds searching for food. PSO performs well in finding good solutions for optimization problems [2], and it has become another powerful tool besides other evolutionary algorithms such as genetic algorithms (GA) [3]. PSO is initialized with a population of particles randomly positioned in an n-dimensional search space. Every particle in the population has two vectors, i.e., velocity vector and position vector. The PSO algorithm is recursive, which motivates social search behavior among particles in the search space, where every particle represents one point. In comparison with other EAs such as GAs, the PSO has better search performance with faster and more stable convergence rates.Maintaining the balance between global and local search in the course of all runs is critical to the success of an optimization algorithm [4]. All of the evolutionary algorithms use various methods to achieve this goal. To bring about a balance between the two searches, Shi and Eberhart proposed a PSO based on inertia weight in which the velocity of each particle is updated according to a fixed equation [5]. A higher value of the inertia weight implies larger incremental changes in velocity, which means the particles have more chances to explore new search areas. However, smaller inertia weight means less variation in velocity and slower updating for particle in local search areas.In this paper, the inertia weight strategies are categorized into three classes. The first class is simple that the value of the inertia weight is constant during the search or is selected randomly. In [6], the impact of the inertia weight is analyzed on the performance of the PSO. In [7], Eberhart and Shi use random value of inertia weight to enable the PSO to track the optima in a dynamic environment. In the second class, the inertia weight changes with time or iteration number. We name the strategy as time-varying inertia weight strategy. In [8,9], a linear decreasing inertia weight strategy is introduced, which performs well in improving the fine-tuning characteristic of the PSO. Lei et al. use the Sugeno function as inertia weight declined curve in [10]. Many other similar linear approaches and nonlinear methods are applied in inertia weight strategies such as in [11–13]. The last class is some methods that inertia weight is revised using a feedback parameter. In [4], a fuzzy system is proposed to dynamically adapt the inertia weight. In [14], the inertia weight is determined by the ratio of the global best fitness and the average of particles’ local best fitness in each iteration. In [15], A new strategy is presented that the inertia weight is dynamically adjusted according to average absolute value of velocity, which follows a given nonlinear ideal velocity by feedback control, which can avoid the velocity closed to zero at the early stage. In [16], dynamic acceleration parameters (DAP) method is proposed, which owns a mechanism to self-tune the acceleration parameters by utilising the averaged velocity information of the particles. In [17], a new adaptive inertia weight strategy is proposed based on the success rate of the particles. In this strategy the success rate of the particles is used as a feedback parameter to realize the state of the particles in the search space and hence to adjust the value of inertia weight.A series of other studies based on mutation strategy has been done on the analysis and development of the PSO since it was introduced in 1995. These approaches aim to improve the PSO's convergence velocity. In [18], a mutation operator is used that changes a particle dimension value using a random number drawn from a Gaussian distribution (GPSO). A particle is selected for mutation using a mutation rate that is linearly decreased during a run. In [19], a mutation strategy is proposed that a particle position is changed using a random number drawn from a Gaussian distribution. A mutation operator in [20] is similar to that of Ref. [18], but a Cauchy probability distribution is used instead (CPSO). The Cauchy distribution curve is similar to the Gaussian distribution curve, except it has more probability in its tails and thus making it more likely to return larger values. In [21], the HPSO with a wavelet mutation (HWPSO) is proposed, in which the mutation incorporates with a wavelet function.Hybrid PSOs (HPSOs) have been proposed to enhance the performance of the PSO, in which different mutation strategies are used. In [22], premature convergence is avoided by adding a mutation strategy, i.e., a perturbation to a randomly selected particle's velocity vector. A Cauchy mutation (HPSO) [23] is proposed, which is used in best particle mutation, so that the best particle could lead the rest of the particles to better positions. The algorithm in [24] called IPSO+ACJ is tested on a suite of well known benchmark multimodel functions and the results. The main idea of our new jump strategy is that pbest and gbest are selected as mutated particles when they have not been improved in a predefined number of iterations. In [25], Ant colony optimization (ACO) and PSO work separately at each iteration and produce their solutions. In [26], The new mutation strategy makes it easier for particles in hybrid MRPSO (HMRPSO) to find the global optimum and seek a balance between the exploration of new regions and the exploitation of the old regions.Fuzzy approaches for PSO is a hot topic in these years. In [27], a fuzzy system is used to dynamically adjust the inertia weight and learning factors of PSO in each topology. In [28], a dynamic parameter adaptation is proposed to improve the convergence and diversity of the swarm in PSO using fuzzy logic. Valdezis et al. [29] introduced an improved FPSO+FGA hybrid method, which combines the advantages of PSO and GA. See Ref. [30] for a comprehensive review on the application of fuzzy logic in PSO, ACO and Gravitational Search Algorithm (GSA).There are some works that have used the Bayesian technique in smart computing. In [31], the Dynamic Bayesian Network (DBN) is used in PSO algorithm for particle motion. In swarm optimization, each particle tries to track the trajectory toward the place of better fitness. Martens et al. [32] explained scientifically the application of the Bayesian network in ACO. In our paper, Bayesian techniques is introduced into the PSO algorithm with a view to enhance its adaptive search ability. We call this algorithm as PSO with Bayesian techniques (BPSO). Different from other inertia weight strategies in the references, BPSO algorithm adjusts the inertia weight ω based on the past particle places automatically. This new development gives particles more opportunity to explore the solution space than a standard PSO. Furthermore, the new algorithm accelerates search velocity for the particles in valuable search-space regions.This paper is organized as follows. In Section 2, generic PSO theory is reviewed and the change of particle position ɛ is analyzed. Section 3 introduces the advantage of PSO with Bayesian Techniques. Section 4 shows the experimental settings for the benchmarks, simulation results and parameters analysis in the BPSO. Finally, Section 5 presents conclusions resulting from the study.PSO is also a population-based stochastic optimization algorithm and starts with an initial population of randomly generated solutions called particles. Each particle in PSO has a position and a velocity. PSO remembers both the best position found by all particles and the best positions found by each particle in the search process. For a search problem in an n-dimensional space, a potential solution is represented by a particle that adjusts its position and velocity according to Eqs. (1) and (2):(1)vi,d(t+1)=ωvi,d(t)+c1r1(Ppid−xi,d(t))+c2r2(Pgd−xi,d(t))(2)xi,d(t+1)=xi,d(t)+vi,d(t+1)where c1 and c2 are two learning factors which control the influence of the social and cognitive components and ri=randi, (i=1, 2) are numbers independently generated within the range of [0,1].vi,d(t)is the velocity of individual i on dimension d. xi,d(t) is current particle position on dimension d. Ppid(pbest) is the best local position of individual i on dimension d, and Pgd(gbest) represents the best particle position among all the particles in the population on dimension d. ω is the inertia weight, which ensures the convergence of the PSO algorithm.According to Eq. (2), changes in the position of particles depend exclusively upon the position item of the PSO. Therefore, we only use the position item to investigate the search ability of particles during iterations. The implicit form of the position equation presented in Eq. (2) is used for a multi-particle PSO working in a multi-dimensional search space. Since the data of each dimension in the PSO are independent, the analysis below will be restricted to a single dimension. We simplify the Eqs. (1) and (2) as follow:(3)V(t+1)=ωV(t)+c1r1(Pp−X(t))+c2r2(Pg−X(t))(4)X(t+1)=X(t)+V(t+1)The following formulas can be obtained from Eq. (4):(5)V(t+1)=X(t+1)−X(t),V(t)=X(t)−X(t−1)By substituting Eq. (5) into Eq. (3), the following non-homogeneous recurrence relation is obtained:(6)X(t+1)=(1+ω−c1r1−c2r2)X(t)−ωX(t−1)+(c1r1Pp−c2r2X(t)Pg)(7)X(t+1)=(1+ω)X(t)−ωX(t−1)+(c1r1Pp+c2r2Pg)−(c1r1+c2r2)X(t)Let ɛ=(c1r1Pp+c2r2Pg)−(c1r1+c2r2)X(t), then(8)X(t+1)=(1+ω)X(t)−ωX(t−1)+ɛThe first and second items on the right side of Eq. (8) both memorize the past values of position which have different weight. They also can be seen as a whole item to be called the memory item of position. Since the value of the third item on the right side of Eq. (8) is obtained from the previous experience of particles, we call it the learning item of position. According to ɛ, (c1r1+c2r2)X(t) in ɛ is the memory part and (c1r1Pp+c2r2Pg) is the learning part. It is obvious that ɛ represents the change of particle position in every iteration.ɛ represents the gap between memory part and learning part. If the particle position converges to one position, ɛ is a Gaussian distribution. We can use Monte Carlo method to illustrate that.Monte Carlo is the art of approximating an expectation by the sample mean of a function of simulated random variables. It is apparently first used by Ulam and von Neumann as a Los Alamos code word for the stochastic simulations applied to building better atomic bombs. Monte Carlo methods are also online simulation methods that learn from experience based on randomly generated simulations. Given a random set of experiences, with the guarantee from the weak law of large numbers, the simulation results will eventually converge when each state is encountered for an infinite number of trials. It is evidenced in part by the voluminous literature of successful applications. In our paper, we use Monte Carlo method to analyze the properties of ɛ, respectively, using a large body of experimental data. Take the test function f6 as the example, the PSO is initialized as follow:(1)The maximum number of iterations is 500.The swarm size is 50.c1 and c2 are set as 1.49445.In the experiment, We obtain the probability distribution of ɛ shown in Fig. 1. Under the condition of pbest=gbest, the value of gbest in the 50 particles is not changed after about 200 iterations. The mean value of ɛ is equal to zero and the variance is σ2, i.e., ɛ is an independent stochastic variable satisfying Gaussian distribution with zero mean value and variance σ2(p(ɛ)∼N(ɛ|0, σ2)).The inertia weight adjusting method proposed in our paper is inspired by the idea of self-adaption. Based on past particle positions in s iteration, ω is used to accelerate up the movement of particles towards the optimum point or slow down the particles so that they converge to the optimum.Write Eq. (8) as follow(9)X(t+1)=W1X(t)+W2X(t−1)+ɛLet W1=(1+ω), W2=−ω, W=[W1, W2]T, Φt=[X(t), X(t−1)]T, Φ=[Φt, Φt+1, ⋯, Φt+s−1]T, s is the constant. Y=ΦW, H=[X(t+1), X(t+2), ⋯, X(t+s)]T, Eq. (9) is written as(10)H=Y+ɛ=ΦW+ɛIn this paper, we propose a Bayesian PSO method that considers a probability density function over the weight space, and the optimal inertia weight vector is calculated by maximizing the posterior probability density function of the weight, where ɛ is an independent stochastic variable satisfying Gaussian distribution with zero mean value and variance σ2, i.e. (p(ɛ)∼N(ɛ|0, σ2))Let D={H, W}, β=1/σ2, Then, the Bayesian method can be used to estimate the weight vector W, in which the probability density function over the weight vectors space is mainly considered.In general, the priori information on the weight vector W is difficult to be found, so we choose a fairly broad distribution as a priori. The expression of this distribution is Gaussian distribution, which is written as(11)P(W)=1ZW(α)exp(−αEW)(12)EW=12||W||2=12∑i=1MWi2where α controls the distribution of weight vector. ZW(α) is a normalization factor. M is the total number of weights.If W is subject to Gaussian prior, the normalization factor ZW(α) can be expressed by(13)ZW(α)=2παM/2The likelihood function can be written as(14)P(D|W)=1ZD(β)exp(−βED)where β controls the distribution of Y, ZD(β) is a normalization factor. EDis an error function. P(D|W) can also be written as(15)P(D|W)=P(H|(W,Φ))=∏i=1sP(X(t+i)|(W,Φ))=1ZD(β)exp−β2∑i=1s{X(t+i)−ΦiW}2(16)ZD(β)=∫e(αED)=2πβs2using formula(17)P(W|D)=P(D|W)P(W)P(D)By substituting Eqs. (11) and (14) into Eq. (17), we obtain the posterior distribution as follows(18)P(W|D)=1ZQexp(−βED−αEW)=1ZQexp(Q(W))where(19)Q(W)=βED+αEW(20)ZQ(α,β)=∫exp(−βED−αEW)dWTo obtain the posterior distribution of W, we apply Gaussian approximation to W. This approximation is obtained through the second-order Taylor expansion of Q(W) around its most probable weights value WMP. Taylor expansion of Q(W) is written as(21)Q(W)=Q(WMP)+12(W−WMP)TA(W−WMP)where A is the Hessian matrix of the total (regularized) error function. The remainder terms of Q(W) have been ignored.According to the content we have discussed, parameters α, β are unknown. Take parameters α, β as integral variables. The posterior distribution of network weights is given by(22)P(W|D)=∬P(W,α,β|D)dαdβ=∬P(W|α,β,D)P(α,β|D)dαdβSince the posterior probability distribution P(W, α, β|D) for the hyper-parameters is around their most probable values αMPand βMP[33]. Replace α, β with αMP, βMP. Eq. (22) can be written as(23)P(W|D)≈P(W|αMP,βMP,D)∬P(α,β|D)dαdβ=P(W|αMP,βMP,D)using the formula as follow(24)P(α,β|D)=P(D|α,β)P(α,β)P(D)by combining Eq. (21) with (24), P(D|α, β) can be written as(25)P(D|α,β)=1ZD(β)ZW(α)∫exp(−Q(W))dW=ZM(α,β)ZD(β)ZW(α)considering Eq. (25), the log of the evidence is then given as follow(26)lnP(D|α,β)=−βEDMP−αEWMP−12ln(detA)+L2ln(α)+N2ln(β)+N2ln(2π)The optimal hyper-parameters values αMP, βMPare obtained by differentiating Eq. (26)[34]. The optimal values are as follow(27)αMP=γ2EW,βMP=n−γ2EDwhere(28)γ=∑i=12λiλi+α,(λi|i=1,2)λiare the eigenvalues of the Hessian matrix of the un-regularized error.By maximizing the posterior distribution Eq. (28), we maximize its logarithm equivalently, which results in the following optimization problem:(29)Q(W)=βED+αEW=β2(ΦW−H)T(ΦW−H)+α2WTWBy fixing the hyperparameters α and β, we maximize Q(W) with respect to W, and have(30)∂Q(W)∂W=β2∂(ΦW−H)T∂W(ΦW−H)+∂(ΦW−H)T∂W(ΦW−H)+αW=β2{2ΦT(ΦW−H)}+αW=βΦTWΦ−βΦTH+αW=βΦTΦW−βΦTH+αWtaking∂Q(W)∂W=0, then W can be written as(31)W=(βΦTΦ+α)−1βΦTHusing the W, we can compute the inertia weight ω.The main process of BPSO algorithm is in the Algorithm 1. In the algorithm, inertia weight ω can change according to the past particle position. In every s iterations, ω is different in Eq. (3). However, the Bayesian approach suffers from local optimal problem. By introducing a mutation operation into BPSO, the ability to escape from local optimum is enhanced and the global search ability of the BPSO algorithm is strengthened. In [18], we see that Gaussian mutation tends to have a fine-tuning ability, however, it only produces short jump. To produce longer jumps, the cauchy mutation is selected as the local mutation operator, which is written as(32)Pp,i=Pp,i+α·cauchy(1)Pp,irepresents the best place of the ith particle in the iteration. cauchy(1) returns a big value, which is drawn from a cauchy distribution. Parameter α controls the range of cauchy random number.The computation cost of the original PSO algorithm can be easily obtained, which is represent as O(maxgen*sizepop). sizepop is the size of the whole population, and maxgen is the maximum number of iterations. In BPSO algorithm, the total computational cost incurred by the computation of the W is denoted as O(maxgen*sizepop*s). s is regrouping period, which is less than 100. In our experiment, maxgen*sizepop is far greater than s, so the total computational cost of BPSO is the same as the original PSO algorithm.Algorithm 1 The details of BPSO.Initialize:maxgen: max iterations; i: the number of iterations; sizepop: size of the whole population; j: the number of particle; s: regrouping period; Pp,i: the best position of one particle in one iteration; Pg: the best position of all particles in one iteration; Initialize each particle's position xi,dand constant c1=c2=1.49445; regrouping period s=30; cout(j): the best position of all particles in one iteration; q: the threshold;Iterate:1:fori=1:maxgendo2:forj=1:sizepopdo3:Update each particle using local version PSO (1);4:if mod(i,s)=0 and i ≥ 2then5:compute the weight W using (31);6:end if7:end for8:forj=1:sizepopdo9:iff(xj,d) < f(Pp,j)then10:f(Pp,j) = f(xj,d)11:else12:cout(j)=cout(j)+113:end if14:ifcout(j)>qthen15:mutate Pp,jusing (32)16:cout(j)=017:end if18:iff(xj,d) < f(Pg)then19:f(Pg) = f(xj,d)20:end if21:end for22:end forTwo comparisons have been conducted in this section. One is among unimodal functions and the other is among multimodal functions.To test the performance of the proposed algorithm, we do experiments on 10 benchmark functions. These test functions, which are shown in Table 1, can be classified into two groups. The first five functions f1–f5 are unimodal functions. For unimodal functions, the convergence rate of an algorithm is more interesting than the final result of optimization. Therefore, we not only give the final achievement but also show the convergence rate of each algorithm. The next five functions f6–f10 are multimodal functions with many local optima. For multimodal functions, we only give the final result since it reflects an algorithm's ability of escaping from poor local optima. The functions are used to test the global search ability of the algorithm in avoiding premature convergence.In this paper, all empirical experiments related to the PSO and its improvements are carried out with a same population size. Furthermore, in order to ensure that the initial values of particles in each algorithm are same, we use the MATLAB command rand(state, sum(i30)). The initial value of i of each run for all algorithms is the same. Parameter s is the interval of the adjacent two inertia weight change in all iterations. The parameters of the BPSO are used as follow.(1)The number of runs is 500; the acceleration coefficients c1 = c2 =1.49445.The population size is 50.The parameter s of BPSO increase from 1 to 50, the step length is 2.From all strategies introduced in the previous sections, four strategies have been adopted for comparisons: decreasing inertia weight (Linear Decreasing) [5,6], random inertia weight (Random) [7],the Sugeno method (Sugeno) [10] and AIWPSO [17].To further validate the effectiveness of the proposed algorithm in this paper, we compare BPSO with six existing PSO variants, including the PSO [5], PSO with Gaussian mutation (GPSO) [19], PSO with Gaussian mutation cauchy (CPSO)[19], hybrid particle swarm (HPSO) [23], improved PSO with a jump strategy(IPSO+AJS) [24], PSO with an MRS strategy (HMRPSO) [26] under the same maximum function evaluations (FEs).Four inertia weight strategies are applied to the five test function f1–f5 on dimensions 10 and 50. The results are listed in Tables 2and 3, where “best” indicate the best function values found in the generation, “Mean” and “Std Dev” stand for mean value and standard deviation. Figs. 2–4are comparison among BPSO and other strategies on dimension 10. The sphere function f1 is unimodal test function, which is often used. For this function, the performance of the BPSO is much more better than the decreasing inertia weight, random inertia weight, the Sugeno method and AIWPSO. Similar results are also obtained on f4 and f5, which are shown in Tables 2 and 3. The differences between the inertia weight adjusting methods on f1, f4, and f5 suggest that the BPSO is better at a fine-gained search than both the other algorithms. f3 is called step function, which is characterized by plateaus and discontinuity. From Tables 2 and 3, using decreasing inertia weight, random inertia weight and the Sugeno method, optimal function value can be found. However, in Fig. 3(a), we can see that the convergence rate of the BPSO is faster than the other two PSO inertia weight adjusting methods. The performance of the BPSO is much more better than the other four methods. The main differences attribute to the change of the inertia weight ω, which affords the BPSO a greater chance to search in the local area. In other words, the feature of ω directly affects the particle's movement, so that the particle preserve the fast converging feature in its searching area.The above mentioned PSO-based optimization algorithms (PSO, GPSO, CPSO, IPSO+AJS, HPSO, HMRPSO) are applied to the test problems. Table 4shows the comparisons of six other PSO variants for function f1–f5. From Table 4 and Figs. 5– 7, BPSO performs better than the other three improved variants. Inf2 and f3, globle optimum both can be found using BPSO and HMRPSO algorithm. But, in Figs. 5(b) and 6(a), we can see that the convergence rate of the BPSO is faster than HMRPSO.On multimodal functions, the global optimum is more difficult to locate. Therefore, in the comparison, we study the accuracy, speed, and reliability of the PSO variants. Comparisons of solution accuracy on multimodal functions are given in Tables 2, 3 and 5.The Schwefel function f6 is a multimodal function with very deep sinusoidal indentations. It is one of the most difficult problems for optimization algorithms. It can be seen from the comparisons in Tables 2, 3 and 5 that, although none of the seven algorithms considered in this paper is efficient in solving this function, BPSO method is more efficient than the other four inertia weight adjusting methods and six PSO variant algorithms in producing the near optimal value.The generalized Rastrigin's function f7 can easily trap an optimization algorithm in a local optimum on its way to the global optimum. By adjusting step length s, particles in the BPSO are able to search more solution space. In Tables 2, 3 and 5, it can be clearly seen that the mean values of the BPSO are better than those of the other variants algorithms.The Ackley function f8 has several local minima. Here, the mean values and the standard deviations of the BPSO are also better than those of the inertia weight adjusting methods and six PSO variant algorithms. Therefore, it is evident that the BPSO can provide more stable and high accuracy results on this function.The Levy-Montalvo function f9 has approximately 15nlocal optima. In Table 5, when the number of dimensions is increased from 10 to 50, the PSO has been trapped in local optima. Meanwhile, the BPSO performs much better principally because the changed inertia weight ω affords the BPSO a greater opportunity to escape from poor local optima.f10 is the Griewank function. Because f10 is a difficult multimodal function that has an exponentially increasing number of local minima as the dimension of the problem increases, it is difficult for PSO algorithms to find the optimal solution steadily. On the prospect of search speed, BPSO remains one of the fastest algorithms in terms of FEs and execution time. These results confirm that BPSO is also competitive on multimodal functions.The performance of BPSO is superior due to the adaptive nature of this algorithm. Fig. 8shows the process of the inertia weight ω changing, in which BPSO is applied to the function f1. We see that the changing method of ω in our paper is different from the other four inertia weight strategies and most value of ω is in [0.4, 0.9]. This is mainly because ω is mainly affected by the particle positions in s step length and adjusted automatically.In the BPSO, s is a parameter that influences the convergence rate. A smaller s means that the inertia weight ω has more opportunities to be changed but less past particle position informations are used. Larger s makes ω having less chance to be changed and more past particle position informations are referred. Thus, it is important to identify the appropriate value for s in the BPSO. We endeavor to get a better parameter in BPSO algorithm. In our paper, an efficient method is used that s varies from 2 to 50 in linear-increasing method. Experiment setup is same as above. We carry out experiments to get a better approximation to best s for the unimodal functions f2 and the multimodal functions f10 on dimensions 10 (see Figs. 9and 10).In Fig. 9 and 10, the convergence rate with different values of s are shown for the test function. When s=2, 4, 6, 8, 10, results on each test function become better with s increasing. However, when s=10, 20, 30, 40, 50, results on each test function become worse with s increasing. From the figure, we can see that the value of s influences the convergence velocity, but not very significant.

@&#CONCLUSIONS@&#
