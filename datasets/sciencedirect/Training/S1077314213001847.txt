@&#MAIN-TITLE@&#
Visual object tracking using spatial Context Information and Global tracking skills

@&#HIGHLIGHTS@&#
This paper proposes a novel color cue called CIG.CIG computes weights based on spatial Context Information and Global tracking skills.CIG is effective and can be computed pixel by pixel efficiently.Weights by CIG have high stability and precision under low-contrast scenes with complex motions.

@&#KEYPHRASES@&#
Object tracking,Mean shift,Weight image,Spatial context model,CIG,

@&#ABSTRACT@&#
Tracking objects in videos by the mean shift algorithm with color weighted histograms has received much attention in recent years. However, the stability of weights in mean shift still needs to be improved especially under low-contrast scenes with complex motions. This paper presents a new type of color cue, which produces stable weights for mean shift tracking and can be computed pixel by pixel efficiently. The proposed color cue employs global tracking techniques to overcome the illustrated drawbacks of the mean shift algorithm. It represents a target candidate with a larger scale than that of the target model so that the model is much more precise than the candidate. We illustrate that the weights by this way are more reliable under various scenes. To further suppress surrounding clutters, we establish a new spatial context model so that the optimization results are a set of weights which can be computed pixel by pixel. The proposed color cue is called CIG since it computes the weights based on spatial Context Information and Global tracking skills. Experimental results on various tracking videos show that weight images by CIG have higher stability and precision than those of current methods especially under low-contrast scenes with complex motions.

@&#INTRODUCTION@&#
Real-time visual tracking is a critical task in many computer vision applications such as driver assistance [1,2], aerial surveillance and exploitation [3,4], etc. The major challenges to be addressed in these circumstances include illumination changes, occlusions, scale variations, presence of clutters, and camera vibrations. Much efforts have been put into the research on object tracking, and some algorithms are proposed including the unscented Kalman filter [5,6], particle filter [7–9], and mean shift [10]. Among the above methods, mean shift has received much attention due to its low computational complexity. However, mean shift may fail for cameras carried by a high-speed moving platform with vibrations. In this case, motion blur is serious and images of objects have large transition regions. Some transition colors may be similar to those of background, and the contrast between object and background is low. Thus, mean shift may drift when some transition colors of objects are similar to those of background. In addition, mean shift would fail when images of objects between adjacent frames have few overlaps or no overlap due to platform vibrations. We refer the above cases as “low-contrast scenes with complex motions” for short. In these cases, mean shift still needs to be improved.In the mean shift tracking algorithm, a weight image is generated by comparisons between color histograms such that pixels on the foreground blob have high weights, whereas pixels in backgrounds have low weights [11]. Then, mean shift provides a way to combine the color weights and a set of kernel weights within the object bandwidth to produce an offset for the centroid of the blob. Thus, a main factor to determine the effectiveness of mean shift tracking algorithms is the quality of the weight image.Popular weight image generation methods by the color cue include color weighted histogram (CWH) and foreground background ratio (FBR). To enhance the discriminant of CWH, Zhao and Tao presented a special form of color correlogram to obtain a richer representation for object tracking [12]. A simplified color correlogram representation encoded the spatial information explicitly and enabled an estimation algorithm to recover the object orientation. In [13,14], ellipse orientation and affine kernel fitting were incorporated into the color histogram to get the object orientation. Leichter et al. enhanced the mean shift tracker to cope with appearance changes by using multiple reference histograms obtained from different target views when they are available prior to the tracking [15]. They used the convex hull of these histograms to represent the model. The main problem was that their method required multiple reference views of the interest target before tracking, which placed an obstacle in many applications. Wang et al. presented a foreground-target histogram approximation method to effectively reduce disturbances from background [39]. The approximating involved brute force searching, thus the computation cost was relatively high. Caulfield [42] fused multiple-part models and background exclusion into a single mean-shift-based tracker. The author showed that the reliability for mean-shift-based trackers was increased considerably by exploiting background models of the scene. However, Caulfield employed background modeling method for surveillance domain under static cameras to get background models of the scene, whereas our interest is in the domain of cameras carried by a high-speed moving platform with vibrations.Current researches by FBR mainly focus on online color feature selection. Collins et al. proposed a method which selected discriminative tracking features online from linear combinations of RGB space based on variance ratio [16]. Babu et al. used color features to develop a target model based on fast learning radial basis function networks [17]. Xu et al. employed subclass discriminant analysis to find a color subspace that best discriminated foreground and background pixels [18]. In [19], the authors calculated color histograms in RGB, HSV, and normalized rg color spaces, separately. They pointed out that two features were appropriate in most cases and developed an evaluation method to adaptively update the color features during tracking. Recently, Wang et al. combined methods of CWH and FBR to get a fused weight image [40]. They showed that the fused weights were more reliable than those by single term. Other features, such as edge density or histograms [20–23], scale invariant feature transform (SIFT) [24,25], or combinations of them [24–26] have also been developed to improve the effectiveness of tracking algorithms.Compared with methods by CWH which can encode long-time information, algorithms by FBR that only use current pixels have gained better performances as shown in [16,18]. In addition, the results by FBR can be further improved by establishing long-time foreground and background models. The comparison results violate with our intuition. In fact, tracking is the detection of specified target in memory, not the one that is only different from backgrounds. Therefore, there may be inherent drawbacks for current methods by CWH. In our earlier work [27], a background weighted histogram (BWH) was selected for the target model whereas a CWH was employed for the target candidate. We found that tracking performances were improved by setting the model and the candidate with different precisions. The same strategy was recently employed and verified from a different viewpoint in [41], and they termed the method as CBWH (corrected background weighted histogram). To address problems when there were no overlaps between consecutive frames, global tracking strategies such as annealed mean shift [28,29] or pyramid mean shift [27] were proposed. These skills gradually smoothed the surface of cost function at different scales, and gently reached the global peak. The results were greatly improved for scenes with both large and small values of motion displacements, which indicated that a global search and comparison method could improve the quality of the weights.In this paper, the inherent drawbacks of the color cue in mean shift are analyzed. We show that a color cue is more reliable under the condition “precise model+less precise candidate enclosing the object”. This is reasonable because mean shift employs color histogram comparisons to get the weight image. A less precise candidate makes the denominator of object colors smaller, thus the comparisons larger. On the other hand, the candidate should enclosing the object to make the denominator larger than 0, otherwise the weight would be 0. These requirements can be met by enlarging the candidate scales. The benefits lie in twofold. One is that more background pixels can be enclosed into the candidate, making the model relatively more “precise”; and the other is that the candidate with a large scale has foreground pixels even when motion displacements between consecutive frames are large. Thus, the quality of the acquired color weight images by the above way will be greatly improved. This idea coincides with the mechanism of human vision. For object model, we only intend to reserve target characteristics since backgrounds are usually unstable for a long time. As for the candidate, a large scale is used to include the whole object into the ROI and to make the object and its surroundings visibly discriminable [30]. This property is termed as global tracking skills. Though simple, it differs from current methods to our knowledge. The proposed method uses a relatively large scale (usually 3 or 4) to calculate the candidate and only needs one large scale, whereas: (1) variable bandwidth selection [10] or scale-space method [11] got similarities under different scales (usually between 0.5 and 2.0) to determine the current object scale; (2) global mode seeking methods [27–29] used different scales (for example: 4, 3, 2, 1) to find the global mode and worked in a coarse-to-fine manner. To further improve the quality of the color weight image, we extend the mean shift algorithm by exploiting background models of the scene. For moving platforms where the background is not available, we employ spatial context information to model the scene. According to human vision, the tracked object should be similar to the model meanwhile its surroundings should be different from the model [30]. We establish a new spatial context model to implement this visual mechanism so that the optimization results are a set of weights which can be computed pixel by pixel. Combined with the above extension, a novel method called CIG is proposed since it computes the color weight image employing spatial Context Information and Global tracking skills. We show that weight images obtained by CIG have higher stability and precision than those of current methods especially for low-contrast scenes with complex motions. Our main contributions include:•We reveal that color cue is more reliable under the condition “precise model+less precise candidate enclosing the object”. We implement this idea by simply enlarging the candidate scales borrowing from global tracking techniques to meet the condition. This method differs from current ones to our knowledge.A new spatial context model is proposed to exploit background models of the scene for moving platforms. The proposed spatial context model can be fused into a single mean-shift-based tracker, thus the optimization results are a set of weights which can be computed pixel by pixel.This paper is outlined as follows. The profiles of the tracking algorithm are reviewed in Section 2. In Section 3, the inherent drawbacks of the classical mean shift are analyzed. Global tracking skills and spatial context information are then explored to improve the quality of weights in Sections 4 and 5, respectively. Section 6 presents experimental results on various videos. Finally, the conclusion of the paper is stated in Section 7 with a discussion of some significant issues.Mean shift algorithms [10] usually use comparisons between color histograms to obtain the weight image. Then, mean shift procedure and scale update methods are employed to get the target position and scale, respectively. Finally, target models are updated using tracking results to cope with viewpoint and illumination changes.Let x0 be the initial object position, q={qu∣u=1,2,…,m} and p(x0+Δx)={pu(x0+Δx)∣u=1,2,…,m} be CWH that represent the target model and target candidate, respectively. CWH is calculated in RGB space with 16×16×16 bins, so m equals to 4096. With these definitions, the tracking algorithm can be represented as finding the best displacement Δx∗ that maximizes the similarity between q and p(x0+Δx):(1)Δx∗=argmaxΔx{ρ[q,p(x0+Δx)]}In the classical mean shift algorithm [10], the Bhattacharyya coefficient is used to obtain a distance metric:(2)ρ[q,p(x0+Δx)]=∑u=1mpu(x0+Δx)quUsing Taylor expansion approximations and gradient descent method, the above tracking problem can be transformed into a mean shift procedure on a weight image. The weight for a given color index u can be computed by [10]:(3)wu=qupu(x0)Thus, the weight for each pixel in ROI (The ROI used in this paper is 4×4 times of the object scale at the previous frame) can be computed by finding its color index u and using distribution comparison of color index u according to Eq. (3).Once the weight image is available, mean shift procedure can be employed to get the local mode. Several improvements to get the global maximum have been proposed, such as combined with SSD tracker [31] and particle filter [32], or employ global tracking skills such as annealed mean shift [28] and Adaptive Pyramid Mean Shift (APMS) [27]. We use APMS to estimate the target position since it can cope with camera vibrations and large object motions. In addition, APMS can decide the pyramid level adaptively, which can save lots of computational resources since motions or vibrations between adjacent frames are small for most instances.Scale selection is difficult for algorithms like mean shift, which use a global color model of the target. A traditional way adapts window size by a fixed percentage and evaluates it using Bhattacharyya coefficient [10]. Although this does stop the window from growing too big, it is insufficient to keep the window from shrinking too much. Collins [11] proposes a method to generate a combined model which captures features at different scales. Then, mean shift is applied in the spatial and scale dimensions to the weight image, hence tracking blobs through scale space. Jiang et al. [33] prove that the kernel bandwidth can be determined by maximizing the lower bound of log-likelihood function of Bhattacharyya coefficient, and the adaptive bandwidth is finally calculated by weighted standard deviation along the X- and Y-directions, respectively. We utilize the method of Jiang et al. [33] to update the target scale due to its simplicity and efficiency.The target model should be updated as the object may undergo changes in scale, shape and illumination during the tracking process. The similarity measure between the model and the candidate at the current location is often used to update the model [23,31]. Another strategy is to use Kalman filters to filter object kernel histogram so as to obtain an optimal estimation of the model [34,35]. These methods make trade-off between adaptation to rapid changes and robustness to changes due to occlusion. In this paper, we adopt the similarity measure to update the target model.Let qt−1 be the color model at the previous frame, pobjbe CWH within the acquired object region at the current frame. Then, the color model qtat current frame can be updated by:(4)qt=qt-1+e-γ[1-ρ(qt-1,pobj)](pobj-qt-1)where γ is a parameter that controls the model update rate with a default value of 15 in this paper, and ρ(q,p) is the similarity function between q and p using the Bhattacharyya coefficient.The color weight image of mean shift algorithm in Eq. (3) has been widely used in many applications. However, it cannot cope with low-contrast scenes involving complex motions such as VIVID sequences [36]. This indicates that there may be some inherent drawbacks in the weight image generation process. This section demonstrates and analyzes the underlining reasons for the failure and points out possible directions to improve performances.Suppose the foreground and background distributions are represented by color histograms Hf(u) and Hb(u){u=1,2,…,m}, respectively. Color histogram is employed because of its high flexibility in representing probability distributions. In tracking applications, the target model q(u) and the target candidate p(u) in Eq. (3) can be approximately seen as combinations of Hf(u) and Hb(u):(5)q(u)=αHb(u)+(1-α)Hf(u)(6)p(u)=βHb(u)+(1-β)Hf(u)In practice, we are only interested in relatively strong colors. That is too say, a color belongs to object if the occurring frequency in object is higher than that in background. For objects which have some parts similar to background, these colors give no contribution for tracking, thus can be categorized as background pixels. Though losing some generality, tracking by only using relatively strong object colors works well for most applications. Let ufand ubbe the relatively strong color elements from foreground and background, respectively. The following relationship holds: Hf(uf)>Hb(uf)⩾0, Hb(ub)>Hf(ub)⩾0. Thus:(7)Hf(uf)Hb(ub)-Hf(ub)Hb(uf)>0In most applications, the target model usually includes a few background pixels (α>0) because the target may be oblique, not rectangular, or with imperfect initializations. From the above assumptions, we can draw several interesting yet surprising conclusions:•For nearly zero motion displacements, target model and target candidate may have similar precision (α≈β). As a result, all color elements have similar weights approximated to 1, and weights for color elements with a low probability may be unstable. Thus, the tracker may drift under clutter scenes.For too large motion displacements, target candidate may contain no or loss parts of object colors. In this case, the weights for lost color elements will be 0 and the tracker fails.For in-between motion displacements, target candidate contains more background pixels than target model, thus is less precise (0<α<β). According to Eqs. (5)–(7), we can get the following relationship after simple manipulations: q(uf)p(ub)>q(ub)p(uf). Thus,(8)w(uf)=q(uf)p(uf)>w(ub)=q(ub)p(ub)It can be seen from (8) that the weight of ufis higher than that of ubfor in-between motions. Therefore, reliable tracking results can be acquired in this case.From the previous subsection, we can conclude that the weight of ufis higher than that of ubwhen target model is more precise than target candidate. In a similar way, we can testify that target model should be more precise than target candidate to ensure that the weight of ufis higher than that of ub. Thus, the relative precision between target model and target candidate is the main decision factor for the quality of the weight image.We now investigate the effects with different target candidate precision, since target candidate may change abruptly due to camera vibrations and illumination changes, whereas target model is usually updated smoothly. The foreground weight strength relative to the background one can be represented as:w(uf)w(ub)=[αHb(uf)+(1-α)Hf(uf)][βHb(ub)+(1-β)Hf(ub)][βHb(uf)+(1-β)Hf(uf)][αHb(ub)+(1-α)Hf(ub)]=CαHf(uf)Hb(ub)-Hb(uf)Hf(ub)Hf(uf)-β[Hf(uf)-Hb(uf)]-[Hb(ub)-Hf(ub)].Here, Cαis a factor which is independent on β. It can be seen that a larger value of β results in a better foreground weight strength. This means that target candidate with a low precision is suitable for reliable object tracking. For real scenes, though color histogram can represent arbitrary probability distributions, spatial layout of color elements can influence the accuracies of assumptions (5) and (6). Nevertheless, the above analysis just intends to explore the basic rules for possible directions to improve the performance of mean shift. Experimental results on various real videos in Section 6 validate the reasonability of the rules.Based on the above analysis, the representations of target model and target candidate should obey the following rules:•Target model should be as precise as possible. In [27,41], BWH is selected for target model whereas CWH is employed for target candidate. Since BWH suppresses surrounding background colors from the model, target model in these methods is more precise than target candidate, thus the tracker is more reliable.Target candidate with lower precision and enclosing the object at the same time is preferred.Global tracking skills such as annealed mean shift [28,29] or pyramid mean shift [27] are implemented in a coarse-to-fine manner. A large scale for target candidate is used at the coarse level, including foreground pixels into target candidate and making target candidate less precision, thus results are improved.The above two rules are called “precise model+less precise candidate enclosing the object” for short in this paper.The classical mean shift tracking algorithm intends to estimate an optimal displacement Δx∗, so that the target candidate p(x0+Δx∗) at the new location best matches the target model q. The tracking is regarded as a block-comparison problem, which somewhat violates the mechanism of human vision [30]. Instead, humans usually lock an object first by focus, and then by comparison. A large scale is used to place the whole object into the ROI and to make the object and its surroundings visibly discriminable. Focuses are given to regions which are more similar to object model than to the environments. As for target tracking applications, a large scale can be used to estimate target candidate representing the characteristics of visibly discriminable object and its surroundings. High weights will be given to colors which have higher probability to occur in target model than in target candidate. This property is termed as global tracking skills. The weights using this skill can be calculated by simply enlarging the target candidate scales:(9)wg(xi)=∑u=1mqupus(x0)δ[b(xi)-u],s>1where s is a scale factor, δ is the Kronecher delta function, b(xi) is the serial number of histogram bin for xi, and ps(x) is the CWH within bandwidth sh:(10)pus(x)=Cs∑i=1nshk‖x-xish‖2δ[b(xi)-u]Here, Csis a normalization constant to make the probabilities sum to 1, nshis the number of pixels within bandwidth sh, and k(x) is a profile function. When s equals to 1, Eq. (10) is the classical mean shift color cue and we denote the expression in this case as p(x).This extension has two desirable properties. Firstly, for large motion displacements, there exists a proper s so that the whole object regions are within bandwidth sh. In this case, there are object pixels in both psand q, and that q is more precise than ps, thus the weight is reliable. Secondly, for near-zero motion displacements, a value of s larger than 1 can make psless precise. Thus, q is more precise than ps, and the tracker will be stable.

@&#CONCLUSIONS@&#
The inherent drawbacks of the color cue in mean shift are analyzed. We show that target model should be far more precise than target candidate to achieve reliable tracking results. Based on this idea, a novel color cue for computing color weight image is proposed by employing spatial Context Information and Global tracking skills (CIG). Experimental results on various sequences show that the proposed method is effective under clutter scenes with complex motions for both rigid and non-rigid objects.To further improve the performance, we will investigate on how to adjust the value of the scale of the kernel to optimize performance according to conditions and the motion of the target object. In addition, shadow removal methods will be investigated in future works to decrease the influence of shadows. Efforts will also be given on occlusion detection and localizing the object when it reappears after long time occlusions.