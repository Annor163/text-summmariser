@&#MAIN-TITLE@&#
Feasibility problems with complementarity constraints

@&#HIGHLIGHTS@&#
Computing a Simple Feasible Solution of MPCC.Computing a Target Feasible Solution of MPCC.Convergence of a PGIP Algorithm for an Underdetermined Complementarity Problem.

@&#KEYPHRASES@&#
Global optimization,Nonlinear programming,Nonlinear systems of equations,Complementarity problems,Mathematical Programming with Complementarity Constraints,

@&#ABSTRACT@&#
A Projected-Gradient Underdetermined Newton-like algorithm will be introduced for finding a solution of a Horizontal Nonlinear Complementarity Problem (HNCP) corresponding to a feasible solution of a Mathematical Programming Problem with Complementarity Constraints (MPCC). The algorithm employs a combination of Interior-Point Newton-like and Projected-Gradient directions with a line-search procedure that guarantees global convergence to a solution of HNCP or, at least, a stationary point of the natural merit function associated to this problem. Fast local convergence will be established under reasonable assumptions. The new algorithm can be applied to the computation of a feasible solution of MPCC with a target objective function value. Computational experience on test problems from well-known sources will illustrate the efficiency of the algorithm to find feasible solutions of MPCC in practice.

@&#INTRODUCTION@&#
A Mathematical Programming Problem with Complementarity Constraints (MPCC) (Luo, Pang, & Ralph, 1996; Outrata, Kocvara, & Zowe, 1998; Ralph, 2007) can be defined in the form(1)Minimizeφ(x,y,w)subjecttoH(x,y,w)=0andmin{x,w}=0,wherex,w∈Rn,y ∈Rm, whileφ:R2n+m→R,andH:R2n+m→Rrare continuously differentiable functions. The feasible set of MPCC will be denoted by D and min {x, w} denotes a vector of components min {xi, wi},i=1,…,n. For alli=1,…,n,the variables xi, wiare said to be complementary and satisfy:(2)xi⩾0,wi⩾0,xiwi=0,i=1,…,n.MPCC has appeared frequently in optimization models and has significant applications in different areas of science, engineering and economics (Luo et al., 1996; Outrata et al., 1998; Ralph, 2007). Many theoretical and application papers in Operations Research, as well as survey papers on related topics (Bomze, 2012; Chen, 2000; Júdice, 2014; Kovacevic & Pflug, 2014; Lin & Fukushima, 2010), have been devoted to this problem in recent years. For example, transport network models were considered in García-Rodenas and Verastegui-Rayo (2008), Walpen, Mancinelli and Lotito (2015), Wu, Yin and Lawphongpanich (2011), bilevel optimization in Kovacevic and Pflug (2014), variational inequality formulations in Toyasaki, Daniele and Wakolbinger (2014), multiobjective problems with complementarity constraints in Lin, Zhang and Liang (2013), Ye (2011), electricity markets in Ehrenmann and Neuhoff (2009), Guo, Lin, Zhang and Zhu (2015), Hu and Ralph (2007), Yao, Oren and Adler (2007), quadratic programming with complementarity constraints in Ralph and Stein (2011), optimality conditions in Pang (2007), order-value applications in Andreani, Dunder and Martínez (2005), and oligopolistic equilibrium in Yao, Adler and Oren (2008), among others.Clearly, MPCC can be seen as a Nonlinear Programming Problem where the n complementarity constraintsmin{xi,wi}=0are replaced with (2) or even withx⊤w=0,x ⩾ 0, w ≥ 0. Attempts for solving MPCC by means of nonlinear programming algorithms present some difficulties, mainly because these algorithms may converge to points from which there exist obvious first-order descent directions. This issue is a consequence of the so-called double zeros or biactive indices, i.e., feasible points satisfying at least a constraintxiwi=0with both variables xiand wiequal to zero. These difficulties have motivated much research on weak forms of stationarity (Ferris & Pang, 1997; Hoheisel, Kanzow, & Schwartz, 2013; Luo et al., 1996;Outrata et al., 1998; Ralph, 2007; Scheel & Scholtes, 2000) and several algorithms have been designed to compute such weak stationary points (Anitescu, 2005; Anitescu, Tseng, & Wright, 2007; Benson, Sen, Shanno, & Vanderbei, 2006; Fang, Leyffer, & Munson, 2012; Fletcher & Leyffer, 2004; Fukushima, Luo, & Pang, 1998; Fukushima & Tseng, 2002; Hoheisel et al., 2013; Hu & Ralph, 2004; Jiang & Ralph, 2003; Júdice, Sherali, Ribeiro, & Faustino, 2007, Leyffer, López-Calva, & Nocedal, 2006; Luo et al., 1996; Outrata et al., 1998; Ralph, 2007).In this paper, we will discuss how to compute a feasible solution of the MPCC, that is, a solution of the following Horizontal (possibly nonlinear) Complementarity Problem (HNCP) Gowda (1995):(3)[H(x,y,w)x1w1⋮xnwn]=0,x≥0,w≥0.We will assume thatr≤m+n,so that the number of equations in (3) is smaller than or equal to the number of unknowns. The case in whichr=m+nhas been studied in Andreani, Júdice, Martínez and Patrício (2011b). The case of H affine has been thoroughly discussed in the literature (see for instance Júdice (2014) for a recent survey). The HNCP is NP-hard in this case Murty (1988) but there are many MPCCs where finding a single feasible solution can be considered as an easy task Júdice (2014).The problem of finding a feasible point of MPCC at which the objective function achieves a target value ctis naturally formulated as follows:(4)φ(x,y,w)⩽ct,H(x,y,w)=0,x⩾0,w⩾0andx⊤w=0.Note that the problem (4) can be written as a standard HNCP adding two auxiliary variables v1 and v2, as follows:(5)φ(x,y,w)+v1=ct,H(x,y,w)=0,v1v2=0,xiwi=0,i=1,…,n,v1≥0,v2≥0,x≥0,andw≥0.In this paper we will extend the algorithm introduced in Andreani et al. (2011b), which deals with the caser=n+m,for the underdetermined HNCP (3) where r may be smaller thann+m. The Projected-Gradient Underdetermined Newton-like algorithm (PGUN) combines fast interior-point iterations with projected-gradient steps. A line-search procedure is employed guaranteeing sufficiently reduction of the natural merit function Andreani, Júdice, Martínez and Patrício (2011a) associated to HNCP. This will allow us to establish global convergence of the PGUN algorithm to a solution of HNCP or to a stationary point of the merit function with a positive function value. In this case the algorithm terminates unsuccessfully. Fast local convergence will be established under reasonable hypotheses.Computational experience with PGUN for solving the HNCP associated to feasible solutions of some MPCC test problems from a well-known collection Leyffer (2000) will show that, for many instances, projected-gradient iterations are seldom used and the algorithm is able to converge very fast to a solution of HNCP. For other instances, PGUN converges slowly using projected-gradient iterations to a stationary point of the merit function that seems not to be a solution of the HNCP. A practical criterion will be introduced to stop prematurely PGUN and avoid many projected-gradient iterations. As the natural merit function is nonconvex, the choice of the starting point is very important for the success of PGUN. Here we will suggest to restart the PGUN algorithm with a new initial point whenever the criterion mentioned before forced the algorithm to stop prematurely. Numerical results with an implementation of PGUN incorporating these two practical procedures (premature stopping criterion and restarting) show that the method is in general efficient to solve the HNCP and seems to perform better than a Projected Levenberg-Marquardt algorithm Kanzow, Yamashita and Fukushima (2005). We have also tested PGUN for solving (5) associated to a target ctequal to the best known objective function value of some MPCCs from the collection mentioned before. As discussed in Fernandes, Friedlander, Guedes and Júdice (2001), the introduction of the target constraint to HNCP makes this problem more difficult to tackle and PGUN has more difficulties to solve the HNCP in this case. Despite this, PGUN has been able to provide a target feasible solution of MPCC for the large majority of tested instances.The organization of this paper is as follows. The properties of the merit function for the HNCP are studied in Section 2. The algorithm PGUN will be described and its global convergence will be analyzed in Section 3. Section 4 will be devoted to the local convergence of the PGUN algorithm. Computational experience with the PGUN algorithm will be reported in Section 5 and some conclusions will be presented in the last section of the paper.Notation: The 2-norm of vectors and matrices will be denoted by ‖·‖. If there is no risk of confusion we denote(x,y,w)=(x⊤,y⊤,w⊤)⊤,as it has been already done in Section 1. We adopt the usual convention of denoting X the diagonal matrix whose entries are the elements of x ∈Rn. The Moore–Penrose pseudoinverse of the matrix A will be denoted by A†. The Jacobian matrix of Φ:Rn→Rm, with componentsφ1,…,φm,will be defined byΦ′(z)=[∂φ1∂z1(z)…∂φ1∂zn(z)⋮⋱⋮∂φm∂z1(z)…∂φm∂zn(z)].We definee=(1,⋯,1)⊤and(6)Ω={(x,y,w):x⩾0,w⩾0}.The Interior of this set will be denoted by Int(Ω).The HNCP (3) may be expressed in the form(7)F(x,y,w)=0,x≥0,w≥0,whereF:Rn+m+n⟶Rr+nis given by(8)F(x,y,w)=[H(x,y,w)x1w1⋮xnwn],andH:Rn+m+n→Rrhas continuous first derivatives.We define the natural merit function:(9)f(x,y,w)=∥F(x,y,w)∥2and we consider the problem(10)Minimizef(x,y,w)subjectto(x,y,w)∈Ω,where Ω is defined in (6). From now on we will denotez=(x,y,w).It is well known that, if z* is an unconstrained stationary point of “Minimize ‖Φ(z)‖2” and the residual Φ(z*) is not null, then the rows of the Φ′(z*) are linearly dependent. In general, this property is not true in the presence of bound constraints. In what follows, generalizing a result proved in Andreani et al. (2011a), we prove that the non-full-rank property also holds in the case of problem (10) with the definitions (8) and (9).Theorem 2.1Suppose thatz¯=(x¯,y¯,w¯)∈Ωis a stationary point of(10). Then,(a)ifH(z¯)=0orHy′(z¯)is full row-rank, thenz¯is solution of(7);if∥F(z¯)∥≠0,the rows of the JacobianF′(z¯)are linearly dependent.Ifz¯is a stationary point of (10), then(11)12∇f(z¯)=F′(z¯)⊤F(z¯)=[Hx′(z¯)⊤WHy′(z¯)⊤0Hw′(z¯)⊤X][H(z¯)x1¯w1¯⋮xn¯wn¯]=[γ0α],(12)xi¯γi=0,i=1,…,n,wi¯αi=0,i=1,…,n,x¯≥0,γ≥0,w¯≥0,andα≥0.(a) IfH(z¯)=0,we deduce that:[WX][x1¯w1¯⋮xn¯wn¯]=[γα].Thus,x¯iw¯i=0for alli=1,…,nandz¯is a solution of (7).On the other hand, ifHy′(z¯)is full row-rank, then, by (11),H(z¯)=0. Therefore, as proved above, we have thatz¯is solution of (7).(b) Suppose now thatF(z¯)≠0. By (11), ifx¯i=w¯i=0for somei∈{1,…,n},the columnr+iof[Hx′(z¯)⊤WHy′(z¯)⊤0Hw′(z¯)⊤X]is null, Then the the rows ofF′(z¯)are linearly dependent.Assume thatx¯ik>0andw¯ik>0for q indices ik,k=1,…,qbelonging to{1,…,n}. Then there are three possible cases:Case 1:q=n;Case 2:q=0;Case 3: 1 ≤ q < n.In Case 1, the stationarity imposes that the derivatives of f with respect to all the variables must vanish. Therefore,[Hx′(z¯)⊤WHy′(z¯)⊤0Hw′(z¯)⊤X][H(z¯)x1¯w1¯⋮xn¯wn¯]=0,withx¯iw¯i>0for alli=1,…,n. Then, the rows ofF′(z¯)are linearly dependent.Let us now consider Case 2. Since the case in which there exists i such thatx¯i=w¯i=0has already been considered, we have thatx¯i+w¯i>0for alli=1,…,n. Then, we may assume without loss of generality thatx¯i=0,w¯i>0for alli=1,…,n. Then, by (11),(13)[Hx′(z¯)⊤W¯Hy′(z¯)⊤0Hw′(z¯)⊤0][H(z¯)0]−[γ00]=0.Thus,[Hy′(z¯)⊤0Hw′(z¯)⊤0][H(z¯)0]=[00].This implies that the matrix[Hy′(z¯)⊤0Hw′(z¯)⊤0]has at mostr−1linearly independent columns. Therefore, the matrix[Hx′(z¯)⊤W¯Hy′(z¯)⊤0Hw′(z¯)⊤0]has at mostn+r−1linearly independent columns. SinceX¯=0,this implies that[Hx′(z¯)⊤W¯Hy′(z¯)⊤0Hw′(z¯)⊤X¯]has at mostn+r−1linearly independent columns. ThusF′(z¯)has at mostn+r−1linearly independent rows. SinceF′(z¯)hasn+rrows, it turns out that this Jacobian is not full row-rank.Let us now consider Case 3. Suppose, without loss of generality, that(14)x¯i,w¯i>0fori=1,…,q<nand(15)x¯i=0,w¯i>0fori=q+1,…,n.Splitting the first block of (11) into two blocks corresponding to its first q and lastn−qequations, using (12), (14) and (15), callingH^x′(z¯)to the matrix formed by the first q rows ofHx′(x¯,y¯,z¯)⊤,and callingW^to the diagonal q × q matrices whose entries arew¯1,…,w¯q,we obtain:(16)[H^x′(z¯)⊤W^Hy′(z¯)⊤0H¯w′(z¯)⊤X¯H˜w′(z¯)⊤0][H(z¯)x1¯w1¯⋮xq¯wq¯]=[000].Therefore, the matrixA=[H^x′(z¯)⊤W^Hy′(z¯)⊤0H¯w′(z¯)⊤X¯H˜w′(z¯)⊤0]has at mostr+q−1linearly independent columns. Now defineH˜x′(z¯)⊤as the matrix containing the lastn−qrows ofHx′(z¯)⊤,W˜as the diagonal matrix whose entries arew¯q+1,…,w¯n,andB=[H^x′(z¯)⊤W^0H˜x′(z¯)⊤0W˜Hy′(z¯)⊤00H¯w′(z¯)⊤X¯0H˜w′(z¯)⊤00]Since B comes from addingn−qrows and columns to A, the matrix B has at mostn+r−1linearly independent columns. But, by (11), (14), and (15), we have thatB=F′(z¯)⊤. Therefore, the Jacobian is not a full row-rank matrix, as we wanted to prove.□In this section we introduce a Projected Gradient Underdetermined Newton-like (PGUN) Algorithm for the solution of the (possibly) underdetermined system (8). This algorithm is an extension of the method introduced in Andreani et al. (2011b) for the solution of this system when the number of equalities is equal to the number of variables, i.e., whenr=n+m. PGUN generates iterates lying inside Int(Ω) and combines interior-point Newton-like and projected-gradient directions with a line-search procedure Li and Fukushima (2000). The steps of the PGUN method are presented below.Step 0:Initial setup: Consider γ > 0 and γk> 0 for all k ∈Nand such that∑k=0∞γk=γ<∞.Let τ ∈ (0, 1), σ ∈ (0, 1),0<η¯1<η¯2,ρ > 0,β∈(0,12),cbig > csmall > 0, csmall < 1. Letz0=(x0,y0,w0)∈Int(Ω). Assume thatzk=(xk,yk,wk)∈Int(Ω),σk∈ [0, 1/6], τk∈ [τ, 1), andηk∈[η¯1,η¯2]. Then, the steps for obtainingzk+1=(xk+1,yk+1,wk+1)∈Int(Ω)or declaring finite convergence are the following:Declare finite convergence if the scaled projected–gradient is zero: Computeg(zk,ηk)=PΩ(zk−ηk∇f(zk))−zk.Ifg(zk,ηk)=0,stop. (An approximate stationary point of (10) has been obtained.)Newton-like direction: Compute, if possible,dk=(dxk,dyk,dwk)∈Rn+m+nsatisfying(17)H′(zk)dk+H(zk)=0and(18)xikwik+xik(dwk)i+wik(dxk)i=μik,where μk≥ 0 and(19)∥μk∥∞≤σk(xk)⊤wkn.If such a direction dkdoes not exist or if ‖dk‖ > cbig, go to Step 4.Compute the maximum steplength: Compute(20)αkbreak=max{α≥0|zk+αdk∈Ω}and(21)αkmax=min{1,τkαkbreak}.Ifαkmax≤csmallmin{1,∥dk∥},go to Step 4. Otherwise, go to Step 5.Projected gradient direction: Compute (or re-define)dk=g(zk,ηk),and setαkmax=τk.Line–search: Setα=αkmax.Step 5.1:If(22)∥F(zk+αdk)∥≤∥F(zk)∥−ρ∥αdk∥2+γksetαk=αand go to Step 6.Chooseαnew∈[βα,(1−β)α],setα=αnewand go to Step 5.1.Compute the new iterate: Choosezk+1∈Ωsuch that(23)∥F(zk+1)∥≤∥F(zk+αkdk)∥.End.Given zknot satisying the stopping criteriong(zk,ηk)=0,the fact thatzk+1is well defined follows trivially from Step 5, using γk> 0. The global convergence of PGUN is established in Theorem 3.1.Theorem 3.1Givenzk=(xk,yk,wk)such that xk> 0, wk> 0 and g(zk, ηk) ≠ 0), the point(xk+1,yk+1,wk+1)∈Int(Ω)is always well defined. Moreover, if {zk} is a sequence generated by Algorithm PGUN and z*is a cluster point such thatlimk∈K1zk=z*,where K1 ⊂Nis an infinite subsequence of indices, then:1.z*is a stationary point of  Minimize f(z) subject to z ∈ Ω.If F′(z*) is a full row-rank matrix, thenF(z*)=0.If K1contains infinitely many indices k such that dk is computed (at Step 2) as a Newton-like direction, thenF(z*)=0.The stationarity of z* and the fact thatF(z*)=0when K1 contains infinitely many Newton-like iterations follow exactly as in Andreani et al. (2011b), where the theorem was proved for the (square) case in whichn+m=r. In the general case considered here the second part of the thesis is a consequence of the stationarity of z* and Theorem 2.1.□At Step 2 of PGUN one considers the linear system given by (17) and (18). If this linear system is incompatible the algorithm goes to Step 4 where a projected gradient direction is computed. All along this section we will assume that, whenever (17)–(18) is compatible, the computed direction dkwill be the minimum-norm solution of that system. This implies that dkbelongs to the range space of F′(zk)⊤ and(24)dk=F′(zk)†[−H(zk)−XkWke+μk],where μk≥ 0 satisfies (19).Note that the minimum-norm Newtonian direction associated with the systemF(z)=0would be obtained takingμk=0in (24).In Theorem 3.1 we proved that limit points of a sequence generated by PGUN are necessarily stationary points of the natural merit function f. Moreover, when the Jacobian of F is full row-rank at a limit point, this point is a solution of the problem. Finally, every limit point of a subsequence of iterates xksuch that dkis always computed at Step 2 is necessarily a solution of the nonlinear system. These global convergence results will be complemented in this section by local characterizations that tell us something about convergence of the whole sequence and its speed of convergence.The local results that will be presented in this section are closely related with the local convergence results of Newton’s method for underdetermined nonlinear systems. Roughly speaking, we are going to prove that, in a neighborhood of a solution at which the Jacobian has full row-rank, PGUN reduces to something very similar to Newton’s method with the minimum norm choice of the solution of the linear system and, as a consequence, enjoys the local convergence properties of that method. However, the identification of the local PGUN and Newton’s method in that case is not complete because μkmay not be zero in (24).Recall that PGUN does not admit negative components of (xk, wk). Therefore, the search direction is multiplied by a factorαmaxkthat inhibits the possibility of taking a trial point with non-positive components in (x, w). For proving that, eventually, PGUN behaves as a pure Newton-like method, we need to prove thatαmaxkis as close to 1 as desired. This essentially means that we do not need to truncate the direction computed at (24). We will prove this property in Theorem 4.1. In Theorem 4.2 we will prove that, if the Jacobian has full row-rank at a limit point, the whole sequence converges to that limit point. As a by-product we will prove that, eventually,αk=αkmax,which means that the first trial point at Step 5 of PGUN is accepted because the norm of F decreases as required by (22). The consequence of Theorems 4.1 and 4.2 is that, for k large enough, PGUN is very similar to Newton’s method with the Moore–Penrose pseudoinverse choice of linear-system solution. The fact thatαk=αkmax,together with Theorem 4.1, implies that αk≈ 1. Therefore, the result of Theorem 4.3 (superlinear and quadratic convergence) is not surprising, since this is the type of result that is typically obtained for Newton’s method in the underdetermined and regular case. Here we could invoke well-known results as the ones given by Chen and Yamamoto (1994) but we prefer include the complete proof for the sake of completeness.In this section we aim to prove that, in a neighborhood of a solution z* of (7) such that F′(z*) is full row-rank, the steplengthαkmax,computed at Step 3 of PGUN (formulas (20) and (21)), with dkcomputed at Step 2, can be taken as close to 1 as desired. This means that, given an arbitrary δ < 1, if zkis close enough to the solution, the maximal steplengthαkbreakis bigger than δ. This result has been proved in the case that2n+m=r+n(square system) in Andreani et al. (2011b). The proof in the rectangular case is more involved since the solution of the Newtonian linear system is not unique.Theorem 4.1Assume that Algorithm PGUN is applied to problem(7)and that z*is a solution at which the Jacobian F′(z*) is full row-rank. Assume that δ ∈ (0, 1). Then, there exists ε > 0 such that, whenever∥zk−z*∥≤ɛone has that dk is well defined by(17)and(18)andαkbreak≥δ.Assume that F′(z*) is full row-rank andF(z*)=0. Denote W ∈Rn × nthe diagonal matrix whose entries arew1,…,wnand X the diagonal matrix whose entries arex1,…,xn. Then,F′(z)=[Hx′(z)Hy′(z)Hw′(z)W0X]∈R(r+n)×(2n+m).Since F′(z*) is full row-rank,xi*andwi*cannot be zero simultaneously. Without loss of generality (perhaps changing the names of some variables xiand wi), we may assume thatxi*=0andwi*>0for alli=1,…,n. So,F′(z*)=[Hx′(z*)Hy′(z*)Hw′(z*)W*00].Therefore, by the linear independence of the rows of F′(z*), the matrix[Hy′(z*)Hw′(z*)]is full row-rank.Let ε > 0 be such that, for all z such that∥z−z*∥≤ɛ,(25)F′(z)andHyw′(z)≡[Hy′(z)Hw′(z)]arefullrow-rank.Since H has continuous first derivatives, (25) implies that ‖F′(z)†‖ and∥Hyw′(z)†∥are uniformly bounded for all z such that∥z−z*∥≤ɛ.For a genericz=(a,b,c),a > 0, c > 0 such that∥z−z*∥≤ɛ,and μ ≥ 0 ∈Rnwe define x, y, and w in such a way that(x−a,y−b,w−c)is the minimum norm solution of:(26){Hx′(a,b,c)(x−a)+Hy′(a,b,c)(y−b)+Hw′(a,b,c)(w−c)=−H(a,b,c),C(x−a)+A(w−c)=−Ca+μ.Clearly, x, y, w are functions of a, b, c, and μ but we do not make this dependence explicit in order to simplify the notation.By the boundedness of ‖F′(a, b, c)†‖,(27)lim(z,μ)→(z*,0)∥x−a∥=lim(z,μ)→(z*,0)∥w−c∥=lim(z,μ)→(z*,0)∥y−b∥=0.So,(28)lim(z,μ)→(z*,0)(x,w)=(x*,w*)=(0,w*).By (26) and simplifying the notation, we have that:(29)[Hx′Hy′Hw′C0A][x−ay−bw−c]=[−H−Ca+μ]∈Rr+n.Taking the minimum norm solution of (29), we have that(x−a,y−b,w−c)⊤belongs to the range space of F′(z*)⊤. Therefore, there exist q ∈Rpand t ∈Rnsuch that(30)[x−ay−bw−c]=[(Hx′)⊤C(Hy′)⊤0(Hw′)⊤A][qt]∈Rm+2n.Therefore,(31){x−a=(Hx′)⊤q+Cty−b=(Hy′)⊤qw−c=(Hw′)⊤q+AtThus, by (29) and (31),(32)[Hx′(Hx′)⊤+Hy′(Hy′)⊤+Hw′(Hw′)⊤Hx′C+Hw′AC(Hx′)⊤+A(Hw′)⊤C2+A2][qt]=[−H−Ca+μ]Therefore,(33)t=−(C2+A2)−1(C(Hx′)⊤+A(Hw′)⊤)q−(C2+A2)−1(Ca−μ).By the first equation of (32) and (33) we have that:(34)((Hx′(Hx′)⊤+Hy′(Hy′)⊤+Hw′(Hw′)⊤)−(Hx′C+Hw′A)(C2+A2)−1(C(Hx′)⊤+A(Hw′)⊤))q=−H+(Hx′C+Hw′A)(C2+A2)−1(Ca−μ).Note that(35)(C2+A2)−1=C−1(I+C−1A2C−1)−1C−1.Let us defineH˜′=Hx′(Hx′)⊤+Hy′(Hy′)⊤+Hw′(Hw′)⊤−(Hx′C+Hw′A)(C2+A2)−1(C(Hx′)⊤+A(Hw′)⊤).Then, by (35),(36)H˜′=Hx′(Hx′)⊤+Hy′(Hy′)⊤+Hw′(Hw′)⊤−(Hx′+Hw′AC−1)(I+C−1A2C−1)−1((Hx′)⊤+C−1A(Hw′)⊤).By (36), since A → 0, we have thatH˜′→Hy′(z*)Hy′(z*)⊤+Hw′(z*)Hw′(z*)⊤.Since the matrix[Hy′Hw′]is full row-rank, we have that, if (a, b, c) is close enough to z*,H˜′is nonsingular and its inverse is bounded. Then, recalling that, by (34),(37)q=(H˜′)−1(−H+(Hx′C+Hw′A)(C2+A2)−1(Ca−μ)),we obtain that q is bounded if (a, b, c) is close enough to the solution and μ is close enough to 0. Moreover, sinceCa−μ→0,we have thatq=q(a,b,c,μ)tends to zero as (a, b, c) tends to z* and μ tends to zero.In other words,(38)lim(z,μ)→(z*,0)q(a,b,c,μ)=0.Analogously, by (33),(39)lim(z,μ)→(z*,0)t(a,b,c,μ)=0.Recall thatx−a=(Hx′)⊤q+Ct.Then, by (33),(40)Ct=−C((C2+A2)−1(C(Hx′)⊤+A(Hw′)⊤)q−(C2+A2)−1(Ca−μ))=−CC−1(I+C−1A2C−1)−1C−1C((Hx′)⊤+C−1A(Hw′)⊤)q−CC−1(I+C−1A2C−1)−1C−1C(a−C−1μ)=−(I+C−1A2C−1)−1((Hx′)⊤+C−1A(Hw′)⊤)q−(I+C−1A2C−1)−1(a−C−1μ)and(41)x=(Hx′)⊤q+Ct+a=(I−(I+C−1A2C−1)−1)a+(I−(I+C−1A2C−1)−1)(Hx′)⊤q−(I+C−1A2C−1)−1(C−1A(Hw′)⊤)q+(I+C−1A2C−1)−1C−1μ.Observe thatI−(I+C−1A2C−1)−1=I−I−∑j=1∞(−1)j(C−1A2C−1)j=C−1A2C−1(I+∑j=1∞(−1)j(C−1A2C−1)j).Then, by (41),x=C−1A2C−1(I+∑j=1∞(−1)j(C−1A2C−1)j)a+C−1A2C−1(I+∑j=1∞(−1)j(C−1A2C−1)j)((Hx′)⊤q)−AC−1(I+C−1A2C−1)−1((Hw′)⊤)q+(I+C−1A2C−1)−1C−1μ.Therefore, for alli=1,…,nwe have that(42)xi≥(ci)−2(ai)2[(I+∑j=1∞(−1)j(C−1A2C−1)j)a]i+(ci)−2(ai)2[(I+∑j=1∞(−1)j(C−1A2C−1)j)((Hx′)⊤q)]i−(ci)−1ai[(I+C−1A2C−1)−1((Hw′)⊤)q]i.Our objective now is to investigate the possible values of α ∈ [0, 1] such that(43)αxi+(1−α)ai=0or(44)αwi+(1−α)ci=0.If (44) takes place, then(45)α=cici−wi.But, by (27) and sincewi*>0,an α ∈ [0, 1] satisfying (45) cannot exist if ε is small enough.Therefore, we only need to analyze the values of α that satisfy (43).By (43),α=1+αxiai.Then, by (42),α≥1+α(ci)−2(ai)2ai[(I+∑j=1∞(−1)j(C−1A2C−1)j)a]i+(ci)−2(ai)2ai[(I+∑j=1∞(−1)j(C−1A2C−1)j)((Hx′)⊤q)]i−(ci)−1aiai[(I+C−1A2C−1)−1(Hw′)⊤q]i.Thus,(46)α≥1+α(ci)−2ai[(I+∑j=1∞(−1)j(C−1A2C−1)j)a]i+α(ci)−2ai[(I+∑j=1∞(−1)j(C−1A2C−1)j)(Hx′)⊤q]i−αci[(I+C−1A2C−1)−1(Hw′)⊤q]iBy (38) and (46), given any δ ∈ [0, 1), and taking ε small enough we obtain thatα=1. Consequently,αkbreak≥δ.□Assumption L. For all z, z′ ∈ Ω,(47)∥F′(z)−F′(z′)∥≤L∥z′−z∥∀z,z′∈Ω⊂Rm+2n.As a consequence, for all z, z′ ∈ Ω,(48)∥F(z′)−F(z)−F′(z)(z′−z)∥≤L2∥z′−z∥2.Theorem 4.2Assume that Assumption L holds, z* ∈ Ω is a cluster point of a sequence generated by Algorithm PGUN, F′(z*) is full row-rank and, for k large enough, we choose(49)zk+1=zk+αkdkat Step 6 of the algorithm. Assume, further, that cbig (used at Step 2 of Algorithm PGUN) is greater than 4‖F′(z*)†‖ andlimk→∞τk=1. Then,limk⟶∞zk=z*and(50)αk=αkmaxfor k large enough.Let K1 be an infinite sequence of indices such thatlimk∈K1zk=z*.By Theorem 3.1, z* is a stationary point of f over Ω.The choice of dkat Step 2 of the algorithm gives:(51)H′(zk)dk+H(zk)=0and(xik[dwk]i+wik[dxk]i+xikwik)2=σk2〈xk,wk〉2n2≤σk2∑i=1n(xikwik)2n.So,∑i=1n(xik[dwk]i+wik[dxk]i+xikwik)2≤σk2∑i=1n(xikwik)2≤σk2∥F(zk)∥2.Then, by (51),(52)∥F′(zk)dk+F(zk)∥≤σk∥F(zk)∥.Since F′(z*) is full row-rank, there exists ε1 > 0 such that ‖F′(z)†‖ ≤ M1 ≡ 2‖F′(z*)†‖ and F′(z) is full row rank whenever∥z−z*∥≤ɛ1. Moreover,F′(z)†F′(z)F′(z)†=F′(z)†. Therefore, by (52), for k ∈ K1 large enough and∥zk−z*∥≤ɛ1,(53)∥dk∥=∥F′(zk)†[−H(zk)−XkWke+μk]∥=∥F′(zk)†F′(zk)F′(zk)†[−H(zk)−XkWke+μk]∥=∥F′(zk)†F′(zk)dk∥≤∥F′(zk)†∥∥F′(zk)dk+F(zk)−F(zk)∥≤∥F′(zk)†∥(∥F′(zk)dk+F(zk)∥+∥F(zk)∥)≤M1(1+σk)∥F(zk)∥.By Theorem 3.1, we have thatF(z*)=0. Moreover, since cbig≥ 4‖F′(z*)†‖, if∥zk−z*∥≤ɛ1,k ∈ K1, large enough, we have that ‖F(zk)‖ ≤ 1 and (53) implies that dkis computed at Step 2.DefineM2=2∥F′(z*)∥. Then, since F and F′ are continuous,F(z*)=0. By (53) and Theorem 4.1 there exists ε2 ∈ (0, ε1] such that for all k ∈Nsuch that∥zk−z*∥≤ɛ2,we have that:(i)∥dk∥≤M1(1+σk)∥F(zk)∥;αkmax≥max{1−112M1M2,1112};‖F′(zk)‖ ≤ M2;∥F(zk)∥≤112LM12;ρ∥αkmaxdk∥2≤12∥F(zk)∥.Then, for all k ∈Nsuch that∥zk−z*∥≤ɛ2,(54)∥F(zk+αkmaxdk)∥≤∥F(zk+αkmaxdk)−F(zk)−αkmaxF′(zk)dk∥+∥F(zk)+αkmaxF′(zk)dk∥≤L2(αkmax)2∥dk∥2+∥F(zk)+F′(zk)dk∥+(1−αkmax)∥F′(zk)dk∥≤L2(αkmax)2∥dk∥2+σk∥F(zk)∥+(1−αkmax)∥F′(zk)dk∥≤L2(αkmax)2M12(1+σk)2∥Fzk∥2+σk∥F(zk)∥+(1−αkmax)∥F′(zk)∥M1(1+σk)∥Fzk∥≤(L2(αkmax)2M12∥F(zk)∥+σk+(1−αkmax)(1+σk)M2M1)∥F(zk)∥≤12∥F(zk)∥≤∥F(zk)∥−ρ∥αkmaxdk∥2+γk.Therefore, by (22), for all k ∈Nsuch that∥zk−z*∥≤ɛ2,we have thatαk=αkmax(proving (50)),(55)zk+1=zk+αkmaxdk,and∥F(zk+1)∥≤12∥F(zk)∥.Sincelimk∈K1F(zk)=F(z*)=0,there exists k0 ∈ K1 such that∥zk0−z*∥≤ɛ24and∥F(zk0)∥≤ɛ24(4M1+1). We will prove by induction that∥zk−z*∥≤ɛ2for all k ≥ k0, k ∈N. This is trivial fork=k0.Assume, by inductive hypothesis, that∥zk−z*∥≤ɛ2for allk=k0,k0+1,…,k0+j−1. Then, by (55),∥F(zk+1)∥≤12∥F(zk)∥fork=k0+1,…,k0+j−1.By (55) and (i)–(v), we can write:∥zk0+j−zk0∥=∥∑i=0j−1αk0+imaxdk0+i∥≤2M1∑i=0j−1(12)i∥F(zk0)∥≤4M1∥F(zk0)∥≤ɛ24.Therefore,∥zk0+j−z*∥≤∥zk0+j−zk0∥+∥zk0−z*∥≤ɛ22.Thus,∥zk0+j−z*∥≤ɛ2. This completes the inductive proof.Let us prove now that {zk} is a Cauchy sequence.Let j ≥ k0 and ℓ ≥ 1. Then,(56)∥zj+ℓ−zj∥≤∑i=0ℓ−1αj+imax∥dj+i∥≤2M1∑i=0ℓ−1(12)i+1∥F(zj)∥≤2M1∑i=0ℓ−1(12)i+1∥F(zj)∥≤2M1∥F(zj)∥.Sincelimj→∞∥F(zj)∥=0,(56) implies that {zk} is a Cauchy sequence. Then, since z* is a limit point, we have thatlimk⟶∞zk=z*.□In this section we will prove that, under the assumptions of Theorem 4.2 and adequate choices of the parameters σk, the algorithm exhibits superlinear or quadratic convergence.We will consider the following assumption on the parameters σk.Assumption S. Choose σksuch that(57)limk→∞σk=0.Theorem 4.3Assume that {zk} is generated by Algorithm PGUN and converges to z*such thatF(z*)=0,where F′(z*) is full row-rank, and for k large enough we choose(58)zk+1=zk+αkdkat Step 6 of the algorithm. Assume that the hypotheses ofTheorem 4.2, and both assumptions L and S hold. Then, zk converges superlinearly to z*.Moreover, if there exists c1, c2 > 0 such that, for all k large enough,(59)σk≤c1∥F(zk)∥and1−τk≤c2∥F(zk)∥,zk converges quadratically to z*.Since τk→ 1 we have thatlimk→∞αkmax=1.By Theorem 4.2, for all k large enough there exists M > 0 such that ‖dk‖ ≤ M‖F(zk)‖, ‖F′(zk)‖ ≤ M and(60)∥F(zk+1)∥≤∥F(zk+1)−F(zk)−αkmaxF′(zk)dk∥+∥F(zk)+αkmaxF′(zk)dk∥≤L2(αkmax)2∥dk∥2+∥F(zk)+F′(zk)dk∥+(1−αkmax)∥F′(zk)dk∥≤L2M2∥F(zk)∥2+σk∥F(zk)∥+(1−αkmax)M2∥F(zk)∥≤(L2M2∥F(zk)∥+σk+(1−αkmax)M2)∥F(zk)∥=Rk∥F(zk)∥whereRk=L2M2∥F(zk)∥+σk+M2(1−αkmax).Moreover,∥zk+1−z*∥≤∑j=k+1∞αjmax∥dj∥≤2M∑j=1∞(12)j∥F(zk+1)∥.By (60) and (48) we have that∥zk+1−z*∥≤2MRk∥F(zk)∥=2MRk∥F(zk)−F(z*)−F′(zk)(zk−z*)+F′(zk)(zk−z*)∥≤2MRk∥F(zk)−F(z*)−F′(zk)(zk−z*)∥+∥F′(zk)(zk−z*)∥≤2MRk(L2∥zk−z*∥+M)∥zk−z*∥≤2MRkL(L2+M)∥zk−z*∥.Sincelimk→∞Rk=0,zkconverges superlinearly to z*.Now, takingc=max{c1,c2},sincemax{σk,1−αkmax}≤max{σk,1−τk}≤c∥F(zk)∥,we have that∥zk+1−z*∥≤2M(L2M2∥F(zk)∥+σk+(1−αkmax)M2)∥F(zk)∥≤2M(L2M2+(1+M2)c)∥F(zk)∥2≤2M(L2+M)2(L2M2+(1+M2)c)∥zk−z*∥2.Therefore, quadratic convergence is proved.□In this section we will report some experiments with the PGUN algorithm for the solution of (3) and (5). In order to have a better idea of the efficiency of PGUN in practice, we have compared the PGUN method with the Projected-Gradient Levenberg–Marquardt (PLM) algorithm Kanzow et al. (2005).The Projected Levenberg–Marquardt (PLM) is an algorithm for the solution of constrained nonlinear systemsF(z)=0,z∈Z,where Z ∈Rnis a nonempty, closed and convex set. For solving this problem the method is applied to a nonlinear program of a form similar to (10) where the merit function is also defined by (9).The PLM algorithm generates a sequence {zk} byzk+1=PZ(zk+dUk)k=0,1,…,wheredUkis the unique solution of the system of linear equations(61)(Jk⊤Jk+μkI)dU=−Jk⊤F(zk)and Jkis an approximation to the Jacobian F′(zk).We present below, in general terms, the method based on Algorithm 3.12 of Kanzow et al. (2005) with the additional line search step considered in the experimental section of Kanzow et al. (2005).For more details about the method and its convergence properties see Kanzow et al. (2005).Step 0:Initial setup: Choose z0 ∈ Z, μ > 0, β, σ, γ ∈ (0, 1), ρ > 0 and p > 1.Declare finite convergence: IfF(zk)=0,stop.Unconstrained direction: Choose Jk, setμk=μ∥F(zk)∥2and computedUkas the solution of (61).Levenberg–Marquardt step: If(62)∥F(PZ(zk+dUk))∥⩽γ∥F(zk)∥,then setzk+1=PZ(zk+dUk)and go to Step 1.Line Search step: If the search directionsk=PZ(zk+dUk)−zkis a descent direction of f in the sense that∇f(zk)⊤sk⩽−ρ∥sk∥p,setα=1andStep 4.1:If∥F(zk+tsk)∥2⩽∥F(zk)∥2+γα∇f(zk)⊤skthen setzk+1=zk+αskand go to Step 1.Choose αnew∈ (0, α), setα=αnewand go to Step 4.1.Projected Gradient step: Compute a stepsizeαk=max{βl∣l=0,1,2,…}such thatf(zk(αk))⩽f(zk)+σ∇f(zk)⊤(zk(αk)−zk),wherezk(α)=PZ(zk−α∇f(zk)). Setzk+1=zk(αk)and go to Step 1.The codes for the PGUN and PLM algorithms were written in Fortran 77 with double precision and the experiments were performed using gfortarn-4.6 on an Intel CORE I3-2310M@2.10 GigaHertz with 100 Gigabyte of HD and 4Gigabyte of Ram. Furthermore we used the ma48 routine of the Harwell Subroutine Library HSL (2013) for the solution of the linear systems required by the two algorithms.We considered the following stopping criteria:SC1:Stop with zkif∥g(zk,η)∥<10−5.Stop with zkwhen SC1 is satisfied and∥F(zk)∥<10−6.Stop at iteration k if∥F(zk)∥>10−3and∥F(zk−1)∥−∥F(zk)∥<10−4.PGUN stops if SC1 occurs at a projected gradient iteration. However, if SC1 takes place at a interior point Newton-like (IP) iteration we continue the execution with the hope of satisfying SC2. If, during this process, a projected gradient iteration is required, we stop with the diagnostic SC1.In some casesthe PGUN algorithm converges very slowly using projected-gradient (PG) iterations to a stationary point with a positive value of the merit function. In this case, PGUN is not converging to a solution of the HNCP and there is no reason to continue the execution of the algorithm. To avoid this occurrence, we decided to stop prematurely the algorithm by using the third stopping criterion. Moreover, when SC3 occurs the algorithm is restarted with a new initial point.PLM employs fast Levenberg–Marquardt (LM) and slow Projected-Gradient (PG) iterations and use the same stopping criteria SCi, i = 1, 2, 3, employed by PGUN with the LM iterations replacing the IP ones.We limited the number of iterations of both PGUN and PLM bymax{100,min{r+1,2n+m}3}and the CPU time by 600 seconds. The initial iterate for both methods was given by:(63)x0=e,y0=0,w0=ewhere e is a vector of ones. The following values for the algorithmic parameters of PGUN were used:αmin=10−8,β=0.25,cbig=104,csmall=10−10,ηk=η=1.0,γk=1k2,ρ=10−3,σk=σ=12n+m,τk=τ=0.9995andθ=0.5. For the PLM Method we utilized the default parameters of Kanzow et al. (2005):αmin=10−12,β=0.9,μ=10−5,σ=10−4,γ=0.99995,p=2.1andρ=10−8.We have made the experiments with both the algorithms on the solution of 48 MPCC test problems of the collection MacMPEC Leyffer (2000). These problems are presented in Table 1. In this table, m is the dimension of y, n is the dimension of x and w, p is the dimension of (φ(x, y, w), H(x, y, w))⊤, nz is the number of possible non zero elements of the Jacobian matrix, density is the density of the Jacobian matrix and min is the lower value known for the function.In orderto compute a simple feasible solution of the MPCC, we considered the HNCP of the form (3). Table 2 shows the number of complementary pairs for each problem. In this table, NCP represents the number of original complementary pairs and NNG is the number of complementary pairs after each nonnegative non-complementary variable xiis transformed into a pair of complementary variables (xi, wi) with wian auxiliary variable.Table 3 reports the performance of the PGUN algorithm for finding a simple feasible solution of the Mathematical Program with Complementarity Constraints (MPCC). In this table, we use the following notations:TERM: termination of the algorithm which can be one of the following:IP-1:algorithm stopped with an interior-point Newton-like (IP) iteration satisfying SC1.algorithm stopped with an IP iteration satisfying SC2.algorithm stopped with a projected-gradient (PG) iteration satisfying SC1.IP: number of interior-point Newton-like (IP) iterations.PG: number of projected-gradient (PG) iterations.CG: number of times that the algorithm changed from an IP to a PG iteration or conversely.NE: number of function evaluations.TIME: CPU time (in seconds), measured with the function etime. A time smaller than 1e-4 is considered as zero.∥F(z¯)∥: value of∥F(z¯)∥,wherez¯is the solution computed by the algorithm.SPG_norm: norm of the projected-gradient at the solution computed by the algorithm.Feas: feasibility measure, that is, Feas =∥h(z¯)∥.Comp: complementarity measure, that is, Comp =maxi=1,n{xiwi}.* The algorithm computed a feasible solution of MPCC with an initial point different from (63).** failure: The algorithm was not able to compute a feasible solution of MPCC after 10 trials with different starting points.We also note from the values of Feas and Comp that PGUN is usually able to compute accurate feasible solutions of the MPCC. Furthermore, the use of the stopping criterion SC2 was shown appropriate for such a goal. This is an interesting point as these accurate solutions can be used as initial points for projected and active-set algorithms (Fang et al., 2012; Fukushima & Tseng, 2002; Júdice et al., 2007; Ralph, 2007) that have been designed for the computation of stationary points of MPCC.In order to have a better idea of the performance of PGUN in practice, we also solved the test problems by the PLM algorithm. The results of the performance of this method are displayed in Table 4, where the notations mentioned before were used together with the following additional ones:TERM: algorithm termination, which can be one of the following:LM-1:algorithm stopped with a Levenberg–Marquardt (LM) iteration satisfying SC1.algorithm stopped with a LM iteration satisfying SC2.algorithm stopped with a projected gradient (PG) iteration satisfying SC1.LM: number of LM iterations (steps 2, 3 and 4).PG: number of PG iterations (step 5).Next, we report the experiments with PGUN and PLM for computing a target feasible solution (i.e., a solution of HNCP (5)) of the MPCC test problems mentioned before when the target value ctis the best value given by the collection. The definition of the test problems used in this experiment and the numerical results on the performance of the algorithms for these instances are displayed in Tables 5, 6 and 7, respectively. In these tables we used the notations mentioned before and the additional one:SLACK: represents the value of the slack variable associated to the target constraint. If SLACK is greater than a tolerance10−6,then the algorithm was able to compute a better feasible solution than the one given by the collection.The numerical results indicate the same type of performance shown before. However, there is an increase of failures of the algorithms when the objective function constraint is included in the HNCP associated to a target feasible solution. Furthermore PGUN and PLM always computed the feasible solution given by the collection (see values in the column SLACK). These conclusions confirm the conclusions in Fernandes et al. (2001) that computing a target feasible solution is usually more difficult than finding a simple feasible solution.

@&#CONCLUSIONS@&#
In this paper, we introduced a Projected-Gradient Underdetermined Newton-like (PGUN) algorithm for computing a feasible solution of a Mathematical Programming Problem with Complementarity Constraints (MPCC). The algorithm can also be applied for the computation of a feasible solution of MPCC that satisfies a certain objective function target. In both cases the algorithm searches a solution of an associated Horizontal Complementarity Problem (HNCP). It was shown that PGUN is globally convergent to a solution of HNCP or to a stationary point of an associated natural merit function. Fast local convergence was established under reasonable hypotheses. The PGUN algorithm seems to perform well for the computation of feasible solutions of an MPCC and seems to be more efficient than a Projected Levenberg–Marquardt (PLM) algorithm designed before for the same goal. The choice of the initial point for the PGUN and PLM algorithms seems to have an important impact on the efficiency of these algorithms. Future research will address the combination of PGUN with algorithms that require feasible initial points for solving MPCC in order to solve practical problems.