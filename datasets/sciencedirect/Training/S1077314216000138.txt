@&#MAIN-TITLE@&#
Improving posture classification accuracy for depth sensor-based human activity monitoring in smart environments

@&#HIGHLIGHTS@&#
A new posture classification framework for Kinect is proposed.Accuracy in classifying noisy postures is improved by considering the reliability of each joint.Reliability of a joint can be evaluated by the consistency in different aspects over time.Performance of classifier is improved by learning the weights of reliability terms.

@&#KEYPHRASES@&#
Smart environments,Monitoring systems,Posture classification,Max-margin classification,Depth camera,Reliability estimation,

@&#ABSTRACT@&#
Smart environments and monitoring systems are popular research areas nowadays due to its potential to enhance the quality of life. Applications such as human behavior analysis and workspace ergonomics monitoring are automated, thereby improving well-being of individuals with minimal running cost. The central problem of smart environments is to understand what the user is doing in order to provide the appropriate support. While it is difficult to obtain information of full body movement in the past, depth camera based motion sensing technology such as Kinect has made it possible to obtain 3D posture without complex setup. This has fused a large number of research projects to apply Kinect in smart environments. The common bottleneck of these researches is the high amount of errors in the detected joint positions, which would result in inaccurate analysis and false alarms. In this paper, we propose a framework that accurately classifies the nature of the 3D postures obtained by Kinect using a max-margin classifier. Different from previous work in the area, we integrate the information about the reliability of the tracked joints in order to enhance the accuracy and robustness of our framework. As a result, apart from general classifying activity of different movement context, our proposed method can classify the subtle differences between correctly performed and incorrectly performed movement in the same context. We demonstrate how our framework can be applied to evaluate the user’s posture and identify the postures that may result in musculoskeletal disorders. Such a system can be used in workplace such as offices and factories to reduce risk of injury. Experimental results have shown that our method consistently outperforms existing algorithms in both activity classification and posture healthiness classification. Due to the low cost and the easy deployment process of depth camera based motion sensors, our framework can be applied widely in home and office to facilitate smart environments.

@&#INTRODUCTION@&#
One of the main purposes of smart environments and monitoring systems is to enhance the quality of life. On one hand, by understanding the needs and intention of the user, smart systems can provide the appropriate support. On the other hand, by monitoring the movement behavior of the user, these systems can alert the user in dangerous situations, such as performing movement that would result in injury. In particular, according to the Health and Safety Executive Annual Statistics Report for Great Britain [1], more than 1.1 million cases of work-related ill health were reported between 2011 and 2012, in which more than 39% belongs to musculoskeletal disorders. A smart environment with an automatic posture monitoring system is a potential solution to save the high cost of workplace injury and ill health.One major challenge of a smart environment is to understand what the user is doing, in order to decide how to react properly to the user’s behavior. Motion capturing is a traditional method to obtain the user’s posture [2]. However, most of the existing techniques such as the optical motion capturing system require careful setup and calibration. These systems usually require the user to wear special devices on the body, making it difficult to be deployed and used in daily life environments. Alternatively, identifying human posture with traditional 2D video cameras can be performed using computer vision techniques [3]. However, because of the lack of details in the source video, as well as the 3D information of joints, only bigger limbs such as the body trunk and the legs can be identified and evaluated. This greatly reduces the accuracy especially for evaluating subtle posture differences.Recently, motion sensor with depth camera such as the Microsoft Kinect has shown its effectiveness in tracking 3D human posture in real-time [4]. Its advantage is that it can track 3D human posture without requiring the user to wear any special equipment. The low cost of the hardware camera, as well as the easy setup of the tracking system, also make it preferable to be used in daily indoor environment such as office and home. By processing the captured depth image, it becomes possible to identify depth-based edge extraction and ridge data, which are used to track human body parts [5]. However, unsupervised approaches require careful algorithm design and may not be easily generalized. To solve the problem, anatomical landmarks trained by sample data using random forests are used. The body skeleton is recognized by analyzing the depth silhouettes of the user and locating the anatomical landmarks [6]. However, run-time detection of such landmarks is not always accurate, which results in degrading the activity recognition accuracy. Similarly, utilizing the skeleton recognized by Kinect for action recognition suffer from the same problem, as the recognized joint can be different from the trained data due to occlusions, which results in noisy skeletons [7]. Previous motion analysis algorithms that assume a reliable input stream do not work well with Kinect, as the tracked joints returned by the depth camera could be wrong [8]. The main focus of this work is to propose new methods to account for the accuracy of the skeleton, such that activity recognition can be more accurate.We propose a new posture classification framework for Kinect, which has an improved accuracy over previous algorithms. To cope with the noisy input posture, we design a set of reliability measurement [9] to evaluate how reliable the tracked joints are. The more reliable joints then contribute more in a max-margin classification system, which is used to classify postures of different context. Our framework allows a smart environment to understand what the user is doing from the noisy data obtained by Kinect. Due to the improved accuracy, the system can even classify the subtle difference between healthily and unhealthily performed postures, such as operating equipment with postures that may lead to injury. This facilitates automatic posture monitoring for workplace, which can alert the user whenever an unhealthy posture is performed. Since our method is robust, affordable and easily deployable, it is a preferable solution for smart environments and monitoring systems.To facilitate further research in the field, the posture healthiness database created in this research will be made available to the public. Up to now, such a kind of database is not openly available. The comprehensive database consists of more than 8000 3D postures for different behaviors such as working at an office desk in sitting and standing postures, together with the source 3D depth images and color images obtained from the depth camera. It is also carefully annotated with information of the behavior, such as the nature of the movement and the potential health risks.There are three major contributions in this paper:•We propose a new framework to monitor and classify user postures. It evaluates the reliability of the observed joints from Kinect, and applying such reliability as weights in a customized max-margin classifier to robustly classify noisy posture data. Our system can accurately distinguish the subtle differences between healthy and unhealthy postures.We propose a set of new reliability measurement terms on top of those presented in [9] to enhance the accuracy of joint reliability estimation. Apart from the traditional kinematic-based reliability measurements, we make use of the color and depth images from Kinect to identify joint that are wrongly tracked or corrupted by noise.We implement the first open access motion database targeting at posture healthiness. The database includes correctly and incorrectly performed postures for different work purposes, annotated posture information, as well as depth and color images obtained from the depth camera.In the rest of this paper, we will first review the related work in Section 2. An overview of our proposed method will be given in Section 3. Next, we explain how to evaluate the reliability of each tracked joint by our proposed reliability measurements (Section 4). A max-margin classification framework which takes into account the reliability of each joint will be introduced in Section 5. We then explain how our motion database is constructed (Section 6) and present experimental results in Section 7. Finally, we conclude this paper in Section 8.

@&#CONCLUSIONS@&#
In this paper, we presented a data-driven framework that considers the reliability of the source data to classify postures captured from depth cameras. We propose new reliability terms to better evaluate the features, and present a customized max-margin classification framework that takes in the measurements. Our framework can classify the subtle different between healthy and unhealthy postures in a workplace environment. We made our motion database available to public usage in order to facilitate further research in this area.Since the postures captured by Kinect is incomplete and noisy due to occlusion, it is proposed to reconstruct the unreliable joints using prior knowledge [9]. A traditional method of posture classification is to evaluate the reconstructed posture. However, since the reconstruction process involve modifying unreliable features, it introduces another major source of error. We opt for a max-margin classification framework, which evaluates posture considering joints with high reliability more, and do not require altering the posture.As a common problem of data-driven approaches, if there is no posture similar to the observed one in the database, our method may fail. This is because we do not have the knowledge to accurately classify the posture. This could happen if the user has a significant different body size or segment length proportion. In the future, we would like to explore motion retargeting techniques to retarget the observed posture.Apart from unhealthy postures, moving rapidly or keeping the body static for extensive long duration can also result in injury. To identify these kind of movements, the spatio-temporal information of the motion has to be considered. In order to efficiently classify long duration of movement, abstraction in the temporal domain may also be needed. We are interested to explore this area in the future to broaden the scope of our classification algorithm.This research demonstrates how our framework can be applied in smart environments to identify incorrectly performed working posture. There are other motions, such as wheelchair handing, floor sweeping and window cleaning, that have a high risk of injury. As a future work, we wish to enhance the database to include a wide variety of motions. Apart from capturing data ourselves, we would like to set up a standard format for capturing different types of motion in the topic of workspace health and safety, such that interested researchers can contribute and share captured motions.