@&#MAIN-TITLE@&#
Evaluating and understanding text-based stock price prediction models

@&#HIGHLIGHTS@&#
Several state-of-the-art stock prediction models are constructed.Different metrics for evaluating prediction models are discussed.Explanatory techniques are applied to gain insights into the model’s decisions.

@&#KEYPHRASES@&#
Stock,Prediction,Support Vector Machine,Sentiment mining,Evaluation,

@&#ABSTRACT@&#
Despite the fact that both the Efficient Market Hypothesis and Random Walk Theory postulate that it is impossible to predict future stock prices based on currently available information, recent advances in empirical research have been proving the opposite by achieving what seems to be better than random prediction performance. We discuss some of the (dis)advantages of the most widely used performance metrics and conclude that is difficult to assess the external validity of performance using some of these measures. Moreover, there remain many questions as to the real-world applicability of these empirical models. In the first part of this study we design novel stock price prediction models, based on state-of-the-art text-mining techniques to assert whether we can predict the movement of stock prices more accurately by including indicators of irrationality. Along with this, we discuss which metrics are most appropriate for which scenarios in order to evaluate the models. Finally, we discuss how to gain insight into text-mining-based stock price prediction models in order to evaluate, validate and refine the models.

@&#INTRODUCTION@&#
Is there a way to outperform other investors on the markets? It is a question that has attracted the attention of many a trader since the advent of stock markets in Europe during the late Middle Ages. With the emergence of companies, financial institutions, financial products and government-imposed regulations on these products, the nature of stock markets has changed substantially since those days. Nevertheless, stock price prediction remains an attractive topic for both researchers and investors.1Querying Google for “stock prediction” reveals over 1.9million results, including 1360 scientific publications.1During the past decades different theories have been developed to motivate why stock price prediction is not feasible under the assumption of rational actors in a market.The efficiënt market hypothesis was first introduced by Fama (1965) and posits that the financial markets are informationally efficient. This implies that one cannot design a system to predict the change in stock price based on any information because all information is already reflected in the current stock price. Similarly, Malkiel (1985) argues that the stock market prices of assets evolve in a pattern comparable to that of a Random Walk (hence its name Random Walk Theory). The implication is that stock prices cannot be predicted better than a “blindfolded chimpanzee throwing darts” at a numerical scale board.The contributions of this publication are twofold. First, we build empirical models to try to counter-act the validity of the previously mentioned theories, based on the fact that humans do not always act rationally. In order to do so, we combine text-mining techniques in a novel hybrid modelling technique. Second, we discuss the difficulties in evaluating such a model as a decision making tool. We discuss how using many different evaluation metrics can remedy this situation and we show how the model can be used as a decision support tool without the aforementioned drawbacks.A selection of recent empirical research is shown in Table 1, together with the main design choices in these studies. As can be seen from the table, most of the models predicted classes of movement (e.g. up/down) instead of the actual values. Although traditionally most research has centred on various short- and long-term technical performance indicators of a stock (e.g., Lavrenko, Schmill, Lawrie, & Ogilvie (2000)), more recent research has focused on building models based on textual information to perform directional predictions of stock movement (e.g., Schumaker & Chen (2009b); Mittermayer (2006)). The behavior explained by both theories mentioned in the Introduction is based on the assumption that investors act rationally. One way to counter them is to counter the assumption of rationality of the trader. Irrational behavior could for example occur as a reaction to news in the popular written media, i.e. information that comes in the format of text. Since there is a lag between the appearance of an article text and the trading action of the reader, automatic trading systems could outperfom human reaction in a high-frequency trading environment.Text mining concerns the process of automatically extracting novel, non-trivial information from unstructured text documents (Fayyad, Piatetsky-Shapiro, & Smyth, 1996), by combining techniques from data mining, machine learning, natural language processing (NLP), information retrieval (IR) and knowledge management (Mihalcea et al., 2007). Common text mining tasks involve document classification, summarization, clustering of similar documents, concept extraction and sentiment analysis. Text mining has had a wide range of applications to date. Prevalent applications include: forecasting petitions (Suh, Park, & Jeon, 2010), guiding financial investments (Rada, 2008) and sentiment detection (Tang, Tan, & Cheng, 2009; Junqué de Fortuny, De Smedt, Martens, & Daelemans, 2012).In our setup we look for patterns in the occurrence of words (the so called bag-of-words-approach) or the sentiment of the message that have an influence on the stock market price of a commodity. In related work, typically only the direction (rise/fall) of the stock movement is predicted and the patterns come in the form of a linear model, in which each word of a certain vocabulary receives a weight towards the stock price either going up or down. The weighted sum of the word scores of all words in the article is then used in the prediction of a new article. Reported results on independent test sets in terms of accuracy have been in the order of a 10% increase when compared to random predictions (Mittermayer, 2006). We will explore the specifics of text mining for stock price prediction in Section 4 when we discuss the construction of the empirical models.Amongst others, Li, Wang, Dong, and Wang (2011) and Schumaker and Chen (2009b) remark that using only textual information can be too limiting because the approach disregards other (complementary) information. Imagine that a negative news article concerning a certain asset is published during an upward trend of the asset’s price. This article might influence the positive trend in a negative way by reducing the slope of that trend, yet the overall trend for the asset can stay upward (see Fig. 1). In this case a negative directional prediction would be wrong, although the impact of the message itself was negative. This behavior can be remedied by analysing proxies for the trend of the stock price and incorporating these in the prediction model. Typically, one or more technical indicators are included. In this study we take a similar but novel approach. We analyze three main factors: a series of technical indicators, a bag-of-words score and the sentiment of a news message (which can induce a bias of the investors).No clear comparison of the above methods exists, yet each of the authors in Table 1 reports better than random accuracy. We hypothesize that a combination of all of the previous modelling approaches in one hybrid model that contains technical information, text-pattern information and sentiment information should be able to reach even better performance. Our first research question is thus:Research Question 1Can we predict the movement of stock market prices more accurately by including indicators of irrationality next to the traditional trade model features?As can be seen in Table 1, prior research has used a range of metrics, with accuracy being the most widely used. We question whether this is actually a good measure based on our own results. This leads us to the second research question:Research Question 2Which metrics are most appropriate for assessing model performance in the context of stock prediction?Furthermore, we noticed that many of the models built in the literature use complex modelling techniques that result in ‘black-box’ models. From the perspective of a trader using the trading tool, however, it is imperative that she can gain insight into these models to assess whether the decision is correct or not.Research Question 3How can we gain insight into text-mining-based stock-prediction models?We have encountered a variety of evaluation metrics, with most studies basing their conclusions solely on one or two metrics (e.g., accuracy). Unfortunately, most of these metrics do not give an accurate representation of the usefulness of the trading model. We argue that one can only gain insights into the validity of a previously constructed model by combining various additional evaluation methods. In this section we consider some of the more frequently used evaluation metrics and their main advantages and drawbacks.Accuracy measures the percentage of correct predictions out of the total amount of predictions made. More than half of the previous studies we encountered used accuracy to evaluate their models. The problem with using accuracy as a performance measure is that it is difficult to assert whether the built models are valid, due to the fact that the data in the test set is generally not uniformly distributed. For example, consider a trading model that always predicts class 1 (upward price movement). If the target label distribution were skewed so as to contain 70% positive examples (class 1) and 30% negative examples (class 2), the resulting accuracy would be 70%. This is a good result at face value, whereas in reality the model has no predictive power for downward price movement. The accuracy measure implicitly uses a fixed cut-off value (zero) on the output scores of a prediction model to predict whether the output label should be positive or negative. This limitation can also be seen as a limitation on the trading strategy since changing the cutoff value leads to different levels of conservativeness in trading, as such we are only evaluating one possible choice when using accuracy. Many other similar measures that operate on the rows of the confusion matrix, suffer from similar problems (including precision, lift and F scores).2For a full discussion, we refer the reader to Fawcett (2006).2Area Under the Receiver Operating Characteristic Curve (AUC, Fawcett (2006)) is a metric that allows easy evaluation of the discriminative power of a model by measuring the performance of the classification model over the complete range of possible cut-off values. It is a proxy for the probability that the model will classify a randomly chosen positive instance higher than a randomly chosen negative one and as such it is related to the Gini coefficient (Breiman, Friedman, Stone, & Olshen, 1984), i.e.Gini=2·AUC-1. The AUC is a generally accepted performance metric to assess the predictive performance of classification models with respect to ranking in data mining. One of the key advantages of using AUC is its ability to cope with skewed distributions of target label data. Furthermore, it allows for easy comparison with random predictions (i.e., the Random Walk Hypothesis), since a random classifier should result in a AUC value of 50%. Even so, none of the studies we encountered in the literature used this metric.AUC is a useful metric for measuring model discrimination power. Even so, just like accuracy, it proves to be less useful in evaluating the real world operational value of a classifier since it makes assumptions about the data that might not be portable to a real setting. These dynamically changing costs are not easily captured in an aggregate measure. Alternative measures exist that simulate how the model would be used in a real world setting. We will discuss both a proxy for the profit of the trading simulation and the Sharpe ratio.In our set-up, the only rule is to buy at time t when the model predicts the price is likely to go up within some time frame defined by the lagt+l. We sell the stock again at timet+l. Given this simple trading strategy, our final revenues and Sharpe ratio can then be evaluated on a test set, simulating a real-life trading scenario.Profit. Almost every study we found included some form of profit measurement. Some simulate the trading model with a fixed budget (e.g.,$50.000) and then report the net profit from a chosen trading strategy. In this set-up, the trading cost is usually assumed to be zero. The problem with this kind of trading assessment is that it is very hard to compare the results to other publications, since many hard-to-distinguish factors can determine the outcome (e.g., starting budget and test set size). A better way to evaluate profit is to use a representation of (excess) return rate. In this study we use the average of the (arithmetic) Rate of Return (ROR) of each trading decision, defined as:(1)ROR=pt+l-ptpt,wherept+lis the selling price of the commodity andptthe initial buying price.The average ROR is not without flaws either: particularly it does not take into account the actual risk undertaken by trading upon the built system. In support of the Random Walk Theory, Malkiel (2005) argues that professional investment managers have not been able to consistently outperform their index benchmarks. More specifically, he states that “no arbitrage opportunities exist that would allow investors to achieve above-average returns without accepting above-average risk”. We should therefore test our models in a trading simulation using a risk-weighted evaluation metric, discussed next.Sharpe ratio. In finance, risk is often defined in terms of variance of yields (note that this notion of risk is only reasonable under the assumption of an underlying normal distribution). A naturally occurring metric that captures both of these ideas is the Sharpe ratioS(x):(2)S(x)=rx-Rxσx,where x is the investment for the relevant quote symbol,Rxis the risk-free rate of return (a theoretical construct, estimated using real-valued bonds or currency values),rxis the average return of x using our trading strategy,σxthe standard deviation of the average return of x. Ideally, we want to generate a value at least higher than zero (profit).In order to properly evaluate the prediction performance of a model, no training information can be used in the evaluation. Usually a hold-out set is kept aside for evaluation purposes. In time series prediction, an additional concern is that we cannot use any future information in the training phase of a model, this is usually referred to as out-of-time. An example that violates both of these principles has received considerable media attention recently. In a publication by Bollen, Mao, and Zeng (2011), a stock prediction model was built, based on Twitter mood prediction. Even though their study has been criticized for containing methodological and representational flaws,3See http://sellthenews.tumblr.com for a full analysis.3a $40million hedge fund was started based on the technique, receiving a nomination for the 9th annual Awards for Excellence in Trading and Technology Europe 2011 for the most innovative trading Firm.4http://www.derwentcapitalmarkets.com/.4The main set-up of the training and testing of our stock prediction model is displayed in Fig. 2. In a first phase both stock tick data and stock news data are gathered and processed to two types of features: technical indicators and text-related features. These are given as input to a Support Vector Machine (SVM) learner after which an “optimal” model is generated. In order to evaluate the model, its output scores are converted by a score-to-label mapping and compared to the future quote price evolution. In the next sections we will briefly discuss each of these components.We chose the Support Vector Machine as the main driver for model generation since it is well established to be successful for text mining (Cohen & Hersh, 2005; Tang et al., 2009) and more specifically for stock prediction (as can be seen from Table 1). The SVM is a learning procedure based on the statistical learning theory (Vapnik, 1995). Given a training set of m-dimensional input vectorsx={x1,…,xm}and corresponding binary class labelsyi∈{-1,+1}, the SVM classifier constructs a hyperplane in a feature space, induced by the non-linear functionφ. According to Vapnik’s original formulation, the classifier should satisfy the following conditions:wTφ(xi)+b⩾+1,ifyi=+1wTφ(xi)+b⩽-1,ifyi=-1which is equivalent to (for a dataset of size n)(3)yiwTφ(xi)+b⩾1,i=1,…,n.The non-linear functionφ(·)maps the input space to a high (possibly infinite) dimensional feature space. In this feature space, the above inequalities construct a hyperplanewTφ(x)+b=0, that discriminates between the two classes. By minimizingwTw, the margin between both classes is maximized.In primal weight space the classifier takes the formy(x)=signwTφ(x)+b,however, it is never evaluated in this form. The exact details of the dual form of SVMs are beyond the scope of this report, but in summary, the problem is recast to an optimization problem that is solved using Lagrange multipliers, leading to the following classifier:(4)y(x)=sign∑i=1NαiyiK(xi,x)+b,whereK(xi,x)=φ(xi)Tφ(x)is a positive definite kernel satisfying the Mercer theorem conditions. No explicit construction of the nonlinear mappingφ(x)is needed, we only need to choose a kernel function K. For the kernel functionK(·,·), one typically has the following choices:K(x,xi)=xiTx(linear kernel)K(x,xi)=1+xiTxcd(polynomial kernel)K(x,xi)=e-‖x-xi‖22σ2(RBF kernel)whered,c,σandθare constants. Throughout this study we will be using a linear kernel due to the high dimensionality of the data and speed considerations.The corpus used in this study comprises all articles published in on-line versions of all major Flemish newspapers in 2007 until March 2012. This leads to a corpus of over 671.751 articles, each of them timestamped on a minute level granularity. An overview of all of the newspapers included in this study is displayed in Table 2.All articles were gathered using a custom built web-crawler. The crawler extracts articles from the sources’ websites using their built-in search functionalities (after obtaining the permission to do so). The crawling process is the equivalent of a typical database selection process in which relevant data are selected using the given query criteria. In this case, the query keywords were the names of the organization behind the stock symbols. An overview of all stock symbols and their search query keywords (“search keys”) is displayed in Table 3.After the filtering process, the scope of the textual data is reduced to include only that part of the article that is relevant to the stock symbol. The following cases are considered:1.Include only the headline.Use all textual data of the article.Use only textual data in the same paragraph as the first occurrence of the key word: the paragraph is defined as one sentence before, the containing sentence and one sentence after the relevant sentence.The rationale behind the third approach is that an article can contain many stock symbol names at the same time or switch tone. For each of these cases we consider both the textual input, as well as the sentiment polarity score after sentiment analysis.In a first step, every article in the corpus has to be lemmatized in order to reduce all of the words in the corpus to their canonical form. Afterwards, all known stop-words are deleted from the corpus. Applying these two steps lowers variability of concept expression in the corpus and allows the learner to focus on content words.Given the clean corpus D, we build a dictionary containing all of the m words contained in the corpus. With this dictionary, each of the individual documents d can now be represented as a bag-of-words vector[w1w2…wm]. Aggregating all of these row-vectors, leads to a high-dimensional and very sparse matrix in which each elementwi,jcontains the amount of occurrences of word i in document j. In order to be able to compare documents of different lengths each row (document) of this matrix is normalized on the total amount of words, leading to a matrix with term-frequencies (tf). This matrix is then rescaled by the inverse document frequency (idf), leading to the input matrixtfidf:(5)tfidf(t,d,D)=tf(t,d)×idf(t,D)(6)idf(t,d,D)=log|D|1+|{d∈D|t∈d}|,where|D|is the cardinality for the set of documents D. This helps to prevent commonly occurring words to dominate the learning procedure, since these do not contain discriminatory information. Empirical research has shown this approach to be a valuable transformation (consult Sebastiani (2002) for more information). Note that this scaling is of course based on information from the training set only. Each row in the resulting matrix represents one of the input vectorsxithat are given as input to the SVM.For sentiment analysis, we used the previously created Pattern module for Python (De Smedt & Daelemans, 2012a). The module contains a suite of tools for web mining and text mining, including a subjectivity lexicon of over 3000 Dutch adjectives that occur frequently in product reviews, manually annotated with scores for polarity (positive or negative between +1.0 and −1.0) and subjectivity (objective or subjective between +0.0 and +1.0). For example: ‘boeiend’ (fascinating) has a positive polarity of +0.9 and ‘belabberd’ (lousy) has a negative polarity of −0.6. A similar approach with one axis for polarity and one for subjectivity is used by Esuli and Sebastiani (2006) for English words. The Pattern module includes an algorithm that further refines the score for each adjective by looking at preceding adverbs (e.g., extremely fascinating), preceding negation words (e.g., not fascinating) and subsequent exclamation marks.In previous research, the lexicon was tested with a set of 2000 Dutch online book reviews. Each review also has a user-given star rating. The test set was evenly distributed over negative opinion (star rating 1 and 2) and positive opinion (star rating 4 and 5). The average score of adjectives in each review was then compared to the original star rating, with a precision of72%and a recall of82%(De Smedt & Daelemans, 2012b).In our approach, we calculate the polarity of each adjective that occurs in the input text. The aforementioned third method discussed in Section 2.1.1, that is, using only textual data in the same paragraph as the first occurrence of the key word, is expected to yield a more reliable correlation between the entity being mentioned (the ‘target’ of the sentiment) and the adjective’s polarity score, contrary to measuring all adjectives in the article. A similar approach for target identification with a 10-word window is used by Balahur et al. (2010). They report improved accuracy when compared to measuring all words in the article. This results in a set of 274,014 assessments, where one assessment corresponds to the sentiment score linked to a stock symbol at a particular time. For example, the following assessment (translated from Dutch to English) scores −0.17:“Belgium’s largest electricity producer threatens to suspend investments if the nuclear tax is raised. ‘If the Belgian State would not honor its commitments, GDF Suez would be forced to revise its policy in terms of investment, employment, education and patronage entirely.’ GDF Suez-Electrabel, by far the largest electricity producer in Belgium, fires a booming shot across the bow of the federal governement negotiators.”We considered four popular technical indicators in our approach, all of which are based on a series of price ticksP={p1,p2,…,pn}leading up to the last known pricepn(Bodie, Kane, & Marcus, 2008). The length of the series was chosen to ben=5ticks, which for the one-day-ahead setting corresponds to a period of a week. For the minutes-ahead setting, we kept the amount of ticks, but sampled at higher frequency as well (30minand5min). The exact values of these windows do not matter, but it is important that the technical indicators should catch the trends on the same level of granularity as the prediction window size.Relative Strength Index (RSI) is an indicator of the historical strength or weakness of a stock over a series of price ticks P is defined as:(7)RSI(P)=100-1001+RS(P)(8)RS(P)=average gainaverage lossAccording to Wilder (1978), the creator of this technical indicator, a stock price should be considered overbought when the price moves up very rapidly (RSI>70). Likewise, when the price falls very rapidly (typicallyRSI<30) it should be considered oversold.Williams %R is an oscillator index relating the current pricepnto the highest and lowest price of the series P.(9)R(P)=pn-minpi∈Ppimaxpi∈Ppi-minpi∈Ppi,Psychological Line (PSY) is the technical variant of a sentiment indication and is defined as the percentage of the number of rising periods over the total number of periods considered in the series P:(10)PSY(P)=100×|{pi|pi∈P∧pi>pi-1}||P|.The Bias indicator assesses the behavior of the market in the given period P as “bullish”, “bearish” or neutral. Once identified, a trading strategy is recommended to counter-act the market. We did not explicitly code this behavior in our trading strategy, but include it in the features since its information is relevant to the movement of the stock. The bias is defined as:(11)BIAS(P)=100×pn-m(P)m(P)(12)m(P)=1|P|∑pi∈PpiCombining Eqs. (7)–(12) for each document based on the document’s appearance time leads to a final input vectorxithat can be given as an input to the SVM.We have gathered two datasets containing quote data for all of the stock symbols in Table 3 on the Euronext Brussels Stock Exchange. The first dataset contains quote ticker data on a low-granularity level (per-day) over a period of three years, from January 1, 2007 to March 25, 2012. On a high-granularity level (per-minute), we have gathered tick data for the same stock symbols for a period of four months from January 1, 2012 up to March 5, 2012.In order to simplify the learning system, the problem is reduced to that of predicting a subset of possible stock movements, aggregated in classes (e.g., increase (+), stable (±), decrease (−), see Table 1). We chose binary classification (up/down movement) or the directionality of the movement of a stock quote as opposed to predicting the true value. The target prediction labels are based on the relative movementΔrof the stock quote as compared to the last-known quote tick data. The relative movement of a quote is defined as:(13)Δr=Q1-Q0Q1In our two-class setting, we defined a class for a positive inclination (i.e.,Δr⩾0) and one for a negative inclination (Δr<0).For the one-day-ahead setting, the labels are based on opening and closing quotes. For the minutes-ahead setting, we experimented with different time windows after the appearance of an article (on a logarithmic scale, with a lag l ranging from20to26min). This time window was chosen in accordance with results from previous empirical experiments from the literature (Table 1). Note that there is no high-granularity level information available outside of office hours of the stock exchange, thus any data gathered during this period was dropped from the dataset (Fig. 3). Previous studies have tried interpolating the values, but we argue that this is a very rough approximation at best when working on a minute granularity level.

@&#CONCLUSIONS@&#
