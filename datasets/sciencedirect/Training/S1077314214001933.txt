@&#MAIN-TITLE@&#
Analysis-by-synthesis: Pedestrian tracking with crowd simulation models in a multi-camera video network

@&#HIGHLIGHTS@&#
Integrate crowd simulators to a multi-camera tracking system and improves the performance.Compared two simulators. The one with a more realistic simulation strategy has better results.The experiments are conducted on a very challenging dataset for crowds with multiple views.

@&#KEYPHRASES@&#
Pedestrian tracking,Multi-camera systems,Crowd simulation,

@&#ABSTRACT@&#
For tracking systems consisting of multiple cameras with overlapping field-of-views, homography-based approaches are widely adopted to significantly reduce occlusions among pedestrians by sharing information among multiple views. However, in these approaches, the usage of information under real-world coordinates is only at a preliminary level. Therefore, in this paper, a multi-camera tracking system with integrated crowd simulation is proposed in order to explore the possibility to make homography information more helpful. Two crowd simulators with different simulation strategies are used to investigate the influence of the simulation strategy on the final tracking performance. The performance is evaluated by multiple object tracking precision and accuracy (MOTP and MOTA) metrics, for all the camera views and the results obtained under real-world coordinates. The experimental results demonstrate that crowd simulators boost the tracking performance significantly, especially for crowded scenes with higher density. In addition, a more realistic simulation strategy helps to further improve the overall tracking result.

@&#INTRODUCTION@&#
Tracking pedestrians has been an active research topic in computer vision. Although many sophisticated techniques have been proposed, it is still a challenging problem that requires further advances to track people in a camera network in real-world applications. There are many reasons that make tracking a difficult problem. For example, the illumination conditions are changing continuously; the appearances for a single pedestrian are not the same from different perspectives; the amount of occlusions among pedestrians is significant when people form a crowd; and moreover, the human behaviors are sometimes unpredictable. To overcome these problems, researchers have proposed different approaches, among which are the approaches that aim to use multiple overlapping cameras [1]. By fusing information from cameras with overlapped field-of-views, the tracking accuracy could be improved due to the reduction of the influence from occlusion, the separation of crowded people from one another in large foreground blobs, etc. [2,3].In this paper, we are focused on the setting where several cameras with overlapped field-of-views are used to track pedestrians [4,5]. To take advantage of this setting, many approaches make use of homography-related methods [3,6,7], which are able to model the relationship among different views in order to estimate the actual position of each pedestrian in the real-world ground plane. These methods are efficient since the only extra information that we need to know is the set of camera parameters and the calculation of the perspective transformation is computationally light.However, in almost all the current trackers that use multiple cameras, the estimated real-world positions for pedestrians are only used in data association across cameras, while their relationships with one another are somehow ignored. In fact, the real-world positions of pedestrians are capable of providing more constraints and predictions, which can be quite helpful in addition to a traditional frame-based tracking approach. From this perspective, crowd simulation is a good example of methods that integrate extra information brought by the real-world positions of pedestrians. In the area of computer graphics, crowd simulation is a very popular topic, with various applications such as designing emergency evacuation routes and introducing special effects in movies. It is used for simulating the behavior of either every individual or the whole group under certain constraints (e.g., to avoid collisions). Nowadays, one of the most popular crowd simulation approaches is mainly focused on simulating walking trajectories (direction and velocity) of each individual given the starting and ending locations. As in a multi-camera system, the direction and velocity information for each pedestrian can be acquired based on the estimated real-world positions at each frame, integrating crowd simulation algorithms with image analysis will be useful for accurate tracking.In this paper, we propose an approach to improve the performance of a multi-camera tracking system by combining vision-based tracking results with the output from a crowd simulation under the real-world coordinates. The system diagram of the proposed approach is illustrated in Fig. 1. In addition to the frame trackers for different cameras which are independent from each other, a crowd simulator runs separately and provides predictions for all the views by projecting the real-world positions back to frame positions. This is a further extension of using the location and velocity information of pedestrians in a tracking system. The frame trackers for each view are designed based on the recent tracking-by-detection approach [8]. Compared to our previous work [9], the manner in which we integrate the information from crowd simulation is different. In addition, the crowd simulator in the proposed approach has two candidates: the RVO2 library [10] and the Social Behavior Model (SBM) [11,12]. Their simulation strategies are different, which may lead to different overall tracking performance. Therefore, besides the utilization of crowd simulation approaches to provide extra predictions for traditional vision-based tracking, a second purpose of this paper is to investigate whether the theoretically better simulation could be more valuable when integrated to the tracking system.The rest of the paper is organized as follows. Section 2 gives a brief description of related work, including vision based tracking approaches (those use frame information only) and crowd simulation methods, as well as the contributions of this paper. Section 3 presents our proposed approach in detail. Section 4 gives the experimental results and provides a discussion on experiments. Finally Section 5 concludes the paper.Most of the state-of-the-art tracking approaches belong to the category called tracking-by-classification or tracking-by-detection. They usually work in an online manner, e.g., the Online Ada-Boosting [13], Semi-Boosting [14] tracker and Online Multiple Instance Learning [15] tracker. The general idea for this category of trackers is to train a classifier based on the object’s appearance features extracted from the initial patch (Region-of-Interest, ROI) on the first frame or the first several frames. Later at each time step, based on the evaluation from this classifier, a patch that maximizes the likelihood in the search window is located, and is further used to update the classifier itself. By repeating these steps, the classifier has the capability to adapt itself to the most recent tracking environment when video continues, as well as maintain a good performance on distinguishing target objects from the surroundings. However, such an evolving classifier may slowly drift and becomes off-target finally. Therefore, some tracking-by-detection approaches perform tracking purely based on detection results from a human detector, which are obtained independently from frame to frame [16–19]. There are also tracking approaches that integrate both evolving classifiers and human detectors [8,20]. Since a human detector is generally more confident, and works independently from the tracker, the input from a human detector is an effective way to initialize the classifier and/or provide the “ground-truth” to correct a drifted tracker. In the proposed approach, the pedestrian tracking method used is based on [8], which is composed of a particle filter, a human detector and an online boosting classifier. This approach is mainly based on particle filtering, while the human detector and online boosting classifier are used to adjust weights for the particles. In addition to the good performance shown in [8], another advantage of this approach is that the crowd simulation can be easily integrated into the system as the extra simulation information can be treated as an additional factor that influences particle weights.As the ability for tracking in a single-camera is often limited, more cameras are added into a surveillance system to solve the problem, which is known as multi-camera tracking. Basically, there are three settings that a multi-camera tracking system can employ: overlapping cameras [2–5,21], non-overlapping cameras [22,23], and the mixture of them [24]. Related to our research focus in this paper, the main challenge of a single-camera tracking system is the presence of occlusion in a crowded scene, therefore, we use an overlapped multi-camera system which can significantly relieve the problem. But as the number of cameras in a system becomes larger, the complexity of the system also increases and many other problems occur. For example, the data correspondence among cameras is one of the most important but not yet perfectly solved problem. There are many different methods reported for the solution of this problem, which can be generally divided into three categories: region-based approaches, point-based approaches, and principal axis-based ones [2,21]. However in this paper, data correspondence is not our focus, so we associate data from different cameras manually to avoid potential errors. We use the principal axis-based intersection method to calculate the position of each pedestrian on the ground plane.The purpose of crowd simulation is to model human behaviors, particularly human walking, and to compare the output from these models to scenarios in real life. It can be considered as opposite to tracking [25]. Due to the uncertainty of human behaviors, many approaches have been proposed that try to model the problem from different perspectives. For example, the social force model is inspired by physics and social-psychology and has been successfully used in many applications such as evacuation simulation [26,27], with many further variants such as the Social Behavior Model [11,12]; the RVO2 (Reciprocal Velocity Obstacles) library assumes that all the pedestrians take the same collision avoidance strategy which leads to the global optimal solution and uses linear programming to have an efficient solution [10]; the rule-based approach provides simple but effective collision avoidance, which is only based on local information “observed” by a pedestrian in the crowd [28]; the continuum dynamics model treats the crowd at a macroscopic level, thus, it is highly efficient in simulating crowd behaviors at an extremely large and dense scale [29].In most cases, crowd simulation approaches are point (individual) based. For example, the social force model (Social Behavior Model) considers each pedestrian in the crowd as a particle and the rules (e.g., collision avoidance) as forces added to the particle. Then the whole crowd simulation problem is transformed to a particle system, which is solved mathematically. In our previous work [9], the RVO2 library [10] is integrated as the crowd simulator. But in this paper, another simulator, Social Behavior Model [11] is combined to the tracking system as well.The common advantages of these two crowd simulators (RVO2 library and Social Behavior Model) are: (1) They only require basic information for each pedestrian, such as position, velocity, and the desired velocity, which is quite easy to obtain; (2) The calculation for both models is relatively efficient. However, there are several essential differences between them: (a) Their collision avoidance strategies follow different ideas, which is similar to the different solutions in Prisoner’s Dilemma in the game theory [30]. The RVO2 library uses a strategy which could result in a global optimal solution, and the Social Behavior Model adopts a much safer strategy but in most cases it is not the best from a holistic perspective. (b) The RVO2 library sets a safe time for each pedestrian, within which the pedestrian is absolutely safe from any kind of collision, but in the Social Behavior Model, the safety of a pedestrian is decided by the “forces” on him/her, which is elastic to a certain extent and not guaranteed. (c) When one pedestrian tries to prevent collisions with others, the RVO2 library treats all the other pedestrians within his/her observation range equally weighted, but the Social Behavior Model puts lower weights for pedestrians farther away from the focus of his/her field-of-view. In conclusion, the RVO2 library simulates pedestrians in a more robotic way, while the Social Behavior Model provides a simulation strategy more similar to human nature in real life.As compared to state-of-the-art tracking systems, the contributions of the paper are:1.It integrates a crowd simulator with a tracker for the better usage of the pedestrian information under real-world coordinates. At each time step, the simulator generates a set of possible locations for all pedestrians, according to their previous positions, velocities, and the estimated desired velocities. When this additional information is combined with a video frame for a pedestrian, it serves as a better prediction for this pedestrian’s location so as to improve the tracking performance.Two crowd simulators are adopted and their influences on the tracking performance are investigated through extensive experiments. The two crowd simulators include the RVO2 library [9,10] and the Social Behavior Model (SBM) [11,12], where the Social Behavior Model follows a more realistic strategy for collision avoidance. The experiments are conducted on different sequences from a challenging multi-camera dataset, with different crowd densities.We introduce a new framework to integrate the information from crowd simulation that is different from out previous work [9]. It discards the sampling step in our previous work when we calculate the contribution from simulation results to particle weights. In this manner, the particle weights in the frame trackers are evaluated without loss of any information. This new framework allows the system to outperform our previous tracking system in [9].As shown in Fig. 1, the proposed system consists of three components: (1) a crowd simulator (RVO2 library or Social Behavior Model) working on the ground plane to provide predictions for the positions of each pedestrian; (2) a frame tracker based on the state-of-the-art tracking-by-detection, which is able to track pedestrians based on the visual information, corresponding to each pedestrian in each camera view; and (3) a global tracker that interacts between the frame trackers working for different camera views and the crowd simulator working on the ground plane, as well as maintains the pedestrian information on the ground plane. In the following, we first describe the details of the existing tracking-by-detection and crowd simulation approaches used in our system, and then propose our advancements that integrate them together.Table 1summarizes the important notations used in the following description. Note that in this section, the subscript and superscript (e.g., the i and t indicating particle index and time step inwit) are explicitly expressed only when necessary.This section is mainly focused on the description for the current analysis and synthesis approaches, i.e., the tracking-by-detection and crowd simulation approaches that serve as foundations of the proposed approach.The frame tracker in this approach is a tracking-by-detection method that combines a particle filter, a boosting classifier, and a human detector [8]. The main components that are used in our system are described below. For readers who are interested in further details, please refer to [8].Each frame tracker corresponds to one pedestrian, and is constructed mainly based on a bootstrap filter, withNpparticles. For each particle, the statex={x,y,u,v}is maintained by position(x,y)and velocity(u,v). This particle filter adopts a simple constant velocity motion model(1)(x,y)t=(x,y)t-1+(u,v)t-1+ε(x,y)(2)(u,v)t=(u,v)t-1+ε(u,v)whereε(x,y)andε(u,v)are two zero-mean normal distributions as noise terms. The variancesσ(x,y)2andσ(u,v)2for these two noise functions are initially set proportional to the size of the tracking patch, and then gradually decrease as the number of successfully tracked frames increases. At every time step t, importance resampling is carried out which makes the particle weightswit-1=1/N, sowitonly depends on the observation from the current frame, which can be calculated based on the observation model(3)wtr,p=βI(tr)Np-do∗+γdc(p)P0(tr)+ηctr(p)For each particle p in the tracker tr, the first term in Eq. (3) contributes the zero mean normal estimation based on the distance between the particle and the associated detectiondo∗if there is one. The second term is the confidence value, which is obtained at the particle position(x,y)from the confidence mapdc. The third term is the classifier evaluation result for the patch located at p. After the weight for each particle is calculated, the weights for all particles are normalized so that they sum to 1.The human detector provides detection output and confidence to the first and second terms in Eq. (3), respectively. For detection results, since they are usually calculated with high confidence, we will try to associate each of them to a frame tracker, which is represented as the indicator functionI(tr)in the equation. For a tracker tr, the indicator function is equal to 1 if this tracker is associated to a detected patch and is set to 0 otherwise. These associations are determined based on the pair-wise matching scores between frame trackers and detections using the following equation(4)m(tr,do)=g(tr,do)·ctr(do)+α·∑p∈trNpN(do-p)where tr anddodenote the positions of the frame tracker and the detection output, respectively,N(do-p)is a normal distribution based on the distance from the detection to each particle in the frame tracker,ctr(do)is the classifier evaluation for the detected patch (described later), α is a parameter balancing the contribution from classifier evaluation and distance based evaluation, andg(tr,do)is a gating function estimating the relationships between the detection and the frame tracker based on their spatial relationship. It is calculated as(5)g(tr,do)=P(sizedo|sizetr)·P(posdo|postr)=Nsizetr-sizedosizetr·N(|do-tr|),if|Vtr|<τvNsizetr-sizedosizetr·N(dist(do,Vtr)),otherwisewhere size is measured as the height of the bounding box,Vtris the velocity of the pedestrian estimated by the frame tracker anddist(do,Vtr)is the distance from the detected position (a point) to the velocity vector (a line). The distributionN(dist(do,Vtr))has a shape similar to a 2D cone, which means that the future position of the tracker should generally follow the current direction when its speed has exceeded a certain thresholdτv. Accordingly, the matching score is related to the spatial relationship between the frame tracker (including its particles) and the detection, as well as their similarity in feature space. With all the pair-wise matching scores computed for every tracker–detection pair, each detected patch is associated to a frame tracker by a greedy algorithm, as long as the pair has a matching score greater than a certain threshold τ.At each time step, the confidence map is computed as the intermediate result by the detector and scaled to[0,1](e.g., Support Vector Machine output in the traditional Histogram of Oriented Gradient (HOG) based human detector [31]). In addition, for the situation when the detection fails because of occlusions,P0is used as the interobject occlusion reasoning, which is defined as(6)P0(tr)=1,ifI(tr)=1maxtr′:I(tr′)=1N(tr-tr′),else if∃I(tr′)=10,otherwiseThe classifier in this frame tracker is based on the online Ada-Boost classifier in [13], which contributes as the third term in Eq. (3). For each frame tracker (pedestrian), an associated classifier is trained and maintained based on the features of the tracked patch. The classifier is initialized when the tracker is created, using the patch information at that frame. The positive sample comes from the initial patch and the negative samples are the nearby patches within a certain range (including background). During tracking, a pool of weak classifiers are maintained and updated, and the ones with best performance are selected to form the current strong classifier. Given the features extracted from a particular patch, the classifier is able to evaluate this patch based on the trained model for the corresponding pedestrian. At each time step, when the new patch location for the pedestrian has been computed, the classifier updates itself using the features extracted from the new patch.We have used two crowd simulators in this approach. The first one is a global optimization approach called RVO2 library [10], and the second one is based on the modeling of social behavior for a single pedestrian [11,12]. As mentioned in Section 2.2, the Social Behavior Model provides a more realistic strategy for collision avoidance, which is expected to yield better tracking performance. In the following we explain the differences of the two simulators in detail, and examine how they impact the overall performance of the multi-camera tracking system.This model solves an optimization problem based on the strategy named Optimal Reciprocal Collision Avoidance (ORCA) [10]. It is computationally efficient and only requires the information about the current position and desired velocity of each pedestrian.The RVO2 library introduces a concept, namely velocity obstacles, with its definition as(7)VOA|BT={v|∃tv∈[0,T]:v·tv∈C(pB-pA,rA+rB)}wherepAandpBare the positions for two pedestrians andrA,rBare their radii.C(p,r)indicates a circle centered atpwith radiusr. Basically,VOA|BTdefines the set of relative velocities of A with respect to B which will cause a collision in the future within a time period[0,T]. Therefore, finding a solution for the collision avoidance equals to finding a set of velocities of pedestrians that are closest to the desired velocities, while none of them falls into the velocity obstacle set. Fig. 2shows a simple example with two pedestrians. Fig. 2a illustrates the system configuration: two pedestrians with radiusrare walking face-to-face along a line and want to swap their positions. The cone-like shape in shadow in Fig. 2b is the velocity obstacle of pedestrian A when B is not moving, which contains the velocities that pedestrian A cannot take to avoid potential collisions within time T (that is why it is called “obstacle”). This velocity obstacle moves as B moves. To avoid collision, the RVO2 library will find a solution such that each of the two pedestrians needs to take some effort but it is globally optimal. In this case, each of them turns right to a certain degree (or even changes speed as well, depends on the setting), so that their circles will be tangent to each other at some time in the future, as shown in Fig. 2c. This global optimal solution is computed efficiently using linear programming.The Social Behavior Model computes an energy function for each pedestrian, according to the current status (position and velocity) of all pedestrians. The first version of the Social Behavior Model is proposed by Pellegrini et al. [11], which comes from the social force model proposed in [26]. Yamaguchi et al. [12] further add group information to the model, which makes it more sophisticated. In our proposed approach, we use the version without group constraints [11] so that it is comparable to the RVO2 library.In this model, each pedestrian i is treated as a particle with real-world positionpitand velocityvit(pitandvithere are vectors). The whole crowd is then considered as a particle system. The main factors that influence the trajectory for each pedestrian are represented by energy functions. The collision avoidance for a particular pedestrian i is achieved by the interaction energy between this particle and all other particles. The interaction energy between particles i and j is calculated as(8)EijI(v)=e-dij∗2(v)2σd2wherevis the candidate velocity of pedestrian i, anddij∗2(v)denotes the smallest squared distance between pedestrians i and j. The squared distance between two pedestrians can be computed as(9)dij2(t,v)=pit-pjt+t·v-vjt2Thus, the time for the minimum squared distance can be obtained by computing the derivative ofdij2with respect totand set it to zero, resulting in(10)t∗=max-pit-pjt·v-vjtv-vjt2,0Therefore, the minimum squared distance is(11)dij∗2(v)=pit-pjt+t∗v-vjt2In addition, for different pedestrians, different weights are assigned to them depending on their spatial relationship to pedestrian i:(12)Wij=e-pit-pjt22σw212(1+cosϕ)ψwhere ϕ is the angle between the vectorvand the vectorΔpji=pjt-pit. So the first half of the weighting function represents the spatial relationship between pedestrians j and i in distance, and the second half denotes the relationship between pedestrian j and the field-of-view of pedestrian i. Here ψ controls the “peakiness” of weighting function in the field-of-view. Note, the field-of-view of each pedestrian is restricted to ±90°, that is, the weightWijis set to 0 when|ϕ|>π/2. Therefore, for pedestrian i, pedestrians that are close to him/her as well as located right on his/her walking way will obtain higher weights.The overall interaction energy for the pedestrian i is the weighted sum of the pair-wise interaction energy:(13)EiI(v)=∑j≠iWijEijI(v)Another two factors that control the trajectory are related to the desired velocityv∗: the speed energy and the direction energy. They are defined as(14)EiS(v)=‖v∗‖-‖v‖2(15)EiD(v)=-v∗‖v∗‖·v‖v‖So the total energy of a pedestrian i with velocityvis(16)Ei(v)=EiI(v)+λsEiS(v)+λdEiD(v)The optimal velocityv′is the one that minimizes the above equation. To make smooth pedestrian trajectories, the update of velocity is a weighted sum of the old and new velocities:vit+1=αsvit+(1-αs)vi′. Fig. 3demonstrates a system with three pedestrians as well as the energy distribution of pedestrian A. It is revealed that the optimal velocityv′is not the current velocity of A.In the idea of Social Behavior Model, each pedestrian makes a decision upon the assumption that all other pedestrians keep their previous trajectories. In addition, the pedestrian treats other pedestrians that may cause collisions differently, depending on their distances to the pedestrian as well as the displacements between them. A nearby pedestrian located right in front of him/her will obtain the most attention compared to others. So if two pedestrians walking face-to-face along a line, their trajectories generated by Social Behavior Model will not be as straight as those generated by the RVO2 library, and the circles within which the two pedestrians are located may not be tangent at some time in the future.As mentioned in Section 1, the integration of analysis and synthesis better utilizes the temporal and spatial relationship between pedestrians during the tracking process. To achieve this, these procedures have to be added at each time step: (1) Generates the input for the crowd simulator, including the estimation of desired velocity for each pedestrian; (2) Project the simulated real-world locations for each pedestrian to all camera views based on homography matrices; (3) After the tracking is done for each camera view, the real-world location for each pedestrian is obtained and updated. As a result, a global tracker is designed with two functions: (1) communicate between frame trackers and the crowd simulator; (2) estimate the desired velocity for each pedestrian. In addition, the frame tracker needs modification in order to use information from the crowd simulator. In the following, the two functions of the global tracker as well as the modification for the frame tracker are described.An important function of the global tracker is to communicate between the frame trackers and the crowd simulator. Therefore, the transformation between the points on the ground plane and the points on each camera view needs to be recovered. This is done based on the homography matrix between the ground plane each view (image plane), which is defined as a3×3matrix(17)Hv=h11vh12vh13vh21vh22vh23vh31vh32v1The computation for the homography matrices is done by manually selecting four corresponding points from different views, as well as from the real-world ground plane. With the homography matrixHv, each point(xg,yg)on the ground plane can be transformed to(x,y)on the image plane following the equation(18)xy1=Hvxgyg1To obtain the real-world location for each pedestrian, the inverse of the homography matrixHvis necessary. Based on the positions of one pedestrian on different camera views, the position of this pedestrian on the ground plane is determined using the principal-axis based integration. The principal axis of a pedestrian is defined as the line connecting the head and the feet. For simplicity, however, in our approach, we use the vertical line in the middle of the patch instead. The principal-axis based approach projects the principal axis of the same pedestrian from each view onto the ground plane and calculates the intersection of them. If the principal axes of the pedestrian in all the views are perfect, then the intersection points of their projection should converge to a single point, which is exactly the position of the pedestrian on the ground plane. Although in most cases this perfect intersection cannot be achieved, it can be proven that the principal axis-based integration is very robust and useful [2,21].For each pair of viewsciandcj, the intersection pointIijof the principal axes is obtained. If there are more than two views, a set of intersection pointsIcan be collected. SinceIij=Iji, only the intersections from viewsciandcjwithi<jare computed. So finally the setI={Iij}(i<j)hasNc(Nc-1)/2points in total (withNcviews). When the intersection points do not converge to a single point, we simply average all theIij’s to estimate the pedestrian positionp. The same strategy applies to the velocity estimation on the ground plane.Since crowd simulation requires information for the desired velocity for each pedestrian when it predicts pedestrians’ future locations, it is important for the global tracker to provide this information to the crowd simulator. However, compared to the real-world position and velocity information which is quite easy to compute in a multi-camera tracking system, it is difficult to obtain the desired velocity directly due to the uncertainty of human behavior in the future. That is, for most of the pedestrians, their preferences of walking direction and speed (especially the direction) cannot be exactly obtained based on the current information. Therefore, we have to find an alternative way to estimate the desired velocity. Our solution is based on using the historical information instead. For each pedestrian, we use Monte Carlo simulation based on his/her trajectory to estimate the desired velocity in the near future. The first step is to calculate the derivatives (accelerations) and their weights from the lastNhframes for a pedestrian k. The calculated set is defined asAkt=akt-Nh,akt-Nh+1,…,akt-1(akt-ihere is the velocity differentiation for pedestrian k at the lastith frame), as well as the corresponding weights(19)wkt-i=Nh-i+1∑j=1Nhj,i=1,…,NhThe assignment of the weights follows a strategy that the more recent acceleration is more important, thus it gets a higher weight (Eq. (19)). After that, a Monte Carlo simulation process is carried out on the acceleration set using these weights, which results in a set ofNaaccelerationsAkt′=ak,1′,ak,2′,…,ak,Na′ak,i′is one ofAkt. Then the desired velocity set is calculated as(20)vk,i′=vk+ak,i′+εa,kwherevki′is the estimation of desired velocity andvkis the current velocity.εa,kis a zero-mean normal distribution with variance equal toσAkt′.Finally, to reduce the computation of the crowd simulation, not all possible combinations of velocities are exploited. Instead, we pick up the velocities with the same index (i.e., i) from the estimated velocity set for each pedestrian so thatNvsets of velocitiesVi={v1,i,v2,i,…}are formed. We then use theseNvsets of desired velocities as the input to the crowd simulator, so the total number of possible locations estimated, i.e. the number that the crowd simulation repeats at each time step, isNv. Thereafter, the crowd simulator repeatsNvtimes with the same initial position and velocity information to generateNvsets of predictions of future positions for all the pedestrians. For each pedestrian, these positions are projected back to each viewcias a distribution of possible frame locationsLtrifor the particular frame tracker.To integrate the crowd simulation predictions into the frame tracker described in Section 3.1.1, we modify the observation model for the tracking-by-detection. Basically, at each time step, after the global tracker transforms the predicted positions for each pedestrian from the ground plane to each camera view, a distribution of these predicted positions can be obtained on each camera view. This distribution is represented by a set of possible locationsLtr, which are transformed from the ground plane based on the homography matrix. It is then used in the integrated observation model to estimate particle weights. For each particle p in a tracker tr, its weight with respect to the simulated predictions can be computed as(21)str(p)=1|Ltr|∑l∈LtrN(p-l)where l is one of the simulated position on the frame that has been transformed from the ground plane.Thereafter, the observation model in Eq. (3) is modified such that it has an additional term that represents the influence from the crowd simulation(22)wtr,p=βI(tr)Np-do∗+γdc(p)P0(tr)+ηctr(p)+δstr(p)where δ is the coefficient for this extra simulation term.According to this observation model, the weight of each particle for each frame tracker depends on the detection result and the confidence map generated by the human detector, the evaluation result from the boosting classifier, as well as the predicted locations from the crowd simulator. Therefore, the modified observation model takes advantage of both existing tracking-by-detection approaches based on detection results [16–19] and tracking-by-classification approaches based on classifier evaluation [13–15], as well as further help from the detection confidence map and crowd simulation. To integrate and balance the contributions from the four components, parametersβ,γ,η, and δ are introduced (the selection of their values is described later in Section 4.1.2.1). Moreover, compared to our previous work in [9], the modification for the observation model further avoids the possible loss of information brought by the sampling for the candidate locations on the ground plane. This might increase the performance even under the same frame tracker and crowd simulator implementation. The pseudo-code for the updated frame trackers is summarized in Algorithm 1.Algorithm 1Frame tracker updateThe pseudo-code for the entire simulation integrated tracking system is summarized as Algorithm 2.Algorithm 2Multi-camera tracking

@&#CONCLUSIONS@&#
In this paper, we have proposed a multi-camera tracking approach that integrates the crowd simulation approaches to the state-of-the-art single camera tracking-by-detection method. The difference between this approach and a traditional multi-camera tracking system is that the crowd simulation provides further usage of homography information. Two different crowd simulation strategies are exploited to observe their influence on the overall tracking performance. The experiments are conducted on crowded scenes from PETS 2009 dataset. The tracking performance is evaluated on different views as well as on the ground plane. Unlike the state-of-the-art trackers in which generally no crowd simulators are used, these results and comparisons demonstrate that significant improvement of tracking performance can be achieved when the predictions from crowd simulation are used, especially for scenarios with higher crowd density. For different crowd simulation strategies, difference in performance is also observed. According to the experimental results, the integration of more realistic crowd simulation can further improve the overall tracking performance in a multi-camera video network.