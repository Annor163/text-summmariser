@&#MAIN-TITLE@&#
Short term stock selection with case-based reasoning technique

@&#HIGHLIGHTS@&#
We proposed an intelligent stock selection method based on case-based reasoning.Fundamental and technical indicators are used to identify the winning stock.CBR method is compared with other artificial intelligence techniques.We showed that CBR outperforms the other techniques.

@&#KEYPHRASES@&#
Stock selection,Case-based reasoning,Intelligent system,Computational intelligence,Genetic algorithms,Earning analysis,

@&#ABSTRACT@&#
Stock selection is an important decision making problem. Trading strategies and rules based on fundamental and technical analysis can be used for decision making process. In this paper, we propose an intelligent stock selection method, which is called case-based reasoning (CBR). This technique uses the fundamental and technical indicators to identify the winning stocks around the earning announcements. CBR method is compared with other artificial intelligence techniques such as multi layer perceptron (MLP), decision trees (QUEST, Classification and Regression Trees, C5), generalized rule induction (GRI) and logistic regression. We show that the performance of CBR is better than the performance of other techniques in terms of classification accuracy, average return, Sharpe ratio and ideal profit.

@&#INTRODUCTION@&#
Stock selection is regarded as a challenging task for portfolio optimization. With the growing importance in the role of equities, the selection of attractive stocks for the short and long term investment has been the most important decision. Therefore, a reliable tool in the selection process can be of great assistance to investors. An effective and efficient system gives investors the competitive edge over others as they can identify the performing stocks with minimum effort. Trading strategies and rules based on fundamental and technical analysis have been used by both academics and practitioners for decision making process. Trading strategies can be transformed to computer language to exploit the logical processing power of the computer. This greatly reduces the time and effort to find attractive stocks.Many papers have focused on fundamental indicators to understand how they affect future earnings and stock prices [8,64,23,18,60]. Developing investment strategy based on fundamental indicators result in significant abnormal returns. In addition to this, analysts’ recommendations, stock market rumors and earning surprises can lead to abnormal returns. Many studies find that stock prices respond positively to the announcements of increase in earnings and negatively to the announcements of decrease in earnings for the U.S. firms [59,29,10,16]. Some researchers prove evidence of the informational content of earning announcements in a number of non U.S. markets [5,15]. Based on these findings, we can develop a model for selecting winning stocks around the earning announcements.There have been many studies using machine learning (ML) techniques in stock selection and stock price prediction. Most of these studies have focused on stock market index and individual stock prediction [7,29,28,6,17,13,14]. Recent studies have presented encouraging results on stock selection using data mining techniques such as rule induction, neural network, and combination of classifiers [20,24,25,58,4,31,27,14,34].CBR technique is one of the popular methodologies in knowledge-based systems. It is a novel paradigm that solves a new problem by recalling and reusing specific knowledge from past experience [1]. Concurrently, it is already an established and powerful methodology for intelligent problem solving and has been used for developing a variety of applications. Due to its strengths, researchers have successfully applied CBR to many areas: supply chain management and scheduling [44,50,45], bond rating [54,33], business failure prediction [43], business control system development [11], bankruptcy prediction and credit analysis [3,49,32], and stock market prediction [20,21,36].This study proposes a short term stock selection model based on CBR. A combination of technical and fundamental indicators is used as an input the CBR model for effective stock selection around the earning announcement. Portfolio managers focus on long-term portfolio management. Therefore, they try to choose fundamentally strong stocks with low volatility. On the other hand, some investors, especially small investors, focus on short term stock selection. They try to develop investment strategy based on fundamental and technical analyses. We propose an intelligent stock selection model around the earning announcement periods that uses combination of fundamental and technical indicators. There are some researches that use the CBR approach to forecast the stock indices and direction of movement [37,35]. As far as we know, there are no researches applying the CBR technique to short term stock selection or stock classification problem. The primary contribution of this study is to show that CBR can be used for short term stock selection. Another contribution is that we combine the fundamental and technical indicators.The rest of this paper is organized as follows: The next section briefly describes the CBR approach. Section 3 presents the proposed stock selection model. Section 4 explains the experimental design and the results of the evaluation experiment. The final section presents the conclusion.Case-based reasoning (CBR) technique is one of the popular methodologies in knowledge-based systems. While other artificial intelligence techniques depend on generalized relationships between problem descriptors and conclusions, CBR utilizes specific knowledge of previously experienced problem situations. It solves a problem by retrieving, reusing, revising and retaining past cases based on their degree of match and usefulness to the current situation. This is done by partial matching of the past cases with the current case, and by ranking across case dimensions until a smaller set of matching and useful cases is retrieved [3,1]. The usefulness of past cases for the current situation, on the other hand, may be assessed by assigning weights. A high degree of similarity or usefulness presents a good reason for adaptation. CBR methodology has been used in a broad range of domains to capture and organize past experience and to learn how to solve new situations from previous solutions.In general, a CBR system can be viewed as a composition of two modules, i.e., a case library and a problem solver [3]. The case library, which contains historical problems and their corresponding solutions, acts as a source of knowledge. Given a new problem, the problem solver performs two actions, i.e., (i) retrieves similar cases from the case library based on some similarity measure; and (ii) adapts the retrieved cases so that a solution to the new problem can be proposed.CBR system is composed of four sequential steps which are called into action each time that a new problem is to be solved [3,1,38]. Conceptually CBR is commonly described by the CBR cycle shown in Fig. 1. It involves four major steps which are recalled every time that a problem needs to be solved [3].i.Retrieve the most relevant case(s).Reuse the case(s) to attempt to solve the problem.Revise the proposed solution if necessary.Retain the new solution as a part of a new case.The purpose of the retrieval step is to search the case base to select existing cases sharing significant features with the new case. The key issues in this step are computing case similarity to match the best case, and adapting a similar solution to fit the new problem. Thus, the success of a CBR system largely depends on an effective retrieval of useful prior cases for the problem. The nearest neighbor method has been widely used for case retrieval. The method involves the assessment of similarities between stored cases and the new input case, based on matching a weighted sum of features. Once one or more cases are identified in the case base as being very similar to the new problem, they are selected for the solution of this particular problem. The CBR system tries to reuse the information and knowledge of the previously retrieved cases for solving the new problem. Once matching cases are retrieved from the case base, they should be adapted to the requirements of the current case. This process is called the revision process for CBR. This solution is revised (if possible) and finally the new case is stored. Cases can also be deleted if they prove to be inaccurate; they can be merged together to create more generalized ones and they can be modified. In the final step, the new solution is retained as part of a new case likely to be useful for future problem solving [61].Efficiency and accuracy of case retrieval highly depend on the determination of weight for each feature. In many cases, subjective weighting values are given by the user, and thus the retrieved solutions cannot always be guaranteed. Therefore, several case indexing methods have been proposed for effective case retrieval [3]. These are nearest neighbor, induction, fuzzy logic, rough set theory, kernel methods and database technology. Nearest neighbor is the most commonly used case indexing method. It is a direct method that uses a numerical function to compute the degree of similarity. In this study, we use a numeric evaluation function which measures the distance taking into account the importance of features to compute the degree of match in retrieval. A typical numerical function is shown in the following formula [42]:(1)DISab=∑i=1nwi⋅(fai−fbi)2where DIS is the matching function using Euclidian distance between cases, withe weight of the feature i, and n is the number of features.In nearest-neighbor, every feature in the input case is matched to its corresponding feature in the stored case, and the degree of match of each pair is computed using the matching function given in Eq. (1). Then, based on the importance assigned to each feature, an aggregate match score is computed. Cases are ordered according to their scores [56].The importance of each field shows us how much attention to pay to the respective match. Although, researchers suggest several ways of assigning the importance values such as knowledge of human expert, statistical evaluation, machine learning techniques and fuzzy logics [56,60,49], it is difficult to tell a priori regarding which set of weights would be the most effective to solve a specific problem. According to Shin and Han [54], one way is to have a human expert assign the importance values as the case library. The expert is expected to have the knowledge and experience required to decide which dimensions make good predictors. Another way to assign importance values is to do a statistical evaluation of known cases to determine which dimensions predict the solutions best. The correlation coefficient between each input and the output in the reference set can be used to weigh each input when computing the distance measure for a new example. Machine learning can be used as an alternative approach to learn the optimal weights from historical cases using evolutionary search technique. By evaluating the fitness of different weight vectors, good solutions can be found for CBR system.Several researchers have suggested using genetic algorithms (GAs) to determine the most appropriate feature weights of CBR approach ([3,47,54]). According to Moon and Sohn [47], the GA is able to improve the search results by constantly examining various possible solutions with the reproduction, crossover and mutation operations.GAs can be used as an alternative approach to compute optimal weights from old cases. Good solutions can be found by evaluating the fitness of different weight vectors. GAs explore a complex space in an adaptive way, guided by biological evolution mechanisms of reproduction, crossover and mutation to generate a new population of problem solutions and select the best solution for the problem. More information about GAs can be found in ([3,47,19]). We need to specify the parameters and their adjustable ranges, potential constraints and objective or fitness function to evaluate the performance. The parameters that are coded binary represent the weight vectors for nearest neighbor matching. We do not use any constraints for this problem. Defining the fitness function is the most critical step. The objective of GAs is to determine the set of weighting values that can best formalize the match between the input case and the previously stored cases. In other words, our objective is to retrieve more relevant cases that can lead to the correct solution. This can be achieved by increasing the classification accuracy. In this study, the fitness function is defined as the classification accuracy of the training set. The fitness function is expressed as:(2)maxCR=1n∑i=1nCAis.t.CAi=1ifO(Ti)=O(Sj*(i)),CAi=0,otherwise,Sj*(i)=minj∈R∑k=1lwk(Tik−Rjk)2,for a given i (i=1,2,…n). CR is the classification accuracy rate of the test set; CAithe classification of the ith case of the test set denoted by 1 and 0; O(Ti) the target output of ith case of the training set; O(Sj*(i)) the output of jth case of reference set that has the minimum distance with the ith case of the training set; Sj(i) the distance between ith case of the training set and jth case of the reference set; Tikthe kth feature of the ith case of the training set(T); Rjkkth feature of the jth case of the reference set(R); wkthe importance weight of the kth feature of case; l the number of features and n the number of the training cases [53].The key parameters consisting of population size, crossover rate, mutation rate and the stopping criteria have to be defined first when developing the algorithm. The population size is determined according to size of the problem. The common view is that a larger population takes longer to settle on a solution, but is more likely to find a global optimum because of its more diverse gene pool. The crossover and mutation rates prevent the output from falling into the local optima. The crossover rate ranges between 0.5 and 0.8 and the mutation rate ranges between 0.06 and 0.1 for this experiment. As a stopping condition, we use 5000 trials.The structure of the algorithm is shown in Fig. 2. The hybrid GA-CBR algorithm is given as follows:Step 1:We search an optimal weight vector with precedent cases for which the classification output is determined.The weight vector obtained in step 1 is applied to the case indexing scheme for the retrieval process. We also evaluate the resulting model with additional validation cases for which the outcome is known. Useful cases are ranked and retrieved by using a weight vector in the nearest neighbor matching function. As the validation cases are not used for parameter optimization, the prediction performance tested by these cases would be the closest to the current or future cases. If the project is successful, this leads to production.In step 3, new data are presented for the model to solve the problem.The weakness of the CBR systems is that there is some human interaction. This is a current weakness of CBR systems and one of their major challenges. Corchado and Aiken [22] have proposed a method of automating the process of case adaptation for the solution of problems in which the cases are characterized predominantly by numerical information. In this study, Corchado and Aiken's [22] approach is utilized.Investors are usually faced with an enormous amount of stocks in the market. A crucial part of their decision process is the selection of stocks to invest in. The identification of winning stocks remains to be one of the major problems for investors in making effective decisions. There exists an immense body of work on the mathematical analysis regarding the behavior of stock prices, stock markets and successful strategies for stock selection. In recent times, a variety of different approaches have been tried for identifying stocks with higher returns. High return (loss) occurs with new information such as earning announcements, company news, and dividend announcements. Market reaction to earning surprises has been investigated by several researchers (see [39,52] for a recent review). They show that there is a positive association between earning surprises and abnormal returns around the earning announcements. Stock return volatilities generally occur around earning announcements [59].Two approaches, technical and fundamental analysis, are commonly used by academicians and market professionals for stock selection and predicting stock prices [8,9,59,26,57]. Fundamental analysis involves using the financial and related data (fundamentals) of a firm to determine stock value and forecast future stock price movements. Fundamental analysts believe that an investment instrument has its intrinsic value that can be derived from the behavior and performance of its company. The fundamental approach utilizes quantitative tools, mainly the financial ratios compiled from financial statements as well as qualitative indicators, such as management policy, marketing strategy, and product innovation, to determine the value of an investment instrument [40]. Technical analysis uses knowledge from the past behavior of a stock price series to predict the future. The technical approach tries to identify turning points, momentum, levels, and directions of an investment instrument, using tools such as charting, relative strength index, moving averages, on balance volume, momentum and rate of change, breadth advance decline indicator, directional movement indicator, and de-trended price oscillator [46,41].A combination of technical and fundamental indicators can be used for effective stock selection. Portfolio managers use different techniques to identify which stocks to add to their portfolio. Generally, they focus on long-term portfolio management. Therefore, they try to choose fundamentally strong stocks with low volatility. On the other hand, some investors, especially small investors, focus on short term stock selection. They try to develop investment strategy based on fundamental and technical analyses. We propose an intelligent stock selection model around the earning announcement periods that uses combination of fundamental and technical indicators.Based on the previous studies [8,30,40,42,57], we select 12 fundamental and technical indicators as predictor variables. These are the last four quarters’ earnings per share (eps), insider buying and selling, institutional buying and selling, 10-day moving average (MA), 50-day moving average, 10-day moving average over 50-day moving average and current quarter eps estimate. Technical indicators are defined as categorical variables. For example, the 10-day MA is defined as “Bull (1)” if the closing price is higher than 10-day MA value; otherwise this variable is defined as “Bear(−1)”. Other indicators are also categorized in the same manner.For each quarter we assign a class to every stock to indicate its performance. Since different companies have different report cycles, the stock returns are calculated individually using the price data for the five days following the date of the quarterly earning announcement. All price data is obtained from the Yahoo finance and the adjusted stock price is used. If the performance of a stock is greater or equal to 5% then, it is labeled as exceptional high return stock (Class +1) and the others are labeled as unexceptional return (Class −1).This stock selection problem is then formulated as a two-class pattern recognition task. We represent the fundamental and technical indicators for the ith firm as a vector of predictor variables xi=(x1, x2,…, xn) (for our case n=12). The expected future return of the stock will be a binary dependent variable yi=±l, where +1 represents exceptional high return stocks, and −1 as normal stocks. Therefore a training set (x, y) of l firms will be the following pairs:(3){(x1,y1),(x2,y2),…(xl,yl)}⊂ℜnx±1In this study, we present stock selection as a two-class classification problem. This problem can be solved by using case based reasoning approach.First, we explain multilayer perceptron (MLP), decision trees (classification and regression trees (CART), QUEST, C5), logistic regression and generalized rule induction (GRI).Multilayer perceptron (MLP) is the commonly used technique for classification and prediction. The MLP also known as backpropagation neural network (BPN) is feed forward neural network trained with the standard back propagation algorithm. Backpropagation algorithm uses the gradient steepest descent method to minimize the total square error of the output computed by the net. A multi-layer perceptron is made up of several layers of neurons. Each layer is fully connected to the next one. The MLP in this paper was a three-layer, single-output network with twelve input nodes, 10 hidden-layer nodes and one output node. Varying the number of hidden nodes from 4 to 15, it was determined that using ten hidden nodes in the BPN gives the best performance using the criteria given by Tay and Cao [57]. The selection of the learning rate as 0.01 and the momentum term as 0.9 is because a BPN with these settings as the learning parameters has the best prediction performance with the least number of epochs [57]. The sigmoid function was used at each of the hidden layer nodes and the output node. The number of training iterations was set to 5000.Decision trees form an integral part of ‘machine learning’ an important sub-discipline of artificial intelligence. Almost all the decision tree algorithms are used for solving classification problems. Decision trees are becoming increasingly more popular for data mining because they are easy to understand and interpret, require little data preparation, handle numerical and categorical data, and they perform very well with a large data set in a short time. Decision tree algorithms induce a binary tree on a given training data, resulting in a set of ‘if–then’ rules. These rules can be used to solve the classification or regression problem. Decision trees produce excellent visualizations of results and their relationships. There are many algorithms of decision trees. Their main difference is the way to decide the sequence of attributes that should be used for each branch node. ID3 [51] is a famous decision tree algorithm, which uses the information gain for the choice of the sequence of attributes. However, a bias may develop when each attribute or variable has different magnitudes. C4.5 and C5 [63] is an extended version of ID3, which uses the gain ratio instead of the information gain to avoid this problem. A decision tree that is able to deal with continuous data is a regression tree such as the classification and regression tree (CART). CART [12] uses the Gini index, which is the sum of the squares of the proportions of the categories, for the choice of the sequence of attributes. The Quick, Unbiased, Efficient Statistical Tree (QUEST) algorithm is a binary-split decision tree algorithm for classification. It is similar to the CART algorithm. However, there are some minor differences. For instance, QUEST employs an unbiased variable selection method, uses imputation for dealing with missing values instead of surrogate splits, and handles categorical variables with many categories. In this study, the C5, CART, and QUEST algorithms are the most commonly used ones.Logistic regression is a widely used statistical modeling technique in which the probability of a dichotomous outcome is related to a set of potential predictor variables in the form:(4)log11−p=β0+β1x1+β2x2+…+βixiwhere p is the probability of the outcome of interest, β0is the intercept term, and βi(i=1,2,…,n) represents the β coefficient associated with the corresponding explanatory variable xi(i=1,2,…,n) [48]. The dependent variable is the logarithm of the odds, {log[p/(1−p)]}; which is the logarithm of the ratio of two probabilities of the outcome of interest. These variables are usually selected for inclusion by using some form of backward or forward stepwise regression technique [48]. The maximization of the likelihood function is usually applied as the convergent criterion to estimate the coefficients of corresponding parameters when the logistic regression models are utilized. In this study, the stepwise logistic regression procedure is used in building the model.An association rule algorithm is capable of producing rules that describe associations (affinities) between attributes of a symbolic target. The association rule shows relationships among items in a transaction of a database. These patterns or rules have been used for various purposes. The GRI induction process can be divided into two steps. First the database is scanned to extract all the itemsets that satisfy a user-specified minimum support criterion. Then each association rule that describes an association between items in a transaction that occur frequently is extracted based on a user-specified minimum confidence criterion [2]. The process usually results in a large number of ARs. In order to reduce the number of rules generated, the minimum confidence threshold value can be increased. However, setting the minimum confidence level too high may prevent the identification of some important ARs. The Generalized Rule Induction (GRI) is one of most commonly used methods for AR induction. The GRI generates rules to summarize patterns in the data using a quantitative measure for the interestingness of rules. This measure provides a method for ranking competing rules and allows the system to constrain the search space for useful rules, as well as identifying the best or most interesting rules describing a database. GRI is based on the ITRule algorithm [55] and extends that algorithm with added functionality.

@&#CONCLUSIONS@&#
