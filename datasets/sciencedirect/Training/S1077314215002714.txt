@&#MAIN-TITLE@&#
Robust depth estimation for light field via spinning parallelogram operator

@&#HIGHLIGHTS@&#
We propose a spinning parallelogram operator (SPO) for depth estimation on EPI.We apply the SPO to both synthetic and real light field camera images.The SPO is proved to be insensitive to occlusion, noise, spatial aliasing.The SPO has no requirement for depth range and angular resolution.

@&#KEYPHRASES@&#
Light field,Epipolar plane image,Depth estimation,Spinning parallelogram operator,

@&#ABSTRACT@&#
Removing the influence of occlusion on the depth estimation for light field images has always been a difficult problem, especially for highly noisy and aliased images captured by plenoptic cameras. In this paper, a spinning parallelogram operator (SPO) is integrated into a depth estimation framework to solve these problems. Utilizing the regions divided by the operator in an Epipolar Plane Image (EPI), the lines that indicate depth information are located by maximizing the distribution distances of the regions. Unlike traditional multi-view stereo matching methods, the distance measure is able to keep the correct depth information even if they are occluded or noisy. We further choose the relative reliable information among the rich structures in the light field to reduce the influences of occlusion and ambiguity. The discrete labeling problem is then solved by a filter-based algorithm to fast approximate the optimal solution. The major advantage of the proposed method is that it is insensitive to occlusion, noise, and aliasing, and has no requirement for depth range and angular resolution. It therefore can be used in various light field images, especially in plenoptic camera images. Experimental results demonstrate that the proposed method outperforms state-of-the-art depth estimation methods on light field images, including both real world images and synthetic images, especially near occlusion boundaries.

@&#INTRODUCTION@&#
The space of light rays in a scene that intersect a plane from different directions may be interpreted as a 4D light field [1]. It captures not only the accumulated intensity in the scene, but also the direction of each light ray. Hence, the light field can reveal the structure of the scene and is adopted in a wide range of applications, e.g. light field rendering [2], super-resolution [3–5], digital refocusing [6] and 3D reconstruction [7].However, it used to be difficult to manufacture a device to acquire the full light field until the concept of “plenoptic camera” [8] was proposed a few years ago. Using an array of micro-lenses, a single camera is capable of capturing multiple views of the scene simultaneously. More and more this type of specially designed cameras, e.g. Lytro [6] and Raytrix [9], have appeared in order to meet the increasing demands in various light field applications.As a critical step in light field image processing, much attention has been paid to efficient and robust algorithms for depth estimation from light fields. On the one hand, light field images can be processed for multiple images from different perspectives of the scene, namely sub-aperture images in light field. Therefore, lots of methods based on multi-view stereo matching [10–12] have been proposed. On the other hand, because of the continuous angular space, some methods based on estimating the slopes of the lines in the Epipolar Plane Image (EPI) [13,14] have been developed. However, these methods have some problems with occluded and noisy regions, especially in plenoptic light field images.Occlusion has been a tough problem for depth estimation [11,15] both in multi-view and light field images. Occlusion occurs when points near the camera occlude points far away from the camera. As a result, the points far away from the camera are only visible in some sub-aperture images and are occluded by front points in other sub-aperture images. In such case, we cannot rely on finding the points’ correct positions in every sub-aperture images to estimate the depth like traditional stereo matching techniques.Since a plenoptic camera samples the light field and provides angular as well as spatial information on the distribution of light rays in space, the spatial and angular resolutions of the captured images are limited by the hardware. Consequently, images captured by these cameras may be highly aliased due to the sparse sampling [10] in space. The limited angular resolution, a large depth range and different kinds of noise in the real environment, along with the occlusion problems, reconstruction errors increase in plenoptic camera images. Overall, depth from the plenoptic cameras is difficult to estimate due to the above problems for most methods (some examples can be found in Fig. 1).In this paper, we propose a novel spinning parallelogram operator (SPO) to locate lines and calculate their orientations in an EPI for local depth estimation. The proposed method measures the slopes by maximizing distribution distances between two parts of the parallelogram window to extract depth information. The spinning parallelogram operator has been demonstrated to be insensitive to occlusion, noise, spatial aliasing, limited angular resolution and EPI specific.The proposed method also defines a confidence matrix to achieve the maximum utilization of information in horizontal and vertical slices, and calculates the depth values for individual views. In addition, a filter-based method [16], which is less computationally demanding but achieves similar performance as energy-based methods, is introduced to obtain a high-quality global depth map. Based on the confidence metric which is used to gauge reliability, we can obtain the refined depth map.Experimental results show that our method is effective for both real camera images and synthetic light field images. For plenoptic camera images, including Lytro and Raytrix images, which are highly noisy and aliased, our method outperforms state-of-the-art ones for light field depth estimation and shows the structure of the object more clearly. For the other types of images, which are more similar to multi-view images, our method achieves better performances near the occlusion boundaries and ambiguous regions. Regions with strong specular highlights or with no texture is a typical failure case and further preprocessing or postprocessing is needed.The main contributions of our work are1.We propose a spinning parallelogram operator (SPO) for depth estimation on the EPI, which can be applied to both synthetic and real light field camera images. This method is insensitive to occlusion, noise, spatial aliasing, angular resolution, and large depth range.We introduce a confidence metric to integrate information from the rich structure of the light field, and to further reduce the influence of occlusion and ambiguities.We adapt the spinning parallelogram operator to different kinds of datasets and achieve the final refined depth maps.

@&#CONCLUSIONS@&#
