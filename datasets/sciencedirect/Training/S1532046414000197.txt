@&#MAIN-TITLE@&#
Improving record linkage performance in the presence of missing linkage data

@&#HIGHLIGHTS@&#
Three novel methods were validated to solve missing data problem in record linkage.Two variants of the Linkage Extension method were implemented.All three new methods produce better results than existing methods.Weight Distribution and Distance Imputation produce no false positive cases.Full Linkage Extension detected more match pairs than Compact Linkage Extension.

@&#KEYPHRASES@&#
Record linkage,Missing data,Data quality,Comparative effectiveness research,Quasi-identifiers,

@&#ABSTRACT@&#
IntroductionExisting record linkage methods do not handle missing linking field values in an efficient and effective manner. The objective of this study is to investigate three novel methods for improving the accuracy and efficiency of record linkage when record linkage fields have missing values.MethodsBy extending the Fellegi–Sunter scoring implementations available in the open-source Fine-grained Record Linkage (FRIL) software system we developed three novel methods to solve the missing data problem in record linkage, which we refer to as: Weight Redistribution, Distance Imputation, and Linkage Expansion. Weight Redistribution removes fields with missing data from the set of quasi-identifiers and redistributes the weight from the missing attribute based on relative proportions across the remaining available linkage fields. Distance Imputation imputes the distance between the missing data fields rather than imputing the missing data value. Linkage Expansion adds previously considered non-linkage fields to the linkage field set to compensate for the missing information in a linkage field. We tested the linkage methods using simulated data sets with varying field value corruption rates.ResultsThe methods developed had sensitivity ranging from .895 to .992 and positive predictive values (PPV) ranging from .865 to 1 in data sets with low corruption rates. Increased corruption rates lead to decreased sensitivity for all methods.ConclusionsThese new record linkage algorithms show promise in terms of accuracy and efficiency and may be valuable for combining large data sets at the patient level to support biomedical and clinical research.

@&#INTRODUCTION@&#
Electronic health records (EHRs) are being adopted across diverse clinical practice settings, enabling clinical investigators to access detailed longitudinal patient- and practice-level data not previously available [1–3]. Rapidly evolving sources of rich health and wellness data include personal medical records, electronic diaries, online social media, disease-specific virtual communities, registries, and real-time personal health monitoring devices. Important data for research also exists in operational, administrative, and financial systems, hence, relevant clinical and financial data often exist in many independent organizations [4,5] and these data sources represent both enormous opportunities for and significant challenges to clinical practice and research. Without an accurate and universal patient identifier, the full spectrum of available patient data is not easily linked, creating barriers to an integrated, comprehensive view of treatments, outcomes, and costs.Record linkage methods combine independent data sources so that data belonging to the same patient are assigned a common identifier. Current record linkage methods use one or more non-unique fields, called quasi-identifiers, to link two records belonging to the same individual [6]. Quasi-identifiers are defined as fields that, when combined, may be able to uniquely identify an individual, such as date of birth and last name [7]. In medical settings, missing data, including quasi-identifiers, can occur due to multiple reasons, creating challenges for record linkage. For instance, patients may not provide required information or clinical workflows may not ensure complete and accurate data collection and documentation. In a study about data quality in electronic medical records of HIV patients, Forster found that the median missing data rate across six observed variables – age, sex, CDC or WHO clinical stage at baseline and follow-up, CD4+ lymphocyte (CD4) counts and year of ART initiation – was about 10.9% [8].Current record linkage methods determine match results based on the calculated similarity between two linking fields’ values and a set of weights which determines the relative contribution of each linking field’s similarity or dissimilarity to a final match score [9]. A number of methods for calculating distance measures that have different properties or optimizations for specific data types can be used to calculate similarity scores. However, it is not possible to calculate a distance if either of the two values is missing.While multiple methods have been proposed to solve the problem of missing data in traditional statistical analytic settings [10], much less research has focused on solving missing-data problems in fields that are used to perform record linkage. A common approach is to remove record pairs that have any missing data in any record linking field. Another approach is to simply ignore the field with missing data in the linkage-scoring algorithm. In both cases, valid record pairs may be missed due to the removal of information available for linkage determination.We have developed novel algorithms with the objective to correctly identify matching records despite the occurrence of missing data in record linkage fields. We sought to accomplish two key goals: (1) maintain computational efficiency and (2) maximize the accuracy (sensitivity and positive predictive value (PPV)) of the linkage mechanism. We adapted solutions used to resolve missing data in standard classification methods to the problem of missing data in record linkage [11,12]. The three novel approaches: Weight Redistribution, Distance Imputation, and Linkage Expansion, better leverage the data available and discard less data, thereby preserving more information for record linkage. Weight Redistribution removes fields with missing data from the set of quasi-identifiers and redistributes the weight from the missing attribute based on relative proportions across the remaining available linkage fields. Distance Imputation imputes the distance between the missing data fields rather than imputing the missing data value. Linkage Expansion adds previously considered non-linkage fields to the linkage field set to compensate for the missing information in a linkage field. This study implements and compares the performance of all three approaches.

@&#CONCLUSIONS@&#
We developed three new algorithms for modifying the most common record linkage methods to respond to missing values in record linkage variables. We compared the linkage performance of these algorithms and two existing algorithms using two pairs of simulated data sets with known corruption properties. None of the existing methods had 100% sensitivity with 100% specificity, and differences in accuracy were observed. Given the enhanced focus on big data analytics and the potential benefits of combining data from disparate sources, the ability to accurately link patient records is crucial. Additional research in this record linkage may result in heuristics that enable selecting optimal algorithms based on the characteristics of the data and the desired trade-offs in the performance goals of the record linkage process.