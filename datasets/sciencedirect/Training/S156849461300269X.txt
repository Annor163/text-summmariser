@&#MAIN-TITLE@&#
Partial imputation of unseen records to improve classification using a hybrid multi-layered artificial immune system and genetic algorithm

@&#HIGHLIGHTS@&#
Genetic algorithm optimization is effective for partial imputation using MAIS.The hybrid MAIS and genetic algorithm improves performance of classifiers.Increased strength and resilience in the presence of escalating missing data.

@&#KEYPHRASES@&#
Multi-layered artificial immune system,Genetic algorithms,Missing data,Correlation-based feature extraction,

@&#ABSTRACT@&#
Missing data in large insurance datasets affects the learning and classification accuracies in predictive modelling. Insurance datasets will continue to increase in size as more variables are added to aid in managing client risk and will therefore be even more vulnerable to missing data. This paper proposes a hybrid multi-layered artificial immune system and genetic algorithm for partial imputation of missing data in datasets with numerous variables. The multi-layered artificial immune system creates and stores antibodies that bind to and annihilate an antigen. The genetic algorithm optimises the learning process of a stimulated antibody. The evaluation of the imputation is performed using the RIPPER, k-nearest neighbour, naïve Bayes and logistic discriminant classifiers. The effect of the imputation on the classifiers is compared with that of the mean/mode and hot deck imputation methods. The results demonstrate that when missing data imputation is performed using the proposed hybrid method, the classification improves and the robustness to the amount of missing data is increased relative to the mean/mode method for data missing completely at random (MCAR) missing at random (MAR), and not missing at random (NMAR).The imputation performance is similar to or marginally better than that of the hot deck imputation.

@&#INTRODUCTION@&#
Missing data and its increasing presence in large-scale insurance datasets can affect the quality of data analyses and predictions. Classifiers designed for such data are required to achieve high prediction accuracies as this is an imperative step in the decision making process. However, missing data in unseen patterns reduces the quality of the data and affects the classification performance [1]. Missing data can occur for a variety of reasons. Common causes include error handling by systems, interoperability amongst heterogeneous systems and people refusing to disclose certain information for security or social status reasons [2].This paper presents a novel hybrid multi-layered artificial immune system (MAIS) and genetic algorithm (GA) for the effective partial imputation of missing data in high-dimensional spaces. MAISs have the advantage of being able to learn and adapt to an antigen. They also have the ability to proliferate and store antibodies in memory cells to help select the antibody that binds most effectively to an antigen. GAs are used to search for a global solution as opposed to a local maximum or minimum and are found to be suitable for the missing data problem in this paper. In this work, GAs are used to optimise the antibodies of the MAIS, created during the learning process. GAs have been used previously to optimise the performance of classifiers [3,4]. They have been successfully applied to the estimation of missing values in fault identification [5] and in optimisations to increase the strength and robustness of support vector machines in datasets with large numbers of variables [6].The effectiveness of the proposed hybrid MAIS–GA imputation in various classifiers is compared with that of the mean/mode and hot deck imputation methods. The impact of the imputation on the performance and robustness of each classier on the increasing number of missing values is determined. The classifiers used to evaluate the effects of the imputation are the repeated incremental pruning to produce error reduction (RIPPER), logistic discriminant analysis (LgDA), naïve Bayes (NB) and k-nearest neighbour (k-NN) classifiers. These classifiers are chosen because they have been applied in the insurance and credit risk analysis domains. The RIPPER algorithm has been utilised in financial risk analysis to help financial institutions determine the correct policies for credit products, increase revenue and reduce deficits [7]. The LgDA classifier has been successfully applied in credit risk analysis to divide loan applications into groups of good and bad creditors [8].The NB classifier has been utilised successfully in the context of customer life insurance, fraud claims analysis and determining whether a potential client is a good or bad creditor [9,10]. The k-NN classifier has been used to construct credit scoring models [11] and determine insurance premiums [12].The remainder of the paper is organised as follows. The following section reviews some background material on missing data mechanisms and imputation methods, and Section 3 provides an overview of previous related work. An introduction to artificial immune systems and genetic algorithms is provided in Section 4. Section 5 discusses the proposed hybrid MAIS–GA imputation method in detail, and the experimental setup is described in Section 6. The experimental results are presented in Section 7, followed by the conclusion in Section 8.An important task in problems involving datasets with missing data is to identify the patterns and mechanisms underlying the missingness. This step provides insight into the process that may have generated the missing entries and aids in the selection of the most appropriate model or method for handling the missing data. Patterns define which entries in the dataset are observed and which are missing, often yielding information on how the missing data occurred. Little and Rubin classified missing data patterns into three types: univariate, monotone and arbitrary patterns [13]. In a univariate pattern, the missing data is confined to one variable. In a monotone pattern, the missing data occurs chronologically in more than one variable such that if the variables are expressed in matrix form, a “staircase” line appears to separate the variables. In an arbitrary pattern, any set of variable entries may have missing data.Three missing data mechanisms are defined by [13]. The first is the Missing at random (MAR) or ignorable case, which occurs when missing values in a variable do not relate to the variable itself but rather to other variables in the dataset. For example, consider a dataset with gender and age as related variables. If some females refuse to reveal their age, then the corresponding age entries will be missing at random because all of the missing entries are related to gender. The second missing data mechanism is missing completely at random (MCAR); this mechanism occurs when the missing values of a variable are not related to the other variable entries in the dataset. The third missing data mechanism is referred to as the not missing at random (NMAR) or non-ignorable case, occurring when the missing values are related to the variable itself. For example, consider a dataset including gender and illness. If both males and females refuse to divulge cancer as an illness, then the illness entries are not missing at random.Determining the missing data mechanism in a dataset with missing entries is highly nontrivial and is a subject of intense debate. Some researchers have claimed that MAR data provides unbiased estimates [14,15], while other researchers argue that NMAR data yields superior performance accuracies compared to MAR data [16,17]. We investigate the imputation and classification performances for MAR, MCAR and NMAR data in this paper.Imputation methods replace missing entries with plausible values, making it possible to analyse data as if it were completely observable. Imputation methods can be grouped into single and multiple imputation methods [18]. In single imputation, a missing value is replaced with one observable value. In multiple imputation, the missing values are replaced with a set of K estimated values. Rubin describes this process in three steps [18]. First, the missing values are replaced K times, yielding K datasets consisting of completely observable data. Second, each of the K datasets is analysed using complete-data analysis techniques. Finally, the results are concatenated from the K datasets based on which of the K datasets provides the best inferences.In mean or mode imputation, the missing entries are replaced by the mean or most frequently occurring value (mode) of the corresponding variable [13]. The advantages of this method are that it preserves the mean or mode of the data and is simple to implement. The disadvantage of the mean/mode method is that the replacement values have zero variance. If the number of replaced values is distributed uniformly, the method therefore yields incorrect and biased estimates. Furthermore, simple substitution using the mean diminishes the variance of the variable as well as its correlation with other variables in the dataset [19–21].In hot deck imputation, the missing values are substituted with values from other records in a cluster of nearest neighbours [19,22]. This is achieved by grouping the records into clusters based on their similarities using the k-NN method. The missing values are then replaced with values from other records in the same cluster. In the cold deck imputation method, the missing values are replaced with a constant value derived from external sources [19,22]. Hot and cold deck imputation are the most common imputation methods second to the mean/mode method because of their simplicity and freedom from assumptions regarding the model fit to the data. These methods have the advantage of being able to predict values for both the numerical and categorical variables and can be adapted to work with any variable as the target variable.Decision trees (DTs) are supervised learning methods designed to separate data into similar groups for classification or regression analysis. A DT is an acyclic graph consisting of a root node, leaf nodes, internal nodes and edges. The root node is the starting point of the DT, and the leaf nodes represent the target variable information or final outcome. The internal nodes hold data regarding the splitting variable. The edges connect the nodes and hold data regarding the splitting [23,24].In DT imputation, a DT is constructed for each variable with missing values and then all of the missing values of each variable are replaced. The original class variable is treated as another variable in the dataset, while the variable in question is treated as the target variable. The variables used to construct the DTs are unordered. Once their construction is complete, the DTs are used to calculate or determine the missing values of the corresponding variable [25].

@&#CONCLUSIONS@&#
