@&#MAIN-TITLE@&#
A two phase approach for the bi-objective non-convex combined heat and power production planning problem

@&#HIGHLIGHTS@&#
Consider emission impacts in combined heat and power production planning.A method for constructing non-dominated line segments are presented.A two phase method for constructing the Pareto frontier for the hourly subproblem.A merging algorithm for approximating the Pareto frontier for the problem.The effectiveness of the algorithm is evaluated against the e-constraint method.

@&#KEYPHRASES@&#
Multi-objective optimization,Combined heat and power production,Mixed integer linear programming,Two phase method,,

@&#ABSTRACT@&#
In this paper, we deal with the bi-objective non-convex combined heat and power (CHP) planning problem. A medium and long term planning problem decomposes into thousands of single period (hourly) subproblems and dynamic constraints can usually be ignored in this context. The hourly subproblem can be formulated as a mixed integer linear programming (MILP) model. First, an efficient two phase approach for constructing the Pareto Frontier (PF) of the hourly subproblem is presented. Then a merging algorithm is developed to approximate the PF for the multi-period planning problem. Numerical results with real CHP plants demonstrate the effectiveness and efficiency of the solution approach using the Cplex based ɛ-constraint method as benchmark.

@&#INTRODUCTION@&#
Energy and environmental policies are inextricably linked. The growing awareness about the environmental impacts of energy has significantly broadened the policy goals set in the energy sector. Combined heat and power (CHP) production is universally accepted as one of the energy efficient technologies with lower fuel consumption and fewer emissions. CHP can provide viable solutions to mitigate environmental impacts of energy production. The European Union (EU) is strongly promoting clean production technologies with fewer emissions (CEC Commission of the European Communities, 2004) to respond to the environmental policy.When environmental impacts must be incorporated into the planning problem, multiple criteria decision making (MCDM) is a goodway to deal with the problem. This is a paradigm under which decisions are made not based on the results of optimizing a single criterion (usually the economic cost) but rather on the tradeoff of simultaneously optimizing different and conflicting criteria (Ehrgott, 2005). MCDM approaches have long been used in energy planning for both traditional power-only and heat-only systems (Ehrgott, Naujoks, Stewart, & Wallenius, 2010; Figueira, Greco, & Ehrgott, 2005; Pohekar & Ramachandran, 2004) as well as poly-generation including CHP systems (Rong, Lahdelma, & Grunow, 2010).In this paper, we consider explicitly the environmental impact of a medium or long term CHP economic dispatch (CHP-ED) problem under the framework of multi-objective optimization. The ED problem can be viewed as a subproblem of the long term planning problem such as the generation expansion planning problem (Phupha, Lantharthong, & Rugthaicharoencheep, 2012). The medium or long term planning problem needs to be considered in the context of risk analysis for tactical and strategic decision making (Makkonen, 2005).In CHP technology, heat and power generation follow a joint characteristic. Traditional CHP production is usually applied in backpressure plants, where the joint characteristic can typically be represented by a convex (linear programming, LP) model (Aringhieri & Malucelli, 2003; Gardner & Rogers, 1997; Guo, Henwood, & van Ooijen, 1996; Lahdelma & Hakonen, 2003; Rong, Hakonen, & Lahdelma, 2006; Rong & Lahdelma, 2007a). But the convexity assumption may not be valid for more advanced production technologies such as backpressure plants with condensing and cooling options, gas turbines and combined gas and steam cycles. A non-convex CHP plant can be formulated as a mixed integer linear programming (MILP) model based on the convex partitioning technique (Makkonen, 2005; Makkonen & Lahdelma, 2006; Rong, 2006; Rong & Lahdelma, 2007b).Usually a long term planning problem can be decomposed into a sequence of single period subproblems using different decomposition techniques (Conejo, Castillo, Mínguez, & García-Bertrand, 2006). The natural period length is typically one-hour because power on the market is traded on the hourly basis. In this paper, we refer to the single period subproblem as the hourly subproblem. In a broader context of risk analysis where numerous scenarios need to be considered, usually the simplification of the planning problem (e. g., ignoring dynamic constraints) is allowed (Linares, 2002; Makkonen & Lahdelma, 1998; 2001; Rong & Lahdelma, 2005; 2007c) for at least two reasons. First, dynamic constraints are associated with a short term horizon and do not have much effect on the operation over a long term horizon. Second, dynamic constraints couple the operations from period to period and cause convergence problems for decomposition-based algorithms for a longer planning horizon. In multi-objective optimization context, the situation becomes more serious. A general solver cannot solve the planning problem even with a very short horizon (e. g., a day), in some cases even when dynamic constraints are ignored.In the following, we briefly review the algorithm development for handling multi-objective CHP-ED and multi-objective MILP problems. For dealing with multi-objective CHP-ED, meta-heuristics were mainly used (Basu, 2013; Chang & Fu, 1998; Hu, Weir, & Wu, 2012; Niknam, Azizipanah-Abarghooee, Roosta, & Amiri, 2012; Shi, Yan, & Wu, 2013; Tsay, 2003; Wang & Singh, 2008). The interested readers can also refer to comprehensive surveys (Gu et al., 2014; Salgado & Pedreo, 2008). In terms of multi-objective MILP problems, the literature in the field includes exact and approximate algorithms. The former are targeted to find the exact Pareto Frontier (PF) while the latter aim at approximating the PF. Exact approaches include different variants of Branch and Bound (BB) algorithms (Belotti, Soylu, & Wiecek, 2012; Cheng, Tadikamalla, Shang, & Zhang, 2014; Mavrotas & Diakoulaki, 1998; 2005; Vincent, Seipp, Ruzika, Przybylski, & Gandibleux, 2013) and the augmented ɛ-constraint method (Mavrotas, 2009). The approximate approaches include meta-heuristics (Ahmadia, Aghaeib, Shayanfara, & Rabieec, 2012; Shimizu, 1999), relaxation based heuristics (Wibaut & Hanafi, 2009), the master slave procedure (Fazlollahi & Maréchal, 2013), interactive procedures (Alves & Clímaco, 2007; Antunes, Martins, & Brito, 2004; Kallio & Halme, 2013; Sahebjamnia, Torabi, & Mansouri, 2015), an algorithm for finding well-dispersed subsets of non-dominated outcomes (Sylva & Crema, 2007) and an algorithm that uses a composite linear function to find all supported non-dominated outcomes (Özpeynirci & Köksalan, 2010).Note that the PF of the multi-objective MILP consists of Non-Dominated Line Segments (NDLSs) and possible isolated points (refer to Fig. 2(a) later in Section 3). An NDLS refers to a line segment on which any two elements (points) do not dominate each other. The contributions of the current research are summarized as follows. First, an NDLS instead of a single point is treated as an entity to represent the non-continuous and non-convex PF for the MILP problem. A method for constructing NDLSs is presented by analyzing the model structure. Second, a two phase approach centered around manipulating NDLSs is developed for the hourly subproblem. Up to now, the two phase method has only been applied to pure multi-objective integer programming (combinatorial) problems (Przybylski, Gandibleux, & Ehrgott, 2008; 2010; Steiner & Radzik, 2008; Visée, Teghem, Pirlot, & Ulungu, 1998) though it is a general approach for dealing with multi-objective mathematical programs with integer variables. Third, the relation between the proposed two phase method and the ɛ-constraint method is identified and the optimality of the NDLS computed by the two phase method can be verified by checking two points on it using the ɛ-constraint method. Finally, a merging algorithm (MA) is developed to approximate the PF for the bi-objective non-convex problem by extending the MA for the bi-objective LP problem (Rong, Figueira, & Lahdelma, 2014).For the single objective optimization case, the utilization of the simplification for ignoring dynamic constraints is straightforward because the optimal solution of the long term planning problem can be obtained trivially by adding directly the solutions of the hourly subproblems. For bi-objective LP, the exact PF for the multi-period problems can also be obtained by merging the PF for the hourly subproblems based on the convexity of the PF (Rong et al., 2014). However, for the multi-objective (including bi-objective) non-convex problem, it is an open question how to aggregate the PF of the hourly subproblems.The paper is organized as follows. Section 2 describes the model of the individual CHP plant as well as the model of the bi-objective CHP planning problem. In Section 3, a two phase method for the hourly subproblem is presented centered around manipulating NDLSs. Then, an MA is presented for approximating the PF of the bi-objective multi-period problem. Section 4 reports the computational results with real CHP plants. A comparison is made between the proposed solution approach and ɛ-constraint method. At the end of the paper, four appendices are attached. Appendix I gives the formulas for calculating the parameters of an NDLS. Appendix II collects the procedures related to the two phase method and MA. Appendix III gives the data for power plants related to the illustrative example. Appendix IV illustrates the two phase algorithm.Here the problem under study can be viewed as an extension of the single objective non-convex CHP planning problem (Rong & Lahdelma, 2007b) to accommodate emissions objective or a non-convex version of the bi-objective CHP planning problem studied in (Rong et al., 2014). The modeling framework of plants is briefly described as follows. The operating region of a convex plant is modeled as a convex combination of extreme points for the region. A non-convex plant is modeled according to the convex partitioning technique (Makkonen, 2005; Makkonen & Lahdelma, 2006), i. e., the characteristic area of a non-convex plant is divided into multiple convex subareas and each subarea is encoded as a convex submodel. Each time only one subarea is active. For detailed discussion about the relation between convex and non-convex plant models, refer to Rong and Lahdelma (2007b). If emissions of the plant are explicitly considered, it is convenient to use fuel characteristics to represent the extreme points of the operating region (characteristic area). The fuel characteristic of a CHP plant defines the relation between fuel consumption and generated heat and power. The operating cost (production cost) of a fossil fuel based plant is mainly determined by the fuel cost, i. e. fuel consumption multiplied by fuel price. Refer to Rong et al. (2014) for detailed discussion about the relation between fuel characteristics and caused emissions.Similar to Rong et al. (2014), a mixture of different fuels is used to affect the tradeoff between economic objective and emission objective. For the system under study, the environmental impact of energy production is associated with CO2 emissions for producing energy. Different types of fuels with different specific CO2 emissions are combusted at plants. However, to facilitate emission calculation, it is assumed that a plant should only combust one fuel. Usually, the fuel with larger emissions is cheaper than that with smaller emissions. For example, coal is cheaper than natural gas. This implies a tradeoff between fuel cost and emissions.When both power market and CO2 emission allowance market coexist, the objective of the CHP planning problem is to simultaneously minimize the overall net acquisition costs for power and heat as well as the emissions costs associated with providing power and heat. In addition to production units (CHP plant, power-only plant, heat-only plant), a CHP system may include non-production components such as bilateral sales and purchase contracts. All components (plants and contracts) can be modeled based on a unified technique as discussed in Rong and Lahdelma (2007b). The emissions for the plant are caused by the fuel combusted at the plant. The emissions for the non-production component are based on a reference system (e. g., coal-fired condensing power plants for power component or coal-fired boiler for heat component). The net acquisition costs consist of actual production costs (fuel costs), costs for purchasing components subtracted by the revenue from selling the produced energy.To facilitate understanding system model for the planning problem presented later, the non-convex plant model is briefly described first.Fig. 1illustrates the non-convex characteristic of a backpressure plant with condensing and auxiliary cooling options. The characteristic is projected onto the p–q (power-heat) plane and the π-coordinate (fuel consumption) at each extreme point is shown numerically in Table 1. The characteristic area is divided into three convex subareas: A1, A2 and A3. A1 is formed by extreme points 1, 8, 9, 2 and 3. This subarea includes the normal backpressure operation mode (line between points 1 and 2), gradual shift into the condensing mode (subarea within points 1, 2 and 3) and the reduction mode (subarea within points 1, 8, 9 and 2). The auxiliary cooling operating mode must be split into two convex subareas A2 and A3. A2 is formed by extreme points 1, 3, 6, 5, and 4 and A3 by points 2, 7, 6, and 3. The plant can only operate in one convex subarea each time, but some extreme points may belong simultaneously to several subareas. To enable (activate) a convex subarea means enabling the extreme points that define the subarea and disabling the remaining extreme points.Due to convexity, when subarea a of plant u is active, the hourly power generation Pu, t, heat generation Qu, t, and operating costs Cu, t= Cu, t(Pu, t, Qu, t) of plant u can be represented as a convex combination of extreme characteristic points (cj, t, pj, t, qj, t) (cost, power, heat) for the subarea below(1)Cu,t=∑j∈Jacj,txj,t,Pu,t=∑j∈Japj,txj,t,Qu,t=∑j∈Jaqj,txj,t,∑j∈Jaxj,t=1,xj,t⩾0,j∈JaHere variables xj, tare used for forming the convex combination, Jais the index set of extreme points for subarea a of plant u and cj, t= πj, tcf, φ(j), t, where πj, tand cf, φ(j), tis fuel consumption and price of fuel φ(j) combusted at plant u and the same with j ∈ Ju(Ja). Note that index set Jain (1) can be replaced by Jufor problem formulation (refer to later formulas (2)–(6)) because xj, t= 0 for non-active subareas.A compact way to represent the convex partition of a non-convex operating area is to tabulate the allocation of the extreme points into different subareas. Table 1 shows the fuel characteristics and related fuel, net and emission costs as well as allocation of extreme points into convex subareas. Refer to later Section 2.3 for computing net and emission costs.The following notation is introduced to formulate the problem.tindex of a period or a point in time. The period t is between points t − 1 and t,number of periods over the planning horizon,super/subscripts or prefixes for power and heat.characteristic areas of all non-convex plants (AN=⋃u∈UNAu),characteristic areas that contain extreme point j,characteristic areas of non-convex plant u,set of extreme points of the operating regions of all components including non-generating components (e. g., contracts). (J=⋃u∈UJu),set of extreme points of the operating regions of all non-convex plants (JN=⋃u∈UNJu),set of extreme points in subarea a,set of extreme points of the operating region of component u ∈ U,set of all components including non-generating components,set of non-convex plants.fuel associated with component u ∈ U and the same for all points j ∈ Ju,extreme point j ∈ Juof operating region of component u ∈ U (fuel consumption, power, heat) in megawatt-hour in period t,emission allowance price in € per ton for period t,price for fuel φ(j) in € per megawatt-hour in period t,power price in € per megawatt-hour on the power market in period t,heat surplus penalty cost in € per megawatt-hour in period t,specific CO2 emission in ton per megawatt-hour for fuel φ(j),heat demand in megawatt-hour in period t.variables encoding the operating level of each component in terms of extreme points j ∈ J in period t,net level of power output in megawatt-hour in period t,heat surplus in megawatt-hour in period t,0–1 variables determining if area a is in operation in period t, a ∈ AN.The above model (2)–(10) is a bi-objective MILP model where the bi-objective LP model (2)–(7) is embedded in the formulation. The objective (2) is to simultaneously minimize the net cost (the first objective) and the emission cost (the second objective). In the first objective, the first, second and third terms represent cumulative costs from all components, revenue from selling produced power on the market and possible penalty costs from heat surplus, respectively. In the second objective, the emission cost is calculated according to caused emissions from all components and emission allowance price. Constraints (3) and (6) represent the convex combination of the extreme points of the operating region of each plant. Power balances (4) determine the net amount of power that can be traded on the market. The first term on the left-hand side is the cumulative power volumes from all components, and xp, tcan be either non-negative or negative. Heat balances (5) state that demand Qtin each period t must be satisfied and heat surplusxq,t+imposes penalty costcq,t+in the first objective. The first term on the left-hand side is the cumulative heat volumes from all components. Constraints (8)–(10) encode non-convex characteristics. Constraints (8) disallow operations in non-active subareas or between subareas by forcing the corresponding xj, tto zero. Constraints (9) state that the exactly one subarea is active for a non-convex plant. It means that non-convex model (2)–(10) reduces to convex model (2)–(7) once active subareas in all plants are determined. For the above formulation, power transaction cost is ignored in the power market. This simplification is acceptable in the broad context of risk analysis.The net cost for the extreme point can be derived from the first objective of (2). The free variables xp, tare solved from constraints (4) and substituted into the first objective, giving∑t=1T(∑j∈J(πj,tcf,φ(j),t−pj,tcp,t)xj,t+cq,t+xq,t+). Then the net cost for point j is defined as(11)c1,j,t:=c1,j,t(cp,t):=πj,tcf,φ(j),t−pj,tcp,tThe emission cost for point is computed according to the second objective of (2)(12)c2,j,t:=c2,j,t(ce,t):=πj,tηφ(j)ce,tIt can be seen that net and emission costs for extreme points are a function of power price and emission allowance price, respectively.In Section 2.2, the bi-objective non-convex CHP planning problem was formulated as a bi-objective MILP problem. Fig. 2(a) shows the non-continuous and the non-convex profile of the Pareto frontier (PF) of the problem characterized by a set of NDLSs. An NDLS can be treated as an entity of the PF. Therefore, our two phase solution approach is developed centered around manipulating NDLSs. In this section, the optimality concept for multi-objective optimization is reviewed first. The concept of point dominance will be extended to the context of NDLSs. Next, the method of constructing NDLSs (feasible outcomes) of the hourly subproblem is given. Then, a two phase solution approach for the hourly subproblem is presented. Next, the merging algorithm (MA) for the multi-period problem is given for approximating the PF.LetXdenote the set of feasible solutions in the decision space andZtheir images in the objective space. The image of solutionx∈Xis f(x) = (f1(x), …, fr(x)), where r ≥ 2. Solving multi-objective optimization problem here is interpreted as generating its efficient setXEin the decision space and corresponding imageZN=f(XE)in the objective spaceRr,called Pareto frontier (PF) or non-dominated set.The dominance relations are defined based on the componentwise ordering ofRr. Considering two pointsz1,z2∈Rr,z1≤z2⇔zk1⩽zk2,k=1,⋯,randz1≠z2z1<z2⇔zk1<zk2,k=1,⋯,r.The relations ≥ and > are defined accordingly.Definition 1Point dominanceForvminproblem,f(x¯)∈Rris dominated byf(x)∈Rriff(x)≤f(x¯),XE:={x∈X:thereexistsnox¯∈Xwithf(x¯)≤f(x)}For multi-objective optimization with integer variables, often supported and unsupported non-dominated outcomes are distinguished (Steuer, 1986). LetR≥r:={z∈Rr,zi⩾0,i=1,…,r}denote the non-negative orthant ofRrandZ≥:=conv{ZN⊕R≥r}. Supported and unsupported non-dominated outcomes are located on the boundary and interior ofZ≥,respectively. In above Fig. 2 (a) Points ‘•’ and ‘○’ represent supported and unsupported non-dominated outcomes, respectively.Now, some definitions related to an NDLS are given. A line segment including NDLS can be presented as [zr,zs] according to its endpointszrandzs, wherez1r<z1s,similar to that in (Belotti et al., 2012). The line segment can be treated as a special set. An NDLS is called convex segment if its two endpoints are supported non-dominated outcomes; otherwise, it is called non-convex segment. Segment PR is the only convex segment illustrated in Fig. 2(a) and the remaining are non-convex. In the following, the dominance relations associated with NDLSs are introduced by extending point dominance in Definition 1.Definition 2Segment-to-segment dominanceFor two NDLSs, [zr,zs] dominates [zx,zy] if for any elementzi∈ [zx,zy], there exists at least one elementzj∈ [zr,zs] such thatzkj⩽zki,k=1,⋯,r. On this basis, ifzj≠zior [zr,zs] − [zx,zy] ≠ ∅ , then [zr,zs] strictly dominates [zx,zy].An NDLS [zr,zs] strictly dominateszxif there is no elementzj∈ [zr,zs] such thatzkj>zkx,k=1,…,r.An isolated pointzxstrictly dominates an NDLS [zr,zs] if for any elementzj∈ [zr,zs], the conditionszkx⩽zkjhold for k = 1, …, r.Fig. 3illustrates dominance relations between NDLSs as well as between an isolated point and an NDLS for the bi-objective case, where (a) and (b) illustrate Definition 2 and (c) and (d) illustrate Definitions 3 and 4 respectively.For the bi-objective case, the slope of an NDLS [zr,zs] (always negative) is defined as(13)γ(r,s)=z2r−z2sz1r−z1sFinally, the notation for the current problem is introduced. Letxtandxdenote the decision variable vector in period t and over the entire planning horizon, respectively(14)z1,t:=f1(xt)=∑j∈Jπj,tcf,φ(j),txj,t−cp,txp,t+cq,t+xq,t+z2,t:=f2(xt)=∑j∈Jπj,tηφ(j)ce,txj,tz1:=f1(x)=∑t=1Tf1(xt)z2:=f2(x)=∑t=1Tf2(xt)The weighted-sum function with a weight vector (λ1, λ2) for period t subproblem, where λ1 ≥ 0 and λ2 ≥ 0 is defined as(15)fλ(xt)=λ1f1(xt)+λ2f2(xt)orzλ(xt)=λ1z1,t+λ2z2,tConstructing NDLSs occurs in the second phase of the two phase procedure presented later, where a series of weighted-sum scalarization problems (single objective) need to be solved with the aid of bounding techniques. The result of solving the individual weighted-sum scalarization problem is a discrete point, called reference outcome. The idea of constructing NDLSs is to construct the neighborhood of the reference outcome as shown in Fig. 4(a), where point ‘A’ represents the reference outcome. The final NDLSs of a given reference outcome are obtained by applying dominance relations among multiple NDLSs according to Definition 2 as shown in Fig. 4(b). The weighted-sum scalarization problem can be solved by specialized efficient algorithms (Makkonen & Lahdelma, 2006; Rong & Lahdelma, 2007b) or general solvers such as Cplex.As mentioned in Section 2.2, solving the original non-convex problem can reduce to solving a convex (LP) subproblem once an active subarea is known. The basis of the LP problem comes from variables of model (2)–(7), i. e., heat surplus variables and extreme points of plants. Then there are |U| + 2 elements in any feasible basis according to (2)–(7). However, for the single objective problem, the feasible basis has only |U| + 1 elements because constraints (4) can be dropped. If f1(xt) is taken as an objective, then the free variable xp, tcan be solved according to constraints (4) and substituted into the objective as shown in (11). If f2(xt) is taken as an objective, then constraints (4) are redundant. It also means that feasible basis of any weighted-sum scalarization problem (15) has |U| + 1 elements. Consequently, the neighborhood can be constructed by introducing an additional element (called adjustment element) into the basis of the reference outcome (called basis for short) to form the feasible basis of the bi-objective problem, called neighborhood basis.Among the solvers for solving the single objective version of the hourly subproblem (2)–(10), the envelope based Branch and Bound (EBB) algorithm (Rong & Lahdelma, 2007b) is the most efficient. In addition, it is easy to identify adjustment elements to form the neighborhood basis. The envelope is the least cost curve of providing heat. In the convex case, it is a piecewise linear convex function (refer to Rong and Lahdelma (2007a) for the algorithm of constructing the envelope.) In the non-convex case, the envelope is a generic piecewise linear function constructed according to individual convex subareas. If the heat surplus variable is in the basis, each plant contributes exactly one element to the basis. Otherwise, only one plant (called regulating plant) contributes two elements. The elements of the plants in the basis come from the envelope of the plants. Here it is worth mentioning that it is possible that linear relaxation of the original problem can produce feasible (optimal) solution to the original problem. In this case, the whole plant is treated as a convex subarea, numbered as the (|Au| + 1)th subarea.Note that the essence of the optimality concept for multi-objective optimization is the tradeoff between objectives. The candidates of adjustment elements should have potential to cause the tradeoff between f1(xt) and f2(xt). They can be on envelopes of f1(xt), f2(xt) and fλ(xt) or in the subareas or in the plant next to the elements in the basis or heat surplus variable. If the elements are selected according to the envelope of fλ(xt), the corresponding elements have to be on the envelopes of f1(xt) or f2(xt).If one or more plants have active subareas (|Au| + 1)th, when the adjustment elements are in the same (natural) subareas as those of the basis elements, the selection has no difference from that of the natural subareas as just mentioned. Otherwise, the selection needs additional steps. First, the corresponding adjustment elements are also selected if they are on the envelopes of f1(xt) or f2(xt). These elements can be used to change the reference outcome (see discussion in the next subsection). In addition, all natural subareas associated with the basis element need to be checked and the elements will be selected according to the relative scale of the envelop slopes.According to the above discussion, it is possible that partial adjustment elements are used to change the reference outcome while the remaining adjustment elements are used to construct the neighborhood. In the following, we first describe how to construct the NDLSs for a given reference outcome. Then, we describe how to change the reference outcome. Note that line segments with non-negative slopes will be discarded automatically during the construction process.To simply the notation, period index t is dropped. For the sake of convenience, the extreme point of the plant is redefined by introducing a plant index explicitly. Let (c1, k, u, c2, k, u, qk, u) denote extreme point k in plant u, where c1, k, u, c2, k, uand qk, uare net cost, emission cost and heat value of point k. Let (z1, 0, z2, 0) denote a reference outcome obtained by solving the weighted-sum scalarization problem (15). At least one point (c1, k(0, u), u, c2, k(0, u), u, qk(0, u), u) of each plant u are in basis of (z1, 0, z2, 0).The salient nature of the envelope-based algorithm is that all of calculations are based on primary operations. However, formulas are different depending on whether heat surplus variablexq+is in the basis or not. For calculating discrete points, the formula are directly adapted from Rong and Lahdelma (2007a). In the following, we give the results without detailed explanation.If heat surplus variablexq+is in the basis of (z1, 0, z2, 0),(16){xq+=∑u∈Uqk(0,u),u−Qz1,0=∑u∈Uc1,k(0,u),u+xq+cq+z2,0=∑u∈Uc2,k(0,u),uIf regulating plant s contributes another point (c1, k(1, s), s, c2, k(1, s), s, qk(1, s), s) with qk(1, s), s> qk(0, s), s. Let qsdenote heat provided by plant s, then(17){qs=Q−∑u∈U,u≠sqk(0,u),uwithqk(0,s),s⩽qs⩽qk(1,s),szi,0=∑u∈U,u≠sci,k(0,u),u+ci,k(0,s),s(qk(1,s),s−qs)+ci,k(1,s),s(qs−qk(0,s),s)qk(1,s),s−qk(0,s),s,i=1,2An NDLS associated with (z1, 0, z2, 0) can be represented as (z1, 0, z2, 0, d1, d2, v), where v ≥ 0, d1d2 < 0, γ = d2/d1 is the slope of the line segment. Parameter v is the length of the segment and an isolated point is treated as a special case of the NDLS with v = 0. The formula for the NDLS is given below(18){z1=z1,0+vd1z2=z2,0+vd2Similarly, formulas for calculating the parameters (d1, d2 and v) associated with the NDLS are also different depending on whether heat surplus variablexq+is in the basis of (z1, 0, z2, 0) or not. The results are given in Appendix I.Next, we consider the situation when the reference outcome (z1, 0, z2, 0) changes into a new reference outcome (z^1,0,z^2,0), where the point in some plant j changes. Again, results are different depending on whether heat surplus variablexq+is in the basis of (z1, 0, z2, 0) or not. Letqu^(u∈U)denote the heat provided by regulating plant u for (z^1,0,z^2,0) if heat surplus variable is not in its basis.If heat surplus variablexq+is in the basis of (z1, 0, z2, 0), then it is possible to generate a new reference outcome with the basis not includingxq+if there exists a plant j with point (c1, w, j, c2, w, j, qw, j), where qw, j< qk(0, j), j. Letq^jdenote the heat provided by plant j, ifqw,j⩽q^j,then plant j is eligible to be a regulating plant.q^jand (z^1,0,z^2,0) can be obtained according to a similar formula of (17). The neighborhood of (z^1,0,z^2,0) can be generated according to (A.4) and (A.6) in Appendix I if relevant adjustment elements exist.If heat surplus variablexq+is not in the basis of (z1, 0, z2, 0), there are three cases for changing the reference outcome.(a)Both the regulating plant s and two basis points of plant s remain unchanged while plant j ≠ s changes its basis point into point w, i. e., w ≠ k(0, j). Thenq^sand (z^1,0,z^2,0) can be obtained according to a similar formula of (17).The regulating plant s remains unchanged while one or both basis points of plant s are changed while the basis points for the remaining plants remain unchanged, then the heat provided by all plants remains unchanged. If qsfalls between the q values of two new basis points for plant s, then (z^1,0,z^2,0) can be obtained according to the second formula of (17).The regulating plant changes to a new plant j ≠ s and a new point of plant j is introduced into the basis. The basis point of plant s will be either point k(0, s) or k(1, s) and basis points of the remaining plants remain unchanged, thenq^jand (z^1,0,z^2,0) can be obtained by a similar formula of (17).Then, the neighborhood of (z^1,0,z^2,0) can be generated according to (A.4), (A.6) and (A.8) in Appendix I if relevant adjustment elements exist.If the hourly subproblem is solved using the ɛ-constraint method where the second objective of (2) is transformed into a constraint while the first objective is minimized. Then, for a given ya, t, the number of constraints is |U| + 2 because constraints (4) can be dropped as described in Section 2.3. It means that the basis structure for constructing NDLSs should be similar to that of the ɛ-constraint method.Lemma 5For a given NDLS generated by the method described inSection 3.2.2, if two endpoints on the NDLS are elements of the PF, then the NDLS are elements of the PF.The NDLSs generated by the method described in Section 3.2.2 are feasible outcomes of the problem. Each adjustment can at most generate one NDLS. The elements on the PF will be generated by certain adjustments. The slope of the line segment is the image of the search gradient in the decision space and two points in the objective space can solely determine slope of the line segment. If two endpoints are the elements of the PF, then the slope of the line segment is the image for the gradient of optimality.□According to Lemma 5, the optimality of an NDLS constructed by the method in Section 3.2.2 can be verified by checking two points on the segment.The two phase method divides the procedures for finding the non-dominated outcomes into two phases. In the first phase, supported non-dominated outcomes are computed. In the second phase, unsupported non-dominated outcomes are computed. Up to now, the two phase methods are mainly used to solve the multi-objective integer (combinatorial) problem (Przybylski et al., 2008; 2010; Steiner & Radzik, 2008; Visée et al., 1998). Different from the combinatorial problem, the procedure for dealing with our problem (an MILP) needs to find NDLSs instead of discrete points in the second phase. For the bi-objective case, usually, in the first phase, the dichotomic search algorithm (DSA) can be used to find supported non-dominated outcomes (Aneja & Nair, 1979; Figueira, Paquete, Simões, & Vanderpooten, 2013) by solving a series of weighted-sum scalarization problems. Here we applied the similar DSA procedure (Rong et al., 2014) in conjunction with a variant of EBB algorithm in the first phase. The profile of supported outcomes (points ‘•’) has been shown in Fig. 2. The envelopes of the first and the second objective are constructed in the first phase according to algorithm in Rong and Lahdelma (2007a) and remain unchanged during the computation process of the second phase. In the following, we mainly focus on the second phase procedure.Assume that supported dominated outcomes are arranged in an increasing order of the first objective, the second phase procedure explores sequentially the triangle (shown in Fig. 2(b)) derived by two consecutive supported non-dominated outcomes for possible convex and non-convex NDLSs as mentioned in Section 3.1. The EBB algorithm in conjunction with the method for constructing NDLSs in Section 3.2.2 is used to solve the problem.For a given triangle ▵zazbwithz1a<z1b,for constructing NDLSs, reference outcomes need to be found first by solving the weighted-sum problem (15) withλ1=z2a−z2bandλ2=z1b−z1ausing bounding techniques. Then NDLSs will be constructed using the method described in Section 3.2.2. The upper bound (ub) for the problem is shown in Fig. 5. Initially,ub=λ1z1b+λ2z2a(Fig. 5(a)). For ease of manipulation, only the endpoints of an NDLS are used to compute ub. If more points on the segment are used, the ubmay be tighter. However, it depends on the profile of the segment. In Fig. 5(c), the ubcannot be reduced if more points on segment [zi,zi + 1] are used. The principle of computing ubfor thevminproblem is similar to that for computing the lower bound for thevmaxproblem (Visée et al., 1998). Suppose that there are m feasible non-dominated outcomeszi(i = 1, …, m) within the triangle withz11<,…,<z1m. Letz0 ≔zaandzm + 1 ≔zb. The upper bound is given below(19)ub=maxi=0,…,m(λ1z1i+1+λ2z2i)Algorithm 1 in Appendix II gives the procedure for generating the upper bound for the weighted-sum problem (15) according to the endpoints of NDLSs. For an NDLS represented as (z1, 0, z2, 0, d1, d2, v), only one endpoint (z1, 0, z2, 0) is explicitly given. The other endpoint is (z1, 0 + d1v, z2, 0 + d2v). This representation makes the NDLS bear similarity to an isolated point and NDLSs can be arranged according to an increasing order of z1, 0. However, the original NDLS constructed by the method in Section 3.2.2 may need to be shortened (cut) for different reasons, e. g., dominance checking, feasible bound checking and pseudo segment discussed a little later. For cutting operations, (z1, 0, z2, 0) and v may be subject to change while d1 and d2 remain unchanged. The first objective of the other endpoint can be larger or smaller than z1, 0 depending on whether d1 > 0 ( < 0). It means that the points used to compute the ubneed to be identified dynamically. In addition, the number of points involved in computation is related to the pattern of the segment. As shown in Fig. 2(b), if NDLSs assume a continuous pattern (▵RS), the number of points involved in computation can be reduced because endpoints for two consecutive segments coincide. As shown in Fig. 4(b), the same (z1, 0, z2, 0) can be associated with at most two NDLSs after dominance checking and the segment with d1 < 0 is always placed before the segment with d1 > 0 if there are two. Algorithm 1 in Appendix II gives the procedure for computing the ub. In the algorithm NDLSs are arranged in a non-decreasing of z1, 0. Ifz1,0i=z1,0i+1,thend1i<0andd1i+1>0;z1,0i=z1,0i+1⇒z2,0i=z2,0i+1. The tolerance for equality is ɛ1 = 0.012 in the algorithm, i. e., 0 ≤ ɛ1 ≤ 0.012 implies 0. This relation holds for all the endpoints for NDLSs.The dominance checking is conducted according to Definitions 2–4 in Section 3.1. For the bi-objective case, it is convenient to proceed the checking according to the slope of the segment as well as the slope between two consecutive reference outcomes. There are different cases according to the difference between these two slopes and the sign of d1. Fig. 6illustrates two cases. Assume that a new segment associated with reference outcomeziwill insert before pointzaaccording to(z1,0i,z2,0i). In the figure, ‘•’ represents pointziwhile ‘○’ represent pointsza − 1 andza. The other endpoints of the segments associated withza,za − 1 andziarezA,zBandzCrespectively.In Fig. 6(a), γ(za − 1,zi) > 0 while γ(za,zi) < 0. It means that(z1,0i,z2,0i)is dominated by(z1,0a−1,z2,0a−1). It is better that segment [zi,zC] is checked against [za − 1,zB] first because cutting operations will be significant by [za − 1,zB]. Two segments will cross if va − 1 and viare sufficiently large because γ(za − 1,zB) < γ(zi,zC). The cross point is ‘D’ as shown in the figure. Segment [zi,zD] is dominated by [za − 1,zD] while segment [zD,zB] is dominated by [zD,zC]. Afterwards, segment [zD,zC] continues to check against the segments prior to [za − 1,zD]. However, it is not necessary to check against segment [za,zA]. In Fig. 6(b), γ(za − 1,zi) < 0 and γ(za,zi) < 0. It does not matter which segments are checked against first. Suppose that segment [zi,zC] is checked against [zazA] first. Two segments will cross at some point if vaand viare sufficiently large because γ(za,zA) < γ(zi,zC). As shown in the figure, point ‘A’ happens to be the cross point and segment [zC,zA] is dominated by [za,zA]. Then segment [zi,zA] needs to be checked against [za − 1,zB]. It can be seen that segment [zD,zB] is dominated by [zi,zA]. As mentioned in Section 3.3.1,z1,0i=z1,0i+1⇒z2,0i=z2,0i+1,thez1Dshould be a little smaller thanz1,0i,i. e.,z1D:=z1,0i−ɛ2,ɛ2>0. In our algorithm, 0.012 < ɛ2 < 0.05.As illustrated in Fig. 5, it is required that NDLSs are within ▵zazb. Usually, an NDLS within ▵zazbare generated according to the segments whose one or two endpoints are initially outside the triangle. During the process of checking the feasible bounds for the segment (z1⩽z1bandz2⩽z2a), the slope of the segment also needs to be checked. It is pretty easy to check whether supported non-dominated outcomes zaand zbare on the current segment by checking the slope of the segment against the slope of the convex segment ( − λ1/λ2). If yes, then the current segment is a convex segment (refer to Section 3.1). The construction process within the triangle ends once the convex segment is identified because all the NDLSs within the triangle are dominated by it. This implies that there are no unsupported non-dominated outcomes within the triangle.As illustrated in Fig. 2(b), non-convex NDLSs (at least one endpoint is an unsupported outcome) may assume a continuous pattern (e. g., all segments within ▵RS) or a non-continuous pattern (e. g., segment [zA,zY] within ▵AB or segment [zT,zU] within ▵ST) or a mixed pattern where some segments are continuous while others not. Segments [zA,zY] and [zT,zU] are called left and right continuous patterns, respectively for distinguishing purpose. In terms of segment [zA,zY], non-dominated outcomes will be points on [zA,zY] whenz2Y⩽z2⩽z2Aand reduce to a single point(z1B,z2B)whenz2B⩽z2⩽z2Y−ɛ3(ɛ3>0). Usuallyz2Y−z2B≫ɛ3. For our problem, ɛ3 = 0.7 whenz2Y−z2B≫0.7and ɛ3 = 0.01 when0.05<z2Y−z2B<0.7. In terms of segment [zT,zU], it means that a small change in z2 can cause a big jump in z1.Pseudo segment refers to the situation where non-dominated outcomes on the partial segment reduce to a single point. This situation may happen to left continuous non-convex segments and convex segments. Take non-convex segment [zA,zY] an example, let [zA,zY] be the original segment constructed by the method described in Section 3.2.2 andzW is a point on [zA,zY] wherez2W>z2Y. In some situations, non-dominated outcomes will reduce to(z1B,z2B)whenz2⩽z2W. It means that segment [zW,zY] is a pseudo segment. An isolated point can be either a supported or an unsupported non-dominated outcome depending on the location of the segment. An isolated supported non-dominated outcome may occur when a pseudo convex segment occurs.The fundamental causes for the pseudo segment should be attributed to the non-convex and non-continuous characteristics of power plants. However, we did not find an effective way to avoid it during the segment construction process. The pseudo segment can be identified and removed with the aid of the ɛ-constraint method. According to numerical experiments, the pseudo convex segment occurs occasionally when γ(za,zb) < −M andz1b−z1a<ɛ4,where M > 0 (a big number) and ɛ4 > 0. For our problem, only one occurrence is identified, where M > 650 and ɛ4 < 0.4. The occurrence of the pseudo non-convex segment is more frequent and it depends on many factors such as the slope of the segment (d2/d1), the slope between two consecutive reference outcomes, and the relative gap between these two slopes.The NDLSs for the hourly subproblem will be subject to further processing to obtain the PF for the multi-period problem after they are constructed. More explicit representation is needed for NDLSs. Two endpoints of each NDLS (e. g., points ‘•’ and ‘○’ as illustrated in Fig. 2) used to calculate ubin Algorithm 1 of Appendix II are explicitly given. The NDLS is re-represented as (z1, 0, z2, 0, γ, θ), where (z1, 0z2, 0) is the endpoint, γ is the slope and θ an auxiliary parameter.The slope associated with a supported non-dominated outcome (including isolated one as mentioned in Section 3.3.4) should be the one with the immediately next supported non-dominated outcome while the slope associated with an unsupported non-dominated should be the one with the immediately previous or next non-dominated outcome. Take ▵AB in Fig. 2(b) as an example, γ(A, B) is associated with point ‘A’ while γ(A, Y) is associated with point ‘Y’. The slope of the left continuous segment is the one with the immediately previous outcome while the slope of the right continuous and continuous segment is the one with the immediately next outcome. For an isolated unsupported non-dominated outcome and the last supported non-dominated outcome or only one outcome resulted from the only one extreme point in the active convex subareas of all plants, the slope is set to a large positive value.Parameter θ is used to distinguish between a supported and an unsupported outcome, segment patterns (e. g., continuous, left and right continuous) or identify how many unsupported non-dominated outcomes are used to represent segments within the triangle derived by two consecutive supported outcomes. The θ is defined below.ba non-negative integer associated with a supported non-dominated outcome where b unsupported non-dominated outcomes used to represent NDLSs within the triangle derived by it and the immediately next supported outcomeassociated with an isolated supported non-dominated outcomeassociated with the only non-dominated outcome in a hourly subproblemassociated with an unsupported non-dominated outcome with continuous segment patternassociated with an unsupported non-dominated outcome with right continuous segment patternassociated with an unsupported non-dominated outcome with left continuous segment patternassociated with an isolated unsupported non-dominated outcomeIn Appendix II, Algorithm 2 gives the procedure for computing the NDLSs for a given pair of supported non-dominated outcomes (within a given triangle). Algorithm 3 gives the two phase procedure for computing NDLSs.Here the practice of obtaining the PF of the convex CHP planning problem (Rong et al., 2014) is extended to the current non-convex problem, i. e., aggregating the PF of hourly subproblems according to a non-decreasing order of slopes for two consecutive supported non-dominated outcomes while unsupported non-dominated outcomes just move along the supported non-dominated outcomes. The notation used is similar to that in Algorithm 3 of Appendix II but the time index t will be attached for period t subproblem, i. e.,(z1,0,ti,z2,0,ti,γti,θti)is used to denote NDLS i. LetZN,tdenote the set of non-dominated outcomes used to represent NDLSs, i. e., endpoints of NDLSs.|ZN,t|=m+2in Algorithm 3 of Appendix II. If|ZN,t|=1,then it means that there is only one non-dominated outcome in period t. It is a trivial case to merge. It is simply to add each non-dominated outcome with (z1, 0, t, z2, 0, t) and remaining associated parameters remain unchanged. In the following, assume that|ZN,t|⩾2.In Appendix II, Algorithm 4 gives the procedure for updating unsupported non-dominated outcomes associated with a supported non-dominated outcome according to the rule that the unsupported outcomes move along the supported outcome. Algorithm 5 gives the procedure for updating results according to slopes of the two consecutive supported outcomes and Algorithm 6 gives the procedure for merging the PF of a two period problem. Finally, Algorithm 7 gives the merging procedure for approximating the PF of a multi-period problem.Lemma 6Algorithm 7 in Appendix II can guarantee the optimality of supported non-dominated outcomes and convex segments.The above result is guaranteed by merging operations of the algorithm, i. e., arranging the non-dominated outcomes according to a non-decreasing order of slopes for two consecutive supported non-dominated outcomes. This is the rationality behind the merging algorithm. However, there is no guarantee for optimality of unsupported non-dominated outcomes.Finally, Appendix IV illustrates the second phase procedure for the two phase algorithm.To evaluate the effectiveness of the two phase approach for the hourly subproblem (Algorithm 3 in Appendix II) as well as the merging algorithm (MA) to aggregate the non-dominated segments for the hourly subproblems (Algorithm 7 in Appendix II). Cplex (ILOG IBM, 2009) based augmented ɛ-constraint method (Mavrotas, 2009) was implemented as a benchmark. For the two phase approach, the EBB algorithm (Rong & Lahdelma, 2007b) was adapted to solve the weighted-sum functions in the first phase and to find feasible outcomes for constructing NDLSs in the second phase. The EBB is on average 785 times faster than Cplexfor solving a single objective hourly subproblem (Rong & Lahdelma, 2007b). The two phase algorithm and the MA were implemented in C + + in Microsoft Visual Studio 2003 environment. All experiments were carried out on a 2.49 GHz Pentium PC with 2.9 GB RAM under the Windows XP operating system.We used the same test problems as in Rong and Lahdelma (2007b). A total of 6 test problems were generated according to three real plants (A1, B1 and C1) and three artificially derived plants (A2, B2 and C2) based on three real plants. A1 is a backpressure plant and the other two (B1 and C) are combined steam and gas cycles. Each real plant consists of 14 convex subareas and each derived plant 8 convex subareas. A1, B1 and C1 have 28, 27 and 28 extreme points, respectively. Each derived plant has 16 extreme points. Here we give a slightly different representation of test problems from that in Rong and Lahdelma (2007b). We mainly focus on the number of binary integer and continuous variables. The number of binary variables is the number of convex subareas for all plants and the number of continuous variables is the number of extreme points for all plants plus the variables for the power output net level and for heat surplus. The dimensions of test problems are shown in Table 2. In ‘Plants’ column of the table, ‘a’ and ‘r’ stand for ‘artificial’ and ‘real’, respectively. That is, ‘3a + 1r’ means that D1 consists of three artificially derived plants and one real plant. For a planning problem with T hours, the number of binary integer and continuous variables is proportional to T. For example, for D2, the number of binary and continuous variables is 42T and 85T, respectively.In the current study, the fuel combusted at each plant needs to be considered explicitly since emission cost is explicitly considered as an objective. It is assumed that plants A1 (A2), B1(B2), C1(C2) are coal, gas and oil fired, respectively. To form a valid test problem, the heat demand is generated based on history data of a Finnish energy company, power price is generated based on the spot price history of the Nordic power market (Pool, 2004) and emission allowance price is generated based on uniform distribution within [6, 16] € /ton according to the price range on the European market (Abadie & Chamorro, 2008).Note that D2 consists of three real plants. We will report detailed results for this problem later.The hourly subproblem is really hard due to the non-convexity of plant characteristics though the problem size is not large. We did numerical experiments with a limited planning horizon. For the first three problems in Table 2, we solved a planning horizon with 3024 hours instead of 8760 hours (one year) while for the last three problems, we solved a monthly planning horizon (672 hours).There are two reasons for this. On the one hand, as mentioned in Section 3.3.4, it is possible to generate pseudo segments when discontinuous patterns of the PF occur. Numerical experiments showed that the frequency of discontinuous patterns for the PF is quite high. For example, the PF can consist of about 30 NDLSs, where more than 15 endpoints need to be checked for possible pseudo segments. It is time consuming to check and remove pseudo segments. On the other hand, 3024 hours = 18 weeks = 4.5 months (1 month = 4 weeks) and a little more than one-third year. It is sufficient to capture the performance of the algorithm against the variation of demand patterns, power prices and emission prices as shown later in Fig. 7for problem D2. It can also be seen that the degree of non-convexity for the test problems is reduced when the artificially derived plants are introduced (see RCs measure in Table 3.)The Cplex based ɛ-constraint method cannot solve a daily (24 hours) subproblem in some cases (see later Tables 4and 5). Therefore, five daily subproblems were formed by choosing evenly distributed starting hour 0, 750, 1500, 2250 and 3000 over the planning horizon for problem D2. These problems are identified by D2(0), D2(750), D2(1500), D2(2250) and D2(3000), respectively. To test the effectiveness of the MA, each daily subproblem was further divided into smaller planning horizons such as 1, 4, 8, 12, 16, 20 and 24 hours. For the ɛ-constraint method, the range of the second objective f2 was obtained by computing the lexicographic minimal (lexmin) solutionsx1 andx2 with respect to f1 and f2.Letx1:=arglexmin(f1(x),f2(x),x∈X)andx2:=arglexmin(f2(x),f1(x),x∈X). Letz1 ≔ f(x1),z2 ≔ f(x2). Then the right-hand-side coefficients related to f2 were chosen asz21−i(z21−z22)/N,i=1,…,N−1. For the augmented ɛ-constraint method, no weakly non-dominated outcomes are generated. However, for our problem, it is possible that discontinuous patterns occur where several right-hand-side coefficients coincide with a single non-dominated outcome as mentioned in Section 3.3.4. Thus, the number of actually generated non-dominated outcomesN^should be not larger than N + 1, includingz1 andz2. In the following, the performance indicators (PIs) for evaluating the solution quality of optimizers are briefly reviewed before the computational results are presented.In the literature, some researchers proposed or reviewed the PIs for evaluating multi-objective optimizers from different perspectives (Datta & Figueira, 2012; Lizárraga, Hernández, & Botello, 2008; Okabe, Jin, & Sendhoff, 2003; Saker & Coello, 2002; Zitzler, Knowles, & Thiele, 2009). Usually, the quality of a non-dominated set can be assessed from three aspects: the size of the non-dominated set, the accuracy of the solutions in the set, i. e., the closeness of the solutions to the theoretical PF and distribution and spread of the solutions. In case the theoretical PF is not known, only the relative closeness can be obtained.Our approach generates a set of NDLSs instead of discrete points in the objective space based on a two phase approach. The size of the non-dominated set is infinite and the NDLSs are well-distributed in the objective space as shown in Fig. 2 of Section 3. Therefore, the evaluation mainly focuses on the accuracy of the solution set.In the literature, there are three PIs that can address the accuracy: error rate (ER), generational distance (GD) (van Veldhuizen, 1999) and hyper-volume indicator (Zitzler & Thiele, 1999). The ER measures the percentage of solutions from the solution set that are not the member of the theoretical PF. The GD measures the distance between the solution set and the theoretical PF. The hyper-volume indicator measures the volume that is dominated by the solution set. The larger the indicator value, the better the approximation set. Generally speaking, it is difficult to judge the performance of the multi-objective optimization algorithm because there is no universally accepted definition of optimum in the multi-objective optimization cases as in the single optimization (Saker & Coello, 2002). Also, the evaluations according to different PIs may disagree with the common sense of when a multi-objective algorithm is performing better than another (Lizárraga et al., 2008).For our problem, it is difficult to calculate the hyper-volume indicator because the solution set consists of NDLSs with the nature of non-continuity and non-convexity as shown in Fig. 2. The ER and GD are used to evaluate the accuracy of the solution set. It is straightforward to calculate the distance between the points generated by the ɛ-constraint method to the NDLSs generated by our approach. Let gidenote the GD between point i on the theoretical PF:={(z^1i,z^2i),i=1,…,N^}(ZN) to the approximate PF:={(z1i,z2i),i=1,…,m+1}generated by our approach. Let j and k be two consecutive non-dominated outcomes on the approximate PF withz1j<z^1i<z1k. Then,gi=|γ(j,k)(z^1i−z1j)+z2j−z^2i|/1+γ2(j,k)if there is a line segment between j and k andgi=min((z^1i−z1j)2+(z^2i−z2j)2,(z^1i−z1k)2+(z^2i−z2k)2)otherwise.A natural PI is average GD (GD¯). Here we also introduce max GD (GD^), which is used to evaluate the worst case performance of the algorithm. In addition, in most cases, the relative GD (GDr) is more meaningful than the absolute value of GD. The distance of the non-dominated outcomesz1 andz2 mentioned at the end of Section 4.1 is used as the reference distance(20)GD¯=∑i=1N^gi2N^(21)GD^=maxi=1,…,N^gi(22)GDr=100GD^(z11−z12)2+(z21−z22)2(%)Finally, the ER is associated with GD, defined as follows(23)ER=100|(z^1i,z^2i)∈ZN,gi>0,i=1,…,N^|N^(%)We have obtained the exact PF of the test problems in Table 2 for the chosen planning horizon by using the two phase approach with the aid of the ɛ-constraint method because the two phase approach cannot avoid pseudo segments as mentioned in Section 3.3.4. The results are given in Table 3. In the table, NDs, CPU and RCS represent the number of NDLSs, solution time in seconds and the ratio of convex line segments, respectively. For counting NDLSs, a jump is treated as an NDLS. For example, there are two NDLSs within triangle ▵AB in Fig. 2(b). One is segment AY and the other is a jump from Y to B. This is consistent with the convention that an isolated point is treated as a special type of NDLS. In addition, the number of NDLSs is directly related to the number of non-dominated outcomes recorded in the algorithm using this counting method. It can be seen that the overall solution efficiency of the two phase method in conjunction with MA is not bad according to Table 3.As mentioned in Lemma 6, the convex segments for the hourly subproblems can maintain their optimality in the multi-period planning problem by our MA. The convex segments show the partially convex nature of the problem. RCs can partially reflect the hardness of the problem:the smaller the RCs, the harder the problem. As shown in Table 3, RCs has tendency to increase when the number of artificially derived plants increases.In the following, the report mainly focuses on problem D2. The results of the Cplex based ɛ-constraint method are reported first. Let N = 20T, i. e., the sampling right-hand-side coefficients related to f2 are proportional to T. The maximum generated non-dominated outcomes should be 20T + 1. Tables 4 and 5 give the number of non-dominated outcomes and solution time (s) for a given sampling interval for different T for problem D2, respectively. For the Cplex solver, only the relative objective gap is set explicitly to a suitable level according to the range of the objective values to guarantee the optimality of the solutions. Based on numerical results, for problem D2(3000),Cplex can only solve partial instances of 24 hour planning horizon with larger right-hand-side coefficients related to f2. As the right-hand-side coefficients become smaller, the solver exits. A possible reason is that some default limits of the solver are exceeded before the optimal solution is found.For problem D2, we have solved 18 weekly planning problems with non-overlapping periods over the planning horizon of 3024 hours. Fig. 7 gives the ratio of convex segments for weekly planning problems of problem D2 for our approach. It can be seen that D2(0) and D2(750) are in the weeks with higher RCs while D2(1500), D2(2250) and D2(3000) are in the weeks with lower RCs. More specifically, the RCs of D2(0), D2(750), D2(1500), D2(2250) and D2(3000) are 0.69, 0.57, 0.2, 0.18, and 0.11. It means that hardness of the problem is also related to the interaction between load profiles and plant characteristics on top of the plant characteristics.When the results of Table 3 for D2 are compared with those for Tables 4 and 5, our approach is clearly superior to the ɛ-constraint method in terms of solution efficiency. Next, the accuracy of the non-dominated set for the proposed approach is evaluated against the ɛ-constraint method. Tables 6and 7give the ER and GDrfor different planning horizons, respectively.According to Table 6, the ER has tendency to increase as the planning horizon increases except D2(0). D2(0) is an instance showing strong convex nature and the ER is kept stable regardless of the planning horizon because the MA can generate the exact PF for the convex problem. The tendency of theGD^(not shown explicitly) also shows the similar tendency. However, it seems that GDrdoes show this kind of tendency according to Table 7. It means that accuracy of the MA is not bad in a relative sense.

@&#CONCLUSIONS@&#
