@&#MAIN-TITLE@&#
Sleep stages classification based on heart rate variability and random forest

@&#HIGHLIGHTS@&#
We classify different sleep stages with 41 HRV features through random forest.We evaluate the importance of every feature for sleep staging.The classification performance is in prior to previous relevant studies.Some new proposed features perform even better than the conventional ones.The first 10 features could lead to considerable results compared to all features.

@&#KEYPHRASES@&#
Sleep stage,Heart rate variability,Random forest,Feature importance,

@&#ABSTRACT@&#
An alternative technique for sleep stages classification based on heart rate variability (HRV) was presented in this paper. The simple subject specific scheme and a more practical subject independent scheme were designed to classify wake, rapid eye movement (REM) sleep and non-REM (NREM) sleep. 41 HRV features extracted from RR sequence of 45 healthy subjects were trained and tested through random forest (RF) method. Among the features, 25 were newly proposed or applied to sleep study for the first time. For the subject independent classifier, all features were normalized with our developed fractile values based method. Besides, the importance of each feature for sleep staging was also assessed by RF and the appropriate number of features was explored. For the subject specific classifier, a mean accuracy of 88.67% with Cohen's kappa statistic κ of 0.7393 was achieved. While the accuracy and κ dropped to 72.58% and 0.4627, respectively when the subject independent classifier was considered. Some new proposed HRV features even performed more effectively than the conventional ones. The proposed method could be used as an alternative or aiding technique for rough and convenient sleep stages classification.

@&#INTRODUCTION@&#
As an important physiological activity of people, sleep contributes to self-repairing and self-recovering. However, as living rhythm quickens and lifestyle changes, sleepiness and sleep structure disorder have become severe factors threatening people's normal daily life and public safety. Thus it is of great importance to monitor sleep and analyze sleep structure.Nowadays, the ‘gold standard’ method of evaluating sleep structure is overnight polysomnography (PSG). It is a multi-parametric system which routinely records many kinds of biological signals synchronously, such as electroencephalogram (EEG), electrooculogram (EOG), electromyogram (EMG), blood oxygenation, airflow, and respiratory effort. Based on the golden manual sleep classification criterion, an overnight sleep was divided into 30-s epochs, and every epoch was categorized as wake, rapid eye movement (REM) sleep or an approximate continuum of depth (stages 1–4) during non-REM (NREM) sleep. In 2007, American Academy of Sleep Medicine (AASM) released the latest edition of sleep staging criterion [1], where NREM3 and NREM4 were combined into a single stage and some other details were changed. To overcome the tedious manual work, many automatic PSG systems have appeared. And most of them can give many annotations such as respiratory events and body movements. However, the PSG system is rather expensive and too cumbersome for using by untrained persons. And it is very intrusive for normal sleep because of too many electrodes. Therefore, PSG is restrictively used in specialized hospital-based sleep laboratory and suffers difficulty in wider application like home nursing.There has been considerable interest in the development of some alternative reliable low cost sleep staging techniques. In fact, due to the modulation of autonomic nervous system (ANS), some other biological signals such as heart rate variability (HRV), respiratory effort, and oxygen saturation also represent characteristic behaviors that vary according to sleep type and depth. Specially, HRV is generally derived from RR intervals of electrocardiogram (ECG) that can be acquired from some ambulatory devices with only a few electrodes. It shows the advantages of convenience and low-cost, and is widely used as noninvasive method to get insight into ANS functioning. Numerous investigations have demonstrated that heart rate (HR) decreased in associated with decreased variability in NREM sleep, while HR increased, with increased variability in wake and REM sleep [2–5]. A decreased ratio of the power in low frequency (LF, 0.04–0.15Hz) and high frequency (HF, 0.15–0.4Hz) band (LF/HF) is associated with NREM sleep and significantly increased LF/HF is shown in REM sleep [6]. In addition, some nonlinear measures like fractal component [7] and detrended fluctuation analysis (DFA) [8] during different sleep stages show significant differences as well.Thus the technique of HRV based sleep staging has attracted much attention in the past decades. Nason et al.[9] applied the non-decimated wavelet packet transform to model HRV of infants. Through the linear discriminate analysis, classification accuracy between sleep and wake was reported as 75–90% for the infants at different stages of development. Adnane et al.[10] showed that analyzing HRV in time domain, frequency domain, and by DFA and windowing DFA one can classify wake and sleep to an average accuracy of 79.31% and Cohen's κ statistic [11,12] of 0.41 using supporting vector machine.But the above literatures were restricted in subject specific scheme, where the training and testing set come from the same subject. In order to develop more practical solution, the subject independent scheme, where the training and testing group are selected from different subjects should also be discussed. Researchers have recognized this problem and made some significant explorations.A comparison between HRV and actigraphy for sleep-wake identification in infants was made by Lewicke et al.[13]. With 13 infants combined into training data and the other 12 served as testing set, the performance with accuracy of 79.7% was reported. Mendez et al.[14] used varying autoregressive model to classify REM and NREM sleep by hidden Markov model. With training and testing set including 12 different subjects respectively, their result agreed with R&K standard criteria of average 79.3%.These investigations strode an important step to more practical study. However, after decades of investigation, it is still an open question and many problems still need to be solved yet. Further exploration employing more effective HRV features and classification methods should be made to improve classification accuracy. To the authors’ knowledge, although large amount of HRV features have been extracted for sleep stages classification, few literatures have evaluated the importance of single feature.In this paper, a total of 41 comprehensive HRV features including time domain measures, frequency domain measures, and nonlinear parameters were extracted. 25 features were proposed or applied to sleep study for the first time. Then the classification method of random forest (RF) was applied to distinct wake, REM sleep and NREM sleep within two schemes, i.e. subject specific and subject independent scheme. Additional, the importance of every single feature was assessed and the appropriate number of features was explored as well.The public database Sleep Heart Rate and Stroke Volume Data Bank (SHRSV) [15] was used in our study. It was provided to aid research leading to development of automatic classification of sleep stages from heart rate related data. Between 1999 and 2005, overnight PSG records corresponding to 45 healthy subjects, aged 16–61, with 28 men and 17 women, were acquired in the Sleep Center Institute of Psychophysiology and Rehabilitation of Kaunas University of Medicine. The whole sleep was classified as wake, REM sleep and stage 1, 2, 3 and 4 of NREM sleep at 30-s epochs according to sleep scoring manual by experienced doctors.The full database only contains RR sequence and stroke volume (SV) instead of the entire PSG signals. RR intervals were extracted from ECG signals at a sampling frequency of 500Hz by automated rhythmus analysis with automatic and manual review and correction. Besides, the stationarity of RR records was also described. For this study, only data labeled with ‘stationary’ were analyzed, while the others labeled with ‘artifact’ or ‘non-stationary’, and the records with else abnormal phenomenon such as premature beats, atrial fibrillation, paroxysmal tachycardia, sleep apnea, etc., were excluded. In addition, the subtle stages 1, 2, 3 and 4 of NREM sleep were combined into NREM sleep, meanwhile wake and REM sleep remained as the same. After records filtering and stages combination, the time length of whole sleep for each individual were 5.09±1.35h (mean±standard deviation). The percentage of each stage takes in the whole night data was listed in Table 1.RR preprocessing is a prerequisite for extracting effective HRV features. In order to remove out the influence of outliers, each RR value was compared to the mean value (mRR) within a 21 points rectangle window centered around the tested value. If RR was less than 0.5*mRR or lager than 1.5*mRR, it was replaced by mRR, otherwise it remained the same. This obtained sequence was called RRnorm.Afterwards, each RR sequence was sectioned. At first, each RR record was divided into 30-s epochs synchronizing in time with sleep stages classification. And then the whole record was further segmented into sections with a duration of 5-min centered around every 30-s epoch [16,17]. Every overlapping 5-min section belongs to a specific sleep stage and it is the data to be analyzed. For convenience, those 5-min sections were still called RRnorm.The assembly of HRV features examined in this study included traditional time domain features, frequency domain features, and some nonlinear analysis measures. To the authors’ knowledge, some of the features were proposed or applied to sleep study for the first time in our paper.Time domain features, which analyze the variation of RR intervals through statistical methods, are the simplest and most intuitive measures to characterize HRV. The time domain features adopted in our study were listed in Table 2.Frequency domain features of HRV were important indicators to reflect the activity of ANS. The power in LF (0.04–0.15Hz) and HF (0.15–0.4Hz) band were related to the regulation of sympathetic (SNS) and para-sympathetic (PNS) nervous system, respectively. Some literatures also demonstrated that medium frequency (MF, 0.1–0.15Hz) power was related to baroreflex activity [18,19]. To make full use of spectral information of HRV, LF was further divided into true LF (TLF, 0.04–0.1Hz) and MF in our study. The combination of LF and HF, denoted total frequency (TF) in our study was also investigated. And more comprehensive measures, i.e. spectrum power, mean frequency and spectral entropy corresponding to different spectral bands were determined. In addition, peak in HF and fractal dimension reflected in very low frequency (0.0033–0.04Hz, VLF) were discussed as well. The partition of a typical HRV power spectrum was shown in Fig. 1.RR intervals were interpolated at a sampling frequency of 4Hz with the help of cubic spline function [4]. Then the auto regression model was used to estimate the power spectrum density (PSD) of RR with an order of 16 [20].a.Spectrum powerDue to total spectrum power fluctuations, it is of little importance to evaluate the absolute value of spectrum power. Only relative or normalized values of spectral components were calculated, including (1) LFn, MFn, TLFn and HFn: percentage of the power in corresponding frequency band takes in TF; (2) LF/HF, MF/LF and TLF/LF: ratio of the power within different frequency bands.Mean frequencyFor a section of power spectrum with energies of P1, P2, ⋯, PNat frequencies f1, f2, ⋯, fN, its mean frequency is defined as(1)f=∑i=1NfiPi∑i=1NPiIt can reflect the average modulation of specific factors. Mean frequency of all spectral bands except for VLF were calculated. Thus there were 5 mean frequency values in total, which are denoted LFf, MFf, TLFf, HFf, and TFf, respectively.Spectral entropySpectral entropy (SE) characterizes the complexity of a series in frequency domain. Considering a power spectrum with energies of E1, E2, ⋯, ENat individual frequency, the SE is defined as [21](2)SE=−∑i=1NpilnpilnNwhere pidenotes the proportion Eitakes in the whole energy, that ispi=Ei/∑j=1NEj. Just like mean frequency, 5 SE values were calculated in this paper, which are denoted LFse, MFse, TLFse, HFse, and TFse, respectively.Peak in HF spectral bandThe peak in HF spectral band is generally considered to reflect the respiratory modulation of HR, and the corresponding frequency is equal to respiratory rate approximately. In order to characterize the features of respiratory during sleep, two parameters related to this peak were extracted in our study: (1) HFmaxf: corresponding frequency [22]; (2) HFamp: normalized amplitude, i.e. (amplitude of the peak)/(total power in HF). In our opinion, the parameter HFamp could reflect the stability of respiratory frequency during the investigated period roughly.Fractal dimensionThe fractal component of HRV was mainly reflected in PSD of VLF, from which the fractal dimension (FD) could be derived. Firstly, PSD of VLF was plotted in a log-power vs. log-frequency plane (1/fβplot), with the spectral exponent β estimated as the slope of the linear, least square regression of the plot [7]. Then FD was determined as(3)FD=2−(β−1)2Due to providing some information neglected by time domain and frequency domain features, many advanced nonlinear methods have been applied to analyzing HRV. But to obtain stable results, long term data series are often required. In our study, only some nonlinear approaches suitable for the analysis of short term HRV were used. These methods included detrended fluctuation analysis, multiscale entropy, mutual information, autocorrelation coefficient and zero crossing analysis.a.Detrended fluctuation analysis (DFA)DFA could detect long range power-law correlations and obtain intrinsic fluctuations of the investigated nonlinear data by removing the polynomial noise.For the time series x(n)={x(1), x(2), ⋯, x(N)}, the average value is subtracted at first and then the processed series is integrated. Next, the integrated signal is divided into non-overlapping segments of equal length n, and the local trend of each segment is fitted with the help of least square method. Afterwards, the fluctuation function is computed as follows(4)Fn=1N∑k=1N(y(k)−yn(k))2where N stands for the total length of original sequence, y(k) indicates the integrated signal and yn(k) is the fitted local trend. The above process is repeated over different values of n to obtain the relationship between F(n) and n. In general, F(n) would increase with n as Fn∼nH. It is H, the slope of the curve log(F(n))–log(n) plotted on log–log plane, that is denoted DFA exponent.Different H represents different correlation intrinsic to the original sequence [20]. In our research, two values of H called H1 and H2 were calculated over n=10–30 and 30–100, respectively [23].Multiscale entropy (MSE)MSE belongs to the category of entropy analysis method. Because of a process termed coarse-grained, it reveals superiority over approximate entropy and sample entropy in the analysis of biological signals [24,25].For the sequence {x(n)}, the consecutive coarse-grained series {yτ(j)} corresponding to the scale factor τ should be constructed at first, whereyτ(j)=∑i=(j−1)τ+1jτxi/τ,j=1,2,⋯,[N/τ]. Then an entropy measure, such as sample entropy, of each coarse-grained series is calculated as MSE of the original sequence.There are two other parameters to be set before calculating MSE besides τ, that is the embedding dimension m and a threshold value r[24–26]. In fact, they are important parameters to determine sample entropy of the coarse-grained series [24–26]. According to our previous investigation [26], τ was set to be 3, m was set to be 2, and r was set to be 0.2*STD, where STD denotes the standard deviation of {x(n)}.Mutual information (MI)MI is an effective measure to quantity the mutual statistical dependence of two variables. MI between variable X and Y could be determined through MI(x,y)=H(x)+H(y)−H(x,y), where H(x) and H(y) are marginal entropies, and H(x,y) is the joint entropy of X and Y.In this paper, the MI function MI(k), of which each value is the MI between RR and its time-delayed sequence with a delay of k was determined by Long's method [27] at first. Then the beat decay (BD) and peak decay (PD) were derived as measures of MI function [28] by(5)BD=MI(0)−MI(1)(6)PD=MI(0)−MIpeak1where MIpeak1 indicates the first extreme maximum value of MI(k) in the range of k from 2 to 7 and represents the modulation of respiratory to HR. If the peak disappeared within that range, the maximum value is used instead [1]. Both BD and PD could reflect the complexity of RR sequence by quantifying the information flow with dependence on time delay.Autocorrelation coefficientAs demonstrated in literature [29], Pearson's interbeat autocorrelation coefficient of RR intervals differs during REM-NREM sleep cycle. Although it could only reflect linear correlation compared with MI, it might implicate some certain physiological meanings. For the series {x(n)}, the autocorrelation function r(k) could be calculated through(7)r(k)=Cov[x(n),x(n+k)]D[x(n)]⋅D[x(n+k)]whereCov(⋅)is covariance, D(·) standards for variance, and x(n+k) denotes the time-delayed series with a delay of k.Similar with MI, the autocorrelation function r(k) of RR sequence was determined at first. Then two features denoted BDa and PDa were estimated through the same calculation approaches of BD and PD, respectively.Zero crossing analysisZero crossing analysis was designed to analyze the oscillating characteristic of RR sequence. Considering the data sequence {x(n)}, the mean value is subtracted at first. Then the zero crossing points are located and the number of data between successive zero crossing points, which is denoted zero crossing interval (ZCI) are counted. At last, the mean value (mZCI) and normalized standard deviation (standard deviation of ZCI/mZCI, nsZCI) of ZCI are extracted as zero crossing features.For RR record studied here, the data was resampled at a sample rate of 4Hz before zero crossing analysis. Next, db6 mother wavelet was adopted to decompose the resampled RR record up to level of 6 [30], with obtaining detailed coefficients d1–d6. Then RRl=d5+d6 (0.03125–0.125Hz) and RRh=d3+d4 (0.125–0.5Hz) were considered as estimation of LF and HF component of RR sequence respectively. At last, zero crossing features of RR, RRland RRh, i.e. mZCIa, nsZCIa, mZCIl, nsZCIl, mZCIh, and nsZCIh, were derived as discussed above.A total of 41 features were explored in this study, and they were summarized in Table 3. The 25 features proposed or applied to investigating HRV during sleep for the first time were marked with a symbol of asterisk (*).Random forest (RF), proposed by Breiman [31], is a novel combined classification method. Compared to other rather excellent classification approaches, such as artificial neural network and supporting vector machine, it reveals advantages of fast computation, high accuracy, excellent anti-noise ability, and avoiding over fitting. Therefore, it has been widely used in the classification of bioinformatics [32,33].RF consists of a large number of decision trees that choose their splitting features from a bootstrap sampled subset of p features at each internal node. The trees are built through the methodology of Classification And Regression Tree (CART) without pruning [31]. Final prediction is determined by majority voting of predictions of the ensemble. More details about the constitution of RF could be found in reference [31].An important ability of RF is evaluating the importance of each feature during the course of training. In fact, during the constitution of RF, there are approximately 33% of the original training sets, which are called out-of-bag (OOB) samples, would not occur in a typical bootstrapped sample. To evaluate the importance of a specific feature, its values for the OOB samples are randomly permuted at first. Then the modified OOB samples are passed down the forest to get new predictions. Next, both the average misclassification rates before and after feature modified were calculated. And the increase of average misclassification rate caused by feature permuted is an importance measure of the corresponding feature [31]. The greater the increase is, the more important the feature performs in the classification, vice versa.There are only two parameters, which are denoted by mtry and ntree, in the constitution of RF. The former one refers to the number of variables available in the random subset at each node during tree induction, while the latter one is the number of trees in RF [34]. Based on empirical experiments, the default values of mtry and ntree for classification, which could lead to relatively stable classification and variable importance measures, are p1/2and 500, respectively [34].Two possible schemes of classifier, named as subject specific classifier and subject independent classifier, were considered in our study. Within subject specific scheme, the training and testing sets were selected from the same record, while they came from different records for subject independent classifier. There is no doubt that a subject independent classifier is more practical. But a subject specific system also has utility, both potentially in multi-night investigations and in evaluating the importance of each feature for sleep staging [22].To test the reliability of our designed classifiers, accuracy and Cohen's kappa statistic κ[11,12] of per stage and overall classification were estimated as performance evaluators.Accuracy is the basic index to evaluate a classifier. It stands for the percentage of correctly classified epochs takes in the whole testing set. κ statistic reveals as a more effective evaluator due to taking into account the prior probability of the specific class. It could be calculated as [11,12](8)κ=PA−PCPprio−PCFor overall κ, PA is the proportion of observed agreement, PC is the proportion of agreement expected by chance, and Pprio is equal to 1. For per-stage κ, PA and PC stand for the corresponding proportion of specific stage, and Pprio stands for its priori proportion [12]. κ≤0 means that the observed agreement is even worse than that expected by chance. And κ=1 means that all samples are classified into the expected class. A higher value of κ indicates a stronger agreement between our designed classifier and the expected results.Generally speaking, a good classifier should be associated with high values of accuracy and κ statistic.For each record, 20% of all the epochs were randomly chosen as training data while the remaining 80% were recognized as testing samples. However, as shown in Table 1, fewer epochs during wake and REM sleep existed compared with NREM sleep. To keep the training set more balanced, the ratios of every class were not in the proportion of that they took in the whole night data exactly. The percentages of wake and REM sleep in training set were slightly higher than the ones they took in the whole data. While the percentage of NREM sleep in training data were slightly lower than that they took in the whole data.To get evaluation of the classification for each record, whole process of training and classification were repeated for 10 runs, with different training set each time, in order to removing bias of randomly chosen training samples. The final individual evaluations were the ensemble average. At last, accuracy and κ statistic were averaged over all the 45 records to obtain the overall evaluation.For each specific record to be analyzed, all the other 44 records were pooled together to form the training set. This process was repeated 45 times, selecting one of the records as testing data one time. As same with the subject specific classifier, the averaged evaluators of all 45 records were recognized as overall performance evaluation.The biggest difficulty of subject independent classifier is overcoming individual differences. The features must be normalized before classifier training. One of the most widely used normalization method is to transform all the original features to a new variable within specific range, such as [0,1] [35,36]. However, this method shows apparent shortcomings when some outliers appear. That is, the distribution of transformed data will be asymmetric and biased toward a certain edge value. To avoid this problem, we developed a new normalization method based on fractiles. In detail, the fractiles of 5% and 95% of a feature were estimated at first. Then the data between the two fractiles, which covers 90% of the whole samples, were transformed to the range of [0,1]. And the rest features were mapped with the same transformation coefficients.In theory, with the classification approach of RF, the addition of features containing little or no valuable information for classification will not degrade the performance. One could simply pass down all features to RF and the features containing no information will be ‘ignored’ by the classifier through CART methodology. However, it is still of great significance to perform features rank and selection. It could help explore the features vary most considerably during sleep and achieve optimum or suboptimum performance with the fewest features.As described above, RF provides an importance measure of each feature during the process of training. In our study, the importance measures of each feature were computed for each individual within both classifiers. And the averaged value over all the 45 subjects was recognized as the final importance measure.Afterwards, the appropriate number of features was explored. The classifier was retrained successively, adding one feature at a time from the most to the least important variables. For each run, the corresponding accuracy and κ statistic were computed. Then the functions of accuracy and κ to the number of variables was plotted and the appropriate number of features was determined according to the curve. This same routine was got into within both subject specific and subject independent scheme. Though this method might not be the optimal, it was still used because our study only focused on the importance of single feature and the analyzed result is easy to understand and analyze.

@&#CONCLUSIONS@&#
