@&#MAIN-TITLE@&#
A clustering based forecasting algorithm for multivariable fuzzy time series using linear combinations of independent variables

@&#HIGHLIGHTS@&#
A clustering based algorithm with linear combinations of the variables is presented.Uncertainty and ambiguity of the data is handled by the fuzzy clusters.Linear combinations of the variables allow more learning from the available samples.The presented algorithm is faster and more accurate than the conventional algorithms.

@&#KEYPHRASES@&#
Fuzzy time series,Fuzzy clustering,Fuzzy C-Means (FCM),Least Square Estimate (LSE),Forecasting,

@&#ABSTRACT@&#
There are two popular types of forecasting algorithms for fuzzy time series (FTS). One is based on intervals of universal sets of independent variables and the other is based on fuzzy clustering algorithms. Clustering based FTS algorithms are preferred since role and optimal length of intervals are not clearly understood. Therefore data of each variable are individually clustered which requires higher computational time. Fuzzy Logical Relationships (FLRs) are used in existing FTS algorithms to relate input and output data. High number of clusters and FLRs are required to establish precise input/output relations which incur high computational time. This article presents a forecasting algorithm based on fuzzy clustering (CFTS) which clusters vectors of input data instead of clustering data of each variable separately and uses linear combinations of the input variables instead of the FLRs. The cluster centers handle fuzziness and ambiguity of the data and the linear parts allow the algorithm to learn more from the available information. It is shown that CFTS outperforms existing FTS algorithms with considerably lower testing error and running time.

@&#INTRODUCTION@&#
Fuzzy time series (FTS) is a universal forecasting method in a fuzzy environment [1–3]. FTS is used in various areas such as forecasting electricity load demand [4], stock exchange [5–10], rainfall and temperature forecasting [11], pollution [12], enrollments [13–15], etc. There are two major categories of FTS algorithms: FTS algorithms based on intervals of the universal set [3,16] and FTS algorithms based on fuzzy clustering [17–22]. The main problem with the interval based algorithms is the length of the intervals which is not clear how to be chosen. Many attempts are made to find optimal intervals but the problem is still unsolved [23–26]. Clustering based algorithms are preferred since they are interval independent.A high-order multi-variable algorithm for FTS (HMV-FTS) was presented based on fuzzy clustering to improve forecasting accuracy and handle fuzzy time series with high order and multi-dimensional input space simultaneously [17]. HMV-FTS outperforms existing FTS algorithms as examined by various data sets of different contexts. Data of each variable of the FTS are clustered individually in HMV-FTS and other clustering based algorithms, which demands higher running time. The objective of the present work is to establish a fast and precise forecasting algorithm for FTS, based on fuzzy clustering and linear combinations of the input variables (CFTS). In contrast to the existing clustering based FTS algorithms, which cluster data of each variable separately, CFTS clusters the input data vectors in the clustering section of the algorithm.This paper is organized as follows: mathematical framework of CFTS algorithm is discussed in Section 2. The algorithm is evaluated in Section 3. Computational cost of the algorithm is investigated in Section 4. CFTS is compared with recent FTS algorithms in Section 5 and concluding remarks are drawn in Section 6.We introduce FTS briefly and then propose CFTS algorithm. Let Y(t)∈ℜ, t=0, 1, 2, ... be the universe of discourse on which fuzzy sets fi(t), i=1, 2, ... are defined and F(t) be a collection of fi(t)s, then F(t) is defined as a fuzzy time series on Y(t). In general, F(t) is a linguistic variable with linguistic values, fi(t). If F(t) is related to F(t−1), the Fuzzy Logical Relationship (FLR) between them is represented by F(t−1)→F(t) which is a first order FLR. In this FLR, F(t−1) and F(t) are called current state and next state and denoted by Aiand Aj, respectively, and their FLR is shown as Ai→Aj. FLRs with the same current states are grouped as a Fuzzy Logical Relationship Group (FLRG). For forecasting, current state of the FLR of the forecast time is constructed and then the FLRG with current state identical with that of the forecast FLR is found. Next state of the forecast FLR is taken the same as the next state of this FLRG. Finally, crisp value of the forecast is computed from defuzzification of the fuzzy value(s) of the forecast obtained from the next state of the forecast FLR [2,16].In the CFTS algorithm, the input data are clustered as in the clustering based FTS algorithms but no FLR is used. Instead of FLRs, CFTS uses combinations of input variables to map the input data into the output space. For high order FTS, one can simply apply CFTS algorithm on the lagged variables of the FTS to forecast future values of the dependent variable.Consider Xr×Nandy→1×Nas the input and output data of the FTS where N is number of observations and r is number of the FTS variables. jth input data vector isx→j=[x1jx2j…xrj]Tand its corresponding output is yj. We group X matrix into c clusters using Fuzzy C-Means algorithm, FCM [27]. For this purpose, following index is minimized with the given constraint [27]:(1)J1=∑j=1N∑i=1cuijm||x→j−v→i||A2,∑i=1cuij−1=0where c is the number of clusters,v→iis center of the ith cluster (ith row of cluster centers matrix, Vr×c), uijis membership grade of the jth data vector in the ith cluster (element of partition matrix, Uc×N),||x→j−v→i||A2=(x→j−v→i)TA(x→j−v→i)is distance,m∈1,∞is degree of fuzziness and Ar×ris the covariance norm matrix, defined as:(2)A=1N∑j=1N(x→j−v→¯)(x→j−v→¯)T−1,v→¯=1N∑j=1Nx→jSince A is a symmetric matrix, A=AT. Using Lagrange Multipliers Method (LMM), J1 is written as:J1*=∑j=1N∑i=1cuijm||x→j−v→i||A2+∑j=1Nλj∑i=1cuij−1Zeroing derivatives ofJ1*with respect tov→i, uijand λjyields:∂J1*∂v→i=∑j=1Nuijm(A+AT)(x→j−v→i)=0,A=AT⇒v→i=∑j=1Nuijmx→j∑j=1Nuijm∂J1*∂uij=muijm−1||x→j−v→i||A2+λj=0,∂J1*∂λj=∑i=1cuij−1=0⇒uij=∑k=1c||x→j−v→i||A2||x→j−v→k||A21m−1−1Therefore,(3)v→i=∑j=1Nuijmx→j∑j=1Nuijm,uij=∑k=1c||x→j−v→i||A2||x→j−v→k||A21m−1−1These equations are repeatedly updated until changes in U and V become negligible. After deciding on cluster centers, Membership Function (MF) of the qth variable in the ith cluster is computed as:(4)uqij=∑k=1c||xqj−vqi||2||xqj−vqk||21m−1−1,||xqj−vqi||2=(xqj−vqi)2∀j∈[1,N]Weighted contribution of each cluster in the calculation of the output associated withx→jis computed as:(5)τij=∏q=1ruqij∑i=1c∏q=1ruqijConsider the matrixX(r+1)×N*such that:x1j*=1,x(q+1)j*=xqj∀q∈[1,r],j∈[1,N].Then output of CFTS algorithm forx→j*=[1x→j]is considered as the weighted linear combinations of the input variables.(6)yj=∑i=1cτij∑q=1r+1piqxqj*The coefficients piqare obtained by minimizing the following index:(7)J2=∑i=1cτij∑q=1r+1piqxqj*−yj2Zeroing derivative of J2with respect to piqyields:(8)∂J2∂piq=∑i=1cτij∑q=1r+1piqxqj*−yjτijxqj*=0⇒∑i=1cτij∑q=1r+1piqxqj*−yj=0∀j∈[1,N]Usingx1j*=1,x(q+1)j*=xqj∀q∈[1,r],j∈[1,N], (8) is written as the following set of N equations:(9)HP→=y→∴P→=[p→1p→2⋯p→i⋯p→c]T,p→i=[pi1pi2⋯piq⋯pir+1]H=τ11...τc1τ11x11...τc1x11...τ11xr1...τc1xr1τ12...τc2τ12x12...τc2x12...τ12xr2...τc2xr2⋮...⋮⋮...⋮...⋮...⋮τ1j...τcjτ1jx1j...τcjx1j...τ1jxrj...τcjxrj⋮...⋮⋮...⋮...⋮...⋮τ1N...τcNτ1Nx1N...τcNx1N...τ1NxrN...τcNxrNSince number of equations inHP→=y→is usually higher than number of unknowns, it is solved by Least Square Estimate method (LSE) where the errore=(y→−HP→)T(y→−HP→)is minimized.e=y→Ty→−2y→THP→+P→THTHP→∂e∂P→=−2HTy→+2HTHP→=0⇒P→=(HTH)−1HTy→However, sometimes HTH is ill-conditioned and pseudo-inverse of this matrix should be used. So,P→is calculated from:(10)P→=(HTH)+HTy→where(HTH)+is pseudo-inverse of HTH.Results of the CFTS algorithm are compared with those of the other FTS algorithms and popular forecasting methods. Four test cases are studied to evaluate CFTS algorithm. Degree of fuzziness, m, is taken 2 for all cases but one can choose an optimal value of m∈(1, ∞] which minimizes the testing error. We use Root Mean Square Error (RMSE) to compare the algorithms performances for both training and testing data sets.(11)RMSE=1n∑j=1n(yj−yj*)2whereyj*is output of the model and n is number of data points used for training or testing. For all the cases, errors are reported as the average of 30 runs.The first test case presents a detailed example of applying CFTS on the real data sets. The other test cases follow the same procedure.TAIEX data are frequently used for evaluation of the FTS algorithms. There are two variables and 226 data vectors in these data where 208 of them are used for training and the remaining data are used for testing as in the FTS algorithm of [19]. For all the TAIEX data sets studied in this work, the close price y is considered as a function of the high price x1 and low price x2. We use seven clusters as [19]. The following step-by-step procedure is used to apply CFTS algorithm on these data.Step 1: Number of clusters c, and degree of fuzziness m, are assigned which are c=7 and m=2 in this case.Step 2: The training input data are clustered using (3). Fuzzy clustering given in (3) is an iterative method which starts with a randomly assigned partition matrix U(0) from which cluster centers V(0) are computed. Then U(1) is calculated from V(0). If ||U(1)−U(0)||≤ɛ where ɛ is a predefined threshold (We use ɛ=0.00001 for all test cases.) and || || is norm ofU1−U0, the solution is converged. If||U1−U0||>ε, this procedure is continued to t iterations until ||U(t)−U(t−1)||≤ɛ so that the clustering algorithm converges. U=U(t) is final partition matrix from which final cluster centers matrix V=V(t) is computed using (3). Final V of these data is:V=58365483634559215896665268035660541560545862578865856693Step 3: uqijand τijare calculated from (4) and (5), respectively. Then, H is computed using τijand the training input data matrix X.Step 4: Parameters of the linear combinations,P→, are calculated using (10) wherey→is output of the training data set. Then, vector of parameters of the ith linear equation,p→ii∈1,c,is extracted fromP→. For this case,P→is:P→=−230.8960.4620.579876.2550.7070.125−77.7170.4460.566−499.2800.0651.024299.2690.8520.091467.5470.3680.561639.2320.0250.886The following matrix includes parameters of the linear parts where the ith row is parameters of the ith linear equation,p→i.Q=−230.89680.46250.5797876.25560.70770.1258−77.71730.44640.5660−499.28080.06511.0249299.26950.85210.0911467.54710.36820.5618639.23210.02510.8868⇒y1j=−230.8968+0.4625x1+0.5797x2y2j=876.2556+0.7077x1+0.1258x2y3j=−77.7173+0.4464x1+0.5660x2y4j=−499.2808+0.0651x1+1.0249x2y5j=299.2695+0.8521x1+0.0911x2y6j=467.5471+0.3682x1+0.5618x2y7j=639.2321+0.0251x1+0.8868x2Step 5: For any training or testing input data vectorx→j=[x1jx2j…xrj]T, uqijand τijare calculated from (4) and (5), respectively. Then, output of the CFTS algorithm forx→jis computed by (6) as following:yj=τ1jy1j+τ2jy2j+τ3jy3j+τ4jy4j+τ5jy5j+τ6jy6j+τ7jy7jNote that number of clusters c, is not optional and should be computed. Optimal number of clusters is simply found by running the algorithm for c=2, 3, ... and choosing c corresponding to the minimum testing error. Although we take degree of fuzziness m=2 but one can find the optimal m by the method used for c. We use this method for all cases studied in this paper.For this data set, training and testing errors of the CFTS algorithm are 35.58 and 34.38 and those of the clustering based FTS algorithm of Ref. [19] are 142.93 and 91.1, respectively. So, testing RMSE of the CFTS algorithm is 62% less than testing error of the FTS algorithm of Ref. [19]. Output of the algorithm for training and testing data is shown in Fig. 1.Moreover, TAIEX data of 1999 are simulated with five clusters and results of the CFTS algorithm are compared with those of the other FTS algorithms. Output of the CFTS algorithm is shown in Fig. 2.These data were also studied using an FTS algorithm combined with Genetic Algorithms (FTSGA) [28]. It was shown that FTSGA is more accurate than other FTS algorithms. Testing RMSE of the CFTS algorithm is compared with those of the FTSGA and other algorithms given in Ref. [28] in Table 1. It is observed that testing RMSE of the CFTS algorithm is 47% less than that of the FTSGA algorithm.Cluster centers and parameters of the CFTS algorithm for the TAIEX data of 1999 are:V=8096730475498530764679707177728983617545,Q=1672.41940.00830.7890−170.41761.2168−0.2061693.3983−0.55601.4762176.7553−0.14921.1377265.64880.58010.3829One can assign linguistic terms to the cluster centers and express CFTS results as conditional fuzzy rules. For example, CFTS parameters of the TAIEX data of 1999 are written as:IFx1isrV11andx2isrV21THENy1=1672.4194+0.0083x1+0.7890x2IFx1isrV12andx2isrV22THENy2=−170.4176+1.2168x1−0.2061x2IFx1isrV13andx2isrV23THENy3=693.3983−0.5560x1+1.4762x2IFx1isrV14andx2isrV24THENy4=176.7553−0.1492x1+1.1377x2IFx1isrV15andx2isrV25THENy5=265.6488+0.5801x1+0.3829x2There are two groups of FTS forecasting algorithms one based on the intervals of the universe of discourse and the other is based on the clustering. The differences between the CFTS algorithm and the other FTS algorithms are summarized as followings:1.The interval based FTS algorithms need to find optimal length of each interval which is not fully understood and researchers are still trying to solve the problem. The CFTS algorithm is based on fuzzy clustering and does not use any interval.The clustering based FTS algorithms deal with fuzziness, uncertainty and ambiguity of the data using fuzzy clusters instead of the intervals. They use FLRGs to establish relations between inputs and outputs but these relations are not strong enough to model behavior of the data with high precision. The interval based algorithms suffer from the same problem. These algorithms usually require high number of clusters or intervals to model the data with the desired testing error which incur high computational time. The CFTS algorithm handles fuzziness of the data by fuzzy clusters as the clustering based FTS algorithms but establishes input/output relations by linear combinations of the input variables instead of the FLRs. These linear relations provide higher degrees of freedom for learning from the training data set and make CFTS more accurate than the other FTS algorithms. Also, number of clusters needed for the CFTS algorithm to achieve the desired testing error is very smaller than those of the other FTS algorithms because of the linear relations. This makes CFTS computationally efficient and fast.Both interval and clustering based FTS algorithms use FLRs as input/output relations. Using the forecasting FLR and the FLRGs, fuzzy value(s) of the forecast is computed which requires defuzzification. However, CFTS gives crisp value of the output and does not require any defuzzification.Enrollment problem is the basic data set studied by the FTS algorithms where all the data are used for training. Training errors of various FTS algorithms are given in Table 2which are taken from Ref. [17]. Seven clusters are used in this case since other algorithms in the table also use seven intervals or clusters.It is observed that RMSE of the CFTS algorithm is 33% lower than those of the other popular FTS algorithms. Cluster centers and parameters of the linear combination functions are:V=19154153801470216893159061641713459,Q=38775.65−1.019233445.26−1.168028043.19−0.855863168.67−2.729820414.45−0.2157−124353.388.5290−2625.531.2185This is a data set with five input variables and 294 data vectors. The first 270 data vectors are used for training and the rest for testing using four clusters. Training and testing RMSE of the CFTS algorithm for these data are 0.2264 and 0.4583, respectively. These data are also modeled using ANFIS (Adaptive Network Based Fuzzy Inference System) [29]. Training and testing RMSE of the ANFIS with triangular MFs, 32 rules and linear THEN part are obtained as 0.1408 and 0.4484, respectively. It is concluded that testing error of the CFTS algorithm with four clusters is comparable with that of the ANFIS with 32 rules. Output of the CFTS algorithm versus actual output is shown in Fig. 3for the training and testing data sets.Cluster centers and parameters of the CFTS algorithm for the Box–Jenkins data are:V=−0.23250.54610.9780−0.8654−0.18700.46380.8221−0.7387−0.14270.36730.6940−0.645654.213451.570848.607157.483554.197251.474648.608957.4871,Q=8.0458−1.21390.8893−0.2816−0.49371.34197.2212−0.81380.4766−0.1746−0.45161.31587.1801−0.89370.5761−0.1493−0.59761.46567.4243−0.84350.4971−0.0845−0.47021.3296Gas consumption data [17] have three variables and 1238 data vectors. 867 data vectors are used for training and the rest for testing the algorithm with ten clusters. Training and testing RMSE of the CFTS algorithm are 1.6272 and 1.6196 and those of the ANFIS with triangular MFs, 27 rules and linear THEN part are 1.4483 and 1.597, respectively. So, testing error of the CFTS algorithm is comparable with that of the ANFIS. Output of CFTS algorithm for gas data is shown in Fig. 4. Cluster centers and parameters of the linear functions of the CFTS algorithm for the gas data are:V=11.85239.889414.033523.491632.727827.934536.000711.173312.777010.995722.731415.381626.91629.87387.40628.59517.584626.281830.445527.015123.499615.595326.97869.85897.40048.65047.560825.086727.319529.6210,Q=3.0704−0.20910.64510.36167.5882−0.1030−0.34171.010212.5460−0.25800.00600.63743.1839−0.0625−0.05850.91781.11820.00340.51120.31263.9231−0.07650.06410.72652.2905−0.04930.36140.582816.6361−0.65060.15490.521617.6259−0.2914−0.11060.630310.7839−0.17500.23080.4530CFTS algorithm allows dealing with fuzziness, ambiguity, vagueness and uncertainty of the data using cluster centers as the other FTS algorithms but provides higher forecasting precision due to learning using parameters of the linear combinations which make it superior to the other FTS algorithms.Sometimes, existing FTS algorithms need high number of clusters or intervals to learn behavior of the data which demands high computational time. Running time of the CFTS algorithm is compared to those of HMV-FTS and another clustering based FTS algorithm given in Ref. [17]. Results are given in Table 3.It is observed that running time of the CFTS algorithm is considerably lower than that of other FTS algorithms especially when high number of clusters is used. CFTS algorithm learns behavior of the data with lower number of clusters than those required for the other FTS algorithms because of parameters of the linear parts. Although high number of clusters considerably reduces training error of the CFTS algorithm but increases testing error because of overtraining due to high number of parameters of the linear parts. Overtraining causes the algorithm to learn unimportant details of the data which reduces its generalization ability and increases testing error. So, number of clusters should be chosen such that the desired training or testing error acquired and excessive number of clusters should be avoided. Moreover, computational cost of the algorithm increases with number of clusters. As an instance, variation of the training and testing errors of CFTS for the Box–Jenkins data is shown in Fig. 5. It is observed that although CFTS algorithm learns more details of the data with higher cluster numbers which causes lower training error, but its generalization ability decreases because of the overtraining which is reflected by higher testing error.TAIEX data from 1997 to 2003 are studied in Ref. [30]. Now, the data for 1997 and 1998 are not available on the Internet. We study these data from 1999 to 2004 to compare CFTS with other FTS algorithms. We use data vectors of November and December of each of the data sets for testing and the rest for training CFTS as in Ref. [30]. Two FTS algorithms are presented in Ref. [30]. The first is based on Entropy Discretization (ED) and the second is combination of Entropy Discretization and Fast Fourier Transform (EDFFT) [30]. These algorithms are compared with 9 other methods including Chen's algorithm, Yu's algorithm, Chang's algorithm, Hsieh's algorithm, AR(1), AR(2), GARCH-M, GARCH-AR(1) and GARCH-AR(2) [30]. Testing error of CFTS is compared with those of the above algorithms as given in Table 4. Errors of these algorithms are taken from Table 9 of Ref. [30] and not computed in this work.ED and EDFFT obviously outperform other algorithms. Based on the average testing error, EDFFT is the best among all the algorithms studied in Ref. [30]. But testing error of CFTS is 39.73% less than that of EDFFT algorithm.TAIEX data of 2004 are studied in Ref. [31] where the last 45 data vectors are used for testing and the rest for training. Results of modeling this data set with various FTS algorithms are presented in Ref. [31]. We model these data using CFTS by taking training and testing data the same as those of Ref. [31]. Training and testing RMSE of CFTS is compared to those of other FTS algorithms in Table 5. Note that results of the other FTS algorithms are taken from Table 2 of Ref. [31] and are not computed here.Testing error of Ref. [31] is the smallest one among those of the eight FTS algorithms. However, testing error of CFTS is 42.4% less than testing error of Ref. [31]. Results of modeling the TAIEX data from 1999 to 2004 are shown in Fig. 6.Finally, TAIEX data from 2005 to 2014 are forecasted using CFTS. The last 45 data vectors of each data set are used for testing and the rest for training. Actual data and CFTS outputs for each year are shown in Figs. 7 and 8.Training and testing errors of CFTS for the TAIEX data from 1999 to 2014 are given in Table 6. Also, optimal number of clusters for each data set is in the table which is chosen such that the testing error of CFTS becomes minimum.

@&#CONCLUSIONS@&#
A clustering based forecasting algorithm for fuzzy time series (CFTS) is proposed. CFTS algorithm deals with ambiguity, vagueness and uncertainty of the fuzzy time series (FTS) using fuzzy clusters and replaces FLRs of the conventional FTS algorithms with linear combinations of the input variables. Parameters of the linear combinations are estimated by the Least Square Estimate (LSE) which enable the algorithm to learn behavior of the data more precisely compared to the existing FTS algorithms. The algorithm is evaluated using various data sets. Modeling the enrollment data as the basic problem of FTS shows that error of the CFTS algorithm is 33% less than that of the best algorithm among five popular FTS algorithms. Forecasting TAIEX data demonstrates that testing error of CFTS algorithm is 62% less than testing error of FTS algorithm. Moreover, it is shown that CFTS algorithm is 47% more accurate than the FTS algorithm combined with Genetic Algorithms (FTSGA). Although CFTS algorithm outperforms existing FTS algorithms but its effectiveness is confirmed if it provides satisfactory simulation of the FTS compared with other popular forecasting methods. For this purpose, Box–Jenkins and natural gas consumption data are forecasted using the CFTS algorithm and it is observed that testing errors of the algorithm are comparable with those of the ANFIS. It is also shown that CFTS algorithm is faster than the other FTS algorithms. High accuracy and low running time makes CFTS an efficient algorithm for forecasting fuzzy time series.