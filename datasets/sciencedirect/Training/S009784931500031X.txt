@&#MAIN-TITLE@&#
Computational rim illumination of dynamic subjects using aerial robots

@&#HIGHLIGHTS@&#
We demonstrate the first approach for studio quality lighting using aerial robots.Our lighting robot automatically positions itself to produce optimal rim lighting.Our robot adapts to changes in subject position, subject posture and camera position.We validate our approach with several indoor experiments.Using an open-loop outdoor setup, we discuss design issues and ergonomic issues of robotic lighting.

@&#KEYPHRASES@&#
Computational illumination,Aerial robots,

@&#ABSTRACT@&#
Graphical abstract

@&#INTRODUCTION@&#
Lighting plays a critical role in good photography. Through the careful placement of lights, photographers can define space and enhance the mood of photographs. Perhaps the most dramatic example is the use of a rim light behind the subject, which highlights silhouettes and can be used as the main light for silhouetted styles, or as an accent to separate a subject from the background. Rim lighting effects are usually associated with posed studio photography because they require careful placement of lights relative to a static subject and often involve a whole crew where assistants move the lights until the photographer is satisfied with the look of the image. Photographers increasingly try to push the envelope and deal with dynamic scenarios by having assistants track a moving subject, but this remains costly, challenging, and might require many takes. There are two central challenges in rim lighting for photography of dynamic scenes: the ability to move the lights (usually handled by assistants), and the decision of how to move them, usually made by the photographer based on what he or she sees in the viewfinder.In this paper we propose an automated technique for rim lighting in dynamic settings with moving subjects. We combine the use of computational photography and robotically controlled light source to facilitate the use of advanced lighting effects such as rim lighting for moving subjects. Our vision is that light sources should be actuated and be able to react to movements in the scene based on feedback from the main camera to achieve a lighting specified by the photographer. In particular, we leverage recent advances in aerial robotics and their commoditization, to enable full 3D placement of light sources around the subject. We focus on the case of rim lighting because it is particularly challenging, important for artistic control, and requires precise positioning of lights.In our scenario, the photographer holds a main camera with the goal of capturing a picture of a potentially moving subject. The photographer controls a desired rim width as a function of the look they want to achieve. An aerial robot (also known as drones, unmanned aerial vehicles, or UAVs) is responsible for the rim light and reacts to the movements of the photographer and the subject to automatically position the light to achieve the desired rim width. The photographer can also specify a wider or thinner rim width and the aerial robot responds accordingly. We introduce a simple computational measure of rim width from the image seen by the photographer׳s camera. While this quantitative rim width is not intended to be a direct characterization of aesthetics, it provides easy control for the photographer who can increase it or decrease it until they achieve a desired look.To enable the automatic placement of rim lights, we introduce a new aerial robot control strategy based not only on absolute localization and sensors on the aerial robot, but also on a computational characterization of rim lighting from the main camera. At a very high level, our control strategy moves the robot away from the photographer (behind the subject) to make the rim thinner, and closer to make it wider. We focus on the placement of the robot within a given horizontal plane because it is the most critical degree of freedom for rim lighting human subjects, but a similar strategy could be used to also modulate the altitude of the aerial robot. In addition to rim width, our controller needs to achieve a number of other objectives such as respecting a given distance to the subject, keeping the robot at a given height, and making sure that the light carried by the robot is directed towards the subject. Fig. 1top row shows our results for various rim widths.We demonstrate our approach with a prototype that relies on a small quadrotor aerial robot that weighs less than a pound (see Fig. 1, bottom left). The aerial robot we use is a low cost (about $300), lightweight quadrotor [1,2] that can easily carry a standard flash as well as a lidar unit to help track the subject. The Lidar can easily be replaced with a cheaper alternative such as a Kinect sensor. We show that the system is able to automatically adjust to subject movement and to free photographers from the labor of lighting placement, enabling free-form photography while achieving a desired rim lighting.This paper is an extended version of the conference paper by Srikanth et al. [3] that made the following contributions:•We demonstrate the first approach for studio quality lighting using aerial robots.We introduce a control approach based on a combination of rim computation from the perspective of the camera and tracking of the subject from the aerial robot.We make the following specific contributions in this paper:•Using numerical simulation, we show approximate monotonic behavior of rim width with reference to the light position under certain conditions.We present more details on the robot control system and the image compositing.Unlike the setup of Srikanth et al. [3], which was an indoor lab based fully automatic system, we present an outdoor open-loop setup that essentially highlights (a) design tradeoffs for aerial robot based lighting and (b) ergonomics of robotic lighting in a realistic shooting scenario.

@&#CONCLUSIONS@&#
This paper presents a new approach to computational illumination where light sources are actuated and automatically adjusted to the view from the photographer׳s camera, which allows lighting to react in real time to changes in viewpoint, subject location, and pose. Our new rim lighting scheme handles dynamic subjects and relies on an aerial robot as a light carrying platform. We propose a new lighting control system based on the collaboration between the aerial robot and the main camera that achieves and maintains given rim lighting characteristics under changes in subject posture and position, and camera movement. Using an aerial robot, a quadrotor, and a few off-the-shelf components, we demonstrate our approach on a variety of subjects. Using an open-loop outdoor experimental setup, we show that our proposed strategies for lighting are inline with the ergonomics of the lighting. We believe that such a combination of computational photography, image analysis, and robotically actuated computational illumination can provide photographers with greater flexibility in dynamic situations and dramatically reduce the need for a full crew of assistants.