@&#MAIN-TITLE@&#
Endpoint prediction model for basic oxygen furnace steel-making based on membrane algorithm evolving extreme learning machine

@&#HIGHLIGHTS@&#
We present a novel model based on evolutionary membrane algorithm identifying the parameters of ELM.The proposed model is an efficient approach to predict the endpoint carbon content and temperature of molten steel.The efficiency of the proposed model has been compared with some well-known models.Computational results indicate that the proposed model is very competitive.

@&#KEYPHRASES@&#
Prediction model,Extreme learning machine,Evolutionary membrane algorithm,Soft measurement,Basic oxygen furnace,Endpoint carbon content,Endpoint temperature,

@&#ABSTRACT@&#
The endpoint parameters of molten steel, such as the steel temperature and the carbon content, directly affect the quality of the production steel. Moreover, these endpoint results cannot be the online continuous measurement in time. To solve the above-mentioned problems, an anti-jamming endpoint prediction model is proposed to predict the endpoint parameters of molten steel. More specifically, the model is constructed on the parameters of extreme learning machine (ELM) adaptively adjusted by the evolutionary membrane algorithm with the global optimization ability. In other words, the evolutionary membrane algorithm may find the suitable parameters of an ELM model which reduces the incidence of the overfitting of ELM affected by the noise in the actual data. Finally, the proposed model is applied to predict the endpoint parameters of molten steel in steel-making. In the simulation experiments, two test problems, including ‘SinC’ function with the Gaussian noise and the actual production data of basic oxygen furnace (BOF) steel-making, are employed to evaluate the performance of the proposed model. The results indicate that the proposed model has good prediction accuracy and robustness in the data with noise. Therefore, the proposed model has good application prospects in the industrial field.

@&#INTRODUCTION@&#
Basic oxygen furnace (BOF) for steel-making is not only an important smelting technology but also the most effective way [1–3]. It is used in about 65% steel factories around the world due to its high productivity and low cost [4,2]. In general, if the endpoint parameters of molten steel can be predicted accurately, the operators can adjust the added amount of the auxiliary raw materials, blowing oxygen and coolant timely [5–9]. And then, the quality of smelting steel can be improved while the production cost can be reduced [10,11]. Therefore, the establishment of a reasonable endpoint prediction model has practical significance to accelerate the development process of the steel industry [12–16].Nowadays, various models have been proposed to predict the endpoint parameters of molten steel so as to improve the quality of steel-making and reduce the production costs. These models can be roughly divided into three categories, such as mechanism models, online measurement models and intelligent models (soft measurement models). First, based on the material balance and the heat balance, most mechanism models are established for the endpoint parameters of molten steel [17]. The validity of the models usually depends on the stationary operation procedure and on the stability of ingredients for the steel-making raw material. However, the components of the raw materials are highly volatile in most of steel plants while the operation process usually relies on more human experience, which cause great difficulties to the use of the mechanism models. Second, with the development of the online measurement techniques, a lot of new and advanced sensors and equipments are applied to BOF steel-making in order to improve the control effect [18–21]. But the high cost of the test and maintenance equipment increases directly the cost of the steel. Third, in recent years, some scholars have established some endpoint prediction models of BOF steel-making based on statistics and smart black box models (such as neural network), and have achieved certain research results [22–30].Extreme learning machine (ELM) is a single hidden layer feedforward neural network learning algorithm [31]. Unlike the other learning algorithms (such as gradient descent algorithm) for neural networks, ELM only needs to set the number of the hidden nodes, and it does not need setting the parameters of input weights and thresholds, because these parameters are randomly generated in each run. Therefore, ELM has the advantages of fast learning speed, and it is suitable for modeling with real-time requirements [32].This paper establishes a BOF steel-making endpoint prediction model which employs an evolutionary ELM. Because the endpoint results are affected by many factors in BOF steel-making, most of the common models may not be competent for this prediction. Evolutionary membrane algorithm (EMA) is an optimization technology based on P systems to solve the numerical optimization problems [33]. EMA exhibits a good ability for global search and convergence speed. Because the standard ELM is vulnerable to the impact of outlier, EMA are employed to adaptively adjust the input weights and thresholds of ELM. In other words, the prediction model is established, in which evolutionary membrane algorithm identifies the parameters of ELM. In the simulation experiments, the proposed model is evaluated on the actual production data in BOF steel-making. The output of the model is the endpoint parameters such as the carbon content and the steel temperature. The experimental results show that the prediction model can predict accurately the endpoint parameters of molten steel.The remainder of this paper is organized as follows. Section 2 presents a brief description of EMA. Section 3 explains the steps of the evolutionary ELM. In Section 4, the details of the proposed prediction model are elaborated. Comprehensive study and experimental results are discussed in Section 5, and finally, Section 6 provides the concluding remarks of the study.Taking inspiration by the structure and the function of the biological cells, Pa˘un has proposed a novel distributed and parallel computing model, named as a membrane computing [34,35]. Based on the membrane computing [36], EMA is proposed as a novel global numeric optimization algorithm for solving the optimization problems [33]. A membrane computing model consists of membrane structure, multiset, symbol-objects, and reaction rules. In EMA, the membrane structure, which consists of a skin membrane containing several elementary membranes, represents an execution logic of the whole algorithm. A symbol-object represents a candidate optimal solution of a global optimization problem. Multiset denotes the set of the candidate solutions because it consists of several symbol-objects. Reaction rules, inspired by the irregular Brownian motion, may update the positions of the symbol-objects so that it can help EMA to find the approximate solutions of the global numeric optimization problem. The process of EMA for solving the numeric optimization problems is shown in Fig. 1. The detailed description of EMA is discussed as follows.Step 1. The parameters of EMA need to be initialized first, such as the maximum iteration number, the number of symbol-objects, the number of elementary membranes.Step 2. After initializing the parameters of EMA, the skin membrane is created. And then, each symbol-object S=[S1, S2, …, Sn] is initialized in the feasible region of the optimization problem. n denotes the scale of the symbol-objects. The i-th symbol-object Si=[si,1, si,2, …, si,D] is a candidate solution for an optimization problem. D denotes the dimension of a decision variable in the optimization problem.Step 3. The fitness of each symbol-object needs to be evaluated according to the objective function of the optimization problem. And then, these symbol-objects are sorted according to their fitness. The sorted symbol-objects are divided equally into some multisets so that each elementary membrane has its own multiset. Finally, the multiset will be sent to different elementary membranes from the skin membrane.Step 4. The elementary membrane is a basic evolutionary unit. In the region of the elementary membranes, the cellular particles (symbol-objects) are simulated to do irregular Brownian motion. Because the simulated process is very complex and the cellular automata model can simulate from the simple state to the complex phenomenon, EMA introduces the cellular automata model to simulate the complex process. The detail forms are described as follows.Firstly, the symbol-objects of the multiset (W) in the elementary membrane are mapped into a two-dimensional grid. The row of the grid equals⌈sizeof(W)⌉, where sizeof(W) represents the number of the symbol-objects in the multiset; at the same time, a state grid is generated with corresponding to the above-mentioned two-dimensional grid. The state value is randomly set as either 0 or 1 in the state grid. Note that the state value 0 represents an inactive cellular particle (symbol-object); otherwise the state value 1 indicates an active cellular particle (symbol-object).Secondly, a symbol-object is randomly selected from the two-dimensional grid. And then, according to the position of the selected symbol-object, its neighbors are found from the two-dimensional grid. And, its state and its neighbor states are also found from the state grid.If the state value of the selected symbol-object equals 1 and the sum of its neighbor state value equals 2, then the following rule is executed.(1)Sw1=α*Sw1+(1−α)*Sw2,Sw2=α*Sw2+(1−α)*Sw1whereSw1andSw2are two symbol-objects with their state 1, which are two neighbors of the current selected symbol-objects. α is a random number in the interval (0,1).If the current state value of a symbol-object equals 1 and the sum of its neighbor state value equals 3, then the following rule is executed.(2)Sw1=Sw1+Sw2+Sw33+α*(Sw1−Sw2−Sw3),Sw2=Sw1+Sw2+Sw33+β*(Sw2−Sw1−Sw3),Sw3=Sw1+Sw2+Sw33+γ*(Sw3−Sw1−Sw2)whereSw1,Sw2, andSw3are three symbol-objects with their state 1, which are three neighbors of the current selected symbol-objects. α, β, γ are random numbers in the interval (0,1), respectively.Thirdly, the changing state rule is invoked to update the state of the current symbol-object. The specific form is detailed as the following equation.(3)Sstate=0,∑i=08=2or31,otherwisewhere Sstatedenotes the state of the selected symbol-object. If the sum of its neighbor state is 2 or 3, the state of the current symbol-object is set to 0, otherwise its state is set to 1.In addition, the operator of the chaotic search is applied to enhance the diversity of the symbol-objects to avoid falling into the local minima. In EMA, Tent Map is employed to implement the chaotic characteristics [37]. Its specific description is shown as follows:First, a symbol-object is randomly selected from the multiset. And it is mapped from the decision space to the chaotic space by using Formula (4).(4)C0=S−SlSu−Slwhere S denotes the selected symbol-object. C0 denotes a chaotic symbol-object which is converted by S. Slis the lower boundary of a symbol-object. Surepresents the upper boundary of a symbol-object.Second, the next generation of the chaotic variables Ck+1 is calculated by Ckaccording to the Tent Map chaotic systems. The implementation of the Tent Map chaotic systems is discussed as follows.(5)Ck+1=Ck0.7,Ck<0.710.3*Ck*(1−Ck),otherwiseThird, until k in Formula (5) is iterated from 1 to 20, the chaotic variable Ck+1 is converted back to the normal symbol-object S. Its form is given as follows:(6)S′=Sl+Ck+1*(Su−Sl)Finally, an excellent symbol-object is determined by comparing between S and S′. If the fitness of S′ is better than S, the symbol-object S is replaced by S′. Otherwise, the symbol-object S is retained.Step 5. After executing Step 4, all symbol-objects in the elementary membrane are sent back to the skin membrane. In the skin membrane, the new generation multisets are reconstructed by regrouping the symbol-objects from different elementary membranes. The reorganization of the symbol-objects enables their information from different elementary membranes to be effectively shared. The operator is conducive to find the global optimal solution of the optimization problems and accelerate the convergence speed of EMA.Step 6. When the end condition is reached, the algorithm execution is terminated. Otherwise, the algorithm will go back to Step3. Finally, in the skin membrane, a symbol-object with the best fitness is chosen as a global optimal approximate solution.ELM is a fast learning algorithm for the single hidden layer feedforward neural networks (SLFNs). A typical structure of the ELM network is shown in Fig. 2. Unlike the other neural networks, input weights and thresholds of ELM is randomly generated, and then its output weights is determined by using pseudo-inverse [31]. ELM is trying to provide the best generalization performance with the extreme learning speed. Compared with the traditional algorithms for SLFNs, ELM has better generalization performance. Particularly in learning speed, it is a thousand times faster. Therefore, the study of ELM has received more and more attention from scholars all over the world [38–40]. The description of ELM is given as follows.For N different random samples (xi, ti), i=1, 2, …, N, the mathematical model of SLFNs is given withN¯hidden nodes and activation function g(x) in Formula (7), where xi=[xi,1, xi,2, …, xi,n]T∈Rnand ti=[ti,1, ti,2, …, ti,m]T∈Rm.(7)∑i=1Nβig(wi·xj+bi)=oj,j=1,…,Nwherewi=[wi,1,wi,1,…,wi,n]Tis the i-th weight vector for the input neurons. βi=[βi,1 , βi,2 , … , βi,n]Tis the i-th weight vector for output neuron weight. biis the i-th threshold of the hidden neurons.wi·xjrepresents the internal output ofwiand xj.The standard SLFN withN¯hidden nodes can make the predicted value to approximate to the actual value under activation function g(x). That standard SLFNs can approximate these N samples with zero error means that∑j=1N∥oj−tj∥=0, these exist βi,wiand biin Formula (8).(8)∑i=1Nβig(wi·xj+bi)=tj,j=1,…,NThe above N equations can be written in matrix as(9)Hβ=Twhere(10)H(w1,⋯,wN¯,b1,⋯,bN¯,x1,⋯,xN¯)=g(w1·x1+b1)⋯g(wN¯·x1+bN¯)⋮g(w1·xN+b1)⋯g(wN¯·xN+bN¯)N×N¯and(11)β=β1T⋮βN¯TN¯×m,T=t1T⋮tNTN×mH is called the output matrix of the hidden layer of neural network; The i-th column of H is the output weights of the i-th hidden neuron with input x1, …, xN.Input weights and thresholds of the standard ELM are both randomly generated. However, their random initialization may lead to decrease in the generalization performance of ELM and consume more time to train the model due to adjusting these parameters repeatedly. Scholars all over the world have proposed many improvements to increase the generalization performance of ELM [40–45].In this paper, the problem that the parameters of ELM are determined adaptively is converted to a global numerical optimization problem. EMA is introduced to solve the numerical optimization problem since EMA is a global optimization algorithm. In other words, EMA is employed to identify the parameters of ELM, called EMA-ELM. Fig. 3shows the process which EMA identifies the parameters of the ELM model. Fig. 4depicts the pseudo-codes of the main steps of the optimal model.The implementation process, which EMA identifies the parameters of ELM, is further described as follows. First, the sample data is chosen as the input node of the ELM model. Second, Root mean square error (RMSE) is used to evaluate the precision of the model which can be calculated in Formula (12). Third, according to the RMSE value, EMA updates the information of the symbol-objects so that the parameters of ELM can be adaptively adjusted. Finally, the learning process will be performed continuously until the termination condition is reached.(12)rmse=∑i=1n(pi−ri)2nwhere piis the prediction value. riis the practical value. n is the number of the predicted samples.In the steel industry, whether the quality of the steel is good or not directly relates to the endpoint parameters of molten steel, such as the carbon content and the steel temperature. The accurate endpoint prediction can not only improve the quality of the steel and increase the types of the steel, but also shorten the smelting time, save energy and reduce production costs. Therefore, the effectiveness of the predicting endpoint model is imperative to improve the level of the steel production.So far, the common approaches are to determine the endpoint parameters of molten steel by the operators’ experience. The approaches make the operating workers to work hard and the steel with poor quality. To solve the above-mentioned problems, an endpoint prediction model is established in BOF steel-making, in which EMA identifies the parameters of ELM. The model, with some advantages such as low-cost, fast-response, and high-precision, is very suitable for the application of the endpoint prediction in BOF steel-making.This paper presents a prediction model, and applies it to predict the endpoint parameters of molten steel. Compared with the original ELM, evolutionary ELM improves ELM with a better generalization performance about the endpoint prediction in BOF steel-making. Fig. 5shows the structure of the prediction model.First of all, the parameters of EMA and ELM are initialized respectively, such as the number of symbol-objects, the number of elementary membranes, the end conditions, and the constraint boundary including input weights, thresholds and hidden nodes. When EMA optimizes the parameters of ELM, the parameters of ELM is encoded as a symbol-object of EMA. In other words, a symbol-object represents a whole set of network parameters of ELM, which consists ofw1,…,wNand θ1, …, θN.w1,…,wNdenote the input weights of ELM, which are initialized on the interval [−1, 1]. θ1, …, θNare the thresholds of ELM, which are initialized on the interval [−1, 1].As depicted in Fig. 5, the endpoint prediction model is created by ELM. From the figure, the input data of ELM consists of weight of hot metal, weight of scrap, weight of lime, weight of mixing material, weight of iron sheet, weight of ore, weight of dolomite, volume of blowing oxygen, process carbon measured by sub-lance, and process temperature measured by sub-lance. The hidden layer of ELM contains 20 hidden nodes. When the endpoint steel temperature is predicted, the output of ELM is the predicting value of the endpoint steel temperature; otherwise, the output of ELM is the predicting value of the endpoint carbon content.The sample data of ELM is determined through the statistical analysis of the actual production data in BOF. Before training samples and testing samples are utilized, they are firstly normalized in order to avoid the annihilation caused by the different scales of the sample data. In order to get the right prediction results, the output of the predicted model need to be anti-normalized. According to the characteristics of the actual data in steel-making, the normalized input equation is designed as shown in Formula (13).(13)xi′=xi−xlxu−xlwherexi′is the normalized input data. xiis the actual input data. xlis a lower boundary of xi. xuis the upper boundary of xi.According to the normalized Formula (13), the anti-normalization equation is designed as shown in Formula (14).(14)xo′=xl+xo*(xu−xl)wherexo′is an anti-normalized output. xois an output of the prediction model. xlis the lower boundary of xo.xouis the upper boundary of xo.The production process in BOF steel-making is very complex physical and chemical change with more uncertainty. In Section 4.1.2, the endpoint prediction model is established. Then, EMA is employed to find the input weights and thresholds of ELM. Finally, the global optimal symbol-object will be found, which represents an ELM model with a good generalization performance.To test the validity and applicability of EMA optimizing the parameters of ELM, two groups of data are used in the simulation experiments. One group is a standard ‘SinC’ function with the noise, which detects the regression ability of the proposed model; another group is some actual production data collected from BOF in a steel plant. The parameters of EMA are shown in Table 1.‘SinC’ is a sin function sin(x) multiplied by a monotonically decreasing function 1/x, as shown in Formula (15). The regression performance of all predicted models may be tested by the function. At first, 200 data points with the noise of μ(0, 0.3) which is a Gaussian distribution function are generated by the ‘SinC’ function as the training samples. And 200 data points are generated in the same way as the testing samples. Then, the training samples are employed to test ELM [31], DE-ELM (a hybrid learning algorithm which uses the differential evolutionary algorithm (DE) to select the input weights and Moore Penrose (MP) generalized inverse to analytically determine the output weights.) [46], and the proposed model EMA-ELM. The number of hidden nodes of all predicted models are set to 10. Finally, test samples are utilized to test the trained models. The test results are shown in Fig. 6.(15)SinC(x)=sin(x)x,−10<x<10As seen in Fig. 6, the proposed model EMA-ELM has better approximation to ‘SinC’ function than ELM, and DE-ELM. The results indicate that the proposed model has a good regression ability, and it is proved that EMA is effective for improving the generalization performance of ELM. In order to further illustrate the performance of three models, these models are run 50 times, and Tables 2 and 3show the statistical predicted results from different models. As shown in Tables 2 and 3, the results achieved by the proposed model are superior to the other models. The results indicate that the proposed model has good stability and robustness.The dataset consists of the measurement results for two-stage, the main blowing stage and auxiliary blowing stage. There are many factors affecting the endpoint results. More specifically, the endpoint results are affected by weight of molten iron, weight of scrap, weight of lime, weight of mixing material, weight of iron sheet, weight of ore, weight of dolomite, the process temperature measured by sub-lance, the process carbon content measured by sub-lance, and volume of the second-blowing oxygen.Generally speaking, molten steel is formed by the decarburization and rising temperature of molten iron. More specifically, the content of carbon is reduced from 4% to 0.08% or less, while the temperature is increased from 1250°C to 1650°C. When the error of endpoint carbon content satisfies |ΔC|<0.05%, the prediction carbon content can be accepted. When the error of endpoint temperature of the prediction model satisfies |ΔT|<15°C, the prediction temperature can be accepted.In simulation, there are 60 groups of the actual production data from the steel plant. Among them, 30 groups sample data are selected randomly as the training samples for the endpoint prediction model, while the remaining samples as the testing samples. The number of hidden nodes of all prediction models is set to 20.The predicting results for the endpoint carbon content and the endpoint temperature are shown in Figs. 7 and 8, respectively. As observed in Figs. 7 and 8, the proposed model for predicting the carbon content and the temperature has better results than the other models at the blowing endpoint.Hit is used to judge whether the prediction results satisfy the request of practical production or not. To further test the predicting capability of the experimental models, two evaluating indicators of hit rate are designed. These indicators are shown in Formula (16).(16)Chit=NcNf,Thit=NtNfwhere Ncrepresents the number of the furnace with meeting the error constraints of the carbon content. Chitis the hit ratio of carbon content on the total number of furnaces. Ntrepresents the number of furnaces which meet the error constraints of the temperature. Thitdenotes the hit ratio of temperature on the total number of furnaces. Nfis the sum of all furnaces.As observed in Tables 4 and 5, compared with the statistical results of the other two models, the proposed model achieves more better results on the endpoint hit rate for both the carbon content and the temperature. The results indicate that EMA can find the suitable parameters of ELM, thereby the proposed model not only has higher prediction accuracy but also has good robustness.

@&#CONCLUSIONS@&#
This paper presents a novel endpoint prediction model in BOF steel-making, which EMA identifies the parameters of ELM. The proposed model employs EMA to adaptively learn the parameters such as input weights and thresholds of ELM, and thus reduce overfitting and poor robustness causing by those parameters generated randomly of ELM. In the standard ‘SinC’ function with some noise, the proposed model not only has good regression ability, but also has good stability and robustness. Then, the actual production data in BOF steel-making is utilized, and the endpoint temperature model and the endpoint carbon content model are established, respectively. The good hit rate on both the temperature and the carbon content of molten steel has been attained, which indicates that the proposed model can be used for the endpoint prediction in the actual BOF steel-making. The proposed model is not only applied to the endpoint prediction in BOF, but also applied to the other areas of industrial production.