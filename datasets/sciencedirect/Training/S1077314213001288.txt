@&#MAIN-TITLE@&#
An optimisation approach to the recovery of reflection parameters from a single hyperspectral image

@&#HIGHLIGHTS@&#
We recover photometric parameters and shape from a single hyperspectral image.We view image radiance as a combination of specular and diffuse reflection component.We cast the recovery of the reflection parameters in an optimisation setting.The approach is quite general and can be applied to a number of reflectance models.

@&#KEYPHRASES@&#
Hyperspectral imaging,Reflectance modelling,Reflection parameter recovery,

@&#ABSTRACT@&#
In this paper, we present a method to recover the parameters governing the reflection of light from a surface making use of a single hyperspectral image. To do this, we view the image radiance as a combination of specular and diffuse reflection components and present a cost functional which can be used for purposes of iterative least squares optimisation. This optimisation process is quite general in nature and can be applied to a number of reflectance models widely used in the computer vision and graphics communities. We elaborate on the use of these models in our optimisation process and provide a variant of the Beckmann–Kirchhoff model which incorporates the Fresnel reflection term. We show results on synthetic images and illustrate how the recovered photometric parameters can be employed for skin recognition in real world imagery, where our estimated albedo yields a classification rate of 95.09±4.26% as compared to an alternative, whose classification rate is of 90.94±6.12%. We also show quantitative results on the estimation of the index of refraction, where our method delivers an average per-pixel angular error of 0.15°. This is a considerable improvement with respect to an alternative, which yields an error of 9.9°.

@&#INTRODUCTION@&#
In this paper, we focus on the recovery of the parameters governing the reflection of light from objects in the scene as captured by imaging spectroscopy sensors. The modelling of surface reflectance is a topic that is of pivotal importance, and has hence attracted considerable effort in both computer vision and computer graphics.In graphics, the problem is of interest since it allows physically realistic images of synthetic surfaces to be generated. In computer vision, the modelling of surface reflectance has attracted considerable attention due to its relevance to scene analysis and image understanding. For instance, Nayar and Bolle [35] have used photometric invariants derived from the BRDF to recognise objects with different reflectance properties. This work builds on that reported in [34], where a background to foreground reflectance ratio is introduced. In a related development, Dror et al. [11] have shown how surfaces may be classified from single images through the use of reflectance properties.Estimation of reflectance parameters is also closely related to the problem of recovering the shape of an object from its shading information. The classic approaches to shape from shading developed by Ikeuchi and Horn [23], and by Horn and Brooks [17], hinge on the compliance with the image irradiance equation and local surface smoothness. Zheng and Chellappa [58] proposed a gradient consistency constraint that penalises differences between the image intensity gradient and the surface gradient for the recovered surface. Moreover, although shape-from-shading [17] usually relies on the assumption of Lambertian reflectance [27], photometric correction or specularity subtraction may be applied as a preprocessing step to improve the results obtained. For instance Brelstaff and Blake [6] used a simple thresholding strategy to identify specularities on moving curved objects. Other lines of research remove specularities by either using additional hardware [35], imposing constrains on the input images [30], requiring colour segmentation [26] as postprocessing steps, or using reflectance models to account for the distribution of image brightness [41].Alternatively, the BRDF can be used to compute a reflectance map, to which a number of shape-from-shading methods may be applied [18,16]. The methods used to model or approximate the BRDF can be divided into those that are physics-based, semi-empirical [39,56] or empirical [27,40,48] in nature. Although the literature from physics is vast, it is perhaps the work of Beckmann on smooth and rough surface reflectance that is better known in the vision and graphics communities [2]. While it is based on physically meaningful surface parameters, the Beckmann theory relies on the evaluation of the Kirchoff wave scattering integral and breaks down when the surface roughness or the scattering angle are large. To overcome this problem, Vernold and Harvey [54] have developed a model which accounts for self shadowing on rough surfaces. Ragheb and Hancock [43] have exploited this modification of the Beckman–Kirchoff theory to develop a means of measuring surface roughness parameters using reflectance. Another widely used physics-based model that accounts for specular reflectance by modelling the angular distribution of surface microfacets is that in [52]. A survey of reflectance and shading models can be found in [46].For purposes of estimating the reflectance properties and light source direction of a scene, Ikeuchi et al. [24] have proposed an iterative least square optimisation based on a simplified Torrance–Sparrow reflectance model. The algorithm in [24] recovers the surface reflectance properties and light source direction from a range and a brightness image. With known geometry of the scene, Sato et al. [44] have utilised brightness values within shadows to solve a system of equations to simultaneously recover reflectance parameters and illumination distribution. Tominaga et al. [51] have proposed a method for estimating various reflection parameters of the Phong reflectance model [40] along with shape, illumination direction and colour from a single image. However, all of these methods assume that the light source and viewing positions are located at infinity. Therefore these methods do not offer a solution for real scenes under light and viewing positions at finite distances which do not follow parallel illumination and orthogonal projection. Later, based on the simplified Torrance–Sparrow reflectance model, Hara et al. [15] have developed a method without the distant illumination and orthogonal projection assumption that estimates reflectance property and light source position from a single image. However, their method still requires prior knowledge of the 3D shape of the scene that narrows down the applicability of this approach. Following a similar approach, the method by Boivin et al. [4] recovers reflectance properties of different surfaces from a single image. With known illumination, camera properties, and 3D geometric model, this method iteratively fits multiple reflection models from the simplest to the most complex one until the error between original and estimated image becomes less than a predefined threshold.We note that a number of models in the literature employ object shape, index of refraction, reflectance, and a measure of surface roughness to embody the surface reflectance. These models [2,52,8,56] also incorporate a Fresnel term [5]. Moreover, the reflectance and index of refraction are, in general, wavelength dependant. This leads to the natural extension of these techniques to multispectral and hyperspectral image understanding. However, the recovery of reflection parameters from a single hyperspectral image is relatively under researched. The method in [21], based on Dichromatic reflectance model, recovers the illuminant power spectrum and Dichromatic parameters in a structural optimisation setting. However, this method does not consider the wave-length dependency of the specular reflection. In [20], an iterative optimisation approach is presented. The method is applicable to a number of reflectance models [2,52,56] and able to recover shape and reflectance parameters from a single image with known illumination direction. Both of these approaches are based on a distant light source assumption and, hence, can break down when applied to real scenes under light and viewing positions at finite distances. Furthermore, in [20], the wave-length dependency of diffuse albedo is ignored and the surface reflectance is not modelled as a composition of both specular and diffuse components but rather the focus is on the optimisation of the model under consideration using Euler–Lagrange equations.Here, we present a method to recover the reflectance model parameters as a function of wavelength. We do not require prior knowledge on the geometry of the scene nor assume a point light source at infinity. Given a known illumination direction and a single image at input, we depart from a general formulation that hinges in the notion that the light reflected from an object can be deemed to be either specular or diffuse. This permits the recovery of the reflection parameters through an optimisation approach, whose target function is a linear combination of both, the specular and the diffuse reflection components. This, together with the use of Cauchy’s and Sellmeier’s expansions [5] permits the recovery of the index of refraction governing the Fresnel term of models such as Cook and Torrance’s [8], Torrance and Sparrow’s [52], Beckmann–Kirchoff’s [2] and Wolff et al.’s [56].The paper is organised as follows. We commence by expressing the object reflection as a linear combination of a diffuse and a specular component. With this linear combination at hand, we proceed to formulate the problem in an optimisation setting in Section 3. Further discussion is provided in Section 4, where we show how the general formulation presented in Section 2 can be expressed in terms of specific reflection models elsewhere in the literature. Here, we focus on the use of those models in [8,52,2] and [56]. We describe implementation issues in Section 5 and present results for our method on synthetic data and real-world imagery in Section 6, where we also compare against a number of alternatives. Finally, in Section 7, we conclude on the developments presented here.As mentioned earlier, our aim is to recover the reflectance model parameters. Nonetheless, there are a wide variety of reflectance models, we can depart from a generalist view of the reflection process based upon a physical interpretation, where the geometry of the scene, photogrammetric variables and wavelength dependent Fresnel term are used to describe the image formation process. From this general viewpoint, we can then cast the recovery of the reflection parameters in an optimisation setting.Here, we adopt a quite general approach applicable to a number of reflectance models in the existing literature [56,52,2,8]. We formulate the general reflectance model as a linear combination of two reflection components, namely diffuse and specular. This concept of modelling the scene radiance as a linear combination of two components was formally proposed by Shafer through the Dichromatic reflectance model [48]. Furthermore, this is consistent with a number of references elsewhere in the literature [56,20,8].It is worth noting in passing that optimisation approaches have been used in computer vision to recover the illuminant [12] and the surface normals [17]. As per the recovery of the reflectance, Fresnel reflection and other parameters, Weyrich et al. [55] have fit a BRDF model to the acquired data. In [20], the authors use Euler–Lagrange equations to recover the reflectance parameters corresponding to a number of reflectance models. These approaches follow the assumption that, given enough data, the reflectance parameters may be recovered accordingly. Note that, in our case, hyperspectral imaging does provide an information-rich representation of the scene which delivers a large amount of data and allows the wavelength dependence to be introduced into the optimisation process. This is similar rationale to that used in Weyrich et al.’s [55] work, where large amounts of trichromatic data is acquired using parallel hardware for purposes of fitting.Here, we further express the diffuse term and specular term as a function of reflection angle variables, photogrammetric variables and wavelength dependent index of refraction. Note that, a number of reflectance models follow a local coordinate system which corresponds to the reflection geometry given in the left-hand panel of Fig. 1. This geometry is defined with respect to a local coordinate system whose origin is the surface location and where the z′-axis is aligned to the normalised local surface normalN→. In the figure, we have denoted the unit incident light direction vectorL→, with slant θiand tilt ϕi. Also, following the costume in the literature, we denote the unit view vector asV→, whose slant is θsand tilt is ϕs. The unit half-way vector is denoted byH→and is given by the angular bisector ofL→andV→, i.e.H→=L→+V→|L→+V|→. We denote the angle betweenN→andH→as θh.Making use of the reflection geometry in Fig. 1, the illuminant power spectrum L(λl), the image radiance at pixel u and wavelength λlis given by(1)f(u,λl)=Wdiff(u)fdiff(L(λl),Θ(u),ρ(u,λl),η(u,λl))+Wspec(u)fspec(L(λl),Θ(u),σm(u),η(u,λl))In the equation above, the first term on the right-hand-side corresponds to the diffuse reflection component, where fdiff(·) stands for the diffuse image radiance and Wdiffdenotes the weight of the diffuse term. The second term on the right-hand-side describes the specular component, where fspec(·) denotes specular image radiance and Wspecdenotes the weight of the specular term. In Eq. (1), fdiff(·) is expressed as a function of the reflection angular variable-set Θ(u)={θi,ϕi,θs,ϕs,θh}, wavelength dependent diffuse albedo ρ(u,λl), and index of refraction η(u,λl). On the other hand, fspec(·) is expressed as a function of the reflection angular variable-set Θ(u), microfacet slope σm(u), and wavelength-dependent refracted index η(u,λl).Further, if the illumination direction is known, we can replace the reflection angle variables by surface gradients and reparameterise the general reflectance model with respect to surface gradients. The benefit of doing this is that such a reparameterisation implies that the number of geometric variables is two per pixel, i.e. p(u) and q(u). This reduces the number of reflectance equations needed to estimate the surface normalN→at pixel u. This reparameterisation is effected by making use of the viewer-centered coordinate system shown in the right-hand panel of Fig. 1. As a result, the (x,y)-axes correspond to the image row and column directions. This implies that, by definition, the surface normalN→at u is [−p(u),−q(u),1]T. This yields the reparameterised image radiance given by(2)f(u,λl)=Wdiff(u)fdiff(L(λl),p(u),q(u),ρ(u,λl),η(u,λl))+Wspec(u)fspec(L(λl),p(u),q(u),σm(u),η(u,λl))In such a coordinate system, the z-axis is lined-up with the optical axis and the positive x-axis points toward the right-hand side of the field of view. It is worth noting that this reparameterisation can be viewed as a rotation of the local coordinate system which aligns the viewer direction with the z-axis making use of the rotation matrix R as follows(3)z=Rz′Reflecting the notion that, in the local coordinate system, the surface normal is lined up with the z′-axis, whereas in the global coordinate system, the viewer is aligned with the z-axis we can rewrite Eq. (3) as follows(4)[0,0,1]T=1p2+q2+1R[-p(u),-q(u),1]Twhere we have assumed a normalised surface normal and used the fact that, in our global coordinate system, the viewer direction becomes [0,0,1]T.Given the illumination direction and a single hyperspectral image at input, we aim at recovering the reflectance parameters, i.e. index of refraction, albedo, microfacet slope, and surface normals. In our formulation, we depart from Eq. (2) in order to express the diffuse and specular term of the image radiance as a function of the surface gradients, photogrammetric variables (microfacet slope and wavelength dependent diffuse albedo) and wavelength dependent index of refraction. We also recover the weights Wdiff(u) and Wspec(u).Our method is an iterative one which employs a cost functionC(I)defined over the hyperspectral imageI. Here, we have expressed our cost function as the summation of two other cost functionalsCdiff(I)andCspec(I), where Cdiffis couched as the squared difference between the image diffuse spectral radianceIdiffand the first term on the right-hand-side of Eq. (2). The other cost functional, denoted by Cspec, corresponds to the squared difference between the image specular radianceIspecand the last term on the right-hand-side of Eq. (2).Thus, our cost function is given by(5)C(I)≜Cdiff(I)+Cspec(I)where(6)Cdiff(I)≜∑u∈I∑λl∈W[Idiff(u,λl)-Wdiff(u)fdiff(L(λl),p(u),q(u),ρ(u,λl),η(u,λl))]2can be viewed as a data term corresponding to the diffuse image radiance and(7)Cspec(I)≜∑u∈I∑λl∈W[Ispec(u,λl)-Wspec(u)fspec(L(λl),p(u),q(u),σm(u),η(u,λl))]2is the converse for the specular component ofI. In the equations above,Wis the wavelength range for the imagery under consideration.Note that, by making use of the linear combination in Eq. (5), we can separate the image radiance into its diffuse and specular components using a specularity removal method such as those in [50] or [30]. This separation responds to the observation that, in Eq. (2), the albedo ρ(·) and Wdiffcontribute only to the diffuse component, whereas σmand Wspeccontribute only to the specular component. Moreover, the index of refraction η(·) and surface gradients p(u), q(u) influence both the specular and diffuse terms.Therefore, we can adopt an optimisation approach where our aim of computation is the recovery of ρ(·) and Wdiffby maximising Cdiffsuch that(8)ρ∗(u,λl),Wdiff∗(u)←argminρ(u,λl),Wdiff(u)Cdiff(I)In a similar manner, we note that the microfacet slope σm(u) and weight Wspec(u) can be recovered by optimisingCspec(I)as follows(9)σm∗(u),Wspec∗(u)←argminσm(u),Wspec(u)Cspec(I)Finally, if the weightsWspec∗(u)andWdiff∗(u), albedo and microfacet slope are available, the index of refraction η(·) and surface gradients p(u), q(u) can be computed by optimising the combined cost function C. This can be expressed as(10)(η∗(u,λl),p∗(u),q∗(u))←argminη(u,λl),p(u),q(u)C(I)Thus, by expressing Eq. (5) in terms of Cspec(·) and Cdiff(·), we obtain twice as many data terms for the estimation of the index of refraction and the surface shape. Furthermore, we can estimate the albedo ρ(·) and the weight Wdiffby extremising the cost function in Eq. (6) alone. Analogously, the microfacet slope σmand the weight Wspeccan be estimated making use of Eq. (7). Since these two sets of parameters can be estimated independently, this treatment also opens-up the possibility of effecting these two optimisation steps in parallel and, once the optimal values of σm, Wspec, ρ(·), and Wdiffare in hand, the index of refraction η(·) and the surface normalN→=[-p(u),-q(u),1]Tat pixel u can be estimated.Here, we opt for a coordinate descent [14] optimisation scheme. This approach is shared with other methods elsewhere in the literature [21,15,44], where the complexity of the multivariable optimisation problem is tackled by optimising comparatively simple scalar subproblems.The idea is to minimise the multivariable cost functionC(I)in Eq. (5) by minimising it along one coordinate direction at a time while keeping all other coordinates fixed. Thus, the multivariable problem is actually solved by computing a sequence of scalar minimisation subproblems, where each of these is either a linear or a non-linear least square optimisation depending on whether or not the cost function is linear in the coordinate space, i.e. the variable under consideration. This provides the additional advantage that, for the linear least square subproblems, the cost function is variable-wise convex and, thus, a globally optimal solution is guaranteed. For the non-linear least squares, the measure of non-linearity and the ability to chose an initial estimate close to the optimal value effectively determines whether the method will converge to a global minimum.The algorithm thus proceeds as follows. At each iteration it recovers ρ(u, λl), Wdiff(u), σm(u), Wspec(u), η(u, λl) and {p(u),q(u)} in interleaved separate minimisation steps. Once it estimates one parameter, the current estimate is used to obtain the remaining parameters. This is, in effect, an update process where the iterations proceed until convergence is reached. The algorithm terminates when none of the parameters change between two successive iterations by an amount greater or equal to a predefined threshold and/or when maximum number of iteration is completed.For the least square optimisation involved we have selected the Levenberg–Marquardt method [29,31]. This method is actually a combination of the gradient descent and the Gauss–Newton method and efficiently utilises the complimentary advantages of these two methods. Being controlled by the value of a damping parameter, the method acts more like a gradient descent method when the parameters are far from their optimal value, whereas, it acts more like the Gauss–Newton method when the parameters are close to their optimal values. The method adaptively controls its own damping and this feature makes it applicable to a wide variety of problems. It increases the damping if a step fails to reduce the error; otherwise it decreases the damping. Thus it defensively navigates a region of parameter space in which the model is highly non-linear [28]. For updating the damping parameter, we adopt the strategy proposed in [38]. This is as it assures faster convergence than that originally proposed by Marquardt [31]. More importantly, it offers protection against a rank-deficient Jacobian and, therefore, it prevents the errors caused by singular Hessian matrices often found when the parameter space is highly non-linear.In the following subsections, we elaborate further on the step sequence of our algorithm, which, for the reader’s reference, we have summarised in the pseudo code shown in Algorithm 1. At input, our algorithm takes a hyperspectral imageIwhose pixel values correspond to the spectral radiance I(u,λl) for each of the wavelength-indexed bands{λ1,…,λ|W|}.At this point, it is worth noting in passing that, following [17], we can write the image radiance as the product of the light power spectrum and the reflectance R(u,λl), i.e.(11)I(u,λl)=L(λl)R(u,λl)The expression above has been used widely in the literature [25] and is consistent with reflectance models elsewhere, such as that in [12]. Indeed, this treatment allows for the estimation of the illuminant power spectrum L(λl) a priori, which we estimated using the method in [21], so as to recover the image reflectance R(u,λl). With the image reflectance in hand, we separate R(u,λl) into the diffuse and specular reflectance Rdiff(u,λl) and Rspec(u,λl) using the method presented in [50]. This can be done without any loss of generality due to the manner in which we have expressed the image radiance in Eq. (2), which is consistent with the relation R(u,λl)=Rdiff(u,λl)+Rspec(u,λl). These two steps are listed under the preprocessing tag in Algorithm 1.Here, we would like to stress that we use one of existing specularity removal methods as a preprocessing tool. This is not exclusive to our method but rather common across other reflectance parameter estimation approaches [15,33]. Specularity removal is often used to decompose the image radiance into specular and diffuse reflection. Thus, there has been a considerable amount of research on separating reflectance components. This literature is not the focus of the work presented here and, therefore, we refer the interested reader to the survey in [1].Note that, here, we employ different reflectance models in order to recover the relevant parameters. These are summarised in Table 1. The accuracy of these is expected to dependent on the diffuse-specular separation. Nonetheless, our method is not overly affected by errors on the specularity removal. This is as the only parameter which is exclusive to the specular pixels is the microfacet slope σm(u), which is shared by both, the Torrance–Sparrow [52] and Beckmann–Kirchhoff [2] models. This, de facto, constrains the estimation further. This is an important observation since diffuse pixels tend to be more abundant in images as compared to specular ones. Furthermore, in our experience, the errors in the specularity removal tend to be more evident at grazing angles, which does not overly affect the estimation of the albedo and index or refraction.Broadly speaking, the reflectance component separation methods can be categorised into two classes, i.e. colour-based and polarisation-based methods. Colour-based methods cannot estimate the diffuse component when the object is white whereas polarisation-based methods are only applicable to materials whose molecules are isotropically arranged, e.g. plastics, paints, papers, metals, woods, clothes, glasses, or liquids. Moreover, in practice, polarizers often fail to remove strong specularities in objects made of materials such as metals, glasses, or liquids [32]. As a result, here we adopt the colour-based component separation technique in [50]. Although this method is based on trichromatic image, it is quite straightforward to apply this to a hyperspectral image. This method requires illumination spectrum normalisation, so the spectra of illumination, L(λl) need to be known beforehand. For us, it is not a problem as we are estimating L(λl) at the preprocessing step of our algorithm. We then normalise image radiance by dividing it by illuminant spectrum for allλl∈Wand provide the method the normalised image intensity value as input. Note that other specularity removal methods elsewhere in the literature may also be used.To initialise the surface normal parameters p(u) and q(u), we follow Worthington and Hancock [57] and make use of the image gradients. Recall that, in [57], the parameters p(u) and q(u) are initialised making use of a grey-scale image. This is in contrast with our imagery, which is wavelength indexed. To tackle this problem, we note that, from robust statistics [19], it can be shown that, if the estimation errors are normally distributed with zero-mean, the expected value can be used as an unbiased estimator. Thus, we have(12)p(u)=1|W|∑l=1|W|∂Rdiff(u,λl)∂xandq(u)=1|W|∑l=1|W|∂Rdiff(u,λl)∂yThe rest of the variables are initialised with random values in the interval [0,1].Algorithm 1Estimating reflectance model parametersInput:The hyperspectral input imageIwhose pixel values correspond to the measured spectral radiance I(u,λl) indexed to wavelengthλl∈W.Output:{ρ(u,λl),η(u,λl),σm(u),Wspec(u),Wdiff(u),p(u),q(u)}|∀u∈I,λl∈WPreprocessing:(i)Estimate the illuminant power spectrum L(λl) using the method in [21] so as to compute R(u,λl) from I(u,λl) using Eq. (11).(ii)Separate R(u,λl) into Rdiff(u,λl) and Rspec(u,λl) using the method in [50].1: t←12: while true do3:for allu∈Ido4:for allλl∈Wdo5:ρ∗(u,λl)←argminρ(u,λl)Cdiff(I)givenWdiff(u)t-1,η(u,λl)t-1,p(u)t-1,q(u)t-16:end for7:end for8:for allr∈Ido9:ρ(u,λl)t←1|r|∑u∈rρ∗(u,λl),∀u∈r,λl∈W10:end for11:for allu∈Ido12:Wdiff(u)t←argminWdiff(u)Cdiff(I)|ρ(u,λl)t,η(u,λl)t-1,p(u)t-1,q(u)t-113:end for14:for allu∈Sdo15:σm(u)t←argminσm(u)Cspec(I)|Wspec(u)t-1,η(u,λl)t-1,p(u)t-1,q(u)t-116:end for17:for allu∈Sdo18:Wspec(u)t←argminWspec(u)Cspec(I)|σm(u)t,η(u,λl)t-1,p(u)t-1,q(u)t-119:end for20:for allu∈Ido21:for allλl∈Wdo22:η∗(u,λl)←argminη(u,λl)C(I)givenρ(u,λl)t,Wdiff(u)t,σm(u)t,Wspec(u)t,p(u)t-1,q(u)t-123:end for24:end for25:for allu∈Ido26:Ck(u)t=argminCk(u)∑λl∈Wη∗(u,λl)-∑k=1MCk(u)t-1λl-2(k-1)227:for allλl∈Wdo28:ηˆ(u,λl)t=∑k=1MCk(u)tλl-2(k-1)29:end for30:end for31:for allr∈Ido32:η(u,λl)t←1|r|∑u∈rηˆ(u,λl),∀u∈r,λl∈W33:end for34:for allu∈Ido35:p(u)t,q(u)t←argminp(u),q(u)C(I)givenρ(u,λl)t,Wdiff(u)t,σm(u)t,Wspec(u)t,η(u,λl)t36:end for37:converge←∑u∈I∑λl∈Wδ(ρ(u,λl))⩽εand∑u∈I∑λl∈Wδ(η(u,λl))⩽εand∑u∈Iδ(σm(u))⩽εand∑u∈Iδ(Wdiff(u))⩽εand∑u∈Iδ(Wspec(u))⩽εand∑u∈Iδ({p(u),q(u)})⩽ε38:ifconverge or t>tmaxthen39: break40:else41:t←t+142:end if43: end while44: returnρ(u,λl), η(u,λl), σm(u), Wspec(u), Wdiff(u), p(u), q(u)As mentioned earlier, the structure of the cost function in Eq. (5), permits the recovery of albedo ρ(u,λl) and diffuse weight Wdiff, making use of the diffuse radiance devoid of the specular reflection. As a result, in this subsection, we focus on these two parameters, whereas in SubSections 3.2 and 3.3, we turn our attention to other photometric variables and object’s shape.To commence, we recover ρ(u, λl) at each pixelu∈Iand wavelengthλl∈Wgiven the current estimate of index of refraction η(u,λl), diffuse weight Wdiff(u), and surface gradients p(u), q(u) as recovered at the previous iteration. This corresponds to Lines 3–7 of Algorithm 1. As the albedo only contributes to the diffuse component of reflectance, we estimate it making use of the diffuse term in cost function in Eq. (6). Moreover, to recover ρ(u,λl) at each pixel u and wavelength λl, we optimise over the neighbourhood Ωuof u, this yields(13)ρ∗(u,λl)=argminρ(u,λl)∑v∊ΩuRdiff(v,λl)-Wdiff(v)L(λl)fdiff(L(λl),p(v),q(v),ρ(v,λl),η(v,λl))2where we have introduced the illuminant power spectrum L(λl) so as to express the squared difference above in terms of diffuse reflectance as an alternative to the diffuse image radiance. Hereafter, we will employ this formalism for the sake of consistency.Furthermore, note that, for each material in the image under consideration, the diffuse albedo is uniform across the scene. Thus, after recovering ρ∗(u,λl) for all the pixels in the image, we cluster the corresponding diffuse albedo into {r1,…,rc} regions. This implies that each region r represents a unique material with unique diffuse albedo. By assuming normally distributed estimation errors with zero-mean, we can further improve our estimate of ρ(u,λl) in Lines 8–10 of Algorithm 1 by taking the expected value over all pixel u∈r as given by(14)ρ(u,λl)=1|r|∑u∊rρ∗(u,λl)over all the material regions in the scene.As mentioned earlier, we also recover the diffuse weight Wdiffat each pixelu∈I. This is done making use of the optimal value of diffuse albedo ρ(u,λl) yielded by the optimisation in Eqs. 13 and 14 and the other parameters, i.e. the index of refraction η(u,λl) and surface gradients p(u) and q(u) recovered at the previous iteration. This process is outlined in Lines 11–13 of Algorithm 1.The diffuse weight determines the contribution of the diffuse reflectance in the linear combination in Eq. (2). We, therefore, estimate this parameter by optimising the cost function in Eq. (6) making use of the fact that the diffuse weight should be fixed over the wavelength domain. Thus, our optimisation is effected per-pixel such that(15)Wdiff∗(u)=argminWdiff(u)∑l=1|W|Rdiff(u,λl)-Wdiff(u)L(λl)fdiff(L(λl),p(u),q(u),ρ(u,λl),η(u,λl))2With the diffuse albedo and weight, we now focus in the recovery of the microfacet slope and the specular weight. As the microfacet slope only influences the specular reflection, it cannot be estimated for matte pixels, which do not convey any information on the specular reflection parameters. As a result, we only estimate σmfor those pixelsu∈S, whereSis the set of specular pixels inI.With the optimal values of specular weight Wspec(u) and the index of refraction η(u,λl) computed at the previous iteration, we recover the microfacet slope making use of the optimisation corresponding to(16)σm∗(u)=argminσm∑l=1|W|Rspec(u,λl)-Wspec(u)L(λl)fspec(L(λl),p(u),q(u),σm(u),η(u,λl))2+αRthis accounts for Lines 14–16 of Algorithm 1 and is consistent with the fact that every wavelength-indexed band for the pixel u share the same σm.Here, we have also introduced a regularisation termRwhere α is a constant that determines the contribution of the regulariser to the optimisation process. A number of regularisation schemes can be used, these span from curvature constraints as applied in shape-from-shading [57] to surface integrability [13]. Since, in practice, σmshould not overly vary over the neighbourhood of the pixel u, here we employ a regularisation term which enforces a smoothly varying microfacet slope given by(17)R=∑v∊Ωu(σm(u)-σm(v))2This parameter determines the contribution of specular component of reflectance in the linear combination in Eq. (2). We, therefore, estimate this parameter by optimising cost function in Eq. (7) so as to encourage data closeness between the measured specular reflectance Rspecand the specular term in Eq. (2). For totally diffuse pixels, the specular weight should be zero. Our method therefore estimates Wspecfor each pixelu∈Sgiven the optimal value of microfacet slope σm(u) estimated using Eq. (16) and the current estimates of the refractive index η(u,λl) and surface gradients p(u), q(u). This corresponds to Lines 17–19 in Algorithm 1.In a manner analogous to the diffuse weight recovered in Subsection 3.1.2, Wspecvaries per pixel, remaining fixed over the wavelength domain. Thus, we optimise over the wavelength-indexed bands as follows(18)Wspec∗(u)=argminWspec(u)∑l=1|W|Rspec(u,λl)-Wspec(u)L(λl)fspec(L(λl),p(u),q(u),σm(u),η(u,λl))2Finally, we turn our attention to the two parameters that apply to both, specular and diffuse reflection. Here, we estimate the index of refraction by noting that each material has its own unique refracted index defined over the spectral domain. Thus, our algorithm recovers the index of refraction per material. Further, following [22], we have constrained the index of refraction to follow Cauchy’s dispersion equation [5].Analogous to our approach to recover the diffuse albedo, we first estimate the index of refraction per pixel. Then, we refine our estimated value by updating η(·) per material making use of the expected value over all pixels belonging to each material in the scene. Since η(·) contributes to both, the specular and diffuse component of reflection, we optimise using the cost function in Eq. (5), which comprises the data closeness terms for both, the specular and diffuse reflectance. This is depicted in Lines 20–24 of Algorithm 1. Here, in a manner akin to Section 3.2.1, we assume that, at each wavelength λl, η(·) varies slowly about the neighbourhood of pixel u. Therefore, we optimise over Ωu, i.e. the neighbourhood of pixel u, so as to recover η(·) at pixel u and wavelength λlas follows(19)η∗(u,λl)=argminη(u,λl)∑v∈ΩuRdiff(v,λl)-Wdiff(v)L(λl)fdiffL(λl),p(v),q(v),ρ(v,λl),η(v,λl)2+Rspec(v,λl)-Wspec(v)L(λl)fspec(L(λl),p(v),q(v),σm(v),η(v,λl))2and, with the per-pixel estimates at hand, We constrain the refractive indexes to follow Cauchy’s dispersion equation.Recall that Cauchy’s equation is an empirical expression relating the refractive index to the wavelength through material specific dispersion coefficients. To enforce Cauchy’s dispersion, we first estimate dispersion coefficients by fitting Cauchy’s equation to the estimated index of refraction as follows(20)Ck∗(u)=argminCk∑l=1|W|η∗(u,λl)-M∑k=1Ck(u)λl-2(k-1)2Here, the coefficients Ck(u), k∊{1,…,M} can be viewed as a characteristic of the material. In Algorithm 1, Lines 25–30 we recover the M dispersion coefficients at each pixel u by optimising over the corresponding wavelength-indexed bands. With the estimated dispersion coefficients, the index of refraction can be updated, as shown in Line 28 of Algorithm 1, using the expected value for Cauchy’s equation given by(21)η(u,λl)=1|r|∑u∊r∑k=1MCk∗(u)λl-2(k-1)where we have used the regions recovered while updating the diffuse albedo.We now proceed to recover the object surface gradients making use of the viewer-centered global coordinate system presented in Section 2.1. Recall that, on our viewer-centered coordinate system, the surface normalN→can be expressed in terms of surface gradients. As a result, the vectors [1,0,p]Tand [0,1,q]Tare, hence, tangent to the surface. By definition, the surface normal is perpendicular to all vectors in the tangent plane and parallel to the cross-product of these two, that is(22)[1,0,p(u)]T×[0,1,q(u)]T=[-p(u),-q(u),1]Tand, as mentioned earlier, the normalised surface normal is given by(23)N→(u)=1[p(u)2+q(u)2+1]12[-p(u),-q(u),1]TThe expression above is important since it permits the recovery of the object’s shape at each pixel by estimating only two variables, i.e. p(u) and q(u), per pixel u. As per the reparameterisation in Eq. (2), we perform the optimisation procedure making use of both, the diffuse and specular components. This is reflected in Lines 34–36 of Algorithm 1. This is a straightforward task since the other reflection parameters are in hand. Moreover, we introduce a regularisation term corresponding to the integrability constraint widely used in shape-from-shading [13,57]. Thus, the optimisation becomes(24)[p∗(u),q∗(u)]=argminp(u),q(u)∑v∊Ωu∑l=1|W|Rdiff(v,λl)-Wdiff(v)L(λl)fdiffL(λl),p(v),q(v),ρ(v,λl),η(v,λl)2+Rspec(v,λl)-Wspec(v)L(λl)fspecL(λl),p(v),q(v),σm(v),η(v,λl)2+∂p(v)∂y-∂q(v)∂x2In the optimisation above, the last term on the right-hand-side corresponds to the regularisation term. Also, note that we optimise the cost functional over the neighbourhood Ωuof pixel u. This implies that the surface normalN→varies slowly about the pixel under consideration. This assumption does not imply any strong constraint on the surface shape rather reflects that, over small neighbourhoods of u, the surface can be considered to be locally smooth.Finally, we discuss two criteria of the algorithm to stop searching for optimal values of the parameters: (i) when the algorithm is already converged; no improvement is seen at the current cycle of optimisation along different coordinate directions, (ii) when the algorithm already completed maximum number of iterations tmaxand therefore giving up. Line 37 of Algorithm 1 describe the convergence criteria, where the function δ(·) is used to denote the absolute difference between the estimates at iterations t and t−1 for any of the reflectance parameters. Therefore, as long as there is a significant change in the current estimate for at least one of the parameters and t<tmax, the algorithm continues, otherwise, it stops and returns the parameter values estimated so far.So far, we have made no assumptions regarding the specific reflectance model to be used for purposes of optimisation. In this section, we examine a number of reflectance models elsewhere in the literature which conform to the general formulation and optimisation approach described in Sections 2 and 3. It is worth noting in passing that, in previous sections, we have used the diffuse and specular image radiance, which can be related to the reflectance in the models hereafter making use of the relations(25)Rdiff(u,λl)=1L(λl)fdiff(L(λl),p(u),q(u),ρ(u,λl),η(u,λl))Rspec(u,λl)=1L(λl)fspec(L(λl),p(u),q(u),σm(u),η(u,λl))In practice, we can use the relations above so as to substitute the reflectance corresponding to one or more of the models elsewhere in the literature into the cost function in Eq. (5). Thus, we elaborate upon four reflectance models elsewhere in the literature and their specific parameters.We commence by exploring the use of the Torrance–Sparrow model [52], which describes the reflectance from rough surfaces as comprised by two components. These are Lambertian diffuse reflection and the specular lobe. Here, we will focus on the component describing the specular lobe exhibited by smooth and rough surfaces. The main idea in [52] is to model a surface as a collection of perfectly smooth mirror like microfacets. In the model, these microfacets are perfect mirrors.For a given light source and viewer directionsL→andV→, the specular reflection is solely dependent on those microfacets with a normalN→aligned with the halfway vectorH→. The corresponding equation for the specular reflectance is therefore given by:(26)RTS(u,λl)=Af4F(θi,η(u,λl))G(θi,θs,ϕi,ϕs)cosθsD(θh,σm)where(27)G(θi,θs,ϕi,ϕs)=min1,2(N→·H→)(N→·V→)(V→·H→),2(N→·H→)(N→·L→)(V→·H→)(28)D(θh,σm)=cexp-θh22σm2the notation · denotes the dot product between vectors, c is a constant and σmis the roughness parameter.Note that, according to Eq. (26), the specular reflectance RTS(·) at pixel u and wavelength λlis governed by the microfacet area Af, the wavelength dependent Fresnel term F(·), geometric attenuation factor G(·) and the microfacet slope distribution function D(·). In the model, the geometric attenuation factor G(·), as given in Eq. (27), accounts for the microfacet-to-microfacet masking and shadowing. The microfacet distribution function D(·) used here is a rotationally symmetric normal distribution with zero mean, i.e.θ¯h=0, and standard deviation σm, which captures the probability density of the microfacets pointing in the direction of the halfway vectorH→.As the surface is not a perfect reflector, only a fraction of the incident light reaching the facets will be reflected. The Fresnel term F(·) determines the fraction of incident light which is reflected by each facet. The computation of the Fresnel term is quite expensive computationally and, therefore, here we apply the Schlick approximation [45] given by(29)F(θi,η(u,λl))=Ro+(1-Ro)(1-cosθi)5where, as before, θiis the angle of incidence and η(u, λl) is the refractive index at pixel u and wavelength λl. In Schlick’s approximation, Rois the reflectance at normal incidence, defined asR0=1-η(u,λl)1+η(u,λl)2.A model akin to that of Torrance and Sparrow is that developed by Cook and Torrance [8]. This is actually a combination of the Torrance–Sparrow model [52] and the Blinn model [3]. Just like the Torrance–Sparrow model, it considers the Fresnel term, surface self-shadowing and microfacets for reflectance modelling. However, it provides microfacet distribution functions for the Phong model [40], the Trowbridge-Reitz [53] and the Beckmann [2] distributions. Here we describe the reflectance equation of this model using the Beckmann distribution. Therefore, the reflectance equation, as described by this model, is given as(30)RCT(u,λl)=F(θi,η(u,λl))G(θi,θs,ϕi,ϕs)cosθscosθiDBK(θh,σm)where DBK(·) stands for the Beckmann distribution function given by(31)DBK(θh,σm)=1σm2cos4θhexp-tanθhσm2We now turn our attention to another model widely cited in the computer vision and graphics literature. The Beckmann–Kirchhoff model [2] describes the reflection from a surface as a sum of two terms. The first of these corresponds to the scattering component in the specular direction and the latter represents the diffuse scattering. The term describing the specular spike given by(32)RBK(u,λl)=P02(θh,σ)exp(-g(θi,θs,λl,σh))F(θi,η(u,λl))where(33)P0(θh,σ)=12πσexp-θh22σ2and(34)g(θi,θs,λl,σh)=2πσhλl(cosθi+cosθs)2The third term in Eq. (32) corresponds to the wavelength dependent Fresnel term F(·) as described in Eq. (29). Note that, even though there is no Fresnel term in the model as proposed in [2], we have included it without any loss of generality so as to make the specular reflectance component consistent across the models presented in this section. This also reflects the notion that no surface is a perfect reflector and, therefore, the Fresnel term is used to determine the fraction of the incident light reflected from the surface as a function of incident angle and index of refraction.According to Eq. (32), the specular reflectance RBK(·) at pixel u and wavelength λlis a product of three terms. The first of these is the magnitude of the specular reflectance P0 which is a function of θh. This function is nearly zero for all scattering directions except a very narrow range around the halfway vectorH→. In the Beckmann–Kirchhoff model, P0 is expressed as a sinc function. Nonetheless, here, for the sake of computational efficiency, we have followed Nayar et al. [36] and employed a Gaussian function with a very small standard deviation σ. The second term is comprised by the function g(·), which is related to the surface roughness throughσhλl, the incidence angle θiand reflected light angle θs. The three cases g≪1, g≈1, and g≫1 correspond to smooth surface, moderately rough and rough surface, respectively.Note that both, the Torrance–Sparrow and Beckmann–Kirchhoff models incorporate the surface roughness parameter, i.e. σmin Eq. (26) and σhin Eq. (32), as a pertinent parameter to influence the reflectance characteristic of the surface. However, these two reflectance models are based on two different surface models. Whereas the Beckmann–Kirchhoff model uses the microfacet height distribution, the Torrance–Sparrow model is based on slope distribution model. Hence, the roughness parameters of these two models are not equivalent. This is important, since our work defines the surface based on slope distribution model and uses a roughness parameter akin to that in the Torrance–Sparrow model. This is not overly restrictive since the surface roughness parameter in the Beckmann–Kirchhoff model can be transformed into that used in our derivation following the approach presented in [36]. We do this making use of the correlation distance T for the height distribution model. We get(35)σh=T2tan2σmwhere(36)g(θi,θs,λl,σm)=πTλltan2σm(cosθi+cosθs)2Finally, we elaborate upon the model proposed by Wolff [56]. This is a diffuse reflection model for smooth dielectric surfaces. When the angle between the illuminant and the viewing direction is large, a significant deviation from Lambert’s law [27] is prevalent for many dielectric objects. The Wolff model explains this deviation from Lambert’s law by considering the refractive attenuation at the surface-air layer. It multiplies Lambert’s cosine law with two Fresnel terms: one for incident light and the other for reflected light. The diffuse reflectance, as defined by the Wolff model is given by:(37)RWF(u,λl)=ρ(u,λl)cosθi[1-F(θi,η(u,λl))]1-Fθs′,1η(u,λl)where, as in previous sections, ρ(u,λl) is the diffuse albedo, η(u,λl) is the index of refraction of the dielectric medium, θiis the angle of incidence for the light ray andθs′is the internal angel of incidence that relates the reflected angle θswith Snell’s law, i.e.θs′=arcsinsin(θs)η(u,λl).Recall that we have expressed the image reflectance as a linear combination of the specular and diffuse reflection. In our experiments, we use a linear combination of three reflectance models described in the previous section. This is given by(38)R(u,λl)=Wdiff(u)RWF(u,λl)+Wlobe(u)RTS(u,λl)+Wspike(u)RBK(u,λl)In Eq. (38), each term represents a different reflection component. We have selected the Wolff model [56] to describe the diffuse reflectance. We have further divided the specular term into the spike and lobe, where we use the Torrance–Sparrow model [52] for the specular lobe and the Beckmann–Kirchhoff model [2] to describe the specular spike. These two terms are governed by the weights Wlobeand Wspike, which control the contribution of the specular lobe and spike to the image radiance.The parameters for each of these models are summarised in Table 1. The optimisation procedure described in Section 3 can be readily applied to recover all the parameters except the contributions of the lobe and spike as captured by Wlobeand Wspike. These can be estimated making use of the optimisation given by(39)Wlobe∗(u),Wspike∗(u)=argmin[Wlobe(u),Wspike(u)]∑l=1|W|(Rspec(u,λl)-Wlobe(u)RTS(u,λl)-Wspike(u)RBK(u,λl))2as an alternative to Eq. (18). In the equation above, we have accounted for the relationship between the specular image radiance and reflectance and opted for a notation consistent with Eq. (26) and (32).As shown in Algorithm 1, our coordinate descent algorithm operates on each coordinate in a cyclic order until convergence. At each cycle, it recovers ρ(u,λl), Wdiff(u), σm(u), {Wlobe(u), Wspike(u)}, η(u,λl) and {p(u), q(u)} in interleaved separate minimisation steps. Note that the recovery of ρ(u,λl), Wdiff(u) and {Wlobe(u), Wspike(u)} can be formulated as linear least squares minimisation problems. These are therefore variable-wise convex and have a globally optimal unique solution.First, we turn our attention to the recovery of diffuse albedo using the following equation, which is in fact, a model specific form of Eq. (13), where we place the Wolff reflectance model to account for the diffuse reflectance.(40)ρ∗(u,λl)=argminρ(u,λl)∑v∊Ωu[Rdiff(v,λl)-Wdiff(v)RWF(v,λl)]2.The second order derivative of Eq. (40) with respect to albedo is2∑v∊ΩuC(v,λl)2where,C(v,λl)=Wdiff(v)cosθi[1-F(θi,η(v,λl))]1-Fθs′,1η(v,λl). Note that the second order derivative is always positive and, thus, Eq. (40) is convex with respect to the diffuse albedo. Analogously, we can derive the second order derivative of model specific form of Eq. (15) with respect to diffuse weight, which is also always positive,2∑l=1|W|RWF(u,λl)2and hence guarantees global minima.For the two specular weights, Wlobe(u) and Wspike(u), we use Eq. (39). The determinant of corresponding Hessian matrix is:(41)det(H)=4∑l=1|W|RTS(u,λl)2∑l=1|W|RBK(u,λl)2-4∑l=1|W|RTS(u,λl)RBK(u,λl)2which is also positive and therefore confirms the unique minima for this function.The recovery of σm(u), η(u,λl), and {p(u),q(u)} are non-linear least squares problems. Note that, as mentioned earlier, the measure of non-linearity and the ability to chose initial estimates close to the real parameter determines whether our method will converge to a minimum. In all our experiments, the algorithm converges with our provided initial values, as described in Section 3.By calculating the remaining second order derivatives for the corresponding cost functions, we can further comment on the non-linearity of the estimation task in hand. For example, for the microfacet slope σm(u), the cost function is “flat” when the angle θh(u) has large values; i.e. when the halfway vector significantly deviates from the surface normal. According to specular reflectance models [2,52,8], in this case, u is not a specular pixel and therefore the algorithm cannot estimate σm(u) at pixel u that does not contribute to the specular reflectance. That is why we estimate microfacet slope only at specular pixels.We have already seen that the cost function for index of refraction has contribution from both specular and diffuse component. If we are to estimate η(u,λl), where local neighbourhood of u is a purely diffuse region, just like σm(u), the specular part of the cost function becomes flat for larger value of θh. In this case, η(u,λl) can still be recovered from the diffuse part. On the other hand, the diffuse part becomes flat for pixels with poor illumination and low image reflectance.For all our least square optimisation, we have used the Levmar C++ library available for download from FORTH-ICS.2http://www.ics.forth.gr/∼lourakis/levmar.2This library provides a Levenburg-Marquardt method which can employ both, an analytic Jacobian or finite difference approximated Jacobians. For computing the gradients {p(u),q(u)}, we avoid the possibly complex analytical derivation of the Jacobian and use finite difference approximated Jacobians. For all the other parameters, we provide the solver with analytic Jacobians. This has the effect of a reduced computational complexity.In our experiments, the Levmar solver has been set to terminate when at least one of the following conditions is met: when the gradient of the cost drops bellow a threshold ∊1, when the change in parameter values has fallen to some threshold ∊2, when cost itself has reached some acceptable value ∊3, and when specified number of iterations itmaxis completed. Therefore, the library requires four user defined threshold values; We provide 10−15 for ∊1 and ∊2, 10−20 for ∊3, and 100 for itmax. The library also requires a user input τ to set the initial value for the damping term. According to the damping strategy of the algorithm, τ should be smaller only if we believe that our provided initial value of the unknown parameters are close to optimal value. Therefore, we set τ to 10−6 for {p(u),q(u)} as we get the initial value from image gradients, whereas, we set 10−1 for the rest.

@&#CONCLUSIONS@&#
In this paper, we have presented a method to recover reflection model parameters and object’s shape from a single hyperspectral image. The method is quite general in nature, stemming from the use of a general formulation for the image radiance based upon a linear combination of the diffuse and specular reflection components. This treatment permits, in turn, the use of a coordinate descent least-square optimisation approach to recover the parameters governing the reflection process. Moreover, the formulation provided here allows for the optimisation on the diffuse and specular reflection to be effected in parallel. Unlike other methods, we do not require prior knowledge of the geometry of the scene nor assume a point light source at infinity. Given the illumination direction, this method utilises the information-rich representation of hyperspectral imagery to recover parameters that can be applied for scene analysis, image understanding, and object recognition purposes. We have illustrated how this optimisation process can be used in combination with the Beckmann–Kirchhoff, the Torrance–Sparrow, and the Wolff reflectance model to recover the index of refraction, microfacet slope, diffuse albedo, and surface normal from a single image. We have also shown results on skin recognition and compared with an alternative elsewhere in the literature.