@&#MAIN-TITLE@&#
Stabilization of panoramic videos from mobile multi-camera platforms

@&#HIGHLIGHTS@&#
Stabilization of panoramic and stabilization of single camera videos are separate problems.Panoramic videos suffer from global and inter-camera vibrations.Blend-masks are useful for dealing with inter-camera vibrations.Our survey suggests that viewers prefer this scheme over prior works.

@&#KEYPHRASES@&#
Panoramic Videos,Video Stabilization,Video Stitching,Mobile multi-camera platforms,

@&#ABSTRACT@&#
Graphical abstract

@&#INTRODUCTION@&#
Multimedia technology has seen a rapid evolution in recent years in terms of both quality and quantity of the information delivered through multimedia displays. Wide Field of View (FOV) panoramic images and videos provide ultra-high definition content that when displayed on large high definition displays, provide an immersive experience to the viewers. Panoramic videos are generated either by using fish-eye lens or by stitching together synchronized video frames coming from multiple cameras arranged on a rig [1,2]. The use of stitching-based panorama generation and display systems once limited to geological surveys and surveillance applications [3] has already been extended for entertainment purposes [4–6]. With decreasing cost of commodity cameras, this trend is expected to be more ubiquitous [7] in the entertainment industry, closely followed by household consumer market in the future. Thus, instead of static panorama acquisition systems [3] that arrange closely coupled sensors in a dedicated closed unit [2], affordable panoramic acquisition systems are emerging that employ commodity cameras mounted on a platform. When set on a mobile platform, such a panoramic video acquisition system may suffer from mechanical vibrations that are global to the camera rig or independent to a particular constituent camera. The global vibrations appear as global jitter in the panoramic video frames while the inter-camera vibrations result in jitter in the spatial region of panoramic video contributed by the particular affected cameras. This results in an unpleasant experience for viewers. This is illustrated conceptually in Fig. 1which shows a single frame of a panoramic video (‘Man video’) that was formed by stitching frames acquired using three cameras. Please refer to the accompanying video to watch this panorama sequence. The tail of the arrows in Fig. 1 represents the location of a few salient features tracked using Kanade–Lucas–Tomasi (KLT) feature tracker [8,9]. The yellow, red and green vectors represent the direction of motion of these features at a particular instance in time and are color coded to signify the independent direction of motion for the contents captured from camera 1, camera 2 and camera 3 respectively. Fig. 1 illustrates an example where camera 3 is experiencing a different vibration and hence its motion vectors (green) appear to have a different direction as compared to camera 1 and camera 2. In the panoramic video (Man video), this effect appears as jitter in the region of panoramic video frames that is contributed by camera 3. Since this jitter appears in a sub-section of panoramic frame, we term it as sub-frame jitter. The ‘Man video’ demonstrates this effect for an actual setup and thus supports our motivation for the requirement of a stabilizing scheme particularly aimed at panoramic videos.The problem of single camera video stabilization has been extensively researched and has reached a certain level of maturity [10–14]. However, for stabilization of panoramic videos captured from multi-camera platforms, little work has been reported. Furthermore, the existing schemes for such systems [15,16] do not account for the inter-camera vibrations experienced in mobile platforms. In this paper, we treat stabilization of panoramic multi-camera videos as a distinct problem from that of a single camera video. We achieve this by classifying the effects of these vibrations as global, sub-frame and local jitter, and by proposing a method to deal with each one of these in a systematic fashion. In summary, global stabilization is achieved by estimating 2D motion models using the tracked feature trajectories over the complete panoramic frame. Sub-frame stabilization is achieved by making use of the information available in the blend masks that are generated by the stitching application [1]. Blend masks are the intensity weights that are used to blend together the images acquired from multiple cameras to generate a seamless panorama. Finally, the local stabilization tackles the residual jitter that might appear in parts of the panoramic scene in the video due to differences in the scene depth. To the best of our knowledge, this is the first scheme that acknowledges that panoramic videos need to be stabilized temporally as a sequence of stitched frames, as well as spatially to handle the sub-frame jitter.This paper is organized as follows. In Section 2, we provide a brief account of predominant approaches for video stabilization. In Section 3, we provide the necessary background for panoramic video stitching process followed by a description of the proposed stabilization scheme. In Section 4, we discuss the comparison of the results of the proposed scheme with that of two recent stabilization schemes [14,15] for a number of videos. Finally in Section 5, we present our conclusion.

@&#CONCLUSIONS@&#
In this paper we propose a video stabilization scheme specifically for stitched panoramic videos generated using mobile multi-camera rigs. The proposed scheme acknowledges that each camera in the panoramic video acquisition system may exhibit independent motion due to which, parts of the panorama contents coming from a camera may jitter differently from the rest. It was demonstrated that by classifying the vibrations for such systems into three categories: global, sub-frame and local vibrations, the problem can be handled efficiently and effectively. For global stabilization, a dynamic trajectory selection criterion was introduced to ensure continuity of the process pipeline. In sub-frame stabilization, for the tracked features found in the overlapping regions of two neighboring cameras, the estimated 2D smoothing transform was weighted by the blending weights generated during the stitching process. In the final step, clustering was used to ensure that erroneous feature trajectories are unable to create artifacts in the video. The performance of the proposed scheme has been compared with two recent stabilization schemes [14,15] by performing rigorous testing for over 40 panoramic videos captured in a variety of settings. Our method successfully stabilizes the videos where the traditional stabilization methods fail. A subjective evaluation was also performed that demonstrated the success of our formulation and technique.The following are the supplementary data related to this article.Supplementary material.Supplementary video.Supplementary data to this article can be found online at http://dx.doi.org/10.1016/j.imavis.2015.02.002.