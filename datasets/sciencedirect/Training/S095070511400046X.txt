@&#MAIN-TITLE@&#
Robust evidential reasoning approach with unknown attribute weights

@&#HIGHLIGHTS@&#
We propose a robust evidential reasoning approach for multiple attribute decision making.The possible set of best alternatives is identified using unknown attribute weights.The robustness of the alternatives in the set is measured from two perspectives.A robust rank-order of the alternatives in the set is generated by their robustness.Intervals of utilities and relevant constraints are handled in the proposed approach.

@&#KEYPHRASES@&#
Multiple attribute decision making,Evidential reasoning approach,Robust decision,Unknown attribute weights,Incompatibility among alternatives,

@&#ABSTRACT@&#
In multiple attribute decision making (MADM), different attribute weights may generate different solutions, which means that attribute weights significantly influence solutions. When there is a lack of sufficient data, knowledge, and experience for a decision maker to generate attribute weights, the decision maker may expect to find the most satisfactory solution based on unknown attribute weights called a robust solution in this study. To generate such a solution, this paper proposes a robust evidential reasoning (ER) approach to compare alternatives by measuring their robustness with respect to attribute weights in the ER context. Alternatives that can become the best with the support of one or more sets of attribute weights are firstly identified. The measurement of robustness of each identified alternative from two perspectives, i.e., the optimal situation of the alternative and the insensitivity of the alternative to a variation in attribute weights is then presented. The procedure of the proposed approach is described based on the combination of such identification of alternatives and the measurement of their robustness. A problem of car performance assessment is investigated to show that the proposed approach can effectively produce a robust solution to a MADM problem with unknown attribute weights.

@&#INTRODUCTION@&#
With a view to solving a multiple attribute decision making (MADM) problem, the assessments of alternatives on each attribute are usually aggregated after being weighted by attribute weights. The aggregated assessments of alternatives are then used to generate a solution to the MADM problem. Different attribute weights may create different solutions to the problem. As a result, attribute weights significantly influence solutions to the problem.In literature, there are three categories of methods to determine attribute weights, comprising subjective, objective, and hybrid methods [40]. Subjective methods use the subjective preference of a decision maker to determine attribute weights (e.g., [2,8,13,21,22,28–31,34,36–38,59]). Differently, objective methods use a decision matrix to determine attribute weights (e.g., [4,5,7,9,10,35,40,45]). The subjective preference of a decision maker and a decision matrix are synthetically employed in hybrid methods to determine attribute weights (e.g., [12,25,41]). However, different subjective methods may elicit different attribute weights. There is no single method that can guarantee more accurate attribute weights and further more satisfactory solutions than others [9,10]. Different objective methods are designed on different principles, such as the principle of maximum contrast [9,10] and the combination principle of maximum contrast and minimum correlation [40]. When a decision maker has a lack of sufficient data, knowledge, and experience, he or she will be unsure about which principle is the best to generate the most appropriate attribute weights and further the most satisfactory solution. To guarantee the most satisfactory solution for the decision maker in this situation, all attribute weights in a feasible or predefined weight space rather than a set of attribute weights generated by a specific method should be considered. More specifically, the decision maker would prefer one alternative supported by more sets of attribute weights to be the best to the others in the satisfactory solution. Such a solution is called a robust solution based on unknown attribute weights in this study.To generate a robust solution, except attribute weights, the assessments of a decision maker need to be flexibly modeled. In a real situation where data for assessing alternatives against criteria are partially or completely unavailable, or the knowledge of the decision maker for alternative evaluation is not sufficient, the decision maker is more likely to give uncertain (or imprecise) assessments. To model various kinds of uncertainties such as ignorance, fuzziness, interval data, and interval belief degrees in a unified format, the evidential reasoning (ER) approach was developed in the 1990s. It has been under development in recent years [6,19,44,50,54–56] to uniformly solve uncertain MADM problems. In particular, precise and interval numbers can be handled in the ER approach by converting them into distributed assessments [44], similar to the conversion of machine measurements into subjective assessments in the evaluation of new product development [24]. The above analysis shows that the extension of the ER approach to model and solve uncertain MADM problems with unknown attribute weights is a new and significant exploration, which is different from most existing MADM methods (e.g., [1,3,11,23,49,58]).For this purpose, we firstly identify which alternatives can become the best with the support of at least one set of attribute weights. Then, the robustness of each identified alternative is measured from two perspectives, i.e., the optimal situation of the alternative and the insensitivity of the alternative to a variation in attribute weights, which is used to compare the identified alternatives. The iterations of the two steps are intended to develop a robust ER (RER) approach to generate a robust solution in the ER context.The main contributions of this paper include the following: (1) the identification of alternatives that can become the best based on unknown attribute weights; (2) the measurement of robustness of each identified alternative from two perspectives; and (3) the development of the RER approach.The rest of this paper is organized as follows. Section 2 presents the preliminaries related to the RER approach. Section 3 introduces the RER approach. Section 4 presents an investigation regarding car performance assessment to demonstrate the applicability and validity of the RER approach. Section 5 compares the RER approach with the ER approach and other objective methods of determining attribute weights to reveal the advantages of generating a robust solution. Finally, this paper is concluded in Section 6.For the convenience of describing the RER approach, in the following we introduce basic notations and the solution process of the ER approach.Suppose that a MADM problem has M alternatives al(l=1,…,M) and L attributes ei(i=1,…,L). The relative weights of the L attributes are denoted by w=(w1,w2,…,wL) such that 0⩽wi⩽1 and∑i=1Lwi=1. Assume that Ω={H1,H2,…,HN} denotes a set of assessment grades. The M alternatives are assessed on the L attributes using Hn(n=1,…,N) in the ER approach. If an alternative alis assessed to a grade Hnon an attribute eiwith a belief degree of βn,i(al), the assessment can be expressed by a belief distribution B(ei(al))={(Hn, βn,i(al)), n=1,…,N; (Ω, βΩ,i(al))}, whereβn,i(al)⩾0,∑n=1Nβn,i(al)⩽1, andβΩ,i(al)=1-∑n=1Nβn,i(al)denotes the degree of global ignorance.To generate a solution in the ER approach, the assessments B(ei(al)) (i=1,…,L, l=1,…,M) are aggregated as B(y(al))={(Hn, βn(al)), n=1,…,N; (Ω, βΩ(al))} (l=1,…,M) using the analytical algorithm [43], where βΩ(al) denotes the degree of aggregated global ignorance. For the convenience of comparing the M alternatives in the ER approach, B(y(al)) (l=1,…,M) is combined with the utilities of grades u(Hn) (n=1,…,N) such that 0=u(H1)<u(H2)<⋯<u(HN)=1 to produce the minimum and maximum expected utilities of the alternative al(l=1,…,M), i.e.,umin(al)=∑n=2Nβn(al)u(Hn)+(β1(al)+βΩ(al))u(H1)andumax(al)=∑n=1N-1βn(al)u(Hn)+(βN(al)+βΩ(al))u(HN). The maximal regret of the alternativeal(l=1,…,M)is then calculated asR(al)=max{0,maxj≠l{umax(aj)}-umin(al)}. Finally, a rank-order of the M alternatives as a solution to the MADM problem is generated by means of R(al) (l=1,…,M) and the minimax regret approach (MRA) [44]. Details regarding the MRA can be found in [44].The assessments B(ei(al)) (i=1,…,L, l=1,…,M) are quasi-Bayesian belief structures (BSs), as presented above, so a compatibility measure between two BSs can be used to measure the compatibility between two assessments. The compatibility measure is given as follows.Definition 1Let m be a BS on Ω={H1,H2,…,HN}. Its associated pignistic probability function BetP(m) in the transferred belief model is defined asBetP(m)(w)=∑A⊆Ω,w∈A1|A|·m(A)1-m(∅),m(∅)≠1,where w can be H1,H2,…, or HN, and|A|is the cardinality of a subset A.BetP(m) can be extended as a function on 2Ω, i.e.,BetP(m)(A)=∑B⊆Ω|A∩B||B|·m(B)1-m(∅),∀A⊆Ω.The transformation from m to BetP(m) is named as the pignistic transformation.Let m1 and m2 be two BSs on Ω={H1,H2,…,HN}, and BetP1 and BetP2 be their associated pignistic probability functions, respectively. ThendifBetP(m1,m2)=maxA⊆Ω(|BetP1(A)-BetP2(A)|)is called the distance between betting commitments of the two BSs.Let m1 and m2 be two BSs on Ω={H1,H2,…,HN}, and BetP1 and BetP2 be their associated pignistic probability functions, respectively. SupposeA‾={w|w∈Ω,BetP1(w)=BetP2(w)>0}whereA‾is a subset of Ω, then EP(m1)=A‾and EP(m2)=A‾are called all equal-pignistic-valued elements of m1 and m2, respectively.Let m1 and m2 be two BSs on Ω={H1,H2,…,HN}, BetP1 and BetP2 respectively be their associated pignistic probability functions, BetPR1={BetP1(H1),…,BetP1(HN)} and BetPR2={BetP2(H1),…,BetP2(HN)} respectively be their pignistic transformation results, EP(m1) and EP(m2) respectively be their equal-pignistic-valued elements, and pm⊕(∅)(m1, m2) be the mass of uncommitted belief when combining BetPR1 and BetPR2 with Dempster’s rule including no contribution completely from EP(m1) and EP(m2). Then, pm⊕(∅)(m1, m2) is defined aspm⊕(∅)(m1,m2)=∑w1∈Ω,w2∈Ω,w1∩w2=∅BetPR1(w1)BetPR2(w2)-∑w1∈EP(m1),w2∈EP(m2),w1∩w2=∅BetPR1(w1)BetPR2(w2).Let m1 and m2 be two BSs, pm⊕(∅)(m1, m2) be the mass of uncommitted belief as described in Definition 4, and difBetP(m1, m2) be the distance between their betting commitments as described in Definition 2. Then, a compatibility measure between m1 and m2 is defined ascm(m1,m2)=1-2×pm⊕(∅)(m1,m2)×difBetP(m1,m2)pm⊕(∅)(m1,m2)+difBetP(m1,m2),pm⊕(∅)(m1,m2)>0,1,pm⊕(∅)(m1,m2)=0.Details regarding the compatibility measure can be seen in [15]. Thus, cm(B(ei(al)), B(ej(al))) can measure the compatibility between two assessments B(ei(al)) and B(ej(al)) (i ≠j). The cm(B(ei(al)), B(ej(al))) is limited to [0,1].In this section, we describe the identification of alternatives that may become the best and the measurement of robustness of the identified alternatives from two perspectives in the ER context. The RER approach based on the two contributions is then demonstrated.When w is known, a solution to a MADM problem can be found based on the assessments B(ei(al)) (i=1,…,L, l=1,…,M) using the MRA. However, when w is unknown, more than one alternative may have the smallest maximal regret and thus become the best. In other words, there exists the possible set of best alternatives in this situation, which is determined as follows.After u(Hn) (n=1,…,N) is given by a decision maker and B(y(al)) (l=1,…,M) is obtained, R(al) (l=1,…,M) can be calculated and used to compare alternatives, as presented in Section 2.1. An alternative with smaller maximal regret is better than the others using the MRA. To guarantee the contribution of each attribute to a solution, the lower bound of wi(i=1,…,L) is specified by the decision maker, i.e.,wir(i=1,…,L). Under the conditions, the possible set of best alternatives is obtained by solving the following nonlinear optimization model:(1)MinR(al)-minm∈{1,…,M}{R(am)}(l=1,…,M)(2)s.t.R(al)=max0,maxj≠l{umax(aj)}-umin(al),l=1,…,M,(3)umin(al)=∑n=2Nβn(al)u(Hn)+(β1(al)+βΩ(al))u(H1),(4)umax(al)=∑n=1N-1βn(al)u(Hn)+(βN(al)+βΩ(al))u(HN),(5)βΩ(al)=1-∑n=1Nβn(al),(6)∑i=1Lwi=1,(7)wi⩾wir,i=1,…,L.If the optimization objective of the model in Eqs. (1)–(7) is equal to 0 for an alternative al(l∈{1,…,M}), the alternative alcan become the best. Finding the solutions to the optimization model for M alternatives, we can obtain the possible set of best alternatives denoted by Mb. Suppose that ∣Mb∣ denotes the cardinality of Mb. Then, ∣Mb∣ sets of attribute weights can be correspondingly obtained to guarantee that any alternative alin Mbcan be the best, which are denoted by wi(al) (i=1,…,L).After the possible set of best alternatives, i.e., Mbis decided, the remaining problem is to measure the robustness of the alternatives in Mbso as to compare the alternatives by their robustness. It is described as follows.As mentioned in Section 1, the robustness of an alternative in Mbis measured from two perspectives. In this subsection, we firstly introduce the first perspective, i.e., the optimal situation of the alternative, which is characterized by the maximal regret and the average incompatibility of the alternative.In the MRA, an alternative with smaller maximal regret is better than the others. To facilitate the comparison of alternatives, we define the minimal satisfaction of an alternative al(l∈{1,…,M}) as Mc(al)=−(maxj≠l(umax(aj))−umin(al)), which is opposed to the maximal regret. Accordingly, an alternative with larger minimal satisfaction is better than the others. The calculation of umin(al) and umax(al) in Section 2.1 indicates that Mc(al) is limited to [−1,1]. When Mc(al)>0, the alternative alabsolutely dominates the others. Although the minimal satisfaction of the alternatives in Mbcan be used to compare them, it cannot guarantee a robust solution to the MADM problem. In general, the more incompatible the best alternative is with the others, the more robust a solution is. Therefore, a combination of the minimal satisfaction and the average incompatibility for the alternatives in Mbis used to measure the first perspective of robustness of the alternatives.Suppose that the average incompatibility of an alternative alsuch that al∈Mbis denoted by Cy(al). By using the compatibility measure between two BSs denoted by cm in Definition 5, the compatibility between the aggregated assessments B(y(al)) and B(y(am)) (m≠l) is measured by cm(B(y(al)), B(y(am))) such that 0⩽cm(B(y(al)), B(y(am)))⩽1, as presented in Section 2.2. Then, 1−cm(B(y(al)), B(y(am))) measures the incompatibility between B(y(al)) and B(y(am)) (m≠l). Thus, the average incompatibility of the alternative alis defined as follows:(8)Cy(al)=∑m=1,m≠lM1-cm(B(y(al)),B(y(am)))M-1=1-∑m=1,m≠lMcm(B(y(al)),B(y(am)))M-1,al∈Mb.It can be obtained that 0⩽Cy(al)⩽1.The concurrent maximization of the minimal satisfaction and the average incompatibility for the alternative almeasures the first perspective of its robustness. It is implemented using the following nonlinear two-objective optimization model:(9)MaxMc(al)(10)MaxCy(al)(11)s.t.R(al)-minm∈{1,…,M}{R(am)}=0,al∈Mb,(12)∑i=1Lwi(al)=1,(13)wi(al)⩾wir,i=1,…,L.The calculation of the constraint in Eq. (11) is the same as the objective function in Eq. (1). It is thus omitted in the above optimization model. To facilitate the concurrent maximization of Mc(al) and Cy(al), the model in Eqs. (9)–(13) is transformed to the following goal programming model:(14)MinδR+δC(15)s.t.R(al)-minm∈{1,…,M}{R(am)}=0,al∈Mb,(16)Mc(al)+δR=1,(17)Cy(al)+δC=1,(18)0⩽δR⩽2,0⩽δC⩽1,(19)∑i=1Lwi(al)=1,(20)wi(al)⩾wir,i=1,…,L.Because −1⩽Mc(al)⩽1 and 0⩽Cy(al)⩽1, Mc(al) and Cy(al) have the same theoretical goal, i.e., 1. The constraints 0⩽δR⩽2 and 0⩽δC⩽1 are set to reach the goal. Solving the model in Eqs. (14)–(20), we can obtain the optimized Mc(al) and Cy(al). They are used to define the measurement of the first perspective of robustness for the alternative al, i.e.,(21)RN1(al)=(Cy(al)+(Mc(al)-(-1))/2)/2,where RN1(al) is limited to [0,1]. An alternative alsuch that al∈Mbwith larger RN1(al) is considered to be more robust than the others to become the best, which means that its optimal situation is better than that of the others.The RN1(al) in Eq. (21) is dependent on one set of optimized attribute weights and thus cannot reflect the insensitivity of the alternative alto a variation in attribute weights. The insensitivity is regarded as the second perspective of robustness of the alternative and measured by the possible interval of Mc(al) and that of Cy(al), which is demonstrated as follows.Suppose thatMc-(al)andMc+(al)denote the minimum and maximum minimal satisfaction of the alternative alon condition that the alternative is guaranteed to be the best. They are determined by solving the following pair of nonlinear optimization problems:(22)Min/MaxMc(al)(23)s.t.R(al)-minm∈{1,…,M}{R(am)}=0,al∈Mb,(24)∑i=1Lwi(al)=1,(25)wi(al)⩾wir,i=1,…,L.WhenCy-(al)andCy+(al)are assumed to denote the minimum and maximum average incompatibility of the alternative al, they are similarly determined by solving the following pair of nonlinear optimization problems:(26)Min/MaxCy(al)(27)s.t.R(al)-minm∈{1,…,M}{R(am)}=0,al∈Mb,(28)∑i=1Lwi(al)=1,(29)wi(al)⩾wir,i=1,…,L.The distance betweenMc-(al)andMc+(al)and the distance betweenCy-(al)andCy+(al)for the alternative alare denoted by ΔMc(al) and ΔCy(al), respectively. These two distances are combined to express the second perspective of robustness of the alternative, i.e.,(30)RN2(al)=(ΔMc(al)/2+ΔCy(al))/2,where RN2(al) is limited to [0,1]. An alternative alsuch that al∈Mbwith larger RN2(al) is considered to be more robust than the others to become the best, which means that the alternative is more insensitive to a variation in attribute weights than the others. In other words, compared with the others, the alternative remains the best when there is a larger variation in attribute weights.Based on Sections 3.2.1 and 3.2.2, similarities and differences between RN1(al) and RN2(al) (al∈Mb) are analyzed to interpret the reason why RN1(al) should combine with RN2(al) to measure the robustness of the alternative aldenoted by RN(al). It is emphasized by analyzing the logical relationship between RN1(al) and RN2(al).On the one hand, RN1(al) and RN2(al) (al∈Mb) have the same foundation. The model in Eqs. (14)–(20) and the two pairs of optimization problems respectively in Eqs. (22)–(25) and (26)–(29) have the same constraints on wi(al) (i=1,…,L) and R(al) (al∈Mb), and the same construction of Mc(al) and Cy(al) (al∈Mb). On the other hand, there are significant differences between RN1(al) and RN2(al). Firstly, two deviation variables are included in the model in Eqs. (14)–(20) to implement the concurrent maximization of Mc(al) and Cy(al). However, they are not required for the two pairs of optimization problems in Eqs. (22)–(25) and (26)–(29), respectively. Secondly, the model in Eqs. (14)–(20) is used to obtain the concurrently maximum Mc(al) and Cy(al) with one set of optimized attribute weights. The resulting RN1(al) cannot reflect the insensitivity of the alternative to a variation in attribute weights. In contrast, the insensitivity can be measured by RN2(al) because any set of attribute weights which generates Mc(al) such thatMc(al)∈Mc-(al),Mc+(al)or Cy(al) such thatCy(al)∈Cy-(al),Cy+(al)can guarantee that the alternative alis the best.The above analysis indicates that RN1(al) and RN2(al) should be combined to effectively measure the robustness of the alternative al. It is defined as(31)RN(al)=θ·RN1(al)+(1-θ)·RN2(al),where θ is a relaxation coefficient that combines RN1(al) and RN2(al). The coefficient θ reflects the different importance of RN1(al) and RN2(al), and further the proportion of their contributions to RN(al). In practice, θ is decided by a decision maker according to the knowledge, experience, preference, and risk attitude of the decision maker, application constraints, the historical setting, and the decision context. The weighted geometric mean method is unsuitable for combining RN1(al) and RN2(al) because the resulting RN(al) by the method is unreasonable when RN1(al) or RN2(al) is equal to zero. An alternative alsuch that al∈Mbwith larger RN(al) is considered to be more robust than the others to become the best.Given θ in Eq. (31), RN1(al) and RN2(al) (al∈Mb) may make different contributions to RN(al) (al∈Mb) in different situations. When a decision maker gives the lowly discordant assessments B(ei(al)) (i=1,…,L, l=1,…,M), i.e., the assessments of alternatives on attributes are similar to each other, RN2(al) will become smaller or even be close to 0. In this situation, RN1(al) mainly contributes to RN(al), while RN2(al) only has a slight influence on RN(al). In contrast, if the highly discordant assessments B(ei(al)) (i=1,…,L, l=1,…,M) are given, both RN1(al) and RN2(al) make significant contributions to RN(al). In other intermediate situations, both RN1(al) and RN2(al) also influence RN(al). It will be found in Section 4 that the intermediate situations generally occur in the assessment of car performance.In real situations, a decision maker may change his or her risk attitude as time passes. Therefore, the utilities of assessment grades from the decision maker are not always precise values. A case in point is that when decision environment is changed, the decision maker may change his or her risk attitude from risk seeking to risk aversion or change the degree to which he or she seeks risk. Such a change has a significant influence on RN1(al) and RN2(al) (al∈Mb) and is handled in this subsection.Suppose that u(Hn) (n=1,…,N) is extended as intervals denoted by [u−(Hn), u+(Hn)] such that u−(Hn)⩽u(Hn)⩽u+(Hn), 0=u(H1)<u(H2)<⋯<u(HN)=1, and u(Hn)−u(Hn−1)⩾δu(n=2,…,N) to cover the possible change of u(Hn). The parameter δudenotes the minimal difference between u(Hn) and u(Hn−1) (n=2,…,N). The δuapproaching to 0 is not useful in practice because δuis related to the risk attitude of the decision maker and the possible change in his or her risk attitude as time passes. The intervals [u−(Hn), u+(Hn)] (n=1,…,N) can be incorporated into the optimization model in Eqs. (1)–(7) as constraints to decide another possible set of best alternatives denoted byMbui. If the u(Hn) (n=1,…,N) generating the set Mbis limited to[u-(Hn),u+(Hn)](n=1,…,N),Mbui⊇Mbcan be obtained. Otherwise,Mbuiis different from Mb. For an alternative alsuch thatal∈Mbui, the intervals [u−(Hn), u+(Hn)] (n=1,…,N) can also be used to decide the optimized Mc(al) andCy(al),Mc-(al),Mc+(al), andCy-(al),Cy+(al). Thus, they provide a significant contribution to RN1(al) and RN2(al).Other constraints on u(Hn) (n=1,…,N) can also be incorporated into the optimization models respectively in Eqs. (1)–(7) and (14)–(20) and the two pairs of optimization problems respectively in Eqs. (22)–(25) and (26)–(29), except for the intrinsic constraint 0=u(H1)<u(H2)<⋯<u(HN)=1. Five types of constraints on u(Hn) (n=1,…,N) are handled in this paper, including the following: (1) fuzzy preference constraint, such as u(H2)/(u(H2)+u(H3))=p23, where p23 denotes a reciprocal fuzzy preference relation with values in the interval [0,1] [39]; (2) multiplicative preference constraint, such as u(H2)/u(H3)=r23, where r23 denotes a reciprocal multiplicative preference relation with values in the interval scale [1/9,9] [20]; (3) linear inequality constraint, such as u(H2)+u(H3)⩾u(H4), u(H3)−u(H2)⩾0.1, u(H2)⩾0.1, and u(H5)−u(H4)⩾u(H3)−u(H2); (4) fuzzy preference inequality constraint, such as u(H2)/(u(H2)+u(H3))⩾p23; and (5) multiplicative preference inequality constraint, such as u(H2)/u(H3)⩾r23. The constraints (1) and (2) are stricter than (4) and (5). All specified constraints on u(Hn) (n=1,…,N) should be consistent with the intrinsic constraint 0=u(H1)<u(H2)<⋯<u(HN)=1. If more than one constraint on u(Hn) (n=1,…,N) needs to be handled, the constraints must form a feasible region. Otherwise, the relevant optimization models and problems will have no feasible solutions.Based on the determination of Mb(orMbui) and the measurement of robustness of the alternatives in Mb, the RER approach is developed to generate a robust solution. That is, iterating the two steps until at most one alternative remains, we can obtain a complete robust rank-order of M alternatives. The procedure of the RER approach is shown in Fig. 1.Fig. 1 shows that the RER approach includes eleven steps:Step 1:A decision maker identifies L attributes and N assessment grades, and lists M alternatives to form a MADM problem.The decision maker specifies the lower bounds of attribute weightswir(i=1,…,L), the relaxation coefficient θ, and u(Hn) (n=1,…,N) such that 0=u(H1)<u(H2)<⋯<u(HN)=1 when he or she has fixed risk attitude. The possible set of best alternatives and the set of remaining alternatives in each iteration are initialized as Mb={Ø} and Mr={a1,…,aM}. This is in preparation for the RER approach to solve the MADM problem.Assessments of alternatives on each attribute are collected from the decision maker.When the decision maker may change his or her risk attitude as time passes, the decision maker gives [u−(Hn), u+(Hn)] (n=1,…,N) such that u−(Hn)⩽u(Hn)⩽u+(Hn) and 0=u(H1)<u(H2)<⋯<u(HN)=1, relevant constraints if possible, and the minimal difference between the utilities of two adjacent grades δu.The possible set of best alternatives Mb(orMbui) in the last iteration is eliminated from the set of remaining alternatives Mrin the current iteration.If ∣Mr∣ is less than or equal to 1, we obtain a complete robust rank-order of M alternatives, and go to Step 11; otherwise, solving the optimization model in Eqs. (1)–(7) incorporating u(Hn) or [u−(Hn), u+(Hn)] (n=1,…,N) with relevant constraints generates MborMbuifrom Mrin the current iteration.If ∣Mb∣ (or|Mbui|) is equal to 1, go to Step 10; otherwise, the optimized Mc(al) and Cy(al) for the alternative alin Mb(orMbui) are obtained by solving the optimization model in Eqs. (14)–(20).For the alternative alin Mb(orMbui),Mc-(al),Mc+(al)andCy-(al),Cy+(al)are obtained by solving the optimization problems respectively in Eqs. (22)–(25) and (26)–(29) incorporating u(Hn) or [u−(Hn), u+(Hn)] (n=1,…,N) with relevant constraints. Then, ΔMc(al) and ΔCy(al) are produced.From the optimized Mc(al) and Cy(al) (al∈Mboral∈Mbui)in Step 7 and ΔMc(al) and ΔCy(al) in Step 8, RN(al) is calculated using Eqs. (21), (30), and (31). Then, RN(al) (al∈Mboral∈Mbui)in the current iteration is used to compare the alternatives in Mb(orMbui) so as to generate their robust rank-order.If ∣Mb∣ (orMbui) is equal to 1, a robust rank-order of the alternatives in Mb+{a1,…,aM}−Mr(orMbui+{a1,…,aM}-Mr) can be directly obtained. Otherwise, the resulting rank-order is combined with the rank-order of the alternatives in the former iterations to form the robust rank-order of the alternatives in Mb+{a1,…,aM}−Mr(orMbui+{a1,…,aM}-Mr). Then, go to Step 5.We draw a conclusion that a robust rank-order of M alternatives is considered a robust solution to the MADM problem.In this section, a car performance assessment (CPA) problem adapted from [50] is resolved to demonstrate the applicability and validity of the RER approach. All optimized problems in the CPA problem are solved by Matlab.To use the RER approach to solve the CPA problem, we firstly describe the problem using Steps 1–4 in the procedure of the RER approach.Step 1:In the CPA problem, six types of cars, denoted by cl(l=1,…,6), are assessed on seven attributes, including acceleration, braking, horsepower, handling, ride quality, power train, and fuel economy. Suppose that the six types of cars are assessed by using the following set of assessment grades:Worst (W), Poor (P), Average (A), Good (G), Excellent (E), and Top (T), sayΩ={Hn,n=1,…,6}={Worst,Poor,Average,Good,Excellent,Top}={W,P,A,G,E,T}.Suppose thatwir(i=1,…,7)=(0.05,0.05,0.05,0.05,0.05,0.05,0.05), and the relaxation coefficient θ is specified as 0.5, which means that the two perspectives of robustness have the same importance.Assessments of cl(l=1,…,6) on the seven attributes are presented in Table 1.The assessments with nonzero degrees of global ignorance, i.e., βΩ,i(al)>0, such as βΩ,3(c3), βΩ,6(c3), and βΩ,3(c6), and the assessments with complete ignorance, i.e., βΩ,i(al)=1, such as βΩ,5(c3) and βΩ,5(c6), are included in Table 1.Suppose that the decision maker may change his or her risk attitude as time passes, then he or she specifies that [u−(Hn), u+(Hn)] (n=1,…,6)={[0,0], [0.1,0.3], [0.3,0.5], [0.5,0.7], [0.7,0.9], [1,1]} and δu=0.05. The decision maker also gives subjective constraints on utilities of assessment grades, as shown in Table 2.Under the conditions specified above, a robust solution to the CPA problem is generated using Steps 5–11 in the procedure of the RER approach.Step 5:Because [u−(Hn), u+(Hn)] (n=1,…,6) is specified in Step 4, we known that Mr={c1, c2, c3, c4, c5, c6} before the first iteration.By reason of ∣Mr∣>1, we can obtainMbui={c1,c2,c3,c4,c5,c6}in the first iteration. Six sets of attribute weights, utilities of assessment grades, and expected utilities are also obtained to guarantee that cl(l=1,…,6) can be the best, as shown in Table 3. In general, the w and u(Hn) (n=1,…,6) in Table 3 are not a unique choice to guarantee that each car inMbuiis the best, but a representative choice. There may be other choices.It is clear thatMbui>1in the first iteration. Thus, we can obtain the optimized Mc(cl) and Cy(cl) such thatcl∈Mbui, as shown in Table 4.We can further obtainMc-(cl),Mc+(cl)andCy-(cl),Cy+(cl)such thatcl∈Mbui, which are also shown in Table 4.From the results in Table 4, (RN1(cl), RN2(cl)) and RN(cl) such thatcl∈Mbuiare calculated, which are {(0.5977,0.3993), (0.7,0.3876), (0.7968,0.4585), (0.4493,0.1195), (0.5021,0.212), (0.6088,0.3046)} and {0.4985,0.5438,0.6276,0.2844,0.357,0.4567}. Therefore, a robust rank-order of six types of cars inMbuiin the first iteration is obtained as c3≻c2≻c1≻c6≻c5≻c4, where the notation ‘≻’ denotes ‘prior to’.BecauseMbui>1, the robust rank-order of the cars inMbui+{c1,…,c6}-Mrin the first iteration is still c3≻c2≻c1≻c6≻c5≻c4.WhenMbuiis eliminated from Mrin the first iteration, it can be derived that ∣Mr∣=0. Therefore, a robust solution to the CPA problem can be found.We draw a conclusion that c3≻c2≻c1≻c6≻c5≻c4 is the robust solution to the CPA problem. The third type of car is the most robust choice of the decision maker.We can easily verify that the two perspectives of robustness of c3 are larger than those of the others inMbui, so c3 absolutely dominates the others whatever the relaxation coefficient θ is specified as. However, different θ may result in different sets of rank-order, which demonstrates the significant contributions of RN1(cl) and RN2(cl) to RN(cl).Suppose that the risk attitude of the decision maker may be completely changed as time passes, i.e., [u−(Hn), u+(Hn)] (n=1,…,6)={[0,0], [0,1], [0,1], [0,1], [0,1], [1,1]}. Under the new conditions, a new robust solution is found using Steps 5–11 in the procedure of the RER approach and compared with the above solution.Step 5:We similarly have Mr={c1, c2, c3, c4, c5, c6} before the first iteration.Due to the fact that|Mr|>1,Mbuiin the first iteration can be similarly decided, which is still {c1, c2, c3, c4, c5, c6}.In the first iteration, the optimized Mc(cl) and Cy(cl) such thatcl∈Mbuiare obtained on account ofMbui>1, which are shown in Table 5.To generate RN2(cl) such thatcl∈Mbuiin the first iteration,Mc-(cl),Mc+(cl)andCy-(cl),Cy+(cl)such thatcl∈Mbuiare obtained, which are also shown in Table 5.From the results in Table 5, we obtain (RN1(cl), RN2(cl)) and RN(cl) such thatcl∈Mbui, i.e., {(0.7696,0.5076), (0.7715,0.5198), (0.8842,0.5865), (0.4829,0.2286), (0.5515,0.3641), (0.6389,0.4073)} and {0.6386,0.6457,0.7353,0.3558,0.4578,0.5231}. The resulting RN(cl) such thatcl∈Mbuiproduces a robust rank-order in the first iteration, i.e., c3≻c2≻c1≻c6≻c5≻c4.The robust rank-order of the cars inMbui+{c1,…,c6}-Mrin the first iteration is still c3≻c2≻c1≻c6≻c5≻c4 on account ofMbui>1.Because Mr=Ø afterMbuiis eliminated from it, the second iteration is not necessary for finding a robust solution.We find the new robust solution to the CPA problem, i.e., c3≻c2≻c1≻c6≻c5≻c4. The third type of car is still the most robust choice of the decision maker.The (RN1(cl), RN2(cl)) such thatcl∈Mbuiin Step 9 indicates that the rank-order remains unchanged with the movement of the relaxation coefficient θ, which is different from the situation with [u−(Hn), u+(Hn)] (n=1,…,6)={[0,0], [0.1,0.3], [0.3,0.5], [0.5,0.7], [0.7,0.9], [1,1]}. More differently, the optimized Mc(cl) andMc-(cl),Mc+(cl)are increased and extended under the new conditions.Suppose that the decision maker has fixed risk attitude, then different sets of u(Hn) (n=1,…,6) may generate different solutions to the CPA problem. In the following, we discuss the influence of u(Hn) (n=1,…,6) on the robust solution to the CPA problem using Steps 5–10 in the procedure of the RER approach. Four representative sets of u(Hn) (n=1,…,6) are chosen, i.e., (0,0.15,0.2,0.25,0.3,1), (0,0.2,0.3,0.45,0.55,1), (0,0.2,0.3,0.5,0.6,1), and (0,0.2,0.3,0.5,0.7,1).Step 5:It is known that Mr={c1, c2, c3, c4, c5, c6} before the first iteration.The condition ∣Mr∣>1 indicates that Mbneeds to be decided in the first iteration. By using the four sets of u(Hn) (n=1,…,6), we can know that Mbin the first iteration is respectively equal to {c1, c2, c3, c6}, {c1, c2, c3, c5, c6}, {c1, c2, c3, c4, c5, c6}, and {c1, c2, c3, c5, c6}.For the four sets of u(Hn) (n=1,…,6), ∣Mb∣ is always greater than 1 in the first iteration. Therefore, under the same constraints on u(Hn) (n=1,…,6), the optimized Mc(cl) and Cy(cl) such that cl∈Mbare obtained, as shown in Table 6.Further, we can obtainMc-(cl),Mc+(cl)andCy-(cl),Cy+(cl)such that cl∈Mb, which are also shown in Table 6.The results in Table 6 produce RN1(cl), RN2(cl), and RN(cl) such that cl∈Mb, which are shown in Table 7.For the four sets of u(Hn) (n=1,…,6), ∣Mb∣>1 always holds in the first iteration. Then, four sets of robust rank-order of the cars in Mb+{c1,…,cM}−Mrin the first iteration are generated by RN(cl) such that cl∈Mb, which are also shown in Table 7.For the sake of simplicity, only the first iteration is handled because the most robust choice of the decision maker is decided in the iteration. Step 11 is thus omitted. In the following, we focus on a change in the most robust choice with the four sets of u(Hn) (n=1,…,6) and a variation in the relaxation coefficient θ.Table 7 shows that the most robust choice of the decision maker is changed with different sets of u(Hn) (n=1,…,6). In particular, the most robust choice with the first three sets of u(Hn) (n=1,…,6) is different from the situations with [u−(Hn), u+(Hn)] (n=1,…,6)={[0,0], [0.1,0.3], [0.3,0.5], [0.5,0.7], [0.7,0.9], [1,1]} and [u−(Hn), u+(Hn)] (n=1,…,6)={[0,0], [0,1], [0,1], [0,1], [0,1], [1,1]}. For the fourth set of u(Hn) (n=1,…,6), the two perspectives of robustness of c3 are larger than those of the others in Mbin the first iteration, so the corresponding robust rank-order of the cars in Mbremains unchanged with a variation in the relaxation coefficient θ. In other words, c3 absolutely dominates the others in Mbin this situation. However, for the first three sets of u(Hn) (n=1,…,6), the robust rank-order of the cars in Mbin the first iteration may be changed with a variation in the relaxation coefficient θ. Suppose that θ is changed from 0.1 to 0.9 with a step of 0.2, RN(cl) such that cl∈Mbis then recalculated, as shown in Table 8. The results show that the most robust choice of the decision maker using the first three sets of u(Hn) (n=1,…,6) has altered along with the variation in θ.

@&#CONCLUSIONS@&#
