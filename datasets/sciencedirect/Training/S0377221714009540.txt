@&#MAIN-TITLE@&#
DC approximation approaches for sparse optimization

@&#HIGHLIGHTS@&#
A unifying DC approximation, including all standard approximations, of the zero-norm is proposed.The consistency between global/local minima of approximate and original problems are proved.The equivalence between approximate and original problems are established for some approximations.Four DCA schemes are developed that cover all standard nonconvex approximation algorithms.A careful empirical experiment for feature selection in SVM are performed.

@&#KEYPHRASES@&#
Global optimization,Sparse optimization,DC approximation function,DC programming and DCA,Feature selection in SVM,

@&#ABSTRACT@&#
Sparse optimization refers to an optimization problem involving the zero-norm in objective or constraints. In this paper, nonconvex approximation approaches for sparse optimization have been studied with a unifying point of view in DC (Difference of Convex functions) programming framework. Considering a common DC approximation of the zero-norm including all standard sparse inducing penalty functions, we studied the consistency between global minimums (resp. local minimums) of approximate and original problems. We showed that, in several cases, some global minimizers (resp. local minimizers) of the approximate problem are also those of the original problem. Using exact penalty techniques in DC programming, we proved stronger results for some particular approximations, namely, the approximate problem, with suitable parameters, is equivalent to the original problem. The efficiency of several sparse inducing penalty functions have been fully analyzed. Four DCA (DC Algorithm) schemes were developed that cover all standard algorithms in nonconvex sparse approximation approaches as special versions. They can be viewed as, an ℓ1-perturbed algorithm/reweighted-ℓ1 algorithm / reweighted-ℓ2 algorithm. We offer a unifying nonconvex approximation approach, with solid theoretical tools as well as efficient algorithms based on DC programming and DCA, to tackle the zero-norm and sparse optimization. As an application, we implemented our methods for the feature selection in SVM (Support Vector Machine) problem and performed empirical comparative numerical experiments on the proposed algorithms with various approximation functions.

@&#INTRODUCTION@&#
The zero-norm onRn,denoted ℓ0-norm or ‖ · ‖0, is defined by∥x∥0:=|{i=1,…,n:xi≠0}|,where |S| is the cardinality of the set S. The ℓ0-norm is an important concept for modelling the sparsity of data and plays a crucial role in optimization problems where one has to select representative variables. Sparse optimization, which refers to an optimization problem involving the ℓ0-norm in objective or constraints, has many applications in various domains (in particular in machine learning, image processing and finance), and draws increased attention from many researchers in recent years. The function ℓ0, apparently very simple, is lower-semicontinuous onRn,but its discontinuity at the origin makes nonconvex programs involving ‖ · ‖0 challenging. Note that although one uses the term “norm” to design ‖ · ‖0, ‖ · ‖0 is not a norm in the mathematical sense. Indeed, for allx∈Rnand λ ≠ 0, one has ‖λx‖0 = ‖x‖0, which is not true for a norm.Formally, a sparse optimization problem takes the form(1)inf{f(x,y)+λ∥x∥0:(x,y)∈K⊂Rn×Rm},(Weston, Elisseeff, Scholkopf, and Tipping, 2003; Zhang, Ahn, Lin, and Park, 2006) where the function f corresponds to a given criterion and λ is a positive number, called the regularization parameter, that makes the trade-off between the criterion f and the sparsity of x. In some applications, one wants to control the sparsity of solutions, the ℓ0-term is thus put in constraints, and the corresponding optimization problem is(2)inf{f(x,y):(x,y)∈K,∥x∥0≤k}.Let us mention some important applications of sparse optimization corresponding to these models.Feature selection in classification learning: Feature selection is one of fundamental problems in machine learning. In many applications such as text classification, web mining, gene expression, micro-array analysis, combinatorial chemistry, image analysis, etc, data sets contain a large number of features, many of which are irrelevant or redundant. Feature selection is often applied to high-dimensional data prior to classification learning. The main goal is to select a subset of features of a given data set while preserving or improving the discriminative ability of the classifier. Given a training data {ai, bi}i = 1, …, qwhere eachai∈Rnis labeled by its class bi∈ Y, the discrete set of labels. The aim of classification learning is to construct a classifier function that discriminates the data points A ≔ {ai}i = 1, …, qwith respect to their classes{bi}i = 1, …, q. The embedded feature selection in classification consists of determining the classifier which uses as few features as possible, that leads to a sparse optimization problem like (1).Sparse regression: Given a training data set{bi,ai}i=1qof q independent and identically distributed samples composed of explanatory variablesai∈Rn(inputs) and response variablesbi∈R(ouputs). Let b ≔ (bi)i = 1, …, qdenote the vector of outputs andA:=(ai,j)i=1,…,qj=1,…,ndenote the matrix of inputs. The problem of the regression consists in looking for a relation which can possibly exist between A and b, in other words, relating b to a function of A and a model parameter x. Such a model parameter x can be obtained by solving the optimization problem(3)min{f(x):=∑i=1qL(bi,aiTx):x∈Rn},whereL:Rn→Ris called loss function. The sparse regression problem aims to find a sparse solution of the above regression model, it takes the form of (1):(4)minx∈Rn{∑i=1qL(bi,aiTx)+ρ∥x∥0}.Sparse Fisher linear discriminant analysis: Discriminant analysis captures the relationship between multiple independent variables and a categorical dependent variable in the usual multivariate way, by forming a composite of the independent variables. Given a set of q independent and identically distributed samples composed of explanatory variablesai∈Rnand binary response variables bi∈ { − 1, 1}. The idea of Fisher linear discriminant analysis is to determine a projection of variables onto a straight line that best separables the two classes. The line is so determined to maximize the ratio of the variances of between and within classes in this projection, i.e. maximize the functionf(α)=〈α,SBα〉〈α,SWα〉,where SB and SW are, respectively, the between and within classes scatter matrix (they are symmetric positive semidefinite) given bySB:=(q+−q−)(q+−q−)T,SW=S++S−,S+=∑i=1,bi=+1q(xi−q+)(xi−q+)T,S−=∑i=1,bi=−1q(xi−q−)(xi−q−)T.Here, for j ∈ { ± }, qjis the mean vector of class j, ljis the number of labeled samples in class j. If α is an optimal solution of the problem, then the classifier is given by F(a) = αTa + c, c = 0.5αT(q+ − q−). The sparse Fisher discriminant model is defined by (ρ > 0)min{αTSWα+ρ∥α∥0:αT(q+−q−)=b}.Compressed sensing: Compressed sensing refers to techniques for efficiently acquiring and reconstructing signals via the resolution of underdetermined linear systems. Compressed sensing concerns sparse signal representation, sparse signal recovery and sparse dictionary learning which can be formulated as sparse optimization problems of the form (1).Portfolio selection problem with cardinality constraint:In portfolio selection problem, given a set of available securities or assets, we want to find the optimum way of investing a particular amount of money in these assets. Each of the different ways to diversify this money among the several assets is called a portfolio. In portfolio management one wants to limit the number of assets to be investigated in the portfolio, that leads to a problem of the form (2).Other applications: Other applications of sparse optimization include sensor networks (Bajwa, Haupt, Sayeed, and Nowak, 2006; Baron, Wakin, Duarte, Sarvotham, and Baraniuk, 2006), error correction (Candes and Tao, 2005; Candes and Randhall, 2006), Digital photography (Takhar, Laska, Wakin, Duarte, Baron, Sarvotham, Kelly, and Baraniuk, 2006), etc.Existing works. During the last two decades, research is very active in models and methods optimization involving the zero-norm. Works can be divided into three categories according to the way to treat the zero-norm: convex approximation, nonconvex approximation, and nonconvex exact reformulation.In the machine learning community, one of the best known approaches, belonging to the group “convex approximation”, is the ℓ1 regularization approach proposed in Tibshirani (1996) in the context of linear regression, called LASSO (Least Absolute Shrinkage and Selection Operator), which consists in replacing the ℓ0 term ‖x‖0 by ‖x‖1, the ℓ1-norm of the vector x. In Gribonval and Nielsen (2003), the authors have proved that, under suitable assumptions, a solution of the ℓ0-regularizer problem over a polyhedral set can be obtained by solving the ℓ1-regularizer problem. However, these assumptions are quite restrictive. Since its introduction, several works have been developed to study the ℓ1-regularization technique, from the theoretical point of view to efficient computational methods (see Hastie, Tibshirani, and Friedman, 2009, chap. 18 for more discussions on ℓ1-regularized methods). The LASSO penalty has been shown to be, in certain cases, inconsistent for variable selection and biased Zou (2006). Hence, the Adaptive LASSO is introduced in Zou (2006) in which adaptive weights are used for penalizing different coefficients in the ℓ1-penalty.At the same time, nonconvex continuous approaches, belonging to the second group “nonconvex approximation” (the ℓ0 term ‖x‖0 is approximated by a nonconvex continuous function) were extensively developed. A variety of sparsity-inducing penalty functions have been proposed to approximate the ℓ0 term: exponential concave function Bradley and Mangasarian (1998), ℓp-norm with 0 < ce: paraid = "para0019" > (Fu, 1998) and p < 0 (Rao and Kreutz-Delgado, 1999), Smoothly Clipped Absolute Deviation (SCAD) (Fan and Li, 2001), Logarithmic function (Weston et al., 2003), Capped-ℓ1(Peleg and Meir, 2008) (see (21), (22) and Table 1in Section 3 for the definition of these functions). Using these approximations, several algorithms have been developed for resulting optimization problems, most of them are in the context of feature selection in classification, sparse regressions or more especially for sparse signal recovery: Successive Linear Approximation (SLA) algorithm (Bradley and Mangasarian, 1998), DCA (Difference of Convex functions Algorithm) based algorithms (Chen, Xu, and Ye, 2010; Collobert, Sinz, Weston and Bottou, 2006; Gasso, Rakotomamonjy, and Canu, 2009; Guan and Gray, 2013; Le Thi, Le, Nguyen, and Pham Dinh, 2008; Le Thi, Nguyen, and Ouchani, 2009; Le, Le Thi, and Nguyen, 2013; Le Thi, Nguyen, and Le, 2013; Le Thi and Nguyen, 2013; Neumann, Schnö and Steidl, 2005; Ong and Le Thi, 2012) , Local Linear Approximation (LLA) (Zou and Li, 2008), Two-stage ℓ1(Zhang, 2009), Adaptive Lasso (Zou, 2006), reweighted-ℓ1 algorithms (Candes, Wakin, and Boyd, 2008), reweighted- ℓ2 algorithms such as Focal Underdetermined System Solver (FOCUSS) (Gorodnitsky and Rao, 1997; Rao and Kreutz-Delgado, 1999; Rao, Engan, Cotter, Palmer, and KreutzDelgado, 2003), Iteratively reweighted least squares (IRLS) algorithm (Chartrand and Yin, 2008) and Local Quadratic Approximation (LQA) algorithm (Fan and Li, 2001; Zou and Li, 2008).In the third category named nonconvex exact reformulation approaches, the ℓ0-regularized problem is reformulated as a continuous nonconvex program. There are a few works in this category. In Mangasarian (1996), the author reformulated the problem (1) in the context of feature selection in SVM as a linear program with equilibrium constraints (LPEC). However, this reformulation is generally intractable for large-scale datasets. In Thiao, Pham Dinh, and Le Thi (2008) and Pham Dinh and Le Thi (2014) an exact penalty technique in DC programming is used to reformulate (1) and (2) as DC programs. In Thiao, Pham Dinh, and Le Thi (2010) this technique is used for Sparse Eigenvalue problem with ℓ0-norm in constraint functions(5)max{xTAx:xTx=1,∥x∥0≤k},where A ∈Rn×nis symmetric and k an integer, and a DCA based algorithm was investigated for the resulting problem.Beside the three above categories, heuristic methods are developed to tackle directly the original problem (1) by greedy based algorithms, e.g. matching pursuit (Mallat and Zang, 1993), orthogonal matching pursuit (Pati, Rezaifar, and Krishnaprasa, 1993), etc.Convex regularization approaches involve convex optimization problems which are so far “easy” to solve, but they do not attain the solution of the ℓ0-regularizer problem. Nonconvex approximations are, in general, deeper than convex relaxations, and then can produce good sparsity, but the resulting optimization problems are still difficult since they are nonconvex and there are many local minima which are not global. Many issues have not yet been studied or proved in the existing approximation approaches. First, the consistency between the approximate problems and the original problem is a very important question but still is open. Only a weak result has been proved for two special cases in Bradley, Mangasarian, and Rosen (1998) (resp. Rinaldi, Schoen, and Sciandrone, 2010) when f is concave, bounded below on a polyhedral convex set K and the approximation term is an exponential concave function (resp. a logarithm function and/or ℓp-norm (p < 1)). It has been shown in these works that the intersection of the solution sets of the approximate problem and the original problem is nonempty. Moreover no result on the consistency between local minimum of approximate and original problems has been available, while most of the proposed algorithms furnish local minima. Second, several existing algorithms lack a rigorous mathematical proof of convergence. Hence the choice of a “good” approximation remains relevant. Two crucial questions should be studied for solving large scale problems, that are, how to suitably approximate the zero-norm and which computational method to use for solving the resulting optimization problem. The development of new models and algorithms for sparse optimization problems is always a challenge for researchers in optimization and machine learning.Our contributions. We consider in this paper the problem (1) where K is a polyhedral convex set inRn×Rmand f is a finite DC function onRn×Rm. We address all issues cited above for approximation approaches and develop an unifying approach based on DC programming and DCA, a robust, fast and scalable approach for nonconvex and nonsmooth continuous optimization (Le Thi and Pham Dinh, 2005; Pham Dinh and Le Thi, 1998). The contributions of this paper are multiple, from both a theoretical and a computational point of view.Firstly, considering a common DC approximate function rθ(θ is a parameter controlling the tightness of approximation) we prove the consistency between the approximate problem and the original problem by showing the link between their global minimizers as well as their local minimizers. We demonstrate that any optimal solution of the approximate problem is in a ε-neighborhood of an optimal solution to the original problem (1). More strongly, if f is concave and the objective function of the approximate problem is bounded below on K, then some optimal solutions of the approximate problem are exactly solutions of the original problem. These new results are important and very useful for justifying the performance of approximation approaches.Secondly, we provide an in-depth analysis of usual sparsity-inducing functions and compare them according to suitable parameter values. This study suggests the choice of good approximations of the zero-norm as well as that of good parameters for each approximation. A reasonable comparison via suitable parameters identifies Capped -ℓ1 and SCAD as the best approximations.Thirdly, we prove, via an exact reformulation approach by exact penalty techniques that, with suitable parameters (say, θ > θ0 for some θ0), nonconvex approximate problems resulting from Capped -ℓ1 or SCAD functions are equivalent to the original problem. Moreover, when the set K is a box, we can show directly (without using exact penalty techniques) the equivalence between the original problem and the approximate Capped-ℓ1 problem and give the value of θ0 such that this equivalence holds for all θ > θ0. These interesting and significant results justify our analysis on usual sparsity-inducing functions and the pertinence of these approximation approaches. It opens the door to study other approximation approaches which are consistent with the original problem.Fourthly, we develop solution methods for all DC approximation approaches. Our algorithms are based on DC programming and DCA, because our main motivation is to exploit the efficiency of DCA to solve this hard problem. We propose three DCA schemes for three different formulations of a common model to all concave approximation functions. We show that these DCA schemes include all standard algorithms as special versions. The fourth DCA scheme is concerned with the resulting DC program given by the DC approximation (nonconcave piecewise linear) function in Le Thi (2012). Using DC programming framework, we unify all solution methods into DCA, and then convergence properties of our algorithms are guaranteed, thanks to general convergence results of the generic DCA scheme. It permits to exploit, in an elegant way, the nice effect of DC decompositions of the objective functions to design various versions of DCA. It is worth mentioning here the flexibility/versatility of DC programming and DCA: the four algorithms can be viewed as an ℓ1-perturbed algorithm/a reweighted-ℓ1 algorithm (intimately related to the ℓ1-penalized LASSO approach)/a reweighted-ℓ2 algorithm in case of convex objective functions.Finally, as an application, we consider the problem of feature selection in SVM and perform a careful empirical comparison of all approaches.The rest of the paper is organized as follows. Since DC programming and DCA is the core of our approaches, we give in Section 2 a brief introduction of these theoretical and algorithmic tools. The consistency between approximate problems and the original one, the link between their global minimizer as well as their local minimizer are studied in Section 3, while a comparative analysis on usual approximations is discussed in Section 4. A deeper study on Capped-ℓ1 approximation and the relation between some approximate problems and exact penalty approaches is presented in Section 5. Solution methods based on DCA are developed in Section 6, while the application of the proposed algorithms for feature selection in SVM and numerical experiments are described in Section 7. At last, Section 8 concludes the paper.Let X be the Euclidean space IRnequipped with the canonical inner product 〈., .〉 and its Euclidean norm ‖ · ‖. The dual space of X, denoted by Y, can be identified with X itself.DC (Difference of Convex functions) Programming and DCA (DC Algorithms), which constitute the backbone of nonconvex programming and global optimization, are introduced in 1985 by Pham Dinh Tao in the preliminary state, and extensively developed by Le Thi Hoai An and Pham Dinh Tao since 1994 (Le Thi, 1994; 2000; 2012; Le Thi, Pham Dinh, and Nguyen Van, 2002; Le Thi and Pham Dinh, 2003; 2005; Le Thi, Belghiti, and Pham Dinh, 2006; Le Thi, Le, and Pham Dinh, 2006; Le Thi, Nguyen, and Pham Dinh, 2007; 2007; Le Thi and Pham Dinh, 2008; Le Thi, Huynh, and Pham Dinh, 2009; 2012; Le Thi, Moeini, Pham Dinh, and Joaquim, 2012; Le, Le Thi, Pham Dinh, and Huynh, 2013; Le Thi, Le, Pham Dinh, and Huynh, 2013; Le Thi and Pham Dinh, 2013; Le Thi, Vo, and Pham Dinh, 2014; Le Thi and Nguyen, 2014; Le Thi, Le, and Pham Dinh, 2014; 2014; Le Thi and Moeini, 2014; Niu, Pham Dinh, Le Thi and Judice, 2012; Pham Dinh and Le Thi, 1997; 1998; 2002; Pham Dinh, Nguyen Canh, and Le Thi, 2010; Pham Dinh, Le, Le Thi, and Lauer, 2014) and references quoted therein). Their original key idea relies on the structure DC of objective function and constraint functions in nonconvex programs which are explored and exploited in a deep and suitable way. The resulting DCA introduces the nice and elegant concept of approximating a nonconvex (DC) program by a sequence of convex ones: each iteration of DCA requires solution of a convex program.Their popularity resides in their rich, deep and rigorous mathematical foundations, and the versatility/flexibility, robustness, and efficiency of DCA’s compared to existing methods, their adaptation to specific structures of addressed problems and their ability to solve real-world large-scale nonconvex programs. Recent developments in convex programming are mainly devoted to reformulation techniques and scalable algorithms in order to handle large-scale problems. Obviously, they allow for enhancement of DC programming and DCA in high dimensional nonconvex programming.Standard DC programs are of the form:α=inf{f(x):=g(x)−h(x):x∈Rn}(Pdc)where g, h ∈ Γ0(Rn),the convex cone of all lower semicontinuous proper (i.e., not identically equal to + ∞) convex functions defined onRnand taking values inR∪{+∞}.Such a function f is called a DC function, and g − h a DC decomposition of f while g and h are the DC components of f. The convex constraint x ∈ C can be incorporated in the objective function of (Pdc) by using the indicator function of C denoted by χCwhich is defined by χC(x) = 0 if x ∈ C, and + ∞ otherwise:inf{f(x):=g(x)−h(x):x∈CAPTARANORMAL}=inf{χC(x)+g(x)−h(x):x∈Rn}.The vector space of DC functions, DC(Rn)=Γ0(Rn)−Γ0(Rn),forms a wide class encompassing most real-life objective functions and is closed with respect to usual operations in optimization. DC programming constitutes so an extension of convex programming, sufficiently large to cover most nonconvex programs (Le Thi, 1997; Le Thi and Pham Dinh, 1997; Le Thi, 2012; Le Thi and Pham Dinh, 2003; 2005; Pham Dinh and Le Thi, 1997; 1998; 2002 and references quoted therein), but not too large in order to leverage the powerful arsenal of the latter.The conjugate of φ, denoted by φ*, is given byφ*(y):=sup{〈x,y〉−φ(x):x∈Rn},∀y∈Rn.DC duality associates the primal DC program (Pdc) with its dual (Ddc), which is also a DC program with the same optimal value and defined byα=inf{h*(y)−g*(y):y∈Rn},(Ddc)and studies the relation between primal and dual solution sets denoted byPandDrespectively. In DC programming we adopt the explainable convention + ∞ − ( + ∞) = +∞ for avoiding ambiguity. Note that the finiteness of α implies that dom g⊂ dom h and dom h*⊂ dom g*, where the effective domain of φ ∈ Γ0 (Rn)is domφ:={x∈Rn:φ(x)<+∞}. The function φ ∈ Γ0 (Rn)is polyhedral convex if it is the sum of the indicator function of a nonempty polyhedral convex set and the pointwise supremum of a finite collection of affine functions. Polyhedral DC program is a DC program in which at least one of the functions g and h is polyhedral convex. Polyhedral DC programming, which plays a key role in nonconvex programming and global optimization, has interesting properties (from both a theoretical and an algorithmic point of view) on local optimality conditions and the finiteness of DCA’s convergence.For φ ∈ Γ0(Rn),the subdifferential of φ at x0 ∈ dom φ, denoted by ∂φ(x0), is defined by(6)∂φ(x0):={y∈Rn:φ(x)≥φ(x0)+〈x−x0,y〉,∀x∈Rn}.The subdifferential ∂φ(x0) is a closed convex set, which generalizes the derivative of φ in the sense that φ is differentiable at x0 if and only if ∂φ(x0) is reduced to a singleton, that is nothing but {▽φ(x0)}.DC programming investigates the structure of DC(Rn),DC duality and local and global optimality conditions for DC programs. The complexity of DC programs clearly lies in the distinction between local and global solution and, consequently the lack of verifiable global optimality conditions.We have developed necessary local optimality conditions for the primal DC program (Pdc), by symmetry those relating to dual DC program(Ddc)are trivially deduced:(7)∂h(x*)∩∂g(x*)≠∅(such a point x* is called critical point of g − h or (7) a generalized Karusk–Kuhn–Tucker (KKT) condition for (Pdc)), and(8)∅≠∂h(x*)⊂∂g(x*).The condition (8) is also sufficient (for local optimality) in many important classes of DC programs. In particular it is sufficient for the next cases quite often encountered in practice:•In polyhedral DC programs with h being a polyhedral convex function. In this case, if h is differentiable at a critical point x*, then x* is actually a local minimizer for (Pdc). Since a convex function is differentiable everywhere except for a set of measure zero, one can say that a critical point x* is almost always a local minimizer for (Pdc).In case the function f is locally convex at x*. Note that, if h is polyhedral convex, then f = g − h is locally convex everywhere h is differentiable.The transportation of global solutions between (Pdc) and (Ddc) is expressed by:(9)⋃y*∈D∂g*(y*)⊂P,⋃x*∈P∂h(x*)⊂D.The first (second) inclusion becomes equality if the function h (resp. g*) is subdifferentiable onP(resp.D). They show that solving a DC program implies solving its dual. Note also that, under technical conditions, this transportation also holds for local solutions of (Pdc) and (Ddc). (Le Thi, 1997; Le Thi and Pham Dinh, 1997; Le Thi, 2012; Le Thi and Pham Dinh, 2003; 2005; Pham Dinh and Le Thi, 1997; 1998; 2002 and references quoted therein).Philosophy of DCA. DCA is based on local optimality conditions and duality in DC programming. The main original idea of DCA is simple, it consists in approximating a DC program by a sequence of convex programs: each iteration k of DCA approximates the concave part − h by its affine majorization (that corresponds to taking yk∈ ∂h(xk)) and minimizes the resulting convex function.The generic DCA scheme can be described as follows:DCA schemeInitialization:Letx0∈Rnbe a guess, set k ≔ 0.Repeat•Calculate some yk∈ ∂h(xk)Calculatexk+1∈argmin{g(x)−[h(xk)+〈x−xk,yk〉]:x∈Rn}(Pk)Increasing k by 1Note that (Pk) is a convex optimization problem and is so far “easy” to solve.Convergence properties of DCA and its theoretical basis can be found in Le Thi (1997); Le Thi and Pham Dinh (1997, 2005); Le Thi, Huynh, and Pham Dinh (2014); Pham Dinh and Le Thi (1997, 1998); 2002); 2014). For instance it is important to mention that (for the sake of simplicity we omit here the dual part of DCA).(i)DCA is a descent method without linesearch (the sequence {g(xk) − h(xk)} is decreasing) but with global convergence (DCA converges from any starting point).If g(xk + 1) − h(xk + 1) = g(xk) − h(xk), then xkis a critical point of g − h. In such a case, DCA terminates at kth iteration.If the optimal value α of problem (Pdc) is finite and the infinite sequence {xk} is bounded, then every limit point x* of the sequence {xk} is a critical point of g − h.DCA has a linear convergence for DC programs.DCA has a finite convergence for polyhedral DC programs. Moreover, if h is polyhedral and h is differentiable at x* then x* is a local optimizer of (Pdc).In DC programming with subanalytic data, the whole sequence {xk} generated by DCA converges and DCA’s rate convergence is stated.It is worth mentioning that the construction of DCA involves DC components g and h but not the function f itself. Hence, for a DC program, each DC decomposition corresponds to a different version of DCA. Since a DC function f has infinitely many DC decompositions which have crucial implications on the qualities (speed of convergence, robustness, efficiency, globality of computed solutions, ...) of DCA, the search of a “good” DC decomposition is important from an algorithmic point of view. For a given DC program, the choice of optimal DC decompositions is still open. Of course, this depends strongly on the very specific structure of the problem being considered. In order to tackle the large-scale setting, one tries in practice to choose g and h such that sequences {xk} and {yk} can be easily calculated, i.e., either they are in an explicit form or their computations are inexpensive. Very often in practice, the sequence {yk} is explicitly computed because the calculation of a subgradient of h can be explicitly obtained by using the usual rules for calculating subdifferential of convex functions. But the solution of the convex program (Pk), if not explicit, should be achieved by efficient algorithms well-adapted to its special structure, in order to handle the large-scale setting.How to develop an efficient algorithm based on the generic DCA scheme for a practical problem is thus a sensible question to be studied. Generally, the answer depends on the specific structure of the problem being considered. The solution of a nonconvex program (Pdc) by DCA must be composed of two stages: the search of an appropriate DC decomposition of f and that of a good initial point.DC programming and DCA have been successfully applied for modeling and solving many and various nonconvex programs from different fields of Applied Sciences, especially in machine learning (Chan, Vasconcelos, and Lanckriet, 2007; Collober et al., 2006; Fawzi, Davies, and Frossard, 2014; Guyon, Gunn, Nikravesh, and Zadeh, 2006; Krause and Singer, 2004; Le Thi et al., 2006; Le Thi et al., 2006; 2007; Le Thi et al., 2013; Le Thi et al., 2014; Le Thi and Nguyen, 2014; Liu and Zheng, 2005; Liu and Shen, 2006; Mohri and Median, 2014; Natarajan, 1995; Pham Dinh et al., 2014; Schmidt, Fung, and Rosales, 2007; Sriperumbudur, Torres, and Lanckriet, 2007; Tan, Wang, and Tsang, 2010); (see also the more complete list of references in Le Thi, 2012). Note that with appropriate DC decompositions and suitably equivalent DC reformulations, DCA permits to recover most of standard methods in convex and nonconvex programming as special cases. In particular, DCA is a global algorithm (i.e. providing global solutions) when applied to convex programs recast as DC programs and therefore DC programming and DCA can be used to build efficiently customized algorithms for solving convex programs generated by DCA itself.For a complete study of DC programming and DCA the reader is referred to (Le Thi, 1997; Le Thi and Pham Dinh, 1997; 2005; Le Thi et al., 2014; Pham Dinh and Le Thi, 1997; 1998; 2002; 2014 and the references quoted therein).We focus on the sparse optimization problem with ℓ0-norm in the objective function, called the ℓ0-problem, that takes the form(10)min{F(x,y)=f(x,y)+λ∥x∥0:(x,y)∈K},where λ is a positive parameter, K is a convex set inRn×Rmand f is a finite DC function onRn×Rm. Suppose that f has a DC decomposition(11)f(x,y)=g(x,y)−h(x,y)∀(x,y)∈Rn×Rm,where g, h are finite convex functions onRn×Rm. Through the paper, for a DC function f ≔ g − h, ∂f(x, y) stands for the set ∂g(x, y) − ∂h(x, y). More precisely, the notation(x¯,y¯)∈∂f(x,y)means that(x¯,y¯)=(xg,yg)−(xh,yh)for some (xg, yg) ∈ ∂g(x, y), (xh, yh) ∈ ∂h(x, y).Define the step functions:R→Rby s(t) = 1 for t ≠ 0 and s(t) = 0 otherwise. Then∥x∥0=∑i=1ns(xi). The idea of approximation methods is to replace the discontinuous step function by a continuous approximation rθ, where θ > 0 is a parameter controling the tightness of approximation. This leads to the approximate problem of the form(12)min{Frθ(x,y)=f(x,y)+λ∑i=1nrθ(xi):(x,y)∈K}.Assumption 1{rθ}θ > 0 is a family of functionsR→Rsatisfying the following properties:(i)limθ → +∞rθ(t) = s(t),∀t∈R.For any θ > 0, rθis even, i.e.rθ(t)=rθ(|t|)∀t∈R)and rθis increasing on [0, +∞).For any θ > 0, rθis a DC function which can be represented asrθ(t)=φθ(t)−ψθ(t),t∈R,where φθ, ψθare finite convex functions onR.tμ ≥ 0∀t∈R,μ∈∂rθ(t). where ∂rθ(t) = {u − v: u ∈ ∂φθ(t), v ∈ ∂ψθ(t)}.For any a ≤ b and0∉[a,b]:limθ→+∞sup{|z|:z∈∂rθ(t),t∈[a,b]}=0.First of all, we observe that by assumption (ii) above, we get another equivalent form of (12)(13)min(x,y,z)∈Ω1F¯rθ(x,y,z):=f(x,y)+λ∑i=1nrθ(zi),whereΩ1={(x,y,z):(x,y)∈K,|xi|≤zi∀i=1,⋯,n}.Indeed, (12) and (13) are equivalent in the following sense.Proposition 1A point (x*, y*) ∈ K is a global (resp. local) solution of the problem (12) if and only if (x*, y*, |x*|) is a global (resp. local) solution of the problem (13). Moreover, if (x*, y*, z*) is a global solution of (13) then (x*, y*) is a global solution of (12).Since rθis an increasing function on [0, +∞), we haveF¯rθ(x,y,z)≥F¯rθ(x,y,|x|)=Frθ(x,y)∀(x,y,z)∈Ω1.Then the conclusion concerning global solutions is trivial. The result on local solutions also follows by remarking that if (x, y, z) ∈ B((x*, y*, z*), δ)11B(u*, δ) stands for the set of vectorsu∈Rdsuch that ‖u − u*‖ < δ.then (x, y) ∈ B((x*, y*), δ), and if(x,y)∈B((x*,y*),δ2)then (x, y, |x|) ∈ B((x*, y*, |x*|), δ).□In standard nonconvex approximation approaches to ℓ0-problem, all the proposed approximation functions rθare even and concave increasing on [0, +∞) (see Table 1) and the approximate problems were often considered in the form (13). Here we study the general case where rθis a DC function and consider both problems (12) and (13) in order to exploit the nice effect of DC decompositions of a DC program.Now we show the link between the original problem (10) and the approximate problem (12). This result gives a mathematical foundationof approximation methods.Theorem 1LetP,Pθbe the solution sets of the problem (10) and (12) respectively.(i)Let {θk} be a sequence of nonnegative numbers such that θk→ +∞ and {(xk, yk)} be a sequence such that(xk,yk)∈Pθkfor any k. If (xk, yk) → (x*, y*), then(x*,y*)∈P.If K is compact, then for any ε > 0 there is θ(ε) > 0 such thatPθ⊂P+B(0,ϵ)∀θ≥θ(ϵ).If there is a finite setSsuch thatPθ∩S≠∅∀θ>0,then there exists θ0 ≥ 0 such thatPθ∩S⊂P∀θ≥θ0.(i) Let (x, y) be arbitrary in K. For any k, since(xk,yk)∈Pθk,we have(14)f(x,y)+λ∑i=1nrθk(xi)≥f(xk,yk)+λ∑i=1nrθk(xik).By Assumption 1 (ii), ifxi*=0,we havelim infk→+∞rθk(xik)≥lim infk→+∞rθk(0)=0.Ifxi*≠0,there exist ai≤ biandki∈Nsuch that 0 ≠ [ai, bi] andxik∈[ai,bi]for all k ≥ ki. Then we have|rθk(xik)−s(xi*)|≤max{|rθk(ai)−s(ai)|,|rθk(bi)−s(bi)|}∀k≥ki.Sincelimk→+∞rθk(ai)=s(ai)andlimk→+∞rθk(bi)=s(bi),we havelimk→+∞rθk(xik)=s(xi*). Note that f is continuous, takinglim infof both sides of (14), we getf(x,y)+λ∑i=1ns(xi)≥f(x*,y*)+λ∑i=1nlim infk→∞rθk(xik)≥f(x*,y*)+λ∑i=1ns(xi*).Thus, F(x, y) ≥ F(x*, y*) for any (x, y) ∈ K, or(x*,y*)∈P.(ii) We assume by contradiction that there exists ε > 0 and a sequence {θk} such that θk→ +∞, and for any k there is(xk,yk)∈Pθk∖(P+B(0,ϵ)). Since {(xk, yk)}⊂K and K is compact, there exists a subsequence{(xkl,ykl)}of {(xk, yk)} converges to a point (x*, y*) ∈ K. By i), we have(x*,y*)∈P. However,{(xkl,ykl)}⊂K∖(P+B(0,ϵ))that is a closed set, so(x*,y*)∈K∖(P+B(0,ϵ)). This contradicts the fact that(x*,y*)∈P.(iii) Assume by contradiction that there is a sequence {θk} such that θk→ +∞, and for any k there is(xk,yk)∈(Pθk∩S)∖P. SinceSis finite, we can extract a subsequence such that(xkl,ykl)=(x¯,y¯)∀l. Then we have(x¯,y¯)∉P. This contradicts the fact that(x¯,y¯)∈Pfollowing (i).□The assumption that rθis an even function is not needed for proving this theorem. More precisely, the theorem still holds when the assumption 1 (ii) is replaced by “for any θ > 0, rθis decreasing on ( − ∞, 0] and is increasing on [0, +∞)”. For the zero-norm, since the step function is even, it is natural to consider its approximation rθas an even function.Theorem 1 shows that any optimal solution of the approximate problem (12) is in a ε-neighborhood of an optimal solution to the original problem (10), and the tighter approximation of ℓ0-norm is, the better approximate solutions are. Moreover, if there is a finite setSsuch thatPθ∩S≠∅∀θ>0,then any optimal solution of the approximate problem (12) contained inSsolves also the problem (10). By considering the equivalent problem (13), we show in the following corollary that such a setSexists in several contexts of applications (for instance, in feature selection in SVM).Corollary 1Suppose that r is concave on [0, +∞), K is a polyhedral convex set having at least a vertex and f is concave, bounded below on K. Then Ω1 defined in (13) is also a polyhedral convex set having at least a vertex. LetVbe the vertex set of Ω1 andP¯θ={(x,y):∃z∈Rns.t.(x,y,z)∈Visaglobalsolutionof13}.ThenP¯θ≠∅∀θ>0and there exists θ0 > 0 such thatP¯θ⊂P,∀θ ≥ θ0.By the assumptions, we haveF¯rθis concave, bounded below on Ω1, soP¯θ≠∅∀θ>0. LetS={(x,y):(x,y,z)∈Vforsomez∈Rn}. By Proposition 1, we haveP¯θ⊂Pθ∩S∀θ>0. SinceVis finite, so isS. The property (iii) of Theorem 1 implies the existence of θ0 > 0 such thatP¯θ⊂Pθ∩S⊂P∀θ≥θ0.□Note that the consistency between the solution of the approximate problem and the original problem have been carried out in Bradley et al. (1998) (resp. Rinaldi et al., 2010) for the case where f is concave, bounded below on the polyhedral convex set K and r is the exponential approximation defined in Table 1 below (resp. r is the logarithm function and/or ℓp-norm (p < 1)). Here, besides general results carried out in Theorem 1, our Corollary 1 gives a much stronger result than those in Bradley et al. (1998) and Rinaldi et al. (2010) where they only ensure thatP¯θ∩P≠∅∀θ≥θ0.Observing that the approximate problem is still nonconvex for which, in general, only local algorithms are available, we are motivated by the study of the consistency between local minimizers of the original and approximate problems. For this purpose, first, we need to describe characteristics of local solutions of these problems.Proposition 2(i) A point (x*, y*) ∈ K is a local optimum of the problem (10) if and only if (x*, y*) is a local optimum of the problem(15)min{f(x,y):(x,y)∈K(x*)},where K(x*) = {(x, y) ∈ K: xi= 0~∀i∉supp(x*)}.(ii) If (x*, y*) ∈ K is a local optimum of the problem (10) then(16)〈x¯*,x−x*〉+〈y¯*,y−y*〉≥0∀(x,y)∈K(x*),for some(x¯*,y¯*)∈∂f(x*,y*).(i) The forward implication is obvious, we only need to prove the backward one. Assume that (x*, y*) is a local solution of the problem (15). There exists a neighborhoodVof (x*, y*) such thatsupp(x*)⊂supp(x)and|f(x,y)−f(x*,y*)|<λ∀(x,y)∈V,andf(x*,y*)≤f(x,y)∀(x,y)∈V∩K(x*).For any(x,y)∈V∩K,two cases occur:- If (x, y) ∈ K(x*), then ‖x‖0 = ‖x*‖0 and f(x*, y*) ≤ f(x, y).- If (x, y)∉K(x*), then ‖x*‖0 ≤ ‖x‖0 − 1 and f(x*, y*) < f(x, y) + λ.In both cases, we have f(x*, y*) + λ‖x*‖0 ≤ f(x, y) + λ‖x‖0. Thus, (x*, y*) is a local solution of the problem (10).(ii) Since f = g − h is a DC function, (15) is a DC program. Therefore, the necessary local condition of the problem (15) can be stated by0∈∂(g+χK(x*))(x*,y*)−∂h(x*,y*),or equivalently, there exists(x¯*,y¯*)∈∂f(x*,y*)such that−(x¯*,y¯*)∈∂χK(x*)(x*,y*)⇔〈x¯*,x−x*〉+〈y¯*,y−y*〉≥0∀(x,y)∈K(x*),□As for the characteristics of local solutions of the problem (12), we follow the condition (7) above for a DC program. Writing the problem (12) in form of a DC program(17)minx,y{Frθ(x,y):=G(x,y)−H(x,y)},with(18)G(x,y)=χK(x,y)+g(x,y)+λ∑i=1nφθ(xi),H(x,y)=h(x,y)+λ∑i=1nψθ(xi).Then, for a point (x*, y*) ∈ K, the necessary local optimality condition (7) can be expressed as0∈∂G(x*,y*)−∂H(x*,y*),which is equivalent to(19)〈x¯*,x−x*〉+〈y¯*,y−y*〉+〈z¯*,x−x*〉≥0∀(x,y)∈K,for some(x¯*,y¯*)∈∂f(x*,y*)andz¯i*∈λ∂rθ(xi*)∀i=1,⋯,n.Now we are able to state consistency results of local optimality.Theorem 2LetLandLθbe the sets of (x, y) ∈ K satisfying the conditions (16) and (19) respectively.(i)Let {θk} be a sequence of nonnegative numbers such that θk→ +∞ and {(xk, yk)} be a sequence such that(xk,yk)∈Lθk,∀k. If (xk, yk) → (x*, y*), we have(x*,y*)∈L.If K is compact then, for any ε > 0, there is θ(ε) > 0 such thatLθ⊂L+B(0,ϵ)∀θ≥θ(ϵ).If there is a finite setSsuch thatLθ∩L≠∅,∀θ>0,then there exists θ0 ≥ 0 such thatLθ∩S⊂L∀θ≥θ0.(i) By definition, there is a sequence{(x¯k,y¯k,z¯k)}such that for all k = 1, 2, …(x¯k,y¯k)∈∂f(xk,yk),andz¯ik∈λ∂rθk(xik)i=1,⋯,n,(20)〈x¯k,x−xk〉+〈y¯k,y−yk〉+〈z¯k,x−xk〉≥0∀(x,y)∈K.For k = 1, 2, …, we have(x¯k,y¯k)=(xgk,ygk)−(xhk,yhk),where(xgk,ygk)∈∂g(xk,yk),and(xhk,yhk)∈∂h(xk,yk).Since {(xk, yk)} converges to (x*, y*), there isk0∈Nand a compact setS⊂Rn×Rmsuch that(xk,yk)∈S,∀k≥k0. It follows by Theorem 24.7 (Rockafellar, 1970) that∂g(S):=∪x∈S∂g(x)and∂h(S):=∪x∈S∂h(x)are compact sets. Thus, there is an infinite setK⊂Nsuch that the sequence{(xgk,ygk)}k∈Kconverges to a point(xg*,yg*)∈∂g(S)and the sequence{(xhk,yhk)}k∈Kconverges to a point(xh*,yh*)∈∂h(S). By Theorem 24.4 (Rockafellar, 1970), we have(xg*,yg*)∈∂g(x*,y*)and(xh*,yh*)∈∂h(x*,y*). Therefore, the sequence{(x¯k,y¯k)}k∈Kconverges to(x¯*,y¯*)=(xg*,yg*)−(xh*,yh*)∈∂f(x*,y*).By Assumption 1 (iv), we havez¯ikxik≥0∀i,k. Moreover, for any i ∈ supp(x*), there exist ai≤ biandki∈Nsuch that 0∉[ai, bi] andxik∈[ai,bi]for all k ≥ ki. By Assumption 1 (v), we deduce thatz¯ik→0as k → +∞.For arbitrary (x, y) ∈ K(x*), (20) implies that〈x¯k,x−xk〉+〈y¯k,y−yk〉≥∑i∉supp(x*)z¯ikxik−∑i∈supp(x*)z¯ik(xi−xik)≥−∑i∈supp(x*)z¯ik(xi−xik)∀k.Takingk∈K,k→+∞,we get〈x¯*,x−x*〉+〈y¯*,y−y*〉≥0∀(x,y)∈K(x*).Thus,(x*,y*)∈L.(ii) and (iii) are proved similarly as in Theorem 1.□First, let us mention, in chronological order, the approximation functions proposed in the literature in different contexts, but we do not indicate the related works concerning algorithms using these approximations. The first was concave exponential approximation proposed in Bradley and Mangasarian (1998) in the context of feature selection in SVM, and ℓp-norm with 0 < ce: paraid = "para0109" > for sparse regression (Fu, 1998). Later, the ℓp-norm with p < 0 was studied in Rao and Kreutz-Delgado (1999) for sparse signal recovery, and then the Smoothly Clipped Absolute Deviation (SCAD) (Fan and Li, 2001) in the context of regression, the logarithmic approximation (Weston et al., 2003) for feature selection in SVM, and the Capped-ℓ1(Peleg and Meir, 2008) applied on sparse regression.A common property of these approximations is they are all even, concave increasing functions on [0, +∞). It is easy to verify that these function satisfy the conditions in Assumption 1 and so they are particular cases of our DC approximation r. More general DC approximation functions are also investigated, e.g., PiL (Le Thi, 2012) that is a (nonconcave) piecewise linear function defined in Table 1.Note that, some of these approximation functions, namely logarithm (log), SCAD and ℓp-norm defined by(21)Log:log(|t|+ϵ),ϵ>0,ℓp:sign(p)(|t|+ϵ)p,0≠p≤1,ϵ>0;(22)SCAD:{γ|t|if0≤|t|≤γ,−t2+2aγ|t|−γ22(a−1)ifγ<|t|<aγ,(a+1)γ22if|t|≥aγ,a>1,γ>0do not directly approximate ℓ0-norm. But they become approximations of ℓ0-norm if we multiply them by an appropriate factor (which can be incorporated into the parameter λ), and add an appropriate term (such a procedure does not affect the original problem). The resulting approximation forms of these functions are given in Table 1. We see that rscad is obtained by multiplying the SCAD function by2(a+1)γ2and settingθ=1γ. Similarly, by takingθ=1ϵ,we haverlog(t)=log(|t|+ϵ)log(1+1/ϵ)−logϵlog(1+1/ϵ),andrℓp−(t)=−(|t|+ϵ)pϵp+1.For using ℓp-norm approximation with 0 < ce: paraid = "para0112" > we takeθ=1p. Note that limθ → ∞|t|1/θ= s(t). To avoid singularity at 0, we add a small ε > 0. In this case, we require ε = ε(θ) satisfying limθ → ∞ε(θ)1/θ= 0 to ensure thatlimθ→∞rℓp+(t)=s(t).All these functions satisfy Assumption 1 (for proving the condition (iii) of Assumption 1 we indicate in Table 1 a DC decomposition of the approximation functions), so the consistency results stated in Theorems 1 and 2 are applicable.Discussion. Except rPiL that is differentiable at 0 withrPiL′(0)=0,the other approximations have the right derivative at 0 depending on the approximation parameter θ. Clearly the tightness of each approximation depends on related parameters. Hence, a suitable way to compare them is using the parameter θ such that their right derivatives at 0 are equal, namelyθcap=2a+1θscad=θexp=−pθℓp−.In this case, by simple calculation we have(23)0≤rℓp−≤rexp≤rscad≤rcap≤s.Comparing rcap and rscad with different values θ, we get(24){0≤rscad≤rcap≤s,if2θscada+1≤θcap0≤rcap≤rscad≤s,ifθcap≤θscada.Inequalities in (23) show that, with the parameter θ such that their right derivatives at 0 are equal, rscad and rcap are closer to the step function s thanrℓp−and rexp.As for rlog andrℓp+,we see that they tend to + ∞ when t → +∞, so they have poor approximation for t large. Whereas, the other approximations are minorants of s and larger t is, closer to s they are. For easier seeing, we depict these approximations in Fig. 1.Now, we give a deeper study on Capped-ℓ1 approximation. Using exact penalty techniques related to ℓ0-norm developed in Thiao et al. (2008) and Pham Dinh and Le Thi (2014) we prove a much stronger result for this approximation, that is the approximation problem (12) is equivalent to the original problem with appropriate parameters θ when K is a compact polyhedral convex set (this case quite often occurs in applications, in particular in machine learning contexts). Furthermore, when K is a box, we show (directly, without using the exact penalty techniques) that the Capped-ℓ1 approximation problem is equivalent to the original problem and we compute an exact value θ0 such that the equivalence holds for all θ > θ0.Thanks to exact continuous reformulation via penalty techniques, we shall prove that, with some sparse inducing functions, the approximate problem is equivalent to the original problem. First of all, let us recall exact penalty techniques related to ℓ0-norm (Pham Dinh and Le Thi, 2014; Thiao et al., 2008).Denote by e the vector of ones in the appropriate vector space. We suppose that K is bounded in the variable x, i.e.K⊂Πi=1n[ai,bi]×Rmwhere ai, bi∈Rsuch that ai≤ 0 < bifor i = 1, …, n. Letci:=max{|xi|:xi∈[ai,bi]}=max{|ai|,|bi|}for i = 1, …, n. Define the binary variable ui∈ {0, 1} as(25)ui=|xi|0={1ifxi≠00ifxi=0,∀i=1,⋯,n.Then (1) can be reformulated as(26)α:=inf{f(x,y)+λeTu:(x,y)∈K,u∈{0,1}n,|xi|≤ciui,i=1,⋯,n},Letp:[0,1]n→Rbe the penalty function defined by(27)p(u):=∑i=1nmin{ui,1−ui}.Then (1) can be rewritten as(28)α=inf{f(x,y)+λeTu:(x,y)∈K,u∈[0,1]n,|xi|≤ciui,i=1,⋯,n,p(u)≤0},which leads to the corresponding penalized problems (τ being the positive penalty parameter)(29)α(τ):=inf{f(x,y)+λeTu+τp(u):(x,y)∈K,u∈[0,1]n,|xi|≤ciui,i=1,⋯,n}.It has been shown in Thiao et al. (2008) and Pham Dinh and Le Thi (2014) that there is τ0 ≥ 0 such that for every τ > τ0 problems (1) and (29) are equivalent, in the sense that they have the same optimal value and (x*, y*) ∈ K is a solution of (1) iff there is u* ∈ {0, 1}nsuch that (x*, y*, u*) is a solution of (29).It is clear that if the function f(x, y) is a DC function on K then (28) is a DC program.Let us state now the link between the continuous problem (29) and the Capped-ℓ1 approximation problem.The Capped-ℓ1 approximation is defined by:(30)Ψθ(x):=∑i=1nrcap(xi),∀x=(xi)∈Rn,withrcap(t):=min{θ|t|,1},t∈R.We will demonstrate that the resulting approximate problem of (1), namely(31)β(θ):=inf{f(x,y)+λ∑i=1nrcap(xi):(x,y)∈K}is equivalent to the penalized problem (29) with suitable values of parameters λ, τ and θ.Let M = max {ci: i = 1, …, n}, consider the problem (29) in the form(32)α(τ):=inf{f(x,y)+λeTu+τp(u):(x,y)∈K,u∈[0,1]n,|xi|≤Mui,i=1,⋯,n}.Letς:R→Rbe the function defined by ς(t) = min {t, 1 − t}. Thenp(u)=∑i=1nς(ui)and the problem (32) can be rewritten as(33)α(τ):=inf{f(x,y)+λ∑i=1n(ui+τλς(ui)):(x,y)∈K,|xi|M≤ui≤1,i=1,⋯,n,∑i=1n}or again(34)α(τ):=inf{f(x,y)+λ∑i=1nπ(ui):(x,y)∈K,|xi|M≤ui≤1,i=1,⋯,n∑i=1n}whereπ:R→Rbe the function defined byπ(t):=t+τλς(t).Proposition 3Letθ:=τ+λλM.For all τ ≥ λ problems (34) and (31) are equivalent in the following sense: (x*, y*) is an optimal solution of (31) iff (x*, y*, u*) is an optimal solution of (34), whereui*∈{|xi*|M,1}such thatπ(ui*)=rcap(xi*)for i = 1, …, n. Moreover, α(τ) = β(θ).If (x*, y*, u*) is an optimal solution of (34), thenui*is an optimal solution of the following problem, for every i = 1, …, n(35)min{π(ui):|xi*|M≤ui≤1}.Since ς is a concave function, so is π. Consequentlymin{π(ui):|xi*|M≤ui≤1}=min{π(|xi*|M),π(1)}=min{(1+τλ)|xi*|M,1}=rcap(xi*).For an arbitrary (x, y) ∈ K, we will show that(36)f(x*,y*)+λ∑i=1nrcap(xi*)≤f(x,y)+λ∑i=1nrcap(xi).By the assumption that (x*, y*, u*) is an optimal solution of (34), we have(37)f(x*,y*)+λ∑i=1nπ(ui*)≤f(x,y)+λ∑i=1nπ(ui)for any feasible solution (x, y, u) of (34). Letuix∈argmin{π(ξ):ξ∈{|xi|M,1}}⊂argmin{π(ξ):|xi|M≤ξ≤1},for all i = 1, …, n. Then (x, y, ux) is a feasible solution of (32) andπ(uix)=min{π(ξ):|xi|M≤ξ≤1}=rcap(xi),∀i=1,…,n.Combining (37) in which uiis replaced byuixand the last equation we get (36), which implies that (x*, y*) is an optimal solution of (31).Conversely, if (x*, y*) is a solution of (31), and letui*∈{|xi*|M,1}such thatπ(ui*)=rcap(xi*)for i = 1, …, n. Then (x*, y*, u*) is a feasible solution of (34) and for an arbitrary feasible solution (x, y, u) of (34), we havef(x,y)+λ∑i=1nπ(ui)≥f(x,y)+λ∑i=1nrcap(xi)≥f(x*,y*)+λ∑i=1nrcap(xi*)=f(x*,y*)+λ∑i=1nπ(ui*).Thus, (x*, y*, u*) is an optimal solution of (34). The equality α(τ) = β(θ) is immediately deduced from the equalityπ(ui*)=rcap(xi*).□We conclude from the above results that forθ=τ+λλMwith τ > max {λ, τ0}, or equivalentlyθ>θ0:=max{2M,τ0+λλM},the approximate problem (31) is equivalent to the original problem (1). The result justifies the goodness of the Capped-ℓ1 approximation studied in Section 4.In particular, for a special structure of K, we get the following result.Proposition 4Suppose thatK=∏i=1n[−l̲i,l¯i]×Y(0≤l̲i,l¯i≤+∞∀i,Y⊂Rm)and κ > 0 is a constant satisfying(38)|f(x,y)−f(x′,y)|≤κ∥x−x′∥2∀(x,y),(x′,y)∈K,∥x−x′∥0≤1.Then forθ>κλ,the problems (1) and (31) are equivalent.We observe that if (x, y) ∈ K such that0<|xi0|<1θfor some i0, let (x′, y) ∈ K determined byxi′=xi∀i≠i0andxi0′=0,thenf(x,y)+λΦ(x)>f(x′,y)+λΦ(x′),whereΦ(x)=∑i=1nrcap(xi). Indeed, this inequality follows the facts that|f(x,y)−f(x′,y)|≤κ∥x−x′∥2=κ|xi0|andΦ(x)−Φ(x′)=rcap(xi0)=θ|xi0|>κλ|xi0|.Forx∈Rn,we definetx∈Rnbytix=0if|xi|<1θandtix=xiotherwise. By applying the above observation, for any (x, y) ∈ K, we havef(x,y)+λΦ(x)≥f(tx,y)+λΦ(tx).The equality holds iff|xi|≥1θ∀i∈supp(x).Therefore, if (x*, y*) is a solution of (31), we have|xi*|≥1θ∀i∈supp(x*). Then, for any (x, y) ∈ K,f(x,y)+λ∥x∥0≥f(x,y)+λΦ(x)≥f(x*,y*)+λΦ(x*)=f(x*,y*)+λ∥x*∥0.This means that (x*, y*) is a solution of (1).Conversely, assume that (x*, y*) is a solution of (1). Then for any (x, y) ∈ K, we havef(x,y)+λΦ(x)≥f(tx,y)+λΦ(tx)=f(tx,y)+λ∥tx∥0≥f(x*,y*)+λ∥x*∥0≥f(x*,y*)+λΦ(x*).Thus, (x*, y*) is a solution of (31).□For the problem of feature selection in SVM, we consider the loss functionf(x,b)=(1−λ)(1NA∥max{0,−Ax+eb+e}∥1+1NB∥max{0,Bx−eb+e}∥1),(cf. Section 7 for definition of notations).It is easy to prove that foru∈Rn,ι∈Rand i ∈ {1, …, n}, we have|max{0,〈u,x〉+ι}−max{0,〈u,x′〉+ι}|≤|u|i|xi−xi′|,for allx,x′∈Rnsuch thatxj=xj′∀j≠i. Therefore, forκ=(1−λ)maxi=1,…,n{1NA∑k=1NA|Aki|+1NB∑l=1NB|Bli|},we have|f(x,b)−f(x′,b)|≤κ∥x−x′∥,∀b∈R,∀x,x′∈Rns.t.∥x−x′∥0≤1.By virtue of Proposition 4, in the case of feature selection in SVM, forθ>θ*:=κλ,the problems (1) and (31) are equivalent.Remark 2Proposition 4 gives a very important result since it permits to tackle a class of box constrained sparse optimization problems including feature selection in SVM instances by solving their equivalent (continuous) DC program of the form (31). Global approaches such as Branch and Bound/interval analysis methods can be investigated for (31) in which efficient local approaches such as DCA is a suitable way for computing tight upper bounds. This is especially useful to interval analysis based methods such as IbexOpt (Trombettoni, Araya, Neveu, and Chabert, 2011) where upper bounding procedures consist of randomly picking a point inside the extracted feasible box. On another hand, thanks to Proposition 4 we can improve the bounds of the variables by a simple procedure. Indeed, for an optimal solutionx*∈Rnof (31) we have: either|xi*|≥1θorxi*=0for any i = 1, …, n. Thus, forxi∈[−l̲i,l¯i](0≤l̲i,l¯i≤+∞;i=1,…,n), ifl̲i<1θ(resp.l¯i<1θ), then we can reduce the interval[−l̲i,l¯i]to[0,l¯i](resp. [ −li, 0]). And ifl̲i,l¯i<1θ,we can reduce the interval[−l̲i,l¯i]to {0}. It is worth noting that improving the bounds of the variables is the heart of interval-based solvers since it has strong impact on computing upper and lower bounds.Proposition 5(i) Suppose that σ is a function onRsatisfyingrcap(t)≤σ(t)≤s(t)={0,ift=0,1,otherwise,for some θcap> θ0. Then, the problems (1) and(39)inf{f(x,y)+λ∑i=1nσ(xi):(x,y)∈K}are equivalent. (ii) In particular, if θscad> aθ0 then for all τ ≥ λ the approximate probleminf{f(x,y)+λ∑i=1nrscad(xi):(x,y)∈K}is equivalent to (1).As discussed before, since θcap > θ0, the problems (1) and (31) are equivalent. Moreover, if (x*, y*) is a common solution thenf(x*,y*)+λ∑i=1nrcap(xi*)=f(x*,y*)+λ∥x*∥0.Then (i) is trivial by the fact thatf(x,y)+λ∑i=1nrcap(xi)≤f(x,y)+λ∑i=1nσ(xi)≤f(x,y)+λ∥x∥0,∀(x,y).(ii) is a direct consequence of (i) and Propositions 3 and (24).□In this section, we will omit the parameter θ when this does not cause any ambiguity.Usual sparsity-inducing functions are concave, increasing on [0, +∞). Therefore, first we present three variants of DCA for solving the problem (12) when r is concave on [0, +∞). We also suppose that r has the right derivative at 0, denoted by r′(0), so ∂( − r)(0) = { − r′(0)}.First, we consider the approximate problem (12).We propose the following DC decomposition of r:(40)r(t)=η|t|−(η|t|−r(t))∀t∈R,where η is a positive number such that ψ(t) = η|t| − r(t) is convex. The next result gives a sufficient condition for the existence of such a η.Proposition 6Suppose that r is a concave function on [0, +∞) and the (right) derivative at 0, r′(0), is well-defined. Let η ≥ r′(0). Then ψ(t) = η|t| − r(|t|) is a convex function onR.Since r is concave on [0, +∞), the function η|t| − r(t) is convex on (0, +∞) and on ( − ∞, 0). Hence it suffices to prove that for any t1 > 0, t2 < 0 and α, β ∈ (0, 1) such that α + β = 1, we have(41)ψ(αt1+βt2)≤αψ(t1)+βψ(t2).Without loss of generality, we assume that α|t1| ≥ β|t2|. Then (41) is equivalent toη(α|t1|−β|t2|)−2r(α|t1|−β|t2|)≤η(α|t1|+β|t2|)−αr(|t1|)−βr(|t2|)which can be equivalently written as(42)αr(|t1|)+βr(|t2|)−r(t0)≤2ηβ|t2|,where t0 = α|t1| − β|t2| ≥ 0. Letμ∈Rsuch that − μ ∈ ∂( − r(t0)). Since r is concave on [0, +∞), we haveαr(|t1|)+βr(|t2|)−r(t0)≤r(α|t1|+β|t2|)−r(t0)≤2μβ|t2|.Hence (42) holds when μ ≤ η. By the concavity of r, we haver(t02)≤r(0)+r′(0)t02,andr(t02)≤r(t0)−μt02,therefore(z−r′(0))t0≤r(0)+r(t0)−2r(t02)≤0.This and the condition r′(0) ≤ η imply that μ ≤ r′(0) ≤ η. The proof is then complete.□With η ≥ r′(0), a DC formulation of the problem (12) is given by(43)minx,y{Fr(x,y):=G1(x,y)−H1(x,y)},whereG1(x,y)=χK(x,y)+g(x,y)+λη∥x∥1,H1(x,y)=h(x,y)+λ∑i=1n(η|xi|−r(xi)),and g, h are DC components of f.By the definitionψ(t)=η|t|−r(t)∀t∈R,we have(44)∂ψ(t)=η+∂(−r)(t)ift>0,−η−∂(−r)(−t)ift<0,[−η+r′(0),η−r′(0)]ift=0.Following the generic DCA scheme described in Section 2, DCA applied on (43) is given by Algorithm 1below.Instances of Algorithm 1 can be found in our previous works (Le Thi et al., 2008; Le Thi et al., 2009; Ong and Le Thi, 2012) using exponential concave, SCAD or Capped-ℓ1 approximations (see Table 2). Note that for usual sparse inducing functions given in Table 2, this DC decomposition is nothing but that given in Table 1, i.e. φ(t) = η|t|.Now we consider the approximate problem (13) and introduce a DCA scheme that includes all standard algorithms of reweighted-ℓ1 -type for sparse optimization problem (10).The problem (13) can be written as a DC program as follows(45)minx,y,z{F¯r(x,y,z):=G2(x,y,z)−H2(x,y,z)},whereG2(x,y,z)=χΩ1(x,y,z)+g(x,y),H2(x,y,z)=h(x,y)+λ∑i=1n(−r)(zi),and g, h are DC components of f as stated in (11).Assume that (xk, yk, zk) ∈ Ω1 is the current solution at iteration k. DCA applied to DC program (45) updates (xk + 1, yk + 1, zk + 1) ∈ Ω1 via two steps:-Step 1: compute(x¯k,y¯k)∈∂h(xk,yk),andz¯ik∈λ∂(−r)(zik)∀i=1,…,n.Step 2: compute(xk+1,yk+1,zk+1)∈argmin{G2(x,y,z)−〈x¯k,x〉−〈y¯k,y〉−〈z¯k,z〉}=argmin(x,y,z)∈Ω1{g(x,y)−〈x¯k,x〉−〈y¯k,y〉+〈−z¯k,z〉}.Since r is increasing, we have−z¯k≥0. Thus, updating (xk + 1, yk + 1, zk + 1) can be done as follows{(xk+1,yk+1)∈argmin(x,y)∈K{g(x,y)−〈x¯k,x〉−〈y¯k,y〉+〈−z¯k,|x|〉}zik+1=|xik+1|∀i.DCA for solving the problem (13) can be described as in Algorithm 2below.Relation with reweighted-ℓ1procedure.If the function f in (10) is convex, we can choose DC components of f as g = f and h = 0. Then(x¯k,y¯k)=0∀k. In this case, the step 2 in Algorithm 2 becomes(46)(xk+1,yk+1)∈argmin(x,y)∈K{f(x,y)+∑i=1nz¯ik|xi|}.We see that the problem (46) has the form of a ℓ1-regularization problem but with different weights on components of |xi|. So Algorithm 2 iteratively solves the weighted-ℓ1 problem (46) with an update of the weightsz¯ikat each iteration k. The expression of weightsz¯ikaccording to approximation functions are given in Table 3.The update rule (46) covers standard algorithms of reweighted-ℓ1-type for sparse optimization problem (10 ) (see Table 3). Some algorithms such as the two–stage ℓ1(Zhang, 2009) and the adaptive Lasso (Zou, 2006) only run in a few iterations (typically two iterations) and their reasonings bear a heuristic character. The reweighted–ℓ1 algorithm proposed in Candes et al. (2008) lacks of theoretical justification for the convergence.Next, we introduce a slight perturbation of the formulation (12) and develop the third DCA scheme that includes existing algorithms of reweighted-ℓ2-type for sparse optimization problem (10 ).To avoid the singularity at 0 of the function r(t1/2), t ≥ 0, we add ε > 0 and consider the perturbation problem of (12) which is defined by(47){minx,yF˜r(x,y):=f(x,y)+λ∑i=1nr((|xi|2+ϵ)1/2)s.t.(x,y)∈K,ϵ>0.The problem (47) is equivalent to(48)min(x,y,z)∈Ω2F^r(x,y,z):=f(x,y)+λ∑i=1nr((zi+ϵ)1/2),where Ω2 = {(x, y, z): (x, y) ∈ K;  |xi|2 ≤ zi~∀i}. The last problem is a DC program of the form(49)minx,y,z{F^r(x,y,z):=G3(x,y,z)−H3(x,y,z)},whereG3(x,y,z)=χΩ2(x,y,z)+g(x,y),H3(x,y,z)=h(x,y)+λ∑i=1n(−r)((zi+ϵ)1/2),and g, h are DC components of f as stated in (11). Note that, since the functions r and (t + ε)1/2 are concave, increasing on [0, +∞), ( − r)((t + ε)1/2) is a convex function on [0, +∞).Let (xk, yk, zk) ∈ Ω2 be the current solution at iteration k. DCA applied to DC program (49) updates (xk + 1, yk + 1, zk + 1) ∈ Ω2 via two steps:-Step 1: compute(x¯k,y¯k)∈∂h(xk,yk),andz¯ik∈λ2(zik+ϵ)1/2∂(−r)((zik+ϵ)1/2)∀i=1,…,n.Step 2: compute(xk+1,yk+1,zk+1)∈argmin{G3(x,y,z)−〈x¯k,x〉−〈y¯k,y〉−〈z¯k,z〉}=argmin(x,y,z)∈Ω2{g(x,y)−〈x¯k,x〉−〈y¯k,y〉+〈−z¯k,z〉}Since r is increasing, we have−z¯k≥0. Thus, updating (xk + 1, yk + 1, zk + 1) can be done as follows{(xk+1,yk+1)∈argmin(x,y)∈K{g(x,y)−〈x¯k,x〉−〈y¯k,y〉+∑i=1n(−z¯ik)xi2〉}zik+1=|xik+1|2∀i=1,…,n.DCA for solving the problem (48) can be described as in Algorithm 3below.Relation with reweighted-ℓ2procedure.If the function f in (10) is convex, then, as before, we can choose DC components of f as g = f and h = 0. Hence, in the step 1 of Algorithm 3, we have(x¯k,y¯k)=0∀k. In this case, the step 2 in Algorithm 3 becomes(50)(xk+1,yk+1)∈argmin(x,y)∈K{f(x,y)+∑i=1nz¯ikxi2}.Thus, each iteration of Algorithm 3 solves a weighted-ℓ2 optimization problem. The expression of weightsz¯ikaccording to approximation functions are given in Table 4.Note that if ε = 0 then the update rule (50) encompasses standard algorithms of reweighted-ℓ2 type for finding sparse solution (see Table 4). However, when ε = 0 the (right) derivative at 0 of r(t1/2) is not well-defined, that is why we take ε > 0 in our algorithm. Note also that, in LQA and FOCUSS, if at an iteration k one hasxik=0thenxil=0for all l ≥ k, by the way these algorithms may converge prematurely to bad solutions.Algorithm 1 seems to be the most interesting in the sense that it addresses directly the problem (12) and does not need the additional variable z, then the subproblem has less constraints than that in Algorithms 2 and 3. Moreover, the DC decomposition (40) is more suitable since it results, in several cases, in a DC polyhedral program where both DC components are polyhedral convex (for instance, in feature selection in SVM with the approximations rscad, rcap) for which Algorithm 1 enjoys interesting convergence properties.Algorithms 2 and 3 are based on two different formulations of the problem (12). In (13), we have linear constraints |x|i≤ zi, ~i = 1, …, n that lead to the subproblem of weighted–ℓ1 type. Whereas, in (47), quadratic constraints|x|i2≤zi,i=1,…,nresult to the subproblem of weighted-ℓ2 type. With second order terms in subproblems, Algorithm 3 is, in general, more expensive than Algorithms 1 and 2. We also see that Algorithms 1 and 2 possess nicer convergence properties than Algorithm 3. Both Algorithms 1 and 2 have finite convergence when the corresponding DC programs are polyhedral DC. While (47) cannot be a polyhedral DC program because the set Ω2 and the functions r((t + ε)1/2) are not polyhedral convex.To compare the sparsity of solutions given by the algorithms, we consider the subproblems in Algorithms 1, 2, and 3 which have the formmin(x,y)∈K{g(x,y)−〈x¯k,x〉−〈y¯k,y〉+λ∑i=1nν(xi,xik)}where(x¯k,y¯k)∈∂h(xk,yk),ν(xi,xik)={ν1(xi,xik)=η|xi|−sign(xik)(η−z¯ik)xi+CikforAlgorithm1ν2(xi,xik)=z¯ik|xi|+CikforAlgorithm2ν3(xi,xik)=z¯ik2|xik||xi|2+12z¯ik|xik|+CikforAlgorithm3,withz¯ik∈−∂(−r)(|xik|),Cik=r(xik)−z¯ik|xik|and η = r′(0) (Fig. 2).All three functions ν1, ν2 and ν3 attain minimum at 0 and encourage solutions to be zero. Denote byν−′(t)andν+′(t)the left and right derivative at t of ν respectively. We haveν1,−′(0,xik)=−2η+z¯ik,ν2,−′(0,xik)=−z¯ik,ν3,−′(0,xik)=0,ν1,+′(0,xik)=z¯ik,ν2,+′(0,xik)=z¯ik,ν3,+′(0,xik)=0.We also haveη≥z¯ikby the concavity of r on [0, +∞). Observe that if the range[ν−′(0),ν+′(0)]is large, it encourages more sparsity. Intuitively, the valuesν−′(0)andν+′(0)reflect the slope of ν at 0, and if the slope is high, it forces solution to be zero. Here we have[ν3,−′(0,xik),ν3,+′(0,xik)]⊂[ν2,−′(0,xik),ν2,+′(0,xik)]⊂[ν1,−′(0,xik),ν1,+′(0,xik)]. Thus, we expect that Algorithm 1 gives sparser solution than Algorithm 2, and Algorithm 2 gives sparser solution than Algorithm 3.We have proposed three DCA schemes for solving (12) or its equivalent form (13) when r is a concave function on [0, +∞). In this section we remove the assumption that r is concave on [0, +∞) and consider now the general case where r is a DC function satisfying Assumption 1. Hence the problem (12) can be expressed as a DC program (17) for which DCA is applicable. Each iteration of DCA applied on (17) consists of computing- Compute(x¯k,y¯k)∈∂h(xk,yk)andz¯ik∈λ∂ψ(xik)∀i=1,…,n.- Compute (xk + 1, yk + 1) as a solution of the following convex program(51)min(x,y)∈K{g(x,y)−〈x¯k,x〉−〈y¯k,y〉+λ∑i=1nφ(xi)−〈z¯k,x〉}.The new approximation function rPiL is a DC function but not concave on [0, +∞). Hence we apply DCA4 for solving the problem (12) with r = rPiL(52)rPiL=min{1,max{0,θ|t|−1a−1}}={0if|t|≤1θ,θ|t|−1a−1if1θ<|t|<aθ,1otherwise,a>1.DC components of rPiL are given by(53)φPiL(t):=θa−1max{1θ,|t|},ψPiL(t):=θa−1max{aθ,|t|}−1∀t∈R,that are polyhedral convex functions. Then, the problem (12) can be expressed in form of a DC program as follows(54)minx,y{FrPiL(x,y):=G4(x,y)−H4(x,y)},whereG4(x,y)=χK(x,y)+g(x,y)+λ∑i=1nφPiL(xi),H4(x,y)=h(x,y)+λ∑i=1nψPiL(xi),and g, h are DC components of f as stated in (11).At each iteration k, DCA applied to (54) updates (xk + 1, yk + 1) from (xk, yk) via two steps:- Compute(x¯k,y¯k)∈∂h(xk,yk)andz¯ik∈λ∂ψPiL(xik)∀i=1,⋯,n.- Compute (xk + 1, yk + 1) as a solution of the following convex program(55)min(x,y)∈K{g(x,y)−〈x¯k,x〉−〈y¯k,y〉∑i=1n+λθa−1∑i=1nmax{1θ,|xi|}−〈z¯k,x〉}.Calculation ofz¯ik(i=1,…,n)is given by(56)z¯ik={λθa−1ifxik>aθ−λθa−1ifxik<−aθ0otherwise.Furthermore, (55) is equivalent to(57)min(x,y,t)∈Ω3{g(x,y)−〈x¯k,x〉−〈y¯k,y〉+λθa−1∑i=1nti−〈z¯k,x〉},whereΩ3={(x,y,t):(x,y)∈K,1θ≤ti,xi≤ti,−xi≤ti∀i=1,…,n}.According to consistency results, the larger θ is, the better approximate solution would be. However, from a computational point of view, with large values of θ, the approximate problems are difficult and the algorithms converge often to local minimums. We can overcome this bottleneck by using an update procedure for θ. Starting with a chosen value θ0, at each iteration k, we compute (xk + 1, yk + 1) from (xk, yk) by applying the DCA based algorithms with θ = θk. The sequence {θk}kis increasing by θk + 1 = θk+ Δθk. Δθkcan be fixed or updated during the iterations (see Experiment 1 in the next section).In this section we focus on the context of Support Vector Machines learning with two-class linear models. Generally, the problem can be formulated as follows.Given two finite point setsA(with label + 1) andB(with label − 1) inRnrepresented by the matricesA∈RNA×nandB∈RNB×n,respectively, we seek to discriminate these sets by a separating hyperplane (x∈Rn,b∈R)(58)P={w∈Rn:wTx=b}which uses as few features as possible. We adopt the notations introduced in Bradley and Mangasarian (1998) and consider the optimization problem proposed in Bradley and Mangasarian (1998) that takes the form (e∈Rnbeing the vector of ones):(59)minx,b(1−λ)(1NA∥max{0,−Ax+eb+e}∥1+1NB∥max{0,Bx−eb+e}∥1)+λ∥x∥0or equivalently(60)minx,y,ξ,ζ(1−λ)(1NAeTξ+1NBeTζ)+λ∥x∥0s.t.−Ax+eb+e≤ξ,Bx−eb+e≤ζ,ξ≥0,ζ≥0.The nonnegative slack variables ξj~(j = 1, …, NA) represent the errors of classification ofaj∈Awhile ζj~(j = 1, …, NB) represent the errors of classification ofbj∈B. More precisely, each positive value of ξjdetermines the distance between a point aj∈ A (lying on the wrong side of the bounding hyperplane wTx = b + 1 forA)and the hyperplane itself. A similar explanation is given for ζj,Band wTx = b − 1. The first term of the objective function of (60) is the average error of classification, and the second term is the number of nonzero components of the vector x, each of which corresponds to a representative feature. Further, if an element of x is zero, the corresponding feature is removed from the dataset. Here λ is a control parameter of the trade-off between the training error and the number of selected features.Observe that the problem (60) is a special case of (1) where the function f is given by(61)f(x,b,ξ,ζ):=(1−λ)(1NAeTξ+1NBeTζ)and K is a polytope defined by(62)K:={(x,b,ξ,ζ)∈Rn×R×R+NA×R+NB:−Ax+eb+e≤ξ,Bx−eb+e≤ζ}.Then the approximate problem takes the form(63)min{F(x,b,ξ,ζ):=f(x,b,ξ,ζ)+λ∑i=1nr(xi):(x,b,ξ,ζ)∈K},where r is one of the sparsity-inducing functions given in Table 1. This problem is also equivalent to(64)min{F¯(x,b,ξ,ζ,z):=f(x,b,ξ,ζ)+λ∑i=1nr(zi):(x,b,ξ,ζ,z)∈K¯},whereK¯={(x,b,ξ,ζ,z):(x,b,ξ,ζ)∈K,−zi≤xi≤zi∀i=1,…,n}.Note that, since K is a polyhedral convex set, all the resulting approximate problems (63) with approximation functions given in Table 2(except for r = rPiL) are equivalent to the problem (60) in the sense of Corollary 1. More strongly, from Proposition 4, if r = rcap andθ>θ*:=1−λλΔ,where(65)Δ:=maxj=1,…,n{1NA∑i=1NA|Aij|+1NB∑i=1NB|Bij|},then the problems (60) and (63) are equivalent.Here the function f is simply linear, and DC components of f is taken as g = f and h = 0. According to Algorithms 1, 2, 3 and 4, DCA for solving the problem (63) is described briefly as follows.DCA1. For η given in Table 2, let ψ(t) = η|t| − r(t). At each iteration k, DCA1 for solving (63) consists of- Computez¯ik∈λ∂ψ(xik)∀i=1,…,nas given in Table 2.- Compute (xk + 1, bk + 1, ξk + 1, ζk + 1) by solving the linear program(66)min{(1−λ)(1NAeTξ+1NBeTζ)+λη∑i=1nzi−〈z¯k,x〉:(x,b,ξ,ζ,z)∈K¯}.Since f is linear and K is a polyhedral convex set, the first DC component G1 in (43) is polyhedral convex. Therefore, (43) is always a polyhedral DC program. According to the convergence property of polyhedral DC programs, DCA1 applied to (63) generates a sequence {(xk, bk, ξk, ζk)} that converges to a critical point (x*, b*, ξ*, ζ*) after finitely many iterations. Furthermore, if r = rcap and|xi*|≠1θ∀i=1,…,n,the second DC component H1 in (43) is polyhedral convex and differentiable at (x*, b*, ξ*, ζ*). Using the DCA’s convergence property (v) in Section 2, we deduce that (x*, b*, ξ*, ζ*) is a local solution of (63).DCA2. At each iteration k, DCA2 for solving (63) consists of- Computez¯ik∈−λ∂(−r)(|xik|)∀i=1,…,nas given in Table 3.- Compute (xk + 1, bk + 1, ξk + 1, ζk + 1) by solving the linear programmin{(1−λ)(1NAeTξ+1NBeTζ)+〈z¯k,z〉:(x,b,ξ,ζ,z)∈K¯}.Similar to the case of DCA1 mentioned above, (45) is also a polyhedral DC program. Thus, DCA2 applied to (64) generates a sequence {(xk, bk, ξk, ζk, |xk|)} that converges to a critical point (x*, b*, ξ*, ζ*, |x*|) after finitely many iterations. Furthermore, if r = rcap and|xi*|≠1θ∀i=1,…,n,the second DC component H2 in (45) is polyhedral convex and differentiable at (x*, b*, ξ*, ζ*, |x*|). Then (x*, b*, ξ*, ζ*, |x*|) is a local solution of (64).DCA3. At each iteration k, DCA3 for solving (63) consists of- Computez¯ik∈−λ2(|xik|2+ϵ)1/2∂(−r)((|xik|2+ϵ)1/2)∀i=1,…,nas given in Table 4.- Compute (xk + 1, bk + 1, ξk + 1, ζk + 1) by solving the quadratic convex programmin{(1−λ)(1NAeTξ+1NBeTζ)+∑i=1nz¯ikxi2:(x,b,ξ,ζ)∈K}.DCA4. Consider the case r = rPiL. At each iteration k, DCA4 for solving (63) consists of- Computez¯ik∈λ∂ψPiL(xik)∀i=1,…,nvia (56).- Compute (xk + 1, bk + 1, ξk + 1, ζk + 1) by solving the linear programmin{(1−λ)(1NAeTξ+1NBeTζ)+λθa−1∑i=1nti−〈z¯k,x〉},s.t.(x,b,ξ,ζ,t)∈K¯,1θ≤ti∀i=1,…,n.Since the second DC component H4 in (54) is polyhedral convex, (54) is a polyhedral DC program. Thus, DCA4 applied to (63) generates a sequence {(xk, bk, ξk, ζk)} that converges to a critical point (x*, b*, ξ*, ζ*) after finitely many of iterations. Moreover, if|xi*|≠1θ∀i=1,⋯,n,then H4 is differentiable at (x*, b*, ξ*, ζ*). This implies that (x*, b*, ξ*, ζ*) is a local solution of (63).The stopping criterion of our algorithms is given by∥xk+1−xk∥+|bk+1−bk|+∥ξk+1−ξk∥+∥ζk+1−ζk∥≤τ(1+∥xk∥+|bk|+∥ξk∥+∥ζk∥),where τ is a small tolerance.We have seen in Section 5 that the approximate problem using Capped-ℓ1 and SCAD approximations are equivalent to the original problem if the parameter θ is beyond a certain threshold: θ ≥ θ0 (cf. Proposition 4 and Proposition 5). However, the computation of such a value θ0 is in general not available, hence one must take large enough values for θ0. But, as discussed in Section 6.6, a large value of θ makes the approximate problem hard to solve. For the feature selection in SVM, we can compute exactly a θ0 as shown in (65), but it is quite large. Hence we use an updating θ procedure. On the other hand, in the DCA1 scheme, at each iteration, we have to computez¯k∈∂λψ(xk)and when ψ is not differentiable at xk, the choice ofz¯kcan influence on the efficiency of the algorithm. For Capped-ℓ1 approximation, based on the properties of this function we propose a specific way to computez¯k. Below, we describe the updating θ procedure for DCA1 with Capped-ℓ1 approximation.Initialization:Δθ > 0, α0 = +∞, θ0 = 0, k = 0. Let (x0, b0, ξ0, ζ0) be a solution of the linear problem (63).Repeat 1.I={i:0<|xik|<αk},αk+1={max{|xik|:i∈I}ifI≠∅,αkotherwise.2. Computeθk+1=min{θ*,max{1αk+1,θk+Δθ}}. 3. Computez¯k: For i = 1, …, n-If|xik|<αk+1,z¯ik=0.If|xik|>αk+1,z¯ik=sign(xik)λθ.If|xik|=αk+1,computeFi−(resp.Fi+) the left (resp. right) derivative of the function u(x, b) w.r.t. the variable xiatxik,whereu(x,b)=(1−λ)(1NA∥max{0,−Ax+eb+e}∥1+1NB∥max{0,Bx−eb+e}∥1)+λ∑j=1nr(xj).Thenz¯ik={sign(xik)λθk+1ifxik(Fi−+Fi+)<00otherwise.4. Solve the linear problem (66) with η = θk + 1 to obtain (xk + 1, bk + 1, ξk + 1, ζk + 1). 5. k = k + 1.Until: Convergence of {xk, bk, ξk, ζk}.In the above procedure, the computation ofz¯kis slightly different from formula given in Table 2. When|xik|=αk+1,∂r(xik)is an interval. Taking into account information of derivative of u w.r.t. the variable xiatxikhelps us judge which between two extreme values of∂r(xik)may give better decrease of algorithm.At each iteration, the value of θ increases at least Δθ > 0 as long as it does not exceed θ* – the value from which the problems (60) and (63) are equivalent. Moreover, we know that for each fixed θ, DCA1 has finite convergence. Hence, the above procedure also possesses finite convergence property.If F(xk + 1, bk + 1, ξk + 1, ζk + 1) = F(xk, bk, ξk, ζk) then (xk, bk, ξk, ζk) is a critical point of (63) with r = rcap and θ = θk + 1. In addition, if αk + 1 = αk, which means that|xik|≥αk≥1θkfor any i ∈ supp(xk), then (xk, bk, ξk, ζk) is a critical point of (63) for all θ ≥ θk + 1.The aim of our experiments is to give a fair comparison of DCA’s versions to identify the best one. For this purpose we perform two experiments to identify(i)the best DCA scheme among three proposed DCA1, DCA2 and DCA3;the best among six existing/proposed approximations.It is worth noting that comparative results between DCA based algorithms and several existing approaches have been presented in the previous works using DCA for feature selection in SVM. More precisely, the FSV algorithm in Bradley and Mangasarian (1998) (which is DCA2 with the exponential approximation) is the best with respect to SVM without regulation (Bennett and Mangasarian, 1992) (named RLP), ℓ2-SVM (Cortes and Vapnik, 1995), ℓ1-SVM and ℓ∞-SVM (Bradley and Mangasarian, 1998). In Weston et al. (2003) the algorithm based on Franke and Wolfe method and the logarithm approximation (this is in fact DCA2 with the logarithm approximation) is better than RFE SVM (Guyon, Weston, Barnhill, and Vapnik, 2002), CORR SVM (Weston et al., 2003), R2W2 SVM (Weston, Mukherjee, Chapelle, Pontil, Poggio, and Vapnik, 2001), FSV (Bradley and Mangasarian, 1998). In Newmann et al. (2005) the authors considered the two models using ℓ2 − ℓ0-norm and ℓ2 − ℓ1-norm with the exponential approximation and proposed a DCA scheme for the ℓ2 − ℓ0-norm model. Their computational experiments indicated the superiority of DCA for ℓ2 - ℓ0-norm model with respect to RLP (Bennett and Mangasarian, 1992), ℓ2-SVM (Cortes and Vapnik, 1995), FSV (Bradley and Mangasarian, 1998), and a SVM based filter method Heiler, Cremers, and Schnörr (2001). At last, according to comparative numerical results provided in Le Thi et al. (2008), the DCA algorithm (DCA1 with the exponential approximation) outperforms RLP (Bennett and Mangasarian, 1992), ℓ2-SVM (Cortes and Vapnik, 1995), ℓ1-SVM and ℓ∞-SVM and FSV. Thus, in the present work a comparison between DCA’s versions and the “other approaches” above mentioned is not helpful. Meanwhile, in the second experiment dealing with the efficiency of approximations, we present also the numerical results of the ℓ1-SVM algorithm (the ℓ1-norm is used to approximate the ℓ0-norm), the best known and widely used convex approximation approach for feature selection in SVM.Numerical experiments were performed on several real-word datasets taken from well-known UCI data repository and from challenging feature-selection problems of the NIPS 2003 datasets. In Table 5, the number of features, the number of points in training and test set of each dataset are given. The full description of each dataset can be found on the web site of UCI repository and NIPS 2003.All algorithms were implemented in the Visual C++ 2008, and performed on a PC Intel i5 CPU650, 3.2  GHz of 4GB RAM. CPLEX 12.2 was used for solving linear/quadratic programs. We stop all algorithms with the tolerance ε = 10−5. The non-zero elements of x are determined according to whether |xi| exceeds a small threshold (10−5).A fair numerical comparison to study the question (i) should be based on the same approximation, and the one to study the question (ii) should be based on the same DCA scheme.For the comparison of algorithms, we are interested in the accuracy (PWCO – Percentage of Well Classified Objects) and the sparsity of obtained solution as well as the rapidity of the algorithms. PWCO1 (resp. PWCO2) denotes the PWCO on training set (resp. test set). The sparsity of solution is determined by the number (and percentage) of selected features (SF) while the rapidity of algorithms is measured by the CPU time in seconds (s).In this experiment, we study the effectiveness of the three proposed DCA schemes DCA1, DCA2 and DCA3 for a same approximation. From theoretical results in Section 5 we chose Capped-ℓ1 approximation for this experiment. For each dataset, the same value of λ is used for all algorithms. We set λ = 0.1 for the first three datasets (Ionosphere, WPBC(24), WPBC(60)) while λ = 0.001 is used for five large datasets (Adv, Arcene, Breast, Gisette, Leukemia). To choose a suitable value of θ for each algorithm DCA1, DCA2 and DCA3, we perform them by 10 folds cross-validation procedure on the set {0.001, 0.005, 0.01, 0.1, 0.5, 1, 2, 3, 5, 10, 20, 50, 100, 500} and then take the value corresponding to the best results. Once θ is chosen (its value is given in Table 6), we perform these algorithms 10 times from 10 random starting solutions and report, in the columns 3–5 of Table 6, the mean and standard deviation of the accuracy, the sparsity of obtained solutions and CPU time of the algorithm.We are also interested on the efficiency of Updating θ procedure. For this purpose, we compare two versions of DCA1 – with and without Updating θ procedure (in case of Capped-ℓ1 approximation). For a fair comparison, we first run DCA1 with Updating θ procedure and then perform DCA1 with the fixed value θ* which is the last value of θ when the Updating θ procedure stops. Computational results are reported in the columns 6 (DCA1 with fixed θ) and 7 (DCA1 with Updating θ procedure) of Table 6.To evaluate the globality of the DCA based algorithms we use CPLEX 12.2 for globally solving the exact formulation problem (5.1.1) via exact penalty techniques (Mixed 0-1 linear programming problem) and report the results in the last column of Table 6.Bold values in the result tables correspond to best results for each data instance.Comments on numerical results•Comparison between DCA1, DCA2 and DCA3 (columns 3–5)•Concerning the correctness, DCA1 furnishes the best solution out of the three algorithms for all datasets (with an important gain of 6.9 percent on dataset WPBC(24)). DCA2 and DCA3 are comparable in terms of correctness.As for the sparsity of solution, all the three DCA schemes reduce considerably the number of selected features (up to 99 percent on large datasets such as Arcene, Breast, Leukemia, ...). Moreover, DCA1 gives better results than DCA2/DCA3 on six out of seven datasets.In terms of CPU Time, DCA1 and DCA2 are faster than DCA3. This is natural, since at each iteration, the first two algorithms only require solving one linear program while DCA3 has to solve one convex quadratic program. DCA1 is somehow a bit faster than DCA2 on five out of seven datasets.Overall, we see that DCA1 is better than DCA2 and DCA3 on all the three evaluation criteria. Hence, it seems to be that the first DCA scheme is more appropriate than the other two for Capped-ℓ1 approximation.DCA1 with and without Updating θ procedure (columns 3, 6 and 7):•For all datasets, Updating θ procedure gives a better solution (on both accuracy and sparsity) than DCA1 with θ = θ*.Except for dataset WPBC(24), Updating θ procedure is better than DCA1 with θ chosen by 10 folds cross-validation in terms of sparsity of solution. As for accuracy, the two algorithms are comparable.The choice of the value of θ defining the approximation function is very important. Indeed, the results given in columns 3 and 6 are far different, due to the fact that, the value of θ chosen by 10 folds cross-validation is much more smaller than θ*. These results confirm our analysis in Section 6.6 above: while the approximate function would be better with larger values of θ, the approximate problems become more difficult and it can happen that the obtained solutions are worse when θ is quite large. To overcome this “contradiction” between theoretical and computational aspects, the proposed Updating θ procedure seems to be efficient.Comparison between DCA based algorithms and CPLEX for solving the original problem (5.1.1)•For Ionosphere and WPBC(60), Updating θ procedure for Capped-ℓ1 gives exactly the same accuracy and the same number of selected features as CPLEX. It means that Updating θ procedure reaches the global solution for those two datasets. For WPBC(24), the two obtained solutions are slightly different (same accuracy on training set and seven selected features for CPLEX instead of eight for Updating θ procedure).For large datasets, CPLEX can not furnish a solution with a CPU Time limited to 3600  s while DCA based algorithms give a good solution in a short time.In the second experiment, we study the effectiveness of different approximations of ℓ0. We use DCA1 for all approximations except PiL for which DCA4 is applied (cf. Section 6.5). We also present the results of ℓ1-SVM algorithm in which ℓ1 is used to approximate ℓ0.In this experiment, for the trade-off parameter λ, we used the following set of candidate values {0.001, 0.002, 0.003, 0.004, 0.05, 0.1, 0.25, 0.4, 0.7, 0.9}. The value of parameter θ is chosen in the set {0.001, 0.005, 0.01, 0.1, 0.5, 1, 2, 3, 5, 10, 20, 50, 100, 500}. The second parameter a of SCAD approximation is taken from {1, 2, 3, 5, 10, 20, 30, 50, 100}. For each algorithm, we firstly perform a 10-fold cross-validation to determine the best set of parameter values. In the second step, we run each algorithm, with the chosen set of parameter values in Step 1, 10 times from 10 starting random points and report the mean and standard deviation of each evaluation criterion. The comparative results are reported in Table 7.We observe, among DCA’s versions, that:•In terms of sparsity of solution, the quality of all approximations are comparable. All the algorithms reduce considerably the number of selected features, especially for five large datasets (Adv, Arcene, Breast, Gisette, Leukemia). For Breast dataset, our algorithms select only about thirty features out of 24, 481 while preserving very good accuracy (up to 98.7 percent correctness on train set).Capped-ℓ1 is the best in terms of accuracy: it gives best accuracy on all train sets and four out of seven test sets. The quality of other approximations are comparable.The CPU time of all the algorithms is quite small: less than 34  s (except for Gisette, CPU time of DCAs varies from 72 to 102  s).Comparing DCA based algorithms with ℓ1-SVM, not surprisingly, DCA is much better than ℓ1-SVM in terms of both sparsity and accuracy, and ℓ1-SVM is the fastest algorithm (it solves one linear program). The results show that the ℓ1 approach is not efficient to deal with sparsity.

@&#CONCLUSIONS@&#
