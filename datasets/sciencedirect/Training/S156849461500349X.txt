@&#MAIN-TITLE@&#
A novel hybrid learning algorithm for full Bayesian approach of artificial neural networks

@&#HIGHLIGHTS@&#
A novel Monte Carlo algorithm is proposed to train Bayesian neural networks.This algorithm is based on the full Bayesian approach of artificial neural networks.Monte Carlo methods are integrated with GAs and fuzzy membership functions.Proposed algorithm is applied to time series and regression analysis in the context of BNNs.Proposed approach is superior to traditional training methods in terms of estimation performance.

@&#KEYPHRASES@&#
Bayesian neural networks,Bayesian learning,Hierarchical Bayesian models,Genetic algorithms,Markov chain Monte Carlo,Hybrid Monte Carlo,

@&#ABSTRACT@&#
The Bayesian neural networks are useful tools to estimate the functional structure in the nonlinear systems. However, they suffer from some complicated problems such as controlling the model complexity, the training time, the efficient parameter estimation, the random walk, and the stuck in the local optima in the high-dimensional parameter cases. In this paper, to alleviate these mentioned problems, a novel hybrid Bayesian learning procedure is proposed. This approach is based on the full Bayesian learning, and integrates Markov chain Monte Carlo procedures with genetic algorithms and the fuzzy membership functions. In the application sections, to examine the performance of proposed approach, nonlinear time series and regression analysis are handled separately, and it is compared with the traditional training techniques in terms of their estimation and prediction abilities.

@&#INTRODUCTION@&#
Within Bayesian perspective, it is assumed that uncertainty of any quantity of interest can be expressed and measured by probabilistic distributions. This framework provides a natural way to estimate the functional structure in the nonlinear systems. For this reason, the Bayesian learning is mostly treated in the regression, the time series, the classification and the density estimation applications of the artificial neural networks (ANNs). Bayesian learning in the ANNs are typically based on Gaussian approximation, ensemble learning and Markov chain Monte Carlo (MCMC) simulations known as full Bayesian approach. For ANNs, Gaussian approximation was introduced by Buntine and Weigend [1] and MacKay [2] in which one well-established procedure for approximating the integrals over parameter space, known as Laplace's method. This approach is to model the posterior distribution by a Gaussian distribution, centered locally at a mode of posterior distribution of parameters [2]. The ensemble learning was introduced by Hinton and Camp [3] in which the approximating distribution is fitted globally by minimizing a Kullback–Leibler divergence rather than locally. In the context of Full Bayes approach, Neal [4] introduced advanced Bayesian simulation methods in which MCMC simulations are used to generate samples from the posterior distribution. However, MCMC techniques can be computationally expensive, and also suffer from assessing the convergence. For this reason, Neal [4] integrated Bayesian learning with Hybrid Monte Carlo (HMC) method introduced by Duane et al. [5] to overcome the mentioned shortcomings. Afterwards, the Bayesian applications to ANNs was reviewed thoroughly in [6–8].In the literature, there are the remarkable studies that deal with the specific problems related to ANNs from Bayesian perspective. For instances, Insua and Müller [9], Marrs [10], Holmes and Mallick [11] worked on the issue of selecting the number of hidden neurons with the growing and the pruning algorithms for the dimensionality problem in the ANNs. In these studies, they applied the reversible jump MCMC algorithm introduced by Green [12], Richardson and Green [13]. Freitas [14] incorporated the particle filters and the sequential Monte Carlo (MC) methods in the BNNs. Liang and Wong [15] proposed to the evolutionary MC algorithm which samples the parameters in the ANNs from the Boltzmann distribution using the mutation, the crossover and the exchange operations defined in the Genetic Algorithms (GAs). Chua and Goh [16] used the Gaussian approach for the multivariate modeling in the ANNs. They used the stochastic gradient descent algorithm integrated with the evolutionary operators to produce the parameters in the ANNs. Liang [17] and Xie et al. [18] used the truncated Poison priors to determine the neuron numbers in the hidden layers, and estimated the parameters in the ANNs via the evolutionary MC algorithms proposed by Liang and Wong [15]. Lampinen and Vehtari [19], Vanhatalo and Vehtari [20] improved a hybrid and reversible MCMC algorithm based on Neal [4]. Marwala [21] adapted to mutation and crossover operators defined in GAs into Bayesian learning, and estimated the parameters using a hybrid learning algorithm. Mirikitani [22] proposed a probabilistic approach to recursive the second-order training of recurrent neural networks for improved time-series modeling in which the regularization hyperparameters leads to better generalization, and stable numerical performance. Goodrich [23] developed a powerful methodology for estimating the full residual uncertainty in the network weights and making predictions by using a modified Jeffery's prior combined with a Metropolis MCMC method. Martens and Sutskever [24] resolved the long-outstanding problem of how to effectively train recurrent neural networks on complex and difficult sequence modeling problems which may contain the long-term data dependencies. Niu et al. [25] adapted Hybrid MC, proposed by Neal [4] and Duane et al. [5], to Gaussian approximation of BNNs. Beam et al. [26] examined Hybrid Monte Carlo proposed by Neal [4] in the context of full Bayesian approach, and then they compared this procedure with the existing methods using artificial and real data sets. Kocadağlı [27] integrated the hierarchical Bayesian learning with GAs and the fuzzy numbers, and then he proposed Genetic MC algorithm in the context of full Bayesian approach. Kocadağlı and Aşıkgil [28] adapted Genetic MC, proposed by Kocadağlı [27], to Gaussian approximation of BNNs.In the model building, main difficulty is generally controlling the model complexity. During training ANNs, measuring the model complexity are mostly overlooked, since it is computationally very expensive. In the Bayesian learning, this issue can be handled in a natural and consistent way. However, Bayesian learning requires evaluating the high-dimensional integrals. Although these high-dimensional integrals can be solved by using the analytical integration, the approximation methods and the numerical integration, the analysts suffer from non-Gaussianity, nonlinearity and non-stationarity involved in the real-world problems that prevent using the analytical integration [29]. In this case, MC methods might provide better estimates than the approximate methods in context of BNNs. In spite of their superior advantage, MC methods suffer from the time consuming in addition to the efficient parameter estimation, the convergence, the random walk and the stuck in local optima in the high dimensional parameter cases. For this reason, the hybrid approaches are mostly preferred to overcome these problems. In these approaches, MC techniques are integrated with the gradient-based optimization algorithms, the simulated annealing method or the evolutionary algorithms. The hybrid methods based on gradient algorithms are capable of searching the regions with high density using the gradient information. However, gradient-based algorithms might not explore freely the high dimensional parameter spaces including many local optima. Besides, adjusting the control parameters or Hessian matrix evaluations in these algorithms causes a computational burden. Besides, this kind of optimization algorithms is not suitable for the optimization problems included non-derivatives functions as well. Some shortcomings of these algorithms are discussed in [7,30–32].Instead of the gradient based algorithms, integrating GAs with MCMC methods provides much more efficient approaches that overcome the mentioned shortcomings in context of training ANNs because they do not require the gradient information and make the parallel searching through the high dimensional parameter spaces to achieve the global solutions rather than local ones. GAs developed by John Holland in 1970s are heuristic optimization methods based on concepts of natural evolution, and belongs to the larger class of evolutionary algorithms [33]. They consist of the artificial operators such as selection, mutation, crossover and migration involved in the natural evaluation. In the treatments of GAs, different kinds of uncertainties arise inherently. For instance, the possibilistic (or linguistic) and the probabilistic uncertainties appear simultaneously [27]. The possibilistic uncertainty concept is first introduced by Zadeh [34]. According to Zadeh [34], this kind of uncertainty deals with problems in which the source of imprecision is the absence of sharply defined criteria of class membership rather than the presence of random variables. In this case, the fuzzy membership functions provide a natural way to intuitively make the plausible semantic description of imprecise properties of data used in the natural system [35].In this paper, a novel hybrid learning algorithm is introduced for the hierarchal full Bayesian approach. This algorithm called as Genetic MC integrates GAs with Gibbs sampling, Metropolis–Hastings and Simulated Annealing methods. By means of this hybrid learning framework, Genetic MC is capable of overcoming some complicated problems such as efficient parameter estimation, model complexity, random walk, convergence and stuck in the local optima in the high-dimensional parameter spaces. In spite of incorporating many complicated concepts in its structure, Genetic MC can be implemented to the nonlinear regression and time series analyses easily, and then it allows estimating the robust models in context of training BNNs. Essentially, this novel approach is based on the hybrid learning procedures proposed by Kocadağlı [27], Kocadağlı and Asikgil [28] in which GAs is integrated with MCMC methods for Gaussian approach of BNNs. However, in this study, Genetic MC is adapted to the full Bayesian approach instead of Gaussian approach. Besides, although this procedure has some similarities with the approaches developed by Liang and Wong [15] and Marwala [21], it consists of different procedure in terms of using evolutionary operators and MCMC methods. Specifically, Marwala's approach [21] creates only one parameter vector (child) in the any generation of GAs, and then this candidate parameter vector is compared with that held in the previous iteration of Metropolis–Hastings algorithm in terms of their performance over the fitting functions. However, this approach conflicts with diversity principle of GAs because the diversity in the population should be accomplished by keeping the members having different features in the selection process [27]. In Liang and Wong [15], GAs is integrated with Simulated Annealing method in context of MCMC procedure, and the system parameters are produced by means of different temperature values. Basically, this approach is different from Genetic MC approach in context of the estimation procedure and designing of the hierarchal full Bayesian learning.In order to introduce Genetic MC thoroughly, this paper is organized as following. Section 3 includes an overview of a simple feed-forward ANN, the different types of error functions and the model complexity concepts. In Section 4, the framework of full Bayesian approach is given in context of BNNs. In Section 5, a novel Bayesian learning algorithm for full Bayesian approach is introduced in detail. In Section 6, to examine the implementations of the proposed algorithm, the nonlinear time series and regression analysis are handled, separately and then it is compared with the traditional training procedures for ANNs and the Gaussian approximation of BNNs in terms of their model estimation and prediction performances over a benchmark and an artificial data set. Sections 7 and 8 cover the results and conclusions of study, respectively.In this paper, as seen in Fig. 1, the feed-forward ANNs with one hidden layer are used due to their simplicity and sufficient performance over the related problems in the application section. According to network structure in Fig. 1, the mathematical relation between inputs, neurons of hidden layer and tth output for ith observation can be formulated as follow:(1)ft(xi,θ)=btII+∑k=1pwtkIIAk(wkIxi+bkI)t=1,2,…,rwhere yi=[y1iy2i⋯ yri] and xi=[x1ix2i⋯ xmi] are target and input vectors of ith observation, respectively;wkI=[w1kIw2kI⋯wmkI]is a row vector that include weights among all inputs and kth neuron in the hidden layer;wtII=[w1tIIw2tII⋯wptII]is a row vector that include weights among all neurons and tth output;bkIandbkIIare biases for kth neuron and tth output, respectively;θ=wkI,wkII,bkI,bkIIis a parameter vector that covers all weights and biases; i=1, 2, …, N; j=1, 2, …, m; k=1, 2, …, p and t=1, 2, …, r. In the hidden layer, the activation functionAk(wkxi+bkI)provides the nonlinearity to the ANN structure, and scales its received inputs to its output range. In the hidden layers, there is able to use the different kinds of activation functions accordance with the data and problem type.In order to reduce the errors between the actual output and the target output values at the desired satisfactory level, the functional structure in Eq. (1) can be estimated by modifying the connection weights and biases. To obtain an estimator of the regression functionfˆt(x,θˆ)by training ANNs, one of the well-known approaches is minimizing the following mean square empirical risk:(2)Re[fˆt(x,θˆ)]=1N∑i=1N(yti−fˆt(xi,θˆ))2where ytiandfˆt(xi,θˆ)are tth target and its estimation for the ith observation, respectively. However, using this empirical risk brings about two types of errors, namely approximation and estimation errors. There is a trade-off between these errors well known as the bias/variance tradeoff which should be balanced for an acceptable generalization performance [27,36]. Therefore, the only ways to reduce the bias and variance error terms simultaneously are to either increase the number of data or to model the noise characteristics and incorporate a priori knowledge about the form of the estimator [14]. Bayesian learning ensures this approach inherently, because it provides a probabilistic knowledge about related data and penalizes the complex models automatically.To control the bias/variance tradeoff, another approach is the regularization which allows estimating the regression function that is simultaneously close to the data and smooth. In the regularization approach, instead of the empirical modeling error, its extension form can be used as follow:(3)Rr[fˆ(x,θˆ)]=1N∑i=1N(yti−fˆt(xi,θˆ))2+νΩwhere the function Ω penalizes the excessive model complexity, and v is a positive parameter that balances the tradeoff between smoothness and data approximation. Weight decay and Laplace function approaches are well-known for function Ω [7,28]. Essentially, the weight decay is given as a natural interpretation in the Gaussian approximation of Bayesian learning introduced by Mackay [2].In the context of the controlling the model complexity, the other approaches are early stopping, training with noise, mixtures of networks, growing and pruning techniques and using information criteria as risk functions. The implementation of these approaches to ANNs is discussed in [37–42].Let us consider a multivariate regression problem with the inputs (independent variables) and the targets (dependent variables) in the context of BNNs. To model this problem using the full Bayesian approach, it can be assumed that the distribution of real valued target yi,t(ith observation of tth target) in case given the inputs xiand the parameter vector is the independent Gaussian distribution with the means corresponding to the network outputs, and with the standard deviation given by the hyperparameters σtcorresponding to the noise levels for target. Thus, the probability density for a target given the associated inputs and the network parameters can be constituted as follow:(4)p(yt,ixi,θ)=1(2π)1/2τt−1/2exp−τt2yt,i−fˆt(xi,θ)2whereτt=σt−2is known as the precision. For the heteroscedasticity problem, alternatively it can be designed that each observation of a target vector has its own standard deviationτt,i=σt,i−2. To measure the variance of targets, it is possible to use both the standard deviation and the precisions. For instances, while Neal [4,8] preferred the gamma distribution for the precisions, Lord et al. [18], Vanhatalo and Vehtari [19], and Lampinen and Vehtari [20] used the inverse gamma distribution for the standard deviations. In this paper, the precisions are preferred as the gamma distribution with means of μtand shape parameter αNoise:(5)p(τt,iμt)=(αNoise/2μt)αNoise/2Γ(αNoise/2)τt,iαNoise/2−1exp−τt,iαNoise2μtWhen the inputs, parameters and common precision τtfor all observations are given, because of independency of all observations of the tth target in the training set, the conditional distribution of tth target can be constituted as follow:(6)p(ytx1:N,θ,τt)=1(2π)N/2τt−N/2exp−τt2∑i=1Nyt,i−fˆt(xi,θ)2whereτt=σt−2is the common noise precision for all observations of tth target. Thus, the conditional distribution of common precision τtis given by(7)p(τtx1:N,yt,1:N,θ)∝τt(αNoise+N)/2−1exp−τt2αNoiseμt+∑i=1Nyt,i−fˆt(xi,θ)2Alternatively, the conditional distribution of tth target can be used for heteroscedasticity problem as follow:(8)p(ytx1:N,θ,τt,i)=∏i=1N1(2π)1/2τt,i−1/2exp−12τt,iyt,i−fˆt(xi,θ)2where the precisions of single cases are the independent each other, and defined as(9)p(τt,ixi,yi,θ)∝τtαNoise−1/2exp−12τt,iαNoiseμt+yt,i−fˆt(xi,θ)2Here, all the precisions for the heteroskedastic situation can be given as(10)p(τt,1,…,τt,Nx1:N,yt,1:N,θ)∝∏i=1NτtαNoise−1/2exp−12τt,iαNoiseμt+yt,i−fˆt(xi,θ)2In the analysis, if only a single precision τtin Eq. (7) is preferred for all target values, either higher level hyperparameters linking τtshould be defined or alternatively a single τtshould have a t-distribution rather than a Gaussian, since this implementation will ensure the robustness in terms of estimation performance [8,19,20,27]. In this study, to capture the robustness, the heteroskedastic approach is preferred to model the noise precision.In the context of full Bayesian approach, another issue is how to define the hyperparameters for the prior distributions of parameters in the BNNs. In order to control the variances of parameters (included the weights or biases) in a certain group, a common hyperparameter can be considered. For instance, it is possible to define a group that consists of the weights (or the biases) defined on all connections from a particular unit to other units. Specifically, such a group can be constituted as a vectorwkI=[w1kIw2kI…wmkI]which includes the weights defined from all inputs to kth neuron in the hidden layer with respect to the network design given in Fig. 1. Thus, the distributions of this weight group can be given as(11)p(w1kIw2kI…wmkIτw)=(2π)−m/2τwm/2exp−τw∑j=1m(wjkI)22where it is assumed that all weights are independent, and they have Gaussian distributions with mean zero and standard deviation σw. Alternatively, such a particular weight group can be constituted as a vectorwjI=[wj1Iwj2I…wjpI]which includes the weights defined from the input j to the all neurons in the hidden layer, and its distribution can be given as follow [4,8]:(12)p(wj1Iwj2I…wjpIτw)=(2π)−p/2τwp/2exp−τw∑k=1p(wjkI)22In this paper, the distributions of weight groups are defined as the form given in Eq. (12), because this approach allows evaluating the impact of any input over targets. The precision of a weight group (or the bias group) is given as a Gamma distribution with mean ωwand shape parameter specified by αwas follow:(13)p(τw)=(αw/2ωw)αw/2Γ(αw/2)τwαw/2−1exp−τwαw2ωwHere, if there is no the hierarchical structure, and then the values of ωwand αwcan be fixed; otherwise, the hyper-prior for hyperparameter ωwshould be defined. The prior for τwis conjugate to the distribution defined forwjI. Thus, the conditional distribution for the precision τwgivenwjIis also the gamma form:(14)p(τwwj1Iwj2I…wjpI)∝τwαw/2−1exp−τwαw2ωwτwp/2exp−τw∑k=1p(wjkI)22=τwαw+p/2−1exp−τwαwωw+∑k=1p(wjkI)2/2From Eq. (14), the prior for τwcan be interpreted as specifying imaginary parameter values αwwhose average squared magnitude is 1/ωw. Here, it is well-known that the small values of αwcarries out uninformative (vague) priors for τw[8,19,20,27]. The value τwcan be drawn from the conditional distribution in Eq. (14) using Gibbs sampling updates when the vectorwjIis given. In this study, the hierarchy on the network parameter and hyperparameters is defined as follows:(15)p(τ1)=(α0/2ω0)α0/2Γ(α0/2)τ1α0/2−1exp−τ1α02ω0(Top-level)(16)p(τwτ1)=(α1/2τ1)αw/2Γ(α1/2)τwαw/2−1exp−τwα12τ1(Middle-level)(17)p(wjkIτw)=(2π)−1/2τw1/2exp−τw(wjkI)22(Low-level)where α0 and ω0 in Eq. (14) are the fixed shape parameter and mean of precision τ1; α1 and τ1 in Eq. (15) are the shape parameter and mean of τw, respectively, andwjkIthat has Gaussian distribution with mean zero and precision τwis the weight value between jth input and kth neuron in the hidden layer. In this framework, α0 and ω0 should be fixed in the top-level of hierarchy. Conceptually, this framework requires another hyperparameter for every parameter and hyperparameter defined in the lower levels. However the hyperparameters in the lowest level are not explicitly represented because they depend on those defined in the higher level. In this hierarchy, the mid-level hyperparameters control the distribution of group parameters defined in the low-level. Similarly the high-level hyperparameters control the distribution of mid-level hyperparameters.Once all the distribution forms are constructed for parameters, hyperparameters and noise level on data; the joint posterior distribution can be defined easily. If the normalization factor is removed from the joint posterior distribution, then it can be rearranged as follow:(18)p(θ,τNoise,τθ|D)∝p(D|θ,τNoise,τθ)p(θ,τNoise,τθ)(19)=p(D|θ,τNoise)p(θτNoise,τθ)p(τNoise,τθ)(20)=p(D|θ,τNoise)p(θτθ)p(τNoise)p(τθ)whereθ=(wI,wII,bI,bII),τθ=(τwI,τwII,τbI,τbII),p(τθ)=p(τwI)p(τwII)p(τbI)p(τbII),D=(x1:N, y1:N) andp(θτθ)=p(wIτwI)p(wIIτwII)p(bIτbI)p(bIIτbII). In detail, p(D|θ, τNoise) andp(θ,τNoise,τw,τb)in Eq. (18) are the likelihood and the prior, respectively. For the likelihood in Eq. (18), data are independent of the precision vector of parameters; the parameter vector θ (included weights and biases) is independent of the noise precision in Eq. (19), and the precisions of noise and parameters are independent of each other in Eq. (18). Here, if the hierarchy structure has three levels, p(τθ) in Eq. (20) corresponds top(τθτ0)=p(τwIτwI0)p(τwIIτwIι0)p(τbIτbI0)p(τbIIτbII0)whereτ0=τwI0,τwIι0,τbI0,τbII0is a set of the highest level hyperparameters. Similarly, p(τNoise) in Eq. (20) corresponds top(τNoiseτNoise0)whereτNoise0is the highest level hyperparameter.In this section, a novel hybrid Bayesian learning algorithm called as Genetic MC is introduced. The purpose of developing a novel Bayesian learning algorithm is to control the model complexity, and estimate the parameters of BNNs efficiently. This approach integrates GAs with MCMC procedures composed of the Simulated Annealing, Metropolis–Hastings method and Gibbs Sampling. By means of MCMC procedures, the complex integrals are approximated via drawing samples from the joint probability distribution of all the model parameters and hyperparameters. In this context, the prediction of output for given new input vectorxN+1newcan be made by(21)yˆk,N+1=E(yk,N+1|x1:N+1,y1:N)=∫fˆk(θ,x1:N+1)p(θ|x1:N,y1:N)dθThe integral in Eq. (21) is the expectation of posterior predictive distribution, and this is approximated using a sample of parameter vectors drawn from the posterior distribution of parameters during the training of BNNs as follow:(22)yˆk,N+1≈1T−B∑iter=B+1Tfˆt(xN+1,θiter)where T is the total number of iterations in the training, and B is the number of iterations in the burn-in process. Actually, the training process is computationally very expensive due to the excessive number of parameters, but predictions for the new data can be calculated quickly using (T−B) out of parameter vectors exception of B iterations in the burn-in process.To construct the framework of MCMC procedure, firstly a specific hierarchical structure for the weights (wI) in the first layer, called Automatic Relevance Determination (ARD) [8], is defined. By means of ARD, common precision hyperparameters are assigned to each weight group connected with the same input (j=1, 2, …, m). Essentially, this approach allows providing different variances for all the weight groups. Thus, it can be expected that the weight groups including very small weights carry out smaller variances, since they are not relevant so much to estimating the output of network [8,19,20,27]. The other steps of the sampling procedure are summarized as follows:•Set the hierarchical structure for priors of parameters θ and precisions τθ:These hierarchical structures on the weights and biases are constructed similar to the scheme given in Eqs. (15)–(17).Draw the precision of parameters τθusing its conditional using Gibbs Sampling. For instance, the precisions of weight vectors (or biases) can be produced from its conditionals in Eq. (14) when the weight vector hold in the previous iteration is given:(26)τw∼p(τwwj1wj2…wjp)where the vector(wj1wj2…wjp)covers the weights defined from jth input to all the neurons in the hidden layer. The precisions of all the weights and biases groups in the network can be produced this way.Define the individual precisions for each case of targets in Eq. (9) for the heteroscedasticity problem:(27)τ1∼Gam(α1,ω1)(28)τt,iτ1∼Gam(αNoise,ωNoise)Draw the noise precisions of each case fromp(τt,1,…,τt,Nx1:N,yt,1:N,θ)defined in Eq. (10) using Gibbs Sampling.Draw the weights and biases from joint posterior distribution p(θ, τNoise, τθ|D) in Eq. (20) by means of Hybrid Monte Carlo.In order to construct Genetic MC, firstly the potential energy function must be formulated. This function is prompted to generate the parameter vectors from the joint posterior distribution, and it corresponds to the negative logarithm of the joint posterior distribution in Eq. (20) as follow [7,8,25–27]:(29)L(θ)=−logp(θ,τNoise,τθ|D)=−logp(D|θ,τNoise)−logp(θτθ)−F(τ)where F(τ) is a function of hyperparameters that are updated via Gibbs sampling in each successive iteration in the training procedure. If desired, F(τ) can be disregarded from energy function because it has no direct impact on the parameters. By updating the energy function, it is possible to move the regions where the joint posterior distribution in Eq. (20) has the high densities. Essentially, the canonical distribution for this energy function is proportional to exp (−L(θ)), hence it produces the posterior probability density for the parameters given the hyperparameters. In order to find the efficient values of parameters in the energy function, Neal [8] proposed the Hybrid MC based on the stochastic dynamics method introduced in [5]. In this approach, the parameters are determined using the stochastic dynamics method integrated with Gibbs sampling and the classic back-propagation method. However, this approach suffers from determining the amounts of change in the parameters because these amounts are evaluated by gradient information or heuristic step-size as discussed in [8]. In addition, in the excessive parameter cases, either this approach will cause inefficient parameter estimations or increase the training time in the MCMC iterations as well. In order to overcome these shortcomings, GAs can be integrated with MCMC methods, since they do not require the gradient information, and make parallel search in the high dimensional parameter cases. Hence they might allow the efficient parameter updates in MCMC iterations depending on the complexity and nonlinearity of risk function. The performance of GAs is discussed in terms of their parameter estimation in the various optimization problem and BNNs [21,28,42,43].On each iteration of Genetic MC, firstly the hyperparameters are produced from their conditional distributions using Gibbs sampling, and then the parameters are determined over the energy function via GA cycle using the updated hyperparameters. Whenever GA cycle stops, the candidate parameter vector is compared with the best one hold in the previous iteration using the Simulated Annealing with Metropolis–Hasting in terms of their performance over the energy function. The steps of Genetic MC are summarized in Fig. 2.In Genetic MC, GA cycle consists of various operators that require some specific adjustments in themselves. This arrangement is given step by step similar to the algorithmic scheme proposed by Kocadağlı [27], Kocadağlı and Aşıkgil [28] as follows:(i)Convert all the parameters of energy function in Eq. (29) to binary numbers (or double vector), and then gather all the parameters into one vector called as chromosome.Create a certain number of parameter vectors by using heuristic or random methods.Calculate scores of all the individuals over energy function in Eq. (29) called as fitness function (here, scores of candidate members is scaled using the fuzzy membership function).Select the favorable individuals (parameter vectors) into the mate pool for the next generation by heuristic or stochastic methods (here, the stochastic method is preferred).Apply elite, crossover and mutation operators to the selected parameter vectors called as parents. This process is known as the reproduction in which the children (parameter vectors) are created for the next generation.If any one of the stopping criteria is met, then stop the algorithm; otherwise turn to step (iii).Whenever the algorithm stops, then hold the best parameter vector and convert all the binary numbers (or double vector) to into the original values.Skip to the Simulated Annealing with Metropolis–Hastings, and then compare the candidate parameter vector with the best one hold in the previous iteration with respect to their probabilities evaluated from the posterior distribution in Eq. (20).The detailed information related to operators of Encoding, Selection, Elitism, Crossover, Mutation and Migration can be found in [27,28,42–44] and MATLAB 7.12. The steps of GA cycle used in Genetic MC are given in Fig. 3.In the reproduction process of GAs, each parameter vector is selected with respect to its crude score assigned over the fitness function. For this reason, the scaling of crude scores plays an important role to ensure the diversification in the population. In step (iii) of GA cycle, determining the range of the scaled scores deals with possibilistic uncertainty. In order to measure this kind of uncertainty, it can be assumed that these scores belong to any fuzzy set, and then fuzzy scores of population members can be evaluated by fuzzy membership functions. Thus, the imprecise properties of data used in scaled process might be intuitively defined by means of fuzzy membership functions. In this context, Kocadağlı [27] and Koacadağlı and Aşıkgil [28] proposed the following fuzzy membership function:(30)μ(scorei)=1/expscorei−min(max−min)pi=1,2,…,populationsize;p=1,2,3where max and min correspond to maximum and minimum scores of population parameter, respectively. Here, the parameter p controls scales of the scores, and contributes to diversification in the population. The expected number of members that are selected into mating pool can be determined as follow:(31)E(scorei)=populationsize×μ(scorei)∑μ(scorei)i=1,2,…,populationsizeAs mentioned before, at end of the GA cycle, the candidate parameter vector is compared with the best one in the previous iteration. This process can be handled by Metropolis–Hastings method with simulated annealing as follow [4,8,27,28]:•Firstly, calculate the negative logarithms of p(θ*|D) and p(θiter−1|D) as L*=−lnp(θ*|D) and Liter−1=−lnp(θiter−1|D),If L*<Liter−1, the accept the candidate parameter vector; otherwise,•Draw u∼U(0, 1). if L*>Liter−1, then accept the parameter vector with the probability exp(−(L*−Liter−1)/T)>u where T is a parameter, referred as the temperature; else,Reject candidate, and then let θiter=θiter−1.While the desired distribution is recovered for T=1, the algorithm explores the parameter space much more freely for T>>1, and it might escape from the regions with the low density. Generally, Simulated Annealing involves starting with a large value of T and then gradually reducing its value during the algorithm works. Thus, the algorithm might into a region with the high density [4,7]. However, this approach is criticized in context of Bayesian implementations to ANNs [7,27,28]. In Genetic MC, the temperature value is alternatively adjusted by updating the minimum and maximum of energy function values obtained in the simulations. To do this, instead of exp(−(L*−Liter−1)/T), the following fuzzy membership function proposed by Kocadagli [27] is used:(32)exp−Li−Li−1Lmax−Lminpp=1,2,3;i=1,2,…,iterationnumberwhere Lmin and Lmax are minimum and maximum energy values obtained in the simulations, and p is a parameter that controls sensitivity. For p>1, the selection chance of candidate parameter vector is higher than one provided in case of p=1.In MCMC procedure, another issue is to examine the autocorrelations between the values of Liter(x, θiter)=−lnp(θiter|D) in terms of estimation accuracy whenever the equilibrium is reached. In order to measure dependency, the statistic τ can be used [8]:(33)τ=1+2∑s=1∞ρ(s)where ρ(s) is the autocorrelation of L(x, θ)=−lnp(θ|D) at sth lag, defined by(34)ρ(s)=EL(x,θiter)−EL(x,θ)L(x,θiter−s)−EL(x,θ)Var[L(x,θ)]Generally, the sampling from complex distributions leads to the positive autocorrelations. Thus, these positive autocorrelations might cause τ values greater than 1. If τ is shorter than one, it can be assumed that the dependencies between L(x, θiter) are at fair level to increase the estimation accuracy [8]. In other words, if p(θ|x1:N, y1:N) is an equilibrium distribution of ergodic Markov chain, this chain converges to its distribution as rapidly as possible, so the parameter vectors θiterare not highly dependent once the equilibrium distribution is reached.In this section, to examine the implementations of the proposed algorithm, nonlinear time series and regression analysis are handled, respectively. In the time series analysis, Canadian lynx data set is used, since it is commonly preferred as a benchmark data in the literature [17,45]. In the regression analysis, to provide the three-dimensional visualization, an artificial data set in [19] is preferred. In either case, the proposed algorithm is compared with various traditional methods in terms of their estimation and prediction performances over the mentioned data sets, and then the analysis results are discussed in detail. The software of the proposed approaches was written in MATLAB 7.12 package program. In the analysis, a computer having a processor with Intel® Core™ i3 CPU 2.13GHz, 4GB RAM and 64 bit operating system was used.The data set used in time series modeling is the annual record of the number of the Canadian lynx “trapped” in the Mackenzie River district of the North-West Canada for the years 1821–1934. This series includes annually 114 observations as seen in Fig. 4. Similar to the former studies in [17,45], this series was transformed to its base-10 logarithm, and used the first 100 observations for model building and the last 14 observations for forecasting. According to the autocorrelogram of log-series given in Fig. 5, the first two lags of series (yt-1, yt-2) are significant for model building. Although 7th (yt−7) and 11th lags (yt−11) seem little bit significant, their partial autocorrelation function (PACF) values are so weak. For this reason, these two lags were overlooked during the time series model building, since this kind of weak correlation is usually caused by random errors.In order to train the feed-forward ANNs by classic optimization algorithms, the time series data was partitioned into three sets: training, validation and test. While training and validation data sets were used to train ANNs and control the overfitting, respectively; the forecasting performances of ANNs were calculated over the test data. Actually, the test data can be considered as the future elements of the time series on which one would desire to forecast. This partition allows comparing the forecasting performances of ANNs over this data set. In analysis, to partition the time series, k-fold and one-leave-out cross-validation techniques were implemented. Essentially, one-leave-out technique is the specific case of the k-fold cross-validation where k is equal to the number of elements in the time series excepted of the test data. Once the last 14 observations were left for the test data, the remaining series was partitioned as training and validation depending on the cross-validation techniques. During the analysis, although the ANNs were trained by the different numbers of folds, k-fold technique were not sufficient in terms of providing the significant estimations over training data because it might have cause the loss of depending structure among elements of the time series. For this reason, the leave-one-out technique was preferred to divide the time series as training and test. In this approach, only one single element is involved as the validation data from the training data. This process is repeated such that each element in the training is used once as the validation data. In Genetic MC implementations, the time series data was partitioned only training and test data because Genetic MC is based on Bayesian learning, so it is capable of learning from whole data. Besides, Genetic MC makes the predictions over many models estimated in MCMC procedure rather than only one model. This feature brings it the superior prediction ability against to traditional methods.As the activation function in the hidden layers of ANNs and BNNs, the tangent hyperbolic function is preferred because it has a rapid calculation facility and the feature of differentiability. In order to make the nonlinear time series forecasting by means of ANNs and BNNs, firstly the feed-forward network structure is constructed as shown in Fig. 6. In this network, the first p lags of time series (yt−1, …, yt−j, …, yt−p) are defined as the inputs of the network. The target of the network corresponds to the original series itself as yt. To train the feed-forward ANNs, the gradient descent, also known as the steepest descent, gradient descent with momentum and Levenberg–Marquardt optimization algorithms are used. For Gaussian approximation with the fixed hyperparameters of BNNs, Quasi-Newton optimization algorithm is preferred due to its advantage in the evaluation of Hessian matrix. For full Bayesian approach of BNNs, Genetic MC approach is used. The performances of ANNs and BNNs were examined by using different numbers of neurons in their hidden layers. To determine how many neurons should be included in the hidden layers, the various information criteria such as Akaike Information Criterion (AIC), Corrected AIC (AICc), Bayesian Information Criterion (BIC) were used. In addition to the information criteria, the performances of the estimated time series models were evaluated by means of Mean Squared Errors (MSE) over training and test data, the correlation coefficient between target (original values) and output (forecasted values). The forecasting results and the comparison of the estimation procedures are given in detail below.In order to apply Genetic MC algorithm to Canadian lynx data in the context of time series modeling, firstly the top-level hyperparameters in Eq. (23) were fixed, thus the means and Betas in the middle level of the hierarchy were generated by simulations. To figure out the efficient hyperparameter values which provide much better parameter estimations, the different values of them were examined. In the analysis, we tried 0.1, 1, 2 and 10 values for shape parameter Alpha; 1, 10 and 100 values for mean values of weights, biases and noise precisions. For instance, if Alpha and precision mean are taken as 1 and 100, respectively, and then scale parameter Beta corresponds to 0.01 (mean=Alpha/Beta). In this case, the priors given in Eqs. (23) and (27) become little bit informative for Alpha 1 and Beta 0.01. In analysis, the non-informative priors such as Gamma (Alpha=0.1, Beta=0.1) and Gamma (Alpha=0.01, Beta=0.01) cannot achieve a sufficient estimation performance. At the end of the analysis, it is concluded that the little bit informative priors carry out much better estimations. For this reason, we fixed both shape parameter and mean as 1 for all hyperparameters in Eq. (25), respectively.As mentioned before, the Genetic MC algorithm has two cycles called as main and GA where the parameters and hyperparameters are reproduced by simulations. In this scheme, the main cycle calls for the GA cycle to update the parameters at the each iteration. For each step of the main cycle, GA cycle runs its inside up to the number of generation, and then it updates the parameters efficiently. Thus, the efficient hyperparameters are updated in the current iteration of the main cycle according to the efficient parameters received from GA cycle in the previous iteration. To achieve much more robust forecasting, the total iteration is divided into two phases called burn-in and learning. Here, the forecasting is performed only over the models estimated in the learning phases after the models estimated in the burn-in are discarded.In the configuration of GA cycle, while the parameters of elitism and migration were fixed as 2 and 0.2, respectively, generation and population sizes were changed depending on the numbers of neurons and inputs defined in the networks. Especially, the number of generation was taken as 2 and 100 to examine whether it has a significant impact on the performance. In order to stop GA cycle, the generation number and the tolerance limit for fitness function values were used.To determine the neuron numbers in the hidden layer, and control the model complexity, three information criteria were used. Using the information criteria helps to ensure the better generalization ability by preventing the overfitting to data. The performance of Genetic MC algorithm is summarized in Table 1.From the results in Table 1, it can be seen that while the neuron number grows, the time series models becomes more complex; hence the values of information criteria increase as well. Actually, this penalization can be seen easily from greater values of information criteria depending on the number of neuron. As mentioned before, this situation known as Occam's rule happens automatically in the Bayesian approaches. As seen from Table 1, Genetic MC penalizes the excessive number of neurons systematically. However, in order to determine the efficient number of neuron, the information criteria are very useful indicators because they can be interpreted easily during the analysis. By means of these criteria, it is straightforward to make a decision about how many neurons is sufficient for estimating the time series models efficiently. According to Table 1, BIC penalizes the model complexity more heavily than the other information criteria. Considering all the information criteria, it can be concluded that the model estimated by using two neurons gives better forecasting performance than the other models over the training data. However, the model estimated (showed by bold font) by using three neurons gives better forecasting performance than the other models over the test data. The use of more neurons than three leads to growing MSEs of both training and test data. That is why the values of information criteria are high at greater number of neurons. Because of superior fitting to test data and reasonable values of information criteria, the model estimated by three neurons can be accepted as the best model in terms of forecasting performance. Besides, it can be seen that Genetic MC is able to achieve the efficient model estimation using different numbers of generation and population. Even though the number of generation has no significant impact on the forecasting performance, the lower numbers of generation require the greater population size, and consume much more time to estimate better the time series models.For the best model in Table 1, at end of 5000 iterations in the burn-in process and 1000 iterations in the learning process, the impact of Genetic MC on the negative logarithm of posterior distribution is demonstrated in Figs. 7 and 8. As seen from Fig. 7, the Markov chain is not stationary without GA updating in the burn-in process because the algorithm cannot move the regions with high density, and the dependency between elements of Markov chains is rather high. However, as seen in Fig. 8, the energy function starts to get much lower values and Markov chains returns to the stationary structure when Genetic MC runs. From the autocorrelogram demonstrated in Fig. 9, it can be seen that the dependency between the elements of Markov chain in the learning stage disappears due to the negative autocorrelations. According to the autocorrelation function, the first three lagged autocorrelations of Markov chain in the learning stage are 0.08, −0.04 and −0.07, respectively. By means of the equation given in Eq. (33), the independency values for the first three lags are evaluated as 1.17, 1.09 and 0.96, respectively. From these values, it can be seen that the independence value evaluated up to 3th lag are smaller than 1. That is, the dependency disappears as the number of delay increases as well. Whereas, in the burn-in stage as seen in Fig. 7, the independency values for the first three lags are calculated as 2.16, 2.95 and 3.44. From here, it can be inferred that the successive elements of Markov chain in burn-in stage have the high positive autocorrelations. Lastly, the estimated outputs of training data and the forecasting of test data are demonstrated in Figs. 10 and 11.In this section, to compare the performance of Genetic MC with the traditional optimization algorithms; gradient descent, gradient descent with momentum, Levenberg–Marquardt and Quasi-Newton known as Broyden, Fletcher, Goldfarb, and Shanno (BFGS) were used. In order to train the feed-forward ANNs, while gradient descent requires the learning rate parameter, gradient descent with momentum also needs an extra parameter known as the momentum constant in addition to the learning rate. Levenberg Marquardt algorithm uses a non-negative damping parameter when its larger values make the algorithm closer to Gauss–Newton Method whereas its larger values tends it closer the gradient descent algorithm. On the contrary, BFGS is able to work without any specific parameter. Detailed information about these algorithms and their parameter settings can be found in [7,31,32].In order to increase the forecasting performance, the leave-one-out cross-validation method was implemented as mentioned before. Thus, the forecasting was made by evaluating all training data which were constituted by the leave-one-out method, instead of only one training data. The cross-validation loop was repeated up to the number of observations in the training data. In the leave-one-out loop, the errors calculated over the each validation data were monitored to make the early stopping during the training process. When the validation error reaches the maximum five validation failures in any training step of the cross-validation loop, the training is stopped by the algorithm automatically, and then it skips to the next step. In addition to the validation failures, the other stopping criteria are the maximum iteration (5000), the error tolerance between the successive iterations (1.10−10) and the minimum gradient magnitude (1.10−5).To improve the efficiency of the optimization algorithms, the best network parameters estimated in any step of the cross-validation loop are used as initial parameter values in the next step. Thus, this implementation allows the optimization algorithms to start searching from much more efficient initial point instead of randomly generated parameters. After the cross-validation procedure ends, the average MSE is evaluated over all the training data sets used in the cross-validation procedure. Similarly, the average SSE of test data is evaluated by means of considering all the models estimated in this procedure. Similar to Genetic MC implementations, to determine the neuron numbers in the hidden layer and control the model complexity, three information criteria were used. The best models obtained by from ANNs trained by using various optimization algorithms are summarized in Table 2. Also, the efficient parameters of optimization algorithms, which were determined by the trial and error during the training of ANNs, are given.From Table 2, it can be seen that BFGS algorithms used in the Gaussian approximation gives the smallest average MSE for training data among the traditional algorithms, in addition to the smallest average MSE and the shortest time consumed for training. Despite of this superior performance, Gaussian approach requires the extra time for determining the efficient value of the hyperparameter Alpha. As the second best, Levenberg–Marquardt gives a superior performance in terms of average MSEs of training and test data as well as the consumed time. Comparing to all the training procedures, it can be seen that Genetic MC shows better performance with respect to MSEs of training and test data. Three information criteria confirm this superiority as well.In the second implementation, Genetic MC is compared with traditional optimization methods of ANNs and Gaussian approach of BNNs in terms of their performance on an artificial data set with two inputs and one target used in [19]. This data is derived from a function with Gaussian noise with mean zero and standard deviation 0.25, N(0, 0.252). During the analysis, this data set is partitioned into two parts as training (200 observations) and test (25 observations) as demonstrated in Figs. 12 and 13, respectively. The aim of regression analysis is to estimate the best surfaces for training and test data sets seen in Figs. 12 and 13. In order to improve the performances of ANNs, k-fold cross-validation was implemented, and a different fold was used as a validation data at each iteration of cross-validation. In addition, the network parameters estimated in any step of the cross-validation loop were assigned as initial parameter values in the next step. The feed-forward ANNs with the mean squared error were trained by traditional optimization algorithms which were used in time series analysis above. In order to run Genetic MC, the hyperparameters in the MCMC framework were predetermined as similar to above time series analysis. In analysis, the population size and generation number in the GA cycle were adjusted depending on the neuron number. The performances of ANNs and BNNs were examined by using the different numbers of neurons in the hidden layer. At end of the analysis, the training results of the proposed and traditional approaches are given in Table 3.From Table 3, it can be seen that Levenberg–Marquardt gives the smallest average MSE for training data among the traditional algorithms in addition to the shortest time consumed for training. Despite of this superior performance over training data, the fitting to test data is not better because of the overfitting to training data. As the second best, BFGS algorithm used in the Gaussian approximation gives the smallest average MSE over the test data since it is able to penalize the overfitting to the training data. Comparing to all the training procedures, it can be seen that Genetic MC shows better performance with respect to MSE of test data, because it prevents the overfitting to training data automatically. However, Genetic MC requires the extra time consuming to ensure the efficient estimation and prediction performances depending on the number of parameters.In the best configuration of Genetic MC, the generation number and population size were 100 and 25, respectively. At end of 5000 iterations in the burn-in process and 1000 iterations in the learning process, the impact of Genetic MC on the negative logarithm of posterior distribution is demonstrated in Figs. 14 and 15. From Fig. 14, the Markov chain is not stationary without GA updating in the burn-in process. However, as seen in Fig. 15, it returns to the stationary structure in a short time after training by Genetic MC. From the autocorrelogram demonstrated in Fig. 16, it can be seen that there are negative autocorrelations between the elements of Markov chain in the learning stage. That is, the dependency between the elements of Markov chain disappears. According to autocorrelation function, the first three lagged autocorrelations of Markov chain in the learning stage are −0.03, −0.01and −0.00, respectively. By means of Eq. (33), the independency values for the first three lags are evaluated as 0.95, 0.92 and 0.92, respectively. From these independency values, it can be inferred that the independence values between the successive elements of chain are the satisfactory level, since they are smaller than 1. Whereas, in the burn-in stage as seen in Fig. 14, the independency values for the first three lags are calculated as 2.16, 2.95 and 3.44, because the successive elements of Markov chain in burn-in stage have high positive autocorrelations. Lastly, the estimated outputs of training and test data sets are demonstrated in Figs. 17 and 18.

@&#CONCLUSIONS@&#
According to the analysis results performed over real and artificial data set, Genetic MC has the substantial advantages in terms of balancing the model complexity, the learning ability in the estimation process, reducing the random walk in MCMC procedures as well as no need of the derivative information. Because of Bayesian learning framework, the proposed approach does not require to partition the analysis data into training, validation and test data, since it is capable of learning over whole of data set as well. Besides, this approach controls the model complexity automatically, even if the network parameters are increased depending on the number of neuron in the hidden layer. In the estimation procedure, GA cycle integrated with MCMC methods updates all the network parameters efficiently; thus the proposed approach copes with the random walk problem, and reduces the dependency between the elements of Markov chains. In addition, the fuzzy membership functions help to measure the possibilistic uncertainty encountered in the scaling process of GAs and the simulated annealing with the Metropolis–Hastings method.Comparing to the traditional training approaches, even if Genetic MC needs the extra time consuming, it is capable of making more efficient estimations than the classical ones. The software of Genetic MC was written in Matlab 7.12; hence some ready-made functions in this program require much more memory allocation. In order to accelerate Genetic MC, its software can be written by the system program languages such as C and C++. In addition to the system program, powerful computers in terms of processor speed and memory will help to reduce training time.As a result, hybrid genetic MC provides a natural way to estimate the parameters and hyperparameters in the BNNs efficiently and it can be easily modified to apply various problems in regression analysis, time series, pattern recognition and clustering. For future studies, we are planning to use Genetic MC in the specific real life problems in medical, finance and engineering. In this context, the studies related to accelerating and modifying of Genetic MC will be continued, and then a user-friendly interface will be designed by means of MATLAB GUI.