@&#MAIN-TITLE@&#
An options-based approach to coordinating distributed decision systems

@&#HIGHLIGHTS@&#
Distributed options-based model that manages multi-agent uncertainties and risk.Flexible model adapts as system information and agent capabilities are better known.Includes the endogenous relationship between decisions and sources of uncertainty.Policy responds to and controls uncertainty in engineering/management domains.Yields an equilibrium system state that improves the agent and system performances.

@&#KEYPHRASES@&#
Distributed decision making,Multi-agent systems,Uncertainty modeling,Real options,Risk management,

@&#ABSTRACT@&#
Engineering and operations management decisions have become increasingly complex as a result of recent advances in information technology. The increased ability to access and communicate information has resulted in expanded system domains consisting of multiple agents, each exhibiting autonomous decision-making capabilities, with potentially complex logistics. Challenges regarding the management of these systems include heterogenous utility drivers and risk preferences among the agents, and various sources of system uncertainty. This paper presents a distributed options-based model that manages the impact of multiple forms of uncertainty from a multi-agent perspective, while adapting as both the stream of information and the capabilities of the agents are better known. Because the actions of decision makers may have an impact on the evolution of underlying sources of uncertainty, this endogenous relationship is modeled and a solution approach developed that converges to an equilibrium system state and improves the performance of agents and the system. The final result is a distributed options-based decision-making policy that both responds to and controls the evolution of uncertainty in large-scale engineering and operations management domains.

@&#INTRODUCTION@&#
Technology and operations management decisions have become increasingly complex in recent years. The increased ability to access and communicate information has resulted in expanded system domains consisting of multiple agents (decision-makers), with each exhibiting autonomous decision-making capabilities. Although these systems may possess the ability to perform and achieve benefits that are beyond those capable of smaller networks (Weiss, 1999), the following challenges are presented. First, the agents may possess individual utility drivers, thus creating an environment that must balance the goals of multiple agents and the overall system. Because an agent may exhibit a finite performance capacity, choices must be made regarding how to most effectively utilize each agent. These decisions are further complicated due to both continuous forms of uncertainty that provide a constant source of variability, as well as discrete, and sometimes rare, events that may provide dramatic disruptions to the system processes. Furthermore, the actions of agents may have an endogenous impact on system characteristics, performance capacity, and underlying sources of uncertainty. Because these systems possess dynamic properties, continuous information updating creates a decision timing issue for the agents where the benefits and costs of waiting for additional information must be considered. This paper develops a distributed decision-making approach that incorporates decision flexibility to manage the impact of multiple uncertainties from a multi-agent perspective, and improve both agent and system performances.Consider the increase in technological innovation and the resulting impact on operations management. As information and communication technologies have increased, the competitive landscape has also increased resulting in a global network of suppliers, producers, and distributors. Many of these supply chain entities are contract manufacturers and compete among other firms for their place in the chain. Because it is imperative to operate in a lean manner, costs must be kept to a minimum and resources allocated to yield a maximum utility. This utility can be viewed in two ways. From a systems point of view, production of the final good or service needs to be performed and delivered to the end customer in the most cost effective manner. However, each entity in the supply chain may be considered an agent (e.g., an individual supplier, producer, distributor) that makes its decisions based on satisfying its own economic utility drivers.The resulting decisions that each individual agent makes may be further complicated by various sources of uncertainty. For example, production facilities typically exhibit a finite resource capacity and challenging decisions must be made when devising operating schedules and determining which customer orders to satisfy. These decisions are complicated by both the uncertain nature of the resource performance and customer order rates. A producer may engage in a contract with an initial customer that utilizes its full capacity, but is then unable to satisfy an additional customer order that may yield even greater profits, thus jeopardizing its competitive position in the supply chain. From the customer’s perspective, resource selection and contracting decisions may be based on such factors as a desired delivery date or price. These contracted conditions, however, may ultimately be subject to the performance uncertainty of the production resource. If the resource can produce with lower levels of process variability, then it may be able to quote better delivery dates and lower prices. Therefore, both the customer and producer benefit by more stability in the resource operations.When devising a decision-making policy for this type of system, it is important to not only consider exogenous factors, but also recognize any endogenous parameter relationships. In this example, a possible endogenous relationship may exist between production stability and the types of customer orders that the resource processes. By recognizing this relationship, the resource may be used to process customer orders that encourage performance stability. These particular orders may be ones that are easier to process or provide smoother scheduling with fewer disruptions and reduced setup costs. The resulting improvements to operational stability may therefore yield reductions in future production uncertainty.In order to effectively manage these types of systems, a decision-making approach must be employed that retains flexibility as the stream of new information arrives, while hedging the impact of uncertainty for multiple agents and incorporating the endogenous relationship between agent decisions, system responses, and future performance capacity. Without flexibility, each agent must act immediately based on the information currently available. Because there is now an increasing amount of real-time system information available, it may be very beneficial to postpone the timing of any decision and re-evaluate based on updated system states. The approach developed in this paper is based on the concept of dynamic flexibility using options-based decision policies. It should be noted that this model does not utilize the Black Scholes options pricing model (Black & Scholes, 1973) or any other closed form solution method that is commonly used in the literature. In an effort to provide insights into systems that do not meet the strict assumptions of these closed form solution approaches, a depiction of a multi-agent resource allocation system was designed and a numerical solution presented in this paper. This model is tested to evaluate the impact of managing uncertainty from a distributed decision-making perspective with respect to improvements in both agent utilities and system properties while adhering to limited and finite capacity resource constraints.This paper is organized as follows. Section 2 provides an overview of literature encompassing the three primary areas used as the basis of this paper: real options, options exercise games, and risk management in engineering and operational systems. In Section 3, a specific multi-agent system is defined and a distributed options-based model is developed that includes both agents’ perspectives while accounting for the endogenous relationship between agent decisions, system performance, and the impact on the underlying source of system uncertainty. This distributed options-based policy is tested numerically in Section 4 and concluding remarks are presented in Section 5. A table giving descriptions of the variables used in the mathematical formulations is presented in Appendix A (online only). Specific model details pertaining to the multi-agent case study consisting of a task and resource agent are included in Appendix B and C (online only), respectively.The model developed in this paper encompasses three primary research areas: (1) the extension of options-based decision theory into an engineering and operations management domain; (2) the impact of competitive agents on the ultimate decision-making process in an options framework; and (3) current approaches toward managing the impact of uncertainty in large-scale engineering and operational systems. The first area demonstrates the flexibility of utilizing options pricing concepts in non-financial domains; the second area introduces a relatively new area of research referred to as “options exercise games”; and the final area provides a domain for which the findings of this paper may be applied. This section provides a review of some of the more relevant research in these areas to the scope of this paper.Since the seminal work of Black and Scholes (1973) and of Merton (1973), options pricing concepts have been used extensively to value financial assets, with the theory then extended to real assets (Myers, 1977) and commonly referred to as “real options”. Some of the common types of real options used in operations and project management decisions include the following: the option to defer investment decisions; a time-to-build option for staged investments; the option to alter the scale of operations through expansion, contraction, shut-downs, or restarts; the option to abandon operations or a project; the option to switch outputs, inputs, or operating modes; growth options; and complex multiple interacting options (Trigeorgis, 1996). Because managerial and operational decisions may be considered at least partially irreversible, there is a value to waiting for more information about the system prior to making a decision. Detailed accounts of both the theory and applications of real options are provided in Dixit and Pindyck (1994) and Trigeorgis (1996). Similar to these applications, the focus area of this paper is with decisions pertaining to real assets (e.g., production capacity). However, this paper further extends these existing options-based concepts into a domain consisting of multiple decision makers.In the supply chain situation described in Section 1, each agent may interact in a competitive manner to maximize its own utility. Consequently, the concept of options exercise games has recently evolved and provides an intersection of traditional real options analysis with game theory. In many situations, the ultimate utility gained from an investment in a real asset is affected by the investment strategies and actions of other agents in the system. This characteristic of real options differs from financial options in many application domains. For example, real assets with respect to real estate development often have a finite elasticity of demand; developers may have finite capacities; there is a limited supply of options available; and there is typically less than perfect competition among developers (Williams, 1993). Financial assets, however, do not exhibit these restrictions and the exercise of a financial option by any agent does not change the characteristics of the security or the option (Grenadier, 2002). In order to account for the impact of other agents’ exercise strategies on the underlying value of a real option and the subsequent optimal exercise policy for a given agent, game theoretic principles must be included in the analysis. The model presented in this paper incorporates game theoretic options to account for the changes in system characteristics and agent payoffs that occur due to the presence of other agents. Because resource capacities are finite, a task agent’s allocation option exercise policy must account for the expected actions of other task agents competing for the resource’s services. This scenario provides an extended domain for the application of options exercise games concepts when allocating resources in large-scale engineering and operational systems.Traditional work in large-scale engineering and operational systems, such as production systems and supply chain networks, has focused primarily on improving the overall cost-efficiency of the system. Whereas these models provide an efficient and low cost approach to managing the system, there is little flexibility to respond in case any portion of the system does not perform as originally planned. Due to the cascading nature of these systems, the impact of even one portion of a network that does not operate as planned may propagate throughout the entire system, and thus have a dramatic effect on the overall performance of the system. Therefore, a disruption to an inflexible system may result in significant and widespread financial and performance costs.The ability for a network to create flexibility and respond to uncertainties may allow businesses to realize efficient current performance and potentially be able to quickly reconfigure and benefit from new unforeseen market opportunities. As evident from the terrorist events of September 11, 2001, the United States northeast power outage of August 2003, the aftermath of Hurricane Katrina in August 2005, the Deepwater Horizon oil spill of April 2010, the Tohoku earthquake and subsequent tsunami of March 2011, and Hurricane Sandy in October 2012, this flexibility will also help to build more secure and resilient supply chain networks from a national security and emergency response standpoint (Rice & Caniato, 2003a; Rice & Caniato, 2003b). Snyder and Daskin (2005) manage system risk through strategic facility location planning. This type of proactive approach is used to incorporate risk management in the planning stage as opposed to being unprepared and reacting to failures during system operations. A review of some more common day-to-day sources of operational risks are presented in Chopra and Sodhi (2004) and include major disruptions, production delays, information system risks, forecasting risks, intellectual property risks, procurement risks, inventory risks, and capacity risks. This attention that has been drawn to managing the impact of uncertainty in large-scale systems may be applied to both continuous operational uncertainties and the discrete disruptions that may be rare, but result in major impact.Competition and game theory have been incorporated into the traditional supply chain models for systems with multiple suppliers. Elmaghraby (2000) provides a literature review regarding the competition for supply contracts and sourcing policies. Minner (2003) provides a good review of multiple supplier inventory models to mitigate the effects of shortages situations, as well as related inventory problems that arise in the areas of reverse logistics and multi-echelon systems. Babich, Burnetas, and Ritchken (2007) and Babich (2006) utilized both game theory and real options to analyze contracting for a single retailer and multiple suppliers when subject to supplier default risk during their production lead times. Ball and Deshmukh (2013) developed a cooperative real options approach utilizing an incentive (or disincentive) pricing scheme to hedge systemic risks when coordinating multi-agent decisions in supply chain and resource allocations systems.This paper builds upon these concepts to provide two key contributions to this area: (1) flexibility in distributed decision-making from multi-agent perspectives and (2) endogeneity between agent actions and an underlying source of uncertainty. Therefore, this paper extends the current research to develop a general distributed decision-making model that manages the impact of uncertainty from multiple agent perspectives in such a way that both agents benefit (e.g., both the retailer and supplier in a supply chain network), while accounting for endogenous parameter modeling that yields overall system improvements. This general model can be used to incorporate distributed decision policies and risk management in a wide range of resource-constrained domains, including engineering and system design processes, new technology development, enterprise systems, healthcare systems, homeland security, emergency preparedness and response, global operations, and supply chain management.For the purpose of this paper, the following model is constructed to manage the impact of uncertainty from the perspectives of two agents: a task and resource agent. The dynamics of this general system are explained throughout Section 3 and illustrated in Fig. 1. Appendix A (online only) has a summary table of descriptions of the notations used in the paper. In this system, the resource performs operations on a task to produce an output (e.g., product for resale, consulting service). Tasks arrive at the system with the agent’s goal of allocating them to a resource for processing and an ultimate utility. The resource may initiate processing a task at set discrete time slots. At any given time slot, the resource presents its current production capacity in the form of a conditionally guaranteed process rate, which would consequently assure the task agent of a guaranteed delivery time and cost for the finished product. Because production systems commonly exhibit continuous random fluctuations in process times for various task types and sizes, it is assumed that this associated resource process rate evolves stochastically according to a known distribution (e.g., the square-root mean reversion process). The decision for the task agent to request processing based on the terms of this current guaranteed process rate and give up the option to wait for a more beneficial rate (and associated completion time and cost) in the future is framed as an irreversible investment decision by the task agent and evaluated using options-based solution techniques.Additional tasks randomly arrive to the system, thus creating a dynamic environment that may limit the choices available to the task agent. Task types are heterogeneous and provide varying levels of utility benefit to the resource production system. Because the resource is of finite capacity and can only process one task at a time, it will consequently maintain a preference level for each task type based on the task’s respective utility contribution to the system. The current task agent recognizes this inherent competition for the resource’s capacity, and therefore factors the risk associated with postponing the allocation decision and subsequently experiencing preemption from a preferred task that may arrive to the system prior to making this decision. If preemption occurs, the task may not be eligible to begin processing until the next available time slot. Therefore, flexibility in decision timing from the perspective of the task agent may be beneficial with respect to ensuring a more economic and timely delivery of the final product; waiting too long may reduce the availability of the resource due to the potential arrival of competing, and preferred, tasks.Once the task agent makes its decision to accept the conditions of a given process rate and request processing from the resource, the resource must then decide whether to allow this current task to exercise its allocation option or deny processing in case a more beneficial task arrives in the future. The resource agent recognizes an endogenous relationship between its actual realized system performance costs (e.g., due to idleness and overtime factors) and the ultimate stability of the production operations, and the respective decision policy is constructed accordingly. Because of this relationship, the resource agent aligns its utility driver to one that prefers to process tasks that will have a positive effect on its future stability and performance capabilities. This type of situation may occur when the starting and stopping of production is minimized, and setups are therefore held to a minimum. Therefore, more stable production operations may yield a reduction in the overall uncertainty of the system. In this particular system, reduced performance uncertainty will lower the risk posed by the stochastic resource process rate and experienced by both the task and resource agents. So, from the resource agent’s viewpoint, flexibility in its decision timing will allow it to better control both the immediate utility gained from processing various task types as well as future production stability.A major contribution of this paper is that this particular system and model utilizes a dual options-based policy where both the task and resource agents value a similar option, but from two distinct viewpoints. The task agent considers the option to request processing at the current guaranteed rate (and corresponding time and cost conditions) or postpone this decision until a future time period. The resource agent, however, considers the option of either accepting a task’s request for processing, or instead postponing this processing decision to evaluate future opportunities that may be more beneficial to its specific utility function. Thus, each agent essentially possesses an option of either enacting a processing decision or waiting for more information regarding the system, however from a different perspective.Furthermore, the underlying sources of uncertainty are viewed differently by the task and resource agents. The task agent considers the sources of uncertainty to be exogenous and, therefore, makes its decisions in an effort to respond to the potential impacts posed by these uncertainties (i.e., the stochastic process rate and the discrete arrivals of potentially preempting tasks). However, the resource agent considers the future task arrivals to be exogenous, but realizes that there is an endogenous relationship between its decisions and the future evolution of the system’s uncertainty and, therefore, makes its decisions in a way that controls this evolution by carefully selecting tasks that encourage system stability. Therefore, the dual policy extracts value from the system by making decisions in a manner that yields a more beneficial evolution of system uncertainty. The reader may refer again to the dynamic process illustrated in Fig. 1 to assist with this understanding. This model now both responds to the impact of multiple forms of uncertainty in the system and from the perspectives of multiple agents, and also manages the future propagation of an underlying source of process uncertainty. The aim of this paper is to demonstrate both the model development and benefits using a general theoretical multi-agent system; however, the theory may be applied to other domains exhibiting this type of agent and system behavior.The model system environment has been designed to allow for task type heterogeneity and support the decision-making process for both the task and resource agents with multiple forms of uncertainty and dynamic states. Multiple state parameters are required to characterize the system environment at any given time and support the complex decision-making processes.Assume thatR(t)is the known instantaneous process rate of the resource at time t. Processing that occurs at the resource during the time interval(t,t+dt)is then modeled using this known process rate (i.e.,R(t)) and the changes in this process rate that are expected to occur over this interval (i.e., dR). It is thus assumed that the process rate of a resource evolves stochastically over a time interval of length dt according to the following square-root, mean-reversion process:(1)dR=η(R‾-R)dt+σRdzwhere η is the speed of reversion towards the mean,R‾is the mean level of the process rate, σ is the variance parameter (i.e., the standard deviation of the change in process rate for the resource), and dz is the increment of a Wiener process. Therefore, the resource processing rate may fluctuate up or down, but tends to revert toward the mean valueR‾either through natural means or with some level of management control (e.g., rescheduling of workers). It is assumed thatη⩾0,R‾⩾0, and the initial process rate value is a non-negative constant. For general notational purposes, letf̃(R)denote any specific parameters that define the process type (i.e.,f̃(R)=(μ,η,σ,R‾)for the square-root mean reversion process of Eq. (1)). This autoregressive square-root process has been used in the financial literature to model the movement of short-term interest rates (Cox, Ingersoll, & Ross, 1979; Cox, Ingersoll, & Ross, 1985).New tasks arrive to the system according to a Poisson process of rate λ. LetX∈Rdenote the task type and, more specifically,Xiis the task type for task i andf̃(X)is the appropriate distribution defining the system’s heterogenous task types. Both the revenue utility and size of each task are distinguished for each specific task type X and determined from their respective conversion functions,V^(X)andxˆ(X). Therefore,V^i=f̃V^i(Xi)andxˆi=xit0i=f̃xˆi(Xi)are the respective general conversion functions for the revenue utility and initial size for each taski∈A, where A is the set of all tasks that arrive to the system.Once a new task has arrived, the agent-specific information for task i at any time t is characterized byϒi(t)and may include the task typeXi, the number of units remaining to be processedxi(t), and the expiration timeTi(i.e., the final point in time that the task may be allocated to the resource for processing). To accommodate more detailed systems, letΞc=Ξc(t)represent each entity c in the system at time t. These entities may include the resource or various queue positions andc∈C, where C is the set of all entities. Given the system dynamics, letΞ̇represent the rate of expected change in entity states over the time period(t,t+dt). Thus,Ξ̇is a function of both the new task arrival rate λ and the resource process rate standard deviation σ; and the overall expected change inΞ̇over(t,t+dt)is(2)dΞ=Ξ̇·dtBecause an agent’s decision policy may be dependent on the state of multiple variables, letY(t)be defined as the collection of any pertinent state variables at time t. For this system, letY(t)=(R(t),ϒ(t),Ξ(t)). This system state structure allows for the model to incorporate all of the pertinent real-time information for each agent and system entity.Task agents develop their options-based task allocation exercise policy to determine the optimal decision based on the current and expected future states of the system. This policy is constructed to hedge the impact of future state uncertainty due to both (1) the stochastic resource process rateR(t), and (2) the threat of preemption from a higher valued task that may arrive during the time period(t,t+dt). This flexible decision policy is based on the appropriate termination valueΩ[Y(t),t], continuation valuef[Y(t),t], and resulting option value when using the Bellman equation (see Eq. (3)).Now that the sources of system uncertainty have been identified, it is important to demonstrate how these fluctuations impact the behavior of the task agent. Each task i enters the system at timet0iwith the task agent’s goal of having it processed by the resource for an ultimate terminal payoff utility. This task allocation opportunity value is now written asF[R(t),Ξ(t),t]and may be evaluated using the Bellman equation(3)F[R(t),Ξ(t),t]=maxΩ[R(t),Ξ(t),t],11+ρdtE[F(R+dR,Ξ+dΞ,t+dt)|R,Ξ]where R and Ξ change to(R+dR)and(Ξ+dΞ), respectively, over the small time interval of length dt as given by Eqs. (1) and (2), respectively. The first term on the right-hand side of Eq. (3) represents the termination value and the second term represents the continuation value when discounted at the agent-specified discount rate ρ.Because the net utility value earned by the task agent is a function of the time that it takes the resource to process the task, the utility function has been generally specified asΩ[Xi,R(τ),τ]. Upon exercise of the option, the task agent is guaranteed the following net utility value associated with the process rate at time τ(4)Ω[Xi,R(τ),τ]=V[Xi,R(τ)]-∫t0iτw(s)dswhereΩ[Xi,R(τ),τ]is the net payoff if the option is exercised at time τ, for a guaranteed rateR(τ), and task typeXi;V[Xi,R(τ)]is the net known utility revenue gained by this agent; and∫t0iτw(s)dsare any applicable penalty waiting costs incurred prior to the exercise of the option. Note that Eq. (4) can be written in a more general form with[·]=[Y(t),t]orX=Xi.Because the ultimate payoff utility is a function of the guaranteed process rate, there is an incentive for the task agent to wait for a more beneficial process rate that would lead to lower processing costs and more timely delivery (i.e., thus yielding a higher value ofΩ[Xi,R(τ),τ]), but at the penalty of forgoing other production opportunities or potential risk of being preempted by the future arrival of tasks deemed by the resource agent to be of a higher priority. The goal for the task agent is to determine the critical process rate (designated asR∗(t)), for any given amount of time in the system, where it is optimal to exercise the allocation option and request processing as opposed to holding it and waiting for a better guaranteed process rate.The governing partial differential equation for the task allocation opportunity value is now constructed using the approach presented in Dixit and Pindyck (1994). For notational simplicity, the derivation may representF[R(t),Ξ(t),t],R(t), andΞ(t)asF,R, and Ξ, respectively. If the option is not exercised at any given point in time t, then the change in the value of the task allocation opportunity over the time interval of length dt is(5)dF=∂F∂RdR+∂F∂ΞdΞ+∂F∂tdtBecauseR(t)is an Ito process, Ito’s Lemma may be used to determine the differential in the option value (i.e., dF) over dt. Using Ito’s Lemma, substituting Eqs. (1) and (2), recognizing thatE[dF]over dt must earn the agent-specified discount rate ρ, and assuming that R lies within the continuation region, Eq. (5) may be modified to yield the following partial differential equation that is satisfied byF[R(t),Ξ(t),t]:(6)12σ2RFRR+η(R‾-R)FR+Ft+Ξ̇FΞ-ρF=0subject to the following boundary conditions:(7)F[R(T),Ξ(T),t=T]=ζ(8)F[R∗(t),Ξ(t),t]=Ω[R∗(t),Ξ(t),t](9)FR[R∗(t),Ξ(t),t]=ΩR[R∗(t),Ξ(t),t]The terminal boundary condition is presented in Eq. (7) and indicates that the task agent may be subject to a penalty cost ζ if it allows the option to expire at the maturity date T (i.e., the task never gets submitted for processing). The boundary conditions of Eqs. (8) and (9) represent the “value-matching” and “smooth-pasting” conditions as described in Dixit and Pindyck (1994). For this paper, the task agent’s allocation option value and decision policy was solved using a numerical approximation method presented in Hull and White (1990).Whereas the termination value is given by Eq. (4), determining the continuation value is more complicated and must account for each possible system scenario. If a current task i decides to postpone its allocation decision from time t untilt+dt, the following three possible scenarios may exist:1.No new task arrival (Case 1). If no new task arrives during(t,t+dt), then the current task i may either exercise its option at timet+dtor continue until timet+2dt. Because tasks arrive according to a Poisson process of rate λ, this scenario occurs with a probability of(1-λdt)over the time interval of length dt. The discounted continuation value for this case is(10)f1[Y(t),t]=11+ρdtE[F(Y(t+dt),t+dt)|Y(t),t]whereE[F(Y(t+dt),t+dt)|Y(t),t]is the expected value of the option at timet+dtgiven the current system state conditions.Arrival of a lesser (or equal) valued task (Case 2). There may be an arrival of a task j whereXj⩽Xi; the value of this new task does not exceed that of the current one. Assuming that only a higher valued task will cause preemption, the current task i will then retain the right to either exercise its option at timet+dtor continue until timet+2dt. This result is equivalent to the situation where no new task arrives (i.e., Case 1) and occurs with a probability ofλdt·P(Xj⩽Xi). The discounted continuation value for this case is equivalent tof1[Y(t),t]and is rewritten here as(11)f2[Y(t),t]=11+ρdtE[F(Y(t+dt),t+dt)|Y(t),t]Arrival of a higher valued task (Case 3). A task j may arrive to the system such thatXj>Xi, with an occurrence probability ofλdt·P(Xj>Xi). Consequently, this task j is of higher value and will preempt the current task i for a time period dependent onXjandE[R(t+dt)|R(t)]. For this case, the expected continuation value at timet+dtmust be calculated. This expected continuation value is necessary because of the heterogeneity in arriving task types and the duration of any resulting resource blockage is dependent on both the arriving task type and the expected process rate quoted upon arrival. So, the discounted continuation value for this case is written as(12)f3[Y(t),t]=11+ρdtE[fb(t+dt)|Y(t),t]whereE[fb(t+dt)|Y(t),t]is the expected overall continuation value due to blocking at timet+dt.Because the resource only accepts new tasks for processing at discretized time periods, it is important to evaluate any potential resource blocking scenarios when determining this continuation value. Given the assumption that tasks arrive randomly according to a Poisson distribution of rate λ and, once arrived, the task type is drawn from the distributionf̃(X), the expected blocking time for each task type and associated process rate must be determined. This model accommodates heterogeneous task types and incorporates their respective preemption impact by evaluating the blocking time (and discretized time periods) as a function of the process rateR(t), task type X, and corresponding initial task sizexˆ.First, letMbmax=Mbmax[f̃(X),R(τ)]be the maximum number of blocking periods given that a task of typeXmax(f̃(X))is guaranteed a rateR(τ), and the allowable allocation times are discretized in intervals of length dt. (Note that, for simplicity, the convention used in this paper is to usedt=Δtto represent both continuous and discretized time interval lengths). Then,(14)Mbmax[f̃(X),R(τ)]=xˆmax/R(τ)dt+whereMbmaxisxˆmax/R(τ)dtrounded up to the nearest integer;Xmax=Xmax(f̃(X))is the maximum task type given the task type distribution functionf̃(X), andxˆmax=xˆmax(Xmax)is the respective maximum task size. LetXˇ(t,t+dt)indicate the task arrivals during the time period(t,t+dt)(i.e.,Xˇ(t,t+dt)=0if no arrival;Xˇ(t,t+dt)=Xjif a task j arrives). Then, letPb(Xi,f̃(X))=P(Xj(t+dt)>Xi(t)|(Xˇ(t,t+dt)>0))be the probability that task i is blocked by an arriving task j at timet+dt, given that task j arrives during(t,t+dt).It is now necessary to determine the task type cutoff points that distinguish each blocking period value. IfMbmax=1, then blocking occurs for only one period and no additional cutoff information is needed. However, ifMbmax>1, then the blocking cutoff task type values for each possible number of blocking time periodsMb=Mb[X,R(τ)]must be calculated, whereMb∈(1,Mbmax). LetX‾j(Mb)be this cutoff point for an arriving task j andMbblocking periods. Therefore,(15)Mb[Xj,R(τ)]=xˆj(Xj)/R(τ)dt+is the number of blocking time periods rounded up to the nearest integer, and at the exact cutoff point(16)Mb[Xj,R(τ)]=x‾j(X‾j)/R(τ)dtThen, rearranging Eq. (16) and solving forx‾j(X‾j)yields(17)x‾j(X‾j)=Mb·dt·R(τ)which represents the size of an arriving task j at the exact cutoff point for a blocking time period ofMb. The corresponding task type at this cutoff point is then evaluated using the inverse functionX‾=f̃-(x‾)and, more specifically,X‾j=f̃-(x‾j)for task j.Finally, the probabilities associated with each possible blocking scenario are determined based on the distribution of arriving task typesf̃(X)and the system’s task preference criteria. Note that this process is illustrated in Ball (2007) and Appendix B (online only) for a specific example system wheref̃(X)follows a standard uniform distribution (i.e., minimum 0; maximum 1) and the utility relationship isU(Xj)>U(Xi)ifXj>Xi.A general solution algorithm has been developed based on this task agent policy using a recursive stochastic dynamic programming approach and is presented in this section. The allocation option for any eligible task i, wherei∈A, may be requested for exercise by the task agent at any eligible time during the period(t0i,Ti). (Note that an eligible task is defined as the highest valued task in the queueing system based on the resource’s task preference; and, the resource is empty and available to accept a task for processing). So, ift=Ti, then the allocation option for task i has expired and the resulting value isF[Ti]=f[Ti]=ζi, wheref[Ti]is the discounted continuation value at timeTi, andζirepresents a terminal boundary condition value for task i (i.e., any penalty cost incurred for not allocating the task for processing). In addition,ft→Ti(t)is defined as the discounted continuation value if resource blocking is expected to cause continuation from time t until at least the expiration date. Because the option expires at timeTi, this situation results inft→Ti(t)=f[Ti]and, as previously noted,f[Ti]=ζi.At timest0i⩽t<Ti, an eligible task agent i may either request to exercise its allocation option or postpone this decision until timet+dt(unlesst=Ti-dtwhen continuation will lead to the expiration timeTi). Exercising the option will yield the termination valueΩ[R(τ),τ,Xi]as calculated using Eq. (4).Continuation will lead to one of the three cases presented in Section 3.3.1, with respective discounted expected continuation values off1,f2, andf3evaluated using Eqs. (10)–(12), respectively. The discounted continuation value without any new task arrival (i.e., Case 1,f1) and with the arrival of a lower valued, non-blocking task (i.e., Case 2,f2) are equivalent and evaluated using Eqs. (10) and (11), respectively (i.e.,f1=f2=11+ρdtE[F(t+dt)|Y(t),t]).The continuation value with the arrival of a blocking task (i.e., Case 3,f3) requires the calculation of the expected continuation value for all possible blocking scenarios. For this case, it may be possible to be blocked either until the task’s expiration date, or for a lesser time period that still allows for the current task i to be processed prior to its expiration date. The discounted value of continuing until expiration (i.e., expected blocking at least until the task’s expiration date) is evaluated from(18)ft→Ti(t)=11+ρdtE[ft→Ti(t+dt)]whereE[ft→Ti(t+dt)]is the expected continuation-to-expiration value next period (i.e.,t+dt).It is also possible that blocking will occur for a time period that ends prior to the expiration date and the task agent may retain the opportunity to allocate the task at some time period in the future. In this case, it is necessary to evaluate the continuation value for each possible number of blocking periods. Definefb,Mb(t)as the continuation value at time t if the resource is blocked forMbperiods. Now, the expected overall continuation value with blocking is necessary for use with Eq. (12) because it is not known in advance what type of task will actually arrive and preempt the current task. Because the blocking time is a function of the task type (see Eqs. (15) and (16)), the expected blocking time is required and already factored into the next-period expected continuation value due to blocking (i.e.,fb,Mb(t+dt)).The continuation value for a given number of blockage periods is dependent on both the number of blocking periodsMband the current process rateR(t). IfMb=1, then blocking occurs for only one period and the associated continuation value is equivalent to the general continuation value for this period,fb,Mb=1(t)=f[Y(t),t]. However, ifMb>1, then blocking will occur for more than one period and there are two possible scenarios. First, ifTb[Xi,R(τ)]⩾Ti-t, then blocking will occur at least until expiration (whereTb[Xi,R(τ)]is the total blocking time for task i’s typeXiand a guaranteed process rateR(τ); andTi-tis the time remaining until task i expires), andfb,Mb(t)=11+ρdtE[ft→Ti(t+dt)]. However, ifTb[Xi,R(τ)]<Ti-t, then the respective preemption duration will end prior to the task’s expiration date andfb,Mb(t)=11+ρdtE[fb,Mb-1(t+dt)], whereE[fb,Mb-1(t+dt)]is the expected continuation value next period (i.e.,t+dt) if blocking occurs for the remainingMb-1time periods. The overall expected continuation value due to blocking at time t is then calculated from(19)E[fb(t)]=∑Mb=1MbmaxPb(Mb|Y(t))·fb,Mb(t)wherePb(Mb|Y(t))is the probability of the resource being blocked forMbtime periods given the system state and dynamic parameters, andfb,Mb(t)is the respective impact on the continuation value. Using this information and given the current task typeXiand system dynamics (i.e.,f̃(R),f̃(X),λ), the recursive dynamic programming algorithm may be used to numerically solve for the current period continuation value using Eq. (13).The overall option value at any time may then be evaluated using the Bellman equation presented as Eq. (3), which is restated here asF[Y(t),t]=maxΩ[Y(t),t],f[Y(t),t]whereΩ[Y(t),t]is the termination value calculated from Eq. (4) andf[Y(t),t]is the expected continuation value determined from Eq. (13). The optimal options-based task allocation exercise policy for any taski∈Amay then be determined by solving the system of equations and the Bellman equation forR∗(t)at all timest0i⩽t⩽Ti. The reader is referred to Ball (2007) and Appendix B (online only) for specific details pertaining to the task agent’s policy for the example system tested in this paper.The resource agent constructs its decision policy in such a manner that extracts value from the endogenous nature of its source of performance uncertainty and improves its ability to maintain a stable operational system. For any given time t that the resource is unoccupied and an eligible task (i.e., the highest valued task currently in the queue) agent i requests to exercise its allocation option, the resource agent must evaluate its option to either (1) accept the current task for processing, or (2) postpone processing and wait until a future time(t+dt)and observe both the changes in the system stateY(t)and the associated expected impact any changes have on its expected utilizationΔE[U∼]. Note that, although there may be an endogenous relationship between many types of performance metrics, the act of planning for increased utilization is most appropriate for the system explored in this paper. For this reason, only the resource utilizationU∼(and associated idleness costs) are included in the resource agent’s policy. The same theoretical approach, however, may be used to include planning for other performance cost metrics, such as overtime costs.This resource decision is based on the relationship between the task type X and the resource’s utility preference (i.e.,U(Xj)>U(Xi)ifXj>Xi) and performance stability (i.e.,dσdX<0). It is further assumed that the resource agent bases its decision on the fact that it will either begin processing a task at time t or timet+dt, but not at both times. This assumption provides a conservative measure of task processing that may be representative of various resource limitations, such as the supply of raw materials, manpower, or excess start-up costs.Letψ(t)be a resource decision indicator, whereψ(t)=0if the resource postpones processing at time t andψ(t)=1if the resource accepts the current task agent’s request for processing at time t. The value ofψ(t)is chosen by the resource based on a comparison of the expected impact on its utilization if it either accepts or rejects the current task’s (i.e., task i) request for processing. If the resource accepts task i’s request for processing at timet=τ, thenψ(t)=1and(20)E[U∼i(t)|ψ(t)=1,Y(t)]=xˆi(Xi)/R(τ)Tb,iwhereE[U∼i(t)|ψ(t)=1,Y(t)]is the expected utilization impact on the resource over the time period(t,t+Tb,i)if it accepts the current task i at timet,xˆi(Xi)is the initial size of taski,R(τ)is the guaranteed process rate at time τ, andTb,i=Tb,i[Xi,R(τ)]is the expected resource utilization (blockage) time when processing task i.If the resource decides to postpone the processing decision from time t untilt+dt, thenψ(t)=0and the expected utilization impact is designated asE[U∼(t+dt)|ψ(t)=0,Y(t)]. This impact is dependent, however, on whether or not a new task arrives during(t,t+dt)as well as the expected system state at timet+dt(i.e.,E[Y(t+dt)|Y(t)]). LetXˇ(t,t+dt)=0if no new task arrives during(t,t+dt); andXˇ(t,t+dt)>0if a new task does arrive during(t,t+dt). Given that new tasks arrive to the system according to a Poisson process of rate λ, the probability that an arrival occurs during the time interval(t,t+dt)isλdt; likewise, the probability that no arrival occurs during(t,t+dt)is(1-λdt). Therefore,E[U∼(t+dt)|ψ(t)=0,Y(t)]is calculated using the expected impact of both scenarios and is expressed as(21)E[U∼(t+dt)|ψ(t)=0,Y(t)]=(1-λdt)·E[U∼(t+dt)|ψ(t)=0,Y(t),Xˇ(t,t+dt)=0]+λdt·E[U∼(t+dt)|ψ(t)=0,Y(t),Xˇ(t,t+dt)>0]whereE[U∼(t+dt)|ψ(t)=0,Y(t),Xˇ(t,t+dt)=0]andE[U∼(t+dt)|ψ(t)=0,Y(t),Xˇ(t,t+dt)>0]represent the impact on the expected resource utilization given that the resource postpones processing at time t and there are either no new task arrivals or a task arrival, respectively, during the time period(t,t+dt).The resource agent evaluates both the system impacts if it were to accept or postpone the processing decision (E[U∼i(t)|ψ(t)=1,Y(t)]andE[U∼(t+dt)|ψ(t)=0,Y(t)], respectively) and selects the decision indicator such that(22)ψ(t)=0,ifE[U∼i(t)|ψ(t)=1,Y(t)]<E[U∼(t+dt)|ψ(t)=0,Y(t)],or1,ifE[U∼i(t)|ψ(t)=1,Y(t)]⩾E[U∼(t+dt)|ψ(t)=0,Y(t)]So, the resource agent will accept the task agent’s request to exercise its allocation option provided that the expected impact on its utilization is non-negative. The reader is referred to Ball (2007) and Appendix C (online only) for specific details pertaining to the resource agent’s policy for the example system tested in this paper.Although both the task and resource agents make their decisions to hedge the impact of system uncertainty, this model also accounts for the actual costs that occur once these decisions have been made and the system evolves. Thus, although a task agent exercises its allocation option and is assured a guaranteed process rateR(τ)and associated delivery time, the actual time that the task will be completed is still unknown due to processing uncertainty. Consequently, various system costs will also be unknown (i.e., the resource idleness costs or overtime costs incurred to assure that the quoted delivery date is satisfied). As the system process capacity evolves according to the distribution ofR(t), the task request will be processed and these system performance costs will be realized.Let the total actual performance cost (designated as Θ) experienced by the system for a time horizon(t0,t)be represented by(23)Θ((t0,t)|Y(t0,t))=∑z=1Zθz(t0,t)whereθz(t0,t)is the performance cost metric z (e.g., idleness, overtime) accumulated over this time range(t0,t),z={1,…,Z}, and Z is the total number of performance cost measures.It should now be recognized that there may be an indirect relationship between these system performance costs and the future stability of the production system. A stable system in this case may be one that consists of lowered and/or more constant levels of production rate uncertainty. It may be noted that each of these costs does not merely represent an exogenous effect of the process uncertainty, but also possesses a direct impact on the evolution of this uncertainty.Therefore, it may be deduced that some systems will yield more stable production systems if these performance costs are reduced (i.e.,dσdΘ>0). The recognition of this relationship provides the resource with a means of basing its processing decisions on their expected impact to future production stability, and allowing for a policy that both responds to, and controls, the underlying source of system risk. Given the relationship between task size and task type (i.e.,x(X)), and the nature of the system, it may be observed that higher valued tasks will reduce the system performance costs (i.e.,dΘdX<0) and result in more stable production systems (i.e.,dσdX<0). Therefore, it may be assumed for this system that σ is monotonically related to both Θ and X (i.e., σ is monotonically increasing with respect to Θ and decreasing with respect to X). This relationship supports the notion that the resource agent will prefer higher valued tasks; thus,U(Xj)>U(Xi)ifXj>Xi.In order to model this endogenous impact between system performance costs and σ, let n denote a time interval index such thatΘn=Θ((tn,0,Tn)|Y(t-dt,t))andtn,0=Tn-1. Based on the understanding that the system’s current performance uncertainty may be a function of its recent stability performance (i.e.,σn=fn(Θn-2,Θn-1,σn-1)), define the current level of uncertainty to be(24)σn=γ(Θn-2,Θn-1)·σn-1whereγ(Θn-2,Θn-1)is a specified multiplicative factor. Thus, the system’s current and future levels of operational stability are based on previous periods’ performance metrics. This linkage provides for the recognition that the agent decisions may be made to both respond to, and control the future propagation of, system uncertainty and corresponding risk.As the model is applied to multiple time periods, the level of risk in the system should approach an equilibrium value. Now, if both agents act consistently with their respective optimal decision policies, this equilibrium state may be representative of a Nash equilibrium.This section presented both task and resource agent policies to manage their respective risks, and an overall process to reach system equilibrium. The solution algorithm developed in this section is summarized in Algorithm 1 to highlight the overall flow of logic and the ordering of different decision processes.Algorithm 1Distributed options algorithm for task/resource allocation system

@&#CONCLUSIONS@&#
The primary objective of this paper was to develop a distributed decision-making approach that manages risk from a multi-agent perspective in large-scale engineering and operational systems, and improves both agent and system performance utilities under resource capacity constraints. The general approach used to develop the theoretical models for this paper was based on the intersection of engineering and operational systems management, the concept of dynamic flexibility using options-based decision policies, and game theory. The effect of managing the impact of multiple sources of uncertainty from a distributed decision-making perspective was evaluated with respect to improvements in both agent utilities and system properties while adhering to any limited and finite capacity resource constraints. By properly identifying an agent’s decision options and the relation to any underlying exogenous or endogenous system uncertainties, a wide range of resource-constrained domains may be modeled and solved using the distributed, options-based framework developed in this paper. Possible application domains include the management of engineering and system design processes, new technology development, enterprise systems, homeland security, healthcare systems, emergency preparedness and response systems, global operations, and supply chain networks.The theoretical model developed in Section 3 was tested using a case study in Section 4. A primary contribution of this paper is to present a distributed decision-making model that manages the impact of uncertainty from a multi-agent perspective. In an effort to avoid limiting the model to the rare situations where conditions suitable to utilizing Black–Scholes options pricing techniques may be appropriate, this new model has been developed to be flexible so that it may be modified and applied to a much wider scope of real system domains. Because each of these domains may require unique modifications to the model, the general model developed in this paper was tested numerically in Section 4 and the ultimate findings should be translatable to a much wider range of technology and operations management systems.Supplementary data associated with this article can be found, in the online version, at http://dx.doi.org/10.1016/j.ejor.2014.05.037.