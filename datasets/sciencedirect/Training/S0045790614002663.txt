@&#MAIN-TITLE@&#
Multi-modal decision fusion for continuous authentication

@&#HIGHLIGHTS@&#
Behavioral biometrics: keystroke dynamics, mouse movement, stylometry.A parallel binary decision fusion architecture with 11 sensors.A dataset collected from 67 users each working in an office environment for a week.Achieve below 1% error rates (FAR, FRR) after only 30s of activity.Characterize robustness of system to adversarial attacks.

@&#KEYPHRASES@&#
Multimodal biometric systems,Distributed communication,Security and privacy,Behavioral biometrics,Decision fusion,Active authentication,

@&#ABSTRACT@&#
Active authentication is the process of continuously verifying a user based on their on-going interaction with a computer. In this study, we consider a representative collection of behavioral biometrics: two low-level modalities of keystroke dynamics and mouse movement, and a high-level modality of stylometry. We develop a sensor for each modality and organize the sensors as a parallel binary decision fusion architecture. We consider several applications for this authentication system, with a particular focus on secure distributed communication. We test our approach on a dataset collected from 67 users, each working individually in an office environment for a period of approximately one week. We are able to characterize the performance of the system with respect to intruder detection time and robustness to adversarial attacks, and to quantify the contribution of each modality to the overall performance.

@&#INTRODUCTION@&#
The challenge of identity verification for the purpose of access control in distributed communication systems is the tradeoff between maximizing the probability of intruder detection, and minimizing the cost for the legitimate user in time, distractions, and extra hardware and computer requirements. In recent years, behavioral biometric systems have been explored extensively in addressing this challenge [1].Behavioral biometric systems rely on computer interface devices such as the keyboard and mouse that are already commonly available with most computers, and are thus low cost in terms of having no extra equipment requirements. However, their performance in terms of detecting intruders, and maintaining a low-distraction human–computer interaction (HCI) experience has been mixed [2], showing error rates ranging from 0% [3] to 30% [4] depending on context, variability in task selection, and various other dataset characteristics.The bulk of biometric-based authentication work focused on verifying a user based on a static set of data. This type of one-time authentication is not sufficiently applicable to a live multi-user environment, where a person may leave the computer for an arbitrary period of time without logging off. This context necessitates continuous authentication when a computer is in a non-idle state. Validated access is important on two levels: (1) locally, to protect the offline data on the computer being used, and (2) globally, to protect the data traveling on a secured distributed network of which the computer is a part of [5]. To represent a real-world scenario where such an authentication system may be used, we created a simulated office environment in order to collect behavioral biometrics associated with typical human–computer interaction (HCI) by an office worker over a typical work week.Using the data collected in an office environment, we consider a representative selection of behavioral biometrics, and show that through a process of fusing the individual decisions of sensors based on those metrics, we can achieve better performance than that of the best sensor from our sensor set. Due to their heterogeneous nature, it stands to reason that a properly designed set of good sensors would outperform a single sensor which is “best” under specific circumstances. Moreover, given the low cost of installing these application-level sensors, this approach may prove to be a cost-effective alternative to sensors based on physiological biometrics [6]. We consider twelve sensors, each falling in one of three biometrics categories: keystroke dynamics, mouse movement, and stylometry.We propose to use decision fusion in order to integrate the sensor bank and make serial authentication decisions. While we consider here specific twelve sensors, the strength of our decision-level approach is that additional sensors can be added to the sensor bank without having to change the basic fusion rule, and with only minimal performance information required about the added sensors. Moreover, it is easy to evaluate the marginal improvement of any added sensor to the overall performance of the system.We evaluate the multimodal continuous authentication system on a large real-world dataset. We consider several parameters and metrics in presenting the system’s performance. First, we look at the False Acceptance Rate (FAR) and the False Rejection Rate (FRR) when the decisions from each of the twelve sensors are combined in the decision fusion center (DFC). Second, we assess the relative contribution of each individual sensor to the performance of the overall decision. Third, we observe the tradeoff between the time to first authentication decision and the error rates. Fourth, we consider adversarial attacks on the system in the form of sensor “spoofing,” and show that the system is robust to partial spoofing.The remainder of the paper is structured as follows. In Section 2, we discuss the related work on behavioral biometrics via the modalities considered in this paper and multimodal fusion. In Section 3, we discuss the simulated work environment dataset used for training and testing. In Section 4, we discuss twelve behavioral biometrics sensors. In Section 5, we detail the fusion algorithm. In Section 6, we present the performance of this system on a 67 user dataset.

@&#CONCLUSIONS@&#
