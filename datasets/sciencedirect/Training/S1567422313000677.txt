@&#MAIN-TITLE@&#
Trust assessment of security for e-health systems

@&#HIGHLIGHTS@&#
We proposed a model for assessing the trust of the security of an e-healthcare service from an entity point of view.We introduced new trust assessment architecture of security for an entity.We proposed novel trust assessment metrics for an entity.We compared our trust model and architecture with other models in literature.We provided a case study to illustrate the applicability of our trust model and our architecture in real life.

@&#KEYPHRASES@&#
Trust,Assessment,Security,Architecture,E-health,

@&#ABSTRACT@&#
The expansive connectivity of emerging information systems has set the stage for pervasive access to healthcare services via e-health systems for selecting the best possible healthcare services. Emerging systems are expected to be highly dynamic open environments connecting diverse number of healthcare services and autonomous entities that are autonomous agents or software applications representing patients. Entities in such dynamic environments may have different security needs from e-health systems raising the challenge of trust computations regarding security. In this research, we proposed a trust assessment model of an e-health service from the viewpoint of an entity. The model contains a comprehensive architecture applicable to different types of entities, and a novel set of trust assessment metrics may be used to assess a specific property of a security system (i.e. partial metrics) or all properties (i.e. total metrics). The simulation based evaluation of proposed model in the context of a Hospital Online Appointment Service has shown that the proposed model provides better trust computation results than existing trust models for e-health systems. Furthermore, the entities are also able to assess the trust even with incomplete security information.

@&#INTRODUCTION@&#
E-health systems provide ubiquitous access to healthcare services by sharing patients data whenever necessary over an open environment like the Internet. Electronic Health Records (EHRs) improve communications between healthcare providers (Neubauer and Heurix 2011), such as medical insurance and dental insurance (Wu et al. 2012). From the clinical perspective, the communication can save lives in some emergency circumstances. Thus, e-health systems have been widely used to improve healthcare services in modern societies.Since e-health systems handle personal data, individuals’ EHRs may be subject to security and privacy attacks; yet majority of the e-health systems have significant weakness (Tejero and de la Torre Díez 2012). Revelation of information such as financial or other protected health information may result in socioeconomic losses for patients. This in turn may reduce patients’ trust in e-health systems in open environments, and they may prevent ubiquitous access to their EHRs which may result in ineffective health care delivery and pose serious health problems especially during emergency situations.Emerging e-health systems are expected to be connected in open environments that contain diverse number of healthcare services and autonomous entities. Here, an entity is an autonomous agent or a software application which represents a patient. As the diversity of services increases, trust1Trust is has various definitions in information systems, such as trust is the judgment expressed by one user about another user, often directly and explicitly, sometimes indirectly through an evaluation of artifacts produced by that user or her activity on the system (Massa 2007). In another definition, trust is the subjective probability by which an individual expects that another individual performs a given action on which its welfare depends on (Jøsang et al. 2007). These definitions shows that the term trust is defined differently even in the same context.1problems related to security issues become complex, such as trust establishment (Conti et al. 2011). Information security has been often discussed in the terms of authentication, confidentiality, integrity, and availability (Chivers 1994, Sun et al. 2008). On the other hand, trust has been investigated in various fields of science, such as philosophy and computer science (Hussain et al. 2006, Massa 2007). However, there is no consensus about trust issues.The trustworthiness of an e-health service mostly depends on its security system (Samuel and Zaïane 2012). A security system is a set of security mechanisms that are implemented according to a security policy. A security policy can be described as a collection of rules that allow or disallow possible actions, events, or something related to security (Chivers 1994, Kagal et al. 2001, Li et al. 2007). On the other hand, a security mechanism implements security policies in the system.Each entity has different trust perception factors regarding systems in open environments, such as security of e-health systems and e-commerce applications (Costante et al. 2011). Trust perception factors depend highly on subjective needs of an entity and social constraints. For instance, dental records of a patient may be private information for the patient because of insurance reasons or simply because of the perception of dental problems in the society. On the other hand, a patient may share his dental records because the records are not considered as private information by that patient. It is expected that patients may not be willing to disclose personal information more accurately or seek medical care for certain sensitive conditions if they cannot trust that their personal health information will be managed with high level of confidentiality (Avancha et al. 2012, Martí et al. 2013, Appari and Johnson 2010, Haas et al. 2011, Trcek and Brodnik 2013, Alemán et al. 2013). Actually, there are many researches and challenges on e-health security and privacy but the researches do not provide desired security level and the challenges still remain. Therefore, an entity may trust security system of e-health services according to its own needs and how it interacts with the services. The entity can make decisions for future interactions with the e-health services based on contextual needs and perceived trust. Generally, the entity may consider the security of an e-health system service and form trust before interacting with it. If an entity has higher trust on the security of e-health system, the entity will likely use the system more often which in turn may promote effective healthcare delivery and perhaps reduce healthcare costs. However, it would require trustworthy security of e-health systems (Zhang and Liu 2010). Therefore, assessing the trust of e-health system’s security from the viewpoint of an entity is critical. Furthermore, such valuation necessitates specific trust assessment architectures of entities along with precise computational models.Recently, several trust computational models have been proposed for various online business environments (Jøsang et al. 2007, Massa 2007, Yan 2007) that may be extended to assessing trust regarding the security of e-health systems. However, these trust computational models do not specifically provide solution to assess the trust from an entity point of view. Our research is motivated by this critical gap in that there is a need for trust model and trust assessment architecture for entities, where an entity can assess the trust of security of e-health system according to its own needs in the emerging open environment.In this paper, we propose an entity oriented model for trust assessment of security of an e-health system. This model is flexible in its approach and facilitates an entity to assess the trust, using a novel set of trust assessment metrics, of all properties of a security system or some properties of the security system depending on the contextual need. Further, we demonstrate the applicability of the model and evaluate its performance in the context of a case study where the behaviors of proposed metrics are analyzed under several scenarios using simulations and compared with existing trust computation models. Our simulation results suggest the proposed model performs better than existing trust computation models. In summary, the primary contributions of our research are twofold.•First, we introduced a novel trust assessment architecture accounting for complexity of health care delivery system and the diverse needs of an entity participating in the e-health system in emerging open environments.Next, we proposed two types of trust assessment metrics – partial metrics and total metrics – that offer flexibility to entity for assessing its trust level on the security system. The entity may assess either a specific property of security system (partial metrics) or all properties of the security system (total metrics) depending on the contextual needs. Subsequently, the entity may use only those security properties to which it has trust for its future interactions with the e-health system.The rest of the paper is organized as follows. Section 2 provides a brief overview of e-health, trust and different trust computation models prevalent in the e-commerce and computer science literature. Section 3 describes our proposed trust assessment architecture followed by discussion of trust assessment metrics and trust assessment process in the Section 4. Finally, Section 5 presents a case study with a simulation based evaluation in the context of an Online Appointment Service of a hospital, followed by concluding remarks in the Section 6.Healthcare organizations have changed their storage systems of health records from paper-based systems to electronic systems to provide better health care services, e-health services. Additionally, open systems like the Internet connect various e-health services (Mans et al. 2013) so service providers, such as doctors and hospitals, can share and access patients medical data remotely for increasing quality of care services (Masud et al. 2012). Therefore, Electronic Medical Records (EMR) or Health Information Systems (HIS) have been integrating in hospitals to improve the quality (Esposito et al. 2014). Actually, medical data about a patient are distributed among many e-health providers, such as different hospitals, laboratories, and doctors. An e-health system may integrate many e-health provides over different information systems to ensure access to such medical data. An abstract e-health system is shown in Fig. 1, which connects different e-health providers and e-health consumers.Initial e-health systems had limited capabilities within certain departments of hospitals and clinics, such as Dental Information System for storing and managing dental-related data. The next step was integrating medical information systems of all departments to support information sharing in the hospital as a whole. For instance, Picture Archiving and Communication System (PACS) provides an integrated image management and communication system within departments of hospital (Esposito et al. 2014). Current trend in e-health systems is to combine fragmented hospital e-health systems to be able to share medical data for ensuring high quality care services. However, there are technical, sociological, and political problems regarding sharing medical data (Tawfik et al. 2012, Khan et al. 2013, Meo et al. 2011). Various countries and institutions involve in solving social and political problems about flow of medical information among different systems and providers. There are also many approaches to solve technical challenges of e-health systems (Aragues et al. 2011). As an example, framework architecture to cope with the challenge for fast deployment of e-health services is presented in (Fengou et al. 2013). Briefly, e-health domain is a multidisciplinary area that is influenced by different scientific fields.Trust is investigated in many fields of science, such as computer science, economics, politics, sociology and philosophy (Deutsch 1958, Grandison and Sloman 2000, Jøsang et al. 2007, Misztal 1996). However, there is no agreement about the definition and properties of trust (Gollmann 2006, Massa 2007, Raya et al. 2008). Trust is also defined in different manner in the same research field, such as in computer science (Jøsang et al. 2007, Raya et al. 2008, Kuter and Golbeck 2007). For instance, Massa defines trust as the judgment expressed by one user about another user, often directly and explicitly, sometimes indirectly through an evaluation of artifacts produced by that user or her activity on the system (Massa 2007). Reliability trust is defined as the subjective probability by which an individual expects that another individual performs a given action on which its welfare depends on (Jøsang et al. 2007).There are various definitions of trust in computer science that may lead to a confusion about trust in the context of security (Gollmann 2006). Since we focus on security of an e-healthcare service from an entity point of view, we follow the trust definition in Bahtiyar and Çağlayan (2012), where trust is defined as the security expectation of an entity from a service according to available security evaluation information of that entity.Trust has three general models that determine the degree of trust relationships between two entities. The first model is the direct trust model that is established through observations (Andert et al. 2002). Trust is transmitted through other parties in the transitive trust model (Andert et al. 2002, Sun et al. 2008). The transitive trust is also referred as the indirect trust (Krukow 2006, Sun et al. 2008). The assumptive trust model is the formal name of the spontaneous trust model and it does not necessitate any validation process (Andert et al. 2002). In this model, credential may be validated implicitly. For instance, spontaneous trust model does not consider any established knowledge or credential so the confidence of an entity’s identity is not provided in this model. Our model combines the assumptive trust model with other two trust models because each entity can compute trust metrics based on its needs. An entity can validate security information according to information flow models it considers.Trust has many properties that depend on the definition of trust and the application context. For instance, two entities may have one-to-one, one-to-many, many-to-many or many-to-one trust relationships (Grandison and Sloman 2000). In our model, an entity may have any of these relationships depending on information gathering model of the entity.Trust has been investigated in different application contexts of computer science and there are many trust based solutions as in (Blaze et al. 1996, Lai et al. 2011, Lopez et al. 2010, Peng et al. 2010, Theodorakopoulos and Baras 2006, Trček 2009). Although these researches contain many contributions to trust and trust related issues, none of them presents a solution for assessing the trust of a security system from an entity point of view in e-health systems. In our model, an entity can assess the trust of the security system of a service based on its needs.Trust computation models use three kinds of information: direct information, indirect information, and existing information. An entity obtains direct information by observations that information is usually called experience. Propagated trust information is indirect information. The previously evaluated trust information in an entity is called existing trust information. A trust computation model may use any of these three information individually or a combination of them to determine the trust.Since trust computation models are constructed according to information types, obtained, extracted, and classified information are significant for an entity. Therefore, entities should process information for trust computations systematically. Trust computation architecture provides a systematic way to deal with trust information and trust computations in e-commerce and e-health systems. Some trust computation models have architectures while some of them have no architecture. Actually, trust is highly context dependent so we expect that specific trust architectures will provide better trust computations. Therefore, our trust architecture is specific to entities for e-health systems in open environments related to trust computations about security of e-health services.In e-commerce and e-health systems, entities have different trust requirements about the security of a service. Specifically, entities may need to compute trust about whole security system of a service or about some properties of the security system based on their own needs. Trust metrics are used to determine the trust in a trust computation model. Therefore, it is important for a trust model to have trust metrics that handle different needs of entities. In our model, we have six trust metrics to determine trust of a security system based on the needs of an entity.A detailed comparison of different trust computation models with respect to context, architecture, metrics, advantages and limitations is provided in Table 1. Differently from existing models, our model is specific to security context of e-health systems in emerging open environments, which is good for trust (Gollmann 2006, Jøsang et al. 2007). In contrast to most of existing trust models, the proposed model has six metrics to meet different trust computation needs of entities. Moreover, we propose entity architecture to be able to compute trust metrics systematically.E-health systems are highly context specific, where each of them may have different purposes. The purpose of an e-health system determines the security system implemented on it. Since security systems require information from many sources, the architecture of the security system of an e-health system is significant to assess the trust about the security system. A detailed comparison of trust computation models regarding security of e-health systems with respect to purpose, architecture, advantages, and limitations is given in Table 2. Differently from other trust models in e-health systems, our model has an entity centric trust computation architecture that enables the entity to represents its specific trust needs from security of e-health systems.In our model, trust assessments are carried out about the security system of a service according to needs of an entity. The proposed model contains three main components, namely an entity, a service, and a trust assessment system. The trust assessment system can be either an independent system or a part of an entity or a service.A trust assessment system (TAS) can be a system independent from entities and services. In this case, a TAS has to gather information both from entities and services by communicating with them. An entity has to submit its needs to a TAS. Moreover, the entity has to inform the TAS about its utility relations with services. Actually, the utility relation between an entity and a service is a private relation so that entity may not reveal its utility relation with the service. On the other hand, the TAS has to obtain information about security systems of services from many services. Both entities and services have to communicate with the TAS in this case, where the communication security may be an important issue. In addition, the TAS has to be a trustworthy system for entities and services, which is usually impossible for open environments.Services may assess their own trust according to their security systems by considering needs of entities from their security systems. In this case, each service has to have a TAS. Entities have to inform services about their needs from the security systems of services. Moreover, each service has to know the computation method of trust metrics for a specific entity. Similar to the independent TAS case, communication security and privacy problems may occur.In the last case, each entity has a TAS. An entity assesses the trust of a security system according to its own needs. Therefore, the entity does not need to send its private information to another party. The privacy of an entity related to computations of trust assessment metrics is preserved and communication security problems decrease. Thus, our TAS is in an entity and here we present its architecture.The environment is an open dynamic environment, where there are various numbers of entities and e-health services that run on many different platforms. For instance, entities and services may run on a PDA, a smart phone, a desktop computer, and etc. An entity can interact with many services and other entities to obtain information for trust assessments. For the sake of simplicity, only entities can obtain services in our model.Entities are autonomous agents or software applications that represent patients. For instance, an entity may be a web application interface in the Internet, where it is used by a patient. An entity may also be a software agent that is responsible to accomplish a given task autonomously.Trust assessments are carried out in trust assessment systems of entities. An entity assesses the trust of a specific e-healthcare service by considering its needs and available security evaluation information. The entity has information from different sources. Specifically, the entity obtains security evaluation information directly by observations from many services. Each service may send its security evaluation information to the entity. Additionally, old trust assessments of the entity contribute to the available information.Actually, an e-healthcare service may be willing to disclose no internal information about its own security system to entities. However, the service may give its security information to entities if the service believes that it will increase its trustworthiness on the entity so the e-healthcare service will have higher benefits. On the other hand, e-healthcare services do not need to reveal their internal information to entities in our model. An entity collects information about security systems of e-healthcare services and carries out trust assessments according to its own needs. In this paper, the definition of an entity’s own needs is all expectations of the entity from security of e-health systems regarding trust establishment.A service provides different healthcare services to entities. In this model, we are interested in security systems of e-healthcare services and e-health systems. The security system of an e-healthcare service contains a security policy, security mechanisms and action logs.A security policy shows the expected behavior of the security system of an e-healthcare service under different circumstances. For example, assume that an e-healthcare service has a password based access control mechanism. Additionally, the security policy has a rule that necessitates the length of a password to be at least x characters long. If an entity attempts to set a password that is shorter than x characters, the security mechanism has to reject the password setting.The security system contains many security mechanisms. For instance, a service may have many cryptographic algorithms for encryption of sensitive data, where each algorithm is a security mechanism. Moreover, encryption keys may be stored in a hardware module, such as in a Trusted Platform Module (TPM). A TPM is also a security mechanism in our model.Each service monitors actions of its security system so entities generate actions logs according to the monitoring process. The action logs in a service consist of information related to the security system of the e-healthcare service.The security system of an e-healthcare service is dynamic in our model. Therefore, the security policy of an e-healthcare service may change with time. Moreover, security mechanisms of the service may also vary in time.The architecture of trust assessment system consists of four layers, namely Communication Interface Layer, Information Classification Layer, Trust Assessment Layer and Decisions Database Layer as shown in Fig. 2.Communication Interface Layer is responsible to manage interactions with entities and services. It interacts with other entities and services to obtain information for trust assessments. Obtained information is submitted to Information Classification Layer. This layer receives trust assessment results from Decisions Database Layer and returns them to the entity after each trust assessment.Information Classification Layer classifies existing information in an entity. Since the trust assessment process is time dependent, information for future trust assessments has to be extracted and classified. Existing information originates from other entities and services. Moreover, the entity generates information related to security systems of e-healthcare services by its observations. Information Classification Layer also manages old trust assessment decisions for subsequent computations of trust metrics. This layer determines values of all parameters that are used for computations of trust metrics. If the values of the parameters are unknown, they are set to their default values.Trust Assessment Layer contains three systems to compute trust metrics. Trust Management System computes Partial Trust Level and Total Trust Level metrics. Confidence Management System is responsible to compute confidences of metrics that are computed in Trust Management System. Learning and Decision System computes relative trust assessment metrics according to assessed trust metrics and their confidences. Old relative assessments contribute to computations of relative trust metrics. Partial Relative Trust Decision and Total Relative Trust Decision are metrics computed in Learning and Decision System.The bottom layer is Decisions Database Layer that is responsible to store all assessments. This Layer assists Information Classification Layer to extract old assessment information. Extracted information is used to compute new values of trust metrics. Simply, Decisions Database Layer can be classified as the database of the TAS. Detailed explanation of trust assessment process according to this architecture is presented in Section 4.3.An entity can assess both the trust of a specific security property and the trust of all security properties. We define two types of trust assessment metrics, namely partial metrics and total metrics. Partial metrics are about a specific security property whereas total metrics are about all security properties of an e-healthcare service.Services may send information about their security systems to entities. Additionally, each entity observes behaviors of e-healthcare services and generates information about security systems of the services. An entity also receives information about the security systems from other entities.We represent the security system of an e-healthcare service from an entity point of view with atomic units. Each entity generates information about all atomic units of an e-healthcare service by observations and obtaining information from other entities as in (Bahtiyar and Çağlayan 2012). An entity can observe only security mechanisms of an e-healthcare service as the security system of the service. Therefore, the atomic unit representation of a security system is the representation of security mechanisms with atomic units.A set of atomic units in an entity is represented withΦ(t)={φ1,…,φn}, wheren∈Z+.φidenotes an atomic unit ofΦ(t). Security mechanisms of e-healthcare services are dynamic therefore the set representation of a security system depends on time. In our set model, t denotes the time varying property of a security mechanism from an entity point of view. For example, assume that the security system of a hospital registration serviceΦH(t)uses an encryption mechanism to store its internal data.ΦH(t)may use DES, AES128, or AES256 symmetric key algorithms for encryption. In addition, the service may use one of two different methods for authentication, which are the digital signature DSS or the password PW. In this case,ΦH(t)has five atomic units,ΦH(t)={DES,AES128,AES256,DSS,PW}.Each entity may have different granularity for the representation of atomic units due to resource costs of entities. It is expected that if all entities have different granularity of atomic units based on their needs, the atomic unit representation of a security system will lead to better computations of trust. For instance, symmetric encryptions may perform better than asymmetric ones for a resource limited entity so each encryption method has to be better represented with an atomic unit. On the other hand, another entity may have no resource limitation. Therefore, the entity may use any encryption method and all encryption methods may be represented with one atomic unit, such asΦH(t)={ENC,DSS,PW}. In this case, the atomic unit ENC represents DES, AES128, and AES256 in an aggregated form.We define totally six trust metrics for an entity. Specifically, we define trust level, confidence and relative trust assessment metrics for both partial and total metrics. Each metric is computed according to needs of an entity so the metrics are specific to the entity. Partial metrics are about a specific atomic unit and they constitute half of the metrics. On the other hand, total metrics are about all atomic units of a security system.There are three sources of information related to computations of trust metrics. Information obtained by observations and information received from other entities is the first information source. Such information depends on the subjective perception of an entity, which we call perceived information. The second information source is e-healthcare services. An e-healthcare service may send information about its security system directly to entities. The last information source is the TAS of an entity, where old assessments are stored. Each trust metric may be computed according to the three information sources. We represent these kinds of information between the same interval to be able to combine them and to compute trust metrics.We represent perceived information related to atomic unitφyof the set representation at a given time t withιx,yα(t)∈[0,1], whereφy∈Φx(t)for serviceωx. In addition, we represent perceived information related to all atomic units of serviceωxwithιxα(t)∈[0,1]. For instance, ultimate experience is a kind of perceived information.Information received from e-healthcare services contributes to the computation of trust metrics.ιx,yω(t)∈[0,1]represents information that is computed with information received from e-healthcare serviceωxaboutφyat a given time t. An entity can computeιxω(t)∈[0,1]about all atomic units ofωx.New values of trust metrics depend on their former values. Effects of former trust computations on new trust computations related to atomic unitφyis represented withιx,yχ(t)∈[0,1], whereφy∈Φx(t). Additionally, former trust computations are significant to compute recent values of total metrics. We represent such effect withιxχ(t)∈[0,1]about e-healthcare serviceωx.Values of information metrics represent the usefulness of information related to computations of trust metrics. Particularly, if a trust metric approaches to one or it is one, information has maximum usefulness for trust computations. On the other hand, low values mean that there is a lack of information or information may not be convenient for trust computations.Trust level metrics are computed in Trust Management System. Partial Trust Level of atomic unitφyis represented withγx,yPT(t)∈[0,1]at a given time t and is computed as follows, whereφy∈Φx(t).(1)γx,yPT(t)=cox,yαιx,yα(t)+cox,yωιx,yω(t)+cox,yχιx,yχ(t).Partial Trust Level metric represents the trust level assessed by a specific entity about a particular atomic unit according to all available information related to the atomic unit by omitting the confidence of the assessment. Coefficientscox,yα,cox,yω,cox,yχ∈[0,1]represent impacts of information sources related to the computation ofγx,yPT(t), wherecox,yα+cox,yω+cox,yχ=1.On the other hand, an entity uses Total Trust Level metric to assess the trust of all atomic units ofωxat a given time t. Total Trust Level about the security system of e-healthcare serviceωxis represented withγxTT(t)∈[0,1]and is computed as follows.(2)γxTT(t)=coxαιxα(t)+coxωιxω(t)+coxχιxχ(t).Total Trust Level is a metric that represents the trustworthiness of a security system according to needs of a specific entity without taking into account the confidence of the assessment. In contrast to Partial Trust Level metric, Total Trust Level metric is computed by considering all information about the security system of an e-healthcare service. Therefore, Total Trust Level metric is significant for an entity if the entity needs to assess the trustworthiness of the whole security system. Similar to coefficients ofγx,yPT(t), coefficientscoxα,coxω,coxχ∈[0,1]represent impacts of information sources related to the computation ofγxTT(t), wherecoxα+coxω+coxχ=1.Values of trust level metrics represent levels of trustworthiness. If the value of a metric is high, the security system or the atomic unit is more trustworthy. For instance, ifγxTT(t)=1, the security system of e-healthcare serviceωxhas maximum trust. Whereas, ifγxTT(t)=0, the security system ofωxhas minimum trust or no trust.An entity computes Partial Trust Level and Total Trust Level without considering the quality of these computations. Partial Confidence and Total Confidence metrics are quality metrics of Partial Trust Level metric and Total Trust Level metric, respectively. Specifically, a confidence metric represents the quality of a trust level computation at a specific time.Partial Confidence metric is the quality measure ofγx,yPT(t)at a given time t and is represented withγx,yPC(t)∈[0,1]. If perceived information, information received from an e-healthcare service, and information extracted from former assessments differ considerably related to an atomic unit, the confidence to Partial Trust Level related to the atomic unit is expected to be low.γx,yPC(t)is computed with Eq. (4).Perceived information, information received from an e-healthcare service, and information extracted from previous assessments lead to our new concept Information Difference, which is a significant issue to compute Partial Confidence metric. Information differenceiDifx,y(t)related to atomic unitφyof e-health serviceωxis computed with Eq. (3). If the three kinds of information vary too much, the value of iDif is greater than one. On the other hand, if the values of the three kinds of information are the same or they are similar, the value of iDif is zero or near zero. For instance, the upper and the lower boundaries of any information metric are one and zero in sequence. Assume that an entity hasιx,yα(t),ιx,yω(t), andιx,yχ(t). In this case, there is a maximum deviation betweenιx,yα(t)andιx,yχ(t)and betweenιx,yω(t)andιx,yχ(t)thereforeiDifx,y(t)=2. On the other hand, the maximum value of a confidence matric is one and havingiDifx,y(t)=1is enough to have minimum confidence. Therefore, we set the maximum threshold to one for information difference regarding any confidence computation.(3)iDifx,y(t)=ιx,yα(t)-ιx,yω(t)+ιx,yα(t)-ιx,yχ(t)+ιx,yω(t)-ιx,yχ(t),(4)γx,yPC(t)=0,iDifx,y(t)>1,1-iDifx,y(t),otherwise.Total Confidence metric is the quality measure ofγxTT(t)at a given time t and is represented withγxTC(t)∈[0,1]. Total Confidence is computed with Eq. (6).iDifx(t)represents information difference related to the security system of e-healthcare serviceωxand has the same properties as theiDifx,y(t). The computation ofiDifx(t)is as follows.(5)iDifx(t)=ιxα(t)-ιxω(t)+ιxα(t)-ιxχ(t)+ιxω(t)-ιxχ(t),(6)γxTC(t)=0,iDifx(t)>1,1-iDifx(t),otherwise.The computation of Total Confidence metric is the same as the computation of Partial Confidence metric. If Total Trust Level metric is computed with high confidence, Total Confidence metric is high. For instance, ifγxTC(t)=1,γxTT(t)has maximum confidence whereas ifγxTC(t)=0,γxTT(t)has no confidence.Entities are optimistic in our model in the sense that an entity should relay on its initial computations of trust if it has no previous information. Therefore, if an entity does not have both perceived information and information received from a specific e-healthcare service and if the entity does not have trust assessments information related to the security system of the service, the entity will have maximum confidence to the newly computed trust level metrics.An entity may need to consider both a trust level and its confidence to make a decision. Trust level metrics are combined with related confidence metrics and the combination is represented with relative trust assessment metrics.Similar to trust level and confidence metrics, we have two relative trust assessment metrics, namely Partial Relative Trust Assessment metric and Total Relative Trust Assessment metric. Partial Relative Trust Assessment metric represents the assessed trust of an atomic unit in an entity at a given time t. The metric contains the confidence of the assessment. Partial Relative Trust Assessment metric is represented withγx,yPR(t)∈[0,1]and is computed as follows, whereφy∈Φx(t).(7)γx,yPR(t)=κx,yγx,yPT(t)γx,yPC(t)+(1-κx,y)Ψx,y(t).γx,yPR(t)is computed according toγx,yPT(t)andγx,yPC(t). Former values ofγx,yPR(t)also affect next computations ofγx,yPR(t).Ψx,y(t)∈[0,1]represents the effect of former assessments related toφy∈Φx(t)as shown in Eq. (7). Each entity may computeΨx,y(t)differently. Each entity may also evaluate recently computed information and former assessments differently to computeγx,yPR(t). Coefficientκx,y∈[0,1]represents the significance of recent information regardingγx,yPR(t).Total Relative Trust Assessment metric represents the assessed trust related to all atomic units of a security system in an entity with the confidence of the assessment at a given time t. The metric related to e-healthcare serviceωxis represented withγxTR(t)∈[0,1]and is computed as follows.(8)γxTR(t)=∑∀φy∈Φx(t)ζx,yγx,yPR(t).γxTR(t)is the weighted sum of all atomic units of a security system, whereζx,yis called Impact Factor representing the weight. Each atomic unit has different impacts to compute Total Relative Trust Assessment metric.ζx,y∈[0,1]related to atomic unitφyis a subjective factor and it varies from one entity to another one, where∑∀φy∈Φx(t)ζx,y=1. Ifζx,y=0, atomic unitφyis not considered for the computation ofγxTR(t)in an entity. Otherwise,φycontributes to the computation ofγxTR(t)proportional to the value ofζx,y.Values of relative trust assessment metrics determine the degree of trustworthiness. For example,γx,yPR(t)>γx,zPR(t)means that atomic unitφyhas more relative trust than atomic unitφzaccording to needs of an entity.An entity can assess the trust of a security system according to its own needs. Here, we present steps of the assessment to clarify the process according to the architecture presented in Section 3.4.Step 1: (Communication Interface Layer) TAS sends a message and then receives a message to/from an e-healthcare service and an entity about the security system of a specific e-healthcare service. TAS carries out the message exchange with all e-healthcare services and entities it interacts. Then, TAS checks information completeness and freshness about the service. It determines incomplete information if exists. If there is insufficient information after the message exchange, TAS may repeat the message exchange.Step 2: (Information Classification Layer) TAS classifies information obtained by observations related to the security system. It also classifies information received from other entities related to the service. Simply, TAS classifies perceived information.Step 3: (Information Classification Layer) TAS classifies information received from the service according to needs of the entity.Step 4: (Information Classification Layer) TAS classifies previous assessments related to the security system according to present needs of the entity.Step 5: (Information Classification Layer) If information for next assessment process is incomplete, TAS uses default values for trust assessments.Step 6: (Trust Assessment Layer) TAS computes both trust level metrics and confidence metrics related to the service by considering present needs of the entity.Step 7: (Trust Assessment Layer) TAS computes relative trust assessment metrics according to recently computed trust level metrics and confidence metrics.Step 8: (Decisions Database Layer) TAS stores recently computed values of all trust assessment metrics.Step 9: (Communication Interface Layer) TAS returns values of newly computed trust assessment metrics to the entity.Trust assessment steps given here are specific for TAS that is in an entity. If TAS is outside an entity, steps of the trust assessment process will be different.Trust assessment metrics are computed according to security evaluation information. The amount of security evaluation information determines the precision of a trust assessment. Therefore, obtaining security evaluation information is the major issue that determines the complexity of trust assessments.In our model, there are three kinds of information as defined in Section 4.2. Perceived information is obtained from entities and services. The second kind of information, information received from e-healthcare services is obtained only from e-healthcare services. The entity is the source of former trust assessments. Therefore, obtaining all these types of information determines the complexity of a trust assessment.An entity interacts with other entities and e-healthcare services to obtain security evaluation information. The interaction is carried out by exchanging messages. The number of entities and the number of e-healthcare services with which the entity interacts increase the complexity of trust assessments. Letnerepresent the number of entities interacting with a specific entity and letnsrepresent the number e-healthcare services interacting with the entity. Then, the complexity of a trust assessment isO(ne+ns). Letn=ne+ns, then the complexity of a trust assessment isO(n).Each entity computes trust assessment metrics in a specific time period, for example each second. Moreover, an entity can exchange a number of messages to obtain security evaluation information both from entities and services according to the trust assessment process introduced in Section 4.3. Normally, an entity sends a message and receives a message, totally two messages per unit time, for each computation of trust metrics. Hence, the actual complexity of trust assessment isO(2n). In exceptional cases, the entity repeats the message exchange several times. Let m represent maximum number of possible message exchange in an entity. Then, the complexity of trust assessment isO(2mn).The number of former trust assessments is also significant to determine the complexity of a trust assessment. Letnfcbe the maximum number of former trust assessments related to the security system of a specific e-healthcare service in an entity. Then, the complexity of trust assessment isO(2mn+nfc).Maximum number of messages m and maximum number of former trust assessmentsnfcare constant. Therefore, precisions and complexities of trust assessments depend on n soO(2mn+nfc)=O(n). This result shows that the complexity of trust assessment increases linearly with n, which makes our model scalable.In this section, we have analyzed the proposed model with a case study. The case study has three objectives. The first objective is to illustrate the applicability of the proposed trust model on a realistic application. Hospital Online Appointment Service has been chosen as a realistic service. The second objective is to show effects of different information sources on trust computations. Therefore, the parameters in the case study have been chosen to illustrate the effects of different information sources. The last objective is to compare the proposed model, namely SecTrust, with existing models to clarify contributions of our work. We have compared SecTrust with FIRE (Huynh et al. 2004), PeerTrust (Xiong and Liu 2004), and CellTrust (Lax and Sarnè 2008) models. Additionally, the proposed trust model is an entity model so we have concentrated to compute trust metrics on an entity.The case study contains three scenarios, where an entity that represents a patient assesses the trust of the security system of Hospital Online Appointment Service. In the first scenario, the entity uses perceived information and information extracted from old assessments. In the second scenario, the entity uses information received from the service and information extracted from old assessments. In the last scenario, the entity carries out trust assessments according to all existing information. We simulated the scenarios and showed the performance results based on our proposed model. Simulations were carried out by using MATLAB R2009b version 7.9.0.529 that run on a PC with Intel Core 2 Duo E8400 3.00GHz processor and 3GB of RAM.Assume that a patient has dental problems and wants to get an appointment from the dental clinic of a hospital. The patient is a busy person and can get an appointment only by using Online Appointment Service of a hospital. There are many hospitals with dental clinics from which the patient can get an appointment. However, the patient knows that some hospitals have weak security systems of their appointment services. A weak security system may result in privacy problems. Therefore, the patient needs to assess the trust of the security system before getting an appointment.The patient has a software agent (SA) that represents herself. SA can assess the trust of a security system according to privacy needs of the patient. Then, the patient can decide whether to get an appointment or not by considering the trust assessments. SA is the entity in this case study.Assume that the entity carries out trust assessments about the security system of Online Appointment Service of Hospital A. Trust assessments are carried out according to available information. In this paper, time is discrete and increases every second by one.The entity represents the security system of Online Appointment Service of Hospital A with two atomic units{ENC,AC}. Atomic units of the security system areΦHA(t)={φ1,φ2}. ENC represents all encryption algorithms of the security system that algorithms are used to record personal data of a patient. AC represents the access control mechanism of the security system. For the sake of simplicity, we assume that the atomic unit representation of the security system does not change in the case study.We are interested in the effects of perceived information and information received from services. Therefore, we select effects of former trust assessments to be constant. Here, perceived information is computed according to the model in (Şerif Bahtiyar et al. 2010) and received information is computer according to the model in (Bahtiyar and Çağlayan 2012). Additionally, we follow the way for selecting coefficients as (Huynh et al. 2004, Lax and Sarnè 2008), since these coefficients reflect subjective behaviors of entities. Specifically, we setιHAχ(t),ιHA,1χ(t), andιHA,2χ(t)to be all 0.1. We assume that the effects of information sources are equal socox,yα,cox,yω,cox,yχandcoxα,coxω,coxχare all 1/3. We also assume that the significance of recent information is equal to the significance of old information so thatκx,yis 0.5. In addition,ΨHA,1(t)=0.05andΨHA,2(t)=0.01. Furthermore,ζHA,1=0.35andζHA,2=0.65.In this scenario, SA has no information received from Online Appointment Service and it carries out trust assessments by using perceived information and information extracted from old assessments. Therefore,ιHAω(t),ιHA,1ω(t), andιHA,2ω(t)are all zero. The aim of this scenario is to show the effects of perceived information.Each entity can compute perceived information differently by considering its own needs so thatιHAα(t),ιHA,1α(t), andιHA,2α(t)depend on entities. In this scenario, we assume thatιHA,1α(t)is between 0.3 and 0.4 andιHA,2α(t)is between 0.2 and 0.25. Only first ten values ofιHA,1α(t)andιHA,2α(t)are outside of these boundaries, because the entity learns from perceived information. The first ten values ofιHA,1α(t)are set to be 0.05, 0.09, 0.13, 0.16, 0.18, 0.20, 0.22, 0.27, 0.28, and 0.29 in sequence. And the first ten values ofιHA,2α(t)are also set to be 0.01, 0.05, 0.06, 0.08, 0.09, 0.14, 0.18, 0.19, 0.199, and 0.1992. Here,ιHAα(t)is computed as follows.(9)ιHAα(t)=ιHA,1α(t)+ιHA,2α(t)2.Initially, SA has no information related to the security system so initial trust levels are all zero as in Fig. 3a. Because SA may have different perceived information about each atomic unit, all atomic units may have different partial trust levels as expected.The effects of former assessments are 0.1 and their coefficients are 1/3 in this scenario. Therefore, trust levels are always greater than or equal to 0.03 except fort=0.In the proposed model, SA computes confidences of trust levels optimistically by considering Information Difference among the three information sources. Specifically, the confidence of a trust level is high if the entity has less Information Difference as shown in Fig. 3b. In this scenario, confidences of trust levels are inversely proportional with perceived information ifιHA,xα(t)>ιHA,xχ(t), whereφx∈ΦHA(t). For instance,ιHA,1α(t)>ιHA,1χ(t)fort>2andιHA,5α(t)>ιHA,5χ(t)fort>5as shown in Fig. 3b.Since effects of former assessments related to computations of Partial Relative Trust Assessment metrics are constant in this case study, the metric depends on its Partial Trust Level and its Partial Confidence as shown in Fig. 4a. Both Partial Trust Level metrics and Partial Confidence metrics change depending on perceived information so that Partial Relative Trust Assessment metric changes only according to perceived information. Additionally, Total Relative Trust Assessment metric is the weighted sum of all Partial Relative Trust Assessment metrics. Here, the behavior ofγHATR(t)is more similar toγHA,2PR(t)thanγHA,1PR(t)because of Impact Factors, whereζHA,1<ζHA,2.We have used Total Relative Trust Assessment metric to compare the proposed trust model with other trust models. According to comparison results, SecTrust provides higher trust values as shown in Fig. 4b. The reason for that high value is the effects of prior trust assessments in SecTrust. Specifically, we have selected initial trust values of FIRE, PeerTrust, CellTrust, and SecTrust to be zero for comparing them in a fair manner. Since the initial trust of an entity is highly subjective that depends on optimistic or pessimistic nature of the entity, it may be unrealistic to select higher initial trust values for these models. On the other hand, if initial trust values of FIRE, PeerTrust, and CellTrust were greater than zero, they would provide higher trust values than SecTrust.This scenario shows that an entity may assess the trust of a security system by using only perceived information about the security system of a service. SecTrust considers direct perceived information whereas other models use only indirect information. Therefore, SecTrust provides higher trust computations results than FIRE, PeerTrust, and CellTrust with perceived direct information and prior assessment results. For instance, FIRE combines interaction trust, role-based trust, witness reputation, and certified reputation with weighted mean, where all these parameters are constructed with indirect information and old trust values. More specifically, interaction trust depends on past experience, where the concept of experience is related to ratings, which are indirect information. In our approach, experiences are computed according to the perception of direct information in an entity. Similar to FIRE, all parameters of CellTrust contain indirect information, where the parameters are constructed with feedbacks. The perception of an entity regarding direct information is omitted in CellTrust.The goal of this scenario is to show effects of information received from a specific service regarding computations of trust metrics. Here, SA evaluates information received from Online Appointment Service for each atomic unit as shown in Fig. 5. The service may or may not send information about its security system to SA. Moreover, it may send incomplete information to SA. For example, the service sends no information to SA for0⩽t⩽5as shown in Fig. 5. The service sends information about ENC, but it does not send information about AC for31⩽t⩽40. Additionally, SA does not receive information about AC for61⩽t⩽65.The service may change information it sends to SA because of many reasons. For instance, assume that account management privileges of employees about access controls to private information of patients are a significant issue for SA. Additionally, assume that there is a rule in the security policy of Hospital A that is “if an employee is fired, her account related to the access control to patients records has to be removed within five days”. In this case, SA evaluates information received from the service for6⩽t⩽30as shown in Fig. 5. However, IT department of the hospital is not able to manage accounts of fired employees within five days. Therefore, the hospital updates its security policy, where removing an account of a fired employee is changed to be 10days. The security policy update decreases the trust to the service in SA for41⩽t⩽60as shown in Fig. 5.On the other hand, IT department of the hospital detects that some fired employees can access private information of some patients if accounts are removed after two days, which may cause problems to the hospital. Therefore, the hospital recruits additional IT specialists and updates its security policy, where the account of a fired employee is removed within one day. Effects of the last update are shown in Fig. 5 for66⩽t⩽100. Similar toιHAα(t), the entity evaluatesιHAω(t)as follows.(10)ιHAω(t)=ιHA,1ω(t)+ιHA,2ω(t)2.In this scenario, a trust level depends only on information received from the service. Therefore, Partial Trust Levels vary according to information related to corresponding atomic unit. For example,γHA,1PT(t)does not change sharply except fort=5as shown in Fig. 6a. On the other hand,γHA,2PT(t)changes sharply many times because of security policy update of the service. Since information about the security system is the average of ENC and AC,γHATT(t)depends on bothιHA,1ω(t)andιHA,2ω(t)as shown in Fig. 6a.Confidences vary according to information received from the service as shown in Fig. 6b. In this scenario,iDifHA,x(t)andiDifHA(t)depend only on information received from the service, whereφx∈ΦHA(t). For example,γHA,2PC(t)changes sharply when there are sharp changes inιHA,2ω(t). Confidences do not exceed 0.8 and trust levels do not fall under 0.1 since we set values of effects of former assessments to be 0.1.BecauseΨHA,1(t)andΨHA,2(t)are constant, Partial Relative Trust Assessments depend only on information received from the service as shown in Fig. 7a. For example,γHA,2PR(t)changes sharply many times whereasγHA,1PR(t)does not change, because of the behavior of information received from the service. SinceγHATR(t)is the weighted sum ofγHA,1PR(t)andγHA,2PR(t),γHATR(t)does not change as sharp asγHA,2PR(t). However,γHATR(t)still reflects the change of the security policy as shown in Fig. 7a.This scenario shows that an entity can assess the trust of a security system only by using information received from services with SecTrust. Since FIRE, PeerTrust, and CellTrust consider information received from other entities, their trust values are constant according to this scenario as shown in Fig. 7b.An entity can compute trust metrics more accurately if it has information from the three sources. In this scenario, SA assesses the trust of the security system by using information from the three sources. Specifically, the behavior of perceived information is the same as the perceived information in Scenario 1 and the behavior of information received from the service is the same as information received from the service in Scenario 2. Here, the average values of trust levels are higher than previous two scenarios as shown in Fig. 8a because SA has totally more information related to the security system.Since SA has information from the three sources, Information Differences vary less than previous two scenarios as shown in Fig. 8b. This means that SA has less Information Difference about an atomic unit so corresponding Partial Trust Level has a higher Partial Confidence. Fig. 8b also shows that the number of atomic units is significant for the computation ofγHATC(t)ifιHAα(t)andιHAω(t)are computed with Eqs. (9) and (10) in sequence. For instance,γHATC(t)does not change in this scenario as it changes in previous two scenarios.Similar to trust level metrics and confidence metrics, average values of relative trust metrics are higher in this scenario than previous two scenarios as shown in Fig. 9a. Information variation about an atomic unit influences both Partial Relative Trust Assessment and Total Relative Trust Assessment. For example, SA does not receive information aboutφ2from the service for31⩽t⩽40soιHA,2ω(t)=0. Therefore, bothγHA,2PR(t)andγHATR(t)decrease butγHA,2PR(t)decreases more thanγHATR(t)as shown in Fig. 9a.This scenario shows that having information related to the security system of a service from three sources ensures trust metrics to be more precise as expected in SecTrust. Therefore, if an entity has information from the three sources, the entity will provide better trust assessments. Specifically, SecTrust considers three kinds of information to compute trust metrics. If there is a lack of information from any kind of source regarding a trust metric, the corresponding metric will have less value. On the other hand, FIRE, PeerTrust, and CellTrust provide less trust and they do not reflect information changes regarding security like SecTrust as shown in Fig. 9b. The reason is that FIRE, PeerTrust, and CellTrust do not consider all the three information sources to compute trust metrics. Therefore, they do not reflect all information changes in their trust metrics. Since these models do not consider all information sources, their trust metrics have lower values with low precisions.The case study shows that the proposed model can be used either with information from one source or with information from all sources. If an entity has information about the security system of a service only from one source, the entity can assess the trust of the security system. However, the entity can get better trust assessments if the entity has information from all sources. Thus, the proposed model is convenient for entities in e-health systems, where entities are autonomous and the amount of information vary in each entity. Additionally, SecTrust better reflects information changes regarding security of e-health systems.

@&#CONCLUSIONS@&#
