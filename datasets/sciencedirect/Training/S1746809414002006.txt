@&#MAIN-TITLE@&#
Comparison of decision tree algorithms for EMG signal classification using DWT

@&#HIGHLIGHTS@&#
Decision tree algorithms are used for EMG signal classification.EMG signals are de-noised using MSPCA, and decomposed into the frequency sub-bands using DWT.Combination of DWT and random forest achieved best performance with 96.67% total classification accuracy.

@&#KEYPHRASES@&#
Electromyography (EMG),Motor unit action potentials (MUAPs),Random forest,C4.5,CART,Multi-scale principle component analysis (MSPCA),Discrete wavelet transform (DWT),

@&#ABSTRACT@&#
Decision tree algorithms are extensively used in machine learning field to classify biomedical signals. De-noising and feature extraction methods are also utilized to get higher classification accuracy. The goal of this study is to find an effective machine learning method for classifying ElectroMyoGram (EMG) signals by applying de-noising, feature extraction and classifier. This study presents a framework for classification of EMG signals using multiscale principal component analysis (MSPCA) for de-noising, discrete wavelet transform (DWT) for feature extraction and decision tree algorithms for classification. The presented framework automatically classifies the EMG signals as myopathic, ALS or normal, using CART, C4.5 and random forest decision tree algorithms. Results are compared by using numerous performance measures such as sensitivity, specificity, accuracy, F-measure and area under ROC curve (AUC). Combination of DWT and random forest achieved the best performance using k-fold cross-validation with 96.67% total classification accuracy. These results demonstrate that the proposed approach has the capability for the classification of EMG signals with a good accuracy. In addition, the proposed framework can be used to support clinicians for diagnosis of neuromuscular disorders.

@&#INTRODUCTION@&#
The electromyography (EMG) signal is a biomedical signal that consists of electrical currents generated in contraction and relaxation phase of muscles. The nervous system manages the muscle activity according to the structure. There are two types of structures which are named as anatomical and physiological. Specifications of muscles change according to the type of structure [1]. EMG signals are affected from environmental noise and signals while passing on different tissues. In addition, motor unit action potentials (MUAPs) can be affected by different signals during the signal acquisition. Besides, MUAPs provide essential information for diagnosis of neuromuscular disorders [2]. Thus, noise seriously distorts the EMG signal during the collection and recording process. These are the reasons that make EMG signal more complex and why they need to be de-noised. In our previous study, significantly better results were obtained by removing noise from the EMG signal waveform using multi-scale principal component analysis (MSPCA) technique [3].Not only de-noising methods but also feature extraction methods are effective for obtaining higher classification accuracy. In this study discrete wavelet transform (DWT) is utilized as a feature extraction method by decomposing the signal into different frequency bands. New approaches and recent improvements in signal processing techniques have made the area more practical and reliable to develop advanced EMG signal analysis [4–6]. As a matter of fact, analysis of EMG signals is becoming a new trend in biomedical signal processing by using powerful and advanced signal processing techniques. EMG signal classification with a higher accuracy is important because outcomes are crucial in clinical diagnosis of neuromuscular disorders.Classification of EMG signals by utilizing reliable and robust methods is a rising trend in biomedical engineering. Popularity of EMG signal analysis is tightly related to the usage field in real life clinical biomedical applications. Coherence between methods and techniques performs efficiently on diagnosis of neuromuscular disorders [1,7–10]. Higher classification accuracies can be obtained by readjusting used kernel parameters of the classifier [11,12]. Machine learning techniques such as artificial neural networks (ANN), dynamic recurrent neural networks (DRNN), support vector machines (SVM) and fuzzy logic systems are used for diagnosis of neuromuscular disorders [13]. Reasonable accuracy rates are obtained by applying spectrum matching and by extracting principle components [1]. Adaptive neuro-fuzzy inference system (ANFIS), multilayer perceptron neural networks (MLPNN), dynamic fuzzy neural network (DFNN) and combined feature extraction methods, such as Autoregressive, discrete wavelet transform and wavelet packed energy, presented due to their consistency in classification of EMG signals [14]. SVM classification technique optimized with particle swarm optimization (PSO) improves the accuracy of EMG signal classification [9]. Subasi et al. [15] developed a classification system with Autoregressive (AR) feature extraction method to produce inputs of feed forward error back propagation artificial neural networks (FEBANN) and wavelet neural networks (WNN) classifiers. The total accuracy for the WNN was 90.7% while 88% for FEBANN.The contribution of this paper is to investigate the classification performance of different decision tree algorithms with discrete wavelet transform (DWT) coefficients using intramuscular EMG signals for diagnosis of neuromuscular disorders. EMG signal classification accuracy improved by utilizing MSPCA de-noising and DWT feature extraction methods. The effects of different signal processing and decision tree algorithms are explained compared and discussed using different performance measures.The rest of the paper is prepared as follows: in the next section, the subjects and data are explained and different methods such as MSPCA, DWT, random forest, CART and C4.5 methods are presented. In Section 3 complete experimental results in respect to different classification accuracy measurements such as area under ROC curve, F-measure and total classification accuracy are presented. In Section 4, discussion is given on the impact of used de-noising and classification methods. Finally, the conclusions are given in Section 5.EMG signals were gathered at low voluntary and constant level of contraction which is just above threshold by using concentric needle electrode. The EMG signals were collected from five different places at deep, medium and low level of insertions. The high and low pass filters were set at 2Hz and 10kHz on the EMG amplifier which can be thought of as boundaries of data. The gathered signal contains control group, myopathy and ALS patients. The control group contains 10 normal subjects aged 21–37 years, 4 of them are females and rest are males. 6 of the 10 normal patients were in very good physical shape, and 3 of the 10 normal patients were in general good shape and the remaining one not in good shape. The myopathy group includes 7 patients. 2 of 7 are females and the rest are males who are between 19 and 63 years old. All of them had clinical and electrophysiological signs of myopathy. The ALS group includes 8 patients. 4 of 8 are females and the other 4 are males who are between 35 and 67 years old. In addition, no one in the control group had signs or history of neuromuscular disorders. The data were collected from brachial biceps and medial vastus since they were the most frequently investigated in the two patient groups [10,16]. Window length of the signal is 12,500 and sampling rate is 20,000.Multi-scale principal component analysis (MSPCA) combines the characteristics and ability of principal components analysis (PCA) to de-correlate the variables by procuring a stable interrelationship. Wavelet analysis was employed to get beneficial features and closely de-correlate the autocorrelated values. At each scale, MSPCA calculates the PCA of the wavelet coefficients and combines the results at defined scales. MSPCA is feasible for signal modeling which changes over time and frequency and it can be thought as an advantage of the multiscale approach [17].PCA method is used in numerous fields of science and engineering [10,17–23]. PCA is used to analyze shorter signal segments to improve practicality of biomedical signals like EMG [24]. This approach is applied in different studies such as data reduction, beat detection, classification, signal segmentation and feature extraction [3,25]. The expected value of processed signals can be obtained by selecting principal components (PC) based on energy features of matrices. PCA uses these matrices for signal de-noising. PCA de-noising approach can be explained as follows: holding the principal components which have the highest variance to rebuilt the decomposed signal. Meanwhile, the noise corresponding to the low variance components can deliberately be omitted hence the noise component in the observed signal is reduced. The decision of multi-scale matrices and eigenvalues includes the expected energy [10,17,21]. PCA transforms the data matrix statistically using diagonalizing method via covariance matrix. The process extracts the correlation and interrelation between the variables in the data matrices. If any similarity is detected, and if the measured and evaluated variables are related in the first few entities, system determines the correlation between the variables. The PCA method is used one by one for the coefficients at each scale [17].Multiscale PCA (MSPCA) includes the capacity, capability and characteristic of PCA to get the correlation between orthonormal wavelets and variables. The quantities of each variable or column are decomposed into its wavelet coefficients using the same orthonormal wavelet in order to combine the advantages of PCA and wavelets. Details are given in [3,17].The wavelet transform (WT) can be used as another way to describe and extract features of a waveform which changes over time. To handle this situation the waveform is divided into segments of scale instead of sections of time [26]. In wavelet transform, the capability of the transformation depends strongly on mother wavelet ψ(t) selection which is the certain function and can be represented by the following equation (1)(1)ψ(t)=1Sψt−uSwhere s used as scale and u as a translation parameter. These parameters can be produced in time with various frequencies and midpoint localities, which are called as baby wavelets or wavelet atoms. Handling of correlations at different frequencies are gained by a form of the signal x(t) with following wavelets as(2)Wx(u,S)=1S∫−∞+∞x(t)ψ*t−uSdtWT coefficients also can be used to define the frequency in the signal, thus information of the signal x(t) can be detected in time and frequency(3)(sj,uk)=(2j,k2j:j,k∈ℤ)DWT utilizes two different functions which are scaling and wavelet functions. These functions are interrelated with low- and high-pass filters. Each step combines two filters and two down-samplers. These high- and low-pass filters observe details, D1 and approximations, A1 for the first one, by using the down-sampled outputs. There are set of processes for each approximation, from A1 to A6, which are decomposition, processing and reconstruction, orderly. Details are given in [14,27,28].Features of the EMG signal can be extracted by means of discrete wavelet coefficients in time and frequency using some mathematical techniques. Signals can be characterized by their statistical information to make them more applicable. Those statistical features reduce dimensionality of the signal. Better performance is obtained by reducing dimension of EMG signal in numerous studies [14,23,28]. In this study, EMG signals are represented by using following features of coefficients c with following formulas [29]:(1)Mean of the coefficients for each sub-band.(4)Mean=∑i=1nCinAverage power of the wavelet coefficients in each sub-band.(5)Average=1N∑i=0N(ci)2Standard deviation of the coefficients in each sub-band(6)Standarddeviation=∑i=1n(ci−μ)2nRatio of mean values of neighbor sub-bands(7)Ratio=∑i=1nci/n∑j=1ncj/n1st and 2nd features are extracted for evaluation of the frequency distribution of the signal. 3rd and 4th features are extracted for the evaluation of the changes in the frequency distribution. Seven different features are extracted from (1), (2) and (3); six different features are extracted from (4). Hence, totally 27 features are extracted which consist of mean, average power of the wavelet coefficients in each sub-band, standard deviation and ratio of mean values of neighbour sub-bands. These extracted features are used on wavelet coefficients to make it more applicable and feasible [23,30–33].These features are calculated for D1–D6 and A6 which are frequency bands and used as input to classifiers [34]. Higher classification accuracy and lower computation cost are obtained with “db4” wavelet filter.The classification and regression tree (CART) is a decision tree algorithm developed by Breiman et al. [35]. CART uses a recursive partitioning technique which has splitting criteria to create nodes. Tree is built by using created and split nodes related to splitting criteria and function. Before applying the split criteria, we need to know what the best split point is. The quality of the splitting criteria is measured by a function which is obtained by processing variance function. Generated function is applied to each split point to calculate the best point for splitting [36]. Different criteria can be used to define the splits fisuch as Gini which is defined as [35]:(8)Gini(t)=1−∑ifi2CART has four process steps. First one is to build a tree by using recursive splitting of nodes where splitting criteria reached. Second one is to stop tree building process after the learning dataset fitted and formed according to the attributes. Third one is tree pruning, through cutting important nodes off to produce simpler trees. The last one is the selection of optimal tree from the sequence of pruned trees, which are not over fitting with the information when fitting with the learning dataset [37]. Efficient results are obtained by assigning minimum number terminal nodes as 2 and number of folds in cross-validation are 5 for pruning.C4.5 is a popular decision tree algorithm which is an upgraded version of ID3 decision tree algorithm that is developed by Quinlan, too [38]. ID3 is upgraded with some features such as categorization of continuous attributes, handling missing values, pruning of decision trees and rule derivation.C4.5 algorithm starts by selection of attribute to test root of the tree. Each attribute is calculated statistically to check feasibility by comparing training examples. The most proper attribute is used to test root node. Branch nodes of the root node are created after examining each potential attribute values in respect to training examples. This process is repeated for each branch node to select the most proper attribute by testing associated training examples. Essence of C 4.5 algorithm is to choose the correct attribute according to the information gain to test nodes [39,40]. Details are given in [41,42]. The confidence factor for pruning is 0.6. The minimum number of values in a leaf is 2. To reduce the error of pruning, data on the tree folded 3 times.In the area of bioinformatics and biomedical engineering, the random forest (RF) classifier, which is a set of decision trees, became a popular option in the machine learning processes. Increased use of random forest can be seen in computational biology field, owing to its advantages in dealing with limited sample size, complex data structures and multidimensional feature space [43].Random forest uses numerous independent decision trees which are created by randomly chosen variables. The independent trees are built by an algorithm. After trees are created they vote to find out the most popular class [44]. The algorithm guarantees that all trees in the forest are different. Randomness is applied in two steps. First step is to use different bootstrap sample data to build each tree. Second step is to choose a subset of predictors randomly then splitting each node of trees with the best subset instead of all predictors [45]. There are two reasons to have bootstrap step. First one is classification accuracy increment when random features are used and the second one is to reduce generalization error [44]. Random selection of splitting does better than bagging in terms of generalization error [46]. The strength of the individual tree classifiers is important on classification. Sometimes, this algorithm works better than some other classifiers such as support vector machines, neural networks and discriminant analysis [47]. Even though random forest was presented as decision trees, it can work with other classifiers. In this study, the optimum number of trees is defined as 30 for efficient results.

@&#CONCLUSIONS@&#
