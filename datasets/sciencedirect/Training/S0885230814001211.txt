@&#MAIN-TITLE@&#
Recurrent neural network language model adaptation with curriculum learning

@&#HIGHLIGHTS@&#
We propose three different types of curriculum learning for rnnlms adaptation.Sub-domain-adapted models outperform general models under oracle situation.Two heuristic methods are proposed to combine the sub-domain-adapted models.The curriculum learning methods can be used as implicit interpolations.Updating of the existing rnnlms can use curriculum learning without retraining.

@&#KEYPHRASES@&#
Recurrent neural networks,Language models,Curriculum learning,Latent Dirichlet allocation,Topics,Socio-situational setting,

@&#ABSTRACT@&#
This paper addresses the issue of language model adaptation for Recurrent Neural Network Language Models (rnnlms), which have recently emerged as a state-of-the-art method for language modeling in the area of speech recognition. Curriculum learning is an established machine learning approach that achieves better models by applying a curriculum, i.e., a well-planned ordering of the training data, during the learning process. Our contribution is to demonstrate the importance of curriculum learning methods for adapting rnnlms and to provide key insights on how they should be applied. rnnlms model language in a continuous space and can theoretically exploit word-dependency information over arbitrarily long distances. These characteristics give rnnlms the ability to learn patterns robustly with relatively little training data, implying that they are well suited for adaptation. In this paper, we focus on two related challenges facing language models: within-domain adaptation and limited-data within-domain adaptation. We propose three types of curricula that start with general data, i.e., characterizing the domain as a whole, and move towards specific data, i.e., characterizing the sub-domain targeted for adaptation. Effectively, these curricula result in a model that can be considered to represent an implicit interpolation between general data and sub-domain-specific data. We carry out an extensive set of experiments that investigates how adapting rnnlms using curriculum learning can improve their performance.Our first set of experiments addresses the within-domain adaptation challenge, i.e., creating models that are adapted to specific sub-domains that are part of a larger, heterogeneous domain of speech data. Under this challenge, all training data is available to the system at the time when the language model is trained. First, we demonstrate that curriculum learning can be used to create effective sub-domain-adapted rnnlms. Second, we show that a combination of sub-domain-adapted rnnlms can be used if the sub-domain of the target data is unknown at test time. Third, we explore the potential of applying combinations of sub-domain-adapted rnnlms to data for which sub-domain information is unknown at training time and must be inferred.Our second set of experiments addresses limited-data within-domain adaptation, i.e., adapting an existing model trained on a large set of data using a smaller amount of data from the target sub-domain. Under this challenge, data from the target sub-domain is not available at the time when the language model is trained, but rather becomes available little by little over time. We demonstrate that the implicit interpolation carried out by applying curriculum learning methods to rnnlms outperforms conventional interpolation and has the potential to make more of less adaptation data.

@&#INTRODUCTION@&#
The task of statistical language models is to judge whether a sequence of words is well formed or not. Conventional n-gram language models factorize the joint probabilities of all the words in a sequence into a product of probabilities of each word given information about its history, i.e., the preceding n−1 words. By using word histories, n-gram language models capture local regularities of languages. However, n-gram language models can only exploit an n-gram if the exact string of n words is present in the training data. As n grows large, the chance that an n-gram seen in the target data was also present in the training data falls off sharply. For this reason, conventional n-gram language models easily suffer from data sparseness. In practice, the history length n−1 that can be effectively exploited is quite limited. For this reason, n-gram language models lack adequate means to model long-distance dependencies.These known shortcomings are addressed by Recurrent Neural Network Language Models (rnnlms). Recently, rnnlms have been demonstrated to outperform n-gram language models for speech recognition (Mikolov et al., 2010). Their superior capabilities rely on two mechanisms. First, rnnlms map the discrete word-based vocabulary into a continuous space. As a result, the model can exploit word sequences which are similar, without requiring them to be exactly identical. This mechanism helps to reduce the effect of data sparseness. Second, rnnlms are explicitly equipped to handle long-distance dependencies. The recurrent loop in their architecture constitutes a memory that allows them to model arbitrarily long word histories theoretically.In this paper, we investigate language model adaptation for rnnlms, and specifically address two central challenges for language model adaptation, within-domain adaptation and limited-data within-domain adaptation, originally identified by Rosenfeld (1994) and explained later in depth. The main contribution of this paper is to demonstrate that curriculum learning is an important technique for carrying out the adaptation of rnnlms and to provide insights on how it must be applied in order to be effective for improving speech recognition.Curriculum learning applies a specific, well-planned ordering of the training data, referred to as a ‘curriculum’, during the learning process and is an established approach in the machine learning community. When conventional n-gram language models are trained, the order in which the training data is processed has no impact on the outcome of the training process. In contrast, neural networks are indeed sensitive to the differences in the order in which the training data is presented to them. The work of Bengio et al. (2009) attributes the benefits of curriculum learning in neural network training to an ability of the curriculum to guide the learner, in particular, directing it away from inappropriate local minima and towards more suitable ones.The advantages that curriculum learning offers to rnnlms for speech recognition have been previously established in the literature (Mikolov et al., 2010, 2011). The previous work has focused on dynamically updating language models during the recognition process (Mikolov et al., 2010) and in optimal reduction and sorting of the training data (Mikolov et al., 2011). The existing work points out that training data presented later in the training process has more influence on the final form of the model than the initial part of the training data. As such, curriculum learning can be used to accomplish an implicit interpolation of the training data, where certain parts of the data are given more importance than others.The specific issue of adaptation is particularly important for rnnlms, and as such deserves dedicated attention. A key reason for its importance is the relatively high cost of training rnnlms, which can be attributed to a range of factors. Here, we mention in particular the fact that the whole training set is usually presented to the model multiple times (referred to as ‘training epochs’). The relatively high cost of the training phase of rnnlms means that retraining the language model whenever new training data becomes available is prohibitively costly.Curriculum learning has several distinction advantages to offer for the adaptation of rnnlm to specific sub-domains. First, curriculum learning provides a method to effectively carry out implicit interpolation that does not require the parameter optimization needed for conventional interpolation. Second, as has been pointed out by Iyer et al. (1994), Iyer and Ostendorf (1999), and, more recently, by Mikolov and Zweig (2012), one danger of adaptation models that build individual component models on data sub-sets is fragmentation. Fragmentation refers to the fact that as more and more component models are built, relatively less data is available to train each. Using curriculum learning to train sub-domain adapted rnnlms neatly circumvents the fragmentation issue. All training data can be used to train each adapted model; it is the order in which the data is presented to the model during training that makes the difference. In short, although the potential of curriculum learning for rnnlms has been established and offers clear advantages, the challenges of curriculum learning to language model adaptation for rnnlms remains nearly entirely unaddressed. The purpose of this paper is to fill that gap.The key insight of this paper is that in order to carry out adaptation, curriculum learning should be used to train language models from general patterns, characteristic of the training data as a whole, to specific patterns characteristic of one specific sub-domain of the overall data. The move from general patterns to specific patterns can be viewed as a special case of a move from simple patterns to complex patterns, discussed in the literature, e.g., by Elman (1993).We propose three types of curricula created with three different strategies: Start-from-Vocabulary (Start-Vocab), Data sorting (Data-Sort) and All-then-Specific (All-Specific). Our experiments are designed to give insight into which types of curriculum learning are best in which situations and which other factors influence the performance of curriculum learning for rnnlm adaptation. When rnnlms are applied in practice to improve speech recognition, they are usually applied to the task of rescoring the N-best output produced by a speech recognizer that has carried out an initial pass over the spoken data. For this reason, all our experiments either produce word prediction results or rescoring results.Our first set of experiments addresses the challenge of within-domain adaptation. As characterized by Rosenfeld (1994), within-domain adaptation can be used to deal with heterogeneous data sets that contain different sub-domains. Different sub-domains are characterized by different word-usage patterns, which are, in turn, reflected by different n-gram distributions. For example, in the Spoken Dutch Corpus which is described in detail later, different speech styles (e.g., spontaneous conversation, lecture and read speech) form different sub-domains. Note that we focus our investigation on within-domain adaptation rather than cross-domain adaptation, since, as mentioned by Rosenfeld (1994), it is relatively rare that a speech recognizer would be trained on one domain and used in a different one. Under the within-domain adaptation challenge, the totality of the training data becomes available at the same time, and the goal is to create models that are adapted to specific sub-domains.Our first within-domain adaptation experiment investigates the oracle situation in which sub-domain information is known during both training and testing. This experiment demonstrates that sub-domain-adapted rnnlms indeed outperform both general rnnlms as well as rnnlms that have been adapted to the sub-domain using linear interpolation between the general model and a sub-domain specific model. The second experiment investigates the situation in which sub-domain information is known during training, but unknown during testing. Here, we investigate two methods of combining sub-domain-adapted rnnlms. The third experiment investigates the situation in which no sub-domain information is known for either training or testing. We use latent Dirichlet allocation with k-means clustering (Qiu and Xu, 2013) on the sentence level to automatically build sub-domains in the training data. Curriculum learning is applied to create sub-domain-adapted rnnlms for each sub-domain, which are combined using the combination methods in the previous experiment.Our second set of experiments addresses the challenge of limited-data within-domain adaptation. This challenge corresponds to the situation often faced by speech recognizers: a relatively large amount of data is available to train an initial model, and, with time, more and more data becomes available that can be used to update the model. The new data is from the same domain, but can be considered to be from a different sub-domain because of shifts in data characteristics over time. Here, we test a sub-domain adapted rnnlm, but focus particularly on the fact that the amount of adaptation data is limited and also on the fact that the vocabulary of the adaptation data is unknown at the time of training of the initial model.The rest of the paper is organized as follows. Section 2 discusses related work in the areas of adaptive language modeling, curriculum learning and other advanced language models such as rnnlms, mixture models and class based language models. In Section 3, we present the three types of curriculum learning that we use to train the sub-domain-adapted rnnlms. We then present the experiments addressing the challenge of within-domain adaptation (Section 4) and the challenge of limited-data within-domain adaptation (Section 5). The final section concludes and presents an outlook.

@&#CONCLUSIONS@&#
In this paper, we investigated the use of curriculum learning for the adaptation of rnnlms. We focus on two situations for language model adaptation, namely, within-domain adaptation and limited-data within-domain adaptation.To address within-domain adaptation, we use a component model method. Each component model is a sub-domain-adapted rnnlm trained by curricula that were scheduled from general patterns to specific patterns. For within-domain adaptation, three different experiments have been used to investigate three different situations, namely the oracle situation (sub-domain information is known during training and testing), the situation that sub-domain information is known only in training and the situation that the sub-domain information is unknown both in training and testing.Three different curriculum learning methods were proposed and analyzed, namely starting from the Same Vocabulary (Start-Vocab), Data Sorting (Data-Sort) and All-then-Specific training (All-Specific). We compared the sub-domain-adapted models that are trained by these methods with conventional rnnlms using a heterogeneous spoken Dutch data set. The results under the oracle condition under which sub-domain information is known at test time show that sub-domain-adapted models that were trained using Data-Sort and All-Specific outperform the conventional rnnlm. Especially on the “News” sub-domain, the sub-domain-adapted models achieved an over 50% reduction in terms of perplexity and a more than 30% improvement in terms of word prediction accuracy. The results reveal that curriculum learning can be used to shape the final rnnlms to emphasize the specific patterns in the sub-domains. An additional experiment demonstrated that the gains achieved by rnnlms are general: if the underlying rnnlm is improved, the curriculum learning adaptation method will translate the underlying improvement into an overall improvement.When the sub-domain information is not available in testing, the sub-domain-adapted models need to be combined to make final prediction. On the sentence level, two combination methods were used. Using hard decision method, for each sentence, one sub-domain-adapted model that gave the maximum probability was selected. Using soft decision method, for each sentence, a heuristic dynamic linear interpolation was used to combine the different sub-domain-adapted models. Experimental results show that the proposed model using these two methods outperform conventional rnnlms.Under the situation that the sub-domain information is unknown both in training and testing, the proposed models were tested using wsj data set in N-best rescoring. During the training, sub-domain information was obtained by using latent Dirichlet allocation in conjunction with k-means clustering. The experimental results show that rnnlm adaptation using Data-Sort curriculum learning can achieve a limited, but not entirely unpromising, reduction in terms of word error rate.To sum up, the set of experiments on within-domain adaptation shows that curriculum learning method can be used to train sub-domain-adapted models that emphasize the patterns characterizing specific sub-domains. Sub-domain-adapted models trained using curriculum learning outperform conventional rnnlms on the corresponding sub-domains. When sub-domain information is unknown during testing, the combinations of the sub-domain-adapted models using a soft combination or a hard combination outperforms conventional rnnlms and sentence level mixture rnnlms.To address limited-data within-domain adaptation, we use curriculum learning as an implicit interpolation method to combine patterns characteristic of existing training data with patterns characteristic of yet-unseen data. The results from our experiment on limited-data domain adaptation reveal that curriculum learning methods are more effective than conventional interpolation methods. The experiment also shows that updating of the existing rnnlms with curriculum learning requires training only on the yet-unseen data without retraining models from scratch by adding the yet-unseen data to the existing data.The comparison of these three types of curriculum learning proposed in this paper reveals that good performance is achieved by the curricula that are designed to be appropriate for specific data and specific challenges. In this paper, results on the wsj data set and on the cgn data set did not achieve comparable improvement. For this reason, our future work will focus on the relationship between the design of the curriculum and the characteristic of the target data.In this paper, we have chosen rnnlms to be representative of neural network language models, under the assumption that the application of curriculum learning to other neural network language models would yield similar behavior. Our future work will explore this assumption in greater detail, allowing further insight onto how the method put forth in this paper should best be operationalized.