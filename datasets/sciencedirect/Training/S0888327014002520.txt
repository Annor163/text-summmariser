@&#MAIN-TITLE@&#
Bayesian system identification of a nonlinear dynamical system using a novel variant of Simulated Annealing

@&#HIGHLIGHTS@&#
Bayesian system identification of a nonlinear dynamical system using a novel MCMC algorithm.The new algorithm – Data Annealing – is computationally cheap and requires little manual tuning.Data Annealing is applied to the system identification of a nonlinear dynamical system.This process is repeated using several competing model structures.The issue of model selection is addressed using the Deviance Information Criterion.

@&#KEYPHRASES@&#
Bayesian model updating,Nonlinear system identification,Markov chain Monte Carlo,Simulated Annealing,Deviance Information Criterion,

@&#ABSTRACT@&#
This work details the Bayesian identification of a nonlinear dynamical system using a novel MCMC algorithm: ‘Data Annealing’. Data Annealing is similar to Simulated Annealing in that it allows the Markov chain to easily clear ‘local traps’ in the target distribution. To achieve this, training data is fed into the likelihood such that its influence over the posterior is introduced gradually - this allows the annealing procedure to be conducted with reduced computational expense. Additionally, Data Annealing uses a proposal distribution which allows it to conduct a local search accompanied by occasional long jumps, reducing the chance that it will become stuck in local traps. Here it is used to identify an experimental nonlinear system. The resulting Markov chains are used to approximate the covariance matrices of the parameters in a set of competing models before the issue of model selection is tackled using the Deviance Information Criterion.

@&#INTRODUCTION@&#
This paper is concerned with the system identification of a nonlinear dynamical system using experimentally obtained training data. A probabilistic, Bayesian approach is utilised throughout. Such an approach is now well established in the structural dynamics community – relatively recent advances include the use of Bayesian methods in structural health monitoring [1], modal identification [2], state-estimation [3] (through use of the particle filter), the sensitivity analysis of large bifurcating nonlinear models [4] as well as an interesting study investigating the relations between frequentist and Bayesian approaches to probabilistic parameter estimation [5].The identification problem detailed herein is one of model selection as well as parameter estimation such that, using experimental dataD, one must endeavor to find the optimum modelMfrom a set of competing model structures as well as estimate the parameter vectorθof that particular model. Using Bayes׳ theorem a measure of the plausibility of a parameter vectorθ, given experimental dataDand assumed model structureM, is given by(1)P(θ|D,M)=P(D|θ,M)P(θ|M)P(D|M)whereP(θ|D,M)is the posterior probability density function (PDF) which one wishes to evaluate,P(D|θ,M)is termed the likelihood,P(θ|M)the prior andP(D|M)the evidence. The likelihood represents the probability that the experimental training dataDwas witnessed according to the modelMwith parametersθ. Defining the likelihood requires the selection of an error-prediction model which describes the uncertainties present in the measurement and modelling processes (see [6] for a detailed discussion of error-prediction models). The prior is a PDF which represents one׳s parameter estimates for modelMbefore the training data was known. The evidence is a normalising constant which ensures that the posterior PDF integrates to one.This paper makes two main contributions. Firstly, a novel variant of Simulated Annealing (referred to as Data Annealing) is proposed and applied to a real system identification problem. It is shown to be computationally cheap and easy to tune. Secondly, it is shown that the issue of model selection of a real nonlinear dynamical system can be addressed using the Deviance Information Criterion (DIC). For the sake of readability the remainder of the introduction is split into two sections. The first outlines the motivation for the Data Annealing algorithm while the second focuses on the issue of model selection.For the case where one is attempting to identify NDparameters (such thatθ∈RND), the evidence is given by(2)P(D|M)=∫⋯∫P(D|θ,M)P(θ|M)dθ1⋯dθND.This integral is usually intractable and its multidimensional nature makes it too computationally expensive to evaluate numerically (ifND>2). Relatively early papers such as [7] made use of the property that the maximum a posteriori (MAP) parameter vector remains the same regardless of whether the posterior distribution has been normalised such that, through locating the MAP, a Taylor series expansion of the log posterior could be used to approximate the posterior PDF as a Gaussian.11For more information the reader may wish to consult the description of the Laplace approximation given in reference [8]Since then, an increase in computing power has allowed the adoption of Markov chain Monte Carlo (MCMC) methods. These involve the creation of an ergodic Markov chain whose stationary distribution is equal to the posterior PDF such that, once converged, the Markov chain is generating samples fromP(θ|D,M)(see [9] for more information on the convergence of Markov chains). This can be achieved without having to evaluate the evidence term. While many MCMC methods are available in the literature (Hamiltonian Monte Carlo for example [10]), by far the most popular is the Metropolis algorithm. Although well-established, a brief description of the Metropolis algorithm is given here as it helps to establish the motivation for the Data Annealing algorithm presented in Section 2 of this work.Essentially, the aim of MCMC methods is to generate a sequence of samples{θ(1),θ(2),…}from a target PDFπ(θ)/Z(where Z is a normalising constant). In the context of this paper,π(θ)represents the unnormalised posterior PDF and Z represents the evidence term. Initialising the Metropolis algorithm from parameter vectorθ(i), a new stateθ′is proposed using a user-defined proposal PDF. The proposal PDF is conditional on the current stateθ(i). For example, in the case where a Gaussian proposal is used then the new state is generated according to(3)θ′~N(θ(i),Σ)(whereΣis a user-defined covariance matrix). The new state is then accepted with probability:(4)a=min{1,π(θ′)π(θ(i))}.If accepted thenθ(i+1)=θ׳elseθ(i+1)=θ(i). This has the property that if the proposed stateθ′is in a region of higher probability density than the current state then it is always accepted. However, the Markov chain is also able to move into regions of lower probability density. One of the benefits of using such an acceptance rule is that the acceptance probability a can be computed without having to evaluate the evidence term. It can be shown that such an acceptance rule allows the chain to generate samples fromπ(θ)(for more information references [8,11] are recommended).The advantages of using MCMC are numerous. Recalling that the purpose of system identification is usually to establish a reliable model which can be used to accurately and robustly predict the system׳s future response then, using the notation outlined in [12], one may want to predict a structural quantity of interesth(θ)using(5)R=∫⋯∫h(θ)P(θ|D,M)dθ1⋯dθND.While evaluating Eq. (5) is difficult (for the same reason it is difficult to evaluate the evidence term), if one has used an MCMC algorithm to generate samples{θ(1),…,θ(M)}from the posterior parameter distribution then Eq. (5) can be approximated by(6)R≈1M∑i=1Mh(θ(i)).Additionally, it has been shown that important information with regard to parameter correlations can be realised through the use of MCMC methods [13] (this is also demonstrated in Section 4 of the present work). However, MCMC also has its disadvantages. Before samples from the target distribution can be drawn in an effective manner, the Markov chain must converge on the globally optimum region of the parameter space. This region can be difficult to locate as it is often very concentrated relative to the size of one׳s prior distribution. Additionally, the Markov chain may become ‘stuck’ in a region of probability density which is not the global optimum. Throughout this paper these regions are referred to as ‘local traps’.The issue of local trapping led to the development of the Simulated Annealing algorithm [14]. This involves the introduction of a factitious temperature22The phrases ‘annealing’ and ‘temperature’ are used as the Simulated Annealing algorithm was originally developed by drawing analogies with statistical physics [14]. The relations between Bayesian inference and statistical physics are discussed in [11].variable T such that, at high temperatures, the Markov chain is able to easily travel over local traps in the parameter space. The temperature variable is then reduced such that the fine details of the target distribution are gradually introduced – this is demonstrated graphically for a bimodal target PDF in Fig. 1(whereπTrepresents one׳s target distribution at temperature T). The rate at which T is reduced is commonly referred to as the annealing schedule.Although this does not guarantee that the chain will converge on the optimum region of parameter space, Simulated Annealing has been established as a reliable optimisation algorithm. Soon after it was introduced several variants of Simulated Annealing were proposed [15,16] in which the spread of the proposal PDF is initially set to be large but then reduces with temperature T (at a user-defined rate), thus encouraging the Markov chain to make large jumps at higher temperatures but conduct a more local search at lower temperatures.When applied to Bayesian inference, the variable T can be introduced such that it controls the influence of the likelihood on the posterior:(7)πT(θ)∝P(D|θ,M)TP(θ|M).Through using Eq. (7) as one׳s target distribution and defining an annealing schedule where T varies monotonically between 0 and 1, a gradual transition between the prior and posterior distribution can be realised. This concept was utilised in [12,17,18] where, by exploiting this gradual transition from prior to posterior, MCMC algorithms were developed which can be used to sample from posterior parameter distributions with complex geometries (where multiple, or even a continuum of optimum parameter vectors exist).The performance of any Simulated Annealing algorithm will be sensitive to the choice of annealing schedule – annealing too fast places one at risk of becoming stuck in a local trap (such that a long time is required for the Markov chain to converge to its stationary distribution) while annealing too slowly will prove to be computationally expensive. It is possible to overcome this issue through the use of ‘adaptive’ annealing schedules such as those proposed in [17–19].While the afore-mentioned algorithms are undoubtedly powerful, they can prove to be computationally expensive. One of the main aims of the current paper is to present a relatively cheap annealing algorithm which, within the context of Bayesian inference, can be applied to computationally demanding models.The issue of model selection occurs when one must choose from a variety of competing model structures. This is complicated by the fact that models with more parameters will likely be able to better replicate some training data than models with less parameters. Consequently, if one judges models simply on their ability to replicate training data, then the most complex of the competing structures will always be accepted. Models which are overly complex for the problem at hand are referred to as overfitted. Such models are often poor representations of the physics involved in the system of interest and, as a result, are poorly suited to making future predictions.For a scenario where different model structures are available, the probability that the modelMiis suitable given the dataDcan also be written using Bayes׳ theorem:(8)P(Mi|D)=P(D|Mi)P(Mi)P(D)thus allowing one to write the relative probability of two different models, given dataD, as(9)P(Mi|D)P(Mj|D)=P(D|Mi)P(Mi)P(D|Mj)P(Mj)whereP(Mi)andP(Mj)represent one׳s prior beliefs in the suitability of each model (typically set equal to one another) andP(D|M)is the evidence term in Eq. (1). It is possible to show that the Bayesian approach to model selection automatically prevents overfitting (see [8,20] for more information). However, as was described in the previous section, the evidence term is difficult to evaluate. As a result, one may instead choose to use a different model selection paradigm which is easier to evaluate than Eq. (9) but also retains the same model selection properties. In this work the Deviance Information Criterion (DIC) [21] is used as a model selection criterion.Before describing the Deviance Information Criterion (DIC) it is convenient to first define the deviance:(10)D(θ)=−2lnP(D|θ,M)where, as stated previously,P(D|θ,M)is the likelihood. The expected DevianceE[D(θ)]is a measure of how well the model structureMfits the data (as the parameter vector has been marginalised). The DIC is then defined as(11)DIC=2E[D(θ)]−D(θ^),where(12)E[D(θ)]=∫P(θ|D,M)D(θ)dθand(13)θ^=E[P(θ|D,M)]=∫P(θ|D,M)θdθsuch that the ‘best’ estimate parameters(θ^)are defined as the expected value of the posterior parameter distribution. Essentially, the lower the DIC, the more favourable the model. It also has the desired property that it rewards model fidelity while penalising model complexity (see reference [22] for a more detailed discussion).The DIC lends itself well to situations where one has sampled from the posterior parameter distribution using MCMC as, using the successive parameter vectors realised by the MCMC algorithm{θ(1),θ(2),…,θ(M)}, the optimum parameter vectorθ^can be approximated by(14)θ^≈1M∑i=1Mθ(i)while the expected deviance can also be approximated by(15)E[D(θ)]≈1M∑i=1MD(θ(i))thus allowing one to approximate the DIC. While this has been applied to synthetic data in [13], the current work demonstrates its application to real experimentally obtained data.The paper is organised as follows. In Section 2 the novel annealing algorithm is presented. In Section 3 the experimental system of interest is described. In Section 4 the results of the new annealing algorithm are analysed. This includes an analysis of the parameter correlations and predictive capabilities of competing model structures. The issue of model selection is then addressed using the Deviance Information Criterion (DIC). Section 5 is concerned with presenting possible future work while the conclusions are presented in Section 6.As stated in the previous section, MCMC methods can be used to generate samples from an unnormalised target PDFπ(θ). In the context of this paper the target PDF is given by(16)π(θ)=P(D|θ,M)P(θ|M).In practice it is usually desirable to evaluate the logarithm of the target PDF:(17)ln(π(θ))=ln(P(D|θ,M))+ln(P(θ|M))as, by first findinglna=lnπ(θ′)−lnπ(θ(i))before evaluatinga=exp(lna), one can often avoid numerical overflow/underflow issues when calculating Eq. (4).For the case where there are N measurements in the training data:(18)D={D1,…,DN}then, assuming that each measurement is mutually independent, the likelihood is given by(19)P(D|θ,M)=∏i=1NP(Di|θ,M).In the case investigated here the training dataDconsists of a vector of inputs{y1,y2,…,yN}and a vector of measured outputs{x1,x2,…,xN}(the physical meaning of x and y is discussed in Section 3). Using a Gaussian error-prediction model allows the likelihood to be written as(20)P(D|θ,M)=∏i=1N[12πσexp(−12σ2(xi−x^i(θ)2))]wherex^i(θ)represents the response of the model with parametersθand σ2 is the likelihood variance (which can be treated as another parameter to be found). Consequently, a single evaluation of the likelihood requires the simulation of N data points. It is suggested here that, rather than using T to control the influence of the likelihood on the posterior (as with Simulated Annealing), a similar effect can be achieved by varying the amount of data used in the likelihood. In other words, it is possible to increase the influence of the likelihood through the introduction of additional data points intoD. The rate at which the data points are introduced can be controlled according to a user-defined schedule – this is conceptually similar to the annealing schedule used in Simulated Annealing. The major advantage of this method is that it is computationally fast – in the early stages of the algorithm relatively few points need to be simulated by the model per evaluation of the likelihood. Throughout the current work this method is referred to as Data Annealing. It should be noted that the concept of annealing through the gradual addition of data points in the likelihood was proposed but not actually implemented in [12].As was stated in Section 1, the Metropolis algorithm requires a user-defined proposal PDF to generate candidate parameter vectorsθ′– this is often chosen to be a Gaussian. In the current work the proposal PDF will be denotedq(θ′|θ(i)). In [15] it was suggested that, to reduce the probability of the Markov chain becoming stuck in a local trap, a proposal distribution with larger tails should be used in place of a Gaussian distribution. Specifically, it was suggested that a Cauchy distribution could be utilised as, while it is locally similar to a Gaussian, it possesses larger tails (as shown in Fig. 2). This is desirable as, while the resulting Markov chain will spend the majority of the time conducting a local search of the parameter space, it will also occasionally propose relatively large jumps (thus increasing its ability to escape from local traps).A disadvantage of this method becomes apparent when the dimension of the parameter space is greater than one as samples from the multidimensional Cauchy distribution are not uncorrelated – large jumps in one parameter will often be accompanied by large jumps in all of the other parameters [11]. In the author׳s opinion this seems rather restrictive. Here, it is proposed that each parameter inθcan be sampled independently from a one-dimensional Cauchy distribution such that, for parameter θn:(21)q(θn′|θn(i))=[πλn(1+(θn′−θn(i)λn)2)]−1(where λncontrols the width of the distribution). Consequently, for the case whereθ∈RND, the complete proposal distribution is simply the product of NDCauchy distributions:(22)q(θ′|θ(i))=∏n=1NDq(θn′|θn(i)).The result is a valid PDF which integrates to one, maintains the irreducibility of the Markov chain, allows one to perform a local search with occasional long jumps and does not have the afore-mentioned restrictive properties of the multidimensional Cauchy distribution. In fact, this property is so useful that an effective exploration of the parameter space can be achieved without having to vary the spread of the independent distributions{λ1,…,λND}with annealing time – this is demonstrated in Section 4 of the current work. It should be noted that in Eq. (22) one has the option of choosing different proposal widths for different parameters. This may be advantageous when the parameters are of very different scales. However, it was found here that simply running the Data Annealing algorithm using the logarithm of the parameter vector allowed one to achieve good mixing despite using the same distribution width for each parameter.A schematic of the nonlinear dynamical system of interest is shown in Fig. 3. A ‘centre magnet’ is positioned such that it is free to slide along an aluminium rod via a set of linear bearings. Two ‘outer magnets’ are attached to the aluminium rod – they are positioned such that their poles oppose that of the centre magnet (thus creating a magnetic restoring force on the centre magnet). Consequently, when excited by the shaker, the centre magnet experiences oscillatory motion relative to the shaker table. Originally developed in the context of nonlinear energy harvesting, it is known that the magnetic restoring force on the centre magnet can be closely approximated using a linear and cubic stiffness term (similar to the hardening spring Duffing oscillator) [23]. As a result, the equation of motion of the system is(23)mx¨=−cż−kz−k3z3−mg−F,z=x−ywhere x is the absolute displacement of the centre magnet, y is the displacement of the shaker table, m is the mass of the centre magnet, c is viscous damping, k is the linear stiffness, k3 is the cubic stiffness and g is gravity. The training dataDis made up of discretely sampled values of the excitation y (measured using the LVDT in Fig. 3) and of the centre magnet response x (measured using the laser in Fig. 3). The quantity F represents the force on the centre magnet as a result of friction effects. Three different friction models were considered. Firstly it was investigated whether the friction effects could be modelled simply using the viscous damping term c. Secondly, the Coulomb damping model was utilised such that(24)F=Fcsgn(ż)where Fcis a parameter to be estimated. Finally, it was hypothesised that the hyperbolic tangent model was appropriate:(25)F=Fctanh(βż)(where Fcand β are parameters to be estimated). Throughout this paper these candidate models are referred to as the viscous, Coulomb and hyperbolic tangent models respectively. The hyperbolic tangent model has the property that(26)limβ→∞tanh(βż)=sgn(ż)such that it is able to form a close approximation to the signum function without being discontinuous atż=0. It should be noted that the mass of the centre magnet was measured accurately before testing and so, in the following analysis, it is not included in the vector of parameters to be estimated.With regard to the applied excitation, a signal generator was used in conjunction with a PID controller to create a band-limited white noise acceleration. For a more detailed discussion of this experiment (which was also developed in the context of energy harvesting) the reader is directed towards references [24,25]. Two seconds of data measured at 1500Hz was used as training data (this is shown in Fig. 4).

@&#CONCLUSIONS@&#
In this paper the system identification of an experimental nonlinear dynamical system was investigated using three competing model structures. A new MCMC algorithm named ‘Data Annealing’ was proposed. Being conceptually similar to Simulated Annealing, Data Annealing is designed such that, at its initial stages, the prior distribution dominates the shape of the target distribution. This allows the Markov chain to move freely around the parameter space. Additional training data is then progressively introduced into the likelihood such that the influence of the likelihood on the posterior is gradually increased. This computationally cheap method improves the ability of the Markov chain to converge on the globally optimum region of the parameter space without getting stuck in ‘local traps’. Additionally, the Data Annealing algorithm utilises a proposal distribution which allows it to conduct a local search of the parameter space accompanied by occasional long jumps. It was shown that this proposal distribution is well suited to the problem at hand as it initially allows the Markov chain to explore large regions of the parameter space while is also capable of providing a more local search once the chain has converged. This was achieved without having to alter the width of the proposal distribution. Having demonstrated the Data Annealing algorithm on a real system identification problem, the resulting Markov chains were used to extract approximate covariance matrices for all of the models investigated, thus revealing information about parameter correlations induced by the data. Finally, a model selection criterion known as the Deviance Information Criterion was used to select the most appropriate model from the set of competing structures. It was shown that the DIC can be used to identify a model which can accurately replicate a set of training data without being overfitted (relative to the other elements in a set of user-defined model structures).